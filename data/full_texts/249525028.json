{"id": 249525028, "updated": "2022-06-12 07:25:51.865", "metadata": {"title": "PAPILA: Dataset with fundus images and clinical data of both eyes of the same patient for glaucoma assessment", "authors": "[{\"first\":\"Oleksandr\",\"last\":\"Kovalyk\",\"middle\":[]},{\"first\":\"Juan\",\"last\":\"Morales-S\u00e1nchez\",\"middle\":[]},{\"first\":\"Rafael\",\"last\":\"Verd\u00fa-Monedero\",\"middle\":[]},{\"first\":\"Inmaculada\",\"last\":\"Sell\u00e9s-Navarro\",\"middle\":[]},{\"first\":\"Ana\",\"last\":\"Palaz\u00f3n-Cabanes\",\"middle\":[]},{\"first\":\"Jos\u00e9-Luis\",\"last\":\"Sancho-G\u00f3mez\",\"middle\":[]}]", "venue": "Scientific Data", "journal": "Scientific Data", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Glaucoma is one of the ophthalmological diseases that frequently causes loss of vision in today\u2019s society. Previous studies assess which anatomical parameters of the optic nerve can be predictive of glaucomatous damage, but to date there is no test that by itself has sufficient sensitivity and specificity to diagnose this disease. This work provides a public dataset with medical data and fundus images of both eyes of the same patient. Segmentations of the cup and optic disc, as well as the labeling of the patients based on the evaluation of clinical data are also provided. The dataset has been tested with a neural network to classify healthy and glaucoma patients. Specifically, the ResNet-50 has been used as the basis to classify patients using information from each eye independently as well as using the joint information from both eyes of each patient. Results provide the baseline metrics, with the aim of promoting research in the early detection of glaucoma based on the joint analysis of both eyes of the same patient.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": "35680965", "pubmedcentral": "9184612", "dblp": null, "doi": "10.1038/s41597-022-01388-1"}}, "content": {"source": {"pdf_hash": "bc46bee660a3b8211b03bb7479a1f3ba1f27f798", "pdf_src": "PubMedCentral", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": null, "status": null}}, "grobid": {"id": "15c7c4dd2419129a06481c861f6db22efd3c21e7", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/bc46bee660a3b8211b03bb7479a1f3ba1f27f798.txt", "contents": "\nPaPILa: Dataset with fundus images and clinical data of both eyes of the same patient for glaucoma assessment\n\n\nOleksandr Kovalyk \n\u2709 \nJuan Morales-S\u00e1nchez \n\u2709 \nRafael Verd\u00fa-Monedero \n\u2709 \nInmaculada Sell\u00e9s-Navarro \nPalaz\u00f3n-Cabanes \nJos\u00e9-Luis Sancho-G\u00f3mez \nPaPILa: Dataset with fundus images and clinical data of both eyes of the same patient for glaucoma assessment\n10.1038/s41597-022-01388-11 Scientific Data | (2022) 9:291 | https://\nGlaucoma is one of the ophthalmological diseases that frequently causes loss of vision in today's society. Previous studies assess which anatomical parameters of the optic nerve can be predictive of glaucomatous damage, but to date there is no test that by itself has sufficient sensitivity and specificity to diagnose this disease. this work provides a public dataset with medical data and fundus images of both eyes of the same patient. Segmentations of the cup and optic disc, as well as the labeling of the patients based on the evaluation of clinical data are also provided. the dataset has been tested with a neural network to classify healthy and glaucoma patients. Specifically, the ResNet-50 has been used as the basis to classify patients using information from each eye independently as well as using the joint information from both eyes of each patient. Results provide the baseline metrics, with the aim of promoting research in the early detection of glaucoma based on the joint analysis of both eyes of the same patient.\n\nprogresses, the cup becomes larger, usually due to the raising of the intraocular pressure, resulting in an increase of the CDR value, a decrease of the RDR value over time and the violation of the ISNT rule. The measurement of these parameters can be done manually by experts or by automatic methods based on image processing 10,11 and/or machine learning 12,13 .\n\nIn the last decade, research efforts have been directed mainly towards methods based on deep learning 14 , which have proven to be very effective in image classification and segmentation tasks, achieving very promising results in the field of ophthalmology 13 . For current reviews of existing methods to aid in the diagnosis of glaucoma, the reader is invited to consult the works of, e.g., Thakur 15 or Almazroa 16 . These methods generally need a large and properly-labeled dataset to train their machine learning models, and the success of the model working in operation mode depends directly on the quality and quantity of the training dataset 17 . In general, building a dataset is a time-consuming task, which becomes more tedious when it handles medical data from several sources. As detailed below and in Table 1, particularly in the diagnosis of glaucoma, there are some datasets only with RFI (not always properly diagnosed), and others dataset which also provide the segmentation of the optic disc, optic cup or both.\n\nNeither the datasets described below nor any other that had been located by the authors contains clinical data as well as retinal fundus images of both eyes of the same patient. For this reason, the proposed PAPILA dataset intends to be useful for developing algorithms which learn and discover other supplemental manifestations using the joint information of both eyes for the early diagnosis of glaucoma, that could be too difficult to notice considering an isolated eye.\n\n\nMethods\n\nThis section details existing databases and describes the proposed dataset explaining the criteria followed in the design and the reasons for including or not including patients in it. The description of every clinical data gathered for each patient is also detailed. existing databases. There are widely used and referenced datasets with RFI such as, e.g., DRIVE 18,19 , which contains 40 fundus images and deals with diabetic retinopathy providing the segmentation of blood vessels; DiaRetDb1 20,21 , with 89 color fundus images with their segmentation and annotated information for different diabetic retinopathies; the STARE project 22,23 with 400 labeled images, as well as the segmentation of the optic nerve in 80 images; DRIONS 24,25 with no-labeled 110 images and two segmentations of the optic disc for each one. Focused specially on glaucoma, some of the most known datasets are the following:\n\n\u2022 The Messidor project 26,27 , whose main purpose is to compare and evaluate segmentation algorithms developed for the detection of lesions in color retinal images. This dataset contains 1200 fundus images with its corresponding medical diagnosis. \u2022 RIGA 28,29 is a dataset for glaucoma analysis with 750 retinal fundus images. The dataset provides the optic cup and optic disc boundaries for each image but the glaucoma diagnosis is not given. \u2022 ORIGA 30 is composed of 482 images of healthy patients and 168 images from patients with glaucoma, together with the segmentation of the disc and cup. This dataset was public and downloadable in 2010 but at this moment it seems not to be longer publicly available. \u2022 The public dataset RIMONE 31 was firstly released in 2011 32 . Four years later, in 2015, 159 stereo fundus images with two ground truth segmentations of disc and cup were provided to assess the CDR 33 . These images corresponded to healthy and glaucoma patients. Recently, in 2020, the dataset has been revisited and optimized for a deep-learning context 34 . The updated dataset contains 313 retinographies from normal subjects and 172 retinographies from patients with glaucoma. \u2022 Drishti-GS 35,36 is a publicly available dataset for glaucoma assesment with optic disc and cup segmentations.\n\nIt consists of 101 monocular fundus images (70 images of glaucoma and 31 normal images), split in training and test sets, with four expert segmentations of the disc and cup for the training set. www.nature.com/scientificdata www.nature.com/scientificdata/ \u2022 ACRIMA 37,38 contains 705 labelled public fundus images (396 glaucomatous images and 309 normal images).\n\nThe annotations were made by two glaucoma experts and no other clinical information was taken into account while providing labels for the images. \u2022 G1020 39,40 is a large retinal fundus image dataset with 1020 publicly available fundus images (724 healthy and 296 glaucoma) for glaucoma diagnosis. Labeling of the images, as well as optic disc and optic cup segmentation is provided. \u2022 The recent REFUGE dataset 13,41 contains 1200 fundus images with ground truth segmentations of the optic disc and optic cup, and clinical glaucoma labels (120 images from patients with glaucoma and 1080 images from healthy patients).\n\n\nSelection of patients. The PAPILA dataset was collected at the Department of Ophthalmology of the\n\nHospital General Universitario Reina Sof\u00eda, HGURS, (Murcia, Spain) between years 2018 and 2020. This study was carried out in accordance with the tenets of the Declaration of Helsinki and with the approval of the hospital's Ethics Committee. After signing an informed consent, the patients were divided into two groups: In Group 1, patients diagnosed with simple chronic glaucoma recruited in the Glaucoma Area of the HGURS; and in Group 2, patients from primary care who, after a ophthalmological examination, did not show any ocular pathology that could influence the morphology of the optic nerve.\n\nThe following medical data of both eyes was collected from all patients: refractive error, intraocular pressure, central corneal thickness (used to adjust IOP according to pachymetry), axial length and a color fundus image. In addition, when patients of Group 2 had IOP greater than 22 mmHg, the Visual Field (VF) was also retrieved using the 30-2 program 42 . It is considered that a visual field has lesions suggestive of glaucoma when, complying with the confidence indices, at least three points in the same hemifield are observed with values 5% below of normal, excluding the pericecal and peripheral rows. In these cases, the VF was repeated, and glaucomatous damage was diagnosed if the defects were consistent. Table 2 gathers this medical data and details the models of each acquisition device.\n\nRegardless the group, patients with opacities in the transparent media (corneal alterations and advanced cataracts) that prevented obtaining an assessable fundus image were excluded from the study. The alteration in the confidence indices of the VF was another reason for excluding a patient if the alteration persisted in two consecutive tests.\n\nAccording to the ophthalmological examination, patients in Group 2 were further classified into: Group 2.a, with individuals without glaucoma-related ocular pathology and whose IOP was less or equal than to 22 mmHg; Group 2.b with ocular hypertensive individuals, whose IOP ranged between 22-28 mm Hg without visual field affectation. No patients with IOP greater than 22 mmHg and lesions suggestive of glaucomatous neuropathy were detected.\n\nThe sample size of patients belonging Group 2 was obtained considering the population of Area VII of the city of Murcia and the prevalence of simple chronic glaucoma (3,5% in the population older than 40 years), applying a confidence level of 95% and a 3% margin of error.\n\nComposition of the dataset. The proposed PAPILA dataset contains records of 244 patients. Each record provides structured information about clinical data, optic disc and optic cup segmentations of both eyes of the same patient. Labeling with the diagnosis is also provided considering clinical data. The records were properly anonymized and an unique identifier was assigned to each record. More specifically, each record contains:\n\n\u2022 Age and gender of the patient.\n\n\u2022 RFI of both the left and right eye, centered at the papilla with an aperture of 30\u00b0, in JPEG format, with 8 bits per color channel (see Fig. 1). These images have been acquired by ophthalmologist or technicians in the HGURS (Murcia, Spain), using a Topcon TRC-NW400 non-mydriatic retinal camera with a resolution of 2576 \u00d7 1934 pixels. \u2022 Knowledge transferred by ophthalmologists:\n\n-Trustworthy labeling of the patient. Three cases are considered: glaucomatous, non-glaucomatous and suspect. The diagnostic labels were assigned based on the comprehensive evaluation of the clinical data of the subject (sometimes with a retrospective analysis of clinical records). Table 4 shows the distribution of the type of patients detailing gender and age ranges.  www.nature.com/scientificdata www.nature.com/scientificdata/ -Segmentations of the OD and OC in RFI of both eyes. Manual annotations provided by two expert ophtalmologists with two (Expert #1) and twenty seven (Expert #2) years of experience, from the Department of Ophthalmology at HGURS. The annotation procedure consisted in manually placing points (pixel-wise) linked with lines to delineate the contours of the OD ad OC, separately, with an own developed tool with capabilities for image review, zoom and contour editing.\n\n\nMedical data Acquisition device Model\n\n\u2022 Clinical data and medical test results:\n\n-Refractive error. Vision problem that happens when the shape of the eye does not bend light correctly and keeps light from focusing correctly on the retina, resulting in a blurred image. The main types of refractive errors are myopia (nearsightedness), hyperopia (farsightedness), presbyopia (loss of near vision with age), and astigmatism. A person with myopia would have a negative refractive error, a person with emmetropia would have zero refractive error and a person with hyperopia would have a positive refractive error. In the case of astigmatism associated with the previous defects, the refractive error is expressed with 3 values: sphere, cylinder and axis. -Crystalline lens. This item informs if the eye has the crystalline lens (phakic) or if it has been surgically removed (pseudophakic). -IOP of both eyes. Normal values for healthy patients range from 10 mmHg to 21 mmHg. Values of IOP are obtained using non-contact tonometer Nidek NT-2000 using the Pneumatic or Perkins method. -Corneal thickness. This measurement is obtained by pachymetry with the specular microscope pachymeter Rodenstock REM 3000. The mean value in healthy patients is 540 \u03bcm. This characteristic is relevant in patients with glaucoma since it perturbs IOP measurements. Depending on the corneal thickness, a correction factor (see Table 3) must be added to or subtracted from the IOP value 43 . -Axial length. This is the distance between the anterior vertex (central area of the cornea) and the posterior pole of the eye (central area of the retina). The axial length of the eye is approximately 24 mm in adulthood. It is typically longer than 24 mm in myopes and shorter than 24 mm in hyperopes. This measurement has been obtained by optical biometry with the Zeiss IOL Master 500. -Mean defect (MD) of both eyes. This parameter, equivalent to the Visual Field Index (VFI), has been measured with the Humphrey field analyzer Zeiss Humphrey 750i following the 30-2 strategy 42 (assessing a grid of 76 points over the central 30\u00b0 of the visual field). This measurement gives an overall value of the total amount of visual field loss compared to the normal sensitivity expected for the population group with the age of the patient. Normal values typically range from 0 dB to \u22122 dB. The MD value becomes more negative as the overall field worsens. The MD value can be helpful for monitoring visual field loss in moderate-stage glaucomatous patients (\u22126 dB to 12 dB). A patient with glaucoma and MD between \u22123 dB and \u22126 dB is classified as mild glaucoma, values between \u22126 and \u221212 dB is moderate glaucoma and above \u221212 dB is severe glaucoma (see Fig. 3). This test is retrieved only in glaucomatous patients from Group 1.   Table 4. Distribution of the type of patients in the PAPILA dataset according to gender and age ranges. The count has been made eye-wise since the diagnosis is made for each eye separately.  www.nature.com/scientificdata www.nature.com/scientificdata/\nFactor (mmHg) +5 +4 +4 +3 +2 +1 +1 0 \u22121 \u22121 \u22122 \u22123 \u22124 \u22124 \u22125\n\nData Records\n\nThe complete PAPILA dataset 44 is available at the public figshare repository https://doi.org/10.6084/ m9.figshare.14798004.v1. The dataset has a directory tree with the following structure:\n\nThe folder ClinicalData contains the clinical data and the diagnosis of 244 patients. The information of the patients is stored in spreadsheet format in two separate files, one for the right eye (OD) and one for the left eye (OS). The acronyms OD and OS refer, respectively, to the right eye and to the left eye in Latin, i.e., Oculus Dexter and Oculus Sinister. These files have the information organized in a table where each row corresponds to a patient and the columns contain the following fields: the unique patient identifier, the age of the patient, the gender of the patient (0 for male and 1 for female), the diagnosis (0 stands for healthy, 1 for glaucoma, and 2 for suspicious), the refractive error, phakic/pseudophakic (1 means that the crystalline lens has been removed and 0 means that the eye keeps the lens), the intraocular pressure, the pachymetry, the axial length, and the mean defect.\n\nThe next folder, ExpertsSegmentations, stores the segmentations of the optic disc and optic cup of the two eyes of each patient performed by the two ophthalmologists. There are 2 \u00d7 2 \u00d7 2 \u00d7 244 = 1952 files with the X and Y coordinates, in plain text, of the nodes of each contour. The names of the files have the following nomenclature: the prefix RET, three digits with the patient number, the string OD or OS indicating whether it is the right or left eye, the string cup or disc indicating which contour it is, and a final string exp1 or exp2 indicating the expert who performed the segmentation. For ease of understanding and illustrative purposes, this folder also contains the fundus images in JPEG format with the segmentation contours superimposed of both experts (see Fig. 2).\n\nThe folder FundusImages provides the 2576 \u00d7 1934 retinal fundus images of both eyes of all patients. There are 488 files in JPEG format corresponding to the right and left eye of 244 patients. The names of these files follow the same nomenclature as the files with the segmentations.\n\nFinally, the folder HelpCode include some programs to help any researcher to handle the data provided.\n\n\ntechnical Validation\n\nValidation of patient's clinical data. Initially, the results of the ophthalmological tests were collected manually in the hospital from each of the devices described in Table 2, along with the fundus images. The test results were subsequently transcribed into a spreadsheet and carefully reviewed by ophthalmologists to verify that there were no outliers or inconsistencies in the data. Unfortunately, due to some impediments, a small set of records lacks certain irrecoverable information (Table 5), although it has the labeling with the diagnosis as well as the segmentations of the two experts. The authors have considered keeping these records because, although incomplete, they may be useful in classification methods with missing data 45,46 .\n\nValidation of expert segmentations. The segmentations of the optic disc and optic cup have been carried out by two ophthalmologists taking into account their deep knowledge and extensive experience, concretely, two and twenty seven years of experience in the specialty of Ophthalmology. However, due to the existence of a subjective component, the consistency of the segmentations has been measured using the Sorensen-Dice coefficient. For this purpose, a mask, i.e. a binary image with the same size as the RFI, has been generated from each contour with the pixels inside the contour set to one and the pixels that lie outside the contour set to zero. Then, the similarity between the contours made by the two experts has been computed as\n\u2229 = + D A B A B A B ( , ) 2 ,(1)\nwhere A and B are the corresponding binary masks and D(A,B) ranges from 0 (no similarity between the masks) to 1 (both masks are identical). To guarantee the quality of the segmentations, two minimum thresholds have  www.nature.com/scientificdata www.nature.com/scientificdata/ been established in the measurements: 0.8 in the case of the optic disc segmentations, and 0.7 for the segmentations of the cup (except in the case of patients with very small optic cups).\n\nTo assess the interobserver and intraobserver variability in the segmentation of the optic disc and optic cup in retinal fundus images, the Sorensen-Dice similarity coefficient and the area-based cup-to-disc ratio (CDR) 47 have been computed, performing student's t-tests over the CDR measurements. The interobserver metrics consider both eyes of all the 244 patients in the database, i.e., 488 eyes, whereas the intraobserver metrics have been calculated with a random selection of 15 patients, i.e., 30 eyes, whose segmentations of the cup and optic disc have been done again by the experts two years after the first time.\n\nSecond and third columns of Table 6 gather the interobserver and intraobserver agreement between manual segmentations expressed as mean \u00b1 standard deviation of the Sorensen-Dice similarity coefficient. As can be seen, the agreement between the segmentations is greater with the optic discs than with the cups, both in the interobserver and intraobserver measurements. In general, the edges of the optic disc are clearly visible and its segmentation is easier than the segmentation of the optic cup, which requires expert knowledge and has a higher degree of subjectivity. Another result that can be deduced is that the intraobserver agreement is slightly higher than the interobserver, both in the disc and cup measurements.\n\nIn addition, the interobserver and intraobserver variability has been evaluated on the difference in the area-based CDR using the segmentations of the experts. The CDR is used in Ophthalmology to evaluate the evolution of glaucoma and compares the diameter of the cup with the diameter of the disc (the value of CDR ranges from 0 to 1). To determine if the means of two sets of measurements are significantly concordant from each other a student's t-test have been performed. Forth to sixth columns of Table 6 show the results of these tests. The forth column of Table 6 contains the mean and standard deviation of the difference of the CDR for the interobserver and intraobserver cases, the fifth column provides the p-value associated to the corresponding matched measurements, and the last column shows the 95% confidence interval (CI) for the true mean of each test.\n\nBaseline results for supervised fundus image classification. To demonstrate the technical validity and give some insight into the statistical quality of the dataset, some direct experiments were performed. The proposed dataset can be used for machine learning purposes in a variety of tasks, with the diagnosis of patients being the most significant. The aim of these experiments is to provide baseline classification metrics that could be useful as a reference for future research. The primary diagnosis approach underlying in the experiments is based on deep Convolutional Neural Networks (CNNs), which have demonstrated to be effective methods for image classification. In the experiments a rectangular Region of Interest (ROI) that includes the optic disc was considered. These ROIs were cropped from original fundus images and resized to 200 \u00d7 200 \u00d7 3 before feeding the neural network. The segmentations of the optic disc made by expert 1 (included in the proposed dataset) were used to determine the optic disc bounding box for every fundus image, and from them to extract a ROI of fixed and common size. This idea for ROI extraction is a common practice and diverse research 48,49 can be found about fine or coarse optical disc segmentations in retinal images, which constitute satisfactory and automatic methods to achieve comparable ROI cropping results.\n\nDifferent CNN models were tested for feature extraction, then connecting the output to a fully connected layer and a Softmax classification layer, as depicted in Fig. 4. In particular, the following well-known pretrained models were selected: DenseNet121, VGG16, MobileNet, Inception, ResNet50 and Xcepcion. During the training stage, a class weighting in the loss function was performed according to the inverse of the class frequency, following the proportionality expression,\n= \u22c5 w N N C ,(2)\nc c\n\nwhere w c represents the weight for c-th class, N is the total number of samples, N c is the number of samples of c-th class and C is the total number of classes.\n\nTraining was performed using a batch size of 16, with the Adam 50 optimizer and a learning rate of 10 \u22124 . The cross entropy was used as cost function. The base CNN was pretrained with the Imagenet 51 dataset. Additionally, to add diversity to the training set and improve the robustness in operation mode, a basic data augmentation was performed over the original training set: rescaling, horizontal flip, horizontal and vertical shift and zoom.  Table 6. Interobserver and intraobserver agreement using the Sorensen-Dice similarity coefficient in expert segmentations of the cup and optic disc in retinal fundus images (second and third columns). Statistical characterization of the interobserver and intraobserver variability using the difference in area-based CDR using the segmentations of the experts (forth to sixth columns).\n\nwww.nature.com/scientificdata www.nature.com/scientificdata/ Each experiment has been evaluated using the Receiver Operating Characteristics (ROC) and the Area Under Curve (AUC) metric, which can be understood like illustrative measures to better observe the limits and possibilities of the dataset.\n\nIn addition, the k-fold cross-validation technique was used for assessing how the trained model generalizes to a separated dataset. A value of k = 5 was considered to be adequate for the size of the PAPILA dataset, and therefore the initial dataset was split into 5 folds, using one of them for testing and the remaining ones for training. Data from both eyes of a particular patient (fundus images or clinical information) were always included in the same fold. The model was then evaluated in these 5 scenarios computing all performance metrics, which are presented in this work in terms of mean value and standard deviation over the 5 folds.\n\nTest #1. Multiclass eye classification. In this first experiment, each fundus image was considered as an independent unit, even when two images comes from the same patient. Note that according to Table 4, in some cases a patient could be diagnosed with early glaucoma in only one eye.\n\nAfter training, every retinal image in the test set was classified into the three classes that are present in the dataset: healthy, glaucoma and suspect. To illustrate this point, both a Principal Component Analysis (PCA) and a t-distributed Stochastic Neighbor Embedding (t-SNE) were performed for dimensionality reduction over the flattened output of a ResNet-50 as head in Fig. 4, when the model was trained using the k-fold cross-validation strategy and evaluated over an arbitrary fold. Figure 5 depicts the results of this projection over a 2D space, which shows (Fig. 5a,c) how the suspect class is not acting as an intermediate class between the healthy and glaucoma classes, hence it is noticeably mixed with both classes.\n\nTest #2. Binary eye classification. According to the previous observation, the suspect class is not behaving as a borderline class between the healthy and the glaucoma classes, but rather as an unresolved class between them which makes it more difficult to find the separation boundary between classes. Then, for comparative purposes in this second experiment, the suspect class was removed from the original dataset and all the process was repeated under the same conditions of the previous case, except that now a Softmax classifier of only 2 units was used, and the vertical flipping was added to the data augmentation procedure to compensate for the lower number of samples in the dataset. The experimentation shows that, when this basic and common data augmentation is used, a remarkable improvement could be obtained for certain pretrained CNN heads (VGG16, MobileNet and Inception), while in others there is no positive improvement (DenseNet121, ResNet50 and Xception). This fact suggests that a specific data augmentation should be designed for each CNN architecture. Figure 6 displays the ROC for both previous tests (Fig. 6a, multiclass classification, and Fig. 6b, binary classification). The AUC metric shows how the classification performance was clearly improved when the suspect class is not present. Furthermore, as shown in Fig. 5b,d, after eliminating the suspect class, we can see how the vast majority of the glaucoma samples of an arbitrary test set are clustered in the same area, showing a remarkable separability from the healthy samples. Both experiments were in any case affected by the problem of class imbalance, which represents a challenge for future research.\n\nBaseline results for clinical data and medical tests. The aim of this section is to illustrate the classification performance that can be achieved from the clinical data and medical tests included in the proposed dataset by means of diverse classical techniques. The results of this metadata classification can serve as a reference baseline for researchers in future investigations.\n\nAs in previous section, two scenarios are considered: multiclass eye classification and binary eye classification. In both cases, the following techniques have been chosen to evaluate the metadata dataset, because they represent methods of a different nature: (1) Logistic Regression, (2) k-Nearest Neighbors algorithm (k-NN), (3) Random Forest, and (4) Support-Vector Machine (SVM). Thus, logistic regression is a parametric model, K-NN is a nonparametric method, Random Forest is a method based on decision trees, and SVM is a semi-parametric method. In this way, the range of variability of these methods allows a more complete analysis, evaluation and discussion of results obtained with them.   www.nature.com/scientificdata www.nature.com/scientificdata/\n\n\nUsage Notes\n\nThe PAPILA dataset contains medical data, retinal fundus images (with their corresponding segmentations of the optic disc and optic cup by two experts) along with their diagnosis. The main objective is to provide a comprehensive dataset to advance in the early diagnosis of glaucoma considering the joint information of both eyes of each patient. These resources are intended not only for healthcare professionals in the field of Ophthalmology, but also for researchers in the scientific community who develop computer tools to assist clinicians in, for example, diagnosing patients from fundus images or clinical data, optic disc and optic cup segmentation or even data augmentation using Generative Adversarial Networks (GAN). In the HelpCode folder, to facilitate future comparisons and ease the use of the dataset in basic machine learning tasks, instructions to assist other researchers with the reuse of the PAPILA dataset are given in a script and are exemplified in a Jupyter Notebook. The dataset splits used with the cross-validation technique are also indicated in that folder.\n\n\nCode availability\n\nThe PAPILA dataset 44 is publicly available at https://doi.org/10.6084/m9.figshare.14798004.v1. As detailed in the composition of the dataset, the clinical data of both eyes of each patient and the corresponding diagnosis are stored in spreadsheet and plain text format. In addition, the folder named HelpCode contains sample code in Python to read, handle and process the dataset. Jupyter Notebooks are also provided to exemplify the use of the PAPILA features. \n\nFig. 3\n3Distribution of the mean defect of the right eye and left eye versus the age of suspicious and glaucoma patients. Based on the mean defect value, three areas have been delimited with horizontal lines, corresponding to mild, moderate and advanced glaucoma. (a) Right eyes, (b) Left eyes.\n\nFig. 2\n2Manual segmentations of the optic disc and optic cup performed by two ophtalmologists. Consent was acquired from the individuals to depict their images. (a) Right eye of Patient #73, (b) Right eye of Patient #20.\n\nFig. 4\n4Basic block diagram of the proposed model to evaluate the PAPILA dataset.\n\nFig. 5\n5PCA and t-SNE projections of the post flatten layer (before entering to softmax) of ResNet-50 output vector for one fold, with the suspect class and without it. (a) PCA projections of three classes, (b) PCA projections of two classes, (c) t-SNE projections of three classes, (d) t-SNE projections of two classes.\n\nFig. 6\n6Classification baseline results of optical fundus images in PAPILA dataset. CNN reference models performance in terms of AUC metric computed from ROCs. (a) Test #1: Multiclass classification, (b) Test #2: Binary classification. (2022) 9:291 | https://doi.org/10.1038/s41597-022-01388-1\n\nFig. 7\n7Classification baseline results of clinical data in PAPILA dataset. Standard models performance in terms of AUC metric computed from ROCs. (a) Test #3: Multiclass classification, (b) Test #4: Binary classification.\n\n\nTable 1. Comparison of the PAPILA dataset with other publicly available datasets. Note that in this summary the suspect class and glaucoma class in PAPILA dataset have been merged, as in the case of RIMONE dataset, for comparative purposes.Dataset \n\nNumber of images \nGround truth labels \n\nDiagnosis from \n\nBoth eyes \nof the same \npatient \nTotal \nHealthy \n\nGlaucoma \n(or suspect) \n\nGlaucoma \nclassification \n\nOptic disc \ncontour \n\nOptic cup \ncountour \n\nRIGA 28,29 \n750 \n-\n-\n\u2717 \n\u2713 \n\u2713 \n-\n\u2717 \n\nORIGA 30 \n650 \n482 \n168 \n\u2713 \n\u2713 \n\u2713 \nNot specified \n\u2717 \n\nRIMONE 31,34 \n485 \n313 \n172 \n\u2713 \n\u2713 \n\u2713 \nClinical \n\u2717 \n\nDrishti-GS 35,36 \n101 \n70 \n31 \n\u2713 \n\u2713 \n\u2713 \nImage \n\u2717 \n\nACRIMA 37,38 \n705 \n309 \n396 \n\u2713 \n\u2717 \n\u2717 \nImage \n\u2717 \n\nG1020 39,40 \n1020 \n724 \n296 \n\u2713 \n\u2713 \n\u2713 \nClinical \n\u2717 \n\nREFUGE 13,41 \n1200 \n1080 \n120 \n\u2713 \n\u2713 \n\u2713 \nClinical \n\u2717 \n\nPAPILA 44 \n488 \n333 \n155 \n\u2713 \n\u2713 \n\u2713 \nClinical \n\u2713 \n\n\n\nTable 2 .\n2Summary of acquisition devices employed in the PAPILA dataset to collect medical data.\n\nTable 3 .\n3Correction factor to add to IOP for a given corneal thickness43 .(2022) 9:291 | https://doi.org/10.1038/s41597-022-01388-1 \n\n\n\nTable 5 .\n5Patients with missing data.\nwww.nature.com/scientificdata www.nature.com/scientificdata/\n\u00a9 The Author(s) 2022\nCompeting interestsThe authors declare no competing interests. Reprints and permissions information is available at www.nature.com/reprints.Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/.\nDefinition of glaucoma: clinical and experimental concepts. R J Casson, G Chidlow, J P Wood, J G Crowston, I Goldberg, 10.1111/j.1442-9071.2012.02773.xClinical & Experimental Ophthalmology. 40Casson, R. J., Chidlow, G., Wood, J. P., Crowston, J. G. & Goldberg, I. Definition of glaucoma: clinical and experimental concepts. Clinical & Experimental Ophthalmology 40, 341-349, https://doi.org/10.1111/j.1442-9071.2012.02773.x (2012).\n\nPrimary open-angle glaucoma. Y H Kwon, J H Fingert, M H Kuehn, W L Alward, 10.1056/NEJMra0804630New England Journal of Medicine. 360Kwon, Y. H., Fingert, J. H., Kuehn, M. H. & Alward, W. L. Primary open-angle glaucoma. New England Journal of Medicine 360, 1113-1124, https://doi.org/10.1056/NEJMra0804630 (2009).\n\nGlobal prevalence of glaucoma and projections of glaucoma burden through 2040: A systematic review and metaanalysis. Y.-C Tham, 10.1016/j.ophtha.2014.05.013Ophthalmology. 121Tham, Y.-C. et al. Global prevalence of glaucoma and projections of glaucoma burden through 2040: A systematic review and meta- analysis. Ophthalmology 121, 2081-2090, https://doi.org/10.1016/j.ophtha.2014.05.013 (2014).\n\nRetinal imaging and image analysis. M Abramoff, M Garvin, M Sonka, 10.1109/RBME.2010.2084567IEEE Reviews in Biomedical Engineering. 3Abramoff, M., Garvin, M. & Sonka, M. Retinal imaging and image analysis. IEEE Reviews in Biomedical Engineering 3, 169-208, https://doi.org/10.1109/RBME.2010.2084567 (2010).\n\nTechniques of glaucoma detection from color fundus images: a review. M K Nath, S Dandapat, 10.5815/ijigsp.2012.09.07International Journal of Image, Graphics & Signal Processing. 4Nath, M. K. & Dandapat, S. Techniques of glaucoma detection from color fundus images: a review. International Journal of Image, Graphics & Signal Processing 4, https://doi.org/10.5815/ijigsp.2012.09.07 (2012).\n\nThe Cup/Disc Ratio: The Findings of Tonometry and Tonography in the Normal Eye. M F Armaly, R E Sayegh, 10.1001/archopht.1969.00990020193008Archives of Ophthalmology. 82Armaly, M. F. & Sayegh, R. E. The Cup/Disc Ratio: The Findings of Tonometry and Tonography in the Normal Eye. Archives of Ophthalmology 82, 191-196, https://doi.org/10.1001/archopht.1969.00990020193008 (1969).\n\nThe disc damage likelihood scale: reproducibility of a new method of estimating the amount of optic nerve damage caused by glaucoma. G L Spaeth, Transactions of the American Ophthalmological Society. 100181Spaeth, G. L. et al. The disc damage likelihood scale: reproducibility of a new method of estimating the amount of optic nerve damage caused by glaucoma. Transactions of the American Ophthalmological Society 100, 181 (2002).\n\nOptic disc, cup and neuroretinal rim size, configuration and correlations in normal eyes. J B Jonas, G C Gusek, G O Naumann, Investigative Ophthalmology & Visual Science. 29Jonas, J. B., Gusek, G. C. & Naumann, G. O. Optic disc, cup and neuroretinal rim size, configuration and correlations in normal eyes. Investigative Ophthalmology & Visual Science 29, 1151-1158 (1988).\n\nThe ISNT rule and differentiation of normal from glaucomatous eyes. N Harizman, 10.1001/archopht.124.11.1579Archives of Ophthalmology. 124Harizman, N. et al. The ISNT rule and differentiation of normal from glaucomatous eyes. Archives of Ophthalmology 124, 1579-1583, https://doi.org/10.1001/archopht.124.11.1579 (2006).\n\nRim-to-disc ratio outperforms cup-to-disc ratio for glaucoma prescreening. J H Kumar, C S Seelamantula, Y S Kamath, R Jampala, Scientific reports. 9Kumar, J. H., Seelamantula, C. S., Kamath, Y. S. & Jampala, R. Rim-to-disc ratio outperforms cup-to-disc ratio for glaucoma prescreening. Scientific reports 9, 1-9 (2019).\n\nAutomatic determination of vertical cup-to-disc ratio in retinal fundus images for glaucoma screening. J Guo, G Azzopardi, C Shi, N M Jansonius, N Petkov, 10.1109/ACCESS.2018.2890544IEEE Access. 7Guo, J., Azzopardi, G., Shi, C., Jansonius, N. M. & Petkov, N. Automatic determination of vertical cup-to-disc ratio in retinal fundus images for glaucoma screening. IEEE Access 7, 8527-8541, https://doi.org/10.1109/ACCESS.2018.2890544 (2019).\n\nComputer-aided diagnosis of glaucoma using fundus images: A review. Y Hagiwara, 10.1016/j.cmpb.2018.07.012Computer Methods and Programs in Biomedicine. 165Hagiwara, Y. et al. Computer-aided diagnosis of glaucoma using fundus images: A review. Computer Methods and Programs in Biomedicine 165, 1-12, https://doi.org/10.1016/j.cmpb.2018.07.012 (2018).\n\nRefuge challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs. J I Orlando, 10.1016/j.media.2019.101570Medical Image Analysis. 59Orlando, J. I. et al. Refuge challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs. Medical Image Analysis 59, 101570, https://doi.org/10.1016/j.media.2019.101570 (2020).\n\nA review of deep learning in medical imaging: Imaging traits, technology trends, case studies with progress highlights, and future promises. S K Zhou, 10.1109/JPROC.2021.3054390Proceedings of the IEEE. 109Zhou, S. K. et al. A review of deep learning in medical imaging: Imaging traits, technology trends, case studies with progress highlights, and future promises. Proceedings of the IEEE 109, 820-838, https://doi.org/10.1109/JPROC.2021.3054390 (2021).\n\nSurvey on segmentation and classification approaches of optic cup and optic disc for diagnosis of glaucoma. N Thakur, M Juneja, 10.1016/j.bspc.2018.01.014Biomedical Signal Processing and Control. 42Thakur, N. & Juneja, M. Survey on segmentation and classification approaches of optic cup and optic disc for diagnosis of glaucoma. Biomedical Signal Processing and Control 42, 162-189, https://doi.org/10.1016/j.bspc.2018.01.014 (2018).\n\nOptic disc and optic cup segmentation methodologies for glaucoma image detection: A survey. A Almazroa, R Burman, K Raahemifar, V Lakshminarayanan, 10.1155/2015/180972Journal of Ophthalmology. 28Almazroa, A., Burman, R., Raahemifar, K. & Lakshminarayanan, V. Optic disc and optic cup segmentation methodologies for glaucoma image detection: A survey. Journal of Ophthalmology 28, https://doi.org/10.1155/2015/180972 (2015).\n\nThe unreasonable effectiveness of data. A Halevy, P Norvig, F Pereira, 10.1109/10.1109/MIS.2009.36IEEE Intelligent Systems. 24Halevy, A., Norvig, P. & Pereira, F. The unreasonable effectiveness of data. IEEE Intelligent Systems 24, 8-12, https://doi.org/ 10.1109/10.1109/MIS.2009.36 (2009).\n\nDRIVE: Digital Retinal Images for Vessel Extraction. DRIVE: Digital Retinal Images for Vessel Extraction. https://drive.grand-challenge.org/.\n\nRidge-based vessel segmentation in color images of the retina. J Staal, M D Abramoff, M Niemeijer, M A Viergever, B Van Ginneken, IEEE Transactions on Medical Imaging. 23Staal, J., Abramoff, M. D., Niemeijer, M., Viergever, M. A. & van Ginneken, B. Ridge-based vessel segmentation in color images of the retina. IEEE Transactions on Medical Imaging 23, 501-509 (2004).\n\nDiaRetDb1: Standard Diabetic Retinopathy Database Calibration level 1. DiaRetDb1: Standard Diabetic Retinopathy Database Calibration level 1. http://www2.it.lut.fi/project/imageret/diaretdb1/.\n\nDiaretdb1 diabetic retinopathy database and evaluation protocol. R K\u00e4lvi\u00e4inen, H Uusitalo, Medical image understanding and analysis. 61K\u00e4lvi\u00e4inen, R. & Uusitalo, H. Diaretdb1 diabetic retinopathy database and evaluation protocol. In Medical image understanding and analysis 2007, 61 (2007).\n\nSTARE: STructured Analysis of the REtina. STARE: STructured Analysis of the REtina. http://cecas.clemson.edu/~ahoover/stare/.\n\nLocating the optic nerve in a retinal image using the fuzzy convergence of the blood vessels. A Hoover, M Goldbaum, IEEE Transactions on Medical Imaging. 22Hoover, A. & Goldbaum, M. Locating the optic nerve in a retinal image using the fuzzy convergence of the blood vessels. IEEE Transactions on Medical Imaging 22, 951-958 (2003).\n\nDrions-Db, Digital Retinal Images for Optic Nerve Segmentation DataBase. DRIONS-DB: Digital Retinal Images for Optic Nerve Segmentation DataBase. http://www.ia.uned.es/~ejcarmona/DRIONS-DB.html.\n\nIdentification of the optic nerve head with genetic algorithms. E J Carmona, M Rinc\u00f3n, J Garc\u00eda-Feijo\u00f3, J M Mart\u00ednez-De-La Casa, Artificial Intelligence in Medicine. 43Carmona, E. J., Rinc\u00f3n, M., Garc\u00eda-Feijo\u00f3, J. & Mart\u00ednez-de-la Casa, J. M. Identification of the optic nerve head with genetic algorithms. Artificial Intelligence in Medicine 43, 243-259 (2008).\n\nMESSIDOR: Methods to Evaluate Segmentation and Indexing Techniques in the field of Retinal Ophthalmology. MESSIDOR: Methods to Evaluate Segmentation and Indexing Techniques in the field of Retinal Ophthalmology. https://www.adcis. net/en/third-party/messidor/.\n\nFeedback on a publicly distributed image database: the Messidor database. E Decenci\u00e8re, Image Analysis and Stereology. 33Decenci\u00e8re, E. et al. Feedback on a publicly distributed image database: the Messidor database. Image Analysis and Stereology 33, 231-234 (2014).\n\nRetinal fundus images for glaucoma analysis: RIGA dataset. Retinal fundus images for glaucoma analysis: RIGA dataset. https://deepblue.lib.umich.edu/data/concern/data_sets/3b591905z.\n\nRetinal fundus images for glaucoma analysis: the RIGA dataset. A Almazroa, 10.1117/12.2293584Medical Imaging 2018: Imaging Informatics for Healthcare, Research, and Applications. Zhang, J. & Chen, P.-H.SPIE10579Almazroa, A. et al. Retinal fundus images for glaucoma analysis: the RIGA dataset. In Zhang, J. & Chen, P.-H. (eds.) Medical Imaging 2018: Imaging Informatics for Healthcare, Research, and Applications, vol. 10579, 55-62, https://doi.org/10.1117/12.2293584. International Society for Optics and Photonics (SPIE, 2018).\n\nORIGA-light: an online retinal fundus image database for glaucoma analysis and research. Z Zhang, 10.1109/iembs.2010.5626137Int Conf of the IEEE Engineering in Medicine and Biology 3065-3068. Zhang, Z. et al. ORIGA-light: an online retinal fundus image database for glaucoma analysis and research. Int Conf of the IEEE Engineering in Medicine and Biology 3065-3068, https://doi.org/10.1109/iembs.2010.5626137 (2010).\n\nRIMONE database. RIMONE database. https://medimrg.webs.ull.es/research/downloads/.\n\nRIM-ONE: an open retinal image database for optic nerve evaluation. F Fumero, S Alay\u00f3n, J L Sanchez, J Sigut, M Gonzalez-Hernandez, 10.1109/CBMS.2011.599914324th Int. Symposium on Computer-based Medical Systems (CBMS). IEEEFumero, F., Alay\u00f3n, S., Sanchez, J. L., Sigut, J. & Gonzalez-Hernandez, M. RIM-ONE: an open retinal image database for optic nerve evaluation. In 2011 24th Int. Symposium on Computer-based Medical Systems (CBMS), 1-6, https://doi.org/10.1109/ CBMS.2011.5999143 (IEEE, 2011).\n\nInteractive tool and database for optic disc and cup segmentation of stereo and monocular retinal fundus images. 23rd Int Conf in Central Europe on Computer Graphics, Visualization and Computer Vision. F Fumero, J Sigut, S Alay\u00f3n, M Gonz\u00e1lez-Hern\u00e1ndez, M Gonz\u00e1lez De La Rosa, Fumero, F., Sigut, J., Alay\u00f3n, S., Gonz\u00e1lez-Hern\u00e1ndez, M. & Gonz\u00e1lez de la Rosa, M. Interactive tool and database for optic disc and cup segmentation of stereo and monocular retinal fundus images. 23rd Int Conf in Central Europe on Computer Graphics, Visualization and Computer Vision (WSCG 2015) (2015).\n\nRim-one dl: A unified retinal image database for assessing glaucoma using deep learning. F J F Batista, 10.5566/ias.2346Image Analysis & Stereology. 39Batista, F. J. F. et al. Rim-one dl: A unified retinal image database for assessing glaucoma using deep learning. Image Analysis & Stereology 39, 161-167, https://doi.org/10.5566/ias.2346 (2020).\n\n. Drishti-Gs Database, Drishti-GS database. http://cvit.iiit.ac.in/projects/mip/drishti-gs/mip-dataset2/Home.php.\n\nDrishti-GS: Retinal image dataset for optic nerve head (ONH) segmentation. J Sivaswamy, S R Krishnadas, G Joshi, M Jain, A U Syed Tabish, 10.1109/ISBI.2014.6867807IEEE 11th International Symposium on Biomedical Imaging (ISBI). Sivaswamy, J., Krishnadas, S. R., Datt Joshi, G., Jain, M. & Syed Tabish, A. U. Drishti-GS: Retinal image dataset for optic nerve head (ONH) segmentation. In 2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI), 53-56, https://doi.org/10.1109/ ISBI.2014.6867807 (2014).\n\nCNNs for Automatic Glaucoma Assessment using Fundus Images: An Extensive Validation. A Diaz-Pinto, 10.6084/m9.figshare.7613135.v1Diaz-Pinto, A., et al. CNNs for Automatic Glaucoma Assessment using Fundus Images: An Extensive Validation. figshare https://doi. org/10.6084/m9.figshare.7613135.v1 (2019).\n\nCNNs for automatic glaucoma assessment using fundus images: an extensive validation. A Diaz-Pinto, 10.1186/s12938-019-0649-yBioMed Eng OnLine. 18Diaz-Pinto, A. et al. CNNs for automatic glaucoma assessment using fundus images: an extensive validation. BioMed Eng OnLine 18, 1-19, https://doi.org/10.1186/s12938-019-0649-y (2019).\n\nG1020 dataset. G1020 dataset. https://www.dfki.uni-kl.de/g1020.\n\nG1020: A benchmark retinal fundus image dataset for computer-aided glaucoma detection. M N Bajwa, 10.1109/IJCNN48605.2020.92076642020 Int Joint Conf on Neural Networks (IJCNN). Bajwa, M. N. et al. G1020: A benchmark retinal fundus image dataset for computer-aided glaucoma detection. In 2020 Int Joint Conf on Neural Networks (IJCNN), 1-7, https://doi.org/10.1109/IJCNN48605.2020.9207664 (2020).\n\nREFUGE: Retinal Fundus Glaucoma Challenge. REFUGE: Retinal Fundus Glaucoma Challenge. https://refuge.grand-challenge.org/.\n\nVisual fields interpretation in glaucoma: a focus on static automated perimetry. M Yaqub, Community eye health. 25Yaqub, M. Visual fields interpretation in glaucoma: a focus on static automated perimetry. Community eye health 25, 1 https://www. ncbi.nlm.nih.gov/pmc/articles/PMC3678209/ (2012).\n\nClinical significance of central corneal thickness in the managementof glaucoma. C Y Shih, J S G Zivin, S L Trokel, J C Tsai, 10.1001/archopht.122.9.1270Archives of Ophthalmology. 122Shih, C. Y., Zivin, J. S. G., Trokel, S. L. & Tsai, J. C. Clinical significance of central corneal thickness in the managementof glaucoma. Archives of Ophthalmology 122, 1270-1275, https://doi.org/10.1001/archopht.122.9.1270 (2004).\n\n. O Kovalyk, 10.6084/m9.figshare.14798004.v1PAPILA datasetKovalyk, O. et al. PAPILA dataset, figshare, https://doi.org/10.6084/m9.figshare.14798004.v1 (2022).\n\nOn classification with incomplete data. D Williams, X Liao, Y Xue, L Carin, B Krishnapuram, 10.1109/TPAMI.2007.52IEEE Transactions on Pattern Analysis and Machine Intelligence. 29Williams, D., Liao, X., Xue, Y., Carin, L. & Krishnapuram, B. On classification with incomplete data. IEEE Transactions on Pattern Analysis and Machine Intelligence 29, 427-436, https://doi.org/10.1109/TPAMI.2007.52 (2007).\n\nPattern classification with missing data: a review. P J Garca-Laencina, J.-L Sancho-G\u00f3mez, A R Figueiras-Vidal, 10.1007/s00521-009-0295-6Neural Computing and Applications. 19Garca-Laencina, P. J., Sancho-G\u00f3mez, J.-L. & Figueiras-Vidal, A. R. Pattern classification with missing data: a review. Neural Computing and Applications 19, 263-282, https://doi.org/10.1007/s00521-009-0295-6 (2010).\n\nAutomatic measurement of isnt and cdr on retinal images by means of a fast and efficient method based on mathematical morphology and active contours. R Verd\u00fa-Monedero, J Morales-S\u00e1nchez, R Berenguer-Vidal, I Sell\u00e9s-Navarro, A Palaz\u00f3n-Cabanes, 10.1007/978-3-030-19651-6_35From Bioinspired Systems and Biomedical Applications to Machine Learning. ChamSpringer International PublishingVerd\u00fa-Monedero, R., Morales-S\u00e1nchez, J., Berenguer-Vidal, R., Sell\u00e9s-Navarro, I. & Palaz\u00f3n-Cabanes, A. Automatic measurement of isnt and cdr on retinal images by means of a fast and efficient method based on mathematical morphology and active contours. In From Bioinspired Systems and Biomedical Applications to Machine Learning, 361-370, https://doi.org/10.1007/978-3-030-19651-6_35 (Springer International Publishing, Cham, 2019).\n\nOptic disc detection using fine tuned convolutional neural networks. F Calimeri, A Marzullo, C Stamile, G Terracina, 10.1109/SITIS.2016.2012th International Conference on Signal-Image Technology Internet-Based Systems (SITIS). Calimeri, F., Marzullo, A., Stamile, C. & Terracina, G. Optic disc detection using fine tuned convolutional neural networks. In 2016 12th International Conference on Signal-Image Technology Internet-Based Systems (SITIS), 69-75, https://doi.org/10.1109/ SITIS.2016.20 (2016).\n\nP Xu, 10.1007/978-3-319-67561-9_15Fetal, Infant and Ophthalmic Medical Image Analysis. ChamSpringer International PublishingXu, P. et al. (eds.) Fetal, Infant and Ophthalmic Medical Image Analysis, 134-141, https://doi.org/10.1007/978-3-319-67561-9_15 (Springer International Publishing, Cham, 2017).\n\nA method for stochastic optimization. D P Kingma, J Ba, Adam, arXiv preprint:1412.6980Kingma, D. P. & Ba, J. Adam: A method for stochastic optimization. arXiv preprint:1412.6980 https://arxiv.org/abs/1412.6980 (2017).\n\nImageNet: A large-scale hierarchical image database. J Deng, 10.1109/CVPR.2009.5206848IEEE Conference on Computer Vision and Pattern Recognition(CVPR) 00. Deng, J. et al. ImageNet: A large-scale hierarchical image database. 2009 IEEE Conference on Computer Vision and Pattern Recognition(CVPR) 00, 248-255, https://doi.org/10.1109/CVPR.2009.5206848 (2009).\n\nThis work has been partially funded by Spanish National projects AES2017-PI17/00771 and. AES2017-PI17/00821Instituto de Salud Carlos III) and regional project 20901/PI/18 (Fundaci\u00f3n S\u00e9necaThis work has been partially funded by Spanish National projects AES2017-PI17/00771 and AES2017-PI17/00821 (Instituto de Salud Carlos III) and regional project 20901/PI/18 (Fundaci\u00f3n S\u00e9neca).\n\ncarried out data analysis, training of networks and method development. I.S.N. and A.P.C. provided all the fundus images, clinical data and annotations for this dataset. O K , J M S , R V M , I S N , O.K. and J.M.S.wrote the manuscript and carried out the main research and analysis tasks of this work. manuscriptO.K., J.M.S., R.V.M. and I.S.N. wrote the manuscript and carried out the main research and analysis tasks of this work. O.K. and J.M.S. carried out data analysis, training of networks and method development. I.S.N. and A.P.C. provided all the fundus images, clinical data and annotations for this dataset. J.L.S.G. provided guidance for method development and reviewed the manuscript.\n", "annotations": {"author": "[{\"end\":131,\"start\":113},{\"end\":134,\"start\":132},{\"end\":156,\"start\":135},{\"end\":159,\"start\":157},{\"end\":182,\"start\":160},{\"end\":185,\"start\":183},{\"end\":212,\"start\":186},{\"end\":229,\"start\":213},{\"end\":253,\"start\":230}]", "publisher": null, "author_last_name": "[{\"end\":130,\"start\":123},{\"end\":155,\"start\":140},{\"end\":181,\"start\":167},{\"end\":211,\"start\":197},{\"end\":252,\"start\":240}]", "author_first_name": "[{\"end\":122,\"start\":113},{\"end\":133,\"start\":132},{\"end\":139,\"start\":135},{\"end\":158,\"start\":157},{\"end\":166,\"start\":160},{\"end\":184,\"start\":183},{\"end\":196,\"start\":186},{\"end\":228,\"start\":213},{\"end\":239,\"start\":230}]", "author_affiliation": null, "title": "[{\"end\":110,\"start\":1},{\"end\":363,\"start\":254}]", "venue": null, "abstract": "[{\"end\":1469,\"start\":434}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b9\"},\"end\":1801,\"start\":1798},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":1803,\"start\":1801},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":1831,\"start\":1828},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":1833,\"start\":1831},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":1941,\"start\":1939},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2096,\"start\":2094},{\"end\":2238,\"start\":2229},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2253,\"start\":2251},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2488,\"start\":2486},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3720,\"start\":3717},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3722,\"start\":3720},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3993,\"start\":3990},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3995,\"start\":3993},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4092,\"start\":4089},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4094,\"start\":4092},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":4285,\"start\":4282},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4287,\"start\":4285},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":5033,\"start\":5031},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":5174,\"start\":5172},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5331,\"start\":5329},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6348,\"start\":6345},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":6350,\"start\":6348},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":7614,\"start\":7612},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":12343,\"start\":12341},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":17042,\"start\":17039},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":17044,\"start\":17042},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":18511,\"start\":18509},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":21699,\"start\":21696},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":21701,\"start\":21699},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":29327,\"start\":29325},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":32238,\"start\":32236}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":30065,\"start\":29770},{\"attributes\":{\"id\":\"fig_1\"},\"end\":30287,\"start\":30066},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30370,\"start\":30288},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30692,\"start\":30371},{\"attributes\":{\"id\":\"fig_4\"},\"end\":30987,\"start\":30693},{\"attributes\":{\"id\":\"fig_5\"},\"end\":31211,\"start\":30988},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":32063,\"start\":31212},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":32162,\"start\":32064},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":32300,\"start\":32163},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":32340,\"start\":32301}]", "paragraph": "[{\"end\":1835,\"start\":1471},{\"end\":2866,\"start\":1837},{\"end\":3341,\"start\":2868},{\"end\":4257,\"start\":3353},{\"end\":5567,\"start\":4259},{\"end\":5931,\"start\":5569},{\"end\":6552,\"start\":5933},{\"end\":7254,\"start\":6654},{\"end\":8059,\"start\":7256},{\"end\":8406,\"start\":8061},{\"end\":8849,\"start\":8408},{\"end\":9123,\"start\":8851},{\"end\":9556,\"start\":9125},{\"end\":9590,\"start\":9558},{\"end\":9974,\"start\":9592},{\"end\":10874,\"start\":9976},{\"end\":10957,\"start\":10916},{\"end\":13923,\"start\":10959},{\"end\":14187,\"start\":13997},{\"end\":15096,\"start\":14189},{\"end\":15883,\"start\":15098},{\"end\":16168,\"start\":15885},{\"end\":16272,\"start\":16170},{\"end\":17046,\"start\":16297},{\"end\":17787,\"start\":17048},{\"end\":18287,\"start\":17821},{\"end\":18913,\"start\":18289},{\"end\":19639,\"start\":18915},{\"end\":20511,\"start\":19641},{\"end\":21877,\"start\":20513},{\"end\":22357,\"start\":21879},{\"end\":22378,\"start\":22375},{\"end\":22542,\"start\":22380},{\"end\":23376,\"start\":22544},{\"end\":23677,\"start\":23378},{\"end\":24323,\"start\":23679},{\"end\":24609,\"start\":24325},{\"end\":25342,\"start\":24611},{\"end\":27034,\"start\":25344},{\"end\":27418,\"start\":27036},{\"end\":28180,\"start\":27420},{\"end\":29284,\"start\":28196},{\"end\":29769,\"start\":29306}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13981,\"start\":13924},{\"attributes\":{\"id\":\"formula_1\"},\"end\":17820,\"start\":17788},{\"attributes\":{\"id\":\"formula_2\"},\"end\":22374,\"start\":22358}]", "table_ref": "[{\"end\":2658,\"start\":2651},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":7982,\"start\":7975},{\"end\":10266,\"start\":10259},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":12289,\"start\":12282},{\"end\":13679,\"start\":13672},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":16474,\"start\":16467},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":16797,\"start\":16788},{\"end\":18950,\"start\":18943},{\"end\":20150,\"start\":20143},{\"end\":20211,\"start\":20204},{\"end\":22999,\"start\":22992},{\"end\":24528,\"start\":24521}]", "section_header": "[{\"end\":3351,\"start\":3344},{\"end\":6652,\"start\":6555},{\"end\":10914,\"start\":10877},{\"end\":13995,\"start\":13983},{\"end\":16295,\"start\":16275},{\"end\":28194,\"start\":28183},{\"end\":29304,\"start\":29287},{\"end\":29777,\"start\":29771},{\"end\":30073,\"start\":30067},{\"end\":30295,\"start\":30289},{\"end\":30378,\"start\":30372},{\"end\":30700,\"start\":30694},{\"end\":30995,\"start\":30989},{\"end\":32074,\"start\":32065},{\"end\":32173,\"start\":32164},{\"end\":32311,\"start\":32302}]", "table": "[{\"end\":32063,\"start\":31454},{\"end\":32300,\"start\":32240}]", "figure_caption": "[{\"end\":30065,\"start\":29779},{\"end\":30287,\"start\":30075},{\"end\":30370,\"start\":30297},{\"end\":30692,\"start\":30380},{\"end\":30987,\"start\":30702},{\"end\":31211,\"start\":30997},{\"end\":31454,\"start\":31214},{\"end\":32162,\"start\":32076},{\"end\":32240,\"start\":32175},{\"end\":32340,\"start\":32313}]", "figure_ref": "[{\"end\":9736,\"start\":9730},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13600,\"start\":13594},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15881,\"start\":15875},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22047,\"start\":22041},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":24993,\"start\":24987},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":25111,\"start\":25103},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":25191,\"start\":25180},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":26428,\"start\":26420},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":26478,\"start\":26470},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":26518,\"start\":26511},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26692,\"start\":26685}]", "bib_author_first_name": "[{\"end\":33610,\"start\":33609},{\"end\":33612,\"start\":33611},{\"end\":33622,\"start\":33621},{\"end\":33633,\"start\":33632},{\"end\":33635,\"start\":33634},{\"end\":33643,\"start\":33642},{\"end\":33645,\"start\":33644},{\"end\":33657,\"start\":33656},{\"end\":34012,\"start\":34011},{\"end\":34014,\"start\":34013},{\"end\":34022,\"start\":34021},{\"end\":34024,\"start\":34023},{\"end\":34035,\"start\":34034},{\"end\":34037,\"start\":34036},{\"end\":34046,\"start\":34045},{\"end\":34048,\"start\":34047},{\"end\":34417,\"start\":34413},{\"end\":34729,\"start\":34728},{\"end\":34741,\"start\":34740},{\"end\":34751,\"start\":34750},{\"end\":35070,\"start\":35069},{\"end\":35072,\"start\":35071},{\"end\":35080,\"start\":35079},{\"end\":35471,\"start\":35470},{\"end\":35473,\"start\":35472},{\"end\":35483,\"start\":35482},{\"end\":35485,\"start\":35484},{\"end\":35904,\"start\":35903},{\"end\":35906,\"start\":35905},{\"end\":36293,\"start\":36292},{\"end\":36295,\"start\":36294},{\"end\":36304,\"start\":36303},{\"end\":36306,\"start\":36305},{\"end\":36315,\"start\":36314},{\"end\":36317,\"start\":36316},{\"end\":36646,\"start\":36645},{\"end\":36975,\"start\":36974},{\"end\":36977,\"start\":36976},{\"end\":36986,\"start\":36985},{\"end\":36988,\"start\":36987},{\"end\":37004,\"start\":37003},{\"end\":37006,\"start\":37005},{\"end\":37016,\"start\":37015},{\"end\":37324,\"start\":37323},{\"end\":37331,\"start\":37330},{\"end\":37344,\"start\":37343},{\"end\":37351,\"start\":37350},{\"end\":37353,\"start\":37352},{\"end\":37366,\"start\":37365},{\"end\":37730,\"start\":37729},{\"end\":38133,\"start\":38132},{\"end\":38135,\"start\":38134},{\"end\":38570,\"start\":38569},{\"end\":38572,\"start\":38571},{\"end\":38992,\"start\":38991},{\"end\":39002,\"start\":39001},{\"end\":39412,\"start\":39411},{\"end\":39424,\"start\":39423},{\"end\":39434,\"start\":39433},{\"end\":39448,\"start\":39447},{\"end\":39785,\"start\":39784},{\"end\":39795,\"start\":39794},{\"end\":39805,\"start\":39804},{\"end\":40243,\"start\":40242},{\"end\":40252,\"start\":40251},{\"end\":40254,\"start\":40253},{\"end\":40266,\"start\":40265},{\"end\":40279,\"start\":40278},{\"end\":40281,\"start\":40280},{\"end\":40294,\"start\":40293},{\"end\":40809,\"start\":40808},{\"end\":40823,\"start\":40822},{\"end\":41257,\"start\":41256},{\"end\":41267,\"start\":41266},{\"end\":41757,\"start\":41756},{\"end\":41759,\"start\":41758},{\"end\":41770,\"start\":41769},{\"end\":41780,\"start\":41779},{\"end\":41797,\"start\":41796},{\"end\":41799,\"start\":41798},{\"end\":42393,\"start\":42392},{\"end\":42834,\"start\":42833},{\"end\":43391,\"start\":43390},{\"end\":43872,\"start\":43871},{\"end\":43882,\"start\":43881},{\"end\":43892,\"start\":43891},{\"end\":43894,\"start\":43893},{\"end\":43905,\"start\":43904},{\"end\":43914,\"start\":43913},{\"end\":44505,\"start\":44504},{\"end\":44515,\"start\":44514},{\"end\":44524,\"start\":44523},{\"end\":44534,\"start\":44533},{\"end\":44556,\"start\":44555},{\"end\":44974,\"start\":44973},{\"end\":44978,\"start\":44975},{\"end\":45244,\"start\":45234},{\"end\":45423,\"start\":45422},{\"end\":45436,\"start\":45435},{\"end\":45438,\"start\":45437},{\"end\":45452,\"start\":45451},{\"end\":45461,\"start\":45460},{\"end\":45469,\"start\":45468},{\"end\":45471,\"start\":45470},{\"end\":45946,\"start\":45945},{\"end\":46249,\"start\":46248},{\"end\":46647,\"start\":46646},{\"end\":46649,\"start\":46648},{\"end\":47162,\"start\":47161},{\"end\":47458,\"start\":47457},{\"end\":47460,\"start\":47459},{\"end\":47468,\"start\":47467},{\"end\":47472,\"start\":47469},{\"end\":47481,\"start\":47480},{\"end\":47483,\"start\":47482},{\"end\":47493,\"start\":47492},{\"end\":47495,\"start\":47494},{\"end\":47796,\"start\":47795},{\"end\":47994,\"start\":47993},{\"end\":48006,\"start\":48005},{\"end\":48014,\"start\":48013},{\"end\":48021,\"start\":48020},{\"end\":48030,\"start\":48029},{\"end\":48410,\"start\":48409},{\"end\":48412,\"start\":48411},{\"end\":48433,\"start\":48429},{\"end\":48449,\"start\":48448},{\"end\":48451,\"start\":48450},{\"end\":48900,\"start\":48899},{\"end\":48918,\"start\":48917},{\"end\":48937,\"start\":48936},{\"end\":48956,\"start\":48955},{\"end\":48974,\"start\":48973},{\"end\":49635,\"start\":49634},{\"end\":49647,\"start\":49646},{\"end\":49659,\"start\":49658},{\"end\":49670,\"start\":49669},{\"end\":50070,\"start\":50069},{\"end\":50410,\"start\":50409},{\"end\":50412,\"start\":50411},{\"end\":50422,\"start\":50421},{\"end\":50644,\"start\":50643},{\"end\":51500,\"start\":51499},{\"end\":51502,\"start\":51501},{\"end\":51506,\"start\":51505},{\"end\":51510,\"start\":51507},{\"end\":51514,\"start\":51513},{\"end\":51518,\"start\":51515},{\"end\":51522,\"start\":51521},{\"end\":51526,\"start\":51523}]", "bib_author_last_name": "[{\"end\":33619,\"start\":33613},{\"end\":33630,\"start\":33623},{\"end\":33640,\"start\":33636},{\"end\":33654,\"start\":33646},{\"end\":33666,\"start\":33658},{\"end\":34019,\"start\":34015},{\"end\":34032,\"start\":34025},{\"end\":34043,\"start\":34038},{\"end\":34055,\"start\":34049},{\"end\":34422,\"start\":34418},{\"end\":34738,\"start\":34730},{\"end\":34748,\"start\":34742},{\"end\":34757,\"start\":34752},{\"end\":35077,\"start\":35073},{\"end\":35089,\"start\":35081},{\"end\":35480,\"start\":35474},{\"end\":35492,\"start\":35486},{\"end\":35913,\"start\":35907},{\"end\":36301,\"start\":36296},{\"end\":36312,\"start\":36307},{\"end\":36325,\"start\":36318},{\"end\":36655,\"start\":36647},{\"end\":36983,\"start\":36978},{\"end\":37001,\"start\":36989},{\"end\":37013,\"start\":37007},{\"end\":37024,\"start\":37017},{\"end\":37328,\"start\":37325},{\"end\":37341,\"start\":37332},{\"end\":37348,\"start\":37345},{\"end\":37363,\"start\":37354},{\"end\":37373,\"start\":37367},{\"end\":37739,\"start\":37731},{\"end\":38143,\"start\":38136},{\"end\":38577,\"start\":38573},{\"end\":38999,\"start\":38993},{\"end\":39009,\"start\":39003},{\"end\":39421,\"start\":39413},{\"end\":39431,\"start\":39425},{\"end\":39445,\"start\":39435},{\"end\":39465,\"start\":39449},{\"end\":39792,\"start\":39786},{\"end\":39802,\"start\":39796},{\"end\":39813,\"start\":39806},{\"end\":40249,\"start\":40244},{\"end\":40263,\"start\":40255},{\"end\":40276,\"start\":40267},{\"end\":40291,\"start\":40282},{\"end\":40307,\"start\":40295},{\"end\":40820,\"start\":40810},{\"end\":40832,\"start\":40824},{\"end\":41264,\"start\":41258},{\"end\":41276,\"start\":41268},{\"end\":41505,\"start\":41496},{\"end\":41767,\"start\":41760},{\"end\":41777,\"start\":41771},{\"end\":41794,\"start\":41781},{\"end\":41819,\"start\":41800},{\"end\":42404,\"start\":42394},{\"end\":42843,\"start\":42835},{\"end\":43397,\"start\":43392},{\"end\":43879,\"start\":43873},{\"end\":43889,\"start\":43883},{\"end\":43902,\"start\":43895},{\"end\":43911,\"start\":43906},{\"end\":43933,\"start\":43915},{\"end\":44512,\"start\":44506},{\"end\":44521,\"start\":44516},{\"end\":44531,\"start\":44525},{\"end\":44553,\"start\":44535},{\"end\":44576,\"start\":44557},{\"end\":44986,\"start\":44979},{\"end\":45253,\"start\":45245},{\"end\":45433,\"start\":45424},{\"end\":45449,\"start\":45439},{\"end\":45458,\"start\":45453},{\"end\":45466,\"start\":45462},{\"end\":45483,\"start\":45472},{\"end\":45957,\"start\":45947},{\"end\":46260,\"start\":46250},{\"end\":46655,\"start\":46650},{\"end\":47168,\"start\":47163},{\"end\":47465,\"start\":47461},{\"end\":47478,\"start\":47473},{\"end\":47490,\"start\":47484},{\"end\":47500,\"start\":47496},{\"end\":47804,\"start\":47797},{\"end\":48003,\"start\":47995},{\"end\":48011,\"start\":48007},{\"end\":48018,\"start\":48015},{\"end\":48027,\"start\":48022},{\"end\":48043,\"start\":48031},{\"end\":48427,\"start\":48413},{\"end\":48446,\"start\":48434},{\"end\":48467,\"start\":48452},{\"end\":48915,\"start\":48901},{\"end\":48934,\"start\":48919},{\"end\":48953,\"start\":48938},{\"end\":48971,\"start\":48957},{\"end\":48990,\"start\":48975},{\"end\":49644,\"start\":49636},{\"end\":49656,\"start\":49648},{\"end\":49667,\"start\":49660},{\"end\":49680,\"start\":49671},{\"end\":50073,\"start\":50071},{\"end\":50419,\"start\":50413},{\"end\":50425,\"start\":50423},{\"end\":50431,\"start\":50427},{\"end\":50649,\"start\":50645}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.1111/j.1442-9071.2012.02773.x\",\"id\":\"b0\",\"matched_paper_id\":46143052},\"end\":33980,\"start\":33549},{\"attributes\":{\"doi\":\"10.1056/NEJMra0804630\",\"id\":\"b1\",\"matched_paper_id\":3028190},\"end\":34294,\"start\":33982},{\"attributes\":{\"doi\":\"10.1016/j.ophtha.2014.05.013\",\"id\":\"b2\",\"matched_paper_id\":8298120},\"end\":34690,\"start\":34296},{\"attributes\":{\"doi\":\"10.1109/RBME.2010.2084567\",\"id\":\"b3\",\"matched_paper_id\":13154386},\"end\":34998,\"start\":34692},{\"attributes\":{\"doi\":\"10.5815/ijigsp.2012.09.07\",\"id\":\"b4\",\"matched_paper_id\":2398335},\"end\":35388,\"start\":35000},{\"attributes\":{\"doi\":\"10.1001/archopht.1969.00990020193008\",\"id\":\"b5\",\"matched_paper_id\":30398950},\"end\":35768,\"start\":35390},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":19404519},\"end\":36200,\"start\":35770},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":23124353},\"end\":36575,\"start\":36202},{\"attributes\":{\"doi\":\"10.1001/archopht.124.11.1579\",\"id\":\"b8\",\"matched_paper_id\":23776084},\"end\":36897,\"start\":36577},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":148568485},\"end\":37218,\"start\":36899},{\"attributes\":{\"doi\":\"10.1109/ACCESS.2018.2890544\",\"id\":\"b10\",\"matched_paper_id\":59233043},\"end\":37659,\"start\":37220},{\"attributes\":{\"doi\":\"10.1016/j.cmpb.2018.07.012\",\"id\":\"b11\",\"matched_paper_id\":53013843},\"end\":38010,\"start\":37661},{\"attributes\":{\"doi\":\"10.1016/j.media.2019.101570\",\"id\":\"b12\",\"matched_paper_id\":203952960},\"end\":38426,\"start\":38012},{\"attributes\":{\"doi\":\"10.1109/JPROC.2021.3054390\",\"id\":\"b13\",\"matched_paper_id\":221187065},\"end\":38881,\"start\":38428},{\"attributes\":{\"doi\":\"10.1016/j.bspc.2018.01.014\",\"id\":\"b14\",\"matched_paper_id\":4771853},\"end\":39317,\"start\":38883},{\"attributes\":{\"doi\":\"10.1155/2015/180972\",\"id\":\"b15\",\"matched_paper_id\":15617439},\"end\":39742,\"start\":39319},{\"attributes\":{\"doi\":\"10.1109/10.1109/MIS.2009.36\",\"id\":\"b16\",\"matched_paper_id\":14300215},\"end\":40034,\"start\":39744},{\"attributes\":{\"id\":\"b17\"},\"end\":40177,\"start\":40036},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":2607360},\"end\":40547,\"start\":40179},{\"attributes\":{\"id\":\"b19\"},\"end\":40741,\"start\":40549},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":15483141},\"end\":41033,\"start\":40743},{\"attributes\":{\"id\":\"b21\"},\"end\":41160,\"start\":41035},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":14424948},\"end\":41494,\"start\":41162},{\"attributes\":{\"id\":\"b23\"},\"end\":41690,\"start\":41496},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":205693942},\"end\":42054,\"start\":41692},{\"attributes\":{\"id\":\"b25\"},\"end\":42316,\"start\":42056},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":21755399},\"end\":42584,\"start\":42318},{\"attributes\":{\"id\":\"b27\"},\"end\":42768,\"start\":42586},{\"attributes\":{\"doi\":\"10.1117/12.2293584\",\"id\":\"b28\",\"matched_paper_id\":80088512},\"end\":43299,\"start\":42770},{\"attributes\":{\"doi\":\"10.1109/iembs.2010.5626137\",\"id\":\"b29\",\"matched_paper_id\":23780456},\"end\":43717,\"start\":43301},{\"attributes\":{\"id\":\"b30\"},\"end\":43801,\"start\":43719},{\"attributes\":{\"doi\":\"10.1109/CBMS.2011.5999143\",\"id\":\"b31\",\"matched_paper_id\":14779650},\"end\":44300,\"start\":43803},{\"attributes\":{\"id\":\"b32\"},\"end\":44882,\"start\":44302},{\"attributes\":{\"doi\":\"10.5566/ias.2346\",\"id\":\"b33\",\"matched_paper_id\":229451012},\"end\":45230,\"start\":44884},{\"attributes\":{\"id\":\"b34\"},\"end\":45345,\"start\":45232},{\"attributes\":{\"doi\":\"10.1109/ISBI.2014.6867807\",\"id\":\"b35\",\"matched_paper_id\":18432155},\"end\":45858,\"start\":45347},{\"attributes\":{\"doi\":\"10.6084/m9.figshare.7613135.v1\",\"id\":\"b36\"},\"end\":46161,\"start\":45860},{\"attributes\":{\"doi\":\"10.1186/s12938-019-0649-y\",\"id\":\"b37\",\"matched_paper_id\":84841586},\"end\":46492,\"start\":46163},{\"attributes\":{\"id\":\"b38\"},\"end\":46557,\"start\":46494},{\"attributes\":{\"doi\":\"10.1109/IJCNN48605.2020.9207664\",\"id\":\"b39\",\"matched_paper_id\":215778022},\"end\":46954,\"start\":46559},{\"attributes\":{\"id\":\"b40\"},\"end\":47078,\"start\":46956},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":7677717},\"end\":47374,\"start\":47080},{\"attributes\":{\"doi\":\"10.1001/archopht.122.9.1270\",\"id\":\"b42\",\"matched_paper_id\":3314404},\"end\":47791,\"start\":47376},{\"attributes\":{\"doi\":\"10.6084/m9.figshare.14798004.v1\",\"id\":\"b43\"},\"end\":47951,\"start\":47793},{\"attributes\":{\"doi\":\"10.1109/TPAMI.2007.52\",\"id\":\"b44\",\"matched_paper_id\":15400937},\"end\":48355,\"start\":47953},{\"attributes\":{\"doi\":\"10.1007/s00521-009-0295-6\",\"id\":\"b45\",\"matched_paper_id\":3351246},\"end\":48747,\"start\":48357},{\"attributes\":{\"doi\":\"10.1007/978-3-030-19651-6_35\",\"id\":\"b46\",\"matched_paper_id\":152283822},\"end\":49563,\"start\":48749},{\"attributes\":{\"doi\":\"10.1109/SITIS.2016.20\",\"id\":\"b47\",\"matched_paper_id\":2175787},\"end\":50067,\"start\":49565},{\"attributes\":{\"doi\":\"10.1007/978-3-319-67561-9_15\",\"id\":\"b48\"},\"end\":50369,\"start\":50069},{\"attributes\":{\"doi\":\"arXiv preprint:1412.6980\",\"id\":\"b49\"},\"end\":50588,\"start\":50371},{\"attributes\":{\"doi\":\"10.1109/CVPR.2009.5206848\",\"id\":\"b50\",\"matched_paper_id\":57246310},\"end\":50946,\"start\":50590},{\"attributes\":{\"doi\":\"AES2017-PI17/00821\",\"id\":\"b51\"},\"end\":51327,\"start\":50948},{\"attributes\":{\"id\":\"b52\"},\"end\":52026,\"start\":51329}]", "bib_title": "[{\"end\":33607,\"start\":33549},{\"end\":34009,\"start\":33982},{\"end\":34411,\"start\":34296},{\"end\":34726,\"start\":34692},{\"end\":35067,\"start\":35000},{\"end\":35468,\"start\":35390},{\"end\":35901,\"start\":35770},{\"end\":36290,\"start\":36202},{\"end\":36643,\"start\":36577},{\"end\":36972,\"start\":36899},{\"end\":37321,\"start\":37220},{\"end\":37727,\"start\":37661},{\"end\":38130,\"start\":38012},{\"end\":38567,\"start\":38428},{\"end\":38989,\"start\":38883},{\"end\":39409,\"start\":39319},{\"end\":39782,\"start\":39744},{\"end\":40240,\"start\":40179},{\"end\":40806,\"start\":40743},{\"end\":41254,\"start\":41162},{\"end\":41754,\"start\":41692},{\"end\":42390,\"start\":42318},{\"end\":42831,\"start\":42770},{\"end\":43388,\"start\":43301},{\"end\":43869,\"start\":43803},{\"end\":44971,\"start\":44884},{\"end\":45420,\"start\":45347},{\"end\":46246,\"start\":46163},{\"end\":46644,\"start\":46559},{\"end\":47159,\"start\":47080},{\"end\":47455,\"start\":47376},{\"end\":47991,\"start\":47953},{\"end\":48407,\"start\":48357},{\"end\":48897,\"start\":48749},{\"end\":49632,\"start\":49565},{\"end\":50641,\"start\":50590}]", "bib_author": "[{\"end\":33621,\"start\":33609},{\"end\":33632,\"start\":33621},{\"end\":33642,\"start\":33632},{\"end\":33656,\"start\":33642},{\"end\":33668,\"start\":33656},{\"end\":34021,\"start\":34011},{\"end\":34034,\"start\":34021},{\"end\":34045,\"start\":34034},{\"end\":34057,\"start\":34045},{\"end\":34424,\"start\":34413},{\"end\":34740,\"start\":34728},{\"end\":34750,\"start\":34740},{\"end\":34759,\"start\":34750},{\"end\":35079,\"start\":35069},{\"end\":35091,\"start\":35079},{\"end\":35482,\"start\":35470},{\"end\":35494,\"start\":35482},{\"end\":35915,\"start\":35903},{\"end\":36303,\"start\":36292},{\"end\":36314,\"start\":36303},{\"end\":36327,\"start\":36314},{\"end\":36657,\"start\":36645},{\"end\":36985,\"start\":36974},{\"end\":37003,\"start\":36985},{\"end\":37015,\"start\":37003},{\"end\":37026,\"start\":37015},{\"end\":37330,\"start\":37323},{\"end\":37343,\"start\":37330},{\"end\":37350,\"start\":37343},{\"end\":37365,\"start\":37350},{\"end\":37375,\"start\":37365},{\"end\":37741,\"start\":37729},{\"end\":38145,\"start\":38132},{\"end\":38579,\"start\":38569},{\"end\":39001,\"start\":38991},{\"end\":39011,\"start\":39001},{\"end\":39423,\"start\":39411},{\"end\":39433,\"start\":39423},{\"end\":39447,\"start\":39433},{\"end\":39467,\"start\":39447},{\"end\":39794,\"start\":39784},{\"end\":39804,\"start\":39794},{\"end\":39815,\"start\":39804},{\"end\":40251,\"start\":40242},{\"end\":40265,\"start\":40251},{\"end\":40278,\"start\":40265},{\"end\":40293,\"start\":40278},{\"end\":40309,\"start\":40293},{\"end\":40822,\"start\":40808},{\"end\":40834,\"start\":40822},{\"end\":41266,\"start\":41256},{\"end\":41278,\"start\":41266},{\"end\":41507,\"start\":41496},{\"end\":41769,\"start\":41756},{\"end\":41779,\"start\":41769},{\"end\":41796,\"start\":41779},{\"end\":41821,\"start\":41796},{\"end\":42406,\"start\":42392},{\"end\":42845,\"start\":42833},{\"end\":43399,\"start\":43390},{\"end\":43881,\"start\":43871},{\"end\":43891,\"start\":43881},{\"end\":43904,\"start\":43891},{\"end\":43913,\"start\":43904},{\"end\":43935,\"start\":43913},{\"end\":44514,\"start\":44504},{\"end\":44523,\"start\":44514},{\"end\":44533,\"start\":44523},{\"end\":44555,\"start\":44533},{\"end\":44578,\"start\":44555},{\"end\":44988,\"start\":44973},{\"end\":45255,\"start\":45234},{\"end\":45435,\"start\":45422},{\"end\":45451,\"start\":45435},{\"end\":45460,\"start\":45451},{\"end\":45468,\"start\":45460},{\"end\":45485,\"start\":45468},{\"end\":45959,\"start\":45945},{\"end\":46262,\"start\":46248},{\"end\":46657,\"start\":46646},{\"end\":47170,\"start\":47161},{\"end\":47467,\"start\":47457},{\"end\":47480,\"start\":47467},{\"end\":47492,\"start\":47480},{\"end\":47502,\"start\":47492},{\"end\":47806,\"start\":47795},{\"end\":48005,\"start\":47993},{\"end\":48013,\"start\":48005},{\"end\":48020,\"start\":48013},{\"end\":48029,\"start\":48020},{\"end\":48045,\"start\":48029},{\"end\":48429,\"start\":48409},{\"end\":48448,\"start\":48429},{\"end\":48469,\"start\":48448},{\"end\":48917,\"start\":48899},{\"end\":48936,\"start\":48917},{\"end\":48955,\"start\":48936},{\"end\":48973,\"start\":48955},{\"end\":48992,\"start\":48973},{\"end\":49646,\"start\":49634},{\"end\":49658,\"start\":49646},{\"end\":49669,\"start\":49658},{\"end\":49682,\"start\":49669},{\"end\":50075,\"start\":50069},{\"end\":50421,\"start\":50409},{\"end\":50427,\"start\":50421},{\"end\":50433,\"start\":50427},{\"end\":50651,\"start\":50643},{\"end\":51505,\"start\":51499},{\"end\":51513,\"start\":51505},{\"end\":51521,\"start\":51513},{\"end\":51529,\"start\":51521}]", "bib_venue": "[{\"end\":33737,\"start\":33700},{\"end\":34109,\"start\":34078},{\"end\":34465,\"start\":34452},{\"end\":34822,\"start\":34784},{\"end\":35176,\"start\":35116},{\"end\":35555,\"start\":35530},{\"end\":35968,\"start\":35915},{\"end\":36371,\"start\":36327},{\"end\":36710,\"start\":36685},{\"end\":37044,\"start\":37026},{\"end\":37413,\"start\":37402},{\"end\":37811,\"start\":37767},{\"end\":38194,\"start\":38172},{\"end\":38628,\"start\":38605},{\"end\":39077,\"start\":39037},{\"end\":39510,\"start\":39486},{\"end\":39866,\"start\":39842},{\"end\":40087,\"start\":40036},{\"end\":40345,\"start\":40309},{\"end\":40618,\"start\":40549},{\"end\":40874,\"start\":40834},{\"end\":41075,\"start\":41035},{\"end\":41314,\"start\":41278},{\"end\":41567,\"start\":41507},{\"end\":41856,\"start\":41821},{\"end\":42160,\"start\":42056},{\"end\":42435,\"start\":42406},{\"end\":42643,\"start\":42586},{\"end\":42947,\"start\":42863},{\"end\":43491,\"start\":43425},{\"end\":43734,\"start\":43719},{\"end\":44020,\"start\":43960},{\"end\":44502,\"start\":44302},{\"end\":45031,\"start\":45004},{\"end\":45572,\"start\":45510},{\"end\":45943,\"start\":45860},{\"end\":46304,\"start\":46287},{\"end\":46507,\"start\":46494},{\"end\":46734,\"start\":46688},{\"end\":46997,\"start\":46956},{\"end\":47190,\"start\":47170},{\"end\":47554,\"start\":47529},{\"end\":48128,\"start\":48066},{\"end\":48527,\"start\":48494},{\"end\":49092,\"start\":49020},{\"end\":49790,\"start\":49703},{\"end\":50154,\"start\":50103},{\"end\":50407,\"start\":50371},{\"end\":50743,\"start\":50676},{\"end\":51035,\"start\":50948},{\"end\":51497,\"start\":51329},{\"end\":49098,\"start\":49094},{\"end\":50160,\"start\":50156}]"}}}, "year": 2023, "month": 12, "day": 17}