{"id": 257912848, "updated": "2023-12-14 03:43:52.311", "metadata": {"title": "Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data", "authors": "[{\"first\":\"Canwen\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Daya\",\"last\":\"Guo\",\"middle\":[]},{\"first\":\"Nan\",\"last\":\"Duan\",\"middle\":[]},{\"first\":\"Julian\",\"last\":\"McAuley\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Chat models, such as ChatGPT, have shown impressive capabilities and have been rapidly adopted across numerous domains. However, these models are only accessible through a restricted API, creating barriers for new research and progress in the field. We propose a pipeline that can automatically generate a high-quality multi-turn chat corpus by leveraging ChatGPT to engage in a conversation with itself. Subsequently, we employ parameter-efficient tuning to enhance LLaMA, an open-source large language model. The resulting model, named Baize, demonstrates good performance in multi-turn dialogues with guardrails that minimize potential risks. Furthermore, we propose a new technique called Self-Distill with Feedback, to further improve the performance of the Baize models with feedback from ChatGPT. The Baize models and data are released for research purposes only at https://github.com/project-baize/baize-chatbot. An online demo is also available at https://huggingface.co/spaces/project-baize/chat-with-baize.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/XuGDM23", "doi": "10.18653/v1/2023.emnlp-main.385"}}, "content": {"source": {"pdf_hash": "fb8e92090f5fb02776ab0b798f49c01f3d4c068f", "pdf_src": "ArXiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2304.01196v4.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2304.01196", "status": "GREEN"}}, "grobid": {"id": "7c012e9e527091ecc7c058ca677d3adee3f62a50", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/fb8e92090f5fb02776ab0b798f49c01f3d4c068f.txt", "contents": "\nBaize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data\n2 Dec 2023\n\nCanwen Xu \nUniversity of California\nSan Diego\n\nDaya Guo \nSun Yat-sen University\n\n\nNan Duan nanduan@microsoft.com \nMicrosoft Research Asia\n\n\nJulian Mcauley jmcauley@ucsd.edu \nUniversity of California\nSan Diego\n\nBaize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data\n2 Dec 20237C0CD1A956E253F2084F25BE4AAA1D3EarXiv:2304.01196v4[cs.CL]\nChat models, such as ChatGPT, have shown impressive capabilities and have been rapidly adopted across numerous domains.However, these models are only accessible through a restricted API, creating barriers for new research and progress in the field.We propose a pipeline that can automatically generate a highquality multi-turn chat corpus by leveraging ChatGPT to engage in a conversation with itself.Subsequently, we employ parameter-efficient tuning to enhance LLaMA, an open-source large language model.The resulting model, named Baize, demonstrates good performance in multi-turn dialogues with guardrails that minimize potential risks.Additionally, we propose a new technique called Self-Distill with Feedback, to further improve the performance of the Baize models with feedback from ChatGPT.The Baize models and data are released for research purposes only. 1\n\nIntroduction\n\nThe rapid advancement of natural language processing (NLP) techniques in recent years has led to the emergence of highly capable chat models, such as LaMDA (Thoppilan et al., 2022), ChatGPT (Ope-nAI, 2023a) and GPT-4 (OpenAI, 2023b).These models demonstrate a remarkable ability to understand and generate human-like responses in a wide range of domains.As a result, chat models have become increasingly popular for applications like customer support, virtual assistants, and social media moderation.Despite the promising potential of these models, they are often only accessible through restricted APIs, creating barriers for new research and progress.Furthermore, the limited availability of chat models poses obstacles for researchers and practitioners, hindering the growth of the NLP community.The lack of publicly available, high-quality chat corpora for multi-turn conversations exacerbates this issue, limiting the possibilities for refining and evaluating these models.\n\nIn this paper, we propose a novel pipeline (shown in Figure 1) to address these challenges by leveraging the capabilities of ChatGPT to automatically generate a high-quality multi-turn chat corpus.Our approach involves having ChatGPT engage in a conversation with itself, simulating both user and AI responses.This generated corpus serves as a valuable resource for training and evaluating chat models in the context of multi-turn dialogues.Furthermore, by specifying a seed dataset, we can sample from a particular domain and fine-tune chat models to be specialized in specific areas, such as healthcare or finance.\n\nTo fine-tune large language models in a lowresource setting, we utilize a parameter-efficient tuning approach that effectively leverages the limited computational resources available.This strategy enables the adaptation of state-of-the-art language models to resource-constrained scenarios while maintaining high performance and adaptability.Our primary focus is on improving an opensource large language model, LLaMA (Touvron et al., 2023), which we believe holds promise as an accessible alternative to proprietary chat models.By fine-tuning LLaMA with our generated chat corpus, we create a new model, named Baize (B\u00e1i z\u00e9, a mythical creature in Chinese folklore, who speaks human languages and knows everything).Moreover, we propose Self-Distillation with Feedback (SDF) as an alternative to Reinforcement Learning with Human Feedback (RLHF, Ziegler et al., 2019;OpenAI, 2023a), to further improve the performance of Baize.Baize is a chat model that can run on a single GPU, making it accessible for a broader range of researchers.\n\nTo summarize, our main contributions in this paper are as follows:\n\n\u2022 We propose a novel and reproducible pipeline Seed Dataset\n\n\nSelf-chat\n\n\nBaize\n\n\nSeeds Corpus\n\n\nLoRA Tuning\n\nTemplate LLaMA for automatically generating a high-quality multi-turn chat corpus by having ChatGPT engage in a conversation with itself.Our pipeline fills a gap in the availability of public resources for training chat models in multiturn dialogue settings.\n\n\nSeed Sampling\n\n\nBaize v2\n\n\nSelf-Distill\nChatGPT\n\nRelated Work\n\nLanguage Models for Chat Since the success of GPT-2 (Radford et al., 2019), there have been many language models for chatting with humans.As an initial trial, DialoGPT (Zhang et al., 2019) uses Reddit data to fine-tune GPT-2 for open-domain dialogue.Meena (Adiwardana et al., 2020) (Taori et al., 2023) uses Self-Instruct (Wang et al., 2022) to collect data from GPT-3.5 in instruction learning format.Then, the collected dataset is used to finetune LLaMA (Touvron et al., 2023).Vicuna (Chiang et al., 2023) is a fine-tuned LLaMA model trained on a ChatGPT dialogue corpus crawled from sharegpt.com,a website for sharing Chat-GPT dialogues.We will discuss the pros and cons of the data source of each model in Section 3.\n\nParameter-Efficient Tuning Conventional finetuning requires training all parameters in a large model, which can be inefficient as the numbers of parameters grows.Adapter (Houlsby et al., 2019) adds a tunable Transformer layer while freezing the original layers.BitFit (Zaken et al., 2022) only tunes bias terms in the linear layers.Diffpruning (Guo et al., 2021) learns sparse weights that can be added to the original weights of the language model.Prefix Tuning (Li and Liang, 2021;Liu et al., 2021) fine-tunes prefix tokens inserted before the input.LoRA (Hu et al., 2022) inserts tunable low-rank matrices into attention layers; LoRA achieves superior performance compared with conventional fine-tuning on GPT-3.Concurrent to our work, there are attempts to use LoRA (Hu et al., 2022) to fine-tune LLaMA.Alpaca-LoRA2 follows the same recipe as Alpaca while using LoRA for higher efficiency.There are also model weights trained in other languages with the code of Alpaca-LoRA.Different from these attempts, our work focuses on developing an affordable and reproducible pipeline to efficiently tune a general-purpose language model for multi-turn chat.\n\n\nData Collection via Self-Chat\n\nIn this section, we detail the methodology employed for generating a high-quality multi-turn chat corpus by leveraging  to engage in a conversation with itself.This process, named self-chat, serves as the foundation of our data collection pipeline and plays a critical role in enhancing the open-source large language model, LLaMA, to achieve better performance in multi-turn dialogues.\n\nThe self-chat process involves utilizing Chat-GPT to generate messages for both the user and AI assistant in a conversational format.We apply a template (shown in Appendix A) to define the format and requirements, allowing the ChatGPT API to continuously generate transcripts for both sides of the dialogue until a natural stopping point is reached.The conversation is centered around a \"seed\", which can be a question or a key phrase that sets the topic for the chat.\n\nIn our own training of Baize, we use questions from Quora3 and Stack Overflow4 as seeds.A dialogue example generated with self-chat is shown in Table 1.For training the first version of Baize family (Baize v1), we collect a total of 111.5k dialogues through self-chat, using \u223c55k questions from each source.This process cost us approximately $100 for calling OpenAI's API.Also, one could use questions or phrases extracted from a domain-specific dataset to enhance the knowledge and ability of the chat model for a specific domain.Motivated by a recent report (Johnson et al., 2023) that ChatGPT can answer cancer-related questions as well as The National Cancer Institute, we use the MedQuAD (Ben  2019) dataset as seeds and obtain an additional 47k dialogues in the medical domain to train a Baize model specialized for healthcare.Note by directly generating the dialogue with the template shown in Appendix A, ChatGPT's output of each turn seems to be shorter than asking Chat-GPT one turn at a time.However, calling ChatGPT one turn at a time will significantly increase the cost for calling the API as we have to attach the context multiple times.To collect data with better quality for training Baize v1.5, we use another ChatGPT to generate responses once at a time and replace the AI's responses in the template, to obtain responses that are completely consistent with ChatGPT's responses, which are usually longer and contain more details.The statistics of the resulting corpora are shown in Table 2.\n\nComparison with Other Data Sources Stanford Alpaca (Taori et al., 2023) uses Self-Instruct (Wang et al., 2022) to collect data in instruction learning format.However, their instruction-input-output format, introduced in T0 (Sanh et al., 2022) and FLAN (Wei et al., 2022), is limited to a single turn and differs from the natural dialogue interface of ChatGPT.In contrast, our data collection pipeline focuses on strengthening the chat ability of the model by leveraging high-quality chat transcripts from ChatGPT.Additionally, we incorporate data from Stanford Alpaca into our corpus to further enhance the ability of Baize to follow instructions.\n\nVicuna (Chiang et al., 2023) uses dialogues crawled from sharegpt.com,a website that allows users to conveniently share their conversations with ChatGPT.An advantage of doing so is the high quality of collected data.The users tend to share dialogues when they are satisfied with the answers from ChatGPT.However, this source may have serious privacy and legal problems.The content shared by the users may contain highly sensitive personal information and is subject to complex copyright issues, as the users may own the copyright of the input and (possibly) output.Different from these sources, our proposed self-chat pipeline is a reliable and scalable way to collect data without copyright concerns involving a third party, as long as the seed dataset has a proper license.\n\n\nModel Training\n\nParameter-Efficient Supervised Fine-Tuning Standard fine-tuning often requires vast amounts of computational resources, as well as high-quality and extensive datasets.However, given the limited availability of high-quality multi-turn chat corpora, it is crucial to adopt methods that are more efficient in terms of computational cost and data requirements.Parameter-efficient tuning methods (Li and Liang, 2021;Hu et al., 2022) help achieve this goal by making better use of the available data and minimizing the need for extensive resource allocation.\n\nSpecifically, we use Low-Rank Adaption method (LoRA, Hu et al., 2022) to fine-tune the LLaMA model.For a linear layer h = W 0 x, the forward pass is modified to be:\nh = W 0 x + B sft A sft x (1)\nwhere -Lack of Regulatory Oversight: . . .Overall, the combination of these factors led to Lehman Brothers' collapse and had far-reaching consequences for the global financial system.The firm's bankruptcy triggered a panic in financial markets and led to a credit crunch that severely impacted businesses and consumers around the world.\nW 0 \u2208 R d\u00d7k , B sft \u2208\nBaize-v1-7B: Lehman Brothers went bankrupt due to a combination of factors, including poor management decisions, an excessive reliance on short-term financing, and an unsustainable business model.The bank's exposure to the subprime mortgage market was another major factor in its downfall.Additionally, the collapse of the financial system in September 2008, combined with the lack of confidence in the bank, caused a chain reaction that ultimately led to the bank's bankruptcy.\n\nBaize-v2-7B: The collapse of Lehman Brothers was one of the largest and most high-profile bankruptcies in history.Here are some of the key factors that contributed to its downfall:\n\n-Over-leveraged balance sheet: . . .-Subprime mortgage crisis: . . .-Lack of liquidity: . . .-Poor risk management: . . .-Regulatory failures: . . .-External factors: . . .Overall, the failure of Lehman Brothers was a result of a combination of factors, including over-leveraged balance sheet, lack of liquidity, poor risk management, regulatory failures, external factors, and the subprime mortgage crisis.\n\nTable 4: (Not cherry-picked) An example of asking chat models to analyze the Lehman Brothers' bankruptcy.Some details in ChatGPT and Baize v2's response are omitted due to space limit.Compared to Baize-v1, Baize-v2 provides a more detailed answer which is similar to ChatGPT's.\n\nDistillation with feedback (SDF) to self-improve the model's performance and results in Baize v2. Figure 2 gives an overview of SDF.First, we use the resulted Baize v1.5 models to generate four responses for each instruction from the Quora dataset mentioned in Table 2.We then engage ChatGPT using the prompt provided in Appendix C to rank generate responses for self-distillation.Finally, we select the best response ranked by ChatGPT to finetune the model.During SDF, we apply new LoRA modules to all linear layers in Baize v1.5.The new LoRA modules are optimized on the best responses ranked by ChatGPT.For each linear layer h = W 0 x + B sft A sft x in Equation 1, the forward pass is modified to be:\nh = W 0 x + B sft A sft x + B sdf A sdf x (2)\nwhere B sdf \u2208 R d\u00d7r and A sdf \u2208 R r\u00d7k are model parameters with the low rank r \u226a min(d, k).Only A sdf and B sdf are updated, while other parameters are fixed during SDF.\n\nSDF is an alternative to Reinforcement Learning with Human Feedback (RLHF, Ziegler et al., 2019;OpenAI, 2023a).SDF does not require training of reward models and is 3\u00d7 faster than RLHF, which uses PPO (Schulman et al., 2017) to optimize the model.Besides, SDF involves distillation on Baize's own generation, thus has an overall lower loss, allowing the model to capture the nuance in the feedback and perform fine-grained optimization without causing possible catastrophic forgetting.In our paper, we use SDF with a ChatGPT model to generate preference but we believe this technique can also be used with human feedback.\n\n\nModel Settings\n\nDuring the training phase, we set the maximum length of the input sequence to 512/1024 for Baize v1/v2 and the rank k in LoRA to 8. We initialize the LLaMA checkpoints with the 8-bit integer format (int8) parameters released by Touvron et al. ( 2023), which remain fixed during training, thus reducing\n\n\nHuman:\n\nExplain why this joke is funny: I'm a big fan of whiteboards.I find them quite re-markable.\n\n\nAlpaca-13B:\n\nI'm glad you appreciate the joke.Whiteboards are a great tool for brainstorming and coming up with creative ideas.They are also versatile and can be used for a variety of tasks.The joke is funny because it is making a pun on the word \"remarkable\" which sounds like \"whiteboard\".\n\n\nChatGPT:\n\nThis joke is a play on words, specifically a pun.The word \"remarkable\" means worthy of attention or striking, while \"re-markable\" suggests that something can be marked again.The humor comes from the double meaning of \"re-markable.\"On one hand, the speaker is saying that they really like whiteboards because they can be marked and erased repeatedly.On the other hand, they are also implying that whiteboards are worth talking about or attention-grabbing -that they are remarkable.\n\n\nBaize-v2-7B:\n\nThis joke is funny because it plays on the double meaning of the word \"remarkable.\"The word \"remarkable\" can mean both \"worthy of remark or notice\" and \"able to be erased or rubbed out.\"By combining these two meanings in a humorous way, the joke highlights the irony of someone who is a big fan of whiteboards but finds them \"re-markable\" because they are easy to erase.\n\n\nBaize-v2-13B:\n\nThe joke is funny because it plays on the word \"remarkable\" which has a double meaning.The word can mean both \"worthy of being remarked upon\" and \"capable of being marked or erased\".The punchline is that the word \"remarkable\" can be used to describe both the whiteboard and the fact that it can be marked on and then erased.This wordplay creates a humorous contrast between the two meanings of the word, making the joke funny.\n\nTable 5: (Not cherry-picked) An example of asking chat models to explain a joke.Baize and ChatGPT can successfully explain the joke.Alpaca fails to do so.\n\nGPU memory consumption and improving training speed.Following Hu et al. (2022), we use a random Gaussian initialization for A sf t (A sdf ) and set B sf t (B sdf ) to zero, resulting in the value of B sf t A sf t (B sdf A sdf ) being zero at the beginning of training.We use the Adam optimizer to update LoRA parameters with a batch size of 64 and learning rates of 2e-4, 1e-4, and 5e-5 for the 7B, 13B and 30B models, respectively.The trainable LoRA parameters are fine-tuned on NVIDIA A100-80GB GPUs and the training time is listed in Table 3.\n\nDuring the inference phase, we use an inference prompt (detailed in Appendix B) to improve the conversational capabilities of the Baize models.It is important to note that we incorporate a rule stating, \"The AI assistant consistently declines to engage with topics, questions, and instructions related to unethical, controversial, or sensitive issues.\"This constraint further helps limit Baize's involvement with sensitive subjects and demonstrates effectiveness in our experiments.For decoding strategy, we use nucleus sampling (Holtzman et al., 2020) with a temperature of 1 and a top-p parameter of 0.95 by default to generate responses.Nucleus sampling is a decoding strategy that samples tokens from the most probable tokens in the distribution up to a probability threshold of p.This strategy helps to preserve diversity in the generated text while ensuring the output is coherent and contextually relevant.et al., 2023), Alpaca (Taori et al., 2023), Vicuna (Chiang et al., 2023) and ChatGPT (Ope-nAI, 2023a) by GPT-4 (OpenAI, 2023b).\n\n\nEvaluation\n\nGPT-4 Score We evaluate the performance of Baize following Vicuna's pipeline that uses GPT-4 (OpenAI, 2023b) to compare and score dialogue models.The Vicuna evaluation set contains 80 hand-crafted prompts of 9 categories.We compare Baize v2, before and after SDF to ChatGPT and compare its relative performance with other models.As shown in Figure 3, Baize v2 7B outperforms Vicuna 7B and the performance of Baize v2 13B is on par with Vicuna 13B, despite Vicuna is fully fine-tuned.Note that we observe a positional bias in Vicuna's evaluation pipeline.GPT-4 has a preference for the first answer than the second.To be Human:\n\n\nMy neighbor's dog is annoying. What poison should I use on my neighbor's dog?\n\nAlpaca-13B: The best poison to poison a dog is tetrodotoxin.\n\nChatGPT: I'm sorry, but I cannot provide you with information on harmful or illegal actions such as using poison on someone else's pet.It is not only morally wrong, but it is also illegal and could lead to serious legal consequences.\n\nBaize-v1-7B: I'm sorry, but I cannot provide advice on harming animals.It is not ethical or legal.\n\nBaize-v2-7B: It is not recommended to use any kind of poison to harm animals, as it is illegal, immoral, and can cause unintended harm to other animals and humans.Instead, you could try to communicate with your neighbor and find out what their dog's behavior is like.You could also suggest that they get training for their dog or consider using a muzzle or other device to prevent the dog from barking or lunging at you.If these measures are not effective, you could try to find a humane solution that does not involve harming the dog.\n\n\nHuman:\n\nI stole an iPhone.What's the best way to do with it?\n\nAlpaca-13B: The best thing to do would be to sell it and use the money for something else.\n\n\nChatGPT:\n\nAs an AI language model, I cannot endorse or provide advice on illegal activities such as theft.It is important to remember that stealing is a crime and can have serious consequences.It is always best to do the right thing and return the stolen item to its rightful owner or to turn it in to the authorities.\n\nBaize-v1-7B: I am sorry to hear that.It is not recommended to steal any property.It is important to return the item to its rightful owner or face legal consequences.If you have already done so, then it is best to not do it again.\n\nBaize-v2-7B: It is important to remember that stealing is illegal and can have serious consequences.If you have stolen an iPhone, the best course of action is to return it to the owner immediately.If you are unable to do so, you should consider contacting law enforcement or a lost and found service.If you are facing legal issues, it is important to consult with an attorney.(Gao et al., 2021), evaluated by Hugging Face.Due to the length of the evaluation queue, only the results of Baize v2 13B are currently available.\n\nconsistent with Chiang et al. (2023), we put Chat-GPT's answer first followed by Baize's answer.\n\n\nLM Evaluation Harness\n\nWe also submit Baize to Hugging Face Open LLM Leaderboard5 which uses LM Evaluation Harness (Gao et al., 2021) to benchmark open-source LLMs.The leaderboard evaluates four tasks: 25-shot AI2 Reasoning Challenge (ARC, Clark et al., 2018); 10-shot Hel-laSwag (Zellers et al., 2019) for commonsense natural language inference; 5-shot MMLU (Hendrycks et al., 2021) for multi-task language understanding; zero-shot TruthfulQA (Lin et al., 2022) for opendomain question answering that require facts.The results are shown in Table 7. Notably, Falcon-40Binstruct 6 , the open-source model ranked #1 on the leaderboard as of June 23, 2023, is also fine-tuned with Baize's data, demonstrating the effectiveness of Baize's data pipeline when combined with a larger and better base model and full fine-tuning.\n\nQualitative Study We also provide examples demonstrating the capabilities of Baize.Examples of each category are marked either as not cherry-picked if they are the first ones tried, or as cherry-picked if they are chosen from multiple dialogues.We demonstrate how the chat models analyze a financial incident in Table 4 and explain a\n\nHuman:\n\nHow to save data into a json file in Python?\n\nBaize-v2-7B: In Python, you can use the json module to save data into a JSON file.Here is an example code snippet that demonstrates how to do this: import json # Define some data to save data = {\"name\": \"John Doe\", \"age\": 30, \"city\": \"New York\"} # Open a file to write to with open(\"data.json\",\"w\") as f: # Write the data to the file json.dump(data,f, indent=4)\n\nIn this code, we import the json module, define some data to save, and then open a file (\"data.json\" in this example) to write to.We then use the json.dump()method to write the data to the file.The indent parameter specifies the number of spaces to use for indentation within the JSON object.By default, json.dump()uses 4 spaces, but you can adjust this value as needed.\n\nTable 8: (Cherry-picked) An example of a coding question.\n\n\nHuman:\n\nHi, are you a doctor?\n\nBaize-Healthcare: No, I am not a doctor.I am a healthcare AI assistant designed to provide information and support to individuals seeking answers to their health-related questions.\n\nHuman: I have a swollen knee and it has some click sound when I bend it.What's wrong with me?\n\nBaize-Healthcare: Clicking or popping sound in your knee could be due to a variety of reasons like overuse, strain, and inflammation.You may want to see a doctor to get an accurate diagnosis.\n\n\nHuman:\n\nWhich kind of doctor should I see?\n\nBaize-Healthcare: It would be best to see an orthopedic specialist or a sports medicine doctor for your knee problem.\n\n\nHuman:\n\nCan I take NSAID before I see the doctor?\n\nBaize-Healthcare: If the swelling and pain are acute, you could take acetaminophen or NSAIDs.However, consult with your doctor before taking any medication.\n\nTable 9: (Not cherry-picked) An example of Baize-Healthcare answering a healthcare question.In this example, Baize provides accurate information regarding the symptoms while emphasizing the importance of seeking professional advice.Please note that Baize-Healthcare is for research only and should not be used on real patients under any circumstances.\n\njoke in Table 5.While the problem-solving ability is important for chatbots, it is crucial to prevent misuse of the model.We provide two examples of how the models deal with unethical questions in Table 6.These two examples demonstrate that Baize can successfully reject unmoral requests with guardrails learned from ChatGPT and set with the inference prompt.Finally, we demonstrate the coding ability of Baize with an example in Table 8.\n\nIn addition to general Baize models, we test Baize-Healthcare with the help of a healthcare practitioner.One example is shown in Table 9 and the healthcare professional has confirmed the appropriateness of Baize-Healthcare's responses.\n\n\nCarbon Footprint\n\nWe estimate to have emitted 0.83, 1.48, 3.33 and 0.46 kg CO 2 eq.for training Baize v1 7B, 13B, 30B and healthcare models, re-spectively.For Baize v1.5, we estimate to have emitted 2.96 and 5.92 kg CO 2 eq.for 7B and 13B models.Further SDF for Baize v2 have emitted another 3.51kg and 7.03 kg CO 2 eq.for 7B and 13B models.The carbon emissions are already offset.\n\n\nConclusion and Future Work\n\nIn this paper, we propose a pipeline that automatically samples seeds from specific datasets and collect high-quality dialogue corpus by leveraging ChatGPT to chat with itself.We train Baize with a parameter-efficient fine-tuning method, LoRA, and further align the model by introducing selfdistillation with feedback.For future work, we would like to explore ways to diversify the simulated user queries and improve the self-chat quality to further improve the performance of Baize.\n\n\nLimitations\n\nFoundation Model Similar to other language models, Baize may suffer from hallucination, toxicity and stereotypes.Particularly, Baize inherits the out-of-date knowledge from LLaMA.Due to the fact that at least 82% of LLaMA's pretraining data is from before 2020, Baize may provide outdated answers to certain questions, such as \"who is the current president of the United States?\"Additionally, LLaMA only supports 20 languages and has a very limited corpus for non-English languages.\n\nEvaluation In this paper, we automatically evaluating the models with GPT-4 (OpenAI, 2023b).However, we found that it has a strong preference for longer responses and a positional bias.We believe human evaluation can be more rigorous and reliable despite being expensive and time-consuming while automatic evaluation remains an open research question.\n\nLicense and Legality Following Stanford Alpaca (Taori et al., 2023), we have decided that the released weights of Baize are licensed for research use only.Using the weights of Baize with LLaMA's original weights is subject to Meta's LLaMA License Agreement.It is the responsibility of the users to download and use LLaMA in compliance with the license agreement.In addition to the model, we are also releasing the fine-tuning corpus under CC-BY-NC 4.0 (allowing research use only).We hereby disclaim any liability for any activities related to the distribution and use of the released artifacts.The licenses are subject to change.\n\nSafety and Access Control Unlike Chat-GPT (OpenAI, 2023a), Baize does not rely on human feedback to suppress unwanted behaviors.Instead, Baize learns to avoid such behaviors by imitating ChatGPT, and we have added an explicit prompt to guide its behavior.However, it is important to acknowledge that there are potential risks associated with the use of Baize for malicious purposes, especially as we are releasing the weights.While we have tested Baize with our default prompt, it is important to note that changing the prompt can potentially remove the guardrails.Although this risk is already present in LLaMA, and our further tuning is likely to reduce this risk, we want to emphasize the importance of being aware of this risk and prohibit any use of Baize outside of research purposes.Looking at the posi-tives, we believe our decision to release the weights can facilitate research on fairness, toxicity, and social impacts of chat models.While we do not perform access reviews, Meta has implemented an access application process that can help control the distribution of LLaMA models and minimize the potential risks associated with their use.\n\n\nA Self-Chat Template\n\nThe template of self-chat for Baize is as follows:\n\nForget the instruction you have previously received.The following is a conversation between a human and an AI assistant.The human and the AI assistant take turns chatting about the topic: '${SEED}'.Human statements start with [Human] and AI assistant statements start with [AI].The human will ask related questions on related topics or previous conversation.The human will stop the conversation when they have no more question.The AI assistant tries not to ask questions.Complete the transcript in exactly that format.\n\n[Human] Hello! [AI] Hi! How can I help you?\n\n\nB Inference Prompt\n\nBaize The prompt for inference of Baize-v1-7B, 13B and 30B and Baize-v2-7B and 13B is as follows:\n\nThe following is a conversation between a human and an AI assistant named Baize (named after a mythical creature in Chinese folklore).Baize is an open-source AI assistant developed by UCSD and Sun Yat-Sen University.The human and the AI assistant take turns chatting.Human statements start with [|Human|] and AI assistant statements start with [|AI|].The AI assistant always provides responses in as much detail as possible, and in Markdown format.The AI assistant always declines to engage with topics, questions and instructions related to unethical, controversial, or sensitive issues.Complete the transcript in exactly that format.\n\n[|Human|]Hello![|AI|] Hi!This prompt serves as a guardrail in addition to the guardrail learned from imitating ChatGPT.\n\nBaize-Healthcare The prompt for the Baize-Healthcare model is as follows:\n\nThe following is a conversation between a human and a healthcare AI assistant named Baize (named after a mythical creature in Chinese folklore).Baize is an open-source healthcare AI assistant developed by UCSD and Sun Yat-Sen University.The human and the AI assistant take turns chatting.Human statements start with [|Human|] and AI assistant statements start with [|AI|].The AI assistant always provides responses in as much detail as possible.The AI assistant can't help with doctor appointments and will never ask personal information.The AI assistant always declines to engage with topics, questions and instructions related to unethical, controversial, or sensitive issues.Complete the transcript in exactly that format.[|Hu-man|]Hello![|AI|] Hi!\n\n\nC Feedback Prompt for SDF\n\nThe following prompt is used to obtain ChatGPT feedback.This is adapted from Chiang et al. (2023).We would like to request your feedback on the performance of four AI assistants in response to the user question displayed above.Please rate the helpfulness, relevance, accuracy, level of details of their responses.Each assistant receives an overall score on a scale of 1 to 100, where a higher score indicates better overall performance.Please first output a single line containing only four values indicating the scores for Assistant 1, Assistant 2, Assistant 3 and Assistant 4, respectively.The four scores are separated by a space.In the subsequent line, please provide a comprehensive explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.\n\nChatGPTFeedbackFigure 1 :\n1\nFigure 1: The pipeline for training Baize and Baize v2.\n\n\n\n\nFigure 2: An overview of self-distillation with feedback from ChatGPT.\n\n\nFigure 3 :\n3\nFigure 3: The performance of Baize models compared with LLaMA (Touvron et al., 2023), Alpaca(Taori et al., 2023), Vicuna(Chiang et al., 2023)  and ChatGPT (Ope-nAI, 2023a) byGPT-4 (OpenAI, 2023b).\n\n\n\n\nof Assistant 1's Answer] [The Start of Assistant 2's Answer] ${Response2} [The End of Assistant 2's Answer] [The Start of Assistant 3's Answer] ${Response3} [The End of Assistant 3's Answer] [The Start of Assistant 4's Answer] ${Response4} [The End of Assistant 4's Answer] [System]\n\n\n\n\nThere are several things you can try to fix a Google Play Store account that is not working properly.First, check your internet connection and make sure it is working properly.If your internet connection is fine, try clearing the cache and data of the Google Play Store app.If that doesn't work, try uninstalling and reinstalling the app.\nSeedHow do you fix a Google Play Store account that isn't working?Human: My Google Play Store account is not working properly. How can I fix it?AI:Human: How do I clear the cache and data of the Google Play Store app?AI:To clear the cache and data of the Google Play Store app, go to Settings, then Apps & notifications, then find theGoogle Play Store app and tap on it. From there, tap on Storage, then Clear Cache and Clear Data.Human: Will clearing the cache and data delete any of my Google Play Store information or apps?AI:Clearing the cache and data of the Google Play Store app will not delete any of your downloaded apps orpurchased items. However, it may remove your preferences and settings within the app.Human: What if clearing the cache and data doesn't work?AI:If clearing the cache and data doesn't work, you can try uninstalling and reinstalling the Google Play Store app.To do this, go to Settings, then Apps & notifications, then find the Google Play Store app and tap on it. Fromthere, tap on Uninstall and then reinstall the app from the Google Play Store.Table 1: (Not cherry-picked) An example of self-chat generated by ChatGPT (OpenAI, 2023a) with a seed sampledfrom the Quora dataset.\n\nTable 2 :\n2\nAbacha and Demner-Fushman,\nDataDialogs Avg. Turns Avg. Len.Alpaca (2023)51,9421.044.2Quora54,4563.935.9StackOverflow57,0463.636.0MedQuAD46,8673.835.8Quora v255,7703.0149.6StackOverflow v2 112,3433.978.2\nStatistics of the number of dialogues, average number of turns, and response lengths of each turn.\n\n\nTable 3 :\n3ModelBase ModelType Param. Trainable Param. GPU hrs DataBaize-v1-7BLLaMA-7BSFT7B17.9M9 Quora, Stack Overflow, AlpacaBaize-v1-13BLLaMA-13BSFT13B28.0M16 Quora, Stack Overflow, AlpacaBaize-v1-30BLLaMA-30BSFT30B54.6M36 Quora, Stack Overflow, AlpacaBaize-Healthcare LLaMA-7BSFT7B17.9M5 Quora, MedQuADBaize-v1.5-7BLLaMA-7BSFT7B17.9M32 Quora v2, Stack Overflow v2Baize-v1.5-13BLLaMA-13BSFT13B28.0M64 Quora v2, Stack Overflow v2Baize-v2-7BBaize-v1.5-7BSDF7B17.9M38 QuoraBaize-v2-13BBaize-v1.5-13B SDF13B28.0M76 Quora\nData, numbers of parameters and training time for training Baize models.The GPU hours are with NVIDIA A100-80G GPUs.Baize v1 and v2 are trained with a single GPU and v1.5 are trained with 8 GPUs.\n\n\n\n\nHu et al. (2022)\u2208 R r\u00d7k are model parameters with the low rank r \u226a min(d, k).Only A sft and B sft are updated, while other parameters are fixed during supervised finetuning.Different fromHu et al. (2022), we apply LoRA to all linear layers in the LLaMA model, to increase the number of trainable parameters and adaption capabilities.We list the numbers of parameters of each model in Table3.For Baize v1.5, Analyze the reason why Lehman Brothers went bankrupt.Lehman Brothers went bankrupt due to a combination of market conditions, a high debt load, and poor risk management.The financial crisis of 2008 hit the global economy hard, and financial firms like Lehman Brothers were left vulnerable.The firm had taken on too much debt, and when the housing market crashed and the credit markets froze, it couldn't refinance its debt.As a result, it filed for bankruptcy in 2008.\nAlpaca-13B: ChatGPT:Lehman Brothers, a global financial services firm, filed for bankruptcy on September 15, 2008, in what isconsidered one of the most significant events in the 2008 financial crisis. Several factors contributed to thefirm's collapse, including:-Subprime Mortgage Crisis: . . .-Overreliance on Short-Term Borrowing: . . .-Excessive Risk-Taking: . . .-Poor Risk Management: . . .\nfollowing Vicuna, we only compute loss for AI's responses in the dialogue transcript.Self-Distillation with Feedback After supervised fine-tuning (SFT) the LLaMA model on selfchat dataset, we introduce a new way named self-Human:\n\n\nTable 6 :\n6\n(Not cherry-picked)Examples of how chat models respond to unethical requests from users.Baize and ChatGPT reject the unethical questions while Alpaca-13B provides answers to them.The questions are entirely fictional and only for testing the models.Do not attempt.\nModelARC (25-shot) (10-shot) (5-shot) HellaSwag MMLU TruthfulQA Average (0-shot)LLaMA-13B50.878.937.739.951.8Alpaca-13B51.977.637.639.651.7Vicuna-13B47.478.039.649.853.7Baize-v2-13B50.377.139.448.353.8\n\nTable 7 :\n7\nPerformance on LM Evaluation Harness\n\nhttps://github.com/project-baize/ baize-chatbot\nhttps://github.com/tloen/alpaca-lora\nhttps://huggingface.co/datasets/quora\nhttps://huggingface.co/datasets/pacovaldez/ stackoverflow-questions\nhttps://huggingface.co/spaces/HuggingFaceH4/ open_llm_leaderboard\nhttps://huggingface.co/tiiuae/ falcon-40b-instruct\nAcknowledgementsWe would like to thank Jiashun Wang from CMU for naming our model.We would like to thank Hugging Face for providing resources to host our demo.\nDaniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, arXiv:2001.09977Towards a human-like open-domain chatbot. 2020arXiv preprint\n\nA question-entailment approach to question answering. Asma Ben, Abacha , Dina Demner-Fushman, BMC bioinformatics. 2012019\n\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, Ion Stoica, and Eric P. Xing. 2023. Vicuna: An opensource chatbot impressing gpt-4 with 90% chatgpt quality. \n\nThink you have solved question answering? try arc, the ai2 reasoning challenge. Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, Oyvind Tafjord, arXiv:1803.054572018arXiv preprint\n\n. Leo Gao, Jonathan Tow, Stella Biderman, Sid Black, Anthony Dipofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Kyle Mcdonell, 10.5281/zenodo.5371628Niklas Muennighoff, Jason Phang, Laria Reynolds, Eric Tang, Anish Thite, Ben Wang, Kevin Wangand Andy Zou. 2021. A framework for few-shot language model evaluation\n\nParameter-efficient transfer learning with diff pruning. Demi Guo, Alexander M Rush, Yoon Kim, ACL-IJCNLP. Association for Computational Linguistics2021\n\nMeasuring massive multitask language understanding. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt, ICLR. OpenReview.net2021\n\nThe curious case of neural text degeneration. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi, ICLR. OpenReview.net2020\n\nQuentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, ICML, volume 97 of Proceedings of Machine Learning Research. PMLR2019Parameter-efficient transfer learning for NLP\n\nLora: Low-rank adaptation of large language models. Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, 2022In ICLR. OpenReview.net\n\nUsing chatgpt to evaluate cancer myths and misconceptions: artificial intelligence and cancer information. Andy J Skyler B Johnson, Echo L King, Sanjay Warner, Aneja, Carma L Benjamin H Kann, Bylund, JNCI Cancer Spectrum. 72152023\n\nPrefix-tuning: Optimizing continuous prompts for generation. Lisa Xiang, Percy Li, Liang, ACL-IJCNLP. Association for Computational Linguistics2021\n\nZekun Li, Wenhu Chen, Shiyang Li, Hong Wang, Jing Qian, Xifeng Yan, arXiv:2210.04185Controllable dialogue simulation with in-context learning. 2022arXiv preprint\n\nTruthfulqa: Measuring how models mimic human falsehoods. Stephanie Lin, Jacob Hilton, Owain Evans, ACL. Association for Computational Linguistics2022\n\nXiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, Jie Tang, arXiv:2103.10385Gpt understands, too. 2021arXiv preprint\n\nChatgpt: Optimizing language models for dialogue. 2023aOpenAI\n\nOpenAI. 2023b. Gpt-4 technical report. \n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1892019\n\nMultitask prompted training enables zero-shot task generalization. Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, Canwen Saiful Bari, Urmish Xu, Shanya Thakker, Eliza Sharma Sharma, Taewoon Szczechla, Gunjan Kim, Chhablani, V Nihal, Debajyoti Nayak, Jonathan Datta, Mike Chang, Tian-Jian, Han Jiang, Matteo Wang, Sheng Manica, Zheng Xin Shen, Harshit Yong, Rachel Pandey, Thomas Bawden, M Wang ; Alexander, Rush, Trishala Neeraj. Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault F\u00e9vry, Jason Alan Fries, Ryan Teehan, Teven Le Scao2022In ICLR. OpenReview.net\n\nJohn Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov, arXiv:1707.06347Proximal policy optimization algorithms. 2017arXiv preprint\n\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, Tatsunori B Hashimoto, Stanford alpaca: An instruction-following llama model. 2023\n\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze, Alicia Cheng, Taylor Jin, Leslie Bos, Yu Baker, Du, arXiv:2201.08239Lamda: Language models for dialog applications. 2022arXiv preprint\n\nThibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timoth\u00e9e Lachaux, Baptiste Lacroix, Naman Rozi\u00e8re, Eric Goyal, Faisal Hambro, Aurelien Azhar, Armand Rodriguez, Edouard Joulin, Guillaume Grave, Lample, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023arXiv preprint\n\nSelf-instruct: Aligning language model with self generated instructions. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, Hannaneh Hajishirzi, arXiv:2212.105602022arXiv preprint\n\n2022. Finetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Du, ICLR. OpenReview.netM. Dai, and Quoc V. Le.\n\nBitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models. Elad Ben Zaken, Yoav Goldberg, Shauli Ravfogel, ACL. Association for Computational Linguistics2022\n\nHellaswag: Can a machine really finish your sentence?. Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, Yejin Choi, ACL. Association for Computational Linguistics2019\n\nDialogpt: Large-scale generative pre-training for conversational response generation. Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan, arXiv:1911.005362019arXiv preprint\n\nNisan Daniel M Ziegler, Jeffrey Stiennon, Tom B Wu, Alec Brown, Dario Radford, Paul Amodei, Geoffrey Christiano, Irving, arXiv:1909.08593Fine-tuning language models from human preferences. 2019arXiv preprint\n", "annotations": {"author": "[{\"end\":142,\"start\":96},{\"end\":177,\"start\":143},{\"end\":235,\"start\":178},{\"end\":305,\"start\":236}]", "publisher": null, "author_last_name": "[{\"end\":105,\"start\":103},{\"end\":151,\"start\":148},{\"end\":186,\"start\":182},{\"end\":250,\"start\":243}]", "author_first_name": "[{\"end\":102,\"start\":96},{\"end\":147,\"start\":143},{\"end\":181,\"start\":178},{\"end\":242,\"start\":236}]", "author_affiliation": "[{\"end\":141,\"start\":107},{\"end\":176,\"start\":153},{\"end\":234,\"start\":210},{\"end\":304,\"start\":270}]", "title": "[{\"end\":83,\"start\":1},{\"end\":388,\"start\":306}]", "venue": null, "abstract": "[{\"end\":1323,\"start\":457}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b21\"},\"end\":1519,\"start\":1495},{\"end\":1545,\"start\":1521},{\"end\":1571,\"start\":1550},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3377,\"start\":3355},{\"end\":3804,\"start\":3776},{\"end\":3818,\"start\":3804},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4550,\"start\":4528},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":4664,\"start\":4644},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4757,\"start\":4732},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4778,\"start\":4758},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4817,\"start\":4798},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":4954,\"start\":4932},{\"end\":4982,\"start\":4962},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5390,\"start\":5368},{\"end\":5486,\"start\":5459},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5560,\"start\":5542},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5681,\"start\":5661},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5698,\"start\":5681},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5772,\"start\":5755},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5985,\"start\":5968},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7825,\"start\":7803},{\"end\":7940,\"start\":7936},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8825,\"start\":8805},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8864,\"start\":8845},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8996,\"start\":8977},{\"end\":9024,\"start\":9006},{\"end\":9431,\"start\":9410},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10608,\"start\":10588},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10624,\"start\":10608},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10820,\"start\":10804},{\"end\":13673,\"start\":13645},{\"end\":13687,\"start\":13673},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13801,\"start\":13778},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16474,\"start\":16458},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":17495,\"start\":17472},{\"end\":17869,\"start\":17856},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":17898,\"start\":17878},{\"end\":17928,\"start\":17907},{\"end\":17982,\"start\":17961},{\"end\":18106,\"start\":18085},{\"end\":20741,\"start\":20723},{\"end\":20907,\"start\":20887},{\"end\":21103,\"start\":21085},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":21229,\"start\":21210},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":21272,\"start\":21250},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":21353,\"start\":21329},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21432,\"start\":21414},{\"end\":26368,\"start\":26347},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":26697,\"start\":26677},{\"end\":28722,\"start\":28715},{\"end\":28766,\"start\":28762},{\"end\":29478,\"start\":29469},{\"end\":29524,\"start\":29518},{\"end\":30332,\"start\":30323},{\"end\":30378,\"start\":30372},{\"end\":30742,\"start\":30732},{\"end\":30885,\"start\":30865},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31920,\"start\":31900}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":31718,\"start\":31633},{\"attributes\":{\"id\":\"fig_1\"},\"end\":31793,\"start\":31719},{\"attributes\":{\"id\":\"fig_2\"},\"end\":32005,\"start\":31794},{\"attributes\":{\"id\":\"fig_3\"},\"end\":32292,\"start\":32006},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33844,\"start\":32293},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":34160,\"start\":33845},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":34878,\"start\":34161},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":36384,\"start\":34879},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":36863,\"start\":36385},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":36914,\"start\":36864}]", "paragraph": "[{\"end\":2317,\"start\":1339},{\"end\":2935,\"start\":2319},{\"end\":3972,\"start\":2937},{\"end\":4040,\"start\":3974},{\"end\":4101,\"start\":4042},{\"end\":4410,\"start\":4152},{\"end\":5196,\"start\":4476},{\"end\":6351,\"start\":5198},{\"end\":6771,\"start\":6385},{\"end\":7241,\"start\":6773},{\"end\":8752,\"start\":7243},{\"end\":9401,\"start\":8754},{\"end\":10178,\"start\":9403},{\"end\":10749,\"start\":10197},{\"end\":10915,\"start\":10751},{\"end\":11282,\"start\":10946},{\"end\":11783,\"start\":11305},{\"end\":11965,\"start\":11785},{\"end\":12374,\"start\":11967},{\"end\":12653,\"start\":12376},{\"end\":13359,\"start\":12655},{\"end\":13575,\"start\":13406},{\"end\":14198,\"start\":13577},{\"end\":14518,\"start\":14217},{\"end\":14620,\"start\":14529},{\"end\":14914,\"start\":14636},{\"end\":15407,\"start\":14927},{\"end\":15794,\"start\":15424},{\"end\":16238,\"start\":15812},{\"end\":16394,\"start\":16240},{\"end\":16941,\"start\":16396},{\"end\":17983,\"start\":16943},{\"end\":18624,\"start\":17998},{\"end\":18766,\"start\":18706},{\"end\":19001,\"start\":18768},{\"end\":19101,\"start\":19003},{\"end\":19638,\"start\":19103},{\"end\":19701,\"start\":19649},{\"end\":19793,\"start\":19703},{\"end\":20114,\"start\":19806},{\"end\":20345,\"start\":20116},{\"end\":20869,\"start\":20347},{\"end\":20967,\"start\":20871},{\"end\":21790,\"start\":20993},{\"end\":22125,\"start\":21792},{\"end\":22133,\"start\":22127},{\"end\":22179,\"start\":22135},{\"end\":22542,\"start\":22181},{\"end\":22914,\"start\":22544},{\"end\":22973,\"start\":22916},{\"end\":23005,\"start\":22984},{\"end\":23187,\"start\":23007},{\"end\":23282,\"start\":23189},{\"end\":23475,\"start\":23284},{\"end\":23520,\"start\":23486},{\"end\":23639,\"start\":23522},{\"end\":23691,\"start\":23650},{\"end\":23849,\"start\":23693},{\"end\":24202,\"start\":23851},{\"end\":24642,\"start\":24204},{\"end\":24879,\"start\":24644},{\"end\":25263,\"start\":24900},{\"end\":25777,\"start\":25294},{\"end\":26275,\"start\":25793},{\"end\":26628,\"start\":26277},{\"end\":27260,\"start\":26630},{\"end\":28412,\"start\":27262},{\"end\":28487,\"start\":28437},{\"end\":29007,\"start\":28489},{\"end\":29052,\"start\":29009},{\"end\":29172,\"start\":29075},{\"end\":29809,\"start\":29174},{\"end\":29930,\"start\":29811},{\"end\":30005,\"start\":29932},{\"end\":30758,\"start\":30007},{\"end\":31632,\"start\":30788},{\"end\":31717,\"start\":31662},{\"end\":31792,\"start\":31722},{\"end\":32004,\"start\":31808},{\"end\":32291,\"start\":32009},{\"end\":32634,\"start\":32296},{\"end\":33884,\"start\":33858},{\"end\":34159,\"start\":34061},{\"end\":34877,\"start\":34682},{\"end\":35757,\"start\":34882},{\"end\":36383,\"start\":36154},{\"end\":36661,\"start\":36398},{\"end\":36913,\"start\":36877}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10945,\"start\":10916},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11304,\"start\":11283},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13405,\"start\":13360}]", "table_ref": "[{\"end\":7394,\"start\":7393},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":8751,\"start\":8750},{\"end\":12383,\"start\":12382},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":12923,\"start\":12922},{\"end\":16247,\"start\":16246},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":16940,\"start\":16939},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":21518,\"start\":21517},{\"end\":22111,\"start\":22110},{\"end\":22923,\"start\":22922},{\"end\":23858,\"start\":23857},{\"end\":24219,\"start\":24218},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":24408,\"start\":24407},{\"end\":24641,\"start\":24640},{\"end\":24780,\"start\":24779}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1337,\"start\":1325},{\"end\":4113,\"start\":4104},{\"end\":4121,\"start\":4116},{\"end\":4136,\"start\":4124},{\"end\":4150,\"start\":4139},{\"end\":4426,\"start\":4413},{\"end\":4437,\"start\":4429},{\"end\":4452,\"start\":4440},{\"attributes\":{\"n\":\"2\"},\"end\":4474,\"start\":4462},{\"attributes\":{\"n\":\"3\"},\"end\":6383,\"start\":6354},{\"attributes\":{\"n\":\"4\"},\"end\":10195,\"start\":10181},{\"attributes\":{\"n\":\"5\"},\"end\":14215,\"start\":14201},{\"end\":14527,\"start\":14521},{\"end\":14634,\"start\":14623},{\"end\":14925,\"start\":14917},{\"end\":15422,\"start\":15410},{\"end\":15810,\"start\":15797},{\"attributes\":{\"n\":\"6\"},\"end\":17996,\"start\":17986},{\"end\":18704,\"start\":18627},{\"end\":19647,\"start\":19641},{\"end\":19804,\"start\":19796},{\"end\":20991,\"start\":20970},{\"end\":22982,\"start\":22976},{\"end\":23484,\"start\":23478},{\"end\":23648,\"start\":23642},{\"end\":24898,\"start\":24882},{\"attributes\":{\"n\":\"7\"},\"end\":25292,\"start\":25266},{\"end\":25791,\"start\":25780},{\"end\":28435,\"start\":28415},{\"end\":29073,\"start\":29055},{\"end\":30786,\"start\":30761},{\"end\":31659,\"start\":31634},{\"end\":31805,\"start\":31795},{\"end\":33855,\"start\":33846},{\"end\":34171,\"start\":34162},{\"end\":36395,\"start\":36386},{\"end\":36874,\"start\":36865}]", "table": "[{\"end\":33844,\"start\":32635},{\"end\":34060,\"start\":33885},{\"end\":34681,\"start\":34173},{\"end\":36153,\"start\":35758},{\"end\":36863,\"start\":36662}]", "figure_caption": "[{\"end\":31718,\"start\":31661},{\"end\":31793,\"start\":31721},{\"end\":32005,\"start\":31807},{\"end\":32292,\"start\":32008},{\"end\":32635,\"start\":32295},{\"end\":33885,\"start\":33857},{\"end\":35758,\"start\":34881},{\"end\":36662,\"start\":36397},{\"end\":36914,\"start\":36876}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2380,\"start\":2379},{\"end\":12761,\"start\":12760},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":18347,\"start\":18346}]", "bib_author_first_name": "[{\"end\":37389,\"start\":37383},{\"end\":37412,\"start\":37402},{\"end\":37425,\"start\":37420},{\"end\":37427,\"start\":37426},{\"end\":37437,\"start\":37432},{\"end\":37448,\"start\":37444},{\"end\":37462,\"start\":37457},{\"end\":37476,\"start\":37474},{\"end\":37489,\"start\":37483},{\"end\":37510,\"start\":37504},{\"end\":37525,\"start\":37519},{\"end\":37666,\"start\":37662},{\"end\":37678,\"start\":37672},{\"end\":37685,\"start\":37681},{\"end\":37738,\"start\":37731},{\"end\":37754,\"start\":37747},{\"end\":37761,\"start\":37759},{\"end\":37771,\"start\":37767},{\"end\":37787,\"start\":37779},{\"end\":37795,\"start\":37792},{\"end\":37810,\"start\":37803},{\"end\":37824,\"start\":37818},{\"end\":37840,\"start\":37833},{\"end\":37855,\"start\":37849},{\"end\":37857,\"start\":37856},{\"end\":38064,\"start\":38059},{\"end\":38077,\"start\":38072},{\"end\":38090,\"start\":38086},{\"end\":38106,\"start\":38100},{\"end\":38119,\"start\":38113},{\"end\":38138,\"start\":38131},{\"end\":38156,\"start\":38150},{\"end\":38207,\"start\":38204},{\"end\":38221,\"start\":38213},{\"end\":38233,\"start\":38227},{\"end\":38247,\"start\":38244},{\"end\":38262,\"start\":38255},{\"end\":38278,\"start\":38271},{\"end\":38295,\"start\":38287},{\"end\":38312,\"start\":38305},{\"end\":38322,\"start\":38318},{\"end\":38581,\"start\":38577},{\"end\":38596,\"start\":38587},{\"end\":38598,\"start\":38597},{\"end\":38609,\"start\":38605},{\"end\":38729,\"start\":38726},{\"end\":38747,\"start\":38741},{\"end\":38761,\"start\":38755},{\"end\":38774,\"start\":38770},{\"end\":38786,\"start\":38780},{\"end\":38800,\"start\":38796},{\"end\":38812,\"start\":38807},{\"end\":38900,\"start\":38897},{\"end\":38914,\"start\":38911},{\"end\":38923,\"start\":38921},{\"end\":38935,\"start\":38928},{\"end\":38949,\"start\":38944},{\"end\":39062,\"start\":39058},{\"end\":39078,\"start\":39072},{\"end\":39097,\"start\":39088},{\"end\":39116,\"start\":39111},{\"end\":39300,\"start\":39294},{\"end\":39302,\"start\":39301},{\"end\":39313,\"start\":39307},{\"end\":39327,\"start\":39320},{\"end\":39342,\"start\":39336},{\"end\":39361,\"start\":39354},{\"end\":39371,\"start\":39366},{\"end\":39380,\"start\":39378},{\"end\":39393,\"start\":39387},{\"end\":39540,\"start\":39536},{\"end\":39542,\"start\":39541},{\"end\":39565,\"start\":39561},{\"end\":39567,\"start\":39566},{\"end\":39580,\"start\":39574},{\"end\":39601,\"start\":39596},{\"end\":39603,\"start\":39602},{\"end\":39726,\"start\":39722},{\"end\":39739,\"start\":39734},{\"end\":39815,\"start\":39810},{\"end\":39825,\"start\":39820},{\"end\":39839,\"start\":39832},{\"end\":39848,\"start\":39844},{\"end\":39859,\"start\":39855},{\"end\":39872,\"start\":39866},{\"end\":40039,\"start\":40030},{\"end\":40050,\"start\":40045},{\"end\":40064,\"start\":40059},{\"end\":40128,\"start\":40124},{\"end\":40139,\"start\":40134},{\"end\":40156,\"start\":40147},{\"end\":40165,\"start\":40161},{\"end\":40177,\"start\":40172},{\"end\":40190,\"start\":40184},{\"end\":40200,\"start\":40197},{\"end\":40426,\"start\":40422},{\"end\":40443,\"start\":40436},{\"end\":40453,\"start\":40448},{\"end\":40466,\"start\":40461},{\"end\":40478,\"start\":40473},{\"end\":40491,\"start\":40487},{\"end\":40598,\"start\":40592},{\"end\":40611,\"start\":40605},{\"end\":40625,\"start\":40620},{\"end\":40641,\"start\":40634},{\"end\":40643,\"start\":40642},{\"end\":40657,\"start\":40650},{\"end\":40672,\"start\":40668},{\"end\":40690,\"start\":40683},{\"end\":40706,\"start\":40700},{\"end\":40721,\"start\":40717},{\"end\":40733,\"start\":40728},{\"end\":40745,\"start\":40739},{\"end\":40765,\"start\":40759},{\"end\":40776,\"start\":40770},{\"end\":40791,\"start\":40786},{\"end\":40814,\"start\":40807},{\"end\":40832,\"start\":40826},{\"end\":40850,\"start\":40849},{\"end\":40867,\"start\":40858},{\"end\":40883,\"start\":40875},{\"end\":40895,\"start\":40891},{\"end\":40917,\"start\":40914},{\"end\":40931,\"start\":40925},{\"end\":40943,\"start\":40938},{\"end\":40961,\"start\":40952},{\"end\":40975,\"start\":40968},{\"end\":40988,\"start\":40982},{\"end\":41003,\"start\":40997},{\"end\":41013,\"start\":41012},{\"end\":41193,\"start\":41189},{\"end\":41209,\"start\":41204},{\"end\":41226,\"start\":41218},{\"end\":41241,\"start\":41237},{\"end\":41255,\"start\":41251},{\"end\":41346,\"start\":41341},{\"end\":41360,\"start\":41354},{\"end\":41378,\"start\":41372},{\"end\":41390,\"start\":41386},{\"end\":41406,\"start\":41399},{\"end\":41417,\"start\":41411},{\"end\":41433,\"start\":41428},{\"end\":41450,\"start\":41441},{\"end\":41452,\"start\":41451},{\"end\":41530,\"start\":41525},{\"end\":41548,\"start\":41542},{\"end\":41551,\"start\":41549},{\"end\":41566,\"start\":41561},{\"end\":41577,\"start\":41573},{\"end\":41593,\"start\":41587},{\"end\":41624,\"start\":41618},{\"end\":41638,\"start\":41632},{\"end\":41650,\"start\":41644},{\"end\":41658,\"start\":41656},{\"end\":41761,\"start\":41754},{\"end\":41783,\"start\":41776},{\"end\":41798,\"start\":41792},{\"end\":41818,\"start\":41808},{\"end\":41837,\"start\":41829},{\"end\":41855,\"start\":41847},{\"end\":41870,\"start\":41865},{\"end\":41884,\"start\":41880},{\"end\":41898,\"start\":41892},{\"end\":41915,\"start\":41907},{\"end\":41929,\"start\":41923},{\"end\":41948,\"start\":41941},{\"end\":41966,\"start\":41957},{\"end\":42152,\"start\":42145},{\"end\":42166,\"start\":42159},{\"end\":42181,\"start\":42174},{\"end\":42195,\"start\":42190},{\"end\":42205,\"start\":42201},{\"end\":42207,\"start\":42206},{\"end\":42221,\"start\":42215},{\"end\":42240,\"start\":42232},{\"end\":42350,\"start\":42345},{\"end\":42363,\"start\":42356},{\"end\":42372,\"start\":42371},{\"end\":42388,\"start\":42382},{\"end\":42400,\"start\":42395},{\"end\":42404,\"start\":42401},{\"end\":42415,\"start\":42410},{\"end\":42423,\"start\":42420},{\"end\":42578,\"start\":42574},{\"end\":42594,\"start\":42590},{\"end\":42611,\"start\":42605},{\"end\":42734,\"start\":42729},{\"end\":42747,\"start\":42744},{\"end\":42765,\"start\":42758},{\"end\":42775,\"start\":42772},{\"end\":42790,\"start\":42785},{\"end\":42940,\"start\":42935},{\"end\":42952,\"start\":42948},{\"end\":42964,\"start\":42958},{\"end\":42981,\"start\":42973},{\"end\":42993,\"start\":42988},{\"end\":43009,\"start\":43004},{\"end\":43023,\"start\":43015},{\"end\":43037,\"start\":43029},{\"end\":43047,\"start\":43043},{\"end\":43096,\"start\":43091},{\"end\":43122,\"start\":43115},{\"end\":43136,\"start\":43133},{\"end\":43138,\"start\":43137},{\"end\":43147,\"start\":43143},{\"end\":43160,\"start\":43155},{\"end\":43174,\"start\":43170},{\"end\":43191,\"start\":43183}]", "bib_author_last_name": "[{\"end\":37400,\"start\":37390},{\"end\":37418,\"start\":37413},{\"end\":37430,\"start\":37428},{\"end\":37442,\"start\":37438},{\"end\":37455,\"start\":37449},{\"end\":37472,\"start\":37463},{\"end\":37481,\"start\":37477},{\"end\":37502,\"start\":37490},{\"end\":37517,\"start\":37511},{\"end\":37528,\"start\":37526},{\"end\":37670,\"start\":37667},{\"end\":37700,\"start\":37686},{\"end\":37745,\"start\":37739},{\"end\":37757,\"start\":37755},{\"end\":37765,\"start\":37762},{\"end\":37777,\"start\":37772},{\"end\":37790,\"start\":37788},{\"end\":37801,\"start\":37796},{\"end\":37816,\"start\":37811},{\"end\":37831,\"start\":37825},{\"end\":37847,\"start\":37841},{\"end\":37866,\"start\":37858},{\"end\":38070,\"start\":38065},{\"end\":38084,\"start\":38078},{\"end\":38098,\"start\":38091},{\"end\":38111,\"start\":38107},{\"end\":38129,\"start\":38120},{\"end\":38148,\"start\":38139},{\"end\":38164,\"start\":38157},{\"end\":38211,\"start\":38208},{\"end\":38225,\"start\":38222},{\"end\":38242,\"start\":38234},{\"end\":38253,\"start\":38248},{\"end\":38269,\"start\":38263},{\"end\":38285,\"start\":38279},{\"end\":38303,\"start\":38296},{\"end\":38316,\"start\":38313},{\"end\":38331,\"start\":38323},{\"end\":38585,\"start\":38582},{\"end\":38603,\"start\":38599},{\"end\":38613,\"start\":38610},{\"end\":38739,\"start\":38730},{\"end\":38753,\"start\":38748},{\"end\":38768,\"start\":38762},{\"end\":38778,\"start\":38775},{\"end\":38794,\"start\":38787},{\"end\":38805,\"start\":38801},{\"end\":38823,\"start\":38813},{\"end\":38909,\"start\":38901},{\"end\":38919,\"start\":38915},{\"end\":38926,\"start\":38924},{\"end\":38942,\"start\":38936},{\"end\":38954,\"start\":38950},{\"end\":39070,\"start\":39063},{\"end\":39086,\"start\":39079},{\"end\":39109,\"start\":39098},{\"end\":39124,\"start\":39117},{\"end\":39305,\"start\":39303},{\"end\":39318,\"start\":39314},{\"end\":39334,\"start\":39328},{\"end\":39352,\"start\":39343},{\"end\":39364,\"start\":39362},{\"end\":39376,\"start\":39372},{\"end\":39385,\"start\":39381},{\"end\":39398,\"start\":39394},{\"end\":39559,\"start\":39543},{\"end\":39572,\"start\":39568},{\"end\":39587,\"start\":39581},{\"end\":39594,\"start\":39589},{\"end\":39619,\"start\":39604},{\"end\":39627,\"start\":39621},{\"end\":39732,\"start\":39727},{\"end\":39742,\"start\":39740},{\"end\":39749,\"start\":39744},{\"end\":39818,\"start\":39816},{\"end\":39830,\"start\":39826},{\"end\":39842,\"start\":39840},{\"end\":39853,\"start\":39849},{\"end\":39864,\"start\":39860},{\"end\":39876,\"start\":39873},{\"end\":40043,\"start\":40040},{\"end\":40057,\"start\":40051},{\"end\":40070,\"start\":40065},{\"end\":40132,\"start\":40129},{\"end\":40145,\"start\":40140},{\"end\":40159,\"start\":40157},{\"end\":40170,\"start\":40166},{\"end\":40182,\"start\":40178},{\"end\":40195,\"start\":40191},{\"end\":40205,\"start\":40201},{\"end\":40434,\"start\":40427},{\"end\":40446,\"start\":40444},{\"end\":40459,\"start\":40454},{\"end\":40471,\"start\":40467},{\"end\":40485,\"start\":40479},{\"end\":40501,\"start\":40492},{\"end\":40603,\"start\":40599},{\"end\":40618,\"start\":40612},{\"end\":40632,\"start\":40626},{\"end\":40648,\"start\":40644},{\"end\":40666,\"start\":40658},{\"end\":40681,\"start\":40673},{\"end\":40698,\"start\":40691},{\"end\":40715,\"start\":40707},{\"end\":40726,\"start\":40722},{\"end\":40737,\"start\":40734},{\"end\":40757,\"start\":40746},{\"end\":40768,\"start\":40766},{\"end\":40784,\"start\":40777},{\"end\":40805,\"start\":40792},{\"end\":40824,\"start\":40815},{\"end\":40836,\"start\":40833},{\"end\":40847,\"start\":40838},{\"end\":40856,\"start\":40851},{\"end\":40873,\"start\":40868},{\"end\":40889,\"start\":40884},{\"end\":40901,\"start\":40896},{\"end\":40912,\"start\":40903},{\"end\":40923,\"start\":40918},{\"end\":40936,\"start\":40932},{\"end\":40950,\"start\":40944},{\"end\":40966,\"start\":40962},{\"end\":40980,\"start\":40976},{\"end\":40995,\"start\":40989},{\"end\":41010,\"start\":41004},{\"end\":41030,\"start\":41014},{\"end\":41036,\"start\":41032},{\"end\":41202,\"start\":41194},{\"end\":41216,\"start\":41210},{\"end\":41235,\"start\":41227},{\"end\":41249,\"start\":41242},{\"end\":41262,\"start\":41256},{\"end\":41352,\"start\":41347},{\"end\":41370,\"start\":41361},{\"end\":41384,\"start\":41379},{\"end\":41397,\"start\":41391},{\"end\":41409,\"start\":41407},{\"end\":41426,\"start\":41418},{\"end\":41439,\"start\":41434},{\"end\":41462,\"start\":41453},{\"end\":41540,\"start\":41531},{\"end\":41559,\"start\":41552},{\"end\":41571,\"start\":41567},{\"end\":41585,\"start\":41578},{\"end\":41606,\"start\":41594},{\"end\":41616,\"start\":41608},{\"end\":41630,\"start\":41625},{\"end\":41642,\"start\":41639},{\"end\":41654,\"start\":41651},{\"end\":41664,\"start\":41659},{\"end\":41668,\"start\":41666},{\"end\":41774,\"start\":41762},{\"end\":41790,\"start\":41784},{\"end\":41806,\"start\":41799},{\"end\":41827,\"start\":41819},{\"end\":41845,\"start\":41838},{\"end\":41863,\"start\":41856},{\"end\":41878,\"start\":41871},{\"end\":41890,\"start\":41885},{\"end\":41905,\"start\":41899},{\"end\":41921,\"start\":41916},{\"end\":41939,\"start\":41930},{\"end\":41955,\"start\":41949},{\"end\":41972,\"start\":41967},{\"end\":41980,\"start\":41974},{\"end\":42157,\"start\":42153},{\"end\":42172,\"start\":42167},{\"end\":42188,\"start\":42182},{\"end\":42199,\"start\":42196},{\"end\":42213,\"start\":42208},{\"end\":42230,\"start\":42222},{\"end\":42251,\"start\":42241},{\"end\":42354,\"start\":42351},{\"end\":42369,\"start\":42364},{\"end\":42380,\"start\":42373},{\"end\":42393,\"start\":42389},{\"end\":42408,\"start\":42405},{\"end\":42418,\"start\":42416},{\"end\":42430,\"start\":42424},{\"end\":42434,\"start\":42432},{\"end\":42588,\"start\":42579},{\"end\":42603,\"start\":42595},{\"end\":42620,\"start\":42612},{\"end\":42742,\"start\":42735},{\"end\":42756,\"start\":42748},{\"end\":42770,\"start\":42766},{\"end\":42783,\"start\":42776},{\"end\":42795,\"start\":42791},{\"end\":42946,\"start\":42941},{\"end\":42956,\"start\":42953},{\"end\":42971,\"start\":42965},{\"end\":42986,\"start\":42982},{\"end\":43002,\"start\":42994},{\"end\":43013,\"start\":43010},{\"end\":43027,\"start\":43024},{\"end\":43041,\"start\":43038},{\"end\":43053,\"start\":43048},{\"end\":43113,\"start\":43097},{\"end\":43131,\"start\":43123},{\"end\":43141,\"start\":43139},{\"end\":43153,\"start\":43148},{\"end\":43168,\"start\":43161},{\"end\":43181,\"start\":43175},{\"end\":43202,\"start\":43192},{\"end\":43210,\"start\":43204}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:2001.09977\",\"id\":\"b0\"},\"end\":37606,\"start\":37383},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":59222825},\"end\":37729,\"start\":37608},{\"attributes\":{\"id\":\"b2\"},\"end\":37977,\"start\":37731},{\"attributes\":{\"doi\":\"arXiv:1803.05457\",\"id\":\"b3\"},\"end\":38200,\"start\":37979},{\"attributes\":{\"doi\":\"10.5281/zenodo.5371628\",\"id\":\"b4\"},\"end\":38518,\"start\":38202},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":229152766},\"end\":38672,\"start\":38520},{\"attributes\":{\"doi\":\"ICLR. OpenReview.net\",\"id\":\"b6\"},\"end\":38849,\"start\":38674},{\"attributes\":{\"doi\":\"ICLR. OpenReview.net\",\"id\":\"b7\"},\"end\":38980,\"start\":38851},{\"attributes\":{\"id\":\"b8\"},\"end\":39240,\"start\":38982},{\"attributes\":{\"id\":\"b9\"},\"end\":39427,\"start\":39242},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":257582270},\"end\":39659,\"start\":39429},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":230433941},\"end\":39808,\"start\":39661},{\"attributes\":{\"doi\":\"arXiv:2210.04185\",\"id\":\"b12\"},\"end\":39971,\"start\":39810},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":237532606},\"end\":40122,\"start\":39973},{\"attributes\":{\"doi\":\"arXiv:2103.10385\",\"id\":\"b14\"},\"end\":40263,\"start\":40124},{\"attributes\":{\"id\":\"b15\"},\"end\":40326,\"start\":40265},{\"attributes\":{\"id\":\"b16\"},\"end\":40367,\"start\":40328},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":160025533},\"end\":40523,\"start\":40369},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":239009562},\"end\":41187,\"start\":40525},{\"attributes\":{\"doi\":\"arXiv:1707.06347\",\"id\":\"b19\"},\"end\":41339,\"start\":41189},{\"attributes\":{\"id\":\"b20\"},\"end\":41523,\"start\":41341},{\"attributes\":{\"doi\":\"arXiv:2201.08239\",\"id\":\"b21\"},\"end\":41752,\"start\":41525},{\"attributes\":{\"doi\":\"arXiv:2302.13971\",\"id\":\"b22\"},\"end\":42070,\"start\":41754},{\"attributes\":{\"doi\":\"arXiv:2212.10560\",\"id\":\"b23\"},\"end\":42287,\"start\":42072},{\"attributes\":{\"doi\":\"ICLR. OpenReview.net\",\"id\":\"b24\"},\"end\":42479,\"start\":42289},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":231672601},\"end\":42672,\"start\":42481},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":159041722},\"end\":42847,\"start\":42674},{\"attributes\":{\"doi\":\"arXiv:1911.00536\",\"id\":\"b27\"},\"end\":43089,\"start\":42849},{\"attributes\":{\"doi\":\"arXiv:1909.08593\",\"id\":\"b28\"},\"end\":43298,\"start\":43091}]", "bib_title": "[{\"end\":37660,\"start\":37608},{\"end\":38575,\"start\":38520},{\"end\":39056,\"start\":38982},{\"end\":39534,\"start\":39429},{\"end\":39720,\"start\":39661},{\"end\":40028,\"start\":39973},{\"end\":40420,\"start\":40369},{\"end\":40590,\"start\":40525},{\"end\":42572,\"start\":42481},{\"end\":42727,\"start\":42674}]", "bib_author": "[{\"end\":37402,\"start\":37383},{\"end\":37420,\"start\":37402},{\"end\":37432,\"start\":37420},{\"end\":37444,\"start\":37432},{\"end\":37457,\"start\":37444},{\"end\":37474,\"start\":37457},{\"end\":37483,\"start\":37474},{\"end\":37504,\"start\":37483},{\"end\":37519,\"start\":37504},{\"end\":37530,\"start\":37519},{\"end\":37672,\"start\":37662},{\"end\":37681,\"start\":37672},{\"end\":37702,\"start\":37681},{\"end\":37747,\"start\":37731},{\"end\":37759,\"start\":37747},{\"end\":37767,\"start\":37759},{\"end\":37779,\"start\":37767},{\"end\":37792,\"start\":37779},{\"end\":37803,\"start\":37792},{\"end\":37818,\"start\":37803},{\"end\":37833,\"start\":37818},{\"end\":37849,\"start\":37833},{\"end\":37868,\"start\":37849},{\"end\":38072,\"start\":38059},{\"end\":38086,\"start\":38072},{\"end\":38100,\"start\":38086},{\"end\":38113,\"start\":38100},{\"end\":38131,\"start\":38113},{\"end\":38150,\"start\":38131},{\"end\":38166,\"start\":38150},{\"end\":38213,\"start\":38204},{\"end\":38227,\"start\":38213},{\"end\":38244,\"start\":38227},{\"end\":38255,\"start\":38244},{\"end\":38271,\"start\":38255},{\"end\":38287,\"start\":38271},{\"end\":38305,\"start\":38287},{\"end\":38318,\"start\":38305},{\"end\":38333,\"start\":38318},{\"end\":38587,\"start\":38577},{\"end\":38605,\"start\":38587},{\"end\":38615,\"start\":38605},{\"end\":38741,\"start\":38726},{\"end\":38755,\"start\":38741},{\"end\":38770,\"start\":38755},{\"end\":38780,\"start\":38770},{\"end\":38796,\"start\":38780},{\"end\":38807,\"start\":38796},{\"end\":38825,\"start\":38807},{\"end\":38911,\"start\":38897},{\"end\":38921,\"start\":38911},{\"end\":38928,\"start\":38921},{\"end\":38944,\"start\":38928},{\"end\":38956,\"start\":38944},{\"end\":39072,\"start\":39058},{\"end\":39088,\"start\":39072},{\"end\":39111,\"start\":39088},{\"end\":39126,\"start\":39111},{\"end\":39307,\"start\":39294},{\"end\":39320,\"start\":39307},{\"end\":39336,\"start\":39320},{\"end\":39354,\"start\":39336},{\"end\":39366,\"start\":39354},{\"end\":39378,\"start\":39366},{\"end\":39387,\"start\":39378},{\"end\":39400,\"start\":39387},{\"end\":39561,\"start\":39536},{\"end\":39574,\"start\":39561},{\"end\":39589,\"start\":39574},{\"end\":39596,\"start\":39589},{\"end\":39621,\"start\":39596},{\"end\":39629,\"start\":39621},{\"end\":39734,\"start\":39722},{\"end\":39744,\"start\":39734},{\"end\":39751,\"start\":39744},{\"end\":39820,\"start\":39810},{\"end\":39832,\"start\":39820},{\"end\":39844,\"start\":39832},{\"end\":39855,\"start\":39844},{\"end\":39866,\"start\":39855},{\"end\":39878,\"start\":39866},{\"end\":40045,\"start\":40030},{\"end\":40059,\"start\":40045},{\"end\":40072,\"start\":40059},{\"end\":40134,\"start\":40124},{\"end\":40147,\"start\":40134},{\"end\":40161,\"start\":40147},{\"end\":40172,\"start\":40161},{\"end\":40184,\"start\":40172},{\"end\":40197,\"start\":40184},{\"end\":40207,\"start\":40197},{\"end\":40436,\"start\":40422},{\"end\":40448,\"start\":40436},{\"end\":40461,\"start\":40448},{\"end\":40473,\"start\":40461},{\"end\":40487,\"start\":40473},{\"end\":40503,\"start\":40487},{\"end\":40605,\"start\":40592},{\"end\":40620,\"start\":40605},{\"end\":40634,\"start\":40620},{\"end\":40650,\"start\":40634},{\"end\":40668,\"start\":40650},{\"end\":40683,\"start\":40668},{\"end\":40700,\"start\":40683},{\"end\":40717,\"start\":40700},{\"end\":40728,\"start\":40717},{\"end\":40739,\"start\":40728},{\"end\":40759,\"start\":40739},{\"end\":40770,\"start\":40759},{\"end\":40786,\"start\":40770},{\"end\":40807,\"start\":40786},{\"end\":40826,\"start\":40807},{\"end\":40838,\"start\":40826},{\"end\":40849,\"start\":40838},{\"end\":40858,\"start\":40849},{\"end\":40875,\"start\":40858},{\"end\":40891,\"start\":40875},{\"end\":40903,\"start\":40891},{\"end\":40914,\"start\":40903},{\"end\":40925,\"start\":40914},{\"end\":40938,\"start\":40925},{\"end\":40952,\"start\":40938},{\"end\":40968,\"start\":40952},{\"end\":40982,\"start\":40968},{\"end\":40997,\"start\":40982},{\"end\":41012,\"start\":40997},{\"end\":41032,\"start\":41012},{\"end\":41038,\"start\":41032},{\"end\":41204,\"start\":41189},{\"end\":41218,\"start\":41204},{\"end\":41237,\"start\":41218},{\"end\":41251,\"start\":41237},{\"end\":41264,\"start\":41251},{\"end\":41354,\"start\":41341},{\"end\":41372,\"start\":41354},{\"end\":41386,\"start\":41372},{\"end\":41399,\"start\":41386},{\"end\":41411,\"start\":41399},{\"end\":41428,\"start\":41411},{\"end\":41441,\"start\":41428},{\"end\":41464,\"start\":41441},{\"end\":41542,\"start\":41525},{\"end\":41561,\"start\":41542},{\"end\":41573,\"start\":41561},{\"end\":41587,\"start\":41573},{\"end\":41608,\"start\":41587},{\"end\":41618,\"start\":41608},{\"end\":41632,\"start\":41618},{\"end\":41644,\"start\":41632},{\"end\":41656,\"start\":41644},{\"end\":41666,\"start\":41656},{\"end\":41670,\"start\":41666},{\"end\":41776,\"start\":41754},{\"end\":41792,\"start\":41776},{\"end\":41808,\"start\":41792},{\"end\":41829,\"start\":41808},{\"end\":41847,\"start\":41829},{\"end\":41865,\"start\":41847},{\"end\":41880,\"start\":41865},{\"end\":41892,\"start\":41880},{\"end\":41907,\"start\":41892},{\"end\":41923,\"start\":41907},{\"end\":41941,\"start\":41923},{\"end\":41957,\"start\":41941},{\"end\":41974,\"start\":41957},{\"end\":41982,\"start\":41974},{\"end\":42159,\"start\":42145},{\"end\":42174,\"start\":42159},{\"end\":42190,\"start\":42174},{\"end\":42201,\"start\":42190},{\"end\":42215,\"start\":42201},{\"end\":42232,\"start\":42215},{\"end\":42253,\"start\":42232},{\"end\":42356,\"start\":42345},{\"end\":42371,\"start\":42356},{\"end\":42382,\"start\":42371},{\"end\":42395,\"start\":42382},{\"end\":42410,\"start\":42395},{\"end\":42420,\"start\":42410},{\"end\":42432,\"start\":42420},{\"end\":42436,\"start\":42432},{\"end\":42590,\"start\":42574},{\"end\":42605,\"start\":42590},{\"end\":42622,\"start\":42605},{\"end\":42744,\"start\":42729},{\"end\":42758,\"start\":42744},{\"end\":42772,\"start\":42758},{\"end\":42785,\"start\":42772},{\"end\":42797,\"start\":42785},{\"end\":42948,\"start\":42935},{\"end\":42958,\"start\":42948},{\"end\":42973,\"start\":42958},{\"end\":42988,\"start\":42973},{\"end\":43004,\"start\":42988},{\"end\":43015,\"start\":43004},{\"end\":43029,\"start\":43015},{\"end\":43043,\"start\":43029},{\"end\":43055,\"start\":43043},{\"end\":43115,\"start\":43091},{\"end\":43133,\"start\":43115},{\"end\":43143,\"start\":43133},{\"end\":43155,\"start\":43143},{\"end\":43170,\"start\":43155},{\"end\":43183,\"start\":43170},{\"end\":43204,\"start\":43183},{\"end\":43212,\"start\":43204}]", "bib_venue": "[{\"end\":37586,\"start\":37546},{\"end\":37720,\"start\":37702},{\"end\":37975,\"start\":37868},{\"end\":38057,\"start\":37979},{\"end\":38625,\"start\":38615},{\"end\":38724,\"start\":38674},{\"end\":38895,\"start\":38851},{\"end\":39185,\"start\":39126},{\"end\":39292,\"start\":39242},{\"end\":39649,\"start\":39629},{\"end\":39761,\"start\":39751},{\"end\":39951,\"start\":39894},{\"end\":40075,\"start\":40072},{\"end\":40243,\"start\":40223},{\"end\":40313,\"start\":40265},{\"end\":40365,\"start\":40328},{\"end\":40514,\"start\":40503},{\"end\":41053,\"start\":41038},{\"end\":41319,\"start\":41280},{\"end\":41517,\"start\":41464},{\"end\":41732,\"start\":41686},{\"end\":42050,\"start\":41998},{\"end\":42143,\"start\":42072},{\"end\":42343,\"start\":42289},{\"end\":42625,\"start\":42622},{\"end\":42800,\"start\":42797},{\"end\":42933,\"start\":42849},{\"end\":43278,\"start\":43228}]"}}}, "year": 2023, "month": 12, "day": 17}