{"id": 222304793, "updated": "2022-07-03 15:31:04.418", "metadata": {"title": "Multi-label HD Classification in 3D Flash", "authors": "[{\"first\":\"Justin\",\"last\":\"Morris\",\"middle\":[]},{\"first\":\"Yilun\",\"last\":\"Hao\",\"middle\":[]},{\"first\":\"Saransh\",\"last\":\"Gupta\",\"middle\":[]},{\"first\":\"Ranganathan\",\"last\":\"Ramkumar\",\"middle\":[]},{\"first\":\"Jeffrey\",\"last\":\"Yu\",\"middle\":[]},{\"first\":\"Mohsen\",\"last\":\"Imani\",\"middle\":[]},{\"first\":\"Baris\",\"last\":\"Aksanli\",\"middle\":[]},{\"first\":\"Tajana\",\"last\":\"Rosing\",\"middle\":[]}]", "venue": "2020 IFIP/IEEE 28th International Conference on Very Large Scale Integration (VLSI-SOC)", "journal": "2020 IFIP/IEEE 28th International Conference on Very Large Scale Integration (VLSI-SOC)", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Many classification problems in practice map each sample to more than one label - this is known as multi-label classification. In this work, we present Multi-label HD, an in 3D storage multi-label classification system that uses Hyperdimensional Computing (HD). Multi-label HD is the first HD system to support multi-label classification. We propose two different mappings of HD to Multi-label HD. The first, Power Set HD, transforms the multi-label problem into single-label classification by creating a new class for each label combination. The second, Multi-Model HD, creates a binary classification model for each possible label. Our evaluation shows that Multi-Model HD achieves, on average, $47.8\\times$ higher energy efficiency and $47.1\\times$ faster execution time while achieving 5% higher classification accuracy as state-of-the-art light-weight multi-label classifiers. Power Set HD achieves 13% higher accuracy than Multi-Model HD, but is $2\\times$ slower. Our 3D-flash acceleration further improves the energy efficiency of Multi-label HD training by $228\\times$ and reduces the latency by $610\\times$ vs training on a CPU.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/vlsi/MorrisHGRYIAR20", "doi": "10.1109/vlsi-soc46417.2020.9344070"}}, "content": {"source": {"pdf_hash": "455e8f6d48f5e76bcec1549cd88d0ff0d9357a8d", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "c7782332d52105c10176f9b2625429a8108196ae", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/455e8f6d48f5e76bcec1549cd88d0ff0d9357a8d.txt", "contents": "\nMulti-label HD Classification in 3D Flash\n\n\nJustin Morris \nSan Diego State University\n92182San DiegoCAUSA\n\nYilun Hao \nSaransh Gupta \nRanganathan Ramkumar \nJeffrey Yu \nMohsen Imani m.imani@uci.edu \nUniversity of California Irvine\n92697IrvineCAUSA\n\nBaris Aksanli baksanli@sdsu.edu \nSan Diego State University\n92182San DiegoCAUSA\n\nTajana Rosing tajana@ucsd.edu \n\nUniversity of California San Diego\nLa Jolla92093CAUSA\n\nMulti-label HD Classification in 3D Flash\n10.1109/VLSI-SOC46417.2020.9344070\nMany classification problems in practice map each sample to more than one label -this is known as multilabel classification. In this work, we present Multi-label HD, an in 3D storage multi-label classification system that uses Hyperdimensional Computing (HD). Multi-label HD is the first HD system to support multi-label classification. We propose two different mappings of HD to Multi-label HD. The first, Power Set HD, transforms the multi-label problem into single-label classification by creating a new class for each label combination. The second, Multi-Model HD, creates a binary classification model for each possible label. Our evaluation shows that Multi-Model HD achieves, on average, 47.8\u00d7 higher energy efficiency and 47.1\u00d7 faster execution time while achieving 5% higher classification accuracy as state-of-the-art light-weight multi-label classifiers. Power Set HD achieves 13% higher accuracy than Multi-Model HD, but is 2\u00d7 slower. Our 3D-flash acceleration further improves the energy efficiency of Multi-label HD training by 228\u00d7 and reduces the latency by 610\u00d7 vs training on a CPU.\n\nI. INTRODUCTION\n\nThe emergence of the Internet of Things (IoT) has created an abundance of small embedded devices [1]. Many of these devices perform classification tasks, such as speech recognition, image classification, etc. More and more devices are now required to perform more complex multi-label classification [2], [3]. However, they have very limited resources such as limited battery lifetime and a small amount of memory, which is not enough to train and run Deep Neural Networks (DNN) [4]. We need a light-weight classification algorithm to perform such tasks on embedded systems.\n\nBrain-inspired Hyperdimensional (HD) computing has been proposed as the alternative light-weight computing method to perform cognitive tasks on devices with limited resources [5]. Inspired by the pattern of neural activity in the brain [6], HD computing maps each data point into high dimension vectors, called hypervectors (HVs). HD computing has three main stages, 1) Encoding: mapping data into HVs. 2) Training: combining encoded HVs to create a model representing each class with a HV. 3) Inference: comparing the incoming sample with the trained model to find the most similar class. HD computing shows promising progress for many cognitive tasks such as activity recognition, object recognition, language recognition, and bio-signal classification [7], [8], [9]. However, there has been no work yet on mapping HD computing to multi-label classification tasks.\n\nWhile HD provides improvements in performance and energy consumption over conventional machine learning algorithms, it still involves fetching each and every data from memory/disk and processing it on CPUs/GPUs. This is exaserbated by the fact that HD expands the dimensionality of the input data into high dimensional space. This massive amount of data needed for HD cannot always fit into the memory. Recent work has introduced computing capabilities to solid-state disks (SSDs) to process data in storage [10], [11], [12], [13], [14]. This not only reduces the computation load from the processing cores but also processes raw data where it is stored. HD computing has compelling properties for efficient hardware acceleration in flash. For instance, HD is highly parallelizable with D = 10, 000 dimensions where each dimension is independent. Furthermore, HD is comprised of simple operations such as addition, multiplication, and comparisons. With these two properties, HD computing is a prime candidate for acceleration in flash.\n\nIn this paper, we design a new Multi-label HD computing in storage system. Our system efficiently accelerates the dataintensive steps of HD, encoding and training, in 3D storage, thus, making it possible to run multi-label classification with HD in the IoT domain. We propose two different mappings of HD to multi-label classification, Power Set HD and Multi-Model HD. Power Set HD, transforms the multi-label problem into classical classification by creating a new class for each label combination. Multi-Model HD that creates a binary classification model for each possible label. Our evaluation shows that Multi-Model HD achieves, on average, 47.8\u00d7 higher energy efficiency and 47.1\u00d7 faster execution time while achieving 5% higher classification accuracy as stateof-the-art light-weight multi-label classifiers such as multilabel kNNs. Power Set HD achieves 13% higher accuracy than Multi-Model HD, but is 2\u00d7 slower. Using our in-3Dflash acceleration, we further improve the energy efficiency of Multi-label HD training by 228\u00d7 and reduce the latency by 610\u00d7.\n\n\nII. RELATED WORK A. Hyperdimensional Computing\n\nPrior work tried to apply the idea of high-dimensional computing to different classification problems such as language recognition, speech recognition, face detection, EMG gesture detection, human-computer interaction, and sensor 978-1-7281-5409-1/20/$31.00 \u00a92020 IEEE fusion prediction [7], [15], [16], [17]. Additionally, work in [9] proposed a new HD encoding based on random indexing for recognizing a text's language by generating and comparing text hypervectors. Work in [18] proposed an encoding method to map and classify biosignal sensory data in high dimensional space. Work in [8] proposed a general encoding module that maps feature vectors into high-dimensional space while keeping most of the original data. There is no work to date that handles multi-label classification in HD.\n\n\nB. Multi-label Classification\n\nPrior work applied problem transformation methods to transform multi-label classification problems into multiple single-label classification problems [2], [3]. The most widely used transformation method is PT3. PT3 combines each different set of labels into a single label so that the new label set L is the power set of the old label set L. For a dataset with three binary labels, the new label set would be 000, 001, 010, 011, 100, 101, 110, 111. This causes an exponential increase in the number of labels in the dataset. This transformation method is popular for other light-weight classifiers as their complexities mostly scale with the number of features and not with the number of labels. However, in HD computing, the complexity of inference does scale with the number of labels. Therefore, in this paper we propose a new Multi-Model transformation method that is designed for scalable HD computing.\n\n\nC. Hardware Acceleration\n\nHD Acceleration on other Platforms: Prior work tried to design different hardware accelerators for HD computing. This includes accelerating HD computing on existing FPGA, ASIC, and processing in-memory platforms [19]. However, these solutions do not scale well with the number of classes and dimensions, primarily due to the data movement issue. Therefore, a new solution is needed that can scale with the dimensionality and number of classes. ISC is a promising acceleration architecture in this aspect. Computing in 3D Flash: The current 3D flash-based storage systems suffer from slow flash array read latency and storage to host I/O latency. To alleviate these issues prior work introduced in-storage computing (ISC) architectures [12]. These works exploit the embedded cores present in the SSD controller to implement ISC. Another set of work in [11], [20] used ASIC accelerators in SSDs. The work in [13] proposed a full-stack storage system to reduce the host-side I/O stack latency. While these works propose single-level computing in storage, [14] on the other hand exploited computing at flash die and in top level accelerator to provide multi-layer computing. It also allows for high parallelism in computation. In this work, we adapt the ISC design in [14] to enable multi-label HD in 3D flash.\n\n\nIII. MULTI-LABEL CLASSIFICATION WITH HD\n\nMulti-label classification is the problem of finding a model that maps inputs x to binary vectors y, and each element in y is a label that is assigned a value either 0 or 1. This is in contrast to single-label classification, where y is a single value, not a vector of labels. Although HD computing performs well for single-label classification tasks, we can't directly apply it to solve multi-label classification problems, as only one label output is chosen. Therefore, we transform the multilabel problem into a single-label problem and then modify the HD computing algorithm to solve the multi-label classification problem. We propose two different mappings of HD to Multilabel HD. The first, Power Set HD, transforms the multilabel problem into single-label classification by creating a new class for each observed label combination. We additionally propose Multi-Model HD that creates a binary classification model for each possible label. By doing this, we can leverage the efficiency of HD computing to complete the multi-label classification task faster and with less energy consumption.\n\n\nA. Problem Transformation Methods\n\nPower Set: Prior work [2] mapped multi-label classification to single label classification by creating a new label set that was the power set of the multi-labels. For instance, if a multilabel problem had 3 possible labels for every sample, then prior work would transform the 3 multi-labels into 8 single labels. Where each single label represents each possible combination of the 3 individual labels. This exponential increase in the number of labels does not cause challenges for classifiers that do not scale in complexity with the number of labels. However, HD computing complexity does scale with the number of labels. We address this issue with a binary classification transformation for HD computing explained below.\n\nMulti-Model: We propose Multi-Model HD, a method of building a binary classification model for each label as the problem transformation method. Suppose [l 1 ...l h ] are the labels of the dataset, then after mapping each data point into hypervectors [v 1 ...v n ], we build h binary classification models, since each label only has a true or false value, i.e., 0 or 1. For example, if a dataset has h = 3, we create 3 different HD models, one for each label. Then upon inference, we feed the input data into all 3 of the models, independently checking for the existence of each label. This transformation method is better for HD in multiple ways: 1) HD model size, execution time, and energy scale with the number of classes, so when using Power Set HD, if there is a large number of possible label combinations, Power Set HD will not be as efficient as Multi-Model HD. 2) If a new label is introduced, in Multi-Model HD, we simply need to train a newly added binary classification HD model. However, with Power Set HD, or other models that use the power set transformation method, the entire model needs to be retrained to accommodate the new label combinations. The rest of Section III is mainly focused on Multi-Model HD, while we additionally provide a comparison with Power Set HD in Section V. Now that the problem has been transformed into k binary classification problems, we describe the algorithmic changes to HD computing blow. HD computing encoding maps each n dimensional feature vector to a D dimensional binary hypervector. We utilize a random projection encoding presented in [21]. Let us assume a feature vector\nF = {f 1 , f 2 , . . . , f n }, with n features (f i \u2208 N)\nin original domain. The goal of encoding is to map this feature vector to a D (e.g. D = 10, 000) dimensional space vector:\nH = {h 1 , h 2 , . . . , h D }.\nThe encoding first generates D dense bipolar vectors with the same dimensionality as original domain,\nP = {p 1 , p 2 , . . . , p D }, where p i \u2208 {\u22121, 1} n . Thus,\nto encode a feature vector into a hypervector, we perform a matrix vector multiplication between the projection matrix and the feature vector using:\nH = sign(PF)\n.\n\nWhere sign is a sign function which maps the result of the dot product to +1 or -1. In Section IV-A we discuss how we accelerate encoding in flash.\n\n\nC. Training\n\nIn HD computing, the model used in training is initialized through element-wise addition of all encoded hypervectors in each existing class. The result of training are k hypervectors each with D dimensions, where k is the number of classes. For example, the i th class hypervector can be computed as: C i = \u2200j\u2208classi T j . However, to map this algorithm to Multi-label classification, we need to modify how we create the initial HVs.\n\nAs stated in Section III-A, since the multi-label classification problem is transformed into multiple binary classification problems with Multi-Model HD, we build two classes for each label (one for value 0 and one for value 1). As shown in Figure 1, after the same encoding process as stated in Section III-B, each data point is classified into either Class labeli=0 or Class labeli=1 for each label i according to the values of its labels [l 1 ...l h ]. As shown in Figure 2 \u2022 A , for a dataset that has h labels, the binary model of this dataset Unlike in single label classification, in Multi-Model HD, each data point is element wise added to multiple class HVs. For instance, in Figure 1, after the sample is encoded, it is added to the Class label1=0 class HV for the first label, as the first label is 0. It is then additionally added to the Class label2=0 class HV for the second label, as the second label is 0. This is continued for all the labels until it is added to the Class label h =1 class HV for the last label, as the last label is 1. After this procedure is repeated for the entire training set, we are left with k classification models for each label.\n\nThis training procedure also results in integer values for the dimensions of the class HVs, requiring the use of a costly cosine similarity during inference to find the best matching class HV to the query HV. We can reduce this computation to a binary operation of Hamming distance by binarizing the model, which is done by changing the class hypervector elements to +1 if they are positive and -1 if they are negative or 0. Hamming distance is desirable because it reduces each multiplication and addition in cosine similarity to a simple bitwise XOR and accumulation, which is significantly more efficient in acceleration circuits. The class with the least mismatching bits to the query is then chosen as the output.\n\n\nD. Inference\n\nAfter training, the HD model for single-label classification can now be used for inference. Upon inference, an input data is encoded to a query hypervector using the same encoding module used for training. HD Computing then computes the similarity between the query hypervector and each class hypervector. It then uses consine similarity to find a class hypervector with the most similarity with the query hypervector.\n\nMulti-Model HD performs inference in a similar way, however, we need to output h labels instead of just 1. Figure 2 \u2022 C shows how inference is performed in Muti-Model HD. Upon inference, an input data is encoded to a query hypervector using the same encoding module used for training, just like baseline HD. However, since Multi-Model HD contains h different classification models, the query HV is input into  Fig. 3. Overview of Multi-label HD in 3D flash-based storage. ISC enabling components of the design are shown in green.\n\neach classification model independently. For each model, if the query HV is more similar to the 0 label HV, then that label output is chosen as 0, and vice versa if the query is more similar to the 1 label HV. This generates our h different labels for output in a multi-label classification problem. In Multi-label HD, inference is performed on the host CPU.\n\n\nIV. ACCELERATION WITH 3D NAND FLASH\n\nHere, we present an ISC design that performs Multi-label HD encoding and training completely in 3D flash. Figure 3 shows an overview of the SSD architecture we adopt from THRIFTY [14]. It uses a die-level accelerator (green on the right in Figure 3), in each plane to encode every read page into a hypervector. These hypervectors are then sent to a SSD-level FPGA, which accumulates the hypervectors in the top-level accelerator (green on bottom left in Figure 3) to perform training. The scratchpad (green on top left in Figure  3) in the controller stores the encoding projection matrix, which it receives as an application parameter from the host. The top-level accelerator is an FPGA which uses INSIDER acceleration cluster [13] to implement HDC accumulation and other operations. We utilize THRIFTY's adaptation of INSIDER's software stack to connect our ISC architecture to the rest of the system.\n\n\nA. Encoding in 3D Flash\n\nAs shown in Figure 3, the flash chip may consist of several flash dies which are further divided into flash planes, each plane consisting of a group of blocks, each of which store multiple pages. Each plane has a page buffer to write the data to. Operations in SSD happen in page granularity where the size of the pages usually ranges from 2KB-16KB. Hence, we use accelerators for each flash plane to exploit the flash hierarchy. These accelerators are multiplexed to the page read path.\n\nThe die-accelerator in [14] encodes an entire page with raw data to generate a D dimensional hypervector. We assume that the feature vectors are page-aligned, with each page storing one full feature vector. Multi-label HD encoding multiplies an n-size feature vector with a projection matrix containing D \u00d7 n 1-bit elements. The accelerator calculates the dot product between the two vectors, one read from the flash array and another being a row-vector of the projection matrix. This involves element-wise multiplication of the two vectors and adding together all the elements in the product. Since the weights in the projection matrix \u2208 {1, \u22121}, we map them to {0, 1} respectively. We use 2's complement to break the multiplication into an inversion using XOR gates and then add the total number of inverted inputs to the accumulated sum of XOR outputs. With the assumption that each page consists of a maximum 1K feature elements, the accelerator consists of an array of 32K XOR gates followed by a 1024 input tree adder. It reduces 1024 inputs to 2, which is followed by a carry look ahead addition to get the final dot product. The sign bit (MSB) of the output is the value of one dimension of the encoded hypervector. Complementary to the projection matrix, the output 0 \u2212 \u2192 1 and 1 \u2212 \u2192 (\u22121). The accelerator is iteratively run D times to generate D dimensions. Each encoded hypervector is appended with the corresponding label vector. We write the output of the accelerator to the page buffer of the plane, which serves as the response to the original read request.\n\n\nB. Training at Top-Level in Storage\n\nThe encoded hypervectors from flash chips are input into the top-level accelerator, which is implemented on an FPGA present in the SSD. During training, they are accumulated into the corresponding label hypervectors. At the end of training we obtain two output hypervector for every label (label i ), one each for Class labeli=0 and Class labeli=1 .\n\nThe design in [14] utilized input queues for each class to increase parallelism between different classes. However in Multi-label HD, each encoded hypervector is added to one of the two classes of each label, i.e. 50% of the classes. Moreover, ideally an encoded hypervector has just one label as '1' while rest are '0's. Hence, all but one classes corresponding to label i = 0 would receive an incoming hypervector. There is negligible parallelism in training between multiple encoded hypervectors. In this case, the input queues of [14] are an overkill. Hence, we remove input queues from the FPGA design of [14]. The label vector of an incoming hypervector is used to input it to the corresponding class (Class labeli=0 or Class labeli=1 ) of each label. The inputs to the remaining classes are set to zero. An accumulator is present for each class, which simply needs to read the input and operate on the corresponding data. The accumulators for each class operates in parallel to add an input hypervector to the corresponding class hypervector. While the computation can also be fully parallelized over all dimensions, the large size of hypervectors and the limited read ports of the memory make it impractical. Hence, we utilize the partition-based approach used in [14] to allow partial parallelism. The final class hypervectors are sent to the host.\n\n\nV. EXPERIMENTAL RESULTS\n\n\nA. Experiment Setup\n\nWe tested Multi-label HD training and inference using an optimized C++ implementation. For comparison, we utilized the open source Mulan multi-label package, which is implemented in Java [22]. We compare Multi-label HD with multi-label versions of k-nearest neighbors (kNN), Sequential  minimal optimization (SMO), C4.5, and Naive Bayes (NB). We also developed a simulator for Multi-label HD in flash which supports parallel read and write accesses to the flash chips. We utilized Verilog and Synopsys Design Compiler to implement and synthesize the die-level accelerator at 45nm and scale it down to 22nm. The top-level FPGA accelerator has been synthesized and simulated in Xilinx Vivado. For drive simulation, we assume the characteristics similar to 1TB Intel DC P4500 PCIe-3.1 SSD connected to an Intel(R) Xeon(R) CPU E5-2640 v3 host. The parameters for our 3D flash implementation are shown in Table I. We compare flash implementation with 6th Gen 3.2GHz Sky Lake Intel Core i5-6300HQ CPU with 8GB of RAM and a 256 GB SSD. We tested our proposed approach on three applications: Genbase (Genbase) [23]: the accuracy of the model on each label individually. Then to aggregate them, we average each label's accuracy together to get one overall accuracy number for each dataset. As the figure shows, Multi-label HD (Multi-Model HD and Power Set HD) are comparable in accuracy to state-of-the-art multilabel classifiers. In fact, Power Set HD is always better than the state-of-the-art on these three datasets. On the other hand, Multi-model is slightly less accurate than other multi-label classifiers on the genbase dataset by 10%. However, Multi-Model HD is able to achieve higher accuracy on the scene and yeast datasets. This could be attributed to mapping the data into HD space, offering better separability than in the low dimensional data. However, more theoretical analysis on HD Computing is necessary in order to understand why Multilabel HD is more accurate. Overall, on average, Multi-Model HD is 5% more accurate and Power Set HD is 14% more accurate than the highest accuracy state-of-the-art multi-label classifier.\n\nAlthough Power Set HD achieves higher accuracy than Multi-Model HD, Figure 5, demonstrates that the improvement in accuracy comes at a significant cost in execution time and energy. This is because of the exponential increase in class HVs as discussed in Section III-A. As mentioned before, the exception is the genbase dataset because there is only a small subset of possible combinations that appear in the dataset. On the other hand, when there is a large portion of possible combinations in the dataset, Power Set HD is 3.6\u00d7 slower than Multi-Model HD. This offers a trade-off between execution time and energy efficiency vs accuracy. If an application requires the highest accuracy, Power Set HD should be used. However, if the key metric is execution time and energy efficiency, for a loss in accuracy compared to Power Set HD, but still comparable with other state-of-theart multilabel classifiers, Multi-Model HD is the clear choice.\n\nIf the dataset does not have a diverse combination of labels, such as in genbase, Power Set HD can potentially be more accurate and energy efficient compared to Multi-Model HD.\n\n2) CPU Execution Time and Energy: Figure 5 compares the execution time and energy consumption of state-of-the-art multi-label classifiers with Multi-label HD on CPU. The data demonstrates that both Multi-Model HD and Power Set HD training are significantly faster than most other multi-label classifiers. On average, Multi-label HD is 60.8\u00d7 faster and 61.8\u00d7 more energy efficient than other multilabel classifiers during training. The one exception is Naive Bayes on the yeast dataset, however, although Naive Bayes trains significantly faster than Multi-Model HD on the yeast dataset, Multi-Model HD is 8.6\u00d7 faster and 8.7\u00d7 more energy efficient than Naive Bayes during inference. Additionally, Power Set HD is only 3.5\u00d7 slower than Multi-Model HD on datasets with a large portion of label combinations. Figure 5 also demonstrates that Multi-Model HD is also significantly faster than kNNs and Naive Bayes multi-label models during inference. Although Multi-Model HD is comparable in execution time and energy efficiency to SMO and C4.5 during inference, Multi-Model HD is 174.4\u00d7(42.8\u00d7) faster and 178.1\u00d7(43.1\u00d7) more energy efficient than SMO(C4.5) during training. Overall, combining training and one iteration of inference, Multi-Model HD is 47.1\u00d7 faster and 47.8\u00d7 more energy efficient than state-of-the-art multi-label classifiers on average, while providing 5% higher classification accuracy. On the other hand, Power Set HD is 24\u00d7 faster than state-ofthe-art multi-label classifiers on average or approximately 2\u00d7 slower than Multi-Model HD for 13% higher accuracy. Figure 5 also shows the latency and energy consumption of Multi-label HD when accelerated in flash. We implement Multi-label HD encoding and training in flash over the three datasets. We observe that our 3D-flash implementation of Multi-label HD is on average 610\u00d7 faster and 228\u00d7 more energy-efficient than CPU. Our evaluations show that the performance and energy consumption of Multi-label HD in 3D-flash increases linearly with an increase in the number of training samples. This happens because more data samples result in more huge hypervectors to generate and process. In conventional systems, this translates to a huge amount of data transfers between the core and memory. In contrast, our 3D-flash implementation generates hypervectors (encoding) while reading data out of the slow flash arrays and processes (training) them on the disk itself, reducing data movement.\n\n\nC. Multi-label HD in 3D Flash\n\n\nVI. CONCLUSION\n\nIn this paper, we design the first accelerator for multi-label HD classification in 3D storage. We also propose two different transformation methods to map HD single label classification to multi-label classification: Power Set HD and Multi-Model HD. Overall, combining training and one iteration of inference, Multi-Model HD is 47.1\u00d7 faster and 47.8\u00d7 more energy efficient than state-of-the-art multi-label classifiers, while also achieving 5% higher accuracy on average. Power Set HD can achieve 13% higher accuracy than Multi-Model HD, but is 2\u00d7 slower. We additionally propose in-3D-flash acceleration that further improves the energy efficiency of Muilti-Model HD training by 228\u00d7 and speedup by 610\u00d7.\n\nFig. 1 .\n1An example of how the Multi-Model HD model is created B. Encoding\n\nFig. 2 .\n2Overview of how Multi-Model HD is constructed and how Multi-Model HD performs inference. would contain 2h class HVs in total, one binary classification model for each label where each model contains 2 class HVs.\n\nFig. 4 .\n4Classification accuracy of Multilabel HD and other multi-label classification algorithms.\n\nFig. 5 .\n5The protein classes considered are the 27 most important protein families. The training and testing datasets are taken from the Genbase dataset. This dataset consists of 662 samples, each with 1186 attributes. Scene (Scene) [24]: This dataset contains characteristics about images and their classes. One image can belong to one or more classes. The training and testing datasets are taken from the Scene dataset. This dataset contains 2407 samples, each with 294 attributes. Yeast (Yeast) [25]: This database contains information about a set of Yeast cells. The task is to determine the localization site of each cell. The training and testing datasets are taken from the Yeast dataset. This dataset consists of 2417 samples, each with 103 attributes.B. Multi-label HD Comparison with State-of-the-Art 1) Accuracy:Figure 4compares the multi-label classification accuracy of current state-of-the-art multi-label classifiers with Multi-label HD. The accuracy for multi-label is calculated by first getting Energy consumption and execution time of Multi-label HD during Encoding and Training.\n\nTABLE I\nIMULTI-LABEL HD 3D STORAGE PARAMETERSCapacity \n1T B \nChannels \n32 \nPage Size \n16KB \nChips/Channel \n4 \nExternal BW \n3.2GBps \nPlanes/Chip \n8 \nBW/Channel \n800MBps \nBlocks/Plane \n512 \nFlash Latency \n53us \nPages/Block \n128 \nFPGA \nXCKU025 \nScratchpad Size \n4MB \nAvg Power/DA \n8mW \nDA Latency \n1.02ns \n\n*DA: Die-accelerator \n\n\nACKNOWLEDGEMENTSThis work was supported by NSF grants #1527034, #1730158, #1826967, and #1911095.\nInternet of things (iot): A vision, architectural elements, and future directions. J Gubbi, Future generation computer systems. 297J. Gubbi et al., \"Internet of things (iot): A vision, architectural elements, and future directions,\" Future generation computer systems, vol. 29, no. 7, pp. 1645-1660, 2013.\n\nMulti-label classification: An overview. G Tsoumakas, I Katakis, International Journal of Data Warehousing and Mining (IJDWM). 33G. Tsoumakas and I. Katakis, \"Multi-label classification: An overview,\" Interna- tional Journal of Data Warehousing and Mining (IJDWM), vol. 3, no. 3, pp. 1-13, 2007.\n\nLearning a deep convnet for multi-label classification with partial labels. T Durand, N Mehrasa, G Mori, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionT. Durand, N. Mehrasa, and G. Mori, \"Learning a deep convnet for multi-label classification with partial labels,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 647-657, 2019.\n\nInternet of things and big data analytics for smart and connected communities. Y Sun, IEEE Access. 4Y. Sun et al., \"Internet of things and big data analytics for smart and connected communities,\" IEEE Access, vol. 4, pp. 766-773, 2016.\n\nExploring hyperdimensional associative memory. M Imani, HPCA. IEEEM. Imani et al., \"Exploring hyperdimensional associative memory,\" in HPCA, pp. 445-456, IEEE, 2017.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, Cognitive Computation. 12P. Kanerva, \"Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors,\" Cognitive Com- putation, vol. 1, no. 2, pp. 139-159, 2009.\n\nSequence prediction with sparse distributed hyperdimensional coding applied to the analysis of mobile phone use patterns. O Rasanen, J Saarinen, IEEE Transactions on Neural Networks and Learning Systems. 99O. Rasanen and J. Saarinen, \"Sequence prediction with sparse distributed hyper- dimensional coding applied to the analysis of mobile phone use patterns,\" IEEE Transactions on Neural Networks and Learning Systems, vol. PP, no. 99, pp. 1-12, 2015.\n\nVoicehd: Hyperdimensional computing for efficient speech recognition. M Imani, ICRC. IEEEM. Imani et al., \"Voicehd: Hyperdimensional computing for efficient speech recognition,\" in ICRC, pp. 1-6, IEEE, 2017.\n\nA robust and energy-efficient classifier using brain-inspired hyperdimensional computing. A Rahimi, ISLPED. ACMA. Rahimi et al., \"A robust and energy-efficient classifier using brain-inspired hyperdimensional computing,\" in ISLPED, pp. 64-69, ACM, 2016.\n\nYoursql: a high-performance database system leveraging in-storage computing. I Jo, D.-H Bae, A S Yoon, J.-U Kang, S Cho, D D Lee, J Jeong, Proceedings of the VLDB Endowment. the VLDB Endowment9I. Jo, D.-H. Bae, A. S. Yoon, J.-U. Kang, S. Cho, D. D. Lee, and J. Jeong, \"Yoursql: a high-performance database system leveraging in-storage computing,\" Proceedings of the VLDB Endowment, vol. 9, no. 12, pp. 924-935, 2016.\n\nBiscuit: A framework for near-data processing of big data workloads. B Gu, A S Yoon, D.-H Bae, I Jo, J Lee, J Yoon, J.-U Kang, M Kwon, C Yoon, S Cho, ACM SIGARCH Computer Architecture News. 443B. Gu, A. S. Yoon, D.-H. Bae, I. Jo, J. Lee, J. Yoon, J.-U. Kang, M. Kwon, C. Yoon, S. Cho, et al., \"Biscuit: A framework for near-data processing of big data workloads,\" ACM SIGARCH Computer Architecture News, vol. 44, no. 3, pp. 153-165, 2016.\n\nSummarizer: trading communication with computing near storage. G Koo, K K Matam, I Te, H K G Narra, J Li, H.-W Tseng, S Swanson, M Annavaram, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). IEEEG. Koo, K. K. Matam, I. Te, H. K. G. Narra, J. Li, H.-W. Tseng, S. Swanson, and M. Annavaram, \"Summarizer: trading communication with computing near storage,\" in 2017 50th Annual IEEE/ACM International Symposium on Microar- chitecture (MICRO), pp. 219-231, IEEE, 2017.\n\nInsider: designing in-storage computing system for emerging high-performance drive. Z Ruan, T He, J Cong, Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference. the 2019 USENIX Conference on Usenix Annual Technical ConferenceZ. Ruan, T. He, and J. Cong, \"Insider: designing in-storage computing system for emerging high-performance drive,\" in Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference, pp. 379-394, 2019.\n\nThrifty: Training with hyperdimensional computing across flash hierarchy. S Gupta, J Morris, M Imani, R Ramkumar, J Yu, A Tiwari, B Aksanli, T Rosing, Proceedings of the IEEE/ACM 2020 International Conference on Computer-Aided Design (ICCAD). the IEEE/ACM 2020 International Conference on Computer-Aided Design (ICCAD)2020S. Gupta, J. Morris, M. Imani, R. Ramkumar, J. Yu, A. Tiwari, B. Aksanli, and T. Rosing, \"Thrifty: Training with hyperdimensional computing across flash hierarchy,\" in Proceedings of the IEEE/ACM 2020 International Conference on Computer-Aided Design (ICCAD), 2020.\n\nEfficient human activity recognition using hyperdimensional computing. Y Kim, IoTACM38Y. Kim et al., \"Efficient human activity recognition using hyperdimensional computing,\" in IoT, p. 38, ACM, 2018.\n\nHdcluster: An accurate clustering using brain-inspired highdimensional computing. M Imani, DATE. M. Imani et al., \"Hdcluster: An accurate clustering using brain-inspired high- dimensional computing,\" in DATE, IEEE/ACM, 2019.\n\nHdna: Energy-efficient dna sequencing using hyperdimensional computing. M Imani, IEEE BHI. IEEEM. Imani et al., \"Hdna: Energy-efficient dna sequencing using hyperdimensional computing,\" in IEEE BHI, pp. 271-274, IEEE, 2018.\n\nHyperdimensional biosignal processing: A case study for emgbased hand gesture recognition. A Rahimi, ICRC. IEEEA. Rahimi et al., \"Hyperdimensional biosignal processing: A case study for emg- based hand gesture recognition,\" in ICRC, pp. 1-8, IEEE, 2016.\n\nHardware optimizations of dense binary hyperdimensional computing: Rematerialization of hypervectors, binarized bundling, and combinational associative memory. M Schmuck, L Benini, A Rahimi, ACM Journal on Emerging Technologies in Computing Systems (JETC). 154M. Schmuck, L. Benini, and A. Rahimi, \"Hardware optimizations of dense binary hyperdimensional computing: Rematerialization of hypervectors, binarized bundling, and combinational associative memory,\" ACM Journal on Emerging Technologies in Computing Systems (JETC), vol. 15, no. 4, pp. 1-25, 2019.\n\nDeepstore: In-storage acceleration for intelligent queries. V S Mailthody, Z Qureshi, W Liang, Z Feng, S G De Gonzalo, Y Li, H Franke, J Xiong, J Huang, W.-M Hwu, Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture. the 52nd Annual IEEE/ACM International Symposium on MicroarchitectureV. S. Mailthody, Z. Qureshi, W. Liang, Z. Feng, S. G. De Gonzalo, Y. Li, H. Franke, J. Xiong, J. Huang, and W.-m. Hwu, \"Deepstore: In-storage acceleration for intelligent queries,\" in Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture, pp. 224-238, 2019.\n\nBric: Localitybased encoding for energy-efficient brain-inspired hyperdimensional computing. M Imani, J Morris, J Messerly, H Shu, Y Deng, T Rosing, Proceedings of the 56th Annual Design Automation Conference. the 56th Annual Design Automation ConferenceM. Imani, J. Morris, J. Messerly, H. Shu, Y. Deng, and T. Rosing, \"Bric: Locality- based encoding for energy-efficient brain-inspired hyperdimensional computing,\" in Proceedings of the 56th Annual Design Automation Conference 2019, pp. 1-6, 2019.\n\nMulan: A java library for multi-label learning. G Tsoumakas, E Spyromitros-Xioufis, J Vilcek, I Vlahavas, Journal of Machine Learning Research. 12G. Tsoumakas, E. Spyromitros-Xioufis, J. Vilcek, and I. Vlahavas, \"Mulan: A java library for multi-label learning,\" Journal of Machine Learning Research, vol. 12, pp. 2411-2414, 2011.\n\nProtein classification with multiple algorithms. S Diplaris, G Tsoumakas, P A Mitkas, I Vlahavas, Panhellenic Conference on Informatics. SpringerS. Diplaris, G. Tsoumakas, P. A. Mitkas, and I. Vlahavas, \"Protein classification with multiple algorithms,\" in Panhellenic Conference on Informatics, pp. 448-456, Springer, 2005.\n\nLearning multi-label scene classification. M R Boutell, J Luo, X Shen, C M Brown, Pattern recognition. 379M. R. Boutell, J. Luo, X. Shen, and C. M. Brown, \"Learning multi-label scene classification,\" Pattern recognition, vol. 37, no. 9, pp. 1757-1771, 2004.\n\nA kernel method for multi-labelled classification. A Elisseeff, J Weston, Advances in neural information processing systems. A. Elisseeff and J. Weston, \"A kernel method for multi-labelled classification,\" in Advances in neural information processing systems, pp. 681-687, 2002.\n", "annotations": {"author": "[{\"end\":107,\"start\":45},{\"end\":118,\"start\":108},{\"end\":133,\"start\":119},{\"end\":155,\"start\":134},{\"end\":167,\"start\":156},{\"end\":247,\"start\":168},{\"end\":328,\"start\":248},{\"end\":359,\"start\":329},{\"end\":415,\"start\":360}]", "publisher": null, "author_last_name": "[{\"end\":58,\"start\":52},{\"end\":117,\"start\":114},{\"end\":132,\"start\":127},{\"end\":154,\"start\":146},{\"end\":166,\"start\":164},{\"end\":180,\"start\":175},{\"end\":261,\"start\":254},{\"end\":342,\"start\":336}]", "author_first_name": "[{\"end\":51,\"start\":45},{\"end\":113,\"start\":108},{\"end\":126,\"start\":119},{\"end\":145,\"start\":134},{\"end\":163,\"start\":156},{\"end\":174,\"start\":168},{\"end\":253,\"start\":248},{\"end\":335,\"start\":329}]", "author_affiliation": "[{\"end\":106,\"start\":60},{\"end\":246,\"start\":198},{\"end\":327,\"start\":281},{\"end\":414,\"start\":361}]", "title": "[{\"end\":42,\"start\":1},{\"end\":457,\"start\":416}]", "venue": null, "abstract": "[{\"end\":1593,\"start\":493}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1712,\"start\":1709},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1914,\"start\":1911},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1919,\"start\":1916},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2093,\"start\":2090},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2365,\"start\":2362},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2426,\"start\":2423},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2945,\"start\":2942},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2950,\"start\":2947},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2955,\"start\":2952},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3567,\"start\":3563},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3573,\"start\":3569},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3579,\"start\":3575},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3585,\"start\":3581},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3591,\"start\":3587},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5496,\"start\":5493},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5502,\"start\":5498},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":5508,\"start\":5504},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5514,\"start\":5510},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5541,\"start\":5538},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5687,\"start\":5683},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5797,\"start\":5794},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6186,\"start\":6183},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6191,\"start\":6188},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7185,\"start\":7181},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7708,\"start\":7704},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7824,\"start\":7820},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7830,\"start\":7826},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7879,\"start\":7875},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8025,\"start\":8021},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8237,\"start\":8233},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9478,\"start\":9475},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11775,\"start\":11771},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16389,\"start\":16385},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":16938,\"start\":16934},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":17653,\"start\":17649},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":19607,\"start\":19603},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20127,\"start\":20123},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20203,\"start\":20199},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20865,\"start\":20861},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21187,\"start\":21183},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":22102,\"start\":22098}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":27536,\"start\":27460},{\"attributes\":{\"id\":\"fig_1\"},\"end\":27759,\"start\":27537},{\"attributes\":{\"id\":\"fig_2\"},\"end\":27860,\"start\":27760},{\"attributes\":{\"id\":\"fig_3\"},\"end\":28961,\"start\":27861},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":29290,\"start\":28962}]", "paragraph": "[{\"end\":2185,\"start\":1612},{\"end\":3053,\"start\":2187},{\"end\":4090,\"start\":3055},{\"end\":5155,\"start\":4092},{\"end\":5999,\"start\":5206},{\"end\":6940,\"start\":6033},{\"end\":8275,\"start\":6969},{\"end\":9415,\"start\":8319},{\"end\":10177,\"start\":9453},{\"end\":11807,\"start\":10179},{\"end\":11988,\"start\":11866},{\"end\":12122,\"start\":12021},{\"end\":12333,\"start\":12185},{\"end\":12348,\"start\":12347},{\"end\":12497,\"start\":12350},{\"end\":12946,\"start\":12513},{\"end\":14120,\"start\":12948},{\"end\":14840,\"start\":14122},{\"end\":15275,\"start\":14857},{\"end\":15806,\"start\":15277},{\"end\":16166,\"start\":15808},{\"end\":17109,\"start\":16206},{\"end\":17624,\"start\":17137},{\"end\":19198,\"start\":17626},{\"end\":19587,\"start\":19238},{\"end\":20946,\"start\":19589},{\"end\":23129,\"start\":20996},{\"end\":24072,\"start\":23131},{\"end\":24250,\"start\":24074},{\"end\":26702,\"start\":24252},{\"end\":27459,\"start\":26753}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11865,\"start\":11808},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12020,\"start\":11989},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12184,\"start\":12123},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12346,\"start\":12334}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21903,\"start\":21896}]", "section_header": "[{\"end\":1610,\"start\":1595},{\"end\":5204,\"start\":5158},{\"end\":6031,\"start\":6002},{\"end\":6967,\"start\":6943},{\"end\":8317,\"start\":8278},{\"end\":9451,\"start\":9418},{\"end\":12511,\"start\":12500},{\"end\":14855,\"start\":14843},{\"end\":16204,\"start\":16169},{\"end\":17135,\"start\":17112},{\"end\":19236,\"start\":19201},{\"end\":20972,\"start\":20949},{\"end\":20994,\"start\":20975},{\"end\":26734,\"start\":26705},{\"end\":26751,\"start\":26737},{\"end\":27469,\"start\":27461},{\"end\":27546,\"start\":27538},{\"end\":27769,\"start\":27761},{\"end\":27870,\"start\":27862},{\"end\":28970,\"start\":28963}]", "table": "[{\"end\":29290,\"start\":29008}]", "figure_caption": "[{\"end\":27536,\"start\":27471},{\"end\":27759,\"start\":27548},{\"end\":27860,\"start\":27771},{\"end\":28961,\"start\":27872},{\"end\":29008,\"start\":28972}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13197,\"start\":13189},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":13424,\"start\":13416},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13641,\"start\":13633},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15392,\"start\":15384},{\"end\":15693,\"start\":15687},{\"end\":16320,\"start\":16312},{\"end\":16454,\"start\":16446},{\"end\":16668,\"start\":16660},{\"end\":16737,\"start\":16728},{\"end\":17157,\"start\":17149},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23207,\"start\":23199},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":24294,\"start\":24286},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":25065,\"start\":25057},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":25833,\"start\":25825}]", "bib_author_first_name": "[{\"end\":29473,\"start\":29472},{\"end\":29738,\"start\":29737},{\"end\":29751,\"start\":29750},{\"end\":30070,\"start\":30069},{\"end\":30080,\"start\":30079},{\"end\":30091,\"start\":30090},{\"end\":30535,\"start\":30534},{\"end\":30740,\"start\":30739},{\"end\":30985,\"start\":30984},{\"end\":31342,\"start\":31341},{\"end\":31353,\"start\":31352},{\"end\":31743,\"start\":31742},{\"end\":31972,\"start\":31971},{\"end\":32214,\"start\":32213},{\"end\":32223,\"start\":32219},{\"end\":32230,\"start\":32229},{\"end\":32232,\"start\":32231},{\"end\":32243,\"start\":32239},{\"end\":32251,\"start\":32250},{\"end\":32258,\"start\":32257},{\"end\":32260,\"start\":32259},{\"end\":32267,\"start\":32266},{\"end\":32624,\"start\":32623},{\"end\":32630,\"start\":32629},{\"end\":32632,\"start\":32631},{\"end\":32643,\"start\":32639},{\"end\":32650,\"start\":32649},{\"end\":32656,\"start\":32655},{\"end\":32663,\"start\":32662},{\"end\":32674,\"start\":32670},{\"end\":32682,\"start\":32681},{\"end\":32690,\"start\":32689},{\"end\":32698,\"start\":32697},{\"end\":33058,\"start\":33057},{\"end\":33065,\"start\":33064},{\"end\":33067,\"start\":33066},{\"end\":33076,\"start\":33075},{\"end\":33082,\"start\":33081},{\"end\":33086,\"start\":33083},{\"end\":33095,\"start\":33094},{\"end\":33104,\"start\":33100},{\"end\":33113,\"start\":33112},{\"end\":33124,\"start\":33123},{\"end\":33575,\"start\":33574},{\"end\":33583,\"start\":33582},{\"end\":33589,\"start\":33588},{\"end\":34035,\"start\":34034},{\"end\":34044,\"start\":34043},{\"end\":34054,\"start\":34053},{\"end\":34063,\"start\":34062},{\"end\":34075,\"start\":34074},{\"end\":34081,\"start\":34080},{\"end\":34091,\"start\":34090},{\"end\":34102,\"start\":34101},{\"end\":34621,\"start\":34620},{\"end\":34833,\"start\":34832},{\"end\":35049,\"start\":35048},{\"end\":35293,\"start\":35292},{\"end\":35617,\"start\":35616},{\"end\":35628,\"start\":35627},{\"end\":35638,\"start\":35637},{\"end\":36076,\"start\":36075},{\"end\":36078,\"start\":36077},{\"end\":36091,\"start\":36090},{\"end\":36102,\"start\":36101},{\"end\":36111,\"start\":36110},{\"end\":36119,\"start\":36118},{\"end\":36121,\"start\":36120},{\"end\":36135,\"start\":36134},{\"end\":36141,\"start\":36140},{\"end\":36151,\"start\":36150},{\"end\":36160,\"start\":36159},{\"end\":36172,\"start\":36168},{\"end\":36717,\"start\":36716},{\"end\":36726,\"start\":36725},{\"end\":36736,\"start\":36735},{\"end\":36748,\"start\":36747},{\"end\":36755,\"start\":36754},{\"end\":36763,\"start\":36762},{\"end\":37174,\"start\":37173},{\"end\":37187,\"start\":37186},{\"end\":37210,\"start\":37209},{\"end\":37220,\"start\":37219},{\"end\":37506,\"start\":37505},{\"end\":37518,\"start\":37517},{\"end\":37531,\"start\":37530},{\"end\":37533,\"start\":37532},{\"end\":37543,\"start\":37542},{\"end\":37826,\"start\":37825},{\"end\":37828,\"start\":37827},{\"end\":37839,\"start\":37838},{\"end\":37846,\"start\":37845},{\"end\":37854,\"start\":37853},{\"end\":37856,\"start\":37855},{\"end\":38093,\"start\":38092},{\"end\":38106,\"start\":38105}]", "bib_author_last_name": "[{\"end\":29479,\"start\":29474},{\"end\":29748,\"start\":29739},{\"end\":29759,\"start\":29752},{\"end\":30077,\"start\":30071},{\"end\":30088,\"start\":30081},{\"end\":30096,\"start\":30092},{\"end\":30539,\"start\":30536},{\"end\":30746,\"start\":30741},{\"end\":30993,\"start\":30986},{\"end\":31350,\"start\":31343},{\"end\":31362,\"start\":31354},{\"end\":31749,\"start\":31744},{\"end\":31979,\"start\":31973},{\"end\":32217,\"start\":32215},{\"end\":32227,\"start\":32224},{\"end\":32237,\"start\":32233},{\"end\":32248,\"start\":32244},{\"end\":32255,\"start\":32252},{\"end\":32264,\"start\":32261},{\"end\":32273,\"start\":32268},{\"end\":32627,\"start\":32625},{\"end\":32637,\"start\":32633},{\"end\":32647,\"start\":32644},{\"end\":32653,\"start\":32651},{\"end\":32660,\"start\":32657},{\"end\":32668,\"start\":32664},{\"end\":32679,\"start\":32675},{\"end\":32687,\"start\":32683},{\"end\":32695,\"start\":32691},{\"end\":32702,\"start\":32699},{\"end\":33062,\"start\":33059},{\"end\":33073,\"start\":33068},{\"end\":33079,\"start\":33077},{\"end\":33092,\"start\":33087},{\"end\":33098,\"start\":33096},{\"end\":33110,\"start\":33105},{\"end\":33121,\"start\":33114},{\"end\":33134,\"start\":33125},{\"end\":33580,\"start\":33576},{\"end\":33586,\"start\":33584},{\"end\":33594,\"start\":33590},{\"end\":34041,\"start\":34036},{\"end\":34051,\"start\":34045},{\"end\":34060,\"start\":34055},{\"end\":34072,\"start\":34064},{\"end\":34078,\"start\":34076},{\"end\":34088,\"start\":34082},{\"end\":34099,\"start\":34092},{\"end\":34109,\"start\":34103},{\"end\":34625,\"start\":34622},{\"end\":34839,\"start\":34834},{\"end\":35055,\"start\":35050},{\"end\":35300,\"start\":35294},{\"end\":35625,\"start\":35618},{\"end\":35635,\"start\":35629},{\"end\":35645,\"start\":35639},{\"end\":36088,\"start\":36079},{\"end\":36099,\"start\":36092},{\"end\":36108,\"start\":36103},{\"end\":36116,\"start\":36112},{\"end\":36132,\"start\":36122},{\"end\":36138,\"start\":36136},{\"end\":36148,\"start\":36142},{\"end\":36157,\"start\":36152},{\"end\":36166,\"start\":36161},{\"end\":36176,\"start\":36173},{\"end\":36723,\"start\":36718},{\"end\":36733,\"start\":36727},{\"end\":36745,\"start\":36737},{\"end\":36752,\"start\":36749},{\"end\":36760,\"start\":36756},{\"end\":36770,\"start\":36764},{\"end\":37184,\"start\":37175},{\"end\":37207,\"start\":37188},{\"end\":37217,\"start\":37211},{\"end\":37229,\"start\":37221},{\"end\":37515,\"start\":37507},{\"end\":37528,\"start\":37519},{\"end\":37540,\"start\":37534},{\"end\":37552,\"start\":37544},{\"end\":37836,\"start\":37829},{\"end\":37843,\"start\":37840},{\"end\":37851,\"start\":37847},{\"end\":37862,\"start\":37857},{\"end\":38103,\"start\":38094},{\"end\":38113,\"start\":38107}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":204982032},\"end\":29694,\"start\":29389},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":11608263},\"end\":29991,\"start\":29696},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":67856781},\"end\":30453,\"start\":29993},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":10167346},\"end\":30690,\"start\":30455},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":1677864},\"end\":30857,\"start\":30692},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":733980},\"end\":31217,\"start\":30859},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":15258913},\"end\":31670,\"start\":31219},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":21351739},\"end\":31879,\"start\":31672},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":9812826},\"end\":32134,\"start\":31881},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":18204650},\"end\":32552,\"start\":32136},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":14108659},\"end\":32992,\"start\":32554},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":21502412},\"end\":33488,\"start\":32994},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":196810101},\"end\":33958,\"start\":33490},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":227069231},\"end\":34547,\"start\":33960},{\"attributes\":{\"id\":\"b14\"},\"end\":34748,\"start\":34549},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":155106744},\"end\":34974,\"start\":34750},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":4708051},\"end\":35199,\"start\":34976},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":12008695},\"end\":35454,\"start\":35201},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":49907924},\"end\":36013,\"start\":35456},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":202758896},\"end\":36621,\"start\":36015},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":163164623},\"end\":37123,\"start\":36623},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":16185365},\"end\":37454,\"start\":37125},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":17837222},\"end\":37780,\"start\":37456},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":9404152},\"end\":38039,\"start\":37782},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":1976599},\"end\":38319,\"start\":38041}]", "bib_title": "[{\"end\":29470,\"start\":29389},{\"end\":29735,\"start\":29696},{\"end\":30067,\"start\":29993},{\"end\":30532,\"start\":30455},{\"end\":30737,\"start\":30692},{\"end\":30982,\"start\":30859},{\"end\":31339,\"start\":31219},{\"end\":31740,\"start\":31672},{\"end\":31969,\"start\":31881},{\"end\":32211,\"start\":32136},{\"end\":32621,\"start\":32554},{\"end\":33055,\"start\":32994},{\"end\":33572,\"start\":33490},{\"end\":34032,\"start\":33960},{\"end\":34830,\"start\":34750},{\"end\":35046,\"start\":34976},{\"end\":35290,\"start\":35201},{\"end\":35614,\"start\":35456},{\"end\":36073,\"start\":36015},{\"end\":36714,\"start\":36623},{\"end\":37171,\"start\":37125},{\"end\":37503,\"start\":37456},{\"end\":37823,\"start\":37782},{\"end\":38090,\"start\":38041}]", "bib_author": "[{\"end\":29481,\"start\":29472},{\"end\":29750,\"start\":29737},{\"end\":29761,\"start\":29750},{\"end\":30079,\"start\":30069},{\"end\":30090,\"start\":30079},{\"end\":30098,\"start\":30090},{\"end\":30541,\"start\":30534},{\"end\":30748,\"start\":30739},{\"end\":30995,\"start\":30984},{\"end\":31352,\"start\":31341},{\"end\":31364,\"start\":31352},{\"end\":31751,\"start\":31742},{\"end\":31981,\"start\":31971},{\"end\":32219,\"start\":32213},{\"end\":32229,\"start\":32219},{\"end\":32239,\"start\":32229},{\"end\":32250,\"start\":32239},{\"end\":32257,\"start\":32250},{\"end\":32266,\"start\":32257},{\"end\":32275,\"start\":32266},{\"end\":32629,\"start\":32623},{\"end\":32639,\"start\":32629},{\"end\":32649,\"start\":32639},{\"end\":32655,\"start\":32649},{\"end\":32662,\"start\":32655},{\"end\":32670,\"start\":32662},{\"end\":32681,\"start\":32670},{\"end\":32689,\"start\":32681},{\"end\":32697,\"start\":32689},{\"end\":32704,\"start\":32697},{\"end\":33064,\"start\":33057},{\"end\":33075,\"start\":33064},{\"end\":33081,\"start\":33075},{\"end\":33094,\"start\":33081},{\"end\":33100,\"start\":33094},{\"end\":33112,\"start\":33100},{\"end\":33123,\"start\":33112},{\"end\":33136,\"start\":33123},{\"end\":33582,\"start\":33574},{\"end\":33588,\"start\":33582},{\"end\":33596,\"start\":33588},{\"end\":34043,\"start\":34034},{\"end\":34053,\"start\":34043},{\"end\":34062,\"start\":34053},{\"end\":34074,\"start\":34062},{\"end\":34080,\"start\":34074},{\"end\":34090,\"start\":34080},{\"end\":34101,\"start\":34090},{\"end\":34111,\"start\":34101},{\"end\":34627,\"start\":34620},{\"end\":34841,\"start\":34832},{\"end\":35057,\"start\":35048},{\"end\":35302,\"start\":35292},{\"end\":35627,\"start\":35616},{\"end\":35637,\"start\":35627},{\"end\":35647,\"start\":35637},{\"end\":36090,\"start\":36075},{\"end\":36101,\"start\":36090},{\"end\":36110,\"start\":36101},{\"end\":36118,\"start\":36110},{\"end\":36134,\"start\":36118},{\"end\":36140,\"start\":36134},{\"end\":36150,\"start\":36140},{\"end\":36159,\"start\":36150},{\"end\":36168,\"start\":36159},{\"end\":36178,\"start\":36168},{\"end\":36725,\"start\":36716},{\"end\":36735,\"start\":36725},{\"end\":36747,\"start\":36735},{\"end\":36754,\"start\":36747},{\"end\":36762,\"start\":36754},{\"end\":36772,\"start\":36762},{\"end\":37186,\"start\":37173},{\"end\":37209,\"start\":37186},{\"end\":37219,\"start\":37209},{\"end\":37231,\"start\":37219},{\"end\":37517,\"start\":37505},{\"end\":37530,\"start\":37517},{\"end\":37542,\"start\":37530},{\"end\":37554,\"start\":37542},{\"end\":37838,\"start\":37825},{\"end\":37845,\"start\":37838},{\"end\":37853,\"start\":37845},{\"end\":37864,\"start\":37853},{\"end\":38105,\"start\":38092},{\"end\":38115,\"start\":38105}]", "bib_venue": "[{\"end\":30239,\"start\":30177},{\"end\":32328,\"start\":32310},{\"end\":33741,\"start\":33677},{\"end\":34278,\"start\":34203},{\"end\":36333,\"start\":36264},{\"end\":36877,\"start\":36833},{\"end\":29515,\"start\":29481},{\"end\":29821,\"start\":29761},{\"end\":30175,\"start\":30098},{\"end\":30552,\"start\":30541},{\"end\":30752,\"start\":30748},{\"end\":31016,\"start\":30995},{\"end\":31421,\"start\":31364},{\"end\":31755,\"start\":31751},{\"end\":31987,\"start\":31981},{\"end\":32308,\"start\":32275},{\"end\":32742,\"start\":32704},{\"end\":33214,\"start\":33136},{\"end\":33675,\"start\":33596},{\"end\":34201,\"start\":34111},{\"end\":34618,\"start\":34549},{\"end\":34845,\"start\":34841},{\"end\":35065,\"start\":35057},{\"end\":35306,\"start\":35302},{\"end\":35711,\"start\":35647},{\"end\":36262,\"start\":36178},{\"end\":36831,\"start\":36772},{\"end\":37267,\"start\":37231},{\"end\":37591,\"start\":37554},{\"end\":37883,\"start\":37864},{\"end\":38164,\"start\":38115}]"}}}, "year": 2023, "month": 12, "day": 17}