{"id": 44129061, "updated": "2023-09-30 21:14:39.193", "metadata": {"title": "Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting", "authors": "[{\"first\":\"Yen-Chun\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Mohit\",\"last\":\"Bansal\",\"middle\":[]}]", "venue": "ACL", "journal": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "Inspired by how humans summarize long documents, we propose an accurate and fast summarization model that first selects salient sentences and then rewrites them abstractively (i.e., compresses and paraphrases) to generate a concise overall summary. We use a novel sentence-level policy gradient method to bridge the non-differentiable computation between these two neural networks in a hierarchical way, while maintaining language fluency. Empirically, we achieve the new state-of-the-art on all metrics (including human evaluation) on the CNN/Daily Mail dataset, as well as significantly higher abstractiveness scores. Moreover, by first operating at the sentence-level and then the word-level, we enable parallel decoding of our neural generative model that results in substantially faster (10-20x) inference speed as well as 4x faster training convergence than previous long-paragraph encoder-decoder models. We also demonstrate the generalization of our model on the test-only DUC-2002 dataset, where we achieve higher scores than a state-of-the-art model.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1805.11080", "mag": "2962985882", "acl": "P18-1063", "pubmed": null, "pubmedcentral": null, "dblp": "conf/acl/BansalC18", "doi": "10.18653/v1/p18-1063"}}, "content": {"source": {"pdf_hash": "e08072566bd415b43cf5f5abc7569179d6a20813", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1805.11080v1.pdf\"]", "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/P18-1063.pdf", "status": "HYBRID"}}, "grobid": {"id": "cc71bbe319a87cc87e7e51e72e0f09d5a53d260a", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/e08072566bd415b43cf5f5abc7569179d6a20813.txt", "contents": "\nFast Abstractive Summarization with Reinforce-Selected Sentence Rewriting\n\n\nYen-Chun Chen \nUNC Chapel Hill\n\n\nMohit Bansal mbansal@cs.unc.edu \nUNC Chapel Hill\n\n\nFast Abstractive Summarization with Reinforce-Selected Sentence Rewriting\n\nInspired by how humans summarize long documents, we propose an accurate and fast summarization model that first selects salient sentences and then rewrites them abstractively (i.e., compresses and paraphrases) to generate a concise overall summary. We use a novel sentence-level policy gradient method to bridge the nondifferentiable computation between these two neural networks in a hierarchical way, while maintaining language fluency. Empirically, we achieve the new state-of-theart on all metrics (including human evaluation) on the CNN/Daily Mail dataset, as well as significantly higher abstractiveness scores. Moreover, by first operating at the sentence-level and then the word-level, we enable parallel decoding of our neural generative model that results in substantially faster (10-20x) inference speed as well as 4x faster training convergence than previous long-paragraph encoder-decoder models. We also demonstrate the generalization of our model on the test-only DUC-2002 dataset, where we achieve higher scores than a state-of-the-art model.\n\nIntroduction\n\nThe task of document summarization has two main paradigms: extractive and abstractive. The former method directly chooses and outputs the salient sentences (or phrases) in the original document (Jing and McKeown, 2000;Knight and Marcu, 2000;Martins and Smith, 2009;Berg-Kirkpatrick et al., 2011). The latter abstractive approach involves rewriting the summary (Banko et al., 2000;Zajic et al., 2004), and has seen substantial recent gains due to neural sequence-to-sequence models Nallapati et al., 2016;See et al., 2017;Paulus et al., 2018). Abstractive models can be more concise by performing generation from scratch, but they suffer from slow and inaccurate encoding of very long documents, with the attention model being required to look at all encoded words (in long paragraphs) for decoding each generated summary word (slow, one by one sequentially). Abstractive models also suffer from redundancy (repetitions), especially when generating multi-sentence summary.\n\nTo address both these issues and combine the advantages of both paradigms, we propose a hybrid extractive-abstractive architecture, with policy-based reinforcement learning (RL) to bridge together the two networks. Similar to how humans summarize long documents, our model first uses an extractor agent to select salient sentences or highlights, and then employs an abstractor network to rewrite (i.e., compress and paraphrase) each of these extracted sentences. To overcome the non-differentiable behavior of our extractor and train on available document-summary pairs without saliency label, we next use actorcritic policy gradient with sentence-level metric rewards to connect these two neural networks and to learn sentence saliency. We also avoid common language fluency issues (Paulus et al., 2018) by preventing the policy gradients from affecting the abstractive summarizer's word-level training, which is supported by our human evaluation study. Our sentence-level reinforcement learning takes into account the word-sentence hierarchy, which better models the language structure and makes parallelization possible. Our extractor combines reinforcement learning and pointer networks, which is inspired by Bello et al. (2017)'s attempt to solve the Traveling Salesman Problem. Our abstractor is a simple encoder-aligner-decoder model (with copying) and is trained on pseudo document-summary sentence pairs obtained via simple automatic matching criteria.\n\nThus, our method incorporates the abstractive paradigm's advantages of concisely rewriting sentences and generating novel words from the full vocabulary, yet it adopts intermediate extractive behavior to improve the overall model's quality, speed, and stability. Instead of encoding and attending to every word in the long input document sequentially, our model adopts a human-inspired coarse-to-fine approach that first extracts all the salient sentences and then decodes (rewrites) them (in parallel). This also avoids almost all redundancy issues because the model has already chosen non-redundant salient sentences to abstractively summarize (but adding an optional final reranker component does give additional gains by removing the fewer across-sentence repetitions).\n\nEmpirically, our approach is the new state-ofthe-art on all ROUGE metrics (Lin, 2004) as well as on METEOR (Denkowski and Lavie, 2014) of the CNN/Daily Mail dataset, achieving statistically significant improvements over previous models that use complex long-encoder, copy, and coverage mechanisms (See et al., 2017). The test-only DUC-2002 improvement also shows our model's better generalization than this strong abstractive system. In addition, we surpass the popular lead-3 baseline on all ROUGE scores with an abstractive model. Moreover, our sentence-level abstractive rewriting module also produces substantially more (3x) novel N -grams that are not seen in the input document, as compared to the strong flat-structured model of See et al. (2017). This empirically justifies that our RL-guided extractor has learned sentence saliency, rather than benefiting from simply copying longer sentences. We also show that our model maintains the same level of fluency as a conventional RNN-based model because the reward does not leak to our abstractor's word-level training. Finally, our model's training is 4x and inference is more than 20x faster than the previous state-of-the-art. The optional final reranker gives further improvements while maintaining a 7x speedup.\n\nOverall, our contribution is three fold: First we propose a novel sentence-level RL technique for the well-known task of abstractive summarization, effectively utilizing the word-then-sentence hierarchical structure without annotated matching sentence-pairs between the document and ground truth summary. Next, our model achieves the new state-of-the-art on all metrics of multiple versions of a popular summarization dataset (as well as a test-only dataset) both extractively and abstractively, without loss in language fluency (also demonstrated via human evaluation and abstractiveness scores). Finally, our parallel decoding results in a significant 10-20x speed-up over the previous best neural abstractive summarization system with even better accuracy. 1\n\n\nModel\n\nIn this work, we consider the task of summarizing a given long text document into several (ordered) highlights, which are then combined to form a multi-sentence summary. Formally, given a training set of document-summary pairs\n{x i , y i } N i=1 , our goal is to approximate the func- tion h : X \u2192 Y, X = {x i } N i=1 , Y = {y i } N i=1 such that h(x i ) = y i , 1 \u2264 i \u2264 N .\nFurthermore, we assume there exists an abstracting function g defined as:\n\u2200s \u2208 S i , \u2203d \u2208 D i such that g(d) = s, 1 \u2264 i \u2264 N ,\nwhere S i is the set of summary sentences in x i and D i the set of document sentences in y i . i.e., in any given pair of document and summary, every summary sentence can be produced from some document sentence. For simplicity, we omit subscript i in the remainder of the paper. Under this assumption, we can further define another latent function f : X \u2192 D n that satisfies f (x) = {d t } n j=1 and y = h(x) = [g(d 1 ), g(d 2 ), . . . , g(d n )], where [, ] denotes sentence concatenation. This latent function f can be seen as an extractor that chooses the salient (ordered) sentences in a given document for the abstracting function g to rewrite. Our overall model consists of these two submodules, the extractor agent and the abstractor network, to approximate the above-mentioned f and g, respectively.\n\n\nExtractor Agent\n\nThe extractor agent is designed to model f , which can be thought of as extracting salient sentences from the document. We exploit a hierarchical neural model to learn the sentence representations of the document and a 'selection network' to extract sentences based on their representations. \nr 1 r 2 r 3 r 4 h 0 h 1 h 4 r 1 r 2 r 3 r 4 h 0 h 1 h 4 r 1 r 2 r 3 r 4 h 0 h 1 h 4 r 1 r 2 r 3 r 4 h 0 h 1 h 4 LSTM LSTM LSTM Extraction Probabilities (Policy) r 1 r 2 r 3 r 4 h 0 h 1 h 4 r 1 r 2 r 3 r 4 h 0 h 1 h 4 r 1 r 2 r 3 r 4 h 0 h 1 h 4\nContext-aware Sent. Reps. (from previous extraction step) CONV Embedded Word Vectors Convolutional Sentence Encoder Figure 1: Our extractor agent: the convolutional encoder computes representation r j for each sentence. The RNN encoder (blue) computes context-aware representation h j and then the RNN decoder (green) selects sentence j t at time step t. With j t selected, h jt will be fed into the decoder at time t + 1.\n\n\nHierarchical Sentence Representation\n\nWe use a temporal convolutional model (Kim, 2014) to compute r j , the representation of each individual sentence in the documents (details in supplementary). To further incorporate global context of the document and capture the long-range semantic dependency between sentences, a bidirectional LSTM- RNN (Hochreiter and Schmidhuber, 1997;Schuster et al., 1997) is applied on the convolutional output. This enables learning a strong representation, denoted as h j for the j-th sentence in the document, that takes into account the context of all previous and future sentences in the same document.\n\n\nSentence Selection\n\nNext, to select the extracted sentences based on the above sentence representations, we add another LSTM-RNN to train a Pointer Network (Vinyals et al., 2015), to extract sentences recurrently. We calculate the extraction probability by:\nu t j = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 v p tanh(W p1 h j + W p2 e t ) if j t = j k \u2200k < t \u2212\u221e otherwise (1) P (j t |j 1 , . . . , j t\u22121 ) = softmax(u t )\n(2) where e t 's are the output of the glimpse operation (Vinyals et al., 2016):\na t j = v g tanh(W g1 h j + W g2 z t )(3)\u03b1 t = softmax(a t )(4)e t = j \u03b1 t j W g1 h j (5) Abstractor d 1 d 2 d 3 d 4 d 5 d jt g(d jt ) s t d 1 d 2 d 3 d 4 d 5 d jt g(d jt ) s t Summary Sentence (ground truth) d 1 d 2 d 3 d 4 d 5 d jt g(d jt ) s t\n\nGenerated Sentence\n\nReward RL Agent\n\n\nExtractor\n\n\nPolicy Gradient Update\n\nObservation\nd 1 d 2 d 3 d 4 d 5 d jt g(d jt ) s t d 1 d 2 d 3 d 4 d 5 d jt g(d jt ) s t d 1 d 2 d 3 d 4 d 5 d jt g(d jt ) s t d 1 d 2 d 3 d 4 d 5 d jt g(d jt ) s t\n\nDocument Sentences\n\nAction (extract sent.) Figure 2: Reinforced training of the extractor (for one extraction step) and its interaction with the abstractor. For simplicity, the critic network is not shown. Note that all d's and s t are raw sentences, not vector representations.\n\nIn Eqn. 3, z t is the output of the added LSTM-RNN (shown in green in Fig. 1) which is referred to as the decoder. All the W 's and v's are trainable parameters. At each time step t, the decoder performs a 2-hop attention mechanism: It first attends to h j 's to get a context vector e t and then attends to h j 's again for the extraction probabilities. 2 This model is essentially classifying all sentences of the document at each extraction step. An illustration of the whole extractor is shown in Fig. 1.\n\n\nAbstractor Network\n\nThe abstractor network approximates g, which compresses and paraphrases an extracted document sentence to a concise summary sentence. We use the standard encoder-aligner-decoder (Bahdanau et al., 2015;Luong et al., 2015). We add the copy mechanism 3 to help directly copy some outof-vocabulary (OOV) words (See et al., 2017). For more details, please refer to the supplementary.\n\n\nLearning\n\nGiven that our extractor performs a nondifferentiable hard extraction, we apply standard policy gradient methods to bridge the backpropagation and form an end-to-end trainable (stochastic) computation graph. However, simply starting from a randomly initialized network to train the whole model in an end-to-end fashion is infeasible. When randomly initialized, the extractor would often select sentences that are not relevant, so it would be difficult for the abstractor to learn to abstractively rewrite. On the other hand, without a well-trained abstractor the extractor would get noisy reward, which leads to a bad estimate of the policy gradient and a sub-optimal policy. We hence propose optimizing each sub-module separately using maximumlikelihood (ML) objectives: train the extractor to select salient sentences (fit f ) and the abstractor to generate shortened summary (fit g). Finally, RL is applied to train the full model end-to-end (fit h).\n\n\nMaximum-Likelihood Training for Submodules\n\nExtractor Training: In Sec. 2.1.2, we have formulated our sentence selection as classification. However, most of the summarization datasets are end-to-end document-summary pairs without extraction (saliency) labels for each sentence. Hence, we propose a simple similarity method to provide a 'proxy' target label for the extractor. Similar to the extractive model of Nallapati et al. \nj t = argmax i (ROUGE-L recall (d i , s t )) (6)\nGiven these proxy training labels, the extractor is then trained to minimize the cross-entropy loss. 3 We use the terminology of copy mechanism (originally named pointer-generator) in order to avoid confusion with the pointer network (Vinyals et al., 2015). 4 Nallapati et al. (2017) selected sentences greedily to maximize the global summary-level ROUGE, whereas we match exactly 1 document sentence for each GT summary sentence based on the individual sentence-level score.\n\nAbstractor Training: For the abstractor training, we create training pairs by taking each summary sentence and pairing it with its extracted document sentence (based on Eqn. 6). The network is trained as an usual sequence-to-sequence model to minimize the cross-entropy loss L(\u03b8 abs ) = \u2212 1 M M m=1 logP \u03b8 abs (w m |w 1:m\u22121 ) of the decoder language model at each generation step, where \u03b8 abs is the set of trainable parameters of the abstractor and w m the m th generated word.\n\n\nReinforce-Guided Extraction\n\nHere we explain how policy gradient techniques are applied to optimize the whole model. To make the extractor an RL agent, we can formulate a Markov Decision Process (MDP) 5 : at each extraction step t, the agent observes the current state c t = (D, d j t\u22121 ), samples an action j t \u223c \u03c0 \u03b8a,\u03c9 (c t , j) = P (j) from Eqn. 2 to extract a document sentence and receive a reward 6\nr(t + 1) = ROUGE-L F 1 (g(d jt ), s t )(7)\nafter the abstractor summarizes the extracted sentence d jt . We denote the trainable parameters of the extractor agent by \u03b8 = {\u03b8 a , \u03c9} for the decoder and hierarchical encoder respectively. We can then train the extractor with policy-based RL. We illustrate this process in Fig. 2. The vanilla policy gradient algorithm, REIN-FORCE (Williams, 1992), is known for high variance. To mitigate this problem, we add a critic network with trainable parameters \u03b8 c to predict the state-value function V \u03c0 \u03b8a,\u03c9 (c). The predicted value of critic b \u03b8c,\u03c9 (c) is called the 'baseline', which is then used to estimate the advantage function: A \u03c0 \u03b8 (c, j) = Q \u03c0 \u03b8a,\u03c9 (c, j) \u2212 V \u03c0 \u03b8a,\u03c9 (c) because the total return R t is an estimate of actionvalue function Q(c t , j t ). Instead of maximizing Q(c t , j t ) as done in REINFORCE, we maximize A \u03c0 \u03b8 (c, j) with the following policy gradient:\n\u2207 \u03b8a,\u03c9 J(\u03b8 a , \u03c9) = E[\u2207 \u03b8a,\u03c9 log\u03c0 \u03b8 (c, j)A \u03c0 \u03b8 (c, j)](8)\nAnd the critic is trained to minimize the square loss: L c (\u03b8 c , \u03c9) = (b \u03b8c,\u03c9 (c t ) \u2212 R t ) 2 . This is 5 Strictly speaking, this is a Partially Observable Markov Decision Process (POMDP). We approximate it as an MDP by assuming that the RNN hidden state contains all past info. 6 In Eqn. 6, we use ROUGE-recall because we want the extracted sentence to contain as much information as possible for rewriting. Nevertheless, for Eqn. 7, ROUGE-F1 is more suitable because the abstractor g is supposed to rewrite the extracted sentence d to be as concise as the ground truth s. known as the Advantage Actor-Critic (A2C), a synchronous variant of A3C (Mnih et al., 2016). For more A2C details, please refer to the supp.\n\nIntuitively, our RL training works as follow: If the extractor chooses a good sentence, after the abstractor rewrites it the ROUGE match would be high and thus the action is encouraged. If a bad sentence is chosen, though the abstractor still produces a compressed version of it, the summary would not match the ground truth and the low ROUGE score discourages this action. Our RL with a sentence-level agent is a novel attempt in neural summarization. We use RL as a saliency guide without altering the abstractor's language model, while previous work applied RL on the word-level, which could be prone to gaming the metric at the cost of language fluency. 7\n\nLearning how many sentences to extract: In a typical RL setting like game playing, an episode is usually terminated by the environment. On the other hand, in text summarization, the agent does not know in advance how many summary sentence to produce for a given article (since the desired length varies for different downstream applications). We make an important yet simple, intuitive adaptation to solve this: by adding a 'stop' action to the policy action space. In the RL training phase, we add another set of trainable parameters v EOE (EOE stands for 'End-Of-Extraction') with the same dimension as the sentence representation. The pointer-network decoder treats v EOE as one of the extraction candidates and hence naturally results in a stop action in the stochastic policy. We set the reward for the agent performing EOE to ROUGE-\n1 F 1 ([{g(d jt )} t ], [{s t } t ])\n; whereas for any extraneous, unwanted extraction step, the agent receives zero reward. The model is therefore encouraged to extract when there are still remaining ground-truth summary sentences (to accumulate intermediate reward), and learn to stop by optimizing a global ROUGE and avoiding extra extraction. 8 Overall, this modification allows dy-7 During this RL training of the extractor, we keep the abstractor parameters fixed. Because the input sentences for the abstractor are extracted by an intermediate stochastic policy of the extractor, it is impossible to find the correct target summary for the abstractor to fit g with ML objective. Though it is possible to optimize the abstractor with RL, in out preliminary experiments we found that this does not improve the overall ROUGE, most likely because this RL optimizes at a sentence-level and can add across-sentence redundancy. We achieve SotA results without this abstractor-level RL. 8 We use ROUGE-1 for terminal reward because it is a better measure of bag-of-words information (i.e., has all the namic decisions of number-of-sentences based on the input document, eliminates the need for tuning a fixed number of steps, and enables a data-driven adaptation for any specific dataset/application.\n\n\nRepetition-Avoiding Reranking\n\nExisting abstractive summarization systems on long documents suffer from generating repeating and redundant words and phrases. To mitigate this issue, See et al. (2017) propose the coverage mechanism and Paulus et al. (2018) incorporate tri-gram avoidance during beam-search at testtime. Our model without these already performs well because the summary sentences are generated from mutually exclusive document sentences, which naturally avoids redundancy. However, we do get a small further boost to the summary quality by removing a few 'across-sentence' repetitions, via a simple reranking strategy: At sentence-level, we apply the same beam-search tri-gram avoidance (Paulus et al., 2018). We keep all k sentence candidates generated by beam search, where k is the size of the beam. Next, we then rerank all k n combinations of the n generated summary sentence beams. The summaries are reranked by the number of repeated N -grams, the smaller the better. We also apply the diverse decoding algorithm described in Li et al. (2016) (which has almost no computation overhead) so as to get the above approach to produce useful diverse reranking lists. We show how much the redundancy affects the summarization task in Sec. 6.2.\n\n\nRelated Work\n\nEarly summarization works mostly focused on extractive and compression based methods (Jing and McKeown, 2000;Knight and Marcu, 2000;Clarke and Lapata, 2010;Berg-Kirkpatrick et al., 2011;Filippova et al., 2015). Recent large-sized corpora attracted neural methods for abstractive summarization (Rush et al., 2015;. Some of the recent success in neural abstractive models include hierarchical attention (Nallapati et al., 2016), coverage (Suzuki and Nagata, 2016;Chen et al., 2016;See et al., 2017), RL based metric optimization (Paulus et al., 2018), graph-based attention (Tan et al., 2017), and the copy mechanism (Miao and Blunsom, 2016;Gu et al., 2016;See et al., 2017).\n\nOur model shares some high-level intuition with extract-then-compress methods. Earlier attempts in this paradigm used Hidden Markov Models and rule-based systems (Jing and McKeown, 2000), statistical models based on parse trees (Knight and Marcu, 2000), and integer linear programming based methods (Martins and Smith, 2009;Gillick and Favre, 2009;Clarke and Lapata, 2010;Berg-Kirkpatrick et al., 2011). Recent approaches investigated discourse structures (Louis et al., 2010;Hirao et al., 2013;Kikuchi et al., 2014;Wang et al., 2015), graph cuts (Qian and Liu, 2013), and parse trees (Li et al., 2014;Bing et al., 2015). For neural models, Cheng and Lapata (2016) used a second neural net to select words from an extractor's output. Our abstractor does not merely 'compress' the sentences but generatively produce novel words. Moreover, our RL bridges the extractor and the abstractor for end-to-end training.\n\nReinforcement learning has been used to optimize the non-differential metrics of language generation and to mitigate exposure bias (Ranzato et al., 2016;Bahdanau et al., 2017). Hen\u00df et al. (2015) use Q-learning based RL for extractive summarization. Paulus et al. (2018) use RL policy gradient methods for abstractive summarization, utilizing sequence-level metric rewards with curriculum learning (Ranzato et al., 2016) or weighted ML+RL mixed loss (Paulus et al., 2018) for stability and language fluency. We use sentence-level rewards to optimize the extractor while keeping our ML trained abstractor decoder fixed, so as to achieve the best of both worlds.\n\nTraining a neural network to use another fixed network has been investigated in machine translation for better decoding (Gu et al., 2017a) and real-time translation (Gu et al., 2017b). They used a fixed pretrained translator and applied policy gradient techniques to train another task-specific network. In question answering (QA), Choi et al. (2017) extract one sentence and then generate the answer from the sentence's vector representation with RL bridging. Another recent work attempted a new coarse-to-fine attention approach on summarization (Ling and Rush, 2017) and found desired sharp focus properties for scaling to larger inputs (though without metric improvements). Very recently (concurrently), Narayan et al. Finally, there are some loosely-related recent works: Zhou et al. (2017) proposed selective gate to improve the attention in abstractive summarization. Tan et al. (2018) used an extract-thensynthesis approach on QA, where an extraction model predicts the important spans in the passage and then another synthesis model generates the final answer. Swayamdipta et al. (2017) attempted cascaded non-recurrent small networks on extractive QA, resulting a scalable, parallelizable model. Fan et al. (2017) added controlling parameters to adapt the summary to length, style, and entity preferences. However, none of these used RL to bridge the non-differentiability of neural models.\n\n\nExperimental Setup\n\nPlease refer to the supplementary for full training details (all hyperparameter tuning was performed on the validation set). We use the CNN/Daily Mail dataset (Hermann et al., 2015) modified for summarization (Nallapati et al., 2016). Because there are two versions of the dataset, original text and entity anonymized, we show results on both versions of the dataset for a fair comparison to prior works. The experiment runs training and evaluation for each version separately. Despite the fact that the 2 versions have been considered separately by the summarization community as 2 different datasets, we use same hyper-parameter values for both dataset versions to show the generalization of our model. We also show improvements on the DUC-2002 dataset in a test-only setup.\n\n\nEvaluation Metrics\n\nFor all the datasets, we evaluate standard ROUGE-1, ROUGE-2, and ROUGE-L (Lin, 2004) on fulllength F 1 (with stemming) following previous works (Nallapati et al., 2017;See et al., 2017;Paulus et al., 2018). Following See et al. (2017), we also evaluate on METEOR (Denkowski and Lavie, 2014) for a more thorough analysis.\n\n\nModular Extractive vs. Abstractive\n\nOur hybrid approach is capable of both extractive and abstractive (i.e., rewriting every sentence) summarization. The extractor alone performs extractive summarization. To investigate the effect of the recurrent extractor (rnn-ext), we implement a feed-forward extractive baseline ff-ext (details in supplementary). It is also possible to apply RL to extractor without using the abstractor (rnn-ext + RL). 9 Benefiting from the high modularity of our model, we can make our summarization system abstractive by simply applying the abstractor on the extracted sentences. Our abstractor rewrites each sentence and generates novel words from a large vocabulary, and hence every word in our overall summary is generated from scratch; making our full model categorized into the abstractive paradigm. 10 We run experiments on separately trained extractor/abstractor (ff-ext + abs, rnn-ext + abs) and the reinforced full model (rnn-ext + abs + RL) as well as the final reranking version (rnn-ext + abs + RL + rerank).\n\n\nResults\n\nFor easier comparison, we show separate tables for the original-text vs. anonymized versions - Table 1 and Table 2, respectively. Overall, our model achieves strong improvements and the new state-of-the-art on both extractive and abstractive settings for both versions of the CNN/DM dataset (with some comparable results on the anonymized version). Moreover, Table 3 shows the generalization of our abstractive system to an out-ofdomain test-only setup (DUC-2002), where our model achieves better scores than See et al. (2017).\n\n\nExtractive Summarization\n\nIn the extractive paradigm, we compare our model with the extractive model from Nallapati et al. 9 In this case the abstractor function g(d) = d. 10 Note that the abstractive CNN/DM dataset does not include any human-annotated extraction label, and hence our models do not receive any direct extractive supervision.  (2017) and a strong lead-3 baseline. For producing our summary, we simply concatenate the extracted sentences from the extractors. From Table 1 and Table 2, we can see that our feed-forward extractor out-performs the lead-3 baseline, empirically showing that our hierarchical sentence encoding model is capable of extracting salient sentences. 11 The reinforced extractor performs the best, because of the ability to get the summary-level reward and the reduced train-test mismatch of feeding the previous extraction decision. The improvement over lead-3 is consistent across both tables. In Table 2, it outperforms the previous best neural extractive model (Nallapati et al., 2017). In Table 1, our model also outperforms a recent, con-   (2018), showing that our pointer-network extractor and reward formulations are very effective when combined with A2C RL.\n\n\nAbstractive Summarization\n\nAfter applying the abstractor, the ff-ext based model still out-performs the rnn-ext model. Both combined models exceed the pointer-generator model (See et al., 2017) without coverage by a large margin for all metrics, showing the effectiveness of our 2-step hierarchical approach: our method naturally avoids repetition by extracting multiple sentences with different keypoints. 12 Moreover, after applying reinforcement learning, our model performs better than the best model of See et al. (2017) and the best ML trained model of Paulus et al. (2018). Our reinforced model outperforms the ML trained rnn-ext + abs baseline with statistical significance of p < 0.01 on all metrics for both version of the dataset, indicating the effectiveness of the RL training. Also, rnn-ext + abs + RL is statistically significant better than See et al. (2017) for all metrics with p < 0.01. 13 In the supplementary, we show the learning curve of our RL training, where the average reward goes up quickly after the extractor learns the End-of-Extract action and then stabilizes. For all the above models, we use standard greedy decoding and find that it performs well.\n\nReranking and Redundancy Although the extract-then-abstract approach inherently will not generate repeating sentences like other neuraldecoders do, there might still be across-sentence redundancy because the abstractor is not aware of other extracted sentences when decoding one. Hence, we incorporate an optional reranking strategy described in Sec. 3.3. The improved ROUGE scores indicate that this successfully removes some remaining redundancies and hence produces more concise summaries. Our best abstractive 12 A trivial lead-3 + abs baseline obtains ROUGE of (37.37, 15.59, 34.82), which again confirms the importance of our reinforce-based sentence selection. 13 We calculate statistical significance based on the bootstrap test (Noreen, 1989;Efron and Tibshirani, 1994)   model (rnn-ext + abs + RL + rerank) is clearly superior than the one of See et al. (2017). We are comparable on R-1 and R-2 but a 0.4 point improvement on R-L w.r.t. Paulus et al. (2018). 14 We also outperform the results of Fan et al. (2017) on both original and anonymized dataset versions. Several previous works have pointed out that extractive baselines are very difficult to beat (in terms of ROUGE) by an abstractive system (See et al., 2017;Nallapati et al., 2017). Note that our best model is one of the first abstractive models to outperform the lead-3 baseline on the originaltext CNN/DM dataset. Our extractive experiment serves as a complementary analysis of the effect of RL with extractive systems.\n\n\nHuman Evaluation\n\nWe also conduct human evaluation to ensure robustness of our training procedure. We measure relevance and readability of the summaries. Relevance is based on the summary containing important, salient information from the input article, being correct by avoiding contradictory/unrelated information, and avoiding repeated/redundant information. Readability is based on the summarys fluency, grammaticality, and coherence. To evaluate both these criteria, we design the following Amazon MTurk experiment: we randomly select 100 samples from the CNN/DM test set and ask the human testers (3 for each sample) to rank between summaries (for relevance and readability) produced by our model and that of See et al. (2017) (the models were anonymized and randomly shuffled), i.e. A is better, B is better, both are equally good/bad. Following previous work, the input article and ground truth summaries are also shown to the human participants in addition to the two model summaries. 15 From the results shown in Table 4, we can see that our model is better in both relevance and readability w.r.t. See et al. (2017). Speed Models total time (hr) words / sec (See et al., 2017) 12.9 14.8 rnn-ext + abs + RL 0.68 361.3 rnn-ext + abs + RL + rerank 2.00 (1.46 +0.54) 109.8 Table 5: Speed comparison with See et al. (2017).\n\n\nSpeed Comparison\n\nOur two-stage extractive-abstractive hybrid model is not only the SotA on summary quality metrics, but more importantly also gives a significant speed-up in both train and test time over a strong neural abstractive system (See et al., 2017). 16 Our full model is composed of a extremely fast extractor and a parallelizable abstractor, where the computation bottleneck is on the abstractor, which has to generate summaries with a large vocabulary from scratch. 17 The main advantage of our abstractor at decoding time is that we can first compute all the extracted sentences for the document, and then abstract every sentence concurrently (in parallel) to generate the overall summary. In Table 5, we show the substantial test-time speed-up of our model compared to See et al. (2017). 18 We calculate the total decoding time for producing all summaries for the test set. 19 Due to the fact that the main test-time speed bottleneck of RNN language generation model is that the model is constrained to generate one word at a time, the total decoding time is dependent on the number of total words generated; we hence also report the decoded words per second for a fair comparison. Our model without reranking is extremely fast. From Table 5 we can see that we achieve a speed up of 18x in time and 24x in word generation rate. Even after adding the (optional) reranker, we still maintain a 6-7x speed-up (and hence a user can choose to use the reranking component depending on their downstream application's speed requirements). 20 16 The only publicly available code with a pretrained model for neural summarization which we can test the speed. 17 The time needed for extractor is negligible w.r.t. the abstractor because it does not require large matrix multiplication for generating every word. Moreover, with convolutional encoder at word-level made parallelizable by the hierarchical rnn-ext, our model is scalable for very long documents. 18 For details of training speed-up, please see the supp. 19 We time the model of See et al. (2017) using beam size of 4 (used for their best-reported scores). Without beam-search, it gets significantly worse ROUGE of (36.62, 15.12, 34.08), so we do not compare speed-ups w.r.t. that version. 20 Most of the recent neural abstractive summarization systems are of similar algorithmic complexity to that of See et al. (2017). The main differences such as the training objective (ML vs. RL) and copying (soft/hard) has negligible test runtime compared to the slowest component: the long-summary Novel N -gram (%) Models 1-gm 2-gm 3-gm 4-gm See et al. (2017) 0.1 2.2 6.0 9.7 rnn-ext + abs + RL + rerank 0.3 10.0 21.7 31.6 reference summaries 10.8 47.5 68.2 78.2 Table 6: Abstractiveness: novel n-gram counts.\n\n\nAnalysis\n\n\nAbstractiveness\n\nWe compute an abstractiveness score (See et al., 2017) as the ratio of novel n-grams in the generated summary that are not present in the input document. The results are shown in Table 6: our model rewrites substantially more abstractive summaries than previous work. A potential reason for this is that when trained with individual sentence-pairs, the abstractor learns to drop more document words so as to write individual summary sentences as concise as human-written ones; thus the improvement in multi-gram novelty.\n\n\nQualitative Analysis on Output Examples\n\nWe show examples of how our best model selects sentences and then rewrites them. In the supplementary Fig. 4 and Fig. 5, we can see how the abstractor rewrites the extracted sentences concisely while keeping the mentioned facts. Adding the reranker makes the output more compact globally. We observe that when rewriting longer text, the abstractor would have many facts to choose from ( Fig. 5 sentence 2) and this is where the reranker helps avoid redundancy across sentences.\n\n\nConclusion\n\nWe propose a novel sentence-level RL model for abstractive summarization, which makes the model aware of the word-sentence hierarchy.  (2014) to compute the representation of every individual sentence in the document. First, the words are converted to the distributed vector representation by a learned word embedding matrix W emb . The sequence of the word vectors from each sentence is then fed through 1-D single-layer convolution filters with various window sizes (3, 4, 5) to capture the temporal dependencies of nearby words and then followed by relu non-linear activation and max-over-time pooling. The convolutional representation r j for the jth sentence is then obtained by concatenating the outputs from the activations of all filter window sizes.\n\n\nA.2 Abstractor\n\nIn this section we discuss the architecture choices for our abstractor network in Sec. 2.2. At a highlevel, it is a sequence-to-sequence model with attention and copy mechanism (but no coverage). Note that the abstractor network is a separate neural network from the extractor agent without any form of parameter sharing.\n\n\nSequence-Attention-Sequence Model\n\nWe use a standard encoder-aligner-decoder model (Bahdanau et al., 2015;Luong et al., 2015) with the bilinear multiplicative attention function (Luong et al., 2015), f att (h i , z j ) = h i W attn z j , for the context vector e j . We share the source and target embedding matrix W emb as well as output projection matrix as in Inan et al. (2017); Press and Wolf (2017); Paulus et al. (2018).\n\n\nCopy Mechanism\n\nWe add the copying mechanism as in See et al. (2017) to extend the decoder to predict over the extended vocabulary of words in the input document. A copy probability p copy = \u03c3(v \u1e91\u1e91 j + v s z j + v w w j + b) is calculated by learnable parameters v's and b, and then is used to further compute a weighted sum of the probability of source vocabulary and the predefined vocabulary. At test time, an OOV prediction is replaced by the document word with the highest attention score.\n\n\nA.3 Actor-Critic Policy Gradient\n\nHere we discuss the details of the actor-critic policy gradient training. Given the MDP formulation described in Sec. 3.2 , the return (total discounted future reward) is R t = Ns t=1 \u03b3 t r(t + 1)\n\nfor each recurrent step t. To learn a optimal policy \u03c0 * that maximize the state-value function:\nV \u03c0 * (c) = E \u03c0 * [R t |c t = c]\nwe will make use of the action-value function\nQ \u03c0 \u03b8 (c, j) = E \u03c0 \u03b8 [R t |c t = c, j t = j]\nWe then take the policy gradient theorem and then substitute the action-value function with the Monte-Carlo sample:\n\u2207 \u03b8 J(\u03b8) = E \u03c0 \u03b8 [\u2207 \u03b8 log\u03c0 \u03b8 (c, j)Q \u03c0 \u03b8 (c, j)] (10) = 1 N s Ns t=1 \u2207 \u03b8 log\u03c0 \u03b8 (c t , j t )R t(11)\nwhich runs a single episode and gets the return (estimate of action-value function) by sampling from the policy \u03c0 \u03b8 , where N s is the total number of sentences the agent extracts. This gradient update is also known as the REINFORCE algorithm (Williams, 1992). The vanilla REINFORCE algorithm is known for high variance. To mitigate this problem we add a critic network with trainable parameters \u03b8 c having the same structure as the pointer-network's decoder (described in Sec. 2.1.2) but change the final output layer to regress the state-value function V \u03c0 \u03b8a,\u03c9 (c). The predicted value b \u03b8c,\u03c9 (c) is called the baseline and is subtracted from the actionvalue function to estimate the advantage A \u03c0 \u03b8 (c, j) = Q \u03c0 \u03b8a,\u03c9 (c, j) \u2212 b \u03b8c,\u03c9 (c)\n\nwhere \u03b8 = {\u03b8 a , \u03b8 c , \u03c9} denotes the set of all trainable parameters. The new policy gradient for our extractor can be estimated by substituting the action-value function in Eqn. 10 by the advantage and then use Monte-Carlo samples (use R t to esti- [\u2207 \u03b8a,\u03c9 log\u03c0 \u03b8 (c, j)A \u03c0 \u03b8 (c, j)]\n\nHere we also show an interesting finding of the effect adding the EOE action. In Fig. 3, we can see that the average reward is low in the beginning but quickly goes up after the agent picks up the EOE action. The low beginning reward is because the agent does not choose the EOE action hence keep getting zero rewards when extracting extra sentences, which lowers the average.\n\n\nA.4 Sentence Selection Baseline ff-ext\n\nIn this subsection, we describe the detailed network structure of the feed-forward extractor baseline (ff-ext). Following the hierarchical sentence representation described in Sec. 2.1.1, if we add another assumption that there exists a sequence j i1 , j i2 , . . . , j iNs where j i1 < j i2 < \u00b7 \u00b7 \u00b7 < j iNs such that [d i1 , d i2 , \u00b7 \u00b7 \u00b7 , d iN d ] = x i and [g(d j i1 ), g(d j i2 ), \u00b7 \u00b7 \u00b7 , g(d j iNs )] = y i\n\ni.e., the extracted document are summarized in the order as is, we could apply the following feedforward structure for sentence selection. We first learn a document representation b\u0177\nx = tanh(W d 1 N d N d j=1 h j + b d )(14)\nwhere N d , N s each denotes the number of sentences in the document x and the summary y respectively. And then we compute the extraction probability:\n\n\n(2018) use RL for ranking sentences in pure extraction-based summarization and \u00c7 elikyilmaz et al. (2018) investigate multiple communicating encoder agents to enhance the copying abstractive summarizer.\n\nFigure 3 :\n3RL\n\nTable 2 :\n2ROUGE for anonymized CNN/DM.\n\nTable 3 :\n3Generalization to DUC-2002 (F1). current sentence-ranking RL model by Narayan et al.\n\n\nwith 100K samples. Output ofPaulus et al. (2018) is not available so we couldn't test for statistical significance there.Relevance Readability Total \nSee et al. (2017) \n120 \n128 \n248 \nrnn-ext + abs + RL + rerank \n137 \n133 \n270 \nEqually good/bad \n43 \n39 \n82 \n\n\n\nTable 4 :\n4Human Evaluation: pairwise comparison between our final model andSee et al. (2017).\n\n\nDiederik P. Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. In ICLR. Jiwei Li, Will Monroe, and Dan Jurafsky. 2016. A simple, fast diverse decoding algorithm for neural generation. arXiv preprint, abs/1611.08562. Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop, pages 74-81, Barcelona, Spain. Association for Computational Linguistics. Jeffrey Ling and Alexander Rush. 2017. Coarse-to-fine attention models for document summarization. In Proceedings of the Workshop on New Frontiers in Summarization, pages 33-42. Association for Computational Linguistics. Annie Louis, Aravind Joshi, and Ani Nenkova. 2010. Discourse indicators for content selection in summarization. In Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, SIGDIAL '10, pages 147-156, Stroudsburg, PA, USA. Association for Computational Linguistics. Minh-Thang Luong, Hieu Pham, and Christopher D. Manning. 2015. Effective approaches to attentionbased neural machine translation. In Empirical Methods in Natural Language Processing (EMNLP), pages 1412-1421, Lisbon, Portugal. Association for Computational Linguistics. Andr\u00e9 F. T. Martins and Noah A. Smith. 2009. Summarization with a joint model for sentence extraction and compression. In Proceedings of the Workshop on Integer Linear Programming for Natural Langauge Processing, ILP '09, pages 1-9, Stroudsburg, PA, USA. Association for Computational Linguistics. Yishu Miao and Phil Blunsom. 2016. Language as a latent variable: Discrete generative models for sentence compression. In EMNLP. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 3111-3119. Curran Associates, Inc. Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. 2016. Asynchronous methods for deep reinforcement learning. In Proceedings of The 33rd International Conference on Machine Learning, volume 48 of Proceedings of Machine Learning Research, pages 1928-1937, New York, New York, USA. PMLR. Ramesh Nallapati, Feifei Zhai, and Bowen Zhou. 2017. Summarunner: A recurrent neural network based sequence model for extractive summarization of documents. In AAAI Conference on Artificial Intelligence. Ramesh Nallapati, Bowen Zhou, Cicero Nogueira dos santos, Caglar Gulcehre, and Bing Xiang. 2016. Abstractive text summarization using sequence-tosequence rnns and beyond. In CoNLL. Shashi Narayan, Shay B. Cohen, and Mirella Lapata. 2018. Ranking sentences for extractive summarization with reinforcement learning. NAACL-HLT. Eric W Noreen. 1989. Computer-intensive methods for testing hypotheses. Wiley New York. Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. 2013. On the difficulty of training recurrent neural networks. In Proceedings of the 30th International Conference on Machine Learning, volume 28 of Here we describe the convolutional sentence representation used in Sec. 2.1.1. We use the temporal convolutional model proposed by KimOur \nmodel achieves the new state-of-the-art on both \nCNN/DM versions as well a better generalization \non test-only DUC-2002, along with a significant \nspeed-up in training and decoding. \nAngela Fan, David Grangier, and Michael Auli. 2017. \nControllable abstractive summarization. \narXiv \npreprint, abs/1711.05217. \n\nKatja Filippova, Enrique Alfonseca, Carlos Col-\nmenares, Lukasz Kaiser, and Oriol Vinyals. 2015. \nSentence compression by deletion with lstms. In \nProceedings of the 2015 Conference on Empir-\nical Methods in Natural Language Processing \n(EMNLP'15). \n\nDan Gillick and Benoit Favre. 2009. A scalable global \nmodel for summarization. In Proceedings of the \nWorkshop on Integer Linear Programming for Nat-\nural Langauge Processing, ILP '09, pages 10-18, \nStroudsburg, PA, USA. Association for Computa-\ntional Linguistics. \n\nJiatao Gu, Kyunghyun Cho, and Victor O. K. Li. 2017a. \nTrainable greedy decoding for neural machine trans-\nlation. In EMNLP. \n\nJiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K. \nLi. 2016. Incorporating copying mechanism in \nsequence-to-sequence learning. In Proceedings of \nthe 54th Annual Meeting of the Association for Com-\nputational Linguistics (Volume 1: Long Papers), \npages 1631-1640, Berlin, Germany. Association for \nComputational Linguistics. \n\nJiatao Gu, Graham Neubig, Kyunghyun Cho, and Vic-\ntor O. K. Li. 2017b. Learning to translate in real-\ntime with neural machine translation. In EACL. \n\nSebastian Hen\u00df, Margot Mieskes, and Iryna Gurevych. \n2015. A reinforcement learning approach for adap-\ntive single-and multi-document summarization. In \nInternational Conference of the German Society for \nComputational Linguistics and Language Technol-\nogy (GSCL-2015), pages 3-12. \n\nKarl Moritz Hermann, Tom\u00e1\u0161 Ko\u010disk\u00fd, Edward \nGrefenstette, Lasse Espeholt, Will Kay, Mustafa Su-\nleyman, and Phil Blunsom. 2015. Teaching ma-\nchines to read and comprehend. In Advances in Neu-\nral Information Processing Systems (NIPS). \n\nTsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino, \nNorihito Yasuda, and Masaaki Nagata. 2013. \nSingle-document summarization as a tree knapsack \nproblem. In Proceedings of the 2013 Conference on \nEmpirical Methods in Natural Language Process-\ning, pages 1515-1520, Seattle, Washington, USA. \nAssociation for Computational Linguistics. \n\nSepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long \nshort-term memory. Neural Comput., 9(9):1735-\n1780. \n\nHakan Inan, Khashayar Khosravi, and Richard Socher. \n2017. Tying word vectors and word classifiers: A \nloss framework for language modeling. In ICLR. \n\nHongyan Jing and Kathleen R. McKeown. 2000. Cut \nand paste based text summarization. In Proceed-\nings of the 1st North American Chapter of the As-\nsociation for Computational Linguistics Conference, \nNAACL 2000, pages 178-185, Stroudsburg, PA, \nUSA. Association for Computational Linguistics. \n\nYuta Kikuchi, Tsutomu Hirao, Hiroya Takamura, Man-\nabu Okumura, and Masaaki Nagata. 2014. Single \ndocument summarization based on nested tree struc-\nture. In Proceedings of the 52nd Annual Meeting of \nthe Association for Computational Linguistics (Vol-\nume 2: Short Papers), pages 315-320, Baltimore, \nMaryland. Association for Computational Linguis-\ntics. \n\nYoon Kim. 2014. Convolutional neural networks \nfor sentence classification. In Proceedings of the \n2014 Conference on Empirical Methods in Natural \nLanguage Processing (EMNLP), pages 1746-1751, \nDoha, Qatar. Association for Computational Lin-\nguistics. \n\nKevin Knight and Daniel Marcu. 2000. Statistics-\nbased summarization -step one: Sentence compres-\nsion. In Proceedings of the Seventeenth National \nConference on Artificial Intelligence and Twelfth \nConference on Innovative Applications of Artificial \nIntelligence, pages 703-710. AAAI Press. \n\nChen Li, Yang Liu, Fei Liu, Lin Zhao, and Fuliang \nWeng. 2014. Improving multi-documents summa-\nrization by sentence compression based on expanded \nconstituent parse trees. In Proceedings of the 2014 \nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 691-701. Asso-\nciation for Computational Linguistics. \n\nSupplementary Materials \n\nA Model Details \n\nA.1 Convolutional Encoder \n\n\nWe are releasing our code, best pretrained models, as well as output summaries, to promote future research: https://github.com/ChenRocks/fast_abs_rl\nNote that we force-zero the extraction prob. of already extracted sentences so as to prevent the model from using repeating document sentences and suffering from redundancy. This is non-differentiable and hence only done in RL training.\nimportant information been generated); while ROUGE-L is used as intermediate rewards since it is known for better measurement of language fluency within a local sentence.\nThe ff-ext model outperforms rnn-ext possibly because it does not predict sentence ordering; thus is easier to optimize and the n-gram based metrics do not consider sentence ordering. Also note that in our MDP formulation, we cannot apply RL on ff-ext due to its historyless nature. Even if applied naively, there is no mean for the feed-forward model to learn the EOE described in Sec. 3.2.\nWe do not list the scores of their pure RL model because they discussed its bad readability.15  We selected human annotators that were located in the US, had an approval rate greater than 95%, and had at least 10,000 approved HITs on record.\nP (d j = 1|h j ,x) = \u03c3(W c h j + h j W sx + b)21  We found that updating with mini-batch of episodes and standardizing Rt over all time steps and all episodes within the batch helps converging.\nDue to the fact that the size of the reranking list is exponential to the number of sentences of the generated summary n, we pruned the beam so as to allow completion (of dev-set summarization) in a reasonable amount of time, as following: for n \u2264 5 , we use our standard beam size of k = 5, but for larger n values, we use gradually-reduced k values: (6, 4), (7 \u2212 8, 3), (9+, 2) for (n, k).B.3 Training SpeedIt took a total of 19.71 hours 23 to train our model. On the other hand,See et al. (2017) reported more than 78 hours of training. The training speed gain is mainly from the shortened input/target pairs of our abstractor model. Since our encoder-decoderaligner structure operates on sentence pair, it trains much faster the the document-summary pair used in the pointer-generator model(See et al., 2017). We also report here the speed of training our abstractor as time per training update. 24 Our abstractor only requires 0.54 seconds per updates whileSee et al. (2017) needs 3.42. For all our speed experiments we use K40 GPUs (similar toSee et al. (2017). The reduced sequence length gives us an advantage of 6x. Also, the model proposed bySee et al. (2017) needs careful scheduling of the sentence lengths.C Generation SamplesPlease seeFig. 4andFig. 5for the output examples (see the discussion of this example in Sec. 7.2). 23 4.15 hours for the abstractor, 15.56 hours for the RL training. Extractor ML training can be run at the same time with abstractor training and is approximately 1.5 hours.24  We use their publicly available code and run training (without coverage mechanism) on our machine for a fair comparison. The number of vocabulary, embedding dimension, RNN hidden units are also set to the same as our model. We set their maximum encoder and decoder steps to 400 and 100 respectively, as reported in their paper.\nAcknowledgmentsWe thank the anonymous reviewers for their helpful comments. This work was supported by a Google Faculty Research Award, a Bloomberg Data Science Research Grant, an IBM Faculty Award, and NVidia GPU awards.attentional-decoder's sequential generation; and this is the component that we substantially speed up via our parallel sentence decoding with sentence-selection RL.for each sentence in the document. Assuming we have the groundtruth extraction labels j 1 , . . . , j Ns , the above formulation treats sentence selection as a sequence of binary classification problems, where W s and bs are trainable parameters. We can therefore train the sentence selection network endto-end by cross-entropy loss, where W s and bs are trainable parameters.At test time, the feed-forward extractor chooses the top-k sentences and then concatenates them as the original order in the document. Note that we still refer to this network as feed-forward extractor (ff-ext) to distinguish from the pointer network extractor (rnn-ext) though it contains recurrent structure.B Training DetailsB.1 Dataset DetailsWe use the CNN/Daily Mail dataset first proposed byHermann et al. (2015)for reading comprehension task. This dataset has been modified for summarization byNallapati et al. (2017). This dataset differs from previous Gigaword dataset(Rush et al., 2015)in the length of the text: both documents and summaries for CNN/Daily Mail is much longer. The standard split of the dataset contains 287,227 documents for training, 13,368 documents for validation, and 11,490 for testing. Note that the original release of this dataset byHermann et al. (2015)is an anonymized version, where the named entities are anonymized and treated as a single word in the evaluation n-gram matching. On the other hand,See et al. (2017)proposed to use the non-anonymized, original-text version of the dataset. For a fair comparison to prior works, we show results on both versions of the dataset. The experiment runs training and evaluation for each version separately (but we transfer the same tuned hyperparameters from original to anonymized version).The DUC-2002 dataset contains 567 documentsummary pairs for single-document summarization. Due to its small size, we utilize it in a test-only setup: we directly use the CNN/Daily Mail (original text) trained model to summarize the DUC documents for testing generalization/transfer our models. The results ofSee et al. (2017)on DUC is obtained by running their publicly available pretrained model. We evaluate the results using the official ROUGE F1 script.B.2 Hyperparameter DetailsAll hyper-parameters are tuned on the validation set of the original text version of CNN/DM. We use mini-batches of 32 samples for all the training. Adam optimizer (Kingma and Ba, 2014) is used with learning rate 0.001 for ML and 0.0001 for RL training (other hyper-parameters at their default). We apply gradient clipping (Pascanu et al., 2013) using 2-norm of 2.0. We do not use any regularization technique except early-stopping. We also found that halving the learning rate whenever validation loss stops decreasing speeds up convergence. For RL training, we use \u03b3 = 0.95 for the discount factor in Eqn. 9. We first train the abstractor and extractors separately until convergence with maximum-likelihood objectives, then apply RL training on the trained sub-modules. For all LSTM-RNNs we use 256 hidden units. We use single layer LSTM-RNN with 256 hidden units for all models. The initial states of RNN are learned for our extractor agent. For the abstractor network, we learn a linear mapping to transform the encoder final states to the decoder initial states. We also train a word2vec(Mikolov et al., 2013)of 128 dimension on the same corpus to initialize the embedding matrix for all maximum-likelihood trained models and the embedding matrix is updated during training. We set a vocabulary size of 30000 most common words in the training set. For saving the memory space in training, we truncate the input article sentences to a maximum length of 100 tokens and summary sentences to 30 tokens (note that this is counted at the sentence-level for our abstractor training). We use all possible sentence pairs within every summary without limit. At test time, the length of input is not limited and the generation limit remains 30 maximum tokens for the abstractor. For all non-RL models, the number of sentences to extract is tuned on the validation set. For the reranking (see Sec. 3.3), we set N = 2 (bi-gram) and k = 5 (beam size).22The diversity ratio of the diverse beam-search(Li et al., 2016)is set to 1.0.Source document * [the oxford university women 's boat race team were rescued from the thames by the royal national lifeboat institution ( rnli ) on wednesday after being overcome by choppy waters . ] \u00a7 [crew members from the chiswick rnli station came to the assistance of the oxford crew and their cox , who were training for the boat race which -along with the men 's race -takes place on saturday , april 11 .] \u2020 [after the rowers were returned safely to putney , the sunken eight was recovered and returned to oxford 's base .] \u2021 [the royal national lifeboat institution come to the assistance of the oxford university women 's team .] the oxford crew were training on the thames for the boat race which takes place on saturday , april 11 . the rnli revealed the conditions were caused by strong wind against the tide creating three successive waves that poured over the boat 's riggers , ' creating an influx of water that could not be managed by the craft 's bilge pump ' . in a statement rnli helmsman ian owen said : ' while we have rescued quite a number of rowers over the years , this is the first time i 've been involved in helping such a prestigious team . ' the weather can be unpredictable on the thames , and the oxford university team dealt with the situation as safely and calmly as possible . we wish them all the best for their upcoming race . ' chiswick and tower stations are the busiest in the country , and the rnli has saved over 3,600 people since the service began in 2002 . the rnli alternative boat race fundraising event on april 10 takes place the day before the bny mellon boat race on the same famous stretch of river . for more information , please visit : rnli.org / boatrace .Ground truth summary the crew were training for the boat race which takes place on april 11 . the sunken eight was recovered and returned to oxford 's base . the choppy conditions were caused by strong wind against the tide creating three successive waves that poured over the boat 's riggers . rnn-ext + abs + RL (ROUGE-1: 48.54, ROUGE-2: 27.72 ROUGE-L: 48.54) * the oxford university women 's boat race team were rescued from the thames by the royal national lifeboat institution . \u00a7 crew members were training for the boat race which takes place on saturday . \u2020 the rowers were returned to oxford 's base . \u2021 the royal national lifeboat institution come to the assistance of the oxford university women 's team . +rerank (ROUGE-1: 60.42, ROUGE-2: 42.55, ROUGE-L: 60.42) * the oxford university women 's boat race team were rescued from the thames . \u00a7 crew members were training for the boat race which takes place on saturday . \u2020 the sunken eight was recovered and returned to oxford 's base . \u2021 the royal national lifeboat institution come to the assistance of the team .Figure 4: Example from the dataset showing the generated summary of our best models. The colored (marked) sentences correspond to our extractor's sentence selection. The listed ROUGE scores are computed for this specific example.Source document ( cnn ) have mercy ! lifetime has its follow-up to its \" unauthorized saved by the bell \" tv movie : the network is now taking on full house . * [the female-skewing cable network has greenlit \" the unauthorized full house story \" ( working title ) , the hollywood reporter has learned .] \u00a7 [in the same vein as its \" saved by the bell \" pic , lifetime 's full house story will look at the rise of the castincluding john stamos , bob saget and the mary-kate and ashley olsen -and explore the pressure they faced to balance idyllic family life on the show with the more complicated reality of their own lives outside the series . additionally , it will look at the warm bond that grew between the cast as the show became one of america 's most beloved family sitcoms .] \u2020 [casting will begin immediately . an air date for the \" full house \" tell-all has yet to be determined .] see more broadcast tv 's returning shows 2015-16 . \u2021 [ron mcgee , who penned the \" unauthorized saved by the bell story , \" will write the \" full house \" take . the telepic will be produced by the bell team of front street pictures and ringaling productions , with harvey kahn and stephen bulka also on board to exec produce .] for lifetime , the news comes after its two-hour bell take fizzled on labor day 2014 . despite tons of build-up and excitement from diehard fans of the original comedy series , the bell take drew only 1.6 million total viewers , with 1.1 million viewers among the 18-49 and 25-54 demographics . that pic was based on former star dustin diamond 's behind the bell 2009 tell-all , with dylan everett starring as mark-paul gosselaar and sam kindseth as diamond . full house aired on abc from 1987 to 1995 . netflix this month revived the beloved family comedy as \" fuller house , \" with original stars candace cameron-bure ( d.j. ) , her on-screen sister , jodie sweetin ( stephanie ) , and best friend andrea barber ( kimmy ) , in a 13-episode follow-up series . from its start as an unassuming family comedy in 1987 to its eventual wildly popular 192-episode run , \" full house \" was \" the little sitcom that could . \" it made huge stars of its cast -from bob saget and dave coulier , who were grinding away on the standup circuit , to john stamos breaking hearts on general hospital , and the olsen twins . see the original story at the hollywood reporter 's website . 2015 the hollywood reporter . all rights reserved .Ground truth summary the network has reportedly greenlit the tell-all . lifetime previously did an unauthorized movie on \" saved by the bell \" rnn-ext + abs + RL (ROUGE-1: 25.00, ROUGE-2: 7.41 ROUGE-L: 25.00) * the female-skewing cable network has greenlit \" the unauthorized full house story \" \u00a7 the cast will look at the warm bond that grew between the cast . \u2021 ron mcgee will write the \" full house \" take . \u2020 casting will begin immediately . +rerank (ROUGE-1: 37.93, ROUGE-2: 17.86, ROUGE-L: 37.93) * the female-skewing cable network has greenlit \" the unauthorized full house story \" \u00a7 lifetime 's full house story will look at the rise of the cast . \u2021 ron mcgee penned the \" unauthorized saved by the bell story \" \u2020 casting will begin immediately .Figure 5: Example from the dataset showing the generated summary of our best models. The colored (marked) sentences correspond to our extractor's sentence selection. The listed ROUGE scores are computed for this specific example.\n. Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron CDzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron C.\n\nAn actor-critic algorithm for sequence prediction. Yoshua Courville, Bengio, ICLR. Courville, and Yoshua Bengio. 2017. An actor-critic algorithm for sequence prediction. In ICLR.\n\nNeural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, ICLR. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2015. Neural machine translation by jointly learning to align and translate. In ICLR.\n\nHeadline generation based on statistical translation. Michele Banko, O Vibhu, Michael J Mittal, Witbrock, 10.3115/1075218.1075259Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, ACL '00. the 38th Annual Meeting on Association for Computational Linguistics, ACL '00Stroudsburg, PA, USAAssociation for Computational LinguisticsMichele Banko, Vibhu O. Mittal, and Michael J. Wit- brock. 2000. Headline generation based on statis- tical translation. In Proceedings of the 38th An- nual Meeting on Association for Computational Lin- guistics, ACL '00, pages 318-325, Stroudsburg, PA, USA. Association for Computational Linguistics.\n\nIrwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi, Samy Bengio, 1611.09940Neural combinatorial optimization with reinforcement learning. arXiv preprintIrwan Bello, Hieu Pham, Quoc V. Le, Mohammad Norouzi, and Samy Bengio. 2017. Neural combi- natorial optimization with reinforcement learning. arXiv preprint 1611.09940.\n\nJointly learning to extract and compress. Taylor Berg-Kirkpatrick, Dan Gillick, Dan Klein, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesStroudsburg, PA, USAAssociation for Computational Linguistics1Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein. 2011. Jointly learning to extract and compress. In Proceedings of the 49th Annual Meeting of the Asso- ciation for Computational Linguistics: Human Lan- guage Technologies -Volume 1, HLT '11, pages 481-490, Stroudsburg, PA, USA. Association for Computational Linguistics.\n\nAbstractive multi-document summarization via phrase selection and merging. Lidong Bing, Piji Li, Yi Liao, Wai Lam, Weiwei Guo, Rebecca J Passonneau, ACL. Lidong Bing, Piji Li, Yi Liao, Wai Lam, Weiwei Guo, and Rebecca J. Passonneau. 2015. Abstractive multi-document summarization via phrase selection and merging. In ACL.\n\nDeep communicating agents for abstractive summarization. Antoine Asli \u00c7 Elikyilmaz, Bosselut, NAACL-HLTXiaodong He, and Yejin ChoiAsli \u00c7 elikyilmaz, Antoine Bosselut, Xiaodong He, and Yejin Choi. 2018. Deep communicating agents for abstractive summarization. NAACL-HLT.\n\nDistraction-based neural networks for modeling documents. Qian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, Hui Jiang, IJCAI. Qian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, and Hui Jiang. 2016. Distraction-based neural networks for modeling documents. In IJCAI.\n\nNeural summarization by extracting sentences and words. Jianpeng Cheng, Mirella Lapata, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyAssociation for Computational Linguistics1Jianpeng Cheng and Mirella Lapata. 2016. Neural summarization by extracting sentences and words. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 484-494, Berlin, Germany. Association for Computational Linguistics.\n\nCoarse-to-fine question answering for long documents. Eunsol Choi, Daniel Hewlett, Jakob Uszkoreit, Illia Polosukhin, 10.18653/v1/P17-1020Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics1Alexandre Lacoste, and Jonathan BerantEunsol Choi, Daniel Hewlett, Jakob Uszkoreit, Illia Polosukhin, Alexandre Lacoste, and Jonathan Be- rant. 2017. Coarse-to-fine question answering for long documents. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics (Volume 1: Long Papers), pages 209-220. Association for Computational Linguistics.\n\nAbstractive sentence summarization with attentive recurrent neural networks. Sumit Chopra, Michael Auli, Alexander M Rush, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSan Diego, CaliforniaAssociation for Computational LinguisticsSumit Chopra, Michael Auli, and Alexander M. Rush. 2016. Abstractive sentence summarization with at- tentive recurrent neural networks. In Proceedings of the 2016 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies, pages 93-98, San Diego, California. Association for Computational Linguistics.\n\nDiscourse constraints for document compression. James Clarke, Mirella Lapata, Computational Linguistics. 363James Clarke and Mirella Lapata. 2010. Discourse constraints for document compression. Computa- tional Linguistics, 36(3):411-441.\n\nMeteor universal: Language specific translation evaluation for any target language. Michael Denkowski, Alon Lavie, Proceedings of the EACL 2014 Workshop on Statistical Machine Translation. the EACL 2014 Workshop on Statistical Machine TranslationMichael Denkowski and Alon Lavie. 2014. Meteor universal: Language specific translation evaluation for any target language. In Proceedings of the EACL 2014 Workshop on Statistical Machine Translation.\n\nAn introduction to the bootstrap. Bradley Efron, J Robert, Tibshirani, CRC pressBradley Efron and Robert J Tibshirani. 1994. An intro- duction to the bootstrap. CRC press.\n\nPMLRProceedings of Machine Learning Research. Machine Learning ResearchAtlanta, Georgia, USAProceedings of Machine Learning Research, pages 1310-1318, Atlanta, Georgia, USA. PMLR.\n\nA deep reinforced model for abstractive summarization. Romain Paulus, Caiming Xiong, Richard Socher, ICLR. Romain Paulus, Caiming Xiong, and Richard Socher. 2018. A deep reinforced model for abstractive sum- marization. In ICLR.\n\nUsing the output embedding to improve language models. Ofir Press, Lior Wolf, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics. the 15th Conference of the European Chapter of the Association for Computational LinguisticsAssociation for Computational Linguistics2Ofir Press and Lior Wolf. 2017. Using the output em- bedding to improve language models. In Proceed- ings of the 15th Conference of the European Chap- ter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 157-163. Association for Computational Linguistics.\n\nFast joint compression and summarization via graph cuts. Xian Qian, Yang Liu, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. the 2013 Conference on Empirical Methods in Natural Language ProcessingSeattle, Washington, USAAssociation for Computational LinguisticsXian Qian and Yang Liu. 2013. Fast joint compres- sion and summarization via graph cuts. In Proceed- ings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1492-1502, Seattle, Washington, USA. Association for Compu- tational Linguistics.\n\nSequence level training with recurrent neural networks. Aurelio Marc, Sumit Ranzato, Michael Chopra, Wojciech Auli, Zaremba, ICLR. Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2016. Sequence level train- ing with recurrent neural networks. In ICLR.\n\nA neural attention model for abstractive sentence summarization. Alexander M Rush, Sumit Chopra, Jason Weston, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational LinguisticsAlexander M. Rush, Sumit Chopra, and Jason Weston. 2015. A neural attention model for abstractive sen- tence summarization. In Proceedings of the 2015 Conference on Empirical Methods in Natural Lan- guage Processing, pages 379-389, Lisbon, Portugal. Association for Computational Linguistics.\n\nBidirectional recurrent neural networks. Mike Schuster, K Kuldip, A Paliwal, General, IEEE Transactions on Signal Processing. Mike Schuster, Kuldip K. Paliwal, and A. General. 1997. Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing.\n\nGet to the point: Summarization with pointergenerator networks. Abigail See, J Peter, Christopher D Liu, Manning, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics1Abigail See, Peter J. Liu, and Christopher D. Manning. 2017. Get to the point: Summarization with pointer- generator networks. In Proceedings of the 55th An- nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1073- 1083. Association for Computational Linguistics.\n\nRnn-based encoder-decoder approach with word frequency estimation. Jun Suzuki, Masaaki Nagata, EACL. Jun Suzuki and Masaaki Nagata. 2016. Rnn-based encoder-decoder approach with word frequency es- timation. In EACL.\n\nMulti-mention learning for reading comprehension with neural cascades. Swabha Swayamdipta, Ankur P Parikh, Tom Kwiatkowski, abs/1711.00894arXiv preprintSwabha Swayamdipta, Ankur P. Parikh, and Tom Kwiatkowski. 2017. Multi-mention learning for reading comprehension with neural cascades. arXiv preprint, abs/1711.00894.\n\nS-net: From answer extraction to answer generation for machine reading comprehension. Chuanqi Tan, Furu Wei, Nan Yang, Weifeng Lv, Ming Zhou, AAAI. Chuanqi Tan, Furu Wei, Nan Yang, Weifeng Lv, and Ming Zhou. 2018. S-net: From answer extraction to answer generation for machine reading comprehen- sion. In AAAI.\n\nAbstractive document summarization with a graphbased attentional neural model. Jiwei Tan, Xiaojun Wan, Jianguo Xiao, In ACLJiwei Tan, Xiaojun Wan, and Jianguo Xiao. 2017. Abstractive document summarization with a graph- based attentional neural model. In ACL.\n\nOrder matters: Sequence to sequence for sets. Oriol Vinyals, Samy Bengio, Manjunath Kudlur, International Conference on Learning Representations. ICLROriol Vinyals, Samy Bengio, and Manjunath Kudlur. 2016. Order matters: Sequence to sequence for sets. In International Conference on Learning Represen- tations (ICLR).\n\nPointer networks. Oriol Vinyals, Meire Fortunato, Navdeep Jaitly, C. Cortes, N. DOriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015. Pointer networks. In C. Cortes, N. D.\n\nD D Lawrence, M Lee, R Sugiyama, Garnett, Advances in Neural Information Processing Systems. Curran Associates, Inc28Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2692-2700. Curran Associates, Inc.\n\nSummarization based on task-oriented discourse parsing. Xun Wang, Yasuhisa Yoshida, Tsutomu Hirao, Katsuhito Sudoh, Masaaki Nagata, 10.1109/TASLP.2015.2432573IEEE/ACM Trans. Audio, Speech and Lang. Proc. 238Xun Wang, Yasuhisa Yoshida, Tsutomu Hirao, Kat- suhito Sudoh, and Masaaki Nagata. 2015. Sum- marization based on task-oriented discourse parsing. IEEE/ACM Trans. Audio, Speech and Lang. Proc., 23(8):1358-1367.\n\nSimple statistical gradientfollowing algorithms for connectionist reinforcement learning. Ronald J Williams, 10.1007/BF00992696Mach. Learn. 83-4Ronald J. Williams. 1992. Simple statistical gradient- following algorithms for connectionist reinforce- ment learning. Mach. Learn., 8(3-4):229-256.\n\nBbn/umd at duc-2004: Topiary. David Zajic, Bonnie Dorr, Richard Schwartz, HLT-NAACL 2004 Document Understanding Workshop. Boston, MassachusettsDavid Zajic, Bonnie Dorr, and Richard Schwartz. 2004. Bbn/umd at duc-2004: Topiary. In HLT-NAACL 2004 Document Understanding Workshop, pages 112-119, Boston, Massachusetts.\n\nSelective encoding for abstractive sentence summarization. Qingyu Zhou, Nan Yang, Furu Wei, Ming Zhou, 10.18653/v1/P17-1101Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics1Qingyu Zhou, Nan Yang, Furu Wei, and Ming Zhou. 2017. Selective encoding for abstractive sentence summarization. In Proceedings of the 55th An- nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1095- 1104. Association for Computational Linguistics.\n", "annotations": {"author": "[{\"end\":109,\"start\":77},{\"end\":160,\"start\":110}]", "publisher": null, "author_last_name": "[{\"end\":90,\"start\":86},{\"end\":122,\"start\":116}]", "author_first_name": "[{\"end\":85,\"start\":77},{\"end\":115,\"start\":110}]", "author_affiliation": "[{\"end\":108,\"start\":92},{\"end\":159,\"start\":143}]", "title": "[{\"end\":74,\"start\":1},{\"end\":234,\"start\":161}]", "venue": null, "abstract": "[{\"end\":1294,\"start\":236}]", "bib_ref": "[{\"end\":1528,\"start\":1504},{\"end\":1551,\"start\":1528},{\"end\":1575,\"start\":1551},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":1605,\"start\":1575},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1690,\"start\":1670},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":1709,\"start\":1690},{\"end\":1814,\"start\":1791},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1831,\"start\":1814},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":1851,\"start\":1831},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3087,\"start\":3066},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3515,\"start\":3496},{\"end\":4606,\"start\":4595},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4655,\"start\":4628},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":4836,\"start\":4818},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5274,\"start\":5257},{\"end\":8944,\"start\":8933},{\"end\":9234,\"start\":9196},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9256,\"start\":9234},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9673,\"start\":9651},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9964,\"start\":9942},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11465,\"start\":11442},{\"end\":11484,\"start\":11465},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":11588,\"start\":11570},{\"end\":13191,\"start\":13190},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":13345,\"start\":13323},{\"end\":13372,\"start\":13347},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14845,\"start\":14829},{\"end\":15716,\"start\":15715},{\"end\":16101,\"start\":16082},{\"end\":18639,\"start\":18638},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":19153,\"start\":19136},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":19677,\"start\":19656},{\"end\":20338,\"start\":20314},{\"end\":20361,\"start\":20338},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":20385,\"start\":20361},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":20415,\"start\":20385},{\"end\":20438,\"start\":20415},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20541,\"start\":20522},{\"end\":20654,\"start\":20630},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":20690,\"start\":20665},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20708,\"start\":20690},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20725,\"start\":20708},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20777,\"start\":20756},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20819,\"start\":20801},{\"end\":20868,\"start\":20844},{\"end\":20884,\"start\":20868},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20901,\"start\":20884},{\"end\":21090,\"start\":21066},{\"end\":21156,\"start\":21132},{\"end\":21228,\"start\":21203},{\"end\":21252,\"start\":21228},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":21276,\"start\":21252},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":21306,\"start\":21276},{\"end\":21380,\"start\":21360},{\"end\":21399,\"start\":21380},{\"end\":21420,\"start\":21399},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21438,\"start\":21420},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":21471,\"start\":21451},{\"end\":21506,\"start\":21489},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":21524,\"start\":21506},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":21969,\"start\":21947},{\"end\":21991,\"start\":21969},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22086,\"start\":22066},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":22236,\"start\":22214},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22287,\"start\":22266},{\"end\":22661,\"start\":22643},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":22828,\"start\":22810},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23273,\"start\":23255},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23370,\"start\":23353},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":23573,\"start\":23548},{\"end\":23701,\"start\":23684},{\"end\":24082,\"start\":24060},{\"end\":24134,\"start\":24110},{\"end\":24868,\"start\":24844},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":24885,\"start\":24868},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":24905,\"start\":24885},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":24934,\"start\":24917},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":24990,\"start\":24963},{\"end\":25855,\"start\":25853},{\"end\":26543,\"start\":26533},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":26606,\"start\":26589},{\"end\":26734,\"start\":26733},{\"end\":27299,\"start\":27297},{\"end\":27635,\"start\":27611},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":28009,\"start\":27991},{\"end\":28225,\"start\":28223},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":28341,\"start\":28324},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":28395,\"start\":28375},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":28690,\"start\":28673},{\"end\":28724,\"start\":28722},{\"end\":29587,\"start\":29566},{\"end\":29670,\"start\":29668},{\"end\":29751,\"start\":29737},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":29778,\"start\":29751},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":29870,\"start\":29853},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29967,\"start\":29947},{\"end\":29971,\"start\":29969},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":30230,\"start\":30212},{\"end\":30253,\"start\":30230},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":31229,\"start\":31212},{\"end\":31493,\"start\":31491},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":31623,\"start\":31606},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":31684,\"start\":31666},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":31825,\"start\":31808},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":32087,\"start\":32069},{\"end\":32091,\"start\":32089},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":32629,\"start\":32612},{\"end\":32633,\"start\":32631},{\"end\":32719,\"start\":32717},{\"end\":33378,\"start\":33376},{\"end\":33492,\"start\":33490},{\"end\":33791,\"start\":33789},{\"end\":33849,\"start\":33847},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":33888,\"start\":33871},{\"end\":34084,\"start\":34082},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":34211,\"start\":34194},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":34443,\"start\":34426},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":34678,\"start\":34660},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":36887,\"start\":36864},{\"end\":36906,\"start\":36887},{\"end\":36979,\"start\":36959},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":37185,\"start\":37164},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":37207,\"start\":37187},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":37279,\"start\":37262},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":38636,\"start\":38620},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":41024,\"start\":41004},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":41330,\"start\":41313},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":50730,\"start\":50713},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":51044,\"start\":51026},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":51211,\"start\":51194},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":51298,\"start\":51281},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":51401,\"start\":51384}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":40819,\"start\":40615},{\"attributes\":{\"id\":\"fig_1\"},\"end\":40835,\"start\":40820},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":40876,\"start\":40836},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":40973,\"start\":40877},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":41235,\"start\":40974},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":41331,\"start\":41236},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":48846,\"start\":41332}]", "paragraph": "[{\"end\":2281,\"start\":1310},{\"end\":3744,\"start\":2283},{\"end\":4519,\"start\":3746},{\"end\":5792,\"start\":4521},{\"end\":6555,\"start\":5794},{\"end\":6791,\"start\":6565},{\"end\":7013,\"start\":6940},{\"end\":7874,\"start\":7066},{\"end\":8186,\"start\":7894},{\"end\":8854,\"start\":8432},{\"end\":9492,\"start\":8895},{\"end\":9752,\"start\":9515},{\"end\":9965,\"start\":9885},{\"end\":10249,\"start\":10234},{\"end\":10299,\"start\":10288},{\"end\":10731,\"start\":10473},{\"end\":11241,\"start\":10733},{\"end\":11642,\"start\":11264},{\"end\":12608,\"start\":11655},{\"end\":13039,\"start\":12655},{\"end\":13564,\"start\":13089},{\"end\":14044,\"start\":13566},{\"end\":14451,\"start\":14076},{\"end\":15374,\"start\":14495},{\"end\":16150,\"start\":15434},{\"end\":16811,\"start\":16152},{\"end\":17651,\"start\":16813},{\"end\":18951,\"start\":17689},{\"end\":20212,\"start\":18985},{\"end\":20902,\"start\":20229},{\"end\":21814,\"start\":20904},{\"end\":22476,\"start\":21816},{\"end\":23878,\"start\":22478},{\"end\":24677,\"start\":23901},{\"end\":25020,\"start\":24700},{\"end\":26068,\"start\":25059},{\"end\":26607,\"start\":26080},{\"end\":27813,\"start\":26636},{\"end\":28998,\"start\":27843},{\"end\":30494,\"start\":29000},{\"end\":31826,\"start\":30515},{\"end\":34593,\"start\":31847},{\"end\":35144,\"start\":34624},{\"end\":35665,\"start\":35188},{\"end\":36438,\"start\":35680},{\"end\":36778,\"start\":36457},{\"end\":37208,\"start\":36816},{\"end\":37705,\"start\":37227},{\"end\":37938,\"start\":37742},{\"end\":38036,\"start\":37940},{\"end\":38115,\"start\":38070},{\"end\":38276,\"start\":38161},{\"end\":39117,\"start\":38377},{\"end\":39404,\"start\":39119},{\"end\":39782,\"start\":39406},{\"end\":40236,\"start\":39825},{\"end\":40420,\"start\":40238},{\"end\":40614,\"start\":40464}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":6939,\"start\":6792},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7065,\"start\":7014},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8431,\"start\":8187},{\"attributes\":{\"id\":\"formula_3\"},\"end\":9884,\"start\":9753},{\"attributes\":{\"id\":\"formula_4\"},\"end\":10007,\"start\":9966},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10029,\"start\":10007},{\"attributes\":{\"id\":\"formula_6\"},\"end\":10212,\"start\":10029},{\"attributes\":{\"id\":\"formula_7\"},\"end\":10451,\"start\":10300},{\"attributes\":{\"id\":\"formula_9\"},\"end\":13088,\"start\":13040},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14494,\"start\":14452},{\"attributes\":{\"id\":\"formula_11\"},\"end\":15433,\"start\":15375},{\"attributes\":{\"id\":\"formula_12\"},\"end\":17688,\"start\":17652},{\"attributes\":{\"id\":\"formula_14\"},\"end\":38069,\"start\":38037},{\"attributes\":{\"id\":\"formula_15\"},\"end\":38160,\"start\":38116},{\"attributes\":{\"id\":\"formula_16\"},\"end\":38376,\"start\":38277},{\"attributes\":{\"id\":\"formula_19\"},\"end\":40463,\"start\":40421}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26194,\"start\":26175},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":26446,\"start\":26439},{\"end\":27096,\"start\":27089},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":27108,\"start\":27101},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":27552,\"start\":27545},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":31527,\"start\":31520},{\"end\":31784,\"start\":31777},{\"end\":33084,\"start\":33077},{\"end\":34554,\"start\":34547},{\"end\":34810,\"start\":34803}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1308,\"start\":1296},{\"attributes\":{\"n\":\"2\"},\"end\":6563,\"start\":6558},{\"attributes\":{\"n\":\"2.1\"},\"end\":7892,\"start\":7877},{\"attributes\":{\"n\":\"2.1.1\"},\"end\":8893,\"start\":8857},{\"attributes\":{\"n\":\"2.1.2\"},\"end\":9513,\"start\":9495},{\"end\":10232,\"start\":10214},{\"end\":10261,\"start\":10252},{\"end\":10286,\"start\":10264},{\"end\":10471,\"start\":10453},{\"attributes\":{\"n\":\"2.2\"},\"end\":11262,\"start\":11244},{\"attributes\":{\"n\":\"3\"},\"end\":11653,\"start\":11645},{\"attributes\":{\"n\":\"3.1\"},\"end\":12653,\"start\":12611},{\"attributes\":{\"n\":\"3.2\"},\"end\":14074,\"start\":14047},{\"attributes\":{\"n\":\"3.3\"},\"end\":18983,\"start\":18954},{\"attributes\":{\"n\":\"4\"},\"end\":20227,\"start\":20215},{\"attributes\":{\"n\":\"5\"},\"end\":23899,\"start\":23881},{\"attributes\":{\"n\":\"5.1\"},\"end\":24698,\"start\":24680},{\"attributes\":{\"n\":\"5.2\"},\"end\":25057,\"start\":25023},{\"attributes\":{\"n\":\"6\"},\"end\":26078,\"start\":26071},{\"attributes\":{\"n\":\"6.1\"},\"end\":26634,\"start\":26610},{\"attributes\":{\"n\":\"6.2\"},\"end\":27841,\"start\":27816},{\"attributes\":{\"n\":\"6.3\"},\"end\":30513,\"start\":30497},{\"attributes\":{\"n\":\"6.4\"},\"end\":31845,\"start\":31829},{\"attributes\":{\"n\":\"7\"},\"end\":34604,\"start\":34596},{\"attributes\":{\"n\":\"7.1\"},\"end\":34622,\"start\":34607},{\"attributes\":{\"n\":\"7.2\"},\"end\":35186,\"start\":35147},{\"attributes\":{\"n\":\"8\"},\"end\":35678,\"start\":35668},{\"end\":36455,\"start\":36441},{\"end\":36814,\"start\":36781},{\"end\":37225,\"start\":37211},{\"end\":37740,\"start\":37708},{\"end\":39823,\"start\":39785},{\"end\":40831,\"start\":40821},{\"end\":40846,\"start\":40837},{\"end\":40887,\"start\":40878},{\"end\":41246,\"start\":41237}]", "table": "[{\"end\":41235,\"start\":41097},{\"end\":48846,\"start\":44674}]", "figure_caption": "[{\"end\":40819,\"start\":40617},{\"end\":40835,\"start\":40833},{\"end\":40876,\"start\":40848},{\"end\":40973,\"start\":40889},{\"end\":41097,\"start\":40976},{\"end\":41331,\"start\":41248},{\"end\":44674,\"start\":41334}]", "figure_ref": "[{\"end\":8556,\"start\":8548},{\"end\":10504,\"start\":10496},{\"end\":10809,\"start\":10803},{\"end\":11240,\"start\":11234},{\"end\":14777,\"start\":14771},{\"end\":35296,\"start\":35290},{\"end\":35307,\"start\":35301},{\"end\":35581,\"start\":35575},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":39493,\"start\":39487}]", "bib_author_first_name": "[{\"end\":63164,\"start\":63157},{\"end\":63183,\"start\":63175},{\"end\":63198,\"start\":63192},{\"end\":63210,\"start\":63203},{\"end\":63222,\"start\":63218},{\"end\":63235,\"start\":63229},{\"end\":63405,\"start\":63399},{\"end\":63606,\"start\":63599},{\"end\":63626,\"start\":63617},{\"end\":63638,\"start\":63632},{\"end\":63855,\"start\":63848},{\"end\":63864,\"start\":63863},{\"end\":63879,\"start\":63872},{\"end\":63881,\"start\":63880},{\"end\":64463,\"start\":64458},{\"end\":64475,\"start\":64471},{\"end\":64486,\"start\":64482},{\"end\":64488,\"start\":64487},{\"end\":64501,\"start\":64493},{\"end\":64515,\"start\":64511},{\"end\":64829,\"start\":64823},{\"end\":64851,\"start\":64848},{\"end\":64864,\"start\":64861},{\"end\":65560,\"start\":65554},{\"end\":65571,\"start\":65567},{\"end\":65578,\"start\":65576},{\"end\":65588,\"start\":65585},{\"end\":65600,\"start\":65594},{\"end\":65613,\"start\":65606},{\"end\":65615,\"start\":65614},{\"end\":65866,\"start\":65859},{\"end\":66135,\"start\":66131},{\"end\":66149,\"start\":66142},{\"end\":66162,\"start\":66155},{\"end\":66171,\"start\":66169},{\"end\":66180,\"start\":66177},{\"end\":66395,\"start\":66387},{\"end\":66410,\"start\":66403},{\"end\":66986,\"start\":66980},{\"end\":66999,\"start\":66993},{\"end\":67014,\"start\":67009},{\"end\":67031,\"start\":67026},{\"end\":67730,\"start\":67725},{\"end\":67746,\"start\":67739},{\"end\":67762,\"start\":67753},{\"end\":67764,\"start\":67763},{\"end\":68522,\"start\":68517},{\"end\":68538,\"start\":68531},{\"end\":68800,\"start\":68793},{\"end\":68816,\"start\":68812},{\"end\":69198,\"start\":69191},{\"end\":69207,\"start\":69206},{\"end\":69572,\"start\":69566},{\"end\":69588,\"start\":69581},{\"end\":69603,\"start\":69596},{\"end\":69800,\"start\":69796},{\"end\":69812,\"start\":69808},{\"end\":70411,\"start\":70407},{\"end\":70422,\"start\":70418},{\"end\":70986,\"start\":70979},{\"end\":70998,\"start\":70993},{\"end\":71015,\"start\":71008},{\"end\":71032,\"start\":71024},{\"end\":71274,\"start\":71265},{\"end\":71276,\"start\":71275},{\"end\":71288,\"start\":71283},{\"end\":71302,\"start\":71297},{\"end\":71866,\"start\":71862},{\"end\":71878,\"start\":71877},{\"end\":71888,\"start\":71887},{\"end\":72156,\"start\":72149},{\"end\":72163,\"start\":72162},{\"end\":72182,\"start\":72171},{\"end\":72184,\"start\":72183},{\"end\":72779,\"start\":72776},{\"end\":72795,\"start\":72788},{\"end\":73003,\"start\":72997},{\"end\":73022,\"start\":73017},{\"end\":73024,\"start\":73023},{\"end\":73036,\"start\":73033},{\"end\":73339,\"start\":73332},{\"end\":73349,\"start\":73345},{\"end\":73358,\"start\":73355},{\"end\":73372,\"start\":73365},{\"end\":73381,\"start\":73377},{\"end\":73642,\"start\":73637},{\"end\":73655,\"start\":73648},{\"end\":73668,\"start\":73661},{\"end\":73870,\"start\":73865},{\"end\":73884,\"start\":73880},{\"end\":73902,\"start\":73893},{\"end\":74161,\"start\":74156},{\"end\":74176,\"start\":74171},{\"end\":74195,\"start\":74188},{\"end\":74317,\"start\":74316},{\"end\":74319,\"start\":74318},{\"end\":74331,\"start\":74330},{\"end\":74338,\"start\":74337},{\"end\":74647,\"start\":74644},{\"end\":74662,\"start\":74654},{\"end\":74679,\"start\":74672},{\"end\":74696,\"start\":74687},{\"end\":74711,\"start\":74704},{\"end\":75102,\"start\":75096},{\"end\":75104,\"start\":75103},{\"end\":75336,\"start\":75331},{\"end\":75350,\"start\":75344},{\"end\":75364,\"start\":75357},{\"end\":75683,\"start\":75677},{\"end\":75693,\"start\":75690},{\"end\":75704,\"start\":75700},{\"end\":75714,\"start\":75710}]", "bib_author_last_name": "[{\"end\":63173,\"start\":63165},{\"end\":63190,\"start\":63184},{\"end\":63201,\"start\":63199},{\"end\":63216,\"start\":63211},{\"end\":63227,\"start\":63223},{\"end\":63242,\"start\":63236},{\"end\":63415,\"start\":63406},{\"end\":63423,\"start\":63417},{\"end\":63615,\"start\":63607},{\"end\":63630,\"start\":63627},{\"end\":63645,\"start\":63639},{\"end\":63861,\"start\":63856},{\"end\":63870,\"start\":63865},{\"end\":63888,\"start\":63882},{\"end\":63898,\"start\":63890},{\"end\":64469,\"start\":64464},{\"end\":64480,\"start\":64476},{\"end\":64491,\"start\":64489},{\"end\":64509,\"start\":64502},{\"end\":64522,\"start\":64516},{\"end\":64846,\"start\":64830},{\"end\":64859,\"start\":64852},{\"end\":64870,\"start\":64865},{\"end\":65565,\"start\":65561},{\"end\":65574,\"start\":65572},{\"end\":65583,\"start\":65579},{\"end\":65592,\"start\":65589},{\"end\":65604,\"start\":65601},{\"end\":65626,\"start\":65616},{\"end\":65884,\"start\":65867},{\"end\":65894,\"start\":65886},{\"end\":66140,\"start\":66136},{\"end\":66153,\"start\":66150},{\"end\":66167,\"start\":66163},{\"end\":66175,\"start\":66172},{\"end\":66186,\"start\":66181},{\"end\":66401,\"start\":66396},{\"end\":66417,\"start\":66411},{\"end\":66991,\"start\":66987},{\"end\":67007,\"start\":67000},{\"end\":67024,\"start\":67015},{\"end\":67042,\"start\":67032},{\"end\":67737,\"start\":67731},{\"end\":67751,\"start\":67747},{\"end\":67769,\"start\":67765},{\"end\":68529,\"start\":68523},{\"end\":68545,\"start\":68539},{\"end\":68810,\"start\":68801},{\"end\":68822,\"start\":68817},{\"end\":69204,\"start\":69199},{\"end\":69214,\"start\":69208},{\"end\":69226,\"start\":69216},{\"end\":69579,\"start\":69573},{\"end\":69594,\"start\":69589},{\"end\":69610,\"start\":69604},{\"end\":69806,\"start\":69801},{\"end\":69817,\"start\":69813},{\"end\":70416,\"start\":70412},{\"end\":70426,\"start\":70423},{\"end\":70991,\"start\":70987},{\"end\":71006,\"start\":70999},{\"end\":71022,\"start\":71016},{\"end\":71037,\"start\":71033},{\"end\":71046,\"start\":71039},{\"end\":71281,\"start\":71277},{\"end\":71295,\"start\":71289},{\"end\":71309,\"start\":71303},{\"end\":71875,\"start\":71867},{\"end\":71885,\"start\":71879},{\"end\":71896,\"start\":71889},{\"end\":71905,\"start\":71898},{\"end\":72160,\"start\":72157},{\"end\":72169,\"start\":72164},{\"end\":72188,\"start\":72185},{\"end\":72197,\"start\":72190},{\"end\":72786,\"start\":72780},{\"end\":72802,\"start\":72796},{\"end\":73015,\"start\":73004},{\"end\":73031,\"start\":73025},{\"end\":73048,\"start\":73037},{\"end\":73343,\"start\":73340},{\"end\":73353,\"start\":73350},{\"end\":73363,\"start\":73359},{\"end\":73375,\"start\":73373},{\"end\":73386,\"start\":73382},{\"end\":73646,\"start\":73643},{\"end\":73659,\"start\":73656},{\"end\":73673,\"start\":73669},{\"end\":73878,\"start\":73871},{\"end\":73891,\"start\":73885},{\"end\":73909,\"start\":73903},{\"end\":74169,\"start\":74162},{\"end\":74186,\"start\":74177},{\"end\":74202,\"start\":74196},{\"end\":74328,\"start\":74320},{\"end\":74335,\"start\":74332},{\"end\":74347,\"start\":74339},{\"end\":74356,\"start\":74349},{\"end\":74652,\"start\":74648},{\"end\":74670,\"start\":74663},{\"end\":74685,\"start\":74680},{\"end\":74702,\"start\":74697},{\"end\":74718,\"start\":74712},{\"end\":75113,\"start\":75105},{\"end\":75342,\"start\":75337},{\"end\":75355,\"start\":75351},{\"end\":75373,\"start\":75365},{\"end\":75688,\"start\":75684},{\"end\":75698,\"start\":75694},{\"end\":75708,\"start\":75705},{\"end\":75719,\"start\":75715}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":63346,\"start\":63155},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":14096841},\"end\":63526,\"start\":63348},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":11212020},\"end\":63792,\"start\":63528},{\"attributes\":{\"doi\":\"10.3115/1075218.1075259\",\"id\":\"b3\",\"matched_paper_id\":9952653},\"end\":64456,\"start\":63794},{\"attributes\":{\"doi\":\"1611.09940\",\"id\":\"b4\"},\"end\":64779,\"start\":64458},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15467396},\"end\":65477,\"start\":64781},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":8377315},\"end\":65800,\"start\":65479},{\"attributes\":{\"id\":\"b7\"},\"end\":66071,\"start\":65802},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":14288483},\"end\":66329,\"start\":66073},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":1499080},\"end\":66924,\"start\":66331},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1020\",\"id\":\"b10\",\"matched_paper_id\":17476563},\"end\":67646,\"start\":66926},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":133195},\"end\":68467,\"start\":67648},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":16531053},\"end\":68707,\"start\":68469},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":5923323},\"end\":69155,\"start\":68709},{\"attributes\":{\"id\":\"b14\"},\"end\":69328,\"start\":69157},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b15\"},\"end\":69509,\"start\":69330},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":21850704},\"end\":69739,\"start\":69511},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":836219},\"end\":70348,\"start\":69741},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":1846037},\"end\":70921,\"start\":70350},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":7147309},\"end\":71198,\"start\":70923},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":1918428},\"end\":71819,\"start\":71200},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":18375389},\"end\":72083,\"start\":71821},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":8314118},\"end\":72707,\"start\":72085},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":1339659},\"end\":72924,\"start\":72709},{\"attributes\":{\"doi\":\"abs/1711.00894\",\"id\":\"b24\"},\"end\":73244,\"start\":72926},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":33257417},\"end\":73556,\"start\":73246},{\"attributes\":{\"id\":\"b26\"},\"end\":73817,\"start\":73558},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":13948549},\"end\":74136,\"start\":73819},{\"attributes\":{\"id\":\"b28\"},\"end\":74314,\"start\":74138},{\"attributes\":{\"id\":\"b29\"},\"end\":74586,\"start\":74316},{\"attributes\":{\"doi\":\"10.1109/TASLP.2015.2432573\",\"id\":\"b30\",\"matched_paper_id\":14583912},\"end\":75004,\"start\":74588},{\"attributes\":{\"doi\":\"10.1007/BF00992696\",\"id\":\"b31\",\"matched_paper_id\":2332513},\"end\":75299,\"start\":75006},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":62613480},\"end\":75616,\"start\":75301},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1101\",\"id\":\"b33\",\"matched_paper_id\":1770102},\"end\":76235,\"start\":75618}]", "bib_title": "[{\"end\":63397,\"start\":63348},{\"end\":63597,\"start\":63528},{\"end\":63846,\"start\":63794},{\"end\":64821,\"start\":64781},{\"end\":65552,\"start\":65479},{\"end\":66129,\"start\":66073},{\"end\":66385,\"start\":66331},{\"end\":66978,\"start\":66926},{\"end\":67723,\"start\":67648},{\"end\":68515,\"start\":68469},{\"end\":68791,\"start\":68709},{\"end\":69564,\"start\":69511},{\"end\":69794,\"start\":69741},{\"end\":70405,\"start\":70350},{\"end\":70977,\"start\":70923},{\"end\":71263,\"start\":71200},{\"end\":71860,\"start\":71821},{\"end\":72147,\"start\":72085},{\"end\":72774,\"start\":72709},{\"end\":73330,\"start\":73246},{\"end\":73863,\"start\":73819},{\"end\":74642,\"start\":74588},{\"end\":75094,\"start\":75006},{\"end\":75329,\"start\":75301},{\"end\":75675,\"start\":75618}]", "bib_author": "[{\"end\":63175,\"start\":63157},{\"end\":63192,\"start\":63175},{\"end\":63203,\"start\":63192},{\"end\":63218,\"start\":63203},{\"end\":63229,\"start\":63218},{\"end\":63244,\"start\":63229},{\"end\":63417,\"start\":63399},{\"end\":63425,\"start\":63417},{\"end\":63617,\"start\":63599},{\"end\":63632,\"start\":63617},{\"end\":63647,\"start\":63632},{\"end\":63863,\"start\":63848},{\"end\":63872,\"start\":63863},{\"end\":63890,\"start\":63872},{\"end\":63900,\"start\":63890},{\"end\":64471,\"start\":64458},{\"end\":64482,\"start\":64471},{\"end\":64493,\"start\":64482},{\"end\":64511,\"start\":64493},{\"end\":64524,\"start\":64511},{\"end\":64848,\"start\":64823},{\"end\":64861,\"start\":64848},{\"end\":64872,\"start\":64861},{\"end\":65567,\"start\":65554},{\"end\":65576,\"start\":65567},{\"end\":65585,\"start\":65576},{\"end\":65594,\"start\":65585},{\"end\":65606,\"start\":65594},{\"end\":65628,\"start\":65606},{\"end\":65886,\"start\":65859},{\"end\":65896,\"start\":65886},{\"end\":66142,\"start\":66131},{\"end\":66155,\"start\":66142},{\"end\":66169,\"start\":66155},{\"end\":66177,\"start\":66169},{\"end\":66188,\"start\":66177},{\"end\":66403,\"start\":66387},{\"end\":66419,\"start\":66403},{\"end\":66993,\"start\":66980},{\"end\":67009,\"start\":66993},{\"end\":67026,\"start\":67009},{\"end\":67044,\"start\":67026},{\"end\":67739,\"start\":67725},{\"end\":67753,\"start\":67739},{\"end\":67771,\"start\":67753},{\"end\":68531,\"start\":68517},{\"end\":68547,\"start\":68531},{\"end\":68812,\"start\":68793},{\"end\":68824,\"start\":68812},{\"end\":69206,\"start\":69191},{\"end\":69216,\"start\":69206},{\"end\":69228,\"start\":69216},{\"end\":69581,\"start\":69566},{\"end\":69596,\"start\":69581},{\"end\":69612,\"start\":69596},{\"end\":69808,\"start\":69796},{\"end\":69819,\"start\":69808},{\"end\":70418,\"start\":70407},{\"end\":70428,\"start\":70418},{\"end\":70993,\"start\":70979},{\"end\":71008,\"start\":70993},{\"end\":71024,\"start\":71008},{\"end\":71039,\"start\":71024},{\"end\":71048,\"start\":71039},{\"end\":71283,\"start\":71265},{\"end\":71297,\"start\":71283},{\"end\":71311,\"start\":71297},{\"end\":71877,\"start\":71862},{\"end\":71887,\"start\":71877},{\"end\":71898,\"start\":71887},{\"end\":71907,\"start\":71898},{\"end\":72162,\"start\":72149},{\"end\":72171,\"start\":72162},{\"end\":72190,\"start\":72171},{\"end\":72199,\"start\":72190},{\"end\":72788,\"start\":72776},{\"end\":72804,\"start\":72788},{\"end\":73017,\"start\":72997},{\"end\":73033,\"start\":73017},{\"end\":73050,\"start\":73033},{\"end\":73345,\"start\":73332},{\"end\":73355,\"start\":73345},{\"end\":73365,\"start\":73355},{\"end\":73377,\"start\":73365},{\"end\":73388,\"start\":73377},{\"end\":73648,\"start\":73637},{\"end\":73661,\"start\":73648},{\"end\":73675,\"start\":73661},{\"end\":73880,\"start\":73865},{\"end\":73893,\"start\":73880},{\"end\":73911,\"start\":73893},{\"end\":74171,\"start\":74156},{\"end\":74188,\"start\":74171},{\"end\":74204,\"start\":74188},{\"end\":74330,\"start\":74316},{\"end\":74337,\"start\":74330},{\"end\":74349,\"start\":74337},{\"end\":74358,\"start\":74349},{\"end\":74654,\"start\":74644},{\"end\":74672,\"start\":74654},{\"end\":74687,\"start\":74672},{\"end\":74704,\"start\":74687},{\"end\":74720,\"start\":74704},{\"end\":75115,\"start\":75096},{\"end\":75344,\"start\":75331},{\"end\":75357,\"start\":75344},{\"end\":75375,\"start\":75357},{\"end\":75690,\"start\":75677},{\"end\":75700,\"start\":75690},{\"end\":75710,\"start\":75700},{\"end\":75721,\"start\":75710}]", "bib_venue": "[{\"end\":63429,\"start\":63425},{\"end\":63651,\"start\":63647},{\"end\":64015,\"start\":63923},{\"end\":64595,\"start\":64534},{\"end\":64988,\"start\":64872},{\"end\":65631,\"start\":65628},{\"end\":65857,\"start\":65802},{\"end\":66193,\"start\":66188},{\"end\":66506,\"start\":66419},{\"end\":67151,\"start\":67064},{\"end\":67913,\"start\":67771},{\"end\":68572,\"start\":68547},{\"end\":68896,\"start\":68824},{\"end\":69189,\"start\":69157},{\"end\":69374,\"start\":69334},{\"end\":69616,\"start\":69612},{\"end\":69926,\"start\":69819},{\"end\":70514,\"start\":70428},{\"end\":71052,\"start\":71048},{\"end\":71397,\"start\":71311},{\"end\":71945,\"start\":71907},{\"end\":72286,\"start\":72199},{\"end\":72808,\"start\":72804},{\"end\":72995,\"start\":72926},{\"end\":73392,\"start\":73388},{\"end\":73635,\"start\":73558},{\"end\":73963,\"start\":73911},{\"end\":74154,\"start\":74138},{\"end\":74407,\"start\":74358},{\"end\":74790,\"start\":74746},{\"end\":75144,\"start\":75133},{\"end\":75421,\"start\":75375},{\"end\":75828,\"start\":75741},{\"end\":64114,\"start\":64017},{\"end\":65111,\"start\":64990},{\"end\":66595,\"start\":66508},{\"end\":67225,\"start\":67153},{\"end\":68063,\"start\":67915},{\"end\":68955,\"start\":68898},{\"end\":69422,\"start\":69376},{\"end\":70020,\"start\":69928},{\"end\":70611,\"start\":70516},{\"end\":71486,\"start\":71399},{\"end\":72360,\"start\":72288},{\"end\":75444,\"start\":75423},{\"end\":75902,\"start\":75830}]"}}}, "year": 2023, "month": 12, "day": 17}