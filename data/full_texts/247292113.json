{"id": 247292113, "updated": "2023-12-14 08:01:14.95", "metadata": {"title": "Multi-CPR: A Multi Domain Chinese Dataset for Passage Retrieval", "authors": "[{\"first\":\"Dingkun\",\"last\":\"Long\",\"middle\":[]},{\"first\":\"Qiong\",\"last\":\"Gao\",\"middle\":[]},{\"first\":\"Kuan\",\"last\":\"Zou\",\"middle\":[]},{\"first\":\"Guangwei\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Pengjun\",\"last\":\"Xie\",\"middle\":[]},{\"first\":\"Ruijie\",\"last\":\"Guo\",\"middle\":[]},{\"first\":\"Jian\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Guanjun\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Luxi\",\"last\":\"Xing\",\"middle\":[]},{\"first\":\"Ping\",\"last\":\"Yang\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Passage retrieval is a fundamental task in information retrieval (IR) research, which has drawn much attention recently. In the English field, the availability of large-scale annotated dataset (e.g, MS MARCO) and the emergence of deep pre-trained language models (e.g, BERT) has resulted in a substantial improvement of existing passage retrieval systems. However, in the Chinese field, especially for specific domains, passage retrieval systems are still immature due to quality-annotated dataset being limited by scale. Therefore, in this paper, we present a novel multi-domain Chinese dataset for passage retrieval (Multi-CPR). The dataset is collected from three different domains, including E-commerce, Entertainment video and Medical. Each dataset contains millions of passages and a certain amount of human annotated query-passage related pairs. We implement various representative passage retrieval methods as baselines. We find that the performance of retrieval models trained on dataset from general domain will inevitably decrease on specific domain. Nevertheless, a passage retrieval system built on in-domain annotated dataset can achieve significant improvement, which indeed demonstrates the necessity of domain labeled data for further optimization. We hope the release of the Multi-CPR dataset could benchmark Chinese passage retrieval task in specific domain and also make advances for future studies.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigir/LongGZXXGXJXY22", "doi": "10.1145/3477495.3531736"}}, "content": {"source": {"pdf_hash": "4529a0d6ba1720ce57ad81cc5c74ccca403262f7", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2203.03367v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "2e016af198c7eba01b5d55bbeb011f7a989558a7", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/4529a0d6ba1720ce57ad81cc5c74ccca403262f7.txt", "contents": "\nMulti Domain Chinese Dataset for Passage Retrieval\nACMCopyright ACMJuly 11-15, 2022\n\nDingkun Long dingkun.ldk@alibaba-inc.com \nAlibaba Group Hangzhou\nChina\n\nQiong Gao gaoqiong.gao@alibaba-inc.com \nAlibaba Group Hangzhou\nChina\n\nKuan Zou zoukuan.zk@alibaba-inc.com \nAlibaba Group Hangzhou\nChina\n\nGuangwei Xu \nAlibaba Group Hangzhou\nChina\n\nPengjun Xie \nAlibaba Group Hangzhou\nChina\n\nRuijie Guo ruijie.guo@alibaba-inc.com \nAlibaba Group Hangzhou\nChina\n\nJian Xu \nAlibaba Group Hangzhou\nChina\n\nGuanjun Jiang guanj.jianggj@alibaba-inc.com \nAlibaba Group Hangzhou\nChina\n\nLuxi Xing luxi.xlx@alibaba-inc.com \nAlibaba Group Hangzhou\nChina\n\nPing Yang \nAlibaba Group Hangzhou\nChina\n\nDingkun Long \nAlibaba Group Hangzhou\nChina\n\nQiong Gao \nAlibaba Group Hangzhou\nChina\n\nKuan Zou \nAlibaba Group Hangzhou\nChina\n\nGuangwei Xu \nAlibaba Group Hangzhou\nChina\n\nPengjun Xie \nAlibaba Group Hangzhou\nChina\n\nRuijie Guo \nAlibaba Group Hangzhou\nChina\n\nJian Xu \nAlibaba Group Hangzhou\nChina\n\nGuanjun Jiang \nAlibaba Group Hangzhou\nChina\n\nLuxi Xing \nAlibaba Group Hangzhou\nChina\n\nPing Yang \nAlibaba Group Hangzhou\nChina\n\nMulti Domain Chinese Dataset for Passage Retrieval\n\nProceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22)\nthe 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22)Madrid, Spain; New York, NY, USAACM11July 11-15, 202210.1145/3477495.3531736ACM Reference Format:\nPassage retrieval is a fundamental task in information retrieval (IR) research, which has drawn much attention recently. In the English field, the availability of large-scale annotated dataset (e.g, MS MARCO) and the emergence of deep pre-trained language models (e.g, BERT) has resulted in a substantial improvement of existing passage retrieval systems. However, in the Chinese field, especially for specific domains, passage retrieval systems are still immature due to quality-annotated dataset being limited by scale. Therefore, in this paper, we present a novel multi-domain Chinese dataset for passage retrieval (Multi-CPR). The dataset is collected from three different domains, including E-commerce, Entertainment video and Medical. Each dataset contains millions of passages and a certain amount of human annotated query-passage related pairs. We implement various representative passage retrieval methods as baselines. We find that the performance of retrieval models trained on dataset from general domain will inevitably decrease on specific domain. Nevertheless, a passage retrieval system built on in-domain annotated dataset can achieve significant improvement, which indeed demonstrates the necessity of domain labeled data for further optimization. We hope the release of the Multi-CPR dataset could benchmark Chinese passage retrieval task in specific domain and also make advances for future studies.\n\nINTRODUCTION\n\nLarge scale passage retrieval is an important problem in information retrieval research field. Passage retrieval is often regarded Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '22, July 11-15, 2022 [26,30], machine reading comprehension [36,43] and web search systems [4], etc. Recent advances in deep learning have allowed state of the art performance on passage retrieval task compared to conventional statistical models [15-17, 26, 42]. However, these deep neural models usually contain millions of parameters that necessitate a large amount of training data. As such, high-quality public available benchmark dataset is critical for research progress with a deep-model fashion for the passage retrieval task.\n\nIn the English field, we observed that large, high-quality dataset enables the community rapidly develop new models for passage retrieval task, and at the same time, the research on model architecture also obtains a more deep understanding. As mentioned above, passage retrieval mainly serves downstream tasks such as question answering and machine reading comprehension. Therefore, existing datasets are also constructed based on the above two tasks. In term of question answering, there are several benchmark datasets like TREC QA [48], WikiPassageQA [6] and InsuranceQA [14]. For machine reading comprehension task, representative datasets including SQuAD [44], MS MARCO [5], CNN /Daily News [23] provide good benchmarks. In summary, dataset in the English field is relatively mature in terms of data scale and domain richness. On the other hand, in the field of Chinese, although some information retrieval datasets and machine reading comprehension datasets have been released in recent years like Sogou-QCL [55], Dureader [22] and SC-MRC [8], these datasets are mainly concentrated in the general domain, and dataset that can be adopted for specific domain passage retrieval research is still in shortage.\n\nTo push forward the quality and variety of Chinese passage retrieval dataset, we present Multi-CPR. There are three main properties of Multi-CPR: a) Multi-CPR is the first dataset that covers multiple specific domains for Chinese passage retrieval, including E-commerce, Entertainment video and Medical. There is a high degree of differentiation within the three domains. Furthermore, Only one (Medical) of these domains has been studied in previous research [54]. b) Multi-CPR is the largest domain specific Chinese passage retrieval dataset. For each domain, Multi-CPR contains millions of passages (e,g. 1,002,822 passages for the E-commerce domain) and sufficient human annotated query-passage related pairs. More detailed statistics of Multi-CPR and annotated examples can be found in Table 4 and Section 3.2. c) All Queries and passages in Multi-CPR are collected from real search engine systems within Alibaba Group. The authenticity of the samples allows Multi-CPR to meet the needs of both academia and industry fields.\n\nAs an attempt to tackle Multi-CPR and provide strong baselines, we implement various representative passage retrieval methods including both sparse and dense models. For the sparse models, except for the basic BM25 method, we also verified that previously proposed optimization methods based on the sparse strategy can indeed achieve significant improvement compared to the BM25 baseline (e,g, doc2query method). For the dense models, we mainly implemented methods based on the DPR model. Similarly, we also made some optimizations based on the DPR model. Compared to the sparse models, we found that the retrieval performance of the dense models trained on labeled dataset can be greatly improved. This observation empirically confirms the value of annotated data. In further, we verified that the retrieval-then-reranking two-stage framework based on the BERT model can further improve the overall retrieval performance on all three datasets in Multi-CPR, which once again corroborates the quality of Multi-CPR.\n\nIn summary, the major contributions of this paper are threefold:\n\n\u2022 We present Multi-CPR, the largest-scale Chinese multi domain passage retrieval dataset collected from practical search engine systems, and it covers E-commence, Entaitement vedio and Medical domain. \u2022 We conduct an in-depth analysis on Multi-CPR. Based on Multi-CPR, we have analyzed the characteristics of different passage retrieval methods along with their optimization strategies associated, which enables us to have a deeper understanding of Chinese passage retrieval task in specific domain. \u2022 We implement various representative methods as baselines and show the performance of existing methods on Multi-CPR, which provides an outlook for future research.\n\n\nRELATED WORK\n\nPassage Retrieval Passage retrieval task aims to recall all potentially relevant passages from a large corpus given an informationseeking query. In practical, passage retrieval is often an important step in other information retrieval tasks [4]. Traditional passage retrieval systems usually rely on term-based retrieval models like BM25 [46]. Recently, with the rapid development in text representation learning research [3] and deep pre-trained language models [21,27,33,51], dense retrieval combined with pre-trained language models, has become a popular paradigm to improve retrieval performance [16,26,42]. In general, dense models significantly outperform traditional term-based retrieval models in terms of effectiveness and benefit downstream tasks. In a basic concept, the core problem of passage retrieval is how to form the text representation and then compute text similarity. Thus, based on the text representation type and corpus index mode, passage retrieval models can be roughly categorized into two main classes. Sparse retrieval Models: improving retrieval by obtaining semantic-captured sparse representations and indexing them with the inverted index for efficient retrieval; Dense Retrieval Models: converting query and passage into continuous embedding representations and turning to approximate nearest neighbor (ANN) algorithms for fast retrieval [13].\n\nFor the above two types of models, the current optimization directions are not the same. Specifically, Sparse retrieval models \nPassage \u5927 \u4eba \u4e0d \u80fd \u628a \u624b \u653e \u5728 \u7761 \u89c9 \u5a74 \u513f \u80f8 \u53e3 \uff0c \u5bf9 \u5b69 \u5b50 \u547c \u5438 \u4e0d \u597d \uff0c \u8981 \u6ce8 \u610f (\nAdults should not put their hands on the chest of a sleeping baby as this is not good for the baby's breathing.)\n\nfocus on improving retrieval performance by either enhancing the bag-of-words (BoW) representations in classical term-based methods or mapping input texts into latent space (e,g. doc2query [37], query expansion [7] and document expansion [39]). The sparse representation has attracted great attention as it can be easily integrated into the inverted index for efficient retrieval. Recently, With the development of deep neural networks, pre-trained language models have been widely employed to improve the capacity of sparse retrieval models, including term re-weighting [9,10], sparse representation learning [24,50], etc. The mainstream of existing studies on improving the performance of dense retrieval models can be roughly divided into three groups. 1) Designing more powerful pre-trained language model architectures for the passage retrieval task and then improving the quality of sentence representation. For example, [15,16] proposed the Condenser family models. 2) Applying pre-training methods for dense retrieval is to use pre-trained models as encoders, and then fine-tuned with labeled dataset. In the fine-tuning stage, existing research work attempted to select more reasonable hard negative samples [49,52]. 3) Existing stateof-the-art retrieval systems usually leverage a two-stage (retrievalthen-reranking) framework. Different from the previous traditional pipeline model, [45] and [53] proposed to better leverage the feedback from reranker to promote the performance of retrieval stage via joint learning and adversarial learning respectively. Related Datasets As mentioned above, the emergence of largescale high-quality labeled data has greatly promoted the optimization process of passage retrieval models. Among all these datasets, MS MARCO [5] is the most representative dataset in the English field. MS MARCO is a passage and document ranking dataset introduced by Microsoft. The passage ranking task focuses on ranking passages from a collection of about 8.8 million, which are gathered from Bing's results to real-world queries. About 808 thousand queries paired with relevant passages are provided for supervised training. Each query is associated with sparse relevance judgments of one (or very few) passages marked as relevant and no passages explicitly indicated as irrelevant.\n\nIn the Chinese field, there are some datasets built based on web page retrieval systems, for example, Sougou-QCL [55]. The Sogou-QCL dataset was created to support research on information retrieval and related human language technologies. The dataset consists of 537,366 queries, more than 9 million Chinese web pages, and five kinds of relevance labels assessed by click models. However, this dataset is concentrated in the general domain, and the labels are obtained based on click behavior, rather than human annotation. Dureader is a recently released large-scale MRC dataset in Chinese [22]. The data distribution is mainly concentrated in the general domain. It can be converted into an information retrieval dataset. Although there are some general domain dataset available, Chinese passage retrieval annotated dataset in specific domain is still in shortage.\n\n\nDATA CONSTRUCTION 3.1 Data Collection\n\nThe core of constructing a passage retrieval dataset is to build high quality query-passage relevant pairs. To generate related querypassage pairs, we first sample some queries from the search logs of different search systems in Alibaba group. We attempt to filter out potentially relevant query-passage pairs based on user behaviors. It should be noted that not all passages clicked by the user are semantic relevant to a search query. For a commercial search engine system, the results finally displayed to users are not only decided by semantic relevance but also depended on excess features such as personalization and item popularity. For Multi-CPR, we only consider the semantic relevance between the query and passage. Therefore, to ensure the quality of the final dataset, we filter out the query-passage pairs with a relatively low number of clicks. Finally, human annotators will annotate all selected pairs to determine whether each pair is semantically related.\n\n\nData Annotation\n\nAs mentioned above, the Multi-CPR dataset covers three different specific domains. Naturally, queries in each domain are sampled from different search systems. In specific, queries in the domain of E-commerce, Entertainment video and Medical are sampled from Taobao search 1 , Youku search 2 , Quark search 3 systems respectively. During the construction of the dataset, we seek to ensure the quality and practicability of the final produced dataset in the following aspects:\n\n3.2.1 Query Distribution. For each domain, we sample queries from the search logs within a single day, and the selected queries Table 2: An example of annotated sample with multiple passages for one query in E-commerce domain.\n\n\nQuery\n\n\u9614\u817f\u88e4\u5973\u51ac\u725b\u4ed4 (Women's winter wide leg pants)\n\nLabel No are uniformly sampled based on all distinct queries. Such a sampling strategy avoids the sampled data being concentrated in highfrequency queries. Thus, the resulted passage retrieval models should also take into account the performance of long-tail queries.\nPassage-1 \u9614 \u817f \u725b \u4ed4 \u88e4 \u5973 \u79cb \u51ac \u6b3e \u6f6e \u6d41 \u767e \u642d \u5bbd \u677e (\n\nAnnotation Guideline.\n\nFor each query-passage pair, our annotation process contains only one component, . ,, to determine whether the query and the passage are truly semantically related. Since our query-passage pairs are sampled from search logs, there may be multiple relevant candidate passages for some queries, as illustrated in Table 2. For this kind of sample, we require the human annotators to compare all candidates and then mark the most semantically relevant passage as the positive, and the others as negatives. If there is no relevant passage in all candidates, then all candidates will be marked as negatives. For all domains, We summarize several basic principles to determine the relevance between the query and passage:\n\nExplicitness For each candidate pair, we require that both query and passage are semantically completed. Moreover, the search intent of query is explicit. Taking the query-passage pair <query:\u7535 \u5f71(movie), passage: \u54c8\u5229\u6ce2\u7279\u4e0e\u9b54\u77f3(Harry Potter and the Magic Stone)> as an example, the search concept of \"\u7535\u5f71 (movie)\" is quite broad, and there are many docs that can meet this search requirement. On the contrary, for pair <\u54c8\u5229\u6ce2\u7279\u7535\u5f71(harry potter movies), \u54c8\u5229\u6ce2\u7279\u4e0e\u9b54\u77f3(Harry Potter and the Magic Stone)>, the query search intent is more explicit, and the doc is semantically complete. During the annotation process, query-passage pair that violates the explicitness principle will be eliminated directly.\n\nHeadword Relevance Headwords and central topic of query and passage should be closed. For example, for the pair <\u51ac\u5b63\u9614\u817f \u88e4\u5973(women's winter wide leg pants), \u51ac\u5b63\u8fde\u8863\u88d9\u5973(women's winter dress). The headwords of query and passage are \"\u9614\u817f\u88e4 (wide-leg pants)\" and \"\u8fde\u8863\u88d9 (dress)\" respectively, which are totally different. For query \u51ac\u5b63\u9614\u817f\u88e4\u5973 (women's winter wide leg pants), the passage \u9614\u817f\u88e4\u725b\u4ed4\u51ac\u5b63\u97e9\u5f0f\u5973 (women's winter  \n\u8111 \u6897 \u585e \u662f \u7531 \u4e8e \u8111 \u90e8 \u7684 \u7f3a \u8840 \u7f3a \u6c27 \u5f15 \u8d77 \u7684 \u8111 \u7ec4 \u7ec7 \u7684 \u574f \u6b7b \u53ca \u8f6f \u5316 \uff0c \u5e38\u89c1\u7684\u6709\u8111\u8840\u6813\u53ca\u8111\u6813\u585e (Cere-\nbral ischemic stroke is the necrosis and softening of brain tissue caused by ischemia and hypoxia in the brain, commonly known as cerebral thrombosis and cerebral embolism.)\n\nNo symptom word mismatch (\"abdominal bloating\" vs \"cerebral ischemic stroke\" Full Matching Passage contains a full answer to query rather than a partial answer. For query \"\u9f3b\u5b50\u4e0a\u6709\u9ed1\u5934\u8be5\u600e\u4e48\u53bb\u9664\" (How to get rid of blackheads on your nose) in the medical domain, some passages only introduce the arsing of blackheads, but do not fully introduce how to get rid of blackheads. This type of passages will be marked as irrelevant. Apart from the three universal principles introduced above, we also have specially designed principles for each domain by considering that each domain has its characteristics. Especially for the headwords relevance principle, the core factors with concern for each domain are different. For example, in the domain of Ecommerce, the headwords are usually brand and category words, but in the domain of Entertainment video, they are usually names of the actor, roles or styles of the movie. In Table 3, we show some examples for each domain to more clearly illustrate our annotation guideline.\n\u5b9d \u5b9d \u8179 \u80c0 \u7684 \u539f \u56e0 \u662f \u4ec0 \u4e48 (\n\nQuality Control.\n\nTo ensure that each annotator can produce high quality annotations, we set a pre-annotation step. We first let the annotators read our instructions thoroughly and ask them to annotate a certain number of test samples (from 100 to 200). The expert examiners on this task checked whether the annotation satisfies the pre-defined annotation guideline. The annotators that meet all the principles can continue to annotate. After finishing all the labeling task, the expert examiners will sample 20% of the annotators' data and check them carefully. If the acceptability ratio is lower than 95%, the corresponding annotators are asked to revise their annotations. The loop stops by the end when the acceptability ratio reaches 95%. We have an internal annotation platform (as illustrated in Figure 1) to assist annotators and experts in producing datasets.\n\nFor some samples, we found that determining whether the querypassage pair is relevant is relatively subjective. It is possible that different annotators generate different labels for the same sample. We control the consistency of annotated labels by employing an inter-annotator agreement labeling methods. Concretely, for each sample, we gather at least 5 independent annotators' annotation results, and the samples whose annotation results are more than 80% agreement will be retained.\n\n\nPassage Set Selection.\n\nSince our query-passage pairs are sampled from real search systems, it is impossible for us to release all passages in the search engine as the passage set given that the collection of passages is too large (on billion-level). Therefore, we attempt to build a passage set on a smaller scale, which is mainly consisting of two parts. Passages in query-passage pairs labeled as positive samples are bound to remain in the final passage set. At the same time, we will also uniformly sample passages from all passage collections to supplement the final set until the size of the final passage set reaches the number we expected. For three different domains, the number of the final passage set size is set at around 1 million. Such a uniform sampling strategy and dataset scale ensure the diversity of sampling passages and the passage retrieval efficiency simultaneously.\n\n\nGeneral Domain Dataset\n\nIn addition to the three domain datasets introduced above, we also construct a general domain passage retrieval dataset based on the existing open domain Chinese machine reading comprehension (MRC) dataset DuReader [22]. DuReader collects documents from the search results of Baidu Search 4 . DuReader contains 200K questions, 1M documents and more than 420K human-summarized answers, which is the largest Chinese MRC dataset so far. For each question, the Dureader dataset provides multiple documents which may contain the answer to the question. Each document consists 4 https://www.baidu.com/ of a title and body text. For each question and its associated documents, the original DuReader dataset has divided each document into independent short passages, and has marked whether each passage contains the correct answer or is semantically related to the question.\n\nTo convert the MRC data format into a data format usable by the passage retrieval task, referring to the method described in MS MARCO [5], for each question (query) in DuReader, we select passages containing the correct answer to building positive querypassage pair and take the union of all the passages in DuReader as the final passage set.\n\n\nDataset Statistics\n\nFollowing previous work [5], we only keep the positive querypassage samples in the final training and testing set. The overall statistics of the Multi-CPR dataset and the converted general domain dataset are summarized in Table 4.\n\n\nTASK AND EXPERIMENTS 4.1 Task Definition\n\nGiven a query , a passage retrieval model aims to recall all potentially relevant passages from a large corpus C = { 1 , 2 , ..., }. Thus, the passage retrieval task can be formulated as:\nR : ( , C) \u2192 C ,(1)\nwhich takes and C as input and then returns a much smaller set of passages C \u2282 C, where |C | \u226a . For the passage retrieval task, the most fundamental problem is to estimate the degree of relevance between a query and a passage . Existing retrieval systems can be divided into two typical groups: Sparse Retrieval Medels The key idea of these models is to utilize exact matching signals to design a relevance scoring function. Specifically, these models consider easily computed statistics (e.g., term frequency, inverse document frequency) of terms-matched signals between and . And the relevance score is derived from the sum of contributions from each query term that appears in the passage. Among these models, BM25 [46] is the most representative and still be regarded as a strong baseline for passage retrieval task. Dense Retrieval Medels The key idea of these models is to leverage deep neural networks to convert text into continuous vector representation for relevance estimation. These models use the lowdimension representations of and as the input and are usually trained with scale annotated relevance labels. Compared with traditional sparse retrieval methods, these models can be trained without handcrafted features in an end-to-end manner. Recently, due to the great success achieved by BERT in the natural language process field, many works adopt the BERT model as the encoder for query and passage to obtain the final representation so as to better compute the final relevance score.\n\n\nMethods\n\nIn this section, we will introduce some widely-adopted passage retrieval models (including both sparse and dense models) for experiments. BM25 BM25 is the most widely used term-based passage retrieval method. Practically, BM25 ranks a set of passages based on the  query terms appearing in each passage, regardless of their proximity within the passage. Doc2Query [39] Doc2Query is still a term-based passage retrieval method. Doc2Query alleviates the term mismatch problem in the BM25 via training a neural sequence-to-sequence model to generate potential queries from passages, and indexes the queries as passage expansion terms. Different from the BM25 method, the implementation of the doc2query method relies on labeled query-passage pairs. DPR [26] DPR is the most widely used dense passage retrieval method, which provides a strong baseline performance. It learns dense embeddings for the query and passage with a BERT-based encoder separately. The embeddings of query and passage are then fed into a \"similarity\" function to compute the final relevance score. The retrieval performance of the DPR model is mainly determined by two factors: the BERT backbone network and the labeled query-passage dataset adopted. Therefore, in order to gain a deep understanding of the DPR model in domain passage retrieval, we conduct various settings based on the DPR model architecture by replacing the original BERT model with a BERT model that has continuously trained on in-domain raw text (DPR-2) or leveraging different domain labeled datasets to carry out the training process (DPR-1).\n\n\nEvaluation Metrics\n\nFollowing the evaluation methodology used in previous work [5], the retrieval performance is evaluated by Mean Reciprocal Rank at 10 passages (MRR@10) and recall precision at depth 1000 (Re-call@1k). For the passage reranking results, we only report the result of the MRR@10 metric.\n\n\nImplementation Details\n\nFor sparse retrieval methods, we adopt the pyseirni [32] tool for experiments. For dense retrieval methods, we mainly focus on the DPR architecture. Following previous work, we use the Chinese BERT-base model released by Google Research 5 . During the model training process, the in-batch negative optimization method is adopted with an initial learning rate of 1 \u2212 5 and a batch size of 32. The Adam Optimizer [28] is adopted during the training process. All DPR models are trained on a single NVIDIA-V100 GPU. We use the faiss 6 package for embedding indexing and searching.\n\n\nResults\n\nThe overall experimental results on the test set are shown in Table  5, from which we can observe that:\n\n(1) On three different domain datasets in Multi-CPR, the retrieval performance of dense models outperforms sparse models. Taking the BM25 model and the DPR-1 model as an example, the average MRR@10 value over the three datasets are 0.2124 and 0.2837 respectively. The retrieval performance on the MRR@10 metric is largely improved by 33.57%, which points out the value of high-quality labeled data for the optimization of dense passage retrieval models.  (2) For sparse methods, the BM25 method provides a strong baseline for all the three domain datasets. Especially on the E-commerce dataset, the retrieval performance of BM25 is even slightly better than the DPR model (MRR@10: 0.2253 vs 0.2106, Recall@1000: 0.8150 vs 0.7750). We infer that the reason for this phenomenon is that the average length of query and passage in the domain of E-commerce is relatively short, and the search intent is explicit to some content. The method based on exact term matching can provide satisfactory retrieval results. This observation illustrates that traditional unsupervised term-based retrieval methods such as BM25 can still provide valuable results for passage retrieval in some specific domains. Moreover, as an optimization method that has been verified in previous work, Doc2Query has also achieved significant improvement on all three datasets as expected.\n\n(3) For dense methods, we conduct the analysis from two aspects. In the dataset aspect, we can find that the DPR model trained on in-domain labeled dataset has achieved remarkable performance improvement compared to the dense model trained with general domain data, even though the size of labeled dataset is much smaller. As such, we can conclude that labeled data in general domain is helpful for training dense retrieval model on specific domain to some extent, but the in-domain labeled data could provide more effective and valuable information for model training. In the encoder aspect, by replacing the BERT model with a BERT model that has been continuing trained on in-domain raw text, the performance of DPR-2 model is significantly better than that of DPR-1. This phenomenon is in line with the observation in previous work [19]. Furthermore, we find that the method of BERT continuous training could achieve greater improvement in domains with larger discrepancies compared to the general domain (e.g, the medical domain).\n\n(4) For both sparse and dense methods, we have attempted some existing optimization strategies based on the baseline model. It can be seen that the improvement brought by the optimization of the dense model is much larger than that of the sparse model. This once again shows that the dense model armed with labeled dataset has more space for optimization, which also shows the value of labeled data for domain specific Chinese passage retrieval task.\n\n\nDISCUSSION AND ANALYSIS 5.1 Full Ranking Performance\n\nRecent state-of-the-art passage retrieval systems are usually built with a multi-stage framework [38,45], which consists of a first-stage retriever that efficiently produces a small set of candidate passages followed by one or more elaborate rerankers that rerank the most promising candidates. Similar to the dense retrieval methods, pretrained language models have a major impact for reranking methods via providing rich deep contextualized matching signals between query and passage, as illustrated in Figure 2. Here, in order to verify the practicability of the Multi-CPR dataset in both quality and scale, we also implement experiments with the BERT base reranking model (see Figure 2).\n\nWe first introduce some basic concepts of BERT base reranking model. We aim to train a BERT reranker to score each query passage pair:\n( , ) = cls( ( ( , ))(2)\nwhere cls extracts BERT's [CLS] vector and is a projection vector. Following previous work [18], we optimize the reranking model with a contrastive learning objective. Concretely, for each query, we aggregate all negatives sampled from retrieval passage candidates. Thus, for each query , we form a group with a single relevant positive + and multiple negatives. By taking the scoring function defined in equation (2), the contrastive loss for each query can be denoted as:\nL := \u2212 ( ( , + ) \u2208 ( ( , ))(3)\nIn Table 6, we summarize the full ranking experiments results on Multi-CPR. From which we can observe that: 1) Reranking model can indeed improve the final passage retrieval performance. In statistics, the retrieval-then-re-ranking pipeline gets an average improvement of 32.5% on the three datasets. 2) Better initial retrieval results can produce better raranking results. Intuitively, better retrieval results provide the BERT reranker with more quality negative passages, which are fruitful for the optimization of the contrastive loss as denoted in Equation (3).\n\nThe full ranking experiment results on Multi-CPR are in line with previous studies which leverage other existing datasets in English filed [18,41]. These experiment results again prove that the Multi-CPR is qualified to build a passage reranking model for specific domain.\n\n\nCase Study\n\nIn practical, to evaluate the relevance of a passage for a given query, retrieval models usually start from two aspects: 1) Precise term overlapping and 2) semantic similarity across related concept [34]. Usually, the sparse models excel at the first problem, while the dense models can be better at the second. To gain a deep understanding of the characteristics of sparse and dense retrieval models, here, we sample some queries along with their top retrieval results, as shown in Table 7.\n\nFor the query \"\u5b69 \u5b50 \u5634 \u91cc \u64e6 \u7d2b \u836f \u6c34 \u4ea7 \u751f \u526f \u4f5c \u7528 \u4e86 \u600e \u4e48 \u529e\" (What should be done if the kid has side effects from rubbing gentian violet in his mouth?) in the medical domain, we can find that: 1) The headword \"\u7d2b\u836f\u6c34\" (gentian violet) appears in all passages retrieved by the sparse model, although these passages do not completely match the query. In the retrieval results of dense models, the top-1 passage is the annotated golden passage, while the third passage does not contain the headword, and this passage is only semantically related to the query to some degree. Therefore, the sparse and dense models have very distinct characteristics, and can make different contributions to the overall passage retrieval performance. Some previous studies attempt to hybrid the two models to engage the merits of both for better retrieval performance [29]. Our analysis illustrates that similar problems also exist in the Chinese passage retrieval task. We hope that the release of the Multi-CPR dataset can help to conduct more in-depth research on this problem. Further, we find that different domains place different emphasis on the sparse and dense models. Queries in the E-commerce and entertainment video domains are relatively short in general. Although the search intent of the query is explicit, the key information is missing for some queries. In this case, the dense model can be helpful in finding semantically relevant passages by generalizing to larger concepts. Before the dense model was widely used, previous studies use query reformulation or synonym expansion to supplement the missing information in the query to improve the performance of the sparse model. For example, the query \"iphone13\" will be reformulated to \"iphone13 \u624b\u673a (iphone13 mobile phone)\" in the E-commerce domain. The above observations show that armed with labeled dataset, the workload of designing handcrafted features in sparse models can be greatly eliminated, and the total complexity of the retrieval system can also be reduced.\n\n\nAvailability\n\nWe will publish the following resources in an open Multi-CPR repository 7 :\n\n\u2022 Annotations: All human annotated query-passage related pairs of three domains along with passage corpus will be released to the public. 7 https://github.com/Alibaba-NLP/Multi-CPR\n\n\u2022 Retrieval results: For further studies, we will release the baseline retrieval results. \u2022 BERT Models: We will also provide the continuing trained BERT model with in-domain raw text for future studies. \u2022 Baselines: we will release the source code to reproduce the baseline results presented in this paper.\n\n\nFuture Directions\n\nWe propose the following potential research questions to indicate future research directions on utilizing this Chinese passage retrieval dataset:\n\n1. Cross-domain Chinese passage retrieval.\n\nCross-domain problem has been studied in many information retrieval [1,35] or natural language processing tasks [12,20,31]. Commonly, models trained on one domain do not generalize well to another domain. Based on our experimental results in Table 5, we can observe that cross-domain is indeed a challenge for the Chinese passage retrieval task. Specifically, for two DPR models trained on dataset of general domain and in-domain, the DPR model trained on in-domain dataset has a 38.49% lead on MRR@10. Therefore, current retrieval systems built for the general domain do not have good transferability.\n\nBased on our Multi-CPR dataset, research in two directions can be carried out: 1) Cross-domain from general domain to specific domain. As introduced in Section 2, Chinese passage retrieval for the general domain has been studied for a relatively long period, and annotated dataset in the general domain is also available. How to leverage models and resources in the general domain to improve the retrieval performance in a specific domain is a problem worthy of study. 2) Cross-domain between specific domains. Apart from the three domains covered by Multi-CPR, there are other specific domains that can not be enumerated. As such, cross-domain research between different domains is also worth exploring. 2.How to further improve in-domain Chinese passage retrieval?\n\nIn our experiments, we find that in-domain retrieval performance can be greatly improved by using some of the optimization strategies proposed in previous work. For example, By continuing training the BERT model on domain raw text, the MRR@10 metric has increased by 25.06% in the medical domain. Previously, due to the lack of a public labeled dataset, more in-depth research on the Chinese passage retrieval task has not been carried out.\n\nIn the English field, many supervised optimization strategies have been proposed for both sparse models and dense models. Recently, as the dense models have shown greater advantages, each module of the dense model has been studied in depth. For the backbone network, except for the method of continuing training the BERT model on the domain corpus, various pre-trained language model architectures specially designed have achieved significant performance improvements on the multiple benchmark datasets (e,g. condenser [15], coCondenser [16]). For the fine-tuning pipeline, based on the Multi-CPR dataset, we can conditionally verify whether the previously proposed methods are effective on the Chinese dataset (e,g. ANCE [49]). Moreover, there is a big gap between Chinese and English. Thus, it is potential to explore more effective optimization strategies according to the characteristics of the Chinese passage retrieval task. \n\u6709 \u5173 \u7cfb \u7684 \uff0c \u53ef \u80fd \u662f \u836f \u7269 \u8fc7 \u654f \u5f15 \u8d77 \u7684\uff0c\u6700\u597d\u8fd8\u662f\u505c\u6b62\u4f7f\u7528\uff0c \u8fd8\u8981\u6ce8\u610f\n\u5b69\u5b50\u7684\u996e\u98df\uff0c\u4ee5\u6e05\u6de1\u4e3a\u4e3b\u7684 (There is a relationship, it may be caused by drug allergies, it is best to stop using, and also pay attention to the child's diet, which should be mainly light food.)\n\n\nCan other tasks benefit from Multi-CPR?\n\nIn practice, passage retrieval is usually regarded as an intermediate step for the entire system. For example, for a web search system or recommendation system, passage retrieval is only one module in the whole process, and there are many subdivided upstream and downstream modules (e,g. query processor, CTR model, Re-ranking model, etc.). Here, we use the query processor module for a more detailed explanation. There are usually two basic modules contained in the query processor module: Query reformulation (QR) and Query suggestion (QS) [25,47]. Concretely, the QR module aims to modify a query to improve the quality of search results to satisfy the user's information need, and the QS module aims to provide a suggestion that may be a reformulated query to better represent a user's search intent. There have been multiple research works attempting to build query reformulation models based on annotated passage retrieval dataset thus finally improving the retrieval performance [2,11,25,47]. We believe that Multi-CPR also provides a solid data resource for similar research in the Chinese passage retrieval field.\n\n\nCONCLUSION\n\nIn this paper, we present Multi-CPR, a Chinese passage retrieval dataset that covers three specific domains. All queries and passages are collected from practical search systems and we present a detailed description of the entire dataset construction process. We develop a deep analysis of Multi-CPR and the experiments results of various competitive baselines further prove the challenge of our dataset. We also discuss some valuable research problems based on the Multi-CPR dataset for future work. Finally, we will open-source all the annotated datasets and related baseline codes.\n\nFigure 1 :\n1Illustration of the annotation platform used. It mainly consists of three parts. Left: display the query-passage pair for annotating; Middle: annotators can choose the label result; Right: the expert can check whether the label result is correct, and add some comments if needed.\n\nFigure 2 :\n2Illustration of BERT based passage retrieval and reranking model. Retrieval (left): query and passage are encoded independently by a dual-encoder. Reranking (right): query and passage are concatenated, jointly encoded by a cross-encoder.\n\n\n, Madrid, Spain \u00a9 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-8732-3/22/07. . . $15.00 https://doi.org/10.1145/3477495.3531736 as a prerequisite to downstream tasks and applications like opendomain question answering\n\nTable 1 :\n1Example of annotated query-passage related pairs in three different domains.E-commerce \nQuery \u5c3c\u5eb7z62 (Nikon z62) \n\nPassage Nikon/\u5c3c \u5eb7 \u4e8c \u4ee3 \u5168 \u753b \u5e45 \u5fae \u5355 \n\u673a \u8eabZ62 Z72 24-70mm\u5957 \u673a \n(Nikon/Nikon II, full-frame micro-\nsingle camera, body Z62 Z72 \n24-70mm set) \n\nEntertainment \nvideo \n\nQuery \u6d77\u795e\u5988\u7956 (Ma-tsu, Goddess of the \nSea) \n\nPassage \u6d77\u4e0a\u5973\u795e\u5988\u7956 (Ma-tsu, Goddess of \nthe Sea ) \n\nMedical \nQuery \u5927\u4eba\u80fd\u628a\u624b\u653e\u5728\u7761\u89c9\u5a74\u513f\u80f8\u53e3\u5417 \n(Can adults put their hands on the \nchest of a sleeping baby?) \n\n\n\nTable 3 :\n3Examples of query-passage pairs and annotated results of three different domains.Medical\u5b9d \u5b9d \u8179 \u80c0 \u7684 \u539f \u56e0 \u662f \u4ec0 \u4e48 (What are the causes of abdominal distension for babies?)Query \nPassage \nLable Interpretation \n\nE-commerce \niphone13 \niphone13\u624b \u673a (iphone13 mobile \nphone) \n\nYes \nProduct category word and product \nmodel word match \n\niphone13 \niphone13\u624b\u673a\u58f3 (iphone13 mobile \nphone cases) \n\nNo \nProduct category mismatch ( \"mobile \nphone\" vs \"mobile phone cases\" \n\nEntertainment \nvideo \n\n\u5341 \u516d \u6b65 \u4ea4 \u8c0a \u821e (Sixteen-\nstep social dance) \n\n\u4ea4 \u8c0a \u821e \u56db \u6b65 (Four-step social \ndance) \n\nNo \nAttribute word mismatch (Sixteen-step \nvs Four-step) \n\n\u5341 \u516d \u6b65 \u4ea4 \u8c0a \u821e (16 steps \nballroom dance) \n\n\u5e7f \u573a \u821e16\u6b65 \u5bf9 \u8df3 (Sixteen-step \nSquare dance by pair) \n\nYes \nAttribute match and Dance type match \n\n\n\nTable 4 :\n4Dataset statistics of three different domains.Domain \nTrain Test Passages Avg Length of Query Avg Length of Passage \n\nGeneral \n245897 \n-\n-\n9.56 \n85.38 \nE-commerce \n100000 1000 1002822 \n6.90 \n32.96 \nEntertainment video 100000 1000 1000000 \n7.41 \n27.45 \nMedical \n99999 1000 \n959526 \n17.07 \n122.02 \n\nRelevance score \n\nquery \ndocument \nquery \ndocument \n\nRelevance score \n\n\n\nTable 5 :\n5Results on three domain datasets. \"In-Domain\" indicates that the training dataset adopted is from the corresponding domain. \"BERT-CT\" notes that the BERT model is continuing trained with domain corpus.Models \nDataset \nEncoder \nE-commerce \nEntertainment video \nMedical \n\nMRR@10 Recall@1000 MRR@10 Recall@1000 MRR@10 Recall@1000 \n\nSparse \nBM25 \n-\n-\n0.2253 \n0.8150 \n0.2252 \n0.7800 \n0.1869 \n0.4820 \nDoc2Query \n-\n-\n0.2385 \n0.8260 \n0.2378 \n0.7940 \n0.2095 \n0.5050 \n\nDense \n\nDPR \nGeneral \nBERT \n0.2106 \n0.7750 \n0.1950 \n0.7710 \n0.2133 \n0.5220 \nDPR-1 \nIn-Domain \nBERT \n0.2704 \n0.9210 \n0.2537 \n0.9340 \n0.3270 \n0.7470 \nDPR-2 \nIn-Domain BERT-CT \n0.2894 \n0.9260 \n0.2627 \n0.9350 \n0.3388 \n0.7690 \n\n\n\nTable 6 :\n6Full ranking results of BERT reranking model on three domain datasets.Retrieval Reranker \nE-commerce \nEntertainment \nvideo \nMedical \n\nMRR@10 \nMRR@10 \nMRR@10 \n\nBM25 \n-\n0.2253 \n0.2252 \n0.1869 \nBM25 \nBERT \n0.2784 \n0.3212 \n0.2673 \n\nDPR-1 \n-\n0.2704 \n0.2537 \n0.3270 \nDPR-1 \nBERT \n0.3624 \n0.3772 \n0.3855 \n\n\n\nTable 7 :\n7Examples of top retrieval results of Sparse and Dense retrieval models.\u674e\u5b8119\u6625\u5b63\u6b3e\u65e0\u754cX\u60c5\u4fa3\u7f13\u9707\u8bad\u7ec3\u978b(Li Ning 19 spring models boundless X couple cushioning training shoes)\u674e \u5b81 \u65e0 \u754c \u7f13 \u9707 \u8bad \u7ec3 \u978b2019\u590f \u79cb \u6b3e (LiNing boundless cushioning trainers 2019 summer and autumn models.) \u9002\u914dlining\u674e\u5b81 \u9a6d\u5e0511 10... (Adapt to lining Li Ning Yu Shuai 11 10...)\u674e \u5b81 \u6625 \u79cb \u9650 \u91cf \u7248 \u7537 \u5973 \u8bad \u7ec3 \u51cf \u9707 \u4e00 Whatshould be done if the kid has side effects from rubbing gentian violet in his mouth?) \u70eb\u4f24\u540e\u6b63\u89c4\u6cbb\u7597\u4e0d\u4f7f\u7528\u7d2b\u836f\u6c34\u4e0e\u7ea2 \u836f\u6c34,...,\u4f1a\u4ea7\u751f\u526f\u4f5c\u7528 (Regular treatment after scald does not use gentian violet and gentian violet,..., there will be side effects) \u4e0d\u8981\u7d2b\u836f\u6c34\uff0c\u6709\u95ee\u9898\u4e0d\u597d\u89c2\u5bdf\uff0c\u73b0 \u5728\u4e0d\u4e3b\u5f20\u7528\u3002 \u505c\u836f\u5c31\u597d\u4e86\u3002\u610f\u89c1\u5efa \u8bae:\u591a\u7528\u767d\u6c34\u6f31\u53e3 (Do not use gentian violet, there is a problem that it is not well observed and is not advocated now. Stop the medicine will be fine. Using white water rinsing mouth is suggested.) \u7d2b\u836f\u6c34\u5b55\u5987\u8981\u614e\u91cd\u4f7f\u7528... (Gentian violets should be used with caution by pregnant women) \u4f60\u597d\uff0c\u4e00\u822c\u7d2b\u836f\u6c34\u662f\u4e0d\u80fd\u8f7b\u6613\u7ed9\u5b9d \u5b9d\u7528\u7684\u60c5\u51b5\u7684 ( Hi, gentian violet are not suggested to be used for babies) \u5bf9\u4e8e\u708e\u75c7\u8f83\u8f7b\u3001\u75c5\u7a0b\u77ed\u7684\u75c7\u72b6,\u53ef\u7528 \u7d2b\u836f\u6c34\u6216\u9152\u7cbe\u6d88\u6bd2 (For mild inflammation and short duration of symptoms, disinfection with gentian violet or alcohol can be used)Domain \nQuery \nSparse Retrieval \nDense Retrieval \n\nE-commerce \nlining\u65e0\u754c (Lining boundless) \n\n\u4f53\u7ec7\u978b\u5957\u889c\u5b50\u8fd0\u52a8\u978b\u7121\u754c (Li Ning \nspring and autumn limited edition men \nand women training shock-absorbing \none piece woven socks sneakers, bound-\nless) \n\nlining\u674e\u5b81\u8fd0\u52a8\u6062\u590d\u9888\u690e\u6309\u6469\u5668 (lin-\ning Li Ning sports recovery cervical \nspine massager) \n\n\u674e\u5b8119\u6625\u5b63\u6b3e\u65e0\u754cX\u60c5\u4fa3\u7f13\u9707\u8bad\u7ec3(Li \nNing 19 Spring Unbounded X Couples \nCushioning Training) \n\nMedical \n\n\u5b69\u5b50\u5634\u91cc\u64e6\u7d2b\u836f\u6c34 \n\u4ea7\u751f\u526f\u4f5c\u7528\u4e86\u600e\u4e48\u529e\u5462 \n(\nhttps://www.taobao.com 2 https://www.youku.com 3 https://www.myquark.cn\nhttps://github.com/google-research/bert 6 https://github.com/facebookresearch/faiss\nACKNOWLEDGMENTSWe thank all anonymous reviewers for their helpful suggestions. We also thank all the annotators for constructing this dataset. Special thanks to Shuyi Li and Qiankun Sun for their efforts as expert examiners in the annotation process.\nCross-Domain Modeling of Sentence-Level Evidence for Document Retrieval. Wei Zeynep Akkalyoncu Yilmaz, Haotian Yang, Jimmy Zhang, Lin, 10.18653/v1/D19-1352Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational LinguisticsZeynep Akkalyoncu Yilmaz, Wei Yang, Haotian Zhang, and Jimmy Lin. 2019. Cross-Domain Modeling of Sentence-Level Evidence for Document Retrieval. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Pro- cessing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Association for Computational Linguistics, Hong Kong, China, 3490-3496. https://doi.org/10.18653/v1/D19-1352\n\nMatches Made in Heaven: Toolkit and Large-Scale Datasets for Supervised Query Reformulation. Negar Arabzadeh, Amin Bigdeli, Shirin Seyedsalehi, Morteza Zihayat, Ebrahim Bagheri, Proceedings of the 30th ACM International Conference on Information & Knowledge Management. the 30th ACM International Conference on Information & Knowledge ManagementNegar Arabzadeh, Amin Bigdeli, Shirin Seyedsalehi, Morteza Zihayat, and Ebrahim Bagheri. 2021. Matches Made in Heaven: Toolkit and Large-Scale Datasets for Supervised Query Reformulation. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management. 4417-4425.\n\nRepresentation learning: A review and new perspectives. Yoshua Bengio, Aaron Courville, Pascal Vincent, IEEE transactions. 35Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence 35, 8 (2013), 1798-1828.\n\nBlock-based web search. Deng Cai, Shipeng Yu, Ji-Rong Wen, Wei-Ying Ma, Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval. the 27th annual international ACM SIGIR conference on Research and development in information retrievalDeng Cai, Shipeng Yu, Ji-Rong Wen, and Wei-Ying Ma. 2004. Block-based web search. In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval. 456-463.\n\nMS MARCO: A Human Generated MAchine Reading COmprehension Dataset. Tri Daniel Fernando Campos, Mir Nguyen, Xia Rosenberg, Jianfeng Song, Saurabh Gao, Rangan Tiwary, Li Majumder, Bhaskar Deng, Mitra, ArXiv abs/1611.09268Daniel Fernando Campos, Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, and Bhaskar Mitra. 2016. MS MARCO: A Human Generated MAchine Reading COmprehension Dataset. ArXiv abs/1611.09268 (2016).\n\nWikiPassageQA: A Benchmark Collection for Research on Non-factoid Answer Passage Retrieval. Daniel Cohen, Liu Yang, William Bruce Croft, The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. Daniel Cohen, Liu Yang, and William Bruce Croft. 2018. WikiPassageQA: A Benchmark Collection for Research on Non-factoid Answer Passage Retrieval. The 41st International ACM SIGIR Conference on Research & Development in Infor- mation Retrieval (2018).\n\nProbabilistic query expansion using query logs. Hang Cui, Ji-Rong Wen, Jian-Yun Nie, Wei-Ying Ma, Proceedings of the 11th international conference on World Wide Web. the 11th international conference on World Wide WebHang Cui, Ji-Rong Wen, Jian-Yun Nie, and Wei-Ying Ma. 2002. Probabilistic query expansion using query logs. In Proceedings of the 11th international conference on World Wide Web. 325-332.\n\nA Sentence Cloze Dataset for Chinese Machine Reading Comprehension. Yiming Cui, Ting Liu, Ziqing Yang, Zhipeng Chen, Wentao Ma, Wanxiang Che, Shijin Wang, Guoping Hu, 10.18653/v1/2020.coling-main.589Proceedings of the 28th International Conference on Computational Linguistics. International Committee on Computational Linguistics. the 28th International Conference on Computational Linguistics. International Committee on Computational LinguisticsBarcelona, Spain (OnlineYiming Cui, Ting Liu, Ziqing Yang, Zhipeng Chen, Wentao Ma, Wanxiang Che, Shijin Wang, and Guoping Hu. 2020. A Sentence Cloze Dataset for Chinese Machine Reading Comprehension. In Proceedings of the 28th International Con- ference on Computational Linguistics. International Committee on Computational Linguistics, Barcelona, Spain (Online), 6717-6723. https://doi.org/10.18653/v1/ 2020.coling-main.589\n\nContext-aware sentence/passage term importance estimation for first stage retrieval. Zhuyun Dai, Jamie Callan, arXiv:1910.10687arXiv preprintZhuyun Dai and Jamie Callan. 2019. Context-aware sentence/passage term importance estimation for first stage retrieval. arXiv preprint arXiv:1910.10687 (2019).\n\nDeeper text understanding for IR with contextual neural language modeling. Zhuyun Dai, Jamie Callan, Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 42nd International ACM SIGIR Conference on Research and Development in Information RetrievalZhuyun Dai and Jamie Callan. 2019. Deeper text understanding for IR with contextual neural language modeling. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 985-988.\n\nLearning to attend, copy, and generate for session-based query suggestion. Mostafa Dehghani, Sascha Rothe, Enrique Alfonseca, Pascal Fleury, Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. the 2017 ACM on Conference on Information and Knowledge ManagementMostafa Dehghani, Sascha Rothe, Enrique Alfonseca, and Pascal Fleury. 2017. Learning to attend, copy, and generate for session-based query suggestion. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Man- agement. 1747-1756.\n\nCoupling Distant Annotation and Adversarial Training for Cross-Domain Chinese Word Segmentation. Ning Ding, Dingkun Long, Guangwei Xu, Muhua Zhu, Pengjun Xie, Xiaobin Wang, Haitao Zheng, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsNing Ding, Dingkun Long, Guangwei Xu, Muhua Zhu, Pengjun Xie, Xiaobin Wang, and Haitao Zheng. 2020. Coupling Distant Annotation and Adversarial Training for Cross-Domain Chinese Word Segmentation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 6662-6671.\n\nYixing Fan, Xiaohui Xie, Yinqiong Cai, Jia Chen, Xinyu Ma, Xiangsheng Li, Ruqing Zhang, Jiafeng Guo, Yiqun Liu, arXiv:2111.13853Pre-training Methods in Information Retrieval. arXiv preprintYixing Fan, Xiaohui Xie, Yinqiong Cai, Jia Chen, Xinyu Ma, Xiangsheng Li, Ruqing Zhang, Jiafeng Guo, and Yiqun Liu. 2021. Pre-training Methods in Information Retrieval. arXiv preprint arXiv:2111.13853 (2021).\n\nApplying deep learning to answer selection: A study and an open task. Minwei Feng, Bing Xiang, Michael R Glass, Lidan Wang, Bowen Zhou, IEEE Workshop on Automatic Speech Recognition and Understanding. ASRUMinwei Feng, Bing Xiang, Michael R. Glass, Lidan Wang, and Bowen Zhou. 2015. Applying deep learning to answer selection: A study and an open task. 2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU) (2015), 813-820.\n\nCondenser: a Pre-training Architecture for Dense Retrieval. Luyu Gao, Jamie Callan, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingLuyu Gao and Jamie Callan. 2021. Condenser: a Pre-training Architecture for Dense Retrieval. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 981-993.\n\nUnsupervised corpus aware language model pre-training for dense passage retrieval. Luyu Gao, Jamie Callan, arXiv:2108.05540arXiv preprintLuyu Gao and Jamie Callan. 2021. Unsupervised corpus aware language model pre-training for dense passage retrieval. arXiv preprint arXiv:2108.05540 (2021).\n\nCOIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List. Luyu Gao, Zhuyun Dai, Jamie Callan, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesLuyu Gao, Zhuyun Dai, and Jamie Callan. 2021. COIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 3030-3042.\n\nRethink Training of BERT Rerankers in Multi-Stage Retrieval Pipeline. Luyu Gao, Zhuyun Dai, Jamie Callan, ECIR. Luyu Gao, Zhuyun Dai, and Jamie Callan. 2021. Rethink Training of BERT Rerankers in Multi-Stage Retrieval Pipeline. In ECIR.\n\nDon't Stop Pretraining: Adapt Language Models to Domains and Tasks. Ana Suchin Gururangan, Swabha Marasovi\u0107, Kyle Swayamdipta, Iz Lo, Doug Beltagy, Noah A Downey, Smith, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsSuchin Gururangan, Ana Marasovi\u0107, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and Noah A Smith. 2020. Don't Stop Pretraining: Adapt Language Models to Domains and Tasks. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 8342-8360.\n\nA unified model for cross-domain and semisupervised named entity recognition in chinese social media. Hangfeng He, Xu Sun, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence31Hangfeng He and Xu Sun. 2017. A unified model for cross-domain and semi- supervised named entity recognition in chinese social media. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 31.\n\nDEBERTA: Decoding-enhanced BERT with disentangled attention. Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen, International Conference on Learning Representations. Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2020. DEBERTA: Decoding-enhanced BERT with disentangled attention. In International Confer- ence on Learning Representations.\n\nDuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications. Wei He, Kai Liu, Jing Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, Haifeng Wang, 10.18653/v1/W18-2605Proceedings of the Workshop on Machine Reading for Question Answering. the Workshop on Machine Reading for Question AnsweringMelbourne, AustraliaAssociation for Computational LinguisticsWei He, Kai Liu, Jing Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, and Haifeng Wang. 2018. DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications. In Proceedings of the Workshop on Machine Reading for Question Answering. Association for Computational Linguistics, Melbourne, Australia, 37-46. https://doi.org/10.18653/v1/W18-2605\n\nTeaching Machines to Read and Comprehend. Karl Moritz Hermann, Tom\u00e1s Kocisk\u00fd, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, Phil Blunsom, NIPS. Karl Moritz Hermann, Tom\u00e1s Kocisk\u00fd, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. 2015. Teaching Machines to Read and Comprehend. In NIPS.\n\nKyoung-Rok Jang, Junmo Kang, Giwon Hong, Sung-Hyon Myaeng, Joohee Park, Taewon Yoon, and Heecheol Seo. 2021. UHD-BERT: Bucketed Ultra-High Dimensional Sparse Representations for Full Ranking. arXiv e-prints (2021). 2104Kyoung-Rok Jang, Junmo Kang, Giwon Hong, Sung-Hyon Myaeng, Joohee Park, Taewon Yoon, and Heecheol Seo. 2021. UHD-BERT: Bucketed Ultra-High Dimen- sional Sparse Representations for Full Ranking. arXiv e-prints (2021), arXiv-2104.\n\nPatterns of query reformulation during web searching. J Bernard, Danielle L Jansen, Amanda Booth, Spink, Journal of the american society for information science and technology. 60Bernard J Jansen, Danielle L Booth, and Amanda Spink. 2009. Patterns of query re- formulation during web searching. Journal of the american society for information science and technology 60, 7 (2009), 1358-1371.\n\nDense Passage Retrieval for Open-Domain Question Answering. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP. the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLPVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense Passage Retrieval for Open- Domain Question Answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 6769-6781.\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of NAACL-HLT. Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina ToutanovaNAACL-HLTJacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of NAACL-HLT. 4171-4186.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti- mization. arXiv preprint arXiv:1412.6980 (2014).\n\nLeveraging semantic and lexical matching to improve the recall of document retrieval systems: A hybrid approach. Saar Kuzi, Mingyang Zhang, Cheng Li, Michael Bendersky, Marc Najork, arXiv:2010.01195arXiv preprintSaar Kuzi, Mingyang Zhang, Cheng Li, Michael Bendersky, and Marc Najork. 2020. Leveraging semantic and lexical matching to improve the recall of document retrieval systems: A hybrid approach. arXiv preprint arXiv:2010.01195 (2020).\n\nEncoder Adaptation of Dense Passage Retrieval for Open-Domain Question Answering. Minghan Li, Jimmy Lin, arXiv:2110.01599arXiv preprintMinghan Li and Jimmy Lin. 2021. Encoder Adaptation of Dense Passage Retrieval for Open-Domain Question Answering. arXiv preprint arXiv:2110.01599 (2021).\n\nNeural Adaptation Layers for Cross-domain Named Entity Recognition. Yuchen Bill, Wei Lin, Lu, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBill Yuchen Lin and Wei Lu. 2018. Neural Adaptation Layers for Cross-domain Named Entity Recognition. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2012-2022.\n\nPyserini: An easy-to-use python toolkit to support replicable ir research with sparse and dense representations. Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak Pradeep, Rodrigo Nogueira, arXiv:2102.10073arXiv preprintJimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak Pradeep, and Rodrigo Nogueira. 2021. Pyserini: An easy-to-use python toolkit to support replicable ir research with sparse and dense representations. arXiv preprint arXiv:2102.10073 (2021).\n\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. arXiv preprintYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019).\n\nSparse, dense, and attentional representations for text retrieval. Yi Luan, Jacob Eisenstein, Kristina Toutanova, Michael Collins, Transactions of the Association for Computational Linguistics. 9Yi Luan, Jacob Eisenstein, Kristina Toutanova, and Michael Collins. 2021. Sparse, dense, and attentional representations for text retrieval. Transactions of the Association for Computational Linguistics 9 (2021), 329-345.\n\nZero-shot Neural Passage Retrieval via Domain-targeted Synthetic Question Generation. Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, Ryan Mcdonald, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeJi Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, and Ryan McDonald. 2021. Zero-shot Neural Passage Retrieval via Domain-targeted Synthetic Question Generation. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. 1075-1088.\n\nRetrieve-and-read: Multi-task learning of information retrieval and reading comprehension. Kyosuke Nishida, Itsumi Saito, Atsushi Otsuka, Hisako Asano, Junji Tomita, Proceedings of the 27th ACM international conference on information and knowledge management. the 27th ACM international conference on information and knowledge managementKyosuke Nishida, Itsumi Saito, Atsushi Otsuka, Hisako Asano, and Junji Tomita. 2018. Retrieve-and-read: Multi-task learning of information retrieval and read- ing comprehension. In Proceedings of the 27th ACM international conference on information and knowledge management. 647-656.\n\nFrom doc2query to docTTTTTquery. Rodrigo Nogueira, Rodrigo Nogueira. 2019. From doc2query to docTTTTTquery.\n\nRodrigo Nogueira, Kyunghyun Cho, arXiv:1901.04085Passage Re-ranking with BERT. arXiv preprintRodrigo Nogueira and Kyunghyun Cho. 2019. Passage Re-ranking with BERT. arXiv preprint arXiv:1901.04085 (2019).\n\nDocument expansion by query prediction. Rodrigo Nogueira, Wei Yang, Jimmy Lin, Kyunghyun Cho, arXiv:1904.08375arXiv preprintRodrigo Nogueira, Wei Yang, Jimmy Lin, and Kyunghyun Cho. 2019. Document expansion by query prediction. arXiv preprint arXiv:1904.08375 (2019).\n\nRetrieval of answer-sentences and answer-figures from papers by text searching. O&apos; John, Connor, Information Processing & Management. 11John O'Connor. 1975. Retrieval of answer-sentences and answer-figures from papers by text searching. Information Processing & Management 11, 5-7 (1975), 155-164.\n\nInvestigating the successes and failures of BERT for passage re-ranking. Harshith Padigela, Hamed Zamani, W Bruce Croft, arXiv:1905.01758arXiv preprintHarshith Padigela, Hamed Zamani, and W Bruce Croft. 2019. Investigating the suc- cesses and failures of BERT for passage re-ranking. arXiv preprint arXiv:1905.01758 (2019).\n\nRocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering. Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesYingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxi- ang Dong, Hua Wu, and Haifeng Wang. 2021. RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 5835-5847.\n\nSQuAD: 100,000+ Questions for Machine Comprehension of Text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ Questions for Machine Comprehension of Text. In Proceed- ings of the 2016 Conference on Empirical Methods in Natural Language Processing. 2383-2392.\n\nSQuAD: 100,000+ Questions for Machine Comprehension of Text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, 10.18653/v1/D16-1264Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingAustin, TexasAssociation for Computational LinguisticsPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ Questions for Machine Comprehension of Text. In Proceed- ings of the 2016 Conference on Empirical Methods in Natural Language Pro- cessing. Association for Computational Linguistics, Austin, Texas, 2383-2392. https://doi.org/10.18653/v1/D16-1264\n\nRuiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Ji-Rong Wen, RocketQAv2: A Joint Training Method for. Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, and Ji-Rong Wen. 2021. RocketQAv2: A Joint Training Method for\n\narXiv:2110.07367Dense Passage Retrieval and Passage Re-ranking. arXiv preprintDense Passage Retrieval and Passage Re-ranking. arXiv preprint arXiv:2110.07367 (2021).\n\nThe probabilistic relevance framework: BM25 and beyond. Stephen Robertson, Hugo Zaragoza, Now Publishers IncStephen Robertson and Hugo Zaragoza. 2009. The probabilistic relevance frame- work: BM25 and beyond. Now Publishers Inc.\n\nA hierarchical recurrent encoder-decoder for generative context-aware query suggestion. Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob Grue Simonsen, Jian-Yun Nie, proceedings of the 24th ACM international on conference on information and knowledge management. the 24th ACM international on conference on information and knowledge managementAlessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob Grue Simonsen, and Jian-Yun Nie. 2015. A hierarchical recurrent encoder-decoder for generative context-aware query suggestion. In proceedings of the 24th ACM international on conference on information and knowledge management. 553-562.\n\nWhat is the Jeopardy model? A quasi-synchronous grammar for QA. Mengqiu Wang, A Noah, Teruko Smith, Mitamura, Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language LearningEMNLP-CoNLLMengqiu Wang, Noah A Smith, and Teruko Mitamura. 2007. What is the Jeopardy model? A quasi-synchronous grammar for QA. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computa- tional Natural Language Learning (EMNLP-CoNLL). 22-32.\n\nLee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, Arnold Overwijk, arXiv:2007.00808Approximate nearest neighbor negative contrastive learning for dense text retrieval. arXiv preprintLee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, and Arnold Overwijk. 2020. Approximate nearest neighbor nega- tive contrastive learning for dense text retrieval. arXiv preprint arXiv:2007.00808 (2020).\n\nEfficient Passage Retrieval with Hashing for Open-domain Question Answering. Ikuya Yamada, Akari Asai, Hannaneh Hajishirzi, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingShort Papers2Ikuya Yamada, Akari Asai, and Hannaneh Hajishirzi. 2021. Efficient Passage Retrieval with Hashing for Open-domain Question Answering. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 979-986.\n\nXlnet: Generalized autoregressive pretraining for language understanding. Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, R Russ, Quoc V Salakhutdinov, Le, Advances in neural information processing systems. 32Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. Advances in neural information processing systems 32 (2019).\n\nOptimizing dense retrieval model training with hard negatives. Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, Min Zhang, Shaoping Ma, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 44th International ACM SIGIR Conference on Research and Development in Information RetrievalJingtao Zhan, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, Min Zhang, and Shaoping Ma. 2021. Optimizing dense retrieval model training with hard negatives. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 1503-1512.\n\nAdversarial Retriever-Ranker for Dense Text Retrieval. Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng Lv, Nan Duan, Weizhu Chen, International Conference on Learning Representations. Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng Lv, Nan Duan, and Weizhu Chen. 2022. Adversarial Retriever-Ranker for Dense Text Retrieval. In Interna- tional Conference on Learning Representations. https://openreview.net/forum?id= MR7XubKUFB\n\nNingyu Zhang, Qianghuai Jia, Kangping Yin, Liang Dong, arXiv:2008.10813Feng Gao, and Nengwei Hua. 2020. Conceptualized representation learning for chinese biomedical text mining. arXiv preprintNingyu Zhang, Qianghuai Jia, Kangping Yin, Liang Dong, Feng Gao, and Nengwei Hua. 2020. Conceptualized representation learning for chinese biomedical text mining. arXiv preprint arXiv:2008.10813 (2020).\n\nSogou-QCL: A New Dataset with Click Relevance Label. Yukun Zheng, Zhen Fan, Yiqun Liu, Cheng Luo, Min Zhang, Shaoping Ma, 10.1145/3209978.3210092SIGIR '18The 41st International ACM SIGIR Conference on Research &#38; Development in Information Retrieval. Ann Arbor, MI, USA; New York, NY, USAACMYukun Zheng, Zhen Fan, Yiqun Liu, Cheng Luo, Min Zhang, and Shaoping Ma. 2018. Sogou-QCL: A New Dataset with Click Relevance Label. In The 41st International ACM SIGIR Conference on Research &#38; Development in Information Retrieval (Ann Arbor, MI, USA) (SIGIR '18). ACM, New York, NY, USA, 1117-1120. https://doi.org/10.1145/3209978.3210092\n", "annotations": {"author": "[{\"end\":157,\"start\":86},{\"end\":227,\"start\":158},{\"end\":294,\"start\":228},{\"end\":337,\"start\":295},{\"end\":380,\"start\":338},{\"end\":449,\"start\":381},{\"end\":488,\"start\":450},{\"end\":563,\"start\":489},{\"end\":629,\"start\":564},{\"end\":670,\"start\":630},{\"end\":714,\"start\":671},{\"end\":755,\"start\":715},{\"end\":795,\"start\":756},{\"end\":838,\"start\":796},{\"end\":881,\"start\":839},{\"end\":923,\"start\":882},{\"end\":962,\"start\":924},{\"end\":1007,\"start\":963},{\"end\":1048,\"start\":1008},{\"end\":1089,\"start\":1049}]", "publisher": "[{\"end\":55,\"start\":52},{\"end\":1409,\"start\":1406}]", "author_last_name": "[{\"end\":98,\"start\":94},{\"end\":167,\"start\":164},{\"end\":236,\"start\":233},{\"end\":306,\"start\":304},{\"end\":349,\"start\":346},{\"end\":391,\"start\":388},{\"end\":457,\"start\":455},{\"end\":502,\"start\":497},{\"end\":573,\"start\":569},{\"end\":639,\"start\":635},{\"end\":683,\"start\":679},{\"end\":724,\"start\":721},{\"end\":764,\"start\":761},{\"end\":807,\"start\":805},{\"end\":850,\"start\":847},{\"end\":892,\"start\":889},{\"end\":931,\"start\":929},{\"end\":976,\"start\":971},{\"end\":1017,\"start\":1013},{\"end\":1058,\"start\":1054}]", "author_first_name": "[{\"end\":93,\"start\":86},{\"end\":163,\"start\":158},{\"end\":232,\"start\":228},{\"end\":303,\"start\":295},{\"end\":345,\"start\":338},{\"end\":387,\"start\":381},{\"end\":454,\"start\":450},{\"end\":496,\"start\":489},{\"end\":568,\"start\":564},{\"end\":634,\"start\":630},{\"end\":678,\"start\":671},{\"end\":720,\"start\":715},{\"end\":760,\"start\":756},{\"end\":804,\"start\":796},{\"end\":846,\"start\":839},{\"end\":888,\"start\":882},{\"end\":928,\"start\":924},{\"end\":970,\"start\":963},{\"end\":1012,\"start\":1008},{\"end\":1053,\"start\":1049}]", "author_affiliation": "[{\"end\":156,\"start\":128},{\"end\":226,\"start\":198},{\"end\":293,\"start\":265},{\"end\":336,\"start\":308},{\"end\":379,\"start\":351},{\"end\":448,\"start\":420},{\"end\":487,\"start\":459},{\"end\":562,\"start\":534},{\"end\":628,\"start\":600},{\"end\":669,\"start\":641},{\"end\":713,\"start\":685},{\"end\":754,\"start\":726},{\"end\":794,\"start\":766},{\"end\":837,\"start\":809},{\"end\":880,\"start\":852},{\"end\":922,\"start\":894},{\"end\":961,\"start\":933},{\"end\":1006,\"start\":978},{\"end\":1047,\"start\":1019},{\"end\":1088,\"start\":1060}]", "title": "[{\"end\":51,\"start\":1},{\"end\":1140,\"start\":1090}]", "venue": "[{\"end\":1265,\"start\":1142}]", "abstract": "[{\"end\":2891,\"start\":1472}]", "bib_ref": "[{\"end\":3651,\"start\":3630},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3656,\"start\":3652},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3659,\"start\":3656},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3695,\"start\":3691},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":3698,\"start\":3695},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3725,\"start\":3722},{\"end\":3892,\"start\":3877},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":4704,\"start\":4700},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4723,\"start\":4720},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4744,\"start\":4740},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":4830,\"start\":4826},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4844,\"start\":4841},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":4866,\"start\":4862},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":5184,\"start\":5180},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5199,\"start\":5195},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5214,\"start\":5211},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":5843,\"start\":5839},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8416,\"start\":8413},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8514,\"start\":8510},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8597,\"start\":8594},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8639,\"start\":8635},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8642,\"start\":8639},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8645,\"start\":8642},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":8648,\"start\":8645},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8776,\"start\":8772},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8779,\"start\":8776},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8782,\"start\":8779},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9548,\"start\":9544},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":10048,\"start\":10044},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10069,\"start\":10066},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10097,\"start\":10093},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10429,\"start\":10426},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10432,\"start\":10429},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10469,\"start\":10465},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":10472,\"start\":10469},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10786,\"start\":10782},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10789,\"start\":10786},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":11076,\"start\":11072},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":11079,\"start\":11076},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":11253,\"start\":11249},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":11262,\"start\":11258},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11626,\"start\":11623},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":12286,\"start\":12282},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12764,\"start\":12760},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20733,\"start\":20729},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":21519,\"start\":21516},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":21774,\"start\":21771},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":22953,\"start\":22949},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":24112,\"start\":24108},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":24498,\"start\":24494},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25414,\"start\":25411},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":25717,\"start\":25713},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":26076,\"start\":26072},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":28550,\"start\":28546},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":29355,\"start\":29351},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":29358,\"start\":29355},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":30202,\"start\":30198},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":31324,\"start\":31320},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":31327,\"start\":31324},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":31671,\"start\":31667},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":32799,\"start\":32795},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":34198,\"start\":34197},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":34832,\"start\":34829},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":34835,\"start\":34832},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":34877,\"start\":34873},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":34880,\"start\":34877},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":34883,\"start\":34880},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":37098,\"start\":37094},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":37116,\"start\":37112},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":37301,\"start\":37297},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":38322,\"start\":38318},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":38325,\"start\":38322},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":38765,\"start\":38762},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":38768,\"start\":38765},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":38771,\"start\":38768},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":38774,\"start\":38771}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":39790,\"start\":39498},{\"attributes\":{\"id\":\"fig_1\"},\"end\":40041,\"start\":39791},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":40316,\"start\":40042},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40788,\"start\":40317},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41554,\"start\":40789},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":41935,\"start\":41555},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":42630,\"start\":41936},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":42942,\"start\":42631},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":44488,\"start\":42943}]", "paragraph": "[{\"end\":4165,\"start\":2907},{\"end\":5378,\"start\":4167},{\"end\":6408,\"start\":5380},{\"end\":7423,\"start\":6410},{\"end\":7489,\"start\":7425},{\"end\":8155,\"start\":7491},{\"end\":9549,\"start\":8172},{\"end\":9678,\"start\":9551},{\"end\":9853,\"start\":9741},{\"end\":12167,\"start\":9855},{\"end\":13035,\"start\":12169},{\"end\":14050,\"start\":13077},{\"end\":14545,\"start\":14070},{\"end\":14773,\"start\":14547},{\"end\":14822,\"start\":14783},{\"end\":15091,\"start\":14824},{\"end\":15872,\"start\":15158},{\"end\":16558,\"start\":15874},{\"end\":16956,\"start\":16560},{\"end\":17201,\"start\":17028},{\"end\":18210,\"start\":17203},{\"end\":19103,\"start\":18252},{\"end\":19592,\"start\":19105},{\"end\":20487,\"start\":19619},{\"end\":21380,\"start\":20514},{\"end\":21724,\"start\":21382},{\"end\":21977,\"start\":21747},{\"end\":22209,\"start\":22022},{\"end\":23732,\"start\":22230},{\"end\":25329,\"start\":23744},{\"end\":25634,\"start\":25352},{\"end\":26237,\"start\":25661},{\"end\":26352,\"start\":26249},{\"end\":27709,\"start\":26354},{\"end\":28745,\"start\":27711},{\"end\":29197,\"start\":28747},{\"end\":29945,\"start\":29254},{\"end\":30081,\"start\":29947},{\"end\":30580,\"start\":30107},{\"end\":31179,\"start\":30612},{\"end\":31453,\"start\":31181},{\"end\":31959,\"start\":31468},{\"end\":33965,\"start\":31961},{\"end\":34057,\"start\":33982},{\"end\":34239,\"start\":34059},{\"end\":34548,\"start\":34241},{\"end\":34715,\"start\":34570},{\"end\":34759,\"start\":34717},{\"end\":35363,\"start\":34761},{\"end\":36131,\"start\":35365},{\"end\":36573,\"start\":36133},{\"end\":37506,\"start\":36575},{\"end\":37732,\"start\":37552},{\"end\":38898,\"start\":37776},{\"end\":39497,\"start\":38913}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9740,\"start\":9679},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15133,\"start\":15092},{\"attributes\":{\"id\":\"formula_2\"},\"end\":17027,\"start\":16957},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18232,\"start\":18211},{\"attributes\":{\"id\":\"formula_4\"},\"end\":22229,\"start\":22210},{\"attributes\":{\"id\":\"formula_5\"},\"end\":30106,\"start\":30082},{\"attributes\":{\"id\":\"formula_6\"},\"end\":30611,\"start\":30581},{\"attributes\":{\"id\":\"formula_7\"},\"end\":37551,\"start\":37507}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":6177,\"start\":6170},{\"end\":14682,\"start\":14675},{\"end\":15476,\"start\":15469},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":18118,\"start\":18111},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":21976,\"start\":21969},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":26319,\"start\":26311},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":30622,\"start\":30615},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":31958,\"start\":31951},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":35010,\"start\":35003}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2905,\"start\":2893},{\"attributes\":{\"n\":\"2\"},\"end\":8170,\"start\":8158},{\"attributes\":{\"n\":\"3\"},\"end\":13075,\"start\":13038},{\"attributes\":{\"n\":\"3.2\"},\"end\":14068,\"start\":14053},{\"end\":14781,\"start\":14776},{\"attributes\":{\"n\":\"3.2.2\"},\"end\":15156,\"start\":15135},{\"attributes\":{\"n\":\"3.2.3\"},\"end\":18250,\"start\":18234},{\"attributes\":{\"n\":\"3.2.4\"},\"end\":19617,\"start\":19595},{\"attributes\":{\"n\":\"3.3\"},\"end\":20512,\"start\":20490},{\"attributes\":{\"n\":\"3.4\"},\"end\":21745,\"start\":21727},{\"attributes\":{\"n\":\"4\"},\"end\":22020,\"start\":21980},{\"attributes\":{\"n\":\"4.2\"},\"end\":23742,\"start\":23735},{\"attributes\":{\"n\":\"4.3\"},\"end\":25350,\"start\":25332},{\"attributes\":{\"n\":\"4.4\"},\"end\":25659,\"start\":25637},{\"attributes\":{\"n\":\"4.5\"},\"end\":26247,\"start\":26240},{\"attributes\":{\"n\":\"5\"},\"end\":29252,\"start\":29200},{\"attributes\":{\"n\":\"5.2\"},\"end\":31466,\"start\":31456},{\"attributes\":{\"n\":\"5.3\"},\"end\":33980,\"start\":33968},{\"attributes\":{\"n\":\"5.4\"},\"end\":34568,\"start\":34551},{\"attributes\":{\"n\":\"3.\"},\"end\":37774,\"start\":37735},{\"attributes\":{\"n\":\"6\"},\"end\":38911,\"start\":38901},{\"end\":39509,\"start\":39499},{\"end\":39802,\"start\":39792},{\"end\":40327,\"start\":40318},{\"end\":40799,\"start\":40790},{\"end\":41565,\"start\":41556},{\"end\":41946,\"start\":41937},{\"end\":42641,\"start\":42632},{\"end\":42953,\"start\":42944}]", "table": "[{\"end\":40788,\"start\":40405},{\"end\":41554,\"start\":40966},{\"end\":41935,\"start\":41613},{\"end\":42630,\"start\":42149},{\"end\":42942,\"start\":42713},{\"end\":44488,\"start\":44058}]", "figure_caption": "[{\"end\":39790,\"start\":39511},{\"end\":40041,\"start\":39804},{\"end\":40316,\"start\":40044},{\"end\":40405,\"start\":40329},{\"end\":40966,\"start\":40801},{\"end\":41613,\"start\":41567},{\"end\":42149,\"start\":41948},{\"end\":42713,\"start\":42643},{\"end\":44058,\"start\":42955}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":19046,\"start\":19038},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":29767,\"start\":29759},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":29944,\"start\":29935}]", "bib_author_first_name": "[{\"end\":44972,\"start\":44969},{\"end\":45006,\"start\":44999},{\"end\":45018,\"start\":45013},{\"end\":45980,\"start\":45975},{\"end\":45996,\"start\":45992},{\"end\":46012,\"start\":46006},{\"end\":46033,\"start\":46026},{\"end\":46050,\"start\":46043},{\"end\":46584,\"start\":46578},{\"end\":46598,\"start\":46593},{\"end\":46616,\"start\":46610},{\"end\":46878,\"start\":46874},{\"end\":46891,\"start\":46884},{\"end\":46903,\"start\":46896},{\"end\":46917,\"start\":46909},{\"end\":47430,\"start\":47427},{\"end\":47458,\"start\":47455},{\"end\":47470,\"start\":47467},{\"end\":47490,\"start\":47482},{\"end\":47504,\"start\":47497},{\"end\":47516,\"start\":47510},{\"end\":47527,\"start\":47525},{\"end\":47545,\"start\":47538},{\"end\":47916,\"start\":47910},{\"end\":47927,\"start\":47924},{\"end\":47941,\"start\":47934},{\"end\":47947,\"start\":47942},{\"end\":48356,\"start\":48352},{\"end\":48369,\"start\":48362},{\"end\":48383,\"start\":48375},{\"end\":48397,\"start\":48389},{\"end\":48784,\"start\":48778},{\"end\":48794,\"start\":48790},{\"end\":48806,\"start\":48800},{\"end\":48820,\"start\":48813},{\"end\":48833,\"start\":48827},{\"end\":48846,\"start\":48838},{\"end\":48858,\"start\":48852},{\"end\":48872,\"start\":48865},{\"end\":49677,\"start\":49671},{\"end\":49688,\"start\":49683},{\"end\":49969,\"start\":49963},{\"end\":49980,\"start\":49975},{\"end\":50516,\"start\":50509},{\"end\":50533,\"start\":50527},{\"end\":50548,\"start\":50541},{\"end\":50566,\"start\":50560},{\"end\":51076,\"start\":51072},{\"end\":51090,\"start\":51083},{\"end\":51105,\"start\":51097},{\"end\":51115,\"start\":51110},{\"end\":51128,\"start\":51121},{\"end\":51141,\"start\":51134},{\"end\":51154,\"start\":51148},{\"end\":51630,\"start\":51624},{\"end\":51643,\"start\":51636},{\"end\":51657,\"start\":51649},{\"end\":51666,\"start\":51663},{\"end\":51678,\"start\":51673},{\"end\":51693,\"start\":51683},{\"end\":51704,\"start\":51698},{\"end\":51719,\"start\":51712},{\"end\":51730,\"start\":51725},{\"end\":52099,\"start\":52093},{\"end\":52110,\"start\":52106},{\"end\":52125,\"start\":52118},{\"end\":52127,\"start\":52126},{\"end\":52140,\"start\":52135},{\"end\":52152,\"start\":52147},{\"end\":52533,\"start\":52529},{\"end\":52544,\"start\":52539},{\"end\":52993,\"start\":52989},{\"end\":53004,\"start\":52999},{\"end\":53298,\"start\":53294},{\"end\":53310,\"start\":53304},{\"end\":53321,\"start\":53316},{\"end\":53974,\"start\":53970},{\"end\":53986,\"start\":53980},{\"end\":53997,\"start\":53992},{\"end\":54209,\"start\":54206},{\"end\":54235,\"start\":54229},{\"end\":54251,\"start\":54247},{\"end\":54267,\"start\":54265},{\"end\":54276,\"start\":54272},{\"end\":54292,\"start\":54286},{\"end\":54863,\"start\":54855},{\"end\":54870,\"start\":54868},{\"end\":55267,\"start\":55258},{\"end\":55280,\"start\":55272},{\"end\":55294,\"start\":55286},{\"end\":55306,\"start\":55300},{\"end\":55644,\"start\":55641},{\"end\":55652,\"start\":55649},{\"end\":55662,\"start\":55658},{\"end\":55674,\"start\":55668},{\"end\":55685,\"start\":55680},{\"end\":55698,\"start\":55692},{\"end\":55709,\"start\":55705},{\"end\":55722,\"start\":55715},{\"end\":55732,\"start\":55729},{\"end\":55745,\"start\":55737},{\"end\":55755,\"start\":55751},{\"end\":55765,\"start\":55761},{\"end\":55777,\"start\":55770},{\"end\":56461,\"start\":56457},{\"end\":56483,\"start\":56478},{\"end\":56499,\"start\":56493},{\"end\":56519,\"start\":56514},{\"end\":56534,\"start\":56530},{\"end\":56547,\"start\":56540},{\"end\":56562,\"start\":56558},{\"end\":56765,\"start\":56755},{\"end\":56777,\"start\":56772},{\"end\":56789,\"start\":56784},{\"end\":56805,\"start\":56796},{\"end\":56820,\"start\":56814},{\"end\":57259,\"start\":57258},{\"end\":57277,\"start\":57269},{\"end\":57279,\"start\":57278},{\"end\":57294,\"start\":57288},{\"end\":57664,\"start\":57656},{\"end\":57682,\"start\":57676},{\"end\":57694,\"start\":57689},{\"end\":57707,\"start\":57700},{\"end\":57721,\"start\":57715},{\"end\":57732,\"start\":57726},{\"end\":57746,\"start\":57741},{\"end\":57760,\"start\":57753},{\"end\":58646,\"start\":58645},{\"end\":58662,\"start\":58657},{\"end\":58945,\"start\":58941},{\"end\":58960,\"start\":58952},{\"end\":58973,\"start\":58968},{\"end\":58985,\"start\":58978},{\"end\":59001,\"start\":58997},{\"end\":59362,\"start\":59355},{\"end\":59372,\"start\":59367},{\"end\":59637,\"start\":59631},{\"end\":59647,\"start\":59644},{\"end\":60139,\"start\":60134},{\"end\":60153,\"start\":60145},{\"end\":60169,\"start\":60158},{\"end\":60185,\"start\":60175},{\"end\":60197,\"start\":60192},{\"end\":60214,\"start\":60207},{\"end\":60516,\"start\":60510},{\"end\":60526,\"start\":60522},{\"end\":60537,\"start\":60532},{\"end\":60552,\"start\":60545},{\"end\":60563,\"start\":60557},{\"end\":60576,\"start\":60571},{\"end\":60587,\"start\":60583},{\"end\":60598,\"start\":60594},{\"end\":60610,\"start\":60606},{\"end\":60631,\"start\":60624},{\"end\":61038,\"start\":61036},{\"end\":61050,\"start\":61045},{\"end\":61071,\"start\":61063},{\"end\":61090,\"start\":61083},{\"end\":61475,\"start\":61473},{\"end\":61484,\"start\":61480},{\"end\":61501,\"start\":61495},{\"end\":61513,\"start\":61508},{\"end\":61524,\"start\":61520},{\"end\":62155,\"start\":62148},{\"end\":62171,\"start\":62165},{\"end\":62186,\"start\":62179},{\"end\":62201,\"start\":62195},{\"end\":62214,\"start\":62209},{\"end\":62719,\"start\":62712},{\"end\":62795,\"start\":62788},{\"end\":62815,\"start\":62806},{\"end\":63041,\"start\":63034},{\"end\":63055,\"start\":63052},{\"end\":63067,\"start\":63062},{\"end\":63082,\"start\":63073},{\"end\":63350,\"start\":63343},{\"end\":63648,\"start\":63640},{\"end\":63664,\"start\":63659},{\"end\":63680,\"start\":63673},{\"end\":64002,\"start\":63996},{\"end\":64013,\"start\":64007},{\"end\":64024,\"start\":64020},{\"end\":64033,\"start\":64030},{\"end\":64046,\"start\":64039},{\"end\":64057,\"start\":64052},{\"end\":64061,\"start\":64058},{\"end\":64075,\"start\":64068},{\"end\":64085,\"start\":64082},{\"end\":64097,\"start\":64090},{\"end\":64825,\"start\":64819},{\"end\":64841,\"start\":64837},{\"end\":64859,\"start\":64849},{\"end\":64874,\"start\":64869},{\"end\":65347,\"start\":65341},{\"end\":65363,\"start\":65359},{\"end\":65381,\"start\":65371},{\"end\":65396,\"start\":65391},{\"end\":65980,\"start\":65973},{\"end\":65992,\"start\":65986},{\"end\":66001,\"start\":65997},{\"end\":66012,\"start\":66007},{\"end\":66016,\"start\":66013},{\"end\":66031,\"start\":66023},{\"end\":66040,\"start\":66037},{\"end\":66052,\"start\":66045},{\"end\":66066,\"start\":66059},{\"end\":66493,\"start\":66486},{\"end\":66509,\"start\":66505},{\"end\":66758,\"start\":66748},{\"end\":66774,\"start\":66768},{\"end\":66790,\"start\":66783},{\"end\":66808,\"start\":66799},{\"end\":66821,\"start\":66816},{\"end\":66826,\"start\":66822},{\"end\":66845,\"start\":66837},{\"end\":67410,\"start\":67403},{\"end\":67418,\"start\":67417},{\"end\":67431,\"start\":67425},{\"end\":68006,\"start\":68003},{\"end\":68021,\"start\":68014},{\"end\":68031,\"start\":68029},{\"end\":68045,\"start\":68036},{\"end\":68058,\"start\":68052},{\"end\":68068,\"start\":68064},{\"end\":68084,\"start\":68078},{\"end\":68098,\"start\":68092},{\"end\":68550,\"start\":68545},{\"end\":68564,\"start\":68559},{\"end\":68579,\"start\":68571},{\"end\":69332,\"start\":69326},{\"end\":69345,\"start\":69339},{\"end\":69357,\"start\":69351},{\"end\":69369,\"start\":69364},{\"end\":69382,\"start\":69381},{\"end\":69395,\"start\":69389},{\"end\":69772,\"start\":69765},{\"end\":69785,\"start\":69779},{\"end\":69796,\"start\":69791},{\"end\":69809,\"start\":69802},{\"end\":69818,\"start\":69815},{\"end\":69834,\"start\":69826},{\"end\":70382,\"start\":70378},{\"end\":70395,\"start\":70390},{\"end\":70408,\"start\":70402},{\"end\":70424,\"start\":70415},{\"end\":70432,\"start\":70429},{\"end\":70445,\"start\":70439},{\"end\":70755,\"start\":70749},{\"end\":70772,\"start\":70763},{\"end\":70786,\"start\":70778},{\"end\":70797,\"start\":70792},{\"end\":71204,\"start\":71199},{\"end\":71216,\"start\":71212},{\"end\":71227,\"start\":71222},{\"end\":71238,\"start\":71233},{\"end\":71247,\"start\":71244},{\"end\":71263,\"start\":71255}]", "bib_author_last_name": "[{\"end\":44997,\"start\":44973},{\"end\":45011,\"start\":45007},{\"end\":45024,\"start\":45019},{\"end\":45029,\"start\":45026},{\"end\":45990,\"start\":45981},{\"end\":46004,\"start\":45997},{\"end\":46024,\"start\":46013},{\"end\":46041,\"start\":46034},{\"end\":46058,\"start\":46051},{\"end\":46591,\"start\":46585},{\"end\":46608,\"start\":46599},{\"end\":46624,\"start\":46617},{\"end\":46882,\"start\":46879},{\"end\":46894,\"start\":46892},{\"end\":46907,\"start\":46904},{\"end\":46920,\"start\":46918},{\"end\":47453,\"start\":47431},{\"end\":47465,\"start\":47459},{\"end\":47480,\"start\":47471},{\"end\":47495,\"start\":47491},{\"end\":47508,\"start\":47505},{\"end\":47523,\"start\":47517},{\"end\":47536,\"start\":47528},{\"end\":47550,\"start\":47546},{\"end\":47557,\"start\":47552},{\"end\":47922,\"start\":47917},{\"end\":47932,\"start\":47928},{\"end\":47953,\"start\":47948},{\"end\":48360,\"start\":48357},{\"end\":48373,\"start\":48370},{\"end\":48387,\"start\":48384},{\"end\":48400,\"start\":48398},{\"end\":48788,\"start\":48785},{\"end\":48798,\"start\":48795},{\"end\":48811,\"start\":48807},{\"end\":48825,\"start\":48821},{\"end\":48836,\"start\":48834},{\"end\":48850,\"start\":48847},{\"end\":48863,\"start\":48859},{\"end\":48875,\"start\":48873},{\"end\":49681,\"start\":49678},{\"end\":49695,\"start\":49689},{\"end\":49973,\"start\":49970},{\"end\":49987,\"start\":49981},{\"end\":50525,\"start\":50517},{\"end\":50539,\"start\":50534},{\"end\":50558,\"start\":50549},{\"end\":50573,\"start\":50567},{\"end\":51081,\"start\":51077},{\"end\":51095,\"start\":51091},{\"end\":51108,\"start\":51106},{\"end\":51119,\"start\":51116},{\"end\":51132,\"start\":51129},{\"end\":51146,\"start\":51142},{\"end\":51160,\"start\":51155},{\"end\":51634,\"start\":51631},{\"end\":51647,\"start\":51644},{\"end\":51661,\"start\":51658},{\"end\":51671,\"start\":51667},{\"end\":51681,\"start\":51679},{\"end\":51696,\"start\":51694},{\"end\":51710,\"start\":51705},{\"end\":51723,\"start\":51720},{\"end\":51734,\"start\":51731},{\"end\":52104,\"start\":52100},{\"end\":52116,\"start\":52111},{\"end\":52133,\"start\":52128},{\"end\":52145,\"start\":52141},{\"end\":52157,\"start\":52153},{\"end\":52537,\"start\":52534},{\"end\":52551,\"start\":52545},{\"end\":52997,\"start\":52994},{\"end\":53011,\"start\":53005},{\"end\":53302,\"start\":53299},{\"end\":53314,\"start\":53311},{\"end\":53328,\"start\":53322},{\"end\":53978,\"start\":53975},{\"end\":53990,\"start\":53987},{\"end\":54004,\"start\":53998},{\"end\":54227,\"start\":54210},{\"end\":54245,\"start\":54236},{\"end\":54263,\"start\":54252},{\"end\":54270,\"start\":54268},{\"end\":54284,\"start\":54277},{\"end\":54299,\"start\":54293},{\"end\":54306,\"start\":54301},{\"end\":54866,\"start\":54864},{\"end\":54874,\"start\":54871},{\"end\":55270,\"start\":55268},{\"end\":55284,\"start\":55281},{\"end\":55298,\"start\":55295},{\"end\":55311,\"start\":55307},{\"end\":55647,\"start\":55645},{\"end\":55656,\"start\":55653},{\"end\":55666,\"start\":55663},{\"end\":55678,\"start\":55675},{\"end\":55690,\"start\":55686},{\"end\":55703,\"start\":55699},{\"end\":55713,\"start\":55710},{\"end\":55727,\"start\":55723},{\"end\":55735,\"start\":55733},{\"end\":55749,\"start\":55746},{\"end\":55759,\"start\":55756},{\"end\":55768,\"start\":55766},{\"end\":55782,\"start\":55778},{\"end\":56476,\"start\":56462},{\"end\":56491,\"start\":56484},{\"end\":56512,\"start\":56500},{\"end\":56528,\"start\":56520},{\"end\":56538,\"start\":56535},{\"end\":56556,\"start\":56548},{\"end\":56570,\"start\":56563},{\"end\":56770,\"start\":56766},{\"end\":56782,\"start\":56778},{\"end\":56794,\"start\":56790},{\"end\":56812,\"start\":56806},{\"end\":56825,\"start\":56821},{\"end\":57267,\"start\":57260},{\"end\":57286,\"start\":57280},{\"end\":57300,\"start\":57295},{\"end\":57307,\"start\":57302},{\"end\":57674,\"start\":57665},{\"end\":57687,\"start\":57683},{\"end\":57698,\"start\":57695},{\"end\":57713,\"start\":57708},{\"end\":57724,\"start\":57722},{\"end\":57739,\"start\":57733},{\"end\":57751,\"start\":57747},{\"end\":57764,\"start\":57761},{\"end\":58655,\"start\":58647},{\"end\":58669,\"start\":58663},{\"end\":58673,\"start\":58671},{\"end\":58950,\"start\":58946},{\"end\":58966,\"start\":58961},{\"end\":58976,\"start\":58974},{\"end\":58995,\"start\":58986},{\"end\":59008,\"start\":59002},{\"end\":59365,\"start\":59363},{\"end\":59376,\"start\":59373},{\"end\":59642,\"start\":59638},{\"end\":59651,\"start\":59648},{\"end\":59655,\"start\":59653},{\"end\":60143,\"start\":60140},{\"end\":60156,\"start\":60154},{\"end\":60173,\"start\":60170},{\"end\":60190,\"start\":60186},{\"end\":60205,\"start\":60198},{\"end\":60223,\"start\":60215},{\"end\":60520,\"start\":60517},{\"end\":60530,\"start\":60527},{\"end\":60543,\"start\":60538},{\"end\":60555,\"start\":60553},{\"end\":60569,\"start\":60564},{\"end\":60581,\"start\":60577},{\"end\":60592,\"start\":60588},{\"end\":60604,\"start\":60599},{\"end\":60622,\"start\":60611},{\"end\":60640,\"start\":60632},{\"end\":61043,\"start\":61039},{\"end\":61061,\"start\":61051},{\"end\":61081,\"start\":61072},{\"end\":61098,\"start\":61091},{\"end\":61478,\"start\":61476},{\"end\":61493,\"start\":61485},{\"end\":61506,\"start\":61502},{\"end\":61518,\"start\":61514},{\"end\":61533,\"start\":61525},{\"end\":62163,\"start\":62156},{\"end\":62177,\"start\":62172},{\"end\":62193,\"start\":62187},{\"end\":62207,\"start\":62202},{\"end\":62221,\"start\":62215},{\"end\":62728,\"start\":62720},{\"end\":62804,\"start\":62796},{\"end\":62819,\"start\":62816},{\"end\":63050,\"start\":63042},{\"end\":63060,\"start\":63056},{\"end\":63071,\"start\":63068},{\"end\":63086,\"start\":63083},{\"end\":63355,\"start\":63351},{\"end\":63363,\"start\":63357},{\"end\":63657,\"start\":63649},{\"end\":63671,\"start\":63665},{\"end\":63686,\"start\":63681},{\"end\":64005,\"start\":64003},{\"end\":64018,\"start\":64014},{\"end\":64028,\"start\":64025},{\"end\":64037,\"start\":64034},{\"end\":64050,\"start\":64047},{\"end\":64066,\"start\":64062},{\"end\":64080,\"start\":64076},{\"end\":64088,\"start\":64086},{\"end\":64102,\"start\":64098},{\"end\":64835,\"start\":64826},{\"end\":64847,\"start\":64842},{\"end\":64867,\"start\":64860},{\"end\":64880,\"start\":64875},{\"end\":65357,\"start\":65348},{\"end\":65369,\"start\":65364},{\"end\":65389,\"start\":65382},{\"end\":65402,\"start\":65397},{\"end\":65984,\"start\":65981},{\"end\":65995,\"start\":65993},{\"end\":66005,\"start\":66002},{\"end\":66021,\"start\":66017},{\"end\":66035,\"start\":66032},{\"end\":66043,\"start\":66041},{\"end\":66057,\"start\":66053},{\"end\":66070,\"start\":66067},{\"end\":66503,\"start\":66494},{\"end\":66518,\"start\":66510},{\"end\":66766,\"start\":66759},{\"end\":66781,\"start\":66775},{\"end\":66797,\"start\":66791},{\"end\":66814,\"start\":66809},{\"end\":66835,\"start\":66827},{\"end\":66849,\"start\":66846},{\"end\":67415,\"start\":67411},{\"end\":67423,\"start\":67419},{\"end\":67437,\"start\":67432},{\"end\":67447,\"start\":67439},{\"end\":68012,\"start\":68007},{\"end\":68027,\"start\":68022},{\"end\":68034,\"start\":68032},{\"end\":68050,\"start\":68046},{\"end\":68062,\"start\":68059},{\"end\":68076,\"start\":68069},{\"end\":68090,\"start\":68085},{\"end\":68107,\"start\":68099},{\"end\":68557,\"start\":68551},{\"end\":68569,\"start\":68565},{\"end\":68590,\"start\":68580},{\"end\":69337,\"start\":69333},{\"end\":69349,\"start\":69346},{\"end\":69362,\"start\":69358},{\"end\":69379,\"start\":69370},{\"end\":69387,\"start\":69383},{\"end\":69409,\"start\":69396},{\"end\":69413,\"start\":69411},{\"end\":69777,\"start\":69773},{\"end\":69789,\"start\":69786},{\"end\":69800,\"start\":69797},{\"end\":69813,\"start\":69810},{\"end\":69824,\"start\":69819},{\"end\":69837,\"start\":69835},{\"end\":70388,\"start\":70383},{\"end\":70400,\"start\":70396},{\"end\":70413,\"start\":70409},{\"end\":70427,\"start\":70425},{\"end\":70437,\"start\":70433},{\"end\":70450,\"start\":70446},{\"end\":70761,\"start\":70756},{\"end\":70776,\"start\":70773},{\"end\":70790,\"start\":70787},{\"end\":70802,\"start\":70798},{\"end\":71210,\"start\":71205},{\"end\":71220,\"start\":71217},{\"end\":71231,\"start\":71228},{\"end\":71242,\"start\":71239},{\"end\":71253,\"start\":71248},{\"end\":71266,\"start\":71264}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.18653/v1/D19-1352\",\"id\":\"b0\",\"matched_paper_id\":202635721},\"end\":45880,\"start\":44896},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":240230724},\"end\":46520,\"start\":45882},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":393948},\"end\":46848,\"start\":46522},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":1058977},\"end\":47358,\"start\":46850},{\"attributes\":{\"doi\":\"ArXiv abs/1611.09268\",\"id\":\"b4\"},\"end\":47816,\"start\":47360},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":13677542},\"end\":48302,\"start\":47818},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":1815908},\"end\":48708,\"start\":48304},{\"attributes\":{\"doi\":\"10.18653/v1/2020.coling-main.589\",\"id\":\"b7\",\"matched_paper_id\":215238329},\"end\":49584,\"start\":48710},{\"attributes\":{\"doi\":\"arXiv:1910.10687\",\"id\":\"b8\"},\"end\":49886,\"start\":49586},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":162168864},\"end\":50432,\"start\":49888},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":3721543},\"end\":50973,\"start\":50434},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":220045918},\"end\":51622,\"start\":50975},{\"attributes\":{\"doi\":\"arXiv:2111.13853\",\"id\":\"b12\"},\"end\":52021,\"start\":51624},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":3477924},\"end\":52467,\"start\":52023},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":237581068},\"end\":52904,\"start\":52469},{\"attributes\":{\"doi\":\"arXiv:2108.05540\",\"id\":\"b15\"},\"end\":53198,\"start\":52906},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":233241070},\"end\":53898,\"start\":53200},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":231662379},\"end\":54136,\"start\":53900},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":216080466},\"end\":54751,\"start\":54138},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":846420},\"end\":55195,\"start\":54753},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":219531210},\"end\":55551,\"start\":55197},{\"attributes\":{\"doi\":\"10.18653/v1/W18-2605\",\"id\":\"b21\",\"matched_paper_id\":3662564},\"end\":56413,\"start\":55553},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":6203757},\"end\":56753,\"start\":56415},{\"attributes\":{\"id\":\"b23\"},\"end\":57202,\"start\":56755},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":1033158},\"end\":57594,\"start\":57204},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":215737187},\"end\":58229,\"start\":57596},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":52967399},\"end\":58599,\"start\":58231},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b27\"},\"end\":58826,\"start\":58601},{\"attributes\":{\"doi\":\"arXiv:2010.01195\",\"id\":\"b28\"},\"end\":59271,\"start\":58828},{\"attributes\":{\"doi\":\"arXiv:2110.01599\",\"id\":\"b29\"},\"end\":59561,\"start\":59273},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":53083555},\"end\":60019,\"start\":59563},{\"attributes\":{\"doi\":\"arXiv:2102.10073\",\"id\":\"b31\"},\"end\":60508,\"start\":60021},{\"attributes\":{\"doi\":\"arXiv:1907.11692\",\"id\":\"b32\"},\"end\":60967,\"start\":60510},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":218470027},\"end\":61385,\"start\":60969},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":231704318},\"end\":62055,\"start\":61387},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":52145665},\"end\":62677,\"start\":62057},{\"attributes\":{\"id\":\"b36\"},\"end\":62786,\"start\":62679},{\"attributes\":{\"doi\":\"arXiv:1901.04085\",\"id\":\"b37\"},\"end\":62992,\"start\":62788},{\"attributes\":{\"doi\":\"arXiv:1904.08375\",\"id\":\"b38\"},\"end\":63261,\"start\":62994},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":19113689},\"end\":63565,\"start\":63263},{\"attributes\":{\"doi\":\"arXiv:1905.01758\",\"id\":\"b40\"},\"end\":63890,\"start\":63567},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":231815627},\"end\":64756,\"start\":63892},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":11816014},\"end\":65278,\"start\":64758},{\"attributes\":{\"doi\":\"10.18653/v1/D16-1264\",\"id\":\"b43\",\"matched_paper_id\":11816014},\"end\":65971,\"start\":65280},{\"attributes\":{\"id\":\"b44\"},\"end\":66261,\"start\":65973},{\"attributes\":{\"doi\":\"arXiv:2110.07367\",\"id\":\"b45\"},\"end\":66428,\"start\":66263},{\"attributes\":{\"id\":\"b46\"},\"end\":66658,\"start\":66430},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":215824871},\"end\":67337,\"start\":66660},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":10761261},\"end\":68001,\"start\":67339},{\"attributes\":{\"doi\":\"arXiv:2007.00808\",\"id\":\"b49\"},\"end\":68466,\"start\":68003},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":235293983},\"end\":69250,\"start\":68468},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":195069387},\"end\":69700,\"start\":69252},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":233289894},\"end\":70321,\"start\":69702},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":238419331},\"end\":70747,\"start\":70323},{\"attributes\":{\"doi\":\"arXiv:2008.10813\",\"id\":\"b54\"},\"end\":71144,\"start\":70749},{\"attributes\":{\"doi\":\"10.1145/3209978.3210092\",\"id\":\"b55\",\"matched_paper_id\":49646876},\"end\":71782,\"start\":71146}]", "bib_title": "[{\"end\":44967,\"start\":44896},{\"end\":45973,\"start\":45882},{\"end\":46576,\"start\":46522},{\"end\":46872,\"start\":46850},{\"end\":47908,\"start\":47818},{\"end\":48350,\"start\":48304},{\"end\":48776,\"start\":48710},{\"end\":49961,\"start\":49888},{\"end\":50507,\"start\":50434},{\"end\":51070,\"start\":50975},{\"end\":52091,\"start\":52023},{\"end\":52527,\"start\":52469},{\"end\":53292,\"start\":53200},{\"end\":53968,\"start\":53900},{\"end\":54204,\"start\":54138},{\"end\":54853,\"start\":54753},{\"end\":55256,\"start\":55197},{\"end\":55639,\"start\":55553},{\"end\":56455,\"start\":56415},{\"end\":57256,\"start\":57204},{\"end\":57654,\"start\":57596},{\"end\":58311,\"start\":58231},{\"end\":59629,\"start\":59563},{\"end\":61034,\"start\":60969},{\"end\":61471,\"start\":61387},{\"end\":62146,\"start\":62057},{\"end\":63341,\"start\":63263},{\"end\":63994,\"start\":63892},{\"end\":64817,\"start\":64758},{\"end\":65339,\"start\":65280},{\"end\":66746,\"start\":66660},{\"end\":67401,\"start\":67339},{\"end\":68543,\"start\":68468},{\"end\":69324,\"start\":69252},{\"end\":69763,\"start\":69702},{\"end\":70376,\"start\":70323},{\"end\":71197,\"start\":71146}]", "bib_author": "[{\"end\":44999,\"start\":44969},{\"end\":45013,\"start\":44999},{\"end\":45026,\"start\":45013},{\"end\":45031,\"start\":45026},{\"end\":45992,\"start\":45975},{\"end\":46006,\"start\":45992},{\"end\":46026,\"start\":46006},{\"end\":46043,\"start\":46026},{\"end\":46060,\"start\":46043},{\"end\":46593,\"start\":46578},{\"end\":46610,\"start\":46593},{\"end\":46626,\"start\":46610},{\"end\":46884,\"start\":46874},{\"end\":46896,\"start\":46884},{\"end\":46909,\"start\":46896},{\"end\":46922,\"start\":46909},{\"end\":47455,\"start\":47427},{\"end\":47467,\"start\":47455},{\"end\":47482,\"start\":47467},{\"end\":47497,\"start\":47482},{\"end\":47510,\"start\":47497},{\"end\":47525,\"start\":47510},{\"end\":47538,\"start\":47525},{\"end\":47552,\"start\":47538},{\"end\":47559,\"start\":47552},{\"end\":47924,\"start\":47910},{\"end\":47934,\"start\":47924},{\"end\":47955,\"start\":47934},{\"end\":48362,\"start\":48352},{\"end\":48375,\"start\":48362},{\"end\":48389,\"start\":48375},{\"end\":48402,\"start\":48389},{\"end\":48790,\"start\":48778},{\"end\":48800,\"start\":48790},{\"end\":48813,\"start\":48800},{\"end\":48827,\"start\":48813},{\"end\":48838,\"start\":48827},{\"end\":48852,\"start\":48838},{\"end\":48865,\"start\":48852},{\"end\":48877,\"start\":48865},{\"end\":49683,\"start\":49671},{\"end\":49697,\"start\":49683},{\"end\":49975,\"start\":49963},{\"end\":49989,\"start\":49975},{\"end\":50527,\"start\":50509},{\"end\":50541,\"start\":50527},{\"end\":50560,\"start\":50541},{\"end\":50575,\"start\":50560},{\"end\":51083,\"start\":51072},{\"end\":51097,\"start\":51083},{\"end\":51110,\"start\":51097},{\"end\":51121,\"start\":51110},{\"end\":51134,\"start\":51121},{\"end\":51148,\"start\":51134},{\"end\":51162,\"start\":51148},{\"end\":51636,\"start\":51624},{\"end\":51649,\"start\":51636},{\"end\":51663,\"start\":51649},{\"end\":51673,\"start\":51663},{\"end\":51683,\"start\":51673},{\"end\":51698,\"start\":51683},{\"end\":51712,\"start\":51698},{\"end\":51725,\"start\":51712},{\"end\":51736,\"start\":51725},{\"end\":52106,\"start\":52093},{\"end\":52118,\"start\":52106},{\"end\":52135,\"start\":52118},{\"end\":52147,\"start\":52135},{\"end\":52159,\"start\":52147},{\"end\":52539,\"start\":52529},{\"end\":52553,\"start\":52539},{\"end\":52999,\"start\":52989},{\"end\":53013,\"start\":52999},{\"end\":53304,\"start\":53294},{\"end\":53316,\"start\":53304},{\"end\":53330,\"start\":53316},{\"end\":53980,\"start\":53970},{\"end\":53992,\"start\":53980},{\"end\":54006,\"start\":53992},{\"end\":54229,\"start\":54206},{\"end\":54247,\"start\":54229},{\"end\":54265,\"start\":54247},{\"end\":54272,\"start\":54265},{\"end\":54286,\"start\":54272},{\"end\":54301,\"start\":54286},{\"end\":54308,\"start\":54301},{\"end\":54868,\"start\":54855},{\"end\":54876,\"start\":54868},{\"end\":55272,\"start\":55258},{\"end\":55286,\"start\":55272},{\"end\":55300,\"start\":55286},{\"end\":55313,\"start\":55300},{\"end\":55649,\"start\":55641},{\"end\":55658,\"start\":55649},{\"end\":55668,\"start\":55658},{\"end\":55680,\"start\":55668},{\"end\":55692,\"start\":55680},{\"end\":55705,\"start\":55692},{\"end\":55715,\"start\":55705},{\"end\":55729,\"start\":55715},{\"end\":55737,\"start\":55729},{\"end\":55751,\"start\":55737},{\"end\":55761,\"start\":55751},{\"end\":55770,\"start\":55761},{\"end\":55784,\"start\":55770},{\"end\":56478,\"start\":56457},{\"end\":56493,\"start\":56478},{\"end\":56514,\"start\":56493},{\"end\":56530,\"start\":56514},{\"end\":56540,\"start\":56530},{\"end\":56558,\"start\":56540},{\"end\":56572,\"start\":56558},{\"end\":56772,\"start\":56755},{\"end\":56784,\"start\":56772},{\"end\":56796,\"start\":56784},{\"end\":56814,\"start\":56796},{\"end\":56827,\"start\":56814},{\"end\":57269,\"start\":57258},{\"end\":57288,\"start\":57269},{\"end\":57302,\"start\":57288},{\"end\":57309,\"start\":57302},{\"end\":57676,\"start\":57656},{\"end\":57689,\"start\":57676},{\"end\":57700,\"start\":57689},{\"end\":57715,\"start\":57700},{\"end\":57726,\"start\":57715},{\"end\":57741,\"start\":57726},{\"end\":57753,\"start\":57741},{\"end\":57766,\"start\":57753},{\"end\":58657,\"start\":58645},{\"end\":58671,\"start\":58657},{\"end\":58675,\"start\":58671},{\"end\":58952,\"start\":58941},{\"end\":58968,\"start\":58952},{\"end\":58978,\"start\":58968},{\"end\":58997,\"start\":58978},{\"end\":59010,\"start\":58997},{\"end\":59367,\"start\":59355},{\"end\":59378,\"start\":59367},{\"end\":59644,\"start\":59631},{\"end\":59653,\"start\":59644},{\"end\":59657,\"start\":59653},{\"end\":60145,\"start\":60134},{\"end\":60158,\"start\":60145},{\"end\":60175,\"start\":60158},{\"end\":60192,\"start\":60175},{\"end\":60207,\"start\":60192},{\"end\":60225,\"start\":60207},{\"end\":60522,\"start\":60510},{\"end\":60532,\"start\":60522},{\"end\":60545,\"start\":60532},{\"end\":60557,\"start\":60545},{\"end\":60571,\"start\":60557},{\"end\":60583,\"start\":60571},{\"end\":60594,\"start\":60583},{\"end\":60606,\"start\":60594},{\"end\":60624,\"start\":60606},{\"end\":60642,\"start\":60624},{\"end\":61045,\"start\":61036},{\"end\":61063,\"start\":61045},{\"end\":61083,\"start\":61063},{\"end\":61100,\"start\":61083},{\"end\":61480,\"start\":61473},{\"end\":61495,\"start\":61480},{\"end\":61508,\"start\":61495},{\"end\":61520,\"start\":61508},{\"end\":61535,\"start\":61520},{\"end\":62165,\"start\":62148},{\"end\":62179,\"start\":62165},{\"end\":62195,\"start\":62179},{\"end\":62209,\"start\":62195},{\"end\":62223,\"start\":62209},{\"end\":62730,\"start\":62712},{\"end\":62806,\"start\":62788},{\"end\":62821,\"start\":62806},{\"end\":63052,\"start\":63034},{\"end\":63062,\"start\":63052},{\"end\":63073,\"start\":63062},{\"end\":63088,\"start\":63073},{\"end\":63357,\"start\":63343},{\"end\":63365,\"start\":63357},{\"end\":63659,\"start\":63640},{\"end\":63673,\"start\":63659},{\"end\":63688,\"start\":63673},{\"end\":64007,\"start\":63996},{\"end\":64020,\"start\":64007},{\"end\":64030,\"start\":64020},{\"end\":64039,\"start\":64030},{\"end\":64052,\"start\":64039},{\"end\":64068,\"start\":64052},{\"end\":64082,\"start\":64068},{\"end\":64090,\"start\":64082},{\"end\":64104,\"start\":64090},{\"end\":64837,\"start\":64819},{\"end\":64849,\"start\":64837},{\"end\":64869,\"start\":64849},{\"end\":64882,\"start\":64869},{\"end\":65359,\"start\":65341},{\"end\":65371,\"start\":65359},{\"end\":65391,\"start\":65371},{\"end\":65404,\"start\":65391},{\"end\":65986,\"start\":65973},{\"end\":65997,\"start\":65986},{\"end\":66007,\"start\":65997},{\"end\":66023,\"start\":66007},{\"end\":66037,\"start\":66023},{\"end\":66045,\"start\":66037},{\"end\":66059,\"start\":66045},{\"end\":66072,\"start\":66059},{\"end\":66505,\"start\":66486},{\"end\":66520,\"start\":66505},{\"end\":66768,\"start\":66748},{\"end\":66783,\"start\":66768},{\"end\":66799,\"start\":66783},{\"end\":66816,\"start\":66799},{\"end\":66837,\"start\":66816},{\"end\":66851,\"start\":66837},{\"end\":67417,\"start\":67403},{\"end\":67425,\"start\":67417},{\"end\":67439,\"start\":67425},{\"end\":67449,\"start\":67439},{\"end\":68014,\"start\":68003},{\"end\":68029,\"start\":68014},{\"end\":68036,\"start\":68029},{\"end\":68052,\"start\":68036},{\"end\":68064,\"start\":68052},{\"end\":68078,\"start\":68064},{\"end\":68092,\"start\":68078},{\"end\":68109,\"start\":68092},{\"end\":68559,\"start\":68545},{\"end\":68571,\"start\":68559},{\"end\":68592,\"start\":68571},{\"end\":69339,\"start\":69326},{\"end\":69351,\"start\":69339},{\"end\":69364,\"start\":69351},{\"end\":69381,\"start\":69364},{\"end\":69389,\"start\":69381},{\"end\":69411,\"start\":69389},{\"end\":69415,\"start\":69411},{\"end\":69779,\"start\":69765},{\"end\":69791,\"start\":69779},{\"end\":69802,\"start\":69791},{\"end\":69815,\"start\":69802},{\"end\":69826,\"start\":69815},{\"end\":69839,\"start\":69826},{\"end\":70390,\"start\":70378},{\"end\":70402,\"start\":70390},{\"end\":70415,\"start\":70402},{\"end\":70429,\"start\":70415},{\"end\":70439,\"start\":70429},{\"end\":70452,\"start\":70439},{\"end\":70763,\"start\":70749},{\"end\":70778,\"start\":70763},{\"end\":70792,\"start\":70778},{\"end\":70804,\"start\":70792},{\"end\":71212,\"start\":71199},{\"end\":71222,\"start\":71212},{\"end\":71233,\"start\":71222},{\"end\":71244,\"start\":71233},{\"end\":71255,\"start\":71244},{\"end\":71268,\"start\":71255}]", "bib_venue": "[{\"end\":45226,\"start\":45051},{\"end\":46150,\"start\":46060},{\"end\":46643,\"start\":46626},{\"end\":47040,\"start\":46922},{\"end\":47425,\"start\":47360},{\"end\":48049,\"start\":47955},{\"end\":48468,\"start\":48402},{\"end\":49040,\"start\":48909},{\"end\":49669,\"start\":49586},{\"end\":50100,\"start\":49989},{\"end\":50656,\"start\":50575},{\"end\":51249,\"start\":51162},{\"end\":51797,\"start\":51752},{\"end\":52222,\"start\":52159},{\"end\":52639,\"start\":52553},{\"end\":52987,\"start\":52906},{\"end\":53472,\"start\":53330},{\"end\":54010,\"start\":54006},{\"end\":54395,\"start\":54308},{\"end\":54937,\"start\":54876},{\"end\":55365,\"start\":55313},{\"end\":55873,\"start\":55804},{\"end\":56576,\"start\":56572},{\"end\":56968,\"start\":56827},{\"end\":57379,\"start\":57309},{\"end\":57859,\"start\":57766},{\"end\":58337,\"start\":58313},{\"end\":58643,\"start\":58601},{\"end\":58939,\"start\":58828},{\"end\":59353,\"start\":59273},{\"end\":59743,\"start\":59657},{\"end\":60132,\"start\":60021},{\"end\":60713,\"start\":60658},{\"end\":61161,\"start\":61100},{\"end\":61655,\"start\":61535},{\"end\":62315,\"start\":62223},{\"end\":62710,\"start\":62679},{\"end\":62865,\"start\":62837},{\"end\":63032,\"start\":62994},{\"end\":63400,\"start\":63365},{\"end\":63638,\"start\":63567},{\"end\":64246,\"start\":64104},{\"end\":64968,\"start\":64882},{\"end\":65510,\"start\":65424},{\"end\":66111,\"start\":66072},{\"end\":66325,\"start\":66279},{\"end\":66484,\"start\":66430},{\"end\":66946,\"start\":66851},{\"end\":67585,\"start\":67449},{\"end\":68208,\"start\":68125},{\"end\":68754,\"start\":68592},{\"end\":69464,\"start\":69415},{\"end\":69950,\"start\":69839},{\"end\":70504,\"start\":70452},{\"end\":70926,\"start\":70820},{\"end\":71398,\"start\":71300},{\"end\":45404,\"start\":45228},{\"end\":46227,\"start\":46152},{\"end\":47145,\"start\":47042},{\"end\":48521,\"start\":48470},{\"end\":49182,\"start\":49042},{\"end\":50198,\"start\":50102},{\"end\":50724,\"start\":50658},{\"end\":51323,\"start\":51251},{\"end\":52712,\"start\":52641},{\"end\":53601,\"start\":53474},{\"end\":54469,\"start\":54397},{\"end\":54985,\"start\":54939},{\"end\":55949,\"start\":55875},{\"end\":57939,\"start\":57861},{\"end\":58409,\"start\":58400},{\"end\":59816,\"start\":59745},{\"end\":61762,\"start\":61657},{\"end\":62394,\"start\":62317},{\"end\":64375,\"start\":64248},{\"end\":65041,\"start\":64970},{\"end\":65596,\"start\":65512},{\"end\":67028,\"start\":66948},{\"end\":67708,\"start\":67587},{\"end\":68903,\"start\":68756},{\"end\":70048,\"start\":69952},{\"end\":71437,\"start\":71400}]"}}}, "year": 2023, "month": 12, "day": 17}