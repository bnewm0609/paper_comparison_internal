{"id": 57400767, "updated": "2023-10-09 23:08:10.449", "metadata": {"title": "The Markov Process as a Compositional Model: A Survey and Tutorial", "authors": "[{\"first\":\"Charles\",\"last\":\"Ames\",\"middle\":[]}]", "venue": null, "journal": "Leonardo", "publication_date": {"year": 2017, "month": null, "day": null}, "abstract": "The author combines a survey of Markov-based efforts in automated composition with a tutorial demonstrating how various theoretical properties associated with Markov processes can be put to practical use. The historical background is traced from A. A. Markov\u2019s original formulation through to the present. A digression into Markov-chain theory introduces \u2018waiting counts\u2019 and \u2018stationary probabilities\u2019. The author\u2019s Demonstration 4 for solo clarinet illustrates how these properties affect the behavior of a melody composed using Markov chains. This simple example becomes a point of departure for increasingly general interpretations of the Markov process. The interpretation of \u2018states\u2019 is reevaluated in the light of recent musical efforts that employ Markov chains of higher-level objects and in the light of other efforts that incorporate relative attributes into the possible interpretations. Other efforts expand Markov\u2019s original definition to embrace \u2018Nth-order\u2019 transitions, evolving transition matrices and chains of chains. The remainder of this article contrasts Markov processes with alternative compositional strategies.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2079172465", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": null, "doi": "10.2307/1575226"}}, "content": {"source": {"pdf_hash": "775e04c89b03d99c144da5f6b39384a84702d6b6", "pdf_src": "JhuPress", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "1e09f08690d049ac82aec3a6215f1f958b2f8fb1", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/775e04c89b03d99c144da5f6b39384a84702d6b6.txt", "contents": "\nThe Markov Process as a Compositional Model: A Survey and Tutorial\n\n\nJohn Myhill \nThe Markov Process as a Compositional Model: A Survey and Tutorial\n3042BA6A46407C4D0B84B0BA303641E0Received 24 May 1988.\nBACKGROUNDCharles Ames (composer).68 Stevenson Boulevard.Eggertsville, NY 14226.U.S.A.\n\nA Markuu chain models the behavior of a sequence of events, each of which can assume any one of a fixed range of states.Changes in state between consecutive events commonly are referred to as transitions.It is convenient to designate the state of the chain prior to a transition as the transition's source (equivalently, the chain's currentstate) and to designate the outcome as the transition's destination (the chain's future state).Consecutive transitions link up so that the destination for one transition serves as the source for the next transition.The range of a Markov chain is, appropriately, the collection of all possible states.For musical applications, we can assume that this collection will always be finite.\n\nIn Markov's model, the behavior ofa chain is distilled into a set ofnumbers called transitionprobabilities.Each transition probability indicates the relative likelihood that the chain will jump to a particular destination, assuming that it currently resides at a particular source.Mathematicians conventionally organize these numbers into a transition matrix (or, more formally, a matrix of transition probabilities).All transition matrices have the form depicted in Matrix 1.\n\n\nSOME\n\n\nDEFINITIONS\n\nwell Markov processes compare to alternative methods in attaining these objectives.\n\nprevious Leonardo article, \"Automated Composition in Retrospect: 1956-1986\", I described a variety of approaches that have been used over the past 30 years to generate musical compositions using computer programs [I].One approach I mentioned only in passing was the Markov process, which I judged at the time to be only of peripheral interest to users of composing programs.Since then, several developments have shown me that the enthusiasm toward Markov processes is much greater than I had estimated.Undoubtedly the strongest indication of misjudgement on my part has been the phenomenal response to M and Jam Factory over the past 2 years--the first time any effort at automated composition has met with the slightest commercial success--but these important programs are only part of a general resurgence of interest in Markov chains over the past decade.Several new approaches toward Markov chains have come to my attention since I wrote my retrospective, and I even found myself personally involved with them in 1986 when John Myhill hired me to implement some Markov processes that could gradually evolve over the course of a musical work he was composing [2].\n\nI choose to integrate the present survey of musical applications with a tutorial because there are some significant theoretical ramifications associated with Markov chains.As with all mathematical formalisms, the intrinsic logic behind Markov processes remains valid no matter what real-world meaning the symbols (in this case the 'states' of the chain) might have.Indeed, the matrix representation devised by mathematicians to describe how Markov chains behave lends a deceptive simplicity; Markov processes can be shown to include many seemingly more complex methodologies as special cases.Although the mathematics is too formidable to elaborate in a tutorial of this nature, a few examples will suffice to demonstrate how one can deduce the behavior of a chain from its matrix [3].The meanings associated with each state of the chain depend, of course, on the application, and for examples of how Markov chains can be applied to music it will generally be best to go directly to the sources.\n\nA constructive evaluation of a compositional procedure ultimately must take into account the music produced; however, different procedures have their different strengths and weaknesses.A composer can estimate the appropriateness of such a procedure by considering his or her musical objectives and by determining how effective the procedure is at realizing these objectives.The last section of this article enumerates a number ofobjectives that have been recurrent among users of composing programs, and it discusses how Markov chains are a primary topic of study in the mathematical discipline of stochastic processes, where they have been used to model random processes, such as the changing fortunes of a gambier, the inventory of a commodity as it is affected by continuing pressures from supply and demand, or genetic fluctuations under random matings and mutations.Markov chains have also played an important role in connection with Claude Shannon's Information Theory.\n\nSince Information Theory was frequently cited but inadequately explained in the music-theoretic writings of the 1950s and 1960s, it is worthwhile to provide a brief outline here.Shannon's 1948 article, \"The Mathematical Theory of Communication\", proposes a formula for measuring the 'information content' of a 'message'-that is, of a sequence of discrete symbols such as a literary text [4], According to these formulas, the least predictable messages have the greatest information content, i.e, information decreases as redundancy increases.It should be pointed out that Shannon's formula often clashes with our intuitive sense of musical meaning, since he considers an unpredictable message as formally equivalent to a random message.(Henceforth, I will enclose the terms 'information content' and 'redundancy' in single quotes when Shannon's interpretation applies.)\n\nShannon models messages as Markov chains, with one state for each different symbol in the message, Consequently, when the 'information content' is high, the transition probabilities will all be close to 1/ n, n being the size of Shannon's 'alphabet'.Conversely, when 'redundancy' is high, transitions will be strongly biased toward certain patterns of succession.Using this model, Shannon proceeds to analyze mathematically how transmitting such a message through a 'noisy channel' (such as a telegraph wire) results in loss of information and what safeguards can be imposed to minimize this loss.\n\nMusical analysts during the late 1940s and 1950s recognized both Markov matrices and Information Theory as potential tools for distilling the norms and deviations of musical styles.Much initial interest in applying Information Theory to music was sparked by Harry Olson's Markov analyses of the songs of Stephen Foster [5] and by Richard Pinkerton's Scientific American article [6].Allen McHose compiled extensive statistics on contrapuntal practices in Bach's chorale harmonizations and used these statistics to deduce 'correct' and 'incorrect' practices [7].In Emotion and Meaning in Music, Leonard Meyer, who was also an early proponent of Markov-style analysis, cites the \"Table of Usual Root Progressions\" from WaIter Piston's Harmony (first published 1941) as \"nothing more than a statement of the system of [conditional] probability which we know as tonal harmony\" [8].Meyer's later \"Meaning in Music and Information Theory\" correlates this attitude directly with Shan-non's ideas [9].Attempts by Meyer and others to apply Information Theory to music have been much less rigorous than Shannon's original formulation.These attempts typically put the listener's faculties for perceiving musical relationships into the role of the 'noisy channel', They then draw inferences concerning how much redundancy may be removed from a musical message before the message begins to lose intelligibility.\n\nMarkov processes have also been used directly in composing programs that have employed both 'composed' transition probabilities and probabilities obtained through analysis of musical source material.Experiment 4 of Lejaren Hiller and Leonard Isaacson's 1957 !lliac Suite stands as the first direct use of Markov chains to compose music.The IIIiac computer selected consecutive intervals for each instrument according to the criteria of harmony (greatest weight to most consonant intervals), proximity (greatest weight to smallest intervals) and combinations of the two [10].The five \"Strophe\" movements of Hiller and Baker's 1963 Computer Cantata derive transition probabilities from the \"Putnum's Camp\" movement of Charles Ives's Three Places in New England and impose these probabilities upon each of the following musical attributes: pitches, durations, dynamics, notes versus rests, and playing styles.In describing their work, Hiller and Baker cite Shannon's notion of 'information content', which Hiller and Baker attempt to treat as a largescale musical attribute analogous to tempo, key, thickness of texture, and so on [11].\n\nIn 1959, lannis Xenakis wrote three works in which he used Markov chains to control successions of large-scale events: Analogique A for string orchestra, Analogique B for sinusoidal sounds, and Syrmos for 18 strings.Xenakis's approach differs strongly from that of Hiller and his collaborators in that Xenakis's processes emulate the behavior of many simultaneous Markov chains.The states of Xenakis's process are constructs, which Xenakis calls 'screens'.Each screen constitutes a configuration of one or more regions of 'musical space' [12], in which some number of elementary 'grains' of sound may occur.\n\nAlthough they have gained little enthusiasm from composers who do not rely on automated decision-making, Markov chains have been employed recurrently in composing programs over Matrix 2. A three-statetransition matrix.\nK' (A) =.5 x K(A) +.4 x K(B) +.4 x K(C) K' (B) =.4 x K(A) +.5 x K(B) +.4 x K(C) K'(C)=.1 x K(A) +.1 x K(B)+.2 x K(C)\nTable3.When all 300 chainsare Initially concentratedIn state A, the equilibriumderivedIn Table 2 rapidly aSHrtl1tse1fhere as well.When the waiting probabilities approach zero, the rate of change grows, and the waiting counts fall to a lower limit of one state (reflecting the original arrival at a state).W grows to infinity as P approaches unity, with the result that a chain evolves very slowly when its waiting probabilities are large.\n\nThe greatest strength of Markov chains is their capability for predicting the immediate future based upon what has happened in the recent past.In an artistic endeavor such as music-which depends heavily upon time as an organizational reference-prediction of expectation (in the psychological sense) is clearly a fundamental dynamic of experience.However, expectation is by no means the only factor upon which listeners base aesthetic judgments; another important basis for judgement is the balance between compositional elements.If these compositional elements operate as states of a Markov chain, then it becomes possible to calculate a set of numbers called stationary probabilities.This set of numbers summarizes the relative balances between elements (or states) overthe long term.\n\nOne can appreciate both the nature of stationary probabilities and the procedure for calculating them by considering a simple case study: Imagine 300 Markov chains all running simultaneously in lockstep.Suppose that all 300 chains share the transition probabilities enumerated in Matrix 2. We want to estimate the overall distribution of states.\n\nAssume for the moment that 100 chains reside at the outset in state A, 100 begin in state D and 100 begin in state C. Consider the first synchronized transition.Of the 100 chains originally residing in state A, the matrix tells us that approximately 50 will remain in state A, 40 will jump to state D and 10 willjump to state C. Similarly, 40 of the 100 original D's would become A's, 50 would remain D's and 1owould become the transition matrix are called the waiting probabilities (or fixed-state probabilities), and they give the probabilities that consecutive events in a chain will occupy the same state.Another way of looking at this is to consider the waiting count, that is, the number of times a single state occurs consecutively.When the waiting probability is P, then the average (or 'expected') waiting count Wis given by the formula:\n\n\nW=_I_ I-P\n\nTwo critical factors contributing to the long-term behavior of a Markov chain are the average waiting counts, which directly affect the rate of activity in the chain, and the stationary probabilities, which predict long-term balances between the various states.These two properties should be taken into account whenever one tries to deduce the behavior of a chain from its transition matrix.\n\nThe transition probabilities along the top-left to bottom-right diagonal of WAITING COUNTS AND STATIONARY PROBABILITIES [13] and with Petr Kotik's interactive transition-matrix editor [14].The \"systems approach to composition\" devised by Curtis Roads [15] can be shown to be based on Markovian principles-although this is not readily apparentand the 'harmonic algorithm' described by Laurie Spiegel [16] is actually a Markov process reminiscent of Piston's \"Table of Usual Root Progressions\".Intentional use of Markov processes has been made by R. C. Zarpov [17], Tracy Lind Peterson [18], Kevin Jones [19], Thomas DeLio [20], Sever Tipei, John Myhill, the group of Claudio Baffioni, Francesco Guerra and Laura Tedeschini Lalli [21], and Darrell Conklin [22].Capabilities for implementing Markov processes are among the features of the Hierarchical Music SpecificatiQTl Language (HMSL) environment for automated composition, which is being developed by Phil Burk, Larry Polansky and David Rosenboom [23].Markov processes also have a close connection with the neural net modeling of music currently being undertaken by researchers such as Jamshed Bharucha [24], who has pointed out that the output from a neural net analysis is a transition matrix.\n\nByfar the most ambitious use of Markov chains in a composing program has been in two programs released in 1987 as commercial products: M by David Zicarelli, Joel Chadabe, John Offenhartz and Antony Widoff, and Jam Factory by Zicarelli [25].Both M and Jam Factoryare real-time compositional processors, exploiting the fact that Markov chains lend themselves well to efficient implementation as computer programs.Both programs have the capability to derive transition probabilities from user-supplied musical excerpts.Table2.GIven 300 simultaneous chains,Initially dividedequallybetweenstates A, Band C, repeated applications of the systemof equations shown In Table 1  Oil-I ' --1--------.For an arbitrary transition, if K(A) , K(B) and K(C) represent the number of chains residing in states A, Band C prior to the transition, while K'(A), K'(B) and K'(C) represent these numbers after the transition, then K (A), K'(B) and K'(C) may be estimated by the system of equations listed in Table I.Table 2 shows what happens when these equations are applied iteratively to an original population of 100 A's, 100B'sand IOOC's, while Table 3 shows what happens when the process starts with 300 A's.\n\nIt is a mathematical fact that no matter how it starts out, the system ultimately will settle down to an equilibrium determined by the stationary probabilities: 44% A's, 44% B's and 12% C's.In general, the stationary probabilities can be derived from any transition matrix by setting up an appropriate system of equations and by applying it iteratively until the numbers settle into equilibrium.Although the procedure is tedious to undertake by hand, it is straightforward to implement on a computer.\n\n\nCOMPOSITION WITH\n\nMARKov CHAINS: A\n\n\nTUTORIAL ExAMPLE\n\nMy composition Demonstration 4 illustrates some of the elementary considerations involved in using Markov chains to compose a piece of music.The piece is one of a series of II didactic studies I composed in 1983 and 1984 to demonstrate techniques of musical composition by computer [26].\n\nThe composing program consists of one short loop: each iteration of this loop generates either a note or a rest, and the iterations continue until the end of the page has been reached (60 measures of 2/4 time).There is no beginning or end and very little 'shaping' of the music; what results is a snapshot of a process that could go on indefinitely.At the beginning of an iteration, the program uses transition matrices to choose an average duration, expressed in sixteenths, and an articulation, expressed as a rest/play probability.This rest/play probability is then used in a random branch to determine whether a note or a rest is to be composed next.If the program decides to compose a note, then it chooses a note duration randomly around the average duration [27] and uses transition matrices to select a degree and a register.If it decides to compose a rest, then it chooses a rest duration randomly around half the average duration.\n\n\nAverage Duration\n\nThere are four average durations available to any note.Expressed in sixteenths, these durations are 2, 3, 5 and 9 for notes (I, 1.5,2.5 and 4.5 for rests).Transitions are guided by the probabilities shown in Matrix 3. One should interpret Matrix 3 by noticing that transitions to destinations other than the source are uniformly likely, and that the waiting probabilities go down as the durations go up.This happens by design.Indeed, by multiplying the average note durations by their average waiting counts, one sees that the period of time over which any average duration holds sway will be approximately two measures: 1-0.688 =16, 1 _ 0.436 =16.\n\nBear in mind that the value 16 is an The remaining triads receive relative weightll from 1 to 6, depending on diasonance; the denominator of each fraction is a 'nonna1izing' value used to convert these weightll into transition probabilities.expectation and that it does not reflect the shorter average durations for rests.The actual periods of time will deviate widely, since the actual (rather than expected) waiting count and the note durations both result from random processes.Since every state has equal access to every other, the relative emphasis placed on each given state is entirely due to the state's waiting probability (see Fig. 1).Fig. 5. Stationary probabilities for chromatic intervals generated by Matrix 6. Intervals are indicated in diatonic scale steps, with the qualifications m (minor), M (major), and P (perfect).IT stands for 'tritone' (an augmented fourth or diminished f\"d'th).The emphasis upon diasonant intervals, especially the minor second, tritone and m~or seventh, reflects the emphasis upon diasonant triads in Matrix 6.\n\n\nChromatic Degrees\n\nThe sequence of chromatic degrees is a first-order Markov chain of displacements through the chromatic scale, which 'wrap-around' at the octave.The chromatic matrix shown in Matrix 6 (see Fig. 4) details the transition probabilities associated with each pair of consecutive displacements.To the extent that it actively excludes 'undesirable' sonorities, Matrix 6 reflects the INTERVAL pitch-selection feature ofKoenig's PROJECT2 composing program; however, the graduated transition probabilities in Matrix 6 also promote 'desirable' sonorities, with the objective of encouraging a consistently dissonant style.These biases are reflected by the fact that the stationary probabilities graphed in Fig. 5 favor dissonant intervals such as seconds, tritones and sevenths.\n\n\nResults\n\nFigure 6 graphs average durations, articulations and registers.Notice that articulations change the least rapidly due to their high waiting probabilities.Average durations change somewhat more frequently, while registers change fairly often.\n\nFigure 7 presents the final result.Floating-point durations are approximated by rounding to the nearest sixteenth note and by accumulating the residue into the next note or rest.When the duration of a rest rounds down to zero, it appears as a break in the slur.FIg. 7. A composition generated by transition Matrices 3-6.This is a 'snapshot' of a process that could go on indef'mitely.Whatever long-term shapes are present in this music are due entirely to the slower-moving processes graphed in Fig. 6.Formally the states assumed by a Markov chain can be anything at all, as long as the range of states is discrete [28].In practice, however, the nature of the events that constitute the chain determines the range of states.In music, these events might be notes or higherlevel objects, such as chords or phrases; in each case, the state of a chain would be a way of describing one of these events.More subtle interpretations are also useful: in this section, I will discuss how states can be relative positions in finite sequences; in later sections, I will illustrate how states can be sequences of states or lower-order Markov chains in their own right.\n\nWhen the events are simple notes, the most common practice has been to let the states be either a simple 'scalar' attribute (e.g.duration alone or pitch alone) or a 'vector' describing two or more attributes simultaneously (e.g.duration, pitch, dynamic and articulation as components of a note).A more subtle approach is to model modes of behavior by using different states to represent alternative inflections ofoneand-the-same attribute.For example, Kotik has represented the one-and-thesame scale degree in ascending and descending versions: the transition probabilities for different versions favor motion in the indicated direction but also incorporate a background likelihood of switching direction.\n\nA common complaint against some early musical applications of Markov chains has been their limited vertical sensitivity.This was especially evident in the Illiac Suite and the Computer Cantata, in which the various instrumental parts were left to go along their independent ways with no 'awareness' of what the other parts were doing.However, many other efforts have remedied this defect by employing higher-level states.As discussed by Xenakis [29], a state can be a 'screen' describing all of the musical activity at a particular instant of time during the composition.States can be chords, as in M and Jam Factory, or they can be polyphonic phrases, as discussed byJones [30].\n\nIt is sometimes advantageous if the states are ordinal positions within a sequence.Consider the event-relation diagram [31] shown in Fig. 8, where the tokens a through m symbolize ordinal elements.These elements might be notes, chords or phrases; the main point is that different elements may possibly represent the same musical ob- indicate, for the most part, the probabilities for advancing 'normally' through the sequence (transitions c --? d, e --? f, j --? k, etc.).3. Other entries to the right of the diagonal give probabilities for skipping ahead (transitions e --? g and h --? j, etc.) or for branching to alternative sequences (transitions b --? C and b --? e). 4. Entries to the left ofthe diagonal give probabilities for looping back (transitions I --? h and I --? b). 5. Since element m is a terminal state, the transition probabilities in the bottom are meaningless; the waiting probability has been set to unity simply for form's sake.The discrimination of Markov modeling can be greatly enhanced by making transition probabilities sensitive to two or more previous states.The orderof a Markov chain indicates the number of past states taken into consideration: events in a 'zeroth-order' chain are independent of their predecessors; events in a (standard) 'first-order' chain are affected directly only by their immediate predecessors; events in a 'second-order' chain are affected by two predecessors, and so on.Zeroth-order chains are described by a one-dimensional probability distribution, while first-order chains require the standard two-dimensional transition matrix.It is therefore logical to extrapolate that each increment in order should add another dimension to the matrix, e.g. a three-dimensional matrix for a second-order chain, or a four-dimensional matrix for a thirdorder chain.However, it can be shown that every Nth order process has an equivalent first-order formulation, which can be obtained by treating sequences of states as states in their own right.In addition, we have already seen that, if the definition of a state takes into account modes of behavior, ordinal positions and other relative properties, it becomes a simple matter to introduce higher-order sensitivity into a nominally first-order matrix.In those instances where l\\Ldimensionai matrices indeed provide the most appropriate representation, the fact that the theoretical number of cells in the matrix increases exponentially with N can be somewhat daunting.However, it is often possible for programmers to effect great savings in computer memory over this theoretical size, since only transitions of nonzero probability need be stored.\n\n\nNTH-ORDER CHAINS\n\nHiller and Baker used Markov chains ofvarious orders in their 1963 Computer Cantata [32], intending that these changing orders would be perceivable as large-scale changes in 'information context'.Figure 9 compares the opening flute passages from Strophes I-III; similar procedures were employed independently to generate each of the remaining instrumental parts.M and Jam Factory allow Markov analysis and generation with up to four orders of discrimination, and even this liberal ceiling undoubtedly will be raised as computers continue to gain in speed and memory.However, Baffioni and his collaborators suggest a point of diminishing returns: \"if [the order] is taken very large ... the sample paths tend to reproduce long pieces of the corpus from which the transition matrix was extracted ('low originality?') and still the lack of general organiza- second matrix in the second section, and so on.It might mean using transition matrices to select certain 'unshaped' attributes but leaving the remaining attributes to other selection methods.In a real-time compositional processor like M orJam Factory, it might mean keeping the same transition matrices but subjecting the results to transformations (e.g.mapping chromatic notes to diatonic notes), which are more easily amenable to real-time manipulation.There are also ways in which Markov's model can be extended directly to accommodate long-term shapes.One method is to allow the transition probabilities to evolve over time; another is to implement the process of selecting transition matrices as a Markov chain in its own right.\n\n\nEvolving Transition Matrices\n\nAn unfinished and untitled work by John Myhill, which I partially programmed, is the first composition, to my knowledge, to employ transition probabilities that evolve gradually under strict parametric control.Myhill's piece was to be constructed from five 2-minute sections, for a total length of 10 minutes.The music was to be played by four antiphonal choirs situated around an auditorium in four locations: on the stage, to the left side, to the right side, and in the balcony.\n\n\nTECHNIQUES OF CONTROL\n\nThe most straightforward approach to shaping Markov-generated music is to select excerpts manually from different chains and to cut and paste these excerpts, again manually, into a satisfactory composite.Markov chains, like all random processes, are inherently contrary and obstinate: over the short term there is absolutely no guarantee that their behavior will conform to the probabilities set forth in the transition matrix.Given this fact, it is reasonable to include a degree of human intervention in the process; the cut-and-paste approach has been characteristic ofKotik's work, for this reason.\n\nHowever, Kotik represents the exception more than the rule; developers of composing programs, for the most part, seek automated methodologies that can accommodate both content and form.This might mean simply instructing the program to use one matrix in the first section of the piece, a\n\n[When] models are being extracted from an existing sequence a new problem arises for high-order models.Most of the long [sequences] will never have been seen, and so there is no basis on which to make a prediction. . . .A compromise which works very well for text is to use a range of models, for example, all models from order 0 to order 5 (Cleary and Witten, 1984).When making [predictions] the order 5 model is first checked, if it has [predictions they are] used, if not the order 4 model is checked and so on [37].\n\nEach of Conklin's viewpoints generates its own list ofweighted predictions, so the program must include an arbiter to mediate between lists and to establish a final order of preferences.If the arbiter determines that there is no common ground between viewpoints, then the program must backtrack and revise an earlier note.Backtracking is an artificial intelligence technique that was not envisioned in Markov's wholly leftto-right scenario, so in this respect the action of the arbiter takes Conklin's program beyond the scope of this article.musical sources, the following complication results: tion at [higher orders] will be clearly recognized\" [33].\n\nRoads's PROCESSjlNG program implements Markov chains of extremely high order, although Roads's program was not intentionally based on Markov's model [34].Roads used PRO-CESSjlNG to create several compositions for tape alone; these included two 1975 pieces, prototype [35] and Pl\u00a3x(revised 1982).The program was inspired by the theory of 'finite automata', a descendent of Information Theory.Each one of 26 automata is given control over one of 26 attributes characterizing a cloud of sonic 'grains' (e.g, starting time, duration, mean frequency, temporal density, registral proximity of grains).The automata are connected by a 26 x 26 'interconnection matrix'; thus, in general, the attribute specified by an automaton during the j+ 1st cloud depends both upon the past history of the automaton itself and upon the attributes specified by the remaining automata during the jth cloud.The process as a whole therefore may be regarded as a Markov chain in which the number of possible states is given by the number of ways in which the attributes may be combined, while the order depends upon how many previous clouds are taken into account by the automata.\n\nDarrell Conklin has devised an approach to Markov modeling that mediates between multiple transition matrices, each 'viewing' the music from a different perspective, e.g.durations, absolute pitches, chromatic degrees, intervals between consecutive pitches in the same voice, intervals between simultaneous pitches in different voices [36].Conklin's approach embraces transitions of arbitrary order; he takes advantage of the fact that a sequence of states can be treated as a state in its own right to express his transition matrices as lists of productions of the form:\n[notej-n, ..., notej-2, notej-I] ~[predictions for note J].\nTo select a production, Conklin's program simply steps through the list until it finds a production whose left side matches the tail end of the music generated so far.Because the productions are derived through analysis of   The segment leng-th determines the period of time separating transitions between choirs in sections 1 and 5 or between pairs of choirs in sections 2 and 4; the program rounded each segment length to the nearest second and accumulated the residue into the next segment.The separation is a single number that controls the antiphonal intensity.When this number is small (near zero), transitions occur between adjacent choirs; when the number is large (near unity), transitions occur across the room or into the balcony, which Myhill defined to be 'separated' from all other choirs.Myhill treated the one-ehoir and twochoir sections separately.For the onechoir sections, he devised a continuum of transition matrices arranged along a line from minimum to maximum separation, and he represented this continuum with the graph shown in Fig. 11a; the graph in Fig. 11b represents his continuum of transition matrices for the two-ehoir sections.Matrix 8 shows what transition probabilities result for a one-ehoir section when the separation in 0.75.To understand how the upper row of probabilities was derived (stage as source state), first locate the 'S' rectangle across the top of Figure 11a and then sketch in a vertical line for 0.75 separation.Notice that the upper one-fourth cuts across the dark region representing transitions from S to B region.A similar procedure may be used to derive transition probabilities from Figure 11b.\n\n\nChains of Chains\n\nIn their 1981 paper, Baffioni, Guerra and Lalli proposed a hierarchical organiz.ation of Markov chains in which the 'low-level' transition matrices used to select the musical details are selected using 'median-level' transition matrices; these 'median-level' matrices in turn are selected by 'higher-level' matrices, and so on, to arbitrary levels of complexity.The approach makes most sense when the lower-level chains are 'highly redundant' from an Infor-mation-Theoretic view and when they are provided with terminal states to kick the process back up into its higher-level modes.Two of the examples presented by Baffioni et al. illustrate thematic variation using low-level matrices with very nonuniform probabilities to represent particular themes.Two other examples incorporate \"some features of classical tonal music\", with matrices to simulate \"chord prolongation, cadences, and modulation\" [38].\n\nCapabilities to implement chains of chains have been included among the many features of HMSL which Burk, Polansky and Rosenboom have been developing since 1985 [39].Like the MUS 1COM P computer-eomposition 'language' of the 1960s [40J, HMSL is a library of compositional procedures, which a composer links together in a main program of his or her own devising.In addition, HMSL provides a set of standardized procedural 'objects', which facilitate implementation of hierarchic processes.Of specific relevance to this article is the TSTRUC TURE object, which consists of the following: (1) a list of n subsidiary objects, which may be musical-event generators, lower-level TSTRUCTURES or other types of HMSL objects; (2) an n x n transition matrix; and (3) a usersupplied procedure for controlling the TSTRUCTURE's behavior.Whenever a subsidiary object completes its task, the TSTRUCTURE employs the behavior procedure to determine which object it should invoke next; the default behavior uses the transition matrix to select an object probabilistically; however, HMSL's designers intentionally have left their system open to alternative interpretations of the matrix.\n\n\nALTERNATIVES TO\n\n\nMARKov CHAINS Statistical Balances\n\nComposers who work with computer programs often have been concerned more with medium-term balances between musical attributes than with short-term note successions.Although transition matrices exercise some influence over balances--through the stationary probabilities--such influence is indirect at best.Unless a transition matrix is 'redundant', one cannot expect the stationary probabilities to become manifest until quite a number of transitions have gone by.For this reason, composing programs generally resort to methods other than Markov chains when balances are important.The traditional mechanism for directly realizing balances is based on the mathematical paradigm of random selection without replacement [41], but I have recently developed a much more versatile technique called statistical feedback [42].\n\n\nTop-Down Grammars\n\nTop-down grammars were introduced to musical theorists through the publications of Fred Lehrdahl and RayJackendoff [43] and to the computer-music community through the writings of Curtis Roads [44], Steven Holtzman [45] and Kevin Jones [46].Arising out of the linguistic theories of Noam Chomsky, top-down grammars quickly demonstrated great power in the formal (non-linguistic) study of structures and processes [47].A formal grammar consists of an archetype (or axiom) and a set of productions.The archetype describes a structure in general terms, while the productions provide the means of deducing details of the structure from generalities.In the symbolic formalism devised by Chomsky, an arbitrary structure can be represented as a string of tokens, which can be either terminalor nonterminal.Productions are expressed as rewrite rules, that is, as instructions for replacing nonterminal tokens with subsidiary strings (substructures).If one begins with an archetype and applies productions repeatedly until all nonterminal tokens have been rewritten as terminal strings, then this final product is said to be an instanceor statement of the archetype.\n\nChomsky's formalism is sufficient in theory, though not always in practice, to embrace a wide variety of formalized compositional approaches, including gestalt hierarchies, fractal generation and Markov chains.Unfortunately, Markov chains have been grossly misrepresented by mathematical linguists who have dismissed them as a trivial instance of a 'context-free' grammar.Quite to the contrary, sensitivity to context is an essential characteristic of any system of conditional probability, especially Markov chains [48].\n\nChomsky and his colleagues make a valid criticism, however, when they point out that Markov chains are exclusively lejt-tQ-right processes predicating all actions upon past behavior.Such systems may be adequate for emulating inanimate processes of nature, but they are totally inadequate for modeling planned activities, such as those in which actions tend to be predicated toward future goals--e.g.language or musical composition.\n\nChomsky's model, by contrast, is a top-doum generative process in which the primary origins and goals can be expressly stated in the archetype, while the paths connecting origins with goals (and connecting subsidiary origins and goals encountered along the way) can be worked out in detail through the productions.Chomsky's model includes Markov chains as a special 'contextsensitive' case, and it offers much more.\n\n\nBottom-Up Processing\n\nA bottom-up approach to composition begins with a kernel of primary material, subjects this material to a variety of transformations (e.g.inversion, retrograde, transposition) and pieces the results together into a piece of music.Most prominent among the systematic bottom-up procedures for composition is the serial approach developed by Schoenberg and extended by composers such as Pierre Boulez, Karlheinz Stockhausen and Milton Babbitt [49]; other examples include the Schillinger system of composition [50] and the germ-eell procedures used in certain pieces by Scriabin and Schoenberg [51].Some very diverse bottom-up approaches have been implemented in composing programs by Emmanual Ghent [52], William Buxton [53] and myself [54].\n\nTo employ a bottom-up approach one must assume a hierarchic division of the whole into parts.This is incompatible with Markov chains as they were originally formulated, since Markov's original model recognizes neither hierarchies nor even boundaries ofany sort.However, the proposal of Baffioni, Guerra, and Lalli removes this incompatibility to some extent.\n\n\nArtificial Intelligence\n\nThere has been some debate over the past few years concerning which methods of automated composition should legitimately be considered artificial intelligence and which should not.Many accept that in order for a program to be called 'intelligent', it is sufficient that it be able to undertake decisions on its own; this has been the basis for the term 'intelligent instrument', which has been used by Laurie Spiegel in reference to her Music Mouse program and by Zicarelli and his colleagues in reference to M and Jam Factory.\n\nI adamantly disagree.Any reader who simply thumbs through a reputable introductory text on artificial intelligence [55] quickly will discover that AI has a well-established repertory of techniques that bear little or no resemblance to Markov procedures-aspects of Conklin's approach excepted.(Music Mouse does not use Markov chains, nor, for that matter, does it employ AI techniques.)Indeed, Markov's approach is probably the most unintelligent decision-making mechanism im- aginable, for it is a veritable paradigm of brute-force modeling.A Markov chain treats each circumstance as a special case; AI, by contrast, employs generalized criteria expressed either as absolute rules or as relative preferences.A Markov chain becomes committed irrevocably to each decision as it is made; AI programs are capable ofbacktracking if they come to an impasse.A Markov chain regards a message (e.g. a musical composition) as a linear sequence of events; AI regards a message as a network of relationships.These differences mean that where Markovchain programs are easy to implement and quick to run, the code for an AI program might well fill this journal, and the execution time for such a program might run into many hours.\n\nThe results produced by AI programs (in conjunction with statistical procedures, top-down grammars and/ or bottom-up processing) have much greater integrity; when used to emulate traditional music, Markov chains at best have produced a garbled 'sense' of the original style, while existing AI programs for traditional music have produced results that are extremely similar to the real thing.\n\n\nCONCLUSIONS\n\nBy no means can Markov chains be said to occupy the cutting edge of progress in automated composition or analysis.They have been around since the turn of the century.They have been dismissed (sometimes unjustly) by mathematicallinguists and by AI researchers.They have long been out of fashion in the music-theory establishment.Despite all this, Markov chains continue to be exploited by composers who work with computer programs.This persistent interest undoubtedly has to do with the fact that Markov's model can be adapted to accommodate just about any discrete system of conditional probability one might think of using in a composing program.In addition, Markov's representation is straightforward, since a chain's behavioral characteristics are described entirely by the transition matrix.This means that standard Markov chains are almost trivial to implement-to a large extent, the matrix is the program.\n\nFrom the earliest of Markov-based composing programs, there have been two equally legitimate ways of obtaining transition probabilities.Either one can 'compose' probabilities to suit generalized compositional objectives, or one can derive probabilities through analysis of musical source material.In both cases, it is critical to define the states of the chain in an appropriate manner.If one chooses to compose one's own probabilities, then one should take into account not only short-term transitions but also the long-term trends described by the stationary probabilities.(Although stationary probabilities are tedious to calculate by hand, it is easy to incorporate a feature for extracting stationary probabilities into a transitionmatrix editor.)If one chooses to derive probabilities analytically, then one should take care that the source material is stylistically uniform; otherwise, the analytic results will not be meaningful.\n\nAs with any technique, the decision of whether to employ transition matrices depends on the compositional requirements of the moment.If Markov's model is sufficient to handle the problem at hand, then its ease and computational efficiency make it a logical way of doing things.If standard firstorder matrices will not suffice, one might consider Mh-order matrices, evolving matrices or chains of chains.Since transition matrices are rarely used in isolation, perhaps a blend of approaches will be needed.If not, then there are plenty of other techniques to choose from.Markov process or Markov chain-a c hai n of states, each determined by the outcome of a random incident.In addition.the following restrictions apply: (I) the range of states (i.e. the range of outcomes available to the random incidents) is fixed, and (2) each random incident is conditioned by the outcome of its predecessor (or.equivalently, by the preceding state).order of a Markov chain-the number of preceding states that directly influence a transition.Each increment in order adds an additional dimension to the transition matrix.probability--a number indicating the likelihood that a random incident will produce a specified outcome.Probabilities range from zero (impossibility) to unity (certainty).with a continuum of gradations in between.\n\nprobabilitydistribution-a function that associates a probability with every conceivable outcome of a random incident.Distributions can be either dis-(Teteor continuous, depending on the range of outcomes.Probability distributions are mathematically identical to statistical distributions, except that the former describes the ideal distribution of a future population, while the latter describes the actual distribution of a population that already exists.\n\nproduction-an elemental)' operation within a generative process.Productions typically transform simple objects into more elaborate ones-as contrasted with reductions; which simplify things.random incident-an incident with unpredictable outcomes.Probability theory circumvents the uncertainty of isolated random incidents by predicting distributions of outcomes from many similar incidents taken together.scalar-a number used to describe one attribute of an object.(See also vector.)stationary probabilities--a distribution predicting how often each state in the range ofa Markov chain will appear over the long term.transition-the progress in a Markov chain from one state to its successor during two consecutive events.transition probability-the probability of making a transition to a specified destination state, given a specified source state.transitionmatrix-a rectangular array detailing the transition probabilities obtained by enumerating every pair of source states and destination states from the range ofa Markov chain and bydetermining the transition probability in each instance.The kth row of a transition matrix gives the probability distribution for the state of the jth event in the chain under the assumption that the j-I st position resides in state k.\n\nunifonn distribution-the distribution of a random process in which each outcome or state is equally likely.\n\nvector-a set of numbers used to describe two or more attributes of an object, e.g. a musical note might be described by a vector consisting of the note's starting time, duration.pitch and dynamic.This is a mathematician's definition of 'vector'; physicists use the word more strictly.(See also scalar.swaiting count-c-the expected number oftimes that a state will directly succeed itselfin a Markov chain.(See also waitingfrrobability.) waiting probability-the prohability that the fih event of a Markov chain will reside in some state k, given that the j-I st event also resides in state k.\n\n2 3 Fig\n23\nFig. I. Stationary probabilities for durations (from Matrix 3).The varying widths of the probability bars reflect the fact that the states affect their own tenures.\n\n\nFig. 2 .\n2\nFig. 2. Stationary probabilities for articulations (from Matrix 4).The stationary probabilities are uniform, since the flow between states is symmetric and the waiting probabilities are equal.C's, while 40 of the 100 original C's would become A's, 40 would become B's and 20 would become C's.The net result of the first transition therefore would be to transform 100 A's, 100 B's and 100 C's into approximately 130A's, 130 B's and 40 C's.For an arbitrary transition, if K(A) , K(B) and K(C) represent the number of chains residing in states A, Band C prior to the transition, while K'(A), K'(B) and K'(C) represent these num-\n\n\n2 3 1\n23\n-0.875 = 16.1-0.813 = 16, 5 9\n\n\nFig. 4 .\n4\nFig. 4. (Matrix 6) Chromatic matrix for Demonstration 4.Each entty gives the probability associated with a pair of two rising chromatic intervals-with middle degrees fixed arbitrarily at B. Any triad containing chromatic identities receives a weight of 0, as do major triads, minor triads, augmented triads and triads with two perfect consonances (e.g.CF-B ~) in any inversion or voicing.The remaining triads receive relative weightll from 1 to 6, depending on diasonance; the denominator of each fraction is a 'nonna1izing' value used to convert these weightll into transition probabilities.\n\n\nFigure 2\n2\nshows that the stationary probabilities are uniform.\n\n\nFig. 6 .\n6\nFig. 6.Graph of average durations, articulations and registers in Demonstration 4, as guided by Matrices 3-5.Rates of activity in each graph are determined by waiting probabilities; the relatively fluid motions in the register graph are due to the fact that Matrix 5 favors transitions between 'nearby' states, while Matrices 3 and 4 encourage abrupt contrasts.\n\n\nFig. 8 .\n8\nFig. 8.An event-nlation diagram representing a procedural network for generating finite sequences using the tokens a through In.This diagram is formally equivalent to Matrix 7.\n\n\n\n\n,~~I.. 1f~8tJ~~.~~~~I~'~J~Fig. 9. Opening flute passages from Strophes I-m of Hiller and Baker's Conaputer Cantata, showing the differences in musical material obtained through zerolb-, f\"Jrst-and 8eCOnd-order ana1ysisof music by Ives.Copyright e 1963 New Music Edition.Used by pennisBion of the publisher, Theodore Presser Company, Bryn Mawr, PA 19010, U.S.A.\n\n\nMatrIx 7 .\n7\nThe event-rel8tlon d1a....m shown In Fl \u2022\u2022 8 .. equivalent to this traMltlon matrix.\n\n\nFig. 10 .\n10\nFig.10.Parameter graph for an unf\"mished composition by John MybiIl.Each %-minute 'section' is pieced together from many short 'segments'; segment lengths are graphed logarithmica1ly from a minimum of %seconds to a maximum of 10.Separations range from 0 to 1.\n\n\n\n\nFigure  10shows how the antiphony was to evolve over the length of the piece.Only one of the four choirs plays at a time in the outermost sections, sections I and 5; the music trades off between pairs of choirs in sections 2 and 4, and all choirs are active continuously in sec-\n\n\nFig\n\nFig. Ila.(left) Transition probabilities for one active choir.Choirs are abbreviated as follows: ~tage, L-Ieft, R-right and B-balcony.Values are derived for a given source state, destination state and separation parameter as follows: (I) Of the four vertically stacked rectangles that together make up the graph as a whole, locate the rectangle with the given source state indicated on the left.(2) Use the key given along the bottom to determine the shading for the given destination state; locate the appropriate destination region within the source rectangle.(3) Locate the given separation parameter along the scale at the top of the graph and sketch a vertical line in this position from the bottom of the source rectangle (zero) to the top of the rectangle (unity).(4) The length of the line segment cutting across the destinationregionwill then indicate the transition probability for the given source, destination and separation.\n\n\nFig. l\nl\nFig. l Ib, (right) Transition probabilities for two active choirs.Choirs are abbreviated as follows: LR-Ieft and right, SB-stage and balcony, LS---Ieft and stage, RS--right and stage, LB-Ieft and balcony, RB-right and balcony.\n\n\n\n\nGlossaryantiphony-musical contrast realized through physical separation of instruments in a performance environment.continuous--a set is continuous, in a practical sense, if every pair ofdistinct elements is connected by intermediate elements.conditionalprobability-random incidents are said to be conditional when their outcomes are influenced by external factors.discrete--a set is discrete if its clements can be represented by integers (e.g.item I, item 2 ... ).event-relation diagram-a diagram showing graphically how the various states ofaMarkov chain progress between one another.Such diagrams are most revealing when transition matrices are 'sparse', that is.when the great majority of transition probabilities are zero.expectation-an average value predicted on the basis of a prohability distribution.\n\n\n\n\n\n\n\nMatrix 1. General form of an n-state matrix.Thetransition probability PlJ lives the relative likelihood of jumpinl from state ;to state j.\nsourcedestinationstate 1state 2state 3state nstate 1Pl,lPI,2P1,3PI,nstate 2P2,1P2,2P2,3P2,nstate nPn,1Pn,2Pn,3Pn,nfollow Qwith U and'! before E exceptafter C', Markov calculated his transi-tion probabilities by tallying pairs ofconsecutive letters (ifPushkin had writ-ten in English, Markov would have hadto compile 26 x 26 = 676 tallies); hethen divided these tallies into groupsbased on first letters (e.g. one group oftallies for pairs ofletters beginning with\nA, one for pairs beginning with B, etc.; each one of these groups fills up one row in the transition matrix); finally, he 'normalized' his transition probabilities by dividing each individual tally by the total of the tallies in the same group.As is evident from Markov's original subject matter, his model is statisticalin nature-the processes it describes need not necessarily be random, However, the fact that one would resort to such a model suggests that the underlying causes and effects are not well understood.At best, the model provides only partial descriptions of nonrandom behavior.\n\n\nTable 1\n1. This'systemof equations'estimatesthe overall distributionof states that will occur wheneachof manysimultaneous chainsun-dertakesone of the transitionsdescribedby Matrix 2.\n\n\n\nMatrix 5. Relistral transitions in Demonstration 4.\nMatrix 3. Duratlonal transitions forDemonstration 4.sourcedestinationsource ---2destination 3 59E3-Eb4E3-Eb4 A3-Ab4 C#4-C5 F#4-F5 Bb4-A5 D5-G#6 G5-F#6 0.66 0.17 0.08 0.05 0.03 0.0120.875 0.042 0.042 0.041A3-Ab40.110.660.110.060.030.020.0130.062 0.813 0.062 0.062C#4-G50.050.100.660.100.050.030.0150.104 0.104 0.688 0.104F#4-F50.030.050.090.660.090.050.0390.187 0.188 0.187 0.438Bb4-A50.010.030.050.100.660.100.05D5-G#60.010.020.030.060.110.660.11G5-F#60.010.030.050.080.170.66Matrix 4. Transitions controlllni ar-ticulations in Demonstration 4.sourcedestination10% 17% 29% 50%10% 0.91 0.02 0.02 0.0517% 0.02 0.91 0.05 0.0229% 0.05 0.02 0.91 0.0250% 0.02 0.05 0.02 0.91Transitionso12345\nwill quickly result In an equilibrium.....nl statesA and B over state C. source the past three decades.Ironically, some elegant instances where Markov chains have been incorporated have been unintentional.Such is the case with the INTERVAI.. feature of Gottfried Michael Koenig's PROJECf2 programFig.3. Stationary probabilities for registers (from Matrix 1).The stationary probabilities are nonuniform even though the waiting probabilities are equal, The central concentration indicates that the transition probabilities act on the whole to direct the music toward the middle registers.\n\n\nCharles Arne, t984\nmU Clarinet STRICTLY J e 80\u00ae Demonstration 4Charles AMESject appearing at different moments into interpret the various matrix entriestime. Figure 8 is equivalent to Matrix 7.as follows:Matrix 7 is filled mostly with zeros1. Entries on the top-left to bottom-(omitted); to an information theorist itright diagonal indicate waiting prob-would have high 'redundancy' and lowabilities (elements d and k; all others'information content'. The fact that theare zero).process has a terminal state m allows us2. Entries immediately to the right ofthe waiting-probabilities diagonal\nArne.\u2022, The Markov Process as a Compositional Model: A Survey and Tutorial\nAmes, The Markov Process as a Compositional Model: A Survey and Tutorial\nAmes, The Markov Process as a Compositional Model: A Surv ey and Tutorial\nA\"\",s, The Markov Process as a Compositional Model: A Survey and Tutorial\nAmes,The Markov Process as a Compositional Model: A Survey and Tutorial\nAl1lI's. The Markov Process as a Compositional Model: A Survey and Tutorial\nAcknowledgmentsI am greatly indebted to the Kurzweil Foundation for its continuing financial support and for the Macintosh computer upon which this article was written.\nAutomated Composition in Retrospect: 1956-1986. I Charles Notes, Ames, Leonardo. 2021987\n\nBefore his creative momentum succumbed during the struggle with cancer that finally took his life in 1987, Myhill had worked out only the general form of a composition, the antiphonal process of which is discussed later in this article. Previously I had also had two direct personal encounters with musical Markov chains: once in 1982 when Petr Kotik asked me to program his interactive Markov-matrix editor, and once in 1983 when I wrote my own short program to illus. The official jargon for such processes is 'timevariant Markov chains. trate basic Markov procedures for a class I was teaching on automated composition\n\nL Joseph, Doob, Two favorite mathematical texts covering Markov chains are William Feller. An Introduction to ProbabilityTheory and Its Applications. New York; New York; New YorkAcademic Press1967. 1953. 1975My primary source was Samuel Karlin and Howard Taylor, A First Course in Stochastic PrOCLSseS\n\nKarlin and Taylor assume intensive mathematical background. \n\nSee also Colin Cherry. On Human Communication. Claude Shannon, 379-423 and 623-656&U Systems Technical Journal. 271948. 1978MIT PressThe Mathematical Theory of Communication. 3rd Ed\n\nA description of Olson's work can be found in Charles Dodge and Thomas Jerse. F Harry, Olson, Music, Engineering Physics, Chap. 8 in ComputerMusic: Synthesis, Composuio\u00ab, andPerftmnance. New York; New YorkSchirmer Books1967. 1985Composition with Computers\n\nInformation Theory and Melody. C Richard, Pinkerton, SdentificAmmcan. 1941956\n\nAllen Irvine, Mchose , TheOmtmpuntalHarmonic Technique of the 18th Century. East Norwalk, CfAppleton-Century-Crofts1947\n\nLeonard B Meyer, Emotionand Meaning in Music. ChicagoUniversity of Chicago Press1956\n\nMeaning in Music and Information Theory. Leonard B Meyer, Chap. 1 in Music, theArts, and Ideas. ChicagoUniversity of Chicago Press1967\n\n. Lejaren Hiller, Leonard Isaacson, 1959. 1979reprinted Greenwood PressNew York\n\nComputer Cantata: An Investigation of Compositional Procedure. Lejaren Hiller, Robert Baker, Perspectives of New. 3621964\n\nMarkovian Stochastic Music-Theory\" and \"Markovian Stochastic Music-Applications. 1971Indiana University Press2Bloomington, INin Formalized Music\n\nPROJECf 2: A Programme for Musical Composition. Gottfried Michael, Koenig , Electronic Music Reporls I. 31970I\n\nThis program was first implemented on an Apple 11 computer in 1982, with myself programming to Kotik's specifications. Kotik learned the name for what he wanted to do from me, but the concept was entirely his own. He has since used the program to compose numerous pieces, beginning with his 1983 Solos and Incidental Harmonies. At Kotik's request, 1adapted the program in 1988 for the Apple Macintosh, upgrading it in the process to include capabilities for steady-state analysis and for chains of chains. When during the spring of 1989 1 faced the challenge of teaching automated composition to non-programmers, the simplicity of Kotik. program made it an ideal way of breaking the ice\n\nA Systems Approach to Composition. Curtis Roads, 1976University of California at San DiegoHonors thesis\n\nSonic Set Theory: A Tonal Music Theory for Computers. Laurie Spiegel, Proceedings of the SecondAnnual Symposiumon Small Computers and the Arts. the SecondAnnual Symposiumon Small Computers and the Arts1982\n\nA Russian about whose work 1 know only indirectly. R C See, Zarpov, Kibemetika i Muzyka. MoscowNauk1971\n\nPeterson uses random walks, a process in which the motions of a travelling subject (e.g. a drunk) are described by transition matrices. L Tracy, Peterson, Proceedings ofthe I 978 International ComputerMusic Omference. the I 978 International ComputerMusic OmferenceSan Francisco1978167Computer Music AssociationInteractive Digital Composition\n\nCompositional Applications of Stochastic Processes. Kevin Jones, ComputerMusicJournal5. 2451981\n\nDelio's Semlade for piano (described in Ames [I) uses a simple transition process in conjunction with many other techniques. \n\nModeling and Generating Music Using Multiple Viewpoints. Claudio Baffioni, Francesco Guerra, Laura Tedeschini Lalli ; John, G Cleary, Proceedings of theFirst Wtnflslwp on Artificial InteUigrmceandMusic. theFirst Wtnflslwp on Artificial InteUigrmceandMusicSt. Paul, MN1981. 198822125Bielefeld UniversityProceedings of the \"5-Tage-Kurs\" of the USP Mathematisimlng\n\nHierarchicalMusic Specification Languagt Reference and User Manual. Larry Polansky, Phil Burk, Robert Marsanyi, Dorothy Hayes, Mitchel Gass, 1988Center for Contemporary Music, Mills CollegeOakland, CA\n\n. Jamshed, \n\nNeural Net Modeling of Music. Bharucha, Proceedings of theFirst Wtnflslwp on Artificial InteUigrmce and Music (SI. theFirst Wtnflslwp on Artificial InteUigrmce and Music (SIPaul, MN1988173\n\nMore exhaustive descriptions appear in the manuals provided with both programs, available from Intelligent Computer Music Systems. David Zicarelli, M , Jam Factory, The Jam Factory manual was written by David Zicarelli, An-tonyWidoffandJoel Chadabe. David Zicarelli, Joel Chadabe, Albany, NY1987. 1987. 1987111312208, U.SA. The M manual was written by\n\nDemonstmtions 7-11 are described in Charles Ames, 'Tutorial on Automated Composition. Proceedings ofthe 1987Internatibnal ComputerMusic Omference. the 1987Internatibnal ComputerMusic OmferenceSan Francisco1987Computer Music AssociationI\n\nNote durations are generated using John Myhill's 'controlled' exponential distribution, limiting the ratio between the maximum and minimum durations to 8. See Lejaren Hiller, Charles Ames, Robert Franki, Perspectives of New Music. 2321985Automated Composition: An Installation at the 1985 International Exposition in Tsukuba\n\nIf the range of states is not discrete, then the transition probabilities cannot be represented as a matrix. However, Markov's model may be generalized to encompass both discrete and continuous ranges by replacing the transition matrix with a conditional probability function of the form P(~, X..l). For example, consider a chain of real numbers in which Xn follows a Gaussian distribution whose mean is X. such a chain simulates Brownian motion\n\n. Xenakis, 12\n\n. Jones, \n\nThis way of graphing event-relations comes to me by wayofJones (19); the notion ofordinal states is the basis of the thematic procedures described in Baffioni. Guerra and Lalli\n\n. Baker Hiller, II\n\n. Guerra Baffioni, Lalli , 21\n\n. M Roads, 15\n\n. Conklin, 22\n\n. Conklin, 22Conklin is referring to\n\nData Compression Using Adaptive Coding and Partial String Matching\", lEEETransInJtmnation Theory, IT. G Cleary, I H Witten, 198430306\n\n. Guerra Baffioni, Lalli , 21\n\n. Polansky, 23\n\n. MUSICOMP. Hiller and BakerII\n\nRandom selection without replacement has been employed to compose numerous pieces, including Herbert Briin's Sonoriferous Loops, G. M. Koenig's Ubung JUr Klaoie: and Thomas Delio's Semlade, Ames (1) describes how all three of these compositions were made. \n\nThe basic procedures for statistical feedback are introduced in Charles Ames, 'Two Pieces for Amplified Guitar. Concurrence. 1986. 1988153important refinements are described in Charles Ames\n\nFred Lehrdahl, Rayjackendoff , A Generative Theory of Tonal Music. Cambridge, MAMIT Press1983\n\nComposing Grammars. Curtis Roads, 1978San FranciscoComputer Music Association2nd Ed.\n\nHoltzman's synopsis of Roads (44) is more readable than Roads's original treatment. Steven Holtzman, 1980951A Generative Grammar Definitional Language for Music\n\n. Jones, 19\n\nThis includes linguistic structures and processes but is not limited to them. See Maurice Gross and Andre Lentin, IntroductibntoFormaiGrammars. 1970Springer-VerlagNew Yorktranslated from the French by Morris Salkoff\n\nAt its heart is a mistaken formulation of transition matrices as productions of the form X ~aX (X non-terminal; a terminal) when transition matrices should correctly be represented as setsof productions of the form aX ~abX (X non-terminal; a, b terminal) where a stands for the source state and b stands for the destination state. This error has been perpetuated by a variety of writers, including Gross and Lentin (47). Roads (44) and Holtzman [45)\n\nSerialComposition and Atonality. See George, Perle , 1972University of California PressBerkeley3rd Ed\n\n. Charles Wourinen, 1979LongmanNew YorkSimple eo.. position\n\nAn algorithmic approach to composition that was very popular before World War 11, but which is all but forgotten today. The Schillinur System of Musical Composition. 1941Carl Fischer\n\nAllen Forte, Free' Atonality. The StructureofAtonal Music. New Haven, CfYale University Press1973II of Perle\n\n[1) describes some of Ghent's work and cites Ghent's articles. Ames, \n\nComputer Music Association, 1980) p. 2,foracase study ofBuxton's score-editing utility being used to produce a composition. See Otto, Laske , San FranciscoSubscore Manipulation as a Tool for Compositional and Sonic Design\n\nProtocot. Motivation, Design, and Production of a Composition for Solo Piano. See Charles, Ames , 198211213AmesSee also the descriptions of Demonstmtions\n\nThe Handbook of Artificial Intelligrmce. E G Barr, Paul Cohen, Edward Feigenbaum, Encyclopedia ofArtificial Intelligrmce. 6381981. 1987John Wiley & SonsAI in Music\n", "annotations": {"author": "[{\"end\":82,\"start\":70}]", "publisher": null, "author_last_name": "[{\"end\":81,\"start\":75}]", "author_first_name": "[{\"end\":74,\"start\":70}]", "author_affiliation": null, "title": "[{\"end\":67,\"start\":1},{\"end\":149,\"start\":83}]", "venue": null, "abstract": "[{\"end\":290,\"start\":204}]", "bib_ref": "[{\"end\":1817,\"start\":1814},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2766,\"start\":2763},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3552,\"start\":3549},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5132,\"start\":5129},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6534,\"start\":6531},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6593,\"start\":6590},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6771,\"start\":6768},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7087,\"start\":7084},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7203,\"start\":7200},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8184,\"start\":8180},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8743,\"start\":8739},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9288,\"start\":9284},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12642,\"start\":12638},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12706,\"start\":12702},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12773,\"start\":12769},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12921,\"start\":12917},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13080,\"start\":13076},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13106,\"start\":13102},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13124,\"start\":13120},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13143,\"start\":13139},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":13250,\"start\":13246},{\"end\":13276,\"start\":13264},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":13521,\"start\":13517},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13677,\"start\":13673},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14006,\"start\":14002},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":15802,\"start\":15798},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16574,\"start\":16570},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":20131,\"start\":20127},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":21825,\"start\":21821},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":22054,\"start\":22050},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":22180,\"start\":22176},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":24811,\"start\":24807},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":28109,\"start\":28084},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":28261,\"start\":28257},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":28916,\"start\":28912},{\"end\":29072,\"start\":29068},{\"end\":29190,\"start\":29186},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":30413,\"start\":30409},{\"end\":31875,\"start\":31867},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":33284,\"start\":33280},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":33452,\"start\":33448},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":35232,\"start\":35228},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":35328,\"start\":35324},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":35470,\"start\":35466},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":35548,\"start\":35544},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":35570,\"start\":35566},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":35591,\"start\":35587},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":35768,\"start\":35764},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":37030,\"start\":37026},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":38350,\"start\":38346},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":38417,\"start\":38413},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":38501,\"start\":38497},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":38607,\"start\":38603},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":38628,\"start\":38624},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":38644,\"start\":38640},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":39681,\"start\":39677}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":46969,\"start\":46792},{\"attributes\":{\"id\":\"fig_2\"},\"end\":47608,\"start\":46970},{\"attributes\":{\"id\":\"fig_3\"},\"end\":47649,\"start\":47609},{\"attributes\":{\"id\":\"fig_4\"},\"end\":48255,\"start\":47650},{\"attributes\":{\"id\":\"fig_5\"},\"end\":48321,\"start\":48256},{\"attributes\":{\"id\":\"fig_6\"},\"end\":48696,\"start\":48322},{\"attributes\":{\"id\":\"fig_7\"},\"end\":48886,\"start\":48697},{\"attributes\":{\"id\":\"fig_8\"},\"end\":49251,\"start\":48887},{\"attributes\":{\"id\":\"fig_9\"},\"end\":49351,\"start\":49252},{\"attributes\":{\"id\":\"fig_10\"},\"end\":49626,\"start\":49352},{\"attributes\":{\"id\":\"fig_11\"},\"end\":49909,\"start\":49627},{\"attributes\":{\"id\":\"fig_13\"},\"end\":50854,\"start\":49910},{\"attributes\":{\"id\":\"fig_14\"},\"end\":51092,\"start\":50855},{\"attributes\":{\"id\":\"fig_15\"},\"end\":51907,\"start\":51093},{\"end\":51912,\"start\":51908},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":53112,\"start\":51913},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":53296,\"start\":53113},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":54625,\"start\":53297},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":55218,\"start\":54626}]", "paragraph": "[{\"end\":1015,\"start\":292},{\"end\":1493,\"start\":1017},{\"end\":1599,\"start\":1516},{\"end\":2767,\"start\":1601},{\"end\":3763,\"start\":2769},{\"end\":4740,\"start\":3765},{\"end\":5611,\"start\":4742},{\"end\":6210,\"start\":5613},{\"end\":7609,\"start\":6212},{\"end\":8744,\"start\":7611},{\"end\":9353,\"start\":8746},{\"end\":9573,\"start\":9355},{\"end\":10129,\"start\":9691},{\"end\":10916,\"start\":10131},{\"end\":11263,\"start\":10918},{\"end\":12111,\"start\":11265},{\"end\":12516,\"start\":12125},{\"end\":13765,\"start\":12518},{\"end\":14956,\"start\":13767},{\"end\":15458,\"start\":14958},{\"end\":15495,\"start\":15479},{\"end\":15803,\"start\":15516},{\"end\":16745,\"start\":15805},{\"end\":17414,\"start\":16766},{\"end\":18469,\"start\":17416},{\"end\":19257,\"start\":18491},{\"end\":19510,\"start\":19269},{\"end\":20667,\"start\":19512},{\"end\":21374,\"start\":20669},{\"end\":22055,\"start\":21376},{\"end\":24702,\"start\":22057},{\"end\":26311,\"start\":24723},{\"end\":26825,\"start\":26344},{\"end\":27453,\"start\":26851},{\"end\":27741,\"start\":27455},{\"end\":28262,\"start\":27743},{\"end\":28917,\"start\":28264},{\"end\":30073,\"start\":28919},{\"end\":30645,\"start\":30075},{\"end\":32360,\"start\":30706},{\"end\":33285,\"start\":32381},{\"end\":34455,\"start\":33287},{\"end\":35329,\"start\":34512},{\"end\":36508,\"start\":35351},{\"end\":37031,\"start\":36510},{\"end\":37464,\"start\":37033},{\"end\":37881,\"start\":37466},{\"end\":38645,\"start\":37906},{\"end\":39005,\"start\":38647},{\"end\":39560,\"start\":39033},{\"end\":40778,\"start\":39562},{\"end\":41171,\"start\":40780},{\"end\":42098,\"start\":41187},{\"end\":43037,\"start\":42100},{\"end\":44358,\"start\":43039},{\"end\":44816,\"start\":44360},{\"end\":46089,\"start\":44818},{\"end\":46198,\"start\":46091},{\"end\":46791,\"start\":46200},{\"end\":46968,\"start\":46804},{\"end\":47607,\"start\":46982},{\"end\":47648,\"start\":47619},{\"end\":48254,\"start\":47662},{\"end\":48320,\"start\":48268},{\"end\":48695,\"start\":48334},{\"end\":48885,\"start\":48709},{\"end\":49250,\"start\":48890},{\"end\":49350,\"start\":49266},{\"end\":49625,\"start\":49366},{\"end\":49908,\"start\":49630},{\"end\":50853,\"start\":49916},{\"end\":51091,\"start\":50865},{\"end\":51906,\"start\":51096},{\"end\":53111,\"start\":52517},{\"end\":53351,\"start\":53300},{\"end\":54624,\"start\":54038}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9690,\"start\":9574},{\"attributes\":{\"id\":\"formula_1\"},\"end\":30705,\"start\":30646}]", "table_ref": "[{\"end\":9787,\"start\":9786},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":14433,\"start\":14432},{\"end\":14757,\"start\":14756},{\"end\":14765,\"start\":14764},{\"end\":14899,\"start\":14898}]", "section_header": "[{\"end\":1500,\"start\":1496},{\"end\":1514,\"start\":1503},{\"end\":12123,\"start\":12114},{\"end\":15477,\"start\":15461},{\"end\":15514,\"start\":15498},{\"end\":16764,\"start\":16748},{\"end\":18489,\"start\":18472},{\"end\":19267,\"start\":19260},{\"end\":24721,\"start\":24705},{\"end\":26342,\"start\":26314},{\"end\":26849,\"start\":26828},{\"end\":32379,\"start\":32363},{\"end\":34473,\"start\":34458},{\"end\":34510,\"start\":34476},{\"end\":35349,\"start\":35332},{\"end\":37904,\"start\":37884},{\"end\":39031,\"start\":39008},{\"end\":41185,\"start\":41174},{\"end\":46800,\"start\":46793},{\"end\":46979,\"start\":46971},{\"end\":47615,\"start\":47610},{\"end\":47659,\"start\":47651},{\"end\":48265,\"start\":48257},{\"end\":48331,\"start\":48323},{\"end\":48706,\"start\":48698},{\"end\":49263,\"start\":49253},{\"end\":49362,\"start\":49353},{\"end\":49914,\"start\":49911},{\"end\":50862,\"start\":50856},{\"end\":52052,\"start\":51914},{\"end\":53121,\"start\":53114},{\"end\":54645,\"start\":54627}]", "table": "[{\"end\":52516,\"start\":52053},{\"end\":53296,\"start\":53123},{\"end\":54037,\"start\":53352},{\"end\":55218,\"start\":54646}]", "figure_caption": "[{\"end\":46969,\"start\":46803},{\"end\":47608,\"start\":46981},{\"end\":47649,\"start\":47618},{\"end\":48255,\"start\":47661},{\"end\":48321,\"start\":48267},{\"end\":48696,\"start\":48333},{\"end\":48886,\"start\":48708},{\"end\":49251,\"start\":48889},{\"end\":49351,\"start\":49265},{\"end\":49626,\"start\":49365},{\"end\":49909,\"start\":49629},{\"end\":50854,\"start\":49915},{\"end\":51092,\"start\":50864},{\"end\":51907,\"start\":51095},{\"end\":51912,\"start\":51910},{\"end\":53352,\"start\":53299}]", "figure_ref": "[{\"end\":18059,\"start\":18058},{\"end\":18067,\"start\":18066},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18685,\"start\":18684},{\"end\":19191,\"start\":19190},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":19277,\"start\":19276},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":19520,\"start\":19519},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":19779,\"start\":19778},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":20013,\"start\":20012},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":22196,\"start\":22195},{\"end\":24927,\"start\":24926},{\"end\":31768,\"start\":31765},{\"end\":31791,\"start\":31788},{\"end\":32116,\"start\":32113},{\"end\":32359,\"start\":32356}]", "bib_author_first_name": "[{\"end\":55881,\"start\":55880},{\"end\":55889,\"start\":55882},{\"end\":56546,\"start\":56545},{\"end\":56963,\"start\":56957},{\"end\":57172,\"start\":57171},{\"end\":57205,\"start\":57194},{\"end\":57382,\"start\":57381},{\"end\":57434,\"start\":57429},{\"end\":57449,\"start\":57443},{\"end\":57557,\"start\":57550},{\"end\":57559,\"start\":57558},{\"end\":57684,\"start\":57677},{\"end\":57686,\"start\":57685},{\"end\":57781,\"start\":57774},{\"end\":57797,\"start\":57790},{\"end\":57923,\"start\":57916},{\"end\":57938,\"start\":57932},{\"end\":58179,\"start\":58170},{\"end\":58195,\"start\":58189},{\"end\":58963,\"start\":58957},{\"end\":59087,\"start\":59081},{\"end\":59286,\"start\":59285},{\"end\":59288,\"start\":59287},{\"end\":59476,\"start\":59475},{\"end\":59740,\"start\":59735},{\"end\":59971,\"start\":59964},{\"end\":59991,\"start\":59982},{\"end\":60005,\"start\":60000},{\"end\":60032,\"start\":60031},{\"end\":60343,\"start\":60338},{\"end\":60358,\"start\":60354},{\"end\":60371,\"start\":60365},{\"end\":60389,\"start\":60382},{\"end\":60404,\"start\":60397},{\"end\":60811,\"start\":60806},{\"end\":60824,\"start\":60823},{\"end\":60830,\"start\":60827},{\"end\":60930,\"start\":60925},{\"end\":60946,\"start\":60942},{\"end\":61424,\"start\":61421},{\"end\":61448,\"start\":61441},{\"end\":61461,\"start\":61455},{\"end\":62250,\"start\":62245},{\"end\":62271,\"start\":62265},{\"end\":62287,\"start\":62282},{\"end\":62297,\"start\":62296},{\"end\":62465,\"start\":62464},{\"end\":62475,\"start\":62474},{\"end\":62477,\"start\":62476},{\"end\":62505,\"start\":62499},{\"end\":62521,\"start\":62516},{\"end\":63029,\"start\":63025},{\"end\":63053,\"start\":63040},{\"end\":63146,\"start\":63140},{\"end\":63296,\"start\":63290},{\"end\":64085,\"start\":64082},{\"end\":64099,\"start\":64094},{\"end\":64161,\"start\":64154},{\"end\":64402,\"start\":64397},{\"end\":64705,\"start\":64702},{\"end\":64717,\"start\":64712},{\"end\":64882,\"start\":64879},{\"end\":64896,\"start\":64892},{\"end\":64998,\"start\":64997},{\"end\":65000,\"start\":64999},{\"end\":65011,\"start\":65007},{\"end\":65025,\"start\":65019}]", "bib_author_last_name": "[{\"end\":55895,\"start\":55890},{\"end\":55901,\"start\":55897},{\"end\":56553,\"start\":56547},{\"end\":56559,\"start\":56555},{\"end\":56971,\"start\":56964},{\"end\":57178,\"start\":57173},{\"end\":57185,\"start\":57180},{\"end\":57192,\"start\":57187},{\"end\":57213,\"start\":57206},{\"end\":57390,\"start\":57383},{\"end\":57401,\"start\":57392},{\"end\":57441,\"start\":57435},{\"end\":57565,\"start\":57560},{\"end\":57692,\"start\":57687},{\"end\":57788,\"start\":57782},{\"end\":57806,\"start\":57798},{\"end\":57930,\"start\":57924},{\"end\":57944,\"start\":57939},{\"end\":58187,\"start\":58180},{\"end\":58969,\"start\":58964},{\"end\":59095,\"start\":59088},{\"end\":59292,\"start\":59289},{\"end\":59300,\"start\":59294},{\"end\":59482,\"start\":59477},{\"end\":59492,\"start\":59484},{\"end\":59746,\"start\":59741},{\"end\":59980,\"start\":59972},{\"end\":59998,\"start\":59992},{\"end\":60029,\"start\":60006},{\"end\":60039,\"start\":60033},{\"end\":60352,\"start\":60344},{\"end\":60363,\"start\":60359},{\"end\":60380,\"start\":60372},{\"end\":60395,\"start\":60390},{\"end\":60409,\"start\":60405},{\"end\":60481,\"start\":60474},{\"end\":60523,\"start\":60515},{\"end\":60821,\"start\":60812},{\"end\":60838,\"start\":60831},{\"end\":60940,\"start\":60931},{\"end\":60954,\"start\":60947},{\"end\":61439,\"start\":61425},{\"end\":61453,\"start\":61449},{\"end\":61468,\"start\":61462},{\"end\":62048,\"start\":62041},{\"end\":62061,\"start\":62056},{\"end\":62257,\"start\":62251},{\"end\":62280,\"start\":62272},{\"end\":62303,\"start\":62298},{\"end\":62318,\"start\":62311},{\"end\":62333,\"start\":62326},{\"end\":62472,\"start\":62466},{\"end\":62484,\"start\":62478},{\"end\":62514,\"start\":62506},{\"end\":62538,\"start\":62530},{\"end\":63038,\"start\":63030},{\"end\":63152,\"start\":63147},{\"end\":63305,\"start\":63297},{\"end\":63375,\"start\":63370},{\"end\":64092,\"start\":64086},{\"end\":64170,\"start\":64162},{\"end\":64408,\"start\":64403},{\"end\":64574,\"start\":64570},{\"end\":64710,\"start\":64706},{\"end\":64890,\"start\":64883},{\"end\":65005,\"start\":65001},{\"end\":65017,\"start\":65012},{\"end\":65036,\"start\":65026}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":58264446},\"end\":55920,\"start\":55832},{\"attributes\":{\"id\":\"b1\"},\"end\":56543,\"start\":55922},{\"attributes\":{\"id\":\"b2\"},\"end\":56846,\"start\":56545},{\"attributes\":{\"id\":\"b3\"},\"end\":56908,\"start\":56848},{\"attributes\":{\"doi\":\"379-423 and 623-656\",\"id\":\"b4\"},\"end\":57091,\"start\":56910},{\"attributes\":{\"id\":\"b5\"},\"end\":57348,\"start\":57093},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":121058413},\"end\":57427,\"start\":57350},{\"attributes\":{\"id\":\"b7\"},\"end\":57548,\"start\":57429},{\"attributes\":{\"id\":\"b8\"},\"end\":57634,\"start\":57550},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":194984993},\"end\":57770,\"start\":57636},{\"attributes\":{\"id\":\"b10\"},\"end\":57851,\"start\":57772},{\"attributes\":{\"id\":\"b11\"},\"end\":57974,\"start\":57853},{\"attributes\":{\"id\":\"b12\"},\"end\":58120,\"start\":57976},{\"attributes\":{\"id\":\"b13\"},\"end\":58232,\"start\":58122},{\"attributes\":{\"id\":\"b14\"},\"end\":58920,\"start\":58234},{\"attributes\":{\"id\":\"b15\"},\"end\":59025,\"start\":58922},{\"attributes\":{\"id\":\"b16\"},\"end\":59232,\"start\":59027},{\"attributes\":{\"id\":\"b17\"},\"end\":59337,\"start\":59234},{\"attributes\":{\"id\":\"b18\"},\"end\":59681,\"start\":59339},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":62652181},\"end\":59778,\"start\":59683},{\"attributes\":{\"id\":\"b20\"},\"end\":59905,\"start\":59780},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":65307496},\"end\":60268,\"start\":59907},{\"attributes\":{\"id\":\"b22\"},\"end\":60470,\"start\":60270},{\"attributes\":{\"id\":\"b23\"},\"end\":60483,\"start\":60472},{\"attributes\":{\"id\":\"b24\"},\"end\":60673,\"start\":60485},{\"attributes\":{\"id\":\"b25\"},\"end\":61026,\"start\":60675},{\"attributes\":{\"id\":\"b26\"},\"end\":61264,\"start\":61028},{\"attributes\":{\"id\":\"b27\"},\"end\":61590,\"start\":61266},{\"attributes\":{\"id\":\"b28\"},\"end\":62037,\"start\":61592},{\"attributes\":{\"id\":\"b29\"},\"end\":62052,\"start\":62039},{\"attributes\":{\"id\":\"b30\"},\"end\":62063,\"start\":62054},{\"attributes\":{\"id\":\"b31\"},\"end\":62241,\"start\":62065},{\"attributes\":{\"id\":\"b32\"},\"end\":62261,\"start\":62243},{\"attributes\":{\"id\":\"b33\"},\"end\":62292,\"start\":62263},{\"attributes\":{\"id\":\"b34\"},\"end\":62307,\"start\":62294},{\"attributes\":{\"id\":\"b35\"},\"end\":62322,\"start\":62309},{\"attributes\":{\"id\":\"b36\"},\"end\":62360,\"start\":62324},{\"attributes\":{\"id\":\"b37\"},\"end\":62495,\"start\":62362},{\"attributes\":{\"id\":\"b38\"},\"end\":62526,\"start\":62497},{\"attributes\":{\"id\":\"b39\"},\"end\":62542,\"start\":62528},{\"attributes\":{\"id\":\"b40\"},\"end\":62574,\"start\":62544},{\"attributes\":{\"id\":\"b41\"},\"end\":62832,\"start\":62576},{\"attributes\":{\"id\":\"b42\"},\"end\":63023,\"start\":62834},{\"attributes\":{\"id\":\"b43\"},\"end\":63118,\"start\":63025},{\"attributes\":{\"id\":\"b44\"},\"end\":63204,\"start\":63120},{\"attributes\":{\"id\":\"b45\"},\"end\":63366,\"start\":63206},{\"attributes\":{\"id\":\"b46\"},\"end\":63379,\"start\":63368},{\"attributes\":{\"id\":\"b47\"},\"end\":63596,\"start\":63381},{\"attributes\":{\"id\":\"b48\"},\"end\":64047,\"start\":63598},{\"attributes\":{\"id\":\"b49\"},\"end\":64150,\"start\":64049},{\"attributes\":{\"id\":\"b50\"},\"end\":64211,\"start\":64152},{\"attributes\":{\"id\":\"b51\"},\"end\":64395,\"start\":64213},{\"attributes\":{\"id\":\"b52\"},\"end\":64505,\"start\":64397},{\"attributes\":{\"id\":\"b53\"},\"end\":64576,\"start\":64507},{\"attributes\":{\"id\":\"b54\"},\"end\":64799,\"start\":64578},{\"attributes\":{\"id\":\"b55\"},\"end\":64954,\"start\":64801},{\"attributes\":{\"id\":\"b56\"},\"end\":65119,\"start\":64956}]", "bib_title": "[{\"end\":55878,\"start\":55832},{\"end\":56955,\"start\":56910},{\"end\":57169,\"start\":57093},{\"end\":57379,\"start\":57350},{\"end\":57675,\"start\":57636},{\"end\":57914,\"start\":57853},{\"end\":58168,\"start\":58122},{\"end\":59079,\"start\":59027},{\"end\":59283,\"start\":59234},{\"end\":59473,\"start\":59339},{\"end\":59733,\"start\":59683},{\"end\":59962,\"start\":59907},{\"end\":60513,\"start\":60485},{\"end\":60804,\"start\":60675},{\"end\":61112,\"start\":61028},{\"end\":61419,\"start\":61266},{\"end\":62944,\"start\":62834},{\"end\":63927,\"start\":63598},{\"end\":64331,\"start\":64213},{\"end\":64995,\"start\":64956}]", "bib_author": "[{\"end\":55897,\"start\":55880},{\"end\":55903,\"start\":55897},{\"end\":56555,\"start\":56545},{\"end\":56561,\"start\":56555},{\"end\":56973,\"start\":56957},{\"end\":57180,\"start\":57171},{\"end\":57187,\"start\":57180},{\"end\":57194,\"start\":57187},{\"end\":57215,\"start\":57194},{\"end\":57392,\"start\":57381},{\"end\":57403,\"start\":57392},{\"end\":57443,\"start\":57429},{\"end\":57452,\"start\":57443},{\"end\":57567,\"start\":57550},{\"end\":57694,\"start\":57677},{\"end\":57790,\"start\":57774},{\"end\":57808,\"start\":57790},{\"end\":57932,\"start\":57916},{\"end\":57946,\"start\":57932},{\"end\":58189,\"start\":58170},{\"end\":58198,\"start\":58189},{\"end\":58971,\"start\":58957},{\"end\":59097,\"start\":59081},{\"end\":59294,\"start\":59285},{\"end\":59302,\"start\":59294},{\"end\":59484,\"start\":59475},{\"end\":59494,\"start\":59484},{\"end\":59748,\"start\":59735},{\"end\":59982,\"start\":59964},{\"end\":60000,\"start\":59982},{\"end\":60031,\"start\":60000},{\"end\":60041,\"start\":60031},{\"end\":60354,\"start\":60338},{\"end\":60365,\"start\":60354},{\"end\":60382,\"start\":60365},{\"end\":60397,\"start\":60382},{\"end\":60411,\"start\":60397},{\"end\":60483,\"start\":60474},{\"end\":60525,\"start\":60515},{\"end\":60823,\"start\":60806},{\"end\":60827,\"start\":60823},{\"end\":60840,\"start\":60827},{\"end\":61441,\"start\":61421},{\"end\":61455,\"start\":61441},{\"end\":61470,\"start\":61455},{\"end\":62050,\"start\":62041},{\"end\":62063,\"start\":62056},{\"end\":62259,\"start\":62245},{\"end\":62282,\"start\":62265},{\"end\":62290,\"start\":62282},{\"end\":62305,\"start\":62296},{\"end\":62320,\"start\":62311},{\"end\":62335,\"start\":62326},{\"end\":62474,\"start\":62464},{\"end\":62486,\"start\":62474},{\"end\":62516,\"start\":62499},{\"end\":62524,\"start\":62516},{\"end\":62540,\"start\":62530},{\"end\":63040,\"start\":63025},{\"end\":63056,\"start\":63040},{\"end\":63154,\"start\":63140},{\"end\":63307,\"start\":63290},{\"end\":63377,\"start\":63370},{\"end\":64094,\"start\":64082},{\"end\":64102,\"start\":64094},{\"end\":64172,\"start\":64154},{\"end\":64410,\"start\":64397},{\"end\":64576,\"start\":64570},{\"end\":64712,\"start\":64702},{\"end\":64720,\"start\":64712},{\"end\":64892,\"start\":64879},{\"end\":64899,\"start\":64892},{\"end\":65007,\"start\":64997},{\"end\":65019,\"start\":65007},{\"end\":65038,\"start\":65019}]", "bib_venue": "[{\"end\":55911,\"start\":55903},{\"end\":56390,\"start\":55922},{\"end\":56693,\"start\":56561},{\"end\":56906,\"start\":56848},{\"end\":57020,\"start\":56992},{\"end\":57278,\"start\":57215},{\"end\":57418,\"start\":57403},{\"end\":57503,\"start\":57452},{\"end\":57594,\"start\":57567},{\"end\":57730,\"start\":57694},{\"end\":57965,\"start\":57946},{\"end\":58055,\"start\":57976},{\"end\":58224,\"start\":58198},{\"end\":58560,\"start\":58234},{\"end\":58955,\"start\":58922},{\"end\":59169,\"start\":59097},{\"end\":59321,\"start\":59302},{\"end\":59555,\"start\":59494},{\"end\":59769,\"start\":59748},{\"end\":59903,\"start\":59780},{\"end\":60108,\"start\":60041},{\"end\":60336,\"start\":60270},{\"end\":60598,\"start\":60525},{\"end\":60923,\"start\":60840},{\"end\":61173,\"start\":61114},{\"end\":61495,\"start\":61470},{\"end\":61997,\"start\":61592},{\"end\":62223,\"start\":62065},{\"end\":62462,\"start\":62362},{\"end\":62554,\"start\":62546},{\"end\":62830,\"start\":62576},{\"end\":62957,\"start\":62946},{\"end\":63090,\"start\":63056},{\"end\":63138,\"start\":63120},{\"end\":63288,\"start\":63206},{\"end\":63523,\"start\":63381},{\"end\":64017,\"start\":63929},{\"end\":64080,\"start\":64049},{\"end\":64377,\"start\":64333},{\"end\":64425,\"start\":64410},{\"end\":64454,\"start\":64427},{\"end\":64568,\"start\":64507},{\"end\":64700,\"start\":64578},{\"end\":64877,\"start\":64801},{\"end\":65076,\"start\":65038},{\"end\":56723,\"start\":56695},{\"end\":57298,\"start\":57280},{\"end\":57521,\"start\":57505},{\"end\":57603,\"start\":57596},{\"end\":57739,\"start\":57732},{\"end\":59228,\"start\":59171},{\"end\":59329,\"start\":59323},{\"end\":59617,\"start\":59557},{\"end\":60174,\"start\":60110},{\"end\":60666,\"start\":60600},{\"end\":60966,\"start\":60956},{\"end\":61233,\"start\":61175},{\"end\":63105,\"start\":63092},{\"end\":64469,\"start\":64456}]"}}}, "year": 2023, "month": 12, "day": 17}