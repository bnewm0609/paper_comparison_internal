{"id": 3972365, "updated": "2023-10-01 05:34:46.56", "metadata": {"title": "A Dual Approach to Scalable Verification of Deep Networks", "authors": "[{\"first\":\"Krishnamurthy\",\"last\":\"Dvijotham\",\"middle\":[]},{\"first\":\"Robert\",\"last\":\"Stanforth\",\"middle\":[]},{\"first\":\"Sven\",\"last\":\"Gowal\",\"middle\":[]},{\"first\":\"Timothy\",\"last\":\"Mann\",\"middle\":[]},{\"first\":\"Pushmeet\",\"last\":\"Kohli\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2018, "month": 3, "day": 17}, "abstract": "This paper addresses the problem of formally verifying desirable properties of neural networks, i.e., obtaining provable guarantees that neural networks satisfy specifications relating their inputs and outputs (robustness to bounded norm adversarial perturbations, for example). Most previous work on this topic was limited in its applicability by the size of the network, network architecture and the complexity of properties to be verified. In contrast, our framework applies to a general class of activation functions and specifications on neural network inputs and outputs. We formulate verification as an optimization problem (seeking to find the largest violation of the specification) and solve a Lagrangian relaxation of the optimization problem to obtain an upper bound on the worst case violation of the specification being verified. Our approach is anytime i.e. it can be stopped at any time and a valid bound on the maximum violation can be obtained. We develop specialized verification algorithms with provable tightness guarantees under special assumptions and demonstrate the practical significance of our general verification approach on a variety of verification tasks.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1803.06567", "mag": "2963565751", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/uai/DvijothamSGMK18", "doi": null}}, "content": {"source": {"pdf_hash": "81214c9a2ce505a4860c9359f47776408f4b090b", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1803.06567v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "7b1689494bf346a68e5159290beb29b866175efb", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/81214c9a2ce505a4860c9359f47776408f4b090b.txt", "contents": "\nA Dual Approach to Scalable Verification of Deep Networks\n\n\nKrishnamurthy ( Dj \nN1C 4AGLondonUK\n\n) Dvijotham \nN1C 4AGLondonUK\n\nRobert Stanforth \nN1C 4AGLondonUK\n\nSven Gowal \nN1C 4AGLondonUK\n\nTimothy Mann \nN1C 4AGLondonUK\n\nPushmeet Kohli \nN1C 4AGLondonUK\n\nA Dual Approach to Scalable Verification of Deep Networks\n\nThis paper addresses the problem of formally verifying desirable properties of neural networks, i.e., obtaining provable guarantees that neural networks satisfy specifications relating their inputs and outputs (robustness to bounded norm adversarial perturbations, for example). Most previous work on this topic was limited in its applicability by the size of the network, network architecture and the complexity of properties to be verified. In contrast, our framework applies to a general class of activation functions and specifications on neural network inputs and outputs. We formulate verification as an optimization problem (seeking to find the largest violation of the specification) and solve a Lagrangian relaxation of the optimization problem to obtain an upper bound on the worst case violation of the specification being verified. Our approach is anytime i.e. it can be stopped at any time and a valid bound on the maximum violation can be obtained. We develop specialized verification algorithms with provable tightness guarantees under special assumptions and demonstrate the practical significance of our general verification approach on a variety of verification tasks.\n\nINTRODUCTION\n\nNeural networks and deep learning have revolutionized machine learning achieving state of the art performance on a wide range of complex prediction tasks [Krizhevsky et al., 2012. However, in recent years, researchers have observed that even state of the art networks can be easily fooled into changing their * dvij@cs.washington.edu predictions by making small but carefully chosen modifications to the input data (known as adversarial perturbations) [Szegedy et al., 2013, Kurakin et al., 2016, Carlini and Wagner, 2017a, Goodfellow et al., 2014, Carlini and Wagner, 2017b. While modifications to neural network training algorithms have been proposed to mitigate this phenomenonMadry et al. [2018], a comprehensive solution that is fully robust to adversarial attacks remains elusive [Carlini andWagner, 2017b, Uesato et al., 2018].\n\nNeural networks are typically tested using the standard machine learning paradigm: If the performance (accuracy) of the network is sufficiently high on a holdout (test) set that the network did not have access to while training, the network is deemed acceptable. This is justified by statistical arguments based on an i.i.d. assumption on the data generating mechanism, that is each input output pair is generated independently from the same (unknown) data distribution. However, this evaluation protocol is not sufficient in domains with critical safety constraints [Marston and Baca, 2015]. In these cases, we may require a stronger test: for example, we may require that the network is robust against adversarial perturbations within certain bounds.\n\nAdversarial evaluation. In the context of adversarial examples, a natural idea is to test neural networks by checking if it is possible to generate an adversarial attack to change the label predicted by the neural network [Kurakin et al., 2016] and train them to be robust to these examples Madry et al. [2018]. Generating adversarial examples is a challenging computational task itself, and the attack generated by a specific attack algorithm may be far from optimal. This may lead one to falsely conclude that a given model is robust to attacks even though a stronger adversary may have broken the robustness. Recent work [Athalye et al., 2018, Uesato et al., 2018 has shown that evaluating models against weak adversaries can lead to incorrect conclusions regarding the robustness of the model. Thus, there is a need to go beyond evaluation us-ing specific adversarial attacks and find approaches that provide provable guarantees against attacks by any adversary.\n\nTowards verifiable models. Verification of neural networks has seen significant research interest in recent years. In the formal verification community, Satisfiability Modulo Theory (SMT) solvers have been adapted for verification of neural networks [Ehlers, 2017, Huang et al., 2017, Katz et al., 2017. While SMT solvers have been successfully applied to several domains, applying them to large neural networks remains a challenge due to the scale of the resulting SMT problem instances. Furthermore, these approaches have been largely limited to networks with piecewise linear activation functions since most SMT solvers are unable to deal efficiently with nonlinear arithmetic. More recently, researchers have proposed a set of approaches that make use of branch and bound algorithms either directly or via mixed-integer programming solvers [Bunel et al., 2017, Cheng et al., 2017, Tjeng and Tedrake, 2017. While these approaches achieve strong results on smaller networks, scaling them to large networks remains an open challenge. These approaches also rely heavily on the piecewise linear structure of networks where the only nonlinearities are maxpooling and ReLUs.\n\nTowards scalable verification of general models. In this paper, we develop a novel approach to neural network verification based on optimization and duality. The approach consists of formulating the verification problem as an optimization problem that tries to find the largest violation of the property being verified. If the largest violation is smaller than zero, we can conclude that the property being verified is true. By using ideas from duality in optimization, we can obtain bounds on the optimal value of this problem in a computationally tractable manner. Note that this approach is sound but incomplete, in that there may be cases where the property of interest is true, but the bound computed by our algorithm is not tight enough to prove the property. This strategy has been used in prior work as well [Kolter andWong, 2018, Raghunathan et al., 2018]. However, our results improve upon prior work in the following ways:\n\n1. Our verification approach applies to arbitrary feedforward neural networks with any architecture and any activation function and our framework recovers previous results [Ehlers, 2017] when applied to the special case of piecewise linear activation functions.\n\n2. We can handle verification of systems with discrete inputs and combinatorial constraints on the input space, including cardinality constraints.\n\n3. The computation involved only requires solving an unconstrained convex optimization problem (of size linear in the number of neurons in the network), which can be done using a subgradient method efficiently. Further, our approach is anytime, in the sense that the computation can be stopped at any time and a valid bound on the verification objective can be obtained.\n\n4. For the special case of single hidden layer networks, we develop specialized verification algorithms with provable tightness guarantees.\n\n5. We attain state of the art verified bounds on adversarial error rates on image classifiers trained on MNIST and CIFAR-10 under adversarial perturbations in the infinity norm.\n\n\nRelated Work\n\nCertifiable training and verification of neural networks A separate but related thread of work is on certifiable training, ie, training neural networks so that they are guaranteed to satisfy a desired property (for example, robustness to adversarial examples within a certain radius) [Kolter andWong, 2018, Raghunathan et al., 2018]. These approaches use ideas from convex optimization and duality to construct bounds on an optimization formulation of verification. However, these approaches are limited to either a class of activation functions (piecewise linear models) or architectures (single hidden layer, as in Raghunathan et al. [2018]). Further, in Kolter and Wong [2018], the dual problem starts with a constrained convex formulation but is then converted into an unconstrained but nonconvex optimization problem to allow for easy optimization via a backprop-style algorithm. In contrast, our formulation allows for an unconstrained dual convex optimization problem so that for any choice of dual variables, we obtain a valid bound on the adversarial objective and this dual problem can be solved efficiently using subgradient methods.\n\nWe also note that the ultimate goals of [Kolter andWong, 2018, Raghunathan et al., 2018] are different from our paper: they modify the training procedure of the neural network so that the network is trained to be easily verifiable. In contrast, our work focuses on extending verification algorithms to apply to a broader class of architectures, activation functions and -in this sense, we view our work as complementary to [Kolter andWong, 2018, Raghunathan et al., 2018]. In fact, since the objective of our dual optimization is differentiable with respect to the network weights, we can extend our approach to training verifiable networks easily by simultaneously optimizing the network weights and dual variables to minimize the dual objective. We leave the study of such an extension for future work.\n\nTheoretical analysis of robustness Another related line of work has to do with theoretical analysis of adversarial examples. It has been shown that feedforward ReLU networks cannot learn to distinguish between points on two concentric spheres without necessarily being vulnerable to adversarial examples within a small radius [Gilmer et al., 2018]. Under a different set of assumptions, the existence of adversarial examples with high probability is also established in Fawzi et al. [2018]. In , the authors study robustness of nearest neighbor classifiers to adversarial examples. As opposed to these theoretical analyses, our approach searches computationally for proofs of existence or non-existence of adversarial examples. The approach does not say anything a-priori about the existence of adversarial examples, but can be used to investigate their existence for a given network and compare strategies to guard against adversarial attacks.\n\n\nVERIFICATION AS OPTIMIZATION\n\n\nNOTATION\n\nOur techniques apply to general feedforward architectures and recurrent networks, but we focus on layered architectures for the development in this paper. The input layer is numbered 0, the hidden layers are numbered 1, . . . , L \u2212 1 and the output layer is numbered L. The size of layer l is denoted n l\n\nWe denote by x in the input to the neural network, by z l the pre-activations of neurons at layer l before application of the activation function and by x l the vector of neural activations after application of the activation function (to z l\u22121 ). For convenience, we define x 0 = x in . We use x l (x in ), z l (x in ) to denote the activations at the l-th layer as a function of the input x in . Upper and lower bounds on the pre/post activations are denoted by x l , x l , z l , z l respectively. The activation function at layer l is denote h l and is assumed to be applied component-wise, ie,\n[h l (z l )] k = h l k (z l k )\nNote that max-pooling is an exception to this rule -we discuss how max-pooling is handled separately in the Appendix section 6.2.1. The weights of the network at layer l are denoted W l and the bias is denoted b l , z l = W l x l + b l .\n\n\nVERIFICATION PROBLEM\n\nAs mentioned earlier, verification refers to the process of checking that the output of the neural network sat-isfies a certain desirable property for all choices of the input within a certain set. Formally, this can be stated as follows:\n\u2200x in \u2208 S in (x nom ) x L (x in ) \u2208 S out (1)\nwhere x in denotes the input to the network, x nom denotes a nominal input, S in (x nom ) defines the constrained subset of inputs induced by the nominal input, and S out denotes the constraints on the output that we would like to verify are true for all inputs in S in (x nom ). In the case of adversarial perturbations in image classification, x nom would refer to the nominal (unperturbed image), S in (x nom ) would refer to all the images that can be obtained by adding bounded perturbations to x nom , and x in would refer to a perturbed image.\n\nIn this paper, we will assume that: S out is always a described by a finite set of linear constraints on the values of final layer ie.\nS out = \u2229 m i=1 {x L : c i T x L + d i \u2264 0}, and S in (x nom ) is any bounded set such that any linear optimization problem of the form max x in \u2208Sin(x nom ) c T x\ncan be solved efficiently. This includes convex sets and also sets describing combinatorial structures like spanning trees, cuts in a graph and cardinality constraints.\n\n\nSee the following examples for a concrete illustration of the formulation of the problem:\n\nRobustness to targeted adversarial attacks. Consider an adversarial attack that seeks to perturb an input x nom to an input x in subject to a constraint on the perturbation x in \u2212 x nom \u2264 to change the label from the true label i to a target label j. We can map this to (1) as follows:\nS in (x nom ) = {x in : x in \u2212 x nom \u2264 },(2a)S out = {z : c T z \u2264 0} (2b)\nwhere c is a vector with c j = 1, c i = \u22121 and all other components 0. Thus, S out denotes the set of outputs for which the true label i has a higher logit value than the target label j (implying that the targeted adversarial attack did not succeed).\n\nMonotonic predictors. Consider a network with a single real valued output and we are interested in ensuring that the output is monotonically increasing wrt each dimension of the input x in . We can state this as a verifica-tion problem:\nS in (x nom ) = {x in : x in \u2265 x nom } (3a) S out = {x L : x L (x nom ) \u2212 x L \u2264 0} (3b)\nThus, S out denotes the set of outputs which are large than the network output at x nom . If this is true for each value of x nom , then the network is monotone.\n\nCardinality constraints. In several cases, it makes sense to constrain a perturbation not just in norm but also in terms of the number of dimensions of the input that can be perturbed. We can state this as:\nS in (x nom ) = {x in : x in \u2212 x nom 0 \u2264 k, x in \u2212 x nom \u221e \u2264 } (4a) S out = {z : c T z \u2264 0} (4b)\nwhere x 0 denotes the number of non-zero entries in x. Thus, S out denotes the set of outputs which are larger than the network output at x nom . If this is true for each value of x nom , then the network is monotone.\n\n\nOPTIMIZATION PROBLEM FOR VERIFICATION\n\nOnce we have a verification problem formulated in the form (1), we can easily turn the verification procedure into an optimization problem. This is similar to the optimization based search for adversarial examples [Szegedy et al., 2013] when the property being verified is adversarial robustness. For brevity, we only consider the case where S out is defined by a single linear constraint c T z + d \u2264 0. If there are multiple constraints, each one can be verified separately.\nmax z 0 ,...,z L\u22121 x 0 ,...,x L c T x L + d (5a) s.t x l+1 = h l z l , l = 0, 1, . . . , L \u2212 1 (5b) z l = W l x l + b l , l = 0, 1, . . . , L \u2212 1 (5c) x 0 = x in , x in \u2208 S in (x nom )(5d)\nIf the optimal value of this problem is smaller than 0 (for each c, d in the set of linear constraints defining S out ), we have verified the property (1). This is a nonconvex optimization problem and finding the global optimum in general is NP-hard (see Appendix section 6.4.1 for a proof). However, if we can compute upper bounds on the value of the optimization problem and the upper bound is smaller than 0, we have successfully verified the property. In the following section, we describe our main approach for computing bounds on the optimal value of (5).\n\n\nBOUNDING THE VALUE OF THE OPTIMIZATION PROBLEM\n\nWe assume that bounds on the activations z l , x l , l = 0, . . . , L\u22121 are available. Section 6.1 discusses details of how such bounds may be obtained given the constraints on the input layer S in (x nom ). We can bound the optimal value of (5) using a Lagrangian relaxation of the constraints:\nmax z 0 ,...,z L\u22121 x 0 ,x 1 ,...,x L\u22121 c T h L\u22121 z L\u22121 + d + L\u22121 l=0 \u00b5 l T z l \u2212 W l x l \u2212 b l + L\u22122 l=0 \u03bb l T x l+1 \u2212 h l z l (6a) s.t. z l \u2264 z l \u2264 z l , l = 0, 1, . . . , L \u2212 1 (6b) x l \u2264 x l \u2264 x l , l = 0, 1, . . . , L \u2212 1 (6c) x 0 \u2208 S in (x nom )(6d)\nNote that any feasible solution for the original problem (5) is feasible for the above problem, and for any such solution, the terms involving \u03bb, \u00b5 become 0 (since the terms multiplying \u03bb, \u00b5 are 0 for every feasible solution). Thus, for any choice of \u03bb, \u00b5, the above optimization problem provides a valid upper bound on the optimal value of (5) (this property is known as weak duality [Vandenberghe and Boyd, 2004]).\n\nWe now look at solving the above optimization problem.\n\nSince the objective and constraints are separable in the layers, the variables in each layer can be optimized independently. For l = 1, . . . , L \u2212 1, we have\nf l \u03bb l\u22121 , \u00b5 l = max x l \u2208[x l ,x l ] \u03bb l\u22121 \u2212 W l T \u00b5 l T x l \u2212 b l T \u00b5 l\nwhich can be solved trivially by setting each component of x l to its upper or lower bound depending on whether the corresponding entry in \u03bb l\u22121 \u2212 W l T \u00b5 l is non-negative. Thus, Similarly, collecting the terms involving z l , we have, for\nf l \u03bb l\u22121 , \u00b5 l = \u03bb l\u22121 \u2212 W l T \u00b5 l + T x l + \u03bb l\u22121 \u2212 W l T \u00b5 l \u2212 T x l \u2212 b l T \u00b5 l where [x] + = max(x, 0), [x] \u2212 = min(x,l = 0, . . . , L \u2212 1 f l (\u03bb l , \u00b5 l ) = max \u00b5 l k z l k \u2212 \u03bb l k h l k z l k\nThis is a one-dimensional optimization problem and can be solved easily-for common activation functions (ReLU, tanh, sigmoid, maxpool), it can be solved analytically, as discussed in appendix section 6.2. Finally, we need to solve\nf 0 (\u00b5 0 ) = max x 0 \u2208Sin(x nom ) \u2212 W 0 T \u00b5 0 T x 0 \u2212 b 0 T \u00b5 0\nwhich can also be solved easily given the assumption on S in . We work out some concrete cases in 6.3.\n\nOnce these problems are solved, we can construct the dual optimization problem:\nmin \u03bb,\u00b5 n L\u22121 k=0f L\u22121,k \u2212c k , \u00b5 l k + L\u22122 l=0 n l k=0f l,k \u03bb l k , \u00b5 l k + L\u22121 l=1 f l (\u03bb l\u22121 , \u00b5 l ) + f 0 \u00b5 0 + d(7)\nThis seeks to choose the values of \u03bb, \u00b5 so as to minimize the upper bound on the verification objective, thereby obtaining the tightest bound on the verification objective.\n\nThis optimization can be solved using a subgradient method on \u03bb, \u00b5.\n\nTheorem 1. For any values of \u03bb, \u00b5, the objective of (7) is an upper bound on the optimal value of (5). Hence, the optimal value of (7) is also an upper bound. Further, (7) is a convex optimization problem in (\u03bb, \u00b5).\n\nProof. The upper bound property follows from weak duality [Vandenberghe and Boyd, 2004]. The fact that (7) is a convex optimization problem can be seen as each term f l ,f l,k is expressed as a maximum overa set of linear functions of \u03bb, \u00b5 [Vandenberghe and Boyd, 2004].\n\nTheorem 2. If each h is a ReLU function, then (7) is equivalent to the dual of the LP described in Ehlers [2017].\n\nProof. See section 6.4.\n\nThe LP formulation from Ehlers [2017] is also used in Kolter and Wong [2018]. The dual of the LP is derived in Kolter and Wong [2018] -however this dual is different from (7) and ends up with a constrained optimization formulation for the dual (the details of this can be found in appendix section 6.4.2). To allow for an unconstrained formulation, this dual LP is transformed to a backpropagation-like computation. While this allows for folding the verification into training, it also introduces nonconvexity in the verification optimization -our formulation of the dual differs from Kolter and Wong [2018] in that we directly solve an unconstrained dual formulation, allowing us to circumvent the need to solve a nonconvex optimization for verification.\n\n\nTOWARDS THEORETICAL GUARANTEES FOR VERIFICATION\n\nThe bounds computed by solving (7) could be loose in general, since (5) is an NP-hard optimization problem (section 6.4.1). SMT solvers and MIP solvers are guaranteed to find the exact optimum for piecewise linear neural networks, however, they may take exponential time to do so. Thus, an open question remains: Are there cases where it is possible to perform exact verification efficiently? If not, can we approximate the verification objective to within a certain factor (known a-priori)? We develop results answering these questions in the following sections.\n\nPrior work: For any linear classifier, the scores of each label are a linear function of the inputs w T i x + b i . Thus, the difference between the predictions of two classes j (target class for an adversary) and class i (true label) is (w i \u2212 w j ) T x. Maximizing this subject to x \u2212 x 0 2 \u2264 can be solved analytically to obtain the value (w i \u2212 w j ) T x 0 + w i \u2212 w j 2 . This observation formed the basis for algorithms in [Raghunathan et al., 2018] and [Hein and Andriushchenko, 2017]. However, once we move to nonlinear classifiers, the situation is not so simple and computing the worst case adversarial example, even in the 2-norm case, becomes a challenging task. In [Hein and Andriushchenko, 2017], the special case of kernel methods and single hidden layer classifiers are considered, but the approaches developed are only upper bounds on the verification objective (just like those computed by our dual relaxation approach). Similarly, in Raghunathan et al. [2018], a semidefinite programming approach is developed to compute bounds on the verification objective for the special case of adversarial perturbations on the infinity norm. However, none of these approaches come with a-priori guarantees on the quality of the bound, that is, before actually running the verification algorithm, one cannot predict how tight the bound on the verification objective would be. In this section, we develop novel theoretical results that quantify when the verification problem (5) can be solved either exactly or with a-priori approximation guarantees. Our results require strong assumptions and do not immediately apply to most practical situations. However, we believe that they shed some understanding on the conditions under which exact verification can be performed tractably and lead to specialized verification algorithms that merit further study.\n\nWe assume the following for all results in this section: 1) We study networks with a single hidden layer, i.e. L = 2, with activation function h 0 = h and a linear mapping from the penultimate to the output layer\nx 2 = h 1 z 1 = z 1 = W 1 x 1 + b 1 .\n2) The network has a differentiable activation function h with Lipschitz-continuous derivatives denoted h (tanh, sigmoid, ELU, polynomials satisfy this requirement).\n\n3) S in (x nom ) = {x in : x in \u2212 x nom 2 \u2264 }. Since the output layer is a linear function of the penultimate layer x 1 , we have\nc T x 2 = W 1 T c T x 1 + c T b 1 = W 1 T c T h 0 z 0 + c T b 1\nFor brevity, we simply denote W 1 T c as c, drop the constant term c T b 1 and let W = W 0 , b = b 0 , z nom = W x nom + b and W i denote the i-th row of W . Then, (5) reduces to:\nmax x in : x in \u2212x nom 2 \u2264 i c i h i W i x in + b i(8)\nTheorem 3. Suppose that h has a Lipschitz continuous first derivative:\nh i (t) \u2212 h i (t) \u2264 \u03b3 i |t \u2212t| Let \u03bd = diag (c) W T h (z nom ) 2 L = \u03c3 max diag (c) W T \u03c3 max (diag (\u03b3) W )\nThen \u2200 \u2208 (0, \u03bd 2L ), the iteration:\nx k+1 \u2190 x nom + W T diag (c) h (W x k + b) W T diag (c) h (W x k + b) 2\nstarting at x 0 = x nom converges to the global optimum\n\nx of (8) at the rate x k \u2212 x \u2264 L \u03bd\u2212 L k Proof. Section 6.4\n\nThus, when is small enough, a simple algorithm exists to find the global optimum of the verification objective. However, even when is larger, one can obtain a good approximation of the verification objective. In order to do this, consider the following quadratic approxiimation of the objective from (8):\nmax i c i (h i (z nom i ) + h i (z nom i ) (W i z)) + i c i 2 h i (z nom i ) (W i z) 2 (9a) s.t. z 2 \u2264(9b)\nThis optimization problem corresponds to a trust region problem that can be solved to global optimality using semidefinite programming [Yakubovic, 1971]:\nmax z,Z i c i (h i (z nom i ) + h i (z nom i ) (W i z)) + i c i 2 h i (z nom i ) tr W T i W i Z (10a) s.t. tr (Z) \u2264 , 1 z T z Z 0 (10b)\nwhere X 0 denotes that X is constrained to be a positive semidefinite matrix. While this can be solved using general semidefinite programming solvers, several special purpose algorithms exist for this trust region problem that can exploit its particular structure for efficient solution, [Hazan and Koren, 2016] Theorem 4. Suppose that h is thrice-differentiable with a globally bounded third derivative. Let\n\u03b6 i = W i 2 , \u03b7 i = sup t |h i (t)|, \u03ba = 1 6 i \u03b7 i c i \u03b6 3 i\nFor each > 0, the difference between the optimal values of (10), (8) is at most \u03ba 3 .\n\nProof. See Section 6.4\n\n\nEXPERIMENTS\n\nIn this section, we present numerical studies validation our approach on three sets of verification tasks: Image classification on MNIST and CIFAR: We use our approach to obtain guaranteed lower bounds on the accuracy of image classifers trained on MNIST and CIFAR-10 under adversarial attack with varying sizes of the perturbation radius. We compare the bounds obtained by our method with prior work (in cases where prior work is applicable) and also with the best attacks found by various approaches.\n\nClassifier stability on GitHub data: We train networks on sequences of commits on GitHub over a collection of 10K repositories -the prediction task consists of predicting whether a given repository will reach more than 40 commits within 250 days given data observed until a certain day. Input features consist a value between 0 and 1 indicating the number of days left until the 250th day, as well as another value indicating the progress of commits towards the total of 40. As the features evolve, the prediction of the classifier changes (for example, predictions should become more accurate as we move closer to the 250th day). In this situation, it is desirable that the classifier provides consistent predictions and that the number of times its prediction switches is as small as possible. It is also desirable that this switching frequency cannot be easily be changed by perturbing input features. We use our verification approach combined with dynamic programming to compute a bound on the maximum number of switches in the classifier prediction over time.\n\nDigit sum task: We consider a more complex verification task here: Given a pair of MNIST digits, the goal is to bound how much the sum of predictions of a classifier can differ from the true sum of those digits under adversarial perturbation subject to a total budget on the perturbation across the two digits.\n\n\nIMAGE CLASSIFICATION: MNIST AND CIFAR\n\nWe study adversarial attacks subject to an l \u221e bound on the input perturbation. An adversarial example (AE) is a pertubation of an input of the neural network such that the output of the neural network differs from the correct label for that input. An AE is said to be within radius if the \u221e norm of the difference between the AE and the original input is smaller than . We are interested in the adversarial error rate, that is,\n\n\n# Test examples that have an AE within radius Size of test set\n\nComputing this quantity precisely requires solving the NP-hard problem (5) for each test example, but we can obtain upper bounds on it using our (and other) verification methods and lower bounds using a fixed attack algorithm (in this paper we use a bound constrained LBFGS algorithm similar to [Carlini and Wagner, 2017b]). Since theorem 2 shows that for the special case of piecewise linear neural networks, our approach reduces to the basic LP relaxation from Ehlers [2017] (which also is the basis for the algorithms in Bunel et al. [2017] and Kolter and Wong [2018]), we focus on networks with smooth nonlinearities like tanh and sigmoid. We compare our approach with The SDP formulation from Raghunathan et al. [2018] (note that this approach only works for sin-gle hidden layer networks, so we just show it as producing vacuous bounds for other networks).\n\nEach approach gets a budget of 300 s per verifiation problem (choice of test example and target label). Since the SDP solver from [Raghunathan et al., 2018] only needs to be run once per label pair (and not per test example), its running time is amortized appropriately.\n\nResults on smooth activation functions: Figures 1a,1b show that our approach is able to compute nearly tight bounds (bounds that match the upper bound) for small perturbation radii (up to 2 pixel units) and our bounds significantly outperform those from the SDP approach [Raghunathan et al., 2018] ( which is only able to compute nontrivial bounds for the smallest model with 20 hidden units).\n\nResults on models trained adversarially: We use the adversarial training approach of [Madry et al., 2018] and train models on MNIST and CIFAR that are robust to perturbations from the LBFGS-style attack on the training set. We then apply our verification algorithm to these robust models and obtain bounds on the adversarial error rate on the test set. These models are all multilayer models, so the SDP approach from [Raghunathan et al., 2018] does not apply and we do not plot it here. We simply plot the attack versus the bound from our approach.\n\nThe results for MNIST are plotted in figure 2b and for CIFAR in figure 2a. On networks trained using a different procedure, the approaches from Raghunathan et al. [2018] and Kolter and Wong [2018] are able to achieve stronger results for larger values of (they work with = .1 in real units, which corresponds to = 26 in pixel units we use here). However, we note that our verification procedure is agnostic to the training procedure, and can be used to obtain fairly tight bounds for any network and any training procedure. In comparison, the results in Kolter and Wong [2018] and Raghunathan et al. [2018] rely on the training procedure optimizing the verification bound. Since we do not rely on a particular adversarial training procedure, we were also able to obtain the first non-trivial verification bounds on CIFAR-10 (to the best of our knowledge) shown in figure 2a. While the model quality is rather poor, the results indicate that our approach could scale to more complicated models.\n\n\nGITHUB CLASSIFIER STABILITY\n\nWe allow the adversary to modify input features by up to 3% (at each timestep) and our goal is to bound the maximum number of prediction switches induced by each attack over time. We can model this within our verification framework as follows: Given a sequence of input features, we compute the maximum number of switches  [Raghunathan et al., 2018]. Each color represents a different network. The dashed lines at the bottom are lower bounds on the error rate computed using the best attack found using the LBFGS algorithm.\n\nachievable by first computing the target classes that are reachable through an adversarial attack at each timestep (using (7)), and then running a dynamic program to compute the choices of target classes over time (from within the reachable target classes) to maximize the number of switches over time. Figure 3a shows how initially predictions are easily attackable (as little information is available to make predictions), and also shows how the gap between our approach and the best attack found using the LBFGS algorithm evolves over time.\n\n\nCOMPLEX VERIFICATION TASK: DIGIT SUM\n\nIn order to test our approach on a more complex specification, we study the following task: Given a pair of MNIST digits, we ask the question: Can an attacker perturb each image, subject to a constraint on the total perturbation across both digits, such that the sum of the digits predicted by the classifier differs from the true sum of those digits by as large an amount as possible? Answering this question requires solving the following optimization problem:\nmax x in a ,x in b a , b | argmax x L x in a + argmax x L x in b \u2212 s| s.t. x in a \u2212 x nom a \u2264 a , x in b \u2212 x nom b \u2264 b a + b \u2264\nwhere s is the true sum of the two digits. Thus, the adversary has to decide on both the perturbation to each digit, as well as the size of the perturbation. We can encode this within our framework (we skip the details here). The upper bound on the maximum error in the predicted sum from the verification and the lower bound on the maximum error computed from an attack for this problem (on an adversarially trained two hidden layer sigmoid network) is plotted in figure 3b. The results show that even on this rather complex verification task, our approach is able to compute tight bounds.\n\n\nCONCLUSIONS\n\nWe have presented a novel framework for verification of neural networks. Our approach extends the applicability of verification algorithms to arbitrary feedforward networks with any architecture and activation function and to more general classes of input constraints than those considered previously (like cardinality constraints). The verification procedure is both efficient (given that it solves an unconstrained convex optimization problem) and practically scalable (given its anytime nature only required gradient like steps). We proved the first known (to the best of our knowledge) theorems showing that under special assumptions, nonlinear neural networks can be verified tractably. Numerical experiments demonstrate the practical performance of our approach on several classes of verification tasks.\n\n(a) Verification of robust CIFAR-10 model as a function of perturbation radius .\n\n(b) Verification of robust models as a function of perturbation radius . \n\n\nAPPENDIX\n\n\nBOUND TIGHTENING\n\nThe quality of the bound in theorem 1 depends crucially on having bounds on all the intermediate pre and post activations z l , x l . In this section, we describe how these bounds may be derived. One simple way to compute bounds on neural activations is to use interval arithmetic given bounds on the input x 0 \u2264 x \u2264 x 0 . Bounds at each layer can then be computed recursively for l = 0, . . . , L \u2212 1 as follows:\nz l = W l + x l + W l \u2212 x l + b l (11a) z l = W l + x l + W l \u2212 z l + b l (11b) x l+1 = h l z l (11c) x l+1 = h l z l (11d)\nHowever, these bounds could be quite loose and could be improved by solving the optimization problem\nmax z 0 ,...,z L\u22121 x 1 ,...,x L\u22121 x l k (12a) s.t (5b), (5c), (5d)(12b)\nWe can relax this problem using dual relaxation approach from the previous section and the optimal value of the relaxation would provide a new (possibly tighter) upper bound on x l k than x l k . Further, since our relaxation approach is anytime (ie for any choice of dual variables we obtain a valid bound), we can stop the computation at any time and use the resulting bounds. This is a significant advantage compared to previous approaches used in [Bunel et al., 2017]. Similarly, one can obtain tighter upper and lower bounds on x l for each value of l, k. Given these bounds, one can infer tighter bounds on z l using (11).\n\nPlugging these tightened bounds back into (6) and rerunning the dual optimization, we can compute a tighter upper bound on the verification objective.\n\n\nCONJUGATES OF TRANSFER FUNCTIONS\n\nWe are interested in computing g = max y\u2208[y,y] g(y) = \u00b5y \u2212 \u03bbh (y). This is a one dimensional optimization problem and can be computed via brute-force discretization of the input domain in general. However, for most commonly used transfer functions, this can be computed analytically. We derive the analytical solution for various commonly used transfer functions: ReLUs: If h is a ReLU, g(y) is piecewise linear and specifically is linear on [y, 0] and on [0, y] (assuming that 0 \u2208 [y, y], else g(y) is simply linear and can be optimized by setting y to one of its bounds). On each linear piece, the optimum is attained at one of the endpoints of the input domain. Thus, the overall maximum can be obtained by evaluating g at y, y, 0 (if 0 \u2208 [y, y]). Thus, g = max g(y), g(y), g (0) if 0 \u2208 [y, y] max g(y), g(y)\n\notherwise .\n\nSigmoid: If h is a sigmoid, we can consider two cases: a) The optimum of g is obtained at one of its input bounds or b) The optimum of g is obtained at a point strictly inside the interval [y, y]. In case (b), we require that the derivative of g vanishes, i.e:\u00b5 \u2212 \u03bb\u03c3(y)(1 \u2212 \u03c3(y)) = 0.\n\nSince \u03c3(y) \u2208 [0, 1], this equation only has a solution if \u03bb = 0 and \u00b5 \u03bb \u2208 0, 1 4 In this case, the solutions are \u03c3(y) =\n1\u00b1 \u221a 1\u2212 4\u00b5 \u03bb 2\nSolving for y, we obtain\ny = \u03c3 \u22121 1\u00b1 \u221a 1\u2212 4\u00b5 \u03bb 2 where \u03c3 \u22121 is the logit function \u03c3 \u22121 (t) = log t 1\u2212t .\nWe only consider these solutions if they lie within the domain [y, y]. Define:\ny 1 (\u00b5, \u03bb) = max \uf8eb \uf8ed y, min \uf8eb \uf8ed y, 1 \u2212 1 \u2212 4\u00b5 \u03bb 2 \uf8f6 \uf8f8 \uf8f6 \uf8f8 y 2 (\u00b5, \u03bb) = max \uf8eb \uf8ed y, min \uf8eb \uf8ed y, 1 + 1 \u2212 4\u00b5 \u03bb 2 \uf8f6 \uf8f8 \uf8f6 \uf8f8\nThus, we obtain the following expression for g : max g y , g (y) if \u03bb = 0 or \u00b5 \u03bb \u2208 [0, 1 4 ] max g y , g (y) , g (y 1 (\u00b5, \u03bb)) , g (y 2 (\u00b5, \u03bb)) otherwise Tanh: Define y 1 (\u00b5, \u03bb) = max y, min y, arctanh 1 \u2212 \u00b5 \u03bb y 2 (\u00b5, \u03bb) = max y, min y, arctanh 1 \u2212 \u00b5 \u03bb and obtain g to be \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 max g y , g (y) if \u03bb = 0 or \u00b5 \u03bb \u2208 [0, 1] max g y , g (y) , g (y 1 (\u00b5, \u03bb)) , g (y 2 (\u00b5, \u03bb)) otherwise\n\n\nMaxPool\n\nIf h is a max-pool, we need to deal with it layer-wise and not component-wise. We have h (y) = max (y 1 , . . . , y t ) and are interested in solving for g = max y\u2208 [y,y] (\u00b5) T y \u2212 \u03bbh (y)\n\nNote here that \u03bb is a scalar while \u00b5 is a vector. This can be solved by considering the case of each component of y attaining the maximumum separately. We look at the case where y i attains the maximum below: max y\u2208[y,y],yi\u2265yj \u2200j =i (\u00b5) T y \u2212 \u03bby i\n\nFixing y i and optimizing the other coordinates, we obtain max yi\u2208[y i ,y i ] j =i,yi\u2265y j max \u00b5 j y j , \u00b5 j y j + j =i,yi\u2264y j max \u00b5 j y i , \u00b5 j y j \u2212 (\u00b5 i \u2212 \u03bb) y i This one-dimensional function can be optimized via binary search on y i . After solving for each i, taking the maximum over i gives the value g\n\n\nUpper bounds for general nonlinearities\n\nIn general, we can compute an upper bound on g even if we cannot optimize it exactly. The idea is to decouple the y from the two terms in g: \u00b5y and \u2212\u03bbh(y) and optimize each independently. However, this gives a very weak bound. This can be made much tighter by applying it separately to a decomposition of the input domain Finally we can bound max [y,y] g(y) using max y\u2208 [y,y] g(y) \u2264 max i (max(\u00b5a i , \u00b5b i ) + max (\u2212\u03bbh(a i ), \u2212\u03bbh(b i )))\n\nAs the decomposition gets finer, ie, |a i \u2212 b i | \u2192 0, we obtain an arbitrarily tight upper bound on g) this way.\n\n\nOPTIMIZING OVER THE INPUT CONSTRAINTS\n\nIn this section, we discuss solving the optimization problem defining f 0 (\u00b5 0 ) in (7) max x\u2208Sin (W T \u00b5) T x + b T \u00b5 where we dropped the superscript (0) for brevity. For commonly occuring constraint sets S in , this problem can be solved in closed form easily: Norm constraints: Consider the case S in = x \u2212x \u2264 . In this case, we by Holder's inequality, the objective is larger than or equal to b T \u00b5 \u2212 W T \u00b5 where \u00b7 is the dual norm to the norm . Further this bound can be achieved for an appropriate choice of x. Hence, the optimal value is precisely b T \u00b5 \u2212 W T \u00b5 . Combinatorial objects: Linear objectives can be optimized efficiently over several combinatorial structures. For example, if x is indexed by the edges in a graph and S in imposes constraints that x is binary valued and that the edges set to 1 should form a spanning tree of the graph, the optimal value can be computed using a maximum spanning tree approach. Cardinality constraints: x may have cardinality constrained imposed on it: x 0 \u2264 k, saying that at most k elements of x can be non-zero. If further we have bounds on x \u2208 [x, x], then the optimization problem can be solved as follows: Let v(\u00b5) = W T \u00b5 + x + W T \u00b5 \u2212 x and let [v] i denote the i-th largest component of v. Then the optimal value is k i=1 [v(\u00b5)] i + b T \u00b5.\n\n\nPROOFS OF THEORETICAL RESULTS\n\n6.4.1 NP-hardness of a verification of a single hidden layer network\n\n\n0) denote the positive and negative parts of x.\n\nFigure 1 :\n1Figures show three curves per model -Dashed line: Lower bound from LBFGS attack. Solid line: Our verified upper bound. Dash-dot line: SDP verified upper bound from\n\n\n[y, y] = \u222a i [a i , b i ]: max y\u2208[ai,bi] g(y) \u2264 max(\u00b5a i , \u00b5b i )+max (\u2212\u03bbh(a i ), \u2212\u03bbh(b i ))\n\n\nSolid lines:verified upper bounds and dashed lines: attack lower bounds. R. Ehlers. Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks. ArXiv e-prints, May 2017. A. Fawzi, H. Fawzi, and O. Fawzi. Adversarial vulnerability for any classifier. arXiv preprint arXiv:1802.08686, 2018.Shane Legg for helpful comments and feedback on this \npaper. Jonathan Uesato's help on adversarial training of \nneural networks is also gratefully acknowledged. \n\nReferences \n\nA. Athalye, N. Carlini, and D. Wagner. Obfuscated gra-\ndients give a false sense of security: Circumventing \ndefenses to adversarial examples. In International \nConference on Machine Learning, 2018. \n\nR. Bunel, I. Turkaslan, P. H. Torr, P. Kohli, and M. P. Ku-\nmar. Piecewise linear neural network verification: A \ncomparative study. arXiv preprint arXiv:1711.00455, \n2017. \n\nN. Carlini and D. Wagner. Adversarial examples are not \neasily detected: Bypassing ten detection methods. In \n\n(a) Maximum number of switches (over number of days eval-\nuated so far) over different days (upper bound from our verifi-\ncation approach and lower bound from the best attack found). \nResults are averaged over 100 unseen repositories. Shaded areas \nare 95% confidence intervals. \n\n(b) Maximum difference between predicted and actual sum of \ndigits vs the perturbation budget for a pair of randomly chosen \nMNIST images. \n\nProceedings of the 10th ACM Workshop on Artificial \nIntelligence and Security, pages 3-14. ACM, 2017a. \n\nN. Carlini and D. Wagner. Towards evaluating the ro-\nbustness of neural networks. In Security and Privacy \n(SP), 2017 IEEE Symposium on, pages 39-57. IEEE, \n2017b. \n\nC.-H. Cheng, G. N\u00fchrenberg, and H. Ruess. Maximum \nresilience of artificial neural networks. In Interna-\ntional Symposium on Automated Technology for Veri-\nfication and Analysis, pages 251-268. Springer, 2017. \n\n\nz l \u2208[z l ,z l ] \u00b5 l T z l \u2212 \u03bb l T h l z l where \u03bb L\u22121 = \u2212c.Since h l is a component-wise nonlinearity, each dimension of z l can be optimized independently. For the k-th dimension, we obtai\u00f1f l,k \u03bb l k , \u00b5 l k = max z l k \u2208[z l k ,z l k ]\nACKNOWLEDGEMENTSThe authors would like to thank Brendan O'Donoghue, Csaba Szepesvari, Rudy Bunel, Jonathan Uesato andConsider the case of sigmoid transfer function with an \u221e norm perturbation. Then, the verification problem reduces to :This is an instance of a sigmoidal programming problem, which is proved to be NP-hard inUdell and Boyd [2013]6.4.2 Proof of theorem 2Proof. In this case, since h is a relu,f can be written as (from section 6.2) asNow, the LP relaxation from[Ehlers, 2017]can be written asWe can rewrite this optimization problem aswhich is still a convex optimization problem, since all the constraints are either linear of the form max(0, z) \u2264 x which is a convex constraint since the LHS is a convex function and the RHS is linear.Taking the dual of this optimization problem, we obtainFurther let I l,k = [z l k , z l k ] and let I a denote the set of l, k such that z l k \u2265 0, I b the set of l, k such that z l k \u2264 0 and I c the set of l, k such that 0 \u2208 I l,k .We can then rewrite the dual asWe now solve for the maximum over z l k considering three cases: (a) l, k \u2208 I a : The maximization is over a linear function and the maximum is attained at one of the bounds, hence the maximum evaluates toThis evaluates tof l,k \u03bb l k , \u00b5 l k for l, k \u2208 I a . (b) l, k \u2208 I b : The maximization is over a linear function and the maximum is attained at one of the bounds, hence the maximum evaluates to max \u00b5 l k z l k , \u00b5 l k z l k This evaluates tof l,k \u03bb l k , \u00b5 l k for l, k \u2208 I b . (c) l, k \u2208 I b : The maximization is over a piecewise linear function and the maximum is attained at one of the bounds or at the breakpoint 0, hence the maximum evaluates to max 0, \u00b5 l k + \u03bb l k,b s l k z l k , \u00b5 l k + \u03bb l k,b s l k \u2212 1 \u2212 \u03bb l k z l k Adding the constant \u2212\u03bb l k,b s l k z l k we obtainMinimizing the above expression with respect to \u03bb l(since the expression is monotonically increasing in \u03bb l k;b , minimizing it subject to these constraints we just set \u03bb l k;b to the larger of its lower bounds). Now, for the second term to attain the maximum, we require that \u03bb l k \u2264 0, \u00b5 l k = s l k \u03bb l k , in which case all the last three terms attain the maximum. Thus, the maximum is equal to the max of three terms:showing that the expression evaluts tof l,k \u03bb l k , \u00b5 l k for l, k \u2208 I c .Thus, the dual objective is equal toGiven this, the rest of the dual exactly matches the calculations from section 3.3.Proof of theorem 3Proof. We leverage results from[Polyak, 2003]which argues that a smooth nonlinear function can be efficicently optimized over a \"small enough\" ball. Specifically, we use theorem 7 from[Polyak, 2003]. In order to apply the theorem, we need to bound the Lipschitz costant of the derivative of the functionWe haveHence by theorem 7 from[Polyak, 2003], the theorem follows.PROOF OF THEOREM 4Proof. We have z 2 \u2264 =\u21d2 |W i z| \u2264 W i 2 (by Cauchy-Schwartz). Thus, for eacn i, we haveThe last term can be bounded above byAdding the error terms over all terms in the objective function, we obtain the result.\nAdversarial spheres. J Gilmer, L Metz, F Faghri, S S Schoenholz, M Raghu, M Wattenberg, I Goodfellow, ArXiv e-printsJ. Gilmer, L. Metz, F. Faghri, S. S. Schoenholz, M. Raghu, M. Wattenberg, and I. Goodfellow. Ad- versarial spheres. ArXiv e-prints, Jan. 2018.\n\nDeep Learning. I Goodfellow, Y Bengio, A Courville, MIT PressI. Goodfellow, Y. Bengio, and A. Courville. Deep Learning. MIT Press, 2016. http://www. deeplearningbook.org.\n\nExplaining and harnessing adversarial examples. I J Goodfellow, J Shlens, C Szegedy, arXiv:1412.6572arXiv preprintI. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.\n\nA linear-time algorithm for trust region problems. E Hazan, T Koren, Mathematical Programming. 1581-2E. Hazan and T. Koren. A linear-time algorithm for trust region problems. Mathematical Programming, 158(1- 2):363-381, 2016.\n\nFormal guarantees on the robustness of a classifier against adversarial manipulation. M Hein, M Andriushchenko, Advances in Neural Information Processing Systems. M. Hein and M. Andriushchenko. Formal guarantees on the robustness of a classifier against adversarial ma- nipulation. In Advances in Neural Information Pro- cessing Systems, pages 2263-2273, 2017.\n\nSafety verification of deep neural networks. X Huang, M Kwiatkowska, S Wang, M Wu, International Conference on Computer Aided Verification. SpringerX. Huang, M. Kwiatkowska, S. Wang, and M. Wu. Safety verification of deep neural networks. In Inter- national Conference on Computer Aided Verification, pages 3-29. Springer, 2017.\n\nReluplex: An efficient SMT solver for verifying deep neural networks. G Katz, C Barrett, D L Dill, K Julian, M J Kochenderfer, 978-3-319-63387-9Computer Aided Verification. R. Majumdar and V. Kun\u010dakChamSpringer International PublishingG. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochenderfer. Reluplex: An efficient SMT solver for verifying deep neural networks. In R. Majum- dar and V. Kun\u010dak, editors, Computer Aided Verifi- cation, pages 97-117, Cham, 2017. Springer Interna- tional Publishing. ISBN 978-3-319-63387-9.\n\nProvable defenses against adversarial examples via the convex outer adversarial polytope. J Z Kolter, E Wong, International Conference on Machine Learning. J. Z. Kolter and E. Wong. Provable defenses against adversarial examples via the convex outer adversar- ial polytope. In International Conference on Machine Learning, 2018.\n\nImagenet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, Advances in neural information processing systems. A. Krizhevsky, I. Sutskever, and G. E. Hinton. Im- agenet classification with deep convolutional neural networks. In Advances in neural information process- ing systems, pages 1097-1105, 2012.\n\nA Kurakin, I Goodfellow, S Bengio, arXiv:1607.02533Adversarial examples in the physical world. arXiv preprintA. Kurakin, I. Goodfellow, and S. Bengio. Adversar- ial examples in the physical world. arXiv preprint arXiv:1607.02533, 2016.\n\nTowards deep learning models resistant to adversarial attacks. A Madry, A Makelov, L Schmidt, D Tsipras, A Vladu, International Conference on Learning Representations. A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant to adversarial attacks. In International Conference on Learning Representations, 2018.\n\nAcas-xu initial self-separation flight tests. M Marston, G Baca, NASA Armstrong Flight Research Center Flight Report. M. Marston and G. Baca. Acas-xu initial self-separation flight tests. NASA Armstrong Flight Research Center Flight Report, 2015.\n\nThe convexity principle and its applications. B Polyak, Bulletin of the Brazilian Mathematical Society. 341B. Polyak. The convexity principle and its applications. Bulletin of the Brazilian Mathematical Society, 34(1): 59-75, 2003.\n\nCertified defenses against adversarial examples. A Raghunathan, J Steinhardt, P Liang, International Conference on Learning Representations. A. Raghunathan, J. Steinhardt, and P. Liang. Certified defenses against adversarial examples. In Interna- tional Conference on Learning Representations, 2018. URL https://openreview.net/forum?id= Bys4ob-Rb.\n\nC Szegedy, W Zaremba, I Sutskever, J Bruna, D Erhan, I Goodfellow, R Fergus, arXiv:1312.6199Intriguing properties of neural networks. arXiv preprintC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intrigu- ing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.\n\nV Tjeng, R Tedrake, arXiv:1711.07356Verifying neural networks with mixed integer programming. arXiv preprintV. Tjeng and R. Tedrake. Verifying neural networks with mixed integer programming. arXiv preprint arXiv:1711.07356, 2017.\n\nMaximizing a sum of sigmoids. Optimization and Engineering. M Udell, S Boyd, M. Udell and S. Boyd. Maximizing a sum of sigmoids. Optimization and Engineering, 2013.\n\nAdversarial risk and the dangers of evaluating against weak attacks. J Uesato, B O&apos;donoghue, A Van Den Oord, P Kohli, International Conference on Machine Learning. J. Uesato, B. O'Donoghue, A. van den Oord, and P. Kohli. Adversarial risk and the dangers of evaluat- ing against weak attacks. In International Conference on Machine Learning, 2018.\n\nL Vandenberghe, S Boyd, Convex optimization. Cambridge University Press Cambridge1L. Vandenberghe and S. Boyd. Convex optimization, vol- ume 1. Cambridge University Press Cambridge, 2004.\n\nAnalyzing the robustness of nearest neighbors to adversarial examples. Y Wang, S Jha, K Chaudhuri, arXiv:1706.03922arXiv preprintY. Wang, S. Jha, and K. Chaudhuri. Analyzing the ro- bustness of nearest neighbors to adversarial examples. arXiv preprint arXiv:1706.03922, 2017.\n\nS-procedure in nonlinear control theory. V Yakubovic, Vestnik Leningrad Univ. 1V. Yakubovic. S-procedure in nonlinear control theory. Vestnik Leningrad Univ., 1:62-77, 1971.\n", "annotations": {"author": "[{\"end\":97,\"start\":61},{\"end\":127,\"start\":98},{\"end\":162,\"start\":128},{\"end\":191,\"start\":163},{\"end\":222,\"start\":192},{\"end\":255,\"start\":223}]", "publisher": null, "author_last_name": "[{\"end\":79,\"start\":77},{\"end\":109,\"start\":100},{\"end\":144,\"start\":135},{\"end\":173,\"start\":168},{\"end\":204,\"start\":200},{\"end\":237,\"start\":232}]", "author_first_name": "[{\"end\":74,\"start\":61},{\"end\":76,\"start\":75},{\"end\":99,\"start\":98},{\"end\":134,\"start\":128},{\"end\":167,\"start\":163},{\"end\":199,\"start\":192},{\"end\":231,\"start\":223}]", "author_affiliation": "[{\"end\":96,\"start\":81},{\"end\":126,\"start\":111},{\"end\":161,\"start\":146},{\"end\":190,\"start\":175},{\"end\":221,\"start\":206},{\"end\":254,\"start\":239}]", "title": "[{\"end\":58,\"start\":1},{\"end\":313,\"start\":256}]", "venue": null, "abstract": "[{\"end\":1501,\"start\":315}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b8\"},\"end\":1695,\"start\":1671},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":1990,\"start\":1969},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2012,\"start\":1990},{\"end\":2039,\"start\":2012},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2064,\"start\":2039},{\"end\":2091,\"start\":2064},{\"end\":2216,\"start\":2210},{\"end\":2315,\"start\":2303},{\"end\":2350,\"start\":2315},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2944,\"start\":2920},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3351,\"start\":3329},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3417,\"start\":3398},{\"end\":3752,\"start\":3731},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3773,\"start\":3752},{\"end\":4338,\"start\":4325},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4358,\"start\":4338},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4377,\"start\":4358},{\"end\":4938,\"start\":4919},{\"end\":4958,\"start\":4938},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4983,\"start\":4958},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6075,\"start\":6064},{\"end\":6112,\"start\":6075},{\"end\":6369,\"start\":6355},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7596,\"start\":7585},{\"end\":7633,\"start\":7596},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7943,\"start\":7918},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7980,\"start\":7958},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8498,\"start\":8487},{\"end\":8535,\"start\":8498},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8881,\"start\":8870},{\"end\":8918,\"start\":8881},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9600,\"start\":9579},{\"end\":9742,\"start\":9736},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":14736,\"start\":14714},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":16742,\"start\":16713},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":18623,\"start\":18594},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":18805,\"start\":18776},{\"end\":18920,\"start\":18914},{\"end\":18985,\"start\":18979},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":19024,\"start\":19002},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":19081,\"start\":19059},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":19555,\"start\":19533},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20775,\"start\":20749},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":20811,\"start\":20780},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":21029,\"start\":20998},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21298,\"start\":21273},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":23994,\"start\":23977},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":24443,\"start\":24420},{\"end\":27466,\"start\":27439},{\"end\":27620,\"start\":27614},{\"end\":27687,\"start\":27681},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27714,\"start\":27692},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":27867,\"start\":27842},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":28164,\"start\":28138},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":28577,\"start\":28551},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":28780,\"start\":28760},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":29119,\"start\":29093},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":29395,\"start\":29370},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":29422,\"start\":29400},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":29802,\"start\":29780},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":29832,\"start\":29807},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":30600,\"start\":30574},{\"end\":34736,\"start\":34716},{\"end\":37192,\"start\":37187},{\"end\":38187,\"start\":38182}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":39858,\"start\":39809},{\"attributes\":{\"id\":\"fig_1\"},\"end\":40035,\"start\":39859},{\"attributes\":{\"id\":\"fig_2\"},\"end\":40130,\"start\":40036},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":42000,\"start\":40131}]", "paragraph": "[{\"end\":2351,\"start\":1517},{\"end\":3105,\"start\":2353},{\"end\":4073,\"start\":3107},{\"end\":5246,\"start\":4075},{\"end\":6181,\"start\":5248},{\"end\":6444,\"start\":6183},{\"end\":6592,\"start\":6446},{\"end\":6964,\"start\":6594},{\"end\":7105,\"start\":6966},{\"end\":7284,\"start\":7107},{\"end\":8445,\"start\":7301},{\"end\":9251,\"start\":8447},{\"end\":10197,\"start\":9253},{\"end\":10545,\"start\":10241},{\"end\":11144,\"start\":10547},{\"end\":11414,\"start\":11177},{\"end\":11677,\"start\":11439},{\"end\":12274,\"start\":11724},{\"end\":12410,\"start\":12276},{\"end\":12743,\"start\":12575},{\"end\":13122,\"start\":12837},{\"end\":13447,\"start\":13197},{\"end\":13685,\"start\":13449},{\"end\":13935,\"start\":13774},{\"end\":14143,\"start\":13937},{\"end\":14458,\"start\":14241},{\"end\":14975,\"start\":14500},{\"end\":15726,\"start\":15165},{\"end\":16072,\"start\":15777},{\"end\":16744,\"start\":16328},{\"end\":16800,\"start\":16746},{\"end\":16960,\"start\":16802},{\"end\":17276,\"start\":17036},{\"end\":17706,\"start\":17476},{\"end\":17873,\"start\":17771},{\"end\":17954,\"start\":17875},{\"end\":18248,\"start\":18076},{\"end\":18317,\"start\":18250},{\"end\":18534,\"start\":18319},{\"end\":18806,\"start\":18536},{\"end\":18921,\"start\":18808},{\"end\":18946,\"start\":18923},{\"end\":19703,\"start\":18948},{\"end\":20318,\"start\":19755},{\"end\":22177,\"start\":20320},{\"end\":22391,\"start\":22179},{\"end\":22595,\"start\":22430},{\"end\":22726,\"start\":22597},{\"end\":22970,\"start\":22791},{\"end\":23096,\"start\":23026},{\"end\":23240,\"start\":23205},{\"end\":23368,\"start\":23313},{\"end\":23428,\"start\":23370},{\"end\":23734,\"start\":23430},{\"end\":23995,\"start\":23842},{\"end\":24540,\"start\":24132},{\"end\":24687,\"start\":24602},{\"end\":24711,\"start\":24689},{\"end\":25229,\"start\":24727},{\"end\":26295,\"start\":25231},{\"end\":26607,\"start\":26297},{\"end\":27077,\"start\":26649},{\"end\":28006,\"start\":27144},{\"end\":28278,\"start\":28008},{\"end\":28673,\"start\":28280},{\"end\":29224,\"start\":28675},{\"end\":30219,\"start\":29226},{\"end\":30774,\"start\":30251},{\"end\":31319,\"start\":30776},{\"end\":31822,\"start\":31360},{\"end\":32540,\"start\":31950},{\"end\":33365,\"start\":32556},{\"end\":33447,\"start\":33367},{\"end\":33522,\"start\":33449},{\"end\":33967,\"start\":33554},{\"end\":34192,\"start\":34092},{\"end\":34893,\"start\":34265},{\"end\":35045,\"start\":34895},{\"end\":35893,\"start\":35082},{\"end\":35906,\"start\":35895},{\"end\":36192,\"start\":35908},{\"end\":36313,\"start\":36194},{\"end\":36353,\"start\":36329},{\"end\":36512,\"start\":36434},{\"end\":37010,\"start\":36629},{\"end\":37209,\"start\":37022},{\"end\":37458,\"start\":37211},{\"end\":37767,\"start\":37460},{\"end\":38249,\"start\":37811},{\"end\":38364,\"start\":38251},{\"end\":39706,\"start\":38406},{\"end\":39808,\"start\":39740}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11176,\"start\":11145},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11723,\"start\":11678},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12574,\"start\":12411},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13168,\"start\":13123},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13196,\"start\":13168},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13773,\"start\":13686},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14240,\"start\":14144},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15164,\"start\":14976},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16327,\"start\":16073},{\"attributes\":{\"id\":\"formula_9\"},\"end\":17035,\"start\":16961},{\"attributes\":{\"id\":\"formula_10\"},\"end\":17400,\"start\":17277},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17475,\"start\":17400},{\"attributes\":{\"id\":\"formula_12\"},\"end\":17770,\"start\":17707},{\"attributes\":{\"id\":\"formula_13\"},\"end\":18075,\"start\":17955},{\"attributes\":{\"id\":\"formula_14\"},\"end\":22429,\"start\":22392},{\"attributes\":{\"id\":\"formula_15\"},\"end\":22790,\"start\":22727},{\"attributes\":{\"id\":\"formula_16\"},\"end\":23025,\"start\":22971},{\"attributes\":{\"id\":\"formula_17\"},\"end\":23204,\"start\":23097},{\"attributes\":{\"id\":\"formula_18\"},\"end\":23312,\"start\":23241},{\"attributes\":{\"id\":\"formula_19\"},\"end\":23841,\"start\":23735},{\"attributes\":{\"id\":\"formula_20\"},\"end\":24131,\"start\":23996},{\"attributes\":{\"id\":\"formula_21\"},\"end\":24601,\"start\":24541},{\"attributes\":{\"id\":\"formula_22\"},\"end\":31949,\"start\":31823},{\"attributes\":{\"id\":\"formula_23\"},\"end\":34091,\"start\":33968},{\"attributes\":{\"id\":\"formula_24\"},\"end\":34264,\"start\":34193},{\"attributes\":{\"id\":\"formula_25\"},\"end\":36328,\"start\":36314},{\"attributes\":{\"id\":\"formula_26\"},\"end\":36433,\"start\":36354},{\"attributes\":{\"id\":\"formula_27\"},\"end\":36628,\"start\":36513}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1515,\"start\":1503},{\"attributes\":{\"n\":\"2\"},\"end\":7299,\"start\":7287},{\"attributes\":{\"n\":\"3\"},\"end\":10228,\"start\":10200},{\"attributes\":{\"n\":\"3.1\"},\"end\":10239,\"start\":10231},{\"attributes\":{\"n\":\"3.2\"},\"end\":11437,\"start\":11417},{\"end\":12835,\"start\":12746},{\"attributes\":{\"n\":\"3.3\"},\"end\":14498,\"start\":14461},{\"attributes\":{\"n\":\"3.4\"},\"end\":15775,\"start\":15729},{\"attributes\":{\"n\":\"3.5\"},\"end\":19753,\"start\":19706},{\"attributes\":{\"n\":\"4\"},\"end\":24725,\"start\":24714},{\"attributes\":{\"n\":\"4.1\"},\"end\":26647,\"start\":26610},{\"end\":27142,\"start\":27080},{\"attributes\":{\"n\":\"4.2\"},\"end\":30249,\"start\":30222},{\"attributes\":{\"n\":\"4.3\"},\"end\":31358,\"start\":31322},{\"attributes\":{\"n\":\"5\"},\"end\":32554,\"start\":32543},{\"attributes\":{\"n\":\"6\"},\"end\":33533,\"start\":33525},{\"attributes\":{\"n\":\"6.1\"},\"end\":33552,\"start\":33536},{\"attributes\":{\"n\":\"6.2\"},\"end\":35080,\"start\":35048},{\"attributes\":{\"n\":\"6.2.1\"},\"end\":37020,\"start\":37013},{\"attributes\":{\"n\":\"6.2.2\"},\"end\":37809,\"start\":37770},{\"attributes\":{\"n\":\"6.3\"},\"end\":38404,\"start\":38367},{\"attributes\":{\"n\":\"6.4\"},\"end\":39738,\"start\":39709},{\"end\":39870,\"start\":39860}]", "table": "[{\"end\":42000,\"start\":40432}]", "figure_caption": "[{\"end\":39858,\"start\":39811},{\"end\":40035,\"start\":39872},{\"end\":40130,\"start\":40038},{\"end\":40432,\"start\":40133}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":28333,\"start\":28320},{\"end\":29272,\"start\":29263},{\"end\":31088,\"start\":31079},{\"end\":32424,\"start\":32415}]", "bib_author_first_name": "[{\"end\":45295,\"start\":45294},{\"end\":45305,\"start\":45304},{\"end\":45313,\"start\":45312},{\"end\":45323,\"start\":45322},{\"end\":45325,\"start\":45324},{\"end\":45339,\"start\":45338},{\"end\":45348,\"start\":45347},{\"end\":45362,\"start\":45361},{\"end\":45549,\"start\":45548},{\"end\":45563,\"start\":45562},{\"end\":45573,\"start\":45572},{\"end\":45754,\"start\":45753},{\"end\":45756,\"start\":45755},{\"end\":45770,\"start\":45769},{\"end\":45780,\"start\":45779},{\"end\":46003,\"start\":46002},{\"end\":46012,\"start\":46011},{\"end\":46265,\"start\":46264},{\"end\":46273,\"start\":46272},{\"end\":46586,\"start\":46585},{\"end\":46595,\"start\":46594},{\"end\":46610,\"start\":46609},{\"end\":46618,\"start\":46617},{\"end\":46941,\"start\":46940},{\"end\":46949,\"start\":46948},{\"end\":46960,\"start\":46959},{\"end\":46962,\"start\":46961},{\"end\":46970,\"start\":46969},{\"end\":46980,\"start\":46979},{\"end\":46982,\"start\":46981},{\"end\":47494,\"start\":47493},{\"end\":47496,\"start\":47495},{\"end\":47506,\"start\":47505},{\"end\":47799,\"start\":47798},{\"end\":47813,\"start\":47812},{\"end\":47826,\"start\":47825},{\"end\":47828,\"start\":47827},{\"end\":48083,\"start\":48082},{\"end\":48094,\"start\":48093},{\"end\":48108,\"start\":48107},{\"end\":48383,\"start\":48382},{\"end\":48392,\"start\":48391},{\"end\":48403,\"start\":48402},{\"end\":48414,\"start\":48413},{\"end\":48425,\"start\":48424},{\"end\":48721,\"start\":48720},{\"end\":48732,\"start\":48731},{\"end\":48969,\"start\":48968},{\"end\":49205,\"start\":49204},{\"end\":49220,\"start\":49219},{\"end\":49234,\"start\":49233},{\"end\":49505,\"start\":49504},{\"end\":49516,\"start\":49515},{\"end\":49527,\"start\":49526},{\"end\":49540,\"start\":49539},{\"end\":49549,\"start\":49548},{\"end\":49558,\"start\":49557},{\"end\":49572,\"start\":49571},{\"end\":49824,\"start\":49823},{\"end\":49833,\"start\":49832},{\"end\":50115,\"start\":50114},{\"end\":50124,\"start\":50123},{\"end\":50290,\"start\":50289},{\"end\":50300,\"start\":50299},{\"end\":50319,\"start\":50318},{\"end\":50335,\"start\":50334},{\"end\":50574,\"start\":50573},{\"end\":50590,\"start\":50589},{\"end\":50834,\"start\":50833},{\"end\":50842,\"start\":50841},{\"end\":50849,\"start\":50848},{\"end\":51081,\"start\":51080}]", "bib_author_last_name": "[{\"end\":45302,\"start\":45296},{\"end\":45310,\"start\":45306},{\"end\":45320,\"start\":45314},{\"end\":45336,\"start\":45326},{\"end\":45345,\"start\":45340},{\"end\":45359,\"start\":45349},{\"end\":45373,\"start\":45363},{\"end\":45560,\"start\":45550},{\"end\":45570,\"start\":45564},{\"end\":45583,\"start\":45574},{\"end\":45767,\"start\":45757},{\"end\":45777,\"start\":45771},{\"end\":45788,\"start\":45781},{\"end\":46009,\"start\":46004},{\"end\":46018,\"start\":46013},{\"end\":46270,\"start\":46266},{\"end\":46288,\"start\":46274},{\"end\":46592,\"start\":46587},{\"end\":46607,\"start\":46596},{\"end\":46615,\"start\":46611},{\"end\":46621,\"start\":46619},{\"end\":46946,\"start\":46942},{\"end\":46957,\"start\":46950},{\"end\":46967,\"start\":46963},{\"end\":46977,\"start\":46971},{\"end\":46995,\"start\":46983},{\"end\":47503,\"start\":47497},{\"end\":47511,\"start\":47507},{\"end\":47810,\"start\":47800},{\"end\":47823,\"start\":47814},{\"end\":47835,\"start\":47829},{\"end\":48091,\"start\":48084},{\"end\":48105,\"start\":48095},{\"end\":48115,\"start\":48109},{\"end\":48389,\"start\":48384},{\"end\":48400,\"start\":48393},{\"end\":48411,\"start\":48404},{\"end\":48422,\"start\":48415},{\"end\":48431,\"start\":48426},{\"end\":48729,\"start\":48722},{\"end\":48737,\"start\":48733},{\"end\":48976,\"start\":48970},{\"end\":49217,\"start\":49206},{\"end\":49231,\"start\":49221},{\"end\":49240,\"start\":49235},{\"end\":49513,\"start\":49506},{\"end\":49524,\"start\":49517},{\"end\":49537,\"start\":49528},{\"end\":49546,\"start\":49541},{\"end\":49555,\"start\":49550},{\"end\":49569,\"start\":49559},{\"end\":49579,\"start\":49573},{\"end\":49830,\"start\":49825},{\"end\":49841,\"start\":49834},{\"end\":50121,\"start\":50116},{\"end\":50129,\"start\":50125},{\"end\":50297,\"start\":50291},{\"end\":50316,\"start\":50301},{\"end\":50332,\"start\":50320},{\"end\":50341,\"start\":50336},{\"end\":50587,\"start\":50575},{\"end\":50595,\"start\":50591},{\"end\":50839,\"start\":50835},{\"end\":50846,\"start\":50843},{\"end\":50859,\"start\":50850},{\"end\":51091,\"start\":51082}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":45531,\"start\":45273},{\"attributes\":{\"id\":\"b1\"},\"end\":45703,\"start\":45533},{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b2\"},\"end\":45949,\"start\":45705},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":9079290},\"end\":46176,\"start\":45951},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":10490694},\"end\":46538,\"start\":46178},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":11626373},\"end\":46868,\"start\":46540},{\"attributes\":{\"doi\":\"978-3-319-63387-9\",\"id\":\"b6\",\"matched_paper_id\":516928},\"end\":47401,\"start\":46870},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":3659467},\"end\":47731,\"start\":47403},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":195908774},\"end\":48080,\"start\":47733},{\"attributes\":{\"doi\":\"arXiv:1607.02533\",\"id\":\"b9\"},\"end\":48317,\"start\":48082},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":3488815},\"end\":48672,\"start\":48319},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":109867755},\"end\":48920,\"start\":48674},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":119597407},\"end\":49153,\"start\":48922},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":11217889},\"end\":49502,\"start\":49155},{\"attributes\":{\"doi\":\"arXiv:1312.6199\",\"id\":\"b14\"},\"end\":49821,\"start\":49504},{\"attributes\":{\"doi\":\"arXiv:1711.07356\",\"id\":\"b15\"},\"end\":50052,\"start\":49823},{\"attributes\":{\"id\":\"b16\"},\"end\":50218,\"start\":50054},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3639844},\"end\":50571,\"start\":50220},{\"attributes\":{\"id\":\"b18\"},\"end\":50760,\"start\":50573},{\"attributes\":{\"doi\":\"arXiv:1706.03922\",\"id\":\"b19\"},\"end\":51037,\"start\":50762},{\"attributes\":{\"id\":\"b20\"},\"end\":51212,\"start\":51039}]", "bib_title": "[{\"end\":46000,\"start\":45951},{\"end\":46262,\"start\":46178},{\"end\":46583,\"start\":46540},{\"end\":46938,\"start\":46870},{\"end\":47491,\"start\":47403},{\"end\":47796,\"start\":47733},{\"end\":48380,\"start\":48319},{\"end\":48718,\"start\":48674},{\"end\":48966,\"start\":48922},{\"end\":49202,\"start\":49155},{\"end\":50287,\"start\":50220},{\"end\":51078,\"start\":51039}]", "bib_author": "[{\"end\":45304,\"start\":45294},{\"end\":45312,\"start\":45304},{\"end\":45322,\"start\":45312},{\"end\":45338,\"start\":45322},{\"end\":45347,\"start\":45338},{\"end\":45361,\"start\":45347},{\"end\":45375,\"start\":45361},{\"end\":45562,\"start\":45548},{\"end\":45572,\"start\":45562},{\"end\":45585,\"start\":45572},{\"end\":45769,\"start\":45753},{\"end\":45779,\"start\":45769},{\"end\":45790,\"start\":45779},{\"end\":46011,\"start\":46002},{\"end\":46020,\"start\":46011},{\"end\":46272,\"start\":46264},{\"end\":46290,\"start\":46272},{\"end\":46594,\"start\":46585},{\"end\":46609,\"start\":46594},{\"end\":46617,\"start\":46609},{\"end\":46623,\"start\":46617},{\"end\":46948,\"start\":46940},{\"end\":46959,\"start\":46948},{\"end\":46969,\"start\":46959},{\"end\":46979,\"start\":46969},{\"end\":46997,\"start\":46979},{\"end\":47505,\"start\":47493},{\"end\":47513,\"start\":47505},{\"end\":47812,\"start\":47798},{\"end\":47825,\"start\":47812},{\"end\":47837,\"start\":47825},{\"end\":48093,\"start\":48082},{\"end\":48107,\"start\":48093},{\"end\":48117,\"start\":48107},{\"end\":48391,\"start\":48382},{\"end\":48402,\"start\":48391},{\"end\":48413,\"start\":48402},{\"end\":48424,\"start\":48413},{\"end\":48433,\"start\":48424},{\"end\":48731,\"start\":48720},{\"end\":48739,\"start\":48731},{\"end\":48978,\"start\":48968},{\"end\":49219,\"start\":49204},{\"end\":49233,\"start\":49219},{\"end\":49242,\"start\":49233},{\"end\":49515,\"start\":49504},{\"end\":49526,\"start\":49515},{\"end\":49539,\"start\":49526},{\"end\":49548,\"start\":49539},{\"end\":49557,\"start\":49548},{\"end\":49571,\"start\":49557},{\"end\":49581,\"start\":49571},{\"end\":49832,\"start\":49823},{\"end\":49843,\"start\":49832},{\"end\":50123,\"start\":50114},{\"end\":50131,\"start\":50123},{\"end\":50299,\"start\":50289},{\"end\":50318,\"start\":50299},{\"end\":50334,\"start\":50318},{\"end\":50343,\"start\":50334},{\"end\":50589,\"start\":50573},{\"end\":50597,\"start\":50589},{\"end\":50841,\"start\":50833},{\"end\":50848,\"start\":50841},{\"end\":50861,\"start\":50848},{\"end\":51093,\"start\":51080}]", "bib_venue": "[{\"end\":47072,\"start\":47068},{\"end\":45292,\"start\":45273},{\"end\":45546,\"start\":45533},{\"end\":45751,\"start\":45705},{\"end\":46044,\"start\":46020},{\"end\":46339,\"start\":46290},{\"end\":46678,\"start\":46623},{\"end\":47041,\"start\":47014},{\"end\":47557,\"start\":47513},{\"end\":47886,\"start\":47837},{\"end\":48175,\"start\":48133},{\"end\":48485,\"start\":48433},{\"end\":48790,\"start\":48739},{\"end\":49024,\"start\":48978},{\"end\":49294,\"start\":49242},{\"end\":49636,\"start\":49596},{\"end\":49915,\"start\":49859},{\"end\":50112,\"start\":50054},{\"end\":50387,\"start\":50343},{\"end\":50616,\"start\":50597},{\"end\":50831,\"start\":50762},{\"end\":51115,\"start\":51093}]"}}}, "year": 2023, "month": 12, "day": 17}