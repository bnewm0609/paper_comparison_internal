{"id": 32370905, "updated": "2022-03-09 05:15:56.076", "metadata": {"title": "Micro Behaviors: A New Perspective in E-commerce Recommender Systems", "authors": "[{\"first\":\"Meizi\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Zhuoye\",\"last\":\"Ding\",\"middle\":[]},{\"first\":\"Jiliang\",\"last\":\"Tang\",\"middle\":[]},{\"first\":\"Dawei\",\"last\":\"Yin\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining", "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "The explosive popularity of e-commerce sites has reshaped users\u00bb shopping habits and an increasing number of users prefer to spend more time shopping online. This evolution allows e-commerce sites to observe rich data about users. The majority of traditional recommender systems have focused on the macro interactions between users and items, i.e., the purchase history of a customer. However, within each macro interaction between a user and an item, the user actually performs a sequence of micro behaviors, which indicate how the user locates the item, what activities the user conducts on the item (e.g., reading the comments, carting, and ordering) and how long the user stays with the item. Such micro behaviors offer fine-grained and deep understandings about users and provide tremendous opportunities to advance recommender systems in e-commerce. However, exploiting micro behaviors for recommendations is rather limited, which motivates us to investigate e-commerce recommendations from a micro-behavior perspective in this paper. Particularly, we uncover the effects of micro behaviors on recommendations and propose an interpretable Recommendation framework RIB, which models inherently the sequence of mIcro Behaviors and their effects. Experimental results on datasets from a real e-commence site demonstrate the effectiveness of the proposed framework and the importance of micro behaviors for recommendations.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2783118243", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/wsdm/ZhouDTY18", "doi": "10.1145/3159652.3159671"}}, "content": {"source": {"pdf_hash": "590e75fdbb7006a7918bab1dfc8d2da881aea899", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "0d0fab2e60da2921dd9cfd32c90519be598b77ac", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/590e75fdbb7006a7918bab1dfc8d2da881aea899.txt", "contents": "\nMicro Behaviors: A New Perspective in E-commerce Recommender Systems\n2018. February 5-9. 2018\n\nMeizi Zhou \nData Science Lab\nData Science Lab\nUniversity of Minnesota\nMichigan State University\n\n\nZhuoye Ding dingzhuoye@jd.com \nData Science Lab\nData Science Lab\nUniversity of Minnesota\nMichigan State University\n\n\nJiliang Tang \nData Science Lab\nData Science Lab\nUniversity of Minnesota\nMichigan State University\n\n\nDawei Yin yindawei@acm.org \nData Science Lab\nData Science Lab\nUniversity of Minnesota\nMichigan State University\n\n\nMicro Behaviors: A New Perspective in E-commerce Recommender Systems\nMarina Del Rey, CA, USA2018. February 5-9. 201810.1145/3159652.3159671* This work was done, when the author was an internship at Data Science Lab of JD.com. \u2020 Corresponding author ACM Reference Format: Meizi Zhou, Zhuoye Ding, Jiliang Tang, and Dawei Yin. 2018. Micro Be-haviors: A New Perspective in E-commerce Recommender Systems. In Proceedings of WSDM 2018: The Eleventh ACM International Conference on Web Search and Data Mining (WSDM 2018). ACM, New York, NY, USA, 9 pages. https://CCS CONCEPTS \u2022 Information systems \u2192 Summarization; KEYWORDS Micro behaviorsRNNattention mechanisme-commercerecom- mendation\nThe explosive popularity of e-commerce sites has reshaped users' shopping habits and an increasing number of users prefer to spend more time shopping online. This evolution allows e-commerce sites to observe rich data about users. The majority of traditional recommender systems have focused on the macro interactions between users and items, i.e., the purchase history of a customer. However, within each macro interaction between a user and an item, the user actually performs a sequence of micro behaviors, which indicate how the user locates the item, what activities the user conducts on the item (e.g., reading the comments, carting, and ordering) and how long the user stays with the item. Such micro behaviors offer fine-grained and deep understandings about users and provide tremendous opportunities to advance recommender systems in e-commerce. However, exploiting micro behaviors for recommendations is rather limited, which motivates us to investigate ecommerce recommendations from a micro-behavior perspective in this paper. Particularly, we uncover the effects of micro behaviors on recommendations and propose an interpretable Recommendation framework RIB, which models inherently the sequence of mIcro Behaviors and their effects. Experimental results on datasets from a real e-commence site demonstrate the effectiveness of the proposed framework and the importance of micro behaviors for recommendations.\n\nINTRODUCTION\n\nThe modern e-commerce sites such as Amazon 1 and eBay 2 offer hundreds of millions of products for sale. For example, as on June 20th, 2017, Amazon has more than 372 million products 3 . It has become increasingly challenging for consumers to find their interested items. Recommender systems play a crucial role in mitigating this information overload problem by suggesting products that have potentials to fit consumers' needs. They have been proven to not only help increase customer satisfaction and create customer loyalty [34] but also boost many aspects of e-commerce services such as revenue and growth [24].\n\nMeanwhile, the popularity of e-commerce sites has reshaped users' shopping habits and users prefer to spend more time shopping online. For example, on average, American parents spend 7 hours per week on e-commerce sites 4 . This evolution enables ecommerce sites to observe rich data about their users. Figure 1 illustrates a real example of observed data on a user from an ecommerce site in a short period. The user first enters a page of iPhone 7 from searching result page. She reads the detailed description, as well as others' comments and adds it to the cart. Then she shifts to a page of iPhone 6 from the searching result page and reads the comments. After that, she browses a page of iPhone 7 cases from the sale page and orders the case. Finally, she jumps to a page of Samsung Galaxy from the home page of the e-commerce site. From a macro perspective as shown in the top subfigure in Figure 1, the user interacted with iPhone 7, iPhone 6, iPhone 7 cases and Samsung Galaxy. While from a micro perspective as shown in the bottom subfigure, each macro interaction includes a sequence of behaviors that can indicate how the user located the product page (e.g., the search engine or the sale promotion), whether the user clicks detailed information about a product (e.g., comments, or specifications), whether a user carts or orders a product, and how long the user dwells on a product. In this work, we refer these behaviors in macro interactions as micro-behaviors. These micro behaviors can provide fine-grained understandings about users. For example, locating a product from searching could indicate stronger intents than from the e-commerce homepage; and longer dwell time on a product suggests more interests in the product than shorter dwell time. Hence, exploiting micro behaviors has immense potential to advance recommender systems. However, such research is rather limited in the literature.\n\nIn this paper, we investigate e-commerce recommendations from the micro-behavior perspective where (a) data of a user is inherently viewed as a sequence of macro interactions between users and items; and (b) each macro interaction between a user and an item includes a sequence of micro behaviors as shown in Figure 1. One major advantage of the new perspective is -it provides a unified setting that makes various settings of existing recommender systems become its special cases:\n\n\u2022 if we completely ignore the sequential information of macro interactions and their micro-behaviors, macro interactions can be denoted as an user-item matrix, which is the typically setting for traditional collaborative filtering [29]; \u2022 when we completely ignore the sequential information of macro interactions but consider certain micro behaviors in macro interactions, our setting is boiled down to traditional collaborative filtering with implicit feedback from certain micro behaviors such clicks [12] and dwell time [35]; and \u2022 when we only consider the sequential information of macro interactions in a session and ignore micro-behaviors within macro interactions, the studied problem become sessionbased recommendations [14,15,31].\n\nOn the other hand, it also poses tremendous challenges including (1) how to model sequential information and (2) how to capture effects from a variety of micro behaviors. Solutions to these two challenges lead to a novel recommendation framework. Our major contributions are summarizas follows:\n\n\u2022 We uncover the effects of micro behaviors on e-commerce recommendations; \u2022 We provide a principled approach to capture the sequence of various micro behaviors mathematically; \u2022 We propose an interpretable Recommendation framework from the mIcro Behavior perspective RIB, which incorporates the sequence of micro behaviors and their corresponding effects into a coherent model; and\n\n\u2022 We demonstrate the effectiveness of the proposed framework and the importance of micro behaviors on data from a real e-commerce site. The rest of this paper is organized as follows. In Section 2, we formally define the problem. We perform preliminary data analysis on micro behaviors in Section 3. In Section 4, we detail the proposed framework RIB. Experimental results with discussions are presented in Section 5. In Section 6, we briefly review related work. Finally we conclude our work and discuss the future work in Section 7.\n\n\nPROBLEM STATEMENT\n\nLet P = {p 1 , p 2 , ..., p N } be the set of products where N is the number of products. A = {a 1 , a 2 , ..., a M } be the set of activities a user can perform where M is the number of activities. In addition, we also consider dwell time, which indicates how long a user performs activities in A. We further assume that there are K different dwell time choices as D = {d 1 , d 2 , ..., d K }. Note that dwell time is typically continuous and in this work, we discretize it into K segments. Recall that in our studied problem, (1) data of a user is a sequence of interactions between the user and items and (2) each interaction includes a sequence of micro-behaviors. With the definitions of P, A, D, data in our study can be represented as a sequence of tuples (p i , a j , d k ) (or micro behaviors) where p i \u2208 P, a j \u2208 A, and d k \u2208 D. The tuple (p i , a j , d k ) denotes that the user performs the activity a j on the product p i with d k dwell time.\n\nWith the notations and definitions, the problem we want to study in this work is formally stated as: Given their historical data of a set of users, i.e., sequences of tuples (or micro behaviors) (p i , a j , d k ), we aim to build a recommender system that can suggest the next product for each user which she is interested in.\n\n\nUNCOVERING EFFECTS OF MICRO-BEHAVIORS\n\nIn this section, we begin by introducing the dataset we use for this analysis and then investigate the effects of micro-behaviors on e-commerce.\n\n\nData\n\nWe collect a dataset from a real e-commerce site in a given period.\n\nIt contains four types of information as:\n\n\u2022 Click Source. The entrence to a product page (or click source) can indicate why the user is interested in this product. For example, if a customer enters a product page from Dwell time 61\u223c120 seconds t 5 Dwell time >120 seconds the home page, she may just want to look around and has no target to buy; while if a customer searches for certain products and enters one from the searching result page, he may have a strong intent to buy it. Click source includes the home page, shopping cart page, sale page, searching result page and so on. \u2022 Browsing Modules. In a product page, there are several common modules, such as the brief information (name, price, thumbnail picture), comments, and specification. Browsing Modules can help us understand users' interests. For instance, if a user browses the comments and specifications instead of only browsing the brief information, he would have a higher probability of buying this product. \u2022 Cart and Order. Adding to cart and ordering actions offer strong signals for recommendations. Adding to cart is usually a strong sign of buying a product. However, depending on the characteristics of products, ordering may mean interest shifting or high potential for re-purchase. For example, if a customer purchases some snacks, she may repurchase it in the near future; however, if a customer buys a TV, she is less likely to buy a TV very soon. \u2022 Dwell time. Dwell time is commonly adopted to measure the importance of a webpage on a search engine [1,18,35]. It denotes the length of time that a visitor spends on a page before jumping to another page. Typically, the longer the dwell time, the more interesting the page. The dwell time also exits in e-commerce sites where it indicates the time a customer spends on one product. In the dataset, each product is identified by its SKU (Stock Keeping Unit) as what is done in industry. We discretize continuous dwell time into 5 segments and each segment has a similar number of micro behaviors. The definitions of P, A and D specific to the dataset are demonstrated in Table 1.\n\nEventually this dataset consists of more than 2, 000, 000 users and 150, 000 items. The total number of micro behaviors is more than 90, 000, 000.\n\n\nEffects of Micro Behaviors\n\nIn this subsection, we investigate the correlations among microbehaviors in the sequence. In particular, each time, we choose one micro behavior and then check how others relate to it. Ordering: to study how ordering relates to other micro behaviors, we investigate the relation between certain micro behaviors and the conversion rate. The conversion rate means the percent of a given behavior that ends with ordering in a time window (or a session). The conversion rate of a micro behavior a i can be formulated as:\nConversion rate = # behaviors of a i ended with ordering # behaviors of a i(1)\nThe relations between ordering and other micro behaviors are demonstrated in Figure 2 and Figure 4. In Figure 2, the micro behavior \"Cart\" has the highest conversion rate, which means if a  Similarly, if a user enters a product page from the cart list, he is also very likely to order it. Besides, if the user reads comments, specifications or finishes all the contents of a page, he is also very likely to order it. But if the user just enters a product page without other behaviors, he is less likely to buy the product in the end. In Figure 4, we note that within a certain range, the longer the dwell time is, the higher the conversion rate is. When the dwell time is out of a certain range, the conversion rate would drop down. If the user stays much longer than he needs to finish the page, he might have transferred his attention offline. Dwell Time: Figure 4 has demonstrated the impact of dwell time on ordering. We further show how dwell time is related to microbehaviors of Click Source and Browsing Modules in Figure 5 and Figure 6, respectively. In Figure 5, dwell time on a product is related to how a user locates the product. For example, from searching pages, she may spend longer time on this product; while if from the shop list, she is more likely to spend less time on this product. We also observe from Figure 6 that the longer the dwell time, the more likely a user would visit the detailed modules including reading comments and specifications.\n\nClick Source: We have demonstrated that micro behaviors of Click Source are related to ordering and dwell time. We further show the relations between Click Source and Browsing Modules in Figure 3. We notice that the likelihood of clicking detailed modules is related to the source how a user locates the project. For example, if a customer locates a product from searching, she has a high probability to read the comments and specifications of the product.\n\nTo sum up, we make two key observations about micro behaviors via the above analysis -(1) micro behaviors are correlated; and (2) the effects of one micro-behavior on others are varied. These two observations suggest the complexity and challenges of modeling micro behaviors, however, they also offer important insights to build a meaningful model for micro behaviors in the following section.\n\n\nE-COMMERCE RECOMMENDER SYSTEMS FROM A MICRO BEHAVIORS PERSPECTIVE\n\nTo model micro-behaviors, there are three major challenges. First, a user is a sequence of tuples (p i , a j , d k ) and there are in total N \u00d7 M \u00d7 K tuples; thus the user representation (or input data) is very sparse and high-dimensional. Second, micro behaviors in the sequence are correlated, then how to model sequential information of micro behaviors. Third, different micro behaviors have distinct importance; hence, how to capture varied effects of micro behaviors.\n\nIn this work, we propose a framework, which can tackle these three challenges simultaneously. The architecture of our framework is shown in Figure 7. It consists of five layers -an input layer, an embedding layer to solve the sparse and high-dimensional challenge, a RNN layer to model sequential information, an attention layer to capture varied effects of micro behaviors and an output layer. In the following subsections, we will detail each layer.\n\n\nThe Input and Embedding Layers\n\nThe input of the model is the data of a user u with a sequence of n micro behaviors. We formally define it as a sequence S u = {x 1 , x 2 , ..., x n }, where each x i is a tuple.\nx t = (p v , a m , d k )(2)\np v \u2208 R V is an one-hot indicator vector where p v (i) = 1 if x i is about the i-th product and other entities are zero. Similarly a m \u2208 R M and d k \u2208 R K are indicator vectors for activities and dwell time, respectively. Each of them indicates a unique element in the product set P, activity set A, dwell time set D respectively. The vocabulary sizes of P, A, D are V , M, K respectively, and there are V \u00d7 M \u00d7 K tuples in total. Therefore, the input data is extremely sparse and high-dimensional. We design an embedding layer to transform the input x t into a low-dimensional dense vector e t , which is formally defined as:\ne t = concatenate (W P p v ,W A a m ,W D d k )(3)\nwhere\nW P \u2208 R d P \u00d7V , W A \u2208 R d A \u00d7M , W D \u2208 R d D \u00d7K where d P \u226a N , d A \u226a M and d D \u226a\nK are the numbers of latent dimensions for products, activities and dwell time, separately. The initial weights of W P , W A , W D are trained via Word2vec [25]. And the final embedding of x t is the concatenation of three embeddings. The new representation of x t , e t is dense with dimension of d P + d A + d D , which is much smaller than V \u00d7 M \u00d7 K. creates an internal state of the network which allows it to exhibit dynamic temporal behavior. Therefore, we build a RNN layer to capture the sequential information of micro behaviors. The output of the embedding layer e t is the input of the RNN layer. The t t h hidden state unit output is calculated by\n\n\nThe RNN Layer\nh t = \u03c3 (W eh e t + W hh h t \u22121 + b t )(4)\nwhere \u03c3 (\u00b7) is a nonlinear activation function, e.g. ReLU, sigmoid or tanh; W eh \u2208 R d h \u00d7d e , W hh \u2208 R d h \u00d7d h , and b i \u2208 R d h . Thus, the output on time t is not only decided by the t t h input but also by the output of previous time h t \u22121 . Recurrently, the historical inputs in a sequence are taken into consideration when making new decisions. Micro behaviors in the sequence may exist long dependencies. For example, a customer purchased water one week ago and now she may be interested in repurchasing the same product again. However, when the input sequence is long, RNN may have the problem of gradient vanishing. In other words, when the current micro behavior is influenced both by the recent and previous ones, RNN may not work well. There are two possible solutions. One is the long short-term memory model (LSTM) [16]. The LSTM updates its hidden unit by introducing the input gate i t , forget gate f t and output gate o t as:\ni t = \u03c3 (W ei e t + W hi h t \u22121 + b i ) f t = \u03c3 (W ef e t + W hf h t \u22121 + b f ) o t = \u03c3 (W eo e t + W ho h t \u22121 + b o ) c t = f t \u00b7 c t \u22121 + i t \u00b7 tanh(W ec e t + W hc h t \u22121 + b c ) h t = o t \u00b7 tanh(c t )(5)\nThe other solution is GRU, which has the gated recurrent unit [6]. The GRU is similar to the LSTM, using gates to control the hidden states. However, instead of using input gate i t and forget gate f t to generate a new state, GRU utilizes an update gate z t . GRU has a reset gate r t to control the input of the former state h t \u22121 . But unlike LSTM, GRU doesn't use the output gate.\nr t = \u03c3 (W er e t + W hr h t \u22121 ) z t = \u03c3 (W ez e t + W hz h t \u22121 ) c t = tanh(W ec e t + W hc (r t \u00b7 h t \u22121 )) h t = (1 \u2212 z t )h t \u22121 + z t c t(6)\nWe empirically find that LSTM and GRU achieve very similar performance in the evaluation. Given the simplified structure and faster training speed of GRU, we choose GRU for the proposed framework. In our task, each h t means the representation of the t t h product and the micro-behaviors on it. When the context changes, the representation of a product is adjusted according to the whole sequence before it.\n\n\nThe Attention Layer\n\nAs we shown in the last section, the micro-behaviors in the sequence have varied effects on the following micro behaviors. Therefore, it is important to capture such impacts. To achieve this goal, we introduce an attention layer [5,36,37] that assigns proper weight on each hidden unit. It helps get a more balanced output. The attention is formed as\nM t = tanh(W m h t + b m ), M t \u2208 R k \u00d7L att t = softmax(W a M t + b a ), att t \u2208 R L output = T t =1 att t h t , output \u2208 R k(7)\nwhere a t is the attention weight on time t. The attention weight is mapped from the hidden layer vector into a real valued score by a function \u03c3 (\u00b7). In order to achieve enough expressive ability, the \u03c3 (\u00b7) is usually implemented by a neural network layer. One of the implementation is achieved by the above transformation, including tanh and softmax activation functions. Then the final output is an attention weighted pooling of the RNN layer. The significance of the attention layer has two fold. First, it models varied effects of micro-behaviors in the sequence on recommendations. Second, it increases the interpretation ability of the proposed framework since we can rely on the attention layer to understand how the proposed framework works.\n\n\nLoss Function\n\nAfter the output layer, we need to apply a powerful loss function to help learn the weight matrices in the whole model. We choose a pointwise loss function to compute the cross-entropy\nL = i \u2212t i log(o i )(8)\nwhere t is the normalized target embedding and o is the normalized output embedding.\n\n\nEXPERIMENT\n\nIn this section, we empirically evaluate our model on real world ecommerce datasets and demonstrate the effectiveness of our model. We first introduce the datasets and experimental settings. Then we compare the proposed framework with representative baselines and finally we illustrate the working of the proposed framework via a case study.\n\n\nDatasets\n\nWe collect two datasets with different product categories and sizes from a real e-commerce site. They are named following their product categories, \"Appliances\" and \"Computers\". The detailed statistics of the two datasets are shown in Table 2. Both of them include 10 activities and 5 dwell time buckets as described in Table 1. Note that \"TNMI\" in the table denotes the total number of macro interactions and \"TNMB\" denotes the total number of micro behaviors. We chooses two widely used metrics to assess the recommendation performance [14,15,17,22,23,31,32]:\n\n\u2022 Recall@k: The proportion of cases with the target among the top k predictions. \u2022 MRR@k: Mean Reciprocal Rank is the average of reciprocal ranks of the target. When the rank is larger than k, the reciprocal rank is set to zero.\n\nNote that we empirically set k = 20 in our experiments. To understand the effects of micro behaviors on recommendation performance, we systematically construct the following four datasets for each raw dataset:\n\n\u2022 SKU: Each entity is a tuple with only a SKU, i.e. x t = (p v ).\n\n\u2022 SKU+Activity: Each entity is a tuple with a SKU and an activity, i.e. x t = (p v , a m ). \u2022 SKU+Dwell: Each entity is a tuple with a SKU and a dwell time bucket, i.e. x t = (p v , d k ).\n\n\u2022 SKU+Micro-behaviors: Each entity is a micro behavior tuple with a SKU, an activity and a dwell time bucket, i.e.\n\nx t = (p v , a m , d k ).\n\n\nPerformance Comparison\n\nWe compare our model with the following representative methods.\n\n\u2022 POP is a naive baseline that always recommends the most popular items of the training set. It's a non-personalized recommendation method, however, it has been proved to be comparable to some sophisticated personalized algorithms [8]. \u2022 BPR-MF is one of the most commonly used matrix factorization methods defined in [28]. \u2022 Item-KNN is defined as conditional probability-based similarity in [9]. The similarity between items can be defined as sim(i, j) = F r eq (i j )\n\nF r eq (i )\u00d7F r eq (j ) , where Freq(t ) means the number of sequences where an item t shows up.\n\n\u2022 Word2vec [26] is a shallow, two-layer neural network that is trained to reconstruct linguistic contexts of words. In our work, we could regard each item as a word and train it via Word2vec. And we only use the word vector of the last item in a sequence for prediction. \u2022 Word2vec Avg. It applies the same embeddings trained from Word2vec method. The difference is that it uses the average of all the embeddings in a sequence for prediction. \u2022 RIB-Attention: It is a variant of the proposed framework RIB by removing the attention layer.\n\nNote that in this work, we choose GRU as the RNN layer for both RIB and RIB-Attention. We implement our model using Keras 5 . The experiments are run on a Tesla K20 GPU. The comparison results are shown in Table 3. Note that numbers in the parentheses denote the performance improvement compared to the best baseline. Since the performance of Word2vec and Word2vec Avg. are different on the two datasets. For the \"Appliances\" dataset, we choose Word2vec as the best baseline. For the \"Computers\", we choose Word2vec Avg. as the best baseline. From Table 3, we made the following observations:\n\n\u2022 Methods capturing sequential information including Word2vec, Word2vec Avg, RIB and RIB-Attention outperforms those ignoring sequential information such as POP, BPR-MF and Item-KNN. \u2022 RIB obtains better performance than RIB-Attention. These results support that capturing varied effects of micro behaviors can boost the performance of recommendation. \u2022 Among SKU, SKU+Activity, SKU+Dwell and SKU + Microbehaviors, RIB consistently obtains the best performance on SKU+Micro-behaviors. These observations suggest the importance of micro-behaviors on recommendations.\n\nTo sum up, the proposed framework achieves the best performance because (1) it models sequential information; (2) it captures micro behaviors and (3) it models varied effects of micro behaviors. In the following subsection, we use a case study to understand why the proposed framework works. \n\n\nA Case Study\n\nIn the last subsection, we demonstrate that the proposed framework outperforms various representative baselines. In this subsection, we aim to understand why the proposed framework RIB works. As discussed before, the attention layer equipped the proposed framework with the ability of interpretation. Therefore, we can understand the effects of micro behavior on recommendations via visualizing the attention layer. Figure 8 illustrates an example from the \"Appliances\" dataset and we visualize the attention layers of the proposed framework on SKU, SKU+Activity, SKU+Dwell and SKU+Micro-behaviors. The left part shows a sequence of macro interactions and micro behaviors. The left bottom is what the customer actually browses in this sequence for the next time. There are 4 types of input tuples to show the influence of micro behaviors. The predicted rank of the ground truth is shown at the right bottom. From this case study, it can be observed:\n\n\u2022 When the input tuple only consists of SKU, the attention is mainly decided by position and repetition of the product. Since Joyoung Juicer is the last of the input and shows twice in the sequence, the two Joyoung products have higher attention. \u2022 When the activity is added to SKU, the attention becomes more fine grained. The last Joyoung still has the highest attention. But Aux Blender is getting more attention. This may be due to the activity number and the \"Cart\" and \"De-tail_specification\" activities.\n\n\u2022 When dwell time is added to SKU, the difference is that Aux Blender gets higher attention than the first Joyoung Juicer. This corresponds to the dwell time on these two products. Aux Blender has the longest dwell time which may mean the customer's deeper interests. \u2022 When both the activity and dwell time are added to SKU, Aux Blender and Joyoung Juicer get higher attention. This may due to their \"Cart\" activity and long dwell time. \u2022 From the final prediction result, we could tell the attention change corresponds to the rank precision. Micro-behaviors help understand the macro sequence and thus improve the prediction.\n\nVia the case study, the proposed framework not only can achieve more accurate recommendations via modeling micro behaviors but also can naturally provide the interpretation for recommendations.\n\n\nRELATED WORK\n\nThe most common and traditional methods used in item recommendation are matrix factorization models and neighborhood methods. The matrix factorization models learn a latent representation of users and items that, when decomposed, produce an approximation of the rating that a user would give to an item. There exist a lot of improved factorization-based models, such as non-negative matrix factorization, Bayesian personalized ranking [28], general factorization framework [2], hierarchical Poisson factorization [11], dynamic Poisson factorization [4], etc. Another widely used method for item recommendation is KNN [21]. The similarity between two items is decided by the co-occurrences of them in sessions. There are also some work combining contextual information for recommendation [20,27]. But these methods rarely apply users' behaviors directly and capture the change of behaviors slowly. And deep learning methods perform better on these problems.\n\n\nDeep Learning for Recommendation\n\nDeep learning methods have been applied in kinds of recommendation problems. [32] achieves improved recommendation accuracy by jointly performing deep representation learning (a Bayesian model) for the item content information and collaborative filtering for the ratings matrix. [7] uses deep neural network (DNN) for recommending YouTube videos, focusing on solving candidate generation and ranking problems. [10] uses Multi-view DNN to match rich user features to item features. The proposed model is scalable to large datasets for dimensionality reduction, and it combines different domains into a single model for learning. [39] makes use of stacked convolutional auto-encoder to extract the semantic representation of visual content. And a joint model is designed by integrating collaborative filtering and visual, textual, structural knowledge to boost recommendation quality.\n\n\nRNN on Sequence Data\n\nRecurrent neural network (RNN) [33] is a deep learning model helping process sequential data. Long Short-Term Memory (LSTM) model [16] is a RNN architecture which is suitable when there are very long time lags between important events in a session. Gated Recurrent Units (GRU) [6] is a simple version of LSTM.\n\nThere exists many works using RNN to classify, process or predict sequence data. [38] proposes an attention and RNN based architecture for modeling queries and ads in online advertising. It learns to assign attention scores to words within a sequence. The scores can be successfully applied in query rewriting tasks and can also help modify BM25 metric performance. [40] introduces an RNN framework for click prediction. It models the dependency on user's sequential behaviors into click prediction through the recurrent structure in RNN. This significantly improves the prediction accuracy. And by enriching user features as input, this work fairly compares the prediction capability of different user behaviors. [13] demonstrates an RNN-based item categorization method called DeepCN. DeepCN uses multiple RNNs for generating features from text metadata and uses fully connected layers for classifying item categories from the generated features. It improves the categorization accuracy compared to the models using single RNN or using unigram-based bag-of-words. In [3], RNNs are leveraged to provide vector representations for the text content associated with items in collaborative filtering. It helps perform cold-start prediction on new items.\n\nIn recommender systems, RNN is just started to be used for session-based recommendations. In [14], Hidasi novelly applies GRU on session-based recommending problems. Comparing with item-to-item recommendations, this method proves that considering the whole session instead of one item provides more accurate recommendations. But [14] only uses item IDs as features. For a richer representation of the clicked items, in [15], Hidasi continues his work by applying parallel RNNs for processing both text and image features. [30] and [19] also solve the session-based recommendation using recurrent networks. [31] provides two new session-aware recommendation methods, matrix factorization and RNN. It concludes that the usage of RNN is considered more attractive and flexible when no session modeling assumptions is made.\n\n[17] uses LSTM to learn users' returning time prediction and item recommendation. It shows the problem of survival analysis can be solved by RNN.\n\n\nCONCLUSIONS\n\nIn this paper, we study recommender systems from the micro behaviors perspective. Micro behaviors provide deeper understandings about users, which can be utilized to advance recommender sytems.\n\nThe new perspective provides a unified setting for several existing ones in traditional recommendations. However, modeling micro behaviors is challenging, which motivates us to develop a novel framework RIB. Experimental results on datasets from a real e-commerce site demonstrate the effectiveness of the proposed framework and uncover the importance of micro behaviors in recommendations.\n\nIn this work, we only consider four types of micro behaviors. We would like to study more types of micro behaviors and their effects on recommendations. Meanwhile, our current focus is the domain of e-commerce, however, micro behaviors also exist in other domains such as movies and news. Therefore, we would like to recommender systems in more domains from the micro behavior perspective.\n\nFigure 1 :\n1An illustrative example of observed data on a user from a real e-commerce site.\n\nFigure 2 :Figure 3 :\n23Ordering vs. Other micro behaviors Click Source vs. Browsing Modules\n\nFigure 4 :\n4Ordering vs. Dwell time.\n\nFigure 5 :\n5Dwell Time vs. Click Source Figure 6: Dwell Time vs. Browsing Modules user adds a product to cart, he is more likely to order it in the end.\n\nFigure 7 :\n7neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This The architecture of the proposed framework.\n\nFigure 8 :\n8A case to understand the working of the proposed framework.\n\nTable 1 :\n1Definitions specific to the datasetVar \nAttribute \nDescription \n\np i \nProduct ID \nSKU (Stock Keeping Unit) \nc i \nCategory ID \nProduct category \n\na 1 \nHome2Product \nEnter p i from homepage \na 2 \nShopList2Product \nEnter p i from category page \na 3 \nSale2Product \nEnter p i from sale page \na 4 \nCart2Product \nEnter p i from carted page \na 5 \nSearchList2Product Enter p i from searched results \n\na 6 \nDetail_comments \nIn p i 's comment module \na 7 Detail_specification \nIn p i 's specification module \na 8 \nDetail_bottom \nAt the bottom \n\na 9 \nCart \nAdd p i to cart \na 10 \nOrder \nOrder p i \n\nt 1 \nDwell time \n0\u223c9 seconds \nt 2 \nDwell time \n10\u223c24 seconds \nt 3 \nDwell time \n25\u223c60 seconds \nt 4 \n\n\nTable 2 :\n2Statistics of Datasets.Datasets \nAppliances \nComputers \nTraining \nTest \nTraining \nTest \nUsers \n1,058,099 \n117,566 \n2,842,871 \n315,874 \nSKU \n115,498 \n12,833 \n134,996 \n14,999 \nTNMI \n5,290,497 \n587,833 11,371,485 1,263,498 \nTNMB \n38,091,578 4,232,397 44,222,445 4,913,604 \n\n\n\nTable 3 :\n3Performance ComparisonData type \nModel \nAppliances \nComputers \n\nRecall@20 \nMRR@20 \nRecall@20 \nMRR@20 \n\nSKU \n\nPOP \n0.0088 \n0.0028 \n0.0149 \n0.0085 \n\nBPR-MF \n0.1255 \n0.0578 \n0.0747 \n0.0271 \n\nItem-KNN \n0.1806 \n0.0738 \n0.1101 \n0.0464 \n\nWord2vec \n0.3645 \n0.1295 \n0.3012 \n0.1044 \n\nWord2vec Avg. \n0.3668 \n0.1268 \n0.3152 \n0.1088 \n\nRIB-Attention 0.4587(+25.84%) 0.1676(+29.42%) 0.3816(+21.07%) 0.1362(+25.18%) \n\nRIB \n0.4732(+29.82%) 0.1718(+32.66%) 0.4043(+28.27%) 0.1456(+33.82%) \n\nSKU+Activity \nRIB-Attention 0.4615(+26.61%) 0.1724(+33.13%) 0.4092(+29.82%) 0.1443(+32.63%) \n\nRIB \n0.4842(+32.82%) 0.1776(+37.14%) 0.4204(+33.38%) 0.1481(+36.12%) \n\nSKU+Dwell \nRIB-Attention \n0.4673(+28.2%) 0.1745(+34.75%) 0.4108(+30.33%) 0.1482(+36.21%) \n\nRIB \n0.4822(+32.29%) 0.1766(+36.37%) 0.4269(+35.44%) 0.149(+36.95%) \n\nSKU+Micro-behaviors \nRIB-Attention \n0.474(+30.04%) 0.1784(+37.76%) 0.4227(+34.11%) 0.1516(+39.34%) \n\nRIB \n0.4889(+34.13%) 0.1793(+38.46%) 0.4332(+37.44%) 0.1533(+40.9%) \n\n\nhttps://keras.io\nACKNOWLEDGEMENTS\nImproving Web Search Ranking by Incorporating User Behavior Information. Eugene Agichtein, Eric Brill, Susan Dumais, 10.1145/1148170.1148177Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '06). the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '06)New York, NY, USAACMEugene Agichtein, Eric Brill, and Susan Dumais. 2006. Improving Web Search Ranking by Incorporating User Behavior Information. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '06). ACM, New York, NY, USA, 19-26. https://doi. org/10.1145/1148170.1148177\n\nGeneral factorization framework for context-aware recommendations. Hidasi Balazs, Tikk Domonkos, Data Mining and Knowledge Discovery. Hidasi Balazs and Tikk Domonkos. 2015. General factorization framework for context-aware recommendations. Data Mining and Knowledge Discovery (2015), 1-30.\n\nT Bansal, D Belanger, A Mccallum, Ask the GRU : Multi-task Learning for Deep Text Recommendations. ACM Conference on Recommender Systems. T. Bansal, D. Belanger, and A. Mccallum. 2016. Ask the GRU : Multi-task Learning for Deep Text Recommendations. ACM Conference on Recommender Systems (2016).\n\nL Charlin, R Ranganath, J Mcinerney, D M Blei, Dynamic poisson factorization. CoRRL. Charlin, R. Ranganath, J. McInerney, and D. M. Blei. 2015. Dynamic poisson factorization. CoRR (2015).\n\nABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering. Kan Chen, Jiang Wang, Liang-Chieh Chen, Haoyuan Gao, Wei Xu, Ram Nevatia, CoRR abs/1511.05960Kan Chen, Jiang Wang, Liang-Chieh Chen, Haoyuan Gao, Wei Xu, and Ram Nevatia. 2015. ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering. CoRR abs/1511.05960 (2015). http://arxiv.org/ abs/1511.05960\n\nOn the Properties of Neural Machine Translation: Encoder-Decoder Approaches. Kyunghyun Cho, Dzmitry Bart Van Merrienboer, Yoshua Bahdanau, Bengio, CoRR abs/1409.1259KyungHyun Cho, Bart van Merrienboer, Dzmitry Bahdanau, and Yoshua Ben- gio. 2014. On the Properties of Neural Machine Translation: Encoder-Decoder Approaches. CoRR abs/1409.1259 (2014). http://arxiv.org/abs/1409.1259\n\nDeep Neural Networks for YouTube Recommendations. P Covington, J Adams, E Sargin, Proceedings of the 10th ACM Conference on Recommender Systems. the 10th ACM Conference on Recommender SystemsP. Covington, J. Adams, and E. Sargin. 2016. Deep Neural Networks for YouTube Recommendations. Proceedings of the 10th ACM Conference on Recommender Systems (2016), 191-198.\n\nPaolo Cremonesi, Yehuda Koren, Roberto Turrin, Performance of recommender algorithms on top-n recommendation tasks. RecSys. Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. 2011. Performance of recommender algorithms on top-n recommendation tasks. RecSys (2011).\n\nItem-based top-N Recommendation Algorithms. Mukund Deshpande, George Karypis, 10.1145/963770.963776ACM Trans. Inf. Syst. 22Mukund Deshpande and George Karypis. 2004. Item-based top-N Recommen- dation Algorithms. ACM Trans. Inf. Syst. 22, 1 (Jan. 2004), 143-177. https: //doi.org/10.1145/963770.963776\n\nA Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems. A Elkahky, Y Song, X He, WWWA. Elkahky, Y. Song, and X. He. 2015. A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems. WWW (2015).\n\nScalable recommendation with hierarchical poisson factorization. P Gopalan, J M Hofman, D M Blei, Proceedings of the Thirty-First Conference on Uncertainty in Artificial Intelligence. the Thirty-First Conference on Uncertainty in Artificial IntelligenceP. Gopalan, J. M. Hofman, and D. M. Blei. 2015. Scalable recommendation with hierarchical poisson factorization. Proceedings of the Thirty-First Conference on Uncertainty in Artificial Intelligence, (2015).\n\nAmazon.com recommendations: item-to-item collaborative filtering. Linden Greg, Smith Brent, York Jeremy, IEEE Internet Computing. 71Linden Greg, Smith Brent, and York Jeremy. 2003. Amazon.com recommendations: item-to-item collaborative filtering. IEEE Internet Computing 7, 1 (Jan. 2003), 76 - 80.\n\nLarge-Scale Item Categorization in e-Commerce Using Multiple Recurrent Neural Networks. J W Ha, H Pyo, J Kim, KDD. J. W. Ha, H. Pyo, and J. Kim. 2016. Large-Scale Item Categorization in e-Commerce Using Multiple Recurrent Neural Networks. KDD (2016).\n\nB Hidasi, A Karatzoglou, L Baltrunas, D Tikk, Session-based Recommendations with Recurrent Neural Networks. ICLR. B. Hidasi, A. Karatzoglou, L. Baltrunas, and D. Tikk. 2016. Session-based Recom- mendations with Recurrent Neural Networks. ICLR (2016).\n\nParallel Recurrent Neural Network Architectures for Feature-rich Session-based Recommendations. B Hidasi, M Quadrana, A Karatzoglou, D Tikk, Proceedings of the 10th ACM Conference on Recommender Systems. the 10th ACM Conference on Recommender SystemsB. Hidasi, M. Quadrana, A. Karatzoglou, and D. Tikk. 2016. Parallel Recurrent Neural Network Architectures for Feature-rich Session-based Recommendations. Proceedings of the 10th ACM Conference on Recommender Systems (2016), 241-248.\n\nLong short-term memory. S Hochreiter, J Schmidhuber, Neural computation. 9S. Hochreiter and J. Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735-1780.\n\n. How Jing, Alexander J Smola, Neural Survival Recommender. WSDM. How Jing and Alexander J Smola. 2017. Neural Survival Recommender. WSDM (2017).\n\nModeling Dwell Time to Predict Click-level Satisfaction. Youngho Kim, Ahmed Hassan, Ryen W White, Imed Zitouni, 10.1145/2556195.2556220Proceedings of the 7th ACM International Conference on Web Search and Data Mining (WSDM '14). the 7th ACM International Conference on Web Search and Data Mining (WSDM '14)New York, NY, USAACMYoungho Kim, Ahmed Hassan, Ryen W. White, and Imed Zitouni. 2014. Modeling Dwell Time to Predict Click-level Satisfaction. In Proceedings of the 7th ACM International Conference on Web Search and Data Mining (WSDM '14). ACM, New York, NY, USA, 193-202. https://doi.org/10.1145/2556195.2556220\n\nJing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Jun Ma, Neural Attentive Session-based Recommendation. CIKM. Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, and Jun Ma. 2017. Neural Attentive Session-based Recommendation. CIKM (2017).\n\nNeural Rating Regression with Abstractive Tips Generation for Recommendation. P Li, Wang, Ren, W Bing, Lam, P Li, Z Wang, Z Ren, L Bing, and W Lam. 2017. Neural Rating Regression with Abstractive Tips Generation for Recommendation. SIGIR (2017).\n\nG Linden, J Smith, York, Amazon. com recommendations: Item-toitem collaborative filtering. Internet Computing. 7G Linden, B Smith, and J York. 2003. Amazon. com recommendations: Item-to- item collaborative filtering. Internet Computing, IEEE 7, 1 (2003), 76-80.\n\nContextaware Sequential Recommendation. Qiang Liu, Shu Wu, Diyi Wang, Zhaokang Li, Liang Wang, CoRR abs/1609.05787Qiang Liu, Shu Wu, Diyi Wang, Zhaokang Li, and Liang Wang. 2016. Context- aware Sequential Recommendation. CoRR abs/1609.05787 (2016). http://arxiv. org/abs/1609.05787\n\nMulti-Behavioral Sequential Prediction with Recurrent Log-Bilinear Model. Qiang Liu, Shu Wu, Liang Wang, 10.1109/TKDE.2017.2661760IEEE Trans. on Knowl. and Data Eng. 296Qiang Liu, Shu Wu, and Liang Wang. 2017. Multi-Behavioral Sequential Predic- tion with Recurrent Log-Bilinear Model. IEEE Trans. on Knowl. and Data Eng. 29, 6 (June 2017), 1254-1267. https://doi.org/10.1109/TKDE.2017.2661760\n\nShow Me the Money: Dynamic Recommendations for Revenue Maximization. Wei Lu, Shanshan Chen, Keqian Li, V S Laks, Lakshmanan, 10.14778/2733085.2733086Proc. VLDB Endow. VLDB Endow7Wei Lu, Shanshan Chen, Keqian Li, and Laks V. S. Lakshmanan. 2014. Show Me the Money: Dynamic Recommendations for Revenue Maximization. Proc. VLDB Endow. 7, 14 (Oct. 2014), 1785-1796. https://doi.org/10.14778/2733085.2733086\n\nEfficient Estimation of Word Representations in Vector Space. Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean, CoRR abs/1301.3781Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. CoRR abs/1301.3781 (2013).\n\nDistributed Representations of Words and Phrases and their Compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, Jeff Dean, Advances in Neural Information Processing Systems. C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. WeinbergerCurran Associates, Inc26Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed Representations of Words and Phrases and their Com- positionality. In Advances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Wein- berger (Eds.). Curran Associates, Inc., 3111-3119. http://papers.nips.cc/paper/ 5021-distributed-representations-of-words-and-phrases-and-their-compositionality. pdf\n\nSocial Collaborative Viewpoint Regression with Explainable Recommendations. Z Ren, P Liang, Li, M Wang, De Rijke, The 10th ACM International Conference on Web Search and Data Mining. Z Ren, S Liang, P Li, S Wang, and M de Rijke. 2017. Social Collaborative Viewpoint Regression with Explainable Recommendations. The 10th ACM International Conference on Web Search and Data Mining (2017).\n\nBPR: Bayesian Personalized Ranking from Implicit Feedback. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. (2009), 452- 461. http://dl.acm.org/citation.cfm?id=1795114.1795167\n\nCollaborative Filtering Recommender Systems. J , Ben Schafer, Dan Frankowski, Jon Herlocker, Shilad Sen, 10.1007/978-3-540-72079-9_9SpringerBerlin Heidelberg; Berlin, HeidelbergJ. Ben Schafer, Dan Frankowski, Jon Herlocker, and Shilad Sen. 2007. Collaborative Filtering Recommender Systems. Springer Berlin Heidelberg, Berlin, Heidelberg, 291-324. https://doi.org/10.1007/978-3-540-72079-9_9\n\nImproved recurrent neural networks for session-based recommendations. Y K Tan, X Xu, Y Liu, CoRRY. K. Tan, X. Xu, and Y. Liu. 2016. Improved recurrent neural networks for session-based recommendations. CoRR (2016).\n\nModelling Contextual Information in Session-Aware Recommender Systems with Neural Networks. B Twardowski, ACM Conference on Recommender Systems. B. Twardowski. 2016. Modelling Contextual Information in Session-Aware Rec- ommender Systems with Neural Networks. ACM Conference on Recommender Systems (2016), 273-276.\n\nCollaborative Deep Learning for Recommender Systems. H Wang, N Wang, D Yeung, KDD. H. Wang, N. Wang, and D. Yeung. 2015. Collaborative Deep Learning for Recom- mender Systems. KDD (2015).\n\nBackpropagation through time: what it does and how to do it. P J Werbos, Proc. IEEE. 78P. J. Werbos. 1990. Backpropagation through time: what it does and how to do it. Proc. IEEE 78, 10 (1990), 1550-1560.\n\nA customer value, satisfaction, and loyalty perspective of mobile application recommendations. Chenyan Xu, Daniel Peak, Victor Prybutok, Decision Support Systems. 79Chenyan Xu, Daniel Peak, and Victor Prybutok. 2015. A customer value, satisfac- tion, and loyalty perspective of mobile application recommendations. Decision Support Systems 79 (2015), 171-183.\n\nBeyond Clicks: Dwell Time for Personalization. Xing Yi, Liangjie Hong, Erheng Zhong, Nanthan Nan Liu, Suju Rajan, 10.1145/2645710.2645724Proceedings of the 8th ACM Conference on Recommender Systems (RecSys '14). the 8th ACM Conference on Recommender Systems (RecSys '14)New York, NY, USAACMXing Yi, Liangjie Hong, Erheng Zhong, Nanthan Nan Liu, and Suju Rajan. 2014. Beyond Clicks: Dwell Time for Personalization. In Proceedings of the 8th ACM Conference on Recommender Systems (RecSys '14). ACM, New York, NY, USA, 113-120. https://doi.org/10.1145/2645710.2645724\n\nAttention-Based Convolutional Neural Network for Machine Comprehension. Wenpeng Yin, Sebastian Ebert, Hinrich Sch\u00fctze, CoRR abs/1602.04341Wenpeng Yin, Sebastian Ebert, and Hinrich Sch\u00fctze. 2016. Attention-Based Con- volutional Neural Network for Machine Comprehension. CoRR abs/1602.04341 (2016). http://arxiv.org/abs/1602.04341\n\nABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs. Wenpeng Yin, Hinrich Sch\u00fctze, Bing Xiang, Bowen Zhou, CoRR abs/1512.05193Wenpeng Yin, Hinrich Sch\u00fctze, Bing Xiang, and Bowen Zhou. 2015. ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs. CoRR abs/1512.05193 (2015). http://arxiv.org/abs/1512.05193\n\nDeepIntent: learning attentions for online advertising with recurrent neural networks. S Zhai, H Chang, R Zhang, Z Zhang, KDD. S. Zhai, H. Chang, R. Zhang, and Z. Zhang. 2016. DeepIntent: learning attentions for online advertising with recurrent neural networks. KDD (2016).\n\nCollaborative Knowledge Base Embedding for Recommender Systems. F Zhang, N J Yuan, D Lian, X Xie, W Ma, KDD. F. Zhang, N. J. Yuan, D. Lian, X. Xie, and W. Ma. 2016. Collaborative Knowledge Base Embedding for Recommender Systems. KDD (2016).\n\nSequential Click Prediction for Sponsored Search with Recurrent Neural Networks. Y Zhang, H Dai, C Xu, J Feng, T Wang, J Bian, B Wang, T Liu, AAAIY. Zhang, H. Dai, C. Xu, J. Feng, T. Wang, J. Bian, B. Wang, and T. Liu. 2014. Se- quential Click Prediction for Sponsored Search with Recurrent Neural Networks. AAAI (2014).\n", "annotations": {"author": "[{\"end\":193,\"start\":96},{\"end\":310,\"start\":194},{\"end\":410,\"start\":311},{\"end\":524,\"start\":411}]", "publisher": null, "author_last_name": "[{\"end\":106,\"start\":102},{\"end\":205,\"start\":201},{\"end\":323,\"start\":319},{\"end\":420,\"start\":417}]", "author_first_name": "[{\"end\":101,\"start\":96},{\"end\":200,\"start\":194},{\"end\":318,\"start\":311},{\"end\":416,\"start\":411}]", "author_affiliation": "[{\"end\":192,\"start\":108},{\"end\":309,\"start\":225},{\"end\":409,\"start\":325},{\"end\":523,\"start\":439}]", "title": "[{\"end\":69,\"start\":1},{\"end\":593,\"start\":525}]", "venue": null, "abstract": "[{\"end\":2631,\"start\":1207}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2831,\"start\":2830},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3178,\"start\":3174},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3261,\"start\":3257},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3485,\"start\":3484},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5895,\"start\":5891},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6168,\"start\":6164},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":6188,\"start\":6184},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6394,\"start\":6390},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6397,\"start\":6394},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6400,\"start\":6397},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9436,\"start\":9435},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":10724,\"start\":10721},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":10727,\"start\":10724},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":10730,\"start\":10727},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":16558,\"start\":16554},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17953,\"start\":17949},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18338,\"start\":18335},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":19471,\"start\":19468},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":19474,\"start\":19471},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":19477,\"start\":19474},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21692,\"start\":21688},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":21695,\"start\":21692},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":21698,\"start\":21695},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21701,\"start\":21698},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":21704,\"start\":21701},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21707,\"start\":21704},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":21710,\"start\":21707},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":22878,\"start\":22875},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":22966,\"start\":22962},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23040,\"start\":23037},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23229,\"start\":23225},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23877,\"start\":23876},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":27966,\"start\":27962},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":28003,\"start\":28000},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":28044,\"start\":28040},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":28079,\"start\":28076},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":28148,\"start\":28144},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":28318,\"start\":28314},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":28321,\"start\":28318},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":28601,\"start\":28597},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":28802,\"start\":28799},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":28934,\"start\":28930},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":29152,\"start\":29148},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":29462,\"start\":29458},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":29561,\"start\":29557},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":29707,\"start\":29704},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":29823,\"start\":29819},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":30108,\"start\":30104},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":30456,\"start\":30452},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":30810,\"start\":30807},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":31087,\"start\":31083},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":31323,\"start\":31319},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":31413,\"start\":31409},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31516,\"start\":31512},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":31525,\"start\":31521},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":31600,\"start\":31596}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33041,\"start\":32949},{\"attributes\":{\"id\":\"fig_1\"},\"end\":33134,\"start\":33042},{\"attributes\":{\"id\":\"fig_2\"},\"end\":33172,\"start\":33135},{\"attributes\":{\"id\":\"fig_3\"},\"end\":33326,\"start\":33173},{\"attributes\":{\"id\":\"fig_4\"},\"end\":33504,\"start\":33327},{\"attributes\":{\"id\":\"fig_5\"},\"end\":33577,\"start\":33505},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":34276,\"start\":33578},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":34560,\"start\":34277},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":35543,\"start\":34561}]", "paragraph": "[{\"end\":3262,\"start\":2647},{\"end\":5175,\"start\":3264},{\"end\":5658,\"start\":5177},{\"end\":6401,\"start\":5660},{\"end\":6697,\"start\":6403},{\"end\":7081,\"start\":6699},{\"end\":7617,\"start\":7083},{\"end\":8595,\"start\":7639},{\"end\":8924,\"start\":8597},{\"end\":9110,\"start\":8966},{\"end\":9186,\"start\":9119},{\"end\":9229,\"start\":9188},{\"end\":11299,\"start\":9231},{\"end\":11447,\"start\":11301},{\"end\":11994,\"start\":11478},{\"end\":13542,\"start\":12074},{\"end\":14000,\"start\":13544},{\"end\":14395,\"start\":14002},{\"end\":14937,\"start\":14465},{\"end\":15390,\"start\":14939},{\"end\":15603,\"start\":15425},{\"end\":16258,\"start\":15632},{\"end\":16314,\"start\":16309},{\"end\":17057,\"start\":16398},{\"end\":18063,\"start\":17117},{\"end\":18658,\"start\":18273},{\"end\":19215,\"start\":18807},{\"end\":19589,\"start\":19239},{\"end\":20470,\"start\":19720},{\"end\":20672,\"start\":20488},{\"end\":20781,\"start\":20697},{\"end\":21137,\"start\":20796},{\"end\":21711,\"start\":21150},{\"end\":21941,\"start\":21713},{\"end\":22152,\"start\":21943},{\"end\":22219,\"start\":22154},{\"end\":22409,\"start\":22221},{\"end\":22525,\"start\":22411},{\"end\":22552,\"start\":22527},{\"end\":22642,\"start\":22579},{\"end\":23114,\"start\":22644},{\"end\":23212,\"start\":23116},{\"end\":23752,\"start\":23214},{\"end\":24346,\"start\":23754},{\"end\":24913,\"start\":24348},{\"end\":25207,\"start\":24915},{\"end\":26173,\"start\":25224},{\"end\":26686,\"start\":26175},{\"end\":27315,\"start\":26688},{\"end\":27510,\"start\":27317},{\"end\":28483,\"start\":27527},{\"end\":29402,\"start\":28520},{\"end\":29736,\"start\":29427},{\"end\":30988,\"start\":29738},{\"end\":31809,\"start\":30990},{\"end\":31956,\"start\":31811},{\"end\":32165,\"start\":31972},{\"end\":32557,\"start\":32167},{\"end\":32948,\"start\":32559}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12073,\"start\":11995},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15631,\"start\":15604},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16308,\"start\":16259},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16397,\"start\":16315},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17116,\"start\":17074},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18272,\"start\":18064},{\"attributes\":{\"id\":\"formula_6\"},\"end\":18806,\"start\":18659},{\"attributes\":{\"id\":\"formula_7\"},\"end\":19719,\"start\":19590},{\"attributes\":{\"id\":\"formula_8\"},\"end\":20696,\"start\":20673}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":11298,\"start\":11291},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21392,\"start\":21385},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21477,\"start\":21470},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23967,\"start\":23960},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24309,\"start\":24302}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2645,\"start\":2633},{\"attributes\":{\"n\":\"2\"},\"end\":7637,\"start\":7620},{\"attributes\":{\"n\":\"3\"},\"end\":8964,\"start\":8927},{\"attributes\":{\"n\":\"3.1\"},\"end\":9117,\"start\":9113},{\"attributes\":{\"n\":\"3.2\"},\"end\":11476,\"start\":11450},{\"attributes\":{\"n\":\"4\"},\"end\":14463,\"start\":14398},{\"attributes\":{\"n\":\"4.1\"},\"end\":15423,\"start\":15393},{\"attributes\":{\"n\":\"4.2\"},\"end\":17073,\"start\":17060},{\"attributes\":{\"n\":\"4.3\"},\"end\":19237,\"start\":19218},{\"attributes\":{\"n\":\"4.4\"},\"end\":20486,\"start\":20473},{\"attributes\":{\"n\":\"5\"},\"end\":20794,\"start\":20784},{\"attributes\":{\"n\":\"5.1\"},\"end\":21148,\"start\":21140},{\"attributes\":{\"n\":\"5.2\"},\"end\":22577,\"start\":22555},{\"attributes\":{\"n\":\"5.3\"},\"end\":25222,\"start\":25210},{\"attributes\":{\"n\":\"6\"},\"end\":27525,\"start\":27513},{\"attributes\":{\"n\":\"6.1\"},\"end\":28518,\"start\":28486},{\"attributes\":{\"n\":\"6.2\"},\"end\":29425,\"start\":29405},{\"attributes\":{\"n\":\"7\"},\"end\":31970,\"start\":31959},{\"end\":32960,\"start\":32950},{\"end\":33063,\"start\":33043},{\"end\":33146,\"start\":33136},{\"end\":33184,\"start\":33174},{\"end\":33338,\"start\":33328},{\"end\":33516,\"start\":33506},{\"end\":33588,\"start\":33579},{\"end\":34287,\"start\":34278},{\"end\":34571,\"start\":34562}]", "table": "[{\"end\":34276,\"start\":33625},{\"end\":34560,\"start\":34312},{\"end\":35543,\"start\":34595}]", "figure_caption": "[{\"end\":33041,\"start\":32962},{\"end\":33134,\"start\":33066},{\"end\":33172,\"start\":33148},{\"end\":33326,\"start\":33186},{\"end\":33504,\"start\":33340},{\"end\":33577,\"start\":33518},{\"end\":33625,\"start\":33590},{\"end\":34312,\"start\":34289},{\"end\":34595,\"start\":34573}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3575,\"start\":3567},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4168,\"start\":4160},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5494,\"start\":5486},{\"end\":12159,\"start\":12151},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":12172,\"start\":12164},{\"end\":12185,\"start\":12177},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":12619,\"start\":12611},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":12940,\"start\":12932},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":13104,\"start\":13096},{\"end\":13117,\"start\":13109},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":13144,\"start\":13136},{\"end\":13407,\"start\":13399},{\"end\":13739,\"start\":13731},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":15087,\"start\":15079},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":25648,\"start\":25640}]", "bib_author_first_name": "[{\"end\":35657,\"start\":35651},{\"end\":35673,\"start\":35669},{\"end\":35686,\"start\":35681},{\"end\":36393,\"start\":36387},{\"end\":36406,\"start\":36402},{\"end\":36612,\"start\":36611},{\"end\":36622,\"start\":36621},{\"end\":36634,\"start\":36633},{\"end\":36909,\"start\":36908},{\"end\":36920,\"start\":36919},{\"end\":36933,\"start\":36932},{\"end\":36946,\"start\":36945},{\"end\":36948,\"start\":36947},{\"end\":37188,\"start\":37185},{\"end\":37200,\"start\":37195},{\"end\":37218,\"start\":37207},{\"end\":37232,\"start\":37225},{\"end\":37241,\"start\":37238},{\"end\":37249,\"start\":37246},{\"end\":37598,\"start\":37589},{\"end\":37611,\"start\":37604},{\"end\":37640,\"start\":37634},{\"end\":37946,\"start\":37945},{\"end\":37959,\"start\":37958},{\"end\":37968,\"start\":37967},{\"end\":38266,\"start\":38261},{\"end\":38284,\"start\":38278},{\"end\":38299,\"start\":38292},{\"end\":38577,\"start\":38571},{\"end\":38595,\"start\":38589},{\"end\":38924,\"start\":38923},{\"end\":38935,\"start\":38934},{\"end\":38943,\"start\":38942},{\"end\":39162,\"start\":39161},{\"end\":39173,\"start\":39172},{\"end\":39175,\"start\":39174},{\"end\":39185,\"start\":39184},{\"end\":39187,\"start\":39186},{\"end\":39629,\"start\":39623},{\"end\":39641,\"start\":39636},{\"end\":39653,\"start\":39649},{\"end\":39945,\"start\":39944},{\"end\":39947,\"start\":39946},{\"end\":39953,\"start\":39952},{\"end\":39960,\"start\":39959},{\"end\":40109,\"start\":40108},{\"end\":40119,\"start\":40118},{\"end\":40134,\"start\":40133},{\"end\":40147,\"start\":40146},{\"end\":40457,\"start\":40456},{\"end\":40467,\"start\":40466},{\"end\":40479,\"start\":40478},{\"end\":40494,\"start\":40493},{\"end\":40870,\"start\":40869},{\"end\":40884,\"start\":40883},{\"end\":41032,\"start\":41029},{\"end\":41048,\"start\":41039},{\"end\":41050,\"start\":41049},{\"end\":41238,\"start\":41231},{\"end\":41249,\"start\":41244},{\"end\":41262,\"start\":41258},{\"end\":41264,\"start\":41263},{\"end\":41276,\"start\":41272},{\"end\":41798,\"start\":41794},{\"end\":41810,\"start\":41803},{\"end\":41822,\"start\":41816},{\"end\":41837,\"start\":41829},{\"end\":41846,\"start\":41843},{\"end\":42111,\"start\":42110},{\"end\":42128,\"start\":42127},{\"end\":42280,\"start\":42279},{\"end\":42290,\"start\":42289},{\"end\":42587,\"start\":42582},{\"end\":42596,\"start\":42593},{\"end\":42605,\"start\":42601},{\"end\":42620,\"start\":42612},{\"end\":42630,\"start\":42625},{\"end\":42904,\"start\":42899},{\"end\":42913,\"start\":42910},{\"end\":42923,\"start\":42918},{\"end\":43292,\"start\":43289},{\"end\":43305,\"start\":43297},{\"end\":43318,\"start\":43312},{\"end\":43324,\"start\":43323},{\"end\":43326,\"start\":43325},{\"end\":43691,\"start\":43686},{\"end\":43704,\"start\":43701},{\"end\":43715,\"start\":43711},{\"end\":43732,\"start\":43725},{\"end\":43992,\"start\":43987},{\"end\":44006,\"start\":44002},{\"end\":44021,\"start\":44018},{\"end\":44032,\"start\":44028},{\"end\":44034,\"start\":44033},{\"end\":44048,\"start\":44044},{\"end\":44741,\"start\":44740},{\"end\":44754,\"start\":44753},{\"end\":45111,\"start\":45104},{\"end\":45129,\"start\":45120},{\"end\":45149,\"start\":45145},{\"end\":45163,\"start\":45159},{\"end\":45440,\"start\":45439},{\"end\":45446,\"start\":45443},{\"end\":45459,\"start\":45456},{\"end\":45475,\"start\":45472},{\"end\":45493,\"start\":45487},{\"end\":45858,\"start\":45857},{\"end\":45860,\"start\":45859},{\"end\":45867,\"start\":45866},{\"end\":45873,\"start\":45872},{\"end\":46096,\"start\":46095},{\"end\":46373,\"start\":46372},{\"end\":46381,\"start\":46380},{\"end\":46389,\"start\":46388},{\"end\":46570,\"start\":46569},{\"end\":46572,\"start\":46571},{\"end\":46816,\"start\":46809},{\"end\":46827,\"start\":46821},{\"end\":46840,\"start\":46834},{\"end\":47125,\"start\":47121},{\"end\":47138,\"start\":47130},{\"end\":47151,\"start\":47145},{\"end\":47166,\"start\":47159},{\"end\":47170,\"start\":47167},{\"end\":47180,\"start\":47176},{\"end\":47719,\"start\":47712},{\"end\":47734,\"start\":47725},{\"end\":47749,\"start\":47742},{\"end\":48058,\"start\":48051},{\"end\":48071,\"start\":48064},{\"end\":48085,\"start\":48081},{\"end\":48098,\"start\":48093},{\"end\":48418,\"start\":48417},{\"end\":48426,\"start\":48425},{\"end\":48435,\"start\":48434},{\"end\":48444,\"start\":48443},{\"end\":48671,\"start\":48670},{\"end\":48680,\"start\":48679},{\"end\":48682,\"start\":48681},{\"end\":48690,\"start\":48689},{\"end\":48698,\"start\":48697},{\"end\":48705,\"start\":48704},{\"end\":48930,\"start\":48929},{\"end\":48939,\"start\":48938},{\"end\":48946,\"start\":48945},{\"end\":48952,\"start\":48951},{\"end\":48960,\"start\":48959},{\"end\":48968,\"start\":48967},{\"end\":48976,\"start\":48975},{\"end\":48984,\"start\":48983}]", "bib_author_last_name": "[{\"end\":35667,\"start\":35658},{\"end\":35679,\"start\":35674},{\"end\":35693,\"start\":35687},{\"end\":36400,\"start\":36394},{\"end\":36415,\"start\":36407},{\"end\":36619,\"start\":36613},{\"end\":36631,\"start\":36623},{\"end\":36643,\"start\":36635},{\"end\":36917,\"start\":36910},{\"end\":36930,\"start\":36921},{\"end\":36943,\"start\":36934},{\"end\":36953,\"start\":36949},{\"end\":37193,\"start\":37189},{\"end\":37205,\"start\":37201},{\"end\":37223,\"start\":37219},{\"end\":37236,\"start\":37233},{\"end\":37244,\"start\":37242},{\"end\":37257,\"start\":37250},{\"end\":37602,\"start\":37599},{\"end\":37632,\"start\":37612},{\"end\":37649,\"start\":37641},{\"end\":37657,\"start\":37651},{\"end\":37956,\"start\":37947},{\"end\":37965,\"start\":37960},{\"end\":37975,\"start\":37969},{\"end\":38276,\"start\":38267},{\"end\":38290,\"start\":38285},{\"end\":38306,\"start\":38300},{\"end\":38587,\"start\":38578},{\"end\":38603,\"start\":38596},{\"end\":38932,\"start\":38925},{\"end\":38940,\"start\":38936},{\"end\":38946,\"start\":38944},{\"end\":39170,\"start\":39163},{\"end\":39182,\"start\":39176},{\"end\":39192,\"start\":39188},{\"end\":39634,\"start\":39630},{\"end\":39647,\"start\":39642},{\"end\":39660,\"start\":39654},{\"end\":39950,\"start\":39948},{\"end\":39957,\"start\":39954},{\"end\":39964,\"start\":39961},{\"end\":40116,\"start\":40110},{\"end\":40131,\"start\":40120},{\"end\":40144,\"start\":40135},{\"end\":40152,\"start\":40148},{\"end\":40464,\"start\":40458},{\"end\":40476,\"start\":40468},{\"end\":40491,\"start\":40480},{\"end\":40499,\"start\":40495},{\"end\":40881,\"start\":40871},{\"end\":40896,\"start\":40885},{\"end\":41037,\"start\":41033},{\"end\":41056,\"start\":41051},{\"end\":41242,\"start\":41239},{\"end\":41256,\"start\":41250},{\"end\":41270,\"start\":41265},{\"end\":41284,\"start\":41277},{\"end\":41801,\"start\":41799},{\"end\":41814,\"start\":41811},{\"end\":41827,\"start\":41823},{\"end\":41841,\"start\":41838},{\"end\":41849,\"start\":41847},{\"end\":42114,\"start\":42112},{\"end\":42120,\"start\":42116},{\"end\":42125,\"start\":42122},{\"end\":42133,\"start\":42129},{\"end\":42138,\"start\":42135},{\"end\":42287,\"start\":42281},{\"end\":42296,\"start\":42291},{\"end\":42302,\"start\":42298},{\"end\":42591,\"start\":42588},{\"end\":42599,\"start\":42597},{\"end\":42610,\"start\":42606},{\"end\":42623,\"start\":42621},{\"end\":42635,\"start\":42631},{\"end\":42908,\"start\":42905},{\"end\":42916,\"start\":42914},{\"end\":42928,\"start\":42924},{\"end\":43295,\"start\":43293},{\"end\":43310,\"start\":43306},{\"end\":43321,\"start\":43319},{\"end\":43331,\"start\":43327},{\"end\":43343,\"start\":43333},{\"end\":43699,\"start\":43692},{\"end\":43709,\"start\":43705},{\"end\":43723,\"start\":43716},{\"end\":43737,\"start\":43733},{\"end\":44000,\"start\":43993},{\"end\":44016,\"start\":44007},{\"end\":44026,\"start\":44022},{\"end\":44042,\"start\":44035},{\"end\":44053,\"start\":44049},{\"end\":44738,\"start\":44733},{\"end\":44747,\"start\":44742},{\"end\":44751,\"start\":44749},{\"end\":44759,\"start\":44755},{\"end\":44769,\"start\":44761},{\"end\":45118,\"start\":45112},{\"end\":45143,\"start\":45130},{\"end\":45157,\"start\":45150},{\"end\":45178,\"start\":45164},{\"end\":45454,\"start\":45447},{\"end\":45470,\"start\":45460},{\"end\":45485,\"start\":45476},{\"end\":45497,\"start\":45494},{\"end\":45864,\"start\":45861},{\"end\":45870,\"start\":45868},{\"end\":45877,\"start\":45874},{\"end\":46107,\"start\":46097},{\"end\":46378,\"start\":46374},{\"end\":46386,\"start\":46382},{\"end\":46395,\"start\":46390},{\"end\":46579,\"start\":46573},{\"end\":46819,\"start\":46817},{\"end\":46832,\"start\":46828},{\"end\":46849,\"start\":46841},{\"end\":47128,\"start\":47126},{\"end\":47143,\"start\":47139},{\"end\":47157,\"start\":47152},{\"end\":47174,\"start\":47171},{\"end\":47186,\"start\":47181},{\"end\":47723,\"start\":47720},{\"end\":47740,\"start\":47735},{\"end\":47757,\"start\":47750},{\"end\":48062,\"start\":48059},{\"end\":48079,\"start\":48072},{\"end\":48091,\"start\":48086},{\"end\":48103,\"start\":48099},{\"end\":48423,\"start\":48419},{\"end\":48432,\"start\":48427},{\"end\":48441,\"start\":48436},{\"end\":48450,\"start\":48445},{\"end\":48677,\"start\":48672},{\"end\":48687,\"start\":48683},{\"end\":48695,\"start\":48691},{\"end\":48702,\"start\":48699},{\"end\":48708,\"start\":48706},{\"end\":48936,\"start\":48931},{\"end\":48943,\"start\":48940},{\"end\":48949,\"start\":48947},{\"end\":48957,\"start\":48953},{\"end\":48965,\"start\":48961},{\"end\":48973,\"start\":48969},{\"end\":48981,\"start\":48977},{\"end\":48988,\"start\":48985}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.1145/1148170.1148177\",\"id\":\"b0\",\"matched_paper_id\":58534973},\"end\":36318,\"start\":35578},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":3221714},\"end\":36609,\"start\":36320},{\"attributes\":{\"id\":\"b2\"},\"end\":36906,\"start\":36611},{\"attributes\":{\"id\":\"b3\"},\"end\":37095,\"start\":36908},{\"attributes\":{\"doi\":\"CoRR abs/1511.05960\",\"id\":\"b4\"},\"end\":37510,\"start\":37097},{\"attributes\":{\"doi\":\"CoRR abs/1409.1259\",\"id\":\"b5\"},\"end\":37893,\"start\":37512},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":207240067},\"end\":38259,\"start\":37895},{\"attributes\":{\"id\":\"b7\"},\"end\":38525,\"start\":38261},{\"attributes\":{\"doi\":\"10.1145/963770.963776\",\"id\":\"b8\",\"matched_paper_id\":207650042},\"end\":38827,\"start\":38527},{\"attributes\":{\"id\":\"b9\"},\"end\":39094,\"start\":38829},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":1723648},\"end\":39555,\"start\":39096},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":14604122},\"end\":39854,\"start\":39557},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":16547564},\"end\":40106,\"start\":39856},{\"attributes\":{\"id\":\"b13\"},\"end\":40358,\"start\":40108},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":8264369},\"end\":40843,\"start\":40360},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":1915014},\"end\":41025,\"start\":40845},{\"attributes\":{\"id\":\"b16\"},\"end\":41172,\"start\":41027},{\"attributes\":{\"doi\":\"10.1145/2556195.2556220\",\"id\":\"b17\",\"matched_paper_id\":1454605},\"end\":41792,\"start\":41174},{\"attributes\":{\"id\":\"b18\"},\"end\":42030,\"start\":41794},{\"attributes\":{\"id\":\"b19\"},\"end\":42277,\"start\":42032},{\"attributes\":{\"id\":\"b20\"},\"end\":42540,\"start\":42279},{\"attributes\":{\"doi\":\"CoRR abs/1609.05787\",\"id\":\"b21\"},\"end\":42823,\"start\":42542},{\"attributes\":{\"doi\":\"10.1109/TKDE.2017.2661760\",\"id\":\"b22\",\"matched_paper_id\":14093453},\"end\":43218,\"start\":42825},{\"attributes\":{\"doi\":\"10.14778/2733085.2733086\",\"id\":\"b23\",\"matched_paper_id\":3485119},\"end\":43622,\"start\":43220},{\"attributes\":{\"doi\":\"CoRR abs/1301.3781\",\"id\":\"b24\"},\"end\":43908,\"start\":43624},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":16447573},\"end\":44655,\"start\":43910},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":7605591},\"end\":45043,\"start\":44657},{\"attributes\":{\"id\":\"b27\"},\"end\":45392,\"start\":45045},{\"attributes\":{\"doi\":\"10.1007/978-3-540-72079-9_9\",\"id\":\"b28\"},\"end\":45785,\"start\":45394},{\"attributes\":{\"id\":\"b29\"},\"end\":46001,\"start\":45787},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":1174745},\"end\":46317,\"start\":46003},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":4833213},\"end\":46506,\"start\":46319},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":18470994},\"end\":46712,\"start\":46508},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":6643251},\"end\":47072,\"start\":46714},{\"attributes\":{\"doi\":\"10.1145/2645710.2645724\",\"id\":\"b34\",\"matched_paper_id\":17424127},\"end\":47638,\"start\":47074},{\"attributes\":{\"doi\":\"CoRR abs/1602.04341\",\"id\":\"b35\"},\"end\":47968,\"start\":47640},{\"attributes\":{\"doi\":\"CoRR abs/1512.05193\",\"id\":\"b36\"},\"end\":48328,\"start\":47970},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":17159318},\"end\":48604,\"start\":48330},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":7062707},\"end\":48846,\"start\":48606},{\"attributes\":{\"id\":\"b39\"},\"end\":49168,\"start\":48848}]", "bib_title": "[{\"end\":35649,\"start\":35578},{\"end\":36385,\"start\":36320},{\"end\":37943,\"start\":37895},{\"end\":38569,\"start\":38527},{\"end\":39159,\"start\":39096},{\"end\":39621,\"start\":39557},{\"end\":39942,\"start\":39856},{\"end\":40454,\"start\":40360},{\"end\":40867,\"start\":40845},{\"end\":41229,\"start\":41174},{\"end\":42897,\"start\":42825},{\"end\":43287,\"start\":43220},{\"end\":43985,\"start\":43910},{\"end\":44731,\"start\":44657},{\"end\":46093,\"start\":46003},{\"end\":46370,\"start\":46319},{\"end\":46567,\"start\":46508},{\"end\":46807,\"start\":46714},{\"end\":47119,\"start\":47074},{\"end\":48415,\"start\":48330},{\"end\":48668,\"start\":48606}]", "bib_author": "[{\"end\":35669,\"start\":35651},{\"end\":35681,\"start\":35669},{\"end\":35695,\"start\":35681},{\"end\":36402,\"start\":36387},{\"end\":36417,\"start\":36402},{\"end\":36621,\"start\":36611},{\"end\":36633,\"start\":36621},{\"end\":36645,\"start\":36633},{\"end\":36919,\"start\":36908},{\"end\":36932,\"start\":36919},{\"end\":36945,\"start\":36932},{\"end\":36955,\"start\":36945},{\"end\":37195,\"start\":37185},{\"end\":37207,\"start\":37195},{\"end\":37225,\"start\":37207},{\"end\":37238,\"start\":37225},{\"end\":37246,\"start\":37238},{\"end\":37259,\"start\":37246},{\"end\":37604,\"start\":37589},{\"end\":37634,\"start\":37604},{\"end\":37651,\"start\":37634},{\"end\":37659,\"start\":37651},{\"end\":37958,\"start\":37945},{\"end\":37967,\"start\":37958},{\"end\":37977,\"start\":37967},{\"end\":38278,\"start\":38261},{\"end\":38292,\"start\":38278},{\"end\":38308,\"start\":38292},{\"end\":38589,\"start\":38571},{\"end\":38605,\"start\":38589},{\"end\":38934,\"start\":38923},{\"end\":38942,\"start\":38934},{\"end\":38948,\"start\":38942},{\"end\":39172,\"start\":39161},{\"end\":39184,\"start\":39172},{\"end\":39194,\"start\":39184},{\"end\":39636,\"start\":39623},{\"end\":39649,\"start\":39636},{\"end\":39662,\"start\":39649},{\"end\":39952,\"start\":39944},{\"end\":39959,\"start\":39952},{\"end\":39966,\"start\":39959},{\"end\":40118,\"start\":40108},{\"end\":40133,\"start\":40118},{\"end\":40146,\"start\":40133},{\"end\":40154,\"start\":40146},{\"end\":40466,\"start\":40456},{\"end\":40478,\"start\":40466},{\"end\":40493,\"start\":40478},{\"end\":40501,\"start\":40493},{\"end\":40883,\"start\":40869},{\"end\":40898,\"start\":40883},{\"end\":41039,\"start\":41029},{\"end\":41058,\"start\":41039},{\"end\":41244,\"start\":41231},{\"end\":41258,\"start\":41244},{\"end\":41272,\"start\":41258},{\"end\":41286,\"start\":41272},{\"end\":41803,\"start\":41794},{\"end\":41816,\"start\":41803},{\"end\":41829,\"start\":41816},{\"end\":41843,\"start\":41829},{\"end\":41851,\"start\":41843},{\"end\":42116,\"start\":42110},{\"end\":42122,\"start\":42116},{\"end\":42127,\"start\":42122},{\"end\":42135,\"start\":42127},{\"end\":42140,\"start\":42135},{\"end\":42289,\"start\":42279},{\"end\":42298,\"start\":42289},{\"end\":42304,\"start\":42298},{\"end\":42593,\"start\":42582},{\"end\":42601,\"start\":42593},{\"end\":42612,\"start\":42601},{\"end\":42625,\"start\":42612},{\"end\":42637,\"start\":42625},{\"end\":42910,\"start\":42899},{\"end\":42918,\"start\":42910},{\"end\":42930,\"start\":42918},{\"end\":43297,\"start\":43289},{\"end\":43312,\"start\":43297},{\"end\":43323,\"start\":43312},{\"end\":43333,\"start\":43323},{\"end\":43345,\"start\":43333},{\"end\":43701,\"start\":43686},{\"end\":43711,\"start\":43701},{\"end\":43725,\"start\":43711},{\"end\":43739,\"start\":43725},{\"end\":44002,\"start\":43987},{\"end\":44018,\"start\":44002},{\"end\":44028,\"start\":44018},{\"end\":44044,\"start\":44028},{\"end\":44055,\"start\":44044},{\"end\":44740,\"start\":44733},{\"end\":44749,\"start\":44740},{\"end\":44753,\"start\":44749},{\"end\":44761,\"start\":44753},{\"end\":44771,\"start\":44761},{\"end\":45120,\"start\":45104},{\"end\":45145,\"start\":45120},{\"end\":45159,\"start\":45145},{\"end\":45180,\"start\":45159},{\"end\":45443,\"start\":45439},{\"end\":45456,\"start\":45443},{\"end\":45472,\"start\":45456},{\"end\":45487,\"start\":45472},{\"end\":45499,\"start\":45487},{\"end\":45866,\"start\":45857},{\"end\":45872,\"start\":45866},{\"end\":45879,\"start\":45872},{\"end\":46109,\"start\":46095},{\"end\":46380,\"start\":46372},{\"end\":46388,\"start\":46380},{\"end\":46397,\"start\":46388},{\"end\":46581,\"start\":46569},{\"end\":46821,\"start\":46809},{\"end\":46834,\"start\":46821},{\"end\":46851,\"start\":46834},{\"end\":47130,\"start\":47121},{\"end\":47145,\"start\":47130},{\"end\":47159,\"start\":47145},{\"end\":47176,\"start\":47159},{\"end\":47188,\"start\":47176},{\"end\":47725,\"start\":47712},{\"end\":47742,\"start\":47725},{\"end\":47759,\"start\":47742},{\"end\":48064,\"start\":48051},{\"end\":48081,\"start\":48064},{\"end\":48093,\"start\":48081},{\"end\":48105,\"start\":48093},{\"end\":48425,\"start\":48417},{\"end\":48434,\"start\":48425},{\"end\":48443,\"start\":48434},{\"end\":48452,\"start\":48443},{\"end\":48679,\"start\":48670},{\"end\":48689,\"start\":48679},{\"end\":48697,\"start\":48689},{\"end\":48704,\"start\":48697},{\"end\":48710,\"start\":48704},{\"end\":48938,\"start\":48929},{\"end\":48945,\"start\":48938},{\"end\":48951,\"start\":48945},{\"end\":48959,\"start\":48951},{\"end\":48967,\"start\":48959},{\"end\":48975,\"start\":48967},{\"end\":48983,\"start\":48975},{\"end\":48990,\"start\":48983}]", "bib_venue": "[{\"end\":35982,\"start\":35850},{\"end\":38086,\"start\":38040},{\"end\":39349,\"start\":39280},{\"end\":40610,\"start\":40564},{\"end\":41497,\"start\":41403},{\"end\":43397,\"start\":43387},{\"end\":47361,\"start\":47286},{\"end\":35848,\"start\":35718},{\"end\":36452,\"start\":36417},{\"end\":36747,\"start\":36645},{\"end\":36984,\"start\":36955},{\"end\":37183,\"start\":37097},{\"end\":37587,\"start\":37512},{\"end\":38038,\"start\":37977},{\"end\":38383,\"start\":38308},{\"end\":38646,\"start\":38626},{\"end\":38921,\"start\":38829},{\"end\":39278,\"start\":39194},{\"end\":39685,\"start\":39662},{\"end\":39969,\"start\":39966},{\"end\":40220,\"start\":40154},{\"end\":40562,\"start\":40501},{\"end\":40916,\"start\":40898},{\"end\":41091,\"start\":41058},{\"end\":41401,\"start\":41309},{\"end\":41902,\"start\":41851},{\"end\":42108,\"start\":42032},{\"end\":42388,\"start\":42304},{\"end\":42580,\"start\":42542},{\"end\":42989,\"start\":42955},{\"end\":43385,\"start\":43369},{\"end\":43684,\"start\":43624},{\"end\":44104,\"start\":44055},{\"end\":44838,\"start\":44771},{\"end\":45102,\"start\":45045},{\"end\":45437,\"start\":45394},{\"end\":45855,\"start\":45787},{\"end\":46146,\"start\":46109},{\"end\":46400,\"start\":46397},{\"end\":46591,\"start\":46581},{\"end\":46875,\"start\":46851},{\"end\":47284,\"start\":47211},{\"end\":47710,\"start\":47640},{\"end\":48049,\"start\":47970},{\"end\":48455,\"start\":48452},{\"end\":48713,\"start\":48710},{\"end\":48927,\"start\":48848}]"}}}, "year": 2023, "month": 12, "day": 17}