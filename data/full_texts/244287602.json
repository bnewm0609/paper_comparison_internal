{"id": 244287602, "updated": "2022-05-15 04:46:51.811", "metadata": {"title": "Beyond Relevance Ranking: A General Graph Matching Framework for Utility-Oriented Learning to Rank", "authors": "[{\"first\":\"Xinyi\",\"last\":\"Dai\",\"middle\":[]},{\"first\":\"Yunjia\",\"last\":\"Xi\",\"middle\":[]},{\"first\":\"Weinan\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Qing\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Ruiming\",\"last\":\"Tang\",\"middle\":[]},{\"first\":\"Xiuqiang\",\"last\":\"He\",\"middle\":[]},{\"first\":\"Jiawei\",\"last\":\"Hou\",\"middle\":[]},{\"first\":\"Jun\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Yong\",\"last\":\"Yu\",\"middle\":[]}]", "venue": "ACM Transactions on Information Systems", "journal": "ACM Transactions on Information Systems (TOIS)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Learning to rank from logged user feedback, such as clicks or purchases, is a central component of many real-world information systems. Different from human-annotated relevance labels, the user feedback is always noisy and biased. Many existing learning to rank methods infer the underlying relevance of query\u2013item pairs based on different assumptions of examination, and still optimize a relevance based objective. Such methods rely heavily on the correct estimation of examination, which is often difficult to achieve in practice. In this work, we propose a general framework U-rank+ for learning to rank with logged user feedback from the perspective of graph matching. We systematically analyze the biases in user feedback, including examination bias and selection bias. Then, we take both biases into consideration for unbiased utility estimation that directly based on user feedback, instead of relevance. In order to maximize the estimated utility in an efficient manner, we design two different solvers based on Sinkhorn and LambdaLoss for U-rank+. The former is based on a standard graph matching algorithm, and the latter is inspired by the traditional method of learning to rank. Both of the algorithms have good theoretical properties to optimize the unbiased utility objective while the latter is proved to be empirically more effective and efficient in practice. Our framework U-rank+ can deal with a general utility function and can be used in a widespread of applications including web search, recommendation, and online advertising. Semi-synthetic experiments on three benchmark learning to rank datasets demonstrate the effectiveness of U-rank+. Furthermore, our proposed framework has been deployed on two different scenarios of a mainstream App store, where the online A/B testing shows that U-rank+ achieves an average improvement of 19.2% on click-through rate and 20.8% improvement on conversion rate in recommendation scenario, and 5.12% on platform revenue in online advertising scenario over the production baselines.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tois/DaiX0LTHH0022", "doi": "10.1145/3464303"}}, "content": {"source": {"pdf_hash": "efcf9d3e27283c4e4a9feb2be36a4cc28fe832f2", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "dfe1ec15df44a82ccaf2aa6ba47f66ff09aac468", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/efcf9d3e27283c4e4a9feb2be36a4cc28fe832f2.txt", "contents": "\nBeyond Relevance Ranking: A General Graph Matching Framework for Utility-Oriented Learning to Rank ACM Reference format\nArticle 25\n\nXinyi Dai \nYunjia Xi \nWeinan Zhang \nShanghai Jiao \nTong University \nQing Liu \nRuiming Tang \nXiuqiang He hexiuqiang1@huawei.com \nHuawei Noah&apos;s Ark Lab \nJiawei Hou \nShanghai Jiao \nTong University \nYong Yu \nWeinan Zhang \nX Dai \nY Xi \nW Zhang \nJ Hou \nY Yu \nShanghai \nXinyi Dai \nYunjia Xi \nWeinan Zhang \nQing Liu \nRuiming Tang \nXiuqiang He \nJiawei Hou \nJun Wang jun.wang@cs.ucl.ac.uk. \nYong Yu \n\nJUN WANG\nUniversity College London\nShanghai Jiao Tong University\nJiao Tong University\n200240ShanghaiChina\n\n\nUniversity College London\nWC1E 6BTLondonUK\n\nBeyond Relevance Ranking: A General Graph Matching Framework for Utility-Oriented Learning to Rank ACM Reference format\n\nACM Transactions on Information Systems\n402Article 2510.1145/3464303Publication date: November 2021.25 Authors' addresses: 25:2 X. Dai et al. 2021. Beyond Relevance Ranking: A General Graph Matching Framework for Utility-Oriented Learning to Rank. ACM Trans. Inf. Syst. 40, 2, Article 25 (November 2021), 29 pages.CCS Concepts: \u2022 Information systems \u2192 Learning to rankAdditional Key Words and Phrases: Learning to rank, utility maximization, graph matching, implicit feedback, position bias, examination bias, selection biascnQ Liu, R Tang, and X He, Huawei Noah's Ark Lab, Longgang district, Shenzhen 518129, Chinaemails: {liuqing48, tangruiming,\nLearning to rank from logged user feedback, such as clicks or purchases, is a central component of many realworld information systems. Different from human-annotated relevance labels, the user feedback is always noisy and biased. Many existing learning to rank methods infer the underlying relevance of query-item pairs based on different assumptions of examination, and still optimize a relevance based objective. Such methods rely heavily on the correct estimation of examination, which is often difficult to achieve in practice. In this work, we propose a general framework U-rank+ for learning to rank with logged user feedback from the perspective of graph matching. We systematically analyze the biases in user feedback, including examination bias and selection bias. Then, we take both biases into consideration for unbiased utility estimation that directly based on user feedback, instead of relevance. In order to maximize the estimated utility in an efficient manner, we design two different solvers based on Sinkhorn and LambdaLoss for U-rank+. The former is based on a standard graph matching algorithm, and the latter is inspired by the traditional method of learning to rank. Both of the algorithms have good theoretical properties to optimize the unbiased utility objective while the latter is proved to be empirically more effective and efficient in practice. Our framework U-rank+ can deal with a general utility function and can be used in a widespread of applications including web search, recommendation, and online advertising. Semi-synthetic experiments on three benchmark learning to rank datasets demonstrate the effectiveness of U-rank+. Furthermore, our proposed framework has been deployed on two different scenarios of a mainstream App store, where the online A/B testing shows that U-rank+ achieves an average improvement of 19.2% on click-through rate and 20.8% improvement on conversion rate in recommendation scenario, and 5.12% on platform revenue in online advertising scenario over the production baselines.\n\nrefers to selection bias which is caused by the historical ranking function previously deployed in the system. The historical ranking function tends to place certain items at top positions, leading to Missing-Not-At-Random (MNAR) of the collected training data. All these biases together bring challenges in deriving an unbiased utility objective based on implicit feedback. 2 Based on all of these considerations, we present a general graph matching framework that optimizes a target ranking metric directly based on implicit feedback. We formulate the ranking problem as a maximum-weight matching problem on an item-position bipartite graph as denoted in Figure 1, where the weight on an edge between an item and a position denotes the utility of placing the item at this position. We define the utility as the product of the item's CTR at this position and the benefit if the item is clicked, where the benefit takes different definitions in various scenarios, e.g., the bid price of each ad in sponsor search [55,56], the watch time of each video in video recommendation [15].\n\nThen, the maximization of utility can be achieved by solving the maximum-weight matching on the item-position bipartite graph. We divide our method into two steps: Firstly, we obtain the weight of each edge on the bipartite graph with a position-aware deep CTR model, which manages to capture the click-position dependency considering both item attributes and user context and thus models position bias and attention bias as a whole. Besides, we learn a propensity model in advance to correct selection bias in the logging data. Secondly, to solve the maximum-weight matching on the graph with learned weights, i.e., maximizing the expected utility, we incorporate two different types of solvers into our framework, namely Sinkhorn and LambdaLoss. Sinkhorn algorithm [2] learns a Doubly-Stochastic Matrices (DSM)-based ranking function and optimizes the expected utility in an end-to-end manner. LambdaLoss [50] solves the matching problem by learning a scoring function, which can reduce the complexity in inference stage from O (N 3 ) to O (N ), where N denotes the maximum size of the ranked list. Both of the algorithms have good theoretical properties and the latter is empirically proved to be more effective in practice.\n\nIn this graph matching framework, we can deal with general utility maximization ranking problems for different application scenarios, including web search, recommendation, and online advertising. We conduct semi-synthetic experiments based on three benchmark datasets for learning to rank, where we demonstrate the superiority of our proposed framework over state-of-the-art unbiased learning to rank baselines in utility based metrics like CTR. Furthermore, we deploy our method on two different application scenarios (i.e., recommendation and online advertising) of a 25:4 X. Dai et al. mainstream App store, where the superiority of our proposed method is validated in industrial applications on online metrics like CTR, CVR, and platform revenue.\n\nThe main contributions of this article are as follows:\n\n-We propose a novel framework for learning to rank with implicit feedback, namely, U-rank+, which formulates the ranking problem as finding the maximum-weight matching on an item-position bipartite graph. Instead of optimizing a relevance-based ranking metric, we optimize for a utility metric that directly based on clicks themselves. This framework deals with a general utility function and can be used in a widespread of application scenarios including web search, recommendation, and online advertising. -To obtain an unbiased utility estimation, we estimate the utility of placing each item at each position with a position-aware deep CTR model, in which we take examination bias and selection bias into consideration. To the best of our knowledge, this is the first work that addresses the above-mentioned biases together in a unified framework for utility-oriented learning to rank. To optimize the estimated utility metric directly, we incorporate two different solvers into the framework, i.e., Sinkhorn and LambdaLoss, providing new paths for learning to rank with implicit feedback from different views. -Semi-synthetic experiments on three real-world benchmark datasets have demonstrated the effectiveness of U-rank+. Furthermore, U-rank+ has been deployed on two different scenarios of a mainstream App store, and in our online A/B testing, U-rank+ achieves an average improvement of 19.2% on CTR and 20.8% improvement on CVR in recommendation scenario, and 5.12% on platform revenue in online advertising scenario over the production baselines.\n\n\nRELATED WORK 2.1 Click Models\n\nImplicit feedback like click data is biased according to the observations in [25,26]. Generative click models are introduced to study user browsing behavior and extract unbiased relevance estimation from click data. For example, Position Based model (PBM) [41] assumes that a click only depends on the position and the relevance of the document. Cascade model [13] assumes that users browse a search web page sequentially from top to bottom, until a relevant document is found. Following these two classical click models, more sophisticated approaches, e.g., User Browsing Model (UBM) [16], Dynamic Bayesian Network (DBN) [11], Click Chain Model (CCM) [18] have been proposed. The most recent model, Neural Click Model [7] utilizes recurrent neural networks and vector representations of users to predict user behavior. However, click models usually require same query-document pair to appear multiple times for reliable estimation [33], thus invalid for tail queries and for personalized information systems.\n\n\nCounterfactual Learning to Rank\n\nRecently, a new line of research, referred to as counterfactual learning to rank, utilizes inverse propensity weighting (IPW) to address position bias in a learning to rank framework. Wang et al. [48] and Joachims et al. [27] proposed IPW-based methods of debiasing click data in a learning to rank framework. In both works, the propensity estimation relies on randomizing search results displayed to users, which obviously degrades users' search experience. Considering this, Agarwal et al. [3] proposed PBM to estimate propensity without Intrusive Interventions. Contextual Position-Based Model (CPBM) [17], on the basis of PBM, learns a query-dependent propensity estimation. However, multiple rankers are required to learn, which makes them inconvenient to deploy in real-world applications. Besides, another category of unbiased learning to rank works jointly learn the propensity model with a relevance model, which results in a biased estimation of U-Rank+ 25:5\n\npropensity unless the relevance estimation is very accurate. Wang et al. [49] proposed a regressionbased EM algorithm to estimate the propensity by maximizing the likelihood of click data. Ai et al. [4] proposed a dual learning algorithm (DLA) that jointly learns the propensity estimation and an unbiased ranker. Hu et al. [22] also proposed to jointly learn the propensity estimation and an unbiased ranker where the propensity at the click and non-click positions are both estimated.\n\nIn this work, we derive a ranking objective that directly based on clicks instead of relevance. A click-based objective does not require an accurate estimation of examination bias/propensity, which is hard to achieve in practice, and is also more aligned with online metrics like CTR, CVR, and so on. Besides, most of the existing works assume examination bias only depend on positions (except CPBM), we can deal with a more complicated examination bias that depends on user contexts and item contributes with a position-aware deep CTR model.\n\nOosterhuis and de Rijke [38] focused on the item selection bias in top-k items of a ranking, which is defined as the missing feedback caused by the selection of only k items to display by the historical ranking policy. In their work, the examination bias is known beforehand. We also use the term selection bias, which is commonly used to refer to the bias caused by collecting data in a non-uniform ranking policy [21], but there is clear difference with the item selection bias in [38] which only appears in top-k rankings. In this work, selection bias refers to the over-estimation of examination bias caused by the historical ranking policy when we estimate it from the click logs.\n\n\nOnline Learning to Rank\n\nThe central idea of OLTR is to optimize the ranking model interactively from user clicks. DBGD based algorithms are commonly used in OLTR. The original DBGD algorithm proposed by Yue and Joachims [52] randomly perturbs parameters and updates models toward perturbed parameters that produces ranked lists with more clicks. Extensive researches extend DBGD with different exploration strategies [37,44,46] and variance reduction techniques [45]. Schuth et al. [44] propose Mutileave Gradient Descent (MGD) based on DBGD by sampling multiple perturbed parameters each time to accelerate convergence. Null Space Gradient Descent (NSGD) proposed by Wang et al. [46] reduces the exploration space to the null space of recent poorly-performed gradients. Oosterhuis and de Rijke [37] propose Pairwise Differentiable Gradient Descent (PDGD) which estimates unbiased gradients based on pairwise preference from user clicks instead of interleaving or multileaving experiments. Wang et al. [45] reduce the variance of DBGD by projecting the estimated gradients into a document space spanned by the feature vectors of examined documents under current query. OLTR methods cannot be directly used in offline setting since they require the ranked list to be dynamically sampled according to the ranking model while the ranked list in offline data is fixed. Instead, our proposed method can work under pure offline settings and does not require a direct interaction with users, which might damage their user experience.\n\n\nPROBLEM FORMULATION AND PRELIMINARIES 3.1 Problem Formulation\n\nWhen a user issues a new query q, the system delivers a ranked list\n( f i , b i ) n q i=1\nof n q items to the user according to a ranking model over all the candidate items. The feature vector f i of each item i consists of item features, context features, and user/query features. 3 The scalar b i denotes the benefit brought to the system if item i is clicked, e.g., the watch time of each video in video recommendation, or the bid price of each ad in sponsored search. Let F , B, and K be the random variables for item feature, benefit, and position, respectively. Let C and O denote the random 25:6 X. Dai et al. variable for click and examination, respectively. We use k i to denote the position that item i is assigned to by the current ranking model. To represent the observed clicks of item i at different positions, for each query q, we introduce a square matrix C \u2208 {0, 1} n q \u00d7n q , where C i,k = 1/0 denotes click/non-click of item i at position k.\n\nThe users' click-through log is a set\nS = {( f i , k h i , b i , c i ) n q i=1 } q \u2208Q .\nBesides the item feature f i and benefit b i as mentioned above, k h i is the position of item i assigned by the historical ranking model, and c i is the users' click on item i when displaying it at position k h i in the logging data, i.e., c i = 1 for click and c i = 0 for non-click. We do not abuse different notations to represent position and click, as different notations are used to distinguish them under current ranking policy from those under historical ranking policy. More specifically, k i and C represent the position and click under current ranking policy, while k h i and c i notate the corresponding information under the historical ranking policy.\n\nThe ultimate goal of this ranking system is to find the best permutation of candidate items for each query q to maximize the utility. The utility is defined as the expectation of weighted sum of clicks on the items in the ranking list, as shown in the following equation:\nU q = E \u23a1 \u23a2 \u23a2 \u23a2 \u23a2 \u23a3 n q i=1 C i,k i \u00b7 b i \u23a4 \u23a5 \u23a5 \u23a5 \u23a5 \u23a6 = n q i=1 P (C = 1|F = f i , K = k i ) \u00b7 b i ,(1)\nwhere P (C = 1|F = f i , K = k i ) is the probability of the item i being clicked if displayed at position k i . Maximizing utility U q is equivalent to solving a maximum-weight matching problem on the item-position bipartite graph, where P (C = 1|F = f i , K = k i ) \u00b7 b i is the weight of the edge between the item i and the position k i in the graph, as shown in Figure 1. In order to estimate P (C = 1|F = f i , K = k i ) accurately, we need to consider several biases in the click-through log.\n\n\nExamination Bias\n\nTo visualize the examination bias, we show CTR at different positions of different device types and of different Apps, respectively, in Figure 2. The data are collected from the random recommendation traffic of a mainstream App store. From Figure 2, we can draw two observations: (1) the CTR decreases as the presented position goes from top to bottom; and (2) the magnitude of the decreasing differs among different items and different device types. As supported by eye-tracking studies [30,31], the decrease of CTR w.r.t position is the effect of the decrease of user's attention. Most existing works only consider position bias, which is considered to be decorrelated with specific ranked items, i.e., making the same effect on all items. This assumption is generally correct in the traditional 10 blue links scenario. Under such an assumption, ranking by relevance in descending order leads to the highest expected utility. However, in real world applications, as indicated in the second observation, the users' examination does not only depend on positions but also on item attributes and user context. All of them will affect the accurate estimation of users' examination biases.\n\nIn web search, an example of item-specific examination bias is vertical bias, commonly observed when the web page contains multiple vertical search results (such as images, videos, maps, etc.). Metrikov et al. [35] found that an image in search results can raise CTR and flatten the CTR curve at the same time. This is consistent with our observation in the App recommendation scenario. A visually attractive content, such as an App with a fancy thumbnail, can attract users' attention even when it is placed at a lower position, which results in a flatter CTR curve. In other words, such visually attractive items are less sensitive to the position change.\n\nWhat is more, the item-specific examination biases lead to a different solution with the traditional relevance-based ranking. Consider a non-personalized case for simplicity that we recommend App 1, App 2, and App 3 in Figure 2 to one user. If the Apps are sorted by Probabilistic Ranking Principle (PRP) [42], the ranked list will be App 1, App 2, and App 3 by their relevance in terms of CTR. However, the optimal ranked list with the maximum utility should be App 1, App 3, and App 2, since the utility gain of promoting App 3 from the third to the second position is 0.196\u22120.177 = 0.019, which is larger than the utility loss 0.294\u22120.284 = 0.010 of dragging App 2 from the second to the third position. For two items with close relevance estimation, putting the item which is more sensitive to position change at a higher position will bring a higher expected utility, even if it is slightly less relevant.\n\nBased on the above considerations, a position-aware modeling of clicks, which takes item attributes and user context into consideration, is indispensable for the correct estimation of expected utility.\n\n\nSelection Bias\n\nAlthough we can attend to examination bias with the position-aware click modeling, we might tend to overestimate the severity of examination bias due to the non-uniform historical ranking policy. In other words, we might overestimate the click probability of items placed at top positions and underestimate the click probability of items placed at bottom positions.\n\nThe bias caused by collecting data from a non-uniform logging policy is often referred to as selection bias [21] or MNAR [29]. In the left panel of Figure 3, we show a simple example to illustrate the selection bias in a position-aware click model. Assume that we recommend two items to two individual users in the form of ranked lists (of two items). User 1 favors item 2 and user 2 favors item 1. The CTR of a user on a liked item at first position and second position are 0.7 and 0.6, respectively, while the CTR of a user on a disliked item at two positions are 0.2 and 0.1, respectively. In a real-world recommender system, a well-trained historical ranking policy will rank the liked item before the disliked one with a high probability. Assume that to user 1 for 90 times we present the ranked list to her in the order of (item 2, item 1) and only for 10 times we present her with (item 1, item 2). To user 2, we do just the opposite. We will find that in the biased click data the estimated CTR of the two items at position 1 and position 2 are 0.7\u00d790+0. The example shows that in a biased logging data, we tend to overestimate the click probability at top positions and underestimate the click probability at bottom positions. This is consistent with the real-world data analysis in the App recommendation scenario where we collect click data from the biased and random traffic, respectively. Here, the biased traffic is the normal traffic served by the production model while the random traffic is a small part of live traffic that we perform uniform ranking policy on. We estimate the CTR for item i at position k as CT R i,k . In order to present the difference of CT R i,k estimated from biased data and random traffic data, we compute \u03c1 i,k as shown in the following equation:\n\u03c1 i,k = log CT R i,k observed from biased traffic CT R i,k observed from random traffic .(2)\nThen, we plot points (k, \u03c1 i,k ) in the right panel of Figure 3. We can find that with the increase of position k, the CTR estimation of items gradually change from overestimation (\u03c1 > 0) to underestimation (\u03c1 \u2264 0). We only show the results of top-15 positions, since at lower positions we collect less data, which makes the CTR estimation unreliable.\n\nThe analysis of selection bias shows that we need to address the exaggerated position effect caused by non-uniform training data in position-aware click modeling.\n\n\nMETHOD\n\nIn this section, we present a general ranking framework to maximize the utility U q in Equation (1) directly. In Section 4.1, we estimate utility unbiasedly from click through logs. The examination bias and selection bias are addressed by a position-aware click model and a position propensity model as described in Sections 4.1.1 and 4.1.2. In Section 4.2, we design two different solvers, namely Sinkhorn (Section 4.2.1) and LambdaLoss (Section 4.2.2) to optimize this metric. The overall procedure of our ranking method is illustrated in Algorithm 1.\n\n\nUnbiased Estimation of the Ranking Metric\n\n\nPosition-Aware Click Estimation.\n\nThe main difficulty of learning to rank via implicit feedback lies in the estimation of examination, since we do not observe it directly from the data. With the new learning objective utility, we do not need to infer relevance or examination explicitly. Instead, we need to deal with the mismatch between the CTR of the historically presented position and that of the finally presented position. For example, if an item is ranked on the 1st position in the click logs but presented at the 10th position in the final ranking, then its utility is overestimated. To correct this bias, we need an accurate model of user's CTR on different positions.\n\nThe estimation of the position-aware click probability P (C = 1|F = f i , K = k i ) refers to one of the most well-studied tasks in recommender systems, i.e., the CTR prediction [39,53]. Some recent works [5,20] pointed out that position is a very important feature in CTR prediction. However, U-Rank+ 25:9\n\n\nALGORITHM 1: Graph Matching for Learning to Rank\nInput: Click through logs S = {( f i , b i , c i , k h i ) n q\ni } q \u2208Q , solver \u2208 {Sinkhorn, Lambdaloss} Output: A family of functions \u03a8, or a scoring function \u03a6 1 Step 1 \u2192 Unbiased position-aware click probability estimation; 2 for N 0 iterations do 3 Choose a batch of ( f i , k h i ) samples from S; 4 Update \u03c9 according to L p (\u03c9) in Equation (5);\n5 end 6 for N 1 iterations do 7 Choose a batch of ( f i , k h i , c i ) samples from S; 8\nUpdate \u03b8 according to L c (\u03b8 ) in Equation (8) and h \u03c9 (\u00b7, \u00b7); 9 end 10 Step 2 \u2192 Unbiased utility maximization; 11 if solver is Sinkhorn then 12 for N s iterations do 13 Choose a set (\nf i , b i ) n q i=1 from S; 14\nCompute the Pre-Sinkhorn matrix A n q according to Equation (9).;\n\n\n15\n\nCompute the DSM W n q via Sinkhorn layers according to Equation (11).; 16 Update the family of functions \u03a8 according to L s (\u03a8, q) in Equation (12) and \u0434 \u03b8 (\u00b7, \u00b7); 17 end 18 end 19 else // solver is Lambdaloss 20 for N r iterations do 21 Choose a batch of paired samples\n( f i , k h i , c i , f j , k h j , c j ) from S; 22\nCompute \u0394U til (i, j) of each pair according to Equation (18).;\n\n\n23\n\nUpdate the scoring function \u03a6 according to L r (\u03a6, q) in Equation (19) and \u0434 \u03b8 (\u00b7, \u00b7); 24 end 25 end in inference stage of the ranking model, the position feature is often vacant. Therefore, we use a position-aware click model to maintain an unbiased utility estimation instead of directly using it as a ranking model. Assume that the probability function of item i displayed at position k i , i.e.,\nP (C = 1|F = f i , K = k i ) is a function of item feature f i and position k i and we use \u0434 \u03b8 ( f i , k i ) to approximate it. \u0434 \u03b8 (\u00b7, \u00b7)\nis a neural network with a sigmoid activation as output activation to ensure the output value in the range of [0, 1]. Then, we can estimate the parameter \u03b8 via maximum likelihood estimation by minimizing the following loss:\nL c (\u03b8 ) = q \u2208Q n q i=1 l c i , \u0434 \u03b8 f i , k h i ,(3)\nwhere\nl (p, q) = \u2212p log q \u2212 (1 \u2212 p) log(1 \u2212 q)\nis the cross entropy loss.\n\n\nPositional Propensity Estimation.\n\nThis position-aware click model that we described above suffers from selection bias. From the perspective of domain adaptation [6], selection bias is caused by the distributional mismatch between source distribution P s (F , K ), i.e., the distribution of (F , K ) pair in the biased logging data and the target distribution P t (F , K ), i.e., the distribution 25:10 X. Dai et al.\n\nof (F , K ) pair of an unbiased click data. Consider the density function of (F , K ),\nP (F , K ) = P (F )P (K |F ),(4)\nwhere P (F ) denotes the distribution of item feature and P (K |F ) denotes the distribution of displayed positions of an item in the logging data conditioned on the item feature. We notice that P (F ) is consistent in source distribution and target distribution. However, P (K |F ), which is influenced by the historical ranking policy, shows inconsistency between source distribution and target distribution. P t (K |F ) is a uniform distribution, which means each item can be placed at each position with equal probability. However, P s (K |F ) is often influenced by the historical ranking policy, which results in a non-uniform distribution. We address the distribution mismatch with IPW. Firstly, we use a conditional propensity model h \u03c9 ( f i ), to estimate the position propensity 4 given item feature, i.e.,\nP s (K = k i |F = f i ), where h \u03c9 ( f i )\nis a neural network with a softmax layer as the output layer. It takes the item feature f i as input and outputs probabilities of this item to appear on different positions. The k i th output of\nh \u03c9 ( f i ) is denoted as h \u03c9 ( f i , k i ), and the loss function of h \u03c9 ( f i , k i ) is defined as L p (\u03c9) = \u2212 q \u2208Q n q i=1 log(h \u03c9 ( f i , k h i )).(5)\nNow, we rewrite the loss function to estimate the click probability of target distribution with the data from source distribution as\nL T (\u03b8 ) = K l C i,k i , \u0434 \u03b8 ( f i , k i ) P t (F = f i , K = k i )dF = K l C i,k i , \u0434 \u03b8 ( f i , k i ) P t (F = f i )P t (K = k i |F = f i )dF = K l C i,k i , \u0434 \u03b8 ( f i , k i ) P t (F = f i ) 1 n q dF = K 1 n q P s (K = k i |F = f i ) l C i,k i , \u0434 \u03b8 ( f i , k i ) P s (F = f i )P s (K = k i |F = f i )dF ,(6)\nwhere l is the cross entropy as shown in Equation (3). This loss can be estimated with sample average asL\nT (\u03b8 ) = q \u2208Q n q i=1 1 n q P s (K = k h i |F = f i ) l c i , \u0434 \u03b8 f i , k h i .(7)\nFinally, we can remove the selection bias and obtain the unbiased estimation of position-aware click model \u0434 \u03b8 ( f i , k i ), the unbiased loss function of which is defined as \nL uc (\u03b8 ) =L T (\u03b8 ) = q \u2208Q n q i=1 1 n q h \u03c9 ( f i , k h i ) l c i , \u0434 \u03b8 f i , k h i .(8)\n\nLearning to Optimize the Ranking Metric\n4.2.1\nSinkhorn. The Sinkhorn Algorithm [2] is an elegant method to solve the graph matching problem in an end-to-end differentiable way. One successful application for Sinkhorn algorithm is [43], which adopted it to solve image matching problem in a deep learning framework. According to the analysis in [34], Sinkhorn algorithm is an approximate and differential version of the Hungarian algorithm. Thus, it is a direct solution to the graph matching problem defined in Section 3.1.\n\nThe Sinkhorn algorithm shows that each non-negative square matrix can be converted to a DSM [34], which is a differentiable relaxation of permutation matrix [2]. Then, the matching objective can be computed with the DSM and thus be optimized in an end-to-end manner.\n\nThe target for the Sinkhorn solver is to learn a family of functions, \u03a8 = {\u03c8 n q : q \u2208 Q}. Each function in this family takes the features of items\n( f i , b i ) n q i=1\nas input and outputs a DSM W. Each column and each row in a DSM sums to 1. We define each function in the family as \u03c8 n q : (F , B) n q \u2192 W n q where (F , B) n q denotes the set of features associate with each of the n q documents, and W n q \u2208 [0, 1] n q \u00d7n q refers to the space of n q \u00d7 n q DSMs.\n\nThe process of the Sinkhorn solver is shown from line 11 to line 17 in Algorithm 1. Before we apply Sinkhorn layers, we need to construct a non-negative square matrix A \u2208 R n q \u00d7n q + from the item features ( f i , b i ) n q (see line 14 in Algorithm 1). We call this non-negative matrix as Pre-Sinkhorn matrix. To obtain the Pre-Sinkhorn matrix, we use another function \u03c6 :\n(F , B, K ) \u2192 R + . Specifically, \u03c6( f i , b i , k i )\nis a neural network which outputs a single value. Note that the activation function of last layer should be carefully chosen to ensure the non-negativity. Each element of the Pre-Sinkhorn matrix A is computed by\nA i,k = \u03c6( f i , b i , k ).(9)\nAfter that, the DSM W is obtained from the Pre-Sinkhorn matrix A by repeatedly normalizing rows and columns (see line 15 in Algorithm 1). Specifically, we defined the row and column normalization functions as\nT R (A) = A A11 T , T C (A) = A 11 T A ,(10)\nwhere is the elementwise division and 1 is a vector of ones. Then, the Sinkhorn layers are defined recursively as\nSinkhorn (l ) (A) = A if l = 0 T R T C Sinkhorn (l \u22121) (A) otherwise ,(11)\nwhere l denotes number of layers. The Sinkhorn Normalization is illustrated in Figure 4. As l increases, Sinkhorn (l ) (A) converges to DSM W. Each element in the DSM, for example, W i,k , denotes the probability of placing item i at position k according to the family of functions \u03a8. To maximize the expected utility, we can define the objective function w.r.t \u03a8 as\nL s (\u03a8, q) = \u2212 n q i=1 n q k=1 \u0434 \u03b8 ( f i , k ) \u00b7 b i \u00b7 W i,k .(12)\nWe prove that minimizing the loss defined in Equation (12) is equivalent to maximizing the expected utility in Section 4.3.1. We minimize this objective to update the parameters in \u03a8 (see line 16 in Algorithm 1). Then repeat the process until convergence and we obtain the optimal \u03a8. The most exciting part about Sinkhorn algorithm is that all of the operations in Equation (9), Equation (10), and Equation (11) are differentiable and can be optimized in an end-to-end manner.\n\nDuring testing, we have to apply Hungarian algorithm with cubic complexity [34] to the DSM W to obtain the permutation matrix S. Each permutation matrix corresponds to a ranking result with each row representing an item, each column representing a position, where each element in permutation matrix S is defined as\nS i,k = 1 k i = k 0 k i k .(13)\nHowever, the cubic complexity becomes a bottleneck in a real-world ranking system. Thus, in practice, according to [2], we can compute a global ordering according to the expected rank of each document as\nE W [k i ] = n q k=1 W i,k \u00b7 k,(14)\nsuch that Hungarian algorithm can be performed on top P < n q items instead of on all n q items to improve the inference efficiency. Thus, the complexity in inference stage is reduced to O (N 2 + P 3 ), where N is the maximum number of n q .\n\n\nLambdaLoss.\n\nAlthough we reduce the complexity of Sinkhorn as shown in Equation (14) from O (N 3 ) to O (N 2 + P 3 ), it is still too consuming for a real-world production system. In this section, we aim at learning a parameterized scoring function \u03a6(\u00b7) to approximate the maximumweight graph matching procedure on each query, still aiming at the maximization of the utility, so that the complexity in the inference stage can be reduced to O (N ).\n\nThe scoring function \u03a6(\u00b7) takes item feature and bid as inputs and outputs a ranking score s i : \u03a6 : (F , B) \u2192 R. The scoring function \u03a6(\u00b7) can be a neural network or a tree model. (Both of the implementations are proposed in the experiment section.) For each query q, we compute the score s i of each item i and the result list is generated by sorting their scores in descending order.\n\nTo elicit the objective for the scoring function, based on users' click through logs, we derive an unbiased metric of utility as\nU q = n q i=1 u (i, k i ),(15)\nwhere the utility u (i, k i ) of displaying item i at position k i is defined as\nu (i, k i ) = P (C = 1|F = f i , K = k i ) P (C = 1|F = f i , K = k h i ) \u00b7 c i \u00b7 b i = \u0434 \u03b8 ( f i , k i ) \u0434 \u03b8 f i , k h i \u00b7 c i \u00b7 b i .(16)\nThe reason that we choose U q instead of U q is its resemblance to existing ranking metrics. We will leave the detailed discussion of such resemblance in Section 4.4, in which we also show the U-Rank+ 25:13 unbiasedness of U q . With k * i being the optimal position assigned to item i, we define the regret of the utility as\nL r (\u03a6, q) = n q i=1 u (i, k * i ) \u2212 n q i=1 u (i, k i ),(17)\nwhich defines the objective of a ranking model. However, minimizing the regret of the utility L r (\u03a6, q) directly w.r.t the positions is infeasible since positions are discrete values. Therefore, we adapt the LambdaLoss framework [50] to learn a ranking model toward the optimal ranking by optimizing our proposed loss function (which will be presented in Equation (19)) with iterative pairwise permutation. Like in LambdaLoss, we follow an EM procedure where in E step we obtain the ranked list based on current scoring function \u03a6 (t ) and in M step we re-estimate the scoring function \u03a6 (t +1) to minimize our loss function. The learning procedure of our learning algorithm is as follows (see line 19 to line 25 in Algorithm 1). We first initialize the ranking model with a random initialization of \u03a6 (0) . Inspired by the reweighting technique used in LambdaRank [10], we compute the difference between the unbiased utility \u0394U til (i, j) when the positions of two items i and j are flipped (see line 22 in Algorithm 1),\nas \u0394U til (i, j) = u (i, k j ) + u (j, k i ) \u2212 u (i, k i ) \u2212 u (j, k j ).(18)\nThen, this difference value is used as the weight in the pairwise loss for each pair of items. Following [8,10], we design our loss function in the form of logistic loss, as\nL r (\u03a6, q) = n q i=1 j:k j <k i \u0394U til (i, j) log 2 1 + e \u2212\u03c3 (si \u2212s j ) ,(19)\nwhere k i and k j denote the position assigned to item i and j by ranking model at the last step (by the scoring function \u03a6 (t ) ). This loss is minimized, so that we get a new scoring function \u03a6 (t +1) (see line 23 in Algorithm 1). Then, we repeat the process until convergence. Notice that in a standard LambdaLoss framework, the LambdaLoss is defined as\nL \u03bb (\u03a6, q) = n q i=1 j:y i >y j |\u0394N DCG(i, j)| log 2 1 + e \u2212\u03c3 (si \u2212s j ) .(20)\nNote that the differences between our objective (19) and the LambdaLoss objective (20) lie in (1) the subscript of the summation symbol and (2) the absolute value symbol of the difference term \u0394. In LambdaLoss framework, the absolute value of the difference term is used and the subscript of the summation symbol is y i > y j . The pairwise label of each item pair (i, j) is determined. The optimal ranking order is known to us by ranking all the items according to relevance label or click label, (denoted by y i for item i), in descending order. However, in our framework, we cannot obtain an explicit label y i for item i. An item is treated as the positive item if it is placed at a lower position by scoring function \u03a6 (t ) and the exchange brings utility gain or it is placed at a higher position and the exchange introduces utility drop. We do not know the optimal ranking order in each query beforehand, where the optimal order is achieved through iterative pairwise permutation.\n\n\nTheoretical Analysis\n\n4.3.1 Sinkhorn. In this section, we theoretically prove that Sinkhorn algorithm maximizes the utility defined in Equation (1)  \u03a8 * n q : (F , B) n q \u2192 S n q , where S n q is the space of permutation matrices of dimension n q \u00d7 n q . To maximize the utility defined in Equation (1), the loss function w.r.t \u03a8 * is defined as\nL s (\u03a8 * , q) = \u2212U q = \u2212 n q i=1 P (C = 1|F = f i , K = k i ) \u00b7 b i = \u2212 n q i=1 n q k=1 S i,k P (C = 1|F = f i , K = k ) \u00b7 b i = \u2212 n q i=1 n q k=1 S i,k \u00b7 \u0434 \u03b8 ( f i , k ) \u00b7 b i .(21)\nThe loss L s (\u03a8 * , q) in Equation (21) is not differentiable w.r.t. S i,k . Thus, Sinkhorn considers the expectation of this loss, which is computed by the marginal probability of S i,k = 1, as follows:\nE \u03a8 * [L s (q)] = \u2212 n q i=1 n q k=1 \u0434 \u03b8 ( f i , k ) \u00b7 b i \u00b7 E \u03a8 * [S i,k ] = \u2212 n q i=1 n q k=1 \u0434 \u03b8 ( f i , k ) \u00b7 b i \u00b7 W i,k ,(22)\nwhich means optimizing the loss function for \u03a8 defined in Equation (12) is equivalent to optimizing the loss function for \u03a8 * defined in Equation (21), which is also equivalent to maximizing U q .\n\n\nLambdaLoss.\n\nIn this section, we theoretically prove that the training objective L r (\u03a6, q) is an upper bound of the utility regret L r (\u03a6, q). To make the proof easier to understand, we construct a function:\nL r (\u03a6, q) = n q i=1 j:s i <s j |u (i, k j ) \u2212 u (i, k i )|.(23)\nWe start with several lemmas which will be used in our proof.    Proof.\n(1 + e \u2212\u03c3 x ) where \u03c3 is a constant in R, it holds that f (x ) \u2264 \u0434(x ) for all x \u2208 R.x ) = max{log(1 + exp(\u03c3C)), 2} \u2212 log 2 (1 + e \u2212\u03c3 x ) where \u03c3 is a constant in R, it holds that f (x ) \u2264 \u0434(x ) for x \u2208 [\u2212C, C].(x ) = max i x i , it holds that f (x ) \u2265 \u0434(x ) for x i \u2265 0, \u2200i.L r (\u03a6, q) = n q i=1 n q j=1 |u (i, k j ) \u2212 u (i, k i )|I(s i < s j ) = n q i=1 j:k j <k i (u (i, k j ) \u2212 u (i, k i ))I(s i < s j ) + n q i=1 j:k j >k i (u (i, k i ) \u2212 u (i, k j ))I(s i < s j ) = n q i=1 j:k j <k i (u (i, k j ) \u2212 u (i, k i ))I(s i < s j ) + n q j=1 i:k i >k j (u (j, k j ) \u2212 u (j, k i ))I(s j < s i ) \u2264 n q i=1 j:k j <k i (u (i, k j ) \u2212 u (i, k i )) log 2 1 + e \u2212\u03c3 (si \u2212s j ) \u2212 n q i=1 j:k j <k i (u (j, k j ) \u2212 u (j, k i ))[log 2 1 + e \u2212\u03c3 (si \u2212s j ) + C 1 ] = n q i=1 j:k j <k i (u (i, k j ) \u2212 u (i, k i ) \u2212 u (j, k j ) + u (j, k i )) log 2 (1 + e \u2212\u03c3 (si \u2212s j ) ) + C 2 = n q i=1 j:k j <k i \u0394U til (i, j) log 2 1 + e \u2212\u03c3 (si \u2212s j ) + C 2 ,(24)= L r (\u03a6, q) + C 2 .(25)\nwhere the inequality holds due to Lemma 4.1 and Lemma 4.2.\n\nTheorem 4.4 states that L r (\u03a6, q) is upper bounded by our objective L r (\u03a6, q) plus C 2 . C 2 is a constant since in the M step C 2 only depends on the current scoring function \u03a6 (t ) . Notice that the assumptions in the theorem are not restrictive in practice. As illustrated in Figure 2, the real utility basically satisfies the monotonic decreasing assumption. Moreover, the ranking score is often clipped in implementation to avoid explosion in exponential function. Proof.\nL r (\u03a6, q) = n q i=1 j:s i <s j |u (i, k j ) \u2212 u (i, k i )| = n q i=1 k i \u22121 k=1 |u (i, k ) \u2212 u (i, k i )| = n q i=1 k i \u22121 k=1 (u (i, k ) \u2212 u (i, k i )) \u2265 n q i=1 u (i, 1) \u2212 n q i=1 u (i, k i ) \u2265 n q i=1 u (i, k * i ) \u2212 n q i=1 u (i, k i ) = L r (\u03a6, q),(26)\nwhere the first inequality holds due to Lemma 4.3.  The proof of Theorem 4.6 is trivial due to Theorem 4.4 and Theorem 4.5. Theorem 4.6 demonstrates that the utility regret L r (\u03a6, q) is bounded by our proposed objective L r (\u03a6, q) plus a constant. It implies that optimizing our proposed objective is actually minimizing the upper bound of the utility regret, which guarantees the effectiveness of our ranking algorithm theoretically.\n\n\nRelations to Previous Works\n\nMany existing relevance based ranking metrics [54] approximate the utility in Equation (1) by the inner product of a relevance vector J and a rank discount vector D. For simplicity, a binary relevance label, r i \u2208 {0, 1} is typically considered. Then, the mainstream relevance based metric/objective function is in the following form:\nMetric = n q i=1 D i \u00b7 r i ,(27)\nwhere the discount factor D i is normally a decreasing function of position k i (note that no item features are considered), indicating users' decreasing attention from top to bottom positions of a list. For example, in DCG, D i = 1/lo\u0434(k i + 1) and in Prec@K, D i = I{k i \u2264 K }/K. The discount factor D i is often interpreted as the examination probability at the displayed position, i.e., P\n(O = 1|F = f i , K = k i )\nwhere O is a binary variable denoting whether the item i is examined at position k i . The underlying assumption of these metrics is the examination hypothesis [41] that a user clicks an item only when it is examined and relevant, i.e.,\nP (C = 1|F = f i , K = k i ) = P (O = 1|F = f i , K = k i ) \u00b7 P (r i = 1).(28)\nMoreover, in order to facilitate learning from users' click through logs, counterfactual learning to rank methods [22,27,48,49] address the mismatch between the binary relevance r i and click feedback c i in the historical data with IPW. The propensity Q i used in counterfactual learning to rank methods also refers to an examination probability. Different from the discount factor, here the examination probability refers to that of item i displayed at position k h i in the logging data, i.e., P (O = 1|F = f i , K = k h i ). According to the general setting of counterfactual learning, an estimate of Metric is defined as\nMetric I PS = n q i=1 D i \u00b7 c i Q i ,(29)\nwhich is essentially an unbiased estimation of Equation (27) since\nE[Metric I PS ] = n q i=1 D i \u00b7 P (C = 1|F = f i , K = k h i ) P (O = 1|F = f i , K = k h i ) = n q i=1 D i \u00b7 P (O = 1|F = f i , K = k h i ) \u00b7 r i P (O = 1|F = f i , K = k h i ) = n q i=1 D i \u00b7 r i .(30)\nMore generally, if we further consider the benefit b i of each item, then we have an unbiased metric of utility based on implicit feedback as\nMetric = n q i=1 D i Q i \u00b7 c i \u00b7 b i ,(31)\nwhere discount factor D i and propensity Q i , as we mentioned before, correspond to P  [10] 1/ log(k i + 1) 1 1 Sponsored search [55,56] 1\n(O = 1|F = f i , K = k i ) and P (O = 1|F = f i , K = k h i ),Discount factor D i Propensity Q i Benefit b i SVMRank [23] \u2212k i 1 1 PropSVMRank [27] \u2212k i \u03b8 k h i 1 PBM [49] \u2212k i \u03b8 k h i 1 CPBM [17] \u2212k i f (k h i , q) 1 LambdaRank (NDCG)1 b i U-rank+ f (k i , q, i) f (k h i , q, i) b i\nEquation (31), we summarize and compare several existing (counterfactual) learning to rank methods in Table 1.\n\nThe main difficulty of estimating the utility metric in Equation (1) \n= 1|F = f i , K = k h i )\nin different models to make the propensity estimation feasible. For instance, in PropSVMrank [27] and PBM [49], the propensity is only related to position k i ; in CPBM [17], the propensity is related to both position k i and query q. Still, we need to meet other strict requirements like online randomization [27] or multiple rankers [17,49]. Jointly learning a propensity model with a relevance model merely from click logs [4,22] does not need to meet these requirements, but is also challenging. In such methods, the propensity estimation and the relevance estimation strongly depend on the unbiasedness of each other. Due to the lack of direct supervision, there is no clear evidence to demonstrate the unbiasedness of either model.\n\nIn this work, we do not rely on the separate estimation of relevance and propensity, which simplify the problem. Thus, we can estimate a much more loose assumption that the examination probability is a function of position k i and feature f i (containing user/query features, item features, and context features). Binding the estimation of discount factor with the estimation of propensity, we notice that\nD i Q i = P (O = 1|F = f i , K = k i )P (r i = 1) P (O = 1|F = f i , K = k h i )P (r i = 1) = P (C = 1|F = f i , K = k i ) P (C = 1|F = f i , K = k h i ) .(32)\nSince the relevance term r i is removed in Equation (32), without relying on an accurate relevance estimation, a ratio between discount factor and propensity can be obtained. We only need to estimate the click probability of the item i at position k i . Based on users' click through logs, we derive an unbiased metric of utility, inspired by Equation (31) and Equation (32), as\nU q = n q i=1 P (C = 1|F = f i , K = k i ) P (C = 1|F = f i , K = k h i ) \u00b7 c i \u00b7 b i .(33)\nThis is exactly the objective we optimize for in Section 4.2.2.\n\n\nSEMI-SYNTHETIC EXPERIMENTS\n\nThe semi-synthetic setup is widely applied in the community of counterfactual learning to rank [4,17,22,27] as it allows us to explore a range of different settings. In this section, we will evaluate the performance of our proposed approaches and the baseline approaches with three semi-synthetic benchmark datasets. 5\n\n\nDatasets\n\nWe base the semi-synthetic experiments on three real-world benchmark datasets. The detailed description of these three datasets is as below.\n\n-Yahoo! LETOR set 1 6 \n\n\nClick Data Generation\n\nWe mainly follow Fang et al. [17] to generate synthetic click data with item-wise examination probability for Yahoo! LETOR, MSLR-WEB10K, and Istella-S LETOR datasets. In the following part, oracle model refers to this click generation model. First of all, we follow the given train/validation/test splits of the three datasets, and queries without relevant documents are filtered. Following [17], to generate the initial positions of the items, we learn two ranking models by running SVMRank [23] on two small randomly sampled subsets of the queries in the training data. Specifically, the two ranking models are trained with 22 shared queries and 92 distinguished queries. Then, the initial positions of the items for the remaining queries are generated by the two learned ranking models. Each query-item pair in the remaining queries corresponds to two initial positions, generated by the two ranking model, respectively. Note that two initial ranking models are required in [17] but not in our method. We follow this setting for fair comparison. The maximal position k max is set to be 10 in our experiments.\n\nFollowing [17], the examination probability which is related to both position and the item is\ncalculated by P (o i,k i = 1|k i , x i ) = 1 k max(w \u00b7x i +1, 0) i\n. In our setting, x i is set of item features, while in the setting of [17], x i is the set of query features which is shared among all the items for a same query. The parameter vector w is drawn from a uniform distribution over [\u2212\u03b7, \u03b7) and is normalized such that j=1 w j = 0. The parameter \u03b7 controls how the examination probability varies with context.\n\nThe relevance probability is defined as P (r i = 1) = \u03f5 + (1 \u2212 \u03f5 ) 2 y i \u22121 2 ymax \u22121 (following [22]), where y i denotes the relevance label of x i and y max is the highest level of relevance. \u03f5 is set to 0.1, which denotes the click probability of irrelevant documents. 5 The code with running instructions for our experiments is available at https://github.com/xydaisjtu/U-rank-TOIS-version. 6 \n\n\nBaselines\n\nWe implement eight baselines that explore the performance of two standard learning to rank methods (i.e., SVMRank [23] and LambdaRank [10]), with four propensity estimation methods, which are detailed as follows:\n\n-None uses the original click data without debiasing.\n\n-Randomization [27] estimates propensity with online randomized experiments.\n\n-CPBM [17] estimates examination probability w.r.t different queries based on intervention harvesting. -Groundtruth uses the groundtruth examination probability for oracle model as propensity.\n\nThe result of this method is the upper bound of the results of other IPS approaches based on the same ranking model.\n\nOther methods that we include for comparison are as follows:\n\n-CTR-1 [20] is the position-aware click model used in our framework which assigns position 1 to each item during online inference. -DLA [4] is a dual learning algorithm that jointly learns an unbiased ranker and an unbiased propensity model. The ranker is a deep neural network.\n\nWe also explore the performance of Kuhn-Munkres (KM) (oracle model) which solves the maximum-weight graph matching problem via KM algorithm with O (N 3 ) time complexity [28,36], given the groundtruth click probability. It is supposed to produce the best utility that can be achieved on the testing data. As for our method, U-rank is the preliminary version of this work (published in [14]), which is a LambdaLoss based implementation without the debiasing of selection bias. In this work, we further debias the selection bias and propose U-rank+ sinkhorn and U-rank+ lambda based on the Sinkhorn solver and LambdaLoss solver, respectively. For fair comparison, the DNN based ranking models adopt the same network architecture. We use a fullyconnected neural network with four hidden layers, where the hidden sizes are 1,024, 1,024, 512, and 50, respectively.  \n\n\nOverall Performance\n\nIn this section, we assume the benefit of each item brought to the system as 1 in order to consistently and fairly compare U-rank+ with existing (counterfactual) learning to rank methods that rank the items according to the relevance they estimate. We evaluate the performance of the baseline approaches and our proposed model in terms of the relevance-based metrics, i.e., Mean Average Precision (MAP) and nDCG (including nDCG@1, nDCG@3, nDCG@5, and nDCG@10), and utility-based metrics, i.e., # Click and CTR. Here, # Click and CTR are utility metrics based on oracle click model denoting number of clicks per query and click probability per document, respectively. Specifically, # Click is average number of clicks over the test queries where the click are sampled once for each query-item pair. CTR is the average of the exact click probability for each query-item pair on the test set.\n\n\nU-Rank+\n\n\n25:21\n\nThe overall performance on the three benchmark datasets is given in Tables 2-4. From the tables, we have the following observations: -Our methods, including U-rank, U-rank+ lambda , and U-rank+ sinkhor n , achieve consistently the best performance than the state-of-the-art baseline approaches on the utility-oriented metrics, i.e., #Click and CTR. For example, U-rank+ lambda achieves 1.7% improvement in Yahoo! LETOR set 1 and 10.2% improvement in MSLR-WEB10K on CTR, compared to the best baseline methods (the baseline in italic use the information from oracle click model, so they are not included for comparison). Besides, U-rank+ lambda improves substantially over Urank on the utility-oriented metrics on those three benchmark datasets, which demonstrates the effectiveness of debiasing selection bias. Compared to LambdaLoss-based U-rank+ lambda method, U-rank+ sinkhor n performs slightly worse. -U-rank, U-rank+ lambda , and U-rank+ sinkhor n also outperform most of the baselines in terms of the relevance-based metrics, i.e., MAP and nDCG, and U-rank+ lambda performs best among those three methods. Though it does not always perform the best, especially on MSLR-WEB10K dataset where CPBM generates the best ranking w.r.t. MAP and nDCG. We also observe that even the KM algorithm, which computes the best item-position matching with the oracle examination probabilities, does not achieve a high MAP/nDCG on MSLR-WEB10K. This observation shows that a model optimizing the utility-based metrics does not always optimize a relevance-based ranking metric, which indicates that traditional ranking metrics such as nDCG are not proper utility metrics. However, on Yahoo! LETOR set 1 and Istella-S LETOR, where the disagreement is smaller, KM algorithm achieves almost the highest MAP and nDCG and our methods also perform well on relevance-based metrices. -The method Groundtruth achieves the best utility among the counterfactual learning approaches, which demonstrates the effectiveness of the IPS-based framework when the propensity estimation is accurate. Randomization does not perform well because it assumes that the examination probability only relates to the position, which is not valid in our setting where the examination probability relies on both the position and the item features. CPBM achieves the second-best utility among IPS-based methods since it models the propensity by considering both position and query features. -U-rank and CTR-1 share the same click model. However, U-rank outperforms CTR-1 mainly because CTR-1 ranks items by their estimated click probability at position 1, which is suboptimal in case of item-wise examination probability. Our methods also outperform DLA since DLA relies heavily on the accuracy of estimated propensity, which is hard to achieve.\n\n\nEmpirical Analysis\n\nIn this section, we conduct empirical analysis to answer the following research questions:\n\n\nRQ1.\n\nHow effective is the position propensity model in reducing selection bias? RQ2. Can our proposed methods deal with position bias? RQ3. How do our methods conduct direct revenue maximization? RQ4. Does our framework generalize to different ranking model architectures?\n\n\nRQ1: How Effective is the Position Propensity Model in Reducing Selection Bias?\n\nIn this section, we study the effect of position propensity model in reducing selection bias. We use two kinds of test datasets, biased and random datasets. The initial ranked lists of the biased test set are generated from two same ranking models as in the training set while the initial ranked lists of the random test set are randomly shuffled. Then, the same click generation procedure as discussed in Section 5.2 is used to generate clicks based on the given ranked lists in the two kinds of datasets. We train U-rank and U-rank+ lambda on the same (biased) training set and then evaluate on the two kinds of test datasets. The evaluation is based on two metrics: Area Under the ROC curve (AUC) and Logloss (cross entropy). Usually, higher AUC and lower Logloss indicate better performance. Both the click model and position propensity model are fully connected neural networks. The network architecture are the same as the ranking model. The performance of U-rank and U-rank+ lambda on those two kinds of test datasets is shown in Table 5. U-rank+ lambda and U-rank achieve similar performance on biased test set; however, U-rank+ lambda works consistently better than U-rank on random test set, which verifies that U-rank+ lambda is less affected by selection bias while still maintains a reasonable accuracy rate. Figure 5, we show the average click probability on each position of U-rank+ lambda , U-rank+ sinkhor n , and LambdaRank based approaches since they are the best baselines on average in terms of utility as given in Tables 2 and  3. We also plot the results of KM (oracle model) for reference.\n\n\nRQ2: Can Our Proposed Methods Deal with Position Bias? In\n\nComparing the results of the three datasets in Figure 5, we observe a steeper decline of average click probability to positions of the KM (oracle model) method on the Yahoo! and Istella datasets than that on the MSLR dataset. It means that the optimal matching tends to display the most relevant items at the Yahoo! and Istella datasets' top positions, which suggests that positions have a powerful impact on users' clicks in these two datasets. Thus, to optimize the utility, a wellperformed approach should put more relevant items at higher positions. In MSLR-WEB10K, on the other hand, we find that the average click probability of the optimal matching tends to be equally distributed on the positions, compared to the Yahoo! and Istella datasets. We find that our methods are adaptive to different severity of position bias. In the Yahoo! and Istalla datasets, our models, U-rank+ lambda and U-rank+ sinkhor n , focus more on top positions than LambdaRank, while in the MSLR dataset, our models learn a flatter distribution. Notably, our models achieve a more considerable sum of click probabilities in these three datasets over all the positions than LambdaRank.\n\n\nRQ3: How Do Our Methods Conduct Direct Revenue Maximization?\n\nWe analyze the result of a single query in detail. The experiment is conducted on the first query of the MSLR-WEB10K dataset. Figure 6 shows the click probabilities of the 10 items for this query and their click  probabilities if placed at each position according to our oracle click data generation model. The position of each item assigned by different methods is denoted in orange color. We can see that although LambdaRank performs better in nDCG with a groundtruth propensity. It, however, achieves a lower click probability than our methods, U-rank+ lambda and U-rank+ sinkhor n . This is because similar to the KM (oracle model), our methods will take the position sensitivity of different items into consideration. For example, document 6 is of high relevance and relatively not sensitive to the position change. LambdaRank displays it in the second position while our methods and KM both display it at a lower position so that the second position is kept for an item that is more sensitive to the position change.\n\n\nRQ4: Does Our Framework Generalize to Different Ranking Model Architectures?\n\nIn our initial implementation, the ranking model is a neural network. To study the influence of different ranking model architectures, we change our ranking model from a NN-based model to a Tree-based model. We train the U-rank (Tree) and U-rank+ (Tree) with a similar procedure in LambdaMART [9]   according to our loss function. Note that here U-rank+ (Tree) is implemented with the LambdaLoss solver. As presented in Tables 6-8, U-rank+ (Tree) works consistently better than LambdaMART w.r.t. utility-based metrics on three datasets. Our methods also outperform all baselines in terms of the relevance-based metrics on Yahoo! and Istella datasets, which demonstrates the generalizability of our methods, taking both NN and Tree models as the ranking model. Though our models do not always perform the best in regard to relevance-based metrics, especially on MSLR-WEB10K dataset, it accords with the results in Table 3 and it is explainable. Besides, U-rank+ (Tree) also outperforms U-rank (Tree) on both relevance-based metrics and utility-based metrics, which indicates the effectiveness of debiasing selection bias.\n\n\nONLINE A/B TESTING\n\nIn order to verify the effectiveness of our proposed model in real-world applications, we conduct experiments on the data from a recommendation scenario and an online advertising scenario in a mainstream App store. This App store has hundreds of millions of daily active users who create hundreds of billions of user logs everyday in the form of implicit feedback such as browsing, clicking, and downloading behaviors.\n\n6.1 Recommendation Scenario 6.1.1 Setups. We conduct A/B testing in a recommendation scenario in a mainstream App store with multiple sub-scenarios such as \"Must-have Apps\" and \"Novel and Fun\". The proposed model U-rank is compared with the current production baseline DeepFM [19]. The whole online experiment lasts 24 days, from May 6, 2020 to May 29, 2020. We monitor the results of A/A testing for the first 7 days, conduct A/B testing for the following 10 days, and conduct A/A testing again in the last 7 days. A total of 15% of the users are randomly selected as the experimental group and another  15% of the users are in the control group. During A/A testing, all the users are served by DeepFM model [19]. During A/B testing, users in the control group are presented with recommendation by DeepFM, while users in the experimental group are presented with the recommendation by our proposed model U-rank. Note that the click model of U-rank shares the same network architecture and parameter complexity with DeepFM in order to verify whether the improvement is brought by the objective function design of the ranker in U-rank.\n\nTo deploy U-rank, we utilize a single node with 48 core Intel Xeon CPU E5-2670 (2.30 GHZ), 400 GB RAM, and as well as 2 NVIDIA TESLA V100 GPU cards, which is the same as the training environment of the baseline DeepFM. For model training, U-rank requires minor changes to the current training procedure due to the pairwise loss function. For model inference, U-rank shares the same pipeline as DeepFM, which means there is no extra engineering work needed in model inference, to upgrade DeepFM model (or other similar deep models) to U-rank.\n\n\nMetrics.\n\nWe examine two metrics in the online evaluation. They are Click-through rate: CT R = #downloads #impr essions and Conversion rate: CV R = #downloads #user s , where # downloads, # impressions, and #users are the number of downloads, impressions, and visited users, respectively. Figures 7 and 8 show the improvement of the experimental group over the control group w.r.t. CTR and CVR, respectively. We can see that the system is rather stable where both CTR and CVR fluctuated within 8% during the A/A testing. Our U-rank model is launched to the live system on Day 8. From Day 8, we observe a significant improvement over the baseline model w.r.t. both CTR and CVR. The average improvement of CTR is 19.2% and the average improvement of CVR is 20.8% over the 10 days of A/B testing. These results clearly demonstrate the high effectiveness of our proposed model in improving the total utility which refers to the number of downloads in this scenario. From Day 18, we conduct A/A testing again to replace our U-rank model with the baseline model in the experimental group. We observe a sharp drop in the performance of the experimental group, which once more verify that the improvement of online performance in the experimental group is indeed introduced by our proposed model.\n\n\nResults.\n\n\nOnline Advertising Scenario\n\n6.2.1 Setups. We also conduct A/B testing in an online advertising scenario \"Boutique Apps\" in the same App store. In this scenario, each App is related to a benefit which is corresponding to the price the campaign would pay to the platform if this App is downloaded once. The performance U-Rank+ 25:27 matching on the item-position bipartite graph, we optimize the expected utility directly based on clicks without any extra assumptions on relevance nor examination. Considering different utility forms in real world applications, a general weighted form of ranking metric is proposed. We first estimate the weight of the bipartite graph with a position-aware deep CTR model, which models the examination bias explicitly by taking user context and item attribute into consideration. Besides, a propensity model is learned in advance and used to correct for selection bias in the logging data, alleviating the overestimation of examination bias. Then, we propose two different solver, Sinkhorn and LambdaLoss, to solve the maximum-weight matching problem, i.e., to optimize the expected utility. Sinkhorn algorithm learns a DSM-based ranking function and solves the graph matching problem in an end-to-end manner. LambdaLoss solves the matching problem by learning a scoring function with pairwise permutations, and reduces the complexity in inference stage from O (N 3 ) to O (N ). Theoretical analysis shows that the LambdaLoss objective proposed in this work is an upper bound of the graph matching objective, and also a natural extension of previous counterfactual learning to rank objectives. Extensive studies on three benchmark datasets have shown the effectiveness of our work. We also deploy this ranking framework on two different application scenarios, including recommendation and online advertising, where we observe a large utility improvement over the production baselines.\n\nFig. 1 .\n1The maximization of the utility can be formulated as solving a maximum-weight matching problem on the item-position bipartite graph, where the weight of an edge between an item and a position denotes the utility of placing the item at this position, e.g., the CTR or the expected revenue of the item at this position.\n\nFig. 2 .\n2The CTR analysis w.r.t. query/item features. The data are collected through 120-days' click logs on random recommendation traffic in a mainstream App store.\n\n\n.35, respectively.   \n\nFig. 3 .\n3An analysis of selection bias by comparing the estimated CTR from biased and unbiased click datasets. See the definition of \u03c1 in Equation (2).\n\nFig. 4 .\n4Sinkhorn normalization of two layers. The square inside the box denotes the value of each element in the matrix. The square at the end of each column/row outside the box denotes sum of the elements in the column/row. In each Sinkhorn layer, row and column normalization are performed to the matrix. After several layers, the row-and column-wise sums are almost indistinguishable.\n\n\n, by relaxing permutation matrix to DSM. Firstly, we define a family of functions \u03a8 * = {\u03c8 * n q : q \u2208 Q}. Each function in this family takes the features of items ( f i , b i ) n q i=1 as input and outputs a permutation matrix S. It is denoted as ACM Transactions on Information Systems, Vol. 40, No. 2, Article 25. Publication date: November 2021.\n\nLemma 4. 1 .\n1Given an indicator function f (x ) = I(x \u2264 0) and a function \u0434(x ) = log 2\n\nLemma 4. 2 .\n2Given an indicator function f (x ) = I(x \u2265 0) and a function \u0434(\n\nLemma 4 . 3 .\n43Given a sum function f (x ) = i x i and a max function \u0434\n\n\nNow, we are ready to derive the main theoretical result.Theorem 4.4. Assume the utility function u (i, k i ) is a monotonic decreasing function w.r.t k i and the ranking score s i is bounded in the range of [\u2212C,C]. Let C 1 = max {log(1 + exp(2\u03c3C)), 2} and C 2 = C1 \u00b7 n q j=1 i:k i >k j (u (j, k j ) \u2212 u (j, k i )). Then, we have L r (\u03a6, q) \u2264 L r (\u03a6, q) + C 2 . ACM Transactions on Information Systems, Vol. 40, No. 2, Article 25. Publication date: November 2021.\n\nTheorem 4 . 5 .\n45Assume the utility u (i, k i ) is a monotonic decreasing function w.r.t k i . Then, L r (\u03a6, q) is upper bounded by L r (\u03a6, q).\n\nTheorem 4. 6 .\n6Under the assumption of Theorem 4.4 and Theorem 4.5, we have that L r (\u03a6, q) \u2264 L r (\u03a6, q) + C 2 .\n\n\nfrom the users' click through logs lies in the estimation of the underlying examination probability P (O = 1|F = f i , K = k i ), since we do not have any direct supervised signal telling whether the item i is observed by the user at position k i . Due to the lack of supervision, strong assumptions are made on P (O\n\n\nis the dataset used in Yahoo! Learning-to-Rank Challenge. It contains 29,921 queries with 710k documents. The 700 features are extracted from query-URL pairs with all the features normalized to be in the [0,1] range. The relevance judgments can take five different values from 0 (irrelevant) to 4 (perfectly relevant). -MSLR-WEB10K 7 is a large-scale dataset released by Microsoft Research Asia in May 2010. Microsoft datasets contains 10,000 queries and 1,200,193 documents. There are in total 136 features extracted from query-URL pairs. The relevance judgements are obtained from a retired labeling set of Microsoft Bing search engine, which take five values from 0 (irrelevant) to 4 (perfectly relevant). -Istella-SLETOR 8 [32] is released by Istella in 2016, which is one of the largest public available datasets. Istella-S is composed of 33,018 queries and 220 features representing each query-document pair. The average examples in one query is 104. The relevance judgement ranges from 0 (irrelevant) to 4 (perfectly relevant).\n\nFig. 6 .\n6Comparison of the result lists of different methods on the first query of MSLR-WEB10K.\n\nFig. 7 .\n7Online experimental results of CTR (recommendation scenario).\n\nFig. 8 .\n8Online experimental results of CVR (recommendation scenario).\n\n\nhttps://webscope.sandbox.yahoo.com. 7 https://www.microsoft.com/en-us/research/project/mslr/. 8 http://quickrank.isti.cnr.it/istella-dataset/.Table 2. Comparison of Different (Counterfactual) Learning to Rank Models on Yahoo! LETOR Set 1U-Rank+ \n\n25:19 \n\nRanking model \nRelevance-based \nUtility-based \nMAP nDCG@1 nDCG@3 nDCG@5 nDCG@10 # Click CTR \n\nSVMRank \n\nNone \n0.702 \n0.653 \n0.680 \n0.728 \n0.845 \n0.599 \n0.0641 \nRandomization 0.639 \n0.498 \n0.571 \n0.640 \n0.787 \n0.533 \n0.0573 \nCPBM \n0.707 \n0.661 \n0.689 \n0.735 \n0.849 \n0.599 \n0.0645 \nGroundtruth \n0.718 \n0.680 \n0.709 \n0.752 \n0.859 \n0.612 \n0.0655 \n\nLambdaRank \n\nNone \n0.707 \n0.665 \n0.691 \n0.735 \n0.850 \n0.608 \n0.0648 \nRandomization 0.680 \n0.605 \n0.650 \n0.703 \n0.828 \n0.582 \n0.0621 \nCPBM \n0.718 \n0.683 \n0.703 \n0.747 \n0.857 \n0.613 \n0.0651 \nGroundtruth \n0.719 \n0.684 \n0.709 \n0.751 \n0.859 \n0.618 \n0.0657 \n\nDNN \nDLA \n0.665 \n0.500 \n0.582 \n0.654 \n0.792 \n0.593 \n0.0587 \nCTR-1 \n0.647 \n0.499 \n0.581 \n0.650 \n0.792 \n0.552 \n0.0577 \nU-rank \n0.721* \n0.692* \n0.714* \n0.755* \n0.862* \n0.614 0.0659* \nU-rank+ sinkhor n \n0.714 \n0.685 \n0.703 \n0.743 \n0.856 \n0.619* 0.0657* \nU-rank+ lambda \n0.722* 0.694* \n0.716* \n0.758* \n0.863* \n0.632* 0.0662* \nKM (oracle model) \n0.935 \n0.981 \n0.986 \n0.974 \n0.988 \n0.697 \n0.0737 \n\n *  denotes statistically significant improvement (t-test with p-value < 0.05) over all baselines (except Groundtruth). \n\n\n\nTable 3 .\n3Comparison of Different (Counterfactual) Learning to Rank Models on MSLR-WEB10KRanking model \nRelevance-based \nUtility-based \nMAP nDCG@1 nDCG@3 nDCG@5 nDCG@10 # Click CTR \n\nSVMRank \n\nNone \n0.496 \n0.443 \n0.509 \n0.570 \n0.735 \n0.818 \n0.0827 \nRandomization 0.433 \n0.351 \n0.416 \n0.484 \n0.686 \n0.777 \n0.0799 \nCPBM \n0.494 \n0.434 \n0.502 \n0.564 \n0.732 \n0.827 \n0.0823 \nGroundtruth \n0.513 \n0.481 \n0.525 \n0.588 \n0.747 \n0.863 \n0.0871 \n\nLambdaRank \n\nNone \n0.500 \n0.456 \n0.508 \n0.569 \n0.736 \n0.829 \n0.0830 \nRandomization 0.451 \n0.380 \n0.440 \n0.507 \n0.700 \n0.813 \n0.0808 \nCPBM \n0.508 \n0.461 \n0.515 \n0.580 \n0.740 \n0.836 \n0.0836 \nGroundtruth \n0.516 \n0.482 \n0.525 \n0.588 \n0.747 \n0.891 \n0.0886 \n\nDNN \n\nDLA \n0.457 \n0.373 \n0.454 \n0.522 \n0.705 \n0.823 \n0.0828 \nCTR-1 \n0.476 \n0.425 \n0.478 \n0.545 \n0.722 \n0.829 \n0.0814 \nU-rank \n0.492 \n0.428 \n0.484 \n0.554 \n0.724 \n0.906* 0.0915* \nU-rank+ sinkhor n \n0.473 \n0.398 \n0.463 \n0.532 \n0.712 \n0.928* 0.0918* \nU-rank+ lambda \n0.479 \n0.416 \n0.468 \n0.540 \n0.716 \n0.951* 0.0921* \nKM (oracle model) \n0.711 \n0.763 \n0.795 \n0.809 \n0.881 \n0.972 \n0.0969 \n\n *  denotes statistically significant improvement (t-test with p-value < 0.05) over all baselines (except Groundtruth). \n\n\n\nTable 4 .\n4Comparison of Different (Counterfactual) Learning to Rank Models on Istella-SLETORRanking model \nRelevance-based \nUtility-based \nMAP nDCG@1 nDCG@3 nDCG@5 nDCG@10 # Click CTR \n\nSVMRank \n\nNone \n0.769 \n0.613 \n0.626 \n0.681 \n0.806 \n0.936 \n0.0937 \nRandomization 0.742 \n0.572 \n0.591 \n0.649 \n0.787 \n0.912 \n0.0911 \nCPBM \n0.770 \n0.619 \n0.630 \n0.684 \n0.808 \n0.939 \n0.0938 \nGroundtruth \n0.775 \n0.639 \n0.646 \n0.695 \n0.816 \n0.953 \n0.0952 \n\nLambdaRank \n\nNone \n0.773 \n0.623 \n0.631 \n0.685 \n0.810 \n0.940 \n0.0941 \nRandomization 0.747 \n0.584 \n0.597 \n0.652 \n0.790 \n0.920 \n0.0917 \nCPBM \n0.776 \n0.631 \n0.638 \n0.691 \n0.813 \n0.945 \n0.0946 \nGroundtruth \n0.781 \n0.633 \n0.642 \n0.695 \n0.815 \n0.948 \n0.0948 \n\nDNN \n\nDLA \n0.690 \n0.363 \n0.435 \n0.515 \n0.703 \n0.840 \n0.0836 \nCTR-1 \n0.733 \n0.537 \n0.562 \n0.620 \n0.771 \n0.895 \n0.0895 \nU-rank \n0.782* \n0.637* \n0.643* \n0.695 \n0.815 \n0.952* 0.0953* \nU-rank+ sinkhor n \n0.776 \n0.640* \n0.642* \n0.693 \n0.815 \n0.954* 0.0952* \nU-rank+ lambda \n0.780* \n0.637* \n0.646* \n0.697* \n0.816 \n0.957* 0.0954* \nKM (oracle model) \n0.993 \n0.993 \n0.995 \n0.995 \n0.995 \n1.128 \n0.1126 \n\n *  denotes statistically significant improvement (t-test with p-value < 0.05) over all baselines (except Groundtruth). \n\n\n\nTable 5 .\n5Comparison of Different Click Models on Three DatasetsModel \nMetric \nMSLR-WEB10K Yahoo! LETOR set 1 Istella-SLETOR \nbiased random biased \nrandom \nbiased random \n\nU-rank \nAUC \n0.6974 0.7456 0.7830 \n0.7463 \n0.7563 0.6711 \nLogloss 0.2699 0.1999 0.2019 \n0.2001 \n0.2695 0.1865 \n\nU-rank+ lambda \nAUC \n0.6973 0.7464 0.7831 \n0.7475 \n0.7566 0.6725 \nLogloss 0.2699 0.1994 0.2020 \n0.1998 \n0.2697 0.1839 \n\nFig. 5. Average click probability on each position. \n\n\n\nTable 6 .\n6Comparison of Different Tree-Based Models on Yahoo! LETOR Set 1 * denotes statistically significant improvement (measured by t-test with p-value < 0.05) over all baselines.Ranking model \nRelevance-based \nUtility-based \nMAP nDCG@1 nDCG@3 nDCG@5 nDCG@10 # Click CTR \n\nLambdaMART \n\nNone \n0.714 \n0.694 \n0.707 \n0.747 \n0.657 \n0.611 0.0655 \nRandomization 0.701 \n0.679 \n0.689 \n0.732 \n0.850 \n0.606 0.0650 \nCPBM \n0.717 \n0.698 \n0.709 \n0.749 \n0.859 \n0.615 0.0657 \nGroundtruth \n0.718 \n0.696 \n0.710 \n0.749 \n0.859 \n0.619 \n0.0658 \nU-rank (Tree) \n0.720 \n0.692 \n0.714* \n0.756* \n0.862 \n0.621* 0.0659 \nU-rank+ (Tree) \n0.722* \n0.694 \n0.714* \n0.757* \n0.863 \n0.622* 0.0660* \nKM (oracle model) \n0.935 \n0.981 \n0.986 \n0.974 \n0.988 \n0.697 0.0737 \n\n \n\nTable 7 .\n7Comparison of Different Tree-Based Models on MSLR-WEB10K * denotes statistically significant improvement (measured by t-test with p-value < 0.05) over all baselines.Ranking model \nRelevance-based \nUtility-based \nMAP nDCG@1 nDCG@3 nDCG@5 nDCG@10 # Click CTR \n\nLambdaMART \n\nNone \n0.509 \n0.493 \n0.528 \n0.581 \n0.747 \n0.845 \n0.0835 \nRandomization 0.501 \n0.476 \n0.516 \n0.573 \n0.741 \n0.835 \n0.0826 \nCPBM \n0.517 \n0.492 \n0.530 \n0.589 \n0.749 \n0.845 \n0.0835 \nGroundtruth \n0.520 \n0.495 \n0.538 \n0.592 \n0.752 \n0.851 \n0.0844 \nU-rank (Tree) \n0.474 \n0.405 \n0.467 \n0.537 \n0.716 \n0.912* 0.0909* \nU-rank+ (Tree) \n0.479 \n0.412 \n0.471 \n0.538 \n0.717 \n0.916* 0.0912* \nKM (oracle model) \n0.710 \n0.763 \n0.795 \n0.809 \n0.881 \n0.972 \n0.0969 \n\n \n\nTable 8 .\n8Comparison of Different Tree-Based Models on Istella-SLETOR 1126 * denotes statistically significant improvement (measured by t-test with p-value < 0.05) over all baselines.Ranking model \nRelevance-based \nUtility-based \nMAP nDCG@1 nDCG@3 nDCG@5 nDCG@10 # Click CTR \n\nLambdaMART \n\nNone \n0.772 \n0.609 \n0.619 \n0.675 \n0.803 \n0.932 \n0.0931 \nRandomization 0.773 \n0.617 \n0.628 \n0.682 \n0.807 \n0.943 \n0.0936 \nCPBM \n0.775 \n0.623 \n0.630 \n0.686 \n0.809 \n0.930 \n0.0938 \nGroundtruth \n0.780 \n0.627 \n0.637 \n0.691 \n0.812 \n0.938 \n0.0941 \nU-rank (Tree) \n0.773 \n0.623 \n0.624 \n0.678 \n0.806 \n0.942 0.0947* \nU-rank+ (Tree) \n0.778 0.629* \n0.640* \n0.690 \n0.814* \n0.970* 0.0952* \nKM (oracle model) \n0.993 \n0.993 \n0.995 \n0.995 \n0.995 \n1.128 \n0.\nHere implicit feedback include, but are not limited to, clicking, purchasing, viewing, add-to-cart, and so on. For simplicity, in the following parts of this article, the term \"click\" is used as a representative of all types of user behaviors.\nFor a comprehensive analysis of bias issues and debias techniques in recommender systems and IR, we refer to[12].ACM Transactions on Information Systems, Vol. 40, No. 2, Article 25. Publication date: November 2021.\nACM Transactions on Information Systems, Vol. 40, No. 2, Article 25. Publication date: November 2021.\nWe treat context features and user/query features as \"special\" item features for simplicity, such that the same items for different queries/users are considered to be different.ACM Transactions on Information Systems, Vol. 40, No. 2, Article 25. Publication date: November 2021.\nIn this work, we assume that we do not know the logging policy or there is multiple ranking policy, which is quite common in a real-world platform. If we know the logging policy exactly, then we can use the true position propensities instead of learning it from click logs.\nThe baseline model is a point-wise CTR prediction model, which is not clearly described due to some commercial concerns.ACM Transactions on Information Systems, Vol. 40, No. 2, Article 25. Publication date: November 2021.\nACKNOWLEDGMENTWe thank MindSpore[1]for the partial support of this work, which is a new deep learning computing framework.Fig. 9. Online experimental results of effective Cost Per Mille (eCPM) (online advertising scenario).of a model would be evaluated by how much profit it brings to the platform. In order to compare the proposed model U-rank+ with the current production baseline model A ,9we conduct online experiment for 25 days, from October 21, 2020 to November 14, 2020. We monitor the results of A/A testing for the first 9 days, conduct A/B testing for the following 16 days. The A/B testing consists of several phases. In the beginning, 5% of the users are randomly selected as the experimental group on October 30 (Day 10 inFigure 9). As we observe the positive performance of U-rank+, we gradually increase the traffic of the experimental group to 17% (Day 15 inFigure 9) and to 20% (Day 19 inFigure 9). Another 20% of the users are randomly selected as the control group. During A/A testing, all the users are served by A . During A/B testing, users in the control group are presented with recommendation by A , while users in the experimental group are presented with the recommendation by our proposed model U-rank+. Note that the click model of U-rank+ shares the same network architecture and parameter complexity with A , in order to verify whether the improvement is brought by the objective function design of the ranker in U-rank+. The deployment of U-rank+ is the same as U-rank.Metrics.We examine effective Cost Per Mille: eCPM = i bid i \u00d71 i #impr essions \u00d7 1000 in the online advertising scenario where for the ith instance in the log of the day of testing (referred to as platform revenue in previous parts), bid i is the bid of the item in the instance, 1 i is the indicator function which equals 1 if the ith instance is a positive sample, and # impressions is the number of impressions.Figure 9shows the improvement of the experimental group over the control group w.r.t. eCPM. We can see that the system is stable where the improvement of eCPM fluctuated within 5% during the A/A testing. The average improvement of the experimental group during the nine days of A/A testing is \u22120.91%. Our U-rank+ model is launched to the live system on Day 10. From Day 10, we observe a significant improvement, 5.12%, over the baseline model. However, the improvement drops to 0.5% on Day 11, then, it increases to 8.72%, 16.41% for the following two days. The fluctuation of the improvement is caused by the small traffic of the experimental group. Thus, we increase the traffic to 17% and 20% on Day 15 and Day 19, respectively. We can see that the improvement of eCPM becomes stable as we increase of traffic of the experimental group. The average improvement of eCPM is 4.19% over the 16 days of A/B testing. Considering the fluctuation of A/A testing, the actual improvement of eCPM is 4.19% \u2212 (\u22120.91%) = 5.1%. These results clearly demonstrate the high effectiveness of U-rank+ in improving the total utility which refers to the income of the platform in this scenario.Results.CONCLUSIONIn this work, we propose a general graph matching framework for utility-oriented learning to rank with logged user feedback. By formulating the ranking objective as the maximum-weight\nRetrieved on 19 Aug. Mindspore, MindSpore. 2020. Retrieved on 19 Aug., 2021 from https://www.mindspore.cn/.\n\nRanking via Sinkhorn propagation. Prescott Ryan, Richard S Adams, Zemel, stat. 1050Ryan Prescott Adams and Richard S. Zemel. 2011. Ranking via Sinkhorn propagation. stat 1050 (2011), 14 pages.\n\nEstimating position bias without intrusive interventions. Aman Agarwal, Ivan Zaitsev, Xuanhui Wang, Cheng Li, Marc Najork, Thorsten Joachims, Proceedings of the 12th ACM International Conference on Web Search and Data Mining. the 12th ACM International Conference on Web Search and Data MiningAman Agarwal, Ivan Zaitsev, Xuanhui Wang, Cheng Li, Marc Najork, and Thorsten Joachims. 2019. Estimating posi- tion bias without intrusive interventions. In Proceedings of the 12th ACM International Conference on Web Search and Data Mining. 474-482.\n\nUnbiased learning to rank with unbiased propensity estimation. Qingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, W Bruce Croft, Proceedings of the 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. the 41st International ACM SIGIR Conference on Research & Development in Information RetrievalQingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, and W. Bruce Croft. 2018. Unbiased learning to rank with unbiased propensity estimation. In Proceedings of the 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. 385-394.\n\nPosition-aware deep character-level CTR prediction for sponsored search. Xiao Bai, Reza Abasi, Bora Edizel, Amin Mantrach, IEEE Transactions on Knowledge and Data Engineering. 33Xiao Bai, Reza Abasi, Bora Edizel, and Amin Mantrach. 2019. Position-aware deep character-level CTR prediction for sponsored search. IEEE Transactions on Knowledge and Data Engineering 33, 4 (2019), 1722-1736.\n\nA theory of learning from different domains. Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, Jennifer Wortman Vaughan, Machine Learning. 79Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. 2010. A theory of learning from different domains. Machine Learning 79, 1-2 (2010), 151-175.\n\nA neural click model for web search. Alexey Borisov, Ilya Markov, Maarten De Rijke, Pavel Serdyukov, Proceedings of the 25th International Conference on World Wide Web. the 25th International Conference on World Wide WebAlexey Borisov, Ilya Markov, Maarten De Rijke, and Pavel Serdyukov. 2016. A neural click model for web search. In Proceedings of the 25th International Conference on World Wide Web. 531-541.\n\nLearning to rank using gradient descent. Christopher Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, Gregory N Hullender, Proceedings of the 22nd International Conference on Machine Learning. the 22nd International Conference on Machine LearningChristopher Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Gregory N. Hullender. 2005. Learning to rank using gradient descent. In Proceedings of the 22nd International Conference on Machine Learning. 89-96.\n\nFrom RankNet to LambdaRank to LambdaMART: An overview. J C Christopher, Burges, Learning. 1181Christopher J. C. Burges. 2010. From RankNet to LambdaRank to LambdaMART: An overview. Learning 11, 23-581 (2010), 81.\n\nLearning to rank with nonsmooth cost functions. Christopher J Burges, Robert Ragno, V Quoc, Le, Proceedings of the 2006 Conference on Advances in Neural Information Processing Systems. the 2006 Conference on Advances in Neural Information Processing SystemsChristopher J. Burges, Robert Ragno, and Quoc V. Le. 2007. Learning to rank with nonsmooth cost functions. In Proceedings of the 2006 Conference on Advances in Neural Information Processing Systems. 193-200.\n\nA dynamic bayesian network click model for web search ranking. Olivier Chapelle, Ya Zhang, Proceedings of the 18th International Conference on World Wide Web. the 18th International Conference on World Wide WebOlivier Chapelle and Ya Zhang. 2009. A dynamic bayesian network click model for web search ranking. In Proceedings of the 18th International Conference on World Wide Web. 1-10.\n\nJiawei Chen, Hande Dong, Xiang Wang, arXiv:2010.03240Fuli Feng, Meng Wang, and Xiangnan He. 2020. Bias and debias in recommender system: A survey and future directions. arXiv preprintJiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and Xiangnan He. 2020. Bias and debias in recom- mender system: A survey and future directions. arXiv preprint arXiv:2010.03240.\n\nAn experimental comparison of click position-bias models. Nick Craswell, Onno Zoeter, Michael Taylor, Bill Ramsey, Proceedings of the 2008 International Conference on Web Search and Data Mining. the 2008 International Conference on Web Search and Data MiningNick Craswell, Onno Zoeter, Michael Taylor, and Bill Ramsey. 2008. An experimental comparison of click position-bias models. In Proceedings of the 2008 International Conference on Web Search and Data Mining. 87-94.\n\nU-rank: Utility-oriented learning to rank with implicit feedback. Xinyi Dai, Jiawei Hou, Qing Liu, Yunjia Xi, Ruiming Tang, Weinan Zhang, Xiuqiang He, Jun Wang, Yong Yu, Proceedings of the 29th ACM International Conference on Information & Knowledge Management. the 29th ACM International Conference on Information & Knowledge ManagementXinyi Dai, Jiawei Hou, Qing Liu, Yunjia Xi, Ruiming Tang, Weinan Zhang, Xiuqiang He, Jun Wang, and Yong Yu. 2020. U-rank: Utility-oriented learning to rank with implicit feedback. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2373-2380.\n\nThe YouTube video recommendation system. James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, Dasarathi Sampath, Proceedings of the 4th ACM Conference on Recommender Systems. the 4th ACM Conference on Recommender SystemsACMJames Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, and Dasarathi Sampath. 2010. The YouTube video recommendation system. In Pro- ceedings of the 4th ACM Conference on Recommender Systems. ACM, 293-296.\n\nA user browsing model to predict search engine click data from past observations. Georges E Dupret, Benjamin Piwowarski, Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. the 31st Annual International ACM SIGIR Conference on Research and Development in Information RetrievalGeorges E. Dupret and Benjamin Piwowarski. 2008. A user browsing model to predict search engine click data from past observations. In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. 331-338.\n\nIntervention harvesting for context-dependent examination-bias estimation. Zhichong Fang, Aman Agarwal, Thorsten Joachims, 10.1145/3331184.3331238Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 42nd International ACM SIGIR Conference on Research and Development in Information RetrievalNew York, NYACMZhichong Fang, Aman Agarwal, and Thorsten Joachims. 2019. Intervention harvesting for context-dependent examination-bias estimation. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Develop- ment in Information Retrieval. ACM, New York, NY, 825-834. DOI: https://doi.org/10.1145/3331184.3331238\n\nClick chain model in web search. Fan Guo, Chao Liu, Anitha Kannan, Tom Minka, Michael Taylor, Yi-Min Wang, Christos Faloutsos, Proceedings of the 18th International Conference on World Wide Web. the 18th International Conference on World Wide WebFan Guo, Chao Liu, Anitha Kannan, Tom Minka, Michael Taylor, Yi-Min Wang, and Christos Faloutsos. 2009. Click chain model in web search. In Proceedings of the 18th International Conference on World Wide Web. 11-20.\n\nDeepFM: A factorization-machine based neural network for CTR prediction. Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, Xiuqiang He, 10.24963/ijcai.2017/239Proceedings of the 26th International Joint Conference on Artificial Intelligence. 1725-1731. the 26th International Joint Conference on Artificial Intelligence. 1725-1731Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A factorization-machine based neural network for CTR prediction. In Proceedings of the 26th International Joint Conference on Artificial Intelli- gence. 1725-1731. DOI:https://doi.org/10.24963/ijcai.2017/239\n\nPAL: A position-bias aware learning framework for CTR prediction in live recommender systems. Huifeng Guo, Jinkai Yu, Qing Liu, Ruiming Tang, Yuzhou Zhang, 10.1145/3298689.3347033Proceedings of the 13th ACM Conference on Recommender Systems. the 13th ACM Conference on Recommender SystemsNew York, NYACMHuifeng Guo, Jinkai Yu, Qing Liu, Ruiming Tang, and Yuzhou Zhang. 2019. PAL: A position-bias aware learning frame- work for CTR prediction in live recommender systems. In Proceedings of the 13th ACM Conference on Recommender Systems. ACM, New York, NY, 452-456. DOI: https://doi.org/10.1145/3298689.3347033\n\nSample selection bias as a specification error. James J Heckman, Econometrica: Journal of the Econometric Society. 47James J. Heckman. 1979. Sample selection bias as a specification error. Econometrica: Journal of the Econometric Society 47, 1 (1979), 153-161.\n\nUnbiased LambdaMART: An unbiased pairwise learning-to-rank algorithm. Ziniu Hu, Yang Wang, Qu Peng, Hang Li, Proceedings of the 2019 World Wide Web Conference. the 2019 World Wide Web ConferenceZiniu Hu, Yang Wang, Qu Peng, and Hang Li. 2019. Unbiased LambdaMART: An unbiased pairwise learning-to-rank algorithm. In Proceedings of the 2019 World Wide Web Conference. 2830-2836.\n\nTraining linear SVMs in linear time. Thorsten Joachims, 10.1145/1150402.1150429Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningNew York, NYACMThorsten Joachims. 2006. Training linear SVMs in linear time. In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, NY, 217-226. DOI: https://doi.org/10.1145/ 1150402.1150429\n\nAccurately interpreting clickthrough data as implicit feedback. Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, Geri Gay, Proceedings of the ACM SIGIR Forum. the ACM SIGIR ForumNew York, NYACM51Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, and Geri Gay. 2017. Accurately interpreting click- through data as implicit feedback. In Proceedings of the ACM SIGIR Forum. Vol. 51. ACM, New York, NY, 4-11.\n\nEvaluating the accuracy of implicit feedback from clicks and query reformulations in web search. Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, Filip Radlinski, Geri Gay, ACM Transactions on Information Systems (TOIS). 257Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, Filip Radlinski, and Geri Gay. 2007. Evaluating the accuracy of implicit feedback from clicks and query reformulations in web search. ACM Transactions on Information Systems (TOIS) 25, 2 (2007), 7.\n\nAccurately interpreting clickthrough data as implicit feedback. Thorsten Joachims, Laura A Granka, Bing Pan, Helene Hembrooke, Geri Gay, Proceedings of the 28th Annual International ACM SIGIR Conference on Research. the 28th Annual International ACM SIGIR Conference on Research5Thorsten Joachims, Laura A. Granka, Bing Pan, Helene Hembrooke, and Geri Gay. 2005. Accurately interpreting click- through data as implicit feedback. In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. Vol. 5, 154-161.\n\nUnbiased learning-to-rank with biased feedback. Thorsten Joachims, Adith Swaminathan, Tobias Schnabel, Proceedings of the Tenth ACM International Conference on Web Search and Data Mining. the Tenth ACM International Conference on Web Search and Data MiningThorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2016. Unbiased learning-to-rank with biased feedback. In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining. 781-789.\n\nThe Hungarian method for the assignment problem. Harold W Kuhn, Naval Research Logistics Quarterly. 2Harold W. Kuhn. 1955. The Hungarian method for the assignment problem. Naval Research Logistics Quarterly 2, 1-2 (1955), 83-97.\n\nJ A Roderick, Donald B Little, Rubin, Statistical Analysis with Missing Data. John Wiley & Sons793Roderick J. A. Little and Donald B. Rubin. 2019. Statistical Analysis with Missing Data. Vol. 793. John Wiley & Sons.\n\nEye tracking and online search: Lessons learned and challenges ahead. Lori Lorigo, Maya Haridasan, Hr\u00f6nn Brynjarsd\u00f3ttir, Ling Xia, Thorsten Joachims, Geri Gay, Laura Granka, Fabio Pellacini, Bing Pan, Journal of the American Society for Information Science and Technology. 59Lori Lorigo, Maya Haridasan, Hr\u00f6nn Brynjarsd\u00f3ttir, Ling Xia, Thorsten Joachims, Geri Gay, Laura Granka, Fabio Pellacini, and Bing Pan. 2008. Eye tracking and online search: Lessons learned and challenges ahead. Journal of the American Society for Information Science and Technology 59, 7 (2008), 1041-1052.\n\nThe influence of task and gender on search and evaluation behavior using Google. Lori Lorigo, Bing Pan, Helene Hembrooke, Thorsten Joachims, Laura Granka, Geri Gay, Information Processing & Management. 424Lori Lorigo, Bing Pan, Helene Hembrooke, Thorsten Joachims, Laura Granka, and Geri Gay. 2006. The influence of task and gender on search and evaluation behavior using Google. Information Processing & Management 42, 4 (2006), 1123-1131.\n\nPost-learning optimization of tree ensembles for efficient ranking. Claudio Lucchese, Maria Franco, Salvatore Nardini, Raffaele Orlando, Fabrizio Perego, Salvatore Silvestri, Trani, Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 39th International ACM SIGIR Conference on Research and Development in Information RetrievalClaudio Lucchese, Franco Maria Nardini, Salvatore Orlando, Raffaele Perego, Fabrizio Silvestri, and Salvatore Trani. 2016. Post-learning optimization of tree ensembles for efficient ranking. In Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval.\n\nInvestigating the reliability of click models. Jiaxin Mao, Zhumin Chu, Yiqun Liu, Min Zhang, Shaoping Ma, Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval. the 2019 ACM SIGIR International Conference on Theory of Information RetrievalJiaxin Mao, Zhumin Chu, Yiqun Liu, Min Zhang, and Shaoping Ma. 2019. Investigating the reliability of click models. In Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval. 125-128.\n\nSinkhorn networks: Using optimal transport techniques to learn permutations. Gonzalo Mena, David Belanger, Gonzalo Munoz, Jasper Snoek, Proceedings of the NIPS Workshop in Optimal Transport and Machine Learning. the NIPS Workshop in Optimal Transport and Machine LearningGonzalo Mena, David Belanger, Gonzalo Munoz, and Jasper Snoek. 2017. Sinkhorn networks: Using optimal transport techniques to learn permutations. In Proceedings of the NIPS Workshop in Optimal Transport and Machine Learning.\n\nWhole page optimization: How page elements interact with the position auction. Pavel Metrikov, Fernando Diaz, Sebastien Lahaie, Justin Rao, Proceedings of the 15th ACM Conference on Economics and Computation. the 15th ACM Conference on Economics and ComputationPavel Metrikov, Fernando Diaz, Sebastien Lahaie, and Justin Rao. 2014. Whole page optimization: How page elements interact with the position auction. In Proceedings of the 15th ACM Conference on Economics and Computation. 583-600.\n\nAlgorithms for the assignment and transportation problems. James Munkres, Journal of the Society for Industrial and Applied Mathematics. 5James Munkres. 1957. Algorithms for the assignment and transportation problems. Journal of the Society for Industrial and Applied Mathematics 5, 1 (1957), 32-38.\n\nDifferentiable unbiased online learning to rank. Harrie Oosterhuis, Maarten De Rijke, Proceedings of the 27th ACM International Conference on Information and Knowledge Management. the 27th ACM International Conference on Information and Knowledge ManagementHarrie Oosterhuis and Maarten de Rijke. 2018. Differentiable unbiased online learning to rank. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 1293-1302.\n\nPolicy-aware unbiased learning to rank for top-k rankings. Harrie Oosterhuis, Maarten De Rijke, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 43rd International ACM SIGIR Conference on Research and Development in Information RetrievalHarrie Oosterhuis and Maarten de Rijke. 2020. Policy-aware unbiased learning to rank for top-k rankings. In Proceed- ings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 489-498.\n\nProduct-based neural networks for user response prediction over multi-field categorical data. Yanru Qu, Bohui Fang, Weinan Zhang, Ruiming Tang, Minzhe Niu, Huifeng Guo, Yong Yu, Xiuqiang He, ACM Transactions on Information Systems (TOIS). 375Yanru Qu, Bohui Fang, Weinan Zhang, Ruiming Tang, Minzhe Niu, Huifeng Guo, Yong Yu, and Xiuqiang He. 2018. Product-based neural networks for user response prediction over multi-field categorical data. ACM Transactions on Information Systems (TOIS) 37, 1 (2018), 5.\n\nHow does clickthrough data reflect retrieval quality?. Filip Radlinski, Madhu Kurup, Thorsten Joachims, Proceedings of the 17th ACM Conference on Information and Knowledge Management. the 17th ACM Conference on Information and Knowledge ManagementFilip Radlinski, Madhu Kurup, and Thorsten Joachims. 2008. How does clickthrough data reflect retrieval quality? In Proceedings of the 17th ACM Conference on Information and Knowledge Management. 43-52.\n\nPredicting clicks: Estimating the click-through rate for new ads. Matthew Richardson, Ewa Dominowska, Robert Ragno, Proceedings of the 16th International Conference on World Wide Web. the 16th International Conference on World Wide WebMatthew Richardson, Ewa Dominowska, and Robert Ragno. 2007. Predicting clicks: Estimating the click-through rate for new ads. In Proceedings of the 16th International Conference on World Wide Web. 521-530.\n\nThe probability ranking principle in IR. Stephen E Robertson, Journal of Documentation. 33Stephen E. Robertson. 1977. The probability ranking principle in IR. Journal of Documentation 33, 4 (1977), 294-304.\n\nDeeppermnet: Visual permutation learning. Rodrigo Santa Cruz, Basura Fernando, Anoop Cherian, Stephen Gould, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionRodrigo Santa Cruz, Basura Fernando, Anoop Cherian, and Stephen Gould. 2017. Deeppermnet: Visual permutation learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 3949-3957.\n\nMultileave gradient descent for fast online learning to rank. Anne Schuth, Harrie Oosterhuis, Shimon Whiteson, Maarten De Rijke, Proceedings of the 9th ACM International Conference on Web Search and Data Mining. the 9th ACM International Conference on Web Search and Data MiningAnne Schuth, Harrie Oosterhuis, Shimon Whiteson, and Maarten de Rijke. 2016. Multileave gradient descent for fast online learning to rank. In Proceedings of the 9th ACM International Conference on Web Search and Data Mining. 457-466.\n\nVariance reduction in gradient exploration for online learning to rank. Huazheng Wang, Sonwoo Kim, Eric Mccord-Snook, Qingyun Wu, Hongning Wang, Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 42nd International ACM SIGIR Conference on Research and Development in Information RetrievalHuazheng Wang, Sonwoo Kim, Eric McCord-Snook, Qingyun Wu, and Hongning Wang. 2019. Variance reduction in gradient exploration for online learning to rank. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 835-844.\n\nEfficient exploration of gradient space for online learning to rank. Huazheng Wang, Ramsey Langley, Sonwoo Kim, Eric Mccord-Snook, Hongning Wang, Proceedings of the 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. the 41st International ACM SIGIR Conference on Research & Development in Information RetrievalHuazheng Wang, Ramsey Langley, Sonwoo Kim, Eric McCord-Snook, and Hongning Wang. 2018. Efficient exploration of gradient space for online learning to rank. In Proceedings of the 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. 145-154.\n\nOn statistical analysis and optimization of information retrieval effectiveness metrics. Jun Wang, Jianhan Zhu, Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 33rd International ACM SIGIR Conference on Research and Development in Information RetrievalACMJun Wang and Jianhan Zhu. 2010. On statistical analysis and optimization of information retrieval effectiveness met- rics. In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Re- trieval. ACM, 226-233.\n\nLearning to rank with selection bias in personal search. Xuanhui Wang, Michael Bendersky, Donald Metzler, Marc Najork, Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 39th International ACM SIGIR Conference on Research and Development in Information RetrievalXuanhui Wang, Michael Bendersky, Donald Metzler, and Marc Najork. 2016. Learning to rank with selection bias in personal search. In Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval. 115-124.\n\nPosition bias estimation for unbiased learning to rank in personal search. Xuanhui Wang, Nadav Golbandi, Michael Bendersky, Donald Metzler, Marc Najork, Proceedings of the 11th ACM International Conference on Web Search and Data Mining. the 11th ACM International Conference on Web Search and Data MiningXuanhui Wang, Nadav Golbandi, Michael Bendersky, Donald Metzler, and Marc Najork. 2018. Position bias estimation for unbiased learning to rank in personal search. In Proceedings of the 11th ACM International Conference on Web Search and Data Mining. 610-618.\n\nThe LambdaLoss framework for ranking metric optimization. Xuanhui Wang, Cheng Li, Nadav Golbandi, Mike Bendersky, Marc Najork, Proceedings of the 27th ACM International Conference on Information and Knowledge Management. the 27th ACM International Conference on Information and Knowledge ManagementXuanhui Wang, Cheng Li, Nadav Golbandi, Mike Bendersky, and Marc Najork. 2018. The LambdaLoss framework for ranking metric optimization. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 1313-1322.\n\nTurning clicks into purchases: Revenue optimization for product search in e-commerce. Liang Wu, Diane Hu, Liangjie Hong, Huan Liu, Proceedings of the 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. the 41st International ACM SIGIR Conference on Research & Development in Information RetrievalACMLiang Wu, Diane Hu, Liangjie Hong, and Huan Liu. 2018. Turning clicks into purchases: Revenue optimization for product search in e-commerce. In Proceedings of the 41st International ACM SIGIR Conference on Research & Develop- ment in Information Retrieval. ACM, 365-374.\n\nInteractively optimizing information retrieval systems as a dueling bandits problem. Yisong Yue, Thorsten Joachims, Proceedings of the 26th Annual International Conference on Machine Learning. the 26th Annual International Conference on Machine LearningYisong Yue and Thorsten Joachims. 2009. Interactively optimizing information retrieval systems as a dueling bandits problem. In Proceedings of the 26th Annual International Conference on Machine Learning. 1201-1208.\n\nDeep learning over multi-field categorical data. Weinan Zhang, Tianming Du, Jun Wang, Proceedings of the European Conference on Information Retrieval. the European Conference on Information RetrievalSpringerWeinan Zhang, Tianming Du, and Jun Wang. 2016. Deep learning over multi-field categorical data. In Proceedings of the European Conference on Information Retrieval. Springer, 45-57.\n\nClick-based evidence for decaying weight distributions in search effectiveness metrics. Yuye Zhang, A F Laurence, Alistair Park, Moffat, Information Retrieval. 13Yuye Zhang, Laurence A. F. Park, and Alistair Moffat. 2010. Click-based evidence for decaying weight distributions in search effectiveness metrics. Information Retrieval 13, 1 (2010), 46-69.\n\nRevenue optimization with relevance constraint in sponsored search. Yunzhang Zhu, Gang Wang, Junli Yang, Dakan Wang, Jun Yan, Zheng Chen, Proceedings of the 3rd International Workshop on Data Mining and Audience Intelligence for Advertising. the 3rd International Workshop on Data Mining and Audience Intelligence for AdvertisingYunzhang Zhu, Gang Wang, Junli Yang, Dakan Wang, Jun Yan, and Zheng Chen. 2009. Revenue optimization with relevance constraint in sponsored search. In Proceedings of the 3rd International Workshop on Data Mining and Audience Intelligence for Advertising. 55-60.\n\nOptimizing search engine revenue in sponsored search. Yunzhang Zhu, Gang Wang, Junli Yang, Dakan Wang, Jun Yan, Jian Hu, Zheng Chen, Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 32nd International ACM SIGIR Conference on Research and Development in Information RetrievalYunzhang Zhu, Gang Wang, Junli Yang, Dakan Wang, Jun Yan, Jian Hu, and Zheng Chen. 2009. Optimizing search engine revenue in sponsored search. In Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 588-595.\n", "annotations": {"author": "[{\"end\":143,\"start\":133},{\"end\":154,\"start\":144},{\"end\":168,\"start\":155},{\"end\":183,\"start\":169},{\"end\":200,\"start\":184},{\"end\":210,\"start\":201},{\"end\":224,\"start\":211},{\"end\":260,\"start\":225},{\"end\":288,\"start\":261},{\"end\":300,\"start\":289},{\"end\":315,\"start\":301},{\"end\":332,\"start\":316},{\"end\":341,\"start\":333},{\"end\":355,\"start\":342},{\"end\":362,\"start\":356},{\"end\":368,\"start\":363},{\"end\":377,\"start\":369},{\"end\":384,\"start\":378},{\"end\":390,\"start\":385},{\"end\":400,\"start\":391},{\"end\":411,\"start\":401},{\"end\":422,\"start\":412},{\"end\":436,\"start\":423},{\"end\":446,\"start\":437},{\"end\":460,\"start\":447},{\"end\":473,\"start\":461},{\"end\":485,\"start\":474},{\"end\":518,\"start\":486},{\"end\":527,\"start\":519},{\"end\":635,\"start\":528},{\"end\":680,\"start\":636}]", "publisher": null, "author_last_name": "[{\"end\":142,\"start\":139},{\"end\":153,\"start\":151},{\"end\":167,\"start\":162},{\"end\":182,\"start\":178},{\"end\":199,\"start\":189},{\"end\":209,\"start\":206},{\"end\":223,\"start\":219},{\"end\":236,\"start\":234},{\"end\":287,\"start\":268},{\"end\":299,\"start\":296},{\"end\":314,\"start\":310},{\"end\":331,\"start\":321},{\"end\":340,\"start\":338},{\"end\":354,\"start\":349},{\"end\":361,\"start\":358},{\"end\":367,\"start\":365},{\"end\":376,\"start\":371},{\"end\":383,\"start\":380},{\"end\":389,\"start\":387},{\"end\":410,\"start\":407},{\"end\":421,\"start\":419},{\"end\":435,\"start\":430},{\"end\":445,\"start\":442},{\"end\":459,\"start\":455},{\"end\":472,\"start\":470},{\"end\":484,\"start\":481},{\"end\":494,\"start\":490}]", "author_first_name": "[{\"end\":138,\"start\":133},{\"end\":150,\"start\":144},{\"end\":161,\"start\":155},{\"end\":177,\"start\":169},{\"end\":188,\"start\":184},{\"end\":205,\"start\":201},{\"end\":218,\"start\":211},{\"end\":233,\"start\":225},{\"end\":267,\"start\":261},{\"end\":295,\"start\":289},{\"end\":309,\"start\":301},{\"end\":320,\"start\":316},{\"end\":337,\"start\":333},{\"end\":348,\"start\":342},{\"end\":357,\"start\":356},{\"end\":364,\"start\":363},{\"end\":370,\"start\":369},{\"end\":379,\"start\":378},{\"end\":386,\"start\":385},{\"end\":399,\"start\":391},{\"end\":406,\"start\":401},{\"end\":418,\"start\":412},{\"end\":429,\"start\":423},{\"end\":441,\"start\":437},{\"end\":454,\"start\":447},{\"end\":469,\"start\":461},{\"end\":480,\"start\":474},{\"end\":489,\"start\":486},{\"end\":523,\"start\":519},{\"end\":526,\"start\":524}]", "author_affiliation": "[{\"end\":634,\"start\":529},{\"end\":679,\"start\":637}]", "title": "[{\"end\":120,\"start\":1},{\"end\":800,\"start\":681}]", "venue": "[{\"end\":841,\"start\":802}]", "abstract": "[{\"end\":3492,\"start\":1450}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3870,\"start\":3869},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":4511,\"start\":4507},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":4514,\"start\":4511},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4573,\"start\":4569},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5346,\"start\":5343},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":5487,\"start\":5483},{\"end\":6393,\"start\":6383},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8286,\"start\":8282},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8289,\"start\":8286},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":8465,\"start\":8461},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8569,\"start\":8565},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8794,\"start\":8790},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8831,\"start\":8827},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8861,\"start\":8857},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8927,\"start\":8924},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9141,\"start\":9137},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":9450,\"start\":9446},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9475,\"start\":9471},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9745,\"start\":9742},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9858,\"start\":9854},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":10297,\"start\":10293},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":10422,\"start\":10419},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10548,\"start\":10544},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":11280,\"start\":11276},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11671,\"start\":11667},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":11739,\"start\":11735},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":12165,\"start\":12161},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12362,\"start\":12358},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":12365,\"start\":12362},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":12368,\"start\":12365},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":12407,\"start\":12403},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":12427,\"start\":12423},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":12625,\"start\":12621},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12740,\"start\":12736},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":12947,\"start\":12943},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13816,\"start\":13815},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":16637,\"start\":16633},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":16640,\"start\":16637},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17546,\"start\":17542},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":18300,\"start\":18296},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":19602,\"start\":19598},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":19615,\"start\":19611},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":23363,\"start\":23359},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":23366,\"start\":23363},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23389,\"start\":23386},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":23392,\"start\":23389},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":23792,\"start\":23791},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":23844,\"start\":23843},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24053,\"start\":24051},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":24096,\"start\":24094},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":24126,\"start\":24124},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":24151,\"start\":24149},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":24261,\"start\":24258},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":24338,\"start\":24334},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":24343,\"start\":24341},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":24507,\"start\":24505},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":24655,\"start\":24651},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":24734,\"start\":24730},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":25721,\"start\":25718},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":28289,\"start\":28286},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":28441,\"start\":28437},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":28555,\"start\":28551},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":28828,\"start\":28824},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":28892,\"start\":28889},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":31577,\"start\":31573},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":31963,\"start\":31960},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":34169,\"start\":34165},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34805,\"start\":34801},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":35144,\"start\":35141},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":35147,\"start\":35144},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":35776,\"start\":35772},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":40398,\"start\":40394},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":41300,\"start\":41296},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":41570,\"start\":41566},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":41573,\"start\":41570},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":41576,\"start\":41573},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":41579,\"start\":41576},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":42668,\"start\":42664},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":42710,\"start\":42706},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":42713,\"start\":42710},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":43306,\"start\":43302},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":43319,\"start\":43315},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":43382,\"start\":43378},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":43523,\"start\":43519},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":43548,\"start\":43544},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":43551,\"start\":43548},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":43638,\"start\":43635},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":43641,\"start\":43638},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":45177,\"start\":45174},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":45180,\"start\":45177},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":45183,\"start\":45180},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":45186,\"start\":45183},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":45573,\"start\":45572},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":45633,\"start\":45629},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":45995,\"start\":45991},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":46096,\"start\":46092},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":46581,\"start\":46577},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":46727,\"start\":46723},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":46949,\"start\":46945},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":47332,\"start\":47328},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":47504,\"start\":47503},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":47627,\"start\":47626},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":47760,\"start\":47756},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":47780,\"start\":47776},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":47930,\"start\":47926},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":47999,\"start\":47995},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":48374,\"start\":48370},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":48502,\"start\":48499},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":48817,\"start\":48813},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":48820,\"start\":48817},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":49032,\"start\":49028},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":58015,\"start\":58012},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":59562,\"start\":59558},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":59995,\"start\":59991},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":74948,\"start\":74944}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":64510,\"start\":64182},{\"attributes\":{\"id\":\"fig_1\"},\"end\":64678,\"start\":64511},{\"attributes\":{\"id\":\"fig_2\"},\"end\":64702,\"start\":64679},{\"attributes\":{\"id\":\"fig_3\"},\"end\":64856,\"start\":64703},{\"attributes\":{\"id\":\"fig_4\"},\"end\":65247,\"start\":64857},{\"attributes\":{\"id\":\"fig_5\"},\"end\":65599,\"start\":65248},{\"attributes\":{\"id\":\"fig_7\"},\"end\":65689,\"start\":65600},{\"attributes\":{\"id\":\"fig_8\"},\"end\":65768,\"start\":65690},{\"attributes\":{\"id\":\"fig_9\"},\"end\":65842,\"start\":65769},{\"attributes\":{\"id\":\"fig_10\"},\"end\":66307,\"start\":65843},{\"attributes\":{\"id\":\"fig_11\"},\"end\":66453,\"start\":66308},{\"attributes\":{\"id\":\"fig_12\"},\"end\":66568,\"start\":66454},{\"attributes\":{\"id\":\"fig_14\"},\"end\":66887,\"start\":66569},{\"attributes\":{\"id\":\"fig_15\"},\"end\":67924,\"start\":66888},{\"attributes\":{\"id\":\"fig_16\"},\"end\":68022,\"start\":67925},{\"attributes\":{\"id\":\"fig_17\"},\"end\":68095,\"start\":68023},{\"attributes\":{\"id\":\"fig_18\"},\"end\":68168,\"start\":68096},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":69536,\"start\":68169},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":70731,\"start\":69537},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":71938,\"start\":70732},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":72399,\"start\":71939},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":73134,\"start\":72400},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":73862,\"start\":73135},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":74591,\"start\":73863}]", "paragraph": "[{\"end\":4574,\"start\":3494},{\"end\":5803,\"start\":4576},{\"end\":6555,\"start\":5805},{\"end\":6611,\"start\":6557},{\"end\":8171,\"start\":6613},{\"end\":9214,\"start\":8205},{\"end\":10218,\"start\":9250},{\"end\":10706,\"start\":10220},{\"end\":11250,\"start\":10708},{\"end\":11937,\"start\":11252},{\"end\":13467,\"start\":11965},{\"end\":13600,\"start\":13533},{\"end\":14493,\"start\":13623},{\"end\":14532,\"start\":14495},{\"end\":15248,\"start\":14583},{\"end\":15521,\"start\":15250},{\"end\":16124,\"start\":15626},{\"end\":17330,\"start\":16145},{\"end\":17989,\"start\":17332},{\"end\":18901,\"start\":17991},{\"end\":19104,\"start\":18903},{\"end\":19488,\"start\":19123},{\"end\":21280,\"start\":19490},{\"end\":21725,\"start\":21374},{\"end\":21889,\"start\":21727},{\"end\":22453,\"start\":21900},{\"end\":23179,\"start\":22534},{\"end\":23487,\"start\":23181},{\"end\":23891,\"start\":23602},{\"end\":24166,\"start\":23982},{\"end\":24263,\"start\":24198},{\"end\":24540,\"start\":24270},{\"end\":24657,\"start\":24594},{\"end\":25063,\"start\":24664},{\"end\":25426,\"start\":25203},{\"end\":25485,\"start\":25480},{\"end\":25553,\"start\":25527},{\"end\":25972,\"start\":25591},{\"end\":26060,\"start\":25974},{\"end\":26911,\"start\":26094},{\"end\":27149,\"start\":26955},{\"end\":27438,\"start\":27306},{\"end\":27855,\"start\":27750},{\"end\":28115,\"start\":27939},{\"end\":28730,\"start\":28253},{\"end\":28998,\"start\":28732},{\"end\":29147,\"start\":29000},{\"end\":29468,\"start\":29170},{\"end\":29844,\"start\":29470},{\"end\":30111,\"start\":29900},{\"end\":30351,\"start\":30143},{\"end\":30510,\"start\":30397},{\"end\":30952,\"start\":30586},{\"end\":31496,\"start\":31020},{\"end\":31812,\"start\":31498},{\"end\":32048,\"start\":31845},{\"end\":32326,\"start\":32085},{\"end\":32776,\"start\":32342},{\"end\":33164,\"start\":32778},{\"end\":33294,\"start\":33166},{\"end\":33406,\"start\":33326},{\"end\":33872,\"start\":33547},{\"end\":34957,\"start\":33935},{\"end\":35209,\"start\":35036},{\"end\":35644,\"start\":35288},{\"end\":36711,\"start\":35724},{\"end\":37059,\"start\":36736},{\"end\":37446,\"start\":37243},{\"end\":37774,\"start\":37578},{\"end\":37985,\"start\":37790},{\"end\":38122,\"start\":38051},{\"end\":39141,\"start\":39083},{\"end\":39621,\"start\":39143},{\"end\":40316,\"start\":39881},{\"end\":40682,\"start\":40348},{\"end\":41108,\"start\":40716},{\"end\":41372,\"start\":41136},{\"end\":42077,\"start\":41452},{\"end\":42186,\"start\":42120},{\"end\":42532,\"start\":42391},{\"end\":42715,\"start\":42576},{\"end\":43111,\"start\":43001},{\"end\":43182,\"start\":43113},{\"end\":43946,\"start\":43209},{\"end\":44353,\"start\":43948},{\"end\":44892,\"start\":44514},{\"end\":45048,\"start\":44985},{\"end\":45397,\"start\":45079},{\"end\":45550,\"start\":45410},{\"end\":45574,\"start\":45552},{\"end\":46711,\"start\":45600},{\"end\":46806,\"start\":46713},{\"end\":47229,\"start\":46874},{\"end\":47628,\"start\":47231},{\"end\":47854,\"start\":47642},{\"end\":47909,\"start\":47856},{\"end\":47987,\"start\":47911},{\"end\":48181,\"start\":47989},{\"end\":48299,\"start\":48183},{\"end\":48361,\"start\":48301},{\"end\":48641,\"start\":48363},{\"end\":49504,\"start\":48643},{\"end\":50417,\"start\":49528},{\"end\":53236,\"start\":50437},{\"end\":53349,\"start\":53259},{\"end\":53625,\"start\":53358},{\"end\":55322,\"start\":53709},{\"end\":56551,\"start\":55384},{\"end\":57638,\"start\":56616},{\"end\":58839,\"start\":57719},{\"end\":59280,\"start\":58862},{\"end\":60416,\"start\":59282},{\"end\":60959,\"start\":60418},{\"end\":62250,\"start\":60972},{\"end\":64181,\"start\":62293}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13622,\"start\":13601},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14582,\"start\":14533},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15625,\"start\":15522},{\"attributes\":{\"id\":\"formula_3\"},\"end\":21373,\"start\":21281},{\"attributes\":{\"id\":\"formula_4\"},\"end\":23601,\"start\":23539},{\"attributes\":{\"id\":\"formula_5\"},\"end\":23981,\"start\":23892},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24197,\"start\":24167},{\"attributes\":{\"id\":\"formula_7\"},\"end\":24593,\"start\":24541},{\"attributes\":{\"id\":\"formula_8\"},\"end\":25202,\"start\":25064},{\"attributes\":{\"id\":\"formula_9\"},\"end\":25479,\"start\":25427},{\"attributes\":{\"id\":\"formula_10\"},\"end\":25526,\"start\":25486},{\"attributes\":{\"id\":\"formula_11\"},\"end\":26093,\"start\":26061},{\"attributes\":{\"id\":\"formula_12\"},\"end\":26954,\"start\":26912},{\"attributes\":{\"id\":\"formula_13\"},\"end\":27305,\"start\":27150},{\"attributes\":{\"id\":\"formula_14\"},\"end\":27749,\"start\":27439},{\"attributes\":{\"id\":\"formula_15\"},\"end\":27938,\"start\":27856},{\"attributes\":{\"id\":\"formula_16\"},\"end\":28205,\"start\":28116},{\"attributes\":{\"id\":\"formula_17\"},\"end\":28252,\"start\":28247},{\"attributes\":{\"id\":\"formula_18\"},\"end\":29169,\"start\":29148},{\"attributes\":{\"id\":\"formula_19\"},\"end\":29899,\"start\":29845},{\"attributes\":{\"id\":\"formula_20\"},\"end\":30142,\"start\":30112},{\"attributes\":{\"id\":\"formula_21\"},\"end\":30396,\"start\":30352},{\"attributes\":{\"id\":\"formula_22\"},\"end\":30585,\"start\":30511},{\"attributes\":{\"id\":\"formula_23\"},\"end\":31019,\"start\":30953},{\"attributes\":{\"id\":\"formula_24\"},\"end\":31844,\"start\":31813},{\"attributes\":{\"id\":\"formula_25\"},\"end\":32084,\"start\":32049},{\"attributes\":{\"id\":\"formula_26\"},\"end\":33325,\"start\":33295},{\"attributes\":{\"id\":\"formula_27\"},\"end\":33546,\"start\":33407},{\"attributes\":{\"id\":\"formula_28\"},\"end\":33934,\"start\":33873},{\"attributes\":{\"id\":\"formula_29\"},\"end\":35035,\"start\":34958},{\"attributes\":{\"id\":\"formula_30\"},\"end\":35287,\"start\":35210},{\"attributes\":{\"id\":\"formula_31\"},\"end\":35723,\"start\":35645},{\"attributes\":{\"id\":\"formula_32\"},\"end\":37242,\"start\":37060},{\"attributes\":{\"id\":\"formula_33\"},\"end\":37577,\"start\":37447},{\"attributes\":{\"id\":\"formula_34\"},\"end\":38050,\"start\":37986},{\"attributes\":{\"id\":\"formula_35\"},\"end\":38208,\"start\":38123},{\"attributes\":{\"id\":\"formula_36\"},\"end\":38334,\"start\":38208},{\"attributes\":{\"id\":\"formula_37\"},\"end\":38398,\"start\":38334},{\"attributes\":{\"id\":\"formula_38\"},\"end\":39058,\"start\":38398},{\"attributes\":{\"id\":\"formula_39\"},\"end\":39082,\"start\":39058},{\"attributes\":{\"id\":\"formula_40\"},\"end\":39880,\"start\":39622},{\"attributes\":{\"id\":\"formula_41\"},\"end\":40715,\"start\":40683},{\"attributes\":{\"id\":\"formula_42\"},\"end\":41135,\"start\":41109},{\"attributes\":{\"id\":\"formula_43\"},\"end\":41451,\"start\":41373},{\"attributes\":{\"id\":\"formula_44\"},\"end\":42119,\"start\":42078},{\"attributes\":{\"id\":\"formula_45\"},\"end\":42390,\"start\":42187},{\"attributes\":{\"id\":\"formula_46\"},\"end\":42575,\"start\":42533},{\"attributes\":{\"id\":\"formula_47\"},\"end\":42778,\"start\":42716},{\"attributes\":{\"id\":\"formula_48\"},\"end\":42951,\"start\":42778},{\"attributes\":{\"id\":\"formula_49\"},\"end\":43000,\"start\":42951},{\"attributes\":{\"id\":\"formula_50\"},\"end\":43208,\"start\":43183},{\"attributes\":{\"id\":\"formula_51\"},\"end\":44513,\"start\":44354},{\"attributes\":{\"id\":\"formula_52\"},\"end\":44984,\"start\":44893},{\"attributes\":{\"id\":\"formula_53\"},\"end\":46873,\"start\":46807}]", "table_ref": "[{\"end\":43110,\"start\":43103},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":50515,\"start\":50505},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":54753,\"start\":54746},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":55260,\"start\":55245},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":58149,\"start\":58139},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":58639,\"start\":58632}]", "section_header": "[{\"attributes\":{\"n\":\"2\"},\"end\":8203,\"start\":8174},{\"attributes\":{\"n\":\"2.2\"},\"end\":9248,\"start\":9217},{\"attributes\":{\"n\":\"2.3\"},\"end\":11963,\"start\":11940},{\"attributes\":{\"n\":\"3\"},\"end\":13531,\"start\":13470},{\"attributes\":{\"n\":\"3.2\"},\"end\":16143,\"start\":16127},{\"attributes\":{\"n\":\"3.3\"},\"end\":19121,\"start\":19107},{\"attributes\":{\"n\":\"4\"},\"end\":21898,\"start\":21892},{\"attributes\":{\"n\":\"4.1\"},\"end\":22497,\"start\":22456},{\"attributes\":{\"n\":\"4.1.1\"},\"end\":22532,\"start\":22500},{\"end\":23538,\"start\":23490},{\"end\":24268,\"start\":24266},{\"end\":24662,\"start\":24660},{\"attributes\":{\"n\":\"4.1.2\"},\"end\":25589,\"start\":25556},{\"attributes\":{\"n\":\"4.2\"},\"end\":28246,\"start\":28207},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":32340,\"start\":32329},{\"attributes\":{\"n\":\"4.3\"},\"end\":36734,\"start\":36714},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":37788,\"start\":37777},{\"attributes\":{\"n\":\"4.4\"},\"end\":40346,\"start\":40319},{\"attributes\":{\"n\":\"5\"},\"end\":45077,\"start\":45051},{\"attributes\":{\"n\":\"5.1\"},\"end\":45408,\"start\":45400},{\"attributes\":{\"n\":\"5.2\"},\"end\":45598,\"start\":45577},{\"attributes\":{\"n\":\"5.3\"},\"end\":47640,\"start\":47631},{\"attributes\":{\"n\":\"5.4\"},\"end\":49526,\"start\":49507},{\"end\":50427,\"start\":50420},{\"end\":50435,\"start\":50430},{\"attributes\":{\"n\":\"5.5\"},\"end\":53257,\"start\":53239},{\"end\":53356,\"start\":53352},{\"attributes\":{\"n\":\"5.5.1\"},\"end\":53707,\"start\":53628},{\"attributes\":{\"n\":\"5.5.2\"},\"end\":55382,\"start\":55325},{\"attributes\":{\"n\":\"5.5.3\"},\"end\":56614,\"start\":56554},{\"attributes\":{\"n\":\"5.5.4\"},\"end\":57717,\"start\":57641},{\"attributes\":{\"n\":\"6\"},\"end\":58860,\"start\":58842},{\"attributes\":{\"n\":\"6.1.2\"},\"end\":60970,\"start\":60962},{\"attributes\":{\"n\":\"6.1.3\"},\"end\":62261,\"start\":62253},{\"attributes\":{\"n\":\"6.2\"},\"end\":62291,\"start\":62264},{\"end\":64191,\"start\":64183},{\"end\":64520,\"start\":64512},{\"end\":64712,\"start\":64704},{\"end\":64866,\"start\":64858},{\"end\":65613,\"start\":65601},{\"end\":65703,\"start\":65691},{\"end\":65783,\"start\":65770},{\"end\":66324,\"start\":66309},{\"end\":66469,\"start\":66455},{\"end\":67934,\"start\":67926},{\"end\":68032,\"start\":68024},{\"end\":68105,\"start\":68097},{\"end\":69547,\"start\":69538},{\"end\":70742,\"start\":70733},{\"end\":71949,\"start\":71940},{\"end\":72410,\"start\":72401},{\"end\":73145,\"start\":73136},{\"end\":73873,\"start\":73864}]", "table": "[{\"end\":69536,\"start\":68408},{\"end\":70731,\"start\":69628},{\"end\":71938,\"start\":70826},{\"end\":72399,\"start\":72005},{\"end\":73134,\"start\":72584},{\"end\":73862,\"start\":73312},{\"end\":74591,\"start\":74048}]", "figure_caption": "[{\"end\":64510,\"start\":64193},{\"end\":64678,\"start\":64522},{\"end\":64702,\"start\":64681},{\"end\":64856,\"start\":64714},{\"end\":65247,\"start\":64868},{\"end\":65599,\"start\":65250},{\"end\":65689,\"start\":65615},{\"end\":65768,\"start\":65705},{\"end\":65842,\"start\":65786},{\"end\":66307,\"start\":65845},{\"end\":66453,\"start\":66327},{\"end\":66568,\"start\":66471},{\"end\":66887,\"start\":66571},{\"end\":67924,\"start\":66890},{\"end\":68022,\"start\":67936},{\"end\":68095,\"start\":68034},{\"end\":68168,\"start\":68107},{\"end\":68408,\"start\":68171},{\"end\":69628,\"start\":69549},{\"end\":70826,\"start\":70744},{\"end\":72005,\"start\":71951},{\"end\":72584,\"start\":72412},{\"end\":73312,\"start\":73147},{\"end\":74048,\"start\":73875}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4159,\"start\":4151},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16000,\"start\":15992},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16289,\"start\":16281},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16393,\"start\":16385},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18218,\"start\":18210},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19646,\"start\":19638},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21437,\"start\":21429},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":30673,\"start\":30665},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":39432,\"start\":39424},{\"end\":55039,\"start\":55031},{\"end\":55439,\"start\":55431},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":56750,\"start\":56742},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":61266,\"start\":61251}]", "bib_author_first_name": "[{\"end\":79373,\"start\":79365},{\"end\":79387,\"start\":79380},{\"end\":79389,\"start\":79388},{\"end\":79587,\"start\":79583},{\"end\":79601,\"start\":79597},{\"end\":79618,\"start\":79611},{\"end\":79630,\"start\":79625},{\"end\":79639,\"start\":79635},{\"end\":79656,\"start\":79648},{\"end\":80139,\"start\":80132},{\"end\":80150,\"start\":80144},{\"end\":80160,\"start\":80155},{\"end\":80173,\"start\":80166},{\"end\":80180,\"start\":80179},{\"end\":80186,\"start\":80181},{\"end\":80736,\"start\":80732},{\"end\":80746,\"start\":80742},{\"end\":80758,\"start\":80754},{\"end\":80771,\"start\":80767},{\"end\":81097,\"start\":81093},{\"end\":81113,\"start\":81109},{\"end\":81127,\"start\":81123},{\"end\":81141,\"start\":81137},{\"end\":81159,\"start\":81151},{\"end\":81177,\"start\":81169},{\"end\":81185,\"start\":81178},{\"end\":81458,\"start\":81452},{\"end\":81472,\"start\":81468},{\"end\":81488,\"start\":81481},{\"end\":81504,\"start\":81499},{\"end\":81879,\"start\":81868},{\"end\":81891,\"start\":81888},{\"end\":81904,\"start\":81900},{\"end\":81917,\"start\":81914},{\"end\":81930,\"start\":81926},{\"end\":81944,\"start\":81938},{\"end\":81962,\"start\":81955},{\"end\":81964,\"start\":81963},{\"end\":82396,\"start\":82395},{\"end\":82398,\"start\":82397},{\"end\":82613,\"start\":82602},{\"end\":82615,\"start\":82614},{\"end\":82630,\"start\":82624},{\"end\":82639,\"start\":82638},{\"end\":83090,\"start\":83083},{\"end\":83103,\"start\":83101},{\"end\":83414,\"start\":83408},{\"end\":83426,\"start\":83421},{\"end\":83438,\"start\":83433},{\"end\":83842,\"start\":83838},{\"end\":83857,\"start\":83853},{\"end\":83873,\"start\":83866},{\"end\":83886,\"start\":83882},{\"end\":84325,\"start\":84320},{\"end\":84337,\"start\":84331},{\"end\":84347,\"start\":84343},{\"end\":84359,\"start\":84353},{\"end\":84371,\"start\":84364},{\"end\":84384,\"start\":84378},{\"end\":84400,\"start\":84392},{\"end\":84408,\"start\":84405},{\"end\":84419,\"start\":84415},{\"end\":84924,\"start\":84919},{\"end\":84943,\"start\":84935},{\"end\":84960,\"start\":84953},{\"end\":84972,\"start\":84966},{\"end\":84986,\"start\":84980},{\"end\":84990,\"start\":84987},{\"end\":85003,\"start\":84998},{\"end\":85016,\"start\":85011},{\"end\":85026,\"start\":85024},{\"end\":85035,\"start\":85031},{\"end\":85050,\"start\":85045},{\"end\":85072,\"start\":85063},{\"end\":85577,\"start\":85570},{\"end\":85579,\"start\":85578},{\"end\":85596,\"start\":85588},{\"end\":86179,\"start\":86171},{\"end\":86190,\"start\":86186},{\"end\":86208,\"start\":86200},{\"end\":86827,\"start\":86824},{\"end\":86837,\"start\":86833},{\"end\":86849,\"start\":86843},{\"end\":86861,\"start\":86858},{\"end\":86876,\"start\":86869},{\"end\":86891,\"start\":86885},{\"end\":86906,\"start\":86898},{\"end\":87333,\"start\":87326},{\"end\":87346,\"start\":87339},{\"end\":87360,\"start\":87353},{\"end\":87372,\"start\":87365},{\"end\":87385,\"start\":87377},{\"end\":87976,\"start\":87969},{\"end\":87988,\"start\":87982},{\"end\":87997,\"start\":87993},{\"end\":88010,\"start\":88003},{\"end\":88023,\"start\":88017},{\"end\":88539,\"start\":88534},{\"end\":88541,\"start\":88540},{\"end\":88823,\"start\":88818},{\"end\":88832,\"start\":88828},{\"end\":88841,\"start\":88839},{\"end\":88852,\"start\":88848},{\"end\":89172,\"start\":89164},{\"end\":89716,\"start\":89708},{\"end\":89732,\"start\":89727},{\"end\":89745,\"start\":89741},{\"end\":89757,\"start\":89751},{\"end\":89773,\"start\":89769},{\"end\":90177,\"start\":90169},{\"end\":90193,\"start\":90188},{\"end\":90206,\"start\":90202},{\"end\":90218,\"start\":90212},{\"end\":90235,\"start\":90230},{\"end\":90251,\"start\":90247},{\"end\":90640,\"start\":90632},{\"end\":90656,\"start\":90651},{\"end\":90658,\"start\":90657},{\"end\":90671,\"start\":90667},{\"end\":90683,\"start\":90677},{\"end\":90699,\"start\":90695},{\"end\":91194,\"start\":91186},{\"end\":91210,\"start\":91205},{\"end\":91230,\"start\":91224},{\"end\":91660,\"start\":91654},{\"end\":91662,\"start\":91661},{\"end\":91836,\"start\":91835},{\"end\":91838,\"start\":91837},{\"end\":91855,\"start\":91849},{\"end\":91857,\"start\":91856},{\"end\":92126,\"start\":92122},{\"end\":92139,\"start\":92135},{\"end\":92156,\"start\":92151},{\"end\":92177,\"start\":92173},{\"end\":92191,\"start\":92183},{\"end\":92206,\"start\":92202},{\"end\":92217,\"start\":92212},{\"end\":92231,\"start\":92226},{\"end\":92247,\"start\":92243},{\"end\":92720,\"start\":92716},{\"end\":92733,\"start\":92729},{\"end\":92745,\"start\":92739},{\"end\":92765,\"start\":92757},{\"end\":92781,\"start\":92776},{\"end\":92794,\"start\":92790},{\"end\":93152,\"start\":93145},{\"end\":93168,\"start\":93163},{\"end\":93186,\"start\":93177},{\"end\":93204,\"start\":93196},{\"end\":93222,\"start\":93214},{\"end\":93240,\"start\":93231},{\"end\":93829,\"start\":93823},{\"end\":93841,\"start\":93835},{\"end\":93852,\"start\":93847},{\"end\":93861,\"start\":93858},{\"end\":93877,\"start\":93869},{\"end\":94363,\"start\":94356},{\"end\":94375,\"start\":94370},{\"end\":94393,\"start\":94386},{\"end\":94407,\"start\":94401},{\"end\":94860,\"start\":94855},{\"end\":94879,\"start\":94871},{\"end\":94895,\"start\":94886},{\"end\":94910,\"start\":94904},{\"end\":95333,\"start\":95328},{\"end\":95625,\"start\":95619},{\"end\":96096,\"start\":96090},{\"end\":96668,\"start\":96663},{\"end\":96678,\"start\":96673},{\"end\":96691,\"start\":96685},{\"end\":96706,\"start\":96699},{\"end\":96719,\"start\":96713},{\"end\":96732,\"start\":96725},{\"end\":96742,\"start\":96738},{\"end\":96755,\"start\":96747},{\"end\":97137,\"start\":97132},{\"end\":97154,\"start\":97149},{\"end\":97170,\"start\":97162},{\"end\":97601,\"start\":97594},{\"end\":97617,\"start\":97614},{\"end\":97636,\"start\":97630},{\"end\":98018,\"start\":98011},{\"end\":98020,\"start\":98019},{\"end\":98227,\"start\":98220},{\"end\":98233,\"start\":98228},{\"end\":98246,\"start\":98240},{\"end\":98262,\"start\":98257},{\"end\":98279,\"start\":98272},{\"end\":98707,\"start\":98703},{\"end\":98722,\"start\":98716},{\"end\":98741,\"start\":98735},{\"end\":98759,\"start\":98752},{\"end\":99234,\"start\":99226},{\"end\":99247,\"start\":99241},{\"end\":99257,\"start\":99253},{\"end\":99279,\"start\":99272},{\"end\":99292,\"start\":99284},{\"end\":99866,\"start\":99858},{\"end\":99879,\"start\":99873},{\"end\":99895,\"start\":99889},{\"end\":99905,\"start\":99901},{\"end\":99928,\"start\":99920},{\"end\":100512,\"start\":100509},{\"end\":100526,\"start\":100519},{\"end\":101064,\"start\":101057},{\"end\":101078,\"start\":101071},{\"end\":101096,\"start\":101090},{\"end\":101110,\"start\":101106},{\"end\":101665,\"start\":101658},{\"end\":101677,\"start\":101672},{\"end\":101695,\"start\":101688},{\"end\":101713,\"start\":101707},{\"end\":101727,\"start\":101723},{\"end\":102212,\"start\":102205},{\"end\":102224,\"start\":102219},{\"end\":102234,\"start\":102229},{\"end\":102249,\"start\":102245},{\"end\":102265,\"start\":102261},{\"end\":102782,\"start\":102777},{\"end\":102792,\"start\":102787},{\"end\":102805,\"start\":102797},{\"end\":102816,\"start\":102812},{\"end\":103393,\"start\":103387},{\"end\":103407,\"start\":103399},{\"end\":103827,\"start\":103821},{\"end\":103843,\"start\":103835},{\"end\":103851,\"start\":103848},{\"end\":104253,\"start\":104249},{\"end\":104262,\"start\":104261},{\"end\":104264,\"start\":104263},{\"end\":104283,\"start\":104275},{\"end\":104591,\"start\":104583},{\"end\":104601,\"start\":104597},{\"end\":104613,\"start\":104608},{\"end\":104625,\"start\":104620},{\"end\":104635,\"start\":104632},{\"end\":104646,\"start\":104641},{\"end\":105169,\"start\":105161},{\"end\":105179,\"start\":105175},{\"end\":105191,\"start\":105186},{\"end\":105203,\"start\":105198},{\"end\":105213,\"start\":105210},{\"end\":105223,\"start\":105219},{\"end\":105233,\"start\":105228}]", "bib_author_last_name": "[{\"end\":79252,\"start\":79243},{\"end\":79378,\"start\":79374},{\"end\":79395,\"start\":79390},{\"end\":79402,\"start\":79397},{\"end\":79595,\"start\":79588},{\"end\":79609,\"start\":79602},{\"end\":79623,\"start\":79619},{\"end\":79633,\"start\":79631},{\"end\":79646,\"start\":79640},{\"end\":79665,\"start\":79657},{\"end\":80142,\"start\":80140},{\"end\":80153,\"start\":80151},{\"end\":80164,\"start\":80161},{\"end\":80177,\"start\":80174},{\"end\":80192,\"start\":80187},{\"end\":80740,\"start\":80737},{\"end\":80752,\"start\":80747},{\"end\":80765,\"start\":80759},{\"end\":80780,\"start\":80772},{\"end\":81107,\"start\":81098},{\"end\":81121,\"start\":81114},{\"end\":81135,\"start\":81128},{\"end\":81149,\"start\":81142},{\"end\":81167,\"start\":81160},{\"end\":81193,\"start\":81186},{\"end\":81466,\"start\":81459},{\"end\":81479,\"start\":81473},{\"end\":81497,\"start\":81489},{\"end\":81514,\"start\":81505},{\"end\":81886,\"start\":81880},{\"end\":81898,\"start\":81892},{\"end\":81912,\"start\":81905},{\"end\":81924,\"start\":81918},{\"end\":81936,\"start\":81931},{\"end\":81953,\"start\":81945},{\"end\":81974,\"start\":81965},{\"end\":82410,\"start\":82399},{\"end\":82418,\"start\":82412},{\"end\":82622,\"start\":82616},{\"end\":82636,\"start\":82631},{\"end\":82644,\"start\":82640},{\"end\":82648,\"start\":82646},{\"end\":83099,\"start\":83091},{\"end\":83109,\"start\":83104},{\"end\":83419,\"start\":83415},{\"end\":83431,\"start\":83427},{\"end\":83443,\"start\":83439},{\"end\":83851,\"start\":83843},{\"end\":83864,\"start\":83858},{\"end\":83880,\"start\":83874},{\"end\":83893,\"start\":83887},{\"end\":84329,\"start\":84326},{\"end\":84341,\"start\":84338},{\"end\":84351,\"start\":84348},{\"end\":84362,\"start\":84360},{\"end\":84376,\"start\":84372},{\"end\":84390,\"start\":84385},{\"end\":84403,\"start\":84401},{\"end\":84413,\"start\":84409},{\"end\":84422,\"start\":84420},{\"end\":84933,\"start\":84925},{\"end\":84951,\"start\":84944},{\"end\":84964,\"start\":84961},{\"end\":84978,\"start\":84973},{\"end\":84996,\"start\":84991},{\"end\":85009,\"start\":85004},{\"end\":85022,\"start\":85017},{\"end\":85029,\"start\":85027},{\"end\":85043,\"start\":85036},{\"end\":85061,\"start\":85051},{\"end\":85080,\"start\":85073},{\"end\":85586,\"start\":85580},{\"end\":85607,\"start\":85597},{\"end\":86184,\"start\":86180},{\"end\":86198,\"start\":86191},{\"end\":86217,\"start\":86209},{\"end\":86831,\"start\":86828},{\"end\":86841,\"start\":86838},{\"end\":86856,\"start\":86850},{\"end\":86867,\"start\":86862},{\"end\":86883,\"start\":86877},{\"end\":86896,\"start\":86892},{\"end\":86916,\"start\":86907},{\"end\":87337,\"start\":87334},{\"end\":87351,\"start\":87347},{\"end\":87363,\"start\":87361},{\"end\":87375,\"start\":87373},{\"end\":87388,\"start\":87386},{\"end\":87980,\"start\":87977},{\"end\":87991,\"start\":87989},{\"end\":88001,\"start\":87998},{\"end\":88015,\"start\":88011},{\"end\":88029,\"start\":88024},{\"end\":88549,\"start\":88542},{\"end\":88826,\"start\":88824},{\"end\":88837,\"start\":88833},{\"end\":88846,\"start\":88842},{\"end\":88855,\"start\":88853},{\"end\":89181,\"start\":89173},{\"end\":89725,\"start\":89717},{\"end\":89739,\"start\":89733},{\"end\":89749,\"start\":89746},{\"end\":89767,\"start\":89758},{\"end\":89777,\"start\":89774},{\"end\":90186,\"start\":90178},{\"end\":90200,\"start\":90194},{\"end\":90210,\"start\":90207},{\"end\":90228,\"start\":90219},{\"end\":90245,\"start\":90236},{\"end\":90255,\"start\":90252},{\"end\":90649,\"start\":90641},{\"end\":90665,\"start\":90659},{\"end\":90675,\"start\":90672},{\"end\":90693,\"start\":90684},{\"end\":90703,\"start\":90700},{\"end\":91203,\"start\":91195},{\"end\":91222,\"start\":91211},{\"end\":91239,\"start\":91231},{\"end\":91667,\"start\":91663},{\"end\":91847,\"start\":91839},{\"end\":91864,\"start\":91858},{\"end\":91871,\"start\":91866},{\"end\":92133,\"start\":92127},{\"end\":92149,\"start\":92140},{\"end\":92171,\"start\":92157},{\"end\":92181,\"start\":92178},{\"end\":92200,\"start\":92192},{\"end\":92210,\"start\":92207},{\"end\":92224,\"start\":92218},{\"end\":92241,\"start\":92232},{\"end\":92251,\"start\":92248},{\"end\":92727,\"start\":92721},{\"end\":92737,\"start\":92734},{\"end\":92755,\"start\":92746},{\"end\":92774,\"start\":92766},{\"end\":92788,\"start\":92782},{\"end\":92798,\"start\":92795},{\"end\":93161,\"start\":93153},{\"end\":93175,\"start\":93169},{\"end\":93194,\"start\":93187},{\"end\":93212,\"start\":93205},{\"end\":93229,\"start\":93223},{\"end\":93250,\"start\":93241},{\"end\":93257,\"start\":93252},{\"end\":93833,\"start\":93830},{\"end\":93845,\"start\":93842},{\"end\":93856,\"start\":93853},{\"end\":93867,\"start\":93862},{\"end\":93880,\"start\":93878},{\"end\":94368,\"start\":94364},{\"end\":94384,\"start\":94376},{\"end\":94399,\"start\":94394},{\"end\":94413,\"start\":94408},{\"end\":94869,\"start\":94861},{\"end\":94884,\"start\":94880},{\"end\":94902,\"start\":94896},{\"end\":94914,\"start\":94911},{\"end\":95341,\"start\":95334},{\"end\":95636,\"start\":95626},{\"end\":95654,\"start\":95638},{\"end\":96107,\"start\":96097},{\"end\":96125,\"start\":96109},{\"end\":96671,\"start\":96669},{\"end\":96683,\"start\":96679},{\"end\":96697,\"start\":96692},{\"end\":96711,\"start\":96707},{\"end\":96723,\"start\":96720},{\"end\":96736,\"start\":96733},{\"end\":96745,\"start\":96743},{\"end\":96758,\"start\":96756},{\"end\":97147,\"start\":97138},{\"end\":97160,\"start\":97155},{\"end\":97179,\"start\":97171},{\"end\":97612,\"start\":97602},{\"end\":97628,\"start\":97618},{\"end\":97642,\"start\":97637},{\"end\":98030,\"start\":98021},{\"end\":98238,\"start\":98234},{\"end\":98255,\"start\":98247},{\"end\":98270,\"start\":98263},{\"end\":98285,\"start\":98280},{\"end\":98714,\"start\":98708},{\"end\":98733,\"start\":98723},{\"end\":98750,\"start\":98742},{\"end\":98768,\"start\":98760},{\"end\":99239,\"start\":99235},{\"end\":99251,\"start\":99248},{\"end\":99270,\"start\":99258},{\"end\":99282,\"start\":99280},{\"end\":99297,\"start\":99293},{\"end\":99871,\"start\":99867},{\"end\":99887,\"start\":99880},{\"end\":99899,\"start\":99896},{\"end\":99918,\"start\":99906},{\"end\":99933,\"start\":99929},{\"end\":100517,\"start\":100513},{\"end\":100530,\"start\":100527},{\"end\":101069,\"start\":101065},{\"end\":101088,\"start\":101079},{\"end\":101104,\"start\":101097},{\"end\":101117,\"start\":101111},{\"end\":101670,\"start\":101666},{\"end\":101686,\"start\":101678},{\"end\":101705,\"start\":101696},{\"end\":101721,\"start\":101714},{\"end\":101734,\"start\":101728},{\"end\":102217,\"start\":102213},{\"end\":102227,\"start\":102225},{\"end\":102243,\"start\":102235},{\"end\":102259,\"start\":102250},{\"end\":102272,\"start\":102266},{\"end\":102785,\"start\":102783},{\"end\":102795,\"start\":102793},{\"end\":102810,\"start\":102806},{\"end\":102820,\"start\":102817},{\"end\":103397,\"start\":103394},{\"end\":103416,\"start\":103408},{\"end\":103833,\"start\":103828},{\"end\":103846,\"start\":103844},{\"end\":103856,\"start\":103852},{\"end\":104259,\"start\":104254},{\"end\":104273,\"start\":104265},{\"end\":104288,\"start\":104284},{\"end\":104296,\"start\":104290},{\"end\":104595,\"start\":104592},{\"end\":104606,\"start\":104602},{\"end\":104618,\"start\":104614},{\"end\":104630,\"start\":104626},{\"end\":104639,\"start\":104636},{\"end\":104651,\"start\":104647},{\"end\":105173,\"start\":105170},{\"end\":105184,\"start\":105180},{\"end\":105196,\"start\":105192},{\"end\":105208,\"start\":105204},{\"end\":105217,\"start\":105214},{\"end\":105226,\"start\":105224},{\"end\":105238,\"start\":105234}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":79329,\"start\":79222},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":2015927},\"end\":79523,\"start\":79331},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":53667926},\"end\":80067,\"start\":79525},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":4896255},\"end\":80657,\"start\":80069},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":203707286},\"end\":81046,\"start\":80659},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":8577357},\"end\":81413,\"start\":81048},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":11777570},\"end\":81825,\"start\":81415},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":11168734},\"end\":82338,\"start\":81827},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":397316},\"end\":82552,\"start\":82340},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":8604596},\"end\":83018,\"start\":82554},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":207172170},\"end\":83406,\"start\":83020},{\"attributes\":{\"doi\":\"arXiv:2010.03240\",\"id\":\"b11\"},\"end\":83778,\"start\":83408},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":2625350},\"end\":84252,\"start\":83780},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":224280759},\"end\":84876,\"start\":84254},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":1145979},\"end\":85486,\"start\":84878},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":7992408},\"end\":86094,\"start\":85488},{\"attributes\":{\"doi\":\"10.1145/3331184.3331238\",\"id\":\"b16\",\"matched_paper_id\":53220549},\"end\":86789,\"start\":86096},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":14992423},\"end\":87251,\"start\":86791},{\"attributes\":{\"doi\":\"10.24963/ijcai.2017/239\",\"id\":\"b18\",\"matched_paper_id\":970388},\"end\":87873,\"start\":87253},{\"attributes\":{\"doi\":\"10.1145/3298689.3347033\",\"id\":\"b19\",\"matched_paper_id\":202639662},\"end\":88484,\"start\":87875},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":30028243},\"end\":88746,\"start\":88486},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":67856498},\"end\":89125,\"start\":88748},{\"attributes\":{\"doi\":\"10.1145/1150402.1150429\",\"id\":\"b22\",\"matched_paper_id\":5155714},\"end\":89642,\"start\":89127},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":2739209},\"end\":90070,\"start\":89644},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":5700664},\"end\":90566,\"start\":90072},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":2739209},\"end\":91136,\"start\":90568},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":300418},\"end\":91603,\"start\":91138},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":9426884},\"end\":91833,\"start\":91605},{\"attributes\":{\"id\":\"b28\"},\"end\":92050,\"start\":91835},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":18726071},\"end\":92633,\"start\":92052},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":17362030},\"end\":93075,\"start\":92635},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":15492438},\"end\":93774,\"start\":93077},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":203592202},\"end\":94277,\"start\":93776},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":244169610},\"end\":94774,\"start\":94279},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":941047},\"end\":95267,\"start\":94776},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":15996572},\"end\":95568,\"start\":95269},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":52235331},\"end\":96029,\"start\":95570},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":218684929},\"end\":96567,\"start\":96031},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":53112894},\"end\":97075,\"start\":96569},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":14480436},\"end\":97526,\"start\":97077},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":14669618},\"end\":97968,\"start\":97528},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":117640044},\"end\":98176,\"start\":97970},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":8518974},\"end\":98639,\"start\":98178},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":1105363},\"end\":99152,\"start\":98641},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":182952337},\"end\":99787,\"start\":99154},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":29149768},\"end\":100418,\"start\":99789},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":17186086},\"end\":100998,\"start\":100420},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":15989814},\"end\":101581,\"start\":101000},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":21054674},\"end\":102145,\"start\":101583},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":53033881},\"end\":102689,\"start\":102147},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":13709505},\"end\":103300,\"start\":102691},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":13141692},\"end\":103770,\"start\":103302},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":3426064},\"end\":104159,\"start\":103772},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":10787208},\"end\":104513,\"start\":104161},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":1220294},\"end\":105105,\"start\":104515},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":14499346},\"end\":105716,\"start\":105107}]", "bib_title": "[{\"end\":79363,\"start\":79331},{\"end\":79581,\"start\":79525},{\"end\":80130,\"start\":80069},{\"end\":80730,\"start\":80659},{\"end\":81091,\"start\":81048},{\"end\":81450,\"start\":81415},{\"end\":81866,\"start\":81827},{\"end\":82393,\"start\":82340},{\"end\":82600,\"start\":82554},{\"end\":83081,\"start\":83020},{\"end\":83836,\"start\":83780},{\"end\":84318,\"start\":84254},{\"end\":84917,\"start\":84878},{\"end\":85568,\"start\":85488},{\"end\":86169,\"start\":86096},{\"end\":86822,\"start\":86791},{\"end\":87324,\"start\":87253},{\"end\":87967,\"start\":87875},{\"end\":88532,\"start\":88486},{\"end\":88816,\"start\":88748},{\"end\":89162,\"start\":89127},{\"end\":89706,\"start\":89644},{\"end\":90167,\"start\":90072},{\"end\":90630,\"start\":90568},{\"end\":91184,\"start\":91138},{\"end\":91652,\"start\":91605},{\"end\":92120,\"start\":92052},{\"end\":92714,\"start\":92635},{\"end\":93143,\"start\":93077},{\"end\":93821,\"start\":93776},{\"end\":94354,\"start\":94279},{\"end\":94853,\"start\":94776},{\"end\":95326,\"start\":95269},{\"end\":95617,\"start\":95570},{\"end\":96088,\"start\":96031},{\"end\":96661,\"start\":96569},{\"end\":97130,\"start\":97077},{\"end\":97592,\"start\":97528},{\"end\":98009,\"start\":97970},{\"end\":98218,\"start\":98178},{\"end\":98701,\"start\":98641},{\"end\":99224,\"start\":99154},{\"end\":99856,\"start\":99789},{\"end\":100507,\"start\":100420},{\"end\":101055,\"start\":101000},{\"end\":101656,\"start\":101583},{\"end\":102203,\"start\":102147},{\"end\":102775,\"start\":102691},{\"end\":103385,\"start\":103302},{\"end\":103819,\"start\":103772},{\"end\":104247,\"start\":104161},{\"end\":104581,\"start\":104515},{\"end\":105159,\"start\":105107}]", "bib_author": "[{\"end\":79254,\"start\":79243},{\"end\":79380,\"start\":79365},{\"end\":79397,\"start\":79380},{\"end\":79404,\"start\":79397},{\"end\":79597,\"start\":79583},{\"end\":79611,\"start\":79597},{\"end\":79625,\"start\":79611},{\"end\":79635,\"start\":79625},{\"end\":79648,\"start\":79635},{\"end\":79667,\"start\":79648},{\"end\":80144,\"start\":80132},{\"end\":80155,\"start\":80144},{\"end\":80166,\"start\":80155},{\"end\":80179,\"start\":80166},{\"end\":80194,\"start\":80179},{\"end\":80742,\"start\":80732},{\"end\":80754,\"start\":80742},{\"end\":80767,\"start\":80754},{\"end\":80782,\"start\":80767},{\"end\":81109,\"start\":81093},{\"end\":81123,\"start\":81109},{\"end\":81137,\"start\":81123},{\"end\":81151,\"start\":81137},{\"end\":81169,\"start\":81151},{\"end\":81195,\"start\":81169},{\"end\":81468,\"start\":81452},{\"end\":81481,\"start\":81468},{\"end\":81499,\"start\":81481},{\"end\":81516,\"start\":81499},{\"end\":81888,\"start\":81868},{\"end\":81900,\"start\":81888},{\"end\":81914,\"start\":81900},{\"end\":81926,\"start\":81914},{\"end\":81938,\"start\":81926},{\"end\":81955,\"start\":81938},{\"end\":81976,\"start\":81955},{\"end\":82412,\"start\":82395},{\"end\":82420,\"start\":82412},{\"end\":82624,\"start\":82602},{\"end\":82638,\"start\":82624},{\"end\":82646,\"start\":82638},{\"end\":82650,\"start\":82646},{\"end\":83101,\"start\":83083},{\"end\":83111,\"start\":83101},{\"end\":83421,\"start\":83408},{\"end\":83433,\"start\":83421},{\"end\":83445,\"start\":83433},{\"end\":83853,\"start\":83838},{\"end\":83866,\"start\":83853},{\"end\":83882,\"start\":83866},{\"end\":83895,\"start\":83882},{\"end\":84331,\"start\":84320},{\"end\":84343,\"start\":84331},{\"end\":84353,\"start\":84343},{\"end\":84364,\"start\":84353},{\"end\":84378,\"start\":84364},{\"end\":84392,\"start\":84378},{\"end\":84405,\"start\":84392},{\"end\":84415,\"start\":84405},{\"end\":84424,\"start\":84415},{\"end\":84935,\"start\":84919},{\"end\":84953,\"start\":84935},{\"end\":84966,\"start\":84953},{\"end\":84980,\"start\":84966},{\"end\":84998,\"start\":84980},{\"end\":85011,\"start\":84998},{\"end\":85024,\"start\":85011},{\"end\":85031,\"start\":85024},{\"end\":85045,\"start\":85031},{\"end\":85063,\"start\":85045},{\"end\":85082,\"start\":85063},{\"end\":85588,\"start\":85570},{\"end\":85609,\"start\":85588},{\"end\":86186,\"start\":86171},{\"end\":86200,\"start\":86186},{\"end\":86219,\"start\":86200},{\"end\":86833,\"start\":86824},{\"end\":86843,\"start\":86833},{\"end\":86858,\"start\":86843},{\"end\":86869,\"start\":86858},{\"end\":86885,\"start\":86869},{\"end\":86898,\"start\":86885},{\"end\":86918,\"start\":86898},{\"end\":87339,\"start\":87326},{\"end\":87353,\"start\":87339},{\"end\":87365,\"start\":87353},{\"end\":87377,\"start\":87365},{\"end\":87390,\"start\":87377},{\"end\":87982,\"start\":87969},{\"end\":87993,\"start\":87982},{\"end\":88003,\"start\":87993},{\"end\":88017,\"start\":88003},{\"end\":88031,\"start\":88017},{\"end\":88551,\"start\":88534},{\"end\":88828,\"start\":88818},{\"end\":88839,\"start\":88828},{\"end\":88848,\"start\":88839},{\"end\":88857,\"start\":88848},{\"end\":89183,\"start\":89164},{\"end\":89727,\"start\":89708},{\"end\":89741,\"start\":89727},{\"end\":89751,\"start\":89741},{\"end\":89769,\"start\":89751},{\"end\":89779,\"start\":89769},{\"end\":90188,\"start\":90169},{\"end\":90202,\"start\":90188},{\"end\":90212,\"start\":90202},{\"end\":90230,\"start\":90212},{\"end\":90247,\"start\":90230},{\"end\":90257,\"start\":90247},{\"end\":90651,\"start\":90632},{\"end\":90667,\"start\":90651},{\"end\":90677,\"start\":90667},{\"end\":90695,\"start\":90677},{\"end\":90705,\"start\":90695},{\"end\":91205,\"start\":91186},{\"end\":91224,\"start\":91205},{\"end\":91241,\"start\":91224},{\"end\":91669,\"start\":91654},{\"end\":91849,\"start\":91835},{\"end\":91866,\"start\":91849},{\"end\":91873,\"start\":91866},{\"end\":92135,\"start\":92122},{\"end\":92151,\"start\":92135},{\"end\":92173,\"start\":92151},{\"end\":92183,\"start\":92173},{\"end\":92202,\"start\":92183},{\"end\":92212,\"start\":92202},{\"end\":92226,\"start\":92212},{\"end\":92243,\"start\":92226},{\"end\":92253,\"start\":92243},{\"end\":92729,\"start\":92716},{\"end\":92739,\"start\":92729},{\"end\":92757,\"start\":92739},{\"end\":92776,\"start\":92757},{\"end\":92790,\"start\":92776},{\"end\":92800,\"start\":92790},{\"end\":93163,\"start\":93145},{\"end\":93177,\"start\":93163},{\"end\":93196,\"start\":93177},{\"end\":93214,\"start\":93196},{\"end\":93231,\"start\":93214},{\"end\":93252,\"start\":93231},{\"end\":93259,\"start\":93252},{\"end\":93835,\"start\":93823},{\"end\":93847,\"start\":93835},{\"end\":93858,\"start\":93847},{\"end\":93869,\"start\":93858},{\"end\":93882,\"start\":93869},{\"end\":94370,\"start\":94356},{\"end\":94386,\"start\":94370},{\"end\":94401,\"start\":94386},{\"end\":94415,\"start\":94401},{\"end\":94871,\"start\":94855},{\"end\":94886,\"start\":94871},{\"end\":94904,\"start\":94886},{\"end\":94916,\"start\":94904},{\"end\":95343,\"start\":95328},{\"end\":95638,\"start\":95619},{\"end\":95656,\"start\":95638},{\"end\":96109,\"start\":96090},{\"end\":96127,\"start\":96109},{\"end\":96673,\"start\":96663},{\"end\":96685,\"start\":96673},{\"end\":96699,\"start\":96685},{\"end\":96713,\"start\":96699},{\"end\":96725,\"start\":96713},{\"end\":96738,\"start\":96725},{\"end\":96747,\"start\":96738},{\"end\":96760,\"start\":96747},{\"end\":97149,\"start\":97132},{\"end\":97162,\"start\":97149},{\"end\":97181,\"start\":97162},{\"end\":97614,\"start\":97594},{\"end\":97630,\"start\":97614},{\"end\":97644,\"start\":97630},{\"end\":98032,\"start\":98011},{\"end\":98240,\"start\":98220},{\"end\":98257,\"start\":98240},{\"end\":98272,\"start\":98257},{\"end\":98287,\"start\":98272},{\"end\":98716,\"start\":98703},{\"end\":98735,\"start\":98716},{\"end\":98752,\"start\":98735},{\"end\":98770,\"start\":98752},{\"end\":99241,\"start\":99226},{\"end\":99253,\"start\":99241},{\"end\":99272,\"start\":99253},{\"end\":99284,\"start\":99272},{\"end\":99299,\"start\":99284},{\"end\":99873,\"start\":99858},{\"end\":99889,\"start\":99873},{\"end\":99901,\"start\":99889},{\"end\":99920,\"start\":99901},{\"end\":99935,\"start\":99920},{\"end\":100519,\"start\":100509},{\"end\":100532,\"start\":100519},{\"end\":101071,\"start\":101057},{\"end\":101090,\"start\":101071},{\"end\":101106,\"start\":101090},{\"end\":101119,\"start\":101106},{\"end\":101672,\"start\":101658},{\"end\":101688,\"start\":101672},{\"end\":101707,\"start\":101688},{\"end\":101723,\"start\":101707},{\"end\":101736,\"start\":101723},{\"end\":102219,\"start\":102205},{\"end\":102229,\"start\":102219},{\"end\":102245,\"start\":102229},{\"end\":102261,\"start\":102245},{\"end\":102274,\"start\":102261},{\"end\":102787,\"start\":102777},{\"end\":102797,\"start\":102787},{\"end\":102812,\"start\":102797},{\"end\":102822,\"start\":102812},{\"end\":103399,\"start\":103387},{\"end\":103418,\"start\":103399},{\"end\":103835,\"start\":103821},{\"end\":103848,\"start\":103835},{\"end\":103858,\"start\":103848},{\"end\":104261,\"start\":104249},{\"end\":104275,\"start\":104261},{\"end\":104290,\"start\":104275},{\"end\":104298,\"start\":104290},{\"end\":104597,\"start\":104583},{\"end\":104608,\"start\":104597},{\"end\":104620,\"start\":104608},{\"end\":104632,\"start\":104620},{\"end\":104641,\"start\":104632},{\"end\":104653,\"start\":104641},{\"end\":105175,\"start\":105161},{\"end\":105186,\"start\":105175},{\"end\":105198,\"start\":105186},{\"end\":105210,\"start\":105198},{\"end\":105219,\"start\":105210},{\"end\":105228,\"start\":105219},{\"end\":105240,\"start\":105228}]", "bib_venue": "[{\"end\":79818,\"start\":79751},{\"end\":80399,\"start\":80305},{\"end\":81635,\"start\":81584},{\"end\":82099,\"start\":82046},{\"end\":82811,\"start\":82739},{\"end\":83230,\"start\":83179},{\"end\":84038,\"start\":83975},{\"end\":84591,\"start\":84516},{\"end\":85189,\"start\":85144},{\"end\":85832,\"start\":85729},{\"end\":86463,\"start\":86355},{\"end\":87037,\"start\":86986},{\"end\":87584,\"start\":87507},{\"end\":88175,\"start\":88117},{\"end\":88942,\"start\":88908},{\"end\":89401,\"start\":89306},{\"end\":89846,\"start\":89815},{\"end\":90846,\"start\":90784},{\"end\":91394,\"start\":91326},{\"end\":93468,\"start\":93372},{\"end\":94055,\"start\":93977},{\"end\":94550,\"start\":94491},{\"end\":95037,\"start\":94985},{\"end\":95827,\"start\":95750},{\"end\":96336,\"start\":96240},{\"end\":97324,\"start\":97261},{\"end\":97763,\"start\":97712},{\"end\":98428,\"start\":98366},{\"end\":98919,\"start\":98853},{\"end\":99508,\"start\":99412},{\"end\":100140,\"start\":100046},{\"end\":100741,\"start\":100645},{\"end\":101328,\"start\":101232},{\"end\":101887,\"start\":101820},{\"end\":102445,\"start\":102368},{\"end\":103027,\"start\":102933},{\"end\":103555,\"start\":103495},{\"end\":103971,\"start\":103923},{\"end\":104844,\"start\":104757},{\"end\":105449,\"start\":105353},{\"end\":79241,\"start\":79222},{\"end\":79408,\"start\":79404},{\"end\":79749,\"start\":79667},{\"end\":80303,\"start\":80194},{\"end\":80833,\"start\":80782},{\"end\":81211,\"start\":81195},{\"end\":81582,\"start\":81516},{\"end\":82044,\"start\":81976},{\"end\":82428,\"start\":82420},{\"end\":82737,\"start\":82650},{\"end\":83177,\"start\":83111},{\"end\":83575,\"start\":83461},{\"end\":83973,\"start\":83895},{\"end\":84514,\"start\":84424},{\"end\":85142,\"start\":85082},{\"end\":85727,\"start\":85609},{\"end\":86353,\"start\":86242},{\"end\":86984,\"start\":86918},{\"end\":87505,\"start\":87413},{\"end\":88115,\"start\":88054},{\"end\":88599,\"start\":88551},{\"end\":88906,\"start\":88857},{\"end\":89304,\"start\":89206},{\"end\":89813,\"start\":89779},{\"end\":90303,\"start\":90257},{\"end\":90782,\"start\":90705},{\"end\":91324,\"start\":91241},{\"end\":91703,\"start\":91669},{\"end\":91911,\"start\":91873},{\"end\":92323,\"start\":92253},{\"end\":92835,\"start\":92800},{\"end\":93370,\"start\":93259},{\"end\":93975,\"start\":93882},{\"end\":94489,\"start\":94415},{\"end\":94983,\"start\":94916},{\"end\":95404,\"start\":95343},{\"end\":95748,\"start\":95656},{\"end\":96238,\"start\":96127},{\"end\":96806,\"start\":96760},{\"end\":97259,\"start\":97181},{\"end\":97710,\"start\":97644},{\"end\":98056,\"start\":98032},{\"end\":98364,\"start\":98287},{\"end\":98851,\"start\":98770},{\"end\":99410,\"start\":99299},{\"end\":100044,\"start\":99935},{\"end\":100643,\"start\":100532},{\"end\":101230,\"start\":101119},{\"end\":101818,\"start\":101736},{\"end\":102366,\"start\":102274},{\"end\":102931,\"start\":102822},{\"end\":103493,\"start\":103418},{\"end\":103921,\"start\":103858},{\"end\":104319,\"start\":104298},{\"end\":104755,\"start\":104653},{\"end\":105351,\"start\":105240}]"}}}, "year": 2023, "month": 12, "day": 17}