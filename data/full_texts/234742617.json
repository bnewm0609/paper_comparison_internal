{"id": 234742617, "updated": "2023-10-06 03:20:57.897", "metadata": {"title": "MultiSports: A Multi-Person Video Dataset of Spatio-Temporally Localized Sports Actions", "authors": "[{\"first\":\"Yixuan\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Lei\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Runyu\",\"last\":\"He\",\"middle\":[]},{\"first\":\"Zhenzhi\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Gangshan\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Limin\",\"last\":\"Wang\",\"middle\":[]}]", "venue": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)", "journal": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)", "publication_date": {"year": 2021, "month": 5, "day": 16}, "abstract": "Spatio-temporal action detection is an important and challenging problem in video understanding. The existing action detection benchmarks are limited in aspects of small numbers of instances in a trimmed video or low-level atomic actions. This paper aims to present a new multi-person dataset of spatio-temporal localized sports actions, coined as MultiSports. We first analyze the important ingredients of constructing a realistic and challenging dataset for spatio-temporal action detection by proposing three criteria: (1) multi-person scenes and motion dependent identification, (2) with well-defined boundaries, (3) relatively fine-grained classes of high complexity. Based on these guide-lines, we build the dataset of MultiSports v1.0 by selecting 4 sports classes, collecting 3200 video clips, and annotating 37701 action instances with 902k bounding boxes. Our datasets are characterized with important properties of high diversity, dense annotation, and high quality. Our Multi-Sports, with its realistic setting and detailed annotations, exposes the intrinsic challenges of spatio-temporal action detection. To benchmark this, we adapt several baseline methods to our dataset and give an in-depth analysis on the action detection results in our dataset. We hope our MultiSports can serve as a standard benchmark for spatio-temporal action detection in the future. Our dataset website is at https://deeperaction.github.io/multisports/.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2105.07404", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iccv/LiCH0W021", "doi": "10.1109/iccv48922.2021.01328"}}, "content": {"source": {"pdf_hash": "32e7df1b63d78ef1f65f4928d8c8c45137e54d3b", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2105.07404v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "0730a462e51af42f31f1b13fbe5d7b6a6bc75e2b", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/32e7df1b63d78ef1f65f4928d8c8c45137e54d3b.txt", "contents": "\nMultiSports: A Multi-Person Video Dataset of Spatio-Temporally Localized Sports Actions\n\n\nYixuan Li \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nLei Chen \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nRunyu He \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nZhenzhi Wang \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nGangshan Wu \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nLimin Wang \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nMultiSports: A Multi-Person Video Dataset of Spatio-Temporally Localized Sports Actions\n\nSpatio-temporal action detection is an important and challenging problem in video understanding. The existing action detection benchmarks are limited in aspects of small numbers of instances in a trimmed video or low-level atomic actions. This paper aims to present a new multiperson dataset of spatio-temporal localized sports actions, coined as MultiSports. We first analyze the important ingredients of constructing a realistic and challenging dataset for spatio-temporal action detection by proposing three criteria: (1) multi-person scenes and motion dependent identification, (2) with well-defined boundaries, (3) relatively finegrained classes of high complexity. Based on these guidelines, we build the dataset of MultiSports v1.0 by selecting 4 sports classes, collecting 3200 video clips, and annotating 37701 action instances with 902k bounding boxes. Our datasets are characterized with important properties of high diversity, dense annotation, and high quality. Our Multi-Sports, with its realistic setting and detailed annotations, exposes the intrinsic challenges of spatio-temporal action detection. To benchmark this, we adapt several baseline methods to our dataset and give an in-depth analysis on the action detection results in our dataset. We hope our MultiSports can serve as a standard benchmark for spatiotemporal action detection in the future. Our dataset website is at https://deeperaction.github.io/multisports/.\n\nIntroduction\n\nSpatio-temporal human action detection in untrimmed videos is of great importance for many applications, such as surveillance and sports analysis. Recently, recognizing actions from short trimmed videos has achieved considerable progress [52,3,48,42,49,50], but these classification models can not be directly applied for video analysis in a multiperson scene. Meanwhile, although temporal action detection methods [66,31,29,59,63] for untrimmed videos can : Corresponding author (lmwang@nju.edu.cn). distinguish intervals of human actions from background, they are still unable to spatially detect multiple concurrent human actions, which is important in real-world applications of video analysis.\n\nCurrent spatio-temporal action detection benchmarks can be mainly classified into two categories: 1) Densely annotated high-level actions such as J-HMDB [20] and UCF101-24 [46]. Their clips only have a single person doing some semantically simple and temporally repeated actions. Typically, the scene context can provide enough cues for recognizing these coarse-grained action categories. Thus, these benchmarks might be impractical for real-world applications such as surveillance, where it is required to deal with more fine-grained actions in a multi-person scene; 2) Sparsely annotated atomic actions such as AVA [15]. They fail to provide clear temporal action boundaries, and simply focus on frame-level spatial localization of atomic actions. This setting removes the requirements of temporal localization for action detection algorithms. Meanwhile, their atomic actions rarely require the complex reasoning over the actors and their surrounding environment.\n\nBased on the analysis above, we argue that a new benchmark is necessary to advance the research of spatiotemporal action detection. The benchmark should satisfy several important requirements to cover the realistic challenges of this task. 1) There should be multiple persons performing different actions concurrently in the same scene, where the background information is not sufficient for action recognition and motion itself of the actor plays a significant role. 2) To address the inherently confusing human action boundaries in time, actions should be both semantically and temporally well-defined with a consensus among humans. 3) Considering the complexity of real-world applications, actions should be fine-grained which requires accurate human pose and motion information, long-term temporal structure, possible interactions between humans, objects and scenes, and reasoning over their relations.\n\nFollowing the above guidelines, we develop the Multi-Sports dataset, short for Multi-person Sports Actions. The dataset is large-scale, high-quality, multi-person, and con- tains fine-grained action categories with precise and dense annotations in both spatial and temporal domains. The action vocabulary consists of 66 action classes collected from 4 sports (basketball, volleyball, football and aerobic gymnastics). An example clip has been visualized in Figure 1. We choose these four sports for the following reasons. 1) There are plenty of multiple concurrent action instances in sports competitions. Also, the background is far less characteristic and cannot provide sufficient information for finegrained action recognition. 2) Sports actions have welldefined categories and boundaries. These boundaries are defined by either professional athletes or official documentations [8]. 3) Due to the complex competition rules, recognizing sports action generally requires to model the longterm structure and the human-object-scene interactions. For example, in football, although the athlete may take only 0.5s to kick the ball, we may need up to 5s context to recognize whether it is pass, long ball, through ball, or cross.\n\nIn practice, we conduct exhaustive annotations of 25 fps frame-wise bounding boxes and fine-grained action categories in a two-stage procedure: 1) a team of professional athletes of corresponding sport to annotate the temporal and category labels, and 2) a team of crowd-sourced annotators to finish the bounding boxes with the help of tracking method FCOT [7]. This two-stage annotation procedure as well as careful quality control together can guarantee consistent and clean annotations. To ensure the visual quality, all videos in our dataset are high-resolution records of professional competitions from a diversity of countries and different performance levels.\n\nGiven the well-defined and dense-annotated action instances in MultiSports v1.0, we benchmark spatio-temporal action detection on this challenging dataset. We perform empirical studies with several recent state-of-the-art action detector methods. Compared with previous action detection benchmarks such as J-HMDB [20] and UCF101-24 [46], our MultiSports is quite challenging with a much lower frame mAP and video mAP. We also introduce a detailed error analysis on detection results and try to provide more insights on spatio-temporal action detection. According to our analysis on MultiSports benchmark, we figure out several challenges of spatio-temporal action detection that needs to be addressed, such as capturing subtle differences between fine-grained action categories, performing accurate temporal localization, dealing with action occlusion and modeling long-range context. We hope MultiSports could serve as a standard benchmark to advance the area of spatiotemporal action detection in the future. MultiSports sptatiotemporal action detection is currently a track of DeeperAction challenge at ICCV 2021 https://deeperaction.github.io/.\n\nIn summary, our main contribution is twofold. 1) We develop a new benchmark MultiSports of spatio-temporal action detection for well-defined and realistically difficult human actions in a multi-person scene, providing high-quality and 25fps frame-wise annotations from four sports. 2) We conduct extensive studies and systematic error analysis on MultiSports, which reveals the key challenges of spatiotemporal action detection and hopefully can facilitate future research in this area.\n\n\nRelated Work\n\nAction recognition datasets. Early datasets of action recognition mainly focus on action classification. Those datasets, including KTH [39], Weizmann [2], UCF-101 [46] and HMDB [24], contains manually trimmed short clips to capture semantics of a single action. Their human action cues, however, are overwhelmed by signals of background scenes. Multi-MiT [33] is a multi-label action recognition dataset, which may have several concurrent actions but do not provide temporal duration and spatial annotations. Recently, large-scale video classification datasets such as Sports-1M [22], YouTube-8M [1] and Kinetics [3] have been created for feature representation learning and serve as pre-training in downstream tasks, but appearance cues still play a important role here. Something-something [14] and FineGym [40], with plenty of fine-grained action categories, effectively reduce the influences of background scenes and reveal some key challenges of modeling a single action. They share the similar property of capturing motion cues with MultiSports, but only have one concurrent action therefore we address a different need with them.\n\nTemporal action detection datasets such as Activi-tyNet [16], HACS [64], THUMOS14 [19], MultiTHU-MOS [61] and Charades [41] provide temporal action detection annotations for each action of interest in untrimmed videos. But unlike MultiSports, they do not provide spatial annotations and could not identify multiple concurrent actions for multiple people.\n\nPrevious spatio-temporal action detection datasets, such as UCF Sports [37], UCF101-24 [46] and J-HMDB [20], typically evaluate spatio-temporal action detection for short videos with only a single person and coarse-grained action categories. Our MultiSports significantly differs from them in several aspects: multiple concurrent actions by multiple people; less characteristic background scenes; the larger number of action and fine-grained categories; more fast movement and large deformation; and significantly more instances per clip. Recently, a new type of extensions such as DALY [54], AVA [15] and AVA-Kinetics [25] adopt sparse annotations of daily life actions, either in composite or atomic forms, to reduce human labors of annotating and increase the scale of datasets. It may be a good way for evaluating daily life actions without fast movement and large deformation, but unsuitable for areas like sports analysis, since it often requires continuous annotations of all human actions of interest. MEVA [6] is a security dataset, which provides spatial-temporal annotations and some other modality annotations. But our sports actions are more complex and fast-changing than MEVA. Different from previous datasets, our MultiSports proposes a more difficult benchmark with multi-person, well-defined bound-aries, fine-grained setting and frame-by-frame annotations, which focuses on the sports domain. Spatio-temporal action detection.\n\nMost recent approaches for UCF101-24 and JHMDB can be classified into two categories: frame-level detectors and clip-level detectors. Many efforts have been made to extend an image object detector to the task of spatio-temporal action detection at the frame level [13,51,34,38,44,53], where the resulting per-frame detections are then linked to generate final tubes. Although flows could be used to capture motion cues, frame-level detector fails to fully utilize temporal information. To model temporal structures for action detection, some clip-level approaches or action tubelet detectors [18,26,21,60,27,65,45] have been proposed. ACT [21] took several frames as input and detected tubelets regressed from anchor cuboids. STEP [60] progressively refined the proposals by a few steps to solve the large displacement problem and utilized longer temporal information. MOC-detector [27] proposed an anchor-free tubelet detector by treating action instances as trajectories of moving points. For AVA, many methods [11,12,47,55,56] have been proposed to better make use of spatio-temporal information for atomic action classification.\n\n\nThe MultiSports Dataset\n\nOur MultiSports dataset aims to introduce a new challenging benchmark with high-quality annotations to the area of spatio-temporal action detection, which differs from previous ones in multi-person scene, well-defined temporal boundaries, and fine-grained action categories. Sec. 3.1 introduces our annotation procedure. Statistics and characteristics of MultiSports are elaborated in Sec. 3.2 and Sec. 3.3.\n\n\nDataset Construction\n\nAction vocabulary generation. We select sports of basketball, volleyball, football and aerobic gymnastics, because of their multi-person setting, less ambiguous actions and welldefined temporal boundary. For aerobic gymnastics, we use the official documentations [8]. In practice, we only select difficulty elements and discard movement patterns. For the remaining ball sports, we use an iterative way to generate our action vocabulary in each sport: we initialize an action list by the suggestions of athletes and write a handbook to clarify the definition of action boundaries. Then we let several annotators try to annotate the data, where inaccurate definitions of action boundaries, ambiguities between action categories and missed action categories will be collected from their feedback. We iteratively adjust our action list and handbook according to the feedback several times before we start massive annotating, which results in the final action hierarchy shown in Figure. 2(a). Note that the annotators of action categories and temporal boundaries are professional athletes of the corresponding sports, so their feedback is important for building a well-defined action vocabulary in practice. To keep action boundaries accurate and make our dataset suitable for spatio-temporal action detection, we do not count common and atomic actions such as run or stand in our action vocabulary. We also exclude foul in ball sports. Because in the 2D video records, we recognize fouls most from the referee's reaction instead of the actor's motion. What is worse, it is hard to identify who fouls due to occlusion. Data preparation. After choosing the four sports, we search for their competition videos by querying the name of sports like volleyball and the name of competition levels like Olympics and World Cup on YouTube, and then download videos from top search results. For each video, we only select high-resolution, e.g. 720P or 1080P, competition records and then manually cut them into clips of minutes, with less shot changes in each clip and to be more suitable for action detection. These official records share consistent and rich content, and can guarantee a high-quality dataset. Action annotation. Since our annotations are difficult in labeling fine-grained categories and exhaustive in determining 25fps frame-wise bounding boxes, we naturally decompose our annotation procedure into two stages: 1) A team of professional athletes generate records of the action label, the starting and ending frame, and the person box in the starting frame, which can ensure the efficiency, accuracy and consistency of our annotation results; 2) With the help of FCOT [7] tracking algorithms, a team of crowdsourced annotators adjust bounding boxes of tracking results at each frame for each record. The ambiguity of spatial human boundaries is much less than that of fine-grained action categories and temporal action boundaries. They use the interface shown in Figure 2(b).\n\nTo ensure the consistency of action temporal boundaries, which tends to be ambiguous and remains as a big challenge for most temporal action detection datasets, we write a handbook to clarify the definition of action boundaries as mentioned above. For example, our handbook unifies the annotations of football pass as starting from the ballcontrolling-leg leaving the ground and ending with this leg touching the ground again. The annotation handbook is provided in Appendix E. Person bounding-box tracking. As mentioned above, we first tack each record generated by professional athletes and then employ crowd-sourced annotators to refine the bounding boxes at each frame. Specifically, we use FCOT [7] to track the bounding boxes frame-by-frame. We find this tracking-to-refinement labeling process can not only speed up the annotation process, but also increase the annotation quality by enforcing workers to focus on determining precise boundary of each box.\n\nWe also evaluate the output of FCOT [7] and results are shown in Table 1. We adopt success and precision metrics proposed in OTB100 [57]. Aerobic turned out the hardest in both success and precision aspects. Quality control. For the first stage of annotation, every clip has at least one annotator with domain knowledge doublechecking the annotations. We correct wrong or inaccurate ones and also add missing annotations for a higher recall, e.g., adding missed defence action in football and modifying inconsistent action boundaries. For the second stage, we double-check each instance by playing it in 5fps and manually correct the inaccurate bounding boxes.\n\n\nDataset Statistics\n\nOur MultiSports v1.0 contains 66 fine-grained action categories from four sports, and has videos selected from 247 competitions. The videos are manually cut into 800 clips per sport to keep data balance between sports. We discard intervals with only background scenes, such as award, and select the highlights of competitions as clips for action detection. Table 2 compares the annotation types and statistics of MultiSports v1.0 with the existing datasets. AVA [15] only has sparse and 1fps annotations of bounding boxes, which fails to provide clear temporal action boundaries and   Table 2. Comparison of statistics between existing action detection datasets and our MultiSports v1.0. ( * only train and val sets' ground-truths are available; T ube with class, temporal boundary and spatial localization; F rame with class and spatial localization; Segment with class and temporal boundary; \u2020 number of person tracklets, each of which has one or more action labels; \u2021 1fps action annotations) focuses on atomic action recognition. AVA-Kinetics [25] uses part of 10s clips of the Kinetics [3] and annotates one key frame per clip without any temporal boundary annotations either. Our annotation type is different from theirs. MultiSports distinguishes with existing datasets such as J-HMDB [20] and UCF101-24 [46] in longer untrimmed video clips (20.9s vs. 1.2s or 6.9s), more fine-grained action categories (66 vs. 21 or 24), much more instances (37701 vs. 928 or 4458), and more instances per video clip (11.8 vs. 1 or 1.4), which raises new challenges of modeling fast movement and fine-grained actions of multiple people in a longer video. Our MultiSports also has the largest number of bounding boxes among all existing datasets. We find that fine-grained category and well-defined boundary usually greatly shorten the action duration, which agrees with Fin-eGym [40]. Also, we only keep the common part of actions in ball sports for well-defined boundaries. For instance, basketball pass starts from the player pushing the ball outwards with his arms, but does not include holding the ball and doing fake actions. Therefore our average action duration is smaller than UCF101-24 and HACS [64], which contains coarse-grained and temporally repeated actions such as volleyball in HACS and riding horses in UCF101-24.  where the x-axis is the number of frames and we count all instances longer than 95 frames in the last bar.\n\nAs shown in Figure 3, the instance number of each action category ranges from 3 to 3,477, showing the natural long-tailed distribution [17]. The long-tailed action categories also raise new challenges for action detection models. Figure 4 shows the distribution of action instance duration. The large variations of action instance duration add more difficulty for action detection models to accurately localize temporal boundary. Moreover, action instances in MultiSports are often related with longer temporal context and interactions with context. These inherent challenges of MultiSports require a more powerful and flexible temporal modeling scheme for action detection.\n\nOur training/validation/test sets are split at the clip level, where the clip numbers in each sport are manually controlled as 3:1:2 for training/validation/test.\n\n\nDataset Characteristics\n\nOur MultiSports has several distinguishing characteristics compared with existing datasets. Difficulty. As discussed above, MultiSports is difficult in several aspects comparing to existing datasets: 1) multiperson situations of different concurrent actions, which prevents the model from distinguishing action categories only with backgrounds and requires models to capture subtly different motion cues; 2) a larger number of fine-grained cat-egories with a long-tailed distribution; 3) the large variance of action instance duration, which makes it difficult to localize the temporal boundary; 4) the fast movement, large deformation and occlusion of actions in sports. High Quality. The videos of MultiSports are with highresolution (720P or 1080P) competition records, which can preserve details of small humans and objects. Besides, with the help of our annotation team composed of professional athletes, our action categories and their corresponding action boundaries are precisely annotated. The professional annotators and careful quality control is able to provide consistent and clean annotations. Diversity. Our video clips are selected from competitions of different performance levels with diverse countries and genders, making the dataset less biased and good balanced for realistic sports analysis.\n\nApplication. This task has many application scenarios for sports analysis. Combined with Re-ID techniques, we can automatically perform game commentary, AI referee and technical statistics. It can also assess the player abilities and provide information for developing the training plan and game strategy, and trading players between clubs.\n\n\nExperiments and Analysis\n\n\nDatasets and Metrics\n\nMultiSports benchmark. To build a solid action detection benchmark, we manually split the instances into the training set, validation set, and testing set. Due to the long-tailed distribution of action instance numbers, following AVA [15], we only evaluate on 60 classes that have at least 25 instances in validation and test splits to benchmark performance. We resize the whole dataset into 720P. In total, the current version contains 18,422 training instances from 1,574 clips and 6,577 validation instances from 555 clips. We provide the detailed ratio of training and validation instances for each sport in Appendix A. All those instances are selected from 3200 clips covering 247 competition records. Unless otherwise mentioned, we report the results trained on the training set and evaluated on the validation set. The testing set includes 1071 clips and we withhold the annotations in the public release. Metrics. Following the standard practice [53,21], we utilize frame-mAP and video-mAP to evaluate action detection performance. For video-mAP, we use the 3D IoU, which is defined as the temporal domain IoU of two tracks, multiplied by the average of the IoU between the overlapped frames. The threshold is 0.5 for frame-mAP, 0.2 and 0.5 for video-mAP.\n\n\nSpatio-temporal Action Detection Results\n\nWe evaluate several representative action detection methods on MultiSports and compare their performance on the UCF101-24 [46], JHMDB [20], and AVA [15] in Table 3. For SlowOnly Det. and SlowFast Det., we use the code in MMAction2 [5]. We use the official released code for ROAD, YOWO and MOC. More details about the methods are provided in Appendix C.\n\nFor UCF101-24 [46] and JHMDB [20], which have dense annotations of high-level actions as MultiSports, we find that these methods achieve good performance on them but obtain low performance on MultiSports (frame-mAP of 25.22%, video-mAP@0.2 of 12.88% and video-mAP@0.5 of 0.62% for MOC [27]). In our dataset, the largest performance drop occurs on ROAD [44], which is a framelevel action detector that performs action detection at each frame independently without exploiting temporal information. UCF101-24 [46] and JHMDB [20] have only one category per video. Characteristic visual scenes provide enough cues for predicting their coarse-grained actions. However, MultiSports has a similar background in the same sport, where the background fails to provide sufficient information for fine-grained action recognition. Meanwhile, our temporal boundary annotation is more precise and requires more accurate localization in temporal domain.\n\nFor AVA [15], which has only sparse annotations of atomic actions, we observe that the performance gap between SlowFast Det. [11] and SlowOnly Det. [11] on Mul-tiSports is more evident than on AVA (frame-mAP gap of 11.02% vs. 4.54%). This indicates that the sports actions need a higher frame rate to capture fast motion at a finer temporal granularity. As shown in Figure 5, many aerobic actions gain large absolute improvement, such as aerobic turn (+30 AP) and aerobic horizontal support (+54 AP). We analyze that aerobic actions' deformation and displacement is the largest among the four sports and benefit more from this finer temporal analysis. We also observe a large performance increase in other sports, such as basketball pass, football clearance and volleyball second attack, which have short temporal duration and intense motion.\n\n\nError Analysis\n\nIn this section, we analyze the cause of errors to better understand MultiSports' challenges. Based on ACT [21] frame-mAP error analysis, which is designed for the dataset with one action category per video, we propose a new detailed error analysis in video-mAP. We classify the detection errors into 10 mutually exclusive categories to analyze which percentage of the mAP is lost. E R : a detection result targets at a ground-truth tube that has already been matched. E N : a detection result that has no spatial-temporal intersection with any ground-truth tubes and appears out of thin air. E L : a detection result that has the correct action class, accurate temporal localization and inaccurate spatial localization. E C : a detection result that has the wrong action class, accurate temporal localization and accurate spatial lo-  Table 3. Comparison of the state-of-the-art methods on MultiSports, UCF101-24, JHMDB and AVA.   Figure 6. Error Analysis. AP is the correct detection. The threshold for a ground-truth matched by a detection is 0.1. Recall is 1 \u2212 EM calization. E T : a detection result that has the correct action class, accurate spatial localization and inaccurate temporal localization. E C&T , E C&L , E T&L , E C&T&L : a detection that is inaccurate in corresponding aspects while acceptable in other aspect (if any). For example, E C&T refers to results with wrong action class, inaccurate temporal localization yet accurate spatial localization. E M : ground-truth tubes that have not been matched by any detection results. The first nine categories cover the false positive predictions. The partition can be explained with a decision tree which is attached to our Appendix D. The code is provided at https://github.com/MCG-NJU/MultiSports. As shown in Figure 6, despite the relatively low recall, SlowFast Det. achieves higher video-mAP than MOC because it makes much fewer false positive predictions. This can be explained by the fact that SlowFast Det. uses Faster RCNN [36] finetuned on MultiSports as person detector to greatly avoid the person boxes without actions. However, there are still many hard examples missed by Slow-Fast Det. For MOC, E C and E N are the most common errors among false positive detection results, indicating the difficulty of our fine-grained action classification. Detection results with E N errors means the model indeed detects the person spatio-temporally but unable to identify the action class correctly as the background class. E N error is also a result of the training strategy of MOC where only the frames temporally inside action instances are sampled for training, so that although there are negative samples in other spatial location of these frames, the detector does not have enough amount of negative samples for people without doing any sports action. What is more, E C&T , E C&T &L and E T are also a large portion of the rest errors (where E C&T > E C&T &L > E T ), indicating more temporal errors with inaccurate action boundaries than spatial localization errors for current methods. Therefore we need a more effective way of modeling temporal boundary. Typical error visualization is shown in Figure 7.\n\n\nAblation Study\n\nHow important is temporal information? The tubelet length K is important in MOC [27] and we report results on UCF101-24 [46] and MultiSports with different K in Table 4. For frame-mAP, we can find that MultiSports can benefit more from longer temporal context than UCF101-24, in spite of the shorter action duration of MultiSports than UCF101-24 as shown in Table 2. For video-mAP, the result does not increase as frame-mAP. We analyze there are two reasons. First, predicting movement in MOC is harder with longer input length. What is worse, the categories in MultiSports have large deformation and displacement, and MOC Movement Branch can not predict them accurately, which harms the video level detection seriously. Second, Figure 4 shows the variability of action duration. The ratio is 9% for instances duration less than 7 and 23% for less than 11. The fixed clip length K (e.g. 11) will damage temporal detection ability. So, we need to consider longer temporal context, more accurate movement estimation and flexible temporal detection for MultiSports. Which action categories are challenging? Figure 5 shows that not all categories yield better performance with more training samples. Categories highly correlated with scenes (such as basketball free throw) or aerobics basic categories (such as aerobic horizontal support and V support) can still achieve high performance with fewer samples. Note that aerobics contains basic and complex categories, where complex action combines the motion of basic action and its own core motion, thus longer temporal context is required for these complex actions. In contrast, categories with short temporal duration and intense motion (such as football pass, basketball pass and football interception) achieve low performance even though with lots of training samples. By observing the confusion matrix in Appendix D, we summarize other common challenges: (1) Context modeling, such as basketball 2-point shot vs. 3-point shot (2) Reasoning, such as for volleyball protect vs. defend, we need to focus on whether the ball was blocked back or was spiked by an opponent several frames earlier.\n\n(3) Long temporal modeling, such as football long ball vs. pass, they have the similar motion but need to identify how long the ball will be passed. Trimmed vs. untrimmed settings. MultiSports has welldefined and high-quality temporal boundaries. We eval-   Table 5. The trimmed setting only evaluates the performance on the frames having annotations and the untrimmed setting reports the performance on all frames. We find that it only drops 2% on AVA while 11% on our dataset, which indicates that temporal localization is really important in our dataset. In addition, video-mAP@0.5 drops far more than video-mAP@0.2. This demonstrates that temporal localization is important for high-quality action tube detection.\n\n\nConclusion\n\nIn this paper, we have introduced the MultiSports dataset with dense spatio-temporal annotations of actions from four sports. MultiSports distinguishes from the existing action detection datasets in many aspects: 1) raising new challenges for recognizing fine-grained action classes; 2) requirement of accurate localization of well-defined boundaries in multiple-person situations; 3) high quality video data and dense annotations; 4) potential applications in sports analysis; 5) less biased dataset with high diversity in competition levels, countries and genders. We have empirically investigated several action detection baseline methods on the MultiSports dataset. Our error analysis and ablation studies on the detection results uncover several insightful findings that are beneficial for the future research of spatiotemporal action detection.\n\nAcknowledgements. This work is supported by National Natural Science Foundation of China (No. 62076119, No. 61921006), Program for Innovative Talents and Entrepreneur in Jiangsu Province, and Collaborative Innovation Center of Novel Software Technology and Industrialization. Thanks to professional athletes of Nanjing University varsities and MCG students for annotating this dataset.\n\n\nAppendix A: More Dataset Details\n\n\nA.1 Train split vs. Validation split\n\nIn order to guarantee enough instances for each class despite the severely unbalanced distribution, we artificially split the instances into the training set and the validation set in Table 6. To avoid data leakage from the training set to the validation/testing set, we ensure that data from the same match should be used for only one purpose. In other words, clips in the validation set cannot come from the matches covered in the training set. Unless otherwise mentioned, we report the results trained on the training set and evaluated on the validation set.\n\n\nA.2 Comparison with other type of Dataset\n\nMEVA [6] is a new security dataset, whose data is from RGB and thermal IR cameras, UAV footage and GPS locations for the actors. It defines 37 activities (66 for Mul-tiSports) with 17055 instances (37701 for MultiSports), where 29 activities are about person and 8 activities are about vehicle. The categories in this dataset are atomic, such as person close trunk and person stand up, which are different from our fine-grained and complicated sports categories. What's more, most of the categories in MEVA are daily actions, whose deformation and displacement are not large. Although it is a multi-person dataset, we believe our MultiSports can bring new challenges different from MEVA.\n\n\nAppendix B: More Ablation Study\n\nHow the well-defined and high quality temporal boundary help? We add some temporal noise to the train set GT. For a L-frame length instance, we randomly choose a new length new L from (1, L) and then the start point offset from (0, L-new L). We sample the new annotation from the original. Other settings are kept the same. From the Table 7, we find the performance is much worse without well-defined temporal boundaries. It can conclude that our MultiSports has well-defined and high quality temporal annotations, which can help improve the performance and promote the algorithms to localize the boundary more accurately.\n\n\nAppendix C: Method Details\n\nROAD [44] is a deep-learning framework for real-time action localisation and classification. It adopts SSD [32] to regress and classify action detection boxes in each frame independently, which does not utilize temporal information. Then, the frame detections are linked into action tubes by an online algorithm. Here we use the python linking code provided by MOC [27] instead of the original MATLAB code. Following the settings of ROAD on UCF101-24 [46], we use an ImageNet pre-trained VGG16 [43] network. We first try an initial learning rate of 1e-4 as their setting on UCF101-24, but the loss diverges into infinity after 20 iterations. The reported experiment on our MultiSports adopts an initial learning rate of 1e-5. We use SGD optimizer and the learning rate is reduced to its 1 10 after 30000, 60000 iterations, which is the same as their practice on UCF101-24. The maximum iteration number is 120000. YOWO [23] is a frame-level action detector with two branches. A 2D-CNN branch extracts the spatial features of the key frame while a 3D-CNN branch extracts spatiotemporal features of the key frame and the previous n (n=16) frames. Then, the features of two branches are fused by a channel fusion and attention mechanism(CFAM) module and finally passed to a convolution layer to predict the action class and bounding box in Yolov2 [35] manner. Finally, the frame detections are linked into action tubes by a dynamic programming algorithm. Note that the linking algorithm in YOWO is trimmed, thus we use the same linking algorithm as MOC on MultiSports. We use 2D Darknet-19 backbone pretrained on PASCAL VOC [10] and 3D ResNeXt-101 backbone pre-trained on Kinetics [3]. To utilize multiple GPUs, we modified the batch size to 80 and the initial learning rate to 8e-4. Following the training strategy of YOWO on UCF101-24 [46], we adopt SGD optimizer and the learning rate is reduced to its 1 2 after 30000, 40000, 50000, 60000 iterations. The epoch maximum is set to 5. Note that YOWO only estimates performance on the frames having annotations, thus frame-mAP we report on UCF101-24 is much lower than in the original paper. MOC [27] is an anchor-free tubelet-level action detector with three branches, which firstly takes K frames as input, then outputs K frame tubelet results and finally links these tubelets into tubes with a common matching strategy. We use DLA34 [62] as the backbone network, which is pretrained on COCO [30]. Following the training strategy of MOC on UCF101-24 [46], we use the Adam optimizer with the learning rate 5e-4. The learning rate is reduced to its 1 10 after epoch 6 and 8. The epoch maximum is set to 12. SlowFast Det. [11] firstly uses a person detector on the key frame to localize for region proposal. Then, each 2D RoI at the key frame is extended into a 3D RoI by replicating it along the temporal dimension. Finally, it extracts RoI features from the backbone features for predicting category. The person detector is a Faster R-CNN with a ResNeXt-101-FPN [58,28] backbone, which is pre-trained on Ima-geNet [9] and the COCO human keypoint images [30]. The backbone is the variant of SlowFast or SlowOnly, which sets the spatial stride of res 5 to 1 and uses a dilation of 2 for its filters. Note that we use the code in MMAction2 [5]. The results on AVA [15] and our MultiSports in the paper are all produced by it. We use the pre-computed proposals for AVA from previous work [11,55] Table 7. Exploration on the effect of the temporal boundary noise.\n\nwork [11,55], we fine-tune the person detector on our Mul-tiSports with MMDetection [4]. We use the SGD optimizer with the learning rate 0.0025 and finetune 2 epochs on our MultiSports. The person detector produces 96.16 AR@100 on our MultiSports validation set. The detected boxes with confidence of > 0.9 are selected for action detection on both datasets. Our backbones are based on ResNet50, which are pre-trained on Kinetics-400 [3]. The T \u00d7 \u03c4 is set to 4 \u00d7 16.\n\nThe \u03b1 is set to 8 for SlowFast. We use a step-wise learning rate, reducing the learning rate 10\u00d7 after epoch 6 and 7. We train for 8 epochs with a linear warm-up for the first 5 epochs, where the result is similar with that of training 20 epochs and a lot of training time is saved. The initial learning rate is set to 0.1125 for SlowFast and 0.2 for SlowOnly. SlowFast and Slowonly Det. use the same link algorithm as MOC.\n\nAppendix D: Error Analysis\n\n\nD.1 Error Tree\n\nTo further understand the difficulty in our MultiSports dataset, we classify the detection errors into 10 different categories in a tree structure as shown in Figure 8 (code in V ideomAP error.py), which are:\n\n\u2022 E R (Errors of repeated detections): a detection result that has tubelet IoU larger than a threshold and the right action class with some ground-truth tubelets, but the ground-truths have been matched by other detection results before with a confidence score larger than it.\n\n\u2022 E N (Errors of not matched): a detection result that has no intersection with any ground-truth tubelets of any class, indicating there should be no detection results but it appears out of thin air.\n\n\u2022 E L (Errors of spatial localization): a detection result that has the same action class and temporal IoU larger than a threshold with some ground-truth, but it has a low average spatial bounding box IoU in the area of the temporal intersection of ground-truth tubelets and it so that a lower tubelet IoU than the required threshold.\n\n\u2022 E C (Errors of classification): a detection result that has the tubelet IoU larger than a threshold with a groundtruth, but its action class is not the same with the ground-truth's class.\n\n\u2022 E T (Errors of temporal localization): a detection result that has the same action class and average spatial bounding box IoU larger than a threshold with some ground-truth in the area of the temporal intersection of ground-truth tubelets and it, but low temporal IoU with ground-truths so that a lower tubelet IoU than the required threshold.\n\n\u2022 E C&T (Errors of both classification and temporal localization): a detection result that has average spatial bounding box IoU larger than a threshold with some ground-truth tubelets in the area of the temporal intersection of ground-truth tubelets and it, but both low temporal IoU and wrong action class.\n\n\u2022 E C&L (Errors of both classification and spatial localization): a detection result that has temporal IoU larger than a threshold with some ground-truth tubelets, but both wrong action class and low average spatial bounding box IoU with some ground-truth in the area of the temporal intersection of ground-truth tubelets and it.\n\n\u2022 E T &L (Errors of both temporal and spatial localization): a detection result in which we first select the ground-truth tubelet from all action classes that has the maximum tubelet IoU with the detection result, then we find they share the same action class, but both temporal IoU and average IoU of spatial bounding boxes lower than a threshold.\n\n\u2022 E C&T &L (Errors of classification, temporal and spatial localization): a detection result that has some intersection with some ground-truth tubelets, which is different with EN, but wrong action class and both the temporal and average bounding box IoU lower than a threshold. \n\n\nD.2 More Visualization of Error Analysis\n\nAs shown in Figure 9, we collect more visualizations of MOC(K=11) as a supplementary of Figure 7 in our paper.\n\n\nD.3 Confusion Matrix\n\nWe draw the confusion matrices of the predictions which are classified into AP and E C in Figure 10. We observe that the aerobic performs best because its categories relate only to individual actors. Actions having similar motions but different spatio-temporal contexts tend to confuse. For example, 1) drive vs. dribble in basketball, drive emphasizes on breaking through defender and being closer to the basket, which needs to model person-person interaction and spatial localization; 2) through ball vs. pass in football, through ball will break through the opponent's line of defense and be passed in front of the teammate, which needs long-term temporal modeling and reasoning. 3) offensive rebound vs. defensive rebound, the difference is whether the offensive player or defensive player gains control of the ball; 4) defend vs. protect in volleyball, we need to focus on whether the ball was blocked back or was spiked by an opponent several frames earlier.\n\n\nAppendix E: Annotation Documentation E.1 Aerobic Gymnastics\n\nThere are four groups of difficulty elements in aerobic gymnastics, namely dynamic strength, static strength, jumps & leaps, and balance & flexibility. We pick out 21 elements to form the aerobic categories of our MultiSports.\n\nThe following is a detailed definition of these categories, a simplified version of the definition in [8].\n\nGroup A: Dynamic Strength. All elements in Group A ending in a split position, must have both hands on each \u2022 Explosive push up: 1) A Frame: Pike position in the airborne phase (60\u00b0between trunk and legs). 2) Cut: While airborne, the legs straddle sideways and forward to land extended in rear support, feet lifted off the floor during the skill.\n\n\u2022 Explosive support: Back support on the floor, back parallel to the floor, extending the legs upward and for-ward with a flight phase. Impulse from High V support position, airborne phase and landing to push up or split position.\n\n\u2022 Leg circle: The starting position must be from free front support on both hands; the hips must be lifted and extended during the full rotation. Feet may not touch the floor before the completion of the circle. 1) Leg circle: the hips must be lifted and extended. 2) Flair: legs straddle, the hips must be lifted and extended during the full rotation. Feet may not touch the floor before the completion of the circle.\n\n\u2022 Helicopter: After alternative leg circles, legs close to the chest, body alignment on the upper back (feet off the floor). The legs are extended upward and forward. \u00bd twist initiated from the feet is made to land in push up or wenson or split.  Figure 11. Diagrams of each difficulty element in aerobic gymnastics.\n\nisometric strength and must be held for 2 seconds. In the case of turns in support, the support must be held for 2 seconds either at the start, during or end of the turn. The body is fully supported by one or both arms and only the hands are in contact with the floor. Feet and/or hips must not touch the floor during the whole skill. While in support, the hands must be flat on the floor. \u2022 Horizontal support: 1) Wenson support: the body is extended parallel to the floor, one leg supported on the upper part of the Triceps. 2) Planche: the body is supported on both hands with straight arms, not more than 20\u00b0above parallel.\n\nGroup C: Jumps & Leaps. All jumps and leaps must demonstrate explosive power and maximum amplitude. All jumps that can be performed from 1 foot or two feet will be considered as the same element and will receive the same value. This applies also for landing. Take off preparation: head, shoulder, chest, hips, knees, feet must in the same direction. Body shape while airborne must be clearly recognizable. Body and legs must be tight and straight, with head in line with the spine. Landing Positions: 1) Standing: Landing on one foot or two feet must be in a vertical position, with bend leg(s) before finishing in perfect alignment. 2) In push up: both hands and supporting feet must land at the same time in a controlled manner. 3) In split: must land from airborne phase to split form with both hands on each side of the body on the floor. 4) In frontal split: must land from airborne phase to frontal split form, both hands in front of the body.\n\n\u2022 Straight jump: The body is in extended alignment, the pelvis is fixed -2 different kinds of jumps and leaps: 1) Vertical: All air turns, Free fall. 2) Vertical to Horizontal: Gainer.\n\n\u2022 Bent leg(s) jump: 1) Tuck: Both legs are lifted close to the chest with knees bent. 2) Cossack: After takeoff, the body shows a pike shape, legs together parallel to the floor or higher, one leg straight, one leg bent. The angle between the trunk and legs: not be more than 60\u00b0. The angle at the knee joint may not be more than 60\u00b0.\n\n\u2022 Pike jump: After takeoff, the body shows a pike shape, legs together and straight, parallel to the floor or higher. The angle between the trunk and legs may not be more than 60\u00b0.\n\n\u2022 Straddle jump: 1) Straddle: Legs are lifted in straddle position (minimum 90\u00b0angle), parallel to the floor or higher, arms and trunk extended over them. The angle between the trunk and legs may not be more than 60\u00b0.\n\n2) Frontal split: Legs are fully abducted laterally (right and left) frontal (180\u00b0) with the upright upper body.\n\n\u2022 Split jump: 1) Split: Legs are fully stretched front and back in sagittal split (180\u00b0) with the upright upper body. 2) Switch: After takeoff, the leading leg must be parallel to the floor and switch with the rear leg to show a split (180\u00b0) in the air.\n\n\u2022 Scissors leap: The leading leg must be parallel to the floor and switches forward with 1/2 turn (180\u00b0).\n\n\u2022 Kick jump: The leading leg must be parallel to the floor and switches forward.\n\n\u2022 Off axis jump: A one-foot take off, kicking the free leg (bend or straight) upward diagonally. While airborne, the body inclines backward to be out of axis with a longitudinal rotation(s) in tuck or straight position, arms close to the chest. Landing in 1 foot/feet together or in split.\n\n\u2022 Butterfly jump: A one-foot take off, kicking the free leg backward to lift the body upward. While airborne, legs fly open in straddle (or feet together) with the body in a horizontal position (with or without longitudinal rotation(s). Landing on one leg.\n\nGroup D: Balance & Flexibility.\n\n\u2022 Split: Legs must be straight, in line, showing 180\u00b0. In Vertical Split: supporting leg must be in vertical position.\n\n\u2022 Turn: All exercises requiring turns must demonstrate complete rotations on the ball of the foot. Turns are completed when the heel of the turning foot touches the floor.\n\n\u2022 Balance turn: A Balance turn where one leg is lifted to either in sagital or frontal balance and is supported by one hand.\n\n\u2022 Illusion: Starting position of illusion: head, shoulder, chest, hips, knees, toes must be in alignment. A full split (180\u00b0) must be shown during the movement.\n\nFor the temporal definition, strictly follow the diagrams in Figure 11 (quoted from [8]) to determine the starting and ending of actions, except for the following situations: when an athlete's action is not in place or is completely blocked by other athletes.\n\n\nE.2 Volleyball\n\n\u2022 Serve: Send the ball over the net from behind the end line to start a new round. Start: The ball leaves the player's hand. End: If the player takes off, any foot touches the ground. Otherwise, the upper arm of the serving arm is below the horizontal plane.\n\n\u2022 Block: Deflect the ball coming from an attacker on the net. The one that doesn't take off is not considered a block. The one that takes off but doesn't touch the ball is considered a block. Start: Any foot leaves the ground. End: Any foot touches the ground.\n\n\u2022 First Hit Pass: Receive the serve. The player can receive the ball overhand, one-hand or underhand. Start: If overhand, the player raises any hand over the chest. If one-hand, the player's arm begins to stretch out. If underhand, the player begins to hold hands together. End: If overhand, the player puts any hand below the chest. If one-hand, the player's hitting-ball arm relaxes. If underhand, the player's hands loose.\n\n\u2022 Defend: Receive the ball from the opposite side except for the serve. The player can receive the ball overhand, one-hand or underhand. Start: If overhand, the player raises any hand over the chest. If one-hand, the player's arm begins to stretch out. If underhand, the player begins to hold hands together. End: If overhand, the player puts any hand below the chest. If onehand, the player's hitting-ball arm relaxes. If underhand, the player's hands loose.\n\n\u2022 Protect: Receive the ball returned by the block. The player can receive the ball overhand, one-hand or underhand. Start: If overhand, the player raises any hand over the chest. If one-hand, the player's arm begins to stretch out. If underhand, the player begins to hold hands together. End: If overhand, the player puts any hand below the chest. If one-hand, the player's hittingball arm relaxes. If underhand, the player's hands loose.\n\n\u2022 Second Hit Pass: The second overhand pass to organize the offense. Start: The player raises any hand over the chest. End: The player puts any hand below the chest.\n\n\u2022 Adjust: For the second touch, due to the inadequacy of first hit pass or defending or protecting, the player has to adjust the ball underhand to organize offense. Start: The player begins to hold hands together. End:\n\nThe player's hands loose.\n\n\u2022 Save: Due to the poor first hit pass or defending or protecting, the route of the ball changes dramatically. The actor can't second hit pass overhand or adjust underhand to organize offense but uses one hand or both hands to reach the ball to prevent the ball from landing directly. Start: If one-hand, the player's arm begins to stretch out. Otherwise, the player begins to hold hands together. End: If one-hand, the player's hitting-ball arm relaxes. Otherwise, the player's hands loose.\n\n\u2022 Second Attack: For the second touch, a direct attack by the setter. Start: Any foot leaves the ground. End: Any foot touches the ground.\n\n\u2022 Spike: Slam the ball over the net into the opposing court. Start: Any foot leaves the ground. End: Any foot touches the ground.\n\n\u2022 Dink: Lightly tap the ball over the net to an area on the opponent's side of the court that is not being guarded or occupied by a defensive player. Start: Any foot leaves the ground. End: Any foot touches the ground.\n\n\u2022 No Offensive Attack: For the second or third touch, the ball is passed over the net non-aggressively, because of the bad first hit pass or defending or protecting. The actor can push the ball overhand, pass the ball underhand or tap the ball from a position below the net with one hand, where the actor doesn't take off. Start: If overhand, the player raises any hand over the chest. If underhand, the player begins to hold hands together. Otherwise, the upper arm of hitting the ball arm is above the horizontal plane. End: If overhand, the player puts any hand below the chest. If underhand, the player's hands loose. Otherwise, the upper arm of hitting the ball arm is below the horizontal plane.\n\n\nE.3 Football\n\n\u2022 Shoot: Hit the ball in an attempt to score a goal. Feet, torso and head are all allowed. Start: If using torso and head: if the player takes off, any part of the body leaves the ground (such as a foot); if the player does not take off, the player stands firmly and prepares to touch the ball. If using feet, the ball-controlling foot leaves the ground. End: If using torso and head: if the player takes off, any part of the body touches the ground (such as a foot); if the player does not take off, stand firmly after touching the ball. If using feet, the ball-controlling foot touches the ground.\n\n\u2022 Long Ball: Middle and long distance (over 30 meters) pass. Feet, torso and head are all allowed. Start: If using torso and head: if the player takes off, any part of the body leaves the ground (such as a foot); if the player does not take off, the player stands firmly and prepares to touch the ball. If using feet, the ballcontrolling foot leaves the ground. End: If using torso and head: if the player takes off, any part of the body touches the ground (such as a foot); if the player does not take off, stand firmly after touching the ball. If using feet, the ball-controlling foot touches the ground.\n\n\u2022 Pass: Short distance (within 30 meters) pass. Feet, torso and head are all allowed. Start: If using torso and head: if the player takes off, any part of the body leaves the ground (such as a foot); if the player does not take off, the player stands firmly and prepares to touch the ball. If using feet, the ball-controlling foot leaves the ground. End: If using torso and head: if the player takes off, any part of the body touches the ground (such as a foot); if the player does not take off, stand firmly after touching the ball. If using feet, the ball-controlling foot touches the ground.\n\n\u2022 Through Ball: A pass that can clearly break through the opponent's line of defense and has a penetrating effect. At least one defensive player is passed. The ball is passed in front of the player's teammate. In other words, the player should pass the ball to where his running teammate is going to be. Feet, torso and head are all allowed. Start: If using torso and head: if the player takes off, any part of the body leaves the ground (such as a foot); if the player does not take off, the player stands firmly and prepares to touch the ball. If using feet, the ball-controlling foot leaves the ground. End: If using torso and head: if the player takes off, any part of the body touches the ground (such as a foot); if the player does not take off, stand firmly after touching the ball. If using feet, the ball-controlling foot touches the ground.\n\n\u2022 Cross: A medium-to-long-range pass from a wide area of the field towards the centre of the field near the opponent's goal. Provide direct or indirect shooting opportunities for offensive players. Feet, torso and head are all allowed. Start: If using torso and head: if the player takes off, any part of the body leaves the ground (such as a foot); if the player does not take off, the player stands firmly and prepares to touch the ball. If using feet, the ball-controlling foot leaves the ground. End: If using torso and head: if the player takes off, any part of the body touches the ground (such as a foot); if the player does not take off, stand firmly after touching the ball. If using feet, the ball-controlling foot touches the ground.\n\n\u2022 Dribble: Have control over the ball for a period of time and distance. Start: At the first touch with the ball, the ball-controlling foot leaves the ground. End: At the last touch with the ball, the ball-controlling foot touches the ground.\n\n\u2022 Trap: Use effective parts of the body to adjust the ball, including the speed and position of the ball. Feet, torso and head are all allowed. Start: If using torso and head: if the player takes off, any part of the body leaves the ground (such as a foot); if the player does not take off, the player stands firmly and prepares to touch the ball. If using feet, the ball-controlling foot leaves the ground. End: If using torso and head: if the player takes off, any part of the body touches the ground (such as a foot); if the player does not take off, stand firmly after touching the ball. If using feet, the ball-controlling foot touches the ground.\n\n\u2022 Throw: The player throws the ball from out of the field and the goalkeeper throws the ball. Start: Upper arms swing forward. End: Upper arms are below the horizontal plane.\n\n\u2022 Save: The goalkeeper uses his body parts (except his feet) to destroy the ball that is threatening to the goal. Start: After the ball is shot, the goalkeeper begins to move. End: Any part of the body touches the ground.\n\n\u2022 Interception: The defensive player consciously destroys the ball on the opponent's pass route. Feet, torso and head are all allowed. Start: If using torso and head: if the player takes off, any part of the body leaves the ground (such as a foot); if the player does not take off, the player stands firmly and prepares to touch the ball. If using feet, the interception foot leaves the ground. End: If using torso and head: if the player takes off, any part of the body touches the ground (such as a foot); if the player does not take off, stand firmly after touching the ball. If using feet, the interception foot touches the ground.\n\n\u2022 Tackle: The defensive player snatches the ball under the control of the offensive player. Start: the tackling foot leaves the ground. End: the tackling foot touches the ground.\n\n\u2022 Clearance: The defensive player destroys the ball in the backfield in order to gain the initiative in time and space. The main difference between clearance and long ball/ball is that long ball/ball aims at some player but clearance is aimless. Feet, torso and head are all allowed. Start: If using torso and head: if the player takes off, any part of the body leaves the ground (such as a foot); if the player does not take off, the player stands firmly and prepares to touch the ball. If using feet, the clearance foot leaves the ground. End: If using torso and head: if the player takes off, any part of the body touches the ground (such as a foot); if the player does not take off, stand firmly after touching the ball. If using feet, the clearance foot touches the ground.\n\n\u2022 Block: Intentionally destroy the opponent's threatening shot or block the opponent's shooting angle. The goalkeeper blocked the ball with his foot. Feet, torso and head are all allowed. Start: If using torso and head: if the player takes off, any part of the body leaves the ground (such as a foot); if the player does not take off, the player stands firmly and prepares to touch the ball. If using feet, the blocking foot leaves the ground. End: If using torso and head: if the player takes off, any part of the body touches the ground (such as a foot); if the player does not take off, stand firmly after touching the ball. If using feet, the blocking foot touches the ground.\n\n\u2022 Defence: The defensive player approaches the player, of whom the ball is under the control, to make restriction and interference. Start: The defender is shorter than 1.2 meters from the offensive player who is controlling the ball. End: 1) the offensive player passes the ball out or the ball is gained by other defensive players. 2) this defender begins to tackle. 3) this defender is longer than 1.2 meters from the offensive player who is controlling the ball.\n\n\u2022 Aerial duels: Two or more people compete for the high-altitude ball in order to obtain the ball, where all people are annotated. If the player does not take off, it is not considered aerial duels. Note that the player who has an obvious purpose, such as clearance and pass, is annotated that action. Start: Any part of the body leaves the ground (such as a foot). End: Any part of the body touches the ground (such as a foot).\n\n\nE.4 Basketball\n\n\u2022 Pass: The player moves the ball to the teammate. Start: The player begins to push the ball outwards with his arms. End: The ball leaves both hands of the player.\n\n\u2022 Drive: The player, who controls the ball, gets rid of the defense by passing the defensive player or stopping suddenly during the movement. The aim is to get closer to the basket and create a space that is conducive to shooting. The next step is usually to shoot, layup, or pass the ball to teammates. Start: At the first touch with the ball, the hand presses the ball down. End: At the last touch with the ball, the ball is bounced into the hand.\n\n\u2022 Dribble: The player slaps the ball bounced from the ground continuously while on the spot or on the move. Start: At the first touch with the ball, the hand presses the ball down. End: At the last touch with the ball, the ball is bounced into the hand.\n\n\u2022 3-point Shot: Shoot from beyond the three-point line.\n\nStart: The player raises the shooting hand over the chest. End: If the player takes off, any part of the body touches the ground (such as a foot). Otherwise, the player puts the shooting hand below the chest.\n\n\u2022 2-point Shot: Shoot from within the three-point line.\n\nStart: The player raises the shooting hand over the chest. End: If the player takes off, any part of the body touches the ground (such as a foot). Otherwise, the player puts the shooting hand below the chest.\n\n\u2022 Free Throw: Unopposed attempts to score points by shooting from behind the free throw line. Start: The player raises the shooting hand over the chest. End: If the player takes off, any part of the body touches the ground (such as a foot). Otherwise, the player puts the shooting hand below the chest.\n\n\u2022 Block: When the offense shoots, the defender successfully knocks the ball out as the ball goes up. Start: The defender raises the blocking hand over the chest. End: If the defender takes off, any part of the body touches the ground (such as a foot). Otherwise, the defender puts the blocking hand below the chest.\n\n\u2022 Offensive Rebound: After a missed shot, the two sides compete for a rebound and the offensive player grabs it. Start: The player raises the grabbing-ball hand over the chest. End: If the player takes off, any part of the body touches the ground (such as a foot). Otherwise, the player catches the ball firmly.\n\n\u2022 Defensive Rebound: After a missed shot, the two sides compete for a rebound and the defensive player grabs it. Start: The player raises the grabbing-ball hand over the chest. End: If the player takes off, any part of the body touches the ground (such as a foot). Otherwise, the player catches the ball firmly.\n\n\u2022 Pass Steal: The defensive player intercept the ball in the process of passing, which is not under the control of offensive player. Start: The defender's stealing-ball hand begins to stretch out. End: 1) Route of the ball changes; 2) The defender catches the ball firmly.\n\n\u2022 Dribble Steal: The defensive player steals the ball under the control of offensive player. Start: The defender's stealing-ball hand begins to stretch out. End:\n\nThe ball is out of the control of the offensive player who had the control.\n\n\u2022 Interfere Shot: The defender interferes with the shot but does not touch the ball. Start: The defender raises the interfering hand over the chest. End: If the defender takes off, any part of the body touches the ground (such as a foot). Otherwise, the defender puts the interfering hand below the chest.\n\n\u2022 Pick-and-roll Defense: In pick-and-roll, the defender of the offensive ball-controlling player is blocked by the teammate of this offensive player. Start: The defender has physical contact with the offensive screening player. End: The defender does not have physical contact with the offensive screening player.\n\n\u2022 Sag: The defender gives up the offensive player he is responsible for and turns to defend the offensive ballcontrolling player. Start: The defender consciously approach the offensive ball-controlling player. End: 1) the offensive player passes or shoots the ball; 2) this defender is broken through; 3) this defender gives up.\n\n\u2022 Screen: In pick-and-roll, the offensive player uses his body to set a pick for his ball-controlling teammate.\n\nStart: Both feet of the offensive player touches the ground. End: Any foot of the offensive player is ready to leave the ground completely. Small range movement is not considered the end.\n\n\u2022 Pass-inbound: The player passes the ball from the boundary lines to restart the play. Start: The player begins to push the ball outwards with his arms. End:\n\nThe ball leaves both hands of the player.\n\n\u2022 Save: The player gets back the ball that is about to go out of bounds. Start: The player begins to push the ball outwards with his arms. End: The ball leaves both hands of the player.\n\n\u2022 Jump Ball: A method used to begin or resume the play. Two opposing players attempt to gain control of the ball after an official tosses it into the air between them, where both players are annotated. Start:\n\nThe player raises the grabbing-ball hand over the chest.\n\nEnd: Any part of the body touches the ground (such as a foot).\n\nFigure 1 .\n1pick-and-roll defensive, pickand-roll defensive bent leg(s) jump, support explosive support, support bent leg(s) jump, support The 25fps tubelets of bounding boxes and fine-grained action category annotations in MultiSports dataset. Multiple concurrent action situations frequently appear in MultiSports with many starting and ending points in the long untrimmed video clips. The frames are cropped and sampled by stride 5 or 7 for visualization propose. Tubes with the same color represent the same person.\n\nFigure 2 .\n2The action vocabulary hierarchy and annotator interface of the MultiSports dataset. (a) Our MultiSports has a two-level hierarchy of action vocabularies, where the actions of each sport are fine-grained. (b) Details of annotations can be found in Sec 3.1.\n\nFigure 3 .\n3Statistics of each action class's data size in MultiSports, which is sorted by descending order with 4 colors indicating 4 different sports. For actions in the different sports sharing the same name, we add the name of sports before them.\n\nFigure 4 .\n4Statistics of action instance duration in MultiSports,\n\nFigure 7 .\n7Visualization of typical errors in MultiSports. Green boxes are the ground-truths. Yellow boxes are the detections. Red boxes are the missed ground-truths. 1st and 2nd row: missed detection due to occlusion. 3rd and 4th row: E C&T : drive is misclassified as dribble and also has inaccurate action boundary; EM : missed detections of screen, pick-and-roll defensive and sag.\n\nFigure 8 .\n8Error Tree \u2022 E M (Errors of missed detections): ground truth tubelets that have not been matched by any detection results.\n\nFigure 9 .Figure 10 .\n910More detailed visualizations on our MultiSports dataset with our novel error categories of video-mAP. Green boxes are the ground-truths. Yellow boxes are the detections. 1st and 2nd row: EM : missed detection of defence; EC : tackle is misclassified as defence; ET : dribble has inaccurate action ending boundary. 3rd and 4th row: EC : turn is misclassified as illusion in the last picture in 4th row; ET : turn has inaccurate action boundary. 5rd and 6th row: EN : detection results contain that athletes actually doing none of sports actions but the model identifies first hit pass and second hit pass for them. 7rd and 8th row: E C&T : drive is misclassified as dribble and also has inaccurate action boundary; EM : missed detections of interfere shot and 2-point shot.side of the body on the floor. \u2022 Push up: Starting and/or finishing: one or both hands are in contact with the floor, elbows extended. Shoul-Confusion Matrix of SlowFast Det. on different sports. ders must be parallel to the floor; head in line with the spine and pelvis tucked with abdominal muscles contracted. Flexion of elbows: All push-ups must have, at the end of the downwards phase, a maximum distance of 10cm from the chest to the floor. The downward and/or the upward phase of a push up must be controlled with shoulders parallel to the floor. Lateral and Hinge push up, 4 phases have to be shown. Wenson push up: one leg on the upper part of the arm (Triceps) of the same side.\n\n\u2022\nSupport: 1) Straddle support: Legs must be straight parallel to the floor in Straddle position (90\u00b0minimum). 2) L support: Legs must be straight together and parallel to the floor. \u2022 V support: 1) Straddle V support: Hips are flexed and legs straddled 90\u00b0open and vertical, minimum width 90\u00b0. 2) V support: Hips are flexed and legs are together vertical. 3) High V support: The back is parallel to the floor.\n\nTable 4 .\n4Exploration study of MOC on the MultiSports and UCF101-24 with different tubelet length K.Estimation \nMultiSports \nAVA \nF@0.5 V@0.2 V@0.5 \nF-mAP@0.5 \nUntrimmed \n27.72 \n24.18 \n9.65 \n22.57 \nTrimmed \n38.71 \n24.95 \n18.34 \n24.56 \n\nTable 5. Test SlowFast Det. on AVA and MultiSports with trimmed \nway and untrimmed way. \n\nuate the performance of SlowFast Det. under both the \nuntrimmed and trimmed setting on MultiSports and AVA \ndatasets. The results are reported in \n\n\n. Following previousVolleyball \n\nFootball \nBasketball \nAerobic \nAll \ninstance ratio \n3549:1294 6144:2153 4532:1715 4197:1415 18422:6577 \nclip ratio \n402:130 \n402:132 \n379:147 \n391:146 \n1574:555 \ncompetition ratio \n32:11 \n36:12 \n34:14 \n23:8 \n125:45 \n\nTable 6. Train split vs Validation split \n\nMethod \nGT Noise \nMultiSports \nF@0.5 V@0.2 V@0.5 \nMOC (K=7) \n13.71 \n8.59 \n0.63 \nMOC (K=7) \n22.51 \n12.13 \n0.77 \nSlowOnly Det., 4 \u00d7 16 \n12.60 \n8.98 \n3.05 \nSlowOnly Det., 4 \u00d7 16 \n16.70 \n15.71 \n5.50 \n\n\n\nYoutube-8m: A large-scale video classification benchmark. Sami Abu-El-Haija, Nisarg Kothari, Joonseok Lee, Paul Natsev, George Toderici, Balakrishnan Varadarajan, Sudheendra Vijayanarasimhan, abs/1609.08675CoRRSami Abu-El-Haija, Nisarg Kothari, Joonseok Lee, Paul Nat- sev, George Toderici, Balakrishnan Varadarajan, and Sud- heendra Vijayanarasimhan. Youtube-8m: A large-scale video classification benchmark. CoRR, abs/1609.08675, 2016. 3\n\nActions as space-time shapes. Moshe Blank, Lena Gorelick, Eli Shechtman, Michal Irani, Ronen Basri, ICCV. Moshe Blank, Lena Gorelick, Eli Shechtman, Michal Irani, and Ronen Basri. Actions as space-time shapes. In ICCV, pages 1395-1402, 2005. 3\n\nQuo vadis, action recognition? A new model and the kinetics dataset. Jo\u00e3o Carreira, Andrew Zisserman, CVPR. 910Jo\u00e3o Carreira and Andrew Zisserman. Quo vadis, action recognition? A new model and the kinetics dataset. In CVPR, pages 4724-4733, 2017. 1, 3, 5, 9, 10\n\nMmdetection: Open mmlab detection toolbox and benchmark. Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li, Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, Zheng Zhang, Dazhi Cheng, Chenchen Zhu, Tianheng Cheng, Qijie Zhao, Buyu Li, Xin Lu, Rui Zhu, Yue Wu, Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang, Chen Change Loy, and Dahua LinCoRR, abs/1906.07155Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li, Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, Zheng Zhang, Dazhi Cheng, Chenchen Zhu, Tianheng Cheng, Qijie Zhao, Buyu Li, Xin Lu, Rui Zhu, Yue Wu, Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang, Chen Change Loy, and Dahua Lin. Mmdetec- tion: Open mmlab detection toolbox and benchmark. CoRR, abs/1906.07155, 2019. 10\n\nOpenmmlab's next generation video understanding toolbox and benchmark. MMAction2 Contributors. 69MMAction2 Contributors. Openmmlab's next generation video understanding toolbox and benchmark. https:// github.com/open-mmlab/mmaction2, 2020. 6, 9\n\nRoderic Collins, and Anthony Hoogs. MEVA: A large-scale multiview, multimodal video dataset for activity detection. Kellie Corona, Katie Osterdahl, WACV. 39Kellie Corona, Katie Osterdahl, Roderic Collins, and An- thony Hoogs. MEVA: A large-scale multiview, multimodal video dataset for activity detection. In WACV, pages 1059- 1067, 2021. 3, 9\n\nFully convolutional online tracking. CoRR, abs. Yutao Cui, Cheng Jiang, Limin Wang, Gangshan Wu, 24Yutao Cui, Cheng Jiang, Limin Wang, and Gangshan Wu. Fully convolutional online tracking. CoRR, abs/2004.07109, 2020. 2, 4\n\nAerobic gymnastics-code of points. FIG Aerobic Gymnastics FIG Executive Committee. 15Federation Internationale de GymnastiqueFederation Internationale de Gymnastique. Aerobic gymnastics-code of points. FIG Aerobic Gymnastics FIG Executive Committee, 2017. 2, 3, 11, 15\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Fei-Fei Li, CVPR. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei Li. Imagenet: A large-scale hierarchical image database. In CVPR, pages 248-255, 2009. 9\n\nThe pascal visual object classes challenge: A retrospective. S M Mark Everingham, Luc Ali Eslami, Van Gool, K I Christopher, John M Williams, Andrew Winn, Zisserman, Int. J. Comput. Vis. 9Mark Everingham, S. M. Ali Eslami, Luc Van Gool, Christo- pher K. I. Williams, John M. Winn, and Andrew Zisserman. The pascal visual object classes challenge: A retrospective. Int. J. Comput. Vis., pages 98-136, 2015. 9\n\nSlowfast networks for video recognition. Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, Kaiming He, ICCV. 10Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He. Slowfast networks for video recognition. In ICCV, pages 6201-6210, 2019. 3, 6, 7, 9, 10\n\nand Andrew Zisserman. Video action transformer network. Rohit Girdhar, Jo\u00e3o Carreira, Carl Doersch, CVPR. Rohit Girdhar, Jo\u00e3o Carreira, Carl Doersch, and Andrew Zis- serman. Video action transformer network. In CVPR, pages 244-253, 2019. 3\n\nFinding action tubes. Georgia Gkioxari, Jitendra Malik, CVPR. Georgia Gkioxari and Jitendra Malik. Finding action tubes. In CVPR, pages 759-768, 2015. 3\n\nThe \"something something\" video database for learning and evaluating visual common sense. Raghav Goyal, Samira Ebrahimi Kahou, Vincent Michalski, Joanna Materzynska, Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fr\u00fcnd, Peter Yianilos, Moritz Mueller-Freitag, Florian Hoppe, Christian Thurau, Ingo Bax, Roland Memisevic, ICCV. Raghav Goyal, Samira Ebrahimi Kahou, Vincent Michal- ski, Joanna Materzynska, Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fr\u00fcnd, Peter Yianilos, Moritz Mueller- Freitag, Florian Hoppe, Christian Thurau, Ingo Bax, and Roland Memisevic. The \"something something\" video database for learning and evaluating visual common sense. In ICCV, pages 5843-5851, 2017. 3\n\nAVA: A video dataset of spatio-temporally localized atomic visual actions. Chunhui Gu, Chen Sun, David A Ross, Carl Vondrick, Caroline Pantofaru, Yeqing Li, Sudheendra Vijayanarasimhan, George Toderici, Susanna Ricco, Rahul Sukthankar, Cordelia Schmid, Jitendra Malik, CVPR. 69Chunhui Gu, Chen Sun, David A. Ross, Carl Von- drick, Caroline Pantofaru, Yeqing Li, Sudheendra Vijaya- narasimhan, George Toderici, Susanna Ricco, Rahul Suk- thankar, Cordelia Schmid, and Jitendra Malik. AVA: A video dataset of spatio-temporally localized atomic visual actions. In CVPR, pages 6047-6056, 2018. 1, 3, 4, 5, 6, 9\n\nActivitynet: A large-scale video benchmark for human activity understanding. Victor Fabian Caba Heilbron, Bernard Escorcia, Juan Carlos Ghanem, Niebles, CVPR. Fabian Caba Heilbron, Victor Escorcia, Bernard Ghanem, and Juan Carlos Niebles. Activitynet: A large-scale video benchmark for human activity understanding. In CVPR, pages 961-970, 2015. 3\n\nThe devil is in the tails: Fine-grained classification in the wild. Grant Van Horn, Pietro Perona, abs/1709.01450CoRRGrant Van Horn and Pietro Perona. The devil is in the tails: Fine-grained classification in the wild. CoRR, abs/1709.01450, 2017. 5\n\nTube convolutional neural network (T-CNN) for action detection in videos. Rui Hou, Chen Chen, Mubarak Shah, ICCV. Rui Hou, Chen Chen, and Mubarak Shah. Tube convolu- tional neural network (T-CNN) for action detection in videos. In ICCV, pages 5823-5832, 2017. 3\n\nThe THUMOS challenge on action recognition for videos. Haroon Idrees, Yu-Gang Amir Roshan Zamir, Alex Jiang, Ivan Gorban, Rahul Laptev, Mubarak Sukthankar, Shah, Comput. Vis. Image Underst. 3Haroon Idrees, Amir Roshan Zamir, Yu-Gang Jiang, Alex Gorban, Ivan Laptev, Rahul Sukthankar, and Mubarak Shah. The THUMOS challenge on action recognition for videos \"in the wild\". Comput. Vis. Image Underst., pages 1-23, 2017. 3\n\nTowards understanding action recognition. Hueihan Jhuang, Juergen Gall, Silvia Zuffi, Cordelia Schmid, Michael J Black, ICCV. 56Hueihan Jhuang, Juergen Gall, Silvia Zuffi, Cordelia Schmid, and Michael J. Black. Towards understanding ac- tion recognition. In ICCV, pages 3192-3199, 2013. 1, 2, 3, 5, 6\n\nAction tubelet detector for spatiotemporal action localization. Vicky Kalogeiton, Philippe Weinzaepfel, Vittorio Ferrari, Cordelia Schmid, ICCV. 36Vicky Kalogeiton, Philippe Weinzaepfel, Vittorio Ferrari, and Cordelia Schmid. Action tubelet detector for spatio- temporal action localization. In ICCV, pages 4415-4423, 2017. 3, 6\n\nLarge-scale video classification with convolutional neural networks. Andrej Karpathy, George Toderici, Sanketh Shetty, Thomas Leung, Rahul Sukthankar, Fei-Fei Li, CVPR. Andrej Karpathy, George Toderici, Sanketh Shetty, Thomas Leung, Rahul Sukthankar, and Fei-Fei Li. Large-scale video classification with convolutional neural networks. In CVPR, pages 1725-1732, 2014. 3\n\nYou only watch once: A unified CNN architecture for real-time spatiotemporal action localization. CoRR, abs/1911.06644. Okan K\u00f6p\u00fckl\u00fc, Xiangyu Wei, Gerhard Rigoll, 79Okan K\u00f6p\u00fckl\u00fc, Xiangyu Wei, and Gerhard Rigoll. You only watch once: A unified CNN architecture for real-time spatiotemporal action localization. CoRR, abs/1911.06644, 2019. 7, 9\n\nHMDB: A large video database for human motion recognition. Hildegard Kuehne, Hueihan Jhuang, Est\u00edbaliz Garrote, A Tomaso, Thomas Poggio, Serre, ICCV. Hildegard Kuehne, Hueihan Jhuang, Est\u00edbaliz Garrote, Tomaso A. Poggio, and Thomas Serre. HMDB: A large video database for human motion recognition. In ICCV, pages 2556-2563, 2011. 3\n\nThe ava-kinetics localized human actions video dataset. CoRR, abs. Ang Li, Meghana Thotakuri, David A Ross, Jo\u00e3o Carreira, Alexander Vostrikov, Andrew Zisserman, 35Ang Li, Meghana Thotakuri, David A. Ross, Jo\u00e3o Car- reira, Alexander Vostrikov, and Andrew Zisserman. The ava-kinetics localized human actions video dataset. CoRR, abs/2005.00214, 2020. 3, 5\n\nRecurrent tubelet proposal and recognition networks for action detection. Dong Li, Zhaofan Qiu, Qi Dai, Ting Yao, Tao Mei, ECCV. Dong Li, Zhaofan Qiu, Qi Dai, Ting Yao, and Tao Mei. Re- current tubelet proposal and recognition networks for action detection. In ECCV, pages 306-322, 2018. 3\n\nActions as moving points. Yixuan Li, Zixu Wang, Limin Wang, Gangshan Wu, ECCV. 79Yixuan Li, Zixu Wang, Limin Wang, and Gangshan Wu. Ac- tions as moving points. In ECCV, pages 68-84, 2020. 3, 6, 7, 9\n\nFeature pyramid networks for object detection. Tsung-Yi Lin, Piotr Doll\u00e1r, Ross B Girshick, Kaiming He, Bharath Hariharan, Serge J Belongie, CVPR. Tsung-Yi Lin, Piotr Doll\u00e1r, Ross B. Girshick, Kaiming He, Bharath Hariharan, and Serge J. Belongie. Feature pyramid networks for object detection. In CVPR, pages 936-944, 2017. 9\n\nBMN: boundary-matching network for temporal action proposal generation. Tianwei Lin, Xiao Liu, Xin Li, Errui Ding, Shilei Wen, ICCV. Tianwei Lin, Xiao Liu, Xin Li, Errui Ding, and Shilei Wen. BMN: boundary-matching network for temporal action pro- posal generation. In ICCV, pages 3888-3897, 2019. 1\n\nMicrosoft COCO: common objects in context. Tsung-Yi Lin, Michael Maire, Serge J Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Lawrence Zitnick, ECCV. Tsung-Yi Lin, Michael Maire, Serge J. Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C. Lawrence Zitnick. Microsoft COCO: common objects in context. In ECCV, pages 740-755, 2014. 9\n\nBSN: boundary sensitive network for temporal action proposal generation. Tianwei Lin, Xu Zhao, Haisheng Su, Chongjing Wang, Ming Yang, ECCV. Tianwei Lin, Xu Zhao, Haisheng Su, Chongjing Wang, and Ming Yang. BSN: boundary sensitive network for temporal action proposal generation. In ECCV, pages 3-21, 2018. 1\n\nSSD: single shot multibox detector. Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott E Reed, Cheng-Yang Fu, Alexander C Berg, ECCV. Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott E. Reed, Cheng-Yang Fu, and Alexander C. Berg. SSD: single shot multibox detector. In ECCV, pages 21-37, 2016. 9\n\nMulti-moments in time: Learning and interpreting models for multi-action video understanding. Mathew Monfort, Kandan Ramakrishnan, Alex Andonian, Barry A Mcnamara, Alex Lascelles, Quanfu Bowen Pan, Dan Fan, Rog\u00e9rio Gutfreund, Aude Schmidt Feris, Oliva, abs/1911.00232CoRRMathew Monfort, Kandan Ramakrishnan, Alex Andonian, Barry A. McNamara, Alex Lascelles, Bowen Pan, Quanfu Fan, Dan Gutfreund, Rog\u00e9rio Schmidt Feris, and Aude Oliva. Multi-moments in time: Learning and interpret- ing models for multi-action video understanding. CoRR, abs/1911.00232, 2019. 3\n\nMulti-region twostream R-CNN for action detection. Xiaojiang Peng, Cordelia Schmid, ECCV. Xiaojiang Peng and Cordelia Schmid. Multi-region two- stream R-CNN for action detection. In ECCV, pages 744- 759, 2016. 3\n\nYOLO9000: better, faster, stronger. Joseph Redmon, Ali Farhadi, CVPR. Joseph Redmon and Ali Farhadi. YOLO9000: better, faster, stronger. In CVPR, pages 6517-6525, 2017. 9\n\nFaster R-CNN: towards real-time object detection with region proposal networks. Kaiming Shaoqing Ren, Ross B He, Jian Girshick, Sun, IEEE Trans. Pattern Anal. Mach. Intell. 396Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. Faster R-CNN: towards real-time object detection with re- gion proposal networks. IEEE Trans. Pattern Anal. Mach. Intell., 39(6):1137-1149, 2017. 7\n\nAction MACH a spatio-temporal maximum average correlation height filter for action recognition. Mikel D Rodriguez, Javed Ahmed, Mubarak Shah, CVPR. Mikel D. Rodriguez, Javed Ahmed, and Mubarak Shah. Ac- tion MACH a spatio-temporal maximum average correlation height filter for action recognition. In CVPR, 2008. 3\n\nDeep learning for detecting multiple space-time action tubes in videos. Suman Saha, Gurkirt Singh, Michael Sapienza, H S Philip, Fabio Torr, Cuzzolin, BMVC. Suman Saha, Gurkirt Singh, Michael Sapienza, Philip H. S. Torr, and Fabio Cuzzolin. Deep learning for detecting multi- ple space-time action tubes in videos. In BMVC, 2016. 3\n\nRecognizing human actions: A local SVM approach. Christian Sch\u00fcldt, Ivan Laptev, Barbara Caputo, ICPR. Christian Sch\u00fcldt, Ivan Laptev, and Barbara Caputo. Rec- ognizing human actions: A local SVM approach. In ICPR, pages 32-36, 2004. 3\n\nFinegym: A hierarchical video dataset for fine-grained action understanding. Dian Shao, Yue Zhao, Bo Dai, Dahua Lin, CVPR. 35Dian Shao, Yue Zhao, Bo Dai, and Dahua Lin. Finegym: A hierarchical video dataset for fine-grained action understand- ing. In CVPR, pages 2613-2622, 2020. 3, 5\n\nHollywood in homes: Crowdsourcing data collection for activity understanding. A Gunnar, G\u00fcl Sigurdsson, Xiaolong Varol, Ali Wang, Ivan Farhadi, Abhinav Laptev, Gupta, ECCV. Gunnar A. Sigurdsson, G\u00fcl Varol, Xiaolong Wang, Ali Farhadi, Ivan Laptev, and Abhinav Gupta. Hollywood in homes: Crowdsourcing data collection for activity under- standing. In ECCV, pages 510-526, 2016. 3\n\nTwo-stream convolutional networks for action recognition in videos. Karen Simonyan, Andrew Zisserman, NIPS. Karen Simonyan and Andrew Zisserman. Two-stream con- volutional networks for action recognition in videos. In NIPS, pages 568-576, 2014. 1\n\nVery deep convolutional networks for large-scale image recognition. Karen Simonyan, Andrew Zisserman, ICLR. Karen Simonyan and Andrew Zisserman. Very deep convo- lutional networks for large-scale image recognition. In ICLR, 2015. 9\n\nOnline real-time multiple spatiotemporal action localisation and prediction. Gurkirt Singh, Suman Saha, Michael Sapienza, H S Philip, Fabio Torr, Cuzzolin, ICCV. 79Gurkirt Singh, Suman Saha, Michael Sapienza, Philip H. S. Torr, and Fabio Cuzzolin. Online real-time multiple spa- tiotemporal action localisation and prediction. In ICCV, pages 3657-3666, 2017. 3, 6, 7, 9\n\nTacnet: Transition-aware context network for spatio-temporal action detection. Lin Song, Shiwei Zhang, Gang Yu, Hongbin Sun, CVPR. Lin Song, Shiwei Zhang, Gang Yu, and Hongbin Sun. Tac- net: Transition-aware context network for spatio-temporal action detection. In CVPR, pages 11987-11995, 2019. 3\n\nUCF101: A dataset of 101 human actions classes from videos in the wild. Khurram Soomro, Mubarak Amir Roshan Zamir, Shah, abs/1212.0402CoRR. 79Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah. UCF101: A dataset of 101 human actions classes from videos in the wild. CoRR, abs/1212.0402, 2012. 1, 2, 3, 5, 6, 7, 9\n\nAsynchronous interaction aggregation for action detection. Jiajun Tang, Jin Xia, Xinzhi Mu, Bo Pang, Cewu Lu, ECCV. 2020Jiajun Tang, Jin Xia, Xinzhi Mu, Bo Pang, and Cewu Lu. Asynchronous interaction aggregation for action detection. In ECCV, pages 71-87, 2020. 3\n\nLearning spatiotemporal features with 3d convolutional networks. Du Tran, D Lubomir, Rob Bourdev, Lorenzo Fergus, Manohar Torresani, Paluri, ICCV. Du Tran, Lubomir D. Bourdev, Rob Fergus, Lorenzo Torre- sani, and Manohar Paluri. Learning spatiotemporal features with 3d convolutional networks. In ICCV, pages 4489-4497, 2015. 1\n\nAppearance-and-relation networks for video classification. Limin Wang, Wei Li, Wen Li, Luc Van Gool, CVPR. Limin Wang, Wei Li, Wen Li, and Luc Van Gool. Appearance-and-relation networks for video classification. In CVPR, pages 1430-1439, 2018. 1\n\nAction recognition with trajectory-pooled deep-convolutional descriptors. Limin Wang, Yu Qiao, Xiaoou Tang, CVPR. Limin Wang, Yu Qiao, and Xiaoou Tang. Action recogni- tion with trajectory-pooled deep-convolutional descriptors. In CVPR, pages 4305-4314, 2015. 1\n\nActionness estimation using hybrid fully convolutional networks. Limin Wang, Yu Qiao, Xiaoou Tang, Luc Van Gool, CVPR. Limin Wang, Yu Qiao, Xiaoou Tang, and Luc Van Gool. Actionness estimation using hybrid fully convolutional net- works. In CVPR, pages 2708-2717, 2016. 3\n\nTemporal segment networks: Towards good practices for deep action recognition. Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, Luc Van Gool, ECCV. Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, and Luc Van Gool. Temporal segment networks: Towards good practices for deep action recogni- tion. In ECCV, pages 20-36, 2016. 1\n\nLearning to track for spatio-temporal action localization. Philippe Weinzaepfel, Za\u00efd Harchaoui, Cordelia Schmid, ICCV. 36Philippe Weinzaepfel, Za\u00efd Harchaoui, and Cordelia Schmid. Learning to track for spatio-temporal action local- ization. In ICCV, pages 3164-3172, 2015. 3, 6\n\nTowards weakly-supervised action localization. Philippe Weinzaepfel, Xavier Martin, Cordelia Schmid, abs/1605.05197CoRRPhilippe Weinzaepfel, Xavier Martin, and Cordelia Schmid. Towards weakly-supervised action localization. CoRR, abs/1605.05197, 2016. 3\n\nLongterm feature banks for detailed video understanding. Chao-Yuan, Christoph Wu, Haoqi Feichtenhofer, Kaiming Fan, Philipp He, Ross B Kr\u00e4henb\u00fchl, Girshick, CVPR. 310Chao-Yuan Wu, Christoph Feichtenhofer, Haoqi Fan, Kaim- ing He, Philipp Kr\u00e4henb\u00fchl, and Ross B. Girshick. Long- term feature banks for detailed video understanding. In CVPR, pages 284-293, 2019. 3, 9, 10\n\nContext-aware RCNN: A baseline for action detection in videos. Jianchao Wu, Zhanghui Kuang, Limin Wang, Wayne Zhang, Gangshan Wu, ECCV. 2020Jianchao Wu, Zhanghui Kuang, Limin Wang, Wayne Zhang, and Gangshan Wu. Context-aware RCNN: A baseline for action detection in videos. In ECCV, pages 440-456, 2020. 3\n\nObject tracking benchmark. Yi Wu, Jongwoo Lim, Ming-Hsuan Yang, IEEE Trans. Pattern Anal. Mach. Intell. 379Yi Wu, Jongwoo Lim, and Ming-Hsuan Yang. Object track- ing benchmark. IEEE Trans. Pattern Anal. Mach. Intell., 37(9):1834-1848, 2015. 4\n\nAggregated residual transformations for deep neural networks. Saining Xie, Ross B Girshick, Piotr Doll\u00e1r, Zhuowen Tu, Kaiming He, CVPR. Saining Xie, Ross B. Girshick, Piotr Doll\u00e1r, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In CVPR, pages 5987-5995, 2017. 9\n\nR-C3D: region convolutional 3d network for temporal activity detection. Huijuan Xu, Abir Das, Kate Saenko, ICCV. Huijuan Xu, Abir Das, and Kate Saenko. R-C3D: region convolutional 3d network for temporal activity detection. In ICCV, pages 5794-5803, 2017. 1\n\nSTEP: spatio-temporal progressive learning for video action detection. Xitong Yang, Xiaodong Yang, Ming-Yu Liu, Fanyi Xiao, Larry S Davis, Jan Kautz, CVPR. Xitong Yang, Xiaodong Yang, Ming-Yu Liu, Fanyi Xiao, Larry S. Davis, and Jan Kautz. STEP: spatio-temporal pro- gressive learning for video action detection. In CVPR, pages 264-272, 2019. 3\n\nEvery moment counts: Dense detailed labeling of actions in complex videos. Serena Yeung, Olga Russakovsky, Ning Jin, Mykhaylo Andriluka, Greg Mori, Li Fei-Fei, Int. J. Comput. Vis. 3Serena Yeung, Olga Russakovsky, Ning Jin, Mykhaylo An- driluka, Greg Mori, and Li Fei-Fei. Every moment counts: Dense detailed labeling of actions in complex videos. Int. J. Comput. Vis., pages 375-389, 2018. 3\n\nDeep layer aggregation. Fisher Yu, Dequan Wang, Evan Shelhamer, Trevor Darrell, CVPR. Fisher Yu, Dequan Wang, Evan Shelhamer, and Trevor Dar- rell. Deep layer aggregation. In CVPR, pages 2403-2412, 2018. 9\n\nGraph convolutional networks for temporal action localization. Runhao Zeng, Wenbing Huang, Chuang Gan, Mingkui Tan, Yu Rong, Peilin Zhao, Junzhou Huang, ICCV. Runhao Zeng, Wenbing Huang, Chuang Gan, Mingkui Tan, Yu Rong, Peilin Zhao, and Junzhou Huang. Graph convo- lutional networks for temporal action localization. In ICCV, pages 7093-7102, 2019. 1\n\nHACS: human action clips and segments dataset for recognition and temporal localization. Hang Zhao, Antonio Torralba, Lorenzo Torresani, Zhicheng Yan, ICCV. 35Hang Zhao, Antonio Torralba, Lorenzo Torresani, and Zhicheng Yan. HACS: human action clips and segments dataset for recognition and temporal localization. In ICCV, pages 8667-8677, 2019. 3, 5\n\nDance with flow: Twoin-one stream action detection. Jiaojiao Zhao, G M Cees, Snoek, CVPR. Jiaojiao Zhao and Cees G. M. Snoek. Dance with flow: Two- in-one stream action detection. In CVPR, pages 9935-9944, 2019. 3\n\nTemporal action detection with structured segment networks. Yue Zhao, Yuanjun Xiong, Limin Wang, Zhirong Wu, Xiaoou Tang, Dahua Lin, ICCV. Yue Zhao, Yuanjun Xiong, Limin Wang, Zhirong Wu, Xi- aoou Tang, and Dahua Lin. Temporal action detection with structured segment networks. In ICCV, pages 2933-2942, 2017. 1\n", "annotations": {"author": "[{\"end\":178,\"start\":91},{\"end\":265,\"start\":179},{\"end\":352,\"start\":266},{\"end\":443,\"start\":353},{\"end\":533,\"start\":444},{\"end\":622,\"start\":534}]", "publisher": null, "author_last_name": "[{\"end\":100,\"start\":98},{\"end\":187,\"start\":183},{\"end\":274,\"start\":272},{\"end\":365,\"start\":361},{\"end\":455,\"start\":453},{\"end\":544,\"start\":540}]", "author_first_name": "[{\"end\":97,\"start\":91},{\"end\":182,\"start\":179},{\"end\":271,\"start\":266},{\"end\":360,\"start\":353},{\"end\":452,\"start\":444},{\"end\":539,\"start\":534}]", "author_affiliation": "[{\"end\":177,\"start\":102},{\"end\":264,\"start\":189},{\"end\":351,\"start\":276},{\"end\":442,\"start\":367},{\"end\":532,\"start\":457},{\"end\":621,\"start\":546}]", "title": "[{\"end\":88,\"start\":1},{\"end\":710,\"start\":623}]", "venue": null, "abstract": "[{\"end\":2153,\"start\":712}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b51\"},\"end\":2411,\"start\":2407},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2413,\"start\":2411},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":2416,\"start\":2413},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2419,\"start\":2416},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":2422,\"start\":2419},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":2425,\"start\":2422},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":2588,\"start\":2584},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":2591,\"start\":2588},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2594,\"start\":2591},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":2597,\"start\":2594},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":2600,\"start\":2597},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3026,\"start\":3022},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3045,\"start\":3041},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3490,\"start\":3486},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5629,\"start\":5626},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5633,\"start\":5631},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6332,\"start\":6329},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6957,\"start\":6953},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":6976,\"start\":6972},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8432,\"start\":8428},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8446,\"start\":8443},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":8460,\"start\":8456},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8474,\"start\":8470},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8652,\"start\":8648},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8876,\"start\":8872},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8892,\"start\":8889},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8909,\"start\":8906},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9089,\"start\":9085},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":9106,\"start\":9102},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9491,\"start\":9487},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":9502,\"start\":9498},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9517,\"start\":9513},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":9536,\"start\":9532},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":9554,\"start\":9550},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":9862,\"start\":9858},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":9878,\"start\":9874},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9894,\"start\":9890},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":10378,\"start\":10374},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10388,\"start\":10384},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10410,\"start\":10406},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10805,\"start\":10802},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11502,\"start\":11498},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":11505,\"start\":11502},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11508,\"start\":11505},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":11511,\"start\":11508},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":11514,\"start\":11511},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":11517,\"start\":11514},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11830,\"start\":11826},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":11833,\"start\":11830},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11836,\"start\":11833},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":11839,\"start\":11836},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11842,\"start\":11839},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":11845,\"start\":11842},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":11848,\"start\":11845},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11877,\"start\":11873},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":11969,\"start\":11965},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12120,\"start\":12116},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":12251,\"start\":12247},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12254,\"start\":12251},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":12257,\"start\":12254},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":12260,\"start\":12257},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":12263,\"start\":12260},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13092,\"start\":13089},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":15499,\"start\":15496},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16508,\"start\":16505},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16808,\"start\":16805},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":16905,\"start\":16901},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":17918,\"start\":17914},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":18503,\"start\":18499},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":18546,\"start\":18543},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18748,\"start\":18744},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":18767,\"start\":18763},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":19326,\"start\":19322},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":19651,\"start\":19647},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20022,\"start\":20018},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22694,\"start\":22690},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":23414,\"start\":23410},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":23417,\"start\":23414},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":23890,\"start\":23886},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":23902,\"start\":23898},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23916,\"start\":23912},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23998,\"start\":23995},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":24136,\"start\":24132},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":24151,\"start\":24147},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24407,\"start\":24403},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":24474,\"start\":24470},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":24628,\"start\":24624},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":24643,\"start\":24639},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":25068,\"start\":25064},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":25185,\"start\":25181},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":25208,\"start\":25204},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":26028,\"start\":26024},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":27919,\"start\":27915},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":29202,\"start\":29198},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":29242,\"start\":29238},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":33920,\"start\":33917},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":35297,\"start\":35293},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":35399,\"start\":35395},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":35657,\"start\":35653},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":35743,\"start\":35739},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":35786,\"start\":35782},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":36210,\"start\":36206},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":36635,\"start\":36631},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":36912,\"start\":36908},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":36968,\"start\":36965},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":37125,\"start\":37121},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":37434,\"start\":37430},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":37674,\"start\":37670},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":37732,\"start\":37728},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":37790,\"start\":37786},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":37959,\"start\":37955},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":38301,\"start\":38297},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":38304,\"start\":38301},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":38352,\"start\":38349},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":38392,\"start\":38388},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":38575,\"start\":38572},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":38600,\"start\":38596},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":38723,\"start\":38719},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":38726,\"start\":38723},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":38804,\"start\":38800},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":38807,\"start\":38804},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":38882,\"start\":38879},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":39232,\"start\":39229},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":44106,\"start\":44103},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":49738,\"start\":49735}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":67449,\"start\":66929},{\"attributes\":{\"id\":\"fig_1\"},\"end\":67718,\"start\":67450},{\"attributes\":{\"id\":\"fig_2\"},\"end\":67970,\"start\":67719},{\"attributes\":{\"id\":\"fig_4\"},\"end\":68038,\"start\":67971},{\"attributes\":{\"id\":\"fig_6\"},\"end\":68426,\"start\":68039},{\"attributes\":{\"id\":\"fig_7\"},\"end\":68562,\"start\":68427},{\"attributes\":{\"id\":\"fig_8\"},\"end\":70049,\"start\":68563},{\"attributes\":{\"id\":\"fig_9\"},\"end\":70461,\"start\":70050},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":70936,\"start\":70462},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":71429,\"start\":70937}]", "paragraph": "[{\"end\":2867,\"start\":2169},{\"end\":3834,\"start\":2869},{\"end\":4742,\"start\":3836},{\"end\":5970,\"start\":4744},{\"end\":6638,\"start\":5972},{\"end\":7788,\"start\":6640},{\"end\":8276,\"start\":7790},{\"end\":9429,\"start\":8293},{\"end\":9785,\"start\":9431},{\"end\":11232,\"start\":9787},{\"end\":12366,\"start\":11234},{\"end\":12801,\"start\":12394},{\"end\":15803,\"start\":12826},{\"end\":16767,\"start\":15805},{\"end\":17429,\"start\":16769},{\"end\":19881,\"start\":17452},{\"end\":20557,\"start\":19883},{\"end\":20721,\"start\":20559},{\"end\":22062,\"start\":20749},{\"end\":22404,\"start\":22064},{\"end\":23719,\"start\":22456},{\"end\":24116,\"start\":23764},{\"end\":25054,\"start\":24118},{\"end\":25898,\"start\":25056},{\"end\":29099,\"start\":25917},{\"end\":31258,\"start\":29118},{\"end\":31977,\"start\":31260},{\"end\":32842,\"start\":31992},{\"end\":33229,\"start\":32844},{\"end\":33866,\"start\":33305},{\"end\":34599,\"start\":33912},{\"end\":35257,\"start\":34635},{\"end\":38793,\"start\":35288},{\"end\":39261,\"start\":38795},{\"end\":39686,\"start\":39263},{\"end\":39714,\"start\":39688},{\"end\":39941,\"start\":39733},{\"end\":40219,\"start\":39943},{\"end\":40420,\"start\":40221},{\"end\":40756,\"start\":40422},{\"end\":40947,\"start\":40758},{\"end\":41294,\"start\":40949},{\"end\":41603,\"start\":41296},{\"end\":41934,\"start\":41605},{\"end\":42284,\"start\":41936},{\"end\":42565,\"start\":42286},{\"end\":42720,\"start\":42610},{\"end\":43709,\"start\":42745},{\"end\":43999,\"start\":43773},{\"end\":44107,\"start\":44001},{\"end\":44455,\"start\":44109},{\"end\":44687,\"start\":44457},{\"end\":45107,\"start\":44689},{\"end\":45425,\"start\":45109},{\"end\":46054,\"start\":45427},{\"end\":47005,\"start\":46056},{\"end\":47191,\"start\":47007},{\"end\":47527,\"start\":47193},{\"end\":47709,\"start\":47529},{\"end\":47928,\"start\":47711},{\"end\":48042,\"start\":47930},{\"end\":48297,\"start\":48044},{\"end\":48404,\"start\":48299},{\"end\":48486,\"start\":48406},{\"end\":48777,\"start\":48488},{\"end\":49035,\"start\":48779},{\"end\":49068,\"start\":49037},{\"end\":49188,\"start\":49070},{\"end\":49361,\"start\":49190},{\"end\":49487,\"start\":49363},{\"end\":49649,\"start\":49489},{\"end\":49910,\"start\":49651},{\"end\":50187,\"start\":49929},{\"end\":50449,\"start\":50189},{\"end\":50876,\"start\":50451},{\"end\":51337,\"start\":50878},{\"end\":51777,\"start\":51339},{\"end\":51944,\"start\":51779},{\"end\":52164,\"start\":51946},{\"end\":52191,\"start\":52166},{\"end\":52684,\"start\":52193},{\"end\":52824,\"start\":52686},{\"end\":52955,\"start\":52826},{\"end\":53175,\"start\":52957},{\"end\":53878,\"start\":53177},{\"end\":54494,\"start\":53895},{\"end\":55102,\"start\":54496},{\"end\":55698,\"start\":55104},{\"end\":56550,\"start\":55700},{\"end\":57296,\"start\":56552},{\"end\":57540,\"start\":57298},{\"end\":58194,\"start\":57542},{\"end\":58370,\"start\":58196},{\"end\":58593,\"start\":58372},{\"end\":59230,\"start\":58595},{\"end\":59410,\"start\":59232},{\"end\":60190,\"start\":59412},{\"end\":60872,\"start\":60192},{\"end\":61339,\"start\":60874},{\"end\":61769,\"start\":61341},{\"end\":61951,\"start\":61788},{\"end\":62402,\"start\":61953},{\"end\":62657,\"start\":62404},{\"end\":62714,\"start\":62659},{\"end\":62924,\"start\":62716},{\"end\":62981,\"start\":62926},{\"end\":63191,\"start\":62983},{\"end\":63495,\"start\":63193},{\"end\":63812,\"start\":63497},{\"end\":64125,\"start\":63814},{\"end\":64438,\"start\":64127},{\"end\":64712,\"start\":64440},{\"end\":64875,\"start\":64714},{\"end\":64952,\"start\":64877},{\"end\":65259,\"start\":64954},{\"end\":65574,\"start\":65261},{\"end\":65904,\"start\":65576},{\"end\":66017,\"start\":65906},{\"end\":66206,\"start\":66019},{\"end\":66366,\"start\":66208},{\"end\":66409,\"start\":66368},{\"end\":66596,\"start\":66411},{\"end\":66806,\"start\":66598},{\"end\":66864,\"start\":66808},{\"end\":66928,\"start\":66866}]", "formula": null, "table_ref": "[{\"end\":16841,\"start\":16834},{\"end\":17816,\"start\":17809},{\"end\":18044,\"start\":18037},{\"end\":23927,\"start\":23920},{\"end\":26760,\"start\":26753},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":29286,\"start\":29279},{\"end\":29483,\"start\":29476},{\"end\":31525,\"start\":31518},{\"end\":33496,\"start\":33489},{\"end\":34975,\"start\":34968},{\"end\":38734,\"start\":38727}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2167,\"start\":2155},{\"attributes\":{\"n\":\"2.\"},\"end\":8291,\"start\":8279},{\"attributes\":{\"n\":\"3.\"},\"end\":12392,\"start\":12369},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12824,\"start\":12804},{\"attributes\":{\"n\":\"3.2.\"},\"end\":17450,\"start\":17432},{\"attributes\":{\"n\":\"3.3.\"},\"end\":20747,\"start\":20724},{\"attributes\":{\"n\":\"4.\"},\"end\":22431,\"start\":22407},{\"attributes\":{\"n\":\"4.1.\"},\"end\":22454,\"start\":22434},{\"attributes\":{\"n\":\"4.2.\"},\"end\":23762,\"start\":23722},{\"attributes\":{\"n\":\"4.3.\"},\"end\":25915,\"start\":25901},{\"attributes\":{\"n\":\"4.4.\"},\"end\":29116,\"start\":29102},{\"attributes\":{\"n\":\"5.\"},\"end\":31990,\"start\":31980},{\"end\":33264,\"start\":33232},{\"end\":33303,\"start\":33267},{\"end\":33910,\"start\":33869},{\"end\":34633,\"start\":34602},{\"end\":35286,\"start\":35260},{\"end\":39731,\"start\":39717},{\"end\":42608,\"start\":42568},{\"end\":42743,\"start\":42723},{\"end\":43771,\"start\":43712},{\"end\":49927,\"start\":49913},{\"end\":53893,\"start\":53881},{\"end\":61786,\"start\":61772},{\"end\":66940,\"start\":66930},{\"end\":67461,\"start\":67451},{\"end\":67730,\"start\":67720},{\"end\":67982,\"start\":67972},{\"end\":68050,\"start\":68040},{\"end\":68438,\"start\":68428},{\"end\":68585,\"start\":68564},{\"end\":70052,\"start\":70051},{\"end\":70472,\"start\":70463}]", "table": "[{\"end\":70936,\"start\":70564},{\"end\":71429,\"start\":70959}]", "figure_caption": "[{\"end\":67449,\"start\":66942},{\"end\":67718,\"start\":67463},{\"end\":67970,\"start\":67732},{\"end\":68038,\"start\":67984},{\"end\":68426,\"start\":68052},{\"end\":68562,\"start\":68440},{\"end\":70049,\"start\":68589},{\"end\":70461,\"start\":70053},{\"end\":70564,\"start\":70474},{\"end\":70959,\"start\":70939}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5209,\"start\":5201},{\"end\":13807,\"start\":13800},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15799,\"start\":15791},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":19903,\"start\":19895},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20121,\"start\":20113},{\"end\":25430,\"start\":25422},{\"end\":26857,\"start\":26849},{\"end\":27703,\"start\":27695},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29098,\"start\":29090},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":29855,\"start\":29847},{\"end\":30230,\"start\":30222},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":39900,\"start\":39892},{\"end\":42630,\"start\":42622},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":42706,\"start\":42698},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":42844,\"start\":42835},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":45365,\"start\":45356},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":49721,\"start\":49712}]", "bib_author_first_name": "[{\"end\":71493,\"start\":71489},{\"end\":71514,\"start\":71508},{\"end\":71532,\"start\":71524},{\"end\":71542,\"start\":71538},{\"end\":71557,\"start\":71551},{\"end\":71580,\"start\":71568},{\"end\":71604,\"start\":71594},{\"end\":71907,\"start\":71902},{\"end\":71919,\"start\":71915},{\"end\":71933,\"start\":71930},{\"end\":71951,\"start\":71945},{\"end\":71964,\"start\":71959},{\"end\":72190,\"start\":72186},{\"end\":72207,\"start\":72201},{\"end\":72441,\"start\":72438},{\"end\":72453,\"start\":72448},{\"end\":72469,\"start\":72460},{\"end\":72482,\"start\":72476},{\"end\":72490,\"start\":72488},{\"end\":72506,\"start\":72498},{\"end\":72518,\"start\":72511},{\"end\":72530,\"start\":72524},{\"end\":72542,\"start\":72537},{\"end\":72554,\"start\":72548},{\"end\":72564,\"start\":72559},{\"end\":72577,\"start\":72572},{\"end\":72593,\"start\":72585},{\"end\":72607,\"start\":72599},{\"end\":72620,\"start\":72615},{\"end\":72631,\"start\":72627},{\"end\":72639,\"start\":72636},{\"end\":72647,\"start\":72644},{\"end\":72656,\"start\":72653},{\"end\":72667,\"start\":72661},{\"end\":72681,\"start\":72673},{\"end\":73535,\"start\":73529},{\"end\":73549,\"start\":73544},{\"end\":73811,\"start\":73806},{\"end\":73822,\"start\":73817},{\"end\":73835,\"start\":73830},{\"end\":73850,\"start\":73842},{\"end\":74307,\"start\":74304},{\"end\":74317,\"start\":74314},{\"end\":74331,\"start\":74324},{\"end\":74346,\"start\":74340},{\"end\":74354,\"start\":74351},{\"end\":74366,\"start\":74359},{\"end\":74596,\"start\":74595},{\"end\":74598,\"start\":74597},{\"end\":74619,\"start\":74616},{\"end\":74643,\"start\":74642},{\"end\":74645,\"start\":74644},{\"end\":74663,\"start\":74659},{\"end\":74665,\"start\":74664},{\"end\":74682,\"start\":74676},{\"end\":74993,\"start\":74984},{\"end\":75014,\"start\":75009},{\"end\":75028,\"start\":75020},{\"end\":75043,\"start\":75036},{\"end\":75274,\"start\":75269},{\"end\":75288,\"start\":75284},{\"end\":75303,\"start\":75299},{\"end\":75483,\"start\":75476},{\"end\":75502,\"start\":75494},{\"end\":75704,\"start\":75698},{\"end\":75718,\"start\":75712},{\"end\":75727,\"start\":75719},{\"end\":75742,\"start\":75735},{\"end\":75760,\"start\":75754},{\"end\":75781,\"start\":75774},{\"end\":75797,\"start\":75792},{\"end\":75811,\"start\":75803},{\"end\":75824,\"start\":75820},{\"end\":75837,\"start\":75832},{\"end\":75854,\"start\":75848},{\"end\":75879,\"start\":75872},{\"end\":75896,\"start\":75887},{\"end\":75909,\"start\":75905},{\"end\":75921,\"start\":75915},{\"end\":76388,\"start\":76381},{\"end\":76397,\"start\":76393},{\"end\":76408,\"start\":76403},{\"end\":76410,\"start\":76409},{\"end\":76421,\"start\":76417},{\"end\":76440,\"start\":76432},{\"end\":76458,\"start\":76452},{\"end\":76473,\"start\":76463},{\"end\":76498,\"start\":76492},{\"end\":76516,\"start\":76509},{\"end\":76529,\"start\":76524},{\"end\":76550,\"start\":76542},{\"end\":76567,\"start\":76559},{\"end\":76996,\"start\":76990},{\"end\":77026,\"start\":77019},{\"end\":77041,\"start\":77037},{\"end\":77048,\"start\":77042},{\"end\":77335,\"start\":77330},{\"end\":77352,\"start\":77346},{\"end\":77589,\"start\":77586},{\"end\":77599,\"start\":77595},{\"end\":77613,\"start\":77606},{\"end\":77836,\"start\":77830},{\"end\":77852,\"start\":77845},{\"end\":77876,\"start\":77872},{\"end\":77888,\"start\":77884},{\"end\":77902,\"start\":77897},{\"end\":77918,\"start\":77911},{\"end\":78245,\"start\":78238},{\"end\":78261,\"start\":78254},{\"end\":78274,\"start\":78268},{\"end\":78290,\"start\":78282},{\"end\":78306,\"start\":78299},{\"end\":78308,\"start\":78307},{\"end\":78567,\"start\":78562},{\"end\":78588,\"start\":78580},{\"end\":78610,\"start\":78602},{\"end\":78628,\"start\":78620},{\"end\":78903,\"start\":78897},{\"end\":78920,\"start\":78914},{\"end\":78938,\"start\":78931},{\"end\":78953,\"start\":78947},{\"end\":78966,\"start\":78961},{\"end\":78986,\"start\":78979},{\"end\":79323,\"start\":79319},{\"end\":79340,\"start\":79333},{\"end\":79353,\"start\":79346},{\"end\":79611,\"start\":79602},{\"end\":79627,\"start\":79620},{\"end\":79645,\"start\":79636},{\"end\":79656,\"start\":79655},{\"end\":79671,\"start\":79665},{\"end\":79946,\"start\":79943},{\"end\":79958,\"start\":79951},{\"end\":79975,\"start\":79970},{\"end\":79977,\"start\":79976},{\"end\":79988,\"start\":79984},{\"end\":80008,\"start\":79999},{\"end\":80026,\"start\":80020},{\"end\":80310,\"start\":80306},{\"end\":80322,\"start\":80315},{\"end\":80330,\"start\":80328},{\"end\":80340,\"start\":80336},{\"end\":80349,\"start\":80346},{\"end\":80555,\"start\":80549},{\"end\":80564,\"start\":80560},{\"end\":80576,\"start\":80571},{\"end\":80591,\"start\":80583},{\"end\":80778,\"start\":80770},{\"end\":80789,\"start\":80784},{\"end\":80802,\"start\":80798},{\"end\":80804,\"start\":80803},{\"end\":80822,\"start\":80815},{\"end\":80834,\"start\":80827},{\"end\":80851,\"start\":80846},{\"end\":80853,\"start\":80852},{\"end\":81129,\"start\":81122},{\"end\":81139,\"start\":81135},{\"end\":81148,\"start\":81145},{\"end\":81158,\"start\":81153},{\"end\":81171,\"start\":81165},{\"end\":81402,\"start\":81394},{\"end\":81415,\"start\":81408},{\"end\":81428,\"start\":81423},{\"end\":81430,\"start\":81429},{\"end\":81446,\"start\":81441},{\"end\":81459,\"start\":81453},{\"end\":81472,\"start\":81468},{\"end\":81487,\"start\":81482},{\"end\":81497,\"start\":81496},{\"end\":81506,\"start\":81498},{\"end\":81806,\"start\":81799},{\"end\":81814,\"start\":81812},{\"end\":81829,\"start\":81821},{\"end\":81843,\"start\":81834},{\"end\":81854,\"start\":81850},{\"end\":82075,\"start\":82072},{\"end\":82089,\"start\":82081},{\"end\":82107,\"start\":82100},{\"end\":82124,\"start\":82115},{\"end\":82139,\"start\":82134},{\"end\":82141,\"start\":82140},{\"end\":82158,\"start\":82148},{\"end\":82172,\"start\":82163},{\"end\":82174,\"start\":82173},{\"end\":82469,\"start\":82463},{\"end\":82485,\"start\":82479},{\"end\":82504,\"start\":82500},{\"end\":82520,\"start\":82515},{\"end\":82522,\"start\":82521},{\"end\":82537,\"start\":82533},{\"end\":82555,\"start\":82549},{\"end\":82570,\"start\":82567},{\"end\":82583,\"start\":82576},{\"end\":82599,\"start\":82595},{\"end\":82991,\"start\":82982},{\"end\":83006,\"start\":82998},{\"end\":83186,\"start\":83180},{\"end\":83198,\"start\":83195},{\"end\":83403,\"start\":83396},{\"end\":83422,\"start\":83418},{\"end\":83424,\"start\":83423},{\"end\":83433,\"start\":83429},{\"end\":83800,\"start\":83795},{\"end\":83802,\"start\":83801},{\"end\":83819,\"start\":83814},{\"end\":83834,\"start\":83827},{\"end\":84091,\"start\":84086},{\"end\":84105,\"start\":84098},{\"end\":84120,\"start\":84113},{\"end\":84132,\"start\":84131},{\"end\":84134,\"start\":84133},{\"end\":84148,\"start\":84143},{\"end\":84405,\"start\":84396},{\"end\":84419,\"start\":84415},{\"end\":84435,\"start\":84428},{\"end\":84665,\"start\":84661},{\"end\":84675,\"start\":84672},{\"end\":84684,\"start\":84682},{\"end\":84695,\"start\":84690},{\"end\":84949,\"start\":84948},{\"end\":84961,\"start\":84958},{\"end\":84982,\"start\":84974},{\"end\":84993,\"start\":84990},{\"end\":85004,\"start\":85000},{\"end\":85021,\"start\":85014},{\"end\":85322,\"start\":85317},{\"end\":85339,\"start\":85333},{\"end\":85570,\"start\":85565},{\"end\":85587,\"start\":85581},{\"end\":85814,\"start\":85807},{\"end\":85827,\"start\":85822},{\"end\":85841,\"start\":85834},{\"end\":85853,\"start\":85852},{\"end\":85855,\"start\":85854},{\"end\":85869,\"start\":85864},{\"end\":86183,\"start\":86180},{\"end\":86196,\"start\":86190},{\"end\":86208,\"start\":86204},{\"end\":86220,\"start\":86213},{\"end\":86479,\"start\":86472},{\"end\":86495,\"start\":86488},{\"end\":86780,\"start\":86774},{\"end\":86790,\"start\":86787},{\"end\":86802,\"start\":86796},{\"end\":86809,\"start\":86807},{\"end\":86820,\"start\":86816},{\"end\":87047,\"start\":87045},{\"end\":87055,\"start\":87054},{\"end\":87068,\"start\":87065},{\"end\":87085,\"start\":87078},{\"end\":87101,\"start\":87094},{\"end\":87373,\"start\":87368},{\"end\":87383,\"start\":87380},{\"end\":87391,\"start\":87388},{\"end\":87399,\"start\":87396},{\"end\":87635,\"start\":87630},{\"end\":87644,\"start\":87642},{\"end\":87657,\"start\":87651},{\"end\":87889,\"start\":87884},{\"end\":87898,\"start\":87896},{\"end\":87911,\"start\":87905},{\"end\":87921,\"start\":87918},{\"end\":88176,\"start\":88171},{\"end\":88190,\"start\":88183},{\"end\":88201,\"start\":88198},{\"end\":88210,\"start\":88208},{\"end\":88222,\"start\":88217},{\"end\":88234,\"start\":88228},{\"end\":88244,\"start\":88241},{\"end\":88528,\"start\":88520},{\"end\":88546,\"start\":88542},{\"end\":88566,\"start\":88558},{\"end\":88796,\"start\":88788},{\"end\":88816,\"start\":88810},{\"end\":88833,\"start\":88825},{\"end\":89073,\"start\":89064},{\"end\":89083,\"start\":89078},{\"end\":89106,\"start\":89099},{\"end\":89119,\"start\":89112},{\"end\":89128,\"start\":89124},{\"end\":89130,\"start\":89129},{\"end\":89438,\"start\":89430},{\"end\":89451,\"start\":89443},{\"end\":89464,\"start\":89459},{\"end\":89476,\"start\":89471},{\"end\":89492,\"start\":89484},{\"end\":89703,\"start\":89701},{\"end\":89715,\"start\":89708},{\"end\":89731,\"start\":89721},{\"end\":89987,\"start\":89980},{\"end\":89997,\"start\":89993},{\"end\":89999,\"start\":89998},{\"end\":90015,\"start\":90010},{\"end\":90031,\"start\":90024},{\"end\":90043,\"start\":90036},{\"end\":90303,\"start\":90296},{\"end\":90312,\"start\":90308},{\"end\":90322,\"start\":90318},{\"end\":90560,\"start\":90554},{\"end\":90575,\"start\":90567},{\"end\":90589,\"start\":90582},{\"end\":90600,\"start\":90595},{\"end\":90612,\"start\":90607},{\"end\":90614,\"start\":90613},{\"end\":90625,\"start\":90622},{\"end\":90910,\"start\":90904},{\"end\":90922,\"start\":90918},{\"end\":90940,\"start\":90936},{\"end\":90954,\"start\":90946},{\"end\":90970,\"start\":90966},{\"end\":90979,\"start\":90977},{\"end\":91253,\"start\":91247},{\"end\":91264,\"start\":91258},{\"end\":91275,\"start\":91271},{\"end\":91293,\"start\":91287},{\"end\":91499,\"start\":91493},{\"end\":91513,\"start\":91506},{\"end\":91527,\"start\":91521},{\"end\":91540,\"start\":91533},{\"end\":91548,\"start\":91546},{\"end\":91561,\"start\":91555},{\"end\":91575,\"start\":91568},{\"end\":91876,\"start\":91872},{\"end\":91890,\"start\":91883},{\"end\":91908,\"start\":91901},{\"end\":91928,\"start\":91920},{\"end\":92195,\"start\":92187},{\"end\":92203,\"start\":92202},{\"end\":92205,\"start\":92204},{\"end\":92413,\"start\":92410},{\"end\":92427,\"start\":92420},{\"end\":92440,\"start\":92435},{\"end\":92454,\"start\":92447},{\"end\":92465,\"start\":92459},{\"end\":92477,\"start\":92472}]", "bib_author_last_name": "[{\"end\":71506,\"start\":71494},{\"end\":71522,\"start\":71515},{\"end\":71536,\"start\":71533},{\"end\":71549,\"start\":71543},{\"end\":71566,\"start\":71558},{\"end\":71592,\"start\":71581},{\"end\":71621,\"start\":71605},{\"end\":71913,\"start\":71908},{\"end\":71928,\"start\":71920},{\"end\":71943,\"start\":71934},{\"end\":71957,\"start\":71952},{\"end\":71970,\"start\":71965},{\"end\":72199,\"start\":72191},{\"end\":72217,\"start\":72208},{\"end\":72446,\"start\":72442},{\"end\":72458,\"start\":72454},{\"end\":72474,\"start\":72470},{\"end\":72486,\"start\":72483},{\"end\":72496,\"start\":72491},{\"end\":72509,\"start\":72507},{\"end\":72522,\"start\":72519},{\"end\":72535,\"start\":72531},{\"end\":72546,\"start\":72543},{\"end\":72557,\"start\":72555},{\"end\":72570,\"start\":72565},{\"end\":72583,\"start\":72578},{\"end\":72597,\"start\":72594},{\"end\":72613,\"start\":72608},{\"end\":72625,\"start\":72621},{\"end\":72634,\"start\":72632},{\"end\":72642,\"start\":72640},{\"end\":72651,\"start\":72648},{\"end\":72659,\"start\":72657},{\"end\":72671,\"start\":72668},{\"end\":72686,\"start\":72682},{\"end\":73542,\"start\":73536},{\"end\":73559,\"start\":73550},{\"end\":73815,\"start\":73812},{\"end\":73828,\"start\":73823},{\"end\":73840,\"start\":73836},{\"end\":73853,\"start\":73851},{\"end\":74312,\"start\":74308},{\"end\":74322,\"start\":74318},{\"end\":74338,\"start\":74332},{\"end\":74349,\"start\":74347},{\"end\":74357,\"start\":74355},{\"end\":74369,\"start\":74367},{\"end\":74614,\"start\":74599},{\"end\":74630,\"start\":74620},{\"end\":74640,\"start\":74632},{\"end\":74657,\"start\":74646},{\"end\":74674,\"start\":74666},{\"end\":74687,\"start\":74683},{\"end\":74698,\"start\":74689},{\"end\":75007,\"start\":74994},{\"end\":75018,\"start\":75015},{\"end\":75034,\"start\":75029},{\"end\":75046,\"start\":75044},{\"end\":75282,\"start\":75275},{\"end\":75297,\"start\":75289},{\"end\":75311,\"start\":75304},{\"end\":75492,\"start\":75484},{\"end\":75508,\"start\":75503},{\"end\":75710,\"start\":75705},{\"end\":75733,\"start\":75728},{\"end\":75752,\"start\":75743},{\"end\":75772,\"start\":75761},{\"end\":75790,\"start\":75782},{\"end\":75801,\"start\":75798},{\"end\":75818,\"start\":75812},{\"end\":75830,\"start\":75825},{\"end\":75846,\"start\":75838},{\"end\":75870,\"start\":75855},{\"end\":75885,\"start\":75880},{\"end\":75903,\"start\":75897},{\"end\":75913,\"start\":75910},{\"end\":75931,\"start\":75922},{\"end\":76391,\"start\":76389},{\"end\":76401,\"start\":76398},{\"end\":76415,\"start\":76411},{\"end\":76430,\"start\":76422},{\"end\":76450,\"start\":76441},{\"end\":76461,\"start\":76459},{\"end\":76490,\"start\":76474},{\"end\":76507,\"start\":76499},{\"end\":76522,\"start\":76517},{\"end\":76540,\"start\":76530},{\"end\":76557,\"start\":76551},{\"end\":76573,\"start\":76568},{\"end\":77017,\"start\":76997},{\"end\":77035,\"start\":77027},{\"end\":77055,\"start\":77049},{\"end\":77064,\"start\":77057},{\"end\":77344,\"start\":77336},{\"end\":77359,\"start\":77353},{\"end\":77593,\"start\":77590},{\"end\":77604,\"start\":77600},{\"end\":77618,\"start\":77614},{\"end\":77843,\"start\":77837},{\"end\":77870,\"start\":77853},{\"end\":77882,\"start\":77877},{\"end\":77895,\"start\":77889},{\"end\":77909,\"start\":77903},{\"end\":77929,\"start\":77919},{\"end\":77935,\"start\":77931},{\"end\":78252,\"start\":78246},{\"end\":78266,\"start\":78262},{\"end\":78280,\"start\":78275},{\"end\":78297,\"start\":78291},{\"end\":78314,\"start\":78309},{\"end\":78578,\"start\":78568},{\"end\":78600,\"start\":78589},{\"end\":78618,\"start\":78611},{\"end\":78635,\"start\":78629},{\"end\":78912,\"start\":78904},{\"end\":78929,\"start\":78921},{\"end\":78945,\"start\":78939},{\"end\":78959,\"start\":78954},{\"end\":78977,\"start\":78967},{\"end\":78989,\"start\":78987},{\"end\":79331,\"start\":79324},{\"end\":79344,\"start\":79341},{\"end\":79360,\"start\":79354},{\"end\":79618,\"start\":79612},{\"end\":79634,\"start\":79628},{\"end\":79653,\"start\":79646},{\"end\":79663,\"start\":79657},{\"end\":79678,\"start\":79672},{\"end\":79685,\"start\":79680},{\"end\":79949,\"start\":79947},{\"end\":79968,\"start\":79959},{\"end\":79982,\"start\":79978},{\"end\":79997,\"start\":79989},{\"end\":80018,\"start\":80009},{\"end\":80036,\"start\":80027},{\"end\":80313,\"start\":80311},{\"end\":80326,\"start\":80323},{\"end\":80334,\"start\":80331},{\"end\":80344,\"start\":80341},{\"end\":80353,\"start\":80350},{\"end\":80558,\"start\":80556},{\"end\":80569,\"start\":80565},{\"end\":80581,\"start\":80577},{\"end\":80594,\"start\":80592},{\"end\":80782,\"start\":80779},{\"end\":80796,\"start\":80790},{\"end\":80813,\"start\":80805},{\"end\":80825,\"start\":80823},{\"end\":80844,\"start\":80835},{\"end\":80862,\"start\":80854},{\"end\":81133,\"start\":81130},{\"end\":81143,\"start\":81140},{\"end\":81151,\"start\":81149},{\"end\":81163,\"start\":81159},{\"end\":81175,\"start\":81172},{\"end\":81406,\"start\":81403},{\"end\":81421,\"start\":81416},{\"end\":81439,\"start\":81431},{\"end\":81451,\"start\":81447},{\"end\":81466,\"start\":81460},{\"end\":81480,\"start\":81473},{\"end\":81494,\"start\":81488},{\"end\":81514,\"start\":81507},{\"end\":81810,\"start\":81807},{\"end\":81819,\"start\":81815},{\"end\":81832,\"start\":81830},{\"end\":81848,\"start\":81844},{\"end\":81859,\"start\":81855},{\"end\":82079,\"start\":82076},{\"end\":82098,\"start\":82090},{\"end\":82113,\"start\":82108},{\"end\":82132,\"start\":82125},{\"end\":82146,\"start\":82142},{\"end\":82161,\"start\":82159},{\"end\":82179,\"start\":82175},{\"end\":82477,\"start\":82470},{\"end\":82498,\"start\":82486},{\"end\":82513,\"start\":82505},{\"end\":82531,\"start\":82523},{\"end\":82547,\"start\":82538},{\"end\":82565,\"start\":82556},{\"end\":82574,\"start\":82571},{\"end\":82593,\"start\":82584},{\"end\":82613,\"start\":82600},{\"end\":82620,\"start\":82615},{\"end\":82996,\"start\":82992},{\"end\":83013,\"start\":83007},{\"end\":83193,\"start\":83187},{\"end\":83206,\"start\":83199},{\"end\":83416,\"start\":83404},{\"end\":83427,\"start\":83425},{\"end\":83442,\"start\":83434},{\"end\":83447,\"start\":83444},{\"end\":83812,\"start\":83803},{\"end\":83825,\"start\":83820},{\"end\":83839,\"start\":83835},{\"end\":84096,\"start\":84092},{\"end\":84111,\"start\":84106},{\"end\":84129,\"start\":84121},{\"end\":84141,\"start\":84135},{\"end\":84153,\"start\":84149},{\"end\":84163,\"start\":84155},{\"end\":84413,\"start\":84406},{\"end\":84426,\"start\":84420},{\"end\":84442,\"start\":84436},{\"end\":84670,\"start\":84666},{\"end\":84680,\"start\":84676},{\"end\":84688,\"start\":84685},{\"end\":84699,\"start\":84696},{\"end\":84956,\"start\":84950},{\"end\":84972,\"start\":84962},{\"end\":84988,\"start\":84983},{\"end\":84998,\"start\":84994},{\"end\":85012,\"start\":85005},{\"end\":85028,\"start\":85022},{\"end\":85035,\"start\":85030},{\"end\":85331,\"start\":85323},{\"end\":85349,\"start\":85340},{\"end\":85579,\"start\":85571},{\"end\":85597,\"start\":85588},{\"end\":85820,\"start\":85815},{\"end\":85832,\"start\":85828},{\"end\":85850,\"start\":85842},{\"end\":85862,\"start\":85856},{\"end\":85874,\"start\":85870},{\"end\":85884,\"start\":85876},{\"end\":86188,\"start\":86184},{\"end\":86202,\"start\":86197},{\"end\":86211,\"start\":86209},{\"end\":86224,\"start\":86221},{\"end\":86486,\"start\":86480},{\"end\":86513,\"start\":86496},{\"end\":86519,\"start\":86515},{\"end\":86785,\"start\":86781},{\"end\":86794,\"start\":86791},{\"end\":86805,\"start\":86803},{\"end\":86814,\"start\":86810},{\"end\":86823,\"start\":86821},{\"end\":87052,\"start\":87048},{\"end\":87063,\"start\":87056},{\"end\":87076,\"start\":87069},{\"end\":87092,\"start\":87086},{\"end\":87111,\"start\":87102},{\"end\":87119,\"start\":87113},{\"end\":87378,\"start\":87374},{\"end\":87386,\"start\":87384},{\"end\":87394,\"start\":87392},{\"end\":87408,\"start\":87400},{\"end\":87640,\"start\":87636},{\"end\":87649,\"start\":87645},{\"end\":87662,\"start\":87658},{\"end\":87894,\"start\":87890},{\"end\":87903,\"start\":87899},{\"end\":87916,\"start\":87912},{\"end\":87930,\"start\":87922},{\"end\":88181,\"start\":88177},{\"end\":88196,\"start\":88191},{\"end\":88206,\"start\":88202},{\"end\":88215,\"start\":88211},{\"end\":88226,\"start\":88223},{\"end\":88239,\"start\":88235},{\"end\":88253,\"start\":88245},{\"end\":88540,\"start\":88529},{\"end\":88556,\"start\":88547},{\"end\":88573,\"start\":88567},{\"end\":88808,\"start\":88797},{\"end\":88823,\"start\":88817},{\"end\":88840,\"start\":88834},{\"end\":89062,\"start\":89053},{\"end\":89076,\"start\":89074},{\"end\":89097,\"start\":89084},{\"end\":89110,\"start\":89107},{\"end\":89122,\"start\":89120},{\"end\":89141,\"start\":89131},{\"end\":89151,\"start\":89143},{\"end\":89441,\"start\":89439},{\"end\":89457,\"start\":89452},{\"end\":89469,\"start\":89465},{\"end\":89482,\"start\":89477},{\"end\":89495,\"start\":89493},{\"end\":89706,\"start\":89704},{\"end\":89719,\"start\":89716},{\"end\":89736,\"start\":89732},{\"end\":89991,\"start\":89988},{\"end\":90008,\"start\":90000},{\"end\":90022,\"start\":90016},{\"end\":90034,\"start\":90032},{\"end\":90046,\"start\":90044},{\"end\":90306,\"start\":90304},{\"end\":90316,\"start\":90313},{\"end\":90329,\"start\":90323},{\"end\":90565,\"start\":90561},{\"end\":90580,\"start\":90576},{\"end\":90593,\"start\":90590},{\"end\":90605,\"start\":90601},{\"end\":90620,\"start\":90615},{\"end\":90631,\"start\":90626},{\"end\":90916,\"start\":90911},{\"end\":90934,\"start\":90923},{\"end\":90944,\"start\":90941},{\"end\":90964,\"start\":90955},{\"end\":90975,\"start\":90971},{\"end\":90987,\"start\":90980},{\"end\":91256,\"start\":91254},{\"end\":91269,\"start\":91265},{\"end\":91285,\"start\":91276},{\"end\":91301,\"start\":91294},{\"end\":91504,\"start\":91500},{\"end\":91519,\"start\":91514},{\"end\":91531,\"start\":91528},{\"end\":91544,\"start\":91541},{\"end\":91553,\"start\":91549},{\"end\":91566,\"start\":91562},{\"end\":91581,\"start\":91576},{\"end\":91881,\"start\":91877},{\"end\":91899,\"start\":91891},{\"end\":91918,\"start\":91909},{\"end\":91932,\"start\":91929},{\"end\":92200,\"start\":92196},{\"end\":92210,\"start\":92206},{\"end\":92217,\"start\":92212},{\"end\":92418,\"start\":92414},{\"end\":92433,\"start\":92428},{\"end\":92445,\"start\":92441},{\"end\":92457,\"start\":92455},{\"end\":92470,\"start\":92466},{\"end\":92481,\"start\":92478}]", "bib_entry": "[{\"attributes\":{\"doi\":\"abs/1609.08675\",\"id\":\"b0\"},\"end\":71870,\"start\":71431},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":175905},\"end\":72115,\"start\":71872},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":206596127},\"end\":72379,\"start\":72117},{\"attributes\":{\"id\":\"b3\"},\"end\":73165,\"start\":72381},{\"attributes\":{\"id\":\"b4\"},\"end\":73411,\"start\":73167},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":227247829},\"end\":73756,\"start\":73413},{\"attributes\":{\"id\":\"b6\"},\"end\":73979,\"start\":73758},{\"attributes\":{\"id\":\"b7\"},\"end\":74249,\"start\":73981},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":57246310},\"end\":74532,\"start\":74251},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":207252270},\"end\":74941,\"start\":74534},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":54463801},\"end\":75211,\"start\":74943},{\"attributes\":{\"id\":\"b11\"},\"end\":75452,\"start\":75213},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":1035098},\"end\":75606,\"start\":75454},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":834612},\"end\":76304,\"start\":75608},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":688013},\"end\":76911,\"start\":76306},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":1710722},\"end\":77260,\"start\":76913},{\"attributes\":{\"doi\":\"abs/1709.01450\",\"id\":\"b16\"},\"end\":77510,\"start\":77262},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":206771624},\"end\":77773,\"start\":77512},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":14049355},\"end\":78194,\"start\":77775},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":13000587},\"end\":78496,\"start\":78196},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":1191338},\"end\":78826,\"start\":78498},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":206592218},\"end\":79197,\"start\":78828},{\"attributes\":{\"id\":\"b22\"},\"end\":79541,\"start\":79199},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":206769852},\"end\":79874,\"start\":79543},{\"attributes\":{\"id\":\"b24\"},\"end\":80230,\"start\":79876},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":52956197},\"end\":80521,\"start\":80232},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":210473278},\"end\":80721,\"start\":80523},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":10716717},\"end\":81048,\"start\":80723},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":198179957},\"end\":81349,\"start\":81050},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":14113767},\"end\":81724,\"start\":81351},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":47009464},\"end\":82034,\"start\":81726},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":2141740},\"end\":82367,\"start\":82036},{\"attributes\":{\"doi\":\"abs/1911.00232\",\"id\":\"b32\"},\"end\":82929,\"start\":82369},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":1995092},\"end\":83142,\"start\":82931},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":786357},\"end\":83314,\"start\":83144},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":10328909},\"end\":83697,\"start\":83316},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":83721},\"end\":84012,\"start\":83699},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":14142501},\"end\":84345,\"start\":84014},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":8777811},\"end\":84582,\"start\":84347},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":215754360},\"end\":84868,\"start\":84584},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":18061547},\"end\":85247,\"start\":84870},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":11797475},\"end\":85495,\"start\":85249},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":14124313},\"end\":85728,\"start\":85497},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":1189033},\"end\":86099,\"start\":85730},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":173188703},\"end\":86398,\"start\":86101},{\"attributes\":{\"doi\":\"abs/1212.0402\",\"id\":\"b45\",\"matched_paper_id\":7197134},\"end\":86713,\"start\":86400},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":215786014},\"end\":86978,\"start\":86715},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":1122604},\"end\":87307,\"start\":86980},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":19132897},\"end\":87554,\"start\":87309},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":4284367},\"end\":87817,\"start\":87556},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":17071670},\"end\":88090,\"start\":87819},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":5711057},\"end\":88459,\"start\":88092},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":6079438},\"end\":88739,\"start\":88461},{\"attributes\":{\"doi\":\"abs/1605.05197\",\"id\":\"b53\"},\"end\":88994,\"start\":88741},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":54476257},\"end\":89365,\"start\":88996},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":220647162},\"end\":89672,\"start\":89367},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":15287463},\"end\":89916,\"start\":89674},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":8485068},\"end\":90222,\"start\":89918},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":10140667},\"end\":90481,\"start\":90224},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":126187344},\"end\":90827,\"start\":90483},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":3337929},\"end\":91221,\"start\":90829},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":30834643},\"end\":91428,\"start\":91223},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":202538533},\"end\":91781,\"start\":91430},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":68049510},\"end\":92133,\"start\":91783},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":90262102},\"end\":92348,\"start\":92135},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":1353488},\"end\":92661,\"start\":92350}]", "bib_title": "[{\"end\":71900,\"start\":71872},{\"end\":72184,\"start\":72117},{\"end\":73236,\"start\":73167},{\"end\":73527,\"start\":73413},{\"end\":74302,\"start\":74251},{\"end\":74593,\"start\":74534},{\"end\":74982,\"start\":74943},{\"end\":75267,\"start\":75213},{\"end\":75474,\"start\":75454},{\"end\":75696,\"start\":75608},{\"end\":76379,\"start\":76306},{\"end\":76988,\"start\":76913},{\"end\":77584,\"start\":77512},{\"end\":77828,\"start\":77775},{\"end\":78236,\"start\":78196},{\"end\":78560,\"start\":78498},{\"end\":78895,\"start\":78828},{\"end\":79600,\"start\":79543},{\"end\":80304,\"start\":80232},{\"end\":80547,\"start\":80523},{\"end\":80768,\"start\":80723},{\"end\":81120,\"start\":81050},{\"end\":81392,\"start\":81351},{\"end\":81797,\"start\":81726},{\"end\":82070,\"start\":82036},{\"end\":82980,\"start\":82931},{\"end\":83178,\"start\":83144},{\"end\":83394,\"start\":83316},{\"end\":83793,\"start\":83699},{\"end\":84084,\"start\":84014},{\"end\":84394,\"start\":84347},{\"end\":84659,\"start\":84584},{\"end\":84946,\"start\":84870},{\"end\":85315,\"start\":85249},{\"end\":85563,\"start\":85497},{\"end\":85805,\"start\":85730},{\"end\":86178,\"start\":86101},{\"end\":86470,\"start\":86400},{\"end\":86772,\"start\":86715},{\"end\":87043,\"start\":86980},{\"end\":87366,\"start\":87309},{\"end\":87628,\"start\":87556},{\"end\":87882,\"start\":87819},{\"end\":88169,\"start\":88092},{\"end\":88518,\"start\":88461},{\"end\":89051,\"start\":88996},{\"end\":89428,\"start\":89367},{\"end\":89699,\"start\":89674},{\"end\":89978,\"start\":89918},{\"end\":90294,\"start\":90224},{\"end\":90552,\"start\":90483},{\"end\":90902,\"start\":90829},{\"end\":91245,\"start\":91223},{\"end\":91491,\"start\":91430},{\"end\":91870,\"start\":91783},{\"end\":92185,\"start\":92135},{\"end\":92408,\"start\":92350}]", "bib_author": "[{\"end\":71508,\"start\":71489},{\"end\":71524,\"start\":71508},{\"end\":71538,\"start\":71524},{\"end\":71551,\"start\":71538},{\"end\":71568,\"start\":71551},{\"end\":71594,\"start\":71568},{\"end\":71623,\"start\":71594},{\"end\":71915,\"start\":71902},{\"end\":71930,\"start\":71915},{\"end\":71945,\"start\":71930},{\"end\":71959,\"start\":71945},{\"end\":71972,\"start\":71959},{\"end\":72201,\"start\":72186},{\"end\":72219,\"start\":72201},{\"end\":72448,\"start\":72438},{\"end\":72460,\"start\":72448},{\"end\":72476,\"start\":72460},{\"end\":72488,\"start\":72476},{\"end\":72498,\"start\":72488},{\"end\":72511,\"start\":72498},{\"end\":72524,\"start\":72511},{\"end\":72537,\"start\":72524},{\"end\":72548,\"start\":72537},{\"end\":72559,\"start\":72548},{\"end\":72572,\"start\":72559},{\"end\":72585,\"start\":72572},{\"end\":72599,\"start\":72585},{\"end\":72615,\"start\":72599},{\"end\":72627,\"start\":72615},{\"end\":72636,\"start\":72627},{\"end\":72644,\"start\":72636},{\"end\":72653,\"start\":72644},{\"end\":72661,\"start\":72653},{\"end\":72673,\"start\":72661},{\"end\":72688,\"start\":72673},{\"end\":73544,\"start\":73529},{\"end\":73561,\"start\":73544},{\"end\":73817,\"start\":73806},{\"end\":73830,\"start\":73817},{\"end\":73842,\"start\":73830},{\"end\":73855,\"start\":73842},{\"end\":74314,\"start\":74304},{\"end\":74324,\"start\":74314},{\"end\":74340,\"start\":74324},{\"end\":74351,\"start\":74340},{\"end\":74359,\"start\":74351},{\"end\":74371,\"start\":74359},{\"end\":74616,\"start\":74595},{\"end\":74632,\"start\":74616},{\"end\":74642,\"start\":74632},{\"end\":74659,\"start\":74642},{\"end\":74676,\"start\":74659},{\"end\":74689,\"start\":74676},{\"end\":74700,\"start\":74689},{\"end\":75009,\"start\":74984},{\"end\":75020,\"start\":75009},{\"end\":75036,\"start\":75020},{\"end\":75048,\"start\":75036},{\"end\":75284,\"start\":75269},{\"end\":75299,\"start\":75284},{\"end\":75313,\"start\":75299},{\"end\":75494,\"start\":75476},{\"end\":75510,\"start\":75494},{\"end\":75712,\"start\":75698},{\"end\":75735,\"start\":75712},{\"end\":75754,\"start\":75735},{\"end\":75774,\"start\":75754},{\"end\":75792,\"start\":75774},{\"end\":75803,\"start\":75792},{\"end\":75820,\"start\":75803},{\"end\":75832,\"start\":75820},{\"end\":75848,\"start\":75832},{\"end\":75872,\"start\":75848},{\"end\":75887,\"start\":75872},{\"end\":75905,\"start\":75887},{\"end\":75915,\"start\":75905},{\"end\":75933,\"start\":75915},{\"end\":76393,\"start\":76381},{\"end\":76403,\"start\":76393},{\"end\":76417,\"start\":76403},{\"end\":76432,\"start\":76417},{\"end\":76452,\"start\":76432},{\"end\":76463,\"start\":76452},{\"end\":76492,\"start\":76463},{\"end\":76509,\"start\":76492},{\"end\":76524,\"start\":76509},{\"end\":76542,\"start\":76524},{\"end\":76559,\"start\":76542},{\"end\":76575,\"start\":76559},{\"end\":77019,\"start\":76990},{\"end\":77037,\"start\":77019},{\"end\":77057,\"start\":77037},{\"end\":77066,\"start\":77057},{\"end\":77346,\"start\":77330},{\"end\":77361,\"start\":77346},{\"end\":77595,\"start\":77586},{\"end\":77606,\"start\":77595},{\"end\":77620,\"start\":77606},{\"end\":77845,\"start\":77830},{\"end\":77872,\"start\":77845},{\"end\":77884,\"start\":77872},{\"end\":77897,\"start\":77884},{\"end\":77911,\"start\":77897},{\"end\":77931,\"start\":77911},{\"end\":77937,\"start\":77931},{\"end\":78254,\"start\":78238},{\"end\":78268,\"start\":78254},{\"end\":78282,\"start\":78268},{\"end\":78299,\"start\":78282},{\"end\":78316,\"start\":78299},{\"end\":78580,\"start\":78562},{\"end\":78602,\"start\":78580},{\"end\":78620,\"start\":78602},{\"end\":78637,\"start\":78620},{\"end\":78914,\"start\":78897},{\"end\":78931,\"start\":78914},{\"end\":78947,\"start\":78931},{\"end\":78961,\"start\":78947},{\"end\":78979,\"start\":78961},{\"end\":78991,\"start\":78979},{\"end\":79333,\"start\":79319},{\"end\":79346,\"start\":79333},{\"end\":79362,\"start\":79346},{\"end\":79620,\"start\":79602},{\"end\":79636,\"start\":79620},{\"end\":79655,\"start\":79636},{\"end\":79665,\"start\":79655},{\"end\":79680,\"start\":79665},{\"end\":79687,\"start\":79680},{\"end\":79951,\"start\":79943},{\"end\":79970,\"start\":79951},{\"end\":79984,\"start\":79970},{\"end\":79999,\"start\":79984},{\"end\":80020,\"start\":79999},{\"end\":80038,\"start\":80020},{\"end\":80315,\"start\":80306},{\"end\":80328,\"start\":80315},{\"end\":80336,\"start\":80328},{\"end\":80346,\"start\":80336},{\"end\":80355,\"start\":80346},{\"end\":80560,\"start\":80549},{\"end\":80571,\"start\":80560},{\"end\":80583,\"start\":80571},{\"end\":80596,\"start\":80583},{\"end\":80784,\"start\":80770},{\"end\":80798,\"start\":80784},{\"end\":80815,\"start\":80798},{\"end\":80827,\"start\":80815},{\"end\":80846,\"start\":80827},{\"end\":80864,\"start\":80846},{\"end\":81135,\"start\":81122},{\"end\":81145,\"start\":81135},{\"end\":81153,\"start\":81145},{\"end\":81165,\"start\":81153},{\"end\":81177,\"start\":81165},{\"end\":81408,\"start\":81394},{\"end\":81423,\"start\":81408},{\"end\":81441,\"start\":81423},{\"end\":81453,\"start\":81441},{\"end\":81468,\"start\":81453},{\"end\":81482,\"start\":81468},{\"end\":81496,\"start\":81482},{\"end\":81516,\"start\":81496},{\"end\":81812,\"start\":81799},{\"end\":81821,\"start\":81812},{\"end\":81834,\"start\":81821},{\"end\":81850,\"start\":81834},{\"end\":81861,\"start\":81850},{\"end\":82081,\"start\":82072},{\"end\":82100,\"start\":82081},{\"end\":82115,\"start\":82100},{\"end\":82134,\"start\":82115},{\"end\":82148,\"start\":82134},{\"end\":82163,\"start\":82148},{\"end\":82181,\"start\":82163},{\"end\":82479,\"start\":82463},{\"end\":82500,\"start\":82479},{\"end\":82515,\"start\":82500},{\"end\":82533,\"start\":82515},{\"end\":82549,\"start\":82533},{\"end\":82567,\"start\":82549},{\"end\":82576,\"start\":82567},{\"end\":82595,\"start\":82576},{\"end\":82615,\"start\":82595},{\"end\":82622,\"start\":82615},{\"end\":82998,\"start\":82982},{\"end\":83015,\"start\":82998},{\"end\":83195,\"start\":83180},{\"end\":83208,\"start\":83195},{\"end\":83418,\"start\":83396},{\"end\":83429,\"start\":83418},{\"end\":83444,\"start\":83429},{\"end\":83449,\"start\":83444},{\"end\":83814,\"start\":83795},{\"end\":83827,\"start\":83814},{\"end\":83841,\"start\":83827},{\"end\":84098,\"start\":84086},{\"end\":84113,\"start\":84098},{\"end\":84131,\"start\":84113},{\"end\":84143,\"start\":84131},{\"end\":84155,\"start\":84143},{\"end\":84165,\"start\":84155},{\"end\":84415,\"start\":84396},{\"end\":84428,\"start\":84415},{\"end\":84444,\"start\":84428},{\"end\":84672,\"start\":84661},{\"end\":84682,\"start\":84672},{\"end\":84690,\"start\":84682},{\"end\":84701,\"start\":84690},{\"end\":84958,\"start\":84948},{\"end\":84974,\"start\":84958},{\"end\":84990,\"start\":84974},{\"end\":85000,\"start\":84990},{\"end\":85014,\"start\":85000},{\"end\":85030,\"start\":85014},{\"end\":85037,\"start\":85030},{\"end\":85333,\"start\":85317},{\"end\":85351,\"start\":85333},{\"end\":85581,\"start\":85565},{\"end\":85599,\"start\":85581},{\"end\":85822,\"start\":85807},{\"end\":85834,\"start\":85822},{\"end\":85852,\"start\":85834},{\"end\":85864,\"start\":85852},{\"end\":85876,\"start\":85864},{\"end\":85886,\"start\":85876},{\"end\":86190,\"start\":86180},{\"end\":86204,\"start\":86190},{\"end\":86213,\"start\":86204},{\"end\":86226,\"start\":86213},{\"end\":86488,\"start\":86472},{\"end\":86515,\"start\":86488},{\"end\":86521,\"start\":86515},{\"end\":86787,\"start\":86774},{\"end\":86796,\"start\":86787},{\"end\":86807,\"start\":86796},{\"end\":86816,\"start\":86807},{\"end\":86825,\"start\":86816},{\"end\":87054,\"start\":87045},{\"end\":87065,\"start\":87054},{\"end\":87078,\"start\":87065},{\"end\":87094,\"start\":87078},{\"end\":87113,\"start\":87094},{\"end\":87121,\"start\":87113},{\"end\":87380,\"start\":87368},{\"end\":87388,\"start\":87380},{\"end\":87396,\"start\":87388},{\"end\":87410,\"start\":87396},{\"end\":87642,\"start\":87630},{\"end\":87651,\"start\":87642},{\"end\":87664,\"start\":87651},{\"end\":87896,\"start\":87884},{\"end\":87905,\"start\":87896},{\"end\":87918,\"start\":87905},{\"end\":87932,\"start\":87918},{\"end\":88183,\"start\":88171},{\"end\":88198,\"start\":88183},{\"end\":88208,\"start\":88198},{\"end\":88217,\"start\":88208},{\"end\":88228,\"start\":88217},{\"end\":88241,\"start\":88228},{\"end\":88255,\"start\":88241},{\"end\":88542,\"start\":88520},{\"end\":88558,\"start\":88542},{\"end\":88575,\"start\":88558},{\"end\":88810,\"start\":88788},{\"end\":88825,\"start\":88810},{\"end\":88842,\"start\":88825},{\"end\":89064,\"start\":89053},{\"end\":89078,\"start\":89064},{\"end\":89099,\"start\":89078},{\"end\":89112,\"start\":89099},{\"end\":89124,\"start\":89112},{\"end\":89143,\"start\":89124},{\"end\":89153,\"start\":89143},{\"end\":89443,\"start\":89430},{\"end\":89459,\"start\":89443},{\"end\":89471,\"start\":89459},{\"end\":89484,\"start\":89471},{\"end\":89497,\"start\":89484},{\"end\":89708,\"start\":89701},{\"end\":89721,\"start\":89708},{\"end\":89738,\"start\":89721},{\"end\":89993,\"start\":89980},{\"end\":90010,\"start\":89993},{\"end\":90024,\"start\":90010},{\"end\":90036,\"start\":90024},{\"end\":90048,\"start\":90036},{\"end\":90308,\"start\":90296},{\"end\":90318,\"start\":90308},{\"end\":90331,\"start\":90318},{\"end\":90567,\"start\":90554},{\"end\":90582,\"start\":90567},{\"end\":90595,\"start\":90582},{\"end\":90607,\"start\":90595},{\"end\":90622,\"start\":90607},{\"end\":90633,\"start\":90622},{\"end\":90918,\"start\":90904},{\"end\":90936,\"start\":90918},{\"end\":90946,\"start\":90936},{\"end\":90966,\"start\":90946},{\"end\":90977,\"start\":90966},{\"end\":90989,\"start\":90977},{\"end\":91258,\"start\":91247},{\"end\":91271,\"start\":91258},{\"end\":91287,\"start\":91271},{\"end\":91303,\"start\":91287},{\"end\":91506,\"start\":91493},{\"end\":91521,\"start\":91506},{\"end\":91533,\"start\":91521},{\"end\":91546,\"start\":91533},{\"end\":91555,\"start\":91546},{\"end\":91568,\"start\":91555},{\"end\":91583,\"start\":91568},{\"end\":91883,\"start\":91872},{\"end\":91901,\"start\":91883},{\"end\":91920,\"start\":91901},{\"end\":91934,\"start\":91920},{\"end\":92202,\"start\":92187},{\"end\":92212,\"start\":92202},{\"end\":92219,\"start\":92212},{\"end\":92420,\"start\":92410},{\"end\":92435,\"start\":92420},{\"end\":92447,\"start\":92435},{\"end\":92459,\"start\":92447},{\"end\":92472,\"start\":92459},{\"end\":92483,\"start\":92472}]", "bib_venue": "[{\"end\":71487,\"start\":71431},{\"end\":71976,\"start\":71972},{\"end\":72223,\"start\":72219},{\"end\":72436,\"start\":72381},{\"end\":73260,\"start\":73238},{\"end\":73565,\"start\":73561},{\"end\":73804,\"start\":73758},{\"end\":74062,\"start\":73981},{\"end\":74375,\"start\":74371},{\"end\":74719,\"start\":74700},{\"end\":75052,\"start\":75048},{\"end\":75317,\"start\":75313},{\"end\":75514,\"start\":75510},{\"end\":75937,\"start\":75933},{\"end\":76579,\"start\":76575},{\"end\":77070,\"start\":77066},{\"end\":77328,\"start\":77262},{\"end\":77624,\"start\":77620},{\"end\":77963,\"start\":77937},{\"end\":78320,\"start\":78316},{\"end\":78641,\"start\":78637},{\"end\":78995,\"start\":78991},{\"end\":79317,\"start\":79199},{\"end\":79691,\"start\":79687},{\"end\":79941,\"start\":79876},{\"end\":80359,\"start\":80355},{\"end\":80600,\"start\":80596},{\"end\":80868,\"start\":80864},{\"end\":81181,\"start\":81177},{\"end\":81520,\"start\":81516},{\"end\":81865,\"start\":81861},{\"end\":82185,\"start\":82181},{\"end\":82461,\"start\":82369},{\"end\":83019,\"start\":83015},{\"end\":83212,\"start\":83208},{\"end\":83487,\"start\":83449},{\"end\":83845,\"start\":83841},{\"end\":84169,\"start\":84165},{\"end\":84448,\"start\":84444},{\"end\":84705,\"start\":84701},{\"end\":85041,\"start\":85037},{\"end\":85355,\"start\":85351},{\"end\":85603,\"start\":85599},{\"end\":85890,\"start\":85886},{\"end\":86230,\"start\":86226},{\"end\":86538,\"start\":86534},{\"end\":86829,\"start\":86825},{\"end\":87125,\"start\":87121},{\"end\":87414,\"start\":87410},{\"end\":87668,\"start\":87664},{\"end\":87936,\"start\":87932},{\"end\":88259,\"start\":88255},{\"end\":88579,\"start\":88575},{\"end\":88786,\"start\":88741},{\"end\":89157,\"start\":89153},{\"end\":89501,\"start\":89497},{\"end\":89776,\"start\":89738},{\"end\":90052,\"start\":90048},{\"end\":90335,\"start\":90331},{\"end\":90637,\"start\":90633},{\"end\":91008,\"start\":90989},{\"end\":91307,\"start\":91303},{\"end\":91587,\"start\":91583},{\"end\":91938,\"start\":91934},{\"end\":92223,\"start\":92219},{\"end\":92487,\"start\":92483}]"}}}, "year": 2023, "month": 12, "day": 17}