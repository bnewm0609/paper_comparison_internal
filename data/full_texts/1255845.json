{"id": 1255845, "updated": "2022-06-14 04:16:05.117", "metadata": {"title": "Combining Retrieval, Statistics, and Inference to Answer Elementary Science Questions", "authors": "[{\"first\":\"Peter\",\"last\":\"Clark\",\"middle\":[]},{\"first\":\"Oren\",\"last\":\"Etzioni\",\"middle\":[]},{\"first\":\"Tushar\",\"last\":\"Khot\",\"middle\":[]},{\"first\":\"Ashish\",\"last\":\"Sabharwal\",\"middle\":[]},{\"first\":\"Oyvind\",\"last\":\"Tafjord\",\"middle\":[]},{\"first\":\"Peter\",\"last\":\"Turney\",\"middle\":[]},{\"first\":\"Daniel\",\"last\":\"Khashabi\",\"middle\":[]}]", "venue": "AAAI", "journal": "2580-2586", "publication_date": {"year": 2016, "month": null, "day": null}, "abstract": "What capabilities are required for an AI system to pass standard 4th Grade Science Tests? Previous work has examined the use of Markov Logic Networks (MLNs) to represent the requisite background knowledge and interpret test questions, but did not improve upon an information retrieval (IR) baseline. In this paper, we describe an alternative approach that operates at three levels of representation and reasoning: information retrieval, corpus statistics, and simple inference over a semi-automatically constructed knowledge base, to achieve substantially improved results. We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam (using only non-diagram, multiple choice questions), and show that our overall system's score is 71.3%, an improvement of 23.8% (absolute) over the MLN-based method described in previous work. We conclude with a detailed analysis, illustrating the complementary strengths of each method in the ensemble. Our datasets are being released to enable further research.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2547185913", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/aaai/ClarkEKSTTK16", "doi": null}}, "content": {"source": {"pdf_hash": "bac9fc77f3f67f3036ee86f7fa2717101c7e8bbe", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4bd510f3ed44cb08211d55cf329d44629b23b094", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/bac9fc77f3f67f3036ee86f7fa2717101c7e8bbe.txt", "contents": "\nCombining Retrieval, Statistics, and Inference to Answer Elementary Science Questions\n\n\nPeter Clark peterc@allenai.org \nAllen Institute for Artificial Intelligence\nCognitive Computation Lab (CCG)\nUniv Illinois\nUrbana-Champaign\n\nOren Etzioni orene@allenai.org \nAllen Institute for Artificial Intelligence\nCognitive Computation Lab (CCG)\nUniv Illinois\nUrbana-Champaign\n\nTushar Khot tushark@allenai.org \nAllen Institute for Artificial Intelligence\nCognitive Computation Lab (CCG)\nUniv Illinois\nUrbana-Champaign\n\nAshish Sabharwal ashishs@allenai.org \nAllen Institute for Artificial Intelligence\nCognitive Computation Lab (CCG)\nUniv Illinois\nUrbana-Champaign\n\nOyvind Tafjord oyvindt@allenai.org \nAllen Institute for Artificial Intelligence\nCognitive Computation Lab (CCG)\nUniv Illinois\nUrbana-Champaign\n\nPeter Turney petert@allenai.org \nAllen Institute for Artificial Intelligence\nCognitive Computation Lab (CCG)\nUniv Illinois\nUrbana-Champaign\n\nDaniel Khashabi khashab2@illinois.edu \nAllen Institute for Artificial Intelligence\nCognitive Computation Lab (CCG)\nUniv Illinois\nUrbana-Champaign\n\nCombining Retrieval, Statistics, and Inference to Answer Elementary Science Questions\n\nWhat capabilities are required for an AI system to pass standard 4th Grade Science Tests? Previous work has examined the use of Markov Logic Networks (MLNs) to represent the requisite background knowledge and interpret test questions, but did not improve upon an information retrieval (IR) baseline. In this paper, we describe an alternative approach that operates at three levels of representation and reasoning: information retrieval, corpus statistics, and simple inference over a semi-automatically constructed knowledge base, to achieve substantially improved results. We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam (using only non-diagram, multiple choice questions), and show that our overall system's score is 71.3%, an improvement of 23.8% (absolute) over the MLN-based method described in previous work. We conclude with a detailed analysis, illustrating the complementary strengths of each method in the ensemble. Our datasets are being released to enable further research.\n\nIntroduction\n\nOur goal is a system that performs well on Elementary Science tests, a grand challenge for AI because of the wide variety of knowledge and reasoning skills required (Clark 2015). Although not itself an application, Fourth Grade test-taking requires question answering (QA) that goes significantly beyond retrieval techniques, yet is simple enough to be accessible. In this sense, it is a simple embodiment of an AI challenge requiring both language and reasoning, suitable as part of a broader Turing Test (Clark and Etzioni 2016), and with many potential applications if solved (e.g., tutoring systems, a scientist's assistant). This goal is hard, for example several Markov Logic Network (MLN) systems aimed at this task were reported by Khot et al. (2015), but the best MLN formulation still did not outperform an IR baseline.\n\nOur approach is to use an ensemble of solvers operating at different levels of representational structure, each capable of answering different genres of question reliably. Consider a question from the NY Regents 4th Grade Science Test:\n\nCopyright c 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\n\n\nFourth graders are planning a roller-skate race. Which surface would be the best for this race? (A) gravel (B) sand (C) blacktop (D) grass\n\nThis question might be answered in several ways. There may be a sentence on the Web that happens to state the answer explicitly (e.g., \"Blacktop is a good surface for a rollerskating race\"), and could be reliably retrieved to support the correct answer (\"blacktop\"). Alternatively, corpus statistics may reveal that \"blacktop\" is strongly associated with \"roller skating\" and \"race\", indicating that blacktop is the right answer. Finally, we might infer the answer from more general knowledge, e.g., roller-skating requires a smooth surface, and blacktop has a smooth surface, therefore blacktop is good for roller-skating.\n\nSimilarly our system, called Aristo, solves non-diagram multiple choice questions using five algorithms (\"solvers\") operating at different levels of structure. The combination addresses some of the reported problems with the earlier MLN systems. First, any system attempting reasoning over text needs some fallback methods when reasoning fails. We provide this using a baseline information retrieval (IR) solver. Second, some simpler questions can be answered using just statistical associations between questions and answer options, but the MLN systems made no attempt to use that knowledge. We address this using two solvers that exploit pointwise mutual information (PMI) and word embeddings (generating features for an SVM) respectively. Third, for more complex questions, we use a RULE solver that uses soft logical rules extracted from text. We also include a solver that uses a structurally simpler knowledge representation (tables), applied using integer linear programming (ILP). This provides an additional reasoning method that avoids the noise and complexity of the extracted rules. This combination thus covers a spectrum of representational levels, allowing questions to be robustly answered using retrieval, statistics, and inference. Solver scores are combined using logistic regression. Our contributions are as follows:\n\n\u2022 By combining solvers working at different levels of representation, our system Aristo achieves a significantly higher performance (71.3%) than the best previously published method (Khot et al. 2015).\n\n\u2022 We carry out ablation studies that quantify the contribution of each method to Aristo, and show that all levels of representation help. Our error analysis indicates the complementary strengths and weaknesses of each method, and directions for future work. \u2022 We show that the challenge problem itself is a valuable testbed for AI research, and are releasing our datasets (at www.allenai.org) to encourage further research.\n\n\nRelated Work\n\nQuestion Answering (QA) has been extensively studied in the past few years, but has primarily focused on retrieving answers to short, factoid questions (e.g., \"\n\nIn which year was Bill Clinton born?\") by locating answers in databases (Yao and Van Durme 2014; Zou et al. 2014;Fader, Zettlemoyer, and Etzioni 2014) or large document collections (Brill, Dumais, and Banko 2002;Ferrucci et al. 2010;Ko, Nyberg, and Si 2007). In contrast, many science questions do not have answers explicitly stated in text, and require some form of analysis or inference to answer them. While there are good examples of inference-based QA systems (Gunning et al. 2010;Novak 1977), they require questions to be posed in logic or restricted English, and were not applied to natural questions. A few systems have attempted standardized tests, e.g., in geometry (Seo et al. 2014) and mathematics (Hosseini et al. 2014;Kushman et al. 2014), and work well due to their limited domains and stylized wording of questions. Our work investigates a far less constrained domain, and thus utilizes different methods.\n\nAnswering questions using an ensemble has been shown to be effective in numerous previous cases, (e.g., T\u00f6scher, Jahrer, and Bell (2009)), most famously in IBM's highly successful Watson system (Ferrucci et al. 2010). What is novel here is the nature of the problem being addressed, namely single and multi-sentence science questions whose answers may require statistical or structured reasoning. By instantiating this architecture with modules at different levels of structure, Aristo can both leverage text when an answer is explicitly stated in a corpus, and perform inference to go beyond textual information when it is not. This latter capability allows Aristo to answer questions out of reach of corpus-based methods, without losing the powerful capabilities such methods provide.\n\n\nApproach\n\nAristo's overall architecture, shown in Figure 1, consists of five solvers that work in parallel to answer a multiple choice question. The IR solver operates directly on the text. The PMI solver and the SVM solver use statistical data derived from text. The RULE solver and the ILP solver reason with knowledge extracted from text. Each solver assigns confidences to each of the answer options, and a combiner module combines the results together using logistic regression trained on a set of training examples. \n\n\nLayer 1: Text as Knowledge\n\nThe Information Retrieval (IR) Solver The IR solver searches to see if the question q along with an answer option is explicitly stated in a corpus, and returns the confidence that such a statement was found. For each answer option a i , it sends q + a i as a query to a search engine (we use Lucene), and returns the search engine's score for the top retrieved sentence s where s also has at least one nonstopword overlap with q, and at least one with a i ; this ensures s has some relevance to both q and a i . This is repeated for all options a i to score them all.\n\n\nLayer 2: Statistical Knowledge\n\nThe IR solver provides a surprisingly strong baseline, but, as we show later, it is clearly limited in at least two ways. First, it requires the answer to a question to be explicitly contained somewhere in the corpus. Second, it requires the wording of that answer to be reasonably similar to that used in the question, so that a retrieval engine will rank it highly.\n\nAggregations over a corpus provides an alternative, weak source of commonsense knowledge. Consider:\n\nA mother hen clucks loudly when danger is near and her chicks quickly gather around her. Which sense helps the chicks receive this warning about danger from their mother? (A) smell (B) taste (C) sight (D) sound An IR approach struggles with this wordy question. However, the simple commonsense knowledge that the question appeals to is that a \"cluck\" is a \"sound\", or, more weakly, that \"cluck\" and \"sound\" are strongly associated. We can use corpus statistics to measure such associations. Although such statistics do not tell us the nature of that association, in many cases knowing the existence of the association provides a strong enough signal for question-answering.\n\n\nThe Pointwise Mutual Information (PMI) solver\n\nThe PMI solver formalizes a way of computing and applying such associational knowledge. Given a question q and an answer option a i , it uses pointwise mutual information (Church and Hanks 1989) to measure the strength of the associations between parts of q and parts of a i . Given a large corpus C, PMI for two n-grams x and y is defined as:\nPMI (x, y) = log p(x, y) p(x)p(y)\nHere p(x, y) is the joint probability that x and y occur together in the corpus C, within a certain window of text (we use a 10 word window). The term p(x)p(y), on the other hand, represents the probability with which x and y would occur together if they were statistically independent. The ratio of p(x, y) to p(x)p(y) is thus the ratio of the observed co-occurrence to the expected co-occurrence. The larger this ratio, the stronger the association between x and y. We extract unigrams, bigrams, trigrams, and skip-bigrams from the question q and each answer option a i . We use the SMART stop word list (Salton 1971) to filter the extracted ngrams, but allow trigrams to have a stop word as their middle word. The answer with the largest average PMI, calculated over all pairs of question n-grams and answer option n-grams, is the best guess for the PMI solver.\n\nThe Support Vector Machine (SVM) solver Word association is one statistical approach to questionanswering. An alternative is word similarity, specifically how semantically related an answer option a i is to the question q, where word embeddings are used to represent the lexical semantics.\n\nWe use the lexical semantics model and implementation, created by Jansen, Surdeanu, and Clark (2014), to generate domain-appropriate embeddings for a corpus of elementary science text. The embeddings are learned using the recurrent neural network language model (RNNLM) (Mikolov et al. 2010;. Like any language model, a RNNLM estimates the probability of observing a word given the preceding context, but, in this process, it also learns word embeddings into a latent, conceptual space with a fixed number of dimensions. Consequently, related words tend to have vectors that are close to each other in this space. We derive two measures from these vectors. The first is a measure of the overall similarity of the question and answer option, which is computed as the cosine similarity between the two composite vectors of q and a i . These composite vectors are assembled by summing the vectors for individual words of q (or a i ), and re-normalizing this composite vector to unit length. (This approach to combining vectors is simple and has worked well previously, e.g., (Yih et al. 2013)). The second measure is the average pairwise cosine similarity between each word in q and a i . This is repeated using four alternative science corpora (two features per corpus), and combined using an SVM ranker trained on a set of multiple choice questions with known answers, to compute a score for each answer option. We use an SVM as it has been previously shown to perform comparably with other algorithms for answer ranking, e.g., (Surdeanu, Ciaramita, and Zaragoza 2011), with mature software available.\n\n\nLayer 3: Structured Knowledge\n\nWhile textual and statistical systems perform well, they operate without any deep understanding of the question or domain, and consequently can be misled. This is especially true for questions for which some representation of general truths about the domain and methods for applying them is required. We explore two solvers that attempt to capture and apply this kind of knowledge, in complementary ways.\n\n\nThe RULE Solver\n\nThe RULE solver is based on the knowledge representation introduced by Clark et al. (2014), which is in the form of rules expressed in a probabilistic (subset of) first-order logic, and extracted automatically from text. Knowledge acquisition occurs in a two-step process. First, a corpus of science text is parsed and then scanned using a small number of (handauthored) extraction patterns to identify expressions of seven types of implication in text (cause, enables, purpose, requirement, condition, part, example, chosen by manual analysis of questions for the most commonly queried relationships). Although manually created, the patterns are domain-general so in principle would apply to a new domain also. Each pattern maps a syntactic structure to the form (tuple implication tuple), for example one pattern maps the textbook sentence \"Some animals grow thick fur to stay warm.\" to the structure: ((\"Some animals\" \"grow\" \"thick fur\") EFFECT (\"Some animals\" \"stay\" \"warm\")) Second, the extracted structure -a generic statement -is converted to an implication by applying a default reading of generics, where (A relation B) is interpreted as \"for all instances of A, there exists a B that is in relation to A\", producing a \"forall...exists...\" implication. For example, the above produces:\n\n// IF An animal grows thick fur // THEN the animal stays warm \u2200 a, g, t isa(a,\"Some animals\"), isa(g,\"grow\"), isa(t,\"thick fur\"), agent(g,a), object(g,t) \u2192 \u2203 s,w isa(s,\"stay\"),isa(w,\"warm\") agent(s,a), object(s,w), effect(g,s).\n\nNote that this representation is \"semi-formal\" as we retain words/phrases in the structures to denote concepts. A simple textual entailment service is used during reasoning to determine the confidence in equality between different text strings, e.g., isa(x,\"bear\") entails, with some confidence, isa(x,\"animal\").\n\nTo apply such knowledge, the question q and an answer option a i are translated into similar structures using the same natural language processing (NLP) machinery. The reasoner then performs a best-first search to find the lowest cost application of rules to derive the answer option (the conclusion) from the question (the premise). To tolerate incompleteness in the KB, the system mixes logical reasoning and lexical matching to determine the confidence that a rule can be applied, where the confidence is a normalized average of the entailment scores between literals in the question interpretation and the rule's antecedent, and the entailment scores between words in the question and words in the rule's antecedent. This allows rules to be applied even if their antecedents are only partially satisfied, providing a degree of robustness. The solver returns the (inverted) cost of the lowest cost proof as its confidence in answer option a i . This is repeated for all answer options.\n\n\nThe Integer Linear Programming (ILP) solver\n\nThe ILP solver uses knowledge represented as a set of tables, akin to the classical relational model (Codd 1970)  Tables were built using an interactive table-building tool applied to science texts. The tool performs bootstrapped relation extraction over a corpus, with a user in the loop to suggest syntactic patterns and accept/reject matches, allowing tables to be built quickly. Our eventual goal is to make table construction as automated as possible.\n\nInformally, question-answering involves matching lexical chunks in the question q and answer option a i against one or more table rows, or a chain of joined rows, and returning the strength of that match as the confidence in a i . For example, a path through two joined rows in Table 1 strongly matches the question + answer \"In USA, when is the summer solstice? (A) June\". We call such connections, which in general form a connected graph structure, a proof graph, and questionanswering involves selecting the answer option with the best scoring proof graph. Note that matching is not just string equality, as there may be lexical variation among question chunks and table cells (e.g., \"fall\" vs. \"autumn\").\n\nFormally, we treat this task as a discrete global optimization problem over tables. We use the ILP formalism, which has been successful in several NLP tasks (Roth and Yih 2004;Srikumar and Roth 2011;Zhang, Hoffmann, and Weld 2012) but, to our knowledge, has not been applied directly to question-answering using semi-structured knowledge. Let T be a set of knowledge tables and g(t, h) be a (possibly directional) similarity measure in [0, 1] between short natural language phrases t and h. Let q denote a multiple choice question with answer options A = {a i } i and correct answer a * \u2208 A. We build an ILP model M = M (q, A, T ) over a set V of integer-valued variables, a set C of linear constraints over V , and a linear maximization objective function f = f (q, A, T ) whose maximizer can be easily mapped to a candidate answer, ideally a * . At a high level, M defines the space of possible proof graphs or reasoning patterns that \"connect\" lexical chunks of q with some answer option a i \u2208 A through cells in one or more tables in T .\n\nVariables V define possible connections or edges between lexical chunks in q, answer options A, and cells of tables T . To improve scalability and reduce noise, we use the top few (typically 4-6) tables matching q as ranked by a simple TF-IDF scoring mechanism. Constraints C reduce the exponentially large search space to proof graphs to what a human might consider as meaningful and appropriate for elementary science reasoning. For instance, we enforce structural constraints such as: a proof graph P must have links to exactly one answer option, P may use at most k 1 rows per table and at least k 2 cells in any row it uses, etc. We also add semantic constraints, such as limiting pairs of columns in two tables that may be linked together, since not all table joins are meaningful. The constraints are designed from manual inspection of desirable proof graphs. Although manually built, they are not specific to 4th Grade Science so are a one-time cost. The objective function f associates with every feasible proof graph P a score f P designed to balance rewards (such as for including many links with high similarity measure g or linking with more columns of a table) with penalties (such as for using too many tables or low similarity links).\n\nTo score answer options, we first build the model M (q, A, T ) and solve it using an off-the-shelf ILP solver SCIP (Achterberg 2009). If a feasible solution is found, we read off the only answer option a \u2208 A that has links in the solution proof graph P , associate a with the value of f in P as its score, and repeat the above process with the remaining answer options A \\ {a} by disabling all links to a, until all answer options have been assigned a score or declared infeasible. The highest scoring option is then selected, while scores for the other options are used later in the Combiner.\n\n\nCombination\n\nEach solver outputs a non-negative confidence score for each of the answer options along with other optional features. The Combiner then produces a combined confidence score (between 0 and 1) using the following two-step approach.\n\nIn the first step, each solver is \"calibrated\" on the training set by learning a logistic regression classifier from each answer option to a correct/incorrect label. The features for an answer option i include the raw confidence score s i as well as the score normalized across the answer options for a given question. We include two types of normalizations:\nnormal i = s i j s j softmax i = exp(s i ) j exp(s j )\nEach solver can also provide other features capturing aspects of the question or the reasoning path. The output of this first step classifier is then a calibrated confidence for each solver s and answer option i: calib s i = 1/(1 + exp(\u2212\u03b2 s \u00b7 f s )) where f s is the solver specific feature vector and \u03b2 s the associated feature weights.\n\nThe second step uses these calibrated confidences as (the only) features to a second logistic regression classifier from answer option to correct/incorrect, resulting in a final confidence in [0, 1], which is used to rank the answers: Figure 2: Aristo significantly outperforms all individual solvers and the best previously published system (Praline).\nconfidence i = 1/ 1 + exp \u2212 \u03b2 0 \u2212 s\u2208Solvers \u03b2 s calib s i\nHere, feature weights \u03b2 s indicate the contribution of each solver to the final confidence. Empirically, this two-step approach yields more robust predictions given limited training data compared to a one-step approach where all solver features are fed directly into a single classification step.\n\n\nEmpirical Evaluation\n\nWe consider two questions: How well does STUDENT perform on 4th Grade Science problems; and do the different levels of representation all contribute to the overall score?\n\nDataset. We use real exam questions, exactly as written, from the NY Regents 1 4th Grade Science exams. 2 We use all questions within our scope (no diagram, multiple choice, NDMC), using 6 years of exams (108 NDMC questions) for training and 6 years (129 NDMC questions) for testing, kept completely hidden during all stages of system development. Questions vary in length from roughly 8 to 70 words, and cover a wide variety of topics and styles. Although the low number of publically released, real exam questions makes the dataset small, it provides sufficient signal for evaluation.\n\nCorpora, Rules, and Tables. We work with two corpora: 1. Elementary Science Corpus: 80k sentences about elementary science, consisting of a Regents study guide, CK12 textbooks, 3 and automatically collected Web sentences of similar style and content to that material. 2. Web Corpus: 5 \u00d7 10 10 tokens (280 GB of plain text) extracted from Web pages. From the Elementary Science corpus, a rulebase of 45,000 rules was automatically extracted for the RULE solver, and a datastore of 45 tables (10k rows, 40k cells) was built using an interactive table-building tool and manually, for the ILP solver. The PMI solver uses the Web Corpus and a window of 10 words to compute PMI values.\n\nScoring A solver's score is the percent correct on the question set. If the solver produces N answers (N-way tie) including the correct one, it scores 1/N (equivalent to the asymptote  of random guessing between the N). If no answer is produced, it is scored 1/K (for K-way multiple choice), equivalent to random guessing.\n\nResults and Comparison. We used as baseline the Praline system of Khot et al. (2015), also developed for 4th Grade Science questions, and the best performing system in that prior work. Praline uses Markov Logic Networks (MLNs) (Richardson and Domingos 2006) to align lexical elements of questions and background science knowledge, and to control inference. Using its optimal parameter values, the highest score it obtained on our dataset was 47.5%.\n\nWe also ran our system, Aristo, as well as each individual solver, on this data. Aristo scored 71.3%, significantly (at the 95% confidence level) higher than both the previously published system Praline, as well as all the individual solvers ( Figure 2). This suggests that the use of multiple levels of representation significantly improves performance on this class of problem.\n\nTo assess the contributions of individual solvers, we first ablated each solver one by one. The results are shown in Figure 3. In all cases, the performance dropped with a solver  Table 2: Adding solvers using increasingly structured representations improves performance. removed, with the PMI solver contributing the most (-8.5% drop when ablated). This suggests that all solvers are contributing to the ensemble, and none are redundant. To further assess possible redundancy, we compared questions correctly answered by different solver pairs to see whether any two solvers were answering essentially the same questions, indicating possible redundancy in the ensemble. The degree to which solver pairs were answering the same questions correctly is shown in Figure 4, again indicating a high degree of non-redundancy.\n\nTo further assess the layers of representation, we compared Aristo with the text only layer (the IR solver), and the text and statistical layer (the IR, PMI, and SVM solvers) together. The results are shown in Table 2. As more layers of representation are added, performance improves, again suggesting value in using multiple representations.\n\n\nDetailed Analysis\n\nWe provide insights into solvers' relative strengths and weaknesses based on a detailed analysis on the training data. The PMI solver: This solver selects the answer that most (relatively) frequently co-occurs with the question words. There are two major causes of failure:\n\n1. When there are multiple strong relationships between question words and answer options. For example, for:\n\n\nWhich characteristic can a human offspring inherit? (A) facial scar (B) blue eyes (C) long hair (D) broken leg\n\nit selects (C) because \"human\" and \"hair\" have high cooccurrence, a distractor from \"blue eyes\" and \"inherit\".\n\n2. When there are polarity-changing words (negation, good/bad, shortest/longest). For example, for:\n\n\nWhich activity is an example of a good health habit? (A) watching television (B) smoking cigarettes (C) eating candy (D) exercising every day\n\nthe solver selects (B) because \"health\" and \"cigarettes\" have high co-occurrence, overwhelming the co-occurrence between \"good health\" and \"exercising\".\n\nDespite these limitations, our experiments suggest the PMI solver provides the strongest signal in Aristo.\n\nThe RULE solver: This solver performs well when the applied rule(s) express an important implication in the domain, and the entailment reasoning correctly connects the rule to the question. For example, for:\n\nA turtle eating worms is an example of (A) breathing (B) reproducing (C) eliminating waste (D) taking in nutrients the solver correctly infers answer (D) by applying the rule:\n\n\"IF animals eat THEN animals get nutrients\" extracted from the textbook, along with the knowledge that a turtle isa animal, and that \"get\" and \"take in\" are synonyms.\n\nWhile this example illustrates how the solver can answer questions that other solvers struggle with, we observed two major failure modes: 1. Errors in the rulebase, question interpretation, or both, arising from poor syntactic analysis and interpretation. 2. Inadequacies in its heuristic scoring algorithm for computing the confidence that a rule applies.\n\nThe ILP solver: This solver's relative strength is for questions where multiple pieces of information need to be combined together. For example it successfully answers:\n\n\nWhich gas is given off by plants? (A) Hydrogen (B) Nitrogen (C) Oxygen (D)\n\nHelium by joining two rows of two different tables together (expressed as propositions below): table13:has-part(\"plant\", \"stomata\"). tablez3:part-output(\"stomata\", \"oxygen\"). In contrast, the PMI solver and the RULE solver both answer this question incorrectly: plants and nitrogen have high co-occurrence, and the RULE solver does not have an appropriate rule.\n\nThe curated table knowledge reduces the problem of noise (compared with the RULE solver), but there are still two main failure modes: 1. Missing knowledge: The curated tables do not cover the information required. 2. Control: While the table solver uses global constraints to constrain the paths explored, it may still find nonsensical paths (joins) through the tables during inference.\n\n\nDifficult Questions\n\nDespite Aristo's good performance, there are five classes of question that are hard for all of its constituent solvers to answer reliably, in the absence of a corpus sentence containing the answer explicitly: 1. Comparison questions ...moves faster or slower than ...?\n\n\nSimple arithmetic reasoning 7 rotations of Earth equals (A) 1 week (B) 2 weeks 3. Complex inference\n\nA white rabbit is best protected in (A) a snowy field..\n\n\nStructured questions\n\nWhich structure is correctly paired with its function?\n\n\nStory Questions\n\nA puddle formed. Then the sun came out ... In addition, linguistic variation, e.g., \"get a better look at/view in more detail\", \"removal of heat\"/\"drop in temperature\", \"35F\"/\"cold', is a challenge in all questions.\n\n\nConclusion\n\nFourth Grade Science tests are difficult for machines due to the wide variety of knowledge and reasoning requirements, making it a unique challenge for the community. In this paper we have presented Aristo, a system that addresses this challenge by using a family of representations with different levels of structure. The significance of this work is three-fold. First, the system achieves a new level of performance on this task compared with previously published work, demonstrating value in the approach. Second, our failure analysis illuminates the complementary strengths of the different methods, and where future work is needed. Finally, although Fourth Grade test-taking is not itself an application, we have shown that it requires QA that goes significantly beyond retrieval techniques, yet is simple enough to be accessible. In this sense, it is a simple embodiment of an AI challenge requiring both language and reasoning, with many potential applications if solved (e.g., tutoring systems, a scientist's assistant), and hence worthy of further exploration. We are releasing our datasets (at www.allenai.org) to encourage such research.\n\nFigure 1 :\n1Aristo uses five solvers, each using different types of knowledge, to answer multiple choice questions.\n\nFigure 3 :\n3Effect of removing an individual solver from the ensemble. The results suggest each solver contributes to the overall score.\n\nFigure 4 :\n4Different pairs of solvers answer substantially different question sets correctly (i.e., solvers are not redundant with each other). For example (line 1), of the questions PMI or SVM answer correctly, only 55.2% are in common.\n\n\nbut built over natural language text. Each knowledge table T consistsCountry \n\nLocation \nFrance north hemisphere \nUSA north hemisphere \n. . . \nBrazil south hemisphere \nZambia south hemisphere \n. . . \n\nHemisphere Orbital Event Month \nnorthern summer solstice Jun \nnorthern winter solstice Dec \nnorthern autumn equinox Sep \n. . . \nsouthern summer solstice Dec \nsouthern autumn equinox Mar \n. . . \n\nTable 1: Examples of knowledge tables \n\nof a head-body pair (H T , B T ) and captures a relation or \npredicate R T (x 1 , . . . , x n ) defined over entities. Columns \nof T represent attributes of R T with attribute names in the \nheader row H T , rows of T represent n-tuples or instances \nof R T , and cells of T represent entities as natural language \nphrases. Cohen (2000) studied noisy joins over similar tables, \nfocusing on efficiently computing, given a database query, the \ntop few matching data entries. Table 1 shows two (simplified) \nexamples. \n\nRegents is the only State-level Board to make all prior exams publically available, making it an ideal choice. 2 http://www.nysedregents.org/Grade4/Science/home.html 3 www.ck12.org\nAcknowledgementsWe are indebted to Paul Allen whose long-term vision inspired this project, and continues to inspire our scientific endeavors. We are grateful to Peter Jansen and Mihai Surdeanu who created the SVM solver and provided the implementation. We are also grateful to Niranjan Balasubramanian, Sumithra Bhakthavatsalam, Isaac Cowhey, Dirk Groeneveld, Kevin Humphreys, Jesse Kinkead, Roie Levin, Carissa Schoenick and Sam Skjonsberg for their contributions to this work.\nSCIP: solving constraint integer programs. T Achterberg, Mathematical Programming Computation. 11Achterberg, T. 2009. SCIP: solving constraint integer programs. Mathematical Programming Computation 1(1):1-41.\n\nAn analysis of the AskMSR question-answering system. E Brill, S Dumais, M Banko, Proceedings of EMNLP. EMNLPBrill, E.; Dumais, S.; and Banko, M. 2002. An analysis of the AskMSR question-answering system. In Proceedings of EMNLP, 257-264.\n\nWord association norms, mutual information and lexicography. K W Church, P Hanks, 27th ACL. Church, K. W., and Hanks, P. 1989. Word association norms, mutual information and lexicography. In 27th ACL, 76-83.\n\nMy Computer is an Honor Student but how Intelligent is it? Standardized Tests as a Measure of AI. AI Magazine. P Clark, O Etzioni, To appearClark, P., and Etzioni, O. 2016. My Computer is an Honor Student but how Intelligent is it? Standardized Tests as a Measure of AI. AI Magazine. (To appear).\n\nAutomatic construction of inference-supporting knowledge bases. P Clark, N Balasubramanian, S Bhakthavatsalam, K Humphreys, J Kinkead, A Sabharwal, O Tafjord, 4th Workshop on Automated Knowledge Base Construction (AKBC). Clark, P.; Balasubramanian, N.; Bhakthavatsalam, S.; Humphreys, K.; Kinkead, J.; Sabharwal, A.; and Tafjord, O. 2014. Automatic construction of inference-supporting knowledge bases. In 4th Workshop on Automated Knowledge Base Construction (AKBC).\n\nElementary school science and math tests as a driver for AI: take the Aristo challenge. P Clark, 29th AAAI/IAAI. Clark, P. 2015. Elementary school science and math tests as a driver for AI: take the Aristo challenge! In 29th AAAI/IAAI, 4019- 4021.\n\nA relational model of data for large shared data banks. E F Codd, Communications of the ACM. 136Codd, E. F. 1970. A relational model of data for large shared data banks. Communications of the ACM 13(6):377-387.\n\nData integration using similarity joins and a word-based information representation language. W W Cohen, ACM Transactions on Information Systems. 183Cohen, W. W. 2000. Data integration using similarity joins and a word-based information representation language. ACM Transac- tions on Information Systems 18(3):288-321.\n\nOpen question answering over curated and extracted knowledge bases. A Fader, L Zettlemoyer, O Etzioni, Proceedings of SIGKDD. SIGKDDFader, A.; Zettlemoyer, L.; and Etzioni, O. 2014. Open question answering over curated and extracted knowledge bases. In Pro- ceedings of SIGKDD, 1156-1165.\n\nBuilding Watson: An overview of the DeepQA project. D Ferrucci, E Brown, J Chu-Carroll, J Fan, D Gondek, A A Kalyanpur, A Lally, J W Murdock, E Nyberg, J Prager, AI magazine. 313Ferrucci, D.; Brown, E.; Chu-Carroll, J.; Fan, J.; Gondek, D.; Kalyanpur, A. A.; Lally, A.; Murdock, J. W.; Nyberg, E.; Prager, J.; et al. 2010. Building Watson: An overview of the DeepQA project. AI magazine 31(3):59-79.\n\nProject Halo update -progress toward digital Aristotle. D Gunning, V Chaudhri, P Clark, K Barker, J Chaw, M Greaves, AI Magazine. 313Gunning, D.; Chaudhri, V.; Clark, P.; Barker, K.; Chaw, J.; and Greaves, M. 2010. Project Halo update -progress toward digital Aristotle. AI Magazine 31(3).\n\nLearning to solve arithmetic word problems with verb categorization. M J Hosseini, H Hajishirzi, O Etzioni, N Kushman, EMNLP. Hosseini, M. J.; Hajishirzi, H.; Etzioni, O.; and Kushman, N. 2014. Learning to solve arithmetic word problems with verb categoriza- tion. In 2014 EMNLP, 523-533.\n\nDiscourse complements lexical semantics for non-factoid answer reranking. P Jansen, M Surdeanu, P Clark, 52nd ACL. Jansen, P.; Surdeanu, M.; and Clark, P. 2014. Discourse comple- ments lexical semantics for non-factoid answer reranking. In 52nd ACL, 977-986.\n\nExploring Markov logic networks for question answering. T Khot, N Balasubramanian, E Gribkoff, A Sabharwal, P Clark, O Etzioni, EMNLP. Khot, T.; Balasubramanian, N.; Gribkoff, E.; Sabharwal, A.; Clark, P.; and Etzioni, O. 2015. Exploring Markov logic networks for question answering. In 2015 EMNLP.\n\nA probabilistic graphical model for joint answer ranking in question answering. J Ko, E Nyberg, L Si, Proceedings of SIGIR. SIGIRKo, J.; Nyberg, E.; and Si, L. 2007. A probabilistic graphical model for joint answer ranking in question answering. In Proceed- ings of SIGIR, 343-350.\n\nLearning to automatically solve algebra word problems. N Kushman, L Zettlemoyer, R Barzilay, Y Artzi, 52nd ACL. Kushman, N.; Zettlemoyer, L.; Barzilay, R.; and Artzi, Y. 2014. Learning to automatically solve algebra word problems. In 52nd ACL, 271-281.\n\nRecurrent neural network based language model. T Mikolov, M Karafi\u00e1t, L Burget, J Cernock\u1ef3, S Khudanpur, INTERSPEECH. Mikolov, T.; Karafi\u00e1t, M.; Burget, L.; Cernock\u1ef3, J.; and Khudan- pur, S. 2010. Recurrent neural network based language model. In INTERSPEECH, 1045-1048.\n\nEfficient estimation of word representations in vector space. T Mikolov, K Chen, G Corrado, J Dean, ICLR. Mikolov, T.; Chen, K.; Corrado, G.; and Dean, J. 2013. Efficient estimation of word representations in vector space. In ICLR.\n\nRepresentations of knowledge in a program for solving physics problems. G Novak, IJCAI-77Novak, G. 1977. Representations of knowledge in a program for solving physics problems. In IJCAI-77.\n\nMarkov logic networks. M Richardson, P Domingos, Machine learning. 621-2Richardson, M., and Domingos, P. 2006. Markov logic networks. Machine learning 62(1-2):107-136.\n\nA linear programming formulation for global inference in natural language tasks. D Roth, Yih , W , CoNLL, 1-8. ACL. Salton, G. 1971. The SMART retrieval system-Experiments in automatic document processing. Prentice-Hall, IncRoth, D., and Yih, W. 2004. A linear programming formulation for global inference in natural language tasks. In CoNLL, 1-8. ACL. Salton, G. 1971. The SMART retrieval system-Experiments in automatic document processing. Prentice-Hall, Inc.\n\nDiagram understanding in geometry questions. M J Seo, H Hajishirzi, A Farhadi, O Etzioni, 28th AAAI. Seo, M. J.; Hajishirzi, H.; Farhadi, A.; and Etzioni, O. 2014. Di- agram understanding in geometry questions. In 28th AAAI, 2831- 2838.\n\nA joint model for extended semantic role labeling. V Srikumar, Roth , D , EMNLP. Srikumar, V., and Roth, D. 2011. A joint model for extended semantic role labeling. In EMNLP.\n\nLearning to rank answers to non-factoid questions from web collections. M Surdeanu, M Ciaramita, H Zaragoza, Computational Linguistics. 372Surdeanu, M.; Ciaramita, M.; and Zaragoza, H. 2011. Learning to rank answers to non-factoid questions from web collections. Com- putational Linguistics 37(2):351-383.\n\nThe BigChaos solution to the Netflix Grand Prize. Netflix prize documentation. A T\u00f6scher, M Jahrer, R M Bell, X Yao, B Van Durme, M.-W Chang, C Meek, A Pastusiak, 52nd ACL. Yih. Proc. ACLT\u00f6scher, A.; Jahrer, M.; and Bell, R. M. 2009. The BigChaos solution to the Netflix Grand Prize. Netflix prize documentation. Yao, X., and Van Durme, B. 2014. Information extraction over structured data: Question answering with Freebase. In 52nd ACL. Yih, W.-t.; Chang, M.-W.; Meek, C.; and Pastusiak, A. 2013. Question answering using enhanced lexical semantic models. In Proc. ACL.\n\nOntological smoothing for relation extraction with minimal supervision. C Zhang, R Hoffmann, D S Weld, 26th AAAI. Zhang, C.; Hoffmann, R.; and Weld, D. S. 2012. Ontological smoothing for relation extraction with minimal supervision. In 26th AAAI.\n\nNatural language question answering over rdf: a graph data driven approach. L Zou, R Huang, H Wang, J X Yu, W He, D Zhao, Proceedings of SIGMOD. SIGMODZou, L.; Huang, R.; Wang, H.; Yu, J. X.; He, W.; and Zhao, D. 2014. Natural language question answering over rdf: a graph data driven approach. In Proceedings of SIGMOD, 313-324.\n", "annotations": {"author": "[{\"end\":228,\"start\":89},{\"end\":368,\"start\":229},{\"end\":509,\"start\":369},{\"end\":655,\"start\":510},{\"end\":799,\"start\":656},{\"end\":940,\"start\":800},{\"end\":1087,\"start\":941}]", "publisher": null, "author_last_name": "[{\"end\":100,\"start\":95},{\"end\":241,\"start\":234},{\"end\":380,\"start\":376},{\"end\":526,\"start\":517},{\"end\":670,\"start\":663},{\"end\":812,\"start\":806},{\"end\":956,\"start\":948}]", "author_first_name": "[{\"end\":94,\"start\":89},{\"end\":233,\"start\":229},{\"end\":375,\"start\":369},{\"end\":516,\"start\":510},{\"end\":662,\"start\":656},{\"end\":805,\"start\":800},{\"end\":947,\"start\":941}]", "author_affiliation": "[{\"end\":227,\"start\":121},{\"end\":367,\"start\":261},{\"end\":508,\"start\":402},{\"end\":654,\"start\":548},{\"end\":798,\"start\":692},{\"end\":939,\"start\":833},{\"end\":1086,\"start\":980}]", "title": "[{\"end\":86,\"start\":1},{\"end\":1173,\"start\":1088}]", "venue": null, "abstract": "[{\"end\":2217,\"start\":1175}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2410,\"start\":2398},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2763,\"start\":2739},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2991,\"start\":2973},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5721,\"start\":5703},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":6439,\"start\":6423},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6476,\"start\":6439},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6538,\"start\":6507},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6559,\"start\":6538},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6583,\"start\":6559},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6812,\"start\":6791},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6823,\"start\":6812},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7018,\"start\":7002},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7058,\"start\":7036},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7078,\"start\":7058},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7385,\"start\":7353},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7465,\"start\":7443},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10580,\"start\":10557},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12021,\"start\":11987},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12212,\"start\":12191},{\"end\":13010,\"start\":12993},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13488,\"start\":13448},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":14069,\"start\":14050},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16966,\"start\":16955},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":18198,\"start\":18179},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":18221,\"start\":18198},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":18252,\"start\":18221},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":20448,\"start\":20432},{\"end\":22920,\"start\":22919},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":24492,\"start\":24474},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":24665,\"start\":24635}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":31494,\"start\":31378},{\"attributes\":{\"id\":\"fig_1\"},\"end\":31632,\"start\":31495},{\"attributes\":{\"id\":\"fig_2\"},\"end\":31872,\"start\":31633},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":32827,\"start\":31873}]", "paragraph": "[{\"end\":3062,\"start\":2233},{\"end\":3299,\"start\":3064},{\"end\":3414,\"start\":3301},{\"end\":4180,\"start\":3557},{\"end\":5519,\"start\":4182},{\"end\":5722,\"start\":5521},{\"end\":6147,\"start\":5724},{\"end\":6324,\"start\":6164},{\"end\":7247,\"start\":6326},{\"end\":8035,\"start\":7249},{\"end\":8560,\"start\":8048},{\"end\":9158,\"start\":8591},{\"end\":9560,\"start\":9193},{\"end\":9661,\"start\":9562},{\"end\":10336,\"start\":9663},{\"end\":10729,\"start\":10386},{\"end\":11628,\"start\":10764},{\"end\":11919,\"start\":11630},{\"end\":13521,\"start\":11921},{\"end\":13959,\"start\":13555},{\"end\":15273,\"start\":13979},{\"end\":15502,\"start\":15275},{\"end\":15816,\"start\":15504},{\"end\":16806,\"start\":15818},{\"end\":17310,\"start\":16854},{\"end\":18020,\"start\":17312},{\"end\":19063,\"start\":18022},{\"end\":20315,\"start\":19065},{\"end\":20910,\"start\":20317},{\"end\":21156,\"start\":20926},{\"end\":21516,\"start\":21158},{\"end\":21909,\"start\":21572},{\"end\":22263,\"start\":21911},{\"end\":22618,\"start\":22322},{\"end\":22813,\"start\":22643},{\"end\":23401,\"start\":22815},{\"end\":24082,\"start\":23403},{\"end\":24406,\"start\":24084},{\"end\":24856,\"start\":24408},{\"end\":25237,\"start\":24858},{\"end\":26058,\"start\":25239},{\"end\":26402,\"start\":26060},{\"end\":26697,\"start\":26424},{\"end\":26807,\"start\":26699},{\"end\":27032,\"start\":26922},{\"end\":27133,\"start\":27034},{\"end\":27431,\"start\":27279},{\"end\":27539,\"start\":27433},{\"end\":27748,\"start\":27541},{\"end\":27925,\"start\":27750},{\"end\":28093,\"start\":27927},{\"end\":28451,\"start\":28095},{\"end\":28621,\"start\":28453},{\"end\":29061,\"start\":28700},{\"end\":29449,\"start\":29063},{\"end\":29741,\"start\":29473},{\"end\":29900,\"start\":29845},{\"end\":29979,\"start\":29925},{\"end\":30214,\"start\":29999},{\"end\":31377,\"start\":30229}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10763,\"start\":10730},{\"attributes\":{\"id\":\"formula_1\"},\"end\":21571,\"start\":21517},{\"attributes\":{\"id\":\"formula_2\"},\"end\":22321,\"start\":22264}]", "table_ref": "[{\"end\":17597,\"start\":17590},{\"end\":25426,\"start\":25419},{\"end\":26277,\"start\":26270}]", "section_header": "[{\"end\":2231,\"start\":2219},{\"end\":3555,\"start\":3417},{\"end\":6162,\"start\":6150},{\"end\":8046,\"start\":8038},{\"end\":8589,\"start\":8563},{\"end\":9191,\"start\":9161},{\"end\":10384,\"start\":10339},{\"end\":13553,\"start\":13524},{\"end\":13977,\"start\":13962},{\"end\":16852,\"start\":16809},{\"end\":20924,\"start\":20913},{\"end\":22641,\"start\":22621},{\"end\":26422,\"start\":26405},{\"end\":26920,\"start\":26810},{\"end\":27277,\"start\":27136},{\"end\":28698,\"start\":28624},{\"end\":29471,\"start\":29452},{\"attributes\":{\"n\":\"2.\"},\"end\":29843,\"start\":29744},{\"attributes\":{\"n\":\"4.\"},\"end\":29923,\"start\":29903},{\"attributes\":{\"n\":\"5.\"},\"end\":29997,\"start\":29982},{\"end\":30227,\"start\":30217},{\"end\":31389,\"start\":31379},{\"end\":31506,\"start\":31496},{\"end\":31644,\"start\":31634}]", "table": "[{\"end\":32827,\"start\":31944}]", "figure_caption": "[{\"end\":31494,\"start\":31391},{\"end\":31632,\"start\":31508},{\"end\":31872,\"start\":31646},{\"end\":31944,\"start\":31875}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8096,\"start\":8088},{\"end\":22154,\"start\":22146},{\"end\":25110,\"start\":25102},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":25364,\"start\":25356},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":26007,\"start\":25999}]", "bib_author_first_name": "[{\"end\":33533,\"start\":33532},{\"end\":33753,\"start\":33752},{\"end\":33762,\"start\":33761},{\"end\":33772,\"start\":33771},{\"end\":34000,\"start\":33999},{\"end\":34002,\"start\":34001},{\"end\":34012,\"start\":34011},{\"end\":34259,\"start\":34258},{\"end\":34268,\"start\":34267},{\"end\":34510,\"start\":34509},{\"end\":34519,\"start\":34518},{\"end\":34538,\"start\":34537},{\"end\":34557,\"start\":34556},{\"end\":34570,\"start\":34569},{\"end\":34581,\"start\":34580},{\"end\":34594,\"start\":34593},{\"end\":35003,\"start\":35002},{\"end\":35220,\"start\":35219},{\"end\":35222,\"start\":35221},{\"end\":35470,\"start\":35469},{\"end\":35472,\"start\":35471},{\"end\":35764,\"start\":35763},{\"end\":35773,\"start\":35772},{\"end\":35788,\"start\":35787},{\"end\":36038,\"start\":36037},{\"end\":36050,\"start\":36049},{\"end\":36059,\"start\":36058},{\"end\":36074,\"start\":36073},{\"end\":36081,\"start\":36080},{\"end\":36091,\"start\":36090},{\"end\":36093,\"start\":36092},{\"end\":36106,\"start\":36105},{\"end\":36115,\"start\":36114},{\"end\":36117,\"start\":36116},{\"end\":36128,\"start\":36127},{\"end\":36138,\"start\":36137},{\"end\":36443,\"start\":36442},{\"end\":36454,\"start\":36453},{\"end\":36466,\"start\":36465},{\"end\":36475,\"start\":36474},{\"end\":36485,\"start\":36484},{\"end\":36493,\"start\":36492},{\"end\":36747,\"start\":36746},{\"end\":36749,\"start\":36748},{\"end\":36761,\"start\":36760},{\"end\":36775,\"start\":36774},{\"end\":36786,\"start\":36785},{\"end\":37042,\"start\":37041},{\"end\":37052,\"start\":37051},{\"end\":37064,\"start\":37063},{\"end\":37284,\"start\":37283},{\"end\":37292,\"start\":37291},{\"end\":37311,\"start\":37310},{\"end\":37323,\"start\":37322},{\"end\":37336,\"start\":37335},{\"end\":37345,\"start\":37344},{\"end\":37608,\"start\":37607},{\"end\":37614,\"start\":37613},{\"end\":37624,\"start\":37623},{\"end\":37866,\"start\":37865},{\"end\":37877,\"start\":37876},{\"end\":37892,\"start\":37891},{\"end\":37904,\"start\":37903},{\"end\":38112,\"start\":38111},{\"end\":38123,\"start\":38122},{\"end\":38135,\"start\":38134},{\"end\":38145,\"start\":38144},{\"end\":38157,\"start\":38156},{\"end\":38399,\"start\":38398},{\"end\":38410,\"start\":38409},{\"end\":38418,\"start\":38417},{\"end\":38429,\"start\":38428},{\"end\":38642,\"start\":38641},{\"end\":38784,\"start\":38783},{\"end\":38798,\"start\":38797},{\"end\":39011,\"start\":39010},{\"end\":39021,\"start\":39018},{\"end\":39025,\"start\":39024},{\"end\":39439,\"start\":39438},{\"end\":39441,\"start\":39440},{\"end\":39448,\"start\":39447},{\"end\":39462,\"start\":39461},{\"end\":39473,\"start\":39472},{\"end\":39683,\"start\":39682},{\"end\":39698,\"start\":39694},{\"end\":39702,\"start\":39701},{\"end\":39880,\"start\":39879},{\"end\":39892,\"start\":39891},{\"end\":39905,\"start\":39904},{\"end\":40194,\"start\":40193},{\"end\":40205,\"start\":40204},{\"end\":40215,\"start\":40214},{\"end\":40217,\"start\":40216},{\"end\":40225,\"start\":40224},{\"end\":40232,\"start\":40231},{\"end\":40248,\"start\":40244},{\"end\":40257,\"start\":40256},{\"end\":40265,\"start\":40264},{\"end\":40759,\"start\":40758},{\"end\":40768,\"start\":40767},{\"end\":40780,\"start\":40779},{\"end\":40782,\"start\":40781},{\"end\":41011,\"start\":41010},{\"end\":41018,\"start\":41017},{\"end\":41027,\"start\":41026},{\"end\":41035,\"start\":41034},{\"end\":41037,\"start\":41036},{\"end\":41043,\"start\":41042},{\"end\":41049,\"start\":41048}]", "bib_author_last_name": "[{\"end\":33544,\"start\":33534},{\"end\":33759,\"start\":33754},{\"end\":33769,\"start\":33763},{\"end\":33778,\"start\":33773},{\"end\":34009,\"start\":34003},{\"end\":34018,\"start\":34013},{\"end\":34265,\"start\":34260},{\"end\":34276,\"start\":34269},{\"end\":34516,\"start\":34511},{\"end\":34535,\"start\":34520},{\"end\":34554,\"start\":34539},{\"end\":34567,\"start\":34558},{\"end\":34578,\"start\":34571},{\"end\":34591,\"start\":34582},{\"end\":34602,\"start\":34595},{\"end\":35009,\"start\":35004},{\"end\":35227,\"start\":35223},{\"end\":35478,\"start\":35473},{\"end\":35770,\"start\":35765},{\"end\":35785,\"start\":35774},{\"end\":35796,\"start\":35789},{\"end\":36047,\"start\":36039},{\"end\":36056,\"start\":36051},{\"end\":36071,\"start\":36060},{\"end\":36078,\"start\":36075},{\"end\":36088,\"start\":36082},{\"end\":36103,\"start\":36094},{\"end\":36112,\"start\":36107},{\"end\":36125,\"start\":36118},{\"end\":36135,\"start\":36129},{\"end\":36145,\"start\":36139},{\"end\":36451,\"start\":36444},{\"end\":36463,\"start\":36455},{\"end\":36472,\"start\":36467},{\"end\":36482,\"start\":36476},{\"end\":36490,\"start\":36486},{\"end\":36501,\"start\":36494},{\"end\":36758,\"start\":36750},{\"end\":36772,\"start\":36762},{\"end\":36783,\"start\":36776},{\"end\":36794,\"start\":36787},{\"end\":37049,\"start\":37043},{\"end\":37061,\"start\":37053},{\"end\":37070,\"start\":37065},{\"end\":37289,\"start\":37285},{\"end\":37308,\"start\":37293},{\"end\":37320,\"start\":37312},{\"end\":37333,\"start\":37324},{\"end\":37342,\"start\":37337},{\"end\":37353,\"start\":37346},{\"end\":37611,\"start\":37609},{\"end\":37621,\"start\":37615},{\"end\":37627,\"start\":37625},{\"end\":37874,\"start\":37867},{\"end\":37889,\"start\":37878},{\"end\":37901,\"start\":37893},{\"end\":37910,\"start\":37905},{\"end\":38120,\"start\":38113},{\"end\":38132,\"start\":38124},{\"end\":38142,\"start\":38136},{\"end\":38154,\"start\":38146},{\"end\":38167,\"start\":38158},{\"end\":38407,\"start\":38400},{\"end\":38415,\"start\":38411},{\"end\":38426,\"start\":38419},{\"end\":38434,\"start\":38430},{\"end\":38648,\"start\":38643},{\"end\":38795,\"start\":38785},{\"end\":38807,\"start\":38799},{\"end\":39016,\"start\":39012},{\"end\":39445,\"start\":39442},{\"end\":39459,\"start\":39449},{\"end\":39470,\"start\":39463},{\"end\":39481,\"start\":39474},{\"end\":39692,\"start\":39684},{\"end\":39889,\"start\":39881},{\"end\":39902,\"start\":39893},{\"end\":39914,\"start\":39906},{\"end\":40202,\"start\":40195},{\"end\":40212,\"start\":40206},{\"end\":40222,\"start\":40218},{\"end\":40229,\"start\":40226},{\"end\":40242,\"start\":40233},{\"end\":40254,\"start\":40249},{\"end\":40262,\"start\":40258},{\"end\":40275,\"start\":40266},{\"end\":40765,\"start\":40760},{\"end\":40777,\"start\":40769},{\"end\":40787,\"start\":40783},{\"end\":41015,\"start\":41012},{\"end\":41024,\"start\":41019},{\"end\":41032,\"start\":41028},{\"end\":41040,\"start\":41038},{\"end\":41046,\"start\":41044},{\"end\":41054,\"start\":41050}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":18195817},\"end\":33697,\"start\":33489},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":5541486},\"end\":33936,\"start\":33699},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":9558665},\"end\":34145,\"start\":33938},{\"attributes\":{\"id\":\"b3\"},\"end\":34443,\"start\":34147},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":2851712},\"end\":34912,\"start\":34445},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":45705325},\"end\":35161,\"start\":34914},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":14926884},\"end\":35373,\"start\":35163},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":18820485},\"end\":35693,\"start\":35375},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":207214527},\"end\":35983,\"start\":35695},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":1831060},\"end\":36384,\"start\":35985},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":688850},\"end\":36675,\"start\":36386},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":428579},\"end\":36965,\"start\":36677},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":6049812},\"end\":37225,\"start\":36967},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":6694415},\"end\":37525,\"start\":37227},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":11834211},\"end\":37808,\"start\":37527},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":12451537},\"end\":38062,\"start\":37810},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":17048224},\"end\":38334,\"start\":38064},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":5959482},\"end\":38567,\"start\":38336},{\"attributes\":{\"doi\":\"IJCAI-77\",\"id\":\"b18\"},\"end\":38758,\"start\":38569},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":12698795},\"end\":38927,\"start\":38760},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":10048734},\"end\":39391,\"start\":38929},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":1537054},\"end\":39629,\"start\":39393},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":1378655},\"end\":39805,\"start\":39631},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":1699647},\"end\":40112,\"start\":39807},{\"attributes\":{\"id\":\"b24\"},\"end\":40684,\"start\":40114},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":8437146},\"end\":40932,\"start\":40686},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":3907371},\"end\":41263,\"start\":40934}]", "bib_title": "[{\"end\":33530,\"start\":33489},{\"end\":33750,\"start\":33699},{\"end\":33997,\"start\":33938},{\"end\":34507,\"start\":34445},{\"end\":35000,\"start\":34914},{\"end\":35217,\"start\":35163},{\"end\":35467,\"start\":35375},{\"end\":35761,\"start\":35695},{\"end\":36035,\"start\":35985},{\"end\":36440,\"start\":36386},{\"end\":36744,\"start\":36677},{\"end\":37039,\"start\":36967},{\"end\":37281,\"start\":37227},{\"end\":37605,\"start\":37527},{\"end\":37863,\"start\":37810},{\"end\":38109,\"start\":38064},{\"end\":38396,\"start\":38336},{\"end\":38781,\"start\":38760},{\"end\":39008,\"start\":38929},{\"end\":39436,\"start\":39393},{\"end\":39680,\"start\":39631},{\"end\":39877,\"start\":39807},{\"end\":40191,\"start\":40114},{\"end\":40756,\"start\":40686},{\"end\":41008,\"start\":40934}]", "bib_author": "[{\"end\":33546,\"start\":33532},{\"end\":33761,\"start\":33752},{\"end\":33771,\"start\":33761},{\"end\":33780,\"start\":33771},{\"end\":34011,\"start\":33999},{\"end\":34020,\"start\":34011},{\"end\":34267,\"start\":34258},{\"end\":34278,\"start\":34267},{\"end\":34518,\"start\":34509},{\"end\":34537,\"start\":34518},{\"end\":34556,\"start\":34537},{\"end\":34569,\"start\":34556},{\"end\":34580,\"start\":34569},{\"end\":34593,\"start\":34580},{\"end\":34604,\"start\":34593},{\"end\":35011,\"start\":35002},{\"end\":35229,\"start\":35219},{\"end\":35480,\"start\":35469},{\"end\":35772,\"start\":35763},{\"end\":35787,\"start\":35772},{\"end\":35798,\"start\":35787},{\"end\":36049,\"start\":36037},{\"end\":36058,\"start\":36049},{\"end\":36073,\"start\":36058},{\"end\":36080,\"start\":36073},{\"end\":36090,\"start\":36080},{\"end\":36105,\"start\":36090},{\"end\":36114,\"start\":36105},{\"end\":36127,\"start\":36114},{\"end\":36137,\"start\":36127},{\"end\":36147,\"start\":36137},{\"end\":36453,\"start\":36442},{\"end\":36465,\"start\":36453},{\"end\":36474,\"start\":36465},{\"end\":36484,\"start\":36474},{\"end\":36492,\"start\":36484},{\"end\":36503,\"start\":36492},{\"end\":36760,\"start\":36746},{\"end\":36774,\"start\":36760},{\"end\":36785,\"start\":36774},{\"end\":36796,\"start\":36785},{\"end\":37051,\"start\":37041},{\"end\":37063,\"start\":37051},{\"end\":37072,\"start\":37063},{\"end\":37291,\"start\":37283},{\"end\":37310,\"start\":37291},{\"end\":37322,\"start\":37310},{\"end\":37335,\"start\":37322},{\"end\":37344,\"start\":37335},{\"end\":37355,\"start\":37344},{\"end\":37613,\"start\":37607},{\"end\":37623,\"start\":37613},{\"end\":37629,\"start\":37623},{\"end\":37876,\"start\":37865},{\"end\":37891,\"start\":37876},{\"end\":37903,\"start\":37891},{\"end\":37912,\"start\":37903},{\"end\":38122,\"start\":38111},{\"end\":38134,\"start\":38122},{\"end\":38144,\"start\":38134},{\"end\":38156,\"start\":38144},{\"end\":38169,\"start\":38156},{\"end\":38409,\"start\":38398},{\"end\":38417,\"start\":38409},{\"end\":38428,\"start\":38417},{\"end\":38436,\"start\":38428},{\"end\":38650,\"start\":38641},{\"end\":38797,\"start\":38783},{\"end\":38809,\"start\":38797},{\"end\":39018,\"start\":39010},{\"end\":39024,\"start\":39018},{\"end\":39028,\"start\":39024},{\"end\":39447,\"start\":39438},{\"end\":39461,\"start\":39447},{\"end\":39472,\"start\":39461},{\"end\":39483,\"start\":39472},{\"end\":39694,\"start\":39682},{\"end\":39701,\"start\":39694},{\"end\":39705,\"start\":39701},{\"end\":39891,\"start\":39879},{\"end\":39904,\"start\":39891},{\"end\":39916,\"start\":39904},{\"end\":40204,\"start\":40193},{\"end\":40214,\"start\":40204},{\"end\":40224,\"start\":40214},{\"end\":40231,\"start\":40224},{\"end\":40244,\"start\":40231},{\"end\":40256,\"start\":40244},{\"end\":40264,\"start\":40256},{\"end\":40277,\"start\":40264},{\"end\":40767,\"start\":40758},{\"end\":40779,\"start\":40767},{\"end\":40789,\"start\":40779},{\"end\":41017,\"start\":41010},{\"end\":41026,\"start\":41017},{\"end\":41034,\"start\":41026},{\"end\":41042,\"start\":41034},{\"end\":41048,\"start\":41042},{\"end\":41056,\"start\":41048}]", "bib_venue": "[{\"end\":33582,\"start\":33546},{\"end\":33800,\"start\":33780},{\"end\":34028,\"start\":34020},{\"end\":34256,\"start\":34147},{\"end\":34664,\"start\":34604},{\"end\":35025,\"start\":35011},{\"end\":35254,\"start\":35229},{\"end\":35519,\"start\":35480},{\"end\":35819,\"start\":35798},{\"end\":36158,\"start\":36147},{\"end\":36514,\"start\":36503},{\"end\":36801,\"start\":36796},{\"end\":37080,\"start\":37072},{\"end\":37360,\"start\":37355},{\"end\":37649,\"start\":37629},{\"end\":37920,\"start\":37912},{\"end\":38180,\"start\":38169},{\"end\":38440,\"start\":38436},{\"end\":38639,\"start\":38569},{\"end\":38825,\"start\":38809},{\"end\":39133,\"start\":39028},{\"end\":39492,\"start\":39483},{\"end\":39710,\"start\":39705},{\"end\":39941,\"start\":39916},{\"end\":40290,\"start\":40277},{\"end\":40798,\"start\":40789},{\"end\":41077,\"start\":41056},{\"end\":33807,\"start\":33802},{\"end\":35827,\"start\":35821},{\"end\":37656,\"start\":37651},{\"end\":41085,\"start\":41079}]"}}}, "year": 2023, "month": 12, "day": 17}