{"id": 226229130, "updated": "2023-10-09 15:37:05.749", "metadata": {"title": "A Novel Path-based Entity Relatedness Measure for Efficient Collective Entity Linking", "authors": "[{\"first\":\"Cheikh\",\"last\":\"El Vaigh\",\"middle\":[\"Brahim\"]},{\"first\":\"Fran\u00e7ois\",\"last\":\"Goasdou\u00e9\",\"middle\":[]},{\"first\":\"Guillaume\",\"last\":\"Gravier\",\"middle\":[]},{\"first\":\"Pascale\",\"last\":\"S\u00e9billot\",\"middle\":[]}]", "venue": "Lecture Notes in Computer Science", "journal": "Lecture Notes in Computer Science", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": ". Collective entity linking is a core natural language processing task, which consists in jointly identifying the entities of a knowledge base (KB) that are mentioned in a text exploiting existing relations between entities within the KB. State-of-the-art methods typically combine local scores accounting for the similarity between mentions and entities, with a global score measuring the coherence of the set of selected entities. The latter relies on the structure of a KB: the hyperlink graph of Wikipedia in most cases or the graph of an RDF KB, e.g., BaseKB or Yago, to bene\ufb01t from the precise semantics of relationships between entities. In this paper, we devise a novel RDF-based entity relatedness measure for global scores with important properties: ( i ) it has a clear semantics, ( ii ) it can be calculated at reasonable computational cost, and ( iii ) it accounts for the transitive aspects of entity relatedness through existing (bounded length) property paths between entities in an RDF KB. Further, we experimentally show on the TAC-KBP2017 dataset, both with BaseKB and Yago, that it provides signi\ufb01cant improvement over state-of-the-art entity relatedness measures for the collective entity linking task.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3097585626", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/semweb/VaighGGS20", "doi": "10.1007/978-3-030-62419-4_10"}}, "content": {"source": {"pdf_hash": "9633ff8446e530b1822c33358b152a5ac3fc2e0c", "pdf_src": "Adhoc", "pdf_uri": "[\"https://web.archive.org/web/20200919090326/https:/hal.inria.fr/hal-02937580/file/paper_292.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://hal.inria.fr/hal-02937580/file/paper_292.pdf", "status": "GREEN"}}, "grobid": {"id": "df739fdf395c88856dcf1bc576cf88bf3cf4fc79", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/9633ff8446e530b1822c33358b152a5ac3fc2e0c.txt", "contents": "\n\n\n\n\nInria\nIRISA\nRennesFrance\n\n\nUniv. Rennes\nIRISA\nLannionFrance\n\n\nCNRS\nIRISA\nRennesFrance\n\n\nINSA Rennes\nIRISA\nRennesFrance\nSubmitted on 14 Sep 2020HAL Id: hal-02937580 https://hal.inria.fr/hal-02937580\n\n\nIntroduction\n\nEntity linking is a crucial task for textual document engineering in both natural language processing and information retrieval, with applications such as semantic search [2] and information extraction [16]. It aims at identifying the mentions of entities in a document and linking each mention to a unique referential such as a URI in Wikipedia or in an RDF knowledge base (KB). Entity linking is thus instrumental for semantic search and retrieval [2,16].\n\nThe literature on entity linking distinguishes two main approaches, depending on whether mentions within a single document are linked to entities independently one from another [20,10,12] or collectively [13,11,27,5,24,19]. The former uses the KB at hand to generate and select candidate entities independently for each entity mention in the text, while collective linking further uses the KB to select the best global mapping between mentions and candidate entities based on the entity interrelationships recorded in the KB. State-of-the-art methods for this collective linking step typically combine within a classifier a local score accounting for the string similarity between the mention and an entity's name, with a global score that measures the coherence of the set of selected entities. In particular, the cornerstone of global score computation is a measure of relatedness between two entities that indicates to which extent these entities may co-occur in a document.\n\nIn this paper, we focus on improving collective entity linking performance by devising a novel entity relatedness measure. Notably, we advocate that, in addition to showing significant performance improvement on standard benchmarks w.r.t. state-of-the-art competitors, a well-founded measure should meet the following three requirements to the extent possible: (R1) it must have a clear semantics so that linking decisions can be easily understood or explained, in particular it must build on a knowledge base with formal semantics (e.g., an RDF or OWL one, as opposed to Wikipedia) and avoid tuning parameters or knobs that are hard to set by end-users, (R2) it must be calculated at reasonable computational cost to be of practical interest and (R3) it must consider relatedness as a transitive relation, to capture that entities may be related within the KB either directly or indirectly, i.e., through paths. The last requirement (R3) is crucial as it allows encoding implicit links between entities. For instance, if X worksFor Y and Y isLocatedIn Z then, the path from X to Z implicitly encodes X worksIn Z, which is an information not stored in the KB that can be captured by measures meeting (R3).\n\nTo the best of our knowledge, no entity relatedness measure in the literature meets all three requirements. Approaches making use of Wikipedia, e.g., [1,4,6,13,11,24,17], consider Wikipedia's web page URIs as entities, web pages as textual entity descriptions, and hyperlinks between web pages as generic relations between entities. It is worth noting that, although a hyperlink from an entity to another states a direct relation between them, it carries very loose semantics: it solely indicates that the target entity somehow occurs in the description of the source one, be it central to this description or unimportant. Hence, Wikipedia-based entity relatedness measures do not meet (R1), at least. A few other approaches [26,14,22,15] rely on RDF KBs, like BaseKB, DBpedia or Yago, instead of Wikipedia. Such KBs encode in a formal knowledge graph model, the precise semantics of entities (e.g., types) and of their direct relations called properties (e.g., property names and cardinalities). While the Ref measure [1,18] just provides a binary indicator of whether or not a relation exists between two entities in the RDF KB, the recent WSRM measure [9], which can be viewed as an extension of Ref, further considers the amount of relations between two entities. Though they both have (simple) clear semantics (R1) and are cheap to calculate with edge lookups (R2), they only consider properties between entities to compute relatedness, thus do not meet (R3). By contrast, the rel k Excl relatedness measure [15] exploits the top-k property paths between two entities (more details in Sec. 2), hence meets (R3). However, it does not fully meet (R1) because though its definition has a clear semantics, its relies on userdefined constants that are non-trivial to set due to their unforeseeable consequences on the measure results. Also, rel k Excl does not meet (R2) because it requires computing all paths between entity pairs so as to select the top-k ones; this is not feasible in general in the setting of entity linking, which relies on large encyclopedic RDF KBs. Finally, the cosine similarity is used as an entity relatedness measure in approaches based on RDF KB embeddings [3,25], i.e., when entities are mapped into coordinates of a multidimensional space. Though the cosine similarity itself has a clear semantics (R1) and is not costly to compute (R2), the machine learning-based computation of embeddings cannot guarantee that cosine similar entities within the multidimensional space are indeed related in the KB, hence does not meet (R3).\n\nOur main contribution is the novel ASRMP m entity relatedness measure for RDF KBs, which satisfies the three requirements stated above. In particular, for two entities e 1 and e 2 , it uses the fuzzy logic AND and OR operators [7] to compute, respectively, the score of every e 1 -to-e 2 path of length up to m within the KB, by aggregating the WSRM values between the entity pairs found along the path, the final measure being obtained by aggregating over all paths of length m between e 1 and e 2 . In particular, ASRMP 1 boils down to WSRM. Importantly, ASRMP m is not tied to WSRM (i.e., another measure could have been used like Ref). We adopt it here because, in addition to satisfying (R1) and (R2), it is currently the relatedness measure showing best performance for collective entity linking in the literature [9]. Our fuzzy logic-based aggregation scheme allows ASRMP m to inherit both (R1) and (R2) from WSRM. Further, while computing the paths of length up to m between entities rapidly becomes unfeasible as m grows, (R3) is met by the need for considering low m values only. Indeed, it has been widely observed (e.g., in [15] for rel k Excl that also consider paths) that the longer the path between two entities, the less significant the relation it encodes. To evaluate ASRMP m for entity linking, we first define a collective entity linking system within which we experimentally show on the TAC-KBP2017 dataset, both with the BaseKB and Yago RDF KBs, that ASRMP m with m > 1 improves linking performance w.r.t. the above-mentioned relatedness measures from the literature. We also show significant improvement over popular collective linking techniques using standard entity linking benchmarks. 5 The paper is organized as follows. We first present in Sec. 2 the main entity relatedness measures used for collective entity linking. In Sec. 3, we define the ASRMP m entity relatedness measure. In Sec. 4, we describe our collective entity linking system with which ASRMP m is experimentally compared to state-of-the-art competitors in Sec. 5. Finally, we conclude and discuss perspectives in Sec. 6.\n\n\nRelated Work\n\nMost of the entity relatedness measures proposed so far in the context of collective entity linking rely on Wikipedia's hyperlink structure [1,4,6,13,11,24,17]. As pointed out above, such hyperlinks do not encode the precise semantics of the relations between entities they model, hence can hardly be used within well-founded entity relatedness measures, i.e., that meet the three requirements stated above.\n\nA handful of measures rely on RDF KBs [1,18,15,3,25,9]. Such KBs model both data (facts) and knowledge (ontological description of the application domain) using explicit and implicit triples; the latter can be derived through reasoning based on an RDF-specific consequence relation, a.k.a. entailment. In particular, within RDF KBs, the precise relation (a.k.a. property) r that directly relates an entity e i to another entity e j is encoded by the triple (e i , r, e j ). The use of RDF KBs can therefore be seen as an important step towards devising well-founded entity relatedness measures. We recall below the few relatedness measures that use RDF KBs, and discuss to which extent they meet the three requirements of well-foundedness introduced above: (R1), (R2) and (R3). The binary indicator Ref [1,18] is defined between two entities e i and e j as: \nRef(e i , e j ) = 1 \u2203r s.t. (e i ,\nwhere E denotes the set of entities in the KB and |S| the cardinality of the set S. In spirit, WSRM is comparable to the Wikipedia popularity often used in local entity linking scores, e.g., [8,10], as the probability that a mention m is used as the text (anchor) of a hyperlink referring to an entity e. WSRM is however conceptually different, being applied between two entities rather than between a mention and an entity. It can be interpreted as the probability that e i is directly related to e j through some property.\n\nThe above definition shows that WSRM has a clear and more fine-grained semantics than Ref (R1). Also, clearly, it can be computed at low computational cost (R2) based on edge lookups. However, like Ref, it does not allow entities to be related through property paths within the RDF KB, hence does not meet (R3). The path-based semantic relatedness measure [15] between two entities, denoted rel (k) Excl , is an aggregation of path weights for the top-k paths with highest weights between those entities; path weights are computed using the so-called exclusivity measure where |x \u03c4 \u2212 \u2192 * | is the number of outgoing \u03c4 relations for x, while | * \u03c4 \u2212 \u2192 y| is the number of incoming \u03c4 relations for y; 1 is subtracted to avoid counting the relation |x\nexclusivity(x \u03c4 \u2212 \u2192 y) = 1 |x \u03c4 \u2212 \u2192 * | + | * \u03c4 \u2212 \u2192 y| \u2212 1 ,(2)Measure (R1) (R2) (R3) Measure (R1) (R2) (R3) Ref [1,18] \u00d7 \u00d7 rel (k) Excl [15] \u223c \u00d7 WSRM [9] \u00d7 \u00d7 cosine [3,25] \u00d7 \u00d7\u03c4 \u2212 \u2192 y| twice. Given a path P = x 1 \u03c41 \u2212 \u2192 x 2 \u03c42 \u2212 \u2192 ... \u03c4 k\u22121 \u2212 \u2212\u2212 \u2192 x k within the KB, its weight is weight(P) = 1 k\u22121 i=1 1/exclusivity(x i \u03c4i \u2212 \u2192 x i+1 ) .(3)\nFinally rel\n(k)\nExcl is defined as the weighted sum of the top-k paths with highest weight between x and y rel\n(k) Excl (x, y) = P\u2208P k xy \u03b1 length(P) weight(P)(4)\nwhere P k xy denotes the top-k paths with highest weight between x and y, and \u03b1 \u2208 [0, 1] is a constant length decay factor introduced to give preference to shorter paths.\n\nWe remark that the above definition relies on paths between entities to measure their relatedness (R3). However, we note that the semantics of rel\n(k)\nExcl is controlled with parameters whose \"good\" values are hard to guess, though k = 5 and \u03b1 = 0.25 are recommended default values based on empirical observations. Thus rel (k) Excl hardly meets (R1). Further, the above definition requires to compute all the paths within the KB, which may not be computationally feasible since in large KBs, like the encyclopedic ones used for entity linking, the number of paths blows up as the considered path length increases; hence rel (k) Excl does not meet (R2). Cosine similarity [3,25] is used to measure the semantic relatedness between two entities in entity linking systems based on embeddings, e.g., [22,24,19,5]: entities are mapped into coordinates of a multidimensional space, in which the closer two entities are, the more related they are. Several kernels exist for computing such embeddings, e.g., [3,25,23]. While the cosine similarity itself has a clear semantics (R1) and is not costly to compute (R2), the machine learning-based construction of the entity embeddings cannot guarantee that cosine similar entities are indeed somehow related through some path in the KB, hence does not meet (R3).\n\nTab. 1 recaps the above discussion and highlights that none of the entity relatedness measures used so far in the entity linking literature meets the three requirements of wellfoundedness. Devising a measure that meets them all is a contribution of this paper, which we present next.\n\n\nThe Path-based Weighted Semantic Relatedness Measure\n\nOur approach to define a novel entity relatedness measure that meets all the wellfoundedness requirements extends a measure from the literature that only considers properties (direct relations) between entities, to a measure that considers paths between entities. In the sequel, we chose to rely on WSRM to capitalize (i) on properties (R1) and (R2) that WSRM verifies and (ii) on its state-of-the-art performance for collective entity linking, in particular w.r.t. Ref [9].\n\nA straightforward extension of WSRM to take into account paths between entities would consist in counting the paths between the entities e i , e j and e i , e , instead of the properties r and r respectively in Eq. 1. However, the resulting measure would loose (R2) as it would require to compute all the paths between the entities in the KB. To circumvent this issue and retain (R2), one may be tempted to only count paths up to some typically small length, as it is well-known (e.g., [15]) that the longer a path between two entities, the weaker the semantics of the relation it encodes. Still, in this case, though clear, the semantics of the resulting measure is poor as it does not account for the strength of the paths between entities.\n\nInstead, in addition to bounding the length of the paths we consider, we do aggregate the WSRM values of the successive entity pairs found along a path between two entities, so that the resulting value reflects how related these entities are through this particular path. Further, since many paths (with same or different lengths) may relate two entities, we also aggregate the individual relatedness values of these paths into a final entity relatedness score. Hereafter, the aggregation operator for the WSRM values found along a path is denoted \u2297, while the one for path scores is denoted \u2295. Tough typical candidate operators for \u2297 and \u2295 are either min and max, or product and sum, we chose fuzzy logic operators (discussed shortly) modeling the counterparts of the Boolean logical AND and OR operators in the [0,1] interval (recall that WSRM values are also within this interval). We now discuss three strategies to combine path relatedness values, yielding a family of entity relatedness measures.\n\nThe first strategy consists in aggregating all paths of length m separately, and aims at showing the contribution of paths with different lengths when considered separately. Formally, we define the weighted semantic relatedness measure for path of length m between entities e i and e j as\nASRMP a m (e i , e j ) = \u2295 p\u2208ei ej ,|p|=m \u2297 |p|\u22121 k=1 WSRM(p k , p k+1 ) ,(5)\nwhere e i e j denotes the set of paths between e i and e j , here limited to paths of length m, and p k is the k th entity along path p (hence p 1 = e i and p |p| = e j ). The inner \u2297 operator aggregates the WSRM scores along the edges of a given path; the outer \u2295 operator aggregates scores obtained for different paths of length m between the two entities. The cost of the different aggregations is low, so ASRMP a m (e i , e j ) meets both (R2) and (R3). It however only roughly meets (R1), because the semantics is deteriorated by combining separately the paths of different lengths at a subsequent stage, e.g., in the entity linking process.\n\nA second strategy consists in aggregating all paths of length less or equal m, as opposed to limiting ourselves to paths of a given length, extending Eq. 5 as\nASRMP b m (e i , e j ) = \u2295 p\u2208ei ej ,|p|\u2264m \u2297 |p|\u22121 k=1 WSRM(p k , p k+1 ) .(6)\nThis measure provides a first approach to combining paths of different lengths, however assuming equal weight for all of them. This assumption seems unrealistic: intuitively, direct relations are expected to account for strong relations, while indirect ones are weaker, where the longer the path, the weaker the relation. We thus introduce a weight depending on the path length according to\nASRMP c m (e i , e j ) = m l=1 p\u2208ei ej ,|p|=l w l \u2297 |p|\u22121 k=0 WSRM(e k , e k+1 ) ,(7)\nwhere w l is a length-dependent weight roughly corresponding to the percentage of useful paths of length l and optimized by grid search. Thus, ASRMP b m (e i , e j ) meets the three requirements while ASRMP c m (e i , e j ) does not meet (R1), because the semantics is once again deteriorated by the introduced weight.\n\nFinally, all measures are made symmetrical according to\n\u03c8 x m (e i , e j ) = 1 2 (ASRMP x m (e i , e j ) + ASRMP x m (e j , e i )) x \u2208 {a, b, c} . (8)\nThe rationale for symmetrization is that in an RDF KB, if a triple (e i , r, e j ) exists, the symmetric triple (e j , r \u2212 , e i ) may not exist at the same time, e.g., for r, r \u2212 the symmetric properties 'hasWritten', 'writtenBy' respectively. This depends on the modeling choices adopted for the KB at design time.\n\nAggregating scores with fuzzy logic The score aggregators used in the definition of ASRMP x m are crucial: they have to be chosen so as to preserve the semantics of the relations between entities without introducing noise, i.e., semantic drift. The longer a path between two entities, the smaller should be the relatedness value because the link between the entities may become meaningless. Typically, a product of WSRM values along a path will quickly decrease, resulting into useless scores; the average score can be noisy. For two given entities with a direct link and indirect links, the average can also result in scores for paths of length m > 1 larger than the score for the direct link, which we assume to be semantically incorrect. Hence we advocate for fuzzy logic operators which provide a wide range of aggregators, such as the equivalent of the AND/OR logic operators for real values in the [0, 1] interval. The semantics of the fuzzy operators is also important because it allows to explain the linking decisions and ensures (R1).\n\nFuzzy logic, especially triangular norm fuzzy logic (t-norm) which guarantees triangular inequality in probabilistic spaces, generalizes intersection in a lattice and conjunction in logic, offering many aggregation operators to define conjunction for values within [0, 1]. Each t-norm operator is associated with an s-norm (t-conorm) with respect to De Morgan's law: S(x, y) = 1\u2212T (1\u2212x, 1\u2212y). The t-norm is the standard semantics for conjunction in fuzzy logic and thus the couple t-norm/s-norm acts as AND/OR operators on real values in [0, 1]. Thus using fuzzy logic to define our relatedness measure allows to ensure its transitivity by definition and avoids the introduction of arbitrary weighting parameters like in rel (k)\n\nExcl . As WSRM(e, e ) \u2208 [0, 1], any t-norm/s-norm couple can be used to aggregate values along one path of length m and across all paths between two entities. We experimented with several couples of fuzzy operators: beside the classical min/max, we also consider the family of Hamacher t-norms (Hamacher product) defined for \u03bb \u2265 0 as\nT H,\u03bb (x, y) = xy \u03bb + (1 \u2212 \u03bb)(x + y \u2212 xy) ,(9)\nthe family of Yager t-norms defined for \u03bb > 0 as\nT Y,\u03bb (x, y) = max 0 1 \u2212 \u03bb (1 \u2212 x) \u03bb + (1 \u2212 y) \u03bb(10)\nand the Einstein sum\nT E (x, y) = xy 1 + (1 \u2212 x)(1 \u2212 y)\n.\n\nThe two families of t-norm used here are not exhaustive but generalize many tnorms: one can easily see that T H,2 (x, y) = T E (x, y); T H,1 (x, y) is known as the product t-norm; T Y,1 (x, y) is the \u0141ukasiewicz t-norm. We studied a large body of those operators and chose the one maximizing the accuracy of the collective linking system described hereunder.\n\n\nLinking with entity relatedness measure\n\nWe study the interest of the entity relatedness measure in the context of entity linking. In a general collective entity linking pipeline, semantic relatedness measures between entities are used at the end of the process to globally select the best candidate entity for each mention. They are typically used within a classifier along with features describing the mapping between the mention and the entity, to predict whether an entity is a good match (1) for a mention or not (0). The classifier operates independently on each mention-entity pair, and allows an ensemble of local classifications based on the relatedness of the entity to candidate entities of other mentions.\n\nWe briefly review the entity linking pipeline that we adopted. As in many previous pieces of work, e.g., [9,11,22,24,5], we do not consider the initial named entity recognition step, assuming perfect entity mention detection. The next step is the candidate entity generation stage, which consists in determining for each mention a reduced set of plausible entities that the mention could refer to. The final stage is the candidate selection stage, a.k.a. disambiguation, in which the best candidate is selected for each mention taking into account possible relations to candidates from other mentions.\n\nIn the remainder of this section, a document D is represented by its set of entity mentions, D = (m 1 , ..., m n ). For each mention m i , C(m i ) = (e i1 , ..., e ik ) denotes the set of its candidate entities.\n\n\nKnowledge Base\n\nIn this paper, we focus on two RDF KBs, namely Yago 6 and BaseKB 7 , but however make use of Wikipedia for candidate generation for practical reasons, since the names 6 https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/ research/yago-naga/yago 7 http://basekb.com/ of Wikipedia pages are meaningful unique identifiers unlike entities' labels in KB. BaseKB, derived from Freebase, contains over one billion facts (i.e., triples) about more than 40 millions subjects. Yago, derived from Wikipedia, WordNet and GeoNames, currently has knowledge of more than 10 million subjects and contains more than 120 million facts. Within those two KBs, interrelationships between entities bear precise semantics as specified by their schema. Contrary to Yago, BaseKB is saturated, i.e., all facts are made explicit with property instances thus circumventing the need for reasoning mechanisms. As, for practical reasons, we take advantage of Wikipedia in the candidate generation step, a mapping between Wikipedia and Yago or BaseKB entities is maintained. We also limit ourselves to entities appearing both in Wikipedia and in the RDF KB, resulting in approximately 2.5M entities in BaseKB and 3M entities in Yago.\n\nNote that while BaseKB and Yago are used in this paper, there are no conceptual limitations to those KBs, ASRMP m being able to account for any RDF KB schema.\n\n\nCandidate Entity Generation\n\nThe generation of the candidate entities e ij for each mention m i in a document relies on Cross-Wiki, a dictionary computed from a Google crawl of the web that stores the frequency with which a mention links to a particular entity within Wikipedia. We used the same Cross-Wiki dictionary as in [12]. Each entry of the dictionary corresponds to a possible entity mention and provides a list of Wikipedia entities to which the mention points to, along with popularity scores. This list is directly used for candidate generation whenever a mention appears in the dictionary. The dictionary entries are normalized by removing all punctuation marks and converting to lower case. For mentions absent from Cross-Wiki, a query on Wikipedia was performed using the text of the mention, and the resulting Wikipedia pages were collected as the candidate entities.\n\n\nSupervised Entity Selection\n\nTo select the best candidate entity e i\uf6be for each entity mention m i in a document in a collective manner, we adopted a supervised approach similar to [9,22,27], where a classifier is trained to predict whether a mention and a candidate entity are related (1) or not (0). We used a binary logistic regression, denoted logreg(), applied independently on each mention-candidate entity pair, selecting for a mention m i the candidate entity with the highest response from the classifier, i.e., ,\uf6be = arg max j logreg(m i , e ij ). We also experimented with different classifiers-see Sec. 5.3 for details-and the choice of a binary logistic regression is motivated by its simplicity and the fact that it turned out the best classification strategy. In our collective setting, the classifier relies on features describing the similarity between the mention and the entity on the one hand, and, on the other hand, the relatedness of the candidate entity under consideration with the candidate entities from other mentions in the document. The latter accounts for the context and ensures the collective aspect of the linking.\n\nFor the similarity between the mention and the candidate entity, we considered two features namely the cosine similarity between the vectors representations of the mention and of the entity name within Wikipedia, as obtained with word2vec [21], and the Wikipedia popularity as provided by Cross-Wiki.\n\nFor the relatedness of the candidate entity e ij with candidate entities from other mentions, i.e., e kl with k = i, we relied on an aggregation of the scores \u03c6(e ij , e kl ) over the set of candidate entities \u222a k =i C(m k ), where \u03c6() is an entity relatedness measure (e.g., rel (k) Excl , WSRM, ASRMP), thus providing a global measure of how e ij relates to other entity propositions in D. This aggregation is different from the one used to design our relatedness measure. We used sum and maximum aggregation, which has proven efficient in previous work. Formally, considering an entity relatedness \u03c6(), we define the sum aggregator as\nS(e ij ; D) = n k=1,k =i e\u2208C(m k ) \u03c6(e ij , e) ,(12)\nand the maximum aggregators as\nM k (e ij ; D) = n max @k k=1,k =i max e\u2208C(m k ) \u03c6(e ij , e)(13)\nwhere max @k is an operator returning the k th highest value. Note that the two aggregators are complementary: the sum provides a global averaged view while the max values emphasize good matches. We observed that retaining the sum, max@1, max@2 and max@3 aggregators as global features for the logistic regression worked best for the relatedness measure \u03c8 a 1 (). We therefore retained the same strategy for \u03c8 a 2 (), and \n\n\nExperiments\n\nIn the remainder of the paper, we report on a set of experiments conducted to assess the benefit of our entity relatedness measure in a collective entity linking task. We are using different entity relatedness measures, within the same collective entity linking pipeline as described per Sec. 4. Experiments are mostly carried out on the TAC-KBP Entity Discovery and Linking (EDL) 2016-2017 datasets, two newswire and forum-discussion sets of documents originally collected for the TAC Knowledge Base Population Entity Discovery and Linking 2016 and 2017 international evaluation campaigns [16], which constitute the reference for the task of entity linking. Results are reported in terms of F1-score, where precision P = |G\u2229S| |S| and recall R = |G\u2229S| |G| are calculated between the linking in the gold-standard (G) and the linking given by a system (S). The 2016 version was used to learn the classifiers while the 2017 one served as test set. As the collective entity linking system is trained while only changing the entity relatedness measure, the linking accuracy can be used to evaluate the quality of the entity relatedness measure.\n\nAfter providing implementation details in Sec. 5.1, selecting the best fuzzy aggregator in Sec. 5.2 and the best classification strategy in Sec. 5.3, we compare in Sec 5.4 the various flavors of ASRMP m seeking for the best one. The latter is compared to the entity relatedness measures used for entity linking in the literature in Sec. 5.5. Finally, we compare in Sec. 5.6 our collective entity linking system to a series of competing systems.\n\n\nImplementation Details\n\nComputing all the paths of length m between every pair of entities in the KB can be computationally expensive. For instance, in BaseKB, and after data cleansing, there are approximately 13M paths of length one and 46B paths of length two. We designed an efficient way of doing so, taking advantage of a relational database management system-which offers today much more tuning opportunities than RDF data management systems, e.g., various indices, clustered tables, etc.-to store edges and their semantic relatedness weights.\n\nIn PostgreSQL 11.2 8 , a table edges(e 1 , e 2 , v) is used to store the pairs of entities (e 1 , e 2 ) directly connected through some property in the KB, along with the corresponding WSRM value v. This table is dictionary-encoded (entity names are replaced by integers) to save space and speed up value comparisons, indexed by (e 1 , e 2 ) and (e 2 , e 1 ) values to offer many options to the PostgreSQL optimizer. Limiting ourselves to path lengths m \u2264 4, the four tables path1(e 1 , e 2 , v 1 ), path2(e 1 , e 2 , v 1 , v 2 ), path3(e 1 , e 2 , v 1 , v 2 , v 3 ) and path4(e 1 , e 2 , v 1 , v 2 , v 3 , v 4 ) are efficiently created from the edge table using SQL queries, to represent paths of length 1, 2, 3 and 4 respectively. The entities e 1 and e 2 are restricted to the candidate entities for the entity mentions found in the TAC-KBP2016-2017 datasets: entities along the paths may however not be candidate entities. The values v i are the WSRM values along the path.\n\nIn BaseKB, we obtained approximately 53K one-, 11M two-and 2B three-edges paths, from which we computed the various ASRMP m , relatedness values. We were not able to compute paths of length four, as the number of paths exploded. The same process was applied to Yago and we obtained approximately 28K one-, 845K two-, 25M three-and 679M four-edges paths. Paths of length four could be computed due to the cleanliness and the higher structure of Yago.\n\n\nComparing Fuzzy Logic Aggregators\n\nOne crucial issue for paths of length m > 1 lies in the aggregation of the semantic relatedness measure of each edge along the path and of the relatedness measure over multiple paths between two entities. ASRMP m reflects entity relatedness in the KB at hand: obviously, an aggregation of its values should reflect similar properties. Moreover, and in order to avoid a semantic drift, the resulting value of the aggregation for one path of length m must be smaller than that of a path of length m \u2212 1 since the latter bears stronger semantics. Finally, because there can be many paths between two entities, one needs also to aggregate the values of the different paths connecting two given entities.\n\nExperimental results (not reported here for lack of space) show that T H,0 (x, y) is the best aggregator with the collective linking setting in this paper. We however experimentally observed only minor differences between the Hammacher and Yager t-norms and  Table 2: F1-scores for various classifiers within the entity linking system for TAC-KBP. various values of \u03bb. In the remainder, T H,0 (x, y) with its associated s-norm is used for the aggregation of paths of length m \u2208 {2, 3, 4} between two entities.\n\n\nComparing Classifiers\n\nWe compared several classifiers within our collective entity linking system. In addition to popular classification techniques such as k-nearest neighbours (KNN), decision trees (DT), logistic regression (REG) or support vector machines (SVM), we also experimented with gradient boosting (GB). The latter was used in previous work on entity relatedness for entity linking [27,28]. Results reported in Tab. 2 for ASRMP a m , m \u2208 {1, 2, 3, 4}, on the TAC-KBP dataset using using either BaseKB or (saturated) Yago as KB, clearly show that the logistic regression classification strategy turns out to be the best option overall, in particular when considering paths of length 2 or more.\n\n\nComparing Aggregation Strategies\n\nWe also compared the aggregation strategies described in Sec. 3, reporting in Fig. 1 the F1-score as a function of m for the various strategies: distinct ASRMP a m measures for each value of m (including length four for Yago) aggregated by the classifier; aggregation with fuzzy logic as defined by ASRMP b m ; explicit weighting as in ASRMP c m optimized by grid search. In most cases, better performance is achieved for m = 2, diminishing for m > 2, which confirms that paths longer than 2 mostly bring noise because of a semantic drift. This is particularly visible in Fig. 1b. Classifier-based fusion, Fig. 1a, however seems to keep increasing for m = 3 on BaseKB, but the gain is only minimal between m = 2 and m = 3 and is counterbalanced by the computational cost (see Sec. 5.5), specially for BaseKB. Interestingly, for explicit weighting, the weights w l can be seen as the strength of the paths with length l. We found that the optimal values of w l decrease when l increases, i.e., w 2 = 1, w 3 = 0.1 and w 4 = 0.1 for Yago.  These different aggregation studies show that fuzzy aggregator (Fig. 1b) and explicit weights (Fig. 1c) are more robust for combining paths of different lengths, while the classifier-based fusion (Fig. 1a) is more accurate though it introduces noise for paths of length > 2. For example, in both Fig. 1b and Fig. 1c paths of length four are always adding noise, when considered with Yago and Yago saturated. With respect to the entity linking task, ASRMP a m with classifier-based fusion appears the best strategy. In all generality and contrary to ASRMP b m , this strategy only loosely verifies (R1) as classifier-based fusion can be difficult to interpret. In this regard, logistic regression nevertheless offers interesting properties, with coefficients and intercepts that can be interpreted to some extent.\n\n\nComparisons of entity relatedness measures\n\nWe now concentrate on the study of (the different components of) ASRMP a m , m > 1, with classifier-based fusion, and how it compares with other relatedness measures, namely WSRM [9], cosine similarity [25,3] and Ref [1,18]. All measures are used within the same collective entity linking system as input features to the classifier, thus providing fair comparison of the entity relatedness measures. Results are gathered in Tab. 3 for BaseKB, Yago and Yago saturated, reporting linking accuracy (F1-score). The different measures compared are:\n\n-Local performs linking using only the two local features depicting the adequacy of the mention and the entity-see Sec. 4.3-thus not considering entity relatedness -Cosine similarity(kernel), the kernel being either rdf2vec [25] or TransE [3], measures entity relatedness as the cosine similarity between the entities embedded in a high-dimension space with the given kernel  \n\nExcl [15] uses entity relatedness as defined in Eq 4 with k = 5 -WSRM [9], which is equivalent to ASRMP 1 , where only direct paths are used to measure entity relatedness -ASRMP a m which embed basic reasoning mechanisms accounting for paths of length m > 1\n\nAdding paths of length 2 allows a slight increase of the linking accuracy, where the best score for ASRMP a 2 is obtained using both S 2 and M (k) 2\n\nfor k = 1, 2, 3 (row ASRMP a 2 ). Looking separately at the benefit of the aggregators S 2 and M (k) 2 across couples of candidate entities, we see that considering only the maximum increases the accuracy of the ASRMP 1 system but, as it reflects the predominant topic, mentions that are far from that general topic can be incorrectly linked. Meanwhile, using S 2 can be slightly worse than ASRMP 1 only (e.g., on BaseKB, not on Yago) because this aggregator reflects choosing the mean topic which can be very vague. Combining both seems to be a compromise between the two extreme cases. On the other hand, ASRMP a 2 is better than both WSRM [9] and Rel (5) Excl [15] showing the interest of using a well founded entity relatedness measure along with property paths.\n\nPaths of length 3 can further be successfully combined with the features used for ASRMP a 2 when S 3 is considered; while using M (k) 3 , either alone or with S 3 , seems to introduce noise in the linking decision. This counter-intuitive result can be explained by the fact that introducing path of length three adds limited relevant semantics into the relatedness measure. As an outcome, considering the predominant entities only (max aggregators) tends to take strong linking decision and can be more drastic than adding vague links, mostly for entities that were not linked with the aggregation of ASRMP  We also studied the impact of the saturation of the KB using Yago. As shown in Tab. 3 (columns 3 and 4) and in Fig. 1 (red and yellow bars), the gain is very limited in the case of TAC-KBP2017 dataset. In practice, this result saves the explicit computation of the implicit triples in the RDF KB.\n\n\nComparison of entity linking systems\n\nWe finally compared the collective entity linking system based on ASRMP a m with prominent state-of-the-art methods over standard benchmarks: NCEL [5], AIDA [13], PHoH [11] and CEL-WSRM [9]. All follow the classical three stage architecture for collective entity linking. CEL-WSRM [9] is based on the WSRM entity relatedness measure (Eq. 1), equivalent to ASRMP 1 . Results of the entity linking process, evaluated in terms of micro-averaged F1 classification scores, are reported in Tab. 5. These results were obtained with the Yago KB that allows considering paths of length up to 4. Similar results are obtained when the Yago KB is saturated. On all four datasets, the proposed method CEL-ASRMP a m , m \u2208 {2, 3, 4}, does outperform the NCEL, AIDA and PBoH collective linking approaches by a large margin. The proposed method is better than CEL-WSRM on the four datasets, with small improvement on the RSS-500 dataset. Moreover, we observe the same conclusion as before: paths of length two improve the accuracy of the linking, while longer paths may add noise.\n\n\nConclusions\n\nIn summary, we extended previous measures of entity relatedness within a knowledge base to account for indirect relations between entities through the consideration of property paths. The measure that we proposed is the first to satisfy the three good properties that such measures should have: clear semantics, reasonable computational cost and transitivity. We experimentally showed its benefit in a collective entity linking task, where paths of length 2 and 3 bring improvement over the state of the art in collective entity linking, using either only direct connections between entities [9] or previous work on path-based relatedness measures [15]. In theory, the scalability of ASRMP m varies in inverse proportion with the length of the paths. We however proved it to be still tractable for reasonable sized datasets with paths of length up to 3, which is sufficient in practice as longer paths add noise.\n\nThis contribution opens up new horizons towards fully exploiting the semantics of RDF knowledge bases for entity linking, when only relatedness measures are used. Taking a historical perspective, this task was first conventionally addressed leveraging entity relatedness measures based on Wikipedia hyperlinks counts between two pages and on the presence of one relation between two entities in the KB. WSRM (= ASRMP 1 ) made use of KB semantics by weighting the relatedness between entities exploiting the basic properties within the KB. The ASRMP m extension proposed here further introduces (basic) reasoning mechanisms that exploit the graph-structure of the KB alongside robust aggregators for paths of arbitrary length. In this work, all paths were considered regardless of their precise semantics. In specific application contexts, this could be improved by selecting paths between two entities that are semantically meaningful in this context, e.g., using ontological knowledge and reasoning.\n\n\u03c8 a 3\n3() resulting in a total of 12 global features-namely S m , M to represent the relatedness of a candidate entity with other possible entities in D. Experiments with \u03c8 x m () with x \u2208 {b, c}, i.e., where different path lengths are already aggregated within ASRMP x m , involve only 4 global features, i.e., sum, max@1, max@2 and max@3. Thus ASRMP a m leverages 12 global features while ASRMP b m and ASRMP c m only use 4.\n\nFig. 1 :\n1Linking F1-score for various aggregation strategies.\n\n\nThe Weighted Semantic Relatedness Measure WSRM[9] improves on Ref by not only accounting for the existence of some property between two entities using a Boolean value, but also by weighting how related they are in the [0,1] interval, assuming that the more properties between them, the stronger their relatedness. Formally, WSRM is defined between two entities e i and e j asr, e j ) \u2208 KB; \n0 otherwise. \n\nThe above definition shows that Ref has a clear semantics (R1) and a low computational \ncost (R2) since it can be computed using edge lookups. We however remark that, though \nclear, its semantics is very simple: it does not take into account the various properties \nbetween e i and e j , nor those that e i and e j may have with other entities. Further, Ref \ndoes not allow entities to be related through a property path within the RDF KB, hence \ndoes not meet (R3): they can only be related through a single property, i.e., a single \nedge or triple. \nWSRM(e i , e j ) = \n|{r | (e i , r, e j ) \u2208 KB}| \n\ne \u2208E \n\n|{r | (e i , r , e ) \u2208 KB}| \n\n, \n\n\nTable 1 :\n1Entity relatedness measures in the light of well-foundedness requirements: \u00d7 indicates the requirement is met, while \u223c indicates it is only partially met.\n\n\nDT GB SVM REG KNN DT GB SVM REG KNN DT GB SVM REGApproach \nBaseKB \nYago \nYago+Saturation \nKNN ASRMP1 49.58 47.71 79.59 79.19 80.03 49.64 47.51 79.67 79.75 79.88 50.46 47.58 80.05 79.60 79.94 \nASRMP a \n2 50.00 47.10 79.75 79.82 80.79 49.13 47.02 80.93 79.52 80.71 49.46 46.99 79.09 80.15 80.78 \nASRMP a \n3 50.02 47.24 80.20 80.12 80.60 49.48 46.79 80.36 79.66 80.40 50.33 46.74 79.42 79.62 80.67 \nASRMP a \n\n4 \n\n-\n-\n-\n-\n-50.20 46.78 78.56 80.40 80.98 49.43 46.79 80.51 80.78 81.34 \n\n\n\nTable 3 :\n3in Eq. 12 and Eq. 13 resp.Linking F1-score on the TAC-KBP2017 dataset. Popularity and cosine simi-\nlarity are the local mention-entity scores; the sum (S m ) and max (M \n\n(k) \n\nm ) global features \nare defined \n\n\nExcl Ref ASRMP1 = WSRM ASRMP a 2 ASRMP aT ransE rel \n\n(5) \n\n3 \n\nBaseKB \n15.29 \n1680 13.33 \n13.85 \n20,94 \n418,85 \nYago \n0.84 \n507 0.58 \n0.59 \n6.75 \n9.17 \nYago+Saturation 0.79 \n403 0.57 \n0.69 \n6.14 \n8.60 \n\n\n\nTable 4 :\n4Time in (min.) for different entity relatedness measures. Ref [1,18] considers the Ref entity relatedness measure as defined in Eq 1 -Rel-\n\n\n1 and ASRMP a 2 . From the complexity point of view, relatedness measures are computed offline for a static KB (a given version of Yago or BaseKB). Meanwhile ASRMP x m can easily be computed for lower values of m making it tractable and more suitable for dynamic scenarii where entities are added to or removed from the KB, unlike rel k Excl where top-k path has to be computed, or cosine similarity where the kernel embedding has to be retrained. Tab. 4 shows the computation time for the different entity relatedness measures, including the offline part. For small values of m, which are required in practice, Ref, ASRMP a m , and T ransE have low computation cost, while rel k Excl has high computation cost due to the need to compute top-k best paths. Thus we can conclude that ASRMP a m meets (R2), and more generally that ASRMP x m with x \u2208 {a, b, c} meets (R2). They indeed have similar computation times: most of the time is spent in computing paths of length up to m, while aggregating path scores is very fast.Approach \nAIDA-A AIDA-B Reuters128 RSS-500 \n\nNCEL [5] \n79.0 \n80.0 \n-\n-\nAIDA [13] \n74.3 \n76.5 \n56.6 \n65.5 \nPBoH [11] \n79.4 \n80.0 \n68.3 \n55.3 \nCEL-ASRMP1 =CEL-WSRM 90.6 \n87.7 \n76.6 \n76.4 \nCEL-ASRMP a \n\n2 \n\n93.8 \n91.0 \n77.5 \n76.6 \nCEL-ASRMP a \n\n3 \n\n93.4 \n90.6 \n78.5 \n76.6 \nCEL-ASRMP a \n\n4 \n\n93.1 \n90.3 \n76.6 \n74.6 \n\n\n\nTable 5 :\n5Micro-averaged F1 score for different collective entity linking systems on four standard datasets.\nhttps://gitlab.inria.fr/celvaigh/celasrmp.\nhttps://www.postgresql.org\n\nGraph ranking for collective named entity disambiguation. A Alhelbawy, R Gaizauskas, 52nd Annual Meeting of the Association for Computational Linguistics. Baltimore, Maryland, USA2Alhelbawy, A., Gaizauskas, R.: Graph ranking for collective named entity disambiguation. In: 52nd Annual Meeting of the Association for Computational Linguistics. vol. 2, pp. 75-80. Baltimore, Maryland, USA (2014)\n\nFast and space-efficient entity linking for queries. R Blanco, G Ottaviano, E Meij, 8th ACM International Conference on Web Search and Data Mining. Shanghai, ChinaBlanco, R., Ottaviano, G., Meij, E.: Fast and space-efficient entity linking for queries. In: 8th ACM International Conference on Web Search and Data Mining. pp. 179-188. Shanghai, China (2015)\n\nTranslating embeddings for modeling multi-relational data. A Bordes, N Usunier, A Garcia-Duran, J Weston, O Yakhnenko, 27th Advances in Neural Information Processing Systems. Lake Tahoe, Nevada, USABordes, A., Usunier, N., Garcia-Duran, A., Weston, J., Yakhnenko, O.: Translating embed- dings for modeling multi-relational data. In: 27th Advances in Neural Information Processing Systems. pp. 2787-2795. Lake Tahoe, Nevada, USA (2013)\n\nUsing encyclopedic knowledge for named entity disambiguation. R Bunescu, M Pa\u015fca, 11th Conference of the European Chapter of the Association for Computational Linguistics. Trento, ItalyBunescu, R., Pa\u015fca, M.: Using encyclopedic knowledge for named entity disambiguation. In: 11th Conference of the European Chapter of the Association for Computational Linguistics. pp. 9-16. Trento, Italy (2006)\n\nNeural collective entity linking. Y Cao, L Hou, J Li, Z Liu, 27th International Conference on Computational Linguistics. Santa Fe, New Mexico, USACao, Y., Hou, L., Li, J., Liu, Z.: Neural collective entity linking. In: 27th International Con- ference on Computational Linguistics. pp. 675-686. Santa Fe, New Mexico, USA (2018)\n\nLarge-scale named entity disambiguation based on wikipedia data. S Cucerzan, Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Prague, Czech RepublicCucerzan, S.: Large-scale named entity disambiguation based on wikipedia data. In: Joint Conference on Empirical Methods in Natural Language Processing and Computational Nat- ural Language Learning. pp. 708-716. Prague, Czech Republic (2007)\n\nMathematical aggregation operators and their application to video querying. M Detyniecki, Univ. Paris. 6Ph.D. thesisDetyniecki, M.: Mathematical aggregation operators and their application to video querying. Ph.D. thesis, Univ. Paris 6 (2000)\n\nA joint model for entity analysis: coreference, typing, and linking. G Durrett, D Klein, Transactions of the Association for Computational Linguistics. 2Durrett, G., Klein, D.: A joint model for entity analysis: coreference, typing, and linking. Transactions of the Association for Computational Linguistics 2, 477-490 (2014)\n\nUsing knowledge base semantics in context-aware entity linking. C B El Vaigh, F Goasdou\u00e9, G Gravier, P S\u00e9billot, ACM Symposium on Document Engineering. Berlin, Germany8El Vaigh, C.B., Goasdou\u00e9, F., Gravier, G., S\u00e9billot, P.: Using knowledge base semantics in context-aware entity linking. In: ACM Symposium on Document Engineering 2019. pp. 8:1- 8:10. Berlin, Germany (2019)\n\nCapturing semantic similarity for entity linking with convolutional neural networks. M Francis-Landau, G Durrett, D Klein, 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. San Diego, CA, USAFrancis-Landau, M., Durrett, G., Klein, D.: Capturing semantic similarity for entity linking with convolutional neural networks. In: 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 1256-1261. San Diego, CA, USA (2016)\n\nProbabilistic bag-ofhyperlinks model for entity linking. O E Ganea, M Ganea, A Lucchi, C Eickhoff, T Hofmann, 25th International Conference on World Wide Web. Montr\u00e9al, Qu\u00e9bec, CanadaGanea, O.E., Ganea, M., Lucchi, A., Eickhoff, C., Hofmann, T.: Probabilistic bag-of- hyperlinks model for entity linking. In: 25th International Conference on World Wide Web. pp. 927-938. Montr\u00e9al, Qu\u00e9bec, Canada (2016)\n\nEntity linking via joint encoding of types, descriptions, and context. N Gupta, S Singh, D Roth, 2017 Conference on Empirical Methods in Natural Language Processing. Copenhagen, DenmarkGupta, N., Singh, S., Roth, D.: Entity linking via joint encoding of types, descriptions, and context. In: 2017 Conference on Empirical Methods in Natural Language Processing. pp. 2681-2690. Copenhagen, Denmark (2017)\n\nRobust disambiguation of named entities in text. J Hoffart, M A Yosef, I Bordino, H F\u00fcrstenau, M Pinkal, M Spaniol, B Taneva, S Thater, G Weikum, 2011 Conference on Empirical Methods in Natural Language Processing. Edinburgh, Scotland, UKHoffart, J., Yosef, M.A., Bordino, I., F\u00fcrstenau, H., Pinkal, M., Spaniol, M., Taneva, B., Thater, S., Weikum, G.: Robust disambiguation of named entities in text. In: 2011 Con- ference on Empirical Methods in Natural Language Processing. pp. 782-792. Edinburgh, Scotland, UK (2011)\n\nH Huang, L Heck, H Ji, arXiv:1504.07678Leveraging deep neural networks and knowledge graphs for entity disambiguation. arXiv preprintHuang, H., Heck, L., Ji, H.: Leveraging deep neural networks and knowledge graphs for entity disambiguation. arXiv preprint arXiv:1504.07678 (2015)\n\nPath-based semantic relatedness on linked data and its use to word and entity disambiguation. I Hulpu\u015f, N Prangnawarat, C Hayes, 14th International Semantic Web Conference. Bethlehem, PA, USAHulpu\u015f, I., Prangnawarat, N., Hayes, C.: Path-based semantic relatedness on linked data and its use to word and entity disambiguation. In: 14th International Semantic Web Conference. pp. 442-457. Bethlehem, PA, USA (2015)\n\nOverview of TAC-KBP2017 13 languages entity discovery and linking. H Ji, X Pan, B Zhang, J Nothman, J Mayfield, P Mcnamee, C Costello, Text Analysis Conference. Gaithersburg, Maryland, USAJi, H., Pan, X., Zhang, B., Nothman, J., Mayfield, J., McNamee, P., Costello, C.: Overview of TAC-KBP2017 13 languages entity discovery and linking. In: Text Analysis Conference. Gaithersburg, Maryland, USA (2017)\n\nImproving entity linking by modeling latent relations between mentions. P Le, I Titov, 56th Annual Meeting of the Association for Computational Linguistics. Melbourne, AustraliaLe, P., Titov, I.: Improving entity linking by modeling latent relations between mentions. In: 56th Annual Meeting of the Association for Computational Linguistics. pp. 1595-1604. Melbourne, Australia (2018)\n\nDesign challenges for entity linking. X Ling, S Singh, D S Weld, Transactions of the Association for Computational Linguistics. 3Ling, X., Singh, S., Weld, D.S.: Design challenges for entity linking. Transactions of the Association for Computational Linguistics 3, 315-328 (2015)\n\nA multi-view-based collective entity linking method. M Liu, G Gong, B Qin, T Liu, ACM Transactions on Information Systems. 37229Liu, M., Gong, G., Qin, B., Liu, T.: A multi-view-based collective entity linking method. ACM Transactions on Information Systems 37(2), 23:1-23:29 (2019)\n\nDbpedia spotlight: shedding light on the web of documents. P N Mendes, M Jakob, A Garc\u00eda-Silva, C Bizer, 7th International Conference on Semantic Systems. Graz, AustriaMendes, P.N., Jakob, M., Garc\u00eda-Silva, A., Bizer, C.: Dbpedia spotlight: shedding light on the web of documents. In: 7th International Conference on Semantic Systems. pp. 1-8. Graz, Austria (2011)\n\nDistributed representations of words and phrases and their compositionality. T Mikolov, I Sutskever, K Chen, G S Corrado, J Dean, Advances in Neural Information Processing Systems. Lake Tahoe, Nevada, USAMikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Distributed representations of words and phrases and their compositionality. In: Advances in Neural Information Process- ing Systems. pp. 3111-3119. Lake Tahoe, Nevada, USA (2013)\n\nCombining word and entity embeddings for entity linking. J G Moreno, R Besan\u00e7on, R Beaumont, E Ligozat, A L Rosset, S Tannier, X Grau, B , 14th European Semantic Web Conference. Portoro\u017e, SloveniaMoreno, J.G., Besan\u00e7on, R., Beaumont, R., D'hondt, E., Ligozat, A.L., Rosset, S., Tannier, X., Grau, B.: Combining word and entity embeddings for entity linking. In: 14th European Semantic Web Conference. pp. 337-352. Portoro\u017e, Slovenia (2017)\n\nGlove: global vectors for word representation. J Pennington, R Socher, C Manning, 2014 Conference on Empirical Methods in Natural Language Processing. Doha, QatarPennington, J., Socher, R., Manning, C.: Glove: global vectors for word representation. In: 2014 Conference on Empirical Methods in Natural Language Processing. pp. 1532-1543. Doha, Qatar (2014)\n\nPair-linking for collective entity disambiguation: Two could be better than all. M C Phan, A Sun, Y Tay, J Han, C Li, IEEE Transactions on Knowledge and Data Engineering. Phan, M.C., Sun, A., Tay, Y., Han, J., Li, C.: Pair-linking for collective entity disambiguation: Two could be better than all. IEEE Transactions on Knowledge and Data Engineering (2018)\n\nRdf2vec: Rdf graph embeddings and their applications. P Ristoski, J Rosati, T Di Noia, R De Leone, H Paulheim, Semantic Web. 104Ristoski, P., Rosati, J., Di Noia, T., De Leone, R., Paulheim, H.: Rdf2vec: Rdf graph embed- dings and their applications. Semantic Web 10(4), 721-752 (2019)\n\nLanguage and domain independent entity linking with quantified collective validation. H Wang, J G Zheng, X Ma, P Fox, H Ji, Conference on Empirical Methods in Natural Language Processing. Lisbon, PortugalWang, H., Zheng, J.G., Ma, X., Fox, P., Ji, H.: Language and domain independent entity linking with quantified collective validation. In: 2015 Conference on Empirical Methods in Natural Language Processing. pp. 695-704. Lisbon, Portugal (2015)\n\nJoint learning of the embedding of words and entities for named entity disambiguation. I Yamada, H Shindo, H Takeda, Y Takefuji, 20th SIGNLL Conference on Computational Natural Language Learning. Berlin, GermanyYamada, I., Shindo, H., Takeda, H., Takefuji, Y.: Joint learning of the embedding of words and entities for named entity disambiguation. In: 20th SIGNLL Conference on Computa- tional Natural Language Learning. pp. 250-259. Berlin, Germany (2016)\n\nCollective entity disambiguation with structured gradient tree boosting. Y Yang, O \u0130rsoy, K S Rahman, 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. New Orleans, Louisiana, USAYang, Y.,\u0130rsoy, O., Rahman, K.S.: Collective entity disambiguation with structured gradi- ent tree boosting. In: 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 777-786. New Orleans, Louisiana, USA (2018)\n", "annotations": {"author": "[{\"end\":30,\"start\":4},{\"end\":65,\"start\":31},{\"end\":91,\"start\":66},{\"end\":124,\"start\":92}]", "publisher": null, "author_last_name": null, "author_first_name": null, "author_affiliation": "[{\"end\":29,\"start\":5},{\"end\":64,\"start\":32},{\"end\":90,\"start\":67},{\"end\":123,\"start\":93}]", "title": null, "venue": null, "abstract": null, "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":393,\"start\":390},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":425,\"start\":421},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":672,\"start\":669},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":675,\"start\":672},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":859,\"start\":855},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":862,\"start\":859},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":865,\"start\":862},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":886,\"start\":882},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":889,\"start\":886},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":892,\"start\":889},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":894,\"start\":892},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":897,\"start\":894},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":900,\"start\":897},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3017,\"start\":3014},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3019,\"start\":3017},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3021,\"start\":3019},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3024,\"start\":3021},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3027,\"start\":3024},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3030,\"start\":3027},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3033,\"start\":3030},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3593,\"start\":3589},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3596,\"start\":3593},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3599,\"start\":3596},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3602,\"start\":3599},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3886,\"start\":3883},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3889,\"start\":3886},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4022,\"start\":4019},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4381,\"start\":4377},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5054,\"start\":5051},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5057,\"start\":5054},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5654,\"start\":5651},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6247,\"start\":6244},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6564,\"start\":6560},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7138,\"start\":7137},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7700,\"start\":7697},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7702,\"start\":7700},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7704,\"start\":7702},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7707,\"start\":7704},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7710,\"start\":7707},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7713,\"start\":7710},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7716,\"start\":7713},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8007,\"start\":8004},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8010,\"start\":8007},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8013,\"start\":8010},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8015,\"start\":8013},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8018,\"start\":8015},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8020,\"start\":8018},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8772,\"start\":8769},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8775,\"start\":8772},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9054,\"start\":9051},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9057,\"start\":9054},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9746,\"start\":9742},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11486,\"start\":11483},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11489,\"start\":11486},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11612,\"start\":11608},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11615,\"start\":11612},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11618,\"start\":11615},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11620,\"start\":11618},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11815,\"start\":11812},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11818,\"start\":11815},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":11821,\"start\":11818},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12927,\"start\":12924},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13420,\"start\":13416},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20702,\"start\":20699},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":20705,\"start\":20702},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20708,\"start\":20705},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":20711,\"start\":20708},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":20713,\"start\":20711},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":23141,\"start\":23137},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23881,\"start\":23878},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23884,\"start\":23881},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":23887,\"start\":23884},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":23986,\"start\":23983},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":25089,\"start\":25085},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26967,\"start\":26963},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":31590,\"start\":31586},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":31593,\"start\":31590},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":34011,\"start\":34008},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":34035,\"start\":34031},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":34037,\"start\":34035},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":34049,\"start\":34046},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":34052,\"start\":34049},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":34602,\"start\":34598},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":34616,\"start\":34613},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":34761,\"start\":34757},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":34825,\"start\":34822},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":35806,\"start\":35803},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":35818,\"start\":35815},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":35828,\"start\":35824},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":37024,\"start\":37021},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":37035,\"start\":37031},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":37046,\"start\":37042},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":37063,\"start\":37060},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":37158,\"start\":37155},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":38548,\"start\":38545},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":38605,\"start\":38601},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":40411,\"start\":40408},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":42647,\"start\":42646}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":40295,\"start\":39868},{\"attributes\":{\"id\":\"fig_1\"},\"end\":40359,\"start\":40296},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":41411,\"start\":40360},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":41578,\"start\":41412},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":42062,\"start\":41579},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":42285,\"start\":42063},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42492,\"start\":42286},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":42643,\"start\":42493},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":43979,\"start\":42644},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":44090,\"start\":43980}]", "paragraph": "[{\"end\":676,\"start\":219},{\"end\":1655,\"start\":678},{\"end\":2862,\"start\":1657},{\"end\":5422,\"start\":2864},{\"end\":7540,\"start\":5424},{\"end\":7964,\"start\":7557},{\"end\":8824,\"start\":7966},{\"end\":9384,\"start\":8860},{\"end\":10134,\"start\":9386},{\"end\":10487,\"start\":10476},{\"end\":10586,\"start\":10492},{\"end\":10809,\"start\":10639},{\"end\":10957,\"start\":10811},{\"end\":12112,\"start\":10962},{\"end\":12397,\"start\":12114},{\"end\":12928,\"start\":12454},{\"end\":13672,\"start\":12930},{\"end\":14676,\"start\":13674},{\"end\":14966,\"start\":14678},{\"end\":15691,\"start\":15045},{\"end\":15851,\"start\":15693},{\"end\":16320,\"start\":15930},{\"end\":16725,\"start\":16407},{\"end\":16782,\"start\":16727},{\"end\":17194,\"start\":16878},{\"end\":18240,\"start\":17196},{\"end\":18970,\"start\":18242},{\"end\":19305,\"start\":18972},{\"end\":19401,\"start\":19353},{\"end\":19475,\"start\":19455},{\"end\":19512,\"start\":19511},{\"end\":19872,\"start\":19514},{\"end\":20592,\"start\":19916},{\"end\":21195,\"start\":20594},{\"end\":21408,\"start\":21197},{\"end\":22650,\"start\":21427},{\"end\":22810,\"start\":22652},{\"end\":23695,\"start\":22842},{\"end\":24844,\"start\":23727},{\"end\":25146,\"start\":24846},{\"end\":25785,\"start\":25148},{\"end\":25869,\"start\":25839},{\"end\":26357,\"start\":25935},{\"end\":27513,\"start\":26373},{\"end\":27959,\"start\":27515},{\"end\":28511,\"start\":27986},{\"end\":29490,\"start\":28513},{\"end\":29941,\"start\":29492},{\"end\":30678,\"start\":29979},{\"end\":31189,\"start\":30680},{\"end\":31896,\"start\":31215},{\"end\":33782,\"start\":31933},{\"end\":34372,\"start\":33829},{\"end\":34750,\"start\":34374},{\"end\":35009,\"start\":34752},{\"end\":35159,\"start\":35011},{\"end\":35927,\"start\":35161},{\"end\":36833,\"start\":35929},{\"end\":37937,\"start\":36874},{\"end\":38865,\"start\":37953},{\"end\":39867,\"start\":38867}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8859,\"start\":8825},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10198,\"start\":10135},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10311,\"start\":10198},{\"attributes\":{\"id\":\"formula_4\"},\"end\":10475,\"start\":10311},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10491,\"start\":10488},{\"attributes\":{\"id\":\"formula_6\"},\"end\":10638,\"start\":10587},{\"attributes\":{\"id\":\"formula_7\"},\"end\":10961,\"start\":10958},{\"attributes\":{\"id\":\"formula_8\"},\"end\":15044,\"start\":14967},{\"attributes\":{\"id\":\"formula_9\"},\"end\":15929,\"start\":15852},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16406,\"start\":16321},{\"attributes\":{\"id\":\"formula_11\"},\"end\":16877,\"start\":16783},{\"attributes\":{\"id\":\"formula_12\"},\"end\":19352,\"start\":19306},{\"attributes\":{\"id\":\"formula_13\"},\"end\":19454,\"start\":19402},{\"attributes\":{\"id\":\"formula_14\"},\"end\":19510,\"start\":19476},{\"attributes\":{\"id\":\"formula_16\"},\"end\":25838,\"start\":25786},{\"attributes\":{\"id\":\"formula_17\"},\"end\":25934,\"start\":25870}]", "table_ref": "[{\"end\":30946,\"start\":30939}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":217,\"start\":205},{\"attributes\":{\"n\":\"2\"},\"end\":7555,\"start\":7543},{\"attributes\":{\"n\":\"3\"},\"end\":12452,\"start\":12400},{\"attributes\":{\"n\":\"4\"},\"end\":19914,\"start\":19875},{\"attributes\":{\"n\":\"4.1\"},\"end\":21425,\"start\":21411},{\"attributes\":{\"n\":\"4.2\"},\"end\":22840,\"start\":22813},{\"attributes\":{\"n\":\"4.3\"},\"end\":23725,\"start\":23698},{\"attributes\":{\"n\":\"5\"},\"end\":26371,\"start\":26360},{\"attributes\":{\"n\":\"5.1\"},\"end\":27984,\"start\":27962},{\"attributes\":{\"n\":\"5.2\"},\"end\":29977,\"start\":29944},{\"attributes\":{\"n\":\"5.3\"},\"end\":31213,\"start\":31192},{\"attributes\":{\"n\":\"5.4\"},\"end\":31931,\"start\":31899},{\"attributes\":{\"n\":\"5.5\"},\"end\":33827,\"start\":33785},{\"attributes\":{\"n\":\"5.6\"},\"end\":36872,\"start\":36836},{\"attributes\":{\"n\":\"6\"},\"end\":37951,\"start\":37940},{\"end\":39874,\"start\":39869},{\"end\":40305,\"start\":40297},{\"end\":41422,\"start\":41413},{\"end\":42073,\"start\":42064},{\"end\":42503,\"start\":42494},{\"end\":43990,\"start\":43981}]", "table": "[{\"end\":41411,\"start\":40737},{\"end\":42062,\"start\":41630},{\"end\":42285,\"start\":42101},{\"end\":42492,\"start\":42328},{\"end\":42643,\"start\":42642},{\"end\":43979,\"start\":43666}]", "figure_caption": "[{\"end\":40295,\"start\":39876},{\"end\":40359,\"start\":40307},{\"end\":40737,\"start\":40362},{\"end\":41578,\"start\":41424},{\"end\":41630,\"start\":41581},{\"end\":42101,\"start\":42075},{\"end\":42328,\"start\":42288},{\"end\":42642,\"start\":42505},{\"end\":43666,\"start\":42646},{\"end\":44090,\"start\":43992}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":32017,\"start\":32011},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":32512,\"start\":32505},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":32546,\"start\":32539},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":33042,\"start\":33033},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":33072,\"start\":33064},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":33175,\"start\":33166},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":33285,\"start\":33266},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":36676,\"start\":36648}]", "bib_author_first_name": "[{\"end\":44221,\"start\":44220},{\"end\":44234,\"start\":44233},{\"end\":44611,\"start\":44610},{\"end\":44621,\"start\":44620},{\"end\":44634,\"start\":44633},{\"end\":44975,\"start\":44974},{\"end\":44985,\"start\":44984},{\"end\":44996,\"start\":44995},{\"end\":45012,\"start\":45011},{\"end\":45022,\"start\":45021},{\"end\":45414,\"start\":45413},{\"end\":45425,\"start\":45424},{\"end\":45783,\"start\":45782},{\"end\":45790,\"start\":45789},{\"end\":45797,\"start\":45796},{\"end\":45803,\"start\":45802},{\"end\":46142,\"start\":46141},{\"end\":46609,\"start\":46608},{\"end\":46846,\"start\":46845},{\"end\":46857,\"start\":46856},{\"end\":47168,\"start\":47167},{\"end\":47170,\"start\":47169},{\"end\":47182,\"start\":47181},{\"end\":47194,\"start\":47193},{\"end\":47205,\"start\":47204},{\"end\":47565,\"start\":47564},{\"end\":47583,\"start\":47582},{\"end\":47594,\"start\":47593},{\"end\":48117,\"start\":48116},{\"end\":48119,\"start\":48118},{\"end\":48128,\"start\":48127},{\"end\":48137,\"start\":48136},{\"end\":48147,\"start\":48146},{\"end\":48159,\"start\":48158},{\"end\":48535,\"start\":48534},{\"end\":48544,\"start\":48543},{\"end\":48553,\"start\":48552},{\"end\":48917,\"start\":48916},{\"end\":48928,\"start\":48927},{\"end\":48930,\"start\":48929},{\"end\":48939,\"start\":48938},{\"end\":48950,\"start\":48949},{\"end\":48963,\"start\":48962},{\"end\":48973,\"start\":48972},{\"end\":48984,\"start\":48983},{\"end\":48994,\"start\":48993},{\"end\":49004,\"start\":49003},{\"end\":49390,\"start\":49389},{\"end\":49399,\"start\":49398},{\"end\":49407,\"start\":49406},{\"end\":49766,\"start\":49765},{\"end\":49776,\"start\":49775},{\"end\":49792,\"start\":49791},{\"end\":50153,\"start\":50152},{\"end\":50159,\"start\":50158},{\"end\":50166,\"start\":50165},{\"end\":50175,\"start\":50174},{\"end\":50186,\"start\":50185},{\"end\":50198,\"start\":50197},{\"end\":50209,\"start\":50208},{\"end\":50561,\"start\":50560},{\"end\":50567,\"start\":50566},{\"end\":50913,\"start\":50912},{\"end\":50921,\"start\":50920},{\"end\":50930,\"start\":50929},{\"end\":50932,\"start\":50931},{\"end\":51209,\"start\":51208},{\"end\":51216,\"start\":51215},{\"end\":51224,\"start\":51223},{\"end\":51231,\"start\":51230},{\"end\":51499,\"start\":51498},{\"end\":51501,\"start\":51500},{\"end\":51511,\"start\":51510},{\"end\":51520,\"start\":51519},{\"end\":51536,\"start\":51535},{\"end\":51883,\"start\":51882},{\"end\":51894,\"start\":51893},{\"end\":51907,\"start\":51906},{\"end\":51915,\"start\":51914},{\"end\":51917,\"start\":51916},{\"end\":51928,\"start\":51927},{\"end\":52311,\"start\":52310},{\"end\":52313,\"start\":52312},{\"end\":52323,\"start\":52322},{\"end\":52335,\"start\":52334},{\"end\":52347,\"start\":52346},{\"end\":52358,\"start\":52357},{\"end\":52360,\"start\":52359},{\"end\":52370,\"start\":52369},{\"end\":52381,\"start\":52380},{\"end\":52389,\"start\":52388},{\"end\":52742,\"start\":52741},{\"end\":52756,\"start\":52755},{\"end\":52766,\"start\":52765},{\"end\":53134,\"start\":53133},{\"end\":53136,\"start\":53135},{\"end\":53144,\"start\":53143},{\"end\":53151,\"start\":53150},{\"end\":53158,\"start\":53157},{\"end\":53165,\"start\":53164},{\"end\":53466,\"start\":53465},{\"end\":53478,\"start\":53477},{\"end\":53488,\"start\":53487},{\"end\":53499,\"start\":53498},{\"end\":53511,\"start\":53510},{\"end\":53785,\"start\":53784},{\"end\":53793,\"start\":53792},{\"end\":53795,\"start\":53794},{\"end\":53804,\"start\":53803},{\"end\":53810,\"start\":53809},{\"end\":53817,\"start\":53816},{\"end\":54235,\"start\":54234},{\"end\":54245,\"start\":54244},{\"end\":54255,\"start\":54254},{\"end\":54265,\"start\":54264},{\"end\":54679,\"start\":54678},{\"end\":54687,\"start\":54686},{\"end\":54696,\"start\":54695},{\"end\":54698,\"start\":54697}]", "bib_author_last_name": "[{\"end\":44231,\"start\":44222},{\"end\":44245,\"start\":44235},{\"end\":44618,\"start\":44612},{\"end\":44631,\"start\":44622},{\"end\":44639,\"start\":44635},{\"end\":44982,\"start\":44976},{\"end\":44993,\"start\":44986},{\"end\":45009,\"start\":44997},{\"end\":45019,\"start\":45013},{\"end\":45032,\"start\":45023},{\"end\":45422,\"start\":45415},{\"end\":45431,\"start\":45426},{\"end\":45787,\"start\":45784},{\"end\":45794,\"start\":45791},{\"end\":45800,\"start\":45798},{\"end\":45807,\"start\":45804},{\"end\":46151,\"start\":46143},{\"end\":46620,\"start\":46610},{\"end\":46854,\"start\":46847},{\"end\":46863,\"start\":46858},{\"end\":47179,\"start\":47171},{\"end\":47191,\"start\":47183},{\"end\":47202,\"start\":47195},{\"end\":47214,\"start\":47206},{\"end\":47580,\"start\":47566},{\"end\":47591,\"start\":47584},{\"end\":47600,\"start\":47595},{\"end\":48125,\"start\":48120},{\"end\":48134,\"start\":48129},{\"end\":48144,\"start\":48138},{\"end\":48156,\"start\":48148},{\"end\":48167,\"start\":48160},{\"end\":48541,\"start\":48536},{\"end\":48550,\"start\":48545},{\"end\":48558,\"start\":48554},{\"end\":48925,\"start\":48918},{\"end\":48936,\"start\":48931},{\"end\":48947,\"start\":48940},{\"end\":48960,\"start\":48951},{\"end\":48970,\"start\":48964},{\"end\":48981,\"start\":48974},{\"end\":48991,\"start\":48985},{\"end\":49001,\"start\":48995},{\"end\":49011,\"start\":49005},{\"end\":49396,\"start\":49391},{\"end\":49404,\"start\":49400},{\"end\":49410,\"start\":49408},{\"end\":49773,\"start\":49767},{\"end\":49789,\"start\":49777},{\"end\":49798,\"start\":49793},{\"end\":50156,\"start\":50154},{\"end\":50163,\"start\":50160},{\"end\":50172,\"start\":50167},{\"end\":50183,\"start\":50176},{\"end\":50195,\"start\":50187},{\"end\":50206,\"start\":50199},{\"end\":50218,\"start\":50210},{\"end\":50564,\"start\":50562},{\"end\":50573,\"start\":50568},{\"end\":50918,\"start\":50914},{\"end\":50927,\"start\":50922},{\"end\":50937,\"start\":50933},{\"end\":51213,\"start\":51210},{\"end\":51221,\"start\":51217},{\"end\":51228,\"start\":51225},{\"end\":51235,\"start\":51232},{\"end\":51508,\"start\":51502},{\"end\":51517,\"start\":51512},{\"end\":51533,\"start\":51521},{\"end\":51542,\"start\":51537},{\"end\":51891,\"start\":51884},{\"end\":51904,\"start\":51895},{\"end\":51912,\"start\":51908},{\"end\":51925,\"start\":51918},{\"end\":51933,\"start\":51929},{\"end\":52320,\"start\":52314},{\"end\":52332,\"start\":52324},{\"end\":52344,\"start\":52336},{\"end\":52355,\"start\":52348},{\"end\":52367,\"start\":52361},{\"end\":52378,\"start\":52371},{\"end\":52386,\"start\":52382},{\"end\":52753,\"start\":52743},{\"end\":52763,\"start\":52757},{\"end\":52774,\"start\":52767},{\"end\":53141,\"start\":53137},{\"end\":53148,\"start\":53145},{\"end\":53155,\"start\":53152},{\"end\":53162,\"start\":53159},{\"end\":53168,\"start\":53166},{\"end\":53475,\"start\":53467},{\"end\":53485,\"start\":53479},{\"end\":53496,\"start\":53489},{\"end\":53508,\"start\":53500},{\"end\":53520,\"start\":53512},{\"end\":53790,\"start\":53786},{\"end\":53801,\"start\":53796},{\"end\":53807,\"start\":53805},{\"end\":53814,\"start\":53811},{\"end\":53820,\"start\":53818},{\"end\":54242,\"start\":54236},{\"end\":54252,\"start\":54246},{\"end\":54262,\"start\":54256},{\"end\":54274,\"start\":54266},{\"end\":54684,\"start\":54680},{\"end\":54693,\"start\":54688},{\"end\":54705,\"start\":54699}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":17826594},\"end\":44555,\"start\":44162},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":10057407},\"end\":44913,\"start\":44557},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":14941970},\"end\":45349,\"start\":44915},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":588986},\"end\":45746,\"start\":45351},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":52009840},\"end\":46074,\"start\":45748},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":7577640},\"end\":46530,\"start\":46076},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":59674493},\"end\":46774,\"start\":46532},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":7499734},\"end\":47101,\"start\":46776},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":198310692},\"end\":47477,\"start\":47103},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":2162860},\"end\":48057,\"start\":47479},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":2015967},\"end\":48461,\"start\":48059},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":28784495},\"end\":48865,\"start\":48463},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":6216506},\"end\":49387,\"start\":48867},{\"attributes\":{\"doi\":\"arXiv:1504.07678\",\"id\":\"b13\"},\"end\":49669,\"start\":49389},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":17742314},\"end\":50083,\"start\":49671},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":31666442},\"end\":50486,\"start\":50085},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":13747961},\"end\":50872,\"start\":50488},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":6737909},\"end\":51153,\"start\":50874},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":67871752},\"end\":51437,\"start\":51155},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":8722811},\"end\":51803,\"start\":51439},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":16447573},\"end\":52251,\"start\":51805},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":4846735},\"end\":52692,\"start\":52253},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":1957433},\"end\":53050,\"start\":52694},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":3616748},\"end\":53409,\"start\":53052},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":150293718},\"end\":53696,\"start\":53411},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":2443837},\"end\":54145,\"start\":53698},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":5267356},\"end\":54603,\"start\":54147},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":3587087},\"end\":55144,\"start\":54605}]", "bib_title": "[{\"end\":44218,\"start\":44162},{\"end\":44608,\"start\":44557},{\"end\":44972,\"start\":44915},{\"end\":45411,\"start\":45351},{\"end\":45780,\"start\":45748},{\"end\":46139,\"start\":46076},{\"end\":46606,\"start\":46532},{\"end\":46843,\"start\":46776},{\"end\":47165,\"start\":47103},{\"end\":47562,\"start\":47479},{\"end\":48114,\"start\":48059},{\"end\":48532,\"start\":48463},{\"end\":48914,\"start\":48867},{\"end\":49763,\"start\":49671},{\"end\":50150,\"start\":50085},{\"end\":50558,\"start\":50488},{\"end\":50910,\"start\":50874},{\"end\":51206,\"start\":51155},{\"end\":51496,\"start\":51439},{\"end\":51880,\"start\":51805},{\"end\":52308,\"start\":52253},{\"end\":52739,\"start\":52694},{\"end\":53131,\"start\":53052},{\"end\":53463,\"start\":53411},{\"end\":53782,\"start\":53698},{\"end\":54232,\"start\":54147},{\"end\":54676,\"start\":54605}]", "bib_author": "[{\"end\":44233,\"start\":44220},{\"end\":44247,\"start\":44233},{\"end\":44620,\"start\":44610},{\"end\":44633,\"start\":44620},{\"end\":44641,\"start\":44633},{\"end\":44984,\"start\":44974},{\"end\":44995,\"start\":44984},{\"end\":45011,\"start\":44995},{\"end\":45021,\"start\":45011},{\"end\":45034,\"start\":45021},{\"end\":45424,\"start\":45413},{\"end\":45433,\"start\":45424},{\"end\":45789,\"start\":45782},{\"end\":45796,\"start\":45789},{\"end\":45802,\"start\":45796},{\"end\":45809,\"start\":45802},{\"end\":46153,\"start\":46141},{\"end\":46622,\"start\":46608},{\"end\":46856,\"start\":46845},{\"end\":46865,\"start\":46856},{\"end\":47181,\"start\":47167},{\"end\":47193,\"start\":47181},{\"end\":47204,\"start\":47193},{\"end\":47216,\"start\":47204},{\"end\":47582,\"start\":47564},{\"end\":47593,\"start\":47582},{\"end\":47602,\"start\":47593},{\"end\":48127,\"start\":48116},{\"end\":48136,\"start\":48127},{\"end\":48146,\"start\":48136},{\"end\":48158,\"start\":48146},{\"end\":48169,\"start\":48158},{\"end\":48543,\"start\":48534},{\"end\":48552,\"start\":48543},{\"end\":48560,\"start\":48552},{\"end\":48927,\"start\":48916},{\"end\":48938,\"start\":48927},{\"end\":48949,\"start\":48938},{\"end\":48962,\"start\":48949},{\"end\":48972,\"start\":48962},{\"end\":48983,\"start\":48972},{\"end\":48993,\"start\":48983},{\"end\":49003,\"start\":48993},{\"end\":49013,\"start\":49003},{\"end\":49398,\"start\":49389},{\"end\":49406,\"start\":49398},{\"end\":49412,\"start\":49406},{\"end\":49775,\"start\":49765},{\"end\":49791,\"start\":49775},{\"end\":49800,\"start\":49791},{\"end\":50158,\"start\":50152},{\"end\":50165,\"start\":50158},{\"end\":50174,\"start\":50165},{\"end\":50185,\"start\":50174},{\"end\":50197,\"start\":50185},{\"end\":50208,\"start\":50197},{\"end\":50220,\"start\":50208},{\"end\":50566,\"start\":50560},{\"end\":50575,\"start\":50566},{\"end\":50920,\"start\":50912},{\"end\":50929,\"start\":50920},{\"end\":50939,\"start\":50929},{\"end\":51215,\"start\":51208},{\"end\":51223,\"start\":51215},{\"end\":51230,\"start\":51223},{\"end\":51237,\"start\":51230},{\"end\":51510,\"start\":51498},{\"end\":51519,\"start\":51510},{\"end\":51535,\"start\":51519},{\"end\":51544,\"start\":51535},{\"end\":51893,\"start\":51882},{\"end\":51906,\"start\":51893},{\"end\":51914,\"start\":51906},{\"end\":51927,\"start\":51914},{\"end\":51935,\"start\":51927},{\"end\":52322,\"start\":52310},{\"end\":52334,\"start\":52322},{\"end\":52346,\"start\":52334},{\"end\":52357,\"start\":52346},{\"end\":52369,\"start\":52357},{\"end\":52380,\"start\":52369},{\"end\":52388,\"start\":52380},{\"end\":52392,\"start\":52388},{\"end\":52755,\"start\":52741},{\"end\":52765,\"start\":52755},{\"end\":52776,\"start\":52765},{\"end\":53143,\"start\":53133},{\"end\":53150,\"start\":53143},{\"end\":53157,\"start\":53150},{\"end\":53164,\"start\":53157},{\"end\":53170,\"start\":53164},{\"end\":53477,\"start\":53465},{\"end\":53487,\"start\":53477},{\"end\":53498,\"start\":53487},{\"end\":53510,\"start\":53498},{\"end\":53522,\"start\":53510},{\"end\":53792,\"start\":53784},{\"end\":53803,\"start\":53792},{\"end\":53809,\"start\":53803},{\"end\":53816,\"start\":53809},{\"end\":53822,\"start\":53816},{\"end\":54244,\"start\":54234},{\"end\":54254,\"start\":54244},{\"end\":54264,\"start\":54254},{\"end\":54276,\"start\":54264},{\"end\":54686,\"start\":54678},{\"end\":54695,\"start\":54686},{\"end\":54707,\"start\":54695}]", "bib_venue": "[{\"end\":44341,\"start\":44317},{\"end\":44720,\"start\":44705},{\"end\":45113,\"start\":45090},{\"end\":45536,\"start\":45523},{\"end\":45894,\"start\":45869},{\"end\":46289,\"start\":46267},{\"end\":47270,\"start\":47255},{\"end\":47752,\"start\":47734},{\"end\":48242,\"start\":48218},{\"end\":48648,\"start\":48629},{\"end\":49105,\"start\":49082},{\"end\":49862,\"start\":49844},{\"end\":50273,\"start\":50246},{\"end\":50665,\"start\":50645},{\"end\":51607,\"start\":51594},{\"end\":52009,\"start\":51986},{\"end\":52449,\"start\":52431},{\"end\":52856,\"start\":52845},{\"end\":53902,\"start\":53886},{\"end\":54358,\"start\":54343},{\"end\":54859,\"start\":54832},{\"end\":44315,\"start\":44247},{\"end\":44703,\"start\":44641},{\"end\":45088,\"start\":45034},{\"end\":45521,\"start\":45433},{\"end\":45867,\"start\":45809},{\"end\":46265,\"start\":46153},{\"end\":46633,\"start\":46622},{\"end\":46926,\"start\":46865},{\"end\":47253,\"start\":47216},{\"end\":47732,\"start\":47602},{\"end\":48216,\"start\":48169},{\"end\":48627,\"start\":48560},{\"end\":49080,\"start\":49013},{\"end\":49506,\"start\":49428},{\"end\":49842,\"start\":49800},{\"end\":50244,\"start\":50220},{\"end\":50643,\"start\":50575},{\"end\":51000,\"start\":50939},{\"end\":51276,\"start\":51237},{\"end\":51592,\"start\":51544},{\"end\":51984,\"start\":51935},{\"end\":52429,\"start\":52392},{\"end\":52843,\"start\":52776},{\"end\":53221,\"start\":53170},{\"end\":53534,\"start\":53522},{\"end\":53884,\"start\":53822},{\"end\":54341,\"start\":54276},{\"end\":54830,\"start\":54707}]"}}}, "year": 2023, "month": 12, "day": 17}