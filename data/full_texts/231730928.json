{"id": 231730928, "updated": "2022-01-15 12:23:30.752", "metadata": {"title": "HyperRec: Efficient Recommender Systems with Hyperdimensional Computing", "authors": "[{\"middle\":[],\"last\":\"Guo\",\"first\":\"Yunhui\"},{\"middle\":[],\"last\":\"Imani\",\"first\":\"Mohsen\"},{\"middle\":[],\"last\":\"Kang\",\"first\":\"Jaeyoung\"},{\"middle\":[],\"last\":\"Salamat\",\"first\":\"Sahand\"},{\"middle\":[],\"last\":\"Morris\",\"first\":\"Justin\"},{\"middle\":[],\"last\":\"Aksanli\",\"first\":\"Baris\"},{\"middle\":[],\"last\":\"Kim\",\"first\":\"Yeseong\"},{\"middle\":[],\"last\":\"Rosing\",\"first\":\"Tajana\"}]", "venue": "2021 26th Asia and South Pacific Design Automation Conference (ASP-DAC)", "journal": "2021 26th Asia and South Pacific Design Automation Conference (ASP-DAC)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Recommender systems are important tools for many commercial applications such as online shopping websites. There are several issues that make the recommendation task very challenging in practice. The first is that an efficient and compact representation is needed to represent users, items and relations. The second is-sue is that the online markets are changing dynamically, it is thus important that the recommendation algorithm is suitable for fast updates and hardware acceleration. In this paper, we propose a new hardware-friendly recommendation algorithm based on Hyperdimensional Computing, called HyperRec. Unlike existing solutions which leverages floating-point numbers for the data representation, in HyperRec, users and items are modeled with binary vectors in a high dimension. The binary representation enables to perform the reasoning process of the proposed algorithm only using Boolean operations, which is efficient on various computing platforms and suitable for hardware acceleration. In this work, we show how to utilize GPU and FPGA to accelerate the proposed HyperRec. When compared with the state-of-the-art methods for rating prediction, the CPU-based HyperRec implementation is 13.75\u00d7 faster and consumes 87% less memory, while decreasing the mean squared error (MSE) for the prediction by as much as 31.84%. Our FPGA implementation is on average 67.0\u00d7 faster and has 6.9\u00d7 higher energy efficient as compared to CPU. Our GPU implementation further achieves on average 3.1\u00d7 speedup as compared to FPGA, while providing only 1.2\u00d7 lower energy efficiency.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/aspdac/GuoIKSMAKR21", "doi": "10.1145/3394885.3431553"}}, "content": {"source": {"pdf_hash": "e0caf058bb85ff2fc782f8b6c5f7b56eb29e02f3", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://dl.acm.org/doi/pdf/10.1145/3394885.3431553", "status": "BRONZE"}}, "grobid": {"id": "5bc375986d9f11dac5c0697f39d3210741574d4f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/e0caf058bb85ff2fc782f8b6c5f7b56eb29e02f3.txt", "contents": "\nHyperRec: Efficient Recommender Systems with Hyperdimensional Computing\nJanuary 18-21, 2021. January 18-21, 2021\n\nYunhui Guo \nUniversity of California\nIrvine\n\nMohsen Imani m.imanii@uci.edu \nSan Diego State University\n\n\nJaeyoung Kang \nUniversity of California\nIrvine\n\nSahand Salamat \nUniversity of California\nIrvine\n\nJustin Morris \nUniversity of California\nIrvine\n\nBaris Aksanli baksanli@sdsu.edu \nDGIST 4\n\n\nYeseong Kim yeseongkim@dgist.ac.kr \nTajana Rosing tajana@ucsd.edu \nUniversity of California\nIrvine\n\nYunhui Guo \nUniversity of California\nIrvine\n\nMohsen Imani \nSan Diego State University\n\n\nJaeyoung Kang \nUniversity of California\nIrvine\n\nSahand Salamat \nUniversity of California\nIrvine\n\nJustin Morris \nUniversity of California\nIrvine\n\nBaris Aksanli \nDGIST 4\n\n\nYeseong Kim \nTajana Rosing \n\nUniversity of California\nSan Diego\n\nHyperRec: Efficient Recommender Systems with Hyperdimensional Computing\n\nHyperRec: Efficient Recommender Systems with Hyperdimensional Computing\nTokyo, JapanJanuary 18-21, 2021. January 18-21, 202110.1145/3394885.3431553ACM Reference Format:, Japan. ACM, New York, NY, USA, 6 pages. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).CCS CONCEPTS \u2022 Computer systems organization \u2192 Embedded systemsRe- dundancyRobotics\u2022 Networks \u2192 Network reliability\nRecommender systems are important tools for many commercial applications such as online shopping websites. There are several issues that make the recommendation task very challenging in practice. The first is that an efficient and compact representation is needed to represent users, items and relations. The second issue is that the online markets are changing dynamically, it is thus important that the recommendation algorithm is suitable for fast updates and hardware acceleration. In this paper, we propose a new hardware-friendly recommendation algorithm based on Hyperdimensional Computing, called HyperRec. Unlike existing solutions which leverages floating-point numbers for the data representation, in HyperRec, users and items are modeled with binary vectors in a high dimension. The binary representation enables to perform the reasoning process of the proposed algorithm only using Boolean operations, which is efficient on various computing platforms and suitable for hardware acceleration. In this work, we show how to utilize GPU and FPGA to accelerate the proposed HyperRec. When compared with the state-of-the-art methods for rating prediction, the CPU-based HyperRec implementation is 13.75\u00d7 faster and consumes 87% less memory, while decreasing the mean squared error (MSE) for the prediction by as much as 31.84%. Our FPGA implementation is on average 67.0\u00d7 faster and has 6.9\u00d7 higher energy efficient as compared to CPU. Our GPU implementation further achieves on average 3.1\u00d7 speedup as compared to FPGA, while providing only 1.2\u00d7 lower energy efficiency.\n\nINTRODUCTION\n\nMany commercial applications such as online shopping websites adopt recommender systems to present products that users will potentially purchase. A fundamental challenge of the recommendation algorithms [1] is to understand and leverage users' preferences for accurate product recommendation by assimilating the large volume of products. Traditional recommender systems [15,16] typically leverage low-dimensional vectors with floating-point numbers to represent users and items. There are several drawbacks of this approach. First, the user and item information would not be fully exploited due to the low dimensionality of the encoding (embedding) vectors, and it is unclear how to choose a suitable dimensionality. In addition, since there is a significant growth in the number of users and items, the traditional approaches consume a large amount of memory to represent user and item vectors with the full-precision numbers. This representation is thereby hard to scale and also unsuitable for hardware acceleration. Thus, it is important to rethink and develop an efficient representation for recommendation systems in order to achieve fast processing and low resource consumption without compromising prediction quality.\n\nIn this paper, we develop the first recommendation solution, called HyperRec, which only relies on binary representation and Boolean operations. Although our representation for the users and items is based on binary, i.e., lower precision than the existing methods, it can preserve required information in the encoding vectors using a high dimensionality, e.g., = 10, 000. We design HyperRec using the principle of Hyperdimensional (HD) Computing [12,13] which is a brain-inspired computing model. In HyperRec, we encode users, items and ratings using hyperdimensional binary vectors, called hypervectors. We represent the relation between users and items via the binding and bundling operation in HD computing. The recommendation phase is based on the the \"nearest neighbor\" principle [4] via Hamming distance.\n\nIn summary, we show that our proposed HyperRec has the following advantages:\n\n(1) Our evaluation on several large datasets, such as 's datasets, demonstrate that the proposed algorithm is able to improve the recommedataion quality. For example, compared with various previous work on recommender systems, HyperRec decreases the mean squared error (MSE) by as much as 31.84%.\n\n(2) When implementing on CPU, HyperRec is 13.75\u00d7 faster and reduces the memory consumption by about 87%, as compared with the best performed recommendation algorithm based on SVD++. (3) Our FPGA implementation is on average 67.0\u00d7 faster and 6.9\u00d7 higher energy efficient as compared to CPU. Our GPU implementation further achieves on average 3.1\u00d7 speedup as compared to FPGA, while providing only 1.2\u00d7 lower energy efficiency.\n\n\nRELATED WORK\n\nRecommender systems have drawn much attention from a variety of communities. The emergence of the e-commerce promotes the development of recommendation algorithms. Various approaches have been proposed to provide better product recommendations. Among them, collaborative filtering [6] is a leading technique which recommends the user with products by analyzing similar users' records. We can roughly classify the collaborative filtering algorithms into two categories: neighbor-based methods and latent-factor methods.\n\nNeighbor-based methods [1,26] identify similar users and items for recommendation. Latent-factor models [15,16] use vector representation to encode users and items, and approximate the rating that a user will give to an item by the inner product of the latent vectors.\n\nTo give the latent vectors probabilistic interpretations, Gaussian matrix factorization models [21] were proposed to handle extremely large datasets and to deal with cold-start users and items. Neural networks-based recommender systems [2,9] are proposed recently as generalization of the traditional matrix factorization. Although neural networks have achieved great success in many other areas, recent work [3] pointed out that it is not clear that the neural networks-based recommendation algorithms can really advance the field of recommender systems due to the model complexity. Although such various algorithms have been proposed, to the best of the authors' knowledge, there are no recommendation algorithms that are designed specifically for high efficiency to enable ease of hardware acceleration. There are few research work to accelerate existing algorithms, e.g., an FPGA design for a neighborhood-based collaborative filtering [19]; given the massive amount of data, it is critical to develop new recommender systems in a hardware friendly manner.\n\n\nPRELIMINARY\n\nThe proposed algorithm is based on the principle of Hyperdimensional (HD) computing [13]. HD computing [14] is a brain-inspired computing model in which entities are represented as hyperdimensional binary vectors. Hyperdimensional computing has been used in language recognition [10,11,22], prediction from multimodal sensor fusion [24,25], hand gesture recognition [22] and brain-computer interfaces [23]. HD computing is inspired by the understanding that the human brain is more capable of recognizing patterns than calculating with numbers. This fact motivates us to simulate the process of brain's computing with points in high-dimensional space [14]. These points can effectively model the neural activity patterns of the brain's circuits. This capability makes hyperdimensional vectors very helpful in many real-world tasks. The information that contained in hyperdimensional vectors is spread uniformly among all its components in a holistic manner so that no component is more responsible to store any piece of information than another. We can easily construct a new hypervector based on some old ones using vector or Boolean operations. Such as binding that forms a new hypervector which associates two base hypervectors, and bundling that combines several hypervectors into a single composite hypervector. We introduce several arithmetic operations that are designed for hypervectors.\n\n\u2022 Component-wise : we can bind two hypervectors and by component-wise and denote the operation as \u2297 . The result of this operation is a new hypervector that is dissimilar to its constituents (i.e., ( \u2297 ; ) \u2248 /2) , where () is the Hamming distance; hence can be used to associate two hypervectors. \n\n\nHYPERREC 4.1 Overview\n\nIn this paper, we propose a new recommendation solution called HyperRec. HyperRec is based on HD computing and leverages the \"nearest neighbor\" principle for recommendation. Figure 1 shows the overview of HyperRec. HyperRec has two stages to make the recommendation: i) HD encoding stage which creates the database from the dataset, and ii) Recommending product stage which provides the rating for the products.\n\nIn the HD encoding stage, we convert the raw data of users, items and ratings with hyperdimensional binary vectors, in short, hypervectors. This is very different from the traditional approaches that represent users and items with low-dimensional full-precision vectors. By representing users and items with hyperdimensional binary vectors, we can save memory as well as enable fast hardware acceleration. Next, we construct the characterization vectors to represent the relation between users and items. Traditional matrix factorization techniques often leverage the latent user and item vectors to approximate the ratings with an iterative optimization procedure [21]. However, it requires the global information of the user-item relation. The proposed relation encoding module only leverages the local information of each user and item which is faster and more scalable. In the next recommending product stage, we make recommendations with the encoded hypervectors based on the \"nearest neighbor\" principle via Hamming distance. In this section, we will introduce the details of the proposed algorithm. \n\n\nHD Encoding\n\nThe encoding strategy of the proposed HyperRec is based on HD computing. We encode all users, items and ratings using hyperdimensional binary vectors. Our goal is to discover and preserve users' and items' information based on their historical interactions in an efficient manner. For each user and item , we first randomly generate a dimensional binary vector, In HD computing, can be as large as ten thousands. Note that if the binary vector for each rating is generated randomly, the information that consecutive ratings should be similar is lost. Instead, we first generate a hypervector filled with ones for rating 1. To generate the hypervector for rating , we flip the bits between ( \u2212 2) and ( \u2212 1) of the hypervector of rating \u2212 1 and assign the resulting vector to rating . By this means, consecutive ratings are close in terms of Hamming distance. Particularly, the Hamming distance between rating and rating \u2212 1 is while the Hamming distance between rating 1 and rating is . Following the proposed procedure, we can generate the hypervectors for each rating . To encode the relation between users and items, we propose an encoding strategy based on the binding and bundling operation in HD computing. The intuition of the proposed encoding strategy is that if two users given similar rating to the same item, their should have a high similarity. The proposed encodings can be written as:\n= [ 1 \u2297 1 + ... + \u2297 ] { 1 ,..., \u2208 } and = [ 1 \u2297 1 + ... + \u2297 ] { 1 ,..., \u2208 } ,\nwhere \u2297 is the operator and [ + ... + ] is the component-wise majority function.\n\nis the rating that user given to item . By this approach, we can capture the difference between users' consuming behaviors and their rating patterns. For instance, if two users and bought the same item and rated it similarly, the Hamming distance between their characterization hypervectors and will be small. The distance is proportional to the difference of the ratings. Note that we keep the last / bits of all rating hypervectors the same, so if two users rated the same item very differently, the Hamming distance between their characterization vectors will still be closer than the users who have no co-purchasing behaviors. The process is shown in Fig. 2. \n\n\nRecommending Products\n\nAfter we obtain the characterization hypervectors of users and items in the form of encoded hypervectors, we use Hamming distance to identify similarity. In order to compute the rating that user will give to item , we first identify the -nearest items of item based the ratings they received, and denote this set as ( ). For each of the k-nearest item \u2208 ( ), we also identify -nearest users of user in the set based on the ratings they give, and denote this set as ( , ). Then we compute the predicted rating of\nuser for item as\u02c6 = + \u2208 ( , ) (1\u2212 ( , )) ( \u2212 )\n, where is the normalization factor which is \u2208 ( , ) (1 \u2212 ( , )). And ( , ) is the normalized Hamming distance between the characterization vectors of users and . Then, we compute the predicted rating of user for item as\u02c6= + \u2208 ( ) (1 \u2212 ( , ))(\u02c6 \u2212 ). Similarly, ( , ) is the normalized Hamming distance between the characterization vector of item and item . After we obtain the predicted ratings of user for all the items he/she did not buy before, we can recommend the user with the items with highest predicted ratings. HyperRec has the simplicity of neighbor-based methods and meanwhile utilizes the effectiveness of HD computing. It is fast since the training phase only needs single pass of the data and the computation consists of only Boolean operations.\n\n\nHYPERREC ACCELERATION\n\nAs HyperRec uses binary representation for the encoded data, we can efficiently implement the proposed algorithm on various processors and systems. For example, similar to the existing recommendation solutions, HyperRec can be implemented on the contemporary CPU in a relatively straight-forward way. We can also further accelerate HyperRec on parallel computing platforms, since the operations are either component-wise binary operations and associative search using Hamming distance. In this section, we elaborate our acceleration strategies for two parallel computing platforms, FPGA and GPU.\n\n\nHyperRec FPGA Implementation\n\nWe use query hypervector to denote a particular user or item characterization hypervector and class hypervector to denote the user or item characterization hypervector used for similarity check. Substantial number of operations that can be executed in parallel in HyperRec is matched with intrinsic parallelism of FPGAs. Each dimension of the encoded hypervector can be generated independent of the other dimensions. The similarity metric between the generated dimensions and the class hypervectors can also be calculated independent of the other dimensions. We fully pipeline the encoding and the associative search of HD such that the encoding module generates dimensions of the query hypervector and then the associative search module calculates the similarity metric between these dimensions and their corresponding dimensions in every class hypervector and accumulates the similarity metric between the query hypervector and each class hypervector. Figure 3 shows the architecture of HyperRec FPGA-based accelerator. As illustrated in the figure, to generate dimension of the query hypervector, first we read the base hypervectors for each user or item, permute them and then by using tree adders, we accumulate the dimensions of all the permuted hypervectors. The generated dimensions of the query hypervector are binarized and passed to the associative search module. dimensions of the query hypervector are compared against their corresponding dimensions of every class hypervector using a series of XORs. The outputs of the XORs are aggregated together using tree adders where is the number of users or items. HyperRec FPGA-based accelerator accumulates the partial similarity metrics for each user or item. At the end the maximum number between all the similarity metrics represents the output.\n\n\nHyperRec GPU Implementation\n\nBefore running the GPU program, also called as kernel, we first generate hypervectors corresponding to user, item, and rating hypervectors on CPU. Note that this generation is a single-time cost since these hypervectors only depend on the number of users, items, and rating scale but not on the actual data. Next, we copy these hypervectors to GPU memory and encode the characterization vectors. The dimensionality of the hypervectors has a large impact on the performance of HD computing. In the encoding module, threads of a kernel sum up each dimension of the characterization vector. After the accumulation, we normalize and binarize the result hypervector. This binarization helps to avoid the divergence and the use of expensive operations. We selectively save the results when the rating of an item and the corresponding user exists. This technique reduces the number of write operations in the global memory of the GPU.\n\nFor the recommending products stage, we construct a matrix of pairwise Hamming distance from user and item characterization vector, respectively. The calculation of Hamming distance can simply parallelize over ( , ) or ( , ) pairs. We compute Hamming distance by comparing bit similarity between two characterization vectors. Using the symmetric nature of pairwise Hamming distance (i.e.\n\n( , ) = ( , )), we only calculate the upper triangular part of the distance matrix which can reduce the global memory access. Even though this adds divergence to each thread, it showed curtailed execution time of pairwise hamming distance calculation. We parallelize the nearest neighbor computation over users and items, with each thread predicting the rating of a user for a specific item. As mentioned above, this process involves selecting the nearest users and items. Searching similar items can be done before the kernel execution of the nearest neighbor recommendation stage. Once the kernel executes, each thread extracts similar users based on Hamming distance, as finding analogous user depends on the user purchase history. We then select similar top-K users/items using the heap data structure.\n\n\nEVALUATION 6.1 Experimental Setup\n\nWe implement the proposed HyperRec on three different platforms, CPU, FPGA, and GPU. The CPU-based HyperRec is implemented on Python 2.7 using Numpy library, which efficiently performs the binary operations using C++ backend. We use the CPU-based implementation to compare with the state-of-the-art algorithms running on CPU. The experiments are run on Intel Core i5 2.9 GHz with 8G RAM. We also evaluate the efficiency of HyperRec on two parallel computing platforms: Xilinx Kintex-7 FPGA, and NVIDIA GPU GTX 1080Ti. For FPGA, we extended the same framework as [27] for implementing HyperRec. For GPU, we used our implementation introduced in Section 5 using CUDA v10.0.\n\nWe conduct extensive experiments using several real-world large datasets for evaluating the proposed algorithm as follows:\n\n6.1.1 Datasets. We use datasets from Movielens [8], Amazon [20], FilmTrust [7] and Yelp 1 . The Movielens datasets contain thousands of ratings that users given to movies over various periods of time. For the movilens-10M, we randomly sample 10000 users and for each user we sample 5 items. Amazon datasets [20] contain a variety of categories ranging from to . The FilmTrust dataset was crawled from the FilmTrust website in June, 2011 and is a relatively small dataset. Yelp dataset contains over 700000 ratings that users given to food and restaurants.  We compare our algorithm with several state-of-the-art rating prediction methods: KNNBasic [6], KNNWithMeans [6], SVD [15], SVD++ [15], PMF [21], NMF [17], SlopeOne [18], Co-clustering [5], NCF [9], GCNN [28] and FM Rec [9]. MSE is used for evaluation since it is the standard metric for comparing rating prediction algorithms [21].\n\n\nRecommendation Quality Evaluation\n\nWe first evaluate the recommendation quality for different solutions.\n\nWe randomly select 70% of ratings in each dataset as training dataset and 20% of ratings in each dataset as testing dataset. The rest 10% of ratings are for validation data to tune hyperparameters. We use the best performed hyperparameters on the validation set. For KNNBasic and KNNWithMeans, the number of neighbors is 40. For SVD, SVD++ and PMF, the dimension of the latent factors is 100. For NMF, the dimension of the latent factor is 20. The learning rate of SVD and PMF is 0.005. The learning rate of SVD++ is 0.007. For all the latent-factor based methods, the regularization parameters is 0.02 and the training epoch is 50. For the co-clustering algorithm, we choose the size of the cluster to be 3. For NCF, we follow the recommended parameters settings in the original paper [9]. For HyperRec, the dimension of the hypervectors is set to be 1000. The number of neighboring items is set to be 5 and the number of neighboring users is set to be 30. Please note that prediction results of HyperRec is independent upon the computing platform. We list the experimental results of all the algorithms in Table 1  and Table 2. The best result on each dataset is shown in bold. As we can see, HyperRec achieves the best results on about half of the considered benchmarks. Compared with neighbor-based methods, our method can capture richer information about users and items with HD computing, which can help us identify similar users and items easily. Compared with latent-factor based methods, HyperRec needs much less memory and is easily scalable. We will show the time and memory comparison of HyperRec with SVD++ in Section 6.3. Note that the neural network based recommendation algorithm, such as NCF, does not achieve competitive performance compared with other methods, which is consistent with the phenomenon observed in a recent work [3]. The possible reason is that neural network based algorithsm can easily overfit the data due to the high complexity of the model. Different from other methods which utilize floating-point numbers, HyperRec stores users and items as hiperdimensional binary vectors rather than full-precision numbers and only relies Boolean operations. These unique properties make it very hardware-friendly so it can be easily accelerated. In the following sections, we will show how the proposed HyperRec is accelerated on various hardware platforms. \n\n\nEfficiency Evaluation\n\n6.3.1 Comparison with State-of-the-Art Method. We compare the efficiency of HyperRec with SVD++. Since SVD++ is typically run on CPU, we compare the results with the CPU-based HyperRec. Table 3 compares the memory consumption and execution time of HyperRec with SVD++ on the four datasets of different sizes: ml-100k, Arts, Clothing and Office. The results show that HyperRec is about 13.75 times faster than SVD++ on these four datasets which is crucial for real-time applications. In SVD++, users and items are usually represented by one hundred dimension full-precision vectors. For each user, we need at least 3200 bits to store his/her latent features and 3200 bits to store the gradients that are used for optimization. In contrast, HyperRec need only 1000 bits to represent each user, which amounts to a factor of six of memory saving. Along with the simpler computations of HyperRec, i.e., binary operations, the reduction of the computed data size leads the significant performance improvement. In our measurements, HyperRec reduces the memory consumption by about 87%.\n\n6.3.2 Different Hardware Accelerations. Figure 4 compares Hyper-Rec efficiency on different platforms. All results are reported as compared to energy and execution time of CPU-based HyperRec. Our evaluation shows that FPGA implementation can provide on average 67.0\u00d7 faster and 6.9\u00d7 higher energy efficiency as compared to CPU. FPGA exploits lookup-tables to paralleize bitwise operations involves in encoding and Hamming computing modules. GPU further improves FPGA efficiency by (i) providing higher parallelism during similarity search and nearest neighbor modules, and (ii) exploiting data sparsity. By utilizing register on FPGA is not sufficient to handle the sparse data. Hence, frequent access to memory degrades performance. However, GPU are general-purpose and consume more energy than FPGA. Our evaluation shows that our GPU implementation is on average 3.1\u00d7 faster than FPGA, while providing only 1.2\u00d7 lower energy efficiency. Note that the efficiency of FPGA and GPU can vary depending on the platforms and devices.\n\n\nCONCLUSION\n\nIn this paper, we propose a novel recommendation algorithm called HyperRec. We conducted extensive experiments to show that Hy-perRec can achieve competitive recommendation quality as compared with the state-of-the-art methods, while improving the performance by 13.75\u00d7 with much less memory footprints. We also demonstrate that how to accelerate HyperRec on parallel computing platforms. The results show that our FPGA implementation is on average 67.0\u00d7 faster and 6.9\u00d7 higher energy efficiency as compared to CPU. Our GPU implementation further achieves on average 3.1\u00d7 speedup compared to FPGA.\n\nFigure 1 :\n1Overview of HyperRec.\n\n\u2022\nComponent-wise majority: bundling operation is done via the component-wise majority function and is denoted as [ + + ]. The majority function is augmented with a method for breaking ties if the number of component hypervectors is even. The result of the majority function is similar to its constituents, i.e., ([ + + ]; ) < /2. This property makes the majority function well suited for representing sets.\n\nFigure 2 :\n2(a): Generation of user characterization vector. (b): Generation of item characterization vector.\n\nFigure 3 :\n3Architecture of HyperRec FPGA-based accelerator.\n\nFigure 4 :\n4HyperRec Efficiency on GPU and FPGA.\n\nTable 1 :\n1The mean squared error of all the algorithms on Movielens, Yelp and Filmtrust.KNNBasic \nKNNWithMeans \nSVD \nSVD++ \nPMF \nNMF \nSlopeOne \nCo Clustering \nNCF \nGCNN \nFM Rec \nHyperRec \nmovielens-100K \n0.9811 \n0.9507 \n0.9357 \n0.9215 \n0.9502 \n0.9632 \n0.9442 \n0.9646 \n1.3561 \n0.9236 \n0.8923 \n0.9649 \nmovielens-1M \n0.9335 \n0.9414 \n0.8920 \n0.8797 \n0.8734 \n0.9190 \n0.9045 \n0.9148 \n1.2120 \n0.9123 \n0.9178 \n0.9195 \nmovielens-10M \n1.1597 \n1.1469 \n1.0088 \n1.0043 \n1.0966 \n1.1254 \n1.2100 \n1.1170 \n1.2258 \n0.9812 \n1.1123 \n1.1030 \nYelp \n1.1065 \n1.0832 \n1.0703 \n1.0709 \n1.1550 \n1.1190 \n1.1048 \n1.0822 \n1.3551 \n1.2312 \n1.1123 \n1.0604 \nFilmtrust \n0.9232 \n0.9203 \n0.8996 \n0.8821 \n1.1562 \n0.9231 \n0.9378 \n0.9416 \n1.0282 \n0.9820 \n0.9210 \n0.8806 \n\n\n\nTable 2 :\n2The mean squared error of all the algorithms on Amazon's datasets.KNNBasic \nKNNWithMeans \nSVD \nSVD++ \nPMF \nNMF \nSlopeOne \nCo Clustering \nNCF \nGCNN \nFM Rec \nHyperRec \nArts \n1.0380 \n0.9837 \n1.0467 \n1.0109 \n0.9445 \n1.1065 \n0.9897 \n1.0672 \n1.2762 \n1.1231 \n0.9721 \n0.9320 \nTools \n1.1370 \n1.1233 \n1.0583 \n1.0437 \n1.1272 \n1.2208 \n1.1457 \n1.1265 \n1.2618 \n1.0123 \n0.9981 \n1.1506 \nSports \n0.9874 \n0.9227 \n0.9681 \n0.9423 \n1.0917 \n1.0535 \n0.9311 \n0.9926 \n0.8583 \n0.9122 \n0.9212 \n0.9108 \nMusical \n1.0784 \n1.1568 \n1.0636 \n1.0593 \n1.0551 \n1.2772 \n1.1628 \n1.1903 \n1.2092 \n1.1213 \n1.2012 \n1.2965 \nClothing \n0.7117 \n0.4768 \n0.7439 \n0.6849 \n0.7262 \n0.5961 \n0.4824 \n0.6362 \n0.3311 \n0.3412 \n0.3348 \n0.3250 \nPatio \n1.2455 \n1.2536 \n1.2178 \n1.2062 \n1.1965 \n1.3284 \n1.2716 \n1.2690 \n1.5917 \n1.3324 \n1.2341 \n1.2805 \nOffice \n1.2241 \n1.1885 \n1.1788 \n1.1658 \n1.2815 \n1.2587 \n1.2026 \n1.2820 \n1.5197 \n1.3412 \n1.3212 \n1.2527 \n\n6.1.2 Baselines for Existing Algorithms. \n\nTable 3 :\n3Efficiency Comparison between SVD++ and Hyper-Rec on CPU.Metrics \nSVD++ \nHyperRec \n\nml-100K \nTime \nMemory \n\n186.08s \n27.56M \n\n25.88s \n2.625M \n\nArts \nTime \nMemory \n\n3.10s \n23.24M \n\n1.10s \n2.619M \n\nClothing \nTime \nMemory \n\n43.50s \n102.74M \n\n40.99s \n13.03M \n\nOffice \nTime \nMemory \n\n412.2s \n73.32M \n\n9.43s \n7.66M \n\n\nhttps://www.yelp.com/dataset\nACKNOWLEDGEMENTThis work was supported in part by CRISP, one of six centers in JUMP, an SRC program sponsored by DARPA. This work is also supported by NSF CHASE-CI #1730158, NSF FET #1911095, NSF CC* NPEO #1826967. The paper was also funded in part by SRC AIHW grants.\nRecommender systems. C Charu, Aggarwal, SpringerCharu C Aggarwal. 2016. Recommender systems. Springer.\n\n. Heng-Tze, Levent Cheng, Jeremiah Koc, Tal Harmsen, Tushar Shaked, Hrishi Chandra, Glen Aradhye, Greg Anderson, Wei Corrado, Mustafa Chai, Ispir, Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al.\n\nWide & deep learning for recommender systems. Proceedings of the 1st workshop on deep learning for recommender systems. the 1st workshop on deep learning for recommender systemsWide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. 7-10.\n\nAre we really making much progress? A worrying analysis of recent neural recommendation approaches. Paolo Maurizio Ferrari Dacrema, Dietmar Cremonesi, Jannach, Proceedings of the 13th ACM Conference on Recommender Systems. the 13th ACM Conference on Recommender SystemsMaurizio Ferrari Dacrema, Paolo Cremonesi, and Dietmar Jannach. 2019. Are we really making much progress? A worrying analysis of recent neural recommen- dation approaches. In Proceedings of the 13th ACM Conference on Recommender Systems. 101-109.\n\nA comprehensive survey of neighborhood-based recommendation methods. Christian Desrosiers, George Karypis, Recommender systems handbook. SpringerChristian Desrosiers and George Karypis. 2011. A comprehensive survey of neighborhood-based recommendation methods. In Recommender systems hand- book. Springer, 107-144.\n\nA scalable collaborative filtering framework based on co-clustering. Thomas George, Srujana Merugu, Data Mining, Fifth IEEE international. 4Thomas George and Srujana Merugu. 2005. A scalable collaborative filtering framework based on co-clustering. In Data Mining, Fifth IEEE international con- ference on. IEEE, 4-pp.\n\nUsing collaborative filtering to weave an information tapestry. David Goldberg, David Nichols, M Brian, Douglas Oki, Terry, Commun. ACM. 35David Goldberg, David Nichols, Brian M Oki, and Douglas Terry. 1992. Using collaborative filtering to weave an information tapestry. Commun. ACM 35, 12 (1992), 61-70.\n\nA Novel Bayesian Similarity Measure for Recommender Systems. G Guo, J Zhang, N Yorke-Smith, Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI. the 23rd International Joint Conference on Artificial Intelligence (IJCAIG. Guo, J. Zhang, and N. Yorke-Smith. 2013. A Novel Bayesian Similarity Mea- sure for Recommender Systems. In Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI). 2619-2625.\n\nThe movielens datasets: History and context. Maxwell Harper, Joseph A Konstan, ACM Transactions on Interactive Intelligent Systems (TiiS). 519F Maxwell Harper and Joseph A Konstan. 2016. The movielens datasets: History and context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4 (2016), 19.\n\nNeural collaborative filtering. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Proceedings of the 26th international conference on world wide web. the 26th international conference on world wide webXiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web. 173-182.\n\nExploring hyperdimensional associative memory. Mohsen Imani, Abbas Rahimi, Deqian Kong, Tajana Rosing, Jan M Rabaey, 2017 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEEMohsen Imani, Abbas Rahimi, Deqian Kong, Tajana Rosing, and Jan M Rabaey. 2017. Exploring hyperdimensional associative memory. In 2017 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEE, 445-456.\n\nLanguage geometry using random indexing. Aditya Joshi, Johan T Halseth, Pentti Kanerva, International Symposium on Quantum Interaction. SpringerAditya Joshi, Johan T Halseth, and Pentti Kanerva. 2016. Language geometry using random indexing. In International Symposium on Quantum Interaction. Springer, 265-274.\n\nSparse distributed memory. Pentti Kanerva, Pentti Kanerva. 1988. Sparse distributed memory.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. Pentti Kanerva, Cognitive computation. 1Pentti Kanerva. 2009. Hyperdimensional computing: An introduction to com- puting in distributed representation with high-dimensional random vectors. Cognitive computation 1, 2 (2009), 139-159.\n\nComputing with 10,000-bit words. Pentti Kanerva, Communication, Control, and Computing (Allerton), 2014 52nd Annual Allerton Conference on. IEEE. Pentti Kanerva. 2014. Computing with 10,000-bit words. In Communication, Control, and Computing (Allerton), 2014 52nd Annual Allerton Conference on. IEEE, 304-310.\n\nFactorization meets the neighborhood: a multifaceted collaborative filtering model. Yehuda Koren, Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningACMYehuda Koren. 2008. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 426-434.\n\nAdvances in collaborative filtering. Yehuda Koren, Robert Bell, Recommender systems handbook. SpringerYehuda Koren and Robert Bell. 2011. Advances in collaborative filtering. In Recommender systems handbook. Springer, 145-186.\n\nAlgorithms for Non-negative Matrix Factorization. D Daniel, H Sebastian Lee, Seung, NIPS. Daniel D. Lee and H. Sebastian Seung. 2000. Algorithms for Non-negative Matrix Factorization. In NIPS.\n\nSlope one predictors for online rating-based collaborative filtering. Daniel Lemire, Anna Maclachlan, Proceedings of the 2005 SIAM International Conference on Data Mining. SIAM. the 2005 SIAM International Conference on Data Mining. SIAMDaniel Lemire and Anna Maclachlan. 2005. Slope one predictors for online rating-based collaborative filtering. In Proceedings of the 2005 SIAM International Conference on Data Mining. SIAM, 471-475.\n\nAn FPGA-based accelerator for neighborhood-based collaborative filtering recommendation algorithms. Xiang Ma, Chao Wang, Qi Yu, Xi Li, Xuehai Zhou, Cluster Computing (CLUSTER), 2015 IEEE International Conference on. IEEE. Xiang Ma, Chao Wang, Qi Yu, Xi Li, and Xuehai Zhou. 2015. An FPGA-based accelerator for neighborhood-based collaborative filtering recommendation algo- rithms. In Cluster Computing (CLUSTER), 2015 IEEE International Conference on. IEEE, 494-495.\n\nHidden factors and hidden topics: understanding rating dimensions with review text. Julian Mcauley, Jure Leskovec, Proceedings of the 7th ACM conference on Recommender systems. the 7th ACM conference on Recommender systemsACMJulian McAuley and Jure Leskovec. 2013. Hidden factors and hidden topics: understanding rating dimensions with review text. In Proceedings of the 7th ACM conference on Recommender systems. ACM, 165-172.\n\nProbabilistic matrix factorization. Andriy Mnih, R Ruslan, Salakhutdinov, Advances in neural information processing systems. Andriy Mnih and Ruslan R Salakhutdinov. 2008. Probabilistic matrix factorization. In Advances in neural information processing systems. 1257-1264.\n\nHyperdimensional biosignal processing: A case study for EMG-based hand gesture recognition. Abbas Rahimi, Simone Benatti, Pentti Kanerva, Luca Benini, Jan M Rabaey, Rebooting Computing (ICRC), IEEE International Conference on. IEEE. Abbas Rahimi, Simone Benatti, Pentti Kanerva, Luca Benini, and Jan M Rabaey. 2016. Hyperdimensional biosignal processing: A case study for EMG-based hand gesture recognition. In Rebooting Computing (ICRC), IEEE International Conference on. IEEE, 1-8.\n\nHyperdimensional computing for noninvasive brain-computer interfaces: Blind and one-shot classification of EEG error-related potentials. Abbas Rahimi, Pentti Kanerva, Jos\u00e9 Del R Mill\u00e1n, Jan M Rabaey, 10th ACM/EAI International Conference on Bio-inspired Information and Communications Technologies (BICT). Abbas Rahimi, Pentti Kanerva, Jos\u00e9 del R Mill\u00e1n, and Jan M Rabaey. 2017. Hyper- dimensional computing for noninvasive brain-computer interfaces: Blind and one-shot classification of EEG error-related potentials. In 10th ACM/EAI Interna- tional Conference on Bio-inspired Information and Communications Technologies (BICT).\n\nModeling dependencies in multiple parallel data streams with hyperdimensional computing. Okko Rasanen, Sofoklis Kakouros, IEEE Signal Processing Letters. 21Okko Rasanen and Sofoklis Kakouros. 2014. Modeling dependencies in multiple parallel data streams with hyperdimensional computing. IEEE Signal Processing Letters 21, 7 (2014), 899-903.\n\nSequence prediction with sparse distributed hyperdimensional coding applied to the analysis of mobile phone use patterns. J Okko, R\u00e4s\u00e4nen, P Jukka, Saarinen, IEEE transactions on neural networks and learning systems. 27Okko J R\u00e4s\u00e4nen and Jukka P Saarinen. 2016. Sequence prediction with sparse distributed hyperdimensional coding applied to the analysis of mobile phone use patterns. IEEE transactions on neural networks and learning systems 27, 9 (2016), 1878-1889.\n\nIntroduction to recommender systems handbook. Francesco Ricci, Lior Rokach, Bracha Shapira, Recommender systems handbook. SpringerFrancesco Ricci, Lior Rokach, and Bracha Shapira. 2011. Introduction to rec- ommender systems handbook. In Recommender systems handbook. Springer, 1-35.\n\nF5-hd: Fast flexible fpga-based framework for refreshing hyperdimensional computing. Sahand Salamat, Mohsen Imani, Behnam Khaleghi, Tajana Rosing, Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays. the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate ArraysSahand Salamat, Mohsen Imani, Behnam Khaleghi, and Tajana Rosing. 2019. F5-hd: Fast flexible fpga-based framework for refreshing hyperdimensional com- puting. In Proceedings of the 2019 ACM/SIGDA International Symposium on Field- Programmable Gate Arrays. 53-62.\n\nGraph convolutional neural networks for web-scale recommender systems. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, L William, Jure Hamilton, Leskovec, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningRex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 974-983.\n", "annotations": {"author": "[{\"start\":\"115\",\"end\":\"159\"},{\"start\":\"160\",\"end\":\"219\"},{\"start\":\"220\",\"end\":\"267\"},{\"start\":\"268\",\"end\":\"316\"},{\"start\":\"317\",\"end\":\"364\"},{\"start\":\"365\",\"end\":\"407\"},{\"start\":\"408\",\"end\":\"443\"},{\"start\":\"444\",\"end\":\"507\"},{\"start\":\"508\",\"end\":\"552\"},{\"start\":\"553\",\"end\":\"595\"},{\"start\":\"596\",\"end\":\"643\"},{\"start\":\"644\",\"end\":\"692\"},{\"start\":\"693\",\"end\":\"740\"},{\"start\":\"741\",\"end\":\"765\"},{\"start\":\"766\",\"end\":\"778\"},{\"start\":\"779\",\"end\":\"793\"},{\"start\":\"794\",\"end\":\"830\"}]", "publisher": null, "author_last_name": "[{\"start\":\"122\",\"end\":\"125\"},{\"start\":\"167\",\"end\":\"172\"},{\"start\":\"229\",\"end\":\"233\"},{\"start\":\"275\",\"end\":\"282\"},{\"start\":\"324\",\"end\":\"330\"},{\"start\":\"371\",\"end\":\"378\"},{\"start\":\"416\",\"end\":\"419\"},{\"start\":\"451\",\"end\":\"457\"},{\"start\":\"515\",\"end\":\"518\"},{\"start\":\"560\",\"end\":\"565\"},{\"start\":\"605\",\"end\":\"609\"},{\"start\":\"651\",\"end\":\"658\"},{\"start\":\"700\",\"end\":\"706\"},{\"start\":\"747\",\"end\":\"754\"},{\"start\":\"774\",\"end\":\"777\"},{\"start\":\"786\",\"end\":\"792\"}]", "author_first_name": "[{\"start\":\"115\",\"end\":\"121\"},{\"start\":\"160\",\"end\":\"166\"},{\"start\":\"220\",\"end\":\"228\"},{\"start\":\"268\",\"end\":\"274\"},{\"start\":\"317\",\"end\":\"323\"},{\"start\":\"365\",\"end\":\"370\"},{\"start\":\"408\",\"end\":\"415\"},{\"start\":\"444\",\"end\":\"450\"},{\"start\":\"508\",\"end\":\"514\"},{\"start\":\"553\",\"end\":\"559\"},{\"start\":\"596\",\"end\":\"604\"},{\"start\":\"644\",\"end\":\"650\"},{\"start\":\"693\",\"end\":\"699\"},{\"start\":\"741\",\"end\":\"746\"},{\"start\":\"766\",\"end\":\"773\"},{\"start\":\"779\",\"end\":\"785\"}]", "author_affiliation": "[{\"start\":\"127\",\"end\":\"158\"},{\"start\":\"191\",\"end\":\"218\"},{\"start\":\"235\",\"end\":\"266\"},{\"start\":\"284\",\"end\":\"315\"},{\"start\":\"332\",\"end\":\"363\"},{\"start\":\"398\",\"end\":\"406\"},{\"start\":\"475\",\"end\":\"506\"},{\"start\":\"520\",\"end\":\"551\"},{\"start\":\"567\",\"end\":\"594\"},{\"start\":\"611\",\"end\":\"642\"},{\"start\":\"660\",\"end\":\"691\"},{\"start\":\"708\",\"end\":\"739\"},{\"start\":\"756\",\"end\":\"764\"},{\"start\":\"795\",\"end\":\"829\"}]", "title": "[{\"start\":\"1\",\"end\":\"72\"},{\"start\":\"831\",\"end\":\"902\"}]", "venue": "[{\"start\":\"904\",\"end\":\"975\"}]", "abstract": "[{\"start\":\"1627\",\"end\":\"3205\"}]", "bib_ref": "[{\"start\":\"3424\",\"end\":\"3427\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"3591\",\"end\":\"3595\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"3595\",\"end\":\"3598\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"4895\",\"end\":\"4899\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"4899\",\"end\":\"4902\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"5234\",\"end\":\"5237\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"6360\",\"end\":\"6363\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"6622\",\"end\":\"6625\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"6625\",\"end\":\"6628\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"6703\",\"end\":\"6707\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"6707\",\"end\":\"6710\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"6964\",\"end\":\"6968\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"7105\",\"end\":\"7108\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"7108\",\"end\":\"7110\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"7278\",\"end\":\"7281\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"7809\",\"end\":\"7813\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"8029\",\"end\":\"8033\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"8048\",\"end\":\"8052\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"8224\",\"end\":\"8228\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"8228\",\"end\":\"8231\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"8231\",\"end\":\"8234\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"8277\",\"end\":\"8281\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"8281\",\"end\":\"8284\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"8311\",\"end\":\"8315\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"8346\",\"end\":\"8350\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"8596\",\"end\":\"8600\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"10743\",\"end\":\"10747\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"19982\",\"end\":\"19986\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"20264\",\"end\":\"20267\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"20276\",\"end\":\"20280\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"20292\",\"end\":\"20295\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"20524\",\"end\":\"20528\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"20865\",\"end\":\"20868\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"20883\",\"end\":\"20886\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"20892\",\"end\":\"20896\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"20904\",\"end\":\"20908\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"20914\",\"end\":\"20918\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"20924\",\"end\":\"20928\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"20939\",\"end\":\"20943\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"20959\",\"end\":\"20962\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"20968\",\"end\":\"20971\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"20978\",\"end\":\"20982\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"20994\",\"end\":\"20997\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"21101\",\"end\":\"21105\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"22001\",\"end\":\"22004\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"23061\",\"end\":\"23064\",\"attributes\":{\"ref_id\":\"b3\"}}]", "figure": "[{\"start\":\"26347\",\"end\":\"26381\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"26382\",\"end\":\"26789\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"26790\",\"end\":\"26900\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"26901\",\"end\":\"26962\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"26963\",\"end\":\"27012\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"27013\",\"end\":\"27746\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"27747\",\"end\":\"28694\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"28695\",\"end\":\"29018\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"3221\",\"end\":\"4446\"},{\"start\":\"4448\",\"end\":\"5259\"},{\"start\":\"5261\",\"end\":\"5337\"},{\"start\":\"5339\",\"end\":\"5635\"},{\"start\":\"5637\",\"end\":\"6062\"},{\"start\":\"6079\",\"end\":\"6597\"},{\"start\":\"6599\",\"end\":\"6867\"},{\"start\":\"6869\",\"end\":\"7929\"},{\"start\":\"7945\",\"end\":\"9340\"},{\"start\":\"9342\",\"end\":\"9639\"},{\"start\":\"9665\",\"end\":\"10076\"},{\"start\":\"10078\",\"end\":\"11184\"},{\"start\":\"11200\",\"end\":\"12599\"},{\"start\":\"12678\",\"end\":\"12758\"},{\"start\":\"12760\",\"end\":\"13423\"},{\"start\":\"13449\",\"end\":\"13960\"},{\"start\":\"14008\",\"end\":\"14768\"},{\"start\":\"14794\",\"end\":\"15389\"},{\"start\":\"15422\",\"end\":\"17226\"},{\"start\":\"17258\",\"end\":\"18185\"},{\"start\":\"18187\",\"end\":\"18574\"},{\"start\":\"18576\",\"end\":\"19382\"},{\"start\":\"19420\",\"end\":\"20091\"},{\"start\":\"20093\",\"end\":\"20215\"},{\"start\":\"20217\",\"end\":\"21106\"},{\"start\":\"21144\",\"end\":\"21213\"},{\"start\":\"21215\",\"end\":\"23600\"},{\"start\":\"23626\",\"end\":\"24704\"},{\"start\":\"24706\",\"end\":\"25734\"},{\"start\":\"25749\",\"end\":\"26346\"}]", "formula": "[{\"start\":\"12600\",\"end\":\"12677\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"13961\",\"end\":\"14007\",\"attributes\":{\"id\":\"formula_1\"}}]", "table_ref": "[{\"start\":\"22323\",\"end\":\"22343\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"23812\",\"end\":\"23819\",\"attributes\":{\"ref_id\":\"tab_2\"}}]", "section_header": "[{\"start\":\"3207\",\"end\":\"3219\",\"attributes\":{\"n\":\"1\"}},{\"start\":\"6065\",\"end\":\"6077\",\"attributes\":{\"n\":\"2\"}},{\"start\":\"7932\",\"end\":\"7943\",\"attributes\":{\"n\":\"3\"}},{\"start\":\"9642\",\"end\":\"9663\",\"attributes\":{\"n\":\"4\"}},{\"start\":\"11187\",\"end\":\"11198\",\"attributes\":{\"n\":\"4.2\"}},{\"start\":\"13426\",\"end\":\"13447\",\"attributes\":{\"n\":\"4.3\"}},{\"start\":\"14771\",\"end\":\"14792\",\"attributes\":{\"n\":\"5\"}},{\"start\":\"15392\",\"end\":\"15420\",\"attributes\":{\"n\":\"5.1\"}},{\"start\":\"17229\",\"end\":\"17256\",\"attributes\":{\"n\":\"5.2\"}},{\"start\":\"19385\",\"end\":\"19418\",\"attributes\":{\"n\":\"6\"}},{\"start\":\"21109\",\"end\":\"21142\",\"attributes\":{\"n\":\"6.2\"}},{\"start\":\"23603\",\"end\":\"23624\",\"attributes\":{\"n\":\"6.3\"}},{\"start\":\"25737\",\"end\":\"25747\",\"attributes\":{\"n\":\"7\"}},{\"start\":\"26348\",\"end\":\"26358\"},{\"start\":\"26383\",\"end\":\"26384\"},{\"start\":\"26791\",\"end\":\"26801\"},{\"start\":\"26902\",\"end\":\"26912\"},{\"start\":\"26964\",\"end\":\"26974\"},{\"start\":\"27014\",\"end\":\"27023\"},{\"start\":\"27748\",\"end\":\"27757\"},{\"start\":\"28696\",\"end\":\"28705\"}]", "table": "[{\"start\":\"27103\",\"end\":\"27746\"},{\"start\":\"27825\",\"end\":\"28694\"},{\"start\":\"28764\",\"end\":\"29018\"}]", "figure_caption": "[{\"start\":\"26360\",\"end\":\"26381\"},{\"start\":\"26385\",\"end\":\"26789\"},{\"start\":\"26803\",\"end\":\"26900\"},{\"start\":\"26914\",\"end\":\"26962\"},{\"start\":\"26976\",\"end\":\"27012\"},{\"start\":\"27025\",\"end\":\"27103\"},{\"start\":\"27759\",\"end\":\"27825\"},{\"start\":\"28707\",\"end\":\"28764\"}]", "figure_ref": "[{\"start\":\"9839\",\"end\":\"9847\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"13415\",\"end\":\"13422\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"16376\",\"end\":\"16384\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"24746\",\"end\":\"24754\",\"attributes\":{\"ref_id\":\"fig_4\"}}]", "bib_author_first_name": "[{\"start\":\"29338\",\"end\":\"29339\"},{\"start\":\"29433\",\"end\":\"29439\"},{\"start\":\"29447\",\"end\":\"29455\"},{\"start\":\"29461\",\"end\":\"29464\"},{\"start\":\"29474\",\"end\":\"29480\"},{\"start\":\"29489\",\"end\":\"29495\"},{\"start\":\"29505\",\"end\":\"29509\"},{\"start\":\"29519\",\"end\":\"29523\"},{\"start\":\"29534\",\"end\":\"29537\"},{\"start\":\"29547\",\"end\":\"29554\"},{\"start\":\"30127\",\"end\":\"30132\"},{\"start\":\"30159\",\"end\":\"30166\"},{\"start\":\"30613\",\"end\":\"30622\"},{\"start\":\"30635\",\"end\":\"30641\"},{\"start\":\"30929\",\"end\":\"30935\"},{\"start\":\"30944\",\"end\":\"30951\"},{\"start\":\"31244\",\"end\":\"31249\"},{\"start\":\"31260\",\"end\":\"31265\"},{\"start\":\"31275\",\"end\":\"31276\"},{\"start\":\"31284\",\"end\":\"31291\"},{\"start\":\"31548\",\"end\":\"31549\"},{\"start\":\"31555\",\"end\":\"31556\"},{\"start\":\"31564\",\"end\":\"31565\"},{\"start\":\"32000\",\"end\":\"32007\"},{\"start\":\"32016\",\"end\":\"32022\"},{\"start\":\"32023\",\"end\":\"32024\"},{\"start\":\"32296\",\"end\":\"32304\"},{\"start\":\"32309\",\"end\":\"32313\"},{\"start\":\"32320\",\"end\":\"32327\"},{\"start\":\"32335\",\"end\":\"32342\"},{\"start\":\"32348\",\"end\":\"32351\"},{\"start\":\"32356\",\"end\":\"32364\"},{\"start\":\"32735\",\"end\":\"32741\"},{\"start\":\"32749\",\"end\":\"32754\"},{\"start\":\"32763\",\"end\":\"32769\"},{\"start\":\"32776\",\"end\":\"32782\"},{\"start\":\"32791\",\"end\":\"32794\"},{\"start\":\"32795\",\"end\":\"32796\"},{\"start\":\"33164\",\"end\":\"33170\"},{\"start\":\"33178\",\"end\":\"33183\"},{\"start\":\"33184\",\"end\":\"33185\"},{\"start\":\"33195\",\"end\":\"33201\"},{\"start\":\"33463\",\"end\":\"33469\"},{\"start\":\"33654\",\"end\":\"33660\"},{\"start\":\"33921\",\"end\":\"33927\"},{\"start\":\"34283\",\"end\":\"34289\"},{\"start\":\"34742\",\"end\":\"34748\"},{\"start\":\"34756\",\"end\":\"34762\"},{\"start\":\"34983\",\"end\":\"34984\"},{\"start\":\"34993\",\"end\":\"34994\"},{\"start\":\"34995\",\"end\":\"35004\"},{\"start\":\"35197\",\"end\":\"35203\"},{\"start\":\"35212\",\"end\":\"35216\"},{\"start\":\"35664\",\"end\":\"35669\"},{\"start\":\"35674\",\"end\":\"35678\"},{\"start\":\"35685\",\"end\":\"35687\"},{\"start\":\"35692\",\"end\":\"35694\"},{\"start\":\"35699\",\"end\":\"35705\"},{\"start\":\"36117\",\"end\":\"36123\"},{\"start\":\"36133\",\"end\":\"36137\"},{\"start\":\"36498\",\"end\":\"36504\"},{\"start\":\"36511\",\"end\":\"36512\"},{\"start\":\"36827\",\"end\":\"36832\"},{\"start\":\"36841\",\"end\":\"36847\"},{\"start\":\"36857\",\"end\":\"36863\"},{\"start\":\"36873\",\"end\":\"36877\"},{\"start\":\"36886\",\"end\":\"36889\"},{\"start\":\"36890\",\"end\":\"36891\"},{\"start\":\"37357\",\"end\":\"37362\"},{\"start\":\"37371\",\"end\":\"37377\"},{\"start\":\"37387\",\"end\":\"37391\"},{\"start\":\"37406\",\"end\":\"37409\"},{\"start\":\"37410\",\"end\":\"37411\"},{\"start\":\"37939\",\"end\":\"37943\"},{\"start\":\"37953\",\"end\":\"37961\"},{\"start\":\"38314\",\"end\":\"38315\"},{\"start\":\"38331\",\"end\":\"38332\"},{\"start\":\"38706\",\"end\":\"38715\"},{\"start\":\"38723\",\"end\":\"38727\"},{\"start\":\"38736\",\"end\":\"38742\"},{\"start\":\"39029\",\"end\":\"39035\"},{\"start\":\"39045\",\"end\":\"39051\"},{\"start\":\"39059\",\"end\":\"39065\"},{\"start\":\"39076\",\"end\":\"39082\"},{\"start\":\"39595\",\"end\":\"39598\"},{\"start\":\"39605\",\"end\":\"39612\"},{\"start\":\"39617\",\"end\":\"39624\"},{\"start\":\"39631\",\"end\":\"39635\"},{\"start\":\"39650\",\"end\":\"39651\"},{\"start\":\"39661\",\"end\":\"39665\"}]", "bib_author_last_name": "[{\"start\":\"29340\",\"end\":\"29345\"},{\"start\":\"29347\",\"end\":\"29355\"},{\"start\":\"29423\",\"end\":\"29431\"},{\"start\":\"29440\",\"end\":\"29445\"},{\"start\":\"29456\",\"end\":\"29459\"},{\"start\":\"29465\",\"end\":\"29472\"},{\"start\":\"29481\",\"end\":\"29487\"},{\"start\":\"29496\",\"end\":\"29503\"},{\"start\":\"29510\",\"end\":\"29517\"},{\"start\":\"29524\",\"end\":\"29532\"},{\"start\":\"29538\",\"end\":\"29545\"},{\"start\":\"29555\",\"end\":\"29559\"},{\"start\":\"29561\",\"end\":\"29566\"},{\"start\":\"30133\",\"end\":\"30157\"},{\"start\":\"30167\",\"end\":\"30176\"},{\"start\":\"30178\",\"end\":\"30185\"},{\"start\":\"30623\",\"end\":\"30633\"},{\"start\":\"30642\",\"end\":\"30649\"},{\"start\":\"30936\",\"end\":\"30942\"},{\"start\":\"30952\",\"end\":\"30958\"},{\"start\":\"31250\",\"end\":\"31258\"},{\"start\":\"31266\",\"end\":\"31273\"},{\"start\":\"31277\",\"end\":\"31282\"},{\"start\":\"31292\",\"end\":\"31295\"},{\"start\":\"31297\",\"end\":\"31302\"},{\"start\":\"31550\",\"end\":\"31553\"},{\"start\":\"31557\",\"end\":\"31562\"},{\"start\":\"31566\",\"end\":\"31577\"},{\"start\":\"32008\",\"end\":\"32014\"},{\"start\":\"32025\",\"end\":\"32032\"},{\"start\":\"32305\",\"end\":\"32307\"},{\"start\":\"32314\",\"end\":\"32318\"},{\"start\":\"32328\",\"end\":\"32333\"},{\"start\":\"32343\",\"end\":\"32346\"},{\"start\":\"32352\",\"end\":\"32354\"},{\"start\":\"32365\",\"end\":\"32369\"},{\"start\":\"32742\",\"end\":\"32747\"},{\"start\":\"32755\",\"end\":\"32761\"},{\"start\":\"32770\",\"end\":\"32774\"},{\"start\":\"32783\",\"end\":\"32789\"},{\"start\":\"32797\",\"end\":\"32803\"},{\"start\":\"33171\",\"end\":\"33176\"},{\"start\":\"33186\",\"end\":\"33193\"},{\"start\":\"33202\",\"end\":\"33209\"},{\"start\":\"33470\",\"end\":\"33477\"},{\"start\":\"33661\",\"end\":\"33668\"},{\"start\":\"33928\",\"end\":\"33935\"},{\"start\":\"34290\",\"end\":\"34295\"},{\"start\":\"34749\",\"end\":\"34754\"},{\"start\":\"34763\",\"end\":\"34767\"},{\"start\":\"34985\",\"end\":\"34991\"},{\"start\":\"35005\",\"end\":\"35008\"},{\"start\":\"35010\",\"end\":\"35015\"},{\"start\":\"35204\",\"end\":\"35210\"},{\"start\":\"35217\",\"end\":\"35227\"},{\"start\":\"35670\",\"end\":\"35672\"},{\"start\":\"35679\",\"end\":\"35683\"},{\"start\":\"35688\",\"end\":\"35690\"},{\"start\":\"35695\",\"end\":\"35697\"},{\"start\":\"35706\",\"end\":\"35710\"},{\"start\":\"36124\",\"end\":\"36131\"},{\"start\":\"36138\",\"end\":\"36146\"},{\"start\":\"36505\",\"end\":\"36509\"},{\"start\":\"36513\",\"end\":\"36519\"},{\"start\":\"36521\",\"end\":\"36534\"},{\"start\":\"36833\",\"end\":\"36839\"},{\"start\":\"36848\",\"end\":\"36855\"},{\"start\":\"36864\",\"end\":\"36871\"},{\"start\":\"36878\",\"end\":\"36884\"},{\"start\":\"36892\",\"end\":\"36898\"},{\"start\":\"37363\",\"end\":\"37369\"},{\"start\":\"37378\",\"end\":\"37385\"},{\"start\":\"37392\",\"end\":\"37404\"},{\"start\":\"37412\",\"end\":\"37418\"},{\"start\":\"37944\",\"end\":\"37951\"},{\"start\":\"37962\",\"end\":\"37970\"},{\"start\":\"38316\",\"end\":\"38320\"},{\"start\":\"38322\",\"end\":\"38329\"},{\"start\":\"38333\",\"end\":\"38338\"},{\"start\":\"38340\",\"end\":\"38348\"},{\"start\":\"38716\",\"end\":\"38721\"},{\"start\":\"38728\",\"end\":\"38734\"},{\"start\":\"38743\",\"end\":\"38750\"},{\"start\":\"39036\",\"end\":\"39043\"},{\"start\":\"39052\",\"end\":\"39057\"},{\"start\":\"39066\",\"end\":\"39074\"},{\"start\":\"39083\",\"end\":\"39089\"},{\"start\":\"39599\",\"end\":\"39603\"},{\"start\":\"39613\",\"end\":\"39615\"},{\"start\":\"39625\",\"end\":\"39629\"},{\"start\":\"39636\",\"end\":\"39648\"},{\"start\":\"39652\",\"end\":\"39659\"},{\"start\":\"39666\",\"end\":\"39674\"},{\"start\":\"39676\",\"end\":\"39684\"}]", "bib_entry": "[{\"start\":\"29317\",\"end\":\"29419\",\"attributes\":{\"id\":\"b0\"}},{\"start\":\"29421\",\"end\":\"29718\",\"attributes\":{\"id\":\"b1\"}},{\"start\":\"29720\",\"end\":\"30025\",\"attributes\":{\"matched_paper_id\":\"3352400\",\"id\":\"b2\"}},{\"start\":\"30027\",\"end\":\"30542\",\"attributes\":{\"matched_paper_id\":\"196831663\",\"id\":\"b3\"}},{\"start\":\"30544\",\"end\":\"30858\",\"attributes\":{\"matched_paper_id\":\"3210193\",\"id\":\"b4\"}},{\"start\":\"30860\",\"end\":\"31178\",\"attributes\":{\"matched_paper_id\":\"9016498\",\"id\":\"b5\"}},{\"start\":\"31180\",\"end\":\"31485\",\"attributes\":{\"matched_paper_id\":\"1591394\",\"id\":\"b6\"}},{\"start\":\"31487\",\"end\":\"31953\",\"attributes\":{\"matched_paper_id\":\"373928\",\"id\":\"b7\"}},{\"start\":\"31955\",\"end\":\"32262\",\"attributes\":{\"matched_paper_id\":\"16619709\",\"id\":\"b8\"}},{\"start\":\"32264\",\"end\":\"32686\",\"attributes\":{\"matched_paper_id\":\"13907106\",\"id\":\"b9\"}},{\"start\":\"32688\",\"end\":\"33121\",\"attributes\":{\"matched_paper_id\":\"1677864\",\"id\":\"b10\"}},{\"start\":\"33123\",\"end\":\"33434\",\"attributes\":{\"matched_paper_id\":\"39020350\",\"id\":\"b11\"}},{\"start\":\"33436\",\"end\":\"33527\",\"attributes\":{\"id\":\"b12\"}},{\"start\":\"33529\",\"end\":\"33886\",\"attributes\":{\"matched_paper_id\":\"733980\",\"id\":\"b13\"}},{\"start\":\"33888\",\"end\":\"34197\",\"attributes\":{\"matched_paper_id\":\"13894815\",\"id\":\"b14\"}},{\"start\":\"34199\",\"end\":\"34703\",\"attributes\":{\"matched_paper_id\":\"207168823\",\"id\":\"b15\"}},{\"start\":\"34705\",\"end\":\"34931\",\"attributes\":{\"matched_paper_id\":\"14698210\",\"id\":\"b16\"}},{\"start\":\"34933\",\"end\":\"35125\",\"attributes\":{\"matched_paper_id\":\"2095855\",\"id\":\"b17\"}},{\"start\":\"35127\",\"end\":\"35562\",\"attributes\":{\"matched_paper_id\":\"2361137\",\"id\":\"b18\"}},{\"start\":\"35564\",\"end\":\"36031\",\"attributes\":{\"matched_paper_id\":\"14869466\",\"id\":\"b19\"}},{\"start\":\"36033\",\"end\":\"36460\",\"attributes\":{\"matched_paper_id\":\"6440341\",\"id\":\"b20\"}},{\"start\":\"36462\",\"end\":\"36733\",\"attributes\":{\"matched_paper_id\":\"467086\",\"id\":\"b21\"}},{\"start\":\"36735\",\"end\":\"37218\",\"attributes\":{\"matched_paper_id\":\"12008695\",\"id\":\"b22\"}},{\"start\":\"37220\",\"end\":\"37848\",\"attributes\":{\"matched_paper_id\":\"8996877\",\"id\":\"b23\"}},{\"start\":\"37850\",\"end\":\"38190\",\"attributes\":{\"matched_paper_id\":\"1690456\",\"id\":\"b24\"}},{\"start\":\"38192\",\"end\":\"38658\",\"attributes\":{\"matched_paper_id\":\"15258913\",\"id\":\"b25\"}},{\"start\":\"38660\",\"end\":\"38942\",\"attributes\":{\"matched_paper_id\":\"35569873\",\"id\":\"b26\"}},{\"start\":\"38944\",\"end\":\"39522\",\"attributes\":{\"matched_paper_id\":\"67872077\",\"id\":\"b27\"}},{\"start\":\"39524\",\"end\":\"40145\",\"attributes\":{\"matched_paper_id\":\"46949657\",\"id\":\"b28\"}}]", "bib_title": "[{\"start\":\"29720\",\"end\":\"29764\"},{\"start\":\"30027\",\"end\":\"30125\"},{\"start\":\"30544\",\"end\":\"30611\"},{\"start\":\"30860\",\"end\":\"30927\"},{\"start\":\"31180\",\"end\":\"31242\"},{\"start\":\"31487\",\"end\":\"31546\"},{\"start\":\"31955\",\"end\":\"31998\"},{\"start\":\"32264\",\"end\":\"32294\"},{\"start\":\"32688\",\"end\":\"32733\"},{\"start\":\"33123\",\"end\":\"33162\"},{\"start\":\"33529\",\"end\":\"33652\"},{\"start\":\"33888\",\"end\":\"33919\"},{\"start\":\"34199\",\"end\":\"34281\"},{\"start\":\"34705\",\"end\":\"34740\"},{\"start\":\"34933\",\"end\":\"34981\"},{\"start\":\"35127\",\"end\":\"35195\"},{\"start\":\"35564\",\"end\":\"35662\"},{\"start\":\"36033\",\"end\":\"36115\"},{\"start\":\"36462\",\"end\":\"36496\"},{\"start\":\"36735\",\"end\":\"36825\"},{\"start\":\"37220\",\"end\":\"37355\"},{\"start\":\"37850\",\"end\":\"37937\"},{\"start\":\"38192\",\"end\":\"38312\"},{\"start\":\"38660\",\"end\":\"38704\"},{\"start\":\"38944\",\"end\":\"39027\"},{\"start\":\"39524\",\"end\":\"39593\"}]", "bib_author": "[{\"start\":\"29338\",\"end\":\"29347\"},{\"start\":\"29347\",\"end\":\"29357\"},{\"start\":\"29423\",\"end\":\"29433\"},{\"start\":\"29433\",\"end\":\"29447\"},{\"start\":\"29447\",\"end\":\"29461\"},{\"start\":\"29461\",\"end\":\"29474\"},{\"start\":\"29474\",\"end\":\"29489\"},{\"start\":\"29489\",\"end\":\"29505\"},{\"start\":\"29505\",\"end\":\"29519\"},{\"start\":\"29519\",\"end\":\"29534\"},{\"start\":\"29534\",\"end\":\"29547\"},{\"start\":\"29547\",\"end\":\"29561\"},{\"start\":\"29561\",\"end\":\"29568\"},{\"start\":\"30127\",\"end\":\"30159\"},{\"start\":\"30159\",\"end\":\"30178\"},{\"start\":\"30178\",\"end\":\"30187\"},{\"start\":\"30613\",\"end\":\"30635\"},{\"start\":\"30635\",\"end\":\"30651\"},{\"start\":\"30929\",\"end\":\"30944\"},{\"start\":\"30944\",\"end\":\"30960\"},{\"start\":\"31244\",\"end\":\"31260\"},{\"start\":\"31260\",\"end\":\"31275\"},{\"start\":\"31275\",\"end\":\"31284\"},{\"start\":\"31284\",\"end\":\"31297\"},{\"start\":\"31297\",\"end\":\"31304\"},{\"start\":\"31548\",\"end\":\"31555\"},{\"start\":\"31555\",\"end\":\"31564\"},{\"start\":\"31564\",\"end\":\"31579\"},{\"start\":\"32000\",\"end\":\"32016\"},{\"start\":\"32016\",\"end\":\"32034\"},{\"start\":\"32296\",\"end\":\"32309\"},{\"start\":\"32309\",\"end\":\"32320\"},{\"start\":\"32320\",\"end\":\"32335\"},{\"start\":\"32335\",\"end\":\"32348\"},{\"start\":\"32348\",\"end\":\"32356\"},{\"start\":\"32356\",\"end\":\"32371\"},{\"start\":\"32735\",\"end\":\"32749\"},{\"start\":\"32749\",\"end\":\"32763\"},{\"start\":\"32763\",\"end\":\"32776\"},{\"start\":\"32776\",\"end\":\"32791\"},{\"start\":\"32791\",\"end\":\"32805\"},{\"start\":\"33164\",\"end\":\"33178\"},{\"start\":\"33178\",\"end\":\"33195\"},{\"start\":\"33195\",\"end\":\"33211\"},{\"start\":\"33463\",\"end\":\"33479\"},{\"start\":\"33654\",\"end\":\"33670\"},{\"start\":\"33921\",\"end\":\"33937\"},{\"start\":\"34283\",\"end\":\"34297\"},{\"start\":\"34742\",\"end\":\"34756\"},{\"start\":\"34756\",\"end\":\"34769\"},{\"start\":\"34983\",\"end\":\"34993\"},{\"start\":\"34993\",\"end\":\"35010\"},{\"start\":\"35010\",\"end\":\"35017\"},{\"start\":\"35197\",\"end\":\"35212\"},{\"start\":\"35212\",\"end\":\"35229\"},{\"start\":\"35664\",\"end\":\"35674\"},{\"start\":\"35674\",\"end\":\"35685\"},{\"start\":\"35685\",\"end\":\"35692\"},{\"start\":\"35692\",\"end\":\"35699\"},{\"start\":\"35699\",\"end\":\"35712\"},{\"start\":\"36117\",\"end\":\"36133\"},{\"start\":\"36133\",\"end\":\"36148\"},{\"start\":\"36498\",\"end\":\"36511\"},{\"start\":\"36511\",\"end\":\"36521\"},{\"start\":\"36521\",\"end\":\"36536\"},{\"start\":\"36827\",\"end\":\"36841\"},{\"start\":\"36841\",\"end\":\"36857\"},{\"start\":\"36857\",\"end\":\"36873\"},{\"start\":\"36873\",\"end\":\"36886\"},{\"start\":\"36886\",\"end\":\"36900\"},{\"start\":\"37357\",\"end\":\"37371\"},{\"start\":\"37371\",\"end\":\"37387\"},{\"start\":\"37387\",\"end\":\"37406\"},{\"start\":\"37406\",\"end\":\"37420\"},{\"start\":\"37939\",\"end\":\"37953\"},{\"start\":\"37953\",\"end\":\"37972\"},{\"start\":\"38314\",\"end\":\"38322\"},{\"start\":\"38322\",\"end\":\"38331\"},{\"start\":\"38331\",\"end\":\"38340\"},{\"start\":\"38340\",\"end\":\"38350\"},{\"start\":\"38706\",\"end\":\"38723\"},{\"start\":\"38723\",\"end\":\"38736\"},{\"start\":\"38736\",\"end\":\"38752\"},{\"start\":\"39029\",\"end\":\"39045\"},{\"start\":\"39045\",\"end\":\"39059\"},{\"start\":\"39059\",\"end\":\"39076\"},{\"start\":\"39076\",\"end\":\"39091\"},{\"start\":\"39595\",\"end\":\"39605\"},{\"start\":\"39605\",\"end\":\"39617\"},{\"start\":\"39617\",\"end\":\"39631\"},{\"start\":\"39631\",\"end\":\"39650\"},{\"start\":\"39650\",\"end\":\"39661\"},{\"start\":\"39661\",\"end\":\"39676\"},{\"start\":\"39676\",\"end\":\"39686\"}]", "bib_venue": "[{\"start\":\"29317\",\"end\":\"29336\"},{\"start\":\"29766\",\"end\":\"29838\"},{\"start\":\"30187\",\"end\":\"30248\"},{\"start\":\"30651\",\"end\":\"30679\"},{\"start\":\"30960\",\"end\":\"30997\"},{\"start\":\"31304\",\"end\":\"31315\"},{\"start\":\"31579\",\"end\":\"31667\"},{\"start\":\"32034\",\"end\":\"32092\"},{\"start\":\"32371\",\"end\":\"32437\"},{\"start\":\"32805\",\"end\":\"32887\"},{\"start\":\"33211\",\"end\":\"33257\"},{\"start\":\"33436\",\"end\":\"33461\"},{\"start\":\"33670\",\"end\":\"33691\"},{\"start\":\"33937\",\"end\":\"34032\"},{\"start\":\"34297\",\"end\":\"34395\"},{\"start\":\"34769\",\"end\":\"34797\"},{\"start\":\"35017\",\"end\":\"35021\"},{\"start\":\"35229\",\"end\":\"35303\"},{\"start\":\"35712\",\"end\":\"35784\"},{\"start\":\"36148\",\"end\":\"36208\"},{\"start\":\"36536\",\"end\":\"36585\"},{\"start\":\"36900\",\"end\":\"36966\"},{\"start\":\"37420\",\"end\":\"37524\"},{\"start\":\"37972\",\"end\":\"38002\"},{\"start\":\"38350\",\"end\":\"38407\"},{\"start\":\"38752\",\"end\":\"38780\"},{\"start\":\"39091\",\"end\":\"39182\"},{\"start\":\"39686\",\"end\":\"39782\"},{\"start\":\"29840\",\"end\":\"29897\"},{\"start\":\"30250\",\"end\":\"30296\"},{\"start\":\"31669\",\"end\":\"31742\"},{\"start\":\"32439\",\"end\":\"32490\"},{\"start\":\"34397\",\"end\":\"34480\"},{\"start\":\"35305\",\"end\":\"35364\"},{\"start\":\"36210\",\"end\":\"36255\"},{\"start\":\"39184\",\"end\":\"39260\"},{\"start\":\"39784\",\"end\":\"39865\"}]"}}}, "year": 2023, "month": 12, "day": 17}