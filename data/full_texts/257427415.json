{"id": 257427415, "updated": "2023-11-29 16:23:59.161", "metadata": {"title": "A syntax-guided multi-task learning approach for Turducken-style code generation", "authors": "[{\"first\":\"Guang\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Yu\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Xiang\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Xiangyu\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Yiran\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Tingting\",\"last\":\"Han\",\"middle\":[]},{\"first\":\"Taolue\",\"last\":\"Chen\",\"middle\":[]}]", "venue": "Empirical Software Engineering", "journal": "Empirical Software Engineering", "publication_date": {"year": 2023, "month": 10, "day": 14}, "abstract": "Due to the development of pre-trained language models, automated code generation techniques have shown great promise in recent years. However, the generated code will not always adhere to syntactic constraints of the target language, especially in the case of Turducken-style code, where declarative code snippets are embedded within imperative programs. In this study, we summarize three significant challenges in regards to syntactic constraints: (1) the efficient representation of syntactic constraints, (2) the effective integration of syntactic information, and (3) the scalable syntax-first decoding algorithm. To address these challenges, we propose a syntax-guided multi-task learning approach TurduckenGen. Specifically, we first explicitly append the type information to the code tokens to capture the representation of syntactic constraints. Then we formalize code generation with syntactic constraint representation as an auxiliary task to enable the model to learn the syntactic constraints of the code. Finally, the syntactically correct code is selected accurately from the multiple candidates with the help of the compiler feedback. Extensive experiments and comprehensive analysis demonstrate the effectiveness and general applicability of our approach after being compared with six state-of-the-art baselines on two Turducken-style code datasets. Finally, we conducted a human study and found the code quality generated by our approach is better than baselines in terms of code readability and semantic similarity.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/ese/YangZCZXHC23", "doi": "10.1007/s10664-023-10372-1"}}, "content": {"source": {"pdf_hash": "79cae3a5080249a627b1fc4416df7535aae76c74", "pdf_src": "Springer", "pdf_uri": "[\"https://export.arxiv.org/pdf/2303.05061v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://arxiv.org/pdf/2303.05061", "status": "GREEN"}}, "grobid": {"id": "8ccaf38d1a0f5bc7e93bc83cca6906dd572fa4bb", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/79cae3a5080249a627b1fc4416df7535aae76c74.txt", "contents": "\nA syntax-guided multi-task learning approach for Turducken-style code generation\n14 October 2023\n\nGuang Yang \nYu Zhou zhouyu@nuaa.edu.cn 0000-0002-3723-7584\n\u2022 Xiang Chen \nXiangyu Zhang \nYiran Xu \nTingting Han \nTaolue Chen \nA syntax-guided multi-task learning approach for Turducken-style code generation\n14 October 2023DCA76C72AD39D92F12294590380E38CC10.1007/s10664-023-10372-1Syntactically-constrained code generationTurducken-style codeMulti-task learningCodeT5Abstract syntax tree\nDue to the development of pre-trained language models, automated code generation techniques have shown great promise in recent years.However, the generated code will not always adhere to syntactic constraints of the target language, especially in the case of Turduckenstyle code, where declarative code snippets are embedded within imperative programs.In this study, we summarize three significant challenges in regards to syntactic constraints: (1) the efficient representation of syntactic constraints, (2) the effective integration of syntactic information, and (3) the scalable syntax-first decoding algorithm.To address these challenges, we propose a syntax-guided multi-task learning approach TurduckenGen.Specifically, we first explicitly append the type information to the code tokens to capture the representation of syntactic constraints.Then we formalize code generation with syntactic constraint representation as an auxiliary task to enable the model to learn the syntactic constraints of the code.Finally, the syntactically correct code is selected accurately from the multiple candidates with the help of the compiler feedback.Extensive experiments and comprehensive analysis demonstrate the effectiveness and general applicability of our approach after being compared with six state-of-the-art baselines on two Turducken-style code datasets.Finally, we conducted a human study and found the code quality generated by our approach is better than baselines in terms of code readability and semantic similarity.\n\nIntroduction\n\nContemporary society is dependent on intricate software applications, and the development of such applications is a complex and prolonged process (Liu et al. 2023c).As the complexity of software increases, the development process becomes increasingly time-consuming and susceptible to errors.Moreover, the demand for acquiring proficiency in multiple programming languages is high, especially for novice developers, which further complicates software development (Xu et al. 2022).To mitigate these challenges, neural code generation has been proposed as a solution that aims to synthesize code snippets based on functional descriptions, with the potential to alleviate the burden of programmers during the development process.\n\nBased on the type of target programming languages, the existing code generation tasks can be classified into imperative code generation and declarative code generation.Previous studies have demonstrated that existing methods can generate code with an accuracy of over 90% on datasets of declarative programs (Sun et al. 2020;Xuan et al. 2021), while the accuracy on datasets of imperative programs is less than 35% (Ahmad et al. 2021;Wang et al. 2021b).However, large software systems are rarely developed exclusively in a declarative language in practical software development.Instead, declarative programs are commonly embedded within imperative programs, which are normally referred to as Turducken-style programs (Liang et al. 2021).For example, in information management systems, developers often include SQL statements within imperative programs; in data mining systems, developers often incorporate regular expressions within imperative programs.A scientifically compelling and engineering-significant question is how to bring the good performance of automatic declarative program generation to real-world software development.\n\nIn general, automatic code generation can be beneficial in various aspects, such as increasing development efficiency, reducing potential faults in code, and enhancing code maintainability and readability.The automatic Turducken-style code generation method is primarily intended to assist programmers who need to simultaneously write declarative and imperative programs during the development process, thereby increasing development efficiency and productivity.\n\nTurducken-style code is prevalent in real-world software development.Allamanis and Sutton (2013) observed that SQL is frequently used in conjunction with imperative programming languages, such as Java and Python.Moreover, we have retrieved Q&A posts on Stack Overflow with both keywords SQL and Java or SQL and Python in the past 10 years.The statistics are shown in Fig. 1 where we can find that the number of posts tagged by SQL and Java has been stable, while the number of posts tagged by SQL and Python has  increased steadily due to the growing popularity of Python.Table 1 presents a real-world post from Stack Overflow1 In this post, the user had successfully constructed a SQL statement query, but encountered difficulties in embedding it into a Java program.This illustrates the challenges faced by developers who are not proficient in imperative programming languages when attempting to write Turducken-style code in the software development process.\n\nIn previous studies (Ahmad et al. 2021;Wang et al. 2021b;Niu et al. 2022;Chakraborty et al. 2022), a prevalent approach is to directly fine-tune pre-trained language models (PLMs) to generate code.However, this approach has a severe limitation, i.e., the generated code may not follow the syntactic rules of the targeted programming language (Dong et al. 2022), which can result in the failed compilation.This issue is particularly serious for domain-specific datasets.For example, in the field of exploit code generation, the two previous studies (Liguori et al. 2021;Yang et al. 2023) both exhibited that even the most advanced pre-training models can generate code that is lexically similar.Therefore, there is still room for improvement in terms of grammatical accuracy.In data science code generation, (Huang et al. 2022) found that about 8% of the errors in the generated code are due to syntax issues.Similarly, (Liang et al. 2021) have demonstrated the feasibility of using pre-trained language models to generate Turducken-style code but also admitted the less accurate syntactic conformation.The purpose of the automatic code generation model is to improve the efficiency of software development through automation and intelligent techniques.However, if the generated code has syntax problems, developers may need to spend a lot of time fixing the defects in the code.Therefore, generating code that conforms to syntactic constraints is still a significant area of research within the field.Proposed solution.To address these issues, we propose a novel approach, i.e., Turducken-Gen, which is based on CodeT5 (Wang et al. 2021b) and multi-task learning.TurduckenGen proposes corresponding solutions from three perspectives.(1) The efficient representation of syntactic constraints.TurduckenGen uses the syntax rule description language to represent syntactic constraints.TurduckenGen first parses the code into an abstract syntax tree, transforming it from a serialized text representation into a syntax tree with rich structural information.Then TurduckenGen proposes the syntax augmented traversal (SAT) algorithm, which can capture the representation of syntactic constraints by traversing the abstract syntax tree of the original code and explicitly appending the type information of the parent node to the code tokens.We refer to code with syntactically constrained representations as syntax-guided code.(2) The effective integration of syntactic information.TurduckenGen formalizes syntax-guided code generation as an auxiliary task to enable the model to learn to generate code that adheres to syntactic constraints.Moreover, TurduckenGen employs a hard prompt method to facilitate the model's ability to distinguish the primary tasks and the auxiliary tasks.TurduckenGen employs the pre-training model CodeT5 to understand the user's functional description and learn both the target code and its corresponding code satisfying syntactic constraints.The encoder and decoder parameters are shared in the joint learning process, and the task-specific layers are customized in the final stage of mapping the semantic vector to the vocabulary.In order to incorporate the syntactic constraints learned in the auxiliary task into the primary task, TurduckenGen utilizes a gated linear unit for knowledge fusion.(3) The scalable syntax-first decoding algorithm.TurduckenGen proposes the syntax-first beam search (SF-Beam Search) method to maximize the ability of the model to generate syntax-correct code, where it can be easily integrated into existing pretrained models.Specifically, the syntactically correct code can be selected accurately from the multiple candidates with the help of the compiler feedback.\n\nTo evaluate the effectiveness of TurduckenGen, we conduct experiments on two Turducken-style code datasets Lyra and Pisces, where Lyra (Liang et al. 2021) is obtained from GitHub repositories and annotated by human annotators, whereas Pisces is obtained by manually translating the python code in Lyra into the corresponding Java code through a crowd-sourcing approach.TurduckenGen is compared to six state-of-the-art baselines, including Transformer (Vaswani et al. 2017), CodeBERT (Feng et al. 2020), Graph-CodeBERT (Guo et al. 2021), GPT (Radford et al. 2019), CodeGPT (Lu et al. 2021a), UniXcoder (Guo et al. 2022) and CodeT5 (Wang et al. 2021b), in terms of six automatic performance metrics (i.e., BLEU (Papineni et al. 2002), Weighted BLEU (Ren et al. 2020), Crystal BLEU (Eghbali and Pradel 2022), Code BLEU (Ren et al. 2020), Syntax Match (Ren et al. 2020), Syntax Exact Match (Liang et al. 2021), and Code Executable (Liang et al. 2021)).The comparison results show that TurduckenGen outperforms these baselines.Moreover, we design ablation studies to verify the effectiveness of multi-task learning and the method SF-Beam Search.Finally, from practitioners' perspectives on the generated Turducken-style code, we conduct a human evaluation to evaluate the quality of the generated code in terms of code readability and semantic similarity.The final results also show the competitiveness of our proposed approach.\n\nThe main contributions of our study can be summarized as follows.-We propose a novel approach TurduckenGen for generating syntax-guided Turduckenstyle code.By utilizing CodeT5 and multi-task learning, we can effectively integrate syntax knowledge into the generated code, while our proposed SAT algorithm and SF-Beam Search method can improve the ability of the model to capture the representation of syntactic constraints and generate syntax-correct code.-We conduct comprehensive experiments using both automatic evaluation metrics and human evaluation to assess the performance of TurduckenGen on two Turducken-style code datasets.The results of the evaluation indicate that TurduckenGen outperforms the state-of-the-art baselines.-To facilitate the replication and reuse of TurduckenGen, we develop an Integrated Development Environment (IDE) plug-in and make our source code, trained models, as well as the datasets in the GitHub repository publicly available2 .Structure The rest of the paper is organized as follows.Section 2 introduces the background of our work.Section 3 describes the framework of TurduckenGen and its key components.\n\nSection 4 presents the experimental design and result analysis.Human Evaluation and potential threats to validity are given in Sections 6 and 7 respectively.Section 8 reviews the related work and emphasize the novelty of our study, and Section 9 concludes the paper.\n\n\nBackground\n\nIn this section, we provide an overview of the background of Turducken-style code, CodeT5, and multi-task learning.\n\n\nTurducken-style Code\n\nIn the neural code generation task, programming languages are typically classified into two categories: declarative and imperative programming languages.Declarative programming is a paradigm that expresses the logic of a computation without describing its control flow (Lloyd 1994).It can simplify writing parallel programs (Bailey 2009).Examples of declarative languages include database query languages (e.g., SQL, XQuery), regular expressions, markup languages (e.g., HTML, XAML), functional programming (e.g.Haskell, Scheme), and configuration management systems (e.g., Json, YAML).On the other hand, imperative programming is a paradigm that focuses on describing how a program should accomplish a task without specifying all the details of how the program should achieve the result (Gifford and Lucassen 1986).Imperative programming focuses on describing how a program runs step-by-step, rather than on a high-level description of its intended outcome.Examples of imperative languages include C, C++, Java, Python, and so on.\n\nTurducken-style code, which was first proposed by Liang et al. (2021), refers to a style of code where declarative programming is embedded within imperative programming.This type of code can be commonly found in real-world software systems.For example, SQL statements are often used with imperative programming in information management systems, and regular expressions are commonly used with imperative programming in data mining systems.\n\n\nCodeT5\n\nCodeT5 (Wang et al. 2021b) is an identifier-aware unified pre-trained encoder-decoder model for code understanding and generation, which is based on the Transformer architecture (Vaswani et al. 2017).It is pre-trained on the large-scale dataset CodeSearchNet (Husain et al. 2019) and BigQuery (Fernandes and Bernardino 2015), which includes eight programming languages (i.e., Go, Java, Javascript, PHP, Python, Ruby, C, and CSharp).To address out-of-vocabulary issues, CodeT5 utilizes a code-specific tokenizer based on the Byte-level BPE method.To take advantage of both bimodal and unimodal large-scale data, CodeT5 proposes four pre-training tasks: Masked Span Prediction (MSP), Identifier Tagging (IT), Masked Identifier Prediction (MIP), and Bimodal Dual Generation (BDG).\n\nThe MSP pre-training task takes a lexical perspective of the code, it utilizes a whole word span masking objective that randomly masks spans of arbitrary lengths and then predicts these masked spans combined with some sentinel tokens at the decoder.The IT and MIP pre-training tasks take a syntactic perspective of the code.It aims to notify the model with the knowledge of whether a code token is an identifier or not, and MIP masks all identifiers in the program language segment, which is inspired by obfuscation in the field of software engineering.The BDG pre-training task treats code generation and code summarization as dual tasks.To bridge the gap between the programming language and natural language, BDG leverages bimodal data to train the model for bidirectional conversion.\n\n\nMulti-task Learning\n\nMulti-task learning (MTL) is a machine learning paradigm.MTL aims to leverage useful information shared across multiple related tasks, which can improve the generalization performance on all tasks or enhance the model performance for a specific task by using auxiliary tasks (Liu et al. 2020a).MTL methods can be divided into hard or soft parameter sharing.In hard parameter sharing, the hidden layer is shared between all tasks, while keeping the output layer for several specific tasks.Intuitively, the more tasks that are learned simultaneously, the more representation of the tasks can be captured by the model, resulting in less risk of overfitting the primary task.In soft parameter sharing, each task has its own hidden layers and output layer.To ensure that the parameters of each task are similar, the distance between the parameters of each task is regularized.\n\nIn the Turducken-style code generation task, MTL has a natural advantage due to the limited labeled data.From a data augmentation perspective, MTL aggregates training samples from datasets of multiple tasks, which is especially beneficial for low-resource tasks whose labeled dataset is sometimes too small to sufficiently train a model.In most cases, the augmented training dataset alleviates the risk of overfitting and leads to more robust models (S\u00e1nchez-Cartagena et al. 2021).Furthermore, MTL provides additional performance gains compared to data augmentation approaches, due to the learned shared knowledge.\n\n\nPrompt-based Learning\n\nPrompt-based learning (Liu et al. 2023b) is a strategy to train large language models (LLMs) so the same model can be used for different downstream tasks without re-training.Traditional strategies for training large language models (such as GPT-3 and BERT) require the model to be pre-trained with unlabeled data and then fine-tuned for specific tasks with labeled data.In contrast, prompt-based learning models can autonomously tune themselves for different tasks by transferring domain knowledge (Wang et al. 2022a) introduced through prompts.\n\nIn general, a prompt is a snippet of natural language text that is added to unlabeled data during the pre-training phase (Gao et al. 2021).The art of writing useful prompts is called prompt engineering.According to the flexibility of the inserted prompt, prompt tuning techniques can be categorized into two types, i.e., hard prompt (Gu et al. 2022) and soft prompt (Li and Liang 2021).The hard prompt is a technique that modifies the model input by adding fixed natural language instruction (prompts), and the tokens in the soft prompt are continuous vectors that can be learned during the tuning stage.\n\n\nApproach\n\nFigure 2 illustrates the overall framework of TurduckenGen.It mainly consists of two phases: Model Training Phase and Model Inference Phase.Model Training Phase mainly includes prompt construction, syntax constraint representation, and syntax information integration.Specifically, we build a prompt that consists of the task description.We also represent syntax constraints using a syntax tree and integrate syntax information into the model, which is used Fig. 2 Overview framework of our proposed approach to guide the model to generate syntactically correct code.Model Inference Phase mainly introduces the scalable syntax-first decoding algorithm SF-Beam Search.This algorithm is used to generate code by considering the feedback provided by the compiler.\n\nIn the rest of this section, we provide more details on these two phases to better illustrate the novelty of our approach.\n\n\nModel Training Phase\n\nTo train the model, we input the natural language functional descriptions of both the primary and auxiliary tasks.We use the template-based hard prompt method to allow the model to recognize and learn different tasks.Compared to continuous-based soft prompt methods, our method is prompted by a series of discrete tokens that are meaningful and understandable.For our task, we design the template by appending task-specific instructions as follows:\nf pr ompt ([T ASK ], [X ], [Y ]) = \"Generate [T ASK ] code : [X ] [Y ]\"(1)\nThis template explains that the model is to generate the code [Y] according to functional description [X] under the task [TASK].Specifically, the input of the auxiliary task is \"Generate syntax code: [X]\", and the output is a sequence that contains syntax information, which is referred to as \"syntax-guided code\".The input of the primary task is \"Generate origin code: Fig. 3 An example is used to illustrate how SAT traverses the AST of the source code [X]\", and the output is code sequence, which is referred to as \"original code\".Both the auxiliary task and the primary task use the model's output and ground truth to calculate the loss function, and the model parameters are updated through backward propagation.\n\nFigure 3 provides the process of the representation of syntactic constraints, and Fig. 4 provides an overview of the proposed network model architecture for the effective integration of syntactic information.In the rest of this section, we show the details of the representation of syntactic constraints (i.e., Syntax Augmented Traversal) and the integration of syntactic information (i.e., Model Architecture).\n\n\nSyntax Augmented Traversal\n\nTo facilitate the pre-trained language model to generate code that adheres to the target programming language's syntactic constraints, we propose a Syntax Augmented Traversal (SAT) algorithm for the efficient representation of syntactic constraints.This algorithm parses the AST of the source code and then converts it into a sequence of tokens annotated with syntactic information.The details of this algorithm can be found in Algorithm 1.\n\nStep 1. From the root node, we use a pair of XML-like flags to annotate the syntax type.\n\nStep 2.Then, we traverse the sub-trees of the root node by pre-order traversal.For a nonleaf node, a determination is made as to whether the node is a string, in which case the label 'STR' is utilized for the node.Conversely, the token value to the current node is employed.For a leaf node, its root node is incorporated into the XML-like flags.\n\nStep 3. Traversing all sub-trees by recursion, this process continues until all nodes are traversed.The result of this process is a syntax-guided code sequence.\n\nAn illustrative example is shown in Fig. 3. Different colors are assigned to the nodes in the AST in the figure for illustrative purposes.Specifically, the red nodes indicate identifiers in the code, which embody the lexical information of the code.For this type of nodes, their value is retained.The blue nodes imply the type of these identifiers.For this type of nodes, their type information is ignored.The green nodes represent the complete syntax constraint information of the code (e.g., module, block, and return_statement), and the first three characters of its type information are extracted as its syntactic information.SAT appends these green nodes' type information to the red nodes' tokens explicitly to incorporate syntactic constraints.This approach enables the preservation of syntactic information and the ability to revert back to the original code.\n\n\nModel Architecture\n\nThe architecture of TurduckenGen adheres to the Transformer (Vaswani et al. 2017 3) Task-specific Layers.They are designed to learn the mapping relationships of various tasks separately and to integrate the knowledge of the auxiliary task into the primary task using the Gated Linear Unit (GLU) network.Encoder.TurduckenGen first generates embedding vectors that capture the semantic meaning of tokens and their position within a functional description.For a functional description X , TurduckenGen firstly tokenizes it into a sequence of sub-words (i.e., X = x 1 , \u2022 \u2022 \u2022 , x m ) by the BPE algorithm (Raffel et al. 2020), where m is the length of the tokenized sequence.For each sub-word, TurduckenGen generates an [1x768] embedding vector and combines it into a matrix to represent the meaningful relationship between a given token and the other tokens.In addition, to capture the position of each token within a functional description, TurduckenGen employs the relative position encoding technique (Raffel et al. 2020).\n\nEncoder contains a stack of twelve layers of blocks, each block consists of two subcomponents: a multi-head self-attention layer with relative position encoding and a feedforward neural network.In contrast to the original Transformer, each sub-component in TurduckenGen is followed by a layer normalization and has a residual connection behind it.Given an input vector X , the first step is to create three main vectors (i.e., a query vector Q, a key vector K , and a value vector V ).Further, TurduckenGen computes the relative positional information P, where P is an edge representation for the two inputs in dot-product operation to determine the positional information between tokens.P is supplied to the model as an additional component to the K and V , and the final attention score is computed as follows:\nAttention(Q, K , V ) = softmax Q(K + P) T \u221a d k (V + P) (2)\nThus, for the embedding vector X , TurduckenGen first uses a layer normalization step and creates three vectors (Q, K , and V ), which are then fed into Multi-head Attention Layer.\nQ, K, V = LayerNorm(X ) (3)\nMulti-head attention mechanisms obtain h different representations of (Q, K , and V ).Then they concatenate the results and project the concatenation with a residual connection layer.\nhead i = Attention QW Q i , K W K i , V W V i (4) MultiHead(Q, K , V ) = Concat i (head i ) W (5) X atten = X + MultiHead(Q, K , V ) (6)\nFinally, TurduckenGen feeds X atten into the feed-forward layer (FFN) to generate the hidden state vector X hidden .\n\nX hidden = LayerNorm(X atten + FFN(X )) (7) Decoder In the decoder part, TurduckenGen also contains a stack of twelve layers of blocks, but each block consists of three sub-components: a masked multi-head self-attention layer with relative position encoding, a multi-head encoder-decoder attention layer with relative position encoding, and a feed-forward neural network.The feed-forward neural network is as same as that in the Encoder component, while the self-attention layer is similar to that in the encoder component except that it only deals with generated code tokens in the output sequence.Different from the self-attention layer, the encoder-decoder attention layer learns the relationship between the source functional description and the target code.The calculation of Y cross-atten is similar to self-attention.The Queries matrix Q comes from the output of the self-attention layer and the Key matrix K and Values matrix V from the output of the encoder component X hidden .Finally, TurduckenGen feeds Y cross-atten into the FFN to generate the hidden state vector Y hidden .\n\nTask-specific Layers Task-specific output layers are employed to generate task-specific outputs, which contain Auxiliary LM layer, Primary LM layer, and GLU layer.\n\nFor the auxiliary task, we append the prompt 'Generate syntax code:' to the functional description, denoted as X aux .Its corresponding decoder output vector is denoted as Y aux-hidden .The auxiliary LM layer is defined to produce the probability distribution of the syntax-guided code.\nP aux = Y aux-hidden W aux + b syn (8)\nFor the primary task, we append the prompt 'Generate origin code:' to the functional description, denoted as X pri .Its corresponding decoder output vector is denoted as Y pri-hidden .Both the Primary LM layer and the Gated Linear Unit (GLU) network are defined to generate the probability distribution of the Turducken-style code.\nP pri = Y pri-hidden W pri + b pri \u2297 \u03c3 Y pri-hidden W aux + b aux (9)\nThe GLU employed here is intended to integrate the code syntax knowledge obtained from the Auxiliary LM layer into the Primary LM layer for the purpose of enforcing syntactic constraints.The GLU allows the network to selectively attend to the output of the semantic vectors in the Auxiliary LM and Primary LM layers for the purpose of knowledge interaction and selection.Furthermore, the GLU possesses non-linear characteristics while also maintaining a linear path for the gradient, thereby reducing the issue of vanishing gradients (Dauphin et al. 2017).\n\nTo learn these two tasks jointly, the parameters of TurduckenGen are trained to minimize the sum of the cross-entropy losses of the two tasks.The final loss function is presented as follows.\n\nloss = min \u03b8 L Primar y (\u03b8 ) + L Auxiliar y (\u03b8 ) (10)\n\n\nModel Inference Phase\n\nDuring the model inference phase, the prompt template proposed in (1) is constructed to direct the trained model to generate the original code.The model output is the probability of each token.In the decoding phase, we propose a scalable syntax-first beam search (SF-Beam Search) method to generate the Turducken-style code.\n\nRecall that the beam search algorithm (Wiseman and Rush 2016) maintains a beam of k possible tokens token i t i = 1 k at each time step t, where k represents the beam size.The possible tokens are updated as follows: for each token token i t , it adds each of the corresponding k most probable candidates, resulting in at most k \u00c3k new tokens of size increased by 1. Then among these tokens, the k tokens with the highest likelihood are selected, thus obtaining the next step tokens token i t+1 k i=1 .However, the beam search algorithm aims at optimizing likelihood and ignores the code syntax, thus we cannot guarantee that the code decoded by beam search can be compiled and executed correctly.\n\nOur proposed Syntax First Beam Search (SF-Beam Search) method is a simple yet effective solution that can be easily integrated into existing models.The SF-Beam Search method is based on our observation that there is a subtle gap between likelihood and code syntax.The likelihood of a code sequence indicates the maximum probability between tokens, but it does not ensure that the code is syntactically correct.To fill this gap, the SF-Beam Search method takes the k candidate code generated by the beam search algorithm and feeds them into a compiler tool in descending order of likelihood.If the current candidate code is executable, the SF-Beam Search method outputs it and terminates the loop.If all k candidate code are not executable, the SF-Beam Search method outputs the candidate code with the highest likelihood.\n\n\nExperimental Setup\n\n\nResearch Questions\n\nTo evaluate the effectiveness of our proposed approach TurduckenGen, we want to investigate the following four research questions (RQs).\n\n-RQ1: Can our proposed approach TurduckenGen outperform the state-of-the-art baselines?-RQ2: What is the contribution of the multi-task learning of TurduckenGen?-RQ3: What is the benefit of using SF-Beam Search method of TurduckenGen?-RQ4: What is the impact of different hard prompts of TurduckenGen?\n\nIn RQ1, we want to compare TurduckenGen with previous pre-trained code generation methods in terms of automatic evaluation metrics.In RQ2, we want to adopt two variants of the multi-task learning methods to investigate the impacts of the multi-task learning method on TurduckenGen.In RQ3, we want to analyze the effectiveness between the SF-Beam Search method in TurduckenGen and other different decoding methods to demonstrate its benefit.In RQ4, we want to further explore the impact of different hard prompts on the performance of TurduckenGen.\n\n\nDatasets\n\nThe Lyra dataset (Liang et al. 2021) which is for mapping functional descriptions to Turducken-style code, only considers Python code with embedded SQL.To improve the diversity of Turducken-style code generation, we used a crowd-sourcing approach to translate the Python code in Lyra into its corresponding Java code and modified the functional description.\n\nFinally, we construct a new high-quality dataset Pisces.The corpus contains 2,000 Turducken-style code and corresponding functional descriptions, which are in Java with embedded SQL.\n\nIn particular, the dataset Lyra is crawled from GitHub and rewritten code and comments by manual filtering.For the dataset Pisces, we hired two Java programmers with 3-5 years of development experience to label the dataset for 10 working days, with each of them spending 1-2 hours per day.They were paid a total of 1,200 Chinese yuan (CNY) as a reward.After the label work was completed, we used Maven to compile and check all the code to ensure the quality of the dataset.To ensure the quality of Lyra and Pisces, we also hired other six graduate student volunteers to review this dataset and discuss and fix the disputed data.Both Lyra and Pisces datasets have two different code styles (i.e., using native SQL and using Object Relational Mapper SQL).To ensure data consistency, ORM in Python uses SQLAlchemy3 , and ORM in Java uses JPA4 .Figure 5 shows an example to illustrate our used datasets.\n\nThe statistical information (such as the count of code snippets, average tokens in the code, and average tokens in the functional descriptions) of the Lyra and Pisces datasets is shown in Table 2.\n\n\nEvaluation Metrics\n\nTo give a comprehensive evaluation, we use six metrics (i.e., BLEU, Weight-BLEU, Crystal-BLEU, Syntax-Match, SyntaxExact-Match, Code-BLEU, and Code-Executable), which have been widely used in previous related studies (Hussain et al. 2020(Hussain et al. , b, 2021;;Yang et al. 2021bYang et al. , 2022a)), to automatically assess the quality of the generated code.BLEU (Papineni et al. 2002), Weight-BLEU (Ren et al. 2020), and Crystal-BLEU (Eghbali and Pradel 2022) perform code similarity computation from the lexical perspective.Specifically, BLEU treats the generated code as the sentence in natural language, Weight-BLEU considers keywords in programming languages on the basis of BLEU, and Crystal-BLEU considers the inherent differences between source code and natural language, and optimizes the computation of N-grams in BLEU.Syntax-Match (Ren et al. 2020) and SyntaxExact-Match (Liang et al. 2021) perform code similarity computation from the syntax perspective.Syntax-Match (Liang et al. 2021) obtains all the sub-tree of the AST and then calculates the accuracy by comparing the candidate and reference sub-trees, while SyntaxExact-Match is the exact match of both AST and SQL statement, which also means the functional correctness of the generated code.Code-BLEU (Ren et al. 2020) is the mixed evaluation metric, which absorbs the strength of BLEU in the n-gram match and further injects code syntax via AST and code semantics via data-flow analysis.\n\nIn addition, Code-Executable (Wang et al. 2022b;Liang et al. 2021) is designed to calculate the executable rate of the generated code.Specially, for the Lyra dataset, we use Python 3.95 as the compiler and utilize the API provided by pylint6 for automated checking.For the Pisces dataset, we use JDK 1.87 as compiler and utilize the command mvn compile provided by Maven8 for automated checking.\n\nTo ensure the fairness of the experiment, we use the scripts provided by Ren et al. ( 2020) and Liang et al. (2021) to calculate the value of these metrics.These performance metrics range from 0 to 1, where larger values represent higher similarity.\n\n\nBaselines\n\nTo our best knowledge, there are no models specifically designed for Turducken-style code generation.There exists only an empirical study (Liang et al. 2021) on Turducken-style code generation and we use their selected methods as our baselines.We evaluate the competi-\n\n\nExperimental Settings\n\nIn our empirical study, Transformer is implemented by OpenNMT-py (Klein et al. 2017), other pre-trained models and corresponding tokenizers are loaded from the official repository Huggingface 9 and our used framework is Pytorch 10 .The hyper-parameters and their values used in our empirical study are summarized in Table 3, where optimizer, learning rate, and beam size are referenced to the parameters of CodeT5 (Wang et al. 2021b).We implement TurduckenGen using PyTorch 1.8 and all the experiments run on a computer with an Intel(R) Xeon(R) Silver 4210 CPU and the Tesla V100 SXM2 GPU with 32 GB memory.The running OS platform is Linux OS.\n\n\nTool Implementation\n\nTo help developers improve development efficiency, we have also developed an IDE plug-in based on our proposed approach.Our developed plug-in can be integrated into a range of IDEs under JetBrains 11 products (e.g.IDEA and PyCharm).We show the screenshot of our developed plug-in in Fig. 6.In our plug-in, developers first simply enter their functional requirements.Then they select these requirements with the mouse and right-click 'Turduck-Gen' in the shortcut menu.Finally, our plug-in can automatically generate the corresponding code.\n\n\nExperimental Results\n\n\nRQ1: Can our Proposed Approach TurduckenGen Outperform the State-of-the-Art Baselines?\n\nWe first apply our approach TurduckenGen and the baseline methods (i.e., Transformer, CodeBERT, GraphCodeBERT, GPT, CodeGPT, and CodeT5) on Lyra and Pisces, and compare their performance in terms of six automatic evaluation metrics.Then we use Wilcoxon signed-rank tests (Wilcoxon 1992) at the confidence level of 95% to check whether the performance differences are significant.Moreover, we use two samples to perform a qualitative analysis for our proposed approach.\n\nTable 4 shows the comparison results between TurduckenGen and the baselines.For both the Lyra and Pisces, TurduckenGen can achieve the best performance in terms of all the performance metrics.Specifically, in terms of BLEU, Weight-BLEU, Crystal-BLEU, and Code-BLEU, TurduckenGen can improve the performance by at least 2.31%, 2.94%, 2.84%, and 3.08% in Lyra, and by at least 4.46%, 4.38%, 10.05%, and 3.88% in Pisces.This demonstrates that TurduckenGen can generate more precise code at the lexical level.In terms of Syntax-Match and Syntax E xact-Match metrics, TurduckenGen can improve the performance by at least 4.47% and 13.33% in Lyra, and 3.08% and 66.67% in Pisces.This demonstrates that TurduckenGen is capable of generating code that not only matches syntax more accurately, but also with more similar semantics.In terms of Code-Executable metrics, TurduckenGen can achieve a 100% code execution rate on both Lyra and Pisces.This demonstrates that TurduckenGen generates more syntactically correct code.\n\nIn addition, we conduct a Wilcoxon signed-rank test (Wilcoxon 1992) with a significance level of 0.05 to assess the statistical significance of the performance differences between TurduckenGen and the state-of-the-art baseline CodeT5.The Wilcoxon signed-rank test is a two-sided test by default, which means that it tests the null hypothesis that there is no significant difference in performance between TurduckenGen and CodeT5, regardless of the direction of the difference.In our study, the null hypothesis is denoted as H 0 , i.e., there is no significant difference between TurduckenGen and the state-of-the-art baseline in terms of metrics BLEU, Weight-BLEU, Crystal-BLEU, Code-BLEU, and Syntax Match.The results are shown in Table 5.In this table, we find all the p-values are smaller than 5e-2.These statistical results lead to the rejection of the null hypothesis, which means that there exists a significant difference between our approach and baseline.Note that the results in Table 4 show that TurduckenGen can outperform other baselines.Therefore we can conclude that TurduckenGen achieves better performance than other baseline approaches significantly.\n\nFinally, we show two examples with the ground-truth code and the code generated by TurduckenGen and all baselines in the Lyra dataset and the Pisces dataset respectively.As shown in Fig. 7, the code generated by CodeBERT contains syntax errors and fails to compile successfully.Additionally, the code generated by GraphCodeBERT deviates from  7 The example of Turducken-style code generated by TurduckenGen and baselines in the Lyra dataset the user's specifications as indicated by error messages.An exception in the SQL statement is present in the code generated by GPT, specifically an extraneous The .Furthermore, the code generated by CodeGPT and CodeT5 may contain a bug, i.e., the generated code lacks the return branch of else , it will return jsonify(None) during code execution resulting in an exception.In contrast, the code generated by TurduckenGen can accurately reflects the functional requirements, though differing from the ground-truth code in terms of naming identifiers.As shown in Fig. 8, the code generated by CodeBERT, GraphCodeBERT, GPT, and CodeGPT all have problems in their SQL statements.While the code generated by CodeT5 is semantically consistent with the ground-truth code, it diverges in terms of code style, specifically in the utilization of native SQL statements as opposed to the ORM framework employed by the ground-truth code.Therefore, the code generated by TurduckenGen shows higher similarity to the ground-truth code, both in semantics and code style.Thus, we can observe that TurduckenGen can generate higher-quality code compared to baselines (Fig. 9).\n\n\nSummary for RQ1\n\nTurduckenGen can significantly outperform the baselines in terms of six performance metrics on both Lyra and Pisces.To demonstrate the significance of each component in our proposed multi-task learning framework, we conduct a comparison of our approach with three of its variants:\n\n-Variant_1 does not introduce task-specific layers.This variant uses the same model and learns different tasks according to the prompt.-Variant_2 does not introduce additional GLU for knowledge interaction.In this variant, the task-specific layers of the two tasks are separated and do not affect each other.-Variant_3 does not introduce the auxiliary task and only consider the impact of the primary task.This variant model only contains CodeT5 with prompt and SF-beam search.\n\nIn Table 6, We can verify the effectiveness of task-specific layers and GLU by comparing TurduckenGen and variants.Similar to RQ1, we use BLEU, Weight-BLEU, Crystal-BLEU, Code-BLEU, Syntax-Match, Syntax E xact-Match, and Code-Executable to evaluate the effectiveness of our proposed approach and these three variants.As shown in Table 6, our proposed approach TurduckenGen shows superior performance compared to the other three variants on all metrics.Specifically, we can notice that when TurduckenGen removes only the GLU, there is a decrease in both lexical and syntactic similarity when compared to Variant 2 in Lyra and Pisces.On the contrary, Variant 1 shows comparable performance to that of Variant 2. When TurduckenGen removes the multitask learning framework and considers only the Fig. 9 The framework structure of the different variants primary task, it can achieve lower performance than both variant 1 and variant 2 in terms of most metrics, especially on Syntax-Match and Code-Executable.These findings suggest that, within a multi-task learning framework, the inclusion or exclusion of task-specific layers does not have a significant impact on performance if there is no additional semantic interaction.Furthermore, we show the importance of multitask learning by comparing it with variant 3, which retains only prompt and SF-beam search compared to TurduckenGen, but is also can outperform CodeT5 with Code-Executable, which shows that the construction of prompt and compiler-based SF-beam search are also beneficial for CodeT5.Moreover, these results indicate that the incorporation of the GLU in TurduckenGen effectively embeds the grammatical knowledge acquired through the auxiliary task into the primary task, thereby improving the model's performance.\n\n\nSummary for RQ2\n\nDifferent from previous multi-task learning frameworks, we incorporate GLU after task-specific layers, which enables the incorporation of knowledge acquired through the auxiliary task into the primary task.Our study shows this setting can result in a positive impact on the performance of TurduckenGen.\n\n\nRQ3: What is the Benefit of Using the SF-Beam Search Method of TurduckenGen?\n\nTo investigate how the SF-Beam Search method affects the performance of TurduckenGen, we mainly consider three different decoding algorithms:\n\n-Sampling Search.It is a sampling algorithm with randomness.Compared to the algorithm by probability, this sampling algorithm can introduce more randomness and is often present in dialogue generation task (Liu et al. 2020b).-Greedy Search.It is a simple yet effective sampling algorithm that directly selects the token with the maximum probability for each output until a terminator appears or the maximum sentence length is reached.-Beam Search.It is a heuristic graph search algorithm that keeps top-k token nodes with the highest probability at each step, which can reduce the space and time cost occupied by the search.\n\nWe show the comparison results in Table 7 and we find that the SF-Beam Search method works best both on Lyra and Pisces.Compared with Sampling Search, Greedy Search, and Beam Search, our SF-Beam Search method outperforms them in all metrics, especially in code execution rate.Therefore, the results show the effectiveness of our proposed GE-BS method.\n\nFurthermore, as our SF-Beam Search method employs the beam search technique, the size of the beam size can have a direct impact on the performance of code generation.Thus, we conduct a comparison of the BLEU metric trends for code generated by the SF-Beam Search method and the beam search method for different beam sizes.\n\nLater, we conduct a time cost analysis when considering program compiler cost during beam search in our SF-Beam Search method.Specifically, we find that without optimization, the average time required for the program compiler is approximately 1\u223c2 seconds.This additional time cost resulted in a total time cost of approximately 15 seconds for each test sample when the beam search is set to 10.However, by using the multi-threading technology, the time cost for each test sample can be reduced to around 2\u223c3 seconds when the beam search is 10.\n\nFinally, we conduct a series of experiments for the influence of the hyper-parameter beam size.As shown in Fig. 10, we can observe that the performance of code generated by the beam search method exhibits fluctuations as the beam size increases, while the code generated by the SF-Beam Search method demonstrates higher stability.Furthermore, the quality of code generated by the SF-Beam Search method is higher than that of the beam search method when analyzing all the results.\n\n\nSummary for RQ3\n\nIn comparison to other decoding algorithms, the utilization of SF-Beam Search can result in a positive impact on the performance of Turducken-style code generation and demonstrates higher stability.\n\n\nRQ4: What is the Impact of Different Prompt Methods of TurduckenGen?\n\nIn our study, we manually define the natural language tokens in hard prompt templates.To explore the impact of hard prompts and other prompt methods on TurduckenGen, we analyzed the performance of different hard prompts, soft prompts, and mixed prompts in terms of seven automatic metrics in this RQ:\n\n-[X] [Y] means that the hard prompt is not used and relies only on the final LM layer for judgment.\n\n\n-[TASK] : [X] [Y]\n\nmeans to use the name of the task as the hard prompt, without adding any other prompt token.-Generate Turducken-Style code under [TASK] : [X] [Y] has the same meaning as the prompt used in TurduckenGen, but we add some tokens to make the prompt longer.-[SOFT] * n : [X] [Y] means to prepend several virtual tokens to the original input, which is referred as prefix-tuning (Li and Liang 2021) and is a typical method of soft prompt (Wang et al. 2022a).\n\n-\n\n\n[SOFT] * n+ Generate [TASK] code : [X]\n\n[Y] means adding several virtual tokens before the hard prompt, which is referred as mixed prompt (Longpre et al. 2023).\n\nWe follow the setting of Wang et al. (2022a) and set the value of the parameter n in the soft prompts and mixed prompts to 4. We show the comparison results in Table 8.In this table, we can find that the different prompts have a slight impact on the performance, and using hard prompt templates for TurduckenGen can achieve the best performance on both Lyra and Pisces in terms of most metrics.More importantly, a well-designed hard prompt template is particularly important.A good prompt can stimulate the potential of the model, but this may require the experts to rely on their own experience for tuning.Moreover, our results indicate a similarity in the model performance between the incorporation of solely the soft prompt and the absence of any prompt.However, the introduction of a mixed prompt can lead to optimal model performance in several metrics.This result shows the significance of the hard prompt and the possibility of improving model performance through the implementation of the soft prompt as a precursor to a well-designed hard prompt.\n\n\nSummary for RQ4\n\nWe demonstrate the importance of different prompt methods and find only welldesigned prompts can have a positive impact on the performance of TurduckenGen.\n\n\nHuman Evaluation\n\nIn RQ1, we conducted performance comparisons automatically in terms of six performance metrics.However, in the absence of test cases, these automatic performance metrics may not truly reflect the semantic similarity between different code snippets.To alleviate this issue, we further conducted a human evaluation to verify the effectiveness of our proposed approach TurduckenGen.In our human study, we only compare TurduckenGen with CodeT5, which can achieve the best performance in all baselines.\n\nWe refer to the methodology used by Hu et al. (2022) and Yang et al. (2022c) to conduct the human evaluation in the code generation task.In the human study, we evaluate the quality of the generated code from three aspects:\n\n-Code Readability.It evaluates the code readability of the generated code.For example, Java code should follow DRAFT 12 and Python code should follow PEP 8 13 .-Semantic Similarity.It evaluates the semantic similarity between the generated code and the reference code since the code snippets with the same semantics may differ at the lexical level.-User Preference.It evaluates the users' preference score between the reference code and code generated by the two methods, which can represent the real preferences of the users and avoid the bias caused by the provided ground truth.\n\nThe scores of Code Readability and Semantic Similarity range from 0 to 4 (the higher the better) and all these scores are integers.In consideration of User Preference, we designed it as a choice question, where volunteers were asked to select the one or more codes they think best from three candidate codes (i.e., the reference code, the code generated by CodeT5, and the code generated by TurduckenGen).We invite five volunteers, who have 3\u223c5 years of Java and Python experience and have good English reading ability.Then we paid a certain fee for each participant in their code evaluation work.Due to the high cost of manually analyzing all these samples in the testing set, we randomly select 100 Turducken-style code snippets and functional descriptions by following Hu et al. (2021).Specifically, we randomly selected 50 samples from the Lyra and 50 samples from the Pisces.To avoid any potential bias (i.e., answer leakage) caused by previously sampled individuals in the Code Readability and Semantic Similarity stages, we randomly selected new 50 samples for the User Preference questionnaire for the same group of volunteers.\n\nFor each code snippet, we generate a questionnaire for each participant, which is shown in Figs.11 and 12.\n\nIn the questionnaire used to evaluate Code Readability and Semantic Similarity, there are two code snippets generated by TurduckenGen and the baseline CodeT5 respectively.Each participant is asked to score each code in terms of code readability and semantic similarity for two code snippets generated by TurduckenGen and the baseline CodeT5 respectively.In the questionnaire used to evaluate user preference, there are three code snippets, which contain the reference code, the code generated by TurduckenGen, and the code generated by CodeT5 respectively.Since there is the possibility of the exact match between these three code snippets, each participant is asked to choose one or more codes that best match the functional description.During the code quality evaluation process, the participants can discuss and resort to external resources (e.g., Wikipedia and Q&A websites).To ensure the fairness of the comparison, the participants do not know which code is generated by which approach, and the order of questionnaires is different for different participants.To guarantee the code evaluation quality, we need each participant to review only 25 code snippets in half a day to avoid fatigue.\n\nFigures 13 and 14 show the statistical results of this feedback in terms of code readability and semantic similarity.In these two figures, the left and right sub-figures show the votes for the Turducken-style code generated by CodeT5 and TurduckenGen, respectively.In terms of code readability, we find that 83% of the human ratings for the code generated by TurduckenGen are not less than 3, which means that they are considered to have good programming specifications and can be easily comprehended by the user.In terms of semantic similarity, we find that 87% of the human ratings for the code generated by TurduckenGen are not less than 3, which means they are considered to have good quality and can be used as code without major modifications.\n\nWe also compute the average score of the participants' feedback and the results are shown in Table 9.In this table, values in parentheses indicate the degree of consistency of the scores marked by the participants using Kendall's coefficient of concordance (Legendre 2005).Notice the value of Kendall's coefficient of concordance ranges from 0 to 1, with larger values indicating higher concordance.Based on the results, we can find that for the Lyra, TurduckenGen can outperform the approach CodeT5 by 0.340 and 0.516 respectively in terms of code readability and semantic similarity.For example, in the corpus Pisces, TurduckenGen can outperform the approach CodeT5 by 0.424 and 0.720 respectively in terms of code readability and semantic similarity.In addition, all Kendall's coefficient of concordance in our human evaluation is larger than 0.5, which indicates their scores are about the same degree of concentration.\n\nAs for user preference, we first calculate the score for each volunteer, which is the proportion of times they chose the reference code, the code generated by CodeT5, and the code  generated by TurduckenGen over all questionnaires.Then, we average the scores of all volunteers to obtain the final score.Based on the results, we can find that regardless of Lyra or Pisces, volunteers tend to prefer the reference code.Secondly, volunteers generally believe that the code generated by TurduckenGen is better than the code generated by CodeT5, indicating that volunteers are more inclined towards the code generated by TurduckenGen.\n\nTherefore, our human study can further verify the competitiveness of TurduckenGen.\n\n\nThreats to Validity\n\n\nConstruct Validity\n\nThe first construct validity concerns the appropriateness of our evaluation metrics.To mitigate this construct threat, we consider six evaluation metrics.Additionally, we also compute the pvalue by utilizing the Wilcoxon signed-rank test to further verify the statistical significance of our proposed approach.The second construct is the semantic correctness of the code generated by TurduckenGen.Due to the lack of high-quality test cases, we mainly conduct a human evaluation and assess the effectiveness of TurduckenGen by taking into account the code readability and semantic similarity of the generated Turducken-style code.\n\net al. 2021).The third internal threat is that our proposed architecture is specifically designed for pre-trained encoder-decoder models, such as CodeT5.Our approach is not applicable to other pre-trained models, such as CodeBERT, GPT, GraphCodeBERT, etc.This is because CodeBERT-like models are only pre-trained on the encoder side, while our multi-task learning approach operates on the decoder side.On the other hand, GPT-like models are only pretrained on the decoder side, while the prompt method proposed by our approach relies more heavily on the encoder side.Therefore, we believe that our method is only suitable for pretrained encoder-decoder models, such as CodeT5.\n\n\nExternal Validity\n\nExternal validity refers to the extent to which the findings of a study can be generalized to other datasets.In our study, we mainly focused on Turducken-style code generation.The main difference between generating Turducken-style code and general code is the nested nature of Turducken-style code (i.e.declarative programs are embedded in imperative programs).\n\nIn addition, it is more common for programmers to write Turducken-style code in real business development scenarios.However, our approach is essentially independent of specific programming languages, meaning that it has a certain degree of generality.By adjusting the training data and fine-tuning the model, our proposed approach can be applied to general code generation tasks.Meanwhile, the corresponding compiler needs to be replaced for a specific programming language in order to parse the AST and perform the SF-Beam Search decoding.\n\n\nRelated Work\n\nIn this section, we mainly summarize related studies for automatic code generation, multitask learning for code intelligence, and abstract syntax tree traversal methods.After related work analysis, we emphasize the novelty of our study.\n\n\nAutomatic Code Generation\n\nIn the field of automatic code generation for declarative programming, most researchers focused on the automatic generation of SQL statements.Dahl et al. (1994) were the first to investigate this area and shared the ATIS dataset for the Airline Travel Query domain.Then, a growing number of researchers explored and constructed various datasets for automatic SQL generation.For example, some datasets (Zelle and Mooney 1996;Iyer et al. 2017) focus on a single domain and other datasets (Zhong et al. 2017;Yu et al. 2018bYu et al. , 2019b, a) , a) encompass multiple domains and cover diverse SQL types.Early studies (Popescu et al. 2003;Mahmud et al. 2015) primarily employed rule-based approaches.However, these methods required pre-defined templates for SQL statements and had poor scalability.With the advent of neural network models, the majority of work in this field has shifted towards generating more flexible SQL statements with a wider range of styles.Yu et al. (2018b) modeled SQL generation as a neural translation task and employed an RNN-based Seq2Seq model for this purpose.Yu et al. (2018a) additionally incorporated Schema Linking in the encoder and added Sketch information in the decoder.Bogin et al. (2019) then used GNN as the encoder and LSTM as the decoder and incorporated grammar information.With the emergence of Transformer (Vaswani et al. 2017), more researchers (Wang et al. 2020;Lin et al. 2020;Huang et al. 2021;Rubin and Berant 2021) applied this technique to SQL generation tasks and considered domain-specific language information to improve performance.Recently, inspired by pre-trained language models, (Scholak et al. 2021) applied the T5 model and achieved state-of-the-art performance.\n\nFor the automatic code generation of imperative programming, (Mou et al. 2015) were the first to propose the use of a standard encoder-decoder architecture based on RNN to generate corresponding C++ code snippets from user functional descriptions.Ling et al. (2016) proposed two new corpora for card games code and employed the LSTM to construct the encoder-decoder architecture, which incorporates character-level softmax and pointer networks.Yin and Neubig (2018) proposed TRANX, a model based on ASDL, LSTM, the attention mechanism, and the copy mechanism for Python code generation.Hayati et al. (2018) proposed RECODE, which is based on TRANX and integrates information retrieval methods into the Seq2Seq model.Wei et al. (2019) and Yang et al. (2022b) formalized the code generation task and code summarization task as dual tasks and improved model performance through dual learning.Sun et al. (2019) designed a grammar-based structural convolutional neural network for code generation that generated a program by predicting the programming language's grammar rules and subsequently proposed a novel tree-based neural architecture TreeGen (Sun et al. 2020) based on Transformer.With the development of pre-trained language models for code-related tasks, (Liguori et al. 2021) and (Yang et al. 2022c) applied CodeBERT to the exploit code generation task.Lu et al. (2021b) proposed CodeGPT, (Ahmad et al. 2021) proposed PLBART, and (Wang et al. 2021b) proposed CodeT5 for improved Java code generation task.Recently, researchers (Wang et al. 2022b;Le et al. 2022) combined pre-trained language models and reinforcement learning to optimize pretrained language models from the perspective of code compilability.\n\nFor the automatic Turducken-style code generation, to our best knowledge, there was only one study (Liang et al. 2021).They used Encoder-Only pre-trained models and Decoder-Only pre-trained models to conduct experiments on the Lyra dataset to demonstrate the potential possibility of Turducken-style code generation.\n\nIn contrast to previous studies, our goal is to generate syntactically correct Turducken-style code, and we consider the learning paradigm of multi-task learning to construct ingenious auxiliary tasks.Moreover, we propose a syntax-first decoding algorithm to satisfy the syntax of the generated code.\n\n\nMulti-task Learning for Code Intelligence\n\nMulti-task learning (MTL) is a machine learning technique that allows a model to learn multiple tasks simultaneously by sharing common features or representations.In the field of code intelligence, multi-task learning has been applied to various tasks, such as code understanding, code summarization, and code completion.Wang et al. (2021a) proposed a multi-task learning approach MulCode for source code understanding.This approach learns unified representation space for tasks, with the pre-trained BERT model for the token sequence and the Tree-LSTM model for abstract syntax trees.MulCode achieves promising performance on three downstream tasks: comment classification, author attribution, and duplicate function detection.For the code summarization task, (Xie et al. 2021) proposed a deliberation multi-Task learning approach DMACOS by exploiting method names to improve code summarization.They introduced the tasks of generation and informativeness prediction of method names as two auxiliary training objectives for code summarization.Then they incorporated a novel two-pass deliberation mechanism into their MTL architecture.For the code completion task, (Liu et al. 2020a) and (Liu et al. 2022) adopted multi-task learning to predict the token and its type jointly and utilize the predicted type to assist the token prediction.In summary, multi-task learning can be used to improve the performance of code intelligence tasks by allowing models to learn multiple tasks and share common features or representations.\n\nCompared with previous multi-task learning studies that were used for code intelligence, our approach designs a syntax-guided auxiliary task using for code-based generation and uses a GLU network to incorporate the syntax knowledge learned from the auxiliary task into the primary task.Empirical results show the promising performance of our proposed approach.\n\n\nAbstract Syntax Tree Traversal Methods\n\nAn Abstract Syntax Tree (AST) is a tree representation of the abstract structure of source code written in a programming language.Researchers usually use AST to extract syntactic knowledge of the code.In the field of code comment generation, (Yang et al. 2021a) proposed Sim_SBT, which uses pre-order traversal to flatten the type nodes of the AST.Hu et al. (2020) and Niu et al. (2022) proposed SBT and X-SBT, respectively.They also used pre-order traversal, along with brackets and xml-like tags to form structured data.In the field of code translation, (Liu et al. 2023a) captured the structural information of the AST by modeling the node distances and the node paths.\n\nDifferent from previous AST traversal methods, our proposed SAT traversal method takes into account both the type and value of nodes in the AST.By incorporating the type information of the parent node into the code tokens explicitly, using our proposed SAT traversal method can help to generate code, which satisfy syntactic constraints.\n\n\nConclusion and Future Work\n\nIn this study, we propose a novel approach TurduckenGen for Turducken-style code generation, where TurduckenGen addresses the challenge of syntactic constraints on code generation from three perspectives.The results of the automated evaluation show that our proposed TurduckenGen outperforms the state-of-the-art baselines on Lyra and Pisces.Moreover, we also verify our SF-Beam Search decoding method and model components rationality of TurduckenGen by designing a set of ablation studies.Finally, We conduct a human study to evaluate the quality of the generated code in terms of code readability and semantic similarity from the practitioner's perspective.\n\nIn the future, we first want to further improve the performance of TurduckenGen by considering advanced code representation methods.We second want to explore more types of Turducken-style code generation tasks to promote the practical application of our study, such as generating programs with regular expressions embedded in Java or Python and JavaScript embedded in HTML.\n\nFig. 1\n1\nFig. 1 The number of related posts in Stack Overflow by year\n\n\n\n\nFig.4The structure of the multi-task learning used in our neural network\n\n\nFig. 5\n5\nFig. 5 An example in the Lyra and Pisces datasets\n\n\nFig. 6\n6\nFig.6The screenshot of our developed IDE plug-in\n\n\nFig. 8\n8\nFig. 8 The example of Turducken-style code generated by TurduckenGen and baselines in the Pisces dataset\n\n\n\n\nFig.10The influence of the hyper-parameter beam size in Lyra and Pisces, where the horizontal axis denotes beam size and the vertical axis denotes the value of BLEU\n\n\nFig. 12 A\n12\nFig. 12 A questionnaire used to evaluate User Preference in our human evaluation\n\n\nFig. 13\n13\nFig. 13 Rating distribution of human evaluation in terms of code readability\n\n\nFig. 14\n14\nFig. 14 Rating distribution of human evaluation in terms of semantic similarity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 1 A\n1\nPost Related to Turducken-style Code Generation on Stack Overflow Title Using Spring JdbcTemplate to extract one string Can't seem to find a way to get one string from table using JdbcTemplate query.This is the table my sql returns: Content Now how am I supposed to get the value of STREET_NAME.SQL always returns one row, so no need to worry about returning more than one row.\nBut how can I extract \"Elm street\" from it using JdbcTemplate?Tagsjava, sql, hsqldb, jdbctemplate\n\nTable 2\n2\nStatistical information of our used Lyra and Pisces datasets\nCorpusTypeTrainValidTestLyraCount1,600200200Avg. token in NL47.1847.4247.27Avg. token in CODE57.9458.5157.66PiscesCount1,600200200Avg. token in NL46.7345.6646.57Avg. token in CODE79.1589.2084.93\n\nTable 3\n3\n(Guo et al. 2022)019)gs proposed approach against seven state-of-the-art pre-trained code generation baselines.Specifically, we classify these baselines into four groups.The first group is the original Transformer(Vaswani et al. 2017), which trains the model from the scratch.The second group is Encoder-Only pre-trained models, including CodeBERT(Feng et al. 2020)and GraphCodeBERT(Guo et al. 2021).The third group is Decoder-Only pre-trained models, including GPT(Radford et al. 2019)and CodeGPT(Lu et al. 2021a).The last group is Encoder-Decoder pre-trained model, including UniXcoder(Guo et al. 2022), CodeT5 (Wang  et al. 2021b).\nHyperparameterValueHyperparameterValueOptimizerAdamWSeed1234Learning Rate5e-5Training batch size16Beam size10Validation batch size16Max input length150Max output length256tiveness of our\n\nTable 4\n4\nThe comparison results between our proposed TurduckenGen and baselines\nCorpusApproachBLEUWeight-BCrystal-BCode-BS-MSE-MC-ELyraTransformer38.9739.5210.0046.4648.460.0015.00CodeBERT63.2963.9343.7068.7774.046.5059.50GraphCodeBERT67.3467.9150.4371.7876.268.5053.50GPT72.7673.1760.8877.2681.3621.5092.50CodeGPT73.2373.6563.5177.4180.3724.0096.00UniXcoder70.4570.3362.1070.1770.7318.5070.00CodeT576.5976.9767.8480.2583.2030.0095.50TurduckenGen78.3679.2369.7782.7286.9234.00100.00PiscesTransformer41.6642.1210.9149.3552.861.0074.00CodeBERT57.6558.4832.6761.0561.810.0093.50GraphCodeBERT60.2261.0538.0663.1662.681.0093.50GPT61.8862.8745.6064.5062.641.0089.50CodeGPT62.7563.6447.2865.3263.081.5089.50UniXcoder61.2762.2546.3564.4562.941.5094.50CodeT563.6964.3646.0265.9663.271.5097.00TurduckenGen66.5367.1852.0368.5265.222.50100.00\n\nTable 5\n5\nThe p-value between our proposed TurduckenGen and CodeT5 by using the Wilcoxon signed-rank test\nCorpusBLEUWeight-BLEUCrystal-BLEUCode-BLEUSyntax-MatchLyra2.6e-31.7e-44.2e-25.8e-41.4e-3Pisces3.0e-106.5e-113.1e-164.3e-117.2e-5\n\nTable 6\n6\nThe comparison results between our proposed TurduckenGen and two variants\nCorpusApproachBLEUWeight-BCrystal-BCode-BS-MSE-MC-ELyraVariant_177.6778.8669.1180.9685.4529.0099.00Variant_277.9378.7068.3781.2184.9530.50100.00Variant_376.9777.3268.1081.0384.2530.5097.50TurduckenGen78.3679.2369.7782.7286.9234.00100.00PiscesVariant_164.8466.5150.7466.4864.522.0099.50Variant_265.8565.9551.5967.2464.482.00100.00Variant_364.0465.2949.7566.3063.862.0098.00TurduckenGen66.5367.1852.0368.5265.222.50100.00\n\nTable 7\n7\nThe comparison results between SF-Beam Search and other decoding algorithms\nCorpusApproachBLEUWeight-BCrystal-BCode-BS-MSE-MC-ELyraSampling Search76.2676.9165.3879.5583.2329.0094.50Greedy Search77.8978.7569.1281.0784.8631.5096.50Beam Search78.0378.9469.1781.4486.0832.5097.00SF-Beam Search78.3679.2369.7782.7286.9234.00100.00PiscesSampling Search64.5264.4849.4866.2363.981.5096.50Greedy Search65.1266.0450.9866.9464.502.0097.00Beam Search66.0566.1551.8667.3664.982.0098.00SF-Beam Search66.5367.1852.0368.5265.222.50100.00\n\nTable 8\n8\nThe comparison results between different prompts\nC -E100.0099.5099.0099.50100.00100.00100.00100.0099.5099.0099.00100.00S E -M29.0033.0034.0032.0034.0034.002.002.002.502.002.502.50S -M84.9784.0685.4285.0486.7886.9264.6664.4464.5064.5165.1265.22Code-B82.4581.9282.5782.4782.7382.7267.9367.5867.9467.8768.1268.52Crystal-B69.5468.9069.1669.4969.6969.7751.4851.3851.2351.4452.0952.03Weight-B78.8978.4579.0679.0879.2479.2366.2365.8966.7666.1567.1267.18BLEU78.1677.6878.2878.1978.3278.3665.8465.2666.0465.2866.7466.53Approach[X] [Y][TASK] : [X] [Y]Generate Turducken-Style codeunder [TASK] : [X] [Y][SOFT]  *  n : [X] [Y][SOFT]  * n+Generate [TASK] code : [X] [Y]Generate [TASK] code : [X] [Y][X] [Y][TASK] : [X] [Y]Generate Turducken-Style codeunder [TASK] : [X] [Y][SOFT]  *  n : [X] [Y][SOFT]  * n+Generate [TASK] code : [X] [Y]Generate [TASK] code : [X] [Y]CorpusLyraPisces\nFig. 11 A questionnaire used to evaluate Code Readability and Semantic Similarity in our human evaluation\n\n\nTable 9\n9\nResults of our human study in terms of code readability, semantic similarity (values in parentheses indicate Kendall's coefficient of concordance in our human evaluation), and user preference\nDatasetApproachCode ReadabilitySemantic SimilarityUser PreferenceLyraReference--86.6%CodeT53.152 (0.533)3.136 (0.788)52.4%TurduckenGen3.492 (0.553)3.652 (0.843)68.5%PiscesReference--90.4%CodeT52.464 (0.771)2.472 (0.884)56.2%TurduckenGen2.888 (0.666)3.192 (0.756)64.7%\nhttps://stackoverflow.com/questions/29286725/\nhttps://github.com/NTDXYG/TurduckenGen\nEmpirical Software Engineering (2023) 28:141   \nPage 8 of 35 Empirical Software Engineering (2023) 28:141\nhttps://www.sqlalchemy.org\nhttps://spring.io/projects/spring-data-jpa\nhttps://www.python.org/downloads/release/python-390/\nhttps://github.com/PyCQA/pylint\nhttps://www.oracle.com/java/technologies/downloads/#java8\nhttps://maven.apache.org/\nPage 20 of 35 Empirical Software Engineering (2023) 28:141\nPage 34 of 35 Empirical Software Engineering (2023) 28:141\nAcknowledgementsThis work is supported by the National Natural Science Foundation of China (No. 62372232), the Natural Science Foundation of Jiangsu Province (No. BK20201292), the Collaborative Innovation Center of Novel Software Technology and Industrialization, the Open Project of Key Laboratory of Safety-Critical Software for Nanjing University of Aeronautics and Astronautics, Ministry of Industry and Information Technology (No. NJ2020022), and the Postgraduate Research & Practice Innovation Program of Jiangsu Province (No. KYCX23_0396).T. Chen is partially supported by an oversea grant from the State Key Laboratory of Novel Software Technology, Nanjing University (KFKT2022A03), Birkbeck BEI School Project (EFFECT), and National Natural Science Foundation of China (No. 62272397).Data Availibility StatementThe datasets generated during and analyzed during the current study are available in the Github repository (https://github.com/NTDXYG/TurduckenGen).DeclarationsConflict of Interest The authors declare that they have no conflict of interest.Authors and Affiliations\nTo alleviate this threat, we first check the code carefully and use mature libraries, such as PyTorch and Transformers. The second internal threat is the implementation of the baseline methods. To alleviate this threat, we try our best to fine-tune the pre-trained models (i.e., CodeBERT 14 , GraphCodeBERT 15 , GPT 16 , CodeGPT 1718 , and CodeT5 19 ). Moreover, the parameters for both CodeT5 and TurduckenGen are the same. Internal Validity The first internal threat is the potential defects in the implementation of our proposed method. as shown in Table 3. For the other baseline models, we followed the parameter setting of the previous study (Liang 14\n\nUnified pre-training for program understanding and generation. W Ahmad, S Chakraborty, B Ray, K W Chang, Proceedings of the 2021 Conference of the North American Chapter. the 2021 Conference of the North American ChapterHuman Language Technologies2021\n\nWhy, when, and what: analyzing stack overflow questions by topic, type, and code. M Allamanis, C Sutton, 10th Working conference on mining software repositories (MSR). IEEE2013. 2013\n\nM W Bailey, Workshop on declarative aspects of multicore programming. 2009. 2009. 2009\n\nRepresenting schema structure with graph neural networks for text-to-sql parsing. B Bogin, J Berant, M Gardner, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational Linguistics2019\n\nNatgen: generative pre-training by \"naturalizing\" source code. S Chakraborty, T Ahmed, Y Ding, P T Devanbu, B Ray, Proceedings of the 30th ACM joint european software engineering conference and symposium on the foundations of software engineering. the 30th ACM joint european software engineering conference and symposium on the foundations of software engineering2022\n\nExpanding the scope of the atis task: The atis-3 corpus. D A Dahl, M Bates, M K Brown, W M Fisher, K Hunicke-Smith, D S Pallett, C Pao, A Rudnicky, E Shriberg, Human language technology: proceedings of a workshop. Plainsboro, New Jersey1994. March 8-11, 1994\n\nLanguage modeling with gated convolutional networks. Y N Dauphin, Fan A Auli, M Grangier, D , International conference on machine learning. PMLR. 2017\n\nCodepad: Sequence-based code generation with pushdown automaton. Y Dong, X Jiang, Y Liu, G Li, Jin Z , 10.48550/ARXIV.2211.00818arXiv:2211.008182022\n\nCrystalbleu: precisely and efficiently measuring the similarity of code. A Eghbali, M Pradel, Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings. the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings2022\n\nCodebert: A pre-trained model for programming and natural languages. Z Feng, D Guo, D Tang, N Duan, X Feng, M Gong, L Shou, B Qin, T Liu, D Jiang, EMNLP. 20202020Findings of the Association for Computational Linguistics\n\nWhat is bigquery?. S Fernandes, J Bernardino, Proceedings of the 19th International Database Engineering & Applications Symposium. the 19th International Database Engineering & Applications Symposium2015\n\nMaking pre-trained language models better few-shot learners. T Gao, A Fisch, D Chen, Joint conference of the 59th annual meeting of the association for computational linguistics and the 11th international joint conference on natural language processing, ACL-IJCNLP 2021, Association for Computational Linguistics (ACL). 2021\n\nIntegrating functional and imperative programming. D K Gifford, J M Lucassen, Proceedings of the 1986 ACM conference on LISP and functional programming. the 1986 ACM conference on LISP and functional programming1986\n\nPpt: Pre-trained prompt tuning for few-shot learning. Y Gu, X Han, Z Liu, M Huang, Proceedings of the 60th annual meeting of the association for computational linguistics. Long Papers. the 60th annual meeting of the association for computational linguistics20221\n\nUnixcoder: Unified cross-modal pre-training for code representation. D Guo, S Ren, S Lu, Z Feng, D Tang, S Liu, L Zhou, N Duan, A Svyatkovskiy, S Fu, Proceedings of the 60th annual meeting of the association for computational linguistics. Long Papers. the 60th annual meeting of the association for computational linguistics2021. 20221Graphcodebert: Pre-training code representations with data flow\n\nRetrieval-based neural code generation. S A Hayati, R Olivier, P Avvaru, P Yin, A Tomasic, G Neubig, Proceedings of the 2018 conference on empirical methods in natural language processing. the 2018 conference on empirical methods in natural language processing2018\n\nDeep code comment generation with hybrid lexical and syntactical information. X Hu, G Li, X Xia, D Lo, Jin Z , Empir Softw Eng. 2532020\n\nAutomating user notice generation for smart contract functions. X Hu, Z Gao, X Xia, D Lo, X Yang, 10.1109/ASE51524.2021.967855236th IEEE/ACM international conference on automated software engineering (ASE). 2021. 2021\n\nPractitioners' expectations on automated code comment generation. X Hu, X Xia, D Lo, Wan Z Chen, Q Zimmermann, T , 10.1145/3510003.351015244th IEEE/ACM 44th International Conference on Software Engineering, ICSE 2022. Pittsburgh, PA, USAACM2022. May 25-27, 2022\n\nRelation aware semi-autoregressive semantic parsing for nl2sql. J Huang, Y Wang, Y Wang, Y Dong, Y Xiao, arXiv:2108.008042021\n\nExecution-based evaluation for data science code generation models. J Huang, C Wang, J Zhang, C Yan, H Cui, J P Inala, C Clement, N Duan, J Gao, arXiv:2211.093742022\n\nCodesearchnet challenge: Evaluating the state of semantic code search. H Husain, H H Wu, T Gazit, M Allamanis, M Brockschmidt, arXiv:1909.094362019\n\nCodegru: Context-aware deep learning with gated recurrent unit for source code modeling. Y Hussain, Z Huang, Y Zhou, S Wang, Inf Softw Technol. 1251063092020\n\nDeep transfer learning for source code modeling. Y Hussain, Z Huang, Y Zhou, S Wang, Int J Softw Eng Knowl Eng. 30052020\n\nImproving source code suggestion with code embedding and enhanced convolutional long short-term memory. Y Hussain, Z Huang, Y Zhou, IET Softw. 1532021\n\nLearning a neural semantic parser from user feedback. S Iyer, I Konstas, A Cheung, J Krishnamurthy, L Zettlemoyer, Proceedings of the 55th annual meeting of the association for computational linguistics. Long Papers. the 55th annual meeting of the association for computational linguistics20171\n\nOpennmt: Open-source toolkit for neural machine translation. G Klein, Y Kim, Y Deng, J Senellart, A M Rush, Proceedings of ACL 2017. ACL 20172017System Demonstrations\n\nCoderl: Mastering code generation through pretrained models and deep reinforcement learning. H Le, Y Wang, A D Gotmare, S Savarese, S C Hoi, arXiv:2207.017802022\n\nSpecies associations: the kendall coefficient of concordance revisited. P Legendre, J Agric Biol Environ Stat. 1022005\n\nPrefix-tuning: Optimizing continuous prompts for generation. X L Li, P Liang, Proceedings of the 59th annual meeting of the association for computational linguistics and the 11th international joint conference on natural language processing. Long Papers. the 59th annual meeting of the association for computational linguistics and the 11th international joint conference on natural language processing20211\n\nQ Liang, Z Sun, Q Zhu, W Zhang, L Yu, Y Xiong, L Zhang, arXiv:2108.12144Lyra: A benchmark for turducken-style code generation. 2021\n\nEvil: exploiting software via natural language. P Liguori, E Al-Hossami, V Orbinato, R Natella, S Shaikh, D Cotroneo, B Cukic, 2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE). IEEE2021\n\nBridging textual and tabular data for cross-domain text-to-sql semantic parsing. X V Lin, R Socher, C Xiong, EMNLP. 20202020Findings of the Association for Computational Linguistics\n\nLatent predictor networks for code generation. W Ling, P Blunsom, E Grefenstette, K M Hermann, T Ko\u010disk\u1ef3, F Wang, A Senior, Proceedings of the 54th annual meeting of the association for computational linguistics. Long Papers. the 54th annual meeting of the association for computational linguistics20161\n\nMulti-task learning based pre-trained language model for code completion. F Liu, G Li, Y Zhao, Jin Z , Proceedings of the 35th IEEE/ACM international conference on automated software engineering. the 35th IEEE/ACM international conference on automated software engineering2020a\n\nA unified multi-task learning model for ast-level and token-level code completion. F Liu, G Li, B Wei, X Xia, Z Fu, Jin Z , Emp Softw Eng. 2742022\n\nSyntax and domain aware model for unsupervised program translation. F Liu, J Li, L Zhang, arXiv:2302.039082023a\n\nPre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. P Liu, W Yuan, J Fu, Z Jiang, H Hayashi, G Neubig, ACM Comput Surv. 5592023\n\nYou impress me: Dialogue generation via mutual persona perception. Q Liu, Y Chen, B Chen, J G Lou, Z Chen, B Zhou, D Zhang, Proceedings of the 58th annual meeting of the association for computational linguistics. the 58th annual meeting of the association for computational linguistics2020b\n\nOn the reliability and explainability of automated code generation approaches. Y Liu, C Tantithamthavorn, Y Liu, L Li, arXiv:2302.095872023c\n\nPractical advtanages of declarative programming. J W Lloyd, GULP-PRODE. 11994\n\nS Longpre, L Hou, T Vu, A Webson, H W Chung, Y Tay, D Zhou, Q V Le, B Zoph, J Wei, arXiv:2301.13688The flan collection: Designing data and methods for effective instruction tuning. 2023\n\nCodexglue: A machine learning benchmark dataset for code understanding and generation. S Lu, D Guo, S Ren, J Huang, A Svyatkovskiy, A Blanco, C Clement, D Drain, D Jiang, D Tang, arXiv:2102.046642021a\n\nCodexglue: A machine learning benchmark dataset for code understanding and generation. S Lu, D Guo, S Ren, J Huang, A Svyatkovskiy, A Blanco, C B Clement, D Drain, D Jiang, D Tang, G Li, L Zhou, L Shou, L Zhou, M Tufano, M Gong, M Zhou, N Duan, N Sundaresan, S K Deng, S Fu, S Liu, Proceedings of the neural information processing systems track on datasets and benchmarks 1, NeurIPS Datasets and Benchmarks 2021. J Vanschoren, S Yeung, the neural information processing systems track on datasets and benchmarks 1, NeurIPS Datasets and Benchmarks 20212021b. December 2021\n\nA rule based approach for nlp based query processing. T Mahmud, K A Hasan, M Ahmed, Thc Chak, 2nd International conference on electrical information and communication technologies (EICT). IEEE2015. 2015\n\nL Mou, R Men, G Li, L Zhang, Jin Z , arXiv:1510.07211On end-to-end program generation from user intention by deep neural networks. 2015\n\nSpt-code: sequence-to-sequence pre-training for learning source code representations. C Niu, C Li, V Ng, J Ge, L Huang, B Luo, Proceedings of the 44th international conference on software engineering. the 44th international conference on software engineering2022. 2006. 2018\n\nBleu: a method for automatic evaluation of machine translation. K Papineni, S Roukos, T Ward, W J Zhu, Proceedings of the 40th annual meeting of the association for computational linguistics. the 40th annual meeting of the association for computational linguistics2002\n\nTowards a theory of natural language interfaces to databases. A M Popescu, O Etzioni, H Kautz, Proceedings of the 8th international conference on intelligent user interfaces. the 8th international conference on intelligent user interfaces2003\n\nLanguage models are unsupervised multitask learners. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, OpenAI blog. 1892019\n\nExploring the limits of transfer learning with a unified text-to-text transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, J Mach Learn Res. 2112020\n\nCodebleu: a method for automatic evaluation of code synthesis. S Ren, D Guo, S Lu, L Zhou, S Liu, D Tang, N Sundaresan, M Zhou, A Blanco, S Ma, arXiv:2009.102972020\n\nSmbop: Semi-autoregressive bottom-up semantic parsing. O Rubin, J Berant, Proceedings of the 5th workshop on structured prediction for NLP. the 5th workshop on structured prediction for NLP2021. 2021\n\nRethinking data augmentation for low-resource neural machine translation: A multi-task learning approach. V M S\u00e1nchez-Cartagena, M Espl\u00e0-Gomis, J A P\u00e9rez-Ortiz, F S\u00e1nchez-Mart\u00ednez, Proceedings of the 2021 conference on empirical methods in natural language processing. the 2021 conference on empirical methods in natural language processing2021\n\nPicard: Parsing incrementally for constrained auto-regressive decoding from language models. T Scholak, N Schucher, D Bahdanau, Proceedings of the 2021 conference on empirical methods in natural language processing. the 2021 conference on empirical methods in natural language processing2021\n\nA grammar-based structural cnn decoder for code generation. Z Sun, Q Zhu, L Mou, Y Xiong, G Li, L Zhang, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201933\n\nTreegen: A tree-based transformer architecture for code generation. Z Sun, Q Zhu, Y Xiong, Y Sun, L Mou, L Zhang, Proc AAAI Conf Art Intell. 342020\n\nAttention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, \u0141 Kaiser, I Polosukhin, Adv Neural Inf Process Syst. 302017\n\nRat-sql: Relation-aware schema encoding and linking for text-to-sql parsers. B Wang, R Shin, X Liu, O Polozov, M Richardson, Proceedings of the 58th annual meeting of the association for computational linguistics. the 58th annual meeting of the association for computational linguistics2020\n\nNo more fine-tuning? an experimental evaluation of prompt tuning in code intelligence. C Wang, Y Yang, C Gao, Y Peng, H Zhang, M R Lyu, Proceedings of the 30th ACM joint European software engineering conference and symposium on the foundations of software engineering. the 30th ACM joint European software engineering conference and symposium on the foundations of software engineering2022a\n\nMulcode: A multi-task learning approach for source code understanding. D Wang, Y Yu, S Li, Dong W Wang, J Qing, L , 2021 IEEE international conference on software analysis, evolution and reengineering (SANER). IEEE2021a\n\nCompilable neural code generation with compiler feedback. X Wang, Y Wang, Wan Y Mi, F Li, Y Zhou, P Liu, J Wu, H Jiang, X Liu, Q , ACL. 20222022Findings of the Association for Computational Linguistics\n\nCodet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. Y Wang, W Wang, S Joty, S C Hoi, Proceedings of the 2021 conference on empirical methods in natural language processing. the 2021 conference on empirical methods in natural language processing2021b\n\nCode generation as a dual task of code summarization. B Wei, G Li, X Xia, Z Fu, Jin Z , Adv Neural Inf Process Syst. 322019\n\nIndividual comparisons by ranking methods. F Wilcoxon, Breakthroughs in statistics. Springer1992\n\nSequence-to-sequence learning as beam-search optimization. S Wiseman, A M Rush, Proceedings of the 2016 conference on empirical methods in natural language processing. the 2016 conference on empirical methods in natural language processing2016\n\nExploiting method names to improve code summarization: A deliberation multi-task learning approach. R Xie, W Ye, J Sun, S Zhang, 2021 IEEE/ACM 29th international conference on program comprehension (ICPC). IEEE2021\n\nIn-ide code generation from natural language: Promise and challenges. F F Xu, B Vasilescu, G Neubig, ACM Trans Softw Eng Methodol (TOSEM). 3122022\n\nSead: End-to-end text-to-sql generation with schema-aware denoising. K Xuan, Y Wang, Y Wang, Z Wen, Y Dong, arXiv:2105.079112021\n\nComformer: Code comment generation via transformer and fusion method-based hybrid code representation. G Yang, X Chen, J Cao, S Xu, Z Cui, C Yu, K Liu, 2021 8th International conference on dependable systems and their applications (DSA). IEEE2021a\n\nFine-grained pseudo-code generation method via code feature extraction and transformer. G Yang, Y Zhou, X Chen, C Yu, 28th Asia-pacific software engineering conference (APSEC). IEEE2021b. 2021\n\nDualsc: Automatic generation and summarization of shellcode via transformer and dual learning. G Yang, X Chen, Y Zhou, C Yu, arXiv:2202.097852022a\n\nDualsc: Automatic generation and summarization of shellcode via transformer and dual learning. G Yang, X Chen, Y Zhou, C Yu, 10.1109/SANER53432.2022.00052IEEE international conference on software analysis, evolution and reengineering, SANER 2022. Honolulu, HI, USAIEEE2022b. March 15-18, 2022\n\nExploitgen: Template-augmented exploit code generation based on codebert. G Yang, Y Zhou, X Chen, X Zhang, T Han, T Chen, J Syst Softw. 1115772022c\n\nExploitgen: Template-augmented exploit code generation based on codebert. G Yang, Y Zhou, X Chen, X Zhang, T Han, T Chen, J Syst Softw. 1971115772023\n\nTranx: A transition-based neural abstract syntax parser for semantic parsing and code generation. P Yin, G Neubig, Proceedings of the 2018 conference on empirical methods in natural language processing: system demonstrations. the 2018 conference on empirical methods in natural language processing: system demonstrations2018\n\nTypesql: Knowledge-based type-aware neural text-to-sql generation. T Yu, Z Li, Z Zhang, R Zhang, D Radev, Proceedings of the 2018 Conference of the North American Chapter. Short Papers. the 2018 Conference of the North American ChapterHuman Language Technologies2018a2\n\nSpider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. T Yu, R Zhang, K Yang, M Yasunaga, D Wang, Z Li, J Ma, I Li, Q Yao, S Roman, Proceedings of the 2018 conference on empirical methods in natural language processing. the 2018 conference on empirical methods in natural language processing2018b\n\nCosql: A conversational text-to-sql challenge towards cross-domain natural language interfaces to databases. T Yu, R Zhang, H Er, S Li, E Xue, B Pang, X V Lin, Y C Tan, T Shi, Z Li, Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing. the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processingEMNLP-IJCNLP2019a\n\nSparc: Crossdomain semantic parsing in context. T Yu, R Zhang, M Yasunaga, Y C Tan, X V Lin, S Li, H Er, I Li, B Pang, T Chen, Proceedings of the 57th annual meeting of the association for computational linguistics. the 57th annual meeting of the association for computational linguistics2019b\n\nLearning to parse database queries using inductive logic programming. J M Zelle, R J Mooney, Proceedings of the national conference on artificial intelligence. the national conference on artificial intelligence1996\n\nV Zhong, C Xiong, R Socher, arXiv:1709.00103Generating structured queries from natural language using reinforcement learning. 20172\n\nPublisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. \n\na society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Springer Nature or its licensor\n", "annotations": {"author": "[{\"end\":110,\"start\":99},{\"end\":157,\"start\":111},{\"end\":171,\"start\":158},{\"end\":186,\"start\":172},{\"end\":196,\"start\":187},{\"end\":210,\"start\":197},{\"end\":223,\"start\":211}]", "publisher": null, "author_last_name": "[{\"end\":109,\"start\":105},{\"end\":118,\"start\":114},{\"end\":170,\"start\":166},{\"end\":185,\"start\":180},{\"end\":195,\"start\":193},{\"end\":209,\"start\":206},{\"end\":222,\"start\":218}]", "author_first_name": "[{\"end\":104,\"start\":99},{\"end\":113,\"start\":111},{\"end\":159,\"start\":158},{\"end\":165,\"start\":160},{\"end\":179,\"start\":172},{\"end\":192,\"start\":187},{\"end\":205,\"start\":197},{\"end\":217,\"start\":211}]", "author_affiliation": null, "title": "[{\"end\":81,\"start\":1},{\"end\":304,\"start\":224}]", "venue": null, "abstract": "[{\"end\":2009,\"start\":485}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b40\"},\"end\":2189,\"start\":2171},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":2503,\"start\":2488},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":3078,\"start\":3061},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":3095,\"start\":3078},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3187,\"start\":3168},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":3204,\"start\":3187},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":3489,\"start\":3470},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4449,\"start\":4422},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5355,\"start\":5336},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":5373,\"start\":5355},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":5389,\"start\":5373},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5413,\"start\":5389},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5676,\"start\":5658},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":5885,\"start\":5864},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":5902,\"start\":5885},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6142,\"start\":6123},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6253,\"start\":6235},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":6953,\"start\":6935},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9192,\"start\":9174},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":9511,\"start\":9490},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9540,\"start\":9522},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9574,\"start\":9557},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":9601,\"start\":9580},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":9628,\"start\":9611},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9656,\"start\":9640},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":9688,\"start\":9669},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":9770,\"start\":9748},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":9802,\"start\":9786},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9843,\"start\":9818},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":9872,\"start\":9855},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":9904,\"start\":9887},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9944,\"start\":9925},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9985,\"start\":9966},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":12312,\"start\":12300},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":12368,\"start\":12355},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12846,\"start\":12819},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":13133,\"start\":13114},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":13539,\"start\":13521},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":13713,\"start\":13692},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":13793,\"start\":13773},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":13838,\"start\":13807},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":15397,\"start\":15379},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":16458,\"start\":16427},{\"end\":16657,\"start\":16640},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":17134,\"start\":17116},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":17303,\"start\":17286},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":17513,\"start\":17498},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":17550,\"start\":17531},{\"end\":19341,\"start\":19335},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":22386,\"start\":22366},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":22927,\"start\":22907},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":23327,\"start\":23307},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":24894,\"start\":24891},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27388,\"start\":27368},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":30588,\"start\":30570},{\"end\":32453,\"start\":32433},{\"end\":32480,\"start\":32453},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":32497,\"start\":32480},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":32518,\"start\":32497},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":32605,\"start\":32583},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":32636,\"start\":32619},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":33078,\"start\":33062},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":33120,\"start\":33102},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":33217,\"start\":33199},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":33507,\"start\":33490},{\"end\":33727,\"start\":33708},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":33744,\"start\":33727},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":34191,\"start\":34172},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":34495,\"start\":34477},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":34717,\"start\":34698},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":35065,\"start\":35047},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":36238,\"start\":36224},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":37504,\"start\":37490},{\"end\":41205,\"start\":41129},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":43528,\"start\":43511},{\"end\":46487,\"start\":46484},{\"end\":46615,\"start\":46612},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":46737,\"start\":46718},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":46795,\"start\":46777},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":46962,\"start\":46941},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":47009,\"start\":46990},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":48768,\"start\":48752},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":48792,\"start\":48773},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":50311,\"start\":50295},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":52988,\"start\":52973},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":57074,\"start\":57056},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":57338,\"start\":57315},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":57355,\"start\":57338},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":57419,\"start\":57400},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":57434,\"start\":57419},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":57460,\"start\":57434},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":57551,\"start\":57530},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":57570,\"start\":57551},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":57893,\"start\":57876},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":58020,\"start\":58003},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":58140,\"start\":58121},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":58285,\"start\":58265},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":58323,\"start\":58305},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":58339,\"start\":58323},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":58357,\"start\":58339},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":58379,\"start\":58357},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":58573,\"start\":58553},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":58718,\"start\":58701},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":58905,\"start\":58887},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":59105,\"start\":59084},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":59246,\"start\":59226},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":59373,\"start\":59356},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":59397,\"start\":59378},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":59546,\"start\":59529},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":59801,\"start\":59785},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":59920,\"start\":59900},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":59944,\"start\":59926},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":60016,\"start\":59999},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":60054,\"start\":60035},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":60095,\"start\":60076},{\"end\":60192,\"start\":60173},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":60206,\"start\":60192},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":60474,\"start\":60455},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":61360,\"start\":61341},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":61797,\"start\":61781},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":62201,\"start\":62184},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":62223,\"start\":62207},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":63209,\"start\":63190},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":63312,\"start\":63296},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":63334,\"start\":63317},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":63521,\"start\":63504}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":65096,\"start\":65025},{\"attributes\":{\"id\":\"fig_1\"},\"end\":65173,\"start\":65097},{\"attributes\":{\"id\":\"fig_2\"},\"end\":65234,\"start\":65174},{\"attributes\":{\"id\":\"fig_3\"},\"end\":65294,\"start\":65235},{\"attributes\":{\"id\":\"fig_4\"},\"end\":65410,\"start\":65295},{\"attributes\":{\"id\":\"fig_5\"},\"end\":65579,\"start\":65411},{\"attributes\":{\"id\":\"fig_6\"},\"end\":65675,\"start\":65580},{\"attributes\":{\"id\":\"fig_7\"},\"end\":65765,\"start\":65676},{\"attributes\":{\"id\":\"fig_8\"},\"end\":65858,\"start\":65766},{\"end\":65863,\"start\":65859},{\"end\":65868,\"start\":65864},{\"end\":65873,\"start\":65869},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":66362,\"start\":65874},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":66629,\"start\":66363},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":67462,\"start\":66630},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":68295,\"start\":67463},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":68531,\"start\":68296},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":69036,\"start\":68532},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":69569,\"start\":69037},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":70558,\"start\":69570},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":71029,\"start\":70559}]", "paragraph": "[{\"end\":2751,\"start\":2025},{\"end\":3887,\"start\":2753},{\"end\":4351,\"start\":3889},{\"end\":5314,\"start\":4353},{\"end\":9037,\"start\":5316},{\"end\":10462,\"start\":9039},{\"end\":11608,\"start\":10464},{\"end\":11876,\"start\":11610},{\"end\":12006,\"start\":11891},{\"end\":13062,\"start\":12031},{\"end\":13503,\"start\":13064},{\"end\":14291,\"start\":13514},{\"end\":15080,\"start\":14293},{\"end\":15975,\"start\":15104},{\"end\":16592,\"start\":15977},{\"end\":17163,\"start\":16618},{\"end\":17769,\"start\":17165},{\"end\":18541,\"start\":17782},{\"end\":18665,\"start\":18543},{\"end\":19138,\"start\":18690},{\"end\":19931,\"start\":19214},{\"end\":20344,\"start\":19933},{\"end\":20815,\"start\":20375},{\"end\":20905,\"start\":20817},{\"end\":21252,\"start\":20907},{\"end\":21414,\"start\":21254},{\"end\":22283,\"start\":21416},{\"end\":23328,\"start\":22306},{\"end\":24142,\"start\":23330},{\"end\":24383,\"start\":24203},{\"end\":24595,\"start\":24412},{\"end\":24849,\"start\":24733},{\"end\":25939,\"start\":24851},{\"end\":26104,\"start\":25941},{\"end\":26392,\"start\":26106},{\"end\":26763,\"start\":26432},{\"end\":27390,\"start\":26834},{\"end\":27582,\"start\":27392},{\"end\":27637,\"start\":27584},{\"end\":27987,\"start\":27663},{\"end\":28685,\"start\":27989},{\"end\":29508,\"start\":28687},{\"end\":29688,\"start\":29552},{\"end\":29991,\"start\":29690},{\"end\":30540,\"start\":29993},{\"end\":30910,\"start\":30553},{\"end\":31094,\"start\":30912},{\"end\":31995,\"start\":31096},{\"end\":32193,\"start\":31997},{\"end\":33677,\"start\":32216},{\"end\":34074,\"start\":33679},{\"end\":34325,\"start\":34076},{\"end\":34607,\"start\":34339},{\"end\":35276,\"start\":34633},{\"end\":35839,\"start\":35300},{\"end\":36421,\"start\":35953},{\"end\":37436,\"start\":36423},{\"end\":38605,\"start\":37438},{\"end\":40204,\"start\":38607},{\"end\":40504,\"start\":40224},{\"end\":40983,\"start\":40506},{\"end\":42760,\"start\":40985},{\"end\":43082,\"start\":42780},{\"end\":43304,\"start\":43163},{\"end\":43929,\"start\":43306},{\"end\":44282,\"start\":43931},{\"end\":44606,\"start\":44284},{\"end\":45151,\"start\":44608},{\"end\":45632,\"start\":45153},{\"end\":45850,\"start\":45652},{\"end\":46223,\"start\":45923},{\"end\":46324,\"start\":46225},{\"end\":46797,\"start\":46346},{\"end\":46800,\"start\":46799},{\"end\":46963,\"start\":46843},{\"end\":48021,\"start\":46965},{\"end\":48196,\"start\":48041},{\"end\":48714,\"start\":48217},{\"end\":48938,\"start\":48716},{\"end\":49521,\"start\":48940},{\"end\":50658,\"start\":49523},{\"end\":50766,\"start\":50660},{\"end\":51963,\"start\":50768},{\"end\":52714,\"start\":51965},{\"end\":53639,\"start\":52716},{\"end\":54270,\"start\":53641},{\"end\":54354,\"start\":54272},{\"end\":55028,\"start\":54399},{\"end\":55706,\"start\":55030},{\"end\":56089,\"start\":55728},{\"end\":56631,\"start\":56091},{\"end\":56884,\"start\":56648},{\"end\":58638,\"start\":56914},{\"end\":60354,\"start\":58640},{\"end\":60672,\"start\":60356},{\"end\":60974,\"start\":60674},{\"end\":62543,\"start\":61020},{\"end\":62905,\"start\":62545},{\"end\":63620,\"start\":62948},{\"end\":63959,\"start\":63622},{\"end\":64649,\"start\":63990},{\"end\":65024,\"start\":64651},{\"end\":65095,\"start\":65035},{\"end\":65172,\"start\":65100},{\"end\":65233,\"start\":65184},{\"end\":65293,\"start\":65245},{\"end\":65409,\"start\":65305},{\"end\":65578,\"start\":65414},{\"end\":65674,\"start\":65594},{\"end\":65764,\"start\":65688},{\"end\":65857,\"start\":65778},{\"end\":66264,\"start\":65887},{\"end\":66434,\"start\":66374},{\"end\":67275,\"start\":66641},{\"end\":67544,\"start\":67474},{\"end\":68402,\"start\":68307},{\"end\":68616,\"start\":68543},{\"end\":69123,\"start\":69048},{\"end\":69629,\"start\":69581},{\"end\":70557,\"start\":70452},{\"end\":70761,\"start\":70570}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":19213,\"start\":19139},{\"attributes\":{\"id\":\"formula_1\"},\"end\":24202,\"start\":24143},{\"attributes\":{\"id\":\"formula_2\"},\"end\":24411,\"start\":24384},{\"attributes\":{\"id\":\"formula_3\"},\"end\":24732,\"start\":24596},{\"attributes\":{\"id\":\"formula_4\"},\"end\":26431,\"start\":26393},{\"attributes\":{\"id\":\"formula_5\"},\"end\":26833,\"start\":26764}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":4932,\"start\":4931},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":32192,\"start\":32191},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":34956,\"start\":34955},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":36430,\"start\":36429},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":38177,\"start\":38176},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":38433,\"start\":38432},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":40995,\"start\":40994},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":41321,\"start\":41320},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":43972,\"start\":43971},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":47132,\"start\":47131},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":52816,\"start\":52815}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2023,\"start\":2011},{\"attributes\":{\"n\":\"2\"},\"end\":11889,\"start\":11879},{\"attributes\":{\"n\":\"2.1\"},\"end\":12029,\"start\":12009},{\"attributes\":{\"n\":\"2.2\"},\"end\":13512,\"start\":13506},{\"attributes\":{\"n\":\"2.3\"},\"end\":15102,\"start\":15083},{\"attributes\":{\"n\":\"2.4\"},\"end\":16616,\"start\":16595},{\"attributes\":{\"n\":\"3\"},\"end\":17780,\"start\":17772},{\"attributes\":{\"n\":\"3.1\"},\"end\":18688,\"start\":18668},{\"attributes\":{\"n\":\"3.1.1\"},\"end\":20373,\"start\":20347},{\"attributes\":{\"n\":\"3.1.2\"},\"end\":22304,\"start\":22286},{\"attributes\":{\"n\":\"3.2\"},\"end\":27661,\"start\":27640},{\"attributes\":{\"n\":\"4\"},\"end\":29529,\"start\":29511},{\"attributes\":{\"n\":\"4.1\"},\"end\":29550,\"start\":29532},{\"attributes\":{\"n\":\"4.2\"},\"end\":30551,\"start\":30543},{\"attributes\":{\"n\":\"4.3\"},\"end\":32214,\"start\":32196},{\"attributes\":{\"n\":\"4.4\"},\"end\":34337,\"start\":34328},{\"attributes\":{\"n\":\"4.5\"},\"end\":34631,\"start\":34610},{\"attributes\":{\"n\":\"4.6\"},\"end\":35298,\"start\":35279},{\"attributes\":{\"n\":\"5\"},\"end\":35862,\"start\":35842},{\"attributes\":{\"n\":\"5.1\"},\"end\":35951,\"start\":35865},{\"end\":40222,\"start\":40207},{\"end\":42778,\"start\":42763},{\"attributes\":{\"n\":\"5.3\"},\"end\":43161,\"start\":43085},{\"end\":45650,\"start\":45635},{\"attributes\":{\"n\":\"5.4\"},\"end\":45921,\"start\":45853},{\"end\":46344,\"start\":46327},{\"end\":46841,\"start\":46803},{\"end\":48039,\"start\":48024},{\"attributes\":{\"n\":\"6\"},\"end\":48215,\"start\":48199},{\"attributes\":{\"n\":\"7\"},\"end\":54376,\"start\":54357},{\"attributes\":{\"n\":\"7.1\"},\"end\":54397,\"start\":54379},{\"attributes\":{\"n\":\"7.3\"},\"end\":55726,\"start\":55709},{\"attributes\":{\"n\":\"8\"},\"end\":56646,\"start\":56634},{\"attributes\":{\"n\":\"8.1\"},\"end\":56912,\"start\":56887},{\"attributes\":{\"n\":\"8.2\"},\"end\":61018,\"start\":60977},{\"attributes\":{\"n\":\"8.3\"},\"end\":62946,\"start\":62908},{\"attributes\":{\"n\":\"9\"},\"end\":63988,\"start\":63962},{\"end\":65032,\"start\":65026},{\"end\":65181,\"start\":65175},{\"end\":65242,\"start\":65236},{\"end\":65302,\"start\":65296},{\"end\":65590,\"start\":65581},{\"end\":65684,\"start\":65677},{\"end\":65774,\"start\":65767},{\"end\":65884,\"start\":65875},{\"end\":66371,\"start\":66364},{\"end\":66638,\"start\":66631},{\"end\":67471,\"start\":67464},{\"end\":68304,\"start\":68297},{\"end\":68540,\"start\":68533},{\"end\":69045,\"start\":69038},{\"end\":69578,\"start\":69571},{\"end\":70567,\"start\":70560}]", "table": "[{\"end\":66362,\"start\":66265},{\"end\":66629,\"start\":66435},{\"end\":67462,\"start\":67276},{\"end\":68295,\"start\":67545},{\"end\":68531,\"start\":68403},{\"end\":69036,\"start\":68617},{\"end\":69569,\"start\":69124},{\"end\":70451,\"start\":69630},{\"end\":71029,\"start\":70762}]", "figure_caption": "[{\"end\":65096,\"start\":65034},{\"end\":65173,\"start\":65099},{\"end\":65234,\"start\":65183},{\"end\":65294,\"start\":65244},{\"end\":65410,\"start\":65304},{\"end\":65579,\"start\":65413},{\"end\":65675,\"start\":65593},{\"end\":65765,\"start\":65687},{\"end\":65858,\"start\":65777},{\"end\":65863,\"start\":65861},{\"end\":65868,\"start\":65866},{\"end\":65873,\"start\":65871},{\"end\":66265,\"start\":65886},{\"end\":66435,\"start\":66373},{\"end\":67276,\"start\":66640},{\"end\":67545,\"start\":67473},{\"end\":68403,\"start\":68306},{\"end\":68617,\"start\":68542},{\"end\":69124,\"start\":69047},{\"end\":69630,\"start\":69580},{\"end\":70762,\"start\":70569}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4726,\"start\":4725},{\"end\":17790,\"start\":17789},{\"end\":18245,\"start\":18244},{\"end\":19590,\"start\":19589},{\"end\":19941,\"start\":19940},{\"end\":20021,\"start\":20020},{\"end\":21458,\"start\":21457},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":31945,\"start\":31944},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":35589,\"start\":35588},{\"end\":38795,\"start\":38794},{\"end\":38951,\"start\":38950},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":39615,\"start\":39614},{\"end\":40202,\"start\":40201},{\"end\":41783,\"start\":41782},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":45267,\"start\":45265},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":50765,\"start\":50756},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":51982,\"start\":51973}]", "bib_author_first_name": "[{\"end\":73386,\"start\":73385},{\"end\":73395,\"start\":73394},{\"end\":73410,\"start\":73409},{\"end\":73417,\"start\":73416},{\"end\":73419,\"start\":73418},{\"end\":73658,\"start\":73657},{\"end\":73671,\"start\":73670},{\"end\":73760,\"start\":73759},{\"end\":73762,\"start\":73761},{\"end\":73930,\"start\":73929},{\"end\":73939,\"start\":73938},{\"end\":73949,\"start\":73948},{\"end\":74190,\"start\":74189},{\"end\":74205,\"start\":74204},{\"end\":74214,\"start\":74213},{\"end\":74222,\"start\":74221},{\"end\":74224,\"start\":74223},{\"end\":74235,\"start\":74234},{\"end\":74554,\"start\":74553},{\"end\":74556,\"start\":74555},{\"end\":74564,\"start\":74563},{\"end\":74573,\"start\":74572},{\"end\":74575,\"start\":74574},{\"end\":74584,\"start\":74583},{\"end\":74586,\"start\":74585},{\"end\":74596,\"start\":74595},{\"end\":74613,\"start\":74612},{\"end\":74615,\"start\":74614},{\"end\":74626,\"start\":74625},{\"end\":74633,\"start\":74632},{\"end\":74645,\"start\":74644},{\"end\":74810,\"start\":74809},{\"end\":74812,\"start\":74811},{\"end\":74825,\"start\":74822},{\"end\":74827,\"start\":74826},{\"end\":74835,\"start\":74834},{\"end\":74847,\"start\":74846},{\"end\":74974,\"start\":74973},{\"end\":74982,\"start\":74981},{\"end\":74991,\"start\":74990},{\"end\":74998,\"start\":74997},{\"end\":75006,\"start\":75003},{\"end\":75008,\"start\":75007},{\"end\":75132,\"start\":75131},{\"end\":75143,\"start\":75142},{\"end\":75423,\"start\":75422},{\"end\":75431,\"start\":75430},{\"end\":75438,\"start\":75437},{\"end\":75446,\"start\":75445},{\"end\":75454,\"start\":75453},{\"end\":75462,\"start\":75461},{\"end\":75470,\"start\":75469},{\"end\":75478,\"start\":75477},{\"end\":75485,\"start\":75484},{\"end\":75492,\"start\":75491},{\"end\":75594,\"start\":75593},{\"end\":75607,\"start\":75606},{\"end\":75841,\"start\":75840},{\"end\":75848,\"start\":75847},{\"end\":75857,\"start\":75856},{\"end\":76157,\"start\":76156},{\"end\":76159,\"start\":76158},{\"end\":76170,\"start\":76169},{\"end\":76172,\"start\":76171},{\"end\":76377,\"start\":76376},{\"end\":76383,\"start\":76382},{\"end\":76390,\"start\":76389},{\"end\":76397,\"start\":76396},{\"end\":76656,\"start\":76655},{\"end\":76663,\"start\":76662},{\"end\":76670,\"start\":76669},{\"end\":76676,\"start\":76675},{\"end\":76684,\"start\":76683},{\"end\":76692,\"start\":76691},{\"end\":76699,\"start\":76698},{\"end\":76707,\"start\":76706},{\"end\":76715,\"start\":76714},{\"end\":76731,\"start\":76730},{\"end\":77027,\"start\":77026},{\"end\":77029,\"start\":77028},{\"end\":77039,\"start\":77038},{\"end\":77050,\"start\":77049},{\"end\":77060,\"start\":77059},{\"end\":77067,\"start\":77066},{\"end\":77078,\"start\":77077},{\"end\":77331,\"start\":77330},{\"end\":77337,\"start\":77336},{\"end\":77343,\"start\":77342},{\"end\":77350,\"start\":77349},{\"end\":77358,\"start\":77355},{\"end\":77360,\"start\":77359},{\"end\":77454,\"start\":77453},{\"end\":77460,\"start\":77459},{\"end\":77467,\"start\":77466},{\"end\":77474,\"start\":77473},{\"end\":77480,\"start\":77479},{\"end\":77675,\"start\":77674},{\"end\":77681,\"start\":77680},{\"end\":77688,\"start\":77687},{\"end\":77696,\"start\":77693},{\"end\":77698,\"start\":77697},{\"end\":77706,\"start\":77705},{\"end\":77720,\"start\":77719},{\"end\":77936,\"start\":77935},{\"end\":77945,\"start\":77944},{\"end\":77953,\"start\":77952},{\"end\":77961,\"start\":77960},{\"end\":77969,\"start\":77968},{\"end\":78067,\"start\":78066},{\"end\":78076,\"start\":78075},{\"end\":78084,\"start\":78083},{\"end\":78093,\"start\":78092},{\"end\":78100,\"start\":78099},{\"end\":78107,\"start\":78106},{\"end\":78109,\"start\":78108},{\"end\":78118,\"start\":78117},{\"end\":78129,\"start\":78128},{\"end\":78137,\"start\":78136},{\"end\":78237,\"start\":78236},{\"end\":78247,\"start\":78246},{\"end\":78249,\"start\":78248},{\"end\":78255,\"start\":78254},{\"end\":78264,\"start\":78263},{\"end\":78277,\"start\":78276},{\"end\":78404,\"start\":78403},{\"end\":78415,\"start\":78414},{\"end\":78424,\"start\":78423},{\"end\":78432,\"start\":78431},{\"end\":78523,\"start\":78522},{\"end\":78534,\"start\":78533},{\"end\":78543,\"start\":78542},{\"end\":78551,\"start\":78550},{\"end\":78700,\"start\":78699},{\"end\":78711,\"start\":78710},{\"end\":78720,\"start\":78719},{\"end\":78802,\"start\":78801},{\"end\":78810,\"start\":78809},{\"end\":78821,\"start\":78820},{\"end\":78831,\"start\":78830},{\"end\":78848,\"start\":78847},{\"end\":79105,\"start\":79104},{\"end\":79114,\"start\":79113},{\"end\":79121,\"start\":79120},{\"end\":79129,\"start\":79128},{\"end\":79142,\"start\":79141},{\"end\":79144,\"start\":79143},{\"end\":79305,\"start\":79304},{\"end\":79311,\"start\":79310},{\"end\":79319,\"start\":79318},{\"end\":79321,\"start\":79320},{\"end\":79332,\"start\":79331},{\"end\":79344,\"start\":79343},{\"end\":79346,\"start\":79345},{\"end\":79447,\"start\":79446},{\"end\":79556,\"start\":79555},{\"end\":79558,\"start\":79557},{\"end\":79564,\"start\":79563},{\"end\":79904,\"start\":79903},{\"end\":79913,\"start\":79912},{\"end\":79920,\"start\":79919},{\"end\":79927,\"start\":79926},{\"end\":79936,\"start\":79935},{\"end\":79942,\"start\":79941},{\"end\":79951,\"start\":79950},{\"end\":80085,\"start\":80084},{\"end\":80096,\"start\":80095},{\"end\":80110,\"start\":80109},{\"end\":80122,\"start\":80121},{\"end\":80133,\"start\":80132},{\"end\":80143,\"start\":80142},{\"end\":80155,\"start\":80154},{\"end\":80339,\"start\":80338},{\"end\":80341,\"start\":80340},{\"end\":80348,\"start\":80347},{\"end\":80358,\"start\":80357},{\"end\":80488,\"start\":80487},{\"end\":80496,\"start\":80495},{\"end\":80507,\"start\":80506},{\"end\":80523,\"start\":80522},{\"end\":80525,\"start\":80524},{\"end\":80536,\"start\":80535},{\"end\":80547,\"start\":80546},{\"end\":80555,\"start\":80554},{\"end\":80820,\"start\":80819},{\"end\":80827,\"start\":80826},{\"end\":80833,\"start\":80832},{\"end\":80843,\"start\":80840},{\"end\":80845,\"start\":80844},{\"end\":81108,\"start\":81107},{\"end\":81115,\"start\":81114},{\"end\":81121,\"start\":81120},{\"end\":81128,\"start\":81127},{\"end\":81135,\"start\":81134},{\"end\":81143,\"start\":81140},{\"end\":81145,\"start\":81144},{\"end\":81241,\"start\":81240},{\"end\":81248,\"start\":81247},{\"end\":81254,\"start\":81253},{\"end\":81391,\"start\":81390},{\"end\":81398,\"start\":81397},{\"end\":81406,\"start\":81405},{\"end\":81412,\"start\":81411},{\"end\":81421,\"start\":81420},{\"end\":81432,\"start\":81431},{\"end\":81535,\"start\":81534},{\"end\":81542,\"start\":81541},{\"end\":81550,\"start\":81549},{\"end\":81558,\"start\":81557},{\"end\":81560,\"start\":81559},{\"end\":81567,\"start\":81566},{\"end\":81575,\"start\":81574},{\"end\":81583,\"start\":81582},{\"end\":81839,\"start\":81838},{\"end\":81846,\"start\":81845},{\"end\":81866,\"start\":81865},{\"end\":81873,\"start\":81872},{\"end\":81951,\"start\":81950},{\"end\":81953,\"start\":81952},{\"end\":81981,\"start\":81980},{\"end\":81992,\"start\":81991},{\"end\":81999,\"start\":81998},{\"end\":82005,\"start\":82004},{\"end\":82015,\"start\":82014},{\"end\":82017,\"start\":82016},{\"end\":82026,\"start\":82025},{\"end\":82033,\"start\":82032},{\"end\":82041,\"start\":82040},{\"end\":82043,\"start\":82042},{\"end\":82049,\"start\":82048},{\"end\":82057,\"start\":82056},{\"end\":82255,\"start\":82254},{\"end\":82261,\"start\":82260},{\"end\":82268,\"start\":82267},{\"end\":82275,\"start\":82274},{\"end\":82284,\"start\":82283},{\"end\":82300,\"start\":82299},{\"end\":82310,\"start\":82309},{\"end\":82321,\"start\":82320},{\"end\":82330,\"start\":82329},{\"end\":82339,\"start\":82338},{\"end\":82457,\"start\":82456},{\"end\":82463,\"start\":82462},{\"end\":82470,\"start\":82469},{\"end\":82477,\"start\":82476},{\"end\":82486,\"start\":82485},{\"end\":82502,\"start\":82501},{\"end\":82512,\"start\":82511},{\"end\":82514,\"start\":82513},{\"end\":82525,\"start\":82524},{\"end\":82534,\"start\":82533},{\"end\":82543,\"start\":82542},{\"end\":82551,\"start\":82550},{\"end\":82557,\"start\":82556},{\"end\":82565,\"start\":82564},{\"end\":82573,\"start\":82572},{\"end\":82581,\"start\":82580},{\"end\":82591,\"start\":82590},{\"end\":82599,\"start\":82598},{\"end\":82607,\"start\":82606},{\"end\":82615,\"start\":82614},{\"end\":82629,\"start\":82628},{\"end\":82631,\"start\":82630},{\"end\":82639,\"start\":82638},{\"end\":82645,\"start\":82644},{\"end\":82783,\"start\":82782},{\"end\":82797,\"start\":82796},{\"end\":82996,\"start\":82995},{\"end\":83006,\"start\":83005},{\"end\":83008,\"start\":83007},{\"end\":83017,\"start\":83016},{\"end\":83028,\"start\":83025},{\"end\":83146,\"start\":83145},{\"end\":83153,\"start\":83152},{\"end\":83160,\"start\":83159},{\"end\":83166,\"start\":83165},{\"end\":83177,\"start\":83174},{\"end\":83179,\"start\":83178},{\"end\":83369,\"start\":83368},{\"end\":83376,\"start\":83375},{\"end\":83382,\"start\":83381},{\"end\":83388,\"start\":83387},{\"end\":83394,\"start\":83393},{\"end\":83403,\"start\":83402},{\"end\":83623,\"start\":83622},{\"end\":83635,\"start\":83634},{\"end\":83645,\"start\":83644},{\"end\":83653,\"start\":83652},{\"end\":83655,\"start\":83654},{\"end\":83891,\"start\":83890},{\"end\":83893,\"start\":83892},{\"end\":83904,\"start\":83903},{\"end\":83915,\"start\":83914},{\"end\":84126,\"start\":84125},{\"end\":84137,\"start\":84136},{\"end\":84143,\"start\":84142},{\"end\":84152,\"start\":84151},{\"end\":84160,\"start\":84159},{\"end\":84170,\"start\":84169},{\"end\":84288,\"start\":84287},{\"end\":84298,\"start\":84297},{\"end\":84309,\"start\":84308},{\"end\":84320,\"start\":84319},{\"end\":84327,\"start\":84326},{\"end\":84337,\"start\":84336},{\"end\":84347,\"start\":84346},{\"end\":84355,\"start\":84354},{\"end\":84361,\"start\":84360},{\"end\":84363,\"start\":84362},{\"end\":84460,\"start\":84459},{\"end\":84467,\"start\":84466},{\"end\":84474,\"start\":84473},{\"end\":84480,\"start\":84479},{\"end\":84488,\"start\":84487},{\"end\":84495,\"start\":84494},{\"end\":84503,\"start\":84502},{\"end\":84517,\"start\":84516},{\"end\":84525,\"start\":84524},{\"end\":84535,\"start\":84534},{\"end\":84618,\"start\":84617},{\"end\":84627,\"start\":84626},{\"end\":84870,\"start\":84869},{\"end\":84872,\"start\":84871},{\"end\":84893,\"start\":84892},{\"end\":84908,\"start\":84907},{\"end\":84910,\"start\":84909},{\"end\":84925,\"start\":84924},{\"end\":85203,\"start\":85202},{\"end\":85214,\"start\":85213},{\"end\":85226,\"start\":85225},{\"end\":85463,\"start\":85462},{\"end\":85470,\"start\":85469},{\"end\":85477,\"start\":85476},{\"end\":85484,\"start\":85483},{\"end\":85493,\"start\":85492},{\"end\":85499,\"start\":85498},{\"end\":85693,\"start\":85692},{\"end\":85700,\"start\":85699},{\"end\":85707,\"start\":85706},{\"end\":85716,\"start\":85715},{\"end\":85723,\"start\":85722},{\"end\":85730,\"start\":85729},{\"end\":85801,\"start\":85800},{\"end\":85812,\"start\":85811},{\"end\":85823,\"start\":85822},{\"end\":85833,\"start\":85832},{\"end\":85846,\"start\":85845},{\"end\":85855,\"start\":85854},{\"end\":85857,\"start\":85856},{\"end\":85866,\"start\":85865},{\"end\":85876,\"start\":85875},{\"end\":86004,\"start\":86003},{\"end\":86012,\"start\":86011},{\"end\":86020,\"start\":86019},{\"end\":86027,\"start\":86026},{\"end\":86038,\"start\":86037},{\"end\":86306,\"start\":86305},{\"end\":86314,\"start\":86313},{\"end\":86322,\"start\":86321},{\"end\":86329,\"start\":86328},{\"end\":86337,\"start\":86336},{\"end\":86346,\"start\":86345},{\"end\":86348,\"start\":86347},{\"end\":86682,\"start\":86681},{\"end\":86690,\"start\":86689},{\"end\":86696,\"start\":86695},{\"end\":86705,\"start\":86701},{\"end\":86707,\"start\":86706},{\"end\":86715,\"start\":86714},{\"end\":86723,\"start\":86722},{\"end\":86890,\"start\":86889},{\"end\":86898,\"start\":86897},{\"end\":86908,\"start\":86905},{\"end\":86910,\"start\":86909},{\"end\":86916,\"start\":86915},{\"end\":86922,\"start\":86921},{\"end\":86930,\"start\":86929},{\"end\":86937,\"start\":86936},{\"end\":86943,\"start\":86942},{\"end\":86952,\"start\":86951},{\"end\":86959,\"start\":86958},{\"end\":87142,\"start\":87141},{\"end\":87150,\"start\":87149},{\"end\":87158,\"start\":87157},{\"end\":87166,\"start\":87165},{\"end\":87168,\"start\":87167},{\"end\":87395,\"start\":87394},{\"end\":87402,\"start\":87401},{\"end\":87408,\"start\":87407},{\"end\":87415,\"start\":87414},{\"end\":87423,\"start\":87420},{\"end\":87425,\"start\":87424},{\"end\":87509,\"start\":87508},{\"end\":87623,\"start\":87622},{\"end\":87634,\"start\":87633},{\"end\":87636,\"start\":87635},{\"end\":87909,\"start\":87908},{\"end\":87916,\"start\":87915},{\"end\":87922,\"start\":87921},{\"end\":87929,\"start\":87928},{\"end\":88095,\"start\":88094},{\"end\":88097,\"start\":88096},{\"end\":88103,\"start\":88102},{\"end\":88116,\"start\":88115},{\"end\":88242,\"start\":88241},{\"end\":88250,\"start\":88249},{\"end\":88258,\"start\":88257},{\"end\":88266,\"start\":88265},{\"end\":88273,\"start\":88272},{\"end\":88406,\"start\":88405},{\"end\":88414,\"start\":88413},{\"end\":88422,\"start\":88421},{\"end\":88429,\"start\":88428},{\"end\":88435,\"start\":88434},{\"end\":88442,\"start\":88441},{\"end\":88448,\"start\":88447},{\"end\":88640,\"start\":88639},{\"end\":88648,\"start\":88647},{\"end\":88656,\"start\":88655},{\"end\":88664,\"start\":88663},{\"end\":88841,\"start\":88840},{\"end\":88849,\"start\":88848},{\"end\":88857,\"start\":88856},{\"end\":88865,\"start\":88864},{\"end\":88989,\"start\":88988},{\"end\":88997,\"start\":88996},{\"end\":89005,\"start\":89004},{\"end\":89013,\"start\":89012},{\"end\":89262,\"start\":89261},{\"end\":89270,\"start\":89269},{\"end\":89278,\"start\":89277},{\"end\":89286,\"start\":89285},{\"end\":89295,\"start\":89294},{\"end\":89302,\"start\":89301},{\"end\":89411,\"start\":89410},{\"end\":89419,\"start\":89418},{\"end\":89427,\"start\":89426},{\"end\":89435,\"start\":89434},{\"end\":89444,\"start\":89443},{\"end\":89451,\"start\":89450},{\"end\":89586,\"start\":89585},{\"end\":89593,\"start\":89592},{\"end\":89881,\"start\":89880},{\"end\":89887,\"start\":89886},{\"end\":89893,\"start\":89892},{\"end\":89902,\"start\":89901},{\"end\":89911,\"start\":89910},{\"end\":90196,\"start\":90195},{\"end\":90202,\"start\":90201},{\"end\":90211,\"start\":90210},{\"end\":90219,\"start\":90218},{\"end\":90231,\"start\":90230},{\"end\":90239,\"start\":90238},{\"end\":90245,\"start\":90244},{\"end\":90251,\"start\":90250},{\"end\":90257,\"start\":90256},{\"end\":90264,\"start\":90263},{\"end\":90548,\"start\":90547},{\"end\":90554,\"start\":90553},{\"end\":90563,\"start\":90562},{\"end\":90569,\"start\":90568},{\"end\":90575,\"start\":90574},{\"end\":90582,\"start\":90581},{\"end\":90590,\"start\":90589},{\"end\":90592,\"start\":90591},{\"end\":90599,\"start\":90598},{\"end\":90601,\"start\":90600},{\"end\":90608,\"start\":90607},{\"end\":90615,\"start\":90614},{\"end\":90995,\"start\":90994},{\"end\":91001,\"start\":91000},{\"end\":91010,\"start\":91009},{\"end\":91022,\"start\":91021},{\"end\":91024,\"start\":91023},{\"end\":91031,\"start\":91030},{\"end\":91033,\"start\":91032},{\"end\":91040,\"start\":91039},{\"end\":91046,\"start\":91045},{\"end\":91052,\"start\":91051},{\"end\":91058,\"start\":91057},{\"end\":91066,\"start\":91065},{\"end\":91312,\"start\":91311},{\"end\":91314,\"start\":91313},{\"end\":91323,\"start\":91322},{\"end\":91325,\"start\":91324},{\"end\":91458,\"start\":91457},{\"end\":91467,\"start\":91466},{\"end\":91476,\"start\":91475}]", "bib_author_last_name": "[{\"end\":73392,\"start\":73387},{\"end\":73407,\"start\":73396},{\"end\":73414,\"start\":73411},{\"end\":73425,\"start\":73420},{\"end\":73668,\"start\":73659},{\"end\":73678,\"start\":73672},{\"end\":73769,\"start\":73763},{\"end\":73936,\"start\":73931},{\"end\":73946,\"start\":73940},{\"end\":73957,\"start\":73950},{\"end\":74202,\"start\":74191},{\"end\":74211,\"start\":74206},{\"end\":74219,\"start\":74215},{\"end\":74232,\"start\":74225},{\"end\":74239,\"start\":74236},{\"end\":74561,\"start\":74557},{\"end\":74570,\"start\":74565},{\"end\":74581,\"start\":74576},{\"end\":74593,\"start\":74587},{\"end\":74610,\"start\":74597},{\"end\":74623,\"start\":74616},{\"end\":74630,\"start\":74627},{\"end\":74642,\"start\":74634},{\"end\":74654,\"start\":74646},{\"end\":74820,\"start\":74813},{\"end\":74832,\"start\":74828},{\"end\":74844,\"start\":74836},{\"end\":74979,\"start\":74975},{\"end\":74988,\"start\":74983},{\"end\":74995,\"start\":74992},{\"end\":75001,\"start\":74999},{\"end\":75140,\"start\":75133},{\"end\":75150,\"start\":75144},{\"end\":75428,\"start\":75424},{\"end\":75435,\"start\":75432},{\"end\":75443,\"start\":75439},{\"end\":75451,\"start\":75447},{\"end\":75459,\"start\":75455},{\"end\":75467,\"start\":75463},{\"end\":75475,\"start\":75471},{\"end\":75482,\"start\":75479},{\"end\":75489,\"start\":75486},{\"end\":75498,\"start\":75493},{\"end\":75604,\"start\":75595},{\"end\":75618,\"start\":75608},{\"end\":75845,\"start\":75842},{\"end\":75854,\"start\":75849},{\"end\":75862,\"start\":75858},{\"end\":76167,\"start\":76160},{\"end\":76181,\"start\":76173},{\"end\":76380,\"start\":76378},{\"end\":76387,\"start\":76384},{\"end\":76394,\"start\":76391},{\"end\":76403,\"start\":76398},{\"end\":76660,\"start\":76657},{\"end\":76667,\"start\":76664},{\"end\":76673,\"start\":76671},{\"end\":76681,\"start\":76677},{\"end\":76689,\"start\":76685},{\"end\":76696,\"start\":76693},{\"end\":76704,\"start\":76700},{\"end\":76712,\"start\":76708},{\"end\":76728,\"start\":76716},{\"end\":76734,\"start\":76732},{\"end\":77036,\"start\":77030},{\"end\":77047,\"start\":77040},{\"end\":77057,\"start\":77051},{\"end\":77064,\"start\":77061},{\"end\":77075,\"start\":77068},{\"end\":77085,\"start\":77079},{\"end\":77334,\"start\":77332},{\"end\":77340,\"start\":77338},{\"end\":77347,\"start\":77344},{\"end\":77353,\"start\":77351},{\"end\":77457,\"start\":77455},{\"end\":77464,\"start\":77461},{\"end\":77471,\"start\":77468},{\"end\":77477,\"start\":77475},{\"end\":77485,\"start\":77481},{\"end\":77678,\"start\":77676},{\"end\":77685,\"start\":77682},{\"end\":77691,\"start\":77689},{\"end\":77703,\"start\":77699},{\"end\":77717,\"start\":77707},{\"end\":77942,\"start\":77937},{\"end\":77950,\"start\":77946},{\"end\":77958,\"start\":77954},{\"end\":77966,\"start\":77962},{\"end\":77974,\"start\":77970},{\"end\":78073,\"start\":78068},{\"end\":78081,\"start\":78077},{\"end\":78090,\"start\":78085},{\"end\":78097,\"start\":78094},{\"end\":78104,\"start\":78101},{\"end\":78115,\"start\":78110},{\"end\":78126,\"start\":78119},{\"end\":78134,\"start\":78130},{\"end\":78141,\"start\":78138},{\"end\":78244,\"start\":78238},{\"end\":78252,\"start\":78250},{\"end\":78261,\"start\":78256},{\"end\":78274,\"start\":78265},{\"end\":78290,\"start\":78278},{\"end\":78412,\"start\":78405},{\"end\":78421,\"start\":78416},{\"end\":78429,\"start\":78425},{\"end\":78437,\"start\":78433},{\"end\":78531,\"start\":78524},{\"end\":78540,\"start\":78535},{\"end\":78548,\"start\":78544},{\"end\":78556,\"start\":78552},{\"end\":78708,\"start\":78701},{\"end\":78717,\"start\":78712},{\"end\":78725,\"start\":78721},{\"end\":78807,\"start\":78803},{\"end\":78818,\"start\":78811},{\"end\":78828,\"start\":78822},{\"end\":78845,\"start\":78832},{\"end\":78860,\"start\":78849},{\"end\":79111,\"start\":79106},{\"end\":79118,\"start\":79115},{\"end\":79126,\"start\":79122},{\"end\":79139,\"start\":79130},{\"end\":79149,\"start\":79145},{\"end\":79308,\"start\":79306},{\"end\":79316,\"start\":79312},{\"end\":79329,\"start\":79322},{\"end\":79341,\"start\":79333},{\"end\":79350,\"start\":79347},{\"end\":79456,\"start\":79448},{\"end\":79561,\"start\":79559},{\"end\":79570,\"start\":79565},{\"end\":79910,\"start\":79905},{\"end\":79917,\"start\":79914},{\"end\":79924,\"start\":79921},{\"end\":79933,\"start\":79928},{\"end\":79939,\"start\":79937},{\"end\":79948,\"start\":79943},{\"end\":79957,\"start\":79952},{\"end\":80093,\"start\":80086},{\"end\":80107,\"start\":80097},{\"end\":80119,\"start\":80111},{\"end\":80130,\"start\":80123},{\"end\":80140,\"start\":80134},{\"end\":80152,\"start\":80144},{\"end\":80161,\"start\":80156},{\"end\":80345,\"start\":80342},{\"end\":80355,\"start\":80349},{\"end\":80364,\"start\":80359},{\"end\":80493,\"start\":80489},{\"end\":80504,\"start\":80497},{\"end\":80520,\"start\":80508},{\"end\":80533,\"start\":80526},{\"end\":80544,\"start\":80537},{\"end\":80552,\"start\":80548},{\"end\":80562,\"start\":80556},{\"end\":80824,\"start\":80821},{\"end\":80830,\"start\":80828},{\"end\":80838,\"start\":80834},{\"end\":81112,\"start\":81109},{\"end\":81118,\"start\":81116},{\"end\":81125,\"start\":81122},{\"end\":81132,\"start\":81129},{\"end\":81138,\"start\":81136},{\"end\":81245,\"start\":81242},{\"end\":81251,\"start\":81249},{\"end\":81260,\"start\":81255},{\"end\":81395,\"start\":81392},{\"end\":81403,\"start\":81399},{\"end\":81409,\"start\":81407},{\"end\":81418,\"start\":81413},{\"end\":81429,\"start\":81422},{\"end\":81439,\"start\":81433},{\"end\":81539,\"start\":81536},{\"end\":81547,\"start\":81543},{\"end\":81555,\"start\":81551},{\"end\":81564,\"start\":81561},{\"end\":81572,\"start\":81568},{\"end\":81580,\"start\":81576},{\"end\":81589,\"start\":81584},{\"end\":81843,\"start\":81840},{\"end\":81863,\"start\":81847},{\"end\":81870,\"start\":81867},{\"end\":81876,\"start\":81874},{\"end\":81959,\"start\":81954},{\"end\":81989,\"start\":81982},{\"end\":81996,\"start\":81993},{\"end\":82002,\"start\":82000},{\"end\":82012,\"start\":82006},{\"end\":82023,\"start\":82018},{\"end\":82030,\"start\":82027},{\"end\":82038,\"start\":82034},{\"end\":82046,\"start\":82044},{\"end\":82054,\"start\":82050},{\"end\":82061,\"start\":82058},{\"end\":82258,\"start\":82256},{\"end\":82265,\"start\":82262},{\"end\":82272,\"start\":82269},{\"end\":82281,\"start\":82276},{\"end\":82297,\"start\":82285},{\"end\":82307,\"start\":82301},{\"end\":82318,\"start\":82311},{\"end\":82327,\"start\":82322},{\"end\":82336,\"start\":82331},{\"end\":82344,\"start\":82340},{\"end\":82460,\"start\":82458},{\"end\":82467,\"start\":82464},{\"end\":82474,\"start\":82471},{\"end\":82483,\"start\":82478},{\"end\":82499,\"start\":82487},{\"end\":82509,\"start\":82503},{\"end\":82522,\"start\":82515},{\"end\":82531,\"start\":82526},{\"end\":82540,\"start\":82535},{\"end\":82548,\"start\":82544},{\"end\":82554,\"start\":82552},{\"end\":82562,\"start\":82558},{\"end\":82570,\"start\":82566},{\"end\":82578,\"start\":82574},{\"end\":82588,\"start\":82582},{\"end\":82596,\"start\":82592},{\"end\":82604,\"start\":82600},{\"end\":82612,\"start\":82608},{\"end\":82626,\"start\":82616},{\"end\":82636,\"start\":82632},{\"end\":82642,\"start\":82640},{\"end\":82649,\"start\":82646},{\"end\":82794,\"start\":82784},{\"end\":82803,\"start\":82798},{\"end\":83003,\"start\":82997},{\"end\":83014,\"start\":83009},{\"end\":83023,\"start\":83018},{\"end\":83033,\"start\":83029},{\"end\":83150,\"start\":83147},{\"end\":83157,\"start\":83154},{\"end\":83163,\"start\":83161},{\"end\":83172,\"start\":83167},{\"end\":83373,\"start\":83370},{\"end\":83379,\"start\":83377},{\"end\":83385,\"start\":83383},{\"end\":83391,\"start\":83389},{\"end\":83400,\"start\":83395},{\"end\":83407,\"start\":83404},{\"end\":83632,\"start\":83624},{\"end\":83642,\"start\":83636},{\"end\":83650,\"start\":83646},{\"end\":83659,\"start\":83656},{\"end\":83901,\"start\":83894},{\"end\":83912,\"start\":83905},{\"end\":83921,\"start\":83916},{\"end\":84134,\"start\":84127},{\"end\":84140,\"start\":84138},{\"end\":84149,\"start\":84144},{\"end\":84157,\"start\":84153},{\"end\":84167,\"start\":84161},{\"end\":84180,\"start\":84171},{\"end\":84295,\"start\":84289},{\"end\":84306,\"start\":84299},{\"end\":84317,\"start\":84310},{\"end\":84324,\"start\":84321},{\"end\":84334,\"start\":84328},{\"end\":84344,\"start\":84338},{\"end\":84352,\"start\":84348},{\"end\":84358,\"start\":84356},{\"end\":84367,\"start\":84364},{\"end\":84464,\"start\":84461},{\"end\":84471,\"start\":84468},{\"end\":84477,\"start\":84475},{\"end\":84485,\"start\":84481},{\"end\":84492,\"start\":84489},{\"end\":84500,\"start\":84496},{\"end\":84514,\"start\":84504},{\"end\":84522,\"start\":84518},{\"end\":84532,\"start\":84526},{\"end\":84538,\"start\":84536},{\"end\":84624,\"start\":84619},{\"end\":84634,\"start\":84628},{\"end\":84890,\"start\":84873},{\"end\":84905,\"start\":84894},{\"end\":84922,\"start\":84911},{\"end\":84942,\"start\":84926},{\"end\":85211,\"start\":85204},{\"end\":85223,\"start\":85215},{\"end\":85235,\"start\":85227},{\"end\":85467,\"start\":85464},{\"end\":85474,\"start\":85471},{\"end\":85481,\"start\":85478},{\"end\":85490,\"start\":85485},{\"end\":85496,\"start\":85494},{\"end\":85505,\"start\":85500},{\"end\":85697,\"start\":85694},{\"end\":85704,\"start\":85701},{\"end\":85713,\"start\":85708},{\"end\":85720,\"start\":85717},{\"end\":85727,\"start\":85724},{\"end\":85736,\"start\":85731},{\"end\":85809,\"start\":85802},{\"end\":85820,\"start\":85813},{\"end\":85830,\"start\":85824},{\"end\":85843,\"start\":85834},{\"end\":85852,\"start\":85847},{\"end\":85863,\"start\":85858},{\"end\":85873,\"start\":85867},{\"end\":85887,\"start\":85877},{\"end\":86009,\"start\":86005},{\"end\":86017,\"start\":86013},{\"end\":86024,\"start\":86021},{\"end\":86035,\"start\":86028},{\"end\":86049,\"start\":86039},{\"end\":86311,\"start\":86307},{\"end\":86319,\"start\":86315},{\"end\":86326,\"start\":86323},{\"end\":86334,\"start\":86330},{\"end\":86343,\"start\":86338},{\"end\":86352,\"start\":86349},{\"end\":86687,\"start\":86683},{\"end\":86693,\"start\":86691},{\"end\":86699,\"start\":86697},{\"end\":86712,\"start\":86708},{\"end\":86720,\"start\":86716},{\"end\":86895,\"start\":86891},{\"end\":86903,\"start\":86899},{\"end\":86913,\"start\":86911},{\"end\":86919,\"start\":86917},{\"end\":86927,\"start\":86923},{\"end\":86934,\"start\":86931},{\"end\":86940,\"start\":86938},{\"end\":86949,\"start\":86944},{\"end\":86956,\"start\":86953},{\"end\":87147,\"start\":87143},{\"end\":87155,\"start\":87151},{\"end\":87163,\"start\":87159},{\"end\":87172,\"start\":87169},{\"end\":87399,\"start\":87396},{\"end\":87405,\"start\":87403},{\"end\":87412,\"start\":87409},{\"end\":87418,\"start\":87416},{\"end\":87518,\"start\":87510},{\"end\":87631,\"start\":87624},{\"end\":87641,\"start\":87637},{\"end\":87913,\"start\":87910},{\"end\":87919,\"start\":87917},{\"end\":87926,\"start\":87923},{\"end\":87935,\"start\":87930},{\"end\":88100,\"start\":88098},{\"end\":88113,\"start\":88104},{\"end\":88123,\"start\":88117},{\"end\":88247,\"start\":88243},{\"end\":88255,\"start\":88251},{\"end\":88263,\"start\":88259},{\"end\":88270,\"start\":88267},{\"end\":88278,\"start\":88274},{\"end\":88411,\"start\":88407},{\"end\":88419,\"start\":88415},{\"end\":88426,\"start\":88423},{\"end\":88432,\"start\":88430},{\"end\":88439,\"start\":88436},{\"end\":88445,\"start\":88443},{\"end\":88452,\"start\":88449},{\"end\":88645,\"start\":88641},{\"end\":88653,\"start\":88649},{\"end\":88661,\"start\":88657},{\"end\":88667,\"start\":88665},{\"end\":88846,\"start\":88842},{\"end\":88854,\"start\":88850},{\"end\":88862,\"start\":88858},{\"end\":88868,\"start\":88866},{\"end\":88994,\"start\":88990},{\"end\":89002,\"start\":88998},{\"end\":89010,\"start\":89006},{\"end\":89016,\"start\":89014},{\"end\":89267,\"start\":89263},{\"end\":89275,\"start\":89271},{\"end\":89283,\"start\":89279},{\"end\":89292,\"start\":89287},{\"end\":89299,\"start\":89296},{\"end\":89307,\"start\":89303},{\"end\":89416,\"start\":89412},{\"end\":89424,\"start\":89420},{\"end\":89432,\"start\":89428},{\"end\":89441,\"start\":89436},{\"end\":89448,\"start\":89445},{\"end\":89456,\"start\":89452},{\"end\":89590,\"start\":89587},{\"end\":89600,\"start\":89594},{\"end\":89884,\"start\":89882},{\"end\":89890,\"start\":89888},{\"end\":89899,\"start\":89894},{\"end\":89908,\"start\":89903},{\"end\":89917,\"start\":89912},{\"end\":90199,\"start\":90197},{\"end\":90208,\"start\":90203},{\"end\":90216,\"start\":90212},{\"end\":90228,\"start\":90220},{\"end\":90236,\"start\":90232},{\"end\":90242,\"start\":90240},{\"end\":90248,\"start\":90246},{\"end\":90254,\"start\":90252},{\"end\":90261,\"start\":90258},{\"end\":90270,\"start\":90265},{\"end\":90551,\"start\":90549},{\"end\":90560,\"start\":90555},{\"end\":90566,\"start\":90564},{\"end\":90572,\"start\":90570},{\"end\":90579,\"start\":90576},{\"end\":90587,\"start\":90583},{\"end\":90596,\"start\":90593},{\"end\":90605,\"start\":90602},{\"end\":90612,\"start\":90609},{\"end\":90618,\"start\":90616},{\"end\":90998,\"start\":90996},{\"end\":91007,\"start\":91002},{\"end\":91019,\"start\":91011},{\"end\":91028,\"start\":91025},{\"end\":91037,\"start\":91034},{\"end\":91043,\"start\":91041},{\"end\":91049,\"start\":91047},{\"end\":91055,\"start\":91053},{\"end\":91063,\"start\":91059},{\"end\":91071,\"start\":91067},{\"end\":91320,\"start\":91315},{\"end\":91332,\"start\":91326},{\"end\":91464,\"start\":91459},{\"end\":91473,\"start\":91468},{\"end\":91483,\"start\":91477}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":73320,\"start\":72663},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":232185260},\"end\":73573,\"start\":73322},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":1737567},\"end\":73757,\"start\":73575},{\"attributes\":{\"id\":\"b3\"},\"end\":73845,\"start\":73759},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":155092736},\"end\":74124,\"start\":73847},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":249674577},\"end\":74494,\"start\":74126},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":8180378},\"end\":74754,\"start\":74496},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":16119010},\"end\":74906,\"start\":74756},{\"attributes\":{\"doi\":\"10.48550/ARXIV.2211.00818\",\"id\":\"b8\"},\"end\":75056,\"start\":74908},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":249663640},\"end\":75351,\"start\":75058},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":211171605},\"end\":75572,\"start\":75353},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":9553396},\"end\":75777,\"start\":75574},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":229923710},\"end\":76103,\"start\":75779},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":10902576},\"end\":76320,\"start\":76105},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":237452236},\"end\":76584,\"start\":76322},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":247315559},\"end\":76984,\"start\":76586},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":52136345},\"end\":77250,\"start\":76986},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":189927337},\"end\":77387,\"start\":77252},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":246080180},\"end\":77606,\"start\":77389},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":248743445},\"end\":77869,\"start\":77608},{\"attributes\":{\"id\":\"b20\"},\"end\":77996,\"start\":77871},{\"attributes\":{\"id\":\"b21\"},\"end\":78163,\"start\":77998},{\"attributes\":{\"id\":\"b22\"},\"end\":78312,\"start\":78165},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":67856492},\"end\":78471,\"start\":78314},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":204512545},\"end\":78593,\"start\":78473},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":233693242},\"end\":78745,\"start\":78595},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":497108},\"end\":79041,\"start\":78747},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":16538528},\"end\":79209,\"start\":79043},{\"attributes\":{\"id\":\"b28\"},\"end\":79372,\"start\":79211},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":11397526},\"end\":79492,\"start\":79374},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":230433941},\"end\":79901,\"start\":79494},{\"attributes\":{\"id\":\"b31\"},\"end\":80034,\"start\":79903},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":237371751},\"end\":80255,\"start\":80036},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":226283779},\"end\":80438,\"start\":80257},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":14434979},\"end\":80743,\"start\":80440},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":229703606},\"end\":81022,\"start\":80745},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":248254529},\"end\":81170,\"start\":81024},{\"attributes\":{\"id\":\"b37\"},\"end\":81283,\"start\":81172},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":236493269},\"end\":81465,\"start\":81285},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":215745354},\"end\":81757,\"start\":81467},{\"attributes\":{\"id\":\"b40\"},\"end\":81899,\"start\":81759},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":19373161},\"end\":81978,\"start\":81901},{\"attributes\":{\"id\":\"b42\"},\"end\":82165,\"start\":81980},{\"attributes\":{\"id\":\"b43\"},\"end\":82367,\"start\":82167},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":231855531},\"end\":82939,\"start\":82369},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":7425119},\"end\":83143,\"start\":82941},{\"attributes\":{\"id\":\"b46\"},\"end\":83280,\"start\":83145},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":246077487},\"end\":83556,\"start\":83282},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":11080756},\"end\":83826,\"start\":83558},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":9101619},\"end\":84070,\"start\":83828},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":160025533},\"end\":84202,\"start\":84072},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":204838007},\"end\":84394,\"start\":84204},{\"attributes\":{\"id\":\"b52\"},\"end\":84560,\"start\":84396},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":225062282},\"end\":84761,\"start\":84562},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":237440458},\"end\":85107,\"start\":84763},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":237491759},\"end\":85400,\"start\":85109},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":53670269},\"end\":85622,\"start\":85402},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":208248351},\"end\":85771,\"start\":85624},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":13756489},\"end\":85924,\"start\":85773},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":207863446},\"end\":86216,\"start\":85926},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":251040169},\"end\":86608,\"start\":86218},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":234477357},\"end\":86829,\"start\":86610},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":247362946},\"end\":87032,\"start\":86831},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":237386541},\"end\":87338,\"start\":87034},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":202769028},\"end\":87463,\"start\":87340},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":53662922},\"end\":87561,\"start\":87465},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":2783746},\"end\":87806,\"start\":87563},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":232307642},\"end\":88022,\"start\":87808},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":231718679},\"end\":88170,\"start\":88024},{\"attributes\":{\"id\":\"b69\"},\"end\":88300,\"start\":88172},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":235765336},\"end\":88549,\"start\":88302},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":236139947},\"end\":88743,\"start\":88551},{\"attributes\":{\"id\":\"b72\"},\"end\":88891,\"start\":88745},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":247011101},\"end\":89185,\"start\":88893},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":254312905},\"end\":89334,\"start\":89187},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":254312905},\"end\":89485,\"start\":89336},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":52926380},\"end\":89811,\"start\":89487},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":13748720},\"end\":90081,\"start\":89813},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":52815560},\"end\":90436,\"start\":90083},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":202565697},\"end\":90944,\"start\":90438},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":174802873},\"end\":91239,\"start\":90946},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":263135},\"end\":91455,\"start\":91241},{\"attributes\":{\"id\":\"b82\"},\"end\":91588,\"start\":91457},{\"attributes\":{\"id\":\"b83\"},\"end\":91726,\"start\":91590},{\"attributes\":{\"id\":\"b84\"},\"end\":92054,\"start\":91728}]", "bib_title": "[{\"end\":73383,\"start\":73322},{\"end\":73655,\"start\":73575},{\"end\":73927,\"start\":73847},{\"end\":74187,\"start\":74126},{\"end\":74551,\"start\":74496},{\"end\":74807,\"start\":74756},{\"end\":75129,\"start\":75058},{\"end\":75420,\"start\":75353},{\"end\":75591,\"start\":75574},{\"end\":75838,\"start\":75779},{\"end\":76154,\"start\":76105},{\"end\":76374,\"start\":76322},{\"end\":76653,\"start\":76586},{\"end\":77024,\"start\":76986},{\"end\":77328,\"start\":77252},{\"end\":77451,\"start\":77389},{\"end\":77672,\"start\":77608},{\"end\":78401,\"start\":78314},{\"end\":78520,\"start\":78473},{\"end\":78697,\"start\":78595},{\"end\":78799,\"start\":78747},{\"end\":79102,\"start\":79043},{\"end\":79444,\"start\":79374},{\"end\":79553,\"start\":79494},{\"end\":80082,\"start\":80036},{\"end\":80336,\"start\":80257},{\"end\":80485,\"start\":80440},{\"end\":80817,\"start\":80745},{\"end\":81105,\"start\":81024},{\"end\":81388,\"start\":81285},{\"end\":81532,\"start\":81467},{\"end\":81948,\"start\":81901},{\"end\":82454,\"start\":82369},{\"end\":82993,\"start\":82941},{\"end\":83366,\"start\":83282},{\"end\":83620,\"start\":83558},{\"end\":83888,\"start\":83828},{\"end\":84123,\"start\":84072},{\"end\":84285,\"start\":84204},{\"end\":84615,\"start\":84562},{\"end\":84867,\"start\":84763},{\"end\":85200,\"start\":85109},{\"end\":85460,\"start\":85402},{\"end\":85690,\"start\":85624},{\"end\":85798,\"start\":85773},{\"end\":86001,\"start\":85926},{\"end\":86303,\"start\":86218},{\"end\":86679,\"start\":86610},{\"end\":86887,\"start\":86831},{\"end\":87139,\"start\":87034},{\"end\":87392,\"start\":87340},{\"end\":87506,\"start\":87465},{\"end\":87620,\"start\":87563},{\"end\":87906,\"start\":87808},{\"end\":88092,\"start\":88024},{\"end\":88403,\"start\":88302},{\"end\":88637,\"start\":88551},{\"end\":88986,\"start\":88893},{\"end\":89259,\"start\":89187},{\"end\":89408,\"start\":89336},{\"end\":89583,\"start\":89487},{\"end\":89878,\"start\":89813},{\"end\":90193,\"start\":90083},{\"end\":90545,\"start\":90438},{\"end\":90992,\"start\":90946},{\"end\":91309,\"start\":91241}]", "bib_author": "[{\"end\":73394,\"start\":73385},{\"end\":73409,\"start\":73394},{\"end\":73416,\"start\":73409},{\"end\":73427,\"start\":73416},{\"end\":73670,\"start\":73657},{\"end\":73680,\"start\":73670},{\"end\":73771,\"start\":73759},{\"end\":73938,\"start\":73929},{\"end\":73948,\"start\":73938},{\"end\":73959,\"start\":73948},{\"end\":74204,\"start\":74189},{\"end\":74213,\"start\":74204},{\"end\":74221,\"start\":74213},{\"end\":74234,\"start\":74221},{\"end\":74241,\"start\":74234},{\"end\":74563,\"start\":74553},{\"end\":74572,\"start\":74563},{\"end\":74583,\"start\":74572},{\"end\":74595,\"start\":74583},{\"end\":74612,\"start\":74595},{\"end\":74625,\"start\":74612},{\"end\":74632,\"start\":74625},{\"end\":74644,\"start\":74632},{\"end\":74656,\"start\":74644},{\"end\":74822,\"start\":74809},{\"end\":74834,\"start\":74822},{\"end\":74846,\"start\":74834},{\"end\":74850,\"start\":74846},{\"end\":74981,\"start\":74973},{\"end\":74990,\"start\":74981},{\"end\":74997,\"start\":74990},{\"end\":75003,\"start\":74997},{\"end\":75011,\"start\":75003},{\"end\":75142,\"start\":75131},{\"end\":75152,\"start\":75142},{\"end\":75430,\"start\":75422},{\"end\":75437,\"start\":75430},{\"end\":75445,\"start\":75437},{\"end\":75453,\"start\":75445},{\"end\":75461,\"start\":75453},{\"end\":75469,\"start\":75461},{\"end\":75477,\"start\":75469},{\"end\":75484,\"start\":75477},{\"end\":75491,\"start\":75484},{\"end\":75500,\"start\":75491},{\"end\":75606,\"start\":75593},{\"end\":75620,\"start\":75606},{\"end\":75847,\"start\":75840},{\"end\":75856,\"start\":75847},{\"end\":75864,\"start\":75856},{\"end\":76169,\"start\":76156},{\"end\":76183,\"start\":76169},{\"end\":76382,\"start\":76376},{\"end\":76389,\"start\":76382},{\"end\":76396,\"start\":76389},{\"end\":76405,\"start\":76396},{\"end\":76662,\"start\":76655},{\"end\":76669,\"start\":76662},{\"end\":76675,\"start\":76669},{\"end\":76683,\"start\":76675},{\"end\":76691,\"start\":76683},{\"end\":76698,\"start\":76691},{\"end\":76706,\"start\":76698},{\"end\":76714,\"start\":76706},{\"end\":76730,\"start\":76714},{\"end\":76736,\"start\":76730},{\"end\":77038,\"start\":77026},{\"end\":77049,\"start\":77038},{\"end\":77059,\"start\":77049},{\"end\":77066,\"start\":77059},{\"end\":77077,\"start\":77066},{\"end\":77087,\"start\":77077},{\"end\":77336,\"start\":77330},{\"end\":77342,\"start\":77336},{\"end\":77349,\"start\":77342},{\"end\":77355,\"start\":77349},{\"end\":77363,\"start\":77355},{\"end\":77459,\"start\":77453},{\"end\":77466,\"start\":77459},{\"end\":77473,\"start\":77466},{\"end\":77479,\"start\":77473},{\"end\":77487,\"start\":77479},{\"end\":77680,\"start\":77674},{\"end\":77687,\"start\":77680},{\"end\":77693,\"start\":77687},{\"end\":77705,\"start\":77693},{\"end\":77719,\"start\":77705},{\"end\":77723,\"start\":77719},{\"end\":77944,\"start\":77935},{\"end\":77952,\"start\":77944},{\"end\":77960,\"start\":77952},{\"end\":77968,\"start\":77960},{\"end\":77976,\"start\":77968},{\"end\":78075,\"start\":78066},{\"end\":78083,\"start\":78075},{\"end\":78092,\"start\":78083},{\"end\":78099,\"start\":78092},{\"end\":78106,\"start\":78099},{\"end\":78117,\"start\":78106},{\"end\":78128,\"start\":78117},{\"end\":78136,\"start\":78128},{\"end\":78143,\"start\":78136},{\"end\":78246,\"start\":78236},{\"end\":78254,\"start\":78246},{\"end\":78263,\"start\":78254},{\"end\":78276,\"start\":78263},{\"end\":78292,\"start\":78276},{\"end\":78414,\"start\":78403},{\"end\":78423,\"start\":78414},{\"end\":78431,\"start\":78423},{\"end\":78439,\"start\":78431},{\"end\":78533,\"start\":78522},{\"end\":78542,\"start\":78533},{\"end\":78550,\"start\":78542},{\"end\":78558,\"start\":78550},{\"end\":78710,\"start\":78699},{\"end\":78719,\"start\":78710},{\"end\":78727,\"start\":78719},{\"end\":78809,\"start\":78801},{\"end\":78820,\"start\":78809},{\"end\":78830,\"start\":78820},{\"end\":78847,\"start\":78830},{\"end\":78862,\"start\":78847},{\"end\":79113,\"start\":79104},{\"end\":79120,\"start\":79113},{\"end\":79128,\"start\":79120},{\"end\":79141,\"start\":79128},{\"end\":79151,\"start\":79141},{\"end\":79310,\"start\":79304},{\"end\":79318,\"start\":79310},{\"end\":79331,\"start\":79318},{\"end\":79343,\"start\":79331},{\"end\":79352,\"start\":79343},{\"end\":79458,\"start\":79446},{\"end\":79563,\"start\":79555},{\"end\":79572,\"start\":79563},{\"end\":79912,\"start\":79903},{\"end\":79919,\"start\":79912},{\"end\":79926,\"start\":79919},{\"end\":79935,\"start\":79926},{\"end\":79941,\"start\":79935},{\"end\":79950,\"start\":79941},{\"end\":79959,\"start\":79950},{\"end\":80095,\"start\":80084},{\"end\":80109,\"start\":80095},{\"end\":80121,\"start\":80109},{\"end\":80132,\"start\":80121},{\"end\":80142,\"start\":80132},{\"end\":80154,\"start\":80142},{\"end\":80163,\"start\":80154},{\"end\":80347,\"start\":80338},{\"end\":80357,\"start\":80347},{\"end\":80366,\"start\":80357},{\"end\":80495,\"start\":80487},{\"end\":80506,\"start\":80495},{\"end\":80522,\"start\":80506},{\"end\":80535,\"start\":80522},{\"end\":80546,\"start\":80535},{\"end\":80554,\"start\":80546},{\"end\":80564,\"start\":80554},{\"end\":80826,\"start\":80819},{\"end\":80832,\"start\":80826},{\"end\":80840,\"start\":80832},{\"end\":80848,\"start\":80840},{\"end\":81114,\"start\":81107},{\"end\":81120,\"start\":81114},{\"end\":81127,\"start\":81120},{\"end\":81134,\"start\":81127},{\"end\":81140,\"start\":81134},{\"end\":81148,\"start\":81140},{\"end\":81247,\"start\":81240},{\"end\":81253,\"start\":81247},{\"end\":81262,\"start\":81253},{\"end\":81397,\"start\":81390},{\"end\":81405,\"start\":81397},{\"end\":81411,\"start\":81405},{\"end\":81420,\"start\":81411},{\"end\":81431,\"start\":81420},{\"end\":81441,\"start\":81431},{\"end\":81541,\"start\":81534},{\"end\":81549,\"start\":81541},{\"end\":81557,\"start\":81549},{\"end\":81566,\"start\":81557},{\"end\":81574,\"start\":81566},{\"end\":81582,\"start\":81574},{\"end\":81591,\"start\":81582},{\"end\":81845,\"start\":81838},{\"end\":81865,\"start\":81845},{\"end\":81872,\"start\":81865},{\"end\":81878,\"start\":81872},{\"end\":81961,\"start\":81950},{\"end\":81991,\"start\":81980},{\"end\":81998,\"start\":81991},{\"end\":82004,\"start\":81998},{\"end\":82014,\"start\":82004},{\"end\":82025,\"start\":82014},{\"end\":82032,\"start\":82025},{\"end\":82040,\"start\":82032},{\"end\":82048,\"start\":82040},{\"end\":82056,\"start\":82048},{\"end\":82063,\"start\":82056},{\"end\":82260,\"start\":82254},{\"end\":82267,\"start\":82260},{\"end\":82274,\"start\":82267},{\"end\":82283,\"start\":82274},{\"end\":82299,\"start\":82283},{\"end\":82309,\"start\":82299},{\"end\":82320,\"start\":82309},{\"end\":82329,\"start\":82320},{\"end\":82338,\"start\":82329},{\"end\":82346,\"start\":82338},{\"end\":82462,\"start\":82456},{\"end\":82469,\"start\":82462},{\"end\":82476,\"start\":82469},{\"end\":82485,\"start\":82476},{\"end\":82501,\"start\":82485},{\"end\":82511,\"start\":82501},{\"end\":82524,\"start\":82511},{\"end\":82533,\"start\":82524},{\"end\":82542,\"start\":82533},{\"end\":82550,\"start\":82542},{\"end\":82556,\"start\":82550},{\"end\":82564,\"start\":82556},{\"end\":82572,\"start\":82564},{\"end\":82580,\"start\":82572},{\"end\":82590,\"start\":82580},{\"end\":82598,\"start\":82590},{\"end\":82606,\"start\":82598},{\"end\":82614,\"start\":82606},{\"end\":82628,\"start\":82614},{\"end\":82638,\"start\":82628},{\"end\":82644,\"start\":82638},{\"end\":82651,\"start\":82644},{\"end\":83005,\"start\":82995},{\"end\":83016,\"start\":83005},{\"end\":83025,\"start\":83016},{\"end\":83035,\"start\":83025},{\"end\":83152,\"start\":83145},{\"end\":83159,\"start\":83152},{\"end\":83165,\"start\":83159},{\"end\":83174,\"start\":83165},{\"end\":83182,\"start\":83174},{\"end\":83375,\"start\":83368},{\"end\":83381,\"start\":83375},{\"end\":83387,\"start\":83381},{\"end\":83393,\"start\":83387},{\"end\":83402,\"start\":83393},{\"end\":83409,\"start\":83402},{\"end\":83634,\"start\":83622},{\"end\":83644,\"start\":83634},{\"end\":83652,\"start\":83644},{\"end\":83661,\"start\":83652},{\"end\":83903,\"start\":83890},{\"end\":83914,\"start\":83903},{\"end\":83923,\"start\":83914},{\"end\":84136,\"start\":84125},{\"end\":84142,\"start\":84136},{\"end\":84151,\"start\":84142},{\"end\":84159,\"start\":84151},{\"end\":84169,\"start\":84159},{\"end\":84182,\"start\":84169},{\"end\":84297,\"start\":84287},{\"end\":84308,\"start\":84297},{\"end\":84319,\"start\":84308},{\"end\":84326,\"start\":84319},{\"end\":84336,\"start\":84326},{\"end\":84346,\"start\":84336},{\"end\":84354,\"start\":84346},{\"end\":84360,\"start\":84354},{\"end\":84369,\"start\":84360},{\"end\":84466,\"start\":84459},{\"end\":84473,\"start\":84466},{\"end\":84479,\"start\":84473},{\"end\":84487,\"start\":84479},{\"end\":84494,\"start\":84487},{\"end\":84502,\"start\":84494},{\"end\":84516,\"start\":84502},{\"end\":84524,\"start\":84516},{\"end\":84534,\"start\":84524},{\"end\":84540,\"start\":84534},{\"end\":84626,\"start\":84617},{\"end\":84636,\"start\":84626},{\"end\":84892,\"start\":84869},{\"end\":84907,\"start\":84892},{\"end\":84924,\"start\":84907},{\"end\":84944,\"start\":84924},{\"end\":85213,\"start\":85202},{\"end\":85225,\"start\":85213},{\"end\":85237,\"start\":85225},{\"end\":85469,\"start\":85462},{\"end\":85476,\"start\":85469},{\"end\":85483,\"start\":85476},{\"end\":85492,\"start\":85483},{\"end\":85498,\"start\":85492},{\"end\":85507,\"start\":85498},{\"end\":85699,\"start\":85692},{\"end\":85706,\"start\":85699},{\"end\":85715,\"start\":85706},{\"end\":85722,\"start\":85715},{\"end\":85729,\"start\":85722},{\"end\":85738,\"start\":85729},{\"end\":85811,\"start\":85800},{\"end\":85822,\"start\":85811},{\"end\":85832,\"start\":85822},{\"end\":85845,\"start\":85832},{\"end\":85854,\"start\":85845},{\"end\":85865,\"start\":85854},{\"end\":85875,\"start\":85865},{\"end\":85889,\"start\":85875},{\"end\":86011,\"start\":86003},{\"end\":86019,\"start\":86011},{\"end\":86026,\"start\":86019},{\"end\":86037,\"start\":86026},{\"end\":86051,\"start\":86037},{\"end\":86313,\"start\":86305},{\"end\":86321,\"start\":86313},{\"end\":86328,\"start\":86321},{\"end\":86336,\"start\":86328},{\"end\":86345,\"start\":86336},{\"end\":86354,\"start\":86345},{\"end\":86689,\"start\":86681},{\"end\":86695,\"start\":86689},{\"end\":86701,\"start\":86695},{\"end\":86714,\"start\":86701},{\"end\":86722,\"start\":86714},{\"end\":86726,\"start\":86722},{\"end\":86897,\"start\":86889},{\"end\":86905,\"start\":86897},{\"end\":86915,\"start\":86905},{\"end\":86921,\"start\":86915},{\"end\":86929,\"start\":86921},{\"end\":86936,\"start\":86929},{\"end\":86942,\"start\":86936},{\"end\":86951,\"start\":86942},{\"end\":86958,\"start\":86951},{\"end\":86962,\"start\":86958},{\"end\":87149,\"start\":87141},{\"end\":87157,\"start\":87149},{\"end\":87165,\"start\":87157},{\"end\":87174,\"start\":87165},{\"end\":87401,\"start\":87394},{\"end\":87407,\"start\":87401},{\"end\":87414,\"start\":87407},{\"end\":87420,\"start\":87414},{\"end\":87428,\"start\":87420},{\"end\":87520,\"start\":87508},{\"end\":87633,\"start\":87622},{\"end\":87643,\"start\":87633},{\"end\":87915,\"start\":87908},{\"end\":87921,\"start\":87915},{\"end\":87928,\"start\":87921},{\"end\":87937,\"start\":87928},{\"end\":88102,\"start\":88094},{\"end\":88115,\"start\":88102},{\"end\":88125,\"start\":88115},{\"end\":88249,\"start\":88241},{\"end\":88257,\"start\":88249},{\"end\":88265,\"start\":88257},{\"end\":88272,\"start\":88265},{\"end\":88280,\"start\":88272},{\"end\":88413,\"start\":88405},{\"end\":88421,\"start\":88413},{\"end\":88428,\"start\":88421},{\"end\":88434,\"start\":88428},{\"end\":88441,\"start\":88434},{\"end\":88447,\"start\":88441},{\"end\":88454,\"start\":88447},{\"end\":88647,\"start\":88639},{\"end\":88655,\"start\":88647},{\"end\":88663,\"start\":88655},{\"end\":88669,\"start\":88663},{\"end\":88848,\"start\":88840},{\"end\":88856,\"start\":88848},{\"end\":88864,\"start\":88856},{\"end\":88870,\"start\":88864},{\"end\":88996,\"start\":88988},{\"end\":89004,\"start\":88996},{\"end\":89012,\"start\":89004},{\"end\":89018,\"start\":89012},{\"end\":89269,\"start\":89261},{\"end\":89277,\"start\":89269},{\"end\":89285,\"start\":89277},{\"end\":89294,\"start\":89285},{\"end\":89301,\"start\":89294},{\"end\":89309,\"start\":89301},{\"end\":89418,\"start\":89410},{\"end\":89426,\"start\":89418},{\"end\":89434,\"start\":89426},{\"end\":89443,\"start\":89434},{\"end\":89450,\"start\":89443},{\"end\":89458,\"start\":89450},{\"end\":89592,\"start\":89585},{\"end\":89602,\"start\":89592},{\"end\":89886,\"start\":89880},{\"end\":89892,\"start\":89886},{\"end\":89901,\"start\":89892},{\"end\":89910,\"start\":89901},{\"end\":89919,\"start\":89910},{\"end\":90201,\"start\":90195},{\"end\":90210,\"start\":90201},{\"end\":90218,\"start\":90210},{\"end\":90230,\"start\":90218},{\"end\":90238,\"start\":90230},{\"end\":90244,\"start\":90238},{\"end\":90250,\"start\":90244},{\"end\":90256,\"start\":90250},{\"end\":90263,\"start\":90256},{\"end\":90272,\"start\":90263},{\"end\":90553,\"start\":90547},{\"end\":90562,\"start\":90553},{\"end\":90568,\"start\":90562},{\"end\":90574,\"start\":90568},{\"end\":90581,\"start\":90574},{\"end\":90589,\"start\":90581},{\"end\":90598,\"start\":90589},{\"end\":90607,\"start\":90598},{\"end\":90614,\"start\":90607},{\"end\":90620,\"start\":90614},{\"end\":91000,\"start\":90994},{\"end\":91009,\"start\":91000},{\"end\":91021,\"start\":91009},{\"end\":91030,\"start\":91021},{\"end\":91039,\"start\":91030},{\"end\":91045,\"start\":91039},{\"end\":91051,\"start\":91045},{\"end\":91057,\"start\":91051},{\"end\":91065,\"start\":91057},{\"end\":91073,\"start\":91065},{\"end\":91322,\"start\":91311},{\"end\":91334,\"start\":91322},{\"end\":91466,\"start\":91457},{\"end\":91475,\"start\":91466},{\"end\":91485,\"start\":91475}]", "bib_venue": "[{\"end\":73542,\"start\":73493},{\"end\":74120,\"start\":74048},{\"end\":74490,\"start\":74374},{\"end\":74732,\"start\":74710},{\"end\":75347,\"start\":75258},{\"end\":75773,\"start\":75705},{\"end\":76316,\"start\":76258},{\"end\":76579,\"start\":76507},{\"end\":76910,\"start\":76838},{\"end\":77246,\"start\":77175},{\"end\":77845,\"start\":77826},{\"end\":79036,\"start\":78964},{\"end\":79184,\"start\":79176},{\"end\":79896,\"start\":79749},{\"end\":80738,\"start\":80666},{\"end\":81017,\"start\":80941},{\"end\":81752,\"start\":81680},{\"end\":82919,\"start\":82805},{\"end\":83540,\"start\":83483},{\"end\":83822,\"start\":83750},{\"end\":84066,\"start\":84003},{\"end\":84751,\"start\":84702},{\"end\":85103,\"start\":85032},{\"end\":85396,\"start\":85325},{\"end\":85616,\"start\":85570},{\"end\":86212,\"start\":86140},{\"end\":86603,\"start\":86487},{\"end\":87333,\"start\":87262},{\"end\":87802,\"start\":87731},{\"end\":89157,\"start\":89140},{\"end\":89807,\"start\":89713},{\"end\":90048,\"start\":89999},{\"end\":90431,\"start\":90360},{\"end\":90927,\"start\":90782},{\"end\":91234,\"start\":91162},{\"end\":91451,\"start\":91401},{\"end\":73086,\"start\":72663},{\"end\":73491,\"start\":73427},{\"end\":73741,\"start\":73680},{\"end\":73827,\"start\":73771},{\"end\":74046,\"start\":73959},{\"end\":74372,\"start\":74241},{\"end\":74708,\"start\":74656},{\"end\":74900,\"start\":74850},{\"end\":74971,\"start\":74908},{\"end\":75256,\"start\":75152},{\"end\":75505,\"start\":75500},{\"end\":75703,\"start\":75620},{\"end\":76097,\"start\":75864},{\"end\":76256,\"start\":76183},{\"end\":76492,\"start\":76405},{\"end\":76505,\"start\":76494},{\"end\":76823,\"start\":76736},{\"end\":76836,\"start\":76825},{\"end\":77173,\"start\":77087},{\"end\":77378,\"start\":77363},{\"end\":77594,\"start\":77516},{\"end\":77824,\"start\":77746},{\"end\":77933,\"start\":77871},{\"end\":78064,\"start\":77998},{\"end\":78234,\"start\":78165},{\"end\":78456,\"start\":78439},{\"end\":78583,\"start\":78558},{\"end\":78736,\"start\":78727},{\"end\":78949,\"start\":78862},{\"end\":78962,\"start\":78951},{\"end\":79174,\"start\":79151},{\"end\":79302,\"start\":79211},{\"end\":79483,\"start\":79458},{\"end\":79734,\"start\":79572},{\"end\":79747,\"start\":79736},{\"end\":80028,\"start\":79975},{\"end\":80245,\"start\":80163},{\"end\":80371,\"start\":80366},{\"end\":80651,\"start\":80564},{\"end\":80664,\"start\":80653},{\"end\":80939,\"start\":80848},{\"end\":81161,\"start\":81148},{\"end\":81238,\"start\":81172},{\"end\":81456,\"start\":81441},{\"end\":81678,\"start\":81591},{\"end\":81836,\"start\":81759},{\"end\":81971,\"start\":81961},{\"end\":82159,\"start\":82079},{\"end\":82252,\"start\":82167},{\"end\":82780,\"start\":82651},{\"end\":83127,\"start\":83035},{\"end\":83274,\"start\":83198},{\"end\":83481,\"start\":83409},{\"end\":83748,\"start\":83661},{\"end\":84001,\"start\":83923},{\"end\":84193,\"start\":84182},{\"end\":84385,\"start\":84369},{\"end\":84457,\"start\":84396},{\"end\":84700,\"start\":84636},{\"end\":85030,\"start\":84944},{\"end\":85323,\"start\":85237},{\"end\":85568,\"start\":85507},{\"end\":85763,\"start\":85738},{\"end\":85916,\"start\":85889},{\"end\":86138,\"start\":86051},{\"end\":86485,\"start\":86354},{\"end\":86818,\"start\":86726},{\"end\":86965,\"start\":86962},{\"end\":87260,\"start\":87174},{\"end\":87455,\"start\":87428},{\"end\":87547,\"start\":87520},{\"end\":87729,\"start\":87643},{\"end\":88012,\"start\":87937},{\"end\":88161,\"start\":88125},{\"end\":88239,\"start\":88172},{\"end\":88538,\"start\":88454},{\"end\":88726,\"start\":88669},{\"end\":88838,\"start\":88745},{\"end\":89138,\"start\":89047},{\"end\":89321,\"start\":89309},{\"end\":89470,\"start\":89458},{\"end\":89711,\"start\":89602},{\"end\":89983,\"start\":89919},{\"end\":89997,\"start\":89985},{\"end\":90358,\"start\":90272},{\"end\":90780,\"start\":90620},{\"end\":91160,\"start\":91073},{\"end\":91399,\"start\":91334},{\"end\":91581,\"start\":91501},{\"end\":91724,\"start\":91590},{\"end\":92021,\"start\":91728}]"}}}, "year": 2023, "month": 12, "day": 17}