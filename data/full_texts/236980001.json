{"id": 236980001, "updated": "2023-11-16 16:08:32.504", "metadata": {"title": "Federated Adversarial Debiasing for Fair and Transferable Representations", "authors": "[{\"first\":\"Junyuan\",\"last\":\"Hong\",\"middle\":[]},{\"first\":\"Zhuangdi\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Shuyang\",\"last\":\"Yu\",\"middle\":[]},{\"first\":\"Zhangyang\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Hiroko\",\"last\":\"Dodge\",\"middle\":[\"H.\"]},{\"first\":\"Jiayu\",\"last\":\"Zhou\",\"middle\":[]}]", "venue": "KDD : proceedings. International Conference on Knowledge Discovery & Data Mining", "journal": "KDD : proceedings. International Conference on Knowledge Discovery & Data Mining", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Federated learning is a distributed learning framework that is communication efficient and provides protection over participating users' raw training data. One outstanding challenge of federate learning comes from the users' heterogeneity, and learning from such data may yield biased and unfair models for minority groups. While adversarial learning is commonly used in centralized learning for mitigating bias, there are significant barriers when extending it to the federated framework. In this work, we study these barriers and address them by proposing a novel approach Federated Adversarial DEbiasing (FADE). FADE does not require users' sensitive group information for debiasing and offers users the freedom to opt-out from the adversarial component when privacy or computational costs become a concern. We show that ideally, FADE can attain the same global optimality as the one by the centralized algorithm. We then analyze when its convergence may fail in practice and propose a simple yet effective method to address the problem. Finally, we demonstrate the effectiveness of the proposed framework through extensive empirical studies, including the problem settings of unsupervised domain adaptation and fair learning. Our codes and pretrained models are available at: https://github.com/illidanlab/FADE.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": "35571559", "pubmedcentral": null, "dblp": "conf/kdd/HongZYWDZ21", "doi": "10.1145/3447548.3467281"}}, "content": {"source": {"pdf_hash": "904e65d0836ae98eb666c0e991bb5d34a5032dd1", "pdf_src": "ScienceParsePlus", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9105979", "status": "GREEN"}}, "grobid": {"id": "e94de429911285a334168768c1442a7ff3d45975", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/904e65d0836ae98eb666c0e991bb5d34a5032dd1.txt", "contents": "\nFederated Adversarial Debiasing for Fair and Transferable Representations\n\n\nJunyuan Hong \nMichigan State University\nEast LansingMichiganUSA\n\nZhuangdi Zhu \nMichigan State University\nEast LansingMichiganUSA\n\nShuyang Yu \nMichigan State University\nEast LansingMichiganUSA\n\nZhangyang Wang \nUniversity of Texas at Austin\nAustinTexasUSA\n\nHiroko Dodge \nOregon Health & Science University\nPortlandOregonUSA\n\nJiayu Zhou \nMichigan State University\nEast LansingMichiganUSA\n\nFederated Adversarial Debiasing for Fair and Transferable Representations\n5CB21BB3BB1233FFF4198B1ADC22DE6910.1145/3447548.3467281Federated learningAdversarial learningUnsupervised domain adaptationFairness\nFederated learning is a distributed learning framework that is communication efficient and provides protection over participating users' raw training data.One outstanding challenge of federate learning comes from the users' heterogeneity, and learning from such data may yield biased and unfair models for minority groups.While adversarial learning is commonly used in centralized learning for mitigating bias, there are significant barriers when extending it to the federated framework.In this work, we study these barriers and address them by proposing a novel approach Federated Adversarial DEbiasing (FADE).FADE does not require users' sensitive group information for debiasing and offers users the freedom to opt-out from the adversarial component when privacy or computational costs become a concern.We show that ideally, FADE can attain the same global optimality as the one by the centralized algorithm.We then analyze when its convergence may fail in practice and propose a simple yet effective method to address the problem.Finally, we demonstrate the effectiveness of the proposed framework through extensive empirical studies, including the problem settings of unsupervised domain adaptation and fair learning.Our codes and pre-trained models are available at: https://github.com/illidanlab/FADE.\n\nINTRODUCTION\n\nThe last decade witnessed the surging adoption of personal devices such as smartphones, smartwatches, and smart personal assistants.These devices directly interface with the users, collect personal data, conduct light-weighted computations, and use machine learning models to offer personalized services.The challenges from privacy concerns of sensitive personal data, limited computational resources, performance issues of localized learning all together lead to the federated learning (FL) paradigm [4,34].FedAvg [32], for example, provides an efficient and privacy-aware FL framework.Users train models locally, upload them to a central server iteratively aggregated to form a global model.FL greatly alleviated privacy concerns because the server can only access model parameters from the users instead of the raw data used for training.\n\nOne major challenge of FL comes from the user heterogeneity where users provide statistically different data for training local models [5,9].Such heterogeneity may come from different sources.For example, the users may collect data under various conditions according to preferential or usages differences.Consider the learning of handwashing behavior from accelerometers of smartwatches, where patterns can drastically change when using different basins worldwide.Such domain shift [19] can lead to negative impacts during knowledge transfer among users [37].Another common source of heterogeneity comes from the sensitive group information such as age, gender, and social groups, which are variables typically not to be identified during learning.Heterogeneity from this source is often associated with critical fairness issues [6] after deploying the models, where groups with less resource or smaller computation capability may be biased or even ignored during the learning [29], and the resulting global model may perform worse in minority groups.\n\nAdversarial learning [12] has been a powerful approach to mitigate bias in centralized learning, in which an adversarial objective minimizes the information extracted by an encoder that can be maximally recovered by a parameterized model, discriminator.For example, it has been applied to disentangle task-specific features that may cause negative transfer [27], to perform unsupervised domain adaptation [11,42], and recently to achieve fair learning [46].However, there are significant barriers when applying adversarial techniques in FL: 1) Most existing approaches follow a top-down principle.In the context of FL, the adversarial objective requires the server to access the sensitive group variable (e.g., gender) to construct an adversarial loss.This requirement directly violates the privacy consideration design for FL, and users may not want to disclose their sensitive group variables.2) adversarial learning demands extra information from users for training the adversarial component and imposes an additional computational burden on smart devices that may not be able to afford.3) besides, it remains unknown how the introduction of an adversarial component would impact the distributed learning behavior (e.g., convergence property) of FL.\n\nTo address the challenges mentioned above, we propose a novel adversarial framework for debiasing federated learning following a bottom-up principle, called Federated Adversarial DEbiasing (FADE).Besides the benefits from typical FL on communication efficiency and data privacy, FADE aims to achieve the following goals:\n\n\u2022 Privacy-Protecting: The learning algorithm conforms to the privacy design of FL and does not require users' group variable to achieve debiasing w.r.t. the group variable.\n\n\n\u2022\n\nAutonomous: A user can choose to join and opt-out from the adversarial component anytime (e.g., due to computational budget or privacy budget) while still participate in the regular federated learning.\n\n\u2022 Satisfiable: Under above restrictions, the distributed learning should output a debiased and accurate model, despite the user heterogeneity and unpredictable user participation.\n\nTo achieve these goals, we first propose a generic algorithm for FADE and show that ideally, it can attain the same global optimality as the one by the central algorithm.We then show how its convergence may fail in practice and propose a simple yet effective method to address the problem.Finally, we demonstrate the effectiveness of the proposed framework through extensive empirical studies on various applications.\n\n\nRELATED WORK\n\nFederated Learning (FL) [32] is a distributed learning framework that allows users with different capabilities to collaboratively train a model without sharing their own data.A critical challenge in FL is the heterogeneity among users.Viewing the learning process of FL as knowledge transfer among different users, heterogeneity in user data leads to negative transfer between users and compromises generalization [3].One idea to alleviate the negative effect from the heterogeneity during the training, is to find the consensus among users.For example, in [10,14,21,26], the consensus on task knowledge is achieved by distillation.In this work, we seek an alternative and efficient approach by adversarial debiasing the users of different groups.\n\nAdversarial Learning has been widely applied in various domains, such as neural language recognition [27], image-to-image (dense) prediction [31], image generation [12], and etc. Conceptually, adversarial learning aims to solve a two-player (or multi-player) game between two adversarial objectives, which typically leads to a min-max optimization problem.Existing approaches can be briefly categorized as: 1) Sample-to-Sample (S2S) adversarial learning, where the adversarial objective quantifies the difference between synthetic and real samples.Examples include adversarial learning against adversarial attacks [30] and generative adversarial networks [12].2) Group-to-Group (G2G) adversarial learning, which aims to reduce the max discrepancy (bias) between group distributions, for example, adversarial domain adaptation [11], adversarial fairness [46] and adversarial multi-task learning [27].All these variants assume the availability of adversarial groups in the same computation node, e.g., by aggregating data in Fig. 1a, and thus cannot be directly extended to federated learning to the violation of privacy design (requiring access of the sensitive group information).A recent effort is done by [38] where embeddings of different groups are shared (see Fig. 1b).Nevertheless, both sharing data and embeddings could induce additional privacy risk and communication costs.The proposed FADE eliminated\n\n\nFEDERATED ADVERSARIAL DEBIASING\n\nIn this section, we first formulate the proposed Federated Adversarial Debiasing (FADE) framework.We work on the standard federated learning problem setting which learns one model from a set of distributed participating users.Users conduct local learning based on their own data and send the parameters of learning models to a server periodically.The server aggregates the local models to form a global model.We assume the users have non-iid data and each user belongs to one of the E user groups as indicated by a group variable (e.g., age, gender, race) that is not to be shared outside of the local learning.\n\nThe model of each user consists of three components: a decoder f for the learning task (e.g., classification target), an encoder G, and a group discriminator D, as illustrated in Fig. 1c.\n\nIn the two-group setting (a data point belongs to either group 0 and 1), D outputs a scalar in (0, 1) approximating the probability of an input data point x belong to the group 0.More generally, for E groups, we use a softmax mapping in the last layer of D which outputs an E-dimensional vector.The FADE objective learns f, D, G by:\nmin f, G \u2112(f, G) = \u2211 g = 1 E \u2211 i = 1 m g L i, g (f, G),(1)L i, g (f, G) = L i task (f, G) + \u03bb max D L i, g adv (G, D),(2)\nwhere L i task (f, G) is the task loss for the i-th user, L i, g adv (G, D) is the adversarial loss, and m g is the number of users in group g.Note that we absorb the variable model D into L i,g in Eq.\n\n(2), and the objective is still an optimization over f, D, G.For classification tasks, the task loss can be defined as L i task (f, G) \u225c E (x, y) p i (x, y) [\u2130(f(G(x)), y)], where \u2130 denotes the cross-entropy loss and p i is the data distribution of user i.The adversarial loss is defined as\nL i, g adv (G, D) \u225c E x p i (x) logD g (G(x))\n, where D g (G(x)) is the g-th output of the softmax vector.\n\nThe optimal solution for the min-max problem is the adversarial balance when D is unable to tell the difference of G(x) among groups.For the two-group case, the adversarial loss can be modified as:\nL i, g adv (G, D) = E x p i (x) [I(g = 0)logD(G(x)) +I(g = 1)log(1 \u2212 D(G(x)))],(3)\nwhere I( \u22c5 ) is the indicator function.\n\nOne fundamental difference between traditional adversarial learning and FADE is that FADE only has one group data in the loss function.Hence, users have no sense of what an adversary (a user from other groups) looks like.Directly optimizing this objective may fail in finding the right direction towards convergence.In the worst case, the optimal solution may not be the adversarial balance.In the next section, we will provide principled analysis to the adversarial balance that is achievable under appropriate conditions.\n\nWe summarize the server and user update strategies in Algorithms 1 and 2. The server is responsible for aggregating users' models and dispatching the global models to users.Meanwhile, users train the received global model and the adversarial component using local data.Note that we use the reversal gradient strategy to implement the min-max optimization in Algorithm 1.Our algorithm enjoys the two nice properties:\n\nAutonomous: Different from vanilla FL, FADE allows the users to decide whether or not to join the learning of the discriminator D at each iteration.A user can opt-in the discriminator learning at a low frequency or completely opt-out when privacy becomes a concern or learn with restrictive computational resources.For example, in the adversarial domain adaptation setting [38] where some users have supervision and some others not, some supervised user may not want to help unsupervised users.FADE will significantly reduce the communication cost and privacy risk overhead involved by cutting down the interactions form these users.\n\nPrivacy: In the proposed FADE framework, the group label g will be restricted to local learning and the group debiasing is done through the discriminator model D. Thus, users\n\nwill not be able to obtain the other users' sensitive attributes including the group variable.Moreover, following [33], the privacy of FADE can be strictly protected by directly injecting Differential-Privacy noise during the gradient descent procedure.\n\u03b8 t + 1 \u03b2\u2211 i = 1 m n i N \u03b8 t i + (1 \u2212 \u03b2)\u03b8 t Output: f t , G t , D t\n\nOPTIMALITY ANALYSIS\n\nDespite the fact that FADE enables autonomous and improves privacy in learning, it is critical to ask if the algorithm gives a satisfiable solution and what is the optimal solution of Eq. (1).Remarkably, FADE differs from traditional adversarial learning by Eq. ( 3), where only one group is used to evaluate the adversarial objective.This imposes a unique challenge in learning as it may compromise the convergence of learning.Below we give formal analysis of the optimality when Algorithm 2 is iterated with users from two groups in non-zero probability.Since most of multi-group adversarial problems can be transformed into two-group problems, we focus on discussing the two-group case for the ease of analysis.\n\nConsider the case when each group only has one user.The data distributions for the two users are p 1 and p 2 , respectively.We single out the min-max optimization in Eq. ( 1) as:\nmin G max D E p 1 [logD(G(x))] + E p 2 [log(1 \u2212 D(G(x)))] .\nFor simplicity, we denote G(x) by z and slightly abuse p 1 (x) by p 1 (z) in our discussion.\n\nHence, we can define:\nD p 1 , p 2 = max D E p 1 [logD(z)] + E p 2 [log(1 \u2212 D(z))],\nwhich is the maximal discrepancy between p 1 (z) and p 2 (z) that D can characterize.Now, we can rewrite the min-max problem as min G D p 1 , p 2 (G) which minimizes the distribution distance over z.Alternatively, we can formulate it by min p 1 , p 2 D p 1 , p 2 since p 1 and p 2 are parameterized by G.\n\nBecause users may participate federated learning at varying frequencies, we use an auxiliary random variable \u03be i \u2208 {0, 1} for i = 0, 1 to denote whether the user is active for training.We assume \u03be i is subject to the Bernoulli distribution, B(1, \u03b1 i ).Plug \u03be i into D p 1 , p 2 to obtain D p 1 , p 2 = max D E p 1 \u03be 1 logD(z) + E p 2 \u03be 2 log(1 \u2212 D(z)) and take expectation:\nD p 1 , p 2 \u225c E \u03be 1 , \u03be 2 D p 1 , p 2 = max D E p 1 \u03b1 1 logD(z) + E p 2 \u03b1 2 log(1 \u2212 D(z)) .(4)\nTherefore, our problem is transformed as minimizing D p 1 , p 2 .\n\nNote that with p 1 and p 2 given, the solution of the maximization in D p 1 , p 2 is:\nD \u03b1 1 , \u03b1 2 * (z) = \u03b1 1 p 1 (z) \u03b1 1 p 1 (z) + \u03b1 2 p 2 (z) ,(5)\nwith which we can derive the optimality sufficiency as below.\n\nTheorem 4.1.The condition p 1 (z) = p 2 (z) is a sufficient condition for minimizing D p 1 , p 2 and the minimal value is\n\u03b1 1 log \u03b1 1 + \u03b1 2 log \u03b1 2 + (\u03b1 1 + \u03b1 2 ) log(\u03b1 1 + \u03b1 2 ).\nTheorem 4.1 shows that even if some users are inactive, the distribution matching, p 1 = p 2 , remains a sufficient optimality condition.We remark that the above result can be generalized to multiple users when all users are iid and \u03be i represent the ratio of group i in users.In addition, we notice Theorem 4.1 does not guarantee a stable convergence or exclude other undesired solutions.We discuss these issues in the following.\n\n\nThe effect of imbalanced groups\n\nAlthough Theorem 4.1 shows the optimality of the matched distribution, the optimization may still fail to converge especially when one group of users are relatively inactive, e.g., \u03b1 1 \u226a \u03b1 2 .When \u03b1 1 \u226a \u03b1 2 or reverse, we call the situation as imbalanced groups.The imbalanced groups happens because the users are free to quit or joint the training.From Eq.\n\n(5), we observe that D*(x) will be less sensitive to changes of p 1 (x) if \u03b1 1 \u226a \u03b1 2 , and vice versa.Meanwhile, log D*(x) \u2192 \u2212\u221e and D p 1 , p 2 approaches the minimum even if p 1 and p 2 are quite different.\n\nTheorem 4.2.Let \u03f5 be a positive constant.Suppose |log p1 (x) \u2212 log p2 (x)| \u2264 \u03f5 for any x in the support of p 1 and p 2 .Then we have\nD p 1 , p 2 = O \u03b1 1 \u03f5/ \u03b1 1 + \u03b1 2 when \u03b1 1 \u226a \u03b1 2 .\nTheorem 4.2 reveals that the imbalance between groups could greatly reduce the sensitivity of the discrepancy \u03f5 between p 1 and p 2 .A less sensitive discriminator will ignore the minor differences between groups.The importance of discrepancy sensitivity for the adversarial convergence was also discussed in [2].It is easy to see the negative impact of the low sensitivity: 1) higher communication cost incurs due to more communication rounds are required to check the discrepancy; 2) the optimization possibly fails to converge due to vanished gradients (scaled by \u03b1 1 ).\n\n\nSquared adversarial loss\n\nIn Eq. ( 4), when \u03b1 1 \u2192 0 and \u03b1 2 \u2192 1, we notice that D p 1 , p 2 approaches 0 while\nE p 1 [logD(z)] \u2212 \u221e.\nIn other words, the large value of E p 1 [logD(z)] is neglected due to its coefficient \u03b1 1 .To re-emphasize the value, a heuristic method is to increase the weight when E p 1 [logD(z)] is large.Thus, we propose to replace L i, g adv (G, D) by:\nL i, g, 2 adv (D, G) = \u2212 1 2 L i, g adv (G, D) 2 ,(6)\nwhich we call squared adversarial loss.We can write the corresponding discrepancy D p 1 , p 2\n\n(2)\n\nas:\nmin D \u03b1 1 E p 1 2 [logD(z)] + \u03b1 2 E p 2 2 [log(1 \u2212 D(z))] .\nThough we derive the squared adversarial loss in a heuristic manner, the loss can be explained in the view of resource-fair federated learning [22].Because the adversarial objective pays more attention to the frequent group, we can interpret the problem as the unfairness between groups.Following [22], we generalize our adversarial loss function as:\nL i, g, 2 adv (D, G) \u225c ( \u2212 1) q \u2212 1 1 q E x \u2113 k q (D, G; x) ,(7)\nwhere q \u2265 1.If q = 1, the loss degrades to the vanilla one.\n\n\nThe effect of non-iid users\n\nIt is well-known that typical federated learning approaches suffer from very heterogeneous users since they sample data from very different distributions.The adversarial objective captured and decreases the group heterogeneity by design.Another kind of heterogeneity is related to the users' tasks.We argue that the heterogeneity is natural and could be essential for the task discriminability but may be accidentally eliminated by adversarial learning.For example, three users are non-iid by three classes.After FADE training, the non-iid users collapse to the similar distributions due to the wrong sense of the group discrepancy.\n\nTo prove the existence of user-collapsed solution for FADE, we consider z ~ p(z|T = t), or simply z ~ p(z|t), where t is a discrete hidden variable related to users' tasks.For example, each user has one class of samples in classification tasks.Then t is the corresponding class.\n\nIn addition, we define\np 1 (z) = 1 m \u2211 t = 1 m p(z | t)\nwhich is a p.d.f.For simplicity, we assume all users always participate the learning, i.e., \u03b1 i = 1 for all users.Hence, we can obtain D p 1 , p 2 as\nmax D \u2211 t = 1 m E p(z | t) [logD(z)] + E p 2 [log(1 \u2212 D(z))] = max D mE p 1 (z) [logD(z)] + E p 2 [log(1 \u2212 D(z))],\nwhose maximizer is given by: D*(z) = mp 1 (z) mp 1 (z) + p 2 (z) .Use similar derivations as in Theorem\n\n4.1, we can show that p 1 (z) = p 2 (z) is a sufficient optimality condition, which implies:\n\u2211 t = 1 m p(z | t) = mp 2 (z) .(8)\nFirst, we can still obtain p 1 (z)\u2211 t = 1 m p(t | z)/p(t) = mp 2 (z) from Eq. ( 8) where we use\np(z | t) = p 1 (z) p(t | z) p(t) . If \u2211 t = 1 m p(t | z) p(t)\n= m, then we can get the vanilla solution, p 1 (z) = p 2 (z).\n\nExcept for the vanilla solution, a trivial solution to Eq. ( 8) is p(z|t) = p 2 (z).However, the solution could hurt the task utility since it may eliminate the inherent difference between tasks.For instance, if t represents the classification label, the solution will vanish the discriminability of the representation z.We call the scenario as the user collapse.It worth noticing that user collapse could happen even if the p 1 and p 2 are matched.\n\n\nMitigate user collapse\n\nSince there are arbitrarily many solutions to\n\u2211 t = 1 m p(t | z) p(t)\n= m, we need to constraint the feasible solutions such that the collapsed solution will be eliminated.Notice\np(t | z) p(t) = p(t, z) p(z)p(t)\nis related to the mutual information between t and z.Conceptually, we can modify the adversarial loss to:\nL i, g, 2 adv (D, G) = L i, g, 2 adv (D, G) + I(G(x); t | i),\nwhere I(G(x); t|i) is the mutual information conditioned on user i.Because mutual information is hard to estimate in practice (especially given few samples), we provide some surrogate solutions.\n\nIf the t represents the class labels and supervision is available, then I(G(x); t|i) is already encouraged by L task .If supervision is not available, we may maximize the entropy of the output of classifier f such that the correlation between user's tasks and representations will not disappear during training.Useful techniques were previously exploited for unsupervised domain adaptation, e.g., [28], and we defer the technique details to Section 5.2.\n\n\nPrivacy risks from malicious FADE users\n\nOur analysis suggests the feasibility of using adversarial training in the federated setting.The distribution matching is achievable under variety of cases including imbalanced groups, although the success rate may vary.But such power also implies potential privacy overhead associated with FADE.Consider a malicious user i who wants to steal data from others, FADE can match p i (x) with a victim's data p j (x).The empirical study in [16] also discussed the risk where a malicious attacker may take advantage of the discriminator to steal other users' data.Our results in Theorem 4.1 theoretically show that the attack is possible in general.During the learning of the adversarial discriminator, injecting predefined noise is known to be effective to defend such attacks [41].Meanwhile, users could quit or frequently opt-out the federated communication when the privacy budget (quantified by noise and Differential Privacy metric [7]) is low.Based on Theorem 4.2, when more and more users opt-out the communication, the adversary's discriminator can hardly sense one victim's distribution.\n\n\nEXPERIMENTS ON UNSUPERVISED DOMAIN ADAPTATION\n\nIn this section, we evaluate the FADE algorithms on Unsupervised Domain Adaptation (UDA) [10,24,38].UDA aims to mitigate the domain shift between supervised and unsupervised data such that the trained classifiers can generalize to unlabeled data.We call the supervised user (domain) as the source user (domain).Each domain may include multiple users.\n\n\nRelated work.\n\n[38] is among the first to discuss the adversarial UDA under federated constraint, through sharing the embedding of samples.However, we consider a more challenging problem, a federated adversarial learning without sharing data.Recently, learning without access to the source data has gained increasing attention.\n\n[24] (SHOT) considered the domain adaptation only using the source-domain model which surprisingly outperformed most traditional UDA with source supervisions.However, its success relies on the pre-matched representation distribution (but not well discriminated) by batch normalization (BN) layers.In the FADE setting, the BN layers will fail to match representations since the local estimate of their mean will be easily biased.In addition, in [10], distillation is used to avoid directly passing data.Differing from [10], FADE is more efficient since it does not need to upload all models from source domain to target domain.\n\nFor example, if M s users (M t ) in source (target) domain take part in training, sending models will involves M s M t communication.Instead, FADE only use M s + M t times to communicate between domains.\n\nNetwork architectures.We adopt the same network architecture as the state-of-the-art of UDA [23].As presented in Fig. 4, we first use a backbone network to extract sample features.Specifically, we use modified LeNet [28] for digit recognition, ResNet50 [15] for Office and Office-Home datasets, and ResNet101 for the VisDA-C dataset.We use an one-layer bottleneck to reduce the feature dimension.After the bottleneck, we get a representation of 256-dimension.A single fully-connected layer is used for classification at the end.The discriminators are small-scale networks to match the capability of the classifiers.The networks and algorithms are implemented using PYTORCH 1.7.The ResNet backbones pre-trained on ImageNet are retrieved from the torchvision 0.8 package.\n\n\nDigit recognition with imbalanced groups\n\nAs discussed in Section 4.1, group imbalance could result in the mismatch of group distributions.Here, we empirically evaluate the effect of the imbalanced groups on convergence, adversarial losses and utility performance.\n\nDigit dataset is a standard UDA benchmark built on digit images collected from different environments.10 digits, from 0 to 9, are included.We follow the UDA protocol of [17] and use two subsets: MNIST and USPS.MNIST dataset contains 60, 000 training images and 10, 000 testing 28 \u00d7 28 gray-scale images.USPS consists of 7291 training and 2007 testing 16 \u00d7 16 gray-scale images.We augment the USPS training set by resizing and random rotation.\n\nSetup.We assume 2 users from source and target domain, respectively.In each round, we select one user with predefined probability.For example, the case that source and target users are of 0.05 and 0.95 probability implies severe imbalance.If a user/group has high probability, that means the user/group will actively participate in the adversarial learning and the other will activate less.The experiment can also be generalized to multiple users in same frequency while one domain has more users.Both situations imply the imbalance between two groups.In experiments, we fix the batch size to 32 and run one user per communication round.In total, we train the users for global 8600 rounds.In each global round, the users will train locally for 10 iterations.Experiments are repeated 3 times with three fixed seeds.\n\nAt the beginning, we train the models with adversarial coefficient \u03bb = 0 when all source users are involved until the classification loss converges.Then, we follow [11,23] to use the decaying schedule of learning rates and schedule the adversarial coefficient \u03bb from 0 to 1.\n\nResults are reported in Fig. 2. Left two figures show the negative impact of imbalanced groups.When the imbalance is severe (large or small target probability), the drop in target accuracies is more obvious.In the middle pane, the convergence curves of imbalanced groups fluctuate more significantly and fail to converge.In the last pane, the imbalanced cases have large adversarial losses which barely decrease by federated iterations.It explains why the corresponding classification tasks fail to converge.When using the squared adversarial losses, the ignored adversarial losses of low-frequent users are reduced during federated learning.Meanwhile, the convergence of utility losses are faster.Thus, the negative impact of imbalanced groups is mitigated.\n\n\nObject recognition with non-iid users\n\nIn Section 4.3, we prove that the non-iid distribution of users will lead to a trivial solution which may lose the natural discrepancy between users.For federated classification learning where each user only has a partial set of classes, the loss of user discrepancy will make the representations non-discriminative to classes.Here, we conduct experiments to reveal the impact of the non-iid users.Baselines.We compare different UDA methods extended by FADE upon the presence of non-iid users.DANN [11] is the first work on adversarial domain adaptation based on which many recent methods are developed.CDAN [28] is the first to condition the discriminator prediction on the estimated classes, which aligns with our purpose to maximize the mutual information between user (related to classes) and representation.SHOT [23] (extended by FedAvg [32]) is the current state-of-the-art method in domain adaptation which does not use source data, assuming approximately mitigated domain shift.\n\n\nDataset\n\nResults.We summarize the results in Tables 1 and 2. Note that the straightforward extension of DANN without constraints will suffer from the user heterogeneity.Therefore, we observe catastrophic failures by DANN, for example, D\u2192A with only a low accuracy.This kind of failures happens when both D ( 498) is of less samples than A (2817).The possible reason is that the discriminators fail to sense the position of target domain batches which is a small ratio of all target-domain samples and changes frequently by iterations.against other baselines (see Table 2).We note that adversarial methods are more robust to the non-iid users.\n\n\nEXPERIMENTS ON FAIR FEDERATED LEARNING\n\nThe fair federated learning is motivated by the imbalanced groups in training.For example, when vendor rallies people to use their software and train model with locally collected data, the global model may be biased by the majority, e.g., male users.When a user from another gender uses the software, she/he may find that the model performs poorly.As a result, the minority group vanishes while majority continues to dominate.Thus, a method actively debiasing w.r.t. the groups will be essential to defend the tendency.\n\n\nRelated work.\n\nThe fairness in federated learning was first discussed in [22] where users are thought to have different capability for computation.Fairness was enforced by increasing the weights of large loss, which was less optimized.In this experiment, we consider the unfairness brought by the difference of group distributions.With FADE, we use a discriminator locally to justify whether the user's representations are biased from the other group.Related central algorithms have been exploited [8,29,45].To the best of our knowledge, we are the first to encourage such group-based fairness in federated setting.Importantly, our method preserve the privacy of group variables.The concerns of the privacy of group variables was previously discussed [13].In [13], Hashimoto et al. assumes the group membership and number of groups are unknown to the central learning server, when users interact with the system and contribute data.Our FADE extends the setting to a distributed framework where the private group information is still unknown to other parties including the aggregation server.\n\nWe utilize the Equalized Odds (\u0394EO) to evaluate the degree of fairness.Consider a binary classifier f : Z 0, 1 predicting label variable y when representations (z \u2208 Z) are sampled from two groups.We denote the conditional p.d.f.p(z|g, y) as z g,y which shapes the probability of z at group g and class y.An algorithm is said to be fair if the positive \u0394EO (defined below) is close to 0.\n\u0394EO \u225c E z 0, 0 [f(z)] \u2212 E z 1, 0 [f(z)] + E z 0, 1 [1 \u2212 f(z)] \u2212 E z 1, 1 [1 \u2212 f(z)](9)\nwhich comprises the absolute difference in false positive rates and the absolute difference in false negative rates.\n\n\nFair adult income prediction\n\nDataset.We evaluate our algorithm on the UCI Adult dataset 1 which is a standard benchmark for fair classification.The dataset consists of over 40,000 vector samples from the 1994 US Census.Each sample includes 14 attributes predicting if his/her income is over 50,000 dollars.\n\n1 https://archive.ics.uci.edu/ml/datasets/adult\n\nSetup.We adversarially disentangle the unfair representations from the gender.When keeping the total data size fixed, we construct one female user and vary the number of male users.Each synthesized user evenly split the samples in the group.We run FADE for 8,000 communication rounds.In every round, 2 users are selected to train for 1 local iteration on a batch of 64 samples.The accuracies and fairness are evaluated on the left-out 10% samples.The network structure is in Fig. 5.We set hyper-parameters as \u03b2 = 0.5 and the initial learning rate as 10 \u22123 .\n\nResults are depicted in Fig. 3a.Without adversarial training, the unfairness is aggravated when the imbalance between groups worsens.When more male users are involved, the squared adversarial loss is able to further improve the fairness.Instead, the vanilla adversarial learning performs better when the two groups are balanced.Both adversarial losses will maintain the utility performance close to the non-adversarial method.\n\n\nFair MCI detection\n\nDataset.Mild Cognition Impairment (MCI) is the pre-symptom of Alzheimer's Disease (AD) which typically happens on elders.Early detection of MCI is important for prevention of AD occurrence and treatment [1,43].Details of the dataset is comprised in Appendix B.3 where females forms the majority group (over 94%).The prediction task here is to classify the disease condition, Normal Cognition (NC) or MCI, based on the daily activities (walking speed, etc.).\n\nSetup.In the original dataset, there are 88 users with different number of samples.We notice the imbalance between NC and MCI users will greatly degrade the model quality.To focus on our fairness task, we manually select 26 users such that 13 users was diagnosed as NC at least once and the other 13 ones are stable MCI patients.Because male users are much fewer than female ones, we prefer to select male users when balancing the two classes.\n\nAfter downsampling, users have 39 samples on average.Among the 26 users, there are 6 males and 20 females in total.Details of features, preprocessing and network architectures are deferred to Appendix B.3.We set hyper-parameters as \u03b2 = 0.5, the initial learning rate as 10 \u22122 and batch size as 16.In the 700 communication rounds, we first train without adversarial losses for 400 rounds and then schedule the \u03bb and learning rates as the Adult experiments.\n\nResults.We compare the convergence of the training F 1 -score (utility) and \u0394EO (fairness) by varying the number of users per round.As shown in Fig. 3b, the unfairness is obvious with \u0394EO over 0.2 when no adversarial losses are used.We see that the vanilla adversarial loss failed to debias in most cases.In contrast, the squared adversarial loss stably debias the unfair performance in all cases.When the number of users per round is less than 10, even the non-adversarial loss is more fair.The natural debiasing could be attributed to the random selection of users, which breaks the domination of one group in a short span.\n\n\nCONCLUSION\n\nIn this work, we propose a unified framework for federated adversarial learning called FADE.Our framework preserves the user privacy and allows user to freely opt-in/out the learning of the adversarial component.To our best knowledge, we are the first to study the properties of adversarial learning in the federated setting.We presented the potential challenge and solution for the FADE, and identified a gap between FADE and its centralized counterpart as an open question for our future work.\n\n\nAcknowledgement\n\nThis material is based in part upon work supported by the National Science Foundation under Grant IIS-1749940, EPCN-2053272, Office of Naval Research N00014-20-1-2382, and National Institute on Aging (NIA) R01AG051628, R01AG056102, P30AG066518, P30AG024978, RF1AG072449.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.Copyrights for components of this work owned by others than ACM must be honored.Abstracting with credit is permitted.To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.Request permissions from permissions@acm.org.\n\n\nA: PROOFS\n\nPROOF OF THEOREM 4.1.Substitute D \u03b1 1 , \u03b1 2 * (z) into Eq.( 4):\nD p 1 , p 2 = E p 1 \u03b1 1 log \u03b1 1 p 1 (z) \u03b1 1 p 1 (z) + \u03b1 2 p 2 (z) + E p 2 \u03b1 2 log \u03b1 2 p 2 (z) \u03b1 1 p 1 (z) + \u03b1 2 p 2 (z) = \u03b1 1 KL p 1 \u03b1 1 p 1 + \u03b1 2 p 2 \u03b1 1 + \u03b1 2 + \u03b1 2 KL p 2 \u03b1 1 p 1 + \u03b1 2 p 2 \u03b1 1 + \u03b1 2 + \u03b1 1 log\u03b1 1 + \u03b1 2 log\u03b1 2 + \u03b1 1 + \u03b1 2 log \u03b1 1 + \u03b1 2 \u2265 \u03b1 1 log\u03b1 1 + \u03b1 2 log\u03b1 2 + \u03b1 1 + \u03b1 2 log \u03b1 1 + \u03b1 2\nwhere the last inequality is from the non-negative property of KL divergence.\n\nNote when p 1 = p 2 , both KL divergence is 0. Thus, we can conclude that p 1 = p 2 is the sufficient condition.\u25a1 PROOF OF THEOREM 4.2.For the ease of derivation, we assume \u03b1 1 and \u03b1 2 are normalized s.t.\u03b1 1 + \u03b1 2 = 1.From |log p 1 (x) -log p 2 (x)| \u2264 \u03f5, we can get where we manually add (\u03b1 1 + \u03b1 2 ) to normalize \u03b1 1 .\u25a1\n\n\nB: EXPERIMENT DETAILS\n\n\nB.1 Dynamic schedules\n\nWe use dynamic schedules for learning rates and the adversarial parameter \u03bb following previous work [11].Specifically,\n\u03b7 t = 1 1 + 10 t T max K 0.75 \u03bb t = 2 1 + exp \u221210t/T max \u2212 1\nwhere K is the number of local iterations and T max is the number of global rounds.Notably, \u03b7 t is schedule locally and \u03bb t is scheduled globally.\n\n\nB.2 Network architectures\n\nFederated UDA.\n\nThe network architectures are presented in Fig. 4. Network architectures for digit and object datasets.WN denotes the weight-norm layer [23] and FC 256 denotes fully-connected layer with 256 units.GRL is the gradient reversal layer [11].\n\n\nBatch normalization in FADE.\n\nDuring training, we share the parameters of ResNet between users.Notably, in ResNet, batch normalization (BN) layer is densely embedded in different depth.The BN layer is known to be important for transferring between distinct domains, because the hidden representations will be normalized with mean and variance estimated from a batch.Because such estimation could be easily biased by a small batch, running estimation by accumulating results from previous batches is a common practice.Thus, it is also important for all users to get the global estimate of the mean and variance by communication.However, sharing such a running estimate of representation mean and standard variance may leak the private information [35,36].For example, given a feature vector at a specific layer, the input image can be reverted using a conditional generative network [35,36].Instead of sharing the mean and variance (BN states), we keep the values the same as values pre-trained on ImageNet.\n\n\nFair federated learning.\n\nWe depict the network architectures for Adult and MCI datasets in Fig. 5.For the Adult dataset, we aim to evaluate the performance of deep networks.Thus, we use a deeper network other than a shallow one for central algorithms [29].Because of the small size of the MCI dataset, we adopt a small network architecture where only two layers of LSTM are used for feature extraction and one layer for classification or group identifying.\n\n\nB.3 Details of MCI datasets Dataset\n\nDue to the mild symptoms and expansive cost of clinic diagnosis, early detection of MCI is a hard task.To address the challenge, MCI detection models is built on a MCI dataset, which is collected with Intelligent Systems for Assessing Aging Change (ISAAC), a longitudinal cohort study [18,20].A total of 152 participants were enrolled beginning in 2017.12 variables are extracted from the participants' sensor data and clinical diagnoses was done once a year.Meanwhile, four kinds of demographic information are also recorded, including age, gender, education, and ethnicity, which are potentially unfair features for each patient.\n\nThough prior work has shown the effectiveness of machine learning methods in diagnosis prediction [18,25], the possibility of training such a model fairly in a distributed framework remains unknown.We assume the sensor data can be immediately trained locally and only the trained models are sent to the server.The distributed framework brings in several new challenges.First, users' data are kept locally and many users only have one-class data which makes the local model less discriminative.For example, 13 users are always diagnosed as MCI during his/her recording.Second, it is difficult to do adversarial learning like Fig. 1b.\n\nBecause the users' group information, e.g., gender, can not be revealed to others, the server has no idea who will be the adversarial group.Therefore, we utilize the FADE framework to tackle these issues as illustrated in Fig. 1c.As far as privacy is concerned, in the ISAAC protocol, the sensor data were collected periodically by engineers such that the user data are kept away from others.But we argue that our extension to federated setting is practical because the data are not directly shared.\n\n\nPreprocessing.\n\nSince the records of some patients are missing due to occasionally off-line of sensor systems, and these incomplete samples can introduce uncertainty in our experiments, we choose to remove some samples according to a certain missing value.To generate samples, hundreds of days of records for each patient will then be sliced by a moving window, and each slice is used as a sample for training or to be predicted.The slicing is done inside each person's sequence without overlap.The time window is moved in a step of 7 days.Only a subsequence of a small enough ratio of missing values will be maintained for the current study.The number of sequences for each patient is related to the amount of data the patient has.For some of the patients, they have only a small number of records.We also remove the samples of those patients to avoid inaccurate prediction.\n\nWe have 12 varaibles in total, including gender (Rsex), years of education (Ryrschool), race/ethnicity (Rethnic), age at each date (ageyrs), total computer use (compuse), computer sessions (numcsess), track sensor line (linenum), walks (numwalks), mean walking speed (meanws), upper quartile of walking speed (wsq3), coefficient of var of walking speed (wscv) and std deviation of walking speed (wsstddev).We preprocess special variables in the following specified methods.For linenum which is a sensor metric identity value, its integer values are transformed into a one-hot encoding form that uses the position of a single one to indicate the ID value.RSex and Rethic variables are encoded in the same way.The ages are transformed by 3-bin discretization.All continuous variables are normalized within [\u22121, 1] by min-max scaling such that no significant variance will occur between different variables and their coefficients could be trained in a numerically robust way.\n\nAll the data features are collected in a relatively redundant way, for which they should be carefully selected for better prediction performance.We select features using mutual information, which measures the dependency between the variables.It is equal to zero if and only if two random variables are independent, and the higher value means higher dependency.A special case is the linenum variable which only makes sense when other walking speed features are used.As a result, when a walking feature is selected according to the above metrics, the linenum variable is automatically included.\n\n\nCCS CONCEPTS\n\n\u2022 Computing methodologies \u2192 Distributed algorithms; Machine learning; \u2022 Transfer learningL\n\nFigure 4 :\n4\nFigure 4:\n\n\nFigure 5 :\n5\nFigure 5: Network architectures for Adult and MCI datasets.LSTM 100 indicates a Long Short-Term Memory (LSTM) cell with 100 hidden units.\n\n\nFigure 1 :\n1\nFigure 1:Illustrations of different adversarial learning frameworks for debiasing.f, D and G are classifier (task model), discriminator and encoder, respectively.C 1 , C 2 , C 3 represents the task supervisions, for example, ground-truth classes, in the corresponding users.g 1 and g 2 represents the two groups of users.The encoders are adversarially trained such that the embeddings are informative for distinguishing C 1 , C 2 , C 3 but not g 1 , g 2 .The proposed FADE tackles a more challenging problem than other two because of isolated and nonsharing group/user data (or embeddings) and class-wise non-iid users within groups.\n\n\nFigure 2 :\n2\nFigure 2: Comparison of vanilla adversarial loss versus the squared adversarial loss on MNISTto-USPS (top) and USPS-to-MNIST (bottom) UDA.We vary the probability of target users.For both UDA experiments, the SOTA central methods [23] can achieve over 98% accuracies.From left to right, the columns are target domain accuracies, classification losses and adversarial losses of target domain users.\n\n\nFigure 3 :\n3\nFigure 3: FADE with/without adversarial losses.In each subfigure, left is fairness measured by \u0394EO where smaller values indicates better fairness; right is the trade off between fairness and utility where left-top is the preferred balance.\n\n\n\n\n. 31 object classes of images are taken under different office environments (corresponding to domains).The Office-Home datasets have 65 categories and 4 domains: Artistic images (Ar), Clip Art (Cl), Product images (Pr), and Real-World images (Re) with 2427, 4365, 4439 and 4357 images, respectively.The VisDA dataset is a challenging large-scale benchmark.The source domain comprises 12-way synthetic classification data.In total, 4 users are generated from two domain datasets.First, we let the single source domain user with all classes.Second, we generate 3 non-iid target domain users with partial set of classes following the standard federated setting[32].For Office dataset, each user has 20 classes and adjacent users have consecutive classes with 10-class stride.For instance, user 1 has class 0 to 20 and user 2 has class 10 to 30.For OfficeHome dataset, each user has 45 classes with 20-class stride.For VisDA-C dataset, each user has 5 classes with 4-class stride.All users in the same domain will have the same number of samples.We select 2 users per communication round when training on OfficeHome.For VisDA-C dataset, we adopt 1 user per round.In this case, the major difficulty comes from non-iid distributions of users conditioned on the subset of classes.In experiments, the parameters for SHOT follows[23].Details of network architectures and learning setup are discussed in Appendix B.\nIn total, 1.5 \u00d7 10 5 images are synthesized by rendering 3D models and are adapted to 55,000 unlabeled real-world images.Setup.. We adopt three object recognition datasets, Office [40] (small size), Office-Home[44] (medium size) and VisDA-C [39] (large size), including image of office products. The\nformer two are standard benchmarks widely used for UDA.The Office dataset contains three domains: Amazon (A), DSLR (D) and Webcam (W) with 2817, 498, 795 images, respectively\n\n\n\n\nIn comparison, when regulated by estimated classes, SHOT and methods combined with SHOT perform better.Notably, because SHOT relies on BN states to mitigate domain shift, its accuracies are much worse than its central version.Since SHOT can provide pseudo supervisions which conditions on the estimated users' local classes, DANN+SHOT outperforms DANN.In reverse, DANN helps SHOT to mitigate the domain shift.We further explore CDAN+SHOT, which conditions group discrimination on local classifier outputs (correlated to users' classes).As a result, CDAN+SHOT outperforms other methods and is close to the central version of CDAN.Plus, CDAN+SHOT achieves the best average accuracies when the number of users per round varies from 1 to 4. Remarkably, in the hardest case where only one user is trained per round, CDAN+SHOT gains the best accuracies on 8 out of 9 tasks.In a more challenging large-scale VisDA-C dataset, CDAN+SHOT also shows its advantage\nAuthor ManuscriptAuthor ManuscriptAuthor ManuscriptAuthor Manuscript\n\nTable 1 :\n1\nAveraged classification UDA accuracies (%) on Office and OfficeHome dataset with 3 non-iid target users and 1 source user.Underlines indicate the occurrence of non-converged results.Standard deviations are included in brackets.\nA\u2192D A\u2192W D\u2192A D\u2192W W\u2192A W\u2192D Re\u2192Ar Re\u2192Cl Re\u2192Pr Avg.Federated methods79.5 73.4 59.6 91.6 58.2 95.8 67.0 46.5 78.2 72.2non-iid target users w/ 20 (Office) or 45 (OfficeHome) classes per user85.4 (1.9) 81.8 (1.8) 43.1 (33) 97.7 (0.5) 64.8 (0.5) 99.7 (0.2) 46.4 (37) 34.9 (27) 78.8(0.1) 70.392.3 (1.2) 91.6 (0.5) 65.9(9.3) 98.9 (0.2) 70.2 (0.8) 99.9 (0.1) 70.3 (1.6) 54.9 (4.6) 82.2 (0.1) 80.783.6 (0.5) 83.1 (0.5) 64.7 (1.4) 91.7 (0.2) 64.7 (2.2) 97.4 (0.5) 70.7 (0.5) 55.4 (0.5) 80.1 (0.3) 76.8iid target users84.2 (1.5) 81.3 (0.4) 66.3 (0.3) 97.5 (1.2) 59.4 (10.6) 99.9 (0.2) 67.3 (0.9) 51.3 (0.4) 79.0 (0.6) 76.293.6 (0.8) 92.2 (1.3)MethodSource onlyFADE-DANNFADE-CDANFedAvg-SHOTFADE-DANNFADE-CDAN\n\n71.2 (1.0) 98.7 (0.4)\n100 (0.0) 70.6 (1.3) 55.1 (1.0) 82.3 (0.2) 81.799.8 (0.0) 74.8 (0.3) 60.0 (0.1) 84.9 (0.2) 83.699.3 53.9 41.2 59.9 67.998.7 65.3 45.4 78.0 73.899.1 63.2 51.8 76.8 76.1100 70.9 56.7 81.6 81.799.9 73.3 58.8 84.3 83.171.3 (0.7)96.3 (0.5) 94.3 (1.1) 70.9 (2.0) 98.4 (0.4) 72.7 (0.9)Central methods68.9 68.4 62.5 96.7 60.780.8 76.9 60.3 95.3 63.679.7 82.0 68.2 96.9 67.492.9 94.1 71.0 98.6 69.394.0 90.1 74.7 98.4 74.3FedAvg-SHOTResNet [15]Source only [23]DANN [11]CDAN [28]SHOT [23]\n\nTable 2 :\n2\nComparison of target accuracies on Visda-C dataset.\nMethods Source only DANN SHOTCDANCentral46.657.682.973.9FADE54.356.469.273.1 (+SHOT)\nKDD.Author manuscript; available in PMC 2022 August 14.\n\nP S Aisen, S Andrieu, C Sampaio, M Carrillo, Z S Khachaturian, B Dubois, H H Feldman, R C Petersen, E Siemers, R S Doody, S B Hendrix, M Grundman, L S Schneider, R J Schindler, E Salmon, W Z Potter, R G Thomas, D Salmon, M Donohue, M M Bednar, J Touchon, B Vellas, Report of the Task Force on Designing Clinical Trials in Early (Predementia) AD. 2011. Jan. 201176PubMed: 21178097\n\n. Arjovsky Martin, Chintala Soumith, Bottou L\u00e9on, Wasserstein GAN. 2017. Jan. 2017\n\nA Theory of Learning from Different Domains. Ben-David Shai, Blitzer John, Crammer Koby, Kulesza Alex, Pereira Fernando, Vaughan Jennifer Wortman, Machine Language. 792010. May 2010\n\nPractical Secure Aggregation for Privacy-Preserving Machine Learning. Bonawitz Keith, Ivanov Vladimir, Kreuter Ben, Marcedone Antonio, H Mcmahan, Sarvar Brendan, Ramage Patel, Segal Daniel, Seth Aaron, Karn, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS '17). the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS '17)New York, NY, USAAssociation for Computing Machinery2017\n\nPersonalized Federated Learning with Moreau Envelopes. Dinh Canh, T , Tran Nguyen, H Nguyen Tuan, Dung , Advances in Neural Information Processing Systems. 2020\n\nFairness through Awareness. Dwork Cynthia, Hardt Moritz, Pitassi Toniann, Reingold Omer, Zemel Richard, Proceedings of the 3rd Innovations in Theoretical Computer Science Conference (ITCS '12). the 3rd Innovations in Theoretical Computer Science Conference (ITCS '12)Cambridge, MassachusettsAssociation for Computing Machinery2012\n\nCalibrating Noise to Sensitivity in Private Data Analysis. Dwork Cynthia, Frank Mcsherry Kobbi, Smith Nissim, Adam, Theory of Cryptography. Lecture Notes in Computer Science. Berlin HeidelbergSpringer2006\n\nCensoring Representations with an Adversary. Edwards Harrison, Storkey Amos, ICLR. 2016. March 2016\n\nPersonalized Federated Learning: A Meta-Learning Approach. Mokhtari Fallah Alireza, Ozdaglar Aryan, Asuman, Advances in Neural Information Processing Systems. 2020\n\nKD3A: Unsupervised Multi-Source Decentralized Domain Adaptation via Knowledge Distillation. Feng Hao-Zhe, You Zhaoyang, Chen Minghao, Zhang Tianye, Zhu Minfeng, Wu Fei, Wu Chao, Chen Wei, 2021. 2021AAAI\n\nUnsupervised Domain Adaptation by Backpropagation. Ganin Yaroslav, Lempitsky Victor, International Conference on Machine Learning. PMLR2015\n\nJ Goodfellow Ian, Jean Pouget-Abadie, Mehdi Mirza, Xu Bing, David , Warde-Farley Sherjil Ozair, Courville Aaron, Bengio Yoshua, arXiv:1406.2661Generative Adversarial Networks. 2014. June 2014cs, stat\n\nFairness without demographics in repeated loss minimization. Hashimoto Tatsunori, Srivastava Megha, Namkoong Hongseok, Liang Percy, International Conference on Machine Learning. PMLR2018\n\nHe Chaoyang, Annavaram Murali, Avestimehr Salman, arXiv:2007.14513Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge. 2020. Nov. 2020\n\nDeep Residual Learning for Image Recognition. He Kaiming, Zhang Xiangyu, Ren Shaoqing, Sun Jian, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2016. 2016\n\nDeep Models Under the GAN: Information Leakage from Collaborative Deep Learning. Hitaj Briland, Ateniese Giuseppe, Perez-Cruz Fernando, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS '17). the 2017 ACM SIGSAC Conference on Computer and Communications Security (CCS '17)New York, NY, USAACM2017\n\nCyCADA: Cycle-Consistent Adversarial Domain Adaptation. Hoffman Judy, Tzeng Eric, Park Taesung, Zhu Jun-Yan, Isola Phillip, Saenko Kate, Efros Alexei, Darrell Trevor, International Conference on Machine Learning. PMLR2018. 1989-1998\n\nDetecting MCI Using Real-Time, Ecologically Valid Data Capture Methodology: How to Improve Scientific Rigor in Digital Biomarker Analyses. Hong Junyuan, Kaye Jeffrey, Dodge Hiroko, H , Zhou Jiayu, Alzheimer's & Dementia. 16e0443712020. 2020\n\nDataset Shift in Machine Learning | The. Qui\u00f1onero-Candela Joaquin, Sugiyama Masashi, Anton Schwaighofer, Lawrence Neil, D , 2008MIT Press\n\nKaye Jeffrey, A Maxwell, Shoshana A , Mattek Nora, Hayes Tamara, L Dodge Hiroko, Pavel Misha, Jimison Holly, B Wild Katherine, Boise Linda, Zitzelberger Tracy, A , Intelligent Systems for Assessing Aging Changes: Home-Based, Unobtrusive, and Continuous Assessment of Aging. 2011. July 201166\n\nLi Daliang, Wang Junpu, arXiv:1910.03581FedMD: Heterogenous Federated Learning via Model Distillation. 2019. Oct. 2019cs, stat\n\nFair Resource Allocation in Federated Learning. Li Tian, Sanjabi Maziar, Beirami Ahmad, Smith Virginia, International Conference on Learning Representations. 2019\n\nDo We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation. Liang Jian, Hu Dapeng, Feng Jiashi, International Conference on Machine Learning. 2020. Oct. 2020\n\nSource Data-Absent Unsupervised Domain Adaptation through Hypothesis Transfer and Labeling Transfer. Liang Jian, Hu Dapeng, Wang Yunbo, ArXiv. 2020. 2020He Ran, and Feng Jiashi\n\nBig Data Analytical Approaches to the NACC Dataset: Aiding Preclinical Trial Enrichment. Lin Ming, Gong Pinghua, Yang Tao, Ye Jieping, Albin Roger, L , Dodge Hiroko, H , Alzheimer Disease & Associated Disorders. 322018. 2018PubMed: 29227306] [26\n\nEnsemble Distillation for Robust Model Fusion in Federated Learning. Lin Tao, Kong Lingjing, Stich Sebastian, U , Jaggi Martin, Advances in Neural Information Processing Systems. 2020\n\nAdversarial Multi-Task Learning for Text Classification. Liu Pengfei, Qiu Xipeng, Huang Xuanjing, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics20171\n\nLong Mingsheng, csCao Zhangjie, csWang Jianmin, csJordan Michael, csI , csarXiv:1705.10667Conditional Adversarial Domain Adaptation. 2018. Dec. 2018\n\nMadras David, Creager Elliot, Pitassi Toniann, Zemel Richard, Learning Adversarially Fair and Transferable Representations. International Conference on Machine Learning. 2018. 201811\n\nMadry Aleksander, Makelov Aleksandar, Schmidt Ludwig, Tsipras Dimitris, Vladu Adrian, arXiv:1706.06083Towards Deep Learning Models Resistant to Adversarial Attacks. 2019. Sept. 2019cs, stat\n\nAttentive Single-Tasking of Multiple Tasks. Maninis Kevis-Kokitsi, Radosavovic Ilija, Kokkinos Iasonas, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2019\n\nCommunication-Efficient Learning of Deep Networks from Decentralized Data. Brendan Mcmahan, Eider Moore, Ramage Daniel, Hampson Seth, Arcas Blaise Aguera Y, Artificial Intelligence and Statistics. 2017\n\nLearning Differentially Private Recurrent Language Models. Brendan Mcmahan, H , Ramage Daniel, Talwar Kunal, Zhang Li, International Conference on Learning Representations. 2018\n\nSecureML: A System for Scalable Privacy-Preserving Machine Learning. P Mohassel, Y Zhang, 2017 IEEE Symposium on Security and Privacy (SP). 2017\n\nPlug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space. Clune Nguyen Anh, Bengio Jeff, Dosovitskiy Yoshua, Yosinski Alexey, Jason, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2017\n\nSynthesizing the Preferred Inputs for Neurons in Neural Networks via Deep Generator Networks. Dosovitskiy Nguyen Anh, Yosinski Alexey, Brox Jason, Clune Thomas, Jeff, Advances in Neural Information Processing Systems. Curran Associates, Inc201629\n\nA Survey on Transfer Learning. Pan Sinno, Jialin , Yang Qiang, IEEE Transactions on Knowledge and Data Engineering. 222010. Oct. 2010\n\nFederated Adversarial Domain Adaptation. Peng Xingchao, Zhu Huang Zijun, Saenko Yizhe, Kate, International Conference on Learning Representations. 2019\n\nPeng Xingchao, Usman Ben, Kaushik Neela, Hoffman Judy, Wang Dequan, Saenko Kate, arXiv:1710.06924VisDA: The Visual Domain Adaptation Challenge. 2017. Nov. 2017\n\nAdapting Visual Category Models to New Domains. Saenko Kate, Kulis Brian, Fritz Mario, Darrell Trevor, Proceedings of the 11th European Conference on Computer Vision: Part IV (ECCV'10). the 11th European Conference on Computer Vision: Part IV (ECCV'10)Berlin, HeidelbergSpringer-Verlag2010\n\nDP-CGAN: Differentially Private Synthetic Data and Label Generation. Torkzadehmahani Reihaneh, Kairouz Peter, Paten Benedict, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern RecognitionWorkshops. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionWorkshops2019\n\nAdversarial Discriminative Domain Adaptation. Tzeng Eric, Hoffman Judy, Kate Saenko, Darrell Trevor, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2017\n\nB Vellas, R Bateman, K Blennow, G Frisoni, K Johnson, R Katz, J Langbaum, D Marson, R Sperling, A Wessels, S Salloway, R Doody, Aisen P , Endpoints for Pre-Dementia AD Trials: A Report from the EU/US/CTAD Task Force. The journal of prevention of Alzheimer's disease. 2015. June 20152\n\nDeep Hashing Network for Unsupervised Domain Adaptation. Venkateswara Hemanth, Eusebio Jose, Chakraborty Shayok, Panchanathan Sethuraman, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2017\n\nAchieving Fairness through Adversarial Learning: An Application to Recidivism Prediction. Wadsworth Christina, Francesca Vera, Piech Chris, arXiv:1807.001992018. June 2018cs, stat\n\nMitigating Unwanted Biases with Adversarial Learning. Brian Zhang, Lemoine Hu, Mitchell Blake, Margaret, Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society (AIES '18). the 2018 AAAI/ACM Conference on AI, Ethics, and Society (AIES '18)New York, NY, USAAssociation for Computing Machinery2018\n", "annotations": {"author": "[{\"end\":141,\"start\":77},{\"end\":206,\"start\":142},{\"end\":269,\"start\":207},{\"end\":331,\"start\":270},{\"end\":399,\"start\":332},{\"end\":462,\"start\":400}]", "publisher": null, "author_last_name": "[{\"end\":89,\"start\":85},{\"end\":154,\"start\":151},{\"end\":217,\"start\":215},{\"end\":284,\"start\":280},{\"end\":344,\"start\":339},{\"end\":410,\"start\":406}]", "author_first_name": "[{\"end\":84,\"start\":77},{\"end\":150,\"start\":142},{\"end\":214,\"start\":207},{\"end\":279,\"start\":270},{\"end\":338,\"start\":332},{\"end\":405,\"start\":400}]", "author_affiliation": "[{\"end\":140,\"start\":91},{\"end\":205,\"start\":156},{\"end\":268,\"start\":219},{\"end\":330,\"start\":286},{\"end\":398,\"start\":346},{\"end\":461,\"start\":412}]", "title": "[{\"end\":74,\"start\":1},{\"end\":536,\"start\":463}]", "venue": null, "abstract": "[{\"end\":1977,\"start\":669}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2497,\"start\":2494},{\"end\":2500,\"start\":2497},{\"end\":2512,\"start\":2501},{\"end\":2974,\"start\":2971},{\"end\":2976,\"start\":2974},{\"end\":3322,\"start\":3318},{\"end\":3394,\"start\":3390},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3668,\"start\":3665},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3817,\"start\":3813},{\"end\":3914,\"start\":3910},{\"end\":4250,\"start\":4246},{\"end\":4298,\"start\":4294},{\"end\":4301,\"start\":4298},{\"end\":4345,\"start\":4341},{\"end\":5338,\"start\":5332},{\"end\":6489,\"start\":6485},{\"end\":6878,\"start\":6875},{\"end\":7022,\"start\":7018},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7025,\"start\":7022},{\"end\":7028,\"start\":7025},{\"end\":7031,\"start\":7028},{\"end\":7355,\"start\":7351},{\"end\":7378,\"start\":7374},{\"end\":7869,\"start\":7865},{\"end\":8040,\"start\":8036},{\"end\":8067,\"start\":8063},{\"end\":8108,\"start\":8104},{\"end\":8421,\"start\":8417},{\"end\":12156,\"start\":12152},{\"end\":12708,\"start\":12704},{\"end\":16829,\"start\":16826},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":17834,\"start\":17830},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":17988,\"start\":17984},{\"end\":21336,\"start\":21332},{\"end\":22209,\"start\":22205},{\"end\":22368,\"start\":22365},{\"end\":22667,\"start\":22663},{\"end\":22670,\"start\":22667},{\"end\":22673,\"start\":22670},{\"end\":23704,\"start\":23700},{\"end\":24185,\"start\":24181},{\"end\":24309,\"start\":24305},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":24346,\"start\":24342},{\"end\":26555,\"start\":26551},{\"end\":26558,\"start\":26555},{\"end\":27965,\"start\":27961},{\"end\":28075,\"start\":28071},{\"end\":28284,\"start\":28280},{\"end\":28309,\"start\":28305},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":29736,\"start\":29732},{\"end\":30160,\"start\":30157},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30163,\"start\":30160},{\"end\":30166,\"start\":30163},{\"end\":30414,\"start\":30410},{\"end\":32917,\"start\":32914},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":32920,\"start\":32917},{\"end\":37007,\"start\":37003},{\"end\":37415,\"start\":37411},{\"end\":37511,\"start\":37507},{\"end\":38265,\"start\":38261},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":38268,\"start\":38265},{\"end\":38401,\"start\":38397},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":38404,\"start\":38401},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":38780,\"start\":38776},{\"end\":39310,\"start\":39306},{\"end\":39313,\"start\":39310},{\"end\":39756,\"start\":39752},{\"end\":39759,\"start\":39756}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":43365,\"start\":43341},{\"attributes\":{\"id\":\"fig_2\"},\"end\":43518,\"start\":43366},{\"attributes\":{\"id\":\"fig_3\"},\"end\":44167,\"start\":43519},{\"attributes\":{\"id\":\"fig_4\"},\"end\":44579,\"start\":44168},{\"attributes\":{\"id\":\"fig_5\"},\"end\":44834,\"start\":44580},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":46719,\"start\":44835},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":47744,\"start\":46720},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":48678,\"start\":47745},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":49180,\"start\":48679},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":49330,\"start\":49181}]", "paragraph": "[{\"end\":2834,\"start\":1993},{\"end\":3887,\"start\":2836},{\"end\":5141,\"start\":3889},{\"end\":5463,\"start\":5143},{\"end\":5637,\"start\":5465},{\"end\":5844,\"start\":5643},{\"end\":6025,\"start\":5846},{\"end\":6444,\"start\":6027},{\"end\":7208,\"start\":6461},{\"end\":8620,\"start\":7210},{\"end\":9267,\"start\":8656},{\"end\":9456,\"start\":9269},{\"end\":9790,\"start\":9458},{\"end\":10114,\"start\":9913},{\"end\":10406,\"start\":10116},{\"end\":10513,\"start\":10453},{\"end\":10712,\"start\":10515},{\"end\":10835,\"start\":10796},{\"end\":11360,\"start\":10837},{\"end\":11777,\"start\":11362},{\"end\":12412,\"start\":11779},{\"end\":12588,\"start\":12414},{\"end\":12843,\"start\":12590},{\"end\":13648,\"start\":12934},{\"end\":13828,\"start\":13650},{\"end\":13981,\"start\":13889},{\"end\":14004,\"start\":13983},{\"end\":14370,\"start\":14066},{\"end\":14745,\"start\":14372},{\"end\":14906,\"start\":14841},{\"end\":14993,\"start\":14908},{\"end\":15118,\"start\":15057},{\"end\":15241,\"start\":15120},{\"end\":15730,\"start\":15300},{\"end\":16123,\"start\":15766},{\"end\":16332,\"start\":16125},{\"end\":16466,\"start\":16334},{\"end\":17090,\"start\":16517},{\"end\":17203,\"start\":17119},{\"end\":17468,\"start\":17225},{\"end\":17616,\"start\":17523},{\"end\":17621,\"start\":17618},{\"end\":17626,\"start\":17623},{\"end\":18037,\"start\":17687},{\"end\":18162,\"start\":18103},{\"end\":18826,\"start\":18194},{\"end\":19106,\"start\":18828},{\"end\":19130,\"start\":19108},{\"end\":19313,\"start\":19164},{\"end\":19532,\"start\":19429},{\"end\":19626,\"start\":19534},{\"end\":19757,\"start\":19662},{\"end\":19881,\"start\":19820},{\"end\":20332,\"start\":19883},{\"end\":20404,\"start\":20359},{\"end\":20537,\"start\":20429},{\"end\":20676,\"start\":20571},{\"end\":20933,\"start\":20739},{\"end\":21388,\"start\":20935},{\"end\":22524,\"start\":21432},{\"end\":22924,\"start\":22574},{\"end\":23254,\"start\":22942},{\"end\":23882,\"start\":23256},{\"end\":24087,\"start\":23884},{\"end\":24858,\"start\":24089},{\"end\":25125,\"start\":24903},{\"end\":25569,\"start\":25127},{\"end\":26385,\"start\":25571},{\"end\":26661,\"start\":26387},{\"end\":27421,\"start\":26663},{\"end\":28449,\"start\":27463},{\"end\":29094,\"start\":28461},{\"end\":29656,\"start\":29137},{\"end\":30750,\"start\":29674},{\"end\":31138,\"start\":30752},{\"end\":31342,\"start\":31226},{\"end\":31652,\"start\":31375},{\"end\":31701,\"start\":31654},{\"end\":32260,\"start\":31703},{\"end\":32688,\"start\":32262},{\"end\":33168,\"start\":32711},{\"end\":33613,\"start\":33170},{\"end\":34070,\"start\":33615},{\"end\":34697,\"start\":34072},{\"end\":35207,\"start\":34712},{\"end\":35497,\"start\":35227},{\"end\":36070,\"start\":35499},{\"end\":36147,\"start\":36084},{\"end\":36531,\"start\":36454},{\"end\":36853,\"start\":36533},{\"end\":37021,\"start\":36903},{\"end\":37229,\"start\":37083},{\"end\":37273,\"start\":37259},{\"end\":37512,\"start\":37275},{\"end\":38521,\"start\":37545},{\"end\":38981,\"start\":38550},{\"end\":39652,\"start\":39021},{\"end\":40286,\"start\":39654},{\"end\":40787,\"start\":40288},{\"end\":41665,\"start\":40806},{\"end\":42639,\"start\":41667},{\"end\":43233,\"start\":42641},{\"end\":43340,\"start\":43250},{\"end\":43364,\"start\":43355},{\"end\":43517,\"start\":43380},{\"end\":44166,\"start\":43533},{\"end\":44578,\"start\":44182},{\"end\":44833,\"start\":44594},{\"end\":46243,\"start\":44838},{\"end\":46718,\"start\":46544},{\"end\":47675,\"start\":46723},{\"end\":47985,\"start\":47758},{\"end\":49245,\"start\":49194}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9849,\"start\":9791},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9912,\"start\":9849},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10452,\"start\":10407},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10795,\"start\":10713},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12911,\"start\":12844},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13888,\"start\":13829},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14065,\"start\":14005},{\"attributes\":{\"id\":\"formula_7\"},\"end\":14840,\"start\":14746},{\"attributes\":{\"id\":\"formula_8\"},\"end\":15056,\"start\":14994},{\"attributes\":{\"id\":\"formula_9\"},\"end\":15299,\"start\":15242},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16516,\"start\":16467},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17224,\"start\":17204},{\"attributes\":{\"id\":\"formula_12\"},\"end\":17522,\"start\":17469},{\"attributes\":{\"id\":\"formula_13\"},\"end\":17686,\"start\":17627},{\"attributes\":{\"id\":\"formula_14\"},\"end\":18102,\"start\":18038},{\"attributes\":{\"id\":\"formula_15\"},\"end\":19163,\"start\":19131},{\"attributes\":{\"id\":\"formula_16\"},\"end\":19428,\"start\":19314},{\"attributes\":{\"id\":\"formula_17\"},\"end\":19661,\"start\":19627},{\"attributes\":{\"id\":\"formula_18\"},\"end\":19819,\"start\":19758},{\"attributes\":{\"id\":\"formula_19\"},\"end\":20428,\"start\":20405},{\"attributes\":{\"id\":\"formula_20\"},\"end\":20570,\"start\":20538},{\"attributes\":{\"id\":\"formula_21\"},\"end\":20738,\"start\":20677},{\"attributes\":{\"id\":\"formula_22\"},\"end\":31225,\"start\":31139},{\"attributes\":{\"id\":\"formula_23\"},\"end\":36453,\"start\":36148},{\"attributes\":{\"id\":\"formula_24\"},\"end\":37082,\"start\":37022}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":28511,\"start\":28504},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":29022,\"start\":29021}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1991,\"start\":1979},{\"end\":5641,\"start\":5640},{\"attributes\":{\"n\":\"2\"},\"end\":6459,\"start\":6447},{\"attributes\":{\"n\":\"3\"},\"end\":8654,\"start\":8623},{\"attributes\":{\"n\":\"4\"},\"end\":12932,\"start\":12913},{\"attributes\":{\"n\":\"4.1\"},\"end\":15764,\"start\":15733},{\"attributes\":{\"n\":\"4.2\"},\"end\":17117,\"start\":17093},{\"attributes\":{\"n\":\"4.3\"},\"end\":18192,\"start\":18165},{\"attributes\":{\"n\":\"4.4\"},\"end\":20357,\"start\":20335},{\"attributes\":{\"n\":\"4.5\"},\"end\":21430,\"start\":21391},{\"attributes\":{\"n\":\"5\"},\"end\":22572,\"start\":22527},{\"end\":22940,\"start\":22927},{\"attributes\":{\"n\":\"5.1\"},\"end\":24901,\"start\":24861},{\"attributes\":{\"n\":\"5.2\"},\"end\":27461,\"start\":27424},{\"end\":28459,\"start\":28452},{\"attributes\":{\"n\":\"6\"},\"end\":29135,\"start\":29097},{\"end\":29672,\"start\":29659},{\"attributes\":{\"n\":\"6.1\"},\"end\":31373,\"start\":31345},{\"attributes\":{\"n\":\"6.2\"},\"end\":32709,\"start\":32691},{\"attributes\":{\"n\":\"7\"},\"end\":34710,\"start\":34700},{\"end\":35225,\"start\":35210},{\"end\":36082,\"start\":36073},{\"end\":36877,\"start\":36856},{\"end\":36901,\"start\":36880},{\"end\":37257,\"start\":37232},{\"end\":37543,\"start\":37515},{\"end\":38548,\"start\":38524},{\"end\":39019,\"start\":38984},{\"end\":40804,\"start\":40790},{\"end\":43248,\"start\":43236},{\"end\":43352,\"start\":43342},{\"end\":43377,\"start\":43367},{\"end\":43530,\"start\":43520},{\"end\":44179,\"start\":44169},{\"end\":44591,\"start\":44581},{\"end\":47755,\"start\":47746},{\"end\":48701,\"start\":48680},{\"end\":49191,\"start\":49182}]", "table": "[{\"end\":46543,\"start\":46244},{\"end\":47744,\"start\":47676},{\"end\":48678,\"start\":47986},{\"end\":49180,\"start\":48702},{\"end\":49330,\"start\":49246}]", "figure_caption": "[{\"end\":43365,\"start\":43354},{\"end\":43518,\"start\":43379},{\"end\":44167,\"start\":43532},{\"end\":44579,\"start\":44181},{\"end\":44834,\"start\":44593},{\"end\":46244,\"start\":44837},{\"end\":47676,\"start\":46722},{\"end\":47986,\"start\":47757},{\"end\":49246,\"start\":49193}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":8240,\"start\":8238},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":8482,\"start\":8480},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":9455,\"start\":9453},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":24208,\"start\":24207},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":26693,\"start\":26692},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":32184,\"start\":32183},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":32293,\"start\":32291},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":34223,\"start\":34221},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":37324,\"start\":37323},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":38622,\"start\":38621},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":40285,\"start\":40283},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":40517,\"start\":40515}]", "bib_author_first_name": "[{\"end\":49389,\"start\":49388},{\"end\":49391,\"start\":49390},{\"end\":49400,\"start\":49399},{\"end\":49411,\"start\":49410},{\"end\":49422,\"start\":49421},{\"end\":49434,\"start\":49433},{\"end\":49436,\"start\":49435},{\"end\":49452,\"start\":49451},{\"end\":49462,\"start\":49461},{\"end\":49464,\"start\":49463},{\"end\":49475,\"start\":49474},{\"end\":49477,\"start\":49476},{\"end\":49489,\"start\":49488},{\"end\":49500,\"start\":49499},{\"end\":49502,\"start\":49501},{\"end\":49511,\"start\":49510},{\"end\":49513,\"start\":49512},{\"end\":49524,\"start\":49523},{\"end\":49536,\"start\":49535},{\"end\":49538,\"start\":49537},{\"end\":49551,\"start\":49550},{\"end\":49553,\"start\":49552},{\"end\":49566,\"start\":49565},{\"end\":49576,\"start\":49575},{\"end\":49578,\"start\":49577},{\"end\":49588,\"start\":49587},{\"end\":49590,\"start\":49589},{\"end\":49600,\"start\":49599},{\"end\":49610,\"start\":49609},{\"end\":49621,\"start\":49620},{\"end\":49623,\"start\":49622},{\"end\":49633,\"start\":49632},{\"end\":49644,\"start\":49643},{\"end\":49779,\"start\":49771},{\"end\":49796,\"start\":49788},{\"end\":49812,\"start\":49806},{\"end\":49907,\"start\":49898},{\"end\":49921,\"start\":49914},{\"end\":49935,\"start\":49928},{\"end\":49949,\"start\":49942},{\"end\":49963,\"start\":49956},{\"end\":49981,\"start\":49974},{\"end\":50114,\"start\":50106},{\"end\":50128,\"start\":50122},{\"end\":50146,\"start\":50139},{\"end\":50161,\"start\":50152},{\"end\":50172,\"start\":50171},{\"end\":50188,\"start\":50182},{\"end\":50204,\"start\":50198},{\"end\":50217,\"start\":50212},{\"end\":50230,\"start\":50226},{\"end\":50538,\"start\":50534},{\"end\":50546,\"start\":50545},{\"end\":50553,\"start\":50549},{\"end\":50563,\"start\":50562},{\"end\":50581,\"start\":50577},{\"end\":50674,\"start\":50669},{\"end\":50689,\"start\":50684},{\"end\":50705,\"start\":50698},{\"end\":50723,\"start\":50715},{\"end\":50735,\"start\":50730},{\"end\":51037,\"start\":51032},{\"end\":51052,\"start\":51047},{\"end\":51074,\"start\":51069},{\"end\":51231,\"start\":51224},{\"end\":51249,\"start\":51242},{\"end\":51347,\"start\":51339},{\"end\":51372,\"start\":51364},{\"end\":51541,\"start\":51537},{\"end\":51554,\"start\":51551},{\"end\":51569,\"start\":51565},{\"end\":51584,\"start\":51579},{\"end\":51596,\"start\":51593},{\"end\":51608,\"start\":51606},{\"end\":51616,\"start\":51614},{\"end\":51627,\"start\":51623},{\"end\":51705,\"start\":51700},{\"end\":51725,\"start\":51716},{\"end\":51791,\"start\":51790},{\"end\":51812,\"start\":51808},{\"end\":51833,\"start\":51828},{\"end\":51843,\"start\":51841},{\"end\":51855,\"start\":51850},{\"end\":51878,\"start\":51858},{\"end\":51895,\"start\":51886},{\"end\":51909,\"start\":51903},{\"end\":52061,\"start\":52052},{\"end\":52083,\"start\":52073},{\"end\":52099,\"start\":52091},{\"end\":52115,\"start\":52110},{\"end\":52181,\"start\":52179},{\"end\":52201,\"start\":52192},{\"end\":52220,\"start\":52210},{\"end\":52382,\"start\":52380},{\"end\":52397,\"start\":52392},{\"end\":52410,\"start\":52407},{\"end\":52424,\"start\":52421},{\"end\":52678,\"start\":52673},{\"end\":52696,\"start\":52688},{\"end\":52717,\"start\":52707},{\"end\":52994,\"start\":52987},{\"end\":53006,\"start\":53001},{\"end\":53017,\"start\":53013},{\"end\":53030,\"start\":53027},{\"end\":53045,\"start\":53040},{\"end\":53061,\"start\":53055},{\"end\":53073,\"start\":53068},{\"end\":53089,\"start\":53082},{\"end\":53308,\"start\":53304},{\"end\":53322,\"start\":53318},{\"end\":53337,\"start\":53332},{\"end\":53347,\"start\":53346},{\"end\":53354,\"start\":53350},{\"end\":53465,\"start\":53448},{\"end\":53483,\"start\":53475},{\"end\":53498,\"start\":53493},{\"end\":53521,\"start\":53513},{\"end\":53529,\"start\":53528},{\"end\":53551,\"start\":53547},{\"end\":53562,\"start\":53561},{\"end\":53580,\"start\":53572},{\"end\":53582,\"start\":53581},{\"end\":53591,\"start\":53585},{\"end\":53603,\"start\":53598},{\"end\":53613,\"start\":53612},{\"end\":53633,\"start\":53628},{\"end\":53648,\"start\":53641},{\"end\":53657,\"start\":53656},{\"end\":53679,\"start\":53674},{\"end\":53699,\"start\":53687},{\"end\":53708,\"start\":53707},{\"end\":53842,\"start\":53840},{\"end\":53856,\"start\":53852},{\"end\":54018,\"start\":54016},{\"end\":54032,\"start\":54025},{\"end\":54048,\"start\":54041},{\"end\":54061,\"start\":54056},{\"end\":54245,\"start\":54240},{\"end\":54254,\"start\":54252},{\"end\":54267,\"start\":54263},{\"end\":54445,\"start\":54440},{\"end\":54454,\"start\":54452},{\"end\":54467,\"start\":54463},{\"end\":54609,\"start\":54606},{\"end\":54620,\"start\":54616},{\"end\":54634,\"start\":54630},{\"end\":54642,\"start\":54640},{\"end\":54657,\"start\":54652},{\"end\":54666,\"start\":54665},{\"end\":54674,\"start\":54669},{\"end\":54684,\"start\":54683},{\"end\":54836,\"start\":54833},{\"end\":54846,\"start\":54842},{\"end\":54862,\"start\":54857},{\"end\":54875,\"start\":54874},{\"end\":54883,\"start\":54878},{\"end\":55009,\"start\":55006},{\"end\":55022,\"start\":55019},{\"end\":55036,\"start\":55031},{\"end\":55290,\"start\":55286},{\"end\":55307,\"start\":55304},{\"end\":55324,\"start\":55320},{\"end\":55342,\"start\":55336},{\"end\":55355,\"start\":55354},{\"end\":55442,\"start\":55436},{\"end\":55457,\"start\":55450},{\"end\":55473,\"start\":55466},{\"end\":55488,\"start\":55483},{\"end\":55625,\"start\":55620},{\"end\":55645,\"start\":55638},{\"end\":55665,\"start\":55658},{\"end\":55681,\"start\":55674},{\"end\":55697,\"start\":55692},{\"end\":55862,\"start\":55855},{\"end\":55889,\"start\":55878},{\"end\":55905,\"start\":55897},{\"end\":56152,\"start\":56145},{\"end\":56167,\"start\":56162},{\"end\":56181,\"start\":56175},{\"end\":56197,\"start\":56190},{\"end\":56209,\"start\":56204},{\"end\":56339,\"start\":56332},{\"end\":56350,\"start\":56349},{\"end\":56359,\"start\":56353},{\"end\":56374,\"start\":56368},{\"end\":56387,\"start\":56382},{\"end\":56522,\"start\":56521},{\"end\":56534,\"start\":56533},{\"end\":56696,\"start\":56691},{\"end\":56715,\"start\":56709},{\"end\":56733,\"start\":56722},{\"end\":56750,\"start\":56742},{\"end\":57018,\"start\":57007},{\"end\":57039,\"start\":57031},{\"end\":57052,\"start\":57048},{\"end\":57065,\"start\":57060},{\"end\":57195,\"start\":57192},{\"end\":57209,\"start\":57203},{\"end\":57216,\"start\":57212},{\"end\":57341,\"start\":57337},{\"end\":57355,\"start\":57352},{\"end\":57375,\"start\":57369},{\"end\":57453,\"start\":57449},{\"end\":57469,\"start\":57464},{\"end\":57482,\"start\":57475},{\"end\":57497,\"start\":57490},{\"end\":57508,\"start\":57504},{\"end\":57523,\"start\":57517},{\"end\":57664,\"start\":57658},{\"end\":57676,\"start\":57671},{\"end\":57689,\"start\":57684},{\"end\":57704,\"start\":57697},{\"end\":57985,\"start\":57970},{\"end\":58003,\"start\":57996},{\"end\":58016,\"start\":58011},{\"end\":58251,\"start\":58246},{\"end\":58265,\"start\":58258},{\"end\":58276,\"start\":58272},{\"end\":58292,\"start\":58285},{\"end\":58449,\"start\":58448},{\"end\":58459,\"start\":58458},{\"end\":58470,\"start\":58469},{\"end\":58481,\"start\":58480},{\"end\":58492,\"start\":58491},{\"end\":58503,\"start\":58502},{\"end\":58511,\"start\":58510},{\"end\":58523,\"start\":58522},{\"end\":58533,\"start\":58532},{\"end\":58545,\"start\":58544},{\"end\":58556,\"start\":58555},{\"end\":58568,\"start\":58567},{\"end\":58581,\"start\":58576},{\"end\":58583,\"start\":58582},{\"end\":58802,\"start\":58790},{\"end\":58819,\"start\":58812},{\"end\":58837,\"start\":58826},{\"end\":58858,\"start\":58846},{\"end\":59117,\"start\":59108},{\"end\":59138,\"start\":59129},{\"end\":59150,\"start\":59145},{\"end\":59258,\"start\":59253},{\"end\":59273,\"start\":59266},{\"end\":59286,\"start\":59278}]", "bib_author_last_name": "[{\"end\":49397,\"start\":49392},{\"end\":49408,\"start\":49401},{\"end\":49419,\"start\":49412},{\"end\":49431,\"start\":49423},{\"end\":49449,\"start\":49437},{\"end\":49459,\"start\":49453},{\"end\":49472,\"start\":49465},{\"end\":49486,\"start\":49478},{\"end\":49497,\"start\":49490},{\"end\":49508,\"start\":49503},{\"end\":49521,\"start\":49514},{\"end\":49533,\"start\":49525},{\"end\":49548,\"start\":49539},{\"end\":49563,\"start\":49554},{\"end\":49573,\"start\":49567},{\"end\":49585,\"start\":49579},{\"end\":49597,\"start\":49591},{\"end\":49607,\"start\":49601},{\"end\":49618,\"start\":49611},{\"end\":49630,\"start\":49624},{\"end\":49641,\"start\":49634},{\"end\":49651,\"start\":49645},{\"end\":49786,\"start\":49780},{\"end\":49804,\"start\":49797},{\"end\":49817,\"start\":49813},{\"end\":49912,\"start\":49908},{\"end\":49926,\"start\":49922},{\"end\":49940,\"start\":49936},{\"end\":49954,\"start\":49950},{\"end\":49972,\"start\":49964},{\"end\":49998,\"start\":49982},{\"end\":50120,\"start\":50115},{\"end\":50137,\"start\":50129},{\"end\":50150,\"start\":50147},{\"end\":50169,\"start\":50162},{\"end\":50180,\"start\":50173},{\"end\":50196,\"start\":50189},{\"end\":50210,\"start\":50205},{\"end\":50224,\"start\":50218},{\"end\":50236,\"start\":50231},{\"end\":50242,\"start\":50238},{\"end\":50543,\"start\":50539},{\"end\":50560,\"start\":50554},{\"end\":50575,\"start\":50564},{\"end\":50682,\"start\":50675},{\"end\":50696,\"start\":50690},{\"end\":50713,\"start\":50706},{\"end\":50728,\"start\":50724},{\"end\":50743,\"start\":50736},{\"end\":51045,\"start\":51038},{\"end\":51067,\"start\":51053},{\"end\":51081,\"start\":51075},{\"end\":51087,\"start\":51083},{\"end\":51240,\"start\":51232},{\"end\":51254,\"start\":51250},{\"end\":51362,\"start\":51348},{\"end\":51378,\"start\":51373},{\"end\":51386,\"start\":51380},{\"end\":51549,\"start\":51542},{\"end\":51563,\"start\":51555},{\"end\":51577,\"start\":51570},{\"end\":51591,\"start\":51585},{\"end\":51604,\"start\":51597},{\"end\":51612,\"start\":51609},{\"end\":51621,\"start\":51617},{\"end\":51631,\"start\":51628},{\"end\":51714,\"start\":51706},{\"end\":51732,\"start\":51726},{\"end\":51806,\"start\":51792},{\"end\":51826,\"start\":51813},{\"end\":51839,\"start\":51834},{\"end\":51848,\"start\":51844},{\"end\":51884,\"start\":51879},{\"end\":51901,\"start\":51896},{\"end\":51916,\"start\":51910},{\"end\":52071,\"start\":52062},{\"end\":52089,\"start\":52084},{\"end\":52108,\"start\":52100},{\"end\":52121,\"start\":52116},{\"end\":52190,\"start\":52182},{\"end\":52208,\"start\":52202},{\"end\":52227,\"start\":52221},{\"end\":52390,\"start\":52383},{\"end\":52405,\"start\":52398},{\"end\":52419,\"start\":52411},{\"end\":52429,\"start\":52425},{\"end\":52686,\"start\":52679},{\"end\":52705,\"start\":52697},{\"end\":52726,\"start\":52718},{\"end\":52999,\"start\":52995},{\"end\":53011,\"start\":53007},{\"end\":53025,\"start\":53018},{\"end\":53038,\"start\":53031},{\"end\":53053,\"start\":53046},{\"end\":53066,\"start\":53062},{\"end\":53080,\"start\":53074},{\"end\":53096,\"start\":53090},{\"end\":53316,\"start\":53309},{\"end\":53330,\"start\":53323},{\"end\":53344,\"start\":53338},{\"end\":53360,\"start\":53355},{\"end\":53473,\"start\":53466},{\"end\":53491,\"start\":53484},{\"end\":53511,\"start\":53499},{\"end\":53526,\"start\":53522},{\"end\":53559,\"start\":53552},{\"end\":53570,\"start\":53563},{\"end\":53596,\"start\":53592},{\"end\":53610,\"start\":53604},{\"end\":53626,\"start\":53614},{\"end\":53639,\"start\":53634},{\"end\":53654,\"start\":53649},{\"end\":53672,\"start\":53658},{\"end\":53685,\"start\":53680},{\"end\":53705,\"start\":53700},{\"end\":53850,\"start\":53843},{\"end\":53862,\"start\":53857},{\"end\":54023,\"start\":54019},{\"end\":54039,\"start\":54033},{\"end\":54054,\"start\":54049},{\"end\":54070,\"start\":54062},{\"end\":54250,\"start\":54246},{\"end\":54261,\"start\":54255},{\"end\":54274,\"start\":54268},{\"end\":54450,\"start\":54446},{\"end\":54461,\"start\":54455},{\"end\":54473,\"start\":54468},{\"end\":54614,\"start\":54610},{\"end\":54628,\"start\":54621},{\"end\":54638,\"start\":54635},{\"end\":54650,\"start\":54643},{\"end\":54663,\"start\":54658},{\"end\":54681,\"start\":54675},{\"end\":54840,\"start\":54837},{\"end\":54855,\"start\":54847},{\"end\":54872,\"start\":54863},{\"end\":54890,\"start\":54884},{\"end\":55017,\"start\":55010},{\"end\":55029,\"start\":55023},{\"end\":55045,\"start\":55037},{\"end\":55300,\"start\":55291},{\"end\":55316,\"start\":55308},{\"end\":55332,\"start\":55325},{\"end\":55350,\"start\":55343},{\"end\":55448,\"start\":55443},{\"end\":55464,\"start\":55458},{\"end\":55481,\"start\":55474},{\"end\":55496,\"start\":55489},{\"end\":55636,\"start\":55626},{\"end\":55656,\"start\":55646},{\"end\":55672,\"start\":55666},{\"end\":55690,\"start\":55682},{\"end\":55704,\"start\":55698},{\"end\":55876,\"start\":55863},{\"end\":55895,\"start\":55890},{\"end\":55913,\"start\":55906},{\"end\":56160,\"start\":56153},{\"end\":56173,\"start\":56168},{\"end\":56188,\"start\":56182},{\"end\":56202,\"start\":56198},{\"end\":56225,\"start\":56210},{\"end\":56347,\"start\":56340},{\"end\":56366,\"start\":56360},{\"end\":56380,\"start\":56375},{\"end\":56390,\"start\":56388},{\"end\":56531,\"start\":56523},{\"end\":56540,\"start\":56535},{\"end\":56707,\"start\":56697},{\"end\":56720,\"start\":56716},{\"end\":56740,\"start\":56734},{\"end\":56757,\"start\":56751},{\"end\":56764,\"start\":56759},{\"end\":57029,\"start\":57019},{\"end\":57046,\"start\":57040},{\"end\":57058,\"start\":57053},{\"end\":57072,\"start\":57066},{\"end\":57078,\"start\":57074},{\"end\":57201,\"start\":57196},{\"end\":57222,\"start\":57217},{\"end\":57350,\"start\":57342},{\"end\":57367,\"start\":57356},{\"end\":57381,\"start\":57376},{\"end\":57387,\"start\":57383},{\"end\":57462,\"start\":57454},{\"end\":57473,\"start\":57470},{\"end\":57488,\"start\":57483},{\"end\":57502,\"start\":57498},{\"end\":57515,\"start\":57509},{\"end\":57528,\"start\":57524},{\"end\":57669,\"start\":57665},{\"end\":57682,\"start\":57677},{\"end\":57695,\"start\":57690},{\"end\":57711,\"start\":57705},{\"end\":57994,\"start\":57986},{\"end\":58009,\"start\":58004},{\"end\":58025,\"start\":58017},{\"end\":58256,\"start\":58252},{\"end\":58270,\"start\":58266},{\"end\":58283,\"start\":58277},{\"end\":58299,\"start\":58293},{\"end\":58456,\"start\":58450},{\"end\":58467,\"start\":58460},{\"end\":58478,\"start\":58471},{\"end\":58489,\"start\":58482},{\"end\":58500,\"start\":58493},{\"end\":58508,\"start\":58504},{\"end\":58520,\"start\":58512},{\"end\":58530,\"start\":58524},{\"end\":58542,\"start\":58534},{\"end\":58553,\"start\":58546},{\"end\":58565,\"start\":58557},{\"end\":58574,\"start\":58569},{\"end\":58810,\"start\":58803},{\"end\":58824,\"start\":58820},{\"end\":58844,\"start\":58838},{\"end\":58869,\"start\":58859},{\"end\":59127,\"start\":59118},{\"end\":59143,\"start\":59139},{\"end\":59156,\"start\":59151},{\"end\":59264,\"start\":59259},{\"end\":59276,\"start\":59274},{\"end\":59292,\"start\":59287},{\"end\":59302,\"start\":59294}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":49767,\"start\":49388},{\"attributes\":{\"id\":\"b1\"},\"end\":49851,\"start\":49769},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":8577357},\"end\":50034,\"start\":49853},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3833774},\"end\":50477,\"start\":50036},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":219708331},\"end\":50639,\"start\":50479},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":13496699},\"end\":50971,\"start\":50641},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":2468323},\"end\":51177,\"start\":50973},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4986726},\"end\":51278,\"start\":51179},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":211171538},\"end\":51443,\"start\":51280},{\"attributes\":{\"id\":\"b9\"},\"end\":51647,\"start\":51445},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":6755881},\"end\":51788,\"start\":51649},{\"attributes\":{\"doi\":\"arXiv:1406.2661\",\"id\":\"b11\"},\"end\":51989,\"start\":51790},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":49343170},\"end\":52177,\"start\":51991},{\"attributes\":{\"doi\":\"arXiv:2007.14513\",\"id\":\"b13\"},\"end\":52332,\"start\":52179},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":206594692},\"end\":52590,\"start\":52334},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":5051282},\"end\":52929,\"start\":52592},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":7646250},\"end\":53163,\"start\":52931},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":227501185},\"end\":53405,\"start\":53165},{\"attributes\":{\"id\":\"b18\"},\"end\":53545,\"start\":53407},{\"attributes\":{\"id\":\"b19\"},\"end\":53838,\"start\":53547},{\"attributes\":{\"doi\":\"arXiv:1910.03581\",\"id\":\"b20\"},\"end\":53966,\"start\":53840},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":166227978},\"end\":54130,\"start\":53968},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":211205159},\"end\":54337,\"start\":54132},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":229156384},\"end\":54515,\"start\":54339},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":4578315},\"end\":54762,\"start\":54517},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":219636007},\"end\":54947,\"start\":54764},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":630188},\"end\":55284,\"start\":54949},{\"attributes\":{\"doi\":\"arXiv:1705.10667\",\"id\":\"b27\"},\"end\":55434,\"start\":55286},{\"attributes\":{\"id\":\"b28\"},\"end\":55618,\"start\":55436},{\"attributes\":{\"doi\":\"arXiv:1706.06083\",\"id\":\"b29\"},\"end\":55809,\"start\":55620},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":121100839},\"end\":56068,\"start\":55811},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":14955348},\"end\":56271,\"start\":56070},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":3461939},\"end\":56450,\"start\":56273},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":11605311},\"end\":56596,\"start\":56452},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":2023211},\"end\":56911,\"start\":56598},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":5284428},\"end\":57159,\"start\":56913},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":740063},\"end\":57294,\"start\":57161},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":207880633},\"end\":57447,\"start\":57296},{\"attributes\":{\"doi\":\"arXiv:1710.06924\",\"id\":\"b38\"},\"end\":57608,\"start\":57449},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":7534823},\"end\":57899,\"start\":57610},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":198181039},\"end\":58198,\"start\":57901},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":4357800},\"end\":58446,\"start\":58200},{\"attributes\":{\"id\":\"b42\"},\"end\":58731,\"start\":58448},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":2928248},\"end\":59016,\"start\":58733},{\"attributes\":{\"doi\":\"arXiv:1807.00199\",\"id\":\"b44\"},\"end\":59197,\"start\":59018},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":9424845},\"end\":59509,\"start\":59199}]", "bib_title": "[{\"end\":49896,\"start\":49853},{\"end\":50104,\"start\":50036},{\"end\":50532,\"start\":50479},{\"end\":50667,\"start\":50641},{\"end\":51030,\"start\":50973},{\"end\":51222,\"start\":51179},{\"end\":51337,\"start\":51280},{\"end\":51698,\"start\":51649},{\"end\":52050,\"start\":51991},{\"end\":52378,\"start\":52334},{\"end\":52671,\"start\":52592},{\"end\":52985,\"start\":52931},{\"end\":53302,\"start\":53165},{\"end\":54014,\"start\":53968},{\"end\":54238,\"start\":54132},{\"end\":54438,\"start\":54339},{\"end\":54604,\"start\":54517},{\"end\":54831,\"start\":54764},{\"end\":55004,\"start\":54949},{\"end\":55853,\"start\":55811},{\"end\":56143,\"start\":56070},{\"end\":56330,\"start\":56273},{\"end\":56519,\"start\":56452},{\"end\":56689,\"start\":56598},{\"end\":57005,\"start\":56913},{\"end\":57190,\"start\":57161},{\"end\":57335,\"start\":57296},{\"end\":57656,\"start\":57610},{\"end\":57968,\"start\":57901},{\"end\":58244,\"start\":58200},{\"end\":58788,\"start\":58733},{\"end\":59251,\"start\":59199}]", "bib_author": "[{\"end\":49399,\"start\":49388},{\"end\":49410,\"start\":49399},{\"end\":49421,\"start\":49410},{\"end\":49433,\"start\":49421},{\"end\":49451,\"start\":49433},{\"end\":49461,\"start\":49451},{\"end\":49474,\"start\":49461},{\"end\":49488,\"start\":49474},{\"end\":49499,\"start\":49488},{\"end\":49510,\"start\":49499},{\"end\":49523,\"start\":49510},{\"end\":49535,\"start\":49523},{\"end\":49550,\"start\":49535},{\"end\":49565,\"start\":49550},{\"end\":49575,\"start\":49565},{\"end\":49587,\"start\":49575},{\"end\":49599,\"start\":49587},{\"end\":49609,\"start\":49599},{\"end\":49620,\"start\":49609},{\"end\":49632,\"start\":49620},{\"end\":49643,\"start\":49632},{\"end\":49653,\"start\":49643},{\"end\":49788,\"start\":49771},{\"end\":49806,\"start\":49788},{\"end\":49819,\"start\":49806},{\"end\":49914,\"start\":49898},{\"end\":49928,\"start\":49914},{\"end\":49942,\"start\":49928},{\"end\":49956,\"start\":49942},{\"end\":49974,\"start\":49956},{\"end\":50000,\"start\":49974},{\"end\":50122,\"start\":50106},{\"end\":50139,\"start\":50122},{\"end\":50152,\"start\":50139},{\"end\":50171,\"start\":50152},{\"end\":50182,\"start\":50171},{\"end\":50198,\"start\":50182},{\"end\":50212,\"start\":50198},{\"end\":50226,\"start\":50212},{\"end\":50238,\"start\":50226},{\"end\":50244,\"start\":50238},{\"end\":50545,\"start\":50534},{\"end\":50549,\"start\":50545},{\"end\":50562,\"start\":50549},{\"end\":50577,\"start\":50562},{\"end\":50584,\"start\":50577},{\"end\":50684,\"start\":50669},{\"end\":50698,\"start\":50684},{\"end\":50715,\"start\":50698},{\"end\":50730,\"start\":50715},{\"end\":50745,\"start\":50730},{\"end\":51047,\"start\":51032},{\"end\":51069,\"start\":51047},{\"end\":51083,\"start\":51069},{\"end\":51089,\"start\":51083},{\"end\":51242,\"start\":51224},{\"end\":51256,\"start\":51242},{\"end\":51364,\"start\":51339},{\"end\":51380,\"start\":51364},{\"end\":51388,\"start\":51380},{\"end\":51551,\"start\":51537},{\"end\":51565,\"start\":51551},{\"end\":51579,\"start\":51565},{\"end\":51593,\"start\":51579},{\"end\":51606,\"start\":51593},{\"end\":51614,\"start\":51606},{\"end\":51623,\"start\":51614},{\"end\":51633,\"start\":51623},{\"end\":51716,\"start\":51700},{\"end\":51734,\"start\":51716},{\"end\":51808,\"start\":51790},{\"end\":51828,\"start\":51808},{\"end\":51841,\"start\":51828},{\"end\":51850,\"start\":51841},{\"end\":51858,\"start\":51850},{\"end\":51886,\"start\":51858},{\"end\":51903,\"start\":51886},{\"end\":51918,\"start\":51903},{\"end\":52073,\"start\":52052},{\"end\":52091,\"start\":52073},{\"end\":52110,\"start\":52091},{\"end\":52123,\"start\":52110},{\"end\":52192,\"start\":52179},{\"end\":52210,\"start\":52192},{\"end\":52229,\"start\":52210},{\"end\":52392,\"start\":52380},{\"end\":52407,\"start\":52392},{\"end\":52421,\"start\":52407},{\"end\":52431,\"start\":52421},{\"end\":52688,\"start\":52673},{\"end\":52707,\"start\":52688},{\"end\":52728,\"start\":52707},{\"end\":53001,\"start\":52987},{\"end\":53013,\"start\":53001},{\"end\":53027,\"start\":53013},{\"end\":53040,\"start\":53027},{\"end\":53055,\"start\":53040},{\"end\":53068,\"start\":53055},{\"end\":53082,\"start\":53068},{\"end\":53098,\"start\":53082},{\"end\":53318,\"start\":53304},{\"end\":53332,\"start\":53318},{\"end\":53346,\"start\":53332},{\"end\":53350,\"start\":53346},{\"end\":53362,\"start\":53350},{\"end\":53475,\"start\":53448},{\"end\":53493,\"start\":53475},{\"end\":53513,\"start\":53493},{\"end\":53528,\"start\":53513},{\"end\":53532,\"start\":53528},{\"end\":53561,\"start\":53547},{\"end\":53572,\"start\":53561},{\"end\":53585,\"start\":53572},{\"end\":53598,\"start\":53585},{\"end\":53612,\"start\":53598},{\"end\":53628,\"start\":53612},{\"end\":53641,\"start\":53628},{\"end\":53656,\"start\":53641},{\"end\":53674,\"start\":53656},{\"end\":53687,\"start\":53674},{\"end\":53707,\"start\":53687},{\"end\":53711,\"start\":53707},{\"end\":53852,\"start\":53840},{\"end\":53864,\"start\":53852},{\"end\":54025,\"start\":54016},{\"end\":54041,\"start\":54025},{\"end\":54056,\"start\":54041},{\"end\":54072,\"start\":54056},{\"end\":54252,\"start\":54240},{\"end\":54263,\"start\":54252},{\"end\":54276,\"start\":54263},{\"end\":54452,\"start\":54440},{\"end\":54463,\"start\":54452},{\"end\":54475,\"start\":54463},{\"end\":54616,\"start\":54606},{\"end\":54630,\"start\":54616},{\"end\":54640,\"start\":54630},{\"end\":54652,\"start\":54640},{\"end\":54665,\"start\":54652},{\"end\":54669,\"start\":54665},{\"end\":54683,\"start\":54669},{\"end\":54687,\"start\":54683},{\"end\":54842,\"start\":54833},{\"end\":54857,\"start\":54842},{\"end\":54874,\"start\":54857},{\"end\":54878,\"start\":54874},{\"end\":54892,\"start\":54878},{\"end\":55019,\"start\":55006},{\"end\":55031,\"start\":55019},{\"end\":55047,\"start\":55031},{\"end\":55304,\"start\":55286},{\"end\":55320,\"start\":55304},{\"end\":55336,\"start\":55320},{\"end\":55354,\"start\":55336},{\"end\":55360,\"start\":55354},{\"end\":55450,\"start\":55436},{\"end\":55466,\"start\":55450},{\"end\":55483,\"start\":55466},{\"end\":55498,\"start\":55483},{\"end\":55638,\"start\":55620},{\"end\":55658,\"start\":55638},{\"end\":55674,\"start\":55658},{\"end\":55692,\"start\":55674},{\"end\":55706,\"start\":55692},{\"end\":55878,\"start\":55855},{\"end\":55897,\"start\":55878},{\"end\":55915,\"start\":55897},{\"end\":56162,\"start\":56145},{\"end\":56175,\"start\":56162},{\"end\":56190,\"start\":56175},{\"end\":56204,\"start\":56190},{\"end\":56227,\"start\":56204},{\"end\":56349,\"start\":56332},{\"end\":56353,\"start\":56349},{\"end\":56368,\"start\":56353},{\"end\":56382,\"start\":56368},{\"end\":56392,\"start\":56382},{\"end\":56533,\"start\":56521},{\"end\":56542,\"start\":56533},{\"end\":56709,\"start\":56691},{\"end\":56722,\"start\":56709},{\"end\":56742,\"start\":56722},{\"end\":56759,\"start\":56742},{\"end\":56766,\"start\":56759},{\"end\":57031,\"start\":57007},{\"end\":57048,\"start\":57031},{\"end\":57060,\"start\":57048},{\"end\":57074,\"start\":57060},{\"end\":57080,\"start\":57074},{\"end\":57203,\"start\":57192},{\"end\":57212,\"start\":57203},{\"end\":57224,\"start\":57212},{\"end\":57352,\"start\":57337},{\"end\":57369,\"start\":57352},{\"end\":57383,\"start\":57369},{\"end\":57389,\"start\":57383},{\"end\":57464,\"start\":57449},{\"end\":57475,\"start\":57464},{\"end\":57490,\"start\":57475},{\"end\":57504,\"start\":57490},{\"end\":57517,\"start\":57504},{\"end\":57530,\"start\":57517},{\"end\":57671,\"start\":57658},{\"end\":57684,\"start\":57671},{\"end\":57697,\"start\":57684},{\"end\":57713,\"start\":57697},{\"end\":57996,\"start\":57970},{\"end\":58011,\"start\":57996},{\"end\":58027,\"start\":58011},{\"end\":58258,\"start\":58246},{\"end\":58272,\"start\":58258},{\"end\":58285,\"start\":58272},{\"end\":58301,\"start\":58285},{\"end\":58458,\"start\":58448},{\"end\":58469,\"start\":58458},{\"end\":58480,\"start\":58469},{\"end\":58491,\"start\":58480},{\"end\":58502,\"start\":58491},{\"end\":58510,\"start\":58502},{\"end\":58522,\"start\":58510},{\"end\":58532,\"start\":58522},{\"end\":58544,\"start\":58532},{\"end\":58555,\"start\":58544},{\"end\":58567,\"start\":58555},{\"end\":58576,\"start\":58567},{\"end\":58586,\"start\":58576},{\"end\":58812,\"start\":58790},{\"end\":58826,\"start\":58812},{\"end\":58846,\"start\":58826},{\"end\":58871,\"start\":58846},{\"end\":59129,\"start\":59108},{\"end\":59145,\"start\":59129},{\"end\":59158,\"start\":59145},{\"end\":59266,\"start\":59253},{\"end\":59278,\"start\":59266},{\"end\":59294,\"start\":59278},{\"end\":59304,\"start\":59294}]", "bib_venue": "[{\"end\":49732,\"start\":49653},{\"end\":49834,\"start\":49819},{\"end\":50016,\"start\":50000},{\"end\":50339,\"start\":50244},{\"end\":50633,\"start\":50584},{\"end\":50833,\"start\":50745},{\"end\":51111,\"start\":51089},{\"end\":51146,\"start\":51113},{\"end\":51260,\"start\":51256},{\"end\":51437,\"start\":51388},{\"end\":51535,\"start\":51445},{\"end\":51778,\"start\":51734},{\"end\":51964,\"start\":51933},{\"end\":52167,\"start\":52123},{\"end\":52315,\"start\":52245},{\"end\":52512,\"start\":52431},{\"end\":52823,\"start\":52728},{\"end\":53142,\"start\":53098},{\"end\":53384,\"start\":53362},{\"end\":53446,\"start\":53407},{\"end\":53819,\"start\":53711},{\"end\":53941,\"start\":53880},{\"end\":54124,\"start\":54072},{\"end\":54320,\"start\":54276},{\"end\":54480,\"start\":54475},{\"end\":54727,\"start\":54687},{\"end\":54941,\"start\":54892},{\"end\":55134,\"start\":55047},{\"end\":55147,\"start\":55136},{\"end\":55417,\"start\":55376},{\"end\":55604,\"start\":55498},{\"end\":55783,\"start\":55722},{\"end\":55996,\"start\":55915},{\"end\":56265,\"start\":56227},{\"end\":56444,\"start\":56392},{\"end\":56590,\"start\":56542},{\"end\":56843,\"start\":56766},{\"end\":57129,\"start\":57080},{\"end\":57275,\"start\":57224},{\"end\":57441,\"start\":57389},{\"end\":57591,\"start\":57546},{\"end\":57794,\"start\":57713},{\"end\":58117,\"start\":58027},{\"end\":58378,\"start\":58301},{\"end\":58713,\"start\":58586},{\"end\":58948,\"start\":58871},{\"end\":59106,\"start\":59018},{\"end\":59385,\"start\":59304},{\"end\":50438,\"start\":50341},{\"end\":50932,\"start\":50835},{\"end\":51165,\"start\":51148},{\"end\":52580,\"start\":52514},{\"end\":52922,\"start\":52825},{\"end\":55238,\"start\":55149},{\"end\":56064,\"start\":55998},{\"end\":56907,\"start\":56845},{\"end\":57880,\"start\":57796},{\"end\":58194,\"start\":58119},{\"end\":58442,\"start\":58380},{\"end\":59012,\"start\":58950},{\"end\":59470,\"start\":59387}]"}}}, "year": 2023, "month": 12, "day": 17}