{"id": 247748688, "updated": "2023-10-05 15:38:46.093", "metadata": {"title": "EnHDC: Ensemble Learning for Brain-Inspired Hyperdimensional Computing", "authors": "[{\"first\":\"Ruixuan\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Dongning\",\"last\":\"Ma\",\"middle\":[]},{\"first\":\"Xun\",\"last\":\"Jiao\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Ensemble learning is a classical learning method utilizing a group of weak learners to form a strong learner, which aims to increase the accuracy of the model. Recently, brain-inspired hyperdimensional computing (HDC) becomes an emerging computational paradigm that has achieved success in various domains such as human activity recognition, voice recognition, and bio-medical signal classification. HDC mimics the brain cognition and leverages high-dimensional vectors (e.g., 10000 dimensions) with fully distributed holographic representation and (pseudo-)randomness. This paper presents the first effort in exploring ensemble learning in the context of HDC and proposes the first ensemble HDC model referred to as EnHDC. EnHDC uses a majority voting-based mechanism to synergistically integrate the prediction outcomes of multiple base HDC classifiers. To enhance the diversity of base classifiers, we vary the encoding mechanisms, dimensions, and data width settings among base classifiers. By applying EnHDC on a wide range of applications, results show that the EnHDC can achieve on average 3.2\\% accuracy improvement over a single HDC classifier. Further, we show that EnHDC with reduced dimensionality, e.g., 1000 dimensions, can achieve similar or even surpass the accuracy of baseline HDC with higher dimensionality, e.g., 10000 dimensions. This leads to a 20\\% reduction of storage requirement of HDC model, which is key to enabling HDC on low-power computing platforms.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2203.13542", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/esl/WangMJ23", "doi": "10.1109/les.2022.3191641"}}, "content": {"source": {"pdf_hash": "87133069429d51d8ec4cc3806d64b304afaf5e63", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2203.13542v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "0534fd620220cdd93864b09c29f66db73604ad31", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/87133069429d51d8ec4cc3806d64b304afaf5e63.txt", "contents": "\nEnHDC: Ensemble Learning for Brain-Inspired Hyperdimensional Computing\n\n\nRuixuan Wang rwang8@villanova.edu \nVillanova University Villanova\n19085PA\n\nDongning Ma \nVillanova University Villanova\n19085PA\n\nXun Jiao xun.jiao@villanova.edu \nVillanova University Villanova\n19085PA\n\nEnHDC: Ensemble Learning for Brain-Inspired Hyperdimensional Computing\n\nEnsemble learning is a classical learning method utilizing a group of weak learners to form a strong learner, which aims to increase the accuracy of the model. Recently, braininspired hyperdimensional computing (HDC) becomes an emerging computational paradigm that has achieved success in various domains such as human activity recognition, voice recognition, and bio-medical signal classification. HDC mimics the brain cognition and leverages high-dimensional vectors (e.g., 10000 dimensions) with fully distributed holographic representation and (pseudo-)randomness. This paper presents the first effort in exploring ensemble learning in the context of HDC and proposes the first ensemble HDC model referred to as EnHDC. EnHDC uses a majority voting-based mechanism to synergistically integrate the prediction outcomes of multiple base HDC classifiers. To enhance the diversity of base classifiers, we vary the encoding mechanisms, dimensions, and data width settings among base classifiers. By applying EnHDC on a wide range of applications, results show that the EnHDC can achieve on average 3.2% accuracy improvement over a single HDC classifier. Further, we show that EnHDC with reduced dimensionality, e.g., 1000 dimensions, can achieve similar or even surpass the accuracy of baseline HDC with higher dimensionality, e.g., 10000 dimensions. This leads to a 20% reduction of storage requirement of HDC model, which is key to enabling HDC on low-power computing platforms.\n\nI. INTRODUCTION\n\nInspired by how human brain functions, hyperdimensional computing (HDC) is an emerging computing scheme that leverages the abstract patterns and mathematical properties of vectors in high dimension spaces [19], [17]. Rather than processing actual numbers, HDC works with hypervectors (HV), which are high dimensional (e.g., 10000 dimensions), holographic (not micro-coded) vectors with i.i.d. (independent and identically distributed) elements [11]. As a novel computing scheme, HDC has shown promising performance for various applications such as language classification [17], voice recognition [9], biomedical signal analysis [3] and robotics [18].\n\nCompared with traditional computing schemes such as neural networks, HDC has several advantages such as smaller model size and low computing cost, making it a promising computing scheme with low power computing platforms and edge computing devices [10]. In particular, training of HDC models is free of back-propagation and can be completed on a sample-basis instead of batches, making it superior to machine learning algorithms such as neural networks that requires intensive iterations of back-propagation to establish a model. This exposes more opportunities for one-shot learning and edge deployment. In addition, the memory-centricity of HDC grants the advantage of easily embracing the emerging energyefficient in-memory computing schemes over other machine learning algorithms such as neural networks that are highly computation-centric [12].\n\nEnsemble learning is a machine learning paradigm where multiple models (often called \"weak learners\") are trained to solve the same problem and combined to get better results. Typically, an ensemble learning system aims to improves the performance by combining diverse weak learners (base classifiers). In a practical problem setting, ensemble is useful for the following question: given a particular classification algorithm, which realization of this algorithm should be chosen? For example, for a multi-layer perceptron (MLP), different initializations and weights will render different decision boundaries. It is worth to note that choosing the best classifier with the smallest error in training data may not be necessarily the best classifier overall due to overfitting. Therefore, it remains a question as to which classifier should be chosen and one can be tempted to choose randomly with the risk of having a particularly poor model at last. Thus, using an ensemble model that combines the output from several models, e.g., averaging them, can reduce the risk of an unfortunate selection of a particularly poor classifier.\n\nFor the first time, this paper explores the use of ensemble learning on HDC models and develop the first ensemble HDC classifier for a wide range of applications. The benefits of using ensemble learning on HDC includes improved accuracy and reduced model size. In particular, we make the following contributions:\n\n\u2022 To the best of our knowledge, we propose the first ensemble HDC classifier called EnHDC. By leveraging the aggregated intelligence of a variety of HDC classifiers with different random initializations, EnHDC is able to achieve on average 3.2% accuracy improvement over a single HDC classifier. \u2022 To further enhance the performance of EnHDC, we improve the diversity of base classifiers by varying a diverse set of parameters for base HDC classifiers such as number of dimensions, data width, and encoding methods. This further leads to 1.2% accuracy improvement over basic EnHDC classifier. \u2022 We evaluate the EnHDC on four different practical ap-plication domains including image classification, human activity recognition, speech recognition, and medical diagnosis. EnHDC enables HDC learning with smaller number of dimensionality, which leads to a 20% model size reduction with no accuracy drop.\n\n\nII. RELATED WORK\n\nHyperdimensional Computing Most related works on HDC focus on two major directions: the application of HDC and the improvement of HDC processing. Particularly, HDC has been intensively applied into emerging applications such as robotics by integrating the sensory perceptions experienced by an agent with its motoric capabilities, which is vital to autonomous learning agents [15]. In bio-sensing applications such as hand gesture recognition, HDC also shows 97% accuracy, superior to traditional machine learning algorithms [16]. HDC is also used in building efficient recommendation systems which is almost 14X faster and 7X energy efficient than traditional rating prediction systems [6]. For optimization of HDC, there are cross-layer in-memory or in-storage computing platforms designed for HDC to enhance energy efficiency [7]. Computation reuse opportunities are also explored to accelerate performance of HDC in FPGAs [20]. Software and hardware multi-fold approximation techniques in encoding are also applied to enhance efficiency [13]. Ensemble Learning Ensemble learning has been applied to various applications or scenarios for enhanced learning performance. In language translation tasks, transductive ensemble learning (TEL) is proposed to surpass marginal improvement on accuracy of traditional ensemble algorithms [21]. In zeroshot learning scenarios, multi-patch generative adversarial nets (MPGAN) with novel weighted voting strategies are also proposed for improvement of current ensemble learning algorithms for better performance [4]. Ensemble learning is also introduced into transfer learning to mitigate the over-fitting drawbacks of current transfer strategies [23]. By parallelism and sharing weights information amongst members in the ensemble classifier, BatchEnsembles achieves 3X speed-up and 3X memory reduction over traditional ensemble algorithms [22]. Our Work Some earlier literature indicates having a group of classifiers each targeting at one feature to build an ensemble can achieve higher classification accuracy while maintaining lower memory footprint [3]. However, a systematic analysis of ensemble learning performance with HDC is still absent. EnHDC, to the best of our knowledge, is the first work that systematically explores ensemble learning performance under different configurations such as encoding methods, dimensions of HV and data widths.\n\n\nIII. PRELIMINARIES\n\nIn this section, we introduce the preliminaries regarding hyperdimensional computing, including backgrounds of HDC and the process of using HDC in learning tasks.\n\n\nA. Backgrounds of HDC\n\nHypervectors Hypervector (HV) is a type of high-dimensional, holographic vectors with i.i.d. elements [11]. Assume we have an HV of n dimensions which can be noted as Eq. 1, where h i denotes the elements inside the HV.\n\nIn HDC, HVs use their high dimensional space to store different layers of information, thus can represent values, features and even samples. For example, in HDC for image classification tasks, HVs can represent a grayscale value, a pixel or even one image. To establish the dynamic connection between different layers of information in HV, methodologies of aggregating or combing information from HVs such as HDC operations, are therefore necessary.\nH = h 1 , h 2 , . . . , h n(1)\nOperations HVs support three basic operations, addition (+), multiplication ( * ) and permutation (\u03c1) as noted in Eq. 2.\n\nAdditions and multiplications take two operand HVs as input and perform element-wise operations that add or multiply each element inside the operand HVs index by index. Permutations only take one operand HV and perform cyclic shift over the HV. For all the three operations, the input HVs and the output HVs are in the same dimension.\nH p + H q = h p1 + h q1 , h p2 + h q2 , . . . , h pn + h qn H p * H q = h p1 * h q1 , h p2 * h q2 , . . . , h pn * h qn \u03c1 1 ( H) = h n , h 1 , h 2 , . . . , h n\u22121(2)\nAddition is used to aggregate parallel features that usually belongs to one modular, while multiplication is used to combine different types of features together to create new features. Permutation is used to reflect spatial or temporal changes in the features. Similarity Check Similarity check is used in HDC for the objective of measuring the similarity \u03b4 of information between different HVs. There are different algorithms to measure similarity such as Euclidean distance and Hamming distance, while in EnHDC, we are using cosine similarity as noted in Eq. 3. A higher similarity between two HVs indicates that they share more alike information, or vice versa.\n\u03b4( H p , H q ) = H p \u00b7 H q || H p || \u00d7 || H q || = n i=1 h pi \u00b7 h qi n i=1 h pi 2 \u00b7 n i=1 h qi 2(3)\n\nB. HDC in Learning Tasks\n\nHDC in learning tasks features three major phases: Training, Inference and Retraining; all the phases require a fundamental procedure called Encoding. Encoding Encoding is the process of mapping input features of one sample to the high-dimensional space available for HDC training, inference and retraining, i.e., building representative HVs of this sample from the fundamental item memory using combinations of HDC operations. Item memory is a type of specially allocated memory during runtime, which stores the bottom layer HVs, or building block HVs that are used to add or multiply for establishing other HVs. To ensure the i.i.d. property, HVs in the item memories are all randomly initialized.\n\nProcess of encoding can be noted as Eq. 4. Assume we have the m-dimensional input features F = f 1 , f 2 , . . . , f m for each sample, a set of corresponding item memories R = {R 1 , R 2 , . . . , R m } and the combination of HDC operations E determined by the application, the encoded HV H is obtained by looking up each feature's corresponding HV in the item memory and then applying them into the HDC operation combination. This encoded HV will subsequently represent the input sample in training, inference and retraining.\nH = E(R, F ) = E(R 1 [f 1 ], R 2 [f 2 ], . . . , R m [f m ]) (4)\nTraining Training is the process of aggregating encoded hypervectors sharing the same label together to build the associative memory. Associative memory stores the class HVs, each representing a class in the learning problem. At the beginning of training phase, all the HVs in the associative memory is initialized as zero. Process of training can be denoted as Eq. 5. In the learning problem with k classes, assume we have encoded the HVs H l for each training sample where l means the class label, training process to establish associative memory A is by adding up hypervectors representing samples from the same class in the training set together.\nA ={ A 1 , A 2 , . . . , A k } ={ H 1 , H 2 , . . . , H k }(5)\nInference Inference is the process of using the associative memory established in the training phase to determine the class label of an unknown sample. Process of inference can be denoted as Eq. 6. First, we encode the unknown sample into its representing HV H q referred to as the query HV. Then we perform similarity check between the query HV and each class HV inside the associative memory. As aforementioned, higher similarity means higher common information shared by the two HVs, further indicating that these two HVs are likely from the same class. Therefore, the class of HVs in the associative memory having the highest similarity is determined to be the class of the query HV, namely the predicted label of the sample.\nl = argmax({\u03b4( H q , A 1 ), \u03b4( H q , A 2 ), . . . , \u03b4( H q , A k )}) (6)\nRetraining Retraining is the process of fine-tuning the HDC model by correcting erroneous information from the associative memory. The process of retraining can be denoted as Eq. 7. Assume we have a query HV H q with class label l.\n\nIf it is predicted wrongly as class l , then we subtract it from the l class HV A l in the associative memory to remove the erroneous information and add it into the correct l class HV A l . By doing this update, the similarity between H q and A l will be reduced while the similarity between H q and A l will be increased to enhance the accuracy of model.\nA l = A l \u2212 H q A l = A l + H q(7)\nIV. ENHDC MODEL In this section, we describe the process of developing EnHDC and how to enhance the diversity of the base classifiers in EnHDC to further improve the performance. Fig. 1 illustrates the overview of EnHDC. First, we separately train and retrain several different base classifiers using different parameter configurations. These base classifiers are well-trained and we integrate these base classifiers into one ensemble classifier. Secondly, we encode the testing sample into query HV and do the inference on every base classifier. And in phase three, as we collected all the base inference results in phase 2, we employ majority voting to get the ensemble inference result of the ensemble classifier.\n\n\nA. Base Classifier Development\n\nIn traditional ensemble learning, base classifiers are developed with different initialization settings. In HDC, base classifiers are developed as described in Section III-B. Each base classifier has different configurations and different randomly generated item memories R. Thus, the training outcome, i.e., the associate memory, will have different class HVs representing the same class. Therefore, for a given query input, the classification output may be different.\n\n\nB. Diversity Enhancement of Base Classifier\n\nTo further enhance the diversity of base classifiers, we propose different configurations for base classifiers, including different encoding mechanisms, different dimensions, and different data width for representing the numbers.  \n\n\nTesting data\n\n\nInference result\nH Record = m i=1 H li * H bi(8)\nIn Eq. 8, H Record is the non-bipolar encoded HV with D dimensions containing several integer values. Meanwhile, since base HVs are randomly generated in hyper-dimensional space, these HVs are almost mutually orthogonal, which means the cosine similarity between any two base HVs H bi and H bj , we have \u03b4( H bi , H bj ) = 0.\n\nWe also use the N-gram Encoding method, in which we employ the locality-based sparse random projection [8] as our N-gram encoding method. In this method, while we are using the D dimensional HVs, we first extended the length of feature vector from N to D. For instance, in MNIST dataset, when we try to encode a feature vector with N = 768 feature values into D = 10000 dimension HVs, we firstly need to attach 13 duplication following the original feature vector. Meanwhile, we generate a random bipolar D dimensional local-hashing HV H s = h s1 , h s2 , . . . , h sn . To encode the extended feature vector into the hyper-dimensional space, N-gram Encoding method deploy an N-gram sliding window and take the dot product of the extended feature vector and projection vector in this window range. The detailed encoding progress of Ngram Encoding method shows as Eq. 9. In this situation, the i-th value of H N \u2212gram equals to the dot product of the w feature values from f i to f i+w\u22121 and w element values from h i to h i+w\u22121 , where w equals to the size of sliding window.\nH N \u2212gram = v 1 , v 2 , . . . , v n v i = f i * h i + f i+1 * h i+1 + \u00b7 \u00b7 \u00b7 + f i+w\u22121 * h i+w\u22121(9)\nDimensions: We use three different dimension settings for base classifiers, 1000, 5000, and 10000. This brings another diversity aspect for the base classifiers. \n\n\nC. Voting Mechanism\n\nThe inference phase has two steps in the EnHDC. First, we map each testing data into a query HV H q using the same encoding method during training. Then we calculate the cosine similarity of each class HVs with the query HV H q in every base classifier, the inference result is pointed to the class with the highest cosine similarity. Then we finish the inference process in each base classifier following the same routine in step 1. And for step 2, we collect all the base inference results in the ensemble classifier to vote the ensemble inference result. We explored different voting mechanisms to get a better inference result and we tested two different voting strategies, soft voting and hard voting. Hard voting is the majority voting. And for soft voting, since each base classifier gave the inference result by cosine similarity checking, we can sum up all the related cosine distances and rank them in order, where the champion will be selected as the final result. Our test result shows that the hard voting strategy achieved better accuracy in EnHDC. Therefore, we integrate all the base inference results in ensemble classifier and use majority voting to get the ensemble inference result of the corresponding query HV.\n\n\nV. EXPERIMENTAL RESULTS\n\n\nA. Experiment Setup\n\nWe evaluate EnHDC using four application domains: speech recognition (ISOLET [5]), human activity recognition (HAR [1]), handwritten digits (MNIST [14]), and cardiotocography (CARDIO [5]). Detail of these four applications are shown below: First as shown in Fig. 2, EnHDC contains 8 and 16 base classifiers with different encoding methods (Record and Ngram encoding). To evaluate the performance of EnHDC, we compare 3 models under the same dimensionality setting across D = 1000, 5000, 10000, EnHDC is showing consistent higher accuracy than baseline models. When EnHDC uses 8 base classifiers, the average improvement is 3.2% over all applications.\n\nSecond, normally HDC requires a high dimensionality such as D = 10000 to achieve satisfying performance. However, with EnHDC, we can even achieve higher accuracy under lower dimensionality than that of baseline model with higher dimensionality. Actually, across all the applications, EnHDC with 8 classifiers under D = 1000 presents higher accuracy than baseline model under D = 10000. The average improvement is 1.37%.\n\nThird, as shown in Fig. 3, the number of base classifiers have a notable impact on the accuracy. Without the loss of generality, our experiment features different ensemble sizes, starting from two base classifiers to twelve base classifiers. As the green line shown in Fig. 3, the accuracy of EnHDC increases by adding more classifiers but comes to the vertex when using eight base classifiers for most applications. After this, the accuracy improvement is saturated. This is consistent with the ensemble theory in [2], where the performance of ensemble learning algorithms cannot constantly increase by adding an infinite amount of base classifiers. The accuracy will peak during the progress of increasing the number of classifiers, and after this peak value, the overall accuracy cannot have an obvious improvement.\n\nLast but not least, the diversity enhancement can further improve the accuracy of EnHDC as shown in Fig. 3. EnHDC enhanced classifier is the EnHDC classifier with enhanced diversity by varying encoding mechanisms (Record encoding, N-gram encoding), dimensions (D = 1000, 5000, 10000), and data width (IN T 8, IN T 16). This figure shows that the EnHDC enhanced classifier can further improve the accuracy of EnHDC classifier by 1.2% on average across all applications, which is 4.4% improvement over baseline HDC model.\n\n\nC. Memory Reduction\n\nWith ensemble learning, we are able to reduce the dimensionality requirement for HDC classifiers. Typically, HDC is required to have a high dimensionality, e.g., 10000, to achieve a satisfying performance. For example, for CARDIO dataset in Fig. 2, the baseline HDC classifier with 10000 dimensions has 1.9% higher accuracy than the baseline HDC classifier with 1000 dimensions.\n\nHowever, with ensemble learning, we can see that EnHDC with just 1000 dimensions is able to achieve similar level or even surpass the accuracy of 10000-dimension baseline HDC classifiers across all applications. This can result in a smaller model size. For example, with 8 base classifiers with D = 1000 dimensions, this can reduce 20% model size compared to a baseline classifier with D = 10000 dimensions. For MNIST dataset with 10 classes, we have a baseline HDC model with D = 10000 and IN T 8 data width whose model size is 8 bits * 10000 dimensions * 10 classes = 800Kb and EnHDC with base classifiers with D = 1000 and IN T 8 whose model size is 8 bits * 1000 dimensions * 10 classes * 8 classif iers = 640Kb. The overall model size reduction is 160Kb for MNIST. Meanwhile, in HAR dataset with 12 classes, we have one 960Kb baseline model with D = 10000 and EnHDC with eight 96Kb base classifiers with D = 1000, pointing out the model size reduction for HAR is 180Kb.\n\n\nVI. CONCLUSION\n\nThis paper presents EnHDC, the first ensemble HDC classifier. As an ensemble learning model, EnHDC employs different base classifiers under different HV dimensions, different data widths, and different encoding methods. In EnHDC, base classifiers are individually trained and retrained and EnHDC applies the majority voting to generate the final inference result. We designed several experiments to evaluate the performance of EnHDC under different HV dimensions and different number of classifiers. By evaluating EnHDC on four practical applications, we show that EnHDC can achieve higher accuracy and can reduce model size compared to baseline HDC classifiers while providing the same or even better classification accuracy. Meanwhile, by increasing the diversity of base classifiers in EnHDC, the classification accuracy has an enhanced improvement compared to the original EnHDC model. This paper presents the first effort in using an ensemble learning method in HDC for boosting the performance and opens the door for this potential research direction. Our future work will consider using a cascading method and more sophisticated ensemble learning algorithms such as boosting.\n\n\nEncoding mechanisms: We use two encoding mechanisms: the Record based encoding and the N-gram based encoding. First of all, the Record Encoding is a general encoding method which mapping every feature vector F = f 1 , f 2 , . . . , f m , containing m features, into hyperdimensional space. The Record encoding method finds the minimum and maximum feature values and converse the range into p feature levels. In Record encoding method, we assign a set of random orthogonal bipolar level HVs H l = h l1 , h l2 , . . . , h ln to every feature levels. Meanwhile, for preserving the position independence of feature values in the feature vector, Record encoding method also assign one set of HVs to each feature values, called base HVs H b = h b1 , h b2 , . . . , h bn . The Record encoding method use the level HVs to represent each feature value in the feature vector and Base HVs for the position relationship of features values. Then Record encoding employed by linearly combining the level HVs and Base HVs in hyper-dimensional space, the detail of Record encoding shows as Eq. 8.\n\n\nData width: To represent the internal data of the HDC base classifiers, we use IN T 8 and IN T 16 data width to further enhance the diversity of base classifiers.\n\nFig. 2 .Fig. 3 .\n23EnHDC performance under different HV dimension: EnHDC performance under different ensemble size application, we use 50000 samples for training and 10000 samples for testing. \u2022 CARDIO: Cardiotocography dataset aiming at classifying measurements of fetal heart rate (FHR) and uterine contraction (UC) features into 10 classes (label consensus by obstetricians). It has a total of 2,126 fetal cardiotocograms (CTGs) signals. In this application, we use 1913 samples for training and 213 samples for testing. \u2022 HAR: Human activity recognition dataset aiming at recognizing 12 types of human activities. The dataset is built from 30 subjects performing activities of daily living (ADL) with 561 features. In this application, we use 7767 samples for training and 3162 samples for testing. \u2022 ISOLET: Speech recognition dataset aiming at recognizing voice audio of the 26 letters of the English alphabet. This dataset contains 150 subjects speaking the name of each alphabet letter twice. In this application, we use 6238 samples for training and 1559 samples for testing. B. Accuracy ImprovementFig. 2 and Fig. 3 present the accuracy comparison between different configurations of EnHDC. The baseline is one HDC classifier while the EnHDC employing several different base classifiers. According to our experiment result, we can observe several important facts.\n\u2022 MNIST: Handwritten digits Recognition dataset aiming at classifying 10 handwritten digits from 0 to 9. In this\n\nA public domain dataset for human activity recognition using smartphones. Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge Luis Reyes-Ortiz , Esann. 33Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, and Jorge Luis Reyes-Ortiz. A public domain dataset for human activity recognition using smartphones. In Esann, volume 3, page 3, 2013.\n\nLess is more: A comprehensive framework for the number of components of ensemble classifiers. H Bonab, F Can, IEEE Transactions on Neural Networks and Learning Systems. 309H. Bonab and F. Can. Less is more: A comprehensive framework for the number of components of ensemble classifiers. IEEE Transactions on Neural Networks and Learning Systems, 30(9):2735-2745, 2019.\n\nOne-shot learning for ieeg seizure detection using end-to-end binary operations: Local binary patterns with hyperdimensional computing. Alessio Burrello, Kaspar Schindler, Luca Benini, Abbas Rahimi, 2018 IEEE Biomedical Circuits and Systems Conference (BioCAS). IEEEAlessio Burrello, Kaspar Schindler, Luca Benini, and Abbas Rahimi. One-shot learning for ieeg seizure detection using end-to-end binary operations: Local binary patterns with hyperdimensional computing. In 2018 IEEE Biomedical Circuits and Systems Conference (BioCAS), pages 1-4. IEEE, 2018.\n\nRethinking generative zero-shot learning: An ensemble learning perspective for recognising visual patches. Zhi Chen, Sen Wang, Jingjing Li, Zi Huang, Proceedings of the 28th ACM International Conference on Multimedia. the 28th ACM International Conference on MultimediaZhi Chen, Sen Wang, Jingjing Li, and Zi Huang. Rethinking generative zero-shot learning: An ensemble learning perspective for recognising vi- sual patches. In Proceedings of the 28th ACM International Conference on Multimedia, pages 3413-3421, 2020.\n\nUCI machine learning repository. Dheeru Dua, Casey Graff, Dheeru Dua and Casey Graff. UCI machine learning repository, 2017.\n\nHyperrec: Efficient recommender systems with hyperdimensional computing. Yunhui Guo, Mohsen Imani, Jaeyoung Kang, Sahand Salamat, Justin Morris, Baris Aksanli, Yeseong Kim, Tajana Rosing, Proceedings of the 26th Asia and South Pacific Design Automation Conference. the 26th Asia and South Pacific Design Automation ConferenceYunhui Guo, Mohsen Imani, Jaeyoung Kang, Sahand Salamat, Justin Morris, Baris Aksanli, Yeseong Kim, and Tajana Rosing. Hyperrec: Efficient recommender systems with hyperdimensional computing. In Proceedings of the 26th Asia and South Pacific Design Automation Conference, pages 384-389, 2021.\n\nThrifty: training with hyperdimensional computing across flash hierarchy. Saransh Gupta, Justin Morris, Mohsen Imani, Ranganathan Ramkumar, Jeffrey Yu, Aniket Tiwari, Baris Aksanli, Tajana\u0161imuni\u0107 Rosing, 2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD). IEEESaransh Gupta, Justin Morris, Mohsen Imani, Ranganathan Ramkumar, Jeffrey Yu, Aniket Tiwari, Baris Aksanli, and Tajana\u0160imuni\u0107 Rosing. Thrifty: training with hyperdimensional computing across flash hierar- chy. In 2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD), pages 1-9. IEEE, 2020.\n\nBric: Locality-based encoding for energy-efficient brain-inspired hyperdimensional computing. M Imani, J Morris, J Messerly, H Shu, Y Deng, T Rosing, 56th ACM/IEEE Design Automation Conference (DAC). M. Imani, J. Morris, J. Messerly, H. Shu, Y. Deng, and T. Rosing. Bric: Locality-based encoding for energy-efficient brain-inspired hyper- dimensional computing. In 2019 56th ACM/IEEE Design Automation Conference (DAC), pages 1-6, 2019.\n\nVoicehd: Hyperdimensional computing for efficient speech recognition. Mohsen Imani, Deqian Kong, Abbas Rahimi, Tajana Rosing, 2017 IEEE International Conference on Rebooting Computing (ICRC). IEEEMohsen Imani, Deqian Kong, Abbas Rahimi, and Tajana Rosing. Voicehd: Hyperdimensional computing for efficient speech recogni- tion. In 2017 IEEE International Conference on Rebooting Computing (ICRC), pages 1-8. IEEE, 2017.\n\nSearchd: A memorycentric hyperdimensional computing with stochastic training. Mohsen Imani, Xunzhao Yin, John Messerly, Saransh Gupta, Michael Niemier, Sharon Xiaobo, Tajana Hu, Rosing, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. 3910Mohsen Imani, Xunzhao Yin, John Messerly, Saransh Gupta, Michael Niemier, Xiaobo Sharon Hu, and Tajana Rosing. Searchd: A memory- centric hyperdimensional computing with stochastic training. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 39(10):2422-2433, 2019.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. Pentti Kanerva, Cognitive computation. 12Pentti Kanerva. Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. Cognitive computation, 1(2):139-159, 2009.\n\nIn-memory hyperdimensional computing. Geethan Karunaratne, Manuel Le Gallo, Giovanni Cherubini, Luca Benini, Abbas Rahimi, Abu Sebastian, Nature Electronics. 36Geethan Karunaratne, Manuel Le Gallo, Giovanni Cherubini, Luca Benini, Abbas Rahimi, and Abu Sebastian. In-memory hyperdimensional computing. Nature Electronics, 3(6):327-337, 2020.\n\nShear er: highly-efficient hyperdimensional computing by software-hardware enabled multifold approximation. Sahand Behnam Khaleghi, Anthony Salamat, Thomas, Proceedings of the ACM/IEEE International Symposium on Low Power Electronics and Design. the ACM/IEEE International Symposium on Low Power Electronics and DesignFatemeh Asgarinejad, Yeseong Kim, and Tajana RosingBehnam Khaleghi, Sahand Salamat, Anthony Thomas, Fatemeh As- garinejad, Yeseong Kim, and Tajana Rosing. Shear er: highly-efficient hyperdimensional computing by software-hardware enabled multifold approximation. In Proceedings of the ACM/IEEE International Sympo- sium on Low Power Electronics and Design, pages 241-246, 2020.\n\nGradient-based learning applied to document recognition. Yann Lecun, Proceedings of the IEEE. the IEEEYann LeCun et al. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 1998.\n\nLearning sensorimotor control with neuromorphic sensors: Toward hyperdimensional active perception. Anton Mitrokhin, Cornelia Sutor, Yiannis Ferm\u00fcller, Aloimonos, Science Robotics. 430Anton Mitrokhin, P Sutor, Cornelia Ferm\u00fcller, and Yiannis Aloimonos. Learning sensorimotor control with neuromorphic sensors: Toward hy- perdimensional active perception. Science Robotics, 4(30), 2019.\n\nA wearable biosensing system with insensor adaptive machine learning for hand gesture recognition. Ali Moin, Andy Zhou, Abbas Rahimi, Alisha Menon, Simone Benatti, George Alexandrov, Senam Tamakloe, Jonathan Ting, Natasha Yamamoto, Yasser Khan, Nature Electronics. 41Ali Moin, Andy Zhou, Abbas Rahimi, Alisha Menon, Simone Be- natti, George Alexandrov, Senam Tamakloe, Jonathan Ting, Natasha Yamamoto, Yasser Khan, et al. A wearable biosensing system with in- sensor adaptive machine learning for hand gesture recognition. Nature Electronics, 4(1):54-63, 2021.\n\nHyperdimensional computing for text classification. Abbas Fateme Rasti Najafabadi, Pentti Rahimi, Jan M Kanerva, Rabaey, Design, Automation Test in Europe Conference Exhibition (DATE). University BoothFateme Rasti Najafabadi, Abbas Rahimi, Pentti Kanerva, and Jan M Rabaey. Hyperdimensional computing for text classification. In Design, Automation Test in Europe Conference Exhibition (DATE), University Booth, pages 1-1, 2016.\n\nAn introduction to hyperdimensional computing for robotics. Peer Neubert, Stefan Schubert, Peter Protzel, 33KI-K\u00fcnstliche IntelligenzPeer Neubert, Stefan Schubert, and Peter Protzel. An introduction to hyperdimensional computing for robotics. KI-K\u00fcnstliche Intelligenz, 33(4):319-330, 2019.\n\nHyperdimensional biosignal processing: A case study for emgbased hand gesture recognition. Abbas Rahimi, Simone Benatti, Pentti Kanerva, Luca Benini, Jan M Rabaey, 2016 IEEE International Conference on Rebooting Computing (ICRC). IEEEAbbas Rahimi, Simone Benatti, Pentti Kanerva, Luca Benini, and Jan M Rabaey. Hyperdimensional biosignal processing: A case study for emg- based hand gesture recognition. In 2016 IEEE International Conference on Rebooting Computing (ICRC), pages 1-8. IEEE, 2016.\n\nAccelerating hyperdimensional computing on fpgas by exploiting computational reuse. Sahand Salamat, Mohsen Imani, Tajana Rosing, IEEE Transactions on Computers. 698Sahand Salamat, Mohsen Imani, and Tajana Rosing. Accelerating hy- perdimensional computing on fpgas by exploiting computational reuse. IEEE Transactions on Computers, 69(8):1159-1171, 2020.\n\nTransductive ensemble learning for neural machine translation. Yiren Wang, Lijun Wu, Yingce Xia, Tao Qin, Chengxiang Zhai, Tie-Yan Liu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34Yiren Wang, Lijun Wu, Yingce Xia, Tao Qin, ChengXiang Zhai, and Tie-Yan Liu. Transductive ensemble learning for neural machine trans- lation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 6291-6298, 2020.\n\nBatchensemble: an alternative approach to efficient ensemble and lifelong learning. Yeming Wen, Dustin Tran, Jimmy Ba, arXiv:2002.06715arXiv preprintYeming Wen, Dustin Tran, and Jimmy Ba. Batchensemble: an alternative approach to efficient ensemble and lifelong learning. arXiv preprint arXiv:2002.06715, 2020.\n\nTranslider: Transfer ensemble learning from exploitation to exploration. Kuo Zhong, Ying Wei, Chun Yuan, Haoli Bai, Junzhou Huang, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningKuo Zhong, Ying Wei, Chun Yuan, Haoli Bai, and Junzhou Huang. Translider: Transfer ensemble learning from exploitation to exploration. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 368-378, 2020.\n", "annotations": {"author": "[{\"end\":148,\"start\":74},{\"end\":201,\"start\":149},{\"end\":274,\"start\":202}]", "publisher": null, "author_last_name": "[{\"end\":86,\"start\":82},{\"end\":160,\"start\":158},{\"end\":210,\"start\":206}]", "author_first_name": "[{\"end\":81,\"start\":74},{\"end\":157,\"start\":149},{\"end\":205,\"start\":202}]", "author_affiliation": "[{\"end\":147,\"start\":109},{\"end\":200,\"start\":162},{\"end\":273,\"start\":235}]", "title": "[{\"end\":71,\"start\":1},{\"end\":345,\"start\":275}]", "venue": null, "abstract": "[{\"end\":1825,\"start\":347}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2053,\"start\":2049},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2059,\"start\":2055},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2292,\"start\":2288},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2420,\"start\":2416},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2443,\"start\":2440},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2475,\"start\":2472},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2493,\"start\":2489},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2748,\"start\":2744},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3344,\"start\":3340},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6094,\"start\":6090},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6243,\"start\":6239},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6404,\"start\":6401},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6546,\"start\":6543},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6644,\"start\":6640},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6759,\"start\":6755},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7049,\"start\":7045},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7269,\"start\":7266},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7405,\"start\":7401},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7599,\"start\":7595},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7812,\"start\":7809},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8425,\"start\":8421},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":15872,\"start\":15869},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":18489,\"start\":18486},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":18527,\"start\":18524},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":18560,\"start\":18556},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":18595,\"start\":18592},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20000,\"start\":19997}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":24483,\"start\":23401},{\"attributes\":{\"id\":\"fig_1\"},\"end\":24648,\"start\":24484},{\"attributes\":{\"id\":\"fig_2\"},\"end\":26023,\"start\":24649}]", "paragraph": "[{\"end\":2494,\"start\":1844},{\"end\":3345,\"start\":2496},{\"end\":4478,\"start\":3347},{\"end\":4792,\"start\":4480},{\"end\":5693,\"start\":4794},{\"end\":8108,\"start\":5714},{\"end\":8293,\"start\":8131},{\"end\":8538,\"start\":8319},{\"end\":8989,\"start\":8540},{\"end\":9141,\"start\":9021},{\"end\":9477,\"start\":9143},{\"end\":10309,\"start\":9644},{\"end\":11136,\"start\":10437},{\"end\":11665,\"start\":11138},{\"end\":12381,\"start\":11731},{\"end\":13174,\"start\":12445},{\"end\":13479,\"start\":13248},{\"end\":13837,\"start\":13481},{\"end\":14589,\"start\":13873},{\"end\":15093,\"start\":14624},{\"end\":15372,\"start\":15141},{\"end\":15764,\"start\":15439},{\"end\":16841,\"start\":15766},{\"end\":17103,\"start\":16941},{\"end\":18359,\"start\":17127},{\"end\":19059,\"start\":18409},{\"end\":19480,\"start\":19061},{\"end\":20300,\"start\":19482},{\"end\":20821,\"start\":20302},{\"end\":21223,\"start\":20845},{\"end\":22199,\"start\":21225},{\"end\":23400,\"start\":22218}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9020,\"start\":8990},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9643,\"start\":9478},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10409,\"start\":10310},{\"attributes\":{\"id\":\"formula_3\"},\"end\":11730,\"start\":11666},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12444,\"start\":12382},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13247,\"start\":13175},{\"attributes\":{\"id\":\"formula_6\"},\"end\":13872,\"start\":13838},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15438,\"start\":15407},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16940,\"start\":16842}]", "table_ref": null, "section_header": "[{\"end\":1842,\"start\":1827},{\"end\":5712,\"start\":5696},{\"end\":8129,\"start\":8111},{\"end\":8317,\"start\":8296},{\"end\":10435,\"start\":10411},{\"end\":14622,\"start\":14592},{\"end\":15139,\"start\":15096},{\"end\":15387,\"start\":15375},{\"end\":15406,\"start\":15390},{\"end\":17125,\"start\":17106},{\"end\":18385,\"start\":18362},{\"end\":18407,\"start\":18388},{\"end\":20843,\"start\":20824},{\"end\":22216,\"start\":22202},{\"end\":24666,\"start\":24650}]", "table": null, "figure_caption": "[{\"end\":24483,\"start\":23403},{\"end\":24648,\"start\":24486},{\"end\":26023,\"start\":24669}]", "figure_ref": "[{\"end\":14058,\"start\":14052},{\"end\":18673,\"start\":18667},{\"end\":19507,\"start\":19501},{\"end\":19757,\"start\":19751},{\"end\":20408,\"start\":20402},{\"end\":20619,\"start\":20602},{\"end\":21092,\"start\":21086}]", "bib_author_first_name": "[{\"end\":26218,\"start\":26212},{\"end\":26238,\"start\":26228},{\"end\":26249,\"start\":26245},{\"end\":26263,\"start\":26257},{\"end\":26293,\"start\":26271},{\"end\":26596,\"start\":26595},{\"end\":26605,\"start\":26604},{\"end\":27014,\"start\":27007},{\"end\":27031,\"start\":27025},{\"end\":27047,\"start\":27043},{\"end\":27061,\"start\":27056},{\"end\":27540,\"start\":27537},{\"end\":27550,\"start\":27547},{\"end\":27565,\"start\":27557},{\"end\":27572,\"start\":27570},{\"end\":27989,\"start\":27983},{\"end\":28000,\"start\":27995},{\"end\":28155,\"start\":28149},{\"end\":28167,\"start\":28161},{\"end\":28183,\"start\":28175},{\"end\":28196,\"start\":28190},{\"end\":28212,\"start\":28206},{\"end\":28226,\"start\":28221},{\"end\":28243,\"start\":28236},{\"end\":28255,\"start\":28249},{\"end\":28776,\"start\":28769},{\"end\":28790,\"start\":28784},{\"end\":28805,\"start\":28799},{\"end\":28824,\"start\":28813},{\"end\":28842,\"start\":28835},{\"end\":28853,\"start\":28847},{\"end\":28867,\"start\":28862},{\"end\":28890,\"start\":28877},{\"end\":29381,\"start\":29380},{\"end\":29390,\"start\":29389},{\"end\":29400,\"start\":29399},{\"end\":29412,\"start\":29411},{\"end\":29419,\"start\":29418},{\"end\":29427,\"start\":29426},{\"end\":29800,\"start\":29794},{\"end\":29814,\"start\":29808},{\"end\":29826,\"start\":29821},{\"end\":29841,\"start\":29835},{\"end\":30229,\"start\":30223},{\"end\":30244,\"start\":30237},{\"end\":30254,\"start\":30250},{\"end\":30272,\"start\":30265},{\"end\":30287,\"start\":30280},{\"end\":30303,\"start\":30297},{\"end\":30318,\"start\":30312},{\"end\":30840,\"start\":30834},{\"end\":31105,\"start\":31098},{\"end\":31125,\"start\":31119},{\"end\":31128,\"start\":31126},{\"end\":31144,\"start\":31136},{\"end\":31160,\"start\":31156},{\"end\":31174,\"start\":31169},{\"end\":31186,\"start\":31183},{\"end\":31517,\"start\":31511},{\"end\":31542,\"start\":31535},{\"end\":32161,\"start\":32157},{\"end\":32414,\"start\":32409},{\"end\":32434,\"start\":32426},{\"end\":32449,\"start\":32442},{\"end\":32798,\"start\":32795},{\"end\":32809,\"start\":32805},{\"end\":32821,\"start\":32816},{\"end\":32836,\"start\":32830},{\"end\":32850,\"start\":32844},{\"end\":32866,\"start\":32860},{\"end\":32884,\"start\":32879},{\"end\":32903,\"start\":32895},{\"end\":32917,\"start\":32910},{\"end\":32934,\"start\":32928},{\"end\":33315,\"start\":33310},{\"end\":33347,\"start\":33341},{\"end\":33359,\"start\":33356},{\"end\":33361,\"start\":33360},{\"end\":33751,\"start\":33747},{\"end\":33767,\"start\":33761},{\"end\":33783,\"start\":33778},{\"end\":34075,\"start\":34070},{\"end\":34090,\"start\":34084},{\"end\":34106,\"start\":34100},{\"end\":34120,\"start\":34116},{\"end\":34132,\"start\":34129},{\"end\":34134,\"start\":34133},{\"end\":34566,\"start\":34560},{\"end\":34582,\"start\":34576},{\"end\":34596,\"start\":34590},{\"end\":34899,\"start\":34894},{\"end\":34911,\"start\":34906},{\"end\":34922,\"start\":34916},{\"end\":34931,\"start\":34928},{\"end\":34947,\"start\":34937},{\"end\":34961,\"start\":34954},{\"end\":35411,\"start\":35405},{\"end\":35423,\"start\":35417},{\"end\":35435,\"start\":35430},{\"end\":35709,\"start\":35706},{\"end\":35721,\"start\":35717},{\"end\":35731,\"start\":35727},{\"end\":35743,\"start\":35738},{\"end\":35756,\"start\":35749}]", "bib_author_last_name": "[{\"end\":26226,\"start\":26219},{\"end\":26243,\"start\":26239},{\"end\":26255,\"start\":26250},{\"end\":26269,\"start\":26264},{\"end\":26602,\"start\":26597},{\"end\":26609,\"start\":26606},{\"end\":27023,\"start\":27015},{\"end\":27041,\"start\":27032},{\"end\":27054,\"start\":27048},{\"end\":27068,\"start\":27062},{\"end\":27545,\"start\":27541},{\"end\":27555,\"start\":27551},{\"end\":27568,\"start\":27566},{\"end\":27578,\"start\":27573},{\"end\":27993,\"start\":27990},{\"end\":28006,\"start\":28001},{\"end\":28159,\"start\":28156},{\"end\":28173,\"start\":28168},{\"end\":28188,\"start\":28184},{\"end\":28204,\"start\":28197},{\"end\":28219,\"start\":28213},{\"end\":28234,\"start\":28227},{\"end\":28247,\"start\":28244},{\"end\":28262,\"start\":28256},{\"end\":28782,\"start\":28777},{\"end\":28797,\"start\":28791},{\"end\":28811,\"start\":28806},{\"end\":28833,\"start\":28825},{\"end\":28845,\"start\":28843},{\"end\":28860,\"start\":28854},{\"end\":28875,\"start\":28868},{\"end\":28897,\"start\":28891},{\"end\":29387,\"start\":29382},{\"end\":29397,\"start\":29391},{\"end\":29409,\"start\":29401},{\"end\":29416,\"start\":29413},{\"end\":29424,\"start\":29420},{\"end\":29434,\"start\":29428},{\"end\":29806,\"start\":29801},{\"end\":29819,\"start\":29815},{\"end\":29833,\"start\":29827},{\"end\":29848,\"start\":29842},{\"end\":30235,\"start\":30230},{\"end\":30248,\"start\":30245},{\"end\":30263,\"start\":30255},{\"end\":30278,\"start\":30273},{\"end\":30295,\"start\":30288},{\"end\":30310,\"start\":30304},{\"end\":30321,\"start\":30319},{\"end\":30329,\"start\":30323},{\"end\":30848,\"start\":30841},{\"end\":31117,\"start\":31106},{\"end\":31134,\"start\":31129},{\"end\":31154,\"start\":31145},{\"end\":31167,\"start\":31161},{\"end\":31181,\"start\":31175},{\"end\":31196,\"start\":31187},{\"end\":31533,\"start\":31518},{\"end\":31550,\"start\":31543},{\"end\":31558,\"start\":31552},{\"end\":32167,\"start\":32162},{\"end\":32424,\"start\":32415},{\"end\":32440,\"start\":32435},{\"end\":32459,\"start\":32450},{\"end\":32470,\"start\":32461},{\"end\":32803,\"start\":32799},{\"end\":32814,\"start\":32810},{\"end\":32828,\"start\":32822},{\"end\":32842,\"start\":32837},{\"end\":32858,\"start\":32851},{\"end\":32877,\"start\":32867},{\"end\":32893,\"start\":32885},{\"end\":32908,\"start\":32904},{\"end\":32926,\"start\":32918},{\"end\":32939,\"start\":32935},{\"end\":33339,\"start\":33316},{\"end\":33354,\"start\":33348},{\"end\":33369,\"start\":33362},{\"end\":33377,\"start\":33371},{\"end\":33759,\"start\":33752},{\"end\":33776,\"start\":33768},{\"end\":33791,\"start\":33784},{\"end\":34082,\"start\":34076},{\"end\":34098,\"start\":34091},{\"end\":34114,\"start\":34107},{\"end\":34127,\"start\":34121},{\"end\":34141,\"start\":34135},{\"end\":34574,\"start\":34567},{\"end\":34588,\"start\":34583},{\"end\":34603,\"start\":34597},{\"end\":34904,\"start\":34900},{\"end\":34914,\"start\":34912},{\"end\":34926,\"start\":34923},{\"end\":34935,\"start\":34932},{\"end\":34952,\"start\":34948},{\"end\":34965,\"start\":34962},{\"end\":35415,\"start\":35412},{\"end\":35428,\"start\":35424},{\"end\":35438,\"start\":35436},{\"end\":35715,\"start\":35710},{\"end\":35725,\"start\":35722},{\"end\":35736,\"start\":35732},{\"end\":35747,\"start\":35744},{\"end\":35762,\"start\":35757}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":6975432},\"end\":26499,\"start\":26138},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":25417297},\"end\":26869,\"start\":26501},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":52168429},\"end\":27428,\"start\":26871},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":220793524},\"end\":27948,\"start\":27430},{\"attributes\":{\"id\":\"b4\"},\"end\":28074,\"start\":27950},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":231730928},\"end\":28693,\"start\":28076},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":227069231},\"end\":29284,\"start\":28695},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":163164623},\"end\":29722,\"start\":29286},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":21351739},\"end\":30143,\"start\":29724},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":209093915},\"end\":30707,\"start\":30145},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":733980},\"end\":31058,\"start\":30709},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":174797921},\"end\":31401,\"start\":31060},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":220665748},\"end\":32098,\"start\":31403},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":14542261},\"end\":32307,\"start\":32100},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":182118830},\"end\":32694,\"start\":32309},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":231705788},\"end\":33256,\"start\":32696},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":201625025},\"end\":33685,\"start\":33258},{\"attributes\":{\"id\":\"b17\"},\"end\":33977,\"start\":33687},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":12008695},\"end\":34474,\"start\":33979},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":218934679},\"end\":34829,\"start\":34476},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":212813747},\"end\":35319,\"start\":34831},{\"attributes\":{\"doi\":\"arXiv:2002.06715\",\"id\":\"b21\"},\"end\":35631,\"start\":35321},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":221191324},\"end\":36199,\"start\":35633}]", "bib_title": "[{\"end\":26210,\"start\":26138},{\"end\":26593,\"start\":26501},{\"end\":27005,\"start\":26871},{\"end\":27535,\"start\":27430},{\"end\":28147,\"start\":28076},{\"end\":28767,\"start\":28695},{\"end\":29378,\"start\":29286},{\"end\":29792,\"start\":29724},{\"end\":30221,\"start\":30145},{\"end\":30832,\"start\":30709},{\"end\":31096,\"start\":31060},{\"end\":31509,\"start\":31403},{\"end\":32155,\"start\":32100},{\"end\":32407,\"start\":32309},{\"end\":32793,\"start\":32696},{\"end\":33308,\"start\":33258},{\"end\":34068,\"start\":33979},{\"end\":34558,\"start\":34476},{\"end\":34892,\"start\":34831},{\"end\":35704,\"start\":35633}]", "bib_author": "[{\"end\":26228,\"start\":26212},{\"end\":26245,\"start\":26228},{\"end\":26257,\"start\":26245},{\"end\":26271,\"start\":26257},{\"end\":26296,\"start\":26271},{\"end\":26604,\"start\":26595},{\"end\":26611,\"start\":26604},{\"end\":27025,\"start\":27007},{\"end\":27043,\"start\":27025},{\"end\":27056,\"start\":27043},{\"end\":27070,\"start\":27056},{\"end\":27547,\"start\":27537},{\"end\":27557,\"start\":27547},{\"end\":27570,\"start\":27557},{\"end\":27580,\"start\":27570},{\"end\":27995,\"start\":27983},{\"end\":28008,\"start\":27995},{\"end\":28161,\"start\":28149},{\"end\":28175,\"start\":28161},{\"end\":28190,\"start\":28175},{\"end\":28206,\"start\":28190},{\"end\":28221,\"start\":28206},{\"end\":28236,\"start\":28221},{\"end\":28249,\"start\":28236},{\"end\":28264,\"start\":28249},{\"end\":28784,\"start\":28769},{\"end\":28799,\"start\":28784},{\"end\":28813,\"start\":28799},{\"end\":28835,\"start\":28813},{\"end\":28847,\"start\":28835},{\"end\":28862,\"start\":28847},{\"end\":28877,\"start\":28862},{\"end\":28899,\"start\":28877},{\"end\":29389,\"start\":29380},{\"end\":29399,\"start\":29389},{\"end\":29411,\"start\":29399},{\"end\":29418,\"start\":29411},{\"end\":29426,\"start\":29418},{\"end\":29436,\"start\":29426},{\"end\":29808,\"start\":29794},{\"end\":29821,\"start\":29808},{\"end\":29835,\"start\":29821},{\"end\":29850,\"start\":29835},{\"end\":30237,\"start\":30223},{\"end\":30250,\"start\":30237},{\"end\":30265,\"start\":30250},{\"end\":30280,\"start\":30265},{\"end\":30297,\"start\":30280},{\"end\":30312,\"start\":30297},{\"end\":30323,\"start\":30312},{\"end\":30331,\"start\":30323},{\"end\":30850,\"start\":30834},{\"end\":31119,\"start\":31098},{\"end\":31136,\"start\":31119},{\"end\":31156,\"start\":31136},{\"end\":31169,\"start\":31156},{\"end\":31183,\"start\":31169},{\"end\":31198,\"start\":31183},{\"end\":31535,\"start\":31511},{\"end\":31552,\"start\":31535},{\"end\":31560,\"start\":31552},{\"end\":32169,\"start\":32157},{\"end\":32426,\"start\":32409},{\"end\":32442,\"start\":32426},{\"end\":32461,\"start\":32442},{\"end\":32472,\"start\":32461},{\"end\":32805,\"start\":32795},{\"end\":32816,\"start\":32805},{\"end\":32830,\"start\":32816},{\"end\":32844,\"start\":32830},{\"end\":32860,\"start\":32844},{\"end\":32879,\"start\":32860},{\"end\":32895,\"start\":32879},{\"end\":32910,\"start\":32895},{\"end\":32928,\"start\":32910},{\"end\":32941,\"start\":32928},{\"end\":33341,\"start\":33310},{\"end\":33356,\"start\":33341},{\"end\":33371,\"start\":33356},{\"end\":33379,\"start\":33371},{\"end\":33761,\"start\":33747},{\"end\":33778,\"start\":33761},{\"end\":33793,\"start\":33778},{\"end\":34084,\"start\":34070},{\"end\":34100,\"start\":34084},{\"end\":34116,\"start\":34100},{\"end\":34129,\"start\":34116},{\"end\":34143,\"start\":34129},{\"end\":34576,\"start\":34560},{\"end\":34590,\"start\":34576},{\"end\":34605,\"start\":34590},{\"end\":34906,\"start\":34894},{\"end\":34916,\"start\":34906},{\"end\":34928,\"start\":34916},{\"end\":34937,\"start\":34928},{\"end\":34954,\"start\":34937},{\"end\":34967,\"start\":34954},{\"end\":35417,\"start\":35405},{\"end\":35430,\"start\":35417},{\"end\":35440,\"start\":35430},{\"end\":35717,\"start\":35706},{\"end\":35727,\"start\":35717},{\"end\":35738,\"start\":35727},{\"end\":35749,\"start\":35738},{\"end\":35764,\"start\":35749}]", "bib_venue": "[{\"end\":27699,\"start\":27648},{\"end\":28401,\"start\":28341},{\"end\":31721,\"start\":31649},{\"end\":32202,\"start\":32194},{\"end\":33459,\"start\":33443},{\"end\":35076,\"start\":35030},{\"end\":35943,\"start\":35862},{\"end\":26301,\"start\":26296},{\"end\":26668,\"start\":26611},{\"end\":27131,\"start\":27070},{\"end\":27646,\"start\":27580},{\"end\":27981,\"start\":27950},{\"end\":28339,\"start\":28264},{\"end\":28970,\"start\":28899},{\"end\":29484,\"start\":29436},{\"end\":29914,\"start\":29850},{\"end\":30408,\"start\":30331},{\"end\":30871,\"start\":30850},{\"end\":31216,\"start\":31198},{\"end\":31647,\"start\":31560},{\"end\":32192,\"start\":32169},{\"end\":32488,\"start\":32472},{\"end\":32959,\"start\":32941},{\"end\":33441,\"start\":33379},{\"end\":33745,\"start\":33687},{\"end\":34207,\"start\":34143},{\"end\":34635,\"start\":34605},{\"end\":35028,\"start\":34967},{\"end\":35403,\"start\":35321},{\"end\":35860,\"start\":35764}]"}}}, "year": 2023, "month": 12, "day": 17}