{"id": 49648997, "updated": "2023-03-28 13:35:38.704", "metadata": {"title": "An Attribute-aware Neural Attentive Model for Next Basket Recommendation", "authors": "[{\"first\":\"Ting\",\"last\":\"Bai\",\"middle\":[]},{\"first\":\"Jian-Yun\",\"last\":\"Nie\",\"middle\":[]},{\"first\":\"Wayne\",\"last\":\"Zhao\",\"middle\":[\"Xin\"]},{\"first\":\"Yutao\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Pan\",\"last\":\"Du\",\"middle\":[]},{\"first\":\"Ji-Rong\",\"last\":\"Wen\",\"middle\":[]}]", "venue": null, "journal": "The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval", "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "Next basket recommendation is a new type of recommendation, which recommends a set of items, or a basket, to the user. Purchase in basket is a common behavior of consumers. Recently, deep neural networks have been applied to model sequential transactions of baskets in next basket recommendation. However, current methods do not track the user's evolving appetite for items explicitly, and they ignore important item attributes such as product category. In this paper, we propose a novel Attribute-aware Neural Attentive Model (ANAM) to address these problems. ANAM adopts an attention mechanism to explicitly model user's evolving appetite for items, and utilizes a hierarchical architecture to incorporate the attribute information. In specific, ANAM utilizes a recurrent neural network to model the user's sequential behavior over time, and relays the user's appetite toward items and their attributes to next basket through attention weights shared across baskets on the two different hierarchies. Experiment results on two public datasets (\u0131e Ta-Feng and JingDong) demonstrate the effectiveness of our ANAM model for next basket recommendation.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2798984840", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigir/BaiNZZDW18", "doi": "10.1145/3209978.3210129"}}, "content": {"source": {"pdf_hash": "ed61f1ae043764e78627fff0af93b9425fd608f4", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "a8c4ae74660ff5ef831e89a6f8e193879bca894c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/ed61f1ae043764e78627fff0af93b9425fd608f4.txt", "contents": "\nAn Attribute-aware Neural Attentive Model for Next Basket Recommendation\nJuly 8-12. 2018. July 8-12. 2018\n\nTing Bai \nSchool of Information\nRenmin University of China\n\n\nBeijing Key Laboratory of Big Data Management and Analysis Methods\n\n\nDepartment of Computer Science and Operations Research\nUniversity of Montreal\n\n\nJian-Yun Nie \nDepartment of Computer Science and Operations Research\nUniversity of Montreal\n\n\nWayne Xin Zhao \nSchool of Information\nRenmin University of China\n\n\nBeijing Key Laboratory of Big Data Management and Analysis Methods\n\n\nYutao Zhu ytzhu@ruc.edu.cn \nSchool of Information\nRenmin University of China\n\n\nBeijing Key Laboratory of Big Data Management and Analysis Methods\n\n\nPan Du pandu@iro.umontreal.ca \nDepartment of Computer Science and Operations Research\nUniversity of Montreal\n\n\nJi-Rong Wen jirong.wen@gmail.com \nSchool of Information\nRenmin University of China\n\n\nBeijing Key Laboratory of Big Data Management and Analysis Methods\n\n\nTing Bai \nSchool of Information\nRenmin University of China\n\n\nBeijing Key Laboratory of Big Data Management and Analysis Methods\n\n\nDepartment of Computer Science and Operations Research\nUniversity of Montreal\n\n\nJian-Yun Nie \nDepartment of Computer Science and Operations Research\nUniversity of Montreal\n\n\nWayne Xin Zhao \nSchool of Information\nRenmin University of China\n\n\nBeijing Key Laboratory of Big Data Management and Analysis Methods\n\n\nYutao Zhu \nSchool of Information\nRenmin University of China\n\n\nBeijing Key Laboratory of Big Data Management and Analysis Methods\n\n\nPan Du \nDepartment of Computer Science and Operations Research\nUniversity of Montreal\n\n\nJi-Rong Wen \nSchool of Information\nRenmin University of China\n\n\nBeijing Key Laboratory of Big Data Management and Analysis Methods\n\n\nAn Attribute-aware Neural Attentive Model for Next Basket Recommendation\n\nSIGIR '18: The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval\nAnn Arbor, MI, USA, Jennifer B. SIGIR; Ann Arbor, MI, USA18July 8-12. 2018. July 8-12. 201810.1145/3209978.32101292018. An Attribute-aware Neural Attentive Model for Next Basket Recommendation. Sartor, Theo D'Hondt, and Wolfgang De Meuter (Eds.). ACM, New York, NY, USA, 4 pages. https:// * Corresponding Author. ACM ISBN 978-1-4503-5657-2/18/07. . . $15.00\nNext basket recommendation is a new type of recommendation, which recommends a set of items, or a basket, to the user. Purchase in basket is a common behavior of consumers. Recently, deep neural networks have been applied to model sequential transactions of baskets in next basket recommendation. However, current methods do not track the user's evolving appetite for items explicitly, and they ignore important item attributes such as product category. In this paper, we propose a novel Attribute-aware Neural Attentive Model (ANAM) to address these problems. ANAM adopts an attention mechanism to explicitly model user's evolving appetite for items, and utilizes a hierarchical architecture to incorporate the attribute information. In specific, ANAM utilizes a recurrent neural network to model the user's sequential behavior over time, and relays the user's appetite toward items and their attributes to next basket through attention weights shared across baskets on the two different hierarchies. Experiment results on two public datasets (i.e., Ta-Feng and JingDong) demonstrate the effectiveness of our ANAM model for next basket recommendation.CCS CONCEPTS\u2022 Information systems \u2192 Recommender systems; \u2022 Computing methodologies \u2192 Neural networks; KEYWORDS Attribute-aware model; Hierarchical attentive architecture; Next basket recommendation ACM Reference Format:\n\nINTRODUCTION\n\nRecommender systems provide great help for users to find their desired items from a huge number of offers. Most studies have focused on item recommendation, where each item is recommended separately. In most real scenarios, users often purchase a basket of items at a visit of an online store. A basket contains several items the user purchases together. The next basket recommendation is to predict the next few items that the user would likely buy.\n\nThe key difference with item recommendation is that items in a basket can be dependent. For example, it is more likely that a user puts bread and beer in the same basket than bread and wrenches. Next basket recommendation is also different from session-based recommendation because the order to put items in the basket is not as important as in a session. The items that a user would put in his basket are certainly dependent on the general interests of the user, but are also dependent on the items that the user has purchased in his previous baskets. Both elements reflect the user's appetite for items, which often evolves over time.\n\nApplying deep learning technique in recommender systems [1] and detecting the purchase appetite of users and their evolution in time has been an active research topic in recent years [2,[4][5][6]. Three main approaches have been proposed to model the sequential behaviors of a user in next basket recommendation, which are respectively based on: purchase pattern, Markov Chains (MC) and Recurrent Neural Network (RNN). Pattern-based method [2] considers the correlation among items within the same basket, and incorporates different product factors (e.g., co-occurrency, periodicity) into the decision process. Factorizing Personalized Markov Chains (FPMC) [4] models both user's sequential behavior and general taste by conducting a tensor factorization over the transition cube. Hierarchical Representation Model (HRM) [5] improves FPMC by employing a two-layer architecture to construct a nolinear hybrid aggregation of the user vector and the transaction representation. Notice that these two MC-based methods model the sequential behaviors of users only between adjacent transactions, which is insufficient to capture the long-term trend of baskets. To address this problem, Dynamic REcurrent bAasket Model [6] (DREAM) adopts RNN to model global sequential features which reflect interactions among baskets, and uses the hidden state of RNN to represent user's dynamic interests over time.\n\nHowever, the previous RNN methods ignore the attributes of item, e.g., category and price, which are crucial in the user's purchase decision. For instance, if a user begins to purchase some products for babies, he or she is more likely to purchase other products in that category in the near future. Based on the above observations, we propose an Attribute-aware Neural Attentive Model (ANAM) for next basket recommendation. Instead of using the combined representation of item and its attributes as the input of recommendation model, we propose a novel hierarchical architecture to apply the independent attention mechanism to items and attributes respectively. Then we apply a joint learning function to combine user\u0105\u0155s varying appetite towards items and attributes. ANAM utilizes an attentive RNN to model the user's sequential behavior over time, and relays the user's appetite for items and their attributes to next basket through attention weights shared across baskets on the two different hierarchies.\n\nOur contributions are summarized as follows: (1) We propose a hierarchical attentive architecture to explicitly model the user's appetite for any attributes of items (e.g., category); (2) Using a joint learning function combining the attentive information of items and attributes, our model is more effective to capture user's varying appetite towards items; (3) We demonstrate through two real-world datasets the effectiveness of our model for the next basket recommendation task.\n\n\nATTRIBUTE-AWARE NEURAL ATTENTIVE MODEL 2.1 Problem Statement\n\nAssume that we have a set of users and items, denoted by U and I respectively. Let u \u2208 U denote a user and i \u2208 I denote an item.\n\nThe number of users and items is donated as |U | and |I | respectively. Given a user u, his or her purchase records sorted by time is a sequence of baskets\nB u = {B u 1 , B u 2 , ..., B u t }.\nt is the step of the sequence of baskets. B u t \u2286 I consists of a set of items. Each item i has some attributes, such as the category and price. Currently we use the category information as item attributes, but our model could be easily extended to characterize other attribute information. The attribute of item i is denoted as c i \u2208 C, where C is the set of categories. The category information of items in basket B u t is denoted as C t . Based on the above notations, given a user u's purchase history, the next basket recommendation task can be defined as a prediction problem which aims to infer a set of items that u would probably buy in the next basket. Such a prediction problem can be reformulated as a ranking problem of all items for each user. With the ranking list of all items, we recommend top K items to the user.\n\n\nThe Proposed Model\n\nIn this paper, we propose a unified Attribute-aware Neural Attentive Model (ANAM) using the architecture shown in Fig. 1. ANAM utilizes a hierarchical attentive RNN to model the user's sequential behavior over time, and relays the user's appetite for items and their attributes to next basket through attention weights shared across baskets. In the following, we first model the information of a basket: encoding information of items and item attributes in each basket; and learning the joint function to integrate the corresponding attention weights of items and attributes. Then we model user's sequential behavior by RNN.\n\n\nEncoding items and item attributes.\n\nFor a basket B u t at step t, we represent the information of item set I t using a |I |-dimensional one-hot representation, denoted by e I t \u2208 R |I |\u00d71 , only the entry corresponding to item which exists in basket B u t will be set to 1. The same for the set of categories C t , denoted by e C t \u2208 R |C |\u00d71 . Then we apply a concatenation-based lookup layer to transform the one-hot vectors of I t and C t into latent vectors\nv I t =concat-lookup(P \u22a4 , e I t ),(1)v C t =concat-lookup(Q \u22a4 , e C t ),(2)\nwhere P \u2208 R D\u00d7 |I | and Q \u2208 R D\u00d7 |C | are the transformation matrices for lookup and D is the embedding dimension of each item and\ncategory. v I t \u2208 R D\u00d7 |I t | and v C t \u2208 R D\u00d7 |C t | are the latent vector of items and item categories in basket B u t . |I t | is the number of items in B u t and |C t | is the number of categories in B u t . For each item i t \u2208 I t , the corresponding embedding vector is v i t \u2208 R D\u00d71 ; and for each category c t \u2208 C t , it is v c t \u2208 R D\u00d71 .\nSince the number of items in each basket changes, we use a masked zero-padding value in the embedding layer to convert each basket to a fixed-dimension of representation vector.\n\n\nIntegrating attention weights.\n\nWe employ attention mechanism to capture user's varying appetite toward items and categories upon all baskets. For each item i \u2208 I and each category c \u2208 C, we assume user's appetite for the item and category is a i \u2208 A I and a c \u2208 A C respectively. a i \u2208 R D\u00d71 and a c \u2208 R D\u00d71 are initialized randomly and learned automatically as the training process over all baskets. A I \u2208 R |I |\u00d7D and A C \u2208 R |C |\u00d7D are the attention matrices of all items and categories (see Figure 1). For an item i in basket B u t , we obtain the attentive representation of i by\u1e7d i t = v i t \u2299 a i , where \"\u2299\" denotes the element-wise product of vectors. Now we have the latent vector v I t of all items (see Eq. 1) and v C t of all categories (see Eq. 2) in B u t , we integrate attention weights with the latent vectors of items and categories as follows\nv I t =v I t \u2299 CONCAT(a i |i \u2208 I t ),(3)v C t =v C t \u2299 CONCAT(c i |i \u2208 I t ),(4)\nwhere \"CONCAT\" function concatenates the attentive vectors of the items or categories in the basket. Intuitively, higher attention to a category makes the product in it more likely to be purchased. We adopt a joint learning function by applying an element-wise product, which incorporates the attentive vectors of items and categories into a unified vector v B t \u2208 R D\u00d7 |I t | to represent the basket. \nv B t =\u1e7d I t \u2299\u1e7d C t .(5)v B = {v B 1 , v B 2 , ..., v B t }.\nFor a user u, we represent it using a |U |-dimensional one-hot representation, denoted by e u \u2208 R |U |\u00d71 , only the entry corresponding to u will be set to 1. Then we apply a lookup layer to transform the one-hot vectors of u into latent vectors\nv u = lookup(W \u22a4 , e u ),(6)\nwhere W \u2208 R D\u00d7|U | is the transformation matrices for lookup. In order to model user's sequential behavior, we adopt Long Short-Term Memory (LSTM), which has proven effective at modeling sequential data. The input of LSTM at step t is v B t . The output of LSTM at step t (i.e., hidden state) is represented as v h t \u2208 R D\u00d71 , and it is applied later to construct our loss function.\n\n\nThe Loss Function for Optimization\n\nFor a user u and his or her previous baskets B u 1,t , we define the probability of an item i being purchased in the next basket B u t +1 by softmax function\np(i \u2208 B u t +1 |u, B u 1,t ) = exp(v \u22a4 i \u00b7 (v u \u2299 v h t )) |I | j=1 exp(v \u22a4 j \u00b7 (v u \u2299 v h t )) ,(7)\nwhere v u \u2208 R D\u00d71 is the embedding vector of user u, and v h t \u2208 R D\u00d71 is the hidden vector of LSTM at step t.\n\nTo effectively learn from the training data, we adopt a weighted cross-entropy as the optimization objective at each step of LSTM, which is defined as\nL = u \u2208U B u t \u2208B u i \u2208I t (\u2212m \u00b7 y i \u00b7 logp i \u2212 n \u00b7 (1 \u2212 y i ) \u00b7 log(1 \u2212p i )),(8)\nwherep i is the probability of an item i being purchased in the next basket in our model. If item i is purchased in the the next basket, y i = 1, otherwise, y i = 0. m and n are the weights of positive and negative instances (purchased or not in the next basket). The reason of using different weights is to cope the fact that there are usually much more negative instances than positive instances in a dataset. We take the last basket of each user as the testing data, the penultimate basket as the validation set to optimize parameters, and the remaining baskets as the training data. We implement our models in Python using the library Keras. The loss function in Eq. 8 is optimized by Adam with a batch size of 200 in Ta-Feng and 500 in JingDong datasets. Due to the disparity of the amount of positive and negative instances, we set m 500 times larger than n in our experiments to punish the error of mistaking the positive instances. The learning rate is set to 0.001 and embedding size in the input layer and the units in LSTM are set to 50 (i.e., D = 50).\n\nAfter training, given a user's historical transaction records, we can obtain the probability of each item i being purchased in the next basket according to Eq. 7. We than rank the items according to their probability, and select top K results as the final recommended items to the user. \n\n\nEXPERIMENTS\n\nDataset. We experiment with two real-world datasets, namely Ta-Feng 1 and JingDong.\n\n\u2022 Ta , and is shared in [7]. On JingDong platform, users are permitted to post reviews towards product only if he or she had purchased the product, hence, we use the reviews records to represent the transaction of user's purchase records. The users having less than 10 and 25 purchases in Ta-Feng and JingDong are removed, so are the items purchased less than 10 and 20 times. The average number of baskets for a user in Ta-Feng and JingDong datasets is 8.4 and 8.7, and the average number of products in each basket is 6.6 and 4.1. The statistics of the two datasets are summarized in Table 1.\n\nEvaluation metrics. Following [5,6], we choose the top K (i.e., K = 5) items in the ranking list of all items as the recommended set.\n\nTo evaluate the performance of our model, we adopt the widely used F1-score and Normalized Discounted Cumulative Gain (NDCG).\n\nBaseline methods compared. We consider the following baselines for performance comparisons.\n\n\u2022 TOP: It ranks the the items according to their popularity.\n\n\u2022 NMF [3]: It is the state-of-the-art method in traditional model based collaborative filtering methods. It uses nonnegative matrix factorization on user-item matrix. For implementation, we use the public code NMF: DTU Toolbox 2 . \u2022 FPMC [4]: It learns a transition matrix based on underlying Markov chains. It models the sequential behavior but only between adjacent transactions. \u2022 HRM [5]: It employs neural network to implement a nonlinear operation to integrate the representation of users and item purchase history in last transactions. \u2022 DREAM [6]: It incorporates both general customers' preferences and sequential information by using RNN. It is the state-of-the-art method in next basket recommendation task. Among all the above method, NMF does not model the basket information. FPMC and HRM only use the sequence information between two adjacent baskets. DREAM uses RNN to capture the global sequential information, but does not use attention mechanism to effectively model the sequence information. Besides, all of the above methods do not consider item attributes. Our ANAM employs a hierarchical attentive architecture to apply attention mechanism to items and attributes respectively, which can effectively model users' varying appetite towards items. To empirically evaluate the effectiveness of the attention mechanism and attribute information respectively, we compare our ANAM with DREAMan RNN model without attention and attribute information, and a degenerated Neural Attentive Model (NAM) -our attentive RNN model without attribute information.\n\nResults and analysis. We present the results of F1-score@5 and NDCG@5 on the next basket recommendation performance in Table 2. In our experiments, the embedding dimension in HRM and DREAM is set to 50. For JingDong dataset, we set the learning rate to 0.001 in Dream, 0.0003 in HRM and 0.001 in FPMC which yield the best results. For Ta-Feng, we use the same training and testing data as HRM, so we report the baseline results as in [5]. We re-implement the DREAM, and modify the objective function as Eq. 8. This change leads to a huge improvement of the original results in [6]. The parameters of our modified DREAM (denoted as DREAM * ) are the same as in our ANAM model. We report the results of DREAM * in Table 2.\n\nWe can make the following observations:\n\n\u2022 TOP is the weakest baseline, since it is a non-personalized method. NMF performs better than TOP, but it does not consider any sequential information of users. FPMC outperforms slightly NMF by taking into account adjacent baskets. \u2022 HRM further improves the effectiveness by using neural network. This shows the ability of neural network to model complex interactions between user's general taste and their sequential behavior. Compared with HRM, DREAM achieves better effectiveness on F1-score@5 and NDCG@5 due to use of whole sequential information. \u2022 DREAM * , which uses a modified loss function, leads to a large boost in effectiveness. This indicates the great importance to weigh the training examples in the training process. \u2022 Our degenerated model NAM consistently and significantly outperforms all baseline methods, showing the effectiveness of our attentive mechanism on item to capture user's evolving appetite for items.\n\n\u2022 ANAM performs better than NAM, This indicates the contribution of the attribute information of item.\n\n\nCONCLUSION\n\nThis paper presented a novel attribute-aware neural attentive model for next basket recommendation, which utilizes a hierarchical attentive architecture to integrate the attribute information of items. ANAM effectively captures the user's evolving appetite for the item by using a joint learning function combining the attentive information of items and attributes. Experimental results on two public datasets (i.e., Ta-Feng and JingDong) demonstrated the effectiveness of our ANAM model for next basket recommendation. This work shows the necessity to model the baskets in the purchase history of a user, and to incorporate the attribute information about items. As future work, we will investigate more attributes of item (e.g., price) and explore the effects of multiple factors on the user's purchase decision. This series of experiments confirms the previous results that the sequential information about baskets provides some useful information for next basket prediction. The superior performance of our model shows that attribute information can further boost the effectiveness.\n\nFigure 1 :\n1Overview of the architecture of ANAM\n\n\n-Feng dataset contains 4 months (November 2000 to February 2001) of shopping transactions of the Ta-Feng supermarket. \u2022 JingDong dataset contains product reviews records of users in 4 months (January 2012 to April 2012)\n\nTable 1 :\n1Statistics of the evaluation datasets.Datasets # Users #Items # Transactions # Category \nTa-Feng \n9,238 \n7,973 \n464,118 \n1,074 \nJingDong \n4,832 \n3,283 \n41,932 \n165 \n\n\n\nTable 2 :\n2Performance comparisons of different methods on the next basket recommendation task.Note: \" * \" indicates the statistically significant improvements (i.e., two-tailed t -test with p < 0.01 ) over the best baseline (i.e., DREAM * ).Datasets \nTa-Feng \nJingDong \nModels \nF1-score@5 NDCG@5 F1-score@5 NDCG@5 \nTOP \n0.051 \n0.084 \n0.0066 \n0.0094 \nNMF \n0.052 \n0.072 \n0.0069 \n0.0097 \nFPMC \n0.059 \n0.087 \n0.0078 \n0.0099 \nHRM \n0.062 \n0.089 \n0.0095 \n0.0174 \nDREAM \n0.065 \n0.084 \n0.0122 \n0.0123 \nDREAM  *  \n0.133 \n0.173 \n0.1046 \n0.1542 \nNAM \n0.142  *  \n0.187  *  \n0.1283  *  \n0.1826  *  \nANAM \n0.146  *  \n0.190  *  \n0.1313  *  \n0.1842  *  \n\n\nhttp://www.bigdatalab.ac.cn/benchmark/bm/dd?data=Ta-Feng 2 http://cogsys.imm.dtu.dk/toolbox/nmf/\nACKNOWLEDGMENTSThis work was partially supported by the National Natural Science\nA Neural Collaborative Filtering Model with Interaction-based Neighborhood. Ting Bai, Ji-Rong Wen, Jun Zhang, Wayne Xin Zhao, Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. the 2017 ACM on Conference on Information and Knowledge ManagementACMTing Bai, Ji-Rong Wen, Jun Zhang, and Wayne Xin Zhao. 2017. A Neural Collab- orative Filtering Model with Interaction-based Neighborhood. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. ACM, 1979-1982.\n\n. Riccardo Guidotti, Giulio Rossetti, Luca Pappalardo, Fosca Giannotti, Dino Pedreschi, arXiv:1702.07158Next Basket Prediction using Recurring Sequential Patterns. arXiv preprintRiccardo Guidotti, Giulio Rossetti, Luca Pappalardo, Fosca Giannotti, and Dino Pedreschi. 2017. Next Basket Prediction using Recurring Sequential Patterns. arXiv preprint arXiv:1702.07158 (2017).\n\nAlgorithms for non-negative matrix factorization. D Daniel, H Lee, Sebastian Seung, Advances in neural information processing systems. Daniel D Lee and H Sebastian Seung. 2001. Algorithms for non-negative matrix factorization. In Advances in neural information processing systems. 556-562.\n\nFactorizing personalized markov chains for next-basket recommendation. Steffen Rendle, Christoph Freudenthaler, Lars Schmidt-Thieme, Proceedings of the 19th international conference on World wide web. the 19th international conference on World wide webACMSteffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factor- izing personalized markov chains for next-basket recommendation. In Proceedings of the 19th international conference on World wide web. ACM, 811-820.\n\nLearning hierarchical representation model for nextbasket recommendation. Pengfei Wang, Jiafeng Guo, Yanyan Lan, Jun Xu, Shengxian Wan, Xueqi Cheng, Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval. the 38th international ACM SIGIR conference on research and development in information retrievalACMPengfei Wang, Jiafeng Guo, Yanyan Lan, Jun Xu, Shengxian Wan, and Xueqi Cheng. 2015. Learning hierarchical representation model for nextbasket recommendation. In Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval. ACM, 403-412.\n\nA dynamic recurrent model for next basket recommendation. Feng Yu, Qiang Liu, Shu Wu, Liang Wang, Tieniu Tan, Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. the 39th International ACM SIGIR conference on Research and Development in Information RetrievalACMFeng Yu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. A dynamic recurrent model for next basket recommendation. In Proceedings of the 39th In- ternational ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 729-732.\n\nWe know what you want to buy: a demographic-based system for product recommendation on microblogs. Yanwei Xin Wayne Zhao, Yulan Guo, Han He, Yuexin Jiang, Xiaoming Wu, Li, Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. the 20th ACM SIGKDD international conference on Knowledge discovery and data miningACMXin Wayne Zhao, Yanwei Guo, Yulan He, Han Jiang, Yuexin Wu, and Xiaoming Li. 2014. We know what you want to buy: a demographic-based system for product recommendation on microblogs. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1935-1944.\n", "annotations": {"author": "[{\"end\":317,\"start\":108},{\"end\":411,\"start\":318},{\"end\":547,\"start\":412},{\"end\":695,\"start\":548},{\"end\":806,\"start\":696},{\"end\":960,\"start\":807},{\"end\":1170,\"start\":961},{\"end\":1264,\"start\":1171},{\"end\":1400,\"start\":1265},{\"end\":1531,\"start\":1401},{\"end\":1619,\"start\":1532},{\"end\":1752,\"start\":1620}]", "publisher": null, "author_last_name": "[{\"end\":116,\"start\":113},{\"end\":330,\"start\":327},{\"end\":426,\"start\":422},{\"end\":557,\"start\":554},{\"end\":702,\"start\":700},{\"end\":818,\"start\":815},{\"end\":969,\"start\":966},{\"end\":1183,\"start\":1180},{\"end\":1279,\"start\":1275},{\"end\":1410,\"start\":1407},{\"end\":1538,\"start\":1536},{\"end\":1631,\"start\":1628}]", "author_first_name": "[{\"end\":112,\"start\":108},{\"end\":326,\"start\":318},{\"end\":417,\"start\":412},{\"end\":421,\"start\":418},{\"end\":553,\"start\":548},{\"end\":699,\"start\":696},{\"end\":814,\"start\":807},{\"end\":965,\"start\":961},{\"end\":1179,\"start\":1171},{\"end\":1270,\"start\":1265},{\"end\":1274,\"start\":1271},{\"end\":1406,\"start\":1401},{\"end\":1535,\"start\":1532},{\"end\":1627,\"start\":1620}]", "author_affiliation": "[{\"end\":167,\"start\":118},{\"end\":236,\"start\":169},{\"end\":316,\"start\":238},{\"end\":410,\"start\":332},{\"end\":477,\"start\":428},{\"end\":546,\"start\":479},{\"end\":625,\"start\":576},{\"end\":694,\"start\":627},{\"end\":805,\"start\":727},{\"end\":890,\"start\":841},{\"end\":959,\"start\":892},{\"end\":1020,\"start\":971},{\"end\":1089,\"start\":1022},{\"end\":1169,\"start\":1091},{\"end\":1263,\"start\":1185},{\"end\":1330,\"start\":1281},{\"end\":1399,\"start\":1332},{\"end\":1461,\"start\":1412},{\"end\":1530,\"start\":1463},{\"end\":1618,\"start\":1540},{\"end\":1682,\"start\":1633},{\"end\":1751,\"start\":1684}]", "title": "[{\"end\":73,\"start\":1},{\"end\":1825,\"start\":1753}]", "venue": "[{\"end\":1932,\"start\":1827}]", "abstract": "[{\"end\":3662,\"start\":2291}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4827,\"start\":4824},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4954,\"start\":4951},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4957,\"start\":4954},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4960,\"start\":4957},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4963,\"start\":4960},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5211,\"start\":5208},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5428,\"start\":5425},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5592,\"start\":5589},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5983,\"start\":5980},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":14914,\"start\":14911},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":15516,\"start\":15513},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":15518,\"start\":15516},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15909,\"start\":15906},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":16141,\"start\":16138},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16291,\"start\":16288},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16454,\"start\":16451},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":17906,\"start\":17903},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18049,\"start\":18046}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":20423,\"start\":20374},{\"attributes\":{\"id\":\"fig_1\"},\"end\":20645,\"start\":20424},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":20824,\"start\":20646},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":21465,\"start\":20825}]", "paragraph": "[{\"end\":4128,\"start\":3678},{\"end\":4766,\"start\":4130},{\"end\":6162,\"start\":4768},{\"end\":7173,\"start\":6164},{\"end\":7656,\"start\":7175},{\"end\":7849,\"start\":7721},{\"end\":8006,\"start\":7851},{\"end\":8875,\"start\":8044},{\"end\":9522,\"start\":8898},{\"end\":9987,\"start\":9562},{\"end\":10195,\"start\":10065},{\"end\":10721,\"start\":10544},{\"end\":11587,\"start\":10756},{\"end\":12071,\"start\":11669},{\"end\":12378,\"start\":12133},{\"end\":12790,\"start\":12408},{\"end\":12986,\"start\":12829},{\"end\":13198,\"start\":13088},{\"end\":13350,\"start\":13200},{\"end\":14497,\"start\":13434},{\"end\":14786,\"start\":14499},{\"end\":14885,\"start\":14802},{\"end\":15481,\"start\":14887},{\"end\":15616,\"start\":15483},{\"end\":15743,\"start\":15618},{\"end\":15836,\"start\":15745},{\"end\":15898,\"start\":15838},{\"end\":17467,\"start\":15900},{\"end\":18189,\"start\":17469},{\"end\":18230,\"start\":18191},{\"end\":19168,\"start\":18232},{\"end\":19272,\"start\":19170},{\"end\":20373,\"start\":19287}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8043,\"start\":8007},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10026,\"start\":9988},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10064,\"start\":10026},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10543,\"start\":10196},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11628,\"start\":11588},{\"attributes\":{\"id\":\"formula_5\"},\"end\":11668,\"start\":11628},{\"attributes\":{\"id\":\"formula_6\"},\"end\":12096,\"start\":12072},{\"attributes\":{\"id\":\"formula_7\"},\"end\":12132,\"start\":12096},{\"attributes\":{\"id\":\"formula_8\"},\"end\":12407,\"start\":12379},{\"attributes\":{\"id\":\"formula_9\"},\"end\":13087,\"start\":12987},{\"attributes\":{\"id\":\"formula_10\"},\"end\":13433,\"start\":13351}]", "table_ref": "[{\"end\":14891,\"start\":14889},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":15480,\"start\":15473},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":17595,\"start\":17588},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":18188,\"start\":18181}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":3676,\"start\":3664},{\"attributes\":{\"n\":\"2\"},\"end\":7719,\"start\":7659},{\"attributes\":{\"n\":\"2.2\"},\"end\":8896,\"start\":8878},{\"attributes\":{\"n\":\"2.2.1\"},\"end\":9560,\"start\":9525},{\"attributes\":{\"n\":\"2.2.2\"},\"end\":10754,\"start\":10724},{\"attributes\":{\"n\":\"2.3\"},\"end\":12827,\"start\":12793},{\"attributes\":{\"n\":\"3\"},\"end\":14800,\"start\":14789},{\"attributes\":{\"n\":\"4\"},\"end\":19285,\"start\":19275},{\"end\":20385,\"start\":20375},{\"end\":20656,\"start\":20647},{\"end\":20835,\"start\":20826}]", "table": "[{\"end\":20824,\"start\":20696},{\"end\":21465,\"start\":21068}]", "figure_caption": "[{\"end\":20423,\"start\":20387},{\"end\":20645,\"start\":20426},{\"end\":20696,\"start\":20658},{\"end\":21068,\"start\":20837}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9018,\"start\":9012},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11228,\"start\":11220}]", "bib_author_first_name": "[{\"end\":21724,\"start\":21720},{\"end\":21737,\"start\":21730},{\"end\":21746,\"start\":21743},{\"end\":21763,\"start\":21754},{\"end\":22173,\"start\":22165},{\"end\":22190,\"start\":22184},{\"end\":22205,\"start\":22201},{\"end\":22223,\"start\":22218},{\"end\":22239,\"start\":22235},{\"end\":22589,\"start\":22588},{\"end\":22599,\"start\":22598},{\"end\":22907,\"start\":22900},{\"end\":22925,\"start\":22916},{\"end\":22945,\"start\":22941},{\"end\":23396,\"start\":23389},{\"end\":23410,\"start\":23403},{\"end\":23422,\"start\":23416},{\"end\":23431,\"start\":23428},{\"end\":23445,\"start\":23436},{\"end\":23456,\"start\":23451},{\"end\":24028,\"start\":24024},{\"end\":24038,\"start\":24033},{\"end\":24047,\"start\":24044},{\"end\":24057,\"start\":24052},{\"end\":24070,\"start\":24064},{\"end\":24646,\"start\":24640},{\"end\":24668,\"start\":24663},{\"end\":24677,\"start\":24674},{\"end\":24688,\"start\":24682},{\"end\":24704,\"start\":24696}]", "bib_author_last_name": "[{\"end\":21728,\"start\":21725},{\"end\":21741,\"start\":21738},{\"end\":21752,\"start\":21747},{\"end\":21768,\"start\":21764},{\"end\":22182,\"start\":22174},{\"end\":22199,\"start\":22191},{\"end\":22216,\"start\":22206},{\"end\":22233,\"start\":22224},{\"end\":22249,\"start\":22240},{\"end\":22596,\"start\":22590},{\"end\":22603,\"start\":22600},{\"end\":22620,\"start\":22605},{\"end\":22914,\"start\":22908},{\"end\":22939,\"start\":22926},{\"end\":22960,\"start\":22946},{\"end\":23401,\"start\":23397},{\"end\":23414,\"start\":23411},{\"end\":23426,\"start\":23423},{\"end\":23434,\"start\":23432},{\"end\":23449,\"start\":23446},{\"end\":23462,\"start\":23457},{\"end\":24031,\"start\":24029},{\"end\":24042,\"start\":24039},{\"end\":24050,\"start\":24048},{\"end\":24062,\"start\":24058},{\"end\":24074,\"start\":24071},{\"end\":24661,\"start\":24647},{\"end\":24672,\"start\":24669},{\"end\":24680,\"start\":24678},{\"end\":24694,\"start\":24689},{\"end\":24707,\"start\":24705},{\"end\":24711,\"start\":24709}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":22738486},\"end\":22161,\"start\":21644},{\"attributes\":{\"doi\":\"arXiv:1702.07158\",\"id\":\"b1\"},\"end\":22536,\"start\":22163},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":2095855},\"end\":22827,\"start\":22538},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":207178809},\"end\":23313,\"start\":22829},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":4002880},\"end\":23964,\"start\":23315},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2023817},\"end\":24539,\"start\":23966},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":207214381},\"end\":25199,\"start\":24541}]", "bib_title": "[{\"end\":21718,\"start\":21644},{\"end\":22586,\"start\":22538},{\"end\":22898,\"start\":22829},{\"end\":23387,\"start\":23315},{\"end\":24022,\"start\":23966},{\"end\":24638,\"start\":24541}]", "bib_author": "[{\"end\":21730,\"start\":21720},{\"end\":21743,\"start\":21730},{\"end\":21754,\"start\":21743},{\"end\":21770,\"start\":21754},{\"end\":22184,\"start\":22165},{\"end\":22201,\"start\":22184},{\"end\":22218,\"start\":22201},{\"end\":22235,\"start\":22218},{\"end\":22251,\"start\":22235},{\"end\":22598,\"start\":22588},{\"end\":22605,\"start\":22598},{\"end\":22622,\"start\":22605},{\"end\":22916,\"start\":22900},{\"end\":22941,\"start\":22916},{\"end\":22962,\"start\":22941},{\"end\":23403,\"start\":23389},{\"end\":23416,\"start\":23403},{\"end\":23428,\"start\":23416},{\"end\":23436,\"start\":23428},{\"end\":23451,\"start\":23436},{\"end\":23464,\"start\":23451},{\"end\":24033,\"start\":24024},{\"end\":24044,\"start\":24033},{\"end\":24052,\"start\":24044},{\"end\":24064,\"start\":24052},{\"end\":24076,\"start\":24064},{\"end\":24663,\"start\":24640},{\"end\":24674,\"start\":24663},{\"end\":24682,\"start\":24674},{\"end\":24696,\"start\":24682},{\"end\":24709,\"start\":24696},{\"end\":24713,\"start\":24709}]", "bib_venue": "[{\"end\":21851,\"start\":21770},{\"end\":22671,\"start\":22622},{\"end\":23028,\"start\":22962},{\"end\":23575,\"start\":23464},{\"end\":24187,\"start\":24076},{\"end\":24811,\"start\":24713},{\"end\":21919,\"start\":21853},{\"end\":23081,\"start\":23030},{\"end\":23673,\"start\":23577},{\"end\":24285,\"start\":24189},{\"end\":24896,\"start\":24813}]"}}}, "year": 2023, "month": 12, "day": 17}