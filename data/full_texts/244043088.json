{"id": 244043088, "updated": "2023-10-06 15:32:30.179", "metadata": {"title": "FedPD: A Federated Learning Framework with Optimal Rates and Adaptivity to Non-IID Data", "authors": "[{\"first\":\"Xinwei\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Mingyi\",\"last\":\"Hong\",\"middle\":[]},{\"first\":\"Sairaj\",\"last\":\"Dhople\",\"middle\":[]},{\"first\":\"Wotao\",\"last\":\"Yin\",\"middle\":[]},{\"first\":\"Yang\",\"last\":\"Liu\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Federated Learning (FL) has become a popular paradigm for learning from distributed data. To effectively utilize data at different devices without moving them to the cloud, algorithms such as the Federated Averaging (FedAvg) have adopted a\"computation then aggregation\"(CTA) model, in which multiple local updates are performed using local data, before sending the local models to the cloud for aggregation. However, these schemes typically require strong assumptions, such as the local data are identically independent distributed (i.i.d), or the size of the local gradients are bounded. In this paper, we first explicitly characterize the behavior of the FedAvg algorithm, and show that without strong and unrealistic assumptions on the problem structure, the algorithm can behave erratically for non-convex problems (e.g., diverge to infinity). Aiming at designing FL algorithms that are provably fast and require as few assumptions as possible, we propose a new algorithm design strategy from the primal-dual optimization perspective. Our strategy yields a family of algorithms that take the same CTA model as existing algorithms, but they can deal with the non-convex objective, achieve the best possible optimization and communication complexity while being able to deal with both the full batch and mini-batch local computation models. Most importantly, the proposed algorithms are {\\it communication efficient}, in the sense that the communication pattern can be adaptive to the level of heterogeneity among the local data. To the best of our knowledge, this is the first algorithmic framework for FL that achieves all the above properties.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2005.11418", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tsp/ZhangHDYL21", "doi": "10.1109/tsp.2021.3115952"}}, "content": {"source": {"pdf_hash": "c9fbdf5453a7d638622585c3f06e830ee649419a", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2005.11418v3.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2005.11418", "status": "GREEN"}}, "grobid": {"id": "e9e1572e50203cde331bbfb03ebf2d791c3e5229", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c9fbdf5453a7d638622585c3f06e830ee649419a.txt", "contents": "\nFedPD: A Federated Learning Framework with Optimal Rates and Adaptivity to Non-IID Data\nJuly 9, 2020\n\nXinwei Zhang \nMingyi Hong \nSairaj Dhople \nWotao Yin \nYang Liu \nFedPD: A Federated Learning Framework with Optimal Rates and Adaptivity to Non-IID Data\nJuly 9, 2020\nFederated Learning (FL) is popular for communication-efficient learning from distributed data. To utilize data at different clients without moving them to the cloud, algorithms such as the Federated Averaging (FedAvg) have adopted a \"computation then aggregation\" (CTA) model, in which multiple local updates are performed using local data, before sending the local models to the cloud for aggregation. These algorithms fail to work when facing practical challenges, e.g., the local data being non-identically independent distributed. In this paper, we first characterize the behavior of the FedAvg algorithm, and show that without strong and unrealistic assumptions on the problem structure, it can behave erratically (e.g., diverge to infinity). Aiming at designing FL algorithms that are provably fast and require as few assumptions as possible, we propose a new algorithm design strategy from the primal-dual optimization perspective. Our strategy yields algorithms that can deal with non-convex objective functions, achieve the best possible optimization and communication complexity (in certain sense), and deal with full-batch and mini-batch local computation models. Importantly, the proposed algorithms are communication efficient, in that the communication effort can be reduced when the level of heterogeneity among the local data also reduces. To our knowledge, this is the first algorithmic framework for FL that achieves all the above properties.We focus on the case where the V t (\u00b7)'s and W t i (\u00b7)'s are linear operators, which implies that x t,q i can use all past iterates and (sample) gradients for its update. Clearly, (10) covers both the local-GD and local-SGD versions of FedAvg as special cases. In the following, we provide an informal statement of the result. The formal statement and the full proof are given in Appendix B and Theorem 2.Claim 2.1. (Informal) Consider any algorithm A that belongs to the class described in (10), with V t (\u00b7) and W t i (\u00b7)'s being linear and possibly time-varying operators. Then, there exists a non-convex problem instance satisfying Assumptions 1-2 such that for any Q > 0, algorithm A takes at least O(1/ ) communication rounds to reach an -stationary solution satisfying(7).Remark 1. The proof technique is related to those developed from both classical and recent works that characterize lower bounds for first-order methods, in both centralized[20,21]and decentralized[22,23]5 settings. The main technical difference is that our processing model (10) additionally allows local processing iterations, and there is a central aggregator. Our goal is not to establish lower bounds on the number of (centralized) gradient access, nor to show the optimal graph dependency, but to characterize (potential) communication savings when allowing multiple steps of local processing.In the proof, we construct difficult problem instances in which f i 's are not i.i.d. (more precisely, \u03b4 in assumption (4) grows with the total number of iterations T ). Then we show that it is necessary to aggregate (thus communicate) to make any progress. On the other hand, it is obvious that in another extreme case where the data are 0-non-i.i.d., only O(1) communication rounds are needed. An open question is: when the local data are related to each other, i.e., \u03b4 lies between 0 and infinity, is it possible to reduce the total communication rounds? This question is addressed below in Sec. 3.We now address Q1 and Q4. We consider the FedAvg Algorithm 1, and show that BN and/or i.i.d. assumptions are critical for them to perform well. Our result suggests that, despite its popularity, components in FedAvg, such as the pure local (stochastic) gradient directions and linear aggregation are not compatible with each other. The proof of the results below are given in Appendix C.Claim 2.2. Fix any constant \u03b7 > 0, Q > 1 for Algorithm 1. There exists a problem that satisfies A1 and A2 but fails to satisfy A3 and A4, on which FedAvg diverges to infinity.Remark 2. A recent work[15]has shown that FedAvg with constant stepsize \u03b7 > 0 can only converge to a neighborhood of the global minimizer for convex problems. Moreover, the error to the global optima is related to Q and the degree of non-i.i.d.-ness as measured by the size of N i=1 \u2207f i (x ) 2 where x is the global optimal solution. On the other hand, our result indicates that when f i 's are non-convex, FedAvg can perform much worse without the BN and the i.i.d. assumption. Even if Q = 2 and there exists a solution such that N i=1 f i (x) 2 = 0, FedAvg (with constant stepsize \u03b7) diverges and the iteration can go to \u221e.One may think that using a constant stepsize is the culprit for the divergence in Claim 2.2. In fact, we can show that having BG or not can still impact the performance of FedAvg, even when diminishing stepsize is used. In particular, we show in Appendix D, that FedAvg converges under the BG assumption for any diminishing stepsize, but without it, the choice of the stepsize can be significantly restricted.\n\nIntroduction\n\nFederated learning (FL)-a distributed machine learning approach proposed in [1]-has gained popularity for applications involving learning from distributed data. In FL, a cloud server (the \"server\") can communicate with distributed data sources (the \"agents\"). The goal is to train a global model that works well for all the distributed data, but without requiring the agents to reveal too much local information. Since its inception, the broad consensus on FL's implementation appears to involve a generic \"computation then aggregation\" (CTA) protocol. This involves the following steps: S1) the server sends the model x to the agents; S2) the agents update their local models x i 's for several iterations based on their local data; S3) the server aggregates x i 's to obtain a new global model x. It is widely acknowledged that multiple local steps save communication efforts, while only transmitting local models protects data privacy [2].\n\nEven though the FL paradigm has attracted significant research from both academia and industry, and many algorithms such as Federated Averaging (FedAvg) have been proposed, several attributes are not clearly established. In particular, the commonly adopted CTA protocol poses significant theoretical and practical challenges to designing effective FL algorithms. This work attempts to provide a deeper understanding of FL, by raising and resolving a few theoretical questions, as well as by developing an effective algorithmic framework with several desirable features. Problem Formulation. Consider the vanilla FL solving the following problem:\nmin x\u2208R d f (x) 1 N N i=1 f i (x), with f i (x) w i \u03be i \u2208D i F (x; \u03be i ),(1)\nwhere N is the number of agents; \u03be i denotes one sample in data set D i stored on the i-th agent; F : R d \u2192 R is the \"loss function\" for the i-th data point; and w i > 0 is a \"weight coefficient\" (a common choice is w i = 1/|D i | [2]). We assume that the loss function takes the same form across different agents, and furthermore, we denote M := N i=1 |D i | to be the total number of samples. One can also consider a related setting, where each f i (x) represents the expected loss [3] \nf i (x) E \u03be i \u2208P i F (x; \u03be i ),(2)\nwhere P i denotes the data distribution on the i-th agent. Throughout the paper, we will make the following blanket assumptions for problem (1):\nA 1. Each f i (\u00b7)\n, as well as f in (1) is L-smooth:\n\u2207f i (x) \u2212 \u2207f i (y) \u2264 L x \u2212 y , \u2207f (x) \u2212 \u2207f (y) \u2264 L x \u2212 y , \u2200 x, y \u2208 R d , i = 1, . . . , N.\nA 2. The objective of problem (1) is lower bounded: f (x) \u2265 c > \u2212\u221e, \u2200 x \u2208 R d .\n\nIn addition to these standard assumptions, state-of-the-art efforts on analysis of FL algorithms oftentimes invoke a number of more restrictive assumptions. \n\u2207f i (x) 2 \u2264 G 2 , \u2200 x \u2208 R d , \u2200 i = 1, . . . , N.(3)\nA 4. (I.I.D. Data) Either one of the following holds:\nE \u2207[f i (x)] = \u2207f (x), \u2200 x \u2208 R d , \u2200 i = 1, . . . , N,(4)N i=1 \u2207f i (x) 2 \u2264 B 2 \u2207f (x) 2 , \u2200 x \u2208 {x \u2208 R d | \u2207f (x) 2 > }.(5)\nLet us comment on the above assumptions. First, the BG assumption typically does not hold for (1), in particular, f i (x) = A i x \u2212 b i 2 (where A i and b i are related to data). However, the BG assumption is critical for analyzing FedAvg-type algorithms because it bounds the distance traveled after multiple local iterates. Second, (4) is typically used in FL to characterize homogeneity about local data [4,5]. However, an assumption of this type does not hold for FL applications where the data (such as medical records, keyboard input data) are generated by the individual agents [1,3,6,7,8,9]. A reasonable relaxation to this i.i.d. assumption is the following notion of \u03b4-non-i.i.d.-ness of the data distribution. \n\u2207f i (x) \u2212 \u2207f j (x) \u2264 \u03b4, \u2200 x \u2208 R d , \u2200 i = j, or \u2207f i (x) \u2212 \u2207f (x) \u2264 \u03b4 \u2200 x \u2208 R d , \u2200 i.(6)\nBy varying \u03b4 from 0 to \u221e, (6) provides a characterization of data non-i.i.d.-ness. In Appendix A, we give a few examples of loss functions with different values of \u03b4. Note that the second inequality in (6) is often used in decentralized optimization to quantify the similarity of local problems [10,11]. Third, (5) does not hold for many practical problems. To see this, note that this condition is parameterized by , which is typically the desired optimization accuracy [12]. Since can be chosen arbitrarily small, (5) essentially requires that the problem is realizable, that is, \u2207f (x) approaches zero only when all the local gradients approach zero at x, that is, when the local data are \"similar\".\n\nFinally, we mention that our objective is to understand FL algorithm from an optimization perspective. So we say that a solution x is an -stationary solution if the following holds:\n\u2207f (x) 2 \u2264 .(7)\nWe are interested in finding the minimum system resources required, such as the number of local updates, the number of times local variables are transmitted to the server, and the number of times local samples F (x; \u03be i )'s are accessed, before computing an -solution (7). These quantities are referred to as local computation, communication complexity, and sample complexities, respectively. Questions to address Despite extensive recent research, the FL framework, and in particular, the CTA protocol is not yet well understood. Below, we list four questions regarding the CTA protocol. Q1 (local updates). What are the best local update directions for the agents to take so as to achieve the best overall system performance (stability, sample complexity, etc.)? Q2 (global aggregation). Can we use more sophisticated processing in the aggregation step to help improve the system performance (sample or communication complexity)? Q3 (communication efficiency). If multiple local updates are preformed between two aggregation steps, will it reduce the communication overhead? Q4 (assumptions). What is the best performance that the CTA type algorithms can achieve while relying on a minimum set of assumptions about the problem? Although these questions are not directly related to data privacy, another important aspect of FL, we argue that answering these fundamental questions can provide much needed understanding on algorithms following the CTA, and thus the FL approach. A few recent works (to be reviewed shortly) have touched upon those questions, but to our knowledge, none of them has conducted a thorough investigation of the questions listed above. Related Works. We start with a popular method following the CTA protocol, the FedAvg in Algorithm 1, which covers the original FedAvg [1], the Local SGD [4], PR-SGD [13,3] and the RI-SGD [14] among others. In FedAvg, T is the total stage number, Q the number of local updates, r the index of the stage, q the index of the inner iteration, and \u03b7 r,q 's are the stepsizes. It has two options for local updates:\n\nOption 1: Sample \u03be r,q i form D i , Set x r,q+1 i x r,q i \u2212 \u03b7 r,q \u2207F (x r,q i ; \u03be r,q i ).\n\nOption 2 : x r,q+1 i x r,q i \u2212 \u03b7 r,q \u2207f i (x r,q i ).  (LC), and number of accessed sample (AS), before reaching -stationary solution. DN refers to degree of non-i.i.d, BG refers to bounded gradient, NC is non-convex, \u00b5SC means \u00b5-Strongly Convex. p is the function of O( \u03b4 2 ) illustrated in Fig. 1. The i.i.d. assumption of FedProx is described in (5); VRL-SGD needs assumption of bounded variance of the stochastic gradient, which in our finite sum setting implies the BG.\n\n\nAlgorithm\n\nConvexity DN BG RC (T ) LC (QT ) AS FedAvg [4] \u00b5SC 0 [9] \u00b5SC\nNo O 1/ 1/2 O(1/ ) O(1/ ) FedAvg- Yes O (1/ ) O(1/ ) O(1/ ) Coop-SGD [5] NC 0 No O(1/ ) O(1/ 2 ) O(1/ 2 ) MPR-SGD [3] NC - Yes O(1/ 3/2 ) O(1/ 2 ) O(1/ 2 ) Local-GD [15] C - No O(1/ 3/2 ) O(1/ 2 ) O(M/ 2 ) FedProx [12] NC - No O(1/ ) O(1/ 2 ) O(1/ 2 ) F-SVRG[17] NC - No O(1/ ) O(Q/ ) O(M/ + Q/ ) VRL-SGD[16] NC - Yes O(1/ ) O(1/ 2 ) O(1/ 2 ) Fed-PD-GD NC \u03b4 > 0 No O ((1 \u2212 p)/ ) O (log(1/ )/ ) O(M log(1/ )/ ) Fed-PD-SGD NC \u03b4 > 0 No O((1 \u2212 p)/ ) O(1/ 2 ) O(1/ 2 ) Fed-PD-VR NC - No O(1/ ) O(Q/ ) O(M + \u221a M / )\nMany recent works are extensions of FedAvg. The algorithm proposed in [3] adds momentum to the algorithm. In [14], the data on the local agents are separated into blocks and shared with other agents. In [15] the local GD version (9) is studied. In [5], a cooperative-SGD is considered; it includes virtual agents, extra variables, and relaxes the parameter server topology.\n\nIt is pertinent to consider how these algorithms address questions Q1-Q4. For Q1, most FedAvg-type algorithms perform multiple local (stochastic) GD steps to minimize the local loss function. However, we will see shortly that in many cases, successive local GD steps lead to algorithm divergence. For Q2, most algorithms use simple averaging, and there is little discussion on whether other types of (linear) processing will be helpful. For Q3, a number of recent works such as [3,15] show that, for non-convex problems, to achieve -solution (7), a total of O(1/ 3/2 ) aggregation steps are needed. However, it is not clear if this achieves the best communication complexity. As for Q4, the FedAvg-type algorithm typically requires either some variant of the BG assumption, or some i.i.d. assumption, or both; See Table 1 rows 1-5 for  detailed discussions. A number of more recent works have improved upon FedAvg in various aspects. FedProx [12] addresses Q1 and Q4 by perturbing the update direction. This algorithm does not need the BG, but it still requires the i.i.d. assumption (5). The VRL-SGD proposed in [16] addresses Q1 and Q4 by using the variance reduction (VR) technique to update the directions for local agents and achieves O(1/ ) communication complexity without the i.i.d. assumption. F-SVRG [17] is another recent algorithm that uses VR. This algorithm does not follow the CTA protocol as the agents have to transmit the local gradients, but it does not require A3 and A4. The PR-SPIDER [18] further improves upon FSVRG by reducing sample complexity (SC) from O(M/ ) to O( \u221a M / ) (where M is typically larger than 1/ ). Although FSVRG and PR-SPIDER neither require the BG or the i.i.d. assumptions, they require the agents to transmit local gradients to the server and thus do not follow the CTA protocol. This is undesirable, as it has been shown that local gradient information can leak private data [19]. Additionally, questions Q2-Q3 are not addressed in these works. Our Main Contributions. First, we address Q1-Q4 and provide an in-depth examination of the CTA protocol. We show that algorithms following the CTA protocol that are based on successive local gradient updates, the best possible communication efficiency is O(1/ ); neither additional local processing nor general linear processing can improve this rate. We then show that the BG and/or i.i.d. data assumption is important for the popular FedAvg to work as intended.\n\nOur investigation suggests that the existing FedAvg-based algorithms are (provably) insufficient in dealing with many practical problems, calling for a new design strategy. We then propose a meta-algorithm called Federated Primal-Dual (FedPD), which also follows the CTA protocol and can be implemented in several different forms with desirable properties. In particular, it i) can deal with the general non-convex problem, ii) achieve the best possible optimization and communication complexity when data is non-i.i.d., iii) achieve convergence under only Assumptions A1-A2. savings, accuracy , heterogeneity \u03b4; Fixing , when the data is heterogeneous (left) the curve is linear, while the data is homogeneous (right) the curve is logarithmic. Details in Sec. 3.2. Most importantly, the communication pattern of the proposed algorithm can be adapted to the degree of non-i.i.d.-ness of the local data. That is, we show that under the \u03b4-non-i.i.d. condition (6), communication saving and data heterogeneity interestingly exhibit a linear-logarithmic relationship; see Fig. 1 for an illustration. To our knowledge, this is the first algorithm for FL that achieves all the above properties.\n\n\nAddressing Open Questions\n\nWe first address Q2-Q3. Specifically, for problems satisfying A1-A2, does performing multiple local updates or using different ways to combine local models reduce communication complexity? We show that such a saving is impossible; there exist problems satisfying A1-A2, yet no matter what types of linear combinations the server performs, as long as the agents use local gradients to update the model, it takes at least O(1/ ) communication rounds to achieve an -stationary solution (7). Consider the following generic CTA protocol. Let t denote the index for communication rounds. Between two rounds t \u2212 1 and t, each agent performs Q local updates. Denote x t\u22121,q i to be the q-th local update. Then, x t\u22121,Q i 's are sent to the server, combined through a (possibly time-varying) function V t (\u00b7) : R N d \u2192 R d , and sent back. The agents then generate a new iterate, by combining the received message with past gradients using a (possibly time-varying) function W t i (\u00b7):\nx t = V t ({x t\u22121,Q i } N i=1 ), x t,0 i = x t , \u2200 i \u2208 [N ],(10a)x t,q i \u2208W t i {x r,k i , {\u2207F (x r,q i ; \u03be i )} \u03be i \u2208D i } k\u2208[q\u22121],r\u2208[t] , \u2200 q \u2208 [Q], \u2200 i \u2208 [N ].(10b)\n\nThe Proposed Algorithm\n\nOur algorithm is based on the following global consensus reformulation of the original problem (1):\nmin x 0 ,x i 1 N N i=1 f i (x i ), s.t. x i = x 0 , \u2200i \u2208 [N ].(11)\nSimilar to traditional primal-dual based algorithms [24], the idea is that, when relaxing the equality constraints, the resulting problem is separable across different nodes. However, different from ADMM, the agents can now perform either a single (or multiple) local update(s) between two communication rounds. Importantly, such flexibility makes it possible to adapt the communication frequency to the degree of \u03b4-non-i.i.d.-ness of the local data. In particular, we identify that under \u03b4-non-i.i.d. (4), the fraction /\u03b4 2 is the key quantity that determines communication saving; see Fig. 1. Intuitively, significant reduction can be achieved when \u03b4 is smaller than ; otherwise, the reduction goes to zero linearly as \u03b4 increases. To our knowledge, none of the existing ADMM based algorithms, nor FL based algorithms, are able to provably achieve such a reduction.\n\nTo present our algorithm, let us define the augmented Lagrangian (AL) function of (11) as\nL(x 0:N , \u03bb) 1 N N i=1 L i (x 0 , x i , \u03bb i ), L i (x i , x 0 , \u03bb i ) f i (x i ) + \u03bb i , x i \u2212 x 0 + 1 2\u03b7 x i \u2212 x 0 2 . Fixing x 0 , the AL is separable over all local pairs {(x i , \u03bb i )}.\nThe key technique in the design is to specify how each local AL L i (\u00b7) should be optimized, and when to perform model aggregation. Federated primal-dual algorithm (FedPD) captures the main idea of the classical primal-dual based algorithm while meeting the flexibility need of FL; see Algorithm 2. In particular, its update rules share a similar pattern as ADMM, but it does not specify how the local models are updated. Instead, an oracle Oracle i (\u00b7) is used as a placeholder for local processing, and we will see that careful instantiations of these oracles lead to algorithms with different properties. Importantly, we introduce a critical constant p \u2208 [0, 1), which determines the frequency at which the aggregation and communication steps are skipped. In Algorithm 3 and Algorithm 4, we provide two useful examples of the local oracles.\n\nIn Algorithm 3, Q i 's are chosen so that the local problems are solved accurately enough to satisfy:\n\u2207 x i L(x r+1 i , x r 0,i , \u03bb r i ) 2 \u2264 1 .(12)\nWe provide two ways for solving this subproblem by using GD and SGD, but any other solver that achieves (12) can be used. For the SGD version, the stochastic gradient is defined as\nh i (x r,q i ; \u03be r,q i ) \u2207F (x r,q i ; \u03be r,q i ), with \u03be r,q i \u223c D i ,(13)\nwhere \u223c denotes uniform sampling. Despite the simplicity of the local updates, we will show that using Oracle I makes FedPD adaptive to the non-i.i.d. parameter \u03b4.\n\nIn Algorithm 4, the oracle applies the variance reduction technique to reduce the sample complexity. The detailed descriptions and the analyses are given in Appendix G due to the space limitation.\n\n\nConvergence and Complexity Analysis\n\nWe analyze the convergence of FedPD with Oracle I. The detailed proofs are given in Appendix F. The convergence analysis of FedPD with an alternative Oracle is given in Appendix G\n\n\nAlgorithm 2 Federated Primal-Dual Algorithm\n\nInput: x 0 , \u03b7, p, T, Q 1 , . . . , Q N Initialize: x 0 0 = x 0 , for r = 0, . . . , T \u2212 1 do for i = 1, . . . , N in parallel do Local Updates:\nx r+1 i = Oracle i (L i (x r i , x r 0,i , \u03bb r i ), Q i ) \u03bb r+1 i = \u03bb r i + 1 \u03b7 (x r+1 i \u2212 x r 0,i ) x r+ 0,i = x r+1 i + \u03b7\u03bb r+1 i end for\nWith probability 1 \u2212 p: Global Communicate: \nx r+1 0 = 1 N N i=1 x r+ 0,i x r+1 0,i = x r+1 0 , i = 1, . . . , N With probability p: Local Update: x r+1 0,i x r+ 0,i end for Algorithm 3 Oracle Choice I Input: L i (x r i , x r 0,i , \u03bb r i ), Q i Initialize: x r i,0 = x r i , Option I (GD) for q = 0, . . . , Q i \u2212 1 do x r,q+1 i = x r,q i \u2212 \u03b7 1 \u2207 xi L(x r,q i , x r 0,i , \u03bb r i ) end for Option II (SGD) for q = 0, . . . , Q i \u2212 1 do x r,q+1 i = x r,q i \u2212 \u03b7 1 (h i (x r,q i ; \u03be r,q i ) + \u03bb r i + 1 \u03b7 (x r,q i \u2212 x r 0,i ))1 T T r=0 \u2207f (x r 0 ) 2 \u2264 C 2 T D 0 + C 4 1 , with D 0 := f (x 0 0 ) \u2212 f (x ). Case II) Suppose 0 < \u03b7 < \u221a 5\u22121 4L\n, 0 \u2264 p < 1, and A5 holds with a finite \u03b4. Then we have:\n1 T T r=0 E \u2207f (x r 0 ) 2 \u2264 C 2 T D 0 + \u03b7(N \u2212 1)C 5 (1 \u2212 C 1/(1\u2212p) 3 ) 2 p(p 2 (3 + L\u03b7) 2 + 4) N (1 \u2212 2L\u03b7 \u2212 p(1 + L\u03b7)) 2 (\u03b4 2 + 1 ) + C 4 1 .(14)\nHere C 2 , C 4 , C 5 > 0 are constants independent of T, \u03b4, p; C 3 := p(1+L\u03b7)+L\u03b7\n1\u2212L\u03b7 \u2265 0.\nRemark 3. (Communication complexity) Case I says if one does not skip communication (p = 0), then to achieve -stationarity (i.e., \u2207f (x t 0 ) 2 \u2264 for some r \u2208 (1, T )), they need to set T = 1/(2C 2 D 0 ), In Case II, the second term on the right hand side of (14) involves both \u03b4 and p, so we can select them appropriately to reduce communication while maintaining the same accuracy. Specifically, we choose 1 = min{ /(4C 4 ), \u03b4 2 } and T = 1/(2C 2 D 0 ). Then we have\nC(p) \u03b7 (1 \u2212 C 1/(1\u2212p) 3 ) 2 p(p 2 (3 + L\u03b7) 2 + 4) (1 \u2212 2L\u03b7 \u2212 p(1 + L\u03b7)) 2 \u2264 3\u03b4 2 .\nThen we can achieve the same -accuracy as Case I. The communication rounds here is T (1 \u2212 p).\n\nThe relation between the saving p and \u03b4 2 is showed in Table 2. Roughly speaking, p is inversely proportional to degree of non-i.i.d-ness \u03b4 2 when \u03b4 2 \u2208 (O( ), \u221e); further, p \u2192 1 at a log-rate when \u03b4 2 \u2192 0. Our result also indicates that, when using stage-wise training for neural networks, the algorithm can communicate less at the early stages since they typically have lower accuracy target to enable larger stepsizes [25]. \nwith fixed \u03b7 = \u221a 5\u22121 8L . Range of p C 3 C(p) p as function of \u03b4 2 Relation [0, 1\u22122L\u03b7 1+L\u03b7 ) < 1 \u2248 12\u03b7p 1 36\u03b7 \u03b4 2 Linear [ 1\u22122L\u03b7 1+L\u03b7 , 1) \u2265 1 \u2248 14\u03b7C 2/(1\u2212p) 3 1 \u2212 2/ log( 1 42\u03b7 \u03b4 2 ) Log\nRemark 4. (Computation complexity) To achieve accuracy, we need both T = O(1/ ) and\n1 = O( ).\nAs the local AL is strongly convex with respect to x i , optimizing it to accuracy requires O(log( )) iterations for GD and O(1/ ) for SGD [26]. So the total number of times that the local gradients (respectively, stochastic gradients) are accessed is given by O(1/ \u00d7 log(1/ )) (respectively, O(1/ 2 )). We conclude this section by noting that the above communication and computation complexity results we have obtained are the best so far among all FL algorithms for non-convex problems satisfying A1 -A2. Please see the last three rows of Table 1 for a summary of the results.\n\n\nConnection with Other Algorithms\n\nBefore we close this section, we discuss the relation of FedPD with a few existing algorithms. The FedProx/FedDANE In FedProx [12] the agents optimize the following local objective:  [27] also proposes a way of designing the subproblem by using the global gradient, but this violates the CTA protocol. Compared with these two algorithms, the proposed FedPD has weaker assumptions, and it achieves better sample and/or communication complexity. Event Triggering Algorithms. A number of recent works such as Lazily Aggregated Gradient (LAG) [28] and COLA [29] have been proposed to occasionally skip message exchanges among the agents to save communication. In LAG, each agent receives the global model every iteration, and decides whether to send some local gradient differences by checking certain conditions. Since gradient information is transmitted, LAG does not belong to the algorithm class (10). When the local problems are unbalanced, in the sense that the discrepancy between the local Lipschitz gradients L i 's is large, then the agents with smaller L i 's can benefit from the lazy aggregation. Meanwhile, instead of measuring whether the local problems are balanced, the \u03b4-non-i.i.d. criteria characterizes if local problems are similar by measuring the uniform difference between arbitrary pairs of the local problems. If the data is i.i.d., then the agents benefit equally from the communication reduction.  \nf i (x i ) + \u03c1 2 x i \u2212 x r\n\nNumerical Experiments\n\nIn the first experiment, we show the convergence of the proposed algorithms on synthetic data with FedAvg and FedProx as baselines. We use the non-convex penalized logistic regression [30] as the loss function. We use two ways to generate the dataset, in the first case (referred to as the \"weakly non-i.i.d\" case), the data is generated in an i.i.d. way. In the second case (referred to as the \"strongly non-i.i.d\" case), we generate the data using non-i.i.d. distribution. In both cases there are 400 samples on each agent with total 100 agents.\n\nWe run FedPD with Oracle I (FedPD-SGD and FedPD-GD) and Oracle II (FedPD-VR). For FedPD-SGD, we set Q = 600, and for FedPD-GD and FedPD-VR we set Q = 8. For FedPD-GD we set p = 0 and p = 0.5, wherein the later case the agents skips half of the communication rounds. For FedPD-VR, we set mini-batch size B = 1 and gradient computation frequency I = 20. For comparison, we also run FedAvg with local GD/SGD and FedProx. For FedAvg with GD, Q = 8, and for FedAvg with SGD, Q = 600. For FedProx, we solve the local problem using variance reduction for Q = 8 iterations. The total number of iterations T is set as 600 for all algorithms. Fig. 2 shows the results with respect to the number of communication rounds. In Fig. 2(a), we compare the convergence of the tested algorithms on weakly non-i.i.d. data set. It is clear that FedProx and FedPD with p = 0 (i.e., no communication skipping) are comparable. Meanwhile, FedAvg with local GD will not converge to the stationary point with a constant stepsize when local update step Q > 1. By skipping half of the communication, FedPD with local GD can still achieve a similar error as FedAvg, but using fewer communication rounds. In Fig. 2(b), we compare the convergence results of different algorithms with the strongly non-i.i.d. data set. We can see that the algorithms using stochastic solvers become less stable compared with the case when the data sets are weakly non-i.i.d. Further, FedPD-VR and FedPD-GD with p = 0 are able still to converge to the global stationary point while FedProx will achieve a similar error as the FedAvg with local GD.\n\nWe included more details on the experimental results and additional experiments in Appendix H.\n\n\nConclusion\n\nWe study federated learning under the CTA protocol. We explore a number of theoretical properties of this protocol, and design a meta-algorithm called FedPD, which contains various algorithms with desirable properties, such achieving the best communication/computation complexity, as being able to adapt its communication pattern with data heterogeneity.\n\n\nA Examples of Cost Functions Satisfy A5\n\nIn this part, we provide a commonly used function that satisfies A5.\n\n\nLogistic Regression\n\nConsider the case where the k th sample \u03be i,k in data set D i consist of a feature vector a k and a scalar label b k . The feature vector a k has the same length as x and b k is a scalar in R. Then the loss function of a logistic regression problem is expressed as\nf i (x) = 1 |D i | (a k ,b k )\u2208D i 1 1 + exp(b k \u2212 a T k x) .(15)\nThe gradient of this loss function is\n\u2207f i (x) = 1 |D i | (a k ,b k )\u2208D i a k exp(b k \u2212 a T k x) (1 + exp(b k \u2212 a T k x)) 2 .(16)\nDefine the scalar\nexp(b k \u2212a T k x) (1+exp(b k \u2212a T k x)) 2 as v(a k , b k , x), we have v(a k , b k , x) \u2208 (0, 1), \u2200x, a k , b k . Further stack v(a k , b k , x) as v(D i , x), that is v(D i , x) = [v(a 1 , b 1 , x); . . . , ; v(a |D i | , b |D i | , x)]. Further we define A i as the stacked matrix of all a k \u2208 D i (i.e., A i = [a 1 , . . . , a |D i | ]), then we can express \u2207f i (x) as \u2207f i (x) = 1 |D i | A i v(D i , x).(17)\nThe difference between the gradients of f i and f j is\n\u2207f i (x) \u2212 \u2207f j (x) = 1 |D i | A i v(D i , x) \u2212 1 |D j | A j v(D j , x) \u2264 1 |D i | A i v(D i , x) + 1 |D j | A j v(D j , x) .(18)\nAs\nv(a, b, x) \u2208 (0, 1), we know v(D i , x) \u2264 [1, . . . , 1] = |D i |, which implies: A i \u2265 A i v(D i , x) v(D i , x) \u2265 A i v(D i , x) |D i | .\nUtilizing the above inequality in (18), we obtain:\n\u2207f i (x) \u2212 \u2207f j (x) \u2264 1 |D i | A i v(D i , x) + 1 |D j | A j v(D j , x) \u2264 1 |D i | A i + 1 |D j | A j .(19)\nSo we can define \u03b4 = max i,j\n1 \u221a |D i | A i + 1 \u221a |D j |\nA j which is a finite constant. Note that the above analysis holds true for any D i and x. Note that with finer analysis we can obtain better bounds for \u03b4.\n\n\nHyperbolic Tangent\n\nSimilar to logistic regression, we can also show that A5 holds for hyperbolic tangent function which is commonly used in neural network models. First, notice that the hyperbolic tangent is a rescaled version of logistic regression:\ntanh(b k \u2212 a T k x) = exp(b k \u2212 a T k x) \u2212 exp(a T k x \u2212 b k ) exp(b k \u2212 a T k x) + exp(a T k x \u2212 b k ) = 2 1 + exp(2(b k \u2212 a T k x)) \u2212 1,\nTherefore we have\n\u2207 x tanh(b k \u2212 a T k x) = 4\u2207 x 1 1 + exp(2(b k \u2212 a T k x))\n.\n\nSo, \u03b4 for tanh is 4 times that applicable to the logistic regression problem. Note that this analysis can further cover a wide range of neural network training problems that uses cross entropy loss and sigmoidal activation functions (e.g. MLP, CNN and RNN).\n\n\nSpecial Case in Linear Regression\n\nConsider the linear regression problem\nf i (x) = 1 2 A i x + b i 2 , i = 1, . . . , N.\nWe have\n\u2207f i (x) = A T i A i x + A T i b i . Then if the feature A i 's satisfy A T i A i = A T j A j , \u2200 i = j, we have \u03b4 = max i,j A T i b i \u2212 A T j b j .\n\nB Proof of Claim 2.1\n\nThe proof is related to techniques developed in classical and recent works that characterize lower bounds for first-order methods in centralized [20,21] and decentralized [22,23] settings. Technically, our computational / communication model is different compared to the aforementioned works, since we allow arbitrary number of local processing iterations, and we have a central aggregator. The difference here is that our goal is not to show the lower bounds on the number of total (centralized) gradient access, nor to show the optimal graph dependency. The main point we would like to make is that there exist constructions of local functions f i 's such that no matter how many times that local first-order processing is performed, without communication and aggregation, no significant progress can be made in reducing the stationarity gap of the original problem.\n\nFor notational simplicity, we will assume that the full local gradients {\u2207f i (x k i )} can be evaluated. Later we will comment on how to extend this result to enable access to the sample gradients \u2207F (x k i ; \u03be i ). In particular, we consider the following slightly simplified model for now:\nx t = V t ({x t\u22121,Q i } N i=1 ), x t,0 i = x t , \u2200 i \u2208 [N ],(20a)x t,q i \u2208 W t i {x r,k i , \u2207f i (x r,k i )} k=0:q\u22121 r=0:t , q \u2208 [Q], \u2200 i. (20b) B.1 Notation.\nIn this section, we will call each t a \"stage,\" and call each local iteration q an \"iteration.\" We use x to denote the variable located at the server. We use x i (and sometimes x q ) to denote the local variable at node i, and use x i [j] and x i [k] to denote its jth and kth elements, respectively. We use g i (\u00b7) and f i (\u00b7) to denote some functions related to node i, and g(\u00b7) and f (\u00b7) to denote the average functions of g i 's and f i 's, respectively. We use N to denote the total number of nodes.\n\n\nB.2 Main Constructions.\n\nSuppose there are N distributed nodes in the system, and they can all communicate with the server. To begin, we construct the following two non-convex functions\ng(x) := 1 N N i=1 g i (x), f (x) := 1 N N i=1 f i (x).(21)\nHere we have x \u2208 R T +1 . We assume N is constant, and T is the total number of stages (a large number and one that can potentially increase). For notational simplicity, and without loss of generality, we assume that T \u2265 N , and it is divisible by N . Let us define the component functions g i 's in (21) as follows.\ng i (x) = \u0398(x, 1) + T /N j=1 \u0398(x, (j \u2212 1)N + i + 1),(22)\nwhere we have defined the following functions\n\u0398(x, j) := \u03a8(\u2212x[j \u2212 1])\u03a6(\u2212x[j]) \u2212 \u03a8(x[j \u2212 1])\u03a6(x[j]), \u2200 j = 2, \u00b7 \u00b7 \u00b7 , T + 1, \u0398(x, 1) := \u2212\u03a8(1)\u03a6(x[1]). (23a) Clearly, each \u0398(x, j) is only related to two components in x, i.e., x[j \u2212 1] and x[j].\nThe component functions \u03a8, \u03a6 : R \u2192 R are given as below\n\u03a8(w) := 0 w \u2264 0 1 \u2212 e \u2212w 2 w > 0, \u03a6(w) := 4 arctan w + 2\u03c0.\nBy the above definition, the average function becomes:\ng(x) := 1 M M j=1 g i (x) = \u0398(x, 1) + T +1 j=2 \u0398(x, j)(24)= \u2212\u03a8(1)\u03a6 (x[1]) + T +1 j=2 [\u03a8 (\u2212x[j \u2212 1]) \u03a6 (\u2212x[j]) \u2212 \u03a8 (x[j \u2212 1]) \u03a6 (x[j])] .\nSee Fig. 3 for an illustration of the construction discussed above. Further, for a given error constant > 0 and a given the Lipschitz constant L, let us define Therefore, we also have\nf i (x) := 2\u03c0 L g i xL \u03c0 \u221a 2 .(25)f (x) := 1 N N i=1 f i (x) = 2\u03c0 L g xL \u03c0 \u221a 2 .(26)\nB.3 Properties.\n\nFirst we present some properties of the component functions h i 's.\nLemma 1.\nThe functions \u03a8 and \u03a6 satisfy the following:\n\n1. For all w \u2264 0, \u03a8(w) = 0, \u03a8 (w) = 0.\n\n2. The following bounds hold for the functions and their first-and second-order derivatives:\n0 \u2264 \u03a8(w) < 1, 0 \u2264 \u03a8 (w) \u2264 2 e , \u2212 4 e 3 2 \u2264 \u03a8 (w) \u2264 2, \u2200w > 0. 0 < \u03a6(w) < 4\u03c0, 0 < \u03a6 (w) \u2264 4, \u2212 3 \u221a 3 2 \u2264 \u03a6 (w) \u2264 3 \u221a 3 2\n, \u2200w \u2208 R.\n\n3. The following key property holds:\n\u03a8(w)\u03a6 (v) > 1, \u2200 w \u2265 1, |v| < 1.(27)\n4. The function h is lower bounded as follows:\ng i (0) \u2212 inf x g i (x) \u2264 5\u03c0T /N , g(0) \u2212 inf x g(x) \u2264 5\u03c0T /N . 5. The first-order derivative of g (respectively, g i ) is Lipschitz continuous with constant = 27\u03c0 (respectively, i = 27\u03c0, \u2200 i).\nProof. Property 1) is easy to check.\n\nTo prove Property 2), note that following holds for w > 0: , \u03a8 (0 + ) = 2, i.e.,\n\u03a8(w) = 1 \u2212 e \u2212w 2 , \u03a8 (w) = 2e \u2212w 2 w, \u03a8 (w) = 2e \u2212w 2 \u2212 4e \u2212w 2 w 2 , \u2200 w > 0.(28)0 \u2264 \u03a8(w) < 1, 0 \u2264 \u03a8 (w) \u2264 2 e , \u2212 4 e 3 2 \u2264 \u03a8 (w) \u2264 2, \u2200w > 0.\nFurther, for all w \u2208 R, the following holds:\n\u03a6(w) = 4 arctan w + 2\u03c0, \u03a6 (w) = 4 w 2 + 1 , \u03a6 (w) = \u2212 8w (w 2 + 1) 2 .(29)\nSimilarly, as above, we can obtain the following bounds:\n0 < \u03a6(w) < 4\u03c0, 0 < \u03a6 (w) \u2264 4, \u2212 3 \u221a 3 2 \u2264 \u03a6 (w) \u2264 3 \u221a 3 2 , \u2200w \u2208 R.\nTo show Property 3), note that for all w \u2265 1 and |v| < 1,\n\u03a8(w)\u03a6 (v) > \u03a8(1)\u03a6 (1) = 2(1 \u2212 e \u22121 ) > 1\nwhere the first inequality is true because \u03a8(w) is strictly increasing and \u03a6 (v) is strictly decreasing for all w > 0 and v > 0, and that \u03a6 (v) = \u03a6 (|v|).\n\nNext we show Property 4). Note that 0 \u2264 \u03a8(w) < 1 and 0 < \u03a6(w) < 4\u03c0. Therefore we have g(0) = \u2212\u03a8(1)\u03a6(0) < 0 and using the construction in (22) \ninf x g i (x) \u2265 \u2212\u03a8(1)\u03a6(x[1]) \u2212 T /N j=1 sup w,v \u03a8(w)\u03a6(v) (30) \u2265 \u22124\u03c0 \u2212 4(T /N )\u03c0 \u2265 \u22125\u03c0T /N ,(31)\nwhere the first inequality follows from \u03a8(w)\u03a6(v) > 0, the second follows from \u03a8(w)\u03a6(v) < 4\u03c0, and the last is true because T /N \u2265 1. Finally, we show Property 5), using the fact that a function is Lipschitz if it is piecewise smooth with bounded derivative. Before proceeding, let us note a few properties of the construction in (24) (also see Fig. 3). First, for a given node q, its local function h q is only related to the following x[j]'s\nj = 1 + q + \u00d7 N \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , (N \u2212 1), j = q + \u00d7 N \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , (N \u2212 1), or equivalently q = j \u2212 1 \u2212 \u00d7 N \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , (N \u2212 1), q = j \u2212 \u00d7 N \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , (N \u2212 1).\nThen the first-order partial derivative of g q (y) can be expressed below.\nCase I) If j = 1 we have \u2202g q \u2202x[j] = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 (\u2212\u03a8 (\u2212x[j \u2212 1]) \u03a6 (\u2212x[j]) \u2212 \u03a8 (x[j \u2212 1]) \u03a6 (x[j])) , q = j \u2212 1 \u2212 N ( ) \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , T N \u2212 1, j = 2, 3, \u00b7 \u00b7 \u00b7 , T + 1 (\u2212\u03a8 (\u2212x[j]) \u03a6 (\u2212x[j + 1]) \u2212 \u03a8 (x[j]) \u03a6 (x[j + 1])) , q = j \u2212 N ( ) \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , T N \u2212 1, j = 3, 4, \u00b7 \u00b7 \u00b7 T 0 otherwise. .(32)\nCase II) If j = 1, we have\n\u2202g q \u2202x[1] = \u2212\u03a8(1)\u03a6 (x[1]) + (\u2212\u03a8 (\u2212x[1]) \u03a6 (\u2212x[2]) \u2212 \u03a8 (x[1]) \u03a6 (x[2])) , q = 1 \u2212\u03a8(1)\u03a6 (x[1]), q = 1 .(33)\nFrom the above derivation, it is clear that for any j, q, \u2202gq \u2202x[j] is either zero or is a piecewise smooth function separated at the non-differentiable point\nx[j] = 0, because the function \u03a8 (\u00b7) is not differentiable at 0. Further, fix a point x \u2208 R T +1 and a unit vector v \u2208 R T +1 where T +1 j=1 v[j] 2 = 1. Define q (\u03b8; x, v) := g q (x + \u03b8v)\nto be the directional projection of g q on to the direction v at point x. We will show that there exists C > 0 such that | q (0; x, v)| \u2264 C for all x = 0 (where the second-order derivative is taken with respect to \u03b8).\n\nFirst, by noting the fact that each if x[j] appears in g q (x), then it must also be coupled with either\nx[j+1] or x[j \u22121], but not other x[k]'s for k = j \u22121, j +1. This means that \u2202 2 gq(x) \u2202x[j 1 ]\u2202x[j 2 ] = 0, \u2200 j 2 = {j 1 , j 1 +1, j 1 \u22121}.\nUsing this fact, we can compute q (0; x, v) as follows:\nq (0; x, v) = T j 1 ,j 2 =1 \u2202 2 g q (x) \u2202x[j 1 ]\u2202x[j 2 ] v[j 1 ]v[i 2 ] = \u03b4\u2208{0,1,\u22121} T j=1 \u2202 2 g q (x) \u2202x[j]\u2202x[j + \u03b4] v[j]v[j + \u03b4],\nwhere we take v[0] := 0 and v[T + 1] := 0. By using (32) and the above facts, the second-order partial derivative of g q (x) (\u2200x = 0) is given as follows when j = 1:\n\u2202 2 g q \u2202x[j]\u2202x[j] = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 (\u03a8 (\u2212x[j \u2212 1]) \u03a6 (\u2212x[j]) \u2212 \u03a8 (x[j \u2212 1]) \u03a6 (x[j])) , q = j \u2212 1 \u2212 N ( ) \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , T N \u2212 1, j = 2, 3, \u00b7 \u00b7 \u00b7 , T + 1 (\u03a8 (\u2212x[j]) \u03a6 (\u2212x[j + 1]) \u2212 \u03a8 (x[j]) \u03a6 (x[j + 1])) , q = j \u2212 N ( ) \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , T N \u2212 1, j = 3, 4, \u00b7 \u00b7 \u00b7 , T 0, otherwise (34) \u2202 2 g q \u2202x[j]\u2202x[j + 1] = \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 (\u03a8 (\u2212x[j]) \u03a6 (\u2212x[j + 1]) \u2212 \u03a8 (x[j]) \u03a6 (x[j + 1])) , q = j \u2212 N ( ) \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , T N \u2212 1, j = 3, 4, \u00b7 \u00b7 \u00b7 , T 0, otherwise(35)\u2202 2 g q \u2202x[j]\u2202x[j \u2212 1] = \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 (\u03a8 (\u2212x[j \u2212 1]) \u03a6 (\u2212x[j]) \u2212 \u03a8 (x[j \u2212 1]) \u03a6 (x[j])) , q = j \u2212 N ( ) \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , T N \u2212 1, j = 2, 3, \u00b7 \u00b7 \u00b7 , T + 1 0, otherwise .(36)By applying Lemma 1 -i) [i.e., \u03a8(w) = \u03a8 (w) = \u03a8 (w) = 0 for \u2200 w \u2264 0], we can obtain that at least one of the terms \u03a8 (\u2212x[j \u2212 1]) \u03a6 (\u2212x[j]) or \u2212\u03a8 (x[j \u2212 1]) \u03a6 (x[j]) is zero. It follows that \u03a8 (\u2212x[j \u2212 1]) \u03a6 (\u2212x[j]) \u2212 \u03a8 (x[j \u2212 1]) \u03a6 (x[j]) \u2264 sup w |\u03a8(w)| sup v |\u03a6 (v)|.\nTaking the maximum over equations (34) to (36) and plug in the above inequalities, we obtain\n\u2202 2 g q \u2202x[j 1 ]\u2202x[j 2 ] \u2264 max{sup w |\u03a8 (w)| sup v |\u03a6(v)|, sup w |\u03a8(w)| sup v |\u03a6 (v)|, sup w |\u03a8 (w)| sup v |\u03a6 (v)|} = max 8\u03c0, 3 \u221a 3 2 , 4 2 e < 8\u03c0, \u2200 j 1 = 1,\nwhere the equality comes from Lemma 1 -ii). When j = 1, by using (33), we have the following:\n\u2202 2 g q (x) \u2202x[1]\u2202x[1] = \u2212\u03a8(1)\u03a6 (x[1]) + (\u2212\u03a8 (\u2212x[1]) \u03a6 (\u2212x[2]) \u2212 \u03a8 (x[1]) \u03a6 (x[2])) , q = 1 \u2212\u03a8(1)\u03a6 (x[1]), otherwise , \u2202 2 g q (x) \u2202x[1]\u2202x[2] = (\u2212\u03a8 (\u2212x[1]) \u03a6 (\u2212x[2]) \u2212 \u03a8 (x[1]) \u03a6 (x[2])) , q = 1 0, otherwise .\nAgain by applying Lemma 1 -i) and ii),\n\u2202 2 g q (x) \u2202x[1]\u2202x[j 2 ] \u2264 max{sup w |\u03a8(1)\u03a6 (w)| + sup w |\u03a8 (w)| sup v |\u03a6(v)|, sup w |\u03a8 (w)| sup v |\u03a6 (v)|} = max 3 \u221a 3 2 (1 \u2212 e \u22121 ) + 8\u03c0, 4 2 e < 9\u03c0, \u2200 j 2 .\nSummarizing the above results, we obtain:\n| q (0; x, v) | = | \u03b4\u2208{0,1,\u22121} T j=1 \u2202 2 g q (y) \u2202x[j]\u2202x[j + \u03b4] v[j]v[j + \u03b4]| \u2264 9\u03c0 \u03b4\u2208{0,1,\u22121} | T j=1 v[j]v[j + \u03b4]| \u2264 9\u03c0 \uf8eb \uf8ed | T j=1 v[j] 2 | + 2| T j=1 v[j]v[j + 1]| \uf8f6 \uf8f8 \u2264 27\u03c0 T j=1 |v[j] 2 | = 27\u03c0.\nOverall, the first-order derivatives of h q are Lipsschitz continuous for any q with constant at most = 27\u03c0.\n\nThe following lemma is a simple extension of the previous result.\n\nLemma 2. We have the following properties for the functions f defined in (26) and (25):\n1. We have \u2200 x \u2208 R T +1 f (0) \u2212 inf x f (x) \u2264 10\u03c0 2 LN T. 2. We have \u2207f (x) = \u221a 2 \u2207g xL \u03c0 \u221a 2 , \u2200 x \u2208 R T +1 .(37)\n3. The first-order derivatives of f and that for each f i , i \u2208 [N ] are Lipschitz continuous, with the same constant U > 0.\n\nProof. To show that property 1) is true, note that we have the following:\nf (0) \u2212 inf x f (x) = 2\u03c0 L g(0) \u2212 inf x g(x) .\nThen by applying Lemma 1 we have that for any T \u2265 1, the following holds\nf (0) \u2212 inf x f (x) \u2264 2\u03c0 L \u00d7 5\u03c0T N .\nProperty 2) is true is due to the definition of f i , so that we have:\n\u2207f i (x) = \u221a 2 \u00d7 \u2207g i xL \u03c0 \u221a 2 .\nProperty 3) is true because the following:\n\u2207f (z) \u2212 \u2207f (y) = \u221a 2 \u2207g zU \u03c0 \u221a 2 \u2212 \u2207g yU \u03c0 \u221a 2 \u2264 U z \u2212 y\nwhere the last inequality comes from . This completes the proof. Next let us analyze the size of \u2207g. We have the following result.\nLemma 3. If there exists k \u2208 [T ] such that |x[k]| < 1, then \u2207g(x) = 1 N N i=1 \u2207g i (x) \u2265 1 N N i=1 \u2202g i (x) \u2202x[k] > 1/N.\nProof. The first inequality holds for all k \u2208 [T ], since 1\nN N i=1 \u2202 \u2202y[k] g i (x) is one element of 1 N N i=1 \u2207g i (x)\n. We divide the proof for the second inequality into two cases. Case 1. Suppose |x[j \u2212 1]| < 1 for all 2 \u2264 j \u2264 k. Therefore, we have |x[1]| < 1. Using (33), we have the following inequalities:\n\u2202g i (x) \u2202x[1] (i) \u2264 \u2212\u03a8(1)\u03a6 (x[1]) (ii) < \u22121, \u2200i(38)\nwhere (i) is true because \u03a8 (w), \u03a6(w) are all non-negative from Lemma 1 -(2); (ii) is true due to Lemma 1 -(3). Therefore, we have the following\n1 N N i=1 \u2207g i (x) \u2265 1 N N i=1 \u2202 \u2202x[1] g i (x) > 1. Case 2) Suppose there exists 2 \u2264 j \u2264 k such that |x[j \u2212 1]| \u2265 1.\nWe choose j so that |x[j \u2212 1]| \u2265 1 and |x[j]| < 1. Therefore, depending on the choices of (i, j) we have three cases:\n\u2202g i (x) \u2202x[j] = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 (\u2212\u03a8 (\u2212x[j \u2212 1]) \u03a6 (\u2212x[j]) \u2212 \u03a8 (x[j \u2212 1]) \u03a6 (x[j])) , i = j \u2212 1 \u2212 N ( ) \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , T N \u2212 1, j = 2, 3, \u00b7 \u00b7 \u00b7 , T + 1 (\u2212\u03a8 (\u2212x[j]) \u03a6 (\u2212x[j + 1]) \u2212 \u03a8 (x[j]) \u03a6 (x[j + 1])) , i = j \u2212 1 \u2212 N ( ) \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , T N \u2212 1, j = 3, 4, \u00b7 \u00b7 \u00b7 , T 0 otherwise .(39)\nFirst, note that \u2202g i (x) \u2202x[j] \u2264 0, for all i, j, by checking the definitions of \u03a8(\u00b7), \u03a6 (\u00b7), \u03a8 (\u00b7), \u03a6(\u00b7). Then for (i, j) satisfying the first condition, because |x[j \u2212 1]| \u2265 1 and |x[j]| < 1, using , and the fact that the negative part is zero for \u03a8, and \u03a6 is even function, the expression further simplifies to:\n\u2212\u03a8(|x[j \u2212 1]|)\u03a6 (|x[j]|)] (27) < \u22121.(40)\nIf the second condition holds true, the expression is obviously non-positive because both \u03a8 and \u03a6 are non-negative. Overall, we have\n1 N N i=1 \u2202g i (x) \u2202x[j] > 1 N .\nThis completes the proof.\n\n\nLemma 4.\n\nConsider using an algorithm of the form (20) to solve the following problem:\nmin x\u2208R T +1 g(x) = 1 N N i=1 g i (x).(41)\nAssume the initial solution: \nx i = 0, \u2200 i \u2208 [N ]. Letx = 1 N N i=1 \u03b1 i x i denote\u2202g i (x i ) \u2202x i [j] = \u2212 \u03a8 (\u2212x i [j \u2212 1]) \u03a6 (\u2212x i [j]) + \u03a8 (x i [j \u2212 1]) \u03a6 (x i [j]) ,(42)i = j \u2212 1 \u2212 N ( ) \u2265 1, = 0, \u00b7 \u00b7 \u00b7 , T N \u2212 1, j = 2, 3, \u00b7 \u00b7 \u00b7 , T + 1.(43)\nClearly, if x i [j \u2212 1] = 0, then by the definition of \u03a8(\u00b7), the above partial gradient is also zero. In other words, the above partial gradient is only non-zero if\nx i [j \u2212 1] = 0.\nRecall that we have assumed that the server aggregation is performed using a linear combination\nx = 1 N N i=1 \u03b1 i x i ,\nwith the coefficients \u03b1 i 's possibly depending on the stage t (but such a dependency will be irrelevant for our purpose, as will be see shortly). Therefore, at a given stage t, for a given node i, when j \u2265 3, its jth element will become nonzero only if one of the following two cases hold true:\n\n\u2022 If before the aggregation step (i.e., at stage t \u2212 1), some other node q has x q [j] being nonzero.\n\u2022 If \u2202g i (x i ) \u2202x i [j] is nonzero at stage t.\nNow suppose that the initial solution is x i [j] = 0 for all (i, j). Then at the first iteration only \u2202g i (x i )\n\u2202x i [1]\nis non-zero for all i, due to the fact that \u2202g i (x i ) \u2202x i [1] = \u03a8(1)\u03a6 (0) = 4(1 \u2212 e \u22121 ) for all i from (33). It is also important to observe that, if all nodes i = 1 were to perform subsequent local updates (20b), the local variable x j will have the same support (i.e., only the first element is non-zero). To see this, suppose k = 2, then for i = 2, we have\n\u2202g i (x i ) \u2202x i [2] = \u2212\u03a8 (\u2212x[2]) \u03a6 (\u2212x[3]) \u2212 \u03a8 (x[2]) \u03a6 (x[3]) = 0,(44)since x[2] = 0 implies \u03a8 (\u2212x[2]) = 0.\nSimilarly reasoning applies when i = 2, k \u2265 3. If i \u2265 3, then these local functions are not related to x i [2], so the partial derivative is also zero. Now let us look at node i = 1. For this node, according to (42), we have\n\u2202g 1 (x 1 ) \u2202x 1 [2] = \u2212 \u03a8 (\u2212x 1 [1]) \u03a6 (\u2212x 1 [2]) + \u03a8 (x 1 [1]) \u03a6 (x 1 [2]) .(45)\nSince x 1 [1] can be non-zero, then this partial gradient can also be non-zero. Further, with a similar argument as above, we can also confirm that no matter how many local computation steps that node 1 performs, only the first two elements of x 1 can be non-zero. So for the first stage t = 1, we conclude that, no matter how many local computation that the nodes perform (in the form of the computation step given in (20b)), only x 1 can have two non-zero entries, while the rest of the local variables only have one non-zero entries.\n\nThen suppose that the communication and aggregation step is performed once. It follows that after broadcastingx = 1 N N i=1 \u03b1 i x i to all the nodes, everyone can have two non-zero entries. Then the nodes proceed with local computation, and by the same argument as above, one can show that this time only x 2 can have three non-zero entries. Following the above procedure, it is clear that each aggregation step can advance the non-zero entry ofx by one, while performing multiple local updates does not advance the non-zero entry. Then we conclude that we need at least T communication steps, and local gradient computation steps, to make x i [T ] possibly non-zero. , and all j = 1, \u00b7 \u00b7 \u00b7 , T + 1. Consider any algorithm obeying the rules given in (10), where the V t (\u00b7) and W t i (\u00b7)'s are linear operators. Then regardless of the number of local updates there exists a problem satisfying Assumption 1 -2, such that it requires at least the following number of stages t (and equivalently, aggregation and communications rounds in (20a))\nt \u2265 (f (0) \u2212 inf x f (x)) LN 10\u03c0 2 \u22121(46)\nto achieve the following error\nh * t = 1 N N i=1 \u2207f i (x t ) 2 < .(47)\nProof of Claim 2.1. First, let us show that the algorithm obeying the rules given in (20) has the desired property. Note that the difference between two rules is whether the sampled local gradients are used for the update, or the full local gradients are used.\n\nBy Lemma 4 we havex[T ] = 0 for all t < T . Then by applying  and Lemma 3, we can conclude that the following holds\n\u2207f (x[T ]) = \u221a 2 \u2207h x[T ]U \u03c0 \u221a 2 > \u221a 2 /N,(48)\nwhere the second inequality follows that there exists k \u2208 [T ] such that |x [k]U \u03c0 \u221a 2 | = 0 < 1, then we can directly apply Lemma 3.\n\nThe third part of Lemma 2 ensures that f i 's are L-Lipschitz continuous gradient, and the first part shows\nf (0) \u2212 inf x f (x) \u2264 10\u03c0 2 LN T,\nTherefore we obtain\nT \u2265 (f (0) \u2212 inf x f (x)) LN 10\u03c0 2 \u22121 .(49)\nThis completes the proof. Second, consider the algorithm obeying the rules give in (10), in which local sampled gradients are used. By careful inspection, the result for this case can be trivially extended from the previous case. We only need to consider the following local function\u015d\nf i (x) = \u03be i \u2208D i F (x; \u03be i )(50)\nwhere each sampled loss function F (x; \u03be i ) is defined as\nF (x; \u03be i ) = \u03b4(\u03be i )f i (x), where f i (x) is defined in (25).(51)\nwhere \u03b4(\u03be i )'s satisfy \u03b4(\u03be i ) > 0 and \u03be i \u2208D i \u03b4(\u03be i ) = 1. It is easy to see that, the local sampled gradients have the same dependency on x as their averaged version (by dependency we meant the structure that is depicted in Fig. 3). Therefore, the progression of the non-zero pattern of the averagex = 1 N N i=1 x i is exactly the same as the batch gradient version. Additionally, since the local functionf (x) is exactly the same as the previous local function f (x), so other estimates, such as the one that bounds f (0) \u2212 inf f (x), also remain the same.\n\n\nC Proof of Claim 2.2\n\nFirst let us consider FedAvg with local-GD update (9). We consider the following problem with N = 2, which satisfies both Assumptions 1 and 2, with f (x) = 0, \u2200 x\nf 1 (x) = 1 2 x 2 , f 2 (x) = \u2212 1 2 x 2 .(52)\nEach local iteration of the FedAvg is given by\nx r+1 1 = (1 \u2212 \u03b7 r+1 )x r 1 , x r+1 2 = (1 + \u03b7 r+1 )x r 2 .(53)\nFor simplicity, let us define y = [x 1 , x 2 ] T , and define the matrix D = [1 \u2212 \u03b7, 0; 0, 1 + \u03b7]. Then running Q rounds of the FedAvg algorithm starting with r = kQ for some non-negative integer k \u2265 0, can be expressed as\ny (k+1)Q = D Q\u22121 y kQ+1 , y kQ+1 = 1 2 11 T Dy kQ .(54)\nTherefore overall we have\ny (k+1)Q = 1 2 D Q\u22121 11 T Dy kQ .(55)\nIt is easy to show that for any Q > 1, the eigenvalues of the matrix 1 2 D Q\u22121 11 T D are 0 and (1+\u03b7)\nQ +(1\u2212\u03b7) Q 2 > 1.\nIt follows that the above iteration will diverge for any Q > 1 starting from any non-zero initial point.\n\nMoreover, when the sample on one agent are the same (e.g., agent 1 has two samples that both has loss function x 2 ), then using SGD as local update will be identical to the update of GD.\n\n\nD Results showing the role of GB for FedAvg with diminishing stepsizes\n\nThis section is used to show the role of A3 in FedAvg. First we prove that with A3, FedAvg can use arbitrary stepsize as long as it diminishes to zero. Next, we show by a simple example that without A3, FedAvg will diverge with the same diminishing stepsize choice.\n\nClaim D.1. Suppose A1-A3 hold and the stepsizes satisfy: 1) \u03b7 r,0 = \u03b7 \u2208 (0, 1/L) for all r; 2) set 0 < \u03b7 r,q \u2264 min{ 1 2(Q\u22121)L , \u03b7 Q }, lim r\u2192\u221e \u03b7 r,q = 0, q = 0. Then the average gradient converges to zero for FedAvg with local-GD update (9):\n1 T T r=0 \u2207f (x r ) 2 \u2264 2(f (x 0 ) \u2212 f (x )) C 1 T + 2QG 2 \u03b7 2 C 1 T T r=0 Q\u22121 q=1\n\u03b7 r,q , for some C 1 := \u03b7(1 \u2212 L\u03b7).\n\nClaim D.2. Suppose that all the assumptions made in Claim D.1 hold, except that A3 does not hold. Then FedAvg with local-GD can diverge for any Q > 1.\n\nBefore we prove Claim D.1, the following lemma is needed.\n\nLemma 5. Under A1 and A3, following the update steps in Algorithm 1, between each outer iterations we have:\nf (x r+1 ) \u2212 f (x r ) \u2264 \u2212 (\u03b7 r,0 (1 \u2212 L\u03b7 r,0 ) + Q\u22121 q=1 \u03b7 r,q 2 ) \u2207f (x r ) 2 \u2212 Q\u22121 q=1 ( \u03b7 r,q 2 \u2212 2L(Q \u2212 1)(\u03b7 r,q ) 2 ) 1 N N i=1 \u2207f i (x r,q i ) 2 + QG 2 2 ((\u03b7 r,0 ) 2 + Q\u22121 q=1 (\u03b7 r,q ) 2 ) Q\u22121 q=1 \u03b7 r,q ,(56)\nwhere r 0 + 1 mod Q = 0.\n\nProof: By using A1 we have:\nf (x r+1 ) \u2212 f (x r ) \u2264 \u2207f (x r ), x r+1 \u2212 x r + L 2 x r+1 \u2212 x r 2 (a) = \u2212 \u2207f (x r ), 1 N N i=1 Q\u22121 q=0 \u03b7 r,q \u2207f i (x r,q i ) + L 2 1 N N i=1 Q\u22121 q=0 \u03b7 r,q \u2207f i (x r,q i ) 2 (b) \u2264 \u2212 Q\u22121 q=1 \u03b7 r,q \u2207f (x r ), 1 N N i=1 \u2207f i (x r,q i ) + L(\u03b7 r,0 ) 2 \u2207f (x r ) 2 + (Q \u2212 1)L Q\u22121 q=1 (\u03b7 r,q ) 2 1 N N i=1 \u2207f i (x r,q i ) 2 (c) = \u2212\u03b7 r,0 \u2207f (x r ) 2 \u2212 Q\u22121 q=1 \u03b7 r,q \u2207f (x r ), 1 N N i=1 \u2207f i (x r,q i ) + L(\u03b7 r,0 ) 2 \u2207f (x r ) 2 + (Q \u2212 1)L Q\u22121 q=1 (\u03b7 r,q ) 2 1 N N i=1 \u2207f i (x r,q i ) 2 ,(57)\nwhere (a) comes from the update rule in Algorithm 1, in (b) we use Jensen's inequality and notice x r,0 i = x r so in (c) we extract the terms with index (r, 0) from the inner product.\n\nNote that for any vector a, b of the same length, the equality 2 a, b = a\n2 + b 2 \u2212 a \u2212 b 2 , holds, we have \u2212 \u03b7 r,q \u2207f (x r ), 1 N N i=1 \u2207f i (x r,q i ) + (Q \u2212 1)L(\u03b7 r,q ) 2 1 N N i=1 \u2207f i (x r,q i ) 2 = \u2212 \u03b7 r,q 2 \u2207f (x r ) 2 \u2212 \u03b7 r,q 2 1 N N i=1 \u2207f i (x r,q i ) 2 + \u03b7 r,q 2 \u2207f (x r ) \u2212 1 N N i=1 \u2207f i (x r,q i ) 2 + (Q \u2212 1)L(\u03b7 r,q ) 2 1 N N i=1 \u2207f i (x r,q i ) 2 (a) \u2264 \u2212 \u03b7 r,q 2 \u2207f (x r ) 2 + \u03b7 r,q 2N N i=1 \u2207f i (x r ) \u2212 \u2207f i (x r,q i ) 2 \u2212 \u03b7 r,q 2 ((1 \u2212 2(Q \u2212 1)L\u03b7 r,q )) 1 N N i=1 \u2207f i (x r,q i ) 2 (b) \u2264 \u2212 \u03b7 r,q 2 \u2207f (x r ) 2 + L 2 \u03b7 r,q 2N N i=1 x r \u2212 x r,q i 2 \u2212 \u03b7 r,q 2 ((1 \u2212 2(Q \u2212 1)L\u03b7 r,q )) 1 N N i=1 \u2207f i (x r,q i ) 2 ,(58)\nwhere we use Jensen's inequality in (a) and A1 in (b).\n\nFurther note that\nx r \u2212 x r,q i 2 = x r \u2212 x r + q\u22121 \u03c4 =0 \u03b7 r,\u03c4 \u2207f i (x r,\u03c4 i ) 2 = q\u22121 \u03c4 =0 \u03b7 r,\u03c4 \u2207f i (x r,\u03c4 i ) 2 (a) \u2264 2(q \u2212 1) q\u22121 \u03c4 =1 (\u03b7 r,\u03c4 ) 2 \u2207f i (x r,\u03c4 i ) 2 + 2(\u03b7 r,0 ) 2 \u2207f i (x r,0 i ) 2 (b) \u2264 2 (q \u2212 1) q\u22121 \u03c4 =1 (\u03b7 r,\u03c4 ) 2 + (\u03b7 r,0 ) 2 G 2 .(59)\nThe first equality comes from the update rule of x r,q i , which basically performs q steps of updates on x r ; (a) comes from Jensen's inequality; in (b) we use A3.\n\nSubstitute (59) to (58) and then to (57), rearrange the terms we obtain (56), which ends the proof of the lemma.\n\n\nD.1 Proof of Claim D.1\n\nNext we prove Claim D.1\n\nProof: By choosing \u03b7 r,0 = \u03b7 1 =\u2208 (0, 1/L) as constant and \u03b7 r,q \u2264 1/(2QL) , \u2200 q = 0 then applying Lemma 5 we have\nf (x r+1 ) \u2212 f (x r ) \u2264 \u2212(C 1 + Q\u22121 q=1 \u03b7 r,q 2 ) \u2207f (x r ) 2 + QG 2 2 ((\u03b7 1 ) 2 + Q\u22121 q=1 (\u03b7 r,q ) 2 ) Q\u22121 q=1 \u03b7 r,q ,(60)\nwhere C 1 = \u03b7 1 (1 \u2212 L\u03b7 1 ) > 0. Using telescope sum from r = 0 to r = T \u2212 1 we have\nf (x T ) \u2212 f (x 0 ) \u2264 \u2212 T \u22121 r=0 (C 1 + Q\u22121 q=1 \u03b7 r,q 2 ) \u2207f (x r ) 2 + QG 2 2 T \u22121 r=0 ((\u03b7 1 ) 2 + Q\u22121 q=1 (\u03b7 r,q ) 2 ) Q\u22121 q=1 \u03b7 r,q .(61)\nRearrange the terms and multiply both side by 2/(T C 1 ), then we have\n( 1 T + T \u22121 r=0 Q\u22121 q=1 \u03b7 r,q T C 1 ) T r=0 \u2207f (x r ) 2 \u2264 2(f (x 0 ) \u2212 f (x )) C 1 T + QG 2 C 1 T T \u22121 r=0 ((\u03b7 1 ) 2 + Q\u22121 q=1 (\u03b7 r,q ) 2 ) Q\u22121 q=1 \u03b7 r,q .(62)\nChoose \u03b7 r,q \u2264 \u03b7 1 /Q, then (\u03b7 1 ) 2 + Q\u22121 q=1 (\u03b7 r,q ) 2 \u2264 2(\u03b7 1 ) 2 . Choose {\u03b7 r,q } as a sequence that diminishes to 0, then for all q = 0, as T \u2192 \u221e, 2\u03b7 1 Q 2 G 2 C 1 1 QT T \u22121 r=0 Q\u22121 q=1 \u03b7 r,q \u2192 0. Therefore the right hand side converges to 0, Claim D.1 is proved.\n\n\nE Proof of Claim D.2\n\nProof. We consider the following problem with N = 2, which satisfies both Assumptions 1 and 2, with\nf (x) = 0, \u2200 x f 1 (x) = x 2 , f 2 (x) = \u2212x 2 .(63)\nEach local iteration of the FedAvg is given by\nx r+1 1 = (1 \u2212 \u03b7 r )x r 1 , x r+1 2 = (1 + \u03b7 r )x r 2 .(64)\nFor simplicity, let us define y = [x 1 , x 2 ] T , and define the matrix D r = [1 \u2212 \u03b7 r , 0; 0, 1 + \u03b7 r ]. Then running Q rounds of the FedAvg algorithm starting with r = kQ for some non-negative integer k \u2265 0, can be expressed as\ny (k+1)Q = (k+1)Q\u22121 r=kQ+1 D r y kQ+1 , y kQ+1 = 1 2 11 T D kQ y kQ .(65)\nTherefore overall we have\ny (k+1)Q = 1 2 (k+1)Q\u22121 r=kQ+1 D r 11 T D kQ y kQ .(66)\nIn particular, we pick \u03b7 r = 1 \u221a r when r = kQ + 1 and \u03b7 kQ+1 = 1/2. Then for Q > 1, it is easy to compute the eigenvalues of the matrix 1 2 (k+1)Q\u22121 r=kQ+1 D r 11 T D kQ to be:\n\u03bb 1 = 0, \u03bb 2 = 1 4 (k+1)Q\u22121 r=kQ+2 (1 \u2212 1 \u221a r )(1 \u2212 1 \u221a kQ ) + 3 4 (k+1)Q\u22121 r=kQ+2 (1 + 1 \u221a r )(1 + 1 \u221a kQ ).\nIt is clear that \u03bb 2 is strictly larger than one which indicates that the algorithm will diverge.\n\n\nF Proofs for Results in Section 3 F.1 Proof of Theorem 1\n\nFirst let us prove Theorem 1 about the FedPD algorithm with Oracle I. Towards this end, let us first introduce some notations. First recall that when Oracle I is used, the local problem is solved such that the following holds true:\n\u2207 x i L(x r+1 i , x r 0 , \u03bb r i ) 2 \u2264 1 .(67)\nNote that if SGD is applied in Oracle I to solve the local problem, then this condition (67) is replaced with the following\nE[ \u2207 x i L(x r+1 i , x r 0 , \u03bb r i ) 2 ] \u2264 1 .(68)\nThe difference does not significantly change the proofs and the results. So throughout the proof of Theorem 1, we use (67) as the condition. Throughout the proof, we denote the expectation taken on the communication r th iteration to the r + 1 th iteration conditioning on all the previous knowledge as E r+1 .\n\nThen we define the error between different nodes as\nr [ x r 0 ; x r ], with x r 0 max i,j x r 0,i \u2212 x r 0,j , x r max i,j x r i \u2212 x r j .(69)\nHere, x r 0 denotes the maximum difference of estimated center model among all the nodes and x r denotes the maximum difference of local models among all nodes.\n\nFrom the termination condition that generates x r+1 i (given in (67)), we have\n\u2207f i (x r+1 i ) + \u03bb r+1 i = \u2207f i (x r+1 i ) + \u03bb r i + 1 \u03b7 (x r+1 i \u2212 x r 0,i ) = e r+1 i , where e r+1 i 2 \u2264 1 ,(70)\nwhere the first equality holds because of the update rule of \u03bb i . Furthermore, from the update step of \u03bb r+1 i , we can explicitly write down the following expression\n\u03bb r+1 i = \u03bb r i + 1 \u03b7 (x r+1 i \u2212 x r 0,i ) = \u2212\u2207f i (x r+1 i ) + e r+1 i .\nThe main lemmas that we need are outlined below. Their proofs can be found in Sec. F.1.1-F.1.4. The first lemma shows the sufficient descent of the local AL function.\n\nLemma 6. Suppose A1 holds true. Consider FedPD with Algorithm 4 (Oracle I) as the update rule. When the local problem is solved such that (67) is satisfied, the difference of the local augmented Lagrangian is bounded by\nL i (x r+1 i , x r+ 0,i , \u03bb r+1 i ) \u2212 L i (x r i , x r 0,i , \u03bb r i ) \u2264 \u2212 1 \u2212 2L\u03b7 2\u03b7 x r+1 i \u2212 x r i 2 \u2212 1 2\u03b7 x r+ 0,i \u2212 x r 0,i 2 + \u03b7 \u03bb r+1 i \u2212 \u03bb r i 2 + 1 2L .(71)\nThen we derive a key lemma about how the error propagates if the communication step is skipped.\n\nLemma 7. Suppose A1 and A5 hold. Consider FedPD with Algorithm 4 (Oracle I) as the update rule. When the local problem is solved such that (67) is satisfied, the difference between the local models x r i 's and the difference between local copies of the global models x r 0,i 's are bounded by\nE r+1 r+1 \u2264 1 1 \u2212 L\u03b7 (A r + \u03b7B(\u03b4 + 2 \u221a 1 ). (72) where A = p(1 + L\u03b7) L\u03b7(1 \u2212 L\u03b7) 1 L\u03b7\nis a rank 1 matrix with eigenvalues (0, L\u03b7 + p(1 + L\u03b7)) and B = [p(3 + L\u03b7), 2] T .\n\n\nWe define a virtual sequence {x\nr 0 } where x r 0 1 N N i=1\nx r 0,i which is the average of the local x r 0,i and we know that x r 0,i = x r 0 when r mod R = 1, that is, when the communication and aggregation step is performed. Next, we bound the error between the local AL and the global AL evaluated at the virtual sequence.\n\nLemma 8. Suppose A1 holds. Consider FedPD with Algorithm 4 (Oracle I) as the update rule. When the local problem is solved such that (67) is satisfied, the difference between local AL and the global AL is bounded as below:\n1 N N i=1 [L i (x r+1 i , x r+ 0,i , \u03bb r+1 i ) \u2212 cL i (x r+1 i , x r+1 0 , \u03bb r+1 i )] \u2265 \u2212 (N \u2212 1) 2N \u03b7 ( x r+1 0 ) 2 .(73)\nLastly we bound the original objective function using the global AL.\n\nLemma 9. Under A1 and A2, when the local problem is solved to 1 accuracy, the difference between the original loss and the augmented Lagrangian is bounded.\nf (x r 0 ) \u2264 L(x r 0 , x r 1 , . . . , x r N , \u03bb r 1 , . . . , \u03bb r N ) \u2212 1 \u2212 2L\u03b7 N \u03b7 N i=1 x r i \u2212 x r 0 2 + 1 2L .(74)\nUsing the previous lemmas, we can then prove Theorem 1.\n\n\nF.1.1 Proof of Lemma 6\n\nWe divide the left hand side (LHS) of (71), i.e.,\nL i (x r+1 i , x r+ 0,i , \u03bb r+1 i ) \u2212 L i (x r i , x r 0,i , \u03bb r i )\n, into the sum of three parts:\nL i (x r+1 i , x r+ 0,i , \u03bb r+1 i ) \u2212 L i (x r i , x r 0,i , \u03bb r i ) = L i (x r+1 i , x r 0,i , \u03bb r i ) \u2212 L i (x r i , x r 0,i \u03bb r i ) + L i (x r+1 i , x r 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r 0,i , \u03bb r i ) + L i (x r+1 i , x r+ 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r 0,i , \u03bb r+1 i ),(75)\nwhich correspond to the three steps in the algorithm's update steps. We bound the first difference by first applying A1 to \u2212f (\u00b7):\n\u2212f i (x r i ) \u2264 \u2212f i (x r+1 i ) + \u2212\u2207f i (x r+1 i ), x r i \u2212 x r+1 i + L 2 x r i \u2212 x r+1 i 2 ,\nand obtain the following series of inequalities:\nL i (x r+1 i , x r 0,i , \u03bb r i )\u2212L i (x r i , x r 0,i , \u03bb r i ) \u2264 \u2207f i (x r+1 i ), x r+1 i \u2212 x r i + L 2 x r+1 i \u2212 x r i 2 + \u03bb r i , x r+1 i \u2212 x r i + 1 2\u03b7 x r+1 i \u2212 x r 0,i 2 \u2212 1 2\u03b7 x r i \u2212 x r 0,i 2 (a) = \u2207f i (x r+1 i ) + \u03bb r i , x r+1 i \u2212 x r i + L 2 x r+1 i \u2212 x r i 2 + 1 2\u03b7 x r+1 i + x r i \u2212 2x r 0,i , x r+1 i \u2212 x r i (b) = \u2207f i (x r+1 i ) + \u03bb r i + 1 \u03b7 (x r+1 i \u2212 x r 0,i ), x r+1 i \u2212 x r i + L 2 x r+1 i \u2212 x r i 2 \u2212 1 2\u03b7 x r+1 i \u2212 x r i 2 (c) \u2264 1 2L \u2207f i (x r+1 i ) + \u03bb r i + 1 \u03b7 (x r+1 i \u2212 x r 0,i ) 2 + L 2 x r+1 i \u2212 x r i 2 \u2212 1 \u2212 L\u03b7 2\u03b7 x r+1 i \u2212 x r i 2 (d) \u2264 \u2212 1 \u2212 2L\u03b7 2\u03b7 x r+1 i \u2212 x r i 2 + 1 2L .(76)\nIn the above equation, in (a) we use the fact that a 2 \u2212 b 2 = a + b, a \u2212 b when vector a, b has the same length to the last two terms; in (b) we split the last term into 2x r+1 i \u2212 2x r 0,i and \u2212x r+1\n\ni + x r i ; in (c) we use the fact that a, b \u2264 L 2 a 2 + 1 2L b 2 ); in (d) we apply the fact that x r+1 i is the inexact solution; see (70).\n\nThen we bound the second difference in (75) by the following:\nL i (x r+1 i , x r 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r 0,i , \u03bb r i ) = \u03bb r+1 i \u2212 \u03bb r i , x r+1 i \u2212 x r 0,i (a) = \u03bb r+1 i \u2212 \u03bb r i , \u03b7(\u03bb r+1 i \u2212 \u03bb r i ) = \u03b7 \u03bb r+1 i \u2212 \u03bb r i 2 ,(77)\nwhere (a) directly comes from the update rule of \u03bb r+1 i . Further we bound the third difference in (75) by the following:\nL i (x r+1 i , x r+ 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r 0,i , \u03bb r+1 i ) = \u03bb r+1 i , x r+1 i \u2212 x r+ 0,i \u2212 \u03bb r+1 i , x r+1 i \u2212 x r 0,i + 1 2\u03b7 x r+1 i \u2212 x r+ 0,i 2 \u2212 1 2\u03b7 x r+1 i \u2212 x r 0,i 2 (a) = \u03bb r+1 i , x r 0,i \u2212 x r+ 0,i + 1 2\u03b7 2x r+1 i \u2212 2x r+ 0,i + x r+ 0,i \u2212 x r 0,i , x r 0,i \u2212 x r+ 0,i = 1 \u03b7 (\u03b7\u03bb r+1 i + x r+1 i \u2212 x r+ 0,i ), x r 0,i \u2212 x r+ 0,i \u2212 1 2\u03b7 x r+ 0,i \u2212 x r 0,i 2 (b) = \u2212 1 2\u03b7 x r+ 0,i \u2212 x r 0,i 2 ,(78)\nwhere, in (a), we use the same reasoning as in (76) (a) and (b); in (b) we apply the update rule of x r+ 0,i in the FedPD algorithm, which implies that the first term becomes zero.\n\nFinally we sum up (76), (77), (78) and Lemma 6 is proved.\n\n\nF.1.2 Proof of Lemma 7\n\nFirst we derive the relation between x r+1\n\ni \u2212 x r+1 j for arbitrary i = j and r by using the definition of 1 (70):\nx r+1 i \u2212 x r+1 j (70) = x r 0,i \u2212 x r 0,j \u2212 \u03b7(\u2207f i (x r+1 i ) + \u03bb r i \u2212 e r+1 i \u2212 \u2207f j (x r+1 j ) \u2212 \u03bb r j + e r+1 j ) \u2264 x r 0,i \u2212 x r 0,j + \u03b7 \u2207f i (x r+1 i ) \u2212 \u2207f j (x r+1 j ) + \u03b7 \u03bb r i \u2212 \u03bb r j + \u03b7( e r+1 i + e r+1 j ) (a) \u2264 x r 0 + \u03b7 \u2207f i (x r+1 i ) \u2212 \u2207f i (x r+1 j ) + \u2207f i (x r+1 j ) \u2212 \u2207f j (x r+1 j ) + \u03b7 \u03bb r i \u2212 \u03bb r j + 2\u03b7 \u221a 1 (b) \u2264 x r 0 + L\u03b7 x r+1 i \u2212 x r+1 j + \u03b7 \u2207f i (x r+1 j ) \u2212 \u2207f j (x r+1 j ) + \u03b7 \u03bb r i \u2212 \u03bb r j + 2\u03b7 \u221a 1 (c) \u2264 x r 0 + L\u03b7 x r+1 i \u2212 x r+1 j + \u03b7\u03b4 + \u03b7 \u03bb r i \u2212 \u03bb r j + 2\u03b7 \u221a 1 (d) = 1 1 \u2212 L\u03b7 x r 0 + \u03b7 1 \u2212 L\u03b7 \u03b4 + \u03b7 1 \u2212 L\u03b7 \u03bb r i \u2212 \u03bb r j + 2\u03b7 1 \u2212 L\u03b7 \u221a 1 ,(79)\nwhere in (a) we plug the definition of x r 0 and e r+1 i ; in (b) we use A1; (c) comes form A5; in (d) we move the second term to the left and divide both side by 1 \u2212 L\u03b7.\n\nThen we bound the difference \u03bb r i \u2212 \u03bb r j by plugging in the expression of \u03bb r i in (70), and note that\n\u03bb r i + 1 \u03b7 (x r+1 i \u2212 x r 0,i ) = \u03bb r+1 i : \u03bb r i \u2212 \u03bb r j = \u2212\u2207f i (x r i ) + e r i + \u2207f j (x r j ) \u2212 e r j (a) \u2264 \u2207f i (x r i ) \u2212 \u2207f i (x r j ) + \u2207f i (x r j ) \u2212 \u2207f j (x r j ) + 2 \u221a 1 (b) \u2264 L x r i \u2212 x r j + \u03b4 + 2 \u221a 1 (c) \u2264 L x r + \u03b4 + 2 \u221a 1 ,(80)\nwhere (a) and (b) follow the same argument in (a), (b) and (c) of (79) ; in (c) we plug in the definition of x r . Next we bound the difference x r+1 0,i \u2212 x r+1 0,j . With probability 1 \u2212 p the aggregation step has just been done at iteration r, x r+1 0,i = x r+1 0,j .With probability p, they are not equal, then we take expectation with communication probability p, and get\nE r+1 x r+1 0,i \u2212 x r+1 0,j = p x r+1 i \u2212 x r+1 j + \u03b7(\u03bb r+1 i \u2212 \u03bb r+1 j ) \u2264 p x r+1 i \u2212 x r+1 j + p\u03b7 \u03bb r+1 i \u2212 \u03bb r+1 j (a) \u2264 p(1 + L\u03b7) x r+1 + p\u03b7(\u03b4 + 2 \u221a 1 ),(81)\nwhere in (a) we plug in the definition of x r+1 and (80). As these relations hold true for arbitrary (i, j) pairs, they are also true for the maximum of x r+1\n\ni \u2212 x r+1 j and x r+1 0,i \u2212 x r+1 0,j . Therefore stacking (79) and (81) and plug in (80), we have\nx r+1 \u2264 1 1 \u2212 L\u03b7 (L\u03b7 x r + x r 0 ) + 2\u03b7 1 \u2212 L\u03b7 (\u03b4 + 2 \u221a 1 ), E r+1 x r+1 0 \u2264p 1 + L\u03b7 1 \u2212 L\u03b7 (L\u03b7 x r + x r 0 ) + p \u03b7(3 + L\u03b7) 1 \u2212 L\u03b7 (\u03b4 + 2 \u221a 1 ).(82)\nRewrite it into matrix form then we complete the proof of Lemma 7.\n\n\nF.1.3 Proof of Lemma 8\n\nLet us first recall that the definition of local AL is given below:\nL i (x i , x 0 , \u03bb i ) f i (x i ) + \u03bb i , x i \u2212 x 0 + 1 2\u03b7 x i \u2212 x 0 2 .\nSimilar to (78), we have\nL i (x r+1 i , x r+ 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r+1 0 , \u03bb r+1 i ) = \u03bb r+1 i , x r+1 i \u2212 x r+ 0,i \u2212 \u03bb r+1 i , x r+1 i \u2212 x r+1 0 + 1 2\u03b7 x r+1 i \u2212 x r+ 0,i 2 \u2212 1 2\u03b7 x r+1 i \u2212 x r+1 0 2 (a) = \u2212 1 2\u03b7 x r+ 0,i \u2212 x r+1 0 2 (b) = \u2212 1 2\u03b7 x r+ 0,i \u2212 1 N N j=1 x r+ 0,j 2 = \u2212 1 2\u03b7 1 N N j=1 (x r+ 0,i \u2212 x r+ 0,j ) 2 (c) \u2265 \u2212 1 2\u03b7N j =i x r+ 0,i \u2212 x r+ 0,j 2 (d) \u2265 \u2212 N \u2212 1 2\u03b7N ( x r+1 0 ) 2 ,(83)\nwhere (a) follows the same argument in (78); in (b),we plug in the definition of x r+1 0 ; in (c) we use Jensen's inequality and we bound the term with x r+1 0 . Then the lemma is proved.\n\n\nF.1.4 Proof of Lemma 9\n\nApplying A1, we have\nf i (x r 0 ) \u2264 f i (x r i ) + \u2207f i (x r i ), x r 0 \u2212 x r i + L 2 x r 0 \u2212 x r i 2 (70) = L i (x r i , x r 0 , \u03bb r i ) \u2212 e r i , x r 0 \u2212 x r i \u2212 1 \u2212 L\u03b7 2\u03b7 x r 0 \u2212 x r i 2 \u2264 L i (x r i , x r 0 , \u03bb r i ) + 1 2L \u2212 1 \u2212 2L\u03b7 2\u03b7 x r 0 \u2212 x r i 2 .(84)\nTaking an average over N agents we are able to prove Lemma 9.\n\n\nF.1.5 Proof of Theorem 1\n\nFirst notice that from the optimality condition (70), the following holds:\n\u03bb r i \u2212 \u03bb r\u22121 i 2 \u2264 2L 2 x r i \u2212 x r\u22121 i 2 + 4 1 .(85)\nThen we bound the gradients of L(x r i , x r 0,i , \u03bb r i ).\n\u2207 x i L i (x r i , x r 0,i , \u03bb r i ) = \u2207f i (x r i ) + \u03bb r i + 1 \u03b7 (x r i \u2212 x r 0,i ) (70) = \u2207f i (x r i ) + \u03bb r i + 1 \u03b7 (x r i \u2212 x r 0,i ) \u2212 \u2207f i (x r+1 i ) \u2212 \u03bb r i \u2212 1 \u03b7 (x r+1 i \u2212 x r 0,i ) + e r+1 i \u2264 1 + L\u03b7 \u03b7 x r+1 i \u2212 x r i + \u221a 1 .(86)\nFurther, we note that, when no aggregation has been performed at iteration r, then x r 0,i = x r i + \u03b7\u03bb r i , so the following holds\n\u2207 x 0 L i (x r i , x r 0,i , \u03bb r i ) = \u03bb r i + 1 \u03b7 (x r i \u2212 x r 0,i ) = 0.(87)\nWhen there the aggregation has been performed at iteration r, then x r 0,i = 1 N N j=1 (x r j + \u03b7\u03bb r j ), \u2200i, so we have\n\u2207 x 0 L(x r 0 , x r 1 , . . . , x r N , \u03bb r 1 , . . . , \u03bb r N ) = 1 N N i=1 (\u03bb r i + 1 \u03b7 (x r i \u2212 x r 0,i )) = 0.(88)\nFurther we have:\n\u2207 \u03bb i L i (x r i , x r 0,i , \u03bb r i ) = x r i \u2212 x r 0,i \u2264 x r i \u2212 x r\u22121 0,i + x r\u22121 0,i \u2212 x r 0,i \u2264 \u03b7 \u03bb r i \u2212 \u03bb r\u22121 i + x r\u22121 0,i \u2212 x r 0,i \u2264 \u03b7(L x r i \u2212 x r\u22121 i + 2 \u221a 1 ) + x r\u22121 0,i \u2212 x r 0,i .(89)\nSumming (86) and (89)\n, denote \u2207 x i L i (x r i , x r 0,i , \u03bb r i ) + \u2207 \u03bb i L i (x r i , x r 0,i , \u03bb r i ) as \u2207L i (x r i , x r 0,i , \u03bb r i ) we have \u2207L i (x r i , x r 0,i , \u03bb r i ) \u2264 x r\u22121 0,i \u2212 x r 0,i + 1 + L\u03b7 \u03b7 x r+1 i \u2212 x r i + L\u03b7 x r i \u2212 x r\u22121 i + (1 + 2\u03b7) \u221a 1 .(90)\nSquaring both sides of the above inequality, we obtain:\n\u2207L i (x r i , x r 0,i , \u03bb r i ) 2 \u2264 C 6 x r\u22121 0,i \u2212 x r 0,i 2 + x r+1 i \u2212 x r i 2 + x r i \u2212 x r\u22121 i 2 + 1 ,(91)\nwhere C 6 \u2265 max{( 1+L\u03b7 \u03b7 ) 2 , (1 + 2\u03b7) 2 , L 2 \u03b7 2 }. Apply (85) to Lemma 6 we have\n1 \u2212 2L\u03b7 \u2212 4L 2 \u03b7 2 2\u03b7 x r+1 i \u2212 x r i 2 + 1 2\u03b7 x r+ 0,i \u2212 x r 0,i 2 + 1 + 8L\u03b7 2L 1 \u2264 L i (x r i , x r 0,i , \u03bb r i ) \u2212 L i (x r+1 i , x r+ 0,i , \u03bb r+1 i ) + 1 + 8L\u03b7 L 1 .(92)\nNotice that when communication is not performed\nx r 0,i \u2212 x r+1 0,i 2 \u2264 x r 0,i \u2212 x r+ 0,i 2 , and when communication is performed 1 N N i=1 x r 0,i \u2212 x r+1 0,i 2 = 2 N N i=1 x r 0,i \u2212 x r+ 0,i 2 + 2 N N i=1 x r+ 0,i \u2212 x r+1 0,i 2 \u2264 2 N N i=1 x r 0,i \u2212 x r+ 0,i 2 + N \u2212 1 \u03b7N ( x r+1 0 ) 2 ,(93)\nwhere the last inequality holds due to the use of Jensen's inequality, and the definition of x r+1 0 in (69). It follows that summing both sides of (92) over i, we have\n1 \u2212 2L\u03b7 \u2212 4L 2 \u03b7 2 2\u03b7 N i=1 x r+1 i \u2212 x r i 2 + N i=1 ( 1 4\u03b7 x r+1 0,i \u2212 x r 0,i 2 \u2212 N \u2212 1 4\u03b7 ( x r+1 0 ) 2 ) + N (1 + 8L\u03b7) 2L 1 \u2264 N i=1 L i (x r i , x r 0,i , \u03bb r i ) \u2212 L i (x r+1 i , x r+ 0,i , \u03bb r+1 i ) + N (1 + 8L\u03b7) L 1 .(94)\nTaking the expectation over the randomness in p, conditioning on the information before the communication\nthe successive difference of L i , E r+1 1 N N i=1 [L i (x r i , x r 0,i , \u03bb r i ) \u2212 L i (x r+1 i , x r+ 0,i , \u03bb r+1 i )] = 1 N N i=1 [L i (x r i , x r 0,i , \u03bb r i ) \u2212 L i (x r+1 i , x r+1 0,i , \u03bb r+1 i )] + E r+1 1 N N i=1 [L i (x r+1 i , x r+1 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r+ 0,i , \u03bb r+1 i )] (a) = 1 N N i=1 [L i (x r i , x r 0,i , \u03bb r i ) \u2212 L i (x r+1 i , x r+1 0,i , \u03bb r+1 i )] + 1 N N i=1 [pL i (x r+1 i , x r+1 0 , \u03bb r+1 i ) + (1 \u2212 p)L i (x r+1 i , x r+ 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r+ 0,i , \u03bb r+1 i )] = 1 N N i=1 [L i (x r i , x r 0,i , \u03bb r i ) \u2212 L i (x r+1 i , x r+1 0,i , \u03bb r+1 i )] + p 1 N N i=1 [L i (x r+1 i , x r+1 0 , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r+ 0,i , \u03bb r+1 i )] (b) \u2264 1 N N i=1 [L i (x r i , x r 0,i , \u03bb r i ) \u2212 L i (x r+1 i , x r+1 0,i , \u03bb r+1 i )] + p N \u2212 1 2\u03b7N ( x r+1 0 ) 2 ,(95)\nwhere (a) expands the expectation on p, and use the fact that with probability p, x r+1 0,i = x r+ 0,i , and with probability (1 \u2212 p) x r+1 0 will be updated; in (b) we apply Lemma 8 to the last term. Combine (94) and (95), we have\nmin{ 1 \u2212 2L\u03b7 \u2212 4L 2 \u03b7 2 2\u03b7 , 1 2\u03b7 , 1 + 8L\u03b7 2L } 1 N N i=1 E r+1 x r+1 i \u2212 x r i 2 + x r+1 0,i \u2212 x r 0,i 2 + 1 \u2264 1 N N i=1 L i (x r i , x r 0,i , \u03bb r i ) \u2212 L i (x r+1 i , x r+1 0,i , \u03bb r+1 i ) + 1 + 8L\u03b7 L 1 + p (N \u2212 1) \u03b7N ( x r+1 0 ) 2 .(96)\nCombining (91), (94) and (96), define\nC 7 = 2C 6 / min{ 1\u22122L\u03b7\u22124L 2 \u03b7 2 2\u03b7 , 1 2\u03b7 , 1+8L\u03b7 2L } and sum up the iterations, we have 1 N N i=1 T r=0 E \u2207L i (x r i , x r 0,i , \u03bb r i ) 2 (91)(94) \u2264 2C 6 N N i=1 T r=0 E x r 0,i \u2212 x r+ 0,i 2 + x r i \u2212 x r+1 i 2 + (N \u2212 1) \u03b7N ( x r+1 0 ) 2 + 1 (96) \u2264 C 7 T r=0 1 N N i=1 (L i (x r i , x r 0,i , \u03bb r i ) \u2212 L i (x r+1 i , x r+1 0,i , \u03bb r+1 i )) + 1 + 8L\u03b7 L 1 + pC 7 T r=0 N \u2212 1 N \u03b7 E( x r+1 0 ) 2 .(97)\nNext we bound the last term. By iteratively applying Lemma 7 from \u03c4 = 0 to r and use the fact that \u2206 0 = 0, we have\nE x r+1 0 \u2264 [1, 0] r \u03c4 =0 ( A 1 \u2212 L\u03b7 ) \u03c4 \u03b7 [p(3 + L\u03b7), 2] T 1 \u2212 L\u03b7 (\u03b4 + 2 \u221a 1 ).(98)\nFrom Lemma 7 we have:\n\u03bb max 1 1 \u2212 L\u03b7 A = p(1 + L\u03b7) + L\u03b7 1 \u2212 L\u03b7 C 8 .\nSo by taking norm square on both side of (98), we have\nE( x r+1 0 ) 2 \u2264 [1, 0] r \u03c4 =1 ( A 1 \u2212 L\u03b7 ) \u03c4 \u03b7 [p(3 + L\u03b7), 2] T 1 \u2212 L\u03b7 (\u03b4 + 2 \u221a 1 ) 2 \u2264 r \u03c4 =1 C \u03c4 8 2 8\u03b7 2 (p 2 (3 + L\u03b7) 2 + 4) (1 \u2212 L\u03b7) 2 (\u03b4 2 + 1 ) \u2264 (1 \u2212 C r+1 8 ) 2 \u00d7 8\u03b7 2 (p 2 (3 + L\u03b7) 2 + 4) (1 \u2212 C 8 ) 2 (1 \u2212 L\u03b7) 2 (\u03b4 2 + 1 ).(99)\nSubstitute (99) into (97) and divide both side by T we have\n1 N N i=1 1 T T r=0 E \u2207L i (x r i , x r 0,i , \u03bb r i ) 2 \u2264 C 7 T L(x 0 0 , x 0 i , \u03bb 0 i ) \u2212 L(x T i , x T 0,i , \u03bb T i ) + C 7 (1 + 8L\u03b7) L 1 + 8p\u03b7C 7 (N \u2212 1)(1 \u2212 C 1/(1\u2212p) 8 ) 2 (p 2 (3 + L\u03b7) 2 + 4) N (1 \u2212 C 8 ) 2 (1 \u2212 L\u03b7) 2 (\u03b4 2 + 1 ).\nFrom the initial conditions we have L(x 0 0 , x 0 i , \u03bb 0 i ) = f (x 0 0 ) and apply Lemma 9 we obtain\n1 N T N i=1 T r=0 E \u2207L i (x r i , x r 0,i , \u03bb r i ) 2 \u2264 C 7 (f (x 0 0 ) \u2212 f (x T 0 )) T + C 7 (1 + 8L\u03b7) L 1 + 8p\u03b7C 7 (N \u2212 1)(1 \u2212 C 1/(1\u2212p) 8 ) 2 (p 2 (3 + L\u03b7) 2 + 4) N (1 \u2212 C 8 ) 2 (1 \u2212 L\u03b7) 2 (\u03b4 2 + 1 ). Finally we bound \u2207f (x r 0 ) 2 by \u2207f (x r 0 ) 2 \u2264 2 \u2207f (x r 0 ) \u2212 1 N N i=1 \u2207 x i L i (x r i , x r 0,i , \u03bb r i ) 2 + 2 N N i=1 \u2207 x i L i (x r i , x r 0,i , \u03bb r i ) 2 \u2264 4 N N i=1 \u2207f i (x r 0 ) \u2212 \u2207f i (x r i ) 2 + 4 1 N \u03b7 N i=1 (\u03b7\u03bb r i + x r i \u2212 x r 0,i ) 2 + 2 N N i=1 \u2207 x i L i (x r i , x r 0,i , \u03bb r i ) 2 (a) \u2264 4L 2 N N i=1 x r 0 \u2212 x r i 2 + 2 N N i=1 \u2207 x i L i (x r i , x r 0,i , \u03bb r i ) 2 = 4L 2 N N i=1 \u2207 \u03bb i L i (x r i , x r 0,i , \u03bb r i ) 2 + 2 N N i=1 \u2207 x i L i (x r i , x r 0,i , \u03bb r i ) 2 \u2264 4L 2 N N i=1 \u2207L i (x r i , x r 0,i , \u03bb r i ) 2 ,(100)\nwhere in (a) we use the same argument in (87) and (88). Therefore Theorem 1 is proved. During the proof, we need all C 2 , . . . , C 7 , C 8 > 0, therefore, 0 < \u03b7 <\n\u221a 5\u22121 4L .\nFinally, let us note that if the local problems are solved with SGD, then the local problem needs to be solved such that the condition (68) holds true. As no other information of the local solvers except error term e r i is used in the proof, the proofs and results of FedPD with SGD as local solver will not change much, except that all the results hold in expectation. Therefore we skip the proof for the SGD version.\n\n\nF.1.6 Constants used in the proofs\n\nIn this subsection we list all the constants C 2 , . . . , C 8 used in the proof of Theorem 1.\nC 2 \u2265 4L 2 C 7 , C 3 = C 8 , C 4 \u2265 C 2 (1 + 8L\u03b7) L , C 5 = 8C 2 , C 6 \u2265 max{( 1 + L\u03b7 \u03b7 ) 2 , (1 + 2\u03b7) 2 , L 2 \u03b7 2 },C 7 = 2C 6 / min{ 1 \u2212 2L\u03b7 \u2212 4L 2 \u03b7 2 2\u03b7 , 1 2\u03b7 , 1 + 8L\u03b7 2L }, C 8 = p(1 + L\u03b7) + L\u03b7 1 \u2212 L\u03b7 ,\nwe can see that when 0 < \u03b7 < \n\n\nG FedPD with Variance Reduction\n\nIn this section we provided an alternative oracle for FedPD which has a lower sample complexity.\n\n\nG.1 Algorithm description\n\nAlternatively, when instantiating the local oracle using Algorithm 4, the original local problems are not required to solve to 1 accuracy. Instead, we successively optimize a linearized AL function:\nL r i (x i ) f i (x i ; x r,q i ) + \u03bb i r , x i \u2212 x r 0,i + 1 2\u03b7 x i \u2212 x r 0,i 2 .\nIn the above expression, we linearize f i (x i ) at inner iteration x r,q i as (\u03b3 is a constant)\nf r i (x i ; x r,q i ) f (x r,q i ) + g r,q i , x i \u2212 x r i + 1 2\u03b3 x i \u2212 x r,q i 2 ,\nwhere g r,q i is an approximation of \u2207f i (x r,q i ). The optimizer has a closed-form expression:\nx r,q+1 i = \u03b7 \u03b7 + \u03b3 x r,q i + \u03b3 \u03b7 + \u03b3 x r 0,i \u2212 \u03b7\u03b3 \u03b7 + \u03b3 (g r,q i + \u03bb r i ).\n\nAlgorithm 4 Oracle Choice II\nInput: L i (x r i , x r 0,i , \u03bb r i ), Q, I, B Initialize: x r,0 i = x r i , if r mod I = 0 then g r,0 i = \u2207f i (x r,0 i ) else g r,0 i = g r\u22121,Q i end if for q = 0, . . . , Q \u2212 1 do x r,q+1 i = arg min x iL i (x i , x r 0,i , \u03bb r i ; x r,q i , g r,q i ) g r,q+1 i = g r,q i + 1 B B b=1 (h i (x r,q+1 i ; \u03be r,q i,b ) \u2212 h i (x r,q i ; \u03be r,q i,b )) end for Output: x r+1 i x r,Q i , g r,Q i\nIn Oracle II, an agent i first decides whether to compute the full gradient \u2207f i (x r,0 i ), or to keep using the previous estimate g r\u22121,Q i . Then Q local steps are performed, each requires B local data samples. In this scheme, Q can be chosen as any positive integer.\n\nIt is important to note that this oracle does not simply apply the VR technique (such as F-SVRG) to solve the subproblem of optimizing L i (x i , x r 0,i , \u03bb r i ). That is, it is not a variation of Oracle I. Instead, the VR technique is applied to the entire primal-dual iteration, and the full gradient evaluation \u2207f i (x r,0 i ) is only needed every I iteration r. Later we will see that if I is large enough, then there is an O( \u221a M ) reduction of sample complexity.\n\n\nG.2 Algorithm Convergence and Complexity\n\nThe convergence result of FedPD with Oracle II is given as follows:\n\nTheorem 3. Suppose A1-A2 hold, and consider FedPD with Oracle II. Choose p = 0, \u03b7 \u2208 0,  \n1 T T r=0 E \u2207f (x r 0 ) 2 \u2264 C 9 T (f (x 0 0 ) \u2212 f (x )).(101)\n\nG.3 Proof of Theorem 3\n\nFollowing the similar proof of Theorem 1, we first analyze the descent between each outer iteration. Notice throughout the proof, we assume that p = 0, that is, there is no delayed communication. It follows that the following holds:\nx r+1 0,i = 1 N N j=1\nx r+ 0,j , \u2200i = 1, . . . , N.\n\nWe also recall that r is the (outer) stage index, and q is the local update index. First we provide a series of lemmas. \nL i (x r+1 i , x r+1 0,i , \u03bb r+1 i ) \u2212 L i (x r i , x r 0,i , \u03bb r i ) \u2264 \u2212 1 2\u03b7 x r+1 0,i \u2212 x r 0,i 2 \u2212 1 2\u03b7 + 1 \u03b3 \u2212 L \u2212 3\u03b7 \u03b3 2 x r,Q i \u2212 x r,Q\u22121 i 2 \u2212 ( 1 2\u03b7 + 1 \u03b3 \u2212 L \u2212 9Q 2 L 2 \u03b7) Q\u22121 q=1 x r,q i \u2212 x r,q\u22121 i 2 + 9Q 2 L 2 \u03b7 + 3\u03b7 \u03b3 2 x r\u22121,Q i \u2212 x r\u22121,Q\u22121 i 2 + 1 2L Q\u22122 q=0 \u2207f i (x r,q i ) \u2212 g r,q i 2 + ( 1 2L + 9\u03b7) g r,Q\u22121 i \u2212 \u2207f i (x r,Q\u22121 i ) 2 + 9\u03b7 g r\u22121,Q\u22121 i \u2212 \u2207f i (x r\u22121,Q\u22121 i ) 2 + \u03bb r+1 i + 1 \u03b7 (x r+1 i \u2212 x r+1 0,i ), x r+1 0,i \u2212 x r 0,i .\nThen we deal with the variance of the stochastic gradient estimations.\n\nLemma 11. Suppose A1 holds true and the samples are randomly sampled according to (13), consider FedPD with Algorithm 4 (Oracle II) as the update rule. The expected norm square of the difference between g r,q+1\n\ni and \u2207f i (x r,q+1 i ) is bounded by\nE g r,q+1 i \u2212 \u2207f i (x r,q+1 i ) 2 \u2264 L 2 B {r,q+1} \u03c4 ={r 0 ,1} E x \u03c4 i \u2212 x \u03c4 \u22121 i 2 .(102)\nLastly we upper bound the original loss function.\n\nLemma 12. Under A1 and A2, the difference between the original loss and the AL is bounded as below:\nE f (x r 0 ) \u2264 E L(x r 0 , x r 1 , . . . , x r N , \u03bb r 1 , . . . , \u03bb r N ) \u2212 1 \u2212 3L\u03b7 2N \u03b7 N i=1 E x r i \u2212 x r 0 2 + (1 + L\u03b3) 2 + L 2 \u03b3 2 4L\u03b3 2 \uf8ee \uf8f0 1 B {r\u22121,Q\u22121} \u03c4 ={r 0 ,1} E x \u03c4 i \u2212 x \u03c4 \u22121 i 2 + E x r\u22121,Q i \u2212 x r\u22121,Q\u22121 i 2 \uf8f9 \uf8fb .\n(103)\n\n\nG.3.1 Proof of Lemma 10\n\nLet us first express the difference of the local AL as following:\nL i (x r+1 i , x r+1 0,i , \u03bb r+1 i ) \u2212 L i (x r i , x r 0,i , \u03bb r i ) (104) = L i (x r+1 i , x r 0,i , \u03bb r i ) \u2212 L i (x r i , x r 0,i , \u03bb r i ) + L i (x r+1 i , x r 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r 0,i , \u03bb r i ) + L i (x r+1 i , x r+1 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r 0,i , \u03bb r+1 i ),\nwhere the above three differences respectively correspond to the three steps in the algorithm's update steps. Let us bound the above three differences one by one. First, note that we have the following decomposition (by using the fact that x r,Q+1 i = x r+1 i and x r,1 i = x r i ):\nL i (x r+1 i , x r 0,i , \u03bb r i ) \u2212 L i (x r i , x r 0,i , \u03bb r i ) = Q q=1 L i (x r,q+1 i , x r 0,i , \u03bb r i ) \u2212 L i (x r,q i , x r 0,i , \u03bb r i ) .(105)\nEach term on the right hand side (RHS) of the above equality can be bounded by (see a similar arguments in (76)):\nL i (x r,q+1 i , x r 0,i , \u03bb r i )\u2212L i (x r,q i , x r 0,i , \u03bb r i ) \u2264 \u2207f i (x r,q i ) + \u03bb r i + 1 \u03b7 (x r,q+1 \u2212 x r 0,i ), x r,q+1 i \u2212 x r,q i \u2212 1 \u2212 L\u03b7 2\u03b7 x r,q+1 i \u2212 x r,q i 2 (a) = \u2207f i (x r,q i ) \u2212 g r,q i \u2212 1 \u03b3 (x r,q+1 \u2212 x r,q i ), x r,q+1 i \u2212 x r,q i \u2212 ( 1 2\u03b7 \u2212 L 2 ) x r,q+1 i \u2212 x r,q i 2 = \u2207f i (x r,q i ) \u2212 g r,q i , x r,q+1 i \u2212 x r,q i \u2212 ( 1 2\u03b7 + 1 \u03b3 \u2212 L 2 ) x r,q+1 i \u2212 x r,q i 2 (b) \u2264 1 2L \u2207f i (x r,q i ) \u2212 g r,q i 2 \u2212 ( 1 2\u03b7 + 1 \u03b3 \u2212 L) x r,q+1 i \u2212 x r,q i 2 ,(106)\nwhere in (a) we use the optimal condition that \u2207 x iL i (x r,q+1\n\ni , x r 0,i , \u03bb r i ; x r,q i , g r,q i ) = 0 which gives us the following relation\n\u03bb r i + 1 \u03b7 (x r,q+1 i \u2212 x r 0,i ) + g r,q i + 1 \u03b3 (x r,q+1 i \u2212 x r,q i ) = 0;(107)\nin (b) we use the fact that 2 a, b \u2264 L a 2 + 1 L b 2 . Therefore, the first difference in the RHS of (104) is given by\nL i (x r+1 i , x r 0,i , \u03bb r i ) \u2212 L i (x r i , x r 0,i , \u03bb r i ) \u2264 1 2L Q q=1 \u2207f i (x r,q i ) \u2212 g r,q i 2 \u2212 ( 1 2\u03b7 + 1 \u03b3 \u2212 L) Q q=1 x r,q+1 i \u2212 x r,q i 2 .(108)\nThe other two differences in (104) can be explicitly expressed as:\nL i (x r+1 i , x r 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r 0,i , \u03bb r i ) = \u03b7 \u03bb r+1 i \u2212 \u03bb r i 2 ,(109)L i (x r+1 i , x r+1 0,i , \u03bb r+1 i ) \u2212 L i (x r+1 i , x r 0,i , \u03bb r+1 i ) = \u2212 1 2\u03b7 x r+1 0,i \u2212 x r 0,i 2 + \u03bb r+1 i + 1 \u03b7 (x r+1 i \u2212 x r+1 0,i ), x r+1 0,i \u2212 x r 0,i .(110)\nNext we bound \u03bb r+1 i \u2212 \u03bb r i 2 . Notice that the from the update rule the following holds:\n\u03bb r+1 i = \u03bb r i + 1 \u03b7 (x r,Q i \u2212 x r 0,i ) (107) = \u2212 1 \u03b3 (x r,Q i \u2212 x r,Q\u22121 i ) \u2212 g r,Q\u22121 .(111)\nUsing the above property, we have\n\u03bb r+1 i \u2212 \u03bb r i 2 = 1 \u03b3 (x r,Q i \u2212 x r,Q\u22121 i ) + g r,Q\u22121 i \u2212 1 \u03b3 (x r\u22121,Q i \u2212 x r\u22121,Q\u22121 i ) \u2212 g r\u22121,Q\u22121 i 2 (a) \u2264 3 g r,Q\u22121 i \u2212 g r\u22121,Q\u22121 i 2 + 3 \u03b3 2 x r,Q i \u2212 x r,Q\u22121 i 2 + 3 \u03b3 2 x r\u22121,Q i \u2212 x r\u22121,Q\u22121 i 2 .(112)\nwhere in (a) we apply Cauchy-Schwarz inequality. Next we bound g r,Q\u22121\ni \u2212 g r\u22121,Q\u22121 i 2 by g r,Q\u22121 i \u2212 g r\u22121,Q\u22121 i 2 = g r,Q\u22121 i \u2212 \u2207f i (x r,Q\u22121 i ) + \u2207f i (x r,Q\u22121 i ) \u2212 \u2207f i (x r\u22121,Q\u22121 i ) + \u2207f i (x r\u22121,Q\u22121 i ) \u2212 g r\u22121,Q\u22121 i 2 (a) \u2264 3 g r,Q\u22121 i \u2212 \u2207f i (x r,Q\u22121 i ) 2 + 3 g r\u22121,Q\u22121 i \u2212 \u2207f i (x r\u22121,Q\u22121 i ) 2 + 3L 2 x r,Q\u22121 i \u2212 x r\u22121,Q\u22121 i 2 (b) \u2264 3 g r,Q\u22121 i \u2212 \u2207f i (x r,Q\u22121 i ) 2 + 3 g r\u22121,Q\u22121 i \u2212 \u2207f i (x r\u22121,Q\u22121 i ) 2 + 3Q 2 L 2 Q\u22121 q=1 x r,q i \u2212 x r,q\u22121 i 2 + 3Q 2 L 2 x r\u22121,Q i \u2212 x r\u22121,Q\u22121 i 2 ,\nwhere in (a) and (b) we both apply Cauchy-Schwarz inequality, in (a) we use A1 to the last term and in (b) we notice x r\u22121,Q i = x r,0 i . Substitute (113) to (112) and sum the three parts, we have\nL i (x r+1 i , x r+1 0,i , \u03bb r+1 i ) \u2212 L i (x r i , x r 0,i , \u03bb r i ) \u2264 \u2212 1 2\u03b7 x r+1 0,i \u2212 x r 0,i 2 \u2212 ( 1 2\u03b7 + 1 \u03b3 \u2212 L \u2212 3\u03b7 \u03b3 2 ) x r,Q i \u2212 x r,Q\u22121 i 2 \u2212 ( 1 2\u03b7 + 1 \u03b3 \u2212 L \u2212 9Q 2 L 2 \u03b7) Q\u22121 q=1 x r,q i \u2212 x r,q\u22121 i 2 + (9Q 2 L 2 \u03b7 + 3\u03b7 \u03b3 2 ) x r\u22121,Q i \u2212 x r\u22121,Q\u22121 i 2 + 1 2L Q\u22122 q=0 \u2207f i (x r,q i ) \u2212 g r,q i 2 + ( 1 2L + 9\u03b7) g r,Q\u22121 i \u2212 \u2207f i (x r,Q\u22121 i ) 2 + 9\u03b7 g r\u22121,Q\u22121 i \u2212 \u2207f i (x r\u22121,Q\u22121 i ) 2 + \u03bb r+1 i + 1 \u03b7 (x r+1 i \u2212 x r+1 0,i ), x r+1 0,i \u2212 x r 0,i ,\nwhich complete the proof of Lemma 10.\n\n\nG.3.2 Proof of Lemma 11\n\nTo study E g r,q i \u2212 \u2207f i (x r,q i ) 2 , we denote the latest iteration before r that computes full gradients as r 0 .\n\nThat is, in r 0 we have g r 0 ,0 i = \u2207f i (x r 0 ,0 i ). By the description of the algorithm we know\nr 0 = kI, k \u2208 N, rQ + q \u2212 r 0 Q \u2264 IQ.\nThat is, r 0 is a multiple of I and there is no more than IQ local update steps between step {r 0 , 0} and step {r, q}. By the update rule of g r,q i , we have\ng r,q+1 i \u2212 \u2207f i (x r,q+1 i ) =g r,q i \u2212 \u2207f i (x r,q+1 i ) + 1 B B b=1 (h i (x r,q+1 i ; \u03be r,q i,b ) \u2212 h i (x r,q i ; \u03be r,q i,b )).(113)\nTake expectation on both sides, we have \nE {\u03be r,q i,b } B b=1 [g r,q+1 i \u2212 \u2207f i (x r,q+1 i )] = g r,q i \u2212 \u2207f i (x r,q+1 i ) + E {\u03be r,q i,b } B b=1 [ 1 B B b=1 (h i (x r,q+1 i ; \u03be r,q i,b ) \u2212 h i (x r,q i ; \u03be r,q i,b ))] = g r,q i \u2212 \u2207f i (x r,q+1 i ) + \u2207f i (x r,q+1 i ) \u2212 \u2207f i (x r,q i ) = g r,q i \u2212 \u2207f i (x r,q i ).E {\u03be r,q i,b } B b=1 g r,q+1 i \u2212 \u2207f i (x r,q+1 i ) 2 = E {\u03be r,q i,b } B b=1 [g r,q+1 i \u2212 \u2207f i (x r,q+1 i )] 2 + E {\u03be r,q i,b } B b=1 g r,q+1 i \u2212 \u2207f i (x r,q+1 i ) \u2212 E {\u03be r,q i,b } B b=1 [g r,q+1 i \u2212 \u2207f i (x r,q+1 i )] 2 (114) = g r,q i \u2212 \u2207f i (x r,q i ) 2 + E {\u03be r,q i,b } B b=1 1 B B b=1 (h i (x r,q+1 i ; \u03be r,q i,b \u2212 h i (x r,q i ; \u03be r,q i,b )) \u2212 \u2207f i (x r,q+1 i ) + \u2207f i (x r,q i ) 2 (a) \u2264 g r,q i \u2212 \u2207f i (x r,q i ) 2 + 1 B 2 B b=1 E {\u03be r,q i,b } B b=1 h i (x r,q+1 i ; \u03be r,q i,b ) \u2212 h i (x r,q i ; \u03be r,q i,b )) 2 (b) \u2264 g r,q i \u2212 \u2207f i (x r,q i ) 2 + L 2 B x r,q+1 i \u2212 x r,q i 2 ,\nwhere (a) comes form the fact that we view h i (x r,q+1\ni ; \u03be r,q i,b ) \u2212 h i (x r,q i ; \u03be r,q i,b\n) as X and by identically random sampling strategy we have\nE X = \u2207f i (x r,q+1 i ) \u2212 \u2207f i (x r,q i ) and E[[X \u2212 E X] 2 \u2264 E[X] 2 , in (b) we use A1. Iteratively taking expectation until {r, q} = {r 0 , 0}, we have E g r,q+1 i \u2212 \u2207f i (x r,q+1 i ) 2 \u2264 L 2 B {r,q+1} \u03c4 ={r 0 ,1} E x \u03c4 i \u2212 x \u03c4 \u22121 i 2 ,(114)\nwhich completes the proof.\n\n\nG.3.3 Proof of Lemma 12\n\nApplying A1, we have\nf i (x r 0 ) \u2264 f i (x r i ) + \u2207f i (x r i ), x r 0 \u2212 x r i + L 2 x r 0 \u2212 x r i 2 = L i (x r i , x r 0 , \u03bb r i ) \u2212 \u2207f i (x r i ) + \u03bb r i , x r 0 \u2212 x r i \u2212 1 \u2212 L\u03b7 2\u03b7 x r 0 \u2212 x r i 2 \u2264 L i (x r i , x r 0 , \u03bb r i ) + 1 4L \u2207f i (x r i ) + \u03bb r i 2 \u2212 1 \u2212 3L\u03b7 2\u03b7 x r 0 \u2212 x r i 2 .(115)1 N N i=1 \u2207 x 0,i L i (x r i , x r 0,i , \u03bb r i ) = 1 N N i=1 ( 1 \u03b7 (x r i \u2212 x r 0,i ) + \u03bb r i ) = 0.\nWe also have\n\u2207L i (x r i , x r 0,i , \u03bb r i ) 2 = \u2207 x i L i (x r i , x r 0,i , \u03bb r i ) 2 + \u2207 \u03bb i L i (x r i , x r 0,i , \u03bb r i ) 2 = \u2207f i (x r i ) + \u03bb r i + 1 \u03b7 (x r i \u2212 x r 0,i ) 2 + x r i \u2212 x r 0,i 2 (a) = \u2207f i (x r i ) \u2212 g r,0 i \u2212 \u03b7 + \u03b3 \u03b7\u03b3 (x r,1 i \u2212 x r i ) 2 + x r i \u2212 x r 0,i + x r\u22121 0,i \u2212 x r\u22121 0,i 2 \u2264 \u2207f i (x r i ) \u2212 g r,0 i \u2212 \u03b7 + \u03b3 \u03b7\u03b3 (x r,1 i \u2212 x r i ) the following 1 N N i=1 E[L i (x T i , x T 0,i , \u03bb T i ) \u2212 L i (x 0 i , x 0 0,i , \u03bb 0 i )] \u2264 \u2212 1 2\u03b7 T \u22121 r=0 E x r+1 0 \u2212 x r 0 2 \u2212 ( 1 2\u03b7 + 1 \u03b3 \u2212 L \u2212 6\u03b7 \u03b3 2 \u2212 9Q 2 L 2 \u03b7) 1 N N i=1 Q\u22121 q=0 T \u22121 r=0 E x r,q+1 i \u2212 x r,q\u22121 i 2 + ( 1 2L + 18\u03b7) 1 N N i=1 T \u22121 r=0 Q\u22121 q=0 E \u2207f i (x r,q i ) \u2212 g r,q i 2 + T \u22121 r=0 1 N E N i=1 (\u03bb r+1 i + 1 \u03b7 (x r+1 i \u2212 x r+1 0,i )), x r+1 0,i \u2212 x r 0,i (a) \u2264 \u2212 ( 1 2\u03b7 + 1 \u03b3 \u2212 L \u2212 6\u03b7 \u03b3 2 \u2212 9Q 2 L 2 \u03b7) 1 N N i=1 Q\u22121 q=0 T \u22121 r=0 E x r,q+1 i \u2212 x r,q\u22121 i 2 \u2212 1 2\u03b7 T \u22121 r=0 E x r+1 0 \u2212 x r 0 2 + (1 + 18L\u03b7)LIQ 2B 1 N N i=1 T \u22121 r=0 Q\u22121 q=0 E x r,q+1 i \u2212 x r,q\u22121 i 2 = \u2212 C 10 N N i=1 Q\u22121 q=0 T \u22121 r=0 E x r,q+1 i \u2212 x r,q\u22121 i 2 \u2212 1 2\u03b7 T \u22121 r=0 E x r+1 0 \u2212 x r 0 2 ,(117)\nwhere in (a) we apply Lemma 11 and (87). Finally, in the last equation of (117), we have defined the constant C 10 as\nC 10 := 1 2\u03b7 + 1 \u03b3 \u2212 L \u2212 6\u03b7 \u03b3 2 \u2212 9Q 2 L 2 \u03b7 \u2212 (1 + 18L\u03b7)LIQ 2B .\nThen by taking expectation and applying Lemma 12, we obtain\nE[f (x T 0 ) \u2212 f (x 0 0 )] \u2264 \u2212 C 10 \u2212 (1+L\u03b3) 2 +L 2 \u03b3 2 4BL\u03b3 2 N N i=1 Q\u22121 q=0 T \u22121 r=0 E x r,q+1 i \u2212 x r,q\u22121 i 2 \u2212 1 2\u03b7 T \u22121 r=0 E x r+1 0 \u2212 x r 0 2 ,\nwhere by the initialization that (117) and (118), we can find a positive constant C 11 satisfying\nx 0 i = x 0 0 we have f ( x 0 0 ) = 1 N N i=1 L i (x 0 i , x 0 0,i , \u03bb 0 i ). CombineC 11 \u2264 min C 12 /C 13 , 1/(4\u03b7) ,(118)\nwhere we have defined\nC 12 C 10 \u2212 (1 + L\u03b3) 2 + L 2 \u03b3 2 4BL\u03b3 2 , C 13 Q 2( \u03b7 + \u03b3 \u03b7\u03b3 ) 2 + 2I(1 + 18\u03b7 2 )L 2 B + 3L(1 + 9L\u03b7)\u03b7 2 2B\u03b3 2 + 18Q 2 L 2 \u03b7 2(119)\nso that the following holds\nC 11 N T T r=0 N i=1 E \u2207L i (x r i , x r 0,i , \u03bb r i ) 2 \u2264 C 10 \u2212 (1+L\u03b3) 2 +L 2 \u03b3 2 4BL\u03b3 2 N T N i=1 Q\u22121 q=0 T \u22121 r=0 E x r,q+1 i \u2212 x r,q\u22121 i 2 + 1 2\u03b7T T \u22121 r=0 E x r+1 0 \u2212 x r 0 2 \u2264 1 T (f (x 0 0 ) \u2212 E f (x T 0 )) \u2264 1 T (f (x 0 0 ) \u2212 f (x )).(120)\nSimilar to the proof of Theorem 1, we can bound \u2207f (x r 0 ) 2 by 1\nN N i=1 \u2207L i (x r i , x r 0 , \u03bb r i ) 2 , therefore Theorem 3 is proved.\nDuring the prove we need\nC 9 = 4L 2 /C 11 , C 10 = 1 2\u03b7 + 1 \u03b3 \u2212 L \u2212 6\u03b7 \u03b3 2 \u2212 9Q 2 L 2 \u03b7 \u2212 (1 + 18L\u03b7)LIQ 2B , C 11 \u2264 min \uf8f1 \uf8f2 \uf8f3 C 10 \u2212 (1+L\u03b3) 2 +L 2 \u03b3 2 4BL\u03b3 2 Q 2( \u03b7+\u03b3 \u03b7\u03b3 ) 2 + 2I(1+18\u03b7 2 )L 2 B + 3L(1+9L\u03b7)\u03b7 2 2B\u03b3 2 + 18Q 2 L 2 \u03b7 2 , 1 4\u03b7 \uf8fc \uf8fd \uf8fe\nto be positive constant. By selecting \u03b3 > 5 B \u221a L \u03b7, and 0 < \u03b7 < \n\n\nH Additional Numerical Results\n\n\nH.1 Penalized Logistic Regression\n\nIn this experiment, we consider the penalized regression problem [30], whose loss function evaluated on a single sample (a, b) = \u03be is given by: In the experiment, we use two ways to generate the data. In the first case (referred to as the \"weakly non-i.i.d\" case), the features and the labels on the agents are randomly generated, so the local data sets are not very non-i.i.d. In the second case (referred to as the \"strong non-i.i.d.\" case), we first generate the feature vector a's following the standard Normal distribution, then we generate the local model x i on the i th agent by using uniform distribution in the range of [\u221210, 10] for each component. Then we compute the label b's according to the local models and the features and add some uniform noise. In this case, the data distribution on the agents are more non-i.i.d. compared to the first case. In both cases, there are 400 samples on each agent with total 100 agents.\n\nThe total number of iterations T is set as 600 for all algorithms. We choose the stepsize to be \u03b7 = 4 for FedAvg-GD with local update number Q = 8 and for FedAvg-SGD we use diminishing stepsize \u03b7 = 4/ \u221a Qr + q + 1 with Q = 600. For FedProx we use VR algorithm as the local solver and set Q = 8, \u03c1 = 1 and stepsize \u03b7 = 4. For FedPD, we also use the same stepsize \u03b7 = 4 with Q = 8 with local GD. For FedPD-SGD, we also set \u03b7 = 4 and uses local step size \u03b7 1 = 1 Q with inner iteration number Q = 600. Lastly for FedPD with VR, we set the parameters to be \u03b7 = 4, \u03b3 = 4, I = 100, Q = 2 and B = 1. The choice of the stepsize is the same among all the algorithms. We used grid search on stepsizes \u03b7 \u2208 {5, 2, 1, 0.1, 0.01} and the relative performance of the algorithms are similar to what we will show shortly.   Fig. 4 shows the convergence results of the penalized logistic regression problem with the first data set. In Fig. 4(a), we compare the convergence of the tested algorithms w.r.t the communication rounds. It is clear that FedProx and FedPD with R = 1 (i.e., no communication skipping) are comparable. Meanwhile, FedAvg with local GD will not converge to the stationary point with a constant stepsize when local update step Q > 1. By skipping half of the communication, FedPD with local GD can still achieve a similar error as FedAvg, but using fewer communication rounds. In Fig. 4(b), we compare the sample complexity of different algorithms. It can be shown that when using the same number of samples for computation, FedPD with Oracle II (FedPD-VR) converges the fastest among all the algorithms. FedProx uses VR to solve the inner problem and converges the second fastest. Fig 5 shows the convergence results with the strongly non-i.i.d. data set. We can see that the algorithms using stochastic solvers become less stable compared with the case when the data sets are weakly non-i.i.d. Further, FedPD-VR and FedPD-GD with R = 1 are able still to converge to the global stationary point while FedProx will achieve a similar error as the FedAvg with local GD.  \n\n\nH.2 Handwritten Character Classification\n\nIn the second experiment, we compare FedPD with FedAvg and FedProx on the FEMNIST data set [31]. The FEMNIST data set collects the handwritten characters, including numbers 1-10 and the upper-and lower-case letters A-Z and a-z, from different writers and is separated by the writers, therefore the data set naturally preserves non-i.i.d-ness.\n\nThe entire data set contains 805,000 samples collected from 3,550 writers. In our experiments, we use the data collected from 100 writers with an average of 300 samples per writer and the size of the whole data set is 29,214. We set the number of agent N = 90, the first ten agents are assigned with data from two writers, and the rest of the agents are assigned with data form one writer. Therefore, the data distribution is neither i.i.d. nor balanced. We use the neural network given in [31] as the training model, which consists of 2 convolutional layers and two fully connected layers. The output layer has 62 neurons that matches the number of classes in the FEMNIST data set.\n\nThe numerical results shown in Fig. 6 in the main text were generated by running MATLAB codes on Amazon Web Services (AWS), with Intel Xeon E5-2686 v4 CPUs. In the training phase, we train the CNN model with FedAvg, FedProx and FedPD. In Fig. 6(a), for FedAvg, we use gradient descent for Q = 8 local update steps between each communication rounds; to solve the local problem for FedProx, we use SARAH with Q = 20 local steps; we use FedPD with Oracle II, computing full gradient every I = 20 communication rounds and perform Q = 2 local steps between two communication rounds. The hyper-parameters we use for FedAvg is \u03b7 = 0.005; for FedProx we use \u03c1 = 1 and stepsize \u03b7 = 0.01; for FedPD we use \u03b7 = 100 and \u03b3 = 400. In Fig. 6(b), we use FedPD with Oracle I, with Q = 20, \u03b7 = 100 and \u03b3 = 400 and the mini-batch size 2. We set the communication saving to p = 0 and p = 0.5.\n\nThe results shown in Fig. 7 were generated by running Python codes (using the the PyTorch package 1 ) with AMD EPYC 7702 CPUs and an NVIDIA V100 GPU.  In the training phase, we train with FedProx, FedAvg and FedPD with a total T = 1000 outer iterations. The local problems are solved with SGD for Q = 300 local iterations and the mini-batch size in evaluating the stochastic gradient is 2. The stepsize choice for FedAvg, FedProx and FedPD are 0.001, 0.01 and 0.01, the hyper-parameter of FedProx is \u03c1 = 1 and for FedPD \u03b7 = 1. In the experiment, we set the communication saving for FedPD to be p = 0, p = 0.5 and p = 0.25. Note that we also tested FedAvg with larger stepsize 0.01, but the algorithm becomes unstable, and its performance degrages significantly. As shown in Fig. 7 and 8, FedAvg is slower than FedPD and FedProx, while FedProx has similar performance as FedPD when R = 1. Further, we can see that as the frequency of communication of FedPD decreases, the final accuracy decreases and the final loss increases. However, the drop of accuracy is not significant, so FedPD is able to achieve a better performance with the same number of communication rounds.    \n\nA 3 .\n3(Bounded Gradient (BG)) The gradients \u2207f i 's are upper bounded (by a constant G > 0)\n\nA 5 .\n5(\u03b4-Non-I.I.D. Data) The local functions are called \u03b4-non-i.i.d. if either one of the equivalent conditions below holds:\n\n\n, i = 1, . . . , N for r = 0, . . . , T \u2212 1 (stage) do for q = 0, . . . , Q \u2212 1 (iteration) do either Option 1 (Local SGD), for all i or Option 2 (Local GD), for all i end for Global averaging: x r+1 = 1 N N i=1 x r,Q i Update agents' x r+1,0 i = x r+1 , i = 1, . . . , N end for\n\nFigure 1 :\n1Relation of the percentage of comm.\n\n.4L , p = 0 .\n0Suppose A1 -A2 hold. Consider FedPD with Oracle I, where Q i are selected by(12). Case I) Suppose A5 holds with \u03b4 = \u221e. Set 0 Then we have:\n\n0 2 .\n2This fails to converge to the global stationary solution. In contrast, FedPD introduces extra local dual variables {\u03bb i } that record the gap between the local model x i and the global model x 0 which help the global convergence. FedDANE\n\n\ngap of FedAvg, FedProx and FedPD; weakly non-i.i.d. data. (b) Stationary gap of FedAvg, FedProx and FedPD; strongly non-i.i.d. data.\n\nFigure 2 :\n2The convergence result of the algorithms on penalized logistic regression with weakly and strongly non-i.i.d.data with respect to the number of communication rounds.\n\nFigure 3 :\n3The example constructed for proving Claim 2.1. Here each agent has a local length T + 1 vector x i ; each block in the figure represents one dimension of the local vector. If for agent i, its jth block is white it means that f i is not a function of x i [j], while if jth block is shaded means f i is a function of x i [j]. Each dashed red box contains two variables that are coupled together by a function \u0398(\u00b7).\n\n\nObviously, \u03a8(w) is an increasing function over w > 0, therefore the lower and upper bounds are \u03a8(\u221e) (this can be verified by checking the signs of \u03a8 (w) = 4e \u2212w 2 w(2w 2 \u2212 3) in these intervals). Therefore the lower and upper bounds are \u03a8 (\n\n\nsome linear combination of local variables, where {\u03b1 i > 0} are the coefficients (possibly time-varying and dependent on t). Then no matter how many local computation steps (20b) are performed, at least T communication steps (20a) are needed to ensurex[T ] = 0. Proof. For a given j \u2265 2, suppose that x i [j], x i [j + 1], ..., x i [T ] = 0, \u2200i, that is, support{x i } \u2286 {1, 2, 3, ..., j \u2212 1} for all i. Then \u03a8 (x i [j]) = \u03a8 (\u2212x i [j]) = 0 for all i, and g i has the following partial derivative (see (32))\n\nB. 4\n4Main Result for Claim 2.1. Below we state and prove a formal version of Claim 2.1 given in the main text. Theorem 2. Let be a positive number. Let x 0 i [j] = 0 for all i \u2208 [N ]\n\n\nall the terms are positive.\n\nL\n. Then, the following holds (where C 9 > 0 is a constant):\n\nRemark 5 .\n5(Communication complexity): As p = 0, the communication round to achieve accuracy is T = O(1/ ) which is independent of Q. Remark 6. (Computation complexity): Note that the total number full gradient evaluation is T /I + 1, each uses M samples. Meanwhile, the total number of mini-batch stochastic gradient evaluation is T Q, each uses 2B samples per node. So the total sample complexity is O(M + M T /I + 2T QBN ). In order to keep the same convergence speed, we need stepsize \u03b7 to be unchanged. Therefore, we choose I = \u221a M , B = I/QN = \u221a M /QN , then the SC of Algorithm 4 is O(M + \u221a M ).\n\nLemma 10 .\n10Under Assumption 1, consider FedPD with Algorithm 4 (Oracle II) as the update rule. The difference of the local AL is bounded by:\n\nF\n(x; (a, b)) = log(1 + exp(\u2212bx T a)) [d] denotes the d th component of x. The feature vector and model parameter a, x \u2208 R D have dimension D and b \u2208 {\u22121, 1} is the label corresponding to the feature. During the simulation, we set the constants to be \u03b1 = 1 and \u03b2 = 0.1.\n\n\nstationary gap of FedAvg, FedProx and FedPD with respect to the number of communication rounds. (b) The stationary gap of of FedAvg, FedProx and FedPD with respect to the number of samples.\n\nFigure 4 :\n4The convergence result of the algorithms on penalized logistic regression with weakly non-i.i.d. data.\n\n\nstationary gap of FedAvg, FedProx and FedPD with respect to the number of communication rounds. (b) The stationary gap of of FedAvg, FedProx and FedPD with respect to the number of samples.\n\nFigure 5 :\n5The convergence result of the algorithms on penalized logistic regression with strongly non-i.i.d. data.\n\n\ntesting accuracy of FedAvg-GD, FedProx-VR and FedPD-VR with respect to the number of samples. (b) The testing accuracy of FedPD-SGD with R = 1 and R = 2 with respect to the number of communications.\n\nFigure 6 :\n6The convergence result of the algorithms on training neural network for handwriting character classification.\n\n\nloss value of FedAvg-SGD, FedProx-SGD and FedPD-SGD with respect to the number of communication rounds. (b) The training accuracy of of FedAvg-SGD, FedProx-SGD and FedPD-SGD with respect to the number of communication rounds.\n\nFigure 7 :\n7The convergence results of the algorithms on training neural networks on the federated handwritten characters classification problem.\n\n\ntesting loss value of FedAvg-SGD, FedProx-SGD and FedPD-SGD with respect to the number of communication rounds. (b) The testing accuracy of of FedAvg-SGD, FedProx-SGD and FedPD-SGD with respect to the number of communication rounds.\n\nFigure 8 :\n8The convergence results of the algorithms on training neural networks on the federated handwritten characters classification problem with test data set.\n\nTable 1 :\n1Convergence rates of FL algorithms, measured by total rounds of communication (RC), number of local updates\n\nTable 2 :\n2The relation between p and \u03b4 2\n\n\nBy using the fact that E[X 2 ] = [E X] 2 + E[[X \u2212 E X] 2 ] and substitute (114) we have\n= /(2C 4 ), and the total communication rounds is T .\nPyTorch: An Imperative Style, High-Performance Deep Learning Library, https://pytorch.org/\n\nFederated learning: Strategies for improving communication efficiency. Jakub Kone\u010dn\u1ef3, Brendan Mcmahan, X Felix, Peter Yu, Ananda Richt\u00e1rik, Dave Theertha Suresh, Bacon, arXiv:1610.05492arXiv preprintJakub Kone\u010dn\u1ef3, H Brendan McMahan, Felix X Yu, Peter Richt\u00e1rik, Ananda Theertha Suresh, and Dave Bacon, \"Federated learning: Strategies for improving communication efficiency,\" arXiv preprint arXiv:1610.05492, 2016.\n\nFederated learning: Challenges, methods, and future directions. Tian Li, Anit Kumar Sahu, Ameet Talwalkar, Virginia Smith, arXiv:1908.07873arXiv preprintTian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith, \"Federated learning: Challenges, methods, and future directions,\" arXiv preprint arXiv:1908.07873, 2019.\n\nOn the linear speedup analysis of communication efficient momentum SGD for distributed non-convex optimization. Hao Yu, Rong Jin, Sen Yang, PMLRProceedings of the 36th International Conference on Machine Learning. Kamalika Chaudhuri and Ruslan Salakhutdinovthe 36th International Conference on Machine LearningLong Beach, California, USA97of Proceedings of Machine Learning ResearchHao Yu, Rong Jin, and Sen Yang, \"On the linear speedup analysis of communication efficient momentum SGD for distributed non-convex optimization,\" in Proceedings of the 36th International Conference on Machine Learning, Kamalika Chaudhuri and Ruslan Salakhutdinov, Eds., Long Beach, California, USA, 09-15 Jun 2019, vol. 97 of Proceedings of Machine Learning Research, pp. 7184-7193, PMLR.\n\nLocal sgd converges fast and communicates little. Stich Sebastian Urban, ICLR 2019 -International Conference on Learning Representations. 17Sebastian Urban Stich, \"Local sgd converges fast and communicates little,\" ICLR 2019 -International Conference on Learning Representations, p. 17, 2019.\n\nCooperative SGD: A unified framework for the design and analysis of communication-efficient sgd algorithms. Jianyu Wang, Gauri Joshi, arXiv:1808.07576arXiv preprintJianyu Wang and Gauri Joshi, \"Cooperative SGD: A unified framework for the design and analysis of communication-efficient sgd algorithms,\" arXiv preprint arXiv:1808.07576, 2018.\n\nIn-edge AI: Intelligentizing mobile edge computing, caching and communication by federated learning. X Wang, Y Han, C Wang, Q Zhao, X Chen, M Chen, IEEE Network. 335X. Wang, Y. Han, C. Wang, Q. Zhao, X. Chen, and M. Chen, \"In-edge AI: Intelligentizing mobile edge computing, caching and communication by federated learning,\" IEEE Network, vol. 33, no. 5, pp. 156-165, Sep. 2019.\n\nFederated multi-task learning. Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, Ameet S Talwalkar, Advances in Neural Information Processing Systems. I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. GarnettCurran Associates, Inc30Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar, \"Federated multi-task learning,\" in Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds., pp. 4424-4434. Curran Associates, Inc., 2017.\n\nTowards federated learning at scale: System design. Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konecny, Stefano Mazzocchi, H Brendan Mcmahan, arXiv:1902.01046arXiv preprintKeith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konecny, Stefano Mazzocchi, H Brendan McMahan, et al., \"Towards federated learning at scale: System design,\" arXiv preprint arXiv:1902.01046, 2019.\n\nXiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, Zhihua Zhang, arXiv:1907.02189On the convergence of fedavg on non-iid data. arXiv preprintXiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang, \"On the convergence of fedavg on non-iid data,\" arXiv preprint arXiv:1907.02189, 2019.\n\nCan decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent. Xiangru Lian, Ce Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, Ji Liu, Advances in Neural Information Processing Systems. Xiangru Lian, Ce Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, and Ji Liu, \"Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent,\" in Advances in Neural Information Processing Systems, 2017.\n\nWhen edge meets learning: Adaptive control for resource-constrained distributed machine learning. Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, K Kin, Christian Leung, Ting Makaya, Kevin He, Chan, IEEE INFOCOM 2018-IEEE Conference on Computer Communications. IEEEShiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung, Christian Makaya, Ting He, and Kevin Chan, \"When edge meets learning: Adaptive control for resource-constrained distributed machine learning,\" in IEEE INFOCOM 2018-IEEE Conference on Computer Communications. IEEE, 2018, pp. 63-71.\n\nOn the convergence of federated optimization in heterogeneous networks. Anit Kumar Sahu, Tian Li, Maziar Sanjabi, Manzil Zaheer, Ameet Talwalkar, Virginia Smith, arXiv:1812.06127arXiv preprintAnit Kumar Sahu, Tian Li, Maziar Sanjabi, Manzil Zaheer, Ameet Talwalkar, and Virginia Smith, \"On the convergence of federated optimization in heterogeneous networks,\" arXiv preprint arXiv:1812.06127, 2018.\n\nParallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning. Hao Yu, Sen Yang, Shenghuo Zhu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence33Hao Yu, Sen Yang, and Shenghuo Zhu, \"Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning,\" in Proceedings of the AAAI Conference on Artificial Intelligence, 2019, vol. 33, pp. 5693-5700.\n\nTrading redundancy for communication: Speeding up distributed SGD for non-convex optimization. Farzin Haddadpour, Mohammad Mahdi Kamani, Mehrdad Mahdavi, Viveck Cadambe, PMLRProceedings of the 36th International Conference on Machine Learning. Kamalika Chaudhuri and Ruslan Salakhutdinovthe 36th International Conference on Machine LearningLong Beach, California, USA97of Proceedings of Machine Learning ResearchFarzin Haddadpour, Mohammad Mahdi Kamani, Mehrdad Mahdavi, and Viveck Cadambe, \"Trading redundancy for communication: Speeding up distributed SGD for non-convex optimization,\" in Proceedings of the 36th International Conference on Machine Learning, Kamalika Chaudhuri and Ruslan Salakhutdinov, Eds., Long Beach, California, USA, 09-15 Jun 2019, vol. 97 of Proceedings of Machine Learning Research, pp. 2545-2554, PMLR.\n\nFirst analysis of local GD on heterogeneous data. Ahmed Khaled, Konstantin Mishchenko, Peter Richt\u00e1rik, arXiv:1909.04715arXiv preprintAhmed Khaled, Konstantin Mishchenko, and Peter Richt\u00e1rik, \"First analysis of local GD on heterogeneous data,\" arXiv preprint arXiv:1909.04715, 2019.\n\nVariance reduced local SGD with lower communication complexity. Xianfeng Liang, Shuheng Shen, Jingchang Liu, Zhen Pan, Enhong Chen, Yifei Cheng, arXiv:1912.12844arXiv preprintXianfeng Liang, Shuheng Shen, Jingchang Liu, Zhen Pan, Enhong Chen, and Yifei Cheng, \"Variance reduced local SGD with lower communication complexity,\" arXiv preprint arXiv:1912.12844, 2019.\n\nConvergence of distributed stochastic variance reduced methods without sampling extra data. Huishuai Shicong Cen, Yuejie Zhang, Wei Chi, Tie-Yan Chen, Liu, arXiv:1905.12648arXiv preprintShicong Cen, Huishuai Zhang, Yuejie Chi, Wei Chen, and Tie-Yan Liu, \"Convergence of distributed stochastic variance reduced methods without sampling extra data,\" arXiv preprint arXiv:1905.12648, 2019.\n\nParallel restarted spider-communication efficient distributed nonconvex optimization with optimal computation complexity. Pranay Sharma, Prashant Khanduri, Saikiran Bulusu, Ketan Rajawat, Pramod K Varshney, arXiv:1912.06036arXiv preprintPranay Sharma, Prashant Khanduri, Saikiran Bulusu, Ketan Rajawat, and Pramod K Varshney, \"Parallel restarted spider-communication efficient distributed nonconvex optimization with optimal computation complexity,\" arXiv preprint arXiv:1912.06036, 2019.\n\niDLG: Improved deep leakage from gradients. Bo Zhao, Konda Reddy Mopuri, Hakan Bilen, Bo Zhao, Konda Reddy Mopuri, and Hakan Bilen, \"iDLG: Improved deep leakage from gradients,\" 2020.\n\nIntroductory lectures on convex optimization: A basic course. Y Nesterov, SpringerY. Nesterov, Introductory lectures on convex optimization: A basic course, Springer, 2004.\n\nLower bounds for finding stationary points i. Y Carmon, J C Duchi, O Hinder, A Sidford, Mathematical Programming. Y. Carmon, J. C. Duchi, O. Hinder, and A. Sidford, \"Lower bounds for finding stationary points i,\" Mathematical Programming, Jun 2019.\n\nOptimal algorithms for smooth and strongly convex distributed optimization in networks. K Scaman, F Bach, S Bubeck, Y Lee, L Massouli\u00e9, arXiv:1702.08704arXiv preprintK. Scaman, F. Bach, S. Bubeck, Y. Lee, and L. Massouli\u00e9, \"Optimal algorithms for smooth and strongly convex distributed optimization in networks,\" arXiv preprint arXiv:1702.08704, 2017.\n\nDistributed non-convex first-order optimization and information processing: Lower complexity bounds and rate optimal algorithms. H Sun, M Hong, IEEE Transactions on Signal processing. accepted for publicationH. Sun and M. Hong, \"Distributed non-convex first-order optimization and information processing: Lower complexity bounds and rate optimal algorithms,\" IEEE Transactions on Signal processing, July 2019, accepted for publication.\n\nDistributed optimization and statistical learning via the alternating direction method of multipliers. S Boyd, N Parikh, E Chu, B Peleato, J Eckstein, Foundations and Trends in Machine Learning. 31S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, \"Distributed optimization and statistical learning via the alternating direction method of multipliers,\" Foundations and Trends in Machine Learning, vol. 3, no. 1, pp. 1-122, 2011.\n\nAn empirical study of learning rates in deep neural networks for speech recognition. Andrew Senior, Georg Heigold, Marc&apos;aurelio Ranzato, Ke Yang, 2013 IEEE international conference on acoustics, speech and signal processing. IEEEAndrew Senior, Georg Heigold, Marc'Aurelio Ranzato, and Ke Yang, \"An empirical study of learning rates in deep neural networks for speech recognition,\" in 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013, pp. 6724-6728.\n\nStochastic gradient descent with finite samples sizes. K Yuan, B Ying, S Vlaski, A H Sayed, 2016 IEEE 26th International Workshop on Machine Learning for Signal Processing. K. Yuan, B. Ying, S. Vlaski, and A. H. Sayed, \"Stochastic gradient descent with finite samples sizes,\" in 2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP), Sep. 2016, pp. 1-6.\n\nFedDANE: A federated newton-type method. Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, Virginia Smith, arXiv:2001.01920arXiv preprintTian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith, \"FedDANE: A federated newton-type method,\" arXiv preprint arXiv:2001.01920, 2020.\n\nLAG: Lazily aggregated gradient for communication-efficient distributed learning. Tianyi Chen, Georgios Giannakis, Tao Sun, Wotao Yin, Advances in Neural Information Processing Systems. S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. GarnettCurran Associates, Inc31Tianyi Chen, Georgios Giannakis, Tao Sun, and Wotao Yin, \"LAG: Lazily aggregated gradient for communication-efficient distributed learning,\" in Advances in Neural Information Processing Systems 31, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, Eds., pp. 5050-5060. Curran Associates, Inc., 2018.\n\nCOLA: Communication-censored linearized admm for decentralized consensus optimization. W Li, Y Liu, Z Tian, Q Ling, ICASSP 2019 -2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). W. Li, Y. Liu, Z. Tian, and Q. Ling, \"COLA: Communication-censored linearized admm for decentralized consensus optimization,\" in ICASSP 2019 -2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), May 2019, pp. 5237-5241.\n\nPenalized likelihood regression for generalized linear models with non-quadratic penalties. Anestis Antoniadis, Ir\u00e8ne Gijbels, Mila Nikolova, Annals of the Institute of Statistical Mathematics. 633Anestis Antoniadis, Ir\u00e8ne Gijbels, and Mila Nikolova, \"Penalized likelihood regression for generalized linear models with non-quadratic penalties,\" Annals of the Institute of Statistical Mathematics, vol. 63, no. 3, pp. 585-615, 2011.\n\nLeaf: A benchmark for federated settings. Sebastian Caldas, Peter Wu, Tian Li, Jakub Kone\u010dn\u1ef3, Brendan Mcmahan, Virginia Smith, Ameet Talwalkar, arXiv:1812.01097arXiv preprintSebastian Caldas, Peter Wu, Tian Li, Jakub Kone\u010dn\u1ef3, H Brendan McMahan, Virginia Smith, and Ameet Talwalkar, \"Leaf: A benchmark for federated settings,\" arXiv preprint arXiv:1812.01097, 2018\n", "annotations": {"author": "[{\"end\":116,\"start\":103},{\"end\":129,\"start\":117},{\"end\":144,\"start\":130},{\"end\":155,\"start\":145},{\"end\":165,\"start\":156}]", "publisher": null, "author_last_name": "[{\"end\":115,\"start\":110},{\"end\":128,\"start\":124},{\"end\":143,\"start\":137},{\"end\":154,\"start\":151},{\"end\":164,\"start\":161}]", "author_first_name": "[{\"end\":109,\"start\":103},{\"end\":123,\"start\":117},{\"end\":136,\"start\":130},{\"end\":150,\"start\":145},{\"end\":160,\"start\":156}]", "author_affiliation": null, "title": "[{\"end\":88,\"start\":1},{\"end\":253,\"start\":166}]", "venue": null, "abstract": "[{\"end\":5301,\"start\":267}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5396,\"start\":5393},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6258,\"start\":6255},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7218,\"start\":7215},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7471,\"start\":7468},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8368,\"start\":8365},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8681,\"start\":8678},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8683,\"start\":8681},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8859,\"start\":8856},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8861,\"start\":8859},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8863,\"start\":8861},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8865,\"start\":8863},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8867,\"start\":8865},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8869,\"start\":8867},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9289,\"start\":9286},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9383,\"start\":9379},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9386,\"start\":9383},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9398,\"start\":9395},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9559,\"start\":9555},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9603,\"start\":9600},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10257,\"start\":10254},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":11785,\"start\":11782},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11804,\"start\":11801},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11817,\"start\":11813},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11819,\"start\":11817},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11839,\"start\":11835},{\"end\":12209,\"start\":12205},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":12502,\"start\":12499},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":12684,\"start\":12681},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12694,\"start\":12691},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13282,\"start\":13279},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":13322,\"start\":13318},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13416,\"start\":13412},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13460,\"start\":13457},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14065,\"start\":14062},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":14068,\"start\":14065},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":14530,\"start\":14526},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":14671,\"start\":14668},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":14701,\"start\":14697},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":14898,\"start\":14894},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15094,\"start\":15090},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":15510,\"start\":15506},{\"end\":16806,\"start\":16802},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":17002,\"start\":16999},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17745,\"start\":17742},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":18652,\"start\":18648},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":20848,\"start\":20844},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":23908,\"start\":23904},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":24336,\"start\":24332},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":24938,\"start\":24934},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24995,\"start\":24991},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":25351,\"start\":25347},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":25365,\"start\":25361},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25708,\"start\":25704},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":26470,\"start\":26466},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":31804,\"start\":31800},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31807,\"start\":31804},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":31830,\"start\":31826},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":31833,\"start\":31830},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":36547,\"start\":36543},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":43725,\"start\":43721},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":44984,\"start\":44981},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":45504,\"start\":45501},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":45715,\"start\":45712},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":46994,\"start\":46990},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":47483,\"start\":47479},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":49246,\"start\":49243},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":75724,\"start\":75720},{\"end\":83694,\"start\":83677},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":85291,\"start\":85287},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":88371,\"start\":88367},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":89114,\"start\":89110},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":92002,\"start\":91998}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":91446,\"start\":91353},{\"attributes\":{\"id\":\"fig_1\"},\"end\":91574,\"start\":91447},{\"attributes\":{\"id\":\"fig_2\"},\"end\":91856,\"start\":91575},{\"attributes\":{\"id\":\"fig_3\"},\"end\":91905,\"start\":91857},{\"attributes\":{\"id\":\"fig_4\"},\"end\":92060,\"start\":91906},{\"attributes\":{\"id\":\"fig_5\"},\"end\":92306,\"start\":92061},{\"attributes\":{\"id\":\"fig_6\"},\"end\":92441,\"start\":92307},{\"attributes\":{\"id\":\"fig_7\"},\"end\":92620,\"start\":92442},{\"attributes\":{\"id\":\"fig_8\"},\"end\":93046,\"start\":92621},{\"attributes\":{\"id\":\"fig_9\"},\"end\":93289,\"start\":93047},{\"attributes\":{\"id\":\"fig_10\"},\"end\":93798,\"start\":93290},{\"attributes\":{\"id\":\"fig_11\"},\"end\":93983,\"start\":93799},{\"attributes\":{\"id\":\"fig_12\"},\"end\":94013,\"start\":93984},{\"attributes\":{\"id\":\"fig_13\"},\"end\":94075,\"start\":94014},{\"attributes\":{\"id\":\"fig_14\"},\"end\":94680,\"start\":94076},{\"attributes\":{\"id\":\"fig_15\"},\"end\":94824,\"start\":94681},{\"attributes\":{\"id\":\"fig_17\"},\"end\":95095,\"start\":94825},{\"attributes\":{\"id\":\"fig_18\"},\"end\":95287,\"start\":95096},{\"attributes\":{\"id\":\"fig_19\"},\"end\":95403,\"start\":95288},{\"attributes\":{\"id\":\"fig_20\"},\"end\":95595,\"start\":95404},{\"attributes\":{\"id\":\"fig_21\"},\"end\":95713,\"start\":95596},{\"attributes\":{\"id\":\"fig_22\"},\"end\":95914,\"start\":95714},{\"attributes\":{\"id\":\"fig_23\"},\"end\":96037,\"start\":95915},{\"attributes\":{\"id\":\"fig_24\"},\"end\":96265,\"start\":96038},{\"attributes\":{\"id\":\"fig_25\"},\"end\":96412,\"start\":96266},{\"attributes\":{\"id\":\"fig_26\"},\"end\":96647,\"start\":96413},{\"attributes\":{\"id\":\"fig_27\"},\"end\":96813,\"start\":96648},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":96933,\"start\":96814},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":96976,\"start\":96934},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":97066,\"start\":96977}]", "paragraph": "[{\"end\":6259,\"start\":5317},{\"end\":6906,\"start\":6261},{\"end\":7472,\"start\":6984},{\"end\":7652,\"start\":7508},{\"end\":7705,\"start\":7671},{\"end\":7878,\"start\":7799},{\"end\":8037,\"start\":7880},{\"end\":8145,\"start\":8092},{\"end\":8992,\"start\":8271},{\"end\":9786,\"start\":9084},{\"end\":9969,\"start\":9788},{\"end\":12056,\"start\":9986},{\"end\":12148,\"start\":12058},{\"end\":12624,\"start\":12150},{\"end\":12698,\"start\":12638},{\"end\":13582,\"start\":13209},{\"end\":16039,\"start\":13584},{\"end\":17229,\"start\":16041},{\"end\":18235,\"start\":17259},{\"end\":18528,\"start\":18429},{\"end\":19463,\"start\":18596},{\"end\":19554,\"start\":19465},{\"end\":20588,\"start\":19745},{\"end\":20691,\"start\":20590},{\"end\":20920,\"start\":20740},{\"end\":21159,\"start\":20996},{\"end\":21357,\"start\":21161},{\"end\":21576,\"start\":21397},{\"end\":21768,\"start\":21624},{\"end\":21952,\"start\":21908},{\"end\":22598,\"start\":22542},{\"end\":22825,\"start\":22745},{\"end\":23304,\"start\":22836},{\"end\":23481,\"start\":23388},{\"end\":23910,\"start\":23483},{\"end\":24182,\"start\":24099},{\"end\":24771,\"start\":24193},{\"end\":26230,\"start\":24808},{\"end\":26829,\"start\":26282},{\"end\":28427,\"start\":26831},{\"end\":28523,\"start\":28429},{\"end\":28892,\"start\":28538},{\"end\":29004,\"start\":28936},{\"end\":29292,\"start\":29028},{\"end\":29396,\"start\":29359},{\"end\":29506,\"start\":29489},{\"end\":29974,\"start\":29920},{\"end\":30107,\"start\":30105},{\"end\":30298,\"start\":30248},{\"end\":30435,\"start\":30407},{\"end\":30619,\"start\":30464},{\"end\":30873,\"start\":30642},{\"end\":31030,\"start\":31013},{\"end\":31091,\"start\":31090},{\"end\":31350,\"start\":31093},{\"end\":31426,\"start\":31388},{\"end\":31482,\"start\":31475},{\"end\":32523,\"start\":31655},{\"end\":32817,\"start\":32525},{\"end\":33481,\"start\":32977},{\"end\":33669,\"start\":33509},{\"end\":34045,\"start\":33729},{\"end\":34148,\"start\":34103},{\"end\":34400,\"start\":34345},{\"end\":34514,\"start\":34460},{\"end\":34835,\"start\":34652},{\"end\":34936,\"start\":34921},{\"end\":35005,\"start\":34938},{\"end\":35059,\"start\":35015},{\"end\":35099,\"start\":35061},{\"end\":35193,\"start\":35101},{\"end\":35324,\"start\":35315},{\"end\":35362,\"start\":35326},{\"end\":35446,\"start\":35400},{\"end\":35677,\"start\":35641},{\"end\":35759,\"start\":35679},{\"end\":35950,\"start\":35906},{\"end\":36082,\"start\":36026},{\"end\":36208,\"start\":36151},{\"end\":36404,\"start\":36250},{\"end\":36548,\"start\":36406},{\"end\":37086,\"start\":36645},{\"end\":37341,\"start\":37267},{\"end\":37689,\"start\":37663},{\"end\":37955,\"start\":37797},{\"end\":38361,\"start\":38144},{\"end\":38467,\"start\":38363},{\"end\":38663,\"start\":38608},{\"end\":38961,\"start\":38796},{\"end\":39967,\"start\":39875},{\"end\":40220,\"start\":40127},{\"end\":40469,\"start\":40431},{\"end\":40672,\"start\":40631},{\"end\":40981,\"start\":40873},{\"end\":41048,\"start\":40983},{\"end\":41137,\"start\":41050},{\"end\":41377,\"start\":41253},{\"end\":41452,\"start\":41379},{\"end\":41572,\"start\":41500},{\"end\":41680,\"start\":41610},{\"end\":41756,\"start\":41714},{\"end\":41945,\"start\":41815},{\"end\":42127,\"start\":42068},{\"end\":42381,\"start\":42189},{\"end\":42579,\"start\":42435},{\"end\":42814,\"start\":42697},{\"end\":43435,\"start\":43120},{\"end\":43609,\"start\":43477},{\"end\":43668,\"start\":43643},{\"end\":43757,\"start\":43681},{\"end\":43830,\"start\":43801},{\"end\":44211,\"start\":44047},{\"end\":44324,\"start\":44229},{\"end\":44644,\"start\":44349},{\"end\":44747,\"start\":44646},{\"end\":44910,\"start\":44797},{\"end\":45283,\"start\":44920},{\"end\":45618,\"start\":45394},{\"end\":46238,\"start\":45702},{\"end\":47280,\"start\":46240},{\"end\":47353,\"start\":47323},{\"end\":47654,\"start\":47394},{\"end\":47771,\"start\":47656},{\"end\":47952,\"start\":47819},{\"end\":48061,\"start\":47954},{\"end\":48115,\"start\":48096},{\"end\":48444,\"start\":48160},{\"end\":48538,\"start\":48480},{\"end\":49168,\"start\":48607},{\"end\":49355,\"start\":49193},{\"end\":49448,\"start\":49402},{\"end\":49735,\"start\":49513},{\"end\":49817,\"start\":49792},{\"end\":49957,\"start\":49856},{\"end\":50080,\"start\":49976},{\"end\":50269,\"start\":50082},{\"end\":50609,\"start\":50344},{\"end\":50852,\"start\":50611},{\"end\":50970,\"start\":50936},{\"end\":51122,\"start\":50972},{\"end\":51181,\"start\":51124},{\"end\":51290,\"start\":51183},{\"end\":51530,\"start\":51506},{\"end\":51559,\"start\":51532},{\"end\":52229,\"start\":52045},{\"end\":52304,\"start\":52231},{\"end\":52921,\"start\":52867},{\"end\":52940,\"start\":52923},{\"end\":53348,\"start\":53183},{\"end\":53462,\"start\":53350},{\"end\":53512,\"start\":53489},{\"end\":53628,\"start\":53514},{\"end\":53837,\"start\":53753},{\"end\":54049,\"start\":53979},{\"end\":54481,\"start\":54211},{\"end\":54605,\"start\":54506},{\"end\":54704,\"start\":54658},{\"end\":54995,\"start\":54765},{\"end\":55095,\"start\":55070},{\"end\":55329,\"start\":55152},{\"end\":55537,\"start\":55440},{\"end\":55829,\"start\":55598},{\"end\":55999,\"start\":55876},{\"end\":56361,\"start\":56051},{\"end\":56414,\"start\":56363},{\"end\":56665,\"start\":56505},{\"end\":56745,\"start\":56667},{\"end\":57030,\"start\":56863},{\"end\":57271,\"start\":57105},{\"end\":57492,\"start\":57273},{\"end\":57753,\"start\":57658},{\"end\":58048,\"start\":57755},{\"end\":58216,\"start\":58134},{\"end\":58545,\"start\":58279},{\"end\":58769,\"start\":58547},{\"end\":58961,\"start\":58893},{\"end\":59118,\"start\":58963},{\"end\":59294,\"start\":59239},{\"end\":59370,\"start\":59321},{\"end\":59470,\"start\":59440},{\"end\":59888,\"start\":59758},{\"end\":60031,\"start\":59983},{\"end\":60849,\"start\":60648},{\"end\":60992,\"start\":60851},{\"end\":61055,\"start\":60994},{\"end\":61358,\"start\":61236},{\"end\":61960,\"start\":61780},{\"end\":62019,\"start\":61962},{\"end\":62088,\"start\":62046},{\"end\":62162,\"start\":62090},{\"end\":62914,\"start\":62744},{\"end\":63020,\"start\":62916},{\"end\":63645,\"start\":63269},{\"end\":63967,\"start\":63809},{\"end\":64067,\"start\":63969},{\"end\":64283,\"start\":64217},{\"end\":64377,\"start\":64310},{\"end\":64475,\"start\":64451},{\"end\":65054,\"start\":64867},{\"end\":65101,\"start\":65081},{\"end\":65405,\"start\":65344},{\"end\":65508,\"start\":65434},{\"end\":65623,\"start\":65564},{\"end\":65998,\"start\":65866},{\"end\":66198,\"start\":66078},{\"end\":66333,\"start\":66317},{\"end\":66554,\"start\":66533},{\"end\":66861,\"start\":66806},{\"end\":67058,\"start\":66974},{\"end\":67280,\"start\":67233},{\"end\":67696,\"start\":67528},{\"end\":68032,\"start\":67927},{\"end\":69081,\"start\":68850},{\"end\":69361,\"start\":69324},{\"end\":69881,\"start\":69766},{\"end\":69988,\"start\":69967},{\"end\":70090,\"start\":70036},{\"end\":70389,\"start\":70330},{\"end\":70728,\"start\":70626},{\"end\":71651,\"start\":71487},{\"end\":72082,\"start\":71663},{\"end\":72215,\"start\":72121},{\"end\":72454,\"start\":72425},{\"end\":72586,\"start\":72490},{\"end\":72814,\"start\":72616},{\"end\":72994,\"start\":72898},{\"end\":73177,\"start\":73080},{\"end\":73944,\"start\":73674},{\"end\":74416,\"start\":73946},{\"end\":74528,\"start\":74461},{\"end\":74618,\"start\":74530},{\"end\":74938,\"start\":74706},{\"end\":74990,\"start\":74961},{\"end\":75112,\"start\":74992},{\"end\":75636,\"start\":75566},{\"end\":75848,\"start\":75638},{\"end\":75887,\"start\":75850},{\"end\":76027,\"start\":75978},{\"end\":76128,\"start\":76029},{\"end\":76364,\"start\":76359},{\"end\":76457,\"start\":76392},{\"end\":77033,\"start\":76751},{\"end\":77298,\"start\":77185},{\"end\":77841,\"start\":77777},{\"end\":77926,\"start\":77843},{\"end\":78129,\"start\":78011},{\"end\":78358,\"start\":78292},{\"end\":78720,\"start\":78629},{\"end\":78851,\"start\":78818},{\"end\":79135,\"start\":79065},{\"end\":79765,\"start\":79568},{\"end\":80263,\"start\":80226},{\"end\":80409,\"start\":80291},{\"end\":80511,\"start\":80411},{\"end\":80709,\"start\":80550},{\"end\":80887,\"start\":80847},{\"end\":81801,\"start\":81746},{\"end\":81903,\"start\":81845},{\"end\":82174,\"start\":82148},{\"end\":82222,\"start\":82202},{\"end\":82613,\"start\":82601},{\"end\":83772,\"start\":83655},{\"end\":83898,\"start\":83839},{\"end\":84148,\"start\":84051},{\"end\":84293,\"start\":84272},{\"end\":84452,\"start\":84425},{\"end\":84768,\"start\":84702},{\"end\":84866,\"start\":84842},{\"end\":85151,\"start\":85086},{\"end\":86158,\"start\":85222},{\"end\":88231,\"start\":86160},{\"end\":88618,\"start\":88276},{\"end\":89302,\"start\":88620},{\"end\":90176,\"start\":89304},{\"end\":91352,\"start\":90178}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":6983,\"start\":6907},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7507,\"start\":7473},{\"attributes\":{\"id\":\"formula_2\"},\"end\":7670,\"start\":7653},{\"attributes\":{\"id\":\"formula_3\"},\"end\":7798,\"start\":7706},{\"attributes\":{\"id\":\"formula_4\"},\"end\":8091,\"start\":8038},{\"attributes\":{\"id\":\"formula_5\"},\"end\":8203,\"start\":8146},{\"attributes\":{\"id\":\"formula_6\"},\"end\":8270,\"start\":8203},{\"attributes\":{\"id\":\"formula_7\"},\"end\":9083,\"start\":8993},{\"attributes\":{\"id\":\"formula_8\"},\"end\":9985,\"start\":9970},{\"attributes\":{\"id\":\"formula_11\"},\"end\":12731,\"start\":12699},{\"attributes\":{\"id\":\"formula_12\"},\"end\":13208,\"start\":12731},{\"attributes\":{\"id\":\"formula_13\"},\"end\":18301,\"start\":18236},{\"attributes\":{\"id\":\"formula_14\"},\"end\":18403,\"start\":18301},{\"attributes\":{\"id\":\"formula_15\"},\"end\":18595,\"start\":18529},{\"attributes\":{\"id\":\"formula_16\"},\"end\":19744,\"start\":19555},{\"attributes\":{\"id\":\"formula_17\"},\"end\":20739,\"start\":20692},{\"attributes\":{\"id\":\"formula_18\"},\"end\":20995,\"start\":20921},{\"attributes\":{\"id\":\"formula_19\"},\"end\":21907,\"start\":21769},{\"attributes\":{\"id\":\"formula_20\"},\"end\":22429,\"start\":21953},{\"attributes\":{\"id\":\"formula_21\"},\"end\":22541,\"start\":22429},{\"attributes\":{\"id\":\"formula_22\"},\"end\":22744,\"start\":22599},{\"attributes\":{\"id\":\"formula_23\"},\"end\":22835,\"start\":22826},{\"attributes\":{\"id\":\"formula_24\"},\"end\":23387,\"start\":23305},{\"attributes\":{\"id\":\"formula_25\"},\"end\":24098,\"start\":23911},{\"attributes\":{\"id\":\"formula_26\"},\"end\":24192,\"start\":24183},{\"attributes\":{\"id\":\"formula_27\"},\"end\":26257,\"start\":26231},{\"attributes\":{\"id\":\"formula_28\"},\"end\":29358,\"start\":29293},{\"attributes\":{\"id\":\"formula_29\"},\"end\":29488,\"start\":29397},{\"attributes\":{\"id\":\"formula_30\"},\"end\":29919,\"start\":29507},{\"attributes\":{\"id\":\"formula_31\"},\"end\":30104,\"start\":29975},{\"attributes\":{\"id\":\"formula_32\"},\"end\":30247,\"start\":30108},{\"attributes\":{\"id\":\"formula_33\"},\"end\":30406,\"start\":30299},{\"attributes\":{\"id\":\"formula_34\"},\"end\":30463,\"start\":30436},{\"attributes\":{\"id\":\"formula_35\"},\"end\":31012,\"start\":30874},{\"attributes\":{\"id\":\"formula_36\"},\"end\":31089,\"start\":31031},{\"attributes\":{\"id\":\"formula_37\"},\"end\":31474,\"start\":31427},{\"attributes\":{\"id\":\"formula_38\"},\"end\":31631,\"start\":31483},{\"attributes\":{\"id\":\"formula_39\"},\"end\":32883,\"start\":32818},{\"attributes\":{\"id\":\"formula_40\"},\"end\":32976,\"start\":32883},{\"attributes\":{\"id\":\"formula_41\"},\"end\":33728,\"start\":33670},{\"attributes\":{\"id\":\"formula_42\"},\"end\":34102,\"start\":34046},{\"attributes\":{\"id\":\"formula_43\"},\"end\":34344,\"start\":34149},{\"attributes\":{\"id\":\"formula_44\"},\"end\":34459,\"start\":34401},{\"attributes\":{\"id\":\"formula_45\"},\"end\":34573,\"start\":34515},{\"attributes\":{\"id\":\"formula_46\"},\"end\":34651,\"start\":34573},{\"attributes\":{\"id\":\"formula_47\"},\"end\":34870,\"start\":34836},{\"attributes\":{\"id\":\"formula_48\"},\"end\":34920,\"start\":34870},{\"attributes\":{\"id\":\"formula_49\"},\"end\":35014,\"start\":35006},{\"attributes\":{\"id\":\"formula_50\"},\"end\":35314,\"start\":35194},{\"attributes\":{\"id\":\"formula_51\"},\"end\":35399,\"start\":35363},{\"attributes\":{\"id\":\"formula_52\"},\"end\":35640,\"start\":35447},{\"attributes\":{\"id\":\"formula_53\"},\"end\":35843,\"start\":35760},{\"attributes\":{\"id\":\"formula_54\"},\"end\":35905,\"start\":35843},{\"attributes\":{\"id\":\"formula_55\"},\"end\":36025,\"start\":35951},{\"attributes\":{\"id\":\"formula_56\"},\"end\":36150,\"start\":36083},{\"attributes\":{\"id\":\"formula_57\"},\"end\":36249,\"start\":36209},{\"attributes\":{\"id\":\"formula_58\"},\"end\":36644,\"start\":36549},{\"attributes\":{\"id\":\"formula_59\"},\"end\":37266,\"start\":37087},{\"attributes\":{\"id\":\"formula_60\"},\"end\":37662,\"start\":37342},{\"attributes\":{\"id\":\"formula_61\"},\"end\":37796,\"start\":37690},{\"attributes\":{\"id\":\"formula_62\"},\"end\":38143,\"start\":37956},{\"attributes\":{\"id\":\"formula_63\"},\"end\":38607,\"start\":38468},{\"attributes\":{\"id\":\"formula_64\"},\"end\":38795,\"start\":38664},{\"attributes\":{\"id\":\"formula_65\"},\"end\":39433,\"start\":38962},{\"attributes\":{\"id\":\"formula_66\"},\"end\":39607,\"start\":39433},{\"attributes\":{\"id\":\"formula_67\"},\"end\":39874,\"start\":39607},{\"attributes\":{\"id\":\"formula_68\"},\"end\":40126,\"start\":39968},{\"attributes\":{\"id\":\"formula_69\"},\"end\":40430,\"start\":40221},{\"attributes\":{\"id\":\"formula_70\"},\"end\":40630,\"start\":40470},{\"attributes\":{\"id\":\"formula_71\"},\"end\":40872,\"start\":40673},{\"attributes\":{\"id\":\"formula_72\"},\"end\":41252,\"start\":41138},{\"attributes\":{\"id\":\"formula_73\"},\"end\":41499,\"start\":41453},{\"attributes\":{\"id\":\"formula_74\"},\"end\":41609,\"start\":41573},{\"attributes\":{\"id\":\"formula_75\"},\"end\":41713,\"start\":41681},{\"attributes\":{\"id\":\"formula_76\"},\"end\":41814,\"start\":41757},{\"attributes\":{\"id\":\"formula_77\"},\"end\":42067,\"start\":41946},{\"attributes\":{\"id\":\"formula_78\"},\"end\":42188,\"start\":42128},{\"attributes\":{\"id\":\"formula_79\"},\"end\":42434,\"start\":42382},{\"attributes\":{\"id\":\"formula_80\"},\"end\":42696,\"start\":42580},{\"attributes\":{\"id\":\"formula_81\"},\"end\":43119,\"start\":42815},{\"attributes\":{\"id\":\"formula_82\"},\"end\":43476,\"start\":43436},{\"attributes\":{\"id\":\"formula_83\"},\"end\":43642,\"start\":43610},{\"attributes\":{\"id\":\"formula_84\"},\"end\":43800,\"start\":43758},{\"attributes\":{\"id\":\"formula_85\"},\"end\":43883,\"start\":43831},{\"attributes\":{\"id\":\"formula_86\"},\"end\":43973,\"start\":43883},{\"attributes\":{\"id\":\"formula_87\"},\"end\":44046,\"start\":43973},{\"attributes\":{\"id\":\"formula_88\"},\"end\":44228,\"start\":44212},{\"attributes\":{\"id\":\"formula_89\"},\"end\":44348,\"start\":44325},{\"attributes\":{\"id\":\"formula_90\"},\"end\":44796,\"start\":44748},{\"attributes\":{\"id\":\"formula_91\"},\"end\":44919,\"start\":44911},{\"attributes\":{\"id\":\"formula_92\"},\"end\":45356,\"start\":45284},{\"attributes\":{\"id\":\"formula_93\"},\"end\":45393,\"start\":45356},{\"attributes\":{\"id\":\"formula_94\"},\"end\":45701,\"start\":45619},{\"attributes\":{\"id\":\"formula_95\"},\"end\":47322,\"start\":47281},{\"attributes\":{\"id\":\"formula_96\"},\"end\":47393,\"start\":47354},{\"attributes\":{\"id\":\"formula_97\"},\"end\":47818,\"start\":47772},{\"attributes\":{\"id\":\"formula_98\"},\"end\":48095,\"start\":48062},{\"attributes\":{\"id\":\"formula_99\"},\"end\":48159,\"start\":48116},{\"attributes\":{\"id\":\"formula_100\"},\"end\":48479,\"start\":48445},{\"attributes\":{\"id\":\"formula_101\"},\"end\":48606,\"start\":48539},{\"attributes\":{\"id\":\"formula_102\"},\"end\":49401,\"start\":49356},{\"attributes\":{\"id\":\"formula_103\"},\"end\":49512,\"start\":49449},{\"attributes\":{\"id\":\"formula_104\"},\"end\":49791,\"start\":49736},{\"attributes\":{\"id\":\"formula_105\"},\"end\":49855,\"start\":49818},{\"attributes\":{\"id\":\"formula_106\"},\"end\":49975,\"start\":49958},{\"attributes\":{\"id\":\"formula_107\"},\"end\":50935,\"start\":50853},{\"attributes\":{\"id\":\"formula_108\"},\"end\":51505,\"start\":51291},{\"attributes\":{\"id\":\"formula_109\"},\"end\":52044,\"start\":51560},{\"attributes\":{\"id\":\"formula_110\"},\"end\":52866,\"start\":52305},{\"attributes\":{\"id\":\"formula_111\"},\"end\":53182,\"start\":52941},{\"attributes\":{\"id\":\"formula_112\"},\"end\":53752,\"start\":53629},{\"attributes\":{\"id\":\"formula_113\"},\"end\":53978,\"start\":53838},{\"attributes\":{\"id\":\"formula_114\"},\"end\":54210,\"start\":54050},{\"attributes\":{\"id\":\"formula_115\"},\"end\":54657,\"start\":54606},{\"attributes\":{\"id\":\"formula_116\"},\"end\":54764,\"start\":54705},{\"attributes\":{\"id\":\"formula_117\"},\"end\":55069,\"start\":54996},{\"attributes\":{\"id\":\"formula_118\"},\"end\":55151,\"start\":55096},{\"attributes\":{\"id\":\"formula_119\"},\"end\":55439,\"start\":55330},{\"attributes\":{\"id\":\"formula_120\"},\"end\":55875,\"start\":55830},{\"attributes\":{\"id\":\"formula_121\"},\"end\":56050,\"start\":56000},{\"attributes\":{\"id\":\"formula_122\"},\"end\":56504,\"start\":56415},{\"attributes\":{\"id\":\"formula_123\"},\"end\":56862,\"start\":56746},{\"attributes\":{\"id\":\"formula_124\"},\"end\":57104,\"start\":57031},{\"attributes\":{\"id\":\"formula_125\"},\"end\":57657,\"start\":57493},{\"attributes\":{\"id\":\"formula_126\"},\"end\":58133,\"start\":58049},{\"attributes\":{\"id\":\"formula_127\"},\"end\":58278,\"start\":58251},{\"attributes\":{\"id\":\"formula_128\"},\"end\":58892,\"start\":58770},{\"attributes\":{\"id\":\"formula_129\"},\"end\":59238,\"start\":59119},{\"attributes\":{\"id\":\"formula_130\"},\"end\":59439,\"start\":59371},{\"attributes\":{\"id\":\"formula_131\"},\"end\":59757,\"start\":59471},{\"attributes\":{\"id\":\"formula_132\"},\"end\":59982,\"start\":59889},{\"attributes\":{\"id\":\"formula_133\"},\"end\":60647,\"start\":60032},{\"attributes\":{\"id\":\"formula_134\"},\"end\":61235,\"start\":61056},{\"attributes\":{\"id\":\"formula_135\"},\"end\":61779,\"start\":61359},{\"attributes\":{\"id\":\"formula_136\"},\"end\":62743,\"start\":62163},{\"attributes\":{\"id\":\"formula_137\"},\"end\":63268,\"start\":63021},{\"attributes\":{\"id\":\"formula_138\"},\"end\":63808,\"start\":63646},{\"attributes\":{\"id\":\"formula_139\"},\"end\":64216,\"start\":64068},{\"attributes\":{\"id\":\"formula_140\"},\"end\":64450,\"start\":64378},{\"attributes\":{\"id\":\"formula_141\"},\"end\":64866,\"start\":64476},{\"attributes\":{\"id\":\"formula_142\"},\"end\":65343,\"start\":65102},{\"attributes\":{\"id\":\"formula_143\"},\"end\":65563,\"start\":65509},{\"attributes\":{\"id\":\"formula_144\"},\"end\":65865,\"start\":65624},{\"attributes\":{\"id\":\"formula_145\"},\"end\":66077,\"start\":65999},{\"attributes\":{\"id\":\"formula_146\"},\"end\":66316,\"start\":66199},{\"attributes\":{\"id\":\"formula_147\"},\"end\":66532,\"start\":66334},{\"attributes\":{\"id\":\"formula_148\"},\"end\":66805,\"start\":66555},{\"attributes\":{\"id\":\"formula_149\"},\"end\":66973,\"start\":66862},{\"attributes\":{\"id\":\"formula_150\"},\"end\":67232,\"start\":67059},{\"attributes\":{\"id\":\"formula_151\"},\"end\":67527,\"start\":67281},{\"attributes\":{\"id\":\"formula_152\"},\"end\":67926,\"start\":67697},{\"attributes\":{\"id\":\"formula_153\"},\"end\":68849,\"start\":68033},{\"attributes\":{\"id\":\"formula_154\"},\"end\":69323,\"start\":69082},{\"attributes\":{\"id\":\"formula_155\"},\"end\":69765,\"start\":69362},{\"attributes\":{\"id\":\"formula_156\"},\"end\":69966,\"start\":69882},{\"attributes\":{\"id\":\"formula_157\"},\"end\":70035,\"start\":69989},{\"attributes\":{\"id\":\"formula_158\"},\"end\":70329,\"start\":70091},{\"attributes\":{\"id\":\"formula_159\"},\"end\":70625,\"start\":70390},{\"attributes\":{\"id\":\"formula_160\"},\"end\":71486,\"start\":70729},{\"attributes\":{\"id\":\"formula_161\"},\"end\":71662,\"start\":71652},{\"attributes\":{\"id\":\"formula_162\"},\"end\":72332,\"start\":72216},{\"attributes\":{\"id\":\"formula_163\"},\"end\":72424,\"start\":72332},{\"attributes\":{\"id\":\"formula_164\"},\"end\":72897,\"start\":72815},{\"attributes\":{\"id\":\"formula_165\"},\"end\":73079,\"start\":72995},{\"attributes\":{\"id\":\"formula_166\"},\"end\":73254,\"start\":73178},{\"attributes\":{\"id\":\"formula_167\"},\"end\":73673,\"start\":73285},{\"attributes\":{\"id\":\"formula_168\"},\"end\":74680,\"start\":74619},{\"attributes\":{\"id\":\"formula_169\"},\"end\":74960,\"start\":74939},{\"attributes\":{\"id\":\"formula_170\"},\"end\":75565,\"start\":75113},{\"attributes\":{\"id\":\"formula_171\"},\"end\":75977,\"start\":75888},{\"attributes\":{\"id\":\"formula_172\"},\"end\":76358,\"start\":76129},{\"attributes\":{\"id\":\"formula_173\"},\"end\":76750,\"start\":76458},{\"attributes\":{\"id\":\"formula_174\"},\"end\":77184,\"start\":77034},{\"attributes\":{\"id\":\"formula_175\"},\"end\":77776,\"start\":77299},{\"attributes\":{\"id\":\"formula_176\"},\"end\":78010,\"start\":77927},{\"attributes\":{\"id\":\"formula_177\"},\"end\":78291,\"start\":78130},{\"attributes\":{\"id\":\"formula_178\"},\"end\":78457,\"start\":78359},{\"attributes\":{\"id\":\"formula_179\"},\"end\":78628,\"start\":78457},{\"attributes\":{\"id\":\"formula_180\"},\"end\":78817,\"start\":78721},{\"attributes\":{\"id\":\"formula_181\"},\"end\":79064,\"start\":78852},{\"attributes\":{\"id\":\"formula_182\"},\"end\":79567,\"start\":79136},{\"attributes\":{\"id\":\"formula_183\"},\"end\":80225,\"start\":79766},{\"attributes\":{\"id\":\"formula_184\"},\"end\":80549,\"start\":80512},{\"attributes\":{\"id\":\"formula_185\"},\"end\":80846,\"start\":80710},{\"attributes\":{\"id\":\"formula_186\"},\"end\":81163,\"start\":80888},{\"attributes\":{\"id\":\"formula_187\"},\"end\":81745,\"start\":81163},{\"attributes\":{\"id\":\"formula_188\"},\"end\":81844,\"start\":81802},{\"attributes\":{\"id\":\"formula_189\"},\"end\":82147,\"start\":81904},{\"attributes\":{\"id\":\"formula_190\"},\"end\":82500,\"start\":82223},{\"attributes\":{\"id\":\"formula_191\"},\"end\":82600,\"start\":82500},{\"attributes\":{\"id\":\"formula_192\"},\"end\":83654,\"start\":82614},{\"attributes\":{\"id\":\"formula_193\"},\"end\":83838,\"start\":83773},{\"attributes\":{\"id\":\"formula_194\"},\"end\":84050,\"start\":83899},{\"attributes\":{\"id\":\"formula_195\"},\"end\":84234,\"start\":84149},{\"attributes\":{\"id\":\"formula_196\"},\"end\":84271,\"start\":84234},{\"attributes\":{\"id\":\"formula_197\"},\"end\":84424,\"start\":84294},{\"attributes\":{\"id\":\"formula_198\"},\"end\":84701,\"start\":84453},{\"attributes\":{\"id\":\"formula_199\"},\"end\":84841,\"start\":84769},{\"attributes\":{\"id\":\"formula_200\"},\"end\":85085,\"start\":84867}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":14441,\"start\":14398},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":23545,\"start\":23538},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":24741,\"start\":24734}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":5315,\"start\":5303},{\"end\":12636,\"start\":12627},{\"attributes\":{\"n\":\"2\"},\"end\":17257,\"start\":17232},{\"attributes\":{\"n\":\"3.1\"},\"end\":18427,\"start\":18405},{\"attributes\":{\"n\":\"3.2\"},\"end\":21395,\"start\":21360},{\"end\":21622,\"start\":21579},{\"attributes\":{\"n\":\"3.3\"},\"end\":24806,\"start\":24774},{\"attributes\":{\"n\":\"4\"},\"end\":26280,\"start\":26259},{\"attributes\":{\"n\":\"5\"},\"end\":28536,\"start\":28526},{\"end\":28934,\"start\":28895},{\"end\":29026,\"start\":29007},{\"end\":30640,\"start\":30622},{\"end\":31386,\"start\":31353},{\"end\":31653,\"start\":31633},{\"end\":33507,\"start\":33484},{\"end\":43679,\"start\":43671},{\"end\":49191,\"start\":49171},{\"end\":50342,\"start\":50272},{\"end\":53487,\"start\":53465},{\"end\":54504,\"start\":54484},{\"end\":55596,\"start\":55540},{\"end\":58250,\"start\":58219},{\"end\":59319,\"start\":59297},{\"end\":62044,\"start\":62022},{\"end\":64308,\"start\":64286},{\"end\":65079,\"start\":65057},{\"end\":65432,\"start\":65408},{\"end\":72119,\"start\":72085},{\"end\":72488,\"start\":72457},{\"end\":72614,\"start\":72589},{\"end\":73284,\"start\":73256},{\"end\":74459,\"start\":74419},{\"end\":74704,\"start\":74682},{\"end\":76390,\"start\":76367},{\"end\":80289,\"start\":80266},{\"end\":82200,\"start\":82177},{\"end\":85184,\"start\":85154},{\"end\":85220,\"start\":85187},{\"end\":88274,\"start\":88234},{\"end\":91359,\"start\":91354},{\"end\":91453,\"start\":91448},{\"end\":91868,\"start\":91858},{\"end\":91920,\"start\":91907},{\"end\":92067,\"start\":92062},{\"end\":92453,\"start\":92443},{\"end\":92632,\"start\":92622},{\"end\":93804,\"start\":93800},{\"end\":94016,\"start\":94015},{\"end\":94087,\"start\":94077},{\"end\":94692,\"start\":94682},{\"end\":94827,\"start\":94826},{\"end\":95299,\"start\":95289},{\"end\":95607,\"start\":95597},{\"end\":95926,\"start\":95916},{\"end\":96277,\"start\":96267},{\"end\":96659,\"start\":96649},{\"end\":96824,\"start\":96815},{\"end\":96944,\"start\":96935}]", "table": null, "figure_caption": "[{\"end\":91446,\"start\":91361},{\"end\":91574,\"start\":91455},{\"end\":91856,\"start\":91577},{\"end\":91905,\"start\":91870},{\"end\":92060,\"start\":91922},{\"end\":92306,\"start\":92069},{\"end\":92441,\"start\":92309},{\"end\":92620,\"start\":92455},{\"end\":93046,\"start\":92634},{\"end\":93289,\"start\":93049},{\"end\":93798,\"start\":93292},{\"end\":93983,\"start\":93806},{\"end\":94013,\"start\":93986},{\"end\":94075,\"start\":94017},{\"end\":94680,\"start\":94089},{\"end\":94824,\"start\":94695},{\"end\":95095,\"start\":94828},{\"end\":95287,\"start\":95098},{\"end\":95403,\"start\":95301},{\"end\":95595,\"start\":95406},{\"end\":95713,\"start\":95609},{\"end\":95914,\"start\":95716},{\"end\":96037,\"start\":95928},{\"end\":96265,\"start\":96040},{\"end\":96412,\"start\":96279},{\"end\":96647,\"start\":96415},{\"end\":96813,\"start\":96661},{\"end\":96933,\"start\":96826},{\"end\":96976,\"start\":96946},{\"end\":97066,\"start\":96979}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":12448,\"start\":12442},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":17115,\"start\":17109},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19189,\"start\":19183},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27470,\"start\":27464},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27550,\"start\":27544},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":28017,\"start\":28008},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34662,\"start\":34656},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36994,\"start\":36988},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":48842,\"start\":48835},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":86973,\"start\":86967},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":87086,\"start\":87077},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":87551,\"start\":87542},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":87855,\"start\":87844},{\"attributes\":{\"ref_id\":\"fig_23\"},\"end\":89341,\"start\":89335},{\"attributes\":{\"ref_id\":\"fig_23\"},\"end\":89551,\"start\":89542},{\"attributes\":{\"ref_id\":\"fig_23\"},\"end\":90033,\"start\":90024},{\"attributes\":{\"ref_id\":\"fig_25\"},\"end\":90205,\"start\":90199},{\"attributes\":{\"ref_id\":\"fig_25\"},\"end\":90958,\"start\":90952}]", "bib_author_first_name": "[{\"end\":97289,\"start\":97284},{\"end\":97306,\"start\":97299},{\"end\":97317,\"start\":97316},{\"end\":97330,\"start\":97325},{\"end\":97341,\"start\":97335},{\"end\":97357,\"start\":97353},{\"end\":97696,\"start\":97692},{\"end\":97705,\"start\":97701},{\"end\":97723,\"start\":97718},{\"end\":97743,\"start\":97735},{\"end\":98065,\"start\":98062},{\"end\":98074,\"start\":98070},{\"end\":98083,\"start\":98080},{\"end\":98777,\"start\":98772},{\"end\":99130,\"start\":99124},{\"end\":99142,\"start\":99137},{\"end\":99461,\"start\":99460},{\"end\":99469,\"start\":99468},{\"end\":99476,\"start\":99475},{\"end\":99484,\"start\":99483},{\"end\":99492,\"start\":99491},{\"end\":99500,\"start\":99499},{\"end\":99778,\"start\":99770},{\"end\":99794,\"start\":99786},{\"end\":99809,\"start\":99803},{\"end\":99826,\"start\":99819},{\"end\":100367,\"start\":100362},{\"end\":100384,\"start\":100378},{\"end\":100402,\"start\":100394},{\"end\":100421,\"start\":100414},{\"end\":100432,\"start\":100428},{\"end\":100451,\"start\":100443},{\"end\":100465,\"start\":100460},{\"end\":100479,\"start\":100474},{\"end\":100496,\"start\":100489},{\"end\":100829,\"start\":100824},{\"end\":100841,\"start\":100834},{\"end\":100855,\"start\":100849},{\"end\":100868,\"start\":100862},{\"end\":100881,\"start\":100875},{\"end\":101262,\"start\":101255},{\"end\":101271,\"start\":101269},{\"end\":101283,\"start\":101279},{\"end\":101298,\"start\":101291},{\"end\":101309,\"start\":101306},{\"end\":101319,\"start\":101317},{\"end\":101752,\"start\":101744},{\"end\":101766,\"start\":101759},{\"end\":101782,\"start\":101773},{\"end\":101795,\"start\":101794},{\"end\":101810,\"start\":101801},{\"end\":101822,\"start\":101818},{\"end\":101836,\"start\":101831},{\"end\":102284,\"start\":102280},{\"end\":102301,\"start\":102297},{\"end\":102312,\"start\":102306},{\"end\":102328,\"start\":102322},{\"end\":102342,\"start\":102337},{\"end\":102362,\"start\":102354},{\"end\":102740,\"start\":102737},{\"end\":102748,\"start\":102745},{\"end\":102763,\"start\":102755},{\"end\":103245,\"start\":103239},{\"end\":103266,\"start\":103258},{\"end\":103272,\"start\":103267},{\"end\":103288,\"start\":103281},{\"end\":103304,\"start\":103298},{\"end\":104031,\"start\":104026},{\"end\":104050,\"start\":104040},{\"end\":104068,\"start\":104063},{\"end\":104332,\"start\":104324},{\"end\":104347,\"start\":104340},{\"end\":104363,\"start\":104354},{\"end\":104373,\"start\":104369},{\"end\":104385,\"start\":104379},{\"end\":104397,\"start\":104392},{\"end\":104726,\"start\":104718},{\"end\":104746,\"start\":104740},{\"end\":104757,\"start\":104754},{\"end\":104770,\"start\":104763},{\"end\":105142,\"start\":105136},{\"end\":105159,\"start\":105151},{\"end\":105178,\"start\":105170},{\"end\":105192,\"start\":105187},{\"end\":105210,\"start\":105202},{\"end\":105550,\"start\":105548},{\"end\":105562,\"start\":105557},{\"end\":105582,\"start\":105577},{\"end\":105752,\"start\":105751},{\"end\":105910,\"start\":105909},{\"end\":105920,\"start\":105919},{\"end\":105922,\"start\":105921},{\"end\":105931,\"start\":105930},{\"end\":105941,\"start\":105940},{\"end\":106202,\"start\":106201},{\"end\":106212,\"start\":106211},{\"end\":106220,\"start\":106219},{\"end\":106230,\"start\":106229},{\"end\":106237,\"start\":106236},{\"end\":106596,\"start\":106595},{\"end\":106603,\"start\":106602},{\"end\":107007,\"start\":107006},{\"end\":107015,\"start\":107014},{\"end\":107025,\"start\":107024},{\"end\":107032,\"start\":107031},{\"end\":107043,\"start\":107042},{\"end\":107430,\"start\":107424},{\"end\":107444,\"start\":107439},{\"end\":107471,\"start\":107454},{\"end\":107483,\"start\":107481},{\"end\":107891,\"start\":107890},{\"end\":107899,\"start\":107898},{\"end\":107907,\"start\":107906},{\"end\":107917,\"start\":107916},{\"end\":107919,\"start\":107918},{\"end\":108268,\"start\":108264},{\"end\":108277,\"start\":108273},{\"end\":108296,\"start\":108290},{\"end\":108311,\"start\":108305},{\"end\":108326,\"start\":108321},{\"end\":108346,\"start\":108338},{\"end\":108649,\"start\":108643},{\"end\":108664,\"start\":108656},{\"end\":108679,\"start\":108676},{\"end\":108690,\"start\":108685},{\"end\":109274,\"start\":109273},{\"end\":109280,\"start\":109279},{\"end\":109287,\"start\":109286},{\"end\":109295,\"start\":109294},{\"end\":109758,\"start\":109751},{\"end\":109776,\"start\":109771},{\"end\":109790,\"start\":109786},{\"end\":110143,\"start\":110134},{\"end\":110157,\"start\":110152},{\"end\":110166,\"start\":110162},{\"end\":110176,\"start\":110171},{\"end\":110193,\"start\":110186},{\"end\":110211,\"start\":110203},{\"end\":110224,\"start\":110219}]", "bib_author_last_name": "[{\"end\":97297,\"start\":97290},{\"end\":97314,\"start\":97307},{\"end\":97323,\"start\":97318},{\"end\":97333,\"start\":97331},{\"end\":97351,\"start\":97342},{\"end\":97373,\"start\":97358},{\"end\":97380,\"start\":97375},{\"end\":97699,\"start\":97697},{\"end\":97716,\"start\":97706},{\"end\":97733,\"start\":97724},{\"end\":97749,\"start\":97744},{\"end\":98068,\"start\":98066},{\"end\":98078,\"start\":98075},{\"end\":98088,\"start\":98084},{\"end\":98793,\"start\":98778},{\"end\":99135,\"start\":99131},{\"end\":99148,\"start\":99143},{\"end\":99466,\"start\":99462},{\"end\":99473,\"start\":99470},{\"end\":99481,\"start\":99477},{\"end\":99489,\"start\":99485},{\"end\":99497,\"start\":99493},{\"end\":99505,\"start\":99501},{\"end\":99784,\"start\":99779},{\"end\":99801,\"start\":99795},{\"end\":99817,\"start\":99810},{\"end\":99836,\"start\":99827},{\"end\":100376,\"start\":100368},{\"end\":100392,\"start\":100385},{\"end\":100412,\"start\":100403},{\"end\":100426,\"start\":100422},{\"end\":100441,\"start\":100433},{\"end\":100458,\"start\":100452},{\"end\":100472,\"start\":100466},{\"end\":100487,\"start\":100480},{\"end\":100506,\"start\":100497},{\"end\":100525,\"start\":100508},{\"end\":100832,\"start\":100830},{\"end\":100847,\"start\":100842},{\"end\":100860,\"start\":100856},{\"end\":100873,\"start\":100869},{\"end\":100887,\"start\":100882},{\"end\":101267,\"start\":101263},{\"end\":101277,\"start\":101272},{\"end\":101289,\"start\":101284},{\"end\":101304,\"start\":101299},{\"end\":101315,\"start\":101310},{\"end\":101323,\"start\":101320},{\"end\":101757,\"start\":101753},{\"end\":101771,\"start\":101767},{\"end\":101792,\"start\":101783},{\"end\":101799,\"start\":101796},{\"end\":101816,\"start\":101811},{\"end\":101829,\"start\":101823},{\"end\":101839,\"start\":101837},{\"end\":101845,\"start\":101841},{\"end\":102295,\"start\":102285},{\"end\":102304,\"start\":102302},{\"end\":102320,\"start\":102313},{\"end\":102335,\"start\":102329},{\"end\":102352,\"start\":102343},{\"end\":102368,\"start\":102363},{\"end\":102743,\"start\":102741},{\"end\":102753,\"start\":102749},{\"end\":102767,\"start\":102764},{\"end\":103256,\"start\":103246},{\"end\":103279,\"start\":103273},{\"end\":103296,\"start\":103289},{\"end\":103312,\"start\":103305},{\"end\":104038,\"start\":104032},{\"end\":104061,\"start\":104051},{\"end\":104078,\"start\":104069},{\"end\":104338,\"start\":104333},{\"end\":104352,\"start\":104348},{\"end\":104367,\"start\":104364},{\"end\":104377,\"start\":104374},{\"end\":104390,\"start\":104386},{\"end\":104403,\"start\":104398},{\"end\":104738,\"start\":104727},{\"end\":104752,\"start\":104747},{\"end\":104761,\"start\":104758},{\"end\":104775,\"start\":104771},{\"end\":104780,\"start\":104777},{\"end\":105149,\"start\":105143},{\"end\":105168,\"start\":105160},{\"end\":105185,\"start\":105179},{\"end\":105200,\"start\":105193},{\"end\":105219,\"start\":105211},{\"end\":105555,\"start\":105551},{\"end\":105575,\"start\":105563},{\"end\":105588,\"start\":105583},{\"end\":105761,\"start\":105753},{\"end\":105917,\"start\":105911},{\"end\":105928,\"start\":105923},{\"end\":105938,\"start\":105932},{\"end\":105949,\"start\":105942},{\"end\":106209,\"start\":106203},{\"end\":106217,\"start\":106213},{\"end\":106227,\"start\":106221},{\"end\":106234,\"start\":106231},{\"end\":106247,\"start\":106238},{\"end\":106600,\"start\":106597},{\"end\":106608,\"start\":106604},{\"end\":107012,\"start\":107008},{\"end\":107022,\"start\":107016},{\"end\":107029,\"start\":107026},{\"end\":107040,\"start\":107033},{\"end\":107052,\"start\":107044},{\"end\":107437,\"start\":107431},{\"end\":107452,\"start\":107445},{\"end\":107479,\"start\":107472},{\"end\":107488,\"start\":107484},{\"end\":107896,\"start\":107892},{\"end\":107904,\"start\":107900},{\"end\":107914,\"start\":107908},{\"end\":107925,\"start\":107920},{\"end\":108271,\"start\":108269},{\"end\":108288,\"start\":108278},{\"end\":108303,\"start\":108297},{\"end\":108319,\"start\":108312},{\"end\":108336,\"start\":108327},{\"end\":108352,\"start\":108347},{\"end\":108654,\"start\":108650},{\"end\":108674,\"start\":108665},{\"end\":108683,\"start\":108680},{\"end\":108694,\"start\":108691},{\"end\":109277,\"start\":109275},{\"end\":109284,\"start\":109281},{\"end\":109292,\"start\":109288},{\"end\":109300,\"start\":109296},{\"end\":109769,\"start\":109759},{\"end\":109784,\"start\":109777},{\"end\":109799,\"start\":109791},{\"end\":110150,\"start\":110144},{\"end\":110160,\"start\":110158},{\"end\":110169,\"start\":110167},{\"end\":110184,\"start\":110177},{\"end\":110201,\"start\":110194},{\"end\":110217,\"start\":110212},{\"end\":110234,\"start\":110225}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1610.05492\",\"id\":\"b0\"},\"end\":97626,\"start\":97213},{\"attributes\":{\"doi\":\"arXiv:1908.07873\",\"id\":\"b1\"},\"end\":97948,\"start\":97628},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b2\",\"matched_paper_id\":150373664},\"end\":98720,\"start\":97950},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":43964415},\"end\":99014,\"start\":98722},{\"attributes\":{\"doi\":\"arXiv:1808.07576\",\"id\":\"b4\"},\"end\":99357,\"start\":99016},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":52343892},\"end\":99737,\"start\":99359},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3586416},\"end\":100308,\"start\":99739},{\"attributes\":{\"doi\":\"arXiv:1902.01046\",\"id\":\"b7\"},\"end\":100822,\"start\":100310},{\"attributes\":{\"doi\":\"arXiv:1907.02189\",\"id\":\"b8\"},\"end\":101120,\"start\":100824},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":1467846},\"end\":101644,\"start\":101122},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":4883014},\"end\":102206,\"start\":101646},{\"attributes\":{\"doi\":\"arXiv:1812.06127\",\"id\":\"b11\"},\"end\":102606,\"start\":102208},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":53285773},\"end\":103142,\"start\":102608},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b13\",\"matched_paper_id\":174800430},\"end\":103974,\"start\":103144},{\"attributes\":{\"doi\":\"arXiv:1909.04715\",\"id\":\"b14\"},\"end\":104258,\"start\":103976},{\"attributes\":{\"doi\":\"arXiv:1912.12844\",\"id\":\"b15\"},\"end\":104624,\"start\":104260},{\"attributes\":{\"doi\":\"arXiv:1905.12648\",\"id\":\"b16\"},\"end\":105012,\"start\":104626},{\"attributes\":{\"doi\":\"arXiv:1912.06036\",\"id\":\"b17\"},\"end\":105502,\"start\":105014},{\"attributes\":{\"id\":\"b18\"},\"end\":105687,\"start\":105504},{\"attributes\":{\"id\":\"b19\"},\"end\":105861,\"start\":105689},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":56431345},\"end\":106111,\"start\":105863},{\"attributes\":{\"doi\":\"arXiv:1702.08704\",\"id\":\"b21\"},\"end\":106464,\"start\":106113},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":4706342},\"end\":106901,\"start\":106466},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":51789432},\"end\":107337,\"start\":106903},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":12041405},\"end\":107833,\"start\":107339},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":14957618},\"end\":108221,\"start\":107835},{\"attributes\":{\"doi\":\"arXiv:2001.01920\",\"id\":\"b26\"},\"end\":108559,\"start\":108223},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":44061071},\"end\":109184,\"start\":108561},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":145937890},\"end\":109657,\"start\":109186},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":42114657},\"end\":110090,\"start\":109659},{\"attributes\":{\"doi\":\"arXiv:1812.01097\",\"id\":\"b30\"},\"end\":110455,\"start\":110092}]", "bib_title": "[{\"end\":98060,\"start\":97950},{\"end\":98770,\"start\":98722},{\"end\":99458,\"start\":99359},{\"end\":99768,\"start\":99739},{\"end\":101253,\"start\":101122},{\"end\":101742,\"start\":101646},{\"end\":102735,\"start\":102608},{\"end\":103237,\"start\":103144},{\"end\":105907,\"start\":105863},{\"end\":106593,\"start\":106466},{\"end\":107004,\"start\":106903},{\"end\":107422,\"start\":107339},{\"end\":107888,\"start\":107835},{\"end\":108641,\"start\":108561},{\"end\":109271,\"start\":109186},{\"end\":109749,\"start\":109659}]", "bib_author": "[{\"end\":97299,\"start\":97284},{\"end\":97316,\"start\":97299},{\"end\":97325,\"start\":97316},{\"end\":97335,\"start\":97325},{\"end\":97353,\"start\":97335},{\"end\":97375,\"start\":97353},{\"end\":97382,\"start\":97375},{\"end\":97701,\"start\":97692},{\"end\":97718,\"start\":97701},{\"end\":97735,\"start\":97718},{\"end\":97751,\"start\":97735},{\"end\":98070,\"start\":98062},{\"end\":98080,\"start\":98070},{\"end\":98090,\"start\":98080},{\"end\":98795,\"start\":98772},{\"end\":99137,\"start\":99124},{\"end\":99150,\"start\":99137},{\"end\":99468,\"start\":99460},{\"end\":99475,\"start\":99468},{\"end\":99483,\"start\":99475},{\"end\":99491,\"start\":99483},{\"end\":99499,\"start\":99491},{\"end\":99507,\"start\":99499},{\"end\":99786,\"start\":99770},{\"end\":99803,\"start\":99786},{\"end\":99819,\"start\":99803},{\"end\":99838,\"start\":99819},{\"end\":100378,\"start\":100362},{\"end\":100394,\"start\":100378},{\"end\":100414,\"start\":100394},{\"end\":100428,\"start\":100414},{\"end\":100443,\"start\":100428},{\"end\":100460,\"start\":100443},{\"end\":100474,\"start\":100460},{\"end\":100489,\"start\":100474},{\"end\":100508,\"start\":100489},{\"end\":100527,\"start\":100508},{\"end\":100834,\"start\":100824},{\"end\":100849,\"start\":100834},{\"end\":100862,\"start\":100849},{\"end\":100875,\"start\":100862},{\"end\":100889,\"start\":100875},{\"end\":101269,\"start\":101255},{\"end\":101279,\"start\":101269},{\"end\":101291,\"start\":101279},{\"end\":101306,\"start\":101291},{\"end\":101317,\"start\":101306},{\"end\":101325,\"start\":101317},{\"end\":101759,\"start\":101744},{\"end\":101773,\"start\":101759},{\"end\":101794,\"start\":101773},{\"end\":101801,\"start\":101794},{\"end\":101818,\"start\":101801},{\"end\":101831,\"start\":101818},{\"end\":101841,\"start\":101831},{\"end\":101847,\"start\":101841},{\"end\":102297,\"start\":102280},{\"end\":102306,\"start\":102297},{\"end\":102322,\"start\":102306},{\"end\":102337,\"start\":102322},{\"end\":102354,\"start\":102337},{\"end\":102370,\"start\":102354},{\"end\":102745,\"start\":102737},{\"end\":102755,\"start\":102745},{\"end\":102769,\"start\":102755},{\"end\":103258,\"start\":103239},{\"end\":103281,\"start\":103258},{\"end\":103298,\"start\":103281},{\"end\":103314,\"start\":103298},{\"end\":104040,\"start\":104026},{\"end\":104063,\"start\":104040},{\"end\":104080,\"start\":104063},{\"end\":104340,\"start\":104324},{\"end\":104354,\"start\":104340},{\"end\":104369,\"start\":104354},{\"end\":104379,\"start\":104369},{\"end\":104392,\"start\":104379},{\"end\":104405,\"start\":104392},{\"end\":104740,\"start\":104718},{\"end\":104754,\"start\":104740},{\"end\":104763,\"start\":104754},{\"end\":104777,\"start\":104763},{\"end\":104782,\"start\":104777},{\"end\":105151,\"start\":105136},{\"end\":105170,\"start\":105151},{\"end\":105187,\"start\":105170},{\"end\":105202,\"start\":105187},{\"end\":105221,\"start\":105202},{\"end\":105557,\"start\":105548},{\"end\":105577,\"start\":105557},{\"end\":105590,\"start\":105577},{\"end\":105763,\"start\":105751},{\"end\":105919,\"start\":105909},{\"end\":105930,\"start\":105919},{\"end\":105940,\"start\":105930},{\"end\":105951,\"start\":105940},{\"end\":106211,\"start\":106201},{\"end\":106219,\"start\":106211},{\"end\":106229,\"start\":106219},{\"end\":106236,\"start\":106229},{\"end\":106249,\"start\":106236},{\"end\":106602,\"start\":106595},{\"end\":106610,\"start\":106602},{\"end\":107014,\"start\":107006},{\"end\":107024,\"start\":107014},{\"end\":107031,\"start\":107024},{\"end\":107042,\"start\":107031},{\"end\":107054,\"start\":107042},{\"end\":107439,\"start\":107424},{\"end\":107454,\"start\":107439},{\"end\":107481,\"start\":107454},{\"end\":107490,\"start\":107481},{\"end\":107898,\"start\":107890},{\"end\":107906,\"start\":107898},{\"end\":107916,\"start\":107906},{\"end\":107927,\"start\":107916},{\"end\":108273,\"start\":108264},{\"end\":108290,\"start\":108273},{\"end\":108305,\"start\":108290},{\"end\":108321,\"start\":108305},{\"end\":108338,\"start\":108321},{\"end\":108354,\"start\":108338},{\"end\":108656,\"start\":108643},{\"end\":108676,\"start\":108656},{\"end\":108685,\"start\":108676},{\"end\":108696,\"start\":108685},{\"end\":109279,\"start\":109273},{\"end\":109286,\"start\":109279},{\"end\":109294,\"start\":109286},{\"end\":109302,\"start\":109294},{\"end\":109771,\"start\":109751},{\"end\":109786,\"start\":109771},{\"end\":109801,\"start\":109786},{\"end\":110152,\"start\":110134},{\"end\":110162,\"start\":110152},{\"end\":110171,\"start\":110162},{\"end\":110186,\"start\":110171},{\"end\":110203,\"start\":110186},{\"end\":110219,\"start\":110203},{\"end\":110236,\"start\":110219}]", "bib_venue": "[{\"end\":98287,\"start\":98207},{\"end\":102878,\"start\":102832},{\"end\":103511,\"start\":103431},{\"end\":97282,\"start\":97213},{\"end\":97690,\"start\":97628},{\"end\":98162,\"start\":98094},{\"end\":98858,\"start\":98795},{\"end\":99122,\"start\":99016},{\"end\":99519,\"start\":99507},{\"end\":99887,\"start\":99838},{\"end\":100360,\"start\":100310},{\"end\":100949,\"start\":100905},{\"end\":101374,\"start\":101325},{\"end\":101907,\"start\":101847},{\"end\":102278,\"start\":102208},{\"end\":102830,\"start\":102769},{\"end\":103386,\"start\":103318},{\"end\":104024,\"start\":103976},{\"end\":104322,\"start\":104260},{\"end\":104716,\"start\":104626},{\"end\":105134,\"start\":105014},{\"end\":105546,\"start\":105504},{\"end\":105749,\"start\":105689},{\"end\":105975,\"start\":105951},{\"end\":106199,\"start\":106113},{\"end\":106648,\"start\":106610},{\"end\":107096,\"start\":107054},{\"end\":107567,\"start\":107490},{\"end\":108006,\"start\":107927},{\"end\":108262,\"start\":108223},{\"end\":108745,\"start\":108696},{\"end\":109401,\"start\":109302},{\"end\":109851,\"start\":109801},{\"end\":110132,\"start\":110092}]"}}}, "year": 2023, "month": 12, "day": 17}