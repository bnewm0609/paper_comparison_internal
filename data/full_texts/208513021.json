{"id": 208513021, "updated": "2023-10-06 21:18:41.452", "metadata": {"title": "QubitHD: A Stochastic Acceleration Method for HD Computing-Based Machine Learning", "authors": "[{\"first\":\"Samuel\",\"last\":\"Bosch\",\"middle\":[]},{\"first\":\"Alexander\",\"last\":\"Cerda\",\"middle\":[\"Sanchez\",\"de\",\"la\"]},{\"first\":\"Mohsen\",\"last\":\"Imani\",\"middle\":[]},{\"first\":\"Tajana\",\"last\":\"Rosing\",\"middle\":[\"Simunic\"]},{\"first\":\"Giovanni\",\"last\":\"Micheli\",\"middle\":[\"De\"]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "Machine Learning algorithms based on Brain-inspired Hyperdimensional(HD) computing imitate cognition by exploiting statistical properties of high-dimensional vector spaces. It is a promising solution for achieving high energy efficiency in different machine learning tasks, such as classification, semi-supervised learning, and clustering. A weakness of existing HD computing-based ML algorithms is the fact that they have to be binarized to achieve very high energy efficiency. At the same time, binarized models reach lower classification accuracies. To solve the problem of the trade-off between energy efficiency and classification accuracy, we propose the QubitHD algorithm. It stochastically binarizes HD-based algorithms, while maintaining comparable classification accuracies to their non-binarized counterparts. The FPGA implementation of QubitHD provides a 65% improvement in terms of energy efficiency, and a 95% improvement in terms of training time, as compared to state-of-the-art HD-based ML algorithms. It also outperforms state-of-the-art low-cost classifiers (such as Binarized Neural Networks) in terms of speed and energy efficiency by an order of magnitude during training and inference.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1911.12446", "mag": "2991652642", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-1911-12446", "doi": null}}, "content": {"source": {"pdf_hash": "1856618351f9f99e5b3d132a58b6e42282068a42", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/1911.12446v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4fb0b12b6527defc42612a41b547d7ac7b5cf13e", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1856618351f9f99e5b3d132a58b6e42282068a42.txt", "contents": "\nQubitHD: A Stochastic Acceleration Method for HD Computing-Based Machine Learning\n\n\nSamuel Bosch \nMassachusetts Institute of Technology\n02139CambridgeMAUSA\n\nAlexander Sanchez De La Cerda \nHarvard University\n02138CambridgeMAUSA\n\nMohsen Imani \nUniversity of California Irvine\n92697IrvineCAUSA\n\nTajana\u0161imuni\u0107 Rosing \nUniversity of California San Diego\nLa Jolla92093CAUSA\n\n5\u00c9 cole polytechnique f\u00e9d\u00e9rale de Lausanne\n1015LausanneVDSwitzerland\n\nGiovanni De Micheli \nQubitHD: A Stochastic Acceleration Method for HD Computing-Based Machine Learning\n(Dated: October 12, 2022)\nMachine Learning algorithms based on Brain-inspired Hyperdimensional (HD) computing imitate cognition by exploiting statistical properties of high-dimensional vector spaces. It is a promising solution for achieving high energy efficiency in different machine learning tasks, such as classification, semi-supervised learning, and clustering. A weakness of existing HD computing-based ML algorithms is the fact that they have to be binarized to achieve very high energy efficiency. At the same time, binarized models reach lower classification accuracies. To solve the problem of the trade-off between energy efficiency and classification accuracy, we propose the QubitHD algorithm. It stochastically binarizes HD-based algorithms, while maintaining comparable classification accuracies to their non-binarized counterparts. The FPGA implementation of QubitHD provides a 65% improvement in terms of energy efficiency, and a 95% improvement in terms of training time, as compared to state-of-the-art HD-based ML algorithms. It also outperforms state-of-the-art low-cost classifiers (such as Binarized Neural Networks) in terms of speed and energy efficiency by an order of magnitude during training and inference.\n\nWith the rise of data science and the Internet of Things (IoT), the amount of produced data on a daily basis has increased to a level we are barely able to handle [1]. As the amount of data that needs to be processed is often significantly larger than small-scale and batterypowered devices can handle, so many of these devices are forced to connect to the internet to process the data in the cloud. Deep Neural Networks (DNNs) are used for complex classification tasks, such as text and image recognition [2], translation, and even medical applications [3]. However, the complexity of DNNs makes them impractical for some real-world applications, such as classification tasks on small battery-powered devices. Engineers often face a trade-off between energy efficiency and the achieved classification accuracy. Therefore, we need to create lightweight classifiers, which can perform inference on small-scale operating devices.\n\nBrain-inspired Hyperdimensional (HD) computing [4] has been proposed as a lightweight learning algorithm and methodology. The principles governing HD computing are based on the fact that the brain computes with patterns of neural activities which are not directly associated with numbers [4]. Machine learning algorithms based on Brain-inspired HD computing imitate cognition by exploiting statistical properties of very highdimensional vector spaces. Recently, architectures such * sbosch@mit.edu as LookHD [5] have been proposed, which enable realtime HDC learning on low-power edge devices. The first step in HD computing is to map each data point into a high-dimensional space (e.g., 10, 000 dimensions). During training, HD computing linearly combines the encoded hypervectors to create a hypervector representing each class. During the inference, classification is done by calculating the cosine similarity between the encoded query hypervector and all class hypervectors. The algorithm then predicts the class with the highest similarity score. In the case of multiple classes with high similarity, the algorithm is likewise suited to express confidence in the correctness of a prediction.\n\nMany publications on Brain-inspired HD computing argue that for most practical applications, HD computing has to be trained and tested using floating-point, or at least integer values [6,7]. Binarized HD computing models provided low classification accuracies. Often too low for practical applications. An algorithm called QuantHD [8] revealed the existence of a method to improve the classification accuracies of binarized and ternarized models significantly.\n\nNevertheless, there still exists a large gap between the classification accuracy of non-binarized and binarized HD computing classifiers. Also, such methods increase the required training time and are unstable as they tend to get stuck in local minima during training. In this paper, we propose a new method that can, both, reduce this classification accuracy gap by between a third and a half whilst simultaneously improving energy efficiency during training by 60%, on average. It also makes the training more stable by introducing randomness. We call this technique QubitHD, as it is based on the arXiv:1911.12446v3 [cs.\n\nLG] 10 Oct 2022 principle of information being stored in a quantum bit (Qubit) before its measurement. The floating-point values represent the quantum state, while the binarized values represent the quantum state after a measurement has been performed.\n\nThe main contributions of the paper are the following:\n\n\u2022 We decreased the gap in classification accuracy between binarized and non-binarized state-of-the-art HD computing-based ML algorithms by 38.8%, on average.\n\n\u2022 We decrease the convergence time in the range of 30-50% (for different datasets). Introducing randomness in the algorithm prevents it from getting stuck in local minima, and incites the algorithm to quickly move towards the optimal value. The reason why the authors of [8] had problems with slow convergence was precisely this: lack of randomness.\n\n\u2022 QubitHD performs a similarity check by calculating the Hamming distance between the hypervectors instead of calculating the costly cosine similarity.\n\n\u2022 We implemented the algorithm on FPGA, which accelerates training and inference. We also evaluated several classification problems, including human activity, face, and text recognition. When looking at energy efficiency and speed, the FPGA implementation of QubitHD provides, on average, a 56\u00d7 and 8\u00d7 energy efficiency improvement and speedup during training, as compared to state-ofthe-art HD computing algorithms [9]. For comparison purposes, the authors of [8] only achieve 34.1\u00d7 and 4.1\u00d7 energy efficiency improvement and speedup during the training against the same state-of-the-art HD computing algorithms. When comparing QubitHD with multi-layer perceptron (MLP) and binarized neural network (BNN) classifiers, we observe that QubitHD can provide 56\u00d7 and 52\u00d7 faster computing in training and testing respectively, while providing similar classification accuracies (see Table III).\n\n\nII. HYPERDIMENSIONAL COMPUTING\n\nThe applications of brain-inspired HD computing in machine learning are diverse. In this publication, we only focus on supervised classification tasks, but a recent publication indicated that HD computing-based ML algorithms can be applied to clustering and semi-supervised learning as well [10]. The basis of QubitHD is described in Figure 2. The core difference to QuantHD is the binarization step that is discussed in Section III. The nonbinarized algorithm with retraining consists of the following steps:  \n\n\nA. Encoding\n\nThe training dataset is pre-processed by converting all data points into very high-dimensional vectors (hypervectors). We used hypervectors of length D = 10, 000 in this paper, as it is the standard baseline for all HD computing-based machine learning algorithms. Like explained in [8], the original data is assumed to have n features: f = {f 1 , . . . f n }. The objective is encoding each feature that corresponds to each datapoint into the hypervector of dimension D (D = 10, 000 in this paper). Each feature vector \"memorizes\" the value and position of the relevant feature. In order to take into account the position of each feature, we use a set of randomly generated base hypervectors {B i , B 2 , . . . , B n }, where n is the total number of features in each data point\n(B i \u2208 {\u22121, 1} D ).\nSince the base-hypervectors are uniformly generated at random (with equal probability for \u22121 and 1), they are approximately mutually orthogonal. The cosine product between hypervectors ranges between cos(H 1 , H 2 ) \u2208 \u2212 1, 1 . The expected cosine product of independent and randomly generated base-\nhypervectors is E[cos(B i , B j )] = 0, whereas the variance is V [cos(B i , B j )] = 1 \u221a D \u2248 0 for D >> n (random walk) for i = j.\nThereby, the hypervectors are almost orthogonal. This is true only when the number of randomly generated base-hypervectors is significantly smaller than the dimension of the entire vector space D. distance. Therefore:\nE[\u03b4(B i , B j )] = D/2 (f or i = j).\nHere \u03b4 is the Hamming distance similarity between the two binarized base-hypervectors.\n\n\nB. Initial training\n\nThe first training round is performed by summing up all hypervectors pertaining to the same class. That is, we abstract all hypervectors with the same labels. This method is called one-shot learning and is, at the moment, the most widespread way of using HD computing in machine learning [9,[11][12][13][14]. We now have one matrix C of size m \u00d7 D (C \u2208 R m\u00d7D ), where m is the number of existing classes and D is the length of the hypervectors.\n\n\nC. Retraining\n\nThe classification accuracy of the current model during the inference is low [8]. For this reason, we have to do retraining. As displayed in Figure 3, retraining is done in the following way. We go through the entire dataset of encoded data points and test them to ascertain if they are correctly classified by the current model C. For every misclassified data point, we have to make additional improvements to the model. Let us assume that the correct label of a data point is k, but it was incorrectly classified as l. We now add the erroneously classified hypervector to its corresponding row C k . (to make them more similar). We also subtract the incorrectly classified hypervector from the row corresponding to the inaccurately predicted class C l (to make them more distinct). To decrease the convergence of time and noise, it is common practice to introduce a learning rate of \u03b1 in this step as illustrated in Figure 3a [15]. This process is repeated several times.\n\n\nD. Inference\n\nDuring the inference, we predict the class to which the data point belongs. This data point is encoded as described in II A, and then compared to all the class hypervectors. The algorithm then predicts the class with the largest cosine similarity.\n\n\nE. Binarization:\n\nSo far, we described in the algorithm that the trained model has non-binarized elements.\n\nMany existing HD computing methods [16][17][18] binarize the class hypervectors to eliminate costly cosine operations used for the associative search (C \u2208 R m\u00d7D \u2192 C binarized \u2208 {\u22121, 1} m\u00d7D ). Binary hypervectors do not provide sufficiently high classification accuracies on many (if not most) real-world applications. The usual way of binarizing class hypervectors is making all positive values equal to +1 and negative values equal to \u22121. This method suffers from a significant loss of information about the trained model. To the best of our knowledge, [8] was the first publication demonstrating a method of achieving high classification accuracy while using a binarized (or quantized) HD model. Instead of just \"blindly\" binarizing the class hypervectors after every retraining iteration, QuantHD trains the model in a way that is optimized for binarized hypervectors. That is, during every single retraining iteration, they create an additional binarized model. Doing so requires no additional computational power, as the binary representation of numbers in usual computer architectures reserves the first bit for the sign (0 stands for positive, 1 for negative). The QuantHD algorithm retrains on the predictions of the binarized model, while updating the non-binarized model as described in subsection II C and Figure 3. The binarized model achieves, after several iterations, very high classification accuracies. They are significantly higher than they would be without binary-optimized retraining.\n\n\nIII. STOCHASTIC BINARIZATION\n\nOur goal is to create a binarized model whose expected value is equal to the non-binarized model. This idea was inspired by the way in which quantum bits (or qubits) are measured -hence the name QubitHD.\n\nIn other words, we want E C binarized \u2248 C non binarized . The QuantHD algorithm uses the following (very trivial) binarization function:\nbin(x) = 1, if x \u2265 0 \u22121, otherwise(1)\nWe propose using the following method instead:\nqbin(x) = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f3 1, if x > b 1, if |x| \u2264 b, then with probability 1 2 + x 2b \u22121, if |x| \u2264 b, otherwise \u22121, if x < \u2212b(2)\nwhere b is the cutoff value defined as a fixed fraction of the standard deviation \u03c3 of the data. It is discussed in greater detail in subsection IV A. The advantage of doing so is the fact that the expected value of qbin(x) for x \u2208 \u2212 b, b is proportional to x:\nE qbin(x) = (+1)( 1 2 + x 2b ) + (\u22121)( 1 2 \u2212 x 2b ) = x b IV. PROPOSED QUBITHD ALGORITHM\n\nMotivation\n\nThe QuantHD algorithm still leaves us with a significant gap between the maximum classification accuracy of the floating-point model and the binarized one. Also, the QuantHD retraining method described in [8] tends to get \"stuck\" in local minima. Further, their algorithm almost doubles the average convergence rate, which hereafter increases energy consumption during training. To summarize, here are the main problems with the QuantHD algorithm, which the QubitHD algorithm can either solve or improve:\n\n1. There still exists a significant gap between the binarized model and non-binarized model accuracy 2. The algorithm can sometimes get stuck in local minima, which makes it unreliable.\n\n3. The convergence time of QuantHD algorithm is almost twice as slow as compared to the other stateof-the-art HD computing algorithms with retraining A. Framework of the QubitHD algorithm\n\nIn this section, we present the QubitHD algorithm. It enables efficient binarization of the HD model with a minor impact on classification accuracy. The algorithm is based on QuantHD and consists of four main steps:\n\n1) Encoding: This part is described in detail in Subsection II A and Figure 2b 2) Initial training: QubitHD trains the class hypervectors by summing all the encoded data points corresponding to the same class as seen in Figure 3a It is evident from Figure 3a that every accumulated hypervector represents one class. As explained in [8], in an application with k classes, the initially trained HD model contains k non-binarized hypervectors\n{C 1 , . . . , C k }, where C i \u2208 N D 1 .\n\n3) Stochastic binarization:\n\nThis part is the main change with respect to the QuantHD algorithm. A given class hypervector is created by summing together random hypervectors h of the type h \u2208 {\u22121, 1} D . Every element C ij in a class hypervector C i (of class i) is the product of a \"random walk\". In other words, its distribution follows a binomial distribution with a probability mass function (pmf):\np(C ij = k) = n k p k (1 \u2212 p) n\u2212k = n k 1 2 n(3)\nwhere p = 1 2 (as we have equal probabilities for h j = \u22121 and h j = +1), n is the number of randomly summed hypervectors for class i, and k is a possible value C ij can take. Note that C ij \u2208 {\u2212n, ..., 0, ..., n}.\n\nAssuming that the number of hypervectors corresponding to every class in the dataset is large enough, the normal distribution is a good approximation for modeling the binomial distribution In previous publications, [8], the way of binarizing a model C was described by Equation 1. We instead propose using Equation 2 shown in Figure 4. Implementing this change requires almost no additional resources (the random flips have to be performed only once per retraining round), but leads to significant improvements in terms of accuracy, reliability, speed, and energy efficiency. The accuracy improvement is due to the fact that the expected value of this stochastically binarized model is equal to the non-binarized model. The reliability and speed improvement are because the model quickly Just as we have demonstrated, the encoded data we are processing is (approximately) normally distributed. To be able to use Equation 2 for the binarization process, we have to define a \"cutoff\" value b. That is, everything above +b will become +1, and everything below \u2212b will become \u22121. Only values between \u2212b and +b will be better approximated through Equation 2. In most cases, b has to be smaller than the standard deviation of the data distribution \u03c3. If we would use b >> \u03c3, our model would become almost completely random, as most of the values are contained in the \u2212 \u03c3, +\u03c3 interval (68% to be precise).\n\nThe reason why the qbin(x) binarization works better than the bin(x) lies in the fact that taking into account the expected value of the binarized model, it is equal to actual values in the non-binarized model, with the exception of values below \u2212b and above +b. Empirically, we also noticed that the randomness of qbin(x) prevents the algorithm from getting stuck in local minima during training, which reduces the convergence time by 50%, on average.\n\n\nV. POSSIBLE FPGA IMPLEMENTATION\n\nIt is known that HD computing-based machine learning algorithms can be implemented in a wide range of different hardware platforms, such as CPUs, GPUs, and FPGAs. As most of the training and all of the inference relies on bit-wise operations, it was proposed in [8] that FPGAs would be a suitable candidate for efficient hardware acceleration. The same hardware can be used for implementing both, the QuantHD and the QubitHD algorithm. This is also one of the major advantages of QubitHD, as it doesn't require costly hardware upgrades from previous models.\n\n\nVI. EVALUATION\n\n\nA. Experimental Setup\n\nThe training and inference of the algorithm were implemented and verified using Verilog and the code was synthesized on the Kintex-7 FPGA KC705 Evaluation Kit. The Vivado XPower tool has been used to estimate the device power. Additionally, for testing purposes, all parts of the QubitHD algorithm have been implemented on the CPU. We also implemented the algorithm on an  [25] embedded device (Rasberry Pi 3 ) with an ARM Cortex A54 CPU. To make an accurate and fair comparison, we use the following FPGA-implemented algorithms as baselines:\n\n\u2022 The QuantHD algorithm from [8], on which\n\nQubitHD is based\n\n\u2022 Other state-of-the-art HD computing-based machine learning algorithms [6,9,15] \u2022 A multi-level perceptron (MLP) [19] (see Table III)\n\n\u2022 A binary neural network (BNN) [20] (see Table III)\n\nTo show the advantage of the QubitHD and the previous [8] algorithm, we used the datasets summarized in Table  I. The datasets range from small datasets like UCIHAR and ISOLET (frequently used in IoT devices, for which QubitHD is specially created), to larger datasets like face recognition.\n\n\nB. Accuracy\n\nThe evaluation of the baseline HD model provides high-classification accuracy when using non-binarized hypervectors for classification. The problem, however, is that retraining and inference with a non-binary class hypervector is very costly, as it requires calculating cosine similarities. That is, for k-bit integers or floating-point numbers O(Dk 2 ) basic operations need to be performed through every step. These are costly and impractical on small-scale and battery-powered devices.\n\nSimilarly, during inference, the associative search between a query and a trained model requires the calculation of the costly cosine similarities. To address this issue, many HD computing-based machine learning algorithms binarize their models [9]. That way, the cosine similarity is replaced by a simple Hamming distance similarity check. The key problem with this approach is that it leads to a significant decrease in classification accuracy, as shown in Table II.\n\nThe authors of [8] already showed the existence of a partial solution to this problem, which involves simultaneously retraining the non-binarized model, while updating the binarized model. We already listed the problems with this model in subsection IV. What especially motivated us to create a stable and more reliable QubitHD algorithm, is the fact that the QuantHD algorithm's retraining is unstable and unreliable. After extensively testing the QubitHD algorithm, we conclude that it, on average, closes the gap of classification accuracy by 38.8% as compared to the baseline HD computing-based machine learning algorithms in [9] using the QuantHD framework (See Table II).\n\nAdditionally, we observe that the accuracies of the QubitHD algorithm, using a binary model, are 1.2% and 60% higher than the classification accuracies of the baseline HD computing-based algorithm using non-quantized and binary respectively. Figure 1 compares the classification accuracy of QubitHD and QuantHD during different training iterations. It is clear that QubitHD converges much faster than QuantHD, as a result of the stochastic binarization process.\n\n\nC. Training Efficiency\n\nThe training efficiency of HD-based algorithms is characterized by initial training of the model and subsequent retraining. Figure 5 shows the energy consumption and execution time of QubitHD during retraining.\n\n\u2022 Algorithms in this type all consume the same energy during the generation of the initial training model\n\n\u2022 The significant cost is the retraining: compared to the non-binarized model, QuantHD uses fewer operations when calculating the hypervector similarities (step 4 in Figure 3).\n\n\u2022 No complex cosine similarity has to be computed as calculating the Hamming distance is sufficient to determine whether there was a correct classification or not\n\n\u2022 The improvement of QubitHD lies in the faster convergence to a high classification accuracy, which is 30-50% faster than in QuantHD and also decreases the energy consumption after the initial training proportionally.\n\n\u2022 The QubitHD modification has a dual benefit. It makes it possible to save energy and time during training, whilst achieving the same or better classification accuracies during testing depending on whether the goal is rapid convergence or high classification accuracy.\n\n\nD. Inference Efficiency\n\nCompared to QuantHD, there is no gain or loss in the time execution or energy efficiency, since the models behave identically once they are trained. So we report the same 44 \u00d7 energy efficiency improvement and 5 \u00d7 speedup as compared to the non-binarized HD algorithm.  QubitHD is a classifier intended to run on low-powered devices, specifically with the goal of low energy consumption and fast and efficient execution in mind. As such, we set out to compare QubitHD, not only to QuantHD but also to other non-HD lightweight classifiers. In our analysis, we compared QubitHD accuracy and efficiency with the state-of-the-art lightweight classifiers, including Multi-Layer Perceptron (MLP) and Binarized Neural Network (BNN). For MLP and BNN, we aimed to use the same metric as employed in [20] with the small modification in input and output layers in order to run different applications. The results of this, presented in Table III, indicate that QubitHD, while having similar classification accuracies to very lightweight classifier BNNs and MLPs, drastically reduces CPU usage during training and execution time during the inference. In particular, compared to MLPs QubitHD uses 12 \u00d7 less CPU during training and is 84 \u00d7 faster during the inference on FPGAs. Compared with BNNs, QubitHD uses a factor of 101 \u00d7 less CPU time during training and is still 20 \u00d7 faster during the inference.\n\n\nVII. CONCLUSION\n\nMachine learning algorithms, based on Brain-inspired Hyperdimensional (HD) computing, imitate cognition by exploiting statistical properties of very high-dimensional vector spaces. They are a promising solution for energyefficient classification tasks. A weakness of existing HD computing-based ML algorithms is the fact that they have to be binarized to achieve very high energy efficiency. At the same time, binarized models reach lower classification accuracies. In order to solve the problem of the trade-off between energy efficiency and classification accuracy, we propose the QubitHD algorithm. With QubitHD, it is possible to use binarized HD computingbased ML algorithms, which provide virtually the same classification accuracies as their non-binarized counterparts. The algorithm is inspired by stochastic quantum state measurement techniques. The improvement of QubitHD is a duality and is reflected in the quicker convergence, and the higher and more stable classification accuracy achieved, as compared to QuantHD.\n\nFIG. 1 :\n1Average classification accuracies during different retraining iterations of QubitHD compared to binary QuantHD, for datasets listed in table (II). It is clear that QubitHD converges faster than QuantHD, as a result of the stochastic binarization process. It does so without utilizing additional hardware resources.\n\nFIG. 2 :\n2For comparison of the binarized hypervectors, we use the Hamming Overview of a simple HD computing-based machine learning algorithm for classification on the left. The encoding scheme used in this publication is illustrated on the right.\n\nFIG. 3 :FIG. 4 :\n34(a) QubitHD framework overview (including the initial training and the retraining of the non-binarized model based on the binarized model). (b) Efficient inference from model \"jumps\" out of local minima, as opposed to getting stuck for several iterations. The energy consumption during training depends on the number of retraining iterations, which are significantly reduced. On the left side, we have a visualization of equation 1 from QuantHD. On the right side, we have a visualization of equation 2 from QubitHD. White represents \u22121, blue +1, and the colors between represent a stochastic selection.\n\nTable (\n(II) also lists the maximum accuracies achieved with a large number (\u2265 1000) of training iterations for the individual datasets.\n\nTABLE I :\nIDatasets (n: number of features, k: number \nof classes). \n\nn K \n\nData \nSize \n\nTrain \nSize \n\nTest \nSize \nDescription \nISOLET 617 26 19MB 6,238 1,559 \nVoice Recognition [21] \nUCIHAR 561 12 10MB 6,213 1,554 Activity recognition(Mobile)[22] \nMNIST 784 10 220MB 60,000 10,000 \nHandwritten digits [23] \nFACE 608 2 1.3GB 522,441 2,494 \nFace recognition[24] \nEXTRA 225 4 140MB 146,869 16,343 Phone position recognition\n\nTABLE II :\nIIComparison of QubitHD classification accuracies with the state-of-the-art HD computing. Quantized Binary Non-Quantized Binary Binary with randomized flipBaseline HD \nQuantHD \nQubitHD \nNon-ISOLET \n91.1% \n88.1% \n95.8% \n94.6% \n95.3% \nUCIHAR \n93.8% \n77.4% \n95.9% \n93.0% \n94.1% \nMNIST \n88.1% \n32.70% \n91.2% \n87.1% \n88.3% \nFACE \n95.9% \n68.4% \n96.2% \n94.6% \n95.4% \nMean \n92.23% \n65.9% \n94.78% \n92.33% \n93.28 \n\n\n\nTABLE III :\nIIIComparison of QubitHD with MLP and BNN in terms of accuracy, efficiency, and model size [8] FIG. 5: Energy consumption and execution time of initial training, QuantHD retraining and QubitHD retraining on a FPGA E. QubitHD comparison with MLP and BNNMLP/BNN \nTopologies \nAccuracy \nCPU Training (s) FPGA Inference (\u00b5s) \nModel Size \n\nMLP BNN QubitHD MLP BNN QubitHD MLP BNN QubitHD \nMLP \nBNN QubitHD \nISOLET 617-512-256-26 95.8% 96.1% 95.3% 2.08 17.69 \n0.19 \n27.39 5.24 \n0.28 \n1.81MB 56.7KB 65.0KB \nUCIHAR 561-512-256-12 97.3% 95.9% 94.1% 1.04 8.32 \n0.08 \n21.43 5.18 \n0.27 \n1.68MB 52.7KB 30.0KB \nFACE \n608-512-256-2 96.1% 96.1% 95.4% 0.56 4.30 \n0.03 \n17.68 5.11 \n0.24 \n1.77MB 55.3KB 5.0KB \n\nBaseline HD \nQuantHD \nQubitHD \n\n30 \n10 \n11 \n\n30 \n9 \n9.7 \n\n31 \n9.5 \n10 \n\n26 \n8.6 \n8.8 \n\nISOLET \n\nUCIHAR \n\nMNIST \n\nFACE \n\nEnergy consumption (\u00b5J) \n\n1 \n\n10 \n\n100 \n\n1000 \n\nISOLET \nUCIHAR \nMNIST \nFACE \n\nInitial Training (one shot) \nQuantHD (retraining) \nQuantHD (retraining) \n\nQuantHD \nretraining \n\nQubitHD \n\n450 \n220 \n\n405 \n194 \n\n427.5 \n200 \n\n387 \n176 \n\nISOLET \n\nUCIHAR \n\nMNIST \n\nFACE \n\nTraining Time (\u00b5s) \non FPGA \n\n1 \n\n10 \n\n100 \n\nISOLET \nUCIHAR \nMNIST \nFACE \n\n2 \n\n\n\nInternet of things (iot): A vision, architectural elements, and future directions, Future generation computer systems. J Gubbi, R Buyya, S Marusic, M Palaniswami, 291645J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, Internet of things (iot): A vision, architectural elements, and future directions, Future generation computer sys- tems 29, 1645 (2013).\n\nImagenet: A large-scale hierarchical image database. J Deng, W Dong, R Socher, L.-J Li, K Li, L Fei-Fei, 2009 IEEE conference on computer vision and pattern recognition. IeeeJ. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei- Fei, Imagenet: A large-scale hierarchical image database, in 2009 IEEE conference on computer vision and pattern recognition (Ieee, 2009) pp. 248-255.\n\nAugmenting existing deterioration indices with chest radiographs to predict clinical deterioration. E Mu, S Jabbour, A V Dalca, J Guttag, J Wiens, M W Sjoding, Plos one. 17263922E. Mu, S. Jabbour, A. V. Dalca, J. Guttag, J. Wiens, and M. W. Sjoding, Augmenting existing deterioration indices with chest radiographs to predict clinical deteri- oration, Plos one 17, e0263922 (2022).\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, Cognitive Computation. 1139P. Kanerva, Hyperdimensional computing: An intro- duction to computing in distributed representation with high-dimensional random vectors, Cognitive Computa- tion 1, 139 (2009).\n\nRevisiting hyperdimensional learning for fpga and low-power architectures. M Imani, Z Zou, S Bosch, S A Rao, S Salamat, V Kumar, Y Kim, T Rosing, 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA. IEEEM. Imani, Z. Zou, S. Bosch, S. A. Rao, S. Salamat, V. Kumar, Y. Kim, and T. Rosing, Revisiting hyper- dimensional learning for fpga and low-power architec- tures, in 2021 IEEE International Symposium on High- Performance Computer Architecture (HPCA) (IEEE, 2021) pp. 221-234.\n\nComphd: Efficient hyperdimensional computing using model compression. J Morris, M Imani, S Bosch, A Thomas, H Shu, T Rosing, 2019 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED. IEEEJ. Morris, M. Imani, S. Bosch, A. Thomas, H. Shu, and T. Rosing, Comphd: Efficient hyperdimensional comput- ing using model compression, in 2019 IEEE/ACM Inter- national Symposium on Low Power Electronics and De- sign (ISLPED) (IEEE, 2019) pp. 1-6.\n\nSparsehd: Algorithmhardware co-optimization for efficient high-dimensional computing. M Imani, S Salamat, B Khaleghi, M Samragh, F Koushanfar, T Rosing, 2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM. IEEEM. Imani, S. Salamat, B. Khaleghi, M. Samragh, F. Koushanfar, and T. Rosing, Sparsehd: Algorithm- hardware co-optimization for efficient high-dimensional computing, in 2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM) (IEEE, 2019) pp. 190-198.\n\nQuanthd: A quantization framework for hyperdimensional computing. M Imani, S Bosch, S Datta, S Ramakrishna, S Salamat, J M Rabaey, T S Rosing, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. TCADM. Imani, S. Bosch, S. Datta, S. Ramakrishna, S. Sala- mat, J. M. Rabaey, and T. S. Rosing, Quanthd: A quanti- zation framework for hyperdimensional computing, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD) (2019).\n\nA robust and energy-efficient classifier using brain-inspired hyperdimensional computing. A Rahimi, P Kanerva, J M Rabaey, Proceedings of the 2016 International Symposium on Low Power Electronics and Design. the 2016 International Symposium on Low Power Electronics and DesignACMA. Rahimi, P. Kanerva, and J. M. Rabaey, A robust and energy-efficient classifier using brain-inspired hyper- dimensional computing, in Proceedings of the 2016 In- ternational Symposium on Low Power Electronics and Design (ACM, 2016) pp. 64-69.\n\nSemihd: Semisupervised learning using hyperdimensional computing. M Imani, S Bosch, M Javaheripi, B Rouhani, X Wu, F Koushanfar, T S Rosing, IEEE/ACM International Conference On Computer Aided Design (ICCAD. 1M. Imani, S. Bosch, M. Javaheripi, B. Rouhani, X. Wu, F. Koushanfar, and T. S. Rosing, Semihd: Semi- supervised learning using hyperdimensional comput- ing, IEEE/ACM International Conference On Computer Aided Design (ICCAD) , 1 (2019).\n\n. H Li, T F Wu, A Rahimi, K.-S Li, M Rusch, C.-H Lin, J.-L Hsu, M M Sabry, S B Eryilmaz, J. Sohn, W.-C. Chiu, M.-C. Chen, T.-T. Wu, J.-M. Shieh, W.-KH. Li, T. F. Wu, A. Rahimi, K.-S. Li, M. Rusch, C.-H. Lin, J.-L. Hsu, M. M. Sabry, S. B. Eryilmaz, J. Sohn, W.-C. Chiu, M.-C. Chen, T.-T. Wu, J.-M. Shieh, W.-K.\n\nHyperdimensional computing with 3d vrram in-memory kernels: Device-architecture co-design for energy-efficient, error-resilient language recognition. J M Yeh, S Rabaey, W H Mitra, - S Philipa, 2016 IEEE International Electron Devices Meeting (IEDM. IEEEYeh, J. M. Rabaey, S. Mitra, and W. H.-S. Philipa, Hy- perdimensional computing with 3d vrram in-memory ker- nels: Device-architecture co-design for energy-efficient, error-resilient language recognition, in 2016 IEEE Inter- national Electron Devices Meeting (IEDM) (IEEE, 2016) pp. 16-1.\n\nHyperdimensional computing exploiting carbon nanotube fets, resistive ram, and their monolithic 3d integration. T F Wu, H Li, P.-C Huang, A Rahimi, G Hills, B Hodson, W Hwang, J M Rabaey, H.-S P Wong, M M Shulaker, S Mitra, IEEE Journal of Solid-State Circuits. 533183T. F. Wu, H. Li, P.-C. Huang, A. Rahimi, G. Hills, B. Hodson, W. Hwang, J. M. Rabaey, H.-S. P. Wong, M. M. Shulaker, and S. Mitra, Hyperdimensional com- puting exploiting carbon nanotube fets, resistive ram, and their monolithic 3d integration, IEEE Journal of Solid-State Circuits 53, 3183 (2018).\n\nHyperdimensional biosignal processing: A case study for emg-based hand gesture recognition. A Rahimi, S Benatti, P Kanerva, L Benini, J M Rabaey, Rebooting Computing (ICRC), IEEE International Conference on. IEEEA. Rahimi, S. Benatti, P. Kanerva, L. Benini, and J. M. Rabaey, Hyperdimensional biosignal processing: A case study for emg-based hand gesture recognition, in Reboot- ing Computing (ICRC), IEEE International Conference on (IEEE, 2016) pp. 1-8.\n\nBrain-inspired computing exploiting carbon nanotube fets and resistive ram: Hyperdimensional computing case study. T Wu, P Huang, A Rahimi, H Li, J Rabaey, P Wong, S Mitra, IEEE Intl. Solid-State Circuits Conference (ISSCC. IEEET. Wu, P. Huang, A. Rahimi, H. Li, J. Rabaey, P. Wong, and S. Mitra, Brain-inspired computing exploiting car- bon nanotube fets and resistive ram: Hyperdimensional computing case study, in IEEE Intl. Solid-State Circuits Conference (ISSCC) (IEEE, 2018).\n\nAdapthd: Adaptive efficient training for brain-inspired hyperdimensional computing. M Imani, J Morris, S Bosch, H Shu, G De Micheli, T Rosing, 2019 IEEE Biomedical Circuits and Systems Conference. Bio-CASIEEEM. Imani, J. Morris, S. Bosch, H. Shu, G. De Micheli, and T. Rosing, Adapthd: Adaptive efficient training for brain-inspired hyperdimensional computing, in 2019 IEEE Biomedical Circuits and Systems Conference (Bio- CAS) (IEEE, 2019) pp. 1-4.\n\nHighdimensional computing as a nanoscalable paradigm. A Rahimi, S Datta, D Kleyko, E P Frady, B Olshausen, P Kanerva, J M Rabaey, IEEE Transactions on Circuits and Systems I: Regular Papers. 642508A. Rahimi, S. Datta, D. Kleyko, E. P. Frady, B. Olshausen, P. Kanerva, and J. M. Rabaey, High- dimensional computing as a nanoscalable paradigm, IEEE Transactions on Circuits and Systems I: Regular Papers 64, 2508 (2017).\n\nExploring hyperdimensional associative memory. M Imani, A Rahimi, D Kong, T Rosing, J M Rabaey, High Performance Computer Architecture (HPCA. 2017 IEEE International Symposium onM. Imani, A. Rahimi, D. Kong, T. Rosing, and J. M. Rabaey, Exploring hyperdimensional associa- tive memory, in High Performance Computer Architec- ture (HPCA), 2017 IEEE International Symposium on (IEEE, 2017) pp. 445-456.\n\nHyperdimensional computing for blind and one-shot classification of eeg error-related potentials. A Rahimi, A Tchouprina, P Kanerva, J D R Mill\u00e1n, J M Rabaey, Mobile Networks and Applications. 1A. Rahimi, A. Tchouprina, P. Kanerva, J. d. R. Mill\u00e1n, and J. M. Rabaey, Hyperdimensional computing for blind and one-shot classification of eeg error-related potentials, Mobile Networks and Applications , 1 (2017).\n\nFrom highlevel deep neural models to fpgas. H Sharma, J Park, D Mahajan, E Amaro, J K Kim, C Shao, A Mishra, H Esmaeilzadeh, 49th Annual IEEE/ACM International Symposium on. IEEEMicroarchitecture (MICRO)H. Sharma, J. Park, D. Mahajan, E. Amaro, J. K. Kim, C. Shao, A. Mishra, and H. Esmaeilzadeh, From high- level deep neural models to fpgas, in Microarchitecture (MICRO), 2016 49th Annual IEEE/ACM International Symposium on (IEEE, 2016) pp. 1-12.\n\nFinn: A framework for fast, scalable binarized neural network inference. Y Umuroglu, N J Fraser, G Gambardella, M Blott, P Leong, M Jahre, K Vissers, Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays. the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate ArraysACMY. Umuroglu, N. J. Fraser, G. Gambardella, M. Blott, P. Leong, M. Jahre, and K. Vissers, Finn: A frame- work for fast, scalable binarized neural network inference, in Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (ACM, 2017) pp. 65-74.\n\nUci machine learning repository. Uci machine learning repository, http://archive.ics. uci.edu/ml/datasets/ISOLET.\n\nHuman activity recognition on smartphones using a multiclass hardware-friendly support vector machine. D Anguita, A Ghio, L Oneto, X Parra, J L Reyes-Ortiz, International workshop on ambient assisted living. SpringerD. Anguita, A. Ghio, L. Oneto, X. Parra, and J. L. Reyes-Ortiz, Human activity recognition on smartphones using a multiclass hardware-friendly support vector ma- chine, in International workshop on ambient assisted liv- ing (Springer, 2012) pp. 216-223.\n\nMnist handwritten digit database. Y Lecun, C Cortes, C J Burges, AT&T LabsY. LeCun, C. Cortes, and C. J. Burges, Mnist hand- written digit database, AT&T Labs [Online]. Available: http://yann. lecun. com/exdb/mnist (2010).\n\nOrchard: Visual object recognition accelerator based on approximate in-memory processing. Y Kim, M Imani, T Rosing, Computer-Aided Design (ICCAD. 2017Y. Kim, M. Imani, and T. Rosing, Orchard: Visual object recognition accelerator based on approximate in-memory processing, in Computer-Aided Design (ICCAD), 2017\n\nIEEE/ACM International Conference on. IEEE/ACM International Conference on (IEEE, 2017) pp. 25-32.\n\nRecognizing detailed human context in the wild from smartphones and smartwatches. Y Vaizman, K Ellis, G Lanckriet, IEEE Pervasive Computing. 1662Y. Vaizman, K. Ellis, and G. Lanckriet, Recognizing de- tailed human context in the wild from smartphones and smartwatches, IEEE Pervasive Computing 16, 62 (2017).\n", "annotations": {"author": "[{\"end\":157,\"start\":85},{\"end\":228,\"start\":158},{\"end\":292,\"start\":229},{\"end\":439,\"start\":293},{\"end\":460,\"start\":440}]", "publisher": null, "author_last_name": "[{\"end\":97,\"start\":92},{\"end\":187,\"start\":168},{\"end\":241,\"start\":236},{\"end\":313,\"start\":307},{\"end\":459,\"start\":449}]", "author_first_name": "[{\"end\":91,\"start\":85},{\"end\":167,\"start\":158},{\"end\":235,\"start\":229},{\"end\":306,\"start\":293},{\"end\":448,\"start\":440}]", "author_affiliation": "[{\"end\":156,\"start\":99},{\"end\":227,\"start\":189},{\"end\":291,\"start\":243},{\"end\":368,\"start\":315},{\"end\":438,\"start\":370}]", "title": "[{\"end\":82,\"start\":1},{\"end\":542,\"start\":461}]", "venue": null, "abstract": "[{\"end\":1778,\"start\":569}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1946,\"start\":1943},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2289,\"start\":2286},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2337,\"start\":2334},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2759,\"start\":2756},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3000,\"start\":2997},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3220,\"start\":3217},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4094,\"start\":4091},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4096,\"start\":4094},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4241,\"start\":4238},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5737,\"start\":5734},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6386,\"start\":6383},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6431,\"start\":6428},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7185,\"start\":7181},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7702,\"start\":7699},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9303,\"start\":9300},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9307,\"start\":9303},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9311,\"start\":9307},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9315,\"start\":9311},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9319,\"start\":9315},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9554,\"start\":9551},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10406,\"start\":10402},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10861,\"start\":10857},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":10865,\"start\":10861},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10869,\"start\":10865},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":11379,\"start\":11376},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13489,\"start\":13486},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":14715,\"start\":14712},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":15749,\"start\":15746},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":17684,\"start\":17681},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":18396,\"start\":18392},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":18595,\"start\":18592},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18700,\"start\":18697},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18702,\"start\":18700},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":18705,\"start\":18702},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18743,\"start\":18739},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":18797,\"start\":18793},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":18872,\"start\":18869},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19860,\"start\":19857},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20100,\"start\":20097},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20715,\"start\":20712},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":23221,\"start\":23217}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":25191,\"start\":24866},{\"attributes\":{\"id\":\"fig_1\"},\"end\":25440,\"start\":25192},{\"attributes\":{\"id\":\"fig_2\"},\"end\":26064,\"start\":25441},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":26202,\"start\":26065},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":26625,\"start\":26203},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":27043,\"start\":26626},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":28210,\"start\":27044}]", "paragraph": "[{\"end\":2707,\"start\":1780},{\"end\":3905,\"start\":2709},{\"end\":4367,\"start\":3907},{\"end\":4992,\"start\":4369},{\"end\":5246,\"start\":4994},{\"end\":5302,\"start\":5248},{\"end\":5461,\"start\":5304},{\"end\":5812,\"start\":5463},{\"end\":5965,\"start\":5814},{\"end\":6855,\"start\":5967},{\"end\":7401,\"start\":6890},{\"end\":8195,\"start\":7417},{\"end\":8514,\"start\":8216},{\"end\":8864,\"start\":8647},{\"end\":8988,\"start\":8902},{\"end\":9456,\"start\":9012},{\"end\":10447,\"start\":9474},{\"end\":10711,\"start\":10464},{\"end\":10820,\"start\":10732},{\"end\":12327,\"start\":10822},{\"end\":12563,\"start\":12360},{\"end\":12701,\"start\":12565},{\"end\":12786,\"start\":12740},{\"end\":13178,\"start\":12918},{\"end\":13785,\"start\":13281},{\"end\":13972,\"start\":13787},{\"end\":14161,\"start\":13974},{\"end\":14378,\"start\":14163},{\"end\":14819,\"start\":14380},{\"end\":15265,\"start\":14892},{\"end\":15529,\"start\":15315},{\"end\":16929,\"start\":15531},{\"end\":17383,\"start\":16931},{\"end\":17976,\"start\":17419},{\"end\":18561,\"start\":18019},{\"end\":18605,\"start\":18563},{\"end\":18623,\"start\":18607},{\"end\":18759,\"start\":18625},{\"end\":18813,\"start\":18761},{\"end\":19106,\"start\":18815},{\"end\":19610,\"start\":19122},{\"end\":20080,\"start\":19612},{\"end\":20759,\"start\":20082},{\"end\":21222,\"start\":20761},{\"end\":21459,\"start\":21249},{\"end\":21566,\"start\":21461},{\"end\":21744,\"start\":21568},{\"end\":21908,\"start\":21746},{\"end\":22128,\"start\":21910},{\"end\":22399,\"start\":22130},{\"end\":23817,\"start\":22427},{\"end\":24865,\"start\":23837}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8215,\"start\":8196},{\"attributes\":{\"id\":\"formula_1\"},\"end\":8646,\"start\":8515},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8901,\"start\":8865},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12739,\"start\":12702},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12917,\"start\":12787},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13267,\"start\":13179},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14861,\"start\":14820},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15314,\"start\":15266}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":6853,\"start\":6844},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":18758,\"start\":18749},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":18812,\"start\":18803},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":18927,\"start\":18919},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":20079,\"start\":20071},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":20758,\"start\":20749},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":23360,\"start\":23351}]", "section_header": "[{\"end\":6888,\"start\":6858},{\"end\":7415,\"start\":7404},{\"end\":9010,\"start\":8991},{\"end\":9472,\"start\":9459},{\"end\":10462,\"start\":10450},{\"end\":10730,\"start\":10714},{\"end\":12358,\"start\":12330},{\"end\":13279,\"start\":13269},{\"end\":14890,\"start\":14863},{\"end\":17417,\"start\":17386},{\"end\":17993,\"start\":17979},{\"end\":18017,\"start\":17996},{\"end\":19120,\"start\":19109},{\"end\":21247,\"start\":21225},{\"end\":22425,\"start\":22402},{\"end\":23835,\"start\":23820},{\"end\":24875,\"start\":24867},{\"end\":25201,\"start\":25193},{\"end\":25458,\"start\":25442},{\"end\":26073,\"start\":26066},{\"end\":26213,\"start\":26204},{\"end\":26637,\"start\":26627},{\"end\":27056,\"start\":27045}]", "table": "[{\"end\":26625,\"start\":26215},{\"end\":27043,\"start\":26793},{\"end\":28210,\"start\":27309}]", "figure_caption": "[{\"end\":25191,\"start\":24877},{\"end\":25440,\"start\":25203},{\"end\":26064,\"start\":25461},{\"end\":26202,\"start\":26075},{\"end\":26793,\"start\":26640},{\"end\":27309,\"start\":27060}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":7232,\"start\":7224},{\"end\":9623,\"start\":9615},{\"end\":10401,\"start\":10392},{\"end\":12147,\"start\":12139},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14458,\"start\":14449},{\"end\":14609,\"start\":14600},{\"end\":14638,\"start\":14629},{\"end\":15865,\"start\":15857},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":21011,\"start\":21003},{\"end\":21381,\"start\":21373},{\"end\":21742,\"start\":21734}]", "bib_author_first_name": "[{\"end\":28332,\"start\":28331},{\"end\":28341,\"start\":28340},{\"end\":28350,\"start\":28349},{\"end\":28361,\"start\":28360},{\"end\":28625,\"start\":28624},{\"end\":28633,\"start\":28632},{\"end\":28641,\"start\":28640},{\"end\":28654,\"start\":28650},{\"end\":28660,\"start\":28659},{\"end\":28666,\"start\":28665},{\"end\":29056,\"start\":29055},{\"end\":29062,\"start\":29061},{\"end\":29073,\"start\":29072},{\"end\":29075,\"start\":29074},{\"end\":29084,\"start\":29083},{\"end\":29094,\"start\":29093},{\"end\":29103,\"start\":29102},{\"end\":29105,\"start\":29104},{\"end\":29464,\"start\":29463},{\"end\":29756,\"start\":29755},{\"end\":29765,\"start\":29764},{\"end\":29772,\"start\":29771},{\"end\":29781,\"start\":29780},{\"end\":29783,\"start\":29782},{\"end\":29790,\"start\":29789},{\"end\":29801,\"start\":29800},{\"end\":29810,\"start\":29809},{\"end\":29817,\"start\":29816},{\"end\":30261,\"start\":30260},{\"end\":30271,\"start\":30270},{\"end\":30280,\"start\":30279},{\"end\":30289,\"start\":30288},{\"end\":30299,\"start\":30298},{\"end\":30306,\"start\":30305},{\"end\":30739,\"start\":30738},{\"end\":30748,\"start\":30747},{\"end\":30759,\"start\":30758},{\"end\":30771,\"start\":30770},{\"end\":30782,\"start\":30781},{\"end\":30796,\"start\":30795},{\"end\":31273,\"start\":31272},{\"end\":31282,\"start\":31281},{\"end\":31291,\"start\":31290},{\"end\":31300,\"start\":31299},{\"end\":31315,\"start\":31314},{\"end\":31326,\"start\":31325},{\"end\":31328,\"start\":31327},{\"end\":31338,\"start\":31337},{\"end\":31340,\"start\":31339},{\"end\":31777,\"start\":31776},{\"end\":31787,\"start\":31786},{\"end\":31798,\"start\":31797},{\"end\":31800,\"start\":31799},{\"end\":32278,\"start\":32277},{\"end\":32287,\"start\":32286},{\"end\":32296,\"start\":32295},{\"end\":32310,\"start\":32309},{\"end\":32321,\"start\":32320},{\"end\":32327,\"start\":32326},{\"end\":32341,\"start\":32340},{\"end\":32343,\"start\":32342},{\"end\":32660,\"start\":32659},{\"end\":32666,\"start\":32665},{\"end\":32668,\"start\":32667},{\"end\":32674,\"start\":32673},{\"end\":32687,\"start\":32683},{\"end\":32693,\"start\":32692},{\"end\":32705,\"start\":32701},{\"end\":32715,\"start\":32711},{\"end\":32722,\"start\":32721},{\"end\":32724,\"start\":32723},{\"end\":32733,\"start\":32732},{\"end\":32735,\"start\":32734},{\"end\":33119,\"start\":33118},{\"end\":33121,\"start\":33120},{\"end\":33128,\"start\":33127},{\"end\":33138,\"start\":33137},{\"end\":33140,\"start\":33139},{\"end\":33149,\"start\":33148},{\"end\":33151,\"start\":33150},{\"end\":33624,\"start\":33623},{\"end\":33626,\"start\":33625},{\"end\":33632,\"start\":33631},{\"end\":33641,\"start\":33637},{\"end\":33650,\"start\":33649},{\"end\":33660,\"start\":33659},{\"end\":33669,\"start\":33668},{\"end\":33679,\"start\":33678},{\"end\":33688,\"start\":33687},{\"end\":33690,\"start\":33689},{\"end\":33703,\"start\":33699},{\"end\":33705,\"start\":33704},{\"end\":33713,\"start\":33712},{\"end\":33715,\"start\":33714},{\"end\":33727,\"start\":33726},{\"end\":34172,\"start\":34171},{\"end\":34182,\"start\":34181},{\"end\":34193,\"start\":34192},{\"end\":34204,\"start\":34203},{\"end\":34214,\"start\":34213},{\"end\":34216,\"start\":34215},{\"end\":34652,\"start\":34651},{\"end\":34658,\"start\":34657},{\"end\":34667,\"start\":34666},{\"end\":34677,\"start\":34676},{\"end\":34683,\"start\":34682},{\"end\":34693,\"start\":34692},{\"end\":34701,\"start\":34700},{\"end\":35104,\"start\":35103},{\"end\":35113,\"start\":35112},{\"end\":35123,\"start\":35122},{\"end\":35132,\"start\":35131},{\"end\":35139,\"start\":35138},{\"end\":35142,\"start\":35140},{\"end\":35153,\"start\":35152},{\"end\":35525,\"start\":35524},{\"end\":35535,\"start\":35534},{\"end\":35544,\"start\":35543},{\"end\":35554,\"start\":35553},{\"end\":35556,\"start\":35555},{\"end\":35565,\"start\":35564},{\"end\":35578,\"start\":35577},{\"end\":35589,\"start\":35588},{\"end\":35591,\"start\":35590},{\"end\":35938,\"start\":35937},{\"end\":35947,\"start\":35946},{\"end\":35957,\"start\":35956},{\"end\":35965,\"start\":35964},{\"end\":35975,\"start\":35974},{\"end\":35977,\"start\":35976},{\"end\":36391,\"start\":36390},{\"end\":36401,\"start\":36400},{\"end\":36415,\"start\":36414},{\"end\":36426,\"start\":36425},{\"end\":36430,\"start\":36427},{\"end\":36440,\"start\":36439},{\"end\":36442,\"start\":36441},{\"end\":36748,\"start\":36747},{\"end\":36758,\"start\":36757},{\"end\":36766,\"start\":36765},{\"end\":36777,\"start\":36776},{\"end\":36786,\"start\":36785},{\"end\":36788,\"start\":36787},{\"end\":36795,\"start\":36794},{\"end\":36803,\"start\":36802},{\"end\":36813,\"start\":36812},{\"end\":37227,\"start\":37226},{\"end\":37239,\"start\":37238},{\"end\":37241,\"start\":37240},{\"end\":37251,\"start\":37250},{\"end\":37266,\"start\":37265},{\"end\":37275,\"start\":37274},{\"end\":37284,\"start\":37283},{\"end\":37293,\"start\":37292},{\"end\":37977,\"start\":37976},{\"end\":37988,\"start\":37987},{\"end\":37996,\"start\":37995},{\"end\":38005,\"start\":38004},{\"end\":38014,\"start\":38013},{\"end\":38016,\"start\":38015},{\"end\":38379,\"start\":38378},{\"end\":38388,\"start\":38387},{\"end\":38398,\"start\":38397},{\"end\":38400,\"start\":38399},{\"end\":38659,\"start\":38658},{\"end\":38666,\"start\":38665},{\"end\":38675,\"start\":38674},{\"end\":39064,\"start\":39063},{\"end\":39075,\"start\":39074},{\"end\":39084,\"start\":39083}]", "bib_author_last_name": "[{\"end\":28338,\"start\":28333},{\"end\":28347,\"start\":28342},{\"end\":28358,\"start\":28351},{\"end\":28373,\"start\":28362},{\"end\":28630,\"start\":28626},{\"end\":28638,\"start\":28634},{\"end\":28648,\"start\":28642},{\"end\":28657,\"start\":28655},{\"end\":28663,\"start\":28661},{\"end\":28674,\"start\":28667},{\"end\":29059,\"start\":29057},{\"end\":29070,\"start\":29063},{\"end\":29081,\"start\":29076},{\"end\":29091,\"start\":29085},{\"end\":29100,\"start\":29095},{\"end\":29113,\"start\":29106},{\"end\":29472,\"start\":29465},{\"end\":29762,\"start\":29757},{\"end\":29769,\"start\":29766},{\"end\":29778,\"start\":29773},{\"end\":29787,\"start\":29784},{\"end\":29798,\"start\":29791},{\"end\":29807,\"start\":29802},{\"end\":29814,\"start\":29811},{\"end\":29824,\"start\":29818},{\"end\":30268,\"start\":30262},{\"end\":30277,\"start\":30272},{\"end\":30286,\"start\":30281},{\"end\":30296,\"start\":30290},{\"end\":30303,\"start\":30300},{\"end\":30313,\"start\":30307},{\"end\":30745,\"start\":30740},{\"end\":30756,\"start\":30749},{\"end\":30768,\"start\":30760},{\"end\":30779,\"start\":30772},{\"end\":30793,\"start\":30783},{\"end\":30803,\"start\":30797},{\"end\":31279,\"start\":31274},{\"end\":31288,\"start\":31283},{\"end\":31297,\"start\":31292},{\"end\":31312,\"start\":31301},{\"end\":31323,\"start\":31316},{\"end\":31335,\"start\":31329},{\"end\":31347,\"start\":31341},{\"end\":31784,\"start\":31778},{\"end\":31795,\"start\":31788},{\"end\":31807,\"start\":31801},{\"end\":32284,\"start\":32279},{\"end\":32293,\"start\":32288},{\"end\":32307,\"start\":32297},{\"end\":32318,\"start\":32311},{\"end\":32324,\"start\":32322},{\"end\":32338,\"start\":32328},{\"end\":32350,\"start\":32344},{\"end\":32663,\"start\":32661},{\"end\":32671,\"start\":32669},{\"end\":32681,\"start\":32675},{\"end\":32690,\"start\":32688},{\"end\":32699,\"start\":32694},{\"end\":32709,\"start\":32706},{\"end\":32719,\"start\":32716},{\"end\":32730,\"start\":32725},{\"end\":32744,\"start\":32736},{\"end\":33125,\"start\":33122},{\"end\":33135,\"start\":33129},{\"end\":33146,\"start\":33141},{\"end\":33159,\"start\":33152},{\"end\":33629,\"start\":33627},{\"end\":33635,\"start\":33633},{\"end\":33647,\"start\":33642},{\"end\":33657,\"start\":33651},{\"end\":33666,\"start\":33661},{\"end\":33676,\"start\":33670},{\"end\":33685,\"start\":33680},{\"end\":33697,\"start\":33691},{\"end\":33710,\"start\":33706},{\"end\":33724,\"start\":33716},{\"end\":33733,\"start\":33728},{\"end\":34179,\"start\":34173},{\"end\":34190,\"start\":34183},{\"end\":34201,\"start\":34194},{\"end\":34211,\"start\":34205},{\"end\":34223,\"start\":34217},{\"end\":34655,\"start\":34653},{\"end\":34664,\"start\":34659},{\"end\":34674,\"start\":34668},{\"end\":34680,\"start\":34678},{\"end\":34690,\"start\":34684},{\"end\":34698,\"start\":34694},{\"end\":34707,\"start\":34702},{\"end\":35110,\"start\":35105},{\"end\":35120,\"start\":35114},{\"end\":35129,\"start\":35124},{\"end\":35136,\"start\":35133},{\"end\":35150,\"start\":35143},{\"end\":35160,\"start\":35154},{\"end\":35532,\"start\":35526},{\"end\":35541,\"start\":35536},{\"end\":35551,\"start\":35545},{\"end\":35562,\"start\":35557},{\"end\":35575,\"start\":35566},{\"end\":35586,\"start\":35579},{\"end\":35598,\"start\":35592},{\"end\":35944,\"start\":35939},{\"end\":35954,\"start\":35948},{\"end\":35962,\"start\":35958},{\"end\":35972,\"start\":35966},{\"end\":35984,\"start\":35978},{\"end\":36398,\"start\":36392},{\"end\":36412,\"start\":36402},{\"end\":36423,\"start\":36416},{\"end\":36437,\"start\":36431},{\"end\":36449,\"start\":36443},{\"end\":36755,\"start\":36749},{\"end\":36763,\"start\":36759},{\"end\":36774,\"start\":36767},{\"end\":36783,\"start\":36778},{\"end\":36792,\"start\":36789},{\"end\":36800,\"start\":36796},{\"end\":36810,\"start\":36804},{\"end\":36826,\"start\":36814},{\"end\":37236,\"start\":37228},{\"end\":37248,\"start\":37242},{\"end\":37263,\"start\":37252},{\"end\":37272,\"start\":37267},{\"end\":37281,\"start\":37276},{\"end\":37290,\"start\":37285},{\"end\":37301,\"start\":37294},{\"end\":37985,\"start\":37978},{\"end\":37993,\"start\":37989},{\"end\":38002,\"start\":37997},{\"end\":38011,\"start\":38006},{\"end\":38028,\"start\":38017},{\"end\":38385,\"start\":38380},{\"end\":38395,\"start\":38389},{\"end\":38407,\"start\":38401},{\"end\":38663,\"start\":38660},{\"end\":38672,\"start\":38667},{\"end\":38682,\"start\":38676},{\"end\":39072,\"start\":39065},{\"end\":39081,\"start\":39076},{\"end\":39094,\"start\":39085}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":28569,\"start\":28212},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":57246310},\"end\":28953,\"start\":28571},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":246864316},\"end\":29336,\"start\":28955},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":733980},\"end\":29678,\"start\":29338},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":233376633},\"end\":30188,\"start\":29680},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":197618493},\"end\":30650,\"start\":30190},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":189824904},\"end\":31204,\"start\":30652},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":211016154},\"end\":31684,\"start\":31206},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":9812826},\"end\":32209,\"start\":31686},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":209497828},\"end\":32655,\"start\":32211},{\"attributes\":{\"id\":\"b10\"},\"end\":32966,\"start\":32657},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":25209638},\"end\":33509,\"start\":32968},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":53227383},\"end\":34077,\"start\":33511},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":12008695},\"end\":34534,\"start\":34079},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3869844},\"end\":35017,\"start\":34536},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":203651142},\"end\":35468,\"start\":35019},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":10569020},\"end\":35888,\"start\":35470},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":1677864},\"end\":36290,\"start\":35890},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":12928560},\"end\":36701,\"start\":36292},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":525898},\"end\":37151,\"start\":36703},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":10530917},\"end\":37756,\"start\":37153},{\"attributes\":{\"id\":\"b21\"},\"end\":37871,\"start\":37758},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":13178535},\"end\":38342,\"start\":37873},{\"attributes\":{\"id\":\"b23\"},\"end\":38566,\"start\":38344},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":4701912},\"end\":38879,\"start\":38568},{\"attributes\":{\"id\":\"b25\"},\"end\":38979,\"start\":38881},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":8728742},\"end\":39289,\"start\":38981}]", "bib_title": "[{\"end\":28622,\"start\":28571},{\"end\":29053,\"start\":28955},{\"end\":29461,\"start\":29338},{\"end\":29753,\"start\":29680},{\"end\":30258,\"start\":30190},{\"end\":30736,\"start\":30652},{\"end\":31270,\"start\":31206},{\"end\":31774,\"start\":31686},{\"end\":32275,\"start\":32211},{\"end\":33116,\"start\":32968},{\"end\":33621,\"start\":33511},{\"end\":34169,\"start\":34079},{\"end\":34649,\"start\":34536},{\"end\":35101,\"start\":35019},{\"end\":35522,\"start\":35470},{\"end\":35935,\"start\":35890},{\"end\":36388,\"start\":36292},{\"end\":36745,\"start\":36703},{\"end\":37224,\"start\":37153},{\"end\":37974,\"start\":37873},{\"end\":38656,\"start\":38568},{\"end\":39061,\"start\":38981}]", "bib_author": "[{\"end\":28340,\"start\":28331},{\"end\":28349,\"start\":28340},{\"end\":28360,\"start\":28349},{\"end\":28375,\"start\":28360},{\"end\":28632,\"start\":28624},{\"end\":28640,\"start\":28632},{\"end\":28650,\"start\":28640},{\"end\":28659,\"start\":28650},{\"end\":28665,\"start\":28659},{\"end\":28676,\"start\":28665},{\"end\":29061,\"start\":29055},{\"end\":29072,\"start\":29061},{\"end\":29083,\"start\":29072},{\"end\":29093,\"start\":29083},{\"end\":29102,\"start\":29093},{\"end\":29115,\"start\":29102},{\"end\":29474,\"start\":29463},{\"end\":29764,\"start\":29755},{\"end\":29771,\"start\":29764},{\"end\":29780,\"start\":29771},{\"end\":29789,\"start\":29780},{\"end\":29800,\"start\":29789},{\"end\":29809,\"start\":29800},{\"end\":29816,\"start\":29809},{\"end\":29826,\"start\":29816},{\"end\":30270,\"start\":30260},{\"end\":30279,\"start\":30270},{\"end\":30288,\"start\":30279},{\"end\":30298,\"start\":30288},{\"end\":30305,\"start\":30298},{\"end\":30315,\"start\":30305},{\"end\":30747,\"start\":30738},{\"end\":30758,\"start\":30747},{\"end\":30770,\"start\":30758},{\"end\":30781,\"start\":30770},{\"end\":30795,\"start\":30781},{\"end\":30805,\"start\":30795},{\"end\":31281,\"start\":31272},{\"end\":31290,\"start\":31281},{\"end\":31299,\"start\":31290},{\"end\":31314,\"start\":31299},{\"end\":31325,\"start\":31314},{\"end\":31337,\"start\":31325},{\"end\":31349,\"start\":31337},{\"end\":31786,\"start\":31776},{\"end\":31797,\"start\":31786},{\"end\":31809,\"start\":31797},{\"end\":32286,\"start\":32277},{\"end\":32295,\"start\":32286},{\"end\":32309,\"start\":32295},{\"end\":32320,\"start\":32309},{\"end\":32326,\"start\":32320},{\"end\":32340,\"start\":32326},{\"end\":32352,\"start\":32340},{\"end\":32665,\"start\":32659},{\"end\":32673,\"start\":32665},{\"end\":32683,\"start\":32673},{\"end\":32692,\"start\":32683},{\"end\":32701,\"start\":32692},{\"end\":32711,\"start\":32701},{\"end\":32721,\"start\":32711},{\"end\":32732,\"start\":32721},{\"end\":32746,\"start\":32732},{\"end\":33127,\"start\":33118},{\"end\":33137,\"start\":33127},{\"end\":33148,\"start\":33137},{\"end\":33161,\"start\":33148},{\"end\":33631,\"start\":33623},{\"end\":33637,\"start\":33631},{\"end\":33649,\"start\":33637},{\"end\":33659,\"start\":33649},{\"end\":33668,\"start\":33659},{\"end\":33678,\"start\":33668},{\"end\":33687,\"start\":33678},{\"end\":33699,\"start\":33687},{\"end\":33712,\"start\":33699},{\"end\":33726,\"start\":33712},{\"end\":33735,\"start\":33726},{\"end\":34181,\"start\":34171},{\"end\":34192,\"start\":34181},{\"end\":34203,\"start\":34192},{\"end\":34213,\"start\":34203},{\"end\":34225,\"start\":34213},{\"end\":34657,\"start\":34651},{\"end\":34666,\"start\":34657},{\"end\":34676,\"start\":34666},{\"end\":34682,\"start\":34676},{\"end\":34692,\"start\":34682},{\"end\":34700,\"start\":34692},{\"end\":34709,\"start\":34700},{\"end\":35112,\"start\":35103},{\"end\":35122,\"start\":35112},{\"end\":35131,\"start\":35122},{\"end\":35138,\"start\":35131},{\"end\":35152,\"start\":35138},{\"end\":35162,\"start\":35152},{\"end\":35534,\"start\":35524},{\"end\":35543,\"start\":35534},{\"end\":35553,\"start\":35543},{\"end\":35564,\"start\":35553},{\"end\":35577,\"start\":35564},{\"end\":35588,\"start\":35577},{\"end\":35600,\"start\":35588},{\"end\":35946,\"start\":35937},{\"end\":35956,\"start\":35946},{\"end\":35964,\"start\":35956},{\"end\":35974,\"start\":35964},{\"end\":35986,\"start\":35974},{\"end\":36400,\"start\":36390},{\"end\":36414,\"start\":36400},{\"end\":36425,\"start\":36414},{\"end\":36439,\"start\":36425},{\"end\":36451,\"start\":36439},{\"end\":36757,\"start\":36747},{\"end\":36765,\"start\":36757},{\"end\":36776,\"start\":36765},{\"end\":36785,\"start\":36776},{\"end\":36794,\"start\":36785},{\"end\":36802,\"start\":36794},{\"end\":36812,\"start\":36802},{\"end\":36828,\"start\":36812},{\"end\":37238,\"start\":37226},{\"end\":37250,\"start\":37238},{\"end\":37265,\"start\":37250},{\"end\":37274,\"start\":37265},{\"end\":37283,\"start\":37274},{\"end\":37292,\"start\":37283},{\"end\":37303,\"start\":37292},{\"end\":37987,\"start\":37976},{\"end\":37995,\"start\":37987},{\"end\":38004,\"start\":37995},{\"end\":38013,\"start\":38004},{\"end\":38030,\"start\":38013},{\"end\":38387,\"start\":38378},{\"end\":38397,\"start\":38387},{\"end\":38409,\"start\":38397},{\"end\":38665,\"start\":38658},{\"end\":38674,\"start\":38665},{\"end\":38684,\"start\":38674},{\"end\":39074,\"start\":39063},{\"end\":39083,\"start\":39074},{\"end\":39096,\"start\":39083}]", "bib_venue": "[{\"end\":31962,\"start\":31894},{\"end\":35223,\"start\":35216},{\"end\":37472,\"start\":37396},{\"end\":28329,\"start\":28212},{\"end\":28739,\"start\":28676},{\"end\":29123,\"start\":29115},{\"end\":29495,\"start\":29474},{\"end\":29907,\"start\":29826},{\"end\":30396,\"start\":30315},{\"end\":30904,\"start\":30805},{\"end\":31426,\"start\":31349},{\"end\":31892,\"start\":31809},{\"end\":32417,\"start\":32352},{\"end\":33215,\"start\":33161},{\"end\":33771,\"start\":33735},{\"end\":34285,\"start\":34225},{\"end\":34758,\"start\":34709},{\"end\":35214,\"start\":35162},{\"end\":35659,\"start\":35600},{\"end\":36030,\"start\":35986},{\"end\":36483,\"start\":36451},{\"end\":36875,\"start\":36828},{\"end\":37394,\"start\":37303},{\"end\":37789,\"start\":37758},{\"end\":38079,\"start\":38030},{\"end\":38376,\"start\":38344},{\"end\":38712,\"start\":38684},{\"end\":38917,\"start\":38881},{\"end\":39120,\"start\":39096}]"}}}, "year": 2023, "month": 12, "day": 17}