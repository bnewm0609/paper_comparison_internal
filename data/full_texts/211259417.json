{"id": 211259417, "updated": "2023-10-06 18:27:29.095", "metadata": {"title": "Lagrangian Decomposition for Neural Network Verification", "authors": "[{\"first\":\"Rudy\",\"last\":\"Bunel\",\"middle\":[]},{\"first\":\"Alessandro\",\"last\":\"Palma\",\"middle\":[\"De\"]},{\"first\":\"Alban\",\"last\":\"Desmaison\",\"middle\":[]},{\"first\":\"Krishnamurthy\",\"last\":\"Dvijotham\",\"middle\":[]},{\"first\":\"Pushmeet\",\"last\":\"Kohli\",\"middle\":[]},{\"first\":\"Philip\",\"last\":\"Torr\",\"middle\":[\"H.S.\"]},{\"first\":\"M.\",\"last\":\"Kumar\",\"middle\":[\"Pawan\"]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": 2, "day": 24}, "abstract": "A fundamental component of neural network verification is the computation of bounds on the values their outputs can take. Previous methods have either used off-the-shelf solvers, discarding the problem structure, or relaxed the problem even further, making the bounds unnecessarily loose. We propose a novel approach based on Lagrangian Decomposition. Our formulation admits an efficient supergradient ascent algorithm, as well as an improved proximal algorithm. Both the algorithms offer three advantages: (i) they yield bounds that are provably at least as tight as previous dual algorithms relying on Lagrangian relaxations; (ii) they are based on operations analogous to forward/backward pass of neural networks layers and are therefore easily parallelizable, amenable to GPU implementation and able to take advantage of the convolutional structure of problems; and (iii) they allow for anytime stopping while still providing valid bounds. Empirically, we show that we obtain bounds comparable with off-the-shelf solvers in a fraction of their running time, and obtain tighter bounds in the same time as previous dual algorithms. This results in an overall speed-up when employing the bounds for formal verification.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2002.10410", "mag": "3089600496", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/uai/BunelPDDKTK20", "doi": null}}, "content": {"source": {"pdf_hash": "fffbc8268f9fb463063cda6c57f9e3fc074adbb4", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2002.10410v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "c4bab141f41e35c48718e712beff2614331b2efe", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/fffbc8268f9fb463063cda6c57f9e3fc074adbb4.txt", "contents": "\nLagrangian Decomposition for Neural Network Verification\n\n\nRudy Bunel \nUniversity of Oxford\nUniversity of Oxford\n\n\nAlessandro De Palma adepalma@robots.ox.ac.uk \nUniversity of Oxford\nUniversity of Oxford\n\n\nAlban Desmaison \nUniversity of Oxford\nUniversity of Oxford\n\n\nKrishnamurthy ( Dj \nUniversity of Oxford\nUniversity of Oxford\n\n\n) Dvijotham \nUniversity of Oxford\nUniversity of Oxford\n\n\nPushmeet Kohli \nUniversity of Oxford\nUniversity of Oxford\n\n\nPhilip H S Torr \nUniversity of Oxford\nUniversity of Oxford\n\n\nM Pawan Kumar \nUniversity of Oxford\nUniversity of Oxford\n\n\nLagrangian Decomposition for Neural Network Verification\n\nA fundamental component of neural network verification is the computation of bounds on the values their outputs can take. Previous methods have either used off-the-shelf solvers, discarding the problem structure, or relaxed the problem even further, making the bounds unnecessarily loose. We propose a novel approach based on Lagrangian Decomposition. Our formulation admits an efficient supergradient ascent algorithm, as well as an improved proximal algorithm. Both the algorithms offer three advantages: (i) they yield bounds that are provably at least as tight as previous dual algorithms relying on Lagrangian relaxations; (ii) they are based on operations analogous to forward/backward pass of neural networks layers and are therefore easily parallelizable, amenable to GPU implementation and able to take advantage of the convolutional structure of problems; and (iii) they allow for anytime stopping while still providing valid bounds. Empirically, we show that we obtain bounds comparable with off-the-shelf solvers in a fraction of their running time, and obtain tighter bounds in the same time as previous dual algorithms. This results in an overall speed-up when employing the bounds for formal verification.\n\nINTRODUCTION\n\nAs deep learning powered systems become more and more common, the lack of robustness of neural networks and their reputation for being \"Black Boxes\" is increasingly worrisome. In order to deploy them in critical scenarios where safety and robustness would be a prerequisite, we need to invent techniques that can prove formal guarantees for neural network behaviour. A particularly desirable * These authors contributed equally to this work.\n\nproperty is resistance to adversarial examples (Goodfellow et al., 2015, Szegedy et al., 2014: perturbations maliciously crafted with the intent of fooling even extremely well performing models. After several defenses were proposed and subsequently broken (Athalye et al., 2018, Uesato et al., 2018, some progress has been made in being able to formally verify whether there exist any adversarial examples in the neighbourhood of a data point (Tjeng et al., 2019, Wong andKolter, 2018).\n\nVerification algorithms fall into three categories: unsound (some false properties are proven false), incomplete (some true properties are proven true), and complete (all properties are correctly verified as either true or false). A critical component of the verification systems developed so far is the computation of lower and upper bounds on the output of neural networks when their inputs are constrained to lie in a bounded set. In incomplete verification, by deriving bounds on the changes of the prediction vector under restricted perturbations, it is possible to identify safe regions of the input space. These results allow the rigorous comparison of adversarial defenses and prevent making overconfident statements about their efficacy (Wong and Kolter, 2018). In complete verification, bounds can also be used as essential subroutines of Branch and Bound complete verifiers (Bunel et al., 2018). Finally, bounds might also be used as a training signal to guide the network towards greater robustness and more verifiability (Gowal et al., 2018, Mirman et al., 2018, Wong and Kolter, 2018.\n\nMost previous algorithms for computing bounds are either computationally expensive (Ehlers, 2017) or sacrifice a lot of tightness in order to scale (Gowal et al., 2018, Mirman et al., 2018, Wong and Kolter, 2018. In this work, we design novel customised relaxations and their corresponding solvers for obtaining bounds on neural networks. Our approach offers the following advantages:\n\n\u2022 While previous approaches to neural network bounds (Dvijotham et al., 2018) are based on Lagrangian relaxations, we derive a new family of opti-mization problems for neural network bounds through Lagrangian Decomposition, which in general yields duals at least as strong as those obtained through Lagrangian relaxation (Guignard and Kim, 1987). We in fact prove that, in the context of ReLU networks, for any dual solution from the approach by Dvijotham et al. (2018), the bounds output by our dual are as least as tight. We demonstrate empirically that this derivation computes tighter bounds in the same time when using supergradient methods. We further improve on the performance by devising a proximal solver for the problem, which decomposes the task into a series of strongly convex subproblems. For each, we use an iterative method for which we derive optimal step sizes. \u2022 The basic step of both the supergradient and the proximal method are linear operations similar to the ones used during forward/backward pass of the network. As a consequence, we can leverage the convolutional structure when necessary, while standard solvers are often restricted to treating it as a general linear operation. Moreover, both methods are easily parallelizable: when computing bounds on the neural activations at layer k, we need two solve two problems for each hidden unit of the network (one for the upper bound and one for the lower bound). These can all be solved in parallel. In complete verification, we need to compute bounds for several different problem domains at once: we solve these problems in parallel as well. Our GPU implementation thus allows us to solve several hundreds of linear programs at once on a single GPU, a level of parallelism that would be hard to match on CPU-based systems. \u2022 Most standard linear programming based relaxations (Ehlers, 2017) will only return a valid bound if the problem is solved to optimality. Others, like the dual simplex method employed by off-the-shelf solvers (Gurobi Optimization, 2020) have a very high cost per iteration and will not yield tight bounds without incurring significant computational costs. Both methods described in this paper are anytime (terminating it before convergence still provides a valid bound), and can be interrupted at very small granularity. This is useful in the context of a subroutine for complete verifiers, as this enables the user to choose an appropriate speed versus accuracy trade-off. It also offers great versatility as an incomplete verification method.\n\n\nRELATED WORKS\n\nBound computations are mainly used for formal verification methods. Some methods are complete (Cheng et al., 2017, Ehlers, 2017, Katz et al., 2017, Tjeng et al., 2019, Xiang et al., 2017, always returning a verdict for each problem instances. Others are incomplete, based on relaxations of the verification problem. They trade speed for completeness: while they cannot verify properties for all problem instances, they scale significantly better. Two main types of bounds have been proposed: on the one hand, some approaches (Ehlers, 2017, Salman et al., 2019 rely on off-the-shelf solvers to solve accurate relaxations such as PLANET (Ehlers, 2017), which is the best known linear-sized approximation of the problem. On the other hand, as PLANET and other more complex relaxations do not have closed form solutions, some researchers have also proposed easier to solve, looser formulations (Gowal et al., 2018, Mirman et al., 2018, Weng et al., 2018, Wong and Kolter, 2018 A closely related approach to ours is the work of Dvijotham et al. (2018). Both their method and ours are anytime and operate on similar duals. While their dual is based on the Lagrangian relaxation of the non-convex problem, ours is based on the Lagrangian Decomposition of the nonlinear activation's convex relaxation. Thanks to the properties of Lagrangian Decomposition (Guignard and Kim, 1987), we are able to show that our dual problem provides better bounds when evaluated on the same dual variables. The relationship between the two duals is studied in detail in section 4.2. Moreover, in terms of the followed optimization strategy, in addition to using a supergradient method like Dvijotham et al. (2018), we further present a proximal method, for which we can derive optimal step sizes. We show that these modifications enable us to compute tighter bounds using the same amount of compute time.\n\n\nPRELIMINARIES\n\nThroughout this paper, we will use bold lower case letters (like z) to represent vectors and upper case letters (like W ) to represent matrices. Brackets are used to indicate the i-th coordinate of a vector (z[i]), and integer ranges (e.g., [1, n \u2212 1]). We will study the computation of the lower bound problem based on a feedforward neural network, with element-wise activation function \u03c3 (\u00b7). The network inputs are restricted to a convex domain C, over which we assume that we can easily optimise linear functions. This is the same assumption that was made by Dvijotham et al.\n\n(2018). The computation for an upper bound is analogous. Formally, we wish to solve the following problem: min\nz,\u1e91\u1e91 n (1a) s.t. z 0 \u2208 C, (1b) z k+1 = W k+1 z k + b k+1 k \u2208 [1, n \u2212 1] , (1c) z k = \u03c3 (\u1e91 k ) k \u2208 [1, n \u2212 1] . (1d)\nThe output of the k-th layer of the network before and after the application of the activation function are denoted by\u1e91 k and z k respectively. Constraints (1c) implements the linear layers (fully connected or convolutional) while constraints (1d) implement the non-linear activation function. Constraints (1b) define the region over which the bounds are being computed. While our method can be extended to more complex networks (such as ResNets), we focus on problem (1) for the sake of clarity.\n\nThe difficulty of problem (1) \nd(\u00b5, \u03bb) = min z,\u1e91 W n z n\u22121 + b n + n\u22121 k=1 \u00b5 T k (\u1e91 k \u2212 W k z k\u22121 \u2212 b k ) + n\u22121 k=1 \u03bb T k (z k \u2212 \u03c3(\u1e91 k )) s.t. l k \u2264\u1e91 k \u2264 u k k \u2208 [1, n \u2212 1] , \u03c3(l k ) \u2264 z k \u2264 \u03c3(u k ) k \u2208 [1, n \u2212 1] , z 0 \u2208 C.\n(2) If \u03c3 is a ReLU, this relaxation is equivalent (Dvijotham et al., 2018) to the PLANET relaxation (Ehlers, 2017). The dual requires upper (u k ) and lower bounds (l k ) on the value that\u1e91 k can take, for k \u2208 [0..n \u2212 1]. We call these intermediate bounds: we detail how to compute them in appendix B. The dual algorithm by Dvijotham et al. (2018) solves (2) via supergradient ascent.\n\n\nLAGRANGIAN DECOMPOSITION\n\nWe will now describe a novel approach to solve problem (1), and relate it to the dual algorithm by Dvijotham et al. (2018). We will focus on computing bounds for an output of the last layer of the neural network.\n\n\nPROBLEM DERIVATION\n\nOur approach is based on Lagrangian decomposition, also known as variable splitting (Guignard and Kim, 1987). Due to the compositional structure of neural networks, most constraints involve only a limited number of variables. As a result, we can split the problem into meaningful, easy to solve subproblems. We then impose con-straints that the solutions of the subproblems should agree.\n\nWe start from the original non-convex primal problem (1), and substitute the nonlinear activation equality (1b) with a constraint corresponding to its convex hull. This leads to the following convex program: min\nz,\u1e91\u1e91 n (3a) s.t. z 0 \u2208 C, (3b) z k+1 = W k+1 z k + b k+1 k \u2208 [1, n \u2212 1] , (3c) cvx hull \u03c3 (\u1e91 k , z k , l k , u k ) k \u2208 [1, n \u2212 1] . (3d)\nIn the following, we will use ReLU activation functions as an example, and employ the PLANET relaxation as its convex hull, which is the tightest linearly sized relaxation published thus far. By linearly sized, we mean that the numbers of variables and constraints to describe the relaxation only grow linearly with the number of units in the network. We stress that the derivation can be extended to other non-linearities. For example, appendix A describes the case of sigmoid activation function. For ReLUs, this convex hull takes the following form (Ehlers, 2017):\ncvx hull \u03c3 \u2261 \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 if l k [i] \u2264 0; u k [i] \u2265 0 : z k [i] \u2265 0, z k [i] \u2265\u1e91 k [i],(4a)z k [i] \u2264 u k [i](\u1e91 k [i] \u2212 l k [i]) u k [i] \u2212 l k [i] . if u k [i] \u2264 0 : z k [i] = 0. (4b) if l k [i] \u2265 0 : z k [i] =\u1e91 k [i].\n(4c) Constraints (4a), (4b), and (4c) corresponds to the relaxation of the ReLU (1d) in different cases (respectively: ambiguous state, always blocking or always passing).\n\nTo obtain a decomposition, we divide the constraints into subsets. Each subset will correspond to a pair of an activation layer, and the linear layer coming after it. The only exception is the first linear layer which is combined with the restriction of the input domain to C. This choice is motivated by the fact that for piecewise-linear activation functions, we will be able to easily perform linear optimisation over the resulting subdomains. For a different activation function, it might be required to have a different decomposition. Formally, we introduce the following notation for subsets of constraints:\nP 0 (z 0 ,\u1e91 1 ) \u2261 z 0 \u2208 \u0108 z 1 = W 1 z 0 + b 1 ,(5)P k (\u1e91 k ,\u1e91 k+1 ) \u2261 \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 l k \u2264\u1e91 k \u2264 u k , cvx hull \u03c3 (\u1e91 k , z k , l k , u k ) , z k+1 = W k+1 z k + b k .(6)\nThe set P k is defined without an explicit dependency on z k because z k only appears internally to the subset of constraints and is not involved in the objective function.\n\nUsing this grouping of the constraints, we can concisely write problem (3) as: min z,\u1e91\u1e91 n s.t. P 0 (z 0 ,\u1e91 1 ),\nP k (\u1e91 k ,\u1e91 k+1 ) k \u2208 [1, n \u2212 1] .(7)\nTo obtain a Lagrangian decomposition, we duplicate the variables so that each subset of constraints has its own copy of the variables it is involved in. Formally, we rewrite problem (7) as follows: min\nz,\u1e91\u1e91 A,n (8a) s.t. P 0 (z 0 ,\u1e91 A,1 ), (8b) P k (\u1e91 B,k ,\u1e91 A,k+1 ) k \u2208 [1, n \u2212 1] , (8c) z A,k =\u1e91 B,k k \u2208 [1, n \u2212 1] .\n(8d) The additional equality constraints (8d) impose agreements between the various copies of variables. We introduce the dual variables \u03c1 and derive the Lagrangian dual:\nmax \u03c1 q(\u03c1), where: q (\u03c1) = min z,\u1e91\u1e91 A,n + n\u22121 k=1 \u03c1 T k (\u1e91 B,k \u2212\u1e91 A,k ) s.t. P 0 (z 0 ,\u1e91 A,1 ), P k (\u1e91 B,k ,\u1e91 A,k+1 ) k \u2208 [1, n \u2212 1] .(9)\nAny value of \u03c1 provides a valid lower bound by virtue of weak duality. While we will maximise over the choice of dual variables in order to obtain as tight a bound as possible, we will be able to interrupt the optimisation process at any point and obtain a valid bound by evaluating q.\n\nWe stress that, at convergence, problems (9) and (2) will yield the same bounds, as they are both reformulations of the same convex problem. This does not imply that the two derivations yield solvers with the same efficiency. In fact, we will next prove that, for ReLU-based networks, problem (9) yields bounds at least as tight as a corresponding dual solution from problem (2).\n\n\nDUALS COMPARISON\n\nWe now compare our dual problem (9) with problem (2) by Dvijotham et al. (2018). From the high level perspective, our decomposition considers larger subsets of constraints and hence results in a smaller number of variables to optimize. We formally prove that, for ReLU-based neural networks, our formulation dominates theirs, producing tighter bounds based on the same dual variables.\n\nTheorem 1. Let us assume \u03c3(\u1e91 k ) = max(0,\u1e91 k ). For any solution \u00b5, \u03bb of dual (2) by Dvijotham et al. (2018) yielding bound d(\u00b5, \u03bb), it holds that q(\u00b5) \u2265 d(\u00b5, \u03bb).\n\n\nProof. See appendix E.\n\nOur dual is also related to the one that Wong and Kolter (2018) operates in. We show in appendix F how our problem can be initialised to a set of dual variables so as to generate a bound matching the one provided by their algorithm. We use this approach as our initialisation for incomplete verification ( \u00a7 6.3).\n\n\nSOLVERS FOR LAGRANGIAN DECOMPOSITION\n\nNow that we motivated the use of dual (9) over problem (2), it remains to show how to solve it efficiently in practice. We present two methods: one based on supergradient ascent, the other on proximal maximisation. A summary, including pseudo-code, can be found in appendix D.\n\n\nSUPERGRADIENT METHOD\n\nAs Dvijotham et al. (2018) use supergradient methods on their dual, we start by applying it on problem (9) as well.\n\nAt a given point \u03c1, obtaining the supergradient requires us to know the values of\u1e91 A and\u1e91 B for which the inner minimisation is achieved. Based on the identified values of\u1e91 * A and\u1e91 * B , we can then compute the supergradient \u2207 \u03c1 q =\u1e91 * B \u2212\u1e91 * A . The updates to \u03c1 are then the usual supergradient ascent updates:\n\u03c1 t+1 = \u03c1 t + \u03b1 t \u2207 \u03c1 q(\u03c1 t ),(10)\nwhere \u03b1 t corresponds to a step size schedule that needs to be provided. It is also possible to use any variants of gradient descent, such as Adam (Kingma and Ba, 2015).\n\nIt remains to show how to perform the inner minimization over the primal variables. By design, each of the variables is only involved in one subset of constraints. As a result, the computation completely decomposes over the subproblems, each corresponding to one of the subset of constraints. We therefore simply need to optimise linear functions over one subset of constraints at a time.\n\n\nInner minimization: P 0 subproblems\n\nTo minimize over z 0 ,\u1e91 A,1 , the variables constrained by P 0 , we need to solve:\n[z * 0 ,\u1e91 * A,1 ] = argmin z0,\u1e91 A,1 \u2212\u03c1 T 1\u1e91A,1 s.t z 0 \u2208 C,\u1e91 A,1 = W 1 z 0 + b 0 .(11)\nRewriting the problem as a linear function of z 0 only, problem (11) is simply equivalent to minimising \u2212\u03c1 T 1 W 1 z 0 over C. We assumed that the optimisation of a linear function over C was efficient. We now give examples of C where problem (11) can be solved efficiently. Bounded Input Domain If C is defined by a set of lower bounds l 0 and upper bounds u 0 (as in the case of \u221e adversarial examples), optimisation will simply amount to choosing either the lower or upper bound depending on the sign of the linear function. Let us denote the indicator function for condition c by 1 c . The optimal solution is:\nx 0 = 1 \u03c1 T 1 W1<0 \u00b7 l 0 + 1 \u03c1 T 1 W1\u22650 \u00b7 u 0 , x A,1 = W 1 x 0 + b 1 . (12) l k[j] u k[j]\u1e91 k[j] z k[j]\nFigure 1: Feasible domain of the convex hull for an ambiguous ReLU. Red circles indicate the vertices of the feasible region.\n\n2 Balls If C is defined by an 2 ball of radius around a pointx ( x 0 \u2212x 2 \u2264 ), optimisation amounts to choosing the point on the boundary of the ball such that the vector from the center to it is opposed to the cost function. Formally, the optimal solution is given by:\nx A,1 = W 1 x 0 + b 1 , x 0 =x + ( \u221a / \u03c11 2)\u03c11 .(13)\n\nInner minimization: P k subproblems\n\nFor the variables constrained by subproblem P k (\u1e91 B,k ,\u1e91 A,k+1 ), we need to solve:\n[\u1e91 * B,k ,\u1e91 * A,k+1 ] = argmin z B,k ,\u1e91 A,k+1 \u03c1 T k\u1e91B,k \u2212 \u03c1 T k+1\u1e91A,k+1 s.t l k \u2264\u1e91 B,k \u2264 u k , cvx hull \u03c3 (\u1e91 B,k , z k , l k , u k ) , z A,k+1 = W k+1 z k + b k+1 .(14)\nIn the case where the activation function \u03c3 is the ReLU and cvx hull is given by equation (4), we can find a closed form solution. Using the last equality of the problem, we can rewrite the objective function as \u03c1 T k\u1e91 B,k \u2212 \u03c1 T k+1 W k+1 z k . If the ReLU is ambiguous, the shape of the convex hull is represented in Figure 1. If the sign of \u03c1 T k+1 W k+1 is negative, optimizing subproblem (14) corresponds to having z k at its lower bound max (\u1e91 B,k , 0). If on the contrary the sign is positive, z k must be equal to its upper bound u k u k \u2212l k (\u1e91 B,k \u2212 l k ). We can therefore rewrite the subproblem (14) in the case of ambiguous ReLUs as:\nargmin z B,k \u2208[l k ,u k ] \u03c1 T k \u2212 \u03c1 T k+1 W k+1 + u k u k \u2212 l k \u1e91 B,k \u2212 \u03c1 T k+1 W k+1 \u2212 max (\u1e91 B,k , 0) ,(15)\nwhere\n[A] \u2212 corresponds to the negative values of A ([A] \u2212 = min (A, 0)) and [A] + corresponds to the pos- itive value of A ([A] + = max (A, 0)).\nThe objective function and the constraints all decompose completely over the coordinates, so all problems can be solved independently. For each dimension, the problem is a convex, piecewise linear function, which means that the optimal point will be a vertex. The possible vertices are (l k [i], 0), (0, 0), and (u k [i], u k [i]). In order to find the minimum, we can therefore evaluate the objective function at these three points and keep the one with the smallest value.\n\nIf for a ReLU we either have l k [i] \u2265 0 or u k [i] \u2264 0, the cvx hull constraint is a simple linear equal-ity constraint. For those coordinates, the problem is analogous to the one solved by equation (12), with the linear function being minimised over the\u1e91 B,k box bounds being \u03c1 T k\u1e91 B,k in the case of blocking ReLUs or \u03c1 T k \u2212 \u03c1 T k+1 W k+1 \u1e91 B,k in the case of passing ReLUs. We have described how to solve problem (14) by simply evaluating linear functions at given points. The matrix operations involved correspond to standard operations of the neural network's layers. Computin\u011d z A,k+1 = W k+1 z k + b k+1 is exactly the forward pass of the network and computing \u03c1 T k+1 W k+1 is analogous to the backpropagation of gradients. We can therefore take advantage of existing deep learning frameworks to gain access to efficient implementations. When dealing with convolutional layers, we can employ specialised implementations rather than building the equivalent W k matrix, which would contain a lot of redundancy.\n\nWe described here the solving process in the context of ReLU activation functions, but this can be generalised to non piecewise linear activation function. For example, appendix A describes the solution for the sigmoid activation function.\n\n\nPROXIMAL METHOD\n\nWe now detail the use of proximal methods on problem (9) as an alternative to supergradient ascent.\n\n\nAugmented Lagrangian\n\nApplying proximal maximization to the dual function q results in the Augmented Lagrangian Method, also known as the method of multipliers. The derivation of the update steps is given in detail by Bertsekas and Tsitsiklis (1989). For our problem, this will correspond to alternating between updates to the dual variables \u03c1 and updates to the primal variables\u1e91, which are given by the following equations (superscript t indicates the value at the t-th iteration):\n\u03c1 t+1 k = \u03c1 t k +\u1e91 t B,k \u2212\u1e91 t A,k \u03b7 k ,(16)z t ,\u1e91 t = argmin z,\u1e91 L \u1e91, \u03c1 t := argmin z,\u1e91 \u1e91 A,n + k=1..n\u22121 \u03c1 T k (\u1e91 B,k \u2212\u1e91 A,k ) + k=1..n\u22121 1 2\u03b7 k \u1e91 B,k \u2212\u1e91 A,k 2 s.t. P 0 (z 0 ,\u1e91 A,1 ), P k (\u1e91 B,k ,\u1e91 A,k+1 ) k \u2208 [1, n \u2212 1] .(17)\nThe term L (\u1e91, \u03c1) is the Augmented Lagrangian of problem (8). The additional quadratic term in (17), compared to the objective of q(\u03c1), arises from the proximal terms on \u03c1. It has the advantage of making the problem strongly convex, and hence easier to optimize. Later on, will show that this allows us to derive optimal step-sizes in closed form. The weight \u03b7 k is a hyperparameter of the algorithm. A high value will make the problem more strongly convex and therefore quicker to solve, but it will also limit the ability of the algorithm to perform large updates.\n\nWhile obtaining the new values of \u03c1 is trivial using equation (16), problem (17) does not have a closed-form solution. We show how to solve it efficiently nonetheless.\n\n\nFrank-Wolfe Algorithm\n\nProblem (17) can be optimised using the conditional gradient method, also known as the Frank-Wolfe algorithm (Frank and Wolfe, 1956). The advantage it provides is that there is no need to perform a projection step to remain in the feasible domain. Indeed, the different iterates remain in the feasible domain by construction as convex combination of points in the feasible domain. At each time step, we replace the objective by its linear approximation and optimize this linear function over the feasible domain to get an update direction, named conditional gradient. We then take a step in this direction.\n\nAs the Augmented Lagrangian is smooth over the primal variables, there is no need to take the Frank-Wolfe step for all the network layers at once. We can in fact do it in a block-coordinate fashion, where a block is a network layer, with the goal of speeding up convergence; we refer the reader to appendix C for further details.\n\nObtaining the conditional gradient requires minimising a linearization of L (\u1e91, \u03c1) on the primal variables, restricted to the feasible domain. This computation corresponds exactly to the one we do to perform the inner minimisation of problem (9) over z and\u1e91 in order to compute the supergradient (cf. \u00a75.1.1, \u00a75.1.2). To make this equivalence clearer, we point out that the linear coefficients of the primal variables will maintain the same form (with the difference that the dual variables are represented as their closed-form update for the following iteration), as\n\u2207\u1e91 B,k L (\u1e91, \u03c1 t ) = \u03c1 t+1 k and \u2207\u1e91 A,k+1 L (\u1e91, \u03c1 t ) = \u2212\u03c1 t+1 k .\nThe equivalence of conditional gradient and supergradient is not particular to our specific problem. A more general description can be found in the work of Bach (2015).\n\nThe use of a proximal method allows us to employ an optimal step size, whose calculation is detailed in appendix C. This would not be possible with supergradient methods, as we would have no guarantee of improvements. We therefore have no need to choose the step-size. In practice, we still have to choose the strength of the proximal term \u03b7 k . Finally, inspired by previous work on accelerating proximal methods (Lin et al., 2017, Salzo andVilla, 2012), we also apply momentum on the dual updates to accelerate convergence; for details see appendix C.\n\n\nEXPERIMENTS\n\n\nIMPLEMENTATION DETAILS\n\nOne of the benefits of our algorithms (and of the supergradient baseline by Dvijotham et al. (2018)) is that they are easily parallelizable. As explained in \u00a7 5.1.1 and \u00a7 5.1.2, the crucial part of both our solvers works by applying linear algebra operations that are equivalent to the ones employed during the forward and backward passes of neural networks. To compute the upper and lower bounds for all the neurons of a layer, there is no dependency between the different problems, so we are free to solve them all simultaneously in a batched mode. In complete verification ( \u00a76.4), where bounds relative to multiple domains (defined by the set of input and intermediate bounds for the given network activations) we can further batch over the domains, providing a further stream of parallelism. In practice, we take the building blocks provided by deep learning frameworks, and apply them to batches of solutions (one per problem), in the same way that normal training applies them to a batch of samples. This makes it possible for us to leverage the engineering efforts made to enable fast training and evaluation of neural networks, and easily take advantage of GPU accelerations. The implementation used in our experiment is based on Pytorch (Paszke et al., 2017).\n\n\nEXPERIMENTAL SETTING\n\nIn order to evaluate the performance of the proposed methods, we first perform a comparison in the quality and speed of bounds obtained by different methods in the context of incomplete verification ( \u00a76.3). We then assess the effect of the various method-specific speed/accuracy trade-offs within a complete verification procedure ( \u00a76.4).\n\nFor both sets of experiments, we report results using networks trained with different methodologies on the CIFAR-10 dataset. We compare the following algorithms:\n\n\u2022 WK uses the method of Wong and Kolter (2018). This is equivalent to a specific choice of \u03c1. \u2022 DSG+ corresponds to supergradient ascent on dual\n\n(2), the method by Dvijotham et al. (2018). We use the Adam (Kingma and Ba, 2015) updates rules and decrease the step size linearly, similarly to the experiments of Dvijotham et al. (2018). We experimented with other step size schedules, like constant step size or 1 t schedules, which all performed worse. \u2022 Supergradient is the first of the two solvers presented ( \u00a75.1). It corresponds to supergradient ascent over problem (9). We use Adam updates analogously to the DSG+ baseline. \u2022 Proximal is the solver presented in \u00a75.2, performing proximal maximisation on problem (9). We limit the total number of inner iterations for each problem to 2 (a single iteration is a full pass over the network layers).\n\n\u2022 Gurobi is our gold standard method, employing the commercial black box solver Gurobi. All the problems are solved to optimality, providing us with the best result that our solver could achieve in terms of accuracy. \u2022 Gurobi-TL is the time-limited version of the above, which stops at the first dual simplex iteration for which the total elapsed time exceeded that required by 400 iterations of the proximal method.\n\nWe \n\n\nINCOMPLETE VERIFICATION\n\nWe investigate the effectiveness of the various methods for incomplete verification on images of the CIFAR-10 test set. For each image, we compute an upper bound on the robustness margin: the difference between the ground truth logit and all the other logits, under an allowed perturbation verif in infinity norm of the inputs. If for any class the upper bound on the robustness margin is negative, then we are certain that the network is vulnerable against that adversarial perturbation. We measure the time to compute last layer bounds, and report the optimality gap compared to the best achieved solution.\n\nAs network architecture, we employ the small model used by Wong and Kolter (2018) and whose structure is given in appendix G.1.1. We train the network against perturbations of a size up to train = 8/255, and test for adversarial vulnerability on verif = 12/255. This is done using adversarial training (Madry et al., 2018), based on an attacker using 50 steps of projected gradient descent to obtain the samples. Additional experiments for a network trained using standard stochastic gradient descent and cross entropy, with no robustness objective can be found in appendix G.1. For both supergradient methods (our Supergradient, and DSG+), we decrease the step size linearly from \u03b1 = 10 \u22122 to \u03b1 = 10 \u22124 , while for Proximal, we employ momentum coefficient \u00b5 = 0.9 and, for all layers, linearly increase the weight of the proximal terms from \u03b7 = 10 2 to \u03b7 = 5 \u00d7 10 3 (see appendix C). Figure 2 presents results as a distribution of runtime and optimality gap. WK by Wong and Kolter (2018) performs a single pass over the network per optimization problem, which allows it to be extremely fast, but this comes at the cost of generating looser bounds. At the complete opposite end of the spectrum, Gurobi is extremely slow but provides the best achievable bounds. Dual iterative methods (the baseline by Dvijotham et al. (2018), and our Supergradient and Proximal methods) allow the user to choose the trade-off between tightness and speed. In order to get a fair comparison, we adjusted the number of iterations for the various methods so that each of them would take roughly the same time. Note that the Lagrangian Decomposition has a higher cost per iteration due to the more expensive computations related to the more complex primal feasible set. The cost of the proximal method is even larger due to the primal-dual updates and the optimal step size computation. For DSG+, Supergradient and Proximal, the improved quality of the bounds as compared to the non-iterative method WK shows that there are benefits in actually solving the best relaxation rather than In both cases, lower is better. The width at a given value represents the proportion of problems for which this is the result. Note that Gurobi always return the optimal solution so doesn't appear on the optimality gap, but is always the highest runtime. simply evaluating looser bounds. Time-limiting Gurobi at the first iteration which exceeded the cost of 400 Proximal iterations significantly worsens the produced bounds without a comparable cut in runtimes. This is due to the high cost per iteration of the dual simplex algorithm.\n\nBy looking at the distributions and at the point-wise comparisons in Figure 3, we can see that Supergradient yields consistently better bounds than DSG+. As both methods employ the Adam update rule (and the same hyperparameters, which turned out to be optimal for both), we can conclude that operating on the Lagrangian Decomposition dual (1) produces better speed-accuracy trade-offs compared to the dual (2) by Dvijotham et al. (2018). This is in line with the expectations from Theorem 1. Moreover, on average, the proximal algorithm yields better bounds than those returned by Supergradient, further improving on the DSG+ baseline. In particular, we stress that the support of optimality gap distribution is larger for Proximal, with a heavier tail towards better bounds.\n\n\nCOMPLETE VERIFICATION\n\nWe present results for complete verification. In this setting, our goal is to verify whether a network is robust to \u221e norm perturbations of radius verif . In order to do so, we search for a counter-example (an input point for which the output of the network is not the correct class) by mini-mizing the difference between the ground truth logit and a randomly chosen logit of images of the CIFAR-10 test set. If the minimum is positive, we have not succeeded in finding a counter-example, and the network is robust. In contrast to the previous section, we now seek to solve a nonconvex problem like (1) (where another layer representing the aforementioned difference has been added at the end) directly, rather than an approximation.\n\nIn order to perform the minimization exactly, we employ BaSBR, the Branch and Bound algorithm by Bunel et al.\n\n. In short, Branch and Bound subdivides the verification domain into a number of smaller problems, for which it repeatedly computes upper and lower bounds. At every iteration, BaSBR picks the sub-problem with the lowest lower bound and creates two new sub-problems by fixing the most \"impactful\" ReLU to be passing or blocking. The impact of a ReLU is determined by estimating the change in the sub-problem's output lower bound caused by making the ReLU non-ambiguous. Subproblems which cannot contain the global lower bound are progressively discarded.\n\nThe computational bottleneck of Branch and Bound is the lower bounds computation, for which we will employ a subset of the methods in section 6.2. Specifically, we want to compare the performance of DSG+, Supergradient and  Proximal with Gurobi. For this purpose, we run the various Branch and Bound implementations on a subset of the dataset employed by Lu and Kumar (2020) to test their novel Branch and Bound splitting strategy. The dataset picks a non-correct class and a perturbation radius verif for a subset of the CIFAR-10 test images, and runs Branch and Bound on three different convolutional network architectures of varying size: a \"base\" network, a \"wide\" network, and a \"deep\" network. Further details on the dataset and architectures are provided in appendix G.2.\n\nWe compare the Branch and Bound implementations with MIPplanet to provide an additional verification baseline. MIPplanet computes the global lower bound by using Gurobi to solve the Mixed-Integer Linear problem arising from the Planet relaxation (Bunel et al., 2019, Ehlers, 2017). As explained in section 6.1, due to the highly parallelizable nature of the dual iterative algorithms, we are able to compute lower bounds for multiple sub-problems at once for DSG+, Supergradient and Proximal, whereas the domains are solved sequentially for Gurobi. The number of simultaneously solved sub-problems is 300 for the base network, and 200 for the wide and deep networks. Intermediate bound computations (see \u00a76.2) are performed in parallel as well, with smaller batch sizes to account for the larger width of intermediate layers (over which we batch as well). For both supergradient methods (our Supergradient, and DSG+), we decrease the step size linearly from \u03b1 = 10 \u22123 to \u03b1 = 10 \u22124 , while for Proximal, we do not employ momentum and keep the weight of the proximal terms fixed to \u03b7 = 10 2 for all layers throughout the iterations. As in the previous section, the number of iterations for the bounding algorithms are tuned to employ roughly the same time: we use 100 iterations for Proximal, 160 for Supergradient, and 260 for DSG+. For all three, the dual variables are initialized from the dual solution of the lower bound computation of the parent node in the Branch and Bound tree. We time-limit the experiments at one hour.\n\nConsistently with the incomplete verification results presented in the last section, Figure 4 and Table 1 show that the Supergradient overperforms DSG+, confirming the benefits of our Lagrangian Decomposition approach. Better bounds decrease the number of sub-problems that Branch and Bound needs to solve, reducing the overall verification time. Furthermore, Proximal provides an ad-ditional increase in performance over DSG+, which is visible especially over the properties that are easier to verify. The gap between competing bounding methods increases with the size of the employed network, both in terms of layer width and network depth: at least an additional 2% of the properties times out when using DSG+ on the larger networks. A more detailed experimental analysis of the base model data is presented in appendix G.2.\n\n\nDISCUSSION\n\nWe have presented a novel dual approach to compute bounds over the activation of neural networks based on Lagrangian Decomposition. It provides significant benefits compared to off-the-shelf solvers and improves on both looser relaxations and on a previous method based on Lagrangian relaxation. As future work, it remains to investigate whether better complete verification results can be obtained by combining our supergradient and proximal methods. Furthermore, it would be interesting to see if similar derivations could be used to make tighter but more expensive relaxations computationally feasible. Improving the quality of bounds may allow the training of robust networks to avoid over-regularisation.\n\n\nReferences\n\nAnderson, R., Huchette, J., Tjandraatmadja, C., and Vielma, J. P. (2019). Strong mixed-integer programming formulations for trained neural networks.   \n\n\nA Sigmoid Activation function\n\nThis section describes the computation highlighted in the paper in the context where the activation function \u03c3 (x) is the sigmoid function:\n\u03c3 (x) = 1 1 + e \u2212x(18)\nA similar methodology to the ones described in this section could be used to adapt the method to work with other activation function such as hyperbolic tangent, but we won't discuss it.\n\nWe will start with a reminders about some properties of the sigmoid activation function. It takes values between 0 and 1, with \u03c3 (0) = 0.5. We can easily compute its derivatives:\n\u03c3 (x) = \u03c3 (x) \u00d7 (1 \u2212 \u03c3 (x)) \u03c3 (x) = \u03c3 (x) \u00d7 (1 \u2212 \u03c3 (x)) \u00d7 (1 \u2212 2\u03c3 (x))(19)\nIf we limit the domain of study to the negative inputs ([\u2212\u221e, 0]), then the function x \u2192 \u03c3 (x) is a convex function, as can be seen by looking at the sign of the second derivative over that domain. Similarly, if we limit the domain of study to the positive inputs ([0, \u221e]), the function is concave.\n\n\nA.1 Convex hull computation\n\nIn the context of ReLU, the convex hull of the activation function is given by equation (4), as introduced by Ehlers (2017). We will now derive it for sigmoid functions. Upper and lower bounds will be dealt in the same way, so our description will only focus on how to obtain the concave upper bound, limiting the activation function convex hull by above. The computation to derive the convex lower bound is equivalent.\n\nDepending on the range of inputs over which the convex hull is taken, the form of the concave upper bound will change. We distinguish two cases.\nCase 1: \u03c3 (u k ) \u2265 \u03c3(u k )\u2212\u03c3(l k ) u k \u2212l k\n. We will prove that in this case, the upper bound will be the line passing through the points (l k , \u03c3 (l k )) and (u k , \u03c3 (l k )). The equation of it is given by:\n\u03c6 u k ,l k (x) = \u03c3 (u k ) \u2212 \u03c3 (l k ) u k \u2212 l k (x \u2212 l k ) + \u03c3 (l k )(20)\nConsider the function d(x) = \u03c6 u k ,l k (x) \u2212 \u03c3 (x). To show that \u03c6 u k ,l k is a valid upper bound, we need to prove that \u2200x \u2208 [l k , u k ] , d(x) \u2265 0. We know that d(l k ) = 0 and d(u k ) = 0, and that d is a continuous function. Its derivative is given by:\nd (x) = \u03c3 (u k ) \u2212 \u03c3 (l k ) u k \u2212 l k \u2212 \u03c3 (x) (1 \u2212 \u03c3 (x)).(21)\nTo find the roots of d , we can solve d (x) = 0 for the value of \u03c3 (x) and then use the logit function to recover the value of x. In that case, this is only a second order polynomial, so it can admit at most two roots.\n\nWe know that lim x\u2192\u221e d (x) \u2265 0, and our hypothesis tells us that d (u k ) \u2264 0. This means that at least one of the root lies necessarily beyond u k and therefore, the derivative of d change signs at most once on the [l k , u k ] interval. If it never changes sign, it is monotonous. Given that the values taken at both extreme points are the same, d being monotonous would imply that d is constant, which is impossible. We therefore conclude that this means that the derivative change its sign exactly once on the interval, and is therefore unimodal. As we know that d (u k ) \u2264 0, this indicates that d is first increasing and then decreasing. As both extreme points have a value of zero, this means that \u2200x \u2208 [l k , u k ] , d(x) \u2265 0.\n\nFrom this result, we deduce that \u03c6 u k ,l k is a valid upper bound of \u03c3. As a linear function, it is concave by definition. Given that it constitutes the line between two points on the curve, all of its points necessarily belong to the convex hull. Therefore, it is not possible for a concave upper bound of the activation function to have lower values. This means that \u03c6 u k ,l k defines the upper bounding part of the convex hull of the activation function.\nCase 2: \u03c3 (u k ) \u2264 \u03c3(u k )\u2212\u03c3(l k ) u k \u2212l k .\nIn this case, we will have to decompose the upper bound into two parts, defined as follows:\n\u03c6 u k ,l k (x) \uf8f1 \uf8f2 \uf8f3 \u03c3 (t k ) \u2212 \u03c3 (l k ) t k \u2212 l k (x \u2212 l k ) + \u03c3 (l k ) if x \u2208 [l k , t k ] (22a) \u03c3 (x) if x \u2208 [t k , u k ],(22b)\nwhere t k is defined as the point such that \u03c3 (t k ) = \u03c3(t k )\u2212\u03c3(l k ) t k \u2212l k and t k > 0. The value of t k can be computed by\nsolving the equation \u03c3 (t k ) (1 \u2212 \u03c3 (t k )) = \u03c3(t k )\u2212\u03c3(l k ) t k \u2212l k\n, which can be done using the Newton-Raphson method or a binary search. Note that this needs to be done only when defining the problem, and not at every iteration of the solver. In addition, the value of t k is dependant only on l k so it's possible to start by building a table of the results at the desired accuracy and cache them.\n\nEvaluating both pieces of the function of equation (22) at t k show that \u03c6 u k ,l k is continuous. Both pieces are concave (for x \u2265 t k \u2265 0, \u03c3 is concave) and they share a supergradient (the linear function of slope \u03c3(t k )\u2212\u03c3(l k ) t k \u2212l k ) in t k , so \u03c6 u k ,l k is a concave function. The proof we did for Case 1 can be duplicated to show that the linear component is the best concave upper bound that can be achieved over the interval [l k , t k ]. On the interval [t k , u k ], \u03c6 u k ,l k is equal to the activation function, so it is also an upper bound which can't be improved upon. Therefore, \u03c6 u k ,l k is the upper bounding part of the convex hull of the activation function.\n\nNote that a special case of this happens when l k \u2265 t k . In which case, \u03c6 u k ,l k consists of only equation (22b).\n\nAll cases are illustrated in Figure 5. Case 1 is shown in 5a, where the upper bound contains only the linear upper bound. Case 2 with both segments is visible in Figure5c, with the cutoff points tb k highlighted by a green dot, and the special case with l k \u2265 t k is demonstrated in Figure 5b.\n\nA.2 Solving the P k subproblems over sigmoid activation As a reminder, the problem that needs to be solved is the following:\n[x B,k ,x A,k+1 ] = argmin z B,k ,\u1e91 A,k+1 c T k\u1e91B,k + c T k+1\u1e91A,k+1 s.t l k \u2264\u1e91 B,k \u2264 u k cvx hull \u03c3 (\u1e91 B,k , z k , l k , u k ) z A,k+1 = W k+1 z k + b k+1 ,(23)\nwhere cvx hull is defined either by equations (20) or (22). In this case, we will still be able to compute a closed form solution.\n\nWe will denote \u03c6 u k ,l k and \u03c8 u k ,l k the upper and lower bound functions defining the convex hull of the sigmoid function, which can be obtained as described in the previous subsection. If we use the last equality constraint of Problem (23) to replace the\u1e91 A,k+1 term in the objective function, we obtain c T k\u1e91 B,k + c T k+1 W k+1 z k . Depending on the sign of c T k+1 W k+1 , z k will either take the value \u03c6 u k ,l k or \u03c8 u k ,l k , resulting in the following problem:\nmin z B,k c T k\u1e91B,k + c T k+1 W k+1 \u2212 \u03c6 u k ,l k (\u1e91 B,k ) + c T k+1 W k+1 + \u03c8 u k ,l k (\u1e91 B,k ) s.t l k \u2264\u1e91 B,k \u2264 u k .(24)\nTo solve this problem, several observations can be made: First of all, at that point, the optimisation decomposes completely over the components of\u1e91 B,k so all problems can be solved independently from each other. The second observation is that to solve this problem, we can decompose the minimisation over the whole range [l k , u k ] into a set of minimisation over the separate pieces, and then returning the minimum corresponding to the piece producing the lowest value.\n\nThe minimisation over the pieces can be of two forms. Both bounds can be linear (such as between the green dotted lines in Figure 5c), in which case the problem is easy to solve by looking at the signs of the coefficient of the objective function. The other option is that one of the bound will be equal to the activation function (such as in Figures 5a or 5b, or in the outer sections of Figure 5c), leaving us with a problem of the form: min\nz B,k c T lin\u1e91B,k + c T \u03c3 \u03c3 (\u1e91 B,k ) l \u2264\u1e91 B,k \u2264 u,(25)\nwhere l, u, c lin and c \u03c3 will depend on what part of the problem we are trying to solve.\n\nThis is a convex problem so the value will be reached either at the extremum of the considered domain (l or u), or it will be reached at the points where the derivative of the objective functions cancels. This corresponds to the roots of (\u1e91 B,k )). Provided that 1 + 4clin c\u03c3 \u2265 0, the possible roots will be given by \u03c3 \u22121 1\u00b1 1+ 4c lin c\u03c3 2 , with \u03c3 \u22121 being the logit function, the inverse of the sigmoid function \u03c3 \u22121 (x) = log x 1\u2212x . To solve problem (25), we evaluate its objective function at the extreme points (l and u) and at those roots if they are in the feasible domain, and return the point corresponding to the minimum score achieved. With this method, we can solve the P k subproblems even when the activation function is a sigmoid.\nc lin + c T \u03c3 \u03c3 (\u1e91 B,k ) (1 \u2212 \u03c3\n\nB Intermediate bounds\n\nIntermediate bounds are obtained by solving a relaxation of (1) over subsets of the network. Instead of defining the objective function on the activation of layer n, we define it over\u1e91 k , iteratively for k \u2208 [1..n \u2212 1]. Computing intermediate bounds with the same relaxation would be the computational cost of this approach: we need to solve two LPs for each of the neurons in the network, and even if (differently from off-the-shelf LP solvers) our method allows for easy parallelization within each layer, the layers need to be tackled sequentially. Therefore, depending on the computational budget, the employed relaxation for intermediate bounds might be looser than (3) or (2): for instance, the one by Wong and Kolter (2018).\n\n\nC Implementation details for Proximal method\n\nWe provide additional details for the implementation of the proximal method. We start with the optimal step size computation, define our block-coordinate updates for the primal variables, and finally provide some insight on acceleration.\n\n\nC.1 Optimal Step Size Computation\n\nHaving obtained the conditional gradientsx k \u2200k \u2208 [0..n \u2212 1] for our problem, we need to decide a step size. Computing the optimal step size amounts to solving a one dimensional quadratic problem:\n\u03b3 * = argmin \u03b3\u2208[0,1] L(\u03b3x + (1 \u2212 \u03b3)\u1e91, \u03c1).(26)\nComputing the gradient with regards to \u03b3 and setting it to 0 will return the optimal step size. This gives us the following formula:\n\u03b3 * = clamp [0,1] \u2212 (x A,n \u2212\u1e91 A,n ) + k \u03c1 T k (x B,k \u2212\u1e91 B,k \u2212x A,k +\u1e91 A,k ) k 1 \u03b7 k x B,k \u2212\u1e91 B,k \u2212x A,k +\u1e91 A,k 2(27)\n\nC.2 Gauss-Seidel style updates\n\nAt iteration t, the Frank-Wolfe step takes the following form:\nz t+1 = \u03b3 * x + (1 \u2212 \u03b3 * )\u1e91 t(28)\nwhere the update is performed on the variables associated to all the network neurons at once.\n\nAs the Augmented Lagrangian (17) is smooth in the primal variables, we can take a conditional gradient step after eachx k computation, resulting in Gauss-Seidel style updates (as opposed to Jacobi style updates 28) (Bertsekas and Tsitsiklis, 1989). As the values of the primals at following layers are inter-dependent through the gradient of the Augmented Lagrangian, these block-coordinate updates will result in faster convergence. The updates become:\nz t+1 k = \u03b3 * kxk + (1 \u2212 \u03b3 * k )\u1e91 t k(29)\nwhere the optimal step size is given by:\n\u03b3 * k = clamp [0,1] \u2212 \u03c1 T k x B,k \u2212\u1e91 B,k ) + \u03c1 T k+1 (\u1e91 A,k+1 \u2212x A,k+1 ) 1 \u03b7 k x B,k \u2212\u1e91 B,k 2 + 1 \u03b7 k+1 \u1e91 A,k+1 \u2212x A,k+1 2(30)\nwith the special casesx B,0 =\u1e91 B,0 = 0 and:\n\u03b3 * n\u22121 = clamp [0,1] \u2212 \u03c1 T n\u22121 (x B,n\u22121 \u2212\u1e91 B,n\u22121 ) + (x A,n \u2212\u1e91 A,n )) 1 \u03b7n\u22121 x B,n\u22121 \u2212\u1e91 B,n\u22121 2(31)\n\nC.3 Momentum\n\nThe supergradient methods that we implemented both for our dual (9) and for (2) (2012), we apply momentum on the proximal updates.\n\nBy closely looking at equation (16), we can draw a similarity between the dual update in the proximal algorithm and supergradient descent. The difference is that the former operation takes place after a closed-form minimization of the linear inner problem in\u1e91 A ,\u1e91 B , whereas the latter after some steps of an optimization algorithm that solves the quadratic form of the augmented Lagrangian (17). We denote the (approximate) argmin of the Lagrangian at the t-th iteration of the proximal method (method of multipliers) by\u1e91 t, \u2020 . Thanks to the aforementioned similarity, we can keep an exponential average of the gradient-like terms with parameter \u00b5 \u2208 [0, 1] and adopt momentum for the dual update, yielding:\n\u03c0 t+1 k = \u00b5\u03c0 t+1 k +\u1e91 t, \u2020 B,k \u2212\u1e91 t, \u2020 A,k \u03b7 k \u03c1 t+1 k = \u03c1 t k + \u03c0 t+1 k(32)\nAs, empirically, a decaying step size has a positive effect on ADAM, we adopt the same strategy for the proximal algorithm as well, resulting in an increasing \u03b7 k . The augmented Lagrangian then becomes:\nz t ,\u1e91 t = argmin z,\u1e91 L \u1e91, \u03c1 t s.t. P 0 (z 0 ,\u1e91 A,1 ); P k (\u1e91 B,k ,\u1e91 A,k+1 ) k \u2208 [1..n \u2212 1] where L (\u1e91, \u03c1) =\u1e91 A,n + k=1..n\u22121 \u03c1 T k (\u1e91 B,k \u2212\u1e91 A,k ) + k=1..n\u22121 \u03b7 k 2 \u00b5\u03c0 k +\u1e91 B,k \u2212\u1e91 A,k \u03b7 k 2 .(33)\n\nD Algorithm summary\n\nWe provide high level summaries of our optimization methods: supergradient (Algorithm 1) and proximal (Algorithm 2).\n\nFor both solvers, we decompose problem (3) into several subset of constraints, duplicate the variables to make the subproblems independent, and enforce their consistency by introducing dual variables \u03c1, which we are going to optimize. This results in problem (9), which we solve using one of the two algorithms. Our initial dual solution is given by the algorithm of Wong and Kolter (2018). The details can be found in Appendix F.\n\nAlgorithm 1 Supergradient method\n1: function SUBG COMPUTE BOUNDS({W k , b k , l k , u k } k=1..n ) 2:\nInitialise dual variables \u03c1 using the algo of Wong and Kolter (2018) 3:\n\nfor nb iterations do 4:\u1e91 * \u2190 inner minimization using \u00a75.1.1 and \u00a75.1.2\n\n\n5:\n\nCompute supergradient using \u2207 \u03c1 q(\u03c1 t ) =\u1e91 * B \u2212\u1e91 * return q(\u03c1) 9: end function The structure of our employed supergradient method is relatively simple. We iteratively minimize over the primal variables (line 4) in order to compute the supergradient, which is then used to update the dual variables through the Adam update (line 6). Compute layer optimal step size \u03b3 * k using (27) 10:\n\nUpdate layer primal variables: return q(\u03c1) 15: end function The proximal method, instead alternates updates to the dual variables (applying the updates from (16); line 5) and to the primal variables (update of (17); lines 6 to 12). The inner minimization problem is solved only approximately, using the Frank-Wolfe algorithm (line 10), applied in a block-coordinate fashion over the network layers (line 7). We have closed form solution for both the conditional gradient (line 8) and the optimal step-size (line 9).\nz k = \u03b3 * kx k + (1 \u2212 \u03b3 * k )\u1e91\n\nE Comparison between the duals\n\nWe will show the relation between the decomposition done by Dvijotham et al. (2018) and the one proposed in this paper. We will show that, in the context of ReLU activation functions, from any dual solution of their dual providing a bound, our dual provides a better bound. Figures 6 and 7 show experiments (see section 6.3) for a network trained using standard stochastic gradient descent and cross entropy, with no robustness objective. We employ verif = 5/255. Most observations done in the main paper for the adversarially trained network (Figures 2 and 3) still hold true: in particular, the advantage of the Lagrangian Decomposition based dual compared to the dual by Dvijotham et al. (2018) is even more marked than in Figure 3. In fact, for a subset of the properties, DSG+ has returns rather loose bounds even after 1040 iterations. Differently from the adversarially trained network, in this case, the enlarged support of the optimality gap distribution for the proximal algorithm nullifies its advantage with respect to the supergradient method, making it return on average the same bounds.  Figure 6. Each datapoint corresponds to a CIFAR image. The dotted line corresponds to the equality and in both graphs, lower is better along both axes.\n\n\nG.1.1 Network Architecture\n\nWe now outline the network architecture for both the adversarially trained and the normally trained network experiments.\n\nConv2D(channels=16, kernel size=4, stride=2) Conv2D(channels=32, kernel size=4, stride=2) Linear(channels=100) Linear(channels=10)  (2018). Each layer but the last is followed by a ReLU activation function.\n\n\nG.2 Complete Verification\n\nAs done by Lu and Kumar (2020), we provide a more in-depth analysis of the base model results presented in Figure 8. Depending on the time t i that the Gurobi baseline employed to verify them, the properties have been divided into an \"easy\" (t i < 800), \"medium\" and a \"hard \" (t i > 2400) set. The relative performance of the iterative dual methods remains unvaried, with the initial gap between our two methods increasing with the difficulty of the problem. \n\n\nG.2.1 Network Architectures\n\nFinally, we describe properties and network architecture for the dataset by Lu and Kumar (2020).   Table 4: For each complete verification experiment, the network architecture used and the number of verification properties tested, from the dataset by Lu and Kumar (2020). Each layer but the last is followed by a ReLU activation function. For some of the property classes, we employed only a subset of the original data due to computational constraints.\n\n\ndo not include in our results bounds computed with Interval Bound Propagation (Gowal et al., 2018, Mirman et al., 2018) as on average it performed significantly worse on the networks we used. For all of the methods above, as done in previous work for neural network verification (Bunel et al., 2019, Lu and Kumar, 2020), we compute intermediate bounds (see appendix B) by taking the layer-wise best bounds output by Interval Propagation and WK. This holds true for both the incomplete and the complete verification experiments. Gurobi and Gurobi-TL were run on 4 CPUs, whereas all the other methods were run on a single GPU. While it may seem to lead to an unfair comparison, the flexibility and parallelism of the methods are a big part of their advantages over off-the-shelf solvers.\n\nFigure 2 :\n2Distribution of runtime and gap to optimality on a network adversarially trained with the method by Madry et al. (2018).\n\nFigure 3 :\n3Pointwise comparison for a subset of the methods inFigure 2. Each datapoint corresponds to a CIFAR image. The dotted line corresponds to the equality and in both graphs, lower is better along both axes.\n\nFigure 4 :\n4Cactus plots for the base, wide and deep models. For each, we compare the bounding methods and complete verification algorithms by plotting the percentage of solved properties as a function of runtime.\n\nFrank\n, M. and Wolfe, P. (1956). An algorithm for quadratic programming. Naval Research Logistics Quarterly. Goodfellow, I. J., Shlens, J., and Szegedy, C. (2015). Explaining and harnessing adversarial examples. International Conference on Learning Representations. Gowal, S., Dvijotham, K., Stanforth, R., Bunel, R., Qin, C., Uesato, J., Mann, T., and Kohli, P. (2018). On the effectiveness of interval bound propagation for training verifiably robust models. Workshop on Security in Machine Learning, NeurIPS. Guignard, M. and Kim, S. (1987). Lagrangean decomposition: A model yielding stronger lagrangean bounds. Mathematical programming. Gurobi Optimization, L. (2020). Gurobi optimizer reference manual. Katz, G., Barrett, C., Dill, D., Julian, K., and Kochenderfer, M. (2017). Reluplex: An efficient smt solver for verifying deep neural networks. International Conference on Computer-Aided Verification. Kingma, D. P. and Ba, J. (2015). Adam: A method for stochastic optimization. International Conference on Learning Representations. Lin, H., Mairal, J., and Harchaoui, Z. (2017). Catalyst acceleration for first-order convex optimization: From theory to practice. Journal of Machine Learning Research. Lu, J. and Kumar, M. P. (2020). Neural network branching for neural network verification. In International Conference on Learning Representations. Luo, L., Xiong, Y., Liu, Y., and Sun, X. (2019). Adaptive gradient methods with dynamic bound of learning rate. International Conference on Learning Representations. Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A. (2018). Towards deep learning models resistant to adversarial attacks. International Conference on Learning Representations. Mirman, M., Gehr, T., and Vechev, M. (2018). Differentiable abstract interpretation for provably robust neural networks. International Conference on Machine Learning. Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., and Lerer, A. (2017). Automatic differentiation in pytorch. NIPS Autodiff Workshop. Raghunathan, A., Steinhardt, J., and Liang, P. S. (2018). Semidefinite relaxations for certifying robustness to adversarial examples. Neural Information Processing Systems. Salman, H., Yang, G., Zhang, H., Hsieh, C.-J., and Zhang, P. (2019). A convex relaxation barrier to tight robustness verification of neural networks. Neural Information Processing Systems. Salzo, S. and Villa, S. (2012). Inexact and accelerated proximal point algorithms. Journal of Convex Analysis, 19:1167-1192. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., and Fergus, R. (2014). Intriguing properties of neural networks. International Conference on Learning Representations. Tjeng, V., Xiao, K., and Tedrake, R. (2019). Evaluating robustness of neural networks with mixed integer programming. International Conference on Learning Representations. Uesato, J., O'Donoghue, B., Oord, A. v. d., and Kohli, P. (2018). Adversarial risk and the dangers of evaluating against weak attacks. International Conference on Machine Learning. Weng, T.-W., Zhang, H., Chen, H., Song, Z., Hsieh, C.-J., Boning, D., Dhillon, I. S., and Daniel, L. (2018). Towards fast computation of certified robustness for relu networks. International Conference on Machine Learning. Wong, E. and Kolter, Z. (2018). Provable defenses against adversarial examples via the convex outer adversarial polytope. International Conference on Machine Learning. Xiang, W., Tran, H.-D., and Johnson, T. T. (2017). Output reachable set estimation and verification for multi-layer neural networks. IEEE Transactions on Neural Networks and Learning Systems. Both upper and lower bounds are in Case 2 with the two pieces visible.\n\nFigure 5 :\n5Convex hull of the Sigmoid activation function for different input bound configurations.\n\n\nby Dvijotham et al. (2018) rely on Adam (Kingma and Ba, 2015) to speed-up convergence. Inspired by its presence in Adam, and by the work on accelerating proximal methods Lin et al. (2017), Salzo and Villa\n\nFigure 7 :\n7Pointwise comparison for a subset of the methods in\n\nFigure 8 :\n8Cactus plots for the base model, with properties of varying difficulty. For each, we compare the bounding methods and complete verification algorithms by plotting the percentage of solved properties as a function of runtime.\n\n\nAnderson et al., 2019)  have a quadratic number of variables or a potentially exponential number of constraints. We do not address them here.). Explicitly or implicitly, these are all \nequivalent to propagating a convex domain through the \nnetwork to overapproximate the set of reachable values. \nOur approach consists in tackling a relaxation equivalent \nto the PLANET one (although generalised beyond ReLU), \nby designing a custom solver that achieves faster perfor-\nmance without sacrificing tightness. Some potentially \ntighter convex relaxations exist but involve a quadratic \nnumber of variables, such as the semi-definite program-\nming method of Raghunathan et al. (2018) . Better re-\nlaxations obtained from relaxing strong Mixed Integer \nProgramming formulations (\n\nTable 1 :\n1For base, wide and deep models, we compare average solving time, average number of solved sub-problems and the percentage of timed out properties. The best performing iterative method is highlighted in bold.Base \nWide \nDeep \nMethod \ntime(s) \nsub-problems %Timeout \ntime(s) \nsub-problems %Timeout \ntime(s) \nsub-problems %Timeout \nGUROBI BABSR \n1384.226 \n1291.019 \n2.39 \n2912.246 \n630.864 \n50.66 \n3007.237 \n299.913 \n54.00 \nMIPPLANET \n2031.495 \n36.10 \n3118.593 \n80.00 \n2997.115 \n73.60 \nDSG+ BABSR \n199.958 \n4209.464 \n1.26 \n1048.594 \n4518.116 \n20.00 \n509.484 \n1992.345 \n9.60 \nSUPERGRADIENT BABSR \n160.541 \n3818.397 \n0.86 \n920.351 \n4069.894 \n18.00 \n390.367 \n1783.577 \n7.2 \nPROXIMAL BABSR \n151.126 \n3305.286 \n0.86 \n891.163 \n3343.601 \n18.00 \n384.984 \n1655.519 \n6.8 \n\n\n\n\nAlgorithm 2 Proximal method 1: function PROX COMPUTE BOUNDS({W k , b k , l k , u k } k=1..n ) Initialise dual variables \u03c1 using the algo of Wong and Kolter(2018)Initialise primal variables\u1e91 at the conditional gradient of \u03c1 for nb outer iterations do for nb inner iterations dofor k \u2208 [0..n \u2212 1] doCompute layer conditional gradient [x k ] using using \u00a75.1.1 and \u00a75.1.22: \n\n3: \n\n4: \n\n5: \n\nUpdate dual variables using equation (16) \n\n6: \n\n7: \n\n8: \n\n9: \n\n\n\nTable 2 :\n2Network architecture for incomplete verification, from Wong and Kolter\n\nTable 3 :\n3For easy, medium and difficult level verification properties on the base model, we compare average solving time, average number of solved sub-problems and the percentage of timed out properties.Easy \nMedium \nHard \nMethod \ntime(s) \nsub-problems \n%Timeout \ntime(s) \nsub-problems \n%Timeout \ntime(s) \nsub-problems \n%Timeout \nGUROBI-BABSR \n545.720 \n580.428 \n0.0 \n1363.175 \n1391.361 \n0.0 \n2894.096 \n2381.555 \n13.33 \nMIPPLANET \n1499.375 \n16.48 \n2233.630 \n42.53 \n2379.898 \n51.85 \nDSG+ BABSR \n112.100 \n2030.362 \n0.85 \n175.945 \n4227.476 \n0.52 \n419.861 \n8052.069 \n4.07 \nSUPERGRADIENT BABSR \n85.004 \n1662.000 \n0.64 \n135.082 \n3723.422 \n0.26 \n363.232 \n7913.587 \n2.96 \nPROXIMAL BABSR \n73.606 \n1377.666 \n0.42 \n127.537 \n3210.052 \n0.26 \n351.954 \n7017.601 \n3.33 \n\n\n\n\nMedium: 764 [Luo et al. (2019): 773] Hard: 270 [Luo et al. (2019): 426] linear layer of 100 hidden units linear layer of 10 hidden units (Total ReLU activation units: 3172) Total ReLU activation units: 6756)Network Name \nNo. of Properties \nNetwork Architecture \n\nBASE \nModel \n\nEasy: 467 \nConv2d(3,8,4, stride=2, padding=1) \nConv2d(8,16,4, stride=2, padding=1) \nWIDE \n300 \n\nConv2d(3,16,4, stride=2, padding=1) \nConv2d(16,32,4, stride=2, padding=1) \nlinear layer of 100 hidden units \nlinear layer of 10 hidden units \n(Total ReLU activation units: 6244) \n\nDEEP \n250 \n\nConv2d(3,8,4, stride=2, padding=1) \nConv2d(8,8,3, stride=1, padding=1) \nConv2d(8,8,3, stride=1, padding=1) \nConv2d(8,8,4, stride=2, padding=1) \nlinear layer of 100 hidden units \nlinear layer of 10 hidden units \n(\nTheorem. Let us assume \u03c3(\u1e91 k ) = max(0,\u1e91 k ). For any solution \u00b5, \u03bb of dual (2) byDvijotham et al. (2018)yielding bound d(\u00b5, \u03bb), it holds that q(\u00b5) \u2265 d(\u00b5, \u03bb).Proof. We start by reproducing the formulation thatDvijotham et al. (2018)uses, which we slightly modify in order to have a notation more comparable to ours 1 . With our convention, doing the decomposition to obtain Problem (6) in(Dvijotham et al., 2018)would give:Decomposing it, in the same way thatDvijotham et al. (2018)do it in order to obtain their equation(7), we obtain(with the convention that \u00b5 n = \u2212I) 1 Our activation function \u03c3 is denoted h in their paper. The equivalent of x in their paper is z in ours, while the equivalent of their z is\u1e91. Also note that their paper use the computation of upper bounds as examples while ours use the computation of lower bounds.As a reminder, the formulation of our dual (9) is:which can be decomposed as:with the convention that \u03c1 n = \u2212I. We will show that when we chose the dual variables such thatwe obtain a tighter bound than the ones given by (35).We will start by showing that the term being optimised over P is equivalent to some of the terms in(35):The first equality is given by the replacement formula (38), while the second one is given by performing the replacement of\u1e91 A,1 with his expression in P 0We will now obtain a lower bound of the term being optimised over P k . Let's start by plugging in the values using the formula (38) and replace the value of\u1e91 A,k+1 using the constraint.Focusing on the second term that contains the minimization over the convex hull, we will obtain a lower bound. It is important, at this stage, to recall that, as seen in section 5.1.2, the minimum of the second term can either be one of the three vertices of the triangle inFigure 1(ambiguous ReLU), the\u1e91 B,k = z k line (passing ReLU), or the (\u1e91 B,k = 0, z k = 0) triangle vertex (blocking ReLU). We will write (\u1e91 B,k , z k ) \u2208 ReLU sol(\u1e91 B,k , z k , l k , u k ).We can add a term \u03bb T k (\u03c3 (\u1e91 k ) \u2212 \u03c3 (\u1e91 k )) = 0 and obtain: minEquality between the second line and the third comes from the fact that we are adding a term equal to zero. The inequality between the third line and the fourth is due to the fact that the sum of minimum is going to be lower than the minimum of the sum. For what concerns obtaining the final line, the first term comes from projecting z k out of the feasible domain and taking the convex hull of the resulting domain. We need to look more carefully at the second term.Plugging in the ReLU formula:as (keeping in mind the shape of ReLU sol and for the purposes of this specific problem) excluding the negative part of the\u1e91 B,k domain does not alter the minimal value. The final line then follows by observing that forcing\u1e91 B,k = z is a convex relaxation of the positive part of ReLU sol.Summing up the lower bounds for all the terms in(37), as given by equations(39)and(41), we obtain the formulation of Problem(35). We conclude that the bound obtained by Dvijotham et al.(2018)is necessarily no larger than the bound derived using our dual. Given that we are computing lower bounds, this means that their bound is looser.F Initialisation of the dualWe will now show that the solution generated by the method of Wong and Kolter(2018)can be used to provide initialization to our dual (9), even though both duals were derived differently. Theirs is derived from the Lagrangian dual of the Planet Ehlers (2017) relaxation, while ours come from Lagrangian decomposition. However, we will show that a solution that can be extracted from theirs lead to the exact same bound they generate.As a reminder, we reproduce results proven inWong and Kolter (2018). In order to obtain the bound, the problem they solved is: min zn c T\u1e91 n such that\u1e91 n \u2208Z (x),When c is just an identity matrix (so we optimise the bounds of each neuron), we recover the problem (3).Z (x) correspond to the contraints (3b) to (3c).Based on the Theorem 1, and the equations (8) to (10) (Wong and Kolter, 2018), the dual problem that they derive has an objective function of 2 :with a solution given by \u03bd n = \u2212\u0109where D i is a diagonal matrix with entriesand I \u2212 i , I + i , I i correspond respectively to blocked ReLUs (with always negative inputs), passing ReLUs (with always positive inputs) and ambiguous ReLUs.We will now prove that, by taking as our solution of (9) \u03c1 k = \u03bd k ,we obtain exactly the same bound.2We adjust the indexing slightly because Wong et al. note the input z1, while we refer to it as z0The problem we're solving is (9), so, given a choice of \u03c1, the bound that we generate is:which can be decomposed into several subproblems:where we take the convention consistent with (46) that \u03c1 n = \u03bd n = \u2212c = \u2212I.Let's start by evaluating the problem over P 0 , having replaced \u03c1 1 by \u03bd 1 in accordance with(46): minwhere in the context of (Wong and Kolter, 2018), C is defined by the bounds l 0 = x \u2212 and u 0 = x + . We already explained how to solve this subproblem in the context of our Frank Wolfe optimisation, see Equation(12)). Plugging in the solution into the objective function gives us:We will now evaluate the values of the problem over P k . Once again, we replace the \u03c1 with the appropriate values of \u03bd in accordance to(46): minWe can rephrase the problem such that it decomposes completely over the ReLUs, by merging the last equality constraint into the objective function: minNote that \u03bd T k+1 W k+1 =\u03bd T k . We will now omit the term \u2212\u03bd T k+1 b k+1 which doesn't depend on the optimisation variable anymore and will therefore be directly passed down to the value of the bound.For the rest of the problem, we will distinguish the different cases of ReLU, I + , I \u2212 and I.In the case of a ReLU j \u2208 I + , we have cvx hull \u03c3 (. . . ) \u2261\u1e91 B,k [j] = z k [j], so the replacement of z k [j] makes the objective function term for j becomes (\u03bd k [j] \u2212\u03bd k [j])\u1e91 B,k[j]. Given that j \u2208 I + , this means that the corresponding element in D k is 1, so \u03bd k [j] =\u03bd k [j], which means that the term in the objective function is zero.In the case of a ReLU j \u2208 I \u2212 , we have cvx hull \u03c3 (. . . ) \u2261 z k [j] = 0, so the replacement of z k [j] makes the objective function term for j becomes \u03bd k [j]\u1e91 B,k[j]. Given that j \u2208 I \u2212 , this means that the corresponding element in D k is 0, so \u03bd k [j] = 0. This means that the term in the objective function is zero.The case for a ReLU j \u2208 I is more complex. We apply the same strategy of picking the appropriate inequalities in cvx hull as we did for obtaining Equation(15), which leads us to:Once again, we can recognize that the coefficient in front of z B,k [j] (in the first line of the objective function) is equal to 0 by construction of the values of \u03bd and\u03bd. The coefficient in front of max(z B,k , 0) in the second line is necessarily positive. Therefore, the minimum value for this problem will necessarily be the constant term in the third line (reachable for z B,k = 0 which is feasible due to j being in I). The value of this constant term is:Regrouping the different cases and the constant term of problem (52) that we ignored, we find that the value of the term corresponding to the P k subproblem is:Plugging all the optimisation result into Equation(48), we obtain:which is exactly the value given byWong and Kolter (2018)in Equation(43).G Supplementary experimentsWe now complement the results presented in the main paper and provide additional information on the experimental setting. We start from incomplete verification ( \u00a7 G.1) and then move on to complete verification ( \u00a7 G.2). Gap to be t boundFigure 6: Comparison of the distribution of runtime and gap to optimality on a normally trained network. In both cases, lower is better. The width at a given value represents the proportion of problems for which this is the result. Note that Gurobi always return the optimal solution so doesn't appear on the optimality gap, but is always the highest runtime.G.1 Incomplete Verification", "annotations": {"author": "[{\"end\":115,\"start\":60},{\"end\":205,\"start\":116},{\"end\":266,\"start\":206},{\"end\":330,\"start\":267},{\"end\":387,\"start\":331},{\"end\":447,\"start\":388},{\"end\":508,\"start\":448},{\"end\":567,\"start\":509}]", "publisher": null, "author_last_name": "[{\"end\":70,\"start\":65},{\"end\":135,\"start\":127},{\"end\":221,\"start\":212},{\"end\":285,\"start\":283},{\"end\":342,\"start\":333},{\"end\":402,\"start\":397},{\"end\":463,\"start\":459},{\"end\":522,\"start\":511}]", "author_first_name": "[{\"end\":64,\"start\":60},{\"end\":126,\"start\":116},{\"end\":211,\"start\":206},{\"end\":280,\"start\":267},{\"end\":282,\"start\":281},{\"end\":332,\"start\":331},{\"end\":396,\"start\":388},{\"end\":454,\"start\":448},{\"end\":458,\"start\":455},{\"end\":510,\"start\":509}]", "author_affiliation": "[{\"end\":114,\"start\":72},{\"end\":204,\"start\":162},{\"end\":265,\"start\":223},{\"end\":329,\"start\":287},{\"end\":386,\"start\":344},{\"end\":446,\"start\":404},{\"end\":507,\"start\":465},{\"end\":566,\"start\":524}]", "title": "[{\"end\":57,\"start\":1},{\"end\":624,\"start\":568}]", "venue": null, "abstract": "[{\"end\":1846,\"start\":626}]", "bib_ref": "[{\"end\":2376,\"start\":2352},{\"end\":2398,\"start\":2376},{\"end\":2582,\"start\":2561},{\"end\":2603,\"start\":2582},{\"end\":2777,\"start\":2748},{\"end\":2790,\"start\":2777},{\"end\":3562,\"start\":3539},{\"end\":3698,\"start\":3678},{\"end\":3846,\"start\":3827},{\"end\":3867,\"start\":3846},{\"end\":3890,\"start\":3867},{\"end\":3990,\"start\":3976},{\"end\":4060,\"start\":4041},{\"end\":4081,\"start\":4060},{\"end\":4104,\"start\":4081},{\"end\":4356,\"start\":4332},{\"end\":4624,\"start\":4600},{\"end\":4748,\"start\":4725},{\"end\":6957,\"start\":6938},{\"end\":6971,\"start\":6957},{\"end\":6990,\"start\":6971},{\"end\":7010,\"start\":6990},{\"end\":7030,\"start\":7010},{\"end\":7382,\"start\":7369},{\"end\":7403,\"start\":7382},{\"end\":7493,\"start\":7479},{\"end\":7753,\"start\":7734},{\"end\":7774,\"start\":7753},{\"end\":7793,\"start\":7774},{\"end\":7816,\"start\":7793},{\"end\":7890,\"start\":7867},{\"end\":8215,\"start\":8191},{\"end\":10345,\"start\":10321},{\"end\":10618,\"start\":10595},{\"end\":10806,\"start\":10783},{\"end\":11027,\"start\":11003},{\"end\":15152,\"start\":15129},{\"end\":15567,\"start\":15544},{\"end\":16329,\"start\":16306},{\"end\":16937,\"start\":16916},{\"end\":22008,\"start\":21977},{\"end\":25417,\"start\":25389},{\"end\":25429,\"start\":25417},{\"end\":25668,\"start\":25645},{\"end\":27414,\"start\":27392},{\"end\":27556,\"start\":27533},{\"end\":27702,\"start\":27679},{\"end\":29362,\"start\":29340},{\"end\":29603,\"start\":29583},{\"end\":30605,\"start\":30582},{\"end\":32318,\"start\":32295},{\"end\":52250,\"start\":52227},{\"end\":52864,\"start\":52841}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":55543,\"start\":54756},{\"attributes\":{\"id\":\"fig_1\"},\"end\":55677,\"start\":55544},{\"attributes\":{\"id\":\"fig_2\"},\"end\":55893,\"start\":55678},{\"attributes\":{\"id\":\"fig_3\"},\"end\":56108,\"start\":55894},{\"attributes\":{\"id\":\"fig_4\"},\"end\":59871,\"start\":56109},{\"attributes\":{\"id\":\"fig_5\"},\"end\":59973,\"start\":59872},{\"attributes\":{\"id\":\"fig_6\"},\"end\":60180,\"start\":59974},{\"attributes\":{\"id\":\"fig_8\"},\"end\":60245,\"start\":60181},{\"attributes\":{\"id\":\"fig_9\"},\"end\":60483,\"start\":60246},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":61259,\"start\":60484},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":62032,\"start\":61260},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":62487,\"start\":62033},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":62570,\"start\":62488},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":63328,\"start\":62571},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":64108,\"start\":63329}]", "paragraph": "[{\"end\":2303,\"start\":1862},{\"end\":2791,\"start\":2305},{\"end\":3891,\"start\":2793},{\"end\":4277,\"start\":3893},{\"end\":6826,\"start\":4279},{\"end\":8722,\"start\":6844},{\"end\":9319,\"start\":8740},{\"end\":9431,\"start\":9321},{\"end\":10044,\"start\":9548},{\"end\":10076,\"start\":10046},{\"end\":10655,\"start\":10271},{\"end\":10896,\"start\":10684},{\"end\":11306,\"start\":10919},{\"end\":11519,\"start\":11308},{\"end\":12224,\"start\":11657},{\"end\":12654,\"start\":12483},{\"end\":13269,\"start\":12656},{\"end\":13606,\"start\":13434},{\"end\":13719,\"start\":13608},{\"end\":13959,\"start\":13758},{\"end\":14247,\"start\":14077},{\"end\":14671,\"start\":14386},{\"end\":15052,\"start\":14673},{\"end\":15457,\"start\":15073},{\"end\":15621,\"start\":15459},{\"end\":15961,\"start\":15648},{\"end\":16278,\"start\":16002},{\"end\":16418,\"start\":16303},{\"end\":16733,\"start\":16420},{\"end\":16938,\"start\":16769},{\"end\":17328,\"start\":16940},{\"end\":17450,\"start\":17368},{\"end\":18152,\"start\":17538},{\"end\":18382,\"start\":18257},{\"end\":18653,\"start\":18384},{\"end\":18829,\"start\":18745},{\"end\":19644,\"start\":18999},{\"end\":19760,\"start\":19755},{\"end\":20375,\"start\":19901},{\"end\":21396,\"start\":20377},{\"end\":21637,\"start\":21398},{\"end\":21756,\"start\":21657},{\"end\":22242,\"start\":21781},{\"end\":23036,\"start\":22470},{\"end\":23205,\"start\":23038},{\"end\":23837,\"start\":23231},{\"end\":24168,\"start\":23839},{\"end\":24737,\"start\":24170},{\"end\":24973,\"start\":24805},{\"end\":25528,\"start\":24975},{\"end\":26838,\"start\":25569},{\"end\":27203,\"start\":26863},{\"end\":27366,\"start\":27205},{\"end\":27512,\"start\":27368},{\"end\":28220,\"start\":27514},{\"end\":28638,\"start\":28222},{\"end\":28643,\"start\":28640},{\"end\":29279,\"start\":28671},{\"end\":31880,\"start\":29281},{\"end\":32657,\"start\":31882},{\"end\":33416,\"start\":32683},{\"end\":33527,\"start\":33418},{\"end\":34082,\"start\":33529},{\"end\":34862,\"start\":34084},{\"end\":36391,\"start\":34864},{\"end\":37220,\"start\":36393},{\"end\":37944,\"start\":37235},{\"end\":38110,\"start\":37959},{\"end\":38283,\"start\":38144},{\"end\":38492,\"start\":38307},{\"end\":38672,\"start\":38494},{\"end\":39045,\"start\":38748},{\"end\":39496,\"start\":39077},{\"end\":39642,\"start\":39498},{\"end\":39852,\"start\":39687},{\"end\":40185,\"start\":39926},{\"end\":40467,\"start\":40249},{\"end\":41203,\"start\":40469},{\"end\":41664,\"start\":41205},{\"end\":41802,\"start\":41711},{\"end\":42062,\"start\":41934},{\"end\":42468,\"start\":42135},{\"end\":43156,\"start\":42470},{\"end\":43274,\"start\":43158},{\"end\":43569,\"start\":43276},{\"end\":43695,\"start\":43571},{\"end\":43987,\"start\":43857},{\"end\":44465,\"start\":43989},{\"end\":45063,\"start\":44589},{\"end\":45508,\"start\":45065},{\"end\":45653,\"start\":45564},{\"end\":46401,\"start\":45655},{\"end\":47190,\"start\":46458},{\"end\":47476,\"start\":47239},{\"end\":47710,\"start\":47514},{\"end\":47889,\"start\":47757},{\"end\":48102,\"start\":48040},{\"end\":48230,\"start\":48137},{\"end\":48685,\"start\":48232},{\"end\":48768,\"start\":48728},{\"end\":48939,\"start\":48896},{\"end\":49186,\"start\":49056},{\"end\":49898,\"start\":49188},{\"end\":50179,\"start\":49976},{\"end\":50513,\"start\":50397},{\"end\":50945,\"start\":50515},{\"end\":50979,\"start\":50947},{\"end\":51120,\"start\":51049},{\"end\":51193,\"start\":51122},{\"end\":51585,\"start\":51200},{\"end\":52102,\"start\":51587},{\"end\":53421,\"start\":52167},{\"end\":53572,\"start\":53452},{\"end\":53780,\"start\":53574},{\"end\":54270,\"start\":53810},{\"end\":54755,\"start\":54302}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9547,\"start\":9432},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10270,\"start\":10077},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11656,\"start\":11520},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12356,\"start\":12225},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12482,\"start\":12356},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13320,\"start\":13270},{\"attributes\":{\"id\":\"formula_6\"},\"end\":13433,\"start\":13320},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13757,\"start\":13720},{\"attributes\":{\"id\":\"formula_8\"},\"end\":14076,\"start\":13960},{\"attributes\":{\"id\":\"formula_9\"},\"end\":14385,\"start\":14248},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16768,\"start\":16734},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17537,\"start\":17451},{\"attributes\":{\"id\":\"formula_12\"},\"end\":18256,\"start\":18153},{\"attributes\":{\"id\":\"formula_13\"},\"end\":18706,\"start\":18654},{\"attributes\":{\"id\":\"formula_14\"},\"end\":18998,\"start\":18830},{\"attributes\":{\"id\":\"formula_15\"},\"end\":19754,\"start\":19645},{\"attributes\":{\"id\":\"formula_16\"},\"end\":19900,\"start\":19761},{\"attributes\":{\"id\":\"formula_17\"},\"end\":22286,\"start\":22243},{\"attributes\":{\"id\":\"formula_18\"},\"end\":22469,\"start\":22286},{\"attributes\":{\"id\":\"formula_19\"},\"end\":24804,\"start\":24738},{\"attributes\":{\"id\":\"formula_21\"},\"end\":38306,\"start\":38284},{\"attributes\":{\"id\":\"formula_22\"},\"end\":38747,\"start\":38673},{\"attributes\":{\"id\":\"formula_23\"},\"end\":39686,\"start\":39643},{\"attributes\":{\"id\":\"formula_24\"},\"end\":39925,\"start\":39853},{\"attributes\":{\"id\":\"formula_25\"},\"end\":40248,\"start\":40186},{\"attributes\":{\"id\":\"formula_26\"},\"end\":41710,\"start\":41665},{\"attributes\":{\"id\":\"formula_27\"},\"end\":41933,\"start\":41803},{\"attributes\":{\"id\":\"formula_28\"},\"end\":42134,\"start\":42063},{\"attributes\":{\"id\":\"formula_29\"},\"end\":43856,\"start\":43696},{\"attributes\":{\"id\":\"formula_30\"},\"end\":44588,\"start\":44466},{\"attributes\":{\"id\":\"formula_31\"},\"end\":45563,\"start\":45509},{\"attributes\":{\"id\":\"formula_32\"},\"end\":46433,\"start\":46402},{\"attributes\":{\"id\":\"formula_33\"},\"end\":47756,\"start\":47711},{\"attributes\":{\"id\":\"formula_34\"},\"end\":48006,\"start\":47890},{\"attributes\":{\"id\":\"formula_35\"},\"end\":48136,\"start\":48103},{\"attributes\":{\"id\":\"formula_36\"},\"end\":48727,\"start\":48686},{\"attributes\":{\"id\":\"formula_37\"},\"end\":48895,\"start\":48769},{\"attributes\":{\"id\":\"formula_38\"},\"end\":49040,\"start\":48940},{\"attributes\":{\"id\":\"formula_39\"},\"end\":49975,\"start\":49899},{\"attributes\":{\"id\":\"formula_40\"},\"end\":50374,\"start\":50180},{\"attributes\":{\"id\":\"formula_41\"},\"end\":51048,\"start\":50980},{\"attributes\":{\"id\":\"formula_42\"},\"end\":52133,\"start\":52103}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":36498,\"start\":36491},{\"end\":54408,\"start\":54401}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1860,\"start\":1848},{\"attributes\":{\"n\":\"2\"},\"end\":6842,\"start\":6829},{\"attributes\":{\"n\":\"3\"},\"end\":8738,\"start\":8725},{\"attributes\":{\"n\":\"4\"},\"end\":10682,\"start\":10658},{\"attributes\":{\"n\":\"4.1\"},\"end\":10917,\"start\":10899},{\"attributes\":{\"n\":\"4.2\"},\"end\":15071,\"start\":15055},{\"end\":15646,\"start\":15624},{\"attributes\":{\"n\":\"5\"},\"end\":16000,\"start\":15964},{\"attributes\":{\"n\":\"5.1\"},\"end\":16301,\"start\":16281},{\"attributes\":{\"n\":\"5.1.1\"},\"end\":17366,\"start\":17331},{\"attributes\":{\"n\":\"5.1.2\"},\"end\":18743,\"start\":18708},{\"attributes\":{\"n\":\"5.2\"},\"end\":21655,\"start\":21640},{\"attributes\":{\"n\":\"5.2.1\"},\"end\":21779,\"start\":21759},{\"attributes\":{\"n\":\"5.2.2\"},\"end\":23229,\"start\":23208},{\"attributes\":{\"n\":\"6\"},\"end\":25542,\"start\":25531},{\"attributes\":{\"n\":\"6.1\"},\"end\":25567,\"start\":25545},{\"attributes\":{\"n\":\"6.2\"},\"end\":26861,\"start\":26841},{\"attributes\":{\"n\":\"6.3\"},\"end\":28669,\"start\":28646},{\"attributes\":{\"n\":\"6.4\"},\"end\":32681,\"start\":32660},{\"attributes\":{\"n\":\"7\"},\"end\":37233,\"start\":37223},{\"end\":37957,\"start\":37947},{\"end\":38142,\"start\":38113},{\"end\":39075,\"start\":39048},{\"end\":46456,\"start\":46435},{\"end\":47237,\"start\":47193},{\"end\":47512,\"start\":47479},{\"end\":48038,\"start\":48008},{\"end\":49054,\"start\":49042},{\"end\":50395,\"start\":50376},{\"end\":51198,\"start\":51196},{\"end\":52165,\"start\":52135},{\"end\":53450,\"start\":53424},{\"end\":53808,\"start\":53783},{\"end\":54300,\"start\":54273},{\"end\":55555,\"start\":55545},{\"end\":55689,\"start\":55679},{\"end\":55905,\"start\":55895},{\"end\":56115,\"start\":56110},{\"end\":59883,\"start\":59873},{\"end\":60192,\"start\":60182},{\"end\":60257,\"start\":60247},{\"end\":61270,\"start\":61261},{\"end\":62498,\"start\":62489},{\"end\":62581,\"start\":62572}]", "table": "[{\"end\":61259,\"start\":60627},{\"end\":62032,\"start\":61479},{\"end\":62487,\"start\":62403},{\"end\":63328,\"start\":62777},{\"end\":64108,\"start\":63538}]", "figure_caption": "[{\"end\":55543,\"start\":54758},{\"end\":55677,\"start\":55557},{\"end\":55893,\"start\":55691},{\"end\":56108,\"start\":55907},{\"end\":59871,\"start\":56116},{\"end\":59973,\"start\":59885},{\"end\":60180,\"start\":59976},{\"end\":60245,\"start\":60194},{\"end\":60483,\"start\":60259},{\"end\":60627,\"start\":60486},{\"end\":61479,\"start\":61272},{\"end\":62403,\"start\":62035},{\"end\":62570,\"start\":62500},{\"end\":62777,\"start\":62583},{\"end\":63538,\"start\":63331}]", "figure_ref": "[{\"end\":19325,\"start\":19317},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":30174,\"start\":30166},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":31959,\"start\":31951},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":36486,\"start\":36478},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":43313,\"start\":43305},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":43568,\"start\":43559},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":45197,\"start\":45188},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":45424,\"start\":45408},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":45463,\"start\":45454},{\"end\":45901,\"start\":45893},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":52456,\"start\":52441},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":52726,\"start\":52710},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":52901,\"start\":52893},{\"end\":53278,\"start\":53270},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":53925,\"start\":53917}]", "bib_author_first_name": null, "bib_author_last_name": null, "bib_entry": null, "bib_title": null, "bib_author": null, "bib_venue": null}}}, "year": 2023, "month": 12, "day": 17}