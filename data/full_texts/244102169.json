{"id": 244102169, "updated": "2023-05-19 13:30:21.268", "metadata": {"title": "A Generative Modeling Approach to Calibrated Predictions: A Use Case on Menstrual Cycle Length Prediction", "authors": "[{\"first\":\"I\u00f1igo\",\"last\":\"Urteaga\",\"middle\":[]},{\"first\":\"Kathy\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Amanda\",\"last\":\"Shea\",\"middle\":[]},{\"first\":\"Virginia\",\"last\":\"Vitzthum\",\"middle\":[\"J.\"]},{\"first\":\"Chris\",\"last\":\"Wiggins\",\"middle\":[\"H.\"]},{\"first\":\"No\u00e9mie\",\"last\":\"Elhadad\",\"middle\":[]}]", "venue": "Proceedings of machine learning research", "journal": "Proceedings of machine learning research", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "We explore how to quantify uncertainty when designing predictive models for healthcare to provide well-calibrated results. Uncertainty quantification and calibration are critical in medicine, as one must not only accommodate the variability of the underlying physiology, but adjust to the uncertain data collection and reporting process. This occurs not only on the context of electronic health records (i.e., the clinical documentation process), but on mobile health as well (i.e., user specific self-tracking patterns must be accounted for). In this work, we show that accurate uncertainty estimation is directly relevant to an important health application: the prediction of menstrual cycle length, based on self-tracked information. We take advantage of a flexible generative model that accommodates under-dispersed distributions via two degrees of freedom to fit the mean and variance of the observed cycle lengths. From a machine learning perspective, our work showcases how flexible generative models can not only provide state-of-the art predictive accuracy, but enable well-calibrated predictions. From a healthcare perspective, we demonstrate that with flexible generative models, not only can we accommodate the idiosyncrasies of mobile health data, but we can also adjust the predictive uncertainty to per-user cycle length patterns. We evaluate the proposed model in real-world cycle length data collected by one of the most popular menstrual trackers worldwide, and demonstrate how the proposed generative model provides accurate and well-calibrated cycle length predictions. Providing meaningful, less uncertain cycle length predictions is beneficial for menstrual health researchers, mobile health users and developers, as it may help design more usable mobile health solutions. \u00a9 2021 I. Urteaga, K. Li, A. Shea, V.J. Vitzthum, C.H. Wiggins & N. Elhadad. Generative modeling for calibrated predictions", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": "35072087", "pubmedcentral": null, "dblp": "conf/mlhc/UrteagaLSVWE21", "doi": null}}, "content": {"source": {"pdf_hash": "3edada6fe0b1d262711733deabd3219bb78ca2ab", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4aa3b71323f51492aab94c5f8aeb259b4a192ef7", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3edada6fe0b1d262711733deabd3219bb78ca2ab.txt", "contents": "\nA Generative Modeling Approach to Calibrated Predictions: A Use Case on Menstrual Cycle Length Prediction Generative modeling for calibrated predictions\n1-30, 2021\n\nI\u00f1igo Urteaga inigo.urteaga@columbia.edu \nKathy Li kathy.li@columbia.edu \nAmanda Shea amanda.shea@biowink.com \nVirginia J Vitzthum vitzthum@indiana.edu \nChris H Wiggins chris.wiggins@columbia.edu \nK Li \nA Shea \nV J Vitzthum \nC H Wiggins \nN Elhadad \n\nDepartment of Applied Physics and Applied Mathematics\nDepartment of Applied Physics and Applied Mathematics\nData Science Institute\nData Science Institute Columbia University\nNew YorkNYUSA\n\n\nClue by BioWink\nKinsey Institute & Department of Anthropology\nColumbia University\nAdalbertstra\u00dfe 7-810999New York, BerlinNYUSA, Germany\n\n\nDepartment of Applied Physics and Applied Mathematics\nData Science Institute\nIndiana University\nBloomingtonINUSA\n\n\nNo\u00e9mie Elhadad\nDepartment of Biomedical Informatics, Data Science Institute\nColumbia University\nNew YorkNYUSA\n\n\nColumbia University\nNew YorkNYUSA\n\nA Generative Modeling Approach to Calibrated Predictions: A Use Case on Menstrual Cycle Length Prediction Generative modeling for calibrated predictions\n\nProceedings of Machine Learning Research\n1491-30, 2021Machine Learning for Healthcare Editor: Editor's name\nWe explore how to quantify uncertainty when designing predictive models for healthcare to provide well-calibrated results. Uncertainty quantification and calibration are critical in medicine, as one must not only accommodate the variability of the underlying physiology, but adjust to the uncertain data collection and reporting process. This occurs not only on the context of electronic health records (i.e., the clinical documentation process), but on mobile health as well (i.e., user specific self-tracking patterns must be accounted for). In this work, we show that accurate uncertainty estimation is directly relevant to an important health application: the prediction of menstrual cycle length, based on self-tracked information. We take advantage of a flexible generative model that accommodates under-dispersed distributions via two degrees of freedom to fit the mean and variance of the observed cycle lengths. From a machine learning perspective, our work showcases how flexible generative models can not only provide state-of-the art predictive accuracy, but enable well-calibrated predictions. From a healthcare perspective, we demonstrate that with flexible generative models, not only can we accommodate the idiosyncrasies of mobile health data, but we can also adjust the predictive uncertainty to per-user cycle length patterns. We evaluate the proposed model in real-world cycle length data collected by one of the most popular menstrual trackers worldwide, and demonstrate how the proposed generative model provides accurate and well-calibrated cycle length predictions. Providing meaningful, less uncertain cycle length predictions is beneficial for menstrual health researchers, mobile health users and developers, as it may help design more usable mobile health solutions.1. We capitalize random variables, we denote their realizations in lower-case.\n\nIntroduction\n\nOne of the primary challenges in predictive modeling for healthcare pertains to handling the uncertainty of both the task and the data at hand, as well as ensuring calibration of model output (Han et al., 2011;Rogers and Walker, 2016;Chen et al., 2020). Because users of these models make decisions -that have health and ethical implications (Gillon, 1994;Siebert, 2003)-based on such predictive outputs, it is critical to ensure users can assess the confidence of a model in its predictions.\n\nIn machine learning predictions, different types of uncertainty are entangled. The uncertainty, given a finite amount of data, of a machine learning technique can be captured with the statistical characterization of its predictions, i.e., via the predictive distribution p(y|x) of the model output y given the input features x. Entangled in this predictive distribution are both aleatoric and epistemic uncertainties. The former denotes the randomness inherent in the data generating process, i.e., the observed data (e.g., collected features and observed outcomes). The latter -also known as model uncertainty-reflects the uncertainty of a model's appropriateness to fit the underlying data generating mechanism.\n\nA goal of statistical machine learning is to devise suitable measures of the uncertainty associated with model predictions . Predictions are probabilistic in nature, taking the form of probability distributions over future events of interest (Dawid, 1984). In a Bayesian view of predictive modeling, the outcome Y , the input features X, and the parameters of a model are viewed as random variables 1 . The distributional assumptions over the model class and the uncertainty over parameters can be characterized with priors and incorporated into the predictive distribution via marginalization of such (parametric) model uncertainties, i.e., p(Y |x) = \u03b8 p(Y |x, \u03b8)p(\u03b8|D)d\u03b8, where D refers to previously observed data.\n\nWithin this probabilistic view of prediction, where the predictive distribution characterizes all the uncertainty in the outcome of interest Y , a model's calibration is a crucial aspect. Calibration refers to the statistical consistency between the distributional forecasts (i.e., the predictive distribution) and the true observations (i.e., the data). As originally argued by Dawid (1984) and many after (Diebold and Mariano, 2002), the predictive posterior must be assessed on the basis of the predicted-observation pairs.\n\nA statistical method is calibrated when, for all the observed examples x for which it predicts an outcome Y = y with probability p(Y = y|x) = p , the proportion (frequency) of real examples observed for outcome y is equal to p , across all values of P (Y = y|x). In this sense, calibration is inherently frequentist, but Bayesian views of calibration have also been argued for (Dawid, 1982). Essentially, calibration is concerned with measuring the over-confidence and under-confidence of a statistical model. As such, it helps assess the extent to which a user can trust the model's predicted outcome probabilities.\n\nIn healthcare, the role of uncertainty estimation and model calibration is gaining momentum (Vach, 2013;Calster et al., 2016;Alba et al., 2017;Stevens and Poppe, 2020;Goldstein et al., 2021), partly due to the increase in popularity of deep learning based approaches (Rajkomar et al., 2018). Recent evidence suggests that deep-learning approaches lack calibrated outputs (Guo et al., 2017;Nixon et al., 2019), even if several techniques have been proposed to assess and fix this gap (Dusenberry et al., 2020;Kwon et al., 2020).\n\nMost of the healthcare model calibration work so far is on classification tasks in the context of clinical, electronic health record data. On the contrary, the use case for this work is menstrual cycle length prediction from mobile health data. Based on a user's self-tracked data from a period tracking app, we aim at forecasting their upcoming cycle length, i.e., the date of their next period. This use case differs from previous work in quantifying uncertainty: (i) we target regression (i.e., next cycle length prediction) rather than classification, and (ii) we leverage mobile health (mHealth) data -subject to selftracking artifacts, like varying adherence to tracking.\n\nWhen characterizing and predicting menstrual patterns based on mHealth data, the relevance of uncertainty quantification is two-fold. On the one hand, self-tracked data from mHealth apps reflects both physiological menstrual patterns and user engagement dynamics (Li et al., 2020). Therefore, one must disentangle the uncertainty of the physiological process (i.e., the menstrual cycle) from the uncertainty on the observed data (i.e., whether users track their period). On the other, uncertain predictions in mHealth often result in non-actionable insights, e.g., \"your next period will occur within the next two weeks\" (Orchard, 2019; Fox and Epstein, 2020).\n\nWe hereby operate within a generative modeling framework, and leverage advances in the statistical characterization of complex distributions to accommodate both self-tracking artifacts and cycle length variability (Li et al., 2020). Precisely, we take advantage of probabilistic machine learning (Chen et al., 2020) and devise a flexible generative model that can accommodate the uncertainties of the task at hand and address predictive calibration directly. We demonstrate how to overcome the over-dispersion of Poisson distributed predictions by proposing a Generalized Poisson based model that provides accurate and better calibrated individualized cycle length predictions. Less uncertain cycle length predictions are intrinsically beneficial, and we hypothesize they may also help design better menstrual mHealth solutions, ultimately increasing their usability.\n\n\nGeneralizable Insights about Machine Learning in the Context of Healthcare\n\nThis work contributes to machine learning in the context of healthcare by first proposing a flexible generative model to provide accurate and well-calibrated predictions. We demonstrate that our model outperforms black-box neural network and state-of-the-art alternatives, by providing interpretable, accurate and well-calibrated predictions. Armed with well-calibrated predictions, users can trust and act upon predictions with more confidence. Second, we argue for the use of probabilistic modeling in healthcare (Chen et al., 2020), since interpretability, accuracy and uncertainty quantification are critical in the medical domain. More broadly, we advocate for the machine learning in healthcare community to not only focus on point estimate based metrics, but to incorporate the calibration tool-set presented here into the evaluation pipeline.\n\n\nRelated Work\n\nCalibration in Predictive Models. A key endeavor of predictive modeling is to provide forecasts that appropriately quantify uncertainty . In healthcare, because of the practical and ethical costs of incorrect and over-confident predictions, there is great value in assessing not only the predictive ability of a given model, but in measuring its uncertainty as well (e.g., by comparing, evaluating, and ranking competing methods).\n\nA probabilistic view of prediction tasks takes the form of predictive posterior densities, and the challenge in evaluating them lies in the dichotomy between comparing predictive probability distributions with observations that are real (or discrete) valued. In general, calibration (the statistical consistency between the distributional forecasts and the observations) and sharpness (the concentration of the predictive distributions) are two key metrics in evaluating predictive posteriors. Many tools for checking calibration and sharpness have been proposed, some based on visual representations and others based on scoring rules . Scoring rules provide summary measures for the evaluation of probabilistic forecasts that assign a numerical score based on the predictive distribution and on the events that materialize.\n\nCalibration in classification tasks (e.g., assessing the risk of a discrete set of events, like in disease prediction) implies transforming classifier scores into class membership probabilities. For these categorical predictive tasks, the expected calibration error (ECE) has become popular (Naeini et al., 2015;Guo et al., 2017;Dusenberry et al., 2020). It is a tractable way to approximate the calibration of a model given a finite dataset, although subject to certain limitations (Nixon et al., 2019). Characterizing probabilistic predictions of continuous variables is fundamentally different from calibrating categorical and binary variable predictions. We refer to , where a theoretically grounded review of scoring rules for density, quantile and interval forecasts is provided.\n\nThe increase in popularity of deep learning (Goodfellow et al., 2016) has resulted in a scrutiny of the uncertainty and calibration performance of these techniques (Malinin and Gales, 2018;Yao et al., 2019). To capture uncertainty, existing state-of-the-art neural network based approaches often make use of ensemble, batch-norm or dropout techniques, yet have been often found to be miscalibrated (Guo et al., 2017;Nixon et al., 2019). Although various post-processing calibration methods have been proposed (Niculescu-Mizil and Caruana, 2005), calibration within deep learning is still a concern.\n\nOn the one hand, some propose to decouple training for good predictive accuracy from its calibration (Song et al., 2019), while others address calibration within-training via alternate loss functions (Avati et al., 2020). These approaches are not guaranteed to appropriately balance prediction and calibration. On the other, an alternative is to consider Bayesian deep learning (Wilson, 2020). However, there still remain many questions regarding the accuracy of the computed Bayesian posteriors (Wenzel et al., 2020), specially so when approximate inference is used (Foong et al., 2019). The investigation of model uncertainty and calibration within the medical domain is also gaining attention, partly due to the rise of deep learning in healthcare (Dusenberry et al., 2020;Stevens and Poppe, 2020;Goldstein et al., 2021). Dusenberry et al. (2020) examined neural network methods to capture model uncertainty in the context of electronic health records (EHR), and acknowledged that there is still plenty of work to do on devising methods that reduce model uncertainty at both training and prediction time. In the work we present here, not only the healthcare context is different (mHealth data, instead of EHR), but our predictive task distinct (regression versus classification).\n\nMenstrual Prediction from mHealth Data. Period tracking apps are some of the most popular smartphone apps (Wartella et al., 2016), and prediction of next period date is one of the most required feature from these app users (Epstein et al., 2017). Recent research has shown that while machine learning methods show promise, predicting cycle length is a challenging task (Pierson et al., 2018;Li et al., 2021), sometimes at the expense of a successful user-app interaction (Fox and Epstein, 2020).\n\nFirst, menstruation is a complex process with inherent variation and uncertainty within and across individuals (Treloar et al., 1967;Chiazze et al., 1968;Ferrell et al., 2005;Vitzthum, 2009;Harlow et al., 2012). The analysis of massive data from menstrual tracking apps confirmed that there are indeed wide variations in cycle length across menstruators, as well as within longitudinal cycle lengths of the same individual (Symul et al., 2018;Li et al., 2020;Soumpasis et al., 2020). Second, self-tracking data also comprises uncertainty, as the tracking behavior of app users is varied across individuals and in time (Urteaga et al., 2020;Li et al., 2021).\n\nIn this work, starting from a state-of-the-art model for cycle length prediction by Li et al. (2021), we leverage flexible generative modeling to capture the intrinsic uncertainty of both the underlying physiological menstrual process and self-tracking data, and explore the value of calibrated predictions.\n\n\nMethods\n\nWe hereby propose a hierarchical, Generalized Poisson-based generative model 2 for cycle lengths self-tracked via mHealth that (i) accounts for when individuals may forget to selftrack their period, (ii) pulls population-level information and learns individualized cycle length patterns and self-tracking propensities, and (iii) enables per-individual cycle length uncertainty quantification that results in well-calibrated predictive posteriors.\n\nIt is a generative, hierarchical model (see Figure 1 and the generative process description in Section 3.1), in that all per-individual parameters are drawn from the same population level distribution, which allows for the incorporation of global menstrual pattern knowledge (via informative priors) and pulling cycle information across individuals (to learn population-level hyperparameters). We take advantage of the Generalized Poisson distribution (Consul and Famoye, 2006) for its specific parameterization that enables us to capture the uncertainty of the observed cycle lengths (its posterior can be under-or over-dispersed) and provide calibrated predictions.\n\nThe Generalized Poisson is a distribution that belongs to the class of Lagrangian distributions over discrete, non-negative integers, with parameters \u03bb and \u03be that are independent (Consul, 1989;Consul and Famoye, 2006). The probability density function (pdf) of a Generalized Poisson, hereby denoted as GP (\u00b7) follows\nGP (x|\u03bb, \u03be) = \u03bb(\u03bb + \u03bex) x\u22121 e \u2212\u03bb\u2212\u03bex x! , \u03bb > 0 , x = 0, 1, \u00b7 \u00b7 \u00b7 , 0, for x > x max if \u03be < 0,(1)\nwhere limits on \u03bb and \u03be are imposed to ensure that there are at least five classes with nonzero probability (Consul, 1989). The first two moments 3 of a GP (x|\u03bb, \u03be) follow \u00b5 x = \u03bb (1\u2212\u03be) and \u03c3 2 x = \u03bb (1\u2212\u03be) 3 , where we observe how the two independent parameters provide two degrees of freedom to fit the mean and the variance, separately. The Generalized Poisson can be over-or under-dispersed, depending on the value of \u03be (when \u03be = 0, we recover the Poisson distribution). For \u03be < 0, the Generalized Poisson is under-dispersed (in comparison to a Poisson distribution) and it can be truncated to a maximum value x max of x, requiring an additional normalizing factor Z GP(\u03bb,\u03be,xmax) , see details in Section A.1 of the Appendix.\n\n\nThe hierarchical, generative process for observed cycle lengths\n\nThe proposed model, depicted in Figure 1, is a generative process with the following random (observed and unobserved) variables and parameters:\n\n\u2022 The observed variables are the cycle lengths x i,c i , with c i = {1, \u00b7 \u00b7 \u00b7 , C i } cycle lengths for each individual i = {1, \u00b7 \u00b7 \u00b7 , I}. We denote with s i,c i the (latent) number of skipped (notreported) cycles, with c i = {1, \u00b7 \u00b7 \u00b7 , C i } cycle lengths for each individual i = {1, \u00b7 \u00b7 \u00b7 , I}. \u2022 \u03bb i and \u03be i denote the Generalized Poisson parameters for each individual i = {1, \u00b7 \u00b7 \u00b7 , I}; \u03c0 i are the per-individual i = {1, \u00b7 \u00b7 \u00b7 , I} probability parameters of skipping a cycle. \u2022 \u03ba, \u03b3 are the population-level hyperparameters of a Gamma distribution prior over the \u03bb i ; \u03b1 \u03be , \u03b2 \u03be the hyperparameters of a Beta distribution prior over the \u03be i ; and \u03b1, \u03b2 the hyperparameters of a Beta distribution prior over the skipping probabilities \u03c0 i .\n\nWe now summarize the generative process of the proposed probabilistic model. First, one draws individual cycle length and self-tracking probability parameters from the population level distributions: i.e., each individual's \u03bb i \u223c p(\u03bb|\u03ba, \u03b3) = G (\u03bb|\u03ba, \u03b3) and \u03be i \u223c max{\u22121, \u2212\u03bb i xmax } + (1 \u2212 max{\u22121, \u2212\u03bb i xmax })B (\u03be|\u03b1 \u03be , \u03b2 \u03be ) parameters, and the the probability of each individual forgetting to track a period \u03c0 i \u223c p(\u03c0|\u03b1, \u03b2) = B (\u03c0|\u03b1, \u03b2) (all distributional details are provided in Section A.2 of the Appendix). Given per-individual parameters \u03bb i , \u03be i , \u03c0 i , then the number of cycles a user forgets to track is drawn from a Truncated Geometric distribution with parameter \u03c0 i , i.e., s i,c i \u223c p(s|\u03c0 i ) = \u03c0 s i (1\u2212\u03c0 i ) smax s=0 \u03c0 s i (1\u2212\u03c0 i ) . Finally, the observed cycle length for each user i is drawn from a Generalized Poisson distribution, conditioned on the number of skipped cycles, i.e., x i,c i \u223c p(x|\u03bb i , \u03be i , s i,c i ) = GP (x|(s i,c 1 + 1)\u03bb i , \u03be i ).\n\n3. Other moments of interest can be computed in closed form, see (Consul and Famoye, 2006) for a full characterization of this distribution.\n\n\nThe proposed model's distributions of interest\n\nThere are two distributions that are critical for the purpose of this study: (i) the joint, over all individuals' marginalized data (log)-likelihood, and (ii) each individual's cycle length predictive posterior. As explained in the introduction, a Bayesian view of predictive modeling requires the derivation of the predictive distribution via marginalization of all the inherent (parametric) model uncertainties:\np(Y |x) = \u03b8 p(Y |x, \u03b8)p(\u03b8|D)d\u03b8 .(2)\nHere, we aim at marginalizing all the parameters of the model, based on the prior distribution assumptions described in Section 3.1. In our proposed model, the latent parameters \u03b8 contain both the unobserved per-cycle skips s i,c i and the per-individual parameters \u03bb i , \u03be i and\n\u03c0 i , i.e., \u03b8 = {s i,c i , \u03bb i , \u03be i , \u03c0 i }.\nSimilarly, and to reduce clutter, we denote with \u0398 all the hyperparameters of our model: \u0398 = {\u03ba, \u03b3, \u03b1 \u03be , \u03b2 \u03be , \u03b1, \u03b2}. We clarify our notation here, where we denote a set of cycle length observations for a given individual i with X i = (x i,1 , \u00b7 \u00b7 \u00b7 , x i,C i ) \u2208 R C i , and the set of cycle length observations for all individuals i = {1, \u00b7 \u00b7 \u00b7 , I} in the population are denoted with X = X 1 , \u00b7 \u00b7 \u00b7 , X I \u2208 R I\u00d7C I , where C I = max C i , \u2200i. Similarly, the set of latent skipped cycle variables for a given individual i is denoted with S i = (s i,1 , \u00b7 \u00b7 \u00b7 , s i,C i ) \u2208 R C i , and the set of all latent skipped cycle variables for all individuals i = {1, \u00b7 \u00b7 \u00b7 , I} in the population are denoted with\nS = S 1 , \u00b7 \u00b7 \u00b7 , S I \u2208 R I\u00d7C I , where C I = max C i , \u2200i.\n\nMarginalized joint data likelihood\n\nThe population level data likelihood, with marginalized parameters, can not be derived in closed form. Instead, we resort to a hybrid approach, where we analytically marginalize per-individual skipped cycles s i,c i and use Monte Carlo to marginalize the per-individual parameters \u03bb i , \u03be i and \u03c0 i . The resulting marginalized joint data likelihood follows\np(X|\u0398) = I i=1 C i c i =1 p(x i,c i |\u0398) \u2248 I i=1 1 M M m=0 p(X i |\u03bb (m) i , \u03be (m) i , \u03c0 (m) i ) ,(3)\nwhere the per-user joint likelihood is marginalized over the skipped cycles s i,c i , i.e.,\np(X i |\u03bb (m) i , \u03be (m) i , \u03c0 (m) i ) = C i c i =1 smax s i,c i =0 p(x i,c i |s i,c i , \u03bb (m) i , \u03be (m) i )p(s i,c i |\u03c0 (m) i ) ,(4)\nand evaluated with Monte Carlo parameters \u03bb\n(m) i \u223c p(\u03bb|\u03ba, \u03b3), \u03be (m) i \u223c p(\u03be|\u03bb (m)\ni , \u03b1 \u03be , \u03b2 \u03be ), and \u03c0 (m) i \u223c p(\u03c0|\u03b1, \u03b2) drawn from their respective prior/posterior distributions (corresponding Equations (11), (12), and (13) are provided in Section A.2 of the Appendix).\n\nThe joint data likelihood is key for our training procedure, and determines the computational complexity of the fitting procedure. Given a dataset of C i cycle lengths for i = {1, \u00b7 \u00b7 \u00b7 , I} users, we perform hyperparameter inference via type-II maximum likelihood estimation; that is, we find the hyperparameters \u0398 that maximize the data log-likelihood as provided in Equation (3), i.e., \u0398 = argmax \u0398 [ln(p(X|\u0398))].\n\nAfter the training procedure, the hyperparameters \u0398 = {\u03ba, \u03b3, \u03b1 \u03be , \u03b2 \u03be , \u03b1, \u03b2} used for drawing the Monte Carlo parameters in Equation (3) will be replaced with the learned population level hyperparameters \u0398.\n\nWe note that the hierarchical nature of the proposed model enables distributed learning, with not only computational, but also privacy benefits: mHealth users do not need to share their data (they can locally compute their individualized predictions), and only need to share per-user data log-likelihood estimates for population-level hyperparameter inference (see Section A.6 of the Appendix for a more detailed discussion).\n\n\nCycle length predictive posterior\n\nWe derive the marginalized predictive posterior of the next cycle length x i,cnew after observing per-user cycle lengths X i ,\np(x i,cnew |X i , \u0398) = \u03bb i \u03be i \u03c0 i p(x i,cnew |\u03bb i , \u03be i , \u03c0 i )p(X i |\u03bb i , \u03be i , \u03c0 i )p(\u03bb i , \u03be i , \u03c0 i |\u0398)d\u03bb i d\u03be i d\u03c0 i \u03bb i \u03be i \u03c0 i p(X i |\u03bb i , \u03be i , \u03c0 i )p(\u03bb i , \u03be i , \u03c0 i |\u0398)d\u03bb i d\u03be i d\u03c0 i ,(5)\nfor which we need to compute p(X i |\u03bb i , \u03be i , \u03c0 i ) as in Equation (4). We again marginalize per-individual skipped cycles s i,cnew in\np(x i,cnew |\u03bb i , \u03be i , \u03c0 i ) = smax s i,cnew =0 p(x i,cnew |s i,cnew , \u03bb i , \u03be i )p(s i,cnew |\u03c0 i ) .(6)\nOne can readily compute the above via Monte Carlo, by drawing from the parameter posterior p(\u03bb i , \u03be i , \u03c0 i |X i , \u0398) as described in Equation (17) in Section A.3 of the Appendix, or via Importance Sampling by drawing from the prior p(\u03bb i , \u03be i , \u03c0 i |\u0398) and weighting samples with p(X i |\u03bb i , \u03be i , \u03c0 i ) as in Equation (4). After the training procedure, the hyperparameters \u0398 above will be replaced with the learned population level hyperparameters \u0398.\n\nIn addition, we note that the above cycle length predictive posterior, as well as the skipping probability predictive posterior, can be updated as subsequent days of the next cycle pass by, which we have derived in Sections A.4 and A.5 of the Appendix, respectively.\n\n\nCohort\n\nReal-world Menstrual mHealth Dataset 4 . We leverage a de-identified self-tracked dataset from Clue by BioWink (Clue, 2021), comprised of 117, 014, 597 self-tracking events over 378, 694 users. Clue app users input overall personal information at sign-up, such as age and birth control type. The dataset contains information from 2015-2018 for users worldwide, covering countries within North and South America, Europe, Asia and Africa. In the entire dataset, the median number of tracked menstrual cycles is 11. Inclusion criteria into the cohort were: (1) users likely to have ovulatory cycles, that is aged 21-33 with natural cycle (i.e., no contraception); (2) users with at least 11 cycles tracked. The cohort resulted in 186, 106 menstruators. For the experiments described in this paper, we randomly select a subset of 50,000 users. The summary statistics of the overall and the selected cohort for the experiments are provided in Table 1. We observe minimal differences in cycle length and period length statistics between the full cohort and the selected cohort. Data Extraction and Feature choices. Even though Clue's mHealth app users can self-track multiple symptoms over time, we focus on period data only, i.e., users' self-reports on which days they have their period. A period is defined as sequential days of bleeding (greater than spotting and within ten days after the first greater than spotting bleeding event) unbroken by no more than one day on which only spotting or no bleeding occurred. We use cycle lengths as input to our proposed model, where we define a menstrual cycle as the span of days from the first day of a period through to and including the day before the first day of the next period (Vitzthum, 2009). We discard any cycle a user has indicated to be excluded from their history -e.g., if the user felt that the cycle was not representative of their typical menstruation due to a medical procedure or changes in birth control.\n\nSynthetic Datasets 5 . To assess the ability of our model to recover ground truth (only possible with simulated data), we leverage two alternative generative processes. A Poisson generative model of cycle lengths, where the observed cycle lengths are drawn from the generative model by Li et al. (2021); i.e., cycle length data follows a Poisson distribution (see model and parameterization details in Appendix B.1). A Generalized Poisson generative model of cycle lengths, where the observed data are drawn from the generative model as proposed in Section 3; i.e., cycle length data is drawn from a Generalized Poisson distribution (full details are provided in Appendix B.2). For each of the simulated scenarios, we draw cycle length data for 50, 000 users, with C i = 11 cycles for each user.\n\n\nEvaluation\n\n\nEvaluation Approach: Real and Synthetic Study Designs\n\nOur objective is to accurately predict the next cycle length of a mHealth menstrual app user, based on their previously-tracked cycle lengths. To that end, we train the proposed generative model (as described in Section 3) and several baselines (described in Section 5.1.1) on the cycle length information from each of the datasets described in Section 4. We train on the first 10 cycle lengths of each user (C i = 10, \u2200i) and, given the hyperparameters \u0398 learned via the training procedure, we predict the next cycle length (i.e., each user's 11th cycle) via the predictive posterior in Section 3.2.2. Consequently, the train-test split is within, and not across, individuals: we train personalized models with each individual's first 10 cycles, and evaluate our individualized predictions with respect to each user's next cycle length.\n\n5. The synthetic dataset can be generated with the Python codebase publicly available in https://github.com/iurteaga/menstrual cycle analysis.\n\nWe average our results (and provide standard deviations) over k = 5 realizations to aggregate over the inherent uncertainties of the training and testing procedure: e.g., robustness to random number generator seeds, Monte Carlo sampling and the optimization procedure.\n\nWe note that the learned predictive posterior p(x i,cnew = x|X i , \u0398) provides per-user fully probabilistic predictions, i.e., it computes the probability of the next cycle length x i,cnew being of length x \u2208 N for each user i. Therefore, we are enabled to provide both point estimate predictions (e.g., the mean or mode of the predictive distribution), as well as to evaluate how well-calibrated the predicted cycle length posterior is.\n\n\nBaselines\n\nWe compare the performance of our model to the following baselines 6 :\n\n\u2022 CNN: a 2-layer convolutional neural network with a 3-dimensional kernel.\n\n\u2022 RNN: a 2-layer bidirectional recurrent neural network with a 3-dimensional hidden state.\n\n\u2022 LSTM: a 2-layer Long Short-Term Memory neural network with a 3-dimensional hidden state. \u2022 Poisson model: the Poisson-based predictive model proposed by Li et al. (2021).\n\n\nPrediction Metrics\n\nWe use several accuracy metrics for the evaluation of next cycle length point estimates x i,cnew with respect to true cycle lengths x i,cnew for all I users in the cohort. The root-\nmean squared error, RMSE = I i=1 (xi,c new \u2212 x i,cnew ) 2 I ; the median squared error, MedianSE = Median x i,cnew \u2212 x i,cnew\n2 (which is less sensitive to outliers than the RMSE); the mean\nabsolute error, MAE = I i=1 |xi,c new \u2212 x i,cnew | I\n; and the median absolute error, MedianAE = Median x i,cnew \u2212 x i,cnew .\n\n\nCalibration Metrics\n\nWe leverage a diverse set of calibration metrics and scoring rules, both visual and numeric, to evaluate the uncertainty quantification of the generative models' predictive posteriors. On one hand, we consider the following, most often visually presented, calibration metrics: The probability integral transform (PIT), defined as the value that the cumulative density function (CDF) of a predictive model F (\u00b7) attains at the observation, i.e.,\np i = F (x i ), where x i \u223c g(\u00b7)\nis drawn from the true (yet unknown) generating mechanism, with CDF G(\u00b7). For continuous true G(\u00b7) and predictive F (\u00b7), p i has a uniform distribution if the predictions are ideal, i.e., if F (\u00b7) = G(\u00b7). PITs are most often reported as a histogram over the set of observed instances x i , \u2200i; and for the ideal case, the histogram of the PIT values is (asymptotically) uniform. The uniformity of the PIT is a necessary, but not sufficient, condition for the predictive distribution to be ideal -  provides a detailed explanation of PIT's limitations. Visual assessment of PIT histograms 6. Similar to what is reported in Li et al. (2021), we don't observe any significant performance difference with other architectures that incorporate higher kernel or hidden state dimensionalities.\n\nprovides insights into the calibration deficiencies of a predictive posterior: hump-shaped histograms indicate over-dispersion (i.e., prediction intervals are too wide), while U-shaped histograms correspond to under-dispersion (i.e., too narrow predictive distributions). Note that triangle-shaped histograms indicate biased predictive distributions. Since its proposal by Rosenblatt (1952), many authors have extended and studied PIT's advantages and disadvantages -see Section 3 in . The marginal calibration plot (MCP), defined as the difference between the predictive CDF F (\u00b7) and the empirical CDF of the observed data\u011c(\u00b7) , i.e.,\nF (x i ) \u2212\u011c(x i ), \u2200x i .\nThe most straightforward approach is to visualize the above difference over all observed instances, towards assessing the marginal calibration of the predictive distribution. The marginal calibration is concerned with the closeness between the predictive outcomes (i.e., predictive distribution) and the actual, observed outcomes (i.e., the data).\n\nThe interested reader can find in  a rigorous study of how, under mild regularity conditions, marginal calibration is a necessary and sufficient condition for the asymptotic equality between the average predictive CDF and the empirical CDF of the observations. Visually, one expects minor fluctuations under the hypothesis of marginal calibration (i.e., the MCP is almost flat), while major excursions from the origin indicate a lack of marginal calibration.\n\nOn the other hand, to quantify with a single numerical score how closely a model's predictive distribution matches each user's observed cycle lengths, we consider several scoring rules. The selected scores presented below form a comprehensive set of summary measures of predictive performance, as they address calibration and sharpness simultaneously . We note that all these are proper scoring rules 7 in general, and strictly proper 8 under quite general conditions -a detailed, theoretically grounded review of the above and other scoring rules is provided in . We define them here for predictive distributions on the natural line x \u2208 N, but they are scoring rules that can readily accommodate continuous variables.\n\nThe quadratic or Brier score, defined as BrierS(p,\nx i ) = \u2212 xmax x=1 (\u03b4(x \u2212 x i ) \u2212 p(x)) 2 . The pseudo-spherical score, defined as PseudoS(p, x i ) = p(x i ) \u03b1\u22121 ||p|| \u03b1\u22121 \u03b1\n, which reduces to the more common Spherical score when \u03b1 = 2, used in our results. The logarithmic score, defined as the log-likelihood of the observation x i under the predicted posterior p(\u00b7): LogS(p, x i ) = log p(x i ), which relates directly to the negative Shannon entropy and the commonly used log-likelihood metric. Interestingly, this score emerges as a limiting case of the pseudospherical score with \u03b1 \u2192 1 when it is suitably scaled. The continuous ranked probability score (CRPS), defined in terms of the CDF F (\u00b7) of the predictive posterior, i.e., CRPS(F,\nx i ) = \u2212 \u221e \u2212\u221e (F (x) \u2212 1 [x i ]) 2 dx\n, and corresponds to the integral of the Brier scores for the associated binary probability forecasts at all realvalued thresholds -note that when dealing with integers in the natural line, the thresholds are countable, resulting in a sum over a finite number of bins. The motivation for the CRPS is to overcome several limitations regarding other metrics on continuous variables. If Lebesgue 7. S(P, P ) \u2265 S(P, Q), \u2200P, Q \u2208 P. 8. S(P, P ) = S(P, Q), if and only if P = Q. densities on the real line are used to predict discrete observations, then the logarithmic score encourages the placement of artificially high density ordinates on the target values, and no credit is given for assigning high probabilities to values near but not identical to the one materializing. As such, defining scoring rules in terms of predictive CDFs (instead of probability density functions) has bee argued for by .\n\n\nValidation on the synthetic cycle length dataset\n\nWe first showcase the added flexibility of our proposed method by leveraging the synthetic datasets described in Section 4. Our synthetic data results (presented in Section B) demonstrate that the proposed model provides better uncertainty quantification capabilities than the alternative proposed by Li et al. (2021), both in terms of predictive accuracy and calibration metrics. Specifically, when the cycle length data is Poisson distributed, both models can accurately fit the data and provide well-calibrated predictions: all scoring rules are identical for both models, see Section B.1.\n\nOn the contrary, when the observed cycle length data is drawn from a Generalized Poisson that is under-dispersed, we observe that the Proposed model clearly outperforms the Poisson model both in terms of predictive accuracy and calibration metrics. Specifically, we note (see Figures in Section B.2) that the PIT of the Poisson model is hump-shaped, i.e., it is clearly over-dispersed, while the Proposed model's PIT histogram is close to a uniform distribution. In addition, the MCP plot for the Proposed model hardly deviates from the origin, while the Poisson model showcases a calibration mismatch around x cnew = 20. Overall, these results validate that a Generalized Poisson based model is able to more flexibly adjust to the uncertainty of observed cycle lengths and provide well-calibrated predictions.\n\n\nResults on the real-world mHealth dataset\n\nWe now present results for all the considered models (generative and neural network based, as described in Section 5.1.1) in the real-world cycle length dataset presented in Section 4. We provide in Table 2 point estimate results for all the models at the next day of the last observed cycle length (i.e., day 0 of the next cycle), as per the metrics in Section 5.1.2.\n\nFirst, we conclude that in our use case, black-box neural network architectures do not provide any prediction accuracy advantage, which aligns with results presented by Li et al. (2021). Results showcasing the calibration shortcomings of the studied neural network architectures are presented in Appendix B.3. Second, we notice that our model's predictive accuracy is as good as the Poisson-based alternative of Li et al. (2021) when the mode of each model's predictive posterior is used as the predicted cycle length point estimate.\n\nThird, as both the Poisson model and our Proposed model provide a full predictive posterior density over the set of natural integers x i,cnew \u2208 N, we compare their performance when considering the mean and the mode of the predictive posterior as point estimates. We observe a slightly better performance of our Proposed model, both in cohort-level average results as well as in their variability, specially so for the metrics most robust to outliers (i.e., MedianSE, MAE and MedianAE). This performance difference suggests that the mean and the mode do not coincide in each model's predictive distributions, which we hypothesize is explained by the dispersion of such densities, i.e., the shape and width of their posterior densities around the mode. 6.820 (\u00b1 0.062) 5.606 (\u00b1 0.783) 3.846 (\u00b1 0.071) 2.362 (\u00b1 0.166) Poisson model (mode) 6.856 (\u00b1 0.023) 4.000 (\u00b1 0.000) 3.451 (\u00b1 0.006) 2.000 (\u00b1 0.000) Proposed model (mode) 6.790 (\u00b1 0.007) 4.000 (\u00b1 0.000) 3.459 (\u00b1 0.003) 2.000 (\u00b1 0.000) Poisson model (mean) 6.690 (\u00b1 0.002) 4.818 (\u00b1 0.292) 3.639 (\u00b1 0.042) 2.194 (\u00b1 0.066) Proposed model (mean) 6.691 (\u00b1 0.005) 4.237 (\u00b1 0.064) 3.592 (\u00b1 0.009) 2.058 (\u00b1 0.015) To elucidate the added flexibility of the Proposed model to capture cycle length uncertainty, we first visualize in Figure 2 the scatter plot of per-user true cycle length average (x-axis) versus each model's per-user expected cycle length (y-axis). Each dot in Figure 2 represents a user, colored by the cycle length variability of each user: i.e., lighter color for users with low cycle length variability, darker color for users with high cycle length variability.  We observe that the Poisson model struggles to find the right mean-variance balance: note how skewed the scatter plot in Figure 2(a)subfigure is, with most of the users (irrespective of their variability) situated below and to the right side of the x = y line.\n\nWe hypothesize that this skewness is due to the rigid parameterization of a Poisson distribution: there is only one degree of freedom (i.e., \u03bb i ) that determines both the mean and the variance of each user's cycle lengths. On the contrary, the two-parameter Generalized Poisson can adjust, via \u03bb i and \u03be i , both the mean and the variance of per-user cycle lengths. As shown in Figure 2(b)subfigure, this ability to quantify the data uncertainty allows the Proposed model to fit the data better (R 2 = 0.873) than the Poisson model (R 2 = 0.803).\n\nWe now turn our attention to the full posterior predictive distribution of each of the models, to investigate their uncertainty quantification capabilities.\n\nIn Figure 3, we illustrate the cycle length predictive posterior of each generative model for a randomly selected user, as days of the subsequent cycle proceed (the form of this per-day cycle length posterior is described in Section A.4 of the Appendix). Note how the Proposed model consistently provides less uncertain (i.e., under-dispersed) predictions.     We showcase in Table 3 that the under-dispersed predictive posterior of the Proposed model occurs for all users in the dataset, by providing the average posterior predictive width at level \u03b1. The values provided in the table indicate the width (in days) of the (1-\u03b1) centered probability mass, i.e., the width of the posterior predictive distribution between quantiles \u03b1/2 and 1 \u2212 \u03b1/2, as illustrated in Figure 4, for the Proposed model's posterior of Figure 3 with \u03b1 = 0.5 at day 0. Note that the posterior predictive width in Table 3 for the 20% posterior mass of our Proposed model is less that 2 days, while it's almost 3 for the Poisson model. Besides, the 50% posterior mass width of the Poisson model is almost 8 days (i.e., the next period is predicted to occur within an interval longer than a week), raising the question on how useful such prediction is for mHealth users.\n\nIn order to settle our claim that the Generalized Poisson based model provides better calibrated predictions, we provide in Table 4 the average results for all the considered scoring rules described in Section 5.1.3, along with PIT and MCP plots in Figure 5: note how over-dispersed (hump-shaped) the Poisson model is in Figure 5(a)subfigure, and how, in Figure 5(b)subfigure, we observe a lack of posterior sharpness for the Poisson model. The calibration shortcomings of neural network based models are showcased in Appendix B.3.  As demonstrated across the variety of considered metrics, we can conclude that the Proposed model provides better calibrated results. However, as shown in Figure 5, the Proposed model is still not ideal: it does not result in a fully uniform PIT and its MCP slightly fluctuates away from 0 around the median cycle length (29 days) of the cohort.  To conclude, we emphasize that the Proposed model provides under-dispersed (i.e., less uncertain) and better calibrated cycle length predictions than the state-of-theart alternative of Li et al. (2021), both as demonstrated at the user and population level. In addition, we showcase in Figure 6 how the under-dispersed predictive posterior of our Proposed model provides additional (across population and point estimate-based) predictive benefits: the predictive accuracy of the Proposed model is better than that of the Poisson model as days of the next cycle proceed. This is especially evident about a week before the median cycle length of the studied cohort. In other words, the Proposed model outperforms other models' predictive accuracy 6 to 8 days before the next cycle length starts.\n\n\nDiscussion\n\nWe proposed a flexible generative model that provides accurate, well-calibrated predictions of menstrual cycle lengths based on self-tracked mobile health data. Specifically, we investigated how to overcome certain limitations of a Poisson regression-based cycle length model by making use of a more flexible distribution, namely the Generalized Poisson. Our proposed model allows for accurate uncertainty quantification: it provides two degrees of freedom to fit the mean and variance of the observed cycle lengths. The model's \u03be parameter allows for controlling the dispersion of its predictive posterior, which enables better calibrated predictive posteriors, as demonstrated by our results.\n\nDue to the well-calibrated predictions, the model not only yields improved predictive accuracy as the cycle days proceed (see Figure 6), but provides more meaningful (i.e., less uncertain) cycle length predictions (see Figure 3).\n\nWe argue that more certain cycle length predictions, like the ones provided by our proposed model, may benefit mHealth users: they help increase trust in the model and may mitigate user notification fatigue, a well-known phenomenon where users ignore prediction notifications if they occur too often and with low sensitivity.\n\nMore broadly, we argue that uncertainty quantification and calibration are critical in the domain of health and healthcare. One must account for the variability of the studied physiology, and adjust to the uncertainties of the data collection and reporting process. To that end, we have presented a diverse tool-set of calibration metrics that are of use in assessing the predictions of our proposed model, and argue that they should be readily incorporated into the practice of machine learning in healthcare.\n\nWe acknowledge several limitations of our work: (i) while we argue that less uncertain cycle length predictions may reduce mHealth user notification fatigue, we leave to future work to validate such a hypothesis; and (ii) our model includes features of the menstrual cycle only related to its length. While it is a minimal feature that we know will be present across many app users, there might be additional features like signs and symptoms of the menstrual cycle that may improve our predictive model.\n\nOverall, our work showcases that generative models can accommodate the idiosyncrasies of mHealth data to provide well-calibrated, accurate predictions. Less uncertain cycle length predictions are beneficial for menstrual health researchers, mHealth users and developers. \n\n\nAppendix A. Methods\n\n\nA.1. The Generalized Poisson\n\nThe Generalized Poisson is a distribution that belongs to the class of Lagrangian distributions over discrete, non-negative integers, with parameters \u03bb and \u03be that are independent (Consul, 1989;Consul and Famoye, 2006). The probability density function (pdf) of a Generalized Poisson, hereby denoted as GP (\u00b7), follows\nGP (x|\u03bb, \u03be) = \u03bb(\u03bb + \u03bex) x\u22121 e \u2212\u03bb\u2212\u03bex x! , \u03bb > 0 , x = 0, 1, \u00b7 \u00b7 \u00b7 , 0, for x > x max if \u03be < 0,(7)\nwhere limits on \u03bb and \u03be are imposed to ensure that there are at least five classes with nonzero probability (Consul, 1989). The first two moments of a GP (x|\u03bb, \u03be) follow\n\u00b5 x = \u03bb (1 \u2212 \u03be) ,(8a)\u03c3 2 x = \u03bb (1 \u2212 \u03be) 3 ,(8b)\nand other moments of interest can be computed in closed form, see (Consul and Famoye, 2006) for a full characterization of this distribution. The Generalized Poisson can be over-or under-dispersed, depending on the value of \u03be: when \u03be = 0, we recover the Poisson distribution. Specifically, for \u03be < 0, the Generalized Poisson is under-dispersed (in comparison to a Poisson distribution) and it can be truncated to a maximum value x max of x, requiring an additional normalizing factor Z GP(\u03bb,\u03be,xmax) :\nx \u223c GP (x|\u03bb, \u03be) = \uf8f1 \uf8f2 \uf8f3 \u03bb(\u03bb+\u03bex) x\u22121 e \u2212\u03bb\u2212\u03bex x! Z GP(\u03bb,\u03be,xmax) , x = 0, 1, \u00b7 \u00b7 \u00b7 , 0, for x > x max if \u03be < 0,(9)\nwith\nZ GP(\u03bb,\u03be,xmax) = xmax x=0 \u03bb(\u03bb + \u03bex) x\u22121 e \u2212\u03bb\u2212\u03bex x! .(10)\nA.2. The hierarchical, generative process for observed cycle lengths\n\nThe proposed model, depicted in Figure 1, is a generative process with the following random (observed and unobserved) variables and parameters:\n\n\u2022 The observed variables are the cycle lengths x i,c i , with c i = {1, \u00b7 \u00b7 \u00b7 , C i } cycle lengths for each individual i = {1, \u00b7 \u00b7 \u00b7 , I}. \u2022 We denote with s i,c i the (latent) number of skipped (not-reported) cycles, with c i = {1, \u00b7 \u00b7 \u00b7 , C i } cycle lengths for each individual i = {1, \u00b7 \u00b7 \u00b7 , I}. \u2022 \u03bb i and \u03be i denote the Generalized Poisson parameters for each individual i = {1, \u00b7 \u00b7 \u00b7 , I}.\n\n\u2022 \u03c0 i are the parameters defining the per-individual i = {1, \u00b7 \u00b7 \u00b7 , I} probability of skipping a cycle. \u2022 \u03ba, \u03b3 are the population-level hyperparameters of a Gamma distribution prior over the \u03bb i . \u2022 \u03b1 \u03be , \u03b2 \u03be are the population-level hyperparameters of a Beta distribution prior over the \u03be i . \u2022 \u03b1, \u03b2 are the population-level hyperparameters of a Beta distribution prior over the skipping probabilities \u03c0 i .\n\nWe now describe in detail the generative process of the proposed probabilistic model. First, one draws individual cycle length and self-tracking probability parameters from the population level distributions:\n\n1. The parameter \u03bb i of each individual's Generalized Poisson is drawn from a populationlevel Gamma distribution with hyperparameters \u03ba and \u03b3\n\u03bb i \u223c p(\u03bb|\u03ba, \u03b3) = G (\u03bb|\u03ba, \u03b3) = \u03b3 \u03ba \u0393(\u03ba) \u03bb \u03ba\u22121 e \u2212\u03b3\u03bb ,\nfor \u03bb > 0 and \u03ba, \u03b3 > 0.\n\n2. The parameter \u03be i of each individual's Generalized Poisson is drawn, conditioned on each \u03bb i , from a shifted and scaled population-level Beta distribution with hyperparameters \u03b1 \u03be and \u03b2 \u03be , so that \u03be i \u2208 max{\u22121, \u2212\u03bb i xmax }, 1 :\n\u03be i \u223c max \u22121, \u2212\u03bb i x max + 1 \u2212 max \u22121, \u2212\u03bb i x max B (\u03be|\u03b1 \u03be , \u03b2 \u03be ) , for \u03be \u2208 [0, 1] ,(12)\nwhere B (\u03be|\u03b1 \u03be , \u03b2 \u03be ) = \u0393(\u03b1 \u03be + \u03b2 \u03be ) \u0393(\u03b1 \u03be )\u0393(\u03b2 \u03be ) \u03be \u03b1 \u03be \u22121 (1 \u2212 \u03be) \u03b2 \u03be \u22121 , for \u03be \u2208 [0, 1] and \u03b1 \u03be , \u03b2 \u03be > 0.\n\n3. The probability \u03c0 i of each individual forgetting to track a period is drawn from a population-level Beta distribution with hyperparameters \u03b1 and \u03b2, \u03c0 i \u223c p(\u03c0|\u03b1, \u03b2) = B (\u03c0|\u03b1, \u03b2) = \u0393(\u03b1 + \u03b2) \u0393(\u03b1)\u0393(\u03b2) \u03c0 \u03b1\u22121 (1 \u2212 \u03c0) \u03b2\u22121 , for \u03c0 \u2208 [0, 1] and \u03b1, \u03b2 > 0.\n\nGiven per-individual parameters \u03bb i , \u03be i , \u03c0 i , then:\n\n4. The number of cycles a user forgets to track s i,c i is drawn from a Truncated Geometric distribution with parameter \u03c0 i , i.e.,\ns i,c i \u223c p(s|\u03c0 i ) = \u03c0 s i (1 \u2212 \u03c0 i ) smax s=0 \u03c0 s i (1 \u2212 \u03c0 i ) = \u03c0 s i smax s=0 \u03c0 s i = \u03c0 s i (1 \u2212 \u03c0 i ) (1 \u2212 \u03c0 (smax+1) i ) , for s \u2208 N(14)\n5. Each true (unobserved) cycle length x is drawn from a Generalized Poisson distribution parameterized with per-individual \u03bb i and \u03be i , i.e.,\nx \u223c p(x|\u03bb i , \u03be i ) = GP (x|\u03bb i , \u03be i ) = \u03bb i (\u03bb i + \u03be i x) x\u22121 e \u2212\u03bb i \u2212\u03be i x x! , x = 0, 1, \u00b7 \u00b7 \u00b7 , 0, for x > x max if \u03be i < 0.(15)\n6. Finally, the observed cycle length x i,c i for user i is drawn from a Generalized Poisson distribution, conditioned on the number of skipped cycles s i,c i , i.e.,\nx i,c i \u223c p(x|s i,c i , \u03bb i , \u03be i ) = s i,c i s=0 p(x|s, \u03bb i , \u03be i ) = GP (x|(s i,c 1 + 1)\u03bb i , \u03be i ) .(16)\nNote that this distribution results from the property of Generalized Poissons that the sum of two independent Generalized Poisson variables X \u223c GP (\u03bb 1 , \u03be) and Y \u223c GP (\u03bb 2 , \u03be) follows another Generalized Poisson: X + Y \u223c GP (\u03bb 1 + \u03bb 2 , \u03be), (Consul and Famoye, 2006).\n\n\nA.3. The model's posterior parameter distributions\n\nIn a similar approach to the joint data likelihood, we can analytically marginalize the skipped cycles and compute a MC approximation to each parameter posterior, as described below:\np(\u03bb i , \u03be i , \u03c0 i |X i , \u0398) = p(X i , \u03bb i , \u03be i , \u03c0 i |\u0398) p(X i |\u0398) = p(X i , \u03bb i , \u03be i , \u03c0 i |\u0398) \u03bb i \u03be i \u03c0 i p(X i , \u03bb i , \u03be i , \u03c0 i |\u0398)d\u03bb i d\u03be i d\u03c0 i (17a) = p(X i |\u03bb i , \u03be i , \u03c0 i )p(\u03bb i , \u03be i , \u03c0 i |\u0398) \u03bb i \u03be i \u03c0 i p(X i |\u03bb i , \u03be i , \u03c0 i )p(\u03bb i , \u03be i , \u03c0 i |\u0398)d\u03bb i d\u03be i d\u03c0 i (17b) = p(X i |\u03bb i , \u03be i , \u03c0 i )p(\u03bb i |\u03ba, \u03b3)p(\u03be i |\u03bb i , \u03b1 \u03be , \u03b2 \u03be )p(\u03c0 i |\u03b1, \u03b2) \u03bb i \u03be i \u03c0 i p(X i |\u03bb i , \u03be i , \u03c0 i )p(\u03bb i |\u03ba, \u03b3)p(\u03be i |\u03bb i , \u03b1 \u03be , \u03b2 \u03be )p(\u03c0 i |\u03b1, \u03b2)d\u03bb i d\u03be i d\u03c0 i (17c) \u2248 M \u03bb m \u03bb =1 M \u03be m \u03be =1 M\u03c0 m\u03c0=1 p(X i |\u03bb (m \u03bb ) i , \u03be (m \u03be ) i , \u03c0 (m\u03c0) i ) M \u03bb m \u03bb =1 M \u03be m \u03be =1 M\u03c0 m\u03c0=1 p(X i |\u03bb (m \u03bb ) i , \u03be (m \u03be ) i , \u03c0 (m\u03c0) i ) ,(17d)\nwith p(X i |\u03bb\n(m \u03bb ) i , \u03be (m \u03be ) i , \u03c0 (m\u03c0) i ) = C i c i =1 p(x i,c i |\u03bb (m) i , \u03be (m) i , \u03c0 (m) i ) (17e) = C i c i =1 smax s i,c i =0 p(x i,c i |s i,c i , \u03bb (m) i , \u03be (m) i )p(s i,c i |\u03c0 (m) i ) ,(17f)\nand\n\uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 \u03bb (m \u03bb ) i \u223c p(\u03bb i |\u03ba, \u03b3) , m \u03bb = 1, \u00b7 \u00b7 \u00b7 , M \u03bb , \u03be (m \u03be ) i \u223c p(\u03be i |\u03bb (m \u03bb ) i \u03b1 \u03be , \u03b2 \u03be ) , m \u03be = 1, \u00b7 \u00b7 \u00b7 , M \u03c0 , \u03c0 (m\u03c0) i \u223c p(\u03c0 i |\u03b1 \u03c0 , \u03b2 \u03c0 ) , m \u03c0 = 1, \u00b7 \u00b7 \u00b7 , M \u03c0 .(17g)\nA.4. The model's predictive cycle length posterior by day\n\nOur model allows for updating next cycle length predictions as each day of the next cycle passes. To that end, we compute the cycle length predictive posterior conditioned on x, the day of the cycle the user is currently on:\np(x i,cnew |x i,cnew > x, X i , \u0398) = p(x i,cnew , x i,cnew > x|X i , \u0398) p(x i,cnew > x|X i , \u0398) (18a) = p(x i,cnew |X i , \u0398)I(x i,cnew > x) p(x i,cnew > x|X i , \u0398) (18b) since p(x i,cnew , x i,cnew > x|X i , \u0398) = 0 if x i,cnew \u2264 x.\nNote that the key term above is p(x i,cnew |X i , \u0398), which follows the expression in (5).\n\nA.5. The model's predictive skipping probability posterior by day\n\nOur model allows for updating per individual next cycle's skipping probability predictions as each day of the next cycle passes. To that end, we compute the predictive posterior of skipping probabilities conditioned on x, the day of the cycle the user is currently on:\np(s i,cnew |x i,cnew > x, X i , \u0398) = p(s i,cnew , x i,cnew > x|X i , \u0398) p(x i,cnew > x|X i , \u0398) (19a) = p(x i,cnew > x|s i,cnew , X i , \u0398)p(s i,cnew |X i , \u0398) s i,cnew p(x i,cnew > x|s i,cnew , X i , \u0398)p(s i,cnew |X i , \u0398) (19b) = \u03bb i \u03be i \u03c0 i p(x i,cnew > x|s i,cnew , \u03bb i , \u03be i )p(s i,cnew |\u03c0 i )p(\u03bb i , \u03be i , \u03c0 i |X i , \u0398)d\u03bb i d\u03be i d\u03c0 i \u03bb i \u03be i \u03c0 i s i,cnew p(x i,cnew > x|s i,cnew , \u03bb i , \u03be i )p(s i,cnew |\u03c0 i )p(\u03bb i , \u03be i , \u03c0 i |X i , \u0398)d\u03bb i d\u03be i d\u03c0 i (19c) = \u03bb i \u03be i \u03c0 i \u221e x p(x i,cnew = x|s i,cnew , \u03bb i , \u03be i )p(s i,cnew |\u03c0 i )p(\u03bb i , \u03be i , \u03c0 i |X i , \u0398)d\u03bb i d\u03be i d\u03c0 i \u03bb i \u03be i \u03c0 i s i,cnew \u221e x p(x i,cnew = x|s i,cnew , \u03bb i , \u03be i )p(s i,cnew |\u03c0 i )p(\u03bb i , \u03be i , \u03c0 i |X i , \u0398)d\u03bb i d\u03be i d\u03c0 i (19d) where p(s i,cnew |\u03c0 i ) = \u03c0 s i,cnew i (1\u2212\u03c0 i ) s \u03c0 s i (1\u2212\u03c0 i )\nand p(\u03bb i , \u03be i , \u03c0 i |X i , \u0398) is the parameter posterior after observing per-individual data X i . We can compute the above via Monte Carlo -by drawing from the parameter posterior p(\u03bb i , \u03be i , \u03c0 i |X i , \u0398) as in Equation (17)-or via Importance Sampling -by drawing from the prior p(\u03bb i , \u03be i , \u03c0 i |\u0398) and weighting them with p(X i |\u03bb i , \u03be i , \u03c0 i ) as in Equation (4).\n\nA.6. The model's computational complexity and distributed training\n\nThe complexity of the training procedure of the proposed Generalized Poisson-based model is determined by the type-II maximum likelihood estimation of model hyperparameters. Specifically, it requires (i) the computation of the marginalized joint data likelihood in Equation (3), and (ii) finding the hyperparameters \u0398 that maximize Equation (3).\n\nTo that end, we leverage Monte Carlo integration and automatic differentiation. The fitting procedure is implemented and executed using stochastic gradient descent methods (as provided by most modern software packages). This same procedure is used for fitting the Poisson and Generalized Poisson-based alternatives.\n\nFor the underdispersed Generalized Poisson model (when \u03be < 0), one must numerically compute the normalizing constant in Equation (10), which adds computational complexity. As a result, the per-epoch computational cost depends on the number of Monte Carlo samples used (M ) in Equation (3), the accuracy on marginalizing out the skipped cycle probability (s max ) in Equation (4), and the computation of the per-user and parameter normalizing constant in Equation (10), dependent on the maximum cycle length (x max ).\n\nWe note that the hierarchical nature of the proposed model provides distributed learning opportunities: mHealth users do not need to share their data (they can locally compute their individualized predictions), and only need to share per-user data log-likelihood estimates for population-level hyperparameter inference.\n\nWhen finding population-level hyperparameters, each user must only share its marginalized data likelihood in Equation (4), averaged over local parameter Monte Carlo samples, for which each user only needs access to the population-level hyperparameters \u0398.\n\nThis training process can be executed in a distributed and iterative fashion, separating (on-device) per-user computations from global (centralized) hyperparameter searches, with not only computational, but privacy benefits too.\n\n\nAppendix B. Results\n\nWe showcase the added flexibility of our proposed method, by leveraging the datasets described in Section 4 and detailed here.\n\nOur goal is to demonstrate that the proposed model provides, both in synthetic and real datasets, better uncertainty quantification capabilities than the alternative proposed in Li et al. (2021) and other neural network based baselines.\n\n\nB.1. Poisson generative model of cycle lengths\n\nData generating process. The observed cycle lengths are drawn from the generative model as in (Li et al., 2021), where cycle length data is assumed to obey a Poisson distribution. The specific hyperparameters used are \u0398 = {\u03ba = 180, \u03b3 = 6, \u03b1 = 2, \u03b2 = 20}, resulting in parameter priors and per-individual sample draws as illustrated in Figure 7. Predictive accuracy and calibration. Figures 8 and 9 demonstrate how our Proposed model is equivalent to the alternative Poisson model, when the data generating mechanism is indeed Poisson. The PIT of both models is almost uniform, and the MCP plots hardly deviate from the origin. Besides, note how the interval width for both models is identical in Table 6. This behavior demonstrates that, when the cycle length data is indeed Poisson, both models can accurately fit the data and provide well-calibrated predictions -all scoring rules in Table 5 are identical for both models.   Data generating process. The observed cycle lengths are drawn from the generative model as proposed in Section 3, where cycle length data is drawn from a Generalized Poisson distribution. The specific hyperparameters used for our simulation are \u0398 = {\u03ba = 160, \u03b3 = 4, \u03b1 \u03be = 2, \u03b2 \u03be = 20, \u03b1 = 2, \u03b2 = 20}, resulting in parameter priors and per-individual sample draws as illustrated in Figure 10. Predictive accuracy and calibration. Figures 11 and 12 demonstrate the limitations of the Poisson model when the data generating mechanism is not Poisson distributed: the generated cycle length data in these experiments is drawn from a Generalized Poisson that is under-dispersed (see specific hyperparameters above).\n\nWe observe that the Proposed model clearly outperforms the Poisson model both in terms of predictive accuracy (reduced MAE and RMSE in Figure 11) and calibration metrics ( Figure 12 and Table 7). In Figure 12, note how the PIT of the Poisson model is hump-shaped, i.e., it is clearly over-dispersed, while the Proposed model's PIT histogram is close to a uniform distribution. In addition, the MCP plot for the Proposed model hardly deviates from the origin, while the Poisson model showcases a calibration mismatch around x cnew = 20.\n\nOverall, these results validate our claim that a Generalized Poisson based model is able to more flexibly adjust to the uncertainty of observed cycle lengths and provide well-calibrated predictions-all scoring rule results in Table 5 are better for the Proposed model, and their posterior predictive interval width much smaller, see Table 8.   Interval Width for (1 \u2212 \u03b1) posterior mass.\n\n\nModel\n\n(1 \u2212 \u03b1) = 0.2 (1 \u2212 \u03b1) = 0.5 (1 \u2212 \u03b1) = 0.8 Poisson model 2.761 (\u00b1 0.010) 7.558 (\u00b1 0.034) 17.569 (\u00b1 0.157) Proposed model 1.511 (\u00b1 0.005) 4.141 (\u00b1 0.019) 12.379 (\u00b1 0.199)\n\n\nB.3. Real-world Menstrual mHealth Data\n\nWe present predictive results for the models as described in Section 5.1.1 in the real-world cycle length dataset presented in Section 4.\n\nPredictive accuracy and calibration. Since we have provided evidence in the main manuscript (see Table 2) on the point estimate accuracy of the neural network based alternatives, we hereby focus on their calibration limitations.   Table 9 and Figure 13 show very poor calibration performance of all the neural network based approaches, in alignment with the existing literature on the calibration limitations of these techniques in other applications as well (Guo et al., 2017;Nixon et al., 2019). Note that these results are computed based on the deterministic outputs of these models, i.e., the outputs of the CNN, LSTM and RNN models are point estimates, hence the extreme-valued PIT results in Figure 13(a)subfigure.\n\n\nResults in\n\nWe acknowledge that this behavior could be avoided with Bayesian or ensemble-based neural network models that provide probabilistic outputs. However, implementing those alternative models was out of the scope of this work, and we reiterate that there is a growing literature on the calibration shortcomings of these approaches (Wenzel et al., 2020), specially so when approximate inference is used (Foong et al., 2019).\n\nAs demonstrated across the variety of considered metrics, we conclude that the Proposed model provides better calibrated results.\n\nComputational complexity. As explained in Section A.6, the complexity of the training procedure of the proposed Generalized Poisson-based model is determined by the type-II maximum likelihood estimation of model hyperparameters.\n\nWe provide in Table 10 details on the number of training epochs (and their corresponding execution times) as executed in an HP Enterprise XL170r E5-2650v4 CPU with 128 GB of RAM memory.\n\nWe observe that all models reach convergence within a few number of training epochs (average of 11 epochs for the proposed model). The execution-time overhead incurred by the proposed model results from the aforementioned computation of the normalizing constant in Equation (10). Based on our vectorized implementation, we did not find significant accuracy/execution-time benefits beyond M = 500, s max = 10, and x max = 1000 in the presented real-data experiments.\n\nImproving or boosting the implementation of the proposed model, both via optimized numerical computation of the normalizing constant and its parallelized/distributed training, was out of the scope of this work. \n\nFigure 1 :\n1Probabilistic graphical model of the hierarchical Generalized Poisson model with a latent skipped cycle s variable to accommodate self-tracking artifacts.\n\nFigure 2 :\n2Real-world dataset: Fitting sufficient statistics of observed cycle length data, colored by user cycle length variability. The colorbar indicates the standard deviation of observed per-user cycle lengths.\n\nFigure 3 :\n3Real-world dataset: Predictive posteriors for a random user at different days of the next cycle.\n\n3 :\n3Real-world dataset: Posterior predictive width at day 0 of next cycle. Posterior predictive interval width at level \u03b1.\n\nFigure 4 .\n4Posterior predictive width at day 0.\n\nFigure 5 :\n5Real-world dataset: Calibration plots for a realization of each generative model.\n\nFigure 6 .\n6Real-world dataset: Prediction accuracy at different days of the next cycle.\n\nFigure 7 :\n7Synthetic Poisson: Ground truth parameter priors and per-individual drawn samples.\n\nFigure 8 :Figure 9 :\n89Synthetic Poisson: Prediction accuracy of the generative models at different days of the next cycle. Synthetic Poisson: Calibration plots for a realization of each model.\n\n\nover \u03bb i (b) Prior over \u03be i (c) Prior over \u03c0 i Figure 10: Synthetic Generalized Poisson: Ground truth parameter priors and perindividual drawn samples.\n\nFigure 11 :\n11Synthetic Generalized Poisson: Prediction accuracy of the generative models at different days of the next cycle.\n\nFigure 12 :\n12Synthetic Generalized Poisson: Calibration plots for a realization of each model.\n\nFigure 13 :\n13Real-world dataset: Calibration plots for a realization of each model.\n\nTable 1 :\n1Summary statistics for the overall cohort and the 50, 000 random user subset. Note that race/ethnicity information is not available from this de-identified dataset.Summary statistic \nFull cohort \nSelected cohort \nTotal number of users \n186,106 \n50,000 \nTotal number of cycles \n2,047,166 \n550,000 \nCycle length in days: mean\u00b1sd (median) 30.7\u00b17.9 (29) \n30.6\u00b17.7 (29) \nPeriod length in days: mean\u00b1sd (median) \n4.1\u00b11.8 (4) \n4.1\u00b11.8 (4) \nAge in years: mean\u00b1sd (median) \n25.6\u00b13.6 (25) \n25.6\u00b13.6 (25) \n\n\n\nTable 2 :\n2Real-world dataset: Point estimate results for all modelsModel \nRMSE \nMedianSE \nMAE \nMedianAE \nCNN \n7.243 (\u00b1 0.000) 11.089 (\u00b1 0.341) 4.379 (\u00b1 0.016) 3.330 (\u00b1 0.051) \nLSTM \n6.730 (\u00b1 0.017) 4.303 (\u00b1 0.515) 3.626 (\u00b1 0.082) 2.071 (\u00b1 0.123) \nRNN \n\n\nTable\n\n\nTable 4 :\n4Real-world dataset: Calibration results for the generative models, higher is better.Model \nBrier score \nSpherical score Logarithmic score \nCRPS \nPoisson model -0.931 (\u00b1 0.000) \n0.266 (\u00b1 0.000) \n-3.022 (\u00b1 0.001) \n-2.922 (\u00b1 0.003) \nProposed model -0.910 (\u00b1 0.000) \n0.299 (\u00b1 0.000) \n-2.855 (\u00b1 0.002) \n-2.740 (\u00b1 0.001) \n\n\n\nEllen Ann Wartella, Vicky Rideout, Heather Montague, Leanne Beaudoin-Ryan, and Alexis Re Lauricella. Teens, health and technology: A national survey.Media and Communica-\ntion, 4(3):13-23, 1 2016. \n\nFlorian Wenzel, Kevin Roth, Bastiaan S Veeling, Jakub Swiatkowski, Linh Tran, Stephan \nMandt, Jasper Snoek, Tim Salimans, Rodolphe Jenatton, and Sebastian Nowozin. \nHow good is the bayes posterior in deep neural networks really? \narXiv preprint \narXiv:2002.02405, 2020. \n\nAndrew Gordon Wilson. \nThe case for Bayesian deep learning. \narXiv preprint \narXiv:2001.10995, 2020. \n\nJiayu Yao, Weiwei Pan, Soumya Ghosh, and Finale Doshi-Velez. Quality of uncertainty \nquantification for Bayesian neural network inference. arXiv preprint arXiv:1906.09686, \n2019. \n\n\nTable 5 :\n5Synthetic Poisson: Calibration results for the generative models, higher is betterModel \nBrier score \nSpherical score Logarithmic score \nCRPS \nPoisson model -0.958 (\u00b1 0.000) \n0.204 (\u00b1 0.000) \n-3.482 (\u00b1 0.000) \n-5.381 (\u00b1 0.000) \nProposed model -0.958 (\u00b1 0.000) \n0.204 (\u00b1 0.000) \n-3.482 (\u00b1 0.000) \n-5.382 (\u00b1 0.001) \n\n\nTable 6 :\n6Posterior predictive width at day 0 of next cycle. Interval Width for (1 \u2212 \u03b1) posterior mass. Poisson model 3.208 (\u00b1 0.006) 8.757 (\u00b1 0.027) 21.060 (\u00b1 0.167) Proposed model 3.211 (\u00b1 0.010) 8.786 (\u00b1 0.030) 21.182 (\u00b1 0.392) B.2. Generalized Poisson generative model of cycle lengthsModel \n(1 \u2212 \u03b1) = 0.2 \n(1 \u2212 \u03b1) = 0.5 \n(1 \u2212 \u03b1) = 0.8 \n\n\nTable 7 :\n7Synthetic Generalized Poisson: Calibration results for the generative models, higher is betterModel \nBrier score \nSpherical score Logarithmic score \nCRPS \nPoisson model -0.930 (\u00b1 0.000) \n0.269 (\u00b1 0.000) \n-2.835 (\u00b1 0.001) \n-3.553 (\u00b1 0.003) \nProposed model -0.912 (\u00b1 0.000) \n0.295 (\u00b1 0.000) \n-2.785 (\u00b1 0.001) \n-3.385 (\u00b1 0.002) \n\n\n\nTable 8 :\n8Posterior predictive width at day 0 of next cycle.\n\nTable 9 :\n9Real-world dataset: Calibration results for the studied models, higher is betterModel \nBrier score \nSpherical score Logarithmic score \nCRPS \nCNN \n-1.816 (\u00b1 0.000) \n0.092 (\u00b1 0.000) \nN/A \n-4.274 (\u00b1 0.000) \nLSTM \n-1.790 (\u00b1 0.036) \n0.105 (\u00b1 0.018) \nN/A \n-3.867 (\u00b1 0.168) \nRNN \n-1.786 (\u00b1 0.028) \n0.107 (\u00b1 0.014) \nN/A \n-3.914 (\u00b1 0.179) \nPoisson model -0.931 (\u00b1 0.000) \n0.267 (\u00b1 0.000) \n-3.022 (\u00b1 0.000) \n-2.921 (\u00b1 0.001) \nProposed model -0.910 (\u00b1 0.000) \n0.298 (\u00b1 0.000) \n-2.854 (\u00b1 0.000) \n-2.740 (\u00b1 0.001) \n\n\nTable 10 :\n10Real-world dataset: Training procedure comparison for the studied models.Model \nNumber of epochs \nExecution time (s) \nCNN \n4.600 (\u00b1 0.800) \n6.642 (\u00b1 1.660) \nLSTM \n42.400 (\u00b1 13.094) \n295.732 (\u00b1 104.709) \nRNN \n25.400 (\u00b1 13.336) \n74.296 (\u00b1 35.354) \nPoisson model \n5.000 (\u00b1 0.632) \n393.072 (\u00b1 69.404) \nProposed model \n11.000 (\u00b1 1.265) \n36093.951 (\u00b1 3804.733) \n\n\u00a9 2021 I. Urteaga, K. Li, A. Shea, V.J. Vitzthum, C.H. Wiggins & N. Elhadad.\n. A Python implementation of the proposed model is available in the public GitHub repository https://github.com/iurteaga/menstrual cycle analysis.\n. Researchers interested in gaining access to the data can contact Clue by BioWink GmbH and establish a data use agreement with them.\nR Gillon. Medical ethics: four principles plus attention to scope.BMJ, 309(6948):184, 1994.   \nAcknowledgmentsThe authors are deeply grateful to all Clue users whose de-identified data have been used for this study. I\u00f1igo Urteaga and No\u00e9mie Elhadad are supported by NLM award R01 LM013043. Kathy Li is supported by NSF's Graduate Research Fellowship Program Award #1644869. We also acknowledge computing resources from Columbia University's Shared Research Computing Facility project, which is supported by NIH Research Facility Improvement Grant 1G20RR030893-01, and associated funds from the New York State Empire State Development, Division of Science Technology and Innovation (NYSTAR) Contract C090171, both awarded April 15, 2010.\nDiscrimination and calibration of clinical prediction models: users' guides to the medical literature. Ana Carolina Alba, Thomas Agoritsas, Michael Walsh, Steven Hanna, Alfonso Iorio, Thomas Devereaux, Gordon Mcginn, Guyatt, JAMA. 31814Ana Carolina Alba, Thomas Agoritsas, Michael Walsh, Steven Hanna, Alfonso Iorio, PJ De- vereaux, Thomas McGinn, and Gordon Guyatt. Discrimination and calibration of clinical prediction models: users' guides to the medical literature. JAMA, 318(14):1377-1384, 2017.\n\nCountdown regression: sharp and calibrated survival predictions. Anand Avati, Tony Duan, Sharon Zhou, Kenneth Jung, H Nigam, Andrew Y Shah, Ng, Uncertainty in Artificial Intelligence. PMLRAnand Avati, Tony Duan, Sharon Zhou, Kenneth Jung, Nigam H Shah, and Andrew Y Ng. Countdown regression: sharp and calibrated survival predictions. In Uncertainty in Artificial Intelligence, pages 145-155. PMLR, 2020.\n\nA calibration hierarchy for risk models was defined: from utopia to empirical data. Daan Ben Van Calster, Yvonne Nieboer, Vergouwe, Bavo De Cock, J Michael, Ewout W Pencina, Steyerberg, Journal of clinical epidemiology. 74Ben Van Calster, Daan Nieboer, Yvonne Vergouwe, Bavo De Cock, Michael J Pencina, and Ewout W Steyerberg. A calibration hierarchy for risk models was defined: from utopia to empirical data. Journal of clinical epidemiology, 74:167-176, 2016.\n\nProbabilistic machine learning for healthcare. I Chen, S Joshi, Marzyeh Ghassemi, Rajesh Ranganath, I. Chen, S. Joshi, Marzyeh Ghassemi, and Rajesh Ranganath. Probabilistic machine learning for healthcare. ArXiv, abs/2009.11087, 2020.\n\nThe Length and Variability of the Human Menstrual Cycle. Leonard Chiazze, Franklin T BrayerJr, John J Macisco, Margaret P Parker, Benefict J Duffy, The Journal of the American Medical Association. 20362021Clue. Clue by BioWink GmbHLeonard Chiazze, Franklin T. Brayer, Jr. John J. Macisco, Margaret P. Parker, and Benefict J. Duffy. The Length and Variability of the Human Menstrual Cycle. The Journal of the American Medical Association, 203(6):377-380, 1968. Clue. Clue by BioWink GmbH, Adalbertstra\u00dfe 7-8, 10999 Berlin, Germany. https://helloclue.com/, 2021.\n\nC Prem, Consul, Generalized Poisson distributions: properties and applications. M. Dekker. Prem C Consul. Generalized Poisson distributions: properties and applications. M. Dekker, 1989.\n\nGeneralized poisson distribution. Lagrangian Probability Distributions. C Prem, Felix Consul, Famoye, Prem C Consul and Felix Famoye. Generalized poisson distribution. Lagrangian Probability Distributions, pages 165-190, 2006.\n\nThe well-calibrated Bayesian. Philip Dawid, Journal of the American Statistical Association. 77379A Philip Dawid. The well-calibrated Bayesian. Journal of the American Statistical Associ- ation, 77(379):605-610, 1982.\n\nPresent position and potential developments: Some personal views statistical theory the prequential approach. Philip Dawid, Journal of the Royal Statistical Society: Series A (General). 1472A Philip Dawid. Present position and potential developments: Some personal views statis- tical theory the prequential approach. Journal of the Royal Statistical Society: Series A (General), 147(2):278-290, 1984.\n\nComparing predictive accuracy. X Francis, Robert S Diebold, Mariano, Journal of Business & economic statistics. 201Francis X Diebold and Robert S Mariano. Comparing predictive accuracy. Journal of Business & economic statistics, 20(1):134-144, 2002.\n\nAnalyzing the Role of Model Uncertainty for Electronic Health Records. Michael W Dusenberry, Dustin Tran, Edward Choi, Jonas Kemp, Jeremy Nixon, Ghassen Jerfel, Katherine Heller, Andrew M Dai, Proceedings of the ACM Conference on Health, Inference, and Learning, CHIL '20. the ACM Conference on Health, Inference, and Learning, CHIL '20New York, NY, USAMichael W. Dusenberry, Dustin Tran, Edward Choi, Jonas Kemp, Jeremy Nixon, Ghassen Jerfel, Katherine Heller, and Andrew M. Dai. Analyzing the Role of Model Uncertainty for Electronic Health Records. In Proceedings of the ACM Conference on Health, Inference, and Learning, CHIL '20, page 204-213, New York, NY, USA, 2020.\n\nExamining Menstrual Tracking to Inform the Design of Personal Informatics Tools. Nicole B Daniel A Epstein, Jennifer H Lee, Elena Kang, Jessica Agapie, Laura R Schroeder, James Pina, Julie A Fogarty, Sean A Kientz, Munson, Proceedings of the SIGCHI conference on human factors in computing systems. CHI Conference. the SIGCHI conference on human factors in computing systems. CHI ConferenceDaniel A Epstein, Nicole B Lee, Jennifer H Kang, Elena Agapie, Jessica Schroeder, Laura R Pina, James Fogarty, Julie A Kientz, and Sean A Munson. Examining Menstrual Tracking to Inform the Design of Personal Informatics Tools. Proceedings of the SIGCHI conference on human factors in computing systems. CHI Conference, 2017:6876-6888, May 2017.\n\nMonitoring reproductive aging in a 5-year prospective study: aggregate and individual changes in steroid hormones and menstrual cycle lengths with age. J Rebecca, Kathleen A Ferrell, German O&apos;connor, Tristan Rodriguez, Darryl J Gorrindo, Eleanor Holman, Rebecca C Brindle, Miller, Menopause. 12Rebecca J Ferrell, Kathleen A O'Connor, German Rodriguez, Tristan Gorrindo, Darryl J Holman, Eleanor Brindle, Rebecca C Miller, et al. Monitoring reproductive aging in a 5-year prospective study: aggregate and individual changes in steroid hormones and menstrual cycle lengths with age. Menopause, 12:567-757, 2005.\n\nOn the expressiveness of approximate inference in bayesian neural networks. Y K Andrew, David R Foong, Yingzhen Burt, Richard E Li, Turner, arXiv:1909.00719arXiv preprintAndrew YK Foong, David R Burt, Yingzhen Li, and Richard E Turner. On the ex- pressiveness of approximate inference in bayesian neural networks. arXiv preprint arXiv:1909.00719, 2019.\n\nMonitoring menses: Design-based investigations of menstrual tracking applications. The Palgrave Handbook of Critical Menstruation Studies. Sarah Fox, Daniel A Epstein, Sarah Fox and Daniel A Epstein. Monitoring menses: Design-based investigations of men- strual tracking applications. The Palgrave Handbook of Critical Menstruation Studies, pages 733-750, 2020.\n\nStrictly proper scoring rules, prediction, and estimation. Tilmann Gneiting, Adrian E Raftery, Journal of the American statistical Association. 102477Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American statistical Association, 102(477):359-378, 2007.\n\nProbabilistic forecasts, calibration and sharpness. Tilmann Gneiting, Fadoua Balabdaoui, Adrian E Raftery, Journal of the Royal Statistical Society: Series B (Statistical Methodology). 692Tilmann Gneiting, Fadoua Balabdaoui, and Adrian E Raftery. Probabilistic forecasts, calibration and sharpness. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 69(2):243-268, 2007.\n\nMark Goldstein, Xintian Han, Aahlad Puli, J Adler, Rajesh Perotte, . X-Cal Ranganath, arXiv:2101.05346Explicit Calibration for Survival Analysis. arXiv preprintMark Goldstein, Xintian Han, Aahlad Puli, Adler J Perotte, and Rajesh Ranganath. X- CAL: Explicit Calibration for Survival Analysis. arXiv preprint arXiv:2101.05346, 2021.\n\nDeep Learning. Ian Goodfellow, Yoshua Bengio, Aaron Courville, MIT PressIan Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http://www.deeplearningbook.org.\n\nOn calibration of modern neural networks. Chuan Guo, Geoff Pleiss, Yu Sun, Kilian Q Weinberger, International Conference on Machine Learning. PMLRChuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In International Conference on Machine Learning, pages 1321-1330. PMLR, 2017.\n\nVarieties of uncertainty in health care: a conceptual taxonomy. K J Paul, Han, M P William, Neeraj K Klein, Arora, Medical Decision Making. 316Paul KJ Han, William MP Klein, and Neeraj K Arora. Varieties of uncertainty in health care: a conceptual taxonomy. Medical Decision Making, 31(6):828-838, 2011.\n\nD Siob\u00e1n, Margery Harlow, Janet E Gass, Roger Hall, Pauline Lobo, Robert W Maki, Sherry Rebar, Patrick M Sherman, Sluss, Tobie J.de Villiers, and for the STRAW+10. Siob\u00e1n D. Harlow, Margery Gass, Janet E. Hall, Roger Lobo, Pauline Maki, Robert W. Rebar, Sherry Sherman, Patrick M. Sluss, Tobie J.de Villiers, and for the STRAW+10\n\nExecutive Summary of the Stages of Reproductive Aging Workshop + 10: Addressing the Unfinished Agenda of Staging Reproductive Aging. Collaborative Group, The Journal of Clinical Endocrinology & Metabolism. 974Collaborative Group. Executive Summary of the Stages of Reproductive Aging Workshop + 10: Addressing the Unfinished Agenda of Staging Reproductive Aging. The Journal of Clinical Endocrinology & Metabolism, 97(4):1159-1168, 04 2012.\n\nUncertainty quantification using Bayesian neural networks in classification: Application to biomedical image segmentation. Yongchan Kwon, Joong-Ho Won, Beom Joon Kim, Myunghee Cho Paik, Computational Statistics & Data Analysis. 142106816Yongchan Kwon, Joong-Ho Won, Beom Joon Kim, and Myunghee Cho Paik. Uncertainty quantification using Bayesian neural networks in classification: Application to biomedical image segmentation. Computational Statistics & Data Analysis, 142:106816, 2020.\n\nCharacterizing physiological and symptomatic variation in menstrual cycles using self-tracked mobile health data. Kathy Li, I\u00f1igo Urteaga, Chris H Wiggins, Anna Druet, Amanda Shea, Virginia J Vitzthum, No\u00e9mie Elhadad, Nature Digital Medicine. 3792020Kathy Li, I\u00f1igo Urteaga, Chris H. Wiggins, Anna Druet, Amanda Shea, Virginia J. Vitzthum, and No\u00e9mie Elhadad. Characterizing physiological and symptomatic varia- tion in menstrual cycles using self-tracked mobile health data. Nature Digital Medicine, 3(79), 2020.\n\nA generative, predictive model for menstrual cycle lengths that accounts for potential self-tracking artifacts in mobile health data. Kathy Li, I\u00f1igo Urteaga, Amanda Shea, J Virginia, Chris H Vitzthum, No\u00e9mie Wiggins, Elhadad, arXiv:2102.12439arXiv preprintPresented at the Machine Learning for Mobile Health Workshop at NeurIPSKathy Li, I\u00f1igo Urteaga, Amanda Shea, Virginia J Vitzthum, Chris H Wiggins, and No\u00e9mie Elhadad. A generative, predictive model for menstrual cycle lengths that accounts for potential self-tracking artifacts in mobile health data. arXiv preprint arXiv:2102.12439, 2021. Presented at the Machine Learning for Mobile Health Workshop at NeurIPS 2020.\n\nPredictive uncertainty estimation via prior networks. Andrey Malinin, Mark Gales, arXiv:1802.10501arXiv preprintAndrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. arXiv preprint arXiv:1802.10501, 2018.\n\nObtaining well calibrated probabilities using bayesian binning. Gregory Mahdi Pakdaman Naeini, Milos Cooper, Hauskrecht, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence29Mahdi Pakdaman Naeini, Gregory Cooper, and Milos Hauskrecht. Obtaining well calibrated probabilities using bayesian binning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 29, 2015.\n\nPredicting good probabilities with supervised learning. Alexandru Niculescu, - Mizil, Rich Caruana, Proceedings of the 22nd international conference on Machine learning. the 22nd international conference on Machine learningAlexandru Niculescu-Mizil and Rich Caruana. Predicting good probabilities with supervised learning. In Proceedings of the 22nd international conference on Machine learning, pages 625-632, 2005.\n\nMeasuring Calibration in Deep Learning. Jeremy Nixon, W Michael, Linchuan Dusenberry, Ghassen Zhang, Dustin Jerfel, Tran, CVPR Workshops. 2Rosemary Orchard. Apple's Cycle Tracking: A Personal ReviewJeremy Nixon, Michael W Dusenberry, Linchuan Zhang, Ghassen Jerfel, and Dustin Tran. Measuring Calibration in Deep Learning. In CVPR Workshops, volume 2, 2019. Rosemary Orchard. Apple's Cycle Tracking: A Personal Review.\n\nModeling Individual Cyclic Variation in Human Behavior. Emma Pierson, Tim Althoff, Jure Leskovec, Proceedings of the 2018 World Wide Web Conference, WWW '18. the 2018 World Wide Web Conference, WWW '18Republic and Canton of Geneva, SwitzerlandEmma Pierson, Tim Althoff, and Jure Leskovec. Modeling Individual Cyclic Variation in Human Behavior. In Proceedings of the 2018 World Wide Web Conference, WWW '18, pages 107-116, Republic and Canton of Geneva, Switzerland, 2018.\n\nScalable and accurate deep learning with electronic health records. Alvin Rajkomar, Kai Oren, Chen, M Andrew, Nissan Dai, Michaela Hajaj, Hardt, J Peter, Xiaobing Liu, Jake Liu, Mimi Marcus, Sun, NPJ Digital Medicine. 11Alvin Rajkomar, Eyal Oren, Kai Chen, Andrew M Dai, Nissan Hajaj, Michaela Hardt, Peter J Liu, Xiaobing Liu, Jake Marcus, Mimi Sun, et al. Scalable and accurate deep learning with electronic health records. NPJ Digital Medicine, 1(1):1-10, 2018.\n\nFragility, uncertainty, and healthcare. Theoretical medicine and bioethics. A Wendy, Mary J Rogers, Walker, 37Wendy A Rogers and Mary J Walker. Fragility, uncertainty, and healthcare. Theoretical medicine and bioethics, 37(1):71-83, 2016.\n\nRemarks on a multivariate transformation. The annals of mathematical statistics. Murray Rosenblatt, 23Murray Rosenblatt. Remarks on a multivariate transformation. The annals of mathematical statistics, 23(3):470-472, 1952.\n\nWhen should decision-analytic modeling be used in the economic evaluation of health care?. Uwe Siebert, Uwe Siebert. When should decision-analytic modeling be used in the economic evaluation of health care?, 2003.\n\nDistribution calibration for regression. Hao Song, Tom Diethe, Meelis Kull, Peter Flach, International Conference on Machine Learning. PMLRHao Song, Tom Diethe, Meelis Kull, and Peter Flach. Distribution calibration for regression. In International Conference on Machine Learning, pages 5897-5906. PMLR, 2019.\n\nReal-life insights on menstrual cycles and ovulation using big data. Ilias Soumpasis, Bola Grace, Sarah Johnson, Human Reproduction Open. 202022020Ilias Soumpasis, Bola Grace, and Sarah Johnson. Real-life insights on menstrual cycles and ovulation using big data. Human Reproduction Open, 2020(2), 04 2020.\n\nValidation of clinical prediction models: what does the \"calibration slope\" really measure. J Richard, Katrina K Stevens, Poppe, Journal of clinical epidemiology. 118Richard J Stevens and Katrina K Poppe. Validation of clinical prediction models: what does the \"calibration slope\" really measure? Journal of clinical epidemiology, 118:93-99, February 2020.\n\nAssessment of Menstrual Health Status and Evolution through Mobile Apps for Fertility Awareness. bioRxiv. Laura Symul, Katarzyna Wac, Paula Hillard, Marcel Salathe, Laura Symul, Katarzyna Wac, Paula Hillard, and Marcel Salathe. Assessment of Menstrual Health Status and Evolution through Mobile Apps for Fertility Awareness. bioRxiv, 2018.\n\nVariation of the human menstrual cycle through reproductive life. Alan E Treloar, Ruth E Boynton, G Borghild, Byron W Behn, Brown, International journal of fertility. 121Pt 2Alan E. Treloar, Ruth E. Boynton, Borghild G. Behn, and Byron W. Brown. Variation of the human menstrual cycle through reproductive life. International journal of fertility, 12(1 Pt 2):77-126, 1967.\n\nLearning endometriosis phenotypes from patient-generated data. I\u00f1igo Urteaga, Mollie Mckillop, No\u00e9mie Elhadad, npj Digital Medicine. 0632020I\u00f1igo Urteaga, Mollie McKillop, and No\u00e9mie Elhadad. Learning endometriosis phenotypes from patient-generated data. npj Digital Medicine, 3(88), 06 2020.\n\nCalibration of clinical prediction rules does not just assess bias. Werner Vach, Journal of clinical epidemiology. 6611Werner Vach. Calibration of clinical prediction rules does not just assess bias. Journal of clinical epidemiology, 66(11):1296-1301, 2013.\n\nThe ecology and evolutionary endocrinology of reproduction in the human female. Virginia J Vitzthum, American Journal of Physical Anthropology. 140S49Virginia J. Vitzthum. The ecology and evolutionary endocrinology of reproduction in the human female. American Journal of Physical Anthropology, 140(S49):95-136, 2009.\n", "annotations": {"author": "[{\"end\":207,\"start\":166},{\"end\":239,\"start\":208},{\"end\":276,\"start\":240},{\"end\":318,\"start\":277},{\"end\":362,\"start\":319},{\"end\":368,\"start\":363},{\"end\":376,\"start\":369},{\"end\":390,\"start\":377},{\"end\":403,\"start\":391},{\"end\":414,\"start\":404},{\"end\":604,\"start\":415},{\"end\":742,\"start\":605},{\"end\":857,\"start\":743},{\"end\":969,\"start\":858},{\"end\":1005,\"start\":970}]", "publisher": null, "author_last_name": "[{\"end\":179,\"start\":172},{\"end\":216,\"start\":214},{\"end\":251,\"start\":247},{\"end\":296,\"start\":288},{\"end\":334,\"start\":327},{\"end\":367,\"start\":365},{\"end\":375,\"start\":371},{\"end\":389,\"start\":381},{\"end\":402,\"start\":395}]", "author_first_name": "[{\"end\":171,\"start\":166},{\"end\":213,\"start\":208},{\"end\":246,\"start\":240},{\"end\":285,\"start\":277},{\"end\":287,\"start\":286},{\"end\":324,\"start\":319},{\"end\":326,\"start\":325},{\"end\":364,\"start\":363},{\"end\":370,\"start\":369},{\"end\":378,\"start\":377},{\"end\":380,\"start\":379},{\"end\":392,\"start\":391},{\"end\":394,\"start\":393},{\"end\":405,\"start\":404},{\"end\":413,\"start\":406}]", "author_affiliation": "[{\"end\":603,\"start\":416},{\"end\":741,\"start\":606},{\"end\":856,\"start\":744},{\"end\":968,\"start\":859},{\"end\":1004,\"start\":971}]", "title": "[{\"end\":153,\"start\":1},{\"end\":1158,\"start\":1006}]", "venue": "[{\"end\":1200,\"start\":1160}]", "abstract": "[{\"end\":3140,\"start\":1268}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3366,\"start\":3348},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3390,\"start\":3366},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3408,\"start\":3390},{\"end\":3512,\"start\":3498},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3526,\"start\":3512},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4620,\"start\":4607},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5475,\"start\":5463},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5518,\"start\":5491},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6002,\"start\":5989},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":6334,\"start\":6322},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6355,\"start\":6334},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6373,\"start\":6355},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":6397,\"start\":6373},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6420,\"start\":6397},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6520,\"start\":6497},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6619,\"start\":6601},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":6638,\"start\":6619},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6738,\"start\":6713},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6756,\"start\":6738},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7718,\"start\":7701},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8097,\"start\":8075},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8331,\"start\":8314},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8415,\"start\":8396},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9580,\"start\":9561},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11483,\"start\":11462},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11500,\"start\":11483},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":11524,\"start\":11500},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":11674,\"start\":11654},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12027,\"start\":12002},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12147,\"start\":12122},{\"end\":12164,\"start\":12147},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12374,\"start\":12356},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12393,\"start\":12374},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":12502,\"start\":12467},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12678,\"start\":12659},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12778,\"start\":12758},{\"end\":13075,\"start\":13054},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":13145,\"start\":13125},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13334,\"start\":13309},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":13358,\"start\":13334},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13381,\"start\":13358},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13407,\"start\":13383},{\"end\":13971,\"start\":13948},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":14087,\"start\":14065},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":14233,\"start\":14211},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14249,\"start\":14233},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":14336,\"start\":14313},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":14472,\"start\":14450},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":14493,\"start\":14472},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":14514,\"start\":14493},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":14529,\"start\":14514},{\"end\":14549,\"start\":14529},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":14782,\"start\":14762},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14798,\"start\":14782},{\"end\":14821,\"start\":14798},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14979,\"start\":14957},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14995,\"start\":14979},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":15098,\"start\":15082},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16242,\"start\":16217},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16627,\"start\":16613},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16651,\"start\":16627},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16970,\"start\":16956},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":19604,\"start\":19579},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":26378,\"start\":26363},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26908,\"start\":26892},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":29587,\"start\":29571},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":31248,\"start\":31232},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":31787,\"start\":31770},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":35642,\"start\":35626},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":37330,\"start\":37314},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":37573,\"start\":37557},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":42601,\"start\":42585},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":45998,\"start\":45984},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":46022,\"start\":45998},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":46341,\"start\":46328},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":46528,\"start\":46503},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":50410,\"start\":50385},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":56159,\"start\":56143},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":56363,\"start\":56346},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":59650,\"start\":59632},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":59669,\"start\":59650},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":60326,\"start\":60306}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":61723,\"start\":61556},{\"attributes\":{\"id\":\"fig_2\"},\"end\":61941,\"start\":61724},{\"attributes\":{\"id\":\"fig_4\"},\"end\":62051,\"start\":61942},{\"attributes\":{\"id\":\"fig_5\"},\"end\":62176,\"start\":62052},{\"attributes\":{\"id\":\"fig_6\"},\"end\":62226,\"start\":62177},{\"attributes\":{\"id\":\"fig_7\"},\"end\":62321,\"start\":62227},{\"attributes\":{\"id\":\"fig_9\"},\"end\":62411,\"start\":62322},{\"attributes\":{\"id\":\"fig_10\"},\"end\":62507,\"start\":62412},{\"attributes\":{\"id\":\"fig_11\"},\"end\":62702,\"start\":62508},{\"attributes\":{\"id\":\"fig_12\"},\"end\":62856,\"start\":62703},{\"attributes\":{\"id\":\"fig_13\"},\"end\":62984,\"start\":62857},{\"attributes\":{\"id\":\"fig_14\"},\"end\":63081,\"start\":62985},{\"attributes\":{\"id\":\"fig_15\"},\"end\":63167,\"start\":63082},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":63676,\"start\":63168},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":63931,\"start\":63677},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":63939,\"start\":63932},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":64268,\"start\":63940},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":65024,\"start\":64269},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":65351,\"start\":65025},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":65695,\"start\":65352},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":66035,\"start\":65696},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":66098,\"start\":66036},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":66613,\"start\":66099},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":66984,\"start\":66614}]", "paragraph": "[{\"end\":3648,\"start\":3156},{\"end\":4363,\"start\":3650},{\"end\":5082,\"start\":4365},{\"end\":5610,\"start\":5084},{\"end\":6228,\"start\":5612},{\"end\":6757,\"start\":6230},{\"end\":7436,\"start\":6759},{\"end\":8098,\"start\":7438},{\"end\":8967,\"start\":8100},{\"end\":9896,\"start\":9046},{\"end\":10343,\"start\":9913},{\"end\":11169,\"start\":10345},{\"end\":11956,\"start\":11171},{\"end\":12556,\"start\":11958},{\"end\":13840,\"start\":12558},{\"end\":14337,\"start\":13842},{\"end\":14996,\"start\":14339},{\"end\":15305,\"start\":14998},{\"end\":15763,\"start\":15317},{\"end\":16432,\"start\":15765},{\"end\":16750,\"start\":16434},{\"end\":17576,\"start\":16848},{\"end\":17787,\"start\":17644},{\"end\":18536,\"start\":17789},{\"end\":19512,\"start\":18538},{\"end\":19654,\"start\":19514},{\"end\":20118,\"start\":19705},{\"end\":20434,\"start\":20155},{\"end\":21189,\"start\":20481},{\"end\":21644,\"start\":21287},{\"end\":21836,\"start\":21745},{\"end\":22012,\"start\":21969},{\"end\":22242,\"start\":22052},{\"end\":22659,\"start\":22244},{\"end\":22869,\"start\":22661},{\"end\":23296,\"start\":22871},{\"end\":23460,\"start\":23334},{\"end\":23798,\"start\":23662},{\"end\":24360,\"start\":23905},{\"end\":24628,\"start\":24362},{\"end\":26604,\"start\":24639},{\"end\":27401,\"start\":26606},{\"end\":28309,\"start\":27472},{\"end\":28453,\"start\":28311},{\"end\":28723,\"start\":28455},{\"end\":29162,\"start\":28725},{\"end\":29246,\"start\":29176},{\"end\":29322,\"start\":29248},{\"end\":29414,\"start\":29324},{\"end\":29588,\"start\":29416},{\"end\":29792,\"start\":29611},{\"end\":29982,\"start\":29919},{\"end\":30108,\"start\":30036},{\"end\":30576,\"start\":30132},{\"end\":31395,\"start\":30610},{\"end\":32033,\"start\":31397},{\"end\":32407,\"start\":32060},{\"end\":32867,\"start\":32409},{\"end\":33587,\"start\":32869},{\"end\":33639,\"start\":33589},{\"end\":34336,\"start\":33766},{\"end\":35272,\"start\":34376},{\"end\":35917,\"start\":35325},{\"end\":36729,\"start\":35919},{\"end\":37143,\"start\":36775},{\"end\":37678,\"start\":37145},{\"end\":39566,\"start\":37680},{\"end\":40115,\"start\":39568},{\"end\":40273,\"start\":40117},{\"end\":41518,\"start\":40275},{\"end\":43193,\"start\":41520},{\"end\":43902,\"start\":43208},{\"end\":44133,\"start\":43904},{\"end\":44460,\"start\":44135},{\"end\":44972,\"start\":44462},{\"end\":45477,\"start\":44974},{\"end\":45750,\"start\":45479},{\"end\":46122,\"start\":45805},{\"end\":46389,\"start\":46220},{\"end\":46937,\"start\":46437},{\"end\":47054,\"start\":47050},{\"end\":47180,\"start\":47112},{\"end\":47325,\"start\":47182},{\"end\":47724,\"start\":47327},{\"end\":48135,\"start\":47726},{\"end\":48345,\"start\":48137},{\"end\":48488,\"start\":48347},{\"end\":48566,\"start\":48543},{\"end\":48800,\"start\":48568},{\"end\":49004,\"start\":48891},{\"end\":49255,\"start\":49006},{\"end\":49312,\"start\":49257},{\"end\":49445,\"start\":49314},{\"end\":49732,\"start\":49589},{\"end\":50033,\"start\":49867},{\"end\":50411,\"start\":50142},{\"end\":50648,\"start\":50466},{\"end\":51283,\"start\":51270},{\"end\":51479,\"start\":51476},{\"end\":51726,\"start\":51669},{\"end\":51952,\"start\":51728},{\"end\":52275,\"start\":52185},{\"end\":52342,\"start\":52277},{\"end\":52612,\"start\":52344},{\"end\":53756,\"start\":53381},{\"end\":53824,\"start\":53758},{\"end\":54171,\"start\":53826},{\"end\":54488,\"start\":54173},{\"end\":55006,\"start\":54490},{\"end\":55327,\"start\":55008},{\"end\":55583,\"start\":55329},{\"end\":55813,\"start\":55585},{\"end\":55963,\"start\":55837},{\"end\":56201,\"start\":55965},{\"end\":57888,\"start\":56252},{\"end\":58425,\"start\":57890},{\"end\":58813,\"start\":58427},{\"end\":58991,\"start\":58823},{\"end\":59171,\"start\":59034},{\"end\":59893,\"start\":59173},{\"end\":60327,\"start\":59908},{\"end\":60458,\"start\":60329},{\"end\":60688,\"start\":60460},{\"end\":60875,\"start\":60690},{\"end\":61342,\"start\":60877},{\"end\":61555,\"start\":61344}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":16847,\"start\":16751},{\"attributes\":{\"id\":\"formula_1\"},\"end\":20154,\"start\":20119},{\"attributes\":{\"id\":\"formula_2\"},\"end\":20480,\"start\":20435},{\"attributes\":{\"id\":\"formula_3\"},\"end\":21249,\"start\":21190},{\"attributes\":{\"id\":\"formula_4\"},\"end\":21744,\"start\":21645},{\"attributes\":{\"id\":\"formula_5\"},\"end\":21968,\"start\":21837},{\"attributes\":{\"id\":\"formula_6\"},\"end\":22051,\"start\":22013},{\"attributes\":{\"id\":\"formula_7\"},\"end\":23661,\"start\":23461},{\"attributes\":{\"id\":\"formula_8\"},\"end\":23904,\"start\":23799},{\"attributes\":{\"id\":\"formula_9\"},\"end\":29918,\"start\":29793},{\"attributes\":{\"id\":\"formula_10\"},\"end\":30035,\"start\":29983},{\"attributes\":{\"id\":\"formula_11\"},\"end\":30609,\"start\":30577},{\"attributes\":{\"id\":\"formula_12\"},\"end\":32059,\"start\":32034},{\"attributes\":{\"id\":\"formula_13\"},\"end\":33765,\"start\":33640},{\"attributes\":{\"id\":\"formula_14\"},\"end\":34375,\"start\":34337},{\"attributes\":{\"id\":\"formula_15\"},\"end\":46219,\"start\":46123},{\"attributes\":{\"id\":\"formula_16\"},\"end\":46411,\"start\":46390},{\"attributes\":{\"id\":\"formula_17\"},\"end\":46436,\"start\":46411},{\"attributes\":{\"id\":\"formula_18\"},\"end\":47049,\"start\":46938},{\"attributes\":{\"id\":\"formula_19\"},\"end\":47111,\"start\":47055},{\"attributes\":{\"id\":\"formula_20\"},\"end\":48542,\"start\":48489},{\"attributes\":{\"id\":\"formula_22\"},\"end\":48890,\"start\":48801},{\"attributes\":{\"id\":\"formula_24\"},\"end\":49588,\"start\":49446},{\"attributes\":{\"id\":\"formula_25\"},\"end\":49866,\"start\":49733},{\"attributes\":{\"id\":\"formula_26\"},\"end\":50141,\"start\":50034},{\"attributes\":{\"id\":\"formula_27\"},\"end\":51269,\"start\":50649},{\"attributes\":{\"id\":\"formula_28\"},\"end\":51475,\"start\":51284},{\"attributes\":{\"id\":\"formula_29\"},\"end\":51668,\"start\":51480},{\"attributes\":{\"id\":\"formula_30\"},\"end\":52184,\"start\":51953},{\"attributes\":{\"id\":\"formula_31\"},\"end\":53380,\"start\":52613}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":25584,\"start\":25577},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":36981,\"start\":36974},{\"end\":40658,\"start\":40651},{\"end\":41171,\"start\":41164},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":41651,\"start\":41644},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":56955,\"start\":56948},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":57145,\"start\":57138},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":58083,\"start\":58076},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":58660,\"start\":58653},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":58767,\"start\":58760},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":59277,\"start\":59270},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":59411,\"start\":59404},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":60712,\"start\":60704}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":3154,\"start\":3142},{\"end\":9044,\"start\":8970},{\"attributes\":{\"n\":\"2.\"},\"end\":9911,\"start\":9899},{\"attributes\":{\"n\":\"3.\"},\"end\":15315,\"start\":15308},{\"attributes\":{\"n\":\"3.1.\"},\"end\":17642,\"start\":17579},{\"attributes\":{\"n\":\"3.2.\"},\"end\":19703,\"start\":19657},{\"attributes\":{\"n\":\"3.2.1.\"},\"end\":21285,\"start\":21251},{\"attributes\":{\"n\":\"3.2.2.\"},\"end\":23332,\"start\":23299},{\"attributes\":{\"n\":\"4.\"},\"end\":24637,\"start\":24631},{\"attributes\":{\"n\":\"5.\"},\"end\":27414,\"start\":27404},{\"attributes\":{\"n\":\"5.1.\"},\"end\":27470,\"start\":27417},{\"attributes\":{\"n\":\"5.1.1.\"},\"end\":29174,\"start\":29165},{\"attributes\":{\"n\":\"5.1.2.\"},\"end\":29609,\"start\":29591},{\"attributes\":{\"n\":\"5.1.3.\"},\"end\":30130,\"start\":30111},{\"attributes\":{\"n\":\"5.2.\"},\"end\":35323,\"start\":35275},{\"attributes\":{\"n\":\"5.3.\"},\"end\":36773,\"start\":36732},{\"attributes\":{\"n\":\"6.\"},\"end\":43206,\"start\":43196},{\"end\":45772,\"start\":45753},{\"end\":45803,\"start\":45775},{\"end\":50464,\"start\":50414},{\"end\":55835,\"start\":55816},{\"end\":56250,\"start\":56204},{\"end\":58821,\"start\":58816},{\"end\":59032,\"start\":58994},{\"end\":59906,\"start\":59896},{\"end\":61567,\"start\":61557},{\"end\":61735,\"start\":61725},{\"end\":61953,\"start\":61943},{\"end\":62056,\"start\":62053},{\"end\":62188,\"start\":62178},{\"end\":62238,\"start\":62228},{\"end\":62333,\"start\":62323},{\"end\":62423,\"start\":62413},{\"end\":62529,\"start\":62509},{\"end\":62869,\"start\":62858},{\"end\":62997,\"start\":62986},{\"end\":63094,\"start\":63083},{\"end\":63178,\"start\":63169},{\"end\":63687,\"start\":63678},{\"end\":63938,\"start\":63933},{\"end\":63950,\"start\":63941},{\"end\":65035,\"start\":65026},{\"end\":65362,\"start\":65353},{\"end\":65706,\"start\":65697},{\"end\":66046,\"start\":66037},{\"end\":66109,\"start\":66100},{\"end\":66625,\"start\":66615}]", "table": "[{\"end\":63676,\"start\":63344},{\"end\":63931,\"start\":63746},{\"end\":64268,\"start\":64036},{\"end\":65024,\"start\":64420},{\"end\":65351,\"start\":65119},{\"end\":65695,\"start\":65643},{\"end\":66035,\"start\":65802},{\"end\":66613,\"start\":66191},{\"end\":66984,\"start\":66701}]", "figure_caption": "[{\"end\":61723,\"start\":61569},{\"end\":61941,\"start\":61737},{\"end\":62051,\"start\":61955},{\"end\":62176,\"start\":62058},{\"end\":62226,\"start\":62190},{\"end\":62321,\"start\":62240},{\"end\":62411,\"start\":62335},{\"end\":62507,\"start\":62425},{\"end\":62702,\"start\":62532},{\"end\":62856,\"start\":62705},{\"end\":62984,\"start\":62872},{\"end\":63081,\"start\":63000},{\"end\":63167,\"start\":63097},{\"end\":63344,\"start\":63180},{\"end\":63746,\"start\":63689},{\"end\":64036,\"start\":63952},{\"end\":64420,\"start\":64271},{\"end\":65119,\"start\":65037},{\"end\":65643,\"start\":65364},{\"end\":65802,\"start\":65708},{\"end\":66098,\"start\":66048},{\"end\":66191,\"start\":66111},{\"end\":66701,\"start\":66628}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15817,\"start\":15809},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":17684,\"start\":17676},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":38961,\"start\":38953},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":39107,\"start\":39099},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":39435,\"start\":39427},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":39955,\"start\":39947},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":40286,\"start\":40278},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":41048,\"start\":41040},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":41096,\"start\":41088},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":41777,\"start\":41769},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":41849,\"start\":41841},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":41883,\"start\":41875},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":42216,\"start\":42208},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":42694,\"start\":42686},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":44038,\"start\":44030},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":44131,\"start\":44123},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":47222,\"start\":47214},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":56595,\"start\":56587},{\"end\":56649,\"start\":56634},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":57569,\"start\":57560},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":57625,\"start\":57608},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":58034,\"start\":58025},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":58071,\"start\":58062},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":58098,\"start\":58089},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":59425,\"start\":59416},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":59880,\"start\":59871}]", "bib_author_first_name": "[{\"end\":68186,\"start\":68183},{\"end\":68195,\"start\":68187},{\"end\":68208,\"start\":68202},{\"end\":68227,\"start\":68220},{\"end\":68241,\"start\":68235},{\"end\":68256,\"start\":68249},{\"end\":68270,\"start\":68264},{\"end\":68288,\"start\":68282},{\"end\":68652,\"start\":68647},{\"end\":68664,\"start\":68660},{\"end\":68677,\"start\":68671},{\"end\":68691,\"start\":68684},{\"end\":68699,\"start\":68698},{\"end\":68715,\"start\":68707},{\"end\":69076,\"start\":69072},{\"end\":69100,\"start\":69094},{\"end\":69135,\"start\":69134},{\"end\":69152,\"start\":69145},{\"end\":69500,\"start\":69499},{\"end\":69508,\"start\":69507},{\"end\":69523,\"start\":69516},{\"end\":69540,\"start\":69534},{\"end\":69752,\"start\":69745},{\"end\":69770,\"start\":69762},{\"end\":69772,\"start\":69771},{\"end\":69787,\"start\":69783},{\"end\":69789,\"start\":69788},{\"end\":69807,\"start\":69799},{\"end\":69809,\"start\":69808},{\"end\":69826,\"start\":69818},{\"end\":69828,\"start\":69827},{\"end\":70251,\"start\":70250},{\"end\":70511,\"start\":70510},{\"end\":70523,\"start\":70518},{\"end\":71320,\"start\":71319},{\"end\":71338,\"start\":71330},{\"end\":71617,\"start\":71610},{\"end\":71619,\"start\":71618},{\"end\":71638,\"start\":71632},{\"end\":71651,\"start\":71645},{\"end\":71663,\"start\":71658},{\"end\":71676,\"start\":71670},{\"end\":71691,\"start\":71684},{\"end\":71709,\"start\":71700},{\"end\":71724,\"start\":71718},{\"end\":71726,\"start\":71725},{\"end\":72301,\"start\":72295},{\"end\":72303,\"start\":72302},{\"end\":72330,\"start\":72322},{\"end\":72332,\"start\":72331},{\"end\":72343,\"start\":72338},{\"end\":72357,\"start\":72350},{\"end\":72371,\"start\":72366},{\"end\":72373,\"start\":72372},{\"end\":72390,\"start\":72385},{\"end\":72402,\"start\":72397},{\"end\":72404,\"start\":72403},{\"end\":72418,\"start\":72414},{\"end\":72420,\"start\":72419},{\"end\":73103,\"start\":73102},{\"end\":73121,\"start\":73113},{\"end\":73123,\"start\":73122},{\"end\":73139,\"start\":73133},{\"end\":73162,\"start\":73155},{\"end\":73180,\"start\":73174},{\"end\":73182,\"start\":73181},{\"end\":73200,\"start\":73193},{\"end\":73216,\"start\":73209},{\"end\":73218,\"start\":73217},{\"end\":73643,\"start\":73642},{\"end\":73645,\"start\":73644},{\"end\":73659,\"start\":73654},{\"end\":73661,\"start\":73660},{\"end\":73677,\"start\":73669},{\"end\":73691,\"start\":73684},{\"end\":73693,\"start\":73692},{\"end\":74064,\"start\":74059},{\"end\":74349,\"start\":74342},{\"end\":74366,\"start\":74360},{\"end\":74368,\"start\":74367},{\"end\":74664,\"start\":74657},{\"end\":74681,\"start\":74675},{\"end\":74700,\"start\":74694},{\"end\":74702,\"start\":74701},{\"end\":75008,\"start\":75004},{\"end\":75027,\"start\":75020},{\"end\":75039,\"start\":75033},{\"end\":75047,\"start\":75046},{\"end\":75061,\"start\":75055},{\"end\":75078,\"start\":75071},{\"end\":75355,\"start\":75352},{\"end\":75374,\"start\":75368},{\"end\":75388,\"start\":75383},{\"end\":75574,\"start\":75569},{\"end\":75585,\"start\":75580},{\"end\":75596,\"start\":75594},{\"end\":75610,\"start\":75602},{\"end\":75917,\"start\":75916},{\"end\":75919,\"start\":75918},{\"end\":75932,\"start\":75931},{\"end\":75934,\"start\":75933},{\"end\":75952,\"start\":75944},{\"end\":76158,\"start\":76157},{\"end\":76174,\"start\":76167},{\"end\":76188,\"start\":76183},{\"end\":76190,\"start\":76189},{\"end\":76202,\"start\":76197},{\"end\":76216,\"start\":76209},{\"end\":76229,\"start\":76223},{\"end\":76231,\"start\":76230},{\"end\":76244,\"start\":76238},{\"end\":76259,\"start\":76252},{\"end\":76261,\"start\":76260},{\"end\":76634,\"start\":76621},{\"end\":77061,\"start\":77053},{\"end\":77076,\"start\":77068},{\"end\":77091,\"start\":77082},{\"end\":77109,\"start\":77097},{\"end\":77537,\"start\":77532},{\"end\":77547,\"start\":77542},{\"end\":77562,\"start\":77557},{\"end\":77564,\"start\":77563},{\"end\":77578,\"start\":77574},{\"end\":77592,\"start\":77586},{\"end\":77607,\"start\":77599},{\"end\":77609,\"start\":77608},{\"end\":77626,\"start\":77620},{\"end\":78072,\"start\":78067},{\"end\":78082,\"start\":78077},{\"end\":78098,\"start\":78092},{\"end\":78106,\"start\":78105},{\"end\":78122,\"start\":78117},{\"end\":78124,\"start\":78123},{\"end\":78141,\"start\":78135},{\"end\":78669,\"start\":78663},{\"end\":78683,\"start\":78679},{\"end\":78917,\"start\":78910},{\"end\":78946,\"start\":78941},{\"end\":79352,\"start\":79343},{\"end\":79365,\"start\":79364},{\"end\":79377,\"start\":79373},{\"end\":79751,\"start\":79745},{\"end\":79760,\"start\":79759},{\"end\":79778,\"start\":79770},{\"end\":79798,\"start\":79791},{\"end\":79812,\"start\":79806},{\"end\":80185,\"start\":80181},{\"end\":80198,\"start\":80195},{\"end\":80212,\"start\":80208},{\"end\":80672,\"start\":80667},{\"end\":80686,\"start\":80683},{\"end\":80700,\"start\":80699},{\"end\":80715,\"start\":80709},{\"end\":80729,\"start\":80721},{\"end\":80745,\"start\":80744},{\"end\":80761,\"start\":80753},{\"end\":80771,\"start\":80767},{\"end\":80781,\"start\":80777},{\"end\":81142,\"start\":81141},{\"end\":81154,\"start\":81150},{\"end\":81156,\"start\":81155},{\"end\":81392,\"start\":81386},{\"end\":81623,\"start\":81620},{\"end\":81788,\"start\":81785},{\"end\":81798,\"start\":81795},{\"end\":81813,\"start\":81807},{\"end\":81825,\"start\":81820},{\"end\":82129,\"start\":82124},{\"end\":82145,\"start\":82141},{\"end\":82158,\"start\":82153},{\"end\":82456,\"start\":82455},{\"end\":82473,\"start\":82466},{\"end\":82475,\"start\":82474},{\"end\":82832,\"start\":82827},{\"end\":82849,\"start\":82840},{\"end\":82860,\"start\":82855},{\"end\":82876,\"start\":82870},{\"end\":83132,\"start\":83128},{\"end\":83134,\"start\":83133},{\"end\":83148,\"start\":83144},{\"end\":83150,\"start\":83149},{\"end\":83161,\"start\":83160},{\"end\":83177,\"start\":83172},{\"end\":83179,\"start\":83178},{\"end\":83504,\"start\":83499},{\"end\":83520,\"start\":83514},{\"end\":83537,\"start\":83531},{\"end\":83804,\"start\":83798},{\"end\":84077,\"start\":84069},{\"end\":84079,\"start\":84078}]", "bib_author_last_name": "[{\"end\":68200,\"start\":68196},{\"end\":68218,\"start\":68209},{\"end\":68233,\"start\":68228},{\"end\":68247,\"start\":68242},{\"end\":68262,\"start\":68257},{\"end\":68280,\"start\":68271},{\"end\":68295,\"start\":68289},{\"end\":68303,\"start\":68297},{\"end\":68658,\"start\":68653},{\"end\":68669,\"start\":68665},{\"end\":68682,\"start\":68678},{\"end\":68696,\"start\":68692},{\"end\":68705,\"start\":68700},{\"end\":68720,\"start\":68716},{\"end\":68724,\"start\":68722},{\"end\":69092,\"start\":69077},{\"end\":69108,\"start\":69101},{\"end\":69118,\"start\":69110},{\"end\":69132,\"start\":69120},{\"end\":69143,\"start\":69136},{\"end\":69160,\"start\":69153},{\"end\":69172,\"start\":69162},{\"end\":69505,\"start\":69501},{\"end\":69514,\"start\":69509},{\"end\":69532,\"start\":69524},{\"end\":69550,\"start\":69541},{\"end\":69760,\"start\":69753},{\"end\":69779,\"start\":69773},{\"end\":69797,\"start\":69790},{\"end\":69816,\"start\":69810},{\"end\":69834,\"start\":69829},{\"end\":70256,\"start\":70252},{\"end\":70264,\"start\":70258},{\"end\":70516,\"start\":70512},{\"end\":70530,\"start\":70524},{\"end\":70538,\"start\":70532},{\"end\":70708,\"start\":70696},{\"end\":71007,\"start\":70995},{\"end\":71328,\"start\":71321},{\"end\":71346,\"start\":71339},{\"end\":71355,\"start\":71348},{\"end\":71630,\"start\":71620},{\"end\":71643,\"start\":71639},{\"end\":71656,\"start\":71652},{\"end\":71668,\"start\":71664},{\"end\":71682,\"start\":71677},{\"end\":71698,\"start\":71692},{\"end\":71716,\"start\":71710},{\"end\":71730,\"start\":71727},{\"end\":72320,\"start\":72304},{\"end\":72336,\"start\":72333},{\"end\":72348,\"start\":72344},{\"end\":72364,\"start\":72358},{\"end\":72383,\"start\":72374},{\"end\":72395,\"start\":72391},{\"end\":72412,\"start\":72405},{\"end\":72427,\"start\":72421},{\"end\":72435,\"start\":72429},{\"end\":73111,\"start\":73104},{\"end\":73131,\"start\":73124},{\"end\":73153,\"start\":73140},{\"end\":73172,\"start\":73163},{\"end\":73191,\"start\":73183},{\"end\":73207,\"start\":73201},{\"end\":73226,\"start\":73219},{\"end\":73234,\"start\":73228},{\"end\":73652,\"start\":73646},{\"end\":73667,\"start\":73662},{\"end\":73682,\"start\":73678},{\"end\":73696,\"start\":73694},{\"end\":73704,\"start\":73698},{\"end\":74068,\"start\":74065},{\"end\":74086,\"start\":74070},{\"end\":74358,\"start\":74350},{\"end\":74376,\"start\":74369},{\"end\":74673,\"start\":74665},{\"end\":74692,\"start\":74682},{\"end\":74710,\"start\":74703},{\"end\":75018,\"start\":75009},{\"end\":75031,\"start\":75028},{\"end\":75044,\"start\":75040},{\"end\":75053,\"start\":75048},{\"end\":75069,\"start\":75062},{\"end\":75088,\"start\":75079},{\"end\":75366,\"start\":75356},{\"end\":75381,\"start\":75375},{\"end\":75398,\"start\":75389},{\"end\":75578,\"start\":75575},{\"end\":75592,\"start\":75586},{\"end\":75600,\"start\":75597},{\"end\":75621,\"start\":75611},{\"end\":75924,\"start\":75920},{\"end\":75929,\"start\":75926},{\"end\":75942,\"start\":75935},{\"end\":75958,\"start\":75953},{\"end\":75965,\"start\":75960},{\"end\":76165,\"start\":76159},{\"end\":76181,\"start\":76175},{\"end\":76195,\"start\":76191},{\"end\":76207,\"start\":76203},{\"end\":76221,\"start\":76217},{\"end\":76236,\"start\":76232},{\"end\":76250,\"start\":76245},{\"end\":76269,\"start\":76262},{\"end\":76276,\"start\":76271},{\"end\":76640,\"start\":76635},{\"end\":77066,\"start\":77062},{\"end\":77080,\"start\":77077},{\"end\":77095,\"start\":77092},{\"end\":77114,\"start\":77110},{\"end\":77540,\"start\":77538},{\"end\":77555,\"start\":77548},{\"end\":77572,\"start\":77565},{\"end\":77584,\"start\":77579},{\"end\":77597,\"start\":77593},{\"end\":77618,\"start\":77610},{\"end\":77634,\"start\":77627},{\"end\":78075,\"start\":78073},{\"end\":78090,\"start\":78083},{\"end\":78103,\"start\":78099},{\"end\":78115,\"start\":78107},{\"end\":78133,\"start\":78125},{\"end\":78149,\"start\":78142},{\"end\":78158,\"start\":78151},{\"end\":78677,\"start\":78670},{\"end\":78689,\"start\":78684},{\"end\":78939,\"start\":78918},{\"end\":78953,\"start\":78947},{\"end\":78965,\"start\":78955},{\"end\":79362,\"start\":79353},{\"end\":79371,\"start\":79366},{\"end\":79385,\"start\":79378},{\"end\":79757,\"start\":79752},{\"end\":79768,\"start\":79761},{\"end\":79789,\"start\":79779},{\"end\":79804,\"start\":79799},{\"end\":79819,\"start\":79813},{\"end\":79825,\"start\":79821},{\"end\":80193,\"start\":80186},{\"end\":80206,\"start\":80199},{\"end\":80221,\"start\":80213},{\"end\":80681,\"start\":80673},{\"end\":80691,\"start\":80687},{\"end\":80697,\"start\":80693},{\"end\":80707,\"start\":80701},{\"end\":80719,\"start\":80716},{\"end\":80735,\"start\":80730},{\"end\":80742,\"start\":80737},{\"end\":80751,\"start\":80746},{\"end\":80765,\"start\":80762},{\"end\":80775,\"start\":80772},{\"end\":80788,\"start\":80782},{\"end\":80793,\"start\":80790},{\"end\":81148,\"start\":81143},{\"end\":81163,\"start\":81157},{\"end\":81171,\"start\":81165},{\"end\":81403,\"start\":81393},{\"end\":81631,\"start\":81624},{\"end\":81793,\"start\":81789},{\"end\":81805,\"start\":81799},{\"end\":81818,\"start\":81814},{\"end\":81831,\"start\":81826},{\"end\":82139,\"start\":82130},{\"end\":82151,\"start\":82146},{\"end\":82166,\"start\":82159},{\"end\":82464,\"start\":82457},{\"end\":82483,\"start\":82476},{\"end\":82490,\"start\":82485},{\"end\":82838,\"start\":82833},{\"end\":82853,\"start\":82850},{\"end\":82868,\"start\":82861},{\"end\":82884,\"start\":82877},{\"end\":83142,\"start\":83135},{\"end\":83158,\"start\":83151},{\"end\":83170,\"start\":83162},{\"end\":83184,\"start\":83180},{\"end\":83191,\"start\":83186},{\"end\":83512,\"start\":83505},{\"end\":83529,\"start\":83521},{\"end\":83545,\"start\":83538},{\"end\":83809,\"start\":83805},{\"end\":84088,\"start\":84080}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":3484844},\"end\":68580,\"start\":68080},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":49344716},\"end\":68986,\"start\":68582},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":205845217},\"end\":69450,\"start\":68988},{\"attributes\":{\"id\":\"b3\"},\"end\":69686,\"start\":69452},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":12389477},\"end\":70248,\"start\":69688},{\"attributes\":{\"id\":\"b5\"},\"end\":70436,\"start\":70250},{\"attributes\":{\"id\":\"b6\"},\"end\":70664,\"start\":70438},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":121781338},\"end\":70883,\"start\":70666},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":116895901},\"end\":71286,\"start\":70885},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":12090811},\"end\":71537,\"start\":71288},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":182952949},\"end\":72212,\"start\":71539},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":13372934},\"end\":72948,\"start\":72214},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":13603757},\"end\":73564,\"start\":72950},{\"attributes\":{\"doi\":\"arXiv:1909.00719\",\"id\":\"b13\"},\"end\":73918,\"start\":73566},{\"attributes\":{\"id\":\"b14\"},\"end\":74281,\"start\":73920},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":1878582},\"end\":74603,\"start\":74283},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":123181502},\"end\":75002,\"start\":74605},{\"attributes\":{\"doi\":\"arXiv:2101.05346\",\"id\":\"b17\"},\"end\":75335,\"start\":75004},{\"attributes\":{\"id\":\"b18\"},\"end\":75525,\"start\":75337},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":28671436},\"end\":75850,\"start\":75527},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":20710939},\"end\":76155,\"start\":75852},{\"attributes\":{\"id\":\"b21\"},\"end\":76486,\"start\":76157},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":18754990},\"end\":76928,\"start\":76488},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":201259884},\"end\":77416,\"start\":76930},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":202750236},\"end\":77931,\"start\":77418},{\"attributes\":{\"doi\":\"arXiv:2102.12439\",\"id\":\"b25\"},\"end\":78607,\"start\":77933},{\"attributes\":{\"doi\":\"arXiv:1802.10501\",\"id\":\"b26\"},\"end\":78844,\"start\":78609},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":6292807},\"end\":79285,\"start\":78846},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":207158152},\"end\":79703,\"start\":79287},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":102486060},\"end\":80123,\"start\":79705},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":3418973},\"end\":80597,\"start\":80125},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":7979241},\"end\":81063,\"start\":80599},{\"attributes\":{\"id\":\"b32\"},\"end\":81303,\"start\":81065},{\"attributes\":{\"id\":\"b33\"},\"end\":81527,\"start\":81305},{\"attributes\":{\"id\":\"b34\"},\"end\":81742,\"start\":81529},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":155092802},\"end\":82053,\"start\":81744},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":216081533},\"end\":82361,\"start\":82055},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":204460710},\"end\":82719,\"start\":82363},{\"attributes\":{\"id\":\"b38\"},\"end\":83060,\"start\":82721},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":7653718},\"end\":83434,\"start\":83062},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":219988530},\"end\":83728,\"start\":83436},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":205843387},\"end\":83987,\"start\":83730},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":38772422},\"end\":84306,\"start\":83989}]", "bib_title": "[{\"end\":68181,\"start\":68080},{\"end\":68645,\"start\":68582},{\"end\":69070,\"start\":68988},{\"end\":69743,\"start\":69688},{\"end\":70694,\"start\":70666},{\"end\":70993,\"start\":70885},{\"end\":71317,\"start\":71288},{\"end\":71608,\"start\":71539},{\"end\":72293,\"start\":72214},{\"end\":73100,\"start\":72950},{\"end\":74340,\"start\":74283},{\"end\":74655,\"start\":74605},{\"end\":75567,\"start\":75527},{\"end\":75914,\"start\":75852},{\"end\":76619,\"start\":76488},{\"end\":77051,\"start\":76930},{\"end\":77530,\"start\":77418},{\"end\":78908,\"start\":78846},{\"end\":79341,\"start\":79287},{\"end\":79743,\"start\":79705},{\"end\":80179,\"start\":80125},{\"end\":80665,\"start\":80599},{\"end\":81783,\"start\":81744},{\"end\":82122,\"start\":82055},{\"end\":82453,\"start\":82363},{\"end\":83126,\"start\":83062},{\"end\":83497,\"start\":83436},{\"end\":83796,\"start\":83730},{\"end\":84067,\"start\":83989}]", "bib_author": "[{\"end\":68202,\"start\":68183},{\"end\":68220,\"start\":68202},{\"end\":68235,\"start\":68220},{\"end\":68249,\"start\":68235},{\"end\":68264,\"start\":68249},{\"end\":68282,\"start\":68264},{\"end\":68297,\"start\":68282},{\"end\":68305,\"start\":68297},{\"end\":68660,\"start\":68647},{\"end\":68671,\"start\":68660},{\"end\":68684,\"start\":68671},{\"end\":68698,\"start\":68684},{\"end\":68707,\"start\":68698},{\"end\":68722,\"start\":68707},{\"end\":68726,\"start\":68722},{\"end\":69094,\"start\":69072},{\"end\":69110,\"start\":69094},{\"end\":69120,\"start\":69110},{\"end\":69134,\"start\":69120},{\"end\":69145,\"start\":69134},{\"end\":69162,\"start\":69145},{\"end\":69174,\"start\":69162},{\"end\":69507,\"start\":69499},{\"end\":69516,\"start\":69507},{\"end\":69534,\"start\":69516},{\"end\":69552,\"start\":69534},{\"end\":69762,\"start\":69745},{\"end\":69783,\"start\":69762},{\"end\":69799,\"start\":69783},{\"end\":69818,\"start\":69799},{\"end\":69836,\"start\":69818},{\"end\":70258,\"start\":70250},{\"end\":70266,\"start\":70258},{\"end\":70518,\"start\":70510},{\"end\":70532,\"start\":70518},{\"end\":70540,\"start\":70532},{\"end\":70710,\"start\":70696},{\"end\":71009,\"start\":70995},{\"end\":71330,\"start\":71319},{\"end\":71348,\"start\":71330},{\"end\":71357,\"start\":71348},{\"end\":71632,\"start\":71610},{\"end\":71645,\"start\":71632},{\"end\":71658,\"start\":71645},{\"end\":71670,\"start\":71658},{\"end\":71684,\"start\":71670},{\"end\":71700,\"start\":71684},{\"end\":71718,\"start\":71700},{\"end\":71732,\"start\":71718},{\"end\":72322,\"start\":72295},{\"end\":72338,\"start\":72322},{\"end\":72350,\"start\":72338},{\"end\":72366,\"start\":72350},{\"end\":72385,\"start\":72366},{\"end\":72397,\"start\":72385},{\"end\":72414,\"start\":72397},{\"end\":72429,\"start\":72414},{\"end\":72437,\"start\":72429},{\"end\":73113,\"start\":73102},{\"end\":73133,\"start\":73113},{\"end\":73155,\"start\":73133},{\"end\":73174,\"start\":73155},{\"end\":73193,\"start\":73174},{\"end\":73209,\"start\":73193},{\"end\":73228,\"start\":73209},{\"end\":73236,\"start\":73228},{\"end\":73654,\"start\":73642},{\"end\":73669,\"start\":73654},{\"end\":73684,\"start\":73669},{\"end\":73698,\"start\":73684},{\"end\":73706,\"start\":73698},{\"end\":74070,\"start\":74059},{\"end\":74088,\"start\":74070},{\"end\":74360,\"start\":74342},{\"end\":74378,\"start\":74360},{\"end\":74675,\"start\":74657},{\"end\":74694,\"start\":74675},{\"end\":74712,\"start\":74694},{\"end\":75020,\"start\":75004},{\"end\":75033,\"start\":75020},{\"end\":75046,\"start\":75033},{\"end\":75055,\"start\":75046},{\"end\":75071,\"start\":75055},{\"end\":75090,\"start\":75071},{\"end\":75368,\"start\":75352},{\"end\":75383,\"start\":75368},{\"end\":75400,\"start\":75383},{\"end\":75580,\"start\":75569},{\"end\":75594,\"start\":75580},{\"end\":75602,\"start\":75594},{\"end\":75623,\"start\":75602},{\"end\":75926,\"start\":75916},{\"end\":75931,\"start\":75926},{\"end\":75944,\"start\":75931},{\"end\":75960,\"start\":75944},{\"end\":75967,\"start\":75960},{\"end\":76167,\"start\":76157},{\"end\":76183,\"start\":76167},{\"end\":76197,\"start\":76183},{\"end\":76209,\"start\":76197},{\"end\":76223,\"start\":76209},{\"end\":76238,\"start\":76223},{\"end\":76252,\"start\":76238},{\"end\":76271,\"start\":76252},{\"end\":76278,\"start\":76271},{\"end\":76642,\"start\":76621},{\"end\":77068,\"start\":77053},{\"end\":77082,\"start\":77068},{\"end\":77097,\"start\":77082},{\"end\":77116,\"start\":77097},{\"end\":77542,\"start\":77532},{\"end\":77557,\"start\":77542},{\"end\":77574,\"start\":77557},{\"end\":77586,\"start\":77574},{\"end\":77599,\"start\":77586},{\"end\":77620,\"start\":77599},{\"end\":77636,\"start\":77620},{\"end\":78077,\"start\":78067},{\"end\":78092,\"start\":78077},{\"end\":78105,\"start\":78092},{\"end\":78117,\"start\":78105},{\"end\":78135,\"start\":78117},{\"end\":78151,\"start\":78135},{\"end\":78160,\"start\":78151},{\"end\":78679,\"start\":78663},{\"end\":78691,\"start\":78679},{\"end\":78941,\"start\":78910},{\"end\":78955,\"start\":78941},{\"end\":78967,\"start\":78955},{\"end\":79364,\"start\":79343},{\"end\":79373,\"start\":79364},{\"end\":79387,\"start\":79373},{\"end\":79759,\"start\":79745},{\"end\":79770,\"start\":79759},{\"end\":79791,\"start\":79770},{\"end\":79806,\"start\":79791},{\"end\":79821,\"start\":79806},{\"end\":79827,\"start\":79821},{\"end\":80195,\"start\":80181},{\"end\":80208,\"start\":80195},{\"end\":80223,\"start\":80208},{\"end\":80683,\"start\":80667},{\"end\":80693,\"start\":80683},{\"end\":80699,\"start\":80693},{\"end\":80709,\"start\":80699},{\"end\":80721,\"start\":80709},{\"end\":80737,\"start\":80721},{\"end\":80744,\"start\":80737},{\"end\":80753,\"start\":80744},{\"end\":80767,\"start\":80753},{\"end\":80777,\"start\":80767},{\"end\":80790,\"start\":80777},{\"end\":80795,\"start\":80790},{\"end\":81150,\"start\":81141},{\"end\":81165,\"start\":81150},{\"end\":81173,\"start\":81165},{\"end\":81405,\"start\":81386},{\"end\":81633,\"start\":81620},{\"end\":81795,\"start\":81785},{\"end\":81807,\"start\":81795},{\"end\":81820,\"start\":81807},{\"end\":81833,\"start\":81820},{\"end\":82141,\"start\":82124},{\"end\":82153,\"start\":82141},{\"end\":82168,\"start\":82153},{\"end\":82466,\"start\":82455},{\"end\":82485,\"start\":82466},{\"end\":82492,\"start\":82485},{\"end\":82840,\"start\":82827},{\"end\":82855,\"start\":82840},{\"end\":82870,\"start\":82855},{\"end\":82886,\"start\":82870},{\"end\":83144,\"start\":83128},{\"end\":83160,\"start\":83144},{\"end\":83172,\"start\":83160},{\"end\":83186,\"start\":83172},{\"end\":83193,\"start\":83186},{\"end\":83514,\"start\":83499},{\"end\":83531,\"start\":83514},{\"end\":83547,\"start\":83531},{\"end\":83811,\"start\":83798},{\"end\":84090,\"start\":84069}]", "bib_venue": "[{\"end\":68309,\"start\":68305},{\"end\":68764,\"start\":68726},{\"end\":69206,\"start\":69174},{\"end\":69497,\"start\":69452},{\"end\":69883,\"start\":69836},{\"end\":70339,\"start\":70266},{\"end\":70508,\"start\":70438},{\"end\":70757,\"start\":70710},{\"end\":71069,\"start\":71009},{\"end\":71398,\"start\":71357},{\"end\":71810,\"start\":71732},{\"end\":72527,\"start\":72437},{\"end\":73245,\"start\":73236},{\"end\":73640,\"start\":73566},{\"end\":74057,\"start\":73920},{\"end\":74425,\"start\":74378},{\"end\":74788,\"start\":74712},{\"end\":75148,\"start\":75106},{\"end\":75350,\"start\":75337},{\"end\":75667,\"start\":75623},{\"end\":75990,\"start\":75967},{\"end\":76319,\"start\":76278},{\"end\":76692,\"start\":76642},{\"end\":77156,\"start\":77116},{\"end\":77659,\"start\":77636},{\"end\":78065,\"start\":77933},{\"end\":78661,\"start\":78609},{\"end\":79028,\"start\":78967},{\"end\":79455,\"start\":79387},{\"end\":79841,\"start\":79827},{\"end\":80281,\"start\":80223},{\"end\":80815,\"start\":80795},{\"end\":81139,\"start\":81065},{\"end\":81384,\"start\":81305},{\"end\":81618,\"start\":81529},{\"end\":81877,\"start\":81833},{\"end\":82191,\"start\":82168},{\"end\":82524,\"start\":82492},{\"end\":82825,\"start\":82721},{\"end\":83227,\"start\":83193},{\"end\":83567,\"start\":83547},{\"end\":83843,\"start\":83811},{\"end\":84131,\"start\":84090},{\"end\":71892,\"start\":71812},{\"end\":72604,\"start\":72529},{\"end\":79076,\"start\":79030},{\"end\":79510,\"start\":79457},{\"end\":80368,\"start\":80283}]"}}}, "year": 2023, "month": 12, "day": 17}