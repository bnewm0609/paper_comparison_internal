{"id": 236150561, "updated": "2021-12-29 02:23:16.492", "metadata": {"title": "ManiHD: Efficient Hyper-Dimensional Learning Using Manifold Trainable Encoder", "authors": "[{\"middle\":[],\"last\":\"Zou\",\"first\":\"Zhuowen\"},{\"middle\":[],\"last\":\"Kim\",\"first\":\"Yeseong\"},{\"middle\":[\"Hassan\"],\"last\":\"Najafi\",\"first\":\"M.\"},{\"middle\":[],\"last\":\"Imani\",\"first\":\"Mohsen\"}]", "venue": "2021 Design, Automation & Test in Europe Conference & Exhibition (DATE)", "journal": "2021 Design, Automation & Test in Europe Conference & Exhibition (DATE)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Hyper-Dimensional (HD) computing emulates the human short memory functionality by computing with hypervectors as an alternative to computing with numbers. The main goal of HD computing is to map data points into sparse highdimensional space where the learning task can perform in a linear and hardware-friendly way. The existing HD computing algorithms are using static and non-trainable encoder; thus, they require very high-dimensionality to provide acceptable accuracy. However, this high dimensionality results in high computational cost, especially over the realistic learning problems. In this paper, we proposed ManiHD that supports adaptive and trainable encoder for efficient learning in high-dimensional space. ManiHD explicitly considers non-linear interactions between the features during the encoding. This enables ManiHD to provide maximum learning accuracy using much lower dimensionality. ManiHD not only enhances the learning accuracy but also significantly improves the learning efficiency during both training and inference phases. ManiHD also enables online learning by sampling data points and capturing the essential features in an unsupervised manner. We also propose a quantization method that trades accuracy and efficiency for optimal configuration. Our evaluation of a wide range of classification tasks shows that ManiHD provides 4.8% higher accuracy than the stateof-the-art HD algorithms. In addition, ManiHD provides, on average, 12.3\u00d7 (3.2\u00d7) faster and 19.3\u00d7 (6.3\u00d7) more energyefficient training (inference) as compared to the state-of-the-art learning algorithms.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/date/ZouKNI21", "doi": "10.23919/date51398.2021.9473987"}}, "content": {"source": {"pdf_hash": "db22eb6a6e173e261ac7902557fa2ab5c6e32a7b", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4ce1e55b66c7dedf912dccece8abbedac18d5834", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/db22eb6a6e173e261ac7902557fa2ab5c6e32a7b.txt", "contents": "\nManiHD: Efficient Hyper-Dimensional Learning Using Manifold Trainable Encoder\n\n\nZhuowen Zou \nYeseong Kim \nDGIST\n\n\nM Hassan Najafi \nUniversity of Louisiana\n\n\nMohsen Imani m.imani@uci.edu \nUniversity of California Irvine\n\n\n\nUniversity of California San Diego\n\n\nManiHD: Efficient Hyper-Dimensional Learning Using Manifold Trainable Encoder\n\nHyper-Dimensional (HD) computing emulates the human short memory functionality by computing with hypervectors as an alternative to computing with numbers. The main goal of HD computing is to map data points into sparse highdimensional space where the learning task can perform in a linear and hardware-friendly way. The existing HD computing algorithms are using static and non-trainable encoder; thus, they require very high-dimensionality to provide acceptable accuracy. However, this high dimensionality results in high computational cost, especially over the realistic learning problems. In this paper, we proposed ManiHD that supports adaptive and trainable encoder for efficient learning in high-dimensional space. ManiHD explicitly considers non-linear interactions between the features during the encoding. This enables ManiHD to provide maximum learning accuracy using much lower dimensionality. ManiHD not only enhances the learning accuracy but also significantly improves the learning efficiency during both training and inference phases. ManiHD also enables online learning by sampling data points and capturing the essential features in an unsupervised manner. We also propose a quantization method that trades accuracy and efficiency for optimal configuration. Our evaluation of a wide range of classification tasks shows that ManiHD provides 4.8% higher accuracy than the stateof-the-art HD algorithms. In addition, ManiHD provides, on average, 12.3\u00d7 (3.2\u00d7) faster and 19.3\u00d7 (6.3\u00d7) more energyefficient training (inference) as compared to the state-of-the-art learning algorithms.\n\nI. INTRODUCTION\n\nIn 2025 more than 175 Zettabytes of data will be generated worldwide, much of it by machines, but less than 1% will be analyzed. We are drowning in data. Today's systems rely on sending all the data to the cloud, and then using complex algorithms, such as Deep Neural Networks, which require billions of parameters and many hours to train [1], [2]. This computational cost is beyond the capability of today's embedded devices, which often have limited resources and battery [3]. Therefore, we need alternative learning methods to train on the less-powerful devices while providing good enough classification accuracy.\n\nThe human brain can do much of this learning effortlessly. In particular, Hyperdimensional (HD) computing has been proposed as a light-weight brain-inspired learning methodology [4], [5], [6]. HD computing is motivated by the observation that the human brain operates on high dimensional representations of data [4]. This high-dimensional space is referred to as a hyperspace, while points in the space are known as hypervectors. Because of their high-dimensionality, any randomly chosen pair of hypervectors will be nearly orthogonal (e.g., uncorrelated). HD computing provides several features that make it suitable for efficient learning in IoT systems. First, HD models are computationally efficient (highly parallel at heart) to train and amenable to hardware level optimization [7], [8], [9], [10]. Second, HD models offer an intuitive and human-interpretable model and offer a complete computational paradigm that can be applied to cognitive and learning problems [11], [12]. Finally, it provides strong robustness to noise -a key strength for IoT systems. These features make HD a promising solution for today's embedded devices with limited storage, battery, and resources [13], [14], [15].\n\nHD computing performs the learning task after encoding all data points to high-dimensional space. The required dimensionality of HD computing increases based on the complexity of the classification takes. All existing HD computing methods use a static and non-trainable encoder to map data into high dimensional space [7], [6], [5], [16]. In other words, the encoding module does not learn or differentiates between the features in the input data. Therefore, HD computing requires very high dimensionality in order to solve realistic learning problems. However, higher dimensionality results in low computational efficiency.\n\nIn this paper, we proposed ManiHD, a trainable encoder for efficient adaptive learning in high-dimensional space. ManiHD enhances the randomized HD encoder with manifold learning in order to eliminate the extreme dimensionality of hypervectors. The main contributions of the paper are as follows:\n\n\u2022 To the best of our knowledge, ManiHD is the first HD computing approach that provides adaptive and trainable encoding. Instead of using a static encoder, ManiHD explicitly considers non-linear interactions between the features during the encoding. This enables ManiHD to provide maximum learning accuracy using much lower dimensionality. \u2022 ManiHD enables online learning by frequently sampling data and capturing the important features in an unsupervised manner. ManiHD enables to adapt itself to changes in the input data or environment during the prediction phase. \u2022 To reduce the ManiHD computation cost, we also introduce the idea of quantizing the encoding module. In addition, to compensate for the quality loss caused by quantization, while providing an optimal system efficiency.\n\nManiHD dimension reduction results in significant improvement in the efficiency of training and inference phases. We evaluation ManiHD on a wide range of classification problems. Our evaluation on a wide range of classification tasks shows that ManiHD provides 4.8% higher accuracy than the stateof-the-art HD algorithms. In addition, ManiHD provides, on average, 12.3\u00d7 (3.2\u00d7) faster and 19.3\u00d7 (6.3\u00d7) more energyefficient training (inference) as compared to the state-of-the-art learning algorithms. II. MANIHD CLASSIFICATION Figure 1 shows the overview of the HD classification. In the first step, HD computing performs the learning task after mapping all training data into the high-dimensional space [7], [5], [17]. To find the universal property for each class in the training dataset, we combine hypervectors belonging to each class, i.e., adding the hypervectors to create a single hypervector for each class. Once combining all hypervectors, we treat per-class accumulated hypervectors, called class hypervectors, as the learned model. Next, a similarity search procedure performs the inference task. For a given query hypervector encoded for a tested data point, it selects the class that has the most similar class hypervector. In the following, we explain the details of the learning process and related work.\n\n\nA. Classification in HD Space\n\n\u2022 A Encoding: The encoded data should satisfy the commonsense principle: data points which are different from each other in the original space should be also different in the highdimensional space. There are multiple encoding methods proposed in literature [18], [19], [7]. Although these methods have shown excellent classification accuracy for their applicationspecific problems, to the best of our knowledge, the existing encoding methods linearly combine the hypervectors corresponding to each feature, resulting in sub-optimal classification quality for general classification problems. To obtain the most informative hypervectors, the HD encoding should consider the non-linear interactions between the feature values with different weights.\n\n\u2022 B Training: In the training step, HD combines all the encoded hypervectors of each class using the element-wise addition. For example, in an activity recognition application, the training procedure adds all hypervectors which have the \"walking\" and \"sitting\" tags into two different hypervectors. Where H i j = h D , \u00b7 \u00b7 \u00b7 , h 1 is encoded for the j th sample in i th class, each class hypervector is trained as follows:\nC i = \u2211 j H i j = c i D , \u00b7 \u00b7 \u00b7 , c i 1\nIf the encoding method projects the original data non-linearly to the high dimensional space, the linearly combined model can perform well even on non-linearly separable data.\n\n\u2022 C Retraining: Once the initial training is done, we train the class hypervector model again to improve the classification accuracy. In this retraining step, we calculate the similarity between each encoded hypervector and trained model to check whether the data sample is correctly classified or not. If the encoded hypervector, H, is correctly classified by the current model, we will make no changes to the model. Otherwise, we update the model by respectively adding and subtracting it from the correct and incorrect classes as follows:\nC correct = C correct + \u03b1H and C wrong = C wrong \u2212 \u03b1H\nThe retrained model provides a better fit to the training data and gets higher accuracy. We repeat the same procedure for multiple iterations. In our observation, repeating 20 iterations yields sufficient convergence for all the tested datasets.\n\n\u2022 D Inference: The main computation of the inference is the encoding and associative search. We perform the same encoding procedure to convert a test data point into a hypervector, called query hypervector, Q \u2208 {0, 1} D . Then, it computes the similarity of the query hypervector with all k class hypervectors, {C 1 , C 2 , \u00b7 \u00b7 \u00b7 , C k }. We measure the similarity between a query and a i th class hypervector using: \u03b4 Q, C i , where \u03b4 denotes the similarity metric. After computing all similarities, each query is assigned to a class with the highest similarity.\n\n\nB. Challenges\n\nThe existing HD algorithms are using a static encoder to map data into high-dimensional space. We observe that this is the main reason that HD requires high dimensionality to provide acceptable accuracy. However, the HD computation cost increases with hypervector dimensionality. In this paper, we propose the idea of adaptively and trainable encoder which enables HD computing to provide maximum accuracy in much lower dimensionality.\n\n\nIII. MANIHD ADAPTIVE ENCODING\n\nThis section proposed ManiHD, an HD-based classification algorithm supporting an adaptive encoder for efficient learning in high-dimensional space. ManiHD encoder is built based on two goals: (i) an encoder that can provide high classification accuracy in smaller dimensions, (i) a dynamic encoding module that can adaptively change depending on data and environment. ManiHD introduces a novel HD encoder that considers the relationship between different features before mapping data into high-dimensional space. ManiHD samples a small portion of training data to determine the relationship between different features in an unsupervised way. Then, it modifies the HD encoder to consider such a relationship before encoding the data point. ManiHD provides several interesting features: (i) eliminates the necessity of using a very large naive projection matrix as an encoding module, (ii) provides high classification accuracy even using lower dimensionality.\n\n\nA. Non-Linear Encoding\n\nIn this context, we propose a novel encoding method which exploits the kernel trick to map data points into the high-dimensional space. The proposed encoding method is inspired by the Radial Basis Function (RBF) kernel trick method [20], [21]. Figure 2A shows our encoding procedure. Let us consider an encoding function that maps a feature vector\nF = { f 1 , f 2 , . . . , f n }, with n features ( f i \u2208 N) to a hypervector H = {h 1 , h 2 , . . . , h D } with D dimensions (h i \u2208 {\u22121, 1}).\nWe generate each dimension of the encoded data by calculating a dot product of the feature vector with a randomly generated vector as h i = cos(B i \u00b7 F), where B i is the randomly generated vector with a Gaussian distribution (mean \u00b5 = 0 and standard deviation \u03c3 = 1) with the same dimensionality to that of the feature vector. The random vectors {B 1 , B 2 , \u00b7 \u00b7 \u00b7 , B D } can be generated once offline and then can be used for the rest of the classification task. After this step, each element h i of a hypervector H n has a non-binary value. In HD computing, binary (bipolar) hypervectors are often used for computation efficiency. We thus obtain the final encoded hypervector by binarizing it with a sign function (H = sign(H n )) where the sign function assigns all positive hypervector dimensions to '1' and zero/negative dimensions to '-1'. The encoded hypervector stores the information of each original data point with D bits.\n\n\nB. Manifold Learning\n\nHere, we exploit manifold learning to capture non-linear structure in data before naively encoding it into highdimensional space. Manifold learning is an approach to nonlinear dimensionality reduction, assuming in many data sets, the number of input features is artificially high. Manifold algorithms are unsupervised [22], [23]; thus, they can learn the data structure without using any labeled data or predetermined classifications. Our goal is to combine the capability of manifold learning with ManiHD static encoder to design an adaptive and trainable encoder for high-dimensional classification.\n\nAlthough there are multiple manifold learning methods, ManiHD requires an approach supporting online and lowcost transformation for the data. Here, we focus on isomap (i.e., Isometric mapping) [24], [22]. The goal of isomap is to find a lower-dimensional of embedding that keeps the geometric distances between all data points. isomap uses the nearest search operation and shortest-path graph search to find a proper projection from original data to a lower dimension. This projection considers the relation between the features and generates a new shorter vector between a representation for learning purposes.\n\nIn isomap, the cost of manifold learning increases quadratically with the number of data points (O[N 2 ]). Therefore, running manifold learning over the entire training data results in a significantly slow training process. One of the main goals of HD computing is to enable fast on-the-fly training on lowend embedded devices. Therefore, the high computational cost of manifold learning does not allow us to run it during the training phase. To address this issue, as we show in Figure 3, ManiHD randomly samples a small portion of data points (e.g., about 1%) to learn the manifold. The output of the algorithm is a projection matrix that maps input data to lower dimensions (\"Manifold Projection\" shown in Figure 2B).\n\nFor all data points (training/test data), ManiHD first passes each original data ({ f 1 , f 2 , \u00b7 \u00b7 \u00b7 , f n }) through a manifold projection matrix. The result will be a vector with a smaller dimensionality, { f 1 , f 2 , \u00b7 \u00b7 \u00b7 , f k }, where k < n. Next, ManiHD runs the HD static encoder on the manifold output vector in order to map it into high-dimensional space. The encoded data will be binarized and then used for the rest of the training and inference tasks. As Figure 2C shows, the manifold projection adds an extra cost to ManiHD static encoder. In other words, ManiHD adaptive encoder consists of two vectormatrix multiplication: first, the manifold projection matrix and second, HD static projection. This extra cost can affect the efficiency of both training and inference phases, as every test data also needs to pass through these two matrices. To address this overhead issue, ManiHD combines manifold and HD projection matrix into a single matrix. As Figure 3C shows, we multiply these matrices once after training the manifold and use a new adaptive HF encoder for encoding the rest of the data points. Note that this matrix's size is the same as the original encoding matrix (n \u00d7 D); thus, computationally, it does not add any extra cost to the HD static encoding.\n\n\nIV. MANIHD ONLINE LEARNING\n\nIn real-world learning problems, data are changing over time as the environment is dynamic. Having a static encoder which has been pre-trained once does not give flexibility to ManiHD. In addition, ManiHD requires fast and efficient encoding and learning in order to enable real-time learning. In this section, we explain how ManiHD supports both these features.\n\n\nA. Real-time Encoding Update\n\nIn order to design a flexible and dynamic encoder, ManiHD processes manifold frequently learning over input data. Since the manifold is unsupervised, it can be processed on the unlabeled data during the inference. After a pre-defined time, ManiHD samples from new data points and run manifold learning on a small portion of data. Next, it updates the HD encoder based on a new projection matrix. This enables us to adaptively improve our encoder's quality, depending on the input data changes. Since manifold learning is computationally expensive, we can run the encoding offline and only once after a while to make sure we do not increase the computational training cost. In this scenario, ManiHD can use the old projection matrix to perform a learning task while updating the projection matrix based on new data. In Section V-E,  we explore the impact of the frequent manifold update on ManiHD accuracy and efficiency.\n\n\nB. ManiHD Encoder Qunatization\n\nIn order to enable online learning, ManiHD needs to provide real-time data encoding and learning. However, ManiHD encoder is significantly costly to allow real-time learning. Figure4a shows the breakdown of ManiHD and baseline HD energy consumption. The results are reported when both approaches are providing the same classification accuracy. The baseline HD computing uses D = 10k to provide high classification accuracy, while ManiHD uses D = 4k to achieve the same quality of classification. This lower dimensionality significantly improves ManiHD efficiency during the training/inference phases, since the costly similarity search performs with higher efficiency. As Figure 4 shows, in ManiHD, the encoding module takes 72% of the training phase, while this portion is less than 20% on the baseline HD.\n\nIn order to run ManiHD on small and tiny embedded devices, we need to reduce overall energy consumption. This means that we need to reduce the computation cost of the encoding module. To this end, we proposed the idea of using a quantized projection matrix, where every element can be represented using n-bits (n << 32). Figure 4b shows the quality loss of ManiHD for activity recognition application [25] when the precision of elements in the projection matrix reduces from 32-bits. The right y-axis in Figure 4b shows the normalized energy consumption of ManiHD encoding during different bit precisions. The energy results are reported for FPGA. Since FPGAs have limited DSP resources, they can significantly speedup the encoding computation when quantization reduces to fewer bits. This is because FPGAs can use their highly parallel lookup table resources to parallelize the computation. However, the lower precision projection matrix results in a quality loss. For example, quantizing the projection matrix from 32-bits to 2-bits results in 3.4% quality loss while improving the energy efficiency by 5.8\u00d7 times.\n\nWe observe that encoding data into higher dimensionality can compensate for the quality loss from quantization. Even with increasing dimensionality, the new quantized encoder has much lower computation cost on FPGA. This is because FPGAs have enough parallelism/resources for low-precision computations. In addition, the increase in hypervector dimensionality has a negative effect on training and associative search block. To provide maximum efficiency, we have optimized the system (devices dimensionality and level of quantization) such that the encoding and associative search consume the same amount of energy.  \n\n\nV. EVALUATION A. Experimental Setup\n\nThe proposed ManiHD framework has been implemented with both software and hardware support. In software, we design ManiHD in C++ for model training and verification while exploiting Scikit-learn library [26] for manifold learning. In hardware, we used a similar framework as [9] to implement ManiHD on Kintex-7 FPGA. The FPGA design accelerates the encoding and learning procedure by parallelizing element-wise computations for hypervectors. We test ManiHD efficiency and accuracy on a wide range of classification datasets. Table I summarizes the details of the datasets. Figure 5 compares the classification accuracy with state-ofthe-art classification algorithms, including Deep Neural Network (DNN), Support Vector Machine (SVM), and AdaBoost. We also compare the accuracy of ManiHD with a stateof-the-art HD-based classifier published in [19], which uses a linear encoding method, as the baseline. The results are reported when all algorithms are performing in a central node that considers all features given in the dataset. The DNN models are trained with Tensorflow [31], and we exploited the Scikit-learn library [26] for the other algorithms. We exploit the common practice of the grid search to identify the best hyper-parameters for each model. The accuracy of ManiHD is reported for D = 4000 dimensions. Our evaluation shows that ManiHD provides comparable classification accuracy to the sophisticated non-HD algorithms. As compared to the baseline HD computing, ManiHD can achieve, on average, 4.7% higher classification accuracy, since our new encoding method non-linearly maps the data to the high dimensional space whereas the baseline HD encoding linearly performs the encoding. ManiHD enhanced with manifold can further improve the classification accuracy, as it can identify better features before mapping them into high-dimensional space. Our evaluation shows that ManiHD can provide, on average, 2.6% (4.8%) higher classification accuracy as compared to ManiHD without manifold (the baseline HD computing).\n\n\nB. ManiHD Classification Accuracy\n\n\nC. ManiHD Accuracy-Efficiency\n\nManiHD efficiency and accuracy depend on a portion of the training data used for the manifold. From an accuracy point of view, using a larger portion of data for manifold results in improving the classification accuracy. However, it comes with the overhead of processing manifold data. Note that the manifold overhead is only on the training phase, while the inference can get the advantage of the manifold for higher classification accuracy. Here, we perform an experiment to show the trade-off in selecting a suitable portion of manifold learning. Table II shows the impact of partial data training of manifold in ManiHD accuracy and efficiency. All results are reported when ManiHD provides the same accuracy. Increasing a portion of manifold data results in providing higher classification accuracy. This enables us to reduce ManiHD dimensionality, as manifold already combines useful features in original data. As Table II reports, this dimension reduction can result in more efficient training and inference phases. However, learning the manifold by itself adds an extra cost to the ManiHD training phase. This cost depends on the portion of data used to learn manifold (quadratic relation). To design an efficient system, we need to ensure that the manifold's overhead does not overcome the efficiency coming from reducing dimensionality. Our evaluation shows that using 0.5% of data for learning manifold results in reducing the hypervector dimensionality by half. This lower dimensionality not only compensates the overhead of manifold but also results in 1.52\u00d7 and 1.81\u00d7 improvement in the training and inference performance, respectively. Further increasing the manifold data results in saturation in the classification accuracy. In other words, at the same level of accuracy, ManiHD provides a small reduction in the dimensionality. In addition, the overhead of the manifold increases quadratically with the number of data points. As results in Table II shows, using 1.5% of data for manifold results in a 14% slower training process. Note that the overhead of learning manifold is not on the inference phase. For systems optimized only for inference, a larger portion of data used to learning manifold results in higher accuracy or potentially lower dimensionality.\n\n\nD. ManiHD Efficiency\n\nWe compare the computation efficiency of the DNN and HD computing algorithms. Figure 6 compares the efficiency of the training and inference procedure for the different configurations. All results are normalized to the execution time and energy consumption of DNN. All designs run on the same FPGA platform. We used DNNWeaver V2.0 [32] for efficient implementation of the DNN inference, and FPDeep [33] for NN training on a single FPGA device. FPGA implementations are optimized to maximize performance by utilizing FPGA resources. All HD-based approaches are compared when they provide the same classification accuracy. Therefore, when ManiHD with manifold works in D = 4k binary, ManiHD without manifold and the baseline HD work in D = 10k binary and non-binary representations. All results listed in Figure 6  are relative to DNN performance and energy efficiency. During training, ManiHD with manifold (without manifold) achieves, on average, 12.3\u00d7 (7.7\u00d7) faster and 19.3\u00d7 (12.0\u00d7) more energy-efficient computation as compared to FPGA-based DNN implementation, respectively. The high efficiency of ManiHD in training comes from: (i) ManiHD capability in creating an initial model that significantly lowers the number of required retraining iterations. (ii) It eliminates the costly gradient descent for the model update. In addition, ManiHD provides 5.4\u00d7 faster and 3.8\u00d7 higher energy efficiency as compared to the baseline HD computing. This efficiency comes from (i) ManiHD advance encoding method that enables ManiHD to provide maximum accuracy in 0.4 \u00d7 lower dimensionality, (ii) ManiHD capability to perform the majority of training/inference over the binary model. Figure 6b also compares ManiHD inference efficiency with DNN and the baseline HD. Although manifold does not affect the inference efficiency, it enables ManiHD to work on lower dimensionality, resulting in a higher computation efficiency. Our evaluation shows that ManiHD with manifold provides 3.2\u00d7 and 6.3\u00d7 (4.4\u00d7 and 4.6\u00d7) faster and more efficient inference as compared to DNN (baseline HD computing).\n\n\nE. Online Manifold Learning\n\nAs we discussed in Section IV-A, in real systems, data points are highly correlated and have high temporal locality. This means that the data points are dynamically changing during time. Therefore, ManiHD with a pre-trained manifold cannot provide suitable accuracy. Here, we design an experiment to show the advantage of ManiHD for online learning. We enable online learning on the smart home project, where the usage of electricity changes during different seasons. We perform two experiments over this dataset to show the impact of the adaptive manifold update on ManiHD encoding: (i) we train ManiHD on the training data (collected from summer season) and learned manifold by sampling 4% of training data. (ii) we train ManiHD on the same training data, but we frequently update the manifold data during the inference. In each season, we sample 1% of data points and update the manifold and ManiHD encoder accordingly. Note that both static and adaptive manifold updates have the same computational overhead as they process a total of 4% of data. Table III reports the classification accuracy of ManiHD in these two configurations during different time steps. Our evaluation shows that ManiHD using static manifold provides high classification accuracy in summer, while in other seasons, the classification accuracy significantly drops. This is because the manifold has been learned using summer data. However, ManiHD updating the manifold adaptively results in providing high accuracy in every season. Our evaluation shows that ManiHD using adaptive manifold provides 4.3% higher accuracy as compared to ManiHD with the static manifold.\n\n\nF. ManiHD Encoding Quantization\n\nAs we discussed in Section IV-B, the ManiHD encoding module dominates the entire training/inference cost. In order to reduce the overall ManiHD efficiency, we propose the idea of encoding quantization. Our approach represents each element of the projection matrix with n-bits, where n << 32. However, quantization reduces ManiHD classification accuracy. ManiHD can compensate for the quality loss caused by quantization with increasing the hypervector dimensions. Figure 7 shows the number of required ManiHD dimensionality during different levels of encoder quantizations. As this graph shows, with no quantization provides maximum accuracy using D = 4k while quantizing ManiHD encoder into 2-bits (3-bits) precision results in providing the maximum accuracy with D = 7.1k (D = 5.7k) dimensions.\n\nAlthough quantizing the projection matrix reduces the encoding cost, it increases dimensionality, directly impacting training, and inference cost. Figure 7 shows the breakdown of ManiHD energy consumption during the training phase. The energy values are reported for the encoding and training modules. As Figure 7 shows, the encoding module takes 72% the energy consumption over baseline ManiHD (Non-quantized). Quantizing the encoder to lower precision increases the training cost (higher dimensionality) while reducing the encoding cost. The optimized system for learning (encoding and training phase) provides maximum efficiency. This optimization depends on the underlying hardware. Since we select FPGA as hardware implementation, our goal is to select the best quantization that minimizes the total FPGA energy, which includes both encoding and training. Our evaluation shows that 3-bits quantization balances the energy consumption of the encoding and training phase, resulting in maximum efficiency.\n\n\nVI. CONCLUSION\n\nIn this paper, we proposed ManiHD that supports adaptive and trainable encoder for efficient learning in high-dimensional space. ManiHD explicitly considers non-linear interactions between the features during the encoding. This enables ManiHD to provide maximum learning accuracy in much lower dimensionality. ManiHD also enables online learning by sampling data points and capturing the essential features in an unsupervised manner. Our evaluation shows that ManiHD provides, on average, 12.3\u00d7 faster and 19.3\u00d7 more energy-efficient training as compared to state-of-the-art learning algorithms. \n\nFig. 3 .\n3ManiHD framework for online trainable encoder.\n\nFig. 4 .\n4Quality vs efficiency trade-off.\n\nFig. 5 .\n5ManiHD classification accuracy vs. the state-of-the-art algorithms.\n\nFig. 6 .\n6ManiHD efficiency during training and inference phases.\n\nFig. 7 .\n7Impact of the encoder quantization on (a) ManiHD dimensionality that provides a certain accuracy, (b) breakdown of the energy consumption in the encoding and training phases.\n\n\nFig. 2. ManiHD encoder consisting of manifold and non-linear HD encoder.h 1 \n\nf'1 \n\nf'2 \n\nf'k \n\nB 11 \n\nDistribution \n\nf1 \nf2 \nfn \n\nM 1n \nM 12 \nM 2n \nM 22 \n\nM kn \nM k2 \n\nOriginal Data \n\nManifold \n\nn\u00d7k \n\nM 11 \nM 21 \n\nM k1 \n\n\u00d7 Static HD Encoder \n\nk\u00d7D \nk \nAdaptive HD Encoder \n\nn\u00d7D \n\nB 12 \n\nB 1k \n\nB 21 \nB 22 \n\nB 2k \n\nB D1 \nB D2 \n\nB Dk \n\n\u00d7 \n\u00d7 \n\u00d7 \n\ncosine \nh 2 \nh D \n\nManifold Projection \n\n\u00d7 \n\u00d7 \u00d7 \n\nCombined \nFeatures \n\nStatic HD Encoder \n\n= \n\nD \nD \n\nB \n\nA \n\nC \n\n\n\nTABLE I\nIDATASETS (n: FEATURE SIZE, K: NUMBER OF CLASSES) \n\nn \nK \n\nData \nSize \n\nTrain \nSize \n\nTest \nSize \nDescription \n\nMNIST \n784 \n10 \n220MB \n60,000 \n10,000 \nHandwritten Recognition[27] \nPECAN \n312 \n3 \n34MB \n22,290 \n5,574 \nSmart home power prediction [28] \nSPEECH \n617 \n26 \n19MB \n6,238 \n1,559 \nVoice recognition [28], [29] \nUCIHAR \n561 \n12 \n10MB \n6,213 \n1,554 \nActivity recognition(Mobile)[25] \nEXTRA \n225 \n4 \n140MB \n146,869 \n16,343 \nPhone position recognition[30] \n\n\n\nTABLE II THE\nIIIMPACT OF MANIFOLD DATA ON MANIHD EFFICIENCY0 \n0.1% 0.2% \n0.5% \n1% \n1.5% \n1% \n\nDimensions (D) \n10k \n7.5k \n5.5k \n4k \n3.5k \n3.5k \n3k \nManifold Overhead \n0.00 \n0.06 \n0.10 \n0.46 \n0.95 \n1.12 \n1.58 \nTraining Speedup \n1 \n1.07 \n1.32 \n1.52 \n1.34 \n1.04 \n0.86 \nInference Speedup \n1 \n1.06 \n1.38 \n1.81 \n2.07 \n2.01 \n2.31 \n\n\n\nTABLE III IMPACT\nIIIOF STATIC AND ADAPTIVE MANIFOLD LEARNING ON MANIHD CLASSIFICATION ACCURACYSummer \nFall \nWinter \nSpring AVERAGE \n\nStatic Design \n95.2% \n92.7% \n84.7% \n86.1% \n89.7% \nAdaptive Design \n94.4% \n95.2% \n93.6% \n92.6% \n94.0% \n\n\n\nRobust machine learning systems: Challenges, current trends, perspectives, and the road ahead. M Shafique, Nothers , D&T. 372M. Shafique and Nothers, \"Robust machine learning systems: Challenges, current trends, perspectives, and the road ahead,\" D&T, vol. 37, no. 2, pp. 30-57, 2020.\n\nFloatpim: In-memory acceleration of deep neural network training with high precision. M Imani, ISCA. IEEEM. Imani et al., \"Floatpim: In-memory acceleration of deep neural network training with high precision,\" in ISCA, pp. 802-815, IEEE, 2019.\n\nPact: Parameterized clipping activation for quantized neural networks. J Choi, arXiv:1805.06085arXiv preprintJ. Choi et al., \"Pact: Parameterized clipping activation for quantized neural networks,\" arXiv preprint arXiv:1805.06085, 2018.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, Cognitive Computation. 12P. Kanerva, \"Hyperdimensional computing: An introduction to computing in dis- tributed representation with high-dimensional random vectors,\" Cognitive Computa- tion, vol. 1, no. 2, pp. 139-159, 2009.\n\nA framework for collaborative learning in secure high-dimensional space. M Imani, IEEECLOUDM. Imani et al., \"A framework for collaborative learning in secure high-dimensional space,\" in CLOUD, pp. 435-446, IEEE, 2019.\n\nBric: Locality-based encoding for energy-efficient brain-inspired hyperdimensional computing. M Imani, DAC. M. Imani et al., \"Bric: Locality-based encoding for energy-efficient brain-inspired hyperdimensional computing,\" in DAC, pp. 1-6, 2019.\n\nA robust and energy-efficient classifier using brain-inspired hyperdimensional computing. A Rahimi, ISLPED. ACMA. Rahimi et al., \"A robust and energy-efficient classifier using brain-inspired hyper- dimensional computing,\" in ISLPED, pp. 64-69, ACM, 2016.\n\nQuanthd: A quantization framework for hyperdimensional computing. M Imani, TCAD. M. Imani et al., \"Quanthd: A quantization framework for hyperdimensional comput- ing,\" TCAD, 2019.\n\nF5-hd: Fast flexible fpga-based framework for refreshing hyperdimensional computing. S Salamat, FPGA. S. Salamat et al., \"F5-hd: Fast flexible fpga-based framework for refreshing hyperdi- mensional computing,\" in FPGA, pp. 53-62, 2019.\n\nAccelerating hyperdimensional computing on fpgas by exploiting computational reuse. S Salamat, TC. S. Salamat et al., \"Accelerating hyperdimensional computing on fpgas by exploiting computational reuse,\" TC, 2020.\n\nGeniehd: Efficient dna pattern matching accelerator using hyperdimensional computing. Y Kim, DATE. IEEEY. Kim et al., \"Geniehd: Efficient dna pattern matching accelerator using hyperdimen- sional computing,\" in DATE, IEEE, 2020.\n\nPrive-hd: Privacy-preserved hyperdimensional computing. B Khaleghi, arXiv:2005.06716arXiv preprintB. Khaleghi et al., \"Prive-hd: Privacy-preserved hyperdimensional computing,\" arXiv preprint arXiv:2005.06716, 2020.\n\nRevisiting hyperdimensional learning for fpga and low-power architectures. M Imani, HPCA. IEEE2021M. Imani et al., \"Revisiting hyperdimensional learning for fpga and low-power architectures,\" in HPCA, IEEE, 2021.\n\nSparsehd: Algorithm-hardware co-optimization for efficient highdimensional computing. M Imani, FCCM. IEEEM. Imani et al., \"Sparsehd: Algorithm-hardware co-optimization for efficient high- dimensional computing,\" in FCCM, pp. 190-198, IEEE, 2019.\n\ntiny-HD: Ultra-Efficient Hyperdimensional Computing Engine for IoT Applications. B Khaleghi, DATE. 2021IEEEB. Khaleghi et al., \"tiny-HD: Ultra-Efficient Hyperdimensional Computing Engine for IoT Applications,\" in DATE, IEEE, 2021.\n\nThrifty: Training with hyperdimensional computing across flash hierarchy. S Gupta, ICCAD. IEEES. Gupta et al., \"Thrifty: Training with hyperdimensional computing across flash hierarchy,\" in ICCAD, pp. 1-9, IEEE, 2020.\n\nAnalysis of contraction effort level in emg-based gesture recognition using hyperdimensional computing. A Moin, BioCAS. IEEEA. Moin et al., \"Analysis of contraction effort level in emg-based gesture recognition using hyperdimensional computing,\" in BioCAS, pp. 1-4, IEEE, 2019.\n\nLearning sensorimotor control with neuromorphic sensors: Toward hyperdimensional active perception. A Mitrokhin, Science Robotics. 4306736A. Mitrokhin et al., \"Learning sensorimotor control with neuromorphic sensors: Toward hyperdimensional active perception,\" Science Robotics, vol. 4, no. 30, p. eaaw6736, 2019.\n\nHierarchical hyperdimensional computing for energy efficient classification. M Imani, DAC. ACM108M. Imani et al., \"Hierarchical hyperdimensional computing for energy efficient classi- fication,\" in DAC, p. 108, ACM, 2018.\n\nRandom features for large-scale kernel machines. A Rahimi, B Recht, NIPS. A. Rahimi and B. Recht, \"Random features for large-scale kernel machines,\" in NIPS, pp. 1177-1184, 2008.\n\nThe kernel trick for distances. B Sch\u00f6lkopf, NIPS. B. Sch\u00f6lkopf, \"The kernel trick for distances,\" in NIPS, pp. 301-307, 2001.\n\nR Abraham, Manifolds, tensor analysis, and applications. Springer Science & Business Media75R. Abraham et al., Manifolds, tensor analysis, and applications, vol. 75. Springer Science & Business Media, 2012.\n\nMulti-view manifold learning with locality alignment. Y Zhao, Pattern Recognition. 78Y. Zhao et al., \"Multi-view manifold learning with locality alignment,\" Pattern Recognition, vol. 78, pp. 154-166, 2018.\n\nM-isomap: Orthogonal constrained marginal isomap for nonlinear dimensionality reduction. Z Zhang, SMC. 431Z. Zhang et al., \"M-isomap: Orthogonal constrained marginal isomap for nonlinear dimensionality reduction,\" SMC, vol. 43, no. 1, pp. 180-191, 2012.\n\nHuman activity recognition on smartphones using a multiclass hardware-friendly support vector machine. D Anguita, AAL. SpringerD. Anguita et al., \"Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine,\" in AAL, pp. 216-223, Springer, 2012.\n\nScikit-learn: Machine learning in python. F Pedregosa, JMLR. 12F. Pedregosa et al., \"Scikit-learn: Machine learning in python,\" JMLR, vol. 12, no. Oct, pp. 2825-2830, 2011.\n\nGradient-based learning applied to document recognition. Y Lecun, Proceedings of the IEEE. the IEEE86Y. LeCun et al., \"Gradient-based learning applied to document recognition,\" Proceed- ings of the IEEE, vol. 86, no. 11, pp. 2278-2324, 1998.\n\nUci machine learning repository. \"Uci machine learning repository.\" http://archive.ics.uci.edu/ml/datasets/ISOLET.\n\nLooknn: Neural network with no multiplication. M S Razlighi, DATE. IEEEM. S. Razlighi et al., \"Looknn: Neural network with no multiplication,\" in DATE, pp. 1775-1780, IEEE, 2017.\n\nRecognizing detailed human context in the wild from smartphones and smartwatches. Y Vaizman, IEEE Pervasive Computing. 164Y. Vaizman et al., \"Recognizing detailed human context in the wild from smartphones and smartwatches,\" IEEE Pervasive Computing, vol. 16, no. 4, pp. 62-74, 2017.\n\nTensorflow: Large-scale machine learning on heterogeneous distributed systems. M Abadi, arXiv:1603.04467arXiv preprintM. Abadi et al., \"Tensorflow: Large-scale machine learning on heterogeneous dis- tributed systems,\" arXiv preprint arXiv:1603.04467, 2016.\n\nFrom high-level deep neural models to fpgas. H Sharma, IEEE17MICROH. Sharma et al., \"From high-level deep neural models to fpgas,\" in MICRO, p. 17, IEEE, 2016.\n\nFpdeep: Acceleration and load balancing of cnn training on fpga clusters. T Geng, FCCM. IEEET. Geng et al., \"Fpdeep: Acceleration and load balancing of cnn training on fpga clusters,\" in FCCM, pp. 81-84, IEEE, 2018.\n", "annotations": {"author": "[{\"start\":\"81\",\"end\":\"93\"},{\"start\":\"94\",\"end\":\"114\"},{\"start\":\"115\",\"end\":\"157\"},{\"start\":\"158\",\"end\":\"221\"},{\"start\":\"222\",\"end\":\"259\"}]", "publisher": null, "author_last_name": "[{\"start\":\"89\",\"end\":\"92\"},{\"start\":\"102\",\"end\":\"105\"},{\"start\":\"124\",\"end\":\"130\"},{\"start\":\"165\",\"end\":\"170\"}]", "author_first_name": "[{\"start\":\"81\",\"end\":\"88\"},{\"start\":\"94\",\"end\":\"101\"},{\"start\":\"115\",\"end\":\"116\"},{\"start\":\"117\",\"end\":\"123\"},{\"start\":\"158\",\"end\":\"164\"}]", "author_affiliation": "[{\"start\":\"107\",\"end\":\"113\"},{\"start\":\"132\",\"end\":\"156\"},{\"start\":\"188\",\"end\":\"220\"},{\"start\":\"223\",\"end\":\"258\"}]", "title": "[{\"start\":\"1\",\"end\":\"78\"},{\"start\":\"260\",\"end\":\"337\"}]", "venue": null, "abstract": "[{\"start\":\"339\",\"end\":\"1935\"}]", "bib_ref": "[{\"start\":\"2293\",\"end\":\"2296\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"2298\",\"end\":\"2301\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"2428\",\"end\":\"2431\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"2751\",\"end\":\"2754\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"2756\",\"end\":\"2759\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"2761\",\"end\":\"2764\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"2885\",\"end\":\"2888\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"3357\",\"end\":\"3360\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"3362\",\"end\":\"3365\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"3367\",\"end\":\"3370\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"3372\",\"end\":\"3376\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"3544\",\"end\":\"3548\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"3550\",\"end\":\"3554\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"3755\",\"end\":\"3759\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"3761\",\"end\":\"3765\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"3767\",\"end\":\"3771\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"4092\",\"end\":\"4095\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"4097\",\"end\":\"4100\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"4102\",\"end\":\"4105\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"4107\",\"end\":\"4111\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"6192\",\"end\":\"6195\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"6197\",\"end\":\"6200\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"6202\",\"end\":\"6206\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"7099\",\"end\":\"7103\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"7105\",\"end\":\"7109\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"7111\",\"end\":\"7114\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"11341\",\"end\":\"11345\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"11347\",\"end\":\"11351\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"12878\",\"end\":\"12882\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"12884\",\"end\":\"12888\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"13356\",\"end\":\"13360\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"13362\",\"end\":\"13366\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"18371\",\"end\":\"18375\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"19948\",\"end\":\"19952\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"20020\",\"end\":\"20023\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"20588\",\"end\":\"20592\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"20819\",\"end\":\"20823\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"20867\",\"end\":\"20871\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"24477\",\"end\":\"24481\",\"attributes\":{\"ref_id\":\"b31\"}},{\"start\":\"24544\",\"end\":\"24548\",\"attributes\":{\"ref_id\":\"b32\"}}]", "figure": "[{\"start\":\"30355\",\"end\":\"30412\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"30413\",\"end\":\"30456\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"30457\",\"end\":\"30535\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"30536\",\"end\":\"30602\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"30603\",\"end\":\"30788\",\"attributes\":{\"id\":\"fig_5\"}},{\"start\":\"30789\",\"end\":\"31249\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"31250\",\"end\":\"31719\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}},{\"start\":\"31720\",\"end\":\"32045\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}},{\"start\":\"32046\",\"end\":\"32283\",\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"1954\",\"end\":\"2571\"},{\"start\":\"2573\",\"end\":\"3772\"},{\"start\":\"3774\",\"end\":\"4398\"},{\"start\":\"4400\",\"end\":\"4696\"},{\"start\":\"4698\",\"end\":\"5487\"},{\"start\":\"5489\",\"end\":\"6808\"},{\"start\":\"6842\",\"end\":\"7589\"},{\"start\":\"7591\",\"end\":\"8013\"},{\"start\":\"8054\",\"end\":\"8229\"},{\"start\":\"8231\",\"end\":\"8772\"},{\"start\":\"8827\",\"end\":\"9072\"},{\"start\":\"9074\",\"end\":\"9637\"},{\"start\":\"9655\",\"end\":\"10090\"},{\"start\":\"10124\",\"end\":\"11082\"},{\"start\":\"11109\",\"end\":\"11456\"},{\"start\":\"11600\",\"end\":\"12535\"},{\"start\":\"12560\",\"end\":\"13161\"},{\"start\":\"13163\",\"end\":\"13774\"},{\"start\":\"13776\",\"end\":\"14496\"},{\"start\":\"14498\",\"end\":\"15780\"},{\"start\":\"15811\",\"end\":\"16173\"},{\"start\":\"16206\",\"end\":\"17126\"},{\"start\":\"17161\",\"end\":\"17968\"},{\"start\":\"17970\",\"end\":\"19086\"},{\"start\":\"19088\",\"end\":\"19705\"},{\"start\":\"19745\",\"end\":\"21773\"},{\"start\":\"21843\",\"end\":\"24121\"},{\"start\":\"24146\",\"end\":\"26225\"},{\"start\":\"26257\",\"end\":\"27898\"},{\"start\":\"27934\",\"end\":\"28730\"},{\"start\":\"28732\",\"end\":\"29739\"},{\"start\":\"29758\",\"end\":\"30354\"}]", "formula": "[{\"start\":\"8014\",\"end\":\"8053\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"8773\",\"end\":\"8826\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"11457\",\"end\":\"11599\",\"attributes\":{\"id\":\"formula_2\"}}]", "table_ref": "[{\"start\":\"20270\",\"end\":\"20277\",\"attributes\":{\"ref_id\":\"tab_2\"}},{\"start\":\"22393\",\"end\":\"22401\",\"attributes\":{\"ref_id\":\"tab_2\"}},{\"start\":\"22762\",\"end\":\"22770\",\"attributes\":{\"ref_id\":\"tab_2\"}},{\"start\":\"23800\",\"end\":\"23808\",\"attributes\":{\"ref_id\":\"tab_2\"}},{\"start\":\"27308\",\"end\":\"27317\",\"attributes\":{\"ref_id\":\"tab_2\"}}]", "section_header": "[{\"start\":\"1937\",\"end\":\"1952\"},{\"start\":\"6811\",\"end\":\"6840\"},{\"start\":\"9640\",\"end\":\"9653\"},{\"start\":\"10093\",\"end\":\"10122\"},{\"start\":\"11085\",\"end\":\"11107\"},{\"start\":\"12538\",\"end\":\"12558\"},{\"start\":\"15783\",\"end\":\"15809\"},{\"start\":\"16176\",\"end\":\"16204\"},{\"start\":\"17129\",\"end\":\"17159\"},{\"start\":\"19708\",\"end\":\"19743\"},{\"start\":\"21776\",\"end\":\"21809\"},{\"start\":\"21812\",\"end\":\"21841\"},{\"start\":\"24124\",\"end\":\"24144\"},{\"start\":\"26228\",\"end\":\"26255\"},{\"start\":\"27901\",\"end\":\"27932\"},{\"start\":\"29742\",\"end\":\"29756\"},{\"start\":\"30356\",\"end\":\"30364\"},{\"start\":\"30414\",\"end\":\"30422\"},{\"start\":\"30458\",\"end\":\"30466\"},{\"start\":\"30537\",\"end\":\"30545\"},{\"start\":\"30604\",\"end\":\"30612\"},{\"start\":\"31251\",\"end\":\"31258\"},{\"start\":\"31721\",\"end\":\"31733\"},{\"start\":\"32047\",\"end\":\"32063\"}]", "table": "[{\"start\":\"30863\",\"end\":\"31249\"},{\"start\":\"31260\",\"end\":\"31719\"},{\"start\":\"31780\",\"end\":\"32045\"},{\"start\":\"32141\",\"end\":\"32283\"}]", "figure_caption": "[{\"start\":\"30366\",\"end\":\"30412\"},{\"start\":\"30424\",\"end\":\"30456\"},{\"start\":\"30468\",\"end\":\"30535\"},{\"start\":\"30547\",\"end\":\"30602\"},{\"start\":\"30614\",\"end\":\"30788\"},{\"start\":\"30791\",\"end\":\"30863\"},{\"start\":\"31736\",\"end\":\"31780\"},{\"start\":\"32067\",\"end\":\"32141\"}]", "figure_ref": "[{\"start\":\"6015\",\"end\":\"6023\"},{\"start\":\"11353\",\"end\":\"11362\"},{\"start\":\"14256\",\"end\":\"14264\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"14485\",\"end\":\"14494\"},{\"start\":\"14968\",\"end\":\"14977\"},{\"start\":\"15465\",\"end\":\"15474\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"17833\",\"end\":\"17841\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"18291\",\"end\":\"18300\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"18474\",\"end\":\"18483\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"20318\",\"end\":\"20326\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"24224\",\"end\":\"24232\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"24949\",\"end\":\"24957\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"25821\",\"end\":\"25830\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"28398\",\"end\":\"28406\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"28879\",\"end\":\"28887\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"29037\",\"end\":\"29045\",\"attributes\":{\"ref_id\":\"fig_5\"}}]", "bib_author_first_name": "[{\"start\":\"32380\",\"end\":\"32381\"},{\"start\":\"32392\",\"end\":\"32399\"},{\"start\":\"32657\",\"end\":\"32658\"},{\"start\":\"32887\",\"end\":\"32888\"},{\"start\":\"33179\",\"end\":\"33180\"},{\"start\":\"33489\",\"end\":\"33490\"},{\"start\":\"33729\",\"end\":\"33730\"},{\"start\":\"33970\",\"end\":\"33971\"},{\"start\":\"34203\",\"end\":\"34204\"},{\"start\":\"34403\",\"end\":\"34404\"},{\"start\":\"34639\",\"end\":\"34640\"},{\"start\":\"34856\",\"end\":\"34857\"},{\"start\":\"35056\",\"end\":\"35057\"},{\"start\":\"35291\",\"end\":\"35292\"},{\"start\":\"35516\",\"end\":\"35517\"},{\"start\":\"35758\",\"end\":\"35759\"},{\"start\":\"35983\",\"end\":\"35984\"},{\"start\":\"36232\",\"end\":\"36233\"},{\"start\":\"36507\",\"end\":\"36508\"},{\"start\":\"36799\",\"end\":\"36800\"},{\"start\":\"36994\",\"end\":\"36995\"},{\"start\":\"37004\",\"end\":\"37005\"},{\"start\":\"37157\",\"end\":\"37158\"},{\"start\":\"37253\",\"end\":\"37254\"},{\"start\":\"37515\",\"end\":\"37516\"},{\"start\":\"37757\",\"end\":\"37758\"},{\"start\":\"38026\",\"end\":\"38027\"},{\"start\":\"38254\",\"end\":\"38255\"},{\"start\":\"38443\",\"end\":\"38444\"},{\"start\":\"38792\",\"end\":\"38793\"},{\"start\":\"38794\",\"end\":\"38795\"},{\"start\":\"39007\",\"end\":\"39008\"},{\"start\":\"39289\",\"end\":\"39290\"},{\"start\":\"39513\",\"end\":\"39514\"},{\"start\":\"39703\",\"end\":\"39704\"}]", "bib_author_last_name": "[{\"start\":\"32382\",\"end\":\"32390\"},{\"start\":\"32659\",\"end\":\"32664\"},{\"start\":\"32889\",\"end\":\"32893\"},{\"start\":\"33181\",\"end\":\"33188\"},{\"start\":\"33491\",\"end\":\"33496\"},{\"start\":\"33731\",\"end\":\"33736\"},{\"start\":\"33972\",\"end\":\"33978\"},{\"start\":\"34205\",\"end\":\"34210\"},{\"start\":\"34405\",\"end\":\"34412\"},{\"start\":\"34641\",\"end\":\"34648\"},{\"start\":\"34858\",\"end\":\"34861\"},{\"start\":\"35058\",\"end\":\"35066\"},{\"start\":\"35293\",\"end\":\"35298\"},{\"start\":\"35518\",\"end\":\"35523\"},{\"start\":\"35760\",\"end\":\"35768\"},{\"start\":\"35985\",\"end\":\"35990\"},{\"start\":\"36234\",\"end\":\"36238\"},{\"start\":\"36509\",\"end\":\"36518\"},{\"start\":\"36801\",\"end\":\"36806\"},{\"start\":\"36996\",\"end\":\"37002\"},{\"start\":\"37006\",\"end\":\"37011\"},{\"start\":\"37159\",\"end\":\"37168\"},{\"start\":\"37255\",\"end\":\"37262\"},{\"start\":\"37517\",\"end\":\"37521\"},{\"start\":\"37759\",\"end\":\"37764\"},{\"start\":\"38028\",\"end\":\"38035\"},{\"start\":\"38256\",\"end\":\"38265\"},{\"start\":\"38445\",\"end\":\"38450\"},{\"start\":\"38796\",\"end\":\"38804\"},{\"start\":\"39009\",\"end\":\"39016\"},{\"start\":\"39291\",\"end\":\"39296\"},{\"start\":\"39515\",\"end\":\"39521\"},{\"start\":\"39705\",\"end\":\"39709\"}]", "bib_entry": "[{\"start\":\"32285\",\"end\":\"32569\",\"attributes\":{\"matched_paper_id\":\"214465428\",\"id\":\"b0\"}},{\"start\":\"32571\",\"end\":\"32814\",\"attributes\":{\"matched_paper_id\":\"189818835\",\"id\":\"b1\"}},{\"start\":\"32816\",\"end\":\"33052\",\"attributes\":{\"id\":\"b2\",\"doi\":\"arXiv:1805.06085\"}},{\"start\":\"33054\",\"end\":\"33414\",\"attributes\":{\"matched_paper_id\":\"733980\",\"id\":\"b3\"}},{\"start\":\"33416\",\"end\":\"33633\",\"attributes\":{\"id\":\"b4\"}},{\"start\":\"33635\",\"end\":\"33878\",\"attributes\":{\"matched_paper_id\":\"163164623\",\"id\":\"b5\"}},{\"start\":\"33880\",\"end\":\"34135\",\"attributes\":{\"matched_paper_id\":\"9812826\",\"id\":\"b6\"}},{\"start\":\"34137\",\"end\":\"34316\",\"attributes\":{\"matched_paper_id\":\"211016154\",\"id\":\"b7\"}},{\"start\":\"34318\",\"end\":\"34553\",\"attributes\":{\"matched_paper_id\":\"67872077\",\"id\":\"b8\"}},{\"start\":\"34555\",\"end\":\"34768\",\"attributes\":{\"matched_paper_id\":\"218934679\",\"id\":\"b9\"}},{\"start\":\"34770\",\"end\":\"34998\",\"attributes\":{\"matched_paper_id\":\"219858990\",\"id\":\"b10\"}},{\"start\":\"35000\",\"end\":\"35214\",\"attributes\":{\"id\":\"b11\",\"doi\":\"arXiv:2005.06716\"}},{\"start\":\"35216\",\"end\":\"35428\",\"attributes\":{\"matched_paper_id\":\"233376633\",\"id\":\"b12\"}},{\"start\":\"35430\",\"end\":\"35675\",\"attributes\":{\"matched_paper_id\":\"189824904\",\"id\":\"b13\"}},{\"start\":\"35677\",\"end\":\"35907\",\"attributes\":{\"matched_paper_id\":\"236150314\",\"id\":\"b14\"}},{\"start\":\"35909\",\"end\":\"36126\",\"attributes\":{\"matched_paper_id\":\"227069231\",\"id\":\"b15\"}},{\"start\":\"36128\",\"end\":\"36405\",\"attributes\":{\"matched_paper_id\":\"202538018\",\"id\":\"b16\"}},{\"start\":\"36407\",\"end\":\"36720\",\"attributes\":{\"matched_paper_id\":\"182118830\",\"id\":\"b17\"}},{\"start\":\"36722\",\"end\":\"36943\",\"attributes\":{\"matched_paper_id\":\"49301394\",\"id\":\"b18\"}},{\"start\":\"36945\",\"end\":\"37123\",\"attributes\":{\"matched_paper_id\":\"877929\",\"id\":\"b19\"}},{\"start\":\"37125\",\"end\":\"37251\",\"attributes\":{\"matched_paper_id\":\"7728339\",\"id\":\"b20\"}},{\"start\":\"37253\",\"end\":\"37459\",\"attributes\":{\"id\":\"b21\"}},{\"start\":\"37461\",\"end\":\"37666\",\"attributes\":{\"matched_paper_id\":\"3843646\",\"id\":\"b22\"}},{\"start\":\"37668\",\"end\":\"37921\",\"attributes\":{\"matched_paper_id\":\"7102842\",\"id\":\"b23\"}},{\"start\":\"37923\",\"end\":\"38210\",\"attributes\":{\"matched_paper_id\":\"13178535\",\"id\":\"b24\"}},{\"start\":\"38212\",\"end\":\"38384\",\"attributes\":{\"matched_paper_id\":\"10659969\",\"id\":\"b25\"}},{\"start\":\"38386\",\"end\":\"38627\",\"attributes\":{\"matched_paper_id\":\"14542261\",\"id\":\"b26\"}},{\"start\":\"38629\",\"end\":\"38743\",\"attributes\":{\"id\":\"b27\"}},{\"start\":\"38745\",\"end\":\"38923\",\"attributes\":{\"matched_paper_id\":\"34011320\",\"id\":\"b28\"}},{\"start\":\"38925\",\"end\":\"39208\",\"attributes\":{\"matched_paper_id\":\"8728742\",\"id\":\"b29\"}},{\"start\":\"39210\",\"end\":\"39466\",\"attributes\":{\"id\":\"b30\",\"doi\":\"arXiv:1603.04467\"}},{\"start\":\"39468\",\"end\":\"39627\",\"attributes\":{\"id\":\"b31\"}},{\"start\":\"39629\",\"end\":\"39844\",\"attributes\":{\"matched_paper_id\":\"21751865\",\"id\":\"b32\"}}]", "bib_title": "[{\"start\":\"32285\",\"end\":\"32378\"},{\"start\":\"32571\",\"end\":\"32655\"},{\"start\":\"33054\",\"end\":\"33177\"},{\"start\":\"33635\",\"end\":\"33727\"},{\"start\":\"33880\",\"end\":\"33968\"},{\"start\":\"34137\",\"end\":\"34201\"},{\"start\":\"34318\",\"end\":\"34401\"},{\"start\":\"34555\",\"end\":\"34637\"},{\"start\":\"34770\",\"end\":\"34854\"},{\"start\":\"35216\",\"end\":\"35289\"},{\"start\":\"35430\",\"end\":\"35514\"},{\"start\":\"35677\",\"end\":\"35756\"},{\"start\":\"35909\",\"end\":\"35981\"},{\"start\":\"36128\",\"end\":\"36230\"},{\"start\":\"36407\",\"end\":\"36505\"},{\"start\":\"36722\",\"end\":\"36797\"},{\"start\":\"36945\",\"end\":\"36992\"},{\"start\":\"37125\",\"end\":\"37155\"},{\"start\":\"37461\",\"end\":\"37513\"},{\"start\":\"37668\",\"end\":\"37755\"},{\"start\":\"37923\",\"end\":\"38024\"},{\"start\":\"38212\",\"end\":\"38252\"},{\"start\":\"38386\",\"end\":\"38441\"},{\"start\":\"38745\",\"end\":\"38790\"},{\"start\":\"38925\",\"end\":\"39005\"},{\"start\":\"39629\",\"end\":\"39701\"}]", "bib_author": "[{\"start\":\"32380\",\"end\":\"32392\"},{\"start\":\"32392\",\"end\":\"32402\"},{\"start\":\"32657\",\"end\":\"32666\"},{\"start\":\"32887\",\"end\":\"32895\"},{\"start\":\"33179\",\"end\":\"33190\"},{\"start\":\"33489\",\"end\":\"33498\"},{\"start\":\"33729\",\"end\":\"33738\"},{\"start\":\"33970\",\"end\":\"33980\"},{\"start\":\"34203\",\"end\":\"34212\"},{\"start\":\"34403\",\"end\":\"34414\"},{\"start\":\"34639\",\"end\":\"34650\"},{\"start\":\"34856\",\"end\":\"34863\"},{\"start\":\"35056\",\"end\":\"35068\"},{\"start\":\"35291\",\"end\":\"35300\"},{\"start\":\"35516\",\"end\":\"35525\"},{\"start\":\"35758\",\"end\":\"35770\"},{\"start\":\"35983\",\"end\":\"35992\"},{\"start\":\"36232\",\"end\":\"36240\"},{\"start\":\"36507\",\"end\":\"36520\"},{\"start\":\"36799\",\"end\":\"36808\"},{\"start\":\"36994\",\"end\":\"37004\"},{\"start\":\"37004\",\"end\":\"37013\"},{\"start\":\"37157\",\"end\":\"37170\"},{\"start\":\"37253\",\"end\":\"37264\"},{\"start\":\"37515\",\"end\":\"37523\"},{\"start\":\"37757\",\"end\":\"37766\"},{\"start\":\"38026\",\"end\":\"38037\"},{\"start\":\"38254\",\"end\":\"38267\"},{\"start\":\"38443\",\"end\":\"38452\"},{\"start\":\"38792\",\"end\":\"38806\"},{\"start\":\"39007\",\"end\":\"39018\"},{\"start\":\"39289\",\"end\":\"39298\"},{\"start\":\"39513\",\"end\":\"39523\"},{\"start\":\"39703\",\"end\":\"39711\"}]", "bib_venue": "[{\"start\":\"32402\",\"end\":\"32405\"},{\"start\":\"32666\",\"end\":\"32670\"},{\"start\":\"32816\",\"end\":\"32885\"},{\"start\":\"33190\",\"end\":\"33211\"},{\"start\":\"33416\",\"end\":\"33487\"},{\"start\":\"33738\",\"end\":\"33741\"},{\"start\":\"33980\",\"end\":\"33986\"},{\"start\":\"34212\",\"end\":\"34216\"},{\"start\":\"34414\",\"end\":\"34418\"},{\"start\":\"34650\",\"end\":\"34652\"},{\"start\":\"34863\",\"end\":\"34867\"},{\"start\":\"35000\",\"end\":\"35054\"},{\"start\":\"35300\",\"end\":\"35304\"},{\"start\":\"35525\",\"end\":\"35529\"},{\"start\":\"35770\",\"end\":\"35774\"},{\"start\":\"35992\",\"end\":\"35997\"},{\"start\":\"36240\",\"end\":\"36246\"},{\"start\":\"36520\",\"end\":\"36536\"},{\"start\":\"36808\",\"end\":\"36811\"},{\"start\":\"37013\",\"end\":\"37017\"},{\"start\":\"37170\",\"end\":\"37174\"},{\"start\":\"37264\",\"end\":\"37308\"},{\"start\":\"37523\",\"end\":\"37542\"},{\"start\":\"37766\",\"end\":\"37769\"},{\"start\":\"38037\",\"end\":\"38040\"},{\"start\":\"38267\",\"end\":\"38271\"},{\"start\":\"38452\",\"end\":\"38475\"},{\"start\":\"38629\",\"end\":\"38660\"},{\"start\":\"38806\",\"end\":\"38810\"},{\"start\":\"39018\",\"end\":\"39042\"},{\"start\":\"39210\",\"end\":\"39287\"},{\"start\":\"39468\",\"end\":\"39511\"},{\"start\":\"39711\",\"end\":\"39715\"},{\"start\":\"38477\",\"end\":\"38485\"}]"}}}, "year": 2023, "month": 12, "day": 17}