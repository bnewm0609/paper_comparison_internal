{"id": 198953378, "updated": "2023-12-15 14:41:11.32", "metadata": {"title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "authors": "[{\"first\":\"Yinhan\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Myle\",\"last\":\"Ott\",\"middle\":[]},{\"first\":\"Naman\",\"last\":\"Goyal\",\"middle\":[]},{\"first\":\"Jingfei\",\"last\":\"Du\",\"middle\":[]},{\"first\":\"Mandar\",\"last\":\"Joshi\",\"middle\":[]},{\"first\":\"Danqi\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Omer\",\"last\":\"Levy\",\"middle\":[]},{\"first\":\"Mike\",\"last\":\"Lewis\",\"middle\":[]},{\"first\":\"Luke\",\"last\":\"Zettlemoyer\",\"middle\":[]},{\"first\":\"Veselin\",\"last\":\"Stoyanov\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2019, "month": 7, "day": 26}, "abstract": "Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2965373594", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-1907-11692", "doi": null}}, "content": {"source": {"pdf_hash": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1907.11692v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "de1de3513a006d894302f61541b1e1b385d0bc9f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/077f8329a7b6fa3b7c877a57b81eb6c18b5f87de.txt", "contents": "\nRoBERTa: A Robustly Optimized BERT Pretraining Approach\n26 Jul 2019\n\nYinhan Liu yinhanliu@fb.com \nFacebook AI\n\n\nMyle Ott myleott@fb.com \nFacebook AI\n\n\nNaman Goyal \nFacebook AI\n\n\nJingfei Du jingfeidu@fb.com \nFacebook AI\n\n\nMandar Joshi mandar90@cs.washington.edu \nDanqi Chen \nFacebook AI\n\n\nOmer Levy omerlevy@fb.com \nFacebook AI\n\n\nMike Lewis mikelewis@fb.com \nFacebook AI\n\n\nLuke Zettlemoyer \nFacebook AI\n\n\nVeselin Stoyanov \nFacebook AI\n\n\nPaul G Allen \n\nSchool of Computer Science & Engineering\nUniversity of Washington\nSeattleWA\n\nRoBERTa: A Robustly Optimized BERT Pretraining Approach\n26 Jul 2019\nLanguage model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code. 1 * Equal contribution. 1 Our models and code are available at: https://github.com/pytorch/fairseq\n\nIntroduction\n\nSelf-training methods such as ELMo (Peters et al., 2018), GPT (Radford et al., 2018), BERT (Devlin et al., 2019), XLM (Lample and Conneau, 2019), and XLNet  have brought significant performance gains, but it can be challenging to determine which aspects of the methods contribute the most. Training is computationally expensive, limiting the amount of tuning that can be done, and is often done with private training data of varying sizes, limiting our ability to measure the effects of the modeling advances.\n\nWe present a replication study of BERT pretraining (Devlin et al., 2019), which includes a careful evaluation of the effects of hyperparmeter tuning and training set size. We find that BERT was significantly undertrained and propose an improved recipe for training BERT models, which we call RoBERTa, that can match or exceed the performance of all of the post-BERT methods. Our modifications are simple, they include: (1) training the model longer, with bigger batches, over more data; (2) removing the next sentence prediction objective; (3) training on longer sequences; and (4) dynamically changing the masking pattern applied to the training data. We also collect a large new dataset (CC-NEWS) of comparable size to other privately used datasets, to better control for training set size effects.\n\nWhen controlling for training data, our improved training procedure improves upon the published BERT results on both GLUE and SQuAD. When trained for longer over additional data, our model achieves a score of 88.5 on the public GLUE leaderboard, matching the 88.4 reported by Yang et al. (2019). Our model establishes a new state-of-the-art on 4/9 of the GLUE tasks: MNLI, QNLI, RTE and STS-B. We also match state-of-the-art results on SQuAD and RACE. Overall, we re-establish that BERT's masked language model training objective is competitive with other recently proposed training objectives such as perturbed autoregressive language modeling . 2 In summary, the contributions of this paper are: (1) We present a set of important BERT design choices and training strategies and introduce alternatives that lead to better downstream task performance; (2) We use a novel dataset, CC-NEWS, and confirm that using more data for pretraining further improves performance on downstream tasks; (3) Our training improvements show that masked language model pretraining, under the right design choices, is competitive with all other recently published methods. We release our model, pretraining and fine-tuning code implemented in PyTorch (Paszke et al., 2017).\n\n\nBackground\n\nIn this section, we give a brief overview of the BERT (Devlin et al., 2019) pretraining approach and some of the training choices that we will examine experimentally in the following section.\n\n\nSetup\n\nBERT takes as input a concatenation of two segments (sequences of tokens), x 1 , . . . , x N and y 1 , . . . , y M . Segments usually consist of more than one natural sentence. The two segments are presented as a single input sequence to BERT with special tokens delimiting them:\n[CLS ], x 1 , . . . , x N , [SEP ], y 1 , . . . , y M , [EOS ].\nM and N are constrained such that M + N < T , where T is a parameter that controls the maximum sequence length during training.\n\nThe model is first pretrained on a large unlabeled text corpus and subsequently finetuned using end-task labeled data.\n\n\nArchitecture\n\nBERT uses the now ubiquitous transformer architecture (Vaswani et al., 2017), which we will not review in detail. We use a transformer architecture with L layers. Each block uses A self-attention heads and hidden dimension H.\n\n\nTraining Objectives\n\nDuring pretraining, BERT uses two objectives: masked language modeling and next sentence prediction.\n\nMasked Language Model (MLM) A random sample of the tokens in the input sequence is selected and replaced with the special token [MASK ]. The MLM objective is a cross-entropy loss on predicting the masked tokens. BERT uniformly selects 15% of the input tokens for possible replacement. Of the selected tokens, 80% are replaced with [MASK ], 10% are left unchanged, and 10% are replaced by a randomly selected vocabulary token.\n\nIn the original implementation, random masking and replacement is performed once in the beginning and saved for the duration of training, although in practice, data is duplicated so the mask is not always the same for every training sentence (see Section 4.1).\n\nNext Sentence Prediction (NSP) NSP is a binary classification loss for predicting whether two segments follow each other in the original text. Positive examples are created by taking consecutive sentences from the text corpus. Negative examples are created by pairing segments from different documents. Positive and negative examples are sampled with equal probability.\n\nThe NSP objective was designed to improve performance on downstream tasks, such as Natural Language Inference (Bowman et al., 2015), which require reasoning about the relationships between pairs of sentences.\n\n\nOptimization\n\nBERT is optimized with Adam (Kingma and Ba, 2015) using the following parameters: \u03b2 1 = 0.9, \u03b2 2 = 0.999, \u01eb = 1e-6 and L 2 weight decay of 0.01. The learning rate is warmed up over the first 10,000 steps to a peak value of 1e-4, and then linearly decayed. BERT trains with a dropout of 0.1 on all layers and attention weights, and a GELU activation function (Hendrycks and Gimpel, 2016). Models are pretrained for S = 1,000,000 updates, with minibatches containing B = 256 sequences of maximum length T = 512 tokens.\n\n\nData\n\nBERT is trained on a combination of BOOKCOR-PUS (Zhu et al., 2015) plus English WIKIPEDIA, which totals 16GB of uncompressed text. 3\n\n\nExperimental Setup\n\nIn this section, we describe the experimental setup for our replication study of BERT.\n\n\nImplementation\n\nWe reimplement BERT in FAIRSEQ (Ott et al., 2019). We primarily follow the original BERT optimization hyperparameters, given in Section 2, except for the peak learning rate and number of warmup steps, which are tuned separately for each setting. We additionally found training to be very sensitive to the Adam epsilon term, and in some cases we obtained better performance or improved stability after tuning it. Similarly, we found setting \u03b2 2 = 0.98 to improve stability when training with large batch sizes.\n\nWe pretrain with sequences of at most T = 512 tokens. Unlike Devlin et al. (2019), we do not randomly inject short sequences, and we do not train with a reduced sequence length for the first 90% of updates. We train only with full-length sequences.\n\nWe train with mixed precision floating point arithmetic on DGX-1 machines, each with 8 \u00d7 32GB Nvidia V100 GPUs interconnected by Infiniband (Micikevicius et al., 2018).\n\n\nData\n\nBERT-style pretraining crucially relies on large quantities of text.  demonstrate that increasing data size can result in improved end-task performance. Several efforts have trained on datasets larger and more diverse than the original BERT (Radford et al., 2019;Yang et al., 2019;Zellers et al., 2019). Unfortunately, not all of the additional datasets can be publicly released. For our study, we focus on gathering as much data as possible for experimentation, allowing us to match the overall quality and quantity of data as appropriate for each comparison.\n\nWe consider five English-language corpora of varying sizes and domains, totaling over 160GB of uncompressed text. We use the following text corpora:\n\n\u2022 BOOKCORPUS (Zhu et al., 2015) plus English WIKIPEDIA. This is the original data used to train BERT. (16GB).\n\n\u2022 CC-NEWS, which we collected from the English portion of the CommonCrawl News dataset (Nagel, 2016). The data contains 63 million English news articles crawled between September 2016 and February 2019. (76GB after filtering). 4\n\n\u2022 OPENWEBTEXT (Gokaslan and Cohen, 2019), an open-source recreation of the WebText cor-pus described in Radford et al. (2019). The text is web content extracted from URLs shared on Reddit with at least three upvotes. (38GB). 5\n\n\u2022 STORIES, a dataset introduced in Trinh and Le (2018) containing a subset of CommonCrawl data filtered to match the story-like style of Winograd schemas. (31GB).\n\n\nEvaluation\n\nFollowing previous work, we evaluate our pretrained models on downstream tasks using the following three benchmarks.\n\nGLUE The General Language Understanding Evaluation (GLUE) benchmark (Wang et al., 2019b) is a collection of 9 datasets for evaluating natural language understanding systems. 6 Tasks are framed as either single-sentence classification or sentence-pair classification tasks. The GLUE organizers provide training and development data splits as well as a submission server and leaderboard that allows participants to evaluate and compare their systems on private held-out test data. For the replication study in Section 4, we report results on the development sets after finetuning the pretrained models on the corresponding singletask training data (i.e., without multi-task training or ensembling). Our finetuning procedure follows the original BERT paper (Devlin et al., 2019).\n\nIn Section 5 we additionally report test set results obtained from the public leaderboard. These results depend on a several task-specific modifications, which we describe in Section 5.1.\n\nSQuAD The Stanford Question Answering Dataset (SQuAD) provides a paragraph of context and a question. The task is to answer the question by extracting the relevant span from the context. We evaluate on two versions of SQuAD: V1.1 and V2.0 (Rajpurkar et al., 2016(Rajpurkar et al., , 2018. In V1.1 the context always contains an answer, whereas in V2.0 some questions are not answered in the provided context, making the task more challenging.\n\nFor SQuAD V1.1 we adopt the same span prediction method as BERT (Devlin et al., 2019). For SQuAD V2.0, we add an additional binary classifier to predict whether the question is answerable, which we train jointly by summing the classification and span loss terms. During evaluation, we only predict span indices on pairs that are classified as answerable.\n\nRACE The ReAding Comprehension from Examinations (RACE) (Lai et al., 2017) task is a large-scale reading comprehension dataset with more than 28,000 passages and nearly 100,000 questions. The dataset is collected from English examinations in China, which are designed for middle and high school students. In RACE, each passage is associated with multiple questions. For every question, the task is to select one correct answer from four options. RACE has significantly longer context than other popular reading comprehension datasets and the proportion of questions that requires reasoning is very large.\n\n\nTraining Procedure Analysis\n\nThis section explores and quantifies which choices are important for successfully pretraining BERT models. We keep the model architecture fixed. 7 Specifically, we begin by training BERT models with the same configuration as BERT BASE (L = 12, H = 768, A = 12, 110M params).\n\n\nStatic vs. Dynamic Masking\n\nAs discussed in Section 2, BERT relies on randomly masking and predicting tokens. The original BERT implementation performed masking once during data preprocessing, resulting in a single static mask. To avoid using the same mask for each training instance in every epoch, training data was duplicated 10 times so that each sequence is masked in 10 different ways over the 40 epochs of training. Thus, each training sequence was seen with the same mask four times during training.\n\nWe compare this strategy with dynamic masking where we generate the masking pattern every time we feed a sequence to the model. This becomes crucial when pretraining for more steps or with larger datasets. Results Table 1 compares the published BERT BASE results from Devlin et al. (2019) to our reimplementation with either static or dynamic masking. We find that our reimplementation with static masking performs similar to the original BERT model, and dynamic masking is comparable or slightly better than static masking. Given these results and the additional efficiency benefits of dynamic masking, we use dynamic masking in the remainder of the experiments.\n\n\nModel Input Format and Next Sentence Prediction\n\nIn the original BERT pretraining procedure, the model observes two concatenated document segments, which are either sampled contiguously from the same document (with p = 0.5) or from distinct documents. In addition to the masked language modeling objective, the model is trained to predict whether the observed document segments come from the same or distinct documents via an auxiliary Next Sentence Prediction (NSP) loss. The NSP loss was hypothesized to be an important factor in training the original BERT model. Devlin et al. (2019) observe that removing NSP hurts performance, with significant performance degradation on QNLI, MNLI, and SQuAD 1.1. However, some recent work has questioned the necessity of the NSP loss (Lample and Conneau, 2019;Yang et al., 2019;Joshi et al., 2019).\n\nTo better understand this discrepancy, we compare several alternative training formats:\n\n\u2022 SEGMENT-PAIR+NSP: This follows the original input format used in BERT (Devlin et al., 2019), with the NSP loss. Each input has a pair of segments, which can each contain multiple natural sentences, but the total combined length must be less than 512 tokens.  \u2022 SENTENCE-PAIR+NSP: Each input contains a pair of natural sentences, either sampled from a contiguous portion of one document or from separate documents. Since these inputs are significantly shorter than 512 tokens, we increase the batch size so that the total number of tokens remains similar to SEGMENT-PAIR+NSP. We retain the NSP loss.\n\n\u2022 FULL-SENTENCES: Each input is packed with full sentences sampled contiguously from one or more documents, such that the total length is at most 512 tokens. Inputs may cross document boundaries. When we reach the end of one document, we begin sampling sentences from the next document and add an extra separator token between documents. We remove the NSP loss.\n\n\u2022 DOC-SENTENCES: Inputs are constructed similarly to FULL-SENTENCES, except that they may not cross document boundaries. Inputs sampled near the end of a document may be shorter than 512 tokens, so we dynamically increase the batch size in these cases to achieve a similar number of total tokens as FULL-SENTENCES. We remove the NSP loss.\n\nResults Table 2 shows results for the four different settings. We first compare the original SEGMENT-PAIR input format from Devlin et al. (2019) to the SENTENCE-PAIR format; both formats retain the NSP loss, but the latter uses single sentences. We find that using individual sentences hurts performance on downstream tasks, which we hypothesize is because the model is not able to learn long-range dependencies.\n\nWe next compare training without the NSP loss and training with blocks of text from a single document (DOC-SENTENCES). We find that this setting outperforms the originally published BERT BASE results and that removing the NSP loss matches or slightly improves downstream task performance, in contrast to Devlin et al. (2019). It is possible that the original BERT implementation may only have removed the loss term while still retaining the SEGMENT-PAIR input format.\n\nFinally we find that restricting sequences to come from a single document (DOC-SENTENCES) performs slightly better than packing sequences from multiple documents (FULL-SENTENCES). However, because the DOC-SENTENCES format results in variable batch sizes, we use FULL-SENTENCES in the remainder of our experiments for easier comparison with related work.\n\n\nTraining with large batches\n\nPast work in Neural Machine Translation has shown that training with very large mini-batches can both improve optimization speed and end-task performance when the learning rate is increased appropriately (Ott et al., 2018). Recent work has shown that BERT is also amenable to large batch training (You et al., 2019). Devlin et al. (2019) originally trained BERT BASE for 1M steps with a batch size of 256 sequences. This is equivalent in computational cost, via gradient accumulation, to training for 125K steps with a batch size of 2K sequences, or for 31K steps with a batch size of 8K.\n\nIn Table 3 we compare perplexity and end-  Table 3: Perplexity on held-out training data (ppl) and development set accuracy for base models trained over BOOKCORPUS and WIKIPEDIA with varying batch sizes (bsz). We tune the learning rate (lr) for each setting. Models make the same number of passes over the data (epochs) and have the same computational cost.\n\ntask performance of BERT BASE as we increase the batch size, controlling for the number of passes through the training data. We observe that training with large batches improves perplexity for the masked language modeling objective, as well as end-task accuracy. Large batches are also easier to parallelize via distributed data parallel training, 8 and in later experiments we train with batches of 8K sequences.\n\nNotably You et al. (2019) train BERT with even larger batche sizes, up to 32K sequences. We leave further exploration of the limits of large batch training to future work.\n\n\nText Encoding\n\nByte-Pair Encoding (BPE) (Sennrich et al., 2016) is a hybrid between character-and word-level representations that allows handling the large vocabularies common in natural language corpora. Instead of full words, BPE relies on subwords units, which are extracted by performing statistical analysis of the training corpus.\n\nBPE vocabulary sizes typically range from 10K-100K subword units. However, unicode characters can account for a sizeable portion of this vocabulary when modeling large and diverse corpora, such as the ones considered in this work. Radford et al. (2019) introduce a clever implementation of BPE that uses bytes instead of unicode characters as the base subword units. Using bytes makes it possible to learn a subword vocabulary of a modest size (50K units) that can still encode any input text without introducing any \"unknown\" tokens. 8 Large batch training can improve training efficiency even without large scale parallel hardware through gradient accumulation, whereby gradients from multiple mini-batches are accumulated locally before each optimization step. This functionality is supported natively in FAIRSEQ (Ott et al., 2019).\n\nThe original BERT implementation (Devlin et al., 2019) uses a character-level BPE vocabulary of size 30K, which is learned after preprocessing the input with heuristic tokenization rules. Following Radford et al. (2019), we instead consider training BERT with a larger byte-level BPE vocabulary containing 50K subword units, without any additional preprocessing or tokenization of the input. This adds approximately 15M and 20M additional parameters for BERT BASE and BERT LARGE , respectively.\n\nEarly experiments revealed only slight differences between these encodings, with the Radford et al. (2019) BPE achieving slightly worse end-task performance on some tasks. Nevertheless, we believe the advantages of a universal encoding scheme outweighs the minor degredation in performance and use this encoding in the remainder of our experiments. A more detailed comparison of these encodings is left to future work.\n\n\nRoBERTa\n\nIn the previous section we propose modifications to the BERT pretraining procedure that improve end-task performance. We now aggregate these improvements and evaluate their combined impact. We call this configuration RoBERTa for Robustly optimized BERT approach. Specifically, RoBERTa is trained with dynamic masking (Section 4.1), FULL-SENTENCES without NSP loss (Section 4.2), large mini-batches (Section 4.3) and a larger byte-level BPE (Section 4.4).\n\nAdditionally, we investigate two other important factors that have been under-emphasized in previous work: (1) the data used for pretraining, and (2) the number of training passes through the data. For example, the recently proposed XLNet architecture  is pretrained using nearly 10 times more data than the original BERT (Devlin et al., 2019). It is also trained with a batch size eight times larger for half as many optimization steps, thus seeing four times as many sequences in pretraining compared to BERT.\n\nTo help disentangle the importance of these factors from other modeling choices (e.g., the pretraining objective), we begin by training RoBERTa following the BERT LARGE architecture (L = 24, H = 1024, A = 16, 355M parameters). We pretrain for 100K steps over a comparable BOOK-CORPUS plus WIKIPEDIA dataset as was used in   Devlin et al. (2019). We pretrain our model using 1024 V100 GPUs for approximately one day.\n\nResults We present our results in Table 4. When controlling for training data, we observe that RoBERTa provides a large improvement over the originally reported BERT LARGE results, reaffirming the importance of the design choices we explored in Section 4. Next, we combine this data with the three additional datasets described in Section 3.2. We train RoBERTa over the combined data with the same number of training steps as before (100K). In total, we pretrain over 160GB of text. We observe further improvements in performance across all downstream tasks, validating the importance of data size and diversity in pretraining. 9 Finally, we pretrain RoBERTa for significantly longer, increasing the number of pretraining steps from 100K to 300K, and then further to 500K. We again observe significant gains in downstream task performance, and the 300K and 500K step models outperform XLNet LARGE across most tasks. We note that even our longest-trained model does not appear to overfit our data and would likely benefit from additional training.\n\nIn the rest of the paper, we evaluate our best RoBERTa model on the three different benchmarks: GLUE, SQuaD and RACE. Specifically 9 Our experiments conflate increases in data size and diversity. We leave a more careful analysis of these two dimensions to future work. we consider RoBERTa trained for 500K steps over all five of the datasets introduced in Section 3.2.\n\n\nGLUE Results\n\nFor GLUE we consider two finetuning settings. In the first setting (single-task, dev) we finetune RoBERTa separately for each of the GLUE tasks, using only the training data for the corresponding task. We consider a limited hyperparameter sweep for each task, with batch sizes \u2208 {16, 32} and learning rates \u2208 {1e\u22125, 2e\u22125, 3e\u22125}, with a linear warmup for the first 6% of steps followed by a linear decay to 0. We finetune for 10 epochs and perform early stopping based on each task's evaluation metric on the dev set. The rest of the hyperparameters remain the same as during pretraining. In this setting, we report the median development set results for each task over five random initializations, without model ensembling.\n\nIn the second setting (ensembles, test), we compare RoBERTa to other approaches on the test set via the GLUE leaderboard. While many submissions to the GLUE leaderboard depend on multitask finetuning, our submission depends only on single-task finetuning. For RTE, STS and MRPC we found it helpful to finetune starting from the MNLI single-task model, rather than the baseline pretrained RoBERTa. We explore a slightly wider hyperparameter space, described in the Appendix, and ensemble between 5 and 7 models per task.  Task-specific modifications Two of the GLUE tasks require task-specific finetuning approaches to achieve competitive leaderboard results. QNLI: Recent submissions on the GLUE leaderboard adopt a pairwise ranking formulation for the QNLI task, in which candidate answers are mined from the training set and compared to one another, and a single (question, candidate) pair is classified as positive (Liu et al., 2019b,a;Yang et al., 2019). This formulation significantly simplifies the task, but is not directly comparable to BERT (Devlin et al., 2019). Following recent work, we adopt the ranking approach for our test submission, but for direct comparison with BERT we report development set results based on a pure classification approach. WNLI: We found the provided NLI-format data to be challenging to work with. Instead we use the reformatted WNLI data from Super-GLUE (Wang et al., 2019a), which indicates the span of the query pronoun and referent. We finetune RoBERTa using the margin ranking loss from Kocijan et al. (2019). For a given input sentence, we use spaCy (Honnibal and Montani, 2017) to extract additional candidate noun phrases from the sentence and finetune our model so that it assigns higher scores to positive referent phrases than for any of the generated negative candidate phrases. One unfortunate consequence of this formulation is that we can only make use of the positive training examples, which excludes over half of the provided training examples. 10\n\nResults We present our results in Table 5. In the first setting (single-task, dev), RoBERTa achieves state-of-the-art results on all 9 of the GLUE task development sets. Crucially, RoBERTa uses the same masked language modeling pretraining objective and architecture as BERT LARGE , yet consistently outperforms both BERT LARGE and XLNet LARGE . This raises questions about the relative importance of model architecture and pretraining objective, compared to more mundane details like dataset size and training time that we explore in this work.\n\nIn the second setting (ensembles, test), we submit RoBERTa to the GLUE leaderboard and achieve state-of-the-art results on 4 out of 9 tasks and the highest average score to date. This is especially exciting because RoBERTa does not depend on multi-task finetuning, unlike most of the other top submissions. We expect future work may further improve these results by incorporating more sophisticated multi-task finetuning procedures.\n\n\nSQuAD Results\n\nWe adopt a much simpler approach for SQuAD compared to past work. In particular, while both BERT (Devlin et al., 2019) and XL-Net  augment their training data with additional QA datasets, we only finetune RoBERTa using the provided SQuAD training data. Yang et al. (2019) also employed a custom layer-wise learning rate schedule to finetune results could potentially be improved by augmenting this with additional pronoun disambiguation datasets.  XLNet, while we use the same learning rate for all layers. For SQuAD v1.1 we follow the same finetuning procedure as Devlin et al. (2019). For SQuAD v2.0, we additionally classify whether a given question is answerable; we train this classifier jointly with the span predictor by summing the classification and span loss terms.\n\n\nResults\n\nWe present our results in Table 6. On the SQuAD v1.1 development set, RoBERTa matches the state-of-the-art set by XLNet. On the SQuAD v2.0 development set, RoBERTa sets a new state-of-the-art, improving over XLNet by 0.4 points (EM) and 0.6 points (F1).\n\nWe also submit RoBERTa to the public SQuAD 2.0 leaderboard and evaluate its performance relative to other systems. Most of the top systems build upon either BERT (Devlin et al., 2019) or XLNet , both of which rely on additional external training data. In contrast, our submission does not use any additional data. Our single RoBERTa model outperforms all but one of the single model submissions, and is the top scoring system among those that do not rely on data augmentation.\n\n\nRACE Results\n\nIn RACE, systems are provided with a passage of text, an associated question, and four candidate answers. Systems are required to classify which of the four candidate answers is correct.\n\nWe modify RoBERTa for this task by concate-  nating each candidate answer with the corresponding question and passage. We then encode each of these four sequences and pass the resulting [CLS] representations through a fully-connected layer, which is used to predict the correct answer. We truncate question-answer pairs that are longer than 128 tokens and, if needed, the passage so that the total length is at most 512 tokens.\n\nResults on the RACE test sets are presented in Table 7. RoBERTa achieves state-of-the-art results on both middle-school and high-school settings.\n\n\nRelated Work\n\nPretraining methods have been designed with different training objectives, including language modeling (Dai and Le, 2015; Peters et al., 2018;Howard and Ruder, 2018), machine translation (McCann et al., 2017), and masked language modeling (Devlin et al., 2019;Lample and Conneau, 2019).\n\nMany recent papers have used a basic recipe of finetuning models for each end task (Howard and Ruder, 2018;Radford et al., 2018), and pretraining with some variant of a masked language model objective.\n\nHowever, newer methods have improved performance by multi-task fine tuning (Dong et al., 2019), incorporating entity embeddings (Sun et al., 2019), span prediction (Joshi et al., 2019), and multiple variants of autoregressive pretraining Chan et al., 2019;Yang et al., 2019). Performance is also typically improved by training bigger models on more data (Devlin et al., 2019;Yang et al., 2019;Radford et al., 2019). Our goal was to replicate, simplify, and better tune the training of BERT, as a reference point for better understanding the relative performance of all of these methods.\n\nWe carefully evaluate a number of design decisions when pretraining BERT models. We find that performance can be substantially improved by training the model longer, with bigger batches over more data; removing the next sentence prediction objective; training on longer sequences; and dynamically changing the masking pattern applied to the training data. Our improved pretraining procedure, which we call RoBERTa, achieves state-of-the-art results on GLUE, RACE and SQuAD, without multi-task finetuning for GLUE or additional data for SQuAD. These results illustrate the importance of these previously overlooked design decisions and suggest that BERT's pretraining objective remains competitive with recently proposed alternatives.\n\nWe additionally use a novel dataset, CC-NEWS, and release our models and code for pretraining and finetuning at: https://github.com/pytorch/fairseq. Optimized BERT Pretraining Approach\"\n\n\nA Full results on GLUE\n\nIn Table 8 we present the full set of development set results for RoBERTa. We present results for a LARGE configuration that follows BERT LARGE , as well as a BASE configuration that follows BERT BASE . \n\n\nB Pretraining Hyperparameters\n\n\nC Finetuning Hyperparameters\n\nFinetuning hyperparameters for RACE, SQuAD and GLUE are given in Table 10. We select the best hyperparameter values based on the median of 5 random seeds for each task.    \n\n\nMNLI QNLI QQP RTE SST MRPC CoLA STS\n\n5\nThe authors and their affiliated institutions are not in any way affiliated with the creation of the OpenWebText dataset. 6 The datasets are: CoLA (Warstadt et al., 2018), Stanford Sentiment Treebank (SST) (Socher et al., 2013), Microsoft Research Paragraph Corpus (MRPC) (Dolan and Brockett, 2005), Semantic Textual Similarity Benchmark (STS) (Agirre et al., 2007), Quora Question Pairs (QQP)(Iyer et al., 2016), Multi-Genre NLI (MNLI)(Williams et al., 2018), Question NLI (QNLI)(Rajpurkar et al., 2016), Recognizing Textual Entailment (RTE)Bar-Haim et al., 2006;Giampiccolo et al., 2007;Bentivogli et al., 2009) and Winograd NLI (WNLI)(Levesque et al., 2011).\n\n\nTable 1: Comparison between static and dynamic masking for BERT BASE . We report F1 for SQuAD and accuracy for MNLI-m and SST-2. Reported results are medians over 5 random initializations (seeds). Reference results are fromYang et al. (2019).Masking SQuAD 2.0 MNLI-m SST-2 \n\nreference \n76.3 \n84.3 \n92.8 \n\nOur reimplementation: \nstatic \n78.3 \n84.3 \n92.5 \ndynamic \n78.7 \n84.0 \n92.9 \n\n\n\nTable 2 :\n2Development set results for base models pretrained over BOOKCORPUS and WIKIPEDIA. All models are trained for 1M steps with a batch size of 256 sequences. We report F1 for SQuAD and accuracy for MNLI-m, SST-2 and RACE. Reported results are medians over five random initializations (seeds). Results for BERT BASE and XLNet BASE are fromYang et al. (2019).\n\nTable 4 :\n4Development set results for RoBERTa as we pretrain over more data (16GB \u2192 160GB of text) and pretrain for longer (100K \u2192 300K \u2192 500K steps). Each row accumulates improvements from the rows above. RoBERTa matches the architecture and training objective of BERT LARGE . Results for BERT LARGE and XLNet LARGE are fromDevlin et al. (2019) and Yang et al. (2019), respectively. Complete results on all GLUE tasks can be found in the \nAppendix. \n\n\n\nTable 5 :\n5Results on GLUE. All results are based on a 24-layer architecture. BERT LARGE and XLNet LARGE results \nare from Devlin et al. (2019) and Yang et al. (2019), respectively. RoBERTa results on the development set are a \nmedian over five runs. RoBERTa results on the test set are ensembles of single-task models. For RTE, STS and \nMRPC we finetune starting from the MNLI model instead of the baseline pretrained model. Averages are obtained \nfrom the GLUE leaderboard. \n\n\n\nTable 6 :\n6Results on SQuAD.  \u2020 indicates results that de-\npend on additional external training data. RoBERTa \nuses only the provided SQuAD data in both dev and \ntest settings. BERT LARGE and XLNet LARGE results are \nfrom Devlin et al. (2019) and Yang et al. (2019), re-\nspectively. \n\n\n\nTable 7 :\n7Results on the RACE test set. BERT LARGE and XLNet LARGE results are fromYang et al. (2019).\n\nTable 9\n9describes the hyperparameters for pretraining of RoBERTa LARGE and RoBERTa BASE\n\nTable 8 :\n8Development set results on GLUE tasks for various configurations of RoBERTa.Hyperparam \nRoBERTa LARGE RoBERTa BASE \n\nNumber of Layers \n24 \n12 \nHidden size \n1024 \n768 \nFFN inner hidden size \n4096 \n3072 \nAttention heads \n16 \n12 \nAttention head size \n64 \n64 \nDropout \n0.1 \n0.1 \nAttention Dropout \n0.1 \n0.1 \nWarmup Steps \n30k \n24k \nPeak Learning Rate \n4e-4 \n6e-4 \nBatch Size \n8k \n8k \nWeight Decay \n0.01 \n0.01 \nMax Steps \n500k \n500k \nLearning Rate Decay \nLinear \nLinear \nAdam \u01eb \n1e-6 \n1e-6 \nAdam \u03b2 1 \n0.9 \n0.9 \nAdam \u03b2 2 \n0.98 \n0.98 \nGradient Clipping \n0.0 \n0.0 \n\n\n\nTable 9 :\n9Hyperparameters for pretraining RoBERTa LARGE and RoBERTa BASE .Hyperparam \nRACE SQuAD \nGLUE \n\nLearning Rate \n1e-5 \n1.5e-5 \n{1e-5, 2e-5, 3e-5} \nBatch Size \n16 \n48 \n{16, 32} \nWeight Decay \n0.1 \n0.01 \n0.1 \nMax Epochs \n4 \n2 \n10 \nLearning Rate Decay Linear \nLinear \nLinear \nWarmup ratio \n0.06 \n0.06 \n0.06 \n\n\n\nTable 10 :\n10Hyperparameters for finetuning RoBERTa LARGE on RACE, SQuAD and GLUE.\nIt is possible that these other methods could also improve with more tuning. We leave this exploration to future work.\nYang et al. (2019) use the same dataset but report having only 13GB of text after data cleaning. This is most likely due to subtle differences in cleaning of the Wikipedia data.\nWe use news-please(Hamborg et al., 2017) to collect and extract CC-NEWS. CC-NEWS is similar to the RE-ALNEWS dataset described inZellers et al. (2019).\nStudying architectural changes, including larger architectures, is an important area for future work.\nWhile we only use the provided WNLI training data, our\nAppendix for \"RoBERTa: A Robustly\nEneko Agirre, Richard Llu&apos;is M&apos;arquez, Wicentowski, Proceedings of the Fourth International Workshop on Semantic Evaluations. the Fourth International Workshop on Semantic EvaluationsEneko Agirre, Llu'is M'arquez, and Richard Wicen- towski, editors. 2007. Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007).\n\nClozedriven pretraining of self-attention networks. Alexei Baevski, Sergey Edunov, Yinhan Liu, Luke Zettlemoyer, Michael Auli, arXiv:1903.07785arXiv preprintAlexei Baevski, Sergey Edunov, Yinhan Liu, Luke Zettlemoyer, and Michael Auli. 2019. Cloze- driven pretraining of self-attention networks. arXiv preprint arXiv:1903.07785.\n\nThe second PASCAL recognising textual entailment challenge. Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, Idan Szpektor, Proceedings of the second PASCAL challenges workshop on recognising textual entailment. the second PASCAL challenges workshop on recognising textual entailmentRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and Idan Szpektor. 2006. The second PASCAL recognising textual entailment challenge. In Proceedings of the second PASCAL challenges workshop on recognis- ing textual entailment.\n\nThe fifth PASCAL recognizing textual entailment challenge. Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, Bernardo Magnini, Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, and Bernardo Magnini. 2009. The fifth PASCAL recognizing textual entailment chal- lenge.\n\nA large annotated corpus for learning natural language inference. Gabor Samuel R Bowman, Christopher Angeli, Christopher D Potts, Manning, Empirical Methods in Natural Language Processing (EMNLP). Samuel R Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. 2015. A large anno- tated corpus for learning natural language inference. In Empirical Methods in Natural Language Process- ing (EMNLP).\n\nKERMIT: Generative insertion-based modeling for sequences. William Chan, Nikita Kitaev, Kelvin Guu, Mitchell Stern, Jakob Uszkoreit, arXiv:1906.01604arXiv preprintWilliam Chan, Nikita Kitaev, Kelvin Guu, Mitchell Stern, and Jakob Uszkoreit. 2019. KERMIT: Gener- ative insertion-based modeling for sequences. arXiv preprint arXiv:1906.01604.\n\nThe PASCAL recognising textual entailment challenge. Oren Ido Dagan, Bernardo Glickman, Magnini, Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment. Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006. The PASCAL recognising textual entailment challenge. In Machine learning challenges. evalu- ating predictive uncertainty, visual object classifica- tion, and recognising tectual entailment.\n\nSemi-supervised sequence learning. M Andrew, Quoc V Dai, Le, Advances in Neural Information Processing Systems (NIPS). Andrew M Dai and Quoc V Le. 2015. Semi-supervised sequence learning. In Advances in Neural Informa- tion Processing Systems (NIPS).\n\nBERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, North American Association for Computational Linguistics (NAACL). Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language under- standing. In North American Association for Com- putational Linguistics (NAACL).\n\nAutomatically constructing a corpus of sentential paraphrases. B William, Chris Dolan, Brockett, Proceedings of the International Workshop on Paraphrasing. the International Workshop on ParaphrasingWilliam B Dolan and Chris Brockett. 2005. Auto- matically constructing a corpus of sentential para- phrases. In Proceedings of the International Work- shop on Paraphrasing.\n\nUnified language model pre-training for natural language understanding and generation. Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon, arXiv:1905.03197arXiv preprintLi Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon. 2019. Unified language model pre-training for natural language understanding and generation. arXiv preprint arXiv:1905.03197.\n\nThe third PASCAL recognizing textual entailment challenge. Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, Bill Dolan, Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing. the ACL-PASCAL workshop on textual entailment and paraphrasingDanilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The third PASCAL recog- nizing textual entailment challenge. In Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing.\n\nOpenwebtext corpus. Aaron Gokaslan, Vanya Cohen, Aaron Gokaslan and Vanya Cohen. 2019. Openweb- text corpus. http://web.archive.org/ save/http://Skylion007.github.io/ OpenWebTextCorpus.\n\nnews-please: A generic news crawler and extractor. Felix Hamborg, Norman Meuschke, Corinna Breitinger, Bela Gipp, Proceedings of the 15th International Symposium of Information Science. the 15th International Symposium of Information ScienceFelix Hamborg, Norman Meuschke, Corinna Bre- itinger, and Bela Gipp. 2017. news-please: A generic news crawler and extractor. In Proceedings of the 15th International Symposium of Information Science.\n\nDan Hendrycks, Kevin Gimpel, arXiv:1606.08415Gaussian error linear units (gelus). arXiv preprintDan Hendrycks and Kevin Gimpel. 2016. Gaus- sian error linear units (gelus). arXiv preprint arXiv:1606.08415.\n\n2017. spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing. Matthew Honnibal, Ines Montani, To appearMatthew Honnibal and Ines Montani. 2017. spaCy 2: Natural language understanding with Bloom embed- dings, convolutional neural networks and incremen- tal parsing. To appear.\n\nUniversal language model fine-tuning for text classification. Jeremy Howard, Sebastian Ruder, arXiv:1801.06146arXiv preprintJeremy Howard and Sebastian Ruder. 2018. Universal language model fine-tuning for text classification. arXiv preprint arXiv:1801.06146.\n\nFirst quora dataset release: Question pairs. Shankar Iyer, Nikhil Dandekar, Kornl Csernai, Shankar Iyer, Nikhil Dandekar, and Kornl Cser- nai. 2016. First quora dataset release: Question pairs. https://data.quora.com/First- Quora-Dataset-Release-Question- Pairs.\n\nSpanBERT: Improving pre-training by representing and predicting spans. Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S Weld, Luke Zettlemoyer, Omer Levy, arXiv:1907.10529arXiv preprintMandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, and Omer Levy. 2019. SpanBERT: Improving pre-training by repre- senting and predicting spans. arXiv preprint arXiv:1907.10529.\n\nAdam: A method for stochastic optimization. Diederik Kingma, Jimmy Ba, International Conference on Learning Representations (ICLR). Diederik Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR).\n\nA surprisingly robust trick for winograd schema challenge. Ana-Maria Vid Kocijan, Oana-Maria Cretu, Yordan Camburu, Thomas Yordanov, Lukasiewicz, arXiv:1905.06290arXiv preprintVid Kocijan, Ana-Maria Cretu, Oana-Maria Camburu, Yordan Yordanov, and Thomas Lukasiewicz. 2019. A surprisingly robust trick for winograd schema challenge. arXiv preprint arXiv:1905.06290.\n\nGuokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, Eduard Hovy, arXiv:1704.04683Race: Large-scale reading comprehension dataset from examinations. arXiv preprintGuokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. 2017. Race: Large-scale reading comprehension dataset from examinations. arXiv preprint arXiv:1704.04683.\n\nGuillaume Lample, Alexis Conneau, arXiv:1901.07291Crosslingual language model pretraining. arXiv preprintGuillaume Lample and Alexis Conneau. 2019. Cross- lingual language model pretraining. arXiv preprint arXiv:1901.07291.\n\nThe Winograd schema challenge. J Hector, Ernest Levesque, Leora Davis, Morgenstern, AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning. Hector J Levesque, Ernest Davis, and Leora Morgen- stern. 2011. The Winograd schema challenge. In AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning.\n\nImproving multi-task deep neural networks via knowledge distillation for natural language understanding. Xiaodong Liu, Pengcheng He, Weizhu Chen, Jianfeng Gao, arXiv:1904.09482arXiv preprintXiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. 2019a. Improving multi-task deep neural networks via knowledge distillation for natural language understanding. arXiv preprint arXiv:1904.09482.\n\nXiaodong Liu, Pengcheng He, Weizhu Chen, Jianfeng Gao, arXiv:1901.11504Multi-task deep neural networks for natural language understanding. arXiv preprintXiaodong Liu, Pengcheng He, Weizhu Chen, and Jian- feng Gao. 2019b. Multi-task deep neural networks for natural language understanding. arXiv preprint arXiv:1901.11504.\n\nLearned in translation: Contextualized word vectors. Bryan Mccann, James Bradbury, Caiming Xiong, Richard Socher, Advances in Neural Information Processing Systems (NIPS). Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher. 2017. Learned in translation: Con- textualized word vectors. In Advances in Neural In- formation Processing Systems (NIPS), pages 6297- 6308.\n\nMixed precision training. Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, Hao Wu, International Conference on Learning Representations. Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu. 2018. Mixed preci- sion training. In International Conference on Learn- ing Representations.\n\n. Sebastian Nagel, Sebastian Nagel. 2016. Cc-news. http: //web.archive.org/save/http: //commoncrawl.org/2016/10/news- dataset-available.\n\nFAIRSEQ: A fast, extensible toolkit for sequence modeling. Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli, North American Association for Computational Linguistics (NAACL): System Demonstrations. Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. 2019. FAIRSEQ: A fast, exten- sible toolkit for sequence modeling. In North American Association for Computational Linguis- tics (NAACL): System Demonstrations.\n\nScaling neural machine translation. Myle Ott, Sergey Edunov, David Grangier, Michael Auli, Proceedings of the Third Conference on Machine Translation (WMT). the Third Conference on Machine Translation (WMT)Myle Ott, Sergey Edunov, David Grangier, and Michael Auli. 2018. Scaling neural machine trans- lation. In Proceedings of the Third Conference on Machine Translation (WMT).\n\nAutomatic differentiation in PyTorch. Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary Devito, Zeming Lin, Alban Desmaison, Luca Antiga, Adam Lerer, NIPS Autodiff Workshop. Adam Paszke, Sam Gross, Soumith Chintala, Gre- gory Chanan, Edward Yang, Zachary DeVito, Zem- ing Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017. Automatic differentiation in PyTorch. In NIPS Autodiff Workshop.\n\nDeep contextualized word representations. Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer, North American Association for Computational Linguistics (NAACL). Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word repre- sentations. In North American Association for Com- putational Linguistics (NAACL).\n\nImproving language understanding with unsupervised learning. Alec Radford, Karthik Narasimhan, OpenAITechnical reportTime Salimans, and Ilya SutskeverAlec Radford, Karthik Narasimhan, Time Salimans, and Ilya Sutskever. 2018. Improving language un- derstanding with unsupervised learning. Technical report, OpenAI.\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAITechnical reportAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. Techni- cal report, OpenAI.\n\nKnow what you don't know: Unanswerable questions for squad. Pranav Rajpurkar, Robin Jia, Percy Liang, Association for Computational Linguistics (ACL). Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018. Know what you don't know: Unanswerable ques- tions for squad. In Association for Computational Linguistics (ACL).\n\nSQuAD: 100,000+ questions for machine comprehension of text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, Empirical Methods in Natural Language Processing (EMNLP). Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. In Empirical Meth- ods in Natural Language Processing (EMNLP).\n\nNeural machine translation of rare words with subword units. Rico Sennrich, Barry Haddow, Alexandra Birch, Association for Computational Linguistics (ACL). Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural machine translation of rare words with subword units. In Association for Computational Linguistics (ACL), pages 1715-1725.\n\nRecursive deep models for semantic compositionality over a sentiment treebank. Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, D Christopher, Andrew Manning, Christopher Ng, Potts, Empirical Methods in Natural Language Processing. EMNLPRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment tree- bank. In Empirical Methods in Natural Language Processing (EMNLP).\n\nMASS: Masked sequence to sequence pre-training for language generation. Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu, International Conference on Machine Learning (ICML). Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2019. MASS: Masked sequence to sequence pre-training for language generation. In International Conference on Machine Learning (ICML).\n\nShuohuan Yu Stephanie Sun, Yukun Wang, Shikun Li, Xuyi Feng, Han Chen, Xinlun Zhang, Danxiang Tian, Zhu, Hua Hao Tian, Wu, arXiv:1904.09223ERNIE: Enhanced representation through knowledge integration. arXiv preprintYu Stephanie Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xinlun Tian, Danxi- ang Zhu, Hao Tian, and Hua Wu. 2019. ERNIE: En- hanced representation through knowledge integra- tion. arXiv preprint arXiv:1904.09223.\n\nA simple method for commonsense reasoning. H Trieu, Quoc V Trinh, Le, arXiv:1806.02847arXiv preprintTrieu H Trinh and Quoc V Le. 2018. A simple method for commonsense reasoning. arXiv preprint arXiv:1806.02847.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information pro- cessing systems.\n\nSuperGLUE: A stickier benchmark for general-purpose language understanding systems. Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R Bowman, 1905.00537arXiv preprintAlex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019a. SuperGLUE: A stickier benchmark for general-purpose language understanding systems. arXiv preprint 1905.00537.\n\nGLUE: A multi-task benchmark and analysis platform for natural language understanding. Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R Bowman, International Conference on Learning Representations. ICLRAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019b. GLUE: A multi-task benchmark and analysis plat- form for natural language understanding. In Inter- national Conference on Learning Representations (ICLR).\n\nBowman. Alex Warstadt, Amanpreet Singh, Samuel R , 1805.12471Neural network acceptability judgments. arXiv preprintAlex Warstadt, Amanpreet Singh, and Samuel R. Bow- man. 2018. Neural network acceptability judg- ments. arXiv preprint 1805.12471.\n\nA broad-coverage challenge corpus for sentence understanding through inference. Adina Williams, Nikita Nangia, Samuel Bowman, North American Association for Computational Linguistics (NAACL). Adina Williams, Nikita Nangia, and Samuel Bowman. 2018. A broad-coverage challenge corpus for sen- tence understanding through inference. In North American Association for Computational Linguis- tics (NAACL).\n\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V Le, arXiv:1906.08237Xlnet: Generalized autoregressive pretraining for language understanding. arXiv preprintZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car- bonell, Ruslan Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretrain- ing for language understanding. arXiv preprint arXiv:1906.08237.\n\nYang You, Jing Li, Jonathan Hseu, Xiaodan Song, James Demmel, Cho-Jui Hsieh, arXiv:1904.00962Reducing bert pre-training time from 3 days to 76 minutes. arXiv preprintYang You, Jing Li, Jonathan Hseu, Xiaodan Song, James Demmel, and Cho-Jui Hsieh. 2019. Reduc- ing bert pre-training time from 3 days to 76 minutes. arXiv preprint arXiv:1904.00962.\n\nRowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, Yejin Choi, arXiv:1905.12616Defending against neural fake news. arXiv preprintRowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin Choi. 2019. Defending against neural fake news. arXiv preprint arXiv:1905.12616.\n\nAligning books and movies: Towards story-like visual explanations by watching movies and reading books. Yukun Zhu, Ryan Kiros, Richard Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, Sanja Fidler, arXivpreprintarXiv:1506.06724Yukun Zhu, Ryan Kiros, Richard Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. 2015. Aligning books and movies: Towards story-like visual explanations by watch- ing movies and reading books. In arXiv preprint arXiv:1506.06724.\n", "annotations": {"author": "[{\"end\":112,\"start\":70},{\"end\":151,\"start\":113},{\"end\":178,\"start\":152},{\"end\":221,\"start\":179},{\"end\":262,\"start\":222},{\"end\":288,\"start\":263},{\"end\":329,\"start\":289},{\"end\":372,\"start\":330},{\"end\":404,\"start\":373},{\"end\":436,\"start\":405},{\"end\":450,\"start\":437},{\"end\":528,\"start\":451},{\"end\":112,\"start\":70},{\"end\":151,\"start\":113},{\"end\":178,\"start\":152},{\"end\":221,\"start\":179},{\"end\":262,\"start\":222},{\"end\":288,\"start\":263},{\"end\":329,\"start\":289},{\"end\":372,\"start\":330},{\"end\":404,\"start\":373},{\"end\":436,\"start\":405},{\"end\":450,\"start\":437},{\"end\":528,\"start\":451}]", "publisher": null, "author_last_name": "[{\"end\":80,\"start\":77},{\"end\":121,\"start\":118},{\"end\":163,\"start\":158},{\"end\":189,\"start\":187},{\"end\":234,\"start\":229},{\"end\":273,\"start\":269},{\"end\":298,\"start\":294},{\"end\":340,\"start\":335},{\"end\":389,\"start\":378},{\"end\":421,\"start\":413},{\"end\":449,\"start\":444},{\"end\":80,\"start\":77},{\"end\":121,\"start\":118},{\"end\":163,\"start\":158},{\"end\":189,\"start\":187},{\"end\":234,\"start\":229},{\"end\":273,\"start\":269},{\"end\":298,\"start\":294},{\"end\":340,\"start\":335},{\"end\":389,\"start\":378},{\"end\":421,\"start\":413},{\"end\":449,\"start\":444}]", "author_first_name": "[{\"end\":76,\"start\":70},{\"end\":117,\"start\":113},{\"end\":157,\"start\":152},{\"end\":186,\"start\":179},{\"end\":228,\"start\":222},{\"end\":268,\"start\":263},{\"end\":293,\"start\":289},{\"end\":334,\"start\":330},{\"end\":377,\"start\":373},{\"end\":412,\"start\":405},{\"end\":441,\"start\":437},{\"end\":443,\"start\":442},{\"end\":76,\"start\":70},{\"end\":117,\"start\":113},{\"end\":157,\"start\":152},{\"end\":186,\"start\":179},{\"end\":228,\"start\":222},{\"end\":268,\"start\":263},{\"end\":293,\"start\":289},{\"end\":334,\"start\":330},{\"end\":377,\"start\":373},{\"end\":412,\"start\":405},{\"end\":441,\"start\":437},{\"end\":443,\"start\":442}]", "author_affiliation": "[{\"end\":111,\"start\":99},{\"end\":150,\"start\":138},{\"end\":177,\"start\":165},{\"end\":220,\"start\":208},{\"end\":287,\"start\":275},{\"end\":328,\"start\":316},{\"end\":371,\"start\":359},{\"end\":403,\"start\":391},{\"end\":435,\"start\":423},{\"end\":527,\"start\":452},{\"end\":111,\"start\":99},{\"end\":150,\"start\":138},{\"end\":177,\"start\":165},{\"end\":220,\"start\":208},{\"end\":287,\"start\":275},{\"end\":328,\"start\":316},{\"end\":371,\"start\":359},{\"end\":403,\"start\":391},{\"end\":435,\"start\":423},{\"end\":527,\"start\":452}]", "title": "[{\"end\":56,\"start\":1},{\"end\":584,\"start\":529},{\"end\":56,\"start\":1},{\"end\":584,\"start\":529}]", "venue": null, "abstract": "[{\"end\":1555,\"start\":597},{\"end\":1555,\"start\":597}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b32\"},\"end\":1627,\"start\":1606},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":1655,\"start\":1633},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":1683,\"start\":1662},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1715,\"start\":1689},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2154,\"start\":2133},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3178,\"start\":3160},{\"end\":3532,\"start\":3531},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":4136,\"start\":4115},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4227,\"start\":4206},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":5037,\"start\":5015},{\"end\":5447,\"start\":5440},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6503,\"start\":6482},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6646,\"start\":6625},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6983,\"start\":6955},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":7188,\"start\":7170},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7431,\"start\":7413},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7974,\"start\":7954},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8310,\"start\":8283},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8583,\"start\":8561},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":8601,\"start\":8583},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":8622,\"start\":8601},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":9063,\"start\":9045},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9243,\"start\":9230},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9413,\"start\":9387},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9498,\"start\":9477},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":9983,\"start\":9964},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10671,\"start\":10650},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11125,\"start\":11102},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11150,\"start\":11125},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11392,\"start\":11371},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11737,\"start\":11719},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13373,\"start\":13353},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":14337,\"start\":14317},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14551,\"start\":14525},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":14569,\"start\":14551},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14588,\"start\":14569},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":14773,\"start\":14752},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16129,\"start\":16109},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16723,\"start\":16703},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":17475,\"start\":17457},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":17568,\"start\":17550},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":17590,\"start\":17570},{\"end\":18551,\"start\":18550},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":18642,\"start\":18625},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":18854,\"start\":18831},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":19381,\"start\":19360},{\"end\":19665,\"start\":19664},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":19963,\"start\":19945},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20020,\"start\":19999},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":20185,\"start\":20164},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":21691,\"start\":21670},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22205,\"start\":22185},{\"end\":22907,\"start\":22906},{\"end\":25375,\"start\":25354},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":25393,\"start\":25375},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":25507,\"start\":25486},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":25851,\"start\":25831},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":25989,\"start\":25968},{\"end\":26060,\"start\":26032},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":27558,\"start\":27537},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":27711,\"start\":27693},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":28025,\"start\":28005},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":28665,\"start\":28644},{\"end\":29354,\"start\":29349},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":29896,\"start\":29876},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29919,\"start\":29896},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":29962,\"start\":29941},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30014,\"start\":29993},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":30039,\"start\":30014},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":30149,\"start\":30125},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":30170,\"start\":30149},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":30339,\"start\":30320},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":30429,\"start\":30409},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":30501,\"start\":30483},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":30519,\"start\":30501},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30620,\"start\":30599},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":30638,\"start\":30620},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":30659,\"start\":30638},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32674,\"start\":32655},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":32721,\"start\":32698},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":32766,\"start\":32742},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":32826,\"start\":32804},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":32851,\"start\":32826},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":32875,\"start\":32851},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":32922,\"start\":32899},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":33167,\"start\":33149},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":33673,\"start\":33655},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":35000,\"start\":34982},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":36200,\"start\":36182},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":36400,\"start\":36378},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":36510,\"start\":36489},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":1627,\"start\":1606},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":1655,\"start\":1633},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":1683,\"start\":1662},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1715,\"start\":1689},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2154,\"start\":2133},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3178,\"start\":3160},{\"end\":3532,\"start\":3531},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":4136,\"start\":4115},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4227,\"start\":4206},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":5037,\"start\":5015},{\"end\":5447,\"start\":5440},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6503,\"start\":6482},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6646,\"start\":6625},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6983,\"start\":6955},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":7188,\"start\":7170},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7431,\"start\":7413},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7974,\"start\":7954},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8310,\"start\":8283},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8583,\"start\":8561},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":8601,\"start\":8583},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":8622,\"start\":8601},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":9063,\"start\":9045},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9243,\"start\":9230},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9413,\"start\":9387},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9498,\"start\":9477},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":9983,\"start\":9964},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10671,\"start\":10650},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11125,\"start\":11102},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11150,\"start\":11125},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11392,\"start\":11371},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11737,\"start\":11719},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13373,\"start\":13353},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":14337,\"start\":14317},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14551,\"start\":14525},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":14569,\"start\":14551},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14588,\"start\":14569},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":14773,\"start\":14752},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16129,\"start\":16109},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16723,\"start\":16703},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":17475,\"start\":17457},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":17568,\"start\":17550},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":17590,\"start\":17570},{\"end\":18551,\"start\":18550},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":18642,\"start\":18625},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":18854,\"start\":18831},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":19381,\"start\":19360},{\"end\":19665,\"start\":19664},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":19963,\"start\":19945},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20020,\"start\":19999},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":20185,\"start\":20164},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":21691,\"start\":21670},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22205,\"start\":22185},{\"end\":22907,\"start\":22906},{\"end\":25375,\"start\":25354},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":25393,\"start\":25375},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":25507,\"start\":25486},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":25851,\"start\":25831},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":25989,\"start\":25968},{\"end\":26060,\"start\":26032},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":27558,\"start\":27537},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":27711,\"start\":27693},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":28025,\"start\":28005},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":28665,\"start\":28644},{\"end\":29354,\"start\":29349},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":29896,\"start\":29876},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29919,\"start\":29896},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":29962,\"start\":29941},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30014,\"start\":29993},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":30039,\"start\":30014},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":30149,\"start\":30125},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":30170,\"start\":30149},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":30339,\"start\":30320},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":30429,\"start\":30409},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":30501,\"start\":30483},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":30519,\"start\":30501},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30620,\"start\":30599},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":30638,\"start\":30620},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":30659,\"start\":30638},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32674,\"start\":32655},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":32721,\"start\":32698},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":32766,\"start\":32742},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":32826,\"start\":32804},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":32851,\"start\":32826},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":32875,\"start\":32851},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":32922,\"start\":32899},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":33167,\"start\":33149},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":33673,\"start\":33655},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":35000,\"start\":34982},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":36200,\"start\":36182},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":36400,\"start\":36378},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":36510,\"start\":36489}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":32923,\"start\":32259},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":33308,\"start\":32924},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33674,\"start\":33309},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":34129,\"start\":33675},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":34609,\"start\":34130},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":34896,\"start\":34610},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":35001,\"start\":34897},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":35091,\"start\":35002},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":35662,\"start\":35092},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":35978,\"start\":35663},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":36062,\"start\":35979},{\"attributes\":{\"id\":\"fig_0\"},\"end\":32923,\"start\":32259},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":33308,\"start\":32924},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33674,\"start\":33309},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":34129,\"start\":33675},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":34609,\"start\":34130},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":34896,\"start\":34610},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":35001,\"start\":34897},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":35091,\"start\":35002},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":35662,\"start\":35092},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":35978,\"start\":35663},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":36062,\"start\":35979}]", "paragraph": "[{\"end\":2080,\"start\":1571},{\"end\":2882,\"start\":2082},{\"end\":4137,\"start\":2884},{\"end\":4343,\"start\":4152},{\"end\":4632,\"start\":4353},{\"end\":4824,\"start\":4697},{\"end\":4944,\"start\":4826},{\"end\":5186,\"start\":4961},{\"end\":5310,\"start\":5210},{\"end\":5737,\"start\":5312},{\"end\":5999,\"start\":5739},{\"end\":6370,\"start\":6001},{\"end\":6580,\"start\":6372},{\"end\":7113,\"start\":6597},{\"end\":7254,\"start\":7122},{\"end\":7363,\"start\":7277},{\"end\":7891,\"start\":7382},{\"end\":8141,\"start\":7893},{\"end\":8311,\"start\":8143},{\"end\":8880,\"start\":8320},{\"end\":9030,\"start\":8882},{\"end\":9141,\"start\":9032},{\"end\":9371,\"start\":9143},{\"end\":9599,\"start\":9373},{\"end\":9763,\"start\":9601},{\"end\":9894,\"start\":9778},{\"end\":10672,\"start\":9896},{\"end\":10861,\"start\":10674},{\"end\":11305,\"start\":10863},{\"end\":11661,\"start\":11307},{\"end\":12267,\"start\":11663},{\"end\":12573,\"start\":12299},{\"end\":13083,\"start\":12604},{\"end\":13748,\"start\":13085},{\"end\":14589,\"start\":13800},{\"end\":14678,\"start\":14591},{\"end\":15280,\"start\":14680},{\"end\":15643,\"start\":15282},{\"end\":15983,\"start\":15645},{\"end\":16397,\"start\":15985},{\"end\":16866,\"start\":16399},{\"end\":17221,\"start\":16868},{\"end\":17841,\"start\":17253},{\"end\":18200,\"start\":17843},{\"end\":18615,\"start\":18202},{\"end\":18788,\"start\":18617},{\"end\":19127,\"start\":18806},{\"end\":19964,\"start\":19129},{\"end\":20460,\"start\":19966},{\"end\":20880,\"start\":20462},{\"end\":21346,\"start\":20892},{\"end\":21859,\"start\":21348},{\"end\":22276,\"start\":21861},{\"end\":23324,\"start\":22278},{\"end\":23694,\"start\":23326},{\"end\":24434,\"start\":23711},{\"end\":26441,\"start\":24436},{\"end\":26988,\"start\":26443},{\"end\":27422,\"start\":26990},{\"end\":28215,\"start\":27440},{\"end\":28480,\"start\":28227},{\"end\":28958,\"start\":28482},{\"end\":29161,\"start\":28975},{\"end\":29590,\"start\":29163},{\"end\":29737,\"start\":29592},{\"end\":30040,\"start\":29754},{\"end\":30243,\"start\":30042},{\"end\":30831,\"start\":30245},{\"end\":31566,\"start\":30833},{\"end\":31753,\"start\":31568},{\"end\":31983,\"start\":31780},{\"end\":32220,\"start\":32048},{\"end\":2080,\"start\":1571},{\"end\":2882,\"start\":2082},{\"end\":4137,\"start\":2884},{\"end\":4343,\"start\":4152},{\"end\":4632,\"start\":4353},{\"end\":4824,\"start\":4697},{\"end\":4944,\"start\":4826},{\"end\":5186,\"start\":4961},{\"end\":5310,\"start\":5210},{\"end\":5737,\"start\":5312},{\"end\":5999,\"start\":5739},{\"end\":6370,\"start\":6001},{\"end\":6580,\"start\":6372},{\"end\":7113,\"start\":6597},{\"end\":7254,\"start\":7122},{\"end\":7363,\"start\":7277},{\"end\":7891,\"start\":7382},{\"end\":8141,\"start\":7893},{\"end\":8311,\"start\":8143},{\"end\":8880,\"start\":8320},{\"end\":9030,\"start\":8882},{\"end\":9141,\"start\":9032},{\"end\":9371,\"start\":9143},{\"end\":9599,\"start\":9373},{\"end\":9763,\"start\":9601},{\"end\":9894,\"start\":9778},{\"end\":10672,\"start\":9896},{\"end\":10861,\"start\":10674},{\"end\":11305,\"start\":10863},{\"end\":11661,\"start\":11307},{\"end\":12267,\"start\":11663},{\"end\":12573,\"start\":12299},{\"end\":13083,\"start\":12604},{\"end\":13748,\"start\":13085},{\"end\":14589,\"start\":13800},{\"end\":14678,\"start\":14591},{\"end\":15280,\"start\":14680},{\"end\":15643,\"start\":15282},{\"end\":15983,\"start\":15645},{\"end\":16397,\"start\":15985},{\"end\":16866,\"start\":16399},{\"end\":17221,\"start\":16868},{\"end\":17841,\"start\":17253},{\"end\":18200,\"start\":17843},{\"end\":18615,\"start\":18202},{\"end\":18788,\"start\":18617},{\"end\":19127,\"start\":18806},{\"end\":19964,\"start\":19129},{\"end\":20460,\"start\":19966},{\"end\":20880,\"start\":20462},{\"end\":21346,\"start\":20892},{\"end\":21859,\"start\":21348},{\"end\":22276,\"start\":21861},{\"end\":23324,\"start\":22278},{\"end\":23694,\"start\":23326},{\"end\":24434,\"start\":23711},{\"end\":26441,\"start\":24436},{\"end\":26988,\"start\":26443},{\"end\":27422,\"start\":26990},{\"end\":28215,\"start\":27440},{\"end\":28480,\"start\":28227},{\"end\":28958,\"start\":28482},{\"end\":29161,\"start\":28975},{\"end\":29590,\"start\":29163},{\"end\":29737,\"start\":29592},{\"end\":30040,\"start\":29754},{\"end\":30243,\"start\":30042},{\"end\":30831,\"start\":30245},{\"end\":31566,\"start\":30833},{\"end\":31753,\"start\":31568},{\"end\":31983,\"start\":31780},{\"end\":32220,\"start\":32048}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":4696,\"start\":4633},{\"attributes\":{\"id\":\"formula_0\"},\"end\":4696,\"start\":4633}]", "table_ref": "[{\"end\":13306,\"start\":13299},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":16000,\"start\":15993},{\"end\":17853,\"start\":17846},{\"end\":17893,\"start\":17886},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":22319,\"start\":22312},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":26484,\"start\":26477},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":28260,\"start\":28253},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":29646,\"start\":29639},{\"attributes\":{\"ref_id\":\"tab_14\"},\"end\":31790,\"start\":31783},{\"attributes\":{\"ref_id\":\"tab_16\"},\"end\":32121,\"start\":32113},{\"end\":13306,\"start\":13299},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":16000,\"start\":15993},{\"end\":17853,\"start\":17846},{\"end\":17893,\"start\":17886},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":22319,\"start\":22312},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":26484,\"start\":26477},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":28260,\"start\":28253},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":29646,\"start\":29639},{\"attributes\":{\"ref_id\":\"tab_14\"},\"end\":31790,\"start\":31783},{\"attributes\":{\"ref_id\":\"tab_16\"},\"end\":32121,\"start\":32113}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1569,\"start\":1557},{\"attributes\":{\"n\":\"2\"},\"end\":4150,\"start\":4140},{\"attributes\":{\"n\":\"2.1\"},\"end\":4351,\"start\":4346},{\"attributes\":{\"n\":\"2.2\"},\"end\":4959,\"start\":4947},{\"attributes\":{\"n\":\"2.3\"},\"end\":5208,\"start\":5189},{\"attributes\":{\"n\":\"2.4\"},\"end\":6595,\"start\":6583},{\"attributes\":{\"n\":\"2.5\"},\"end\":7120,\"start\":7116},{\"attributes\":{\"n\":\"3\"},\"end\":7275,\"start\":7257},{\"attributes\":{\"n\":\"3.1\"},\"end\":7380,\"start\":7366},{\"attributes\":{\"n\":\"3.2\"},\"end\":8318,\"start\":8314},{\"attributes\":{\"n\":\"3.3\"},\"end\":9776,\"start\":9766},{\"attributes\":{\"n\":\"4\"},\"end\":12297,\"start\":12270},{\"attributes\":{\"n\":\"4.1\"},\"end\":12602,\"start\":12576},{\"attributes\":{\"n\":\"4.2\"},\"end\":13798,\"start\":13751},{\"attributes\":{\"n\":\"4.3\"},\"end\":17251,\"start\":17224},{\"attributes\":{\"n\":\"4.4\"},\"end\":18804,\"start\":18791},{\"attributes\":{\"n\":\"5\"},\"end\":20890,\"start\":20883},{\"attributes\":{\"n\":\"5.1\"},\"end\":23709,\"start\":23697},{\"attributes\":{\"n\":\"5.2\"},\"end\":27438,\"start\":27425},{\"end\":28225,\"start\":28218},{\"attributes\":{\"n\":\"5.3\"},\"end\":28973,\"start\":28961},{\"attributes\":{\"n\":\"6\"},\"end\":29752,\"start\":29740},{\"end\":31778,\"start\":31756},{\"end\":32015,\"start\":31986},{\"end\":32046,\"start\":32018},{\"end\":32258,\"start\":32223},{\"end\":32261,\"start\":32260},{\"end\":33319,\"start\":33310},{\"end\":33685,\"start\":33676},{\"end\":34140,\"start\":34131},{\"end\":34620,\"start\":34611},{\"end\":34907,\"start\":34898},{\"end\":35010,\"start\":35003},{\"end\":35102,\"start\":35093},{\"end\":35673,\"start\":35664},{\"end\":35990,\"start\":35980},{\"attributes\":{\"n\":\"1\"},\"end\":1569,\"start\":1557},{\"attributes\":{\"n\":\"2\"},\"end\":4150,\"start\":4140},{\"attributes\":{\"n\":\"2.1\"},\"end\":4351,\"start\":4346},{\"attributes\":{\"n\":\"2.2\"},\"end\":4959,\"start\":4947},{\"attributes\":{\"n\":\"2.3\"},\"end\":5208,\"start\":5189},{\"attributes\":{\"n\":\"2.4\"},\"end\":6595,\"start\":6583},{\"attributes\":{\"n\":\"2.5\"},\"end\":7120,\"start\":7116},{\"attributes\":{\"n\":\"3\"},\"end\":7275,\"start\":7257},{\"attributes\":{\"n\":\"3.1\"},\"end\":7380,\"start\":7366},{\"attributes\":{\"n\":\"3.2\"},\"end\":8318,\"start\":8314},{\"attributes\":{\"n\":\"3.3\"},\"end\":9776,\"start\":9766},{\"attributes\":{\"n\":\"4\"},\"end\":12297,\"start\":12270},{\"attributes\":{\"n\":\"4.1\"},\"end\":12602,\"start\":12576},{\"attributes\":{\"n\":\"4.2\"},\"end\":13798,\"start\":13751},{\"attributes\":{\"n\":\"4.3\"},\"end\":17251,\"start\":17224},{\"attributes\":{\"n\":\"4.4\"},\"end\":18804,\"start\":18791},{\"attributes\":{\"n\":\"5\"},\"end\":20890,\"start\":20883},{\"attributes\":{\"n\":\"5.1\"},\"end\":23709,\"start\":23697},{\"attributes\":{\"n\":\"5.2\"},\"end\":27438,\"start\":27425},{\"end\":28225,\"start\":28218},{\"attributes\":{\"n\":\"5.3\"},\"end\":28973,\"start\":28961},{\"attributes\":{\"n\":\"6\"},\"end\":29752,\"start\":29740},{\"end\":31778,\"start\":31756},{\"end\":32015,\"start\":31986},{\"end\":32046,\"start\":32018},{\"end\":32258,\"start\":32223},{\"end\":32261,\"start\":32260},{\"end\":33319,\"start\":33310},{\"end\":33685,\"start\":33676},{\"end\":34140,\"start\":34131},{\"end\":34620,\"start\":34611},{\"end\":34907,\"start\":34898},{\"end\":35010,\"start\":35003},{\"end\":35102,\"start\":35093},{\"end\":35673,\"start\":35664},{\"end\":35990,\"start\":35980}]", "table": "[{\"end\":33308,\"start\":33168},{\"end\":34129,\"start\":34002},{\"end\":34609,\"start\":34142},{\"end\":34896,\"start\":34622},{\"end\":35662,\"start\":35180},{\"end\":35978,\"start\":35739},{\"end\":33308,\"start\":33168},{\"end\":34129,\"start\":34002},{\"end\":34609,\"start\":34142},{\"end\":34896,\"start\":34622},{\"end\":35662,\"start\":35180},{\"end\":35978,\"start\":35739}]", "figure_caption": "[{\"end\":32923,\"start\":32262},{\"end\":33168,\"start\":32926},{\"end\":33674,\"start\":33321},{\"end\":34002,\"start\":33687},{\"end\":35001,\"start\":34909},{\"end\":35091,\"start\":35012},{\"end\":35180,\"start\":35104},{\"end\":35739,\"start\":35675},{\"end\":36062,\"start\":35993},{\"end\":32923,\"start\":32262},{\"end\":33168,\"start\":32926},{\"end\":33674,\"start\":33321},{\"end\":34002,\"start\":33687},{\"end\":35001,\"start\":34909},{\"end\":35091,\"start\":35012},{\"end\":35180,\"start\":35104},{\"end\":35739,\"start\":35675},{\"end\":36062,\"start\":35993}]", "figure_ref": null, "bib_author_first_name": "[{\"end\":36708,\"start\":36703},{\"end\":36724,\"start\":36717},{\"end\":37117,\"start\":37111},{\"end\":37133,\"start\":37127},{\"end\":37148,\"start\":37142},{\"end\":37158,\"start\":37154},{\"end\":37179,\"start\":37172},{\"end\":37452,\"start\":37449},{\"end\":37466,\"start\":37463},{\"end\":37478,\"start\":37474},{\"end\":37490,\"start\":37486},{\"end\":37504,\"start\":37498},{\"end\":37526,\"start\":37518},{\"end\":37540,\"start\":37536},{\"end\":38040,\"start\":38035},{\"end\":38056,\"start\":38053},{\"end\":38067,\"start\":38064},{\"end\":38073,\"start\":38068},{\"end\":38086,\"start\":38080},{\"end\":38108,\"start\":38100},{\"end\":38344,\"start\":38339},{\"end\":38373,\"start\":38362},{\"end\":38395,\"start\":38382},{\"end\":38751,\"start\":38744},{\"end\":38764,\"start\":38758},{\"end\":38779,\"start\":38773},{\"end\":38793,\"start\":38785},{\"end\":38806,\"start\":38801},{\"end\":39084,\"start\":39080},{\"end\":39104,\"start\":39096},{\"end\":39535,\"start\":39534},{\"end\":39550,\"start\":39544},{\"end\":39838,\"start\":39833},{\"end\":39855,\"start\":39847},{\"end\":39869,\"start\":39863},{\"end\":39883,\"start\":39875},{\"end\":40253,\"start\":40252},{\"end\":40268,\"start\":40263},{\"end\":40650,\"start\":40648},{\"end\":40660,\"start\":40657},{\"end\":40673,\"start\":40667},{\"end\":40684,\"start\":40680},{\"end\":40698,\"start\":40690},{\"end\":40706,\"start\":40704},{\"end\":40721,\"start\":40713},{\"end\":40731,\"start\":40727},{\"end\":40748,\"start\":40738},{\"end\":41086,\"start\":41080},{\"end\":41108,\"start\":41100},{\"end\":41121,\"start\":41118},{\"end\":41133,\"start\":41129},{\"end\":41522,\"start\":41517},{\"end\":41538,\"start\":41533},{\"end\":41740,\"start\":41735},{\"end\":41756,\"start\":41750},{\"end\":41774,\"start\":41767},{\"end\":41791,\"start\":41787},{\"end\":42130,\"start\":42127},{\"end\":42147,\"start\":42142},{\"end\":42465,\"start\":42458},{\"end\":42480,\"start\":42476},{\"end\":42742,\"start\":42736},{\"end\":42760,\"start\":42751},{\"end\":42987,\"start\":42980},{\"end\":43000,\"start\":42994},{\"end\":43016,\"start\":43011},{\"end\":43276,\"start\":43270},{\"end\":43289,\"start\":43284},{\"end\":43302,\"start\":43296},{\"end\":43314,\"start\":43308},{\"end\":43316,\"start\":43315},{\"end\":43327,\"start\":43323},{\"end\":43345,\"start\":43341},{\"end\":43634,\"start\":43626},{\"end\":43648,\"start\":43643},{\"end\":43927,\"start\":43918},{\"end\":43951,\"start\":43941},{\"end\":43965,\"start\":43959},{\"end\":43981,\"start\":43975},{\"end\":44231,\"start\":44225},{\"end\":44242,\"start\":44237},{\"end\":44255,\"start\":44248},{\"end\":44267,\"start\":44261},{\"end\":44280,\"start\":44274},{\"end\":44566,\"start\":44557},{\"end\":44581,\"start\":44575},{\"end\":44814,\"start\":44813},{\"end\":44829,\"start\":44823},{\"end\":44845,\"start\":44840},{\"end\":45222,\"start\":45214},{\"end\":45237,\"start\":45228},{\"end\":45248,\"start\":45242},{\"end\":45263,\"start\":45255},{\"end\":45512,\"start\":45504},{\"end\":45527,\"start\":45518},{\"end\":45538,\"start\":45532},{\"end\":45553,\"start\":45545},{\"end\":45885,\"start\":45880},{\"end\":45899,\"start\":45894},{\"end\":45917,\"start\":45910},{\"end\":45932,\"start\":45925},{\"end\":46240,\"start\":46233},{\"end\":46261,\"start\":46255},{\"end\":46275,\"start\":46270},{\"end\":46290,\"start\":46283},{\"end\":46304,\"start\":46299},{\"end\":46317,\"start\":46312},{\"end\":46331,\"start\":46326},{\"end\":46349,\"start\":46342},{\"end\":46366,\"start\":46359},{\"end\":46383,\"start\":46377},{\"end\":46398,\"start\":46395},{\"end\":46736,\"start\":46727},{\"end\":46926,\"start\":46922},{\"end\":46938,\"start\":46932},{\"end\":46953,\"start\":46947},{\"end\":46969,\"start\":46963},{\"end\":46978,\"start\":46975},{\"end\":46992,\"start\":46986},{\"end\":47002,\"start\":46997},{\"end\":47020,\"start\":47013},{\"end\":47427,\"start\":47423},{\"end\":47439,\"start\":47433},{\"end\":47453,\"start\":47448},{\"end\":47471,\"start\":47464},{\"end\":47808,\"start\":47804},{\"end\":47820,\"start\":47817},{\"end\":47835,\"start\":47828},{\"end\":47853,\"start\":47846},{\"end\":47868,\"start\":47862},{\"end\":47882,\"start\":47875},{\"end\":47897,\"start\":47891},{\"end\":47908,\"start\":47903},{\"end\":47924,\"start\":47920},{\"end\":47937,\"start\":47933},{\"end\":48239,\"start\":48232},{\"end\":48252,\"start\":48248},{\"end\":48267,\"start\":48262},{\"end\":48279,\"start\":48275},{\"end\":48300,\"start\":48289},{\"end\":48314,\"start\":48308},{\"end\":48324,\"start\":48320},{\"end\":48701,\"start\":48697},{\"end\":48718,\"start\":48711},{\"end\":49008,\"start\":49004},{\"end\":49025,\"start\":49018},{\"end\":49035,\"start\":49030},{\"end\":49048,\"start\":49043},{\"end\":49060,\"start\":49055},{\"end\":49073,\"start\":49069},{\"end\":49346,\"start\":49340},{\"end\":49363,\"start\":49358},{\"end\":49374,\"start\":49369},{\"end\":49665,\"start\":49659},{\"end\":49681,\"start\":49677},{\"end\":49699,\"start\":49689},{\"end\":49714,\"start\":49709},{\"end\":50043,\"start\":50039},{\"end\":50059,\"start\":50054},{\"end\":50077,\"start\":50068},{\"end\":50407,\"start\":50400},{\"end\":50420,\"start\":50416},{\"end\":50436,\"start\":50432},{\"end\":50446,\"start\":50441},{\"end\":50456,\"start\":50455},{\"end\":50476,\"start\":50470},{\"end\":50497,\"start\":50486},{\"end\":50903,\"start\":50897},{\"end\":50912,\"start\":50910},{\"end\":50921,\"start\":50918},{\"end\":50935,\"start\":50927},{\"end\":50947,\"start\":50940},{\"end\":51209,\"start\":51201},{\"end\":51233,\"start\":51228},{\"end\":51246,\"start\":51240},{\"end\":51255,\"start\":51251},{\"end\":51265,\"start\":51262},{\"end\":51278,\"start\":51272},{\"end\":51294,\"start\":51286},{\"end\":51309,\"start\":51306},{\"end\":51695,\"start\":51694},{\"end\":51709,\"start\":51703},{\"end\":51896,\"start\":51890},{\"end\":51910,\"start\":51906},{\"end\":51924,\"start\":51920},{\"end\":51938,\"start\":51933},{\"end\":51955,\"start\":51950},{\"end\":51968,\"start\":51963},{\"end\":51970,\"start\":51969},{\"end\":51984,\"start\":51978},{\"end\":51998,\"start\":51993},{\"end\":52365,\"start\":52361},{\"end\":52376,\"start\":52372},{\"end\":52398,\"start\":52392},{\"end\":52416,\"start\":52407},{\"end\":52430,\"start\":52424},{\"end\":52445,\"start\":52440},{\"end\":52456,\"start\":52452},{\"end\":52469,\"start\":52463},{\"end\":52471,\"start\":52470},{\"end\":52838,\"start\":52834},{\"end\":52854,\"start\":52845},{\"end\":52868,\"start\":52862},{\"end\":52883,\"start\":52878},{\"end\":52894,\"start\":52890},{\"end\":52907,\"start\":52901},{\"end\":52909,\"start\":52908},{\"end\":53240,\"start\":53236},{\"end\":53260,\"start\":53251},{\"end\":53274,\"start\":53268},{\"end\":53276,\"start\":53275},{\"end\":53560,\"start\":53555},{\"end\":53577,\"start\":53571},{\"end\":53592,\"start\":53586},{\"end\":53883,\"start\":53877},{\"end\":53896,\"start\":53890},{\"end\":53908,\"start\":53902},{\"end\":53920,\"start\":53915},{\"end\":53938,\"start\":53932},{\"end\":53960,\"start\":53954},{\"end\":54283,\"start\":54279},{\"end\":54293,\"start\":54289},{\"end\":54306,\"start\":54298},{\"end\":54320,\"start\":54313},{\"end\":54332,\"start\":54327},{\"end\":54348,\"start\":54341},{\"end\":54632,\"start\":54627},{\"end\":54645,\"start\":54642},{\"end\":54662,\"start\":54656},{\"end\":54679,\"start\":54672},{\"end\":54689,\"start\":54686},{\"end\":54708,\"start\":54699},{\"end\":54723,\"start\":54718},{\"end\":55088,\"start\":55083},{\"end\":55098,\"start\":55094},{\"end\":55113,\"start\":55106},{\"end\":55127,\"start\":55121},{\"end\":55149,\"start\":55143},{\"end\":55166,\"start\":55159},{\"end\":55182,\"start\":55177},{\"end\":36708,\"start\":36703},{\"end\":36724,\"start\":36717},{\"end\":37117,\"start\":37111},{\"end\":37133,\"start\":37127},{\"end\":37148,\"start\":37142},{\"end\":37158,\"start\":37154},{\"end\":37179,\"start\":37172},{\"end\":37452,\"start\":37449},{\"end\":37466,\"start\":37463},{\"end\":37478,\"start\":37474},{\"end\":37490,\"start\":37486},{\"end\":37504,\"start\":37498},{\"end\":37526,\"start\":37518},{\"end\":37540,\"start\":37536},{\"end\":38040,\"start\":38035},{\"end\":38056,\"start\":38053},{\"end\":38067,\"start\":38064},{\"end\":38073,\"start\":38068},{\"end\":38086,\"start\":38080},{\"end\":38108,\"start\":38100},{\"end\":38344,\"start\":38339},{\"end\":38373,\"start\":38362},{\"end\":38395,\"start\":38382},{\"end\":38751,\"start\":38744},{\"end\":38764,\"start\":38758},{\"end\":38779,\"start\":38773},{\"end\":38793,\"start\":38785},{\"end\":38806,\"start\":38801},{\"end\":39084,\"start\":39080},{\"end\":39104,\"start\":39096},{\"end\":39535,\"start\":39534},{\"end\":39550,\"start\":39544},{\"end\":39838,\"start\":39833},{\"end\":39855,\"start\":39847},{\"end\":39869,\"start\":39863},{\"end\":39883,\"start\":39875},{\"end\":40253,\"start\":40252},{\"end\":40268,\"start\":40263},{\"end\":40650,\"start\":40648},{\"end\":40660,\"start\":40657},{\"end\":40673,\"start\":40667},{\"end\":40684,\"start\":40680},{\"end\":40698,\"start\":40690},{\"end\":40706,\"start\":40704},{\"end\":40721,\"start\":40713},{\"end\":40731,\"start\":40727},{\"end\":40748,\"start\":40738},{\"end\":41086,\"start\":41080},{\"end\":41108,\"start\":41100},{\"end\":41121,\"start\":41118},{\"end\":41133,\"start\":41129},{\"end\":41522,\"start\":41517},{\"end\":41538,\"start\":41533},{\"end\":41740,\"start\":41735},{\"end\":41756,\"start\":41750},{\"end\":41774,\"start\":41767},{\"end\":41791,\"start\":41787},{\"end\":42130,\"start\":42127},{\"end\":42147,\"start\":42142},{\"end\":42465,\"start\":42458},{\"end\":42480,\"start\":42476},{\"end\":42742,\"start\":42736},{\"end\":42760,\"start\":42751},{\"end\":42987,\"start\":42980},{\"end\":43000,\"start\":42994},{\"end\":43016,\"start\":43011},{\"end\":43276,\"start\":43270},{\"end\":43289,\"start\":43284},{\"end\":43302,\"start\":43296},{\"end\":43314,\"start\":43308},{\"end\":43316,\"start\":43315},{\"end\":43327,\"start\":43323},{\"end\":43345,\"start\":43341},{\"end\":43634,\"start\":43626},{\"end\":43648,\"start\":43643},{\"end\":43927,\"start\":43918},{\"end\":43951,\"start\":43941},{\"end\":43965,\"start\":43959},{\"end\":43981,\"start\":43975},{\"end\":44231,\"start\":44225},{\"end\":44242,\"start\":44237},{\"end\":44255,\"start\":44248},{\"end\":44267,\"start\":44261},{\"end\":44280,\"start\":44274},{\"end\":44566,\"start\":44557},{\"end\":44581,\"start\":44575},{\"end\":44814,\"start\":44813},{\"end\":44829,\"start\":44823},{\"end\":44845,\"start\":44840},{\"end\":45222,\"start\":45214},{\"end\":45237,\"start\":45228},{\"end\":45248,\"start\":45242},{\"end\":45263,\"start\":45255},{\"end\":45512,\"start\":45504},{\"end\":45527,\"start\":45518},{\"end\":45538,\"start\":45532},{\"end\":45553,\"start\":45545},{\"end\":45885,\"start\":45880},{\"end\":45899,\"start\":45894},{\"end\":45917,\"start\":45910},{\"end\":45932,\"start\":45925},{\"end\":46240,\"start\":46233},{\"end\":46261,\"start\":46255},{\"end\":46275,\"start\":46270},{\"end\":46290,\"start\":46283},{\"end\":46304,\"start\":46299},{\"end\":46317,\"start\":46312},{\"end\":46331,\"start\":46326},{\"end\":46349,\"start\":46342},{\"end\":46366,\"start\":46359},{\"end\":46383,\"start\":46377},{\"end\":46398,\"start\":46395},{\"end\":46736,\"start\":46727},{\"end\":46926,\"start\":46922},{\"end\":46938,\"start\":46932},{\"end\":46953,\"start\":46947},{\"end\":46969,\"start\":46963},{\"end\":46978,\"start\":46975},{\"end\":46992,\"start\":46986},{\"end\":47002,\"start\":46997},{\"end\":47020,\"start\":47013},{\"end\":47427,\"start\":47423},{\"end\":47439,\"start\":47433},{\"end\":47453,\"start\":47448},{\"end\":47471,\"start\":47464},{\"end\":47808,\"start\":47804},{\"end\":47820,\"start\":47817},{\"end\":47835,\"start\":47828},{\"end\":47853,\"start\":47846},{\"end\":47868,\"start\":47862},{\"end\":47882,\"start\":47875},{\"end\":47897,\"start\":47891},{\"end\":47908,\"start\":47903},{\"end\":47924,\"start\":47920},{\"end\":47937,\"start\":47933},{\"end\":48239,\"start\":48232},{\"end\":48252,\"start\":48248},{\"end\":48267,\"start\":48262},{\"end\":48279,\"start\":48275},{\"end\":48300,\"start\":48289},{\"end\":48314,\"start\":48308},{\"end\":48324,\"start\":48320},{\"end\":48701,\"start\":48697},{\"end\":48718,\"start\":48711},{\"end\":49008,\"start\":49004},{\"end\":49025,\"start\":49018},{\"end\":49035,\"start\":49030},{\"end\":49048,\"start\":49043},{\"end\":49060,\"start\":49055},{\"end\":49073,\"start\":49069},{\"end\":49346,\"start\":49340},{\"end\":49363,\"start\":49358},{\"end\":49374,\"start\":49369},{\"end\":49665,\"start\":49659},{\"end\":49681,\"start\":49677},{\"end\":49699,\"start\":49689},{\"end\":49714,\"start\":49709},{\"end\":50043,\"start\":50039},{\"end\":50059,\"start\":50054},{\"end\":50077,\"start\":50068},{\"end\":50407,\"start\":50400},{\"end\":50420,\"start\":50416},{\"end\":50436,\"start\":50432},{\"end\":50446,\"start\":50441},{\"end\":50456,\"start\":50455},{\"end\":50476,\"start\":50470},{\"end\":50497,\"start\":50486},{\"end\":50903,\"start\":50897},{\"end\":50912,\"start\":50910},{\"end\":50921,\"start\":50918},{\"end\":50935,\"start\":50927},{\"end\":50947,\"start\":50940},{\"end\":51209,\"start\":51201},{\"end\":51233,\"start\":51228},{\"end\":51246,\"start\":51240},{\"end\":51255,\"start\":51251},{\"end\":51265,\"start\":51262},{\"end\":51278,\"start\":51272},{\"end\":51294,\"start\":51286},{\"end\":51309,\"start\":51306},{\"end\":51695,\"start\":51694},{\"end\":51709,\"start\":51703},{\"end\":51896,\"start\":51890},{\"end\":51910,\"start\":51906},{\"end\":51924,\"start\":51920},{\"end\":51938,\"start\":51933},{\"end\":51955,\"start\":51950},{\"end\":51968,\"start\":51963},{\"end\":51970,\"start\":51969},{\"end\":51984,\"start\":51978},{\"end\":51998,\"start\":51993},{\"end\":52365,\"start\":52361},{\"end\":52376,\"start\":52372},{\"end\":52398,\"start\":52392},{\"end\":52416,\"start\":52407},{\"end\":52430,\"start\":52424},{\"end\":52445,\"start\":52440},{\"end\":52456,\"start\":52452},{\"end\":52469,\"start\":52463},{\"end\":52471,\"start\":52470},{\"end\":52838,\"start\":52834},{\"end\":52854,\"start\":52845},{\"end\":52868,\"start\":52862},{\"end\":52883,\"start\":52878},{\"end\":52894,\"start\":52890},{\"end\":52907,\"start\":52901},{\"end\":52909,\"start\":52908},{\"end\":53240,\"start\":53236},{\"end\":53260,\"start\":53251},{\"end\":53274,\"start\":53268},{\"end\":53276,\"start\":53275},{\"end\":53560,\"start\":53555},{\"end\":53577,\"start\":53571},{\"end\":53592,\"start\":53586},{\"end\":53883,\"start\":53877},{\"end\":53896,\"start\":53890},{\"end\":53908,\"start\":53902},{\"end\":53920,\"start\":53915},{\"end\":53938,\"start\":53932},{\"end\":53960,\"start\":53954},{\"end\":54283,\"start\":54279},{\"end\":54293,\"start\":54289},{\"end\":54306,\"start\":54298},{\"end\":54320,\"start\":54313},{\"end\":54332,\"start\":54327},{\"end\":54348,\"start\":54341},{\"end\":54632,\"start\":54627},{\"end\":54645,\"start\":54642},{\"end\":54662,\"start\":54656},{\"end\":54679,\"start\":54672},{\"end\":54689,\"start\":54686},{\"end\":54708,\"start\":54699},{\"end\":54723,\"start\":54718},{\"end\":55088,\"start\":55083},{\"end\":55098,\"start\":55094},{\"end\":55113,\"start\":55106},{\"end\":55127,\"start\":55121},{\"end\":55149,\"start\":55143},{\"end\":55166,\"start\":55159},{\"end\":55182,\"start\":55177}]", "bib_author_last_name": "[{\"end\":36715,\"start\":36709},{\"end\":36750,\"start\":36725},{\"end\":36763,\"start\":36752},{\"end\":37125,\"start\":37118},{\"end\":37140,\"start\":37134},{\"end\":37152,\"start\":37149},{\"end\":37170,\"start\":37159},{\"end\":37184,\"start\":37180},{\"end\":37461,\"start\":37453},{\"end\":37472,\"start\":37467},{\"end\":37484,\"start\":37479},{\"end\":37496,\"start\":37491},{\"end\":37516,\"start\":37505},{\"end\":37534,\"start\":37527},{\"end\":37549,\"start\":37541},{\"end\":38051,\"start\":38041},{\"end\":38062,\"start\":38057},{\"end\":38078,\"start\":38074},{\"end\":38098,\"start\":38087},{\"end\":38116,\"start\":38109},{\"end\":38360,\"start\":38345},{\"end\":38380,\"start\":38374},{\"end\":38401,\"start\":38396},{\"end\":38410,\"start\":38403},{\"end\":38756,\"start\":38752},{\"end\":38771,\"start\":38765},{\"end\":38783,\"start\":38780},{\"end\":38799,\"start\":38794},{\"end\":38816,\"start\":38807},{\"end\":39094,\"start\":39085},{\"end\":39113,\"start\":39105},{\"end\":39122,\"start\":39115},{\"end\":39542,\"start\":39536},{\"end\":39554,\"start\":39551},{\"end\":39558,\"start\":39556},{\"end\":39845,\"start\":39839},{\"end\":39861,\"start\":39856},{\"end\":39873,\"start\":39870},{\"end\":39893,\"start\":39884},{\"end\":40261,\"start\":40254},{\"end\":40274,\"start\":40269},{\"end\":40284,\"start\":40276},{\"end\":40655,\"start\":40651},{\"end\":40665,\"start\":40661},{\"end\":40678,\"start\":40674},{\"end\":40688,\"start\":40685},{\"end\":40702,\"start\":40699},{\"end\":40711,\"start\":40707},{\"end\":40725,\"start\":40722},{\"end\":40736,\"start\":40732},{\"end\":40752,\"start\":40749},{\"end\":41098,\"start\":41087},{\"end\":41116,\"start\":41109},{\"end\":41127,\"start\":41122},{\"end\":41139,\"start\":41134},{\"end\":41531,\"start\":41523},{\"end\":41544,\"start\":41539},{\"end\":41748,\"start\":41741},{\"end\":41765,\"start\":41757},{\"end\":41785,\"start\":41775},{\"end\":41796,\"start\":41792},{\"end\":42140,\"start\":42131},{\"end\":42154,\"start\":42148},{\"end\":42474,\"start\":42466},{\"end\":42488,\"start\":42481},{\"end\":42749,\"start\":42743},{\"end\":42766,\"start\":42761},{\"end\":42992,\"start\":42988},{\"end\":43009,\"start\":43001},{\"end\":43024,\"start\":43017},{\"end\":43282,\"start\":43277},{\"end\":43294,\"start\":43290},{\"end\":43306,\"start\":43303},{\"end\":43321,\"start\":43317},{\"end\":43339,\"start\":43328},{\"end\":43350,\"start\":43346},{\"end\":43641,\"start\":43635},{\"end\":43651,\"start\":43649},{\"end\":43939,\"start\":43928},{\"end\":43957,\"start\":43952},{\"end\":43973,\"start\":43966},{\"end\":43990,\"start\":43982},{\"end\":44003,\"start\":43992},{\"end\":44235,\"start\":44232},{\"end\":44246,\"start\":44243},{\"end\":44259,\"start\":44256},{\"end\":44272,\"start\":44268},{\"end\":44285,\"start\":44281},{\"end\":44573,\"start\":44567},{\"end\":44589,\"start\":44582},{\"end\":44821,\"start\":44815},{\"end\":44838,\"start\":44830},{\"end\":44851,\"start\":44846},{\"end\":44864,\"start\":44853},{\"end\":45226,\"start\":45223},{\"end\":45240,\"start\":45238},{\"end\":45253,\"start\":45249},{\"end\":45267,\"start\":45264},{\"end\":45516,\"start\":45513},{\"end\":45530,\"start\":45528},{\"end\":45543,\"start\":45539},{\"end\":45557,\"start\":45554},{\"end\":45892,\"start\":45886},{\"end\":45908,\"start\":45900},{\"end\":45923,\"start\":45918},{\"end\":45939,\"start\":45933},{\"end\":46253,\"start\":46241},{\"end\":46268,\"start\":46262},{\"end\":46281,\"start\":46276},{\"end\":46297,\"start\":46291},{\"end\":46310,\"start\":46305},{\"end\":46324,\"start\":46318},{\"end\":46340,\"start\":46332},{\"end\":46357,\"start\":46350},{\"end\":46375,\"start\":46367},{\"end\":46393,\"start\":46384},{\"end\":46401,\"start\":46399},{\"end\":46742,\"start\":46737},{\"end\":46930,\"start\":46927},{\"end\":46945,\"start\":46939},{\"end\":46961,\"start\":46954},{\"end\":46973,\"start\":46970},{\"end\":46984,\"start\":46979},{\"end\":46995,\"start\":46993},{\"end\":47011,\"start\":47003},{\"end\":47025,\"start\":47021},{\"end\":47431,\"start\":47428},{\"end\":47446,\"start\":47440},{\"end\":47462,\"start\":47454},{\"end\":47476,\"start\":47472},{\"end\":47815,\"start\":47809},{\"end\":47826,\"start\":47821},{\"end\":47844,\"start\":47836},{\"end\":47860,\"start\":47854},{\"end\":47873,\"start\":47869},{\"end\":47889,\"start\":47883},{\"end\":47901,\"start\":47898},{\"end\":47918,\"start\":47909},{\"end\":47931,\"start\":47925},{\"end\":47943,\"start\":47938},{\"end\":48246,\"start\":48240},{\"end\":48260,\"start\":48253},{\"end\":48273,\"start\":48268},{\"end\":48287,\"start\":48280},{\"end\":48306,\"start\":48301},{\"end\":48318,\"start\":48315},{\"end\":48336,\"start\":48325},{\"end\":48709,\"start\":48702},{\"end\":48729,\"start\":48719},{\"end\":49016,\"start\":49009},{\"end\":49028,\"start\":49026},{\"end\":49041,\"start\":49036},{\"end\":49053,\"start\":49049},{\"end\":49067,\"start\":49061},{\"end\":49083,\"start\":49074},{\"end\":49356,\"start\":49347},{\"end\":49367,\"start\":49364},{\"end\":49380,\"start\":49375},{\"end\":49675,\"start\":49666},{\"end\":49687,\"start\":49682},{\"end\":49707,\"start\":49700},{\"end\":49720,\"start\":49715},{\"end\":50052,\"start\":50044},{\"end\":50066,\"start\":50060},{\"end\":50083,\"start\":50078},{\"end\":50414,\"start\":50408},{\"end\":50430,\"start\":50421},{\"end\":50439,\"start\":50437},{\"end\":50453,\"start\":50447},{\"end\":50468,\"start\":50457},{\"end\":50484,\"start\":50477},{\"end\":50500,\"start\":50498},{\"end\":50507,\"start\":50502},{\"end\":50908,\"start\":50904},{\"end\":50916,\"start\":50913},{\"end\":50925,\"start\":50922},{\"end\":50938,\"start\":50936},{\"end\":50951,\"start\":50948},{\"end\":51226,\"start\":51210},{\"end\":51238,\"start\":51234},{\"end\":51249,\"start\":51247},{\"end\":51260,\"start\":51256},{\"end\":51270,\"start\":51266},{\"end\":51284,\"start\":51279},{\"end\":51299,\"start\":51295},{\"end\":51304,\"start\":51301},{\"end\":51318,\"start\":51310},{\"end\":51322,\"start\":51320},{\"end\":51701,\"start\":51696},{\"end\":51715,\"start\":51710},{\"end\":51719,\"start\":51717},{\"end\":51904,\"start\":51897},{\"end\":51918,\"start\":51911},{\"end\":51931,\"start\":51925},{\"end\":51948,\"start\":51939},{\"end\":51961,\"start\":51956},{\"end\":51976,\"start\":51971},{\"end\":51991,\"start\":51985},{\"end\":52009,\"start\":51999},{\"end\":52370,\"start\":52366},{\"end\":52390,\"start\":52377},{\"end\":52405,\"start\":52399},{\"end\":52422,\"start\":52417},{\"end\":52438,\"start\":52431},{\"end\":52450,\"start\":52446},{\"end\":52461,\"start\":52457},{\"end\":52478,\"start\":52472},{\"end\":52843,\"start\":52839},{\"end\":52860,\"start\":52855},{\"end\":52876,\"start\":52869},{\"end\":52888,\"start\":52884},{\"end\":52899,\"start\":52895},{\"end\":52916,\"start\":52910},{\"end\":53249,\"start\":53241},{\"end\":53266,\"start\":53261},{\"end\":53569,\"start\":53561},{\"end\":53584,\"start\":53578},{\"end\":53599,\"start\":53593},{\"end\":53888,\"start\":53884},{\"end\":53900,\"start\":53897},{\"end\":53913,\"start\":53909},{\"end\":53930,\"start\":53921},{\"end\":53952,\"start\":53939},{\"end\":53963,\"start\":53961},{\"end\":54287,\"start\":54284},{\"end\":54296,\"start\":54294},{\"end\":54311,\"start\":54307},{\"end\":54325,\"start\":54321},{\"end\":54339,\"start\":54333},{\"end\":54354,\"start\":54349},{\"end\":54640,\"start\":54633},{\"end\":54654,\"start\":54646},{\"end\":54670,\"start\":54663},{\"end\":54684,\"start\":54680},{\"end\":54697,\"start\":54690},{\"end\":54716,\"start\":54709},{\"end\":54728,\"start\":54724},{\"end\":55092,\"start\":55089},{\"end\":55104,\"start\":55099},{\"end\":55119,\"start\":55114},{\"end\":55141,\"start\":55128},{\"end\":55157,\"start\":55150},{\"end\":55175,\"start\":55167},{\"end\":55189,\"start\":55183},{\"end\":36715,\"start\":36709},{\"end\":36750,\"start\":36725},{\"end\":36763,\"start\":36752},{\"end\":37125,\"start\":37118},{\"end\":37140,\"start\":37134},{\"end\":37152,\"start\":37149},{\"end\":37170,\"start\":37159},{\"end\":37184,\"start\":37180},{\"end\":37461,\"start\":37453},{\"end\":37472,\"start\":37467},{\"end\":37484,\"start\":37479},{\"end\":37496,\"start\":37491},{\"end\":37516,\"start\":37505},{\"end\":37534,\"start\":37527},{\"end\":37549,\"start\":37541},{\"end\":38051,\"start\":38041},{\"end\":38062,\"start\":38057},{\"end\":38078,\"start\":38074},{\"end\":38098,\"start\":38087},{\"end\":38116,\"start\":38109},{\"end\":38360,\"start\":38345},{\"end\":38380,\"start\":38374},{\"end\":38401,\"start\":38396},{\"end\":38410,\"start\":38403},{\"end\":38756,\"start\":38752},{\"end\":38771,\"start\":38765},{\"end\":38783,\"start\":38780},{\"end\":38799,\"start\":38794},{\"end\":38816,\"start\":38807},{\"end\":39094,\"start\":39085},{\"end\":39113,\"start\":39105},{\"end\":39122,\"start\":39115},{\"end\":39542,\"start\":39536},{\"end\":39554,\"start\":39551},{\"end\":39558,\"start\":39556},{\"end\":39845,\"start\":39839},{\"end\":39861,\"start\":39856},{\"end\":39873,\"start\":39870},{\"end\":39893,\"start\":39884},{\"end\":40261,\"start\":40254},{\"end\":40274,\"start\":40269},{\"end\":40284,\"start\":40276},{\"end\":40655,\"start\":40651},{\"end\":40665,\"start\":40661},{\"end\":40678,\"start\":40674},{\"end\":40688,\"start\":40685},{\"end\":40702,\"start\":40699},{\"end\":40711,\"start\":40707},{\"end\":40725,\"start\":40722},{\"end\":40736,\"start\":40732},{\"end\":40752,\"start\":40749},{\"end\":41098,\"start\":41087},{\"end\":41116,\"start\":41109},{\"end\":41127,\"start\":41122},{\"end\":41139,\"start\":41134},{\"end\":41531,\"start\":41523},{\"end\":41544,\"start\":41539},{\"end\":41748,\"start\":41741},{\"end\":41765,\"start\":41757},{\"end\":41785,\"start\":41775},{\"end\":41796,\"start\":41792},{\"end\":42140,\"start\":42131},{\"end\":42154,\"start\":42148},{\"end\":42474,\"start\":42466},{\"end\":42488,\"start\":42481},{\"end\":42749,\"start\":42743},{\"end\":42766,\"start\":42761},{\"end\":42992,\"start\":42988},{\"end\":43009,\"start\":43001},{\"end\":43024,\"start\":43017},{\"end\":43282,\"start\":43277},{\"end\":43294,\"start\":43290},{\"end\":43306,\"start\":43303},{\"end\":43321,\"start\":43317},{\"end\":43339,\"start\":43328},{\"end\":43350,\"start\":43346},{\"end\":43641,\"start\":43635},{\"end\":43651,\"start\":43649},{\"end\":43939,\"start\":43928},{\"end\":43957,\"start\":43952},{\"end\":43973,\"start\":43966},{\"end\":43990,\"start\":43982},{\"end\":44003,\"start\":43992},{\"end\":44235,\"start\":44232},{\"end\":44246,\"start\":44243},{\"end\":44259,\"start\":44256},{\"end\":44272,\"start\":44268},{\"end\":44285,\"start\":44281},{\"end\":44573,\"start\":44567},{\"end\":44589,\"start\":44582},{\"end\":44821,\"start\":44815},{\"end\":44838,\"start\":44830},{\"end\":44851,\"start\":44846},{\"end\":44864,\"start\":44853},{\"end\":45226,\"start\":45223},{\"end\":45240,\"start\":45238},{\"end\":45253,\"start\":45249},{\"end\":45267,\"start\":45264},{\"end\":45516,\"start\":45513},{\"end\":45530,\"start\":45528},{\"end\":45543,\"start\":45539},{\"end\":45557,\"start\":45554},{\"end\":45892,\"start\":45886},{\"end\":45908,\"start\":45900},{\"end\":45923,\"start\":45918},{\"end\":45939,\"start\":45933},{\"end\":46253,\"start\":46241},{\"end\":46268,\"start\":46262},{\"end\":46281,\"start\":46276},{\"end\":46297,\"start\":46291},{\"end\":46310,\"start\":46305},{\"end\":46324,\"start\":46318},{\"end\":46340,\"start\":46332},{\"end\":46357,\"start\":46350},{\"end\":46375,\"start\":46367},{\"end\":46393,\"start\":46384},{\"end\":46401,\"start\":46399},{\"end\":46742,\"start\":46737},{\"end\":46930,\"start\":46927},{\"end\":46945,\"start\":46939},{\"end\":46961,\"start\":46954},{\"end\":46973,\"start\":46970},{\"end\":46984,\"start\":46979},{\"end\":46995,\"start\":46993},{\"end\":47011,\"start\":47003},{\"end\":47025,\"start\":47021},{\"end\":47431,\"start\":47428},{\"end\":47446,\"start\":47440},{\"end\":47462,\"start\":47454},{\"end\":47476,\"start\":47472},{\"end\":47815,\"start\":47809},{\"end\":47826,\"start\":47821},{\"end\":47844,\"start\":47836},{\"end\":47860,\"start\":47854},{\"end\":47873,\"start\":47869},{\"end\":47889,\"start\":47883},{\"end\":47901,\"start\":47898},{\"end\":47918,\"start\":47909},{\"end\":47931,\"start\":47925},{\"end\":47943,\"start\":47938},{\"end\":48246,\"start\":48240},{\"end\":48260,\"start\":48253},{\"end\":48273,\"start\":48268},{\"end\":48287,\"start\":48280},{\"end\":48306,\"start\":48301},{\"end\":48318,\"start\":48315},{\"end\":48336,\"start\":48325},{\"end\":48709,\"start\":48702},{\"end\":48729,\"start\":48719},{\"end\":49016,\"start\":49009},{\"end\":49028,\"start\":49026},{\"end\":49041,\"start\":49036},{\"end\":49053,\"start\":49049},{\"end\":49067,\"start\":49061},{\"end\":49083,\"start\":49074},{\"end\":49356,\"start\":49347},{\"end\":49367,\"start\":49364},{\"end\":49380,\"start\":49375},{\"end\":49675,\"start\":49666},{\"end\":49687,\"start\":49682},{\"end\":49707,\"start\":49700},{\"end\":49720,\"start\":49715},{\"end\":50052,\"start\":50044},{\"end\":50066,\"start\":50060},{\"end\":50083,\"start\":50078},{\"end\":50414,\"start\":50408},{\"end\":50430,\"start\":50421},{\"end\":50439,\"start\":50437},{\"end\":50453,\"start\":50447},{\"end\":50468,\"start\":50457},{\"end\":50484,\"start\":50477},{\"end\":50500,\"start\":50498},{\"end\":50507,\"start\":50502},{\"end\":50908,\"start\":50904},{\"end\":50916,\"start\":50913},{\"end\":50925,\"start\":50922},{\"end\":50938,\"start\":50936},{\"end\":50951,\"start\":50948},{\"end\":51226,\"start\":51210},{\"end\":51238,\"start\":51234},{\"end\":51249,\"start\":51247},{\"end\":51260,\"start\":51256},{\"end\":51270,\"start\":51266},{\"end\":51284,\"start\":51279},{\"end\":51299,\"start\":51295},{\"end\":51304,\"start\":51301},{\"end\":51318,\"start\":51310},{\"end\":51322,\"start\":51320},{\"end\":51701,\"start\":51696},{\"end\":51715,\"start\":51710},{\"end\":51719,\"start\":51717},{\"end\":51904,\"start\":51897},{\"end\":51918,\"start\":51911},{\"end\":51931,\"start\":51925},{\"end\":51948,\"start\":51939},{\"end\":51961,\"start\":51956},{\"end\":51976,\"start\":51971},{\"end\":51991,\"start\":51985},{\"end\":52009,\"start\":51999},{\"end\":52370,\"start\":52366},{\"end\":52390,\"start\":52377},{\"end\":52405,\"start\":52399},{\"end\":52422,\"start\":52417},{\"end\":52438,\"start\":52431},{\"end\":52450,\"start\":52446},{\"end\":52461,\"start\":52457},{\"end\":52478,\"start\":52472},{\"end\":52843,\"start\":52839},{\"end\":52860,\"start\":52855},{\"end\":52876,\"start\":52869},{\"end\":52888,\"start\":52884},{\"end\":52899,\"start\":52895},{\"end\":52916,\"start\":52910},{\"end\":53249,\"start\":53241},{\"end\":53266,\"start\":53261},{\"end\":53569,\"start\":53561},{\"end\":53584,\"start\":53578},{\"end\":53599,\"start\":53593},{\"end\":53888,\"start\":53884},{\"end\":53900,\"start\":53897},{\"end\":53913,\"start\":53909},{\"end\":53930,\"start\":53921},{\"end\":53952,\"start\":53939},{\"end\":53963,\"start\":53961},{\"end\":54287,\"start\":54284},{\"end\":54296,\"start\":54294},{\"end\":54311,\"start\":54307},{\"end\":54325,\"start\":54321},{\"end\":54339,\"start\":54333},{\"end\":54354,\"start\":54349},{\"end\":54640,\"start\":54633},{\"end\":54654,\"start\":54646},{\"end\":54670,\"start\":54663},{\"end\":54684,\"start\":54680},{\"end\":54697,\"start\":54690},{\"end\":54716,\"start\":54709},{\"end\":54728,\"start\":54724},{\"end\":55092,\"start\":55089},{\"end\":55104,\"start\":55099},{\"end\":55119,\"start\":55114},{\"end\":55141,\"start\":55128},{\"end\":55157,\"start\":55150},{\"end\":55175,\"start\":55167},{\"end\":55189,\"start\":55183}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":37057,\"start\":36703},{\"attributes\":{\"doi\":\"arXiv:1903.07785\",\"id\":\"b1\"},\"end\":37387,\"start\":37059},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":13385138},\"end\":37974,\"start\":37389},{\"attributes\":{\"id\":\"b3\"},\"end\":38271,\"start\":37976},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":14604520},\"end\":38683,\"start\":38273},{\"attributes\":{\"doi\":\"arXiv:1906.01604\",\"id\":\"b5\"},\"end\":39025,\"start\":38685},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":8587959},\"end\":39497,\"start\":39027},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":7138078},\"end\":39749,\"start\":39499},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":52967399},\"end\":40187,\"start\":39751},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":16639476},\"end\":40559,\"start\":40189},{\"attributes\":{\"doi\":\"arXiv:1905.03197\",\"id\":\"b10\"},\"end\":41019,\"start\":40561},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":195352006},\"end\":41495,\"start\":41021},{\"attributes\":{\"id\":\"b12\"},\"end\":41682,\"start\":41497},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":5830937},\"end\":42125,\"start\":41684},{\"attributes\":{\"doi\":\"arXiv:1606.08415\",\"id\":\"b14\"},\"end\":42332,\"start\":42127},{\"attributes\":{\"id\":\"b15\"},\"end\":42672,\"start\":42334},{\"attributes\":{\"doi\":\"arXiv:1801.06146\",\"id\":\"b16\"},\"end\":42933,\"start\":42674},{\"attributes\":{\"id\":\"b17\"},\"end\":43197,\"start\":42935},{\"attributes\":{\"doi\":\"arXiv:1907.10529\",\"id\":\"b18\"},\"end\":43580,\"start\":43199},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":6628106},\"end\":43857,\"start\":43582},{\"attributes\":{\"doi\":\"arXiv:1905.06290\",\"id\":\"b20\"},\"end\":44223,\"start\":43859},{\"attributes\":{\"doi\":\"arXiv:1704.04683\",\"id\":\"b21\"},\"end\":44555,\"start\":44225},{\"attributes\":{\"doi\":\"arXiv:1901.07291\",\"id\":\"b22\"},\"end\":44780,\"start\":44557},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":15710851},\"end\":45107,\"start\":44782},{\"attributes\":{\"doi\":\"arXiv:1904.09482\",\"id\":\"b24\"},\"end\":45502,\"start\":45109},{\"attributes\":{\"doi\":\"arXiv:1901.11504\",\"id\":\"b25\"},\"end\":45825,\"start\":45504},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":9447219},\"end\":46205,\"start\":45827},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":3297437},\"end\":46723,\"start\":46207},{\"attributes\":{\"id\":\"b28\"},\"end\":46861,\"start\":46725},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":91184134},\"end\":47385,\"start\":46863},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":44131019},\"end\":47764,\"start\":47387},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":40027675},\"end\":48188,\"start\":47766},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":3626819},\"end\":48634,\"start\":48190},{\"attributes\":{\"id\":\"b33\"},\"end\":48949,\"start\":48636},{\"attributes\":{\"id\":\"b34\"},\"end\":49278,\"start\":48951},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":47018994},\"end\":49596,\"start\":49280},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":11816014},\"end\":49976,\"start\":49598},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":1114678},\"end\":50319,\"start\":49978},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":990233},\"end\":50823,\"start\":50321},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":146808476},\"end\":51199,\"start\":50825},{\"attributes\":{\"doi\":\"arXiv:1904.09223\",\"id\":\"b40\"},\"end\":51649,\"start\":51201},{\"attributes\":{\"doi\":\"arXiv:1806.02847\",\"id\":\"b41\"},\"end\":51861,\"start\":51651},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":13756489},\"end\":52275,\"start\":51863},{\"attributes\":{\"doi\":\"1905.00537\",\"id\":\"b43\"},\"end\":52745,\"start\":52277},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":5034059},\"end\":53226,\"start\":52747},{\"attributes\":{\"doi\":\"1805.12471\",\"id\":\"b45\"},\"end\":53473,\"start\":53228},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":3432876},\"end\":53875,\"start\":53475},{\"attributes\":{\"doi\":\"arXiv:1906.08237\",\"id\":\"b47\"},\"end\":54277,\"start\":53877},{\"attributes\":{\"doi\":\"arXiv:1904.00962\",\"id\":\"b48\"},\"end\":54625,\"start\":54279},{\"attributes\":{\"doi\":\"arXiv:1905.12616\",\"id\":\"b49\"},\"end\":54977,\"start\":54627},{\"attributes\":{\"doi\":\"arXivpreprintarXiv:1506.06724\",\"id\":\"b50\"},\"end\":55479,\"start\":54979},{\"attributes\":{\"id\":\"b0\"},\"end\":37057,\"start\":36703},{\"attributes\":{\"doi\":\"arXiv:1903.07785\",\"id\":\"b1\"},\"end\":37387,\"start\":37059},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":13385138},\"end\":37974,\"start\":37389},{\"attributes\":{\"id\":\"b3\"},\"end\":38271,\"start\":37976},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":14604520},\"end\":38683,\"start\":38273},{\"attributes\":{\"doi\":\"arXiv:1906.01604\",\"id\":\"b5\"},\"end\":39025,\"start\":38685},{\"attributes\":{\"id\":\"b6\"},\"end\":39497,\"start\":39027},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":7138078},\"end\":39749,\"start\":39499},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":52967399},\"end\":40187,\"start\":39751},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":16639476},\"end\":40559,\"start\":40189},{\"attributes\":{\"doi\":\"arXiv:1905.03197\",\"id\":\"b10\"},\"end\":41019,\"start\":40561},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":8587959},\"end\":41495,\"start\":41021},{\"attributes\":{\"id\":\"b12\"},\"end\":41682,\"start\":41497},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":5830937},\"end\":42125,\"start\":41684},{\"attributes\":{\"doi\":\"arXiv:1606.08415\",\"id\":\"b14\"},\"end\":42332,\"start\":42127},{\"attributes\":{\"id\":\"b15\"},\"end\":42672,\"start\":42334},{\"attributes\":{\"doi\":\"arXiv:1801.06146\",\"id\":\"b16\"},\"end\":42933,\"start\":42674},{\"attributes\":{\"id\":\"b17\"},\"end\":43197,\"start\":42935},{\"attributes\":{\"doi\":\"arXiv:1907.10529\",\"id\":\"b18\"},\"end\":43580,\"start\":43199},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":6628106},\"end\":43857,\"start\":43582},{\"attributes\":{\"doi\":\"arXiv:1905.06290\",\"id\":\"b20\"},\"end\":44223,\"start\":43859},{\"attributes\":{\"doi\":\"arXiv:1704.04683\",\"id\":\"b21\"},\"end\":44555,\"start\":44225},{\"attributes\":{\"doi\":\"arXiv:1901.07291\",\"id\":\"b22\"},\"end\":44780,\"start\":44557},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":15710851},\"end\":45107,\"start\":44782},{\"attributes\":{\"doi\":\"arXiv:1904.09482\",\"id\":\"b24\"},\"end\":45502,\"start\":45109},{\"attributes\":{\"doi\":\"arXiv:1901.11504\",\"id\":\"b25\"},\"end\":45825,\"start\":45504},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":9447219},\"end\":46205,\"start\":45827},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":3297437},\"end\":46723,\"start\":46207},{\"attributes\":{\"id\":\"b28\"},\"end\":46861,\"start\":46725},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":91184134},\"end\":47385,\"start\":46863},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":44131019},\"end\":47764,\"start\":47387},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":40027675},\"end\":48188,\"start\":47766},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":3626819},\"end\":48634,\"start\":48190},{\"attributes\":{\"id\":\"b33\"},\"end\":48949,\"start\":48636},{\"attributes\":{\"id\":\"b34\"},\"end\":49278,\"start\":48951},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":47018994},\"end\":49596,\"start\":49280},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":11816014},\"end\":49976,\"start\":49598},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":1114678},\"end\":50319,\"start\":49978},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":990233},\"end\":50823,\"start\":50321},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":146808476},\"end\":51199,\"start\":50825},{\"attributes\":{\"doi\":\"arXiv:1904.09223\",\"id\":\"b40\"},\"end\":51649,\"start\":51201},{\"attributes\":{\"doi\":\"arXiv:1806.02847\",\"id\":\"b41\"},\"end\":51861,\"start\":51651},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":13756489},\"end\":52275,\"start\":51863},{\"attributes\":{\"doi\":\"1905.00537\",\"id\":\"b43\"},\"end\":52745,\"start\":52277},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":5034059},\"end\":53226,\"start\":52747},{\"attributes\":{\"doi\":\"1805.12471\",\"id\":\"b45\"},\"end\":53473,\"start\":53228},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":3432876},\"end\":53875,\"start\":53475},{\"attributes\":{\"doi\":\"arXiv:1906.08237\",\"id\":\"b47\"},\"end\":54277,\"start\":53877},{\"attributes\":{\"doi\":\"arXiv:1904.00962\",\"id\":\"b48\"},\"end\":54625,\"start\":54279},{\"attributes\":{\"doi\":\"arXiv:1905.12616\",\"id\":\"b49\"},\"end\":54977,\"start\":54627},{\"attributes\":{\"doi\":\"arXivpreprintarXiv:1506.06724\",\"id\":\"b50\"},\"end\":55479,\"start\":54979}]", "bib_title": "[{\"end\":37447,\"start\":37389},{\"end\":38337,\"start\":38273},{\"end\":39078,\"start\":39027},{\"end\":39532,\"start\":39499},{\"end\":39831,\"start\":39751},{\"end\":40250,\"start\":40189},{\"end\":41078,\"start\":41021},{\"end\":41733,\"start\":41684},{\"end\":43624,\"start\":43582},{\"end\":44811,\"start\":44782},{\"end\":45878,\"start\":45827},{\"end\":46231,\"start\":46207},{\"end\":46920,\"start\":46863},{\"end\":47421,\"start\":47387},{\"end\":47802,\"start\":47766},{\"end\":48230,\"start\":48190},{\"end\":49338,\"start\":49280},{\"end\":49657,\"start\":49598},{\"end\":50037,\"start\":49978},{\"end\":50398,\"start\":50321},{\"end\":50895,\"start\":50825},{\"end\":51888,\"start\":51863},{\"end\":52832,\"start\":52747},{\"end\":53234,\"start\":53228},{\"end\":53553,\"start\":53475},{\"end\":37447,\"start\":37389},{\"end\":38337,\"start\":38273},{\"end\":39078,\"start\":39027},{\"end\":39532,\"start\":39499},{\"end\":39831,\"start\":39751},{\"end\":40250,\"start\":40189},{\"end\":41078,\"start\":41021},{\"end\":41733,\"start\":41684},{\"end\":43624,\"start\":43582},{\"end\":44811,\"start\":44782},{\"end\":45878,\"start\":45827},{\"end\":46231,\"start\":46207},{\"end\":46920,\"start\":46863},{\"end\":47421,\"start\":47387},{\"end\":47802,\"start\":47766},{\"end\":48230,\"start\":48190},{\"end\":49338,\"start\":49280},{\"end\":49657,\"start\":49598},{\"end\":50037,\"start\":49978},{\"end\":50398,\"start\":50321},{\"end\":50895,\"start\":50825},{\"end\":51888,\"start\":51863},{\"end\":52832,\"start\":52747},{\"end\":53234,\"start\":53228},{\"end\":53553,\"start\":53475}]", "bib_author": "[{\"end\":36717,\"start\":36703},{\"end\":36752,\"start\":36717},{\"end\":36765,\"start\":36752},{\"end\":37127,\"start\":37111},{\"end\":37142,\"start\":37127},{\"end\":37154,\"start\":37142},{\"end\":37172,\"start\":37154},{\"end\":37186,\"start\":37172},{\"end\":37463,\"start\":37449},{\"end\":37474,\"start\":37463},{\"end\":37486,\"start\":37474},{\"end\":37498,\"start\":37486},{\"end\":37518,\"start\":37498},{\"end\":37536,\"start\":37518},{\"end\":37551,\"start\":37536},{\"end\":38053,\"start\":38035},{\"end\":38064,\"start\":38053},{\"end\":38080,\"start\":38064},{\"end\":38100,\"start\":38080},{\"end\":38118,\"start\":38100},{\"end\":38362,\"start\":38339},{\"end\":38382,\"start\":38362},{\"end\":38403,\"start\":38382},{\"end\":38412,\"start\":38403},{\"end\":38758,\"start\":38744},{\"end\":38773,\"start\":38758},{\"end\":38785,\"start\":38773},{\"end\":38801,\"start\":38785},{\"end\":38818,\"start\":38801},{\"end\":39096,\"start\":39080},{\"end\":39115,\"start\":39096},{\"end\":39124,\"start\":39115},{\"end\":39544,\"start\":39534},{\"end\":39556,\"start\":39544},{\"end\":39560,\"start\":39556},{\"end\":39847,\"start\":39833},{\"end\":39863,\"start\":39847},{\"end\":39875,\"start\":39863},{\"end\":39895,\"start\":39875},{\"end\":40263,\"start\":40252},{\"end\":40276,\"start\":40263},{\"end\":40286,\"start\":40276},{\"end\":40657,\"start\":40648},{\"end\":40667,\"start\":40657},{\"end\":40680,\"start\":40667},{\"end\":40690,\"start\":40680},{\"end\":40704,\"start\":40690},{\"end\":40713,\"start\":40704},{\"end\":40727,\"start\":40713},{\"end\":40738,\"start\":40727},{\"end\":40754,\"start\":40738},{\"end\":41100,\"start\":41080},{\"end\":41118,\"start\":41100},{\"end\":41129,\"start\":41118},{\"end\":41141,\"start\":41129},{\"end\":41533,\"start\":41517},{\"end\":41546,\"start\":41533},{\"end\":41750,\"start\":41735},{\"end\":41767,\"start\":41750},{\"end\":41787,\"start\":41767},{\"end\":41798,\"start\":41787},{\"end\":42142,\"start\":42127},{\"end\":42156,\"start\":42142},{\"end\":42476,\"start\":42458},{\"end\":42490,\"start\":42476},{\"end\":42751,\"start\":42736},{\"end\":42768,\"start\":42751},{\"end\":42994,\"start\":42980},{\"end\":43011,\"start\":42994},{\"end\":43026,\"start\":43011},{\"end\":43284,\"start\":43270},{\"end\":43296,\"start\":43284},{\"end\":43308,\"start\":43296},{\"end\":43323,\"start\":43308},{\"end\":43341,\"start\":43323},{\"end\":43352,\"start\":43341},{\"end\":43643,\"start\":43626},{\"end\":43653,\"start\":43643},{\"end\":43941,\"start\":43918},{\"end\":43959,\"start\":43941},{\"end\":43975,\"start\":43959},{\"end\":43992,\"start\":43975},{\"end\":44005,\"start\":43992},{\"end\":44237,\"start\":44225},{\"end\":44248,\"start\":44237},{\"end\":44261,\"start\":44248},{\"end\":44274,\"start\":44261},{\"end\":44287,\"start\":44274},{\"end\":44575,\"start\":44557},{\"end\":44591,\"start\":44575},{\"end\":44823,\"start\":44813},{\"end\":44840,\"start\":44823},{\"end\":44853,\"start\":44840},{\"end\":44866,\"start\":44853},{\"end\":45228,\"start\":45214},{\"end\":45242,\"start\":45228},{\"end\":45255,\"start\":45242},{\"end\":45269,\"start\":45255},{\"end\":45518,\"start\":45504},{\"end\":45532,\"start\":45518},{\"end\":45545,\"start\":45532},{\"end\":45559,\"start\":45545},{\"end\":45894,\"start\":45880},{\"end\":45910,\"start\":45894},{\"end\":45925,\"start\":45910},{\"end\":45941,\"start\":45925},{\"end\":46255,\"start\":46233},{\"end\":46270,\"start\":46255},{\"end\":46283,\"start\":46270},{\"end\":46299,\"start\":46283},{\"end\":46312,\"start\":46299},{\"end\":46326,\"start\":46312},{\"end\":46342,\"start\":46326},{\"end\":46359,\"start\":46342},{\"end\":46377,\"start\":46359},{\"end\":46395,\"start\":46377},{\"end\":46403,\"start\":46395},{\"end\":46744,\"start\":46727},{\"end\":46932,\"start\":46922},{\"end\":46947,\"start\":46932},{\"end\":46963,\"start\":46947},{\"end\":46975,\"start\":46963},{\"end\":46986,\"start\":46975},{\"end\":46997,\"start\":46986},{\"end\":47013,\"start\":46997},{\"end\":47027,\"start\":47013},{\"end\":47433,\"start\":47423},{\"end\":47448,\"start\":47433},{\"end\":47464,\"start\":47448},{\"end\":47478,\"start\":47464},{\"end\":47817,\"start\":47804},{\"end\":47828,\"start\":47817},{\"end\":47846,\"start\":47828},{\"end\":47862,\"start\":47846},{\"end\":47875,\"start\":47862},{\"end\":47891,\"start\":47875},{\"end\":47903,\"start\":47891},{\"end\":47920,\"start\":47903},{\"end\":47933,\"start\":47920},{\"end\":47945,\"start\":47933},{\"end\":48248,\"start\":48232},{\"end\":48262,\"start\":48248},{\"end\":48275,\"start\":48262},{\"end\":48289,\"start\":48275},{\"end\":48308,\"start\":48289},{\"end\":48320,\"start\":48308},{\"end\":48338,\"start\":48320},{\"end\":48711,\"start\":48697},{\"end\":48731,\"start\":48711},{\"end\":49018,\"start\":49004},{\"end\":49030,\"start\":49018},{\"end\":49043,\"start\":49030},{\"end\":49055,\"start\":49043},{\"end\":49069,\"start\":49055},{\"end\":49085,\"start\":49069},{\"end\":49358,\"start\":49340},{\"end\":49369,\"start\":49358},{\"end\":49382,\"start\":49369},{\"end\":49677,\"start\":49659},{\"end\":49689,\"start\":49677},{\"end\":49709,\"start\":49689},{\"end\":49722,\"start\":49709},{\"end\":50054,\"start\":50039},{\"end\":50068,\"start\":50054},{\"end\":50085,\"start\":50068},{\"end\":50416,\"start\":50400},{\"end\":50432,\"start\":50416},{\"end\":50441,\"start\":50432},{\"end\":50455,\"start\":50441},{\"end\":50470,\"start\":50455},{\"end\":50486,\"start\":50470},{\"end\":50502,\"start\":50486},{\"end\":50509,\"start\":50502},{\"end\":50910,\"start\":50897},{\"end\":50918,\"start\":50910},{\"end\":50927,\"start\":50918},{\"end\":50940,\"start\":50927},{\"end\":50953,\"start\":50940},{\"end\":51228,\"start\":51201},{\"end\":51240,\"start\":51228},{\"end\":51251,\"start\":51240},{\"end\":51262,\"start\":51251},{\"end\":51272,\"start\":51262},{\"end\":51286,\"start\":51272},{\"end\":51301,\"start\":51286},{\"end\":51306,\"start\":51301},{\"end\":51320,\"start\":51306},{\"end\":51324,\"start\":51320},{\"end\":51703,\"start\":51694},{\"end\":51717,\"start\":51703},{\"end\":51721,\"start\":51717},{\"end\":51906,\"start\":51890},{\"end\":51920,\"start\":51906},{\"end\":51933,\"start\":51920},{\"end\":51950,\"start\":51933},{\"end\":51963,\"start\":51950},{\"end\":51978,\"start\":51963},{\"end\":51993,\"start\":51978},{\"end\":52011,\"start\":51993},{\"end\":52372,\"start\":52361},{\"end\":52392,\"start\":52372},{\"end\":52407,\"start\":52392},{\"end\":52424,\"start\":52407},{\"end\":52440,\"start\":52424},{\"end\":52452,\"start\":52440},{\"end\":52463,\"start\":52452},{\"end\":52480,\"start\":52463},{\"end\":52845,\"start\":52834},{\"end\":52862,\"start\":52845},{\"end\":52878,\"start\":52862},{\"end\":52890,\"start\":52878},{\"end\":52901,\"start\":52890},{\"end\":52918,\"start\":52901},{\"end\":53251,\"start\":53236},{\"end\":53268,\"start\":53251},{\"end\":53279,\"start\":53268},{\"end\":53571,\"start\":53555},{\"end\":53586,\"start\":53571},{\"end\":53601,\"start\":53586},{\"end\":53890,\"start\":53877},{\"end\":53902,\"start\":53890},{\"end\":53915,\"start\":53902},{\"end\":53932,\"start\":53915},{\"end\":53954,\"start\":53932},{\"end\":53965,\"start\":53954},{\"end\":54289,\"start\":54279},{\"end\":54298,\"start\":54289},{\"end\":54313,\"start\":54298},{\"end\":54327,\"start\":54313},{\"end\":54341,\"start\":54327},{\"end\":54356,\"start\":54341},{\"end\":54642,\"start\":54627},{\"end\":54656,\"start\":54642},{\"end\":54672,\"start\":54656},{\"end\":54686,\"start\":54672},{\"end\":54699,\"start\":54686},{\"end\":54718,\"start\":54699},{\"end\":54730,\"start\":54718},{\"end\":55094,\"start\":55083},{\"end\":55106,\"start\":55094},{\"end\":55121,\"start\":55106},{\"end\":55143,\"start\":55121},{\"end\":55159,\"start\":55143},{\"end\":55177,\"start\":55159},{\"end\":55191,\"start\":55177},{\"end\":36717,\"start\":36703},{\"end\":36752,\"start\":36717},{\"end\":36765,\"start\":36752},{\"end\":37127,\"start\":37111},{\"end\":37142,\"start\":37127},{\"end\":37154,\"start\":37142},{\"end\":37172,\"start\":37154},{\"end\":37186,\"start\":37172},{\"end\":37463,\"start\":37449},{\"end\":37474,\"start\":37463},{\"end\":37486,\"start\":37474},{\"end\":37498,\"start\":37486},{\"end\":37518,\"start\":37498},{\"end\":37536,\"start\":37518},{\"end\":37551,\"start\":37536},{\"end\":38053,\"start\":38035},{\"end\":38064,\"start\":38053},{\"end\":38080,\"start\":38064},{\"end\":38100,\"start\":38080},{\"end\":38118,\"start\":38100},{\"end\":38362,\"start\":38339},{\"end\":38382,\"start\":38362},{\"end\":38403,\"start\":38382},{\"end\":38412,\"start\":38403},{\"end\":38758,\"start\":38744},{\"end\":38773,\"start\":38758},{\"end\":38785,\"start\":38773},{\"end\":38801,\"start\":38785},{\"end\":38818,\"start\":38801},{\"end\":39096,\"start\":39080},{\"end\":39115,\"start\":39096},{\"end\":39124,\"start\":39115},{\"end\":39544,\"start\":39534},{\"end\":39556,\"start\":39544},{\"end\":39560,\"start\":39556},{\"end\":39847,\"start\":39833},{\"end\":39863,\"start\":39847},{\"end\":39875,\"start\":39863},{\"end\":39895,\"start\":39875},{\"end\":40263,\"start\":40252},{\"end\":40276,\"start\":40263},{\"end\":40286,\"start\":40276},{\"end\":40657,\"start\":40648},{\"end\":40667,\"start\":40657},{\"end\":40680,\"start\":40667},{\"end\":40690,\"start\":40680},{\"end\":40704,\"start\":40690},{\"end\":40713,\"start\":40704},{\"end\":40727,\"start\":40713},{\"end\":40738,\"start\":40727},{\"end\":40754,\"start\":40738},{\"end\":41100,\"start\":41080},{\"end\":41118,\"start\":41100},{\"end\":41129,\"start\":41118},{\"end\":41141,\"start\":41129},{\"end\":41533,\"start\":41517},{\"end\":41546,\"start\":41533},{\"end\":41750,\"start\":41735},{\"end\":41767,\"start\":41750},{\"end\":41787,\"start\":41767},{\"end\":41798,\"start\":41787},{\"end\":42142,\"start\":42127},{\"end\":42156,\"start\":42142},{\"end\":42476,\"start\":42458},{\"end\":42490,\"start\":42476},{\"end\":42751,\"start\":42736},{\"end\":42768,\"start\":42751},{\"end\":42994,\"start\":42980},{\"end\":43011,\"start\":42994},{\"end\":43026,\"start\":43011},{\"end\":43284,\"start\":43270},{\"end\":43296,\"start\":43284},{\"end\":43308,\"start\":43296},{\"end\":43323,\"start\":43308},{\"end\":43341,\"start\":43323},{\"end\":43352,\"start\":43341},{\"end\":43643,\"start\":43626},{\"end\":43653,\"start\":43643},{\"end\":43941,\"start\":43918},{\"end\":43959,\"start\":43941},{\"end\":43975,\"start\":43959},{\"end\":43992,\"start\":43975},{\"end\":44005,\"start\":43992},{\"end\":44237,\"start\":44225},{\"end\":44248,\"start\":44237},{\"end\":44261,\"start\":44248},{\"end\":44274,\"start\":44261},{\"end\":44287,\"start\":44274},{\"end\":44575,\"start\":44557},{\"end\":44591,\"start\":44575},{\"end\":44823,\"start\":44813},{\"end\":44840,\"start\":44823},{\"end\":44853,\"start\":44840},{\"end\":44866,\"start\":44853},{\"end\":45228,\"start\":45214},{\"end\":45242,\"start\":45228},{\"end\":45255,\"start\":45242},{\"end\":45269,\"start\":45255},{\"end\":45518,\"start\":45504},{\"end\":45532,\"start\":45518},{\"end\":45545,\"start\":45532},{\"end\":45559,\"start\":45545},{\"end\":45894,\"start\":45880},{\"end\":45910,\"start\":45894},{\"end\":45925,\"start\":45910},{\"end\":45941,\"start\":45925},{\"end\":46255,\"start\":46233},{\"end\":46270,\"start\":46255},{\"end\":46283,\"start\":46270},{\"end\":46299,\"start\":46283},{\"end\":46312,\"start\":46299},{\"end\":46326,\"start\":46312},{\"end\":46342,\"start\":46326},{\"end\":46359,\"start\":46342},{\"end\":46377,\"start\":46359},{\"end\":46395,\"start\":46377},{\"end\":46403,\"start\":46395},{\"end\":46744,\"start\":46727},{\"end\":46932,\"start\":46922},{\"end\":46947,\"start\":46932},{\"end\":46963,\"start\":46947},{\"end\":46975,\"start\":46963},{\"end\":46986,\"start\":46975},{\"end\":46997,\"start\":46986},{\"end\":47013,\"start\":46997},{\"end\":47027,\"start\":47013},{\"end\":47433,\"start\":47423},{\"end\":47448,\"start\":47433},{\"end\":47464,\"start\":47448},{\"end\":47478,\"start\":47464},{\"end\":47817,\"start\":47804},{\"end\":47828,\"start\":47817},{\"end\":47846,\"start\":47828},{\"end\":47862,\"start\":47846},{\"end\":47875,\"start\":47862},{\"end\":47891,\"start\":47875},{\"end\":47903,\"start\":47891},{\"end\":47920,\"start\":47903},{\"end\":47933,\"start\":47920},{\"end\":47945,\"start\":47933},{\"end\":48248,\"start\":48232},{\"end\":48262,\"start\":48248},{\"end\":48275,\"start\":48262},{\"end\":48289,\"start\":48275},{\"end\":48308,\"start\":48289},{\"end\":48320,\"start\":48308},{\"end\":48338,\"start\":48320},{\"end\":48711,\"start\":48697},{\"end\":48731,\"start\":48711},{\"end\":49018,\"start\":49004},{\"end\":49030,\"start\":49018},{\"end\":49043,\"start\":49030},{\"end\":49055,\"start\":49043},{\"end\":49069,\"start\":49055},{\"end\":49085,\"start\":49069},{\"end\":49358,\"start\":49340},{\"end\":49369,\"start\":49358},{\"end\":49382,\"start\":49369},{\"end\":49677,\"start\":49659},{\"end\":49689,\"start\":49677},{\"end\":49709,\"start\":49689},{\"end\":49722,\"start\":49709},{\"end\":50054,\"start\":50039},{\"end\":50068,\"start\":50054},{\"end\":50085,\"start\":50068},{\"end\":50416,\"start\":50400},{\"end\":50432,\"start\":50416},{\"end\":50441,\"start\":50432},{\"end\":50455,\"start\":50441},{\"end\":50470,\"start\":50455},{\"end\":50486,\"start\":50470},{\"end\":50502,\"start\":50486},{\"end\":50509,\"start\":50502},{\"end\":50910,\"start\":50897},{\"end\":50918,\"start\":50910},{\"end\":50927,\"start\":50918},{\"end\":50940,\"start\":50927},{\"end\":50953,\"start\":50940},{\"end\":51228,\"start\":51201},{\"end\":51240,\"start\":51228},{\"end\":51251,\"start\":51240},{\"end\":51262,\"start\":51251},{\"end\":51272,\"start\":51262},{\"end\":51286,\"start\":51272},{\"end\":51301,\"start\":51286},{\"end\":51306,\"start\":51301},{\"end\":51320,\"start\":51306},{\"end\":51324,\"start\":51320},{\"end\":51703,\"start\":51694},{\"end\":51717,\"start\":51703},{\"end\":51721,\"start\":51717},{\"end\":51906,\"start\":51890},{\"end\":51920,\"start\":51906},{\"end\":51933,\"start\":51920},{\"end\":51950,\"start\":51933},{\"end\":51963,\"start\":51950},{\"end\":51978,\"start\":51963},{\"end\":51993,\"start\":51978},{\"end\":52011,\"start\":51993},{\"end\":52372,\"start\":52361},{\"end\":52392,\"start\":52372},{\"end\":52407,\"start\":52392},{\"end\":52424,\"start\":52407},{\"end\":52440,\"start\":52424},{\"end\":52452,\"start\":52440},{\"end\":52463,\"start\":52452},{\"end\":52480,\"start\":52463},{\"end\":52845,\"start\":52834},{\"end\":52862,\"start\":52845},{\"end\":52878,\"start\":52862},{\"end\":52890,\"start\":52878},{\"end\":52901,\"start\":52890},{\"end\":52918,\"start\":52901},{\"end\":53251,\"start\":53236},{\"end\":53268,\"start\":53251},{\"end\":53279,\"start\":53268},{\"end\":53571,\"start\":53555},{\"end\":53586,\"start\":53571},{\"end\":53601,\"start\":53586},{\"end\":53890,\"start\":53877},{\"end\":53902,\"start\":53890},{\"end\":53915,\"start\":53902},{\"end\":53932,\"start\":53915},{\"end\":53954,\"start\":53932},{\"end\":53965,\"start\":53954},{\"end\":54289,\"start\":54279},{\"end\":54298,\"start\":54289},{\"end\":54313,\"start\":54298},{\"end\":54327,\"start\":54313},{\"end\":54341,\"start\":54327},{\"end\":54356,\"start\":54341},{\"end\":54642,\"start\":54627},{\"end\":54656,\"start\":54642},{\"end\":54672,\"start\":54656},{\"end\":54686,\"start\":54672},{\"end\":54699,\"start\":54686},{\"end\":54718,\"start\":54699},{\"end\":54730,\"start\":54718},{\"end\":55094,\"start\":55083},{\"end\":55106,\"start\":55094},{\"end\":55121,\"start\":55106},{\"end\":55143,\"start\":55121},{\"end\":55159,\"start\":55143},{\"end\":55177,\"start\":55159},{\"end\":55191,\"start\":55177}]", "bib_venue": "[{\"end\":36896,\"start\":36839},{\"end\":37710,\"start\":37639},{\"end\":40387,\"start\":40345},{\"end\":41282,\"start\":41220},{\"end\":41925,\"start\":41870},{\"end\":47593,\"start\":47544},{\"end\":36896,\"start\":36839},{\"end\":37710,\"start\":37639},{\"end\":40387,\"start\":40345},{\"end\":41282,\"start\":41220},{\"end\":41925,\"start\":41870},{\"end\":47593,\"start\":47544},{\"end\":36837,\"start\":36765},{\"end\":37109,\"start\":37059},{\"end\":37637,\"start\":37551},{\"end\":38033,\"start\":37976},{\"end\":38468,\"start\":38412},{\"end\":38742,\"start\":38685},{\"end\":39252,\"start\":39124},{\"end\":39616,\"start\":39560},{\"end\":39959,\"start\":39895},{\"end\":40343,\"start\":40286},{\"end\":40646,\"start\":40561},{\"end\":41218,\"start\":41141},{\"end\":41515,\"start\":41497},{\"end\":41868,\"start\":41798},{\"end\":42207,\"start\":42172},{\"end\":42456,\"start\":42334},{\"end\":42734,\"start\":42674},{\"end\":42978,\"start\":42935},{\"end\":43268,\"start\":43199},{\"end\":43712,\"start\":43653},{\"end\":43916,\"start\":43859},{\"end\":44368,\"start\":44303},{\"end\":44646,\"start\":44607},{\"end\":44936,\"start\":44866},{\"end\":45212,\"start\":45109},{\"end\":45641,\"start\":45575},{\"end\":45997,\"start\":45941},{\"end\":46455,\"start\":46403},{\"end\":47114,\"start\":47027},{\"end\":47542,\"start\":47478},{\"end\":47967,\"start\":47945},{\"end\":48402,\"start\":48338},{\"end\":48695,\"start\":48636},{\"end\":49002,\"start\":48951},{\"end\":49429,\"start\":49382},{\"end\":49778,\"start\":49722},{\"end\":50132,\"start\":50085},{\"end\":50557,\"start\":50509},{\"end\":51004,\"start\":50953},{\"end\":51400,\"start\":51340},{\"end\":51692,\"start\":51651},{\"end\":52060,\"start\":52011},{\"end\":52359,\"start\":52277},{\"end\":52970,\"start\":52918},{\"end\":53327,\"start\":53289},{\"end\":53665,\"start\":53601},{\"end\":54053,\"start\":53981},{\"end\":54429,\"start\":54372},{\"end\":54780,\"start\":54746},{\"end\":55081,\"start\":54979},{\"end\":36837,\"start\":36765},{\"end\":37109,\"start\":37059},{\"end\":37637,\"start\":37551},{\"end\":38033,\"start\":37976},{\"end\":38468,\"start\":38412},{\"end\":38742,\"start\":38685},{\"end\":39252,\"start\":39124},{\"end\":39616,\"start\":39560},{\"end\":39959,\"start\":39895},{\"end\":40343,\"start\":40286},{\"end\":40646,\"start\":40561},{\"end\":41218,\"start\":41141},{\"end\":41515,\"start\":41497},{\"end\":41868,\"start\":41798},{\"end\":42207,\"start\":42172},{\"end\":42456,\"start\":42334},{\"end\":42734,\"start\":42674},{\"end\":42978,\"start\":42935},{\"end\":43268,\"start\":43199},{\"end\":43712,\"start\":43653},{\"end\":43916,\"start\":43859},{\"end\":44368,\"start\":44303},{\"end\":44646,\"start\":44607},{\"end\":44936,\"start\":44866},{\"end\":45212,\"start\":45109},{\"end\":45641,\"start\":45575},{\"end\":45997,\"start\":45941},{\"end\":46455,\"start\":46403},{\"end\":47114,\"start\":47027},{\"end\":47542,\"start\":47478},{\"end\":47967,\"start\":47945},{\"end\":48402,\"start\":48338},{\"end\":48695,\"start\":48636},{\"end\":49002,\"start\":48951},{\"end\":49429,\"start\":49382},{\"end\":49778,\"start\":49722},{\"end\":50132,\"start\":50085},{\"end\":50557,\"start\":50509},{\"end\":51004,\"start\":50953},{\"end\":51400,\"start\":51340},{\"end\":51692,\"start\":51651},{\"end\":52060,\"start\":52011},{\"end\":52359,\"start\":52277},{\"end\":52970,\"start\":52918},{\"end\":53327,\"start\":53289},{\"end\":53665,\"start\":53601},{\"end\":54053,\"start\":53981},{\"end\":54429,\"start\":54372},{\"end\":54780,\"start\":54746},{\"end\":55081,\"start\":54979}]"}}}, "year": 2023, "month": 12, "day": 17}