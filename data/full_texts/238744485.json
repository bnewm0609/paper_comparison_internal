{"id": 238744485, "updated": "2023-11-11 01:21:32.111", "metadata": {"title": "Graph-Fraudster: Adversarial Attacks on Graph Neural Network-Based Vertical Federated Learning", "authors": "[{\"first\":\"Jinyin\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Guohan\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Haibin\",\"last\":\"Zheng\",\"middle\":[]},{\"first\":\"Shanqing\",\"last\":\"Yu\",\"middle\":[]},{\"first\":\"Wenrong\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Chen\",\"last\":\"Cui\",\"middle\":[]}]", "venue": "IEEE Transactions on Computational Social Systems", "journal": "IEEE Transactions on Computational Social Systems", "publication_date": {"year": 2023, "month": 4, "day": 1}, "abstract": "Graph neural network (GNN) has achieved great success on graph representation learning. Challenged by large-scale private data collected from user side, GNN may not be able to reflect the excellent performance, without rich features and complete adjacent relationships. Addressing the problem, vertical federated learning (VFL) is proposed to implement local data protection through training a global model collaboratively. Consequently, for graph-structured data, it is a natural idea to construct a GNN-based VFL (GVFL) framework. However, GNN has been proven vulnerable to adversarial attacks. Whether the vulnerability will be brought into the GVFL has not been studied. This is the first study of adversarial attacks on GVFL. A novel adversarial attack method is proposed, named Graph-Fraudster. It generates adversarial perturbations based on the noise-added global node embeddings via the privacy leakage and the gradient of pairwise node. Specifically, first, Graph-Fraudster steals the global node embeddings and sets up a shadow model of the server for the attack generator. Second, noise is added into node embeddings to confuse the shadow model. Finally, the gradient of pairwise node is used to generate attacks with the guidance of noise-added node embeddings. Extensive experiments on five benchmark datasets demonstrate that Graph-Fraudster achieves the state-of-the-art attack performance compared with baselines in different GNN based GVFLs. Furthermore, Graph-Fraudster can remain a threat to GVFL even if two possible defense mechanisms are applied. In addition, some suggestions are put forward for the future work to improve the robustness of GVFL. The code and datasets can be downloaded at https://github.com/hgh0545/Graph-Fraudster.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tcss/ChenHZYJC23", "doi": "10.1109/tcss.2022.3161016"}}, "content": {"source": {"pdf_hash": "167893f716d30d48d80f49ea3db4552966c2abc0", "pdf_src": "IEEE", "pdf_uri": "[\"https://arxiv.org/pdf/2110.06468v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://arxiv.org/pdf/2110.06468", "status": "GREEN"}}, "grobid": {"id": "626f031110e55aa3dab1c16378908733186ae99f", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/167893f716d30d48d80f49ea3db4552966c2abc0.txt", "contents": "\nGraph-Fraudster: Adversarial Attacks on Graph Neural Network-Based Vertical Federated Learning\nAPRIL 2023\n\nJinyin Chen chenjinyin@zjut.edu.cn \nCollege of Information Engineering\nCollege of Information Engineering\nInstitute of Cyberspace Security\nZhejiang University of Technology\n310023HangzhouChina\n\nGuohan Huang \nCollege of Information Engineering\nCollege of Information Engineering\nInstitute of Cyberspace Security\nZhejiang University of Technology\n310023HangzhouChina\n\nHaibin Zheng haibinzheng320@gmail.com.wenrongjiangiswiththe \nCollege of Information Engineering\nCollege of Information Engineering\nInstitute of Cyberspace Security\nZhejiang University of Technology\n310023HangzhouChina\n\nShanqing Yu yushanqing@zjut.edu.cn. \nCollege of Information Engineering\nCollege of Information Engineering\nInstitute of Cyberspace Security\nZhejiang University of Technology\n310023HangzhouChina\n\nWenrong Jiang jiangwenrong@zjjcxy.cn. \nCollege of Information Engineering\nCollege of Information Engineering\nInstitute of Cyberspace Security\nZhejiang University of Technology\n310023HangzhouChina\n\nChen Cui cuichen@zjjcxy.cn. \nCollege of Information Engineering\nCollege of Information Engineering\nInstitute of Cyberspace Security\nZhejiang University of Technology\n310023HangzhouChina\n\nHaibin Zheng \nInstitute of Cyberspace Security\nHaibin Zheng is with the College of Computer Science and Technol-ogy\nZhejiang University of Technology\n310023HangzhouChina\n\nJinyin Chen \nInstitute of Cyberspace Security\nHaibin Zheng is with the College of Computer Science and Technol-ogy\nZhejiang University of Technology\n310023HangzhouChina\n\nShanqing Yu \nInstitute of Cyberspace Security\nHaibin Zheng is with the College of Computer Science and Technol-ogy\nZhejiang University of Technology\n310023HangzhouChina\n\nGuohan Huang \nBig Data and Cyber Security Research Institute\nZhejiang University of Technology\nZhejiang Police College310023, 310053, 310018Hangzhou, Hangzhou, HangzhouChina, China, China\n\nGraph-Fraudster: Adversarial Attacks on Graph Neural Network-Based Vertical Federated Learning\n\nIEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS\n102APRIL 202310.1109/TCSS.2022.3161016received 28 June 2021; revised 9 January 2022 and 14 February 2022; accepted 15 March 2022. Date of publication 30 March 2022; date of current version 3 April 2023.492 (Corresponding author: Chen Cui is with the College of Computer Science, Hangzhou Dianzi University,\nGraph neural network (GNN) has achieved great success on graph representation learning. Challenged by large-scale private data collected from user side, GNN may not be able to reflect the excellent performance, without rich features and complete adjacent relationships. Addressing the problem, vertical federated learning (VFL) is proposed to implement local data protection through training a global model collaboratively. Consequently, for graph-structured data, it is a natural idea to construct a GNN-based VFL (GVFL) framework. However, GNN has been proven vulnerable to adversarial attacks. Whether the vulnerability will be brought into the GVFL has not been studied. This is the first study of adversarial attacks on GVFL. A novel adversarial attack method is proposed, named Graph-Fraudster. It generates adversarial perturbations based on the noise-added global node embeddings via the privacy leakage and the gradient of pairwise node. Specifically, first, Graph-Fraudster steals the global node embeddings and sets up a shadow model of the server for the attack generator. Second, noise is added into node embeddings to confuse the shadow model. Finally, the gradient of pairwise node is used to generate attacks with the guidance of noise-added node embeddings. Extensive experiments on five benchmark datasets demonstrate that Graph-Fraudster achieves the state-of-the-art attack performance compared with baselines in different GNN based GVFLs. Furthermore, Graph-Fraudster can remain a threat to GVFL even if two possible defense mechanisms are applied. In addition, some suggestions are put forward for the future work to improve the Manuscript\n\nProbabilities with the real global node embeddings. P Probabilities with the fake global node embeddings. d\n\nDimensions of local node embeddings. h f ake Fake global node embeddings.\n\n\nS(\u00b7)\n\nServer model in GVFL.\n\n\nS(\u00b7)\n\nShadow server model.\nC 0 d , R 0 d\n\nWeights and bias of the simplified S(\u00b7). B S , BS\n\nBoundary of S andS.\n\n\nI. INTRODUCTION\n\nF EDERATED learning (FL) [1], [2], a privacy-preserving and distributed learning paradigm, establishes machine learning models based on distributed datasets across multiple parties/devices. It aims to protect client's local data and mitigate privacy leakage in the context of legal restrictions, user-side privacy protection, and commercial competition. Benefiting from the collaborative training of the server model 2329-924X \u00a9 2022 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\n\nSee https://www.ieee.org/publications/rights/index.html for more information. and privacy protection of the local raw data, FL may be widely applied to various industries, e.g., mobile service [3], healthcare [4], finance [5], and face annotation [6], [7]. According to the data distribution characteristic, FL can be roughly categorized into horizontal FL (HFL), vertical FL (VFL), and federated transfer learning (FTL). HFL is suitable for the clients sharing datasets of the same feature space but different examples, while VFL is designed for the clients sharing datasets of the same examples but different feature spaces. FTL is proposed for the client's dataset diffs neither in feature space nor in examples. Among the three FLs, most studies are focused on HFL [8]- [12], while the other two still need to be further explored. Vertical data distribution is typical in real-world applications, for instance, financial data (e.g., transaction records and income) are often vertically partitioned and owned by different financial institutions (e.g., banks or lending platforms). The banks attempt to avoid lending to users with low credit ratings. Thus, a reliable evaluation agency is necessary to assess the same users among financial parties while sharing different features. To avoid raw data sharing between banks, a VFL framework is a good option for such a practical scenario. As described, some financial data can be constructed as graphs. Consequently, graph neural network-based VFL (GVFL) is suitable for this scenario.\n\nIn such a practical scenario, there could be some potential threats in GVFL. Fig. 1 shows the threat model of the adversarial attack on GVFL. To be evaluated as high-creditrating users, some may hide their true behaviors by adding some extra transaction records. Even worse, some dishonest lending platforms may tamper their data to help the low-creditrating users by evading the detection of the evaluation agency. These maliciously crafted operations will cause the bank to issue loans to low-credit users.\n\nWe further analyze the possibility of the adversarial attack on GVFL and find out that the threats could come from the innate deficiency in GVFL. Specifically, each participant in GVFL uploads the intermediate information, i.e., the node embeddings extracted by the local GNN model instead of the raw data. The adversarial perturbations (e.g., fake relationship and extra transaction record) on the local raw data will influence the updated node embeddings, thus posing a threat to the server model by making a wrong decision. Besides, privacy leakage of embeddings of GVFL will provide conditions for adversarial attacks, e.g., the leakage of the embeddings will help the malicious client to establish a precise shadow model of the server. These threats of adversarial attacks on GVFL have not been studied yet. Motivated by the practical application of GVFL and its potential vulnerability toward adversarial attacks, a novel attack method is proposed in this article as the first work of security research of GVFL.\n\nThe contributions of our work are summarized as follows. 1) To the best of our knowledge, this is the first work of proposing and formulating the adversarial attack on GVFL, by revealing its vulnerability toward a crisis of distrust in practical applications. Due to privacy leakage and data bias of the local model, GVFL unintentionally provides the conditions for successful adversarial attacks. 2) A novel adversarial attack method is proposed against GVFL, denoted as Graph-Fraudster. Aiming at confusing the server model in GVFL, Graph-Fraudster generates adversarial perturbations based on the noise-added global node embeddings via GVFL's privacy leakage and the gradient of pairwise node. 3) Extensive experiments are conducted on five real-world graph-structured datasets for node classification with different GNN structured GVFLs. Graph-Fraudster is validated that it performs significantly better than three advanced adversarial attacks transferable to GVFL from a centralized framework on seven metrics, achieving the state-of-the-art performance. 4) Furthermore, we propose two possible defenses against the attack. Graph-Fraudster can still pose a threat to the defensive GVFL. In addition, according to the observations of the experiments, some suggestions are provided to improve the robustness of GVFL, including privacy preserving, bias removal, and defense/detection deployment. The code and datasets are available at https://github.com/hgh0545/Graph-Fraudster. The rest of this article is organized as follows. Related works on GNN-based FL, inference attacks on FL, and adversarial attacks on GNN models are reviewed in Section II. Section III defines the adversarial attack on the GNN model and GVFL, sets up threat model, and then introduces Graph-Fraudster in detail. In Section IV, extensive experiments are presented to demonstrate the performance of Graph-Fraudster. Finally, this article is concluded, and the future work is enumerated in Section V.\n\n\nII. RELATED WORK\n\nIn line with the focus of the work, we briefly summarize the existing works of GNN-based FL, inference attacks on FL, and adversarial attacks on GNN.\n\n\nA. GNN-Based FL\n\nThough FL has shown the superiority in various domains, it has not been widely applied to graph-structured data. According to the investigation, most of the works focus on horizontal scenarios. For instance, considering data privacy preservation in nonindependent identically and distribution (Non-IID), Zheng et al. [13] used clients to implement message communication and leveraged the Bayesian optimization for hyperparameters' fine-tuning. They further proposed a novel learning paradigm, named ASFGNN. Inspired by metalearning, GraphFL [14] is proposed to address the node classification under Non-IID. These proposed FLs are supported by machine learning models designed for graph mining. In the aspect of GNN as the local model for FL, He et al. [15] presented FedGraphNN, an open-source FL system based on GNN models. However, it is not suitable for VFL. As for GVFL, the research is still in its fancy. Zhou et al. [16] gave the first vertical learning paradigm for privacy-preserving GNN models for node classification, by splitting the graph into two parts for different clients. Secure multiparty computation is adopted as well to ensure data privacy and efficiency. To ensure privacy, Ni et al. [17] adopted additively homomorphic encryption and proposed a federated graph convolutional network (GCN) learning paradigm for the privacy-preserving node classification task, named FedVGCN. Besides the framework study of GNN-based FL, it is also applied to real-world applications. For instance, Wu et al. [18] proposed a GNN structured FL for recommendation to accomplish server model training and user-side privacy.\n\n\nB. Inference Attack on FL\n\nSince the inference attack on GNN-based FL has not been studied yet, we summarize some inference attacks on FL. Numerous attacks on HFL have been proposed. For instance, in [19], generative adversarial network is used for inference attack on HFL for the first time, which generates the same distribution as the training data. Nasr et al. [20] exploited the vulnerability of the stochastic gradient descent (SGD) and designed a membership attack in white-box setting. Besides, deep leakage from gradients (DLG) [21] uses public shared gradients to obtain the local training data without extra knowledge of the data. To sum up, most of them greatly rely on the gradient that exchanged during the training process. In vertical scenarios, Luo et al. [22] formulated the problem of feature inference attack in model's inference process for the first time, and they proposed two attack methods on the logistic regression (LR) and decision tree (DT) models, named equality solving attack (ESA) and path restriction attack (PRA). Furthermore, they proposed a general attack method named generative regression network (GRN) attack to handle more complex models. Zhang et al. [23] devoted to gathering the man-made poison data and the corresponding intermediate outputs in the model's training process. Then, they built the training set for the decoder to recover other private data of the victim. Besides, Li et al. [24] explored whether the labels can be uncovered by sharing gradient in the VFL setting and proposed a label inference attack method based on the gradient norm.\n\n\nC. Adversarial Attacks on GNN Models\n\nExisting technologies may have multiple vulnerabilities that enable hackers or criminals to manipulate data for malicious purposes [25], and the adversarial examples may jeopardize the operation of the reality systems such as the Internet of Things [26]. Extensive studies have proven that GNN models are vulnerable to imperceptible adversarial perturbations that affect the performance of downstream applications. For node classification, Z\u00fcgner et al. [27] proposed the first adversarial attack on GNN models, denoted as NETTACK, by generating attacks iteratively according to score functions. Reinforcement learning is applied to generate perturbations in [28] as well. Aiming at fooling GNN models by attacking embeddings of the target node, Chen et al. [29] proposed a fast gradient attack (FGA) method via the maximal absolute edge gradient. Analogously, IG-FGSM and IG-JSMA are introduced in [30]. To deal with the large-scale graph, Li et al. [31] proposed a multistage attack framework SGA, which relies on a much smaller subgraph centered at the target node. Another modification strategy is proposed by inserting fake nodes [32] instead of adding/deleting edges in the adversarial examples. Considering a black-box scenario, GF-Attack [33] is constructed by the graph filter and feature matrix without accessing any knowledge of the target classifiers. For graph classification, Ma et al. [34] used rewiring to hide the adversarial edges, which preserves some important properties of the graph such as the number of nodes, edges, and total degrees of the graph. For community detection, a genetic algorithm is adopted in Q-Attack [35] to fail the detection method. To sum up, the existing graph adversarial attacks mainly degrade the performance of GNN models in various tasks by adding or deleting key edges.\n\nIII. METHODOLOGY First, we formalize the problem of adversarial attack on GVFL and give its definition. Then, the threat model of adversarial attack on GVFL is elaborated. Afterward, we introduce the Graph-Fraudster in aspect of framework, implementation details, and algorithm rationality. For convenience, the definitions of symbols used in this article are listed in the Nomenclature.\n\n\nA. Problem Definition\n\nDefinition 1 (Adversarial Attack on GNN Model): For node classification, the attacker is aiming to mislead the target GNN model to output the expected label of the adversarial example, which is carefully crafted with imperceptible perturbations (e.g., rewiring edges and fake nodes) on the benign one. As expected, fed by the adversarial example, the GNN model will extract low-quality node embeddings, leading to the wrong prediction. Specifically, G = (V, E) represents a graph and f \u03b8 (\u00b7) represents a GNN model. Denote A and X as the adjacency matrix of G and node features, respectively. The adversarial attack on the GNN model can be formalized as\nmax t\u2208T L atk softmax f \u03b8 * \u00c2 ,X , v t , y t s.t. \u03b8 * = arg min \u03b8 v l \u2208V L L train ( f \u03b8 (A, X, v l ), y l )(1)\nwhere\u00c2 represents the perturbed adjacency,X expresses the perturbed node features, v t represents the target node, and y t is the ground truth of v t . The parameters of GNN model \u03b8 are trained with labeled node sets V L , resulting \u03b8 * . Note that the attacker can manipulate edges and node features, or both. The research shows that modifying edges is more effective than modifying node features [30]. Thus, only adding/deleting edges is considered as perturbations in this work.\n\n\nDefinition 2 (Adversarial Attack on GVFL):\n\nIn GVFL, each client trains a local GNN model with its private data and updates the embedding for the aggregation of the server. The attacker's goal is to disrupt the local embeddings, causing the server model to produce wrong predictions. Fig. 2 shows the schematic of the forward propagation for GVFL.\n\nIn this article, concatenating the local node embeddings is used as the combination strategy:\nh global = h 1 ||h 2 || \u00b7 \u00b7 \u00b7 ||h K(2)\nwhere K denotes the number of participants and || is the concatenating operator. For a node classification task, the server model S is a classifier to make prediction by\nY = softmax W l \u00b7 \u03c1 . . . \u03c1 W 0 \u00b7 h global(3)\nwhere {W 0 , . . . , W l } are weight matrices of the classifier and \u03c1(\u00b7) represents activation function such as ReLU. Furthermore, the GVFL uses the cross-entropy error over all labeled examples, which can be learned by gradient descent\nL train = \u2212 |V L | l=1 |F| n=1 Y ln ln Y ln (4)\nwhere V L is the set of nodes with labels, Y ln is the ground truth, and |F| is the number of node classes in the graph G.\n\nThen, the adversarial attack on GVFL is defined a\u015d\nY t = softmax W l \u00b7 \u03c1 . . . \u03c1 W v t 0 \u00b7 h v t 1 h v t 2 \u00b7 \u00b7 \u00b7 \u0125 v t m h v t K s.t.\u0125 v t m = f \u03b8 * \u00c2 ,X , v t(5)\nwhere\u0125 v t m is the perturbed node embeddings of the target node v t which is uploaded by a malicious participant. It means that a malicious participant can add perturbations into the graph by manipulating A or X. Then, the local GNN model may be confused, which will produce low-quality or even targeted node embeddings and upload the perturbed node embeddings to the server model. Therefore, the server model will make wrong decision.\n\nThe target loss function L atk of target node v t can be defined as\nL atk = \u2212 |F| n=1 Y tn ln Y tn(6)\nwhich measures the difference between the prediction and the ground truth. It is easy to find that the prediction of the model is worse with larger value of L atk .\n\nB. Threat Model 1) Scenario: Taking more general scenarios into consideration, GVFL is applied to multiple participants training a central server collaboratively for node classification. When the server model is well-trained, the prediction of the server model will be shared by all participants. Besides, the server model is semi-honest, i.e., the server model serves to be queried by the malicious participant without revealing the inner parameters.\n\n2) Knowledge of the Malicious Participant: Assume that the malicious participant knows the structure of the server and only can access to its own data. In other words, the malicious participant can attack the server model by manipulating its own data merely. In addition, the trained server model will be served as an API for the malicious participant, and it only returns probability for each query. Thus, more details, such as the parameters of the server model and the gradient information, are unable to be obtained by the malicious participant.\n\n3) Goal of the Malicious Participant: For the malicious participant, the goal is to attack the server model by uploading perturbed embeddings so that the other benign participants, which rely on the server model, receive the unexpected prediction for the target example.\n\n\nC. Graph-Fraudster\n\nAs described in Section III-B, the attacker can manipulate the own edges or node features in the testing to fool the global GVFL. During the aggregate process, modifying the edges affects all dimensions of features belonging to the target node, while modifying features only affects a few features. Thus, Graph-Fraudster is designed to attack the server model by manipulating edges of the local graph. It is conducted through three stages: 1) stealing node embeddings of other participants; 2) adding noises into embeddings via constructing the shadow server model; and 3) generating adversarial attacks to mislead the global GVFL. The framework of Graph-Fraudster is shown in Fig. 3. The details and rationality of Graph-Fraudster are described in this section.\n\n1) Embeddings Stealing Strategy: Similar to [22], Graph-Fraudster uses GRN to steal embeddings uploaded by other participants. First, as shown in Fig. 4 One participant is randomly selected as the malicious participant from all. The adversarial attack is conducted through three stages: 1) stealing embeddings: a global node embedding is generated, which is adjusted by querying result of trained server model; 2) adding noises: noises are added into the generated embeddings to attack the shadow model of the server; and 3) generating adversarial attacks: guided by noise-added node embeddings of malicious participant, adversarial attacks are generated by using gradient of pairwise node. As a result, the wrong prediction of the target node will be produced by the trained server model. noise vector is generated, where K is the number of participants in GVFL and d is dimensions of local node embeddings. Then, an L-layers' multilayer perceptron (MLP) is used to generate the target node embeddings, i.e., the embeddings uploaded by other participants. In this article, a three-layer MLP with ReLU is applied as the generator. The dimension of an input is K \u00d7d, the dimension of an output is (K \u22121)\u00d7d, and the hidden units are 512 and 256. Then, the local node embeddings of the malicious participant and the target node embeddings are concatenated, represented as h fake , as input of the discriminator. The classification probabilities of an adversarial example can be obtained by querying the server model. Note that the parameters of the trained server model are fixed. The target of stealing privacy can be converted to a regression problem. Therefore, mean square error (mse) is adopted for the training process, which can be formulated as\n, a (K \u2212 1) \u00d7 d randomL GRN = 1 N \u00d7 |F| N i=1 |F| j =1 P i, j \u2212 P i, j 2(7)\nwhere N is the number of nodes,P = S(h fake ) is the probabilities returned when node embeddings of an adversarial example are fed, and P is the probabilities returned at the end of GVFL's training process.\n\nTo recognize the GRN in detail, we simplify the model structure of GRN with a single-layer generator model and a discriminator model S with fixed parameters. Thus, for the real node embeddings h real , its ground-truth prediction output of the discriminator model can be represented as\nP = S(h real ) = softmax C 0 d h real + R 0 d .(8)\nSince the parameters of S are fixed, C 0 d is used to represent the weights of S. R 0 d is bias of S. For a fake of node embeddings h fake , the output of S is\nP 1 = S(h fake ) = S(g(n in )||h m ) = softmax (((n in ||h m )w 0 + b 0 )||h m )C 0 d + R 0 d s.t. g(n in ) = (n in ||h m )w 0 + b 0 (9)\nwhere n in is a (K \u2212 1) \u00d7 d dimensions noise, h m is local node embeddings of the malicious participant, g(\u00b7) is the generator, w 0 is the weights of the generator model, and b 0 is bias. GRN backpropagates the loss and updates the parameters of the MLP model.\n\n\n2) Noise Addition via Stolen Embeddings:\n\nIn order to degrade the performance of the server model, it is significant to produce the adversarial embeddings crossing the decision boundary to mislead the server model. An effective and efficient method is using the gradient information of the server model to produce adversarial examples, which has been widely used to construct attack on GNN. However, in GVFL, the attackers cannot get gradient information but only the returned probabilities. Therefore, it is necessary to establish a shadow model in local to simulate the server model. By stealing the global node embeddings, the shadow modelS can be successfully established based on the necessary knowledge, i.e., training data h fake , model structure, and target probabilities P. According to the setting in Section III-B, the model structure and P are known. To the end, the shadow model will output the similar probability P to the servers when fed by the same examples. The mse is applied as the target as follows:\nL shadow = 1 N \u00d7 |F| N i=1 |F| j =1 S (h fake ) \u2212 P i, j 2(10)\nwhereS(h fake ) is the output ofS. Then, a fast gradient sign method (FGSM) [36] is adopted as a noise generator by using the gradient information of the shadow modelS.\n\nFor a target node v t , its noise-added embeddings h v t fake could be represented as\nh v t fake = h v t fake + \u00b7 sign \u2202 L atk \u2202h v t fake(11)\nwhere sign(\u00b7) is the gradient's direction and \u2208 [0, 1] is the noise scale.\n\nIn particular, the reason for using mse as the target to establish the shadow model is as follows. Suppose using a mapping equation to represent the server model\nk S (h) = arg max k S(h)(12)\nwhere h is the node embeddings and k is the kth class of S. The classification boundary function can be expressed as follows:\nS k (h) \u2212k S (h) = 0.(13)\nBy applying the first-order Taylor expansion, the approximate classification boundary function of S is denoted asS\nB S : S k (h real ) + h real \u2207 S k (h real ) \u2212k S (h real ) \u2212 h real \u2207k S (h real ) = 0 (14) BS:S k (h fake ) + h fake \u2207S k (h fake ) \u2212kS(h fake ) \u2212 h fake \u2207kS(h fake ) = 0.(15)\nThe mse of the shadow model is aiming to approximate the classification boundary ofS and S. Thus, the target can be converted to\narg mi\u00f1 S mse S (h fake ), S(h real ) \u21d4 arg mi\u00f1 S BS \u2212 B S \u21d4 arg mi\u00f1 S S (h fake ) \u2212 S(h real ) + (h fake \u2212 h real ) \u2207S(h fake ) \u2212 \u2207S(h real ) .(16)\nThen, assuming \u2207S(h fake ) \u2248 \u2207S(h real ), the noise generated by FGSM against the shadow model can also attack the server model in GVFL successfully since the approximate direction of the gradient is obtained. \n\n\n3) Adversarial Attack via Noise-\nA mse f \u03b8 * \u00c2 , X, v t , h v t m(17)\nwhere \u00c2 \u2212 A 0 is twice the budget , i.e., \u00c2 \u2212 A 0 \u2264 2 due to the symmetry of the adjacency matrix.\n\nTo speed up the process of searching the suitable adversarial edges, the gradient of pairwise node is applied, followed the work of Chen et al. [29]. The edge gradient matrix is computed as follows:\ng u,v = \u2202 L t \u2202 A u,v s.t. L t = 1 d d i=1 f \u03b8 * \u00c2 , X, v t i \u2212 h v t fake i 2(18)\nwhere (u, v) is any pairwise node in the graph G, [\u00b7] i denotes the i th element of node embeddings, and d is the dimensions of local node embeddings. Considering the symmetry of the adjacency matrix of the undirected graphs, the gradient matrix is symmetric as\ng sym = g + g T 2(19)\nwhere \u00b7 T is the transpose symbol. The adversarial edge e adv is selected by\ne adv = (u, v) \u2190 \u2212 arg max u,v \u2212 g sym .(20)\nTo minimize the difference between the local GNN model's output and the noise-added embeddings rather than maximizing L atk , the gradient value should be inverted. Finally, the adversarial edges will be added into clean adjacency iteratively within budget \u00c2\nu,v = \u2212A u,v + 1(21)\nwhere (u, v) comes from e adv and\u00c2 is symmetrical.\n\n\nD. Algorithm\n\nThe pseudocode for Graph-Fraudster is given in Algorithm 1.\n\n\nE. Complexity Analysis\n\nFor generation of adversarial attacks, the calculation time of Graph-Fraudster is divided into four parts, including GRN's training time T GRN , shadow model's training time T shadow , noise adding time, and adversarial edges selecting time. Thus, the time complexity of Graph-Fraudster is\nO(T GRN ) + O(T shadow ) + O(1) + O() \u223c O(N) (22)\n\nAlgorithm 1 Graph-Fraudster\n\nInput: Original adjacency A, node features X, target node v t , attack budget , dimensions of local node embeddings d, number of participants K . Output: The adversarial network\u00c2. 1 Train the GVFL to obtain the server model S and the local GNN models f \u03b8 * (\u00b7). 2 Generate a (K \u2212 1) \u00d7 d dimensions noise randomly. 3 Concatenate generated noise and the local node embeddings of malicious participant h m as input h in . 4 for t = 1 to T G RN do 5 h target \u2190 \u2212 M L P(h in ) 6 Concatenate h target and h m as h f ake for the server model S. 7 Minimize the MSE in Equation 7. 8 end 9 Save h f ake . 10 Initialize the parameter of the shallow server modelS. 11 for t = 1 to T shadow do 12 Minimize the MSE in Equation 10 with h f ake . 13 end 14 Generate the noises and add them into h f ake as Equation 11 and return h v t f ake for target node v t . 15 Initialize\u00c2 0 = A. 16 for i = 1 to do 17 Calculate the symmetrical edge gradient matrix as Equation 18 and 19. The parameters of Graph-Fraudster include GRN's parameters and shadow model's parameters. Therefore, the space complexity is\nO(K \u00d7 d \u00d7 n 0 + n 0 \u00d7 n 1 + \u00b7 \u00b7 \u00b7 + (K \u2212 1) \u00d7 d \u00d7 n L\u22121 ) + O S \u223c O M 2(23)\nwhere K is the number of participants, d is the dimensions of local node embeddings, [n 0 , . . . , n L\u22121 ] is the number of the units in GRN models, andS is the shadow model. O(M 2 ) indicates that the space complexity depends on the memory occupied by the model's weight matrix, whose is squared level. \n\n\nIV. EXPERIMENTS\n\nIn order to comprehensively evaluate the performance of Graph-Fraudster, both dual-participant-based GVFL and multiparticipant-based GVFL are testified in the aspect of attack performance, two possible defense strategies against GVFL, and parameter sensitivity analysis.\n\n\nA. Datasets\n\nFive graph-structured datasets are used to evaluate the performance of the proposed method, including Cora [37], Cora_ML [37], Citeseer [37], Pol.Blogs [38], and Pubmed [39]. Their basic statistics are summarized in Table I, and the specific information is the same as the reference source.\n\nIn GVFL, each dataset will be split for different clients. Assuming that there are no overlap edges for each client, then with more clients' participant in, the more isolated nodes appear in clients' graph data. It will be not conducive to collaboratively train the server model. Consequently, two splitting strategies are adopted for a different number of clients. Specifically, for dual participants, both edges and node features of the dataset are divided into two parts on average, in which a small part of isolated nodes will appear. For multiparticipant, node features are divided averagely to each participant, and the complete topology of the graph is retained. Due to the randomness of the segmentation, the dataset is divided and tested ten times. The average accuracy of the trained server model will be recorded.\n\n\nB. Local GNN Model\n\nTo demonstrate that Graph-Fraudster is effective in various GNN structure-based GVFLs, three GNN models are adopted as local participants. 1) GCN [40]: It uses a layerwise propagation rule based on a first-order approximation of spectral convolutions on graphs. For node classification, a two-layer GCN is adopted as each local GNN model in GVFL. The node is represented as\nh (l+1) i = \u03c1 \u239b \u239d j \u2208ne(i) 1 D iiD j j h (l) j W (l) \u239e \u23a0(24)\nwhere h (l+1) is the (l + 1)th layer's node representation and W (l) is the parameters of lth layer. Node j belongs to neighbor node set ne of node i .D ii = j (A + I N ) is the degree matrix of A + I N , and I N is the identity matrix.\n\n2) Simple Graph Convolution (SGC) [41]: It is a linearized version of GCN without the activation function. The aggregation function can be formulated as\nh (l+1) i = j \u2208ne(i) 1 D iiD j j h (l) j W (l) .(25)\nSGC usually outperforms GCN for node classification. 3) Robust GCN (RGCN) [42]: It adopts Gaussian distributions as the hidden representations of nodes, which can absorb the effects of adversarial attack\n\u03bc (l+1) i = \u03c1 \u239b \u239d j \u2208ne(i) 1 D iiD j j \u03bc (l) j \u03b1 (l) j W (l) \u03bc \u239e \u23a0 \u03c3 (l+1) i = \u03c1 \u239b \u239d j \u2208ne(i) 1 D iiD j j \u03c3 (l) j \u03b1 (l) j \u03b1 (l) j W (l) \u03c3 \u239e \u23a0 (26)\nwhere \u03bc is the means, \u03c3 is the variances of Gaussian distributions, W \u03bc and W \u03c3 are the weight matrices of the means and the variances, respectively, and is the elementwise product.\n\n\nC. Attack Baselines\n\nSince this is the first work of adversarial attack on GVFL, three attack methods in the centralized setting are chosen as baselines. To make the attack methods transferable to GVFL, the probabilities returned by the server model and the local data are used to train a surrogate model, which is the same as the local GNN model. The baselines are briefly described as follows.\n\n1) RND [27]: We assume that the connection of different types of nodes will affect the prediction result. For a given target node, RND randomly samples a node whose predicted label is unequal to the target node. Then, add an edge between the target node and the sampled node. 2) NETTACK [27]: It generates the adversarial edges guided by two evaluation functions from selected candidate edges and features. It modifies the highest scoring edges or features and updates the adversarial network iteratively to confuse GNNs. 3) FGA [29]: It constructs the edge gradient network based on the original network first. Then, it generates the adversarial edges iteratively with the maximal absolute edge gradient until it reaches the attack budget .\n\n\nD. Experiment Setup\n\nFor each local GNN model, a two-layer GNN model is applied to extract the local node embeddings, whose dimension is set to 16. The number of hidden units is fixed to 32. For GCN and SGC, the activation function is ReLU. ELU and ReLU are applied for means and variances, respectively, in RGCN. The GVFL is trained for 200 epochs using Adam with a learning rate of 0.01. Considering sparsity of the dataset and concealment of attack, the attack budget is fixed to 1. Besides, the accuracy of the server model is applied as the main evaluation metric, and the lower the accuracy, the better the attacker's performance.\n\nOur experimental environment consists of Intel XEON 6240 2.6 GHz \u00d7 18C (CPU), Tesla V100 32 GiB (GPU), 16-GiB memory (DDR4-RECC 2666), and Ubuntu 16.04 (OS).\n\n\nE. Attack Performance\n\nIn this section, Graph-Fraudster is conducted on five real-world datasets in two main scenes, i.e., dual-participantbased GVFL and multiparticipant-based GVFL.\n\n1) Attack on Dual-Participant-Based GVFL: As described above, in this setting, datasets are divided into two pieces both in edges and node features randomly. Multiperspective metrics are used to evaluate the performance of the attackers, including the node classification accuracy, precision, recall, F1-Score, mean absolute error (MAE), and log loss.\n\nAs shown in Table II, in order to verify the generality of Graph-Fraudster in different graph segmentation situations, we conduct the experiments ten times and report the average accuracy with standard deviation. The best attack performance is highlighted in bold. In Fig. 5, other five metrics are shown to evaluate the proposed method variously. Specifically, precision, recall, and F1-Score are applied to measure the performance of GVFL. The lower the attacker's score, the better the attack performance is. MAE and log loss are used to evaluate the degree of confusion of the target server model. A higher value represents better performance of attack. Some observations are concluded in this experiment.\n\n1) Graph-Fraudster Achieves the SOTA Attack Performance Compared With Baselines: For instance, the accuracy of Graph-Fraudster degrades the baselines more than 10% on Cora, Cora_ML, and Citeseer, which shows the superior performance of Graph-Fraudster. For Pol.Blogs, it can be seen that the performance of GVFL drops less than other datasets under attacks. For example, Graph-Fraudster reduces the GVFL's performance by about 21%, 20.8%, and 24.1%, corresponding to GCN, SGC, and RGCN, respectively, but gains more than 25% on the other datasets. It is caused by the rich relationships of Pol.Blogs, which makes attacks more difficult within limited perturbation budget. It is worth mentioning that the standard deviation shows that Graph-Fraudster is more stable than NETTACK and FGA generally. Fig. 5 reports the results on other five metrics, and Graph-Fraudster gains better attack performance than baselines on each metric. 2) Integrity of Graph-Structured Data Affects the Performance of the Model: Compared with the performance of centralized GNN models, GVFL's performance drops. It can be analyzed that the local GNN models cannot capture complete node information, while edges are assigned to different participants, which weakens the quality of the local node embeddings. Furthermore, GVFL performs better on the graph with higher degree, e.g., the performance of GVFL based on GCN drops by 8.7% on Cora (the average degree is 2.00), while it only drops by 3.2% on Pol.Blogs (the average degree is 13.68). There are similar results on different GVFLs.  5. Multiperspective metrics to measure the performance of attacks. For precision, recall, and F1-Score, the lower the attacker's score, the better the attack performance, and for MAE and log loss, the higher the attacker's score, the better the attack performance.\n\nThe phenomenon can be interpreted as the denser graph can retain more relational information after data segmentation.\n\n\n3) Graph-Fraudster Outperforms the Other Baselines on\n\nthe Robust GNN Model: RGCN was proposed as a kind of robust GNN model with defense mechanism. Thus, in most cases, RGCN-based GVFL outperforms other GVFLs without defense mechanism. Despite the performance of attack methods declines, Graph-Fraudster still keeps the state-of-the-art performance. In addition, benefiting from its randomness, RND always maintains its performance, but its attack performance is poor. To further compare the performance of attack methods in more detail, classification margin is used as a metric to measure the influence of the attack methods on the probabilities of the model's prediction, following Z\u00fcgner's work [27]. We select 100 nodes from the test set, which are correctly classified. These nodes satisfy the following.\n\n1) The 20 nodes with the highest classification margin.\n\n2) The 20 nodes with the lowest classification margin but still be classified correctly.\n\n3) The 60 nodes are selected randomly. It can be observed from Fig. 6 that Graph-Fraudster outperforms baselines. More than half of the target nodes' classification margin below 0, on Cora, Citeseer, and Pubmed, corresponds to the higher attack performance of Graph-Fraudster on these datasets. Moreover, more nodes gain low classification margin than NETTACK and FGA, under Graph-Fraudster's attack, on Cora_ML. Although, for Pol.Blogs, all attack methods cannot achieve the same performance as well as other datasets due to its density, Graph-Fraudster still performs better. On Pubmed, Graph-Fraudster achieves similar performance to NETTACK and FGA but stays ahead. For RND, only a few nodes obtain low classification margin, which explains its worst attack performance. In addition, there are still some nodes with higher classification margin, corresponding to nodes that have not been successfully attacked. It may be caused by the single-edge attack, which is unable to make the GVFL misclassify these nodes.\n\nThe above experiments suggest that GVFL suffers from adversarial attacks. Although the existing adversarial attacks transferable to GVFL are not powerful enough without the knowledge of GVFL, GVFL still performs as expected. It reveals that GVFL is vulnerable to adversarial attacks. The vulnerability may be caused by the GNN model. The adversarial attacks make the GNN model extract the node embedding vector incorrectly and finally confuse the server model. Furthermore, benefiting from the global node embeddings leakage in GVFL, Graph-Fraudster establishes a shadow server model, which guides the attack to succeed. More knowledge of GVFL helps the performance of attacks, which explains the superior performance of Graph-Fraudster.\n\n\n2) Attack on Multiparticipant-Based GVFL:\n\nMore generally, there are multiple participants in FL. In order to verify the capacity of Graph-Fraudster, the number of participants is set from 2 to 6 in the experiments. To avoid the emergence of numerous isolated nodes, we just distribute node features randomly to each participant without segmentation of edges. Since Pol.Blogs has no node features, the experiments will be conducted on the remaining four datasets. The results are shown in Fig. 7.\n\nFirst, compared to edges segmentation, the performance of GVFL is more close to the centralized GNN models in this setting due to the retention of complete relationships between node pairs. Then, as the number of participants increases, the accuracy of GVFL decreases gradually. It is caused by information loss in node features segmentation. Similar to edges segmentation setting, Graph-Fraudster maintains optimal attack performance with two participants. In general, the performance of attack methods decreases with the increase of participants' number. Because the server model treats every participant equally, as the number of participants increases, the contribution of the malicious participant's node embeddings decreases. As a result, the server model is harder to be confused. For example, on Pubmed, all attack methods almost fail with the single-edge attack when the participant number is 6. Interestingly, it not always happens in the experiments. Taking Citeseer as an example, the accuracy of GVFL falls when the number of participants is 6. We give the relationship between attack performance of Graph-Fraudster and contribution of the malicious participant in Fig. 8. The contribution of the i th participant is defined as is the number of participants and acc i is the accuracy of the server model when only participant i 's node embeddings is input. It can be observed that on Cora_ML, when the number of participants increases, the contribution of participants gradually decreases, and the server model is less susceptible to attacks. On Citeseer, when the number of participants is 6, the proportion of malicious participant's contribution increases, causing the server model to be attacked by Graph-Fraudster. We attribute the reason to the segmentation of the dataset. In this setting, the node features are divided randomly, which may cause that not all participants get useful node features.\nC i = (acc i /( K j acc j =1 )), where K\nThus, a small perturbation is powerful enough to fool the server model. On the contrary, the performance drops when the benign participants get some key node features and the slight structural perturbation from malicious participants is not enough to affect the performance of the server model, that is, the model is biased against the data. Besides, the properties of datasets affect attack performance. Taking Citeseer, which is the most sparse, it can be seen that Graph-Fraudster maintains good attack performance. Due to its sparseness, it improves the influence of structural attacks on the perturbations of the local node embeddings. In summary, in the multiparticipant case, with the number of participants increasing, the performance of attackers generally shows a downward trend. It may be caused by the influence of the server model of each participant decreasing, while the number of participants increases. Thus, considering adding perturbations into both structure and node features may a better strategy, and it will be considered in our future work. Furthermore, the model's bias against the data is one of the possible reasons for the success of the adversarial attack. It indicates that data bias of the model may lead the server model more relying on high-contributing participants. As a result, it is easier for attacks initiated by high-contributing participants to cheat the server model. Therefore, setting up a fair evaluation mechanism for participants may help to improve the robustness of GVFL against adversarial attacks.\n\n3) Impact of Attacks on Decision Boundary: To explain the attack results of Graph-Fraudster better, the decision boundaries on Pol.Blogs before and after attack are plotted in Fig. 9. The setting is the same as dual-participant-based GVFL. Combining the accuracy of the server model, the decision boundary is regular without perturbations, which corresponds to high accuracy. After attack, as mentioned in the previous experiments, the server model is not easy to be perturbed with high accuracy. However, some nodes break away from their corresponding groups, which makes the decision boundary fracture. In other words, these outliers will be misclassified.\n\n\nF. Possible Defense\n\nTo mitigate the performance of Graph-Fraudster, differential privacy (DP) mechanism and Top-k mechanism are introduced as the possible defenses. DP is used to prevent  Graph-Fraudster from stealing the node embeddings, and Top-k devotes to filtering out perturbations in the local node embeddings. The two strategies are briefly introduced as follows.\n\n1) DP [43]: The randomized noise is injected into the local node embeddings before uploading, obeying the principle of DP. The Laplacian mechanism is used in this article with the scale of noise \u03b2.  2) Top-k [44]: Before uploading the local node embeddings, we sort the embedding value and preserve the top k values to reduce the influence of some useless information. The scale of Laplacian noise \u03b2 is set from 0 to 0.5, and the value of k is set from 8 to 16. Fig. 10 shows the result on GCN-based GVFL. Note that \u03b2 = 0 and k = 16 present the GVFL without defense mechanism. With the increase of \u03b2 or the decrease of k, these two defense mechanisms reduce the performance of GVFL to a certain extent. It shows that there should be a tradeoff between defense performance and GVFL's performance. As shown in Fig. 10(a), DP has limited defensive capability against Graph-Fraudster or even useless, e.g., the performance on Citeseer. It may be that the noise added by DP cannot offset the noise added by Graph-Fraudster well. As for Top-k, as shown in Fig. 10(b), it is more effective than DP, but it is unstable. For example, on Cora, Top-k with k = 8 outperforms other value and k = 12 is second, which is not monotonous with the change of k. It is caused by the nonconcentrated distribution of perturbations in the node embeddings. Specifically, the perturbations do not only exist in lower values. Moreover, the price of better defensive capability against Graph-Fraudster is the performance degradation of the main task. In summary, Graph-Fraudster can still perform well under two possible defense mechanisms. In future works, filtering perturbations from the local node embeddings is a feasible solution against adversarial attacks in GVFL, and keeping the performance of GVFL while gaining defensive capability is also a great challenge. \n\n\nG. Parameter Analysis\n\nIn this section, the sensitivity of the dimensions of the local node embeddings d and the scale of noise for Graph-Fraudster is explored. The value of these parameters is adjusted to see how they affect the performance of Graph-Fraudster. In more detail, d is set from 8 to 32 with a step size of 4, and is changed from 0 to 0.01.\n\nThe performance change of Graph-Fraudster is shown in Figs. 11 and 12. It can be observed that as the value of d increases, the attack performance of Graph-Fraudster is not significantly affected (less than 10%), which shows the stability of Graph-Fraudster. In addition, we take the performance of Graph-Fraudster on GCN-based VFL with different noise scales as an example. The results are shown in Fig. 12.\n\nSimilar results are observed in other settings. It can be seen that the accuracy of the server model drops rapidly in a small range of (from 0 to 0.002). Single-edge attack may be the main reason because the perturbations are too small to further approximate the node embeddings with large-scale noise. Thus, for single-edge attack, a small value of is enough (e.g., 0.004 in this setting) to guide the attack, and choosing an appropriate value of can boost the performance of Graph-Fraudster.\n\n\nV. CONCLUSION\n\n\nA. Contributions\n\nThe first novel adversarial attack method on GVFL, named Graph-Fraudster, is proposed by combining GVFL's privacy leakage and the gradient of pairwise node. Benefiting from the information of GVFL, Graph-Fraudster achieves the state-ofthe-art attack performance compared with the baselines. Extensive experiments have testified the effectiveness and efficiency of Graph-Fraudster and further revealed the vulnerability of GVFL even under defensive circumstances.\n\n\nB. Observations\n\nBesides the adversarial attack problem formulation and Graph-Fraudster attack, several observations are gained according to the comprehensive experiments and analysis.\n\n1) GVFL does suffer from adversarial attacks, especially when some information (e.g., node embeddings, structure of model, and gradient of model) is explored by the attackers. 2) Graph splitting strategy of GVFL will not only affect the performance of GVFL but also affect the success rate of adversarial attack, and thus, a proper splitting strategy should be seriously considered in real-world scenarios.\n\n3) The more a participant contributes to the server, the more likely the perturbations added to the participant is to construct a successful adversarial attack. 4) Although DP and Top-K fail to fully defend Graph-Fraudster, the results show that denoising the uploaded node embeddings is still a feasible defensive strategy.\n\n\nC. Limitations\n\nGraph-Fraudster devotes to fooling the server model, even with single-edge modifying. However, the small number of perturbations does not mean that the perturbations are imperceptible, and these perturbations may change some properties of the graph significantly. Besides, frequent queries are needed for Graph-Fraudster, which are expensive and detectable.\n\n\nD. Future Works\n\nAdversarial attack on GVFL will raise our attention about the robustness of GVFL. There are two sides of suggestions that are provided for future works.\n\nRecommendations for Vulnerability Mining: 1) For perturbation strategies, both structure and node features should be considered for perturbation, to reduce the impact of the data imbalance of attacks.\n\n2) Since frequent queries on the server model are expensive and abnormal, reducing queries by stealing more information from GVFL is a possible solution. 3) Exploring the concealment of the perturbations for diverse downstream tasks, such as link prediction and graph classification, should be discussed as well. Suggestions for Defenders: 1) Researchers are advised to focus on the information leakage problem on GVFL, which provides convenience for attackers. Preventing key information of GVFL from privacy inferencing is a direct and efficient method. 2) A fair evaluation agency for participants should be established. Overreliance on high-contributing participants may bring potential security risks, i.e., the impact of adversarial attacks may be amplified by the data bias of the model. 3) Some defense or detection mechanisms can be deployed in terminals or servers to eliminate the impact of adversarial perturbations.\n\n\nrobustness of GVFL. The code and datasets can be downloaded at https://github.com/hgh0545/Graph-Fraudster. Index Terms-Adversarial attack, defense, graph neural network (GNN), privacy leakage, vertical federated learning (VFL).NOMENCLATURE G = (V, E) Originalgraph with sets of nodes and edges. A,\u00c2 Adjacency matrix/adversarial adjacency matrix of G. X,X Feature matrix/adversarial feature matrix of nodes. f \u03b8 (\u00b7) GNN model with parameter \u03b8 . K Number of participants. h m Node embeddings of the malicious participant. h global Global node embeddings. V L Set of nodes with labels. T Set of target nodes. \u03c1 Activation function. Y, Y Real/predicted label list. |F| Number of class for nodes in G. N Number of nodes in the graph G. P\n\nFig. 1 .\n1Illustration of the adversarial attack on GVFL. Small perturbations (e.g., fake relationship and extra transaction record) of the graph-structured data could lead to misclassification of the evaluation agency based on GVFL.\n\nFig. 2 .\n2Forward propagation of GVFL. The server model concatenates the local embeddings as global embeddings and completes the downstream task.\n\nFig. 3 .\n3Framework of Graph-Fraudster.\n\nFig. 4 .\n4Stealing node embeddings via GRN.\n\n18\nSelect adversarial edge e adv = (u, v) by Equation 20.19 Add adversarial edge e adv = (u, v) into\u00c2 i\u22121 as Equation 21 and obtain\u00c2 i . 20 end 21 Return the adversarial adjacency matrix\u00c2. where is the attack budget; O(T GRN ) and O(T shadow ) are the complexity of the training time of GRN and the shadow, depending on maximum training epochs T GRN and T shadow , respectively; O(1) indicates the complexity of noise adding time because FGSM is a one-step noise generator; O() is the complexity of adversarial edges selecting time, which is controlled by the attack budget ; and O(N) indicates that the complexity of Graph-Fraudster is linear, according to the total number of the above steps N.\n\nFig. 6 .\n6Classification margin of target nodes predicted by GVFL on five datasets. The lower classification margin, the better the attack performance.\n\nFig. 7 .\n7Attack on multiparticipant-based GVFL. The x-axis represents the number of participants, and the y-axis represents the node classification tasks' accuracy. Each row represents experiments on different datasets of the same local GNN model.\n\nFig. 8 .\n8Relationship between attack performance of Graph-Fraudster and contribution of the malicious participant on GCN-based VFL.\n\nFig. 9 .\n9Decision boundary before (first row) and after (second row) Graph-Fraudster's attack on Pol.Blogs. (a) GCN (Clean). (b) SGC (Clean). (c) RGCN (Clean). (d) GCN (Graph-Fraudster). (e) SGC (Graph-Fraudster). (f) RGCN (Graph-Fraudster).\n\nFig. 10 .\n10Possible defense against Graph-Fraudster on GCN-based VFL. The upper part is the attack performance of Graph-Fraudster under the defense mechanisms, and the lower part is the performance of GVFL without attack. (a) DP. (b) Top-k.\n\nFig. 11 .\n11Performance of Graph-Fraudster with different dimensions of the local node embeddings. (a) GCN. (b) SGC. (c) RGCN.\n\nFig. 12 .\n12Performance of Graph-Fraudster with different noise scales on GCN-based VFL.\n\n\nAdded Embeddings: Based on the above steps, the noise-added embeddings h fake are obtained. Next, the part of the noise-added embeddings h that belongs to the malicious participant is extracted from h fake . Assuming thath v t fake can confuse the shadow model successfully, the rest of the work is modifying some suitable edges in the original graph to make the node embeddings approximate toh v t m . Thus, Graph-Fraudster devotes to making the target node's embeddings and hv t \n\nv t \nm \n\nv t \n\nv t \n\nm more similar by adding \nperturbations into A \n\narg min \n\n\n\nTABLE I\nIBASIC STATISTICS OF FIVE NETWORK DATASETS\n\nTABLE II\nIIACCURACY (\u00b1STD) OF GVFL BASED ON DIFFERENT GNN MODELS AGAINST FOUR ADVERSARIAL ATTACK METHODS \nON MULTIPLE DATASETS (IN DUAL-PARTICIPANT CASE) \n\nFig. \n\nCommunication-efficient learning of deep networks from decentralized data. H B Mcmahan, E Moore, D Ramage, S Hampson, B A Y Arcas, arXiv:1602.05629H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. Y. Arcas, \"Communication-efficient learning of deep networks from decentralized data,\" 2016, arXiv:1602.05629.\n\nFederated machine learning: Concept and applications. Q Yang, Y Liu, T Chen, Y Tong, ACM Trans. Intell. Syst. Technol. 102Q. Yang, Y. Liu, T. Chen, and Y. Tong, \"Federated machine learning: Concept and applications,\" ACM Trans. Intell. Syst. Technol., vol. 10, no. 2, pp. 1-19, 2019.\n\nApplied federated learning: Improving Google keyboard query suggestions. T Yang, arXiv:1812.02903T. Yang et al., \"Applied federated learning: Improving Google keyboard query suggestions,\" 2018, arXiv:1812.02903.\n\nFedNER: Privacypreserving medical named entity recognition with federated learning. S Ge, F Wu, C Wu, T Qi, Y Huang, X Xie, arXiv:2003.092882020S. Ge, F. Wu, C. Wu, T. Qi, Y. Huang, and X. Xie, \"FedNER: Privacy- preserving medical named entity recognition with federated learning,\" 2020, arXiv:2003.09288.\n\nFederated learning for open banking. G Long, Y Tan, J Jiang, C Zhang, Federated Learning. SpringerCham. SwitzerlandSpringerG. Long, Y. Tan, J. Jiang, and C. Zhang, \"Federated learning for open banking,\" in Federated Learning. SpringerCham, Switzerland: Springer 2020, pp. 240-254.\n\nDeep feature representation and similarity matrix based noise label refinement method for efficient face annotation. A Suruliandi, A Kasthuri, S Raja, Int. J. Interact. Multimedia Artif. Intell. 72A. Suruliandi, A. Kasthuri, and S. Raja, \"Deep feature representation and similarity matrix based noise label refinement method for efficient face annotation,\" Int. J. Interact. Multimedia Artif. Intell., vol. 7, no. 2, pp. 66-78, 2021.\n\nGabor-oriented local order feature-based deep learning for face annotation. A Kasthuri, A Suruliandi, S P Raja, Int. J. Wavelets, Multiresolution Inf. Process. 175A. Kasthuri, A. Suruliandi, and S. P. Raja, \"Gabor-oriented local order feature-based deep learning for face annotation,\" Int. J. Wavelets, Mul- tiresolution Inf. Process., vol. 17, no. 5, Sep. 2019, Art. no. 1950032.\n\nFederated optimization: Distributed machine learning for on-device intelligence. J Kone\u010dn\u00fd, H B Mcmahan, D Ramage, P Richt\u00e1rik, arXiv:1610.02527J. Kone\u010dn\u00fd, H. B. McMahan, D. Ramage, and P. Richt\u00e1rik, \"Federated optimization: Distributed machine learning for on-device intelligence,\" 2016, arXiv:1610.02527.\n\nCommunication-efficient learning of deep networks from decentralized data. B Mcmahan, E Moore, D Ramage, S Hampson, B A Y Arcas, Proc. Artif. Intell. Statist. Artif. Intell. StatistB. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. Y. Arcas, \"Communication-efficient learning of deep networks from decentralized data,\" in Proc. Artif. Intell. Statist., 2017, pp. 1273-1282.\n\nAgnostic federated learning. M Mohri, G Sivek, A T Suresh, Proc. Int. Conf. Mach. Learn. Int. Conf. Mach. LearnM. Mohri, G. Sivek, and A. T. Suresh, \"Agnostic federated learning,\" in Proc. Int. Conf. Mach. Learn., 2019, pp. 4615-4625.\n\nBayesian nonparametric federated learning of neural networks. M Yurochkin, M Agarwal, S Ghosh, K Greenewald, N Hoang, Y Khazaeni, Proc. Int. Conf. Mach. Learn. Int. Conf. Mach. LearnM. Yurochkin, M. Agarwal, S. Ghosh, K. Greenewald, N. Hoang, and Y. Khazaeni, \"Bayesian nonparametric federated learning of neural networks,\" in Proc. Int. Conf. Mach. Learn., 2019, pp. 7252-7261.\n\nPrivacyFL: A simulator for privacy-preserving and secure federated learning. V Mugunthan, A Peraire-Bueno, L Kagal, Proc. 29th ACM Int. Conf. Inf. Knowl. Manage. 29th ACM Int. Conf. Inf. Knowl. ManageV. Mugunthan, A. Peraire-Bueno, and L. Kagal, \"PrivacyFL: A simulator for privacy-preserving and secure federated learning,\" in Proc. 29th ACM Int. Conf. Inf. Knowl. Manage., Oct. 2020, pp. 3085-3092.\n\nASFGNN: Automated separated-federated graph neural network. L Zheng, J Zhou, C Chen, B Wu, L Wang, B Zhang, arXiv:2011.032482020L. Zheng, J. Zhou, C. Chen, B. Wu, L. Wang, and B. Zhang, \"ASFGNN: Automated separated-federated graph neural network,\" 2020, arXiv:2011.03248.\n\nGraphFL: A federated learning framework for semi-supervised node classification on graphs. B Wang, A Li, H Li, Y Chen, arXiv:2012.041872020B. Wang, A. Li, H. Li, and Y. Chen, \"GraphFL: A federated learning framework for semi-supervised node classification on graphs,\" 2020, arXiv:2012.04187.\n\nFedGraphNN: A federated learning system and benchmark for graph neural networks. C He, arXiv:2104.071452021C. He et al., \"FedGraphNN: A federated learning system and benchmark for graph neural networks,\" 2021, arXiv:2104.07145.\n\nVertically federated graph neural network for privacypreserving node classification. J Zhou, arXiv:2005.119032020J. Zhou et al., \"Vertically federated graph neural network for privacy- preserving node classification,\" 2020, arXiv:2005.11903.\n\nA vertical federated learning framework for graph convolutional network. X Ni, X Xu, L Lyu, C Meng, W Wang, arXiv:2106.115932021X. Ni, X. Xu, L. Lyu, C. Meng, and W. Wang, \"A vertical fed- erated learning framework for graph convolutional network,\" 2021, arXiv:2106.11593.\n\nFedGNN: Federated graph neural network for privacy-preserving recommendation. C Wu, F Wu, Y Cao, Y Huang, X Xie, arXiv:2102.049252021C. Wu, F. Wu, Y. Cao, Y. Huang, and X. Xie, \"FedGNN: Federated graph neural network for privacy-preserving recommendation,\" 2021, arXiv:2102.04925.\n\nDeep models under the GAN: Information leakage from collaborative deep learning. B Hitaj, G Ateniese, F Perez-Cruz, Proc. ACM SIGSAC Conf. ACM SIGSAC ConfB. Hitaj, G. Ateniese, and F. Perez-Cruz, \"Deep models under the GAN: Information leakage from collaborative deep learning,\" in Proc. ACM SIGSAC Conf. Comput. Commun. Secur., Oct. 2017, pp. 603-618.\n\nComprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning. M Nasr, R Shokri, A Houmansadr, Proc. IEEE Symp. Secur. Privacy (SP). IEEE Symp. Secur. Privacy (SP)M. Nasr, R. Shokri, and A. Houmansadr, \"Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning,\" in Proc. IEEE Symp. Secur. Privacy (SP), May 2019, pp. 739-753.\n\nDeep leakage from gradients. L Zhu, S Han, Federated Learning. Cham, SwitzerlandSpringerL. Zhu and S. Han, \"Deep leakage from gradients,\" in Federated Learning. Cham, Switzerland: Springer, 2020, pp. 17-31.\n\nFeature inference attack on model predictions in vertical federated learning. X Luo, Y Wu, X Xiao, B C Ooi, arXiv:2010.101522020X. Luo, Y. Wu, X. Xiao, and B. C. Ooi, \"Feature inference attack on model predictions in vertical federated learning,\" 2020, arXiv:2010.10152.\n\nPrivacy-preserving federated learning on partitioned attributes. S Zhang, arXiv:2104.143832021S. Zhang et al., \"Privacy-preserving federated learning on partitioned attributes,\" 2021, arXiv:2104.14383.\n\nLabel leakage and protection in two-party split learning. O Li, arXiv:2102.085042021O. Li et al., \"Label leakage and protection in two-party split learning,\" 2021, arXiv:2102.08504.\n\nSustainable security for the Internet of Things using artificial intelligence architectures. C Iwendi, S U Rehman, A R Javed, S Khan, G Srivastava, ACM Trans. Internet Technol. 213C. Iwendi, S. U. Rehman, A. R. Javed, S. Khan, and G. Srivastava, \"Sus- tainable security for the Internet of Things using artificial intelligence architectures,\" ACM Trans. Internet Technol., vol. 21, no. 3, pp. 1-22, Jun. 2021.\n\nGenerative ensemble learning for mitigating adversarial malware detection in IoT. U Ahmed, J C W Lin, G Srivastava, Proc. IEEE 29th Int. Conf. Netw. Protocols (ICNP). IEEE 29th Int. Conf. Netw. Protocols (ICNP)U. Ahmed, J. C.-W. Lin, and G. Srivastava, \"Generative ensem- ble learning for mitigating adversarial malware detection in IoT,\" in Proc. IEEE 29th Int. Conf. Netw. Protocols (ICNP), Nov. 2021, pp. 1-5.\n\nAdversarial attacks on neural networks for graph data. D Z\u00fcgner, A Akbarnejad, S G\u00fcnnemann, Proc. 28th Int. Joint Conf. 28th Int. Joint ConfD. Z\u00fcgner, A. Akbarnejad, and S. G\u00fcnnemann, \"Adversarial attacks on neural networks for graph data,\" in Proc. 28th Int. Joint Conf. Artif. Intell., Aug. 2019, pp. 2847-2856.\n\nAdversarial attack on graph structured data. H Dai, arXiv:1806.02371H. Dai et al., \"Adversarial attack on graph structured data,\" 2018, arXiv:1806.02371.\n\nFast gradient attack on network embedding. J Chen, Y Wu, X Xu, Y Chen, H Zheng, Q Xuan, arXiv:1809.02797J. Chen, Y. Wu, X. Xu, Y. Chen, H. Zheng, and Q. Xuan, \"Fast gradient attack on network embedding,\" 2018, arXiv:1809.02797.\n\nAdversarial examples on graph data: Deep insights into attack and defense. H Wu, C Wang, Y Tyshetskiy, A Docherty, K Lu, L Zhu, arXiv:1903.01610H. Wu, C. Wang, Y. Tyshetskiy, A. Docherty, K. Lu, and L. Zhu, \"Adversarial examples on graph data: Deep insights into attack and defense,\" 2019, arXiv:1903.01610.\n\nAdversarial attack on large scale graph. J Li, T Xie, C Liang, F Xie, X He, Z Zheng, 10.1109/TKDE.2021.3078755IEEE Trans. Knowl. Data Eng., early access. J. Li, T. Xie, C. Liang, F. Xie, X. He, and Z. Zheng, \"Adversarial attack on large scale graph,\" IEEE Trans. Knowl. Data Eng., early access, May 11, 2021, doi: 10.1109/TKDE.2021.3078755.\n\nAttack graph convolutional networks by adding fake nodes. X Wang, M Cheng, J Eaton, C.-J Hsieh, F Wu, arXiv:1810.10751X. Wang, M. Cheng, J. Eaton, C.-J. Hsieh, and F. Wu, \"Attack graph convolutional networks by adding fake nodes,\" 2018, arXiv:1810. 10751.\n\nA restricted black-box adversarial framework towards attacking graph embedding models. H Chang, Proc. AAAI Conf. AAAI Conf34H. Chang et al., \"A restricted black-box adversarial framework towards attacking graph embedding models,\" in Proc. AAAI Conf. Artif. Intell., vol. 34, no. 4, 2020, pp. 3389-3396.\n\nAttacking graph convolutional networks via rewiring. Y Ma, S Wang, T Derr, L Wu, J Tang, arXiv:1906.03750Y. Ma, S. Wang, T. Derr, L. Wu, and J. Tang, \"Attacking graph convolutional networks via rewiring,\" 2019, arXiv:1906.03750.\n\nGA-based Q-attack on community detection. J Chen, IEEE Trans. Comput. Soc. Syst. 63J. Chen et al., \"GA-based Q-attack on community detection,\" IEEE Trans. Comput. Soc. Syst., vol. 6, no. 3, pp. 491-503, Jun. 2019.\n\nExplaining and harnessing adversarial examples. I J Goodfellow, J Shlens, C Szegedy, arXiv:1412.6572I. J. Goodfellow, J. Shlens, and C. Szegedy, \"Explaining and harnessing adversarial examples,\" 2014, arXiv:1412.6572.\n\nAutomating the construction of internet portals with machine learning. A K Mccallum, K Nigam, J Rennie, K Seymore, Inf. Retr. 32A. K. McCallum, K. Nigam, J. Rennie, and K. Seymore, \"Automating the construction of internet portals with machine learning,\" Inf. Retr., vol. 3, no. 2, pp. 127-163, 2000.\n\nThe political blogosphere and the 2004 U.S. election: Divided they blog. L A Adamic, N Glance, Proc. 3rd Int. Workshop Link Discovery (LinkKDD). 3rd Int. Workshop Link Discovery (LinkKDD)L. A. Adamic and N. Glance, \"The political blogosphere and the 2004 U.S. election: Divided they blog,\" in Proc. 3rd Int. Workshop Link Discovery (LinkKDD), 2005, pp. 36-43.\n\nCollective classification in network data. P Sen, G Namata, M Bilgic, L Getoor, B Galligher, T Eliassi-Rad, AI Mag. 29393P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Galligher, and T. Eliassi-Rad, \"Collective classification in network data,\" AI Mag., vol. 29, no. 3, p. 93, 2008.\n\nSemi-supervised classification with graph convolutional networks. T N Kipf, M Welling, arXiv:1609.02907T. N. Kipf and M. Welling, \"Semi-supervised classification with graph convolutional networks,\" 2016, arXiv:1609.02907.\n\nSimplifying graph convolutional networks. F Wu, A Souza, T Zhang, C Fifty, T Yu, K Weinberger, Proc. Int. Conf. Mach. Learn. Int. Conf. Mach. LearnF. Wu, A. Souza, T. Zhang, C. Fifty, T. Yu, and K. Weinberger, \"Simplifying graph convolutional networks,\" in Proc. Int. Conf. Mach. Learn., 2019, pp. 6861-6871.\n\nRobust graph convolutional networks against adversarial attacks. D Zhu, Z Zhang, P Cui, W Zhu, Proc. 25th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining. 25th ACM SIGKDD Int. Conf. Knowl. Discovery Data MiningD. Zhu, Z. Zhang, P. Cui, and W. Zhu, \"Robust graph convolutional networks against adversarial attacks,\" in Proc. 25th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, Jul. 2019, pp. 1399-1407.\n\nDifferential privacy: A survey of results. C Dwork, Proc. Int. Conf. Theory Appl. Models Comput. Int. Conf. Theory Appl. Models ComputSpringerC. Dwork, \"Differential privacy: A survey of results,\" in Proc. Int. Conf. Theory Appl. Models Comput., Springer, 2008, pp. 1-19.\n\nFedSel: Federated SGD under local differential privacy with top-k dimension selection. R Liu, Y Cao, M Yoshikawa, H Chen, Proc. Int. Conf. Database Syst. Int. Conf. Database SystCham, SwitzerlandSpringerR. Liu, Y. Cao, M. Yoshikawa, and H. Chen, \"FedSel: Federated SGD under local differential privacy with top-k dimension selection,\" in Proc. Int. Conf. Database Syst. Adv. Appl., Cham, Switzerland: Springer, 2020, pp. 485-501.\n", "annotations": {"author": "[{\"end\":301,\"start\":108},{\"end\":473,\"start\":302},{\"end\":692,\"start\":474},{\"end\":887,\"start\":693},{\"end\":1084,\"start\":888},{\"end\":1271,\"start\":1085},{\"end\":1442,\"start\":1272},{\"end\":1612,\"start\":1443},{\"end\":1782,\"start\":1613},{\"end\":1971,\"start\":1783}]", "publisher": null, "author_last_name": "[{\"end\":119,\"start\":115},{\"end\":314,\"start\":309},{\"end\":486,\"start\":481},{\"end\":704,\"start\":702},{\"end\":901,\"start\":896},{\"end\":1093,\"start\":1090},{\"end\":1454,\"start\":1450},{\"end\":1624,\"start\":1622},{\"end\":1795,\"start\":1790}]", "author_first_name": "[{\"end\":114,\"start\":108},{\"end\":308,\"start\":302},{\"end\":480,\"start\":474},{\"end\":701,\"start\":693},{\"end\":895,\"start\":888},{\"end\":1089,\"start\":1085},{\"end\":1278,\"start\":1272},{\"end\":1284,\"start\":1279},{\"end\":1449,\"start\":1443},{\"end\":1621,\"start\":1613},{\"end\":1789,\"start\":1783}]", "author_affiliation": "[{\"end\":300,\"start\":144},{\"end\":472,\"start\":316},{\"end\":691,\"start\":535},{\"end\":886,\"start\":730},{\"end\":1083,\"start\":927},{\"end\":1270,\"start\":1114},{\"end\":1441,\"start\":1286},{\"end\":1611,\"start\":1456},{\"end\":1781,\"start\":1626},{\"end\":1970,\"start\":1797}]", "title": "[{\"end\":95,\"start\":1},{\"end\":2066,\"start\":1972}]", "venue": "[{\"end\":2117,\"start\":2068}]", "abstract": "[{\"end\":4086,\"start\":2425}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4463,\"start\":4460},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4468,\"start\":4465},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5158,\"start\":5155},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5174,\"start\":5171},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5187,\"start\":5184},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5212,\"start\":5209},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5217,\"start\":5214},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5734,\"start\":5731},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5740,\"start\":5736},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10517,\"start\":10513},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10741,\"start\":10737},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10953,\"start\":10949},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11124,\"start\":11120},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11408,\"start\":11404},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11716,\"start\":11712},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12030,\"start\":12026},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12195,\"start\":12191},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12367,\"start\":12363},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12603,\"start\":12599},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":13023,\"start\":13019},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13264,\"start\":13260},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":13597,\"start\":13593},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":13715,\"start\":13711},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":13920,\"start\":13916},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":14125,\"start\":14121},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":14224,\"start\":14220},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14365,\"start\":14361},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":14417,\"start\":14413},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14601,\"start\":14597},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14712,\"start\":14708},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14866,\"start\":14862},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":15107,\"start\":15103},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":16865,\"start\":16861},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21033,\"start\":21029},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":25081,\"start\":25077},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":26835,\"start\":26831},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":28359,\"start\":28358},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":28493,\"start\":28492},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":28623,\"start\":28622},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":28651,\"start\":28650},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":28717,\"start\":28716},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":28757,\"start\":28756},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":28775,\"start\":28773},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":28861,\"start\":28859},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":28893,\"start\":28891},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":28918,\"start\":28916},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":28979,\"start\":28977},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":29049,\"start\":29047},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29068,\"start\":29066},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":29130,\"start\":29128},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":30062,\"start\":30058},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":30076,\"start\":30072},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":30091,\"start\":30087},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":30107,\"start\":30103},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":30124,\"start\":30120},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":31240,\"start\":31236},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":31801,\"start\":31797},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":32047,\"start\":32043},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":32912,\"start\":32908},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":33192,\"start\":33188},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":33434,\"start\":33430},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":38346,\"start\":38342},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":45413,\"start\":45409},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":45615,\"start\":45611}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":52343,\"start\":51609},{\"attributes\":{\"id\":\"fig_1\"},\"end\":52578,\"start\":52344},{\"attributes\":{\"id\":\"fig_2\"},\"end\":52725,\"start\":52579},{\"attributes\":{\"id\":\"fig_3\"},\"end\":52766,\"start\":52726},{\"attributes\":{\"id\":\"fig_4\"},\"end\":52811,\"start\":52767},{\"attributes\":{\"id\":\"fig_5\"},\"end\":53509,\"start\":52812},{\"attributes\":{\"id\":\"fig_6\"},\"end\":53662,\"start\":53510},{\"attributes\":{\"id\":\"fig_7\"},\"end\":53912,\"start\":53663},{\"attributes\":{\"id\":\"fig_8\"},\"end\":54046,\"start\":53913},{\"attributes\":{\"id\":\"fig_9\"},\"end\":54290,\"start\":54047},{\"attributes\":{\"id\":\"fig_10\"},\"end\":54533,\"start\":54291},{\"attributes\":{\"id\":\"fig_11\"},\"end\":54661,\"start\":54534},{\"attributes\":{\"id\":\"fig_12\"},\"end\":54751,\"start\":54662},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":55317,\"start\":54752},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":55369,\"start\":55318},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":55532,\"start\":55370}]", "paragraph": "[{\"end\":4195,\"start\":4088},{\"end\":4270,\"start\":4197},{\"end\":4300,\"start\":4279},{\"end\":4329,\"start\":4309},{\"end\":4415,\"start\":4396},{\"end\":4960,\"start\":4435},{\"end\":6497,\"start\":4962},{\"end\":7007,\"start\":6499},{\"end\":8026,\"start\":7009},{\"end\":10006,\"start\":8028},{\"end\":10176,\"start\":10027},{\"end\":11823,\"start\":10196},{\"end\":13421,\"start\":11853},{\"end\":15282,\"start\":13462},{\"end\":15671,\"start\":15284},{\"end\":16350,\"start\":15697},{\"end\":16944,\"start\":16463},{\"end\":17294,\"start\":16991},{\"end\":17389,\"start\":17296},{\"end\":17598,\"start\":17429},{\"end\":17882,\"start\":17645},{\"end\":18053,\"start\":17931},{\"end\":18105,\"start\":18055},{\"end\":18654,\"start\":18218},{\"end\":18723,\"start\":18656},{\"end\":18922,\"start\":18758},{\"end\":19375,\"start\":18924},{\"end\":19926,\"start\":19377},{\"end\":20198,\"start\":19928},{\"end\":20983,\"start\":20221},{\"end\":22734,\"start\":20985},{\"end\":23017,\"start\":22811},{\"end\":23304,\"start\":23019},{\"end\":23515,\"start\":23356},{\"end\":23913,\"start\":23653},{\"end\":24937,\"start\":23958},{\"end\":25169,\"start\":25001},{\"end\":25256,\"start\":25171},{\"end\":25388,\"start\":25314},{\"end\":25551,\"start\":25390},{\"end\":25706,\"start\":25581},{\"end\":25847,\"start\":25733},{\"end\":26154,\"start\":26026},{\"end\":26514,\"start\":26304},{\"end\":26685,\"start\":26587},{\"end\":26885,\"start\":26687},{\"end\":27230,\"start\":26969},{\"end\":27329,\"start\":27253},{\"end\":27633,\"start\":27375},{\"end\":27705,\"start\":27655},{\"end\":27781,\"start\":27722},{\"end\":28097,\"start\":27808},{\"end\":29263,\"start\":28178},{\"end\":29645,\"start\":29340},{\"end\":29935,\"start\":29665},{\"end\":30241,\"start\":29951},{\"end\":31067,\"start\":30243},{\"end\":31463,\"start\":31090},{\"end\":31761,\"start\":31525},{\"end\":31915,\"start\":31763},{\"end\":32172,\"start\":31969},{\"end\":32501,\"start\":32320},{\"end\":32899,\"start\":32525},{\"end\":33642,\"start\":32901},{\"end\":34281,\"start\":33666},{\"end\":34440,\"start\":34283},{\"end\":34625,\"start\":34466},{\"end\":34978,\"start\":34627},{\"end\":35689,\"start\":34980},{\"end\":37520,\"start\":35691},{\"end\":37639,\"start\":37522},{\"end\":38453,\"start\":37697},{\"end\":38510,\"start\":38455},{\"end\":38600,\"start\":38512},{\"end\":39618,\"start\":38602},{\"end\":40357,\"start\":39620},{\"end\":40856,\"start\":40403},{\"end\":42775,\"start\":40858},{\"end\":44366,\"start\":42817},{\"end\":45026,\"start\":44368},{\"end\":45401,\"start\":45050},{\"end\":47247,\"start\":45403},{\"end\":47603,\"start\":47273},{\"end\":48013,\"start\":47605},{\"end\":48508,\"start\":48015},{\"end\":49007,\"start\":48545},{\"end\":49194,\"start\":49027},{\"end\":49602,\"start\":49196},{\"end\":49928,\"start\":49604},{\"end\":50304,\"start\":49947},{\"end\":50476,\"start\":50324},{\"end\":50678,\"start\":50478},{\"end\":51608,\"start\":50680}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":4343,\"start\":4330},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16462,\"start\":16351},{\"attributes\":{\"id\":\"formula_2\"},\"end\":17428,\"start\":17390},{\"attributes\":{\"id\":\"formula_3\"},\"end\":17644,\"start\":17599},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17930,\"start\":17883},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18217,\"start\":18106},{\"attributes\":{\"id\":\"formula_6\"},\"end\":18757,\"start\":18724},{\"attributes\":{\"id\":\"formula_7\"},\"end\":22757,\"start\":22735},{\"attributes\":{\"id\":\"formula_8\"},\"end\":22810,\"start\":22757},{\"attributes\":{\"id\":\"formula_9\"},\"end\":23355,\"start\":23305},{\"attributes\":{\"id\":\"formula_10\"},\"end\":23652,\"start\":23516},{\"attributes\":{\"id\":\"formula_11\"},\"end\":25000,\"start\":24938},{\"attributes\":{\"id\":\"formula_12\"},\"end\":25313,\"start\":25257},{\"attributes\":{\"id\":\"formula_13\"},\"end\":25580,\"start\":25552},{\"attributes\":{\"id\":\"formula_14\"},\"end\":25732,\"start\":25707},{\"attributes\":{\"id\":\"formula_15\"},\"end\":26025,\"start\":25848},{\"attributes\":{\"id\":\"formula_16\"},\"end\":26303,\"start\":26155},{\"attributes\":{\"id\":\"formula_17\"},\"end\":26586,\"start\":26550},{\"attributes\":{\"id\":\"formula_18\"},\"end\":26968,\"start\":26886},{\"attributes\":{\"id\":\"formula_19\"},\"end\":27252,\"start\":27231},{\"attributes\":{\"id\":\"formula_20\"},\"end\":27374,\"start\":27330},{\"attributes\":{\"id\":\"formula_21\"},\"end\":27654,\"start\":27634},{\"attributes\":{\"id\":\"formula_22\"},\"end\":28147,\"start\":28098},{\"attributes\":{\"id\":\"formula_23\"},\"end\":29339,\"start\":29264},{\"attributes\":{\"id\":\"formula_24\"},\"end\":31524,\"start\":31464},{\"attributes\":{\"id\":\"formula_25\"},\"end\":31968,\"start\":31916},{\"attributes\":{\"id\":\"formula_26\"},\"end\":32319,\"start\":32173},{\"attributes\":{\"id\":\"formula_27\"},\"end\":42816,\"start\":42776}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":30174,\"start\":30167},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":35000,\"start\":34992}]", "section_header": "[{\"end\":4277,\"start\":4273},{\"end\":4307,\"start\":4303},{\"end\":4394,\"start\":4345},{\"end\":4433,\"start\":4418},{\"end\":10025,\"start\":10009},{\"end\":10194,\"start\":10179},{\"end\":11851,\"start\":11826},{\"end\":13460,\"start\":13424},{\"end\":15695,\"start\":15674},{\"end\":16989,\"start\":16947},{\"end\":20219,\"start\":20201},{\"end\":23956,\"start\":23916},{\"end\":26549,\"start\":26517},{\"end\":27720,\"start\":27708},{\"end\":27806,\"start\":27784},{\"end\":28176,\"start\":28149},{\"end\":29663,\"start\":29648},{\"end\":29949,\"start\":29938},{\"end\":31088,\"start\":31070},{\"end\":32523,\"start\":32504},{\"end\":33664,\"start\":33645},{\"end\":34464,\"start\":34443},{\"end\":37695,\"start\":37642},{\"end\":40401,\"start\":40360},{\"end\":45048,\"start\":45029},{\"end\":47271,\"start\":47250},{\"end\":48524,\"start\":48511},{\"end\":48543,\"start\":48527},{\"end\":49025,\"start\":49010},{\"end\":49945,\"start\":49931},{\"end\":50322,\"start\":50307},{\"end\":52353,\"start\":52345},{\"end\":52588,\"start\":52580},{\"end\":52735,\"start\":52727},{\"end\":52776,\"start\":52768},{\"end\":52815,\"start\":52813},{\"end\":53519,\"start\":53511},{\"end\":53672,\"start\":53664},{\"end\":53922,\"start\":53914},{\"end\":54056,\"start\":54048},{\"end\":54301,\"start\":54292},{\"end\":54544,\"start\":54535},{\"end\":54672,\"start\":54663},{\"end\":55326,\"start\":55319},{\"end\":55379,\"start\":55371}]", "table": "[{\"end\":55317,\"start\":55231},{\"end\":55532,\"start\":55382}]", "figure_caption": "[{\"end\":52343,\"start\":51611},{\"end\":52578,\"start\":52355},{\"end\":52725,\"start\":52590},{\"end\":52766,\"start\":52737},{\"end\":52811,\"start\":52778},{\"end\":53509,\"start\":52816},{\"end\":53662,\"start\":53521},{\"end\":53912,\"start\":53674},{\"end\":54046,\"start\":53924},{\"end\":54290,\"start\":54058},{\"end\":54533,\"start\":54304},{\"end\":54661,\"start\":54547},{\"end\":54751,\"start\":54675},{\"end\":55231,\"start\":54754},{\"end\":55369,\"start\":55328}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":6582,\"start\":6576},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17237,\"start\":17231},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20904,\"start\":20898},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":21137,\"start\":21131},{\"end\":35254,\"start\":35248},{\"end\":36494,\"start\":36488},{\"end\":37257,\"start\":37256},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":38671,\"start\":38665},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":40855,\"start\":40849},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":42042,\"start\":42036},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":44550,\"start\":44544},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":45872,\"start\":45865},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":46221,\"start\":46211},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":46463,\"start\":46453},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":48012,\"start\":48005}]", "bib_author_first_name": "[{\"end\":55610,\"start\":55609},{\"end\":55612,\"start\":55611},{\"end\":55623,\"start\":55622},{\"end\":55632,\"start\":55631},{\"end\":55642,\"start\":55641},{\"end\":55653,\"start\":55652},{\"end\":55657,\"start\":55654},{\"end\":55906,\"start\":55905},{\"end\":55914,\"start\":55913},{\"end\":55921,\"start\":55920},{\"end\":55929,\"start\":55928},{\"end\":56210,\"start\":56209},{\"end\":56434,\"start\":56433},{\"end\":56440,\"start\":56439},{\"end\":56446,\"start\":56445},{\"end\":56452,\"start\":56451},{\"end\":56458,\"start\":56457},{\"end\":56467,\"start\":56466},{\"end\":56694,\"start\":56693},{\"end\":56702,\"start\":56701},{\"end\":56709,\"start\":56708},{\"end\":56718,\"start\":56717},{\"end\":57056,\"start\":57055},{\"end\":57070,\"start\":57069},{\"end\":57082,\"start\":57081},{\"end\":57450,\"start\":57449},{\"end\":57462,\"start\":57461},{\"end\":57476,\"start\":57475},{\"end\":57478,\"start\":57477},{\"end\":57837,\"start\":57836},{\"end\":57848,\"start\":57847},{\"end\":57850,\"start\":57849},{\"end\":57861,\"start\":57860},{\"end\":57871,\"start\":57870},{\"end\":58139,\"start\":58138},{\"end\":58150,\"start\":58149},{\"end\":58159,\"start\":58158},{\"end\":58169,\"start\":58168},{\"end\":58180,\"start\":58179},{\"end\":58184,\"start\":58181},{\"end\":58472,\"start\":58471},{\"end\":58481,\"start\":58480},{\"end\":58490,\"start\":58489},{\"end\":58492,\"start\":58491},{\"end\":58741,\"start\":58740},{\"end\":58754,\"start\":58753},{\"end\":58765,\"start\":58764},{\"end\":58774,\"start\":58773},{\"end\":58788,\"start\":58787},{\"end\":58797,\"start\":58796},{\"end\":59136,\"start\":59135},{\"end\":59149,\"start\":59148},{\"end\":59166,\"start\":59165},{\"end\":59521,\"start\":59520},{\"end\":59530,\"start\":59529},{\"end\":59538,\"start\":59537},{\"end\":59546,\"start\":59545},{\"end\":59552,\"start\":59551},{\"end\":59560,\"start\":59559},{\"end\":59825,\"start\":59824},{\"end\":59833,\"start\":59832},{\"end\":59839,\"start\":59838},{\"end\":59845,\"start\":59844},{\"end\":60108,\"start\":60107},{\"end\":60341,\"start\":60340},{\"end\":60572,\"start\":60571},{\"end\":60578,\"start\":60577},{\"end\":60584,\"start\":60583},{\"end\":60591,\"start\":60590},{\"end\":60599,\"start\":60598},{\"end\":60851,\"start\":60850},{\"end\":60857,\"start\":60856},{\"end\":60863,\"start\":60862},{\"end\":60870,\"start\":60869},{\"end\":60879,\"start\":60878},{\"end\":61136,\"start\":61135},{\"end\":61145,\"start\":61144},{\"end\":61157,\"start\":61156},{\"end\":61549,\"start\":61548},{\"end\":61557,\"start\":61556},{\"end\":61567,\"start\":61566},{\"end\":61924,\"start\":61923},{\"end\":61931,\"start\":61930},{\"end\":62181,\"start\":62180},{\"end\":62188,\"start\":62187},{\"end\":62194,\"start\":62193},{\"end\":62202,\"start\":62201},{\"end\":62204,\"start\":62203},{\"end\":62440,\"start\":62439},{\"end\":62636,\"start\":62635},{\"end\":62854,\"start\":62853},{\"end\":62864,\"start\":62863},{\"end\":62866,\"start\":62865},{\"end\":62876,\"start\":62875},{\"end\":62878,\"start\":62877},{\"end\":62887,\"start\":62886},{\"end\":62895,\"start\":62894},{\"end\":63254,\"start\":63253},{\"end\":63263,\"start\":63262},{\"end\":63267,\"start\":63264},{\"end\":63274,\"start\":63273},{\"end\":63641,\"start\":63640},{\"end\":63651,\"start\":63650},{\"end\":63665,\"start\":63664},{\"end\":63946,\"start\":63945},{\"end\":64099,\"start\":64098},{\"end\":64107,\"start\":64106},{\"end\":64113,\"start\":64112},{\"end\":64119,\"start\":64118},{\"end\":64127,\"start\":64126},{\"end\":64136,\"start\":64135},{\"end\":64360,\"start\":64359},{\"end\":64366,\"start\":64365},{\"end\":64374,\"start\":64373},{\"end\":64388,\"start\":64387},{\"end\":64400,\"start\":64399},{\"end\":64406,\"start\":64405},{\"end\":64635,\"start\":64634},{\"end\":64641,\"start\":64640},{\"end\":64648,\"start\":64647},{\"end\":64657,\"start\":64656},{\"end\":64664,\"start\":64663},{\"end\":64670,\"start\":64669},{\"end\":64994,\"start\":64993},{\"end\":65002,\"start\":65001},{\"end\":65011,\"start\":65010},{\"end\":65023,\"start\":65019},{\"end\":65032,\"start\":65031},{\"end\":65280,\"start\":65279},{\"end\":65550,\"start\":65549},{\"end\":65556,\"start\":65555},{\"end\":65564,\"start\":65563},{\"end\":65572,\"start\":65571},{\"end\":65578,\"start\":65577},{\"end\":65769,\"start\":65768},{\"end\":65990,\"start\":65989},{\"end\":65992,\"start\":65991},{\"end\":66006,\"start\":66005},{\"end\":66016,\"start\":66015},{\"end\":66232,\"start\":66231},{\"end\":66234,\"start\":66233},{\"end\":66246,\"start\":66245},{\"end\":66255,\"start\":66254},{\"end\":66265,\"start\":66264},{\"end\":66535,\"start\":66534},{\"end\":66537,\"start\":66536},{\"end\":66547,\"start\":66546},{\"end\":66866,\"start\":66865},{\"end\":66873,\"start\":66872},{\"end\":66883,\"start\":66882},{\"end\":66893,\"start\":66892},{\"end\":66903,\"start\":66902},{\"end\":66916,\"start\":66915},{\"end\":67169,\"start\":67168},{\"end\":67171,\"start\":67170},{\"end\":67179,\"start\":67178},{\"end\":67368,\"start\":67367},{\"end\":67374,\"start\":67373},{\"end\":67383,\"start\":67382},{\"end\":67392,\"start\":67391},{\"end\":67401,\"start\":67400},{\"end\":67407,\"start\":67406},{\"end\":67701,\"start\":67700},{\"end\":67708,\"start\":67707},{\"end\":67717,\"start\":67716},{\"end\":67724,\"start\":67723},{\"end\":68090,\"start\":68089},{\"end\":68407,\"start\":68406},{\"end\":68414,\"start\":68413},{\"end\":68421,\"start\":68420},{\"end\":68434,\"start\":68433}]", "bib_author_last_name": "[{\"end\":55620,\"start\":55613},{\"end\":55629,\"start\":55624},{\"end\":55639,\"start\":55633},{\"end\":55650,\"start\":55643},{\"end\":55663,\"start\":55658},{\"end\":55911,\"start\":55907},{\"end\":55918,\"start\":55915},{\"end\":55926,\"start\":55922},{\"end\":55934,\"start\":55930},{\"end\":56215,\"start\":56211},{\"end\":56437,\"start\":56435},{\"end\":56443,\"start\":56441},{\"end\":56449,\"start\":56447},{\"end\":56455,\"start\":56453},{\"end\":56464,\"start\":56459},{\"end\":56471,\"start\":56468},{\"end\":56699,\"start\":56695},{\"end\":56706,\"start\":56703},{\"end\":56715,\"start\":56710},{\"end\":56724,\"start\":56719},{\"end\":57067,\"start\":57057},{\"end\":57079,\"start\":57071},{\"end\":57087,\"start\":57083},{\"end\":57459,\"start\":57451},{\"end\":57473,\"start\":57463},{\"end\":57483,\"start\":57479},{\"end\":57845,\"start\":57838},{\"end\":57858,\"start\":57851},{\"end\":57868,\"start\":57862},{\"end\":57881,\"start\":57872},{\"end\":58147,\"start\":58140},{\"end\":58156,\"start\":58151},{\"end\":58166,\"start\":58160},{\"end\":58177,\"start\":58170},{\"end\":58190,\"start\":58185},{\"end\":58478,\"start\":58473},{\"end\":58487,\"start\":58482},{\"end\":58499,\"start\":58493},{\"end\":58751,\"start\":58742},{\"end\":58762,\"start\":58755},{\"end\":58771,\"start\":58766},{\"end\":58785,\"start\":58775},{\"end\":58794,\"start\":58789},{\"end\":58806,\"start\":58798},{\"end\":59146,\"start\":59137},{\"end\":59163,\"start\":59150},{\"end\":59172,\"start\":59167},{\"end\":59527,\"start\":59522},{\"end\":59535,\"start\":59531},{\"end\":59543,\"start\":59539},{\"end\":59549,\"start\":59547},{\"end\":59557,\"start\":59553},{\"end\":59566,\"start\":59561},{\"end\":59830,\"start\":59826},{\"end\":59836,\"start\":59834},{\"end\":59842,\"start\":59840},{\"end\":59850,\"start\":59846},{\"end\":60111,\"start\":60109},{\"end\":60346,\"start\":60342},{\"end\":60575,\"start\":60573},{\"end\":60581,\"start\":60579},{\"end\":60588,\"start\":60585},{\"end\":60596,\"start\":60592},{\"end\":60604,\"start\":60600},{\"end\":60854,\"start\":60852},{\"end\":60860,\"start\":60858},{\"end\":60867,\"start\":60864},{\"end\":60876,\"start\":60871},{\"end\":60883,\"start\":60880},{\"end\":61142,\"start\":61137},{\"end\":61154,\"start\":61146},{\"end\":61168,\"start\":61158},{\"end\":61554,\"start\":61550},{\"end\":61564,\"start\":61558},{\"end\":61578,\"start\":61568},{\"end\":61928,\"start\":61925},{\"end\":61935,\"start\":61932},{\"end\":62185,\"start\":62182},{\"end\":62191,\"start\":62189},{\"end\":62199,\"start\":62195},{\"end\":62208,\"start\":62205},{\"end\":62446,\"start\":62441},{\"end\":62639,\"start\":62637},{\"end\":62861,\"start\":62855},{\"end\":62873,\"start\":62867},{\"end\":62884,\"start\":62879},{\"end\":62892,\"start\":62888},{\"end\":62906,\"start\":62896},{\"end\":63260,\"start\":63255},{\"end\":63271,\"start\":63268},{\"end\":63285,\"start\":63275},{\"end\":63648,\"start\":63642},{\"end\":63662,\"start\":63652},{\"end\":63675,\"start\":63666},{\"end\":63950,\"start\":63947},{\"end\":64104,\"start\":64100},{\"end\":64110,\"start\":64108},{\"end\":64116,\"start\":64114},{\"end\":64124,\"start\":64120},{\"end\":64133,\"start\":64128},{\"end\":64141,\"start\":64137},{\"end\":64363,\"start\":64361},{\"end\":64371,\"start\":64367},{\"end\":64385,\"start\":64375},{\"end\":64397,\"start\":64389},{\"end\":64403,\"start\":64401},{\"end\":64410,\"start\":64407},{\"end\":64638,\"start\":64636},{\"end\":64645,\"start\":64642},{\"end\":64654,\"start\":64649},{\"end\":64661,\"start\":64658},{\"end\":64667,\"start\":64665},{\"end\":64676,\"start\":64671},{\"end\":64999,\"start\":64995},{\"end\":65008,\"start\":65003},{\"end\":65017,\"start\":65012},{\"end\":65029,\"start\":65024},{\"end\":65035,\"start\":65033},{\"end\":65286,\"start\":65281},{\"end\":65553,\"start\":65551},{\"end\":65561,\"start\":65557},{\"end\":65569,\"start\":65565},{\"end\":65575,\"start\":65573},{\"end\":65583,\"start\":65579},{\"end\":65774,\"start\":65770},{\"end\":66003,\"start\":65993},{\"end\":66013,\"start\":66007},{\"end\":66024,\"start\":66017},{\"end\":66243,\"start\":66235},{\"end\":66252,\"start\":66247},{\"end\":66262,\"start\":66256},{\"end\":66273,\"start\":66266},{\"end\":66544,\"start\":66538},{\"end\":66554,\"start\":66548},{\"end\":66870,\"start\":66867},{\"end\":66880,\"start\":66874},{\"end\":66890,\"start\":66884},{\"end\":66900,\"start\":66894},{\"end\":66913,\"start\":66904},{\"end\":66928,\"start\":66917},{\"end\":67176,\"start\":67172},{\"end\":67187,\"start\":67180},{\"end\":67371,\"start\":67369},{\"end\":67380,\"start\":67375},{\"end\":67389,\"start\":67384},{\"end\":67398,\"start\":67393},{\"end\":67404,\"start\":67402},{\"end\":67418,\"start\":67408},{\"end\":67705,\"start\":67702},{\"end\":67714,\"start\":67709},{\"end\":67721,\"start\":67718},{\"end\":67728,\"start\":67725},{\"end\":68096,\"start\":68091},{\"end\":68411,\"start\":68408},{\"end\":68418,\"start\":68415},{\"end\":68431,\"start\":68422},{\"end\":68439,\"start\":68435}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1602.05629\",\"id\":\"b0\"},\"end\":55849,\"start\":55534},{\"attributes\":{\"id\":\"b1\"},\"end\":56134,\"start\":55851},{\"attributes\":{\"doi\":\"arXiv:1812.02903\",\"id\":\"b2\"},\"end\":56347,\"start\":56136},{\"attributes\":{\"doi\":\"arXiv:2003.09288\",\"id\":\"b3\"},\"end\":56654,\"start\":56349},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":227232157},\"end\":56936,\"start\":56656},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":236719460},\"end\":57371,\"start\":56938},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":127053789},\"end\":57753,\"start\":57373},{\"attributes\":{\"doi\":\"arXiv:1610.02527\",\"id\":\"b7\"},\"end\":58061,\"start\":57755},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":14955348},\"end\":58440,\"start\":58063},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":59553531},\"end\":58676,\"start\":58442},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":168170092},\"end\":59056,\"start\":58678},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":211204935},\"end\":59458,\"start\":59058},{\"attributes\":{\"doi\":\"arXiv:2011.03248\",\"id\":\"b12\"},\"end\":59731,\"start\":59460},{\"attributes\":{\"doi\":\"arXiv:2012.04187\",\"id\":\"b13\"},\"end\":60024,\"start\":59733},{\"attributes\":{\"doi\":\"arXiv:2104.07145\",\"id\":\"b14\"},\"end\":60253,\"start\":60026},{\"attributes\":{\"doi\":\"arXiv:2005.11903\",\"id\":\"b15\"},\"end\":60496,\"start\":60255},{\"attributes\":{\"doi\":\"arXiv:2106.11593\",\"id\":\"b16\"},\"end\":60770,\"start\":60498},{\"attributes\":{\"doi\":\"arXiv:2102.04925\",\"id\":\"b17\"},\"end\":61052,\"start\":60772},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":5051282},\"end\":61406,\"start\":61054},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":133091488},\"end\":61892,\"start\":61408},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":195316471},\"end\":62100,\"start\":61894},{\"attributes\":{\"doi\":\"arXiv:2010.10152\",\"id\":\"b21\"},\"end\":62372,\"start\":62102},{\"attributes\":{\"doi\":\"arXiv:2104.14383\",\"id\":\"b22\"},\"end\":62575,\"start\":62374},{\"attributes\":{\"doi\":\"arXiv:2102.08504\",\"id\":\"b23\"},\"end\":62758,\"start\":62577},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":236232571},\"end\":63169,\"start\":62760},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":245542038},\"end\":63583,\"start\":63171},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":29169801},\"end\":63898,\"start\":63585},{\"attributes\":{\"doi\":\"arXiv:1806.02371\",\"id\":\"b27\"},\"end\":64053,\"start\":63900},{\"attributes\":{\"doi\":\"arXiv:1809.02797\",\"id\":\"b28\"},\"end\":64282,\"start\":64055},{\"attributes\":{\"doi\":\"arXiv:1903.01610\",\"id\":\"b29\"},\"end\":64591,\"start\":64284},{\"attributes\":{\"doi\":\"10.1109/TKDE.2021.3078755\",\"id\":\"b30\",\"matched_paper_id\":221534624},\"end\":64933,\"start\":64593},{\"attributes\":{\"doi\":\"arXiv:1810.10751\",\"id\":\"b31\"},\"end\":65190,\"start\":64935},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":202539492},\"end\":65494,\"start\":65192},{\"attributes\":{\"doi\":\"arXiv:1906.03750\",\"id\":\"b33\"},\"end\":65724,\"start\":65496},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":53145065},\"end\":65939,\"start\":65726},{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b35\"},\"end\":66158,\"start\":65941},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":349242},\"end\":66459,\"start\":66160},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":8895676},\"end\":66820,\"start\":66461},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":62016134},\"end\":67100,\"start\":66822},{\"attributes\":{\"doi\":\"arXiv:1609.02907\",\"id\":\"b39\"},\"end\":67323,\"start\":67102},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":67752026},\"end\":67633,\"start\":67325},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":196215305},\"end\":68044,\"start\":67635},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":2887752},\"end\":68317,\"start\":68046},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":214623066},\"end\":68748,\"start\":68319}]", "bib_title": "[{\"end\":55903,\"start\":55851},{\"end\":56691,\"start\":56656},{\"end\":57053,\"start\":56938},{\"end\":57447,\"start\":57373},{\"end\":58136,\"start\":58063},{\"end\":58469,\"start\":58442},{\"end\":58738,\"start\":58678},{\"end\":59133,\"start\":59058},{\"end\":61133,\"start\":61054},{\"end\":61546,\"start\":61408},{\"end\":61921,\"start\":61894},{\"end\":62851,\"start\":62760},{\"end\":63251,\"start\":63171},{\"end\":63638,\"start\":63585},{\"end\":64632,\"start\":64593},{\"end\":65277,\"start\":65192},{\"end\":65766,\"start\":65726},{\"end\":66229,\"start\":66160},{\"end\":66532,\"start\":66461},{\"end\":66863,\"start\":66822},{\"end\":67365,\"start\":67325},{\"end\":67698,\"start\":67635},{\"end\":68087,\"start\":68046},{\"end\":68404,\"start\":68319}]", "bib_author": "[{\"end\":55622,\"start\":55609},{\"end\":55631,\"start\":55622},{\"end\":55641,\"start\":55631},{\"end\":55652,\"start\":55641},{\"end\":55665,\"start\":55652},{\"end\":55913,\"start\":55905},{\"end\":55920,\"start\":55913},{\"end\":55928,\"start\":55920},{\"end\":55936,\"start\":55928},{\"end\":56217,\"start\":56209},{\"end\":56439,\"start\":56433},{\"end\":56445,\"start\":56439},{\"end\":56451,\"start\":56445},{\"end\":56457,\"start\":56451},{\"end\":56466,\"start\":56457},{\"end\":56473,\"start\":56466},{\"end\":56701,\"start\":56693},{\"end\":56708,\"start\":56701},{\"end\":56717,\"start\":56708},{\"end\":56726,\"start\":56717},{\"end\":57069,\"start\":57055},{\"end\":57081,\"start\":57069},{\"end\":57089,\"start\":57081},{\"end\":57461,\"start\":57449},{\"end\":57475,\"start\":57461},{\"end\":57485,\"start\":57475},{\"end\":57847,\"start\":57836},{\"end\":57860,\"start\":57847},{\"end\":57870,\"start\":57860},{\"end\":57883,\"start\":57870},{\"end\":58149,\"start\":58138},{\"end\":58158,\"start\":58149},{\"end\":58168,\"start\":58158},{\"end\":58179,\"start\":58168},{\"end\":58192,\"start\":58179},{\"end\":58480,\"start\":58471},{\"end\":58489,\"start\":58480},{\"end\":58501,\"start\":58489},{\"end\":58753,\"start\":58740},{\"end\":58764,\"start\":58753},{\"end\":58773,\"start\":58764},{\"end\":58787,\"start\":58773},{\"end\":58796,\"start\":58787},{\"end\":58808,\"start\":58796},{\"end\":59148,\"start\":59135},{\"end\":59165,\"start\":59148},{\"end\":59174,\"start\":59165},{\"end\":59529,\"start\":59520},{\"end\":59537,\"start\":59529},{\"end\":59545,\"start\":59537},{\"end\":59551,\"start\":59545},{\"end\":59559,\"start\":59551},{\"end\":59568,\"start\":59559},{\"end\":59832,\"start\":59824},{\"end\":59838,\"start\":59832},{\"end\":59844,\"start\":59838},{\"end\":59852,\"start\":59844},{\"end\":60113,\"start\":60107},{\"end\":60348,\"start\":60340},{\"end\":60577,\"start\":60571},{\"end\":60583,\"start\":60577},{\"end\":60590,\"start\":60583},{\"end\":60598,\"start\":60590},{\"end\":60606,\"start\":60598},{\"end\":60856,\"start\":60850},{\"end\":60862,\"start\":60856},{\"end\":60869,\"start\":60862},{\"end\":60878,\"start\":60869},{\"end\":60885,\"start\":60878},{\"end\":61144,\"start\":61135},{\"end\":61156,\"start\":61144},{\"end\":61170,\"start\":61156},{\"end\":61556,\"start\":61548},{\"end\":61566,\"start\":61556},{\"end\":61580,\"start\":61566},{\"end\":61930,\"start\":61923},{\"end\":61937,\"start\":61930},{\"end\":62187,\"start\":62180},{\"end\":62193,\"start\":62187},{\"end\":62201,\"start\":62193},{\"end\":62210,\"start\":62201},{\"end\":62448,\"start\":62439},{\"end\":62641,\"start\":62635},{\"end\":62863,\"start\":62853},{\"end\":62875,\"start\":62863},{\"end\":62886,\"start\":62875},{\"end\":62894,\"start\":62886},{\"end\":62908,\"start\":62894},{\"end\":63262,\"start\":63253},{\"end\":63273,\"start\":63262},{\"end\":63287,\"start\":63273},{\"end\":63650,\"start\":63640},{\"end\":63664,\"start\":63650},{\"end\":63677,\"start\":63664},{\"end\":63952,\"start\":63945},{\"end\":64106,\"start\":64098},{\"end\":64112,\"start\":64106},{\"end\":64118,\"start\":64112},{\"end\":64126,\"start\":64118},{\"end\":64135,\"start\":64126},{\"end\":64143,\"start\":64135},{\"end\":64365,\"start\":64359},{\"end\":64373,\"start\":64365},{\"end\":64387,\"start\":64373},{\"end\":64399,\"start\":64387},{\"end\":64405,\"start\":64399},{\"end\":64412,\"start\":64405},{\"end\":64640,\"start\":64634},{\"end\":64647,\"start\":64640},{\"end\":64656,\"start\":64647},{\"end\":64663,\"start\":64656},{\"end\":64669,\"start\":64663},{\"end\":64678,\"start\":64669},{\"end\":65001,\"start\":64993},{\"end\":65010,\"start\":65001},{\"end\":65019,\"start\":65010},{\"end\":65031,\"start\":65019},{\"end\":65037,\"start\":65031},{\"end\":65288,\"start\":65279},{\"end\":65555,\"start\":65549},{\"end\":65563,\"start\":65555},{\"end\":65571,\"start\":65563},{\"end\":65577,\"start\":65571},{\"end\":65585,\"start\":65577},{\"end\":65776,\"start\":65768},{\"end\":66005,\"start\":65989},{\"end\":66015,\"start\":66005},{\"end\":66026,\"start\":66015},{\"end\":66245,\"start\":66231},{\"end\":66254,\"start\":66245},{\"end\":66264,\"start\":66254},{\"end\":66275,\"start\":66264},{\"end\":66546,\"start\":66534},{\"end\":66556,\"start\":66546},{\"end\":66872,\"start\":66865},{\"end\":66882,\"start\":66872},{\"end\":66892,\"start\":66882},{\"end\":66902,\"start\":66892},{\"end\":66915,\"start\":66902},{\"end\":66930,\"start\":66915},{\"end\":67178,\"start\":67168},{\"end\":67189,\"start\":67178},{\"end\":67373,\"start\":67367},{\"end\":67382,\"start\":67373},{\"end\":67391,\"start\":67382},{\"end\":67400,\"start\":67391},{\"end\":67406,\"start\":67400},{\"end\":67420,\"start\":67406},{\"end\":67707,\"start\":67700},{\"end\":67716,\"start\":67707},{\"end\":67723,\"start\":67716},{\"end\":67730,\"start\":67723},{\"end\":68098,\"start\":68089},{\"end\":68413,\"start\":68406},{\"end\":68420,\"start\":68413},{\"end\":68433,\"start\":68420},{\"end\":68441,\"start\":68433}]", "bib_venue": "[{\"end\":55607,\"start\":55534},{\"end\":55968,\"start\":55936},{\"end\":56207,\"start\":56136},{\"end\":56431,\"start\":56349},{\"end\":56758,\"start\":56726},{\"end\":57131,\"start\":57089},{\"end\":57531,\"start\":57485},{\"end\":57834,\"start\":57755},{\"end\":58220,\"start\":58192},{\"end\":58529,\"start\":58501},{\"end\":58836,\"start\":58808},{\"end\":59218,\"start\":59174},{\"end\":59518,\"start\":59460},{\"end\":59822,\"start\":59733},{\"end\":60105,\"start\":60026},{\"end\":60338,\"start\":60255},{\"end\":60569,\"start\":60498},{\"end\":60848,\"start\":60772},{\"end\":61191,\"start\":61170},{\"end\":61616,\"start\":61580},{\"end\":61955,\"start\":61937},{\"end\":62178,\"start\":62102},{\"end\":62437,\"start\":62374},{\"end\":62633,\"start\":62577},{\"end\":62935,\"start\":62908},{\"end\":63336,\"start\":63287},{\"end\":63703,\"start\":63677},{\"end\":63943,\"start\":63900},{\"end\":64096,\"start\":64055},{\"end\":64357,\"start\":64284},{\"end\":64745,\"start\":64703},{\"end\":64991,\"start\":64935},{\"end\":65303,\"start\":65288},{\"end\":65547,\"start\":65496},{\"end\":65805,\"start\":65776},{\"end\":65987,\"start\":65941},{\"end\":66284,\"start\":66275},{\"end\":66604,\"start\":66556},{\"end\":66936,\"start\":66930},{\"end\":67166,\"start\":67102},{\"end\":67448,\"start\":67420},{\"end\":67791,\"start\":67730},{\"end\":68141,\"start\":68098},{\"end\":68471,\"start\":68441},{\"end\":56771,\"start\":56760},{\"end\":58244,\"start\":58222},{\"end\":58553,\"start\":58531},{\"end\":58860,\"start\":58838},{\"end\":59258,\"start\":59220},{\"end\":61208,\"start\":61193},{\"end\":61648,\"start\":61618},{\"end\":61974,\"start\":61957},{\"end\":63381,\"start\":63338},{\"end\":63725,\"start\":63705},{\"end\":65314,\"start\":65305},{\"end\":66648,\"start\":66606},{\"end\":67472,\"start\":67450},{\"end\":67848,\"start\":67793},{\"end\":68180,\"start\":68143},{\"end\":68514,\"start\":68473}]"}}}, "year": 2023, "month": 12, "day": 17}