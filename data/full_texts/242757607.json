{"id": 242757607, "updated": "2023-10-05 20:02:42.051", "metadata": {"title": "SZ3: A Modular Framework for Composing Prediction-Based Error-Bounded Lossy Compressors", "authors": "[{\"first\":\"Xin\",\"last\":\"Liang\",\"middle\":[]},{\"first\":\"Kai\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Sheng\",\"last\":\"Di\",\"middle\":[]},{\"first\":\"Sihuan\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Robert\",\"last\":\"Underwood\",\"middle\":[]},{\"first\":\"Ali\",\"last\":\"Gok\",\"middle\":[\"M.\"]},{\"first\":\"Jiannan\",\"last\":\"Tian\",\"middle\":[]},{\"first\":\"Junjing\",\"last\":\"Deng\",\"middle\":[]},{\"first\":\"Jon\",\"last\":\"Calhoun\",\"middle\":[\"C.\"]},{\"first\":\"Dingwen\",\"last\":\"Tao\",\"middle\":[]},{\"first\":\"Zizhong\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Franck\",\"last\":\"Cappello\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2021, "month": 11, "day": 4}, "abstract": "Today's scientific simulations require a significant reduction of data volume because of extremely large amounts of data they produce and the limited I/O bandwidth and storage space. Error-bounded lossy compressor has been considered one of the most effective solutions to the above problem. In practice, however, the best-fit compression method often needs to be customized/optimized in particular because of diverse characteristics in different datasets and various user requirements on the compression quality and performance. In this paper, we develop a novel modular, composable compression framework (namely SZ3), which involves three significant contributions. (1) SZ3 features a modular abstraction for the prediction-based compression framework such that the new compression modules can be plugged in easily. (2) SZ3 supports multialgorithm predictors and can automatically select the best-fit predictor for each data block based on the designed error estimation criterion. (3) SZ3 allows users to easily compose different compression pipelines on demand, such that both compression quality and performance can be significantly improved for their specific datasets and requirements. (4) In addition, we evaluate several lossy compressors composed from SZ3 using the real-world datasets. Specifically, we leverage SZ3 to improve the compression quality and performance for different use-cases, including GAMESS quantum chemistry dataset and Advanced Photon Source (APS) instrument dataset. Experiments show that our customized compression pipelines lead to up to 20% improvement in compression ratios under the same data distortion compared with the state-of-the-art approaches.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2111.02925", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tbd/LiangZDLUGTDCTCC23", "doi": "10.1109/tbdata.2022.3201176"}}, "content": {"source": {"pdf_hash": "125e5cf6199dfdef770fe0f4b258aab01e5e8aa9", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2111.02925v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "be7c577cf3357c2c58f3b0207936f905c40ea468", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/125e5cf6199dfdef770fe0f4b258aab01e5e8aa9.txt", "contents": "\nSZ3: A Modular Framework for Composing Prediction-Based Error-Bounded Lossy Compressors\nAUGUST 2015\n\nJournal Of L A T E X Class \nFiles \nSZ3: A Modular Framework for Composing Prediction-Based Error-Bounded Lossy Compressors\n148AUGUST 20151Index Terms-Big DataError-Bounded Lossy CompressionData ReductionLarge-Scale Scientific Simulation !\nToday's scientific simulations require a significant reduction of data volume because of extremely large amounts of data they produce and the limited I/O bandwidth and storage space. Error-bounded lossy compression has been considered one of the most effective solutions to the above problem. In practice, however, the best-fit compression method often needs to be customized or optimized in particular because of diverse characteristics in different datasets and various user requirements on the compression quality and performance. In this paper, we address this issue with a novel modular, composable compression framework named SZ3. Our contributions are four-folds. (1) We develop SZ3 which features an innovative modular abstraction for the prediction-based compression framework, such that compression modules can be plugged in easily to create new compressors based on characteristics of data and user requirements. (2) We create a new compression pipeline by SZ3 for GAMESS data, which significantly improves the compression ratios over state-of-the-art compressors.(3)We develop an adaptive compression pipeline by SZ3 for APS data with minimal efforts, which leads to the best rate-distortion among all existing error-bounded lossy compressors for any bit-rate. (4) We compare the sustainability of SZ3 with leading error-controlled prediction-based compressors, and then demonstrate the necessity of diverse pipelines by integrating and evaluating several compression pipelines on diverse scientific datasets from multiple disciplines. Experiments show that SZ3 incurs very limited overhead in compressor integration and our customized compression pipelines lead to up to 20% improvement in compression ratios under the same data distortion, when compared with the best existing approach.\n\nINTRODUCTION\n\nD ATA reduction is becoming increasingly important to scientific research because of the large amount of data produced by simulations running on exascale computing systems and experiments conducted on advanced instru-ments. For instance, recent climate research, which performs climate simulation in 1 km\u00d71 km resolution, generates 260 TB of floating-point data every 16 seconds [1]. When the generated data are dumped into parallel file systems or secondary storage systems to ensure long-term access, the limited storage capacity and/or I/O bandwidth will impose great challenges. While scientists aim to significantly reduce the size of their data to mitigate this problem, they are also concerned about the quality of data reduction. General data reduction approaches, including traditional wavelet-based methods [2], [3] and emerging neural-network-based methods [4], [5] widely used in the image processing community, may lead to loss of important scientific insights as they do not enforce quantifiable error bounds on reconstructed data.\n\nOver the past decade, error-bounded lossy compression [6], [7], [8], [9], [10], [11], [12], [13], [14], [15] has been proposed and employed to reduce scientific data while controlling the distortion. Depending on how the original data are decorrelated, existing compressors can be classified into prediction-based and transform-based. These compressors all allow users to specify an error bound during compression and ensure that the error between original and decompressed data is strictly than the bound. In this paper we focus mainly on prediction-based approaches because transformed-based approaches can be formulated to prediction-based ones by using the corresponding transforms as predictors (at the cost of certain speed degradation), as suggested by prior works [16].\n\n\narXiv:2111.02925v2 [cs.DC] 12 Nov 2021\n\nAlthough existing prediction-based approaches such as SZ [6], [7], [8] are general and can be applied to various scenarios, they may not lead to the best quality and performance given a specific dataset or error bound requirement. The best-fit compression method is never universal, which is true even for the same dataset because the compression efficiency would be affected by the required error bounds as well. For instance, SZ-1.4 [7] with a Lorenzo predictor shows very good compression ratios with low error bounds, but it suffers from low quality and artifacts with high error bounds, where approaches with a regression-based predictor [8] or an interpolation-based predictor [17] have been proved to be much more efficient. Likewise, data generated by the GAMESS quantum chemistry package [18] exhibits periodic scaled patterns, where a pattern-based predictor demonstrates obvious improvements in both compression speed and ratios [19]. Thus, a loosely coupled compression framework that allows for customization of the predictionbased error-bounded lossy compression model is critical to optimizing the compression quality and performance for users in practice.\n\nIn this paper, we present a modular and composable framework-SZ3-which can be used to easily create new error-bounded lossy compressors on demand. SZ3 features a modular abstraction for the prediction-based compression pipelines such that modules can be developed and adopted independently. Specifically, users can customize any stages in the compression pipeline, including preprocessing, prediction, quantization, encoding, and lossless compression, via carefully designed modules. Based on these customized modules, SZ3 allows users to compose their own compressors (or compression pipelines) to adapt to diverse data characteristics and requirements, thus achieving high compression quality and performance with minimal effort. Such a composable design is able to provide a variety of useful supports, including point-wise relative error bounds (logarithmic transform-based preprocessor [20]), featurepreserving compression (element-wise quantizer [21]), and speed-ratio tradeoffs (module bypass). Although designed for data in Cartesian grids, SZ3 can also work with data in unstructured grids by applying a linearization which rearranges data to a one-dimensional array.\n\nWe summarize our contributions as follows. \u2022 We carefully design and develop SZ3, a flexible, efficient framework that allows easy creation and customization of prediction-based error-bounded lossy compressors. This work is critical to obtaining high data compression quality because of diverse scientific data characteristics and user requirmeents in practice. \u2022 We develop a new compressor using SZ3 for data generated from GAMESS quantum chemistry package. By substituting the default quantizer with a specialized one and augmenting a lossless compression stage, the composed compressor achieves better performance than current state of the art with minimal effort. \u2022 We develop an efficient compressor using SZ3 for data collected from Advanced Photon Source instruments. By incorporating an adaptive pipeline with existing modules, the composed compressor leads to the best rate-distortion under any bit rate. \u2022 We compare the sustainability of SZ3 with leading prediction-based compressors, and then integrate several compression pipelines to demonstrate the necessity of diverse pipelines. The performance and efficiency are carefully characterized using diverse scientific datasets across multiple domains. The rest of the paper is organized as follows. In Section 2 we discuss related work. In Section 3 we present the design and modules of SZ3 framework. In Section 4 and Section 5 we describe how we leverage the proposed framework to create efficient compressors for GAMESS and APS data in details. In Section 6 we present the comparison on sustainability and evaluation for diverse pipelines. In Section 7 we conclude with a vision of future work.\n\n\nRELATED WORK\n\nWith more powerful high-performance computing (HPC) systems and high-resolution instruments, the volume and generation speed of scientific data have been experiencing an unprecedented increase in recent years, causing problems in data storage, transmission, and analysis. Compared with the fast evolution of computing resources, the I/O systems are heavily underdeveloped, remaining a bottleneck in most scenarios. Data compression is regarded as a direct way to mitigate such a bottleneck, and many approaches have been presented in the literature to address this issue.\n\nLossless compressors [22], [23], [24], [25], [26] ensure that no information is lost during the compression. Despite their success in many fields, lossless compressors suffer from low compression ratios on floating-point scientific data due to the almost randomly distributed mantissas. Previous work [27] has shown that state-of-the-art lossless compressors can lead to a compression ratio of only 2 when directly applied to most floating-point scientific datasets, whereas scientific applications usually require over 10\u00d7 reduction on their data [28].\n\nLossy compressors [2], [3], [4], [5], [29], [30] offer the flexibility to trade off data quality for high compression ratios, but they may result in a higher distortion than users' expectation. The unbounded distortion may result in unexpected behaviors in post hoc data analytics and even false discoveries, leaving risks in trusting the analysis results on the decompressed data.\n\nIn comparison with traditional lossy compression, errorbounded lossy compression has been rapidly developed to fill the gap by reducing the size of scientific data while guaranteeing quantifiable error bounds. Prediction-based and transform-based models are the most popular models for designing error-bounded lossy compressors. One of the most well-known transform-based error-bounded lossy compressors is ZFP [10], which decorrelates the data using a near-orthogonal transform and encodes the transformed coefficients using embedded encoding. MGARD [12], [13], [14] is another compressor relying on the transform-based model. It leverages wavelet theories and L 2 projection for data decorrelation, followed by linear-scaling quantization, variable-length encoding, and lossless compression.\n\nAccording to recent studies [31], SZ [6], [7], [8] is regarded as one of the leading prediction-based lossy compressor in the scientific computing community. SZ follows a 4-step pipeline to perform the compression, namely data prediction, quantization, Huffman encoding, and lossless compression. Significant efforts have been made to enable new features or functionalities based on this pipeline. For instance, in [20], a logarithmic transform was used in a preprocessing step to change a pointwise-relative-error-bound compression problem to an absolute-error-bound compression problem, which is then solved by the SZ compression pipeline. In [21], the authors derived the element-wise error bounds based on how critical points are extracted, and they leveraged the SZ compression pipeline along with elementwise quantization to ensure that those critical points are preserved in the decompressed data. In [19], the authors adjusted the pipeline by using a pattern-based predictor to better exploit the correlation in data and a predefined fixed Huffman tree for faster encoding. Attempts were also made to use the near-orthogonal transform in ZFP as a predictor in the pipeline [16]. All the above works, however, are developed within a tightly-coupled design, so that the compression pipelines cannot be adjusted on demand, which thus cannot adapt to user's diverse requirements or different use-cases in turn. By contrast, the SZ3 framework offers a breakthrough, flexible, modular framework, which can be leveraged to adapt to diverse use-cases very efficiently.\n\nAlthough many efforts have been spent on abstracting lossy compression, most of them are focused on enabling an adaptive selection of existing compressors. For instance, SCIL [32] attempts to abstract across compressors and acts as a metacompressor that provides backends to various existing algorithms. LibPressio [33] provides a common API for different compressors to allow for easy integration of lossy compression in an extensible fashion. Instead, SZ3 separates and abstracts stages in the prediction-based compression model, allowing for easy creation of new compressors in fine granularity rather than selection of existing ones. To the best of our knowledge, this is the first attempt to build a generic framework that allows users to easily customize their own compressors based on their actual needs.\n\n\nSZ3: A MODULAR COMPRESSION FRAMEWORK\n\nIn this section we introduce the design and implementation of SZ3. With modularity in mind, SZ3 enables easy customization of prediction-based compression pipelines with minimal overhead. Figure 1 illustrates the design overview of SZ3. The compression process is abstracted into five stages (displayed as the dotted boxes), each of which serves as an individual module. Orange boxes depict the key functionalities of each module and green boxes illustrate several corresponding instances. A compressor is realized by identifying a compression pipeline which is composed by instances from each module. This figure demonstrates how five leading compressors designed for different purposes, namely FPZIP [11], SZ1.4 [7], SZ2 [8], SZ-Pastri [19], and cpSZ [21], are composed using this abstraction (see the solid lines), which shows the generality of the abstraction. For instance, the FPZIP compression pipeline bypasses the precessor and leverages Lorenzo predictor for data decorrelation, followed by residual encoding to ensure error control and arithmetic encoding for size reduction. In the following text we will detail the modular design in SZ3, along with example instances of the modules.\n\n\nDesign overview\n\n\nModularity\n\nIn this section we discuss the five modules in SZ3, namely preprocessor, predictor, quantizer, encoder, and lossless compressor, with module instances that have proven to be effective for scientific datasets. Developers can write their own module instances and plug them in the compression pipeline to design prediction-based error-bounded lossy compression for their dataset. Due to space limitation, we present only the most important functions and several representative instances for each module. Detailed interfaces for each module are listed in Appendix A.\n\nPreprocessor (see Appendix A.1): The preprocessor is used to process the input dataset for achieving high efficiency or diverse requirements before performing the actual compression. The key function in the preprocessor, namely preprocess, takes in original data and compression configuration as input, and then transforms the data in an in-place fashion and change the compression configuration accordingly. If users want to keep original data while the preprocessor needs to alter the data, a separate buffer is required to perform the preprocessing. Based on the actual design, the postprocess function either reverses the preprocessing procedure or is omitted.\n\nInstances: A typical preprocessor for error-controlled lossy compressors is the logarithmic transform used to enable point-wise relative error bounds [20], where data are transformed to the logarithmic domain and compressed with an absolute error bound transformed from the pointwise relative one. Besides, SZ-Pastri [19] requires a preprocessing step to identify the proper parameters, such as block size and pattern size, for the pattern-based predictor. In Section 5, we further leverage a preprocessor to alter the layout of data for better compression ratio. This is based on our observations that some 3D datasets will have a better compression ratio when treated as a 2D or 1D dataset (as will be detailed later).\n\nPredictor (see Appendix A.2): Predictors are the key components of prediction-based compressors, which perform value prediction based on diverse patterns for data decorrelation. There are two important functions in the predictor interface, namely predict and save/load. The predict function outputs the predicted value based on the characteristics of the underlying predictor using the multidimensional iterator (to be detailed in Section 6.1). Necessary information about the predictor, for instance the coefficients of the regression predictor [8], [9], will be recorded in the save function. During decompression, load function will be invoked to reconstruct the predictor.\n\nInstances: Lorenzo predictor [34] and its high order variations [7], which perform multidimensional prediction for each data point based on its neighbor data points, are classic and powerful prediction methods used in lossy compressors such as SZ [7] and FPZIP [11]. In [8], a regression-based predictor is proposed to construct a hyperplane and uses points on the hyperplane as predicted values, which significantly  improves the prediction efficiency when user-specified error bound is high. We further implement a composite predictor instance inherited from this interface, which may consist of multiple predictors using different prediction algorithms. This requires an error estimation function for each predictor, which will be used to determine the best-fit predictor for a given data chunk. The statistical approach in [8] and [15] is generalized as the estimation criterion in SZ3. With the composite predictor, multialgorithm designs with more than one predictors can be implemented very easily.\n\n\nQuantizer (see Appendix A.3):\n\nThe quantizer is used to approximate prediction errors generated by the predictors with a smaller countable set to reduce their entropy while respecting the error bound. As the only module that introduces errors in the compression pipeline, quantizer determines how the final errors in the decompressed data are controlled. The quantize function is the most important function in a quantizer, where the prediction error is quantized based on the original data value and its predicted value from the predictor. During decompression, the decompressed data value is computed by the recover function, which reverses the steps in the quantize function. The quantizer module is also responsible for encoding/decoding the unpredictable data, i.e., data fall out of the countable set. This is realized in the save/load function.\n\nInstances: Linear-scaling quantizer [7] is a widely used quantizer to enable absolute error control in lossy compression. In particular, this quantizer constructs a set of equalsized consecutive bins each with twice the error bound in length. Then, the prediction error will be translated into the index of the bin containing it. Prediction errors that fall out of range are regarded as unpredictable and will be encoded and stored separately. Besides, log-scale quantizer [35] is used to adjust the size of bins for a more centralized error distribution and element-wise quantizer [21] is used to provide fine-granularity error control for each data point.\n\n\nEncoder (see Appendix A.4):\n\nEncoder is a lossless scheme to reduce the storage of integer indices (or symbols) generated by quantizers. The encoder module involves two essential functions-encode and save/load. The encode function transforms the quantized integers from the quantizer to compressed binary formats; similar to other modules, the encoder module has a decode function which performs the reverse process during decompression. This module also has save/load functions for storing/recovering metadata such as the Huffman tree.\n\nInstances: Huffman encoder [36] is a classic variablelength encoding algorithm that uses fewer bits to represent more common symbols. This encoder first constructs a Huffman tree based on the frequency of input data using a greedy algorithm, generates codebook according to the tree, and then compress the data using the codebook. The fixed Huffman encoder used in SZ-Pastri [19] is a variation of the Huffman encoder, which uses a predefined Huffman tree instead of constructing one on the fly to eliminate the cost for both construction and storage of the tree. Arithmetic encoder is another type of encoder widely used in data compression, which represents current information as range and encodes the entire data into a single number.\n\n\nLossless Compressor (see Appendix A.5):\n\nLossless compressors are used to further shrink the size of compressed binary formats produced by the encoders, because the entropy-based encoders may overlook repeated patterns in the data thus lead to suboptimal compression ratios. The lossless compressor module in SZ3 acts mainly as a proxy of state-of-the-art lossless compression libraries. This module invokes external libraries to compress the output from the encoder module with compress and decompress interfaces.\n\nInstances: We provide portable interfaces in SZ3 to integrate with state-of-the-art lossless compressors including ZSTD [23], GZIP [22], and BLOSC [26]. Because lossless compressor is a standlone module attached to the previous stages, it would be fairly easy to include and integrate new lossless compression routines as well.\n\n\nCompression pipeline composition\n\nIn SZ3, a compression pipeline can be composed by identifying the instances of modules and putting them together. Algorithm 1 shows how a general-purpose error-controlled lossy compressor is composed using the selected preprocessor, predictor, quantizer, encoder, and lossless compressor. In addition, SZ3 employs compile time polymorphism (see Section 6.1) such that users can switch the instances without bothering to modify the compression functions. This makes SZ3 highly adaptive to diverse use cases, with significantly reduced efforts on compressor development.\n\n\nAlgorithm 1 A GENERAL COMPRESSOR IN SZ3\n\nInput: input data d of size n, compression configuration conf Output: compressed data cc 1: preprocessor.process(d, conf ) /*perform preprocessing*/ 2:\nfor i = 1 \u2192 n do 3: p \u2190 predictor.predict(d[i]) /*perform prediction*/ 4: q[i] \u2190 quantizer.quantize(d[i]\n, p) /*perform quantization*/ 5: end for 6: c \u2190 allocate_memory() 7: predictor.save(c) /*save predictor*/ 8: quantizer.save(c) /*save quantizer*/ 9: encoder.encode(q, c) /*perform encoding*/ 10: encoder.save(c) /*save encoder*/ 11: cc \u2190 lossless compressor.compress(c) /*perform lossless compression*/ 12: return cc\n\n\nDEVELOPING AN EFFICIENT COMPRESSOR FOR GAMESS DATA USING SZ3\n\nIn this section, we present how we create a new compressor using SZ3, which can improve the compression ratios for the data generated from the real-world scientific simulation GAMESS [18]. In the following text, we first introduce the GAMESS data and its current compressor -SZ-Pastri [19], and then present our characterization on the quanzation integers and the new customization method. At last, we evaluate the compression ratios and speed based on three representative data fields in GAMESS.\n\n\nGAMESS data and SZ-Pastri Compressor\n\nQuantum chemistry researchers often need to obtain a wavefunction by solving the Schr\u00f6dinger differential equation, which involves all the chemical system's information. The wavefunction needs to be constructed by twoelectron repulsion integrals (ERI), which requires too large a memory capacity to hold at runtime during the simulation. A straightforward solution is reproducing the ERI dataset whenever needed during the simulation, although this would significantly delay the simulation because of the fairly expensive cost in generating the ERI data. In our prior work, we developed an efficient error-bounded lossy compressor called SZ-Pastri [19], which can compress the ERI data in memory and decompress it in the beginning of each iteration of the simulation. Such a method can effectively avoid the ERI recalculation cost, so as to improve the overall performance. SZ-Pastri takes advantages of the periodic patterns that exist in the GAMESS dataset, because the ERI values are calculated in order and are dependent on shape and distance of electron clouds. Specifically, SZ-Pastri identifies a periodic pattern and uses it along with a scaling coefficient for each block to enable accurate data prediction. This leads to substantial performance gain compared to existing general compressors [8], [10].\n\n\nData characterization and pipeline customization\n\nWe first characterize the quantization integers for SZ-Pastri, which are the most impactful factors for the final compression ratios. To enable correct decompression, SZ-Pastri needs to quantize and store the information for both the periodic patterns and block-wise scales. Thus, the quantization integers in SZ-Pastri consist of three components, which are computed from data, patterns, and scales, respectively. As displayed in Figure 3(a), the distribution of quantization integers for the pattern-based predictor is centered in 0, which indicates very high prediction accuracy and thus better compression ratios. However, a significant percentage (20% for data) of the quantization integers fall out of the quantization range (64 in this setting). These data, usually described as unpredictable, require additional mechanisms for storage in order to be correctly recovered during decompression. In SZ-Pastri, they are directly truncated and stored based on the user-specified error, which fails to exploit the correlation in the data to achieve high compression, although relatively fast compression speed is provided.  Based on these observations, we improve the compression efficiency of SZ-Pastri by leveraging a specialized quantizer to deal with the unpredictable data. Inspired by the embedded encoding approaches widely used in transformbased compressors [10], [37], we store data in the order of bitplane instead of applying the truncation directly. A bitplane represents a set of bits corresponding to a given bit position in the binary representations of the data. Because small data values have meaningful bits only in less significant bitplanes, the relatively significant bitplanes will yield good compression ratios because of consecutive 0s. Similar to [10], we first align the exponents of the prediction difference on unpredictable data to that of the error bound to convert the floating-point data into integers. These integers are then recorded in the order of bitplanes, namely, from the most significant bitplane to the least significant bitplane. Compared with direct truncation, this encoding method will not change the encoded size at this stage; however, its compressive encoded format will promise better compression ratios when lossless compression is adopted. Since this quantizer takes special care of unpredictable data storage, we name it Unpred-aware Quantizer throughput the paper. To take advantage of this method, we also add a lossless stage to the composed compression pipeline, as displayed in Figure 2. This new compressor is called SZ3-Pastri, as it optimizes SZ-Pastri using the SZ3 framework.\n\n\nEvaluation results\n\nWe evaluate our method and compare it with SZ-Pastri and its variation (SZ-Pastri equipped with lossless compression) using three representative fields in GAMESS. Unless otherwise noted, all the experiments in this paper are conducted on the Bebop supercomputer [38] at Argonne National Laboratory. Bebop has 664 Broadwell nodes, each of which is equipped with two Intel Xeon E5-2695v4 processors containing 36 physical cores in total and 128 GB of DDL4 memory.\n\nThe rate-distortion graphs of the evaluation are displayed in Figure 4. This graph entails the correlation between bit rate and Peak Signal-to-Noise Ratio (PSNR). The bit rate equals bits/cr where bits is number of bit in original data representation (e.g., 32 for single-precision and 64 for double-precision floating-point data) and cr is the compression ratio. PSNR is inversely proportional to the mean square error of decompress data and original data in logarithmic scale. Lower bit rate and higher PSNR indicate better compression quality. According to this figure, SZ3-Pastri leads to the best rate-distortion along almost all bit rates. For example, the improvements of compression ratios on the f f |f f dataset are generally 40% and 20%, respectively, compared with SZ-Pastri and its lossless variation. We also show the exact compression ratio and speed of the three approaches under the desired absolute error tolerance (1E-10 according to the domain scientists) in Table 1. Compared with original SZ-Pastri, SZ3-Pastri significantly improves the compression ratios under the requirements. However, it has a degradation in performance, which is caused by the embedded encoding on unpredictable data (i.e., unpredaware Quantizer, which improves the compression ratio) and the final lossless compression. \n\n\nCOMPOSING AN EFFICIENT COMPRESSOR FOR APS DATA USING SZ3\n\nWe then leverage our SZ3 framework to create an adaptive compression pipeline for the X-ray ptychographic data acquired at the Advanced Photon Source (APS). Similar to the previous section, we first introduce APS data, followed by the data characterization and compression pipeline customization along with the evaluation.\n\n\nAPS data\n\nX-ray ptychography is a main high-resolution imaging technique that takes advantage of the coherence provided by the synchrotron source. However, this computational method of microscopic imaging requires much larger data volume and computational resource compared with conventional microscopic techniques. A revolutionary increase of about 3 orders of magnitude in the coherent flux provided by the coming APS upgrade will aggravate the burden of the data transfer and storage. Therefore, a new compression strategy with high compression ratios is being highly pursued in ptychography. In order to represent most sample scenarios, two ptychographic datasets were acquired from a computer (c) dd|dd Fig. 4. Rate-distortion on GAMESS data.\n\nchip pillar (isolated sample) and a subregion of an entire flat chip (extended sample), respectively. In both cases, a Dectris Eiger detector (514\u00d71030 pixels) was used to acquire diffraction patterns as X-ray beam scanned across the sample, and the 2D diffraction images were saved along the time dimension to form a 3D matrix array (19500\u00d7514\u00d71030 for chip pillar and 16800\u00d7514\u00d71030 for flat chip). In the data analysis, domain experts usually cropped only central region of the diffraction pattern that contains X-ray signals (lots of zeros outside this region). To fairly assess our compression strategy without giving an overestimated compression ratio, we cropped only central 256\u00d7256 pixels.\n\n\nData characterization and pipeline customization\n\nWe design an adaptive compression pipeline for APS data based on the following analysis. First, multidimensional Lorenzo predictor introduces higher noise because more decompressed data values are used for prediction [8], even though it is usually superior to the one-dimensional one by exploiting the multidimensional correlation. Second, although APS data has three dimensions (e.g., 19500 \u00d7 256 \u00d7 256 for the chip pillar sample), it is actually a stack of 2D images along the time dimension with relatively low spatial correlation. When the spatial correlation is not strong, the benefit of using the multidimension Lorenzo predictor may not be able to make up the cost for the higher noise. In addition, considering the usually high correlation in time compared with that in spatial region, it might be more effective to compress the data along the time dimension, namely, treating the data as 256 \u00d7 256 1D time series. On the other hand, the multidimensional regression-based predictor should be included because it leverages the multidimensional correlation without being affected by the decompression noise [8], which yields good performance when error bound is relatively high. This requires switching predictors based on the error bound: using a traditional multialgorithm predictor that involves regression for high error bounds and a customized 1D Lorenzo predictor with a transposition preprocessor that reorganizes the data along the time dimension for low error bounds. In our implementation, we switch to the latter along with quantization bin width 2 when the user-specified absolute error bound is less than 0.5 since this setting generates lossless compression. Under such circumstance, the noise introduced by using decompressed data is reduced to 0 when the unpred-aware Quantizer is leveraged, thanks to the restricted quantization bin and the principle of embedded encoding. We further employ a fixed Huffman encoder for fast encoding with comparable compression ratios. The corresponding compression pipeline for APS data is depicted in Figure 5. \n\n\nEvaluation results\n\nWe evaluate the customized APS compressor and compare it with 3 baselines: the generic SZ-2.1 compressor for 1D, 3D, and transposed 1D data. As illustrated in Figure 6, a 3D compressor leads to higher PSNR under low bit-rate (high compression ratios), but it suffers when the bit-rate increases to a certain level, where there is a sharp increase in the compression quality for 1D compressors. This is caused by the fact that the noise introduced by decompressed data is mitigated with such an error setting in this dataset. SZ-2.1 is not aware of this information and incorrectly estimates the Lorenzo prediction noise, leading to the selection of regression predictor even when Lorenzo predictor is better. SZ3-APS adaptively chooses the compression pipeline based on the error bound, which leads to comparable performance to that of SZ-2.1 for 3D data when error bound is high. Furthermore, the adopted Unpred-aware Quantizer exhibits higher compression ratios in low error bound, since it provides near-lossless decompressed data that improves the prediction efficiency of the Lorenzo predictor. In absolute terms, when the decompression data is near lossless (i.e., error bound less than 0.5), the compression ratio gain of the proposed compression pipeline is 18% on chip pillar and  Data  Type   FP32, FP64  INT8, INT16, INT32, INT64  UINT8, UINT16, UINT32, UINT64  Data  Dimension  1D, 2D, 3D, 4D   Functionality Compression Decompression Parameter Optimization 12% on flat chip compared with the second best one. Note that SZ3-APS turns out to be lossless in this case, which leads to infinity PSNR in the figure.  \n\n\nSUSTAINABILITY, QUALITY, AND PERFORMANCE INVESTIGATION OF SZ3\n\nIn this section we first discuss the sustainability of SZ3, and then leverage SZ3 to characterize the quality and performance of diverse compression pipelines.\n\n\nSustainability\n\nWe design SZ3 with modularity in mind to allow for a composable framework with high sustainability. Specially, we compare the design of SZ3 with that of SZ2 [39], one of the leading error-controlled lossy compressors with predictionbased pipeline, to demonstrate its superiority.\n\n\nThe codebase of SZ2\n\nSZ2 has a large codebase including more than 120 functions with little code reuse, as shown in Table 2. For example, SZ2 has separate functions to handle the compression or decompression on a dataset with a specific data type, although the logic to compress and decompress different data types is similar. As a result, SZ2 needs to maintain separate code for each data type. The lack of software architecture design makes it difficult and time-consuming to modify and extend the functionality of SZ2. With more than 120 functions to update, some of them are likely to be missed when adding new features to SZ2. Furthermore, the complexity of SZ2 brings challenges to fully validate the correctness of newly added features, because it is time-consuming to write test code that achieves high code coverage for so many functions of SZ2.\n\n\nThe Codebase of SZ3\n\nWe propose three technologies in SZ3 to improve the code sustainability dramatically, namely compile-time polymorphism, datatype abstraction, and multidimensional iterator.\n\nCompile Time Polymorphism: SZ constructs the composed compression pipelines at compile time, because compile time polymorphism provides an efficient way to switch different implementations of modules to avoid runtime performance downgrade. For implementation, the module instances are placed as the template parameters of the compressor (see Appendix A.6). A static assert is executed during the construction of the compressor to ensure that only classes that inherent from specific module interfaces are allowed to be used to initialize template parameters.\n\nDatatype Abstraction: We adopt datatype abstraction to simplify the codebase of SZ3 significantly. Most module interfaces, implementations, and compressor pipelines in SZ3 are designed with datatypes as template parameters for efficient code reuse. By comparison, SZ2 has separate implementations for each datatype, which result in a large code base without code reuse.\n\nMultidimensional Iterator: A multidimensional iterator is designed in SZ3 to support data access patterns of different dimensions. This is totally different from SZ2, where independent implementations are required for each dimensionality. The multidimensional iterator in SZ3 provides a simple API to access the current and nearby data points and move to another position. The boundary situations are handled inside iterators. The iterator design eliminates the need to write separate code based on the data dimensions. The pseudocode of prediction and quantization using the multidimensional iterator is presented in Appendix A.7.\n\nWith the multidimensional iterator, the complex nestedloop to iterator through the data and the boundary condition checking are hidden from the users. The multidimensional iterator also supports arbitrary movement. For example, to change a 3D iterator to its upper left neighbor, developers can simply use iterator.move(-1, -1, -1) instead of calculating the offset for three dimensions.\n\n\nPipeline integration and evaluation\n\nWe integrate three compression pipelines using SZ3 and reveal their suitable cases in terms of quality and performance. Details of the three pipelines are described as follows.\n\nCompression Pipeline SZ3-LR: SZ3-LR is the implementation of the classic compressor SZ2 [8] using SZ3's modular mechanism, which relies on a multialgorithm predictor for better data correlation. This predictor consists of a Lorenzo predictor and a regression-based predictor and predicts data using the better result in between based on blockwise error estimation. As depicted in Figure 1, it uses a linear-scaling quantizer and a Huffman encoder and the zstd lossless compressor in the other stages.\n\nCompression Pipeline SZ3-Truncation: SZ3-Truncation is a very fast compression pipeline designed for cases where speed is more important than compression ratio. Given the target bytes k as input parameter, it keeps k most-significant bytes of each floating-point data while discarding the rest of the bytes. To achieve high compression speed, it bypasses  the other stages, which in turn leads to low compression ratios in general cases.\n\nCompression Pipeline SZ3-Interp: SZ3-Interp has interpolation-based predictors [17] in its pipeline. Both linear interpolation and cubic spline interpolation are included, and they are better than Lorenzo and regression predictors in many cases for the following reasons. On the one hand, interpolation-based predictors are not affected by the error accumulation effect that is normal in Lorenzo predictor, because the predicted value is based on previous data points in the Lorenzo predictor while it is based on coefficients in interpolation-based predictors. On the other hand, unlike linear regression, which has an overhead to store coefficients, SZ3-Interp has constant coefficients and therefore does not have storage overhead. Similar to SZ3-LR, it uses a linear-scaling quantizer for respecting error bounds, as well as a Huffman encoder and the zstd lossless compressor for high compression ratios.\n\nWe use datasets from five scientific domains : cosmology, climate, quantum structure, seismic wave, and turbulence. The detailed information is shown in Table 3. We demonstrate the compression quality of the three pipelines using rate-distortion graph in Figure 7. Note that the rate distortion of SZ2.1 is identical to that of SZ3-LR; thus we do not show SZ2.1 in this figure. We observe from Figure 7 that SZ3-Truncation has the lowest compression quality, and this is consistent with its simple byte-truncation design. SZ3-Interp is better than SZ3-LR on most of the datasets, especially on cases with a high compression ratio with a bit rate lower than 3. For example, on the Miranda dataset, under the same PSNR of 90, the compression ratio of SZ3-Interp is 47, and it is 56% higher than the compression ratio of SZ3-LR, which is 30. On the other hand, SZ3-LR is still the best choice on the Scale and Hurricane datasets when high compression accuracy is needed.\n\nThe performance evaluation is shown in Figure 8. We include SZ2.1 as the baseline. SZ3-LR-s) is a performanceoriented version of SZ3-LR that shares the same logic but has a different implementation of the predictor module with SZ3-LR. The predictor module in SZ3-LR uses a multidimensional iterator for better code simplicity, and in SZ3-LR-s the predictor contains several codecs, each of which handles data in a specific dimension. Note that SZ3-LR-s still has a modular design and can be customized with different a quantizer, encoder, and lossless compressors. We can see from Figure 8 that SZ3-LR-s has comparable performance with SZ2.1 on all datasets. SZ3-Truncation has the best performance among all compressors including SZ2.1. Its 1GB/s compression throughput is 4X higher than that of the second-best compressor. SZ3-Interp is not as fast as others, but its throughput is still higher than 100 MB/s in all cases.\n\nThe quality and performance evaluations reveal the suitable cases for the three built-in pipelines. Specifically, SZ3-Trunction, as a high-speed compressor, is the best choice when there are strict requirements on the compression time, as with some in situ applications. SZ3-Interp would be the first preference in cases where high compression ratio is wanted under relaxed time constraints, such as scientific applications that run for a long time and generate large amounts of data. SZ3-LR has balanced quality and speed; users could choose it as the default compressor in general situations where both high compression ratio and short compression time are needed.\n\n\nCONCLUSION AND FUTURE WORK\n\nIn this paper, we propose a modular, composable compression framework -SZ3-which allows users to customize ondemand error-bounded lossy compressors in an adaptive and extensible fashion with minimal effort. Using SZ3, we develop efficient error-bounded lossy compressors for two real-word application datasets based on the data characteristic and user requirements, which improve the compression ratios by 20% when compared with other state-of-the-art compressors with the same data distortion. We also compare the sustainability of SZ3 with existing compressors, and leverage it to integrate and evaluate different compression pipelines. In the future, we will integrate more instances to the framework for diverse use cases and provide support for various hardware including GPUs and FPGAs. Zizhong Chen (Senior Member, IEEE) received a bachelor's degree in mathematics from Beijing Normal University, a master's degree degree in economics from the Renmin University of China, and a Ph.D. degree in computer science from the University of Tennessee, Knoxville. He is a professor of computer science at the University of California, Riverside. His research interests include high-performance computing, parallel and distributed systems, big data analytics, cluster and cloud computing, algorithm-based fault tolerance, power and energy efficient computing, numerical algorithms and software, and large-scale computer simulations. He currently serves as a subject area editor for Elsevier Parallel Computing journal and an associate editor for the IEEE Transactions on Parallel and Distributed Systems. Email: chen@cs.ucr.edu. (Fellow, IEEE) is the director of the Joint-Laboratory on Extreme Scale Computing gathering six of the leading highperformance computing institutions in the world: Argonne National Laboratory, National Center for Scientific Applications, Inria, Barcelona Supercomputing Center, Julich Supercomputing Center, and Riken AICS. He is a senior computer scientist at Argonne National Laboratory and an adjunct associate professor in the Department of Computer Science at the University of Illinois at Urbana-Champaign. He is an expert in resilience and fault tolerance for scientific computing and data analytics. Recently he started investigating lossy compression for scientific data sets to respond to the pressing needs of scientist performing large-scale simulations and experiments. His contribution to this domain is one of the best lossy compressors for scientific data set respecting user-set error bounds. He is a member of the editorial board of the IEEE Transactions on Parallel and Distributed Computing and of the ACM HPDC and IEEE CCGRID steering committees. He is a fellow of the IEEE. Email: cappello@mcs.anl.gov.\n\n\nFranck Cappello\n\nFig. 1 .\n1SZ3 design overview: left part of the figure shows the abstraction and key functionalities of prediction-based compression pipeline with SZ3 modules; right part of the figure displays common instances of these modules and how five leading compressors are composed by these instances.\n\nFig. 2 .\n2Compression pipelines for GAMESS data. Blue boxes indicate optimized/added modules in SZ3-Pastri over SZ-Pastri.\n\nFig. 3 .\n3Distribution of quantization integers in SZ3-Pastri.\n\nFig. 5 .\n5Adaptive compression pipeline for APS data.\n\nFig. 6 .\n6Rate-distortion on APS data.\n\nFig. 7 .\n7Compression quality evaluation (lower bit rate & higher PSNR \u2192 better quality). Result for SZ2.1 is omitted since it is very similar to that of SZ3-LR.\n\nFig. 8 .\n8Compression/decompression throughput (MB/s) when relative error bound (error bound normalized to value range) is 1E-3.\n\n\n(DOE) Office of Science User Facility, operated for the DOE Office of Science by Argonne National Laboratory under Contract No. DE-AC02-06CH11357. We acknowledge the computing resources provided on Bebop, which is operated by the Laboratory Computing Resource Center at Argonne National Laboratory.\n\nTABLE 1\n1Result on GAMESS data when absolute error bound is 1E-10Dataset \nCompressor \nRatios Compression Speed \n\nf f |f f \n\nSZ-Pastri \n8.46 \n662.01 MB/s \nSZ-Pastri-with-zstd \n9.27 \n377.17 MB/s \nSZ3-Pastri \n10.76 \n244.43 MB/s \n\nf f |dd \n\nSZ-Pastri \n8.40 \n643.58 MB/s \nSZ-Pastri-with-zstd \n9.23 \n370.88 MB/s \nSZ3-Pastri \n10.06 \n221.03 MB/s \n\ndd|dd \n\nSZ-Pastri \n9.14 \n613.12 MB/s \nSZ-Pastri-with-zstd \n9.96 \n364.51 MB/s \nSZ3-Pastri \n10.71 \n226.80 MB/s \n\n\n\nTABLE 3 Dataset\n3InformationApplication \nDomain \n#Fields \nDimensions \nTotal Size \nHACC \nCosmology \n6 \n280 \u00d7 953 \u00d7 867 \n6.3GB \nATM \nClimate \n77 \n1800 \u00d7 3600 \n1.9GB \nHurricane \nClimate \n13 \n100 \u00d7 500 \u00d7 500 \n1.2GB \nNYX \nCosmology \n6 \n512 \u00d7 512 \u00d7 512 \n3GB \nSCALE-LETKF \nClimate \n6 \n98 \u00d7 1200 \u00d7 1200 \n3.2GB \nQMCPack \nQuantum Structure \n1 \n288 \u00d7 115 \u00d7 69 \u00d7 69 \n0.6GB \nRTM \nSeismic Wave \n3600 \n449 \u00d7 449 \u00d7 235 \n635GB \nMiranda \nTurbulence \n7 \n256 \u00d7 384 \u00d7 384 \n1GB \n\n\nACKNOWLEDGMENTSThis research was supported by the Exascale Computing Project (ECP), Project Number: 17-SC-20-SC, a collaborative effort of two DOE organizations -the Office of Science and the National Nuclear Security Administration, responsible for the planning and preparation of a capable exascale ecosystem, including software, applications, hardware, advanced system engineering and early testbed platforms, to support the nation's exascale computing imperative. The material was supported by the U.S. Department of EnergyAPPENDIX AWe demonstrate some representative interfaces and functions in this appendix. Note that T is the template for data type, N is the template for dimensionality, and X is the template for quantized data type. A.3 Snippet of Quantizer Interface template<c l a s s T , c l a s s X , u i n t N> c l a s s Q u a n t i z e r I n t e r f a c e { v i r t u a l X q u a n t i z e ( T data , T pred ) ; v i r t u a l T r e c o v e r ( T pred , X quant value ) ; v i r t u a l u i n t save ( uchar * &c ) ; v i r t u a l void load ( uchar * &c ) ; } ; ; quan= q u a n t i z e r . q u a n t i z e ( * element , pred ) ; q u a n t i z a t i o n r e s u l t s . push back ( quan ) ; } } r e t u r n q u a n t i z a t i o n r e s u l t s ; He is currently a computer scientist at Argonne National Laboratory. Dr. Di's research interest involves resilience on high-performance computing (such as silent data corruption, optimization checkpoint model, and in-situ data compression) and broad research topics on cloud computing (including optimization of resource allocation, cloud network topology, and prediction of cloud workload/hostload). He is working on multiple HPC projects, such as detection of silent data corruption, characterization of failures and faults for HPC systems, and optimization of multilevel checkpoint models. He is the recipient of DOE 2021 Early Career Research Program Award. Email: sdi1@anl.gov.A.1 Snippet of Preprocess InterfaceA.4 Snippet of Encoder InterfaceSihuanLi is a research scientist at Facebook. Before that, he received his Ph.D. degree in computer science at University of California, Riverside. He obtained his bachelor's degree in math from Huazhong University of Science and Technology, China. He did a long-term internship at Argonne National Laboratory. Broadly speaking, his research interests fall into High Performance Computing. Specifically, he mainly studies Algorithm Based Fault Tolerance (ABFT), lossy compression and their applications in large scale scientific simulations. Email: sli049@ucr.edu. Robert Underwood is a PhD Candidate at Clemson University. His research interests involve using approximate computing methods such as lossy data compression to accelerate parallel and distributed computing while ensuring that scientific data integrity is preserved. He is currently working on using optimization based approaches to configure lossy compression. Email: robertu@g.clemson.edu Ali Murat Gok is a computer engineer at Cerebras Systems. He received his PhD in computer engineering from Northwestern University in 2018 and his B.S. in electronics engineering / mathematics double major program from Bogazici University, Turkey in 2012. He had long term internships followed by a postdoctoral position at Argonne National Laboratory. His research interest include energy efficient computer architecture, high performance computing, and scientific lossy data compression. Email: ali.gok@cerebras.net Jiannan Tian is current PhD Candidate in Computer Science at Washington State University. His research interests include lossy compression for scientific data and error analysis, and GPU-centric computing. His ongoing project including developing GPU-accelerated compression algorithm and system design optmization of lossy compression framework. Email: jiannan.tian@wsu.edu Junjing Deng is a physicist at the Advanced Photon Source, Argonne National Laboratory. He received the Ph.D. degree in applied physics from Northwestern University in 2016. His research interests center on high-resolution synchrotron X-ray microcopy, lensless computational imaging, and their applications on a variety of scientific problems. Email: junjing-deng@anl.gov.Jon C. Calhoun is an Assistant\nComputing just what you need: Online data analysis and reduction at extreme scales. I T Foster, European Conference on Parallel Processing. ChamSpringer International PublishingI. T. Foster et al., \"Computing just what you need: Online data analysis and reduction at extreme scales,\" in European Conference on Parallel Processing, Springer. Cham: Springer International Publishing, 2017, pp. 3-19.\n\nThe JPEG still picture compression standard. G K Wallace, IEEE Transactions on Consumer Electronics. 381G. K. Wallace, \"The JPEG still picture compression standard,\" IEEE Transactions on Consumer Electronics, vol. 38, no. 1, pp. xviii-xxxiv, 1992.\n\nD Taubman, M Marcellin, JPEG2000 Image Compression Fundamentals, Standards and Practice. New York, NY, USASpringer Publishing CompanyIncorporatedD. Taubman and M. Marcellin, JPEG2000 Image Compression Fun- damentals, Standards and Practice. New York, NY, USA: Springer Publishing Company, Incorporated, 2013.\n\nLossy image compression with compressive autoencoders. L Theis, W Shi, A Cunningham, F Husz\u00e1r, arXiv:1703.00395arXiv preprintL. Theis, W. Shi, A. Cunningham, and F. Husz\u00e1r, \"Lossy im- age compression with compressive autoencoders,\" arXiv preprint arXiv:1703.00395, 2017.\n\nGenerative adversarial networks for extreme learned image compression. E Agustsson, M Tschannen, F Mentzer, R Timofte, L V Gool, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer VisionE. Agustsson, M. Tschannen, F. Mentzer, R. Timofte, and L. V. Gool, \"Generative adversarial networks for extreme learned image com- pression,\" in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2019, pp. 221-231.\n\nFast error-bounded lossy HPC data compression with SZ. S Di, F Cappello, 2016 IEEE International Parallel and Distributed Processing Symposium. New York, NY, USAIEEES. Di and F. Cappello, \"Fast error-bounded lossy HPC data compression with SZ,\" in 2016 IEEE International Parallel and Distributed Processing Symposium. New York, NY, USA: IEEE, 2016, pp. 730-739.\n\nSignificantly improving lossy compression for scientific data sets based on multidimensional prediction and error-controlled quantization. D Tao, S Di, Z Chen, F Cappello, 2017 IEEE International Parallel and Distributed Processing Symposium. New York, NY, USAIEEED. Tao, S. Di, Z. Chen, and F. Cappello, \"Significantly improving lossy compression for scientific data sets based on multidimen- sional prediction and error-controlled quantization,\" in 2017 IEEE International Parallel and Distributed Processing Symposium. New York, NY, USA: IEEE, 2017, pp. 1129-1139.\n\nError-controlled lossy compression optimized for high compression ratios of scientific datasets. X Liang, S Di, D Tao, S Li, S Li, H Guo, Z Chen, F Cappello, 2018 IEEE International Conference on Big Data. New York, NY, USAIEEEX. Liang, S. Di, D. Tao, S. Li, S. Li, H. Guo, Z. Chen, and F. Cap- pello, \"Error-controlled lossy compression optimized for high compression ratios of scientific datasets,\" in 2018 IEEE International Conference on Big Data, IEEE. New York, NY, USA: IEEE, 2018.\n\nSignificantly improving lossy compression for HPC datasets with second-order prediction and parameter optimization. K Zhao, S Di, X Liang, S Li, D Tao, Z Chen, F Cappello, Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, ser. HPDC '20. the 29th International Symposium on High-Performance Parallel and Distributed Computing, ser. HPDC '20New York, NY, USAAssociation for Computing MachineryK. Zhao, S. Di, X. Liang, S. Li, D. Tao, Z. Chen, and F. Cappello, \"Significantly improving lossy compression for HPC datasets with second-order prediction and parameter optimization,\" in Proceed- ings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, ser. HPDC '20. New York, NY, USA: Association for Computing Machinery, 2020, pp. 89--100.\n\nFixed-rate compressed floating-point arrays. P Lindstrom, IEEE Transactions on Visualization and Computer Graphics. 2012P. Lindstrom, \"Fixed-rate compressed floating-point arrays,\" IEEE Transactions on Visualization and Computer Graphics, vol. 20, no. 12, pp. 2674-2683, 2014.\n\nFast and efficient compression of floating-point data. P Lindstrom, M Isenburg, IEEE Transactions on Visualization and Computer Graphics. 125P. Lindstrom and M. Isenburg, \"Fast and efficient compression of floating-point data,\" IEEE Transactions on Visualization and Com- puter Graphics, vol. 12, no. 5, pp. 1245-1250, 2006.\n\nCompression using lossless decimation: analysis and application. M Ainsworth, S Klasky, B Whitney, SIAM Journal on Scientific Computing. 394M. Ainsworth, S. Klasky, and B. Whitney, \"Compression using lossless decimation: analysis and application,\" SIAM Journal on Scientific Computing, vol. 39, no. 4, pp. B732-B757, 2017.\n\nMultilevel techniques for compression and reduction of scientific data-the univariate case. M Ainsworth, O Tugluk, B Whitney, S Klasky, Computing and Visualization in Science. 195-6M. Ainsworth, O. Tugluk, B. Whitney, and S. Klasky, \"Multilevel techniques for compression and reduction of scientific data-the univariate case,\" Computing and Visualization in Science, vol. 19, no. 5-6, pp. 65-76, 2018.\n\nMultilevel techniques for compression and reduction of scientific data-quantitative control of accuracy in derived quantities. SIAM Journal on Scientific Computing. 414--, \"Multilevel techniques for compression and reduction of sci- entific data-quantitative control of accuracy in derived quantities,\" SIAM Journal on Scientific Computing, vol. 41, no. 4, pp. A2146- A2171, 2019.\n\nMgard+: Optimizing multilevel methods for error-bounded scientific data reduction. X Liang, B Whitney, J Chen, L Wan, Q Liu, D Tao, J Kress, D R Pugmire, M Wolf, N Podhorszki, IEEE Transactions on Computers. X. Liang, B. Whitney, J. Chen, L. Wan, Q. Liu, D. Tao, J. Kress, D. R. Pugmire, M. Wolf, N. Podhorszki et al., \"Mgard+: Optimizing multilevel methods for error-bounded scientific data reduction,\" IEEE Transactions on Computers, 2021.\n\nSignificantly improving lossy compression quality based on an optimized hybrid prediction model. X Liang, S Di, S Li, D Tao, B Nicolae, Z Chen, F Cappello, Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. the International Conference for High Performance Computing, Networking, Storage and AnalysisX. Liang, S. Di, S. Li, D. Tao, B. Nicolae, Z. Chen, and F. Cap- pello, \"Significantly improving lossy compression quality based on an optimized hybrid prediction model,\" in Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, 2019, pp. 1-26.\n\nOptimizing error-bounded lossy compression for scientific data by dynamic spline interpolation. K Zhao, S Di, M Dmitriev, T.-L D Tonellot, Z Chen, F Cappello, 2021 IEEE 37th International Conference on Data Engineering (ICDE). IEEEK. Zhao, S. Di, M. Dmitriev, T.-L. D. Tonellot, Z. Chen, and F. Cappello, \"Optimizing error-bounded lossy compression for scientific data by dynamic spline interpolation,\" in 2021 IEEE 37th International Conference on Data Engineering (ICDE). IEEE, 2021, pp. 1643-1654.\n\nGAMESS as a free quantum-mechanical platform for drug research. Y Alexeev, M Mazanetz, O Ichihara, D Fedorov, Current topics in medicinal chemistry. 1218Y. Alexeev, M. P Mazanetz, O. Ichihara, and D. G Fedorov, \"GAMESS as a free quantum-mechanical platform for drug re- search,\" Current topics in medicinal chemistry, vol. 12, no. 18, pp. 2013-2033, 2012.\n\nPaSTRI: A novel data compression algorithm for two-electron integrals in quantum chemistry. A M Gok, S Di, A Yuri, D Tao, V Mironov, X Liang, F Cappello, IEEE International Conference on Cluster Computing (CLUSTER). New York, NY, USAIEEEA. M. Gok, S. Di, A. Yuri, D. Tao, V. Mironov, X. Liang, and F. Cappello, \"PaSTRI: A novel data compression algorithm for two-electron integrals in quantum chemistry,\" in IEEE International Conference on Cluster Computing (CLUSTER). New York, NY, USA: IEEE, 2018, pp. 1-11.\n\nAn efficient transformation scheme for lossy data compression with point-wise relative error bound. X Liang, S Di, D Tao, Z Chen, F Cappello, IEEE International Conference on Cluster Computing (CLUSTER). New York, NY, USAIEEEX. Liang, S. Di, D. Tao, Z. Chen, and F. Cappello, \"An efficient transformation scheme for lossy data compression with point-wise relative error bound,\" in IEEE International Conference on Cluster Computing (CLUSTER). New York, NY, USA: IEEE, 2018, pp. 179-189.\n\nToward feature-preserving 2D and 3D vector field compression. X Liang, H Guo, S Di, F Cappello, M Raj, C Liu, K Ono, Z Chen, T Peterka, in PacificVis, 2020X. Liang, H. Guo, S. Di, F. Cappello, M. Raj, C. Liu, K. Ono, Z. Chen, and T. Peterka, \"Toward feature-preserving 2D and 3D vector field compression.\" in PacificVis, 2020, pp. 81-90.\n\nGZIP file format specification version 4.3. L P Deutsch, L. P. Deutsch, \"GZIP file format specification version 4.3,\" 1996.\n\nFPC: A high-speed compressor for double-precision floating-point data. M Burtscher, P Ratanaworabhan, IEEE Transactions on Computers. 581M. Burtscher and P. Ratanaworabhan, \"FPC: A high-speed com- pressor for double-precision floating-point data,\" IEEE Transac- tions on Computers, vol. 58, no. 1, pp. 18-31, Jan 2009.\n\nSPDP: An automatically synthesized lossless compression algorithm for floating-point data. S Claggett, S Azimi, M Burtscher, 2018 Data Compression Conference. New York, NY, USAIEEES. Claggett, S. Azimi, and M. Burtscher, \"SPDP: An automati- cally synthesized lossless compression algorithm for floating-point data,\" in 2018 Data Compression Conference. New York, NY, USA: IEEE, March 2018, pp. 335-344.\n\nBlosc, an extremely fast, multi-threaded, metacompressor library. F Alted, F. Alted, \"Blosc, an extremely fast, multi-threaded, meta- compressor library,\" 2017.\n\nError distributions of lossy floating-point compressors. P Lindstrom, Joint Statistical Meetings. 11P. Lindstrom, \"Error distributions of lossy floating-point compres- sors,\" Joint Statistical Meetings, vol. 1, no. 1, pp. 2574-2589, 2017.\n\nUse cases of lossy compression for floating-point data in scientific data sets. F Cappello, S Di, S Li, X Liang, A M Gok, D Tao, C H Yoon, X.-C Wu, Y Alexeev, F T Chong, 33F. Cappello, S. Di, S. Li, X. Liang, A. M. Gok, D. Tao, C. H. Yoon, X.-C. Wu, Y. Alexeev, and F. T. Chong, \"Use cases of lossy compression for floating-point data in scientific data sets,\" vol. 33, no. 6, pp. 1201-1220, 2019.\n\nVAPOR: A visualization package tailored to analyze simulation data in earth system science. S Li, S Jaroszynski, S Pearse, L Orf, J Clyne, S. Li, S. Jaroszynski, S. Pearse, L. Orf, and J. Clyne, \"VAPOR: A visualization package tailored to analyze simulation data in earth system science,\" 2019.\n\nEnd-to-end optimized versatile image compression with wavelet-like transform. H Ma, D Liu, N Yan, H Li, F Wu, IEEE Transactions on Pattern Analysis and Machine Intelligence. H. Ma, D. Liu, N. Yan, H. Li, and F. Wu, \"End-to-end optimized versatile image compression with wavelet-like transform,\" IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020.\n\nUnderstanding and modeling lossy compression schemes on HPC scientific data. T Lu, Q Liu, X He, H Luo, E Suchyta, J Choi, N Podhorszki, S Klasky, M Wolf, T Liu, 2018 IEEE International Parallel and Distributed Processing Symposium. IEEET. Lu, Q. Liu, X. He, H. Luo, E. Suchyta, J. Choi, N. Podhorszki, S. Klasky, M. Wolf, T. Liu et al., \"Understanding and modeling lossy compression schemes on HPC scientific data,\" in 2018 IEEE International Parallel and Distributed Processing Symposium. IEEE, 2018, pp. 348-357.\n\nToward decoupling the selection of compression algorithms from quality constraints. J Kunkel, A Novikova, E Betke, A Schaare, High Performance Computing, J. M. Kunkel, R. Yokota, M. Taufer, and J. ShalfSpringer International Publishing10524J. Kunkel, A. Novikova, E. Betke, and A. Schaare, \"Toward decou- pling the selection of compression algorithms from quality con- straints,\" in High Performance Computing, J. M. Kunkel, R. Yokota, M. Taufer, and J. Shalf, Eds. Cham: Springer International Publishing, 2017, vol. 10524, pp. 3-14.\n\nFRaZ: A generic high-fidelity fixed-ratio lossy compression framework for scientific floating-point data. R Underwood, S Di, J C Calhoun, F Cappello, onlineR. Underwood, S. Di, J. C. Calhoun, and F. Cappello, \"FRaZ: A generic high-fidelity fixed-ratio lossy compression framework for scientific floating-point data,\" https://arxiv.org/abs/2001.06139, 2020, online.\n\nOutof-core compression and decompression of large n-dimensional scalar fields. L Ibarria, P Lindstrom, J Rossignac, A Szymczak, Computer Graphics Forum. 223Wiley Online LibraryL. Ibarria, P. Lindstrom, J. Rossignac, and A. Szymczak, \"Out- of-core compression and decompression of large n-dimensional scalar fields,\" in Computer Graphics Forum, vol. 22, no. 3. Wiley Online Library, 2003, pp. 343-348.\n\nNUMARCK: machine learning algorithm for resiliency and checkpointing. Z Chen, S W Son, W Hendrix, A Agrawal, W Liao, A Choudhary, Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. the International Conference for High Performance Computing, Networking, Storage and AnalysisNew York, NY, USAIEEEZ. Chen, S. W. Son, W. Hendrix, A. Agrawal, W.-k. Liao, and A. Choudhary, \"NUMARCK: machine learning algorithm for resiliency and checkpointing,\" in Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE Press. New York, NY, USA: IEEE, 2014, pp. 733- 744.\n\nA method for the construction of minimumredundancy codes. D A Huffman, Proceedings of the IRE. 409D. A. Huffman, \"A method for the construction of minimum- redundancy codes,\" Proceedings of the IRE, vol. 40, no. 9, pp. 1098- 1101, 1952.\n\nError-controlled, progressive, and adaptable retrieval of scientific data with multilevel decomposition. X Liang, Q Gong, J Chen, B Whitney, L Wan, Q Liu, D Pugmire, R Archibald, N Podhorszki, S Klasky, Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. the International Conference for High Performance Computing, Networking, Storage and AnalysisX. Liang, Q. Gong, J. Chen, B. Whitney, L. Wan, Q. Liu, D. Pugmire, R. Archibald, N. Podhorszki, and S. Klasky, \"Error-controlled, pro- gressive, and adaptable retrieval of scientific data with multilevel decomposition,\" in Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, 2021, pp. 1-13.\n\nBebop supercomputer. Bebop supercomputer, Available at https://www.lcrc.anl.gov/ systems/resources/bebop, 2019, online.\n\nRepository of sz2 compresssor. \"Repository of sz2 compresssor,\" https://github.com/ szcompressor/SZ, 2021, online.\n", "annotations": {"author": "[{\"end\":129,\"start\":102},{\"end\":136,\"start\":130}]", "publisher": null, "author_last_name": "[{\"end\":128,\"start\":102},{\"end\":135,\"start\":130}]", "author_first_name": null, "author_affiliation": null, "title": "[{\"end\":88,\"start\":1},{\"end\":224,\"start\":137}]", "venue": null, "abstract": "[{\"end\":2141,\"start\":341}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2539,\"start\":2536},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2977,\"start\":2974},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2982,\"start\":2979},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3028,\"start\":3025},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3033,\"start\":3030},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3261,\"start\":3258},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3266,\"start\":3263},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3271,\"start\":3268},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3276,\"start\":3273},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3282,\"start\":3278},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3288,\"start\":3284},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3294,\"start\":3290},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3300,\"start\":3296},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3306,\"start\":3302},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3312,\"start\":3308},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3980,\"start\":3976},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4084,\"start\":4081},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4089,\"start\":4086},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4094,\"start\":4091},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4462,\"start\":4459},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4670,\"start\":4667},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4711,\"start\":4707},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4825,\"start\":4821},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4968,\"start\":4964},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6092,\"start\":6088},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6153,\"start\":6149},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8650,\"start\":8646},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8662,\"start\":8658},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8668,\"start\":8664},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8674,\"start\":8670},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8930,\"start\":8926},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9177,\"start\":9173},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9201,\"start\":9198},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9206,\"start\":9203},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9211,\"start\":9208},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9216,\"start\":9213},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9222,\"start\":9218},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9228,\"start\":9224},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9978,\"start\":9974},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10118,\"start\":10114},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10124,\"start\":10120},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10130,\"start\":10126},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10390,\"start\":10386},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10398,\"start\":10395},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10403,\"start\":10400},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10408,\"start\":10405},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10777,\"start\":10773},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11007,\"start\":11003},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11270,\"start\":11266},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11543,\"start\":11539},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12107,\"start\":12103},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":12247,\"start\":12243},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13486,\"start\":13482},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13497,\"start\":13494},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13506,\"start\":13503},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13522,\"start\":13518},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13537,\"start\":13533},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":15392,\"start\":15388},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":15559,\"start\":15555},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16509,\"start\":16506},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16514,\"start\":16511},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":16671,\"start\":16667},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16705,\"start\":16702},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16888,\"start\":16885},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":16903,\"start\":16899},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16911,\"start\":16908},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":17468,\"start\":17465},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":17477,\"start\":17473},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":18538,\"start\":18535},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":18976,\"start\":18972},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":19085,\"start\":19081},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":19728,\"start\":19724},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20076,\"start\":20072},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21089,\"start\":21085},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":21105,\"start\":21101},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22754,\"start\":22750},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":22856,\"start\":22852},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23756,\"start\":23752},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":24408,\"start\":24405},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24414,\"start\":24410},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25839,\"start\":25835},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":25845,\"start\":25841},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":26245,\"start\":26241},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":27396,\"start\":27392},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":31015,\"start\":31012},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":31912,\"start\":31909},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":34917,\"start\":34913},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":38350,\"start\":38347},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":39283,\"start\":39279}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":45766,\"start\":45472},{\"attributes\":{\"id\":\"fig_2\"},\"end\":45890,\"start\":45767},{\"attributes\":{\"id\":\"fig_3\"},\"end\":45954,\"start\":45891},{\"attributes\":{\"id\":\"fig_5\"},\"end\":46009,\"start\":45955},{\"attributes\":{\"id\":\"fig_7\"},\"end\":46049,\"start\":46010},{\"attributes\":{\"id\":\"fig_9\"},\"end\":46212,\"start\":46050},{\"attributes\":{\"id\":\"fig_10\"},\"end\":46342,\"start\":46213},{\"attributes\":{\"id\":\"fig_11\"},\"end\":46643,\"start\":46343},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":47096,\"start\":46644},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":47556,\"start\":47097}]", "paragraph": "[{\"end\":3202,\"start\":2157},{\"end\":3981,\"start\":3204},{\"end\":5195,\"start\":4024},{\"end\":6373,\"start\":5197},{\"end\":8035,\"start\":6375},{\"end\":8623,\"start\":8052},{\"end\":9178,\"start\":8625},{\"end\":9561,\"start\":9180},{\"end\":10356,\"start\":9563},{\"end\":11926,\"start\":10358},{\"end\":12739,\"start\":11928},{\"end\":13975,\"start\":12780},{\"end\":14570,\"start\":14008},{\"end\":15236,\"start\":14572},{\"end\":15958,\"start\":15238},{\"end\":16636,\"start\":15960},{\"end\":17643,\"start\":16638},{\"end\":18497,\"start\":17677},{\"end\":19156,\"start\":18499},{\"end\":19695,\"start\":19188},{\"end\":20435,\"start\":19697},{\"end\":20952,\"start\":20479},{\"end\":21281,\"start\":20954},{\"end\":21886,\"start\":21318},{\"end\":22081,\"start\":21930},{\"end\":22502,\"start\":22187},{\"end\":23063,\"start\":22567},{\"end\":24415,\"start\":23104},{\"end\":27107,\"start\":24468},{\"end\":27591,\"start\":27130},{\"end\":28909,\"start\":27593},{\"end\":29292,\"start\":28970},{\"end\":30042,\"start\":29305},{\"end\":30742,\"start\":30044},{\"end\":32865,\"start\":30795},{\"end\":34512,\"start\":32888},{\"end\":34737,\"start\":34578},{\"end\":35035,\"start\":34756},{\"end\":35892,\"start\":35059},{\"end\":36088,\"start\":35916},{\"end\":36648,\"start\":36090},{\"end\":37019,\"start\":36650},{\"end\":37652,\"start\":37021},{\"end\":38041,\"start\":37654},{\"end\":38257,\"start\":38081},{\"end\":38759,\"start\":38259},{\"end\":39198,\"start\":38761},{\"end\":40108,\"start\":39200},{\"end\":41077,\"start\":40110},{\"end\":42003,\"start\":41079},{\"end\":42671,\"start\":42005},{\"end\":45453,\"start\":42702}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":22186,\"start\":22082}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":28579,\"start\":28572},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":34308,\"start\":34178},{\"end\":35161,\"start\":35154},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":40270,\"start\":40263}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2155,\"start\":2143},{\"end\":4022,\"start\":3984},{\"attributes\":{\"n\":\"2\"},\"end\":8050,\"start\":8038},{\"attributes\":{\"n\":\"3\"},\"end\":12778,\"start\":12742},{\"attributes\":{\"n\":\"3.1\"},\"end\":13993,\"start\":13978},{\"attributes\":{\"n\":\"3.2\"},\"end\":14006,\"start\":13996},{\"end\":17675,\"start\":17646},{\"end\":19186,\"start\":19159},{\"end\":20477,\"start\":20438},{\"attributes\":{\"n\":\"3.3\"},\"end\":21316,\"start\":21284},{\"end\":21928,\"start\":21889},{\"attributes\":{\"n\":\"4\"},\"end\":22565,\"start\":22505},{\"attributes\":{\"n\":\"4.1\"},\"end\":23102,\"start\":23066},{\"attributes\":{\"n\":\"4.2\"},\"end\":24466,\"start\":24418},{\"attributes\":{\"n\":\"4.3\"},\"end\":27128,\"start\":27110},{\"attributes\":{\"n\":\"5\"},\"end\":28968,\"start\":28912},{\"attributes\":{\"n\":\"5.1\"},\"end\":29303,\"start\":29295},{\"attributes\":{\"n\":\"5.2\"},\"end\":30793,\"start\":30745},{\"attributes\":{\"n\":\"5.3\"},\"end\":32886,\"start\":32868},{\"attributes\":{\"n\":\"6\"},\"end\":34576,\"start\":34515},{\"attributes\":{\"n\":\"6.1\"},\"end\":34754,\"start\":34740},{\"attributes\":{\"n\":\"6.1.1\"},\"end\":35057,\"start\":35038},{\"attributes\":{\"n\":\"6.1.2\"},\"end\":35914,\"start\":35895},{\"attributes\":{\"n\":\"6.2\"},\"end\":38079,\"start\":38044},{\"attributes\":{\"n\":\"7\"},\"end\":42700,\"start\":42674},{\"end\":45471,\"start\":45456},{\"end\":45481,\"start\":45473},{\"end\":45776,\"start\":45768},{\"end\":45900,\"start\":45892},{\"end\":45964,\"start\":45956},{\"end\":46019,\"start\":46011},{\"end\":46059,\"start\":46051},{\"end\":46222,\"start\":46214},{\"end\":46652,\"start\":46645},{\"end\":47113,\"start\":47098}]", "table": "[{\"end\":47096,\"start\":46710},{\"end\":47556,\"start\":47126}]", "figure_caption": "[{\"end\":45766,\"start\":45483},{\"end\":45890,\"start\":45778},{\"end\":45954,\"start\":45902},{\"end\":46009,\"start\":45966},{\"end\":46049,\"start\":46021},{\"end\":46212,\"start\":46061},{\"end\":46342,\"start\":46224},{\"end\":46643,\"start\":46345},{\"end\":46710,\"start\":46654},{\"end\":47126,\"start\":47115}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12976,\"start\":12968},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":24907,\"start\":24899},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":27013,\"start\":27005},{\"end\":27663,\"start\":27655},{\"end\":30009,\"start\":30003},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":32863,\"start\":32855},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":33055,\"start\":33047},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":38647,\"start\":38639},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":40373,\"start\":40365},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":40512,\"start\":40504},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":41126,\"start\":41118},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":41668,\"start\":41660},{\"end\":44343,\"start\":44329}]", "bib_author_first_name": "[{\"end\":51902,\"start\":51901},{\"end\":51904,\"start\":51903},{\"end\":52262,\"start\":52261},{\"end\":52264,\"start\":52263},{\"end\":52466,\"start\":52465},{\"end\":52477,\"start\":52476},{\"end\":52831,\"start\":52830},{\"end\":52840,\"start\":52839},{\"end\":52847,\"start\":52846},{\"end\":52861,\"start\":52860},{\"end\":53119,\"start\":53118},{\"end\":53132,\"start\":53131},{\"end\":53145,\"start\":53144},{\"end\":53156,\"start\":53155},{\"end\":53167,\"start\":53166},{\"end\":53169,\"start\":53168},{\"end\":53600,\"start\":53599},{\"end\":53606,\"start\":53605},{\"end\":54048,\"start\":54047},{\"end\":54055,\"start\":54054},{\"end\":54061,\"start\":54060},{\"end\":54069,\"start\":54068},{\"end\":54575,\"start\":54574},{\"end\":54584,\"start\":54583},{\"end\":54590,\"start\":54589},{\"end\":54597,\"start\":54596},{\"end\":54603,\"start\":54602},{\"end\":54609,\"start\":54608},{\"end\":54616,\"start\":54615},{\"end\":54624,\"start\":54623},{\"end\":55084,\"start\":55083},{\"end\":55092,\"start\":55091},{\"end\":55098,\"start\":55097},{\"end\":55107,\"start\":55106},{\"end\":55113,\"start\":55112},{\"end\":55120,\"start\":55119},{\"end\":55128,\"start\":55127},{\"end\":55843,\"start\":55842},{\"end\":56131,\"start\":56130},{\"end\":56144,\"start\":56143},{\"end\":56467,\"start\":56466},{\"end\":56480,\"start\":56479},{\"end\":56490,\"start\":56489},{\"end\":56818,\"start\":56817},{\"end\":56831,\"start\":56830},{\"end\":56841,\"start\":56840},{\"end\":56852,\"start\":56851},{\"end\":57594,\"start\":57593},{\"end\":57603,\"start\":57602},{\"end\":57614,\"start\":57613},{\"end\":57622,\"start\":57621},{\"end\":57629,\"start\":57628},{\"end\":57636,\"start\":57635},{\"end\":57643,\"start\":57642},{\"end\":57652,\"start\":57651},{\"end\":57654,\"start\":57653},{\"end\":57665,\"start\":57664},{\"end\":57673,\"start\":57672},{\"end\":58051,\"start\":58050},{\"end\":58060,\"start\":58059},{\"end\":58066,\"start\":58065},{\"end\":58072,\"start\":58071},{\"end\":58079,\"start\":58078},{\"end\":58090,\"start\":58089},{\"end\":58098,\"start\":58097},{\"end\":58710,\"start\":58709},{\"end\":58718,\"start\":58717},{\"end\":58724,\"start\":58723},{\"end\":58739,\"start\":58735},{\"end\":58741,\"start\":58740},{\"end\":58753,\"start\":58752},{\"end\":58761,\"start\":58760},{\"end\":59180,\"start\":59179},{\"end\":59191,\"start\":59190},{\"end\":59203,\"start\":59202},{\"end\":59215,\"start\":59214},{\"end\":59565,\"start\":59564},{\"end\":59567,\"start\":59566},{\"end\":59574,\"start\":59573},{\"end\":59580,\"start\":59579},{\"end\":59588,\"start\":59587},{\"end\":59595,\"start\":59594},{\"end\":59606,\"start\":59605},{\"end\":59615,\"start\":59614},{\"end\":60085,\"start\":60084},{\"end\":60094,\"start\":60093},{\"end\":60100,\"start\":60099},{\"end\":60107,\"start\":60106},{\"end\":60115,\"start\":60114},{\"end\":60535,\"start\":60534},{\"end\":60544,\"start\":60543},{\"end\":60551,\"start\":60550},{\"end\":60557,\"start\":60556},{\"end\":60569,\"start\":60568},{\"end\":60576,\"start\":60575},{\"end\":60583,\"start\":60582},{\"end\":60590,\"start\":60589},{\"end\":60598,\"start\":60597},{\"end\":60856,\"start\":60855},{\"end\":60858,\"start\":60857},{\"end\":61008,\"start\":61007},{\"end\":61021,\"start\":61020},{\"end\":61348,\"start\":61347},{\"end\":61360,\"start\":61359},{\"end\":61369,\"start\":61368},{\"end\":61727,\"start\":61726},{\"end\":61880,\"start\":61879},{\"end\":62143,\"start\":62142},{\"end\":62155,\"start\":62154},{\"end\":62161,\"start\":62160},{\"end\":62167,\"start\":62166},{\"end\":62176,\"start\":62175},{\"end\":62178,\"start\":62177},{\"end\":62185,\"start\":62184},{\"end\":62192,\"start\":62191},{\"end\":62194,\"start\":62193},{\"end\":62205,\"start\":62201},{\"end\":62211,\"start\":62210},{\"end\":62222,\"start\":62221},{\"end\":62224,\"start\":62223},{\"end\":62554,\"start\":62553},{\"end\":62560,\"start\":62559},{\"end\":62575,\"start\":62574},{\"end\":62585,\"start\":62584},{\"end\":62592,\"start\":62591},{\"end\":62836,\"start\":62835},{\"end\":62842,\"start\":62841},{\"end\":62849,\"start\":62848},{\"end\":62856,\"start\":62855},{\"end\":62862,\"start\":62861},{\"end\":63201,\"start\":63200},{\"end\":63207,\"start\":63206},{\"end\":63214,\"start\":63213},{\"end\":63220,\"start\":63219},{\"end\":63227,\"start\":63226},{\"end\":63238,\"start\":63237},{\"end\":63246,\"start\":63245},{\"end\":63260,\"start\":63259},{\"end\":63270,\"start\":63269},{\"end\":63278,\"start\":63277},{\"end\":63724,\"start\":63723},{\"end\":63734,\"start\":63733},{\"end\":63746,\"start\":63745},{\"end\":63755,\"start\":63754},{\"end\":64282,\"start\":64281},{\"end\":64295,\"start\":64294},{\"end\":64301,\"start\":64300},{\"end\":64303,\"start\":64302},{\"end\":64314,\"start\":64313},{\"end\":64621,\"start\":64620},{\"end\":64632,\"start\":64631},{\"end\":64645,\"start\":64644},{\"end\":64658,\"start\":64657},{\"end\":65014,\"start\":65013},{\"end\":65022,\"start\":65021},{\"end\":65024,\"start\":65023},{\"end\":65031,\"start\":65030},{\"end\":65042,\"start\":65041},{\"end\":65053,\"start\":65052},{\"end\":65061,\"start\":65060},{\"end\":65673,\"start\":65672},{\"end\":65675,\"start\":65674},{\"end\":65958,\"start\":65957},{\"end\":65967,\"start\":65966},{\"end\":65975,\"start\":65974},{\"end\":65983,\"start\":65982},{\"end\":65994,\"start\":65993},{\"end\":66001,\"start\":66000},{\"end\":66008,\"start\":66007},{\"end\":66019,\"start\":66018},{\"end\":66032,\"start\":66031},{\"end\":66046,\"start\":66045}]", "bib_author_last_name": "[{\"end\":51911,\"start\":51905},{\"end\":52272,\"start\":52265},{\"end\":52474,\"start\":52467},{\"end\":52487,\"start\":52478},{\"end\":52837,\"start\":52832},{\"end\":52844,\"start\":52841},{\"end\":52858,\"start\":52848},{\"end\":52868,\"start\":52862},{\"end\":53129,\"start\":53120},{\"end\":53142,\"start\":53133},{\"end\":53153,\"start\":53146},{\"end\":53164,\"start\":53157},{\"end\":53174,\"start\":53170},{\"end\":53603,\"start\":53601},{\"end\":53615,\"start\":53607},{\"end\":54052,\"start\":54049},{\"end\":54058,\"start\":54056},{\"end\":54066,\"start\":54062},{\"end\":54078,\"start\":54070},{\"end\":54581,\"start\":54576},{\"end\":54587,\"start\":54585},{\"end\":54594,\"start\":54591},{\"end\":54600,\"start\":54598},{\"end\":54606,\"start\":54604},{\"end\":54613,\"start\":54610},{\"end\":54621,\"start\":54617},{\"end\":54633,\"start\":54625},{\"end\":55089,\"start\":55085},{\"end\":55095,\"start\":55093},{\"end\":55104,\"start\":55099},{\"end\":55110,\"start\":55108},{\"end\":55117,\"start\":55114},{\"end\":55125,\"start\":55121},{\"end\":55137,\"start\":55129},{\"end\":55853,\"start\":55844},{\"end\":56141,\"start\":56132},{\"end\":56153,\"start\":56145},{\"end\":56477,\"start\":56468},{\"end\":56487,\"start\":56481},{\"end\":56498,\"start\":56491},{\"end\":56828,\"start\":56819},{\"end\":56838,\"start\":56832},{\"end\":56849,\"start\":56842},{\"end\":56859,\"start\":56853},{\"end\":57600,\"start\":57595},{\"end\":57611,\"start\":57604},{\"end\":57619,\"start\":57615},{\"end\":57626,\"start\":57623},{\"end\":57633,\"start\":57630},{\"end\":57640,\"start\":57637},{\"end\":57649,\"start\":57644},{\"end\":57662,\"start\":57655},{\"end\":57670,\"start\":57666},{\"end\":57684,\"start\":57674},{\"end\":58057,\"start\":58052},{\"end\":58063,\"start\":58061},{\"end\":58069,\"start\":58067},{\"end\":58076,\"start\":58073},{\"end\":58087,\"start\":58080},{\"end\":58095,\"start\":58091},{\"end\":58107,\"start\":58099},{\"end\":58715,\"start\":58711},{\"end\":58721,\"start\":58719},{\"end\":58733,\"start\":58725},{\"end\":58750,\"start\":58742},{\"end\":58758,\"start\":58754},{\"end\":58770,\"start\":58762},{\"end\":59188,\"start\":59181},{\"end\":59200,\"start\":59192},{\"end\":59212,\"start\":59204},{\"end\":59223,\"start\":59216},{\"end\":59571,\"start\":59568},{\"end\":59577,\"start\":59575},{\"end\":59585,\"start\":59581},{\"end\":59592,\"start\":59589},{\"end\":59603,\"start\":59596},{\"end\":59612,\"start\":59607},{\"end\":59624,\"start\":59616},{\"end\":60091,\"start\":60086},{\"end\":60097,\"start\":60095},{\"end\":60104,\"start\":60101},{\"end\":60112,\"start\":60108},{\"end\":60124,\"start\":60116},{\"end\":60541,\"start\":60536},{\"end\":60548,\"start\":60545},{\"end\":60554,\"start\":60552},{\"end\":60566,\"start\":60558},{\"end\":60573,\"start\":60570},{\"end\":60580,\"start\":60577},{\"end\":60587,\"start\":60584},{\"end\":60595,\"start\":60591},{\"end\":60606,\"start\":60599},{\"end\":60866,\"start\":60859},{\"end\":61018,\"start\":61009},{\"end\":61036,\"start\":61022},{\"end\":61357,\"start\":61349},{\"end\":61366,\"start\":61361},{\"end\":61379,\"start\":61370},{\"end\":61733,\"start\":61728},{\"end\":61890,\"start\":61881},{\"end\":62152,\"start\":62144},{\"end\":62158,\"start\":62156},{\"end\":62164,\"start\":62162},{\"end\":62173,\"start\":62168},{\"end\":62182,\"start\":62179},{\"end\":62189,\"start\":62186},{\"end\":62199,\"start\":62195},{\"end\":62208,\"start\":62206},{\"end\":62219,\"start\":62212},{\"end\":62230,\"start\":62225},{\"end\":62557,\"start\":62555},{\"end\":62572,\"start\":62561},{\"end\":62582,\"start\":62576},{\"end\":62589,\"start\":62586},{\"end\":62598,\"start\":62593},{\"end\":62839,\"start\":62837},{\"end\":62846,\"start\":62843},{\"end\":62853,\"start\":62850},{\"end\":62859,\"start\":62857},{\"end\":62865,\"start\":62863},{\"end\":63204,\"start\":63202},{\"end\":63211,\"start\":63208},{\"end\":63217,\"start\":63215},{\"end\":63224,\"start\":63221},{\"end\":63235,\"start\":63228},{\"end\":63243,\"start\":63239},{\"end\":63257,\"start\":63247},{\"end\":63267,\"start\":63261},{\"end\":63275,\"start\":63271},{\"end\":63282,\"start\":63279},{\"end\":63731,\"start\":63725},{\"end\":63743,\"start\":63735},{\"end\":63752,\"start\":63747},{\"end\":63763,\"start\":63756},{\"end\":64292,\"start\":64283},{\"end\":64298,\"start\":64296},{\"end\":64311,\"start\":64304},{\"end\":64323,\"start\":64315},{\"end\":64629,\"start\":64622},{\"end\":64642,\"start\":64633},{\"end\":64655,\"start\":64646},{\"end\":64667,\"start\":64659},{\"end\":65019,\"start\":65015},{\"end\":65028,\"start\":65025},{\"end\":65039,\"start\":65032},{\"end\":65050,\"start\":65043},{\"end\":65058,\"start\":65054},{\"end\":65071,\"start\":65062},{\"end\":65683,\"start\":65676},{\"end\":65964,\"start\":65959},{\"end\":65972,\"start\":65968},{\"end\":65980,\"start\":65976},{\"end\":65991,\"start\":65984},{\"end\":65998,\"start\":65995},{\"end\":66005,\"start\":66002},{\"end\":66016,\"start\":66009},{\"end\":66029,\"start\":66020},{\"end\":66043,\"start\":66033},{\"end\":66053,\"start\":66047}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":3434387},\"end\":52214,\"start\":51817},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":7051992},\"end\":52463,\"start\":52216},{\"attributes\":{\"id\":\"b2\"},\"end\":52773,\"start\":52465},{\"attributes\":{\"doi\":\"arXiv:1703.00395\",\"id\":\"b3\"},\"end\":53045,\"start\":52775},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":4718798},\"end\":53542,\"start\":53047},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":8296694},\"end\":53906,\"start\":53544},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":2178023},\"end\":54475,\"start\":53908},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":53358213},\"end\":54965,\"start\":54477},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":219719709},\"end\":55795,\"start\":54967},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":15277033},\"end\":56073,\"start\":55797},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":12262331},\"end\":56399,\"start\":56075},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":28157634},\"end\":56723,\"start\":56401},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":57661300},\"end\":57126,\"start\":56725},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":198465736},\"end\":57508,\"start\":57128},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":226299516},\"end\":57951,\"start\":57510},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":207925294},\"end\":58611,\"start\":57953},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":235616415},\"end\":59113,\"start\":58613},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":21543904},\"end\":59470,\"start\":59115},{\"attributes\":{\"id\":\"b18\"},\"end\":59982,\"start\":59472},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":52200248},\"end\":60470,\"start\":59984},{\"attributes\":{\"id\":\"b20\"},\"end\":60809,\"start\":60472},{\"attributes\":{\"id\":\"b21\"},\"end\":60934,\"start\":60811},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":5132658},\"end\":61254,\"start\":60936},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":20280062},\"end\":61658,\"start\":61256},{\"attributes\":{\"id\":\"b24\"},\"end\":61820,\"start\":61660},{\"attributes\":{\"id\":\"b25\"},\"end\":62060,\"start\":61822},{\"attributes\":{\"id\":\"b26\"},\"end\":62459,\"start\":62062},{\"attributes\":{\"id\":\"b27\"},\"end\":62755,\"start\":62461},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":221887792},\"end\":63121,\"start\":62757},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":51924604},\"end\":63637,\"start\":63123},{\"attributes\":{\"id\":\"b30\"},\"end\":64173,\"start\":63639},{\"attributes\":{\"id\":\"b31\"},\"end\":64539,\"start\":64175},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":14381533},\"end\":64941,\"start\":64541},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":2909637},\"end\":65612,\"start\":64943},{\"attributes\":{\"id\":\"b34\"},\"end\":65850,\"start\":65614},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":239036980},\"end\":66607,\"start\":65852},{\"attributes\":{\"id\":\"b36\"},\"end\":66728,\"start\":66609},{\"attributes\":{\"id\":\"b37\"},\"end\":66844,\"start\":66730}]", "bib_title": "[{\"end\":51899,\"start\":51817},{\"end\":52259,\"start\":52216},{\"end\":53116,\"start\":53047},{\"end\":53597,\"start\":53544},{\"end\":54045,\"start\":53908},{\"end\":54572,\"start\":54477},{\"end\":55081,\"start\":54967},{\"end\":55840,\"start\":55797},{\"end\":56128,\"start\":56075},{\"end\":56464,\"start\":56401},{\"end\":56815,\"start\":56725},{\"end\":57253,\"start\":57128},{\"end\":57591,\"start\":57510},{\"end\":58048,\"start\":57953},{\"end\":58707,\"start\":58613},{\"end\":59177,\"start\":59115},{\"end\":59562,\"start\":59472},{\"end\":60082,\"start\":59984},{\"end\":61005,\"start\":60936},{\"end\":61345,\"start\":61256},{\"end\":61877,\"start\":61822},{\"end\":62833,\"start\":62757},{\"end\":63198,\"start\":63123},{\"end\":64618,\"start\":64541},{\"end\":65011,\"start\":64943},{\"end\":65670,\"start\":65614},{\"end\":65955,\"start\":65852}]", "bib_author": "[{\"end\":51913,\"start\":51901},{\"end\":52274,\"start\":52261},{\"end\":52476,\"start\":52465},{\"end\":52489,\"start\":52476},{\"end\":52839,\"start\":52830},{\"end\":52846,\"start\":52839},{\"end\":52860,\"start\":52846},{\"end\":52870,\"start\":52860},{\"end\":53131,\"start\":53118},{\"end\":53144,\"start\":53131},{\"end\":53155,\"start\":53144},{\"end\":53166,\"start\":53155},{\"end\":53176,\"start\":53166},{\"end\":53605,\"start\":53599},{\"end\":53617,\"start\":53605},{\"end\":54054,\"start\":54047},{\"end\":54060,\"start\":54054},{\"end\":54068,\"start\":54060},{\"end\":54080,\"start\":54068},{\"end\":54583,\"start\":54574},{\"end\":54589,\"start\":54583},{\"end\":54596,\"start\":54589},{\"end\":54602,\"start\":54596},{\"end\":54608,\"start\":54602},{\"end\":54615,\"start\":54608},{\"end\":54623,\"start\":54615},{\"end\":54635,\"start\":54623},{\"end\":55091,\"start\":55083},{\"end\":55097,\"start\":55091},{\"end\":55106,\"start\":55097},{\"end\":55112,\"start\":55106},{\"end\":55119,\"start\":55112},{\"end\":55127,\"start\":55119},{\"end\":55139,\"start\":55127},{\"end\":55855,\"start\":55842},{\"end\":56143,\"start\":56130},{\"end\":56155,\"start\":56143},{\"end\":56479,\"start\":56466},{\"end\":56489,\"start\":56479},{\"end\":56500,\"start\":56489},{\"end\":56830,\"start\":56817},{\"end\":56840,\"start\":56830},{\"end\":56851,\"start\":56840},{\"end\":56861,\"start\":56851},{\"end\":57602,\"start\":57593},{\"end\":57613,\"start\":57602},{\"end\":57621,\"start\":57613},{\"end\":57628,\"start\":57621},{\"end\":57635,\"start\":57628},{\"end\":57642,\"start\":57635},{\"end\":57651,\"start\":57642},{\"end\":57664,\"start\":57651},{\"end\":57672,\"start\":57664},{\"end\":57686,\"start\":57672},{\"end\":58059,\"start\":58050},{\"end\":58065,\"start\":58059},{\"end\":58071,\"start\":58065},{\"end\":58078,\"start\":58071},{\"end\":58089,\"start\":58078},{\"end\":58097,\"start\":58089},{\"end\":58109,\"start\":58097},{\"end\":58717,\"start\":58709},{\"end\":58723,\"start\":58717},{\"end\":58735,\"start\":58723},{\"end\":58752,\"start\":58735},{\"end\":58760,\"start\":58752},{\"end\":58772,\"start\":58760},{\"end\":59190,\"start\":59179},{\"end\":59202,\"start\":59190},{\"end\":59214,\"start\":59202},{\"end\":59225,\"start\":59214},{\"end\":59573,\"start\":59564},{\"end\":59579,\"start\":59573},{\"end\":59587,\"start\":59579},{\"end\":59594,\"start\":59587},{\"end\":59605,\"start\":59594},{\"end\":59614,\"start\":59605},{\"end\":59626,\"start\":59614},{\"end\":60093,\"start\":60084},{\"end\":60099,\"start\":60093},{\"end\":60106,\"start\":60099},{\"end\":60114,\"start\":60106},{\"end\":60126,\"start\":60114},{\"end\":60543,\"start\":60534},{\"end\":60550,\"start\":60543},{\"end\":60556,\"start\":60550},{\"end\":60568,\"start\":60556},{\"end\":60575,\"start\":60568},{\"end\":60582,\"start\":60575},{\"end\":60589,\"start\":60582},{\"end\":60597,\"start\":60589},{\"end\":60608,\"start\":60597},{\"end\":60868,\"start\":60855},{\"end\":61020,\"start\":61007},{\"end\":61038,\"start\":61020},{\"end\":61359,\"start\":61347},{\"end\":61368,\"start\":61359},{\"end\":61381,\"start\":61368},{\"end\":61735,\"start\":61726},{\"end\":61892,\"start\":61879},{\"end\":62154,\"start\":62142},{\"end\":62160,\"start\":62154},{\"end\":62166,\"start\":62160},{\"end\":62175,\"start\":62166},{\"end\":62184,\"start\":62175},{\"end\":62191,\"start\":62184},{\"end\":62201,\"start\":62191},{\"end\":62210,\"start\":62201},{\"end\":62221,\"start\":62210},{\"end\":62232,\"start\":62221},{\"end\":62559,\"start\":62553},{\"end\":62574,\"start\":62559},{\"end\":62584,\"start\":62574},{\"end\":62591,\"start\":62584},{\"end\":62600,\"start\":62591},{\"end\":62841,\"start\":62835},{\"end\":62848,\"start\":62841},{\"end\":62855,\"start\":62848},{\"end\":62861,\"start\":62855},{\"end\":62867,\"start\":62861},{\"end\":63206,\"start\":63200},{\"end\":63213,\"start\":63206},{\"end\":63219,\"start\":63213},{\"end\":63226,\"start\":63219},{\"end\":63237,\"start\":63226},{\"end\":63245,\"start\":63237},{\"end\":63259,\"start\":63245},{\"end\":63269,\"start\":63259},{\"end\":63277,\"start\":63269},{\"end\":63284,\"start\":63277},{\"end\":63733,\"start\":63723},{\"end\":63745,\"start\":63733},{\"end\":63754,\"start\":63745},{\"end\":63765,\"start\":63754},{\"end\":64294,\"start\":64281},{\"end\":64300,\"start\":64294},{\"end\":64313,\"start\":64300},{\"end\":64325,\"start\":64313},{\"end\":64631,\"start\":64620},{\"end\":64644,\"start\":64631},{\"end\":64657,\"start\":64644},{\"end\":64669,\"start\":64657},{\"end\":65021,\"start\":65013},{\"end\":65030,\"start\":65021},{\"end\":65041,\"start\":65030},{\"end\":65052,\"start\":65041},{\"end\":65060,\"start\":65052},{\"end\":65073,\"start\":65060},{\"end\":65685,\"start\":65672},{\"end\":65966,\"start\":65957},{\"end\":65974,\"start\":65966},{\"end\":65982,\"start\":65974},{\"end\":65993,\"start\":65982},{\"end\":66000,\"start\":65993},{\"end\":66007,\"start\":66000},{\"end\":66018,\"start\":66007},{\"end\":66031,\"start\":66018},{\"end\":66045,\"start\":66031},{\"end\":66055,\"start\":66045}]", "bib_venue": "[{\"end\":51961,\"start\":51957},{\"end\":52571,\"start\":52554},{\"end\":53305,\"start\":53249},{\"end\":53705,\"start\":53688},{\"end\":54168,\"start\":54151},{\"end\":54700,\"start\":54683},{\"end\":55377,\"start\":55258},{\"end\":58312,\"start\":58219},{\"end\":59705,\"start\":59688},{\"end\":60205,\"start\":60188},{\"end\":61432,\"start\":61415},{\"end\":65293,\"start\":65183},{\"end\":66258,\"start\":66165},{\"end\":51955,\"start\":51913},{\"end\":52315,\"start\":52274},{\"end\":52552,\"start\":52489},{\"end\":52828,\"start\":52775},{\"end\":53247,\"start\":53176},{\"end\":53686,\"start\":53617},{\"end\":54149,\"start\":54080},{\"end\":54681,\"start\":54635},{\"end\":55256,\"start\":55139},{\"end\":55911,\"start\":55855},{\"end\":56211,\"start\":56155},{\"end\":56536,\"start\":56500},{\"end\":56899,\"start\":56861},{\"end\":57291,\"start\":57255},{\"end\":57716,\"start\":57686},{\"end\":58217,\"start\":58109},{\"end\":58838,\"start\":58772},{\"end\":59262,\"start\":59225},{\"end\":59686,\"start\":59626},{\"end\":60186,\"start\":60126},{\"end\":60532,\"start\":60472},{\"end\":60853,\"start\":60811},{\"end\":61068,\"start\":61038},{\"end\":61413,\"start\":61381},{\"end\":61724,\"start\":61660},{\"end\":61918,\"start\":61892},{\"end\":62140,\"start\":62062},{\"end\":62551,\"start\":62461},{\"end\":62929,\"start\":62867},{\"end\":63353,\"start\":63284},{\"end\":63721,\"start\":63639},{\"end\":64279,\"start\":64175},{\"end\":64692,\"start\":64669},{\"end\":65181,\"start\":65073},{\"end\":65707,\"start\":65685},{\"end\":66163,\"start\":66055},{\"end\":66628,\"start\":66609},{\"end\":66759,\"start\":66730}]"}}}, "year": 2023, "month": 12, "day": 17}