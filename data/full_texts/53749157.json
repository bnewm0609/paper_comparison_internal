{"id": 53749157, "updated": "2023-09-30 10:00:03.798", "metadata": {"title": "On Filter Size in Graph Convolutional Networks", "authors": "[{\"first\":\"Dinh\",\"last\":\"Tran\",\"middle\":[\"Van\"]},{\"first\":\"Nicolo\",\"last\":\"Navarin\",\"middle\":[]},{\"first\":\"Alessandro\",\"last\":\"Sperduti\",\"middle\":[]}]", "venue": "IEEE Symposium on Deep Learning, 2018 Symposium Series on Computational Intelligence, 18 - 21 November, 2018, Bengaluru, India", "journal": null, "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "Recently, many researchers have been focusing on the definition of neural networks for graphs. The basic component for many of these approaches remains the graph convolution idea proposed almost a decade ago. In this paper, we extend this basic component, following an intuition derived from the well-known convolutional filters over multi-dimensional tensors. In particular, we derive a simple, efficient and effective way to introduce a hyper-parameter on graph convolutions that influences the filter size, i.e. its receptive field over the considered graph. We show with experimental results on real-world graph datasets that the proposed graph convolutional filter improves the predictive performance of Deep Graph Convolutional Networks.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1811.10435", "mag": "2963280944", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/ssci/TranNS18", "doi": "10.1109/ssci.2018.8628758"}}, "content": {"source": {"pdf_hash": "5de994cd9db8f02b663315c3dd4b03cc8ea9d5b3", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1811.10435v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1811.10435", "status": "GREEN"}}, "grobid": {"id": "5271eb39b0f6fa1808f593b43658df2a3db133fb", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/5de994cd9db8f02b663315c3dd4b03cc8ea9d5b3.txt", "contents": "\nOn Filter Size in Graph Convolutional Networks\n\n\nDinh V Tran \nNicol\u00f2 Navarin nnavarin@math.unipd.it \nAlessandro Sperduti sperduti@math.unipd.it \n\nDepartment of Mathematics\nDepartment of Computer Science\n\u2020 Bioinformatics Group\nUniversity of Padova\nItaly\n\n\nSchool of Computer Science\nUniversity of Freiburg\nGermany\n\n\nUniversity of Nottingham\nUnited Kingdom\n\nOn Filter Size in Graph Convolutional Networks\nIndex Terms-graphsdeep learning for graphsgraph convo- lutionconvolutional neural networks for graphs\nRecently, many researchers have been focusing on the definition of neural networks for graphs. The basic component for many of these approaches remains the graph convolution idea proposed almost a decade ago. In this paper, we extend this basic component, following an intuition derived from the well-known convolutional filters over multi-dimensional tensors. In particular, we derive a simple, efficient and effective way to introduce a hyper-parameter on graph convolutions that influences the filter size, i.e. its receptive field over the considered graph. We show with experimental results on real-world graph datasets that the proposed graph convolutional filter improves the predictive performance of Deep Graph Convolutional Networks.\n\nI. INTRODUCTION\n\nGraphs are a common and natural way to represent many real world data, e.g. in Chemistry a compound can be represented by its molecular graph, in social networks the relationships between users are represented as edges in a graph where users are nodes. Many computational tasks involving such graphical representations require machine learning, such as classification of active/non-active drugs or prediction of the creation of a future link between two users in a social network. State-of-the-art machine learning techniques for classification and regression on graphs are at the moment kernel machines equipped with specifically designed kernels for graphs (e.g, [1]- [3]). Although there are examples of kernels for structures that can be designed on the basis of a training set [4]- [6], most of the more efficient and effective graph kernels are based on predefined structural features, i.e, features definition is not part of the learning process.\n\nThere is a recent shift of trend from kernels to neural networks for graphs. Unlike kernels, the definition of features in neural networks are defined based on a learning process which is supervised by the graph's labels (targets). Many approaches have addressed the problem of defining neural networks for graphs [7]. However, one of the core components, the graph convolution, has not changed much with respect to the earlier works [8], [9].\n\nIn this paper, we work on the re-design of this basic component. We propose a new formulation for the graph convolution operator that is strictly more general than the existing one. Our proposal can be virtually applied to all the techniques based on graph convolutions.\n\nThe paper is organized as follows. We start in Section II with some basic definitions and notation. In Section III, we provide an overview over the various proposals of graph convolution available in literature. In Section IV we detail our proposed parametric graph convolutional filter. In Section V we discuss other related works that are not based on graph convolution, including some alternative graph neural network architectures and graph kernels. In Section VI we report our experimental results. Finally, Section VII concludes the paper.\n\n\nII. NOTATION AND DEFINITIONS\n\nWe denote matrices with bold uppercase letters, vectors with uppercase letters, and variables with lowercase letters. Given a matrix M, M i denotes the i-th row of the matrix, and m ij is the element in i-th row and j-th column. Given the vector V , v i refers its i-th element.\n\nLet's consider G = (V G , E G , X G ) as a graph, where V G = {v 1 , . . . , v n } is the set of vertices (or nodes), E G \u2286 V G \u00d7 V G is the set of edges, and X G \u2208 R n\u00d7d is a node label matrix, where each row is the label (a vector of size d) associated to each vertex v i \u2208 V G , i.e. X G i = (x i,0 , . . . , x i,d ). Note that, in this paper, we will not consider edge labels. When the reference to the graph G is clear from the context, for the sake of notation we discard the superscript referring to the specific graph. We define the adjacency matrix A \u2208 R n\u00d7n as a ij = 1 \u21d0\u21d2 (i, j) \u2208 E, 0 otherwise. We also define the neighborhood of a vertex v as the set of vertices connected to v by an edge, i.e.\nN (v) = {u|(v, u) \u2208 E}. Note that N (v)\nis also the set of nodes at shortest path distance exactly one from v, i.e. N (v) = {u|sp(v, u) = 1}, where sp is a function computing the shortest-path distance between two nodes in a graph.\n\nIn this paper, we consider the problem of graph classification. Given a dataset composed of N pairs {(G i , y i )|1 \u2264 i \u2264 N }, the task is then, given an unseen graph G, to predict its correct target y.\n\n\nIII. GRAPH CONVOLUTIONS\n\nThe first definition of neural network for graphs has been proposed in [10]. More recent models have been proposed in [8], [9]. Both works are based on an idea that has been rebranded later as graph convolution.\n\nThe idea is to define the neural architecture following the topology of the graph. Then a transformation is performed from the neurons corresponding to a vertex and its neighborhood to a hidden representation, that is associated to the same vertex (possibly in another layer of the network). This transformation depends on some parameters, that are shared among all the nodes. In the following, for the sake of simplicity we ignore the bias terms.\n\nIn [9], when considering non-positional graphs, i.e. the most common definition, and the one we are considering in this paper, a transition function on a graph node v at time 0 \u2264 t is defined as:\nH t+1 v = u\u2208N (v) f \u0398 (H t u , X v , X u ),(1)\nwhere f \u0398 is a parametric function whose parameters \u0398 have to be learned (e.g. a neural network) and are shared among all the vertices. Note that, if edge labels are available, they can be included in eq. (1). In fact, in the original formulation, f \u0398 depends also on the label of the edge between v and u. This transition function is part of a recurrent system. It is defined as a contraction mapping, thus the system is guaranteed to converge to a fixed point, i.e. a representation, that does not depend on the particular initialization of the weight matrix H 0 . The output is computed from the last representation and the original node labels as follows:\nO t v = g \u0398 (H t v , X v ),(2)\nwhere g \u0398 is another neural network. [11] extends the work in [9] by removing the constraint for the recurrent system to be a contraction mapping, and replacing the recurrent units with GRUs. However, recently it has been shown in [12] that stacked graph convolutions are superior to graph recurrent architectures in terms of both accuracy and computational cost. In [8], a model referred to as Neural Network for Graphs (NN4G) is proposed. In the first layer, a transformation over node labels is computed:\nh 1 v = f \uf8eb \uf8ed d j=1w 1,j x v,j \uf8f6 \uf8f8 ,(3)\nwhereW 1 are the weights connecting the original labels X to the current neuron, and 1 \u2264 v \u2264 n is the vertex index. The graph convolution is then defined for the i + 1-th layer (for i > 0) as:\nh i+1 v = f \uf8eb \uf8ed d j=1w i+1,j x v,j + i k=1\u0175 i+1,k u\u2208N (v)\u0125 k u \uf8f6 \uf8f8 ,(4)\nwhere\u0174 i+1 are weights connecting the previous hidden layers to the current neuron (shared). Note that in this formulation, skip connections are present, to the (i+1)-th layer, from layer 1 to layer i. There is an interesting recent work about the parallel between skip-connections (residual networks in that case) Fig. 1: Graph convolution as described in [8], and adopted with some variations by many state-of-the-art Graph Convolutional neural networks. and recurrent networks [13]. However, since in the formulation in eq. (4), every layer is connected to all the subsequent layers, it is not possible to reconduct it to a (vanilla) recurrent model. Let us consider the (i + 1)-th graph convolutional layer, that comprehends c i+1 graph convolutional filters. We can rewrite eq. (4) for the whole layer as:\nH i+1 = f (XW i+1 + i k=1 AH k\u0174i+1,k ),(5)\nwhere i = 0, . . . , l \u2212 1 (and l is the number of layers), W i+1 \u2208 R d\u00d7ci+1 ,\u0174 i+1,k \u2208 R c k \u00d7ci+1 , H k \u2208 R n\u00d7c k , c i is the size of the hidden representation at the i-th layer, and f is applied element-wise. An abstract representation of eq. (4) is depicted in Figure 1. The convolution in eq. (4) is part of a multi-layer architecture, where each layer's connectivity resembles the topology of the graph, and the training is layer-wise. Finally, for each graph, NN4G computes the average graph node representation for each hidden layer, and concatenates them. This is the graph representation computed by NN4G, and it can be used for the final prediction of graph properties with a standard output layer.\n\nIn [14], a hierarchical approach has been proposed. This method is similar to NN4G and is inspired by circular fingerprints in chemical structures. While [8] adopts Cascade-Correlation for training, [14] uses an end-to-end backpropagation. ECC [15] proposes an improvement of [14], weighting the sum over the neighbors of a node by weights conditioned by the edge labels. We consider this last version as a baseline in our experiments.\n\nRecently, [16] derives a graph convolution that closely resembles (4). Let us, from now on, consider H 0 = X. Motivated by a first-order approximation of localized spectral filters on graphs, the proposed graph convolutional filter looks like:\nH i+1 = f (D \u2212 1 2\u00c3D \u2212 1 2 H i W i ),(6)\nwhere\u00c3 = A + I,d ii = j\u00e3 i,j , and f is any activation function applied element-wise.\n\nIf we ignore the termsD \u2212 1 2 (that in practice act as normalization), it is easy to see that eq. (6) is very similar to eq. (5), the difference being that there are no skip connections in this case, i.e. the (i + 1)-th layer is connected just to the i-th layer. Consequently, we just have to learn one weight matrix per layer.\n\nIn [17], a slightly more complex model compared to [16] is proposed. This model shows the highest predictive performance with respect to the other methods presented in this section. The first layers of the network are again stacked graph convolutional layers, defined as follows:\nH i+1 = f (D \u22121\u00c3 H i W i ),(7)\nwhere H 0 = X and\u00c3 = A + I. Note that in the previous equation, we compute the representation of all the nodes in the graph at once. The difference between eq. (7) and eq. (6) is the use of different propagation scheme for nodes' representations: eq. (6) is based on the normalized graph Laplacian, while eq. (7) is based on the random-walk graph Laplacian. In [17], authors state that the choice of normalization does not significantly affect the results. In fact, both equations can be seen as first-order approximations of the polynomially parameterized spectral graph convolution. In [17], three graph convolutional layers are stacked. The graph convolutions are followed by a concatenation layer that merges the representations computed by each graph convolutional layer. Then, differently from previous approaches, the paper introduces a sortpooling layer, that selects a fixed number of node representations, and computes the output from them stacking 1D convolutional layers and dense layers. This is the same network architecture that we considered in this paper.\n\n\nA. SortPooling layer\n\nAfter stacking some graph convolution layer, we need a mechanism to predict the target for the graph, starting from its node encoding. Ideally, this mechanism should be applicable to graphs with variable number of vertices. Instead of averaging the node representations, [17] proposes to solve this issue with the SortPooling layer.\n\nLet us assume that the encoding, for each node, of the ith graph convolution layer is c. Let us consider the output of the last graph convolution (or concatenation) layer to be H l \u2208 R n\u00d7c , where each row is a vertex's feature descriptor and each column is a feature channel. The output of the SortPooling layer is a k \u00d7 c tensor, where k is a user-defined integer.\n\nIn the SortPooling layer, the rows of H l are sorted lexicographically (possibly starting from the last column). We can see the output of the graph convolutional layer as continuous WL colors, and thus we are sorting all the vertices according to these colors. This way, a consistent ordering is imposed for graph vertices, making it possible to train traditional neural networks on the sorted graph representations.\n\nIn addition to sorting vertex features in a consistent order, the other function of SortPooling is to unify the sizes of the output tensors. After sorting, we truncate/extend the output tensor in the first dimension from n to k. The intention is to unify graph sizes, making graphs with different numbers of vertices unify their sizes to k. The unifying is done by deleting the last n \u2212 k rows if n > k, or adding k \u2212 n zero rows if n < k.\n\nNote that if two vertices have the same hidden representation, it doesn't matter which node we pick because the output of the SortPooling layer would be exactly the same.\n\n\nIV. PARAMETRIC GRAPH CONVOLUTIONS\n\nA straightforward generalization of eq. (7) would be defined on the powers of the adjacency matrix, i.e. on random walks [18]. This would introduce tottering in the learned representation, that is not considered to be beneficial in general. We decided to follow another approach, based on shortest-paths. As mentioned before, the adjacency matrix A of a graph can be seen as the matrix of the shortest-paths of length 1, i.e.\na i,j = sp 1 i,j = 1 if sp(i, j) = 1 0 otherwise .(8)\nMoreover, the identity matrix I is the matrix of the shortestpaths of length 0 (assuming that each node is at distance zero from itself), i.e. I = SP 0 . Moreover, note that A = SP 0 + SP 1 . By means of this new notation, we can rewrite eq. (7) as:\nH l+1 = f D \u22121 SP 0 + SP 1 H l W l .(9)\nLet us now defined r ii = j sp r i,j . We can now extend our reasoning and define our parameterized (by r) graph convolution layer. In our contribution, we decided to process information in a slightly different way with respect to (9). Instead of summing the contributions of the SP matrices, we decided to keep the contributions of the nodes at different shortest-path distance separated. This is equivalent to the definition of multiple graph convolutional filters, one for each shortest-path distance. We define the Parametric Graph Convolution as:\nH r,l+1 = r j=0 f (D j ) \u22121 SP j H l W j,l ,(10)\nwhere is the vertical concatenation of vectors. Note that with our formulation, we have a different W j,l matrix for each layer l and for each shortest-path distance j. Moreover, as mentioned before, we are concatenating the information and not summing it, explicitly keeping the contributions of the different distances separated. This approach follows the network-in-network idea [19]. In our case, at each layer, we are effectively applying, at the same time, r + 1 convolutions (one for each shortest-path distance) and concatenating their output. Let us fix a parameter controlling the number of filters for the l layer, say c l , and a value for the hyper-parameter r, then we have H r,l+1 \u2208 R n\u00d7r\u00b7c l . \n\n\nA. Receptive field\n\nIt has been shown in [16], [17] that with the standard definition of graph convolution, e.g. the ones in eq. (6) and eq. (7), the receptive field of a graph convolutional filter at layer l corresponding to the vertex v is N l (v). This draws an interesting parallel with the Weisfeiler-Lehman graph kernel (see Section V-A), where intuitively the number of WL iterations is equivalent to the number of stacked graph convolution layers in the architecture.\n\nIn our proposed parametric graph convolution in eq. (10), the r parameter directly influences the considered neighborhood in the graph convolutional filter (and the number of output channels, since we concatenate the output of the convolutions for all j \u2264 r). It is easy to see that, by definition, the receptive field of a graph convolutional filter parameterized by r and applied to the vertex v includes all the nodes at shortestpath distance at most r from v. When we stack multiple layers of our parametric graph convolution, the receptive field grows in the same way. The receptive field of a parametric graph convolutional filter of size r at layer l applied to the vertex v includes then all the vertices at shortest-path distance at most l \u00b7 r from v.\n\n\nB. Computational complexity\n\nEquation (10) requires to compute the all-pairs shortest paths, up to a fixed length r. While computing the unbounded shortest paths for a graph with n nodes requires O(n 3 ) time, if the maximum length is small enough, it is possible to implement it with one depth-limited breadth-first visit starting from each node, with an overall complexity of O(m r ), where m is the number of edges in a graph.\n\n\nV. RELATED WORKS\n\nBesides the approaches based on graph convolutions presented in Section III, there are some other methods in literature to process graphs with neural networks.\n\nFor instance, [20] defined an attention mechanism to propagate information between the nodes in a graph. The basic idea is the definition of an external network that, given two neighboring nodes, outputs an attention weight for that specific edge. A shared attentive mechanism a : R d \u00d7 R d \u2192 R computes the attention coefficients\ne v,u = a \u0398 (WX v , WX u ),(11)\nthat indicate the importance of node u's features to node v.\n\nHere, a \u0398 is a parametric function, that in the original paper is a single-layer feed-forward network parameterized by the vector \u0398 \u2208 R 2d . The information about the graph structure is injected into the mechanism by performing masked attention, i.e. e v,u is only computed for nodes u \u2208 N (v). To make coefficients easily comparable across different nodes, a softmax function is used:\nb v,u = sof tmax u (e v,u ) = exp(e v,u ) k\u2208N (v) exp(e v,k ) .(12)\nOnce obtained, the normalized attention coefficients are used to compute a linear combination of the features corresponding to them, to serve as the final output features for every node (after potentially applying a point-wise nonlinearity, f ):\nH v = f \uf8eb \uf8ed u\u2208N (v) b vu WX u \uf8f6 \uf8f8 .(13)\nTo stabilize the learning process of self-attention, authors propose to extending the mechanism to employ multi-head attention(K different attention weights per edge). For the last layer, authors employ averaging, and delay applying the final nonlinearity (usually a softmax or logistic sigmoid for classification problems) until then. This technique has been applied to node classification only, and its complexity (due to implementation issues) is high. In principle, the same approach of NN4G can be adopted to generate graph-level representations and predictions for this model. [21] (PSCN) proposes another interpretation of graph convolution. Given a graph, it first selects the nodes where the convolutional filter have to be centered. Then, it selects a fixed number of vertices from its neighborhood, and infers an order on them. This ordering constraint limits the flexibility of the approach because learning a consistent order is difficult, and the number of nodes in the convolutional filter has to be fixed a-priori.\n\nDiffusion CNN (DCNN) [22] is based on the principle of heat diffusion (on graphs). The idea is to map from nodes and their labels to the result of a diffusion process that begins at that node. \n\n\nA. Graph Kernels\n\nKernel methods defines the model as a linear classifier in a Reproducing Kernel Hilbert Space, that is the space implicitly defined by a kernel function K(x 1 , x 2 ) = \u03c6(x 1 ), \u03c6(x 2 ) . SVM is the most popular kernelized learning algorithm, that defines the solution as the maximum-margin hyper-plane.\n\nKernel functions can be defined for many objects, and in particular for graphs. Many graph kernels have been defined in literature. For instance, Random Walk kernels are based on the number of common random walks in two graphs [2], [23] and can be computed efficiently in closed form. More recent proposals focus on more complex structures, and allow to represent the \u03c6 function explicitly, with computational benefits. Among others, kernels have been defined considering graphlets [24], shortest-paths [25], subtrees [26], [27] and subtree-walks [28], [29]. For instance, the Weisfeiler-Lehman subtree kernel (WL) defines its features as rooted subtreewalks, i.e, subtrees whose nodes can appear multiple times, up to a user-defined maximum height h (maximum number of iterations).\n\nPropagation kernels (PK) [30] follow a different idea, inspired by the diffusion process in graph node kernels (i.e. kernels between nodes in a single graph), of propagating the node label information through the edges in a graph. Then, for each node, a distribution over the propagated labels is computed. Finally, the kernel between two graphs compares such distributions over all the nodes in the two graphs.\n\nWhile exhibiting state-of-the-art performance on many graph datasets, the main problem of graph kernels is that they define a fixed representation, that is not task-dependent and can in principle limit the predictive performance of the method. Deep graph kernels (DGK) [31] propose an approach to alleviate this problem. Let us fix a base kernel and its explicit representation \u03c6(\u00b7). Then a deep graph kernel can be defined as:\nDGK(x 1 , x 2 ) = \u03c6(x 1 ) T M\u03c6(x 2 ),\nwhere M is a matrix of parameters that has to be learned, possibly including target information.\n\n\nVI. EXPERIMENTS\n\nIn this section, we aim at evaluating the performance of the proposed method and comparing it with many existing graph kernels and deep learning approaches for graphs. We pay a special attention to the performances of our method and DGCNN, to see whether the proposed generalization helps to improve the predictive performance. As a means to achieve this purpose, various experiments are conducted in two settings, following the experimental procedure used in [17] on eight graph datasets (see Table I for a summary). The code for our experiments is available online at https://github.com/dinhinfotech/PGC-DGCNN.\n\nIn the first setting, we compare the performance of our method with DGCNN and state-of-the-art graph kernels: the graphlet kernel (GK) [1], the random walk kernel (RW) [2], the propagation kernel (PK) [30], and the Weisfeiler-Lehman subtree kernel (WL) [32]. We do not include other state-ofthe-art graph kernels such as NSPDK [33] and ODD [26] because their performance is not much different from the considered ones, and it is above the scope of this paper to extensively compare the graph kernels in literature. In this setting, five datasets containing biological node-labeled graphs are employed, namely MUTAG [34], PTC [35], NCI1 [36], PROTEINS, and D&D [37]. In the first three datasets, each graph represents a chemical compound, where nodes are labeled with the atom type, and edges represent bonds between them. MUTAG is a dataset of aromatic and hetero-aromatic nitro compounds, where the task is to predict their mutagenic effect on a bacterium. In PTC, the task is to predict chemical compounds carcinogenicity for male and female rats. NCI1 contains anti-cancer screens for cell lung cancer. In PRO-TEINS and D&D, each graph represents a protein. The nodes are labeled according to the amino-acid type. The proteins are classified into two classes: enzymes and non-enzymes.\n\nIn the second setting, we desire to evaluate the performance of the proposed method and DGCNN along with other deep learning approaches for graphs: PATCHY-SAN (PSCN) [21], Diffusion CNN (DCNN) [22], ECC [15] and Deep Graphlet Kernel (DGK) [31]. In this setting, three biological datasets (NCI1, PROTEINS and D&D) and three social network datasets from [31] (COLLAB, IMDB-B and IMDB-M) are used. COLLAB is a dataset of scientific collaborations, where ego-networks are generated for researchers and are classified in three research fields. IMDB-B (binary) is a movie collaboration dataset where ego-networks for actors/actresses are classified in action or romance genres. IMDB-M is a multiclass version of IMDB-B, containing genres comedy, romance, and sci-fi.\n\nIn this setting, we eliminate MUTAG and PTC since they have a small number of examples which easily causes overfitting problems for deep learning approaches. Evaluation method and model selection: to evaluate the different methods, a nested 10-fold cross-validation is employed, i.e, one fold for testing, 9 folds for training of which one is  used as validation set for model selection. For each dataset, we repeated each experiment 10 times and report the average accuracy over the 100 resulting folds. To select the best model, the hyper-parameters' values of different kernels are set as follows: the height of WL and PK in {0, 1, 2, 3, 4, 5}, the bin width of PK to 0.001, the size of the graphlets in GK to 3 and the decay of RW to the largest power of 10 that is smaller than the reciprocal of the squared maximum node degree. Note that some of our results are reported from [17]. Network architecture: we employ the network architecture used in [17] to have a fair comparison with DGCNN. The network consists of three graph convolution layers, a concatenation layer, a SortPooling layer, followed by two 1-D convolutional layers and one dense layer. The activation function for the graph convolutions is the hyperbolic tangent, while the 1D convolutions and the dense layer use rectified linear units. Note that our proposal, as presented in Section IV, is a generalization of DGCNN. In other words, DGCNN is very similar to a special case of our method where just the neighbors at shortest-path distance 1 are considered. On the contrary, our proposal considers the distance as a hyperparameter, r, allowing to flexibly capture local structures associated to graph nodes. In this section, we set r equal to 2 as the first attempt and plan to explore neighborhoods with nodes at a higher distance as a future work.\n\n\nA. Experimental Results\n\nTable II and III show the performance of various methods in the first and second settings, respectively. Overall, DGCNN and our proposed method outperform the compared kernels and deep learning methods in most datasets.\n\nAs can be seen from Table II, DGCNN and the proposed method (PGC-DGCNN) present higher performances in four out of five datasets with an improvement ranging from 1.03% to 3.11% with respect to the best performing kernel. Compared to the RW kernel, our proposed method impressively achieves the highest improvement in MUTAG and PROTEINS with about 8% and 17%, respectively. Concerning PK and WL, that are similar in spirit to DGCNN and our method as shown in [17], DGCNN and PGC-DGCNN illustrate higher performances in most cases with a bigger difference comparing with PK. It is worth noticing, when comparing with PK and WL, that their optimal models in each experiment are selected by tuning the height parameter, h, from a range of pre-defined values. Instead, DGCNN and our method are evaluated with a fixed number of layers only. This indicates that the performance of DGCNN and the proposed method can be higher if we validate the number of stacked graph convolutional layers.\n\nRelated to the performances of various deep learning methods described in Table III, our method and DGCNN obtain the highest results in five out of six cases, except in NCI1 where they show marginally lower results. Considering the performance of DCNN, DGCNN and our method gain dramatically higher accuracies with the improvement ranges from around 14% and up to 21%.\n\nWe now move our consideration to the difference between the performances of DGCNN and our proposal. It can be seen from the Table II and III that our method performs better than DGCNN in the majority of the datasets. In particular, PGC-DGCNN outperforms DGCNN in six out of eight cases with a consistent improvement from about 1% to 2%. In D&D and IMDB-M, the accuracy of our method is slightly lower than DGCNN. However, these declines are only marginal. The general improved performance of our method comparing to DGCNN can be explained by the fact that our method parameterizes the graph convolutions, making it a generalization of DGCNN. (we recall that we fix the neighborhood distance r = 2). In this case, our method captures more information about the local graph structure associated to each node comparing to DGCNN which considers just the direct neighbors, i.e. r = 1. It is worth to notice that (1) we use a single value for r to build our model. However, in general, we can choose an optimal model by tuning values from a range of values for r; (2) we utilize the architecture as proposed in [17], meaning that we have not tried to optimize the network architecture. Therefore, the performance of our method can improve if we optimize the distance parameter r and the number of graph convolutional layers, together with the rest of the architecture.\n\n\nVII. CONCLUSIONS AND FUTURE WORKS\n\nIn this paper, we presented a new definition of graph convolutional filter. It generalizes the most commonly adopted filter, adding an hyper-parameter controlling the distance of the considered neighborhood. Experimental results show that our proposed filter improves the predictive performance of Deep graph Convolutional Neural Networks on many realworld datasets.\n\nIn future, we plan to analyze more in depth the impact of filter size in graph convolutional networks. We will define the 1D convolutions as special cases of Graph Convolutions, and we will explore Fully Graph-Convolutional neural architectures, that will avoid fully-connected layers, and possibly stack more graph convolution layers. Moreover, we will explore the impact of different activation functions for the graph convolutions in such a setting. Finally, we plan to enhance the input graph representation associating to each node the explicit features extracted by graph kernels.\n\nFig. 2 :\n2The proposed Parametric Graph Convolution. The parameter r controls the maximum distance of the considered neighborhood, and the dimensionality of the output.\n\nTABLE I :\nISummary of employed graph datasetsDataset \nMUTAG \nPTC \nNCI1 PROTEINS \nD&D \nCOLLAB IMDB-B IMDB-M \n\n#Nodes (Max) \n28 \n109 \n111 \n620 \n5748 \n492 \n136 \n89 \n\n#Nodes (Avg) \n17.93 \n25.56 \n29.87 \n39.06 \n284.32 \n74.49 \n19.77 \n13.00 \n\n#Graphs \n188 \n344 \n4110 \n1113 \n1178 \n5000 \n1000 \n1500 \n\n\n\nTABLE II :\nIIComparison with graph kernels. * : our proposed approach. DGCNN is similar to our approach with r = 1.Dataset \nMUTAG \nPTC \nNCI1 \nPROTEINS \nD&D \n\nGK \n81.39\u00b11.74 55.65\u00b10.46 62.49\u00b10.27 \n71.39\u00b10.31 \n74.38\u00b10.69 \n\nRW \n79.17\u00b12.07 55.91\u00b10.32 \n>3 days \n59.57\u00b10.09 \n>3 days \n\nPK \n76.00\u00b12.69 59.50\u00b12.44 82.54\u00b10.47 \n73.68\u00b10.68 \n78.25\u00b10.51 \n\nWL \n84.11\u00b11.91 57.97\u00b12.49 \n84.46\u00b10.45 \n74.68\u00b10.49 \n78.34\u00b10.62 \n\nDGCNN \n85.83\u00b11.66 58.59\u00b12.47 74.44\u00b10.47 \n75.54\u00b10.94 \n79.37\u00b10.94 \n\nPGC-DGCNN  *  (r = 2) 87.22\u00b11.43 61.06\u00b11.83 \n76.13\u00b10.73 \n76.45\u00b11.02 \n78.93\u00b10.91 \n\n\n\nTABLE III :\nIIIComparison with other deep learning approaches. * : our proposed approach. DGCNN is similar to our approach with r = 1.Dataset \nNCI1 \nPROTEINS \nD&D \nCOLLAB \nIMDB-B \nIMDB-M \n\nPSCN \n76.34\u00b11.68 \n75.00\u00b12.51 \n76.27\u00b12.64 72.60\u00b12.15 71.00\u00b12.29 45.23\u00b12.84 \n\nDCNN \n56.61\u00b11.04 \n61.29\u00b11.60 \n58.09\u00b10.53 52.11\u00b10.71 49.06\u00b11.37 33.49\u00b11.42 \n\nECC \n76.82 \n-\n72.54 \n-\n-\n-\n\nDGK \n62.48\u00b10.25 \n71.68\u00b10.50 \n-\n73.09\u00b10.25 66.96\u00b10.56 44.55\u00b10.52 \n\nDGCNN \n74.44\u00b10.47 \n75.54\u00b10.94 \n79.37\u00b10.94 73.76\u00b10.49 70.03\u00b10.86 \n47.83\u00b10.85 \n\nPGC-DGCNN  *  \n76.13\u00b10.73 \n76.45\u00b11.02 \n78.93\u00b10.91 75.00\u00b10.58 71.62\u00b11.22 \n47.25\u00b11.44 \n\n\nACKNOWLEDGMENTThis project was funded, in part, by the Department of Mathematics, University of Padova, under the DEEP project and DFG project, BA 2168/3-3.\nEfficient graphlet kernels for large graph comparison. N Shervashidze, S Vishwanathan, T Petri, K Mehlhorn, K Borgwardt, Artificial Intelligence and Statistics. N. Shervashidze, S. Vishwanathan, T. Petri, K. Mehlhorn, and K. Borg- wardt, \"Efficient graphlet kernels for large graph comparison,\" in Arti- ficial Intelligence and Statistics, 2009, pp. 488-495.\n\nGraph kernels. S V N Vishwanathan, N N Schraudolph, R Kondor, K M Borgwardt, Journal of Machine Learning Research. 11S. V. N. Vishwanathan, N. N. Schraudolph, R. Kondor, and K. M. Borgwardt, \"Graph kernels,\" Journal of Machine Learning Research, vol. 11, no. Apr, pp. 1201-1242, 2010.\n\nA treebased kernel for graphs. G Da San, N Martino, A Navarin, Sperduti, 10.1137/1.9781611972825.84Proceedings of the Twelfth SIAM International Conference on Data Mining. the Twelfth SIAM International Conference on Data MiningAnaheim, California, USAG. Da San Martino, N. Navarin, and A. Sperduti, \"A tree- based kernel for graphs,\" in Proceedings of the Twelfth SIAM International Conference on Data Mining, Anaheim, California, USA, April 26-28, 2012., 2012, pp. 975-986. [Online]. Available: https://doi.org/10.1137/1.9781611972825.84\n\nLearning discriminative fisher kernels. L Van Der Maaten, Proceedings of the 28th International Conference on Machine Learning. the 28th International Conference on Machine LearningBellevue, Washington, USAL. van der Maaten, \"Learning discriminative fisher kernels,\" in Proceed- ings of the 28th International Conference on Machine Learning, ICML 2011, Bellevue, Washington, USA, June 28 -July 2, 2011, 2011, pp. 217-224.\n\nLearning nonsparse kernels by self-organizing maps for structured data. F Aiolli, G Da San, M Martino, A Hagenbuchner, Sperduti, 10.1109/TNN.2009.2033473IEEE Trans. Neural Networks. 2012F. Aiolli, G. Da San Martino, M. Hagenbuchner, and A. Sperduti, \"Learning nonsparse kernels by self-organizing maps for structured data,\" IEEE Trans. Neural Networks, vol. 20, no. 12, pp. 1938-1949, 2009. [Online]. Available: https://doi.org/10.1109/TNN.2009.2033473\n\nGenerative kernels for tree-structured data. D Bacciu, A Micheli, A Sperduti, IEEE Trans. Neural Netw. Learning Syst. early accessD. Bacciu, A. Micheli, and A. Sperduti, \"Generative kernels for tree-structured data,\" IEEE Trans. Neural Netw. Learning Syst., vol. early access, 2018. [Online]. Available: https://ieeexplore.ieee.org/ document/8259316/\n\nRepresentation learning on graphs: Methods and applications. W L Hamilton, R Ying, J Leskovec, abs/1709.05584CoRR. W. L. Hamilton, R. Ying, and J. Leskovec, \"Representation learning on graphs: Methods and applications,\" CoRR, vol. abs/1709.05584, 2017. [Online]. Available: http://arxiv.org/abs/1709.05584\n\nNeural network for graphs: A contextual constructive approach. A Micheli, IEEE Transactions on Neural Networks. 203A. Micheli, \"Neural network for graphs: A contextual constructive approach,\" IEEE Transactions on Neural Networks, vol. 20, no. 3, pp. 498-511, 2009.\n\nThe Graph Neural Network Model. F Scarselli, M Gori, A C Ah Chung Tsoi, M Hagenbuchner, G Monfardini, IEEE Transactions on Neural Networks. 201F. Scarselli, M. Gori, A. C. Ah Chung Tsoi, M. Hagenbuchner, and G. Monfardini, \"The Graph Neural Network Model,\" IEEE Transactions on Neural Networks, vol. 20, no. 1, pp. 61- 80, 2009. [Online]. Available: http://ieeexplore.ieee.org/lpdocs/epic03/ wrapper.htm?arnumber=4700287\n\nSupervised neural networks for the classification of structures. A Sperduti, A Starita, 10.1109/72.572108IEEE Trans. Neural Networks. 83A. Sperduti and A. Starita, \"Supervised neural networks for the classification of structures,\" IEEE Trans. Neural Networks, vol. 8, no. 3, pp. 714-735, 1997. [Online]. Available: https: //doi.org/10.1109/72.572108\n\nGated Graph Sequence Neural Networks. Y Li, D Tarlow, M Brockschmidt, R Zemel, ICLR. Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel, \"Gated Graph Sequence Neural Networks,\" in ICLR, 2016. [Online]. Available: http://arxiv.org/abs/1511.05493\n\nAn Experimental Study of Neural Networks for Variable Graphs. X Bresson, T Laurent, ICLR 2018 Workshop. X. Bresson and T. Laurent, \"An Experimental Study of Neural Networks for Variable Graphs,\" in ICLR 2018 Workshop, 2018.\n\nBridging the Gaps Between Residual Learning. Q Liao, T Poggio, Recurrent Neural Networks and Visual Cortex. arXiv preprintQ. Liao and T. Poggio, \"Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex,\" arXiv preprint, 2016. [Online]. Available: http://arxiv.org/abs/1604.03640\n\nConvolutional networks on graphs for learning molecular fingerprints. D Duvenaud, D Maclaurin, J Aguilera-Iparraguirre, R G\u00f3mez-Bombarelli, T Hirzel, A Aspuru-Guzik, R P Adams, Advances in Neural Information Processing Systems. Montreal, CanadaD. Duvenaud, D. Maclaurin, J. Aguilera-Iparraguirre, R. G\u00f3mez- Bombarelli, T. Hirzel, A. Aspuru-Guzik, and R. P. Adams, \"Convo- lutional networks on graphs for learning molecular fingerprints,\" in Advances in Neural Information Processing Systems, Montreal, Canada, 2015, pp. 2215-2223.\n\nDynamic edge-conditioned filters in convolutional neural networks on graphs. M Simonovsky, N Komodakis, CVPR. M. Simonovsky and N. Komodakis, \"Dynamic edge-conditioned filters in convolutional neural networks on graphs,\" in CVPR, 2017.\n\nSemi-Supervised Classification with Graph Convolutional Networks. T N Kipf, M Welling, T. N. Kipf and M. Welling, \"Semi-Supervised Classification with Graph Convolutional Networks,\" in ICLR, 2017, pp. 1-14. [Online].\n\nAn End-to-End Deep Learning Architecture for Graph Classification. M Zhang, Z Cui, M Neumann, Y Chen, AAAI Conference on Artificial Intelligence. M. Zhang, Z. Cui, M. Neumann, and Y. Chen, \"An End-to-End Deep Learning Architecture for Graph Classification,\" in AAAI Conference on Artificial Intelligence, 2018.\n\nN-GCN: Multiscale Graph Convolution for Semi-supervised Node Classification. S Abu-El-Haija, A Kapoor, B Perozzi, J Lee, Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG). the 14th International Workshop on Mining and Learning with Graphs (MLG)S. Abu-El-Haija, A. Kapoor, B. Perozzi, and J. Lee, \"N-GCN: Multi- scale Graph Convolution for Semi-supervised Node Classification,\" in Proceedings of the 14th International Workshop on Mining and Learning with Graphs (MLG), 2018. [Online]. Available: http://arxiv.org/abs/1802.08888\n\nGoing deeper with convolutions. C Szegedy, Wei Liu, Yangqing Jia, P Sermanet, S Reed, D Anguelov, D Erhan, V Vanhoucke, A Rabinovich, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEEC. Szegedy, Wei Liu, Yangqing Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich, \"Going deeper with convolutions,\" in 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, jun 2015, pp. 1-9. [Online].\n\nGraph Attention Networks. P Veli\u010dkovi\u0107, G Cucurull, A Casanova, A Romero, P Li\u00f2, Y Bengio, ICLR. P. Veli\u010dkovi\u0107, G. Cucurull, A. Casanova, A. Romero, P. Li\u00f2, and Y. Bengio, \"Graph Attention Networks,\" in ICLR, 2018. [Online].\n\nLearning convolutional neural networks for graphs. M Niepert, M Ahmed, K Kutzkov, International conference on machine learning. M. Niepert, M. Ahmed, and K. Kutzkov, \"Learning convolutional neural networks for graphs,\" in International conference on machine learning, 2016, pp. 2014-2023.\n\nDiffusion-convolutional neural networks. J Atwood, D Towsley, Advances in Neural Information Processing Systems. J. Atwood and D. Towsley, \"Diffusion-convolutional neural networks,\" in Advances in Neural Information Processing Systems, 2016, pp. 1993- 2001.\n\nOn Graph Kernels: Hardness Results and Efficient Alternatives. T Gartner, P Flach, S Wrobel, T G\u00e4rtner, http:/link.springer.com/10.1007/b12006Proceedings of the 16th Annual Conference on Computational Learning Theory and 7th Kernel Workshop, ser. Lecture Notes in Computer Science. M. K. Warmuththe 16th Annual Conference on Computational Learning Theory and 7th Kernel Workshop, ser. Lecture Notes in Computer ScienceBerlin, Heidelberg; Berlin HeidelbergSpringer2777T. Gartner, P. Flach, S. Wrobel, and T. G\u00e4rtner, \"On Graph Kernels: Hardness Results and Efficient Alternatives,\" in Proceedings of the 16th Annual Conference on Computational Learning Theory and 7th Kernel Workshop, ser. Lecture Notes in Computer Science, B. Sch\u00f6lkopf and M. K. Warmuth, Eds., vol. 2777. Berlin, Heidelberg: Springer Berlin Heidelberg, 2003, pp. 129-143. [Online]. Available: http://link.springer.com/10.1007/b12006\n\nEfficient graphlet kernels for large graph comparison. N Shervashidze, K Mehlhorn, T H Petri, S V N Vishwanathan, K M Borgwardt, T H Petri, K Mehlhorn, K M Borgwardt, AISTATS. 5CSAILN. Shervashidze, K. Mehlhorn, T. H. Petri, S. V. N. Vishwanathan, K. M. Borgwardt, T. H. Petri, K. Mehlhorn, and K. M. Borgwardt, \"Efficient graphlet kernels for large graph comparison,\" in AISTATS, vol. 5. Clearwater Beach, Florida, USA: CSAIL, 2009, pp. 488-495.\n\nShortest-Path Kernels on Graphs. K Borgwardt, H.-P Kriegel, ICDM. Los Alamitos, CA, USAIEEEK. Borgwardt and H.-P. Kriegel, \"Shortest-Path Kernels on Graphs,\" in ICDM. Los Alamitos, CA, USA: IEEE, 2005, pp. 74- 81. [Online]. Available: http://ieeexplore.ieee.org/lpdocs/epic03/wrapper. htm?arnumber=1565664\n\nOrdered Decompositional DAG Kernels Enhancements. G Da San, N Martino, A Navarin, Sperduti, Neurocomputing. 192G. Da San Martino, N. Navarin, and A. Sperduti, \"Ordered Decompo- sitional DAG Kernels Enhancements,\" Neurocomputing, vol. 192, pp. 92-103, 2016.\n\nA Tree-Based Kernel for Graphs. Proceedings of the Twelfth SIAM International Conference on Data Mining. the Twelfth SIAM International Conference on Data Mining--, \"A Tree-Based Kernel for Graphs,\" in Proceedings of the Twelfth SIAM International Conference on Data Mining, 2012, pp. 975-986.\n\nGraph Kernels Exploiting Weisfeiler-Lehman Graph Isomorphism Test Extensions. http:/link.springer.com/10.1007/978-3-319-12640-1{_}12Neural Information Processing. 8835--, \"Graph Kernels Exploiting Weisfeiler-Lehman Graph Isomorphism Test Extensions,\" in Neural Information Pro- cessing, vol. 8835, 2014, pp. 93-100. [Online]. Available: http://link.springer.com/10.1007/978-3-319-12640-1{ }12\n\nWeisfeiler-Lehman Graph Kernels. N Shervashidze, P Schweitzer, E J Van Leeuwen, K Mehlhorn, K M Borgwardt, JMLR. 12N. Shervashidze, P. Schweitzer, E. J. van Leeuwen, K. Mehlhorn, and K. M. Borgwardt, \"Weisfeiler-Lehman Graph Kernels,\" JMLR, vol. 12, pp. 2539-2561, 2011.\n\nEfficient graph kernels by randomization. M Neumann, N Patricia, R Garnett, K Kersting, Joint European Conference on Machine Learning and Knowledge Discovery in Databases. SpringerM. Neumann, N. Patricia, R. Garnett, and K. Kersting, \"Efficient graph kernels by randomization,\" in Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 2012, pp. 378-393.\n\nDeep graph kernels. P Yanardag, S Vishwanathan, Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningACMP. Yanardag and S. Vishwanathan, \"Deep graph kernels,\" in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2015, pp. 1365-1374.\n\nWeisfeiler-lehman graph kernels. N Shervashidze, P Schweitzer, E J Leeuwen, K Mehlhorn, K M Borgwardt, Journal of Machine Learning Research. 12N. Shervashidze, P. Schweitzer, E. J. v. Leeuwen, K. Mehlhorn, and K. M. Borgwardt, \"Weisfeiler-lehman graph kernels,\" Journal of Ma- chine Learning Research, vol. 12, no. Sep, pp. 2539-2561, 2011.\n\nFast neighborhood subgraph pairwise distance kernel. F Costa, K De Grave, ICML. OmnipressF. Costa and K. De Grave, \"Fast neighborhood subgraph pairwise distance kernel,\" in ICML. Omnipress, 2010, pp. 255-262.\n\nStructure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. Correlation with molecular orbital energies and hydrophobicity. A K Debnath, R L Lopez De Compadre, G Debnath, A J Shusterman, C Hansch, Journal of Medicinal Chemistry. 342A. K. Debnath, R. L. Lopez de Compadre, G. Debnath, A. J. Shusterman, and C. Hansch, \"Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. Correlation with molecular orbital energies and hydrophobicity,\" Journal of Medicinal Chemistry, vol. 34, no. 2, pp. 786-797, feb 1991. [Online].\n\n. http:/pubs.acs.org/doi/abs/10.1021/jm00106a046Available: http://pubs.acs.org/doi/abs/10.1021/jm00106a046\n\nStatistical evaluation of the predictive toxicology challenge. H Toivonen, A Srinivasan, R D King, S Kramer, C Helma, Bioinformatics. H. Toivonen, A. Srinivasan, R. D. King, S. Kramer, and C. Helma, \"Statistical evaluation of the predictive toxicology challenge 2000-2001,\" Bioinformatics, 2003.\n\nComparison of descriptor spaces for chemical compound retrieval and classification. N Wale, I Watson, G Karypis, Knowledge and Information Systems. 143N. Wale, I. Watson, and G. Karypis, \"Comparison of descriptor spaces for chemical compound retrieval and classification,\" Knowledge and Information Systems, vol. 14, no. 3, pp. 347-375, 2008.\n\nDistinguishing Enzyme Structures from Non-enzymes Without Alignments. P D Dobson, A J Doig, Journal of Molecular Biology. 3304P. D. Dobson and A. J. Doig, \"Distinguishing Enzyme Structures from Non-enzymes Without Alignments,\" Journal of Molecular Biology, vol. 330, no. 4, pp. 771-783, 2003.\n", "annotations": {"author": "[{\"end\":62,\"start\":50},{\"end\":101,\"start\":63},{\"end\":145,\"start\":102},{\"end\":254,\"start\":146},{\"end\":314,\"start\":255},{\"end\":356,\"start\":315},{\"end\":62,\"start\":50},{\"end\":101,\"start\":63},{\"end\":145,\"start\":102},{\"end\":254,\"start\":146},{\"end\":314,\"start\":255},{\"end\":356,\"start\":315}]", "publisher": null, "author_last_name": "[{\"end\":61,\"start\":57},{\"end\":77,\"start\":70},{\"end\":121,\"start\":113},{\"end\":61,\"start\":57},{\"end\":77,\"start\":70},{\"end\":121,\"start\":113}]", "author_first_name": "[{\"end\":54,\"start\":50},{\"end\":56,\"start\":55},{\"end\":69,\"start\":63},{\"end\":112,\"start\":102},{\"end\":54,\"start\":50},{\"end\":56,\"start\":55},{\"end\":69,\"start\":63},{\"end\":112,\"start\":102}]", "author_affiliation": "[{\"end\":253,\"start\":147},{\"end\":313,\"start\":256},{\"end\":355,\"start\":316},{\"end\":253,\"start\":147},{\"end\":313,\"start\":256},{\"end\":355,\"start\":316}]", "title": "[{\"end\":47,\"start\":1},{\"end\":403,\"start\":357},{\"end\":47,\"start\":1},{\"end\":403,\"start\":357}]", "venue": null, "abstract": "[{\"end\":1249,\"start\":506},{\"end\":1249,\"start\":506}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1936,\"start\":1933},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1941,\"start\":1938},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2053,\"start\":2050},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2058,\"start\":2055},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2540,\"start\":2537},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2660,\"start\":2657},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2665,\"start\":2662},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5045,\"start\":5041},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5091,\"start\":5088},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5096,\"start\":5093},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5638,\"start\":5635},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6607,\"start\":6603},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6631,\"start\":6628},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6801,\"start\":6797},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6936,\"start\":6933},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7739,\"start\":7736},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7863,\"start\":7859},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8952,\"start\":8948},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9102,\"start\":9099},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9148,\"start\":9144},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9193,\"start\":9189},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9225,\"start\":9221},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9396,\"start\":9392},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10090,\"start\":10086},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10138,\"start\":10134},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10759,\"start\":10755},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10986,\"start\":10982},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11766,\"start\":11762},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13385,\"start\":13381},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":14264,\"start\":14261},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":15017,\"start\":15013},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15389,\"start\":15385},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":15395,\"start\":15391},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":17213,\"start\":17209},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":18947,\"start\":18943},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":19417,\"start\":19413},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20141,\"start\":20138},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20147,\"start\":20143},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":20397,\"start\":20393},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":20418,\"start\":20414},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":20433,\"start\":20429},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20439,\"start\":20435},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":20462,\"start\":20458},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":20468,\"start\":20464},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":20724,\"start\":20720},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21381,\"start\":21377},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22154,\"start\":22150},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":22442,\"start\":22439},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":22475,\"start\":22472},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":22509,\"start\":22505},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":22561,\"start\":22557},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22635,\"start\":22631},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":22648,\"start\":22644},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22923,\"start\":22919},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":22933,\"start\":22929},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":22944,\"start\":22940},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":22968,\"start\":22964},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":23763,\"start\":23759},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23790,\"start\":23786},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23800,\"start\":23796},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":23836,\"start\":23832},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":23949,\"start\":23945},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":25241,\"start\":25237},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":25312,\"start\":25308},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":26888,\"start\":26884},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":28889,\"start\":28885},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1936,\"start\":1933},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1941,\"start\":1938},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2053,\"start\":2050},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2058,\"start\":2055},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2540,\"start\":2537},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2660,\"start\":2657},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2665,\"start\":2662},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5045,\"start\":5041},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5091,\"start\":5088},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5096,\"start\":5093},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5638,\"start\":5635},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6607,\"start\":6603},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6631,\"start\":6628},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6801,\"start\":6797},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6936,\"start\":6933},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7739,\"start\":7736},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7863,\"start\":7859},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8952,\"start\":8948},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9102,\"start\":9099},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9148,\"start\":9144},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9193,\"start\":9189},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9225,\"start\":9221},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9396,\"start\":9392},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10090,\"start\":10086},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10138,\"start\":10134},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10759,\"start\":10755},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10986,\"start\":10982},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11766,\"start\":11762},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13385,\"start\":13381},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":14264,\"start\":14261},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":15017,\"start\":15013},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15389,\"start\":15385},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":15395,\"start\":15391},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":17213,\"start\":17209},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":18947,\"start\":18943},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":19417,\"start\":19413},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20141,\"start\":20138},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20147,\"start\":20143},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":20397,\"start\":20393},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":20418,\"start\":20414},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":20433,\"start\":20429},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20439,\"start\":20435},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":20462,\"start\":20458},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":20468,\"start\":20464},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":20724,\"start\":20720},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21381,\"start\":21377},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22154,\"start\":22150},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":22442,\"start\":22439},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":22475,\"start\":22472},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":22509,\"start\":22505},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":22561,\"start\":22557},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22635,\"start\":22631},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":22648,\"start\":22644},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22923,\"start\":22919},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":22933,\"start\":22929},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":22944,\"start\":22940},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":22968,\"start\":22964},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":23763,\"start\":23759},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23790,\"start\":23786},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23800,\"start\":23796},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":23836,\"start\":23832},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":23949,\"start\":23945},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":25241,\"start\":25237},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":25312,\"start\":25308},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":26888,\"start\":26884},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":28889,\"start\":28885}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":30304,\"start\":30135},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":30597,\"start\":30305},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":31153,\"start\":30598},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":31754,\"start\":31154},{\"attributes\":{\"id\":\"fig_0\"},\"end\":30304,\"start\":30135},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":30597,\"start\":30305},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":31153,\"start\":30598},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":31754,\"start\":31154}]", "paragraph": "[{\"end\":2221,\"start\":1268},{\"end\":2666,\"start\":2223},{\"end\":2938,\"start\":2668},{\"end\":3485,\"start\":2940},{\"end\":3796,\"start\":3518},{\"end\":4506,\"start\":3798},{\"end\":4738,\"start\":4547},{\"end\":4942,\"start\":4740},{\"end\":5181,\"start\":4970},{\"end\":5630,\"start\":5183},{\"end\":5827,\"start\":5632},{\"end\":6534,\"start\":5875},{\"end\":7073,\"start\":6566},{\"end\":7306,\"start\":7114},{\"end\":8189,\"start\":7379},{\"end\":8943,\"start\":8233},{\"end\":9380,\"start\":8945},{\"end\":9625,\"start\":9382},{\"end\":9752,\"start\":9667},{\"end\":10081,\"start\":9754},{\"end\":10362,\"start\":10083},{\"end\":11466,\"start\":10394},{\"end\":11823,\"start\":11491},{\"end\":12191,\"start\":11825},{\"end\":12609,\"start\":12193},{\"end\":13050,\"start\":12611},{\"end\":13222,\"start\":13052},{\"end\":13685,\"start\":13260},{\"end\":13989,\"start\":13740},{\"end\":14581,\"start\":14030},{\"end\":15341,\"start\":14631},{\"end\":15819,\"start\":15364},{\"end\":16581,\"start\":15821},{\"end\":17013,\"start\":16613},{\"end\":17193,\"start\":17034},{\"end\":17525,\"start\":17195},{\"end\":17618,\"start\":17558},{\"end\":18005,\"start\":17620},{\"end\":18319,\"start\":18074},{\"end\":19390,\"start\":18360},{\"end\":19585,\"start\":19392},{\"end\":19909,\"start\":19606},{\"end\":20693,\"start\":19911},{\"end\":21106,\"start\":20695},{\"end\":21535,\"start\":21108},{\"end\":21670,\"start\":21574},{\"end\":22302,\"start\":21690},{\"end\":23591,\"start\":22304},{\"end\":24353,\"start\":23593},{\"end\":26177,\"start\":24355},{\"end\":26424,\"start\":26205},{\"end\":27408,\"start\":26426},{\"end\":27778,\"start\":27410},{\"end\":29142,\"start\":27780},{\"end\":29546,\"start\":29180},{\"end\":30134,\"start\":29548},{\"end\":2221,\"start\":1268},{\"end\":2666,\"start\":2223},{\"end\":2938,\"start\":2668},{\"end\":3485,\"start\":2940},{\"end\":3796,\"start\":3518},{\"end\":4506,\"start\":3798},{\"end\":4738,\"start\":4547},{\"end\":4942,\"start\":4740},{\"end\":5181,\"start\":4970},{\"end\":5630,\"start\":5183},{\"end\":5827,\"start\":5632},{\"end\":6534,\"start\":5875},{\"end\":7073,\"start\":6566},{\"end\":7306,\"start\":7114},{\"end\":8189,\"start\":7379},{\"end\":8943,\"start\":8233},{\"end\":9380,\"start\":8945},{\"end\":9625,\"start\":9382},{\"end\":9752,\"start\":9667},{\"end\":10081,\"start\":9754},{\"end\":10362,\"start\":10083},{\"end\":11466,\"start\":10394},{\"end\":11823,\"start\":11491},{\"end\":12191,\"start\":11825},{\"end\":12609,\"start\":12193},{\"end\":13050,\"start\":12611},{\"end\":13222,\"start\":13052},{\"end\":13685,\"start\":13260},{\"end\":13989,\"start\":13740},{\"end\":14581,\"start\":14030},{\"end\":15341,\"start\":14631},{\"end\":15819,\"start\":15364},{\"end\":16581,\"start\":15821},{\"end\":17013,\"start\":16613},{\"end\":17193,\"start\":17034},{\"end\":17525,\"start\":17195},{\"end\":17618,\"start\":17558},{\"end\":18005,\"start\":17620},{\"end\":18319,\"start\":18074},{\"end\":19390,\"start\":18360},{\"end\":19585,\"start\":19392},{\"end\":19909,\"start\":19606},{\"end\":20693,\"start\":19911},{\"end\":21106,\"start\":20695},{\"end\":21535,\"start\":21108},{\"end\":21670,\"start\":21574},{\"end\":22302,\"start\":21690},{\"end\":23591,\"start\":22304},{\"end\":24353,\"start\":23593},{\"end\":26177,\"start\":24355},{\"end\":26424,\"start\":26205},{\"end\":27408,\"start\":26426},{\"end\":27778,\"start\":27410},{\"end\":29142,\"start\":27780},{\"end\":29546,\"start\":29180},{\"end\":30134,\"start\":29548}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":4546,\"start\":4507},{\"attributes\":{\"id\":\"formula_1\"},\"end\":5874,\"start\":5828},{\"attributes\":{\"id\":\"formula_2\"},\"end\":6565,\"start\":6535},{\"attributes\":{\"id\":\"formula_3\"},\"end\":7113,\"start\":7074},{\"attributes\":{\"id\":\"formula_4\"},\"end\":7378,\"start\":7307},{\"attributes\":{\"id\":\"formula_5\"},\"end\":8232,\"start\":8190},{\"attributes\":{\"id\":\"formula_6\"},\"end\":9666,\"start\":9626},{\"attributes\":{\"id\":\"formula_7\"},\"end\":10393,\"start\":10363},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13739,\"start\":13686},{\"attributes\":{\"id\":\"formula_9\"},\"end\":14029,\"start\":13990},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14630,\"start\":14582},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17557,\"start\":17526},{\"attributes\":{\"id\":\"formula_12\"},\"end\":18073,\"start\":18006},{\"attributes\":{\"id\":\"formula_13\"},\"end\":18359,\"start\":18320},{\"attributes\":{\"id\":\"formula_14\"},\"end\":21573,\"start\":21536},{\"attributes\":{\"id\":\"formula_0\"},\"end\":4546,\"start\":4507},{\"attributes\":{\"id\":\"formula_1\"},\"end\":5874,\"start\":5828},{\"attributes\":{\"id\":\"formula_2\"},\"end\":6565,\"start\":6535},{\"attributes\":{\"id\":\"formula_3\"},\"end\":7113,\"start\":7074},{\"attributes\":{\"id\":\"formula_4\"},\"end\":7378,\"start\":7307},{\"attributes\":{\"id\":\"formula_5\"},\"end\":8232,\"start\":8190},{\"attributes\":{\"id\":\"formula_6\"},\"end\":9666,\"start\":9626},{\"attributes\":{\"id\":\"formula_7\"},\"end\":10393,\"start\":10363},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13739,\"start\":13686},{\"attributes\":{\"id\":\"formula_9\"},\"end\":14029,\"start\":13990},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14630,\"start\":14582},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17557,\"start\":17526},{\"attributes\":{\"id\":\"formula_12\"},\"end\":18073,\"start\":18006},{\"attributes\":{\"id\":\"formula_13\"},\"end\":18359,\"start\":18320},{\"attributes\":{\"id\":\"formula_14\"},\"end\":21573,\"start\":21536}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22191,\"start\":22184},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":26454,\"start\":26446},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":27493,\"start\":27484},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":27912,\"start\":27904},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22191,\"start\":22184},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":26454,\"start\":26446},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":27493,\"start\":27484},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":27912,\"start\":27904}]", "section_header": "[{\"end\":1266,\"start\":1251},{\"end\":3516,\"start\":3488},{\"end\":4968,\"start\":4945},{\"end\":11489,\"start\":11469},{\"end\":13258,\"start\":13225},{\"end\":15362,\"start\":15344},{\"end\":16611,\"start\":16584},{\"end\":17032,\"start\":17016},{\"end\":19604,\"start\":19588},{\"end\":21688,\"start\":21673},{\"end\":26203,\"start\":26180},{\"end\":29178,\"start\":29145},{\"end\":30144,\"start\":30136},{\"end\":30315,\"start\":30306},{\"end\":30609,\"start\":30599},{\"end\":31166,\"start\":31155},{\"end\":1266,\"start\":1251},{\"end\":3516,\"start\":3488},{\"end\":4968,\"start\":4945},{\"end\":11489,\"start\":11469},{\"end\":13258,\"start\":13225},{\"end\":15362,\"start\":15344},{\"end\":16611,\"start\":16584},{\"end\":17032,\"start\":17016},{\"end\":19604,\"start\":19588},{\"end\":21688,\"start\":21673},{\"end\":26203,\"start\":26180},{\"end\":29178,\"start\":29145},{\"end\":30144,\"start\":30136},{\"end\":30315,\"start\":30306},{\"end\":30609,\"start\":30599},{\"end\":31166,\"start\":31155}]", "table": "[{\"end\":30597,\"start\":30351},{\"end\":31153,\"start\":30714},{\"end\":31754,\"start\":31289},{\"end\":30597,\"start\":30351},{\"end\":31153,\"start\":30714},{\"end\":31754,\"start\":31289}]", "figure_caption": "[{\"end\":30304,\"start\":30146},{\"end\":30351,\"start\":30317},{\"end\":30714,\"start\":30612},{\"end\":31289,\"start\":31170},{\"end\":30304,\"start\":30146},{\"end\":30351,\"start\":30317},{\"end\":30714,\"start\":30612},{\"end\":31289,\"start\":31170}]", "figure_ref": "[{\"end\":7700,\"start\":7694},{\"end\":8507,\"start\":8499},{\"end\":7700,\"start\":7694},{\"end\":8507,\"start\":8499}]", "bib_author_first_name": "[{\"end\":31968,\"start\":31967},{\"end\":31984,\"start\":31983},{\"end\":32000,\"start\":31999},{\"end\":32009,\"start\":32008},{\"end\":32021,\"start\":32020},{\"end\":32288,\"start\":32287},{\"end\":32292,\"start\":32289},{\"end\":32308,\"start\":32307},{\"end\":32310,\"start\":32309},{\"end\":32325,\"start\":32324},{\"end\":32335,\"start\":32334},{\"end\":32337,\"start\":32336},{\"end\":32590,\"start\":32589},{\"end\":32600,\"start\":32599},{\"end\":32611,\"start\":32610},{\"end\":33140,\"start\":33139},{\"end\":33595,\"start\":33594},{\"end\":33605,\"start\":33604},{\"end\":33615,\"start\":33614},{\"end\":33626,\"start\":33625},{\"end\":34022,\"start\":34021},{\"end\":34032,\"start\":34031},{\"end\":34043,\"start\":34042},{\"end\":34390,\"start\":34389},{\"end\":34392,\"start\":34391},{\"end\":34404,\"start\":34403},{\"end\":34412,\"start\":34411},{\"end\":34699,\"start\":34698},{\"end\":34934,\"start\":34933},{\"end\":34947,\"start\":34946},{\"end\":34955,\"start\":34954},{\"end\":34957,\"start\":34956},{\"end\":34974,\"start\":34973},{\"end\":34990,\"start\":34989},{\"end\":35389,\"start\":35388},{\"end\":35401,\"start\":35400},{\"end\":35713,\"start\":35712},{\"end\":35719,\"start\":35718},{\"end\":35729,\"start\":35728},{\"end\":35745,\"start\":35744},{\"end\":35980,\"start\":35979},{\"end\":35991,\"start\":35990},{\"end\":36188,\"start\":36187},{\"end\":36196,\"start\":36195},{\"end\":36526,\"start\":36525},{\"end\":36538,\"start\":36537},{\"end\":36551,\"start\":36550},{\"end\":36576,\"start\":36575},{\"end\":36596,\"start\":36595},{\"end\":36606,\"start\":36605},{\"end\":36622,\"start\":36621},{\"end\":36624,\"start\":36623},{\"end\":37065,\"start\":37064},{\"end\":37079,\"start\":37078},{\"end\":37291,\"start\":37290},{\"end\":37293,\"start\":37292},{\"end\":37301,\"start\":37300},{\"end\":37510,\"start\":37509},{\"end\":37519,\"start\":37518},{\"end\":37526,\"start\":37525},{\"end\":37537,\"start\":37536},{\"end\":37832,\"start\":37831},{\"end\":37848,\"start\":37847},{\"end\":37858,\"start\":37857},{\"end\":37869,\"start\":37868},{\"end\":38354,\"start\":38353},{\"end\":38367,\"start\":38364},{\"end\":38381,\"start\":38373},{\"end\":38388,\"start\":38387},{\"end\":38400,\"start\":38399},{\"end\":38408,\"start\":38407},{\"end\":38420,\"start\":38419},{\"end\":38429,\"start\":38428},{\"end\":38442,\"start\":38441},{\"end\":38816,\"start\":38815},{\"end\":38830,\"start\":38829},{\"end\":38842,\"start\":38841},{\"end\":38854,\"start\":38853},{\"end\":38864,\"start\":38863},{\"end\":38871,\"start\":38870},{\"end\":39067,\"start\":39066},{\"end\":39078,\"start\":39077},{\"end\":39087,\"start\":39086},{\"end\":39347,\"start\":39346},{\"end\":39357,\"start\":39356},{\"end\":39628,\"start\":39627},{\"end\":39639,\"start\":39638},{\"end\":39648,\"start\":39647},{\"end\":39658,\"start\":39657},{\"end\":40522,\"start\":40521},{\"end\":40538,\"start\":40537},{\"end\":40550,\"start\":40549},{\"end\":40552,\"start\":40551},{\"end\":40561,\"start\":40560},{\"end\":40565,\"start\":40562},{\"end\":40581,\"start\":40580},{\"end\":40583,\"start\":40582},{\"end\":40596,\"start\":40595},{\"end\":40598,\"start\":40597},{\"end\":40607,\"start\":40606},{\"end\":40619,\"start\":40618},{\"end\":40621,\"start\":40620},{\"end\":40948,\"start\":40947},{\"end\":40964,\"start\":40960},{\"end\":41272,\"start\":41271},{\"end\":41282,\"start\":41281},{\"end\":41293,\"start\":41292},{\"end\":42202,\"start\":42201},{\"end\":42218,\"start\":42217},{\"end\":42232,\"start\":42231},{\"end\":42234,\"start\":42233},{\"end\":42249,\"start\":42248},{\"end\":42261,\"start\":42260},{\"end\":42263,\"start\":42262},{\"end\":42483,\"start\":42482},{\"end\":42494,\"start\":42493},{\"end\":42506,\"start\":42505},{\"end\":42517,\"start\":42516},{\"end\":42856,\"start\":42855},{\"end\":42868,\"start\":42867},{\"end\":43288,\"start\":43287},{\"end\":43304,\"start\":43303},{\"end\":43318,\"start\":43317},{\"end\":43320,\"start\":43319},{\"end\":43331,\"start\":43330},{\"end\":43343,\"start\":43342},{\"end\":43345,\"start\":43344},{\"end\":43650,\"start\":43649},{\"end\":43659,\"start\":43658},{\"end\":43961,\"start\":43960},{\"end\":43963,\"start\":43962},{\"end\":43974,\"start\":43973},{\"end\":43976,\"start\":43975},{\"end\":43997,\"start\":43996},{\"end\":44008,\"start\":44007},{\"end\":44010,\"start\":44009},{\"end\":44024,\"start\":44023},{\"end\":44563,\"start\":44562},{\"end\":44575,\"start\":44574},{\"end\":44589,\"start\":44588},{\"end\":44591,\"start\":44590},{\"end\":44599,\"start\":44598},{\"end\":44609,\"start\":44608},{\"end\":44881,\"start\":44880},{\"end\":44889,\"start\":44888},{\"end\":44899,\"start\":44898},{\"end\":45211,\"start\":45210},{\"end\":45213,\"start\":45212},{\"end\":45223,\"start\":45222},{\"end\":45225,\"start\":45224},{\"end\":31968,\"start\":31967},{\"end\":31984,\"start\":31983},{\"end\":32000,\"start\":31999},{\"end\":32009,\"start\":32008},{\"end\":32021,\"start\":32020},{\"end\":32288,\"start\":32287},{\"end\":32292,\"start\":32289},{\"end\":32308,\"start\":32307},{\"end\":32310,\"start\":32309},{\"end\":32325,\"start\":32324},{\"end\":32335,\"start\":32334},{\"end\":32337,\"start\":32336},{\"end\":32590,\"start\":32589},{\"end\":32600,\"start\":32599},{\"end\":32611,\"start\":32610},{\"end\":33140,\"start\":33139},{\"end\":33595,\"start\":33594},{\"end\":33605,\"start\":33604},{\"end\":33615,\"start\":33614},{\"end\":33626,\"start\":33625},{\"end\":34022,\"start\":34021},{\"end\":34032,\"start\":34031},{\"end\":34043,\"start\":34042},{\"end\":34390,\"start\":34389},{\"end\":34392,\"start\":34391},{\"end\":34404,\"start\":34403},{\"end\":34412,\"start\":34411},{\"end\":34699,\"start\":34698},{\"end\":34934,\"start\":34933},{\"end\":34947,\"start\":34946},{\"end\":34955,\"start\":34954},{\"end\":34957,\"start\":34956},{\"end\":34974,\"start\":34973},{\"end\":34990,\"start\":34989},{\"end\":35389,\"start\":35388},{\"end\":35401,\"start\":35400},{\"end\":35713,\"start\":35712},{\"end\":35719,\"start\":35718},{\"end\":35729,\"start\":35728},{\"end\":35745,\"start\":35744},{\"end\":35980,\"start\":35979},{\"end\":35991,\"start\":35990},{\"end\":36188,\"start\":36187},{\"end\":36196,\"start\":36195},{\"end\":36526,\"start\":36525},{\"end\":36538,\"start\":36537},{\"end\":36551,\"start\":36550},{\"end\":36576,\"start\":36575},{\"end\":36596,\"start\":36595},{\"end\":36606,\"start\":36605},{\"end\":36622,\"start\":36621},{\"end\":36624,\"start\":36623},{\"end\":37065,\"start\":37064},{\"end\":37079,\"start\":37078},{\"end\":37291,\"start\":37290},{\"end\":37293,\"start\":37292},{\"end\":37301,\"start\":37300},{\"end\":37510,\"start\":37509},{\"end\":37519,\"start\":37518},{\"end\":37526,\"start\":37525},{\"end\":37537,\"start\":37536},{\"end\":37832,\"start\":37831},{\"end\":37848,\"start\":37847},{\"end\":37858,\"start\":37857},{\"end\":37869,\"start\":37868},{\"end\":38354,\"start\":38353},{\"end\":38367,\"start\":38364},{\"end\":38381,\"start\":38373},{\"end\":38388,\"start\":38387},{\"end\":38400,\"start\":38399},{\"end\":38408,\"start\":38407},{\"end\":38420,\"start\":38419},{\"end\":38429,\"start\":38428},{\"end\":38442,\"start\":38441},{\"end\":38816,\"start\":38815},{\"end\":38830,\"start\":38829},{\"end\":38842,\"start\":38841},{\"end\":38854,\"start\":38853},{\"end\":38864,\"start\":38863},{\"end\":38871,\"start\":38870},{\"end\":39067,\"start\":39066},{\"end\":39078,\"start\":39077},{\"end\":39087,\"start\":39086},{\"end\":39347,\"start\":39346},{\"end\":39357,\"start\":39356},{\"end\":39628,\"start\":39627},{\"end\":39639,\"start\":39638},{\"end\":39648,\"start\":39647},{\"end\":39658,\"start\":39657},{\"end\":40522,\"start\":40521},{\"end\":40538,\"start\":40537},{\"end\":40550,\"start\":40549},{\"end\":40552,\"start\":40551},{\"end\":40561,\"start\":40560},{\"end\":40565,\"start\":40562},{\"end\":40581,\"start\":40580},{\"end\":40583,\"start\":40582},{\"end\":40596,\"start\":40595},{\"end\":40598,\"start\":40597},{\"end\":40607,\"start\":40606},{\"end\":40619,\"start\":40618},{\"end\":40621,\"start\":40620},{\"end\":40948,\"start\":40947},{\"end\":40964,\"start\":40960},{\"end\":41272,\"start\":41271},{\"end\":41282,\"start\":41281},{\"end\":41293,\"start\":41292},{\"end\":42202,\"start\":42201},{\"end\":42218,\"start\":42217},{\"end\":42232,\"start\":42231},{\"end\":42234,\"start\":42233},{\"end\":42249,\"start\":42248},{\"end\":42261,\"start\":42260},{\"end\":42263,\"start\":42262},{\"end\":42483,\"start\":42482},{\"end\":42494,\"start\":42493},{\"end\":42506,\"start\":42505},{\"end\":42517,\"start\":42516},{\"end\":42856,\"start\":42855},{\"end\":42868,\"start\":42867},{\"end\":43288,\"start\":43287},{\"end\":43304,\"start\":43303},{\"end\":43318,\"start\":43317},{\"end\":43320,\"start\":43319},{\"end\":43331,\"start\":43330},{\"end\":43343,\"start\":43342},{\"end\":43345,\"start\":43344},{\"end\":43650,\"start\":43649},{\"end\":43659,\"start\":43658},{\"end\":43961,\"start\":43960},{\"end\":43963,\"start\":43962},{\"end\":43974,\"start\":43973},{\"end\":43976,\"start\":43975},{\"end\":43997,\"start\":43996},{\"end\":44008,\"start\":44007},{\"end\":44010,\"start\":44009},{\"end\":44024,\"start\":44023},{\"end\":44563,\"start\":44562},{\"end\":44575,\"start\":44574},{\"end\":44589,\"start\":44588},{\"end\":44591,\"start\":44590},{\"end\":44599,\"start\":44598},{\"end\":44609,\"start\":44608},{\"end\":44881,\"start\":44880},{\"end\":44889,\"start\":44888},{\"end\":44899,\"start\":44898},{\"end\":45211,\"start\":45210},{\"end\":45213,\"start\":45212},{\"end\":45223,\"start\":45222},{\"end\":45225,\"start\":45224}]", "bib_author_last_name": "[{\"end\":31981,\"start\":31969},{\"end\":31997,\"start\":31985},{\"end\":32006,\"start\":32001},{\"end\":32018,\"start\":32010},{\"end\":32031,\"start\":32022},{\"end\":32305,\"start\":32293},{\"end\":32322,\"start\":32311},{\"end\":32332,\"start\":32326},{\"end\":32347,\"start\":32338},{\"end\":32597,\"start\":32591},{\"end\":32608,\"start\":32601},{\"end\":32619,\"start\":32612},{\"end\":32629,\"start\":32621},{\"end\":33155,\"start\":33141},{\"end\":33602,\"start\":33596},{\"end\":33612,\"start\":33606},{\"end\":33623,\"start\":33616},{\"end\":33639,\"start\":33627},{\"end\":33649,\"start\":33641},{\"end\":34029,\"start\":34023},{\"end\":34040,\"start\":34033},{\"end\":34052,\"start\":34044},{\"end\":34401,\"start\":34393},{\"end\":34409,\"start\":34405},{\"end\":34421,\"start\":34413},{\"end\":34707,\"start\":34700},{\"end\":34944,\"start\":34935},{\"end\":34952,\"start\":34948},{\"end\":34971,\"start\":34958},{\"end\":34987,\"start\":34975},{\"end\":35001,\"start\":34991},{\"end\":35398,\"start\":35390},{\"end\":35409,\"start\":35402},{\"end\":35716,\"start\":35714},{\"end\":35726,\"start\":35720},{\"end\":35742,\"start\":35730},{\"end\":35751,\"start\":35746},{\"end\":35988,\"start\":35981},{\"end\":35999,\"start\":35992},{\"end\":36193,\"start\":36189},{\"end\":36203,\"start\":36197},{\"end\":36535,\"start\":36527},{\"end\":36548,\"start\":36539},{\"end\":36573,\"start\":36552},{\"end\":36593,\"start\":36577},{\"end\":36603,\"start\":36597},{\"end\":36619,\"start\":36607},{\"end\":36630,\"start\":36625},{\"end\":37076,\"start\":37066},{\"end\":37089,\"start\":37080},{\"end\":37298,\"start\":37294},{\"end\":37309,\"start\":37302},{\"end\":37516,\"start\":37511},{\"end\":37523,\"start\":37520},{\"end\":37534,\"start\":37527},{\"end\":37542,\"start\":37538},{\"end\":37845,\"start\":37833},{\"end\":37855,\"start\":37849},{\"end\":37866,\"start\":37859},{\"end\":37873,\"start\":37870},{\"end\":38362,\"start\":38355},{\"end\":38371,\"start\":38368},{\"end\":38385,\"start\":38382},{\"end\":38397,\"start\":38389},{\"end\":38405,\"start\":38401},{\"end\":38417,\"start\":38409},{\"end\":38426,\"start\":38421},{\"end\":38439,\"start\":38430},{\"end\":38453,\"start\":38443},{\"end\":38827,\"start\":38817},{\"end\":38839,\"start\":38831},{\"end\":38851,\"start\":38843},{\"end\":38861,\"start\":38855},{\"end\":38868,\"start\":38865},{\"end\":38878,\"start\":38872},{\"end\":39075,\"start\":39068},{\"end\":39084,\"start\":39079},{\"end\":39095,\"start\":39088},{\"end\":39354,\"start\":39348},{\"end\":39365,\"start\":39358},{\"end\":39636,\"start\":39629},{\"end\":39645,\"start\":39640},{\"end\":39655,\"start\":39649},{\"end\":39666,\"start\":39659},{\"end\":40535,\"start\":40523},{\"end\":40547,\"start\":40539},{\"end\":40558,\"start\":40553},{\"end\":40578,\"start\":40566},{\"end\":40593,\"start\":40584},{\"end\":40604,\"start\":40599},{\"end\":40616,\"start\":40608},{\"end\":40631,\"start\":40622},{\"end\":40958,\"start\":40949},{\"end\":40972,\"start\":40965},{\"end\":41279,\"start\":41273},{\"end\":41290,\"start\":41283},{\"end\":41301,\"start\":41294},{\"end\":41311,\"start\":41303},{\"end\":42215,\"start\":42203},{\"end\":42229,\"start\":42219},{\"end\":42246,\"start\":42235},{\"end\":42258,\"start\":42250},{\"end\":42273,\"start\":42264},{\"end\":42491,\"start\":42484},{\"end\":42503,\"start\":42495},{\"end\":42514,\"start\":42507},{\"end\":42526,\"start\":42518},{\"end\":42865,\"start\":42857},{\"end\":42881,\"start\":42869},{\"end\":43301,\"start\":43289},{\"end\":43315,\"start\":43305},{\"end\":43328,\"start\":43321},{\"end\":43340,\"start\":43332},{\"end\":43355,\"start\":43346},{\"end\":43656,\"start\":43651},{\"end\":43668,\"start\":43660},{\"end\":43971,\"start\":43964},{\"end\":43994,\"start\":43977},{\"end\":44005,\"start\":43998},{\"end\":44021,\"start\":44011},{\"end\":44031,\"start\":44025},{\"end\":44572,\"start\":44564},{\"end\":44586,\"start\":44576},{\"end\":44596,\"start\":44592},{\"end\":44606,\"start\":44600},{\"end\":44615,\"start\":44610},{\"end\":44886,\"start\":44882},{\"end\":44896,\"start\":44890},{\"end\":44907,\"start\":44900},{\"end\":45220,\"start\":45214},{\"end\":45230,\"start\":45226},{\"end\":31981,\"start\":31969},{\"end\":31997,\"start\":31985},{\"end\":32006,\"start\":32001},{\"end\":32018,\"start\":32010},{\"end\":32031,\"start\":32022},{\"end\":32305,\"start\":32293},{\"end\":32322,\"start\":32311},{\"end\":32332,\"start\":32326},{\"end\":32347,\"start\":32338},{\"end\":32597,\"start\":32591},{\"end\":32608,\"start\":32601},{\"end\":32619,\"start\":32612},{\"end\":32629,\"start\":32621},{\"end\":33155,\"start\":33141},{\"end\":33602,\"start\":33596},{\"end\":33612,\"start\":33606},{\"end\":33623,\"start\":33616},{\"end\":33639,\"start\":33627},{\"end\":33649,\"start\":33641},{\"end\":34029,\"start\":34023},{\"end\":34040,\"start\":34033},{\"end\":34052,\"start\":34044},{\"end\":34401,\"start\":34393},{\"end\":34409,\"start\":34405},{\"end\":34421,\"start\":34413},{\"end\":34707,\"start\":34700},{\"end\":34944,\"start\":34935},{\"end\":34952,\"start\":34948},{\"end\":34971,\"start\":34958},{\"end\":34987,\"start\":34975},{\"end\":35001,\"start\":34991},{\"end\":35398,\"start\":35390},{\"end\":35409,\"start\":35402},{\"end\":35716,\"start\":35714},{\"end\":35726,\"start\":35720},{\"end\":35742,\"start\":35730},{\"end\":35751,\"start\":35746},{\"end\":35988,\"start\":35981},{\"end\":35999,\"start\":35992},{\"end\":36193,\"start\":36189},{\"end\":36203,\"start\":36197},{\"end\":36535,\"start\":36527},{\"end\":36548,\"start\":36539},{\"end\":36573,\"start\":36552},{\"end\":36593,\"start\":36577},{\"end\":36603,\"start\":36597},{\"end\":36619,\"start\":36607},{\"end\":36630,\"start\":36625},{\"end\":37076,\"start\":37066},{\"end\":37089,\"start\":37080},{\"end\":37298,\"start\":37294},{\"end\":37309,\"start\":37302},{\"end\":37516,\"start\":37511},{\"end\":37523,\"start\":37520},{\"end\":37534,\"start\":37527},{\"end\":37542,\"start\":37538},{\"end\":37845,\"start\":37833},{\"end\":37855,\"start\":37849},{\"end\":37866,\"start\":37859},{\"end\":37873,\"start\":37870},{\"end\":38362,\"start\":38355},{\"end\":38371,\"start\":38368},{\"end\":38385,\"start\":38382},{\"end\":38397,\"start\":38389},{\"end\":38405,\"start\":38401},{\"end\":38417,\"start\":38409},{\"end\":38426,\"start\":38421},{\"end\":38439,\"start\":38430},{\"end\":38453,\"start\":38443},{\"end\":38827,\"start\":38817},{\"end\":38839,\"start\":38831},{\"end\":38851,\"start\":38843},{\"end\":38861,\"start\":38855},{\"end\":38868,\"start\":38865},{\"end\":38878,\"start\":38872},{\"end\":39075,\"start\":39068},{\"end\":39084,\"start\":39079},{\"end\":39095,\"start\":39088},{\"end\":39354,\"start\":39348},{\"end\":39365,\"start\":39358},{\"end\":39636,\"start\":39629},{\"end\":39645,\"start\":39640},{\"end\":39655,\"start\":39649},{\"end\":39666,\"start\":39659},{\"end\":40535,\"start\":40523},{\"end\":40547,\"start\":40539},{\"end\":40558,\"start\":40553},{\"end\":40578,\"start\":40566},{\"end\":40593,\"start\":40584},{\"end\":40604,\"start\":40599},{\"end\":40616,\"start\":40608},{\"end\":40631,\"start\":40622},{\"end\":40958,\"start\":40949},{\"end\":40972,\"start\":40965},{\"end\":41279,\"start\":41273},{\"end\":41290,\"start\":41283},{\"end\":41301,\"start\":41294},{\"end\":41311,\"start\":41303},{\"end\":42215,\"start\":42203},{\"end\":42229,\"start\":42219},{\"end\":42246,\"start\":42235},{\"end\":42258,\"start\":42250},{\"end\":42273,\"start\":42264},{\"end\":42491,\"start\":42484},{\"end\":42503,\"start\":42495},{\"end\":42514,\"start\":42507},{\"end\":42526,\"start\":42518},{\"end\":42865,\"start\":42857},{\"end\":42881,\"start\":42869},{\"end\":43301,\"start\":43289},{\"end\":43315,\"start\":43305},{\"end\":43328,\"start\":43321},{\"end\":43340,\"start\":43332},{\"end\":43355,\"start\":43346},{\"end\":43656,\"start\":43651},{\"end\":43668,\"start\":43660},{\"end\":43971,\"start\":43964},{\"end\":43994,\"start\":43977},{\"end\":44005,\"start\":43998},{\"end\":44021,\"start\":44011},{\"end\":44031,\"start\":44025},{\"end\":44572,\"start\":44564},{\"end\":44586,\"start\":44576},{\"end\":44596,\"start\":44592},{\"end\":44606,\"start\":44600},{\"end\":44615,\"start\":44610},{\"end\":44886,\"start\":44882},{\"end\":44896,\"start\":44890},{\"end\":44907,\"start\":44900},{\"end\":45220,\"start\":45214},{\"end\":45230,\"start\":45226}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":17557614},\"end\":32270,\"start\":31912},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":1729012},\"end\":32556,\"start\":32272},{\"attributes\":{\"doi\":\"10.1137/1.9781611972825.84\",\"id\":\"b2\"},\"end\":33097,\"start\":32558},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":17766069},\"end\":33520,\"start\":33099},{\"attributes\":{\"doi\":\"10.1109/TNN.2009.2033473\",\"id\":\"b4\",\"matched_paper_id\":8281463},\"end\":33974,\"start\":33522},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":51613805},\"end\":34326,\"start\":33976},{\"attributes\":{\"doi\":\"abs/1709.05584\",\"id\":\"b6\",\"matched_paper_id\":3215337},\"end\":34633,\"start\":34328},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":17486263},\"end\":34899,\"start\":34635},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":206756462},\"end\":35321,\"start\":34901},{\"attributes\":{\"doi\":\"10.1109/72.572108\",\"id\":\"b9\",\"matched_paper_id\":5942593},\"end\":35672,\"start\":35323},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":8393918},\"end\":35915,\"start\":35674},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":69568978},\"end\":36140,\"start\":35917},{\"attributes\":{\"id\":\"b12\"},\"end\":36453,\"start\":36142},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1690180},\"end\":36985,\"start\":36455},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":17648673},\"end\":37222,\"start\":36987},{\"attributes\":{\"id\":\"b15\"},\"end\":37440,\"start\":37224},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":4770492},\"end\":37752,\"start\":37442},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3507043},\"end\":38319,\"start\":37754},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":206592484},\"end\":38787,\"start\":38321},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":3292002},\"end\":39013,\"start\":38789},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":1430801},\"end\":39303,\"start\":39015},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":15483870},\"end\":39562,\"start\":39305},{\"attributes\":{\"doi\":\"http:/link.springer.com/10.1007/b12006\",\"id\":\"b22\",\"matched_paper_id\":10856944},\"end\":40464,\"start\":39564},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":17557614},\"end\":40912,\"start\":40466},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":1550330},\"end\":41219,\"start\":40914},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":1969813},\"end\":41477,\"start\":41221},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":18448541},\"end\":41772,\"start\":41479},{\"attributes\":{\"doi\":\"http:/link.springer.com/10.1007/978-3-319-12640-1{_}12\",\"id\":\"b27\",\"matched_paper_id\":7500102},\"end\":42166,\"start\":41774},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1797579},\"end\":42438,\"start\":42168},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":7218366},\"end\":42833,\"start\":42440},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":207227372},\"end\":43252,\"start\":42835},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":1797579},\"end\":43594,\"start\":43254},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":16262476},\"end\":43804,\"start\":43596},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":19990980},\"end\":44389,\"start\":43806},{\"attributes\":{\"doi\":\"http:/pubs.acs.org/doi/abs/10.1021/jm00106a046\",\"id\":\"b34\"},\"end\":44497,\"start\":44391},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":60027311},\"end\":44794,\"start\":44499},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":2596211},\"end\":45138,\"start\":44796},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":5719990},\"end\":45432,\"start\":45140},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":17557614},\"end\":32270,\"start\":31912},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":1729012},\"end\":32556,\"start\":32272},{\"attributes\":{\"doi\":\"10.1137/1.9781611972825.84\",\"id\":\"b2\"},\"end\":33097,\"start\":32558},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":17766069},\"end\":33520,\"start\":33099},{\"attributes\":{\"doi\":\"10.1109/TNN.2009.2033473\",\"id\":\"b4\",\"matched_paper_id\":8281463},\"end\":33974,\"start\":33522},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":51613805},\"end\":34326,\"start\":33976},{\"attributes\":{\"doi\":\"abs/1709.05584\",\"id\":\"b6\",\"matched_paper_id\":3215337},\"end\":34633,\"start\":34328},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":17486263},\"end\":34899,\"start\":34635},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":206756462},\"end\":35321,\"start\":34901},{\"attributes\":{\"doi\":\"10.1109/72.572108\",\"id\":\"b9\",\"matched_paper_id\":5942593},\"end\":35672,\"start\":35323},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":8393918},\"end\":35915,\"start\":35674},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":69568978},\"end\":36140,\"start\":35917},{\"attributes\":{\"id\":\"b12\"},\"end\":36453,\"start\":36142},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1690180},\"end\":36985,\"start\":36455},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":17648673},\"end\":37222,\"start\":36987},{\"attributes\":{\"id\":\"b15\"},\"end\":37440,\"start\":37224},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":4770492},\"end\":37752,\"start\":37442},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3507043},\"end\":38319,\"start\":37754},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":206592484},\"end\":38787,\"start\":38321},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":3292002},\"end\":39013,\"start\":38789},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":1430801},\"end\":39303,\"start\":39015},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":15483870},\"end\":39562,\"start\":39305},{\"attributes\":{\"doi\":\"http:/link.springer.com/10.1007/b12006\",\"id\":\"b22\",\"matched_paper_id\":10856944},\"end\":40464,\"start\":39564},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":17557614},\"end\":40912,\"start\":40466},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":1550330},\"end\":41219,\"start\":40914},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":1969813},\"end\":41477,\"start\":41221},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":18448541},\"end\":41772,\"start\":41479},{\"attributes\":{\"doi\":\"http:/link.springer.com/10.1007/978-3-319-12640-1{_}12\",\"id\":\"b27\",\"matched_paper_id\":7500102},\"end\":42166,\"start\":41774},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1797579},\"end\":42438,\"start\":42168},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":7218366},\"end\":42833,\"start\":42440},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":207227372},\"end\":43252,\"start\":42835},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":1797579},\"end\":43594,\"start\":43254},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":16262476},\"end\":43804,\"start\":43596},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":19990980},\"end\":44389,\"start\":43806},{\"attributes\":{\"doi\":\"http:/pubs.acs.org/doi/abs/10.1021/jm00106a046\",\"id\":\"b34\"},\"end\":44497,\"start\":44391},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":60027311},\"end\":44794,\"start\":44499},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":2596211},\"end\":45138,\"start\":44796},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":5719990},\"end\":45432,\"start\":45140}]", "bib_title": "[{\"end\":31965,\"start\":31912},{\"end\":32285,\"start\":32272},{\"end\":32587,\"start\":32558},{\"end\":33137,\"start\":33099},{\"end\":33592,\"start\":33522},{\"end\":34019,\"start\":33976},{\"end\":34387,\"start\":34328},{\"end\":34696,\"start\":34635},{\"end\":34931,\"start\":34901},{\"end\":35386,\"start\":35323},{\"end\":35710,\"start\":35674},{\"end\":35977,\"start\":35917},{\"end\":36185,\"start\":36142},{\"end\":36523,\"start\":36455},{\"end\":37062,\"start\":36987},{\"end\":37507,\"start\":37442},{\"end\":37829,\"start\":37754},{\"end\":38351,\"start\":38321},{\"end\":38813,\"start\":38789},{\"end\":39064,\"start\":39015},{\"end\":39344,\"start\":39305},{\"end\":39625,\"start\":39564},{\"end\":40519,\"start\":40466},{\"end\":40945,\"start\":40914},{\"end\":41269,\"start\":41221},{\"end\":41509,\"start\":41479},{\"end\":41850,\"start\":41774},{\"end\":42199,\"start\":42168},{\"end\":42480,\"start\":42440},{\"end\":42853,\"start\":42835},{\"end\":43285,\"start\":43254},{\"end\":43647,\"start\":43596},{\"end\":43958,\"start\":43806},{\"end\":44560,\"start\":44499},{\"end\":44878,\"start\":44796},{\"end\":45208,\"start\":45140},{\"end\":31965,\"start\":31912},{\"end\":32285,\"start\":32272},{\"end\":32587,\"start\":32558},{\"end\":33137,\"start\":33099},{\"end\":33592,\"start\":33522},{\"end\":34019,\"start\":33976},{\"end\":34387,\"start\":34328},{\"end\":34696,\"start\":34635},{\"end\":34931,\"start\":34901},{\"end\":35386,\"start\":35323},{\"end\":35710,\"start\":35674},{\"end\":35977,\"start\":35917},{\"end\":36185,\"start\":36142},{\"end\":36523,\"start\":36455},{\"end\":37062,\"start\":36987},{\"end\":37507,\"start\":37442},{\"end\":37829,\"start\":37754},{\"end\":38351,\"start\":38321},{\"end\":38813,\"start\":38789},{\"end\":39064,\"start\":39015},{\"end\":39344,\"start\":39305},{\"end\":39625,\"start\":39564},{\"end\":40519,\"start\":40466},{\"end\":40945,\"start\":40914},{\"end\":41269,\"start\":41221},{\"end\":41509,\"start\":41479},{\"end\":41850,\"start\":41774},{\"end\":42199,\"start\":42168},{\"end\":42480,\"start\":42440},{\"end\":42853,\"start\":42835},{\"end\":43285,\"start\":43254},{\"end\":43647,\"start\":43596},{\"end\":43958,\"start\":43806},{\"end\":44560,\"start\":44499},{\"end\":44878,\"start\":44796},{\"end\":45208,\"start\":45140}]", "bib_author": "[{\"end\":31983,\"start\":31967},{\"end\":31999,\"start\":31983},{\"end\":32008,\"start\":31999},{\"end\":32020,\"start\":32008},{\"end\":32033,\"start\":32020},{\"end\":32307,\"start\":32287},{\"end\":32324,\"start\":32307},{\"end\":32334,\"start\":32324},{\"end\":32349,\"start\":32334},{\"end\":32599,\"start\":32589},{\"end\":32610,\"start\":32599},{\"end\":32621,\"start\":32610},{\"end\":32631,\"start\":32621},{\"end\":33157,\"start\":33139},{\"end\":33604,\"start\":33594},{\"end\":33614,\"start\":33604},{\"end\":33625,\"start\":33614},{\"end\":33641,\"start\":33625},{\"end\":33651,\"start\":33641},{\"end\":34031,\"start\":34021},{\"end\":34042,\"start\":34031},{\"end\":34054,\"start\":34042},{\"end\":34403,\"start\":34389},{\"end\":34411,\"start\":34403},{\"end\":34423,\"start\":34411},{\"end\":34709,\"start\":34698},{\"end\":34946,\"start\":34933},{\"end\":34954,\"start\":34946},{\"end\":34973,\"start\":34954},{\"end\":34989,\"start\":34973},{\"end\":35003,\"start\":34989},{\"end\":35400,\"start\":35388},{\"end\":35411,\"start\":35400},{\"end\":35718,\"start\":35712},{\"end\":35728,\"start\":35718},{\"end\":35744,\"start\":35728},{\"end\":35753,\"start\":35744},{\"end\":35990,\"start\":35979},{\"end\":36001,\"start\":35990},{\"end\":36195,\"start\":36187},{\"end\":36205,\"start\":36195},{\"end\":36537,\"start\":36525},{\"end\":36550,\"start\":36537},{\"end\":36575,\"start\":36550},{\"end\":36595,\"start\":36575},{\"end\":36605,\"start\":36595},{\"end\":36621,\"start\":36605},{\"end\":36632,\"start\":36621},{\"end\":37078,\"start\":37064},{\"end\":37091,\"start\":37078},{\"end\":37300,\"start\":37290},{\"end\":37311,\"start\":37300},{\"end\":37518,\"start\":37509},{\"end\":37525,\"start\":37518},{\"end\":37536,\"start\":37525},{\"end\":37544,\"start\":37536},{\"end\":37847,\"start\":37831},{\"end\":37857,\"start\":37847},{\"end\":37868,\"start\":37857},{\"end\":37875,\"start\":37868},{\"end\":38364,\"start\":38353},{\"end\":38373,\"start\":38364},{\"end\":38387,\"start\":38373},{\"end\":38399,\"start\":38387},{\"end\":38407,\"start\":38399},{\"end\":38419,\"start\":38407},{\"end\":38428,\"start\":38419},{\"end\":38441,\"start\":38428},{\"end\":38455,\"start\":38441},{\"end\":38829,\"start\":38815},{\"end\":38841,\"start\":38829},{\"end\":38853,\"start\":38841},{\"end\":38863,\"start\":38853},{\"end\":38870,\"start\":38863},{\"end\":38880,\"start\":38870},{\"end\":39077,\"start\":39066},{\"end\":39086,\"start\":39077},{\"end\":39097,\"start\":39086},{\"end\":39356,\"start\":39346},{\"end\":39367,\"start\":39356},{\"end\":39638,\"start\":39627},{\"end\":39647,\"start\":39638},{\"end\":39657,\"start\":39647},{\"end\":39668,\"start\":39657},{\"end\":40537,\"start\":40521},{\"end\":40549,\"start\":40537},{\"end\":40560,\"start\":40549},{\"end\":40580,\"start\":40560},{\"end\":40595,\"start\":40580},{\"end\":40606,\"start\":40595},{\"end\":40618,\"start\":40606},{\"end\":40633,\"start\":40618},{\"end\":40960,\"start\":40947},{\"end\":40974,\"start\":40960},{\"end\":41281,\"start\":41271},{\"end\":41292,\"start\":41281},{\"end\":41303,\"start\":41292},{\"end\":41313,\"start\":41303},{\"end\":42217,\"start\":42201},{\"end\":42231,\"start\":42217},{\"end\":42248,\"start\":42231},{\"end\":42260,\"start\":42248},{\"end\":42275,\"start\":42260},{\"end\":42493,\"start\":42482},{\"end\":42505,\"start\":42493},{\"end\":42516,\"start\":42505},{\"end\":42528,\"start\":42516},{\"end\":42867,\"start\":42855},{\"end\":42883,\"start\":42867},{\"end\":43303,\"start\":43287},{\"end\":43317,\"start\":43303},{\"end\":43330,\"start\":43317},{\"end\":43342,\"start\":43330},{\"end\":43357,\"start\":43342},{\"end\":43658,\"start\":43649},{\"end\":43670,\"start\":43658},{\"end\":43973,\"start\":43960},{\"end\":43996,\"start\":43973},{\"end\":44007,\"start\":43996},{\"end\":44023,\"start\":44007},{\"end\":44033,\"start\":44023},{\"end\":44574,\"start\":44562},{\"end\":44588,\"start\":44574},{\"end\":44598,\"start\":44588},{\"end\":44608,\"start\":44598},{\"end\":44617,\"start\":44608},{\"end\":44888,\"start\":44880},{\"end\":44898,\"start\":44888},{\"end\":44909,\"start\":44898},{\"end\":45222,\"start\":45210},{\"end\":45232,\"start\":45222},{\"end\":31983,\"start\":31967},{\"end\":31999,\"start\":31983},{\"end\":32008,\"start\":31999},{\"end\":32020,\"start\":32008},{\"end\":32033,\"start\":32020},{\"end\":32307,\"start\":32287},{\"end\":32324,\"start\":32307},{\"end\":32334,\"start\":32324},{\"end\":32349,\"start\":32334},{\"end\":32599,\"start\":32589},{\"end\":32610,\"start\":32599},{\"end\":32621,\"start\":32610},{\"end\":32631,\"start\":32621},{\"end\":33157,\"start\":33139},{\"end\":33604,\"start\":33594},{\"end\":33614,\"start\":33604},{\"end\":33625,\"start\":33614},{\"end\":33641,\"start\":33625},{\"end\":33651,\"start\":33641},{\"end\":34031,\"start\":34021},{\"end\":34042,\"start\":34031},{\"end\":34054,\"start\":34042},{\"end\":34403,\"start\":34389},{\"end\":34411,\"start\":34403},{\"end\":34423,\"start\":34411},{\"end\":34709,\"start\":34698},{\"end\":34946,\"start\":34933},{\"end\":34954,\"start\":34946},{\"end\":34973,\"start\":34954},{\"end\":34989,\"start\":34973},{\"end\":35003,\"start\":34989},{\"end\":35400,\"start\":35388},{\"end\":35411,\"start\":35400},{\"end\":35718,\"start\":35712},{\"end\":35728,\"start\":35718},{\"end\":35744,\"start\":35728},{\"end\":35753,\"start\":35744},{\"end\":35990,\"start\":35979},{\"end\":36001,\"start\":35990},{\"end\":36195,\"start\":36187},{\"end\":36205,\"start\":36195},{\"end\":36537,\"start\":36525},{\"end\":36550,\"start\":36537},{\"end\":36575,\"start\":36550},{\"end\":36595,\"start\":36575},{\"end\":36605,\"start\":36595},{\"end\":36621,\"start\":36605},{\"end\":36632,\"start\":36621},{\"end\":37078,\"start\":37064},{\"end\":37091,\"start\":37078},{\"end\":37300,\"start\":37290},{\"end\":37311,\"start\":37300},{\"end\":37518,\"start\":37509},{\"end\":37525,\"start\":37518},{\"end\":37536,\"start\":37525},{\"end\":37544,\"start\":37536},{\"end\":37847,\"start\":37831},{\"end\":37857,\"start\":37847},{\"end\":37868,\"start\":37857},{\"end\":37875,\"start\":37868},{\"end\":38364,\"start\":38353},{\"end\":38373,\"start\":38364},{\"end\":38387,\"start\":38373},{\"end\":38399,\"start\":38387},{\"end\":38407,\"start\":38399},{\"end\":38419,\"start\":38407},{\"end\":38428,\"start\":38419},{\"end\":38441,\"start\":38428},{\"end\":38455,\"start\":38441},{\"end\":38829,\"start\":38815},{\"end\":38841,\"start\":38829},{\"end\":38853,\"start\":38841},{\"end\":38863,\"start\":38853},{\"end\":38870,\"start\":38863},{\"end\":38880,\"start\":38870},{\"end\":39077,\"start\":39066},{\"end\":39086,\"start\":39077},{\"end\":39097,\"start\":39086},{\"end\":39356,\"start\":39346},{\"end\":39367,\"start\":39356},{\"end\":39638,\"start\":39627},{\"end\":39647,\"start\":39638},{\"end\":39657,\"start\":39647},{\"end\":39668,\"start\":39657},{\"end\":40537,\"start\":40521},{\"end\":40549,\"start\":40537},{\"end\":40560,\"start\":40549},{\"end\":40580,\"start\":40560},{\"end\":40595,\"start\":40580},{\"end\":40606,\"start\":40595},{\"end\":40618,\"start\":40606},{\"end\":40633,\"start\":40618},{\"end\":40960,\"start\":40947},{\"end\":40974,\"start\":40960},{\"end\":41281,\"start\":41271},{\"end\":41292,\"start\":41281},{\"end\":41303,\"start\":41292},{\"end\":41313,\"start\":41303},{\"end\":42217,\"start\":42201},{\"end\":42231,\"start\":42217},{\"end\":42248,\"start\":42231},{\"end\":42260,\"start\":42248},{\"end\":42275,\"start\":42260},{\"end\":42493,\"start\":42482},{\"end\":42505,\"start\":42493},{\"end\":42516,\"start\":42505},{\"end\":42528,\"start\":42516},{\"end\":42867,\"start\":42855},{\"end\":42883,\"start\":42867},{\"end\":43303,\"start\":43287},{\"end\":43317,\"start\":43303},{\"end\":43330,\"start\":43317},{\"end\":43342,\"start\":43330},{\"end\":43357,\"start\":43342},{\"end\":43658,\"start\":43649},{\"end\":43670,\"start\":43658},{\"end\":43973,\"start\":43960},{\"end\":43996,\"start\":43973},{\"end\":44007,\"start\":43996},{\"end\":44023,\"start\":44007},{\"end\":44033,\"start\":44023},{\"end\":44574,\"start\":44562},{\"end\":44588,\"start\":44574},{\"end\":44598,\"start\":44588},{\"end\":44608,\"start\":44598},{\"end\":44617,\"start\":44608},{\"end\":44888,\"start\":44880},{\"end\":44898,\"start\":44888},{\"end\":44909,\"start\":44898},{\"end\":45222,\"start\":45210},{\"end\":45232,\"start\":45222}]", "bib_venue": "[{\"end\":32810,\"start\":32730},{\"end\":33305,\"start\":33227},{\"end\":36699,\"start\":36683},{\"end\":38036,\"start\":37964},{\"end\":40019,\"start\":39859},{\"end\":41001,\"start\":40980},{\"end\":41640,\"start\":41584},{\"end\":43066,\"start\":42983},{\"end\":32810,\"start\":32730},{\"end\":33305,\"start\":33227},{\"end\":36699,\"start\":36683},{\"end\":38036,\"start\":37964},{\"end\":40019,\"start\":39859},{\"end\":41001,\"start\":40980},{\"end\":41640,\"start\":41584},{\"end\":43066,\"start\":42983},{\"end\":32071,\"start\":32033},{\"end\":32385,\"start\":32349},{\"end\":32728,\"start\":32657},{\"end\":33225,\"start\":33157},{\"end\":33702,\"start\":33675},{\"end\":34092,\"start\":34054},{\"end\":34441,\"start\":34437},{\"end\":34745,\"start\":34709},{\"end\":35039,\"start\":35003},{\"end\":35455,\"start\":35428},{\"end\":35757,\"start\":35753},{\"end\":36019,\"start\":36001},{\"end\":36248,\"start\":36205},{\"end\":36681,\"start\":36632},{\"end\":37095,\"start\":37091},{\"end\":37288,\"start\":37224},{\"end\":37586,\"start\":37544},{\"end\":37962,\"start\":37875},{\"end\":38525,\"start\":38455},{\"end\":38884,\"start\":38880},{\"end\":39141,\"start\":39097},{\"end\":39416,\"start\":39367},{\"end\":39844,\"start\":39706},{\"end\":40640,\"start\":40633},{\"end\":40978,\"start\":40974},{\"end\":41327,\"start\":41313},{\"end\":41582,\"start\":41511},{\"end\":41935,\"start\":41906},{\"end\":42279,\"start\":42275},{\"end\":42610,\"start\":42528},{\"end\":42981,\"start\":42883},{\"end\":43393,\"start\":43357},{\"end\":43674,\"start\":43670},{\"end\":44063,\"start\":44033},{\"end\":44631,\"start\":44617},{\"end\":44942,\"start\":44909},{\"end\":45260,\"start\":45232},{\"end\":32071,\"start\":32033},{\"end\":32385,\"start\":32349},{\"end\":32728,\"start\":32657},{\"end\":33225,\"start\":33157},{\"end\":33702,\"start\":33675},{\"end\":34092,\"start\":34054},{\"end\":34441,\"start\":34437},{\"end\":34745,\"start\":34709},{\"end\":35039,\"start\":35003},{\"end\":35455,\"start\":35428},{\"end\":35757,\"start\":35753},{\"end\":36019,\"start\":36001},{\"end\":36248,\"start\":36205},{\"end\":36681,\"start\":36632},{\"end\":37095,\"start\":37091},{\"end\":37288,\"start\":37224},{\"end\":37586,\"start\":37544},{\"end\":37962,\"start\":37875},{\"end\":38525,\"start\":38455},{\"end\":38884,\"start\":38880},{\"end\":39141,\"start\":39097},{\"end\":39416,\"start\":39367},{\"end\":39844,\"start\":39706},{\"end\":40640,\"start\":40633},{\"end\":40978,\"start\":40974},{\"end\":41327,\"start\":41313},{\"end\":41582,\"start\":41511},{\"end\":41935,\"start\":41906},{\"end\":42279,\"start\":42275},{\"end\":42610,\"start\":42528},{\"end\":42981,\"start\":42883},{\"end\":43393,\"start\":43357},{\"end\":43674,\"start\":43670},{\"end\":44063,\"start\":44033},{\"end\":44631,\"start\":44617},{\"end\":44942,\"start\":44909},{\"end\":45260,\"start\":45232}]"}}}, "year": 2023, "month": 12, "day": 17}