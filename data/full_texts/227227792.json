{"id": 227227792, "updated": "2023-11-29 16:46:38.602", "metadata": {"title": "A Survey on Deep Learning for Software Engineering", "authors": "[{\"first\":\"Yanming\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Xin\",\"last\":\"Xia\",\"middle\":[]},{\"first\":\"David\",\"last\":\"Lo\",\"middle\":[]},{\"first\":\"John\",\"last\":\"Grundy\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": 11, "day": 30}, "abstract": "In 2006, Geoffrey Hinton proposed the concept of training ''Deep Neural Networks (DNNs)'' and an improved model training method to break the bottleneck of neural network development. More recently, the introduction of AlphaGo in 2016 demonstrated the powerful learning ability of deep learning and its enormous potential. Deep learning has been increasingly used to develop state-of-the-art software engineering (SE) research tools due to its ability to boost performance for various SE tasks. There are many factors, e.g., deep learning model selection, internal structure differences, and model optimization techniques, that may have an impact on the performance of DNNs applied in SE. Few works to date focus on summarizing, classifying, and analyzing the application of deep learning techniques in SE. To fill this gap, we performed a survey to analyse the relevant studies published since 2006. We first provide an example to illustrate how deep learning techniques are used in SE. We then summarize and classify different deep learning techniques used in SE. We analyzed key optimization technologies used in these deep learning models, and finally describe a range of key research topics using DNNs in SE. Based on our findings, we present a set of current challenges remaining to be investigated and outline a proposed research road map highlighting key opportunities for future work.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3108184962", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/csur/YangXLG22", "doi": "10.1145/3505243"}}, "content": {"source": {"pdf_hash": "bea6af010fc02f5ac29edfc17096be6078edab46", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2011.14597v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "25924f0e432a4b9f361af378c4ce9c9ce0d961a0", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/bea6af010fc02f5ac29edfc17096be6078edab46.txt", "contents": "\nA Survey on Deep Learning for Software Engineering\nJanuary 2020\n\nYanming Yang \nDavid Lo \nYanming Yang \nXin Xia \nDavid Lo \nJohn Grundy \n\nFaculty of Information Technology\nFaculty of Information Technology\nXIN XIA\nMonash University\nAustralia\n\n\nSchool of Information Systems\nMonash University\nAustralia, Singapore\n\n\nJOHN GRUNDY\nFaculty of Information Technology\nManagement University\nSingapore\n\n\nMonash University\nAustralia\n\nA Survey on Deep Learning for Software Engineering\n\n2020. A Survey on Deep Learning for Software Engineering. ACM Comput. Surv. 1, 1, Article\n1January 202010.1145/1122445.11224561 Additional Key Words and Phrases: Deep learning, neural network, machine learning, software engineering, survey ACM Reference Format:\nIn 2006, Geoffrey Hinton proposed the concept of training \"Deep Neural Networks (DNNs)\" and an improved model training method to break the bottleneck of neural network development. More recently, the introduction of AlphaGo in 2016 demonstrated the powerful learning ability of deep learning and its enormous potential. Deep learning has been increasingly used to develop state-of-the-art software engineering (SE) research tools due to its ability to boost performance for various SE tasks. There are many factors, e.g., deep learning model selection, internal structure differences, and model optimization techniques, that may have an impact on the performance of DNNs applied in SE. Few works to date focus on summarizing, classifying, and analyzing the application of deep learning techniques in SE. To fill this gap, we performed a survey to analyse the relevant studies published since 2006. We first provide an example to illustrate how deep learning techniques are used in SE. We then summarize and classify different deep learning techniques used in SE. We analyzed key optimization technologies used in these deep learning models, and finally describe a range of key research topics using DNNs in SE. Based on our findings, we present a set of current challenges remaining to be investigated and outline a proposed research road map highlighting key opportunities for future work.AlexNet on the ImageNet dataset. AlexNet outperformed the second best classifier (SVM) by a substantial margin. In March 2016, AlphaGo was developed by DeepMind, a subsidiary of Google, which defeated the world champion of Go by a big score. With continuous improvements in DL's network structures, training methods and hardware devices, DL has been widely used to solve a wide variety of research problems in various fields.Driven by the success of DL techniques in image recognition and data mining, industrial practitioners and academic researchers have shown great enthusiasm for exploring and applying DL algorithms in diverse software engineering (SE) tasks, including requirements, software design and modeling, software implementation, testing and debugging, and maintenance. In requirements engineering, various DL algorithms have been employed to extract key features for requirement analysis, and automatically identify actors and actions (i.e., user cases) in natural language-based requirement descriptions[1,100,127]. In software design and modeling, DL has been leveraged for design pattern detection [108], UI design search [14], and software design mining [81]. During software implementation, researchers and developers have used DL for source code generation [26], source code modeling [49], software effort/cost estimation [7], etc. In software testing and debugging, various DL algorithms have been designed for detecting and fixing defects and bugs existed in software products, e.g., defect prediction [118], bug localization [63], vulnerability prediction [37]. It has been used for a varietu of software testing applications, such as test case generation [73], and automatic testing [144]. Researchers have applied DL to SE tasks to facilitate software maintenance and evolution, such as code clone detection [90], feature envy detection [69], code change recommendation [106], user review classification [28], etc.However, there is a lack of a comprehensive survey of deep learning usage to date in SE. This study performs a detailed survey to review, summarize, classify, and analyze relevant papers in the field of SE that apply DL models. We collected, reviewed, and analyzed 142 papers published in 20 major SE conferences and journals since \"deep learning\" was introduced in 2006. We then analyzed the development trends of DL in SE, classified various DL techniques used in diverse SE tasks, analyzed DL's construction process, and summarized the research topics tackled by relevant papers. This study makes the following contributions:Most learning algorithms are shallow models with one or two non-linear feature representation layers, such as GMM, HMM, SVM, and MLP. The limitation of such a shallow model is the lack of ability to express complex functions. Their generalization ability is restricted for the complexity of problems, resulting in decreased learning ability.Deep learning allows computational models composed of multiple layers to learn data representations with multiple higher levels of abstraction[61]. This builds a neural network that simulates the human brain for analysis and learning. Similar to traditional ML, DL is suitable for various types of problems, such as regression, clustering, classification, ranking, and generation problems. We present the basic structure of a DNN inFig. 1.Based on the position and function of different layers, layers in a DNN can be classified into three categories, i.e., the input layer, the hidden layer, and the output layer. Generally, the first layer denotes the input layer, where the preprocessed data can be fed into DNNs; the last layer denotes the output layer, from which the results of a model can be achieved, e.g., classification results, regression results, generation results, etc. The middle layers between the input layer and the output layer are hidden layers. DNNs usually contain multiple hidden layers for enhancing the expressive ability of DNNs and learning high-level feature representation. Besides, the way to connect between different layers may vary, and as shown inFig. 1, adjacent layers are full-connected (aka., full-connected layer), meaning that any neuron in the \u210e layer are connected to any neuron in the + 1 \u210e layer. In some DNNs with complex structures, for tackling different SE issues, not only the fully connected layer can be used as a hidden layer, but also a layer composed of other types of neurons can also be used as the hidden layer of a DNN, such as convolution layer, pooling layer, LSTM layers, etc.. Currently, diverse DNNs and learning methods are used for SE tasks, such as Feedback Neural Network (FNN),We present an example of using DL for a representative SE task. A novel sequence-to-sequence neural network is used to automatically perform comment updates with code changes[77]. Code comments are a vital source of software documentation, helping developers to have a better understanding of source code and are beneficial to the communication between developers. However, developers sometimes neglect to update comments after changing source code, leading to obsolete or inconsistent comments. It is necessary to perform Just-In-Time (JIT) code comments updating, which aims to reduce and even avoid bad comments. To achieve this, a new approach called CUP builds a novel neural seq2seq model. Using DL techniques for such an SE task can be broken into six steps:(1) data collection, (2) data processing, (3) input construction, (4) model training, (5) model optimization, (6) model testing, and (6) model application.Data collection: Collecting data is a key step when building and training a DL model. Different SE tasks need to process and analyze different data types, such as requirements documents for requirements analysis, bug reports for bug report summarization, source code for code clone detection or code search, etc. In this example, for updating JIT code comments, the commonly available data are method-level code change datasets with comments. Each qualified instance contains old code snippets, new code snippets, old code comments, and new code comments.Data processing: Processing raw data involves a number of steps, including data filtering, data splitting, data cleaning, data augmentation, and data segmentation for eliminating noise in data. For JIT code comments updating, some instances are removed with unqualified comments, and no differences or empty between old and new comments. Instances containing abstract methods are deleted to reduce method mismatching.Input construction: Since most DL models have strict requirements on the input-form, such as the input requiring to be numeric and fixed size, it is necessary to transform SE data into multi-dimensional vectors in order to use DL models. In this JIT code comment updating example, code comments and code changes can be viewed as text-based data, processed by using a token-based method. Code changes and code comments are converted into sequences so that they can be fed into their seq2seq model through data flattening and tokenization. After tokenization, old comments are converted into a token sequence. While to better represent code changes, each change is aligned into two token sequences and construct a triple < ,\n\nINTRODUCTION\n\nIn 1943, Warren Mcculloch and Walter Pitts first introduced the concept of the Artificial Neural Network (ANN) and proposed a mathematical model of an artificial neuron [84]. This pioneered a new era of research on artificial intelligence (AI). In 2006, Hinton et al. [40] proposed the concept of \"Deep Learning (DL)\". They believed that an ANN with multiple layers possessed extraordinary feature learning ability, which allows the feature data learned to represent the essence of the original data. In 2009, they proposed Deep Belief Networks(DBN) and an unsupervised greedy layer-wise pre-training algorithm [87], showing great ability to solve complex problems. DL has since attracted attention of academics and industry practioners for many tasks. Development of Nvidia's graphics processing units (GPUs) significantly reduced the computation time of DL-based algorithms. DL has now entered a period of great development. In 2012 Hinton's research group participated in an image recognition competition for the first time and won the championship in a landslide victory by training a CNN model called (1) We conducted a detailed analysis on 142 relevant studies that used DL techniques in terms of publication trend, distribution of publication venues, and types of contributions. We analyzed an example in detail to describe the basic framework and the usage of DL techniques in SE. (2) We provide a classification of DL models used in SE based on their architectures and an analysis of DL technique selection strategy. (3) We performed a comprehensive analysis on the key factors that impact the performance of DL models in SE, including dataset, model optimization, and model evaluation. (4) We provide a description of each primary study according to six different SE activities and conducted an analysis on these studies based on their task types. These include regression, classification, ranking, and generation tasks. (5) We discuss distinct technical challenges of using DL in software engineering and outline key future avenues for research on using DL in software engineering.\n\nSection 2 introduces the workflow of a DL model through an example. Section 3 presents our Systematic Literature Review methodology. Section 4 investigates the distribution and evolution of DL studies for SE tasks, and Section 5 gives an overall analysis on various DL techniques used in primary studies, including classifying 30 DNN models based on their architectures and summarizing the model selection strategies adopted by studies. Section 6 analyzes a set of key techniques from four perspectives -datasets, model optimization, model evaluation, and the accessibility of source code. Section 7 lists research topics involved in primary studies and makes a briefly description of each work. Section 8 presents limitations of this study and its main threats to validity. Section 9 discusses the challenges that still need to be solved in future work and outlines a clear research road-map of research opportunities. Section 10 concludes this paper. , > as an edit sequence to respectively record old source code, new source code, and an edit action, i.e., insert, delete, equal or replace.\n\nModel training: DL users need to select suitable DL techniques and different datasets, construct the structure of a model, and decide model configuration, e.g., the number of layers and neural units of each layers. In our example, a seq2seq DL model was built by training an encoder-decoder LSTM, since it is good at process nature language text and token-based source code. In this model, the edit sequence of a code change and a token sequence of its old comment were fed into the input layer. To capture the relationship between the code change and the old comment, the encoder was composed of 4 layers: an embedding layer, a contextual embed layer, a co-attention layer, and a modeling layer, where each layer had its role. The decoder included 2 layers: a LSTM layer and a dense layer. The output of decoder was a new comment based on the corresponding captured relationship.\n\nModel optimization: After model design and construction, the designed model will be trained with the training set for achieving an effective DL model. Whether a model can work depends on thousands of parameters (aka., weights), connecting neural units adjacent layers. Hence, model training is to fine-tune these weights to minimize the loss of the model. For the seq2seq model in the example, the weights in the seq2seq neural network are trained by minimizing the difference between the real new comment and the generated new comment in a supervised way.\n\nModel testing: Generally, a training set is usually divided into two subsets of unequal sizes. The big subset is used for training the DL model, while the small one will be used for validating and testing the performance of the model when meeting new data. In this example, 20% of samples in the training set are put into the validation and test set to ensure the effectiveness of CUP.\n\nModel application: Finally, the trained DL model can be applied to tackle practical SE tasks. In this example, the trained model leverages two distinct encoders and a co-attention layer to learn the relationships between the code change and the old comment. The LSTM-based decoder is used to generate new comments whose tokens are copied from both the new code and the old comments.\n\n\nMETHODOLOGY\n\nWe performed a systematic literature review (SLR) following Kitchenham and Charters [52] and Petersen et al. [98]. In this section, we present details of our SLR methodology.\n\n\nResearch Questions\n\nWe want to analyse the history of using DL models in SE by summarizing and analyzing the relevant studies, and providing the guidelines on how to select and apply the DL techniques. To achieve this, we wanted to answer the following research questions:\n\n(1) RQ1: What are the trends in the primary studies on the use of DL in SE?\n\n(2) RQ2: What DL techniques have been applied to support SE tasks? \n\n\nLiterature search and selection\n\nTo collect DL related papers in SE, we identified a search string including several DL related terms frequently appeared in SE papers that make use of DL. We then refined the search string by checking the title and abstract of a small number of relevant papers. After that, we used logical ORs to combine these terms, and the search string is:\n\n(\"deep\" OR \"neural\" OR \"Intelligence\" OR \"reinforcement\") We specified the range the papers are published later: 2006-July 2020. Following previous studies [43,47,67], we selected 22 widely read SE journals (10) and conferences (12) listed in Table 1 to conduct a comprehensive literature review. We run the search string on three databases (i.e., ACM digital library 1 , IEEE Explore 2 , and Web of Science 3 ) looking for publications in the 22 publication venues whose meta data (including title, abstract and keywords) satisfies the search string. Our search returns 655 relevant papers. After discarding duplicate papers, we applied some inclusion/exclusion criteria (presented in Section 3.3) by reading their title, abstract and keywords, and narrow the candidate set to 146 studies. After reading these 146 studies in full to ensure their relevance, we retained 142 studies.\n\n\nInclusion and Exclusion Criteria\n\nAfter retrieving studies that match our search string, it is necessary to filter unqualified studies, such as studies with insufficient contents or missing information. To achieve this, we applied our inclusion and exclusion criteria to determine the quality of candidate studies for ensuring that every study we kept implemented and evaluated a full DL approaches to tackle SE tasks.\n\nThe following inclusion and exclusion criteria are used: \u2714 The paper must be written in English. \u2714 The paper must adopt DL techniques to address SE problems. \u2714 The length of paper must not be less than 6 pages. \u2718 Books, keynote records, non-published manuscripts, and grey literature are dropped. \n\n\nData Extraction and Collection\n\nAfter removing the irrelevant and duplicated papers, we extracted and recorded the essential data and performed overall analysis for answering our four RQs. Table 2 described the detailed information being extracted and collected from 142 primary studies, where the column \u2032 \u2032 lists the related data items that would be extracted from each primary study, and the column ' \u2032 denotes the related research questions to be answered by the extracted data items on the right. To avoid making mistakes in data collection, two researchers extracted these data items from primary studies together and then another researcher double checked the results to make sure of the correctness of the extracted data.\n\n\nRQ1: WHAT ARE THE TRENDS IN THE PRIMARY STUDIES ON USE OF DL IN SE?\n\nWe analyzed the basic information of primary studies to comprehend the trend of DL techniques used in SE in terms of the publication date, publication venues, and main contribution types of primary studies.\n\n\nPublication trends of DL techniques for SE\n\nWe analyzed the publication trends of DL-based primary studies published between 2006 and the middle of 2020. Although the concept of \"Deep Learning\" has been proposed in 2006 and DL techniques had been widely used in many other fields in 2009, we did not find any studies using DL to address SE tasks before 2015. Fig. 2(a) shows the number of relevant studies published in predefined publication venues since the middle of 2020. It can be observed that the number of publications from 2015 to 2019 shows a significant increase, with the number reaching 58 papers in 2019. In data collection, we only collect papers whose initial publication date is on July 2020 The practical problem that a SE task tries to solve RQ4\n\nThe SE activity in which each SE task belongs RQ4\n\nThe approach used for each SE task (e.g., regression, classification, ranking, and generation)   or earlier; thus, the number of relevant studies in 2020 cannot reveal the overall trend of DL in 2020. However, extrapolating from the number of primary studies in previous years, we can estimate that there may be over 65 relevant publications using various DL techniques to solve SE issues by the end of 2020.\n\nWe also performed an analysis of the cumulative number of publications as shown in Fig. 2(b). We fit the cumulative number of publications as a power function, showing the publication trend in the last five years. We can notice that the slope of the curve fitting the distribution increases substantially between 2015 and 2019, and the coefficient of determination ( 2 ) attains the peak value (0.99447), which indicates that the number of relevant studies using DL in SE intends to experience a strong rise in the future. Therefore, after analyzing Fig. 2, it can be foreseen that using DL techniques to address various SE tasks has become a prevalent trend since 2015, and huge numbers of studies will adopt DL to address further challenges of SE.\n\n\nDistribution of publication venues\n\nWe reviewed 142 studies published in various publication venues, including 12 conference proceedings and symposiums as well as 10 journals, which covers most research areas in SE. Table 3 lists the number of relevant papers published in each publication venue. 69% of publications appeared in conferences and symposiums, while only 31% of journal papers leveraged DL techniques for SE tasks. Among all conference papers, only 4 different conferences include over 10 studies using DL in SE in the last five years, i.e., SANER, ASE, ICSE, and MSR. Compared with other conference proceedings, SANER is the most popular one containing the highest number of primary study papers (22), followed by ASE (16). There are 13 and 6 relevant papers published in ICSE and   FSE, respectively. Meanwhile, in all journals, TSE and IST include the highest number of relevant papers (11). Ten studies related to DL techniques were published in JSS, and 5 were published in TOSEM. Almost half of the publication venues only published not more than 5 relevant papers. We also checked the distribution of primary studies published in conferences and journals between 2015 and 2020, shown in Fig. 3. Fig 3(a) illustrates that the publication trend of various conference proceedings and symposiums has a noticeable increase from 2015 to 2019. 70.4% of conference papers were published in 2018 and 2019, while only a few different conferences or symposium venues included relevant papers between 2015 and 2017, which demonstrates a booming trend in the last few years. Fig. 3(b) shows the number of primary study papers published in different journal venues. It can be seen that there is an increasing trend in the last five years, especially between 2018 and 2020. Furthermore, the relevant papers published in TSE, as one of the most popular journals, accounts for the largest proportion in 2018 and 2019; while another popular journal, IST, also makes up a large percentage in 2019 and 2020.\n\n\nTypes of main contributions\n\nWe summarized the main contribution of each primary study and then categorized these studies according to their main contributions into five categories, i.e., New technique or methodology, Tool, Empirical study, Case study, and User study. We gave the definition of each main contribution in Table 4. The main contribution of 76% primary studies was to build a novel DNN as their proposed new technique or methodology for dealing with various Table 4. The definition of five main contributions in primary studies.\n\n\nMain contribution Definition\n\nNew technique or methodology The study provided a solid solution or developed a novel framework to address specific SE issues. Tool\n\nThe study implemented and published a new tool or tool demo targeting SE issues.\n\n\nEmpirical study\n\nThe study collected primary data and performed a quantitative and qualitative analysis on the data to explore interesting findings.\n\n\nCase study\n\nThe study analyzed certain SE issues based on one or more specific cases.\n\n\nUser study\n\nThe study conducted a survey to investigate the attitudes of different people (e.g., developers, practitioners, users, etc) towards SE issues.\n\nproblems in different SE activities. 10% of relevant studies concentrated on performing assessment and empirical studies for exploring the benefits of DL towards different SE aspects, such as research on the differences between ML and DL to solve certain SE tasks, the performance of using DL to mine software repositories, applying DL in testing, etc. The main contribution of 9% was case studies. 2 primary studies (1%) that both proposed a novel methodology and evaluated the novel methodology via a user study. Therefore, the main contribution of these two studies spans across two categories, i.e., New technique or methodology and user study.\n\n\nSummary\n\n(1) DL has shown a booming trend in recent years (2) Most of primary study papers were published between 2018 and 2020 (3) The number of conference papers employing DNNs for SE significantly exceeds that of journal papers.\n\n(4) SANER is the conference venue publishing the most DL-based papers (22), while TSE and IST include the highest number of relevant papers among all journals (11). (5) Most DL-based studies were only published in a few conference proceedings (e.g., SANER, ASE, ICSE, MSR) and journals (e.g., TSE, IST, JSS, and TOSEM). (6) The main contribution of 75% primary studies is to propose a novel methodology by applying various DL techniques, while only two primary studies performed a user study to better understand users' attitudes and experience toward various DNNs used for solving specific SE tasks.  Table 5 shows the variety of different DNNs, and also lists the number of times these models have been applied in SE. As can be seen from Table 5 that compared Encoder-Decoder and AutoEncoder (AE) architectures, layered based DNNs are the most popular and widely used architecture. In the layered architecture, 72 primary studies used nine different kinds of RNN-based models to solve practical SE issues, where LSTM is the most often applied RNN-based model (35), followed by standard RNN (23). The variants of LSTM, such as GRU and Bi-LSTM, are often adopted by researchers in multiple research directions. 48 primary studies employed CNN-based models, where almost 90% of studies employed CNN. FNN-based model is the third most frequently used family with 25 studies using FNNs, followed by GNN-based models and tailored models. There are 24 combined DNNs were proposed in tailored models. 15 primary studies leveraged different types of DNNs following the Encoder-Decoder architecture, where RNNs were used in 12 studies, which is much higher than the number of other models used, i.e., CNN and FNN. In the last architecture, over 70% of studies used FNN-based AEs as their proposed novel approaches; only 2 studies selected GRU and CNN to construct AEs respectively.\n\n\nDL technique selection strategy\n\nSince heterogeneous DNNs have been used for SE tasks, selecting and employing the most suitable network is a crucial factor. We scanned the relevant sections of DL technique selection in all of the selected primary studies and classified the extracted rationale into three categories.\n\nCharacteristic-based selection strategy ( 1): The studies justified the selected techniques based on their characteristics to overcome the obstacles associated with a specific SE issue [12,23,33,145]. For instance, most of the seq2seq models were built by using RNN-based models thanks to their strong ability to analyze the sequence data.\n\nSelection based on prior studies ( 2): Some researchers determined the most suitable DNN used in their studies by referring to the relevant DL techniques in the related work [10,49,137]. For instance, due to the good performance of CNN in the field of image processing, most studies selected CNN as the first option when the dataset contains images.\n\nUsing multiple feasible DNNs ( 3): Though not providing any explicit rationale, some studies designed experiments for technique comparisons that demonstrated that the selected algorithms performed better than other methods. For example, some studies often selected a set of DNNs in the same SE tasks to compare their performance and picked up the best one [2,22,110].\n\nWe noticed that the most commonly selection strategy is 1 (i.e., Characteristic-based selection strategy), accounting for 69%, nearly 3 times that of 2 (25%). Only 6% of primary studies adopt 3 to select their suitable DL algorithms.\n\n\nSummary\n\n(1) There are 30 different DNNs used in the selected primary studies.\n\n(2) We used a classification of DL-based algorithms from two perspectives, i.e., their architectures and the families to which they belong. The architecture can be classified into three types: Layered architecture, Encoder-Decoder, and AutoEncoder (AE); the family can be classified into five categories: RNN-based, CNN-based, FNN-based, GNN-based, and Tailored models.  (22), and each of them has several variants that are also often used in many SE tasks. (5) We summarized three types of DNN-based model selection strategies. The majority of studies adopted 1 to select suitable DL algorithms. Only 6% of primary studies used 3 as the model selection strategy due to the heavy workload brought by 3.\n\n\nRQ3: WHAT KEY FACTORS CONTRIBUTE TO DIFFICULTY WHEN TRAINING DNNS IN SE?\n\nSince analyzing a DL architecture can provide a lot of insight, we investigated the construction process of a DL framework from three aspects: techniques used in data processing, model optimization, evaluation, and the accessibility of primary studies.\n\n\nHow were datasets collected, processed, and used?\n\nData is one of the most important roles in the training phase. Unsuitable datasets can result in failed approaches or tools with the low performance. We focused on the data used in primary studies and conducted a comprehensive analysis on the steps of data collection, data processing, and data application.  certain SE issues (e.g., code clone detection, software effort/cost prediction, etc). Others are used because the datasets were applied in related previous work. Due to the lack of available and suitable datasets, 18% of primary studies constructed new datasets. Real-world datasets from industry are only used by 4% of studies. 33% of studies performed a series of experiments on large-scale datasets so as to verify the scalability and robustness of their models. To achieve this, many studies collected multiple small datasets from different sources. Fig. 4(b) describes the sources of collected datasets. As tens of thousands of developers contribute to GitHub community by uploading source code of their software artifacts, GitHub has become the most frequently used source of collected data (51%). 26% of studies collected their datasets from different systems and projects. For instance, Deshmukh et al. [21] collected bug reports from several bug tracking systems, i.e., issue tracking systems of Open Office, Eclipse, and Net Beans projects, as datasets to build a DL-based model for duplicated bug detection. The app store is the third-largest source (11%), followed by Stack Overflow (SO) and Youtube.\n\n6.1.2 What are the types of SE datasets used in prior DL studies? The datasets used in primary studies are of various data types. It is essential to analyze data types of datasets since the relationship between the type of implicit feature being extracted and the architecture has a dominating influence on model selection. We summarize the data types in primary studies and interpreted how data types determine the choice of DNNs.\n\nWe classified the data types of used datasets into four categories -code-based, text-based, software repositorybased, and user-based data types. Table 6 describes specific data in each data type. 104 primary studies collected data from source code, and most of these studies used source code directly in some important SE activities, such as software testing and maintenance. Datasets containing various metrics were employed in 8 relevant studies, followed by code comments, defects (7), and test cases (6). Whereas few studies focused on analyzing the code annotation, pull-request, and patches. 8 primary studies used a multitude of screencasts as their datasets, where 4 studies selected program screencasts to analyze developers' behavior and 4 studies researched UI images for improving the quality of APPs.\n\nText-based data types were the second most popular, including 13 different kinds of documentation. Bug report and requirements documentation are the two most commonly applied text-based data types in primary studies. Some types rarely appeared, such as logs, certifications, design documentation, etc.\n\nSince software repositories, especially SO and GitHub, contain a lot of useful patterns or information, we classified the type of the information collected from these repositories into \u2032 \u2212 \u2032 . 12% of studies concentrated on obtaining and learning useful information and patterns by crawling related contents from SO (e.g., Q&A (questions and answers) and tags) and GitHub (e.g., issues, commits and, pull-requests). User-based data generally contains a great deal of user information, which can promote developers to better comprehend user needs and behavior targeting different applications. Only 5 studies adopted user-based data types (i.e., user behavior, review, and interactions) to solve relevant SE tasks.\n\n\nWhat input forms were datasets transformed into when training DNNs?\n\nThe inputs of DNNs need to be various forms of vectors. We found two techniques were often used to transform different source data types into vectors: One-hot encoding and Word2vec. Only 5 studies produced the input of their models by adopting the One-hot technique. We described input forms using 5 categories referring to their data types.\n\nToken-based input: Since some studies treated source code as text, they used a simple program analysis technique to generate code tokens into sequences and transformed tokens into vectors as the input of their DL-based models. A token-based input form can be applied to source code and text-based data when processing related datasets.\n\nTree/graph-based input: To better comprehend the structure of source code, several studies convert source code into Abstract Syntax Trees (AST) or Control Flow Graphs (CFGs), and then generate vector sequences by traversing the nodes in each tree or graph. Table 7. The various input forms of DL-based models proposed in primary studies.\n\n\nFamily Input forms #Studies Total\n\nToken-based input Code in tokens 17 Text in tokens 34 Code and text in tokens 13 64 Tree/graph-based input Code in tree structure 25 Code in graph structure 4 29 Feature-based input feature/metric 33 33 Pixel-based input pixel 9 9\n\nHybrid input Code in tree structure + text in token 4 Code features + text in token 2 Code in tree structure + features 1 7\n\nFeature/metric-based input: For analyzing the characteristics of software artifacts, some studies applied datasets consisting of features or metrics extracted from different products, and thus the input form of the models proposed in these studies is software feature/metric-based vectors.\n\nPixel-based input: Some studies used datasets containing a large number of images and screencasts, e.g., program screencasts, UI images, etc. When preprocessing these datasets, they often broke down screencasts into pixels as an effective input form, for analyzing graph-based datasets in different SE tasks, such as bug detection, code extraction, etc.\n\nCombined input: Many studies combined two or more data types extracted from software products to build comprehensive datasets with more information for enhancing the quality and accuracy of proposed models. For instance, Leclair et al. [60] proposed a novel approach for generating summaries of programs not only by analyzing their source code but also their code comments. Table 7 depicts the input formats of DL-based models. We can see that over 45% of studies transformed data (i.e., source code and various documentations) into the token-based input form (64), where 17 studies considered source code as texts and thus converted code into token sequences as the input of models. 13 studies used both source code and text-based materials and also constructed a token-based data structure as the input form of their proposed models. 25 studies utilize tree-based input form to analyze the source code, and only 4 studies transform source code into a graph-based structure for extracting essential information. 33 studies adopted embedding techniques to generate feature-based vectors. Furthermore, 8 studies using image-based datasets split screencasts into pixels as the basic unit of the input form. Only 7 studies processed datasets into multiple forms.\n\n\nWhat techniques were used to optimize and evaluate DL-based models in SE?\n\nIn the training phase, developers attempt to optimize the models in different ways for achieving good performance. In this section, we summarized the information describing the optimization methods and evaluation process, and performed an analysis on key techniques. 6.2.1 What learning algorithms are used in order to optimize the models? The performance of DL-based models is dependent on selected optimization methods, which can systematically adjust the parameters of the DNN as training progresses.\n\nOut of the 142 studies analyzed, 131 identified the specific optimization method, but 11 studies did not mention what optimizers were used to adjust parameters in their work. Fig. 5 illustrated the frequency of the use of 20 optimization methods used in all primary studies. We see that 6 optimizers were used in no less than 5 studies, where Adam optimizer is the most commonly used optimization method. Stochastic gradient descent (SGD) and gradient descent (GD) are also popular optimizers, which were used by 21 and 15 studies respectively, followed 32   by back-propagation (14) and fine-tuning (11). Besides, some optimization methods are not often used, such as Adagrad and Adadelta.\n\n6.2.2 What methods were used to alleviate the impact of Overfitting? One major problem associated with applying any type of learning algorithm is overfitting. Overfitting is the phenomenon of a DNN learning to fit the noise in the training data extremely well, yet not being able to generalize to unseen data, which is not a good approximation of the true target function that the algorithm is looking forward to learn. We describe 9 general ways to combat overfitting [38,107] by considering 3 aspects: data processing, model construction as well as model training, and then analyzed the usage distribution of these methods in relevant studies. Cross-validation: A cross-validation algorithm can split a dataset into k groups (k-fold cross-validation). Researchers often leave one group to be the validation set and the others as the training set. This process will be repeated until each group has been used as the validation set. Since a remaining subset of data is new towards the training process of DL-based models, the algorithm can only rely on the learned knowledge from other groups of data to predict the results of the remaining subset, preventing overfitting.\n\nFeature selection: Overfitting can be prevented by selecting several of the most essential features for training DL-based models can effectively avoid overfitting. Therefore, researchers can pick up some key features by using feature selection methods, train individual models for these features, and evaluate the generalization capabilities of models. For instance, Pooling is a typical technique to prevent overfitting since pooling can reserve main features while reducing the number of parameters and the amount of computation, and improve the generalization ability of the model.\n\nRegularization: Regularization is a technique to constrain the network from learning a model that is too complex, which therefore can avoid overfitting. A penalty term would be added in the cost function to push the estimated coefficients towards zero by applying L1 or L2 regularization.\n\nDropout: By applying dropout, a form of regularization, to the layers of DNNs, a part of neurons were ignored with a set probability. Therefore, dropout can reduce interdependent learning among units to avoid overfitting.\n\nData augmentation: A larger dataset can reduce the chance of overfitting. Data augmentation is a good way to artificially increase the size of our dataset for improving the performance of a DNN when the scale of data was constrained due to difficult to gather more data. For example, many studies performed various image transformations to the image dataset (e.g., flipping, rotating, rescaling, shifting) for enlarging data size in the image classification task.\n\nEarly stopping: Early stopping is an effective method for avoiding overfitting by truncating the number of iterations, that is, stopping iterations before DL-based models converge on the training dataset to eliminate the impact on overfitting.\n\nData balancing: With imbalanced data, DL-based models are likely to occur the overfitting problem since models will learn imbalanced knowledge with a disproportionate ratio of observations in each class. Using some data balancing techniques can effectively alleviate the impact on models' performance caused by overfitting.\n\nEnsembling: Ensembles are a set of machine learning methods for combining predictions from multiple separate models. For instance, Bagging as an ensemble learner can reduce the chance of overfitting complex models by training a large number of \"strong\" learners in parallel without restriction. Fig. 6 illustrates the distribution of the techniques used for combating overfitting problems. Cross-validation has been used frequently among the selected studies to prevent overfitting; it is used in 40 studies, followed by pooling (25). Regularization and dropout are the third most popular techniques used in 20 studies. There are 8 studies that prevent overfitting by enlarging the scale of data, such as using a large-scale dataset, combining multiple datasets, and using different data augmentation techniques. 6 studies used early stopping and 5 selected data balancing to combat the overfitting problem. Ensembling is the least frequently used one (1) compared with other techniques (1). Furthermore, among all primary studies, 4 studies used several new algorithms proposed by some studies to solve overfitting. We analyzed which factors may have an impact on the overfitting technique selection. We noticed that the techniques used for combating overfitting have no strong association with either data types or input forms. However, there is a special relationship between model selection and these techniques. Most of the studies that adopted CNNs to address specific SE tasks selected pooling as their first choice for preventing the overfitting problem.\n\n6.2.3 What measures are used to evaluate DL-based models? Accessing appropriate benchmarks is a crucial part of evaluating any DL-based models in SE. We also explored the frequent metrics used to measure the performance of DL-based models applied to respective SE tasks. Table 8 summarizes the commonly used evaluation metrics in the primary studies, used in no less than 3 studies. Precision, recall, F1-measure, and accuracy are widely accepted metrics for evaluating the performance of DL-based models. Some studies adopted MRR and BLEU as evaluation metrics in their work, potentially indicating that many studies focused on addressing ranking and translation tasks by training various DNNs. Another interesting observation from Table 8 is that running time is selected as a performance indicator by a set of studies, which does not occur frequently when using non-learning techniques. This is because that learning algorithms, especially DNNs, require more time during their construction, training, and testing phases due to the high complexity of these networks (e.g., numerous types of layers, a great many neurons, and different optimization methods). Also, almost half of metrics are not commonly used in relevant studies, which are only used in 3 or 4 studies (e.g., P-value, ROC, ROUGE, Coverage, Balance, etc.) and thus these metrics can reflect their respective characteristics of different SE tasks.\n\n\nAccessibility of DL-based models used in primary studies.\n\nWe checked whether the source code of DL-based models is accessible for supporting replicability and reproducibility. 53 studies provided the replication packages of their DL-based models, only accounting for 37.3% of all primary studies. 89 studies proposed novel DL-based models without publicly available source code, making it difficult for other researchers to reproduce their results; some of these studies only disclosed their datasets. Based on this observation, obtaining open-source code of DNNs is still one of the challenges in SE because many factors may result in never realizing the replicability and reproducibility of DL application, e.g., data accessibility, source code accessibility, different data preprocessing techniques, optimization methods, and model selection methods. Therefore, we recommend future DL studies to release replication packages.\n\n\nSummary\n\n(1) Most datasets are available online and 33% of datasets consist of multiple small-scale ones collected from GitHub, software systems and projects, and some software repositories. (2) 5 different data types are used in the primary studies, i.e., code-based, text-based, software repository-based, graph-based, and user-based data types, where code-based and text-based types are the two main data types being used in 82.3% of primary studies.  (3) Most studies parse source code into token, tree, or graph structures, or extract features from programs. When the raw datasets are documentation, studies would convert them into token-based vectors as the input form of their models. (4) We observed that Adam is the most popular optimization algorithm being used in 32 studies, followed by SGD and GD, and several variants of Adam are still commonly used in SE. There are also some well-known optimization algorithms used in primary studies, such as back propagation, fin-tuning, and hyperparameter optimizer. (5) 9 different ways are used for combating the overfitting problem. 4 techniques were widely used -cross-validation, feature selection, regularization, and dropout. We found that studies applying CNNs would choose the pooling method to prevent overfitting with high probability, and data type and input form does not influence technique selection. (6) There are over 20 different metrics used to verify the performance of DL-based models. Precision, recall, F1-measure, and accuracy were used commonly in primary studies. (7) Only 53 studies provided a public link of their models in their papers and yet 62.7% of proposed models are difficult to be reproduced since the source code is unavailable.\n\n\nRQ4: WHAT TYPES OF SE TASKS AND WHICH SE PHASES HAVE BEEN FACILITATED BY DL-BASED APPROACHES?\n\nIn this section, we first categorise a variety of SE tasks into six SE activities referring to Software Engineering Body of Knowledge [8], i.e., software requirements, software design, software implementation, software testing and debugging, software maintenance, and software management. We then analyze the distribution of DL-based studies for different SE activities. We present a short description of each primary study, including the specific SE issue each study focused on, which and how DL techniques are used, and the performance of each DL model used.\n\n\nDistribution of DL techniques in different SE activities\n\nWe analysed which SE activities and specific SE tasks each selected primary study tried to solve. As shown in Fig. 7, the largest number of primary studies focused on addressing SE issues in software maintenance (39%). 36% of studies researched software testing and debugging. Software management was the topic of 11% of primary studies, followed by software implementation (9%). Software design and modeling (3%) and software requirements (2%) are addressed in very few studies. We classified all primary studies into four categories based on the types of their SE tasks, i.e., the regression task, classification task, ranking task, and generation task. Fig. 8 describes the distribution of different task types where DL techniques were applied. Classification and generation tasks account for almost 80% of primary studies, where classification is the most frequent task (54%). 13% of studies belong to the regression task and the output of their proposed models is a prediction value, such as effort cost prediction. In SE, some studies adopted DL to concentrate on a ranking task, accounting for 11% of all studies.\n\nWe summarized a set of research topics in which DL was engaged. Table 9 lists the research topics containing no less than three related studies. Software testing and debugging, as the most prevalent SE activity, has 37 primary studies in six topics. The most popular study is defect prediction (11 studies), followed by bug localization (7) and application testing (7). Software maintenance, as the second most popular activities, involves five research topics with 28 relevant studies, where code clone detection is the most popular research topic. Two SE activities, software implementation and software management, both contain two important research topics, where 19 primary studies mined software repositories by training DNNs, 6 studies estimated development cost, and 5 studies applied DL for code search. Software design and modeling only involve one popular topic, i.e., source code representation/modeling. There are no topics with more than three studies using DL techniques in software requirements.\n\n\nSoftware requirements\n\n7.2.1 Requirements analysis. A number of natural language-based documents that describe users' specific needs or services of a software product can be referred to as user requirements (aka, use cases, or actions) [127]. Extracting use cases of a product from a large volume of textual requirement documentation is a common but laborintensive task. Since the manual mapping system states between requirements and simulation is a time-consuming task, Pudlitz et al. [100] proposed a self-trained Named-entity Recognition model combined with Bi-LSTM and CNN to extract the system states from requirements specification, working to reduce labor cost when linking the state extracted from requirements to the simulation signal.\n\n\nrequirement validation.\n\nThe requirements specification may be subject to validation and verification procedures, ensuring that developers have understood the requirements and the requirements conform to company standards. Winkler et al. [128] present an automatic approach to identify and determine the method for requirement validation. They predefined six possible verification methods and trained a CNN model as a multiclass and multilabel classifier to classify requirements with respect to their potential verification methods. The mixed results revealed that the imperfect training data impacted the performance of their classifier, but it still achieved good results on the testing data.\n\n\nSoftware design\n\n7.3.1 Software design patterns detection. UI design is an essential component of software development, yet previous studies cannot reliably identify relevant high-fidelity UI designs from large-scale datasets. Mart\u00edn et al. [78] proposed a DL-based search engine to detect UI designs in various software products. The core idea of this search engine is to build a CNN-based wireframe image autoencoder to automatically generate labels on a large-scale dataset of Android UI designs. After manual evaluation of experimental results, they confirmed that their search engine achieved superior performance compared with image-similarity-based and component-matching-based methods. Thaller et al. [108] proposed a flexible human-and machine-comprehensible software representation algorithm, namely Feature Maps. They first extracted subtrees from the system's abstract semantic graph (ASG). Then their algorithm pressed the high-dimensional and inhomogeneous vector space of these micro-structures into a feature map. Finally, they adopted a classical machine learning model and a DL model (i.e., Random Forest and CNN) to identify instances of design patterns in source code. Their evaluation suggested that Feature Map is an effective software representation method, revealing important information hidden in the source code.\n\n\nGUI modeling.\n\nChen et al. [12] proposed a neural machine translator to learn a crowd-scale knowledge of user interfaces (UI). Their generative tool encoded the spatial layouts of visual features learned from a UI image and learned to generate its graphical user interface (GUI) skeleton by combining RNN and CNN models. Its performance had been verified on the large-scale UI data from real-world applications. Moran et al. [88] proposed a strategy to facilitate developers automate the process of prototyping of GUIs in 3 steps: detection, classification, and assembly. First, they used computer vision techniques to detect logical components of a GUI from mock-up metadata. They then trained CNNs to category GUI-components into domain-specific types. Finally, a KNN algorithm was applied to generate a suitable hierarchical GUI structure to assemble prototype applications. Their evaluation achieved an average GUI-component classification accuracy of 91%.\n\n\nSoftware implementation\n\n7.4.1 Code search. Gu et al. [33] proposed DeepAPI, a DL-based approach to generate functional API usage sequences for a given natural language-based user query by using an attention-based GRU Encoder-Decoder. DeepAPI first encoded the user query into a fixed-length context vector and produced the API sequence according to the context vector. It also enhanced their model by considering the importance of individual APIs. To evaluate its effectiveness, they empirically evaluated their approach on 7 million code snippets. Gu et al. [32] proposed a code search tool, DeepCS by using a novel DNN model. They considered code snippets as well as natural language descriptions, and then embedded them into a high-dimensional unified vector representation. Thus, DeepCS gave the relevant code snippets by retrieving the vector of the corresponding natural language query. They evaluated DeepCS with a large-scale dataset collected from GitHub.\n\nRecently, several proposals use DL techniques for code search by embedding source code and given queries into vector space and calculating their semantic correlation [3]. Cambronero et al. [10] noticed that multiple approaches existed for searching related code snippets applied unsupervised techniques, while some adopted supervised ones to embed source code and queries for code search. They defined 3 RQs to investigate whether using supervised techniques is an effective way for code search and what types of DNNs and training corpus to use for this supervision. To understand these tradeoffs quantitatively, They selected and implemented four state-of-the-art code search techniques. They found that UNIF outperformed CODEnn and SCS models based on their benchmarks and suggested evaluating simple components first before integrating a complicated one. Wan et al. [115] addressed the lack of analysis of structured features and inability to interpret search results in existing code search works. To address these issues, they presented a new approach MMAN, which adopted three different DNNs (i.e., LSTM, Tree-LSTM, and GGNN (Gated Graph Neural Network)) to analyze both shallow features and the semantic features in ASTs, and control-flow graphs (CFGs) of source code. The final results on a large-scale real-world dataset demonstrated that MMAN accurately provided code snippets. Huang et al. [45] proposed an attention-based code-description representation learning model (CDRL) to refine the general DL-based code search approaches. They only picked up description terms and semantically related code tokens to embed a given query and its code snippet into a shared vector space.\n\n\nProgramming.\n\nGao et al. [26] introduced an attention-based Encoder-Decoder framework to directly generate sensible method names by considering the relationship between the functional descriptions and method names. To evaluate their model, experiments were performed on large-scale datasets for handling the cold-start problem, and the model achieved significant improvement over baselines. Alahmadi et al. [2] applied a CNN model to automatically identify the exact location of code in images for reducing the noise. They extracted 450 screencasts covering C#, Java, and Python programming languages to evaluate their model, and the final result showed that the accuracy of their model achieved 94%. Wang et al. [121] proposed a Neural Network-based translation model to address the domain-specific rare word problem when carrying out software localization. They trained an RNN encoder-decoder framework and enhanced it by adding linguistic information. Nguyen et al. [92] proposed a DL-based language model, Dnn4C, which augmented the local context of lexical code elements with both syntactic and type contexts by using an FNN model. Empirical evaluation on code completion showed that Dnn4C improved accuracy by 24.9% on average over four baseline approaches. 7.5 Software testing and debugging 7.5.1 Defect prediction. Defect prediction is the most extensive and active research topic in use of DL techniques in software maintenance. Almost 30% of primary studies focused on identifying defects [4,18,74,111,123,133,147].\n\nMetrics-based defect prediction. Metrics or features extracted from a software product can give a vivid description of its running state, and thus it is easy for researchers and participants to use these software metrics for defect prediction. Tong et al. [111] proposed a novel two-stage approach, SDAEsT, which is build based on stacked denoising autoencoders (SDAEs) and a two-stage ensemble (TSE) learning strategy. Specifically, in the first stage, they used SDAEs to extract more robust and representative features. To mitigate the impact on the class imbalance problem and eliminate the overfitting problem, they propose TSE learning strategy as the second phase. They evaluated their work using 12 open-source defect datasets. Xu et al. [133] built an FNN model with a new hybrid loss function to learn the intrinsic structure and more discriminative features hidden behind the programs. Previous studies obtained process metrics throughout analyzing change histories manually and often ignored the sequence information of changes during software evaluation. For better utilization of such sequence data, Wen et al. [123] built an RNN model to encode features from change sequences. They considered defect prediction as to the sequence labeling problem and performed fine-grained change analysis to extract six categories of change sequences, covering different aspects of software changes. Their evaluation on 10 public datasets showed that their approach achieved high performance in terms of F1-measure and AUC. To address the same problem, Liu et al. [74] proposed to obtain the Historical Version Sequence of Metrics (HVSM) from various software versions as defect predictors and leveraged RNN to detect defects. Barbez et al. [4] analyzed and mined the version control system to achieve historical values of structural code metrics. They then trained a CNN based classifier, CAME, to infer the anti-patterns in the software products.\n\nSemantic-based defect prediction. Wang et al. [117,118] leveraged Deep Belief Network (DBN) to automatically learn semantic features from token vectors extracted from programs' ASTs, compared to most previous works that use manual feature specification. They evaluated their approach on file-level defect prediction tasks (withinproject and cross-project) and change-level defect prediction tasks (within-project and cross-project) respectively. The evaluation results confirmed that DBN-based semantic features significantly outperformed the previous defect prediction based on traditional features in terms of F1-measure. Similarly, Dam et al. [18] used a tree-based LSTM network, which can directly match with the AST of programs for capturing multiple levels of the semantics of source code.\n\nJust-In-Time (JIT) defect prediction. Hoang et al. [41] presented an end-to-end DL-based framework, DeepJIT, for change-level defect prediction, or Just-In-Time (JIT) defect prediction. DeepJIT automatically extracted features from code changes and commit messages, and trained a CNN model to analyze them for defect prediction. The evaluation experiments on two popular projects showed that DeepJIT achieved improvements over 10% for two open-source datasets in terms of AUC.\n\n\nBug detection.\n\nWan et al. [114] implemented a Supervised Representation Learning Approach (SRLA) based on an autoencoder with double encoding-layers to conduct cross-project Aging-Related Bugs (ARBs) prediction. They compared SRLA with the state-of-the-art approach, TLAP, to prove the effectiveness of SRLA. Wang et al. [122] present a novel framework, Textout, for detecting text-layout bugs in mobile apps. They formulated layout bug prediction as a classification issue and addressed this problem with image processing and deep learning techniques. Thus, they designed a specifically-tailored text detection method and trained a CNN classifier to identify text-layout bugs automatically. Textout achieved an AUC of 95.6% on the dataset with 33,102 text-region images from real-world apps. Source code is composed of different terms and identifiers written in natural language with rich semantic information. Based on this intuition, Li et al. [63] trained a DL-based model to detect suspicious return statements. They used a CNN to determine whether a given return statement in source code matched its method signature. To reduce the impact of the lack of negative training data, they converted the correct return statements in real-world projects to incorrect ones. Li et al. [66] proposed an AIOps solution for identifying node failures for an ultra-large-scale cloud computing platform at Alibaba.\n\n\nVulnerability detection.\n\nDam et al. [19] described a novel approach for vulnerability detection, which automatically captured both syntactic and semantic features of source code. The experiments on 18 Android applications and Firefox applications indicated that the effectiveness of their approach for within-project prediction and cross-project prediction. Tian et al. [110] proposed to learn the fine-grained representation of binary programs and trained a Gated Recurrent Unit (BGRU) network model for intelligent vulnerability detection. Han et al. [37] trained a shallow CNN model to capture discriminative features of vulnerability description and exploit these features for predicting the multi-class severity level of software vulnerabilities. They collected large-scale data from the Common Vulnerabilities and Exposures (CVE) database to test their approach.\n\n\nBug localization.\n\nTo locate buggy files, Lam et al. [57] built an autoencoder in combination with Information Retrieval (IR) technique, rVSM, which learned the relationship between the terms used in bug reports and code tokens in software projects. Some studies proposed to exploit CNN in the bug localization task [48,129,139]. Zhang et al. [139] proposed CNNFL, which localized suspicious statements in source code responsible for failures based on CNN. They trained this model with test cases and tested it by evaluating the suspiciousness of statements. Huo et al. [48] present a deep transform learning algorithm, TRANP-CNN, for cross-project bug localization by training a CNN model to extract transferable semantic features from source code. Xiao et al. [129] used the wordembedding technique to retain the semantic information of the bug report and source code and enhanced CNN to consider bug-fixing frequency and recency in company with feature detection techniques for bug localization. Li et al. [65] proposed a novel approach, DeepFL, to learn latent features for precise fault localization, adopting an RNN model. The evaluation on the benchmark dataset, Defects4J, described that DeepFL significantly outperformed state-of-the-art approaches, i.e., TraPT/FLUCCS. Standard code parsers are of little help, typically resolving syntax errors and their precise location poorly. Santos et al. [105] proposed a new methodology for locating syntax errors and provided some suggestions for possible changes for fixing these errors. Their methodology was of practical use to all developers but especially useful to novices frustrated with incomprehensible syntax errors. 7.5.5 Test case generation. Liu et al. [73] proposed a novel approach to automatically generate the most relevant text of test cases based on the context of use cases for mobile testing. Koo et al. [54] implemented a novel approach, PySE1, to generate the test case. PySE1 tackled the limitations of symbolic execution schemes by proposing a DL-based reinforcement learning algorithm to improve the branch policy for exploring the worse case program execution. Zhao et al. [142] trained a DL-based model that combines LSTM and FNN to learn the structures of protocol frames and deal with the temporal features of stateful protocols for carrying out security checks on industrial network and generating fake but plausible messages as test cases. Liu et al. [72] proposed a deep natural language processing tool, DeepSQLi, to produce test cases used to detect SQLi vulnerabilities. They trained an encoder-decoder based seq2seq model to capture the semantic knowledge of SQLi attacks and used it to transform user inputs into new test cases. 7.5.6 Program analysis. Program analysis refers to any examination of source code or program executions that attempt to find patterns or anomalies thought to reveal specific behaviors of the software.\n\nStatic analysis. In Android mobile operating systems, applications communicate with each other a messagepassing system, namely, Inter-Component Communication (ICC). Many serious security vulnerabilities may occur owing to misuse and abuse of communication links, i.e., ICCs. Zhao et al. [143] presented a new approach to determine communication links between Android applications. They augmented static analysis with DL techniques by encoding data types of the links and calculating the probability of the link existence. To reduce the number of false alarms, Lee et al. [62] trained a CNN model as an automated classifier to learn the lexical patterns in the parts of source code for detecting and classifying false alarms. Due to the impact of high false-positive rates on static analysis tools, Koc et al. [53] performed a comparative empirical study of 4 learning techniques (i.e., handengineered features, a bag of words, RNNs, and GNNs) for classifying false positives, using multiple ground-truth program sets. Their results suggest that RNNs outperform the other studied techniques with high accuracy.\n\nType inference. Helledoorn et al. [39] developed an automated framework, DeepTyper, a DL-based model to analyze JavaScript language and learn types that naturally occurred in certain contexts. It then provided a type of suggestion when the type checker cannot infer the types of code elements, such as variables and functions. Malik et al. [82] formulated the problem of inferring Javascript function types as a classification task. Thus, they trained a LSTM-based neural model to learn patterns and features from code annotated programs collected from real-world projects, and then predicted the function types of unannotated code by leveraging the learned knowledge. 7.5.7 Testing techniques. Many studies focus on new methods to perform testing, such as for apps [96], games [144], and other software systems [5,11]. There are also some studies using well-known testing techniques (e.g., fuzzing [17,30] and mutation testing [83]) for improving the quality of software artifacts. Zheng et al. [144] conducted a comprehensive analysis of 1,349 real bugs and proposed Wuji, a game testing framework, which used an FNN model to perform automatic game testing. Ben et al. [5] also used the FNN to test Advanced Driver Assistance Systems (ADAS). They leveraged a multi-objective search to guide testing towards the most critical behaviors of ADAS. Pan et al. [96] present Q-testing, a reinforcement learning-based approach, benefiting from both random and model-based approaches to automated testing of Android applications. Mao et al. [83] performed an extensive study on the effectiveness and efficiency of the promising PMT technique. They also complemented the original PMT work by considering more features and the powerful deep learning models to speed up this process of generating the huge number of mutants. Godefroid et al. [30] used DL-based statistical machine-learning techniques to automatically generate input syntax suitable for input fuzzing. Cummins et al. [17] introduced DeepSmith, a novel LSTM-based approach, for reducing the development task when using Fuzzers to discover bugs in compilers. They accelerated compiler validation through the inference of generative models for compiler inputs, and then applied DeepSmith to automatically generate tens of thousands of realistic programs. Finally, they constructed differential testing methodologies on these generated programs for exposing bugs in compilers.\n\n\nReverse execution.\n\nA decompiler is a tool to reverse the compilation process for examining binaries. Lacomis et al. [56] introduced a novel probabilistic technique, namely Decompiled Identifier Renaming Engine (DIRE), which utilized both lexical and structural information recovered by the decompiler for variable name recovery. They also present a technique for generating corpora suitable for training and evaluating models of decompiled code renaming. Although reverse execution is an effective method to diagnose the root cause of software crashes, some inherent challenges may influence its performance. To address this issue, Mu et al. [89] present a novel DNN, which significantly increased the burden of doing hypothesis testing to track down non-alias relation in binary code and improved memory alias resolution. To achieve this, they first employed an RNN to learn the binary code pattern pertaining to memory access and then inferred the memory region accessed by memory references. Katz et al. [51] noticed that the source code generated by decompilation techniques are difficult for developers to read and understand. To narrow the differences between human-written code and decompiled code, they trained a non-language-specific RNN model to learn properties and patterns in source code for decompiling binary code.\n\n\nSoftware maintenance\n\nThere are a lot of studies contributing to increasing maintenance efficiency, such as improving source code, logging information, software energy consumption, etc. [36,42,75,80,103]. 7.6.1 Code clone detection. Code clone detection is a very popular SE task in software maintenance using DL, with around 20% of primary studies concentrating on this research topic.\n\nRNN-based code clone detection. Most studies use RNNs including RtNN [27], RvNN [125], and LSTM [9,97,112] to identify clones in source code. White et al. [125] proposed a novel code clone detector by combining two different RNNs, i.e., RtNN and RvNN, for automatically linking patterns mined at the lexical level with patterns mined at the syntactic level. They evaluated their DL-based approach based on file-and function-level. Gao et al. [27] first transformed source code into AST by parsing programs and then adopted a skip-gram language model to generate vector representation of ASTs. After that, they used the standard RNN model to find code clones from java projects. Buch et al. [9] introduced a tree-based code clone detection approach, and traversed ASTs to form data sequences as the input of LSTM. Perez et al. [97] also used LSTM to learn from ASTs, and then calculated the similarities between ASTs written in Java and Python for identifying cross-language clones. Since source code can be represented at different levels of abstraction: identifiers, Abstract Syntax Trees, Control Flow Graphs, and Bytecode, Tufano et al. [112] conducted a series of experiments to demonstrate how DL can automatically learn code similarities from different representations.\n\nFNN-based code clone detection. Some studies adopted FNNs for the code clone detection task [64,90,141]. Li et al. [64] implemented a DL-based classifier, CClearner, for detecting function-level code clones by training an FNN. Compared with the approaches not using DL, CClearner achieved competitive clone detection effectiveness with a low time cost. Zhao et al. [141] introduced a novel clone detection approach, which encoded data flow and control flow and into a semantic matrix and designed an FNN structure to measure the functional similarity between semantic representation of each code segment. Nafi et al. [90] proposed a cross-language clone detector without extensive processing of the source code and without the need to generate an intermediate representation. They trained an FNN model, which can learn different syntactic features of source code across programming languages and identified clones by comparing the similarity of features.\n\nOthers. For detecting Type-4 code clones, Yu et al. [135] present a new approach that uses tree-based convolution to detect semantic clones, by capturing both the structural information of a code fragment from its AST and lexical information from code tokens. They also addressed the limitation of an unlimited vocabulary of tokens and models. Wang et al. [120] developed a novel graph-based program representation method, flow-augmented abstract syntax tree (FA-AST), to better capture and leverage control and data flow information. FA-AST augmented original ASTs with explicit control and data flow edges and then adopted two different GNN models (i.e., gated graph neural network (GGNN) and graph matching network (GMN)) to measure the similarity of various code pairs. To effectively capture syntax and semantic information from programs to detect semantic clones, Fang et al. [25] adopted fusion embedding techniques to learn hidden syntactic and semantic features by building a novel joint code representation. They also proposed a new granularity for functional code clone detection called caller-callee method relationships. Finally, they trained a supervised deep learning model to find semantic clones. 7.6.2 Code comment generation. Hu et al. [44] present a new approach that can automatically generate code comments for Java code to help developers better understand the functionality of code segments. They trained a LSTM-based framework to learn the program structure for better comments generation. The context information of the source code was not used and analyzed in previous automated comment summarization techniques. Ciurumelea et al. [16] proposed a semi-automated system to generate code comments by using LSTM. Zhou et al. [148] combined program analysis and natural language processing to build a Dl-based seq2seq model to generate Java code comments. To generate code summarization, Leclair et al. [60] proposed a DL-based model combining texts from code with code structure from an AST. They processed data source as a separate input to reduce the entire dependence on internal documentation of code. Wan et al. [116] noticed that most of the previous work used the Encoder-Decoder architecture to generate code summaries, which omitted the tree structure of source code and introduced some bias when decoding code sequences. To solve these problems, they trained a deep reinforcement learning framework that incorporated an abstract syntax tree structure as well as sequential content of code snippets. They trained this DNN by adopting an advantage reward composed of BLEU metric. 7.6.3 Program repair. Bhatia et al. [6] proposed a novel neuro-symbolic approach combining DL techniques with constraint-based reasoning for automatically correcting programs with errors. Specifically, they trained an RNN model to perform syntax repairs for the buggy programs and ensured functional correctness by using constraintbased techniques. Through evaluation, their approach was able to repair syntax errors in 60% of submissions and identified functionally correct repairs for 24% submissions. Tufano et al. [113] proposed to leverage the proliferation of software development histories to fix common programming bugs. They used the Encoder-Decoder framework to translate buggy code into its fixed version after generating the abstract representation of buggy programs and their fixed code. White et al. [124] trained an autoencoder framework to reason about the repair ingredients (i.e., the code reused to craft a patch). They prioritized and transformed suspicious statements and elements in the code repository for patch generation by calculating code similarities. Lutellier et al. [79] present a new automated generate-and-validate program repair approach, CoCoNuT, which trained multiple models to extract hierarchical features and model source code at different granularity levels (e.g., statement and function level) and then constructed a CNN model to fix different program bugs. Liu et al. [71] proposed an automated approach for detecting and refactoring inconsistent method names by using Paragraph Vector and a CNN. Ni et al. [93] exploited the bug fixes of historical bugs to classify bugs into their cause categories based on the intuition that historical information may reflect the bug causes. They first defined the code-related bug classification criterion from the perspective of the cause of bugs and generated ASTs from diff source code to construct fixed trees. Then, they trained Tree-based Convolutional Neural Network (TBCNN) to represent each fixed tree and classified bugs into their cause categories according to the relationship between bug fixes and bug causes. 7.6.4 Source code representation. White et al. [126] conducted an empirical study to adopt DL in software language modeling and highlight the fundamental differences between state-of-the-practice software language models and DL models. Their intuition is that the representation power of the abstractions is the key element of improving the quality of software language models. Therefore, the goal of this study was to improve the quality of the underlying abstractions by using Neural Network Language Models (i.e., Feed-forward neural networks (FNN), RNN) for numerous SE issues. They pinpointed that DL had a strong capability to model semantics and consider rich contexts, allowing it performed better at source code modeling. They evaluated these DL-based language models at a real SE task (i.e., code suggestion). Their evaluation results suggested that their model significantly outperformed the traditional language models on 16,221 Java projects.\n\nHussain et al. [49] introduced a gated recurrent unit-based model, namely CodeGRU, to model source code by capturing its contextual, syntactical, and structural dependencies. The key innovation of their approach was to performing simple program analysis for capturing the source code context and further employed GRU to learn variable size context while modeling source code. They evaluated CodeGRU on several open-source java projects, and the experimental results verified that the approach alleviated the out of vocabulary issue. Using abstract syntax tree (AST)-based DNNs may induce a long-term dependency problem due to the large size of ASTs. To address this problem, Zhang et al. [137] present an advanced AST-based Neural Network (ASTNN) for source code representation. The advanced ASTNN cut each entire AST into a set of small statement trees, and transform these subtrees into vectors by capturing the lexical and syntactical knowledge of statement trees. They applied a bidirectional RNN model to produce the vector representation of a code snippet. They used ASTNN to detect code clones and classify source code for evaluating its performance. Gill et al. [29] introduced a lightweight framework, ThermoSim, to simulate the thermal behavior of computing nodes in the Cloud Data Center (CDC) and measure the effect of temperatures on key performance parameters. They extended the previous framework, i.e., the CloudSim toolkit by presenting an RNN-based temperature predictor for helping to analyze the performance of some key parameters. The final results demonstrated that ThermoSim accurately modeled and simulated the thermal behavior of a CDC in terms of energy consumption, time, cost, and memory usage. 7.6.5 Code classification. Bui et al. [22] described a framework of Bi-NN that built a neural network on top of two underlying sub-networks, each of which encoded syntax and semantics of code in a language. Bi-NN was trained with bilateral programs that implement the same algorithms and/or data structures in different languages and then be applied to recognize algorithm classes across languages. Software categorization is the task of organizing software into groups that broadly describe the behavior of the software. However, previous studies suffered very large performance penalties when classifying source code and code comments only. Leclair et al. [59] proposed a set of adaptations to a state-of-the-art neural classification algorithm and conducted two evaluations. 7.6.6 Code smell detection. Fakhoury et al. [24] reported their experience in building an automatic linguistic anti-pattern detection using DNNs. They trained several traditional machine learning and DNNs to identify linguistic anti-patterns. A big challenge for DL-based code smell detection is the lack of a large number of labeled datasets, and thus Liu et al. [68] present a DL-based approach to automatically generating labeled training data for DL-based classifiers. They applied their approach to detecting four common and well-known code smells, i.e., feature envy, long method, large class, and misplaced class. 7.6.7 Self-Admitted Technical Debt (SATD) detection. Technical debt (TD) is a metaphor to reflect the tradeoff developers make between short term benefits and long term stability. Self-admitted technical debt (SATD), a variant of TD, has been proposed to identify debt that is intentionally introduced during SDLC. Ren et al. [102] proposed a CNN-based approach to determine code comments as SATD or non-SATD. They exploited the computational structure of CNNs to identify key phrases and patterns in code comments that are most relevant to SATD for improving the explainability of our model's prediction results. Zampetti et al. [136] proposed to automatically recommend SATD removal strategies by building a multi-level classifier on a curated dataset of SATD removal patterns. Their strategy was capable of recommending six SATD removal patterns, i.e., changing API calls, conditionals, method signatures, exception handling, return statements, or telling that a more complex change is needed. 7.6.8 Code review. Siow et al. [106] believed that the hinge of the accurate code review suggestion is to learn good representations for both code changes and reviews. Therefore, they designed a multi-level embedding framework to represent the semantics provided by code changes and reviews and then well trained through an attention-based deep learning model, CORE. Guo et al. [34] proposed Deep Review Sharing, a new technique based on code clone detection for accurate review sharing among similar software projects, and optimized their technique by a series of operations such as heuristic filtering and review deduplication. They evaluated Deep Review Sharing on hundreds of real code segments and it won considerable positive approvals by experts, illustrating its effectiveness.\n\n7.6.9 Software quality evaluation. Variety evaluation metrics can be used to describe the quality of software products [101].\n\nSoftware trustworthiness. It is essential and necessary to evaluate software trustworthiness based on the influence degrees of different software behaviors for minimizing the interference of human factors. Tian et al. [109] constructed behaviour trajectory matrices to represent the behaviour trajectory and then trained the deep residual network (ResNet) as a software trustworthiness evaluation model to classify the current software behaviors. After that, they used the cosine similarity algorithm to calculate the deviation degree of the software behavior trajectory.\n\nReadability. Mi et al. [86] proposed to leverage CNN to improve code readability classification. First, they present a transformation strategy to generate integer matrices as the input of ConvNets. Then they trained Deep CRM, a DL-based model, which was made up of three separate ConvNets with identical architectures for code readability classification.\n\nMaintainability. Kumar et al. [55] performed two case studies and applied three DNNs i.e., FLANN-Genetic (FGA and AFGA), FLANN-PSO (FPSO and MFPSO), FLANN-CSA (FCSA), to design a model for predicting maintainability. They also evaluated the effectiveness of feature reduction techniques for predicting maintainability. The experimental result showed that feature reduction techniques can achieve better results compared with using DNNs. 7.7 Software management 7.7.1 Effort estimation. Since only 39% of software projects are finished and published on time relative to the duration planned originally [7,78], it is necessary to assess the development cost to achieve reliable software within development schedule and budget. Lopez et al. [78] compared three different neural network models for effort estimation. The experimental result demonstrated that MLP and RBFNN can achieve higher accuracy than the MLR model. Choetkiertiku et al. [15] observed that few studies focused on estimating effort cost in agile projects, and thus they proposed a DL-based model for predicting development cost based on combining two powerful DL techniques: LSTM and recurrent highway network (RHN). Phannachitta et al. [99] conducted an empirical study to revisit the systematic comparison of heuristics-based and learning-based software effort estimators on 13 standard benchmark datasets. Ochodek et al. [94] employed several DNNs (i.e., CNN, RNN, Convolutional + Recurrent Neural Network (CRNN)) to design a novel prediction model, and compared the performance of the DL-based model with three state-of-the-art approaches: AUC, AUCG, and BN-UCGAIN. They noticed that CNN obtained the best prediction accuracy among all software effort adaptors. 7.7.2 Software repository mining. Some primary studies use DL techniques to mine the contents in different software repositories [35,58,81]. In this section, we introduce three most widely used repositories, i.e., Stack Overflow (SO) [70,146], GitHub [50], and Youtube [95].\n\nMining Stack Overflow (SO). The questions and answers in SO contain a great deal of useful information that is beneficial for programmers to address some tough problems when implementing software products. Considering a question and its answers in Stack Overflow as a knowledge unit, Xu et al. [131,132] extracted the knowledge units and analyzed the potential semantic relationship between Q and A in each unit. They formulated the problem of predicting semantically linkable knowledge units as a multi-class classification problem and adopted a CNN model combining with word-embedding to capture and classify document-level semantics of knowledge units. Chen et al. [13] also applied word embeddings and the CNN model to mine SO for retrieving cross-lingual questions. They compared their approach with other translation-based methods, and the final results showed that their approach can significantly outperform baselines and can also be extended to dual-language document retrieval from different sources. Yin et al. [134] proposed a new approach to pair the title of a question with the code in the accepted answer by mining high-quality aligned data from SO using two sets of features. To validate whether DL was the best solution in all research topics, Menzies et al. [85] conducted a case study to explore faster approaches for text mining SO. They compared nine different solutions including traditional machine learning algorithms and DL algorithms and noticed that a tuned SVM performs similarly to a deep learner and was over 500 times faster than DL-based models. Zhang et al. [138] performed an empirical study to mine the posts in SO for investigating what potential challenges developers face when using DL. They also built a classification model to quantify the distribution of different Sort of DL related questions. They summarized the three most frequently asked questions and provided five future research directions. Since answers to a question may contain extensive irrelevant information, Wang et al. [119] proposed a DL-based approach, DeepTip, using different CNN architectures to extract short practical and useful tips and filtered useless information from developer answers. They conducted a user study to prove the effectiveness of their approach and the extensive empirical experiments demonstrated that DeepTip can extract useful information from answers with high precision and coverage, significantly outperforming two state-of-the-art approaches.\n\nMining GitHub. Huang et al. [46] proposed a new model to classify sentences from issue reports of four projects in GitHub. They constructed a dataset collecting 5,408 sentences and refined previous categories (i.e., feature request, problem discovery, information seeking, information giving, and others). They then trained a CNN-based model to automatically classify sentences into different categories of intentions and used the batch normalization and automatic hyperparameter tuning approach to optimize their model. Xie et al. [130] proposed a new approach to recover issue-commit links. They constructed the code knowledge graph of a code repository and captured the semantics of issue-or commit-related text by generating embeddings of source code files. Then they trained a DNN model to calculate code similarity and semantic similarity using additional features. Ruan et al. [104] propose a novel semantically-enhanced link recovery method, DeepLink, using DL techniques. They applied word embedding and RNN to implement a DNN architecture to learn the semantic representation of code and texts as well as the semantic correlation between issues and commits. They compared DeepLink with the state-of-the-art approach on 10 GitHub Java projects to evaluate the effectiveness of DeepLink. Liu et al. [76] proposed a DL-based approach to automatically generate pull request descriptions based on the commit messages and the added source code comments in pull requests. They formulated this problem as a text summarization problem and solved it, constructing an attentional encoder-decoder model with a pointer generator.\n\nMining Youtube. Ott et al. [95] employed CNN and AutoEncoder to identify Java code from videos on Youtube. Their approach was able to identify the presence of typeset and handwritten source code in thousands of video images with 85.6%-98.6% accuracy based on syntactic and contextual features learned through DL techniques. Zhao et al. [140] present a new technique for recognizing workflow actions in programming screencasts. They collected programming screencasts from Youtube and trained a CNN model to identify nine classes of frequent developer actions by employing the image differencing technique and training a CNN model.\n\n\nSummary\n\n(1) We grouped six SE activities based on the body knowledge of SE -Software requirements, Software design and modeling, Software implementation, Software testing and debugging, Software maintenance, and Software management -and provided an outline of the application trend of DL techniques among these SE activities.\n\n(2) We summarized various SE tasks into four categories -regression task, classification task, ranking task, and generation task -and classified all primary studies based on the task types. Most studies can be mapped to classification tasks, and only 11% of primary studies are mapped to ranking tasks. (3) Software testing and software maintenance are the two SE activities containing the most related studies and include 17 specific SE research topics in which DL techniques were used.\n\n\nLIMITATIONS\n\nData Extraction. There are several potential limitations to our work. One limitation is the potential bias in data collection. Although we have listed the data items used for analysis in RQs in Section 3.4, some disagreements still appeared inevitably when extracting related content and classifying these data items. Two researchers first recorded the relevant descriptions in each primary study and then discussed and generalized temporary categories based on all data in one item by comparing the objectives and contributions with related studies. If they were unable to reach an agreement on classification, another researcher would join in and resolve differences, which can mitigate the bias in data extraction to study validity. Study Selection Bias. Another threat might be the possibility of missing DL related studies during the literature search and selection phase. We are unable to identify and retrieve all relevant publications considering the many publication venues publishing SE relevant papers. Therefore, we carefully selected 21 publication venues, including conference proceedings, symposiums, and journals, which can cover many prior works in SE. Besides, we identified our search terms and formed a search string by combining and amending the search strings used in other literature reviews on DL. These could keep the number of missed primary studies as small as possible.\n\n\nCHALLENGES AND OPPORTUNITIES\n\nUsing DL in more SE activities. We found that DL has been widely used in certain SE topics, such as defect prediction, code clone detection, software repository mining, etc. However, few studies used DL for some SE research topics compared with other techniques or other learning algorithms. Although Software requirements and software design are the most two important documentations during SDLC, not many studies focus on these two SE activities. Therefore, one potential opportunity is that researchers can utilize DL techniques to explore new research topics or pay attention to classical topics in software requirements and design. The transparency of DL. In this study, we discussed 142 studies that used DL to address various SE issues. We noticed that few studies declared the reason for the architecture they chose and explained the necessity and value of each layer in DNN, which leads to low transparency of the proposed DL solutions. Because it is inherently difficult to comprehend what drives the decisions of the DNN due to the black-box nature of DL. Humans only pay attention to the output of DNNs since they can provide wise and actionable suggestions for humans. Furthermore, DL algorithms sift through millions of data points to find patterns and correlations that often go unnoticed by human experts. The decision they make based on these findings often confound even the engineers who created them. New methods and studies on explaining the decision-making process of DNNs should be an active research direction, which facilitates software engineers to design more effective DNN architectures for specific SE problems.\n\nDL in real scenarios. We analyzed the source of datasets used for training DNNs in RQ3 and noticed that only 4% studies used industry datasets to train and evaluate their proposed models. In fact, most studies contribute to addressing real-world SE issues, but the novel solutions or DL-based models have not been evaluated on industry data. There is a room for more industry-academia collaboration so that the proposed models can be validated on real industry data (which can be of very different nature than open-source data. Data hungry. When analyzing the studies related to code clone detection, we found that several open-source public data sets are often used repeatedly in these studies to evaluate their proposed models. A similar situation also exists in other research topics. These highlight the dependence on some studies on large publicly available labelled datasets. One reason is that training a DNN requires a massive volume of data, but copious amounts of training data are rarely available in most SE tasks. Besides, it is impossible to give every possible labeled sample of a problem space to a DL algorithm. Therefore, it will have to generalize or interpolate between its previous samples in order to classify data it has never seen before. It is a challenge to tackle the problem that DL techniques currently lack a mechanism for learning abstractions through explicit, verbal definition and only work best with thousands, millions, or even billions of training examples. One solution is to construct widely accepted datasets by using industrial labeled data or crawling software repositories to collect related data samples and label them as public datasets. Another is to develop new DL techniques, which can learn how to learn and be trained as an effective model with as little data size as possible, such as meta-learning.\n\nPerformance of DL and traditional techniques. DL has been gradually used in more and more SE tasks, replacing the status of traditional algorithms. However, are DL algorithms really more efficient than traditional algorithms? What SE tasks are suitable for DL algorithms? What factors determine whether DL algorithms are better or worse than traditional algorithms? These questions are almost unanswered and neglected by most researchers. A potential opportunity is to answer these questions. researchers can conduct empirical studies to investigate what SE tasks or environments are suitable for DL and compare the performance between DL and traditional techniques in some important SE research topics where most of Dl algorithms were applied.\n\n\nCONCLUSION\n\nThis work performed a SLR on 142 primary studies related to DL for SE from 21 publication venues, including conference proceedings, symposiums, and journals. We established four research questions to comprehensively investigate various aspects pertaining to applications of DL models to SE tasks. Our SLR showed that there was a rapid growth of research interest in the use of DL for SE. Through an elaborated investigation and analysis, three DL architectures containing 30 different DNNs were used in primary studies, where RNN, CNN, and FNN are the three most widely used neural networks compared with other DNNs. We also generalized three different model selection strategies and analyzed the popularity of each one. To comprehensively understand the DNN training and testing process, we provided a detailed overview of key techniques in terms of data collection, data processing, model optimization, and model evaluation in RQ3. In RQ4, we analyzed the distribution of DL techniques used in different SE activities, classified primary studies according to specific SE tasks they solved and gave a brief summary of each work. We observed that DL techniques were applied in 23 SE topics, covering 6 SE activities. Finally, we identified a set of current challenges that still need to be addressed in future work on using DLs in SE.\n\nFig. 1 .\n1The basic structure of a deep learning model.\n\n( 3 )\n3RQ3: What key factors contribute to difficulties in training DNNs for SE tasks? (4) RQ4: What types of SE tasks and which SE phases have been facilitated by DL-based approaches? RQ1 analyzes the distribution of relevant publications that used DL in their studies since 2006 to give an overview of the trend of DL in SE. RQ2 provides a classification of different DL techniques supporting SE tasks and analyze their popularity based on their frequency of use in SE. RQ3 explores key technologies and factors that may affect the efficiency of the DNN training phase. RQ4 investigates what types of SE tasks and which SE phases have been facilitated by DNNs.\n\n\nof publications per year.\n\n\nnumber of publications per year.\n\nFig. 2 .\n2Publication trends of DL-based primary studies in SE.\n\n\nNumber of primary studies published in various journals.\n\nFig. 3 .\n3Distribution of different publication venues.\n\n( 3 )\n3Compared with Encoder-Decoder and AE, the layered architecture of DNNs is by far the most popular option in SE. (4) Four specific DNNs are used in more than 20 primary studies, i.e., CNN (43), LSTM (35), RNN (23), and FNN\n\n6.1. 1\n1What were the sources of datasets used for training DNNs?Fig. 4shows the sources of datasets in the selected primary studies. It can be seen that 45% of primary studies trained DNNs by using an open-source dataset. One reason for choosing an open-source dataset is that studies are willing to pick up these datasets to evaluate the effectiveness of proposed DL-based approaches due to the existence of widely accepted datasets in (a) The sources of DL-related dataets.(b) The sources of collected datasets.\n\nFig. 4 .\n4The source of datasets used in primary study papers\n\nFig. 5 .\n5Various optimization algorithms used in primary studies.\n\nFig. 6 .\n6The distribution of various overfitting techniques used in primary studies\n\nFig. 7 .\n7The distribution of DL techniques in Different SE activities.\n\nFig. 8 .\n8The classification of primary studies.\n\nTable 1 .\n1Publication venues for manual search \u2718 If a conference paper has an extended journal version, the conference version is excluded.No. Acronym \nFull name \n\n1. \nICSE \nACM/IEEE International Conference on Software Engineering \n2. \nASE \nIEEE/ACM International Conference Automated Software Engineering \n3. \nESEC/FSE ACM SIGSOFT Symposium on the Foundation of Software Engineering/European Soft-\nware Engineering Conference \n4. \nICSME \nIEEE International Conference on Software Maintenance and Evolution \n5. \nICPC \nIEEE International Conference on Program Comprehension \n6. \nESEM \nInternational Symposium on Empirical Software Engineering and Measurement \n7. \nRE \nIEEE International Conference on Requirements Engineering \n8. \nMSR \nIEEE Working Conference on Mining Software Repositories \n9. \nISSTA \nInternational Symposium on Testing and Analysis Working Conference on Mining Soft-\nware Repositories \n10. SANER \nIEEE International Conference on Software Analysis, Evolution and Reengineering \n11. ICST \nIEEE International Conference on Software Testing, Verification and Validation \n12. ISSRE \nIEEE International Symposium on Software Reliability Engineering \n\n13. TSE \nIEEE Transactions on Software Engineering \n14. TOSEM \nACM Transactions on Software Engineering and Methodology \n15. ESE \nEmpirical Software Engineering \n16. JSS \nJournal of Systems and Software \n17. IST \nInformation and Software Systems \n18. ASEJ \nAutomated Software Engineering \n19. IETS \nIET Software \n20. STVR \nSoftware Testing, Verification and Reliability \n21. JSEP \nJournal of Software: Evolution and Process \n22. SQJ \nSoftware Quality Journal \n\n\n\nTable 2 .\n2Data Collection for Research QuestionsRQs \nExtracted data items \n\nRQ1 \nBasic information of each primary study (i.e., title, publication year, authors, publication venue) \nRQ1 \nThe type of main contribution in each study (e.g., empirical study, case study, survey, or algorithm) \nRQ2 \nDL techniques used in each study \nRQ2 \nWhether and how the authors describe the rationale behind techniques selection \nRQ3 \nDataset source (e.g., industry data, open source data, or collected data) \nRQ3 \nData type (e.g., source code, nature language text, and pictures) \nRQ3 \nThe process that datasets are transformed into input sets suitable for DNNs \nRQ3 \nWhether and what optimization techniques are used \nRQ3 \nWhat measures are used to evaluate the DL model \nRQ3 \nPresence / absence of replication package \nRQ4 \n\n\nTable 3 .\n3Publication Venues with DL-based Studies.Conference venue #Studies Journal venue #Studies \n\nSANER \n22 \nTSE \n11 \nASE \n16 \nIST \n11 \nICSE \n13 \nJSS \n10 \nMSR \n10 \nTOSEM \n5 \nICSME \n8 \nESE \n2 \nISSTA \n7 \nASEJ \n2 \nFSE \n6 \nIETS \n1 \nICST \n5 \nSTVR \n1 \nICPC \n4 \nSQJ \n1 \nRE \n3 \nISSRE \n3 \nESEM \n1 \n\nESEM \nISSRE \nRE \nICPC \nICST \nFSE \nISSTA \nICSME \nMSR \nICSE \nASE \nSANER \n\nNumber of Publications \n\n\n\nTable 5 .\n5The number of various DNNs applied in per year.Architecture \nFamily \nModel Name \n2015 2016 2017 2018 2019 2020 Total \n\nLayered \narchitecture \n(157) \n\nRNN-based \nmodel (72) \n\nRNN \n1 \n3 \n7 \n10 \n2 \n23 \nRtNN \n1 \n1 \n2 \nBidirectional RNN (BRNN) \n1 \n1 \nLSTM \n3 \n10 \n16 \n6 \n35 \nBi-LSTM \n1 \n1 \n2 \n4 \nSiamese LSTM \n1 \n1 \nGRU \n1 \n3 \n4 \nBidirectional GRU \n1 \n1 \nRecurrent Highway Network \n1 \n1 \n\nCNN-based \nmodel (48) \n\nCNN \n2 \n2 \n13 \n20 \n6 \n43 \nTree-based CNN (TBCNN) \n2 \n1 \n3 \nRCNN \n1 \n1 \nDeep Residual Network \n1 \n1 \n\nFNN-based \nmodel (25) \n\nFNN \n3 \n1 \n8 \n7 \n3 \n22 \nRBFNN \n1 \n1 \nDeep Sparse FNN \n1 \n1 \nDeep MLP \n1 \n1 \nGNN-based \nmodel (6) \n\nGGNN \n4 \n1 \n5 \nGraph Matching Network \n(GMN) \n\n1 \n1 \n\nTailored \nmodel (4) \n\nDeep Beliefe Network \n(DBN) \n\n1 \n1 \n2 \n\nHAN \n1 \n1 \nDeep Forest \n1 \n1 \n\nEncoder-Decoder \n(15) \n\nRNN-based \nmodel (12) \n\nRNN \n1 \n1 \n6 \n8 \nLSTM \n2 \n2 \n4 \nCNN-based \nmodel (1) \n\nCNN \n1 \n1 \n\nFNN-based \nmodel (2) \n\nFNN \n1 \n1 \n2 \n\nAutoEncoder \n(7) \n\nRNN-based \nmodel (1) \n\nGRU \n1 \n1 \n\nCNN-based \nmodel (1) \n\nCNN \n1 \n1 \n\nFNN-based \nmodel (5) \n\nFNN \n2 \n1 \n2 \n5 \n\n\n\nTable 6 .\n6Data types of datasets involved in primary studies.Family \nData types \n#Studies Total \n\nCode-based data types \n\nSource code \n61 \nSoftware/code metric \n8 \nCode comment \n7 \nDefects \n7 \nTest case \n6 \nprogram screencasts \n4 \nUI images \n4 \nCode change \n2 \nCode annotation \n2 \nPull-requests \n2 \nPatch \n1 \n\n104 \n\nText-based data types \n\nBug report \n9 \nRequirement documentation \n4 \nconfiguration documentation \n2 \nAPP description \n2 \nSoftware version information \n2 \nDesign documentation \n1 \nLog information \n1 \nCertification \n1 \nProtocol message \n1 \nPatch \n1 \n\n23 \n\nSoftware repository-based data types \n\nQ&A in SO \n6 \nTags in SO \n5 \nIssues and commits \n4 \nPull-requests \n2 \n\n17 \n\nUser-based data types \n\nUser behavior \n3 \nUser review \n1 \nInteraction traces \n1 \n\n5 \n\n\n\nTable 8 .\n8Metrics used for evaluation.Metrics \n#Studies \n\nPrecision@k \n69 \nRecall@k \n59 \nF1@k \n53 \nAccuracy \n26 \nMean Reciprocal Rank (MRR) \n15 \nBLEU \n13 \nRunning time \n13 \nAUC \n11 \nMean Average Precision (MAP) \n7 \nMatthews Correlation Coefficient (MCC) \n5 \nP-value \n4 \nMETEOR \n4 \nROC \n4 \nROUGE \n4 \nMean Absolute Error (MAE) \n4 \nSuccessRate@k \n3 \nCliff's Delta \n3 \nCoverage \n3 \nBal (Balance) \n3 \nStandardized Accuracy (SA) \n3 \nOthers \n11 \n\n\n\nTable 9 .\n9The specific research topics where DL techniques are often applied.SE activities \nspecific research topics \n#Studies Total \n\nSoftware design \nSource code representation \n5 \n5 \n\nSoftware implementation \nCode search \n5 \nCode programming \n4 \n9 \n\nSoftware testing and debugging \n\nDefect prediction \n11 \nBug localization \n7 \nApplication testing \n7 \nProgram analysis \n5 \nTest case generation \n4 \nReverse execution \n3 \n\n37 \n\nSoftware maintenance \n\nCode clone detection \n11 \nProgram repair \n6 \nCode comment generation \n4 \nSoftware quality evaluation \n4 \nSource code representation \n4 \n\n28 \n\nSoftware management \nSoftware repository mining \n19 \nEffort cost prediction \n6 \n25 \n\n\nACM Comput. Surv., Vol. 1, No. 1, Article 1. Publication date: January 2020.\nhttps://dl.acm.org 2 https://ieeexplore.ieee.org 3 http://apps.webofknowledge.com\n\nThe use of artificial neural networks for extracting actions and actors from requirements document. Aysh Al-Hroob, Ayad Tareq Imam, Rawan Al-Heisa, IST. 101Aysh Al-Hroob, Ayad Tareq Imam, and Rawan Al-Heisa. 2018. The use of artificial neural networks for extracting actions and actors from requirements document. IST 101 (2018), 1-15.\n\nCode Localization in Programming Screencasts. Mohammad Alahmadi, Abdulkarim Khormi, Biswas Parajuli, Jonathan Hassel, Sonia Haiduc, Piyush Kumar, ESE. 25Mohammad Alahmadi, Abdulkarim Khormi, Biswas Parajuli, Jonathan Hassel, Sonia Haiduc, and Piyush Kumar. 2020. Code Localization in Programming Screencasts. ESE 25, 2 (2020), 1536-1572.\n\n2020. psc2code: Denoising Code Extraction from Programming Screencasts. Lingfeng Bao, Zhenchang Xing, Xin Xia, David Lo, Minghui Wu, Xiaohu Yang, TOSEM. 29Lingfeng Bao, Zhenchang Xing, Xin Xia, David Lo, Minghui Wu, and Xiaohu Yang. 2020. psc2code: Denoising Code Extraction from Programming Screencasts. TOSEM 29, 3 (2020), 1-38.\n\nDeep Learning Anti-patterns from Code Metrics History. Antoine Barbez, Foutse Khomh, Yann-Ga\u00ebl Gu\u00e9h\u00e9neuc, ICSME. IEEE. Antoine Barbez, Foutse Khomh, and Yann-Ga\u00ebl Gu\u00e9h\u00e9neuc. 2019. Deep Learning Anti-patterns from Code Metrics History. In ICSME. IEEE, 114-124.\n\nTesting advanced driver assistance systems using multi-objective search and neural networks. Raja Ben Abdessalem, Shiva Nejati, C Lionel, Thomas Briand, Stifter, ASE. Raja Ben Abdessalem, Shiva Nejati, Lionel C Briand, and Thomas Stifter. 2016. Testing advanced driver assistance systems using multi-objective search and neural networks. In ASE. 63-74.\n\nNeuro-symbolic program corrector for introductory programming assignments. Sahil Bhatia, Pushmeet Kohli, Rishabh Singh, ICSE. IEEE. Sahil Bhatia, Pushmeet Kohli, and Rishabh Singh. 2018. Neuro-symbolic program corrector for introductory programming assignments. In ICSE. IEEE, 60-70.\n\nSoftware development efforts prediction using artificial neural network. Manjubala Bisi, Neeraj Kumar Goyal, IETS. 10Manjubala Bisi and Neeraj Kumar Goyal. 2016. Software development efforts prediction using artificial neural network. IETS 10, 3 (2016), 63-71.\n\nGuide to the software engineering body of knowledge (SWEBOK (R)): Version 3.0. Pierre Bourque, Richard E Fairley, IEEE Computer Society PressPierre Bourque, Richard E Fairley, et al. 2014. Guide to the software engineering body of knowledge (SWEBOK (R)): Version 3.0. IEEE Computer Society Press.\n\nLearning-based recursive aggregation of abstract syntax trees for code clone detection. Lutz B\u00fcch, Artur Andrzejak, SANER. IEEE. Lutz B\u00fcch and Artur Andrzejak. 2019. Learning-based recursive aggregation of abstract syntax trees for code clone detection. In SANER. IEEE, 95-104.\n\nWhen deep learning met code search. Jose Cambronero, Hongyu Li, Seohyun Kim, Koushik Sen, Satish Chandra, FSE. Jose Cambronero, Hongyu Li, Seohyun Kim, Koushik Sen, and Satish Chandra. 2019. When deep learning met code search. In FSE. 964-974.\n\nDRLgencert: Deep learning-based automated testing of certificate verification in SSL/TLS implementations. Chao Chen, Wenrui Diao, Yingpei Zeng, Shanqing Guo, Chengyu Hu, ICSME. IEEE. Chao Chen, Wenrui Diao, Yingpei Zeng, Shanqing Guo, and Chengyu Hu. 2018. DRLgencert: Deep learning-based automated testing of certificate verification in SSL/TLS implementations. In ICSME. IEEE, 48-58.\n\nFrom ui design image to gui skeleton: a neural machine translator to bootstrap mobile gui implementation. Chunyang Chen, Ting Su, Guozhu Meng, Zhenchang Xing, Yang Liu, Chunyang Chen, Ting Su, Guozhu Meng, Zhenchang Xing, and Yang Liu. 2018. From ui design image to gui skeleton: a neural machine translator to bootstrap mobile gui implementation. In ICSE. 665-676.\n\nLearning a dual-language vector space for domain-specific cross-lingual question retrieval. Guibin Chen, Chunyang Chen, Zhenchang Xing, Bowen Xu, ASE. IEEE. Guibin Chen, Chunyang Chen, Zhenchang Xing, and Bowen Xu. 2016. Learning a dual-language vector space for domain-specific cross-lingual question retrieval. In ASE. IEEE, 744-755.\n\nWireframe-based UI design search through image autoencoder. Jieshan Chen, Chunyang Chen, Zhenchang Xing, Xin Xia, Liming Zhu, John Grundy, Jinshui Wang, TOSEM. 29Jieshan Chen, Chunyang Chen, Zhenchang Xing, Xin Xia, Liming Zhu, John Grundy, and Jinshui Wang. 2020. Wireframe-based UI design search through image autoencoder. TOSEM 29, 3 (2020), 1-31.\n\nA deep learning model for estimating story points. Morakot Choetkiertikul, Hoa Khanh Dam, Truyen Tran, Trang Pham, Aditya Ghose, Tim Menzies, TSE. 45Morakot Choetkiertikul, Hoa Khanh Dam, Truyen Tran, Trang Pham, Aditya Ghose, and Tim Menzies. 2018. A deep learning model for estimating story points. TSE 45, 7 (2018), 637-656.\n\nSuggesting Comment Completions for Python using Neural Language Models. Adelina Ciurumelea, Sebastian Proksch, Harald C Gall, SANER. IEEE. Adelina Ciurumelea, Sebastian Proksch, and Harald C Gall. 2020. Suggesting Comment Completions for Python using Neural Language Models. In SANER. IEEE, 456-467.\n\nCompiler fuzzing through deep learning. Chris Cummins, Pavlos Petoumenos, Alastair Murray, Hugh Leather, ISSTA. Chris Cummins, Pavlos Petoumenos, Alastair Murray, and Hugh Leather. 2018. Compiler fuzzing through deep learning. In ISSTA. 95-105.\n\nLessons learned from using a deep tree-based model for software defect prediction in practice. Hoa Khanh Dam, Trang Pham, Shien Wee, Truyen Ng, John Tran, Aditya Grundy, Taeksu Ghose, Chul-Joo Kim, Kim, MSR. IEEEHoa Khanh Dam, Trang Pham, Shien Wee Ng, Truyen Tran, John Grundy, Aditya Ghose, Taeksu Kim, and Chul-Joo Kim. 2019. Lessons learned from using a deep tree-based model for software defect prediction in practice. In MSR. IEEE, 46-57.\n\nAutomatic feature learning for predicting vulnerable software components. Hoa Khanh Dam, Truyen Tran, Trang Thi , Minh Pham, Shien Wee Ng, John Grundy, Aditya Ghose, TSEHoa Khanh Dam, Truyen Tran, Trang Thi Minh Pham, Shien Wee Ng, John Grundy, and Aditya Ghose. 2018. Automatic feature learning for predicting vulnerable software components. TSE (2018).\n\nA tutorial survey of architectures, algorithms, and applications for deep learning. Li Deng, APSIPA Transactions on Signal and Information Processing. 3Li Deng. 2014. A tutorial survey of architectures, algorithms, and applications for deep learning. APSIPA Transactions on Signal and Information Processing 3 (2014).\n\nTowards accurate duplicate bug retrieval using deep learning techniques. Jayati Deshmukh, Sanjay Annervaz, Shubhashis Podder, Neville Sengupta, Dubash, ICSME. IEEE. Jayati Deshmukh, KM Annervaz, Sanjay Podder, Shubhashis Sengupta, and Neville Dubash. 2017. Towards accurate duplicate bug retrieval using deep learning techniques. In ICSME. IEEE, 115-124.\n\nBilateral dependency neural networks for cross-language algorithm classification. D Q Bui Nghi, Yijun Yu, Lingxiao Jiang, SANER. IEEE. Bui Nghi DQ, Yijun Yu, and Lingxiao Jiang. 2019. Bilateral dependency neural networks for cross-language algorithm classification. In SANER. IEEE, 422-433.\n\nVirtualization of stateful services via machine learning. Ferit Hasan, Alper Eni\u015fer, Sen, SQJ. 28Hasan Ferit Eni\u015fer and Alper Sen. 2020. Virtualization of stateful services via machine learning. SQJ 28, 1 (2020), 283-306.\n\nKeep it simple: Is deep learning good for linguistic smell detection. Sarah Fakhoury, Venera Arnaoudova, Cedric Noiseux, Foutse Khomh, Giuliano Antoniol, SANER. IEEE. Sarah Fakhoury, Venera Arnaoudova, Cedric Noiseux, Foutse Khomh, and Giuliano Antoniol. 2018. Keep it simple: Is deep learning good for linguistic smell detection?. In SANER. IEEE, 602-611.\n\nFunctional code clone detection with syntax and semantics fusion learning. Chunrong Fang, Zixi Liu, Yangyang Shi, Jeff Huang, Qingkai Shi, Chunrong Fang, Zixi Liu, Yangyang Shi, Jeff Huang, and Qingkai Shi. 2020. Functional code clone detection with syntax and semantics fusion learning. In ISSTA. 516-527.\n\nA neural model for method name generation from functional description. Sa Gao, Chunyang Chen, Zhenchang Xing, Yukun Ma, Wen Song, Shang-Wei Lin, SANER. IEEE. Sa Gao, Chunyang Chen, Zhenchang Xing, Yukun Ma, Wen Song, and Shang-Wei Lin. 2019. A neural model for method name generation from functional description. In SANER. IEEE, 414-421.\n\nTECCD: A Tree Embedding Approach for Code Clone Detection. Yi Gao, Zan Wang, Shuang Liu, Lin Yang, Wei Sang, Yuanfang Cai, ICSME. IEEE. Yi Gao, Zan Wang, Shuang Liu, Lin Yang, Wei Sang, and Yuanfang Cai. 2019. TECCD: A Tree Embedding Approach for Code Clone Detection. In ICSME. IEEE, 145-156.\n\nA systematic literature review: Opinion mining studies from mobile app store user reviews. Necmiye Genc, - Nayebi, Alain Abran, JSS. 125Necmiye Genc-Nayebi and Alain Abran. 2017. A systematic literature review: Opinion mining studies from mobile app store user reviews. JSS 125 (2017), 207-219.\n\nThermoSim: Deep learning based framework for modeling and simulation of thermal-aware resource management for cloud computing environments. Shreshth Sukhpal Singh Gill, Adel Nadjaran Tuli, Felix Toosi, Peter Cuadrado, Rami Garraghan, Hanan Bahsoon, Rizos Lutfiyya, Omer Sakellariou, Schahram Rana, Dustdar, JSS. 110596Sukhpal Singh Gill, Shreshth Tuli, Adel Nadjaran Toosi, Felix Cuadrado, Peter Garraghan, Rami Bahsoon, Hanan Lutfiyya, Rizos Sakellariou, Omer Rana, Schahram Dustdar, et al. 2020. ThermoSim: Deep learning based framework for modeling and simulation of thermal-aware resource management for cloud computing environments. JSS (2020), 110596.\n\nLearn&fuzz: Machine learning for input fuzzing. Patrice Godefroid, Hila Peleg, Rishabh Singh, ASE. IEEE. Patrice Godefroid, Hila Peleg, and Rishabh Singh. 2017. Learn&fuzz: Machine learning for input fuzzing. In ASE. IEEE, 50-59.\n\nDeep learning. Ian Goodfellow, Yoshua Bengio, Aaron Courville, MIT pressIan Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep learning. MIT press.\n\nDeep code search. Xiaodong Gu, Hongyu Zhang, Sunghun Kim, ICSE. IEEE. Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. 2018. Deep code search. In ICSE. IEEE, 933-944.\n\nDeep API learning. Xiaodong Gu, Hongyu Zhang, Dongmei Zhang, Sunghun Kim, FSE. Xiaodong Gu, Hongyu Zhang, Dongmei Zhang, and Sunghun Kim. 2016. Deep API learning. In FSE. 631-642.\n\nDeep review sharing. Chenkai Guo, Dengrong Huang, Naipeng Dong, Quanqi Ye, Jing Xu, Yaqing Fan, Hui Yang, Yifan Xu, SANER. IEEE. Chenkai Guo, Dengrong Huang, Naipeng Dong, Quanqi Ye, Jing Xu, Yaqing Fan, Hui Yang, and Yifan Xu. 2019. Deep review sharing. In SANER. IEEE, 61-72.\n\nSystematic comprehension for developer reply in mobile system forum. Chenkai Guo, Weijing Wang, Yanfeng Wu, Naipeng Dong, Quanqi Ye, Jing Xu, Sen Zhang, SANER. IEEE. Chenkai Guo, Weijing Wang, Yanfeng Wu, Naipeng Dong, Quanqi Ye, Jing Xu, and Sen Zhang. 2019. Systematic comprehension for developer reply in mobile system forum. In SANER. IEEE, 242-252.\n\nDeepperf: performance prediction for configurable software with deep sparse neural network. Huong Ha, Hongyu Zhang, ICSE. IEEE. Huong Ha and Hongyu Zhang. 2019. Deepperf: performance prediction for configurable software with deep sparse neural network. In ICSE. IEEE, 1095-1106.\n\nLearning to predict severity of software vulnerability using only vulnerability description. Zhuobing Han, Xiaohong Li, Zhenchang Xing, Hongtao Liu, Zhiyong Feng, ICSME. IEEE. Zhuobing Han, Xiaohong Li, Zhenchang Xing, Hongtao Liu, and Zhiyong Feng. 2017. Learning to predict severity of software vulnerability using only vulnerability description. In ICSME. IEEE, 125-136.\n\nThe problem of overfitting. M Douglas, Hawkins, Journal of chemical information and computer sciences. 44Douglas M Hawkins. 2004. The problem of overfitting. Journal of chemical information and computer sciences 44, 1 (2004), 1-12.\n\nDeep learning type inference. J Vincent, Christian Hellendoorn, Bird, T Earl, Miltiadis Barr, Allamanis, FSE. Vincent J Hellendoorn, Christian Bird, Earl T Barr, and Miltiadis Allamanis. 2018. Deep learning type inference. In FSE. 152-162.\n\nA fast learning algorithm for deep belief nets. Geoffrey E Hinton, Simon Osindero, Yee-Whye Teh, Neural computation. 187Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh. 2006. A fast learning algorithm for deep belief nets. Neural computation 18, 7 (2006), 1527-1554.\n\nDeepJIT: an end-to-end deep learning framework for just-in-time defect prediction. Thong Hoang, Hoa Khanh Dam, Yasutaka Kamei, David Lo, Naoyasu Ubayashi, MSR. IEEEThong Hoang, Hoa Khanh Dam, Yasutaka Kamei, David Lo, and Naoyasu Ubayashi. 2019. DeepJIT: an end-to-end deep learning framework for just-in-time defect prediction. In MSR. IEEE, 34-45.\n\nPatchNet: Hierarchical Deep Learning-Based Stable Patch Identification for the Linux Kernel. Thong Hoang, Julia Lawall, Yuan Tian, J Richard, David Oentaryo, Lo, TSEThong Hoang, Julia Lawall, Yuan Tian, Richard J Oentaryo, and David Lo. 2019. PatchNet: Hierarchical Deep Learning-Based Stable Patch Identification for the Linux Kernel. TSE (2019).\n\nA systematic literature review and meta-analysis on cross project defect prediction. Seyedrebvar Hosseini, Burak Turhan, Dimuthu Gunarathna, TSE. 45Seyedrebvar Hosseini, Burak Turhan, and Dimuthu Gunarathna. 2017. A systematic literature review and meta-analysis on cross project defect prediction. TSE 45, 2 (2017), 111-147.\n\nDeep code comment generation. Xing Hu, Ge Li, Xin Xia, David Lo, Zhi Jin, ICPC. IEEE. Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep code comment generation. In ICPC. IEEE, 200-20010.\n\nA Code-Description Representation Learning Model Based on Attention. Qing Huang, An Qiu, Maosheng Zhong, Yuan Wang, SANER. IEEE. Qing Huang, An Qiu, Maosheng Zhong, and Yuan Wang. 2020. A Code-Description Representation Learning Model Based on Attention. In SANER. IEEE, 447-455.\n\nAutomating intention mining. Qiao Huang, Xin Xia, David Lo, Gail C Murphy, TSEQiao Huang, Xin Xia, David Lo, and Gail C Murphy. 2018. Automating intention mining. TSE (2018).\n\nRubing Huang, Weifeng Sun, Yinyin Xu, Haibo Chen, Dave Towey, and Xin Xia. 2019. A survey on adaptive random testing. TSE. Rubing Huang, Weifeng Sun, Yinyin Xu, Haibo Chen, Dave Towey, and Xin Xia. 2019. A survey on adaptive random testing. TSE (2019).\n\nDeep transfer bug localization. Xuan Huo, Ferdian Thung, Ming Li, David Lo, Shu-Ting Shi, TSEXuan Huo, Ferdian Thung, Ming Li, David Lo, and Shu-Ting Shi. 2019. Deep transfer bug localization. TSE (2019).\n\nCodeGRU: Context-aware deep learning with gated recurrent unit for source code modeling. Yasir Hussain, Zhiqiu Huang, Yu Zhou, Senzhang Wang, IST. 106309Yasir Hussain, Zhiqiu Huang, Yu Zhou, and Senzhang Wang. 2020. CodeGRU: Context-aware deep learning with gated recurrent unit for source code modeling. IST (2020), 106309.\n\nAutomatically generating commit messages from diffs using neural machine translation. Siyuan Jiang, Ameer Armaly, Collin Mcmillan, ASE. IEEE. Siyuan Jiang, Ameer Armaly, and Collin McMillan. 2017. Automatically generating commit messages from diffs using neural machine translation. In ASE. IEEE, 135-146.\n\nUsing recurrent neural networks for decompilation. S Deborah, Jason Katz, Eric Ruchti, Schulte, SANER. IEEE. Deborah S Katz, Jason Ruchti, and Eric Schulte. 2018. Using recurrent neural networks for decompilation. In SANER. IEEE, 346-356.\n\nGuidelines for performing systematic literature reviews in software engineering. Staffs Keele, Technical reportVer. 2.3 EBSE Technical Report. EBSEStaffs Keele et al. 2007. Guidelines for performing systematic literature reviews in software engineering. Technical Report. Technical report, Ver. 2.3 EBSE Technical Report. EBSE.\n\nAn empirical assessment of machine learning approaches for triaging reports of a java static analysis tool. Ugur Koc, Shiyi Wei, S Jeffrey, Marine Foster, Adam A Carpuat, Porter, ICST. IEEEUgur Koc, Shiyi Wei, Jeffrey S Foster, Marine Carpuat, and Adam A Porter. 2019. An empirical assessment of machine learning approaches for triaging reports of a java static analysis tool. In ICST. IEEE, 288-299.\n\nPyse: Automatic worst-case test generation by reinforcement learning. Jinkyu Koo, Charitha Saumya, Milind Kulkarni, Saurabh Bagchi, ICST. IEEE. Jinkyu Koo, Charitha Saumya, Milind Kulkarni, and Saurabh Bagchi. 2019. Pyse: Automatic worst-case test generation by reinforcement learning. In ICST. IEEE, 136-147.\n\nHybrid functional link artificial neural network approach for predicting maintainability of object-oriented software. Lov Kumar, Santanu Ku Rath, JSS. 121Lov Kumar and Santanu Ku Rath. 2016. Hybrid functional link artificial neural network approach for predicting maintainability of object-oriented software. JSS 121 (2016), 170-190.\n\nDire: A neural approach to decompiled identifier naming. Jeremy Lacomis, Pengcheng Yin, Edward Schwartz, Miltiadis Allamanis, Claire Le Goues, Graham Neubig, Bogdan Vasilescu, ASE. IEEEJeremy Lacomis, Pengcheng Yin, Edward Schwartz, Miltiadis Allamanis, Claire Le Goues, Graham Neubig, and Bogdan Vasilescu. 2019. Dire: A neural approach to decompiled identifier naming. In ASE. IEEE, 628-639.\n\nBug localization with combination of deep learning and information retrieval. An Ngoc Lam, Anh Tuan Nguyen, Anh Hoan, Tien N Nguyen, Nguyen, ICPC. IEEE. An Ngoc Lam, Anh Tuan Nguyen, Hoan Anh Nguyen, and Tien N Nguyen. 2017. Bug localization with combination of deep learning and information retrieval. In ICPC. IEEE, 218-229.\n\nDeep specification mining. B Tien-Duy, David Le, Lo, Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis. the 27th ACM SIGSOFT International Symposium on Software Testing and AnalysisTien-Duy B Le and David Lo. 2018. Deep specification mining. In Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis. 106-117.\n\nAdapting neural text classification for improved software categorization. Alexander Leclair, Zachary Eberhart, Collin Mcmillan, ICSME. IEEE. Alexander LeClair, Zachary Eberhart, and Collin McMillan. 2018. Adapting neural text classification for improved software categorization. In ICSME. IEEE, 461-472.\n\nA neural model for generating natural language summaries of program subroutines. Alexander Leclair, Siyuan Jiang, Collin Mcmillan, ICSE. IEEE. Alexander LeClair, Siyuan Jiang, and Collin McMillan. 2019. A neural model for generating natural language summaries of program subroutines. In ICSE. IEEE, 795-806.\n\nDeep learning. Yann Lecun, Yoshua Bengio, Geoffrey Hinton, nature. 521Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature 521, 7553 (2015), 436-444.\n\nClassifying false positive static checker alarms in continuous integration using convolutional neural networks. Seongmin Lee, Shin Hong, Jungbae Yi, Taeksu Kim, Chul-Joo Kim, Shin Yoo, ICST. IEEESeongmin Lee, Shin Hong, Jungbae Yi, Taeksu Kim, Chul-Joo Kim, and Shin Yoo. 2019. Classifying false positive static checker alarms in continuous integration using convolutional neural networks. In ICST. IEEE, 391-401.\n\nDeep Learning Based Identification of Suspicious Return Statements. Guangjie Li, Hui Liu, Jiahao Jin, Qasim Umer, SANER. IEEE. Guangjie Li, Hui Liu, Jiahao Jin, and Qasim Umer. 2020. Deep Learning Based Identification of Suspicious Return Statements. In SANER. IEEE, 480-491.\n\n. ACM Comput. Surv. 11Publication dateACM Comput. Surv., Vol. 1, No. 1, Article 1. Publication date: January 2020.\n\nCclearner: A deep learning-based clone detection approach. Liuqing Li, He Feng, Wenjie Zhuang, Na Meng, Barbara Ryder, ICSME. IEEE. Liuqing Li, He Feng, Wenjie Zhuang, Na Meng, and Barbara Ryder. 2017. Cclearner: A deep learning-based clone detection approach. In ICSME. IEEE, 249-260.\n\nDeepfl: Integrating multiple fault diagnosis dimensions for deep fault localization. Xia Li, Wei Li, Yuqun Zhang, Lingming Zhang, Xia Li, Wei Li, Yuqun Zhang, and Lingming Zhang. 2019. Deepfl: Integrating multiple fault diagnosis dimensions for deep fault localization. In ISSTA. 169-180.\n\nPredicting Node Failures in an Ultra-large-scale Cloud Computing Platform: an AIOps Solution. Yangguang Li, Ming Zhen, Heng Jiang, Ahmed E Li, Cheng Hassan, Ruirui He, Zhengda Huang, Mian Zeng, Pinan Wang, Chen, TOSEM. 29Yangguang Li, Zhen Ming Jiang, Heng Li, Ahmed E Hassan, Cheng He, Ruirui Huang, Zhengda Zeng, Mian Wang, and Pinan Chen. 2020. Predicting Node Failures in an Ultra-large-scale Cloud Computing Platform: an AIOps Solution. TOSEM 29, 2 (2020), 1-24.\n\nChao Liu, Cuiyun Gao, Xin Xia, David Lo, John Grundy, Xiaohu Yang, arXiv:2006.14244On the Replicability and Reproducibility of Deep Learning in Software Engineering. arXiv preprintChao Liu, Cuiyun Gao, Xin Xia, David Lo, John Grundy, and Xiaohu Yang. 2020. On the Replicability and Reproducibility of Deep Learning in Software Engineering. arXiv preprint arXiv:2006.14244 (2020).\n\nDeep learning based code smell detection. Hui Liu, Jiahao Jin, Zhifeng Xu, Yifan Bu, Yanzhen Zou, Lu Zhang, TSEHui Liu, Jiahao Jin, Zhifeng Xu, Yifan Bu, Yanzhen Zou, and Lu Zhang. 2019. Deep learning based code smell detection. TSE (2019).\n\nDeep learning based feature envy detection. Hui Liu, Zhifeng Xu, Yanzhen Zou, ASE. Hui Liu, Zhifeng Xu, and Yanzhen Zou. 2018. Deep learning based feature envy detection. In ASE. 385-396.\n\nFastTagRec: fast tag recommendation for software information sites. Jin Liu, Pingyi Zhou, Zijiang Yang, Xiao Liu, John Grundy, ASEJ. 25Jin Liu, Pingyi Zhou, Zijiang Yang, Xiao Liu, and John Grundy. 2018. FastTagRec: fast tag recommendation for software information sites. ASEJ 25, 4 (2018), 675-701.\n\nLearning to spot and refactor inconsistent method names. Kui Liu, Dongsun Kim, F Tegawend\u00e9, Taeyoung Bissyand\u00e9, Kisub Kim, Anil Kim, Suntae Koyuncu, Yves Le Kim, Traon, ICSE. IEEE. Kui Liu, Dongsun Kim, Tegawend\u00e9 F Bissyand\u00e9, Taeyoung Kim, Kisub Kim, Anil Koyuncu, Suntae Kim, and Yves Le Traon. 2019. Learning to spot and refactor inconsistent method names. In ICSE. IEEE, 1-12.\n\nMuyang Liu, Ke Li, Tao Chen, arXiv:2005.11728DeepSQLi: Deep Semantic Learning for Testing SQL Injection. arXiv preprintMuyang Liu, Ke Li, and Tao Chen. 2020. DeepSQLi: Deep Semantic Learning for Testing SQL Injection. arXiv preprint arXiv:2005.11728 (2020).\n\nAutomatic text input generation for mobile testing. Peng Liu, Xiangyu Zhang, Marco Pistoia, Yunhui Zheng, Manoel Marques, Lingfei Zeng, ICSE. IEEE. Peng Liu, Xiangyu Zhang, Marco Pistoia, Yunhui Zheng, Manoel Marques, and Lingfei Zeng. 2017. Automatic text input generation for mobile testing. In ICSE. IEEE, 643-653.\n\nConnecting software metrics across versions to predict defects. Yibin Liu, Yanhui Li, Jianbo Guo, Yuming Zhou, Baowen Xu, SANER. IEEE. Yibin Liu, Yanhui Li, Jianbo Guo, Yuming Zhou, and Baowen Xu. 2018. Connecting software metrics across versions to predict defects. In SANER. IEEE, 232-243.\n\nWhich variables should i log?. Zhongxin Liu, Xin Xia, David Lo, Zhenchang Xing, Ahmed E Hassan, Shanping Li, TSEZhongxin Liu, Xin Xia, David Lo, Zhenchang Xing, Ahmed E Hassan, and Shanping Li. 2019. Which variables should i log? TSE (2019).\n\nAutomatic generation of pull request descriptions. Zhongxin Liu, Xin Xia, Christoph Treude, David Lo, Shanping Li, ASE. IEEE. Zhongxin Liu, Xin Xia, Christoph Treude, David Lo, and Shanping Li. 2019. Automatic generation of pull request descriptions. In ASE. IEEE, 176-188.\n\nAutomating Just-In-Time Comment Updating. Zhongxin Liu, Xin Xia, Meng Yan, Shanping Li, ASE. n. d.Zhongxin Liu, Xin Xia, Meng Yan, and Shanping Li. [n. d.]. Automating Just-In-Time Comment Updating. In ASE.\n\nNeural networks for predicting the duration of new software projects. Cuauht\u00e9moc L\u00f3pez-Mart\u00edn, Alain Abran, JSS. 101Cuauht\u00e9moc L\u00f3pez-Mart\u00edn and Alain Abran. 2015. Neural networks for predicting the duration of new software projects. JSS 101 (2015), 127-135.\n\nCoCoNuT: combining context-aware neural translation models using ensemble for program repair. Thibaud Lutellier, Hung Viet Pham, Lawrence Pang, Yitong Li, Moshi Wei, Lin Tan, Thibaud Lutellier, Hung Viet Pham, Lawrence Pang, Yitong Li, Moshi Wei, and Lin Tan. 2020. CoCoNuT: combining context-aware neural translation models using ensemble for program repair. In ISSTA. 101-114.\n\nEasy-to-Deploy API Extraction by Multi-Level Feature Embedding and Transfer Learning. Suyu Ma, Zhenchang Xing, Chunyang Chen, Cheng Chen, Lizhen Qu, Guoqiang Li, TSE. Suyu Ma, Zhenchang Xing, Chunyang Chen, Cheng Chen, Lizhen Qu, and Guoqiang Li. 2019. Easy-to-Deploy API Extraction by Multi-Level Feature Embedding and Transfer Learning. TSE (2019).\n\nCross-Dataset Design Discussion Mining. Alvi Mahadi, Karan Tongay, Neil A Ernst, SANER. IEEE. Alvi Mahadi, Karan Tongay, and Neil A Ernst. 2020. Cross-Dataset Design Discussion Mining. In SANER. IEEE, 149-160.\n\nNl2type: inferring javascript function types from natural language information. Jibesh Rabee Sohail Malik, Michael Patra, Pradel, ICSE. IEEE. Rabee Sohail Malik, Jibesh Patra, and Michael Pradel. 2019. Nl2type: inferring javascript function types from natural language information. In ICSE. IEEE, 304-315.\n\nAn extensive study on cross-project predictive mutation testing. Dongyu Mao, Lingchao Chen, Lingming Zhang, ICST. IEEE. Dongyu Mao, Lingchao Chen, and Lingming Zhang. 2019. An extensive study on cross-project predictive mutation testing. In ICST. IEEE, 160-171.\n\nA logical calculus of the ideas immanent in nervous activity. S Warren, Walter Mcculloch, Pitts, The bulletin of mathematical biophysics. 5Warren S McCulloch and Walter Pitts. 1943. A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics 5, 4 (1943), 115-133.\n\n500+ times faster than deep learning:(a case study exploring faster methods for text mining stackoverflow). Tim Menzies, Suvodeep Majumder, Nikhila Balaji, Katie Brey, Wei Fu, MSR. IEEETim Menzies, Suvodeep Majumder, Nikhila Balaji, Katie Brey, and Wei Fu. 2018. 500+ times faster than deep learning:(a case study exploring faster methods for text mining stackoverflow). In MSR. IEEE, 554-563.\n\nImproving code readability classification using convolutional neural networks. Qing Mi, Jacky Keung, Yan Xiao, Solomon Mensah, Yujin Gao, IST. 104Qing Mi, Jacky Keung, Yan Xiao, Solomon Mensah, and Yujin Gao. 2018. Improving code readability classification using convolutional neural networks. IST 104 (2018), 60-71.\n\nDeep belief networks for phone recognition. Abdel-Rahman Mohamed, George Dahl, Geoffrey Hinton, Nips workshop on deep learning for speech recognition and related applications. Vancouver, Canada139Abdel-rahman Mohamed, George Dahl, and Geoffrey Hinton. 2009. Deep belief networks for phone recognition. In Nips workshop on deep learning for speech recognition and related applications, Vol. 1. Vancouver, Canada, 39.\n\nMachine learning-based prototyping of graphical user interfaces for mobile apps. Kevin Patrick Moran, Carlos Bernal-C\u00e1rdenas, Michael Curcio, Richard Bonett, Denys Poshyvanyk, TSEKevin Patrick Moran, Carlos Bernal-C\u00e1rdenas, Michael Curcio, Richard Bonett, and Denys Poshyvanyk. 2018. Machine learning-based prototyping of graphical user interfaces for mobile apps. TSE (2018).\n\nRENN: efficient reverse execution with neural-network-assisted alias analysis. Dongliang Mu, Wenbo Guo, Alejandro Cuevas, Yueqi Chen, Jinxuan Gai, Xinyu Xing, Bing Mao, Chengyu Song, ASE. IEEEDongliang Mu, Wenbo Guo, Alejandro Cuevas, Yueqi Chen, Jinxuan Gai, Xinyu Xing, Bing Mao, and Chengyu Song. 2019. RENN: efficient reverse execution with neural-network-assisted alias analysis. In ASE. IEEE, 924-935.\n\nCLCDSA: cross language code clone detection using syntactical features and API documentation. Tonny Kawser Wazed Nafi, Banani Shekha Kar, Roy, K Chanchal, Kevin A Roy, Schneider, ASE. IEEEKawser Wazed Nafi, Tonny Shekha Kar, Banani Roy, Chanchal K Roy, and Kevin A Schneider. 2019. CLCDSA: cross language code clone detection using syntactical features and API documentation. In ASE. IEEE, 1026-1037.\n\nEffective modeling of encoder-decoder architecture for joint entity and relation extraction. Tapas Nayak, Hwee Tou Ng, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34Tapas Nayak and Hwee Tou Ng. 2020. Effective modeling of encoder-decoder architecture for joint entity and relation extraction. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 8528-8535.\n\nA deep neural network language model with contexts for source code. Anh Tuan Nguyen, Trong Duc Nguyen, Hung Dang Phan, Tien N Nguyen, SANER. IEEE. Anh Tuan Nguyen, Trong Duc Nguyen, Hung Dang Phan, and Tien N Nguyen. 2018. A deep neural network language model with contexts for source code. In SANER. IEEE, 323-334.\n\nAnalyzing bug fix for automatic bug cause classification. Zhen Ni, Bin Li, Xiaobing Sun, Tianhao Chen, Ben Tang, Xinchen Shi, JSS. 163110538Zhen Ni, Bin Li, Xiaobing Sun, Tianhao Chen, Ben Tang, and Xinchen Shi. 2020. Analyzing bug fix for automatic bug cause classification. JSS 163 (2020), 110538.\n\nDeep learning model for end-to-end approximation of COSMIC functional size based on use-case names. Miros\u0142aw Ochodek, Sylwia Kopczy\u0144ska, Miroslaw Staron, IST. 106310Miros\u0142aw Ochodek, Sylwia Kopczy\u0144ska, and Miroslaw Staron. 2020. Deep learning model for end-to-end approximation of COSMIC functional size based on use-case names. IST (2020), 106310.\n\nA deep learning approach to identifying source code in images and video. Jordan Ott, Abigail Atchison, Paul Harnack, Adrienne Bergh, Erik Linstead, MSR. IEEE. Jordan Ott, Abigail Atchison, Paul Harnack, Adrienne Bergh, and Erik Linstead. 2018. A deep learning approach to identifying source code in images and video. In MSR. IEEE, 376-386.\n\nReinforcement learning based curiosity-driven testing of Android applications. Minxue Pan, An Huang, Guoxin Wang, Tian Zhang, Xuandong Li, Minxue Pan, An Huang, Guoxin Wang, Tian Zhang, and Xuandong Li. 2020. Reinforcement learning based curiosity-driven testing of Android applications. In ISSTA. 153-164.\n\nCross-language clone detection by learning over abstract syntax trees. Daniel Perez, Shigeru Chiba, MSR. IEEE. Daniel Perez and Shigeru Chiba. 2019. Cross-language clone detection by learning over abstract syntax trees. In MSR. IEEE, 518-528.\n\nGuidelines for conducting systematic mapping studies in software engineering: An update. Kai Petersen, Sairam Vakkalanka, Ludwik Kuzniarz, IST. 64Kai Petersen, Sairam Vakkalanka, and Ludwik Kuzniarz. 2015. Guidelines for conducting systematic mapping studies in software engineering: An update. IST 64 (2015), 1-18.\n\nOn an optimal analogy-based software effort estimation. Passakorn Phannachitta, 2020106330Passakorn Phannachitta. 2020. On an optimal analogy-based software effort estimation. IST (2020), 106330.\n\nExtraction of system states from natural language requirements. Florian Pudlitz, Florian Brokhausen, Andreas Vogelsang, RE. IEEE. Florian Pudlitz, Florian Brokhausen, and Andreas Vogelsang. 2019. Extraction of system states from natural language requirements. In RE. IEEE, 211-222.\n\nNeural network for software reliability analysis of dynamically weighted NHPP growth models with imperfect debugging. Pooja Rani, Mahapatra, STVR. 281663Pooja Rani and GS Mahapatra. 2018. Neural network for software reliability analysis of dynamically weighted NHPP growth models with imperfect debugging. STVR 28, 5 (2018), e1663.\n\nNeural network-based detection of self-admitted technical debt: from performance to explainability. Xiaoxue Ren, Zhenchang Xing, Xin Xia, David Lo, Xinyu Wang, John Grundy, TOSEM. 28Xiaoxue Ren, Zhenchang Xing, Xin Xia, David Lo, Xinyu Wang, and John Grundy. 2019. Neural network-based detection of self-admitted technical debt: from performance to explainability. TOSEM 28, 3 (2019), 1-45.\n\nDeep green: Modelling time-series of software energy consumption. Stephen Romansky, C Neil, Shaiful Borle, Abram Chowdhury, Russ Hindle, Greiner, ICSME. IEEE. Stephen Romansky, Neil C Borle, Shaiful Chowdhury, Abram Hindle, and Russ Greiner. 2017. Deep green: Modelling time-series of software energy consumption. In ICSME. IEEE, 273-283.\n\nDeepLink: Recovering issue-commit links based on deep learning. Hang Ruan, Bihuan Chen, Xin Peng, Wenyun Zhao, JSS. 158110406Hang Ruan, Bihuan Chen, Xin Peng, and Wenyun Zhao. 2019. DeepLink: Recovering issue-commit links based on deep learning. JSS 158 (2019), 110406.\n\nSyntax and sensibility: Using language models to detect and correct syntax errors. Eddie Antonio Santos, Joshua Charles Campbell, Dhvani Patel, Abram Hindle, Jos\u00e9 Nelson Amaral, SANER. IEEE. Eddie Antonio Santos, Joshua Charles Campbell, Dhvani Patel, Abram Hindle, and Jos\u00e9 Nelson Amaral. 2018. Syntax and sensibility: Using language models to detect and correct syntax errors. In SANER. IEEE, 311-322.\n\nCORE: Automating Review Recommendation for Code Changes. Kai Jing, Cuiyun Siow, Lingling Gao, Sen Fan, Yang Chen, Liu, SANER. IEEE. Jing Kai Siow, Cuiyun Gao, Lingling Fan, Sen Chen, and Yang Liu. 2020. CORE: Automating Review Recommendation for Code Changes. In SANER. IEEE, 284-295.\n\nDropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research. Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov, 15Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research 15, 1 (2014), 1929-1958.\n\nFeature maps: A comprehensible software representation for design pattern detection. Hannes Thaller, Lukas Linsbauer, Alexander Egyed, SANER. IEEE. Hannes Thaller, Lukas Linsbauer, and Alexander Egyed. 2019. Feature maps: A comprehensible software representation for design pattern detection. In SANER. IEEE, 207-217.\n\nSoftware trustworthiness evaluation model based on a behaviour trajectory matrix. Junfeng Tian, Yuhui Guo, IST. 119106233Junfeng Tian and Yuhui Guo. 2020. Software trustworthiness evaluation model based on a behaviour trajectory matrix. IST 119 (2020), 106233.\n\nBVDetector: A program slice-based binary code vulnerability intelligent detection system. Junfeng Tian, Wenjing Xing, Zhen Li, IST. 123106289Junfeng Tian, Wenjing Xing, and Zhen Li. 2020. BVDetector: A program slice-based binary code vulnerability intelligent detection system. IST 123 (2020), 106289.\n\nSoftware defect prediction using stacked denoising autoencoders and two-stage ensemble learning. Haonan Tong, Bin Liu, Shihai Wang, IST. 96Haonan Tong, Bin Liu, and Shihai Wang. 2018. Software defect prediction using stacked denoising autoencoders and two-stage ensemble learning. IST 96 (2018), 94-111.\n\nDeep learning similarities from different representations of source code. Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin White, Denys Poshyvanyk, MSR. IEEE. Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin White, and Denys Poshyvanyk. 2018. Deep learning similarities from different representations of source code. In MSR. IEEE, 542-553.\n\nAn empirical study on learning bug-fixing patches in the wild via neural machine translation. Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin White, Denys Poshyvanyk, TOSEM. 28Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin White, and Denys Poshyvanyk. 2019. An empirical study on learning bug-fixing patches in the wild via neural machine translation. TOSEM 28, 4 (2019), 1-29.\n\nSupervised Representation Learning Approach for Cross-Project Aging-Related Bug Prediction. Xiaohui Wan, Zheng Zheng, Fangyun Qin, Yu Qiao, Kishor S Trivedi, ISSRE. IEEE. Xiaohui Wan, Zheng Zheng, Fangyun Qin, Yu Qiao, and Kishor S Trivedi. 2019. Supervised Representation Learning Approach for Cross-Project Aging-Related Bug Prediction. In ISSRE. IEEE, 163-172.\n\nMulti-modal attention network learning for semantic source code retrieval. Yao Wan, Jingdong Shu, Yulei Sui, Guandong Xu, Zhou Zhao, Jian Wu, Philip Yu, ASE. IEEEYao Wan, Jingdong Shu, Yulei Sui, Guandong Xu, Zhou Zhao, Jian Wu, and Philip Yu. 2019. Multi-modal attention network learning for semantic source code retrieval. In ASE. IEEE, 13-25.\n\nImproving automatic source code summarization via deep reinforcement learning. Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, Philip S Yu, ASE. Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and Philip S Yu. 2018. Improving automatic source code summarization via deep reinforcement learning. In ASE. 397-407.\n\nDeep semantic feature learning for software defect prediction. Song Wang, Taiyue Liu, Jaechang Nam, Lin Tan, TSESong Wang, Taiyue Liu, Jaechang Nam, and Lin Tan. 2018. Deep semantic feature learning for software defect prediction. TSE (2018).\n\nAutomatically learning semantic features for defect prediction. Song Wang, Taiyue Liu, Lin Tan, ICSE. IEEE. Song Wang, Taiyue Liu, and Lin Tan. 2016. Automatically learning semantic features for defect prediction. In ICSE. IEEE, 297-308.\n\nExtracting API tips from developer question and answer websites. Shaohua Wang, Nhathai Phan, Yan Wang, Yong Zhao, MSR. IEEE. Shaohua Wang, NhatHai Phan, Yan Wang, and Yong Zhao. 2019. Extracting API tips from developer question and answer websites. In MSR. IEEE, 321-332.\n\nDetecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree. Wenhan Wang, Ge Li, Bo Ma, Xin Xia, Zhi Jin, SANER. IEEE. Wenhan Wang, Ge Li, Bo Ma, Xin Xia, and Zhi Jin. 2020. Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree. In SANER. IEEE, 261-271.\n\nDomain-specific machine translation with recurrent neural network for software localization. Xu Wang, Chunyang Chen, Zhenchang Xing, ESE. 24Xu Wang, Chunyang Chen, and Zhenchang Xing. 2019. Domain-specific machine translation with recurrent neural network for software localization. ESE 24, 6 (2019), 3514-3545.\n\nTextout: Detecting Text-Layout Bugs in Mobile Apps via Visualization-Oriented Learning. Yaohui Wang, Hui Xu, Yangfan Zhou, Xin Michael R Lyu, Wang, ISSRE. IEEE. Yaohui Wang, Hui Xu, Yangfan Zhou, Michael R Lyu, and Xin Wang. 2019. Textout: Detecting Text-Layout Bugs in Mobile Apps via Visualization-Oriented Learning. In ISSRE. IEEE, 239-249.\n\nHow well do change sequences predict defects? sequence learning from software changes. Ming Wen, Rongxin Wu, Shing-Chi Cheung, TSEMing Wen, Rongxin Wu, and Shing-Chi Cheung. 2018. How well do change sequences predict defects? sequence learning from software changes. TSE (2018).\n\nSorting and transforming program repair ingredients via deep learning code similarities. Martin White, Michele Tufano, Matias Martinez, Martin Monperrus, Denys Poshyvanyk, SANER. IEEE. Martin White, Michele Tufano, Matias Martinez, Martin Monperrus, and Denys Poshyvanyk. 2019. Sorting and transforming program repair ingredients via deep learning code similarities. In SANER. IEEE, 479-490.\n\nDeep learning code fragments for code clone detection. Martin White, Michele Tufano, Christopher Vendome, Denys Poshyvanyk, ASE. IEEE. Martin White, Michele Tufano, Christopher Vendome, and Denys Poshyvanyk. 2016. Deep learning code fragments for code clone detection. In ASE. IEEE, 87-98.\n\nToward deep learning software repositories. Martin White, Christopher Vendome, Mario Linares-V\u00e1squez, Denys Poshyvanyk, MSR. IEEE. Martin White, Christopher Vendome, Mario Linares-V\u00e1squez, and Denys Poshyvanyk. 2015. Toward deep learning software repositories. In MSR. IEEE, 334-345.\n\nSoftware requirements. Pearson Education. Karl Wiegers, Joy Beatty, Karl Wiegers and Joy Beatty. 2013. Software requirements. Pearson Education.\n\nPredicting How to Test Requirements: An Automated Approach. Jonas Paul Winkler, Jannis Gr\u00f6nberg, and Andreas Vogelsang. RE. IEEEJonas Paul Winkler, Jannis Gr\u00f6nberg, and Andreas Vogelsang. 2019. Predicting How to Test Requirements: An Automated Approach. In RE. IEEE, 120-130.\n\nImproving bug localization with word embedding and enhanced convolutional neural networks. Yan Xiao, Jacky Keung, E Kwabena, Qing Bennin, Mi, IST. 105Yan Xiao, Jacky Keung, Kwabena E Bennin, and Qing Mi. 2019. Improving bug localization with word embedding and enhanced convolutional neural networks. IST 105 (2019), 17-29.\n\nDeepLink: A code knowledge graph based deep learning approach for issue-commit link recovery. Rui Xie, Long Chen, Wei Ye, Zhiyu Li, Tianxiang Hu, Dongdong Du, Shikun Zhang, SANER. IEEE. Rui Xie, Long Chen, Wei Ye, Zhiyu Li, Tianxiang Hu, Dongdong Du, and Shikun Zhang. 2019. DeepLink: A code knowledge graph based deep learning approach for issue-commit link recovery. In SANER. IEEE, 434-444.\n\nPrediction of relatedness in stack overflow: deep learning vs. SVM: a reproducibility study. Bowen Xu, Amirreza Shirani, David Lo, Mohammad Amin Alipour, ESEM. Bowen Xu, Amirreza Shirani, David Lo, and Mohammad Amin Alipour. 2018. Prediction of relatedness in stack overflow: deep learning vs. SVM: a reproducibility study. In ESEM. 1-10.\n\nPredicting semantically linkable knowledge in developer online forums via convolutional neural network. Bowen Xu, Deheng Ye, Zhenchang Xing, Xin Xia, Guibin Chen, Shanping Li, ASE. IEEE. Bowen Xu, Deheng Ye, Zhenchang Xing, Xin Xia, Guibin Chen, and Shanping Li. 2016. Predicting semantically linkable knowledge in developer online forums via convolutional neural network. In ASE. IEEE, 51-62.\n\nLDFR: Learning deep feature representation for software defect prediction. Zhou Xu, Shuai Li, Jun Xu, Jin Liu, Xiapu Luo, Yifeng Zhang, Tao Zhang, Jacky Keung, Yutian Tang, JSS. 158110402Zhou Xu, Shuai Li, Jun Xu, Jin Liu, Xiapu Luo, Yifeng Zhang, Tao Zhang, Jacky Keung, and Yutian Tang. 2019. LDFR: Learning deep feature representation for software defect prediction. JSS 158 (2019), 110402.\n\nLearning to mine aligned code and natural language pairs from stack overflow. Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu, Graham Neubig, MSR. IEEE. Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu, and Graham Neubig. 2018. Learning to mine aligned code and natural language pairs from stack overflow. In MSR. IEEE, 476-486.\n\nNeural detection of semantic code clones via tree-based convolution. Hao Yu, Wing Lam, Long Chen, Ge Li, Tao Xie, Qianxiang Wang, ICPC. IEEE. Hao Yu, Wing Lam, Long Chen, Ge Li, Tao Xie, and Qianxiang Wang. 2019. Neural detection of semantic code clones via tree-based convolution. In ICPC. IEEE, 70-80.\n\nAutomatically learning patterns for self-admitted technical debt removal. Fiorella Zampetti, Alexander Serebrenik, Massimiliano Di Penta, SANER. IEEE. Fiorella Zampetti, Alexander Serebrenik, and Massimiliano Di Penta. 2020. Automatically learning patterns for self-admitted technical debt removal. In SANER. IEEE, 355-366.\n\nA novel neural source code representation based on abstract syntax tree. Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Kaixuan Wang, Xudong Liu, ICSE. IEEE. Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Kaixuan Wang, and Xudong Liu. 2019. A novel neural source code representation based on abstract syntax tree. In ICSE. IEEE, 783-794.\n\nAn empirical study of common challenges in developing deep learning applications. Tianyi Zhang, Cuiyun Gao, Lei Ma, Michael Lyu, Miryung Kim, ISSRE. IEEE. Tianyi Zhang, Cuiyun Gao, Lei Ma, Michael Lyu, and Miryung Kim. 2019. An empirical study of common challenges in developing deep learning applications. In ISSRE. IEEE, 104-115.\n\nCNN-FL: An effective approach for localizing faults using convolutional neural networks. Zhuo Zhang, Yan Lei, Xiaoguang Mao, Panpan Li, SANER. IEEE. Zhuo Zhang, Yan Lei, Xiaoguang Mao, and Panpan Li. 2019. CNN-FL: An effective approach for localizing faults using convolutional neural networks. In SANER. IEEE, 445-455.\n\nActionNet: vision-based workflow action recognition from programming screencasts. Dehai Zhao, Zhenchang Xing, Chunyang Chen, Xin Xia, Guoqiang Li, ICSE. IEEE. Dehai Zhao, Zhenchang Xing, Chunyang Chen, Xin Xia, and Guoqiang Li. 2019. ActionNet: vision-based workflow action recognition from programming screencasts. In ICSE. IEEE, 350-361.\n\nDeepsim: deep learning code functional similarity. Gang Zhao, Jeff Huang, FSE. Gang Zhao and Jeff Huang. 2018. Deepsim: deep learning code functional similarity. In FSE. 141-151.\n\nSeqFuzzer: An industrial protocol fuzzing framework from a deep learning perspective. Hui Zhao, Zhihui Li, Hansheng Wei, Jianqi Shi, Yanhong Huang, ICST. IEEE. Hui Zhao, Zhihui Li, Hansheng Wei, Jianqi Shi, and Yanhong Huang. 2019. SeqFuzzer: An industrial protocol fuzzing framework from a deep learning perspective. In ICST. IEEE, 59-67.\n\nNeural-augmented static analysis of Android communication. Jinman Zhao, Aws Albarghouthi, Vaibhav Rastogi, Somesh Jha, Damien Octeau, Jinman Zhao, Aws Albarghouthi, Vaibhav Rastogi, Somesh Jha, and Damien Octeau. 2018. Neural-augmented static analysis of Android communication. In FSE. 342-353.\n\nWuji: Automatic online combat game testing using evolutionary deep reinforcement learning. Yan Zheng, Xiaofei Xie, Ting Su, Lei Ma, Jianye Hao, Zhaopeng Meng, Yang Liu, Ruimin Shen, Yingfeng Chen, Changjie Fan, ASE. IEEEYan Zheng, Xiaofei Xie, Ting Su, Lei Ma, Jianye Hao, Zhaopeng Meng, Yang Liu, Ruimin Shen, Yingfeng Chen, and Changjie Fan. 2019. Wuji: Automatic online combat game testing using evolutionary deep reinforcement learning. In ASE. IEEE, 772-784.\n\nImproving software bug-specific named entity recognition with deep neural network. Cheng Zhou, Bin Li, Xiaobing Sun, JSS. 110572Cheng Zhou, Bin Li, and Xiaobing Sun. 2020. Improving software bug-specific named entity recognition with deep neural network. JSS (2020), 110572.\n\nIs deep learning better than traditional approaches in tag recommendation for software information sites. Pingyi Zhou, Jin Liu, Xiao Liu, Zijiang Yang, John Grundy, IST. 109Pingyi Zhou, Jin Liu, Xiao Liu, Zijiang Yang, and John Grundy. 2019. Is deep learning better than traditional approaches in tag recommendation for software information sites? IST 109 (2019), 1-13.\n\nImproving defect prediction with deep forest. Tianchi Zhou, Xiaobing Sun, Xin Xia, Bin Li, Xiang Chen, IST. 114Tianchi Zhou, Xiaobing Sun, Xin Xia, Bin Li, and Xiang Chen. 2019. Improving defect prediction with deep forest. IST 114 (2019), 204-216.\n\nAugmenting Java method comments generation with context information based on neural networks. Yu Zhou, Xin Yan, Wenhua Yang, Taolue Chen, Zhiqiu Huang, JSS. 156Yu Zhou, Xin Yan, Wenhua Yang, Taolue Chen, and Zhiqiu Huang. 2019. Augmenting Java method comments generation with context information based on neural networks. JSS 156 (2019), 328-340.\n", "annotations": {"author": "[{\"end\":79,\"start\":66},{\"end\":89,\"start\":80},{\"end\":103,\"start\":90},{\"end\":112,\"start\":104},{\"end\":122,\"start\":113},{\"end\":135,\"start\":123},{\"end\":241,\"start\":136},{\"end\":312,\"start\":242},{\"end\":392,\"start\":313},{\"end\":422,\"start\":393}]", "publisher": null, "author_last_name": "[{\"end\":78,\"start\":74},{\"end\":88,\"start\":86},{\"end\":102,\"start\":98},{\"end\":111,\"start\":108},{\"end\":121,\"start\":119},{\"end\":134,\"start\":128}]", "author_first_name": "[{\"end\":73,\"start\":66},{\"end\":85,\"start\":80},{\"end\":97,\"start\":90},{\"end\":107,\"start\":104},{\"end\":118,\"start\":113},{\"end\":127,\"start\":123}]", "author_affiliation": "[{\"end\":240,\"start\":137},{\"end\":311,\"start\":243},{\"end\":391,\"start\":314},{\"end\":421,\"start\":394}]", "title": "[{\"end\":51,\"start\":1},{\"end\":473,\"start\":423}]", "venue": "[{\"end\":564,\"start\":475}]", "abstract": "[{\"end\":9395,\"start\":737}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b84\"},\"end\":9584,\"start\":9580},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":9683,\"start\":9679},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":10026,\"start\":10022},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":10520,\"start\":10517},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":10803,\"start\":10800},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11110,\"start\":11107},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":14913,\"start\":14909},{\"attributes\":{\"ref_id\":\"b98\"},\"end\":14938,\"start\":14934},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":15961,\"start\":15957},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":15964,\"start\":15961},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":15967,\"start\":15964},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16012,\"start\":16008},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":16033,\"start\":16029},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21108,\"start\":21104},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":21130,\"start\":21126},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":21300,\"start\":21296},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":24548,\"start\":24544},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":25539,\"start\":25535},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":25570,\"start\":25566},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":26858,\"start\":26854},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":26861,\"start\":26858},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":26864,\"start\":26861},{\"attributes\":{\"ref_id\":\"b145\"},\"end\":26868,\"start\":26864},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27188,\"start\":27184},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":27191,\"start\":27188},{\"attributes\":{\"ref_id\":\"b137\"},\"end\":27195,\"start\":27191},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":27720,\"start\":27717},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":27723,\"start\":27720},{\"attributes\":{\"ref_id\":\"b110\"},\"end\":27727,\"start\":27723},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":28421,\"start\":28417},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":30355,\"start\":30351},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":31594,\"start\":31591},{\"end\":34128,\"start\":34123},{\"end\":34206,\"start\":34202},{\"end\":34247,\"start\":34242},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":35288,\"start\":35284},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":35612,\"start\":35608},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":37446,\"start\":37444},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":37494,\"start\":37490},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":38055,\"start\":38051},{\"attributes\":{\"ref_id\":\"b107\"},\"end\":38059,\"start\":38055},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":41423,\"start\":41419},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":46173,\"start\":46170},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":46755,\"start\":46752},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":48729,\"start\":48726},{\"attributes\":{\"ref_id\":\"b127\"},\"end\":49616,\"start\":49611},{\"attributes\":{\"ref_id\":\"b100\"},\"end\":49867,\"start\":49862},{\"attributes\":{\"ref_id\":\"b128\"},\"end\":50366,\"start\":50361},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":51066,\"start\":51062},{\"attributes\":{\"ref_id\":\"b108\"},\"end\":51535,\"start\":51530},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":52194,\"start\":52190},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":52592,\"start\":52588},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":53184,\"start\":53180},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":53690,\"start\":53686},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":54262,\"start\":54259},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":54286,\"start\":54282},{\"attributes\":{\"ref_id\":\"b115\"},\"end\":54967,\"start\":54962},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":55498,\"start\":55494},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":55814,\"start\":55810},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":56195,\"start\":56192},{\"attributes\":{\"ref_id\":\"b121\"},\"end\":56503,\"start\":56498},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":56758,\"start\":56754},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":57288,\"start\":57285},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":57291,\"start\":57288},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":57294,\"start\":57291},{\"attributes\":{\"ref_id\":\"b111\"},\"end\":57298,\"start\":57294},{\"attributes\":{\"ref_id\":\"b123\"},\"end\":57302,\"start\":57298},{\"attributes\":{\"ref_id\":\"b133\"},\"end\":57306,\"start\":57302},{\"attributes\":{\"ref_id\":\"b147\"},\"end\":57310,\"start\":57306},{\"attributes\":{\"ref_id\":\"b111\"},\"end\":57574,\"start\":57569},{\"attributes\":{\"ref_id\":\"b133\"},\"end\":58063,\"start\":58058},{\"attributes\":{\"ref_id\":\"b123\"},\"end\":58442,\"start\":58437},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":58880,\"start\":58876},{\"end\":59056,\"start\":59039},{\"attributes\":{\"ref_id\":\"b117\"},\"end\":59313,\"start\":59308},{\"attributes\":{\"ref_id\":\"b118\"},\"end\":59317,\"start\":59313},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":59912,\"start\":59908},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":60114,\"start\":60110},{\"attributes\":{\"ref_id\":\"b114\"},\"end\":60570,\"start\":60565},{\"attributes\":{\"ref_id\":\"b122\"},\"end\":60865,\"start\":60860},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":61490,\"start\":61486},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":61824,\"start\":61820},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":61987,\"start\":61983},{\"attributes\":{\"ref_id\":\"b110\"},\"end\":62322,\"start\":62317},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":62504,\"start\":62500},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":62875,\"start\":62871},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":63138,\"start\":63134},{\"attributes\":{\"ref_id\":\"b129\"},\"end\":63142,\"start\":63138},{\"attributes\":{\"ref_id\":\"b139\"},\"end\":63146,\"start\":63142},{\"attributes\":{\"ref_id\":\"b139\"},\"end\":63166,\"start\":63161},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":63392,\"start\":63388},{\"attributes\":{\"ref_id\":\"b129\"},\"end\":63585,\"start\":63580},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":63831,\"start\":63827},{\"attributes\":{\"ref_id\":\"b105\"},\"end\":64227,\"start\":64222},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":64539,\"start\":64535},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":64698,\"start\":64694},{\"attributes\":{\"ref_id\":\"b142\"},\"end\":64974,\"start\":64969},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":65256,\"start\":65252},{\"attributes\":{\"ref_id\":\"b143\"},\"end\":66030,\"start\":66025},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":66313,\"start\":66309},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":66551,\"start\":66547},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":66887,\"start\":66883},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":67193,\"start\":67189},{\"attributes\":{\"ref_id\":\"b96\"},\"end\":67619,\"start\":67615},{\"attributes\":{\"ref_id\":\"b144\"},\"end\":67632,\"start\":67627},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":67664,\"start\":67661},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":67667,\"start\":67664},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":67752,\"start\":67748},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":67755,\"start\":67752},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":67781,\"start\":67777},{\"attributes\":{\"ref_id\":\"b144\"},\"end\":67850,\"start\":67845},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":68023,\"start\":68020},{\"attributes\":{\"ref_id\":\"b96\"},\"end\":68210,\"start\":68206},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":68387,\"start\":68383},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":68685,\"start\":68681},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":68826,\"start\":68822},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":69401,\"start\":69397},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":69927,\"start\":69923},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":70292,\"start\":70288},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":70803,\"start\":70799},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":70806,\"start\":70803},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":70809,\"start\":70806},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":70812,\"start\":70809},{\"attributes\":{\"ref_id\":\"b103\"},\"end\":70816,\"start\":70812},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":71074,\"start\":71070},{\"attributes\":{\"ref_id\":\"b125\"},\"end\":71086,\"start\":71081},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":71100,\"start\":71097},{\"attributes\":{\"ref_id\":\"b97\"},\"end\":71103,\"start\":71100},{\"attributes\":{\"ref_id\":\"b112\"},\"end\":71107,\"start\":71103},{\"attributes\":{\"ref_id\":\"b125\"},\"end\":71161,\"start\":71156},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":71447,\"start\":71443},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":71694,\"start\":71691},{\"attributes\":{\"ref_id\":\"b97\"},\"end\":71831,\"start\":71827},{\"attributes\":{\"ref_id\":\"b112\"},\"end\":72146,\"start\":72141},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":72374,\"start\":72370},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":72377,\"start\":72374},{\"attributes\":{\"ref_id\":\"b141\"},\"end\":72381,\"start\":72377},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":72397,\"start\":72393},{\"attributes\":{\"ref_id\":\"b141\"},\"end\":72648,\"start\":72643},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":72899,\"start\":72895},{\"attributes\":{\"ref_id\":\"b135\"},\"end\":73291,\"start\":73286},{\"attributes\":{\"ref_id\":\"b120\"},\"end\":73595,\"start\":73590},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":74120,\"start\":74116},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":74493,\"start\":74489},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":74896,\"start\":74892},{\"attributes\":{\"ref_id\":\"b148\"},\"end\":74988,\"start\":74983},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":75164,\"start\":75160},{\"attributes\":{\"ref_id\":\"b116\"},\"end\":75380,\"start\":75375},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":75885,\"start\":75882},{\"attributes\":{\"ref_id\":\"b113\"},\"end\":76369,\"start\":76364},{\"attributes\":{\"ref_id\":\"b124\"},\"end\":76665,\"start\":76660},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":76947,\"start\":76943},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":77261,\"start\":77257},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":77400,\"start\":77396},{\"attributes\":{\"ref_id\":\"b126\"},\"end\":78002,\"start\":77997},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":78926,\"start\":78922},{\"attributes\":{\"ref_id\":\"b137\"},\"end\":79600,\"start\":79595},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":80081,\"start\":80077},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":80672,\"start\":80668},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":81292,\"start\":81288},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":81456,\"start\":81452},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":81776,\"start\":81772},{\"attributes\":{\"ref_id\":\"b102\"},\"end\":82360,\"start\":82355},{\"attributes\":{\"ref_id\":\"b136\"},\"end\":82664,\"start\":82659},{\"attributes\":{\"ref_id\":\"b106\"},\"end\":83062,\"start\":83057},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":83408,\"start\":83404},{\"attributes\":{\"ref_id\":\"b101\"},\"end\":83937,\"start\":83932},{\"attributes\":{\"ref_id\":\"b109\"},\"end\":84163,\"start\":84158},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":84540,\"start\":84536},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":84903,\"start\":84899},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":85473,\"start\":85470},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":85476,\"start\":85473},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":85611,\"start\":85607},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":85811,\"start\":85807},{\"attributes\":{\"ref_id\":\"b99\"},\"end\":86076,\"start\":86072},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":86263,\"start\":86259},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":86734,\"start\":86730},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":86737,\"start\":86734},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":86740,\"start\":86737},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":86839,\"start\":86835},{\"attributes\":{\"ref_id\":\"b146\"},\"end\":86843,\"start\":86839},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":86856,\"start\":86852},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":86874,\"start\":86870},{\"attributes\":{\"ref_id\":\"b131\"},\"end\":87176,\"start\":87171},{\"attributes\":{\"ref_id\":\"b132\"},\"end\":87180,\"start\":87176},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":87549,\"start\":87545},{\"attributes\":{\"ref_id\":\"b134\"},\"end\":87904,\"start\":87899},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":88158,\"start\":88154},{\"attributes\":{\"ref_id\":\"b138\"},\"end\":88474,\"start\":88469},{\"attributes\":{\"ref_id\":\"b119\"},\"end\":88909,\"start\":88904},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":89394,\"start\":89390},{\"attributes\":{\"ref_id\":\"b130\"},\"end\":89899,\"start\":89894},{\"attributes\":{\"ref_id\":\"b104\"},\"end\":90251,\"start\":90246},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":90673,\"start\":90669},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":91021,\"start\":91017},{\"attributes\":{\"ref_id\":\"b140\"},\"end\":91331,\"start\":91326}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":99527,\"start\":99471},{\"attributes\":{\"id\":\"fig_1\"},\"end\":100191,\"start\":99528},{\"attributes\":{\"id\":\"fig_2\"},\"end\":100219,\"start\":100192},{\"attributes\":{\"id\":\"fig_3\"},\"end\":100254,\"start\":100220},{\"attributes\":{\"id\":\"fig_4\"},\"end\":100319,\"start\":100255},{\"attributes\":{\"id\":\"fig_5\"},\"end\":100378,\"start\":100320},{\"attributes\":{\"id\":\"fig_6\"},\"end\":100435,\"start\":100379},{\"attributes\":{\"id\":\"fig_7\"},\"end\":100665,\"start\":100436},{\"attributes\":{\"id\":\"fig_8\"},\"end\":101181,\"start\":100666},{\"attributes\":{\"id\":\"fig_9\"},\"end\":101244,\"start\":101182},{\"attributes\":{\"id\":\"fig_10\"},\"end\":101312,\"start\":101245},{\"attributes\":{\"id\":\"fig_11\"},\"end\":101398,\"start\":101313},{\"attributes\":{\"id\":\"fig_12\"},\"end\":101471,\"start\":101399},{\"attributes\":{\"id\":\"fig_13\"},\"end\":101521,\"start\":101472},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":103151,\"start\":101522},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":103965,\"start\":103152},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":104359,\"start\":103966},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":105434,\"start\":104360},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":106208,\"start\":105435},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":106651,\"start\":106209},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":107332,\"start\":106652}]", "paragraph": "[{\"end\":11503,\"start\":9411},{\"end\":12598,\"start\":11505},{\"end\":13480,\"start\":12600},{\"end\":14038,\"start\":13482},{\"end\":14425,\"start\":14040},{\"end\":14809,\"start\":14427},{\"end\":14999,\"start\":14825},{\"end\":15274,\"start\":15022},{\"end\":15351,\"start\":15276},{\"end\":15420,\"start\":15353},{\"end\":15799,\"start\":15456},{\"end\":16683,\"start\":15801},{\"end\":17104,\"start\":16720},{\"end\":17403,\"start\":17106},{\"end\":18135,\"start\":17438},{\"end\":18413,\"start\":18207},{\"end\":19179,\"start\":18460},{\"end\":19230,\"start\":19181},{\"end\":19640,\"start\":19232},{\"end\":20391,\"start\":19642},{\"end\":22401,\"start\":20430},{\"end\":22946,\"start\":22433},{\"end\":23110,\"start\":22979},{\"end\":23192,\"start\":23112},{\"end\":23343,\"start\":23212},{\"end\":23431,\"start\":23358},{\"end\":23588,\"start\":23446},{\"end\":24238,\"start\":23590},{\"end\":24472,\"start\":24250},{\"end\":26347,\"start\":24474},{\"end\":26667,\"start\":26383},{\"end\":27008,\"start\":26669},{\"end\":27359,\"start\":27010},{\"end\":27728,\"start\":27361},{\"end\":27963,\"start\":27730},{\"end\":28044,\"start\":27975},{\"end\":28748,\"start\":28046},{\"end\":29077,\"start\":28825},{\"end\":30652,\"start\":29131},{\"end\":31085,\"start\":30654},{\"end\":31900,\"start\":31087},{\"end\":32203,\"start\":31902},{\"end\":32918,\"start\":32205},{\"end\":33331,\"start\":32990},{\"end\":33668,\"start\":33333},{\"end\":34007,\"start\":33670},{\"end\":34275,\"start\":34045},{\"end\":34400,\"start\":34277},{\"end\":34691,\"start\":34402},{\"end\":35046,\"start\":34693},{\"end\":36307,\"start\":35048},{\"end\":36888,\"start\":36385},{\"end\":37580,\"start\":36890},{\"end\":38754,\"start\":37582},{\"end\":39340,\"start\":38756},{\"end\":39630,\"start\":39342},{\"end\":39853,\"start\":39632},{\"end\":40318,\"start\":39855},{\"end\":40563,\"start\":40320},{\"end\":40888,\"start\":40565},{\"end\":42452,\"start\":40890},{\"end\":43867,\"start\":42454},{\"end\":44799,\"start\":43929},{\"end\":46520,\"start\":44811},{\"end\":47178,\"start\":46618},{\"end\":48359,\"start\":47239},{\"end\":49372,\"start\":48361},{\"end\":50120,\"start\":49398},{\"end\":50818,\"start\":50148},{\"end\":52160,\"start\":50838},{\"end\":53123,\"start\":52178},{\"end\":54091,\"start\":53151},{\"end\":55782,\"start\":54093},{\"end\":57311,\"start\":55799},{\"end\":59260,\"start\":57313},{\"end\":60057,\"start\":59262},{\"end\":60535,\"start\":60059},{\"end\":61943,\"start\":60554},{\"end\":62815,\"start\":61972},{\"end\":65736,\"start\":62837},{\"end\":66847,\"start\":65738},{\"end\":69277,\"start\":66849},{\"end\":70610,\"start\":69300},{\"end\":70999,\"start\":70635},{\"end\":72276,\"start\":71001},{\"end\":73232,\"start\":72278},{\"end\":78905,\"start\":73234},{\"end\":83811,\"start\":78907},{\"end\":83938,\"start\":83813},{\"end\":84511,\"start\":83940},{\"end\":84867,\"start\":84513},{\"end\":86875,\"start\":84869},{\"end\":89360,\"start\":86877},{\"end\":90988,\"start\":89362},{\"end\":91619,\"start\":90990},{\"end\":91948,\"start\":91631},{\"end\":92437,\"start\":91950},{\"end\":93850,\"start\":92453},{\"end\":95523,\"start\":93883},{\"end\":97375,\"start\":95525},{\"end\":98121,\"start\":97377},{\"end\":99470,\"start\":98136}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":16051,\"start\":16044},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":17602,\"start\":17595},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":20617,\"start\":20610},{\"end\":22732,\"start\":22725},{\"end\":22883,\"start\":22876},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":25083,\"start\":25076},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":25221,\"start\":25214},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":31239,\"start\":31232},{\"end\":33934,\"start\":33927},{\"end\":35429,\"start\":35422},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":42732,\"start\":42725},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":43194,\"start\":43187},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":48432,\"start\":48425}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":9409,\"start\":9397},{\"attributes\":{\"n\":\"3\"},\"end\":14823,\"start\":14812},{\"attributes\":{\"n\":\"3.1\"},\"end\":15020,\"start\":15002},{\"attributes\":{\"n\":\"3.2\"},\"end\":15454,\"start\":15423},{\"attributes\":{\"n\":\"3.3\"},\"end\":16718,\"start\":16686},{\"attributes\":{\"n\":\"3.4\"},\"end\":17436,\"start\":17406},{\"attributes\":{\"n\":\"4\"},\"end\":18205,\"start\":18138},{\"attributes\":{\"n\":\"4.1\"},\"end\":18458,\"start\":18416},{\"attributes\":{\"n\":\"4.2\"},\"end\":20428,\"start\":20394},{\"attributes\":{\"n\":\"4.3\"},\"end\":22431,\"start\":22404},{\"end\":22977,\"start\":22949},{\"end\":23210,\"start\":23195},{\"end\":23356,\"start\":23346},{\"end\":23444,\"start\":23434},{\"end\":24248,\"start\":24241},{\"attributes\":{\"n\":\"5.2\"},\"end\":26381,\"start\":26350},{\"end\":27973,\"start\":27966},{\"attributes\":{\"n\":\"6\"},\"end\":28823,\"start\":28751},{\"attributes\":{\"n\":\"6.1\"},\"end\":29129,\"start\":29080},{\"attributes\":{\"n\":\"6.1.3\"},\"end\":32988,\"start\":32921},{\"end\":34043,\"start\":34010},{\"attributes\":{\"n\":\"6.2\"},\"end\":36383,\"start\":36310},{\"attributes\":{\"n\":\"6.3\"},\"end\":43927,\"start\":43870},{\"end\":44809,\"start\":44802},{\"attributes\":{\"n\":\"7\"},\"end\":46616,\"start\":46523},{\"attributes\":{\"n\":\"7.1\"},\"end\":47237,\"start\":47181},{\"attributes\":{\"n\":\"7.2\"},\"end\":49396,\"start\":49375},{\"attributes\":{\"n\":\"7.2.2\"},\"end\":50146,\"start\":50123},{\"attributes\":{\"n\":\"7.3\"},\"end\":50836,\"start\":50821},{\"attributes\":{\"n\":\"7.3.2\"},\"end\":52176,\"start\":52163},{\"attributes\":{\"n\":\"7.4\"},\"end\":53149,\"start\":53126},{\"attributes\":{\"n\":\"7.4.2\"},\"end\":55797,\"start\":55785},{\"attributes\":{\"n\":\"7.5.2\"},\"end\":60552,\"start\":60538},{\"attributes\":{\"n\":\"7.5.3\"},\"end\":61970,\"start\":61946},{\"attributes\":{\"n\":\"7.5.4\"},\"end\":62835,\"start\":62818},{\"attributes\":{\"n\":\"7.5.8\"},\"end\":69298,\"start\":69280},{\"attributes\":{\"n\":\"7.6\"},\"end\":70633,\"start\":70613},{\"end\":91629,\"start\":91622},{\"attributes\":{\"n\":\"8\"},\"end\":92451,\"start\":92440},{\"attributes\":{\"n\":\"9\"},\"end\":93881,\"start\":93853},{\"attributes\":{\"n\":\"10\"},\"end\":98134,\"start\":98124},{\"end\":99480,\"start\":99472},{\"end\":99534,\"start\":99529},{\"end\":100264,\"start\":100256},{\"end\":100388,\"start\":100380},{\"end\":100442,\"start\":100437},{\"end\":100673,\"start\":100667},{\"end\":101191,\"start\":101183},{\"end\":101254,\"start\":101246},{\"end\":101322,\"start\":101314},{\"end\":101408,\"start\":101400},{\"end\":101481,\"start\":101473},{\"end\":101532,\"start\":101523},{\"end\":103162,\"start\":103153},{\"end\":103976,\"start\":103967},{\"end\":104370,\"start\":104361},{\"end\":105445,\"start\":105436},{\"end\":106219,\"start\":106210},{\"end\":106662,\"start\":106653}]", "table": "[{\"end\":103151,\"start\":101663},{\"end\":103965,\"start\":103202},{\"end\":104359,\"start\":104019},{\"end\":105434,\"start\":104419},{\"end\":106208,\"start\":105498},{\"end\":106651,\"start\":106249},{\"end\":107332,\"start\":106731}]", "figure_caption": "[{\"end\":99527,\"start\":99482},{\"end\":100191,\"start\":99536},{\"end\":100219,\"start\":100194},{\"end\":100254,\"start\":100222},{\"end\":100319,\"start\":100266},{\"end\":100378,\"start\":100322},{\"end\":100435,\"start\":100390},{\"end\":100665,\"start\":100444},{\"end\":101181,\"start\":100675},{\"end\":101244,\"start\":101193},{\"end\":101312,\"start\":101256},{\"end\":101398,\"start\":101324},{\"end\":101471,\"start\":101410},{\"end\":101521,\"start\":101483},{\"end\":101663,\"start\":101534},{\"end\":103202,\"start\":103164},{\"end\":104019,\"start\":103978},{\"end\":104419,\"start\":104372},{\"end\":105498,\"start\":105447},{\"end\":106249,\"start\":106221},{\"end\":106731,\"start\":106664}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18781,\"start\":18775},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":19731,\"start\":19725},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20198,\"start\":20192},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":21617,\"start\":21601},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":21982,\"start\":21976},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":30000,\"start\":29994},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":37071,\"start\":37065},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":41191,\"start\":41185},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":47355,\"start\":47349},{\"attributes\":{\"ref_id\":\"fig_13\"},\"end\":47901,\"start\":47895}]", "bib_author_first_name": "[{\"end\":107597,\"start\":107593},{\"end\":107612,\"start\":107608},{\"end\":107630,\"start\":107625},{\"end\":107884,\"start\":107876},{\"end\":107905,\"start\":107895},{\"end\":107920,\"start\":107914},{\"end\":107939,\"start\":107931},{\"end\":107953,\"start\":107948},{\"end\":107968,\"start\":107962},{\"end\":108249,\"start\":108241},{\"end\":108264,\"start\":108255},{\"end\":108274,\"start\":108271},{\"end\":108285,\"start\":108280},{\"end\":108297,\"start\":108290},{\"end\":108308,\"start\":108302},{\"end\":108563,\"start\":108556},{\"end\":108578,\"start\":108572},{\"end\":108595,\"start\":108586},{\"end\":108859,\"start\":108855},{\"end\":108881,\"start\":108876},{\"end\":108891,\"start\":108890},{\"end\":108906,\"start\":108900},{\"end\":109196,\"start\":109191},{\"end\":109213,\"start\":109205},{\"end\":109228,\"start\":109221},{\"end\":109483,\"start\":109474},{\"end\":109502,\"start\":109490},{\"end\":109748,\"start\":109742},{\"end\":109765,\"start\":109758},{\"end\":109767,\"start\":109766},{\"end\":110053,\"start\":110049},{\"end\":110065,\"start\":110060},{\"end\":110280,\"start\":110276},{\"end\":110299,\"start\":110293},{\"end\":110311,\"start\":110304},{\"end\":110324,\"start\":110317},{\"end\":110336,\"start\":110330},{\"end\":110595,\"start\":110591},{\"end\":110608,\"start\":110602},{\"end\":110622,\"start\":110615},{\"end\":110637,\"start\":110629},{\"end\":110650,\"start\":110643},{\"end\":110986,\"start\":110978},{\"end\":110997,\"start\":110993},{\"end\":111008,\"start\":111002},{\"end\":111024,\"start\":111015},{\"end\":111035,\"start\":111031},{\"end\":111337,\"start\":111331},{\"end\":111352,\"start\":111344},{\"end\":111368,\"start\":111359},{\"end\":111380,\"start\":111375},{\"end\":111643,\"start\":111636},{\"end\":111658,\"start\":111650},{\"end\":111674,\"start\":111665},{\"end\":111684,\"start\":111681},{\"end\":111696,\"start\":111690},{\"end\":111706,\"start\":111702},{\"end\":111722,\"start\":111715},{\"end\":111986,\"start\":111979},{\"end\":112006,\"start\":112003},{\"end\":112012,\"start\":112007},{\"end\":112024,\"start\":112018},{\"end\":112036,\"start\":112031},{\"end\":112049,\"start\":112043},{\"end\":112060,\"start\":112057},{\"end\":112336,\"start\":112329},{\"end\":112358,\"start\":112349},{\"end\":112374,\"start\":112368},{\"end\":112376,\"start\":112375},{\"end\":112603,\"start\":112598},{\"end\":112619,\"start\":112613},{\"end\":112640,\"start\":112632},{\"end\":112653,\"start\":112649},{\"end\":112902,\"start\":112899},{\"end\":112919,\"start\":112914},{\"end\":112943,\"start\":112937},{\"end\":112952,\"start\":112948},{\"end\":112965,\"start\":112959},{\"end\":112980,\"start\":112974},{\"end\":112996,\"start\":112988},{\"end\":113327,\"start\":113324},{\"end\":113345,\"start\":113339},{\"end\":113357,\"start\":113352},{\"end\":113361,\"start\":113358},{\"end\":113368,\"start\":113364},{\"end\":113380,\"start\":113375},{\"end\":113384,\"start\":113381},{\"end\":113393,\"start\":113389},{\"end\":113408,\"start\":113402},{\"end\":113692,\"start\":113690},{\"end\":114004,\"start\":113998},{\"end\":114021,\"start\":114015},{\"end\":114042,\"start\":114032},{\"end\":114058,\"start\":114051},{\"end\":114364,\"start\":114363},{\"end\":114366,\"start\":114365},{\"end\":114382,\"start\":114377},{\"end\":114395,\"start\":114387},{\"end\":114636,\"start\":114631},{\"end\":114649,\"start\":114644},{\"end\":114871,\"start\":114866},{\"end\":114888,\"start\":114882},{\"end\":114907,\"start\":114901},{\"end\":114923,\"start\":114917},{\"end\":114939,\"start\":114931},{\"end\":115237,\"start\":115229},{\"end\":115248,\"start\":115244},{\"end\":115262,\"start\":115254},{\"end\":115272,\"start\":115268},{\"end\":115287,\"start\":115280},{\"end\":115535,\"start\":115533},{\"end\":115549,\"start\":115541},{\"end\":115565,\"start\":115556},{\"end\":115577,\"start\":115572},{\"end\":115585,\"start\":115582},{\"end\":115601,\"start\":115592},{\"end\":115862,\"start\":115860},{\"end\":115871,\"start\":115868},{\"end\":115884,\"start\":115878},{\"end\":115893,\"start\":115890},{\"end\":115903,\"start\":115900},{\"end\":115918,\"start\":115910},{\"end\":116194,\"start\":116187},{\"end\":116202,\"start\":116201},{\"end\":116216,\"start\":116211},{\"end\":116540,\"start\":116532},{\"end\":116565,\"start\":116561},{\"end\":116574,\"start\":116566},{\"end\":116586,\"start\":116581},{\"end\":116599,\"start\":116594},{\"end\":116614,\"start\":116610},{\"end\":116631,\"start\":116626},{\"end\":116646,\"start\":116641},{\"end\":116661,\"start\":116657},{\"end\":116683,\"start\":116675},{\"end\":117106,\"start\":117099},{\"end\":117122,\"start\":117118},{\"end\":117137,\"start\":117130},{\"end\":117300,\"start\":117297},{\"end\":117319,\"start\":117313},{\"end\":117333,\"start\":117328},{\"end\":117465,\"start\":117457},{\"end\":117476,\"start\":117470},{\"end\":117491,\"start\":117484},{\"end\":117629,\"start\":117621},{\"end\":117640,\"start\":117634},{\"end\":117655,\"start\":117648},{\"end\":117670,\"start\":117663},{\"end\":117811,\"start\":117804},{\"end\":117825,\"start\":117817},{\"end\":117840,\"start\":117833},{\"end\":117853,\"start\":117847},{\"end\":117862,\"start\":117858},{\"end\":117873,\"start\":117867},{\"end\":117882,\"start\":117879},{\"end\":117894,\"start\":117889},{\"end\":118138,\"start\":118131},{\"end\":118151,\"start\":118144},{\"end\":118165,\"start\":118158},{\"end\":118177,\"start\":118170},{\"end\":118190,\"start\":118184},{\"end\":118199,\"start\":118195},{\"end\":118207,\"start\":118204},{\"end\":118514,\"start\":118509},{\"end\":118525,\"start\":118519},{\"end\":118798,\"start\":118790},{\"end\":118812,\"start\":118804},{\"end\":118826,\"start\":118817},{\"end\":118840,\"start\":118833},{\"end\":118853,\"start\":118846},{\"end\":119101,\"start\":119100},{\"end\":119336,\"start\":119335},{\"end\":119355,\"start\":119346},{\"end\":119376,\"start\":119375},{\"end\":119392,\"start\":119383},{\"end\":119602,\"start\":119594},{\"end\":119604,\"start\":119603},{\"end\":119618,\"start\":119613},{\"end\":119637,\"start\":119629},{\"end\":119906,\"start\":119901},{\"end\":119917,\"start\":119914},{\"end\":119923,\"start\":119918},{\"end\":119937,\"start\":119929},{\"end\":119950,\"start\":119945},{\"end\":119962,\"start\":119955},{\"end\":120267,\"start\":120262},{\"end\":120280,\"start\":120275},{\"end\":120293,\"start\":120289},{\"end\":120301,\"start\":120300},{\"end\":120316,\"start\":120311},{\"end\":120614,\"start\":120603},{\"end\":120630,\"start\":120625},{\"end\":120646,\"start\":120639},{\"end\":120879,\"start\":120875},{\"end\":120886,\"start\":120884},{\"end\":120894,\"start\":120891},{\"end\":120905,\"start\":120900},{\"end\":120913,\"start\":120910},{\"end\":121115,\"start\":121111},{\"end\":121125,\"start\":121123},{\"end\":121139,\"start\":121131},{\"end\":121151,\"start\":121147},{\"end\":121356,\"start\":121352},{\"end\":121367,\"start\":121364},{\"end\":121378,\"start\":121373},{\"end\":121387,\"start\":121383},{\"end\":121389,\"start\":121388},{\"end\":121505,\"start\":121499},{\"end\":121520,\"start\":121513},{\"end\":121532,\"start\":121526},{\"end\":121542,\"start\":121537},{\"end\":121789,\"start\":121785},{\"end\":121802,\"start\":121795},{\"end\":121814,\"start\":121810},{\"end\":121824,\"start\":121819},{\"end\":121837,\"start\":121829},{\"end\":122053,\"start\":122048},{\"end\":122069,\"start\":122063},{\"end\":122079,\"start\":122077},{\"end\":122094,\"start\":122086},{\"end\":122377,\"start\":122371},{\"end\":122390,\"start\":122385},{\"end\":122405,\"start\":122399},{\"end\":122644,\"start\":122643},{\"end\":122659,\"start\":122654},{\"end\":122670,\"start\":122666},{\"end\":122919,\"start\":122913},{\"end\":123273,\"start\":123269},{\"end\":123284,\"start\":123279},{\"end\":123291,\"start\":123290},{\"end\":123307,\"start\":123301},{\"end\":123322,\"start\":123316},{\"end\":123639,\"start\":123633},{\"end\":123653,\"start\":123645},{\"end\":123668,\"start\":123662},{\"end\":123686,\"start\":123679},{\"end\":123995,\"start\":123992},{\"end\":124010,\"start\":124003},{\"end\":124272,\"start\":124266},{\"end\":124291,\"start\":124282},{\"end\":124303,\"start\":124297},{\"end\":124323,\"start\":124314},{\"end\":124341,\"start\":124335},{\"end\":124344,\"start\":124342},{\"end\":124358,\"start\":124352},{\"end\":124373,\"start\":124367},{\"end\":124684,\"start\":124682},{\"end\":124689,\"start\":124685},{\"end\":124698,\"start\":124695},{\"end\":124703,\"start\":124699},{\"end\":124715,\"start\":124712},{\"end\":124728,\"start\":124722},{\"end\":124960,\"start\":124959},{\"end\":124976,\"start\":124971},{\"end\":125407,\"start\":125398},{\"end\":125424,\"start\":125417},{\"end\":125441,\"start\":125435},{\"end\":125719,\"start\":125710},{\"end\":125735,\"start\":125729},{\"end\":125749,\"start\":125743},{\"end\":125957,\"start\":125953},{\"end\":125971,\"start\":125965},{\"end\":125988,\"start\":125980},{\"end\":126232,\"start\":126224},{\"end\":126242,\"start\":126238},{\"end\":126256,\"start\":126249},{\"end\":126267,\"start\":126261},{\"end\":126281,\"start\":126273},{\"end\":126291,\"start\":126287},{\"end\":126603,\"start\":126595},{\"end\":126611,\"start\":126608},{\"end\":126623,\"start\":126617},{\"end\":126634,\"start\":126629},{\"end\":126986,\"start\":126979},{\"end\":126993,\"start\":126991},{\"end\":127006,\"start\":127000},{\"end\":127017,\"start\":127015},{\"end\":127031,\"start\":127024},{\"end\":127295,\"start\":127292},{\"end\":127303,\"start\":127300},{\"end\":127313,\"start\":127308},{\"end\":127329,\"start\":127321},{\"end\":127600,\"start\":127591},{\"end\":127609,\"start\":127605},{\"end\":127620,\"start\":127616},{\"end\":127633,\"start\":127628},{\"end\":127635,\"start\":127634},{\"end\":127645,\"start\":127640},{\"end\":127660,\"start\":127654},{\"end\":127672,\"start\":127665},{\"end\":127684,\"start\":127680},{\"end\":127696,\"start\":127691},{\"end\":127970,\"start\":127966},{\"end\":127982,\"start\":127976},{\"end\":127991,\"start\":127988},{\"end\":128002,\"start\":127997},{\"end\":128011,\"start\":128007},{\"end\":128026,\"start\":128020},{\"end\":128392,\"start\":128389},{\"end\":128404,\"start\":128398},{\"end\":128417,\"start\":128410},{\"end\":128427,\"start\":128422},{\"end\":128439,\"start\":128432},{\"end\":128447,\"start\":128445},{\"end\":128636,\"start\":128633},{\"end\":128649,\"start\":128642},{\"end\":128661,\"start\":128654},{\"end\":128849,\"start\":128846},{\"end\":128861,\"start\":128855},{\"end\":128875,\"start\":128868},{\"end\":128886,\"start\":128882},{\"end\":128896,\"start\":128892},{\"end\":129139,\"start\":129136},{\"end\":129152,\"start\":129145},{\"end\":129159,\"start\":129158},{\"end\":129179,\"start\":129171},{\"end\":129196,\"start\":129191},{\"end\":129206,\"start\":129202},{\"end\":129218,\"start\":129212},{\"end\":129232,\"start\":129228},{\"end\":129235,\"start\":129233},{\"end\":129466,\"start\":129460},{\"end\":129474,\"start\":129472},{\"end\":129482,\"start\":129479},{\"end\":129775,\"start\":129771},{\"end\":129788,\"start\":129781},{\"end\":129801,\"start\":129796},{\"end\":129817,\"start\":129811},{\"end\":129831,\"start\":129825},{\"end\":129848,\"start\":129841},{\"end\":130107,\"start\":130102},{\"end\":130119,\"start\":130113},{\"end\":130130,\"start\":130124},{\"end\":130142,\"start\":130136},{\"end\":130155,\"start\":130149},{\"end\":130370,\"start\":130362},{\"end\":130379,\"start\":130376},{\"end\":130390,\"start\":130385},{\"end\":130404,\"start\":130395},{\"end\":130416,\"start\":130411},{\"end\":130418,\"start\":130417},{\"end\":130435,\"start\":130427},{\"end\":130633,\"start\":130625},{\"end\":130642,\"start\":130639},{\"end\":130657,\"start\":130648},{\"end\":130671,\"start\":130666},{\"end\":130684,\"start\":130676},{\"end\":130899,\"start\":130891},{\"end\":130908,\"start\":130905},{\"end\":130918,\"start\":130914},{\"end\":130932,\"start\":130924},{\"end\":131137,\"start\":131127},{\"end\":131157,\"start\":131152},{\"end\":131417,\"start\":131410},{\"end\":131433,\"start\":131429},{\"end\":131438,\"start\":131434},{\"end\":131453,\"start\":131445},{\"end\":131466,\"start\":131460},{\"end\":131476,\"start\":131471},{\"end\":131485,\"start\":131482},{\"end\":131786,\"start\":131782},{\"end\":131800,\"start\":131791},{\"end\":131815,\"start\":131807},{\"end\":131827,\"start\":131822},{\"end\":131840,\"start\":131834},{\"end\":131853,\"start\":131845},{\"end\":132092,\"start\":132088},{\"end\":132106,\"start\":132101},{\"end\":132121,\"start\":132115},{\"end\":132345,\"start\":132339},{\"end\":132373,\"start\":132366},{\"end\":132637,\"start\":132631},{\"end\":132651,\"start\":132643},{\"end\":132666,\"start\":132658},{\"end\":132892,\"start\":132891},{\"end\":132907,\"start\":132901},{\"end\":133247,\"start\":133244},{\"end\":133265,\"start\":133257},{\"end\":133283,\"start\":133276},{\"end\":133297,\"start\":133292},{\"end\":133307,\"start\":133304},{\"end\":133614,\"start\":133610},{\"end\":133624,\"start\":133619},{\"end\":133635,\"start\":133632},{\"end\":133649,\"start\":133642},{\"end\":133663,\"start\":133658},{\"end\":133905,\"start\":133893},{\"end\":133921,\"start\":133915},{\"end\":133936,\"start\":133928},{\"end\":134352,\"start\":134347},{\"end\":134360,\"start\":134353},{\"end\":134374,\"start\":134368},{\"end\":134399,\"start\":134392},{\"end\":134415,\"start\":134408},{\"end\":134429,\"start\":134424},{\"end\":134732,\"start\":134723},{\"end\":134742,\"start\":134737},{\"end\":134757,\"start\":134748},{\"end\":134771,\"start\":134766},{\"end\":134785,\"start\":134778},{\"end\":134796,\"start\":134791},{\"end\":134807,\"start\":134803},{\"end\":134820,\"start\":134813},{\"end\":135152,\"start\":135147},{\"end\":135178,\"start\":135172},{\"end\":135197,\"start\":135196},{\"end\":135213,\"start\":135208},{\"end\":135215,\"start\":135214},{\"end\":135553,\"start\":135548},{\"end\":135569,\"start\":135561},{\"end\":135971,\"start\":135968},{\"end\":135990,\"start\":135985},{\"end\":136007,\"start\":136003},{\"end\":136025,\"start\":136019},{\"end\":136279,\"start\":136275},{\"end\":136287,\"start\":136284},{\"end\":136300,\"start\":136292},{\"end\":136313,\"start\":136306},{\"end\":136323,\"start\":136320},{\"end\":136337,\"start\":136330},{\"end\":136626,\"start\":136618},{\"end\":136642,\"start\":136636},{\"end\":136663,\"start\":136655},{\"end\":136947,\"start\":136941},{\"end\":136960,\"start\":136953},{\"end\":136975,\"start\":136971},{\"end\":136993,\"start\":136985},{\"end\":137005,\"start\":137001},{\"end\":137294,\"start\":137288},{\"end\":137302,\"start\":137300},{\"end\":137316,\"start\":137310},{\"end\":137327,\"start\":137323},{\"end\":137343,\"start\":137335},{\"end\":137594,\"start\":137588},{\"end\":137609,\"start\":137602},{\"end\":137853,\"start\":137850},{\"end\":137870,\"start\":137864},{\"end\":137889,\"start\":137883},{\"end\":138143,\"start\":138134},{\"end\":138346,\"start\":138339},{\"end\":138363,\"start\":138356},{\"end\":138383,\"start\":138376},{\"end\":138681,\"start\":138676},{\"end\":138998,\"start\":138991},{\"end\":139013,\"start\":139004},{\"end\":139023,\"start\":139020},{\"end\":139034,\"start\":139029},{\"end\":139044,\"start\":139039},{\"end\":139055,\"start\":139051},{\"end\":139356,\"start\":139349},{\"end\":139368,\"start\":139367},{\"end\":139382,\"start\":139375},{\"end\":139395,\"start\":139390},{\"end\":139411,\"start\":139407},{\"end\":139691,\"start\":139687},{\"end\":139704,\"start\":139698},{\"end\":139714,\"start\":139711},{\"end\":139727,\"start\":139721},{\"end\":139982,\"start\":139977},{\"end\":139990,\"start\":139983},{\"end\":140005,\"start\":139999},{\"end\":140013,\"start\":140006},{\"end\":140030,\"start\":140024},{\"end\":140043,\"start\":140038},{\"end\":140063,\"start\":140052},{\"end\":140359,\"start\":140356},{\"end\":140372,\"start\":140366},{\"end\":140387,\"start\":140379},{\"end\":140396,\"start\":140393},{\"end\":140406,\"start\":140402},{\"end\":140700,\"start\":140694},{\"end\":140721,\"start\":140713},{\"end\":140734,\"start\":140730},{\"end\":140751,\"start\":140747},{\"end\":140769,\"start\":140763},{\"end\":141113,\"start\":141107},{\"end\":141128,\"start\":141123},{\"end\":141149,\"start\":141140},{\"end\":141430,\"start\":141423},{\"end\":141442,\"start\":141437},{\"end\":141700,\"start\":141693},{\"end\":141714,\"start\":141707},{\"end\":141725,\"start\":141721},{\"end\":142009,\"start\":142003},{\"end\":142019,\"start\":142016},{\"end\":142031,\"start\":142025},{\"end\":142292,\"start\":142285},{\"end\":142305,\"start\":142301},{\"end\":142322,\"start\":142314},{\"end\":142343,\"start\":142331},{\"end\":142346,\"start\":142344},{\"end\":142360,\"start\":142354},{\"end\":142373,\"start\":142368},{\"end\":142707,\"start\":142700},{\"end\":142720,\"start\":142716},{\"end\":142737,\"start\":142729},{\"end\":142758,\"start\":142746},{\"end\":142761,\"start\":142759},{\"end\":142775,\"start\":142769},{\"end\":142788,\"start\":142783},{\"end\":143141,\"start\":143134},{\"end\":143152,\"start\":143147},{\"end\":143167,\"start\":143160},{\"end\":143175,\"start\":143173},{\"end\":143190,\"start\":143182},{\"end\":143485,\"start\":143482},{\"end\":143499,\"start\":143491},{\"end\":143510,\"start\":143505},{\"end\":143524,\"start\":143516},{\"end\":143533,\"start\":143529},{\"end\":143544,\"start\":143540},{\"end\":143555,\"start\":143549},{\"end\":143836,\"start\":143833},{\"end\":143846,\"start\":143842},{\"end\":143856,\"start\":143853},{\"end\":143871,\"start\":143863},{\"end\":143883,\"start\":143876},{\"end\":143894,\"start\":143890},{\"end\":143907,\"start\":143899},{\"end\":144170,\"start\":144166},{\"end\":144183,\"start\":144177},{\"end\":144197,\"start\":144189},{\"end\":144206,\"start\":144203},{\"end\":144415,\"start\":144411},{\"end\":144428,\"start\":144422},{\"end\":144437,\"start\":144434},{\"end\":144658,\"start\":144651},{\"end\":144672,\"start\":144665},{\"end\":144682,\"start\":144679},{\"end\":144693,\"start\":144689},{\"end\":144954,\"start\":144948},{\"end\":144963,\"start\":144961},{\"end\":144970,\"start\":144968},{\"end\":144978,\"start\":144975},{\"end\":144987,\"start\":144984},{\"end\":145271,\"start\":145269},{\"end\":145286,\"start\":145278},{\"end\":145302,\"start\":145293},{\"end\":145583,\"start\":145577},{\"end\":145593,\"start\":145590},{\"end\":145605,\"start\":145598},{\"end\":145615,\"start\":145612},{\"end\":145925,\"start\":145921},{\"end\":145938,\"start\":145931},{\"end\":145952,\"start\":145943},{\"end\":146209,\"start\":146203},{\"end\":146224,\"start\":146217},{\"end\":146239,\"start\":146233},{\"end\":146256,\"start\":146250},{\"end\":146273,\"start\":146268},{\"end\":146568,\"start\":146562},{\"end\":146583,\"start\":146576},{\"end\":146603,\"start\":146592},{\"end\":146618,\"start\":146613},{\"end\":146848,\"start\":146842},{\"end\":146867,\"start\":146856},{\"end\":146882,\"start\":146877},{\"end\":146905,\"start\":146900},{\"end\":147129,\"start\":147125},{\"end\":147142,\"start\":147139},{\"end\":147294,\"start\":147289},{\"end\":147299,\"start\":147295},{\"end\":147600,\"start\":147597},{\"end\":147612,\"start\":147607},{\"end\":147621,\"start\":147620},{\"end\":147635,\"start\":147631},{\"end\":147928,\"start\":147925},{\"end\":147938,\"start\":147934},{\"end\":147948,\"start\":147945},{\"end\":147958,\"start\":147953},{\"end\":147972,\"start\":147963},{\"end\":147985,\"start\":147977},{\"end\":147996,\"start\":147990},{\"end\":148324,\"start\":148319},{\"end\":148337,\"start\":148329},{\"end\":148352,\"start\":148347},{\"end\":148365,\"start\":148357},{\"end\":148675,\"start\":148670},{\"end\":148686,\"start\":148680},{\"end\":148700,\"start\":148691},{\"end\":148710,\"start\":148707},{\"end\":148722,\"start\":148716},{\"end\":148737,\"start\":148729},{\"end\":149040,\"start\":149036},{\"end\":149050,\"start\":149045},{\"end\":149058,\"start\":149055},{\"end\":149066,\"start\":149063},{\"end\":149077,\"start\":149072},{\"end\":149089,\"start\":149083},{\"end\":149100,\"start\":149097},{\"end\":149113,\"start\":149108},{\"end\":149127,\"start\":149121},{\"end\":149443,\"start\":149434},{\"end\":149454,\"start\":149449},{\"end\":149466,\"start\":149461},{\"end\":149479,\"start\":149473},{\"end\":149497,\"start\":149491},{\"end\":149773,\"start\":149770},{\"end\":149782,\"start\":149778},{\"end\":149792,\"start\":149788},{\"end\":149801,\"start\":149799},{\"end\":149809,\"start\":149806},{\"end\":149824,\"start\":149815},{\"end\":150088,\"start\":150080},{\"end\":150108,\"start\":150099},{\"end\":150136,\"start\":150121},{\"end\":150408,\"start\":150404},{\"end\":150418,\"start\":150416},{\"end\":150431,\"start\":150425},{\"end\":150446,\"start\":150439},{\"end\":150459,\"start\":150452},{\"end\":150472,\"start\":150466},{\"end\":150760,\"start\":150754},{\"end\":150774,\"start\":150768},{\"end\":150783,\"start\":150780},{\"end\":150795,\"start\":150788},{\"end\":150808,\"start\":150801},{\"end\":151098,\"start\":151094},{\"end\":151109,\"start\":151106},{\"end\":151124,\"start\":151115},{\"end\":151136,\"start\":151130},{\"end\":151413,\"start\":151408},{\"end\":151429,\"start\":151420},{\"end\":151444,\"start\":151436},{\"end\":151454,\"start\":151451},{\"end\":151468,\"start\":151460},{\"end\":151722,\"start\":151718},{\"end\":151733,\"start\":151729},{\"end\":151936,\"start\":151933},{\"end\":151949,\"start\":151943},{\"end\":151962,\"start\":151954},{\"end\":151974,\"start\":151968},{\"end\":151987,\"start\":151980},{\"end\":152253,\"start\":152247},{\"end\":152263,\"start\":152260},{\"end\":152285,\"start\":152278},{\"end\":152301,\"start\":152295},{\"end\":152313,\"start\":152307},{\"end\":152578,\"start\":152575},{\"end\":152593,\"start\":152586},{\"end\":152603,\"start\":152599},{\"end\":152611,\"start\":152608},{\"end\":152622,\"start\":152616},{\"end\":152636,\"start\":152628},{\"end\":152647,\"start\":152643},{\"end\":152659,\"start\":152653},{\"end\":152674,\"start\":152666},{\"end\":152689,\"start\":152681},{\"end\":153037,\"start\":153032},{\"end\":153047,\"start\":153044},{\"end\":153060,\"start\":153052},{\"end\":153337,\"start\":153331},{\"end\":153347,\"start\":153344},{\"end\":153357,\"start\":153353},{\"end\":153370,\"start\":153363},{\"end\":153381,\"start\":153377},{\"end\":153649,\"start\":153642},{\"end\":153664,\"start\":153656},{\"end\":153673,\"start\":153670},{\"end\":153682,\"start\":153679},{\"end\":153692,\"start\":153687},{\"end\":153942,\"start\":153940},{\"end\":153952,\"start\":153949},{\"end\":153964,\"start\":153958},{\"end\":153977,\"start\":153971},{\"end\":153990,\"start\":153984}]", "bib_author_last_name": "[{\"end\":107606,\"start\":107598},{\"end\":107623,\"start\":107613},{\"end\":107639,\"start\":107631},{\"end\":107893,\"start\":107885},{\"end\":107912,\"start\":107906},{\"end\":107929,\"start\":107921},{\"end\":107946,\"start\":107940},{\"end\":107960,\"start\":107954},{\"end\":107974,\"start\":107969},{\"end\":108253,\"start\":108250},{\"end\":108269,\"start\":108265},{\"end\":108278,\"start\":108275},{\"end\":108288,\"start\":108286},{\"end\":108300,\"start\":108298},{\"end\":108313,\"start\":108309},{\"end\":108570,\"start\":108564},{\"end\":108584,\"start\":108579},{\"end\":108605,\"start\":108596},{\"end\":108874,\"start\":108860},{\"end\":108888,\"start\":108882},{\"end\":108898,\"start\":108892},{\"end\":108913,\"start\":108907},{\"end\":108922,\"start\":108915},{\"end\":109203,\"start\":109197},{\"end\":109219,\"start\":109214},{\"end\":109234,\"start\":109229},{\"end\":109488,\"start\":109484},{\"end\":109508,\"start\":109503},{\"end\":109756,\"start\":109749},{\"end\":109775,\"start\":109768},{\"end\":110058,\"start\":110054},{\"end\":110075,\"start\":110066},{\"end\":110291,\"start\":110281},{\"end\":110302,\"start\":110300},{\"end\":110315,\"start\":110312},{\"end\":110328,\"start\":110325},{\"end\":110344,\"start\":110337},{\"end\":110600,\"start\":110596},{\"end\":110613,\"start\":110609},{\"end\":110627,\"start\":110623},{\"end\":110641,\"start\":110638},{\"end\":110653,\"start\":110651},{\"end\":110991,\"start\":110987},{\"end\":111000,\"start\":110998},{\"end\":111013,\"start\":111009},{\"end\":111029,\"start\":111025},{\"end\":111039,\"start\":111036},{\"end\":111342,\"start\":111338},{\"end\":111357,\"start\":111353},{\"end\":111373,\"start\":111369},{\"end\":111383,\"start\":111381},{\"end\":111648,\"start\":111644},{\"end\":111663,\"start\":111659},{\"end\":111679,\"start\":111675},{\"end\":111688,\"start\":111685},{\"end\":111700,\"start\":111697},{\"end\":111713,\"start\":111707},{\"end\":111727,\"start\":111723},{\"end\":112001,\"start\":111987},{\"end\":112016,\"start\":112013},{\"end\":112029,\"start\":112025},{\"end\":112041,\"start\":112037},{\"end\":112055,\"start\":112050},{\"end\":112068,\"start\":112061},{\"end\":112347,\"start\":112337},{\"end\":112366,\"start\":112359},{\"end\":112381,\"start\":112377},{\"end\":112611,\"start\":112604},{\"end\":112630,\"start\":112620},{\"end\":112647,\"start\":112641},{\"end\":112661,\"start\":112654},{\"end\":112912,\"start\":112903},{\"end\":112924,\"start\":112920},{\"end\":112935,\"start\":112926},{\"end\":112946,\"start\":112944},{\"end\":112957,\"start\":112953},{\"end\":112972,\"start\":112966},{\"end\":112986,\"start\":112981},{\"end\":113000,\"start\":112997},{\"end\":113005,\"start\":113002},{\"end\":113337,\"start\":113328},{\"end\":113350,\"start\":113346},{\"end\":113373,\"start\":113369},{\"end\":113387,\"start\":113385},{\"end\":113400,\"start\":113394},{\"end\":113414,\"start\":113409},{\"end\":113697,\"start\":113693},{\"end\":114013,\"start\":114005},{\"end\":114030,\"start\":114022},{\"end\":114049,\"start\":114043},{\"end\":114067,\"start\":114059},{\"end\":114075,\"start\":114069},{\"end\":114375,\"start\":114367},{\"end\":114385,\"start\":114383},{\"end\":114401,\"start\":114396},{\"end\":114642,\"start\":114637},{\"end\":114656,\"start\":114650},{\"end\":114661,\"start\":114658},{\"end\":114880,\"start\":114872},{\"end\":114899,\"start\":114889},{\"end\":114915,\"start\":114908},{\"end\":114929,\"start\":114924},{\"end\":114948,\"start\":114940},{\"end\":115242,\"start\":115238},{\"end\":115252,\"start\":115249},{\"end\":115266,\"start\":115263},{\"end\":115278,\"start\":115273},{\"end\":115291,\"start\":115288},{\"end\":115539,\"start\":115536},{\"end\":115554,\"start\":115550},{\"end\":115570,\"start\":115566},{\"end\":115580,\"start\":115578},{\"end\":115590,\"start\":115586},{\"end\":115605,\"start\":115602},{\"end\":115866,\"start\":115863},{\"end\":115876,\"start\":115872},{\"end\":115888,\"start\":115885},{\"end\":115898,\"start\":115894},{\"end\":115908,\"start\":115904},{\"end\":115922,\"start\":115919},{\"end\":116199,\"start\":116195},{\"end\":116209,\"start\":116203},{\"end\":116222,\"start\":116217},{\"end\":116559,\"start\":116541},{\"end\":116579,\"start\":116575},{\"end\":116592,\"start\":116587},{\"end\":116608,\"start\":116600},{\"end\":116624,\"start\":116615},{\"end\":116639,\"start\":116632},{\"end\":116655,\"start\":116647},{\"end\":116673,\"start\":116662},{\"end\":116688,\"start\":116684},{\"end\":116697,\"start\":116690},{\"end\":117116,\"start\":117107},{\"end\":117128,\"start\":117123},{\"end\":117143,\"start\":117138},{\"end\":117311,\"start\":117301},{\"end\":117326,\"start\":117320},{\"end\":117343,\"start\":117334},{\"end\":117468,\"start\":117466},{\"end\":117482,\"start\":117477},{\"end\":117495,\"start\":117492},{\"end\":117632,\"start\":117630},{\"end\":117646,\"start\":117641},{\"end\":117661,\"start\":117656},{\"end\":117674,\"start\":117671},{\"end\":117815,\"start\":117812},{\"end\":117831,\"start\":117826},{\"end\":117845,\"start\":117841},{\"end\":117856,\"start\":117854},{\"end\":117865,\"start\":117863},{\"end\":117877,\"start\":117874},{\"end\":117887,\"start\":117883},{\"end\":117897,\"start\":117895},{\"end\":118142,\"start\":118139},{\"end\":118156,\"start\":118152},{\"end\":118168,\"start\":118166},{\"end\":118182,\"start\":118178},{\"end\":118193,\"start\":118191},{\"end\":118202,\"start\":118200},{\"end\":118213,\"start\":118208},{\"end\":118517,\"start\":118515},{\"end\":118531,\"start\":118526},{\"end\":118802,\"start\":118799},{\"end\":118815,\"start\":118813},{\"end\":118831,\"start\":118827},{\"end\":118844,\"start\":118841},{\"end\":118858,\"start\":118854},{\"end\":119109,\"start\":119102},{\"end\":119118,\"start\":119111},{\"end\":119344,\"start\":119337},{\"end\":119367,\"start\":119356},{\"end\":119373,\"start\":119369},{\"end\":119381,\"start\":119377},{\"end\":119397,\"start\":119393},{\"end\":119408,\"start\":119399},{\"end\":119611,\"start\":119605},{\"end\":119627,\"start\":119619},{\"end\":119641,\"start\":119638},{\"end\":119912,\"start\":119907},{\"end\":119927,\"start\":119924},{\"end\":119943,\"start\":119938},{\"end\":119953,\"start\":119951},{\"end\":119971,\"start\":119963},{\"end\":120273,\"start\":120268},{\"end\":120287,\"start\":120281},{\"end\":120298,\"start\":120294},{\"end\":120309,\"start\":120302},{\"end\":120325,\"start\":120317},{\"end\":120329,\"start\":120327},{\"end\":120623,\"start\":120615},{\"end\":120637,\"start\":120631},{\"end\":120657,\"start\":120647},{\"end\":120882,\"start\":120880},{\"end\":120889,\"start\":120887},{\"end\":120898,\"start\":120895},{\"end\":120908,\"start\":120906},{\"end\":120917,\"start\":120914},{\"end\":121121,\"start\":121116},{\"end\":121129,\"start\":121126},{\"end\":121145,\"start\":121140},{\"end\":121156,\"start\":121152},{\"end\":121362,\"start\":121357},{\"end\":121371,\"start\":121368},{\"end\":121381,\"start\":121379},{\"end\":121396,\"start\":121390},{\"end\":121511,\"start\":121506},{\"end\":121524,\"start\":121521},{\"end\":121535,\"start\":121533},{\"end\":121547,\"start\":121543},{\"end\":121793,\"start\":121790},{\"end\":121808,\"start\":121803},{\"end\":121817,\"start\":121815},{\"end\":121827,\"start\":121825},{\"end\":121841,\"start\":121838},{\"end\":122061,\"start\":122054},{\"end\":122075,\"start\":122070},{\"end\":122084,\"start\":122080},{\"end\":122099,\"start\":122095},{\"end\":122383,\"start\":122378},{\"end\":122397,\"start\":122391},{\"end\":122414,\"start\":122406},{\"end\":122652,\"start\":122645},{\"end\":122664,\"start\":122660},{\"end\":122677,\"start\":122671},{\"end\":122686,\"start\":122679},{\"end\":122925,\"start\":122920},{\"end\":123277,\"start\":123274},{\"end\":123288,\"start\":123285},{\"end\":123299,\"start\":123292},{\"end\":123314,\"start\":123308},{\"end\":123330,\"start\":123323},{\"end\":123338,\"start\":123332},{\"end\":123643,\"start\":123640},{\"end\":123660,\"start\":123654},{\"end\":123677,\"start\":123669},{\"end\":123693,\"start\":123687},{\"end\":124001,\"start\":123996},{\"end\":124018,\"start\":124011},{\"end\":124280,\"start\":124273},{\"end\":124295,\"start\":124292},{\"end\":124312,\"start\":124304},{\"end\":124333,\"start\":124324},{\"end\":124350,\"start\":124345},{\"end\":124365,\"start\":124359},{\"end\":124383,\"start\":124374},{\"end\":124693,\"start\":124690},{\"end\":124710,\"start\":124704},{\"end\":124720,\"start\":124716},{\"end\":124735,\"start\":124729},{\"end\":124743,\"start\":124737},{\"end\":124969,\"start\":124961},{\"end\":124979,\"start\":124977},{\"end\":124983,\"start\":124981},{\"end\":125415,\"start\":125408},{\"end\":125433,\"start\":125425},{\"end\":125450,\"start\":125442},{\"end\":125727,\"start\":125720},{\"end\":125741,\"start\":125736},{\"end\":125758,\"start\":125750},{\"end\":125963,\"start\":125958},{\"end\":125978,\"start\":125972},{\"end\":125995,\"start\":125989},{\"end\":126236,\"start\":126233},{\"end\":126247,\"start\":126243},{\"end\":126259,\"start\":126257},{\"end\":126271,\"start\":126268},{\"end\":126285,\"start\":126282},{\"end\":126295,\"start\":126292},{\"end\":126606,\"start\":126604},{\"end\":126615,\"start\":126612},{\"end\":126627,\"start\":126624},{\"end\":126639,\"start\":126635},{\"end\":126989,\"start\":126987},{\"end\":126998,\"start\":126994},{\"end\":127013,\"start\":127007},{\"end\":127022,\"start\":127018},{\"end\":127037,\"start\":127032},{\"end\":127298,\"start\":127296},{\"end\":127306,\"start\":127304},{\"end\":127319,\"start\":127314},{\"end\":127335,\"start\":127330},{\"end\":127603,\"start\":127601},{\"end\":127614,\"start\":127610},{\"end\":127626,\"start\":127621},{\"end\":127638,\"start\":127636},{\"end\":127652,\"start\":127646},{\"end\":127663,\"start\":127661},{\"end\":127678,\"start\":127673},{\"end\":127689,\"start\":127685},{\"end\":127701,\"start\":127697},{\"end\":127707,\"start\":127703},{\"end\":127974,\"start\":127971},{\"end\":127986,\"start\":127983},{\"end\":127995,\"start\":127992},{\"end\":128005,\"start\":128003},{\"end\":128018,\"start\":128012},{\"end\":128031,\"start\":128027},{\"end\":128396,\"start\":128393},{\"end\":128408,\"start\":128405},{\"end\":128420,\"start\":128418},{\"end\":128430,\"start\":128428},{\"end\":128443,\"start\":128440},{\"end\":128453,\"start\":128448},{\"end\":128640,\"start\":128637},{\"end\":128652,\"start\":128650},{\"end\":128665,\"start\":128662},{\"end\":128853,\"start\":128850},{\"end\":128866,\"start\":128862},{\"end\":128880,\"start\":128876},{\"end\":128890,\"start\":128887},{\"end\":128903,\"start\":128897},{\"end\":129143,\"start\":129140},{\"end\":129156,\"start\":129153},{\"end\":129169,\"start\":129160},{\"end\":129189,\"start\":129180},{\"end\":129200,\"start\":129197},{\"end\":129210,\"start\":129207},{\"end\":129226,\"start\":129219},{\"end\":129239,\"start\":129236},{\"end\":129246,\"start\":129241},{\"end\":129470,\"start\":129467},{\"end\":129477,\"start\":129475},{\"end\":129487,\"start\":129483},{\"end\":129779,\"start\":129776},{\"end\":129794,\"start\":129789},{\"end\":129809,\"start\":129802},{\"end\":129823,\"start\":129818},{\"end\":129839,\"start\":129832},{\"end\":129853,\"start\":129849},{\"end\":130111,\"start\":130108},{\"end\":130122,\"start\":130120},{\"end\":130134,\"start\":130131},{\"end\":130147,\"start\":130143},{\"end\":130158,\"start\":130156},{\"end\":130374,\"start\":130371},{\"end\":130383,\"start\":130380},{\"end\":130393,\"start\":130391},{\"end\":130409,\"start\":130405},{\"end\":130425,\"start\":130419},{\"end\":130438,\"start\":130436},{\"end\":130637,\"start\":130634},{\"end\":130646,\"start\":130643},{\"end\":130664,\"start\":130658},{\"end\":130674,\"start\":130672},{\"end\":130687,\"start\":130685},{\"end\":130903,\"start\":130900},{\"end\":130912,\"start\":130909},{\"end\":130922,\"start\":130919},{\"end\":130935,\"start\":130933},{\"end\":131150,\"start\":131138},{\"end\":131163,\"start\":131158},{\"end\":131427,\"start\":131418},{\"end\":131443,\"start\":131439},{\"end\":131458,\"start\":131454},{\"end\":131469,\"start\":131467},{\"end\":131480,\"start\":131477},{\"end\":131489,\"start\":131486},{\"end\":131789,\"start\":131787},{\"end\":131805,\"start\":131801},{\"end\":131820,\"start\":131816},{\"end\":131832,\"start\":131828},{\"end\":131843,\"start\":131841},{\"end\":131856,\"start\":131854},{\"end\":132099,\"start\":132093},{\"end\":132113,\"start\":132107},{\"end\":132127,\"start\":132122},{\"end\":132364,\"start\":132346},{\"end\":132379,\"start\":132374},{\"end\":132387,\"start\":132381},{\"end\":132641,\"start\":132638},{\"end\":132656,\"start\":132652},{\"end\":132672,\"start\":132667},{\"end\":132899,\"start\":132893},{\"end\":132917,\"start\":132908},{\"end\":132924,\"start\":132919},{\"end\":133255,\"start\":133248},{\"end\":133274,\"start\":133266},{\"end\":133290,\"start\":133284},{\"end\":133302,\"start\":133298},{\"end\":133310,\"start\":133308},{\"end\":133617,\"start\":133615},{\"end\":133630,\"start\":133625},{\"end\":133640,\"start\":133636},{\"end\":133656,\"start\":133650},{\"end\":133667,\"start\":133664},{\"end\":133913,\"start\":133906},{\"end\":133926,\"start\":133922},{\"end\":133943,\"start\":133937},{\"end\":134366,\"start\":134361},{\"end\":134390,\"start\":134375},{\"end\":134406,\"start\":134400},{\"end\":134422,\"start\":134416},{\"end\":134440,\"start\":134430},{\"end\":134735,\"start\":134733},{\"end\":134746,\"start\":134743},{\"end\":134764,\"start\":134758},{\"end\":134776,\"start\":134772},{\"end\":134789,\"start\":134786},{\"end\":134801,\"start\":134797},{\"end\":134811,\"start\":134808},{\"end\":134825,\"start\":134821},{\"end\":135170,\"start\":135153},{\"end\":135189,\"start\":135179},{\"end\":135194,\"start\":135191},{\"end\":135206,\"start\":135198},{\"end\":135219,\"start\":135216},{\"end\":135230,\"start\":135221},{\"end\":135559,\"start\":135554},{\"end\":135572,\"start\":135570},{\"end\":135983,\"start\":135972},{\"end\":136001,\"start\":135991},{\"end\":136017,\"start\":136008},{\"end\":136032,\"start\":136026},{\"end\":136282,\"start\":136280},{\"end\":136290,\"start\":136288},{\"end\":136304,\"start\":136301},{\"end\":136318,\"start\":136314},{\"end\":136328,\"start\":136324},{\"end\":136341,\"start\":136338},{\"end\":136634,\"start\":136627},{\"end\":136653,\"start\":136643},{\"end\":136670,\"start\":136664},{\"end\":136951,\"start\":136948},{\"end\":136969,\"start\":136961},{\"end\":136983,\"start\":136976},{\"end\":136999,\"start\":136994},{\"end\":137014,\"start\":137006},{\"end\":137298,\"start\":137295},{\"end\":137308,\"start\":137303},{\"end\":137321,\"start\":137317},{\"end\":137333,\"start\":137328},{\"end\":137346,\"start\":137344},{\"end\":137600,\"start\":137595},{\"end\":137615,\"start\":137610},{\"end\":137862,\"start\":137854},{\"end\":137881,\"start\":137871},{\"end\":137898,\"start\":137890},{\"end\":138156,\"start\":138144},{\"end\":138354,\"start\":138347},{\"end\":138374,\"start\":138364},{\"end\":138393,\"start\":138384},{\"end\":138686,\"start\":138682},{\"end\":138697,\"start\":138688},{\"end\":139002,\"start\":138999},{\"end\":139018,\"start\":139014},{\"end\":139027,\"start\":139024},{\"end\":139037,\"start\":139035},{\"end\":139049,\"start\":139045},{\"end\":139062,\"start\":139056},{\"end\":139365,\"start\":139357},{\"end\":139373,\"start\":139369},{\"end\":139388,\"start\":139383},{\"end\":139405,\"start\":139396},{\"end\":139418,\"start\":139412},{\"end\":139427,\"start\":139420},{\"end\":139696,\"start\":139692},{\"end\":139709,\"start\":139705},{\"end\":139719,\"start\":139715},{\"end\":139732,\"start\":139728},{\"end\":139997,\"start\":139991},{\"end\":140022,\"start\":140014},{\"end\":140036,\"start\":140031},{\"end\":140050,\"start\":140044},{\"end\":140070,\"start\":140064},{\"end\":140364,\"start\":140360},{\"end\":140377,\"start\":140373},{\"end\":140391,\"start\":140388},{\"end\":140400,\"start\":140397},{\"end\":140411,\"start\":140407},{\"end\":140416,\"start\":140413},{\"end\":140711,\"start\":140701},{\"end\":140728,\"start\":140722},{\"end\":140745,\"start\":140735},{\"end\":140761,\"start\":140752},{\"end\":140783,\"start\":140770},{\"end\":141121,\"start\":141114},{\"end\":141138,\"start\":141129},{\"end\":141155,\"start\":141150},{\"end\":141435,\"start\":141431},{\"end\":141446,\"start\":141443},{\"end\":141705,\"start\":141701},{\"end\":141719,\"start\":141715},{\"end\":141728,\"start\":141726},{\"end\":142014,\"start\":142010},{\"end\":142023,\"start\":142020},{\"end\":142036,\"start\":142032},{\"end\":142299,\"start\":142293},{\"end\":142312,\"start\":142306},{\"end\":142329,\"start\":142323},{\"end\":142352,\"start\":142347},{\"end\":142366,\"start\":142361},{\"end\":142384,\"start\":142374},{\"end\":142714,\"start\":142708},{\"end\":142727,\"start\":142721},{\"end\":142744,\"start\":142738},{\"end\":142767,\"start\":142762},{\"end\":142781,\"start\":142776},{\"end\":142799,\"start\":142789},{\"end\":143145,\"start\":143142},{\"end\":143158,\"start\":143153},{\"end\":143171,\"start\":143168},{\"end\":143180,\"start\":143176},{\"end\":143198,\"start\":143191},{\"end\":143489,\"start\":143486},{\"end\":143503,\"start\":143500},{\"end\":143514,\"start\":143511},{\"end\":143527,\"start\":143525},{\"end\":143538,\"start\":143534},{\"end\":143547,\"start\":143545},{\"end\":143558,\"start\":143556},{\"end\":143840,\"start\":143837},{\"end\":143851,\"start\":143847},{\"end\":143861,\"start\":143857},{\"end\":143874,\"start\":143872},{\"end\":143888,\"start\":143884},{\"end\":143897,\"start\":143895},{\"end\":143910,\"start\":143908},{\"end\":144175,\"start\":144171},{\"end\":144187,\"start\":144184},{\"end\":144201,\"start\":144198},{\"end\":144210,\"start\":144207},{\"end\":144420,\"start\":144416},{\"end\":144432,\"start\":144429},{\"end\":144441,\"start\":144438},{\"end\":144663,\"start\":144659},{\"end\":144677,\"start\":144673},{\"end\":144687,\"start\":144683},{\"end\":144698,\"start\":144694},{\"end\":144959,\"start\":144955},{\"end\":144966,\"start\":144964},{\"end\":144973,\"start\":144971},{\"end\":144982,\"start\":144979},{\"end\":144991,\"start\":144988},{\"end\":145276,\"start\":145272},{\"end\":145291,\"start\":145287},{\"end\":145307,\"start\":145303},{\"end\":145588,\"start\":145584},{\"end\":145596,\"start\":145594},{\"end\":145610,\"start\":145606},{\"end\":145629,\"start\":145616},{\"end\":145635,\"start\":145631},{\"end\":145929,\"start\":145926},{\"end\":145941,\"start\":145939},{\"end\":145959,\"start\":145953},{\"end\":146215,\"start\":146210},{\"end\":146231,\"start\":146225},{\"end\":146248,\"start\":146240},{\"end\":146266,\"start\":146257},{\"end\":146284,\"start\":146274},{\"end\":146574,\"start\":146569},{\"end\":146590,\"start\":146584},{\"end\":146611,\"start\":146604},{\"end\":146629,\"start\":146619},{\"end\":146854,\"start\":146849},{\"end\":146875,\"start\":146868},{\"end\":146898,\"start\":146883},{\"end\":146916,\"start\":146906},{\"end\":147137,\"start\":147130},{\"end\":147149,\"start\":147143},{\"end\":147307,\"start\":147300},{\"end\":147605,\"start\":147601},{\"end\":147618,\"start\":147613},{\"end\":147629,\"start\":147622},{\"end\":147642,\"start\":147636},{\"end\":147646,\"start\":147644},{\"end\":147932,\"start\":147929},{\"end\":147943,\"start\":147939},{\"end\":147951,\"start\":147949},{\"end\":147961,\"start\":147959},{\"end\":147975,\"start\":147973},{\"end\":147988,\"start\":147986},{\"end\":148002,\"start\":147997},{\"end\":148327,\"start\":148325},{\"end\":148345,\"start\":148338},{\"end\":148355,\"start\":148353},{\"end\":148378,\"start\":148366},{\"end\":148678,\"start\":148676},{\"end\":148689,\"start\":148687},{\"end\":148705,\"start\":148701},{\"end\":148714,\"start\":148711},{\"end\":148727,\"start\":148723},{\"end\":148740,\"start\":148738},{\"end\":149043,\"start\":149041},{\"end\":149053,\"start\":149051},{\"end\":149061,\"start\":149059},{\"end\":149070,\"start\":149067},{\"end\":149081,\"start\":149078},{\"end\":149095,\"start\":149090},{\"end\":149106,\"start\":149101},{\"end\":149119,\"start\":149114},{\"end\":149132,\"start\":149128},{\"end\":149447,\"start\":149444},{\"end\":149459,\"start\":149455},{\"end\":149471,\"start\":149467},{\"end\":149489,\"start\":149480},{\"end\":149504,\"start\":149498},{\"end\":149776,\"start\":149774},{\"end\":149786,\"start\":149783},{\"end\":149797,\"start\":149793},{\"end\":149804,\"start\":149802},{\"end\":149813,\"start\":149810},{\"end\":149829,\"start\":149825},{\"end\":150097,\"start\":150089},{\"end\":150119,\"start\":150109},{\"end\":150142,\"start\":150137},{\"end\":150414,\"start\":150409},{\"end\":150423,\"start\":150419},{\"end\":150437,\"start\":150432},{\"end\":150450,\"start\":150447},{\"end\":150464,\"start\":150460},{\"end\":150476,\"start\":150473},{\"end\":150766,\"start\":150761},{\"end\":150778,\"start\":150775},{\"end\":150786,\"start\":150784},{\"end\":150799,\"start\":150796},{\"end\":150812,\"start\":150809},{\"end\":151104,\"start\":151099},{\"end\":151113,\"start\":151110},{\"end\":151128,\"start\":151125},{\"end\":151139,\"start\":151137},{\"end\":151418,\"start\":151414},{\"end\":151434,\"start\":151430},{\"end\":151449,\"start\":151445},{\"end\":151458,\"start\":151455},{\"end\":151471,\"start\":151469},{\"end\":151727,\"start\":151723},{\"end\":151739,\"start\":151734},{\"end\":151941,\"start\":151937},{\"end\":151952,\"start\":151950},{\"end\":151966,\"start\":151963},{\"end\":151978,\"start\":151975},{\"end\":151993,\"start\":151988},{\"end\":152258,\"start\":152254},{\"end\":152276,\"start\":152264},{\"end\":152293,\"start\":152286},{\"end\":152305,\"start\":152302},{\"end\":152320,\"start\":152314},{\"end\":152584,\"start\":152579},{\"end\":152597,\"start\":152594},{\"end\":152606,\"start\":152604},{\"end\":152614,\"start\":152612},{\"end\":152626,\"start\":152623},{\"end\":152641,\"start\":152637},{\"end\":152651,\"start\":152648},{\"end\":152664,\"start\":152660},{\"end\":152679,\"start\":152675},{\"end\":152693,\"start\":152690},{\"end\":153042,\"start\":153038},{\"end\":153050,\"start\":153048},{\"end\":153064,\"start\":153061},{\"end\":153342,\"start\":153338},{\"end\":153351,\"start\":153348},{\"end\":153361,\"start\":153358},{\"end\":153375,\"start\":153371},{\"end\":153388,\"start\":153382},{\"end\":153654,\"start\":153650},{\"end\":153668,\"start\":153665},{\"end\":153677,\"start\":153674},{\"end\":153685,\"start\":153683},{\"end\":153697,\"start\":153693},{\"end\":153947,\"start\":153943},{\"end\":153956,\"start\":153953},{\"end\":153969,\"start\":153965},{\"end\":153982,\"start\":153978},{\"end\":153996,\"start\":153991}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":49378119},\"end\":107828,\"start\":107493},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":210716092},\"end\":108167,\"start\":107830},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":218517472},\"end\":108499,\"start\":108169},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":204743650},\"end\":108760,\"start\":108501},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":18234945},\"end\":109114,\"start\":108762},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":49669237},\"end\":109399,\"start\":109116},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":26201011},\"end\":109661,\"start\":109401},{\"attributes\":{\"id\":\"b7\"},\"end\":109959,\"start\":109663},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":84182572},\"end\":110238,\"start\":109961},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":150373675},\"end\":110483,\"start\":110240},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":52017209},\"end\":110870,\"start\":110485},{\"attributes\":{\"id\":\"b11\"},\"end\":111237,\"start\":110872},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":5556270},\"end\":111574,\"start\":111239},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":218518034},\"end\":111926,\"start\":111576},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":15300052},\"end\":112255,\"start\":111928},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":215722835},\"end\":112556,\"start\":112257},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":49362428},\"end\":112802,\"start\":112558},{\"attributes\":{\"id\":\"b17\"},\"end\":113248,\"start\":112804},{\"attributes\":{\"id\":\"b18\"},\"end\":113604,\"start\":113250},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":9928823},\"end\":113923,\"start\":113606},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":19056247},\"end\":114279,\"start\":113925},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":84182601},\"end\":114571,\"start\":114281},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":203638815},\"end\":114794,\"start\":114573},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":4657352},\"end\":115152,\"start\":114796},{\"attributes\":{\"id\":\"b24\"},\"end\":115460,\"start\":115154},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":84183346},\"end\":115799,\"start\":115462},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":208882127},\"end\":116094,\"start\":115801},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":39898715},\"end\":116390,\"start\":116096},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":215814095},\"end\":117049,\"start\":116392},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":1568498},\"end\":117280,\"start\":117051},{\"attributes\":{\"id\":\"b30\"},\"end\":117437,\"start\":117282},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":47021242},\"end\":117600,\"start\":117439},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":11540100},\"end\":117781,\"start\":117602},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":84182635},\"end\":118060,\"start\":117783},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":84182692},\"end\":118415,\"start\":118062},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":174800638},\"end\":118695,\"start\":118417},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":33064240},\"end\":119070,\"start\":118697},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":12440383},\"end\":119303,\"start\":119072},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":53056070},\"end\":119544,\"start\":119305},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":2309950},\"end\":119816,\"start\":119546},{\"attributes\":{\"id\":\"b40\"},\"end\":120167,\"start\":119818},{\"attributes\":{\"id\":\"b41\"},\"end\":120516,\"start\":120169},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":56208985},\"end\":120843,\"start\":120518},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":49584534},\"end\":121040,\"start\":120845},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":215722119},\"end\":121321,\"start\":121042},{\"attributes\":{\"id\":\"b45\"},\"end\":121497,\"start\":121323},{\"attributes\":{\"id\":\"b46\"},\"end\":121751,\"start\":121499},{\"attributes\":{\"id\":\"b47\"},\"end\":121957,\"start\":121753},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":67856492},\"end\":122283,\"start\":121959},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":9237290},\"end\":122590,\"start\":122285},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":4611331},\"end\":122830,\"start\":122592},{\"attributes\":{\"id\":\"b51\"},\"end\":123159,\"start\":122832},{\"attributes\":{\"id\":\"b52\"},\"end\":123561,\"start\":123161},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":141059016},\"end\":123872,\"start\":123563},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":20072317},\"end\":124207,\"start\":123874},{\"attributes\":{\"id\":\"b55\"},\"end\":124602,\"start\":124209},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":9203280},\"end\":124930,\"start\":124604},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":49862170},\"end\":125322,\"start\":124932},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":46939411},\"end\":125627,\"start\":125324},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":59606259},\"end\":125936,\"start\":125629},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":1779661},\"end\":126110,\"start\":125938},{\"attributes\":{\"id\":\"b61\"},\"end\":126525,\"start\":126112},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":215723970},\"end\":126802,\"start\":126527},{\"attributes\":{\"id\":\"b63\"},\"end\":126918,\"start\":126804},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":1474148},\"end\":127205,\"start\":126920},{\"attributes\":{\"id\":\"b65\"},\"end\":127495,\"start\":127207},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":212733953},\"end\":127964,\"start\":127497},{\"attributes\":{\"doi\":\"arXiv:2006.14244\",\"id\":\"b67\"},\"end\":128345,\"start\":127966},{\"attributes\":{\"id\":\"b68\"},\"end\":128587,\"start\":128347},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":52068707},\"end\":128776,\"start\":128589},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":49558277},\"end\":129077,\"start\":128778},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":155144146},\"end\":129458,\"start\":129079},{\"attributes\":{\"doi\":\"arXiv:2005.11728\",\"id\":\"b72\"},\"end\":129717,\"start\":129460},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":2599319},\"end\":130036,\"start\":129719},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":4619305},\"end\":130329,\"start\":130038},{\"attributes\":{\"id\":\"b75\"},\"end\":130572,\"start\":130331},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":202577456},\"end\":130847,\"start\":130574},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":221783357},\"end\":131055,\"start\":130849},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":38926033},\"end\":131314,\"start\":131057},{\"attributes\":{\"id\":\"b79\"},\"end\":131694,\"start\":131316},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":207987615},\"end\":132046,\"start\":131696},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":209862846},\"end\":132257,\"start\":132048},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":174800859},\"end\":132564,\"start\":132259},{\"attributes\":{\"id\":\"b83\",\"matched_paper_id\":129940547},\"end\":132827,\"start\":132566},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":15619658},\"end\":133134,\"start\":132829},{\"attributes\":{\"doi\":\"MSR. IEEE\",\"id\":\"b85\"},\"end\":133529,\"start\":133136},{\"attributes\":{\"id\":\"b86\",\"matched_paper_id\":53090174},\"end\":133847,\"start\":133531},{\"attributes\":{\"id\":\"b87\",\"matched_paper_id\":131773},\"end\":134264,\"start\":133849},{\"attributes\":{\"id\":\"b88\"},\"end\":134642,\"start\":134266},{\"attributes\":{\"id\":\"b89\"},\"end\":135051,\"start\":134644},{\"attributes\":{\"id\":\"b90\"},\"end\":135453,\"start\":135053},{\"attributes\":{\"id\":\"b91\",\"matched_paper_id\":208248243},\"end\":135898,\"start\":135455},{\"attributes\":{\"id\":\"b92\",\"matched_paper_id\":4616133},\"end\":136215,\"start\":135900},{\"attributes\":{\"id\":\"b93\",\"matched_paper_id\":211829736},\"end\":136516,\"start\":136217},{\"attributes\":{\"id\":\"b94\",\"matched_paper_id\":215866632},\"end\":136866,\"start\":136518},{\"attributes\":{\"id\":\"b95\",\"matched_paper_id\":50771430},\"end\":137207,\"start\":136868},{\"attributes\":{\"id\":\"b96\"},\"end\":137515,\"start\":137209},{\"attributes\":{\"id\":\"b97\",\"matched_paper_id\":195298507},\"end\":137759,\"start\":137517},{\"attributes\":{\"id\":\"b98\",\"matched_paper_id\":13134455},\"end\":138076,\"start\":137761},{\"attributes\":{\"id\":\"b99\"},\"end\":138273,\"start\":138078},{\"attributes\":{\"id\":\"b100\",\"matched_paper_id\":201142074},\"end\":138556,\"start\":138275},{\"attributes\":{\"id\":\"b101\",\"matched_paper_id\":51979905},\"end\":138889,\"start\":138558},{\"attributes\":{\"id\":\"b102\",\"matched_paper_id\":201130938},\"end\":139281,\"start\":138891},{\"attributes\":{\"id\":\"b103\",\"matched_paper_id\":11315392},\"end\":139621,\"start\":139283},{\"attributes\":{\"id\":\"b104\",\"matched_paper_id\":202787142},\"end\":139892,\"start\":139623},{\"attributes\":{\"id\":\"b105\",\"matched_paper_id\":4651225},\"end\":140297,\"start\":139894},{\"attributes\":{\"id\":\"b106\",\"matched_paper_id\":209439473},\"end\":140583,\"start\":140299},{\"attributes\":{\"id\":\"b107\"},\"end\":141020,\"start\":140585},{\"attributes\":{\"id\":\"b108\",\"matched_paper_id\":56895558},\"end\":141339,\"start\":141022},{\"attributes\":{\"id\":\"b109\",\"matched_paper_id\":209066874},\"end\":141601,\"start\":141341},{\"attributes\":{\"id\":\"b110\",\"matched_paper_id\":214254122},\"end\":141904,\"start\":141603},{\"attributes\":{\"id\":\"b111\",\"matched_paper_id\":3292103},\"end\":142209,\"start\":141906},{\"attributes\":{\"id\":\"b112\",\"matched_paper_id\":46902434},\"end\":142604,\"start\":142211},{\"attributes\":{\"id\":\"b113\",\"matched_paper_id\":56517510},\"end\":143040,\"start\":142606},{\"attributes\":{\"id\":\"b114\",\"matched_paper_id\":211118610},\"end\":143405,\"start\":143042},{\"attributes\":{\"id\":\"b115\"},\"end\":143752,\"start\":143407},{\"attributes\":{\"id\":\"b116\",\"matched_paper_id\":52069701},\"end\":144101,\"start\":143754},{\"attributes\":{\"id\":\"b117\"},\"end\":144345,\"start\":144103},{\"attributes\":{\"id\":\"b118\",\"matched_paper_id\":10769502},\"end\":144584,\"start\":144347},{\"attributes\":{\"id\":\"b119\",\"matched_paper_id\":195298516},\"end\":144857,\"start\":144586},{\"attributes\":{\"id\":\"b120\",\"matched_paper_id\":211205176},\"end\":145174,\"start\":144859},{\"attributes\":{\"id\":\"b121\",\"matched_paper_id\":155630443},\"end\":145487,\"start\":145176},{\"attributes\":{\"id\":\"b122\",\"matched_paper_id\":211119929},\"end\":145832,\"start\":145489},{\"attributes\":{\"id\":\"b123\"},\"end\":146112,\"start\":145834},{\"attributes\":{\"id\":\"b124\",\"matched_paper_id\":13578285},\"end\":146505,\"start\":146114},{\"attributes\":{\"id\":\"b125\",\"matched_paper_id\":14867364},\"end\":146796,\"start\":146507},{\"attributes\":{\"id\":\"b126\",\"matched_paper_id\":367166},\"end\":147081,\"start\":146798},{\"attributes\":{\"id\":\"b127\"},\"end\":147227,\"start\":147083},{\"attributes\":{\"id\":\"b128\",\"matched_paper_id\":201570273},\"end\":147504,\"start\":147229},{\"attributes\":{\"id\":\"b129\",\"matched_paper_id\":54445369},\"end\":147829,\"start\":147506},{\"attributes\":{\"id\":\"b130\",\"matched_paper_id\":84182749},\"end\":148224,\"start\":147831},{\"attributes\":{\"id\":\"b131\",\"matched_paper_id\":52939211},\"end\":148564,\"start\":148226},{\"attributes\":{\"id\":\"b132\",\"matched_paper_id\":17547160},\"end\":148959,\"start\":148566},{\"attributes\":{\"id\":\"b133\",\"matched_paper_id\":202785943},\"end\":149354,\"start\":148961},{\"attributes\":{\"id\":\"b134\",\"matched_paper_id\":43922261},\"end\":149699,\"start\":149356},{\"attributes\":{\"id\":\"b135\",\"matched_paper_id\":174803974},\"end\":150004,\"start\":149701},{\"attributes\":{\"id\":\"b136\",\"matched_paper_id\":209480585},\"end\":150329,\"start\":150006},{\"attributes\":{\"id\":\"b137\",\"matched_paper_id\":174799700},\"end\":150670,\"start\":150331},{\"attributes\":{\"id\":\"b138\",\"matched_paper_id\":202548549},\"end\":151003,\"start\":150672},{\"attributes\":{\"id\":\"b139\",\"matched_paper_id\":84182792},\"end\":151324,\"start\":151005},{\"attributes\":{\"id\":\"b140\",\"matched_paper_id\":174800466},\"end\":151665,\"start\":151326},{\"attributes\":{\"id\":\"b141\",\"matched_paper_id\":53081316},\"end\":151845,\"start\":151667},{\"attributes\":{\"id\":\"b142\",\"matched_paper_id\":174820105},\"end\":152186,\"start\":151847},{\"attributes\":{\"id\":\"b143\"},\"end\":152482,\"start\":152188},{\"attributes\":{\"id\":\"b144\"},\"end\":152947,\"start\":152484},{\"attributes\":{\"id\":\"b145\",\"matched_paper_id\":215852621},\"end\":153223,\"start\":152949},{\"attributes\":{\"id\":\"b146\",\"matched_paper_id\":67891926},\"end\":153594,\"start\":153225},{\"attributes\":{\"id\":\"b147\",\"matched_paper_id\":198359124},\"end\":153844,\"start\":153596},{\"attributes\":{\"id\":\"b148\",\"matched_paper_id\":199586098},\"end\":154192,\"start\":153846}]", "bib_title": "[{\"end\":107591,\"start\":107493},{\"end\":107874,\"start\":107830},{\"end\":108239,\"start\":108169},{\"end\":108554,\"start\":108501},{\"end\":108853,\"start\":108762},{\"end\":109189,\"start\":109116},{\"end\":109472,\"start\":109401},{\"end\":110047,\"start\":109961},{\"end\":110274,\"start\":110240},{\"end\":110589,\"start\":110485},{\"end\":111329,\"start\":111239},{\"end\":111634,\"start\":111576},{\"end\":111977,\"start\":111928},{\"end\":112327,\"start\":112257},{\"end\":112596,\"start\":112558},{\"end\":113688,\"start\":113606},{\"end\":113996,\"start\":113925},{\"end\":114361,\"start\":114281},{\"end\":114629,\"start\":114573},{\"end\":114864,\"start\":114796},{\"end\":115531,\"start\":115462},{\"end\":115858,\"start\":115801},{\"end\":116185,\"start\":116096},{\"end\":116530,\"start\":116392},{\"end\":117097,\"start\":117051},{\"end\":117455,\"start\":117439},{\"end\":117619,\"start\":117602},{\"end\":117802,\"start\":117783},{\"end\":118129,\"start\":118062},{\"end\":118507,\"start\":118417},{\"end\":118788,\"start\":118697},{\"end\":119098,\"start\":119072},{\"end\":119333,\"start\":119305},{\"end\":119592,\"start\":119546},{\"end\":120601,\"start\":120518},{\"end\":120873,\"start\":120845},{\"end\":121109,\"start\":121042},{\"end\":122046,\"start\":121959},{\"end\":122369,\"start\":122285},{\"end\":122641,\"start\":122592},{\"end\":123631,\"start\":123563},{\"end\":123990,\"start\":123874},{\"end\":124680,\"start\":124604},{\"end\":124957,\"start\":124932},{\"end\":125396,\"start\":125324},{\"end\":125708,\"start\":125629},{\"end\":125951,\"start\":125938},{\"end\":126593,\"start\":126527},{\"end\":126977,\"start\":126920},{\"end\":127589,\"start\":127497},{\"end\":128631,\"start\":128589},{\"end\":128844,\"start\":128778},{\"end\":129134,\"start\":129079},{\"end\":129769,\"start\":129719},{\"end\":130100,\"start\":130038},{\"end\":130623,\"start\":130574},{\"end\":130889,\"start\":130849},{\"end\":131125,\"start\":131057},{\"end\":131780,\"start\":131696},{\"end\":132086,\"start\":132048},{\"end\":132337,\"start\":132259},{\"end\":132629,\"start\":132566},{\"end\":132889,\"start\":132829},{\"end\":133608,\"start\":133531},{\"end\":133891,\"start\":133849},{\"end\":135546,\"start\":135455},{\"end\":135966,\"start\":135900},{\"end\":136273,\"start\":136217},{\"end\":136616,\"start\":136518},{\"end\":136939,\"start\":136868},{\"end\":137586,\"start\":137517},{\"end\":137848,\"start\":137761},{\"end\":138337,\"start\":138275},{\"end\":138674,\"start\":138558},{\"end\":138989,\"start\":138891},{\"end\":139347,\"start\":139283},{\"end\":139685,\"start\":139623},{\"end\":139975,\"start\":139894},{\"end\":140354,\"start\":140299},{\"end\":141105,\"start\":141022},{\"end\":141421,\"start\":141341},{\"end\":141691,\"start\":141603},{\"end\":142001,\"start\":141906},{\"end\":142283,\"start\":142211},{\"end\":142698,\"start\":142606},{\"end\":143132,\"start\":143042},{\"end\":143831,\"start\":143754},{\"end\":144409,\"start\":144347},{\"end\":144649,\"start\":144586},{\"end\":144946,\"start\":144859},{\"end\":145267,\"start\":145176},{\"end\":145575,\"start\":145489},{\"end\":146201,\"start\":146114},{\"end\":146560,\"start\":146507},{\"end\":146840,\"start\":146798},{\"end\":147287,\"start\":147229},{\"end\":147595,\"start\":147506},{\"end\":147923,\"start\":147831},{\"end\":148317,\"start\":148226},{\"end\":148668,\"start\":148566},{\"end\":149034,\"start\":148961},{\"end\":149432,\"start\":149356},{\"end\":149768,\"start\":149701},{\"end\":150078,\"start\":150006},{\"end\":150402,\"start\":150331},{\"end\":150752,\"start\":150672},{\"end\":151092,\"start\":151005},{\"end\":151406,\"start\":151326},{\"end\":151716,\"start\":151667},{\"end\":151931,\"start\":151847},{\"end\":153030,\"start\":152949},{\"end\":153329,\"start\":153225},{\"end\":153640,\"start\":153596},{\"end\":153938,\"start\":153846}]", "bib_author": "[{\"end\":107608,\"start\":107593},{\"end\":107625,\"start\":107608},{\"end\":107641,\"start\":107625},{\"end\":107895,\"start\":107876},{\"end\":107914,\"start\":107895},{\"end\":107931,\"start\":107914},{\"end\":107948,\"start\":107931},{\"end\":107962,\"start\":107948},{\"end\":107976,\"start\":107962},{\"end\":108255,\"start\":108241},{\"end\":108271,\"start\":108255},{\"end\":108280,\"start\":108271},{\"end\":108290,\"start\":108280},{\"end\":108302,\"start\":108290},{\"end\":108315,\"start\":108302},{\"end\":108572,\"start\":108556},{\"end\":108586,\"start\":108572},{\"end\":108607,\"start\":108586},{\"end\":108876,\"start\":108855},{\"end\":108890,\"start\":108876},{\"end\":108900,\"start\":108890},{\"end\":108915,\"start\":108900},{\"end\":108924,\"start\":108915},{\"end\":109205,\"start\":109191},{\"end\":109221,\"start\":109205},{\"end\":109236,\"start\":109221},{\"end\":109490,\"start\":109474},{\"end\":109510,\"start\":109490},{\"end\":109758,\"start\":109742},{\"end\":109777,\"start\":109758},{\"end\":110060,\"start\":110049},{\"end\":110077,\"start\":110060},{\"end\":110293,\"start\":110276},{\"end\":110304,\"start\":110293},{\"end\":110317,\"start\":110304},{\"end\":110330,\"start\":110317},{\"end\":110346,\"start\":110330},{\"end\":110602,\"start\":110591},{\"end\":110615,\"start\":110602},{\"end\":110629,\"start\":110615},{\"end\":110643,\"start\":110629},{\"end\":110655,\"start\":110643},{\"end\":110993,\"start\":110978},{\"end\":111002,\"start\":110993},{\"end\":111015,\"start\":111002},{\"end\":111031,\"start\":111015},{\"end\":111041,\"start\":111031},{\"end\":111344,\"start\":111331},{\"end\":111359,\"start\":111344},{\"end\":111375,\"start\":111359},{\"end\":111385,\"start\":111375},{\"end\":111650,\"start\":111636},{\"end\":111665,\"start\":111650},{\"end\":111681,\"start\":111665},{\"end\":111690,\"start\":111681},{\"end\":111702,\"start\":111690},{\"end\":111715,\"start\":111702},{\"end\":111729,\"start\":111715},{\"end\":112003,\"start\":111979},{\"end\":112018,\"start\":112003},{\"end\":112031,\"start\":112018},{\"end\":112043,\"start\":112031},{\"end\":112057,\"start\":112043},{\"end\":112070,\"start\":112057},{\"end\":112349,\"start\":112329},{\"end\":112368,\"start\":112349},{\"end\":112383,\"start\":112368},{\"end\":112613,\"start\":112598},{\"end\":112632,\"start\":112613},{\"end\":112649,\"start\":112632},{\"end\":112663,\"start\":112649},{\"end\":112914,\"start\":112899},{\"end\":112926,\"start\":112914},{\"end\":112937,\"start\":112926},{\"end\":112948,\"start\":112937},{\"end\":112959,\"start\":112948},{\"end\":112974,\"start\":112959},{\"end\":112988,\"start\":112974},{\"end\":113002,\"start\":112988},{\"end\":113007,\"start\":113002},{\"end\":113339,\"start\":113324},{\"end\":113352,\"start\":113339},{\"end\":113364,\"start\":113352},{\"end\":113375,\"start\":113364},{\"end\":113389,\"start\":113375},{\"end\":113402,\"start\":113389},{\"end\":113416,\"start\":113402},{\"end\":113699,\"start\":113690},{\"end\":114015,\"start\":113998},{\"end\":114032,\"start\":114015},{\"end\":114051,\"start\":114032},{\"end\":114069,\"start\":114051},{\"end\":114077,\"start\":114069},{\"end\":114377,\"start\":114363},{\"end\":114387,\"start\":114377},{\"end\":114403,\"start\":114387},{\"end\":114644,\"start\":114631},{\"end\":114658,\"start\":114644},{\"end\":114663,\"start\":114658},{\"end\":114882,\"start\":114866},{\"end\":114901,\"start\":114882},{\"end\":114917,\"start\":114901},{\"end\":114931,\"start\":114917},{\"end\":114950,\"start\":114931},{\"end\":115244,\"start\":115229},{\"end\":115254,\"start\":115244},{\"end\":115268,\"start\":115254},{\"end\":115280,\"start\":115268},{\"end\":115293,\"start\":115280},{\"end\":115541,\"start\":115533},{\"end\":115556,\"start\":115541},{\"end\":115572,\"start\":115556},{\"end\":115582,\"start\":115572},{\"end\":115592,\"start\":115582},{\"end\":115607,\"start\":115592},{\"end\":115868,\"start\":115860},{\"end\":115878,\"start\":115868},{\"end\":115890,\"start\":115878},{\"end\":115900,\"start\":115890},{\"end\":115910,\"start\":115900},{\"end\":115924,\"start\":115910},{\"end\":116201,\"start\":116187},{\"end\":116211,\"start\":116201},{\"end\":116224,\"start\":116211},{\"end\":116561,\"start\":116532},{\"end\":116581,\"start\":116561},{\"end\":116594,\"start\":116581},{\"end\":116610,\"start\":116594},{\"end\":116626,\"start\":116610},{\"end\":116641,\"start\":116626},{\"end\":116657,\"start\":116641},{\"end\":116675,\"start\":116657},{\"end\":116690,\"start\":116675},{\"end\":116699,\"start\":116690},{\"end\":117118,\"start\":117099},{\"end\":117130,\"start\":117118},{\"end\":117145,\"start\":117130},{\"end\":117313,\"start\":117297},{\"end\":117328,\"start\":117313},{\"end\":117345,\"start\":117328},{\"end\":117470,\"start\":117457},{\"end\":117484,\"start\":117470},{\"end\":117497,\"start\":117484},{\"end\":117634,\"start\":117621},{\"end\":117648,\"start\":117634},{\"end\":117663,\"start\":117648},{\"end\":117676,\"start\":117663},{\"end\":117817,\"start\":117804},{\"end\":117833,\"start\":117817},{\"end\":117847,\"start\":117833},{\"end\":117858,\"start\":117847},{\"end\":117867,\"start\":117858},{\"end\":117879,\"start\":117867},{\"end\":117889,\"start\":117879},{\"end\":117899,\"start\":117889},{\"end\":118144,\"start\":118131},{\"end\":118158,\"start\":118144},{\"end\":118170,\"start\":118158},{\"end\":118184,\"start\":118170},{\"end\":118195,\"start\":118184},{\"end\":118204,\"start\":118195},{\"end\":118215,\"start\":118204},{\"end\":118519,\"start\":118509},{\"end\":118533,\"start\":118519},{\"end\":118804,\"start\":118790},{\"end\":118817,\"start\":118804},{\"end\":118833,\"start\":118817},{\"end\":118846,\"start\":118833},{\"end\":118860,\"start\":118846},{\"end\":119111,\"start\":119100},{\"end\":119120,\"start\":119111},{\"end\":119346,\"start\":119335},{\"end\":119369,\"start\":119346},{\"end\":119375,\"start\":119369},{\"end\":119383,\"start\":119375},{\"end\":119399,\"start\":119383},{\"end\":119410,\"start\":119399},{\"end\":119613,\"start\":119594},{\"end\":119629,\"start\":119613},{\"end\":119643,\"start\":119629},{\"end\":119914,\"start\":119901},{\"end\":119929,\"start\":119914},{\"end\":119945,\"start\":119929},{\"end\":119955,\"start\":119945},{\"end\":119973,\"start\":119955},{\"end\":120275,\"start\":120262},{\"end\":120289,\"start\":120275},{\"end\":120300,\"start\":120289},{\"end\":120311,\"start\":120300},{\"end\":120327,\"start\":120311},{\"end\":120331,\"start\":120327},{\"end\":120625,\"start\":120603},{\"end\":120639,\"start\":120625},{\"end\":120659,\"start\":120639},{\"end\":120884,\"start\":120875},{\"end\":120891,\"start\":120884},{\"end\":120900,\"start\":120891},{\"end\":120910,\"start\":120900},{\"end\":120919,\"start\":120910},{\"end\":121123,\"start\":121111},{\"end\":121131,\"start\":121123},{\"end\":121147,\"start\":121131},{\"end\":121158,\"start\":121147},{\"end\":121364,\"start\":121352},{\"end\":121373,\"start\":121364},{\"end\":121383,\"start\":121373},{\"end\":121398,\"start\":121383},{\"end\":121513,\"start\":121499},{\"end\":121526,\"start\":121513},{\"end\":121537,\"start\":121526},{\"end\":121549,\"start\":121537},{\"end\":121795,\"start\":121785},{\"end\":121810,\"start\":121795},{\"end\":121819,\"start\":121810},{\"end\":121829,\"start\":121819},{\"end\":121843,\"start\":121829},{\"end\":122063,\"start\":122048},{\"end\":122077,\"start\":122063},{\"end\":122086,\"start\":122077},{\"end\":122101,\"start\":122086},{\"end\":122385,\"start\":122371},{\"end\":122399,\"start\":122385},{\"end\":122416,\"start\":122399},{\"end\":122654,\"start\":122643},{\"end\":122666,\"start\":122654},{\"end\":122679,\"start\":122666},{\"end\":122688,\"start\":122679},{\"end\":122927,\"start\":122913},{\"end\":123279,\"start\":123269},{\"end\":123290,\"start\":123279},{\"end\":123301,\"start\":123290},{\"end\":123316,\"start\":123301},{\"end\":123332,\"start\":123316},{\"end\":123340,\"start\":123332},{\"end\":123645,\"start\":123633},{\"end\":123662,\"start\":123645},{\"end\":123679,\"start\":123662},{\"end\":123695,\"start\":123679},{\"end\":124003,\"start\":123992},{\"end\":124020,\"start\":124003},{\"end\":124282,\"start\":124266},{\"end\":124297,\"start\":124282},{\"end\":124314,\"start\":124297},{\"end\":124335,\"start\":124314},{\"end\":124352,\"start\":124335},{\"end\":124367,\"start\":124352},{\"end\":124385,\"start\":124367},{\"end\":124695,\"start\":124682},{\"end\":124712,\"start\":124695},{\"end\":124722,\"start\":124712},{\"end\":124737,\"start\":124722},{\"end\":124745,\"start\":124737},{\"end\":124971,\"start\":124959},{\"end\":124981,\"start\":124971},{\"end\":124985,\"start\":124981},{\"end\":125417,\"start\":125398},{\"end\":125435,\"start\":125417},{\"end\":125452,\"start\":125435},{\"end\":125729,\"start\":125710},{\"end\":125743,\"start\":125729},{\"end\":125760,\"start\":125743},{\"end\":125965,\"start\":125953},{\"end\":125980,\"start\":125965},{\"end\":125997,\"start\":125980},{\"end\":126238,\"start\":126224},{\"end\":126249,\"start\":126238},{\"end\":126261,\"start\":126249},{\"end\":126273,\"start\":126261},{\"end\":126287,\"start\":126273},{\"end\":126297,\"start\":126287},{\"end\":126608,\"start\":126595},{\"end\":126617,\"start\":126608},{\"end\":126629,\"start\":126617},{\"end\":126641,\"start\":126629},{\"end\":126991,\"start\":126979},{\"end\":127000,\"start\":126991},{\"end\":127015,\"start\":127000},{\"end\":127024,\"start\":127015},{\"end\":127039,\"start\":127024},{\"end\":127300,\"start\":127292},{\"end\":127308,\"start\":127300},{\"end\":127321,\"start\":127308},{\"end\":127337,\"start\":127321},{\"end\":127605,\"start\":127591},{\"end\":127616,\"start\":127605},{\"end\":127628,\"start\":127616},{\"end\":127640,\"start\":127628},{\"end\":127654,\"start\":127640},{\"end\":127665,\"start\":127654},{\"end\":127680,\"start\":127665},{\"end\":127691,\"start\":127680},{\"end\":127703,\"start\":127691},{\"end\":127709,\"start\":127703},{\"end\":127976,\"start\":127966},{\"end\":127988,\"start\":127976},{\"end\":127997,\"start\":127988},{\"end\":128007,\"start\":127997},{\"end\":128020,\"start\":128007},{\"end\":128033,\"start\":128020},{\"end\":128398,\"start\":128389},{\"end\":128410,\"start\":128398},{\"end\":128422,\"start\":128410},{\"end\":128432,\"start\":128422},{\"end\":128445,\"start\":128432},{\"end\":128455,\"start\":128445},{\"end\":128642,\"start\":128633},{\"end\":128654,\"start\":128642},{\"end\":128667,\"start\":128654},{\"end\":128855,\"start\":128846},{\"end\":128868,\"start\":128855},{\"end\":128882,\"start\":128868},{\"end\":128892,\"start\":128882},{\"end\":128905,\"start\":128892},{\"end\":129145,\"start\":129136},{\"end\":129158,\"start\":129145},{\"end\":129171,\"start\":129158},{\"end\":129191,\"start\":129171},{\"end\":129202,\"start\":129191},{\"end\":129212,\"start\":129202},{\"end\":129228,\"start\":129212},{\"end\":129241,\"start\":129228},{\"end\":129248,\"start\":129241},{\"end\":129472,\"start\":129460},{\"end\":129479,\"start\":129472},{\"end\":129489,\"start\":129479},{\"end\":129781,\"start\":129771},{\"end\":129796,\"start\":129781},{\"end\":129811,\"start\":129796},{\"end\":129825,\"start\":129811},{\"end\":129841,\"start\":129825},{\"end\":129855,\"start\":129841},{\"end\":130113,\"start\":130102},{\"end\":130124,\"start\":130113},{\"end\":130136,\"start\":130124},{\"end\":130149,\"start\":130136},{\"end\":130160,\"start\":130149},{\"end\":130376,\"start\":130362},{\"end\":130385,\"start\":130376},{\"end\":130395,\"start\":130385},{\"end\":130411,\"start\":130395},{\"end\":130427,\"start\":130411},{\"end\":130440,\"start\":130427},{\"end\":130639,\"start\":130625},{\"end\":130648,\"start\":130639},{\"end\":130666,\"start\":130648},{\"end\":130676,\"start\":130666},{\"end\":130689,\"start\":130676},{\"end\":130905,\"start\":130891},{\"end\":130914,\"start\":130905},{\"end\":130924,\"start\":130914},{\"end\":130937,\"start\":130924},{\"end\":131152,\"start\":131127},{\"end\":131165,\"start\":131152},{\"end\":131429,\"start\":131410},{\"end\":131445,\"start\":131429},{\"end\":131460,\"start\":131445},{\"end\":131471,\"start\":131460},{\"end\":131482,\"start\":131471},{\"end\":131491,\"start\":131482},{\"end\":131791,\"start\":131782},{\"end\":131807,\"start\":131791},{\"end\":131822,\"start\":131807},{\"end\":131834,\"start\":131822},{\"end\":131845,\"start\":131834},{\"end\":131858,\"start\":131845},{\"end\":132101,\"start\":132088},{\"end\":132115,\"start\":132101},{\"end\":132129,\"start\":132115},{\"end\":132366,\"start\":132339},{\"end\":132381,\"start\":132366},{\"end\":132389,\"start\":132381},{\"end\":132643,\"start\":132631},{\"end\":132658,\"start\":132643},{\"end\":132674,\"start\":132658},{\"end\":132901,\"start\":132891},{\"end\":132919,\"start\":132901},{\"end\":132926,\"start\":132919},{\"end\":133257,\"start\":133244},{\"end\":133276,\"start\":133257},{\"end\":133292,\"start\":133276},{\"end\":133304,\"start\":133292},{\"end\":133312,\"start\":133304},{\"end\":133619,\"start\":133610},{\"end\":133632,\"start\":133619},{\"end\":133642,\"start\":133632},{\"end\":133658,\"start\":133642},{\"end\":133669,\"start\":133658},{\"end\":133915,\"start\":133893},{\"end\":133928,\"start\":133915},{\"end\":133945,\"start\":133928},{\"end\":134368,\"start\":134347},{\"end\":134392,\"start\":134368},{\"end\":134408,\"start\":134392},{\"end\":134424,\"start\":134408},{\"end\":134442,\"start\":134424},{\"end\":134737,\"start\":134723},{\"end\":134748,\"start\":134737},{\"end\":134766,\"start\":134748},{\"end\":134778,\"start\":134766},{\"end\":134791,\"start\":134778},{\"end\":134803,\"start\":134791},{\"end\":134813,\"start\":134803},{\"end\":134827,\"start\":134813},{\"end\":135172,\"start\":135147},{\"end\":135191,\"start\":135172},{\"end\":135196,\"start\":135191},{\"end\":135208,\"start\":135196},{\"end\":135221,\"start\":135208},{\"end\":135232,\"start\":135221},{\"end\":135561,\"start\":135548},{\"end\":135574,\"start\":135561},{\"end\":135985,\"start\":135968},{\"end\":136003,\"start\":135985},{\"end\":136019,\"start\":136003},{\"end\":136034,\"start\":136019},{\"end\":136284,\"start\":136275},{\"end\":136292,\"start\":136284},{\"end\":136306,\"start\":136292},{\"end\":136320,\"start\":136306},{\"end\":136330,\"start\":136320},{\"end\":136343,\"start\":136330},{\"end\":136636,\"start\":136618},{\"end\":136655,\"start\":136636},{\"end\":136672,\"start\":136655},{\"end\":136953,\"start\":136941},{\"end\":136971,\"start\":136953},{\"end\":136985,\"start\":136971},{\"end\":137001,\"start\":136985},{\"end\":137016,\"start\":137001},{\"end\":137300,\"start\":137288},{\"end\":137310,\"start\":137300},{\"end\":137323,\"start\":137310},{\"end\":137335,\"start\":137323},{\"end\":137348,\"start\":137335},{\"end\":137602,\"start\":137588},{\"end\":137617,\"start\":137602},{\"end\":137864,\"start\":137850},{\"end\":137883,\"start\":137864},{\"end\":137900,\"start\":137883},{\"end\":138158,\"start\":138134},{\"end\":138356,\"start\":138339},{\"end\":138376,\"start\":138356},{\"end\":138395,\"start\":138376},{\"end\":138688,\"start\":138676},{\"end\":138699,\"start\":138688},{\"end\":139004,\"start\":138991},{\"end\":139020,\"start\":139004},{\"end\":139029,\"start\":139020},{\"end\":139039,\"start\":139029},{\"end\":139051,\"start\":139039},{\"end\":139064,\"start\":139051},{\"end\":139367,\"start\":139349},{\"end\":139375,\"start\":139367},{\"end\":139390,\"start\":139375},{\"end\":139407,\"start\":139390},{\"end\":139420,\"start\":139407},{\"end\":139429,\"start\":139420},{\"end\":139698,\"start\":139687},{\"end\":139711,\"start\":139698},{\"end\":139721,\"start\":139711},{\"end\":139734,\"start\":139721},{\"end\":139999,\"start\":139977},{\"end\":140024,\"start\":139999},{\"end\":140038,\"start\":140024},{\"end\":140052,\"start\":140038},{\"end\":140072,\"start\":140052},{\"end\":140366,\"start\":140356},{\"end\":140379,\"start\":140366},{\"end\":140393,\"start\":140379},{\"end\":140402,\"start\":140393},{\"end\":140413,\"start\":140402},{\"end\":140418,\"start\":140413},{\"end\":140713,\"start\":140694},{\"end\":140730,\"start\":140713},{\"end\":140747,\"start\":140730},{\"end\":140763,\"start\":140747},{\"end\":140785,\"start\":140763},{\"end\":141123,\"start\":141107},{\"end\":141140,\"start\":141123},{\"end\":141157,\"start\":141140},{\"end\":141437,\"start\":141423},{\"end\":141448,\"start\":141437},{\"end\":141707,\"start\":141693},{\"end\":141721,\"start\":141707},{\"end\":141730,\"start\":141721},{\"end\":142016,\"start\":142003},{\"end\":142025,\"start\":142016},{\"end\":142038,\"start\":142025},{\"end\":142301,\"start\":142285},{\"end\":142314,\"start\":142301},{\"end\":142331,\"start\":142314},{\"end\":142354,\"start\":142331},{\"end\":142368,\"start\":142354},{\"end\":142386,\"start\":142368},{\"end\":142716,\"start\":142700},{\"end\":142729,\"start\":142716},{\"end\":142746,\"start\":142729},{\"end\":142769,\"start\":142746},{\"end\":142783,\"start\":142769},{\"end\":142801,\"start\":142783},{\"end\":143147,\"start\":143134},{\"end\":143160,\"start\":143147},{\"end\":143173,\"start\":143160},{\"end\":143182,\"start\":143173},{\"end\":143200,\"start\":143182},{\"end\":143491,\"start\":143482},{\"end\":143505,\"start\":143491},{\"end\":143516,\"start\":143505},{\"end\":143529,\"start\":143516},{\"end\":143540,\"start\":143529},{\"end\":143549,\"start\":143540},{\"end\":143560,\"start\":143549},{\"end\":143842,\"start\":143833},{\"end\":143853,\"start\":143842},{\"end\":143863,\"start\":143853},{\"end\":143876,\"start\":143863},{\"end\":143890,\"start\":143876},{\"end\":143899,\"start\":143890},{\"end\":143912,\"start\":143899},{\"end\":144177,\"start\":144166},{\"end\":144189,\"start\":144177},{\"end\":144203,\"start\":144189},{\"end\":144212,\"start\":144203},{\"end\":144422,\"start\":144411},{\"end\":144434,\"start\":144422},{\"end\":144443,\"start\":144434},{\"end\":144665,\"start\":144651},{\"end\":144679,\"start\":144665},{\"end\":144689,\"start\":144679},{\"end\":144700,\"start\":144689},{\"end\":144961,\"start\":144948},{\"end\":144968,\"start\":144961},{\"end\":144975,\"start\":144968},{\"end\":144984,\"start\":144975},{\"end\":144993,\"start\":144984},{\"end\":145278,\"start\":145269},{\"end\":145293,\"start\":145278},{\"end\":145309,\"start\":145293},{\"end\":145590,\"start\":145577},{\"end\":145598,\"start\":145590},{\"end\":145612,\"start\":145598},{\"end\":145631,\"start\":145612},{\"end\":145637,\"start\":145631},{\"end\":145931,\"start\":145921},{\"end\":145943,\"start\":145931},{\"end\":145961,\"start\":145943},{\"end\":146217,\"start\":146203},{\"end\":146233,\"start\":146217},{\"end\":146250,\"start\":146233},{\"end\":146268,\"start\":146250},{\"end\":146286,\"start\":146268},{\"end\":146576,\"start\":146562},{\"end\":146592,\"start\":146576},{\"end\":146613,\"start\":146592},{\"end\":146631,\"start\":146613},{\"end\":146856,\"start\":146842},{\"end\":146877,\"start\":146856},{\"end\":146900,\"start\":146877},{\"end\":146918,\"start\":146900},{\"end\":147139,\"start\":147125},{\"end\":147151,\"start\":147139},{\"end\":147309,\"start\":147289},{\"end\":147607,\"start\":147597},{\"end\":147620,\"start\":147607},{\"end\":147631,\"start\":147620},{\"end\":147644,\"start\":147631},{\"end\":147648,\"start\":147644},{\"end\":147934,\"start\":147925},{\"end\":147945,\"start\":147934},{\"end\":147953,\"start\":147945},{\"end\":147963,\"start\":147953},{\"end\":147977,\"start\":147963},{\"end\":147990,\"start\":147977},{\"end\":148004,\"start\":147990},{\"end\":148329,\"start\":148319},{\"end\":148347,\"start\":148329},{\"end\":148357,\"start\":148347},{\"end\":148380,\"start\":148357},{\"end\":148680,\"start\":148670},{\"end\":148691,\"start\":148680},{\"end\":148707,\"start\":148691},{\"end\":148716,\"start\":148707},{\"end\":148729,\"start\":148716},{\"end\":148742,\"start\":148729},{\"end\":149045,\"start\":149036},{\"end\":149055,\"start\":149045},{\"end\":149063,\"start\":149055},{\"end\":149072,\"start\":149063},{\"end\":149083,\"start\":149072},{\"end\":149097,\"start\":149083},{\"end\":149108,\"start\":149097},{\"end\":149121,\"start\":149108},{\"end\":149134,\"start\":149121},{\"end\":149449,\"start\":149434},{\"end\":149461,\"start\":149449},{\"end\":149473,\"start\":149461},{\"end\":149491,\"start\":149473},{\"end\":149506,\"start\":149491},{\"end\":149778,\"start\":149770},{\"end\":149788,\"start\":149778},{\"end\":149799,\"start\":149788},{\"end\":149806,\"start\":149799},{\"end\":149815,\"start\":149806},{\"end\":149831,\"start\":149815},{\"end\":150099,\"start\":150080},{\"end\":150121,\"start\":150099},{\"end\":150144,\"start\":150121},{\"end\":150416,\"start\":150404},{\"end\":150425,\"start\":150416},{\"end\":150439,\"start\":150425},{\"end\":150452,\"start\":150439},{\"end\":150466,\"start\":150452},{\"end\":150478,\"start\":150466},{\"end\":150768,\"start\":150754},{\"end\":150780,\"start\":150768},{\"end\":150788,\"start\":150780},{\"end\":150801,\"start\":150788},{\"end\":150814,\"start\":150801},{\"end\":151106,\"start\":151094},{\"end\":151115,\"start\":151106},{\"end\":151130,\"start\":151115},{\"end\":151141,\"start\":151130},{\"end\":151420,\"start\":151408},{\"end\":151436,\"start\":151420},{\"end\":151451,\"start\":151436},{\"end\":151460,\"start\":151451},{\"end\":151473,\"start\":151460},{\"end\":151729,\"start\":151718},{\"end\":151741,\"start\":151729},{\"end\":151943,\"start\":151933},{\"end\":151954,\"start\":151943},{\"end\":151968,\"start\":151954},{\"end\":151980,\"start\":151968},{\"end\":151995,\"start\":151980},{\"end\":152260,\"start\":152247},{\"end\":152278,\"start\":152260},{\"end\":152295,\"start\":152278},{\"end\":152307,\"start\":152295},{\"end\":152322,\"start\":152307},{\"end\":152586,\"start\":152575},{\"end\":152599,\"start\":152586},{\"end\":152608,\"start\":152599},{\"end\":152616,\"start\":152608},{\"end\":152628,\"start\":152616},{\"end\":152643,\"start\":152628},{\"end\":152653,\"start\":152643},{\"end\":152666,\"start\":152653},{\"end\":152681,\"start\":152666},{\"end\":152695,\"start\":152681},{\"end\":153044,\"start\":153032},{\"end\":153052,\"start\":153044},{\"end\":153066,\"start\":153052},{\"end\":153344,\"start\":153331},{\"end\":153353,\"start\":153344},{\"end\":153363,\"start\":153353},{\"end\":153377,\"start\":153363},{\"end\":153390,\"start\":153377},{\"end\":153656,\"start\":153642},{\"end\":153670,\"start\":153656},{\"end\":153679,\"start\":153670},{\"end\":153687,\"start\":153679},{\"end\":153699,\"start\":153687},{\"end\":153949,\"start\":153940},{\"end\":153958,\"start\":153949},{\"end\":153971,\"start\":153958},{\"end\":153984,\"start\":153971},{\"end\":153998,\"start\":153984}]", "bib_venue": "[{\"end\":125156,\"start\":125079},{\"end\":134042,\"start\":134025},{\"end\":135683,\"start\":135637},{\"end\":107644,\"start\":107641},{\"end\":107979,\"start\":107976},{\"end\":108320,\"start\":108315},{\"end\":108618,\"start\":108607},{\"end\":108927,\"start\":108924},{\"end\":109246,\"start\":109236},{\"end\":109514,\"start\":109510},{\"end\":109740,\"start\":109663},{\"end\":110088,\"start\":110077},{\"end\":110349,\"start\":110346},{\"end\":110666,\"start\":110655},{\"end\":110976,\"start\":110872},{\"end\":111394,\"start\":111385},{\"end\":111734,\"start\":111729},{\"end\":112073,\"start\":112070},{\"end\":112394,\"start\":112383},{\"end\":112668,\"start\":112663},{\"end\":112897,\"start\":112804},{\"end\":113322,\"start\":113250},{\"end\":113755,\"start\":113699},{\"end\":114088,\"start\":114077},{\"end\":114414,\"start\":114403},{\"end\":114666,\"start\":114663},{\"end\":114961,\"start\":114950},{\"end\":115227,\"start\":115154},{\"end\":115618,\"start\":115607},{\"end\":115935,\"start\":115924},{\"end\":116227,\"start\":116224},{\"end\":116702,\"start\":116699},{\"end\":117154,\"start\":117145},{\"end\":117295,\"start\":117282},{\"end\":117507,\"start\":117497},{\"end\":117679,\"start\":117676},{\"end\":117910,\"start\":117899},{\"end\":118226,\"start\":118215},{\"end\":118543,\"start\":118533},{\"end\":118871,\"start\":118860},{\"end\":119173,\"start\":119120},{\"end\":119413,\"start\":119410},{\"end\":119661,\"start\":119643},{\"end\":119899,\"start\":119818},{\"end\":120260,\"start\":120169},{\"end\":120662,\"start\":120659},{\"end\":120929,\"start\":120919},{\"end\":121169,\"start\":121158},{\"end\":121350,\"start\":121323},{\"end\":121620,\"start\":121549},{\"end\":121783,\"start\":121753},{\"end\":122104,\"start\":122101},{\"end\":122425,\"start\":122416},{\"end\":122699,\"start\":122688},{\"end\":122911,\"start\":122832},{\"end\":123267,\"start\":123161},{\"end\":123705,\"start\":123695},{\"end\":124023,\"start\":124020},{\"end\":124264,\"start\":124209},{\"end\":124755,\"start\":124745},{\"end\":125077,\"start\":124985},{\"end\":125463,\"start\":125452},{\"end\":125770,\"start\":125760},{\"end\":126003,\"start\":125997},{\"end\":126222,\"start\":126112},{\"end\":126652,\"start\":126641},{\"end\":126822,\"start\":126806},{\"end\":127050,\"start\":127039},{\"end\":127290,\"start\":127207},{\"end\":127714,\"start\":127709},{\"end\":128130,\"start\":128049},{\"end\":128387,\"start\":128347},{\"end\":128670,\"start\":128667},{\"end\":128909,\"start\":128905},{\"end\":129258,\"start\":129248},{\"end\":129563,\"start\":129505},{\"end\":129865,\"start\":129855},{\"end\":130171,\"start\":130160},{\"end\":130360,\"start\":130331},{\"end\":130698,\"start\":130689},{\"end\":130940,\"start\":130937},{\"end\":131168,\"start\":131165},{\"end\":131408,\"start\":131316},{\"end\":131861,\"start\":131858},{\"end\":132140,\"start\":132129},{\"end\":132399,\"start\":132389},{\"end\":132684,\"start\":132674},{\"end\":132965,\"start\":132926},{\"end\":133242,\"start\":133136},{\"end\":133672,\"start\":133669},{\"end\":134023,\"start\":133945},{\"end\":134345,\"start\":134266},{\"end\":134721,\"start\":134644},{\"end\":135145,\"start\":135053},{\"end\":135635,\"start\":135574},{\"end\":136045,\"start\":136034},{\"end\":136346,\"start\":136343},{\"end\":136675,\"start\":136672},{\"end\":137025,\"start\":137016},{\"end\":137286,\"start\":137209},{\"end\":137626,\"start\":137617},{\"end\":137903,\"start\":137900},{\"end\":138132,\"start\":138078},{\"end\":138403,\"start\":138395},{\"end\":138703,\"start\":138699},{\"end\":139069,\"start\":139064},{\"end\":139440,\"start\":139429},{\"end\":139737,\"start\":139734},{\"end\":140083,\"start\":140072},{\"end\":140429,\"start\":140418},{\"end\":140692,\"start\":140585},{\"end\":141168,\"start\":141157},{\"end\":141451,\"start\":141448},{\"end\":141733,\"start\":141730},{\"end\":142041,\"start\":142038},{\"end\":142395,\"start\":142386},{\"end\":142806,\"start\":142801},{\"end\":143211,\"start\":143200},{\"end\":143480,\"start\":143407},{\"end\":143915,\"start\":143912},{\"end\":144164,\"start\":144103},{\"end\":144453,\"start\":144443},{\"end\":144709,\"start\":144700},{\"end\":145004,\"start\":144993},{\"end\":145312,\"start\":145309},{\"end\":145648,\"start\":145637},{\"end\":145919,\"start\":145834},{\"end\":146297,\"start\":146286},{\"end\":146640,\"start\":146631},{\"end\":146927,\"start\":146918},{\"end\":147123,\"start\":147083},{\"end\":147347,\"start\":147309},{\"end\":147651,\"start\":147648},{\"end\":148015,\"start\":148004},{\"end\":148384,\"start\":148380},{\"end\":148751,\"start\":148742},{\"end\":149137,\"start\":149134},{\"end\":149515,\"start\":149506},{\"end\":149841,\"start\":149831},{\"end\":150155,\"start\":150144},{\"end\":150488,\"start\":150478},{\"end\":150825,\"start\":150814},{\"end\":151152,\"start\":151141},{\"end\":151483,\"start\":151473},{\"end\":151744,\"start\":151741},{\"end\":152005,\"start\":151995},{\"end\":152245,\"start\":152188},{\"end\":152573,\"start\":152484},{\"end\":153069,\"start\":153066},{\"end\":153393,\"start\":153390},{\"end\":153702,\"start\":153699},{\"end\":154001,\"start\":153998}]"}}}, "year": 2023, "month": 12, "day": 17}