{"id": 232320204, "updated": "2023-10-06 05:51:00.915", "metadata": {"title": "Hybrid Edge Partitioner: Partitioning Large Power-Law Graphs under Memory Constraints", "authors": "[{\"first\":\"Ruben\",\"last\":\"Mayer\",\"middle\":[]},{\"first\":\"Hans-Arno\",\"last\":\"Jacobsen\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 2021 International Conference on Management of Data", "publication_date": {"year": 2021, "month": 3, "day": 23}, "abstract": "Distributed systems that manage and process graph-structured data internally solve a graph partitioning problem to minimize their communication overhead and query run-time. Besides computational complexity -- optimal graph partitioning is NP-hard -- another important consideration is the memory overhead. Real-world graphs often have an immense size, such that loading the complete graph into memory for partitioning is not economical or feasible. Currently, the common approach to reduce memory overhead is to rely on streaming partitioning algorithms. While the latest streaming algorithms lead to reasonable partitioning quality on some graphs, they are still not completely competitive to in-memory partitioners. In this paper, we propose a new system, Hybrid Edge Partitioner (HEP), that can partition graphs that fit partly into memory while yielding a high partitioning quality. HEP can flexibly adapt its memory overhead by separating the edge set of the graph into two sub-sets. One sub-set is partitioned by NE++, a novel, efficient in-memory algorithm, while the other sub-set is partitioned by a streaming approach. Our evaluations on large real-world graphs show that in many cases, HEP outperforms both in-memory partitioning and streaming partitioning at the same time. Hence, HEP is an attractive alternative to existing solutions that cannot fine-tune their memory overheads. Finally, we show that using HEP, we achieve a significant speedup of distributed graph processing jobs on Spark/GraphX compared to state-of-the-art partitioning algorithms.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2103.12594", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigmod/MayerJ21", "doi": "10.1145/3448016.3457300"}}, "content": {"source": {"pdf_hash": "14ef4fd54551db367c862598b50dddf094d85c32", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2103.12594v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2103.12594", "status": "GREEN"}}, "grobid": {"id": "5e3d728c0da9df9a16ba050ea90ccb641fbe086e", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/14ef4fd54551db367c862598b50dddf094d85c32.txt", "contents": "\nVirtual Event, China\nACMCopyright ACMJune 20-25, 2021. June 20-25, 2021. June 20-25, 2021\n\nRuben Mayer ruben.mayer@tum.de \nTechnical University of Munich\nUniversity of Toronto\n\n\nHans-Arno Jacobsen jacobsen@eecg.toronto.edu \nTechnical University of Munich\nUniversity of Toronto\n\n\nVirtual Event, China\n\nVirtual Event, China Proceedings of the 2021 International Conference on Management of Data (SIGMOD '21)\nNew York, NY, USA; New York, NY, USAACM14June 20-25, 2021. June 20-25, 2021. June 20-25, 202110.1145/3448016.3457300ACM Reference Format: Ruben Mayer and Hans-Arno Jacobsen. 2021. Hybrid Edge Partitioner: Parti-tioning Large Power-Law Graphs under Memory Constraints. In ACM ISBN 978-1-4503-8343-1/21/06. . . $15.00 (c) Owner 2021. This is the authors' version of the work. It is posted here for your personal use. Not for redistribution. The definitive version is published inGraph partitioning; distributed graph processing\nDistributed systems that manage and process graph-structured data internally solve a graph partitioning problem to minimize their communication overhead and query run-time. Besides computational complexity-optimal graph partitioning is NP-hard-another important consideration is the memory overhead. Real-world graphs often have an immense size, such that loading the complete graph into memory for partitioning is not economical or feasible. Currently, the common approach to reduce memory overhead is to rely on streaming partitioning algorithms. While the latest streaming algorithms lead to reasonable partitioning quality on some graphs, they are still not completely competitive to in-memory partitioners. In this paper, we propose a new system, Hybrid Edge Partitioner (HEP), that can partition graphs that fit partly into memory while yielding a high partitioning quality. HEP can flexibly adapt its memory overhead by separating the edge set of the graph into two sub-sets. One sub-set is partitioned by NE++, a novel, efficient in-memory algorithm, while the other sub-set is partitioned by a streaming approach. Our evaluations on large real-world graphs show that in many cases, HEP outperforms both in-memory partitioning and streaming partitioning at the same time. Hence, HEP is an attractive alternative to existing solutions that cannot finetune their memory overheads. Finally, we show that using HEP, we achieve a significant speedup of distributed graph processing jobs on Spark/GraphX compared to state-of-the-art partitioning algorithms.CCS CONCEPTS\u2022 Information systems \u2192 Graph-based database models; \u2022 Theory of computation \u2192 Graph algorithms analysis.\n\nINTRODUCTION\n\nIn the past decade, many specialized frameworks for managing and processing graph-structured data have emerged, such as Pregel [43], Giraph [1], GraphLab [41], PowerGraph [28], Spark/GraphX [29], Neo4j [63], and Trinity [56]. All of these system share a fundamental property: They keep a large graph distributed onto multiple machines and compute global queries that can potentially span the entire graph, such that communication between the machines is unavoidable in order to answer the queries. Thereby, the induced amount of communication in query processing depends on how the graph is placed on the machines: The lower the cut size 1 through the graph, the lower is the communication volume and the faster runs the query processing. This led to a renaissance of a classical problem in mathematics and computer science, being now researched in the context of optimizing specialized graph data processing systems: graph partitioning [21,34,35]. Fueled by the developments described above, the focus of graph partitioning research has shifted toward highly skewed graphs, i.e., graphs where the distribution of the vertex degrees roughly follows a power-law [28,51,66]. Such graphs are naturally emerging in many real-world situations, such as web graphs and online social networks. While the classical formulation of graph partitioning problems is centered around vertex partitioning, i.e., separating the vertices of the graph by cutting through the edges, it has been shown that edge partitioning is more effective in reducing the communication volume of distributed query processing on skewed power-law graphs [19,26]. In edge partitioning, the edges of the graph are separated by cutting through the vertices. Unfortunately, the edge partitioning problem is NP-hard [66]. Hence, a number of heuristic algorithms have been proposed to solve the edge partitioning problem for large graphs [47,49,58,61,66].\n\nExisting partitioning algorithms can be divided into two categories: In-memory algorithms [30,44,55,66] and streaming algorithms [28,32,47,51,64]. In-memory algorithms load the complete graph into memory, and, hence, have full flexibility to assign any edge to any partition at any time. On the other hand, streaming algorithms pass through the edge stream, only looking at one (or a small number of) edge(s) at a time. None of these two ways of graph partitioning is entirely satisfactory. In-memory algorithms may yield very good partitioning quality even on challenging graphs, but they consume a lot of memory. Streaming algorithms consume little memory, but even though they have been improved by sophisticated techniques such as window-based streaming [47] and multi-pass streaming [48], they do not yield the same partitioning quality on all graphs as the best in-memory algorithms. In current graph partitioning systems, the user has to decide for one of the two options, and then either provide a very large machine (or a cluster of machines) and get good partitioning quality [30,44,55,66] or a small machine and get worse partitioning quality [28,32,47,51,64].\n\nA further shortcoming in existing work is that many of the graph partitioning algorithms are described from a rather theoretical viewpoint without discussing their design and implementation [47,51,66]. This leaves opportunities for optimizations unexplored. For instance, in their implementation of the neighborhood expansion (NE) algorithm [66], the authors solve complex problems like the prevention of \"double assignments\" of edges (cf. Section 3.2.2) in a rather straight-forward and unoptimized manner.\n\nIn this paper, we propose a new hybrid approach of edge partitioning that fine-tunes the trade-off between memory consumption and partitioning quality. In doing so, we challenge the common pattern of partitioning algorithms and break out of the dichotomy of pure in-memory and pure streaming algorithms. Instead, we perform different partitioning strategies on different sub-graphs. Edges incident to at least one low-degree vertex are partitioned with a novel efficient in-memory partitioning algorithm called NE++. Edges incident to two high-degree vertices, however, are partitioned with stateful streaming partitioning. In doing so, partitioning state from in-memory partitioning is exploited in the streaming phase to increase the partitioning quality.\n\nIn detail, our contributions are the following:\n\n(1) We propose Hybrid Edge Partitioner (HEP), a novel graph partitioning system that follows the hybrid partitioning model outlined above. In many cases, HEP outperforms both in-memory partitioning and streaming partitioning at the same time. The code is available online: https://github.com/ mayerrn/hybrid_edge_partitioner. (2) We introduce NE++, a new, highly memory-efficient and fast extension of the well-known NE algorithm [66]. In particular, NE++ shows significantly lower run-time and memory overhead than NE while yielding the same partitioning quality. We achieve this by introducing two novel optimizations, namely graph pruning and lazy edge removal which make the in-memory partitioning phase of HEP extremely resource-efficient.\n\n(3) We describe in detail the design and implementation we employ for graph partitioning in both phases, i.e., in-memory and streaming. This closes a gap in the literature, where papers mostly focus on the partitioning algorithms but fall short in discussing their efficient implementation. (4) Extensive evaluations on seven real-world graphs of up to 64 billion edges show the efficiency of HEP compared to seven strong competitors. Furthermore, we show a speedup in the state-of-the-art production-grade distributed graph processing system Spark/GraphX in many cases when using HEP instead of previously proposed partitioning algorithms. Finally, based on our evaluations, we make a recommendation when it is most beneficial to use HEP.\n\nThe rest of the paper is organized as follows. In Section 2, we formalize and discuss the edge partitioning problem. In Section 3, we introduce the HEP system, including the novel NE++ algorithm and further optimizations. We provide a theoretical analysis of HEP in Section 4. Finally, we evaluate HEP against seven strong baseline systems in Section 5, discuss related work in Section 6 and conclude the paper in Section 7.\n\n\nEFFICIENT EDGE PARTITIONING\n\nThe problem setting that HEP addressed relates to the type of partitioning and graphs targeted as well as to resource efficiency. Cut Type. We tackle the edge partitioning problem, as specified in the following (cf. [19,66]). Let there be an undirected, unweighted graph = ( , ) with a set of vertices and a set of edges \u2286 \u00d7 . The goal of edge partitioning is to divide into > 1, \u2208 N components that are called partitions = { 1 , ..., } such that =1,..., = and \u2229 = \u2205, \u2260 . The size of the partitions is limited by a balancing constraint: \u2200 \u2208 : | | \u2264 * | | for a given \u2265 1, \u2208 R. Figure 1 illustrates edge partitioning with = 2 partitions on an exemplary star-shaped graph. When an edge ( , ) is assigned to a partition , both and are covered by . For a partition , denote ( ) = { |( , ) \u2208 } as the set of vertices covered by . When a vertex is covered by a partition, we also say that is replicated on that partition. In the example in Figure 1, vertex 0 is replicated on both partitions, while the other vertices are replicated only on a single partition. Now, the optimization objective in graph partitioning is to minimize the replication factor RF( 1 , . . . , )= 1 | | =1,..., | ( )|. In the given example, replicating vertex 0 induces communication between the two machines that execute a query that spans the complete graph. For instance, the state of vertex 0 would need to be synchronized in each iteration of a distributed graph processing algorithm [28]. By minimizing the replication factor, the amount of synchronization between the distributed compute nodes that process a query is thus minimized.\n\nEdge partitioning stands in contrast to vertex partitioning, where the vertices are assigned to partitions and the edges are cut (cf. right side in Figure 1). Here, the edge cut induces the communication in query processing; the machines exchange vertex states across the cut edges. As can be seen in the example of the star-shaped graph, such an edge cut might be much larger than the corresponding best vertex cut. Bourse et al. [19] have analyzed the difference between both cut types, proving that vertex cuts are smaller than edge cuts on power-law graphs.\n\nGraph Type. In many natural graphs, e.g., social networks and web graphs, the degree distribution of the vertices follows a powerlaw [14]. In power-law graphs, a large fraction of edges in the graph are incident to only a few vertices which have a very high degree. This property can be exploited by assigning edges to partitions in such a way that the replication of a high-degree vertex is preferred   to the replication of a low-degree vertex. The rationale for this is that high-degree vertices are incident to so many edges that they are likely to be replicated anyway; by focusing on placing lowdegree vertices with a low replication factor, the overall replication factor can be decreased [23,51,64].\n\nEfficiency. Resource efficiency is desirable, e.g., in order to reduce monetary costs. Given a compute node with constrained memory capacities (which may be less than the size of the graph data), the graph partitioning algorithm should be able to provide the best possible replication factor in the lowest possible run-time.\n\n\nHYBRID EDGE PARTITIONER\n\nHEP is a hybrid edge partitioning system that combines in-memory partitioning with streaming partitioning. In-memory partitioning can achieve a low replication factor, because the problem is less constrained than streaming partitioning. On the other hand, streaming partitioning induces very low memory overhead, because there is no need to keep the complete graph in memory. Our objective is to combine both paradigms by partitioning one sub-part of the graph with in-memory partitioning and the other sub-part with streaming partitioning. To do so, we have to find a sub-graph that can be partitioned with streaming partitioning while not compromising too much in terms of the replication factor.\n\n\nApproach Overview\n\nWe divide the graph into two sub-graphs by considering the vertex degrees. To motivate this, we perform experiments on two different real-world graphs (cf. Figure 2). We measure the replication factor of vertices that have a degree in a specific range ( [1,10], [11,100], etc.) using both the streaming partitioner HDRF [51] as well as the in-memory partitioner NE [66] for building = 32 partitions. In the same figure, we also plot the degree distribution of the respective graphs. We can observe that the replication factor obtained by either partitioner heavily depends on the vertex degree: Vertices with a low degree are less often replicated than vertices with a high degree. Furthermore, the number of vertices of a low degree is much higher than the number of vertices of a high degree. Both HDRF and NE are degree-aware partitioners: They focus on trying to reduce the replication factor of the many low-degree vertices rather than the few high-degree vertices.\n\nOur strategy in HEP is similar to existing partitioners in the sense that we try to achieve very good partitioning quality for low-degree vertices to keep the overall replication factor low. However, we add the new aspect of memory efficiency by allowing to compromise for each \u2208 ( ) \u2229 ( \u222a ) do 20:\next ( , ) \u2190 ext ( , ) \u2212 1 21: ext ( , ) \u2190 ext ( , ) \u2212 1 22:\nif | | < | | then 23:\n\n\u2190 \u222a ( , ) \u22b2 assign edge to 24:\n\nRemoveEdge(( , )) 25: else \u22b2 spill over to next partition 26: +1 \u2190 +1 \u222a ( , ) 27:\n\nRemoveEdge(( , )) 28:\n+1 \u2190 +1 \u222a { , }\non the replication factor of high-degree vertices in order to reduce memory overhead:\n\n(1) Edges that are incident to at least one low-degree vertex are partitioned with in-memory partitioning. This significantly reduces the overall replication factor, because in power-law graphs, the number of low-degree vertices is much higher than the number of high-degree vertices.\n\n(2) Edges that are incident to two high-degree vertices ( \u210e2\u210e ) are partitioned with streaming partitioning. Even if there are many edges between high-degree vertices, the number of vertices affected will still be low, because of the skewedness of power-law graphs. Hence, a large number of edges can be partitioned with streaming partitioning while only a small number of vertices is affected.\n\nBut what is a \"high\" degree? We define a threshold factor (tau) that separates high-degree vertices \u210e from low-degree vertices , such that \u210e \u222a = and \u210e \u2229 = \u2205, as follows:\n\u2208 \u210e if ( ) > * , else,\nwhere is the mean degree of all vertices in the graph. By setting , one can control the memory overhead of the partitioning algorithm: A lower means that more edges are incident to two high-degree vertices, so that the memory overhead is reduced because more edges are partitioned with streaming partitioning.\n\n\nIn-Memory Partitioning via NE++\n\nThe first phase of HEP is in-memory partitioning via NE++. NE++ is a new, highly memory-efficient and fast extension of the wellknown NE (neighborhood expansion) algorithm [66]. In particular, NE++ introduces two novelties compared to NE. (1) NE++ employs a pruned graph represention, which significantly reduces the memory overhead.\n\n(2) NE++ introduces lazy edge removal, an efficient technique to avoid the assignment of the same edge to multiple partitions without eagerly keeping books on past edge assignments.\n\nBasic NE Algorithm. Before we detail the technical contributions of NE++, we quickly review the basic NE algorithm [66] and analyze its shortcomings. In the NE algorithm, partitions are built in sequence. To build partition , a seed vertex is chosen (Algorithm 1, lines 1-3). This seed vertex is placed in a vertex sub-set that is called core set, denoted by ; hence, the seed vertex must not have been in before. All neighboring vertices of the seed vertex in are placed in another vertex sub-set that is called secondary set, denoted by . Edges that connect vertices between or within and are assigned to the current partition . Now, in an expansion step (lines 6-11), the vertex from is selected that has the lowest external degree ext ( , ), i.e., the lowest number of neighbors that are neither in nor in (line 8). This vertex is moved from to (line 9) and its external neighbors are added to (lines 12-15). Whenever a vertex is added to , the algorithm decrements the external degree of neighboring vertices that are already in and calculates the external degree of (lines [19][20][21][22][23][24][25]. Finally, edges between and vertices in or are assigned to the current partition (line 23); such edges are then removed from the graph to avoid double assignments (line 24). This ends the expansion step. Then, the next expansion step is performed by again determining the vertex in with the lowest degree and moving it to (lines 8-9). The expansion phase of a partition stops when the capacity bound of is reached. Then, the next partition +1 is built. If the capacity bound of a partition is reached within an expansion step, further edges assigned in the expansion step are \"spilled over\" to the next partition +1 (lines [26][27][28]. The overall algorithm terminates when all partitions have been built. In Figure 3, we provide a detailed example of the first expansion step in a partition 1 . Vertices in are marked in green, vertices in 1 are marked in blue. We further list the set of edges already assigned to 1 and the external degrees of all vertices in 1 .\n\nLimitations of NE. We identify the following limitations of NE. (1) The complete graph must be loaded into memory. This prevents NE from being used to partition graphs that exceed the memory capacity of the available compute node. (2) NE eagerly keeps book on which edge has been assigned to which partition. This induces high memory and run-time overhead. 3.2.1 Pruned Graph Representation. NE++ employs an adaptation of the compressed sparse row (CSR) graph representation [22,59] 2 . However, when we build the CSR from the input graph file-a binary edge list-, we leave out certain parts of the column array. In particular, we do not store the adjacency lists of high-degree vertices in the column array. Edges between a low-degree and a high-degree vertex can still be reached via the adjacency list of the low-degree vertex. However, edges between two high-degree vertices are not represented in the column array at all. We, hence, write out edges between two high-degree vertices to an external file while building the CSR. Figure 4 depicts an example. The original graph contains 9 vertices and 11 undirected edges; the average degree is 2.4. In the column array, this results in 22 entries. Now, with a degree threshold of = 1.5, all vertices with a degree of 4 or more are considered high-degree (in the example, those are 4 and 5 ). In the column array of the pruned graph, adjacency lists of 4 and 5 are, hence, omitted. To not lose the edge ( 4 , 5 ), we write it out into an external edge file that is later partitioned by a streaming algorithm. The column array of the pruned graph is much smaller (in the example, 13 entries instead of 22), i.e., we save memory.\n\nTo adapt the NE algorithm to the pruned graph representation, we have to completely avoid access to the adjacency lists of highdegree vertices. We observe that in NE, high-degree vertices have a tendency to remain in the secondary set until the end of the expansion of a partition , as they are less likely to have the lowest external degree compared to low-degree vertices. In Figure 5, we compare the normalized average degree between vertices in and in \\ on different real-world graphs when performing partitioning with NE at = 32 partitions. The average degree of vertices that remain in the secondary set is very high, while for vertices that are moved to the core set, it is much lower. In other words, there are many high-degree vertices that remain in throughout the partition expansion and are not moved to .\n\nIn NE++, we exploit this property as follows: We assign highdegree vertices to the secondary set a priori and also do not move LJ OK BR WI IT TW FR UK GSH WDC  graphs   0   10   20   30 norm. average degree C S\\C Figure 5: Average degree of vertices in and \\ at = 32 partitions, normalized to the total average degree (cf. Table 3).\n\nthem to the core set (\"no expansion via a high-degree vertex\"), i.e., high-degree vertices are always in the secondary set. This implies that we do not iterate over the adjacency lists of high-degree vertices, so that the pruned graph representation in NE++ is sufficient.\n\nAs moving a high-degree vertex to is unlikely in NE, NE++ stays close to the original behavior of the algorithm.\n\n\nLazy Edge Removal.\n\nA central property of a valid edge partitioning is that an edge must be assigned exactly once, i.e., to exactly one single partition. However, in an undirected graph, an edge ( , ) is represented twice in the CSR column array: if is a neighbor of , then is also a neighbor of . For instance, in Figure 4, 7 is in the adjacency list of 0 , and 0 is in the adjacency list of 7 .\n\nTo prevent an edge from being assigned to multiple partitions, the assignment of the edge to a partition must be taken into account in the further partitioning process, i.e., the edge must be removed or marked as invalid. There are two rather naive ways to implement this. First, one could remove the edge from two different locations in the column array. However, this induces computational overhead and leads to poor cache locality, as different (random) locations in the column array must be accessed subsequently. Second, one could introduce an auxiliary data structure that holds for each edge the information of whether it is still valid or not-the reference implementation of NE follows this approach. However, this induces additional memory overhead for the auxiliary data structure and it also leads to poor cache access locality, because such a data structure cannot be a contiguous representation of the adjacency lists of both vertices and at the same time.\n\nIn NE++, we introduce a new method, called lazy edge removal, to solve this problem more efficiently. Lazy edge removal is both memory-efficient, as it foregoes introducing auxiliary data structures, and leads to a good cache locality, as it only accesses adjacency lists in a contiguous way. Before we introduce the method, we first analyze which vertices are visited in which phase of the expansion algorithm. If a vertex is not visited again by any other partition, removing edges in this vertex's adjacency list is not necessary.\n\nThe following theorem (Theorem 3.1) proves that only vertices that remain in the secondary set of a partition at the end of the partition's expansion phase can be visited again in the expansion phase of a subsequent partition; vertices that are moved to the core set will not be visited again.\n\nTheorem 3.1. Access of Column Array. After a vertex has been moved to the secondary set of a partition , the adjacency list of in the column array is accessed in a subsequent partition again only if is still in after has been completed.\n\nProof. See Appendix B. \u25a1\n\nAs the adjacency lists of vertices moved to will not be accessed again, we can restrict edge removal for a partition to those\n\nAlgorithm 2 Clean-up Algorithm. 1: procedure CleanUp(Partition ) 2: for each \u2208 do 3:\n\nfor each \u2208 ( ) \u2229 ( \u222a ) do 4:\n\nv.adjacency_list.Remove( )  Table 3).\n\nvertices that remain in . Hence, we introduce a clean-up phase which is executed after the completion of each partition. It removes those entries from the column array that may be accessed again in a following partition , > , but represent edges that have been assigned to . This affects only adjacency lists of vertices in . The clean-up algorithm (Algorithm 2) iterates through all vertices in and removes those edges from the column array that have been assigned to (i.e., neighbors of that are in or in ). Edge removal can be implemented efficiently by swapping the last valid entry of the adjacency list with the to-be-removed entry and then decrementing the \"size\" (a field indicating the number of valid entries) of the adjacency list. This is a constant-time operation. Figure 6 depicts an example of a graph before and after the clean-up algorithm has been executed. The figure visualizes how the clean-up algorithm \"separates\" the core set from the rest of the graph; subsequent expansions cannot enter the core set of the graph any more, as the clean-up algorithm removes all links into it. Therefore, none of the edges that connect two vertices in the core set will be visited again and, hence, double-assignment of those edges is impossible. As the heuristic in NE++ tries to keep as small as possible, only a small number of vertices is visited in the clean-up phase.\n\nTo show the effectiveness of lazy edge invalidation, we evaluate on different graphs the overall fraction of edges in the column array which are removed in the clean-up process of NE++ (at = 32 partitions). The results in Figure 7 show that only a small fraction of edges are actually removed. The rest of the column array remains untouched. This is particularly pronounced on web graphs (IT, UK, GSH, WDC). Different from that, eager invalidation would remove all column array entries to prevent double assignment.\n\nAlgorithm 3 Building the last partition in NE++. 1: procedure AssignRemainingInMemoryEdges 2:\n\nfor each \u2208 do 3:\n\nif \u2209 then 4:\n\nfor each \u2208 out ( ) do 5:\n\n\u2190 \u222a ( , )\n\n6: if has high-degree neighbors then 7:\n\nfor each \u2208 in ( ) do 8:\n\nif \u2208 \u210e then 9:\n\n\u2190 \u222a ( , )\n\n10: if | | \u2265 | | then 11:\n\n\u2190 + 1\n\nAlgorithm 4 Streaming partitioning in HEP.\n\n1: procedure StatefulStreamingPartitioning 2: for each \u2208 h2h do 3:\n\nbestScore \u2190 0 4: bestScore \u2190 NULL 5:\n\nfor each \u2208 : | | < * | | do 6: score \u2190 scoring_function( , ) 7:\n\nif score > bestScore then 8: bestScore \u2190 score 9:\n\ntarget_p \u2190 10: target_p \u2190 target_p \u222a\n\n\nFurther Optimizations for NE++.\n\nInitialization. The initialization function is called in the expansion of a partition when there are no more vertices in that can be moved to . The goal is to find a suitable vertex outside of that can be moved to , i.e., the vertex must neither be a high-degree vertex nor a vertex in . There are three scenarios when such an initialization is needed. First, when a partition's expansion is started. Second, when the graph is split into disconnected components and the expansion of a partition has assigned all edges of one of these components. Third, when there are only high-degree vertices in and, hence, no more vertices can be moved to . The first case only happens once, but the other cases can occur frequently, depending on the graph structure and the number of high-degree vertices. Hence, it is important that the initialization procedure finds a suitable vertex quickly and efficiently. Using randomized vertex selection-as done in the reference implementation of NEcomes with the problem that the chance of hitting a suitable vertex becomes lower over time as the number of vertices that are not in decreases. Hence, the overhead grows as the partitioning process progresses. In NE++, we instead perform a sequential search through the vertices based on their ID. A vertex that was once found to be unsuitable for the initialization is thus never visited again in the initialization procedure.\n\nAdapted Partition Capacity Bound. As a consequence to graph pruning, edges incident to two high-degree vertices are not partitioned by NE++, but by streaming partitioning. Hence, in NE++, we adapt the capacity bound for the partitions, such that the in-memory edges are distributed to the partitions in a balanced fashion. Instead of a capacity bound of | | , the new capacity bound is\n| \\ \u210e2\u210e | .\nBuilding the Last Partition. For building the last partition, it is sufficient to simply assign all remaining in-memory edges to the last partition. To this end, NE++ iterates through the adjacency lists of all low-degree vertices that are not yet in the core set (cf. Algorithm 3). These adjacency lists contain all the remaining in-memory edges. There are two cases which must be treated differently: A remaining in-memory edge can be an edge between two low-degree vertices, or an edge between a low-degree and a high-degree vertexedges between two high-degree vertices are external-memory edges by definition and are treated with streaming partitioning.\n\nWhen assigning the remaining edges between two low-degree vertices, we may approach an edge ( , ) from two different directions (from or from ), but should only assign it once. To solve that issue, we assign edges between two low-degree vertices always from the perspective of the left-hand side vertex of the edge in the original edge list (i.e., from if the edge is ( , ) in the input edge list). To do so, we need to track the \"direction\" of each edge in the CSR, i.e., whether an edge between vertex and vertex is ( , ) (will be assigned from 's side) or ( , ) (will be assigned from 's side). We can do that in the graph construction phase (cf. Section 3.2.1) by building a second index array and dividing the adjacency list of each vertex into a set of out-edges and a subsequent set of in-edges. The first index array contains the reference to the beginning of the out-list of a vertex in the column array, while the second index array refers to the corresponding in-list. An alternative solution would be to always assign edges between two low-degree vertices from the perspective of the vertex with the smaller ID. This would save memory (no need for a second index array to separate out-list from in-list), but requires to pass through a vertex's complete adjacency list instead of only the out-list.\n\nThe assignment of edges between a low-degree vertex and a high-degree vertex is straight-forward. As the adjacency list of the high-degree vertex is not present in the column array, the edge can safely be assigned from the low degree vertex's side.\n\n\nInformed Stateful Streaming Partitioning\n\nIn HEP, we use stateful streaming partitioning and exploit the partitioning state from in-memory partitioning to improve the partitioning quality. Stateful streaming partitioning rates the placement of a given edge on each partition via a scoring function : ( , ) \u2192 . Then, the edge is assigned to the partition that yields the highest score value (cf. Algorithm 4).\n\nIn our implementation of HEP, we use the HDRF scoring function [51], which takes into account the vertex degrees, the vertex replication on each partition, and the load (in number of edges) of each partition. The vertex degrees and the vertex replication of each partition are used as a result of NE++: A vertex is replicated in partition exactly if it is in . This way, we overcome the \"uninformed assignment problem\" [47] of stateful streaming partitioning where early edges in the stream are assigned to a partition without any knowledge of the rest of the graph. HDRF is the partitioning algorithm that fits best for the streaming phase of HEP and can be easily integrated without any need for adaptations. Having said this, the streaming phase of HEP could also employ other stateful streaming edge partitioning algorithms, such as Greedy [28] or AD-WISE [47]. However, the Greedy strategy is clearly outperformed by HDRF [51]. ADWISE invests additional run-time to overcome the uninformed assignment problem which is, however, already tackled in HEP by the in-memory phase via NE++. ) with = maximum vertex degree, = number of CPU cores METIS [34] In-Memory O ( ( | | + | |) * log ) \n\n\nTHEORETICAL ANALYSIS\n\nWe perform a theoretical analysis of HEP's run-time and memory overhead as well as the obtained replication factor. Finally, we discuss strategies for setting so that a memory bound can be met.\n\n\nTime Complexity\n\nWe analyze the time complexity of the following steps of HEP separately: building the CSR graph representation, in-memory partitioning with NE++, and streaming partitioning. Graph Building. The run-time complexity of graph building is O (| | + | |). There are two passes over the edge list, each having constant complexity per edge. In the first pass, the degree of each vertex is determined; then, the index array is built by performing a pass over the vertices' degrees and computing a running sum. In the second pass, the edges are inserted into the column array or, if an edge is incident to two high-degree vertices, into the external memory edge file.\n\nNE++. To determine the vertex _min with the minimum external degree, we store vertices in in a binary min-heap, sorted by their external degree. In the worst case, contains all vertices of the entire graph. Every time the external degree of a vertex changes, the min-heap is updated to retain the heap property. Hence, each min-heap update operation has a complexity in O (log | |). In total, there will be up to 2 * | | updates of the min-heap, resulting in O (| | * log | |) complexity to maintain the min-heap. The other operations of the main expansion algorithm have the following complexity. Assigning each edge to a partition is in O (| |). Traversing the neighbors of a vertex in order to update the min-heap is in O (| | * ), as each neighborhood is maximally traversed times (in case a vertex is in every secondary set ). Initialization has a complexity of O (| |), as each vertex is visited at most once. Finally, the clean-up procedure is executed \u2212 1 times, each time iterating through all adjacency lists of all vertices in and performing a constant-time operation on them. Hence, clean-up has a time complexity of O (| | * ). The overall time complexity of NE++ is O (| | * (log | | + ) + | |).\n\nStreaming. Stateful streaming partitioning computes a scoring function for each edge and each partition; the computation of each score is a constant-time operation. Hence, the streaming phase has a time complexity of O (| | * ).\n\nComparison and Discussion. The overall time complexity of HEP is dominated by the NE++ phase, and, hence, is in O (| | * (log | | + ) + | |). This is higher than the stateful streaming partitioners Greedy, HDRF and ADWISE. However, the case that each vertex is in every secondary set is highly unlikely, as this would mean that each vertex is replicated on every partition. In contrast to this, the time complexity bounds of Greedy, HDRF and ADWISE are tight, as they involve the computation of a scoring function on every combination of edges and partitions.\n\n\nMemory Overhead\n\nLet the ID of a vertex be stored in id bytes. For instance, for a graph with up to 2 32 (i.e., 4.29 B) vertices, we can store vertex IDs in 4 byte unsigned integers. The following data structures are necessary in order to implement HEP efficiently.\n\n(1) Two indices for the index array to separate incoming and outgoing edges. Both contain one field for each vertex, which totals in 2 * | | * id bytes. (2) A column array to store the edges. The size of the column array is the sum over the sizes of the adjacency lists of the low-degree vertices: \u2208 ( ) * id bytes. (3) Size fields for each in and out adjacency list to indicate the number of valid entries (this is used for efficient edge removal, as discussed above). Each size field occupies id bytes, totalling in | | * 2 * id bytes. (4) dense bitsets to track the vertices in the secondary set for each partition and one dense bitset to track the vertices in the core set . A dense bit set works as follows: For each vertex id, the bit with the corresponding index in the bit set signals whether the vertex is part of the set. Overall, these data structures occupy | | * +1 8 bytes. (5) A min heap to store the external degrees of vertices in and a lookup table to directly access the entry of a vertex in the min heap by its ID. Together, they require 2 * | | * id bytes.\n\nThe total size of all data structures is: \u2208 ( ) * id + 6 * | | * id + | | * +1 8 bytes.\n\n\nBounds on Replication Factor\n\nThe worst-case replication factor obtained with HEP is between the bounds of NE [66] and of HDRF [51]. NE has a better bound on replication factor than HDRF for power-law graphs [66], i.e., a higher setting of leads to a better replication factor as more edges are partitioned with NE++.\n\n\nSetting of to Keep Memory Bounds\n\nA unique characteristic of hybrid partitioning with HEP is its ability to flexibly reduce memory overhead by setting . The lower is set, the more vertices are considered high-degree and, thus, the column array-which is the dominant data structure-is pruned more aggressively. Hence, can be set with respect to the memory capacities of the compute node. To do so, one can perform a pre-computation step and build the cumulative sum of the size of the adjacency lists of the respective low-degree vertices for different values of ; this is a trivially parallelizable process. Then, one chooses the maximal value of that keeps the memory bound (e.g., memory capacity of the compute node). Once is determined, graph partitioning with HEP is performed. We measured the run-time to determine the memory requirements for a specific setting of for different graphs (Table 2). Compared to graph partitioning run-time (Section 5.2), this is negligible, so that pre-computing an optimal value of is feasible and practical. OK [16][17][18], UK [12, [16][17][18], GSH [4, [16][17][18] and WDC [13]). The reasons that we chose these graphs are as follows: First, many of them are commonly used as baselines in related papers [30,47,66]. Second, most of them are very large (billions of edges), and hence, are particularly challenging in terms of memory overheads even on a large machine. Indeed, we show that not all partitioners can handle graphs of that size on our evaluation platform. Third, the graphs have a large diversity in terms of how \"easy\" they are to partition; for some of them, even the best partitioners reach only relatively high replication factors.\n\nBaselines. We compare HEP to 7 of the most recent and best streaming and in-memory partitioners. From the group of streaming partitioners, we compare to ADWISE [47], DBH [64], HDRF [51], and SNE [66]. From the group of in-memory partitioners, we compare to NE [66], DNE [30] and METIS [34]. There exist dozens of other partitioners, and we cannot compare to all of them. However, other partitioners are consistently outperformed by the chosen baselines either in terms of replication factor, run-time, scalability or memory efficiency. Hence, we argue that we made a reasonable and fair choice of baselines. See Section 6 for a comprehensive discussion of other partitioners.\n\nPerformance Metrics. We measure replication factor, run-time (including graph ingestion) and memory overhead (maximum resident set size). We also track edge balancing: Most partitioners kept the partitions balanced; in case partitioning was imbalanced, we report the balancing factor in the plots.\n\nExperiments. We perform systematic experiments with = {4, 32, 128, 256} partitions. We configured HEP with the following values of : 100, 10 and 1. For each graph, we first perform one warm-up run that does not count into the measurements (e.g., to warm up caches). We aborted experiments on smaller graphs (< 10 B edges) when they took more than 12 hours, as some partitioners (NE, SNE and METIS) would \"freeze\" in an unknown state for many hours. On the smaller graphs, we repeat every experiment 3 times and report the mean values with standard deviations; for GSH and WDC, we run experiments only once due to very large run-times. In Appendix A, we discuss configurations and implementation of the baseline partitioners as well as the input formats of graph data. (1) HEP has a lower memory overhead than the in-memory partitioners NE, DNE and METIS (see Figure 8(c, f, i, l, o)). Regardless of the setting of , memory overheads of the in-memory partitioners are higher by up to an order of magnitude. At the same time, HEP can reach competitive replication factors to NE (especially, at settings of \u2265 10), which is the partitioner with the best replication factor throughout all experiments (cf. Figure 8(a, d, g, i, m)).\n\n\nGraph Partitioning\n\nA major cause for the improvements compared to NE is the lazy edge removal method, which allowed us to remove an auxiliary data structure in NE, namely, an unsorted edge list, that keeps track of whether every edge is still valid or not. Furthermore, the run-time of HEP is better, as we use more efficient data structures, namely, the CSR representation. Different from HEP, the unsorted edge list that NE internally employs causes a lot of random access and cache misses while performing the neighborhood expansion steps.\n\nDNE is the state-of-the-art in scalable edge partitioning, being able to scale across large clusters of machines. However, this comes with a cost: DNE requires an order of magnitude more memory than HEP. Further, if the resources used for partitioning are limited (in our case to 64 hardware threads), the run-time of HEP is often competitive to DNE; in some cases, even lower. Furthermore, the distributed and parallel nature of DNE leads to a degradation of the yielded replication factors. HEP achieves better replication factors than DNE in all evaluated settings of on all graphs. Finally, DNE could not always keep the partitions balanced, while HEP achieved perfect balancing in all cases.\n\nMETIS is often considered the \"gold standard\" in graph partitioning quality and is commonly used as a baseline [44,66]. While the replication factor obtained by METIS is relatively good in some cases (especially on the IT graph), METIS takes a lot of time, as it follows a multi-level partitioning approach with coarsening and refinement phases. HEP is faster, uses less memory, and achieves better replication factors than METIS. In some instances, the advantage in run-time of HEP is more than an order of magnitude, e.g., on the TW graph with = 32, it is 15 minutes for HEP-100 and 10 hours for METIS (Figure 8(h)), while the replication factor of HEP-100 is 1.99 vs. METIS with 5.68 (Figure 8(g)).\n\n(2) Compared to streaming partitioners (ADWISE, HDRF, DBH, and SNE), HEP achieves much better replication factors. At the same time, HEP's memory overhead can be reduced such that it is close to streaming partitioning. By setting a lower value of , on all graphs and all number of partitions, we observe a significant reduction in memory overhead of HEP. At = 1, HEP's memory      overhead comes close to streaming partitioning (Figure 8(c, f, i, l, o, r, u)). This way, memory bounds on smaller machines can be kept. However, HEP achieves a better replication factor than streaming partitioners (Figure 8(a, d, g, j, m, p, s)). Summary: HEP combines the best of both worlds by integrating in-memory with streaming partitioning. This brings the following benefits to the end user: (1) Flexibility to adapt memory overheads to the graphs at hand and the existing hardware capabilities without needing to switch between partitioners. Instead of having to install or even integrate into another system many different partitioners, one can simply employ HEP and use the tuning knob (the parameter ) to fit the graph into memory.\n\n(2) In scenarios where in-memory partitioning is not feasible because the graph is too large, HEP yields better replication factors than streaming partitioners, especially on social network graphs. (3) In scenarios where in-memory partitioning would theoretically be feasible, using HEP with a high setting of yields a good replication factor and is much faster than the previous state-of-the-art partitioner NE.\n\n\nDistributed Graph Processing\n\nWe evaluate the run-time of distributed graph processing under different graph partitionings. To this end, we set up a distributed Spark v3.0.0 cluster with 32 machines, each having 8 CPU cores and 20 GiB of RAM. They are connected by 10-GBit Ethernet. We perform a set of experiments, using three algorithms: PageRank (100 iterations), Breadth First Search (subsequently from 10 different random seed vertices) and Connected Components. PageRank is an algorithm that keeps all vertices active in every iteration; hence, it is very communication-intensive. BFS starts with all vertices but one seed vertex being inactive; from that seed vertex, the computation spreads through the graph. Finally, CC starts with all vertices being active, but in every iteration, more and more of the vertices become inactive. Hence, these three algorithms are characteristic for different sorts of workloads. We compare the run-time of these graph processing algorithms on the Spark cluster using prepartitioned graphs with different partitioning algorithms. Please note that processing larger graphs than the TW graph led to out-ofmemory errors in Spark. We report the mean result of three runs for each experiment. We did not perform partitioning with ADWISE or METIS, as these partitioners already take more run-time for partitioning than the entire subsequent graph processing job takes for processing. Further, DNE led to largely imbalanced partitions (cf. Section 5.2) which can hinder good processing performance. Instead, we compare HEP to NE, SNE, HDRF and DBH. Table 4 shows the results. In many cases, the total run-time (partitioning + processing) is lowest when using HEP partitioning. There are two exceptions: First, if the processing task itself is very short, like in the Connected Components algorithm, it is better to perform fast partitioning with DBH, as despite of the higher runtime of graph processing, the total run-time is still lower. Second, different from the other graphs, on the TW graph, DBH performed reasonably well in terms of replication factor. Hence, although the graph processing run-time is faster when using HEP, the total run-time is still better with DBH.\n\nThere are some surprising observations on the IT graph. This graph could be partitioned with very high quality by most of the partitioners (HEP, NE, SNE, and HDRF). As a result, communication overhead only plays a minor role and load balancing becomes more important. Here, HEP shows a hidden strength of its hybrid partitioning approach: It optimizes both vertex replication and vertex balancing at the same time, as the streaming phase shows better vertex balancing than the neighborhood expansion phase (cf. Table 5). Therefore, for all graph processing algorithms, the fastest processing time on the IT graph is obtained with HEP-1 or HEP-10, even though these do not yield the lowest replication factor.\n\nWe draw the following conclusions. First of all, the choice of partitioner largely depends on the run-time of the subsequent graph processing job. For very short processing jobs, simple hashing is still the best option, as it is the fastest way to partition a graph. Second, for long-running graph processing jobs, like PageRank or multiple subsequent runs of Breadth First Search, it is in many cases beneficial to perform high-quality graph partitioning. Here, the optimal choice of partitioner depends on the replication factor achieved and the run-time of partitioning. Third, good partitioning quality, i.e., low communication overhead, matters a lot to the performance of graph processing. However, there is a saturation point where further improvements of partitioning quality do not lead to better processing performance, as the bottleneck shifts from communication overhead to balancing. While many partitioners try to balance the number of edges across the partitions, we have shown that there are cases where vertex balancing also plays a role in the overall processing performance. HEP's hybrid approach shows to be advantageous in such a situation, leading to the best processing performance among all partitioners on the IT graph.\n\nOverall recommendation: Use HEP for long-running graph processing jobs on graphs were it can achieve very low replication factors (e.g., on web graphs, cf. Figure 8).\n\n\nComparison to Simple Hybrid Partitioning\n\nHow much of HEP's performance is due to its specific design (using NE++ and HDRF), as opposed to hybrid partitioning per se? To answer this question, we compare HEP's performance to a simple hybrid partitioning baseline. We first divide the input graph into one subgraph H2H that contains only edges incident to two high-degree vertices and another subgraph REST that contains the remaining edges. Then, REST is partitioned with NE and H2H is partitioned with random streaming partitioning. The main observations (see Figure 9) are as follows.\n\n(1) NE++ has up to \u223c20\u00d7 lower run-time than NE (Figure 9(r), = 100, = 256) when both are run on the same set of edges. Only at a low value of ( = 1.0), the baseline sometimes runs faster than HEP (by up to 2.5\u00d7), as H2H is larger than REST and partitioning is dominated by streaming (Figure 9(d,h,l,p,t)). Random streaming partitioning is faster than HDRF, because it has no scoring function; however, the replication factor is much worse (see (3)).\n\n(2) NE++ has 2 \u2212 3\u00d7 lower memory overhead than NE when both are run on the same set of edges (Figure 9(c,g,k,o,s)). Beyond the savings of hybrid partitioning, NE++ saves additional memory by pruning the adjacency lists of high-degree vertices and by avoiding auxiliary data structures to track which edges have already been assigned to partitions.    (3) HDRF outperforms random streaming partitioning in terms of partitioning quality by up to \u223c12\u00d7 (Figure 9(q), = 1, = 256). At = 1, the amount of edges in H2H is higher than in REST , so that partitioning quality of the streaming phase matters a lot.\n\nIn summary, we have shown that the design of HEP realizes the idea of hybrid partitioning in an efficient and effective manner.\n\n\nComparison to Paging\n\nInstead of hybrid partitioning, one could exploit memory paging to partition large graphs with an in-memory algorithm and swap pages to disk that do not fit into memory. To evaluate this, we ran NE++ on the OK graph for = 32 partitions with different memory restrictions (using cgroups) employing an SSD for fast swapping. The run-time and hard page faults quickly increase when we restrict the process memory (Table 6). For instance, at a memory restriction of 400 MB, NE++ takes 1,736 seconds and induces 5.79 million hard page faults, while with HEP at = 1, we keep a maximum resident set size of 417 MB at a run-time of 45 seconds without any hard page faults. The advantage of paged NE++ is in a better replication factor (2.51 with NE++ compared to 4.52 with HEP at = 1). Similar results were observed for other values of .\n\n\nRELATED WORK\n\nExisting graph partitioners are either in-memory or streaming partitioners. The most prominent type of in-memory partitioners are multi-level partitioners, such as Chaco [31], Jostle [62], SCOTCH [50], METIS [34,38] or KaHiP [54,55]. They apply three subsequent steps: First, the graph is coarsened by combining neighboring vertices. Second, the coarsened graph is partitioned. Third, the partitioning of the coarsened graph is refined to the original graph. The main difference between the various multi-level partitioners is in which algorithms they use for each of these steps. These partitioners focus on partitioning quality, but come with a high overhead. In our experiments, KaHiP ran out of memory on large graphs, while METIS ran for days on some graphs.\n\nSheep [44] is a distributed edge partitioner that builds and partitions the elimination tree of the input graph. Spinner [45] and XtraPuLP [57] are distributed and parallel vertex partitioners that build upon the label propagation algorithm for community detection. These partitioners are outperformed by DNE in terms of replication factor, run-time, memory efficiency and scalability [30]. HEP performs better than DNE in terms of partitioning quality and memory overhead. NE [66] is a sequential partitioner that yields superior partitioning quality compared to other non-multi-level partitioners. In HEP, we improve the design of NE and overcome shortcomings that bloat its memory overhead and run-time.\n\nSome in-memory partitioners, like Sheep [44] and Streaming NE (SNE) [66], decrease their memory overhead by creating chunks of the input graph that are partitioned sequentially one at a time. However, this leads to longer run-times, and in case of SNE, also to worse partitioning quality. HEP also makes such trade-offs, but its performance is superior to prior approaches, as instead of applying the same in-memory algorithm to subsequent chunks of the input graph, it applies different algorithms to selected parts of the graph. This maximizes partitioning quality on the most crucial part of the graph, i.e., edges incident to low-degree vertices, while relaxing the partitioning quality only on a low number of high-degree vertices.\n\nWe have evaluated a large range of streaming partitioners in Section 5. They work either on hashing [32,64] or they gather and exploit partitioning state while passing through the graph stream [47,51,58,60]). These partitioners are outperformed by HEP in terms of replication factor. Common variations of the streaming model are re-streaming [48], i.e., performing multiple passes through the graph stream and refining the partitioning in each pass, and local reordering [47], i.e., buffering parts of the graph stream and reordering it to improve partitioning quality. TLP [33] builds on a similar neighbor expansion scheme as NE, but in a semistreaming manner. The authors claim a low space complexity, but TLP requires the graph to be sorted and streamed multiple times in different breadth-first-search orderings. This overhead seems prohibitive to achieve competitive run-time.\n\nFan et al. [24] propose an approach to refine a given vertex or edge partitioning to a hybrid partitioning that is tailored to the graph processing job. HEP can be used as a pre-partitioning algorithm for this. Further, Fan et al. [25] propose a method to incrementalize iterative vertex-cut partitioners, which is also applicable to NE++. A similar problem to graph partitioning is to find \"vertex separators\" [20,26], i.e., vertices whose removal from the graph would split it into two or more disconnected components.\n\nCompression techniques, such as SlashBurn [40] or Frame of Reference [27], can reduce the memory footprint of graph processing algorithms. However, the efficacy of compression depends on the graph data. Different from that, HEP can reduce the memory overhead in a predictable way by tuning . Frame of Reference also benefits from sorted adjacency lists, which is at odds with NE++'s pruning mechanism that changes the ordering.\n\nPowerLyra [23] is a graph processing system that follows a hybrid partitioning and processing strategy: It applies vertex partitioning to low-degree vertices and edge partitioning to edges incident to high-degree vertices. While this idea is related to ours in its nature of treating low-degree and high-degree vertices differently, PowerLyra is completely in-memory. Out-of-core graph processing systems, such as GraphChi [37], X-Stream [53], Chaos [52], Grid-Graph [67] and Mosaic [42] commonly pre-process the graph data to increase access locality. These pre-processing problems differ from the partitioning problem we target with HEP. It would be inefficient to implement the NE algorithm in out-of-core graph processing frameworks, as the number of iterations in NE is linear in the number of vertices, while each iteration in these frameworks requires a complete pass through the entire graph.\n\n\nCONCLUSIONS\n\nIn this paper, we proposed HEP, a new hybrid system for edge partitioning. HEP separates the edge set into two sub-sets based on the vertex degrees and partitions them separately with a novel inmemory algorithm NE++ and subsequent informed stateful streaming partitioning. Evaluations show that HEP yields a state-of-the-art replication factor faster and with less memory overhead than pure in-memory systems, while yielding a better replication factor than streaming partitioning. Finally, graph partitioning with HEP leads to a faster run-time of graph processing jobs.\n\nIn future work, we aim to further improve the performance of HEP by focusing on parallelism and distribution. Beyond that, we aim to explore the extension of the hybrid in-memory and streaming partitioning paradigm to hypergraphs [15,46].\n\n\nAPPENDIX A: CONFIGURATIONS\n\nSystem Parameters. We follow the author recommendations to set all system parameters. For HDRF, we set = 1.1 [51]. For SNE, we set a sample size of 2 [66]. We compiled DNE with 32-bit vertex IDs, which is optimal for the graphs we partitioned (having less than 2 32 vertices) and set an expansion ratio of 0.1 and a balance factor of 1.05. DNE always starts one separate process per partition. As our machine has 64 hardware threads, we use \u2308 64 \u2309 threads per process. We ran METIS [34] using direct -way partitioning and set -objtype=vol to optimize for communication volume. As METIS is a vertex partitioner, we weighted each vertex with its degree before partitioning and then assigned each edge = ( , ) randomly either to the partition of or of (see also [19,66]). We did not count the time for this conversion step into the METIS run-time.\n\nImplementation. When possible, we used the reference implementation provided by the respective authors [2, 7, 10]. The stand-alone implementation of HDRF [5] does not work for large graphs and shows excessive run-time, while the version integrated into Power-Graph [9] cannot be used stand-alone. We, hence, re-implemented the HDRF algorithm in C++. DBH has no public reference implementation, so that we also re-implemented it in C++.\n\nInput Formats. For HEP, HDRF, DBH, NE, and SNE, the input graph is provided as binary edge list with 32-bit vertex ids. Other partitioners require different input formats. We do not include the transformation time of the graph data into our run-time results.\n\n\nAPPENDIX B: PROOF OF THEOREM 1\n\nProof. We first analyze when in the NE algorithm (Algorithm 1) the adjacency list of a vertex is accessed. First, when a vertex is moved to the core set , its neighbors which are neither in nor in are moved to (lines [14][15]. Second, when a vertex is moved to the secondary set , it is checked for each neighbor of whether is in or , in order to update the external degree of and to assign corresponding edges to partition (lines 20-28). After a vertex is moved to in the expansion phase of partition , it can neither be moved to another time nor be moved to in the expansion phase of a subsequent partition , > . In other words, once moved to , a vertex stays in . Therefore, once is moved to , the adjacency list of will not be accessed again. On the other hand, if is not moved to , it remains in at the end of the expansion phase of . This proves the theorem.\n\n\u25a1\n\nFigure 1 :\n1Edge partitioning vs. vertex partitioning.\n\nFigure 2 :\n2Degree vs. replication factor for LJ and WI graph (cf.\n\nFigure 3 :\n3Example of expansion step. (I) Input graph. (II) Initialization. (III) Partitioning state after first expansion step.\n\nFigure 4 :\n4CSR representation of original and of pruned graph. Red-shaded vertices are high-degree.\n\nFigure 6 :Figure 7 :\n67Clean-up phase: Example.LJ OK BR WI IT TW FR UK GSH Total fraction of edges removed from column array during clean-up at = 32 partitions (graphs cf.\n\nFigure 8\n8shows all results. The main observations are as follows.\n\n\nres. set size (KB) (u) WDC: Mem. overh. (log).\n\nFigure 8 :\n8Performance results on real-world graphs. HEP-indicates that HEP was run with a setting of = . \"OOM\": out-ofmemory error, \"OOT\": excessive run-time, \"FAIL\": crashed for other reasons.\n\nTable 3 )\n3at = 32 partitions.\n\n\nAlgorithm 1 NE: Basic Algorithm.1: procedure Initialize( ) \n2: \n\u2190 any vertex in , such that \u2209 \n3: \nMoveToCore( ) \n\n4: procedure PartitionGraph \n5: \nfor each \n\u2208 do \n\n6: \nwhile | | < | | do \n7: \nif \\ \u2260 \u2205 then \n8: \nmin \u2190 arg min \n\n\u2208 \\ \n\next ( , ) \n\n9: \nMoveToCore( min ) \n10: \nelse \n11: \nInitialize( ) \n\n12: procedure MoveToCore(Vertex ) \n13: \n\u2190 \u222a \n14: \nfor each \u2208 ( ) \\ ( \u222a ) do \n\u22b2 ( ) is the set of 's neighbors. \n15: \nMoveToSecondary( ) \n\n16: procedure MoveToSecondary(Vertex ) \n17: \n\u2190 \u222a \n18: \next ( , ) \u2190 ( ) \n19: \n\n\nTable 1 :\n1Time complexity of different partitioners.\n\nTable 2 :\n2Run-time to pre-compute memory footprint.Name \n\n| | \n| | \n\nSize \nType \ncom-livejournal (LJ) \n4.0 M \n35 M \n265 MiB \nSocial \ncom-orkut (OK) \n3.1 M \n117 M \n895 MiB \nSocial \nbrain (BR) \n784 k \n268 M \n2 GiB \nBiological \nwiki-links (WI) \n12 M \n378 M \n3 GiB \nWeb \nit-2004 (IT) \n41 M \n1.2 B \n9 GiB \nWeb \ntwitter-2010 (TW) \n42 M \n1.5 B \n11 GiB \nSocial \ncom-friendster (FR) \n66 M \n1.8 B \n14 GiB \nSocial \nuk-2007-05 (UK) \n106 M \n3.7 B \n28 GiB \nWeb \ngsh-2015 (GSH) \n988 M \n33 B \n248 GiB \nWeb \nwdc-2014 (WDC) \n1.7 B \n64 B \n478 GiB \nWeb \n\n\n\nTable 3 :\n3Real-world graphs. GiB of main memory and an HDD disk. Using a large server allows us to evaluate many baseline partitioners even for the larger graphs. We use Ubuntu 18.04.2 LTS as operating system.Real-World Graph Datasets. We use 7 different graphs (cf.Table 3) that have different sizes and stem from different web repositories, having been crawled by different organizations. These are social network graphs (OK [8, 39, 65], TW [11, 36, 39] and FR [3, 39, 65]) as well as web graphs (IT [6,Size refers to binary edge lists \nwith 32-bit vertex ids. \n\n5 EVALUATION \n5.1 Experimental Setup \n\nEvaluation Platform. We perform all experiments on a server \nwith 4 x 16 Intel(R) Xeon(R) CPU E5-4650 @ 2.70GHz, about 500 \n\n\nTable 4 :\n4Processing time of distributed graph algorithms and partitioning time (sec). Lowest \ntotal time (partitioning + processing) is underlined; lowest processing time is printed in bold. \n\nOK \nIT \nTW \nHEP-100 0.184 0.425 0.320 \nHEP-10 \n0.168 0.376 0.222 \nHEP-1 \n0.124 0.196 0.216 \n\n\n\nTable 5 :\n5HEP: Vertex balanc-\ning (std. deviation / average \nnumber of vertex replicas \nper partition) at = 32. \n\n\n\n\n(i) TW: Replication factor.norm. run-time(j) TW: Run-time (logscale). norm. max. RSS (k) TW: Memory overhead. (m) FR: Replication factor. norm. run-time (n) FR: Run-time (logscale). norm. max. RSS (o) FR: Memory overhead. (p) FR: Edge Type Ratios. (q) UK: Replication factor. norm. run-time (r) UK: Run-time (logscale). norm. max. RSS (s) UK: Memory overhead. (t) UK: Edge Type Ratios.Figure 9: Performance of simple hybrid strategy (NE + random streaming), normalized to the results of HEP (blue line).IT \nTAU=100 TAU=10 TAU=1 \nH2H \n9.82E-03 0.110763 0.58119 \nREST \n9.90E-01 8.89E-01 4.19E-01 \n\n0% \n\n50% \n\n100% \n\nTAU=100 TAU=10 TAU=1 \n\nH2H REST \n\n(h) IT: Edge Type Ratios. \n\n4 \n32 \n128 \n256 \npartitions \n\n0 \n\n1 \n\n2 \n\n3 \n\nnorm. rep. factor \n\nTAU=100 \nTAU=10 \nTAU=1 \n\n4 \n32 \n128 \n256 \npartitions \n\n10 1 \n\n10 0 \n\n10 1 \n\n4 \n32 \n128 \n256 \npartitions \n\n0 \n\n1 \n\n2 \n\nTW \nTAU=100 TAU=10 TAU=1 \nH2H \n3.16E-02 0.275379 0.607268 \nREST \n9.68E-01 7.25E-01 3.93E-01 \n\n0% \n\n50% \n\n100% \n\nTAU=100 TAU=10 TAU=1 \n\nH2H REST \n\n(l) TW: Edge Type Ratios. \n\n4 \n32 \n128 \n256 \npartitions \n\n0 \n\n2 \n\n4 \n\nnorm. rep. factor \n\nTAU=100 \nTAU=10 \nTAU=1 \n\n4 \n32 \n128 \n256 \npartitions \n\n10 1 \n\n10 0 \n\n10 1 \n\n4 \n32 \n128 \n256 \npartitions \n\n0 \n\n1 \n\n2 \n\nFR \nTAU=100 TAU=10 TAU=1 \nH2H \n0.00E+00 0.074991 0.742416 \nREST \n1.00E+00 9.25E-01 2.58E-01 \n\n0% \n\n50% \n\n100% \n\nTAU=100 TAU=10 TAU=1 \n\nH2H REST \n\n4 \n32 \n128 \n256 \npartitions \n\n0 \n\n5 \n\n10 \n\nnorm. rep. factor \n\n=1.42 \n\nTAU=100 \nTAU=10 \nTAU=1 \n\n4 \n32 \n128 \n256 \npartitions \n\n10 1 \n\n10 0 \n\n10 1 \n\n4 \n32 \n128 \n256 \npartitions \n\n0 \n\n1 \n\n2 \n\n3 \n\nUK \nTAU=100 TAU=10 TAU=1 \nH2H \n2.50E-02 0.176865 0.543468 \nREST \n9.75E-01 8.23E-01 4.57E-01 \n\n0% \n\n50% \n\n100% \n\nTAU=100 TAU=10 TAU=1 \n\nH2H REST \n\nMem. limit (MB) \n1,000 900 \n800 \n700 \n600 \n500 \n400 \n\nRun-time (sec) \n42 \n65 \n116 \n205 \n374 \n587 \n1,736 \nHard page faults \n61 K \n156 K 365 K 688 K 1.32 M 2.13 M 5.79 M \n\n\n\nTable 6 :\n6Performance of paging on OK graph.\nInformally, \"cut size\" means how many times an edge or vertex spans two different graph partitions. A formal definition is provided in Section 2.\nIn our CSR implementation, we store edges in both directions (in and out) for each vertex in the column array. We denote the entries in the column array that represent the neighborhood of a vertex also as 's adjacency list.\nAcknowledgements. This work is funded in part by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) -438107855.\n. Apache Giraph, n.d.Apache Giraph. https://giraph.apache.org/ [2] [n.d.]. DNE. https://github.com/masatoshihanai/DistributedNE\n\nIT Graph. n.d.HDRF. https://github.com/fabiopetroni/VGP [6] [n.d.]. IT Graph. http://law.di.unimi.it/webdata/it-2004/\n\nWDC Graph. TW Graphn.d.. html [12] [n.d.. n.d.[n.d.]. TW Graph. https://snap.stanford.edu/data/twitter-2010.html [12] [n.d.]. UK Graph. http://law.di.unimi.it/webdata/uk-2007-05/ [13] [n.d.]. WDC Graph. http://webdatacommons.org/hyperlinkgraph/\n\nStatistical mechanics of complex networks. R\u00e9ka Albert, Albert-L\u00e1szl\u00f3 Barab\u00e1si, 10.1103/RevModPhys.74.47Rev. Mod. Phys. 74R\u00e9ka Albert and Albert-L\u00e1szl\u00f3 Barab\u00e1si. 2002. Statistical mechanics of complex networks. Rev. Mod. Phys. 74 (Jan 2002), 47-97. Issue 1. https://doi.org/10.1103/ RevModPhys.74.47\n\nStreaming Min-max Hypergraph Partitioning. Dan Alistarh, Jennifer Iglesias, Milan Vojnovic, Proceedings of the 28th International Conference on Neural Information Processing Systems. the 28th International Conference on Neural Information Processing SystemsCambridge, MA, USAMIT Press2Dan Alistarh, Jennifer Iglesias, and Milan Vojnovic. 2015. Streaming Min-max Hypergraph Partitioning. In Proceedings of the 28th International Conference on Neural Information Processing Systems -Volume 2 (NIPS'15). MIT Press, Cambridge, MA, USA, 1900-1908. http://dl.acm.org/citation.cfm?id=2969442.2969452\n\nBUb-iNG: Massive Crawling for the Masses. Paolo Boldi, Andrea Marino, Massimo Santini, Sebastiano Vigna, Proceedings of the Companion Publication of the 23rd International Conference on World Wide Web. International World Wide Web Conferences Steering Committee. the Companion Publication of the 23rd International Conference on World Wide Web. International World Wide Web Conferences Steering CommitteePaolo Boldi, Andrea Marino, Massimo Santini, and Sebastiano Vigna. 2014. BUb- iNG: Massive Crawling for the Masses. In Proceedings of the Companion Publica- tion of the 23rd International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 227-228.\n\nLayered Label Propagation: A MultiResolution Coordinate-Free Ordering for Compressing Social Networks. Paolo Boldi, Marco Rosa, Massimo Santini, Sebastiano Vigna, Proceedings of the 20th International Conference on World Wide Web. Sadagopan Srinivasan, Krithi Ramamritham, Arun Kumar, M. P. Ravindra, Elisa Bertino, and Ravi Kumarthe 20th International Conference on World Wide WebACM PressPaolo Boldi, Marco Rosa, Massimo Santini, and Sebastiano Vigna. 2011. Layered Label Propagation: A MultiResolution Coordinate-Free Ordering for Compressing Social Networks. In Proceedings of the 20th International Conference on World Wide Web, Sadagopan Srinivasan, Krithi Ramamritham, Arun Kumar, M. P. Ravindra, Elisa Bertino, and Ravi Kumar (Eds.). ACM Press, 587-596.\n\nThe WebGraph Framework I: Compression Techniques. Paolo Boldi, Sebastiano Vigna, Proc. of the Thirteenth International World Wide Web Conference. of the Thirteenth International World Wide Web ConferenceManhattan, USAACMPaolo Boldi and Sebastiano Vigna. 2004. The WebGraph Framework I: Com- pression Techniques. In Proc. of the Thirteenth International World Wide Web Conference (WWW 2004). ACM, Manhattan, USA, 595-601.\n\nBalanced Graph Edge Partition. Florian Bourse, Marc Lelarge, Milan Vojnovic, 10.1145/2623330.2623660Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '14). the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '14)New York, NY, USAACMFlorian Bourse, Marc Lelarge, and Milan Vojnovic. 2014. Balanced Graph Edge Partition. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '14). ACM, New York, NY, USA, 1456-1465. https://doi.org/10.1145/2623330.2623660\n\nApproximating Small Balanced Vertex Separators in Almost Linear Time. Sebastian Brandt, Roger Wattenhofer, Algorithms and Data Structures. J\u00f6rg-R\u00fcdiger SackFaith Ellen, Antonina Kolokolova; ChamSpringer International PublishingSebastian Brandt and Roger Wattenhofer. 2017. Approximating Small Balanced Vertex Separators in Almost Linear Time. In Algorithms and Data Structures, Faith Ellen, Antonina Kolokolova, and J\u00f6rg-R\u00fcdiger Sack (Eds.). Springer International Publishing, Cham, 229-240.\n\nRecent Advances in Graph Partitioning. Ayd\u0131n Bulu\u00e7, Ilya Henning Meyerhenke, Peter Safro, Christian Sanders, Schulz, 10.1007/978-3-319-49487-6_4Algorithm Engineering: Selected Results and Surveys. Lasse Kliemann and Peter SandersChamSpringer International PublishingAyd\u0131n Bulu\u00e7, Henning Meyerhenke, Ilya Safro, Peter Sanders, and Christian Schulz. 2016. Recent Advances in Graph Partitioning. In Algorithm Engineering: Selected Results and Surveys, Lasse Kliemann and Peter Sanders (Eds.). Springer International Publishing, Cham, 117-158. https://doi.org/10.1007/978-3-319- 49487-6_4\n\nParallel Sparse Matrix-Vector and Matrix-Transpose-Vector Multiplication Using Compressed Sparse Blocks. Aydin Bulu\u00e7, Jeremy T Fineman, Matteo Frigo, John R Gilbert, Charles E Leiserson, 10.1145/1583991.1584053Proceedings of the Twenty-First Annual Symposium on Parallelism in Algorithms and Architectures (SPAA '09). the Twenty-First Annual Symposium on Parallelism in Algorithms and Architectures (SPAA '09)New York, NY, USAAssociation for Computing MachineryAydin Bulu\u00e7, Jeremy T. Fineman, Matteo Frigo, John R. Gilbert, and Charles E. Leiserson. 2009. Parallel Sparse Matrix-Vector and Matrix-Transpose-Vector Multiplication Using Compressed Sparse Blocks. In Proceedings of the Twenty- First Annual Symposium on Parallelism in Algorithms and Architectures (SPAA '09). Association for Computing Machinery, New York, NY, USA, 233-244. https: //doi.org/10.1145/1583991.1584053\n\nPowerLyra: Differentiated Graph Computation and Partitioning on Skewed Graphs. Rong Chen, Jiaxin Shi, Yanzhe Chen, Haibo Chen, 10.1145/2741948.2741970Proceedings of the Tenth European Conference on Computer Systems (EuroSys '15). the Tenth European Conference on Computer Systems (EuroSys '15)New York, NY, USAACMArticle 1, 15 pagesRong Chen, Jiaxin Shi, Yanzhe Chen, and Haibo Chen. 2015. PowerLyra: Differ- entiated Graph Computation and Partitioning on Skewed Graphs. In Proceedings of the Tenth European Conference on Computer Systems (EuroSys '15). ACM, New York, NY, USA, Article 1, 15 pages. https://doi.org/10.1145/2741948.2741970\n\nApplication Driven Graph Partitioning. Wenfei Fan, Ruochun Jin, Muyang Liu, Ping Lu, Xiaojian Luo, Ruiqi Xu, Qiang Yin, Wenyuan Yu, Jingren Zhou, 10.1145/3318464.3389745Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data (SIGMOD '20). the 2020 ACM SIGMOD International Conference on Management of Data (SIGMOD '20)New York, NY, USAAssociation for Computing MachineryWenfei Fan, Ruochun Jin, Muyang Liu, Ping Lu, Xiaojian Luo, Ruiqi Xu, Qiang Yin, Wenyuan Yu, and Jingren Zhou. 2020. Application Driven Graph Partitioning. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data (SIGMOD '20). Association for Computing Machinery, New York, NY, USA, 1765-1779. https://doi.org/10.1145/3318464.3389745\n\nIncrementalization of Graph Partitioning Algorithms. Wenfei Fan, Muyang Liu, Chao Tian, Ruiqi Xu, Jingren Zhou, Proc. VLDB Endow. VLDB Endow1314Wenfei Fan, Muyang Liu, Chao Tian, Ruiqi Xu, and Jingren Zhou. 2020. Incre- mentalization of Graph Partitioning Algorithms. Proc. VLDB Endow. 13, 8 (2020), 14.\n\nImproved Approximation Algorithms for Minimum-Weight Vertex Separators. Uriel Feige, Mohammad Taghi Hajiaghayi, James R Lee, 10.1145/1060590.1060674Proceedings of the Thirty-Seventh Annual ACM Symposium on Theory of Computing (STOC '05). the Thirty-Seventh Annual ACM Symposium on Theory of Computing (STOC '05)New York, NY, USAAssociation for Computing MachineryUriel Feige, Mohammad Taghi Hajiaghayi, and James R. Lee. 2005. Improved Approximation Algorithms for Minimum-Weight Vertex Separators. In Proceed- ings of the Thirty-Seventh Annual ACM Symposium on Theory of Computing (STOC '05). Association for Computing Machinery, New York, NY, USA, 563-572. https://doi.org/10.1145/1060590.1060674\n\nCompressing relations and indexes. Jonathan Goldstein, Raghu Ramakrishnan, Uri Shaft, 10.1109/ICDE.1998.655800Proceedings 14th International Conference on Data Engineering. 370-379. 14th International Conference on Data Engineering. 370-379Jonathan Goldstein, Raghu Ramakrishnan, and Uri Shaft. 1998. Compressing relations and indexes. In Proceedings 14th International Conference on Data Engi- neering. 370-379. https://doi.org/10.1109/ICDE.1998.655800\n\nPowerGraph: Distributed Graph-Parallel Computation on Natural Graphs. Joseph E Gonzalez, Yucheng Low, Haijie Gu, Danny Bickson, Carlos Guestrin, 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 12). USENIX. Joseph E. Gonzalez, Yucheng Low, Haijie Gu, Danny Bickson, and Carlos Guestrin. 2012. PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs. In 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 12). USENIX, 17-30. https://www.usenix.org/conference/osdi12/technical- sessions/presentation/gonzalez\n\nGraphX: Graph Processing in a Distributed Dataflow Framework. Joseph E Gonzalez, Reynold S Xin, Ankur Dave, Daniel Crankshaw, Michael J Franklin, Ion Stoica, 11th USENIX Symposium on Operating Systems Design and Implementation (OSDI 14). USENIX. Joseph E. Gonzalez, Reynold S. Xin, Ankur Dave, Daniel Crankshaw, Michael J. Franklin, and Ion Stoica. 2014. GraphX: Graph Processing in a Distributed Dataflow Framework. In 11th USENIX Symposium on Operating Systems De- sign and Implementation (OSDI 14). USENIX, 599-613. https://www.usenix.org/ conference/osdi14/technical-sessions/presentation/gonzalez\n\nDistributed Edge Partitioning for Trillion-Edge Graphs. Masatoshi Hanai, Toyotaro Suzumura, Wen Jun Tan, Elvis Liu, 10.14778/3358701.3358706Proc. VLDB Endow. VLDB Endow12Georgios Theodoropoulos, and Wentong CaiMasatoshi Hanai, Toyotaro Suzumura, Wen Jun Tan, Elvis Liu, Georgios Theodor- opoulos, and Wentong Cai. 2019. Distributed Edge Partitioning for Trillion- Edge Graphs. Proc. VLDB Endow. 12, 13 (Sept. 2019), 2379-2392. https: //doi.org/10.14778/3358701.3358706\n\nA Multilevel Algorithm for Partitioning Graphs. Bruce Hendrickson, Robert Leland, 10.1145/224170.224228Proceedings of the 1995 ACM/IEEE Conference on Supercomputing (Supercomputing '95). the 1995 ACM/IEEE Conference on Supercomputing (Supercomputing '95)New York, NY, USAAssociation for Computing Machinery28Bruce Hendrickson and Robert Leland. 1995. A Multilevel Algorithm for Partition- ing Graphs. In Proceedings of the 1995 ACM/IEEE Conference on Supercomputing (Supercomputing '95). Association for Computing Machinery, New York, NY, USA, 28-es. https://doi.org/10.1145/224170.224228\n\nGraphBuilder: Scalable Graph ETL Framework. Nilesh Jain, Guangdeng Liao, Theodore L Willke, 10.1145/2484425.2484429First International Workshop on Graph Data Management Experiences and Systems (GRADES '13). New York, NY, USAACMNilesh Jain, Guangdeng Liao, and Theodore L. Willke. 2013. GraphBuilder: Scalable Graph ETL Framework. In First International Workshop on Graph Data Management Experiences and Systems (GRADES '13). ACM, New York, NY, USA, Article 4, 6 pages. https://doi.org/10.1145/2484425.2484429\n\nLocal Graph Edge Partitioning with a Two-Stage Heuristic Method. Shengwei Ji, Chenyang Bu, Lei Li, Xindong Wu, 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS). Shengwei Ji, Chenyang Bu, Lei Li, and Xindong Wu. 2019. Local Graph Edge Partitioning with a Two-Stage Heuristic Method. In 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS). 228-237.\n\nA Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs. George Karypis, Vipin Kumar, 10.1137/S1064827595287997SIAM J. Sci. Comput. 20George Karypis and Vipin Kumar. 1998. A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs. SIAM J. Sci. Comput. 20, 1 (Dec. 1998), 359-392. https://doi.org/10.1137/S1064827595287997\n\nAn efficient heuristic procedure for partitioning graphs. Brian W Kernighan, Shen Lin, The Bell System Technical Journal. 49Brian W. Kernighan and Shen Lin. 1970. An efficient heuristic procedure for partitioning graphs. The Bell System Technical Journal 49, 2 (1970), 291-307.\n\nWhat is Twitter, a Social Network or a News Media. Haewoon Kwak, Changhyun Lee, Hosung Park, Sue Moon, 10.1145/1772690.1772751Proceedings of the 19th International Conference on World Wide Web (WWW '10). the 19th International Conference on World Wide Web (WWW '10)New York, NY, USAACMHaewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. 2010. What is Twitter, a Social Network or a News Media?. In Proceedings of the 19th Interna- tional Conference on World Wide Web (WWW '10). ACM, New York, NY, USA, 591-600. https://doi.org/10.1145/1772690.1772751\n\nGraphChi: Large-Scale Graph Computation on Just a PC. Aapo Kyrola, Guy Blelloch, Carlos Guestrin, 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 12). USENIX. Aapo Kyrola, Guy Blelloch, and Carlos Guestrin. 2012. GraphChi: Large-Scale Graph Computation on Just a PC. In 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 12). USENIX, 31-46. https://www. usenix.org/conference/osdi12/technical-sessions/presentation/kyrola\n\nMulti-threaded graph partitioning. Dominique Lasalle, George Karypis, 2013 IEEE 27th International Symposium on Parallel and Distributed Processing. IEEEDominique LaSalle and George Karypis. 2013. Multi-threaded graph partitioning. In 2013 IEEE 27th International Symposium on Parallel and Distributed Processing. IEEE, 225-236.\n\nJure Leskovec, Andrej Krevl, SNAP Datasets: Stanford Large Network Dataset Collection. Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data.\n\nSlashBurn: Graph Compression and Mining beyond Caveman Communities. Yongsub Lim, Christos Kang, Faloutsos, 10.1109/TKDE.2014.2320716IEEE Transactions on Knowledge and Data Engineering. 26Yongsub Lim, U Kang, and Christos Faloutsos. 2014. SlashBurn: Graph Compres- sion and Mining beyond Caveman Communities. IEEE Transactions on Knowledge and Data Engineering 26, 12 (2014), 3077-3089. https://doi.org/10.1109/TKDE. 2014.2320716\n\nDistributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud. Yucheng Low, Danny Bickson, Joseph Gonzalez, Carlos Guestrin, Aapo Kyrola, Joseph M Hellerstein, 10.14778/2212351.2212354Proc. VLDB Endow. VLDB Endow5Yucheng Low, Danny Bickson, Joseph Gonzalez, Carlos Guestrin, Aapo Kyrola, and Joseph M. Hellerstein. 2012. Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud. Proc. VLDB Endow. 5, 8 (April 2012), 716-727. https://doi.org/10.14778/2212351.2212354\n\nMosaic: Processing a Trillion-Edge Graph on a Single Machine. Steffen Maass, Changwoo Min, Sanidhya Kashyap, Woonhak Kang, Mohan Kumar, Taesoo Kim, 10.1145/3064176.3064191Proceedings of the Twelfth European Conference on Computer Systems (EuroSys '17). the Twelfth European Conference on Computer Systems (EuroSys '17)New York, NY, USAACMSteffen Maass, Changwoo Min, Sanidhya Kashyap, Woonhak Kang, Mohan Kumar, and Taesoo Kim. 2017. Mosaic: Processing a Trillion-Edge Graph on a Single Machine. In Proceedings of the Twelfth European Conference on Computer Systems (EuroSys '17). ACM, New York, NY, USA, 527-543. https://doi.org/10.1145/ 3064176.3064191\n\nPregel: A System for Largescale Graph Processing. Grzegorz Malewicz, Matthew H Austern, J Aart, James C Bik, Ilan Dehnert, Naty Horn, Grzegorz Leiser, Czajkowski, 10.1145/1807167.1807184Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data (SIGMOD '10). the 2010 ACM SIGMOD International Conference on Management of Data (SIGMOD '10)New York, NY, USAACMGrzegorz Malewicz, Matthew H. Austern, Aart J.C Bik, James C. Dehnert, Ilan Horn, Naty Leiser, and Grzegorz Czajkowski. 2010. Pregel: A System for Large- scale Graph Processing. In Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data (SIGMOD '10). ACM, New York, NY, USA, 135-146. https://doi.org/10.1145/1807167.1807184\n\nA Scalable Distributed Graph Partitioner. Daniel Margo, Margo Seltzer, 10.14778/2824032.2824046Proc. VLDB Endow. VLDB Endow8Daniel Margo and Margo Seltzer. 2015. A Scalable Distributed Graph Partitioner. Proc. VLDB Endow. 8, 12 (Aug. 2015), 1478-1489. https://doi.org/10.14778/2824032. 2824046\n\nSpinner: Scalable Graph Partitioning in the Cloud. Claudio Martella, 10.1109/ICDE.2017.1532017 IEEE 33rd International Conference on Data Engineering (ICDE). Dionysios Logothetis, Andreas Loukas, and Georgos SiganosClaudio Martella, Dionysios Logothetis, Andreas Loukas, and Georgos Siganos. 2017. Spinner: Scalable Graph Partitioning in the Cloud. In 2017 IEEE 33rd International Conference on Data Engineering (ICDE). 1083-1094. https://doi.org/ 10.1109/ICDE.2017.153\n\nHYPE: Massive Hypergraph Partitioning with Neighborhood Expansion. Christian Mayer, Ruben Mayer, Sukanya Bhowmik, Lukas Epple, Kurt Rothermel, 10.1109/BigData.2018.86219682018 IEEE International Conference on Big Data (Big Data. Christian Mayer, Ruben Mayer, Sukanya Bhowmik, Lukas Epple, and Kurt Rother- mel. 2018. HYPE: Massive Hypergraph Partitioning with Neighborhood Expan- sion. In 2018 IEEE International Conference on Big Data (Big Data). 458-467. https://doi.org/10.1109/BigData.2018.8621968\n\nADWISE: Adaptive Window-Based Streaming Edge Partitioning for High-Speed Graph Processing. Christian Mayer, Ruben Mayer, Muhammad Adnan Tariq, Heiko Geppert, Larissa Laich, Lukas Rieger, Kurt Rothermel, 10.1109/ICDCS.2018.00072IEEE 38th International Conference on Distributed Computing Systems (ICDCS). Christian Mayer, Ruben Mayer, Muhammad Adnan Tariq, Heiko Geppert, Larissa Laich, Lukas Rieger, and Kurt Rothermel. 2018. ADWISE: Adaptive Window- Based Streaming Edge Partitioning for High-Speed Graph Processing. In 2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS). 685-695. https://doi.org/10.1109/ICDCS.2018.00072\n\nRestreaming Graph Partitioning: Simple Versatile Algorithms for Advanced Balancing. Joel Nishimura, Johan Ugander, 10.1145/2487575.2487696Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '13). the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '13)New York, NY, USAACMJoel Nishimura and Johan Ugander. 2013. Restreaming Graph Partitioning: Simple Versatile Algorithms for Advanced Balancing. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '13). ACM, New York, NY, USA, 1106-1114. https://doi.org/10.1145/2487575. 2487696\n\nExperimental Analysis of Streaming Algorithms for Graph Partitioning. Anil Pacaci, M. Tamer \u00d6zsu, 10.1145/3299869.3300076Proceedings of the 2019 International Conference on Management of Data (SIGMOD '19). the 2019 International Conference on Management of Data (SIGMOD '19)New York, NY, USAACMAnil Pacaci and M. Tamer \u00d6zsu. 2019. Experimental Analysis of Streaming Algo- rithms for Graph Partitioning. In Proceedings of the 2019 International Conference on Management of Data (SIGMOD '19). ACM, New York, NY, USA, 1375-1392. https://doi.org/10.1145/3299869.3300076\n\nSCOTCH: A Software Package for Static Mapping by Dual Recursive Bipartitioning of Process and Architecture Graphs. Fran\u00e7ois Pellegrini, Jean Roman, Proceedings of the International Conference and Exhibition on High-Performance Computing and Networking. the International Conference and Exhibition on High-Performance Computing and NetworkingEurope; Berlin, HeidelbergSpringer-VerlagFran\u00e7ois Pellegrini and Jean Roman. 1996. SCOTCH: A Software Package for Static Mapping by Dual Recursive Bipartitioning of Process and Architecture Graphs. In Proceedings of the International Conference and Exhibition on High- Performance Computing and Networking (HPCN Europe 1996). Springer-Verlag, Berlin, Heidelberg, 493-498.\n\nHDRF: Stream-Based Partitioning for Power-Law Graphs. Fabio Petroni, Leonardo Querzoni, Khuzaima Daudjee, Shahin Kamali, Giorgio Iacoboni, 10.1145/2806416.2806424Proceedings of the 24th ACM International Conference on Information and Knowledge Management (CIKM '15). the 24th ACM International Conference on Information and Knowledge Management (CIKM '15)New York, NY, USAACMFabio Petroni, Leonardo Querzoni, Khuzaima Daudjee, Shahin Kamali, and Giorgio Iacoboni. 2015. HDRF: Stream-Based Partitioning for Power-Law Graphs. In Proceedings of the 24th ACM International Conference on Informa- tion and Knowledge Management (CIKM '15). ACM, New York, NY, USA, 243-252. https://doi.org/10.1145/2806416.2806424\n\nChaos: Scale-out Graph Processing from Secondary Storage. Amitabha Roy, Laurent Bindschaedler, Jasmina Malicevic, Willy Zwaenepoel, 10.1145/2815400.2815408Proceedings of the 25th Symposium on Operating Systems Principles (SOSP '15). the 25th Symposium on Operating Systems Principles (SOSP '15)New York, NY, USAACMAmitabha Roy, Laurent Bindschaedler, Jasmina Malicevic, and Willy Zwaenepoel. 2015. Chaos: Scale-out Graph Processing from Secondary Storage. In Proceedings of the 25th Symposium on Operating Systems Principles (SOSP '15). ACM, New York, NY, USA, 410-424. https://doi.org/10.1145/2815400.2815408\n\nX-Stream: Edgecentric Graph Processing Using Streaming Partitions. Amitabha Roy, Ivo Mihailovic, Willy Zwaenepoel, 10.1145/2517349.2522740Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles (SOSP '13). the Twenty-Fourth ACM Symposium on Operating Systems Principles (SOSP '13)New York, NY, USAACMAmitabha Roy, Ivo Mihailovic, and Willy Zwaenepoel. 2013. X-Stream: Edge- centric Graph Processing Using Streaming Partitions. In Proceedings of the Twenty- Fourth ACM Symposium on Operating Systems Principles (SOSP '13). ACM, New York, NY, USA, 472-488. https://doi.org/10.1145/2517349.2522740\n\nEngineering multilevel graph partitioning algorithms. Peter Sanders, Christian Schulz, European Symposium on Algorithms. SpringerPeter Sanders and Christian Schulz. 2011. Engineering multilevel graph parti- tioning algorithms. In European Symposium on Algorithms. Springer, 469-480.\n\nScalable Edge Partitioning. Sebastian Schlag, Christian Schulz, Daniel Seemaier, Darren Strash, 2019 Proceedings of the Twenty-First Workshop on Algorithm Engineering and Experiments (ALENEX). SIAM. Sebastian Schlag, Christian Schulz, Daniel Seemaier, and Darren Strash. 2019. Scalable Edge Partitioning. In 2019 Proceedings of the Twenty-First Workshop on Algorithm Engineering and Experiments (ALENEX). SIAM, 211-225.\n\nTrinity: A Distributed Graph Engine on a Memory Cloud. Bin Shao, Haixun Wang, Yatao Li, 10.1145/2463676.2467799Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data (SIGMOD '13). the 2013 ACM SIGMOD International Conference on Management of Data (SIGMOD '13)New York, NY, USAACMBin Shao, Haixun Wang, and Yatao Li. 2013. Trinity: A Distributed Graph Engine on a Memory Cloud. In Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data (SIGMOD '13). ACM, New York, NY, USA, 505-516. https://doi.org/10.1145/2463676.2467799\n\nPartitioning Trillion-Edge Graphs in Minutes. George M Slota, Sivasankaran Rajamanickam, Karen Devine, Kamesh Madduri, 10.1109/IPDPS.2017.952017 IEEE International Parallel and Distributed Processing Symposium (IPDPS). George M. Slota, Sivasankaran Rajamanickam, Karen Devine, and Kamesh Madduri. 2017. Partitioning Trillion-Edge Graphs in Minutes. In 2017 IEEE International Parallel and Distributed Processing Symposium (IPDPS). 646-655. https://doi.org/10.1109/IPDPS.2017.95\n\nStreaming Graph Partitioning for Large Distributed Graphs. Isabelle Stanton, Gabriel Kliot, 10.1145/2339530.2339722Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '12). the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '12)New York, NY, USAACMIsabelle Stanton and Gabriel Kliot. 2012. Streaming Graph Partitioning for Large Distributed Graphs. In Proceedings of the 18th ACM SIGKDD International Confer- ence on Knowledge Discovery and Data Mining (KDD '12). ACM, New York, NY, USA, 1222-1230. https://doi.org/10.1145/2339530.2339722\n\nDirect solutions of sparse network equations by optimally ordered triangular factorization. F William, John W Tinney, Walker, Proc. IEEE. 55William F. Tinney and John W. Walker. 1967. Direct solutions of sparse network equations by optimally ordered triangular factorization. Proc. IEEE 55, 11 (1967), 1801-1809.\n\nFENNEL: Streaming Graph Partitioning for Massive Scale Graphs. Charalampos Tsourakakis, Christos Gkantsidis, Bozidar Radunovic, Milan Vojnovic, 10.1145/2556195.2556213Proceedings of the 7th ACM International Conference on Web Search and Data Mining (WSDM '14). the 7th ACM International Conference on Web Search and Data Mining (WSDM '14)New York, NY, USAACMCharalampos Tsourakakis, Christos Gkantsidis, Bozidar Radunovic, and Milan Vojnovic. 2014. FENNEL: Streaming Graph Partitioning for Massive Scale Graphs. In Proceedings of the 7th ACM International Conference on Web Search and Data Mining (WSDM '14). ACM, New York, NY, USA, 333-342. https://doi.org/10. 1145/2556195.2556213\n\nAn Experimental Comparison of Partitioning Strategies in Distributed Graph Processing. Shiv Verma, Luke M Leslie, Yosub Shin, Indranil Gupta, 10.14778/3055540.3055543Proc. VLDB Endow. VLDB Endow10Shiv Verma, Luke M. Leslie, Yosub Shin, and Indranil Gupta. 2017. An Experimen- tal Comparison of Partitioning Strategies in Distributed Graph Processing. Proc. VLDB Endow. 10, 5 (Jan. 2017), 493-504. https://doi.org/10.14778/3055540.3055543\n\nMesh Partitioning: A Multilevel Balancing and Refinement Algorithm. Chris Walshaw, Mark Cross, 10.1137/S1064827598337373SIAM Journal on Scientific Computing. 22Chris Walshaw and Mark Cross. 2000. Mesh Partitioning: A Multilevel Balancing and Refinement Algorithm. SIAM Journal on Scientific Computing 22, 1 (2000), 63-80. https://doi.org/10.1137/S1064827598337373\n\nA Programmatic Introduction to Neo4j. Jim Webber, 10.1145/2384716.2384777Proceedings of the 3rd Annual Conference on Systems, Programming, and Applications: Software for Humanity (SPLASH '12). the 3rd Annual Conference on Systems, Programming, and Applications: Software for Humanity (SPLASH '12)New York, NY, USAACMJim Webber. 2012. A Programmatic Introduction to Neo4j. In Proceedings of the 3rd Annual Conference on Systems, Programming, and Applications: Software for Humanity (SPLASH '12). ACM, New York, NY, USA, 217-218. https://doi.org/10. 1145/2384716.2384777\n\nDistributed Power-law Graph Computing: Theoretical and Empirical Analysis. Cong Xie, Ling Yan, Wu-Jun Li, Zhihua Zhang, Advances in Neural Information Processing Systems. 27Cong Xie, Ling Yan, Wu-Jun Li, and Zhihua Zhang. 2014. Distributed Power-law Graph Computing: Theoretical and Empirical Analysis. In Advances in Neural Information Processing Systems 27. 1673-1681.\n\nDefining and Evaluating Network Communities Based on Ground-Truth. Jaewon Yang, Jure Leskovec, 10.1109/ICDM.2012.1382012 IEEE 12th International Conference on Data Mining. Jaewon Yang and Jure Leskovec. 2012. Defining and Evaluating Network Com- munities Based on Ground-Truth. In 2012 IEEE 12th International Conference on Data Mining. 745-754. https://doi.org/10.1109/ICDM.2012.138\n\nGraph Edge Partitioning via Neighborhood Heuristic. Chenzi Zhang, Fan Wei, Qin Liu, Zhihao Gavin Tang, Zhenguo Li, 10.1145/3097983.3098033Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '17). the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '17)New York, NY, USAACMChenzi Zhang, Fan Wei, Qin Liu, Zhihao Gavin Tang, and Zhenguo Li. 2017. Graph Edge Partitioning via Neighborhood Heuristic. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '17). ACM, New York, NY, USA, 605-614. https://doi.org/10.1145/3097983.3098033\n\nGridGraph: Large-Scale Graph Processing on a Single Machine Using 2-Level Hierarchical Partitioning. Xiaowei Zhu, Wentao Han, Wenguang Chen, 2015 USENIX Annual Technical Conference (USENIX ATC 15). USENIX. Xiaowei Zhu, Wentao Han, and Wenguang Chen. 2015. GridGraph: Large-Scale Graph Processing on a Single Machine Using 2-Level Hierarchical Partitioning. In 2015 USENIX Annual Technical Conference (USENIX ATC 15). USENIX, 375-386. https://www.usenix.org/conference/atc15/technical-session/presentation/zhu\n", "annotations": {"author": "[{\"end\":178,\"start\":92},{\"end\":279,\"start\":179}]", "publisher": "[{\"end\":25,\"start\":22},{\"end\":446,\"start\":443}]", "author_last_name": "[{\"end\":103,\"start\":98},{\"end\":197,\"start\":189}]", "author_first_name": "[{\"end\":97,\"start\":92},{\"end\":188,\"start\":179}]", "author_affiliation": "[{\"end\":177,\"start\":124},{\"end\":278,\"start\":225}]", "title": "[{\"end\":21,\"start\":1},{\"end\":300,\"start\":280}]", "venue": "[{\"end\":406,\"start\":302}]", "abstract": "[{\"end\":2609,\"start\":933}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2756,\"start\":2752},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2768,\"start\":2765},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":2783,\"start\":2779},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2800,\"start\":2796},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2819,\"start\":2815},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":2831,\"start\":2827},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":2849,\"start\":2845},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3566,\"start\":3562},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3569,\"start\":3566},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3572,\"start\":3569},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3790,\"start\":3786},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":3793,\"start\":3790},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":3796,\"start\":3793},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4246,\"start\":4242},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4249,\"start\":4246},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":4403,\"start\":4399},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":4524,\"start\":4520},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":4527,\"start\":4524},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":4530,\"start\":4527},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":4533,\"start\":4530},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":4536,\"start\":4533},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4633,\"start\":4629},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":4636,\"start\":4633},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":4639,\"start\":4636},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":4642,\"start\":4639},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4672,\"start\":4668},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":4675,\"start\":4672},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":4678,\"start\":4675},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":4681,\"start\":4678},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":4684,\"start\":4681},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":5301,\"start\":5297},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5331,\"start\":5327},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5629,\"start\":5625},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5632,\"start\":5629},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":5635,\"start\":5632},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":5638,\"start\":5635},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5697,\"start\":5693},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5700,\"start\":5697},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":5703,\"start\":5700},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5706,\"start\":5703},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":5709,\"start\":5706},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":5906,\"start\":5902},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5909,\"start\":5906},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":5912,\"start\":5909},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":6057,\"start\":6053},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":7463,\"start\":7459},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9192,\"start\":9188},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":9195,\"start\":9192},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":10434,\"start\":10430},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11018,\"start\":11014},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11283,\"start\":11279},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11846,\"start\":11842},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":11849,\"start\":11846},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":11852,\"start\":11849},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":13184,\"start\":13181},{\"end\":13187,\"start\":13184},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13193,\"start\":13189},{\"end\":13197,\"start\":13193},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":13251,\"start\":13247},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":13296,\"start\":13292},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":15917,\"start\":15913},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":16378,\"start\":16374},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":17342,\"start\":17338},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":17346,\"start\":17342},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":17350,\"start\":17346},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":17354,\"start\":17350},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":17358,\"start\":17354},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":17362,\"start\":17358},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":17366,\"start\":17362},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17994,\"start\":17990},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":17998,\"start\":17994},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":18002,\"start\":17998},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":18814,\"start\":18810},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":18817,\"start\":18814},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":24180,\"start\":24179},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":26252,\"start\":26251},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":31336,\"start\":31332},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":31692,\"start\":31688},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32117,\"start\":32113},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":32133,\"start\":32129},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":32200,\"start\":32196},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":32422,\"start\":32418},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":36908,\"start\":36904},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":36925,\"start\":36921},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":37006,\"start\":37002},{\"end\":38162,\"start\":38160},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":38167,\"start\":38163},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":38171,\"start\":38167},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":38175,\"start\":38171},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":38189,\"start\":38185},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":38193,\"start\":38189},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":38197,\"start\":38193},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":38211,\"start\":38207},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":38215,\"start\":38211},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":38219,\"start\":38215},{\"end\":38232,\"start\":38228},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":38363,\"start\":38359},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":38366,\"start\":38363},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":38369,\"start\":38366},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":38968,\"start\":38964},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":38978,\"start\":38974},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":38989,\"start\":38985},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":39003,\"start\":38999},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":39068,\"start\":39064},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":39078,\"start\":39074},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":39093,\"start\":39089},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":42367,\"start\":42363},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":42370,\"start\":42367},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":51649,\"start\":51645},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":51662,\"start\":51658},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":51675,\"start\":51671},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":51687,\"start\":51683},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":51690,\"start\":51687},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":51704,\"start\":51700},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":51707,\"start\":51704},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":52250,\"start\":52246},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":52365,\"start\":52361},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":52383,\"start\":52379},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":52629,\"start\":52625},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":52721,\"start\":52717},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":52992,\"start\":52988},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":53020,\"start\":53016},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":53790,\"start\":53786},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":53793,\"start\":53790},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":53883,\"start\":53879},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":53886,\"start\":53883},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":53889,\"start\":53886},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":53892,\"start\":53889},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":54032,\"start\":54028},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":54161,\"start\":54157},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":54264,\"start\":54260},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":54585,\"start\":54581},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":54805,\"start\":54801},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":54985,\"start\":54981},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":54988,\"start\":54985},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":55138,\"start\":55134},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":55165,\"start\":55161},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":55535,\"start\":55531},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":55948,\"start\":55944},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":55963,\"start\":55959},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":55975,\"start\":55971},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":55992,\"start\":55988},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":56008,\"start\":56004},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":57244,\"start\":57240},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":57247,\"start\":57244},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":57392,\"start\":57388},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":57433,\"start\":57429},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":57765,\"start\":57761},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":58042,\"start\":58038},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":58045,\"start\":58042},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":59076,\"start\":59072},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":59080,\"start\":59076}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":59778,\"start\":59723},{\"attributes\":{\"id\":\"fig_2\"},\"end\":59846,\"start\":59779},{\"attributes\":{\"id\":\"fig_3\"},\"end\":59977,\"start\":59847},{\"attributes\":{\"id\":\"fig_4\"},\"end\":60079,\"start\":59978},{\"attributes\":{\"id\":\"fig_5\"},\"end\":60252,\"start\":60080},{\"attributes\":{\"id\":\"fig_6\"},\"end\":60320,\"start\":60253},{\"attributes\":{\"id\":\"fig_7\"},\"end\":60369,\"start\":60321},{\"attributes\":{\"id\":\"fig_8\"},\"end\":60566,\"start\":60370},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":60598,\"start\":60567},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":61117,\"start\":60599},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":61172,\"start\":61118},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":61710,\"start\":61173},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":62441,\"start\":61711},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":62731,\"start\":62442},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":62848,\"start\":62732},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":64720,\"start\":62849},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":64767,\"start\":64721}]", "paragraph": "[{\"end\":4537,\"start\":2625},{\"end\":5710,\"start\":4539},{\"end\":6219,\"start\":5712},{\"end\":6978,\"start\":6221},{\"end\":7027,\"start\":6980},{\"end\":7773,\"start\":7029},{\"end\":8514,\"start\":7775},{\"end\":8940,\"start\":8516},{\"end\":10581,\"start\":8972},{\"end\":11144,\"start\":10583},{\"end\":11853,\"start\":11146},{\"end\":12179,\"start\":11855},{\"end\":12905,\"start\":12207},{\"end\":13897,\"start\":12927},{\"end\":14197,\"start\":13899},{\"end\":14279,\"start\":14258},{\"end\":14311,\"start\":14281},{\"end\":14394,\"start\":14313},{\"end\":14417,\"start\":14396},{\"end\":14519,\"start\":14434},{\"end\":14805,\"start\":14521},{\"end\":15201,\"start\":14807},{\"end\":15372,\"start\":15203},{\"end\":15705,\"start\":15396},{\"end\":16074,\"start\":15741},{\"end\":16257,\"start\":16076},{\"end\":18333,\"start\":16259},{\"end\":20013,\"start\":18335},{\"end\":20832,\"start\":20015},{\"end\":21166,\"start\":20834},{\"end\":21440,\"start\":21168},{\"end\":21554,\"start\":21442},{\"end\":21953,\"start\":21577},{\"end\":22924,\"start\":21955},{\"end\":23459,\"start\":22926},{\"end\":23754,\"start\":23461},{\"end\":23992,\"start\":23756},{\"end\":24018,\"start\":23994},{\"end\":24145,\"start\":24020},{\"end\":24231,\"start\":24147},{\"end\":24261,\"start\":24233},{\"end\":24300,\"start\":24263},{\"end\":25683,\"start\":24302},{\"end\":26200,\"start\":25685},{\"end\":26295,\"start\":26202},{\"end\":26313,\"start\":26297},{\"end\":26327,\"start\":26315},{\"end\":26353,\"start\":26329},{\"end\":26364,\"start\":26355},{\"end\":26405,\"start\":26366},{\"end\":26430,\"start\":26407},{\"end\":26446,\"start\":26432},{\"end\":26457,\"start\":26448},{\"end\":26484,\"start\":26459},{\"end\":26491,\"start\":26486},{\"end\":26535,\"start\":26493},{\"end\":26603,\"start\":26537},{\"end\":26641,\"start\":26605},{\"end\":26706,\"start\":26643},{\"end\":26757,\"start\":26708},{\"end\":26795,\"start\":26759},{\"end\":28237,\"start\":26831},{\"end\":28624,\"start\":28239},{\"end\":29294,\"start\":28637},{\"end\":30606,\"start\":29296},{\"end\":30856,\"start\":30608},{\"end\":31267,\"start\":30901},{\"end\":32458,\"start\":31269},{\"end\":32676,\"start\":32483},{\"end\":33353,\"start\":32696},{\"end\":34564,\"start\":33355},{\"end\":34794,\"start\":34566},{\"end\":35355,\"start\":34796},{\"end\":35623,\"start\":35375},{\"end\":36702,\"start\":35625},{\"end\":36791,\"start\":36704},{\"end\":37111,\"start\":36824},{\"end\":38802,\"start\":37148},{\"end\":39479,\"start\":38804},{\"end\":39778,\"start\":39481},{\"end\":41006,\"start\":39780},{\"end\":41552,\"start\":41029},{\"end\":42250,\"start\":41554},{\"end\":42953,\"start\":42252},{\"end\":44079,\"start\":42955},{\"end\":44493,\"start\":44081},{\"end\":46708,\"start\":44526},{\"end\":47418,\"start\":46710},{\"end\":48664,\"start\":47420},{\"end\":48832,\"start\":48666},{\"end\":49420,\"start\":48877},{\"end\":49871,\"start\":49422},{\"end\":50475,\"start\":49873},{\"end\":50604,\"start\":50477},{\"end\":51458,\"start\":50629},{\"end\":52238,\"start\":51475},{\"end\":52946,\"start\":52240},{\"end\":53684,\"start\":52948},{\"end\":54568,\"start\":53686},{\"end\":55090,\"start\":54570},{\"end\":55519,\"start\":55092},{\"end\":56421,\"start\":55521},{\"end\":57008,\"start\":56437},{\"end\":57248,\"start\":57010},{\"end\":58123,\"start\":57279},{\"end\":58560,\"start\":58125},{\"end\":58820,\"start\":58562},{\"end\":59719,\"start\":58855},{\"end\":59722,\"start\":59721}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14257,\"start\":14198},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14433,\"start\":14418},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15395,\"start\":15373},{\"attributes\":{\"id\":\"formula_3\"},\"end\":28636,\"start\":28625}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21019,\"start\":20961},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21164,\"start\":21157},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":24298,\"start\":24291},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":38014,\"start\":38005},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":46088,\"start\":46081},{\"attributes\":{\"ref_id\":\"tab_12\"},\"end\":51047,\"start\":51039}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2623,\"start\":2611},{\"attributes\":{\"n\":\"2\"},\"end\":8970,\"start\":8943},{\"attributes\":{\"n\":\"3\"},\"end\":12205,\"start\":12182},{\"attributes\":{\"n\":\"3.1\"},\"end\":12925,\"start\":12908},{\"attributes\":{\"n\":\"3.2\"},\"end\":15739,\"start\":15708},{\"attributes\":{\"n\":\"3.2.2\"},\"end\":21575,\"start\":21557},{\"attributes\":{\"n\":\"3.2.3\"},\"end\":26829,\"start\":26798},{\"attributes\":{\"n\":\"3.3\"},\"end\":30899,\"start\":30859},{\"attributes\":{\"n\":\"4\"},\"end\":32481,\"start\":32461},{\"attributes\":{\"n\":\"4.1\"},\"end\":32694,\"start\":32679},{\"attributes\":{\"n\":\"4.2\"},\"end\":35373,\"start\":35358},{\"attributes\":{\"n\":\"4.3\"},\"end\":36822,\"start\":36794},{\"attributes\":{\"n\":\"4.4\"},\"end\":37146,\"start\":37114},{\"attributes\":{\"n\":\"5.2\"},\"end\":41027,\"start\":41009},{\"attributes\":{\"n\":\"5.3\"},\"end\":44524,\"start\":44496},{\"attributes\":{\"n\":\"5.4\"},\"end\":48875,\"start\":48835},{\"attributes\":{\"n\":\"5.5\"},\"end\":50627,\"start\":50607},{\"attributes\":{\"n\":\"6\"},\"end\":51473,\"start\":51461},{\"attributes\":{\"n\":\"7\"},\"end\":56435,\"start\":56424},{\"end\":57277,\"start\":57251},{\"end\":58853,\"start\":58823},{\"end\":59734,\"start\":59724},{\"end\":59790,\"start\":59780},{\"end\":59858,\"start\":59848},{\"end\":59989,\"start\":59979},{\"end\":60101,\"start\":60081},{\"end\":60262,\"start\":60254},{\"end\":60381,\"start\":60371},{\"end\":60577,\"start\":60568},{\"end\":61128,\"start\":61119},{\"end\":61183,\"start\":61174},{\"end\":61721,\"start\":61712},{\"end\":62452,\"start\":62443},{\"end\":62742,\"start\":62733},{\"end\":64731,\"start\":64722}]", "table": "[{\"end\":61117,\"start\":60633},{\"end\":61710,\"start\":61226},{\"end\":62441,\"start\":62218},{\"end\":62731,\"start\":62454},{\"end\":62848,\"start\":62744},{\"end\":64720,\"start\":63354}]", "figure_caption": "[{\"end\":59778,\"start\":59736},{\"end\":59846,\"start\":59792},{\"end\":59977,\"start\":59860},{\"end\":60079,\"start\":59991},{\"end\":60252,\"start\":60104},{\"end\":60320,\"start\":60264},{\"end\":60369,\"start\":60323},{\"end\":60566,\"start\":60383},{\"end\":60598,\"start\":60579},{\"end\":60633,\"start\":60601},{\"end\":61172,\"start\":61130},{\"end\":61226,\"start\":61185},{\"end\":62218,\"start\":61723},{\"end\":63354,\"start\":62851},{\"end\":64767,\"start\":64733}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9557,\"start\":9549},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9914,\"start\":9906},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10739,\"start\":10731},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13092,\"start\":13083},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18085,\"start\":18077},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":19374,\"start\":19366},{\"end\":20401,\"start\":20393},{\"end\":21055,\"start\":21047},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":21880,\"start\":21872},{\"end\":25088,\"start\":25080},{\"end\":25915,\"start\":25907},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":40662,\"start\":40639},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":41004,\"start\":40981},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":42868,\"start\":42856},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":42951,\"start\":42939},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":43392,\"start\":43383},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":43581,\"start\":43551},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":48830,\"start\":48822},{\"end\":49403,\"start\":49395},{\"end\":49478,\"start\":49469},{\"end\":49725,\"start\":49705},{\"end\":49986,\"start\":49966},{\"end\":50331,\"start\":50322}]", "bib_author_first_name": "[{\"end\":65277,\"start\":65271},{\"end\":65810,\"start\":65806},{\"end\":65832,\"start\":65819},{\"end\":66110,\"start\":66107},{\"end\":66129,\"start\":66121},{\"end\":66145,\"start\":66140},{\"end\":66705,\"start\":66700},{\"end\":66719,\"start\":66713},{\"end\":66735,\"start\":66728},{\"end\":66755,\"start\":66745},{\"end\":67459,\"start\":67454},{\"end\":67472,\"start\":67467},{\"end\":67486,\"start\":67479},{\"end\":67506,\"start\":67496},{\"end\":68169,\"start\":68164},{\"end\":68187,\"start\":68177},{\"end\":68574,\"start\":68567},{\"end\":68587,\"start\":68583},{\"end\":68602,\"start\":68597},{\"end\":69214,\"start\":69205},{\"end\":69228,\"start\":69223},{\"end\":69672,\"start\":69667},{\"end\":69684,\"start\":69680},{\"end\":69710,\"start\":69705},{\"end\":69727,\"start\":69718},{\"end\":70324,\"start\":70319},{\"end\":70338,\"start\":70332},{\"end\":70340,\"start\":70339},{\"end\":70356,\"start\":70350},{\"end\":70368,\"start\":70364},{\"end\":70370,\"start\":70369},{\"end\":70387,\"start\":70380},{\"end\":70389,\"start\":70388},{\"end\":71177,\"start\":71173},{\"end\":71190,\"start\":71184},{\"end\":71202,\"start\":71196},{\"end\":71214,\"start\":71209},{\"end\":71779,\"start\":71773},{\"end\":71792,\"start\":71785},{\"end\":71804,\"start\":71798},{\"end\":71814,\"start\":71810},{\"end\":71827,\"start\":71819},{\"end\":71838,\"start\":71833},{\"end\":71848,\"start\":71843},{\"end\":71861,\"start\":71854},{\"end\":71873,\"start\":71866},{\"end\":72552,\"start\":72546},{\"end\":72564,\"start\":72558},{\"end\":72574,\"start\":72570},{\"end\":72586,\"start\":72581},{\"end\":72598,\"start\":72591},{\"end\":72875,\"start\":72870},{\"end\":72891,\"start\":72883},{\"end\":72897,\"start\":72892},{\"end\":72915,\"start\":72910},{\"end\":72917,\"start\":72916},{\"end\":73541,\"start\":73533},{\"end\":73558,\"start\":73553},{\"end\":73576,\"start\":73573},{\"end\":74029,\"start\":74023},{\"end\":74031,\"start\":74030},{\"end\":74049,\"start\":74042},{\"end\":74061,\"start\":74055},{\"end\":74071,\"start\":74066},{\"end\":74087,\"start\":74081},{\"end\":74592,\"start\":74586},{\"end\":74594,\"start\":74593},{\"end\":74612,\"start\":74605},{\"end\":74614,\"start\":74613},{\"end\":74625,\"start\":74620},{\"end\":74638,\"start\":74632},{\"end\":74657,\"start\":74650},{\"end\":74659,\"start\":74658},{\"end\":74673,\"start\":74670},{\"end\":75192,\"start\":75183},{\"end\":75208,\"start\":75200},{\"end\":75222,\"start\":75219},{\"end\":75226,\"start\":75223},{\"end\":75237,\"start\":75232},{\"end\":75650,\"start\":75645},{\"end\":75670,\"start\":75664},{\"end\":76237,\"start\":76231},{\"end\":76253,\"start\":76244},{\"end\":76268,\"start\":76260},{\"end\":76270,\"start\":76269},{\"end\":76770,\"start\":76762},{\"end\":76783,\"start\":76775},{\"end\":76791,\"start\":76788},{\"end\":76803,\"start\":76796},{\"end\":77189,\"start\":77183},{\"end\":77204,\"start\":77199},{\"end\":77530,\"start\":77525},{\"end\":77532,\"start\":77531},{\"end\":77548,\"start\":77544},{\"end\":77804,\"start\":77797},{\"end\":77820,\"start\":77811},{\"end\":77832,\"start\":77826},{\"end\":77842,\"start\":77839},{\"end\":78360,\"start\":78356},{\"end\":78372,\"start\":78369},{\"end\":78389,\"start\":78383},{\"end\":78820,\"start\":78811},{\"end\":78836,\"start\":78830},{\"end\":79110,\"start\":79106},{\"end\":79127,\"start\":79121},{\"end\":79396,\"start\":79389},{\"end\":79410,\"start\":79402},{\"end\":79843,\"start\":79836},{\"end\":79854,\"start\":79849},{\"end\":79870,\"start\":79864},{\"end\":79887,\"start\":79881},{\"end\":79902,\"start\":79898},{\"end\":79917,\"start\":79911},{\"end\":79919,\"start\":79918},{\"end\":80336,\"start\":80329},{\"end\":80352,\"start\":80344},{\"end\":80366,\"start\":80358},{\"end\":80383,\"start\":80376},{\"end\":80395,\"start\":80390},{\"end\":80409,\"start\":80403},{\"end\":80981,\"start\":80973},{\"end\":80999,\"start\":80992},{\"end\":81001,\"start\":81000},{\"end\":81012,\"start\":81011},{\"end\":81024,\"start\":81019},{\"end\":81026,\"start\":81025},{\"end\":81036,\"start\":81032},{\"end\":81050,\"start\":81046},{\"end\":81065,\"start\":81057},{\"end\":81703,\"start\":81697},{\"end\":81716,\"start\":81711},{\"end\":82008,\"start\":82001},{\"end\":82497,\"start\":82488},{\"end\":82510,\"start\":82505},{\"end\":82525,\"start\":82518},{\"end\":82540,\"start\":82535},{\"end\":82552,\"start\":82548},{\"end\":83024,\"start\":83015},{\"end\":83037,\"start\":83032},{\"end\":83053,\"start\":83045},{\"end\":83059,\"start\":83054},{\"end\":83072,\"start\":83067},{\"end\":83089,\"start\":83082},{\"end\":83102,\"start\":83097},{\"end\":83115,\"start\":83111},{\"end\":83666,\"start\":83662},{\"end\":83683,\"start\":83678},{\"end\":84327,\"start\":84323},{\"end\":84344,\"start\":84336},{\"end\":84943,\"start\":84935},{\"end\":84960,\"start\":84956},{\"end\":85593,\"start\":85588},{\"end\":85611,\"start\":85603},{\"end\":85630,\"start\":85622},{\"end\":85646,\"start\":85640},{\"end\":85662,\"start\":85655},{\"end\":86308,\"start\":86300},{\"end\":86321,\"start\":86314},{\"end\":86344,\"start\":86337},{\"end\":86361,\"start\":86356},{\"end\":86928,\"start\":86920},{\"end\":86937,\"start\":86934},{\"end\":86955,\"start\":86950},{\"end\":87531,\"start\":87526},{\"end\":87550,\"start\":87541},{\"end\":87793,\"start\":87784},{\"end\":87811,\"start\":87802},{\"end\":87826,\"start\":87820},{\"end\":87843,\"start\":87837},{\"end\":88235,\"start\":88232},{\"end\":88248,\"start\":88242},{\"end\":88260,\"start\":88255},{\"end\":88806,\"start\":88800},{\"end\":88808,\"start\":88807},{\"end\":88828,\"start\":88816},{\"end\":88848,\"start\":88843},{\"end\":88863,\"start\":88857},{\"end\":89300,\"start\":89292},{\"end\":89317,\"start\":89310},{\"end\":89956,\"start\":89955},{\"end\":89970,\"start\":89966},{\"end\":89972,\"start\":89971},{\"end\":90251,\"start\":90240},{\"end\":90273,\"start\":90265},{\"end\":90293,\"start\":90286},{\"end\":90310,\"start\":90305},{\"end\":90952,\"start\":90948},{\"end\":90964,\"start\":90960},{\"end\":90966,\"start\":90965},{\"end\":90980,\"start\":90975},{\"end\":90995,\"start\":90987},{\"end\":91373,\"start\":91368},{\"end\":91387,\"start\":91383},{\"end\":91706,\"start\":91703},{\"end\":92314,\"start\":92310},{\"end\":92324,\"start\":92320},{\"end\":92336,\"start\":92330},{\"end\":92347,\"start\":92341},{\"end\":92680,\"start\":92674},{\"end\":92691,\"start\":92687},{\"end\":93050,\"start\":93044},{\"end\":93061,\"start\":93058},{\"end\":93070,\"start\":93067},{\"end\":93082,\"start\":93076},{\"end\":93088,\"start\":93083},{\"end\":93102,\"start\":93095},{\"end\":93773,\"start\":93766},{\"end\":93785,\"start\":93779},{\"end\":93799,\"start\":93791}]", "bib_author_last_name": "[{\"end\":65284,\"start\":65278},{\"end\":65817,\"start\":65811},{\"end\":65841,\"start\":65833},{\"end\":66119,\"start\":66111},{\"end\":66138,\"start\":66130},{\"end\":66154,\"start\":66146},{\"end\":66711,\"start\":66706},{\"end\":66726,\"start\":66720},{\"end\":66743,\"start\":66736},{\"end\":66761,\"start\":66756},{\"end\":67465,\"start\":67460},{\"end\":67477,\"start\":67473},{\"end\":67494,\"start\":67487},{\"end\":67512,\"start\":67507},{\"end\":68175,\"start\":68170},{\"end\":68193,\"start\":68188},{\"end\":68581,\"start\":68575},{\"end\":68595,\"start\":68588},{\"end\":68611,\"start\":68603},{\"end\":69221,\"start\":69215},{\"end\":69240,\"start\":69229},{\"end\":69678,\"start\":69673},{\"end\":69703,\"start\":69685},{\"end\":69716,\"start\":69711},{\"end\":69735,\"start\":69728},{\"end\":69743,\"start\":69737},{\"end\":70330,\"start\":70325},{\"end\":70348,\"start\":70341},{\"end\":70362,\"start\":70357},{\"end\":70378,\"start\":70371},{\"end\":70399,\"start\":70390},{\"end\":71182,\"start\":71178},{\"end\":71194,\"start\":71191},{\"end\":71207,\"start\":71203},{\"end\":71219,\"start\":71215},{\"end\":71783,\"start\":71780},{\"end\":71796,\"start\":71793},{\"end\":71808,\"start\":71805},{\"end\":71817,\"start\":71815},{\"end\":71831,\"start\":71828},{\"end\":71841,\"start\":71839},{\"end\":71852,\"start\":71849},{\"end\":71864,\"start\":71862},{\"end\":71878,\"start\":71874},{\"end\":72556,\"start\":72553},{\"end\":72568,\"start\":72565},{\"end\":72579,\"start\":72575},{\"end\":72589,\"start\":72587},{\"end\":72603,\"start\":72599},{\"end\":72881,\"start\":72876},{\"end\":72908,\"start\":72898},{\"end\":72921,\"start\":72918},{\"end\":73551,\"start\":73542},{\"end\":73571,\"start\":73559},{\"end\":73582,\"start\":73577},{\"end\":74040,\"start\":74032},{\"end\":74053,\"start\":74050},{\"end\":74064,\"start\":74062},{\"end\":74079,\"start\":74072},{\"end\":74096,\"start\":74088},{\"end\":74603,\"start\":74595},{\"end\":74618,\"start\":74615},{\"end\":74630,\"start\":74626},{\"end\":74648,\"start\":74639},{\"end\":74668,\"start\":74660},{\"end\":74680,\"start\":74674},{\"end\":75198,\"start\":75193},{\"end\":75217,\"start\":75209},{\"end\":75230,\"start\":75227},{\"end\":75241,\"start\":75238},{\"end\":75662,\"start\":75651},{\"end\":75677,\"start\":75671},{\"end\":76242,\"start\":76238},{\"end\":76258,\"start\":76254},{\"end\":76277,\"start\":76271},{\"end\":76773,\"start\":76771},{\"end\":76786,\"start\":76784},{\"end\":76794,\"start\":76792},{\"end\":76806,\"start\":76804},{\"end\":77197,\"start\":77190},{\"end\":77210,\"start\":77205},{\"end\":77542,\"start\":77533},{\"end\":77552,\"start\":77549},{\"end\":77809,\"start\":77805},{\"end\":77824,\"start\":77821},{\"end\":77837,\"start\":77833},{\"end\":77847,\"start\":77843},{\"end\":78367,\"start\":78361},{\"end\":78381,\"start\":78373},{\"end\":78398,\"start\":78390},{\"end\":78828,\"start\":78821},{\"end\":78844,\"start\":78837},{\"end\":79119,\"start\":79111},{\"end\":79133,\"start\":79128},{\"end\":79400,\"start\":79397},{\"end\":79415,\"start\":79411},{\"end\":79426,\"start\":79417},{\"end\":79847,\"start\":79844},{\"end\":79862,\"start\":79855},{\"end\":79879,\"start\":79871},{\"end\":79896,\"start\":79888},{\"end\":79909,\"start\":79903},{\"end\":79931,\"start\":79920},{\"end\":80342,\"start\":80337},{\"end\":80356,\"start\":80353},{\"end\":80374,\"start\":80367},{\"end\":80388,\"start\":80384},{\"end\":80401,\"start\":80396},{\"end\":80413,\"start\":80410},{\"end\":80990,\"start\":80982},{\"end\":81009,\"start\":81002},{\"end\":81017,\"start\":81013},{\"end\":81030,\"start\":81027},{\"end\":81044,\"start\":81037},{\"end\":81055,\"start\":81051},{\"end\":81072,\"start\":81066},{\"end\":81084,\"start\":81074},{\"end\":81709,\"start\":81704},{\"end\":81724,\"start\":81717},{\"end\":82017,\"start\":82009},{\"end\":82503,\"start\":82498},{\"end\":82516,\"start\":82511},{\"end\":82533,\"start\":82526},{\"end\":82546,\"start\":82541},{\"end\":82562,\"start\":82553},{\"end\":83030,\"start\":83025},{\"end\":83043,\"start\":83038},{\"end\":83065,\"start\":83060},{\"end\":83080,\"start\":83073},{\"end\":83095,\"start\":83090},{\"end\":83109,\"start\":83103},{\"end\":83125,\"start\":83116},{\"end\":83676,\"start\":83667},{\"end\":83691,\"start\":83684},{\"end\":84334,\"start\":84328},{\"end\":84349,\"start\":84345},{\"end\":84954,\"start\":84944},{\"end\":84966,\"start\":84961},{\"end\":85601,\"start\":85594},{\"end\":85620,\"start\":85612},{\"end\":85638,\"start\":85631},{\"end\":85653,\"start\":85647},{\"end\":85671,\"start\":85663},{\"end\":86312,\"start\":86309},{\"end\":86335,\"start\":86322},{\"end\":86354,\"start\":86345},{\"end\":86372,\"start\":86362},{\"end\":86932,\"start\":86929},{\"end\":86948,\"start\":86938},{\"end\":86966,\"start\":86956},{\"end\":87539,\"start\":87532},{\"end\":87557,\"start\":87551},{\"end\":87800,\"start\":87794},{\"end\":87818,\"start\":87812},{\"end\":87835,\"start\":87827},{\"end\":87850,\"start\":87844},{\"end\":88240,\"start\":88236},{\"end\":88253,\"start\":88249},{\"end\":88263,\"start\":88261},{\"end\":88814,\"start\":88809},{\"end\":88841,\"start\":88829},{\"end\":88855,\"start\":88849},{\"end\":88871,\"start\":88864},{\"end\":89308,\"start\":89301},{\"end\":89323,\"start\":89318},{\"end\":89964,\"start\":89957},{\"end\":89979,\"start\":89973},{\"end\":89987,\"start\":89981},{\"end\":90263,\"start\":90252},{\"end\":90284,\"start\":90274},{\"end\":90303,\"start\":90294},{\"end\":90319,\"start\":90311},{\"end\":90958,\"start\":90953},{\"end\":90973,\"start\":90967},{\"end\":90985,\"start\":90981},{\"end\":91001,\"start\":90996},{\"end\":91381,\"start\":91374},{\"end\":91393,\"start\":91388},{\"end\":91713,\"start\":91707},{\"end\":92318,\"start\":92315},{\"end\":92328,\"start\":92325},{\"end\":92339,\"start\":92337},{\"end\":92353,\"start\":92348},{\"end\":92685,\"start\":92681},{\"end\":92700,\"start\":92692},{\"end\":93056,\"start\":93051},{\"end\":93065,\"start\":93062},{\"end\":93074,\"start\":93071},{\"end\":93093,\"start\":93089},{\"end\":93105,\"start\":93103},{\"end\":93777,\"start\":93774},{\"end\":93789,\"start\":93786},{\"end\":93804,\"start\":93800}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":65396,\"start\":65269},{\"attributes\":{\"id\":\"b1\"},\"end\":65515,\"start\":65398},{\"attributes\":{\"id\":\"b2\"},\"end\":65761,\"start\":65517},{\"attributes\":{\"doi\":\"10.1103/RevModPhys.74.47\",\"id\":\"b3\",\"matched_paper_id\":60545},\"end\":66062,\"start\":65763},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":8340340},\"end\":66656,\"start\":66064},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":1364237},\"end\":67349,\"start\":66658},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":1689835},\"end\":68112,\"start\":67351},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":14428620},\"end\":68534,\"start\":68114},{\"attributes\":{\"doi\":\"10.1145/2623330.2623660\",\"id\":\"b8\",\"matched_paper_id\":2586639},\"end\":69133,\"start\":68536},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":794929},\"end\":69626,\"start\":69135},{\"attributes\":{\"doi\":\"10.1007/978-3-319-49487-6_4\",\"id\":\"b10\",\"matched_paper_id\":3619914},\"end\":70212,\"start\":69628},{\"attributes\":{\"doi\":\"10.1145/1583991.1584053\",\"id\":\"b11\",\"matched_paper_id\":2762299},\"end\":71092,\"start\":70214},{\"attributes\":{\"doi\":\"10.1145/2741948.2741970\",\"id\":\"b12\",\"matched_paper_id\":59337241},\"end\":71732,\"start\":71094},{\"attributes\":{\"doi\":\"10.1145/3318464.3389745\",\"id\":\"b13\",\"matched_paper_id\":218982049},\"end\":72491,\"start\":71734},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":218475777},\"end\":72796,\"start\":72493},{\"attributes\":{\"doi\":\"10.1145/1060590.1060674\",\"id\":\"b15\",\"matched_paper_id\":14097859},\"end\":73496,\"start\":72798},{\"attributes\":{\"doi\":\"10.1109/ICDE.1998.655800\",\"id\":\"b16\",\"matched_paper_id\":1824799},\"end\":73951,\"start\":73498},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":13396177},\"end\":74522,\"start\":73953},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":2693696},\"end\":75125,\"start\":74524},{\"attributes\":{\"doi\":\"10.14778/3358701.3358706\",\"id\":\"b19\",\"matched_paper_id\":201058730},\"end\":75595,\"start\":75127},{\"attributes\":{\"doi\":\"10.1145/224170.224228\",\"id\":\"b20\",\"matched_paper_id\":3626585},\"end\":76185,\"start\":75597},{\"attributes\":{\"doi\":\"10.1145/2484425.2484429\",\"id\":\"b21\",\"matched_paper_id\":1447679},\"end\":76695,\"start\":76187},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":196197710},\"end\":77104,\"start\":76697},{\"attributes\":{\"doi\":\"10.1137/S1064827595287997\",\"id\":\"b23\",\"matched_paper_id\":3628209},\"end\":77465,\"start\":77106},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":122828516},\"end\":77744,\"start\":77467},{\"attributes\":{\"doi\":\"10.1145/1772690.1772751\",\"id\":\"b25\",\"matched_paper_id\":207178765},\"end\":78300,\"start\":77746},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":2227285},\"end\":78774,\"start\":78302},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":5559924},\"end\":79104,\"start\":78776},{\"attributes\":{\"id\":\"b28\"},\"end\":79319,\"start\":79106},{\"attributes\":{\"doi\":\"10.1109/TKDE.2014.2320716\",\"id\":\"b29\",\"matched_paper_id\":4560688},\"end\":79749,\"start\":79321},{\"attributes\":{\"doi\":\"10.14778/2212351.2212354\",\"id\":\"b30\",\"matched_paper_id\":11819780},\"end\":80265,\"start\":79751},{\"attributes\":{\"doi\":\"10.1145/3064176.3064191\",\"id\":\"b31\",\"matched_paper_id\":12681321},\"end\":80921,\"start\":80267},{\"attributes\":{\"doi\":\"10.1145/1807167.1807184\",\"id\":\"b32\"},\"end\":81653,\"start\":80923},{\"attributes\":{\"doi\":\"10.14778/2824032.2824046\",\"id\":\"b33\",\"matched_paper_id\":6815550},\"end\":81948,\"start\":81655},{\"attributes\":{\"doi\":\"10.1109/ICDE.2017.153\",\"id\":\"b34\",\"matched_paper_id\":2138943},\"end\":82419,\"start\":81950},{\"attributes\":{\"doi\":\"10.1109/BigData.2018.8621968\",\"id\":\"b35\",\"matched_paper_id\":53083809},\"end\":82922,\"start\":82421},{\"attributes\":{\"doi\":\"10.1109/ICDCS.2018.00072\",\"id\":\"b36\",\"matched_paper_id\":25372358},\"end\":83576,\"start\":82924},{\"attributes\":{\"doi\":\"10.1145/2487575.2487696\",\"id\":\"b37\",\"matched_paper_id\":14950070},\"end\":84251,\"start\":83578},{\"attributes\":{\"doi\":\"10.1145/3299869.3300076\",\"id\":\"b38\",\"matched_paper_id\":195259340},\"end\":84818,\"start\":84253},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":42052160},\"end\":85532,\"start\":84820},{\"attributes\":{\"doi\":\"10.1145/2806416.2806424\",\"id\":\"b40\",\"matched_paper_id\":79300},\"end\":86240,\"start\":85534},{\"attributes\":{\"doi\":\"10.1145/2815400.2815408\",\"id\":\"b41\",\"matched_paper_id\":1582381},\"end\":86851,\"start\":86242},{\"attributes\":{\"doi\":\"10.1145/2517349.2522740\",\"id\":\"b42\",\"matched_paper_id\":1151068},\"end\":87470,\"start\":86853},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":9894145},\"end\":87754,\"start\":87472},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":52054566},\"end\":88175,\"start\":87756},{\"attributes\":{\"doi\":\"10.1145/2463676.2467799\",\"id\":\"b45\",\"matched_paper_id\":1664117},\"end\":88752,\"start\":88177},{\"attributes\":{\"doi\":\"10.1109/IPDPS.2017.95\",\"id\":\"b46\",\"matched_paper_id\":1077172},\"end\":89231,\"start\":88754},{\"attributes\":{\"doi\":\"10.1145/2339530.2339722\",\"id\":\"b47\",\"matched_paper_id\":3142693},\"end\":89861,\"start\":89233},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":8481609},\"end\":90175,\"start\":89863},{\"attributes\":{\"doi\":\"10.1145/2556195.2556213\",\"id\":\"b49\",\"matched_paper_id\":9590483},\"end\":90859,\"start\":90177},{\"attributes\":{\"doi\":\"10.14778/3055540.3055543\",\"id\":\"b50\",\"matched_paper_id\":17308756},\"end\":91298,\"start\":90861},{\"attributes\":{\"doi\":\"10.1137/S1064827598337373\",\"id\":\"b51\",\"matched_paper_id\":10044658},\"end\":91663,\"start\":91300},{\"attributes\":{\"doi\":\"10.1145/2384716.2384777\",\"id\":\"b52\",\"matched_paper_id\":22401246},\"end\":92233,\"start\":91665},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":5957760},\"end\":92605,\"start\":92235},{\"attributes\":{\"doi\":\"10.1109/ICDM.2012.138\",\"id\":\"b54\",\"matched_paper_id\":9136948},\"end\":92990,\"start\":92607},{\"attributes\":{\"doi\":\"10.1145/3097983.3098033\",\"id\":\"b55\",\"matched_paper_id\":10689680},\"end\":93663,\"start\":92992},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":17191560},\"end\":94173,\"start\":93665}]", "bib_title": "[{\"end\":65804,\"start\":65763},{\"end\":66105,\"start\":66064},{\"end\":66698,\"start\":66658},{\"end\":67452,\"start\":67351},{\"end\":68162,\"start\":68114},{\"end\":68565,\"start\":68536},{\"end\":69203,\"start\":69135},{\"end\":69665,\"start\":69628},{\"end\":70317,\"start\":70214},{\"end\":71171,\"start\":71094},{\"end\":71771,\"start\":71734},{\"end\":72544,\"start\":72493},{\"end\":72868,\"start\":72798},{\"end\":73531,\"start\":73498},{\"end\":74021,\"start\":73953},{\"end\":74584,\"start\":74524},{\"end\":75181,\"start\":75127},{\"end\":75643,\"start\":75597},{\"end\":76229,\"start\":76187},{\"end\":76760,\"start\":76697},{\"end\":77181,\"start\":77106},{\"end\":77523,\"start\":77467},{\"end\":77795,\"start\":77746},{\"end\":78354,\"start\":78302},{\"end\":78809,\"start\":78776},{\"end\":79387,\"start\":79321},{\"end\":79834,\"start\":79751},{\"end\":80327,\"start\":80267},{\"end\":80971,\"start\":80923},{\"end\":81695,\"start\":81655},{\"end\":81999,\"start\":81950},{\"end\":82486,\"start\":82421},{\"end\":83013,\"start\":82924},{\"end\":83660,\"start\":83578},{\"end\":84321,\"start\":84253},{\"end\":84933,\"start\":84820},{\"end\":85586,\"start\":85534},{\"end\":86298,\"start\":86242},{\"end\":86918,\"start\":86853},{\"end\":87524,\"start\":87472},{\"end\":87782,\"start\":87756},{\"end\":88230,\"start\":88177},{\"end\":88798,\"start\":88754},{\"end\":89290,\"start\":89233},{\"end\":89953,\"start\":89863},{\"end\":90238,\"start\":90177},{\"end\":90946,\"start\":90861},{\"end\":91366,\"start\":91300},{\"end\":91701,\"start\":91665},{\"end\":92308,\"start\":92235},{\"end\":92672,\"start\":92607},{\"end\":93042,\"start\":92992},{\"end\":93764,\"start\":93665}]", "bib_author": "[{\"end\":65286,\"start\":65271},{\"end\":65819,\"start\":65806},{\"end\":65843,\"start\":65819},{\"end\":66121,\"start\":66107},{\"end\":66140,\"start\":66121},{\"end\":66156,\"start\":66140},{\"end\":66713,\"start\":66700},{\"end\":66728,\"start\":66713},{\"end\":66745,\"start\":66728},{\"end\":66763,\"start\":66745},{\"end\":67467,\"start\":67454},{\"end\":67479,\"start\":67467},{\"end\":67496,\"start\":67479},{\"end\":67514,\"start\":67496},{\"end\":68177,\"start\":68164},{\"end\":68195,\"start\":68177},{\"end\":68583,\"start\":68567},{\"end\":68597,\"start\":68583},{\"end\":68613,\"start\":68597},{\"end\":69223,\"start\":69205},{\"end\":69242,\"start\":69223},{\"end\":69680,\"start\":69667},{\"end\":69705,\"start\":69680},{\"end\":69718,\"start\":69705},{\"end\":69737,\"start\":69718},{\"end\":69745,\"start\":69737},{\"end\":70332,\"start\":70319},{\"end\":70350,\"start\":70332},{\"end\":70364,\"start\":70350},{\"end\":70380,\"start\":70364},{\"end\":70401,\"start\":70380},{\"end\":71184,\"start\":71173},{\"end\":71196,\"start\":71184},{\"end\":71209,\"start\":71196},{\"end\":71221,\"start\":71209},{\"end\":71785,\"start\":71773},{\"end\":71798,\"start\":71785},{\"end\":71810,\"start\":71798},{\"end\":71819,\"start\":71810},{\"end\":71833,\"start\":71819},{\"end\":71843,\"start\":71833},{\"end\":71854,\"start\":71843},{\"end\":71866,\"start\":71854},{\"end\":71880,\"start\":71866},{\"end\":72558,\"start\":72546},{\"end\":72570,\"start\":72558},{\"end\":72581,\"start\":72570},{\"end\":72591,\"start\":72581},{\"end\":72605,\"start\":72591},{\"end\":72883,\"start\":72870},{\"end\":72910,\"start\":72883},{\"end\":72923,\"start\":72910},{\"end\":73553,\"start\":73533},{\"end\":73573,\"start\":73553},{\"end\":73584,\"start\":73573},{\"end\":74042,\"start\":74023},{\"end\":74055,\"start\":74042},{\"end\":74066,\"start\":74055},{\"end\":74081,\"start\":74066},{\"end\":74098,\"start\":74081},{\"end\":74605,\"start\":74586},{\"end\":74620,\"start\":74605},{\"end\":74632,\"start\":74620},{\"end\":74650,\"start\":74632},{\"end\":74670,\"start\":74650},{\"end\":74682,\"start\":74670},{\"end\":75200,\"start\":75183},{\"end\":75219,\"start\":75200},{\"end\":75232,\"start\":75219},{\"end\":75243,\"start\":75232},{\"end\":75664,\"start\":75645},{\"end\":75679,\"start\":75664},{\"end\":76244,\"start\":76231},{\"end\":76260,\"start\":76244},{\"end\":76279,\"start\":76260},{\"end\":76775,\"start\":76762},{\"end\":76788,\"start\":76775},{\"end\":76796,\"start\":76788},{\"end\":76808,\"start\":76796},{\"end\":77199,\"start\":77183},{\"end\":77212,\"start\":77199},{\"end\":77544,\"start\":77525},{\"end\":77554,\"start\":77544},{\"end\":77811,\"start\":77797},{\"end\":77826,\"start\":77811},{\"end\":77839,\"start\":77826},{\"end\":77849,\"start\":77839},{\"end\":78369,\"start\":78356},{\"end\":78383,\"start\":78369},{\"end\":78400,\"start\":78383},{\"end\":78830,\"start\":78811},{\"end\":78846,\"start\":78830},{\"end\":79121,\"start\":79106},{\"end\":79135,\"start\":79121},{\"end\":79402,\"start\":79389},{\"end\":79417,\"start\":79402},{\"end\":79428,\"start\":79417},{\"end\":79849,\"start\":79836},{\"end\":79864,\"start\":79849},{\"end\":79881,\"start\":79864},{\"end\":79898,\"start\":79881},{\"end\":79911,\"start\":79898},{\"end\":79933,\"start\":79911},{\"end\":80344,\"start\":80329},{\"end\":80358,\"start\":80344},{\"end\":80376,\"start\":80358},{\"end\":80390,\"start\":80376},{\"end\":80403,\"start\":80390},{\"end\":80415,\"start\":80403},{\"end\":80992,\"start\":80973},{\"end\":81011,\"start\":80992},{\"end\":81019,\"start\":81011},{\"end\":81032,\"start\":81019},{\"end\":81046,\"start\":81032},{\"end\":81057,\"start\":81046},{\"end\":81074,\"start\":81057},{\"end\":81086,\"start\":81074},{\"end\":81711,\"start\":81697},{\"end\":81726,\"start\":81711},{\"end\":82019,\"start\":82001},{\"end\":82505,\"start\":82488},{\"end\":82518,\"start\":82505},{\"end\":82535,\"start\":82518},{\"end\":82548,\"start\":82535},{\"end\":82564,\"start\":82548},{\"end\":83032,\"start\":83015},{\"end\":83045,\"start\":83032},{\"end\":83067,\"start\":83045},{\"end\":83082,\"start\":83067},{\"end\":83097,\"start\":83082},{\"end\":83111,\"start\":83097},{\"end\":83127,\"start\":83111},{\"end\":83678,\"start\":83662},{\"end\":83693,\"start\":83678},{\"end\":84336,\"start\":84323},{\"end\":84351,\"start\":84336},{\"end\":84956,\"start\":84935},{\"end\":84968,\"start\":84956},{\"end\":85603,\"start\":85588},{\"end\":85622,\"start\":85603},{\"end\":85640,\"start\":85622},{\"end\":85655,\"start\":85640},{\"end\":85673,\"start\":85655},{\"end\":86314,\"start\":86300},{\"end\":86337,\"start\":86314},{\"end\":86356,\"start\":86337},{\"end\":86374,\"start\":86356},{\"end\":86934,\"start\":86920},{\"end\":86950,\"start\":86934},{\"end\":86968,\"start\":86950},{\"end\":87541,\"start\":87526},{\"end\":87559,\"start\":87541},{\"end\":87802,\"start\":87784},{\"end\":87820,\"start\":87802},{\"end\":87837,\"start\":87820},{\"end\":87852,\"start\":87837},{\"end\":88242,\"start\":88232},{\"end\":88255,\"start\":88242},{\"end\":88265,\"start\":88255},{\"end\":88816,\"start\":88800},{\"end\":88843,\"start\":88816},{\"end\":88857,\"start\":88843},{\"end\":88873,\"start\":88857},{\"end\":89310,\"start\":89292},{\"end\":89325,\"start\":89310},{\"end\":89966,\"start\":89955},{\"end\":89981,\"start\":89966},{\"end\":89989,\"start\":89981},{\"end\":90265,\"start\":90240},{\"end\":90286,\"start\":90265},{\"end\":90305,\"start\":90286},{\"end\":90321,\"start\":90305},{\"end\":90960,\"start\":90948},{\"end\":90975,\"start\":90960},{\"end\":90987,\"start\":90975},{\"end\":91003,\"start\":90987},{\"end\":91383,\"start\":91368},{\"end\":91395,\"start\":91383},{\"end\":91715,\"start\":91703},{\"end\":92320,\"start\":92310},{\"end\":92330,\"start\":92320},{\"end\":92341,\"start\":92330},{\"end\":92355,\"start\":92341},{\"end\":92687,\"start\":92674},{\"end\":92702,\"start\":92687},{\"end\":93058,\"start\":93044},{\"end\":93067,\"start\":93058},{\"end\":93076,\"start\":93067},{\"end\":93095,\"start\":93076},{\"end\":93107,\"start\":93095},{\"end\":93779,\"start\":93766},{\"end\":93791,\"start\":93779},{\"end\":93806,\"start\":93791}]", "bib_venue": "[{\"end\":66339,\"start\":66247},{\"end\":67062,\"start\":66921},{\"end\":67732,\"start\":67681},{\"end\":68331,\"start\":68260},{\"end\":68856,\"start\":68746},{\"end\":69329,\"start\":69291},{\"end\":69861,\"start\":69857},{\"end\":70640,\"start\":70532},{\"end\":71404,\"start\":71324},{\"end\":72095,\"start\":71999},{\"end\":72633,\"start\":72623},{\"end\":73126,\"start\":73036},{\"end\":73738,\"start\":73680},{\"end\":75295,\"start\":75285},{\"end\":75868,\"start\":75784},{\"end\":76411,\"start\":76394},{\"end\":78028,\"start\":77950},{\"end\":79985,\"start\":79975},{\"end\":80602,\"start\":80520},{\"end\":81301,\"start\":81205},{\"end\":81778,\"start\":81768},{\"end\":83936,\"start\":83826},{\"end\":84544,\"start\":84459},{\"end\":85187,\"start\":85073},{\"end\":85906,\"start\":85801},{\"end\":86553,\"start\":86475},{\"end\":87173,\"start\":87082},{\"end\":88480,\"start\":88384},{\"end\":89568,\"start\":89458},{\"end\":90532,\"start\":90438},{\"end\":91055,\"start\":91045},{\"end\":91978,\"start\":91858},{\"end\":93350,\"start\":93240},{\"end\":65406,\"start\":65398},{\"end\":65526,\"start\":65517},{\"end\":65881,\"start\":65867},{\"end\":66245,\"start\":66156},{\"end\":66919,\"start\":66763},{\"end\":67580,\"start\":67514},{\"end\":68258,\"start\":68195},{\"end\":68744,\"start\":68636},{\"end\":69272,\"start\":69242},{\"end\":69823,\"start\":69772},{\"end\":70530,\"start\":70424},{\"end\":71322,\"start\":71244},{\"end\":71997,\"start\":71903},{\"end\":72621,\"start\":72605},{\"end\":73034,\"start\":72946},{\"end\":73678,\"start\":73608},{\"end\":74184,\"start\":74098},{\"end\":74768,\"start\":74682},{\"end\":75283,\"start\":75267},{\"end\":75782,\"start\":75700},{\"end\":76392,\"start\":76302},{\"end\":76888,\"start\":76808},{\"end\":77256,\"start\":77237},{\"end\":77587,\"start\":77554},{\"end\":77948,\"start\":77872},{\"end\":78486,\"start\":78400},{\"end\":78923,\"start\":78846},{\"end\":79191,\"start\":79135},{\"end\":79504,\"start\":79453},{\"end\":79973,\"start\":79957},{\"end\":80518,\"start\":80438},{\"end\":81203,\"start\":81109},{\"end\":81766,\"start\":81750},{\"end\":82106,\"start\":82040},{\"end\":82648,\"start\":82592},{\"end\":83226,\"start\":83151},{\"end\":83824,\"start\":83716},{\"end\":84457,\"start\":84374},{\"end\":85071,\"start\":84968},{\"end\":85799,\"start\":85696},{\"end\":86473,\"start\":86397},{\"end\":87080,\"start\":86991},{\"end\":87591,\"start\":87559},{\"end\":87953,\"start\":87852},{\"end\":88382,\"start\":88288},{\"end\":88971,\"start\":88894},{\"end\":89456,\"start\":89348},{\"end\":89999,\"start\":89989},{\"end\":90436,\"start\":90344},{\"end\":91043,\"start\":91027},{\"end\":91456,\"start\":91420},{\"end\":91856,\"start\":91738},{\"end\":92404,\"start\":92355},{\"end\":92777,\"start\":92723},{\"end\":93238,\"start\":93130},{\"end\":93869,\"start\":93806}]"}}}, "year": 2023, "month": 12, "day": 17}