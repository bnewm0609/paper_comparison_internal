{"id": 257505063, "updated": "2023-12-14 03:43:56.541", "metadata": {"title": "Query2doc: Query Expansion with Large Language Models", "authors": "[{\"first\":\"Liang\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Nan\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Furu\",\"last\":\"Wei\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "This paper introduces a simple yet effective query expansion approach, denoted as query2doc, to improve both sparse and dense retrieval systems. The proposed method first generates pseudo-documents by few-shot prompting large language models (LLMs), and then expands the query with generated pseudo-documents. LLMs are trained on web-scale text corpora and are adept at knowledge memorization. The pseudo-documents from LLMs often contain highly relevant information that can aid in query disambiguation and guide the retrievers. Experimental results demonstrate that query2doc boosts the performance of BM25 by 3% to 15% on ad-hoc IR datasets, such as MS-MARCO and TREC DL, without any model fine-tuning. Furthermore, our method also benefits state-of-the-art dense retrievers in terms of both in-domain and out-of-domain results.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/WangYW23", "doi": "10.18653/v1/2023.emnlp-main.585"}}, "content": {"source": {"pdf_hash": "ccc772d88c231275f24c4fac9b28bbe0942e1107", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2303.07678v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "3047345119fa4859dbde6f70f7c41304a9432888", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/ccc772d88c231275f24c4fac9b28bbe0942e1107.txt", "contents": "\nQuery2doc: Query Expansion with Large Language Models\n\n\nLiang Wang wangliang@microsoft.com \nMicrosoft Research\n\n\nNan Yang \nMicrosoft Research\n\n\nFuru Wei fuwei@microsoft.com \nMicrosoft Research\n\n\nQuery2doc: Query Expansion with Large Language Models\n05D18BAEBB2E584B3CCDB1FC188B0CBA\nThis paper introduces a simple yet effective query expansion approach, denoted as query2doc, to improve both sparse and dense retrieval systems.The proposed method first generates pseudo-documents by few-shot prompting large language models (LLMs), and then expands the query with generated pseudodocuments.LLMs are trained on web-scale text corpora and are adept at knowledge memorization.The pseudo-documents from LLMs often contain highly relevant information that can aid in query disambiguation and guide the retrievers.Experimental results demonstrate that query2doc boosts the performance of BM25 by 3% to 15% on ad-hoc IR datasets, such as MS-MARCO and TREC DL, without any model fine-tuning.Furthermore, our method also benefits state-of-the-art dense retrievers in terms of both in-domain and out-of-domain results.\n\nIntroduction\n\nInformation retrieval (IR) aims to locate relevant documents from a large corpus given a user issued query.It is a core component in modern search engines and researchers have invested for decades in this field.There are two mainstream paradigms for IR: lexical-based sparse retrieval, such as BM25, and embedding-based dense retrieval (Xiong et al., 2021;Qu et al., 2021).Although dense retrievers perform better when large amounts of labeled data are available (Karpukhin et al., 2020), BM25 remains competitive on out-ofdomain datasets (Thakur et al., 2021).\n\nQuery expansion (Rocchio, 1971;Lavrenko and Croft, 2001) is a long-standing technique that rewrites the query based on pseudo-relevance feedback or external knowledge sources such as WordNet.For sparse retrieval, it can help bridge the lexical gap between the query and the documents.However, query expansion methods like RM3 (Lavrenko and Croft, 2001;Lv and Zhai, 2009) have only shown limited success on popular datasets (Campos et al., 2016), and most state-ofthe-art dense retrievers do not adopt this technique.In the meantime, document expansion methods like doc2query (Nogueira et al., 2019) have proven to be effective for sparse retrieval.\n\nIn this paper, we demonstrate the effectiveness of LLMs (Brown et al., 2020) as query expansion models by generating pseudo-documents conditioned on few-shot prompts.Given that search queries are often short, ambiguous, or lack necessary background information, LLMs can provide relevant information to guide retrieval systems, as they memorize an enormous amount of knowledge and language patterns by pre-training on trillions of tokens.\n\nOur proposed method, called query2doc, generates pseudo-documents by few-shot prompting LLMs and concatenates them with the original query to form a new query.This method is simple to implement and does not require any changes in training pipelines or model architectures, making it orthogonal to the progress in the field of LLMs and information retrieval.Future methods can easily build upon our query expansion framework.\n\nFor in-domain evaluation, we adopt the MS-MARCO passage ranking (Campos et al., 2016), TREC DL 2019 and 2020 datasets.Pseudodocuments are generated by prompting an improved version of GPT-3 text-davinci-003 from OpenAI (Brown et al., 2020).Results show that query2doc substantially improves the off-theshelf BM25 algorithm without fine-tuning any model, particularly for hard queries from the TREC DL track.Strong dense retrievers, including DPR (Karpukhin et al., 2020), SimLM (Wang et al., 2023), and E5 (Wang et al., 2022) also benefit from query2doc, although the gains tend to be diminishing when distilling from a strong cross-encoder based re-ranker.Experiments in zero-shot OOD settings demonstrate that our method outperforms strong baselines on most arXiv:2303.07678v2[cs.IR] 11 Oct 2023 datasets.Further analysis also reveals the importance of model scales: query2doc works best when combined with the most capable LLMs while small language models only provide marginal improvements over baselines.To aid reproduction, we release all the generations from text-davinci-003 at https://huggingface.co/datasets/ intfloat/query2doc_msmarco.\n\n\nMethod\n\nWrite a passage that answers the given query:\n\nQuery: what state is this zip code 85282 Passage: Welcome to TEMPE, AZ 85282.85282 is a rural zip code in Tempe, Arizona.The population is primarily white\u2026 \u2026 Query: when was pokemon green released Passage:\n\n\nLLM Prompts\n\nPokemon Green was released in Japan on February 27th, 1996.It was the first in the Pokemon series of games and served as the basis for Pokemon Red and Blue, which were released in the US in 1998.The original Pokemon Green remains a beloved classic among fans of the series.Given a query q, we employ few-shot prompting to generate a pseudo-document d \u2032 as depicted in Figure 1.The prompt comprises a brief instruction \"Write a passage that answers the given query:\" and k labeled pairs randomly sampled from a training set.We use k = 4 throughout this paper.Subsequently, we rewrite q to a new query q + by concatenating with the pseudo-document d \u2032 .There are slight differences in the concatenation operation for sparse and dense retrievers, which we elaborate on in the following section.Sparse Retrieval Since the query q is typically much shorter than pseudo-documents, to balance the relative weights of the query and the pseudodocument, we boost the query term weights by repeating the query n times before concatenating with the pseudo-document d \u2032 :\n\n\nLLM Output\nq + = concat({q} \u00d7 n, d \u2032 ) (1)\nHere, \"concat\" denotes the string concatenation function.q + is used as the new query for BM25 retrieval.We find that n = 5 is a generally good value and do not tune it on a dataset basis.Dense Retrieval The new query q + is a simple concatenation of the original query q and the pseudo-document d \u2032 separated by [SEP]:\nq + = concat(q, [SEP], d \u2032 ) (2)\nFor training dense retrievers, several factors can influence the final performance, such as hard negative mining (Xiong et al., 2021), intermediate pretraining (Gao and Callan, 2021), and knowledge distillation from a cross-encoder based re-ranker (Qu et al., 2021).In this paper, we investigate two settings to gain a more comprehensive understanding of our method.The first setting is training DPR (Karpukhin et al., 2020) models initialized from BERT base with BM25 hard negatives only.The optimization objective is a standard contrastive loss:\nL cont = \u2212 log e hq\u2022h d e hq\u2022h d + d i \u2208N e hq\u2022h d i(3)\nwhere h q and h d represent the embeddings for the query and document, respectively.N denotes the set of hard negatives.\n\nThe second setting is to build upon state-of-theart dense retrievers and use KL divergence to distill from a cross-encoder teacher model.\nmin D KL (p ce , p stu ) + \u03b1L cont (4)\np ce and p stu are the probabilities from the crossencoder and our student model, respectively.\u03b1 is a coefficient to balance the distillation loss and contrastive loss.\n\n\nComparison with Pseudo-relevance Feedback\n\nOur proposed method is related to the classic method of pseudo-relevance feedback (PRF) (Lavrenko and Croft, 2001;Lv and Zhai, 2009).In conventional PRF, the feedback signals for query expansion come from the top-k documents obtained in the initial retrieval step, while our method prompts LLMs to generate pseudo-documents.Our method does not rely on the quality of the initial retrieval results, which are often noisy or irrelevant.Rather, it exploits cutting-edge LLMs to generate documents that are more likely to contain relevant terms.(Craswell et al., 2020a) and 2020 (Craswell et al., 2020b) datasets.\n\nFor zero-shot out-of-domain evaluation, we select five low-resource datasets from the BEIR benchmark (Thakur et al., 2021).The evaluation metrics include MRR@10, R@k (k \u2208 {50, 1k}), and nDCG@10.\n\nHyperparameters For sparse retrieval including BM25 and RM3, we adopt the default implementation from Pyserini (Lin et al., 2021).When training dense retrievers, we use mostly the same hyperparameters as SimLM (Wang et al., 2023), with the exception of increasing the maximum query length to 144 to include pseudo-documents.When prompting LLMs, we include 4 in-context examples and use the default temperature of 1 to sample at most 128 tokens.For further details, please refer to Appendix A.\n\n\nMain Results\n\nIn Table 1, we list the results on the MS-MARCO passage ranking and TREC DL datasets.For sparse retrieval, \"BM25 + query2doc\" beats the BM25 baseline with over 15% improvements on TREC DL 2019 and 2020 datasets.Our manual inspection reveals that most queries from the TREC DL track are long-tailed entity-centric queries, which benefit more from the exact lexical match.The traditional query expansion method RM3 only marginally improves the R@1k metric.Although the document expansion method docT5query achieves better numbers on the MS-MARCO dev set, it requires training a T5-based query generator with all the available labeled data, while \"BM25 + query2doc\" does not require any model fine-tuning.\n\nFor dense retrieval, the model variants that combine with query2doc also outperform the corresponding baselines on all metrics.However, the gain brought by query2doc tends to diminish when using intermediate pre-training or knowledge distillation from cross-encoder re-rankers, as shown by the \"SimLM + query2doc\" and \"E5 + query2doc\" results.\n\nFor zero-shot out-of-domain retrieval, the results are mixed as shown in Table 2. Entity-centric datasets like DBpedia see the largest improvements.On the NFCorpus and Scifact datasets, we observe a minor decrease in ranking quality.This is likely due to the distribution mismatch between training and evaluation.\n\n\nAnalysis\n\nScaling up LLMs is Critical For our proposed method, a question that naturally arises is: how does the model scale affect the quality of query expansion?Table 3 shows that the performance steadily improves as we go from the 1.3B model DBpedia NFCorpus Scifact Trec-Covid Touche2020 BM25 31.3 32.5 66.5 65.6 36.7 + query2doc 37.0 +5.7 34.9 +2.4 68.6 +2.1 72.2 +6.6 39.8 +3.1 SimLM (Wang et al., 2023) 34.9 32.7 62.4 55.0 18.9 + query2doc 38.3 +3.4  32.1 -0.6 59.5 -2.9 59.9 +4.9 25.6 +6.7 E5 base + KD (Wang et al., 2022)  to 175B models.Empirically, the texts generated by smaller language models tend to be shorter and contain more factual errors.Also, the \"davinci-003\" model outperforms its earlier version \"davinci-001\" by using better training data and improved instruction tuning.The recently released GPT-4 (OpenAI, 2023) achieves the best results.How to Use Pseudo-documents In this paper, we concatenate the original query and pseudodocuments as the new query.Alternatively, one can solely use the pseudo-documents, as done in the approach of HyDE (Gao et al., 2022).The results presented in Table 4 demonstrate that the original query and pseudo-documents are complementary, and their combination leads to substantially better performance in sparse retrieval.\n\n\nCase Analysis\n\nIn Table 5, we show two queries along with their respective pseudo-documents and groundtruth.The pseudo-documents, which are generated by LLMs, offer detailed and mostly accurate information, thereby reducing the lexical mismatch between the query and documents.In some cases, the pseudo-documents are sufficient to meet the user's information needs, rendering the retrieval step unnecessary.However, it is worth noting that the LLM generations may contain factual errors.For instance, in the second query, the theme song \"It's a Jungle Out There\" was used as of season two in 2003, not 2002 1 .Although such errors may appear subtle and difficult to verify, they pose a significant challenge to building trustworthy systems using LLMs.\n\nquery who killed nicholas ii of russia LLM generation Nicholas II of Russia, the last Tsar of Russia, was executed by Bolshevik revolutionaries on July 17th, 1918, along with his wife Alexandra and their five children.The execution was ordered by Vladimir Lenin, the leader of the Bolshevik Party.The actual execution was carried out by a firing squad of Bolshevik troops, and the bodies were later buried in a mass grave. . .Groundtruth\n\n\nRelated Work\n\nQuery Expansion and Document Expansion are two classical techniques to improve retrieval quality, particularly for sparse retrieval systems.Both techniques aim to minimize the lexical gap between the query and the documents.Query expansion typically involves rewriting the query based on relevance feedback (Lavrenko and Croft, 2001;Rocchio, 1971) or lexical resources such as WordNet (Miller, 1992).In cases where labels are not available, the top-k retrieved documents can serve as pseudo-relevance feedback signals (Lv and Zhai, 2009).Liu et al. fine-tunes an encoder-decoder model to generate contextual clues.In contrast, document expansion enriches the document representation by appending additional relevant terms.Doc2query (Nogueira et al., 2019) trains a seq2seq model to predict pseudo-queries based on documents and then adds generated pseudo-queries to the document index.Learned sparse retrieval models such as SPLADE (Formal et al., 2021) and uniCOIL (Lin and Ma, 2021) also learn document term weighting in an end-to-end fashion.However, most state-of-the-art dense retrievers (Ren et al., 2021;Wang et al., 2023) do not adopt any expansion techniques.Our paper demonstrates that strong dense retrievers also benefit from query expansion using LLMs.Large Language Models (LLMs) such as GPT-3 (Brown et al., 2020), PaLM (Chowdhery et al., 2022), andLLaMA (Touvron et al., 2023) are trained on trillions of tokens with billions of param-eters, exhibiting unparalleled generalization ability across various tasks.LLMs can follow instructions in a zero-shot manner or conduct in-context learning through few-shot prompting.Labeling a few high-quality examples only requires minimal human effort.In this paper, we employ few-shot prompting to generate pseudo-documents from a given query.A closely related recent work HyDE (Gao et al., 2022) instead focuses on the zeroshot setting and uses embeddings of the pseudodocuments for similarity search.HyDE implicitly assumes that the groundtruth document and pseudodocuments express the same semantics in different words, which may not hold for some queries.In the field of question answering, RECITE (Sun et al., 2022) and GENREAD (Yu et al., 2022) demonstrate that LLMs are powerful context generators and can encode abundant factual knowledge.However, as our analysis shows, LLMs can sometimes generate false claims, hindering their practical application in critical areas.\n\n\nConclusion\n\nThis paper presents a simple method query2doc to leverage LLMs for query expansion.It first prompts LLMs with few-shot examples to generate pseudo-documents and then integrates with existing sparse or dense retrievers by augmenting queries with generated pseudo-documents.The underlying motivation is to distill the LLMs through prompting.Despite its simplicity, empirical evaluations demonstrate consistent improvements across various retrieval models and datasets.\n\n\nLimitations\n\nLLM call Index search BM25 -16ms + query2doc >2000ms 177ms\n\nTable 6: Latency analysis for retrieval systems with our proposed query2doc.We retrieve the top 100 results for MS-MARCO dev queries with a single thread and then average over all the queries.The latency for LLM API calls depends on server load and is difficult to precisely measure.\n\nAn apparent limitation is the efficiency of retrieval.Our method requires running inference with LLMs which can be considerably slower due to the token-by-token autoregressive decoding.Moreover, with query2doc, searching the inverted index also becomes slower as the number of query terms increases after expansion.This is supported by the benchmarking results in Table 6.Real-world deployment of our method should take these factors into consideration.\n\nFigure 1 :\n1\nFigure 1: Illustration of query2doc few-shot prompting.We omit some in-context examples for space reasons.\n\n\nTable 1 :\n1\nMain results on the MS-MARCO passage ranking and TREC datasets.The \"Fine-tuning\" column indicates whether the method requires fine-tuning model on labeled data or not.* : our reproduction.\nMethodFine-tuningMS MARCO dev MRR@10 R@50 R@1kTREC DL 19 TREC DL 20 nDCG@10 nDCG@10Sparse retrievalBM25\u271718.458.585.751.2  *47.7  *+ query2doc\u271721.4 +3.065.3 +6.8 91.8 +6.1 66.2 +15.062.9 +15.2BM25 + RM3\u271715.856.786.452.247.4docT5query (Nogueira and Lin)\u271327.775.694.764.2-Dense retrieval w/o distillationANCE (Xiong et al., 2021)\u271333.0-95.964.564.6HyDE (Gao et al., 2022)\u2717---61.357.9DPR bert-base (our impl.)\u271333.780.595.964.764.1+ query2doc\u271335.1 +1.482.6 +2.1 97.2 +1.3 68.7 +4.067.1 +3.0Dense retrieval w/ distillationRocketQAv2 (Ren et al., 2021)\u271338.886.298.1--AR2 (Zhang et al., 2022)\u271339.587.898.6--SimLM (Wang et al., 2023)\u271341.187.898.771.469.7+ query2doc\u271341.5 +0.488.0 +0.2 98.8 +0.1 72.9 +1.571.6 +1.9E5 base + KD (Wang et al., 2022)\u271340.787.698.674.370.7+ query2doc\u271341.5 +0.888.1 +0.5 98.7 +0.1 74.9 +0.672.5 +1.83 Experiments3.1 Setup\n(Campos et al., 2016)or in-domain evaluation, we utilize the MS-MARCO passage ranking(Campos et al., 2016), TREC DL 2019\n\n\nTable 3 :\n3\nQuery expansion with different model sizes.Even though GPT-4 performs best, we are unable to apply it in the main experiments due to quota limits.\n40.735.070.474.130.9+ query2doc42.4 +1.735.2 +0.267.5 -2.9 75.1 +1.031.7 +0.8Table 2: Zero-shot out-of-domain results on 5 low-resource datasets from the BEIR benchmark (Thakur et al.,2021). The reported numbers are nDCG@10. For a fair comparison, the in-context examples for prompting LLMscome from the MS-MARCO training set.# params TREC 19 TREC 20BM25-51.247.7w/ babbage1.3B52.050.2w/ curie6.7B55.150.1w/ davinci-001175B63.558.2w/ davinci-003175B66.262.9w/ gpt-4-69.264.5\n\nTable 4 :\n4\nUsing the concatenation of the original query and the generated pseudo-documents perform substantially better.\nMRR on dev set26 28 30 32 34 3627.3 28.531.4 32.132.8 34.133.7 35.120 22 241 10 21.4 22.730 % labeled data for fine-tuning 50 DPR w/o query2doc 100 DPR w/ query2docFigure 2: MRR on MS-MARCO dev set w.r.t the per-centage of labeled data used for fine-tuning.Performance Gains are Consistent across DataScales Figure 2 presents a comparison betweentwo variants of DPR models, which differ in theamount of labeled data used. The results showthat the \"DPR + query2doc\" variant consistentlyoutperforms the DPR baseline by approximately\n\n\n\n. Nicholas II was the last emperor, or tsar, of Russia, serving from 1894 to 1917.Nicholas, his wife, and their five children were killed by the Bolsheviks, members of a revolutionary group (led by Lenin) who seized control of the government in Russia during the October Revolution (see Russian Revolution) of 1917.query who sings monk theme song LLM generation The theme song for the television show Monk is entitled \"It's a Jungle Out There\" and is sung by American singer-songwriter Randy Newman.The song was written specifically for the show, and it has been used as the theme song since the series premiered in 2002.It has been praised by critics and fans alike and is often regarded as one of the best theme songs in television history.Groundtruth exists and is an alternate of.The Monk theme song is It's a Jungle Out There by Randy Newman.The Monk theme song is It's a Jungle Out There by Randy Newman.\n\n\nTable 5 :\n5\nExamples from the TREC DL 2020 dataset.Bold texts are the overlapping words between groundtruth and pseudo-documents generated from LLMs.The italicized red sentence demonstrates a factual error in language model generations.\n\nRefer to https://en.wikipedia.org/wiki/It's_a_Jungle_Out_There_(song)   \nFor dense retrieval experiments in Table1, we list the hyperparameters in Table7.When training dense retrievers with distillation from cross-encoder, we use the same teacher score released byWang et al..The SimLM and E5 checkpoints for initialization are publicly available at https://huggingface. co/intfloat/simlm-base-msmarco and https://huggingface.co/intfloat/ e5-base-unsupervised.To compute the text embeddings, we utilize the [CLS] vector for SimLM and mean pooling for E5.This makes sure that the pooling mechanisms remain consistent between intermediate pre-training and fine-tuning.The training and evaluation of a dense retriever take less than 10 hours to finish.When prompting LLMs, we include 4 in-context examples from the MS-MARCO training set.To increase prompt diversity, we randomly select 4 examples for each API call.A complete prompt is shown in Table11.On the budget side, we make about 550k API calls to OpenAI's service, which costs nearly 5k dollars.Most API calls are used to generate pseudo-documents for the training queries.For GPT-4 prompting, we find that it has a tendency to ask for clarification instead of directly generating the pseudo-documents.To mitigate this issue, we set the system message to \"You are asked to write a passage that answers the given query.Do not ask the user for further clarification.\".Regarding out-of-domain evaluations on DBpedia(Hasibi et al., 2017), NFCorpus(Boteva et al., 2016), Scifact(Wadden et al., 2020), Trec-Covid(Voorhees et al., 2021), and Touche2020 (Bondarenko et al., 2022)Instead of generating pseudo-documents in one round, recent work(Press et al., 2022)proposes to iteratively prompt the LLM to improve the generation quality.We explore this intuition by asking GPT-4 to rewrite its own generated pseudodocuments with the following prompt template: You are asked to rewrite the passage that potentially answers the given query.You should only correct the factual errors in the passage, do not ask for clarification or make unnecessary changes.Query: {{query}} # Begin of passage {{passage}} # End of passage Empirically, we find that GPT-4 makes very few changes to the generated pseudo-documents, which suggests that the pseudo-documents are already of high quality or GPT-4 is not capable of correcting its own errors.The results are shown in The key difference between HRA and HSA is that HRA is an employer funded health benefit plan that reimburses for medical expenses including personal health insurance policy premiums of employees whereas HSA is also a tax-advantaged health benefit plan exclusively available to taxpayers in the United States who are enrolled in a High-Deductible Health Plan (HDHP).Table9: More examples of LLM generations.The format is the same as in Table5.DL 2019 DL 2020 Average 64.8 60.9 Std dev.\u00b11.14 \u00b11.63C Results Across Multiple RunsIn our method, there are two sources of randomness: the selection of few-shot examples and the auto-regressive top-p sampling of LLMs.To quantify the variance of our method, we report the average and standard deviation of sparse retrieval results across 3 random runs in Query: what does a thousand pardons means Passage: Oh, that's all right, that's all right, give us a rest; never mind about the direction, hang the direction -I beg pardon, I beg a thousand pardons, I am not well to-day; pay no attention when I soliloquize, it is an old habit, an old, bad habit, and hard to get rid of when one's digestion is all disordered with eating food that was raised forever and ever before he was born; good land!a man can't keep his functions regular on spring chickens thirteen hundred years old.Table11: The full prompt used for the example in Figure1.\nOverview of touch\u00e9 2022: argument retrieval. Alexander Bondarenko, Maik Fr\u00f6be, Johannes Kiesel, Shahbaz Syed, Timon Gurcke, Meriem Beloucif, Alexander Panchenko, Chris Biemann, Benno Stein, Henning Wachsmuth, International Conference of the Cross-Language Evaluation Forum for European Languages. Springer2022\n\nA full-text learning to rank dataset for medical information retrieval. Vera Boteva, Demian Gholipour, Artem Sokolov, Stefan Riezler, European Conference on Information Retrieval. Springer2016\n\nAlec Radford, Ilya Sutskever, and Dario Amodei. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish; NeurIPS2020. 2020. 2020. December 6-12, 2020Language models are few-shot learners\n\nMs marco: A human generated machine reading comprehension dataset. Daniel Fernando Campos, Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, Bhaskar Mitra, abs/1611.09268ArXiv preprint. 2016\n\n. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam M Shazeer, Emily Vinodkumar Prabhakaran, Nan Reif, Benton C Du, Reiner Hutchinson, James Pope, Jacob Bradbury, Michael Austin, Guy Isard, Pengcheng Gur-Ari, Toju Yin, Anselm Duke, Sanjay Levskaya, Sunipa Ghemawat, Henryk Dev, Xavier Michalewski, Vedant Garc\u00eda, Kevin Misra, Liam Robinson, Denny Fedus, Daphne Zhou, David Ippolito, Hyeontaek Luan, Barret Lim, Alexander Zoph, Ryan Spiridonov, Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark D\u00edaz, Orhan Firat, Michele Catasta, Jason Wei, Kathleen S. Meier-Hellstern, Douglas EckJeff Dean, Slav Petrovand Noah Fiedel. 2022. Palm: Scaling language modeling with pathways. ArXiv preprint, abs/2204.02311\n\nOverview of the trec 2019 deep learning track. Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, Ellen M Voorhees, abs/2003.078202020aArXiv preprint\n\nOverview of the trec 2020 deep learning track. Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Fernando Campos, Ellen M Voorhees, abs/2003.07820ArXiv preprint. 2020b\n\nSplade: Sparse lexical and expansion model for first stage ranking. Thibault Formal, Benjamin Piwowarski, St\u00e9phane Clinchant, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval2021\n\nCondenser: a pretraining architecture for dense retrieval. Luyu Gao, Jamie Callan, 10.18653/v1/2021.emnlp-main.75Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicAssociation for Computational Linguistics2021Online and Punta Cana\n\nPrecise zero-shot dense retrieval without relevance labels. Luyu Gao, Xueguang Ma, Jimmy Lin, Jamie Callan, abs/2212.10496ArXiv preprint. 2022\n\nDbpedia-entity v2: A test collection for entity search. Faegheh Hasibi, Fedor Nikolaev, Chenyan Xiong, Krisztian Balog, Erik Svein, Alexander Bratsberg, Jamie Kotov, Callan, 10.1145/3077136.3080751Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 40th International ACM SIGIR Conference on Research and Development in Information RetrievalShinjuku, Tokyo, JapanACM2017. August 7-11, 2017\n\nDense passage retrieval for opendomain question answering. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, 10.18653/v1/2020.emnlp-main.550Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational Linguistics2020\n\nRelevancebased language models. Victor Lavrenko, W Bruce Croft, ACM SIGIR Forum. 512001\n\nA few brief notes on deepimpact, coil, and a conceptual framework for information retrieval techniques. Jimmy J Lin, Xueguang Ma, abs/2106.148072021ArXiv preprint\n\nPyserini: A python toolkit for reproducible information retrieval research with sparse and dense representations. Jimmy J Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak Pradeep, Rodrigo Nogueira, David R Cheriton, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval2021\n\nQuery expansion using contextual clue sampling with language models. Linqing Liu, Minghan Li, Jimmy Lin, Sebastian Riedel, Pontus Stenetorp, abs/2210.070932022ArXiv preprint\n\nA comparative study of methods for estimating query language models with pseudo feedback. Yuanhua Lv, Chengxiang Zhai, Proceedings of the 18th ACM conference on Information and knowledge management. the 18th ACM conference on Information and knowledge management2009\n\nWordNet: A lexical database for English. A George, Miller, Speech and Natural Language: Proceedings of a Workshop. Harriman, New York1992. February 23-26, 1992\n\nFrom doc2query to doctttttquery. Rodrigo Nogueira, Jimmy Lin, \n\nDocument expansion by query prediction. Rodrigo Nogueira, Wei Yang, Jimmy J Lin, Kyunghyun Cho, abs/1904.083752019ArXiv preprint\n\nArXiv, abs/2303.08774Gpt-4 technical report. 2023OpenAI\n\nOfir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, Mike Lewis, arXiv:2210.03350Measuring and narrowing the compositionality gap in language models. 2022arXiv preprint\n\nRocketQA: An optimized training approach to dense passage retrieval for opendomain question answering. Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, 10.18653/v1/2021.naacl-main.466Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesAssociation for Computational Linguistics2021\n\nRocketQAv2: A joint training method for dense passage retrieval and passage re-ranking. Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Ji-Rong Wen, 10.18653/v1/2021.emnlp-main.224Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational Linguistics2021Online and Punta Cana\n\nRelevance feedback in information retrieval. J J Rocchio, 1971\n\nRecitation-augmented language models. Zhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, Denny Zhou, abs/2210.012962022ArXiv preprint\n\nBeir: A heterogeneous benchmark for zero-shot evaluation of information retrieval models. Nandan Thakur, Nils Reimers, Andreas R\u00fcckl\u00e9, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2021Abhishek Srivastava, and Iryna Gurevych\n\nEdouard Grave, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models. Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timoth\u00e9e Lachaux, Baptiste Lacroix, Naman Rozi\u00e8re, Eric Goyal, Faisal Hambro, Azhar, Armand Aur'elien Rodriguez, Joulin, ArXiv preprint, abs/2302.13971\n\nTrec-covid: constructing a pandemic information retrieval test collection. Ellen Voorhees, Tasmeer Alam, Steven Bedrick, Dina Demner-Fushman, William R Hersh, Kyle Lo, Kirk Roberts, Ian Soboroff, Lucy Lu, Wang , ACM SIGIR Forum. New York, NY, USAACM202154\n\nFact or fiction: Verifying scientific claims. David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu Wang, Madeleine Van Zuylen, Arman Cohan, Hannaneh Hajishirzi, 10.18653/v1/2020.emnlp-main.609Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational Linguistics2020\n\nText embeddings by weaklysupervised contrastive pre-training. Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, Furu Wei, abs/2212.03533ArXiv preprint. 2022\n\nSimLM: Pre-training with representation bottleneck for dense passage retrieval. Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, Furu Wei, 10.18653/v1/2023.acl-long.125Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20231\n\nApproximate nearest neighbor negative contrastive learning for dense text retrieval. Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N Bennett, Junaid Ahmed, Arnold Overwijk, 9th International Conference on Learning Representations, ICLR 2021, Virtual Event. Austria2021. May 3-7, 2021OpenReview.net\n\nGenerate rather than retrieve: Large language models are strong context generators. W Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, Michael Zeng, Meng Jiang, 2022ArXiv preprint, abs/2209.10063\n\nAdversarial retriever-ranker for dense text retrieval. Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng Lv, Nan Duan, Weizhu Chen, The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event. 2022. April 25-29, 2022OpenReview.net\n", "annotations": {"author": "[{\"end\":113,\"start\":57},{\"end\":144,\"start\":114},{\"end\":195,\"start\":145}]", "publisher": null, "author_last_name": "[{\"end\":67,\"start\":63},{\"end\":122,\"start\":118},{\"end\":153,\"start\":150}]", "author_first_name": "[{\"end\":62,\"start\":57},{\"end\":117,\"start\":114},{\"end\":149,\"start\":145}]", "author_affiliation": "[{\"end\":112,\"start\":93},{\"end\":143,\"start\":124},{\"end\":194,\"start\":175}]", "title": "[{\"end\":54,\"start\":1},{\"end\":249,\"start\":196}]", "venue": null, "abstract": "[{\"end\":1108,\"start\":283}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b32\"},\"end\":1480,\"start\":1460},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1496,\"start\":1480},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":1611,\"start\":1587},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":1684,\"start\":1663},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":1718,\"start\":1703},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":1742,\"start\":1718},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2039,\"start\":2013},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2057,\"start\":2039},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2131,\"start\":2110},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2285,\"start\":2262},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2413,\"start\":2393},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3288,\"start\":3267},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3442,\"start\":3422},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3673,\"start\":3649},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":3700,\"start\":3681},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3728,\"start\":3709},{\"end\":6050,\"start\":6045},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":6218,\"start\":6198},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6267,\"start\":6245},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6350,\"start\":6333},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6509,\"start\":6485},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7316,\"start\":7290},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7334,\"start\":7316},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7767,\"start\":7743},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7801,\"start\":7777},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7935,\"start\":7914},{\"end\":8138,\"start\":8120},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8238,\"start\":8219},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10292,\"start\":10273},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10413,\"start\":10394},{\"end\":10721,\"start\":10701},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10968,\"start\":10950},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12705,\"start\":12679},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12719,\"start\":12705},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":12771,\"start\":12757},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12909,\"start\":12890},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13127,\"start\":13104},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13325,\"start\":13304},{\"end\":13355,\"start\":13338},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13483,\"start\":13465},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":13501,\"start\":13483},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13700,\"start\":13680},{\"end\":13736,\"start\":13707},{\"end\":13764,\"start\":13736},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":14224,\"start\":14206},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14548,\"start\":14530},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14578,\"start\":14561}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":16222,\"start\":16101},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":17384,\"start\":16223},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":18019,\"start\":17385},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":18674,\"start\":18020},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":19589,\"start\":18675},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":19828,\"start\":19590}]", "paragraph": "[{\"end\":1685,\"start\":1124},{\"end\":2335,\"start\":1687},{\"end\":2775,\"start\":2337},{\"end\":3201,\"start\":2777},{\"end\":4349,\"start\":3203},{\"end\":4405,\"start\":4360},{\"end\":4612,\"start\":4407},{\"end\":5686,\"start\":4628},{\"end\":6051,\"start\":5732},{\"end\":6632,\"start\":6085},{\"end\":6809,\"start\":6689},{\"end\":6948,\"start\":6811},{\"end\":7156,\"start\":6988},{\"end\":7811,\"start\":7202},{\"end\":8007,\"start\":7813},{\"end\":8501,\"start\":8009},{\"end\":9220,\"start\":8518},{\"end\":9565,\"start\":9222},{\"end\":9880,\"start\":9567},{\"end\":11162,\"start\":9893},{\"end\":11916,\"start\":11180},{\"end\":12355,\"start\":11918},{\"end\":14805,\"start\":12372},{\"end\":15286,\"start\":14820},{\"end\":15360,\"start\":15302},{\"end\":15645,\"start\":15362},{\"end\":16100,\"start\":15647},{\"end\":16221,\"start\":16115},{\"end\":16424,\"start\":16236},{\"end\":17383,\"start\":17263},{\"end\":17544,\"start\":17398},{\"end\":18143,\"start\":18033},{\"end\":19588,\"start\":18678},{\"end\":19827,\"start\":19603}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":5731,\"start\":5700},{\"attributes\":{\"id\":\"formula_1\"},\"end\":6084,\"start\":6052},{\"attributes\":{\"id\":\"formula_2\"},\"end\":6688,\"start\":6633},{\"attributes\":{\"id\":\"formula_3\"},\"end\":6987,\"start\":6949}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":8528,\"start\":8527},{\"end\":9647,\"start\":9646},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":10053,\"start\":10052},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":11001,\"start\":11000},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":11190,\"start\":11189},{\"end\":15369,\"start\":15368},{\"end\":16018,\"start\":16017}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1122,\"start\":1110},{\"attributes\":{\"n\":\"2\"},\"end\":4358,\"start\":4352},{\"end\":4626,\"start\":4615},{\"end\":5699,\"start\":5689},{\"end\":7200,\"start\":7159},{\"attributes\":{\"n\":\"3.2\"},\"end\":8516,\"start\":8504},{\"attributes\":{\"n\":\"4\"},\"end\":9891,\"start\":9883},{\"end\":11178,\"start\":11165},{\"attributes\":{\"n\":\"5\"},\"end\":12370,\"start\":12358},{\"attributes\":{\"n\":\"6\"},\"end\":14818,\"start\":14808},{\"end\":15300,\"start\":15289},{\"end\":16112,\"start\":16102},{\"end\":16233,\"start\":16224},{\"end\":17395,\"start\":17386},{\"end\":18030,\"start\":18021},{\"end\":19600,\"start\":19591}]", "table": "[{\"end\":17262,\"start\":16425},{\"end\":18019,\"start\":17545},{\"end\":18674,\"start\":18144}]", "figure_caption": "[{\"end\":16222,\"start\":16114},{\"end\":16425,\"start\":16235},{\"end\":17545,\"start\":17397},{\"end\":18144,\"start\":18032},{\"end\":19589,\"start\":18677},{\"end\":19828,\"start\":19602}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5004,\"start\":5003}]", "bib_author_first_name": "[{\"end\":23663,\"start\":23654},{\"end\":23680,\"start\":23676},{\"end\":23696,\"start\":23688},{\"end\":23712,\"start\":23705},{\"end\":23724,\"start\":23719},{\"end\":23739,\"start\":23733},{\"end\":23759,\"start\":23750},{\"end\":23776,\"start\":23771},{\"end\":23791,\"start\":23786},{\"end\":23806,\"start\":23799},{\"end\":23996,\"start\":23992},{\"end\":24011,\"start\":24005},{\"end\":24028,\"start\":24023},{\"end\":24044,\"start\":24038},{\"end\":24165,\"start\":24162},{\"end\":24167,\"start\":24166},{\"end\":24183,\"start\":24175},{\"end\":24194,\"start\":24190},{\"end\":24209,\"start\":24202},{\"end\":24224,\"start\":24219},{\"end\":24241,\"start\":24233},{\"end\":24258,\"start\":24252},{\"end\":24278,\"start\":24272},{\"end\":24292,\"start\":24286},{\"end\":24307,\"start\":24301},{\"end\":24324,\"start\":24316},{\"end\":24339,\"start\":24334},{\"end\":24362,\"start\":24354},{\"end\":24375,\"start\":24372},{\"end\":24391,\"start\":24386},{\"end\":24405,\"start\":24399},{\"end\":24420,\"start\":24414},{\"end\":24422,\"start\":24421},{\"end\":24439,\"start\":24432},{\"end\":24451,\"start\":24444},{\"end\":24471,\"start\":24460},{\"end\":24483,\"start\":24479},{\"end\":24494,\"start\":24490},{\"end\":24510,\"start\":24503},{\"end\":24865,\"start\":24859},{\"end\":24886,\"start\":24883},{\"end\":24898,\"start\":24895},{\"end\":24913,\"start\":24910},{\"end\":24928,\"start\":24920},{\"end\":24941,\"start\":24934},{\"end\":24956,\"start\":24950},{\"end\":24969,\"start\":24967},{\"end\":24983,\"start\":24976},{\"end\":25038,\"start\":25029},{\"end\":25056,\"start\":25050},{\"end\":25070,\"start\":25065},{\"end\":25086,\"start\":25079},{\"end\":25100,\"start\":25094},{\"end\":25113,\"start\":25109},{\"end\":25127,\"start\":25123},{\"end\":25141,\"start\":25136},{\"end\":25145,\"start\":25142},{\"end\":25160,\"start\":25153},{\"end\":25178,\"start\":25169},{\"end\":25195,\"start\":25189},{\"end\":25209,\"start\":25203},{\"end\":25220,\"start\":25215},{\"end\":25242,\"start\":25236},{\"end\":25259,\"start\":25251},{\"end\":25271,\"start\":25265},{\"end\":25282,\"start\":25280},{\"end\":25292,\"start\":25288},{\"end\":25294,\"start\":25293},{\"end\":25309,\"start\":25304},{\"end\":25337,\"start\":25334},{\"end\":25350,\"start\":25344},{\"end\":25352,\"start\":25351},{\"end\":25363,\"start\":25357},{\"end\":25381,\"start\":25376},{\"end\":25393,\"start\":25388},{\"end\":25411,\"start\":25404},{\"end\":25423,\"start\":25420},{\"end\":25440,\"start\":25431},{\"end\":25454,\"start\":25450},{\"end\":25466,\"start\":25460},{\"end\":25479,\"start\":25473},{\"end\":25496,\"start\":25490},{\"end\":25513,\"start\":25507},{\"end\":25525,\"start\":25519},{\"end\":25545,\"start\":25539},{\"end\":25559,\"start\":25554},{\"end\":25571,\"start\":25567},{\"end\":25587,\"start\":25582},{\"end\":25601,\"start\":25595},{\"end\":25613,\"start\":25608},{\"end\":25633,\"start\":25624},{\"end\":25646,\"start\":25640},{\"end\":25661,\"start\":25652},{\"end\":25672,\"start\":25668},{\"end\":26193,\"start\":26189},{\"end\":26211,\"start\":26204},{\"end\":26224,\"start\":26219},{\"end\":26239,\"start\":26233},{\"end\":26253,\"start\":26248},{\"end\":26255,\"start\":26254},{\"end\":26352,\"start\":26348},{\"end\":26370,\"start\":26363},{\"end\":26383,\"start\":26378},{\"end\":26398,\"start\":26392},{\"end\":26421,\"start\":26416},{\"end\":26423,\"start\":26422},{\"end\":26547,\"start\":26539},{\"end\":26564,\"start\":26556},{\"end\":26585,\"start\":26577},{\"end\":26875,\"start\":26871},{\"end\":26886,\"start\":26881},{\"end\":27234,\"start\":27230},{\"end\":27248,\"start\":27240},{\"end\":27258,\"start\":27253},{\"end\":27269,\"start\":27264},{\"end\":27377,\"start\":27370},{\"end\":27391,\"start\":27386},{\"end\":27409,\"start\":27402},{\"end\":27426,\"start\":27417},{\"end\":27438,\"start\":27434},{\"end\":27455,\"start\":27446},{\"end\":27472,\"start\":27467},{\"end\":27837,\"start\":27829},{\"end\":27855,\"start\":27849},{\"end\":27867,\"start\":27862},{\"end\":27880,\"start\":27873},{\"end\":27894,\"start\":27888},{\"end\":27905,\"start\":27899},{\"end\":27919,\"start\":27914},{\"end\":27933,\"start\":27926},{\"end\":28238,\"start\":28232},{\"end\":28250,\"start\":28249},{\"end\":28256,\"start\":28251},{\"end\":28398,\"start\":28393},{\"end\":28400,\"start\":28399},{\"end\":28414,\"start\":28406},{\"end\":28572,\"start\":28567},{\"end\":28574,\"start\":28573},{\"end\":28588,\"start\":28580},{\"end\":28604,\"start\":28593},{\"end\":28620,\"start\":28610},{\"end\":28632,\"start\":28627},{\"end\":28649,\"start\":28642},{\"end\":28665,\"start\":28660},{\"end\":28667,\"start\":28666},{\"end\":28969,\"start\":28962},{\"end\":28982,\"start\":28975},{\"end\":28992,\"start\":28987},{\"end\":29007,\"start\":28998},{\"end\":29022,\"start\":29016},{\"end\":29165,\"start\":29158},{\"end\":29180,\"start\":29170},{\"end\":29378,\"start\":29377},{\"end\":29537,\"start\":29530},{\"end\":29553,\"start\":29548},{\"end\":29608,\"start\":29601},{\"end\":29622,\"start\":29619},{\"end\":29634,\"start\":29629},{\"end\":29636,\"start\":29635},{\"end\":29651,\"start\":29642},{\"end\":29752,\"start\":29748},{\"end\":29764,\"start\":29760},{\"end\":29777,\"start\":29772},{\"end\":29789,\"start\":29783},{\"end\":29803,\"start\":29799},{\"end\":29805,\"start\":29804},{\"end\":29817,\"start\":29813},{\"end\":30039,\"start\":30033},{\"end\":30050,\"start\":30044},{\"end\":30061,\"start\":30057},{\"end\":30070,\"start\":30067},{\"end\":30083,\"start\":30076},{\"end\":30094,\"start\":30089},{\"end\":30098,\"start\":30095},{\"end\":30112,\"start\":30105},{\"end\":30122,\"start\":30119},{\"end\":30134,\"start\":30127},{\"end\":30585,\"start\":30578},{\"end\":30597,\"start\":30591},{\"end\":30606,\"start\":30602},{\"end\":30617,\"start\":30612},{\"end\":30621,\"start\":30618},{\"end\":30636,\"start\":30628},{\"end\":30645,\"start\":30642},{\"end\":30657,\"start\":30650},{\"end\":30671,\"start\":30664},{\"end\":30981,\"start\":30980},{\"end\":30983,\"start\":30982},{\"end\":31044,\"start\":31037},{\"end\":31056,\"start\":31050},{\"end\":31065,\"start\":31063},{\"end\":31077,\"start\":31071},{\"end\":31089,\"start\":31084},{\"end\":31226,\"start\":31220},{\"end\":31239,\"start\":31235},{\"end\":31256,\"start\":31249},{\"end\":31510,\"start\":31503},{\"end\":31532,\"start\":31525},{\"end\":31547,\"start\":31541},{\"end\":31567,\"start\":31557},{\"end\":31586,\"start\":31578},{\"end\":31604,\"start\":31596},{\"end\":31619,\"start\":31614},{\"end\":31633,\"start\":31629},{\"end\":31647,\"start\":31641},{\"end\":31669,\"start\":31663},{\"end\":31811,\"start\":31806},{\"end\":31829,\"start\":31822},{\"end\":31842,\"start\":31836},{\"end\":31856,\"start\":31852},{\"end\":31880,\"start\":31873},{\"end\":31882,\"start\":31881},{\"end\":31894,\"start\":31890},{\"end\":31903,\"start\":31899},{\"end\":31916,\"start\":31913},{\"end\":31931,\"start\":31927},{\"end\":31940,\"start\":31936},{\"end\":32039,\"start\":32034},{\"end\":32057,\"start\":32048},{\"end\":32067,\"start\":32063},{\"end\":32076,\"start\":32072},{\"end\":32079,\"start\":32077},{\"end\":32095,\"start\":32086},{\"end\":32113,\"start\":32108},{\"end\":32129,\"start\":32121},{\"end\":32470,\"start\":32465},{\"end\":32480,\"start\":32477},{\"end\":32495,\"start\":32487},{\"end\":32510,\"start\":32503},{\"end\":32523,\"start\":32517},{\"end\":32535,\"start\":32530},{\"end\":32549,\"start\":32543},{\"end\":32564,\"start\":32560},{\"end\":32691,\"start\":32686},{\"end\":32701,\"start\":32698},{\"end\":32716,\"start\":32708},{\"end\":32731,\"start\":32724},{\"end\":32744,\"start\":32738},{\"end\":32756,\"start\":32751},{\"end\":32770,\"start\":32764},{\"end\":32785,\"start\":32781},{\"end\":33145,\"start\":33142},{\"end\":33160,\"start\":33153},{\"end\":33170,\"start\":33168},{\"end\":33184,\"start\":33175},{\"end\":33197,\"start\":33191},{\"end\":33207,\"start\":33203},{\"end\":33209,\"start\":33208},{\"end\":33225,\"start\":33219},{\"end\":33239,\"start\":33233},{\"end\":33461,\"start\":33460},{\"end\":33469,\"start\":33466},{\"end\":33484,\"start\":33476},{\"end\":33498,\"start\":33491},{\"end\":33511,\"start\":33503},{\"end\":33522,\"start\":33516},{\"end\":33540,\"start\":33531},{\"end\":33553,\"start\":33546},{\"end\":33564,\"start\":33560},{\"end\":33667,\"start\":33663},{\"end\":33680,\"start\":33675},{\"end\":33693,\"start\":33687},{\"end\":33709,\"start\":33700},{\"end\":33717,\"start\":33714},{\"end\":33730,\"start\":33724}]", "bib_author_last_name": "[{\"end\":23674,\"start\":23664},{\"end\":23686,\"start\":23681},{\"end\":23703,\"start\":23697},{\"end\":23717,\"start\":23713},{\"end\":23731,\"start\":23725},{\"end\":23748,\"start\":23740},{\"end\":23769,\"start\":23760},{\"end\":23784,\"start\":23777},{\"end\":23797,\"start\":23792},{\"end\":23816,\"start\":23807},{\"end\":24003,\"start\":23997},{\"end\":24021,\"start\":24012},{\"end\":24036,\"start\":24029},{\"end\":24052,\"start\":24045},{\"end\":24173,\"start\":24168},{\"end\":24188,\"start\":24184},{\"end\":24200,\"start\":24195},{\"end\":24217,\"start\":24210},{\"end\":24231,\"start\":24225},{\"end\":24250,\"start\":24242},{\"end\":24270,\"start\":24259},{\"end\":24284,\"start\":24279},{\"end\":24299,\"start\":24293},{\"end\":24314,\"start\":24308},{\"end\":24332,\"start\":24325},{\"end\":24352,\"start\":24340},{\"end\":24370,\"start\":24363},{\"end\":24384,\"start\":24376},{\"end\":24397,\"start\":24392},{\"end\":24412,\"start\":24406},{\"end\":24430,\"start\":24423},{\"end\":24442,\"start\":24440},{\"end\":24458,\"start\":24452},{\"end\":24477,\"start\":24472},{\"end\":24488,\"start\":24484},{\"end\":24501,\"start\":24495},{\"end\":24517,\"start\":24511},{\"end\":24881,\"start\":24866},{\"end\":24893,\"start\":24887},{\"end\":24908,\"start\":24899},{\"end\":24918,\"start\":24914},{\"end\":24932,\"start\":24929},{\"end\":24948,\"start\":24942},{\"end\":24965,\"start\":24957},{\"end\":24974,\"start\":24970},{\"end\":24989,\"start\":24984},{\"end\":25048,\"start\":25039},{\"end\":25063,\"start\":25057},{\"end\":25077,\"start\":25071},{\"end\":25092,\"start\":25087},{\"end\":25107,\"start\":25101},{\"end\":25121,\"start\":25114},{\"end\":25134,\"start\":25128},{\"end\":25151,\"start\":25146},{\"end\":25167,\"start\":25161},{\"end\":25187,\"start\":25179},{\"end\":25201,\"start\":25196},{\"end\":25213,\"start\":25210},{\"end\":25234,\"start\":25221},{\"end\":25249,\"start\":25243},{\"end\":25263,\"start\":25260},{\"end\":25278,\"start\":25272},{\"end\":25286,\"start\":25283},{\"end\":25302,\"start\":25295},{\"end\":25332,\"start\":25310},{\"end\":25342,\"start\":25338},{\"end\":25355,\"start\":25353},{\"end\":25374,\"start\":25364},{\"end\":25386,\"start\":25382},{\"end\":25402,\"start\":25394},{\"end\":25418,\"start\":25412},{\"end\":25429,\"start\":25424},{\"end\":25448,\"start\":25441},{\"end\":25458,\"start\":25455},{\"end\":25471,\"start\":25467},{\"end\":25488,\"start\":25480},{\"end\":25505,\"start\":25497},{\"end\":25517,\"start\":25514},{\"end\":25537,\"start\":25526},{\"end\":25552,\"start\":25546},{\"end\":25565,\"start\":25560},{\"end\":25580,\"start\":25572},{\"end\":25593,\"start\":25588},{\"end\":25606,\"start\":25602},{\"end\":25622,\"start\":25614},{\"end\":25638,\"start\":25634},{\"end\":25650,\"start\":25647},{\"end\":25666,\"start\":25662},{\"end\":25683,\"start\":25673},{\"end\":25692,\"start\":25685},{\"end\":26202,\"start\":26194},{\"end\":26217,\"start\":26212},{\"end\":26231,\"start\":26225},{\"end\":26246,\"start\":26240},{\"end\":26264,\"start\":26256},{\"end\":26361,\"start\":26353},{\"end\":26376,\"start\":26371},{\"end\":26390,\"start\":26384},{\"end\":26414,\"start\":26399},{\"end\":26432,\"start\":26424},{\"end\":26554,\"start\":26548},{\"end\":26575,\"start\":26565},{\"end\":26595,\"start\":26586},{\"end\":26879,\"start\":26876},{\"end\":26893,\"start\":26887},{\"end\":27238,\"start\":27235},{\"end\":27251,\"start\":27249},{\"end\":27262,\"start\":27259},{\"end\":27276,\"start\":27270},{\"end\":27384,\"start\":27378},{\"end\":27400,\"start\":27392},{\"end\":27415,\"start\":27410},{\"end\":27432,\"start\":27427},{\"end\":27444,\"start\":27439},{\"end\":27465,\"start\":27456},{\"end\":27478,\"start\":27473},{\"end\":27486,\"start\":27480},{\"end\":27847,\"start\":27838},{\"end\":27860,\"start\":27856},{\"end\":27871,\"start\":27868},{\"end\":27886,\"start\":27881},{\"end\":27897,\"start\":27895},{\"end\":27912,\"start\":27906},{\"end\":27924,\"start\":27920},{\"end\":27937,\"start\":27934},{\"end\":28247,\"start\":28239},{\"end\":28262,\"start\":28257},{\"end\":28404,\"start\":28401},{\"end\":28417,\"start\":28415},{\"end\":28578,\"start\":28575},{\"end\":28591,\"start\":28589},{\"end\":28608,\"start\":28605},{\"end\":28625,\"start\":28621},{\"end\":28640,\"start\":28633},{\"end\":28658,\"start\":28650},{\"end\":28676,\"start\":28668},{\"end\":28973,\"start\":28970},{\"end\":28985,\"start\":28983},{\"end\":28996,\"start\":28993},{\"end\":29014,\"start\":29008},{\"end\":29032,\"start\":29023},{\"end\":29168,\"start\":29166},{\"end\":29185,\"start\":29181},{\"end\":29385,\"start\":29379},{\"end\":29393,\"start\":29387},{\"end\":29546,\"start\":29538},{\"end\":29557,\"start\":29554},{\"end\":29617,\"start\":29609},{\"end\":29627,\"start\":29623},{\"end\":29640,\"start\":29637},{\"end\":29655,\"start\":29652},{\"end\":29758,\"start\":29753},{\"end\":29770,\"start\":29765},{\"end\":29781,\"start\":29778},{\"end\":29797,\"start\":29790},{\"end\":29811,\"start\":29806},{\"end\":29823,\"start\":29818},{\"end\":30042,\"start\":30040},{\"end\":30055,\"start\":30051},{\"end\":30065,\"start\":30062},{\"end\":30074,\"start\":30071},{\"end\":30087,\"start\":30084},{\"end\":30103,\"start\":30099},{\"end\":30117,\"start\":30113},{\"end\":30125,\"start\":30123},{\"end\":30139,\"start\":30135},{\"end\":30589,\"start\":30586},{\"end\":30600,\"start\":30598},{\"end\":30610,\"start\":30607},{\"end\":30626,\"start\":30622},{\"end\":30640,\"start\":30637},{\"end\":30648,\"start\":30646},{\"end\":30662,\"start\":30658},{\"end\":30675,\"start\":30672},{\"end\":30991,\"start\":30984},{\"end\":31048,\"start\":31045},{\"end\":31061,\"start\":31057},{\"end\":31069,\"start\":31066},{\"end\":31082,\"start\":31078},{\"end\":31094,\"start\":31090},{\"end\":31233,\"start\":31227},{\"end\":31247,\"start\":31240},{\"end\":31263,\"start\":31257},{\"end\":31523,\"start\":31511},{\"end\":31539,\"start\":31533},{\"end\":31555,\"start\":31548},{\"end\":31576,\"start\":31568},{\"end\":31594,\"start\":31587},{\"end\":31612,\"start\":31605},{\"end\":31627,\"start\":31620},{\"end\":31639,\"start\":31634},{\"end\":31654,\"start\":31648},{\"end\":31661,\"start\":31656},{\"end\":31689,\"start\":31670},{\"end\":31697,\"start\":31691},{\"end\":31820,\"start\":31812},{\"end\":31834,\"start\":31830},{\"end\":31850,\"start\":31843},{\"end\":31871,\"start\":31857},{\"end\":31888,\"start\":31883},{\"end\":31897,\"start\":31895},{\"end\":31911,\"start\":31904},{\"end\":31925,\"start\":31917},{\"end\":31934,\"start\":31932},{\"end\":32046,\"start\":32040},{\"end\":32061,\"start\":32058},{\"end\":32070,\"start\":32068},{\"end\":32084,\"start\":32080},{\"end\":32106,\"start\":32096},{\"end\":32119,\"start\":32114},{\"end\":32140,\"start\":32130},{\"end\":32475,\"start\":32471},{\"end\":32485,\"start\":32481},{\"end\":32501,\"start\":32496},{\"end\":32515,\"start\":32511},{\"end\":32528,\"start\":32524},{\"end\":32541,\"start\":32536},{\"end\":32558,\"start\":32550},{\"end\":32568,\"start\":32565},{\"end\":32696,\"start\":32692},{\"end\":32706,\"start\":32702},{\"end\":32722,\"start\":32717},{\"end\":32736,\"start\":32732},{\"end\":32749,\"start\":32745},{\"end\":32762,\"start\":32757},{\"end\":32779,\"start\":32771},{\"end\":32789,\"start\":32786},{\"end\":33151,\"start\":33146},{\"end\":33166,\"start\":33161},{\"end\":33173,\"start\":33171},{\"end\":33189,\"start\":33185},{\"end\":33201,\"start\":33198},{\"end\":33217,\"start\":33210},{\"end\":33231,\"start\":33226},{\"end\":33248,\"start\":33240},{\"end\":33464,\"start\":33462},{\"end\":33474,\"start\":33470},{\"end\":33489,\"start\":33485},{\"end\":33501,\"start\":33499},{\"end\":33514,\"start\":33512},{\"end\":33529,\"start\":33523},{\"end\":33544,\"start\":33541},{\"end\":33558,\"start\":33554},{\"end\":33570,\"start\":33565},{\"end\":33673,\"start\":33668},{\"end\":33685,\"start\":33681},{\"end\":33698,\"start\":33694},{\"end\":33712,\"start\":33710},{\"end\":33722,\"start\":33718},{\"end\":33735,\"start\":33731}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":251385004},\"end\":23918,\"start\":23609},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":14355670},\"end\":24112,\"start\":23920},{\"attributes\":{\"id\":\"b2\"},\"end\":24790,\"start\":24114},{\"attributes\":{\"doi\":\"abs/1611.09268\",\"id\":\"b3\",\"matched_paper_id\":1289517},\"end\":25025,\"start\":24792},{\"attributes\":{\"id\":\"b4\"},\"end\":26140,\"start\":25027},{\"attributes\":{\"doi\":\"abs/2003.07820\",\"id\":\"b5\"},\"end\":26299,\"start\":26142},{\"attributes\":{\"doi\":\"abs/2003.07820\",\"id\":\"b6\",\"matched_paper_id\":212737158},\"end\":26469,\"start\":26301},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":235792467},\"end\":26810,\"start\":26471},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.75\",\"id\":\"b8\",\"matched_paper_id\":237581068},\"end\":27168,\"start\":26812},{\"attributes\":{\"doi\":\"abs/2212.10496\",\"id\":\"b9\",\"matched_paper_id\":254877046},\"end\":27312,\"start\":27170},{\"attributes\":{\"doi\":\"10.1145/3077136.3080751\",\"id\":\"b10\",\"matched_paper_id\":3675602},\"end\":27768,\"start\":27314},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.550\",\"id\":\"b11\",\"matched_paper_id\":215737187},\"end\":28198,\"start\":27770},{\"attributes\":{\"id\":\"b12\"},\"end\":28287,\"start\":28200},{\"attributes\":{\"doi\":\"abs/2106.14807\",\"id\":\"b13\"},\"end\":28451,\"start\":28289},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":235366815},\"end\":28891,\"start\":28453},{\"attributes\":{\"doi\":\"abs/2210.07093\",\"id\":\"b15\"},\"end\":29066,\"start\":28893},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":12012494},\"end\":29334,\"start\":29068},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":1671874},\"end\":29495,\"start\":29336},{\"attributes\":{\"id\":\"b18\"},\"end\":29559,\"start\":29497},{\"attributes\":{\"doi\":\"abs/1904.08375\",\"id\":\"b19\"},\"end\":29689,\"start\":29561},{\"attributes\":{\"doi\":\"ArXiv, abs/2303.08774\",\"id\":\"b20\"},\"end\":29746,\"start\":29691},{\"attributes\":{\"doi\":\"arXiv:2210.03350\",\"id\":\"b21\"},\"end\":29928,\"start\":29748},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.466\",\"id\":\"b22\",\"matched_paper_id\":231815627},\"end\":30488,\"start\":29930},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.224\",\"id\":\"b23\",\"matched_paper_id\":238857121},\"end\":30933,\"start\":30490},{\"attributes\":{\"id\":\"b24\"},\"end\":30997,\"start\":30935},{\"attributes\":{\"doi\":\"abs/2210.01296\",\"id\":\"b25\"},\"end\":31128,\"start\":30999},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":233296016},\"end\":31404,\"start\":31130},{\"attributes\":{\"doi\":\"ArXiv preprint, abs/2302.13971\",\"id\":\"b27\"},\"end\":31729,\"start\":31406},{\"attributes\":{\"id\":\"b28\"},\"end\":31986,\"start\":31731},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.609\",\"id\":\"b29\",\"matched_paper_id\":216867133},\"end\":32401,\"start\":31988},{\"attributes\":{\"doi\":\"abs/2212.03533\",\"id\":\"b30\",\"matched_paper_id\":254366618},\"end\":32604,\"start\":32403},{\"attributes\":{\"doi\":\"10.18653/v1/2023.acl-long.125\",\"id\":\"b31\",\"matched_paper_id\":250311114},\"end\":33055,\"start\":32606},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":220302524},\"end\":33374,\"start\":33057},{\"attributes\":{\"id\":\"b33\"},\"end\":33606,\"start\":33376},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":238419331},\"end\":33864,\"start\":33608}]", "bib_title": "[{\"end\":23652,\"start\":23609},{\"end\":23990,\"start\":23920},{\"end\":24160,\"start\":24114},{\"end\":24857,\"start\":24792},{\"end\":26346,\"start\":26301},{\"end\":26537,\"start\":26471},{\"end\":26869,\"start\":26812},{\"end\":27228,\"start\":27170},{\"end\":27368,\"start\":27314},{\"end\":27827,\"start\":27770},{\"end\":28230,\"start\":28200},{\"end\":28565,\"start\":28453},{\"end\":29156,\"start\":29068},{\"end\":29375,\"start\":29336},{\"end\":30031,\"start\":29930},{\"end\":30576,\"start\":30490},{\"end\":31218,\"start\":31130},{\"end\":31804,\"start\":31731},{\"end\":32032,\"start\":31988},{\"end\":32463,\"start\":32403},{\"end\":32684,\"start\":32606},{\"end\":33140,\"start\":33057},{\"end\":33661,\"start\":33608}]", "bib_author": "[{\"end\":23676,\"start\":23654},{\"end\":23688,\"start\":23676},{\"end\":23705,\"start\":23688},{\"end\":23719,\"start\":23705},{\"end\":23733,\"start\":23719},{\"end\":23750,\"start\":23733},{\"end\":23771,\"start\":23750},{\"end\":23786,\"start\":23771},{\"end\":23799,\"start\":23786},{\"end\":23818,\"start\":23799},{\"end\":24005,\"start\":23992},{\"end\":24023,\"start\":24005},{\"end\":24038,\"start\":24023},{\"end\":24054,\"start\":24038},{\"end\":24175,\"start\":24162},{\"end\":24190,\"start\":24175},{\"end\":24202,\"start\":24190},{\"end\":24219,\"start\":24202},{\"end\":24233,\"start\":24219},{\"end\":24252,\"start\":24233},{\"end\":24272,\"start\":24252},{\"end\":24286,\"start\":24272},{\"end\":24301,\"start\":24286},{\"end\":24316,\"start\":24301},{\"end\":24334,\"start\":24316},{\"end\":24354,\"start\":24334},{\"end\":24372,\"start\":24354},{\"end\":24386,\"start\":24372},{\"end\":24399,\"start\":24386},{\"end\":24414,\"start\":24399},{\"end\":24432,\"start\":24414},{\"end\":24444,\"start\":24432},{\"end\":24460,\"start\":24444},{\"end\":24479,\"start\":24460},{\"end\":24490,\"start\":24479},{\"end\":24503,\"start\":24490},{\"end\":24519,\"start\":24503},{\"end\":24883,\"start\":24859},{\"end\":24895,\"start\":24883},{\"end\":24910,\"start\":24895},{\"end\":24920,\"start\":24910},{\"end\":24934,\"start\":24920},{\"end\":24950,\"start\":24934},{\"end\":24967,\"start\":24950},{\"end\":24976,\"start\":24967},{\"end\":24991,\"start\":24976},{\"end\":25050,\"start\":25029},{\"end\":25065,\"start\":25050},{\"end\":25079,\"start\":25065},{\"end\":25094,\"start\":25079},{\"end\":25109,\"start\":25094},{\"end\":25123,\"start\":25109},{\"end\":25136,\"start\":25123},{\"end\":25153,\"start\":25136},{\"end\":25169,\"start\":25153},{\"end\":25189,\"start\":25169},{\"end\":25203,\"start\":25189},{\"end\":25215,\"start\":25203},{\"end\":25236,\"start\":25215},{\"end\":25251,\"start\":25236},{\"end\":25265,\"start\":25251},{\"end\":25280,\"start\":25265},{\"end\":25288,\"start\":25280},{\"end\":25304,\"start\":25288},{\"end\":25334,\"start\":25304},{\"end\":25344,\"start\":25334},{\"end\":25357,\"start\":25344},{\"end\":25376,\"start\":25357},{\"end\":25388,\"start\":25376},{\"end\":25404,\"start\":25388},{\"end\":25420,\"start\":25404},{\"end\":25431,\"start\":25420},{\"end\":25450,\"start\":25431},{\"end\":25460,\"start\":25450},{\"end\":25473,\"start\":25460},{\"end\":25490,\"start\":25473},{\"end\":25507,\"start\":25490},{\"end\":25519,\"start\":25507},{\"end\":25539,\"start\":25519},{\"end\":25554,\"start\":25539},{\"end\":25567,\"start\":25554},{\"end\":25582,\"start\":25567},{\"end\":25595,\"start\":25582},{\"end\":25608,\"start\":25595},{\"end\":25624,\"start\":25608},{\"end\":25640,\"start\":25624},{\"end\":25652,\"start\":25640},{\"end\":25668,\"start\":25652},{\"end\":25685,\"start\":25668},{\"end\":25694,\"start\":25685},{\"end\":26204,\"start\":26189},{\"end\":26219,\"start\":26204},{\"end\":26233,\"start\":26219},{\"end\":26248,\"start\":26233},{\"end\":26266,\"start\":26248},{\"end\":26363,\"start\":26348},{\"end\":26378,\"start\":26363},{\"end\":26392,\"start\":26378},{\"end\":26416,\"start\":26392},{\"end\":26434,\"start\":26416},{\"end\":26556,\"start\":26539},{\"end\":26577,\"start\":26556},{\"end\":26597,\"start\":26577},{\"end\":26881,\"start\":26871},{\"end\":26895,\"start\":26881},{\"end\":27240,\"start\":27230},{\"end\":27253,\"start\":27240},{\"end\":27264,\"start\":27253},{\"end\":27278,\"start\":27264},{\"end\":27386,\"start\":27370},{\"end\":27402,\"start\":27386},{\"end\":27417,\"start\":27402},{\"end\":27434,\"start\":27417},{\"end\":27446,\"start\":27434},{\"end\":27467,\"start\":27446},{\"end\":27480,\"start\":27467},{\"end\":27488,\"start\":27480},{\"end\":27849,\"start\":27829},{\"end\":27862,\"start\":27849},{\"end\":27873,\"start\":27862},{\"end\":27888,\"start\":27873},{\"end\":27899,\"start\":27888},{\"end\":27914,\"start\":27899},{\"end\":27926,\"start\":27914},{\"end\":27939,\"start\":27926},{\"end\":28249,\"start\":28232},{\"end\":28264,\"start\":28249},{\"end\":28406,\"start\":28393},{\"end\":28419,\"start\":28406},{\"end\":28580,\"start\":28567},{\"end\":28593,\"start\":28580},{\"end\":28610,\"start\":28593},{\"end\":28627,\"start\":28610},{\"end\":28642,\"start\":28627},{\"end\":28660,\"start\":28642},{\"end\":28678,\"start\":28660},{\"end\":28975,\"start\":28962},{\"end\":28987,\"start\":28975},{\"end\":28998,\"start\":28987},{\"end\":29016,\"start\":28998},{\"end\":29034,\"start\":29016},{\"end\":29170,\"start\":29158},{\"end\":29187,\"start\":29170},{\"end\":29387,\"start\":29377},{\"end\":29395,\"start\":29387},{\"end\":29548,\"start\":29530},{\"end\":29559,\"start\":29548},{\"end\":29619,\"start\":29601},{\"end\":29629,\"start\":29619},{\"end\":29642,\"start\":29629},{\"end\":29657,\"start\":29642},{\"end\":29760,\"start\":29748},{\"end\":29772,\"start\":29760},{\"end\":29783,\"start\":29772},{\"end\":29799,\"start\":29783},{\"end\":29813,\"start\":29799},{\"end\":29825,\"start\":29813},{\"end\":30044,\"start\":30033},{\"end\":30057,\"start\":30044},{\"end\":30067,\"start\":30057},{\"end\":30076,\"start\":30067},{\"end\":30089,\"start\":30076},{\"end\":30105,\"start\":30089},{\"end\":30119,\"start\":30105},{\"end\":30127,\"start\":30119},{\"end\":30141,\"start\":30127},{\"end\":30591,\"start\":30578},{\"end\":30602,\"start\":30591},{\"end\":30612,\"start\":30602},{\"end\":30628,\"start\":30612},{\"end\":30642,\"start\":30628},{\"end\":30650,\"start\":30642},{\"end\":30664,\"start\":30650},{\"end\":30677,\"start\":30664},{\"end\":30993,\"start\":30980},{\"end\":31050,\"start\":31037},{\"end\":31063,\"start\":31050},{\"end\":31071,\"start\":31063},{\"end\":31084,\"start\":31071},{\"end\":31096,\"start\":31084},{\"end\":31235,\"start\":31220},{\"end\":31249,\"start\":31235},{\"end\":31265,\"start\":31249},{\"end\":31525,\"start\":31503},{\"end\":31541,\"start\":31525},{\"end\":31557,\"start\":31541},{\"end\":31578,\"start\":31557},{\"end\":31596,\"start\":31578},{\"end\":31614,\"start\":31596},{\"end\":31629,\"start\":31614},{\"end\":31641,\"start\":31629},{\"end\":31656,\"start\":31641},{\"end\":31663,\"start\":31656},{\"end\":31691,\"start\":31663},{\"end\":31699,\"start\":31691},{\"end\":31822,\"start\":31806},{\"end\":31836,\"start\":31822},{\"end\":31852,\"start\":31836},{\"end\":31873,\"start\":31852},{\"end\":31890,\"start\":31873},{\"end\":31899,\"start\":31890},{\"end\":31913,\"start\":31899},{\"end\":31927,\"start\":31913},{\"end\":31936,\"start\":31927},{\"end\":31943,\"start\":31936},{\"end\":32048,\"start\":32034},{\"end\":32063,\"start\":32048},{\"end\":32072,\"start\":32063},{\"end\":32086,\"start\":32072},{\"end\":32108,\"start\":32086},{\"end\":32121,\"start\":32108},{\"end\":32142,\"start\":32121},{\"end\":32477,\"start\":32465},{\"end\":32487,\"start\":32477},{\"end\":32503,\"start\":32487},{\"end\":32517,\"start\":32503},{\"end\":32530,\"start\":32517},{\"end\":32543,\"start\":32530},{\"end\":32560,\"start\":32543},{\"end\":32570,\"start\":32560},{\"end\":32698,\"start\":32686},{\"end\":32708,\"start\":32698},{\"end\":32724,\"start\":32708},{\"end\":32738,\"start\":32724},{\"end\":32751,\"start\":32738},{\"end\":32764,\"start\":32751},{\"end\":32781,\"start\":32764},{\"end\":32791,\"start\":32781},{\"end\":33153,\"start\":33142},{\"end\":33168,\"start\":33153},{\"end\":33175,\"start\":33168},{\"end\":33191,\"start\":33175},{\"end\":33203,\"start\":33191},{\"end\":33219,\"start\":33203},{\"end\":33233,\"start\":33219},{\"end\":33250,\"start\":33233},{\"end\":33466,\"start\":33460},{\"end\":33476,\"start\":33466},{\"end\":33491,\"start\":33476},{\"end\":33503,\"start\":33491},{\"end\":33516,\"start\":33503},{\"end\":33531,\"start\":33516},{\"end\":33546,\"start\":33531},{\"end\":33560,\"start\":33546},{\"end\":33572,\"start\":33560},{\"end\":33675,\"start\":33663},{\"end\":33687,\"start\":33675},{\"end\":33700,\"start\":33687},{\"end\":33714,\"start\":33700},{\"end\":33724,\"start\":33714},{\"end\":33737,\"start\":33724}]", "bib_venue": "[{\"end\":23904,\"start\":23818},{\"end\":24098,\"start\":24054},{\"end\":24631,\"start\":24519},{\"end\":25019,\"start\":25005},{\"end\":26187,\"start\":26142},{\"end\":26462,\"start\":26448},{\"end\":26708,\"start\":26597},{\"end\":27011,\"start\":26925},{\"end\":27306,\"start\":27292},{\"end\":27622,\"start\":27511},{\"end\":28064,\"start\":27970},{\"end\":28279,\"start\":28264},{\"end\":28391,\"start\":28289},{\"end\":28789,\"start\":28678},{\"end\":28960,\"start\":28893},{\"end\":29265,\"start\":29187},{\"end\":29449,\"start\":29395},{\"end\":29528,\"start\":29497},{\"end\":29599,\"start\":29561},{\"end\":29734,\"start\":29712},{\"end\":29908,\"start\":29841},{\"end\":30314,\"start\":30172},{\"end\":30794,\"start\":30708},{\"end\":30978,\"start\":30935},{\"end\":31035,\"start\":30999},{\"end\":31359,\"start\":31265},{\"end\":31501,\"start\":31406},{\"end\":31958,\"start\":31943},{\"end\":32267,\"start\":32173},{\"end\":32598,\"start\":32584},{\"end\":32907,\"start\":32820},{\"end\":32920,\"start\":32909},{\"end\":33332,\"start\":33250},{\"end\":33458,\"start\":33376},{\"end\":33825,\"start\":33737},{\"end\":24716,\"start\":24633},{\"end\":26806,\"start\":26710},{\"end\":27102,\"start\":27013},{\"end\":27742,\"start\":27624},{\"end\":28145,\"start\":28066},{\"end\":28887,\"start\":28791},{\"end\":29330,\"start\":29267},{\"end\":29469,\"start\":29451},{\"end\":30443,\"start\":30316},{\"end\":30867,\"start\":30796},{\"end\":31977,\"start\":31960},{\"end\":32348,\"start\":32269},{\"end\":33009,\"start\":32922},{\"end\":33341,\"start\":33334}]"}}}, "year": 2023, "month": 12, "day": 17}