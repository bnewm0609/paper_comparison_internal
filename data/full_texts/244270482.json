{"id": 244270482, "updated": "2023-10-05 19:35:58.594", "metadata": {"title": "Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection", "authors": "[{\"first\":\"Nicolae-Catalin\",\"last\":\"Ristea\",\"middle\":[]},{\"first\":\"Neelu\",\"last\":\"Madan\",\"middle\":[]},{\"first\":\"Radu\",\"last\":\"Ionescu\",\"middle\":[\"Tudor\"]},{\"first\":\"Kamal\",\"last\":\"Nasrollahi\",\"middle\":[]},{\"first\":\"Fahad\",\"last\":\"Khan\",\"middle\":[\"Shahbaz\"]},{\"first\":\"Thomas\",\"last\":\"Moeslund\",\"middle\":[\"B.\"]},{\"first\":\"Mubarak\",\"last\":\"Shah\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Anomaly detection is commonly pursued as a one-class classification problem, where models can only learn from normal training samples, while being evaluated on both normal and abnormal test samples. Among the successful approaches for anomaly detection, a distinguished category of methods relies on predicting masked information (e.g. patches, future frames, etc.) and leveraging the reconstruction error with respect to the masked information as an abnormality score. Different from related methods, we propose to integrate the reconstruction-based functionality into a novel self-supervised predictive architectural building block. The proposed self-supervised block is generic and can easily be incorporated into various state-of-the-art anomaly detection methods. Our block starts with a convolutional layer with dilated filters, where the center area of the receptive field is masked. The resulting activation maps are passed through a channel attention module. Our block is equipped with a loss that minimizes the reconstruction error with respect to the masked area in the receptive field. We demonstrate the generality of our block by integrating it into several state-of-the-art frameworks for anomaly detection on image and video, providing empirical evidence that shows considerable performance improvements on MVTec AD, Avenue, and ShanghaiTech. We release our code as open source at https://github.com/ristea/sspcab.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2111.09099", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/RisteaMINKMS22", "doi": "10.1109/cvpr52688.2022.01321"}}, "content": {"source": {"pdf_hash": "976916d7969c5faee96bde61ed1ed5f5fd90c185", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2111.09099v6.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "db8f55fb38313e4f454213dd83c3ac5ed6f34f16", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/976916d7969c5faee96bde61ed1ed5f5fd90c185.txt", "contents": "\nSelf-Supervised Predictive Convolutional Attentive Block for Anomaly Detection\n\n\nNicolae-C\u0203t\u0203lin Ristea \nUniversity Politehnica of Bucharest\nRomania\n\nMBZ University of Artificial Intelligence\nUAE\n\nNeelu Madan \nAalborg University\nDenmark\n\nRadu Tudor Ionescu \nUniversity of Bucharest\n5 SecurifAIRomania, Romania\n\nKamal Nasrollahi \nAalborg University\nDenmark\n\nMilestone Systems\nDenmark\n\nFahad Shahbaz Khan \nMBZ University of Artificial Intelligence\nUAE\n\nLink\u00f6ping University\nSweden\n\nThomas B Moeslund \nAalborg University\nDenmark\n\nMubarak Shah \nUniversity of Central Florida\nUS\n\nSelf-Supervised Predictive Convolutional Attentive Block for Anomaly Detection\n\nAnomaly detection is commonly pursued as a one-class classification problem, where models can only learn from normal training samples, while being evaluated on both normal and abnormal test samples. Among the successful approaches for anomaly detection, a distinguished category of methods relies on predicting masked information (e.g. patches, future frames, etc.) and leveraging the reconstruction error with respect to the masked information as an abnormality score. Different from related methods, we propose to integrate the reconstruction-based functionality into a novel self-supervised predictive architectural building block. The proposed self-supervised block is generic and can easily be incorporated into various state-of-the-art anomaly detection methods. Our block starts with a convolutional layer with dilated filters, where the center area of the receptive field is masked. The resulting activation maps are passed through a channel attention module. Our block is equipped with a loss that minimizes the reconstruction error with respect to the masked area in the receptive field. We demonstrate the generality of our block by integrating it into several state-of-the-art frameworks for anomaly detection on image and video, providing empirical evidence that shows considerable performance improvements on MVTec AD, Avenue, and ShanghaiTech. We release our code as open source at: https://github.com/ ristea/sspcab.\n\nIntroduction\n\nAnomaly detection is an important task with a broad set of applications ranging from industrial inspection (finding defects of objects or materials on industrial production lines) [5,7,10,15,36,56,62,76] to public security (detecting abnormal events such as traffic accidents, fights, explosions, etc.) [12, 13, 17-19, 27, 28, 33, 39, 41, 47-50, 52, 67, 72, 73, 77, 78]. The task is typically framed as a one-class classification (outlier detection) problem, where methods [2, 8, 12, 21, 25, 27, 29, 33, 35, 37, 40, 43-45, 49-* corresponding author: raducu.ionescu@gmail.com 51,53,54,57,69,73,75,81,82] learn a familiarity model from normal training samples, labeling unfamiliar examples (outliers) as anomalies, at inference time. Since abnormal samples are available only at test time, supervised learning methods are not directly applicable to anomaly detection. To this end, researchers turned their attention to other directions such as reconstruction-based approaches [15,19,21,36,37,43,47,49,54,62,69,71], dictionary learning methods [7-9, 14, 40, 55], distance-based models [6,10,25,27,50,51,53,57,58,63,65,68,70], change detection frameworks [11,26,38,48], and probabilistic models [1,2,16,23,29,44,45,56,61,74].\n\nA distinguished subcategory of reconstruction methods relies on predicting masked information, leveraging the reconstruction error with respect to the masked information as an abnormality score. The masked information can come in different forms, e.g. superpixels [36], future frames [37], middle bounding boxes [17], among others. Methods in this subcategory mask some part of the input and employ a deep neural network to predict the missing input information. Different from such methods, we propose to integrate the capability of reconstructing the masked information into a neural block. Introducing the reconstruction task at a core architectural level has two important advantages: (i) it allows us to mask information at any layer in a neural network (not only at the input), and (ii) it can be integrated into a wide range of neural architectures, thus being very general.\n\nWe design our reconstruction block as a self-supervised predictive block formed of a dilated convolutional layer and a channel attention mechanism. The dilated filters are based on a custom receptive field, where the center area of the kernel is masked. The resulting convolutional activation maps are then passed through a channel attention module [24]. The attention module ensures the block does not simply learn to reconstruct the masked region based on linearly interpolating contextual information. Our block is equipped with a loss that minimizes the reconstruction error between the final activation maps and the masked information. In other words, our block is trained to predict the masked information in a self-supervised manner. Our self-supervised  For each location where the dilated convolutional filter is applied, the block learns to reconstruct the masked area using contextual information. A channel attention module performs feature recalibration by using global information to selectively emphasize or suppress reconstruction maps. Best viewed in color.\n\npredictive convolutional attentive block (SSPCAB) is illustrated in Figure 1. For each location where the dilated convolutional filter is applied, the block learns to reconstruct the masked area using contextual information. Meanwhile, the dilation rate becomes a natural way to control the context level (from local to global), as required for the specific application.\n\nWe integrate SSPCAB into various state-of-the-art anomaly detection frameworks [18,34,37,39,49,79] and conduct comprehensive experiments on the MVTec AD [5], Avenue [40] and ShanghaiTech [43] data sets. Our empirical results show that SSPCAB can bring significant performance improvements, e.g. the region-based detection criterion (RBDC) of Liu et al. [39] on Avenue increases from 41% to 62% by adding SSPCAB. Moreover, with the help of SSPCAB, we are able to report new state-of-the-art performance levels on Avenue and ShanghaiTech. Additionally, we show extra results on the Avenue data set, indicating that the masked convolutional layer can also increase performance levels, all by itself.\n\nIn summary, our contribution is twofold: \u2022 We introduce a novel self-supervised predictive convolutional attentive block that is inherently capable of performing anomaly detection. \u2022 We integrate the block into several state-of-the-art neural models [18,34,37,39,49,79] for anomaly detection, showing significant performance improvements across multiple models and benchmarks.\n\n\nRelated Work\n\nAs anomalies are difficult to anticipate, methods are typically trained only on normal data, while being tested on both normal and abnormal data [21,49]. Therefore, outlier detection [25,27,50,51,53] and self-supervised learning [17-19, 34, 39, 41, 49, 79] approaches are extensively used to address the anomaly detection task. Anomaly detection methods can be classified into: dictionary learning methods [7-9, 14, 40, 55], change detection frameworks [11,26,38,48], probability-based methods [1,2,16,23,29,44,45,56,61,74], distance-based models [6,10,25,27,50,51,53,57,58,63,65,68,70], and reconstruction-based methods [15,19,21,36,37,43,47,49,54,62,69,71,79].\n\nDictionary-based methods learn the normal behavior by constructing a dictionary, where each entry in the dictionary represents a normal pattern. Ren et al. [55] extended dictionary learning methods by considering the relation among different entries. Change-detection frameworks detect anomalies by quantifying changes across the video frames, i.e. a significant deviation from the immediately preceding event marks the beginning of an abnormal event. After quantifying the change, approaches such as unmasking [26] or ordinal regression [48] can be used to segregate anomalies. Probability-based methods build upon the assumption that anomalies occur in a low probability region. These methods estimate the probability density function (PDF) of the normal data and evaluate the test samples based on the PDF. For example, Mahadevan et al. [44] used a Mixture of Dynamic Textures (MDTs) to model the distribution of the spatio-temporal domain, while Rudolph et al. [56] employed normalizing flow to represent the normal distribution. Distance-based methods learn a distance function based on the assumption that normal events occur in the close vicinity of the learned feature space, while the abnormal events are far apart from the normal data. For instance, Ramachandra et al. [51] employed a Siamese network to learn the distance function. Reconstruction-based methods rely on the assumption that the normal examples can be reconstructed more faithfully from the latent manifold. Our new block belongs to the category of reconstruction-based anomaly detection methods, particularly siding with meth-ods that predict or reconstruct missing (or masked) information [17,36,37].\n\nReconstruction-based methods. In the past few years, reconstruction-based methods became prevalent in anomaly detection. Such methods typically use auto-encoders [21] and generative adversarial networks (GANs) [37], as these neural models enable the learning of powerful reconstruction manifolds via using normal data only. However, the generalization capability of neural networks sometimes leads to reconstructing abnormal frames with low error [12,18], affecting the discrimination between abnormal and normal frames. To address this issue, researchers have tried to improve the latent manifold by diversifying the architecture and training methodologies. Some works focusing on transforming the architectures include memory-based autoencoders [12,39,49], which memorize the normal prototypes in the training data, thus increasing the discrimination between normal and abnormal samples. Other works remodeled the reconstruction manifold via training the models with pseudo-abnormal samples [4,18,79]. The adversarial training proposed in [17] applies gradient ascent for outof-domain pseudo-abnormal samples and gradient descent for normal data, thus learning a more powerful discriminative manifold for video anomaly detection. Zavrtanik et al. [79] created pseudo-abnormal samples by adding random noise patches on normal images for image anomaly detection. Some variants of auto-encoders, such as Variational Auto-Encoders (VAEs), have been proposed in [39,83] for the anomaly detection task. These works are based on the assumption that VAEs can only reconstruct the normal images. Liu et al. [39] used a conditional VAE, conditioning the image prediction on optical flow reconstruction, thus accumulating the error from the optical flow reconstruction task with the image prediction. However, this approach can only be applied to video anomaly detection, due to the presence of motion information in the form of optical flow.\n\nReconstruction of masked information. A surrogate task for many anomaly detection approaches [15,22,37,42,77] is to erase some information from the input, while making neural networks predict the erased information. Haselmann et al. [22] framed anomaly detection as an inpainting problem, where patches from images are masked randomly, using the pixel-wise reconstruction error of the masked patches for surface anomaly detection. Fei et al. [15] proposed the Attribute Restoration Network (ARNet), which includes an attribute erasing module (AEM) to disorient the model by erasing certain attributes from an image, such as color and orientation. In turn, ARNet learns to restore the original image and detect anomalies based on the assumption that normal images can be restored properly. The Cloze task [42] is about learning to complete a video when certain frames are removed, being recently employed by Yu et al. [77] for anomaly detection. In a similar direc-tion, Georgescu et al. [17] proposed middle frame masking as one of the auxiliary tasks for video anomaly detection. Both approaches are based on the assumption that an erased frame can be reconstructed more accurately for regular motion. Future frame prediction [34] utilizes past frames to predict the next frame in the video. The anomaly, in this case, is detected through the prediction error. Another approach based on GANs [59] learns to erase patches from an image, while the discriminator identifies if patches are normal or irregular.\n\nUnlike existing approaches, we are the first to introduce the reconstruction-based functionality as a basic building block for neural architectures. More specifically, we design a novel block based on masked convolution and channel attention to reconstruct a masked part of the convolutional receptive field. As shown in the experiments, our block can be integrated into a multitude of existing anomaly detection frameworks [18,34,37,39,49,79], almost always bringing significant performance improvements.\n\n\nMethod\n\nConvolutional neural networks (CNNs) [30,31] are widely used across a broad spectrum of computer vision tasks, also being prevalent in anomaly detection [18,20,34,39,49]. CNNs are formed of convolutional layers equipped with kernels which learn to activate on discriminative local patterns, in order to solve a desired task. The local features extracted by a convolutional layer are combined into more complex features by the subsequent convolutional layers. From this learning process, a hierarchy of features emerges, ranging from low-level features (corners, edges, etc.) to high-level features (car wheels, bird heads, etc.) [80]. While this hierarchy of features is extremely powerful, CNNs lack the ability to comprehend the global arrangement of such local features, as noted by Sabour et al. [60].\n\nIn this paper, we introduce a novel self-supervised predictive convolutional attentive block (SSPCAB) that is purposed at learning to predict (or reconstruct) masked information using contextual information. To achieve highly accurate reconstruction results, our block is forced to learn the global structure of the discovered local patterns. Thus, it addresses the issue pointed out in [60], namely the fact that CNNs do not grasp the global arrangement of local features, as they do not generalize to novel viewpoints or affine transformations. To implement this behavior, we design our block as a convolutional layer with dilated masked filters, followed by a channel attention module. The block is equipped with its own loss function, which is aimed at minimizing the reconstruction error between the masked input and the predicted output.\n\nWe underline that our design is generic, as SSPCAB can be integrated into just about any CNN architecture, being able to learn to reconstruct masked information, while offer- ing useful features for subsequent neural layers. Although the capability of learning and using global structure might make SSPCAB useful for a wide range of tasks, we conjecture that our block has a natural and direct applicability in anomaly detection, as explained next. When integrated into a CNN trained on normal training data, SSPCAB will learn the global structure of normal examples only. When presented with an abnormal data sample at inference time, our block will likely provide a poor reconstruction. We can thus measure the quality of the reconstruction and employ the result as a way to differentiate between normal and abnormal examples. In Section 4, we provide empirical evidence to support our claims. SSPCAB is composed of a masked convolutional layer activated by Rectified Linear Units (ReLU) [46], followed by a Squeeze-and-Excitation (SE) module [24]. We next present its components in more details. Masked convolution. The receptive field of our convolutional filter is depicted in Figure 2. The learnable parameters of our masked convolution are located in the corners of the receptive field, being denoted by the sub-kernels K i \u2208 R k \u00d7k \u00d7c , \u2200i \u2208 {1, 2, 3, 4}, where k \u2208 N + is a hyperparameter defining the sub-kernel size and c is the number of input channels. Each kernel K i is located at a distance (dilation rate) d \u2208 N + from the masked region in the center of our receptive field, which is denoted by M \u2208 R 1\u00d71\u00d7c . Consequently, the spatial size k of our receptive field can be computed as follows: k = 2k + 2d + 1.\n\nLet X \u2208 R h\u00d7w\u00d7c be the input tensor of our masked convolutional layer, where c is the number of channels, and h and w are the height and width, respectively. The convolutional operation performed with our custom kernel in a certain location of the input X only considers the input values from the positions where the sub-kernels K i are located, the other information being ignored. The results of the convolution operations between each K i and the corresponding inputs are summed into a single number, as if the sub-kernels K i belong to a single convolutional ker-nel. The resulting value denotes a prediction located at the same position as M . Naturally, applying the convolution with one filter produces a single activation map. Hence, we would only be able to predict one value from the masked vector M , at the current location. To predict a value for every channel in M , we introduce a number of c masked convolutional filters, each predicting the masked information from a distinct channel. As we aim to learn and predict the reconstruction for every spatial location of the input, we add zero-padding of k + d pixels around the input and set the stride to 1, such that every pixel in the input is used as masked information. Therefore, the spatial dimension of the output tensor Z is identical to that of the input tensor X. Finally, the output tensor is passed through a ReLU activation. We underline that the only configurable hyperparameters of our custom convolutional layer are k and d. Channel attention module. Next, the output of the masked convolution is processed by a channel attention module, which computes an attention score for each channel. Knowing that each activation map in Z is predicted by a separate filter in the presence of masked information, we infer that the masked convolution might end up producing activation maps containing disproportionate (uncalibrated) values across channels. Therefore, we aim to exploit the relationships between channels, with the goal of scaling each channel in Z in accordance with the quality of the representations produced by the masked convolutional layer. To this end, we employ the channel attention module proposed by Hu et al. [24]. The SE module [24] provides a mechanism that performs adaptive recalibration of channel-wise feature responses. Through this mechanism, it can learn to use global information to selectively emphasize or suppress reconstruction maps, as necessary. Another motivation to use attention is to increase the modeling capacity of SSP-CAB and enable a non-linear processing between the input and output of our block.\n\nFormally, the channel attention block reduces Z to a vector z \u2208 R c through a global pooling performed on each channel. Subsequently, the vector of scale factors s \u2208 R c is computed as follows:\ns = \u03c3 (W 2 \u00b7 \u03b4 (W 1 \u00b7 z)) ,(1)\nwhere \u03c3 is the sigmoid activation, \u03b4 is the ReLU activation, and W 1 \u2208 R c r \u00d7c and W 2 \u2208 R c\u00d7 c r represent the weight matrices of two consecutive fully connected (FC) layers, respectively. The first FC layer consists of c r neurons, squeezing the information by a reduction ratio of r.\n\nNext, the vector s is replicated in the spatial dimension, generating a tensor S of the same size as Z. Our last step is the element-wise multiplication between S and Z, producing the final tensorX \u2208 R h\u00d7w\u00d7c containing recalibrated features maps. Reconstruction loss. We add a self-supervised task consist-ing of reconstructing the masked region inside our convolutional receptive field, for every location where the masked filters are applied. To this end, our block should learn to provide the corresponding reconstructions as the outputX. Let G denote the SSPCAB function. We define the selfsupervised reconstruction loss as the mean squared error (MSE) between the input and the output, as follows:\nL SSPCAB (G, X) = (G(X) \u2212 X) 2 = X \u2212 X 2 .(2)\nWhen integrating SSPCAB into a neural model F having its own loss function L F , our loss can simply be added to the respective loss, resulting in a new loss function that comprises both terms:\nL total = L F + \u03bb \u00b7 L SSPCAB ,(3)\nwhere \u03bb \u2208 R + is a hyperparameter that controls the importance of our loss with respect to L F . We adopt this procedure when incorporating SSPCAB into various neural architectures during our experiments. \n\n\nExperiments and Results\n\n\nEvaluation Metrics\n\nImage anomaly detection. On MVTec AD, we evaluate methods in terms of the average precision (AP) and the area under the receiver operating characteristic curve (AUROC). The ROC curve is obtained by plotting the true positive rate (TPR) versus the false positive rate (FPR). We consider both localization and detection performance rates. For the detection task, the TPR and FPR values are computed at the image level, i.e. TPR is the percentage of anomalous images that are correctly classified, while FPR is the percentage of normal images mistakenly classified as anomalous.\n\nFor the localization (segmentation) task, TPR is the percentage of abnormal pixels that are correctly classified, whereas FPR is the percentage of normal pixels wrongly classified as anomalous. To determine the segmentation threshold for each method, we follow the approach described in [5]. Video anomaly detection. We evaluate abnormal event detection methods in terms of the area under the curve (AUC), which is computed by marking a frame as abnormal if at least one pixel inside the frame is abnormal. Following [18], we report both the macro and micro AUC scores. The micro AUC is computed after concatenating all frames from the entire test set, while the macro AUC is the average of the AUC scores on individual videos. The frame-level AUC can be an unreliable evaluation measure, as it may fail to evaluate the localization of anomalies [50]. Therefore, we also evaluate models in terms of the region-based detection criterion (RBDC) and track-based detection criterion (TBDC), as proposed by Ramachandra et al. [50]. RBDC takes each detected region into consideration, marking a detected region as true positive if the Intersection-over-Union with the ground-truth region is greater than a threshold \u03b1. TBDC measures whether abnormal regions are accurately tracked across time. It considers a detected track as true positive if the number of detections in a track is greater than a threshold \u03b2. Following [18,50], we set \u03b1 = 0.1 and \u03b2 = 0.1.\n\n\nImplementation Choices and Tuning\n\nFor the methods [18,34,37,39,49,79] chosen to serve as underlying models for SSPCAB, we use the official code from the repositories provided by the corresponding authors, inheriting the hyperparameters, e.g. the number of epochs and learning rate, from each method. Unless specified otherwise, we replace the penultimate convolutional layer with SSPCAB in all underlying models.\n\nIn a set of preliminary trials with a basic auto-encoder on Avenue, we tuned the hyperparameter \u03bb from Eq. (3), representing the weight of the SSPCAB reconstruction error, considering values between 0.1 and 1, at a step of 0.1. Based on these preliminary trials, we decided to use \u03bb = 0.1 across all models and data sets. However, we observed that \u03bb = 0.1 gives a higher than necessary magnitude to our loss for the framework of Liu et al. [39]. Hence, for Liu et al. [39], we reduced \u03bb to 0.01.\n\n\nPreliminary Results\n\nWe performed preliminary experiments on Avenue to decide the hyperparameters of our masked convolution, i.e. the kernel size k and dilation rate d. We consider values in {1, 2, 3} for k , and values in {0, 1, 2} for d. In addition, we consider two alternative loss functions, namely the Mean Absolute Error (MAE) and Mean Squared Error (MSE), and several types of attention to be added after the masked convolution, namely channel attention (CA), spatial \n\n\nattention (SA), and both (CA+SA).\n\nFor the preliminary experiments, we take the appearance convolutional auto-encoder from [18] as our baseline, stripping out the additional components such as optical flow, skip connections, adversarial training, mask reconstruction and binary classifiers. Our aim is to test various SSPCAB configurations on top of a basic architecture, without trying to overfit the configuration to a specific framework, such as that of Georgescu et al. [18]. To this end, we decided to remove the aforementioned components, thus using only a plain auto-encoder in our preliminary experiments.\n\nThe preliminary results are presented in Table 1. Upon adding the masked convolutional layer based on the MAE loss on top of the basic architecture, we observe significant performance gains, especially for k = 1 and d = 1. The performance further increases when we replace the MAE loss function with MSE. We performed extensive experiments with different combinations of k and d, obtaining better results with k = 1 and d = 1. We therefore decided to fix the loss to MSE, the sub-kernel size k to 1, and the dilation rate d to 1, for all subsequent experiments. Next, we introduced various attention modules after our masked convolution. Among the considered attention modules, we observe that channel attention is the one that better compliments our masked convolutional layer, providing the highest performance gains for three of the metrics: 5.9% for the micro AUC, 2.2% for the macro AUC, and 4.6% for TBDC. Accordingly, we selected the channel attention module for the remaining experiments. Upon choosing to use channel attention, we test additional reduction rates (r = 4 and r = 16), without observing any improvements. As such, we keep the reduction rate of the SE module to r = 8, whenever we integrate SSPCAB into a neural model.\n\n\nAnomaly Detection in Images\n\nBaselines. We choose two recent models for image anomaly detection, i.e. CutPaste [34] and DRAEM [79].\n\nLi et al. [34] proposed CutPaste, a simple data augmentation technique that cuts a patch from an image and pastes it to a random location. The CutPaste architecture is built on top of GradCAM [64]. The model is based on a selfsupervised 3-way classification task, learning to classify samples into normal, CutPaste and CutPaste-Scar, where a scar is a long and thin mark of a random color. Li et al. [34] also used an ensemble of five 3-way CutPaste models trained with different random seeds to improve results.\n\nZavrtanik et al. [79] introduced DRAEM, a method based on a dual auto-encoder for anomaly detection and localization on MVTec AD. We introduce SSPCAB into both the localization and detection networks. Results. We present the results on MVTec AD in Table 2. Considering the detection results, we observe that SSPCAB brings consistent performance improvements on most categories for both CutPaste [34] and DRAEM [79]. Moreover, the overall performance gains in terms of detection AUROC are close to 1%, regardless of the underlying model. Given that the baselines are already very good, we consider the improvements brought by SSPCAB as noteworthy.\n\nConsidering the localization results, it seems that SSP-CAB is not able to improve the overall AUROC score of DRAEM [79]. However, the more challenging AP metric tells a different story. Indeed, SSPCAB increases the overall AP of DRAEM [79] by 1.5%, from 68.4% to 69.9%.\n\nIn Figure 3, we illustrate a few anomaly localization examples where SSPCAB introduces significant changes to the anomaly localization contours of DRAEM [79], showing a higher overlap with the ground-truth anomalies. We believe that these improvements are a direct effect induced  \n\n\nAbnormal Event Detection in Video\n\nBaselines. We choose four recently introduced methods [18,37,39,49] attaining state-of-the-art performance levels in video anomaly detection, as candidates for integrating SSPCAB. We first reproduce the results using the official implementations provided by the corresponding authors [18,37,39,49]. We refrain from making any modifi-cation to the hyperparameters of the chosen baselines. Despite using the unmodified code from the official repositories, we were not able to exactly reproduce the results of Liu et al. [39] and Park et al. [49], but our numbers are very close. As we add SSPCAB into the reproduced models, we consider the reproduced results as reference. We underline that, for Georgescu et al. [18], we integrate SSPCAB into the auto-encoders, not in the binary classifiers. We report RBDC and TBDC results whenever possible, computing the scores using the implementation provided by Georgescu et al. [18].\n\nResults. We report the results on Avenue and ShanghaiTech in Table 3. First, we observe that the inclusion of SSPCAB in the framework of Liu et al. [37] brings consistent improvements over all metrics on both benchmarks. Similarly, we observe consistent performance gains when integrating SSPCAB into the model of Park et al. [49]. We note that the method of Park et al. [49] does not produce anomaly localization results, preventing us from computing the RBDC and TBDC scores for their method. SSPCAB also brings consistent improvements for Liu et al. [39], the only exception being the macro AUC on Avenue. For this baseline [39], we observe a remarkable increase of 21.22% in terms of the RBDC score on Avenue. Finally, we notice that SSPCAB also improves the performance of the approach proposed by Georgescu et al. [18] for almost all metrics, the exceptions being the TBDC on Avenue and RBDC on ShanghaiTech. In summary, we conclude that integrating SSPCAB is beneficial, regardless of the underlying model. Moreover, due to the integration of SSPCAB, we are able  Table 3. Micro-averaged frame-level AUC, macro-averaged frame-level AUC, RBDC, and TBDC scores (in %) of various state-of-the-art methods on Avenue and ShanghaiTech. Among the existing models, we select four models [18,37,39,49] to show results before and after including SSPCAB. The best result for each before-versus-after pair is highlighted in bold. The top score for each metric is shown in red.\n\nto report new state-of-the-art results on Avenue and Shang-haiTech, for several metrics.\n\nIn Figure 4, we compare the frame-level anomaly scores on test video 18 from Avenue, before and after integrating SSPCAB into the method of Liu et al. [37]. On this video, SSPCAB increases the AUC by more than 5%. We observe that the approach based on SSPCAB can precisely localize and detect the abnormal event (person walking in the wrong direction). We provide more anomaly detection examples in the supplementary.\n\n\nConclusion\n\nIn this paper, we introduced SSPCAB, a novel neural block composed of a masked convolutional layer and a channel attention module, which predicts a masked region in the convolutional receptive field. Our neural block is trained in a self-supervised manner, via a reconstruction loss of its own. To show the benefit of using SSP-CAB in anomaly detection, we integrated our block into a series of image and video anomaly detection methods [18,34,37,39,49,79]. Our empirical results indicate that SSPCAB brings performance improvements in almost all cases. The preliminary results show that both the masked convolution and the channel attention contribute to the performance gains. Furthermore, with the help of SSPCAB, we are able to obtain new state-of-the-art levels on Avenue and ShanghaiTech. We consider this as a major achievement.\n\nIn future work, we aim to extend SSPCAB by replacing the masked convolution with a masked 3D convolution. In addition, we aim to consider other application domains besides anomaly detection.  Table 5. Micro-averaged frame-level AUC, macro-averaged frame-level AUC, RBDC, and TBDC scores (in %) on Avenue, while varying the size of the masked kernel M .\n\n\nSupplementary\n\n\nAblation Study\n\nIn the main article, we mention that we generally replace the penultimate convolutional layer with SSPCAB in underlying models [18,34,37,39,49,79]. Ideally, for optimal performance gains, the integration place and the number of SSPCAB modules should be tuned on a validation set for each framework. However, anomaly detection data sets do not have a validation set and there is no way to obtain one from the training set, as the training contains only normal examples. In this context, to fairly demonstrate the generality and utility of SSPCAB, we only used a single configuration (one block, closer to the output) across all existing frameworks. However, adding more modules could be beneficial. To test various configurations, we perform an ablation study on the number of SSPCAB modules and the places where these modules can be integrated in a plain auto-encoder. In Table 4, we present the corresponding experiments on the Avenue data set. We observe that SSPCAB improves the results, regardless of the place of integration or the number of blocks. The improvements seem larger when SSPCAB is integrated closer to the output. Integrating more blocks can sometimes help.\n\nAnother hyperparameter that could be tuned is the size of the masked kernel M . In our experiments, we kept M to a size of 1 \u00d7 1 for simplicity and speed. To study the effect of increasing the size of M , we have tested the size of 3 \u00d7 3 with the plain auto-encoder on Avenue. We report the corresponding results in Table 5. When comparing the results with masked kernels of 1 \u00d7 1 or 3 \u00d7 3 components, we do not observe significant differences.\n\nAn additional aspect that can suffer multiple reconfigurations, given a validation set, is the pattern of the proposed kernel. In our experiments, we tried a simple pattern where the mask is placed in the center and the reception field is connected to the four corner sub-kernels denoted by K i , \u2200i \u2208 {1, 2, 3, 4}. We designed this pattern while trying to extrapolate the idea from middle frame prediction (which was shown to provide somewhat better results than future frame prediction) to a 2D kernel. Of course, other patterns are possible and are likely to work equally well.\n\n\nQualitative Anomaly Detection Results\n\nAnomaly detection in images. In Figure 5, we present additional qualitative results produced by DRAEM [79] on the MVTec AD benchmark. The displayed examples illustrate the benefit of integrating SSPCAB, which is much better at segmenting the anomalies compared to the baseline DRAEM. We show improvements in terms of the pixellevel annotation for both objects and textures. Anomaly detection in videos. In Figure 6, we show a com-  parison of the frame-level anomaly scores on test video 10 from the Avenue data set, before and after integrating SSP-CAB into the method of Liu et al. [37]. On this video, SSP-CAB increases the AUC by nearly 4%. After introducing SSPCAB, we observe higher frame-level anomaly scores for the first abnormal event. The anomaly localization results depict a person throwing a backpack and a person walking in the wrong direction.\n\nIn Figures 7 and 8, we illustrate similar comparisons for test videos 01 0054 and 01 0130 from the ShanghaiTech  data set, before and after adding SSPCAB into the framework of Georgescu et al. [18]. For test video 01 0054, SSP-CAB increases the AUC by more than 10%. For test video 01 0130, the baseline framework seems to detect the abnormal event too early, but SSPCAB seems capable of shifting the detection towards the correct moment. As a result, SSP-CAB increases the frame-level AUC score by almost 6%. We observe a similar AUC improvement from SSPCAB in Figure 9, where we compare the frame-level anomaly scores on test video 07 0047 from the ShanghaiTech data set. For Method Time (ms) Relative (%) Baseline +SSPCAB Liu et al. [37] 2.1 2.4 14.2 Georgescu et al. [18] 1.5 1.7 13.3 Table 6. Inference times (in milliseconds) and relative time expansions (in %) for two frameworks [18,37], before and after integrating SSPCAB. The running times are measured on an Nvidia GeForce GTX 3090 GPU with 24 GB of VRAM.\n\nthis video, we underline that the frame-level scores are visibly more correlated to the ground-truth anomalies. Moreover, in all three ShanghaiTech videos, we observe that the approach based on SSPCAB can precisely localize and detect the abnormal events (person pulling a lever cart, car inside pedestrian area, people fighting, people running).\n\n\nInference Time\n\nRegardless of the underlying framework [18,34,37,39,49,79], we add only one instance of SSPCAB, usually replacing the penultimate convolutional layer. As such, we expect the running time to increase. To assess the amount of extra time added by SSPCAB, we present the running times before and after integrating SSPCAB into two state-of-theart frameworks [18,37] in Table 6. The reported times show time expansions lower than 0.3 ms for both frameworks. Hence, we consider that the accuracy gains brought by SSP-CAB outweigh the marginal running time expansions observed in Table 6.\n\n\nDiscussion\n\nAlthough SSPCAB belongs to an existing family of anomaly detection methods, i.e. reconstruction-based frameworks [15,19,21,36,37,43,47,49,54,62,69,71], we would like to underline that we are the first to integrate the reconstruction functionality at the block level. Unlike other reconstruction approaches, our contribution is more flexible, as it can be integrated in existing and future reconstruction methods. Moreover, SSPCAB can also be used to introduce reconstruction-based anomaly detection in other frameworks, which do not rely on reconstruction. We thus believe that our generic and effective approach will help ease future research in anomaly detection.\n\nAn important aspect that must be noted is that, due to the masked convolution, our block will not reconstruct the input exactly. Except for the degenerate case where the input is constant, this scenario should not occur in the real world, which means that the reconstruction performed by SSPCAB is not trivial. However, our foremost intuition about the usefulness of SSPCAB is different: our block provides a better reconstruction for normal convolutional features than for abnormal convolutional features. If the features representing normal versus abnormal examples are different at any layer of a neural architecture, it should result in greater differences at the final output of the architecture. This idea is also supported by the experiments presented in Table 4.\n\nFurther looking at the results shown in Table 4, we observe that SSPCAB does not bring significant gains when the block is placed near the input. We aim to further investigate this limitation in future work. Aside from this small issue, we did not observe other limitations of SSPCAB during our experiments.\n\nFigure 1 .\n1Our self-supervised predictive convolutional attentive block (SSPCAB).\n\nFigure 2 .\n2Our masked convolutional kernel. The visible area of the receptive field is denoted by the regions Ki, \u2200i \u2208 {1, 2, 3, 4}, while the masked area is denoted by M . A dilation factor d controls the local or global nature of the visible information with respect to M . Best viewed in color.\n\nFigure 3 .\n3Anomaly localization examples of DRAEM[79] (blue) versus DRAEM+SSPCAB (green) on MVTec AD. The groundtruth anomalies are marked with a red mask. Best viewed in color.\n\nFigure 4 .\n4Frame-level anomaly scores for Liu et al. [37] before (baseline) and after (ours) integrating SSPCAB, for test video 18 from Avenue. Anomaly localization results correspond to the model based on SSPCAB. Best viewed in color.by the reconstruction errors produced by our novel block. We provide more anomaly detection examples in the supplementary.\n\nFigure 5 .\n5Additional anomaly localization examples of DRAEM [79] (blue) versus DRAEM+SSPCAB (green) on MVTec AD. The ground-truth anomalies are marked with a red mask. Best viewed in color.\n\nFigure 6 .\n6Frame-level anomaly scores for Liu et al.[37] before (baseline) and after (ours) integrating SSPCAB, for test video 10 from Avenue. Anomaly localization results correspond to the model based on SSPCAB. Best viewed in color.\n\nFigure 7 .\n7Frame-level anomaly scores for Georgescu et al.[18] before (baseline) and after (ours) integrating SSPCAB, for test video 01 0054 from ShanghaiTech. Anomaly localization results correspond to the model based on SSPCAB. Best viewed in color.\n\nFigure 8 .\n8Frame-level anomaly scores for Georgescu et al.[18] before (baseline) and after (ours) integrating SSPCAB, for test video 01 0130 from ShanghaiTech. Anomaly localization results correspond to the model based on SSPCAB. Best viewed in color.\n\nFigure 9 .\n9Frame-level anomaly scores for Georgescu et al.[18] before (baseline) and after (ours) integrating SSPCAB, for test video 07 0047 from ShanghaiTech. Anomaly localization results correspond to the model based on SSPCAB. Best viewed in color.\n\n\nloss type, and attention type, for our SSPCAB. Results are obtained by introducing SSPCAB into a plain auto-encoder that follows the basic architecture designed by Georgescu et al.[18]. Best results are highlighted in bold.Method \n\nLoss d k r \nAttention \nAUC \nRBDC TBDC \ntype \ntype \nMicro Macro \n\nPlain auto-encoder \n\n-\n---\n-\n80.0 83.4 49.98 51.69 \n\nMAE \n\n0 1 -\n-\n83.3 84.1 47.46 52.11 \n1 1 -\n-\n83.9 84.6 49.05 52.21 \n2 1 -\n-\n83.2 84.3 48.56 52.03 \n\nMSE \n\n0 1 -\n-\n83.6 84.2 47.86 52.21 \n1 1 -\n-\n84.2 84.9 49.22 52.29 \n2 1 -\n-\n83.6 84.3 48.44 51.98 \n\nMSE \n\n0 2 -\n-\n83.7 84.0 47.41 53.02 \n1 2 -\n-\n84.0 85.1 48.22 51.84 \n2 2 -\n-\n82.7 83.1 46.94 50.22 \n\nMSE \n\n0 3 -\n-\n82.6 83.7 48.28 51.91 \n1 3 -\n-\n82.9 84.7 48.13 52.07 \n2 3 -\n-\n83.1 83.8 47.13 49.96 \n\nMSE \n\n1 1 8 \nCA \n85.9 85.6 53.81 56.33 \n1 1 -\nSA \n84.3 84.4 53.31 53.41 \n1 1 8 CA+SA 85.7 85.6 53.98 54.11 \n\nMSE \n1 1 4 \nCA \n85.6 85.3 53.83 55.99 \n1 1 16 \nCA \n84.4 84.9 53.28 54.37 \n\nTable 1. Micro AUC, macro AUC, RBDC and TBDC scores (in \n%) obtained on the Avenue data set with different hyperparameter \nconfigurations, i.e. kernel size (k ), dilation rate (d), reduction ra-\ntio (r), \nAcknowledgmentsThe research leading to these results has received funding from the EEA Grants 2014-2021, under Project contract no. EEA-RO-NO-2018-0496. This work has also been funded by the Milestone Research Programme at AAU, SecurifAI, and the Romanian Young Academy, which is funded by Stiftung Mercator and the Alexander von Humboldt Foundation for the period 2020-2022.\nRobust Real-Time Unusual Event Detection Using Multiple Fixed-Location Monitors. Amit Adam, Ehud Rivlin, Ilan Shimshoni, Daviv Reinitz, IEEE Transactions on Pattern Analysis and Machine Intelligence. 303Amit Adam, Ehud Rivlin, Ilan Shimshoni, and Daviv Reinitz. Robust Real-Time Unusual Event Detection Using Multiple Fixed-Location Monitors. IEEE Transactions on Pattern Analysis and Machine Intelligence, 30(3):555-560, 2008. 1, 2\n\nVideo parsing for abnormality detection. Borislav Antic, Bjorn Ommer, Proceedings of ICCV. ICCV1Borislav Antic and Bjorn Ommer. Video parsing for abnor- mality detection. In Proceedings of ICCV, pages 2415-2422, 2011. 1, 2\n\nLearning not to reconstruct anomalies. Marcella Astrid, Muhammad Zaigham Zaheer, Jae-Yeong Lee, Seung-Ik Lee, Proceedings of BMVC. BMVCMarcella Astrid, Muhammad Zaigham Zaheer, Jae-Yeong Lee, and Seung-Ik Lee. Learning not to reconstruct anoma- lies. In Proceedings of BMVC, 2021. 8\n\nSynthetic Temporal Anomaly Guided End-to-End Video Anomaly Detection. Marcella Astrid, Muhammad Zaigham Zaheer, Seung-Ik Lee, Proceedings of ICCVW. ICCVW3Marcella Astrid, Muhammad Zaigham Zaheer, and Seung- Ik Lee. Synthetic Temporal Anomaly Guided End-to-End Video Anomaly Detection. In Proceedings of ICCVW, pages 207-214, 2021. 3, 8\n\nMVTec AD -A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection. Paul Bergmann, Michael Fauser, David Sattlegger, Carsten Steger, Proceedings of CVPR. CVPRPaul Bergmann, Michael Fauser, David Sattlegger, and Carsten Steger. MVTec AD -A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection. In Proceed- ings of CVPR, pages 9592-9600, 2019. 1, 2, 5\n\nUninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings. Paul Bergmann, Michael Fauser, David Sattlegger, Carsten Steger, Proceedings of CVPR. CVPR1Paul Bergmann, Michael Fauser, David Sattlegger, and Carsten Steger. Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embed- dings. In Proceedings of CVPR, pages 4183-4192, 2020. 1, 2\n\nDefect Detection in SEM Images of Nanofibrous Materials. Diego Carrera, Fabio Manganini, Giacomo Boracchi, Ettore Lanzarone, IEEE Transactions on Industrial Informatics. 132Diego Carrera, Fabio Manganini, Giacomo Boracchi, and Et- tore Lanzarone. Defect Detection in SEM Images of Nanofi- brous Materials. IEEE Transactions on Industrial Informat- ics, 13(2):551-561, 2017. 1, 2\n\nVideo anomaly detection and localization using hierarchical feature representation and Gaussian process regression. Kai-Wen Cheng, Yie-Tarng Chen, Wen-Hsien Fang, Proceedings of CVPR. CVPR1Kai-Wen Cheng, Yie-Tarng Chen, and Wen-Hsien Fang. Video anomaly detection and localization using hierarchical feature representation and Gaussian process regression. In Proceedings of CVPR, pages 2909-2917, 2015. 1, 2\n\nSparse reconstruction cost for abnormal event detection. Y Cong, J Yuan, J Liu, Proceedings of CVPR. CVPR1Y. Cong, J. Yuan, and J. Liu. Sparse reconstruction cost for abnormal event detection. In Proceedings of CVPR, pages 3449-3456, 2011. 1, 2\n\nPaDiM: A patch distribution modeling framework for anomaly detection and localization. Thomas Defard, Aleksandr Setkov, Angelique Loesch, Romaric Audigier, Proceedings of ICPR. ICPR1Thomas Defard, Aleksandr Setkov, Angelique Loesch, and Romaric Audigier. PaDiM: A patch distribution modeling framework for anomaly detection and localization. In Pro- ceedings of ICPR, pages 475-489, 2021. 1, 2\n\nA Discriminative Framework for Anomaly Detection in Large Videos. Allison Del Giorno, J Andrew Bagnell, Martial Hebert, Proceedings of ECCV. ECCV1Allison Del Giorno, J. Andrew Bagnell, and Martial Hebert. A Discriminative Framework for Anomaly Detection in Large Videos. In Proceedings of ECCV, pages 334-349, 2016. 1, 2\n\nDual Discriminator Generative Adversarial Network for Video Anomaly Detection. Fei Dong, Yu Zhang, Xiushan Nie, IEEE Access. 8Fei Dong, Yu Zhang, and Xiushan Nie. Dual Discriminator Generative Adversarial Network for Video Anomaly Detec- tion. IEEE Access, 8:88170-88176, 2020. 1, 3, 8\n\nAny-Shot Sequential Anomaly Detection in Surveillance Videos. Keval Doshi, Yasin Yilmaz, Proceedings of CVPRW. CVPRW1Keval Doshi and Yasin Yilmaz. Any-Shot Sequential Anomaly Detection in Surveillance Videos. In Proceedings of CVPRW, pages 934-935, 2020. 1, 8\n\nOnline Detection of Abnormal Events Using Incremental Coding Length. K Jayanta, Bonny Dutta, Banerjee, Proceedings of AAAI. AAAI1Jayanta K. Dutta and Bonny Banerjee. Online Detection of Abnormal Events Using Incremental Coding Length. In Pro- ceedings of AAAI, pages 3755-3761, 2015. 1, 2\n\nAttribute Restoration Framework for Anomaly Detection. Ye Fei, Chaoqin Huang, Cao Jinkun, Maosen Li, Ya Zhang, Cewu Lu, IEEE Transactions on Multimedia. 14Ye Fei, Chaoqin Huang, Cao Jinkun, Maosen Li, Ya Zhang, and Cewu Lu. Attribute Restoration Framework for Anomaly Detection. IEEE Transactions on Multimedia, pages 1-1, 2020. 1, 2, 3, 14\n\nLearning deep event models for crowd anomaly detection. Yachuang Feng, Yuan Yuan, Xiaoqiang Lu, Neurocomputing. 2192Yachuang Feng, Yuan Yuan, and Xiaoqiang Lu. Learning deep event models for crowd anomaly detection. Neurocom- puting, 219:548-556, 2017. 1, 2\n\nAnomaly Detection in Video via Self-Supervised and Multi-Task Learning. Mariana-Iuliana Georgescu, Antonio Barbalau, Tudor Radu, Fahad Ionescu, Marius Shahbaz Khan, Mubarak Popescu, Shah, Proceedings of CVPR. CVPRMariana-Iuliana Georgescu, Antonio Barbalau, Radu Tu- dor Ionescu, Fahad Shahbaz Khan, Marius Popescu, and Mubarak Shah. Anomaly Detection in Video via Self- Supervised and Multi-Task Learning. In Proceedings of CVPR, pages 12742-12752, 2021. 1, 2, 3, 8\n\nA Background-Agnostic Framework with Adversarial Training for Abnormal Event Detection in Video. Mariana Iuliana Georgescu, Radu Ionescu, Marius Fahad Shahbaz Khan, Mubarak Popescu, Shah, IEEE Transactions on Pattern Analysis and Machine Intelligence. 1314Mariana Iuliana Georgescu, Radu Ionescu, Fahad Shahbaz Khan, Marius Popescu, and Mubarak Shah. A Background- Agnostic Framework with Adversarial Training for Abnor- mal Event Detection in Video. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021. 1, 2, 3, 5, 6, 7, 8, 12, 13, 14\n\nMoussa Reda Mansour, Svetha Venkatesh, and Anton Van Den Hengel. Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection. Dong Gong, Lingqiao Liu, Vuong Le, Budhaditya Saha, Proceedings of ICCV. ICCV14Dong Gong, Lingqiao Liu, Vuong Le, Budhaditya Saha, Moussa Reda Mansour, Svetha Venkatesh, and Anton Van Den Hengel. Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection. In Proceedings of ICCV, pages 1705- 1714, 2019. 1, 2, 14\n\nXin Guo, Zhongming Jin, Chong Chen, Helei Nie, Jianqiang Huang, Deng Cai, arXiv:2104.14430Xiaofei He, and Xiansheng Hua. Discriminative-Generative Dual Memory Video Anomaly Detection. arXiv preprintXin Guo, Zhongming Jin, Chong Chen, Helei Nie, Jian- qiang Huang, Deng Cai, Xiaofei He, and Xiansheng Hua. Discriminative-Generative Dual Memory Video Anomaly Detection. arXiv preprint arXiv:2104.14430, 2021. 3\n\nLearning temporal regularity in video sequences. Mahmudul Hasan, Jonghyun Choi, Jan Neumann, K Amit, Larry S Roy-Chowdhury, Davis, Proceedings of CVPR. CVPR14Mahmudul Hasan, Jonghyun Choi, Jan Neumann, Amit K. Roy-Chowdhury, and Larry S. Davis. Learning temporal reg- ularity in video sequences. In Proceedings of CVPR, pages 733-742, 2016. 1, 2, 3, 14\n\nAnomaly detection using deep learning based image completion. Matthias Haselmann, Dieter P Gruber, Paul Tabatabai, Proceedings of ICMLA. ICMLAMatthias Haselmann, Dieter P. Gruber, and Paul Tabatabai. Anomaly detection using deep learning based image com- pletion. Proceedings of ICMLA, pages 1237-1242, 2018. 3\n\nJoint Detection and Recounting of Abnormal Events by Learning Deep Generic Knowledge. Ryota Hinami, Tao Mei, Shin&apos;ichi Satoh, Proceedings of ICCV. ICCV1Ryota Hinami, Tao Mei, and Shin'ichi Satoh. Joint Detec- tion and Recounting of Abnormal Events by Learning Deep Generic Knowledge. In Proceedings of ICCV, pages 3639- 3647, 2017. 1, 2\n\nSqueeze-and-Excitation Networks. Jie Hu, Li Shen, Gang Sun, Proceedings of CVPR. CVPR14Jie Hu, Li Shen, and Gang Sun. Squeeze-and-Excitation Net- works. In Proceedings of CVPR, pages 7132-7141, 2018. 1, 4\n\nObject-Centric Auto-Encoders and Dummy Anomalies for Abnormal Event Detection in Video. Fahad Radu Tudor Ionescu, Mariana-Iuliana Shahbaz Khan, Ling Georgescu, Shao, Proceedings of CVPR. CVPRRadu Tudor Ionescu, Fahad Shahbaz Khan, Mariana-Iuliana Georgescu, and Ling Shao. Object-Centric Auto-Encoders and Dummy Anomalies for Abnormal Event Detection in Video. In Proceedings of CVPR, pages 7842-7851, 2019. 1, 2, 8\n\nUnmasking the abnormal events in video. Sorina Radu Tudor Ionescu, Bogdan Smeureanu, Marius Alexe, Popescu, Proceedings of ICCV. ICCV1Radu Tudor Ionescu, Sorina Smeureanu, Bogdan Alexe, and Marius Popescu. Unmasking the abnormal events in video. In Proceedings of ICCV, pages 2895-2903, 2017. 1, 2\n\nDetecting abnormal events in video using Narrowed Normality Clusters. Sorina Radu Tudor Ionescu, Marius Smeureanu, Bogdan Popescu, Alexe, Proceedings of WACV. WACVRadu Tudor Ionescu, Sorina Smeureanu, Marius Popescu, and Bogdan Alexe. Detecting abnormal events in video us- ing Narrowed Normality Clusters. In Proceedings of WACV, pages 1951-1960, 2019. 1, 2, 8\n\nTAM-Net: Temporal Enhanced Appearance-to-Motion Generative Network for Video Anomaly Detection. Xiangli Ji, Bairong Li, Yuesheng Zhu, Proceedings of IJCNN. IJCNNXiangli Ji, Bairong Li, and Yuesheng Zhu. TAM-Net: Tem- poral Enhanced Appearance-to-Motion Generative Network for Video Anomaly Detection. In Proceedings of IJCNN, pages 1-8, 2020. 1\n\nObserve locally, infer globally: A space-time MRF for detecting abnormal activities with incremental updates. Jaechul Kim, Kristen Grauman, Proceedings of CVPR. CVPR1Jaechul Kim and Kristen Grauman. Observe locally, infer globally: A space-time MRF for detecting abnormal activ- ities with incremental updates. In Proceedings of CVPR, pages 2921-2928, 2009. 1, 2\n\nImageNet Classification with Deep Convolutional Neural Networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Proceedings of NIPS. NIPSAlex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. ImageNet Classification with Deep Convolutional Neural Networks. In Proceedings of NIPS, pages 1106-1114, 2012. 3\n\nGradient-based learning applied to document recognition. Yann Lecun, Leon Bottou, Yoshua Bengio, Pattrick Haffner, Proceedings of the IEEE. the IEEE86Yann LeCun, Leon Bottou, Yoshua Bengio, and Pattrick Haffner. Gradient-based learning applied to document recog- nition. Proceedings of the IEEE, 86(11):2278-2324, 1998. 3\n\nSTAN: Spatio-temporal adversarial networks for abnormal event detection. Sangmin Lee, Yong Man Hak Gu Kim, Ro, Proceedings of ICASSP. ICASSPSangmin Lee, Hak Gu Kim, and Yong Man Ro. STAN: Spatio-temporal adversarial networks for abnormal event de- tection. In Proceedings of ICASSP, pages 1323-1327, 2018. 8\n\nBMAN: Bidirectional Multi-Scale Aggregation Networks for Abnormal Event Detection. Sangmin Lee, Yong Man Hak Gu Kim, Ro, IEEE Transactions on Image Processing. 298Sangmin Lee, Hak Gu Kim, and Yong Man Ro. BMAN: Bidirectional Multi-Scale Aggregation Networks for Abnor- mal Event Detection. IEEE Transactions on Image Process- ing, 29:2395-2408, 2019. 1, 8\n\nCutPaste: Self-Supervised Learning for Anomaly Detection and Localization. Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, Tomas Pfister, Proceedings of CVPR. CVPR1214Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, and Tomas Pfister. CutPaste: Self-Supervised Learning for Anomaly Detection and Localization. In Proceedings of CVPR, pages 9664-9674, 2021. 2, 3, 5, 6, 7, 8, 12, 14\n\nAnomaly detection and localization in crowded scenes. Weixin Li, Vijay Mahadevan, Nuno Vasconcelos, IEEE Transactions on Pattern Analysis and Machine Intelligence. 361Weixin Li, Vijay Mahadevan, and Nuno Vasconcelos. Anomaly detection and localization in crowded scenes. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(1):18-32, 2014. 1\n\nSuperpixel Masking and Inpainting for Self-Supervised Anomaly Detection. Zhenyu Li, Ning Li, Kaitao Jiang, Zhiheng Ma, Xing Wei, Xiaopeng Hong, Yihong Gong, Proceedings of BMVC. BMVC14Zhenyu Li, Ning Li, Kaitao Jiang, Zhiheng Ma, Xing Wei, Xiaopeng Hong, and Yihong Gong. Superpixel Masking and Inpainting for Self-Supervised Anomaly Detection. In Pro- ceedings of BMVC, 2020. 1, 2, 3, 14\n\nFuture Frame Prediction for Anomaly Detection -A New Baseline. Wen Liu, Weixin Luo, Dongze Lian, Shenghua Gao, Proceedings of CVPR. CVPR1314Wen Liu, Weixin Luo, Dongze Lian, and Shenghua Gao. Fu- ture Frame Prediction for Anomaly Detection -A New Base- line. In Proceedings of CVPR, pages 6536-6545, 2018. 1, 2, 3, 5, 7, 8, 12, 13, 14\n\nClassifier Two-Sample Test for Video Anomaly Detections. Yusha Liu, Chun-Liang Li, Barnaba\u00e1s P\u00f3czos, Proceedings of BMVC. BMVCYusha Liu, Chun-Liang Li, and Barnaba\u00e1s P\u00f3czos. Clas- sifier Two-Sample Test for Video Anomaly Detections. In Proceedings of BMVC, 2018. 1, 2, 8\n\nA Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow-Guided Frame Prediction. Zhian Liu, Yongwei Nie, Chengjiang Long, Qing Zhang, Guiqing Li, Proceedings of ICCV. ICCV1214Zhian Liu, Yongwei Nie, Chengjiang Long, Qing Zhang, and Guiqing Li. A Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow- Guided Frame Prediction. In Proceedings of ICCV, pages 13588-13597, 2021. 1, 2, 3, 5, 7, 8, 12, 14\n\nAbnormal Event Detection at 150 FPS in MATLAB. Cewu Lu, Jianping Shi, Jiaya Jia, Proceedings of ICCV. ICCV25Cewu Lu, Jianping Shi, and Jiaya Jia. Abnormal Event De- tection at 150 FPS in MATLAB. In Proceedings of ICCV, pages 2720-2727, 2013. 1, 2, 5\n\nFew-Shot Scene-Adaptive Anomaly Detection. Yiwei Lu, Frank Yu, Mahesh Kumar, Krishna Reddy, Yang Wang, Proceedings of ECCV. ECCV1Yiwei Lu, Frank Yu, Mahesh Kumar, Krishna Reddy, and Yang Wang. Few-Shot Scene-Adaptive Anomaly Detection. In Proceedings of ECCV, pages 125-141, 2020. 1, 2\n\nVideo Cloze Procedure for Self-Supervised Spatio-Temporal Learning. Dezhao Luo, Chang Liu, Y Zhou, Dongbao Yang, Can Ma, Qixiang Ye, Weiping Wang, Proceedings of AAAI. AAAIDezhao Luo, Chang Liu, Y. Zhou, Dongbao Yang, Can Ma, Qixiang Ye, and Weiping Wang. Video Cloze Procedure for Self-Supervised Spatio-Temporal Learning. In Proceedings of AAAI, pages 11701-11708, 2020. 3\n\nA Revisit of Sparse Coding Based Anomaly Detection in Stacked RNN Framework. Weixin Luo, Wen Liu, Shenghua Gao, Proceedings of ICCV. ICCV14Weixin Luo, Wen Liu, and Shenghua Gao. A Revisit of Sparse Coding Based Anomaly Detection in Stacked RNN Framework. In Proceedings of ICCV, pages 341-349, 2017. 1, 2, 5, 14\n\nAnomaly Detection in Crowded Scenes. Vijay Mahadevan, L I Wei-Xin, Viral Bhalodia, Nuno Vasconcelos, Proceedings of CVPR. CVPRVijay Mahadevan, Wei-Xin LI, Viral Bhalodia, and Nuno Vasconcelos. Anomaly Detection in Crowded Scenes. In Proceedings of CVPR, pages 1975-1981, 2010. 1, 2\n\nAbnormal crowd behavior detection using social force model. Ramin Mehran, Alexis Oyama, Mubarak Shah, Proceedings of CVPR. CVPR1Ramin Mehran, Alexis Oyama, and Mubarak Shah. Abnor- mal crowd behavior detection using social force model. In Proceedings of CVPR, pages 935-942, 2009. 1, 2\n\nRectified Linear Units Improve Restricted Boltzmann Machines. Vinod Nair, Geoffrey E Hinton, Proceedings of ICML. ICML4Vinod Nair and Geoffrey E Hinton. Rectified Linear Units Improve Restricted Boltzmann Machines. In Proceedings of ICML, pages 807-814, 2010. 4\n\nAnomaly Detection in Video Sequence With Appearance-Motion Correspondence. Jean Trong-Nguyen Nguyen, Meunier, Proceedings of ICCV. ICCV14Trong-Nguyen Nguyen and Jean Meunier. Anomaly De- tection in Video Sequence With Appearance-Motion Cor- respondence. In Proceedings of ICCV, pages 1273-1283, 2019. 1, 2, 8, 14\n\nSelf-trained Deep Ordinal Regression for End-to-End Video Anomaly Detection. Guansong Pang, Cheng Yan, Chunhua Shen, Proceedings of CVPR. CVPR1Anton van den Hengel, and Xiao BaiGuansong Pang, Cheng Yan, Chunhua Shen, Anton van den Hengel, and Xiao Bai. Self-trained Deep Ordinal Regression for End-to-End Video Anomaly Detection. In Proceedings of CVPR, pages 12173-12182, 2020. 1, 2\n\nLearning Memory-guided Normality for Anomaly Detection. Hyunjong Park, Jongyoun Noh, Bumsub Ham, Proceedings of CVPR. CVPR14Hyunjong Park, Jongyoun Noh, and Bumsub Ham. Learning Memory-guided Normality for Anomaly Detection. In Pro- ceedings of CVPR, pages 14372-14381, 2020. 1, 2, 3, 5, 7, 8, 12, 14\n\nStreet Scene: A new dataset and evaluation protocol for video anomaly detection. Bharathkumar Ramachandra, Michael Jones, Proceedings of WACV. WACVBharathkumar Ramachandra and Michael Jones. Street Scene: A new dataset and evaluation protocol for video anomaly detection. In Proceedings of WACV, pages 2569- 2578, 2020. 1, 2, 5, 8\n\nLearning a distance function with a Siamese network to localize anomalies in videos. Bharathkumar Ramachandra, Michael Jones, Ranga Vatsavai, Proceedings of WACV. WACVBharathkumar Ramachandra, Michael Jones, and Ranga Vat- savai. Learning a distance function with a Siamese network to localize anomalies in videos. In Proceedings of WACV, pages 2598-2607, 2020. 1, 2, 8\n\nA Survey of Single-Scene Video Anomaly Detection. Bharathkumar Ramachandra, Michael J Jones, Ranga Raju Vatsavai, IEEE Transactions on Pattern Analysis and Machine Intelligence. 2020Bharathkumar Ramachandra, Michael J. Jones, and Ranga Raju Vatsavai. A Survey of Single-Scene Video Anomaly Detection. IEEE Transactions on Pattern Analy- sis and Machine Intelligence, 2020. 1\n\nPlug-and-Play CNN for Crowd Motion Analysis: An Application in Abnormal Event Detection. Mahdyar Ravanbakhsh, Moin Nabi, Hossein Mousavi, Enver Sangineto, Nicu Sebe, Proceedings of WACV. WACV1Mahdyar Ravanbakhsh, Moin Nabi, Hossein Mousavi, Enver Sangineto, and Nicu Sebe. Plug-and-Play CNN for Crowd Motion Analysis: An Application in Abnormal Event Detec- tion. In Proceedings of WACV, pages 1689-1698, 2018. 1, 2\n\nAbnormal Event Detection in Videos using Generative Adversarial Nets. Mahdyar Ravanbakhsh, Moin Nabi, Enver Sangineto, Lucio Marcenaro, Carlo Regazzoni, Nicu Sebe, Proceedings of ICIP. ICIP14Mahdyar Ravanbakhsh, Moin Nabi, Enver Sangineto, Lu- cio Marcenaro, Carlo Regazzoni, and Nicu Sebe. Abnor- mal Event Detection in Videos using Generative Adversarial Nets. In Proceedings of ICIP, pages 1577-1581, 2017. 1, 2, 14\n\nUnsupervised Behavior-Specific Dictionary Learning for Abnormal Event Detection. Weifeng Huamin Ren, Liu, Sergio Soren Ingvor Olsen, Thomas B Escalera, Moeslund, Proceedings of BMVC. BMVC13Huamin Ren, Weifeng Liu, Soren Ingvor Olsen, Sergio Es- calera, and Thomas B. Moeslund. Unsupervised Behavior- Specific Dictionary Learning for Abnormal Event Detection. In Proceedings of BMVC, pages 28.1-28.13, 2015. 1, 2\n\nSame Same But DifferNet: Semi-Supervised Defect Detection with Normalizing Flows. Marco Rudolph, Bastian Wandt, Bodo Rosenhahn, Proceedings of WACV. WACV1Marco Rudolph, Bastian Wandt, and Bodo Rosenhahn. Same Same But DifferNet: Semi-Supervised Defect Detection with Normalizing Flows. In Proceedings of WACV, pages 1907-1916, 2021. 1, 2\n\nDeep-Cascade: Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localization in Crowded Scenes. Mohammad Sabokrou, Mohsen Fayyaz, Mahmood Fathy, Reinhard Klette, IEEE Transactions on Image Processing. 264Mohammad Sabokrou, Mohsen Fayyaz, Mahmood Fathy, and Reinhard Klette. Deep-Cascade: Cascading 3D Deep Neural Networks for Fast Anomaly Detection and Localiza- tion in Crowded Scenes. IEEE Transactions on Image Pro- cessing, 26(4):1992-2004, 2017. 1, 2\n\nDeep-anomaly: Fully convolutional neural network for fast anomaly detection in crowded scenes. Mohammad Sabokrou, Mohsen Fayyaz, Mahmood Fathy, Zahra Moayed, Reinhard Klette, Computer Vision and Image Understanding. 1722Mohammad Sabokrou, Mohsen Fayyaz, Mahmood Fathy, Zahra Moayed, and Reinhard Klette. Deep-anomaly: Fully convolutional neural network for fast anomaly detection in crowded scenes. Computer Vision and Image Understand- ing, 172:88-97, 2018. 1, 2\n\nAVID: Adversarial Visual Irregularity Detection. Mohammad Sabokrou, Masoud Pourreza, Mohsen Fayyaz, Rahim Entezari, Mahmood Fathy, Juergen Gall, Ehsan Adeli, Proceedings of ACCV. ACCVMohammad Sabokrou, Masoud PourReza, Mohsen Fayyaz, Rahim Entezari, Mahmood Fathy, Juergen Gall, and Ehsan Adeli. AVID: Adversarial Visual Irregularity Detection. In Proceedings of ACCV, pages 488-505, 2018. 3\n\nDynamic Routing Between Capsules. Sara Sabour, Nicholas Frosst, Geoffrey E Hinton, Proceedings of NIPS. NIPSSara Sabour, Nicholas Frosst, and Geoffrey E. Hinton. Dy- namic Routing Between Capsules. In Proceedings of NIPS, pages 3859-3869, 2017. 3\n\nObject-Centric Anomaly Detection by Attribute-Based Reasoning. Babak Saleh, Ali Farhadi, Ahmed Elgammal, Proceedings of CVPR. CVPR1Babak Saleh, Ali Farhadi, and Ahmed Elgammal. Object- Centric Anomaly Detection by Attribute-Based Reasoning. In Proceedings of CVPR, pages 787-794, 2013. 1, 2\n\nMultiresolution Knowledge Distillation for Anomaly Detection. Mohammadreza Salehi, Niousha Sadjadi, Soroosh Baselizadeh, Mohammad H Rohban, Hamid R Rabiee, Proceedings of CVPR. CVPR14Mohammadreza Salehi, Niousha Sadjadi, Soroosh Baselizadeh, Mohammad H. Rohban, and Hamid R. Rabiee. Multiresolution Knowledge Distillation for Anomaly Detec- tion. In Proceedings of CVPR, pages 14902-14912, 2021. 1, 2, 14\n\nVideo anomaly detection based on local statistical aggregates. Venkatesh Saligrama, Zhu Chen, Proceedings of CVPR. CVPR1Venkatesh Saligrama and Zhu Chen. Video anomaly detec- tion based on local statistical aggregates. In Proceedings of CVPR, pages 2112-2119, 2012. 1, 2\n\nGrad-CAM: Visual Explanations From Deep Networks via Gradient-Based Localization. R Ramprasaath, Michael Selvaraju, Abhishek Cogswell, Ramakrishna Das, Devi Vedantam, Dhruv Parikh, Batra, Proceedings of ICCV. ICCVRamprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Ba- tra. Grad-CAM: Visual Explanations From Deep Networks via Gradient-Based Localization. In Proceedings of ICCV, pages 618-626, 2017. 6\n\nDeep Appearance Features for Abnormal Behavior Detection in Video. Sorina Smeureanu, Tudor Radu, Marius Ionescu, Bogdan Popescu, Alexe, Proceedings of ICIAP. ICIAP10485Sorina Smeureanu, Radu Tudor Ionescu, Marius Popescu, and Bogdan Alexe. Deep Appearance Features for Abnor- mal Behavior Detection in Video. In Proceedings of ICIAP, volume 10485, pages 779-789, 2017. 1, 2\n\nReal-World Anomaly Detection in Surveillance Videos. Waqas Sultani, Chen Chen, Mubarak Shah, Proceedings of CVPR. CVPRWaqas Sultani, Chen Chen, and Mubarak Shah. Real-World Anomaly Detection in Surveillance Videos. In Proceedings of CVPR, pages 6479-6488, 2018. 8\n\nScene-Aware Context Reasoning for Unsupervised Abnormal Event Detection in Videos. Che Sun, Yunde Jia, Yao Hu, Yuwei Wu, Proceedings of ACMMM. ACMMM1Che Sun, Yunde Jia, Yao Hu, and Yuwei Wu. Scene-Aware Context Reasoning for Unsupervised Abnormal Event De- tection in Videos. In Proceedings of ACMMM, pages 184- 192, 2020. 1, 8\n\nOnline growing neural gas for anomaly detection in changing surveillance scenes. Qianru Sun, Hong Liu, Tatsuya Harada, Pattern Recognition. 64CQianru Sun, Hong Liu, and Tatsuya Harada. Online growing neural gas for anomaly detection in changing surveillance scenes. Pattern Recognition, 64(C):187-201, Apr. 2017. 1, 2\n\nIntegrating prediction and reconstruction for anomaly detection. Yao Tang, Lin Zhao, Shanshan Zhang, Chen Gong, Guangyu Li, Jian Yang, Pattern Recognition Letters. 12914Yao Tang, Lin Zhao, Shanshan Zhang, Chen Gong, Guangyu Li, and Jian Yang. Integrating prediction and reconstruc- tion for anomaly detection. Pattern Recognition Letters, 129:123-130, 2020. 1, 2, 8, 14\n\nAnomaly Detection using a Convolutional Winner-Take-All Autoencoder. T M Hanh, David Tran, Hogg, Proceedings of BMVC. BMVC1Hanh T.M. Tran and David Hogg. Anomaly Detection using a Convolutional Winner-Take-All Autoencoder. In Proceed- ings of BMVC, 2017. 1, 2\n\nAttention guided anomaly localization in images. Shashanka Venkataramanan, Kuan-Chuan, Peng, Rajat Vikram Singh, and Abhijit Mahalanobis. 14Proceedings of ECCVShashanka Venkataramanan, Kuan-Chuan Peng, Ra- jat Vikram Singh, and Abhijit Mahalanobis. Attention guided anomaly localization in images. In Proceedings of ECCV, pages 485-503, 2020. 1, 2, 14\n\nCluster Attention Contrast for Video Anomaly Detection. Ziming Wang, Yuexian Zou, Zeming Zhang, Proceedings of ACMMM. ACMMM1Ziming Wang, Yuexian Zou, and Zeming Zhang. Cluster Attention Contrast for Video Anomaly Detection. In Pro- ceedings of ACMMM, pages 2463-2471, 2020. 1, 8\n\nA Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes. Peng Wu, Jing Liu, Fang Shen, IEEE Transactions on Neural Networks and Learning Systems. 317Peng Wu, Jing Liu, and Fang Shen. A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes. IEEE Transactions on Neural Networks and Learn- ing Systems, 31(7):2609-2622, 2019. 1, 8\n\nChaotic Invariants of Lagrangian Particle Trajectories for Anomaly Detection in Crowded Scenes. Shandong Wu, Brian E Moore, Mubarak Shah, Proceedings of CVPR. CVPR1Shandong Wu, Brian E. Moore, and Mubarak Shah. Chaotic Invariants of Lagrangian Particle Trajectories for Anomaly Detection in Crowded Scenes. In Proceedings of CVPR, pages 2054-2060, 2010. 1, 2\n\nDetecting Anomalous Events in Videos by Learning Deep Representations of Appearance and Motion. Dan Xu, Yan Yan, Elisa Ricci, Nicu Sebe, Computer Vision and Image Understanding. 1561Dan Xu, Yan Yan, Elisa Ricci, and Nicu Sebe. Detecting Anomalous Events in Videos by Learning Deep Represen- tations of Appearance and Motion. Computer Vision and Image Understanding, 156:117-127, 2017. 1\n\nPatch SVDD: Patch-level SVDD for Anomaly Detection and Segmentation. Jihun Yi, Sungroh Yoon, Proceedings of ACCV. ACCV2020Jihun Yi and Sungroh Yoon. Patch SVDD: Patch-level SVDD for Anomaly Detection and Segmentation. In Pro- ceedings of ACCV, pages 375-390, 2020. 1\n\nCloze Test Helps: Effective Video Anomaly Detection via Learning to Complete Video Events. Guang Yu, Siqi Wang, Zhiping Cai, En Zhu, Chuanfu Xu, Jianping Yin, Marius Kloft, Proceedings of ACMMM. ACMMMGuang Yu, Siqi Wang, Zhiping Cai, En Zhu, Chuanfu Xu, Jianping Yin, and Marius Kloft. Cloze Test Helps: Effective Video Anomaly Detection via Learning to Complete Video Events. In Proceedings of ACMMM, pages 583-591, 2020. 1, 3, 8\n\nOld is Gold: Redefining the Adversarially Learned One-Class Classifier Training Paradigm. Jin-Ha Muhammad Zaigham Zaheer, Marcella Lee, Seung-Ik Astrid, Lee, Proceedings of CVPR. CVPRMuhammad Zaigham Zaheer, Jin-ha Lee, Marcella Astrid, and Seung-Ik Lee. Old is Gold: Redefining the Adversar- ially Learned One-Class Classifier Training Paradigm. In Proceedings of CVPR, pages 14183-14193, 2020. 1\n\nDRAEM -A Discriminatively Trained Reconstruction Embedding for Surface Anomaly Detection. Vitjan Zavrtanik, Matej Kristan, Danijel Skocaj, Proceedings of ICCV. ICCV1214Vitjan Zavrtanik, Matej Kristan, and Danijel Skocaj. DRAEM -A Discriminatively Trained Reconstruction Em- bedding for Surface Anomaly Detection. In Proceedings of ICCV, pages 8330-8339, 2021. 2, 3, 5, 6, 7, 8, 12, 14\n\nVisualizing and Understanding Convolutional Networks. D Matthew, Rob Zeiler, Fergus, Proceedings of ECCV. ECCVMatthew D. Zeiler and Rob Fergus. Visualizing and Under- standing Convolutional Networks. In Proceedings of ECCV, pages 818-833, 2014. 3\n\nVideo Anomaly Detection and Localization using Motion-field Shape Description and Homogeneity Testing. Xinfeng Zhang, Su Yang, Jiulong Zhang, Weishan Zhang, Pattern Recognition. 1107394Xinfeng Zhang, Su Yang, Jiulong Zhang, and Weishan Zhang. Video Anomaly Detection and Localization using Motion-field Shape Description and Homogeneity Testing. Pattern Recognition, page 107394, 2020. 1\n\nOnline Detection of Unusual Events in Videos via Dynamic Sparse Coding. Bin Zhao, Li Fei-Fei, Eric P Xing, Proceedings of CVPR. CVPRBin Zhao, Li Fei-Fei, and Eric P. Xing. Online Detection of Unusual Events in Videos via Dynamic Sparse Coding. In Proceedings of CVPR, pages 3313-3320, 2011. 1\n\nContext-encoding Variational Autoencoder for Unsupervised Anomaly Detection. David Zimmerer, Simon Kohl, Jens Petersen, Fabian Isensee, Klaus Maier-Hein, Proceedings of MIDL. MIDLDavid Zimmerer, Simon Kohl, Jens Petersen, Fabian Isensee, and Klaus Maier-Hein. Context-encoding Variational Au- toencoder for Unsupervised Anomaly Detection. In Proceed- ings of MIDL, 2019. 3\n", "annotations": {"author": "[{\"end\":197,\"start\":82},{\"end\":238,\"start\":198},{\"end\":311,\"start\":239},{\"end\":384,\"start\":312},{\"end\":480,\"start\":385},{\"end\":527,\"start\":481},{\"end\":575,\"start\":528}]", "publisher": null, "author_last_name": "[{\"end\":104,\"start\":98},{\"end\":209,\"start\":204},{\"end\":257,\"start\":250},{\"end\":328,\"start\":318},{\"end\":403,\"start\":391},{\"end\":498,\"start\":490},{\"end\":540,\"start\":536}]", "author_first_name": "[{\"end\":97,\"start\":82},{\"end\":203,\"start\":198},{\"end\":243,\"start\":239},{\"end\":249,\"start\":244},{\"end\":317,\"start\":312},{\"end\":390,\"start\":385},{\"end\":487,\"start\":481},{\"end\":489,\"start\":488},{\"end\":535,\"start\":528}]", "author_affiliation": "[{\"end\":149,\"start\":106},{\"end\":196,\"start\":151},{\"end\":237,\"start\":211},{\"end\":310,\"start\":259},{\"end\":356,\"start\":330},{\"end\":383,\"start\":358},{\"end\":450,\"start\":405},{\"end\":479,\"start\":452},{\"end\":526,\"start\":500},{\"end\":574,\"start\":542}]", "title": "[{\"end\":79,\"start\":1},{\"end\":654,\"start\":576}]", "venue": null, "abstract": "[{\"end\":2088,\"start\":656}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2287,\"start\":2284},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2289,\"start\":2287},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2292,\"start\":2289},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2295,\"start\":2292},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":2298,\"start\":2295},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":2301,\"start\":2298},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":2304,\"start\":2301},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":2307,\"start\":2304},{\"end\":2473,\"start\":2407},{\"end\":2630,\"start\":2577},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":2682,\"start\":2679},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":2685,\"start\":2682},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":2688,\"start\":2685},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":2691,\"start\":2688},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":2694,\"start\":2691},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":2697,\"start\":2694},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":2700,\"start\":2697},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":2703,\"start\":2700},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":2705,\"start\":2703},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3082,\"start\":3078},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3085,\"start\":3082},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3088,\"start\":3085},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3091,\"start\":3088},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":3094,\"start\":3091},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":3097,\"start\":3094},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3100,\"start\":3097},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3103,\"start\":3100},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":3106,\"start\":3103},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":3109,\"start\":3106},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":3112,\"start\":3109},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":3115,\"start\":3112},{\"end\":3162,\"start\":3145},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3189,\"start\":3186},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3192,\"start\":3189},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3195,\"start\":3192},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3198,\"start\":3195},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":3201,\"start\":3198},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":3204,\"start\":3201},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":3207,\"start\":3204},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":3210,\"start\":3207},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":3213,\"start\":3210},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":3216,\"start\":3213},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":3219,\"start\":3216},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":3222,\"start\":3219},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":3225,\"start\":3222},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3259,\"start\":3255},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3262,\"start\":3259},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3265,\"start\":3262},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":3268,\"start\":3265},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3298,\"start\":3295},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3300,\"start\":3298},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3303,\"start\":3300},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3306,\"start\":3303},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3309,\"start\":3306},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3312,\"start\":3309},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":3315,\"start\":3312},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":3318,\"start\":3315},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":3321,\"start\":3318},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":3324,\"start\":3321},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3595,\"start\":3591},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":3615,\"start\":3611},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3643,\"start\":3639},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4563,\"start\":4559},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5741,\"start\":5737},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5744,\"start\":5741},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":5747,\"start\":5744},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":5750,\"start\":5747},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":5753,\"start\":5750},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":5756,\"start\":5753},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5814,\"start\":5811},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":5827,\"start\":5823},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":5849,\"start\":5845},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":6015,\"start\":6011},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6610,\"start\":6606},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":6613,\"start\":6610},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":6616,\"start\":6613},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":6619,\"start\":6616},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":6622,\"start\":6619},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":6625,\"start\":6622},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6898,\"start\":6894},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":6901,\"start\":6898},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6936,\"start\":6932},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":6939,\"start\":6936},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":6942,\"start\":6939},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":6945,\"start\":6942},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":6948,\"start\":6945},{\"end\":7005,\"start\":6978},{\"end\":7172,\"start\":7155},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7206,\"start\":7202},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7209,\"start\":7206},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":7212,\"start\":7209},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7215,\"start\":7212},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7246,\"start\":7243},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7248,\"start\":7246},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7251,\"start\":7248},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7254,\"start\":7251},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7257,\"start\":7254},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7260,\"start\":7257},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":7263,\"start\":7260},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":7266,\"start\":7263},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":7269,\"start\":7266},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":7272,\"start\":7269},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7299,\"start\":7296},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7302,\"start\":7299},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7305,\"start\":7302},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7308,\"start\":7305},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":7311,\"start\":7308},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":7314,\"start\":7311},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":7317,\"start\":7314},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":7320,\"start\":7317},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":7323,\"start\":7320},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":7326,\"start\":7323},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":7329,\"start\":7326},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":7332,\"start\":7329},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":7335,\"start\":7332},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7374,\"start\":7370},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7377,\"start\":7374},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7380,\"start\":7377},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":7383,\"start\":7380},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":7386,\"start\":7383},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7389,\"start\":7386},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":7392,\"start\":7389},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":7395,\"start\":7392},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":7398,\"start\":7395},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":7401,\"start\":7398},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":7404,\"start\":7401},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":7407,\"start\":7404},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":7410,\"start\":7407},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":7573,\"start\":7569},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7928,\"start\":7924},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7955,\"start\":7951},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":8257,\"start\":8253},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":8382,\"start\":8378},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":8696,\"start\":8692},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9083,\"start\":9079},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":9086,\"start\":9083},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":9089,\"start\":9086},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9258,\"start\":9254},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":9306,\"start\":9302},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9543,\"start\":9539},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9546,\"start\":9543},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9843,\"start\":9839},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":9846,\"start\":9843},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":9849,\"start\":9846},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":10088,\"start\":10085},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":10091,\"start\":10088},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":10094,\"start\":10091},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10137,\"start\":10133},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":10345,\"start\":10341},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10555,\"start\":10551},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":10558,\"start\":10555},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10696,\"start\":10692},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11124,\"start\":11120},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11127,\"start\":11124},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11130,\"start\":11127},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":11133,\"start\":11130},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":11136,\"start\":11133},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11264,\"start\":11260},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11473,\"start\":11469},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":11835,\"start\":11831},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":11948,\"start\":11944},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12018,\"start\":12014},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12258,\"start\":12254},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":12424,\"start\":12420},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":12964,\"start\":12960},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12967,\"start\":12964},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12970,\"start\":12967},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":12973,\"start\":12970},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":12976,\"start\":12973},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":12979,\"start\":12976},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":13093,\"start\":13089},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":13096,\"start\":13093},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13209,\"start\":13205},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13212,\"start\":13209},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":13215,\"start\":13212},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":13218,\"start\":13215},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":13221,\"start\":13218},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":13685,\"start\":13681},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":13856,\"start\":13852},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":14250,\"start\":14246},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":15698,\"start\":15694},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":15753,\"start\":15749},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":18639,\"start\":18635},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":18659,\"start\":18655},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":21663,\"start\":21660},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":21894,\"start\":21890},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":22223,\"start\":22219},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":22398,\"start\":22394},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22792,\"start\":22788},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":22795,\"start\":22792},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22882,\"start\":22878},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22885,\"start\":22882},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":22888,\"start\":22885},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":22891,\"start\":22888},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":22894,\"start\":22891},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":22897,\"start\":22894},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":23686,\"start\":23682},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":23714,\"start\":23710},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":24346,\"start\":24342},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":24697,\"start\":24693},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":26192,\"start\":26188},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":26207,\"start\":26203},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":26224,\"start\":26220},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":26406,\"start\":26402},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":26614,\"start\":26610},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":26745,\"start\":26741},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":27123,\"start\":27119},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":27138,\"start\":27134},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":27492,\"start\":27488},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":27612,\"start\":27608},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":27801,\"start\":27797},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":28021,\"start\":28017},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":28024,\"start\":28021},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":28027,\"start\":28024},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28030,\"start\":28027},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":28251,\"start\":28247},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":28254,\"start\":28251},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":28257,\"start\":28254},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28260,\"start\":28257},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":28485,\"start\":28481},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28506,\"start\":28502},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":28678,\"start\":28674},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":28885,\"start\":28881},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":29040,\"start\":29036},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":29218,\"start\":29214},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":29263,\"start\":29259},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":29445,\"start\":29441},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":29519,\"start\":29515},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":29712,\"start\":29708},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":30178,\"start\":30174},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":30181,\"start\":30178},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":30184,\"start\":30181},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":30187,\"start\":30184},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":30606,\"start\":30602},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":31324,\"start\":31320},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":31327,\"start\":31324},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":31330,\"start\":31327},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":31333,\"start\":31330},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":31336,\"start\":31333},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":31339,\"start\":31336},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32238,\"start\":32234},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":32241,\"start\":32238},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":32244,\"start\":32241},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":32247,\"start\":32244},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":32250,\"start\":32247},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":32253,\"start\":32250},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":34458,\"start\":34454},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":34940,\"start\":34936},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":35410,\"start\":35406},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":35953,\"start\":35949},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":35988,\"start\":35984},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":36104,\"start\":36100},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":36107,\"start\":36104},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":36640,\"start\":36636},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":36643,\"start\":36640},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":36646,\"start\":36643},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":36649,\"start\":36646},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":36652,\"start\":36649},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":36655,\"start\":36652},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":36954,\"start\":36950},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":36957,\"start\":36954},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":37309,\"start\":37305},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":37312,\"start\":37309},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":37315,\"start\":37312},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":37318,\"start\":37315},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":37321,\"start\":37318},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":37324,\"start\":37321},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":37327,\"start\":37324},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":37330,\"start\":37327},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":37333,\"start\":37330},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":37336,\"start\":37333},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":37339,\"start\":37336},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":37342,\"start\":37339},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":39378,\"start\":39374},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":40114,\"start\":40110},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":40357,\"start\":40353},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":40611,\"start\":40607},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":40865,\"start\":40861},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":41241,\"start\":41237}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":39022,\"start\":38939},{\"attributes\":{\"id\":\"fig_2\"},\"end\":39322,\"start\":39023},{\"attributes\":{\"id\":\"fig_3\"},\"end\":39502,\"start\":39323},{\"attributes\":{\"id\":\"fig_4\"},\"end\":39862,\"start\":39503},{\"attributes\":{\"id\":\"fig_5\"},\"end\":40055,\"start\":39863},{\"attributes\":{\"id\":\"fig_6\"},\"end\":40292,\"start\":40056},{\"attributes\":{\"id\":\"fig_7\"},\"end\":40546,\"start\":40293},{\"attributes\":{\"id\":\"fig_8\"},\"end\":40800,\"start\":40547},{\"attributes\":{\"id\":\"fig_9\"},\"end\":41054,\"start\":40801},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":42195,\"start\":41055}]", "paragraph": "[{\"end\":3325,\"start\":2104},{\"end\":4208,\"start\":3327},{\"end\":5284,\"start\":4210},{\"end\":5656,\"start\":5286},{\"end\":6354,\"start\":5658},{\"end\":6732,\"start\":6356},{\"end\":7411,\"start\":6749},{\"end\":9090,\"start\":7413},{\"end\":11025,\"start\":9092},{\"end\":12534,\"start\":11027},{\"end\":13041,\"start\":12536},{\"end\":13857,\"start\":13052},{\"end\":14702,\"start\":13859},{\"end\":16430,\"start\":14704},{\"end\":19049,\"start\":16432},{\"end\":19244,\"start\":19051},{\"end\":19563,\"start\":19276},{\"end\":20267,\"start\":19565},{\"end\":20507,\"start\":20314},{\"end\":20747,\"start\":20542},{\"end\":21371,\"start\":20796},{\"end\":22824,\"start\":21373},{\"end\":23240,\"start\":22862},{\"end\":23737,\"start\":23242},{\"end\":24216,\"start\":23761},{\"end\":24832,\"start\":24254},{\"end\":26074,\"start\":24834},{\"end\":26208,\"start\":26106},{\"end\":26722,\"start\":26210},{\"end\":27370,\"start\":26724},{\"end\":27642,\"start\":27372},{\"end\":27925,\"start\":27644},{\"end\":28886,\"start\":27963},{\"end\":30359,\"start\":28888},{\"end\":30449,\"start\":30361},{\"end\":30868,\"start\":30451},{\"end\":31718,\"start\":30883},{\"end\":32072,\"start\":31720},{\"end\":33282,\"start\":32107},{\"end\":33728,\"start\":33284},{\"end\":34310,\"start\":33730},{\"end\":35211,\"start\":34352},{\"end\":36230,\"start\":35213},{\"end\":36578,\"start\":36232},{\"end\":37177,\"start\":36597},{\"end\":37857,\"start\":37192},{\"end\":38629,\"start\":37859},{\"end\":38938,\"start\":38631}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":19275,\"start\":19245},{\"attributes\":{\"id\":\"formula_1\"},\"end\":20313,\"start\":20268},{\"attributes\":{\"id\":\"formula_2\"},\"end\":20541,\"start\":20508}]", "table_ref": "[{\"end\":24882,\"start\":24875},{\"end\":26979,\"start\":26972},{\"end\":28956,\"start\":28949},{\"end\":29966,\"start\":29959},{\"end\":31919,\"start\":31912},{\"end\":32986,\"start\":32979},{\"end\":33607,\"start\":33600},{\"end\":36009,\"start\":36002},{\"end\":36968,\"start\":36961},{\"end\":37176,\"start\":37169},{\"end\":38628,\"start\":38621},{\"end\":38678,\"start\":38671}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2102,\"start\":2090},{\"attributes\":{\"n\":\"2.\"},\"end\":6747,\"start\":6735},{\"attributes\":{\"n\":\"3.\"},\"end\":13050,\"start\":13044},{\"attributes\":{\"n\":\"4.\"},\"end\":20773,\"start\":20750},{\"attributes\":{\"n\":\"4.2.\"},\"end\":20794,\"start\":20776},{\"attributes\":{\"n\":\"4.3.\"},\"end\":22860,\"start\":22827},{\"attributes\":{\"n\":\"4.4.\"},\"end\":23759,\"start\":23740},{\"end\":24252,\"start\":24219},{\"attributes\":{\"n\":\"4.5.\"},\"end\":26104,\"start\":26077},{\"attributes\":{\"n\":\"4.6.\"},\"end\":27961,\"start\":27928},{\"attributes\":{\"n\":\"5.\"},\"end\":30881,\"start\":30871},{\"attributes\":{\"n\":\"6.\"},\"end\":32088,\"start\":32075},{\"attributes\":{\"n\":\"6.1.\"},\"end\":32105,\"start\":32091},{\"attributes\":{\"n\":\"6.2.\"},\"end\":34350,\"start\":34313},{\"attributes\":{\"n\":\"6.3.\"},\"end\":36595,\"start\":36581},{\"attributes\":{\"n\":\"6.4.\"},\"end\":37190,\"start\":37180},{\"end\":38950,\"start\":38940},{\"end\":39034,\"start\":39024},{\"end\":39334,\"start\":39324},{\"end\":39514,\"start\":39504},{\"end\":39874,\"start\":39864},{\"end\":40067,\"start\":40057},{\"end\":40304,\"start\":40294},{\"end\":40558,\"start\":40548},{\"end\":40812,\"start\":40802}]", "table": "[{\"end\":42195,\"start\":41280}]", "figure_caption": "[{\"end\":39022,\"start\":38952},{\"end\":39322,\"start\":39036},{\"end\":39502,\"start\":39336},{\"end\":39862,\"start\":39516},{\"end\":40055,\"start\":39876},{\"end\":40292,\"start\":40069},{\"end\":40546,\"start\":40306},{\"end\":40800,\"start\":40560},{\"end\":41054,\"start\":40814},{\"end\":41280,\"start\":41057}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":5362,\"start\":5354},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":15894,\"start\":15886},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":27655,\"start\":27647},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":30462,\"start\":30454},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":34392,\"start\":34384},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":34766,\"start\":34758},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":35231,\"start\":35216},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":35783,\"start\":35775}]", "bib_author_first_name": "[{\"end\":42657,\"start\":42653},{\"end\":42668,\"start\":42664},{\"end\":42681,\"start\":42677},{\"end\":42698,\"start\":42693},{\"end\":43055,\"start\":43047},{\"end\":43068,\"start\":43063},{\"end\":43277,\"start\":43269},{\"end\":43294,\"start\":43286},{\"end\":43302,\"start\":43295},{\"end\":43320,\"start\":43311},{\"end\":43334,\"start\":43326},{\"end\":43592,\"start\":43584},{\"end\":43609,\"start\":43601},{\"end\":43617,\"start\":43610},{\"end\":43634,\"start\":43626},{\"end\":43936,\"start\":43932},{\"end\":43954,\"start\":43947},{\"end\":43968,\"start\":43963},{\"end\":43988,\"start\":43981},{\"end\":44328,\"start\":44324},{\"end\":44346,\"start\":44339},{\"end\":44360,\"start\":44355},{\"end\":44380,\"start\":44373},{\"end\":44695,\"start\":44690},{\"end\":44710,\"start\":44705},{\"end\":44729,\"start\":44722},{\"end\":44746,\"start\":44740},{\"end\":45136,\"start\":45129},{\"end\":45153,\"start\":45144},{\"end\":45169,\"start\":45160},{\"end\":45480,\"start\":45479},{\"end\":45488,\"start\":45487},{\"end\":45496,\"start\":45495},{\"end\":45761,\"start\":45755},{\"end\":45779,\"start\":45770},{\"end\":45797,\"start\":45788},{\"end\":45813,\"start\":45806},{\"end\":46136,\"start\":46129},{\"end\":46150,\"start\":46149},{\"end\":46157,\"start\":46151},{\"end\":46174,\"start\":46167},{\"end\":46467,\"start\":46464},{\"end\":46476,\"start\":46474},{\"end\":46491,\"start\":46484},{\"end\":46739,\"start\":46734},{\"end\":46752,\"start\":46747},{\"end\":47003,\"start\":47002},{\"end\":47018,\"start\":47013},{\"end\":47280,\"start\":47278},{\"end\":47293,\"start\":47286},{\"end\":47304,\"start\":47301},{\"end\":47319,\"start\":47313},{\"end\":47326,\"start\":47324},{\"end\":47338,\"start\":47334},{\"end\":47629,\"start\":47621},{\"end\":47640,\"start\":47636},{\"end\":47656,\"start\":47647},{\"end\":47911,\"start\":47896},{\"end\":47930,\"start\":47923},{\"end\":47946,\"start\":47941},{\"end\":47958,\"start\":47953},{\"end\":47974,\"start\":47968},{\"end\":47996,\"start\":47989},{\"end\":48396,\"start\":48389},{\"end\":48404,\"start\":48397},{\"end\":48420,\"start\":48416},{\"end\":48436,\"start\":48430},{\"end\":48464,\"start\":48457},{\"end\":49025,\"start\":49021},{\"end\":49040,\"start\":49032},{\"end\":49051,\"start\":49046},{\"end\":49066,\"start\":49056},{\"end\":49388,\"start\":49385},{\"end\":49403,\"start\":49394},{\"end\":49414,\"start\":49409},{\"end\":49426,\"start\":49421},{\"end\":49441,\"start\":49432},{\"end\":49453,\"start\":49449},{\"end\":49852,\"start\":49844},{\"end\":49868,\"start\":49860},{\"end\":49878,\"start\":49875},{\"end\":49889,\"start\":49888},{\"end\":49901,\"start\":49896},{\"end\":49903,\"start\":49902},{\"end\":50219,\"start\":50211},{\"end\":50237,\"start\":50231},{\"end\":50239,\"start\":50238},{\"end\":50252,\"start\":50248},{\"end\":50552,\"start\":50547},{\"end\":50564,\"start\":50561},{\"end\":50584,\"start\":50570},{\"end\":50840,\"start\":50837},{\"end\":50847,\"start\":50845},{\"end\":50858,\"start\":50854},{\"end\":51103,\"start\":51098},{\"end\":51139,\"start\":51124},{\"end\":51158,\"start\":51154},{\"end\":51473,\"start\":51467},{\"end\":51500,\"start\":51494},{\"end\":51518,\"start\":51512},{\"end\":51802,\"start\":51796},{\"end\":51829,\"start\":51823},{\"end\":51847,\"start\":51841},{\"end\":52192,\"start\":52185},{\"end\":52204,\"start\":52197},{\"end\":52217,\"start\":52209},{\"end\":52552,\"start\":52545},{\"end\":52565,\"start\":52558},{\"end\":52868,\"start\":52864},{\"end\":52885,\"start\":52881},{\"end\":52905,\"start\":52897},{\"end\":52907,\"start\":52906},{\"end\":53174,\"start\":53170},{\"end\":53186,\"start\":53182},{\"end\":53201,\"start\":53195},{\"end\":53218,\"start\":53210},{\"end\":53516,\"start\":53509},{\"end\":53526,\"start\":53522},{\"end\":53530,\"start\":53527},{\"end\":53835,\"start\":53828},{\"end\":53845,\"start\":53841},{\"end\":53849,\"start\":53846},{\"end\":54187,\"start\":54177},{\"end\":54198,\"start\":54192},{\"end\":54212,\"start\":54205},{\"end\":54224,\"start\":54219},{\"end\":54532,\"start\":54526},{\"end\":54542,\"start\":54537},{\"end\":54558,\"start\":54554},{\"end\":54908,\"start\":54902},{\"end\":54917,\"start\":54913},{\"end\":54928,\"start\":54922},{\"end\":54943,\"start\":54936},{\"end\":54952,\"start\":54948},{\"end\":54966,\"start\":54958},{\"end\":54979,\"start\":54973},{\"end\":55285,\"start\":55282},{\"end\":55297,\"start\":55291},{\"end\":55309,\"start\":55303},{\"end\":55324,\"start\":55316},{\"end\":55617,\"start\":55612},{\"end\":55633,\"start\":55623},{\"end\":55647,\"start\":55638},{\"end\":55950,\"start\":55945},{\"end\":55963,\"start\":55956},{\"end\":55979,\"start\":55969},{\"end\":55990,\"start\":55986},{\"end\":56005,\"start\":55998},{\"end\":56353,\"start\":56349},{\"end\":56366,\"start\":56358},{\"end\":56377,\"start\":56372},{\"end\":56601,\"start\":56596},{\"end\":56611,\"start\":56606},{\"end\":56622,\"start\":56616},{\"end\":56637,\"start\":56630},{\"end\":56649,\"start\":56645},{\"end\":56914,\"start\":56908},{\"end\":56925,\"start\":56920},{\"end\":56932,\"start\":56931},{\"end\":56946,\"start\":56939},{\"end\":56956,\"start\":56953},{\"end\":56968,\"start\":56961},{\"end\":56980,\"start\":56973},{\"end\":57299,\"start\":57293},{\"end\":57308,\"start\":57305},{\"end\":57322,\"start\":57314},{\"end\":57571,\"start\":57566},{\"end\":57584,\"start\":57583},{\"end\":57586,\"start\":57585},{\"end\":57601,\"start\":57596},{\"end\":57616,\"start\":57612},{\"end\":57877,\"start\":57872},{\"end\":57892,\"start\":57886},{\"end\":57907,\"start\":57900},{\"end\":58166,\"start\":58161},{\"end\":58181,\"start\":58173},{\"end\":58183,\"start\":58182},{\"end\":58441,\"start\":58437},{\"end\":58761,\"start\":58753},{\"end\":58773,\"start\":58768},{\"end\":58786,\"start\":58779},{\"end\":59125,\"start\":59117},{\"end\":59140,\"start\":59132},{\"end\":59152,\"start\":59146},{\"end\":59456,\"start\":59444},{\"end\":59477,\"start\":59470},{\"end\":59792,\"start\":59780},{\"end\":59813,\"start\":59806},{\"end\":59826,\"start\":59821},{\"end\":60128,\"start\":60116},{\"end\":60149,\"start\":60142},{\"end\":60151,\"start\":60150},{\"end\":60169,\"start\":60159},{\"end\":60538,\"start\":60531},{\"end\":60556,\"start\":60552},{\"end\":60570,\"start\":60563},{\"end\":60585,\"start\":60580},{\"end\":60601,\"start\":60597},{\"end\":60936,\"start\":60929},{\"end\":60954,\"start\":60950},{\"end\":60966,\"start\":60961},{\"end\":60983,\"start\":60978},{\"end\":61000,\"start\":60995},{\"end\":61016,\"start\":61012},{\"end\":61367,\"start\":61360},{\"end\":61391,\"start\":61385},{\"end\":61418,\"start\":61412},{\"end\":61420,\"start\":61419},{\"end\":61779,\"start\":61774},{\"end\":61796,\"start\":61789},{\"end\":61808,\"start\":61804},{\"end\":62150,\"start\":62142},{\"end\":62167,\"start\":62161},{\"end\":62183,\"start\":62176},{\"end\":62199,\"start\":62191},{\"end\":62606,\"start\":62598},{\"end\":62623,\"start\":62617},{\"end\":62639,\"start\":62632},{\"end\":62652,\"start\":62647},{\"end\":62669,\"start\":62661},{\"end\":63025,\"start\":63017},{\"end\":63042,\"start\":63036},{\"end\":63059,\"start\":63053},{\"end\":63073,\"start\":63068},{\"end\":63091,\"start\":63084},{\"end\":63106,\"start\":63099},{\"end\":63118,\"start\":63113},{\"end\":63399,\"start\":63395},{\"end\":63416,\"start\":63408},{\"end\":63433,\"start\":63425},{\"end\":63435,\"start\":63434},{\"end\":63677,\"start\":63672},{\"end\":63688,\"start\":63685},{\"end\":63703,\"start\":63698},{\"end\":63975,\"start\":63963},{\"end\":63991,\"start\":63984},{\"end\":64008,\"start\":64001},{\"end\":64030,\"start\":64022},{\"end\":64032,\"start\":64031},{\"end\":64046,\"start\":64041},{\"end\":64048,\"start\":64047},{\"end\":64379,\"start\":64370},{\"end\":64394,\"start\":64391},{\"end\":64662,\"start\":64661},{\"end\":64683,\"start\":64676},{\"end\":64703,\"start\":64695},{\"end\":64725,\"start\":64714},{\"end\":64735,\"start\":64731},{\"end\":64751,\"start\":64746},{\"end\":65107,\"start\":65101},{\"end\":65124,\"start\":65119},{\"end\":65137,\"start\":65131},{\"end\":65153,\"start\":65147},{\"end\":65467,\"start\":65462},{\"end\":65481,\"start\":65477},{\"end\":65495,\"start\":65488},{\"end\":65760,\"start\":65757},{\"end\":65771,\"start\":65766},{\"end\":65780,\"start\":65777},{\"end\":65790,\"start\":65785},{\"end\":66090,\"start\":66084},{\"end\":66100,\"start\":66096},{\"end\":66113,\"start\":66106},{\"end\":66390,\"start\":66387},{\"end\":66400,\"start\":66397},{\"end\":66415,\"start\":66407},{\"end\":66427,\"start\":66423},{\"end\":66441,\"start\":66434},{\"end\":66450,\"start\":66446},{\"end\":66763,\"start\":66762},{\"end\":66765,\"start\":66764},{\"end\":66777,\"start\":66772},{\"end\":67012,\"start\":67003},{\"end\":67369,\"start\":67363},{\"end\":67383,\"start\":67376},{\"end\":67395,\"start\":67389},{\"end\":67672,\"start\":67668},{\"end\":67681,\"start\":67677},{\"end\":67691,\"start\":67687},{\"end\":68069,\"start\":68061},{\"end\":68079,\"start\":68074},{\"end\":68081,\"start\":68080},{\"end\":68096,\"start\":68089},{\"end\":68424,\"start\":68421},{\"end\":68432,\"start\":68429},{\"end\":68443,\"start\":68438},{\"end\":68455,\"start\":68451},{\"end\":68787,\"start\":68782},{\"end\":68799,\"start\":68792},{\"end\":69077,\"start\":69072},{\"end\":69086,\"start\":69082},{\"end\":69100,\"start\":69093},{\"end\":69108,\"start\":69106},{\"end\":69121,\"start\":69114},{\"end\":69134,\"start\":69126},{\"end\":69146,\"start\":69140},{\"end\":69509,\"start\":69503},{\"end\":69543,\"start\":69535},{\"end\":69557,\"start\":69549},{\"end\":69908,\"start\":69902},{\"end\":69925,\"start\":69920},{\"end\":69942,\"start\":69935},{\"end\":70253,\"start\":70252},{\"end\":70266,\"start\":70263},{\"end\":70556,\"start\":70549},{\"end\":70566,\"start\":70564},{\"end\":70580,\"start\":70573},{\"end\":70595,\"start\":70588},{\"end\":70910,\"start\":70907},{\"end\":70919,\"start\":70917},{\"end\":70933,\"start\":70929},{\"end\":70935,\"start\":70934},{\"end\":71211,\"start\":71206},{\"end\":71227,\"start\":71222},{\"end\":71238,\"start\":71234},{\"end\":71255,\"start\":71249},{\"end\":71270,\"start\":71265}]", "bib_author_last_name": "[{\"end\":42662,\"start\":42658},{\"end\":42675,\"start\":42669},{\"end\":42691,\"start\":42682},{\"end\":42706,\"start\":42699},{\"end\":43061,\"start\":43056},{\"end\":43074,\"start\":43069},{\"end\":43284,\"start\":43278},{\"end\":43309,\"start\":43303},{\"end\":43324,\"start\":43321},{\"end\":43338,\"start\":43335},{\"end\":43599,\"start\":43593},{\"end\":43624,\"start\":43618},{\"end\":43638,\"start\":43635},{\"end\":43945,\"start\":43937},{\"end\":43961,\"start\":43955},{\"end\":43979,\"start\":43969},{\"end\":43995,\"start\":43989},{\"end\":44337,\"start\":44329},{\"end\":44353,\"start\":44347},{\"end\":44371,\"start\":44361},{\"end\":44387,\"start\":44381},{\"end\":44703,\"start\":44696},{\"end\":44720,\"start\":44711},{\"end\":44738,\"start\":44730},{\"end\":44756,\"start\":44747},{\"end\":45142,\"start\":45137},{\"end\":45158,\"start\":45154},{\"end\":45174,\"start\":45170},{\"end\":45485,\"start\":45481},{\"end\":45493,\"start\":45489},{\"end\":45500,\"start\":45497},{\"end\":45768,\"start\":45762},{\"end\":45786,\"start\":45780},{\"end\":45804,\"start\":45798},{\"end\":45822,\"start\":45814},{\"end\":46147,\"start\":46137},{\"end\":46165,\"start\":46158},{\"end\":46181,\"start\":46175},{\"end\":46472,\"start\":46468},{\"end\":46482,\"start\":46477},{\"end\":46495,\"start\":46492},{\"end\":46745,\"start\":46740},{\"end\":46759,\"start\":46753},{\"end\":47011,\"start\":47004},{\"end\":47024,\"start\":47019},{\"end\":47034,\"start\":47026},{\"end\":47284,\"start\":47281},{\"end\":47299,\"start\":47294},{\"end\":47311,\"start\":47305},{\"end\":47322,\"start\":47320},{\"end\":47332,\"start\":47327},{\"end\":47341,\"start\":47339},{\"end\":47634,\"start\":47630},{\"end\":47645,\"start\":47641},{\"end\":47659,\"start\":47657},{\"end\":47921,\"start\":47912},{\"end\":47939,\"start\":47931},{\"end\":47951,\"start\":47947},{\"end\":47966,\"start\":47959},{\"end\":47987,\"start\":47975},{\"end\":48004,\"start\":47997},{\"end\":48010,\"start\":48006},{\"end\":48414,\"start\":48405},{\"end\":48428,\"start\":48421},{\"end\":48455,\"start\":48437},{\"end\":48472,\"start\":48465},{\"end\":48478,\"start\":48474},{\"end\":49030,\"start\":49026},{\"end\":49044,\"start\":49041},{\"end\":49054,\"start\":49052},{\"end\":49071,\"start\":49067},{\"end\":49392,\"start\":49389},{\"end\":49407,\"start\":49404},{\"end\":49419,\"start\":49415},{\"end\":49430,\"start\":49427},{\"end\":49447,\"start\":49442},{\"end\":49457,\"start\":49454},{\"end\":49858,\"start\":49853},{\"end\":49873,\"start\":49869},{\"end\":49886,\"start\":49879},{\"end\":49894,\"start\":49890},{\"end\":49917,\"start\":49904},{\"end\":49924,\"start\":49919},{\"end\":50229,\"start\":50220},{\"end\":50246,\"start\":50240},{\"end\":50262,\"start\":50253},{\"end\":50559,\"start\":50553},{\"end\":50568,\"start\":50565},{\"end\":50590,\"start\":50585},{\"end\":50843,\"start\":50841},{\"end\":50852,\"start\":50848},{\"end\":50862,\"start\":50859},{\"end\":51122,\"start\":51104},{\"end\":51152,\"start\":51140},{\"end\":51168,\"start\":51159},{\"end\":51174,\"start\":51170},{\"end\":51492,\"start\":51474},{\"end\":51510,\"start\":51501},{\"end\":51524,\"start\":51519},{\"end\":51533,\"start\":51526},{\"end\":51821,\"start\":51803},{\"end\":51839,\"start\":51830},{\"end\":51855,\"start\":51848},{\"end\":51862,\"start\":51857},{\"end\":52195,\"start\":52193},{\"end\":52207,\"start\":52205},{\"end\":52221,\"start\":52218},{\"end\":52556,\"start\":52553},{\"end\":52573,\"start\":52566},{\"end\":52879,\"start\":52869},{\"end\":52895,\"start\":52886},{\"end\":52914,\"start\":52908},{\"end\":53180,\"start\":53175},{\"end\":53193,\"start\":53187},{\"end\":53208,\"start\":53202},{\"end\":53226,\"start\":53219},{\"end\":53520,\"start\":53517},{\"end\":53541,\"start\":53531},{\"end\":53545,\"start\":53543},{\"end\":53839,\"start\":53836},{\"end\":53860,\"start\":53850},{\"end\":53864,\"start\":53862},{\"end\":54190,\"start\":54188},{\"end\":54203,\"start\":54199},{\"end\":54217,\"start\":54213},{\"end\":54232,\"start\":54225},{\"end\":54535,\"start\":54533},{\"end\":54552,\"start\":54543},{\"end\":54570,\"start\":54559},{\"end\":54911,\"start\":54909},{\"end\":54920,\"start\":54918},{\"end\":54934,\"start\":54929},{\"end\":54946,\"start\":54944},{\"end\":54956,\"start\":54953},{\"end\":54971,\"start\":54967},{\"end\":54984,\"start\":54980},{\"end\":55289,\"start\":55286},{\"end\":55301,\"start\":55298},{\"end\":55314,\"start\":55310},{\"end\":55328,\"start\":55325},{\"end\":55621,\"start\":55618},{\"end\":55636,\"start\":55634},{\"end\":55654,\"start\":55648},{\"end\":55954,\"start\":55951},{\"end\":55967,\"start\":55964},{\"end\":55984,\"start\":55980},{\"end\":55996,\"start\":55991},{\"end\":56008,\"start\":56006},{\"end\":56356,\"start\":56354},{\"end\":56370,\"start\":56367},{\"end\":56381,\"start\":56378},{\"end\":56604,\"start\":56602},{\"end\":56614,\"start\":56612},{\"end\":56628,\"start\":56623},{\"end\":56643,\"start\":56638},{\"end\":56654,\"start\":56650},{\"end\":56918,\"start\":56915},{\"end\":56929,\"start\":56926},{\"end\":56937,\"start\":56933},{\"end\":56951,\"start\":56947},{\"end\":56959,\"start\":56957},{\"end\":56971,\"start\":56969},{\"end\":56985,\"start\":56981},{\"end\":57303,\"start\":57300},{\"end\":57312,\"start\":57309},{\"end\":57326,\"start\":57323},{\"end\":57581,\"start\":57572},{\"end\":57594,\"start\":57587},{\"end\":57610,\"start\":57602},{\"end\":57628,\"start\":57617},{\"end\":57884,\"start\":57878},{\"end\":57898,\"start\":57893},{\"end\":57912,\"start\":57908},{\"end\":58171,\"start\":58167},{\"end\":58190,\"start\":58184},{\"end\":58461,\"start\":58442},{\"end\":58470,\"start\":58463},{\"end\":58766,\"start\":58762},{\"end\":58777,\"start\":58774},{\"end\":58791,\"start\":58787},{\"end\":59130,\"start\":59126},{\"end\":59144,\"start\":59141},{\"end\":59156,\"start\":59153},{\"end\":59468,\"start\":59457},{\"end\":59483,\"start\":59478},{\"end\":59804,\"start\":59793},{\"end\":59819,\"start\":59814},{\"end\":59835,\"start\":59827},{\"end\":60140,\"start\":60129},{\"end\":60157,\"start\":60152},{\"end\":60178,\"start\":60170},{\"end\":60550,\"start\":60539},{\"end\":60561,\"start\":60557},{\"end\":60578,\"start\":60571},{\"end\":60595,\"start\":60586},{\"end\":60606,\"start\":60602},{\"end\":60948,\"start\":60937},{\"end\":60959,\"start\":60955},{\"end\":60976,\"start\":60967},{\"end\":60993,\"start\":60984},{\"end\":61010,\"start\":61001},{\"end\":61021,\"start\":61017},{\"end\":61378,\"start\":61368},{\"end\":61383,\"start\":61380},{\"end\":61410,\"start\":61392},{\"end\":61429,\"start\":61421},{\"end\":61439,\"start\":61431},{\"end\":61787,\"start\":61780},{\"end\":61802,\"start\":61797},{\"end\":61818,\"start\":61809},{\"end\":62159,\"start\":62151},{\"end\":62174,\"start\":62168},{\"end\":62189,\"start\":62184},{\"end\":62206,\"start\":62200},{\"end\":62615,\"start\":62607},{\"end\":62630,\"start\":62624},{\"end\":62645,\"start\":62640},{\"end\":62659,\"start\":62653},{\"end\":62676,\"start\":62670},{\"end\":63034,\"start\":63026},{\"end\":63051,\"start\":63043},{\"end\":63066,\"start\":63060},{\"end\":63082,\"start\":63074},{\"end\":63097,\"start\":63092},{\"end\":63111,\"start\":63107},{\"end\":63124,\"start\":63119},{\"end\":63406,\"start\":63400},{\"end\":63423,\"start\":63417},{\"end\":63442,\"start\":63436},{\"end\":63683,\"start\":63678},{\"end\":63696,\"start\":63689},{\"end\":63712,\"start\":63704},{\"end\":63982,\"start\":63976},{\"end\":63999,\"start\":63992},{\"end\":64020,\"start\":64009},{\"end\":64039,\"start\":64033},{\"end\":64055,\"start\":64049},{\"end\":64389,\"start\":64380},{\"end\":64399,\"start\":64395},{\"end\":64674,\"start\":64663},{\"end\":64693,\"start\":64684},{\"end\":64712,\"start\":64704},{\"end\":64729,\"start\":64726},{\"end\":64744,\"start\":64736},{\"end\":64758,\"start\":64752},{\"end\":64765,\"start\":64760},{\"end\":65117,\"start\":65108},{\"end\":65129,\"start\":65125},{\"end\":65145,\"start\":65138},{\"end\":65161,\"start\":65154},{\"end\":65168,\"start\":65163},{\"end\":65475,\"start\":65468},{\"end\":65486,\"start\":65482},{\"end\":65500,\"start\":65496},{\"end\":65764,\"start\":65761},{\"end\":65775,\"start\":65772},{\"end\":65783,\"start\":65781},{\"end\":65793,\"start\":65791},{\"end\":66094,\"start\":66091},{\"end\":66104,\"start\":66101},{\"end\":66120,\"start\":66114},{\"end\":66395,\"start\":66391},{\"end\":66405,\"start\":66401},{\"end\":66421,\"start\":66416},{\"end\":66432,\"start\":66428},{\"end\":66444,\"start\":66442},{\"end\":66455,\"start\":66451},{\"end\":66770,\"start\":66766},{\"end\":66782,\"start\":66778},{\"end\":66788,\"start\":66784},{\"end\":67027,\"start\":67013},{\"end\":67039,\"start\":67029},{\"end\":67045,\"start\":67041},{\"end\":67374,\"start\":67370},{\"end\":67387,\"start\":67384},{\"end\":67401,\"start\":67396},{\"end\":67675,\"start\":67673},{\"end\":67685,\"start\":67682},{\"end\":67696,\"start\":67692},{\"end\":68072,\"start\":68070},{\"end\":68087,\"start\":68082},{\"end\":68101,\"start\":68097},{\"end\":68427,\"start\":68425},{\"end\":68436,\"start\":68433},{\"end\":68449,\"start\":68444},{\"end\":68460,\"start\":68456},{\"end\":68790,\"start\":68788},{\"end\":68804,\"start\":68800},{\"end\":69080,\"start\":69078},{\"end\":69091,\"start\":69087},{\"end\":69104,\"start\":69101},{\"end\":69112,\"start\":69109},{\"end\":69124,\"start\":69122},{\"end\":69138,\"start\":69135},{\"end\":69152,\"start\":69147},{\"end\":69533,\"start\":69510},{\"end\":69547,\"start\":69544},{\"end\":69564,\"start\":69558},{\"end\":69569,\"start\":69566},{\"end\":69918,\"start\":69909},{\"end\":69933,\"start\":69926},{\"end\":69949,\"start\":69943},{\"end\":70261,\"start\":70254},{\"end\":70273,\"start\":70267},{\"end\":70281,\"start\":70275},{\"end\":70562,\"start\":70557},{\"end\":70571,\"start\":70567},{\"end\":70586,\"start\":70581},{\"end\":70601,\"start\":70596},{\"end\":70915,\"start\":70911},{\"end\":70927,\"start\":70920},{\"end\":70940,\"start\":70936},{\"end\":71220,\"start\":71212},{\"end\":71232,\"start\":71228},{\"end\":71247,\"start\":71239},{\"end\":71263,\"start\":71256},{\"end\":71281,\"start\":71271}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":14648950},\"end\":43004,\"start\":42572},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":14053425},\"end\":43228,\"start\":43006},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":239024474},\"end\":43512,\"start\":43230},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":239024750},\"end\":43849,\"start\":43514},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":189857704},\"end\":44228,\"start\":43851},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":207880670},\"end\":44631,\"start\":44230},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":13356813},\"end\":45011,\"start\":44633},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":5858418},\"end\":45420,\"start\":45013},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":7490062},\"end\":45666,\"start\":45422},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":226976039},\"end\":46061,\"start\":45668},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":7241698},\"end\":46383,\"start\":46063},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":218834415},\"end\":46670,\"start\":46385},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":214802548},\"end\":46931,\"start\":46672},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1110984},\"end\":47221,\"start\":46933},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":219687613},\"end\":47563,\"start\":47223},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":207115581},\"end\":47822,\"start\":47565},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":226964553},\"end\":48290,\"start\":47824},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":233293201},\"end\":48844,\"start\":48292},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":102353587},\"end\":49383,\"start\":48846},{\"attributes\":{\"doi\":\"arXiv:2104.14430\",\"id\":\"b19\"},\"end\":49793,\"start\":49385},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":2429016},\"end\":50147,\"start\":49795},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":53669904},\"end\":50459,\"start\":50149},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":20635214},\"end\":50802,\"start\":50461},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":140309863},\"end\":51008,\"start\":50804},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":54475483},\"end\":51425,\"start\":51010},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":12118158},\"end\":51724,\"start\":51427},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":53875671},\"end\":52087,\"start\":51726},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":221543494},\"end\":52433,\"start\":52089},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":561197},\"end\":52797,\"start\":52435},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":195908774},\"end\":53111,\"start\":52799},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":14542261},\"end\":53434,\"start\":53113},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":5053204},\"end\":53743,\"start\":53436},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":204965884},\"end\":54100,\"start\":53745},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":233204792},\"end\":54470,\"start\":54102},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3143815},\"end\":54827,\"start\":54472},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":221669098},\"end\":55217,\"start\":54829},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":3865699},\"end\":55553,\"start\":55219},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":52290309},\"end\":55825,\"start\":55555},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":237091198},\"end\":56300,\"start\":55827},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":6070091},\"end\":56551,\"start\":56302},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":220525322},\"end\":56838,\"start\":56553},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":209531629},\"end\":57214,\"start\":56840},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":19052864},\"end\":57527,\"start\":57216},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":206591190},\"end\":57810,\"start\":57529},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":2430392},\"end\":58097,\"start\":57812},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":15539264},\"end\":58360,\"start\":58099},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":201070056},\"end\":58674,\"start\":58362},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":212725213},\"end\":59059,\"start\":58676},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":214713500},\"end\":59361,\"start\":59061},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":62988676},\"end\":59693,\"start\":59363},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":210920560},\"end\":60064,\"start\":59695},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":215745350},\"end\":60440,\"start\":60066},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":13692638},\"end\":60857,\"start\":60442},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":3477836},\"end\":61277,\"start\":60859},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":216612544},\"end\":61690,\"start\":61279},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":221370646},\"end\":62029,\"start\":61692},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":16951789},\"end\":62501,\"start\":62031},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":13590446},\"end\":62966,\"start\":62503},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":43948826},\"end\":63359,\"start\":62968},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":3603485},\"end\":63607,\"start\":63361},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":1659589},\"end\":63899,\"start\":63609},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":227126845},\"end\":64305,\"start\":63901},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":5445347},\"end\":64577,\"start\":64307},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":15019293},\"end\":65032,\"start\":64579},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":10297336},\"end\":65407,\"start\":65034},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":1610415},\"end\":65672,\"start\":65409},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":222278685},\"end\":66001,\"start\":65674},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":40558661},\"end\":66320,\"start\":66003},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":209901760},\"end\":66691,\"start\":66322},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":52273621},\"end\":66952,\"start\":66693},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":215870627},\"end\":67305,\"start\":66954},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":222278287},\"end\":67585,\"start\":67307},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":202003755},\"end\":67963,\"start\":67587},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":14411054},\"end\":68323,\"start\":67965},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":3949944},\"end\":68711,\"start\":68325},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":220250825},\"end\":68979,\"start\":68713},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":221340734},\"end\":69411,\"start\":68981},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":215786155},\"end\":69810,\"start\":69413},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":237142564},\"end\":70196,\"start\":69812},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":3960646},\"end\":70444,\"start\":70198},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":218998873},\"end\":70833,\"start\":70446},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":7151015},\"end\":71127,\"start\":70835},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":55701890},\"end\":71501,\"start\":71129}]", "bib_title": "[{\"end\":42651,\"start\":42572},{\"end\":43045,\"start\":43006},{\"end\":43267,\"start\":43230},{\"end\":43582,\"start\":43514},{\"end\":43930,\"start\":43851},{\"end\":44322,\"start\":44230},{\"end\":44688,\"start\":44633},{\"end\":45127,\"start\":45013},{\"end\":45477,\"start\":45422},{\"end\":45753,\"start\":45668},{\"end\":46127,\"start\":46063},{\"end\":46462,\"start\":46385},{\"end\":46732,\"start\":46672},{\"end\":47000,\"start\":46933},{\"end\":47276,\"start\":47223},{\"end\":47619,\"start\":47565},{\"end\":47894,\"start\":47824},{\"end\":48387,\"start\":48292},{\"end\":49019,\"start\":48846},{\"end\":49842,\"start\":49795},{\"end\":50209,\"start\":50149},{\"end\":50545,\"start\":50461},{\"end\":50835,\"start\":50804},{\"end\":51096,\"start\":51010},{\"end\":51465,\"start\":51427},{\"end\":51794,\"start\":51726},{\"end\":52183,\"start\":52089},{\"end\":52543,\"start\":52435},{\"end\":52862,\"start\":52799},{\"end\":53168,\"start\":53113},{\"end\":53507,\"start\":53436},{\"end\":53826,\"start\":53745},{\"end\":54175,\"start\":54102},{\"end\":54524,\"start\":54472},{\"end\":54900,\"start\":54829},{\"end\":55280,\"start\":55219},{\"end\":55610,\"start\":55555},{\"end\":55943,\"start\":55827},{\"end\":56347,\"start\":56302},{\"end\":56594,\"start\":56553},{\"end\":56906,\"start\":56840},{\"end\":57291,\"start\":57216},{\"end\":57564,\"start\":57529},{\"end\":57870,\"start\":57812},{\"end\":58159,\"start\":58099},{\"end\":58435,\"start\":58362},{\"end\":58751,\"start\":58676},{\"end\":59115,\"start\":59061},{\"end\":59442,\"start\":59363},{\"end\":59778,\"start\":59695},{\"end\":60114,\"start\":60066},{\"end\":60529,\"start\":60442},{\"end\":60927,\"start\":60859},{\"end\":61358,\"start\":61279},{\"end\":61772,\"start\":61692},{\"end\":62140,\"start\":62031},{\"end\":62596,\"start\":62503},{\"end\":63015,\"start\":62968},{\"end\":63393,\"start\":63361},{\"end\":63670,\"start\":63609},{\"end\":63961,\"start\":63901},{\"end\":64368,\"start\":64307},{\"end\":64659,\"start\":64579},{\"end\":65099,\"start\":65034},{\"end\":65460,\"start\":65409},{\"end\":65755,\"start\":65674},{\"end\":66082,\"start\":66003},{\"end\":66385,\"start\":66322},{\"end\":66760,\"start\":66693},{\"end\":67001,\"start\":66954},{\"end\":67361,\"start\":67307},{\"end\":67666,\"start\":67587},{\"end\":68059,\"start\":67965},{\"end\":68419,\"start\":68325},{\"end\":68780,\"start\":68713},{\"end\":69070,\"start\":68981},{\"end\":69501,\"start\":69413},{\"end\":69900,\"start\":69812},{\"end\":70250,\"start\":70198},{\"end\":70547,\"start\":70446},{\"end\":70905,\"start\":70835},{\"end\":71204,\"start\":71129}]", "bib_author": "[{\"end\":42664,\"start\":42653},{\"end\":42677,\"start\":42664},{\"end\":42693,\"start\":42677},{\"end\":42708,\"start\":42693},{\"end\":43063,\"start\":43047},{\"end\":43076,\"start\":43063},{\"end\":43286,\"start\":43269},{\"end\":43311,\"start\":43286},{\"end\":43326,\"start\":43311},{\"end\":43340,\"start\":43326},{\"end\":43601,\"start\":43584},{\"end\":43626,\"start\":43601},{\"end\":43640,\"start\":43626},{\"end\":43947,\"start\":43932},{\"end\":43963,\"start\":43947},{\"end\":43981,\"start\":43963},{\"end\":43997,\"start\":43981},{\"end\":44339,\"start\":44324},{\"end\":44355,\"start\":44339},{\"end\":44373,\"start\":44355},{\"end\":44389,\"start\":44373},{\"end\":44705,\"start\":44690},{\"end\":44722,\"start\":44705},{\"end\":44740,\"start\":44722},{\"end\":44758,\"start\":44740},{\"end\":45144,\"start\":45129},{\"end\":45160,\"start\":45144},{\"end\":45176,\"start\":45160},{\"end\":45487,\"start\":45479},{\"end\":45495,\"start\":45487},{\"end\":45502,\"start\":45495},{\"end\":45770,\"start\":45755},{\"end\":45788,\"start\":45770},{\"end\":45806,\"start\":45788},{\"end\":45824,\"start\":45806},{\"end\":46149,\"start\":46129},{\"end\":46167,\"start\":46149},{\"end\":46183,\"start\":46167},{\"end\":46474,\"start\":46464},{\"end\":46484,\"start\":46474},{\"end\":46497,\"start\":46484},{\"end\":46747,\"start\":46734},{\"end\":46761,\"start\":46747},{\"end\":47013,\"start\":47002},{\"end\":47026,\"start\":47013},{\"end\":47036,\"start\":47026},{\"end\":47286,\"start\":47278},{\"end\":47301,\"start\":47286},{\"end\":47313,\"start\":47301},{\"end\":47324,\"start\":47313},{\"end\":47334,\"start\":47324},{\"end\":47343,\"start\":47334},{\"end\":47636,\"start\":47621},{\"end\":47647,\"start\":47636},{\"end\":47661,\"start\":47647},{\"end\":47923,\"start\":47896},{\"end\":47941,\"start\":47923},{\"end\":47953,\"start\":47941},{\"end\":47968,\"start\":47953},{\"end\":47989,\"start\":47968},{\"end\":48006,\"start\":47989},{\"end\":48012,\"start\":48006},{\"end\":48416,\"start\":48389},{\"end\":48430,\"start\":48416},{\"end\":48457,\"start\":48430},{\"end\":48474,\"start\":48457},{\"end\":48480,\"start\":48474},{\"end\":49032,\"start\":49021},{\"end\":49046,\"start\":49032},{\"end\":49056,\"start\":49046},{\"end\":49073,\"start\":49056},{\"end\":49394,\"start\":49385},{\"end\":49409,\"start\":49394},{\"end\":49421,\"start\":49409},{\"end\":49432,\"start\":49421},{\"end\":49449,\"start\":49432},{\"end\":49459,\"start\":49449},{\"end\":49860,\"start\":49844},{\"end\":49875,\"start\":49860},{\"end\":49888,\"start\":49875},{\"end\":49896,\"start\":49888},{\"end\":49919,\"start\":49896},{\"end\":49926,\"start\":49919},{\"end\":50231,\"start\":50211},{\"end\":50248,\"start\":50231},{\"end\":50264,\"start\":50248},{\"end\":50561,\"start\":50547},{\"end\":50570,\"start\":50561},{\"end\":50592,\"start\":50570},{\"end\":50845,\"start\":50837},{\"end\":50854,\"start\":50845},{\"end\":50864,\"start\":50854},{\"end\":51124,\"start\":51098},{\"end\":51154,\"start\":51124},{\"end\":51170,\"start\":51154},{\"end\":51176,\"start\":51170},{\"end\":51494,\"start\":51467},{\"end\":51512,\"start\":51494},{\"end\":51526,\"start\":51512},{\"end\":51535,\"start\":51526},{\"end\":51823,\"start\":51796},{\"end\":51841,\"start\":51823},{\"end\":51857,\"start\":51841},{\"end\":51864,\"start\":51857},{\"end\":52197,\"start\":52185},{\"end\":52209,\"start\":52197},{\"end\":52223,\"start\":52209},{\"end\":52558,\"start\":52545},{\"end\":52575,\"start\":52558},{\"end\":52881,\"start\":52864},{\"end\":52897,\"start\":52881},{\"end\":52916,\"start\":52897},{\"end\":53182,\"start\":53170},{\"end\":53195,\"start\":53182},{\"end\":53210,\"start\":53195},{\"end\":53228,\"start\":53210},{\"end\":53522,\"start\":53509},{\"end\":53543,\"start\":53522},{\"end\":53547,\"start\":53543},{\"end\":53841,\"start\":53828},{\"end\":53862,\"start\":53841},{\"end\":53866,\"start\":53862},{\"end\":54192,\"start\":54177},{\"end\":54205,\"start\":54192},{\"end\":54219,\"start\":54205},{\"end\":54234,\"start\":54219},{\"end\":54537,\"start\":54526},{\"end\":54554,\"start\":54537},{\"end\":54572,\"start\":54554},{\"end\":54913,\"start\":54902},{\"end\":54922,\"start\":54913},{\"end\":54936,\"start\":54922},{\"end\":54948,\"start\":54936},{\"end\":54958,\"start\":54948},{\"end\":54973,\"start\":54958},{\"end\":54986,\"start\":54973},{\"end\":55291,\"start\":55282},{\"end\":55303,\"start\":55291},{\"end\":55316,\"start\":55303},{\"end\":55330,\"start\":55316},{\"end\":55623,\"start\":55612},{\"end\":55638,\"start\":55623},{\"end\":55656,\"start\":55638},{\"end\":55956,\"start\":55945},{\"end\":55969,\"start\":55956},{\"end\":55986,\"start\":55969},{\"end\":55998,\"start\":55986},{\"end\":56010,\"start\":55998},{\"end\":56358,\"start\":56349},{\"end\":56372,\"start\":56358},{\"end\":56383,\"start\":56372},{\"end\":56606,\"start\":56596},{\"end\":56616,\"start\":56606},{\"end\":56630,\"start\":56616},{\"end\":56645,\"start\":56630},{\"end\":56656,\"start\":56645},{\"end\":56920,\"start\":56908},{\"end\":56931,\"start\":56920},{\"end\":56939,\"start\":56931},{\"end\":56953,\"start\":56939},{\"end\":56961,\"start\":56953},{\"end\":56973,\"start\":56961},{\"end\":56987,\"start\":56973},{\"end\":57305,\"start\":57293},{\"end\":57314,\"start\":57305},{\"end\":57328,\"start\":57314},{\"end\":57583,\"start\":57566},{\"end\":57596,\"start\":57583},{\"end\":57612,\"start\":57596},{\"end\":57630,\"start\":57612},{\"end\":57886,\"start\":57872},{\"end\":57900,\"start\":57886},{\"end\":57914,\"start\":57900},{\"end\":58173,\"start\":58161},{\"end\":58192,\"start\":58173},{\"end\":58463,\"start\":58437},{\"end\":58472,\"start\":58463},{\"end\":58768,\"start\":58753},{\"end\":58779,\"start\":58768},{\"end\":58793,\"start\":58779},{\"end\":59132,\"start\":59117},{\"end\":59146,\"start\":59132},{\"end\":59158,\"start\":59146},{\"end\":59470,\"start\":59444},{\"end\":59485,\"start\":59470},{\"end\":59806,\"start\":59780},{\"end\":59821,\"start\":59806},{\"end\":59837,\"start\":59821},{\"end\":60142,\"start\":60116},{\"end\":60159,\"start\":60142},{\"end\":60180,\"start\":60159},{\"end\":60552,\"start\":60531},{\"end\":60563,\"start\":60552},{\"end\":60580,\"start\":60563},{\"end\":60597,\"start\":60580},{\"end\":60608,\"start\":60597},{\"end\":60950,\"start\":60929},{\"end\":60961,\"start\":60950},{\"end\":60978,\"start\":60961},{\"end\":60995,\"start\":60978},{\"end\":61012,\"start\":60995},{\"end\":61023,\"start\":61012},{\"end\":61380,\"start\":61360},{\"end\":61385,\"start\":61380},{\"end\":61412,\"start\":61385},{\"end\":61431,\"start\":61412},{\"end\":61441,\"start\":61431},{\"end\":61789,\"start\":61774},{\"end\":61804,\"start\":61789},{\"end\":61820,\"start\":61804},{\"end\":62161,\"start\":62142},{\"end\":62176,\"start\":62161},{\"end\":62191,\"start\":62176},{\"end\":62208,\"start\":62191},{\"end\":62617,\"start\":62598},{\"end\":62632,\"start\":62617},{\"end\":62647,\"start\":62632},{\"end\":62661,\"start\":62647},{\"end\":62678,\"start\":62661},{\"end\":63036,\"start\":63017},{\"end\":63053,\"start\":63036},{\"end\":63068,\"start\":63053},{\"end\":63084,\"start\":63068},{\"end\":63099,\"start\":63084},{\"end\":63113,\"start\":63099},{\"end\":63126,\"start\":63113},{\"end\":63408,\"start\":63395},{\"end\":63425,\"start\":63408},{\"end\":63444,\"start\":63425},{\"end\":63685,\"start\":63672},{\"end\":63698,\"start\":63685},{\"end\":63714,\"start\":63698},{\"end\":63984,\"start\":63963},{\"end\":64001,\"start\":63984},{\"end\":64022,\"start\":64001},{\"end\":64041,\"start\":64022},{\"end\":64057,\"start\":64041},{\"end\":64391,\"start\":64370},{\"end\":64401,\"start\":64391},{\"end\":64676,\"start\":64661},{\"end\":64695,\"start\":64676},{\"end\":64714,\"start\":64695},{\"end\":64731,\"start\":64714},{\"end\":64746,\"start\":64731},{\"end\":64760,\"start\":64746},{\"end\":64767,\"start\":64760},{\"end\":65119,\"start\":65101},{\"end\":65131,\"start\":65119},{\"end\":65147,\"start\":65131},{\"end\":65163,\"start\":65147},{\"end\":65170,\"start\":65163},{\"end\":65477,\"start\":65462},{\"end\":65488,\"start\":65477},{\"end\":65502,\"start\":65488},{\"end\":65766,\"start\":65757},{\"end\":65777,\"start\":65766},{\"end\":65785,\"start\":65777},{\"end\":65795,\"start\":65785},{\"end\":66096,\"start\":66084},{\"end\":66106,\"start\":66096},{\"end\":66122,\"start\":66106},{\"end\":66397,\"start\":66387},{\"end\":66407,\"start\":66397},{\"end\":66423,\"start\":66407},{\"end\":66434,\"start\":66423},{\"end\":66446,\"start\":66434},{\"end\":66457,\"start\":66446},{\"end\":66772,\"start\":66762},{\"end\":66784,\"start\":66772},{\"end\":66790,\"start\":66784},{\"end\":67029,\"start\":67003},{\"end\":67041,\"start\":67029},{\"end\":67047,\"start\":67041},{\"end\":67376,\"start\":67363},{\"end\":67389,\"start\":67376},{\"end\":67403,\"start\":67389},{\"end\":67677,\"start\":67668},{\"end\":67687,\"start\":67677},{\"end\":67698,\"start\":67687},{\"end\":68074,\"start\":68061},{\"end\":68089,\"start\":68074},{\"end\":68103,\"start\":68089},{\"end\":68429,\"start\":68421},{\"end\":68438,\"start\":68429},{\"end\":68451,\"start\":68438},{\"end\":68462,\"start\":68451},{\"end\":68792,\"start\":68782},{\"end\":68806,\"start\":68792},{\"end\":69082,\"start\":69072},{\"end\":69093,\"start\":69082},{\"end\":69106,\"start\":69093},{\"end\":69114,\"start\":69106},{\"end\":69126,\"start\":69114},{\"end\":69140,\"start\":69126},{\"end\":69154,\"start\":69140},{\"end\":69535,\"start\":69503},{\"end\":69549,\"start\":69535},{\"end\":69566,\"start\":69549},{\"end\":69571,\"start\":69566},{\"end\":69920,\"start\":69902},{\"end\":69935,\"start\":69920},{\"end\":69951,\"start\":69935},{\"end\":70263,\"start\":70252},{\"end\":70275,\"start\":70263},{\"end\":70283,\"start\":70275},{\"end\":70564,\"start\":70549},{\"end\":70573,\"start\":70564},{\"end\":70588,\"start\":70573},{\"end\":70603,\"start\":70588},{\"end\":70917,\"start\":70907},{\"end\":70929,\"start\":70917},{\"end\":70942,\"start\":70929},{\"end\":71222,\"start\":71206},{\"end\":71234,\"start\":71222},{\"end\":71249,\"start\":71234},{\"end\":71265,\"start\":71249},{\"end\":71283,\"start\":71265}]", "bib_venue": "[{\"end\":42770,\"start\":42708},{\"end\":43095,\"start\":43076},{\"end\":43359,\"start\":43340},{\"end\":43660,\"start\":43640},{\"end\":44016,\"start\":43997},{\"end\":44408,\"start\":44389},{\"end\":44801,\"start\":44758},{\"end\":45195,\"start\":45176},{\"end\":45521,\"start\":45502},{\"end\":45843,\"start\":45824},{\"end\":46202,\"start\":46183},{\"end\":46508,\"start\":46497},{\"end\":46781,\"start\":46761},{\"end\":47055,\"start\":47036},{\"end\":47374,\"start\":47343},{\"end\":47675,\"start\":47661},{\"end\":48031,\"start\":48012},{\"end\":48542,\"start\":48480},{\"end\":49092,\"start\":49073},{\"end\":49567,\"start\":49475},{\"end\":49945,\"start\":49926},{\"end\":50284,\"start\":50264},{\"end\":50611,\"start\":50592},{\"end\":50883,\"start\":50864},{\"end\":51195,\"start\":51176},{\"end\":51554,\"start\":51535},{\"end\":51883,\"start\":51864},{\"end\":52243,\"start\":52223},{\"end\":52594,\"start\":52575},{\"end\":52935,\"start\":52916},{\"end\":53251,\"start\":53228},{\"end\":53568,\"start\":53547},{\"end\":53903,\"start\":53866},{\"end\":54253,\"start\":54234},{\"end\":54634,\"start\":54572},{\"end\":55005,\"start\":54986},{\"end\":55349,\"start\":55330},{\"end\":55675,\"start\":55656},{\"end\":56029,\"start\":56010},{\"end\":56402,\"start\":56383},{\"end\":56675,\"start\":56656},{\"end\":57006,\"start\":56987},{\"end\":57347,\"start\":57328},{\"end\":57649,\"start\":57630},{\"end\":57933,\"start\":57914},{\"end\":58211,\"start\":58192},{\"end\":58491,\"start\":58472},{\"end\":58812,\"start\":58793},{\"end\":59177,\"start\":59158},{\"end\":59504,\"start\":59485},{\"end\":59856,\"start\":59837},{\"end\":60242,\"start\":60180},{\"end\":60627,\"start\":60608},{\"end\":61042,\"start\":61023},{\"end\":61460,\"start\":61441},{\"end\":61839,\"start\":61820},{\"end\":62245,\"start\":62208},{\"end\":62717,\"start\":62678},{\"end\":63145,\"start\":63126},{\"end\":63463,\"start\":63444},{\"end\":63733,\"start\":63714},{\"end\":64076,\"start\":64057},{\"end\":64420,\"start\":64401},{\"end\":64786,\"start\":64767},{\"end\":65190,\"start\":65170},{\"end\":65521,\"start\":65502},{\"end\":65815,\"start\":65795},{\"end\":66141,\"start\":66122},{\"end\":66484,\"start\":66457},{\"end\":66809,\"start\":66790},{\"end\":67090,\"start\":67047},{\"end\":67423,\"start\":67403},{\"end\":67755,\"start\":67698},{\"end\":68122,\"start\":68103},{\"end\":68501,\"start\":68462},{\"end\":68825,\"start\":68806},{\"end\":69174,\"start\":69154},{\"end\":69590,\"start\":69571},{\"end\":69970,\"start\":69951},{\"end\":70302,\"start\":70283},{\"end\":70622,\"start\":70603},{\"end\":70961,\"start\":70942},{\"end\":71302,\"start\":71283},{\"end\":43101,\"start\":43097},{\"end\":43365,\"start\":43361},{\"end\":43667,\"start\":43662},{\"end\":44022,\"start\":44018},{\"end\":44414,\"start\":44410},{\"end\":45201,\"start\":45197},{\"end\":45527,\"start\":45523},{\"end\":45849,\"start\":45845},{\"end\":46208,\"start\":46204},{\"end\":46788,\"start\":46783},{\"end\":47061,\"start\":47057},{\"end\":48037,\"start\":48033},{\"end\":49098,\"start\":49094},{\"end\":49951,\"start\":49947},{\"end\":50291,\"start\":50286},{\"end\":50617,\"start\":50613},{\"end\":50889,\"start\":50885},{\"end\":51201,\"start\":51197},{\"end\":51560,\"start\":51556},{\"end\":51889,\"start\":51885},{\"end\":52250,\"start\":52245},{\"end\":52600,\"start\":52596},{\"end\":52941,\"start\":52937},{\"end\":53261,\"start\":53253},{\"end\":53576,\"start\":53570},{\"end\":54259,\"start\":54255},{\"end\":55011,\"start\":55007},{\"end\":55355,\"start\":55351},{\"end\":55681,\"start\":55677},{\"end\":56035,\"start\":56031},{\"end\":56408,\"start\":56404},{\"end\":56681,\"start\":56677},{\"end\":57012,\"start\":57008},{\"end\":57353,\"start\":57349},{\"end\":57655,\"start\":57651},{\"end\":57939,\"start\":57935},{\"end\":58217,\"start\":58213},{\"end\":58497,\"start\":58493},{\"end\":58818,\"start\":58814},{\"end\":59183,\"start\":59179},{\"end\":59510,\"start\":59506},{\"end\":59862,\"start\":59858},{\"end\":60633,\"start\":60629},{\"end\":61048,\"start\":61044},{\"end\":61466,\"start\":61462},{\"end\":61845,\"start\":61841},{\"end\":63151,\"start\":63147},{\"end\":63469,\"start\":63465},{\"end\":63739,\"start\":63735},{\"end\":64082,\"start\":64078},{\"end\":64426,\"start\":64422},{\"end\":64792,\"start\":64788},{\"end\":65197,\"start\":65192},{\"end\":65527,\"start\":65523},{\"end\":65822,\"start\":65817},{\"end\":66815,\"start\":66811},{\"end\":67430,\"start\":67425},{\"end\":68128,\"start\":68124},{\"end\":68831,\"start\":68827},{\"end\":69181,\"start\":69176},{\"end\":69596,\"start\":69592},{\"end\":69976,\"start\":69972},{\"end\":70308,\"start\":70304},{\"end\":70967,\"start\":70963},{\"end\":71308,\"start\":71304}]"}}}, "year": 2023, "month": 12, "day": 17}