{"id": 248546739, "updated": "2022-09-29 23:10:05.645", "metadata": {"title": "Reinforcement Learning Applicability for Resource-Based Auto-scaling in Serverless Edge Applications", "authors": "[{\"first\":\"Priscilla\",\"last\":\"Benedetti\",\"middle\":[]},{\"first\":\"M.\",\"last\":\"Femminella\",\"middle\":[]},{\"first\":\"G.\",\"last\":\"Reali\",\"middle\":[]},{\"first\":\"Kris\",\"last\":\"Steenhaut\",\"middle\":[]}]", "venue": "2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)", "journal": "2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Serverless computing is an alternative deployment paradigm for cloud computing platforms, aimed to provide scalability and cost reduction without requiring any additional deployment overhead from developers. Generally, open-source serverless computing platforms rely on two auto-scaling approaches: workload-based and resource-based. In the former, a designated algorithm scales instances according to the number of incoming requests. In the latter, instances are scaled when a certain resource usage limit, such as maximum Central Processing Unit (CPU) utilization, is reached. Resource-based auto-scaling is usually implemented leveraging Kubernetes Horizontal Pod Autoscaler (HPA). In this work, we investigate the applicability of a reinforcement-based approach to resource-based auto-scaling in OpenFaaS, the most widely used open-source serverless platform. Serverless technologies are particularly convenient when dealing with edge computing on constrained devices or resource-limited machines. Our experimental analysis has been conducted on constrained Kubernetes-based nodes, to simulate such an edge application scenario. Its preliminary results show that our proposed model learns an effective scaling policy, based on CPU utilization, to provide minimal service latency within a limited number of iterations.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/percom/BenedettiFRS22", "doi": "10.1109/percomworkshops53856.2022.9767437"}}, "content": {"source": {"pdf_hash": "38ec7a861d35618fda497401e737af9c79ecbcf5", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "5b9ba85a6087cd5bcc12a44633e79c8785651f10", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/38ec7a861d35618fda497401e737af9c79ecbcf5.txt", "contents": "\nReinforcement Learning Applicability for Resource-Based Auto-scaling in Serverless Edge Applications\n\n\nPriscilla Benedetti priscilla.benedetti@vub.be \nM Femminella \nG Reali \nKris Steenhaut ksteenha@etrovub.be \n\nDept. of Eng. via G.Duranti 93\nUniv. of Perugia\nPerugiaItaly\n\n\nVrije Universiteit Brussel\nETRO\nPleinlaan 2BrusselsBelgium\n\n\nDept. of Eng, CNIT RU via G.Duranti 93\nUniv. of Perugia\nPerugiaItaly\n\n\nBrussel ETRO Dept\nVrije Universiteit\nPleinlaan 2BrusselsBelgium\n\nReinforcement Learning Applicability for Resource-Based Auto-scaling in Serverless Edge Applications\n10.1109/PerComWorkshops53856.2022.9767437Index Terms-edge computingserverless computingrein- forcement learningKubernetesOpenFaaS\nServerless computing is an alternative deployment paradigm for cloud computing platforms, aimed to provide scalability and cost reduction without requiring any additional deployment overhead from developers. Generally, open-source serverless computing platforms rely on two auto-scaling approaches: workload-based and resource-based. In the former, a designated algorithm scales instances according to the number of incoming requests. In the latter, instances are scaled when a certain resource usage limit, such as maximum Central Processing Unit (CPU) utilization, is reached. Resource-based auto-scaling is usually implemented leveraging Kubernetes Horizontal Pod Autoscaler (HPA). In this work, we investigate the applicability of a reinforcement-based approach to resource-based auto-scaling in OpenFaaS, the most widely used open-source serverless platform. Serverless technologies are particularly convenient when dealing with edge computing on constrained devices or resourcelimited machines. Our experimental analysis has been conducted on constrained Kubernetes-based nodes, to simulate such an edge application scenario. Its preliminary results show that our proposed model learns an effective scaling policy, based on CPU utilization, to provide minimal service latency within a limited number of iterations.\n\nI. INTRODUCTION\n\nServerless computing has been introduced to enhance multiplexing and scalability functions in computing platforms [1]. Whereas traditional cloud computing frameworks allocate compute resources in advance, serverless technologies make use of dynamic resource allocation, through an event-driven allocation control, allowing the number of service instances to be zero when there is no demand while scaling to as many instances as needed by the incoming requests, leading to reduced cost. Serverless computing, usually implemented using Functions-as-a-Service (FaaS), only focuses on the application code, organized through individual services, typically eventtriggered and executed in containers. Infrastructure provisioning and maintenance are handled by the serverless platform and are completely hidden from developers and users [2]. Instead of deploying a whole platform or an application in the cloud servers, by using FaaS just functions are required, as components of complex applications. Such functions can be loaded as virtual containers when needed, on demand, and possibly in parallel, without any need for controlling application deployment processes at operating system level. This means that containers are dynamically scheduled in the hardware infrastructure maintained by cloud providers. This approach, focused on dynamic provisioning and resource efficiency, makes serverless computing a promising deployment model for edge platforms [3] [4]. Through the use of advanced virtualization technologies, FaaS can ensure that the volume of resources consumed by an application is dynamically controlled and is tailored to the actual computing needs.\n\nThis auto-scaling capability is handled with different mechanism within the available serverless solutions. Auto-scaling can be either workload-based, i.e., providing additional resources when incoming traffic increases as done with Amazon Web Services (AWS) Lambda, or it can be resource-based [5], using the resource-based Kubernetes Horizontal Pod Autoscaler (HPA) [6] to trigger scaling via per-instance CPU or memory utilization thresholds. In this work, we focus on resource-based auto-scaling. Resource-based auto-scaling is available in all Kubernetes-based serverless platforms, i.e., the majority of the available open source serverless solutions [7]. Without loss of generality, we decided to deploy and analyse the feasibility of a reinforcement learning (RL) model to dynamically set the optimal configuration for resource-based auto-scaling in OpenFaaS [8], the open-source FaaS solution with highest adoption rate [7]. RL implies the development of an agent learning an optimal policy through a certain number of trial-and-error interactions with the environment. Since this approach has been successful in the field of virtual machines auto-scaling, there is a growing interest in the applicability of RL to serverless platforms auto-scaling mechanisms [9].\n\nTherefore, in this work we present some preliminary results on RL for resource-based auto-scaling optimization in serverless platforms. Specifically, we implemented a simple serverless application in an edge computing use case scenario, relying on nodes with limited resources. On this testbed, two consecutive experiments are conducted. First, a baseline analysis of application latency variation under different CPUconsumption auto-scaling configurations is done. It demonstrates the dependency of application latency on the specific auto-scaling settings. Subsequently, given the baseline results, we evaluate the ability of a RL algorithm for optimal resourcebased auto-scaling configuration in OpenFaaS. Results show that the developed agent can learn within a reasonable time an effective scaling configuration policy, which provides a lower response time than the one obtained with the serverless platform's default CPU-consumption auto-scaling settings.\n\nThe rest of the paper is organized as follows. Section II introduces OpenFaaS and reinforcement learning theory, specifically Q-learning. Section III presents related work in serverless platforms and general cloud-computing auto-scaling techniques. Section IV provides an overview of the experimental setup of this work, describing the testbed in use. Section V illustrates the impact of different CPU-rate autoscaling configurations on application latency, while Section VI delves into the RL agent development and evaluation. Section VII concludes the paper with further comments, remarks on limitations and possible future work.\n\n\nII. BACKGROUND\n\nIn this section we provide a brief introduction of the Open-FaaS serverless platform, with a particular focus on resourcebased auto-scaling via Kubernetes HPA. Moreover, we give an overview of Q-learning, the reinforcement learning algorithm used in this work.\n\n\nA. OpenFaaS\n\nOpenFaaS [8] is a cloud native computing foundation (CNCF) open source serverless platform. It allows developers to define and use templates of different languages to create and build serverless functions. It relies on Docker images and Kubernetes control plane to run applications, providing failover, high availability, scale-out and secret management. As shown in Fig.1, the OpenFaaS gateway, which is similar to a reverse proxy, is in charge of exposing and managing the function Pods, offering a Representational State Transfer (REST) Application Programming Interface (API) for all interactions. For workload-based auto-scaling, OpenFaaS is set by default with a single auto-scaling rule defined for the AlertManager component. The AlertManager will monitor requestsper-second metrics provided by a Prometheus [10] instance in the cluster and trigger auto-scaling when needed. Conversely, when a resource-based auto-scaling approach is considered, OpenFaaS does not rely on AlertManager and Prometheus components. The auto-scaling process will be completely governed by Kubernetes Horizontal Pod Autoscaler (HPA), which supports CPU utilization metrics as well as applicationprovided metrics and custom metrics. As shown in Fig.1, the HPA controller gets resource usage metrics from the API provided by Kubernetes native metrics-server. Then, if a target utilization value is set, the HPA controller calculates the utilization value as a percentage of the equivalent resource request on the containers in each Pod and produces a ratio used to scale the number of desired replicas. HPA operates on the number of Pods by using Deployment's Scale, which is an interface that allows to dynamically set the number of replicas and examine their current state [6].\n\n\nB. Q-learning\n\nReinforcement learning problems involve mapping situations to actions so as to maximize a numerical reward signal. In particular, Q-learning is one of the most applied representative reinforcement learning approaches, which uses an off-policy control that separates the deferral policy from the learning policy and updates the action selection using the Bellman optimal equations and the -greed policy. Q-learning is an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states [11] [12]. Q-learning is aimed at training in a stepwise fashion an approximator Q \u03b8 (s, a) of the optimal action-value function Q * . Q \u03b8 (s, a) identifies the cumulative reward expected by the agent when taking an action a in a state s. Considering the actual reward at each iteration, the optimization of Q is performed incrementally per step t,as shown below in formula 1:\nQ(s t , a t ) \u2190 (1\u2212\u03b1)Q(s t , a t )+\u03b1[r t +\u03b3max a Q(s t+1 , a)] (1)\n\u03b1 is the learning rate, r t is the immediate reward received when moving from s t to s t+1 and \u03b3 a discount factor to balance between immediate and future rewards. During the training phase, the agent has the ability to choose between trying an action in a random way (exploration) or selecting the current best action (exploitation), i.e., the action with the highest Q-value. A common approach is storing the Qvalue for each state-action in a lookup table, i.e., the Q-table, which serves as a basis for the agent's decision-making in the exploitation case. The probability of exploration versus exploitation is defined by an coefficient, which defines the probability of exploration and usually decreases as the training process advances. III. RELATED WORK Serverless computing feasibility for edge platforms has been introduced in [1], where the authors present a general description of serverless computing and its relevant programming model, pointing to Function-as-a-Service (FaaS) platforms as the concretisation of serverless computing principles. Moreover, a serverless edge platform based on OpenWhisk is presented in [13], along with different application scenarios and an evaluation in terms of memory footprint, latency, throughput, and scalability. Another example of serverless application in an edge computing scenario is provided in [14], where the authors rely on OpenFaaS to deploy a monitoring application for IoT data deployed on low-hardware nodes to simulate an edge layer. There is a vast offering in open-source serverless computing platforms. Thus, some studies can be found that compare these solutions from different points of view, taking in account also scalability features. In [15], an assessment of serverless platforms is conducted on top of a Kubernetes cluster. [7] and [16] perform tests for measuring some interesting metrics such as the response time, the ratio of successful responses or the impact of auto-scaling on some of these metrics. The study on open-source serverless platforms presented in [5] includes a detailed comparison of autoscaling performance, taking in account both resource-based and workload-based policies. Nevertheless, these works do not consider possible alternatives such as RL to the default autoscaling mechanisms present in the analyzed platforms. In fact, reinforcement learning has been adopted by many researchers for organising scaling in the field of VM provisioning and deprovisioning, such as in [17] and [18]. Moreover, auto-scaling configuration for container-based applications has been widely explored [19] [20]. Regarding the applicability of RL-based algorithms to optimize serverless platform auto-scaling, [9] presents an RL-based model to optimize requests-per-second (RPS) throughput tuning serverless auto-scaling mechanisms. The research considers workload-based auto-scaling for Kna- tive, which is an open-source serverless platform based on Kubernetes. As far as we know, the use of RL for optimizing resource-based auto-scaling in serverless platforms has not been analysed at present.\n\n\nIV. TESTBED SETUP\n\nThe testbed architecture for our experiments is shown in Fig.2. To simulate an edge computing layer, we deployed a Kubernetes cluster on 4 virtual machines, hosted on two physical nodes residing in the same Local Area Network (LAN). Node 1 is equipped with a 4-core CPU and 8GB RAM, Node 2 with a 12-core CPU and 32 GB RAM. Each virtual machine, simulating a node of the edge cluster, was equipped with 2 vCPU and 4 GB of memory. The three workers are in communication via Mininet 1 , a virtualized network emulator. The OpenFaaS serverless platform is hosted on the worker nodes, as well as the Kubernetes metricsserver needed by the Horizontal Pod Autoscaler. The master is including the reinforcement-learning agent developed for this work. The serverless application deployed on this platform is a web-server showing an HTML text, show-html, developed using OpenFaaS Python Flask template 2 , which relies on ofwatchdog, OpenFaas' reverse proxy for HTTP microservices. To first analyse the OpenFaaS resource-based auto-scaling process and then develop the RL-based optimization, we considered HPA auto-scaling based on the average CPU utilization across all serverless application's Pods, setting the minimum number of replicas to 1 and the maximum to 200. With the first baseline experiment, we analysed the throughput, in terms of execution time, of show-html, considering every HPA's CPU usage percentage setting in the interval [ For the Q-learning experiment, the process flow of one training iteration is shown in Fig.3. At each iteration, the agent sets the HPA according to its CPU usage percentage choice. Then, the same load test of the baseline experiment is executed, while HPA, communicating with the Client Cluster metricsserver, scales replicas to maintain serverless application Pods CPU usage below the configured threshold if needed. When the test ends, the agent scrapes the latency results, deletes the current HPA configuration and processes its decision for the next iteration. It must be noted that the agent waits for Pods replicas to come back to their initial minimum number before proceeding to the next iteration.\n\n\nV. BASELINE EXPERIMENT\n\nDuring the baseline experiment, a load test has been executed for each CPU usage percentage considered, to assess the best configuration. The load test, performed via Hey generator, sent an incremental number of requests from 25 concurrent entities to the OpenFaaS gateway, to call showhtml serverless function, up to 7500 requests per seconds (RPS). We considered the report produced by Hey to get the average latency of the responses per second, considering 300 s with an increasing number of requests per second from 0 to 7500. Before each load test, show-html replicas are set back to the minimum. Fig.4 depicts average latency evolution during Hey load test for each CPU usage setting considered. The presence of latency spikes can be observed in every test, this phenomenon is due to the auto-scaling process. Indeed, the waiting time for the new replicas to be up and 3 https://github.com/rakyll/hey running increases the overall execution time for the considered serverless function. To have a better insight of latency variation with different configurations, the boxplots of average latency for each CPU setting over the load test is shown in Fig. 5. The mean is shown as a green triangle. From this plot, there is an improvement of latency in the interval from 30% to 50% CPU usage, with good performance for the 80% as well. The overall best performance is achieved for the 30% CPU usage setting, leading to the minimal latency, i.e., 0.0341653 s. A manifest performance degradation for the 90% CPU usage setting can be observed. This is due to several instabilities in the latency results, as can be seen in the previous figure (Fig.4). Forcing the cluster to not scale replicas until the CPU is almost saturated leads to a pronounced latency increase and many Pods crashes. It must be noted that the monitoring components as well have a CPU footprint which influences the overall auto-scaling behaviour, as previously pointed out in [5]. This issue will be further commented in Section VII.\n\n\nVI. Q-LEARNING EXPERIMENT\n\nThe previously described baseline experiment showed the impact of CPU usage auto-scaling settings on latency. Hence, in this second experiment we evaluate the applicability of Q-learning models to learn effective resource-based scaling policies. Instead of incrementally increasing maximum CPU usage allowed for serverless Pods, the agent uses knowledge of the environment, encoded using states, to test different CPU usage auto-scaling settings (actions), evaluating them by obtained rewards. The states, which provide all relevant information about system's conditions, can include a large number of features influencing the throughput, such as network utilization or memory usage. For this preliminary analysis, we limited the considered states to CPU usage settings in use at each iteration. This simplification of state's space ensures feasibility of the problem in the used Q-learning algorithm [9]. For each state s i \u2208 S, being S the space of available CPU usage configurations, we introduce A(s i ) as the set of valid actions. The agent can choose if increasing maximum CPU usage threshold in HPA autoscaler, decreasing it or maintaining it, so the set of all action is defined as A = {\u22121, 0, +1}. If the agent reaches the minimum or maximum configuration allowed, the action set A(s i ) is reduced by removing the invalid action for that state, e.g., a = +1 for s i = 90. To evaluate the chosen action at each iteration, the agent receives a reward based on the performance achieved through the action at the specific iteration. This reward is usually based on the distance between the obtained performance and a specific Service Level Agreement, such as a response time target value [9]. The target value can be identified using adaptive, dynamic approaches such as metalearning. Nevertheless, for this preliminary study we considered the minimal latency value obtained in the baseline case, i.e., 0.0341653 s, as the target Service Level Agreement, including a tolerance for greater values. Therefore, the calculation of the immediate reward r i for iteration i is defined as follows:\nr i = target resulti * 10 if result i \u2264 target * 1.05 1 otherwise (2)\nIt has to be noted that, being result i the obtained latency for iteration i and target the Service Level Agreement value, the lower is result i with respect to target, the higher the reward. The Q-learning process is configured with the following parameters: learning rate \u03b1 = 0.5 to balance new and past information, a discount factor \u03b3 = 0.95 to ensure that the agent promotes a long-term high return. Finally, angreedy policy is implemented for which the agent starts in full exploration mode and opts for exploitation of its previous experience with increasing probability. Therefore, an is set to 1 for the initial 10 iterations and will be gradually decreased to 0.2, fixing that value from iteration 150 to 200. During the last 50 iterations the agent only relies on the learned Q-table to choose its actions ( = 0). The results of the training process are depicted in Fig.6. It can be seen how the RL agent gradually explores the available configurations, tending to oscillate around the interval between 30% and 50% CPU usage and 80% CPU usage setting, being the local minimum previously shown in Fig.5. Moreover, the lower the coefficient gets, the stronger gets the trend to choose in the 30%-50% interval, up to the final convergence to the optimal value of 30%, when the agent is relying exclusively on the acquired knowledge to choose the next action. The evolution of the obtained average latency during the load test at each iteration is reported as a blue line in Fig.6. The latency trend during the training process is kept in the interval between 0.035 s and 0.055 s, with few peaks over the maximum. From around the 175 th iteration onwards, there is an increased tendency to get values of 0.04 s and below, gradually decreasing the resulting latency when the agent is set for a 100% exploitation mode (no random choices, = 0).  Indeed, in this phase, apart from oscillations of hundredths of a second due to system's hidden stochastic conditions, a trend toward lower latencies can be observed. In the last 10 iteration of the training process, latencies are oscillating around 0.0375 s, reaching a minimum of 0.03488667 s, 0.7 ms greater than the minimum observed in the baseline case (Section V).\n\n\nVII. CONCLUSION\n\nThe optimization of dynamic resource provisioning (autoscaling) in serverless applications has become a key area of research that led to the introduction of various autoscaling mechanism, mainly partitioned in workload-based and resource-based auto-scaling solutions. In this work, we investigated, with the use of a preliminary simplified model, the applicability of reinforcement-learning algorithms to learn effective resource-based auto-scaling policies for OpenFaaS, the highly adopted open-source serverless platform. The analysis was conducted considering a testbed with limited hardware resources to simulate an edge-computing scenario, a frequent use-case for serverless technologies. The experiment showed the ability of an RL-model to learn the optimal CPU usage threshold configuration for resource-based autoscaling in a limited number of iterations. Nevertheless, these results are presented as preliminary because of resource-based auto-scaling features variability: Resource-based auto-scaling mechanisms are influenced by the impact of the specific serverless platform's components resource usage. Moreover, as noted in the baseline experiment, when the CPU usage threshold is close to the maximum in our edge-like testbed, the cluster incurs into strong instabilities. In such situation where the system is overloaded, the resource-usage footprint of the cluster's monitoring components can influence negatively the service quality. Hence, we plan to further investigate these factors to develop an enhanced RL model for CPU usage based auto-scaling optimization, taking in account these features influencing system conditions in the modelled states. Moreover, we plan to test the trained model in a dynamic scenario with time-varying workloads made by CPU-intensive functions, to further refine the agent in a real-time changing environment scenario, without relying on a baseline case to evaluate its performance. Nevertheless, we highlight the flexibility of this type of research: being resource-based autoscaling in serverless platform based on the underlying Kubernetes HPA functionalities, the procedures shown in this work for OpenFaaS can be applied in other serverless Kubernetesbased platforms.\n\nFig. 1 :\n1Conceptual workflow of OpenFaas resource-based autoscaling using Kubernetes HPA.\n\nFig. 2 :\n2Testbed setup for the experiments.\n\nFig. 3 :\n3RL agent training process flow for each iteration.\n\nFig. 5 :\n5Boxplots of the average latency for each CPU usage setting. The overall best result is obtained for 30%: 0.0341653 s.\n\nFig. 6 :\n6Q-learning model state transition during training process (red), average latency evolution during training (blue).\n\n\n10,...90]. For each HPA configuration, the throughput has been evaluated under a load test with an increasing number of incoming parallel requests, for a load test duration of 5 minutes. To simulate Fig. 4: show-html latency, [s], for each CPU usage setting considered during the load test. the load test, we relied on the heavy-duty Hey HTTP load generator 3 , considering 25 parallel requests senders.\n\n\nStarless 2022: First Workshop on Serverless Computing for Pervasive Cloud-Edge-Device Systems and Services Starless 2022: First Workshop on Serverless Computing for Pervasive Cloud-Edge-Device Systems and Services\nIEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops) | 978-1-6654-1647-4/22/$31.00 \u00a92022 IEEE | DOI: 10.1109/PerComWorkshops53856.2022.9767437\nStarless 2022: First Workshop on Serverless Computing for Pervasive Cloud-Edge-Device Systems and Services Starless 2022: First Workshop on Serverless Computing for Pervasive Cloud-Edge-Device Systems and Services\nhttp://mininet.org/ 2 https://github.com/openfaas/python-flask-template Starless 2022: First Workshop on Serverless Computing for Pervasive Cloud-Edge-Device Systems and Services Starless 2022: First Workshop on Serverless Computing for Pervasive Cloud-Edge-Device Systems and Services\nACKNOWLEDGMENT This work has been partially supported by the EU project 5G-CARMEN under GA No. 825012. The views expressed are those of the authors and do not necessarily represent the project. The Commission is not responsible for any use that may be made of the information it contains.\nThe rise of serverless computing. P Castro, V Ishakian, V Muthusamy, A Slominski, 10.1145/3368454Commun. ACM. 6212P. Castro, V. Ishakian, V. Muthusamy, and A. Slominski, \"The rise of serverless computing,\" Commun. ACM, vol. 62, no. 12, p. 44-54, Nov. 2019. [Online]. Available: https://doi.org/10.1145/3368454\n\nCNCF WG-Serverless Whitepaper v1.0. \"CNCF WG-Serverless Whitepaper v1.0.\"\n\nA serverless real-time data analytics platform for edge computing. S Nastic, T Rausch, O Scekic, S Dustdar, M Gusev, B Koteska, M Kostoska, B Jakimovski, S Ristov, R Prodan, IEEE Internet Computing. 214S. Nastic, T. Rausch, O. Scekic, S. Dustdar, M. Gusev, B. Koteska, M. Kostoska, B. Jakimovski, S. Ristov, and R. Prodan, \"A serverless real-time data analytics platform for edge computing,\" IEEE Internet Computing, vol. 21, no. 4, pp. 64-71, 2017.\n\nDeviceless edge computing: Extending serverless computing to the edge of the network. A Glikson, S Nastic, S Dustdar, 10.1145/3078468.3078497Proceedings of the 10th ACM International Systems and Storage Conference, ser. SYSTOR '17. the 10th ACM International Systems and Storage Conference, ser. SYSTOR '17New York, NY, USAAssociation for Computing MachineryA. Glikson, S. Nastic, and S. Dustdar, \"Deviceless edge computing: Extending serverless computing to the edge of the network,\" in Proceedings of the 10th ACM International Systems and Storage Conference, ser. SYSTOR '17. New York, NY, USA: Association for Computing Machinery, 2017. [Online]. Available: https://doi.org/10.1145/3078468.3078497\n\nUnderstanding open source serverless platforms: Design considerations and performance. J Li, S G Kulkarni, K K Ramakrishnan, D Li, Proceedings of the 5th International Workshop on Serverless Computing, ser. WOSC '19. the 5th International Workshop on Serverless Computing, ser. WOSC '19New York, NY, USAAssociation for Computing MachineryJ. Li, S. G. Kulkarni, K. K. Ramakrishnan, and D. Li, \"Understanding open source serverless platforms: Design considerations and performance,\" in Proceedings of the 5th International Workshop on Serverless Computing, ser. WOSC '19. New York, NY, USA: Association for Computing Machinery, 2019, p. 37-42. [Online].\n\n. 10.1145/3366623.3368139Available: https://doi.org/10.1145/3366623.3368139\n\nKubernetes horizontal pod autoscaler. \"Kubernetes horizontal pod autoscaler.\" [Online].\n\n. Available, Avail- able: https://kubernetes.io/docs/tasks/run-application/horizontal-pod- autoscale/\n\nAn Evaluation of Open Source Serverless Computing Frameworks. S K Mohanty, G Premsankar, M Di Francesco, S. K. Mohanty, G. Premsankar, and M. di Francesco, \"An Evaluation of Open Source Serverless Computing Frameworks,\" in CloudCom 2018, 2018, pp. 115-120.\n\nOpenFaaS: Open function as a service. Accessed on 26\"OpenFaaS: Open function as a service,\" [Accessed on 26-Sep-2021].\n\nAi-based resource allocation: Reinforcement learning for adaptive auto-scaling in serverless environments. L Schuler, S Jamil, N Kuhl, 10.1109/CCGrid51090.2021.000982021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid). Los Alamitos, CA, USAIEEE Computer SocietyL. Schuler, S. Jamil, and N. Kuhl, \"Ai-based resource allocation: Reinforcement learning for adaptive auto-scaling in serverless environ- ments,\" in 2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid). Los Alamitos, CA, USA: IEEE Computer Society, may 2021, pp. 804-811. [Online]. Available: https://doi.ieeecomputersociety.org/10.1109/CCGrid51090.2021.00098\n\nPrometheus -monitoring system & time series database. \"Prometheus -monitoring system & time series database.\" [Online]. Available: https://prometheus.io/\n\nQ-learning algorithms: A comprehensive classification and applications. B Jang, M Kim, G Harerimana, J Kim, IEEE Access. B. Jang, M. Kim, G. Harerimana, and J. Kim, \"Q-learning algorithms: A comprehensive classification and applications,\" IEEE Access, vol. PP, pp. 1-1, 09 2019.\n\nQ-learning. C J C H Watkins, P Dayan, Mach Learn. 8C. J. C. H. Watkins and P. Dayan, \"Q-learning,\" Mach Learn, vol. 8, p. 279-292, May 1992.\n\nTowards a serverless platform for edge computing. L Baresi, D Filgueira Mendon\u00e7a, 2019 IEEE International Conference on Fog Computing (ICFC). L. Baresi and D. Filgueira Mendon\u00e7a, \"Towards a serverless platform for edge computing,\" in 2019 IEEE International Conference on Fog Computing (ICFC), 2019, pp. 1-10.\n\nExperimental analysis of the application of serverless computing to IoT platforms. P Benedetti, M Femminella, G Reali, K Steenhaut, Sensors. 213P. Benedetti, M. Femminella, G. Reali, and K. Steenhaut, \"Experimental analysis of the application of serverless computing to IoT platforms,\" Sensors, vol. 21, no. 3, 2021. [Online]. Available: https://www.mdpi.com/1424-8220/21/3/928\n\nPerformance Analysis of Virtualisation Technologies in NFV and Edge Deployments. V Aggarwal, B Thangaraju, IEEE CONECCT 2020. V. Aggarwal and B. Thangaraju, \"Performance Analysis of Virtualisation Technologies in NFV and Edge Deployments,\" in IEEE CONECCT 2020, 2020, pp. 1-5.\n\nAn evaluation of open source serverless computing frameworks support at the edge. A Palade, A Kazmi, S Clarke, 2019 IEEE World Congress on Services (SERVICES). A. Palade, A. Kazmi, and S. Clarke, \"An evaluation of open source serverless computing frameworks support at the edge,\" in 2019 IEEE World Congress on Services (SERVICES), vol. 2642-939X, 2019, pp. 206-211.\n\nFrom data center resource allocation to control theory and back. X Dutreilh, N Rivierre, A Moreau, J Malenfant, I Truck, CLOUD 2010Proceedings -2010 IEEE 3rd International Conference on Cloud Computing. -2010 IEEE 3rd International Conference on Cloud ComputingX. Dutreilh, N. Rivierre, A. Moreau, J. Malenfant, and I. Truck, \"From data center resource allocation to control theory and back,\" Proceedings - 2010 IEEE 3rd International Conference on Cloud Computing, CLOUD 2010, pp. 410-417, 07 2010.\n\nC Bitsakos, I Konstantinou, N Koziris, DERP: A Deep Reinforcement Learning Cloud System for Elastic Resource Provisioning. 12C. Bitsakos, I. Konstantinou, and N. Koziris, in DERP: A Deep Rein- forcement Learning Cloud System for Elastic Resource Provisioning, 12 2018, pp. 21-29.\n\nEfficient cloud auto-scaling with sla objective using q-learning. S Horovitz, Y Arian, 2018 IEEE 6th International Conference on Future Internet of Things and Cloud (FiCloud). S. Horovitz and Y. Arian, \"Efficient cloud auto-scaling with sla objective using q-learning,\" in 2018 IEEE 6th International Conference on Future Internet of Things and Cloud (FiCloud), 2018, pp. 85-92.\n\nA distributed self-learning approach for elastic provisioning of virtualized cloud resources. J Rao, X Bu, C.-Z Xu, K Wang, J. Rao, X. Bu, C.-Z. Xu, and K. Wang, \"A distributed self-learning approach for elastic provisioning of virtualized cloud resources,\" 07 2011, pp. 45-54.\n\nStarless 2022: First Workshop on Serverless Computing for Pervasive Cloud-Edge-Device Systems and Services Starless 2022: First Workshop on Serverless Computing for Pervasive. Starless 2022: First Workshop on Serverless Computing for Pervasive Cloud-Edge-Device Systems and Services Starless 2022: First Workshop on Serverless Computing for Pervasive Cloud-Edge-Device Systems and Services\n", "annotations": {"author": "[{\"end\":151,\"start\":104},{\"end\":165,\"start\":152},{\"end\":174,\"start\":166},{\"end\":210,\"start\":175},{\"end\":273,\"start\":211},{\"end\":334,\"start\":274},{\"end\":405,\"start\":335},{\"end\":471,\"start\":406}]", "publisher": null, "author_last_name": "[{\"end\":123,\"start\":114},{\"end\":164,\"start\":154},{\"end\":173,\"start\":168},{\"end\":189,\"start\":180}]", "author_first_name": "[{\"end\":113,\"start\":104},{\"end\":153,\"start\":152},{\"end\":167,\"start\":166},{\"end\":179,\"start\":175}]", "author_affiliation": "[{\"end\":272,\"start\":212},{\"end\":333,\"start\":275},{\"end\":404,\"start\":336},{\"end\":470,\"start\":407}]", "title": "[{\"end\":101,\"start\":1},{\"end\":572,\"start\":472}]", "venue": null, "abstract": "[{\"end\":2023,\"start\":703}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2159,\"start\":2156},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2875,\"start\":2872},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3496,\"start\":3493},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3500,\"start\":3497},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4003,\"start\":4000},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4076,\"start\":4073},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4365,\"start\":4362},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4575,\"start\":4572},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4637,\"start\":4634},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4977,\"start\":4974},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6881,\"start\":6878},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7689,\"start\":7685},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8631,\"start\":8628},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9271,\"start\":9267},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9276,\"start\":9272},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":10549,\"start\":10546},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10844,\"start\":10840},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11066,\"start\":11062},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11425,\"start\":11421},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11513,\"start\":11510},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11522,\"start\":11518},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11755,\"start\":11752},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12189,\"start\":12185},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12198,\"start\":12194},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12299,\"start\":12295},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12304,\"start\":12300},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":12406,\"start\":12403},{\"end\":14249,\"start\":14248},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16934,\"start\":16931},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":17922,\"start\":17919},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":18716,\"start\":18713}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":23741,\"start\":23650},{\"attributes\":{\"id\":\"fig_1\"},\"end\":23787,\"start\":23742},{\"attributes\":{\"id\":\"fig_2\"},\"end\":23849,\"start\":23788},{\"attributes\":{\"id\":\"fig_3\"},\"end\":23978,\"start\":23850},{\"attributes\":{\"id\":\"fig_4\"},\"end\":24104,\"start\":23979},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":24510,\"start\":24105},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":24726,\"start\":24511}]", "paragraph": "[{\"end\":3703,\"start\":2042},{\"end\":4978,\"start\":3705},{\"end\":5941,\"start\":4980},{\"end\":6574,\"start\":5943},{\"end\":6853,\"start\":6593},{\"end\":8632,\"start\":6869},{\"end\":9643,\"start\":8650},{\"end\":12790,\"start\":9711},{\"end\":14957,\"start\":12812},{\"end\":16988,\"start\":14984},{\"end\":19115,\"start\":17018},{\"end\":21406,\"start\":19186},{\"end\":23649,\"start\":21426}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9710,\"start\":9644},{\"attributes\":{\"id\":\"formula_1\"},\"end\":19185,\"start\":19116}]", "table_ref": null, "section_header": "[{\"end\":2040,\"start\":2025},{\"end\":6591,\"start\":6577},{\"end\":6867,\"start\":6856},{\"end\":8648,\"start\":8635},{\"end\":12810,\"start\":12793},{\"end\":14982,\"start\":14960},{\"end\":17016,\"start\":16991},{\"end\":21424,\"start\":21409},{\"end\":23659,\"start\":23651},{\"end\":23751,\"start\":23743},{\"end\":23797,\"start\":23789},{\"end\":23859,\"start\":23851},{\"end\":23988,\"start\":23980}]", "table": null, "figure_caption": "[{\"end\":23741,\"start\":23661},{\"end\":23787,\"start\":23753},{\"end\":23849,\"start\":23799},{\"end\":23978,\"start\":23861},{\"end\":24104,\"start\":23990},{\"end\":24510,\"start\":24107},{\"end\":24726,\"start\":24513}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7241,\"start\":7236},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8104,\"start\":8099},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12874,\"start\":12869},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":14341,\"start\":14336},{\"end\":15591,\"start\":15586},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16143,\"start\":16137},{\"end\":16632,\"start\":16618},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20068,\"start\":20063},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20298,\"start\":20293},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20673,\"start\":20668}]", "bib_author_first_name": "[{\"end\":25770,\"start\":25769},{\"end\":25780,\"start\":25779},{\"end\":25792,\"start\":25791},{\"end\":25805,\"start\":25804},{\"end\":26189,\"start\":26188},{\"end\":26199,\"start\":26198},{\"end\":26209,\"start\":26208},{\"end\":26219,\"start\":26218},{\"end\":26230,\"start\":26229},{\"end\":26239,\"start\":26238},{\"end\":26250,\"start\":26249},{\"end\":26262,\"start\":26261},{\"end\":26276,\"start\":26275},{\"end\":26286,\"start\":26285},{\"end\":26659,\"start\":26658},{\"end\":26670,\"start\":26669},{\"end\":26680,\"start\":26679},{\"end\":27363,\"start\":27362},{\"end\":27369,\"start\":27368},{\"end\":27371,\"start\":27370},{\"end\":27383,\"start\":27382},{\"end\":27385,\"start\":27384},{\"end\":27401,\"start\":27400},{\"end\":28260,\"start\":28259},{\"end\":28262,\"start\":28261},{\"end\":28273,\"start\":28272},{\"end\":28287,\"start\":28286},{\"end\":28683,\"start\":28682},{\"end\":28694,\"start\":28693},{\"end\":28703,\"start\":28702},{\"end\":29505,\"start\":29504},{\"end\":29513,\"start\":29512},{\"end\":29520,\"start\":29519},{\"end\":29534,\"start\":29533},{\"end\":29725,\"start\":29724},{\"end\":29731,\"start\":29726},{\"end\":29742,\"start\":29741},{\"end\":29905,\"start\":29904},{\"end\":29915,\"start\":29914},{\"end\":29925,\"start\":29916},{\"end\":30249,\"start\":30248},{\"end\":30262,\"start\":30261},{\"end\":30276,\"start\":30275},{\"end\":30285,\"start\":30284},{\"end\":30626,\"start\":30625},{\"end\":30638,\"start\":30637},{\"end\":30905,\"start\":30904},{\"end\":30915,\"start\":30914},{\"end\":30924,\"start\":30923},{\"end\":31256,\"start\":31255},{\"end\":31268,\"start\":31267},{\"end\":31280,\"start\":31279},{\"end\":31290,\"start\":31289},{\"end\":31303,\"start\":31302},{\"end\":31692,\"start\":31691},{\"end\":31704,\"start\":31703},{\"end\":31720,\"start\":31719},{\"end\":32039,\"start\":32038},{\"end\":32051,\"start\":32050},{\"end\":32447,\"start\":32446},{\"end\":32454,\"start\":32453},{\"end\":32463,\"start\":32459},{\"end\":32469,\"start\":32468}]", "bib_author_last_name": "[{\"end\":25777,\"start\":25771},{\"end\":25789,\"start\":25781},{\"end\":25802,\"start\":25793},{\"end\":25815,\"start\":25806},{\"end\":26196,\"start\":26190},{\"end\":26206,\"start\":26200},{\"end\":26216,\"start\":26210},{\"end\":26227,\"start\":26220},{\"end\":26236,\"start\":26231},{\"end\":26247,\"start\":26240},{\"end\":26259,\"start\":26251},{\"end\":26273,\"start\":26263},{\"end\":26283,\"start\":26277},{\"end\":26293,\"start\":26287},{\"end\":26667,\"start\":26660},{\"end\":26677,\"start\":26671},{\"end\":26688,\"start\":26681},{\"end\":27366,\"start\":27364},{\"end\":27380,\"start\":27372},{\"end\":27398,\"start\":27386},{\"end\":27404,\"start\":27402},{\"end\":28105,\"start\":28096},{\"end\":28270,\"start\":28263},{\"end\":28284,\"start\":28274},{\"end\":28300,\"start\":28288},{\"end\":28691,\"start\":28684},{\"end\":28700,\"start\":28695},{\"end\":28708,\"start\":28704},{\"end\":29510,\"start\":29506},{\"end\":29517,\"start\":29514},{\"end\":29531,\"start\":29521},{\"end\":29538,\"start\":29535},{\"end\":29739,\"start\":29732},{\"end\":29748,\"start\":29743},{\"end\":29912,\"start\":29906},{\"end\":29934,\"start\":29926},{\"end\":30259,\"start\":30250},{\"end\":30273,\"start\":30263},{\"end\":30282,\"start\":30277},{\"end\":30295,\"start\":30286},{\"end\":30635,\"start\":30627},{\"end\":30649,\"start\":30639},{\"end\":30912,\"start\":30906},{\"end\":30921,\"start\":30916},{\"end\":30931,\"start\":30925},{\"end\":31265,\"start\":31257},{\"end\":31277,\"start\":31269},{\"end\":31287,\"start\":31281},{\"end\":31300,\"start\":31291},{\"end\":31309,\"start\":31304},{\"end\":31701,\"start\":31693},{\"end\":31717,\"start\":31705},{\"end\":31728,\"start\":31721},{\"end\":32048,\"start\":32040},{\"end\":32057,\"start\":32052},{\"end\":32451,\"start\":32448},{\"end\":32457,\"start\":32455},{\"end\":32466,\"start\":32464},{\"end\":32474,\"start\":32470}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.1145/3368454\",\"id\":\"b0\",\"matched_paper_id\":208277948},\"end\":26044,\"start\":25735},{\"attributes\":{\"id\":\"b1\"},\"end\":26119,\"start\":26046},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":206464023},\"end\":26570,\"start\":26121},{\"attributes\":{\"doi\":\"10.1145/3078468.3078497\",\"id\":\"b3\",\"matched_paper_id\":29732258},\"end\":27273,\"start\":26572},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":208139154},\"end\":27926,\"start\":27275},{\"attributes\":{\"doi\":\"10.1145/3366623.3368139\",\"id\":\"b5\"},\"end\":28003,\"start\":27928},{\"attributes\":{\"id\":\"b6\"},\"end\":28092,\"start\":28005},{\"attributes\":{\"id\":\"b7\"},\"end\":28195,\"start\":28094},{\"attributes\":{\"id\":\"b8\"},\"end\":28453,\"start\":28197},{\"attributes\":{\"id\":\"b9\"},\"end\":28573,\"start\":28455},{\"attributes\":{\"doi\":\"10.1109/CCGrid51090.2021.00098\",\"id\":\"b10\",\"matched_paper_id\":219124116},\"end\":29275,\"start\":28575},{\"attributes\":{\"id\":\"b11\"},\"end\":29430,\"start\":29277},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":203149977},\"end\":29710,\"start\":29432},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":208910339},\"end\":29852,\"start\":29712},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":201833991},\"end\":30163,\"start\":29854},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":231840184},\"end\":30542,\"start\":30165},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":221845351},\"end\":30820,\"start\":30544},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":201813150},\"end\":31188,\"start\":30822},{\"attributes\":{\"doi\":\"CLOUD 2010\",\"id\":\"b18\",\"matched_paper_id\":16297166},\"end\":31689,\"start\":31190},{\"attributes\":{\"id\":\"b19\"},\"end\":31970,\"start\":31691},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":52194764},\"end\":32350,\"start\":31972},{\"attributes\":{\"id\":\"b21\"},\"end\":32629,\"start\":32352},{\"attributes\":{\"id\":\"b22\"},\"end\":33020,\"start\":32631}]", "bib_title": "[{\"end\":25767,\"start\":25735},{\"end\":26186,\"start\":26121},{\"end\":26656,\"start\":26572},{\"end\":27360,\"start\":27275},{\"end\":28680,\"start\":28575},{\"end\":29502,\"start\":29432},{\"end\":29722,\"start\":29712},{\"end\":29902,\"start\":29854},{\"end\":30246,\"start\":30165},{\"end\":30623,\"start\":30544},{\"end\":30902,\"start\":30822},{\"end\":31253,\"start\":31190},{\"end\":32036,\"start\":31972}]", "bib_author": "[{\"end\":25779,\"start\":25769},{\"end\":25791,\"start\":25779},{\"end\":25804,\"start\":25791},{\"end\":25817,\"start\":25804},{\"end\":26198,\"start\":26188},{\"end\":26208,\"start\":26198},{\"end\":26218,\"start\":26208},{\"end\":26229,\"start\":26218},{\"end\":26238,\"start\":26229},{\"end\":26249,\"start\":26238},{\"end\":26261,\"start\":26249},{\"end\":26275,\"start\":26261},{\"end\":26285,\"start\":26275},{\"end\":26295,\"start\":26285},{\"end\":26669,\"start\":26658},{\"end\":26679,\"start\":26669},{\"end\":26690,\"start\":26679},{\"end\":27368,\"start\":27362},{\"end\":27382,\"start\":27368},{\"end\":27400,\"start\":27382},{\"end\":27406,\"start\":27400},{\"end\":28107,\"start\":28096},{\"end\":28272,\"start\":28259},{\"end\":28286,\"start\":28272},{\"end\":28302,\"start\":28286},{\"end\":28693,\"start\":28682},{\"end\":28702,\"start\":28693},{\"end\":28710,\"start\":28702},{\"end\":29512,\"start\":29504},{\"end\":29519,\"start\":29512},{\"end\":29533,\"start\":29519},{\"end\":29540,\"start\":29533},{\"end\":29741,\"start\":29724},{\"end\":29750,\"start\":29741},{\"end\":29914,\"start\":29904},{\"end\":29936,\"start\":29914},{\"end\":30261,\"start\":30248},{\"end\":30275,\"start\":30261},{\"end\":30284,\"start\":30275},{\"end\":30297,\"start\":30284},{\"end\":30637,\"start\":30625},{\"end\":30651,\"start\":30637},{\"end\":30914,\"start\":30904},{\"end\":30923,\"start\":30914},{\"end\":30933,\"start\":30923},{\"end\":31267,\"start\":31255},{\"end\":31279,\"start\":31267},{\"end\":31289,\"start\":31279},{\"end\":31302,\"start\":31289},{\"end\":31311,\"start\":31302},{\"end\":31703,\"start\":31691},{\"end\":31719,\"start\":31703},{\"end\":31730,\"start\":31719},{\"end\":32050,\"start\":32038},{\"end\":32059,\"start\":32050},{\"end\":32453,\"start\":32446},{\"end\":32459,\"start\":32453},{\"end\":32468,\"start\":32459},{\"end\":32476,\"start\":32468}]", "bib_venue": "[{\"end\":25843,\"start\":25832},{\"end\":26080,\"start\":26046},{\"end\":26318,\"start\":26295},{\"end\":26802,\"start\":26713},{\"end\":27490,\"start\":27406},{\"end\":28041,\"start\":28005},{\"end\":28257,\"start\":28197},{\"end\":28491,\"start\":28455},{\"end\":28832,\"start\":28740},{\"end\":29329,\"start\":29277},{\"end\":29551,\"start\":29540},{\"end\":29760,\"start\":29750},{\"end\":29994,\"start\":29936},{\"end\":30304,\"start\":30297},{\"end\":30668,\"start\":30651},{\"end\":30980,\"start\":30933},{\"end\":31391,\"start\":31321},{\"end\":31812,\"start\":31730},{\"end\":32146,\"start\":32059},{\"end\":32444,\"start\":32352},{\"end\":32805,\"start\":32631},{\"end\":26895,\"start\":26804},{\"end\":27578,\"start\":27492},{\"end\":28855,\"start\":28834},{\"end\":31451,\"start\":31393}]"}}}, "year": 2023, "month": 12, "day": 17}