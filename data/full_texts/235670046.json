{"id": 235670046, "updated": "2023-10-06 01:57:52.871", "metadata": {"title": "Improving Transferability of Adversarial Patches on Face Recognition with Generative Models", "authors": "[{\"first\":\"Zihao\",\"last\":\"Xiao\",\"middle\":[]},{\"first\":\"Xianfeng\",\"last\":\"Gao\",\"middle\":[]},{\"first\":\"Chilin\",\"last\":\"Fu\",\"middle\":[]},{\"first\":\"Yinpeng\",\"last\":\"Dong\",\"middle\":[]},{\"first\":\"Wei\",\"last\":\"Gao\",\"middle\":[]},{\"first\":\"Xiaolu\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Jun\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Jun\",\"last\":\"Zhu\",\"middle\":[]}]", "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "journal": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "publication_date": {"year": 2021, "month": 6, "day": 29}, "abstract": "Face recognition is greatly improved by deep convolutional neural networks (CNNs). Recently, these face recognition models have been used for identity authentication in security sensitive applications. However, deep CNNs are vulnerable to adversarial patches, which are physically realizable and stealthy, raising new security concerns on the real-world applications of these models. In this paper, we evaluate the robustness of face recognition models using adversarial patches based on transferability, where the attacker has limited accessibility to the target models. First, we extend the existing transfer-based attack techniques to generate transferable adversarial patches. However, we observe that the transferability is sensitive to initialization and degrades when the perturbation magnitude is large, indicating the overfitting to the substitute models. Second, we propose to regularize the adversarial patches on the low dimensional data manifold. The manifold is represented by generative models pre-trained on legitimate human face images. Using face-like features as adversarial perturbations through optimization on the manifold, we show that the gaps between the responses of substitute models and the target models dramatically decrease, exhibiting a better transferability. Extensive digital world experiments are conducted to demonstrate the superiority of the proposed method in the black-box setting. We apply the proposed method in the physical world as well.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2106.15058", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/XiaoGFDGZ0021", "doi": "10.1109/cvpr46437.2021.01167"}}, "content": {"source": {"pdf_hash": "cef2370a769df907e0badcf1c80081f7efcdb1f3", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2106.15058v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2106.15058", "status": "GREEN"}}, "grobid": {"id": "15c57eb80b20915c8dfc54414b580e1380032784", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/cef2370a769df907e0badcf1c80081f7efcdb1f3.txt", "contents": "\nImproving Transferability of Adversarial Patches on Face Recognition with Generative Models\n\n\nZihao Xiao zihao.xiao@realai.ai \n\u2020 Xianfeng Gao \nBeijing Institute of Technology\n\n\nChilin Fu chilin.fcl@antgroup.com \nAnt Financial\n\n\nYinpeng Dong \nTsinghua University\n\n\nWei Gao \nNanyang Technological University\n\n\n\u2021 Xiaolu Zhang \nAnt Financial\n\n\nJun Zhou jun.zhoujun@antfin.com \nAnt Financial\n\n\nJun Zhu \nTsinghua University\n\n\nRealai \nImproving Transferability of Adversarial Patches on Face Recognition with Generative Models\n\nFace recognition is greatly improved by deep convolutional neural networks (CNNs). Recently, these face recognition models have been used for identity authentication in security sensitive applications. However, deep CNNs are vulnerable to adversarial patches, which are physically realizable and stealthy, raising new security concerns on the real-world applications of these models. In this paper, we evaluate the robustness of face recognition models using adversarial patches based on transferability, where the attacker has limited accessibility to the target models. First, we extend the existing transfer-based attack techniques to generate transferable adversarial patches. However, we observe that the transferability is sensitive to initialization and degrades when the perturbation magnitude is large, indicating the overfitting to the substitute models. Second, we propose to regularize the adversarial patches on the low dimensional data manifold. The manifold is represented by generative models pre-trained on legitimate human face images. Using face-like features as adversarial perturbations through optimization on the manifold, we show that the gaps between the responses of substitute models and the target models dramatically decrease, exhibiting a better transferability. Extensive digital world experiments are conducted to demonstrate the superiority of the proposed method in the black-box setting. We apply the proposed method in the physical world as well.\n\nIntroduction\n\nDeep convolutional neural networks (CNNs) have led to substantial performance improvements on many com- puter vision tasks. As an important task, face recognition is also greatly facilitated by deep CNNs [18,24,5]. Due to their excellent recognition performance, deep face recognition models have been used for identity authentication in security-sensitive applications, e.g., finance/payment, public access, face unlock on smart phones, etc.\n\nHowever, deep CNNs are shown to be vulnerable to adversarial examples at test time [22,6]. Adversarial examples are elaborately perturbed images that can fool models to make wrong predictions. Early adversarial examples on deep CNNs are indistinguishable from legitimate ones for human observers by slightly perturbing every pixel in an image. Later, [19] proposes adversarial patches, which only perturb a small cluster of pixels. Several works have shown that the adversarial patches can be made into physical objects to fool deep CNNs in the wild. For example, [10,20,25] use adversarial stickers or T-shirts to fool special purpose object detectors. [19] proposes an adversarial eyeglass frame to impersonate another identity against face recognition models. These works show that adversarial patches are physically realizable and stealthy. Using the adversarial patches in the physical world, the attacker can fool a recognition model without accessing the digital input to it, making them an emerging threat to deep learning applications, especially to face recognition systems in security-sensitive scenarios.\n\nPrevious works on adversarial patches are developed under the white-box setting [10,20,3,19], where the attacker knows the parameters of the target model, or under the query-based setting [19,28], where the attacker can make many queries against the target model. But for a black-box model deployed in the wild, both the white-box information and the excessive queries are not easily attainable. In this paper, we focus on evaluating the robustness of face recognition models under the query-free black-box setting, which is a more severe and realistic threat model.\n\nUnder the query-free black-box setting, the adversarial attacks based on transferability are widely used. Transferbased attacks [11] leverage that the adversarial examples for the white-box substitute models are also effective at the black-box target models. Specifically, most adversarial algorithms perform optimization on an adversarial objective specified by the substitute models as a surrogate, to approximate the true (but unknown) adversarial objective on the black-box target models. Existing techniques on improving the transferability of adversarial examples focus on using advanced non-convex optimization [7], data augmentations [27,8], etc. These techniques are originally proposed to generate L p -norm (p > 0) constrained adversarial examples, and we show that they can be extended to improve the transferability of adversarial patches as well.\n\nHowever, even though these techniques are extended and applied in the patch setting, we still observe it easy for the optimization to be trapped into local optima with unsatisfactory transferability. First, the transferability is sensitive to initialization of the algorithms. Second, if the perturbation magnitude increases, the transferability first rises and then falls, exhibiting an overfitting phenomenon. The difficulties in escaping solutions of unsatisfactory transferability indicate that the optimization is prone to overfitting the substitute model and new regularization methods are required.\n\nWe propose to regularize the adversarial patch by optimizing it on a low-dimensional manifold. Specifically, the manifold is represented by a generative model and the optimization is conducted in its latent space. The generative model is pre-trained on legitimate human face data and can generate diverse and unseen human face images by manipu-lating the latent vectors to assemble different face features. By optimizing the adversarial objective on this latent space, the adversarial perturbations resemble human face features (see Fig. 1, (d)), on which the predictions of the white-box substitute and the black-box target model are more related. Consequently, the overfitting problem is relieved and the transferability is improved.\n\nExtensive experiments are conducted to show the superiority of the proposed method for black-box attacks on face recognition. We show its effectiveness in the physical world as well. Finally, we extend the proposed method to other tasks, e.g., image classification.\n\n\nRelated work 2.1. Adversarial patches\n\nMost existing works on adversarial patches are designed for the white-box setting [19,10,20,3,25] or the querybased black-box setting [19,28]. This paper focuses on the query-free black-box setting, a realistic assumption on the adversary's knowledge on the target models deployed in the wild [7]. Although some works demonstrate results on query-free attacks [3,25], their methods are not optimized for this setting and not optimal.\n\n\nTransferable adversarial examples\n\nThere are many works proposed for improving the transferability of adversarial examples, and most of them are developed under the L p -norm constrained setting [7,27,8]. In contrast, we focus on adversarial patches, a different condition on the adversary's capacity to perturb the visual inputs. Adversarial patches are physically realizable and stealthy, posing threats to target models deployed in the wild. In this paper, we show that while many methods proposed for the L p -norm constrained setting are useful for the patch setting, they are still prone to overfitting the substitute models and new regularization techniques are required.\n\n\nGenerative modeling for adversarial examples\n\nResearchers have discovered that using generative models to generate adversarial examples has advantages. For example, efficient attack algorithms are proposed for whitebox attacks [26] and query-based attacks [23,29]. Emerging threat models are studied using generative models as well, e.g., unrestricted adversarial examples [21] and semantic adversarial examples [17]. Unrestricted adversarial examples are closely related to adversarial patches, but [21] does not show an improvement of transferability. Although SemanticAdv [17] claims an improvement of transferability in their setting 1 , we show that it is sub-optimal in the patch setting. Our work shows how to adequately use generative models to improve the transferability of adversarial patches.\n\n\nMethodology\n\nThis section introduces our method of generating adversarial patches on face recognition models with generative models. Sec. 3.1 introduces the attack setting. Sec. 3.2 extends the existing transfer-based attack methods from the L p -norm constrained setting to the patch setting, and show their problems. Sec. 3.3 elaborates the proposed method.\n\n\nAttack setting\n\nFace recognition usually includes face verification and face identification. The former identifies whether two face images belong to the same identity, while the latter classifies an image to a specific identity. For face verification, the similarity between two faces are compared with a threshold to give the prediction. For face identification, the similarity between a face image and those of a gallery set of face images is compared, and the input image is recognized as the identity whose representation is most similar to its.\n\nLet f (x) : X \u2192 R d denote a face recognition model that extracts a normalized feature representation vector for an input image x \u2208 X \u2282 R n . Given a pair of face images {x s , x t }, the face recognition model estimates the similarity between the two faces by calculating the distance between the feature vectors extracted from the two images\nD f (x s , x t ) = ||f (x s ) \u2212 f (x t )|| 2 2 .(1)\nAnd face verification and identification methods are done based on this similarity score D f or its simple variants. An adversary has generally two goals against the face recognition models -dodging and impersonation. Dodging attack aims to generate an adversarial face image that is recognized wrongly, which can be utilized to protect privacy against excessive surveillance. For face verification, the adversary can modify one image from a pair of images belonging to the same identity, to make the model recognize them as different identities. For face identification, the adversary generates an adversarial face image such that it is recognized as any other false identity.\n\nImpersonation attack corresponds to generating an adversarial face image that is recognized as an adversaryspecified target identity, which could be used to evade the face authentication systems. For face verification, the attacker aims to find an adversarial image that is recognized as the same identity of another image, while the original images are from different identities. For face identification, the generated adversarial image is expected to be classified as a specific identity.\n\n\nTransferable adversarial patch\n\nIn the query-free black-box setting, the detailed information of the target model is unknown and an excessive amount of queries are not allowed. The adversarial attacks based on transferability [7,27] show that, the adversarial examples for some white-box substitute model g can remain adversarial for the black-box target model f . We focus on generating transferable adversarial patches (TAPs).\n\nSuppose g is a white-box face recognition model that is accessible to the attacker, and it can also define a similarity score D g (x s , x t ) for face recognition, similar to Eq. (1). An adversary solves the following optimization problem to generate the adversarial patch on the substitute model [19]:\nmax x L g (x, x t ), s.t. x (1 \u2212 M) = x s (1 \u2212 M),(2)\nwhere L g is a differentiable adversarial objective, is the element-wise product, and M \u2208 {0, 1} n is a binary mask. The constrain emphasizes that only the pixels whose corresponding elements in M are 1 can be perturbed. Fig. 1 demonstrates how the masks M control the regions of the adversarial patches. We use L g = D g for dodging attack and L g = \u2212D g for impersonation attack, respectively. In this paper, we fix the adversarial loss to fairly compare different techniques operated on the input x.\n\nExisting works on improving the transferability of adversarial examples focus on the L p -norm constrained setting. We can extend them to the patch setting. The vanilla algorithm is to use the momentum iterative method (MIM) [7] to solve the optimization problem (2). We denote this algorithm as TAP-MIM. Advanced techniques to improve the transferability can be applied, e.g. the data augmentations in TI-DIM [27,9]. The overall algorithm is depicted in Alg. 1 and is denoted as TAP-TIDIM. In the experiment (Sec. 4.2), we show that TAP-TIDIM outperforms TAP-MIM, indicating that methods proposed for the L p -norm constrained setting might also be useful for the patch setting. Note that the TAP-TIDIM algorithm is similar with using the EoT technique [2] to generate universal and physical-world adversarial patches in the white-box setting [3,10,20] However, even for the more advanced TAP-TIDIM algorithm, it is still difficult for the optimization to escape local optima with unsatisfactory transferability. Specifically, we observe the following two phenomena in our ablation studies (the details are in Sec. 4.3):\n\n\u2022 The transferability is sensitive to the initialization of the optimization. Note that TAP-TIDIM uses the face image of the attacker to initialize the patch, i.e.,x 0 = x s (see line 2 of Alg. 1). For the impersonation attack, a simple modification is to use the face image of the target identity to initialize the patch, i.e.,x 0 = x t . The modified algorithm is denoted as TAP-TIDIMv2. Experiments show that, TAP-TIDIMv2 finds solutions with significantly higher transferability than TAP-TIDIM by simply changing the initialization step (see Tab. 2).\n\n\u2022 The transferability degrades when the search space is large. Specifically, we apply an additional L \u221e -norm con- Input T (x * n ) and obtain the loss Lg(T (x * n ), xt) 7:\n\nObtain the gradient \u2207x=x n Lg(T (x * n )); 8: Convolve the gradient as in [8] \nW * \u2207xLg(T (x * n )),\nwhere W is the Gaussian kernel and * is convolution; 9: Update gt+1 as in [7] \ngn+1 = \u00b5 \u00b7 gn + W * \u2207xLg(T (x * n )) W * \u2207xLg(T (x * n )) 1 ; 10:\nUpdatexn+1 by applying the sign gradient as\nxn+1 = Clip [x * 0 \u2212 ,x * 0 + ] x n \u2212 \u03b1 \u00b7 sign(gn+1) ; 11: end for 12: return x * = xs (1 \u2212 M) +xN M.\nstrain on the optimization problem (2) to control the size of the search space, i.e., |(x \u2212 x s ) M| \u221e \u2264 . The L \u221enorm constrain bounds the maximum allowable perturbation magnitude [11]. Our ablation studies show that, when increases, the transferability first rises and then falls (see Fig. 3).\n\nThe aforementioned two phenomena are indicators that the optimization problem (2) has many local optima of unsatisfactory transferability and the adversarial patches are overfitting the substitute model. It is hard to escape from these solutions even though many existing regularization techniques [7,27,8] have been applied in TAP-TIDIM. Therefore, we resort to new regularization methods for the patch setting in the following section.\n\n\nGenerative adversarial patch\n\nWe propose to optimize the adversarial patch on a lowdimensional manifold as a regularization to escape from the local optima of unsatisfactory transferability in the optimization problem (2). The manifold poses a specific structure on the optimization dynamics. We consider a good manifold should have the following properties: 1. Sufficient capacity. The manifold should have a sufficient capacity so that the white-box attack on the substitute model is successful. 2. Well regularized. The manifold should be well regularized so that the responses of the substitute models and the target models are effectively related to avoid overfitting the substitute models.\n\nTo balance the demands for capacity and regularity, we use the manifold learnt by a generative model, where the generative model is pre-trained on natural human face data. Specifically, let h(s) : S \u2192 R n denote a pre-trained generative model and S is its latent space. The generative model can generate diverse and unseen human faces by manipulating the latent vector to assemble different face features, e.g., the color of eyeballs, the thickness of eyebrows, etc. We propose to use the generative model to generate the adversarial patch, and optimize the patch through the latent vector. The optimization problem (2) becomes:\nmax s\u2208S L g (x, x t ), s.t. x (1 \u2212 M) = x s (1 \u2212 M), x M = h(s) M(3)\nwhere the second constrain restricts the adversarial patch on the low-dimensional manifold represented by the generative model. When constrained on this manifold, the adversarial perturbations resemble face-like features. We expect that the responses to the face-like features are effectively related for different face recognition models, which improves the transferability of the adversarial patches. This hypothesis will be confirmed in experiments. The performance of the algorithms depends on the generative model h and the latent space S that define the manifold. In Sec. 4.4, we perform ablation studies on the architectures, parameters of the generative models h, as well as the latent spaces S. First, the capacity of the latent space influences the white-box attack on the substitute model. The latent space of the generative model should have sufficient capacity so that the optimization can find effective adversarial examples on the white-box substitute model. Second, we observe that a generative model, which can generate features semantically related to the adversarial task at hand (i.e. face features in our case), can effectively relate the responses from the substitute models and the target models and provide better regularity.\n\nA straightforward algorithm to solve the optimization problem (3) is to use the Adam optimizer [16]. We denote this algorithm as GenAP. Similar with TAP-TIDIM, existing techniques [27] can be incorporated. This algorithm is depicted in Alg. 2 and is denoted as GenAP-DI 2 .\n\n\nExperiments\n\nIn the experiments, we demonstrate the superiority of the proposed GenAP methods in black-box attacks. Sec. 4.1\n\n\nAlgorithm 2 Transferable Adversarial Patch: GenAP-DI\n\nInput: The adversarial objective function Lg; a real face image xs of the attacker; a real face images xt of the target identity; a binary mask matrix M. Input: A generative model h. Input: A set of transformations T ; iterations N ; a gradient-based optimizer, e.g., Adam [16]. Output: An adversarial image x * by solving Eq. (3).\n\n1: Randomly initialize the latent vector s * 0 \u223c N (0, I); 2: for n = 0 to N \u2212 1 do 3:\n\nSample a transformation T from T ; 4: Blend the adversarial patch to xs\nx * n = xs (1 \u2212 M) + h(s * n ) M; 5:\nInput T (x * n ) and obtain the loss Lg(T (x * n ), xt) 6: Obtain the gradient \u2207s=s * n Lg(T (x * n ));\n\n\n7:\n\nUpdate s * n+1 using the optimizer 8: end for \n9: return x * = xs (1 \u2212 M) + h(s * N ) M.\n\nExperimental setting\n\nDatasets. Two face image datasets are used for evaluation: LFW [12] and CelebA-HQ [13]. LFW is a dataset for unconstrained face recognition. CelebA-HQ is a human face dataset of high quality. The datasets are used to test the generalization of our methods on both low quality and high quality face images, as the generative models we used are essentially trained on high quality images. For each dataset, we select face image pairs to evaluate the adversarial algorithms on that dataset. For face verification, we select 400 pairs in dodging attack, where each pair belongs to the same identity, and another 400 pairs in impersonation attack, where the images from the same pair are from different identities. For face identification, we select 400 images of 400 different identities as the gallery set, and the corresponding 400 images of the same identities to form the probe set. Both dodging and impersonation are performed on the probe set. This setting follows [9]. Face recognition models. We study three face recognition models, including FaceNet [18], CosFace [24] and Ar-cFace [5], which all achieve over 99% accuracies on the LFW validation set. In testing, the feature representation for each input face image is extracted. Then, the cosine similarity between a pair of face images is calculated and compared with a threshold. We first calculate the threshold of each face recognition model by the LFW validation set. It contains 6, 000 pairs of images from same identi- ties (3, 000) and different identities (3, 000). We choose the threshold of each model that gives the highest accuracy on this validation set. In addition, we also evaluate the performance of our method on commercial face recognition systems-Face++ and Aliyun. Given a pair of face images, a system returns a score indicating their similarity. Generative models. We study three pre-trained generative models, including ProGAN [13], StyleGAN [14] and Style-GAN2 [15], which can generate face images of high quality. ProGAN has only one latent space. For StyleGANs, we use the Z, W, W + and the noise latent spaces [1,14].\n\nRegions of patches. We use two different regions to generate the patches, an eyeglass frame and a respirator, to show the generalization of the proposed methods to different face regions. The binary masks indicating the regions of these patches are displayed in Fig. 2. Evaluate Metrics. We use the thresholding strategy and nearest neighbor classifier for face verification and identification, respectively. To evaluate the attack performance, we report the success rate (higher is better) as the fraction of adversarial images that are not classified to the attacker himself by the model in dodging attack, and are misclassified to the desired target identity in impersonation attack.\n\n\nExperimental results\n\nIn this section, we present the experimental results of adversarial patches for black-box attack in the digital world. We generate adversarial patches using the TAP and the GenAP algorithms, respectively. In impersonation attack, we also use a vanilla baseline of pasting the corresponding face region from the target identity to the attacker (PASTE). We then feed the generated adversarial examples to our local models and commercial APIs to test the success rates of attacks. For the TAP algorithms, we use = 40, which achieves the best transferability as shown by the ablation study in Sec. 4.3. For the GenAP algorithms, we use Style-GAN2 and its W + plus the noise space as a representative, where the results of other generative models and latent spaces are left to ablation studies in Sec. 4.4. We show the results on the face verification task using the eyeglass frame in Tab. 1 (dodging) and 2 (impersonation). Results on face identification, the respirator mask and SemanticAdv [17] are in the supplementary materials, which are qualitatively similar with the results in Tab. 1 and 2.\n\nThe results show that the adversarial patches achieve high success rates on the black-box models. First, TAP-TIDIM outperforms TAP-MIM. This shows that applying the existing techniques [7,27,8] originally proposed to improve the transferability of L p -norm constrained adversarial examples against image classification models can be helpful for improving the transferability of adversarial patches against face recognition models as well. Second, the vanilla GenAP significantly outperforms TAP algorithms in most cases (except when using FaceNet as the substitute model for impersonation attack) without bells and whistles. These results show the effectiveness of the proposed regularization method to improve the transferability of the patches. Third, the vanilla GenAP and the more sophisticated GenAP-DI performs similarly, showing that applying additional techniques [27] do not necessarily significantly improve the performance of the GenAP algorithms. Forth, the GenAP algorithms significantly outperform PASTE. This shows that the GenAP algorithms do not naively generating the face features of the target identity, but search the optimal adversarial face features fitting the attacker's own face features. Fifth, our results also show the insecurity of the commercial systems (Face++ and Aliyun) against adversarial patches.\n\n\nAblation study on TAP-TIDIM\n\nThis section presents the ablation studies on the TAP algorithms to support the discussions in Sec. 3.2. These ablation studies show that TAP-TIDIM has trouble escaping local optima of unsatisfactory transferability, though many regularization methods have been used [27,8]. This motivates us to develop new regularization in this paper.\n\n\nSensitivity to initialization\n\nThe initialization step is the only difference between TAP-TIDIM and TAP-TIDIMv2 when solving problem (2). But TAP-TIDIMv2 shows significantly higher success rates in black-box impersonation attack, as shown in Tab. 2. While the solution of TAP-TIDIMv2 is within the search space of TAP-TIDIM 3 , TAP-TIDIM cannot find it and is trapped into local optima with significantly worse transferability.\n\n\nSensitivity to\n\nThe hyperparameter in TAP-TIDIM can control the upper bound for the perturbation magnitudes of the adversarial patches, which is an indicator of the size of the search space. The larger the , the larger the search space. Fig. 3 shows that, as the upper bound increases, the success rates on the black-box models first rise and then fall. When is small, 3 \n\n\nAblation study on GenAP\n\nIn this section, we present the ablation studies on the GenAP algorithms, which show how the regularity and the capacity of the manifold influence the transferability of the generative adversarial patches. This section use the GenAP algorithm and the eyeglass frame mask for experiments.\n\n\nParameters of the generative models\n\nWe use the StyleGAN2 with different parameters, including the parameters that are randomly initialized (Rand), trained on the LSUN car dataset (CAR) and trained on the FFHQ face image dataset (FFHQ). We use W + plus the noise space [1,14] as the latent space. Tab. 3(a) shows that using the randomly initialized model cannot find effective adversarial examples even in the white-box case. While the StyleGAN2 trained on CAR is effective at white-box attack, their transferability to black-box models is poor. The transferability of GenAP is better than the TAP algorithms (c.f., Tab. 2) only when the generative model is trained on human face dataset. This phenomenon indicates that using facelike features as perturbations is important for bridging the gap between the substitute and the target face recognition models to improve transferability in the GenAP methods.  \n\n\nArchitectures of the generative models\n\nWe use three different generative models, including Pro-GAN [13], StyleGAN [14] and StyleGAN2 [15]. These generative models differ in their network architectures and can generate human face images with higher and higher quality. For the StyleGANs, we use the W + latent plus the noise space [1,14]. The results are shown in Tab. 3(b). The performance of GenAP depends on the architectures of the generative models. Even though ProGAN is trained on human face images, it is difficult to find effective adversarial examples in its latent space, even in the white-box case. Both StyleGANs achieve high success rates against the black-box models. These phenomena indicate that the style-based decoder in StyleGANs might be important for the GenAP algorithms to find effective adversarial examples.\n\n\nLatent spaces of the generative models\n\nWe use different latent spaces for the StyleGAN2, including the Z, the W, the W + and the noise spaces [1,14]. The W + is more flexible than the Z, the W and the noise spaces with much more degrees of freedom. Tab. 3(c) shows that, the performance on the W and the W + spaces is substantially higher than that on the Z and the noise spaces. The optimizations in the Z and the noise spaces cannot find effective adversarial patches even in the white-box case.  \n\n\nPhysical-world experiment\n\nIn this section, we verify that the adversarial patches generated by the proposed GenAP algorithms are physically realizable, and their superiority is retained after printing and photographing. Specifically, we select a volunteer as the attacker and 3 target identities (one male and two females) from the CelebA-HQ dataset. For each target identity, we generate an eyeglass frame for the attacker to impersonate that identity. After the attacker wears the adversarial eyeglass frame, we take a video of him from the front and randomly select 100 video frames. The video frames are used for face verification. We evaluate the transferability of the patches using the cosine similarities. The higher the similarity, the better the transferability. Results in Fig.4 show that the patches generated by the proposed GenAP-DI retain high transferability even after printing and photographing.\n\n\nExtra experiments\n\nIn the supplementary material, we also compare the proposed GenAP methods with an existing method of using face-like features as adversarial perturbations, Semanti-cAdv [17], and extend the GenAP methods to other tasks, e.g., image classification. First, we explain why Seman-ticAdv is sub-optimal in the patch setting. Second, we show the generalizability of the proposed GenAP methods to other recognition tasks.\n\n\nConclusion\n\nIn this paper, we evaluate the robustness of face recognition models against adversarial patches in the query-free  Table 4. The cosine similarties between the attacker wearing the adversarial eyeglass frame and three different target identities in the physical-world. The target identities are randomly drawn from CelebA-HQ. The adversarial eyeglass frame is crafted by the TAP-TIDIMv2 and the proposed GenAP-DI algorithms on ArcFace, and is tested on CosFace and FaceNet. black-box setting. Firstly, we extend existing techniques from the L p -constrained (p > 0) setting to the patch setting, yielding TAP algorithms to generate transferable adversarial patches. However, several experimental phenomena indicate that it is hard for the TAP algorithms to escape from local optima with unsatisfactory transferability. Therefore, we propose to regularize the adversarial patches on the manifold learnt by generative models pre-trained on human face images. The perturbations in the proposed GenAP algorithms resemble face-like features, which is important for reducing the gap between the substitute and the target face recognition models. Experiments confirm the superiority of the proposed methods.\n\nIn the main text, we present the attack success rates on using adversarial eyeglass frames to perform dodging and impersonation attacks on the face verification task. In this section, we present the success rates on dodging and impersonation attacks on the face identification task in Tab. 5 and 6. The conclusions on these results are consistent.\n\nMoreover, we visualize the adversarial examples generated by the TAP-TIDIM and the GenAP-DI methods for dodging attack (see Fig. 4) and impersonation attack (see Fig. 5), respectively. The proposed GAP methods generates face-like features as perturbations.\n\n\nC. Experiments on adversarial respirators\n\nIn this section, we present the results on adversarial respirators to show the generalization of the proposed methods to different regions of the adversarial patches. Tab. 7, 8 show the results on dodging and impersonation attack, respectively, on the face verification task. Tab. 9, 10 show the results on face identification task. The conclusions are consistent with those drawn from the adversarial eyeglass frames. We visualize the adversarial examples in Fig. 6 and Fig. 7.\n\n\nD. Experiments on SemanticAdv\n\nSemanticAdv [17] uses StarGAN [4] to adversarially perturb the attributes in a face image. This is very similar with our idea of using face-like features to generate adversarial perturbations. Nevertheless, SemanticAdv proposed to generate the adversarial example by interpolation between two feature maps. Their algorithm is designed for the imperceptible setting, where the adversarial perturbation should be indistinguiable from the original image. However, the slight perturbation limits their performance in the patch setting, where the perturbation is allowed to be perceptible. Instead, the proposed GenAP algorithms can leverage the relaxation on perceptibility to improve the attack success rates. We perform experiments to verify this point in the following.\n\nSpecifically, we use the code from SemanticAdv 12 to reproduce their results. We use the first 100 image pairs from their dataset (Celeba) to compare the algorithms. The code performs targeted attack on face verification. We modify their code to 1) perturb only the eyeglass frame region, 2) use our substitute models. Since their method generates adversarial examples for each attributes for each attackertarget pair, we consider their attack for an image pair is successful if the attack from any attribute is successful. The results are shown in Tab. 11. Our methods significantly outperforms theirs in the patch setting. In this setting, the slight perturbation generated by their method has difficulty in even white-box attacks.\n\n\nE. Experiments on image classification\n\nThe proposed GenAP methods can be easily extended to the image classification task by replacing the adversarial losses for face recognition (Eq. (2) in the main text) by the cross-entropy loss [11] widely used in image classification. This section shows the effectiveness of the GenAP algorithms on the image classification tasks.\n\nWe use two datasets, CIFAR10 and ImageNet. The images from these two datasets are 32 \u00d7 32 and 224 \u00d7 224, respectively. The adversarial patch region is designed to be a square at the center of the image. We observe the experimental results by changing the length of the square. The detailed information of the recognition models, generative models and lengths of the square patches are listed in Tab. 12. All models are accessible from the Internet 13 To evaluate the attack performance, we report the success rate (higher is better) as the fraction of adversarial images that 12 https://github.com/AI-secure/SemanticAdv 13 CIFAR recognition models:\n\nhttps : / / github . com / huyvnphan / PyTorch _ CIFAR10, CIFAR10 generative models: https://github.com/NVlabs/stylegan2-ada-pytorch, ImageNet recognition models:\n\nhttps : / / pytorch . org / vision / stable / models . html, ImageNet generative models: https://github.com/ajbrock/BigGAN-PyTorch  are misclassified to the desired target class (i.e., targeted attack). For each dataset, we randomly sample 1000 images. For each image, we randomly sample a distinct class as the target.\n\nFor the TAP algorithms, we set = 255. For the GenAP algorithms on CIFAR10, we introduce several GenAP algorithms that optimize in different latent spaces. StyleGAN2-ADA is a conditional generative model. First, the GenAPcond algorithm uses the image directly generated by the generative model conditional on the target class. Second, the GenAP-DI-cond-opt algorithm is the GenAP-DI algorithm optimized in the Z space, with the conditional variable set to the target class. Third, the GenAP-DI-uncondopt algorithm is a GenAP-DI algorithm optimized in the W + plus the noise space. Similarly, GenAP algorithms are introduced on ImageNet. Since BigGAN is also a condi-tional generative model, we can also define the corresponding GenAP-cond and GenAP-DI-cond-opt algorithm with it.\n\nThe experimental results on CIFAR10 are shown in Tab. 13. We have the following observations. First, when the patch size is very small, the TAP algorithms achieve higher success rates on white-box attack by leveraging the larger search space (i.e., without regularization). Second, optimizing the latent spaces of the generative models yield better results than naively using the inference results from the conditional generative model (GenAP-DI-uncond-opt and GenAP-DI-cond-opt v.s. GenAP-cond). Third, the GenAP-DI-cond-opt outperforms the TAP-TIDIM in blackbox attacks when the patch size is as small as 8 \u00d7 8, which occupies 6% of the whole image.\n\nThe experiments results on ImageNet are shown in Attacker TAP-TIDIM GenAP-DI  Tab. 14. The observations are consistent with those on CIFAR-10. The GenAP-DI-cond-opt outperforms the TAP-TIDIM in black-box attacks when the patch size is as small as 60 \u00d7 60, which occupies 7% of the whole image.   Attacker TAP-TIDIM GenAP-DI Figure 6. Visualization of adversarial respirators generated by the TAP-TIDIM and the GenAP-DI methods for dodging attack. The first three rows are the demonstrations on CelebA-HQ dataset and the others are from LFW dataset. And the three columns denotes the pictures of attackers and attackers with the adversarial respirators by generated by TAP-TIDIM and GenAP-DI methods separately. In TAP-TIDIM, we use = 255.\n\n\nAttacker\n\nTarget identity TAP-TIDIM GenAP-DI  Table 14. The success rates of black-box targeted attack on ImageNet dataset using adversarial patches. The adversarial patches are generated against ResNet101. * indicates white-box attacks.\n\nFigure 1 .\n1Demonstration of adversarial patches against face recognition models. (a) The attacker who wants to impersonate the target identity. (b) An image of the target identity. (c) The adversarial patch and the corresponding adversarial example generated by the TAP-TIDIM algorithm. (d) The adversarial patch and the corresponding adversarial example generated by the proposed GenAP-DI algorithm. The proposed GenAP algorithms use face-like features as perturbations to improve the transferability.\n\n\nThe adversarial objective function Lg; a real face image xs of the attacker; a real face images xt of the target identity; a binary mask matrix M. Input: A set of transformations T ; the size of perturbation ; learning rate \u03b1; iterations N ; decay factor \u00b5. Output: An adversarial image x * by solving Eq. (2).1: g0 = 0; 2:x0 = xs; 3: for n = 0 to N \u2212\n\nFigure 2 .\n2The binary masks M indicating the regions of the designed patches. (a) An eyeglass frame. (b) A respirator.\n\n\nStrictly speaking, the solution of TAP-TIDIMv2 is within the search space of TAP-TIDIM ( = 255) and the results in Tab. 2 are for TAP-TIDIM ( = 40). Nevertheless, the TAP-TIDIM ( = 40) outperforms TAP-TIDIM ( = 255) as shown in Fig. 3 and our conclusion holds.\n\nFigure 3 .\n3The success rates of TAP-TIDIM on the black-box models first rise and then fall when the maximal perturbation magnitude increases. This indicates that the adversarial patches are overfitting the substitute model. The results are black-box impersonation attack on FaceNet and CosFace under the face verification task. The adversarial examples are generated against ArcFace by restricting the adversarial patches to an eyeglass frame region. 200 image pairs from the LFW dataset are used. the transferability benefits from the larger search space by finding more effective adversarial examples against the substitute model. But when is large, the adversarial patches overfit the substitute model and are trapped into poor local optima. The transferability of TAP-TIDIM reaches the optimality around = 40, which is used in Sec. 4.2.\n\nTable 2 .\n2The success rates of black-box impersonation attack on FaceNet, CosFace, ArcFace, Face++ and Aliyun in the digital world under the face verification task. The adversarial examples are generated against FaceNet, CosFace, and ArcFace by restricting the adversarial patches to an eyeglass frame region. * indicates white-box attacks.\n\nTable 3 .\n3The success rates of black-box impersonation attack when the architectures, the parameter and the latent space are changed in the proposed GenAP algorithm. The adversarial examples are generated against ArcFace by restricting the adversarial patches to an eyeglass frame region, and are tested on FaceNet, CosFace and ArcFace in the digital world under the face verification task. * indicates white-box attacks. The ablation studies are on (a) the parameters (RAND, CAR and FFHQ) of the StyleGAN2, (b) the architectures of the generative model (ProGAN, StyleGAN, StyleGAN2) and (c) the latent space (Z, W, W + and noise) used by StyleGAN2 trained on FFHQ.\n\n\nTable 6. The success rates of black-box impersonation attack on FaceNet, CosFace, ArcFace in the digital world under the face identification task. The adversarial examples are generated against FaceNet, CosFace, and ArcFace by restricting the adversarial patches to a eyeglass frame region. * indicates white-box attacks.\n\nFigure 4 .Figure 5 .\n45Visualization of adversarial eyeglass frames generated by the TAP-TIDIM and the GenAP-DI methods for dodging attack. The first three rows are the demonstrations on CelebA-HQ dataset and the others are from LFW dataset. And the three columns denotes the pictures of attackers and attackers with the adversarial eyeglass frames by generated by TAP-TIDIM and GenAP-DI methods separately. In TAP-TIDIM, we use = 255. Visualization of adversarial eyeglass frames generated by the TAP-TIDIM and the GenAP-DI methods for impersonation attack. The first three rows are the demonstrations on CelebA-HQ dataset and the others are from LFW dataset. The first two columns are the photos of attackers and their target identities, and the following two columns show the attackers with the adversarial eyeglass frames generated by the proposed TAP-TIDIM and GenAP-DI methods. In TAP-TIDIM, we use = 40.\n\nFigure 7 .\n7Visualization of adversarial respirators generated by the TAP-TIDIM and the GenAP-DI methods for impersonation attack. Table format follows theFig.5. The first three rows are the demonstrations on CelebA-HQ dataset and the others are from LFW dataset. The first two columns are the photos of attackers and their target identities, and the following two columns show the attackers with the adversarial respirators generated by the proposed TAP-TIDIM and GenAP-DI methods. In TAP-TIDIM, we use = 40. . The success rates of black-box targeted attack on CIFAR-10 dataset using adversarial patches. The adversarial patches are generated against ResNet50. * indicates white-box attacks.\n\n\nperform ablation studies on the TAP and the GenAP algorithms respectively. Sec. 4.5 presents the physical-world results.introduces the experimental setting. Sec. 4.2 presents the \nresults in the digital-world attack setting. Sec. 4.3 and 4.4 \n\n\n\nTable 1. The success rates of black-box dodging attack on FaceNet, CosFace, ArcFace, Face++ and Aliyun in the digital world under the face verification task. The adversarial examples are generated against FaceNet, CosFace, and ArcFace by restricting the adversarial patches to an eyeglass frame region. * indicates white-box attacks.Attack \n\nCelebA-HQ \nLFW \nArcFace CosFace FaceNet Face++ Aliyun ArcFace CosFace FaceNet Face++ Aliyun \n\nArcFace \n\nTAP-MIM \nTAP-TIDIM \nGenAP (ours) \nGenAP-DI (ours) \n\n0.9875  *  \n1.0000  *  \n0.9975  *  \n1.0000  *  \n\n0.1800 \n0.2975 \n0.6100 \n0.5050 \n\n0.6475 \n0.7050 \n0.9375 \n0.8600 \n\n0.0000 \n0.1625 \n0.7975 \n0.6600 \n\n0.1800 \n0.7350 \n0.9900 \n0.9800 \n\n0.9850  *  \n1.0000  *  \n0.9975  *  \n1.0000  *  \n\n0.1475 \n0.2500 \n0.4850 \n0.4050 \n\n0.4275 \n0.5200 \n0.8725 \n0.7725 \n\n0.0075 \n0.1550 \n0.7450 \n0.6250 \n\n0.1850 \n0.5850 \n0.9850 \n0.9850 \n\nCosFace \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n0.0475 \n0.0025 \n0.5375 \n0.3650 \n\n0.9925  *  \n1.0000  *  \n0.9975  *  \n1.0000  *  \n\n0.6950 \n0.4925 \n0.9550 \n0.9150 \n\n0.0025 \n0.0350 \n0.5675 \n0.3675 \n\n0.4250 \n0.6550 \n1.0000 \n0.9950 \n\n0.0125 \n0.0100 \n0.3650 \n0.2175 \n\n0.9975  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.4950 \n0.3550 \n0.9275 \n0.9025 \n\n0.0075 \n0.0425 \n0.5600 \n0.3900 \n\n0.5350 \n0.5650 \n0.9900 \n0.9800 \n\nFaceNet \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n0.0250 \n0.0025 \n0.3575 \n0.2100 \n\n0.2100 \n0.1525 \n0.3475 \n0.1950 \n\n0.9900  *  \n0.9975  *  \n0.9975  *  \n0.9975  *  \n\n0.0025 \n0.0775 \n0.5675 \n0.4400 \n\n0.2350 \n0.7050 \n1.0000 \n0.9800 \n\n0.0075 \n0.0025 \n0.1950 \n0.0950 \n\n0.1475 \n0.1025 \n0.2450 \n0.1500 \n\n0.9675  *  \n1.0000  *  \n0.9950  *  \n0.9925  *  \n\n0.0050 \n0.0850 \n0.5550 \n0.3625 \n\n0.3400 \n0.6300 \n0.9950 \n0.9700 \n\nAttack \nCelebA-HQ \nLFW \nArcFace CosFace FaceNet Face++ Aliyun ArcFace CosFace FaceNet Face++ Aliyun \nPASTE \n0.4725 \n0.3700 \n0.3000 0.2425 0.0900 0.4150 \n0.3100 \n0.1825 0.1775 0.0250 \n\nArcFace \n\nTAP-MIM \nTAP-TIDIM \nTAP-TIDIMv2 \nGenAP (ours) \nGenAP-DI (ours) \n\n0.9900  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.3100 \n0.3675 \n0.4975 \n0.5825 \n0.5300 \n\n0.2325 \n0.2725 \n0.3425 \n0.4625 \n0.4100 \n\n0.1250 \n0.1900 \n0.2525 \n0.3425 \n0.3500 \n\n0.0400 \n0.0650 \n0.0750 \n0.1700 \n0.1450 \n\n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.2600 \n0.3125 \n0.4225 \n0.5000 \n0.4325 \n\n0.1875 \n0.2025 \n0.2350 \n0.4000 \n0.3275 \n\n0.0425 \n0.0800 \n0.1250 \n0.2125 \n0.1825 \n\n0.0100 \n0.0150 \n0.0050 \n0.1000 \n0.0550 \n\nCosFace \n\nTAP-MIM \nTAP-TIDIM \nTAP-TIDIMv2 \nGenAP \nGenAP-DI \n\n0.4275 \n0.4550 \n0.5250 \n0.6575 \n0.6325 \n\n0.9900  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.3125 \n0.3725 \n0.4175 \n0.5250 \n0.5325 \n\n0.1425 \n0.2000 \n0.2650 \n0.3500 \n0.3275 \n\n0.0450 \n0.0750 \n0.0950 \n0.2000 \n0.1900 \n\n0.3250 \n0.2725 \n0.3625 \n0.5350 \n0.4975 \n\n0.9850  *  \n1.0000  *  \n1.0000  *  \n0.9975 \n1.0000  *  \n\n0.2525 \n0.2700 \n0.3225 \n0.4600 \n0.4650 \n\n0.0550 \n0.0750 \n0.1325 \n0.2100 \n0.2000 \n\n0.0200 \n0.0150 \n0.0100 \n0.0700 \n0.1000 \n\n\n\n\nTable 5. The success rates of black-box dodging attack on FaceNet, CosFace, ArcFace in the digital world under the face identification task. The adversarial examples are generated against FaceNet, CosFace, and ArcFace by restricting the adversarial patches to a eyeglass frame region. * indicates white-box attacks.Attack \n\nCelebA-HQ \nLFW \nArcFace \nCosFace \nFaceNet \nArcFace \nCosFace \nFaceNet \n\nArcFace \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n0.9875  *  \n1.0000  *  \n0.9950  *  \n1.0000  *  \n\n0.3000 \n0.3750 \n0.7100 \n0.5975 \n\n0.7550 \n0.8050 \n0.9650 \n0.9200 \n\n0.9875  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.2150 \n0.3250 \n0.5650 \n0.4750 \n\n0.5950 \n0.6625 \n0.9250 \n0.8500 \n\nCosFace \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n0.1600 \n0.0425 \n0.6700 \n0.5350 \n\n0.9950  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.8175 \n0.6700 \n0.9675 \n0.9400 \n\n0.0525 \n0.0275 \n0.5700 \n0.3700 \n\n0.9975  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.7075 \n0.5425 \n0.9850 \n0.9550 \n\nFaceNet \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n0.1075 \n0.0350 \n0.4825 \n0.3425 \n\n0.2750 \n0.1900 \n0.4000 \n0.2650 \n\n0.9950  *  \n1.0000  *  \n0.9975  *  \n1.0000  *  \n\n0.0425 \n0.0125 \n0.3375 \n0.1875 \n\n0.2100 \n0.1475 \n0.3250 \n0.1675 \n\n0.9900  *  \n1.0000  *  \n0.9975  *  \n0.9950  *  \n\nAttack \nCelebA-HQ \nLFW \nArcFace \nCosFace \nFaceNet \nArcFace \nCosFace \nFaceNet \n\nArcFace \n\nTAP-MIM \nTAP-TIDIM \nTAP-TIDIMv2 \nGenAP \nGenAP-DI \n\n0.6450  *  \n0.9050  *  \n0.9375  *  \n0.8625  *  \n0.9625  *  \n\n0.1000 \n0.1200 \n0.2575 \n0.3425 \n0.3225 \n\n0.0700 \n0.1000 \n0.1900 \n0.2750 \n0.2425 \n\n0.6850  *  \n0.9275  *  \n0.9425  *  \n0.8675  *  \n0.9400  *  \n\n0.0925 \n0.1175 \n0.2075 \n0.2425 \n0.2325 \n\n0.0650 \n0.0625 \n0.0950 \n0.2150 \n0.1550 \n\nCosFace \n\nTAP-MIM \nTAP-TIDIM \nTAP-TIDIMv2 \nGenAP \nGenAP-DI \n\n0.1150 \n0.1200 \n0.1700 \n0.2975 \n0.2375 \n\n0.7425  *  \n0.9625  *  \n0.9875  *  \n0.9425  *  \n0.9950  *  \n\n0.1525 \n0.1650 \n0.2275 \n0.3625 \n0.3550 \n\n0.1175 \n0.1100 \n0.1650 \n0.2750 \n0.2500 \n\n0.7250  *  \n0.9750  *  \n0.9900  *  \n0.9350  *  \n0.9925  *  \n\n0.0825 \n0.1075 \n0.1500 \n0.2875 \n0.2675 \n\n\n\n\nTable 7. The success rates of black-box dodging attack on FaceNet, CosFace, ArcFace in the digital world under the face verification task.The adversarial examples are generated against FaceNet, CosFace, and ArcFace by restricting the adversarial patches to a respirator region. * indicates white-box attacks.Table 8. The success rates of black-box impersonation attack on FaceNet, CosFace, ArcFace in the digital world under the face verification task. The adversarial examples are generated against FaceNet, CosFace, and ArcFace by restricting the adversarial patches to a respirator region. * indicates white-box attacks.Attack \n\nCelebA-HQ \nLFW \nArcFace \nCosFace \nFaceNet \nArcFace \nCosFace \nFaceNet \n\nArcFace \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.0800 \n0.1175 \n0.3875 \n0.3150 \n\n0.3050 \n0.3300 \n0.8875 \n0.8150 \n\n0.9950  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.0600 \n0.0875 \n0.2950 \n0.2675 \n\n0.1175 \n0.1275 \n0.7300 \n0.6325 \n\nCosFace \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n0.0400 \n0.0650 \n0.5425 \n0.5725 \n\n0.9975  *  \n0.9975  *  \n1.0000  *  \n1.0000  *  \n\n0.2600 \n0.2825 \n0.8650 \n0.8650 \n\n0.0250 \n0.0200 \n0.3975 \n0.4025 \n\n0.9975  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.0975 \n0.1150 \n0.7350 \n0.7750 \n\nFaceNet \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n0.0475 \n0.0425 \n0.2200 \n0.1925 \n\n0.0525 \n0.0425 \n0.1375 \n0.1375 \n\n0.9675  *  \n0.9925  *  \n0.9950  *  \n0.9975  *  \n\n0.0125 \n0.0100 \n0.1425 \n0.1500 \n\n0.0575 \n0.0375 \n0.1400 \n0.1400 \n\n0.9425  *  \n0.9800  *  \n0.9850  *  \n0.9900  *  \n\nAttack \nCelebA-HQ \nLFW \nArcFace \nCosFace \nFaceNet \nArcFace \nCosFace \nFaceNet \n\nArcFace \n\nTAP-MIM \nTAP-TIDIM \nTAP-TIDIMv2 \nGenAP \nGenAP-DI \n\n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.2625 \n0.3125 \n0.4250 \n0.4850 \n0.4450 \n\n0.1225 \n0.1450 \n0.1975 \n0.3025 \n0.2800 \n\n0.9850  *  \n1.0000  *  \n1.0000  *  \n0.9975  *  \n1.0000  *  \n\n0.2450 \n0.2800 \n0.3725 \n0.4675 \n0.4525 \n\n0.1025 \n0.1125 \n0.1475 \n0.2750 \n0.2275 \n\nCosFace \n\nTAP-MIM \nTAP-TIDIM \nTAP-TIDIMv2 \nGenAP \nGenAP-DI \n\n0.4100 \n0.4025 \n0.5425 \n0.6250 \n0.6325 \n\n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.1475 \n0.1750 \n0.2250 \n0.2975 \n0.2975 \n\n0.2500 \n0.2225 \n0.3400 \n0.5025 \n0.5050 \n\n0.9925  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n0.9975  *  \n\n0.1200 \n0.1300 \n0.1775 \n0.2900 \n0.3100 \n\nFaceNet \n\nTAP-MIM \nTAP-TIDIM \nTAP-TIDIMv2 \nGenAP \nGenAP-DI \n\n0.1925 \n0.1900 \n0.3700 \n0.1950 \n0.2025 \n\n0.1625 \n0.1950 \n0.2700 \n0.1525 \n0.1550 \n\n0.6525  *  \n0.8700  *  \n0.8600  *  \n0.7075  *  \n0.7325  *  \n\n0.0900 \n0.1000 \n0.2275 \n0.1475 \n0.1325 \n\n0.1450 \n0.1725 \n0.2400 \n0.1800 \n0.1700 \n\n0.6325  *  \n0.8550  *  \n0.8575  *  \n0.7550  *  \n0.7450  *  \n\n\n\n\nTable 9. The success rates of black-box dodging attack on FaceNet, CosFace, ArcFace in the digital world under the face identification task. The adversarial examples are generated against FaceNet, CosFace, and ArcFace by restricting the adversarial patches to a respirator frame region. * indicates white-box attacks.Table 10. The success rates of black-box impersonation attack on FaceNet, CosFace, ArcFace in the digital world under the face identification task. The adversarial examples are generated against FaceNet, CosFace, and ArcFace by restricting the adversarial patches to a respirator frame region. * indicates white-box attacks.Attack \n\nCelebA-HQ \nLFW \nArcFace \nCosFace \nFaceNet \nArcFace \nCosFace \nFaceNet \n\nArcFace \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.1875 \n0.2350 \n0.5450 \n0.4850 \n\n0.4800 \n0.4925 \n0.9400 \n0.9000 \n\n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.1075 \n0.1550 \n0.5025 \n0.4400 \n\n0.2375 \n0.2550 \n0.8525 \n0.7950 \n\nCosFace \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n0.1250 \n0.1650 \n0.7325 \n0.7325 \n\n0.9975  *  \n0.9975  *  \n0.9975  *  \n1.0000  *  \n\n0.4500 \n0.4500 \n0.9250 \n0.9150 \n\n0.0325 \n0.0300 \n0.5750 \n0.5500 \n\n1.0000  *  \n1.0000  *  \n1.0000  *  \n1.0000  *  \n\n0.2075 \n0.2375 \n0.8850 \n0.9075 \n\nFaceNet \n\nTAP-MIM \nTAP-TIDIM \nGenAP \nGenAP-DI \n\n0.1300 \n0.0900 \n0.3500 \n0.3350 \n\n0.1475 \n0.1325 \n0.2725 \n0.2800 \n\n0.9800  *  \n0.9950  *  \n0.9975  *  \n0.9975  *  \n\n0.0425 \n0.0200 \n0.2425 \n0.2600 \n\n0.1200 \n0.0750 \n0.3275 \n0.3425 \n\n0.9650  *  \n0.9850  *  \n0.9875  *  \n0.9950  *  \n\nAttack \nCelebA-HQ \nLFW \nArcFace \nCosFace \nFaceNet \nArcFace \nCosFace \nFaceNet \n\nArcFace \n\nTAP-MIM \nTAP-TIDIM \nTAP-TIDIMv2 \nGenAP \nGenAP-DI \n\n0.6650  *  \n0.9350  *  \n0.9625  *  \n0.8800  *  \n0.9525  *  \n\n0.0575 \n0.0750 \n0.1875 \n0.2425 \n0.1850 \n\n0.0200 \n0.0275 \n0.0675 \n0.1325 \n0.0975 \n\n0.6555  *  \n0.9425  *  \n0.9650  *  \n0.8800  *  \n0.9625  *  \n\n0.0600 \n0.0875 \n0.1500 \n0.2025 \n0.2075 \n\n0.0200 \n0.0300 \n0.0600 \n0.1275 \n0.0975 \n\nCosFace \n\nTAP-MIM \nTAP-TIDIM \nTAP-TIDIMv2 \nGenAP \nGenAP-DI \n\n0.1100 \n0.1150 \n0.2125 \n0.2725 \n0.2550 \n\n0.6900  *  \n0.8875  *  \n0.9375  *  \n0.8725  *  \n0.8825  *  \n\n0.0375 \n0.0375 \n0.0825 \n0.1275 \n0.1300 \n\n0.0800 \n0.0950 \n0.1425 \n0.2200 \n0.2275 \n\n0.7125  *  \n0.9425  *  \n0.9875  *  \n0.9325  *  \n0.9225  *  \n\n0.0450 \n0.0450 \n0.0800 \n0.1375 \n0.1400 \n\nFaceNet \n\nTAP-MIM \nTAP-TIDIM \nTAP-TIDIMv2 \nGenAP \nGenAP-DI \n\n0.0425 \n0.0475 \n0.1275 \n0.0450 \n0.0525 \n\n0.0325 \n0.0550 \n0.0975 \n0.0550 \n0.0400 \n\n0.3250  *  \n0.6375  *  \n0.6800  *  \n0.4400  *  \n0.4700  *  \n\n0.0350 \n0.0300 \n0.0900 \n0.0625 \n0.0575 \n\n0.0275 \n0.0425 \n0.0850 \n0.0725 \n0.0575 \n\n0.3000  *  \n0.5825  *  \n0.6550  *  \n0.5100  *  \n0.4950  *  \n\nAttack \nArcFace \nCosFace \nFaceNet \n\nSemanticAdv \nGenAP \n\n0.82 \n1.00 \n\n0.19 \n0.51 \n\n0.11 \n0.36 \n\n\n\nTable 11 .\n11The attack success rate of black-box impersonation attack in face verification using SemanticAdv and GenAP on the CelebA dataset. ArcFace is the substitute model.Dataset \nImage classification models \nGenerative models \nLengths of the square patch \n\nCIFAR10 \nResNet50, MobileNetV2, InceptionV3, DenseNet121, VGG16 \nStyleGAN2-ADA \n8, 12, 16, 24 \nImageNet \nResNet101, DenseNet121, VGG16, ResNet50 \nBigGAN \n40, 80, 60, 80, 100, 120 \n\n\n\nTable 12 .\n12Setting of the image classification experiments.\nThey consider semantic perturbations.\nGenAP-DI is Generative Adversarial Patch with Diversified Inputs\nhttps://github.com/timesler/facenet-pytorch 5 https://github.com/MuggleWang/CosFace_pytorch 6 https://github.com/TreB1eN/InsightFace_Pytorch 7 https://www.faceplusplus.com/face-comparing/ 8 https://vision.aliyun.com/facebody 9 https : / / github . com / tkarras / progressive _ growing_of_gans/tree/master 10 https://github.com/NVlabs/stylegan 11 https://github.com/NVlabs/stylegan2\nA. Implementation details A.1. Hyperparameters TAP algorithms: We set the number of iterations N = 400, the learning rate \u03b1 = 1 and the decay factor \u00b5 = 1. We use = 255 for dodging and = 40 for impersonation. GenAP algorithms: We set the number of iterations N = 100, and the learning rate of Adam optimizer \u03b1 = 0.01.A.2. ModelsFace recognition models: All face recognition models are accessible from the Internet, including FaceNet 4 , CosFace 5 , ArcFace 6 , Face++ 7 and Aliyun 8 . Generative models: All generative models are accessible from the Internet, including ProGAN 9 , StyleGAN 10 , Style-GAN211.\nIm-age2stylegan: How to embed images into the stylegan latent space?. Rameen Abdal, Yipeng Qin, Peter Wonka, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer vision67Rameen Abdal, Yipeng Qin, and Peter Wonka. Im- age2stylegan: How to embed images into the stylegan latent space? In Proceedings of the IEEE international conference on computer vision, pages 4432-4441, 2019. 5, 6, 7\n\nSynthesizing robust adversarial examples. Anish Athalye, Logan Engstrom, Andrew Ilyas, Kevin Kwok, PMLRInternational conference on machine learning. Anish Athalye, Logan Engstrom, Andrew Ilyas, and Kevin Kwok. Synthesizing robust adversarial examples. In Inter- national conference on machine learning, pages 284-293. PMLR, 2018. 3\n\n. Dandelion Tom B Brown, Aurko Man\u00e9, Mart\u00edn Roy, Justin Abadi, Gilmer, arXiv:1712.0966523Adversarial patch. arXiv preprintTom B Brown, Dandelion Man\u00e9, Aurko Roy, Mart\u00edn Abadi, and Justin Gilmer. Adversarial patch. arXiv preprint arXiv:1712.09665, 2017. 2, 3\n\nStargan: Unified generative adversarial networks for multi-domain image-to-image translation. Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition11Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo. Stargan: Unified genera- tive adversarial networks for multi-domain image-to-image translation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 8789-8797, 2018. 11\n\nArcface: Additive angular margin loss for deep face recognition. Jiankang Deng, Jia Guo, Niannan Xue, Stefanos Zafeiriou, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition15Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. Arcface: Additive angular margin loss for deep face recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4690- 4699, 2019. 1, 5\n\nBenchmarking adversarial robustness on image classification. Yinpeng Dong, Qi-An Fu, Xiao Yang, Tianyu Pang, Hang Su, Zihao Xiao, Jun Zhu, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionYinpeng Dong, Qi-An Fu, Xiao Yang, Tianyu Pang, Hang Su, Zihao Xiao, and Jun Zhu. Benchmarking adversar- ial robustness on image classification. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 321-331, 2020. 1\n\nBoosting adversarial attacks with momentum. Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, Jianguo Li, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionYinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and Jianguo Li. Boosting adversarial at- tacks with momentum. In Proceedings of the IEEE con- ference on computer vision and pattern recognition, pages 9185-9193, 2018. 2, 3, 4, 6\n\nEvading defenses to transferable adversarial examples by translation-invariant attacks. Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition6Yinpeng Dong, Tianyu Pang, Hang Su, and Jun Zhu. Evading defenses to transferable adversarial examples by translation-invariant attacks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4312-4321, 2019. 2, 4, 6\n\nEfficient decision-based blackbox adversarial attacks on face recognition. Yinpeng Dong, Hang Su, Baoyuan Wu, Zhifeng Li, Wei Liu, Tong Zhang, Jun Zhu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition35Yinpeng Dong, Hang Su, Baoyuan Wu, Zhifeng Li, Wei Liu, Tong Zhang, and Jun Zhu. Efficient decision-based black- box adversarial attacks on face recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7714-7722, 2019. 3, 5\n\nAmir Rahmati, and Dawn Song. Robust physical-world attacks on machine learning models. Ivan Evtimov, Kevin Eykholt, Earlence Fernandes, Tadayoshi Kohno, Bo Li, Atul Prakash, arXiv:1707.0894523arXiv preprintIvan Evtimov, Kevin Eykholt, Earlence Fernandes, Ta- dayoshi Kohno, Bo Li, Atul Prakash, Amir Rahmati, and Dawn Song. Robust physical-world attacks on machine learning models. arXiv preprint arXiv:1707.08945, 2(3):4, 2017. 2, 3\n\nJ Ian, Goodfellow, arXiv:1412.6572Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. 11arXiv preprintIan J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014. 2, 4, 11\n\nLabeled faces in the wild: A database for studying face recognition in unconstrained environments. B Gary, Manu Huang, Tamara Ramesh, Erik Berg, Learned-Miller, 07-49AmherstUniversity of MassachusettsTechnical ReportGary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller. Labeled faces in the wild: A database for studying face recognition in unconstrained environ- ments. Technical Report 07-49, University of Massachusetts, Amherst, October 2007. 5\n\nProgressive growing of gans for improved quality, stability, and variation. Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen, arXiv:1710.1019657arXiv preprintTero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 5, 7\n\nA style-based generator architecture for generative adversarial networks. Tero Karras, Samuli Laine, Timo Aila, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition67Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4401-4410, 2019. 5, 6, 7\n\nAnalyzing and improving the image quality of stylegan. Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition57Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- ing the image quality of stylegan. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110-8119, 2020. 5, 7\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.698045arXiv preprintDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 4, 5\n\nSemanticadv: Generating adversarial examples via attribute-conditioned image editing. Haonan Qiu, Chaowei Xiao, Lei Yang, Xinchen Yan, Honglak Lee, Bo Li, European Conference on Computer Vision. Springer811Haonan Qiu, Chaowei Xiao, Lei Yang, Xinchen Yan, Honglak Lee, and Bo Li. Semanticadv: Generating ad- versarial examples via attribute-conditioned image editing. In European Conference on Computer Vision, pages 19-37. Springer, 2020. 2, 5, 8, 11\n\nFacenet: A unified embedding for face recognition and clustering. Florian Schroff, Dmitry Kalenichenko, James Philbin, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition15Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet: A unified embedding for face recognition and clus- tering. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 815-823, 2015. 1, 5\n\nAccessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, Michael K Reiter, Proceedings of the 2016 acm sigsac conference on computer and communications security. the 2016 acm sigsac conference on computer and communications security13Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, and Michael K Reiter. Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. In Proceedings of the 2016 acm sigsac conference on computer and commu- nications security, pages 1528-1540, 2016. 1, 2, 3\n\nPhysical adversarial examples for object detectors. Dawn Song, Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Florian Tramer, Atul Prakash, Tadayoshi Kohno, 12th {USENIX} Workshop on Offensive Technologies ({WOOT} 18). 23Dawn Song, Kevin Eykholt, Ivan Evtimov, Earlence Fernan- des, Bo Li, Amir Rahmati, Florian Tramer, Atul Prakash, and Tadayoshi Kohno. Physical adversarial examples for object detectors. In 12th {USENIX} Workshop on Offensive Tech- nologies ({WOOT} 18), 2018. 2, 3\n\nConstructing unrestricted adversarial examples with generative models. Yang Song, Rui Shu, Nate Kushman, Stefano Ermon, Advances in Neural Information Processing Systems. Yang Song, Rui Shu, Nate Kushman, and Stefano Ermon. Constructing unrestricted adversarial examples with genera- tive models. In Advances in Neural Information Processing Systems, pages 8312-8323, 2018. 2\n\nChristian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, arXiv:1312.6199Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. arXiv preprintChristian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013. 1\n\nAutozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks. Chun-Chen Tu, Paishun Ting, Pin-Yu Chen, Sijia Liu, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, Shin-Ming Cheng, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence33Chun-Chen Tu, Paishun Ting, Pin-Yu Chen, Sijia Liu, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, and Shin-Ming Cheng. Autozoom: Autoencoder-based zeroth order optimization method for attacking black-box neural networks. In Pro- ceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 742-749, 2019. 2\n\nCosface: Large margin cosine loss for deep face recognition. Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou, Zhifeng Li, Wei Liu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition15Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou, Zhifeng Li, and Wei Liu. Cosface: Large margin cosine loss for deep face recognition. In Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5265-5274, 2018. 1, 5\n\nMaking an invisibility cloak: Real world adversarial attacks on object detectors. Zuxuan Wu, Ser-Nam Lim, Larry Davis, Tom Goldstein, arXiv:1910.14667arXiv preprintZuxuan Wu, Ser-Nam Lim, Larry Davis, and Tom Goldstein. Making an invisibility cloak: Real world adversarial attacks on object detectors. arXiv preprint arXiv:1910.14667, 2019. 2\n\nGenerating adversarial examples with adversarial networks. Chaowei Xiao, Bo Li, Jun-Yan Zhu, Warren He, Mingyan Liu, Dawn Song, arXiv:1801.02610arXiv preprintChaowei Xiao, Bo Li, Jun-Yan Zhu, Warren He, Mingyan Liu, and Dawn Song. Generating adversarial examples with adversarial networks. arXiv preprint arXiv:1801.02610, 2018. 2\n\nImproving transferability of adversarial examples with input diversity. Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Alan L Zhou Ren, Yuille, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionCihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou Ren, and Alan L Yuille. Improving transferabil- ity of adversarial examples with input diversity. In Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2730-2739, 2019. 2, 3, 4, 6\n\nPatchattack: A black-box texture-based attack with reinforcement learning. Chenglin Yang, Adam Kortylewski, Cihang Xie, Yinzhi Cao, Alan Yuille, European Conference on Computer Vision. SpringerChenglin Yang, Adam Kortylewski, Cihang Xie, Yinzhi Cao, and Alan Yuille. Patchattack: A black-box texture-based at- tack with reinforcement learning. In European Conference on Computer Vision, pages 681-698. Springer, 2020. 2\n\nZhengli Zhao, Dheeru Dua, Sameer Singh, arXiv:1710.11342Generating natural adversarial examples. arXiv preprintZhengli Zhao, Dheeru Dua, and Sameer Singh. Gen- erating natural adversarial examples. arXiv preprint arXiv:1710.11342, 2017. 2\n", "annotations": {"author": "[{\"end\":127,\"start\":95},{\"end\":177,\"start\":128},{\"end\":228,\"start\":178},{\"end\":264,\"start\":229},{\"end\":308,\"start\":265},{\"end\":340,\"start\":309},{\"end\":389,\"start\":341},{\"end\":420,\"start\":390},{\"end\":428,\"start\":421}]", "publisher": null, "author_last_name": "[{\"end\":105,\"start\":101},{\"end\":142,\"start\":139},{\"end\":187,\"start\":185},{\"end\":241,\"start\":237},{\"end\":272,\"start\":269},{\"end\":323,\"start\":318},{\"end\":349,\"start\":345},{\"end\":397,\"start\":394},{\"end\":427,\"start\":421}]", "author_first_name": "[{\"end\":100,\"start\":95},{\"end\":129,\"start\":128},{\"end\":138,\"start\":130},{\"end\":184,\"start\":178},{\"end\":236,\"start\":229},{\"end\":268,\"start\":265},{\"end\":310,\"start\":309},{\"end\":317,\"start\":311},{\"end\":344,\"start\":341},{\"end\":393,\"start\":390}]", "author_affiliation": "[{\"end\":176,\"start\":144},{\"end\":227,\"start\":213},{\"end\":263,\"start\":243},{\"end\":307,\"start\":274},{\"end\":339,\"start\":325},{\"end\":388,\"start\":374},{\"end\":419,\"start\":399}]", "title": "[{\"end\":92,\"start\":1},{\"end\":520,\"start\":429}]", "venue": null, "abstract": "[{\"end\":2004,\"start\":522}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2228,\"start\":2224},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2231,\"start\":2228},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2233,\"start\":2231},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2551,\"start\":2547},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2553,\"start\":2551},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2819,\"start\":2815},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3032,\"start\":3028},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3035,\"start\":3032},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3038,\"start\":3035},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3122,\"start\":3118},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3666,\"start\":3662},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3669,\"start\":3666},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3671,\"start\":3669},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3674,\"start\":3671},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3774,\"start\":3770},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3777,\"start\":3774},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4282,\"start\":4278},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4771,\"start\":4768},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4796,\"start\":4792},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4798,\"start\":4796},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6749,\"start\":6745},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6752,\"start\":6749},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6755,\"start\":6752},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6757,\"start\":6755},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6760,\"start\":6757},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6801,\"start\":6797},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":6804,\"start\":6801},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6959,\"start\":6956},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7026,\"start\":7023},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7029,\"start\":7026},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7297,\"start\":7294},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7300,\"start\":7297},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7302,\"start\":7300},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8011,\"start\":8007},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8040,\"start\":8036},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8043,\"start\":8040},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8157,\"start\":8153},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8196,\"start\":8192},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8284,\"start\":8280},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8359,\"start\":8355},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11297,\"start\":11294},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11300,\"start\":11297},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11800,\"start\":11796},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":12588,\"start\":12585},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12626,\"start\":12623},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12774,\"start\":12770},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12776,\"start\":12774},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13117,\"start\":13114},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13207,\"start\":13204},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13210,\"start\":13207},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13213,\"start\":13210},{\"end\":14259,\"start\":14257},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":14291,\"start\":14288},{\"end\":14370,\"start\":14368},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":14392,\"start\":14389},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":14791,\"start\":14787},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":15204,\"start\":15201},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":15207,\"start\":15204},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":15209,\"start\":15207},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":15564,\"start\":15561},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":18088,\"start\":18084},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":18173,\"start\":18169},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":18723,\"start\":18719},{\"end\":18904,\"start\":18902},{\"end\":19034,\"start\":19032},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":19265,\"start\":19261},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":19284,\"start\":19280},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20168,\"start\":20165},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":20257,\"start\":20253},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":20271,\"start\":20267},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":20288,\"start\":20285},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":21111,\"start\":21107},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21126,\"start\":21122},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":21146,\"start\":21142},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21297,\"start\":21294},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21300,\"start\":21297},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":23006,\"start\":23002},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":23298,\"start\":23295},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":23301,\"start\":23298},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":23303,\"start\":23301},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":23987,\"start\":23983},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24747,\"start\":24743},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":24749,\"start\":24747},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":24952,\"start\":24949},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25616,\"start\":25615},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":26207,\"start\":26204},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":26210,\"start\":26207},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":26949,\"start\":26945},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":26964,\"start\":26960},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":26983,\"start\":26979},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":27179,\"start\":27176},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":27182,\"start\":27179},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":27827,\"start\":27824},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":27830,\"start\":27827},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29293,\"start\":29289},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":31930,\"start\":31926},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":31947,\"start\":31944},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":33657,\"start\":33653}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":37843,\"start\":37339},{\"attributes\":{\"id\":\"fig_1\"},\"end\":38197,\"start\":37844},{\"attributes\":{\"id\":\"fig_2\"},\"end\":38318,\"start\":38198},{\"attributes\":{\"id\":\"fig_3\"},\"end\":38581,\"start\":38319},{\"attributes\":{\"id\":\"fig_4\"},\"end\":39424,\"start\":38582},{\"attributes\":{\"id\":\"fig_5\"},\"end\":39767,\"start\":39425},{\"attributes\":{\"id\":\"fig_6\"},\"end\":40435,\"start\":39768},{\"attributes\":{\"id\":\"fig_8\"},\"end\":40759,\"start\":40436},{\"attributes\":{\"id\":\"fig_9\"},\"end\":41671,\"start\":40760},{\"attributes\":{\"id\":\"fig_10\"},\"end\":42365,\"start\":41672},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":42611,\"start\":42366},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":45510,\"start\":42612},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":47515,\"start\":45511},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":50175,\"start\":47516},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":52949,\"start\":50176},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":53394,\"start\":52950},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":53457,\"start\":53395}]", "paragraph": "[{\"end\":2462,\"start\":2020},{\"end\":3580,\"start\":2464},{\"end\":4148,\"start\":3582},{\"end\":5010,\"start\":4150},{\"end\":5617,\"start\":5012},{\"end\":6354,\"start\":5619},{\"end\":6621,\"start\":6356},{\"end\":7096,\"start\":6663},{\"end\":7777,\"start\":7134},{\"end\":8584,\"start\":7826},{\"end\":8946,\"start\":8600},{\"end\":9498,\"start\":8965},{\"end\":9843,\"start\":9500},{\"end\":10573,\"start\":9896},{\"end\":11065,\"start\":10575},{\"end\":11496,\"start\":11100},{\"end\":11801,\"start\":11498},{\"end\":12358,\"start\":11856},{\"end\":13481,\"start\":12360},{\"end\":14037,\"start\":13483},{\"end\":14212,\"start\":14039},{\"end\":14292,\"start\":14214},{\"end\":14393,\"start\":14315},{\"end\":14503,\"start\":14460},{\"end\":14901,\"start\":14606},{\"end\":15340,\"start\":14903},{\"end\":16038,\"start\":15373},{\"end\":16668,\"start\":16040},{\"end\":17987,\"start\":16738},{\"end\":18262,\"start\":17989},{\"end\":18389,\"start\":18278},{\"end\":18777,\"start\":18446},{\"end\":18865,\"start\":18779},{\"end\":18938,\"start\":18867},{\"end\":19079,\"start\":18976},{\"end\":19132,\"start\":19086},{\"end\":21301,\"start\":19198},{\"end\":21989,\"start\":21303},{\"end\":23108,\"start\":22014},{\"end\":24444,\"start\":23110},{\"end\":24813,\"start\":24476},{\"end\":25243,\"start\":24847},{\"end\":25617,\"start\":25262},{\"end\":25932,\"start\":25645},{\"end\":26842,\"start\":25972},{\"end\":27678,\"start\":26885},{\"end\":28181,\"start\":27721},{\"end\":29098,\"start\":28211},{\"end\":29534,\"start\":29120},{\"end\":30749,\"start\":29549},{\"end\":31098,\"start\":30751},{\"end\":31356,\"start\":31100},{\"end\":31880,\"start\":31402},{\"end\":32682,\"start\":31914},{\"end\":33417,\"start\":32684},{\"end\":33790,\"start\":33460},{\"end\":34440,\"start\":33792},{\"end\":34604,\"start\":34442},{\"end\":34925,\"start\":34606},{\"end\":35705,\"start\":34927},{\"end\":36358,\"start\":35707},{\"end\":37098,\"start\":36360},{\"end\":37338,\"start\":37111}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9895,\"start\":9844},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11855,\"start\":11802},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14314,\"start\":14293},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14459,\"start\":14394},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14605,\"start\":14504},{\"attributes\":{\"id\":\"formula_5\"},\"end\":16737,\"start\":16669},{\"attributes\":{\"id\":\"formula_6\"},\"end\":18975,\"start\":18939},{\"attributes\":{\"id\":\"formula_7\"},\"end\":19174,\"start\":19133}]", "table_ref": "[{\"end\":14033,\"start\":14029},{\"end\":29672,\"start\":29665},{\"end\":37155,\"start\":37147}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2018,\"start\":2006},{\"attributes\":{\"n\":\"2.\"},\"end\":6661,\"start\":6624},{\"attributes\":{\"n\":\"2.2.\"},\"end\":7132,\"start\":7099},{\"attributes\":{\"n\":\"2.3.\"},\"end\":7824,\"start\":7780},{\"attributes\":{\"n\":\"3.\"},\"end\":8598,\"start\":8587},{\"attributes\":{\"n\":\"3.1.\"},\"end\":8963,\"start\":8949},{\"attributes\":{\"n\":\"3.2.\"},\"end\":11098,\"start\":11068},{\"attributes\":{\"n\":\"3.3.\"},\"end\":15371,\"start\":15343},{\"attributes\":{\"n\":\"4.\"},\"end\":18276,\"start\":18265},{\"end\":18444,\"start\":18392},{\"end\":19084,\"start\":19082},{\"attributes\":{\"n\":\"4.1.\"},\"end\":19196,\"start\":19176},{\"attributes\":{\"n\":\"4.2.\"},\"end\":22012,\"start\":21992},{\"attributes\":{\"n\":\"4.3.\"},\"end\":24474,\"start\":24447},{\"attributes\":{\"n\":\"4.3.1\"},\"end\":24845,\"start\":24816},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":25260,\"start\":25246},{\"attributes\":{\"n\":\"4.4.\"},\"end\":25643,\"start\":25620},{\"attributes\":{\"n\":\"4.4.1\"},\"end\":25970,\"start\":25935},{\"attributes\":{\"n\":\"4.4.2\"},\"end\":26883,\"start\":26845},{\"attributes\":{\"n\":\"4.4.3\"},\"end\":27719,\"start\":27681},{\"attributes\":{\"n\":\"4.5.\"},\"end\":28209,\"start\":28184},{\"attributes\":{\"n\":\"4.6.\"},\"end\":29118,\"start\":29101},{\"attributes\":{\"n\":\"5.\"},\"end\":29547,\"start\":29537},{\"end\":31400,\"start\":31359},{\"end\":31912,\"start\":31883},{\"end\":33458,\"start\":33420},{\"end\":37109,\"start\":37101},{\"end\":37350,\"start\":37340},{\"end\":38209,\"start\":38199},{\"end\":38593,\"start\":38583},{\"end\":39435,\"start\":39426},{\"end\":39778,\"start\":39769},{\"end\":40781,\"start\":40761},{\"end\":41683,\"start\":41673},{\"end\":52961,\"start\":52951},{\"end\":53406,\"start\":53396}]", "table": "[{\"end\":42611,\"start\":42488},{\"end\":45510,\"start\":42947},{\"end\":47515,\"start\":45828},{\"end\":50175,\"start\":48141},{\"end\":52949,\"start\":50819},{\"end\":53394,\"start\":53126}]", "figure_caption": "[{\"end\":37843,\"start\":37352},{\"end\":38197,\"start\":37846},{\"end\":38318,\"start\":38211},{\"end\":38581,\"start\":38321},{\"end\":39424,\"start\":38595},{\"end\":39767,\"start\":39437},{\"end\":40435,\"start\":39780},{\"end\":40759,\"start\":40438},{\"end\":41671,\"start\":40784},{\"end\":42365,\"start\":41685},{\"end\":42488,\"start\":42368},{\"end\":42947,\"start\":42614},{\"end\":45828,\"start\":45513},{\"end\":48141,\"start\":47518},{\"end\":50819,\"start\":50178},{\"end\":53126,\"start\":52964},{\"end\":53457,\"start\":53409}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6158,\"start\":6152},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12083,\"start\":12077},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":14899,\"start\":14893},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21571,\"start\":21565},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":25489,\"start\":25483},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":27218,\"start\":27209},{\"end\":28974,\"start\":28969},{\"end\":31230,\"start\":31224},{\"end\":31268,\"start\":31262},{\"end\":31868,\"start\":31862},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":31879,\"start\":31873},{\"end\":36692,\"start\":36684}]", "bib_author_first_name": "[{\"end\":54629,\"start\":54623},{\"end\":54643,\"start\":54637},{\"end\":54654,\"start\":54649},{\"end\":55049,\"start\":55044},{\"end\":55064,\"start\":55059},{\"end\":55081,\"start\":55075},{\"end\":55094,\"start\":55089},{\"end\":55346,\"start\":55337},{\"end\":55365,\"start\":55360},{\"end\":55378,\"start\":55372},{\"end\":55390,\"start\":55384},{\"end\":55694,\"start\":55688},{\"end\":55706,\"start\":55701},{\"end\":55721,\"start\":55713},{\"end\":55735,\"start\":55727},{\"end\":55747,\"start\":55740},{\"end\":55759,\"start\":55753},{\"end\":56269,\"start\":56261},{\"end\":56279,\"start\":56276},{\"end\":56292,\"start\":56285},{\"end\":56306,\"start\":56298},{\"end\":56767,\"start\":56760},{\"end\":56779,\"start\":56774},{\"end\":56788,\"start\":56784},{\"end\":56801,\"start\":56795},{\"end\":56812,\"start\":56808},{\"end\":56822,\"start\":56817},{\"end\":56832,\"start\":56829},{\"end\":57293,\"start\":57286},{\"end\":57308,\"start\":57300},{\"end\":57321,\"start\":57315},{\"end\":57332,\"start\":57328},{\"end\":57340,\"start\":57337},{\"end\":57353,\"start\":57346},{\"end\":57365,\"start\":57358},{\"end\":57859,\"start\":57852},{\"end\":57872,\"start\":57866},{\"end\":57883,\"start\":57879},{\"end\":57891,\"start\":57888},{\"end\":58372,\"start\":58365},{\"end\":58383,\"start\":58379},{\"end\":58395,\"start\":58388},{\"end\":58407,\"start\":58400},{\"end\":58415,\"start\":58412},{\"end\":58425,\"start\":58421},{\"end\":58436,\"start\":58433},{\"end\":58945,\"start\":58941},{\"end\":58960,\"start\":58955},{\"end\":58978,\"start\":58970},{\"end\":58999,\"start\":58990},{\"end\":59009,\"start\":59007},{\"end\":59018,\"start\":59014},{\"end\":59290,\"start\":59289},{\"end\":59681,\"start\":59680},{\"end\":59692,\"start\":59688},{\"end\":59706,\"start\":59700},{\"end\":59719,\"start\":59715},{\"end\":60123,\"start\":60119},{\"end\":60136,\"start\":60132},{\"end\":60149,\"start\":60143},{\"end\":60163,\"start\":60157},{\"end\":60464,\"start\":60460},{\"end\":60479,\"start\":60473},{\"end\":60491,\"start\":60487},{\"end\":60930,\"start\":60926},{\"end\":60945,\"start\":60939},{\"end\":60958,\"start\":60953},{\"end\":60973,\"start\":60968},{\"end\":60990,\"start\":60984},{\"end\":61005,\"start\":61001},{\"end\":61470,\"start\":61469},{\"end\":61486,\"start\":61481},{\"end\":61742,\"start\":61736},{\"end\":61755,\"start\":61748},{\"end\":61765,\"start\":61762},{\"end\":61779,\"start\":61772},{\"end\":61792,\"start\":61785},{\"end\":61800,\"start\":61798},{\"end\":62175,\"start\":62168},{\"end\":62191,\"start\":62185},{\"end\":62211,\"start\":62206},{\"end\":62693,\"start\":62686},{\"end\":62707,\"start\":62702},{\"end\":62725,\"start\":62721},{\"end\":62742,\"start\":62733},{\"end\":63247,\"start\":63243},{\"end\":63259,\"start\":63254},{\"end\":63273,\"start\":63269},{\"end\":63291,\"start\":63283},{\"end\":63305,\"start\":63303},{\"end\":63314,\"start\":63310},{\"end\":63331,\"start\":63324},{\"end\":63344,\"start\":63340},{\"end\":63363,\"start\":63354},{\"end\":63775,\"start\":63771},{\"end\":63785,\"start\":63782},{\"end\":63795,\"start\":63791},{\"end\":63812,\"start\":63805},{\"end\":64086,\"start\":64077},{\"end\":64104,\"start\":64096},{\"end\":64118,\"start\":64114},{\"end\":64134,\"start\":64130},{\"end\":64566,\"start\":64557},{\"end\":64578,\"start\":64571},{\"end\":64591,\"start\":64585},{\"end\":64603,\"start\":64598},{\"end\":64613,\"start\":64609},{\"end\":64628,\"start\":64621},{\"end\":64640,\"start\":64633},{\"end\":64657,\"start\":64648},{\"end\":65157,\"start\":65154},{\"end\":65170,\"start\":65164},{\"end\":65182,\"start\":65177},{\"end\":65193,\"start\":65189},{\"end\":65204,\"start\":65198},{\"end\":65219,\"start\":65211},{\"end\":65233,\"start\":65226},{\"end\":65241,\"start\":65238},{\"end\":65749,\"start\":65743},{\"end\":65761,\"start\":65754},{\"end\":65772,\"start\":65767},{\"end\":65783,\"start\":65780},{\"end\":66071,\"start\":66064},{\"end\":66080,\"start\":66078},{\"end\":66092,\"start\":66085},{\"end\":66104,\"start\":66098},{\"end\":66116,\"start\":66109},{\"end\":66126,\"start\":66122},{\"end\":66415,\"start\":66409},{\"end\":66429,\"start\":66421},{\"end\":66442,\"start\":66437},{\"end\":66453,\"start\":66449},{\"end\":66465,\"start\":66459},{\"end\":66476,\"start\":66472},{\"end\":66478,\"start\":66477},{\"end\":67006,\"start\":66998},{\"end\":67017,\"start\":67013},{\"end\":67037,\"start\":67031},{\"end\":67049,\"start\":67043},{\"end\":67059,\"start\":67055},{\"end\":67351,\"start\":67344},{\"end\":67364,\"start\":67358},{\"end\":67376,\"start\":67370}]", "bib_author_last_name": "[{\"end\":54635,\"start\":54630},{\"end\":54647,\"start\":54644},{\"end\":54660,\"start\":54655},{\"end\":55057,\"start\":55050},{\"end\":55073,\"start\":55065},{\"end\":55087,\"start\":55082},{\"end\":55099,\"start\":55095},{\"end\":55358,\"start\":55347},{\"end\":55370,\"start\":55366},{\"end\":55382,\"start\":55379},{\"end\":55396,\"start\":55391},{\"end\":55404,\"start\":55398},{\"end\":55699,\"start\":55695},{\"end\":55711,\"start\":55707},{\"end\":55725,\"start\":55722},{\"end\":55738,\"start\":55736},{\"end\":55751,\"start\":55748},{\"end\":55764,\"start\":55760},{\"end\":56274,\"start\":56270},{\"end\":56283,\"start\":56280},{\"end\":56296,\"start\":56293},{\"end\":56316,\"start\":56307},{\"end\":56772,\"start\":56768},{\"end\":56782,\"start\":56780},{\"end\":56793,\"start\":56789},{\"end\":56806,\"start\":56802},{\"end\":56815,\"start\":56813},{\"end\":56827,\"start\":56823},{\"end\":56836,\"start\":56833},{\"end\":57298,\"start\":57294},{\"end\":57313,\"start\":57309},{\"end\":57326,\"start\":57322},{\"end\":57335,\"start\":57333},{\"end\":57344,\"start\":57341},{\"end\":57356,\"start\":57354},{\"end\":57368,\"start\":57366},{\"end\":57864,\"start\":57860},{\"end\":57877,\"start\":57873},{\"end\":57886,\"start\":57884},{\"end\":57895,\"start\":57892},{\"end\":58377,\"start\":58373},{\"end\":58386,\"start\":58384},{\"end\":58398,\"start\":58396},{\"end\":58410,\"start\":58408},{\"end\":58419,\"start\":58416},{\"end\":58431,\"start\":58426},{\"end\":58440,\"start\":58437},{\"end\":58953,\"start\":58946},{\"end\":58968,\"start\":58961},{\"end\":58988,\"start\":58979},{\"end\":59005,\"start\":59000},{\"end\":59012,\"start\":59010},{\"end\":59026,\"start\":59019},{\"end\":59294,\"start\":59291},{\"end\":59306,\"start\":59296},{\"end\":59686,\"start\":59682},{\"end\":59698,\"start\":59693},{\"end\":59713,\"start\":59707},{\"end\":59724,\"start\":59720},{\"end\":59740,\"start\":59726},{\"end\":60130,\"start\":60124},{\"end\":60141,\"start\":60137},{\"end\":60155,\"start\":60150},{\"end\":60172,\"start\":60164},{\"end\":60471,\"start\":60465},{\"end\":60485,\"start\":60480},{\"end\":60496,\"start\":60492},{\"end\":60937,\"start\":60931},{\"end\":60951,\"start\":60946},{\"end\":60966,\"start\":60959},{\"end\":60982,\"start\":60974},{\"end\":60999,\"start\":60991},{\"end\":61010,\"start\":61006},{\"end\":61479,\"start\":61471},{\"end\":61493,\"start\":61487},{\"end\":61497,\"start\":61495},{\"end\":61746,\"start\":61743},{\"end\":61760,\"start\":61756},{\"end\":61770,\"start\":61766},{\"end\":61783,\"start\":61780},{\"end\":61796,\"start\":61793},{\"end\":61803,\"start\":61801},{\"end\":62183,\"start\":62176},{\"end\":62204,\"start\":62192},{\"end\":62219,\"start\":62212},{\"end\":62700,\"start\":62694},{\"end\":62719,\"start\":62708},{\"end\":62731,\"start\":62726},{\"end\":62749,\"start\":62743},{\"end\":63252,\"start\":63248},{\"end\":63267,\"start\":63260},{\"end\":63281,\"start\":63274},{\"end\":63301,\"start\":63292},{\"end\":63308,\"start\":63306},{\"end\":63322,\"start\":63315},{\"end\":63338,\"start\":63332},{\"end\":63352,\"start\":63345},{\"end\":63369,\"start\":63364},{\"end\":63780,\"start\":63776},{\"end\":63789,\"start\":63786},{\"end\":63803,\"start\":63796},{\"end\":63818,\"start\":63813},{\"end\":64094,\"start\":64087},{\"end\":64112,\"start\":64105},{\"end\":64128,\"start\":64119},{\"end\":64140,\"start\":64135},{\"end\":64569,\"start\":64567},{\"end\":64583,\"start\":64579},{\"end\":64596,\"start\":64592},{\"end\":64607,\"start\":64604},{\"end\":64619,\"start\":64614},{\"end\":64631,\"start\":64629},{\"end\":64646,\"start\":64641},{\"end\":64663,\"start\":64658},{\"end\":65162,\"start\":65158},{\"end\":65175,\"start\":65171},{\"end\":65187,\"start\":65183},{\"end\":65196,\"start\":65194},{\"end\":65209,\"start\":65205},{\"end\":65224,\"start\":65220},{\"end\":65236,\"start\":65234},{\"end\":65245,\"start\":65242},{\"end\":65752,\"start\":65750},{\"end\":65765,\"start\":65762},{\"end\":65778,\"start\":65773},{\"end\":65793,\"start\":65784},{\"end\":66076,\"start\":66072},{\"end\":66083,\"start\":66081},{\"end\":66096,\"start\":66093},{\"end\":66107,\"start\":66105},{\"end\":66120,\"start\":66117},{\"end\":66131,\"start\":66127},{\"end\":66419,\"start\":66416},{\"end\":66435,\"start\":66430},{\"end\":66447,\"start\":66443},{\"end\":66457,\"start\":66454},{\"end\":66470,\"start\":66466},{\"end\":66487,\"start\":66479},{\"end\":66495,\"start\":66489},{\"end\":67011,\"start\":67007},{\"end\":67029,\"start\":67018},{\"end\":67041,\"start\":67038},{\"end\":67053,\"start\":67050},{\"end\":67066,\"start\":67060},{\"end\":67356,\"start\":67352},{\"end\":67368,\"start\":67365},{\"end\":67382,\"start\":67377}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":102350964},\"end\":55000,\"start\":54553},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b1\",\"matched_paper_id\":2645819},\"end\":55333,\"start\":55002},{\"attributes\":{\"doi\":\"arXiv:1712.09665\",\"id\":\"b2\"},\"end\":55592,\"start\":55335},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":9417016},\"end\":56194,\"start\":55594},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":8923541},\"end\":56697,\"start\":56196},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":219964167},\"end\":57240,\"start\":56699},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":4119221},\"end\":57762,\"start\":57242},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":102350868},\"end\":58288,\"start\":57764},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":104291897},\"end\":58852,\"start\":58290},{\"attributes\":{\"doi\":\"arXiv:1707.08945\",\"id\":\"b9\"},\"end\":59287,\"start\":58854},{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b10\"},\"end\":59579,\"start\":59289},{\"attributes\":{\"doi\":\"07-49\",\"id\":\"b11\"},\"end\":60041,\"start\":59581},{\"attributes\":{\"doi\":\"arXiv:1710.10196\",\"id\":\"b12\"},\"end\":60384,\"start\":60043},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":54482423},\"end\":60869,\"start\":60386},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":209202273},\"end\":61423,\"start\":60871},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b15\"},\"end\":61648,\"start\":61425},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":195069241},\"end\":62100,\"start\":61650},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":206592766},\"end\":62596,\"start\":62102},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":207241700},\"end\":63189,\"start\":62598},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":49904930},\"end\":63698,\"start\":63191},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":52309169},\"end\":64075,\"start\":63700},{\"attributes\":{\"doi\":\"arXiv:1312.6199\",\"id\":\"b21\"},\"end\":64453,\"start\":64077},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":44079102},\"end\":65091,\"start\":64455},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":68589},\"end\":65659,\"start\":65093},{\"attributes\":{\"doi\":\"arXiv:1910.14667\",\"id\":\"b24\"},\"end\":66003,\"start\":65661},{\"attributes\":{\"doi\":\"arXiv:1801.02610\",\"id\":\"b25\"},\"end\":66335,\"start\":66005},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":3972825},\"end\":66921,\"start\":66337},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":215745555},\"end\":67342,\"start\":66923},{\"attributes\":{\"doi\":\"arXiv:1710.11342\",\"id\":\"b28\"},\"end\":67582,\"start\":67344}]", "bib_title": "[{\"end\":54621,\"start\":54553},{\"end\":55042,\"start\":55002},{\"end\":55686,\"start\":55594},{\"end\":56259,\"start\":56196},{\"end\":56758,\"start\":56699},{\"end\":57284,\"start\":57242},{\"end\":57850,\"start\":57764},{\"end\":58363,\"start\":58290},{\"end\":60458,\"start\":60386},{\"end\":60924,\"start\":60871},{\"end\":61734,\"start\":61650},{\"end\":62166,\"start\":62102},{\"end\":62684,\"start\":62598},{\"end\":63241,\"start\":63191},{\"end\":63769,\"start\":63700},{\"end\":64555,\"start\":64455},{\"end\":65152,\"start\":65093},{\"end\":66407,\"start\":66337},{\"end\":66996,\"start\":66923}]", "bib_author": "[{\"end\":54637,\"start\":54623},{\"end\":54649,\"start\":54637},{\"end\":54662,\"start\":54649},{\"end\":55059,\"start\":55044},{\"end\":55075,\"start\":55059},{\"end\":55089,\"start\":55075},{\"end\":55101,\"start\":55089},{\"end\":55360,\"start\":55337},{\"end\":55372,\"start\":55360},{\"end\":55384,\"start\":55372},{\"end\":55398,\"start\":55384},{\"end\":55406,\"start\":55398},{\"end\":55701,\"start\":55688},{\"end\":55713,\"start\":55701},{\"end\":55727,\"start\":55713},{\"end\":55740,\"start\":55727},{\"end\":55753,\"start\":55740},{\"end\":55766,\"start\":55753},{\"end\":56276,\"start\":56261},{\"end\":56285,\"start\":56276},{\"end\":56298,\"start\":56285},{\"end\":56318,\"start\":56298},{\"end\":56774,\"start\":56760},{\"end\":56784,\"start\":56774},{\"end\":56795,\"start\":56784},{\"end\":56808,\"start\":56795},{\"end\":56817,\"start\":56808},{\"end\":56829,\"start\":56817},{\"end\":56838,\"start\":56829},{\"end\":57300,\"start\":57286},{\"end\":57315,\"start\":57300},{\"end\":57328,\"start\":57315},{\"end\":57337,\"start\":57328},{\"end\":57346,\"start\":57337},{\"end\":57358,\"start\":57346},{\"end\":57370,\"start\":57358},{\"end\":57866,\"start\":57852},{\"end\":57879,\"start\":57866},{\"end\":57888,\"start\":57879},{\"end\":57897,\"start\":57888},{\"end\":58379,\"start\":58365},{\"end\":58388,\"start\":58379},{\"end\":58400,\"start\":58388},{\"end\":58412,\"start\":58400},{\"end\":58421,\"start\":58412},{\"end\":58433,\"start\":58421},{\"end\":58442,\"start\":58433},{\"end\":58955,\"start\":58941},{\"end\":58970,\"start\":58955},{\"end\":58990,\"start\":58970},{\"end\":59007,\"start\":58990},{\"end\":59014,\"start\":59007},{\"end\":59028,\"start\":59014},{\"end\":59296,\"start\":59289},{\"end\":59308,\"start\":59296},{\"end\":59688,\"start\":59680},{\"end\":59700,\"start\":59688},{\"end\":59715,\"start\":59700},{\"end\":59726,\"start\":59715},{\"end\":59742,\"start\":59726},{\"end\":60132,\"start\":60119},{\"end\":60143,\"start\":60132},{\"end\":60157,\"start\":60143},{\"end\":60174,\"start\":60157},{\"end\":60473,\"start\":60460},{\"end\":60487,\"start\":60473},{\"end\":60498,\"start\":60487},{\"end\":60939,\"start\":60926},{\"end\":60953,\"start\":60939},{\"end\":60968,\"start\":60953},{\"end\":60984,\"start\":60968},{\"end\":61001,\"start\":60984},{\"end\":61012,\"start\":61001},{\"end\":61481,\"start\":61469},{\"end\":61495,\"start\":61481},{\"end\":61499,\"start\":61495},{\"end\":61748,\"start\":61736},{\"end\":61762,\"start\":61748},{\"end\":61772,\"start\":61762},{\"end\":61785,\"start\":61772},{\"end\":61798,\"start\":61785},{\"end\":61805,\"start\":61798},{\"end\":62185,\"start\":62168},{\"end\":62206,\"start\":62185},{\"end\":62221,\"start\":62206},{\"end\":62702,\"start\":62686},{\"end\":62721,\"start\":62702},{\"end\":62733,\"start\":62721},{\"end\":62751,\"start\":62733},{\"end\":63254,\"start\":63243},{\"end\":63269,\"start\":63254},{\"end\":63283,\"start\":63269},{\"end\":63303,\"start\":63283},{\"end\":63310,\"start\":63303},{\"end\":63324,\"start\":63310},{\"end\":63340,\"start\":63324},{\"end\":63354,\"start\":63340},{\"end\":63371,\"start\":63354},{\"end\":63782,\"start\":63771},{\"end\":63791,\"start\":63782},{\"end\":63805,\"start\":63791},{\"end\":63820,\"start\":63805},{\"end\":64096,\"start\":64077},{\"end\":64114,\"start\":64096},{\"end\":64130,\"start\":64114},{\"end\":64142,\"start\":64130},{\"end\":64571,\"start\":64557},{\"end\":64585,\"start\":64571},{\"end\":64598,\"start\":64585},{\"end\":64609,\"start\":64598},{\"end\":64621,\"start\":64609},{\"end\":64633,\"start\":64621},{\"end\":64648,\"start\":64633},{\"end\":64665,\"start\":64648},{\"end\":65164,\"start\":65154},{\"end\":65177,\"start\":65164},{\"end\":65189,\"start\":65177},{\"end\":65198,\"start\":65189},{\"end\":65211,\"start\":65198},{\"end\":65226,\"start\":65211},{\"end\":65238,\"start\":65226},{\"end\":65247,\"start\":65238},{\"end\":65754,\"start\":65743},{\"end\":65767,\"start\":65754},{\"end\":65780,\"start\":65767},{\"end\":65795,\"start\":65780},{\"end\":66078,\"start\":66064},{\"end\":66085,\"start\":66078},{\"end\":66098,\"start\":66085},{\"end\":66109,\"start\":66098},{\"end\":66122,\"start\":66109},{\"end\":66133,\"start\":66122},{\"end\":66421,\"start\":66409},{\"end\":66437,\"start\":66421},{\"end\":66449,\"start\":66437},{\"end\":66459,\"start\":66449},{\"end\":66472,\"start\":66459},{\"end\":66489,\"start\":66472},{\"end\":66497,\"start\":66489},{\"end\":67013,\"start\":66998},{\"end\":67031,\"start\":67013},{\"end\":67043,\"start\":67031},{\"end\":67055,\"start\":67043},{\"end\":67068,\"start\":67055},{\"end\":67358,\"start\":67344},{\"end\":67370,\"start\":67358},{\"end\":67384,\"start\":67370}]", "bib_venue": "[{\"end\":54729,\"start\":54662},{\"end\":55149,\"start\":55105},{\"end\":55843,\"start\":55766},{\"end\":56395,\"start\":56318},{\"end\":56919,\"start\":56838},{\"end\":57447,\"start\":57370},{\"end\":57974,\"start\":57897},{\"end\":58519,\"start\":58442},{\"end\":58939,\"start\":58854},{\"end\":59409,\"start\":59323},{\"end\":59678,\"start\":59581},{\"end\":60117,\"start\":60043},{\"end\":60575,\"start\":60498},{\"end\":61093,\"start\":61012},{\"end\":61467,\"start\":61425},{\"end\":61843,\"start\":61805},{\"end\":62298,\"start\":62221},{\"end\":62836,\"start\":62751},{\"end\":63431,\"start\":63371},{\"end\":63869,\"start\":63820},{\"end\":64244,\"start\":64157},{\"end\":64726,\"start\":64665},{\"end\":65324,\"start\":65247},{\"end\":65741,\"start\":65661},{\"end\":66062,\"start\":66005},{\"end\":66574,\"start\":66497},{\"end\":67106,\"start\":67068},{\"end\":67439,\"start\":67400},{\"end\":54783,\"start\":54731},{\"end\":55907,\"start\":55845},{\"end\":56459,\"start\":56397},{\"end\":56987,\"start\":56921},{\"end\":57511,\"start\":57449},{\"end\":58038,\"start\":57976},{\"end\":58583,\"start\":58521},{\"end\":60639,\"start\":60577},{\"end\":61161,\"start\":61095},{\"end\":62362,\"start\":62300},{\"end\":62908,\"start\":62838},{\"end\":64774,\"start\":64728},{\"end\":65388,\"start\":65326},{\"end\":66638,\"start\":66576}]"}}}, "year": 2023, "month": 12, "day": 17}