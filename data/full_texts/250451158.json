{"id": 250451158, "updated": "2023-10-05 12:37:17.873", "metadata": {"title": "Multi-Behavior Hypergraph-Enhanced Transformer for Sequential Recommendation", "authors": "[{\"first\":\"Yuhao\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Chao\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Lianghao\",\"last\":\"Xia\",\"middle\":[]},{\"first\":\"Yuxuan\",\"last\":\"Liang\",\"middle\":[]},{\"first\":\"Yanwei\",\"last\":\"Yu\",\"middle\":[]},{\"first\":\"Chenliang\",\"last\":\"Li\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Learning dynamic user preference has become an increasingly important component for many online platforms (e.g., video-sharing sites, e-commerce systems) to make sequential recommendations. Previous works have made many efforts to model item-item transitions over user interaction sequences, based on various architectures, e.g., recurrent neural networks and self-attention mechanism. Recently emerged graph neural networks also serve as useful backbone models to capture item dependencies in sequential recommendation scenarios. Despite their effectiveness, existing methods have far focused on item sequence representation with singular type of interactions, and thus are limited to capture dynamic heterogeneous relational structures between users and items (e.g., page view, add-to-favorite, purchase). To tackle this challenge, we design a Multi-Behavior Hypergraph-enhanced Transformer framework (MBHT) to capture both short-term and long-term cross-type behavior dependencies. Specifically, a multi-scale Transformer is equipped with low-rank self-attention to jointly encode behavior-aware sequential patterns from fine-grained and coarse-grained levels. Additionally, we incorporate the global multi-behavior dependency into the hypergraph neural architecture to capture the hierarchical long-range item correlations in a customized manner. Experimental results demonstrate the superiority of our MBHT over various state-of-the-art recommendation solutions across different settings. Further ablation studies validate the effectiveness of our model design and benefits of the new MBHT framework. Our implementation code is released at: https://github.com/yuh-yang/MBHT-KDD22.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2207.05584", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/kdd/YangHXLYL22", "doi": "10.1145/3534678.3539342"}}, "content": {"source": {"pdf_hash": "8e9d2d90e2369f6d4a8cd0eaa4634765b2c72fd4", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2207.05584v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://dl.acm.org/doi/pdf/10.1145/3534678.3539342", "status": "BRONZE"}}, "grobid": {"id": "d9110630ce360d12d5bc6621782dea311bc15eff", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/8e9d2d90e2369f6d4a8cd0eaa4634765b2c72fd4.txt", "contents": "\nMulti-Behavior Hypergraph-Enhanced Transformer for Se-quential Recommendation\nAugust 14-18, 2022. 2022. August 14-18, 2022\n\nYuhao Yang yuhao-yang@outlook.com \nChao Huang chaohuang75@gmail.com \nLianghao Xia \nYuxuan Liang yuxliang@outlook.com \nYanwei Yu yuyanwei@ouc.edu.cn \nChenliang Li \nYuhao Yang \nChao Huang \nLianghao Xia \nYuxuan Liang \nYanwei Yu \nChen-Liang Li \n\nUniversity of Hong Kong Hong Kong\nChina\n\n\nUniversity of Hong Kong Hong Kong\nChina\n\n\nUniversity of Hong Kong Hong Kong\nChina\n\n\nNational University of Singapore Singapore\nSingapore\n\n\nOcean University of China\nQingdaoChina\n\n\nWuhan University Wuhan\nChina\n\nMulti-Behavior Hypergraph-Enhanced Transformer for Se-quential Recommendation\n\nKDD\nthe 28th ACM SIGKDD Con-ference on Knowledge Discovery and Data Mining (KDD'22)Washington, DC, USA; Washington22August 14-18, 2022. 2022. August 14-18, 202210.1145/3534678.3539342CCS CONCEPTS \u2022 Information systems \u2192 Recommender systems. * Chao Huang is the corresponding author., DC, USA. ACM, New York, NY, USA, 12 pages. https: //\nLearning dynamic user preference has become an increasingly important component for many online platforms (e.g., video-sharing sites, e-commerce systems) to make sequential recommendations. Previous works have made many efforts to model item-item transitions over user interaction sequences, based on various architectures, e.g., recurrent neural networks and self-attention mechanism. Recently emerged graph neural networks also serve as useful backbone models to capture item dependencies in sequential recommendation scenarios. Despite their effectiveness, existing methods have far focused on item sequence representation with singular type of interactions, and thus are limited to capture dynamic heterogeneous relational structures between users and items (e.g., page view, addto-favorite, purchase). To tackle this challenge, we design a Multi-Behavior Hypergraph-enhanced Transformer framework (MBHT) to capture both short-term and long-term cross-type behavior dependencies. Specifically, a multi-scale Transformer is equipped with low-rank self-attention to jointly encode behavior-aware sequential patterns from fine-grained and coarse-grained levels. Additionally, we incorporate the global multi-behavior dependency into the hypergraph neural architecture to capture the hierarchical long-range item correlations in a customized manner. Experimental results demonstrate the superiority of our MBHT over various state-ofthe-art recommendation solutions across different settings. Further ablation studies validate the effectiveness of our model design and benefits of the new MBHT framework. Our implementation code is released at: https://github.com/yuh-yang/MBHT-KDD22.\n\nINTRODUCTION\n\nRecommendation models have emerged as the core components of many online applications [34], such as social media platforms [36], video streaming services [10] and online retail systems [24]. Due to the highly practical value of sequential behavior modeling in various online platforms, sequential recommendation has been widely adopted in online platforms, with the aim of forecasting future users' interacted item based on their past behavior sequences [1,19].\n\nGenerally, in the sequential recommendation scenario, the systems rely on the item sequences to model time-evolving user preferences. Upon this learning paradigm, many sequential recommender systems have been proposed to encode the item dependencies based on various neural techniques and provided stronger performance, e.g., recurrent neural recommendation architecture-GRU4Rec [7] and convolution-based sequence encoder model-Caser [20]. Inspired by the Transformer framework, self-attention has been utilized to capture the item-item pairwise correlations in SASRec [13] and BERT4Rec [19]. Recently, graph neural networks (GNNs) have shown effectiveness in sequential recommender systems. Owing to strength of graph convolutions, GNN-based methods (e.g., SR-GNN [25], GCSAN [28]) are developed to learn item transitions with message passing over the constructed item graph structures.\n\nDespite their effectiveness, most of existing works have thus far focused on sequential behavior pattern encoding for singular type of interactions (e.g., clicks or purchases), without taking multi-typed user-item relationships into consideration. However, in practical online platforms, user behaviors often exhibit both time-dependent and multi-typed, involving different types of user-item interactions, e.g.,, page view, add-to-favorite, purchase. As illustrated in Figure 1, customers may click and add their interested products to their favorite lists before purchasing them. Additionally, we also visualize  Figure 1: (a) Illustration example of sequential recommendation with multi-behavior dynamics. (b) Learned behavioraware dependency weights for short-term item correlations among neighboring { [4], [5], [6]} and long-range dependencies among { [2], [13], [15]} by BERT4Rec and our MBHT.\n\nthe learned dependency weights by the baseline BERT4Rec and our MBHT method to capture behavior-aware short-term item correlations (among neighboring items { [4], [5], [6]}) and long-term itemwise dependencies (among { [2], [13], [15]}). We can observe that the global multi-behavior dependencies can be better distilled by our MBHT as compared to BERT4Rec. Hence, effectively enhancing the user preference learning with the exploration of heterogeneous user-item interactions in a dynamic environment, is also the key to making accurate sequential recommendations. Nevertheless, this task is not trivial due to the following challenges:\n\n\u2022 Dynamic Behavior-aware Item Transitions. How to explicitly capture the dynamic behavior-aware item transitions with multi-scale temporal dynamics remains a challenge. There exist different periodic behavior patterns (e.g., daily, weekly, monthly) for different categories of items (e.g., daily necessities, seasonal clothing) [9,17]. Therefore, it is necessary to explicitly capture multi-scale sequential effects of behavior-aware item transitional patterns from fine-grained to coarse-grained temporal levels.\n\n\u2022 Personalized Global Multi-Behavior Dependencies. The implicit dependencies across different types of behaviors over time vary from user to user. For example, due to the personalized and diverse user interaction preferences, some people would like to add products to their favorite list if they show interested in the items. Others may prefer to generate their favorite item list with products they are very likely to buy. That is to say, for different users, multi-behaviors have various time-aware dependencies on their interests. Moreover, multi-behavior item-wise dependencies are beyond pairwise relations and may exhibit triadic or event higher-order. Hence, the designed model requires a tailored modeling of diverse users' multi-behavior dependencies with a dynamic multi-order relation learning paradigm.\n\nContribution. This work proposes a Multi-Behavior Hypergraphenhanced Transformer (MBHT) to capture dynamic item dependencies with behavior type awareness. Our developed MBHT framework consitens of two key learning paradigms to address the aforementioned challenges correspondingly. (1) Behavior-aware Sequential Patterns. We propose a multi-scale Transformer module to comprehensively encode the multi-grained sequential patterns from fine-grained level to coarse-grained level for behavior-aware item transitions. To improve the efficiency of our sequential pattern encoder, we equip our multi-scale Transformer with the selfattentive projection based on low-rank factorization. To aggregate scale-specific temporal effects, a multi-scale behavior-aware pattern fusion is introduced to integrate multi-grained item transitional signals into a common latent representation space. (2) Global Modeling of Diverse Multi-Behavior Dependencies. We generalize the modeling of global and time-dependent cross-type behavior dependencies with a multi-behavior hypergraph learning paradigm. We construct the item hypergraph structures by unifying the latent item-wise semantic relateness and item-specific multi-behavior correlations. Technically, to capture the global item semantics, we design the item semantic dependence encoder with metric learning. Upon the hypergraph structures, we design the multi-behavior hyperedge-based message passing schema for refining item embeddings, which encourages the long-range dependency learning of different types of user-item relationships. Empirically, MBHT is able to provide better performance than state-of-the-art methods, e.g., BERT4Rec [19], HyperRec [21], SURGE [1], MB-GMN [27].\n\nThe main contributions are summarized as follows:\n\n\u2022 This work proposes a new framework named MBHT for sequential recommendation, which uncovers the underlying dynamic and multi-behavior user-item interaction patterns. \u2022 To model multi-grained item transitions with the behavior type awareness, we design a multi-scale Transformer which is empowered with the low-rank and multi-scale self-attention projection, to maintain the evolving relation-aware user interaction patterns. \u2022 In addition, to capture the diverse and long-range multi-behavior item dependencies, we propose a multi-behavior hypergraph learning paradigm to distill the item-specific multi-behavior correlations with global and customized sequential context injection. \u2022 We perform extensive experiments on three publicly available datasets, to validate the superiority of our proposed MBHT over various state-of-the-art recommender systems. Model ablation and case studies further show the benefits of our model.\n\n\nPROBLEM FORMULATION\n\nIn this section, we introduce the primary knowledge and formulates the task of multi-behavior sequential recommendation.\n\nBehavior-aware Interaction Sequence. Suppose we have a sequential recommender system with a set of users \u2208 U where |U| = . For an individual user , we define the behavior-aware interaction sequence = [( ,1 , ,1 ), ..., ( , , , ), ..., ( , , , )] with the consideration of item-specific interaction type, where denotes the length of temporally-ordered item sequence. Here, we define , to represent the behavior type of the interaction between user and -th item in , such as page view, add-to-favorite, add-to-cart and purchase in e-commerce platforms.\n\nTask Formulation. In our multi-behavior sequential recommender system, different types of interaction behaviors are partitioned into target behaviors and auxiliary behaviors. Specifically, we regard the interaction with the behavior type we aim to predict as target behaviors. Other types of user behaviors are defined as auxiliary behaviors to provide various behaviour contextual information about users' diverse preference, so as to assist the recommendation task on the target type of user-item interactions. For example, in many online retail platforms, purchase behaviors can be considered as the prediction targets, due to their highly relevance to the Gross Merchandise Volume (GMV) in online retailing to indicate the total sales value for merchandise [9,24]. We formally present our studied sequential recommendation problem as follows:\n\n\u2022 Input: The behavior-aware interaction sequence = [( ,1 , ,1 )\n\n, ..., ( , , , ), ..., ( , , , )] of each user \u2208 U. \u2022 Output: The learning function that estimates the probability of user will interact with the item +1 with the target behavior type at the future ( + 1)-th time step. \n\n\nMETHODOLOGY\n\n\nMulti-Scale Modeling of Behavior-aware Sequential Patterns\n\nIn this section, we present the technical details of our MBHT in capturing the behavior-aware user interest with multi-scale dynamics.\n\n3.1.1 Behavior-aware Context Embedding Layer. To inject the behavior-aware interaction context into our sequential learning framework, we design the behavior-aware context embedding layer to jointly encode the individual item information and the corresponding interaction behavior contextual signal. Towards this end, given an item , we offer its behavior-aware latent representation h \u2208 R with the following operation:\nh = e \u2295 p \u2295 b(1)\nwhere e \u2208 R represents the initialized item embedding. b \u2208 R is the behavior type embedding corresponding to the interaction type (e.g., page view, add-to-favorite) between user and item . Here, p \u2208 R represents the learnable positional embedding of item which differentiates the temporally-ordered positional information of different interacted items. After this context embedding layer, we can obtain the item representation matrix H \u2208 R \u00d7 for the behavior-aware interacted item sequence of user .\n\n\n3.1.2\n\nMulti-Scale Transformer Layer. In practical recommendation scenarios, user-item interaction preference may exhibit multi-scale transitional patterns over time. For instance, users often purchase different categories of products (e.g., daily necessities, clothes, digital devices) with different periodic trends, such as daily or weekly routines [10]. To tackle this challenge, we design a multiscale sequential preference encoder based on the Transformer architecture to capture the multi-grained behavior dynamics in the behavior-aware interaction sequence of users ( \u2208 U).\n\nLow-Rank Self-Attention Module. Transformer has shown its effectiveness in modeling relational data across various domains (e.g., language [31], vision [15]). In Transformer framework, selfattention serves as the key component to perform the relevanceaware information aggregation among attentive data points (e.g., words, pixels, items). However, the high computational cost (i.e., quadratic time complexity) of the self-attention mechanism limits the model scalability in practical settings [14]. Motivated by the design of Transformer structure in [22], we design a low-rank-based self-attention layer without the quadratic attentive operation, to approximate linear model complexity.\n\nIn particular, different from the original scaled dot-product attention for pairwise relation encoding, we generate multiple smaller attention operations to approximate the original attention with low-rank factorization. We first define two trainable projection matrices \u2208 R \u00d7 and \u2208 R \u00d7 to perform the low-rank embedding transformation. Here, denotes the low-rank scale and represents the number of low-rank latent representation spaces over the input behavior-aware interaction sequence . Formally, we represent our low-rank self-attention as follows:\nH = softmax( H \u00b7 (E \u00b7 H \u00b7 ) T \u221a ) \u00b7 F \u00b7 H \u00b7(2)\nwhere , , are learnable transformation matrices for embedding projection. In our low-rank self-attention module, and are utilized to project the (R \u00d7 )-dimensional key and value transformed representations H\u00b7 and H\u00b7 into (R \u00d7 )-dimensional latent low-rank embeddings H \u2208 R \u00d7 . In summary, with the lowrank factor decomposition over the original attention operations, we calculate the context mapping matrix M = H\u00b7 (H\u00b7 ) \u221a with the dimension of R \u00d7 as compared to the original dimension R \u00d7 in the vanilla self-attention mechanism. By doing so, the computational cost of our behavior sequence encoder can be significantly reduced from the ( \u00d7 ) to ( \u00d7 ) given that the low-rank projected dimension / is often much smaller than , i.e., / \u226a .\n\n\nMulti-Scale Behavior Dynamics.\n\nTo endow our MBHT model with the effective learning of multi-scale behaviour transitional patterns, we propose to enhance our low-rank-based transformer with a hierarchical structure, so as to capture granularity-specific behavior dynamics. To be specific, we develop a granularity-aware aggregator to generate granularity-specific representation g which preserves the short-term behavior dynamic. Here, we define as the length of sub-sequence for a certain granularity. We formally present our granularity-aware emebdding generation with the aggregated representation \u2208 R \u00d7 and \u2208 R as follows:\n= { 1 , ..., } = [ (h 1 , ..., h ); ...; (h \u2212 +1 , ..., h )](3)\nwhere (\u00b7) represents the aggregator to capture the short-term behavior-aware dynamics. Here, we utilize the mean pooling to perform the embedding aggregation. After that, we feed the granularityaware behavior representations into a self-attention layer for encoding granularity-specific behavior pattern as shown below:\nH = softmax( \u00b7 ( \u00b7 ) T \u221a ) \u00b7 \u00b7 (4) Behavior-aware Item Sequence item type \u2026 Low-rank Projection content mapping matrix T softmax \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026\n\nMulti-scale Behavior Dynamics\n\n\nMulti-Scale Pattern Fusion\n\n\nItem-wise Semantic Hypergraph\n\nItem-wise Multi-Behavior Hypergraph\n\n\nHyperedge Embeddings\n\nHypergraph Convolution \n= ( H \u2225 H 1 \u2225 H 2 ). (c)\nWe capture the global and personalized multi-behavior dependency learning with our hypergraph neural architecture over G.\n\nH \u2208 R \u00d7 encodes the short-term transitional patterns over different item sub-sequences. In our MBHT framework, we design a hierarchical Transformer network with two different scale settings 1 and 2 . Accordingly, our multi-scale Transformer can produce three scale-specific sequential behavior embeddings H \u2208 R \u00d7 ,\nH 1 \u2208 R 1 \u00d7 , H 2 \u2208 R 2 \u00d7 .\n\nMulti-Scale Behaviour Pattern Fusion.\n\nTo integrate the multi-scale dynamic behavior patterns into a common latent representation space, we propose to aggregate the above encoded scale-specific embeddings with a fusion layer presented as follows:\nH = ( H \u2225 H 1 \u2225 H 2 )(5)\nHere (\u00b7) represents the projection function which transforms\nR ( + 1 + 2 )\u00d7 dimensional embeddings into R \u00d7 dimensional\nrepresentations corresponding to different items ( \u2208 ) in the behavior-aware interaction sequence of user . Here, \u2225 denotes the concatenation operation over different embedding vectors.\n\nMulti-Head-Enhanced Representation Spaces. In this part, we propose to endow our behavior-aware item sequence encoder with the capability of jointly attending multi-dimensional interaction semantics. In particular, our multi-head sequential pattern encoder projects the H into latent representation spaces and performs head-specific attentive operations in parallel.\nH = (head 1 \u2225 head 2 \u2225 \u00b7 \u00b7 \u00b7 \u2225 head ) (6) head = ( H \u2225 H 1 \u2225 H 2 )\nwhere H , H 1 and H 2 are computed with head-specific projection matrices , , \u2208 R \u00d7 / , and \u2208 R \u00d7 is the output transformation matrix. The multiple attention heads allows our multi-scale Transformer architecture to encode multi-dimensional dependencies among items in .\n\nNon-linearity Injection with Feed-forward Module. In our multi-scale Transformer, we use the point-wise feed-forward network to inject non-linearities into the new generated representations. The non-linear transformation layer is formally represented:\nPFFN( H ( ) ) = [FFN(h ( ) 1 ) T , \u00b7 \u00b7 \u00b7 , FFN(h ( ) ) T ](7)\nFFN(x) = GELU(xW\n( ) 1 + b ( ) 1 )W ( ) 2 + b ( ) 2 ,\nIn our feed-forward module, we adopt two layers of non-linear transformation with the integration of intermediate non-linear activation GELU(\u00b7). In addition, W ( )\n1 \u2208 R \u00d7 \u210e , W ( ) 2 \u2208 R \u210e \u00d7 , b ( ) 1 \u2208 R , b ( ) 2 \u2208 R\nare learnable parameters of projection matrices and bias terms. Here, denotes the -th multi-scale Transformer layer.\n\n\nCustomized Hypergraph Learning of Global Multi-Behavior Dependencies\n\nIn our MBHT framework, we aim to incorporate long-range multibehavior dependency into the learning paradigm of evolving user interests. However, it is non-trivial to effectively capture the personalized long-range multi-behavior dependencies. To achieve our goal, we propose to tackle two key challenges in our learning paradigm:\n\n\u2022 i) Multi-Order Behavior-wise Dependency. The item-wise multi-behavior dependencies are no longer dyadic with the consideration of comprehensive relationships among different types of user behaviors. For example, when deciding to recommend a specific item to users for their potential purchase preference, it would be useful to explore past multi-behavior interactions (e.g., page view, add-to-favorite) between users and this item. Customers are more likely to add their interested products into their favorite item list before making final purchases.\n\n\u2022 ii) Personalized Multi-Behavior Interaction Patterns. Multibehavior patterns may vary by users with different correlations across multi-typed user-item interactions. In real-life e-commerce systems, some users like to add many items to their favorite list or cart, if they are interested in, but only a few of them will be purchased later. In contrast, another group of users only tag their interested products as favorite only if they show strong willingness to buy them. Hence, such complex and personalized multi-behavior patterns require our model to preserve the diverse cross-type behaviour dependencies.\n\nTo address the above challenges, we build our global multibehavior dependency encoder upon the hypergraph neural architecture. Inspired by the flexibility of hypergraphs in connecting multiple nodes through a single edge [2,26], we leverage the hyperedge structure to capture the tetradic or higher-order multi-behavior dependencies over time. Additionally, given the behavior-aware interaction sequence of different users, we construct different hypergraph structures over the sequence ( \u2208 U), with the aim of encoding the multi-behavior dependency in a customized manner.\n\n\n3.2.1\n\nItem-wise Hypergraph Construction. In our hypergraph framework, we generate two types of item-wise hyperedge connections corresponding to i) long-range semantic correlations among items; ii) item-specific multi-behavior dependencies across time.\n\nItem Semantic Dependency Encoding with Metric Learning. To encode the time-evolving item semantics and the underlying long-range item dependencies based on the same user interest (e.g., food, outdoor activities), we introduce an item semantic encoder based on a metric learning framework. Specifically, we design the learnable metric^, \u2032 between items with a multi-channel weight function (\u00b7) presented as follows:\n, \u2032 = 1 \u2211\ufe01 =1^, \u2032 ; v = e \u2295 b (8) , \u2032 = ( \u2299 v , \u2299 v \u2032 )(9)\nwhere^, \u2032 represents the learnable channel-specific dependency weight between item and \u2032 . We define the weight function (\u00b7) as the cosine similarity estimation based on the trainable of -th representation channel. ( \u2299 v ) represents the embedding projection operation. In our item-wise semantic dependency, we perform metric learning under representation channels (indexed by ). The mean pooling operation is applied to all learned channelspecific item semantic dependency scores (e.g.,^, \u2032 ), to obtain the final relevance , \u2032 between item and \u2032 .\n\nItem-wise Semantic Dependency Hypergraph. With the encoded semantic dependencies among different items, we generate the item-wise semantic hypergraph by simultaneously connecting multiple highly dependent items with hyperedges. In particular, we construct a set of hyperedges E , where |E | corresponds to the number of unique items in sequence . In the hypergraph G of item-wise semantic dependencies, each unique item will be assigned with a hyperedge in \u2208 E to connect top-semantic dependent items according to the learned item-item semantic dependency score , \u2032 (encoded from the metric learning component).\n\nrepresents the set of top-semantic correlated items of a specific item . We define the connection matrix between items and hyperedges as M \u2208 R \u00d7 | E | in which each entry ( , \u2032 ) is:\n( , \u2032 ) = , \u2032 \u2032 \u2208 ; 0 \u210e ;(10)\nwhere \u2032 denotes the hyperedge which is assigned to item \u2032 .\n\nItem-wise Multi-Behavior Dependency Hypergraph. To capture the personalized item-wise multi-behavior dependency in a time-aware environment, we further generate a hypergraph structure G based on the observed multi-typed interactions (e.g., page view, add-to-cart) between user and a specific item at different timestamps. Here, we define E to represent the set of items which have multi-typed interactions with user . In hypergraph G , the number of hyperedges is equal to |E |. Given that users have diverse multi-behaviour patterns with their interacted items, the constructed multi-behavior dependency hypergraphs vary by users. To be specific, we generate item-hyperedge connection matrix M \u2208 R \u00d7| E | ( \u2208 M ) for hypergraph G as follow:\n( , \u2032 ) = 1 \u2208 E ; 0 \u210e ;(11)\nrepresents that item is interacted with user under the -th behavior type. E denotes the set of multi-typed -interactions. We further integrate our constructed hypergraph structures G and G by concatenating connection matrices M and M along with the column side. As such, the integrated hypergraph G is constructed with the concatenated connection matrix M \u2208 R \u00d7( | E |+| E |) , i.e., M = M \u2225 M . Different behavior-aware interaction sequences result in different hypergraph structures for different users, which allow our MBHT model to encode the personalized multi-behavior dependent patterns in a customized way.\n\n\nHypergraph Convolution Module.\n\nIn this module, we introduce our hypergraph message passing paradigm with the convolutional layer, to capture the global multi-behavior dependencies over time. The hypergraph convolutional layer generally involves two-stage information passing [2], i.e., node-hyperedge and hyperedge-node embedding propagation along with the hypergraph connection matrix M for refining item representations. Particularly, we design our hypergraph convolutional layer as:\nX ( +1) = D \u22121 \u00b7 M \u00b7 D \u22121 \u00b7 M T \u00b7 X ( )(12)\nwhere X ( ) represents the item embeddings encoded from theth layer of hypergraph convolution. Furthermore, D and D are diagonal matrices for normalization based on vertex and edge degrees, respectively. Note that the two-stage message passing by M \u00b7 M T takes ((|E | + |E |) \u00d7 2 ) calculations, which is quite time-consuming. Inspired by the design in [33], we calculate a matrix M \u2032 by leveraging pre-calculated , \u2032 to obtain a close approximation representation of M\u00b7M T and thus boost the inference. The detailed process can be found in the supplementary material. We also remove the non-linear projection following [6] to simplify the message passing process. Each item embedding x (0) in X (0) is initialized with the behavior-aware self-gating operation as:\nx (0) = (v \u2295 b ) \u2299 sigmoid((v \u2295 b ) \u00b7 w + r).\n\nCross-View Aggregation\n\nIn the forecasting layer of MBHT framework, we propose to fuse the learned item representations from different views: 1) multi-scale behavior-aware sequential patterns with Transformer architecture; 2) personalized global multi-behavior dependencies with Hypergraph framework. To enable this cross-view aggregation in an adaptive way, we develop an attention layer to learn explicit importance for view-specific item embeddings. Formally, the aggregation procedure is presented as follows:\n= Attn( ) = exp( T \u00b7 ) exp( T \u00b7 )(13)\n\u2208 {h ,x }; g = 1 \u00b7h \u2295 2 \u00b7x whereh andx are embeddings from the two views separately for item at the -th position, and \u2208 R , \u2208 R \u00d7 are trainable parameters. Here, to eliminate the over-smooth effect of graph convolution,x is the average of x ( ) across all convolutional layers. Finally, the probability of -th item in the sequence being item is estimated as:^, = g T v , where v represents item 's embedding.\n\n\nModel Learning And Analysis\n\nTo fit our multi-behavior sequential recommendation scenario, we utilize the Cloze task [12,19] as our training objective to model the bidirectional information of item sequence. We describe our Cloze task settings as follows: Considering the multi-behavior sequential recommender systems, we mask all items in the sequence with the target behavior type (e.g., purchase). To avoid the label leak issue, we replace the masked items as well as the corresponding behavior type embeddings with the special token [mask], and leave out masked items in the hypergraph construction in Section 3.2.1. Instead, for masked items, we generate its hypergraph embedding x in Equation 13 by adopting sliding-window average pooling function over hypergraph embeddings of the contextual neighbors surrounding the mask position ( \u2212 1 , + 2 ). The details are presented in Algorithm 1 in the supplementary material. Hence, our model makes prediction on masked items based on the encoded surrounding context embeddings in the behavior interaction sequence. Given the probability estimation function^, = g T v , we define our optimized objective loss with Cross-Entropy as below:\nL = 1 | | \u2211\ufe01 \u2208 , \u2208 \u2212 log( exp^, \u2208 exp^, )(14)\nwhere is the set of ground-truth ids for masked items in each batch, is the set of masked positions corresponding to , and is the item set. The time complexity is analyzed in supplementary material.\n\n\nEXPERIMENTS\n\nThis section aims to answer the following research questions: \n\n\nExperimental Settings\n\n4.1.1 Datasets. We utilize three recommendation datasets collected from real-world scenarios. i) Taobao. This dataset is collected from Taobao which is one of the largest e-commerce platforms in China. Four types of user-item interactions are included in this dataset, i.e., target behaviors-purchase; auxiliary behaviors-add-tofavorites, add-to-cart, page view. ii) Retailrocket. This dataset is generated from an online shopping site-Retailrocket over 4 months, to record three types of user behaviors, i.e., target behaviors-purchase; auxiliary behaviors-page view & add-to-cart. iii) IJCAI. This dataset is released by IJCAI Contest 2015 for the task of repeat buyers prediction. It shares the same types of interaction behaviors with the Taobao dataset. The detailed statistical information of these experimented datasets are summarized in Table 1. Note that different datasets vary by average sequence length and user-item interaction density, which provides diverse evaluation settings.\n\n\nEvaluation Protocols.\n\nIn our experiments, closely following the settings in [19,20], we adopt the leave-one-out strategy for performance evaluation. For each user, we regard the temporallyordered last purchase as the test samples, and the previous ones as validation samples. Additionally, we pair each positive sample with 100 negative instances based on item popularity [19]. We utilize three evaluation metrics: Hit Ratio (HR@N), Normalized Discounted Cumulative Gain (NDCG@N) and Mean Reciprocal Rank (MRR) [21,25,30]. Note that larger HR, NDCG and MRR scores indicate better recommendation performance.\n\n\nBaselines.\n\nWe compare our MBHT with a variety of recommendation baselines to validate the performance superiority. General Sequential Recommendation Methods.\n\n\u2022 GRU4Rec [7]. It utilizes the gated recurrent unit as sequence encoder to learn dynamic preference with a ranking-based loss. \u2022 SASRec [13]. The self-attention mechanism is leveraged in this method to encode the item-wise sequential correlations. \u2022 Caser [20]. This method integrates the convolutional neural layers from both vertical and horizontal views to encode timeevolving user preference of item sequence. \u2022 HPMN [17]. It employs a hierarchically structured periodic memory network to model multi-scale transitional information of user sequential behaviors. The incremental updating mechanism is introduced to retain behaviour patterns over time. \u2022 BERT4Rec [19]. It uses a bidirectional encoder for modeling sequential information with Transformer. The model is optimized with the Cloze objective, and has produced state-of-the-art performance among sequence learning-based baselines.\n\nGraph-based Sequential Recommender Systems.\n\n\u2022 SR-GNN [25]. It generates graph structures based on item-item transitional relations in sequences, and conducts graph-based message passing to capture local and global user interests. \u2022 GCSAN [28]. It empowers the self-attention mechanism with with a front-mounted GNN structure. The attentive aggregation is performed over the encoded graph embeddings. \u2022 HyperRec [21]. It designs sequential hypergraphs to capture evolving users' interests and regards users as hyperedges to connect interacted items, so as to model dynamic user preferences. \u2022 SURGE [1]. It adopts metric learning to build personalized graphs and uses hierarchical attention to capture multi-dimensional user interests in the graph.\n\n\nMulti-Behavior Recommendation Models.\n\n\u2022 BERT4Rec-MB [19]. We enhance the BERT4Rec method to handle the dynamic multi-behavior context by injecting behavior type representations into the input embeddings for self-attention. \u2022 MB-GCN [11]. This model is built upon the graph convolutional layer to refine user/item embeddings through the behavior-aware message passing on the user-item interaction graph. \u2022 NMTR [3]. It defines the behavior-wise cascading relationships to model the dependency among different types of behaviors under a multi-task learning paradigm. \u2022 MB-GMN [27]. It employs a graph meta network to capture personalized multi-behavior signals and model the diverse multibehavior dependencies. It generates state-of-the-art performance among different multi-behavior recommendation methods.\n\n\nHyperparameter Settings.\n\nIn MBHT model, we search the number of hypergraph propagation layers from {1,2,3,4}. The number of multi-head channels is set as 2 for both self-attention and metric learning components. The value of for constructing item-wise semantic dependency hypergraph is tuned from [4,6,8,10,12,14]. Considering that datasets vary by average sequence length, the multi-scale setting parameters ( , 1 , 2 ) are searched amongst the value range of ( [20,4,20], [20,8,40], [40,4,20], [40,8,40]).\n\n\nPerformance Evaluation (RQ1)\n\nWe report the detailed performance comparison on different datasets in Table 2 and summarize the observations as followed:\n\n\u2022 The proposed MBHT consistently outperforms all types of baselines by a significant margin on different datasets. The performance improvements can be attributed from: i) Through the multi-scale behavior-aware Transformer, MBHT is able to capture the behavior-aware item transitional patterns from fine-grained to coarse-grained time granularities. ii) With the hypergraph neural network for multi-behavior dependency learning, we endow MBHT with the capability of capturing long-range item correlations across behavior types over time.\n\n\u2022 By jointly analyzing the results across different datasets, we can observe that our MBHT is robust to different recommendation scenarios with various data characteristics, such as average sequence length and user-item interaction density, reflecting various user behaviour patterns in many online platforms. \u2022 Graph-based sequential recommendation methods (e.g., SR-GNN, GCSAN, SURGE) perform worse than general sequential baselines (e.g., BERT4Rec, HPMN) on IJCAI dataset with longer item sequences. The possible reason is that passing message between items over the generated graph structures based on their directly transitional relations can hardly capture the long-term item dependencies. However, the performance superiority of GNN-based models can be observed on Retailrocket with shorter item sequences. In such cases, modeling of short-term item transitional regularities is sufficient for capturing item dependencies.\n\n\u2022 BERT4Rec-MB outperforms BERT4Rec in most evaluation cases. In addition, it can be found that multi-behavior recommendation models (e.g., MB-GCN, MB-GMN) achieve comparable performance to other baselines. These observations indicate the effectiveness of incorporating multi-behavior context into the learning process of user preference. With the effective modeling of dynamic multi-behaviour patterns from both short-term and long-term perspectives, our MBHT is more effective than those stationary multi-behavior recommendation approaches. From the reported results in Table 3, we summarize the following observations to show the rationality of our model design. 1) With the incorporation of hypergraph-based dependency learning on either item-wise latent semantic ((-) MB-Hyper) or dynamic multibehavior correlations ((-) ML-Hyper), MBHT can further boost the recommendation performance. 2) Comparing with the vanilla multi-head attention ((-) MS-Attention), the effectiveness of our multi-scale low-rank self-attention can be validated.\n\n\nAblation Study (RQ2)\n\n\nContribution of Learning Views.\n\nWe further investigate the contribution of sequential and hypergraph learning views, by presenting the distributions of our learned importance scores of h and x in Figure 3. In particular, h preserves multi-scale behavior dynamics of diverse user preference and x encodes the global multibehavior dependencies. We can observe that hypergraph learning view contributes more to the effective modeling of dynamic multibehavior patterns with longer item sequences (e.g., Taobao and IJCAI dataset). This further confirms the efficacy of our behavioraware hypergraph learning component in capturing the long-range item dependencies in multi-relational sequential recommendation.\n\n\nModel Benefit Study (RQ3)\n\n4.4.1 Performance w.r.t Sequence Length. To further study the robustness of our model, we evaluate MBHT on item sequences with different length. Specifically, we split users into five groups in terms of their item sequences and conduct the performance comparison on each group of users. From results presented in Figure 4, MBHT outperforms several representative baselines not only on the shorter item interaction sequences, but also on the longer item   Figure 6: Case studies with cross-type behavior dependencies.\n\nsequences. It indicates that our recommendation framework is enhanced by injecting the behavior-aware short-term and long-term dependencies (from locally to globally) into the sequence embeddings. Such data scarcity issue is hard to be alleviated purely from the general and GNN-based sequential recommender systems.\n\n\nModel Convergence Study.\n\nWe further investigate the convergence property of our MBHT and various sequential and graph-based temporal recommendation methods in Figure 5. Along the model training process, MBHT achieves faster convergence rate compared with most competitive methods. For example, MBHT obtains its best performance at epoch 2 and 8, while BERT4Rec and BERT4Rec-MB take 10 and 15 epochs to converge on Taobao and IJCAI datasets, respectively. This observation suggests that exploring the augmented multi-behavior information from both sequential and hypergraph views can provide better gradient to guide the model optimization in sequential recommendation.\n\n\nCase Study\n\nIn this section, we conduct further model analysis with case study to show the model interpretation for multi-behavior dependency modeling. In particular, we show user-specific cross-type behavior dependencies in Figure 6 (a)-(d). Each 4 \u00d7 4 dependency matrix is learned from our multi-scale Transformer. We compute the itemitem correlations by considering their behavior-aware interactions in the specific sequence of user . Figure 6 (e)-(f) show the scalespecific multi-behavior dependencies with the scales of 1 and 2 in our multi-scale modeling of behavior-aware sequential patterns. In Figure 6 (g), we show the overall relevance scores among different types of behaviors in making final forecasting on target behaviors. Additionally, our hypergraph-based item dependencies (M \u00b7 M T ) are shown in Figure 6 (h), such as hypergraph-based i) behavioraware item relevance; and ii) item-wise semantic dependence.\n\n\nRELATED WORK\n\nSequential Recommendation. Earlier studies solve the next-item recommendation using the Markov Chain-based approaches to model item-item transitions [5,18]. In recent years, many efforts have been devoted to proposing neural network-enhanced sequential recommender systems to encode the complex dependencies among items from different perspectives. For example, recurrent neural network in GRU4Rec [7] and convolutional operations in Caser [20]. Inspired by the strength of Transformer, SASRec [13] and BERT4Rec [19] are built upon the self-attention mechanism for item-item relation modeling. Furthermore, recently emerged graph neural networks produce state-of-the-art performance by performing graph-based message passing among neighboring items, in order to capture sequential signals, e.g., SR-GNN [25], MTD [8], MA-GNN [16] and SURGE [1]. However, most of those methods are specifically designed for singular type of interaction behaviors, and cannot handle diverse user-item relationships.\n\nHypergraph Learning for Recommendation. Motivated by expressiveness of hypergraphs [2,32], hypergraph neural networks are utilized in several recent recommender systems to model highorder relationships, such as multi-order item correlations in Hy-perRec [21], global user dependencies in HCCF [26], high-order social relationships in MHCN [33], and item dependencies with multi-modal features in HyperCTR [4]. Following this research line, this work integrates the hypergraph neural architecture with Transformer architecture to encode behavior-aware sequential patterns from local to global-level for comprehensive behavior modeling.\n\nMulti-Behavior Recommender Systems. There exist recently developed multi-behavior recommender systems for modeling useritem relation heterogeneity [3,11,23,29,35]. For example, NMTR [3] is a multi-task recommendation framework with the predefined behavior-wise cascading relationships. Motivated by the strength of GNNs, MBGCN [11], MBGMN [27], MGNN [35] are developed based on the graph-structured message passing over the generated multi-relational user-item interaction graphs. Nevertheless, none of those approaches considers the time-evolving multi-behaviour user preference. To fill this gap, our MBHT model is able to capture both short-term and long-term multi-behavior dependencies with a hypergraph-enhanced transformer architecture.\n\n\nCONCLUSION\n\nIn this paper, we present a new sequential recommendation framework MBHT which explicitly captures both short-term and longterm multi-behavior dependencies. MBHT designs a multi-scale Transformer to encode the behavior-aware sequential patterns at both fine-grained and coarse-grained levels. To capture the global cross-type behavior dependencies, we empower MBHT with a multi-behavior hypergraph learning component. Empirical results on several real-world datasets validate the strengths of our MBHT when competing with state-of-the-art recommendation methods.  of the second-order complexity is time-consuming, and a number of such values are slight due to the top-truncation, we replace , by a hyperparameter 0 to obtain a close approximation M \u2032 for MM T . Formally, M \u2032 \u2208 R \u00d7 is generated as follows:\nM \u2032 = \u2295 \u2295(18)\nwhere , = 1 if = , otherwise , = 0, and , = , if = , otherwise , = , + , . , = 0 . In our experiments, 0 is searched among [0.05, 0.1, 0.15, 0.2]. Finally, we express the light version of hypergraph convolution function below:\nX ( +1) = D \u22121 \u00b7 M \u2032 \u00b7 X ( )(19)\nWe conduct empirical experiments to further evaluate the model performance of our simplified hypergraph convolution mechanism. We report the evaluation results in Table 4. The model training is performed on a single GTX3090 GPU for running time evaluation. We can observe that our simplified hypergraph-based message passing scheme only lead to slightly performance degradation and improve the model efficiency with lower computational cost. The potential reasons are: i) a large number of second-order similarity are slight, since scores are truncated from top-and ii) the convolution process inherently takes into account high-order connectivity. At the same time, simplifying the convolutional function brings a lot enhancement on inference speed, since it eliminates the original ((|E | + |E |) \u00d7 2 ) calculations and M \u2032 can be easily built by leveraging pre-calculated values and data pre-processing.\n\n\nA.4 Hyperparameter Study (RQ4)\n\nWe conduct experiments to analyze the influence of key hyperparameters in our MBHT framework and report results in Figure 7.\n\nImpact of Multi-Scale Settings. We search multi-scale setting parameters ( , 1 , 2 ) among the range { [20,4,20], [20,8,40], [40,4,20] [40, 8, 40]}. We present the observations as followed:\n\n\u2022 The best performance on Retailrocket and Taobao datasets can be achieved with ( 1 , 2 ) = (4, 20) and ( 1 , 2 ) = (8, 40) given the difference of average sequence length.\n\n\u2022 For the low-rank projection scale parameter , we can notice that projecting original self-attentive sequence embedding space into 20 channels can bring the best performance on IJCAI and Retailrocket datasets. For Taobao dataset, we can observe that 40 performs better than 20 , which indicates that dense user-item interaction data may need less low-rank projection channels for better sequential pattern encoding.\n\nImpact of Item-wise Semantic Dependency Set. Our hypergraph item dependency encoder investigates the latent semantic correlations among different items. We search the top-semantic dependent items from {4,6,8,10,12,14} for global message passing through the item-wise semantic hyperedges. Observations are:\n\n\u2022 The best settings of is proportionally to the average sequence length of different datasets. It indicates that larger hypergraph propagation scope is better for modeling longer item sequences.\n\n\u2022 Increasing the number of connected items through hyperedges may firstly boost the performance at the early stage, and then lead to performance degradation by involving noise during the hypergraph-based embedding propagation.\n\nFigure 2\n2presents the overall architecture of our proposed MBHT model which consists of three key modules: i) Multi-scale modeling of behavior-aware transitional patterns of user preference; ii) Global learning of multi-behavior dependencies of time-aware user interactions; iii) Cross-view aggregation with the encoded representations of sequential behavior-aware transitional patterns and hypergraph-enhanced multi-behavior dependencies.\n\nFigure 2 :\n2MBHT's model flow. (a) We inject the behavior-aware interaction context into item embeddings h = e \u2295 p \u2295 b . (b) Multi-scale transformer architecture to capture behavior-aware transitional patterns via low-rank self-attention and multiscale sequence aggregation. Scale-specific behavior patterns are fused through the fusion function H\n\n4.3. 1 Figure 3 :Figure 4 :\n134Effects of Key Components. We firstly investigate the effectiveness of different components of our MBHT from both Transformer and Hypergraph learning views. Specifically, we generate four variants and make comparison with our MBHT method:\u2022 (-) MB-Hyper. This variant does not include the hypergraph of item-wise multi-behavior dependency to capture the long-range cross-type behavior correlations. \u2022 (-) ML-Hyper. In this variant, we remove the hypergraph message passing over the hyperedges of item semantic dependence (encoded with the metric learning component). Distributions of the learned attentive view-specific contributions. Green triangles and black line in the showed boxes denote the mean and median values, respectively. Performance w.r.t different sequence lengths. \u2022 (-) Hypergraph. This variant disables the entire hypergraph itemwise dependency learning, and only relies on the multi-scale Transformer to model the sequential behavior patterns. \u2022 (-) MS-Attention. For this variant, we replace our multi-scale attention layer with the original multi-head attentional operation.\n\nFigure 5 :\n5Training curves evaluated by testing Hit Rate.\n\nFigure 7 :\n7Hyperparameter study of MBHT framework.\n\nTable 1 :\n1Statistical information of experimented datasets. Behavior Types [buy, cart, fav, pv] [buy, cart, pv] [buy, cart, fav, pv]Stats. \nTaobao \nRetailrocket \nIJCAI \n# Users \n147, 892 \n11, 649 \n200, 000 \n# Items \n99, 038 \n36, 223 \n808, 354 \n# Interactions \n7, 092, 362 \n87, 822 \n13, 072, 940 \n# Average Length \n48.23 \n14.55 \n78.58 \n# Density \n5 \u00d7 10 \u22126 \n1 \u00d7 10 \u22126 \n7 \u00d7 10 \u22127 \n# \n\n\n\u2022 RQ1: How does our MBHT perform as compared to various stateof-the-art recommendation methods with different settings? \u2022 RQ2: How effective are the key modules (e.g., multi-scale attention encoder, multi-behavior hypergraph learning) in MBHT? \u2022 RQ3: How does MBHT perform to alleviate the data scarcity issue of item sequences when competing with baselines? \u2022 RQ4: How do different hyperparameters affect the model performance? (Evaluation results are presented in Appendix A.4).\n\nTable 2 :\n2The performance of our method and the best performed baseline are presented with bold and underlined, respectively. Superscript * indicates the significant improvement between our MBHT and the best performed baseline with value < 0.01.Model \nTaobao \nRetailrocket \nIJCAI \nHR@5 NDCG@5 HR@10 NDCG@10 MRR \nHR@5 NDCG@5 HR@10 NDCG@10 MRR \nHR@5 NDCG@5 HR@10 NDCG@10 MRR \nGeneral Sequential Recommendation Methods \nCaser \n0.082 \n0.058 \n0.123 \n0.071 \n0.070 \n0.632 \n0.539 \n0.754 \n0.578 \n0.535 \n0.134 \n0.092 \n0.167 \n0.104 \n0.109 \nHPMN \n0.162 \n0.130 \n0.219 \n0.141 \n0.139 \n0.664 \n0.633 \n0.711 \n0.587 \n0.602 \n0.144 \n0.085 \n0.197 \n0.124 \n0.123 \nGRU4Rec \n0.147 \n0.105 \n0.209 \n0.125 \n0.118 \n0.640 \n0.575 \n0.708 \n0.597 \n0.572 \n0.141 \n0.100 \n0.200 \n0.119 \n0.113 \nSASRec \n0.150 \n0.110 \n0.206 \n0.128 \n0.123 \n0.669 \n0.644 \n0.689 \n0.650 \n0.645 \n0.146 \n0.110 \n0.191 \n0.124 \n0.122 \nBERT4Rec \n0.198 \n0.153 \n0.254 \n0.171 \n0.163 \n0.808 \n0.670 \n0.881 \n0.694 \n0.639 \n0.297 \n0.220 \n0.402 \n0.253 \n0.227 \nGraph-based Sequential Recommender Systems \nSR-GNN \n0.102 \n0.071 \n0.153 \n0.087 \n0.086 \n0.848 \n0.780 \n0.891 \n0.793 \n0.767 \n0.072 \n0.048 \n0.118 \n0.062 \n0.064 \nGCSAN \n0.217 \n0.160 \n0.305 \n0.188 \n0.173 \n0.872 \n0.846 \n0.890 \n0.851 \n0.842 \n0.119 \n0.086 \n0.175 \n0.104 \n0.101 \nHyperRec \n0.145 \n0.130 \n0.224 \n0.133 \n0.129 \n0.860 \n0.705 \n0.833 \n0.820 \n0.816 \n0.140 \n0.109 \n0.236 \n0.144 \n0.132 \nSURGE \n0.122 \n0.078 \n0.193 \n0.100 \n0.093 \n0.878 \n0.879 \n0.906 \n0.887 \n0.870 \n0.226 \n0.159 \n0.322 \n0.190 \n0.171 \nMulti-Behavior Recommendation Models \nBERT4Rec-MB 0.211 \n0.169 \n0.263 \n0.186 \n0.178 \n0.875 \n0.858 \n0.889 \n0.863 \n0.857 \n0.257 \n0.189 \n0.342 \n0.216 \n0.197 \nMB-GCN \n0.185 \n0.103 \n0.309 \n0.143 \n0.149 \n0.844 \n0.735 \n0.878 \n0.752 \n0.739 \n0.218 \n0.145 \n0.335 \n0.182 \n0.177 \nNMTR \n0.125 \n0.082 \n0.174 \n0.097 \n0.103 \n0.827 \n0.697 \n0.858 \n0.724 \n0.741 \n0.109 \n0.076 \n0.184 \n0.099 \n0.106 \nMB-GMN \n0.196 \n0.115 \n0.319 \n0.154 \n0.151 \n0.853 \n0.762 \n0.901 \n0.830 \n0.822 \n0.235 \n0.161 \n0.337 \n0.193 \n0.176 \nMBHT \n0.323  *  \n0.257  *  \n0.405  *  \n0.283  *  \n0.262  *  0.931  *  \n0.933  *  \n0.956  *  \n0.950  *  \n0.929  *  0.346  *  \n0.268  *  \n0.437  *  \n0.297  *  \n0.272  *  \n# Improve \n48.84% \n52.07% \n26.95% \n50.53% \n47.19% 6.04% \n6.14% \n5.52% \n7.10% \n6.78% 16.50% \n21.82% \n8.71% \n17.39% \n19.82% \n\n\n\nTable 3 :\n3Ablation study with key modules.Model Variants \nTaobao \nRetailrocket \nIJCAI \nHR@5 NDCG@5 HR@5 NDCG@5 HR@5 NDCG@5 \nMBHT \n0.323 \n0.257 \n0.956 \n0.950 \n0.346 \n0.268 \n(-) MB-Hyper \n0.261 \n0.206 \n0.883 \n0.861 \n0.320 \n0.249 \n(-) ML-Hyper \n0.271 \n0.212 \n0.898 \n0.874 \n0.328 \n0.256 \n(-) Hypergraph \n0.246 \n0.194 \n0.813 \n0.839 \n0.301 \n0.234 \n(-) MS-Attention 0.253 \n0.200 \n0.816 \n0.832 \n0.329 \n0.256 \n\n\n\nTable 4 :\n4Comparison between two implementation of hypergraph message passing schemes, i.e., the original embedding propagation based on hypergraph connection matrices, and the simplified message passing schema. The recommendation accuracy is measured by Recall@5 and model computational cost is measured by the running time of each epoch.(b) Sensitivity to sim-group lengthTaoabo \nRetailrocket \nIJCAI \nRecall@5 Epoch Time Recall@5 Epoch Time Recall@5 Epoch Time \nOrigin \n0.326 \n86.43 \n0.959 \n4.58 \n0.352 \n133.28 \nSimplified \n0.323 \n38.05 \n0.956 \n2.11 \n0.346 \n65.2 \n\n0.92 \n\n0.94 \nHR@5 \n\nRetailrocket \n\n[40,4,20] [40,8,40] [20,4,20] [20,8,40] \nScales \n\n0.30 \n\n0.35 \n\nHR@5 \nTaobao \nIJCAI \n\n(a) Sensitivity to attention scales \n\n0.92 \n\n0.94 \n\nHR@5 \n\nRetailrocket \n\n4 6 8 10 12 14 \nSim-Group Lengths \n\n0.32 \n\n0.34 \nHR@5 \n\nTaobao \nIJCAI \n\n\nKDD'22, August 14-18, 2022, Washington, DC, USA Yuhao Yang et al.\nACKNOWLEDGMENTSA SUPPLEMENTARY MATERIALIn our supplemental material, we first summarize the learning process of our MBHT framework in Algorithm 1 and conduct the model time complexity analysis. Then, we present our strategy to simplify the implementation of our hypergraph-based embedding propagation, so as to improve the model efficiency.  8 Apply hypergraph convolutional function to aggregate information from the graph:Fusion and Prediction; 10 foreach \u2208 , \u2208 do 11 Generate hypergraph-view embedding for mask position using sliding-window contextual pooling:Apply attentive cross-view aggregation to fuse the information according to Equation13:Calculate the probability of item at being :A.2 Time Complexity AnalysisThis section conducts the time complexity analysis of our MBHT framework as follows.(1)For the multi-scale Transformer view, with our low-rank self-attention layer, we significantly reduce the computational cost from ( \u00d7 \u00d7 (( ) 2 + ( 1 ) 2 + ( 2 ) 2 )) to approximate the linear time complexity(3 ), given that (low-rank scale), 1 , 2 (resolution scales) \u226a[22]. denotes the length of item sequence. (2) For the hypergraph learning view, the semantic metric learning takes ( 2 ) complexity, and the hypergraph convolutional function takes ( 2 ). Based on the above discussion, the overall time complexity of our MBHT is (3 + 2 + 2 ), which is comparable to state-of-the-art baselines.A.3 Simplifying Hypergraph Message PassingWith the consideration of high computational cost during the message passing in our hypergraph learning framework, we propose to simplify the propagation scheme with the learnable embedding projection. Formally, we rewrite the two-stage (node-hyperedge-node) message propagation process M \u00b7 M T as follows:where M ( ) and M ( ) denotes the -th row and -th column vector, respectively. Based on our item-wise semantic dependence and multi-behavior correlations, our hypergraph-guided information propagation can be presented as follows:where M , and M , denote the value of hypergraph connection matrix with item-wise semantic dependency and multi-behavior correlations of item , respectively. Here, we first simplify the multiplication operations with the multi-behavior dependency hyperedges. Specifically, the same item ( = ) interacted with different behavior types over time will be connected to the same hyperedge , i.e., M , = M , = 1. Since each item can only be connected to one hyperedge, for \u2032 \u2260 , M , \u2032 = M , = 0. This indicates that if \u2260 , there exists no multi-behavior dependency hyperedge \u2032 such that M , \u2032 M , \u2032 = 1, since different items cannot be connected to the same hyperedge. Hence, we can isolate the influence of the multi-behavior dependency hyperedges as follows:We further investigate the item-wise semantic dependency hyperedges in Equation16for simplifying hypergraph convolutional operations. Note that, M , denotes the cosine similarity between item and that belong to the hyperedge . Generally, the computation | E | =1 M M can be divided into three cases depending on the hyperedge : i) behavior-aware self-connection, if = and is the hyperedge assigned to this item; ii) first-order similarity, if \u2260 and is assigned to or ; iii) second-order similarity, if \u2260 and is not assigned to either or .We leverage the pre-calculated behavior-aware semantic similarities , between items for the first and second cases. Here , is truncated from the top-value to be consistent with the semantic dependency hyperedges. We denote the values of the third case by , . Therefore, based on the above discussions, for the first case, we have:\nSequential Recommendation with Graph Neural Networks. Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, SIGIR. Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, et al. 2021. Sequential Recommendation with Graph Neural Networks. In SIGIR. 378-387.\n\nHypergraph neural networks. Yifan Feng, Haoxuan You, Zizhao Zhang, Rongrong Ji, Yue Gao, In AAAI. 33Yifan Feng, Haoxuan You, Zizhao Zhang, Rongrong Ji, and Yue Gao. 2019. Hy- pergraph neural networks. In AAAI, Vol. 33. 3558-3565.\n\nNeural multitask recommendation from multi-behavior data. Chen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, ICDE. IEEE. Chen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, et al. 2019. Neural multi- task recommendation from multi-behavior data. In ICDE. IEEE, 1554-1557.\n\nClick-Through Rate Prediction with Multi-Modal Hypergraphs. Li He, Hongxu Chen, Dingxian Wang, Shoaib Jameel, Philip Yu, CIKM. Li He, Hongxu Chen, Dingxian Wang, Shoaib Jameel, Philip Yu, et al. 2021. Click- Through Rate Prediction with Multi-Modal Hypergraphs. In CIKM. 690-699.\n\nFusing similarity models with markov chains for sparse sequential recommendation. Ruining He, Julian Mcauley, ICDM. IEEE. Ruining He and Julian McAuley. 2016. Fusing similarity models with markov chains for sparse sequential recommendation. In ICDM. IEEE, 191-200.\n\nLightgcn: Simplifying and powering graph convolution network for recommendation. Xiangnan He, Kuan Deng, Xiang Wang, SIGIR. Xiangnan He, Kuan Deng, Xiang Wang, et al. 2020. Lightgcn: Simplifying and powering graph convolution network for recommendation. In SIGIR. 639-648.\n\nSession-based recommendations with recurrent neural networks. Bal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. In ICLRBal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based recommendations with recurrent neural networks. In ICLR.\n\nGraph-enhanced multi-task learning of multi-level transition dynamics for session-based recommendation. Chao Huang, Jiahui Chen, Lianghao Xia, Yong Xu, Peng Dai, Yanqing Chen, Liefeng Bo, Jiashu Zhao, Jimmy Xiangji Huang, AAAI. Chao Huang, Jiahui Chen, Lianghao Xia, Yong Xu, Peng Dai, Yanqing Chen, Liefeng Bo, Jiashu Zhao, and Jimmy Xiangji Huang. 2021. Graph-enhanced multi-task learning of multi-level transition dynamics for session-based recom- mendation. In AAAI.\n\nOnline purchase prediction via multi-scale modeling of behavior dynamics. Chao Huang, Xian Wu, Xuchao Zhang, Chuxu Zhang, Jiashu Zhao, Dawei Yin, Nitesh V Chawla, Chao Huang, Xian Wu, Xuchao Zhang, Chuxu Zhang, Jiashu Zhao, Dawei Yin, and Nitesh V Chawla. 2019. Online purchase prediction via multi-scale modeling of behavior dynamics. In KDD. 2613-2622.\n\nWhat aspect do you like: Multi-scale time-aware user interest modeling for micro-video recommendation. Hao Jiang, MM. Hao Jiang et al. 2020. What aspect do you like: Multi-scale time-aware user interest modeling for micro-video recommendation. In MM. 3487-3495.\n\nMulti-behavior recommendation with graph convolutional networks. Chen Bowen Jin, Xiangnan Gao, Depeng He, Jin, SIGIR. Bowen Jin, Chen Gao, Xiangnan He, Depeng Jin, et al. 2020. Multi-behavior recommendation with graph convolutional networks. In SIGIR. 659-668.\n\nEntangled bidirectional encoder to autoregressive decoder for sequential recommendation. Taegwan Kang, Hwanhee Lee, Byeongjin Choe, Kyomin Jung, SIGIR. Taegwan Kang, Hwanhee Lee, Byeongjin Choe, and Kyomin Jung. 2021. Entan- gled bidirectional encoder to autoregressive decoder for sequential recommenda- tion. In SIGIR. 1657-1661.\n\nSelf-attentive sequential recommendation. Wang-Cheng Kang, Julian Mcauley, ICDM. IEEE. Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom- mendation. In ICDM. IEEE, 197-206.\n\nReformer: The efficient transformer. Nikita Kitaev, ICLR. Nikita Kitaev et al. 2020. Reformer: The efficient transformer. In ICLR.\n\nSwin transformer: Hierarchical vision transformer using shifted windows. Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, et al. 2021. Swin transformer: Hierarchical vision transformer using shifted windows. In ICCV. 10012-10022.\n\nMemory augmented graph neural networks for sequential recommendation. Chen Ma, Liheng Ma, Yingxue Zhang, In AAAI. 34Chen Ma, Liheng Ma, Yingxue Zhang, et al. 2020. Memory augmented graph neural networks for sequential recommendation. In AAAI, Vol. 34. 5045-5052.\n\nLifelong sequential modeling with personalized memorization for user response prediction. Jiarui Kan Ren, Qin, SIGIR. Kan Ren, Jiarui Qin, et al. 2019. Lifelong sequential modeling with personalized memorization for user response prediction. In SIGIR. 565-574.\n\nFactorizing personalized markov chains for next-basket recommendation. Steffen Rendle, Christoph Freudenthaler, WWW. Steffen Rendle, Christoph Freudenthaler, et al. 2010. Factorizing personalized markov chains for next-basket recommendation. In WWW. 811-820.\n\nBERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. Fei Sun, Jun Liu, CIKM. Fei Sun, Jun Liu, et al. 2019. BERT4Rec: Sequential recommendation with bidi- rectional encoder representations from transformer. In CIKM. 1441-1450.\n\nPersonalized top-n sequential recommendation via convolutional sequence embedding. Jiaxi Tang, Ke Wang, WSDM. Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In WSDM. 565-573.\n\nNext-item recommendation with sequential hypergraphs. Jianling Wang, Kaize Ding, Liangjie Hong, Huan Liu, James Caverlee, SIGIR. Jianling Wang, Kaize Ding, Liangjie Hong, Huan Liu, and James Caverlee. 2020. Next-item recommendation with sequential hypergraphs. In SIGIR. 1101-1110.\n\nSinong Wang, Belinda Z Li, Madian Khabsa, Han Fang, Hao Ma, arXiv:2006.04768Linformer: Self-Attention with Linear Complexity. cs.LGSinong Wang, Belinda Z. Li, Madian Khabsa, Han Fang, and Hao Ma. 2020. Linformer: Self-Attention with Linear Complexity. arXiv:2006.04768 [cs.LG]\n\nContrastive Meta Learning with Behavior Multiplicity for Recommendation. Wei Wei, Chao Huang, Lianghao Xia, Yong Xu, Jiashu Zhao, Dawei Yin, WSDM. Wei Wei, Chao Huang, Lianghao Xia, Yong Xu, Jiashu Zhao, and Dawei Yin. 2022. Contrastive Meta Learning with Behavior Multiplicity for Recommendation. In WSDM. 1120-1128.\n\nTurning clicks into purchases: Revenue optimization for product search in e-commerce. Liang Wu, Diane Hu, Liangjie Hong, SIGIR. Liang Wu, Diane Hu, Liangjie Hong, et al. 2018. Turning clicks into purchases: Revenue optimization for product search in e-commerce. In SIGIR. 365-374.\n\nSession-based recommendation with graph neural networks. Shu Wu, Yuyuan Tang, Yanqiao Zhu, In AAAI. 33Shu Wu, Yuyuan Tang, Yanqiao Zhu, et al. 2019. Session-based recommendation with graph neural networks. In AAAI, Vol. 33. 346-353.\n\nLianghao Xia, Chao Huang, Yong Xu, Jiashu Zhao, Dawei Yin, Jimmy Xiangji Huang, arXiv:2204.12200Hypergraph Contrastive Collaborative Filtering. arXiv preprintLianghao Xia, Chao Huang, Yong Xu, Jiashu Zhao, Dawei Yin, and Jimmy Xiangji Huang. 2022. Hypergraph Contrastive Collaborative Filtering. arXiv preprint arXiv:2204.12200.\n\nGraph meta network for multi-behavior recommendation. Lianghao Xia, Yong Xu, Chao Huang, Peng Dai, Liefeng Bo, SIGIR. Lianghao Xia, Yong Xu, Chao Huang, Peng Dai, and Liefeng Bo. 2021. Graph meta network for multi-behavior recommendation. In SIGIR. 757-766.\n\nGraph Contextualized Self-Attention Network for Session-based Recommendation. Chengfeng Xu, Pengpeng Zhao, IJCAI. 19Chengfeng Xu, Pengpeng Zhao, et al. 2019. Graph Contextualized Self-Attention Network for Session-based Recommendation.. In IJCAI, Vol. 19. 3940-3946.\n\nHyper Meta-Path Contrastive Learning for Multi-Behavior Recommendation. Haoran Yang, Hongxu Chen, Lin Li, Yu Philip, Guandong Xu, ICDM. IEEE. Haoran Yang, Hongxu Chen, Lin Li, S Yu Philip, and Guandong Xu. 2021. Hyper Meta-Path Contrastive Learning for Multi-Behavior Recommendation. In ICDM. IEEE, 787-796.\n\nYuhao Yang, Chao Huang, arXiv:2205.00976Lianghao Xia, and Chenliang Li. 2022. Knowledge Graph Contrastive Learning for Recommendation. arXiv preprintYuhao Yang, Chao Huang, Lianghao Xia, and Chenliang Li. 2022. Knowledge Graph Contrastive Learning for Recommendation. arXiv preprint arXiv:2205.00976 (2022).\n\nMultimodal transformer for multimodal machine translation. Shaowei Yao, Xiaojun Wan, ACL. Shaowei Yao and Xiaojun Wan. 2020. Multimodal transformer for multimodal machine translation. In ACL. 4346-4350.\n\nJaehyuk Yi, Jinkyoo Park, Hypergraph convolutional recurrent neural network. In KDD. Jaehyuk Yi and Jinkyoo Park. 2020. Hypergraph convolutional recurrent neural network. In KDD. 3366-3376.\n\nSelf-Supervised Multi-Channel Hypergraph Convolutional Network for Social Recommendation. Junliang Yu, Hongzhi Yin, WWW. Junliang Yu, Hongzhi Yin, et al. 2021. Self-Supervised Multi-Channel Hypergraph Convolutional Network for Social Recommendation. In WWW. 413-424.\n\nDeep learning based recommender system: A survey and new perspectives. Shuai Zhang, Lina Yao, Aixin Sun, Yi Tay, ACM Computing Surveys (CSUR). 52Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019. Deep learning based rec- ommender system: A survey and new perspectives. ACM Computing Surveys (CSUR) 52, 1 (2019), 1-38.\n\nMultiplex graph neural networks for multi-behavior recommendation. Weifeng Zhang, Jingwen Mao, Yi Cao, Congfu Xu, CIKM. Weifeng Zhang, Jingwen Mao, Yi Cao, and Congfu Xu. 2020. Multiplex graph neural networks for multi-behavior recommendation. In CIKM. 2313-2316.\n\nOnline social media recommendation over streams. Xiangmin Zhou, Dong Qin, Xiaolu Lu, Lei Chen, Yanchun Zhang, ICDE. IEEE. Xiangmin Zhou, Dong Qin, Xiaolu Lu, Lei Chen, and Yanchun Zhang. 2019. Online social media recommendation over streams. In ICDE. IEEE, 938-949.\n", "annotations": {"author": "[{\"end\":159,\"start\":125},{\"end\":193,\"start\":160},{\"end\":207,\"start\":194},{\"end\":242,\"start\":208},{\"end\":273,\"start\":243},{\"end\":287,\"start\":274},{\"end\":299,\"start\":288},{\"end\":311,\"start\":300},{\"end\":325,\"start\":312},{\"end\":339,\"start\":326},{\"end\":350,\"start\":340},{\"end\":365,\"start\":351},{\"end\":407,\"start\":366},{\"end\":449,\"start\":408},{\"end\":491,\"start\":450},{\"end\":546,\"start\":492},{\"end\":587,\"start\":547},{\"end\":618,\"start\":588}]", "publisher": null, "author_last_name": "[{\"end\":135,\"start\":131},{\"end\":170,\"start\":165},{\"end\":206,\"start\":203},{\"end\":220,\"start\":215},{\"end\":252,\"start\":250},{\"end\":286,\"start\":284},{\"end\":298,\"start\":294},{\"end\":310,\"start\":305},{\"end\":324,\"start\":321},{\"end\":338,\"start\":333},{\"end\":349,\"start\":347},{\"end\":364,\"start\":362}]", "author_first_name": "[{\"end\":130,\"start\":125},{\"end\":164,\"start\":160},{\"end\":202,\"start\":194},{\"end\":214,\"start\":208},{\"end\":249,\"start\":243},{\"end\":283,\"start\":274},{\"end\":293,\"start\":288},{\"end\":304,\"start\":300},{\"end\":320,\"start\":312},{\"end\":332,\"start\":326},{\"end\":346,\"start\":340},{\"end\":361,\"start\":351}]", "author_affiliation": "[{\"end\":406,\"start\":367},{\"end\":448,\"start\":409},{\"end\":490,\"start\":451},{\"end\":545,\"start\":493},{\"end\":586,\"start\":548},{\"end\":617,\"start\":589}]", "title": "[{\"end\":78,\"start\":1},{\"end\":696,\"start\":619}]", "venue": "[{\"end\":701,\"start\":698}]", "abstract": "[{\"end\":2718,\"start\":1035}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b33\"},\"end\":2824,\"start\":2820},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":2861,\"start\":2857},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2892,\"start\":2888},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2923,\"start\":2919},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3191,\"start\":3188},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3194,\"start\":3191},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3579,\"start\":3576},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3635,\"start\":3631},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3770,\"start\":3766},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3788,\"start\":3784},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3966,\"start\":3962},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3978,\"start\":3974},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4896,\"start\":4893},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4901,\"start\":4898},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4906,\"start\":4903},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4947,\"start\":4944},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4953,\"start\":4949},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4959,\"start\":4955},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5149,\"start\":5146},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5154,\"start\":5151},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5159,\"start\":5156},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5210,\"start\":5207},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":5216,\"start\":5212},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5222,\"start\":5218},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5958,\"start\":5955},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5961,\"start\":5958},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8638,\"start\":8634},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8653,\"start\":8649},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8664,\"start\":8661},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8677,\"start\":8673},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11122,\"start\":11119},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11125,\"start\":11122},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12998,\"start\":12994},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":13368,\"start\":13364},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13381,\"start\":13377},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":13722,\"start\":13718},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":13780,\"start\":13776},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20866,\"start\":20863},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":20869,\"start\":20866},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":25050,\"start\":25047},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":25659,\"start\":25655},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":25925,\"start\":25922},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":27198,\"start\":27194},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":27201,\"start\":27198},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":29690,\"start\":29686},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":29693,\"start\":29690},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":29986,\"start\":29982},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":30125,\"start\":30121},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":30128,\"start\":30125},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":30131,\"start\":30128},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":30393,\"start\":30390},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":30520,\"start\":30516},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":30640,\"start\":30636},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":30805,\"start\":30801},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":31050,\"start\":31046},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":31333,\"start\":31329},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":31518,\"start\":31514},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31691,\"start\":31687},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":31877,\"start\":31874},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":32083,\"start\":32079},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":32263,\"start\":32259},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":32440,\"start\":32437},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":32605,\"start\":32601},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33136,\"start\":33133},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":33138,\"start\":33136},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":33140,\"start\":33138},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":33143,\"start\":33140},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":33146,\"start\":33143},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":33149,\"start\":33146},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":33303,\"start\":33299},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33305,\"start\":33303},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":33308,\"start\":33305},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":33314,\"start\":33310},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":33316,\"start\":33314},{\"end\":33319,\"start\":33316},{\"end\":33325,\"start\":33321},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33327,\"start\":33325},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":33330,\"start\":33327},{\"end\":33336,\"start\":33332},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":33338,\"start\":33336},{\"end\":33341,\"start\":33338},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":39373,\"start\":39370},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":39376,\"start\":39373},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":39622,\"start\":39619},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":39665,\"start\":39661},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":39719,\"start\":39715},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":39737,\"start\":39733},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":40028,\"start\":40024},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":40037,\"start\":40034},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":40050,\"start\":40046},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":40064,\"start\":40061},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":40305,\"start\":40302},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":40308,\"start\":40305},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":40477,\"start\":40473},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":40516,\"start\":40512},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":40562,\"start\":40558},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":40627,\"start\":40624},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":41005,\"start\":41002},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":41008,\"start\":41005},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":41011,\"start\":41008},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":41014,\"start\":41011},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":41017,\"start\":41014},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":41040,\"start\":41037},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":41186,\"start\":41182},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":41198,\"start\":41194},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":41209,\"start\":41205},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":43868,\"start\":43864},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":43870,\"start\":43868},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":43873,\"start\":43870},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":43879,\"start\":43875},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":43881,\"start\":43879},{\"end\":43884,\"start\":43881},{\"end\":43890,\"start\":43886},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":43892,\"start\":43890},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":43895,\"start\":43892}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":45715,\"start\":45274},{\"attributes\":{\"id\":\"fig_2\"},\"end\":46064,\"start\":45716},{\"attributes\":{\"id\":\"fig_3\"},\"end\":47191,\"start\":46065},{\"attributes\":{\"id\":\"fig_4\"},\"end\":47251,\"start\":47192},{\"attributes\":{\"id\":\"fig_5\"},\"end\":47304,\"start\":47252},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":47688,\"start\":47305},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":48171,\"start\":47689},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":50437,\"start\":48172},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":50842,\"start\":50438},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":51679,\"start\":50843}]", "paragraph": "[{\"end\":3195,\"start\":2734},{\"end\":4084,\"start\":3197},{\"end\":4986,\"start\":4086},{\"end\":5625,\"start\":4988},{\"end\":6140,\"start\":5627},{\"end\":6956,\"start\":6142},{\"end\":8678,\"start\":6958},{\"end\":8729,\"start\":8680},{\"end\":9660,\"start\":8731},{\"end\":9804,\"start\":9684},{\"end\":10356,\"start\":9806},{\"end\":11204,\"start\":10358},{\"end\":11269,\"start\":11206},{\"end\":11490,\"start\":11271},{\"end\":11701,\"start\":11567},{\"end\":12122,\"start\":11703},{\"end\":12639,\"start\":12140},{\"end\":13223,\"start\":12649},{\"end\":13912,\"start\":13225},{\"end\":14466,\"start\":13914},{\"end\":15253,\"start\":14514},{\"end\":15882,\"start\":15288},{\"end\":16266,\"start\":15947},{\"end\":16540,\"start\":16505},{\"end\":16588,\"start\":16565},{\"end\":16735,\"start\":16614},{\"end\":17051,\"start\":16737},{\"end\":17327,\"start\":17120},{\"end\":17413,\"start\":17353},{\"end\":17658,\"start\":17473},{\"end\":18026,\"start\":17660},{\"end\":18363,\"start\":18094},{\"end\":18616,\"start\":18365},{\"end\":18695,\"start\":18679},{\"end\":18896,\"start\":18733},{\"end\":19069,\"start\":18953},{\"end\":19471,\"start\":19142},{\"end\":20026,\"start\":19473},{\"end\":20640,\"start\":20028},{\"end\":21215,\"start\":20642},{\"end\":21470,\"start\":21225},{\"end\":21886,\"start\":21472},{\"end\":22495,\"start\":21946},{\"end\":23108,\"start\":22497},{\"end\":23292,\"start\":23110},{\"end\":23382,\"start\":23323},{\"end\":24125,\"start\":23384},{\"end\":24768,\"start\":24154},{\"end\":25257,\"start\":24803},{\"end\":26066,\"start\":25302},{\"end\":26627,\"start\":26138},{\"end\":27074,\"start\":26666},{\"end\":28264,\"start\":27106},{\"end\":28509,\"start\":28311},{\"end\":28587,\"start\":28525},{\"end\":29606,\"start\":28613},{\"end\":30217,\"start\":29632},{\"end\":30378,\"start\":30232},{\"end\":31273,\"start\":30380},{\"end\":31318,\"start\":31275},{\"end\":32023,\"start\":31320},{\"end\":32832,\"start\":32065},{\"end\":33343,\"start\":32861},{\"end\":33498,\"start\":33376},{\"end\":34036,\"start\":33500},{\"end\":34967,\"start\":34038},{\"end\":36009,\"start\":34969},{\"end\":36740,\"start\":36068},{\"end\":37286,\"start\":36770},{\"end\":37604,\"start\":37288},{\"end\":38276,\"start\":37633},{\"end\":39204,\"start\":38291},{\"end\":40217,\"start\":39221},{\"end\":40853,\"start\":40219},{\"end\":41598,\"start\":40855},{\"end\":42419,\"start\":41613},{\"end\":42660,\"start\":42434},{\"end\":43600,\"start\":42694},{\"end\":43759,\"start\":43635},{\"end\":43950,\"start\":43761},{\"end\":44124,\"start\":43952},{\"end\":44542,\"start\":44126},{\"end\":44849,\"start\":44544},{\"end\":45045,\"start\":44851},{\"end\":45273,\"start\":45047}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12139,\"start\":12123},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14513,\"start\":14467},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15946,\"start\":15883},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16411,\"start\":16267},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16613,\"start\":16589},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17079,\"start\":17052},{\"attributes\":{\"id\":\"formula_6\"},\"end\":17352,\"start\":17328},{\"attributes\":{\"id\":\"formula_7\"},\"end\":17472,\"start\":17414},{\"attributes\":{\"id\":\"formula_8\"},\"end\":18093,\"start\":18027},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18678,\"start\":18617},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18732,\"start\":18696},{\"attributes\":{\"id\":\"formula_11\"},\"end\":18952,\"start\":18897},{\"attributes\":{\"id\":\"formula_12\"},\"end\":21945,\"start\":21887},{\"attributes\":{\"id\":\"formula_13\"},\"end\":23322,\"start\":23293},{\"attributes\":{\"id\":\"formula_14\"},\"end\":24153,\"start\":24126},{\"attributes\":{\"id\":\"formula_15\"},\"end\":25301,\"start\":25258},{\"attributes\":{\"id\":\"formula_16\"},\"end\":26112,\"start\":26067},{\"attributes\":{\"id\":\"formula_17\"},\"end\":26665,\"start\":26628},{\"attributes\":{\"id\":\"formula_18\"},\"end\":28310,\"start\":28265},{\"attributes\":{\"id\":\"formula_19\"},\"end\":42433,\"start\":42420},{\"attributes\":{\"id\":\"formula_20\"},\"end\":42693,\"start\":42661}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":29465,\"start\":29458},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":33454,\"start\":33447},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":35547,\"start\":35540},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":42864,\"start\":42857}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2732,\"start\":2720},{\"attributes\":{\"n\":\"2\"},\"end\":9682,\"start\":9663},{\"attributes\":{\"n\":\"3\"},\"end\":11504,\"start\":11493},{\"attributes\":{\"n\":\"3.1\"},\"end\":11565,\"start\":11507},{\"end\":12647,\"start\":12642},{\"end\":15286,\"start\":15256},{\"end\":16442,\"start\":16413},{\"end\":16471,\"start\":16445},{\"end\":16503,\"start\":16474},{\"end\":16563,\"start\":16543},{\"attributes\":{\"n\":\"3.1.3\"},\"end\":17118,\"start\":17081},{\"attributes\":{\"n\":\"3.2\"},\"end\":19140,\"start\":19072},{\"end\":21223,\"start\":21218},{\"attributes\":{\"n\":\"3.2.2\"},\"end\":24801,\"start\":24771},{\"attributes\":{\"n\":\"3.3\"},\"end\":26136,\"start\":26114},{\"attributes\":{\"n\":\"3.4\"},\"end\":27104,\"start\":27077},{\"attributes\":{\"n\":\"4\"},\"end\":28523,\"start\":28512},{\"attributes\":{\"n\":\"4.1\"},\"end\":28611,\"start\":28590},{\"attributes\":{\"n\":\"4.1.2\"},\"end\":29630,\"start\":29609},{\"attributes\":{\"n\":\"4.1.3\"},\"end\":30230,\"start\":30220},{\"end\":32063,\"start\":32026},{\"attributes\":{\"n\":\"4.1.4\"},\"end\":32859,\"start\":32835},{\"attributes\":{\"n\":\"4.2\"},\"end\":33374,\"start\":33346},{\"attributes\":{\"n\":\"4.3\"},\"end\":36032,\"start\":36012},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":36066,\"start\":36035},{\"attributes\":{\"n\":\"4.4\"},\"end\":36768,\"start\":36743},{\"attributes\":{\"n\":\"4.4.2\"},\"end\":37631,\"start\":37607},{\"attributes\":{\"n\":\"4.5\"},\"end\":38289,\"start\":38279},{\"attributes\":{\"n\":\"5\"},\"end\":39219,\"start\":39207},{\"attributes\":{\"n\":\"6\"},\"end\":41611,\"start\":41601},{\"end\":43633,\"start\":43603},{\"end\":45283,\"start\":45275},{\"end\":45727,\"start\":45717},{\"end\":46093,\"start\":46066},{\"end\":47203,\"start\":47193},{\"end\":47263,\"start\":47253},{\"end\":47315,\"start\":47306},{\"end\":48182,\"start\":48173},{\"end\":50448,\"start\":50439},{\"end\":50853,\"start\":50844}]", "table": "[{\"end\":47688,\"start\":47439},{\"end\":50437,\"start\":48419},{\"end\":50842,\"start\":50482},{\"end\":51679,\"start\":51219}]", "figure_caption": "[{\"end\":45715,\"start\":45285},{\"end\":46064,\"start\":45729},{\"end\":47191,\"start\":46097},{\"end\":47251,\"start\":47205},{\"end\":47304,\"start\":47265},{\"end\":47439,\"start\":47317},{\"end\":48171,\"start\":47691},{\"end\":48419,\"start\":48184},{\"end\":50482,\"start\":50450},{\"end\":51219,\"start\":50855}]", "figure_ref": "[{\"end\":4564,\"start\":4556},{\"end\":4709,\"start\":4701},{\"end\":36240,\"start\":36232},{\"end\":37091,\"start\":37083},{\"end\":37233,\"start\":37225},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":37775,\"start\":37767},{\"end\":38512,\"start\":38504},{\"end\":38725,\"start\":38717},{\"end\":38890,\"start\":38882},{\"end\":39102,\"start\":39094},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":43758,\"start\":43750}]", "bib_author_first_name": "[{\"end\":55412,\"start\":55405},{\"end\":55424,\"start\":55420},{\"end\":55432,\"start\":55430},{\"end\":55445,\"start\":55440},{\"end\":55456,\"start\":55451},{\"end\":55466,\"start\":55462},{\"end\":55668,\"start\":55663},{\"end\":55682,\"start\":55675},{\"end\":55694,\"start\":55688},{\"end\":55710,\"start\":55702},{\"end\":55718,\"start\":55715},{\"end\":55928,\"start\":55924},{\"end\":55942,\"start\":55934},{\"end\":55952,\"start\":55947},{\"end\":55967,\"start\":55958},{\"end\":56198,\"start\":56196},{\"end\":56209,\"start\":56203},{\"end\":56224,\"start\":56216},{\"end\":56237,\"start\":56231},{\"end\":56252,\"start\":56246},{\"end\":56506,\"start\":56499},{\"end\":56517,\"start\":56511},{\"end\":56772,\"start\":56764},{\"end\":56781,\"start\":56777},{\"end\":56793,\"start\":56788},{\"end\":57025,\"start\":57019},{\"end\":57044,\"start\":57034},{\"end\":57362,\"start\":57358},{\"end\":57376,\"start\":57370},{\"end\":57391,\"start\":57383},{\"end\":57401,\"start\":57397},{\"end\":57410,\"start\":57406},{\"end\":57423,\"start\":57416},{\"end\":57437,\"start\":57430},{\"end\":57448,\"start\":57442},{\"end\":57460,\"start\":57455},{\"end\":57468,\"start\":57461},{\"end\":57804,\"start\":57800},{\"end\":57816,\"start\":57812},{\"end\":57827,\"start\":57821},{\"end\":57840,\"start\":57835},{\"end\":57854,\"start\":57848},{\"end\":57866,\"start\":57861},{\"end\":57880,\"start\":57872},{\"end\":58188,\"start\":58185},{\"end\":58414,\"start\":58410},{\"end\":58434,\"start\":58426},{\"end\":58446,\"start\":58440},{\"end\":58703,\"start\":58696},{\"end\":58717,\"start\":58710},{\"end\":58732,\"start\":58723},{\"end\":58745,\"start\":58739},{\"end\":58992,\"start\":58982},{\"end\":59005,\"start\":58999},{\"end\":59181,\"start\":59175},{\"end\":59345,\"start\":59343},{\"end\":59357,\"start\":59351},{\"end\":59366,\"start\":59363},{\"end\":59375,\"start\":59372},{\"end\":59386,\"start\":59380},{\"end\":59624,\"start\":59620},{\"end\":59635,\"start\":59629},{\"end\":59647,\"start\":59640},{\"end\":59910,\"start\":59904},{\"end\":60154,\"start\":60147},{\"end\":60172,\"start\":60163},{\"end\":60436,\"start\":60433},{\"end\":60445,\"start\":60442},{\"end\":60696,\"start\":60691},{\"end\":60705,\"start\":60703},{\"end\":60912,\"start\":60904},{\"end\":60924,\"start\":60919},{\"end\":60939,\"start\":60931},{\"end\":60950,\"start\":60946},{\"end\":60961,\"start\":60956},{\"end\":61139,\"start\":61133},{\"end\":61153,\"start\":61146},{\"end\":61155,\"start\":61154},{\"end\":61166,\"start\":61160},{\"end\":61178,\"start\":61175},{\"end\":61188,\"start\":61185},{\"end\":61487,\"start\":61484},{\"end\":61497,\"start\":61493},{\"end\":61513,\"start\":61505},{\"end\":61523,\"start\":61519},{\"end\":61534,\"start\":61528},{\"end\":61546,\"start\":61541},{\"end\":61821,\"start\":61816},{\"end\":61831,\"start\":61826},{\"end\":61844,\"start\":61836},{\"end\":62072,\"start\":62069},{\"end\":62083,\"start\":62077},{\"end\":62097,\"start\":62090},{\"end\":62254,\"start\":62246},{\"end\":62264,\"start\":62260},{\"end\":62276,\"start\":62272},{\"end\":62287,\"start\":62281},{\"end\":62299,\"start\":62294},{\"end\":62310,\"start\":62305},{\"end\":62318,\"start\":62311},{\"end\":62638,\"start\":62630},{\"end\":62648,\"start\":62644},{\"end\":62657,\"start\":62653},{\"end\":62669,\"start\":62665},{\"end\":62682,\"start\":62675},{\"end\":62922,\"start\":62913},{\"end\":62935,\"start\":62927},{\"end\":63181,\"start\":63175},{\"end\":63194,\"start\":63188},{\"end\":63204,\"start\":63201},{\"end\":63211,\"start\":63209},{\"end\":63228,\"start\":63220},{\"end\":63417,\"start\":63412},{\"end\":63428,\"start\":63424},{\"end\":63787,\"start\":63780},{\"end\":63800,\"start\":63793},{\"end\":63932,\"start\":63925},{\"end\":63944,\"start\":63937},{\"end\":64214,\"start\":64206},{\"end\":64226,\"start\":64219},{\"end\":64460,\"start\":64455},{\"end\":64472,\"start\":64468},{\"end\":64483,\"start\":64478},{\"end\":64491,\"start\":64489},{\"end\":64778,\"start\":64771},{\"end\":64793,\"start\":64786},{\"end\":64801,\"start\":64799},{\"end\":64813,\"start\":64807},{\"end\":65026,\"start\":65018},{\"end\":65037,\"start\":65033},{\"end\":65049,\"start\":65043},{\"end\":65057,\"start\":65054},{\"end\":65071,\"start\":65064}]", "bib_author_last_name": "[{\"end\":55418,\"start\":55413},{\"end\":55428,\"start\":55425},{\"end\":55438,\"start\":55433},{\"end\":55449,\"start\":55446},{\"end\":55460,\"start\":55457},{\"end\":55471,\"start\":55467},{\"end\":55673,\"start\":55669},{\"end\":55686,\"start\":55683},{\"end\":55700,\"start\":55695},{\"end\":55713,\"start\":55711},{\"end\":55722,\"start\":55719},{\"end\":55932,\"start\":55929},{\"end\":55945,\"start\":55943},{\"end\":55956,\"start\":55953},{\"end\":55972,\"start\":55968},{\"end\":56201,\"start\":56199},{\"end\":56214,\"start\":56210},{\"end\":56229,\"start\":56225},{\"end\":56244,\"start\":56238},{\"end\":56255,\"start\":56253},{\"end\":56509,\"start\":56507},{\"end\":56525,\"start\":56518},{\"end\":56775,\"start\":56773},{\"end\":56786,\"start\":56782},{\"end\":56798,\"start\":56794},{\"end\":57032,\"start\":57026},{\"end\":57056,\"start\":57045},{\"end\":57368,\"start\":57363},{\"end\":57381,\"start\":57377},{\"end\":57395,\"start\":57392},{\"end\":57404,\"start\":57402},{\"end\":57414,\"start\":57411},{\"end\":57428,\"start\":57424},{\"end\":57440,\"start\":57438},{\"end\":57453,\"start\":57449},{\"end\":57474,\"start\":57469},{\"end\":57810,\"start\":57805},{\"end\":57819,\"start\":57817},{\"end\":57833,\"start\":57828},{\"end\":57846,\"start\":57841},{\"end\":57859,\"start\":57855},{\"end\":57870,\"start\":57867},{\"end\":57887,\"start\":57881},{\"end\":58194,\"start\":58189},{\"end\":58424,\"start\":58415},{\"end\":58438,\"start\":58435},{\"end\":58449,\"start\":58447},{\"end\":58454,\"start\":58451},{\"end\":58708,\"start\":58704},{\"end\":58721,\"start\":58718},{\"end\":58737,\"start\":58733},{\"end\":58750,\"start\":58746},{\"end\":58997,\"start\":58993},{\"end\":59013,\"start\":59006},{\"end\":59188,\"start\":59182},{\"end\":59349,\"start\":59346},{\"end\":59361,\"start\":59358},{\"end\":59370,\"start\":59367},{\"end\":59378,\"start\":59376},{\"end\":59390,\"start\":59387},{\"end\":59627,\"start\":59625},{\"end\":59638,\"start\":59636},{\"end\":59653,\"start\":59648},{\"end\":59918,\"start\":59911},{\"end\":59923,\"start\":59920},{\"end\":60161,\"start\":60155},{\"end\":60186,\"start\":60173},{\"end\":60440,\"start\":60437},{\"end\":60449,\"start\":60446},{\"end\":60701,\"start\":60697},{\"end\":60710,\"start\":60706},{\"end\":60917,\"start\":60913},{\"end\":60929,\"start\":60925},{\"end\":60944,\"start\":60940},{\"end\":60954,\"start\":60951},{\"end\":60970,\"start\":60962},{\"end\":61144,\"start\":61140},{\"end\":61158,\"start\":61156},{\"end\":61173,\"start\":61167},{\"end\":61183,\"start\":61179},{\"end\":61191,\"start\":61189},{\"end\":61491,\"start\":61488},{\"end\":61503,\"start\":61498},{\"end\":61517,\"start\":61514},{\"end\":61526,\"start\":61524},{\"end\":61539,\"start\":61535},{\"end\":61550,\"start\":61547},{\"end\":61824,\"start\":61822},{\"end\":61834,\"start\":61832},{\"end\":61849,\"start\":61845},{\"end\":62075,\"start\":62073},{\"end\":62088,\"start\":62084},{\"end\":62101,\"start\":62098},{\"end\":62258,\"start\":62255},{\"end\":62270,\"start\":62265},{\"end\":62279,\"start\":62277},{\"end\":62292,\"start\":62288},{\"end\":62303,\"start\":62300},{\"end\":62324,\"start\":62319},{\"end\":62642,\"start\":62639},{\"end\":62651,\"start\":62649},{\"end\":62663,\"start\":62658},{\"end\":62673,\"start\":62670},{\"end\":62685,\"start\":62683},{\"end\":62925,\"start\":62923},{\"end\":62940,\"start\":62936},{\"end\":63186,\"start\":63182},{\"end\":63199,\"start\":63195},{\"end\":63207,\"start\":63205},{\"end\":63218,\"start\":63212},{\"end\":63231,\"start\":63229},{\"end\":63422,\"start\":63418},{\"end\":63434,\"start\":63429},{\"end\":63791,\"start\":63788},{\"end\":63804,\"start\":63801},{\"end\":63935,\"start\":63933},{\"end\":63949,\"start\":63945},{\"end\":64217,\"start\":64215},{\"end\":64230,\"start\":64227},{\"end\":64466,\"start\":64461},{\"end\":64476,\"start\":64473},{\"end\":64487,\"start\":64484},{\"end\":64495,\"start\":64492},{\"end\":64784,\"start\":64779},{\"end\":64797,\"start\":64794},{\"end\":64805,\"start\":64802},{\"end\":64816,\"start\":64814},{\"end\":65031,\"start\":65027},{\"end\":65041,\"start\":65038},{\"end\":65052,\"start\":65050},{\"end\":65062,\"start\":65058},{\"end\":65077,\"start\":65072}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":235658226},\"end\":55633,\"start\":55351},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":52825543},\"end\":55864,\"start\":55635},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":160030052},\"end\":56134,\"start\":55866},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":237420672},\"end\":56415,\"start\":56136},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":9124261},\"end\":56681,\"start\":56417},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":211043589},\"end\":56955,\"start\":56683},{\"attributes\":{\"id\":\"b6\"},\"end\":57252,\"start\":56957},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":235306079},\"end\":57724,\"start\":57254},{\"attributes\":{\"id\":\"b8\"},\"end\":58080,\"start\":57726},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":222278687},\"end\":58343,\"start\":58082},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":220730113},\"end\":58605,\"start\":58345},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":235792329},\"end\":58938,\"start\":58607},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":52127932},\"end\":59136,\"start\":58940},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":209315300},\"end\":59268,\"start\":59138},{\"attributes\":{\"id\":\"b14\"},\"end\":59548,\"start\":59270},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":209501162},\"end\":59812,\"start\":59550},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":143424179},\"end\":60074,\"start\":59814},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":207178809},\"end\":60334,\"start\":60076},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":119181611},\"end\":60606,\"start\":60336},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":39847715},\"end\":60848,\"start\":60608},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":220513062},\"end\":61131,\"start\":60850},{\"attributes\":{\"doi\":\"arXiv:2006.04768\",\"id\":\"b21\"},\"end\":61409,\"start\":61133},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":246828747},\"end\":61728,\"start\":61411},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":13709505},\"end\":62010,\"start\":61730},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":53219431},\"end\":62244,\"start\":62012},{\"attributes\":{\"doi\":\"arXiv:2204.12200\",\"id\":\"b25\"},\"end\":62574,\"start\":62246},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":235792434},\"end\":62833,\"start\":62576},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":199465865},\"end\":63101,\"start\":62835},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":237431172},\"end\":63410,\"start\":63103},{\"attributes\":{\"doi\":\"arXiv:2205.00976\",\"id\":\"b29\"},\"end\":63719,\"start\":63412},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":220045418},\"end\":63923,\"start\":63721},{\"attributes\":{\"id\":\"b31\"},\"end\":64114,\"start\":63925},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":231632459},\"end\":64382,\"start\":64116},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":220264982},\"end\":64702,\"start\":64384},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":224281062},\"end\":64967,\"start\":64704},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":57572904},\"end\":65234,\"start\":64969}]", "bib_title": "[{\"end\":55403,\"start\":55351},{\"end\":55661,\"start\":55635},{\"end\":55922,\"start\":55866},{\"end\":56194,\"start\":56136},{\"end\":56497,\"start\":56417},{\"end\":56762,\"start\":56683},{\"end\":57356,\"start\":57254},{\"end\":58183,\"start\":58082},{\"end\":58408,\"start\":58345},{\"end\":58694,\"start\":58607},{\"end\":58980,\"start\":58940},{\"end\":59173,\"start\":59138},{\"end\":59618,\"start\":59550},{\"end\":59902,\"start\":59814},{\"end\":60145,\"start\":60076},{\"end\":60431,\"start\":60336},{\"end\":60689,\"start\":60608},{\"end\":60902,\"start\":60850},{\"end\":61482,\"start\":61411},{\"end\":61814,\"start\":61730},{\"end\":62067,\"start\":62012},{\"end\":62628,\"start\":62576},{\"end\":62911,\"start\":62835},{\"end\":63173,\"start\":63103},{\"end\":63778,\"start\":63721},{\"end\":64204,\"start\":64116},{\"end\":64453,\"start\":64384},{\"end\":64769,\"start\":64704},{\"end\":65016,\"start\":64969}]", "bib_author": "[{\"end\":55420,\"start\":55405},{\"end\":55430,\"start\":55420},{\"end\":55440,\"start\":55430},{\"end\":55451,\"start\":55440},{\"end\":55462,\"start\":55451},{\"end\":55473,\"start\":55462},{\"end\":55675,\"start\":55663},{\"end\":55688,\"start\":55675},{\"end\":55702,\"start\":55688},{\"end\":55715,\"start\":55702},{\"end\":55724,\"start\":55715},{\"end\":55934,\"start\":55924},{\"end\":55947,\"start\":55934},{\"end\":55958,\"start\":55947},{\"end\":55974,\"start\":55958},{\"end\":56203,\"start\":56196},{\"end\":56216,\"start\":56203},{\"end\":56231,\"start\":56216},{\"end\":56246,\"start\":56231},{\"end\":56257,\"start\":56246},{\"end\":56511,\"start\":56499},{\"end\":56527,\"start\":56511},{\"end\":56777,\"start\":56764},{\"end\":56788,\"start\":56777},{\"end\":56800,\"start\":56788},{\"end\":57034,\"start\":57019},{\"end\":57058,\"start\":57034},{\"end\":57370,\"start\":57358},{\"end\":57383,\"start\":57370},{\"end\":57397,\"start\":57383},{\"end\":57406,\"start\":57397},{\"end\":57416,\"start\":57406},{\"end\":57430,\"start\":57416},{\"end\":57442,\"start\":57430},{\"end\":57455,\"start\":57442},{\"end\":57476,\"start\":57455},{\"end\":57812,\"start\":57800},{\"end\":57821,\"start\":57812},{\"end\":57835,\"start\":57821},{\"end\":57848,\"start\":57835},{\"end\":57861,\"start\":57848},{\"end\":57872,\"start\":57861},{\"end\":57889,\"start\":57872},{\"end\":58196,\"start\":58185},{\"end\":58426,\"start\":58410},{\"end\":58440,\"start\":58426},{\"end\":58451,\"start\":58440},{\"end\":58456,\"start\":58451},{\"end\":58710,\"start\":58696},{\"end\":58723,\"start\":58710},{\"end\":58739,\"start\":58723},{\"end\":58752,\"start\":58739},{\"end\":58999,\"start\":58982},{\"end\":59015,\"start\":58999},{\"end\":59190,\"start\":59175},{\"end\":59351,\"start\":59343},{\"end\":59363,\"start\":59351},{\"end\":59372,\"start\":59363},{\"end\":59380,\"start\":59372},{\"end\":59392,\"start\":59380},{\"end\":59629,\"start\":59620},{\"end\":59640,\"start\":59629},{\"end\":59655,\"start\":59640},{\"end\":59920,\"start\":59904},{\"end\":59925,\"start\":59920},{\"end\":60163,\"start\":60147},{\"end\":60188,\"start\":60163},{\"end\":60442,\"start\":60433},{\"end\":60451,\"start\":60442},{\"end\":60703,\"start\":60691},{\"end\":60712,\"start\":60703},{\"end\":60919,\"start\":60904},{\"end\":60931,\"start\":60919},{\"end\":60946,\"start\":60931},{\"end\":60956,\"start\":60946},{\"end\":60972,\"start\":60956},{\"end\":61146,\"start\":61133},{\"end\":61160,\"start\":61146},{\"end\":61175,\"start\":61160},{\"end\":61185,\"start\":61175},{\"end\":61193,\"start\":61185},{\"end\":61493,\"start\":61484},{\"end\":61505,\"start\":61493},{\"end\":61519,\"start\":61505},{\"end\":61528,\"start\":61519},{\"end\":61541,\"start\":61528},{\"end\":61552,\"start\":61541},{\"end\":61826,\"start\":61816},{\"end\":61836,\"start\":61826},{\"end\":61851,\"start\":61836},{\"end\":62077,\"start\":62069},{\"end\":62090,\"start\":62077},{\"end\":62103,\"start\":62090},{\"end\":62260,\"start\":62246},{\"end\":62272,\"start\":62260},{\"end\":62281,\"start\":62272},{\"end\":62294,\"start\":62281},{\"end\":62305,\"start\":62294},{\"end\":62326,\"start\":62305},{\"end\":62644,\"start\":62630},{\"end\":62653,\"start\":62644},{\"end\":62665,\"start\":62653},{\"end\":62675,\"start\":62665},{\"end\":62687,\"start\":62675},{\"end\":62927,\"start\":62913},{\"end\":62942,\"start\":62927},{\"end\":63188,\"start\":63175},{\"end\":63201,\"start\":63188},{\"end\":63209,\"start\":63201},{\"end\":63220,\"start\":63209},{\"end\":63233,\"start\":63220},{\"end\":63424,\"start\":63412},{\"end\":63436,\"start\":63424},{\"end\":63793,\"start\":63780},{\"end\":63806,\"start\":63793},{\"end\":63937,\"start\":63925},{\"end\":63951,\"start\":63937},{\"end\":64219,\"start\":64206},{\"end\":64232,\"start\":64219},{\"end\":64468,\"start\":64455},{\"end\":64478,\"start\":64468},{\"end\":64489,\"start\":64478},{\"end\":64497,\"start\":64489},{\"end\":64786,\"start\":64771},{\"end\":64799,\"start\":64786},{\"end\":64807,\"start\":64799},{\"end\":64818,\"start\":64807},{\"end\":65033,\"start\":65018},{\"end\":65043,\"start\":65033},{\"end\":65054,\"start\":65043},{\"end\":65064,\"start\":65054},{\"end\":65079,\"start\":65064}]", "bib_venue": "[{\"end\":55478,\"start\":55473},{\"end\":55731,\"start\":55724},{\"end\":55984,\"start\":55974},{\"end\":56261,\"start\":56257},{\"end\":56537,\"start\":56527},{\"end\":56805,\"start\":56800},{\"end\":57017,\"start\":56957},{\"end\":57480,\"start\":57476},{\"end\":57798,\"start\":57726},{\"end\":58198,\"start\":58196},{\"end\":58461,\"start\":58456},{\"end\":58757,\"start\":58752},{\"end\":59025,\"start\":59015},{\"end\":59194,\"start\":59190},{\"end\":59341,\"start\":59270},{\"end\":59662,\"start\":59655},{\"end\":59930,\"start\":59925},{\"end\":60191,\"start\":60188},{\"end\":60455,\"start\":60451},{\"end\":60716,\"start\":60712},{\"end\":60977,\"start\":60972},{\"end\":61257,\"start\":61209},{\"end\":61556,\"start\":61552},{\"end\":61856,\"start\":61851},{\"end\":62110,\"start\":62103},{\"end\":62388,\"start\":62342},{\"end\":62692,\"start\":62687},{\"end\":62947,\"start\":62942},{\"end\":63243,\"start\":63233},{\"end\":63545,\"start\":63452},{\"end\":63809,\"start\":63806},{\"end\":64008,\"start\":63951},{\"end\":64235,\"start\":64232},{\"end\":64525,\"start\":64497},{\"end\":64822,\"start\":64818},{\"end\":65089,\"start\":65079}]"}}}, "year": 2023, "month": 12, "day": 17}