{"id": 53234493, "updated": "2023-09-29 17:28:45.254", "metadata": {"title": "GIDS: GAN based Intrusion Detection System for In-Vehicle Network", "authors": "[{\"first\":\"Eunbi\",\"last\":\"Seo\",\"middle\":[]},{\"first\":\"Hyun\",\"last\":\"Song\",\"middle\":[\"Min\"]},{\"first\":\"Huy\",\"last\":\"Kim\",\"middle\":[\"Kang\"]}]", "venue": "In 2018 16th Annual Conference on Privacy, Security and Trust (PST), pp. 1-6. IEEE, 2018", "journal": null, "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "A Controller Area Network (CAN) bus in the vehicles is an efficient standard bus enabling communication between all Electronic Control Units (ECU). However, CAN bus is not enough to protect itself because of lack of security features. To detect suspicious network connections effectively, the intrusion detection system (IDS) is strongly required. Unlike the traditional IDS for Internet, there are small number of known attack signatures for vehicle networks. Also, IDS for vehicle requires high accuracy because any false-positive error can seriously affect the safety of the driver. To solve this problem, we propose a novel IDS model for in-vehicle networks, GIDS (GAN based Intrusion Detection System) using deep-learning model, Generative Adversarial Nets. GIDS can learn to detect unknown attacks using only normal data. As experiment result, GIDS shows high detection accuracy for four unknown attacks.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1907.07377", "mag": "3105105644", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-1907-07377", "doi": "10.1109/pst.2018.8514157"}}, "content": {"source": {"pdf_hash": "0490fe87e008605fbcfdafbea904d4678752ba5d", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1907.07377v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1907.07377", "status": "GREEN"}}, "grobid": {"id": "ad0317314d02462cfc8a65a1a75a94955b7d1f4e", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/0490fe87e008605fbcfdafbea904d4678752ba5d.txt", "contents": "\nGIDS: GAN BASED INTRUSION DETECTION SYSTEM FOR IN-VEHICLE NETWORK A PREPRINT\nJuly 18, 2019\n\nEunbi Seo \nGraduate School of Information Security\nGraduate School of Information Security\nKorea University Seoul\nRepublic of Korea\n\nHyun Min Song \nGraduate School of Information Security\nKorea University Seoul\nRepublic of Korea\n\nHuy Kang \nKorea University Seoul\nRepublic of Korea\n\nKim \nKorea University Seoul\nRepublic of Korea\n\nGIDS: GAN BASED INTRUSION DETECTION SYSTEM FOR IN-VEHICLE NETWORK A PREPRINT\nJuly 18, 2019Generative Adversarial Nets \u00b7 Intrusion detection System \u00b7 Controller Area Network \u00b7 In-Vehicle Security\nA Controller Area Network (CAN) bus in the vehicles is an efficient standard bus enabling communication between all Electronic Control Units (ECU). However, CAN bus is not enough to protect itself because of lack of security features. To detect suspicious network connections effectively, the intrusion detection system (IDS) is strongly required. Unlike the traditional IDS for Internet, there are small number of known attack signatures for vehicle networks. Also, IDS for vehicle requires high accuracy because any false-positive error can seriously affect the safety of the driver. To solve this problem, we propose a novel IDS model for in-vehicle networks, GIDS (GAN based Intrusion Detection System) using deep-learning model, Generative Adversarial Nets. GIDS can learn to detect unknown attacks using only normal data. As experiment result, GIDS shows high detection accuracy for four unknown attacks.\n\nIntroduction\n\nThe advances in the automotive technology have brought great convenience to driver's life. However, as V2X technology enables interactions with vehicles and everything from outside (e.g., vehicles, infrastructure), security threats on ECU of vehicles become higher. Therefore, we need to develop a security system to mitigate the various risks of the vehicle. In particular, intrusion detection system (IDS) for in-vehicle network is required to protect all of the ECUs and related equipment in the vehicle from emerging threats.\n\nController Area Network (CAN) is a standard of the bus system for in-vehicle network and provides efficient communication between ECUs. CAN bus is a reliable and economical serial bus for the in-vehicle network. However, because it uses a broadcast communication without authentication, attackers can access CAN bus easily, and it causes severe risk. For example, an adversary could inject a malicious packet in CAN bus via a vulnerability at one of the numerous external interfaces Also, many modern cars which have a communication module for infotainment service can be exposed to the attacks via Over-The-Air (OTA) update module. These attacks could result in not only serious malfunctions of the vehicle but also threats to the safety of drivers.\n\n\narXiv:1907.07377v1 [cs.CR] 17 Jul 2019\n\nIDS is the best way to detect and respond known and unknown attacks of today because it can continuously monitor the in-vehicle system and detect suspicious network events generated by ECUs in real time. Recently, there has been some research for IDS to detect attacks targeted on the vehicles. For example, Song et al. proposed a detection model based on time interval analysis of CAN data [1], and Lee et al. presented a method to detect intrusion by monitoring the time interval of the request and response of CAN data [2].\n\nAlthough these models are lightweight and efficient, they have some limitations. When in-vehicle environments are changed, it can require a lot of updates. Also, targets to be detected may be limited since specific attacks are reflected when constructing detection system. If IDS be leaked to the attacker, the attacker can manipulate and avoid detection.\n\nTo solve these problems, we propose GIDS (Generative Adversarial Nets based Intrusion Detection System) which has the following characteristics: expandability, effectiveness, and security.\n\n1. Expandability: GIDS maintains consistent detection methodology even if in-vehicle environments are changed.\n\nIt requires only one training process. 2. Effectiveness: Because GIDS can be trained using only normal data, it GIDS can detect intrusions without being limited to specific types of attacks. Thus, GIDS is likely to detect unknown attacks not used in the implementation process of the IDS. 3. Security: GIDS is one of the deep-learning model which has the characteristic of black-box. Thus,it is difficult for an attacker to manipulate internal structure of detection system.\n\n\nOrganization of This Paper\n\nWe introduced in-vehicle networks and IDS for in-vehicle network in \u00a71. The rest of the paper is organized as follows. \u00a72 presents the recent researches. We introduce our IDS, GIDS in \u00a73. In \u00a74, we describe the result of the experiment and discuss the experiment result. Finally we conclude the paper in \u00a75.\n\n\nRelated works\n\nThe early research for anomaly detection of the in-vehicle system was introduced by Hoppe et al. [3]. He presented three selected characteristics as patterns available for anomaly detection that include the recognition of an increased frequency of cyclic CAN messages, the observation of low-level communication characteristics, and the identification of obvious misuse of message IDs. M\u00fcter et al. proposed an anomaly detection based entropy [4]. Marchetti et al. analyzed and identified anomalies in the sequence of CAN [5]. The proposed model features low memory and computational footprints. SALMAN et al. proposed a software-based light-weight IDS and two anomaly-based algorithms based on message cycle time analysis and plausibility analysis of messages [6]. It contributed to more advanced research in the field of IDS for in-vehicle networks.\n\nMany security research in various fields has adopted deep-learning methods for IDS. For example, Zhang et al. presented a deep-learning method to detect Web attacks by using the specially designed CNN [7]. The method is based on analyzing the HTTP request packets, to which only some preprocessing is needed whereas the tedious feature extraction is done by the CNN itself. Recently, Generative Adversarial Nets (GAN) was adopted to not only image generation but also other research like anomaly detection. Schlegl et al. proposed AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability. The model demonstrated that the approach correctly identifies anomalous images, such as images containing retinal fluid [8].\n\nAlthough various studies using GAN have been published, most of them are focused only on discrimination of image data. GAN could be useful for security such as IDS. However, few works have explored the use of GAN for security of other fields. We developed a GAN based IDS for in-vehicle security and showed high performance on CAN data that is one of the in-vehicle network datasets. We proved expandability, effectiveness, and security of the proposed model for in-vehicle networks.  Fig. 1. Also, we converted extracted CAN IDs into a simple image by encoding with one-hot-vector. This method can reduce detection time required for real-time, and improve the performance of IDS.    In this study, we propose GAN based IDS model for the in-vehicle network. We named this model as GIDS. GAN is one of the deep-learning models. GAN is the new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G [9]. GAN  is often used to generate fake images that are similar to real ones. We focused on the fact and designed our IDS using this fact. GIDS has two discriminative model, the first discriminator and the second discriminator which are trained with the following procedure as shown in Fig. 3. 1. Training for known attack: the First discriminator receives normal CAN images and abnormal CAN images which are extracted from the actual vehicle. Because the first discriminator uses attack data in the training process, the type of attacks that can be detected is likely to be limited to the attacks used for training. 2. Training for unknown attack: The generator G and the second discriminator are trained simultaneously by an adversarial process. The generator generates fake images by using random noise. The second discriminator receives normal CAN images and the fake images generated by the generator and estimates the probability that received images are real CAN images. That is, the second discriminator discriminates whether input images are real CAN images or fake images generated by the generator. The generator and the second discriminator compete with each other and increase their performance. In the GIDS model, the second discriminator ultimately win the generator so that the second discriminator can detect even fake images similar to real CAN images.\n\nGIDS detects attacks of the in-vehicle networks with the following procedure as shown in Fig. 4.\n\n1. The real-time CAN data is encoded with one-hot-vector, and it is converted into CAN images.\n\n2. The first discriminator receives CAN images and outputs one value which is between 0 and 1.\n\n3. If output is lower than the threshold, current status is classified as abnormal. (Because the first discriminator is trained for known attacks, unknown attacks are unlikely to be detected in this process.) 4. If output is higher than the threshold, the corresponding CAN images are received by the second discriminator.\n\nAs in step 2 and step 3, the second discriminator receives CAN images and outputs one value which is between 0 and 1. 5. If output is lower than the threshold, current status is classified as abnormal. (Because the second discriminator is trained with only normal data, attack data to be detected are not limited. That is, it may even be possible to detect unknown attacks.)\n\nOur goal is to ensure high accuracy for detecting even unpredictable attacks with only normal data. However, if we use only the second discriminator trained with only normal data, the detection accuracy can be lower than when using the first discriminator trained with attack data. Therefore, we combine the first discriminator and the second discriminator, which is able to detect both known attacks and unknown attacks.\n\n\nDesign of Neural Networks\n\nIn the chapter, we describe two model structures of the discriminator and the generator in the GIDS model. We measured the detection performance for four combinations of discriminator and generator composed of the convolutional neural network (CNN) and deep neural network (DNN). The neural networks of GIDS was selected as the combination which are shown the best detection performance.\n\n\nDesign the discriminator\n\nThe discriminator consists of a deep neural network composed of three layers as shown in Fig. 5 (b). The discriminator reduces the dimension of the input data to one output between 0 and 1. Fig. 5 (b) shows the   \n\n\nExperiment and Result\n\n\nExperiment Environment\n\nIn the Experiment, we use two criteria: Detection rate and accuracy. The detection rate is defined as the proportion of the detected abnormal data accounting for the total abnormal ones. The accuracy is defined as the proportion of data including normal and abnormal to be correctly classified. We tested the GIDS model in the following experiment environment. \n\n\nAttack Design and Dataset\n\nHyundai's YF Sonata is used as a testing vehicle. To capture CAN bus traffic, we plug Y-cable into OBD-II port; OBD-II port of YF Sonata is located under the steering wheel. Then, Raspberry Pi3 is used to connect to CAN bus. Also, a laptop computer is connected to Raspberry Pi3 through WiFi as shown in Fig. 7.\n\nWe launched four types of attacks on CAN bus as illustrated in Fig. 6. Each attack is defined as follows.\n\n1. DoS attack: Dos attack is to inject high priority of CAN messages (e.g. '0x000' CAN ID packet) in a short cycle. We injected 'messages of '0x000' CAN ID every 0.3 milliseconds. 3. RPM/GEAR attack: RPM/GEAR attack is to inject messages of certain CAN ID related to RPM/GEAR information. We injected messages related to RPM/GEAR every 1 millisecond.\n\nAfter data acquisition, we did labeling for the captured attack-free state traffic and attack traffic data. We released the dataset used in our experiments to foster further research. We make our dataset available at http://ocslab.hksecurity.net/Datasets/CAN-intrusion-dataset. Table 1 shows dataset which was used to test our model. The dataset consists of the training dataset and test dataset. The dataset was extracted from the running vehicle for about 10 minutes and contains both normal and abnormal packet with labeling. In Table 1, '#CAN message' means the total number of CAN packets including abnormal and normal ones during the attacks. '#Attack image' means the only total number of the CAN images containing at least one abnormal CAN packet. Each dataset in Table 1 is independent of each other and not a multi-class.  \n\n\nEvaluating One-hot-vector Encoding\n\nWe converted the CAN data extracted from the vehicle into simple form images by encoding them with one-hot-vector. Fig. 9 shows the images generated by this way, and Fig. 10 shows the images not encoded with the one-hot-vector; All CAN IDs of 11 bits are converted into an image. In both Fig. 9 and Fig. 10, the left image is real CAN image and the right image is fake CAN image generated by the generator. Fig. 9 shows more simple form whereas Fig. 10 shows complex form.\n\nEncoding with one-hot-vector can reduce the required time and show better performance than when the binary CAN data are converted as it is. Fig. 8 shows the distribution of the output of GIDS before and after one-hot-vector encoding. In the left model which uses binary images as it is, the output is widely distributed from 0 to 1. On the other hand, as shown in the right model, GIDS model using images converted with one-hot-vector has a certain threshold to classify normal data and abnormal data. That is, one-hot-vector encoding allows the intrusion detection model to separate normal data and attack data explicitly. \n\n\nHyperparameters\n\nBased on the experiment, we set some hyperparameters of the GIDS model, which can improve the detection performance of the GIDS model. GIDS shows different performance according to values of these parameters. Parameters consist of detection threshold, attack threshold, and input size. We found the most suitable values of parameters through experiments and applied it to the final GIDS model. We present experimental results for each parameter as follows.\n\n\nDetection threshold:\n\nThe outputs of GIDS model are 0 to 1. Among these outputs, GIDS classify attack data and normal data by a specific detection threshold. We define detection threshold as 0.1. If the output of the GIDS model is less than 0.1, it is judged to an anomaly. Although some outputs in the normal data were distributed below 0.1 as in Fig. 8(b), it may be regarded as an error that can appear in the sampling process. 2. Input size: Input size means a unit to convert CAN IDs into images. CAN IDs extracted from the vehicle are grouped by input size and they are converted into images. We measured the accuracy of the GIDS model, increasing the input size from a minimum of 32 to a maximum of 128. Experimental results showed that the accuracy increased until 64 input size, but it tended to decrease after that as shown in Fig. 11. Therefore, we define an input size as 64, and it can be changed flexibly depending on the vehicle environment. Figure 11: Accuracy of GIDS according to input size 3. Attack threshold: The attack threshold is a criterion for judging attack CAN images. We define attack threshold as 1. That is, if at least one attack packet is included in the CAN image, it is judged to be an abnormal image. We improve the security of the GIDS model by detecting even occasionally injected abnormal packets. \n\n\nExperiment Result\n\nFirstly, we tested the accuracy of the first discriminator which is trained using known attack data. Table 2 shows the detection rates of first discriminator for each attack data. As results of the experiment, attack data used in the training process were detected well but attack data not used for training were hardly detected. It requires a new detection model that can detect attacks even if only normal data are used in the training process.\n\nSecondly, we tested the detection accuracy of the second discriminator which uses random fake data in the training process instead of the real attack data. Table 3 shows the detection performance for each of the four attack data. Any attacks in the Table 3 were not used in the training process of the second discriminator. As results of the experiment, each of the four attacks was detected with an average of 98% accuracy. Although the accuracy is less than 100%, we can improve the accuracy of the GIDS model by combining it with first discriminator which uses attack data for the training process. \n\n\nConclusion\n\nIn this study, we presented the GIDS, GAN based IDS for the in-vehicle network. Firstly, we proposed encoding a large number of CAN IDs with simple one-hot-vector, which can increase the performance and speed of the GIDS. Also, the proposed GIDS uses random fake data in the training process instead of the real attack data. It allows the GIDS model to detect unknown attacks with only normal data. Finally, we proposed a detection system that combines the first discriminator for detecting known attack data and the second discriminator for detecting unknown attack data. It can improve the detection accuracy of the proposed GIDS model. As a result of the experiment, The GIDS showed the average accuracy of 100% for the first discriminator and the average accuracy of 98% for the second discriminator.\n\nGIDS can be applied to the various types of the vehicle through the new training process and adjustment of the hyperparameters. Because the GIDS is pre-trained system and uses the deep-learning method, it is difficult to be manipulated by the attacker. Also, it can be real-time intrusion detection for the in-vehicle network. In practically, the number of messages that CAN bus system generates per second is about 1,954. GIDS takes only 0.18 seconds to detect about 1,954 CAN messages and it has a constant ratio of elapsed time for intrusion detection even if the amount of CAN data to be detected increases.\n\nThe proposed GIDS model has the strengths of expandability, effectiveness, and security so it can be suitable IDS for the in-vehicle network.\n\n\nDiscussion\n\nAlthough GAN based IDS describes the CAN network traffic well, it is still challenging point to distinguish anomalous traffic caused from 'normal malfunctioning of electronic components' from anomalous traffic caused from 'intentional attacks by hacker'. Nonetheless, GAN based IDS is still effective under the circumstance of lack of 'known attack patterns for vehicles' such as nowadays. GAN based IDS and its evaluation becomes more precise as many attack patterns for vehicles become revealed.\n\nFigure 1 :\n1Structure of CAN frame Fig. 2 shows the process of encoding CAN IDs with one-hot-vector. Firstly, because the CAN ID is hexadecimal, each element of the CAN ID such as '2' in '0x2a0' is expressed in a binary form with 16 digits. After that, binary forms of each element of the CAN IDs are encoded to one-hot-vector. Encoding with one-hot-vector makes one of the bits to be 1, and the remaining bits to be all 0. For example, if the element of the CAN ID is '2' in '0x2a0', A one-hot-vector consists of only one bit of the second digit as 1 and the remaining all bits as 0. Finally, a CAN ID of 3-digit such as '0x2a0' is expressed in 16*3 matrix form. For example, if the CAN ID is '0x2a0', it consists of 3 one-hot-vectors such as [0100 ... 000], [0..0100000], and [0..1000000]. We name this matrix as a 'CAN image'.\n\nFigure 2 :\n2The process of one-hot-vector encoding\n\nFigure 3 :\n3The training process of GIDS\n\nFigure 4 :\n4The process of one-hot-vector encoding\n\n( a )Figure 5 :\na5Architecture of generator in GIDS (b) Architecture of discriminator in GIDS Architecture of GIDS\n\nFigure 6 :\n6Illustration of DoS, FUZZY and RPM/GEAR attacks process of reduction dimension of the discriminator when the number of CAN IDs is 64. The activation function of each layer is ReLU, and the activation function of the last layer is sigmoid. Finally, the output of the discriminator is used to distinguish between normal status and abnormal status in the in-vehicle network.2. Design the generator The generator consists of a deconvolutional neural network composed of five layers as shown in 5 (a). The generator expands the dimension of random noise data to the one image of the same size as the input data of the discriminator. That is, the generator generates a fake image similar to the real CAN image converted from the CAN IDs. ReLU is used by the activation function of each layer, and Tanh is used as activation function of the last layer. The generator and the discriminator calculate the cost through back-propagation reducing the errors between actual answers and outputs of the model.\n\nFigure 7 :\n7Data acquisition setup via OBD-II port of YF sonata with Raspberry Pi3 2. FUZZY attack: Fuzzy attack is to inject messages of spoofed random CAN ID and DATA values. We injected messages of CAN ID and CAN data every 0.5 milliseconds.\n\nFigure 8 :\n8Distribution of the output before and after one-hot-vector encoding\n\nFigure 9 Figure 10 :\n910Image samples not encoded with one-hot-vector\n\n\ntime CAN data generated by ECUs are must be able to be processed. If all the bits of CAN data are used directly for image conversion, the converted image can be very complex. In the case, GIDS may require a long time not suitable for real-time detection. CAN IDs in CAN data show repetitive patterns and we extracted only patterns of CAN IDs from CAN data for training as in3 GIDS: GAN based IDS \n\n3.1 Converting CAN Data to Image \n\nCAN bus supports the ECU to ECU communication. In CAN bus, there are frequent transmissions composed of \nperiodically used CAN messages. ECUs in the vehicle generate about 2,000 CAN data per second to CAN bus. A large \namount of real-\n\n\nEx. FUZZY attack dataTraining for Known Attackoutput \n\n\u2026 \n\n[ normal CAN data image ] \n\n2nd D \n\nG \n\n[ random data ] \n\n\u2026 \n\n[ fake CAN data image ] \n\n\u2026 \n\nback \npropagation \n\nback \npropagation \n\nTraining for Unknown Attack \n\n\u2026 \n\n[ abnormal CAN data image ] \n\n\u2026 \n\n[ normal CAN data image ] \n\n1st D \n\noutput \n\nback \npropagation \n\n\n\nTable 1 :\n1Data type and sizeData \nAttack type \n#CAN message #Attack image \nTraining set \nNormal data \n1,171,637 \nN/A \n\nTest set \n\nDoS attack data \n3,665,771 \n17,128 \nFUZZY attack data \n3,838,860 \n20,317 \nRPM attack data \n4,621,702 \n32,501 \nGEAR attack data \n4,443,142 \n29,751 \n\n(a) binary image density \n(b) GIDS image density \n\n\n\nTable 2 :\n2Detection rate of the first discriminator in GIDS according to attack data of training set training set DoS detection rate FUZZY detection rate RPM detection rate GEAR detection rate Normality detection rateDoS \n99.9% \n0.0% \n0.0% \n0.0% \n99.9% \nFUZZY \n2.0% \n98.7% \n33.0% \n1.9% \n100.0% \nRPM \n0.0% \n0.0% \n99.6% \n0.0% \n100.0% \nGEAR \n0.0% \n0.9% \n0.0% \n99.8% \n99.6% \n\n\n\nTable 3 :\n3Performance of the second discriminator in GIDSData type \nDetection rate Precision Accuracy AUC \nDoS attack \n99.6% \n96.8% \n97.9% 0.999 \nFUZZY attack \n99.5% \n97.3% \n98.0% 0.999 \nRPM attack \n99.0% \n98.3% \n98.0% 0.999 \nGEAR attack \n96.5% \n98.1% \n96.2% 0.996 \n\n\nAcknowledgment\nIntrusion detection system based on the analysis of time intervals of can messages for in-vehicle network. H M Song, H R Kim, H K Kim, Information Networking (ICOIN), 2016 International Conference on. IEEEH. M. Song, H. R. Kim, and H. K. Kim, \"Intrusion detection system based on the analysis of time intervals of can messages for in-vehicle network,\" in Information Networking (ICOIN), 2016 International Conference on. IEEE, 2016, pp. 63-68.\n\nOtids: A novel intrusion detection system for in-vehicle network by using remote frame. H Lee, S H Jeong, H K Kim, H. Lee, S. H. Jeong, and H. K. Kim, \"Otids: A novel intrusion detection system for in-vehicle network by using remote frame.\"\n\nSecurity threats to automotive can networks-practical examples and selected short-term countermeasures. T Hoppe, S Kiltz, J Dittmann, Computer Safety, Reliability, and Security. T. Hoppe, S. Kiltz, and J. Dittmann, \"Security threats to automotive can networks-practical examples and selected short-term countermeasures,\" Computer Safety, Reliability, and Security, pp. 235-248, 2008.\n\nEntropy-based anomaly detection for in-vehicle networks. M M\u00fcter, N Asaj, Intelligent Vehicles Symposium (IV). IEEEM. M\u00fcter and N. Asaj, \"Entropy-based anomaly detection for in-vehicle networks,\" in Intelligent Vehicles Sympo- sium (IV), 2011 IEEE. IEEE, 2011, pp. 1110-1115.\n\nAnomaly detection of can bus messages through analysis of id sequences. M Marchetti, D Stabili, Intelligent Vehicles Symposium (IV. M. Marchetti and D. Stabili, \"Anomaly detection of can bus messages through analysis of id sequences,\" in Intelligent Vehicles Symposium (IV), 2017 IEEE. IEEE, 2017, pp. 1577-1583.\n\nDesign and implementation of an intrusion detection system (ids) for in-vehicle networks. N Salman, M Bresch, N. SALMAN and M. BRESCH, \"Design and implementation of an intrusion detection system (ids) for in-vehicle networks.\"\n\nA deep learning method to detect web attacks using a specially designed cnn. M Zhang, B Xu, S Bai, S Lu, Z Lin, International Conference on Neural Information Processing. SpringerM. Zhang, B. Xu, S. Bai, S. Lu, and Z. Lin, \"A deep learning method to detect web attacks using a specially designed cnn,\" in International Conference on Neural Information Processing. Springer, 2017, pp. 828-836.\n\nUnsupervised anomaly detection with generative adversarial networks to guide marker discovery. T Schlegl, P Seeb\u00f6ck, S M Waldstein, U Schmidt-Erfurth, G Langs, International Conference on Information Processing in Medical Imaging. SpringerT. Schlegl, P. Seeb\u00f6ck, S. M. Waldstein, U. Schmidt-Erfurth, and G. Langs, \"Unsupervised anomaly detection with generative adversarial networks to guide marker discovery,\" in International Conference on Information Processing in Medical Imaging. Springer, 2017, pp. 146-157.\n\nGenerative adversarial nets. I Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A Courville, Y Bengio, Advances in neural information processing systems. I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, \"Generative adversarial nets,\" in Advances in neural information processing systems, 2014, pp. 2672-2680.\n", "annotations": {"author": "[{\"end\":225,\"start\":93},{\"end\":322,\"start\":226},{\"end\":374,\"start\":323},{\"end\":421,\"start\":375}]", "publisher": null, "author_last_name": "[{\"end\":102,\"start\":99},{\"end\":239,\"start\":235},{\"end\":331,\"start\":327}]", "author_first_name": "[{\"end\":98,\"start\":93},{\"end\":230,\"start\":226},{\"end\":234,\"start\":231},{\"end\":326,\"start\":323},{\"end\":378,\"start\":375}]", "author_affiliation": "[{\"end\":224,\"start\":104},{\"end\":321,\"start\":241},{\"end\":373,\"start\":333},{\"end\":420,\"start\":380}]", "title": "[{\"end\":77,\"start\":1},{\"end\":498,\"start\":422}]", "venue": null, "abstract": "[{\"end\":1527,\"start\":617}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3261,\"start\":3258},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3392,\"start\":3389},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4984,\"start\":4981},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5330,\"start\":5327},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5409,\"start\":5406},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5648,\"start\":5645},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5941,\"start\":5938},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6505,\"start\":6502},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7643,\"start\":7640}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":20073,\"start\":19243},{\"attributes\":{\"id\":\"fig_1\"},\"end\":20125,\"start\":20074},{\"attributes\":{\"id\":\"fig_2\"},\"end\":20167,\"start\":20126},{\"attributes\":{\"id\":\"fig_4\"},\"end\":20219,\"start\":20168},{\"attributes\":{\"id\":\"fig_5\"},\"end\":20335,\"start\":20220},{\"attributes\":{\"id\":\"fig_6\"},\"end\":21343,\"start\":20336},{\"attributes\":{\"id\":\"fig_7\"},\"end\":21589,\"start\":21344},{\"attributes\":{\"id\":\"fig_8\"},\"end\":21670,\"start\":21590},{\"attributes\":{\"id\":\"fig_9\"},\"end\":21741,\"start\":21671},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":22411,\"start\":21742},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":22738,\"start\":22412},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":23070,\"start\":22739},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":23445,\"start\":23071},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":23715,\"start\":23446}]", "paragraph": "[{\"end\":2072,\"start\":1543},{\"end\":2824,\"start\":2074},{\"end\":3393,\"start\":2867},{\"end\":3750,\"start\":3395},{\"end\":3940,\"start\":3752},{\"end\":4052,\"start\":3942},{\"end\":4528,\"start\":4054},{\"end\":4866,\"start\":4559},{\"end\":5735,\"start\":4884},{\"end\":6506,\"start\":5737},{\"end\":9011,\"start\":6508},{\"end\":9109,\"start\":9013},{\"end\":9205,\"start\":9111},{\"end\":9301,\"start\":9207},{\"end\":9625,\"start\":9303},{\"end\":10001,\"start\":9627},{\"end\":10424,\"start\":10003},{\"end\":10841,\"start\":10454},{\"end\":11083,\"start\":10870},{\"end\":11495,\"start\":11134},{\"end\":11836,\"start\":11525},{\"end\":11943,\"start\":11838},{\"end\":12295,\"start\":11945},{\"end\":13130,\"start\":12297},{\"end\":13641,\"start\":13169},{\"end\":14267,\"start\":13643},{\"end\":14743,\"start\":14287},{\"end\":16083,\"start\":14768},{\"end\":16551,\"start\":16105},{\"end\":17155,\"start\":16553},{\"end\":17974,\"start\":17170},{\"end\":18587,\"start\":17976},{\"end\":18730,\"start\":18589},{\"end\":19242,\"start\":18745}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":12582,\"start\":12575},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":12836,\"start\":12829},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":13076,\"start\":13069},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":16213,\"start\":16206},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":16716,\"start\":16709},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":16809,\"start\":16802}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1541,\"start\":1529},{\"end\":2865,\"start\":2827},{\"attributes\":{\"n\":\"1.1\"},\"end\":4557,\"start\":4531},{\"attributes\":{\"n\":\"2\"},\"end\":4882,\"start\":4869},{\"attributes\":{\"n\":\"3.2\"},\"end\":10452,\"start\":10427},{\"attributes\":{\"n\":\"1.\"},\"end\":10868,\"start\":10844},{\"attributes\":{\"n\":\"4\"},\"end\":11107,\"start\":11086},{\"attributes\":{\"n\":\"4.1\"},\"end\":11132,\"start\":11110},{\"attributes\":{\"n\":\"4.2\"},\"end\":11523,\"start\":11498},{\"attributes\":{\"n\":\"4.3\"},\"end\":13167,\"start\":13133},{\"attributes\":{\"n\":\"4.4\"},\"end\":14285,\"start\":14270},{\"attributes\":{\"n\":\"1.\"},\"end\":14766,\"start\":14746},{\"attributes\":{\"n\":\"4.5\"},\"end\":16103,\"start\":16086},{\"attributes\":{\"n\":\"5\"},\"end\":17168,\"start\":17158},{\"attributes\":{\"n\":\"5.1\"},\"end\":18743,\"start\":18733},{\"end\":19254,\"start\":19244},{\"end\":20085,\"start\":20075},{\"end\":20137,\"start\":20127},{\"end\":20179,\"start\":20169},{\"end\":20236,\"start\":20221},{\"end\":20347,\"start\":20337},{\"end\":21355,\"start\":21345},{\"end\":21601,\"start\":21591},{\"end\":21692,\"start\":21672},{\"end\":22749,\"start\":22740},{\"end\":23081,\"start\":23072},{\"end\":23456,\"start\":23447}]", "table": "[{\"end\":22411,\"start\":22118},{\"end\":22738,\"start\":22460},{\"end\":23070,\"start\":22769},{\"end\":23445,\"start\":23290},{\"end\":23715,\"start\":23505}]", "figure_caption": "[{\"end\":20073,\"start\":19256},{\"end\":20125,\"start\":20087},{\"end\":20167,\"start\":20139},{\"end\":20219,\"start\":20181},{\"end\":20335,\"start\":20239},{\"end\":21343,\"start\":20349},{\"end\":21589,\"start\":21357},{\"end\":21670,\"start\":21603},{\"end\":21741,\"start\":21696},{\"end\":22118,\"start\":21744},{\"end\":22460,\"start\":22414},{\"end\":22769,\"start\":22751},{\"end\":23290,\"start\":23083},{\"end\":23505,\"start\":23458}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6999,\"start\":6993},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":7934,\"start\":7927},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":9108,\"start\":9102},{\"end\":10969,\"start\":10959},{\"end\":11070,\"start\":11060},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":11835,\"start\":11829},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":11907,\"start\":11901},{\"end\":13290,\"start\":13284},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13342,\"start\":13335},{\"end\":13463,\"start\":13457},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13475,\"start\":13468},{\"end\":13582,\"start\":13576},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13621,\"start\":13614},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":13789,\"start\":13783},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":15103,\"start\":15094},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15590,\"start\":15583},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15712,\"start\":15703}]", "bib_author_first_name": "[{\"end\":23839,\"start\":23838},{\"end\":23841,\"start\":23840},{\"end\":23849,\"start\":23848},{\"end\":23851,\"start\":23850},{\"end\":23858,\"start\":23857},{\"end\":23860,\"start\":23859},{\"end\":24265,\"start\":24264},{\"end\":24272,\"start\":24271},{\"end\":24274,\"start\":24273},{\"end\":24283,\"start\":24282},{\"end\":24285,\"start\":24284},{\"end\":24523,\"start\":24522},{\"end\":24532,\"start\":24531},{\"end\":24541,\"start\":24540},{\"end\":24861,\"start\":24860},{\"end\":24870,\"start\":24869},{\"end\":25153,\"start\":25152},{\"end\":25166,\"start\":25165},{\"end\":25485,\"start\":25484},{\"end\":25495,\"start\":25494},{\"end\":25700,\"start\":25699},{\"end\":25709,\"start\":25708},{\"end\":25715,\"start\":25714},{\"end\":25722,\"start\":25721},{\"end\":25728,\"start\":25727},{\"end\":26112,\"start\":26111},{\"end\":26123,\"start\":26122},{\"end\":26134,\"start\":26133},{\"end\":26136,\"start\":26135},{\"end\":26149,\"start\":26148},{\"end\":26168,\"start\":26167},{\"end\":26561,\"start\":26560},{\"end\":26575,\"start\":26574},{\"end\":26592,\"start\":26591},{\"end\":26601,\"start\":26600},{\"end\":26607,\"start\":26606},{\"end\":26623,\"start\":26622},{\"end\":26632,\"start\":26631},{\"end\":26645,\"start\":26644}]", "bib_author_last_name": "[{\"end\":23846,\"start\":23842},{\"end\":23855,\"start\":23852},{\"end\":23864,\"start\":23861},{\"end\":24269,\"start\":24266},{\"end\":24280,\"start\":24275},{\"end\":24289,\"start\":24286},{\"end\":24529,\"start\":24524},{\"end\":24538,\"start\":24533},{\"end\":24550,\"start\":24542},{\"end\":24867,\"start\":24862},{\"end\":24875,\"start\":24871},{\"end\":25163,\"start\":25154},{\"end\":25174,\"start\":25167},{\"end\":25492,\"start\":25486},{\"end\":25502,\"start\":25496},{\"end\":25706,\"start\":25701},{\"end\":25712,\"start\":25710},{\"end\":25719,\"start\":25716},{\"end\":25725,\"start\":25723},{\"end\":25732,\"start\":25729},{\"end\":26120,\"start\":26113},{\"end\":26131,\"start\":26124},{\"end\":26146,\"start\":26137},{\"end\":26165,\"start\":26150},{\"end\":26174,\"start\":26169},{\"end\":26572,\"start\":26562},{\"end\":26589,\"start\":26576},{\"end\":26598,\"start\":26593},{\"end\":26604,\"start\":26602},{\"end\":26620,\"start\":26608},{\"end\":26629,\"start\":26624},{\"end\":26642,\"start\":26633},{\"end\":26652,\"start\":26646}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":9333718},\"end\":24174,\"start\":23731},{\"attributes\":{\"id\":\"b1\"},\"end\":24416,\"start\":24176},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":7830197},\"end\":24801,\"start\":24418},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":9017380},\"end\":25078,\"start\":24803},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":25832817},\"end\":25392,\"start\":25080},{\"attributes\":{\"id\":\"b5\"},\"end\":25620,\"start\":25394},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":39712173},\"end\":26014,\"start\":25622},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":17427022},\"end\":26529,\"start\":26016},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1033682},\"end\":26916,\"start\":26531}]", "bib_title": "[{\"end\":23836,\"start\":23731},{\"end\":24520,\"start\":24418},{\"end\":24858,\"start\":24803},{\"end\":25150,\"start\":25080},{\"end\":25697,\"start\":25622},{\"end\":26109,\"start\":26016},{\"end\":26558,\"start\":26531}]", "bib_author": "[{\"end\":23848,\"start\":23838},{\"end\":23857,\"start\":23848},{\"end\":23866,\"start\":23857},{\"end\":24271,\"start\":24264},{\"end\":24282,\"start\":24271},{\"end\":24291,\"start\":24282},{\"end\":24531,\"start\":24522},{\"end\":24540,\"start\":24531},{\"end\":24552,\"start\":24540},{\"end\":24869,\"start\":24860},{\"end\":24877,\"start\":24869},{\"end\":25165,\"start\":25152},{\"end\":25176,\"start\":25165},{\"end\":25494,\"start\":25484},{\"end\":25504,\"start\":25494},{\"end\":25708,\"start\":25699},{\"end\":25714,\"start\":25708},{\"end\":25721,\"start\":25714},{\"end\":25727,\"start\":25721},{\"end\":25734,\"start\":25727},{\"end\":26122,\"start\":26111},{\"end\":26133,\"start\":26122},{\"end\":26148,\"start\":26133},{\"end\":26167,\"start\":26148},{\"end\":26176,\"start\":26167},{\"end\":26574,\"start\":26560},{\"end\":26591,\"start\":26574},{\"end\":26600,\"start\":26591},{\"end\":26606,\"start\":26600},{\"end\":26622,\"start\":26606},{\"end\":26631,\"start\":26622},{\"end\":26644,\"start\":26631},{\"end\":26654,\"start\":26644}]", "bib_venue": "[{\"end\":23930,\"start\":23866},{\"end\":24262,\"start\":24176},{\"end\":24594,\"start\":24552},{\"end\":24912,\"start\":24877},{\"end\":25210,\"start\":25176},{\"end\":25482,\"start\":25394},{\"end\":25791,\"start\":25734},{\"end\":26245,\"start\":26176},{\"end\":26703,\"start\":26654}]"}}}, "year": 2023, "month": 12, "day": 17}