{"id": 247761951, "updated": "2023-10-06 05:14:44.77", "metadata": {"title": "A Benchmark and Comprehensive Survey on Knowledge Graph Entity Alignment via Representation Learning", "authors": "[{\"first\":\"Rui\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Bayu\",\"last\":\"Trisedy\",\"middle\":[\"Distiawan\"]},{\"first\":\"Miao\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Yong\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Jianzhong\",\"last\":\"Qi\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "In the last few years, the interest in knowledge bases has grown exponentially in both the research community and the industry due to their essential role in AI applications. Entity alignment is an important task for enriching knowledge bases. This paper provides a comprehensive tutorial-type survey on representative entity alignment techniques that use the new approach of representation learning. We present a framework for capturing the key characteristics of these techniques, propose two datasets to address the limitation of existing benchmark datasets, and conduct extensive experiments using the proposed datasets. The framework gives a clear picture of how the techniques work. The experiments yield important results about the empirical performance of the techniques and how various factors affect the performance. One important observation not stressed by previous work is that techniques making good use of attribute triples and relation predicates as features stand out as winners.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2103.15059", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/vldb/ZhangTLJQ22", "doi": "10.1007/s00778-022-00747-z"}}, "content": {"source": {"pdf_hash": "76abca3cc5c6478d50d176019eceea84bf3e0581", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2103.15059v5.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "c46395ec514f040ca197e6811118671b8f981c55", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/76abca3cc5c6478d50d176019eceea84bf3e0581.txt", "contents": "\nA Benchmark and Comprehensive Survey on Knowledge Graph Entity Alignment via Representation Learning\n\n\nRui Zhang \nBayu Distiawan \nTrisedya \u00b7 Miao miao4@student.unimelb.edu.au \nLi \nYong Jiang jiangy@mail.sz.tsinghua.edu.cn \nJianzhong Qi jianzhong.qi@unimelb.edu.au \nRui Zhang \nBayu Distiawan Trisedya \nJianzhong Qi \nMiao Li \nYong Jiang \n\nThe University of Melbourne\nTsinghua University\n\n\n\nIntroduction\n\n\nA Benchmark and Comprehensive Survey on Knowledge Graph Entity Alignment via Representation Learning\nReceived: date / Accepted: dateNoname manuscript No. (will be inserted by the editor)knowledge graph \u00b7 entity alignment \u00b7 knowledge graph alignment \u00b7 knowledge base \u00b7 representation learning \u00b7 deep learning \u00b7 embedding \u00b7 graph neural networks \u00b7 graph convolutional networks\nIn the last few years, the interest in knowledge bases has grown exponentially in both the research community and the industry due to their essential role in AI applications. Entity alignment is an important task for enriching knowledge bases. This paper provides a comprehensive tutorial-type survey on representative entity alignment techniques that use the new approach of representation learning. We present a framework for capturing the key characteristics of these techniques, propose a benchmark addressing the limitation of existing benchmark datasets, and conduct extensive experiments using our benchmark. The framework gives a clear picture of how various techniques work. The experiments yield important results about the empirical performance of the techniques and how various factors affect the performance. One important observation not stressed by previous work is that techniques making good use of attribute triples and relation predicates as features stand out as winners. We are also the first to investigate the question of how to perform entity alignments on large scale knowledge graphs such as the full Wikidata and Freebase (in Experiment 5).\n\nIntroduction\n\nKnowledge bases are a technology used to store complex structured and unstructured information, typically facts or knowledge. A knowledge graph (KG), which is a knowledge base modeled by a graph structure or topology, is the most popular form of knowledge bases and has almost become a synonym of knowledge base today. There have been continuous research and development on KGs for several decades due to their significance in systems that involve reasoning based on knowledge and facts. Example KGs include open-source ones such as DBpedia [Auer et al., 2007], Freebase [Bollacker et al., 2008], YAGO [Hoffart et al., 2013], as well as proprietary ones such as those developed by Google [Dong et al., 2014] and Microsoft [F\u00e4rber, 2019]. In the last few years, there has been an explosive growth of interest in KGs in both the research community and the industry due to their essential role in AI applications such as natural language processing (including dialogue systems/chatbots, question answering, sentence generation, etc.) [Wu et al., 2018;Xu et al., 2019b;Yang et al., 2020bYang et al., , 2021Trisedya et al., 2018Trisedya et al., , 2021, search engines [Kathuria et al., 2016], recommendation systems [Zhang et al., 2016], and information extraction [Du et al., 2015;Trisedya et al., 2019b].\n\nOne of the most important tasks for KGs is entity alignment (EA), which aims to identify entities from different KGs that represent the same real-world entity. EA enables enrichment of a KG from another complementary one, hence improving the quality and coverage of the KG, which is critical for downstream applications. Different KGs may be created via different sources and methods, so even entities representing the same real-world entity may be denoted differently in different KGs, and it is challenging to identify all such arXiv:2103.15059v5 [cs.AI] 6 May 2022 aligned entities accurately. Figure 1  ple of EA on two KGs G 1 and G 2 (each in a dashed-line rectangle), which are tiny subsets from two real publicly available KGs, Wikidata and DBpedia, respectively. The rounded rectangles represent entities and the rectangles represent attribute values. An arrow between rounded rectangles indicates a relation predicate, which forms a relation triple, e.g., (dbp:Victoria, country, dbp:Australia). An arrow between a rounded rectangle and a rectangle indicates an attribute predicate, which forms an attribute triple, e.g., (dbp:Victoria, total area, \"237,659 km 2 \"). We can see that the same real-world entity may have different surface forms in the two KGs such as Q36687 v.s. dbp:Victoria. The two KGs have complementary information about this entity: G 1 has information about its premier and G 2 has information about its capital. The information about this entity can be enriched if we can determine that Q36687 in G 1 refers to the same real-world entity as dbp:Victoria in G 2 , i.e., Q36687 and dbp:Victoria are aligned entities. EA between G 1 and G 2 is to find all the pairs of aligned entities from the two KGs. In this example, there are two pairs of aligned entities Q36687, dbp:Victoria and Q408, dbp:Australia .\n\nTraditional EA techniques use data mining or database approaches, typically heuristics, to identify similar entities. The accuracy of such approaches are limited, and heuristics are difficult to generalize. In the past several years, a very large number of studies on EA take the new approach of deep learning to learn effective vector representation (i.e., embeddings) of the KG and then performing EA based on the learned representation, which achieve much better accuracy. They also have better generalizability as they rarely rely on ad hoc heuristics. In the rest of this paper, by saying embedding-based EA techniques or simply EA techniques, we refer to those taking this new representation learning approach rather than traditional approaches unless explicitly specified otherwise. There are a few recent experimental studies aiming at benchmarking EA techniques [Sun et al., 2020b;Zhao et al., 2020;Zhang et al., 2020]. They have high-level discussions on frameworks for embedding-based techniques and summarize a good range of EA papers, but their focus is on experimental comparison, but without self-contained explanation on each technique. Moreover, the frameworks discussed in those papers miss important mechanisms such as the use of semantic information of KGs (e.g., strings of relation predicates, attribute predicates and attribute values), making those frameworks inapplicable to many EA techniques, especially the latest ones. In comparison to the aforementioned studies, this paper fills the void and make the following contributions:\n\n\u2022 We provide a comprehensive tutorial-type survey to help readers understand how each technique works with little need to refer to individual full papers.\n\n\u2022 We provide a comprehensive framework that accommodates almost all the embedding-based EA techniques, capturing their key components, strategies and characteristics. We also comparatively analyze different techniques in reference to the framework.\n\n\u2022 We identify significant limitations of existing benchmark datasets such as bijection, lack of name variety, and small scale (detailed in Section 7.1). To address these limitations, we devise a benchmark 1 that complement the existing collection of benchmark datasets. Further, we conduct an extensive experimental study comparing the performance of the state-of-the-art techniques on our datasets.\n\nThe rest of the paper is organized as follows. Section 2 provides preliminaries, including problem formulation and a summary on traditional EA techniques. We present our framework for EA techniques in Section 3. Section 4 covers KG structure embedding models, mainly translation-based and graph-neuralnetwork-based embedding, which are the foundation of embedding-based EA techniques. Sections 5 and 6 survey the most representative EA techniques based on the two major KG structure embeddings, respectively. Section 7 discusses the limitations of existing datasets, presents our proposed new datasets, and reports an extensive experimental study using our datasets. Section 8 concludes the paper and discusses future directions.\n\n\nPreliminaries\n\nNotation and Terminology. Many different notation and terminology conventions have been used in different papers in the literature. In this paper, we make a great effort at a standard notation and terminology convention that provides clarity and is consistent with as many existing papers as possible. The terminology will be seen throughout the paper as various terms are introduced, and the frequently used symbols in our notation convention are summarized in Table 1. We use bold lowercase (e.g., e), bold uppercase (e.g., M ) and math calligraphy (e.g., E) to denote vectors, matrices, and sets, respectively.\n\nIn the literature, a method proposed by a paper may have been referred to by different terms such as model, approach, technique, algorithm, method, etc.; we primarily use the term technique in this paper, while other terms might be used when the semantics are clear.\n\n\nProblem Formulation\n\nWe first introduce some notation. A KG denoted as G = (E, R, A, V, T ), consisting of a set of entities E, a set of relation predicates R, a set of attribute predicates A, and a set of attribute values V, represents knowledge in the form of a set of triples T . There are two types of triples, relation triples (denoted by T r ) in the form of (h, r, t) and attribute triples (denoted by T a ) in the form of (e, a, v); T = T r \u222a T a . A relation triple (h, r, t) indicates a relation predicate r between two entities, a head entity h and a tail entity t, where h, t \u2208 E and r \u2208 R. Take a triple in Fig 1 as an example: (dbp:Victoria, country, dbp:Australia). Here, dbp:Victoria. and dbp:Australia are the head entity and tail entity, respectively, and county is the relation predicate. An attribute triple (e, a, v) indicates that an entity e \u2208 E has the attribute value of v \u2208 V for the attribute (predicate) a \u2208 A. For example, in (dbp:Victoria, total area, \"237,659 km 2 \"), total area is the attribute predicate and \"237,659 km 2 \" is the attribute value.\n\nThe problem of EA is formulated as follows.\n\nDefinition 1 Entity Alignment (EA)\nGiven two KGs G 1 = (E 1 , R 1 , A 1 , V 1 , T 1 ) and G 2 = (E 2 , R 2 , A 2 , V 2 , T 2 )\n, EA aims to identify every pair of entities (e 1 , e 2 ), e 1 \u2208 E 1 , e 2 \u2208 E 2 , where e 1 and e 2 represent the same real-world entity (i.e., e 1 and e 2 are aligned entities).\n\n\nRelated Problems and Traditional Techniques\n\nRelated Problems. There have been research on various problems similar to EA on KGs. Both sources structured. Entity matching [Verykios et al., 2000;Qin et al., 2020], object identification [Tejada et al., 2001], and record linkage [Fellegi and Sunter, 1969] aim to align entities from two different relational databases, where both data sources are well structured. Solutions for these problems mostly find database records that are similar in terms of contents.\n\nOne source semi-structured and the other unstructured. Entity resolution [Bhattacharya and Getoor, 2006] and entity linking [Kulkarni et al., 2009] aim to match entity mentions from natural sentences, which are unstructured, to the corresponding entities in a KG, which is semi-structured. A KG is semi-structured because it consists of a graph (structured), and attributes and predicates, which are in the form of natural language or other un-predefined types (unstructured). Solutions for these problems mostly find database records that have similar contents to named entities recognized from natural sentences.\n\nIn comparison, EA on KGs aligns entities from two different KGs, both of which are semi-structured.\n\nTraditional Techniques for EA. Among traditional techniques for EA on KGs, some have focused on improving the effectiveness of the matching of entities via different entity similarity measures. For example, RDF-AI [Francois et al., 2009] uses fuzzy string matching based on sequence alignment, word relation, and taxonomic similarity. SILK [Julius et al., 2009] provides the Link Specification Language, which allows users to specify the similarity measures for comparing certain attributes. LD-Mapper [Raimond et al., 2008] combines string similarity and entity nearest neighbors. PARIS [Suchanek et al., 2011] includes schema matching (e.g., classes and sub-classes of entities) to compute the entity similarity. Some other traditional EA techniques focus on the efficiency of entity matching, e.g., LIMES [Ngomo and Auer, 2011] uses clustering to reduce the amount of similarity computation.\n\nTraditional EA techniques, as exemplified above, usually use data mining or database approaches, typically heuristics, to identify similar entities. It is difficult for them to achieve high accuracy and to generalize.\n\n\nGeneric Framework of Embedding-based EA\n\nWe provide a generic framework for embedding-based EA techniques to capture key components and strategies in Figure 2. The components drawn in dashed lines are optional. The approach of embedding-based EA typically consists of three components, an embedding module, an alignment module, and an inference module. The embedding module and the alignment module may be trained alternatively or jointly, and these two together compose the training modules for EA.\n\nEmbedding module. The embedding module aims to learn (typically low-dimensional) vector representations, i.e., embeddings of entities. There are four types of raw information that may be taken as input features to the embedding module: KG structure (in the form of relation triples in the raw KG data), relation predicates, attribute predicates and attribute values (attribute predicates and attribute values are grouped into one component \"Attributes\" in Figure 2 and the 5 th column in Table 2). The embedding module may produce as output the embeddings of entities, entity pairs, relation predicates, attributes, etc.; we refer to the process of \"encoding\" the input features into the targeted embeddings as KG embedding. Among all the possible input features, the KG structure is the most critical one. The machine learning model for embedding KG structure, which we simply term as the KG structure embedding model, serves as the skeleton of an EA technique, and other types of information may be optionally added to the KG structure embedding model to create a more sophisticated KG embedding. Note that the other types of information (i.e., relation predicates, attribute predicates, and attribute values) are usually in the form of strings and hence contain rich semantic information, which may greatly benefit EA as we will see. The KG structure embedding model mostly follows one of two paradigms, translation-based and GNNbased. Translation-based models mainly utilize relation triples while GNN-based models mainly utilize the neighborhood of entities. How relation triples are utilized in the translation-based models and how the neighborhood of entities is utilized in the GNN-based models are detailed in Sections 4.1 and 4.2, respectively.\n\nRelation predicates and attribute predicates may be encoded as categorical values or strings. Attribute values are usually encoded as strings.\n\nAlignment module. The embedding module computes the embeddings of each KG separately, which makes the embeddings of G 1 and G 2 fall into different vector spaces. The alignment module aims to unify the embeddings of the two KGs into the same vector space so that aligned entities can be identified, which is a major challenge for EA. EA techniques usually make use of a set of manually aligned entities, relation predicates, or attributes, called seed alignments, as input features to train the alignment module. The most common approach is using a set of seed entity alignments S = {(e 1 , e 2 )|e 1 \u2208 E 1 , e 2 \u2208 E 2 , e 1 \u2261 e 2 }. These seeds consist of pairs of entities (e 1 , e 2 ), where e 1 is an entity in E 1 and e 2 is an entity in E 2 . The seeds are used to compute a loss function for the embedding module to learn a unified vector space. A typical example of how the loss function may be defined is as follows:\nL = (e1,e2)\u2208S (e 1 ,e 2 )\u2208S max 0, \u03b3 + f align (e 1 , e 2 ) \u2212 f align (e 1 , e 2 )(1)\nwhere \u03b3 > 0 is a margin hyper-parameter. The above loss function is designed to minimize the distances between pairs of entities in the seed entity alignments S, and maximize the distances between the pairs of entities (e 1 , e 2 ) in corrupted seed alignments S , which are negative samples obtained by replacing an entity in the seed alignments with a random entity. Here, the distance between a pair of entities is computed by f align , which we call the alignment score function. It indicates how (dis)similar two entities are; the more the two entities are aligned (i.e., similar to each other), the smaller f align is. The most commonly used alignment score functions are cosine similarity, L 1 norm (i.e., Manhattan distance), and L 2 norm (i.e., Euclidean distance). We do not observe large difference in performance in our experiments when swapping these metrics (also note that L 2 norm and cosine similarity are equivalent). Some techniques customize the alignment score function to serve more sophisticated optimization goals such as Wang et al. [2018]. The function max(0, ) ensures that any negative margin loss values are not added to the total loss. Some techniques may exploit other types of seed alignments, including seed relation predicate alignments, seed attribute predicate alignments and seed attribute value alignments (seed attribute predicate alignments and seed attribute value alignments are grouped into one component \"Seed attribute alignment\" in Figure 2). Relation predicate and attribute predicate alignment are needed because the same predicate may be stored in different surface forms, e.g., one KG has the attribute predicate birth date while the other KG has the attribute predicate date of birth. The need for attribute value alignment is similar.\n\nNote that like the embedding module, the alignment module may also use the four types of raw information (KG structure, relation predicates, attribute predicates, and attribute values) besides seed alignments as features. Some EA techniques may use an unsupervised method to train the alignment module; e.g., AttrE [Trisedya et al., 2019a] exploits attribute triples to learn a unified attribute vector space, so manually labelled seed relation predicate/attribute alignments are not necessity, and we put parenthesis on the word \"seed\" for relation predicate alignments and attribute alignments in Figure 2. At least one input feature is required to train the alignment module, though.\n\nIn summary, the input features to the alignment module may be raw information such as KG structure, relation predicates, and attributes, as well as entity/relation/attribute alignments which may be created manually or automatically.\n\nBootstrapping is a common strategy when limited seed alignments are available. The idea is that those aligned entity/attribute/relation produced by the EA inference module are fed back to the alignment module as training data, and this process may be iterated multiple times. Note that creating seeds takes human effort, which is expensive. Bootstrapping may help reduce human effort but is at the cost of much more computation since it iterates training multiple times. From the summary in Table 2, we can see that bootstrapping is very popular among the translation-based techniques but not among the GNN-based techniques. Eight out of 15 translation-based techniques exploit bootstrapping, but only one out of 17 GNN-based technique exploits bootstrapping. The reason is that the GNN-based technique is better at capturing the relationships between entities in a graph compare to the translation-based techniques. Thus, the translation-based techniques use bootstrapping to improve their capability in capturing the entity relationships. However, we believe that bootstrapping is also helpful for GNN-based techniques, which may be investigated in future work.\n\nEA Inference module. This module aims to predict whether a pair of entities from G 1 and G 2 are aligned. In practice, almost all the techniques use the following alternative aim: given a target entity e 1 from G 1 , the EA inference module aims to predict an entity e 2 from G 2 that is aligned to e 1 ; we may call e 1 (e 2 ) the aligned entity or the counterpart entity of e 2 (e 1 ). The aligned entity may not exist if a similarity threshold is applied.\n\nThe most common approach for the inference module is nearest neighbor search (NNS), which finds the entity from G 2 that is the most similar to e 1 based on their embeddings obtained from the EA training module. Commonly used similarity measures include cosine similarity, Euclidean distance and Manhattan distance. When describing individual techniques later, we may omit the inference module if it uses this most common approach of NNS.\n\nThe NNS inference approach may incur many-toone alignment, where two different entities from a KG are aligned with the same entity from the other KG. To avoid it, some studies impose a one-to-one constraint.\n\nDiscussions. Table 2 summarizes representative EA techniques according to six key characteristics (the first row): KG structure embedding, KG structure, the way attributes used as input features, the way relation predicates used as input features, input features for the alignment module, and whether bootstrapping is used. Column 2 captures the paradigm of the embedding module. Columns 3 to 5 describe all the raw input features. Column 6 describes the input features of the alignment module. Early techniques make use of fewer types of information. For example, MTransE [Chen et al., 2017] only uses KG structure as features for the embedding module and seed relation triple alignments for the alignment module. Newer techniques such as At-trE [Trisedya et al., 2019a] and MultiKE  use all the four types of raw information as input features for training modules as well as various types of features for the alignment module. As our experimental study shows (cf. Table 5), techniques using more types of input features tend to have better performance.\n\nSome studies especially early ones regard whether a technique can perform EA on multilingual KGs or only on monolingual KGs as an important distinction. We argue that this is not an essential characteristic of EA techniques. The reason is that most recently proposed techniques make use of the semantic information of KGs such as the strings of relation predicates, attribute predicates and attribute values (cf. Table 2), and we can perform automatic translation on the semantic information into the target language so that both KGs are in the same language, and then conduct EA on monolingual KGs such as in JarKA . Our experimental study (Table 7) validates this.\n\n\nKG Structure Embedding Models\n\nWe review two paradigms of KG structure embedding, which underlie embedding-based EA techniques.\n\n\nTranslation-based Embedding Models\n\nThe essence of translation-based embedding models is treating a relation in KGs as a \"translation\" in a vector space between the head and the tail entities.\n\nTransE [Bordes et al., 2013] is the first translationbased embedding model, which embeds both entities and relations into a unified (typically low-dimensional) vector space. The main idea is that, if we can find a perfect suite of vector representations, i.e., embeddings, of entities and relation predicates, then for any relation triple (h, r, t), the corresponding embeddings h, r and t should satisfy the vector translation operation of h + r = t. For example, the embedding of Victoria plus the embedding of capital should equal the embedding of Melbourne. In other words, if we define the following function\nf triple (h, r, t) = ||h + r \u2212 t||(2)\nthen ideally this function should have the value of 0 for the embeddings of all the true relation triples. Equation 2 is called the triple score function, which measures the plausibility of a relation triple (the smaller the function value, the more likely (h, r, t) form a true relation triple). In reality, the embeddings of all the entities and relation predicates are unknown and need to be learned. Further there may well not exist a suite of embeddings such that f triple = 0 for all the relations. Therefore, the aim of learning becomes finding a suite of embeddings that minimize the sum of f triple for all the relations in a KG. To learn effectively, Bordes et al. [2013] use the strategy of negative sampling, i.e., for any (h , r , t ) that do not form a true relation triple, f triple (h , r , t ) should be a large value, e.g., (Victoria, capital, dog); these negative samples are called corrupted relation triples and are generated from true triples with either the head or the tail entity being replaced by a random entity. The learning process usually randomly initialize all the embeddings and then minimize a margin-loss based objective function below via gradient descent:\nL = (h,r,t)\u2208Tr (h ,r,t )\u2208T r max 0, \u03b3 + f triple (h, r, t) \u2212 f triple (h , r , t )(3)\nwhere \u03b3 > 0 is a margin hyper-parameter, T r is the set of true relation triples, and T r is a set of corrupted relation triples. After the seminal work of TransE, several variants of translation-based KG structure embedding models are proposed with improvements on the embedding space [Wang et al., 2014;Ji et al., 2015;Xiao et al., 2016b,a] or on the triple score function . Interested readers are referred to Wang et al. [2017] and Ji et al. [2020] for surveys on KG embedding models.\n\n\nGNN-based Embedding Models\n\nGraph neural networks (GNNs) have yielded strong performance on graph data analysis and gained immense popularity [Wu et al., 2021]. There are two representative models, namely graph convolutional networks (GCNs) [Kipf and Welling, 2017], and graph attention networks (GAT) [Velickovic et al., 2018], which will be detailed later. These two models are frequently used in recent KG embedding and EA studies because KGs Seed entity alignments -are of graph structure by nature. Unlike translationbased embedding models, which treats each triple separately, GNN-based embedding models focus on aggregating information from the neighborhood of entities together with the graph structure to compute entity embeddings. The essence of GNN-based embedding models is aggregating information from the neighborhood to a target node according to rules of message passing [Gilmer et al., 2017], i.e., the embedding information is propagated from neighbor entities to the target entity through the edges. The optimization goal of GNN-based embedding is to map entities with a similar neighborhood into embeddings close to each other in the embedding space. Graph Convolutional Networks (GCNs) [Kipf and Welling, 2017] compute a target node's embedding as a low-dimensional vector (i.e., embedding) by aggregating the features of its neighbors in addition to itself, following the rules of message passing in graphs. Specifically, a GCN is a multi-layer GNN denoted by a function f (X, A), where the inputs are feature vectors of a graph's nodes represented by a matrix X and the graph's adjacency matrix A. The element a ij \u2208 A indicates the connectivity between nodes i and j, and can be viewed as the weight of the edge between the two nodes. The features of the neighbors encoded as embeddings are passed on to the target node weighted by the edge weights. This message passing process is formulated as:\nQ (l+1) = \u03c3(D \u2212 1 2\u00c3D \u2212 1 2 Q (l) W (l) )(4)\nwhere W (l) is a learnable weight matrix in the l-th layer,\u00c3 = A + I is the adjacency matrix with selfconnections,D is a diagonal matrix of node degrees (D ii = j\u00c3 ij ),D \u2212 1 2\u00c3D \u2212 1 2 is the normalization of\u00c3 by node degrees, and Q (l+1) is the output of the l-th layer, which consists of the node embeddings computed by the GCN after l iterations. The input of the l-th layer is Q (l) , which in turn is the output of the previous layer. The node embeddings are usually initialized by the input matrix, i.e., Q (0) = X, and the final layer produces the final node embeddings learned by the GCN. Usually A is determined by the connectivity of the graph where 1 means connected and 0 means not; A may also be determined by heuristics such as the similarity between nodes and the values may be between 0 and 1. Once A is determined, it remains unchanged during the training which means that it is not learned.\n\nGraph Attention Networks (GAT) [Velickovic et al., 2018] aggregate information from neighborhood with the attention mechanism [Vaswani et al., 2017] and allows for focusing on the most relevant neighbors. Conceptually, GAT is similar to GCN in the sense that they both perform message passing to compute the node embeddings; the main difference is that the edge weights of GCNs (i.e., the adjacency matrix) are not learned but those of GAT (i.e., the attentions) are. Specifically, GAT is also a multi-layer GNN denoted by a function f (X) and the input X is the feature vectors of nodes. The output of the l-th layer is computed based on the attention mechanism as follows:\nq (l+1) i = \u03c3 j\u2208Ni \u03b1 ij W q l (j) (5) where W is a learnable weight matrix; Q (l+1) = q (l+1) 1 , q (l+1) 2 , ..., q (l+1) n\nis the output of the l-th layer; n is the number of the nodes; q (l+1) i is the node embedding of node i computed by the GAT after l iterations. The input of the l-th layer is Q (l) , which in turn is the output of the previous layer using Q (l\u22121) as input. The node embeddings are usually initialized by the input matrix, i.e., Q (0) = X, and the final layer produces the final node embeddings learned by the GAT. The attention weight \u03b1 ij is computed by a softmax normalization over attention coefficients:\n\u03b1 ij = exp(c ij ) k\u2208Ni exp(c ik )(6)\nwhere N i indicates the set of nodes in the neighborhood of node i. The attention coefficient c ij is the correlation between nodes, which is learned as follows:\nc ij = LeakyReLU w T [W q (l) i W q (l) j ](7)\nwhere the parameter vector w is used to transform the concatenation of two node embeddingss into a scalar. GAT applies multi-head attention as follows:\nq (l+1) i = K k=1 \u03c3 j\u2208Ni \u03b1 k ij W k q (l) j(8)\nwhere the output is the concatenation of K independent self-attentions with different normalized attention weight \u03b1 k ij and weight matrix W k . Variants. The two representative GNN models, GCN and GAT, have served as the foundation for more sophisticated models designed for various applications. Alternative symmetric matrices have been proposed to replace the adjacency matrix of GCNs (e.g., AGCN [Yuan et al., 2019] and DGCN [Zhuang and Ma, 2018]), and various ways of computing attention have been proposed for GAT. A comprehensive discussion on GNNs is given by Wu et al. [2021].\n\n\nTranslation-based EA Techniques\n\nThis section reviews representative translation-based EA techniques. We focus on the two key components, the embedding module determined by f triple , and the alignment module determined by f align . The KG embedding in translation-based EA techniques either use TransE [Bordes et al., 2013] directly or its variants, which encodes KG structure by relation triples, paths or neighborhood. We review the techniques that only use KG structure for their KG embedding in Section 5.1 and the techniques that exploit other types of information, i.e., relation predicates and attributes for their KG embedding in Section 5.2.\n\n\nTechniques that Only Use KG Structure\n\nMTransE [Chen et al., 2017] is the first translationbased model for embedding-based EA. Its embedding module uses TransE to embed the entities and relation predicates from each KG into a different embedding space with part of the loss function being the same as Equation 3. To make these embeddings all fall into a unified space, the alignment module learns cross-KG transitions by minimizing the sum of the alignment score function for all the seed relation triple alignments as follows:\nL = (tr1,tr2)\u2208St f align (tr 1 , tr 2 )(9)\nwhere S t is a set of seed relation triple alignments from the G 1 and G 2 (essentially the combination of seed entity alignments and seed relation predicate alignments), and f align (tr 1 , tr 2 ) is the alignment score function. Different from the alignment score function described in Section 3, which computes the (dis)similarity of two entities, here the alignment score function computes the (dis)similarity of two relation triples, tr 1 = (h 1 , r 1 , t 1 ) \u2208 G 1 and tr 2 = (h 2 , r 2 , t 2 ) \u2208 G 2 . To compute the alignment score, MTransE has three strategies to construct cross-KG transitions including distance-based axis calibration, transformation vectors, and linear transformations. According to their experimental study, MTransE with the linear transformation strategy has the best performance. This strategy learns a linear transformation between the entity embeddings of G 1 and G 2 with the following alignment score function:\nf align (tr 1 , tr 2 ) =||M e ij h 1 \u2212 h 2 ||+ ||M r ij r 1 \u2212 r 2 || + ||M e ij t 1 \u2212 t 2 ||(10)\nwhere M e ij and M r ij are linear transformations on entity embeddings and relation predicate embeddings, respec-tively. Minimizing f align will minimize the distance between the transformed entities/relation predicates from G 1 and those from G 2 , making the embeddings of the two KGs fall into the same vector space.\n\nThe inference module of MTransE uses NNS.\n\nIPTransE  first learns the embeddings of G 1 and G 2 separately in the embedding module with an extension of TransE named PTransE [Lin et al., 2015a]). Different from TransE, PTransE can model indirectly connected entities by considering the path between them, which is composed of relation predicates that form a translation between them. The alignment module of IPTransE learns transitions between G 1 and G 2 with three different strategies based on seed entity alignments: translation-based, linear transformation, and parameter sharing.\n\nThe translation-based strategy adapts the idea of \"translation\" to the cross-KG context, and treats alignment as a special relation predicate r (E1\u2192E2) between two sets of entities, E 1 and E 2 from G 1 and G 2 , respectively. The alignment score function is defined as:\nf align (e 1 , e 2 ) = ||e 1 + r (E1\u2192E2) \u2212 e 2 ||(11)\nwhere e 1 and e 2 are the embeddings of two entities e 1 \u2208 E 1 and e 2 \u2208 E 2 . The objective function is a weighted sum of the loss function of PTranE and f align on seed entity alignments. The linear transformation strategy learns a transformation matrix M (E1\u2192E2) , which makes two aligned entities close to each other, with the alignment score function below:\nf align (e 1 , e 2 ) = ||M (E1\u2192E2) e 1 \u2212 e 2 ||(12)\nThe objective function is a weighted sum of the loss function of PTranE and f align on seed entity alignments. The parameter sharing strategy forces e 1 = e 2 , which indicates that a pair of aligned entities share the same embedding, and hence applying f align on two aligned seed entities always gives 0. The objective function reduces to the loss function of PTranE. The parameter sharing strategy shows the best joint embedding learning performance among the three strategies.\n\nIn the training process, IPTransE adopts bootstrapping and has two strategies to add newly-aligned entities to the seeds: a hard strategy and a soft strategy. Other techniques usually apply the hard strategy where newly-aligned entities are directly appended into the set of seed alignments, which may suffer from error propagation. In the soft strategy, reliability scores are assigned to newly aligned entities to mitigate error propagation, which correspond to the embedding distance between aligned entities. This may be implemented as a loss item added to the objective function.\n\nBootEA [Sun et al., 2018] models EA as a oneto-one classification problem and the counterpart of an entity is regarded as the label of the entity. It iteratively learns the classifier via bootstrapping from both labeled data (seed entity alignments) and unlabeled data (predicated aligned entities). The embedding module adapts the triple score function of TransE f triple (\u00b7) as defined in Equation 2 by applying f triple (\u00b7) on not only true triples from G 1 and G 2 , but also all the \"generated triples\" obtained as follows: when an entity in a true triple, either head or tail, exists in the current set of aligned entities S, replacing that entity by its aligned one in S generates a new triple. Note that S grows gradually with the iterations of bootstrapping. Specifically, the loss function for the embedding module is: 13) where T r includes all the true triples in G 1 and G 2 , as well as all the generated triples described above; T r contains all the corrupted triples generated by uniform negative sampling [Bordes et al., 2013]. Note that this loss function is the sum of two parts in comparison to Equation 3, which is called limit-based loss function proposed by Zhou et al. [2017]; it minimizes both f triple (h, r, t) and f triple (h , r , t ) by using two hyper-parameters \u03b3 1 and \u03b3 2 to control them directly.\nL e = (h,r,t)\u2208Tr max(0, [f triple (h, r, t) \u2212 \u03b3 1 ])+ \u03b2 1 (h ,r ,t )\u2208T r max(0, [\u03b3 2 \u2212 f triple (h , r , t )]) (\nThe alignment module of BootEA is a one-to-one classifier, which is different from the aligning method in Equation 1 and uses a cross-entropy loss between the distribution of the entities in G 1 vs. the distribution of the predicted class (i.e., the aligned entity) from G 2 . All the pairs of entities in S are plugged into the following equation to compute the cross-entropy loss:\nL a = \u2212 e1\u2208E1 e2\u2208E2 \u03c6 e1 (e 2 ) log \u03c0(e 2 | e 1 )(14)\nwhere \u03c6 e1 (e 2 ) is a function that computes the labeling probability of e 1 . If e 1 is labeled as e 2 , the labeling distribution \u03c6 e1 has all of its mass concentrated on e 2 , i.e., \u03c6 e1 (e 2 ) = 1. If e 1 is unlabeled, \u03c6 e1 is a uniform distribution; \u03c0 is the classifier that predicts the aligned entity from E 2 given e 1 \u2208 E 1 . The overall objective function of BootEA L = L e + \u03b2 2 L a , where \u03b2 2 is a balancing hyperparameter.\n\nNAEA [Zhu et al., 2019] also formulates EA as a one-to-one classification problem but combines the translation-based and the GAT-based paradigms. Specifically, NAEA embeds neighbor-level information in addition to relation-level information. The neighborlevel information is embedded by aggregating the embeddings of the neighborhood with the attention mechanism as described in the GAT part of Section 4.2. Denote the neighbor-level representation of an entity e and the neighbor-level representation of a relation predicate r as Ne(e) and Nr(r), respectively. Then, based on the \"translation\" idea, the triple score function for the neighbor-level embedding is f triple (h, r, t) = Ne(h) + Nr(r) \u2212 Ne(t) . NAEA also uses the limitbased loss trick [Zhou et al., 2017] and gets the following loss function for the neighbor-level embedding.\nL 1 = (h,r,t)\u2208Tr (h ,r ,t )\u2208T r max([f triple (h, r, t) + \u03b3 1 \u2212 f triple (h , r , t )], 0)+ \u03b2 1 (h,r,t)\u2208Tr max([f triple (h, r, t) \u2212 \u03b3 2 ] , 0)(15)\nThe relation-level information is embedded using TransE. The overall loss function for the embedding module is L e = \u03b2 2 L 1 + (1 \u2212 \u03b2 2 )L 2 , where L 2 is the same as Equation 3 and \u03b2 2 is a hyperparameter.\n\nThe alignment module of NAEA is similar to BootEA, which uses a cross-entropy loss between the distribution of the entities in G 1 and the distribution of the predicted class from G 2 as follows.\nL a = \u2212 ei\u2208E1 ej \u2208E2 \u03c6 e1 (e 2 ) log \u03c0 (e j | e i )(16)\nwhere \u03c6 e1 (e 2 ) is the same as that in BootEA. The classifier \u03c0 (e j | e i ) is defined as follows:\n\n\u03c0 (e j | e i ) =\u03b2 3 \u03c3(sim (Ne (e i ) , Ne (e j )))\n+ (1 \u2212 \u03b2 3 ) \u03c3(sim (e i , e j ))(17)\nwhere sim(\u00b7) is the cosine similarity and \u03b2 3 is a balancing hyperparameter.\n\nTransEdge  addresses TransE's deficiency that its relation predicate embeddings are entity-independent, but in reality a relation predicate embedding should depend on its context, i.e., the head and tail entities. For example, the relation predicate director has different meanings in two different relation triples, (Steve Jobs, director, Apple) and (James Cameron, director, Avatar).\n\nTo address this issue, TransEdge proposes an edgecentric translational embedding model which regards the contextualized embedding of the relation predicate as the translation from the head entity to the tail entity. It contextualizes relation predicates as different edge embeddings, where the context of a relation predicate is specified by its head and tail entities. This is achieved by a triple score function as follows:\nf triple (h, r, t) = h + \u03c8(h c , t c , r) \u2212 t(18)\nwhere \u03c8(h c , t c , r) is the contextualized embeddings of a relation predicate, called the edge embedding. The paper introduces two interaction embeddings h c and t c for encoding the head and tail entities' participation in the computation of the edge embeddings, respectively. The edge embeddings may be computed via two strategies, context compression and context projection. The first strategy, context compression, adopts mulilayer perceptrons (MLPs) to compress the embeddings of the head entity, tail entity and the relation predicate as follows:\n\u03c8(h c , t c , r) = MLP ( MLP([h c r]) + MLP([t c r]) ) (19)\nThe other strategy, context projection, projects the relation embedding onto the hyperplane of the head and the tail entities, and compute the edge embedding as:\n\u03c8(h c , t c , r) = r \u2212 W (h,t) rW (h,t) (20) where W = MLP([h c t c ])\nis the normal vector of the hyperplane.\n\nThe alignment module of TransEdge uses a parameter sharing strategy to unify two different KGs, i.e., it forces a pair of aligned entities in the seed entity alignments to have the same embedding. TransEdge uses bootstrapping but newly aligned entities in each iteration are not processed with parameter sharing. To make these newly aligned entities close in the embedding space, a loss is added based on the embedding distance on the set D of newly aligned entities:\nL = (e1,e2)\u2208D e 1 \u2212 e 2(21)\nOther techniques that only use KG structure.\n\nOTEA [Pei et al., 2019b] adapts the optimal transport theory for EA. SEA [Pei et al., 2019a] makes use of unlabeled data (unaligned entities) by adopting a cycle consistency restriction in the loss function. SX19 [Shi and Xiao, 2019] models multi-mappings (i.e., many-to-many, one-to-many, or many-to-one) relations with a newly designed score function based on multiplication and complex vector space. AKE  first learns entity embeddings via TransE and then learns the unified vector space for G 1 and G 2 in an adversarial learning framework.\n\n\nTechniques that Exploit Relation Predicates and Attributes\n\nJAPE  makes use of attribute triples, albeit limited to only data types of attribute values (e.g., integers or strings), in addition to relation triples. The embedding module of JAPE has two components: structure embedding and attribute embedding. The structure embeddings are obtained using TransE on G 1 and G 2 separately, producing two structure-based entity embedding matrices E 1 s and E 2 s , respectively. The attribute embeddings are obtained by modeling the attribute co-occurrence within a same entity or across a pair of aligned seed entities. Specifically, a word embedding (Skip-gram [Mikolov et al., 2013] in their paper) is computed for every data type of attribute values based on the attribute co-occurrence as described above. Then the obtained word embedding for the data type is regarded as the embedding of the attribute itself. Then we can form an attribute-based entity embedding matrix consisting of the averaged attribute embeddings of all the entities, denoted as E i a for each KG, respectively, where i = 1, 2.\n\nAfter obtaining both the structure and attributebased entity embedding matrices, JAPE first computes cross-KG similarity S 1,2 and inner-KG similarity for each KG (i.e., S 1 and S 2 ) based on the attribute-based entity embedding matrices:\nS 1,2 = E 1 a E 2 a ; S 1 = E 1 a E 1 a ; S 2 = E 2 a E 2 a(22)\nThen, it refines the embeddings by integrating the structural information with the following loss function.\nL = E 1 s \u2212 S 1,2 E 2 s 2 F + \u03b2 E 1 s \u2212 S 1 E 1 s 2 F + E 2 s \u2212 S 2 E 2 s 2 F(23)\nwhere \u03b2 is a hyper-parameter that balances the importance of cross-KG similarity and inner-KG similarities.\n\nKDCoE [Chen et al., 2018] builds on top of MTransE by shifting the entity embeddings by the embeddings of entity descriptions (i.e., literal descriptions for entities in KGs), which are treated as a type of special attribute triples where the attribute value is a literal description for the entity.\n\nAttrE [Trisedya et al., 2019a] is the first technique that makes use of attribute values. Moreover, it is the only EA technique that needs no seed alignments.\n\nThe embedding module of AttrE uses TransE to learn KG structure embeddings for the entities from G 1 and G 2 . The main novelty of AttrE is to encode the semantics of the attribute values and three methods for encoding them are proposed: averaged character embedding, aggregated character embedding by LSTM, and aggregated n-gram character embedding. The aggregated n-gram character embedding has the best performance as reported in their paper, which uses the sum of ngrams of varying lengths to encode attribute values.\n\nAnother interesting idea proposed in AttrE, inspired by the \"translation\" idea in Equation 2, is interpreting attribute triples (in addition to relation triples) as translating operation to learn the attribute embeddings as follows:\nf triple (e, a, v) = e + a \u2212 \u03c4 (v)(24)\nwhere \u03c4 (v) is a function implementing one of the aforementioned encoding methods on the attribute value v. Thereby the same triple score function can be used to compute the plausibility of both relation and attribute triples uniformly. It helps shift the KG structure embeddings of G 1 and G 2 into the same vector space by minimizing the following loss function:\nL s = e\u2208E1\u222aE2 [1 \u2212 sim (e s , e c )](25)\nwhere sim (e s , e c ) is the cosine similarity between the structure embedding e s and the attribute embedding e c of an entity e.\n\nBesides making use of relation triples and attribute values, AttrE also aligns predicates (including both relation and attribute predicates) by exploiting the string similarity in the naming conventions of the predicates.\n\nFinally, the inference module of AttrE predicts the aligned entity by computing the cosine similarity between the shifted structure embeddings.\n\nMultiKE  uses multi-view learning on various kinds of features. The embedding module of MultiKE divides the features of KGs into three subsets called views: name view, relation view, and attribute view. Entity embeddings are learned for each view and then combined.\n\nIn the name view, an entity embedding is obtained from concatenating pre-trained word/character embeddings of the tokens in the entity name.\n\nIn the relation view, TransE is adopted to produce embeddings but with a logistic loss function:\nL r = (h,r,t)\u2208Tr\u222aT r log 1 + exp \u03b6(h, r, t)f triple (h, r, t)(26)\nwhere \u03b6(h, r, t) is 1 if (h, r, t) is a true triple, and -1 otherwise; f triple (h, r, t) is the same as in TransE.\n\nIn the attribute view, an attribute-value matrix [a v] is first formed by the concatenation of the embeddings of attribute predicates and their values, and then the triple score function is defined as the head entity minus the result of a convolution neural network (CNN) on the attribute-value matrix, formally:\nf triple (e, a, v) = e \u2212 CNN([a v])(27)\nThis triple score function is then used to obtain the embeddings in the attribute view by minimizing the following objective function:\nL a = (e,a,v)\u2208Ta log(1 + exp(f triple (e, a, v)))(28)\nwhere T a is a set of true attribute triples. Next, the alignment module unifies the embedding spaces of the two KGs into the same vector space in each of the views. In the name view, the two KGs both use the same embedding scheme, i.e., pre-trained word embedding, so their embedding spaces are already unified. In the relation view and the attribute view, MultiKE performs the so-called cross-KG entity/relation/attribute identity inference to unify the embedding spaces as follows.\n\nThe entity identity inference is performed in both the relation and the attribute views. First, a strategy similar to BootEA [Sun et al., 2018] is adopted to generate triples as follows: when an entity in a true triple, either head or tail, exists in the current set of aligned entities S, replace that entity by its aligned one in S generates a new triple. Then the sum of the plausibility (f triple ) of all the generated triples is minimized in both the relation and attribute views, which update all the embeddings. The updated embeddings are then fed into the relation and attribute identity inference below.\n\nIn the relation and attribute identity inference, first a similar strategy as AttrE [Trisedya et al., 2019a] is adopted to derive soft relation and attribute predicate alignments by string similarity. Then the relation (attribute, respectively) identity inference generates triples in the relation view (attribute view, respectively) as follows: when a relation (attribute, respectively) predicate in a true triple exists in derived relation (attribute, respectively) alignments, replace the relation (attribute, respectively) predicate with its aligned counterpart. Then the sum of the plausibility (f triple ) of all the generated triples is minimized in both the relation and attribute views, which update all the embeddings.\n\nThe embeddings of an entity for the three views obtained above are combined into one embedding for the entity by averaging each view or minimizing a combination loss function. Finally, the inference module uses NNS based on the similarity between the combined entity embeddings.\n\nCOTSAE [Yang et al., 2020a] alternatively trains structural and attribute embeddings, and then combines the alignment results obtained from them.\n\n\nGNN-based EA Techniques\n\nGNNs suit KGs' inherent graph structure so there are growing numbers of EA techniques based on GNNs recently. GNN-based EA techniques are categorized into GCN-based and GAT-based ones. They usually encode KG structure by the neighborhood of entities and many of them take attributes as input features for the embedding module because aligned entities tend to have similar neighborhood and attributes. Most GNN-based techniques use only seed entity alignments rather than other kinds of seed alignments in the training.  is the first study on GNN-based EA. Like many GNN-based EA techniques, GCN-Align learns entity embeddings from structural information of entities. GCN-Align also exploits attribute triples by treating them as relation triples. Specifically, GCN-Align uses two GCNs to embed the entities of G 1 and G 2 (one GCN for each KG) into a unified space with shared weight matrices, described by the following equation: (29) where H are the weight matrices for these two types of embeddings, which are shared by the two GCNs. The matrix H (l) in the vanilla GCN [Kipf and Welling, 2017] (Equation 4) is replaced by a concatenation of structure and attribute embedding matrices. Unlike GCN, GCN-Align considers various types of relation predicates in KGs when computing the element a ij \u2208 A. The new adjacency matrix A is designed as follows:\n\n\nGCN-based EA Techniques\n\n\nGCN-Align\n[H (l+1) s H (l+1) a ] = \u03c3(D \u2212 1 2\u00c2D \u2212 1 2 [H (l) s W (l) s H (l) a W (l) a ])a ij \u2208 A = (ei,r,ej )\u2208Tr g h (r) + (ej ,r,ei)\u2208Tr g t (r)(30)\nwhere a ij is the edge weight from the i-th entity to the j-th entity. Both (e j , r, e i ) and (e i , r, e j ) are triples in a KG. The functions g h (r) and g t (r) compute the number of head entities and the number of tail entities connected by relation r divided by the number of triples containing relation r, respectively. In this way, the adjacency matrix A helps model how the embedding information propagates across entities.\n\nGCN-Align is trained by minimizing a margin-based loss function like Equation 1. Taking into account of both structure and attribute embeddings, GCN-Align defines its alignment score function as follows:\nf align (e 1 , e 2 ) =\u03b2 h s (e 1 ) \u2212 h s (e 2 )) L1 d s + (1 \u2212 \u03b2) h a (e 1 ) \u2212 h a (e 2 ) L1 d a(31)\nwhere h s (\u00b7) and h a (\u00b7) are the structure embedding with dimensionality d s and attribute embedding with dimensionality d a , respectively; \u03b2 is used to balance the importance of these two embeddings.\n\nHGCN [Wu et al., 2019b] explicitly utilizes relation representation to improve the alignment process in EA. To incorporate the relation information, HGCN jointly learns entity and relation predicate embeddings in three stages as follows.\n\nState 1 computes entity embeddings by a GCN variant named the Highway-GCN [Rahimi et al., 2018], which embeds entities into a unified vector space. The layer-wise highway gates control the forward propagation on top of the vanilla GCN layer, formulated as function T below:\nT (H (l) ) = \u03c3 H (l) W (l) + b (l)(32)H (l+1) = T H (l) H (l+1) + 1 \u2212 T H (l) H (l) (33)\nwhere H (l) is the output of the l th layer and the input of the (l + 1) th layer, W (l) and b (l) are the weight matrix and bias vector, respectively; is element-wise multiplication. HGCN computes entity embeddings for both KGs separately and then maps the embeddings into a unified vector space using Equation 1. Stage 2 gets relation predicate embeddings based on their head and tail entity representations. This stage first computes the average embeddings of all the head entities and tail entities connected to the relation predicate, respectively. The two averaged embeddings are then concatenated as the embedding of the relation predicate after a linear transformation.\n\nStage 3 uses Highway-GCN again with the input being the concatenation of the entity embeddings computed in Stage 1 and the sum of all the relation predicate embeddings related to the entity. The alignment module maps the output of the Highway-GCN for the two KGs into a unified vector space with a loss similar to Equation 1.\n\nGMNN [Xu et al., 2019a] formulates the EA problem as graph matching between two topic entity graphs. Every entity in a KG corresponds to a topic entity graph, which is formed by the one-hop neighbors of the entity and the corresponding relation predicates (i.e., edges). Such a graph represents the local context information of the entity. GMNN uses a graph matching model to model the similarity of two topic entity graphs, which indicates the probability of the two corresponding entities being aligned. The graph matching model consists of four layers, including an input representation layer, a node-level matching layer, a graph-level matching layer, and a prediction layer. The input representation layer uses a GCN to encode two topic entity graphs and obtain entity embeddings. The node-level matching layer computes the cosine similarity between the embeddings of every pair of entities from two topic entity graphs. This layer further computes an attentive sum of entity embeddings as follows:\ne i = |E2| j=1 \u03b1 i,j \u00b7 e j |E2| j=1 \u03b1 i,j(34)\nwhere \u03b1 i,j is the cosine similarity between entity e i in a topic graph and entity e j in another topic graph. This computation is done for entities from both two topic entity graphs. The resultant weighted sum of embeddings serves as the input to the graph-level matching layer. The graph-level matching layer runs a GCN on each topic entity graph to further propagate the local information throughout the topic entity graph. The output embeddings of the GCN is then fed to a fully-connected neural network followed by the element-wise max and mean pooling method to get the graph matching representations for each topic entity graph. Finally the prediction layer takes the graph matching representation as input and uses a softmax regression function to predict entity alignment.\n\nMuGNN  addresses the structural heterogeneity between KGs that may result in dissimilar embeddings of the entities that should be aligned. To reconcile the heterogeneity (i.e., the difference) between the structures of G 1 and G 2 , MuGNN uses a multichannel GNN in the embedding module to encode a KG in multiple channels towards KG completion and pruning exclusive entities.\n\nOne channel of MuGNN conducts KG completion by adding the relation predicates missing from a KG using the Horn rules for each KG, e.g., marriedT o(x; y) \u2227 liveIn(x; z) \u21d2 liveIn(y; z), as extracted by AMIE+ [Gal\u00e1rraga et al., 2015]. The two resultant sets of rules are then transferred into each other via parameter sharing. The other channel of MuGNN prunes \"exclusive entities\", i.e., those entities that only appear in one of the two KGs.\n\nSpecifically, the multi-channel GNN is formulated as follows, assuming a two-channel MuGNN:\nMultiGNN(H l ; A 1 , A 2 ) = Pooling(H l+1 1 , H l+1 2 ) (35) H l+1 i = GCN(A i , H l , W i ), i = 1, 2(36)\nwhere, similar to Equation 4, H l is the input entity embeddings of the current layer while H l+1 i is the output entity embeddings of this layer for the i-th channel; A i and W i are the adjacency matrix and learnable weight matrix in the i-th channel, respectively. At the end of the layer, pooling is used to combine the two channels. The adjacency matrices A i are determined by different weighting schemes with self-attention and cross-KG attentions as follows.\n\nA 1 is determined based on self-attention, where element a ij is the connectivity from e i to e j as follows:\na ij = softmax(c ij ) = exp(c ij ) e k \u2208Ne i \u222a{ei} exp(c ik )(37)\nHere, N ei is the neighborhood of e i , and c ij is the attention coefficient defined the same way as in Equation 7. A 2 prunes exclusive entities by lowering the weight of the connectivity a ij between those entities if one of them is an exclusive entity, formally:\na ij \u2208 A 2 = max r1\u2208R1,r2\u2208R2\n1((e i , r 1 , e j ) \u2208 T 1 ) sim(r 1 , r 2 ) (38) where, R 1 and R 2 are the sets of relation predicates of G 1 and G 2 , respectively. The function 1(\u00b7) = 1 if (e i , r 1 , e j ) \u2208 T 1 , and 0 otherwise. The function sim(r 1 , r 2 ) is the inner-product similarity between two relation predicates r 1 and r 2 . To unify embeddings of G 1 and G 2 from the multichannel GNN into a same vector space, the alignment module of MuGNN utilizes a variant of Equation 1, which is the weighted sum of the seed entity alignments loss and the seed relation predicate alignments loss.\n\nNMN  aims to tackle the structural heterogeneity between KGs. To address this issue, the technique learns both the KG structure information and the neighborhood difference so that the similarities between entities can be better captured in the presence of structural heterogeneity.\n\nTo learn the KG structure information, NMN's embedding module uses a GCN with highway gates to model the KG structure information with the input of a combination of G 1 and G 2 to be aligned. This module is pre-trained with a margin-based loss function (cf. Equation 1) using seed entity alignments. NMN then uses cross-graph matching to capture the neighborhood difference. A neighborhood sampling strategy is first used to select the more informative onehop neighbors, based on the observation that the more often an entity and its neighbor appear in the same context, the more representative and informative the neighbor is for the entity. The cross-graph matching then compares the sampled neighborhood subgraph of an entity in the source KG with the subgraph of each candidate entity in the target KG to select an optimal aligned entity. A cross-graph vector is computed to indicate whether the entities are similar. The cross-graph matching is done by an attention mechanism.\n\nNMN concatenate the entity embedding and its neighborhood representation to get the final embeddings for EA. EA is performed by measuring the Euclidean distance between entity embeddings.\n\nCEA  considers the dependency of alignment decisions among entities, e.g., an entity is less likely to be an alignment target if it has already been aligned to some entity. The paper proposes a collective EA framework. It uses structural, semantic, and string signals to capture different aspects of the similarity between entities in the source and the target KGs, which are represented by three separate similarity matrices. Specifically, the structural similarity matrix is computed based on the embedding matrices via GCNs with cosine similarity, the semantic similarity matrix is computed from the word embeddings, and the string similarity matrix is computed by the Levenshtein distance between the entity names. The three matrices are further combined into a fused matrix. CEA then formulates EA as a classical stable matching problem on the fused matrix to capture interdependent EA decisions, which is solved by the deferred acceptance algorithm [Roth, 2008].\n\nOther GCN-based EA techniques. RDGCN [Wu et al., 2019a], which is similar to HGCN, utilizes relation information and extends GCNs with highway gates to capture the neighborhood structural information. RDGCN differs from HGCN in that it incorporates relation information by the attentive interaction. AVR-GCN [Ye et al., 2019] considers multi-mappings under the GCN paradigm and learns the embeddings of entities and relation predicates simultaneously for KGs. Specifically, it first learns these embeddings via an embedding model named vectorized relational GCN, and then uses a weight sharing mechanism to join (e.g., via concatenation or vector transformation) those embeddings into a unified vector space. HMAN  takes into account even more other types of information such as relation predicates, attribute values, and entity descriptions besides the structural information. Specifically, HMAN employs a pre-trained BERT model [Devlin et al., 2019] to capture the semantic relatedness of the descriptions of two entities that cannot be measured directly. SSP [Nie et al., 2020] uses both translation-and GNN-based paradigms. It captures local semantics from relation predicates and global structural information by a structure and semantics preserving network. CG-MuAlign [Zhu et al., 2020] addresses structural heterogeneity by collectively aligning entities via the attention mechanism. XS20  is another EA technique that addresses the many-to-one alignment problem in its inference module. It models EA as a task assignment problem and solves it by the Hungarian algorithm [Kuhn, 2010].\n\n\nGAT-based EA Techniques\n\nKECG  aims to reconcile the issue of structural heterogeneity between KGs by jointly training both a GAT-based cross-graph model and a TransEbased knowledge embedding model.\n\nThe cross-graph model in KECG embeds entities with two GATs on the two KGs, which encode the graph structure information. The attention mechanism in the GATs helps ignore unimportant neighbors and mitigate the issue of structural heterogeneity. The GATs' projection matrices W (cf. Equation 5) are set to diagonal matrices, which reduces the number of parameters to be learned and increases the model generalizability.\n\nAs usual, KECG uses attention mechanisms as described in Section 4.2 and margin-based loss for the cross-graph model as described in Section 3. The knowledge embedding model in KECG uses TransE to encode the structural information in each KG separately. The overall objective function of KECG is a weighted sum of the loss functions from the cross-graph model and the knowledge embedding model.\n\nAliNet [Sun et al., 2020a] is based on the observation that some aligned entities from G 1 and G 2 do not share similar neighborhood structures. Such aligned entities may be missed by the other GNN-based EA techniques, because they rely on similar neighborhood structures for EA. AliNet addresses the issue by considering both direct and distant neighbors.\n\nAliNet learns entity embeddings by a controlled aggregation of entity neighborhood information. Without loss of generality, we describe the process for two-hop neighborhood below, although any number of hops is applicable. First, a GCN is used to aggregate the direct (i.e., one-hop) neighbors' information. Let the embedding of an entity e i at the l-th layer be e (l)\n\ni,1 after one-hop neighbor aggregation. Then for two-hop neighbors, an attention mechanism is used to indicate their contribution to the embedding of e i as follows:\ne (l) i,2 = \u03c3 j\u2208N2(i)\u222a{i} \u03b1 (l) ij W (l) 2 e (l\u22121) j (39)\nwhere e (l\u22121) j is the embedding of e j at the (l \u2212 1)-th layer of the GCN; N 2 (\u00b7) is the set of the two-hop neighbors of e i ; W At the end of each layer of AliNet, the information from one-hop and two-hop neighbors is combined with a gating mechanism, i.e., the embedding of entity e i at the l-th layer is computed as follows:\ne (l) i = g e (l) i,2 \u00b7 e (l) i,1 + 1 \u2212 g e (l) i,2 \u00b7 e (l) i,2(41)\nwhere g(\u00b7) is the gate, g(e MRAEA [Mao et al., 2020] considers meta relation semantics including relation predicates, relation direction, and inverse relation predicates, in addition to structural information learned from the structure of relation triples. The meta relation semantics are integrated into structural embedding via meta-relationaware embedding and relation-aware GAT.\n\nTo compute the meta-relation-aware embeddings (concatenation of entity and relation predicate embeddings), we first extend the set of relation triples by creating an \"inverse triple\" for each triple by replacing the original relation predicate with an \"inverse relation predicate\" while keeping the same head and tail entities unchanged. Second, the entity and relation embedding components of the meta-relation-aware embeddings of the target entity are computed by averaging those of the neighbor entities, respectively.\n\nThe relation-aware GAT generates a structure-andrelation-aware embedding of each entity by attending the meta-relation-aware embeddings of the target entity's neighbors. Specifically, the GAT's attention coefficient c ij , which indicates the importance of both the neighbor entity e j and the connecting relation predicate r k to the target entity e i , is computed as:\nc ij = w T e i e j 1 |M ij | r k \u2208Mij r k(42)\nwhere the embeddings e i , e j , and r k are obtained from the meta-relation-aware embeddings; w is a learnable weight vector; M ij = {r k | (e i , r k , e j ) \u2208 T } is the set of relation predicates that link from e i to e j , which incorporates relation features into the attention mechanism. As usual, MRAEA is trained with a margin-based loss function like Equation 1.\n\nEPEA  learns embeddings of entity pairs via a pair-wise connectivity graph (PCG) rather than embeddings for individual entities. EPEA first generates the PCG, whose nodes are pairs of entities from G 1 and G 2 . Given two entity pairs (e 1,i , e 2,i ) and (e 1,j , e 2,j ) in the PCG, an edge is added between the two entity pairs if there is a relation predicate r 1 connecting e 1,i to e 1,j in G 1 and a relation predicate r 2 connecting e 2,i to e 2,j in G 2 . After generating the entity pairs as the nodes of the PCG, EPEA uses a CNN to encode the attributes of entity pairs into embeddings based on attribute similarity. These attribute embeddings are then fed into a GAT that further incorporates structural information and produce a score, which indicates the probability of a pair consisting of aligned entities. This scoring function is then used as f align in Equation 1 to train the whole model. The inference module predicts aligned entities by performing binary classification on the scoring function value with the input being the embeddings of entity pairs.\n\nAttrGNN  learns embeddings from both relation triples and attribute triples in a unified network. It partitions each KG into four subgraphs containing attribute triples of entity names, attribute triples of literal values, attribute triples of digital values, and the remaining triples (i.e., relation triples), respectively. For each subgraph, entity embedding is computed based on attributes as well as the KG structure using GAT; then a similarity matrix between G 1 and G 2 is computed based on the entity embedding. Finally, the four similarity matrices are averaged to yield a final similarity matrix for the inference module.\n\n\nDatasets and Experimental Studies\n\nWe discuss the limitations of existing datasets and experimental studies, present our proposed datasets addressing the limitations, and report on a comprehensive experimental study on representative EA techniques using our datasets.\n\n\nLimitations of Existing Datasets\n\nThere are several significant limitations of existing datasets, namely bijection, lack of name variety and, small scale, which are detailed below.\n\nBijection. Many existing papers, including some of the benchmarking papers, have used datasets that consist of two KGs where almost every entity in one KG has one and only one aligned entity in the other KG, i.e., there is bijection between the two KGs. Such datasets have been generated from different language versions of Wikipedia (e.g., DBP15K  and SRPRS multi ) and the application argued for such datasets is aligning two KGs in different languages, i.e., multilingual EA. However, such application instances are infrequent in real life.\n\nWe argue that the following scenario is more common: two KGs come from different sources, e.g., a generic KG built from Wikipedia and the other from a domain-specific source such as medicine, locations, flights and music. The difference in the sources is typically not language but the coverage of knowledge, so the two KGs are complementary to each other and aligning them helps enrich them. Therefore, non-bijection between the KGs is desired. A recent paper  also points out that bijection is an unrealistic setting and created DBP-FB, a dataset consisting of two KGs built from different sources, DBpedia and Freebase. It is a great step towards non-bijection datasets, but unfortunately, a big limitation of DBP-FB is that it does not contain any generic attribute (e.g., year, address, etc) triples except entity names and hence does not suffice the need of most recent EA techniques, which make heavy use of generic attributes as features. From our experiments ( Table 5) we see that most recent EA techniques use generic attributes as input features which are essential for effectiveness. Creating datasets coming from different sources is challenging. A recent industrial benchmark dataset MED-BBK-9K  is built from different sources. However, this dataset also has the bijection problem and the size is small: the number of unique entities covered in this dataset is less than 10, 000.\n\nLack of name variety. Unlike recently proposed datasets MED-BBK-9K and DBP-FB, most previous EA datasets are constructed from KGs with the same source. For example, DWY100K [Sun et al., 2018] and its resampled version SRPRS mono  consist of KG pairs (DBpedia-Yago and DBpedia-Wikidata) with the same primary source, Wikipedia. Thus, the names of entities from two KGs may have the same surface label; such names become \"tricky features\", which can be used to achieve 100% accurate EA easily (we call this the lack of name variety problem). To address this problem, Sun et al. [2020b] remove all the entity names from DWY100K. However, this is an overkill because, in real-world settings, KGs do contain entity names as attributes but just have variety in the names of the same real-world entity. The recently proposed dataset DBP-FB have significant portion of entities (42%) with different entity names and hence have good name variety due to the different data sources DBpedia and Freebase, but its lack of generic attribute triples limits its use as mentioned earlier. We need datasets that have significant amount of generic   No No Small Multilingual DWY100K [Sun et al., 2018] Large No No Monolingual SRPRSmulti  No No Small Multilingual SRPRSmono  No No Small Monolingual DBP-FB ] Yes Yes Medium Monolingual DBP-FB ] Yes Yes Medium Monolingual MED-BBK-9K  No Yes Small Monolingual DWY-NB (Our Proposed) Yes Yes Large Monolingual * Dataset size represent the number of unique entities in the dataset: Small (< 20, 000); Medium (20, 000 \u2212 50, 000); Large (> 50, 000) attribute triples and variety in the names. Our proposed datasets address these issues.\n\nSmall scale. Most existing datasets are of small (e.g., MED-BBK-9K contains 9,162 unique entities) to medium (e.g., DBP-FB contains 29,861 unique entities) sizes. Our proposed datasets contain up to 600,000 unique entities from the two KGs combined. Table 3 summarizes the key properties of various datasets. Our proposed benchmark DWY-NB has all the three desirable properties: non-bijection, name variety and large size. Some studies consider the property of whether the dataset is multilingual or monolingual. We do not view it as an essential property that affects the utility of the datasets, since EA techniques that utilize semantic information of KGs such as attributes can first translate it into the target language. Note that all the current multilingual datasets have the bijection problem discussed earlier.\n\n\nLimitations of Existing Experimental Studies\n\nSeveral recent studies aim at benchmarking EA techniques. Sun et al. [2020b] re-implemented 12 representative EA techniques, but the re-implementation missed important components in some techniques such as predicate alignments in AttrE [Trisedya et al., 2019a] and MuGNN ). To avoid such problems, we use the original code of each compared technique. Another limitation of Sun et al. [2020b] is that they only used bijection datasets. The study by Zhao et al. [2020] does not include experiments on techniques that use attribute triples such as AttrE [Trisedya et al., 2019a] and MultiKE , but as our experiments show, most recent techniques use attribute triples and they have much best performance. Zhang et al. [2020] proposes a new dataset MED-BBK-9K, but it has the limitations of bijection and small size, making the study less comprehensive.\n\n\nOur Proposed Benchmark DWY-NB\n\nTo address the limitations of existing datasets, we propose a new benchmark called DWY-NB where NB stands for non-bijection. This benchmark consists of two regular-scale datasets and large-scale ones described at the end of this sub-section; each of the regular-scale datasets consists of a pair of KGs that can be used for the evaluation of EA techniques. We call the two datasets DW-NB and DY-NB. The two KGs of DW-NB are subsets of DBpedia and Wikidata [Vrandecic and Kr\u00f6tzsch, 2014], respectively. The two KGs of DY-NB are subsets of DBpedia [Auer et al., 2007] and Yago [Hoffart et al., 2013], respectively. We choose these sources as starting points because they contain rich relation and attribute triples. Now we explain how the datasets are generated. For ease of explanation, we next use DW-NB as an example while the process for DY-NB is similar. We start from the list of aligned entities between two KGs (DBpedia and Wikidata) from the dataset DWY100K from [Sun et al., 2020b], we call this list the seed entity alignments. This seed entity alignment contains a list of 100,000 alignments between the entities in DBpedia and Wikidata, which originally provided by the DBpedia website 2 . We extract all those triples from DBpedia (and Wikidata, respectively) that contain the entities listed in the seed entity alignments to form a sub-graph of DBpedia (and Wikidata, respectively), and this subgraph of DBpedia and sub-graph of Wikidata become the pair of KGs in our DW-NB dataset.\n\nTo address the bijection problem, we randomly remove a certain percentage (25% by default) of the entities from each of the two KGs; we make sure the entities removed from one KG is different from the entities removed from the other KG so that not every entity in one KG will have an aligned entity in the other KG. As a result, by default 50% of the entities in the two KGs combined do not have aligned ones. We also vary the proportion of aligned entities in our benchmark.\n\nTo address the lack of name variety problem, we add variety to the entity name attributes as follows. In every KG source (DBpedia, Wikidata, or Yago), there are often multiple attributes corresponding to the name of the entity, which we refer to as name attributes. These multiple name attributes have different attribute values (i.e., entity names) as a result of the curation process of the KGs conducted by different humans. For an entity with multiple name attributes, we select a name attribute that is different from that of the corresponding entity in the other KG, if any. Thus, the above procedure provides variety in entity names be-2 https://wiki.dbpedia.org/downloads-2016-10 tween the KGs in our datasets. After this process, it turns out that 36% of the aligned entities have different entity names. The statistics of DWY-NB are listed in Table 4. To conduct scalability experiment in Experiment 5 of Section 7.4, we further generate larger versions (100K, 300K and 600K entities in each KG of the KG pair) of the dataset DW-NB in the same way as as described above. Details of all the datasets can be found at (https://github.com/ruizhang-ai/EA_for_KG).\n\n\nExperiments and Results\n\nWe conduct five sets of experiments. Experiment 1 : Following the literature [Chen et al., 2017;Sun et al., 2018;Wu et al., 2020], the main evaluation measure for the effectiveness of EA techniques is hits@1 (or hits@k) which indicates the percentage of entities that have the correct aligned entity in the top-k predicated aligned entities. Experiment 2 : We evaluate the effect of attribute triples on the effectiveness of EA techniques as using attribute triples has been a trend of recently proposed EA techniques. Experiment 3 : In addition to Experiment 1, we also evaluate the effectiveness of EA techniques via direct downstream applications. Experiment 4 : At the end of Section 3, we argue that whether a technique is designed to conduct multilingual EA is not an essential characteristic because we can perform an automatic translation on the semantic information into the target language so that both KGs are in the same language. This experiment justifies this argument. To be able to isolate the effect of the factor being evaluated for a certain experiment in our experimental study (e.g., the effect of seed entity alignments proportions, the effect of attribute triples, etc.), we have aligned the predicates between the KGs in those experiments so that predicate alignments have the same effect on the performance of all the techniques no matter whether they take measures to align predicates. If we did not align the predicates in our data, then the techniques that do not take measures to align predicates might have poorer performance due to unaligned predicates rather than due to the effect of the factor being evaluated.\n\nEnvironments. We run the experiments with an Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz processor, 128GB main memory, a Nvidia Tesla GPU with 32GB memory, and Ubuntu 20.4. The programming language and libraries include Python, TensorFlow, Torch, etc. depending on the language used for the original code.\n\nExperiment 1: the effect of seed entity alignments. This experiment evaluates the accuracy of EA in terms of Hits@k while varying the amount of seed entity alignments used for training from 10% to 50% of the total available set of seed entity alignments (50,000 for DW-NB and 7,500 for DY-NB). Higher hits@k means better accuracy. Table 5 shows the result. The accuracy of all the techniques gets higher with more seeds, which is expected since more seeds provide more supervision.\n\nOverall, AttrE and MultiKE have much better performance than the others especially when less seed entity alignments are available. This is because they make great use of various types of features such as attributes and relation predicates while the other techniques do not. AttrE's performance does not change while varying the amount of seeds since it does not use seed alignments, so when seed alignments are hardly available, AttrE is the clear winner. Only when the amount of seed entity alignments reaches 50%, NMN has slightly higher Hits@1 than AttrE. In general, to achieve good alignment results, supervised models require seed alignments with the proportion of at least 30%.\n\nAmong the GNN-based techniques, RDGCN and NMN are the top-2 in terms of Hits@1. It is worth noting that the top-2 from both translation-and GNNbased techniques exploit attribute triples, and we can see that on average, the techniques that exploit attribute triples achieve much better performance than the techniques that do not. JAPE has poorer performance compared to other techniques that use attributes because it uses very limited information from attributes, only the data type of attribute value.\n\nExperiment 2: the effect of attribute triples. This experiment evaluates how much benefit may be gained by exploiting attribute triples. For every EA technique, we compare the performance of a \"using-attribute\" version vs. a \"not-using-attribute\" version as follows. For a technique that exploits attribute triples by design, we get the performance of its \"not-using-attribute\" version by only using relation triples (and not using attribute triples) to compute the entity embeddings. For a technique that only uses relation triples by design, we get the performance of its \"using-attribute\" version by applying a naive way of exploiting attribute triples, i.e., treating the attribute triples as relation triples which means treating the attribute values as nodes in the graph. Figure 3 shows the results. The proportion of seed entity alignments used in this experiment is 30% and the results on other proportions have a similar behavior. For every technique, the \"using-attribute\" version outperforms the \"not-using-attribute\" version, especially for those techniques that use attribute triples by design. These show that making good use of attribute triples can improve the accuracy significantly. Among them, the gap between the two versions of At-trE is huge, because AttrE does not use seed alignments and heavily rely on attributes to train the alignment module. MultiKE uses both seed alignments and attribute triples to produce the unified embedding space, and hence has relatively smaller gap between the two versions, but still using attributes provides substantial gains. When the KGs do not contain attribute triples but seed alignments are available, MultiKE is the winner. In comparison, the performance of GNN-based techniques (e.g., HGCN, RDGCN, NMN) drops significantly (most by 50%) when \"not-using-attribute\", as they heavily rely on entity names to initialize the node embeddings in the embedding module. In the absence of entity names, node embeddings are randomly initialized which leads to poor performance. Interestingly, the techniques that do not use attribute triples by design also gets better performance with the \"using-attribute\" version, even this is by the naive way of treating attribute triples as relation triples.\n\nAs a case study to understand the benefit of attribute triples intuitively, we examine the following example: dbp:Ali Lohan and dbp:Lindsay Lohan are siblings that have the same neighbors: dbp:Michael Lohan and dbp:Dina lohan, which represent the father and mother, respectively. EA techniques that only use the graph structure information cannot distinguish dbp:Ali Lohan from dbp:Lindsay Lohan, which may lead to a misalignment. EA techniques that exploit attribute triples can use the attribute triples, such as (dbp:Lindsay Lohan, birth date,  [Sun et al., 2020b;Zhao et al., 2020], we use two common downstream tasks for this purpose: link prediction for translation-based techniques and node classification for GNN-based techniques, detailed as follows. The link prediction task aims to predict t given h and r of a relation triple. Specifically, first a relation triple is corrupted by replacing its tail entity with all the entities in the dataset. Then, the corrupted triples are ranked in ascending order by the plausibility score computed as h + r \u2212 t. Since true triples (i.e., the triples in a KG) are expected to have smaller plausibility scores and rank higher in the list than the corrupted ones, hits@10 (whether the true triples are in the top-10) is used as the measure for the link prediction task. The node classification task aims to classify nodes and determine their labels. Given the embedding of a node, a simple classifier SVM [Cortes and Vapnik, 1995] with two-fold cross-validation is trained to predict the entity type (e.g., person, organization, etc.) of the node. Table 6 shows the accuracy of downstream applications on DWY-NB with 10%, 30%, and 50% of seed entity alignments. The accuracy increases with the amount of seed alignments but not significantly. Translation-based EA techniques are compared against TransE, a pure KG embedding technique. Mul-tiKE and AttrE have higher link prediction accuracy than TransE while the others do not. This is because MultiKE and AttrE make great use of various types of information including attribute triples as input features, which improve the quality of KG embeddings.\n\nGNN-based EA techniques are compared against GCN, a pure KG embedding technique. All of the GNNbased techniques have lower node classification accuracy than GCN; the best one is NMN (about 2% lower than GCN). The techniques that use attribute triples achieve better accuracy than those that do not.\n\nIn summary, the KG embeddings obtained from EA techniques may have slightly better or worse perfor-    Note. Although translation-and GNN-based techniques have the same asymptotic training cost, their practical GPU memory usage differs greatly due to different training mechanisms. Each training iteration of translation-based techniques typically requires computing the translation function (Equation 3) or its variant, which only involves several triples. The two KGs and the embeddings are stored in the CPU memory. A machine learning framework such as TensorFlow only loads the triples needed for each training iteration, namely mini-batch, from the CPU memory to the GPU memory. We can control the mini-batch size to be as small as only several triples, so the required GPU memory for translation-based techniques is very small. In comparison, GNN-based techniques usually use message passing to compute the embedding of graph nodes and edges, and the message passing procedure in Tensor-Flow loads the whole graph into the GPU memory, which is O(M ), a large number. GPU memory is a bottleneck for running machine learning algorithms. This makes translation-based techniques more scalable than GNN-based ones in terms of GPU memory requirement.\n\nExperimental results. Table 8 shows the running time and GPU memory usage of the training module of four representative techniques as data sizes grow. The running time of all the tested techniques is similar for the same dataset size. Translation-based techniques, AttrE and MultiKE, have constant GPU memory usage, because it is determined by the size of mini-batches. Mul-tiKE uses more GPU memory than AttrE because Mul-tiKE is more complicated and computes more things. As the data size grows from 100K to 300K, the GPU memory usage of GNN-based techniques grows more than translation-based ones because it is O(M ). We are not able to run the two GNN-based techniques on the 600K dataset as the GPU memory on our server (32GB) is not enough. In summary, translation-based techniques are more scalable than GNN-based ones in practice. We observe that the growth of running time and GPU memory usage of GNN-based techniques is sub-linear, which is due to great sparsity of the graphs. The inference modules of all the techniques take two to three hours, much less than training. Table 9 shows the accuracy of the techniques as the dataset size grows. The accuracy of all the techniques degrades a little as the number of entities increases. This is because for the same entity in a KG, there are more entities in the other KG similar to it in the case of larger datasets, making it harder to predict the aligned entity correctly. Alignment on large-scale KGs. An interesting question is whether the algorithms can scale up to large-scale KGs such as Wikidata (95 million entities) with Freebase (86 million entities). In what follows, we estimate the running time for aligning large-scale KGs using the CPU and GPU servers available to us, which has 128GB CPU main memory and 32GB GPU memory. It turns out to be over 2000 days. We then give an idea of how one may do it within days if large numbers of GPU servers are available.\n\nAs we discussed earlier, GNN-based techniques require loading the whole graph into the GPU memory. The full Wikidata or Freebase KGs would require hundreds of GB memory to even store the embeddings of the entities, so we will not be able to do the experiment using GNN-based techniques. For translationbased techniques, the GPU memory used for training is constant. The total training time mainly consists of the time for the embedding module and the aligning module. The embedding time of translation-based models is proportional to M, the number of triples in the two KGs. The alignment time for techniques that use seed entity alignments such as MultiKE is proportional to |S|, the number of seed entity alignments. Our experiment has followed previous work to set |S| as a certain percentage of the total number of entities N, so the alignment time is also proportional to N. AttrE does not use seed alignments, and its alignment time is proportional to N, the number of entities in the two KGs. The training time for AttrE and MultiKE are 2.2 days for the 100K entities dataset as shown in Table 8. We have recorded the training time for the embedding and alignment modules, respectively, as shown in Table 10. Take AttrE as an example, the embedding time is 1.76 days and the alignment time is 0.44 days, which add up to 2.2 days.\n\nThere are totally 1,120M triples in Wikidata (782M triples) and Freebase (338M triples) together while there are 0.79M triples in the DW-NB-100K dataset, so the total embedding time for aligning Wiki-Freebase is 1.76 \u00d7 1, 120M/0.79M = 2495.2 days for AttrE. There  days. Therefore, using the academic resources available to us, it is impossible to run this experiment in practice. Large companies may have thousands of GPUs and run machine learning tasks in parallel. A straightforward approach to parallelize the algorithm is like the block nested-loop join algorithm. We may divide the two KGs into i and j blocks, and then align each of the i blocks with each of the j blocks. Every block pair to be aligned can be computed on a GPU server. This way, we may be able to perform the training of the alignment within days if we use thousands of GPU servers in parallel. Of course, there are details to be worked out in terms of how to coordinate all the nodes and deal with the effect that now the alignment is computed locally rather than globally. Another question is the accuracy of the algorithms at large-scale. The accuracy depends on a number of factors including: the alignment algorithms, the amount of seed entity alignments, the nature of the datasets, the embedding size, etc. We have seen from Table 5 that the accuracy increases with the amount of seed alignments, and can be above 95% for some of the cases. One approach to increase accuracy is enlarging the embedding size. We have conducted experiments for the effect of embedding size on the accuracy of the algorithms using the 100K DBpedia-Wikidata dataset, and the results are shown in Table 11. It shows how the accuracy of the different algorithms increases as the embedding size grows from 128 dimensions to 512 dimensions. The accuracy increase plateaus after the number of dimensions is large enough.\n\n\nConclusions and Future Directions\n\nWe have provided a comprehensive tutorial-type survey on representative EA techniques that use the new approach of representation learning. We have presented a framework for capturing the key characteristics of these techniques, proposed a benchmark DWY-NB to address the limitation of existing benchmark datasets, and conducted extensive experiments using the proposed datasets. The experimental study shows the comparative performance of the techniques and how various factors affect the performance. An insight from the experiments is that making good use of semantic information such as attribute triples improves the accuracy significantly. AttrE and MultiKE consistently perform the best in various settings of our experiments.\n\nFuture Directions. In terms of the benchmark, more experimental settings may be further explored such as varying the proportion of entities with the same name (i.e., the proportion of the \"tricky\" feature), and the ratio between relation triples and attribute triples.\n\nIn terms of the accuracy of EA techniques, we may improve via pre-training. Pre-training has been very successful in NLP but its use in knowledge bases is limited to using pre-trained word embeddings for initializing entity name features. There is still huge potential of innovative ways of pre-training. For example, pretrained predicate embeddings may be computed based on the predicate description to capture the semantics and similarity of predicates from different KGs. To train such embeddings, we may use transformer for relation prediction from relation descriptions, i.e., given a relation description, the model is trained to predict the corresponding relation. It may be further expanded into relation prediction between two entities, where the model takes the description of two entities and predicts the relations between the two entities.\n\nVarious components and strategies used by EA techniques may be improved following the analysis and discussions based on our framework. First, many translation-based EA techniques uses TransE as the KG structure embedding (cf. Table 2). We may explore replacing this component by improved versions of TransE such as TransD [Ji et al., 2015] and TransR [Lin et al., 2015b]. Second, many translation-based techniques use the same loss function as TransE (Equation 3). We may try the limit-based loss function (Equation 13) which has been reported to have better performance [Zhou et al., 2017]. Third, most of the existing EA techniques use seed alignments in the alignment module (cf. Figure 2), but seed alignments are expensive and difficult to obtain, so unsupervised EA techniques will be an attractive direction.\n\nIn terms of the efficiency and scalability of EA techniques, existing studies have mostly been conducted on small datasets. It is important to develop techniques that can conduct EA on very large KGs, improving on both efficiency and memory required.\n\nFig. 1\n1An example of EA.\n\n\na learnable weight matrix. To re-tain the difference between e i and its neighbors\n\n\nb , and M and b are the weight matrix and the bias.\n\nTable 1\n1Frequently Used SymbolsSymbols \nDescriptions \n\n(E, R, A, V, T ) A knowledge graph \n\nE \nA set of entities \n\nR \nA set of relation predicates \n\nA \nA set of attribute predicates \n\nV \nA set of attribute values which may be nu-\nmeric or literal \n\nT \nA set of triples, which may consist of rela-\ntion triples T r and attribute triples T a \n\n(h, r, t) \nA relation triple, which consists of a head \nentity h, a tail entity t, the relation predi-\ncate r between the entities \n\nh, r, t \nEmbeddings of the head entity, relation \npredicate and tail entity, respectively \n\n(e, a, v) \nAn attribute triple, which consists of an en-\ntity e, an attribute predicate a and the at-\ntribute value v \n\ne, a, v \nEmbeddings of an entity, attribute predi-\ncate and attribute value, respectively \n\nf triple \nTriple score function \n\nf align \nAlignment score function \n\n\u03c3 \nAn non-linear activation function \n\nS \nA set of pre-aligned entities from G 1 and G 2 \n\nS \nA set of corrupted entity alignments from \nG 1 and G 2 \n\nT r \nA set of corrupted relation triples \n\nConcatenation of two vectors \n\n\n\n\nFig. 2 Framework of embedding-based EA techniques. Dashed lines indicate optional parts.interaction \nEmbedding module \nAlignment module \nSeed entity alignments \nAttributes \n\nRelation predicates \n\nKG 1 \n\nKG structure \n(Seed) attribute alignments \n\nKG 2 \n\nOutput: KG embeddings \n(entities, entity pairs, relation \npredicates, attributes, etc) \nAligned entities \n\nbootstrapping \n\nEA inference module \n\nEA training modules \n(Seed) relation predicate \n\nalignments \n\nInput features for \n\nEA training modules \n\nInput features for \nalignment module \n\n\n\nTable 2 A\n2summary of embedding-based EA techniques (\"-\" means not applicable)Technique \nKG structure \nembedding \n\nKG \nstructure \n\nRelation predicates as \ninput features \n\nAttributes as input \nfeatures \n\nInput features for alignment \nmodule \n\nB. 1 \n\nMTransE (2017) \nTransE \nTriple \n-\n-\nSeed entity alignments; Seed \nrelation predicate alignments \n\n-\n\nIPTransE (2017) \nPTransE \nPath \n-\n-\nSeed entity alignments; Seed \nrelation predicate alignments \n\nJAPE (2017) \nModified TransE 2 \nTriple \n-\nData type of \nattribute value \n\nSeed entity alignments; Seed \nrelation triple alignments \n\n-\n\nBootEA (2018) \nModified TransE 2 \nTriple \n-\n-\nSeed entity alignments \n\nKDCoE (2018) \nTransE \nTriple \n-\nEntity description \nSeed entity alignments \n\nOTEA (2019) \nTransE \nTriple \n-\n-\nSeed entity alignments \n-\n\nSEA (2019) \nTransE \nTriple \n-\n-\nSeed entity alignments \n\nNAEA (2019) \nModified TransE 2 Neighborhood \n-\n-\nSeed entity alignments \n\nTransEdge (2019) \nTransEdge \nTriple \n-\n-\nSeed entity alignments \n\nSX19 (2019) \nTransE \nTriple \n-\n-\nSeed entity alignments; Seed \nrelation predicate alignments \n\n-\n\nAKE (2019) \nModified TransE 2 \nTriple \n-\n-\nSeed entity alignments \n-\n\nAttrE (2019) \nTransE \nTriple \nString of relation \npredicate \n\nAttribute triple as \nrelation triple; \nCharacter sequence \nof attribute value; \nString of attribute \npredicate \n\nAttribute triple as relation \ntriple; Character sequence of \nattribute value; String of \nattribute/relation predicate \n\n-\n\nMultiKE (2019) \nModified TransE 2 \nTriple \nString of relation \npredicate \n\nAttribute triple as \nrelation triple; \nString of attribute \npredicate/value; \nEntity name \n\nSeed entity alignments; \nRelation/attribute predicate \nalignments \n\n-\n\nCOTSAE (2020) \nTransE \nTriple \n-\nCharacter sequence \nof attribute \nvalue/predicate \n\nSeed entity alignments \n\nJarKA (2020) \nModified TransE 2 \nTriple \n-\nWord embeddings \nof attribute value \n\nSeed entity alignments; Seed \nrelation/attribute predicate \nalignments; Seed attribute \nvalue alignments \n\nGCN-Align (2018) \nGCN \nNeighborhood \n-\nAttribute triple as \nrelation triple \n\nSeed entity alignments \n-\n\nHMAN (2019) \nGCN \nNeighborhood Bag-of-words of relation \npredicate \n\nBag-of-words of \nattribute value; \nEntity description \n\nSeed entity alignments \n-\n\nAVR-GCN (2019) \nVR-GCN \nNeighborhood \n-\n-\nSeed entity alignments; Seed \nrelation predicate alignments \n\n-\n\nHGCN (2019) \nGCN \nNeighborhood \n-\nEntity name \nSeed entity alignments, \nRelation predicate alignments \n\n-\n\nRDGCN (2019) \nDPGGNN \nNeighborhood \n-\nEntity name \nSeed entity alignments \n-\n\nGMNN (2019) \nGCN \nNeighborhood \n-\nEntity name \nSeed entity alignments \n-\n\nMuGNN (2019) \nGCN \nNeighborhood \n-\n-\nSeed entity alignments; Seed \nrelation predicate alignments \n\n-\n\nNMN (2020) \nGCN \nNeighborhood \n-\nEntity name \nSeed entity alignments \n-\n\nCG-MuAlign (2020) \nCollectiveAGG \nNeighborhood \n-\n-\nSeed entity alignments \n-\n\nCEA (2020) \nGCN \nNeighborhood \n-\nEntity name \nSeed entity alignments \n-\n\nSSP (2020) \nGCN \nNeighborhood \n-\n-\nSeed entity alignments \n-\n\nXS20 (2020) \nGCN \nNeighborhood \n-\nEntity name \nSeed entity alignments \n-\n\nKECG (2019) \nGAT+TransE \nNeighborhood \n-\n-\nSeed entity alignments \n-\n\nAliNet (2020) \nGAT \nPath \n-\n-\n-\n\nAttrGNN (2020) \nGAT \nNeighborhood \n-\nString of attribute \nvalue; Entity name \n\nSeed entity alignments \n-\n\nMRAEA (2020) \nGAT \nNeighborhood \nString of relation \npredicate; Direction of \nrelation predicate \n\nEntity name \nSeed entity alignments \n\nEPEA (2020) \nGAT \nNeighborhood \n-\nString of attribute \nvalue; Entity name \n\n\n\nTable 3\n3Dataset/Benchmark comparisons.Name \nNon-\nBijection \n\nName \nvariety \n\nSize* \nLanguage \n\nDBP15K \n\nTable 4\n4Statistics of our proposed benchmark DWY-NB.Subset \nUnique \nentities \n\nAligned \nentities \n\nPredicates Relationship \ntriples \n\nAttribute \ntriples \n\nDW-NB \n\nDBpedia \n84,911 \n50,000 \n545 \n203,502 \n221,591 \nWikidata \n86,116 \n703 \n198,797 \n223,232 \n\nDY-NB \n\nDBpedia \n58,858 \n15,000 \n211 \n87,676 \n173,520 \nYago \n60,228 \n91 \n66,546 \n186,328 \n\n\n\nTable 5\n5Experiment 1: The effect of the amount of seed entity alignments on EA accuracy in terms of Hits@k (%)Fig. 3Experiment 2: Using attributes vs. Not using attributes (sorted by performance of \"using-attribute\" version).1986-07-02) and (dbp:Ali Lohan, birth date, 1993-12-22) to distinguish them. Such cases are very common in the two KGs. Experiment 3: the effect of the alignment module on KG embeddings. The training in EA techniques optimize for two objectives, the KG embeddings and the alignment of two KGs (either jointly or alternatively), rather than merely the KG embeddings, so it might not produce the best KG embeddings. This experiment evaluates how the quality of the KG embeddings obtained from EA techniques are affected compared to the KG embeddings obtained from pure KG embedding techniques (TransE for translation-based and GCN for GNN-based techniques) via downstream applications of KGs. Following previous studies in EA techniquesTechnique \n\nSeed: 10% \nSeed: 20% \nSeed: 30% \nSeed: 40% \nSeed: 50% \n\nHits@1 Hits@10 Hits@1 Hits@10 Hits@1 Hits@10 Hits@1 Hits@10 Hits@1 Hits@10 \n\nDW-NB \n\nTranslation-based \nMTransE \n2.82 \n10.45 \n5.42 \n18.72 \n7.88 \n25.75 \n10.42 \n31.44 \n12.98 \n36.00 \nIPTransE \n5.98 \n13.45 \n7.54 \n18.78 \n12.90 \n24.61 \n16.32 \n32.86 \n23.54 \n35.98 \nBootEA \n8.12 \n16.15 \n12.54 \n20.13 \n17.92 \n28.38 \n21.46 \n35.16 \n25.44 \n37.57 \nTransEdge \n22.98 \n48.12 \n38.29 \n56.22 \n45.27 \n68.95 \n49.26 \n75.25 \n54.85 \n79.68 \nJAPE \n4.62 \n7.87 \n8.62 \n14.43 \n12.57 \n19.96 \n17.20 \n27.32 \n19.91 \n30.63 \nMultiKE \n80.25 \n87.58 \n82.56 \n88.92 \n84.06 \n90.05 \n84.87 \n91.24 \n85.21 \n95.06 \nAttrE \n87.98 \n95.80 \n87.98 \n95.80 \n87.98 \n95.80 \n87.98 \n95.80 \n87.98 \n95.80 \n\nGNN-based \n\nMuGNN \n13.49 \n37.79 \n20.96 \n49.28 \n26.92 \n56.77 \n31.09 \n61.43 \n34.41 \n64.96 \nAliNet \n14.58 \n31.46 \n18.55 \n35.84 \n24.34 \n50.46 \n28.39 \n55.46 \n35.31 \n58.22 \nKECG \n18.95 \n34.17 \n24.32 \n40.78 \n30.24 \n48.66 \n35.29 \n52.12 \n39.40 \n62.31 \nGCN-Align \n12.40 \n30.18 \n20.04 \n41.56 \n24.76 \n48.52 \n29.02 \n53.43 \n31.80 \n56.20 \nHGCN \n58.08 \n62.15 \n63.14 \n68.15 \n78.97 \n86.51 \n84.25 \n90.75 \n88.54 \n91.54 \nGMNN \n71.32 \n74.24 \n75.34 \n79.23 \n80.98 \n82.23 \n82.67 \n85.87 \n84.59 \n88.64 \nRDGCN \n59.22 \n62.98 \n64.22 \n68.98 \n79.02 \n87.12 \n85.34 \n90.45 \n88.21 \n93.23 \nCEA \n50.13 \n52.31 \n63.25 \n64.12 \n80.32 \n84.21 \n84.34 \n85.54 \n86.58 \n88.34 \nMRAEA \n53.75 \n54.74 \n64.58 \n66.12 \n81.54 \n85.97 \n83.54 \n86.02 \n84.06 \n87.55 \nNMN \n51.45 \n59.78 \n68.21 \n72.54 \n84.03 \n88.21 \n85.65 \n90.54 \n88.69 \n95.46 \n\nDY-NB \n\nTranslation-based \nMTransE \n0.01 \n0.15 \n0.01 \n0.39 \n0.08 \n0.68 \n0.08 \n1.39 \n0.13 \n1.89 \nIPTransE \n1.54 \n9.87 \n5.67 \n25.76 \n14.55 \n36.45 \n15.77 \n45.81 \n17.33 \n52.18 \nBootEA \n2.15 \n14.19 \n8.47 \n38.15 \n15.77 \n48.32 \n17.22 \n57.15 \n19.24 \n58.14 \nTransEdge \n22.98 \n47.50 \n37.85 \n64.85 \n48.98 \n72.15 \n58.95 \n76.54 \n62.49 \n78.54 \nJAPE \n0.70 \n1.83 \n1.57 \n3.37 \n1.40 \n3.27 \n1.37 \n1.77 \n2.37 \n4.97 \nMultiKE \n81.87 \n88.05 \n82.11 \n89.26 \n84.97 \n90.84 \n87.22 \n92.05 \n89.25 \n93.58 \nAttrE \n90.44 \n94.23 \n90.44 \n94.23 \n90.44 \n94.23 \n90.44 \n94.23 \n90.44 \n94.23 \n\nGNN-based \n\nMuGNN \n19.16 \n51.41 \n27.40 \n62.69 \n31.60 \n68.56 \n34.73 \n71.24 \n37.15 \n74.07 \nAliNet \n13.54 \n28.53 \n14.25 \n31.69 \n25.39 \n58.31 \n28.98 \n56.12 \n34.59 \n64.12 \nKECG \n11.19 \n23.65 \n14.89 \n27.25 \n20.95 \n34.48 \n22.81 \n35.44 \n24.71 \n37.15 \nGCN-Align \n8.56 \n25.09 \n17.88 \n43.88 \n24.36 \n53.43 \n31.29 \n62.44 \n33.56 \n67.88 \nHGCN \n52.54 \n64.51 \n65.87 \n77.40 \n71.14 \n85.64 \n71.45 \n85.64 \n74.54 \n87.48 \nGMNN \n62.34 \n70.34 \n64.32 \n67.34 \n75.57 \n77.47 \n78.65 \n82.65 \n82.34 \n85.62 \nRDGCN \n53.13 \n65.30 \n67.28 \n78.21 \n74.54 \n85.22 \n77.45 \n87.43 \n78.67 \n89.45 \nCEA \n55.24 \n58.97 \n64.35 \n65.42 \n74.56 \n78.42 \n77.78 \n80.95 \n78.91 \n83.24 \nMRAEA \n52.46 \n53.20 \n60.33 \n64.54 \n73.71 \n78.52 \n74.25 \n78.66 \n76.22 \n80.15 \nNMN \n55.74 \n64.78 \n62.54 \n70.54 \n75.87 \n80.54 \n84.55 \n88.69 \n90.78 \n94.77 \n\n* Techniques that use attribute triples are underlined. The rest tables and figures follow this convention. \n* AttrE does not use any seed alignments. \n\nMTransE \nJAPE \nIPTransE \nBootEA \nGCN-Align \nAliNet \nKECG \nMuGNN \nTransEdge \nHGCN \nRDGCN \nCEA \nGMNN \nMRAEA \nNMN \nMultiKE \nAttrE \n\n0 \n20 \n40 \n60 \n80 \n100 \n\nDW-NB \n\nhits@1 \n\nMTransE \nJAPE \nBootEA \nIPTransE \nKECG \nGCN-Align \nAliNet \nTransEdge \nMuGNN \nHGCN \nMRAEA \nRDGCN \nCEA \nGMNN \nNMN \nMultiKE \nAttrE \n\n0 \n20 \n40 \n60 \n80 \n100 \n\nDY-NB \n\nhits@1 \n\nNot using attribute \nUsing attribute \n\n\n\nTable 6\n6Experiment 3: effects on downstream tasks.mance in downstream tasks depending on the paradigm of KG structure embeddings, details provided in previous paragraphs.Experiment 4: Multilinguality. This experiment evaluates how various techniques perform on multilingual KGs with the approach of first translating into the same language. Following previous studies we use the multilingual dataset SRPRS multi, which contains two KG pairs EN-DE and EN-FR. To translate the attribute triples into English, we use a popular open-source translation tool Fairseq[Ott et al., 2019]. For each technique we run a version \"not using attributes\" (the original techniques) and a version \"using attributes\" (the translation approach). The results are shown inTable 7. All the techniques have significant improvement by using attributes via the translation approach, including the techniques that can perform multilingual EA by design (mostly all the GNN-based techniques). AttrE and MultiKE are not designed for multilingual EA, but via the translation approach both have comparable performance to the techniques designed for multilingual EA. These validate our argument that techniques designed for monolingual EA can perform multilingual EA well by exploiting semantic information (such as attributes) and automatic translation.Experiment 5: Scalability. This experiment evaluates how various techniques perform as data sizes grow. We use the same way described in Section 7.3 to create EA datasets with varying numbers of entities 100K,Technique \n\nDBP-WD (seed) \nDBP-YAGO (seed) \n\n(10%) (30%) (50%) (10%) (30%) (50%) \n\nLink Prediction (Evaluating Translation-based Models) \n\nMultiKE \n88.76 88.98 89.52 \n98.62 98.87 \n98.07 \nAttrE \n88.50 \n88.50 \n88.50 98.75 \n98.75 98.75 \nTransE* \n87.45 \n87.45 \n87.45 \n98.42 \n98.42 \n98.42 \nTransEdge \n85.27 \n85.71 \n86.40 \n93.24 \n93.54 \n93.76 \nJAPE \n83.24 \n83.71 \n83.09 \n75.03 \n75.32 \n75.66 \nIPTransE \n81.06 \n81.23 \n81.78 \n93.10 \n93.55 \n93.91 \nBootEA \n80.41 \n80.90 \n81.66 \n94.11 \n94.54 \n94.85 \nMTransE \n80.10 \n80.33 \n80.69 \n93.81 \n94.31 \n94.74 \n\nNode Classification (Evaluating GNN-based Models) \n\nGCN* \n64.93 64.93 64.93 68.21 68.21 68.21 \nNMN \n62.25 \n62.74 \n62.85 \n66.46 \n66.57 \n66.79 \nCEA \n60.06 \n60.24 \n60.39 \n65.95 \n66.31 \n66.66 \nMRAEA \n57.95 \n58.34 \n58.56 \n65.77 \n65.87 \n66.37 \nGCN-Align \n54.05 \n54.52 \n54.93 \n61.54 \n62.03 \n62.37 \nHGCN \n53.93 \n54.11 \n54.59 \n65.79 \n66.24 \n66.48 \nGMNN \n52.21 \n52.36 \n52.67 \n67.63 \n67.87 \n67.95 \nMuGNN \n51.63 \n51.96 \n52.46 \n43.16 \n43.45 \n43.58 \nRDGCN \n51.31 \n51.46 \n51.86 \n56.80 \n57.00 \n57.28 \nKECG \n44.83 \n45.19 \n45.50 \n57.75 \n58.12 \n58.45 \nAlinet \n42.68 \n42.98 \n43.16 \n37.96 \n38.45 \n38.72 \n\n* baseline \n\n\n\nTable 7\n7Effects of multilingual KGs300K, and 600K in each KG of the KG pair. The sources of the pair of KGs are DBpedia and Wikidata, so we call them DW-NB-100K, DW-NB-300K and DW-NB-600K, respectively. We have addressed the bijection and name variety problems in them such that the numbers of seed entity alignments are around 50K, 150K, and 300K, respectively. For each dataset, we use 30% of the aligned entities for training. We focus our experiments on four representative techniques, AttrE, Mul-tiKE, NMN and MRAEA, the top-2 from translationand GNN-based techniques on the DW-NB dataset. Theoretical analysis. For simplicity, suppose both KGs have a similar number of entities N . Let M denote the total number of triples (i.e., the number of edges) in the two KGs; then M is N 2 in the worst case but M << N 2 in practice as the graph is sparse.The inference module is typically via NNS or similar operations, which has the time/space cost of O(N ) for each entity; for for aligning all the entities, the time cost is O(N 2 ) and space cost is O(N ).The training module includes an embedding module and an alignment module. The time/space cost for the embedding module is O(M ) as it iterates through all the triples in the two KGs as well as a fixed number of negative samples per positive sample (i.e. per triple). The time/space cost of the alignment module depends on the algorithm. Most techniques iterate through the seed entity alignments and optionally a fixed number of negative alignment samples per seed entity alignment, so the cost is O(|S|), where |S| is the number of seed entity alignments. AttrE is a special case as it does not use seeds; its cost is O(N ) according to Equation 5.2. The space cost of alignment is O(N ). The space cost for the training is O(N ).Technique \n\nHits@1 \n\nNot using attributes \nUsing attribute \n\nEN-DE \nEN-FR \nEN-DE EN-FR \n\nMTransE \n14.51 \n8.58 \n21.78 \n13.31 \nIPTransE \n8.09 \n9.45 \n12.80 \n14.46 \nBootEA \n24.67 \n35.20 \n36.66 \n51.50 \nTransEdge \n27.53 \n37.81 \n40.11 \n55.21 \nMuGNN \n15.61 \n19.44 \n23.22 \n28.81 \nAlinet \n14.07 \n18.36 \n20.82 \n27.30 \nKECG \n20.90 \n20.34 \n31.24 \n30.28 \nJAPE \n15.86 \n19.90 \n24.00 \n29.44 \nMultiKE \n46.53 \n41.78 \n67.56 \n60.56 \nAttrE \n14.55 \n12.83 \n64.74 \n56.79 \nGCN-Align \n21.18 \n30.86 \n31.10 \n45.38 \nHGCN \n46.78 \n38.25 \n67.76 \n55.91 \nGMNN \n46.53 \n38.09 \n67.63 \n55.28 \nRDGCN \n46.06 \n39.77 \n66.72 \n57.95 \nCEA \n46.72 \n43.97 \n67.83 \n63.83 \nMRAEA \n47.67 \n43.25 \n69.13 \n62.67 \nNMN \n48.08 \n42.96 \n69.47 \n62.72 \n\n\n\nTable 8\n8Running time and GPU memory vs. dataset sizesTechnique \n\nRunning time (days) \nGPU memory usage (GB) \n\n100K 300K \n600K \n100K 300K \n600K \n\nAttrE \n2.2 \n5.6 \n10.9 \n4.5 \n4.5 \n4.5 \nMultiKE \n2.2 \n6.0 \n11.5 \n7.3 \n7.3 \n7.3 \nNMN \n2.8 \n6.1 \nN/A \n11.2 \n28.6 \nN/A \nMRAEA \n2.5 \n5.7 \nN/A \n11.5 \n28.6 \nN/A \n\n\n\nTable 9\n9Accuracy vs. dataset sizesTechnique \n\n100K \n300K \n600K \n\nHits@1 Hits@10 Hits@1 Hits@10 Hits@1 Hits@10 \n\n\nTable 10\n10Estimate of the training time (days) for aligning Wikidata and Freebase Technique DW-NB-100K Wikidata&FreebaseEmbedding Alignment Total \nTraining time \n\nAttrE \n1.76 \n0.44 \n2.2 \n1.76 \u00d7 1120M/0.79M + 0.44 \u00d7 184M/0.2M = 2, 900 \nMultiKE \n1.88 \n0.32 \n2.2 \n1.88 \u00d7 1120M/0.79M + 0.32 \u00d7 184M/0.2M = 2, 960 \n\n\n\nTable 11\n11Experiments on embedding size (DW-NB-100K) are totally 184M entities in Wikidata (98M entities) and Freebase (86M entities) while there are 0.2M entities in 100K dataset, so the alignment module running time for AttrE is 0.44 \u00d7 184M/0.2M = 404.8 days. The total training time for AttrE is 1.76 \u00d7 1120M/0.79M + 0.44 \u00d7 184M/0.2M = 2, 900 days. We can estimate the training time for MultiKE similarly as 1.88 \u00d7 1120M/0.79M + 0.32 \u00d7 184M/0.2M = 2, 960Technique \n\n128 \n256 \n512 \n\nThe column \"B.\" indicates whether the technique uses bootstrapping. 2 \"Modified TransE\" proposed in different papers may differ from each other.\nRui Zhang et al.   \nAcknowledgements We would like to thank the anonymous reviewers whose comments have greatly helped improve this paper.\nDbpedia: A nucleus for a web of open data. S Auer, C Bizer, G Kobilarov, J Lehmann, R Cyganiak, Z G Ives, Auer S, Bizer C, Kobilarov G, Lehmann J, Cyganiak R, Ives ZG (2007) Dbpedia: A nucleus for a web of open data. In: ISWC 2007\n\nEntity resolution in graphs. I Bhattacharya, L Getoor, Mining Graph Data. 13Bhattacharya I, Getoor L (2006) Entity resolution in graphs. Mining Graph Data 13:311-344\n\nFreebase: a collaboratively created graph database for structuring human knowledge. K D Bollacker, C Evans, P Paritosh, T Sturge, J Taylor, Bollacker KD, Evans C, Paritosh P, Sturge T, Taylor J (2008) Freebase: a collaboratively created graph database for structuring human knowledge. In: SIG- MOD 2008\n\nTranslating embeddings for modeling multi-relational data. A Bordes, N Usunier, A Garcia-Duran, J Weston, O Yakhnenko, NeurIPSBordes A, Usunier N, Garcia-Duran A, Weston J, Yakhnenko O (2013) Translating embeddings for modeling multi-relational data. In: NeurIPS 2013\n\nMultichannel graph neural network for entity alignment. Y Cao, Z Liu, C Li, Z Liu, J Li, T S Chua, ACL 2019. Cao Y, Liu Z, Li C, Liu Z, Li J, Chua TS (2019) Multi- channel graph neural network for entity alignment. In: ACL 2019\n\nJarka: Modeling attribute interactions for crosslingual knowledge alignment. B Chen, J Zhang, X Tang, H Chen, C Li, PAKDD 2020Chen B, Zhang J, Tang X, Chen H, Li C (2020) Jarka: Modeling attribute interactions for cross- lingual knowledge alignment. In: PAKDD 2020\n\nMultilingual knowledge graph embeddings for cross-lingual knowledge alignment. M Chen, Y Tian, M Yang, C Zaniolo, Chen M, Tian Y, Yang M, Zaniolo C (2017) Multilin- gual knowledge graph embeddings for cross-lingual knowledge alignment. In: IJCAI 2017\n\nCo-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment. M Chen, Y Tian, K Chang, S Skiena, C Zaniolo, IJCAI 2018. Chen M, Tian Y, Chang K, Skiena S, Zaniolo C (2018) Co-training embeddings of knowledge graphs and en- tity descriptions for cross-lingual entity alignment. In: IJCAI 2018\n\nSupport-vector networks. C Cortes, V Vapnik, Machine learning. 203Cortes C, Vapnik V (1995) Support-vector networks. Machine learning 20(3):273-297\n\nBERT: pre-training of deep bidirectional transformers for language understanding. J Devlin, M Chang, K Lee, K Toutanova, 2019Devlin J, Chang M, Lee K, Toutanova K (2019) BERT: pre-training of deep bidirectional transformers for language understanding. In: NAACL 2019\n\nKnowledge vault: A web-scale approach to probabilistic knowledge fusion. X Dong, E Gabrilovich, G Heitz, W Horn, N Lao, K Murphy, T Strohmann, S Sun, W Zhang, SIGKDD 2014. Dong X, Gabrilovich E, Heitz G, Horn W, Lao N, Murphy K, Strohmann T, Sun S, Zhang W (2014) Knowledge vault: A web-scale approach to probabilis- tic knowledge fusion. In: SIGKDD 2014\n\nUsing entity information from a knowledge base to improve relation extraction. L Du, A Kumar, M Johnson, M Ciaramita, ALTADu L, Kumar A, Johnson M, Ciaramita M (2015) Using entity information from a knowledge base to improve relation extraction. In: ALTA 2015\n\nThe Microsoft Academic Knowledge Graph: A Linked Data Source with 8 Billion Triples of Scholarly Data. M F\u00e4rber, 2019F\u00e4rber M (2019) The Microsoft Academic Knowledge Graph: A Linked Data Source with 8 Billion Triples of Scholarly Data. In: ISWC 2019\n\nA theory for record linkage. I P Fellegi, A B Sunter, JASA. 64328Fellegi IP, Sunter AB (1969) A theory for record link- age. JASA 1969 64(328):1183-1210\n\nRdf-ai: an architecture for rdf datasets matching, fusion and interlink. S Francois, L Y Francois, Z Chuguang, IJCAI Workshop. Francois S, Francois LY, Chuguang Z (2009) Rdf-ai: an architecture for rdf datasets matching, fusion and interlink. In: IJCAI Workshop 2009\n\nFast rule mining in ontological knowledge bases with AMIE+. L Gal\u00e1rraga, C Teflioudi, K Hose, F M Suchanek, VLDBJ 2015. 246Gal\u00e1rraga L, Teflioudi C, Hose K, Suchanek FM (2015) Fast rule mining in ontological knowledge bases with AMIE+. VLDBJ 2015 24(6):707-730\n\nNeural message passing for quantum chemistry. J Gilmer, S S Schoenholz, P F Riley, O Vinyals, G E Dahl, 2017Gilmer J, Schoenholz SS, Riley PF, Vinyals O, Dahl GE (2017) Neural message passing for quantum chem- istry. In: ICML 2017\n\nLearning to exploit longterm relational dependencies in knowledge graphs. L Guo, Z Sun, W Hu, 2019Guo L, Sun Z, Hu W (2019) Learning to exploit long- term relational dependencies in knowledge graphs. In: ICML 2019\n\nYAGO2: A spatially and temporally enhanced knowledge base from wikipedia. J Hoffart, F M Suchanek, K Berberich, G Weikum, Artificial Intelligence. 194Hoffart J, Suchanek FM, Berberich K, Weikum G (2013) YAGO2: A spatially and temporally enhanced knowledge base from wikipedia. Artificial Intelligence 194:28-61\n\nKnowledge graph embedding via dynamic mapping matrix. G Ji, S He, L Xu, K Liu, J Zhao, Ji G, He S, Xu L, Liu K, Zhao J (2015) Knowledge graph embedding via dynamic mapping matrix. In: ACL 2015\n\nA survey on knowledge graphs: Representation, acquisition and applications. S Ji, S Pan, E Cambria, P Marttinen, P S Yu, CoRR abs/2002.00388Ji S, Pan S, Cambria E, Marttinen P, Yu PS (2020) A survey on knowledge graphs: Representation, acqui- sition and applications. CoRR abs/2002.00388\n\nDiscovering and maintaining links on the web of data. V Julius, B Christian, G Martin, K Georgi, Julius V, Christian B, Martin G, Georgi K (2009) Dis- covering and maintaining links on the web of data. In: ISWC 2009\n\nJourney of web search engines: Milestones, challenges & innovations. M Kathuria, C Nagpal, N Duhan, IJITCS. 12Kathuria M, Nagpal C, Duhan N (2016) Journey of web search engines: Milestones, challenges & innovations. IJITCS 2016 12:47-58\n\nSemi-supervised classification with graph convolutional networks. T N Kipf, M Welling, ICLR 2017Kipf TN, Welling M (2017) Semi-supervised classifi- cation with graph convolutional networks. In: ICLR 2017\n\nThe hungarian method for the assignment problem. H W Kuhn, 50 Years of Integer Programming. Kuhn HW (2010) The hungarian method for the assign- ment problem. In: 50 Years of Integer Programming 1958-2008\n\nCollective annotation of wikipedia entities in web text. S Kulkarni, A Singh, G Ramakrishnan, S Chakrabarti, Kulkarni S, Singh A, Ramakrishnan G, Chakrabarti S (2009) Collective annotation of wikipedia entities in web text. In: SIGKDD 2009\n\nSemisupervised entity alignment via joint knowledge embedding model and cross-graph model. C Li, Y Cao, L Hou, J Shi, J Li, T Chua, 2019Li C, Cao Y, Hou L, Shi J, Li J, Chua T (2019) Semi- supervised entity alignment via joint knowledge em- bedding model and cross-graph model. In: EMNLP 2019\n\nGuiding cross-lingual entity alignment via adversarial knowledge embedding. X Lin, H Yang, J Wu, C Zhou, B Wang, ICDM 2019. Lin X, Yang H, Wu J, Zhou C, Wang B (2019) Guiding cross-lingual entity alignment via adversarial knowl- edge embedding. In: ICDM 2019\n\nModeling relation paths for representation learning of knowledge bases. Y Lin, Z Liu, H Luan, M Sun, S Rao, S Liu, EMNLP 2015. Lin Y, Liu Z, Luan H, Sun M, Rao S, Liu S (2015a) Modeling relation paths for representation learning of knowledge bases. In: EMNLP 2015\n\nLearning entity and relation embeddings for knowledge graph completion. Y Lin, Z Liu, M Sun, Y Liu, X Zhu, AAAILin Y, Liu Z, Sun M, Liu Y, Zhu X (2015b) Learning entity and relation embeddings for knowledge graph completion. In: AAAI 2015\n\nExploring and evaluating attributes, values, and structures for entity alignment. Z Liu, Y Cao, L Pan, J Li, T Chua, 2020Liu Z, Cao Y, Pan L, Li J, Chua T (2020) Exploring and evaluating attributes, values, and structures for entity alignment. In: EMNLP 2020\n\nMRAEA: an efficient and robust entity alignment approach for cross-lingual knowledge graph. X Mao, W Wang, H Xu, M Lan, Y Wu, WSDM 2020. Mao X, Wang W, Xu H, Lan M, Wu Y (2020) MRAEA: an efficient and robust entity alignment approach for cross-lingual knowledge graph. In: WSDM 2020\n\nEfficient estimation of word representations in vector space. T Mikolov, K Chen, G Corrado, J Dean, ICLR Workshop. Mikolov T, Chen K, Corrado G, Dean J (2013) Efficient estimation of word representations in vector space. In: ICLR Workshop 2013\n\nLimes: a time-efficient approach for large-scale link discovery on the web of data. Acn Ngomo, S Auer, IJCAI 2011. Ngomo ACN, Auer S (2011) Limes: a time-efficient ap- proach for large-scale link discovery on the web of data. In: IJCAI 2011\n\nGlobal structure and local semanticspreserved embeddings for entity alignment. H Nie, X Han, L Sun, C M Wong, Q Chen, S Wu, W Zhang, IJCAI 2020Nie H, Han X, Sun L, Wong CM, Chen Q, Wu S, Zhang W (2020) Global structure and local semantics- preserved embeddings for entity alignment. In: IJCAI 2020\n\nfairseq: A fast, extensible toolkit for sequence modeling. M Ott, S Edunov, A Baevski, A Fan, S Gross, N Ng, D Grangier, M Auli, NAACL-HLT 2019Ott M, Edunov S, Baevski A, Fan A, Gross S, Ng N, Grangier D, Auli M (2019) fairseq: A fast, extensible toolkit for sequence modeling. In: NAACL-HLT 2019\n\nSemisupervised entity alignment via knowledge graph embedding with awareness of degree difference. S Pei, L Yu, R Hoehndorf, X Zhang, Web Conference. Pei S, Yu L, Hoehndorf R, Zhang X (2019a) Semi- supervised entity alignment via knowledge graph em- bedding with awareness of degree difference. In: Web Conference 2019\n\nImproving cross-lingual entity alignment via optimal transport. S Pei, L Yu, X Zhang, IJCAI 2019. Pei S, Yu L, Zhang X (2019b) Improving cross-lingual entity alignment via optimal transport. In: IJCAI 2019\n\nG-crewe: Graph compression with embedding for network alignment. K K Qin, F D Salim, Y Ren, W Shao, M Heimann, D Koutra, CIKM 2020. Qin KK, Salim FD, Ren Y, Shao W, Heimann M, Koutra D (2020) G-crewe: Graph compression with embedding for network alignment. In: CIKM 2020\n\nSemi-supervised user geolocation via graph convolutional networks. A Rahimi, T Cohn, T Baldwin, Rahimi A, Cohn T, Baldwin T (2018) Semi-supervised user geolocation via graph convolutional networks. In: ACL 2018\n\nAutomatic interlinking of music datasets on the semantic web. Y Raimond, C Sutton, M B Sandler, WWW WorkshopRaimond Y, Sutton C, Sandler MB (2008) Automatic interlinking of music datasets on the semantic web. In: WWW Workshop 2008\n\nDeferred acceptance algorithms: history, theory, practice, and open questions. A E Roth, International Journal of Game Theory. 363-4Roth AE (2008) Deferred acceptance algorithms: his- tory, theory, practice, and open questions. Interna- tional Journal of Game Theory 36(3-4):537-569\n\nModeling multi-mapping relations for precise cross-lingual entity alignment. X Shi, Y Xiao, EMNLP 2019. Shi X, Xiao Y (2019) Modeling multi-mapping relations for precise cross-lingual entity alignment. In: EMNLP 2019\n\nProbabilistic alignment of relations, instances, and schema. F M Suchanek, S Abiteboul, P Senellart, PVLDBParisSuchanek FM, Abiteboul S, Senellart P (2011) Paris: Probabilistic alignment of relations, instances, and schema. In: PVLDB 2011\n\nCross-lingual entity alignment via joint attribute-preserving embedding. Z Sun, W Hu, C Li, 2017Sun Z, Hu W, Li C (2017) Cross-lingual entity align- ment via joint attribute-preserving embedding. In: ISWC 2017\n\nBootstrapping entity alignment with knowledge graph embedding. Z Sun, W Hu, Q Zhang, Y Qu, Sun Z, Hu W, Zhang Q, Qu Y (2018) Bootstrapping entity alignment with knowledge graph embedding. In: IJCAI 2018\n\nTransedge: Translating relation-contextualized embeddings for knowledge graphs. Z Sun, J Huang, W Hu, M Chen, L Guo, Y Qu, ISWC 2019. Sun Z, Huang J, Hu W, Chen M, Guo L, Qu Y (2019) Transedge: Translating relation-contextualized em- beddings for knowledge graphs. In: ISWC 2019\n\nKnowledge graph alignment network with gated multi-hop neighborhood aggregation. Z Sun, C Wang, W Hu, M Chen, J Dai, W Zhang, Y Qu, AAAI 2020Sun Z, Wang C, Hu W, Chen M, Dai J, Zhang W, Qu Y (2020a) Knowledge graph alignment network with gated multi-hop neighborhood aggregation. In: AAAI 2020\n\nA benchmarking study of embeddingbased entity alignment for knowledge graphs. Z Sun, Q Zhang, W Hu, C Wang, M Chen, F Akrami, C Li, 2020Sun Z, Zhang Q, Hu W, Wang C, Chen M, Akrami F, Li C (2020b) A benchmarking study of embedding- based entity alignment for knowledge graphs. In: VLDB 2020\n\nLearning object identification rules for information integration. S Tejada, C A Knoblock, S Minton, Information Systems. 268Tejada S, Knoblock CA, Minton S (2001) Learning ob- ject identification rules for information integration. Information Systems 26(8):607-633\n\nGTR-LSTM: A triple encoder for sentence generation from RDF data. B D Trisedya, J Qi, R Zhang, W Wang, Trisedya BD, Qi J, Zhang R, Wang W (2018) GTR- LSTM: A triple encoder for sentence generation from RDF data\n\nEntity alignment between knowledge graphs using attribute embeddings. B D Trisedya, J Qi, R Zhang, AAAI 2019. Trisedya BD, Qi J, Zhang R (2019a) Entity alignment between knowledge graphs using attribute embed- dings. In: AAAI 2019\n\nNeural relation extraction for knowledge base enrichment. B D Trisedya, G Weikum, J Qi, R Zhang, Korhonen A, Traum DR, M\u00e0rquez LTrisedya BD, Weikum G, Qi J, Zhang R (2019b) Neural relation extraction for knowledge base enrichment. In: Korhonen A, Traum DR, M\u00e0rquez L (eds) ACL\n\nGCP: Graph Encoder with Content-Planning for Sentence Generation from Knowledge Base. B D Trisedya, J Qi, W Wang, R Zhang, TPAMITrisedya BD, Qi J, Wang W, Zhang R (2021) GCP: Graph Encoder with Content-Planning for Sentence Generation from Knowledge Base. TPAMI\n\nAttention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, 2017Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser L, Polosukhin I (2017) Attention is all you need. In: NIPS 2017\n\nGraph attention networks. P Velickovic, G Cucurull, A Casanova, A Romero, P Li\u00f2, Y Bengio, Velickovic P, Cucurull G, Casanova A, Romero A, Li\u00f2 P, Bengio Y (2018) Graph attention networks. In: ICLR 2018\n\nAutomating the approximate record-matching process. V S Verykios, A K Elmagarmid, E N Houstis, Information Sciences. 1261-4Verykios VS, Elmagarmid AK, Houstis EN (2000) Au- tomating the approximate record-matching process. Information Sciences 126(1-4):83-98\n\nWikidata: a free collaborative knowledgebase. D Vrandecic, M Kr\u00f6tzsch, CACM. 5710Vrandecic D, Kr\u00f6tzsch M (2014) Wikidata: a free col- laborative knowledgebase. CACM 57(10):78-85\n\nKnowledge graph embedding: A survey of approaches and applications. Q Wang, Z Mao, B Wang, L Guo, 29Wang Q, Mao Z, Wang B, Guo L (2017) Knowledge graph embedding: A survey of approaches and appli- cations. TKDE 2017 29(12):2724-2743\n\nKnowledge graph embedding by translating on hyperplanes. Z Wang, J Zhang, J Feng, Z Chen, AAAIWang Z, Zhang J, Feng J, Chen Z (2014) Knowledge graph embedding by translating on hyperplanes. In: AAAI 2014\n\nCross-lingual knowledge graph alignment via graph convolutional networks. Z Wang, Q Lv, X Lan, Y Zhang, Wang Z, Lv Q, Lan X, Zhang Y (2018) Cross-lingual knowledge graph alignment via graph convolutional networks. In: EMNLP 2018\n\nKnowledge graph alignment with entity-pair embedding. Z Wang, J Yang, X Ye, 2020Wang Z, Yang J, Ye X (2020) Knowledge graph align- ment with entity-pair embedding. In: EMNLP 2020\n\nImage captioning and visual question answering based on attributes and external knowledge. Q Wu, C Shen, P Wang, A Dick, A Van Den Hengel, TPAMI. 4006Wu Q, Shen C, Wang P, Dick A, van den Hengel A (2018) Image captioning and visual question an- swering based on attributes and external knowledge. TPAMI 2018 40(06):1367-1381\n\nRelation-aware entity alignment for heterogeneous knowledge graphs. Y Wu, X Liu, Y Feng, Z Wang, R Yan, D Zhao, IJCAI 2019. Wu Y, Liu X, Feng Y, Wang Z, Yan R, Zhao D (2019a) Relation-aware entity alignment for heterogeneous knowledge graphs. In: IJCAI 2019\n\nJointly learning entity and relation representations for entity alignment. Y Wu, X Liu, Y Feng, Z Wang, D Zhao, 2019Wu Y, Liu X, Feng Y, Wang Z, Zhao D (2019b) Jointly learning entity and relation representations for entity alignment. In: EMNLP 2019\n\nNeighborhood matching network for entity alignment. Y Wu, X Liu, Y Feng, Z Wang, D Zhao, 2020Wu Y, Liu X, Feng Y, Wang Z, Zhao D (2020) Neigh- borhood matching network for entity alignment. In: ACL 2020\n\nA comprehensive survey on graph neural networks. Z Wu, S Pan, F Chen, G Long, C Zhang, P S Yu, TNNLS. 321Wu Z, Pan S, Chen F, Long G, Zhang C, Yu PS (2021) A comprehensive survey on graph neural networks. TNNLS 32(1):4-24\n\nFrom one point to a manifold: Knowledge graph embedding for precise link prediction. H Xiao, M Huang, X Zhu, IJCAI 2016. Xiao H, Huang M, Zhu X (2016a) From one point to a manifold: Knowledge graph embedding for precise link prediction. In: IJCAI 2016\n\nTransg : A generative model for knowledge graph embedding. H Xiao, M Huang, X Zhu, Xiao H, Huang M, Zhu X (2016b) Transg : A generative model for knowledge graph embedding. In: ACL 2016\n\nAn interpretable knowledge transfer model for knowledge base completion. Q Xie, X Ma, Z Dai, E H Hovy, 2017Xie Q, Ma X, Dai Z, Hovy EH (2017) An interpretable knowledge transfer model for knowledge base com- pletion. In: ACL 2017\n\nCross-lingual knowledge graph alignment via graph matching neural network. K Xu, L Wang, M Yu, Y Feng, Y Song, Z Wang, D Yu, ACL 2019. Xu K, Wang L, Yu M, Feng Y, Song Y, Wang Z, Yu D (2019a) Cross-lingual knowledge graph alignment via graph matching neural network. In: ACL 2019\n\nCoordinated reasoning for cross-lingual knowledge graph alignment. K Xu, L Song, Y Feng, Y Song, D Yu, AAAI 2020Xu K, Song L, Feng Y, Song Y, Yu D (2020) Coor- dinated reasoning for cross-lingual knowledge graph alignment. In: AAAI 2020\n\nEnd-to-end knowledge-routed relational dialogue system for automatic diagnosis. L Xu, Q Zhou, K Gong, X Liang, J Tang, L Lin, AAAI 2019. Xu L, Zhou Q, Gong K, Liang X, Tang J, Lin L (2019b) End-to-end knowledge-routed relational dialogue sys- tem for automatic diagnosis. In: AAAI 2019\n\nAligning cross-lingual entities with multi-aspect information. H Yang, Y Zou, P Shi, W Lu, J Lin, X Sun, EMNLP 2019. Yang H, Zou Y, Shi P, Lu W, Lin J, Sun X (2019) Aligning cross-lingual entities with multi-aspect in- formation. In: EMNLP 2019\n\nCOT-SAE: co-training of structure and attribute embeddings for entity alignment. K Yang, S Liu, J Zhao, Y Wang, B Xie, AAAI 2020. Yang K, Liu S, Zhao J, Wang Y, Xie B (2020a) COT- SAE: co-training of structure and attribute embed- dings for entity alignment. In: AAAI 2020\n\nGraphdialog: Integrating graph knowledge into end-to-end taskoriented dialogue systems. S Yang, R Zhang, S M Erfani, EMNLPYang S, Zhang R, Erfani SM (2020b) Graphdialog: Integrating graph knowledge into end-to-end task- oriented dialogue systems. In: EMNLP\n\nUnimf: A unified framework to incorporate multimodal knowledge bases intoend-to-end task-oriented dialogue systems. S Yang, R Zhang, S M Erfani, J H Lau, Yang S, Zhang R, Erfani SM, Lau JH (2021) Unimf: A unified framework to incorporate multimodal knowl- edge bases intoend-to-end task-oriented dialogue sys- tems. In: IJCAI\n\nA vectorized relational graph convolutional network for multirelational network alignment. R Ye, X Li, Y Fang, H Zang, M Wang, IJCAI 2019. Ye R, Li X, Fang Y, Zang H, Wang M (2019) A vector- ized relational graph convolutional network for multi- relational network alignment. In: IJCAI 2019\n\nACM: adaptive crossmodal graph convolutional neural networks for RGB-D scene recognition. Y Yuan, Z Xiong, Q Wang, AAAI 2019. Yuan Y, Xiong Z, Wang Q (2019) ACM: adaptive cross- modal graph convolutional neural networks for RGB- D scene recognition. In: AAAI 2019\n\nCollective entity alignment via adaptive features. W Zeng, X Zhao, J Tang, X Lin, 2020Zeng W, Zhao X, Tang J, Lin X (2020) Collective entity alignment via adaptive features. In: ICDE 2020\n\nCollaborative knowledge base embedding for recommender systems. F Zhang, N J Yuan, D Lian, X Xie, W Y Ma, SIGKDD 2016. Zhang F, Yuan NJ, Lian D, Xie X, Ma WY (2016) Collaborative knowledge base embedding for recom- mender systems. In: SIGKDD 2016\n\nMulti-view knowledge graph embedding for entity alignment. Q Zhang, Z Sun, W Hu, M Chen, L Guo, Y Qu, IJCAI 2019. Zhang Q, Sun Z, Hu W, Chen M, Guo L, Qu Y (2019) Multi-view knowledge graph embedding for entity alignment. In: IJCAI 2019\n\nAn industry evaluation of embedding-based entity alignment. Z Zhang, H Liu, J Chen, X Chen, B Liu, Y Xiang, Y Zheng, COLING 2020. Zhang Z, Liu H, Chen J, Chen X, Liu B, Xiang Y, Zheng Y (2020) An industry evaluation of embedding-based entity alignment. In: COLING 2020\n\nAn experimental study of state-of-the-art entity alignment approaches. X Zhao, W Zeng, J Tang, W Wang, F M Suchanek, TKDE. 2020Zhao X, Zeng W, Tang J, Wang W, Suchanek FM (2020) An experimental study of state-of-the-art en- tity alignment approaches. TKDE 2020 pp 1-1\n\nLearning knowledge embeddings by combining limit-based scoring loss. X Zhou, Q Zhu, P Liu, L Guo, CIKM 2017. Zhou X, Zhu Q, Liu P, Guo L (2017) Learning knowl- edge embeddings by combining limit-based scoring loss. In: CIKM 2017\n\nIterative entity alignment via joint knowledge embeddings. H Zhu, R Xie, Z Liu, M Sun, Zhu H, Xie R, Liu Z, Sun M (2017) Iterative entity alignment via joint knowledge embeddings. In: IJCAI 2017\n\nNeighborhood-aware attentional representation for multilingual knowledge graphs. Q Zhu, X Zhou, J Wu, J Tan, L Guo, IJCAI 2019. Zhu Q, Zhou X, Wu J, Tan J, Guo L (2019) Neighborhood-aware attentional representation for multilingual knowledge graphs. In: IJCAI 2019\n\nCollective multi-type entity alignment between knowledge graphs. Q Zhu, H Wei, B Sisman, D Zheng, C Faloutsos, X L Dong, J Han, Web Conference. Zhu Q, Wei H, Sisman B, Zheng D, Faloutsos C, Dong XL, Han J (2020) Collective multi-type entity align- ment between knowledge graphs. In: Web Conference 2020\n\nDual graph convolutional networks for graph-based semi-supervised classification. C Zhuang, Q Ma, Web Conference. Zhuang C, Ma Q (2018) Dual graph convolutional net- works for graph-based semi-supervised classification. In: Web Conference 2018\n", "annotations": {"author": "[{\"end\":114,\"start\":104},{\"end\":130,\"start\":115},{\"end\":176,\"start\":131},{\"end\":180,\"start\":177},{\"end\":223,\"start\":181},{\"end\":265,\"start\":224},{\"end\":276,\"start\":266},{\"end\":301,\"start\":277},{\"end\":315,\"start\":302},{\"end\":324,\"start\":316},{\"end\":336,\"start\":325},{\"end\":387,\"start\":337},{\"end\":403,\"start\":388}]", "publisher": null, "author_last_name": "[{\"end\":113,\"start\":108},{\"end\":129,\"start\":120},{\"end\":146,\"start\":142},{\"end\":191,\"start\":186},{\"end\":236,\"start\":234},{\"end\":275,\"start\":270},{\"end\":300,\"start\":282},{\"end\":314,\"start\":312},{\"end\":323,\"start\":321},{\"end\":335,\"start\":330}]", "author_first_name": "[{\"end\":107,\"start\":104},{\"end\":119,\"start\":115},{\"end\":139,\"start\":131},{\"end\":141,\"start\":140},{\"end\":179,\"start\":177},{\"end\":185,\"start\":181},{\"end\":233,\"start\":224},{\"end\":269,\"start\":266},{\"end\":281,\"start\":277},{\"end\":311,\"start\":302},{\"end\":320,\"start\":316},{\"end\":329,\"start\":325}]", "author_affiliation": "[{\"end\":386,\"start\":338},{\"end\":402,\"start\":389}]", "title": "[{\"end\":101,\"start\":1},{\"end\":504,\"start\":404}]", "venue": null, "abstract": "[{\"end\":1946,\"start\":779}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2522,\"start\":2503},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2557,\"start\":2533},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2586,\"start\":2564},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2669,\"start\":2650},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2698,\"start\":2684},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":3010,\"start\":2993},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":3027,\"start\":3010},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":3045,\"start\":3027},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":3064,\"start\":3045},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":3085,\"start\":3064},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":3108,\"start\":3085},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3148,\"start\":3125},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":3193,\"start\":3173},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3239,\"start\":3222},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":3262,\"start\":3239},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":5994,\"start\":5975},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":6012,\"start\":5994},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":6031,\"start\":6012},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":10731,\"start\":10708},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10748,\"start\":10731},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":10793,\"start\":10772},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10840,\"start\":10814},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11150,\"start\":11120},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":11194,\"start\":11171},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12001,\"start\":11978},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12125,\"start\":12104},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":12288,\"start\":12266},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":12375,\"start\":12352},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12594,\"start\":12572},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":17357,\"start\":17339},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":18420,\"start\":18396},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":21869,\"start\":21850},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":22048,\"start\":22024},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":23354,\"start\":23333},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":24659,\"start\":24639},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":25562,\"start\":25543},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":25578,\"start\":25562},{\"end\":25599,\"start\":25578},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":25687,\"start\":25669},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":25708,\"start\":25692},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":25906,\"start\":25889},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":26012,\"start\":25988},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":26074,\"start\":26049},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":26655,\"start\":26634},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":26978,\"start\":26954},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":28679,\"start\":28654},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":28771,\"start\":28749},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":30796,\"start\":30777},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":30827,\"start\":30806},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":30961,\"start\":30945},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":31289,\"start\":31268},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":31685,\"start\":31666},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":33748,\"start\":33729},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":35975,\"start\":35957},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":36993,\"start\":36972},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":37149,\"start\":37131},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":38294,\"start\":38276},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":39039,\"start\":39020},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":42307,\"start\":42288},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":42374,\"start\":42356},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":42515,\"start\":42496},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":43510,\"start\":43488},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":44559,\"start\":44540},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":44865,\"start\":44841},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":48556,\"start\":48539},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":49137,\"start\":49113},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":50066,\"start\":50046},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":51309,\"start\":51285},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":52710,\"start\":52692},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":53021,\"start\":53000},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":54318,\"start\":54300},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":56737,\"start\":56713},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":61085,\"start\":61073},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":61143,\"start\":61125},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":61413,\"start\":61396},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":62039,\"start\":62018},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":62168,\"start\":62150},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":62381,\"start\":62363},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":62679,\"start\":62667},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":63725,\"start\":63706},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":65103,\"start\":65085},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":71045,\"start\":71027},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":71437,\"start\":71419},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":72036,\"start\":72018},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":73460,\"start\":73442},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":73644,\"start\":73620},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":73775,\"start\":73757},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":73850,\"start\":73832},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":73959,\"start\":73935},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":74104,\"start\":74085},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":74752,\"start\":74722},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":74831,\"start\":74812},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":74863,\"start\":74841},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":75255,\"start\":75236},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":77532,\"start\":77513},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":77549,\"start\":77532},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":77565,\"start\":77549},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":83882,\"start\":83863},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":83900,\"start\":83882},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":84794,\"start\":84769},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":94400,\"start\":94383},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":94431,\"start\":94412},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":94651,\"start\":94632},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":105776,\"start\":105758}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":95155,\"start\":95129},{\"attributes\":{\"id\":\"fig_2\"},\"end\":95240,\"start\":95156},{\"attributes\":{\"id\":\"fig_3\"},\"end\":95294,\"start\":95241},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":96371,\"start\":95295},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":96917,\"start\":96372},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":100419,\"start\":96918},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":100524,\"start\":100420},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":100871,\"start\":100525},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":105195,\"start\":100872},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":107865,\"start\":105196},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":110348,\"start\":107866},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":110651,\"start\":110349},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":110765,\"start\":110652},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":111078,\"start\":110766},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":111565,\"start\":111079}]", "paragraph": "[{\"end\":3263,\"start\":1962},{\"end\":5102,\"start\":3265},{\"end\":6660,\"start\":5104},{\"end\":6816,\"start\":6662},{\"end\":7066,\"start\":6818},{\"end\":7467,\"start\":7068},{\"end\":8198,\"start\":7469},{\"end\":8829,\"start\":8216},{\"end\":9097,\"start\":8831},{\"end\":10181,\"start\":9121},{\"end\":10226,\"start\":10183},{\"end\":10262,\"start\":10228},{\"end\":10534,\"start\":10355},{\"end\":11045,\"start\":10582},{\"end\":11661,\"start\":11047},{\"end\":11762,\"start\":11663},{\"end\":12658,\"start\":11764},{\"end\":12877,\"start\":12660},{\"end\":13379,\"start\":12921},{\"end\":15135,\"start\":13381},{\"end\":15279,\"start\":15137},{\"end\":16206,\"start\":15281},{\"end\":18079,\"start\":16293},{\"end\":18767,\"start\":18081},{\"end\":19001,\"start\":18769},{\"end\":20166,\"start\":19003},{\"end\":20626,\"start\":20168},{\"end\":21066,\"start\":20628},{\"end\":21275,\"start\":21068},{\"end\":22331,\"start\":21277},{\"end\":22999,\"start\":22333},{\"end\":23129,\"start\":23033},{\"end\":23324,\"start\":23168},{\"end\":23939,\"start\":23326},{\"end\":25170,\"start\":23978},{\"end\":25744,\"start\":25257},{\"end\":27667,\"start\":25775},{\"end\":28621,\"start\":27713},{\"end\":29297,\"start\":28623},{\"end\":29931,\"start\":29423},{\"end\":30130,\"start\":29969},{\"end\":30329,\"start\":30178},{\"end\":30962,\"start\":30377},{\"end\":31616,\"start\":30998},{\"end\":32146,\"start\":31658},{\"end\":33136,\"start\":32190},{\"end\":33554,\"start\":33234},{\"end\":33597,\"start\":33556},{\"end\":34140,\"start\":33599},{\"end\":34412,\"start\":34142},{\"end\":34829,\"start\":34467},{\"end\":35362,\"start\":34882},{\"end\":35948,\"start\":35364},{\"end\":37281,\"start\":35950},{\"end\":37777,\"start\":37395},{\"end\":38269,\"start\":37832},{\"end\":39110,\"start\":38271},{\"end\":39466,\"start\":39259},{\"end\":39663,\"start\":39468},{\"end\":39821,\"start\":39720},{\"end\":39873,\"start\":39823},{\"end\":39987,\"start\":39911},{\"end\":40374,\"start\":39989},{\"end\":40801,\"start\":40376},{\"end\":41406,\"start\":40852},{\"end\":41628,\"start\":41467},{\"end\":41739,\"start\":41700},{\"end\":42208,\"start\":41741},{\"end\":42281,\"start\":42237},{\"end\":42827,\"start\":42283},{\"end\":43929,\"start\":42890},{\"end\":44170,\"start\":43931},{\"end\":44342,\"start\":44235},{\"end\":44532,\"start\":44425},{\"end\":44833,\"start\":44534},{\"end\":44993,\"start\":44835},{\"end\":45516,\"start\":44995},{\"end\":45750,\"start\":45518},{\"end\":46154,\"start\":45790},{\"end\":46327,\"start\":46196},{\"end\":46550,\"start\":46329},{\"end\":46695,\"start\":46552},{\"end\":46962,\"start\":46697},{\"end\":47104,\"start\":46964},{\"end\":47202,\"start\":47106},{\"end\":47384,\"start\":47269},{\"end\":47698,\"start\":47386},{\"end\":47873,\"start\":47739},{\"end\":48412,\"start\":47928},{\"end\":49027,\"start\":48414},{\"end\":49757,\"start\":49029},{\"end\":50037,\"start\":49759},{\"end\":50184,\"start\":50039},{\"end\":51564,\"start\":50212},{\"end\":52176,\"start\":51742},{\"end\":52381,\"start\":52178},{\"end\":52685,\"start\":52483},{\"end\":52924,\"start\":52687},{\"end\":53199,\"start\":52926},{\"end\":53966,\"start\":53289},{\"end\":54293,\"start\":53968},{\"end\":55298,\"start\":54295},{\"end\":56127,\"start\":55345},{\"end\":56505,\"start\":56129},{\"end\":56947,\"start\":56507},{\"end\":57040,\"start\":56949},{\"end\":57615,\"start\":57149},{\"end\":57726,\"start\":57617},{\"end\":58059,\"start\":57793},{\"end\":58661,\"start\":58089},{\"end\":58944,\"start\":58663},{\"end\":59927,\"start\":58946},{\"end\":60116,\"start\":59929},{\"end\":61086,\"start\":60118},{\"end\":62680,\"start\":61088},{\"end\":62881,\"start\":62708},{\"end\":63301,\"start\":62883},{\"end\":63697,\"start\":63303},{\"end\":64055,\"start\":63699},{\"end\":64426,\"start\":64057},{\"end\":64593,\"start\":64428},{\"end\":64982,\"start\":64652},{\"end\":65433,\"start\":65051},{\"end\":65956,\"start\":65435},{\"end\":66328,\"start\":65958},{\"end\":66747,\"start\":66375},{\"end\":67823,\"start\":66749},{\"end\":68457,\"start\":67825},{\"end\":68727,\"start\":68495},{\"end\":68910,\"start\":68764},{\"end\":69455,\"start\":68912},{\"end\":70852,\"start\":69457},{\"end\":72513,\"start\":70854},{\"end\":73335,\"start\":72515},{\"end\":74232,\"start\":73384},{\"end\":75761,\"start\":74266},{\"end\":76238,\"start\":75763},{\"end\":77408,\"start\":76240},{\"end\":79080,\"start\":77436},{\"end\":79385,\"start\":79082},{\"end\":79868,\"start\":79387},{\"end\":80554,\"start\":79870},{\"end\":81059,\"start\":80556},{\"end\":83313,\"start\":81061},{\"end\":85463,\"start\":83315},{\"end\":85763,\"start\":85465},{\"end\":87015,\"start\":85765},{\"end\":88948,\"start\":87017},{\"end\":90286,\"start\":88950},{\"end\":92164,\"start\":90288},{\"end\":92935,\"start\":92202},{\"end\":93205,\"start\":92937},{\"end\":94059,\"start\":93207},{\"end\":94876,\"start\":94061},{\"end\":95128,\"start\":94878}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10354,\"start\":10263},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16292,\"start\":16207},{\"attributes\":{\"id\":\"formula_2\"},\"end\":23977,\"start\":23940},{\"attributes\":{\"id\":\"formula_3\"},\"end\":25256,\"start\":25171},{\"attributes\":{\"id\":\"formula_4\"},\"end\":27712,\"start\":27668},{\"attributes\":{\"id\":\"formula_5\"},\"end\":29422,\"start\":29298},{\"attributes\":{\"id\":\"formula_6\"},\"end\":29968,\"start\":29932},{\"attributes\":{\"id\":\"formula_7\"},\"end\":30177,\"start\":30131},{\"attributes\":{\"id\":\"formula_8\"},\"end\":30376,\"start\":30330},{\"attributes\":{\"id\":\"formula_9\"},\"end\":32189,\"start\":32147},{\"attributes\":{\"id\":\"formula_10\"},\"end\":33233,\"start\":33137},{\"attributes\":{\"id\":\"formula_11\"},\"end\":34466,\"start\":34413},{\"attributes\":{\"id\":\"formula_12\"},\"end\":34881,\"start\":34830},{\"attributes\":{\"id\":\"formula_13\"},\"end\":37394,\"start\":37282},{\"attributes\":{\"id\":\"formula_14\"},\"end\":37831,\"start\":37778},{\"attributes\":{\"id\":\"formula_15\"},\"end\":39258,\"start\":39111},{\"attributes\":{\"id\":\"formula_16\"},\"end\":39719,\"start\":39664},{\"attributes\":{\"id\":\"formula_17\"},\"end\":39910,\"start\":39874},{\"attributes\":{\"id\":\"formula_18\"},\"end\":40851,\"start\":40802},{\"attributes\":{\"id\":\"formula_19\"},\"end\":41466,\"start\":41407},{\"attributes\":{\"id\":\"formula_20\"},\"end\":41699,\"start\":41629},{\"attributes\":{\"id\":\"formula_21\"},\"end\":42236,\"start\":42209},{\"attributes\":{\"id\":\"formula_22\"},\"end\":44234,\"start\":44171},{\"attributes\":{\"id\":\"formula_23\"},\"end\":44424,\"start\":44343},{\"attributes\":{\"id\":\"formula_24\"},\"end\":45789,\"start\":45751},{\"attributes\":{\"id\":\"formula_25\"},\"end\":46195,\"start\":46155},{\"attributes\":{\"id\":\"formula_26\"},\"end\":47268,\"start\":47203},{\"attributes\":{\"id\":\"formula_27\"},\"end\":47738,\"start\":47699},{\"attributes\":{\"id\":\"formula_28\"},\"end\":47927,\"start\":47874},{\"attributes\":{\"id\":\"formula_29\"},\"end\":51681,\"start\":51603},{\"attributes\":{\"id\":\"formula_30\"},\"end\":51741,\"start\":51681},{\"attributes\":{\"id\":\"formula_31\"},\"end\":52482,\"start\":52382},{\"attributes\":{\"id\":\"formula_32\"},\"end\":53238,\"start\":53200},{\"attributes\":{\"id\":\"formula_33\"},\"end\":53288,\"start\":53238},{\"attributes\":{\"id\":\"formula_34\"},\"end\":55344,\"start\":55299},{\"attributes\":{\"id\":\"formula_35\"},\"end\":57148,\"start\":57041},{\"attributes\":{\"id\":\"formula_36\"},\"end\":57792,\"start\":57727},{\"attributes\":{\"id\":\"formula_37\"},\"end\":58088,\"start\":58060},{\"attributes\":{\"id\":\"formula_38\"},\"end\":64651,\"start\":64594},{\"attributes\":{\"id\":\"formula_39\"},\"end\":65050,\"start\":64983},{\"attributes\":{\"id\":\"formula_40\"},\"end\":66374,\"start\":66329}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":8685,\"start\":8678},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":13876,\"start\":13869},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":19501,\"start\":19494},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":21297,\"start\":21290},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":22250,\"start\":22243},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22753,\"start\":22746},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":22983,\"start\":22974},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":70434,\"start\":70427},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":72772,\"start\":72765},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":77100,\"start\":77093},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":79725,\"start\":79718},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":84919,\"start\":84912},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":87046,\"start\":87039},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":88106,\"start\":88099},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":90052,\"start\":90045},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":90164,\"start\":90156},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":91602,\"start\":91595},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":91953,\"start\":91945},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":94294,\"start\":94287}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1960,\"start\":1948},{\"attributes\":{\"n\":\"2\"},\"end\":8214,\"start\":8201},{\"attributes\":{\"n\":\"2.1\"},\"end\":9119,\"start\":9100},{\"attributes\":{\"n\":\"2.2\"},\"end\":10580,\"start\":10537},{\"attributes\":{\"n\":\"3\"},\"end\":12919,\"start\":12880},{\"attributes\":{\"n\":\"4\"},\"end\":23031,\"start\":23002},{\"attributes\":{\"n\":\"4.1\"},\"end\":23166,\"start\":23132},{\"attributes\":{\"n\":\"4.2\"},\"end\":25773,\"start\":25747},{\"attributes\":{\"n\":\"5\"},\"end\":30996,\"start\":30965},{\"attributes\":{\"n\":\"5.1\"},\"end\":31656,\"start\":31619},{\"attributes\":{\"n\":\"5.2\"},\"end\":42888,\"start\":42830},{\"attributes\":{\"n\":\"6\"},\"end\":50210,\"start\":50187},{\"attributes\":{\"n\":\"6.1\"},\"end\":51590,\"start\":51567},{\"end\":51602,\"start\":51593},{\"attributes\":{\"n\":\"6.2\"},\"end\":62706,\"start\":62683},{\"attributes\":{\"n\":\"7\"},\"end\":68493,\"start\":68460},{\"attributes\":{\"n\":\"7.1\"},\"end\":68762,\"start\":68730},{\"attributes\":{\"n\":\"7.2\"},\"end\":73382,\"start\":73338},{\"attributes\":{\"n\":\"7.3\"},\"end\":74264,\"start\":74235},{\"attributes\":{\"n\":\"7.4\"},\"end\":77434,\"start\":77411},{\"attributes\":{\"n\":\"8\"},\"end\":92200,\"start\":92167},{\"end\":95136,\"start\":95130},{\"end\":95303,\"start\":95296},{\"end\":96928,\"start\":96919},{\"end\":100428,\"start\":100421},{\"end\":100533,\"start\":100526},{\"end\":100880,\"start\":100873},{\"end\":105204,\"start\":105197},{\"end\":107874,\"start\":107867},{\"end\":110357,\"start\":110350},{\"end\":110660,\"start\":110653},{\"end\":110775,\"start\":110767},{\"end\":111088,\"start\":111080}]", "table": "[{\"end\":96371,\"start\":95328},{\"end\":96917,\"start\":96462},{\"end\":100419,\"start\":96997},{\"end\":100524,\"start\":100460},{\"end\":100871,\"start\":100579},{\"end\":105195,\"start\":101833},{\"end\":107865,\"start\":106728},{\"end\":110348,\"start\":109657},{\"end\":110651,\"start\":110404},{\"end\":110765,\"start\":110688},{\"end\":111078,\"start\":110888},{\"end\":111565,\"start\":111538}]", "figure_caption": "[{\"end\":95155,\"start\":95138},{\"end\":95240,\"start\":95158},{\"end\":95294,\"start\":95243},{\"end\":95328,\"start\":95305},{\"end\":96462,\"start\":96374},{\"end\":96997,\"start\":96930},{\"end\":100460,\"start\":100430},{\"end\":100579,\"start\":100535},{\"end\":101833,\"start\":100882},{\"end\":106728,\"start\":105206},{\"end\":109657,\"start\":107876},{\"end\":110404,\"start\":110359},{\"end\":110688,\"start\":110662},{\"end\":110888,\"start\":110778},{\"end\":111538,\"start\":111091}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3870,\"start\":3862},{\"end\":13038,\"start\":13030},{\"end\":13845,\"start\":13837},{\"end\":17779,\"start\":17771},{\"end\":18688,\"start\":18680},{\"end\":81848,\"start\":81840},{\"end\":94753,\"start\":94744}]", "bib_author_first_name": "[{\"end\":111894,\"start\":111893},{\"end\":111902,\"start\":111901},{\"end\":111911,\"start\":111910},{\"end\":111924,\"start\":111923},{\"end\":111935,\"start\":111934},{\"end\":111947,\"start\":111946},{\"end\":111949,\"start\":111948},{\"end\":112112,\"start\":112111},{\"end\":112128,\"start\":112127},{\"end\":112334,\"start\":112333},{\"end\":112336,\"start\":112335},{\"end\":112349,\"start\":112348},{\"end\":112358,\"start\":112357},{\"end\":112370,\"start\":112369},{\"end\":112380,\"start\":112379},{\"end\":112613,\"start\":112612},{\"end\":112623,\"start\":112622},{\"end\":112634,\"start\":112633},{\"end\":112650,\"start\":112649},{\"end\":112660,\"start\":112659},{\"end\":112879,\"start\":112878},{\"end\":112886,\"start\":112885},{\"end\":112893,\"start\":112892},{\"end\":112899,\"start\":112898},{\"end\":112906,\"start\":112905},{\"end\":112912,\"start\":112911},{\"end\":112914,\"start\":112913},{\"end\":113129,\"start\":113128},{\"end\":113137,\"start\":113136},{\"end\":113146,\"start\":113145},{\"end\":113154,\"start\":113153},{\"end\":113162,\"start\":113161},{\"end\":113397,\"start\":113396},{\"end\":113405,\"start\":113404},{\"end\":113413,\"start\":113412},{\"end\":113421,\"start\":113420},{\"end\":113673,\"start\":113672},{\"end\":113681,\"start\":113680},{\"end\":113689,\"start\":113688},{\"end\":113698,\"start\":113697},{\"end\":113708,\"start\":113707},{\"end\":113929,\"start\":113928},{\"end\":113939,\"start\":113938},{\"end\":114135,\"start\":114134},{\"end\":114145,\"start\":114144},{\"end\":114154,\"start\":114153},{\"end\":114161,\"start\":114160},{\"end\":114394,\"start\":114393},{\"end\":114402,\"start\":114401},{\"end\":114417,\"start\":114416},{\"end\":114426,\"start\":114425},{\"end\":114434,\"start\":114433},{\"end\":114441,\"start\":114440},{\"end\":114451,\"start\":114450},{\"end\":114464,\"start\":114463},{\"end\":114471,\"start\":114470},{\"end\":114756,\"start\":114755},{\"end\":114762,\"start\":114761},{\"end\":114771,\"start\":114770},{\"end\":114782,\"start\":114781},{\"end\":115041,\"start\":115040},{\"end\":115218,\"start\":115217},{\"end\":115220,\"start\":115219},{\"end\":115231,\"start\":115230},{\"end\":115233,\"start\":115232},{\"end\":115416,\"start\":115415},{\"end\":115428,\"start\":115427},{\"end\":115430,\"start\":115429},{\"end\":115442,\"start\":115441},{\"end\":115671,\"start\":115670},{\"end\":115684,\"start\":115683},{\"end\":115697,\"start\":115696},{\"end\":115705,\"start\":115704},{\"end\":115707,\"start\":115706},{\"end\":115919,\"start\":115918},{\"end\":115929,\"start\":115928},{\"end\":115931,\"start\":115930},{\"end\":115945,\"start\":115944},{\"end\":115947,\"start\":115946},{\"end\":115956,\"start\":115955},{\"end\":115967,\"start\":115966},{\"end\":115969,\"start\":115968},{\"end\":116179,\"start\":116178},{\"end\":116186,\"start\":116185},{\"end\":116193,\"start\":116192},{\"end\":116394,\"start\":116393},{\"end\":116405,\"start\":116404},{\"end\":116407,\"start\":116406},{\"end\":116419,\"start\":116418},{\"end\":116432,\"start\":116431},{\"end\":116686,\"start\":116685},{\"end\":116692,\"start\":116691},{\"end\":116698,\"start\":116697},{\"end\":116704,\"start\":116703},{\"end\":116711,\"start\":116710},{\"end\":116902,\"start\":116901},{\"end\":116908,\"start\":116907},{\"end\":116915,\"start\":116914},{\"end\":116926,\"start\":116925},{\"end\":116939,\"start\":116938},{\"end\":116941,\"start\":116940},{\"end\":117169,\"start\":117168},{\"end\":117179,\"start\":117178},{\"end\":117192,\"start\":117191},{\"end\":117202,\"start\":117201},{\"end\":117401,\"start\":117400},{\"end\":117413,\"start\":117412},{\"end\":117423,\"start\":117422},{\"end\":117636,\"start\":117635},{\"end\":117638,\"start\":117637},{\"end\":117646,\"start\":117645},{\"end\":117824,\"start\":117823},{\"end\":117826,\"start\":117825},{\"end\":118037,\"start\":118036},{\"end\":118049,\"start\":118048},{\"end\":118058,\"start\":118057},{\"end\":118074,\"start\":118073},{\"end\":118312,\"start\":118311},{\"end\":118318,\"start\":118317},{\"end\":118325,\"start\":118324},{\"end\":118332,\"start\":118331},{\"end\":118339,\"start\":118338},{\"end\":118345,\"start\":118344},{\"end\":118591,\"start\":118590},{\"end\":118598,\"start\":118597},{\"end\":118606,\"start\":118605},{\"end\":118612,\"start\":118611},{\"end\":118620,\"start\":118619},{\"end\":118847,\"start\":118846},{\"end\":118854,\"start\":118853},{\"end\":118861,\"start\":118860},{\"end\":118869,\"start\":118868},{\"end\":118876,\"start\":118875},{\"end\":118883,\"start\":118882},{\"end\":119112,\"start\":119111},{\"end\":119119,\"start\":119118},{\"end\":119126,\"start\":119125},{\"end\":119133,\"start\":119132},{\"end\":119140,\"start\":119139},{\"end\":119362,\"start\":119361},{\"end\":119369,\"start\":119368},{\"end\":119376,\"start\":119375},{\"end\":119383,\"start\":119382},{\"end\":119389,\"start\":119388},{\"end\":119632,\"start\":119631},{\"end\":119639,\"start\":119638},{\"end\":119647,\"start\":119646},{\"end\":119653,\"start\":119652},{\"end\":119660,\"start\":119659},{\"end\":119886,\"start\":119885},{\"end\":119897,\"start\":119896},{\"end\":119905,\"start\":119904},{\"end\":119916,\"start\":119915},{\"end\":120155,\"start\":120152},{\"end\":120164,\"start\":120163},{\"end\":120390,\"start\":120389},{\"end\":120397,\"start\":120396},{\"end\":120404,\"start\":120403},{\"end\":120411,\"start\":120410},{\"end\":120413,\"start\":120412},{\"end\":120421,\"start\":120420},{\"end\":120429,\"start\":120428},{\"end\":120435,\"start\":120434},{\"end\":120669,\"start\":120668},{\"end\":120676,\"start\":120675},{\"end\":120686,\"start\":120685},{\"end\":120697,\"start\":120696},{\"end\":120704,\"start\":120703},{\"end\":120713,\"start\":120712},{\"end\":120719,\"start\":120718},{\"end\":120731,\"start\":120730},{\"end\":121007,\"start\":121006},{\"end\":121014,\"start\":121013},{\"end\":121020,\"start\":121019},{\"end\":121033,\"start\":121032},{\"end\":121292,\"start\":121291},{\"end\":121299,\"start\":121298},{\"end\":121305,\"start\":121304},{\"end\":121500,\"start\":121499},{\"end\":121502,\"start\":121501},{\"end\":121509,\"start\":121508},{\"end\":121511,\"start\":121510},{\"end\":121520,\"start\":121519},{\"end\":121527,\"start\":121526},{\"end\":121535,\"start\":121534},{\"end\":121546,\"start\":121545},{\"end\":121774,\"start\":121773},{\"end\":121784,\"start\":121783},{\"end\":121792,\"start\":121791},{\"end\":121981,\"start\":121980},{\"end\":121992,\"start\":121991},{\"end\":122002,\"start\":122001},{\"end\":122004,\"start\":122003},{\"end\":122230,\"start\":122229},{\"end\":122232,\"start\":122231},{\"end\":122512,\"start\":122511},{\"end\":122519,\"start\":122518},{\"end\":122714,\"start\":122713},{\"end\":122716,\"start\":122715},{\"end\":122728,\"start\":122727},{\"end\":122741,\"start\":122740},{\"end\":122966,\"start\":122965},{\"end\":122973,\"start\":122972},{\"end\":122979,\"start\":122978},{\"end\":123167,\"start\":123166},{\"end\":123174,\"start\":123173},{\"end\":123180,\"start\":123179},{\"end\":123189,\"start\":123188},{\"end\":123388,\"start\":123387},{\"end\":123395,\"start\":123394},{\"end\":123404,\"start\":123403},{\"end\":123410,\"start\":123409},{\"end\":123418,\"start\":123417},{\"end\":123425,\"start\":123424},{\"end\":123669,\"start\":123668},{\"end\":123676,\"start\":123675},{\"end\":123684,\"start\":123683},{\"end\":123690,\"start\":123689},{\"end\":123698,\"start\":123697},{\"end\":123705,\"start\":123704},{\"end\":123714,\"start\":123713},{\"end\":123961,\"start\":123960},{\"end\":123968,\"start\":123967},{\"end\":123977,\"start\":123976},{\"end\":123983,\"start\":123982},{\"end\":123991,\"start\":123990},{\"end\":123999,\"start\":123998},{\"end\":124009,\"start\":124008},{\"end\":124241,\"start\":124240},{\"end\":124251,\"start\":124250},{\"end\":124253,\"start\":124252},{\"end\":124265,\"start\":124264},{\"end\":124507,\"start\":124506},{\"end\":124509,\"start\":124508},{\"end\":124521,\"start\":124520},{\"end\":124527,\"start\":124526},{\"end\":124536,\"start\":124535},{\"end\":124723,\"start\":124722},{\"end\":124725,\"start\":124724},{\"end\":124737,\"start\":124736},{\"end\":124743,\"start\":124742},{\"end\":124943,\"start\":124942},{\"end\":124945,\"start\":124944},{\"end\":124957,\"start\":124956},{\"end\":124967,\"start\":124966},{\"end\":124973,\"start\":124972},{\"end\":125249,\"start\":125248},{\"end\":125251,\"start\":125250},{\"end\":125263,\"start\":125262},{\"end\":125269,\"start\":125268},{\"end\":125277,\"start\":125276},{\"end\":125453,\"start\":125452},{\"end\":125464,\"start\":125463},{\"end\":125475,\"start\":125474},{\"end\":125485,\"start\":125484},{\"end\":125498,\"start\":125497},{\"end\":125507,\"start\":125506},{\"end\":125509,\"start\":125508},{\"end\":125518,\"start\":125517},{\"end\":125528,\"start\":125527},{\"end\":125708,\"start\":125707},{\"end\":125722,\"start\":125721},{\"end\":125734,\"start\":125733},{\"end\":125746,\"start\":125745},{\"end\":125756,\"start\":125755},{\"end\":125763,\"start\":125762},{\"end\":125937,\"start\":125936},{\"end\":125939,\"start\":125938},{\"end\":125951,\"start\":125950},{\"end\":125953,\"start\":125952},{\"end\":125967,\"start\":125966},{\"end\":125969,\"start\":125968},{\"end\":126191,\"start\":126190},{\"end\":126204,\"start\":126203},{\"end\":126392,\"start\":126391},{\"end\":126400,\"start\":126399},{\"end\":126407,\"start\":126406},{\"end\":126415,\"start\":126414},{\"end\":126615,\"start\":126614},{\"end\":126623,\"start\":126622},{\"end\":126632,\"start\":126631},{\"end\":126640,\"start\":126639},{\"end\":126837,\"start\":126836},{\"end\":126845,\"start\":126844},{\"end\":126851,\"start\":126850},{\"end\":126858,\"start\":126857},{\"end\":127047,\"start\":127046},{\"end\":127055,\"start\":127054},{\"end\":127063,\"start\":127062},{\"end\":127264,\"start\":127263},{\"end\":127270,\"start\":127269},{\"end\":127278,\"start\":127277},{\"end\":127286,\"start\":127285},{\"end\":127294,\"start\":127293},{\"end\":127567,\"start\":127566},{\"end\":127573,\"start\":127572},{\"end\":127580,\"start\":127579},{\"end\":127588,\"start\":127587},{\"end\":127596,\"start\":127595},{\"end\":127603,\"start\":127602},{\"end\":127833,\"start\":127832},{\"end\":127839,\"start\":127838},{\"end\":127846,\"start\":127845},{\"end\":127854,\"start\":127853},{\"end\":127862,\"start\":127861},{\"end\":128061,\"start\":128060},{\"end\":128067,\"start\":128066},{\"end\":128074,\"start\":128073},{\"end\":128082,\"start\":128081},{\"end\":128090,\"start\":128089},{\"end\":128262,\"start\":128261},{\"end\":128268,\"start\":128267},{\"end\":128275,\"start\":128274},{\"end\":128283,\"start\":128282},{\"end\":128291,\"start\":128290},{\"end\":128300,\"start\":128299},{\"end\":128302,\"start\":128301},{\"end\":128521,\"start\":128520},{\"end\":128529,\"start\":128528},{\"end\":128538,\"start\":128537},{\"end\":128748,\"start\":128747},{\"end\":128756,\"start\":128755},{\"end\":128765,\"start\":128764},{\"end\":128949,\"start\":128948},{\"end\":128956,\"start\":128955},{\"end\":128962,\"start\":128961},{\"end\":128969,\"start\":128968},{\"end\":128971,\"start\":128970},{\"end\":129182,\"start\":129181},{\"end\":129188,\"start\":129187},{\"end\":129196,\"start\":129195},{\"end\":129202,\"start\":129201},{\"end\":129210,\"start\":129209},{\"end\":129218,\"start\":129217},{\"end\":129226,\"start\":129225},{\"end\":129455,\"start\":129454},{\"end\":129461,\"start\":129460},{\"end\":129469,\"start\":129468},{\"end\":129477,\"start\":129476},{\"end\":129485,\"start\":129484},{\"end\":129706,\"start\":129705},{\"end\":129712,\"start\":129711},{\"end\":129720,\"start\":129719},{\"end\":129728,\"start\":129727},{\"end\":129737,\"start\":129736},{\"end\":129745,\"start\":129744},{\"end\":129976,\"start\":129975},{\"end\":129984,\"start\":129983},{\"end\":129991,\"start\":129990},{\"end\":129998,\"start\":129997},{\"end\":130004,\"start\":130003},{\"end\":130011,\"start\":130010},{\"end\":130240,\"start\":130239},{\"end\":130248,\"start\":130247},{\"end\":130255,\"start\":130254},{\"end\":130263,\"start\":130262},{\"end\":130271,\"start\":130270},{\"end\":130521,\"start\":130520},{\"end\":130529,\"start\":130528},{\"end\":130538,\"start\":130537},{\"end\":130540,\"start\":130539},{\"end\":130807,\"start\":130806},{\"end\":130815,\"start\":130814},{\"end\":130824,\"start\":130823},{\"end\":130826,\"start\":130825},{\"end\":130836,\"start\":130835},{\"end\":130838,\"start\":130837},{\"end\":131109,\"start\":131108},{\"end\":131115,\"start\":131114},{\"end\":131121,\"start\":131120},{\"end\":131129,\"start\":131128},{\"end\":131137,\"start\":131136},{\"end\":131400,\"start\":131399},{\"end\":131408,\"start\":131407},{\"end\":131417,\"start\":131416},{\"end\":131626,\"start\":131625},{\"end\":131634,\"start\":131633},{\"end\":131642,\"start\":131641},{\"end\":131650,\"start\":131649},{\"end\":131828,\"start\":131827},{\"end\":131837,\"start\":131836},{\"end\":131839,\"start\":131838},{\"end\":131847,\"start\":131846},{\"end\":131855,\"start\":131854},{\"end\":131862,\"start\":131861},{\"end\":131864,\"start\":131863},{\"end\":132071,\"start\":132070},{\"end\":132080,\"start\":132079},{\"end\":132087,\"start\":132086},{\"end\":132093,\"start\":132092},{\"end\":132101,\"start\":132100},{\"end\":132108,\"start\":132107},{\"end\":132310,\"start\":132309},{\"end\":132319,\"start\":132318},{\"end\":132326,\"start\":132325},{\"end\":132334,\"start\":132333},{\"end\":132342,\"start\":132341},{\"end\":132349,\"start\":132348},{\"end\":132358,\"start\":132357},{\"end\":132591,\"start\":132590},{\"end\":132599,\"start\":132598},{\"end\":132607,\"start\":132606},{\"end\":132615,\"start\":132614},{\"end\":132623,\"start\":132622},{\"end\":132625,\"start\":132624},{\"end\":132858,\"start\":132857},{\"end\":132866,\"start\":132865},{\"end\":132873,\"start\":132872},{\"end\":132880,\"start\":132879},{\"end\":133078,\"start\":133077},{\"end\":133085,\"start\":133084},{\"end\":133092,\"start\":133091},{\"end\":133099,\"start\":133098},{\"end\":133296,\"start\":133295},{\"end\":133303,\"start\":133302},{\"end\":133311,\"start\":133310},{\"end\":133317,\"start\":133316},{\"end\":133324,\"start\":133323},{\"end\":133546,\"start\":133545},{\"end\":133553,\"start\":133552},{\"end\":133560,\"start\":133559},{\"end\":133570,\"start\":133569},{\"end\":133579,\"start\":133578},{\"end\":133592,\"start\":133591},{\"end\":133594,\"start\":133593},{\"end\":133602,\"start\":133601},{\"end\":133867,\"start\":133866},{\"end\":133877,\"start\":133876}]", "bib_author_last_name": "[{\"end\":111899,\"start\":111895},{\"end\":111908,\"start\":111903},{\"end\":111921,\"start\":111912},{\"end\":111932,\"start\":111925},{\"end\":111944,\"start\":111936},{\"end\":111954,\"start\":111950},{\"end\":112125,\"start\":112113},{\"end\":112135,\"start\":112129},{\"end\":112346,\"start\":112337},{\"end\":112355,\"start\":112350},{\"end\":112367,\"start\":112359},{\"end\":112377,\"start\":112371},{\"end\":112387,\"start\":112381},{\"end\":112620,\"start\":112614},{\"end\":112631,\"start\":112624},{\"end\":112647,\"start\":112635},{\"end\":112657,\"start\":112651},{\"end\":112670,\"start\":112661},{\"end\":112883,\"start\":112880},{\"end\":112890,\"start\":112887},{\"end\":112896,\"start\":112894},{\"end\":112903,\"start\":112900},{\"end\":112909,\"start\":112907},{\"end\":112919,\"start\":112915},{\"end\":113134,\"start\":113130},{\"end\":113143,\"start\":113138},{\"end\":113151,\"start\":113147},{\"end\":113159,\"start\":113155},{\"end\":113165,\"start\":113163},{\"end\":113402,\"start\":113398},{\"end\":113410,\"start\":113406},{\"end\":113418,\"start\":113414},{\"end\":113429,\"start\":113422},{\"end\":113678,\"start\":113674},{\"end\":113686,\"start\":113682},{\"end\":113695,\"start\":113690},{\"end\":113705,\"start\":113699},{\"end\":113716,\"start\":113709},{\"end\":113936,\"start\":113930},{\"end\":113946,\"start\":113940},{\"end\":114142,\"start\":114136},{\"end\":114151,\"start\":114146},{\"end\":114158,\"start\":114155},{\"end\":114171,\"start\":114162},{\"end\":114399,\"start\":114395},{\"end\":114414,\"start\":114403},{\"end\":114423,\"start\":114418},{\"end\":114431,\"start\":114427},{\"end\":114438,\"start\":114435},{\"end\":114448,\"start\":114442},{\"end\":114461,\"start\":114452},{\"end\":114468,\"start\":114465},{\"end\":114477,\"start\":114472},{\"end\":114759,\"start\":114757},{\"end\":114768,\"start\":114763},{\"end\":114779,\"start\":114772},{\"end\":114792,\"start\":114783},{\"end\":115048,\"start\":115042},{\"end\":115228,\"start\":115221},{\"end\":115240,\"start\":115234},{\"end\":115425,\"start\":115417},{\"end\":115439,\"start\":115431},{\"end\":115451,\"start\":115443},{\"end\":115681,\"start\":115672},{\"end\":115694,\"start\":115685},{\"end\":115702,\"start\":115698},{\"end\":115716,\"start\":115708},{\"end\":115926,\"start\":115920},{\"end\":115942,\"start\":115932},{\"end\":115953,\"start\":115948},{\"end\":115964,\"start\":115957},{\"end\":115974,\"start\":115970},{\"end\":116183,\"start\":116180},{\"end\":116190,\"start\":116187},{\"end\":116196,\"start\":116194},{\"end\":116402,\"start\":116395},{\"end\":116416,\"start\":116408},{\"end\":116429,\"start\":116420},{\"end\":116439,\"start\":116433},{\"end\":116689,\"start\":116687},{\"end\":116695,\"start\":116693},{\"end\":116701,\"start\":116699},{\"end\":116708,\"start\":116705},{\"end\":116716,\"start\":116712},{\"end\":116905,\"start\":116903},{\"end\":116912,\"start\":116909},{\"end\":116923,\"start\":116916},{\"end\":116936,\"start\":116927},{\"end\":116944,\"start\":116942},{\"end\":117176,\"start\":117170},{\"end\":117189,\"start\":117180},{\"end\":117199,\"start\":117193},{\"end\":117209,\"start\":117203},{\"end\":117410,\"start\":117402},{\"end\":117420,\"start\":117414},{\"end\":117429,\"start\":117424},{\"end\":117643,\"start\":117639},{\"end\":117654,\"start\":117647},{\"end\":117831,\"start\":117827},{\"end\":118046,\"start\":118038},{\"end\":118055,\"start\":118050},{\"end\":118071,\"start\":118059},{\"end\":118086,\"start\":118075},{\"end\":118315,\"start\":118313},{\"end\":118322,\"start\":118319},{\"end\":118329,\"start\":118326},{\"end\":118336,\"start\":118333},{\"end\":118342,\"start\":118340},{\"end\":118350,\"start\":118346},{\"end\":118595,\"start\":118592},{\"end\":118603,\"start\":118599},{\"end\":118609,\"start\":118607},{\"end\":118617,\"start\":118613},{\"end\":118625,\"start\":118621},{\"end\":118851,\"start\":118848},{\"end\":118858,\"start\":118855},{\"end\":118866,\"start\":118862},{\"end\":118873,\"start\":118870},{\"end\":118880,\"start\":118877},{\"end\":118887,\"start\":118884},{\"end\":119116,\"start\":119113},{\"end\":119123,\"start\":119120},{\"end\":119130,\"start\":119127},{\"end\":119137,\"start\":119134},{\"end\":119144,\"start\":119141},{\"end\":119366,\"start\":119363},{\"end\":119373,\"start\":119370},{\"end\":119380,\"start\":119377},{\"end\":119386,\"start\":119384},{\"end\":119394,\"start\":119390},{\"end\":119636,\"start\":119633},{\"end\":119644,\"start\":119640},{\"end\":119650,\"start\":119648},{\"end\":119657,\"start\":119654},{\"end\":119663,\"start\":119661},{\"end\":119894,\"start\":119887},{\"end\":119902,\"start\":119898},{\"end\":119913,\"start\":119906},{\"end\":119921,\"start\":119917},{\"end\":120161,\"start\":120156},{\"end\":120169,\"start\":120165},{\"end\":120394,\"start\":120391},{\"end\":120401,\"start\":120398},{\"end\":120408,\"start\":120405},{\"end\":120418,\"start\":120414},{\"end\":120426,\"start\":120422},{\"end\":120432,\"start\":120430},{\"end\":120441,\"start\":120436},{\"end\":120673,\"start\":120670},{\"end\":120683,\"start\":120677},{\"end\":120694,\"start\":120687},{\"end\":120701,\"start\":120698},{\"end\":120710,\"start\":120705},{\"end\":120716,\"start\":120714},{\"end\":120728,\"start\":120720},{\"end\":120736,\"start\":120732},{\"end\":121011,\"start\":121008},{\"end\":121017,\"start\":121015},{\"end\":121030,\"start\":121021},{\"end\":121039,\"start\":121034},{\"end\":121296,\"start\":121293},{\"end\":121302,\"start\":121300},{\"end\":121311,\"start\":121306},{\"end\":121506,\"start\":121503},{\"end\":121517,\"start\":121512},{\"end\":121524,\"start\":121521},{\"end\":121532,\"start\":121528},{\"end\":121543,\"start\":121536},{\"end\":121553,\"start\":121547},{\"end\":121781,\"start\":121775},{\"end\":121789,\"start\":121785},{\"end\":121800,\"start\":121793},{\"end\":121989,\"start\":121982},{\"end\":121999,\"start\":121993},{\"end\":122012,\"start\":122005},{\"end\":122237,\"start\":122233},{\"end\":122516,\"start\":122513},{\"end\":122524,\"start\":122520},{\"end\":122725,\"start\":122717},{\"end\":122738,\"start\":122729},{\"end\":122751,\"start\":122742},{\"end\":122970,\"start\":122967},{\"end\":122976,\"start\":122974},{\"end\":122982,\"start\":122980},{\"end\":123171,\"start\":123168},{\"end\":123177,\"start\":123175},{\"end\":123186,\"start\":123181},{\"end\":123192,\"start\":123190},{\"end\":123392,\"start\":123389},{\"end\":123401,\"start\":123396},{\"end\":123407,\"start\":123405},{\"end\":123415,\"start\":123411},{\"end\":123422,\"start\":123419},{\"end\":123428,\"start\":123426},{\"end\":123673,\"start\":123670},{\"end\":123681,\"start\":123677},{\"end\":123687,\"start\":123685},{\"end\":123695,\"start\":123691},{\"end\":123702,\"start\":123699},{\"end\":123711,\"start\":123706},{\"end\":123717,\"start\":123715},{\"end\":123965,\"start\":123962},{\"end\":123974,\"start\":123969},{\"end\":123980,\"start\":123978},{\"end\":123988,\"start\":123984},{\"end\":123996,\"start\":123992},{\"end\":124006,\"start\":124000},{\"end\":124012,\"start\":124010},{\"end\":124248,\"start\":124242},{\"end\":124262,\"start\":124254},{\"end\":124272,\"start\":124266},{\"end\":124518,\"start\":124510},{\"end\":124524,\"start\":124522},{\"end\":124533,\"start\":124528},{\"end\":124541,\"start\":124537},{\"end\":124734,\"start\":124726},{\"end\":124740,\"start\":124738},{\"end\":124749,\"start\":124744},{\"end\":124954,\"start\":124946},{\"end\":124964,\"start\":124958},{\"end\":124970,\"start\":124968},{\"end\":124979,\"start\":124974},{\"end\":125260,\"start\":125252},{\"end\":125266,\"start\":125264},{\"end\":125274,\"start\":125270},{\"end\":125283,\"start\":125278},{\"end\":125461,\"start\":125454},{\"end\":125472,\"start\":125465},{\"end\":125482,\"start\":125476},{\"end\":125495,\"start\":125486},{\"end\":125504,\"start\":125499},{\"end\":125515,\"start\":125510},{\"end\":125525,\"start\":125519},{\"end\":125539,\"start\":125529},{\"end\":125719,\"start\":125709},{\"end\":125731,\"start\":125723},{\"end\":125743,\"start\":125735},{\"end\":125753,\"start\":125747},{\"end\":125760,\"start\":125757},{\"end\":125770,\"start\":125764},{\"end\":125948,\"start\":125940},{\"end\":125964,\"start\":125954},{\"end\":125977,\"start\":125970},{\"end\":126201,\"start\":126192},{\"end\":126213,\"start\":126205},{\"end\":126397,\"start\":126393},{\"end\":126404,\"start\":126401},{\"end\":126412,\"start\":126408},{\"end\":126419,\"start\":126416},{\"end\":126620,\"start\":126616},{\"end\":126629,\"start\":126624},{\"end\":126637,\"start\":126633},{\"end\":126645,\"start\":126641},{\"end\":126842,\"start\":126838},{\"end\":126848,\"start\":126846},{\"end\":126855,\"start\":126852},{\"end\":126864,\"start\":126859},{\"end\":127052,\"start\":127048},{\"end\":127060,\"start\":127056},{\"end\":127066,\"start\":127064},{\"end\":127267,\"start\":127265},{\"end\":127275,\"start\":127271},{\"end\":127283,\"start\":127279},{\"end\":127291,\"start\":127287},{\"end\":127309,\"start\":127295},{\"end\":127570,\"start\":127568},{\"end\":127577,\"start\":127574},{\"end\":127585,\"start\":127581},{\"end\":127593,\"start\":127589},{\"end\":127600,\"start\":127597},{\"end\":127608,\"start\":127604},{\"end\":127836,\"start\":127834},{\"end\":127843,\"start\":127840},{\"end\":127851,\"start\":127847},{\"end\":127859,\"start\":127855},{\"end\":127867,\"start\":127863},{\"end\":128064,\"start\":128062},{\"end\":128071,\"start\":128068},{\"end\":128079,\"start\":128075},{\"end\":128087,\"start\":128083},{\"end\":128095,\"start\":128091},{\"end\":128265,\"start\":128263},{\"end\":128272,\"start\":128269},{\"end\":128280,\"start\":128276},{\"end\":128288,\"start\":128284},{\"end\":128297,\"start\":128292},{\"end\":128305,\"start\":128303},{\"end\":128526,\"start\":128522},{\"end\":128535,\"start\":128530},{\"end\":128542,\"start\":128539},{\"end\":128753,\"start\":128749},{\"end\":128762,\"start\":128757},{\"end\":128769,\"start\":128766},{\"end\":128953,\"start\":128950},{\"end\":128959,\"start\":128957},{\"end\":128966,\"start\":128963},{\"end\":128976,\"start\":128972},{\"end\":129185,\"start\":129183},{\"end\":129193,\"start\":129189},{\"end\":129199,\"start\":129197},{\"end\":129207,\"start\":129203},{\"end\":129215,\"start\":129211},{\"end\":129223,\"start\":129219},{\"end\":129229,\"start\":129227},{\"end\":129458,\"start\":129456},{\"end\":129466,\"start\":129462},{\"end\":129474,\"start\":129470},{\"end\":129482,\"start\":129478},{\"end\":129488,\"start\":129486},{\"end\":129709,\"start\":129707},{\"end\":129717,\"start\":129713},{\"end\":129725,\"start\":129721},{\"end\":129734,\"start\":129729},{\"end\":129742,\"start\":129738},{\"end\":129749,\"start\":129746},{\"end\":129981,\"start\":129977},{\"end\":129988,\"start\":129985},{\"end\":129995,\"start\":129992},{\"end\":130001,\"start\":129999},{\"end\":130008,\"start\":130005},{\"end\":130015,\"start\":130012},{\"end\":130245,\"start\":130241},{\"end\":130252,\"start\":130249},{\"end\":130260,\"start\":130256},{\"end\":130268,\"start\":130264},{\"end\":130275,\"start\":130272},{\"end\":130526,\"start\":130522},{\"end\":130535,\"start\":130530},{\"end\":130547,\"start\":130541},{\"end\":130812,\"start\":130808},{\"end\":130821,\"start\":130816},{\"end\":130833,\"start\":130827},{\"end\":130842,\"start\":130839},{\"end\":131112,\"start\":131110},{\"end\":131118,\"start\":131116},{\"end\":131126,\"start\":131122},{\"end\":131134,\"start\":131130},{\"end\":131142,\"start\":131138},{\"end\":131405,\"start\":131401},{\"end\":131414,\"start\":131409},{\"end\":131422,\"start\":131418},{\"end\":131631,\"start\":131627},{\"end\":131639,\"start\":131635},{\"end\":131647,\"start\":131643},{\"end\":131654,\"start\":131651},{\"end\":131834,\"start\":131829},{\"end\":131844,\"start\":131840},{\"end\":131852,\"start\":131848},{\"end\":131859,\"start\":131856},{\"end\":131867,\"start\":131865},{\"end\":132077,\"start\":132072},{\"end\":132084,\"start\":132081},{\"end\":132090,\"start\":132088},{\"end\":132098,\"start\":132094},{\"end\":132105,\"start\":132102},{\"end\":132111,\"start\":132109},{\"end\":132316,\"start\":132311},{\"end\":132323,\"start\":132320},{\"end\":132331,\"start\":132327},{\"end\":132339,\"start\":132335},{\"end\":132346,\"start\":132343},{\"end\":132355,\"start\":132350},{\"end\":132364,\"start\":132359},{\"end\":132596,\"start\":132592},{\"end\":132604,\"start\":132600},{\"end\":132612,\"start\":132608},{\"end\":132620,\"start\":132616},{\"end\":132634,\"start\":132626},{\"end\":132863,\"start\":132859},{\"end\":132870,\"start\":132867},{\"end\":132877,\"start\":132874},{\"end\":132884,\"start\":132881},{\"end\":133082,\"start\":133079},{\"end\":133089,\"start\":133086},{\"end\":133096,\"start\":133093},{\"end\":133103,\"start\":133100},{\"end\":133300,\"start\":133297},{\"end\":133308,\"start\":133304},{\"end\":133314,\"start\":133312},{\"end\":133321,\"start\":133318},{\"end\":133328,\"start\":133325},{\"end\":133550,\"start\":133547},{\"end\":133557,\"start\":133554},{\"end\":133567,\"start\":133561},{\"end\":133576,\"start\":133571},{\"end\":133589,\"start\":133580},{\"end\":133599,\"start\":133595},{\"end\":133606,\"start\":133603},{\"end\":133874,\"start\":133868},{\"end\":133880,\"start\":133878}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":112080,\"start\":111850},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":20169246},\"end\":112247,\"start\":112082},{\"attributes\":{\"id\":\"b2\"},\"end\":112551,\"start\":112249},{\"attributes\":{\"id\":\"b3\"},\"end\":112820,\"start\":112553},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":196205749},\"end\":113049,\"start\":112822},{\"attributes\":{\"doi\":\"PAKDD 2020\",\"id\":\"b5\"},\"end\":113315,\"start\":113051},{\"attributes\":{\"id\":\"b6\"},\"end\":113567,\"start\":113317},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":49299019},\"end\":113901,\"start\":113569},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":52874011},\"end\":114050,\"start\":113903},{\"attributes\":{\"id\":\"b9\"},\"end\":114318,\"start\":114052},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":4557963},\"end\":114674,\"start\":114320},{\"attributes\":{\"id\":\"b11\"},\"end\":114935,\"start\":114676},{\"attributes\":{\"id\":\"b12\"},\"end\":115186,\"start\":114937},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":17349112},\"end\":115340,\"start\":115188},{\"attributes\":{\"id\":\"b14\"},\"end\":115608,\"start\":115342},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":207032678},\"end\":115870,\"start\":115610},{\"attributes\":{\"id\":\"b16\"},\"end\":116102,\"start\":115872},{\"attributes\":{\"id\":\"b17\"},\"end\":116317,\"start\":116104},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":6118799},\"end\":116629,\"start\":116319},{\"attributes\":{\"id\":\"b19\"},\"end\":116823,\"start\":116631},{\"attributes\":{\"doi\":\"CoRR abs/2002.00388\",\"id\":\"b20\"},\"end\":117112,\"start\":116825},{\"attributes\":{\"id\":\"b21\"},\"end\":117329,\"start\":117114},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":55731992},\"end\":117567,\"start\":117331},{\"attributes\":{\"doi\":\"ICLR 2017\",\"id\":\"b23\"},\"end\":117772,\"start\":117569},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":9426884},\"end\":117977,\"start\":117774},{\"attributes\":{\"id\":\"b25\"},\"end\":118218,\"start\":117979},{\"attributes\":{\"id\":\"b26\"},\"end\":118512,\"start\":118220},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":210992203},\"end\":118772,\"start\":118514},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1969092},\"end\":119037,\"start\":118774},{\"attributes\":{\"id\":\"b29\"},\"end\":119277,\"start\":119039},{\"attributes\":{\"id\":\"b30\"},\"end\":119537,\"start\":119279},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":210882549},\"end\":119821,\"start\":119539},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":5959482},\"end\":120066,\"start\":119823},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":6111745},\"end\":120308,\"start\":120068},{\"attributes\":{\"doi\":\"IJCAI 2020\",\"id\":\"b34\"},\"end\":120607,\"start\":120310},{\"attributes\":{\"doi\":\"NAACL-HLT 2019\",\"id\":\"b35\"},\"end\":120905,\"start\":120609},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":86510052},\"end\":121225,\"start\":120907},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":199466365},\"end\":121432,\"start\":121227},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":220919937},\"end\":121704,\"start\":121434},{\"attributes\":{\"id\":\"b39\"},\"end\":121916,\"start\":121706},{\"attributes\":{\"id\":\"b40\"},\"end\":122148,\"start\":121918},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":44752256},\"end\":122432,\"start\":122150},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":202790121},\"end\":122650,\"start\":122434},{\"attributes\":{\"id\":\"b43\"},\"end\":122890,\"start\":122652},{\"attributes\":{\"id\":\"b44\"},\"end\":123101,\"start\":122892},{\"attributes\":{\"id\":\"b45\"},\"end\":123305,\"start\":123103},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":204754514},\"end\":123585,\"start\":123307},{\"attributes\":{\"doi\":\"AAAI 2020\",\"id\":\"b47\"},\"end\":123880,\"start\":123587},{\"attributes\":{\"id\":\"b48\"},\"end\":124172,\"start\":123882},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":6420555},\"end\":124438,\"start\":124174},{\"attributes\":{\"id\":\"b50\"},\"end\":124650,\"start\":124440},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":69930495},\"end\":124882,\"start\":124652},{\"attributes\":{\"id\":\"b52\"},\"end\":125160,\"start\":124884},{\"attributes\":{\"id\":\"b53\"},\"end\":125423,\"start\":125162},{\"attributes\":{\"id\":\"b54\"},\"end\":125679,\"start\":125425},{\"attributes\":{\"id\":\"b55\"},\"end\":125882,\"start\":125681},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":10774942},\"end\":126142,\"start\":125884},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":14494942},\"end\":126321,\"start\":126144},{\"attributes\":{\"id\":\"b58\"},\"end\":126555,\"start\":126323},{\"attributes\":{\"id\":\"b59\"},\"end\":126760,\"start\":126557},{\"attributes\":{\"id\":\"b60\"},\"end\":126990,\"start\":126762},{\"attributes\":{\"id\":\"b61\"},\"end\":127170,\"start\":126992},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":18548166},\"end\":127496,\"start\":127172},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":198354047},\"end\":127755,\"start\":127498},{\"attributes\":{\"id\":\"b64\"},\"end\":128006,\"start\":127757},{\"attributes\":{\"id\":\"b65\"},\"end\":128210,\"start\":128008},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":57375753},\"end\":128433,\"start\":128212},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":2055276},\"end\":128686,\"start\":128435},{\"attributes\":{\"id\":\"b68\"},\"end\":128873,\"start\":128688},{\"attributes\":{\"id\":\"b69\"},\"end\":129104,\"start\":128875},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":167217453},\"end\":129385,\"start\":129106},{\"attributes\":{\"doi\":\"AAAI 2020\",\"id\":\"b71\"},\"end\":129623,\"start\":129387},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":57512667},\"end\":129910,\"start\":129625},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":202121966},\"end\":130156,\"start\":129912},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":213752427},\"end\":130430,\"start\":130158},{\"attributes\":{\"id\":\"b75\"},\"end\":130688,\"start\":130432},{\"attributes\":{\"id\":\"b76\"},\"end\":131015,\"start\":130690},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":199466148},\"end\":131307,\"start\":131017},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":70192277},\"end\":131572,\"start\":131309},{\"attributes\":{\"id\":\"b79\"},\"end\":131761,\"start\":131574},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":7062707},\"end\":132009,\"start\":131763},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":174802832},\"end\":132247,\"start\":132011},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":225039947},\"end\":132517,\"start\":132249},{\"attributes\":{\"id\":\"b83\",\"matched_paper_id\":226374030},\"end\":132786,\"start\":132519},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":23977924},\"end\":133016,\"start\":132788},{\"attributes\":{\"id\":\"b85\"},\"end\":133212,\"start\":133018},{\"attributes\":{\"id\":\"b86\",\"matched_paper_id\":199465777},\"end\":133478,\"start\":133214},{\"attributes\":{\"id\":\"b87\",\"matched_paper_id\":214791315},\"end\":133782,\"start\":133480},{\"attributes\":{\"id\":\"b88\",\"matched_paper_id\":4899764},\"end\":134027,\"start\":133784}]", "bib_title": "[{\"end\":112109,\"start\":112082},{\"end\":112876,\"start\":112822},{\"end\":113670,\"start\":113569},{\"end\":113926,\"start\":113903},{\"end\":114391,\"start\":114320},{\"end\":115215,\"start\":115188},{\"end\":115413,\"start\":115342},{\"end\":115668,\"start\":115610},{\"end\":116391,\"start\":116319},{\"end\":117398,\"start\":117331},{\"end\":117821,\"start\":117774},{\"end\":118588,\"start\":118514},{\"end\":118844,\"start\":118774},{\"end\":119629,\"start\":119539},{\"end\":119883,\"start\":119823},{\"end\":120150,\"start\":120068},{\"end\":121004,\"start\":120907},{\"end\":121289,\"start\":121227},{\"end\":121497,\"start\":121434},{\"end\":122227,\"start\":122150},{\"end\":122509,\"start\":122434},{\"end\":123385,\"start\":123307},{\"end\":124238,\"start\":124174},{\"end\":124720,\"start\":124652},{\"end\":125934,\"start\":125884},{\"end\":126188,\"start\":126144},{\"end\":127261,\"start\":127172},{\"end\":127564,\"start\":127498},{\"end\":128259,\"start\":128212},{\"end\":128518,\"start\":128435},{\"end\":129179,\"start\":129106},{\"end\":129703,\"start\":129625},{\"end\":129973,\"start\":129912},{\"end\":130237,\"start\":130158},{\"end\":131106,\"start\":131017},{\"end\":131397,\"start\":131309},{\"end\":131825,\"start\":131763},{\"end\":132068,\"start\":132011},{\"end\":132307,\"start\":132249},{\"end\":132588,\"start\":132519},{\"end\":132855,\"start\":132788},{\"end\":133293,\"start\":133214},{\"end\":133543,\"start\":133480},{\"end\":133864,\"start\":133784}]", "bib_author": "[{\"end\":111901,\"start\":111893},{\"end\":111910,\"start\":111901},{\"end\":111923,\"start\":111910},{\"end\":111934,\"start\":111923},{\"end\":111946,\"start\":111934},{\"end\":111956,\"start\":111946},{\"end\":112127,\"start\":112111},{\"end\":112137,\"start\":112127},{\"end\":112348,\"start\":112333},{\"end\":112357,\"start\":112348},{\"end\":112369,\"start\":112357},{\"end\":112379,\"start\":112369},{\"end\":112389,\"start\":112379},{\"end\":112622,\"start\":112612},{\"end\":112633,\"start\":112622},{\"end\":112649,\"start\":112633},{\"end\":112659,\"start\":112649},{\"end\":112672,\"start\":112659},{\"end\":112885,\"start\":112878},{\"end\":112892,\"start\":112885},{\"end\":112898,\"start\":112892},{\"end\":112905,\"start\":112898},{\"end\":112911,\"start\":112905},{\"end\":112921,\"start\":112911},{\"end\":113136,\"start\":113128},{\"end\":113145,\"start\":113136},{\"end\":113153,\"start\":113145},{\"end\":113161,\"start\":113153},{\"end\":113167,\"start\":113161},{\"end\":113404,\"start\":113396},{\"end\":113412,\"start\":113404},{\"end\":113420,\"start\":113412},{\"end\":113431,\"start\":113420},{\"end\":113680,\"start\":113672},{\"end\":113688,\"start\":113680},{\"end\":113697,\"start\":113688},{\"end\":113707,\"start\":113697},{\"end\":113718,\"start\":113707},{\"end\":113938,\"start\":113928},{\"end\":113948,\"start\":113938},{\"end\":114144,\"start\":114134},{\"end\":114153,\"start\":114144},{\"end\":114160,\"start\":114153},{\"end\":114173,\"start\":114160},{\"end\":114401,\"start\":114393},{\"end\":114416,\"start\":114401},{\"end\":114425,\"start\":114416},{\"end\":114433,\"start\":114425},{\"end\":114440,\"start\":114433},{\"end\":114450,\"start\":114440},{\"end\":114463,\"start\":114450},{\"end\":114470,\"start\":114463},{\"end\":114479,\"start\":114470},{\"end\":114761,\"start\":114755},{\"end\":114770,\"start\":114761},{\"end\":114781,\"start\":114770},{\"end\":114794,\"start\":114781},{\"end\":115050,\"start\":115040},{\"end\":115230,\"start\":115217},{\"end\":115242,\"start\":115230},{\"end\":115427,\"start\":115415},{\"end\":115441,\"start\":115427},{\"end\":115453,\"start\":115441},{\"end\":115683,\"start\":115670},{\"end\":115696,\"start\":115683},{\"end\":115704,\"start\":115696},{\"end\":115718,\"start\":115704},{\"end\":115928,\"start\":115918},{\"end\":115944,\"start\":115928},{\"end\":115955,\"start\":115944},{\"end\":115966,\"start\":115955},{\"end\":115976,\"start\":115966},{\"end\":116185,\"start\":116178},{\"end\":116192,\"start\":116185},{\"end\":116198,\"start\":116192},{\"end\":116404,\"start\":116393},{\"end\":116418,\"start\":116404},{\"end\":116431,\"start\":116418},{\"end\":116441,\"start\":116431},{\"end\":116691,\"start\":116685},{\"end\":116697,\"start\":116691},{\"end\":116703,\"start\":116697},{\"end\":116710,\"start\":116703},{\"end\":116718,\"start\":116710},{\"end\":116907,\"start\":116901},{\"end\":116914,\"start\":116907},{\"end\":116925,\"start\":116914},{\"end\":116938,\"start\":116925},{\"end\":116946,\"start\":116938},{\"end\":117178,\"start\":117168},{\"end\":117191,\"start\":117178},{\"end\":117201,\"start\":117191},{\"end\":117211,\"start\":117201},{\"end\":117412,\"start\":117400},{\"end\":117422,\"start\":117412},{\"end\":117431,\"start\":117422},{\"end\":117645,\"start\":117635},{\"end\":117656,\"start\":117645},{\"end\":117833,\"start\":117823},{\"end\":118048,\"start\":118036},{\"end\":118057,\"start\":118048},{\"end\":118073,\"start\":118057},{\"end\":118088,\"start\":118073},{\"end\":118317,\"start\":118311},{\"end\":118324,\"start\":118317},{\"end\":118331,\"start\":118324},{\"end\":118338,\"start\":118331},{\"end\":118344,\"start\":118338},{\"end\":118352,\"start\":118344},{\"end\":118597,\"start\":118590},{\"end\":118605,\"start\":118597},{\"end\":118611,\"start\":118605},{\"end\":118619,\"start\":118611},{\"end\":118627,\"start\":118619},{\"end\":118853,\"start\":118846},{\"end\":118860,\"start\":118853},{\"end\":118868,\"start\":118860},{\"end\":118875,\"start\":118868},{\"end\":118882,\"start\":118875},{\"end\":118889,\"start\":118882},{\"end\":119118,\"start\":119111},{\"end\":119125,\"start\":119118},{\"end\":119132,\"start\":119125},{\"end\":119139,\"start\":119132},{\"end\":119146,\"start\":119139},{\"end\":119368,\"start\":119361},{\"end\":119375,\"start\":119368},{\"end\":119382,\"start\":119375},{\"end\":119388,\"start\":119382},{\"end\":119396,\"start\":119388},{\"end\":119638,\"start\":119631},{\"end\":119646,\"start\":119638},{\"end\":119652,\"start\":119646},{\"end\":119659,\"start\":119652},{\"end\":119665,\"start\":119659},{\"end\":119896,\"start\":119885},{\"end\":119904,\"start\":119896},{\"end\":119915,\"start\":119904},{\"end\":119923,\"start\":119915},{\"end\":120163,\"start\":120152},{\"end\":120171,\"start\":120163},{\"end\":120396,\"start\":120389},{\"end\":120403,\"start\":120396},{\"end\":120410,\"start\":120403},{\"end\":120420,\"start\":120410},{\"end\":120428,\"start\":120420},{\"end\":120434,\"start\":120428},{\"end\":120443,\"start\":120434},{\"end\":120675,\"start\":120668},{\"end\":120685,\"start\":120675},{\"end\":120696,\"start\":120685},{\"end\":120703,\"start\":120696},{\"end\":120712,\"start\":120703},{\"end\":120718,\"start\":120712},{\"end\":120730,\"start\":120718},{\"end\":120738,\"start\":120730},{\"end\":121013,\"start\":121006},{\"end\":121019,\"start\":121013},{\"end\":121032,\"start\":121019},{\"end\":121041,\"start\":121032},{\"end\":121298,\"start\":121291},{\"end\":121304,\"start\":121298},{\"end\":121313,\"start\":121304},{\"end\":121508,\"start\":121499},{\"end\":121519,\"start\":121508},{\"end\":121526,\"start\":121519},{\"end\":121534,\"start\":121526},{\"end\":121545,\"start\":121534},{\"end\":121555,\"start\":121545},{\"end\":121783,\"start\":121773},{\"end\":121791,\"start\":121783},{\"end\":121802,\"start\":121791},{\"end\":121991,\"start\":121980},{\"end\":122001,\"start\":121991},{\"end\":122014,\"start\":122001},{\"end\":122239,\"start\":122229},{\"end\":122518,\"start\":122511},{\"end\":122526,\"start\":122518},{\"end\":122727,\"start\":122713},{\"end\":122740,\"start\":122727},{\"end\":122753,\"start\":122740},{\"end\":122972,\"start\":122965},{\"end\":122978,\"start\":122972},{\"end\":122984,\"start\":122978},{\"end\":123173,\"start\":123166},{\"end\":123179,\"start\":123173},{\"end\":123188,\"start\":123179},{\"end\":123194,\"start\":123188},{\"end\":123394,\"start\":123387},{\"end\":123403,\"start\":123394},{\"end\":123409,\"start\":123403},{\"end\":123417,\"start\":123409},{\"end\":123424,\"start\":123417},{\"end\":123430,\"start\":123424},{\"end\":123675,\"start\":123668},{\"end\":123683,\"start\":123675},{\"end\":123689,\"start\":123683},{\"end\":123697,\"start\":123689},{\"end\":123704,\"start\":123697},{\"end\":123713,\"start\":123704},{\"end\":123719,\"start\":123713},{\"end\":123967,\"start\":123960},{\"end\":123976,\"start\":123967},{\"end\":123982,\"start\":123976},{\"end\":123990,\"start\":123982},{\"end\":123998,\"start\":123990},{\"end\":124008,\"start\":123998},{\"end\":124014,\"start\":124008},{\"end\":124250,\"start\":124240},{\"end\":124264,\"start\":124250},{\"end\":124274,\"start\":124264},{\"end\":124520,\"start\":124506},{\"end\":124526,\"start\":124520},{\"end\":124535,\"start\":124526},{\"end\":124543,\"start\":124535},{\"end\":124736,\"start\":124722},{\"end\":124742,\"start\":124736},{\"end\":124751,\"start\":124742},{\"end\":124956,\"start\":124942},{\"end\":124966,\"start\":124956},{\"end\":124972,\"start\":124966},{\"end\":124981,\"start\":124972},{\"end\":125262,\"start\":125248},{\"end\":125268,\"start\":125262},{\"end\":125276,\"start\":125268},{\"end\":125285,\"start\":125276},{\"end\":125463,\"start\":125452},{\"end\":125474,\"start\":125463},{\"end\":125484,\"start\":125474},{\"end\":125497,\"start\":125484},{\"end\":125506,\"start\":125497},{\"end\":125517,\"start\":125506},{\"end\":125527,\"start\":125517},{\"end\":125541,\"start\":125527},{\"end\":125721,\"start\":125707},{\"end\":125733,\"start\":125721},{\"end\":125745,\"start\":125733},{\"end\":125755,\"start\":125745},{\"end\":125762,\"start\":125755},{\"end\":125772,\"start\":125762},{\"end\":125950,\"start\":125936},{\"end\":125966,\"start\":125950},{\"end\":125979,\"start\":125966},{\"end\":126203,\"start\":126190},{\"end\":126215,\"start\":126203},{\"end\":126399,\"start\":126391},{\"end\":126406,\"start\":126399},{\"end\":126414,\"start\":126406},{\"end\":126421,\"start\":126414},{\"end\":126622,\"start\":126614},{\"end\":126631,\"start\":126622},{\"end\":126639,\"start\":126631},{\"end\":126647,\"start\":126639},{\"end\":126844,\"start\":126836},{\"end\":126850,\"start\":126844},{\"end\":126857,\"start\":126850},{\"end\":126866,\"start\":126857},{\"end\":127054,\"start\":127046},{\"end\":127062,\"start\":127054},{\"end\":127068,\"start\":127062},{\"end\":127269,\"start\":127263},{\"end\":127277,\"start\":127269},{\"end\":127285,\"start\":127277},{\"end\":127293,\"start\":127285},{\"end\":127311,\"start\":127293},{\"end\":127572,\"start\":127566},{\"end\":127579,\"start\":127572},{\"end\":127587,\"start\":127579},{\"end\":127595,\"start\":127587},{\"end\":127602,\"start\":127595},{\"end\":127610,\"start\":127602},{\"end\":127838,\"start\":127832},{\"end\":127845,\"start\":127838},{\"end\":127853,\"start\":127845},{\"end\":127861,\"start\":127853},{\"end\":127869,\"start\":127861},{\"end\":128066,\"start\":128060},{\"end\":128073,\"start\":128066},{\"end\":128081,\"start\":128073},{\"end\":128089,\"start\":128081},{\"end\":128097,\"start\":128089},{\"end\":128267,\"start\":128261},{\"end\":128274,\"start\":128267},{\"end\":128282,\"start\":128274},{\"end\":128290,\"start\":128282},{\"end\":128299,\"start\":128290},{\"end\":128307,\"start\":128299},{\"end\":128528,\"start\":128520},{\"end\":128537,\"start\":128528},{\"end\":128544,\"start\":128537},{\"end\":128755,\"start\":128747},{\"end\":128764,\"start\":128755},{\"end\":128771,\"start\":128764},{\"end\":128955,\"start\":128948},{\"end\":128961,\"start\":128955},{\"end\":128968,\"start\":128961},{\"end\":128978,\"start\":128968},{\"end\":129187,\"start\":129181},{\"end\":129195,\"start\":129187},{\"end\":129201,\"start\":129195},{\"end\":129209,\"start\":129201},{\"end\":129217,\"start\":129209},{\"end\":129225,\"start\":129217},{\"end\":129231,\"start\":129225},{\"end\":129460,\"start\":129454},{\"end\":129468,\"start\":129460},{\"end\":129476,\"start\":129468},{\"end\":129484,\"start\":129476},{\"end\":129490,\"start\":129484},{\"end\":129711,\"start\":129705},{\"end\":129719,\"start\":129711},{\"end\":129727,\"start\":129719},{\"end\":129736,\"start\":129727},{\"end\":129744,\"start\":129736},{\"end\":129751,\"start\":129744},{\"end\":129983,\"start\":129975},{\"end\":129990,\"start\":129983},{\"end\":129997,\"start\":129990},{\"end\":130003,\"start\":129997},{\"end\":130010,\"start\":130003},{\"end\":130017,\"start\":130010},{\"end\":130247,\"start\":130239},{\"end\":130254,\"start\":130247},{\"end\":130262,\"start\":130254},{\"end\":130270,\"start\":130262},{\"end\":130277,\"start\":130270},{\"end\":130528,\"start\":130520},{\"end\":130537,\"start\":130528},{\"end\":130549,\"start\":130537},{\"end\":130814,\"start\":130806},{\"end\":130823,\"start\":130814},{\"end\":130835,\"start\":130823},{\"end\":130844,\"start\":130835},{\"end\":131114,\"start\":131108},{\"end\":131120,\"start\":131114},{\"end\":131128,\"start\":131120},{\"end\":131136,\"start\":131128},{\"end\":131144,\"start\":131136},{\"end\":131407,\"start\":131399},{\"end\":131416,\"start\":131407},{\"end\":131424,\"start\":131416},{\"end\":131633,\"start\":131625},{\"end\":131641,\"start\":131633},{\"end\":131649,\"start\":131641},{\"end\":131656,\"start\":131649},{\"end\":131836,\"start\":131827},{\"end\":131846,\"start\":131836},{\"end\":131854,\"start\":131846},{\"end\":131861,\"start\":131854},{\"end\":131869,\"start\":131861},{\"end\":132079,\"start\":132070},{\"end\":132086,\"start\":132079},{\"end\":132092,\"start\":132086},{\"end\":132100,\"start\":132092},{\"end\":132107,\"start\":132100},{\"end\":132113,\"start\":132107},{\"end\":132318,\"start\":132309},{\"end\":132325,\"start\":132318},{\"end\":132333,\"start\":132325},{\"end\":132341,\"start\":132333},{\"end\":132348,\"start\":132341},{\"end\":132357,\"start\":132348},{\"end\":132366,\"start\":132357},{\"end\":132598,\"start\":132590},{\"end\":132606,\"start\":132598},{\"end\":132614,\"start\":132606},{\"end\":132622,\"start\":132614},{\"end\":132636,\"start\":132622},{\"end\":132865,\"start\":132857},{\"end\":132872,\"start\":132865},{\"end\":132879,\"start\":132872},{\"end\":132886,\"start\":132879},{\"end\":133084,\"start\":133077},{\"end\":133091,\"start\":133084},{\"end\":133098,\"start\":133091},{\"end\":133105,\"start\":133098},{\"end\":133302,\"start\":133295},{\"end\":133310,\"start\":133302},{\"end\":133316,\"start\":133310},{\"end\":133323,\"start\":133316},{\"end\":133330,\"start\":133323},{\"end\":133552,\"start\":133545},{\"end\":133559,\"start\":133552},{\"end\":133569,\"start\":133559},{\"end\":133578,\"start\":133569},{\"end\":133591,\"start\":133578},{\"end\":133601,\"start\":133591},{\"end\":133608,\"start\":133601},{\"end\":133876,\"start\":133866},{\"end\":133882,\"start\":133876}]", "bib_venue": "[{\"end\":111891,\"start\":111850},{\"end\":112154,\"start\":112137},{\"end\":112331,\"start\":112249},{\"end\":112610,\"start\":112553},{\"end\":112929,\"start\":112921},{\"end\":113126,\"start\":113051},{\"end\":113394,\"start\":113317},{\"end\":113728,\"start\":113718},{\"end\":113964,\"start\":113948},{\"end\":114132,\"start\":114052},{\"end\":114490,\"start\":114479},{\"end\":114753,\"start\":114676},{\"end\":115038,\"start\":114937},{\"end\":115246,\"start\":115242},{\"end\":115467,\"start\":115453},{\"end\":115728,\"start\":115718},{\"end\":115916,\"start\":115872},{\"end\":116176,\"start\":116104},{\"end\":116464,\"start\":116441},{\"end\":116683,\"start\":116631},{\"end\":116899,\"start\":116825},{\"end\":117166,\"start\":117114},{\"end\":117437,\"start\":117431},{\"end\":117633,\"start\":117569},{\"end\":117864,\"start\":117833},{\"end\":118034,\"start\":117979},{\"end\":118309,\"start\":118220},{\"end\":118636,\"start\":118627},{\"end\":118899,\"start\":118889},{\"end\":119109,\"start\":119039},{\"end\":119359,\"start\":119279},{\"end\":119674,\"start\":119665},{\"end\":119936,\"start\":119923},{\"end\":120181,\"start\":120171},{\"end\":120387,\"start\":120310},{\"end\":120666,\"start\":120609},{\"end\":121055,\"start\":121041},{\"end\":121323,\"start\":121313},{\"end\":121564,\"start\":121555},{\"end\":121771,\"start\":121706},{\"end\":121978,\"start\":121918},{\"end\":122275,\"start\":122239},{\"end\":122536,\"start\":122526},{\"end\":122711,\"start\":122652},{\"end\":122963,\"start\":122892},{\"end\":123164,\"start\":123103},{\"end\":123439,\"start\":123430},{\"end\":123666,\"start\":123587},{\"end\":123958,\"start\":123882},{\"end\":124293,\"start\":124274},{\"end\":124504,\"start\":124440},{\"end\":124760,\"start\":124751},{\"end\":124940,\"start\":124884},{\"end\":125246,\"start\":125162},{\"end\":125450,\"start\":125425},{\"end\":125705,\"start\":125681},{\"end\":125999,\"start\":125979},{\"end\":126219,\"start\":126215},{\"end\":126389,\"start\":126323},{\"end\":126612,\"start\":126557},{\"end\":126834,\"start\":126762},{\"end\":127044,\"start\":126992},{\"end\":127316,\"start\":127311},{\"end\":127620,\"start\":127610},{\"end\":127830,\"start\":127757},{\"end\":128058,\"start\":128008},{\"end\":128312,\"start\":128307},{\"end\":128554,\"start\":128544},{\"end\":128745,\"start\":128688},{\"end\":128946,\"start\":128875},{\"end\":129239,\"start\":129231},{\"end\":129452,\"start\":129387},{\"end\":129760,\"start\":129751},{\"end\":130027,\"start\":130017},{\"end\":130286,\"start\":130277},{\"end\":130518,\"start\":130432},{\"end\":130804,\"start\":130690},{\"end\":131154,\"start\":131144},{\"end\":131433,\"start\":131424},{\"end\":131623,\"start\":131574},{\"end\":131880,\"start\":131869},{\"end\":132123,\"start\":132113},{\"end\":132377,\"start\":132366},{\"end\":132640,\"start\":132636},{\"end\":132895,\"start\":132886},{\"end\":133075,\"start\":133018},{\"end\":133340,\"start\":133330},{\"end\":133622,\"start\":133608},{\"end\":133896,\"start\":133882}]"}}}, "year": 2023, "month": 12, "day": 17}