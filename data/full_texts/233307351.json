{"id": 233307351, "updated": "2023-10-06 05:09:05.141", "metadata": {"title": "Federated Learning for Malware Detection in IoT Devices", "authors": "[{\"first\":\"Valerian\",\"last\":\"Rey\",\"middle\":[]},{\"first\":\"Pedro\",\"last\":\"S'anchez\",\"middle\":[\"Miguel\",\"S'anchez\"]},{\"first\":\"Alberto\",\"last\":\"Celdr'an\",\"middle\":[\"Huertas\"]},{\"first\":\"G'erome\",\"last\":\"Bovet\",\"middle\":[]},{\"first\":\"Martin\",\"last\":\"Jaggi\",\"middle\":[]}]", "venue": "Rey, V., S\\'anchez, P. M. S., Celdr\\'an, A. H.,&Bovet, G. (2022). Federated learning for malware detection in iot devices. Computer Networks, 108693", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "This work investigates the possibilities enabled by federated learning concerning IoT malware detection and studies security issues inherent to this new learning paradigm. In this context, a framework that uses federated learning to detect malware affecting IoT devices is presented. N-BaIoT, a dataset modeling network traffic of several real IoT devices while affected by malware, has been used to evaluate the proposed framework. Both supervised and unsupervised federated models (multi-layer perceptron and autoencoder) able to detect malware affecting seen and unseen IoT devices of N-BaIoT have been trained and evaluated. Furthermore, their performance has been compared to two traditional approaches. The first one lets each participant locally train a model using only its own data, while the second consists of making the participants share their data with a central entity in charge of training a global model. This comparison has shown that the use of more diverse and large data, as done in the federated and centralized methods, has a considerable positive impact on the model performance. Besides, the federated models, while preserving the participant's privacy, show similar results as the centralized ones. As an additional contribution and to measure the robustness of the federated approach, an adversarial setup with several malicious participants poisoning the federated model has been considered. The baseline model aggregation averaging step used in most federated learning algorithms appears highly vulnerable to different attacks, even with a single adversary. The performance of other model aggregation functions acting as countermeasures is thus evaluated under the same attack scenarios. These functions provide a significant improvement against malicious participants, but more efforts are still needed to make federated approaches robust.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2104.09994", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/cn/ReySCB22", "doi": "10.1016/j.comnet.2021.108693"}}, "content": {"source": {"pdf_hash": "bcf4daf9b16b1d52054e7aec78f1caf62b85d596", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2104.09994v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "d4f0695c6f4a5e471ca251a8f5870420029a2183", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/bcf4daf9b16b1d52054e7aec78f1caf62b85d596.txt", "contents": "\nFederated Learning for Malware Detection in IoT Devices\n\n\nValerian Rey \n\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL)\n1015LausanneSwitzerland\n\nPedro Miguel S\u00e1nchez S\u00e1nchez \nDepartment of Information and Communications Engineering\nUniversity of Murcia\n30100MurciaSpain\n\nAlberto Huertas Celdr\u00e1n \nDepartment of Informatics (IfI)\nCommunication Systems Group (CSG)\nUniversity of Zurich UZH\n8050Z\u00fcrichSwitzerland\n\nG\u00e9r\u00f4me Bovet \nCyber-Defence Campus\narmasuisse Science & Technology\n3602ThunSwitzerland\n\nMartin Jaggi \n\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL)\n1015LausanneSwitzerland\n\nFederated Learning for Malware Detection in IoT Devices\nA R T I C L E I N F OIoT Security Federated Learning IoT Device Botnet Detection Adversarial Attack\nBillions of IoT devices lacking proper security mechanisms have been manufactured and deployed for the last years, and more will come with the development of Beyond 5G technologies. Their vulnerability to malware has motivated the need for efficient techniques to detect infected IoT devices inside networks. With data privacy and integrity becoming a major concern in recent years, increasing with the arrival of 5G and Beyond networks, new technologies such as federated learning and blockchain emerged. They allow training machine learning models with decentralized data while preserving its privacy by design. This work investigates the possibilities enabled by federated learning concerning IoT malware detection and studies security issues inherent to this new learning paradigm. In this context, a framework that uses federated learning to detect malware affecting IoT devices is presented. N-BaIoT, a dataset modeling network traffic of several real IoT devices while affected by malware, has been used to evaluate the proposed framework. Both supervised and unsupervised federated models (multi-layer perceptron and autoencoder) able to detect malware affecting seen and unseen IoT devices of N-BaIoT have been trained and evaluated. Furthermore, their performance has been compared to two traditional approaches. The first one lets each participant locally train a model using only its own data, while the second consists of making the participants share their data with a central entity in charge of training a global model. This comparison has shown that the use of more diverse and large data, as done in the federated and centralized methods, has a considerable positive impact on the model performance. Besides, the federated models, while preserving the participant's privacy, show similar results as the centralized ones. As an additional contribution and to measure the robustness of the federated approach, an adversarial setup with several malicious participants poisoning the federated model has been considered. The baseline model aggregation averaging step used in most federated learning algorithms appears highly vulnerable to different attacks, even with a single adversary. The performance of other model aggregation functions acting as countermeasures is thus evaluated under the same attack scenarios. These functions provide a significant improvement against malicious participants, but more efforts are still needed to make federated approaches robust. * Corresponding author. Email address: pedromiguel.sanchez@um.es (P.M.S. S\u00e1nchez) ORCID(s): 0000-0003-3078-3598 (V. Rey); 0000-0002-6444-2102 (P.M. S\u00e1nchez S\u00e1nchez); 0000-0001-7125-1710 (A. Huertas Celdr\u00e1n); 0000-0003-1579-5558 (M. Jaggi)\n\nIntroduction\n\nBy 2025, forecasts estimate that there will be about 64 billion IoT devices online [1]. The massive deployment of these devices is undoubtedly transforming the world into a hyper interconnected environment. The IoT paradigm, together with new 5G and Beyond 5G (B5G) network technologies, are enabling new application scenarios and businesses not seen before, such as Industries 4.0 and Smart Cities, among many others [2]. However, simultaneously to the advances in new technologies, the number and variety of cyberattacks have grown in recent years, making current security approaches outdated in a short time [3]. For this reason, controlling the security of future network environments enabled by B5G technologies presents open challenges that must be solved with modern techniques.\n\nOne strategy that has gained relevance when detecting devices that have been corrupted by malware is monitoring device activities to generate behavioral fingerprints or profiles.\n\nFingerprints can be utilized to detect deviations caused by cyberattacks or malicious software modifications [4]. In IoT devices, heterogeneous behavior sources can be monitored, such as network communications, resource consumption, software actions and events, or users' interactions. Therefore, depending on the objective to be achieved, one or another can be used. Concretely, when it comes to detecting cyberattacks, the most widely used dimension in the literature is network communications [5].\n\nOnce behavior sources are selected and monitored, the next step to achieve successful malware detection is to process the data and generate device behavior fingerprints. In the 5G and B5G context, Artificial Intelligence (AI) techniques, mainly Machine Learning (ML) and Deep Learning (DL), have gained enormous relevance in recent years [6]. Nowadays, most of the existing solutions that use ML/DL to detect malware rely on a central entity in charge of collecting data from different devices and training global models. Later, these models are distributed between individual clients, or these clients send their live test data to the server for behavior evaluation and malware detection. However, this approach is not suitable for scenarios where device behaviors contain sensitive or confidential data that would significantly affect environmental security and privacy in case of falling into malicious hands. A similar situation occurs in scenarios where the monitored data sources are related to human beings and private actions are involved.\n\nIn such a context where data privacy and integrity are critical, Federated Learning (FL) [7] and Blockchain are gaining huge relevance in the last years as a collaborative ML paradigm. In FL, the algorithm training is performed in a decentralized manner by different nodes, or clients, that use local data. In this scenario, each decentralized node trains an individual model using its own data and shares the model parameters (instead of the data) with the rest. The exchange of the model parameters and their aggregation to create a unique and global model can be performed through a central entity, called server, or following a peer-to-peer approach [8]. After several iterations, each client has a global model obtained as an aggregation of the individual model of each client. This approach enables data privacy by design, as data is not shared with any external identity.\n\nDespite the novelty and benefits of FL approaches, their application in real-world scenarios still presents several open questions that must be analyzed and solved (or at least improved) [9]. Previous works dealing with FL for intrusion detection [10,11,12] lack the use of realistic datasets in the FL context, the analysis on adversarial impact, or the discussion of their deployment in B5G scenarios, among others. In this sense, some of the most relevant open challenges can be summarized as: 1) how can FL be used in the IoT context to build joint models without sharing sensitive data?; 2) how do FL approaches affect the performance of traditional anomaly detectors and classifiers in IoT scenarios?; 3) what is the impact of different adversarial attacks affecting federated models designed to detect cyberattacks on IoT scenarios?; and 4) are existing countermeasure mechanisms able to mitigate the effects of adversarial attacks?; and if so, 5) what are the most suitable countermeasures for IoT scenarios?; 6) how these solutions could be incorporated in future networks such as B5G?.\n\nWith the goal of overcoming the previous open challenges, this paper presents the following main contributions:\n\n\u2022 A use case presenting a B5G scenario where there is a necessity of detecting cyberattacks affecting IoT devices, managing sensitive data, having Non-IID (Independent and Identically Distributed) data, and with non trusted stakeholders or clients.\n\n\u2022 A security framework that uses FL to detect, in a privacy preserving fashion, cyberattacks affecting IoT devices. The proposed framework covers both anomaly detection and classification approaches using multilayer perceptron and autoencoder neural network architectures.\n\n\u2022 A pool of experiments measuring the performance of the proposed framework when detecting malware in IoT devices. To that end, the next scenarios have been compared: i) a centralized approach where all the data is shared, ii) a distributed approach where each entity trains an independent model with its local data, and iii) a federated approach where a joint model is generated sharing the local model updates. Two different federated learning algorithms that differ in the number of communications (model sharing updates) with the server have been considered in the previous comparison.\n\n\u2022 The evaluation of the impact of several adversarial attacks affecting our FL solution. The objective is to measure how the federated models performance degrades when some clients are malicious and send tampered model updates. Besides, it has been evaluated how different aggregation functions acting as countermeasure mechanisms improve the model resilience against adversarial attacks.\n\n\u2022 The discussion on the adversarial results, the communication and computation costs and the design of the framework, describing possible issues and drawbacks in B5G scenarios, together with their possible solution.\n\nThe remainder of this paper is organized as follows. Section 2 describes related work on AI for IoT cybersecurity, FL algorithms, vulnerabilities and countermeasures, and datasets containing IoT cyberattack data. Section 3 depicts an IoT scenario with privacy requirements that are accomplished by the N-BaIoT dataset, which serves as use case for this work. Section 4 details the design and implementation of the proposed framework, which uses FL to detect malware affecting IoT devices. Section 5 defines the adversarial attacks and countermeasures tested against the proposed framework. Section 6 shows the results of the experiments done in this work, comparing the federated approaches against traditional ones and detailing the results of the adversarial settings. Section 7 analyzes the lessons learned as well as the possible drawbacks of the architecture. Finally, Section 8 shows the conclusions of this research and future directions.\n\n\nRelated work\n\nThis section details the current state-of-the-art in different topics covered in the present work. First, it reviews the usage of AI for IoT cybersecurity, with special consideration of FL. Then, it describes the main literature on adversarial attacks against the FL process and their possible mitigations. Finally, it reviews the available datasets modeling cyberattacks on IoT devices.\n\n\nArtificial Intelligence for IoT Cybersecurity\n\nTraditional AI techniques have been widely applied in the literature to detect cybersecurity issues in IoT scenarios. In [4], existing works on device behavior fingerprinting were surveyed, including those targeting IoT security. This work shows how IoT security solutions are turning nowadays towards the application of ML and DL techniques. In this direction, the authors of [13] used ML techniques for early detection of heterogeneous malware affecting IoT devices.\n\nAnother work was presented in [5], where many intrusion detection systems for IoT devices were reviewed, providing recommendations for designing robust and lightweight intrusion detection solutions for IoT.\n\nIn the last years, FL is gaining importance in the field of cybersecurity, with several works already using this paradigm for IoT security. In this context, the research proposed in [14] clearly stated the data privacy problem of traditional AI-based solutions, but the evaluation took place on a private dataset. Also, the data was randomly split among clients, which can be improbable in realistic scenarios, as the one considered in this work, in which each client data comes from a different distribution in general. The works presented in [10,11] also have very similar objectives, but these researches were conducted specifically for industrial IoT devices, and they analyzed respectively application samples and sensor readings rather than network data, as we do in this work. In [12], FL was studied through the use case of intrusion detection systems. This work also includes blockchain technology to mitigate the problems faced in adversarial FL. However, it concentrates on the early steps of intrusion detection rather than detecting already running malware, and it does not focus specifically on IoT devices.\n\nIn summary, this section has shown the lack of solutions dealing with FL approaches considering data generated by decentralized sources to detect malware affecting IoT devices and scenarios.\n\n\nFederated Learning Algorithms, Vulnerabilities and Countermeasures\n\nFocusing on FL algorithms and their particularities, the work of [7] defines the term federated learning by characterizing the decentralized non-IID optimization problem. They propose the Federated Averaging (FedAVG) algorithm that now serves as a powerful baseline for many researches using FL. In this algorithm, several clients use their individual datasets to collaboratively train a global model, thanks to the coordination provided by a central server. The role of the server is to average the parameters of the models sent by the clients and return the resulting global model to them. This process is iterated until a terminating condition is met. FL has matured a lot since then and several surveys ( [8,15]) review the latest advances in that domain.\n\nBecause of its decentralized nature, FL shares the threat among multiple entities, namely the clients and the server. The work of [16] reviews many of the problems that can arise when considering an adversarial setup, as well as most of the well-known defenses to protect the system against that. In [17], several data poisoning attacks against Support Vector Machines were defined. Their baseline experiment used the idea of label flipping, in which the binary label of some datapoints in the training set is inverted to hinder the training of the model. In [18], the authors studied the resilience of a distributed implementation of Stochastic Gradient Descent against arbitrarily behaving (Byzantine) adversaries. To that end, a model poisoning attack from the standpoint of a malicious client, that is capable of estimating the gradi-ent, was experimented. First, it demonstrated that the usual model averaging step executed by the server in most FL algorithms does not handle even a single malicious client in the federation. More generally, they proved that no model aggregation function, linear in the models sent by the clients, is robust against Byzantine adversaries. In [19], two additional robust model aggregation functions were proposed. In particular, they are based on the coordinate-wise median and the coordinate-wise trimmed mean of the models sent by the clients to the server. The authors of [20] proposed resampling to reduce heterogeneity in the distribution of the models sent by the clients. It is meant to be applied before using a robust aggregation function, and it aims at reducing the side-effects that such a function has when applied to models trained with non-IID datasets.\n\nFinally, in the literature there are also decentralized algorithms for securing distributed computing tasks which use reinforcement learning approaches in scenarios where there is no direct trust in the clients but a correct result is desired even if there are some clients with malicious behavior [21].\n\n\nDatasets Modeling Cyberattacks Affecting IoT Devices\n\nDatasets are key for AI in general and FL in particular. In this sense, several public network datasets about IoT security can be found in the literature. Table 1 reviews some of the most interesting ones. All of those datasets are generated at a central location, but for some of them, a realistic splitting strategy is doable to let them be used in FL approaches. In this context, the Splitting column presents our proposal in terms of possible strategies to split the dataset among different entities. In the Device splitting strategy, the dataset already has the traffic from each device placed into a different file. The IP strategy would consist of grouping the dataset samples by IP address to manually isolate the traffic of each device. The Scenario splitting strategy would take advantage of the fact that the dataset was generated in several different scenarios, and it might be possible to consider each scenario as coming from a different client. Finally, the Unrealistic label means that no realistic (non-IID) strategy was found to make the dataset appear to come from several sources.\n\nIn [22], a dataset called N-BaIoT was produced by preprocessing the traffic generated by 9 commercial IoT devices of various types, either infected by Mirai or BASHLITE (two botnet malware attacks), or uncorrupted. In [23], a medium-sized network of 83 real or emulated IoT devices is considered to produce the MedBIoT dataset. It uses the same packet preprocessing as in N-BaIoT, but here other stages of malware traffic are considered (infection, propagation and communication with the command and control server). In [24], the evaluation dataset consists of a network made of 8 security cameras suffering from several attacks. Additionally, they included another network consisting of 9 commercial IoT devices, among which one was infected by Mirai. [25] proposes a dataset called Bot_IoT, that contains legitimate and simulated IoT network traffic, including different attacks. The dataset TON_IoT [26] consists of heterogeneous data Table 1 Public IoT network datasets.\n\nsources (network data but also sensor readings, operating system logs and telemetry data) about a network containing several IoT/IIoT devices. In [27], the authors propose a dataset collecting benign and volumetric attacks traffic traces for 27 IoT devices. The main purpose of this dataset is to evaluate volumetric attacks perpetrated against a network containing real commercial IoT devices. The dataset proposed in [28] was generated with the traffic of 2 home IoT devices under multiple attack scenarios. It also includes simulated Mirai traffic appearing to come from the IoT devices. Finally, IoT-23 [29] is a dataset consisting of 20 captures that include malware activity as well as 3 captures of benign IoT traffic.\n\nTo conclude, it is worthy to mention that there is a lack of dataset suitable for FL approaches detecting malware in IoT devices. Existing FL-based solutions must consider split centralized datasets in order to apply federated techniques.\n\n\nUse Case: IoT Scenario Affected by Malware\n\nThis section presents the characteristics of the scenario defined in this work and explains the details of the dataset used to evaluate the performance of the proposed framework.\n\nOur cities have millions of IoT devices connected to the Internet and sensing heterogeneous pieces of data. The number and heterogeneity of devices will increase exponentially with the advent of B5G networks, as they enable new verticals and scenarios based on the enhanced network performance in terms of latency and throughput [30]. Some examples are Unmanned Aerial Vehicle Services, Holographic Teleportation, or Extended Reality. In such a context, privacy issues frequently appear when pieces of sensed data belong to sensitive aspects of our daily lives or organizations [31]. As demonstrated, IoT devices are constrained in terms of resources and have not been designed with security in mind, making them vulnerable to a wide variety of malware. In these scenarios, traditional AI-based detection approaches are not suitable due to the impossibility of training centralized models with sensitive data belonging to different organizations or subjects. Because of that, FL is raising as a key mechanism to detect anomalous behaviors and trigger mitigation mechanisms in privacy-sensitive scenarios enabled by 5G and B5G networks. However, FL also suffers from inherent problems of dealing with unknown and, therefore, untrusted parties. Malicious clients executing poisoning attacks over data and models is one of the best examples in this direction. Following the previous characteristics, this work considers the following key aspects for the defined scenario: i) data is non identically distributed across the IoT devices (owned by the clients), ii) it is needed to detect anomalies provoked by unseen or zero-day malware affecting IoT devices, iii) it is required to classify well-known malware affecting different IoT devices, iv) adversaries can be present among the federated clients, so some countermeasures should be applied.\n\nSeveral public datasets aligned with B5G application scenarios and IoT malware exist in the literature. Among them, N-BaIoT is the most suitable to evaluate privacy-preserving collaborative training. Specifically, this dataset already separates the IoT devices' traffic data into different files, making it easy to split it into several non identically distributed parts for a realistic federated setting. For that reason, we selected N-BaIoT to evaluate our approach. Note that a drawback of this dataset is that it only contains the data from 9 IoT devices, which is a limitation for the experiments as it limits the maximum number of clients that can be considered.\n\nN-BaIoT contains the preprocessed packets from the traffic of the 9 IoT devices. All devices have generated some traffic while non-corrupted (benign samples) and while being infected by Mirai and BASHLITE. All devices, except the Ennio doorbell and the webcam, also have generated some traffic while infected by Mirai. Table 2 shows the number of benign and attack samples for each device, as well as the total.\n\nEach sample in the dataset corresponds to a network packet sniffed by Wireshark. For each, 115 numerical features characterizing the context of the packet were extracted. The available features are statistics about the size, count and jitter of aggregated network packets, in the last 100 ms, 500 ms, 1.5 sec, 10 sec and 1 min. For example, one feature is the mean packet size over the last 10 seconds in the traffic between the current packet source IP and destination IP. Noticeably, the features of packets captured in a very short time interval are highly correlated. This means that this dataset needs to be handled with care in order to reduce as much as possible the data leak between the train and the test sets when separating a given file into those two parts. To that end, we always used chronological splitting to make the train and test parts, and we left a small set of samples unused between the train part and the test part for each file in the dataset.\n\nAfter analyzing the most relevant characteristics of the dataset, we also reviewed some of the most notable existing works on N-BaIoT [22,32,33,34,35,36]. Most of those focus on unsupervised anomaly-detection solutions, using only the benign part of the dataset to train. Still, in [36], the hyper-parameters are tuned using also some attack data, and in [34], a supervised classification is considered instead. Some works use multiple samples in order to detect potential malware, and others focus on the more granular task of single-sample classification. In our methodology, both the supervised and the unsupervised situations are considered, and the attention is placed on single-sample analysis. In the supervised situation, as N-BaIoT contains 10 different attacks performed using Mirai and BASHLITE, we use all the available attacks labeled using the same class (attack) in order to detect as many attacks as possible. Note that in [35], a collaborative learning approach is proposed. However, the assumed scenario and the goal are different from ours, as they focus on building one model per device with the assumption that the data of a single device comes from 2 or 3 different sources.\n\n\nFederated Learning-based Framework and Deployment\n\nThis section details the architectural design of the proposed FL-based framework, describing its components and how they interact with each other during the model training and evaluation processes. Besides, it also depicts how the framework is deployed for our validation use case, which leverages the N-BaIoT dataset.\n\nThe framework architecture, depicted in Figure 1, consists of clients that own the data from a single device each and a server that coordinates the FL process. The following sections provide the design details about each component making up the proposed architecture. The code used to implement the whole pipeline is available at [37].  \n\n\nClient\n\nConsidering that IoT devices generally have limited resources and modest reliability, the clients in charge of training the models are not the devices to be protected, but other entities capable of collecting the traffic of the IoT devices present in the same network, such as B5G base stations or other access points. In this sense, in the B5G architecture [38], the present system would be incorporated in the RAN SLICING Edge Nodes or in the CLOUD SLICING Fog Nodes. This system falls into the category of cross-silo FL, as defined in [15], where the federated clients are few but powerful and reliable. Note that each client can own several IoT devices, but for the sake of simplicity, the architecture and the experiments are described with a single one per client. Figure 2 details the architecture of a client after data acquisition, as well as its interactions with the server. The dataset and the components depicted in the figure mentioned above are explained in detail in the remainder of this section.\n\n\nData Acquisition\n\nThe client is in charge of gathering the traffic data from the device under observation. This can be done, for example, by using port mirroring on the switch that connects the IoT device (as described in [22]). In our solution, since we use an existing dataset, this component was not developed.\n\n\nDataset\n\nTwo situations are considered here. The supervised situation assumes a setup in which each client has access to labeled data from its own device. In the second situation, we assume that each client only has access to the benign traffic of its device. Since getting a large quantity of benign traffic data is generally easy and does not need manual labelling, this situation is often termed as unsupervised in the literature [22,33,36]. However, in the strict sense of the term, it refers to single-class supervised learning [33].\n\nNote that in reality, a supervised situation with several clients able to generate a decent amount of labeled data is plausible but uncommon. Therefore, the supervised solution has two main motivations. The first one is to have a comparison point for the unsupervised solution. As the supervised situation is easier to tackle and is more controllable than the unsupervised one, the second motivation is to be able to go as in-depth as possible in our experiments, to potentially reveal vulnerabilities or other concerns about using FL for malware detection. Figure 3 shows for both situations how we have split the dataset of a single device for training and testing purposes. In the supervised situation, each dataset is split chronologically between 3 parts: the train set (79%), the aforementioned unused set (1%) and the test set (20%). In the unsupervised situation, only the benign data is available for training, so this part is split between 4 different sets: the train set (39.5%), a so-called threshold-selection set (39.5%), the unused set (1%) and the benign part of the test set (20%). All attack data is available for the final testing of our experiments.\n\nWe also decided to re-balance the dataset in three different ways in order to cover several possible data scenarios. We selected the following class proportions for every device:\n\n\u2022 7.87% benign traffic and 92.13% attack traffic. This is the original dataset balance, with the difference that the proportion of each class now does not vary across the devices.\n\n\u2022 50% benign traffic and 50% attack traffic, making the dataset perfectly balanced for binary classification.\n\n\u2022 95% benign traffic and 5% attack traffic. This is much  more representative and aligned with the reality, where usually much more benign data is available.\n\nIt is important to note that these three re-balancings lead to three different problems. Both train and test sets are indeed affected by each change, and the goal is not to compare the impact on the model performance when re-balancing the classes. This is an operation to make the results as broad as possible rather than a way to handle the dataset imbalance.\n\nThe number of samples per device is also fixed to a constant in order to make the results less dependent on the number of training instances and to keep the dataset size fixed no matter what the proportions of classes are. 100 000 samples per device are used for the supervised solution and only 10 000 for the unsupervised one. This is because the unsupervised training takes more time to converge, and it only needs benign data (which rarely reaches 100 000 samples anyway) in its train set. The procedure followed to reach at the same time these numbers of samples and the desired class proportions is to use upsampling (duplicating the original samples) when more samples than available are needed, and downsampling (keeping only a subset of the original samples) otherwise. Either way, it takes place after splitting the data between the train and test sets, so no data leak is created. After setting the proportions of each class and the desired number of samples per device, we obtain a dataset where the number of samples and the proportions of classes are the same for all devices.\n\nAfter this balancing process, the train set of client is defined as \ue230 Train and its threshold selection set (in the unsupervised solution) is defined as \ue230 Thr . The number of training samples of client is \u2236= |\ue230 Train |.\n\n\nData Preprocessing\n\nThis component is in charge of normalizing the samples. Min-max feature scaling is used, i.e. \u2032 = \u2212 \u2212 \u2208 \u211d 115 , where operations are applied element-wise. The normalization values are computed only with the train set that the client owns. Note that each client originally has its own normalization values and . As we will see in Section 4.3.1, clients can collaborate in order to know the global values for and , over the train sets of all devices.\n\n\nModel training\n\nThe purpose of the component is to train the federated ML model that will be used for malware detection. To that end, we first present the architectures used for classification and anomaly-detection. Later, for two different FL algorithms, we explain how this component interacts with the server. Throughout the rest of this work, the model parameters of client are referred as and the global model parameters as . Further, with the number of dimensions of and with \u2208 [ ], ( ) specifies the th dimension of . Note that most well-known ML models are compatible with our framework, as long as the trained models do not vary in structure among clients and do not store training data explicitly (otherwise sharing them would compromise privacy).\n\nSupervised situation. In this setup, a binary classification task is considered with four different architectures of multilayer perceptrons (MLP) with 1 output neuron:\n\n\u2022 Classifier A: No hidden layer (linear model).\n\n\u2022 Classifier B: 1 hidden layer with 115 hidden neurons.\n\n\u2022 Classifier C: 2 hidden layers with 115 and 58 hidden neurons, respectively.\n\n\u2022 Classifier D: 3 hidden layers with 115, 58 and 29 hidden neurons, respectively.\n\nAfter each hidden layer, the exponential linear unit (ELU) [39] activation function is used. Note that the numbers of hidden neurons that are tried, 115, 58 and 29, correspond respectively to 100%, 50%, and 25% of the input dimension.\n\nUnsupervised situation. In this setup, autoencoders are used for anomaly detection, following a similar methodology as the authors of N-BaIoT [22]. An autoencoder is a special form of feed-forward neural network made of two parts, the encoder and the decoder. The encoder transforms the input by reducing its number of dimensions to a value defined as the coding dimension, and the decoder tries to map the encoded input back to the original input. It is trained by minimizing the Mean Squared Error (MSE) between the reconstructed features and the input. In order to use this principle for anomaly detection, an autoencoder is trained with benign data, learning how to reconstruct it, such that it has a low reconstruction error on future benign data and a high reconstruction error on anything that deviates from benign data. Once the training process is completed, a threshold is set based on statistics about the reconstruction error of benign data. During testing, if a sample has a mean squared reconstruction error higher than the specified threshold, it is considered as anomalous (positive), otherwise it is considered as benign (negative). The threshold formula used in this work comes from [22], and selects for client \u2208 [ ] the threshold\n\u210e = (MSE(\ue230 Thr ; ))+ (MSE(\ue230 Thr ; )) (1)\nwhere MSE( \u22c5 ; ) is the mean squared reconstruction error computed with model parameters . Multiple autoencoder architectures are investigated during the grid searches.\n\n\u2022 Autoencoder A: 1 hidden layer of 29 neurons (shallow autoencoder).\n\n\u2022 Autoencoder B: 3 hidden layers of 58, 29 and 58 neurons.\n\n\u2022 Autoencoder C: 7 hidden layers of 86, 58, 38, 29, 38, 58 and 86 neurons. These numbers of neurons and layers correspond roughly to those used in the solution of the creators of N-BaIoT [22].\n\nOnce again, ELU is used after each hidden layer. All considered architectures have 29 coding dimensions. A low number of dimensions is a way to constrain the autoencoder to learn a representation that is more specific to benign data. Indeed, using 115 coding dimensions would make the autoencoder able to learn the identity function for any input vector in \u211d 115 , making it produce low reconstruction errors for very unusual data, even if it is trained only with benign data. The choice of 29 coding dimensions corresponds to what is used in [22]. Without looking at labeled data, it is hard to make a better selection of this hyper-parameter. The numbers 86, 58, 38 and 29, correspond respectively to 75%, 50%, 33% and 25% of the input dimension.\n\nInteractions with the server. Two FL algorithms, MINI-BATCH AGGREGATION and MULTI-EPOCH AGGREGATION, deriving from the popular FedAVG [7] are considered. For both algorithms, the main difference with FedAVG is that we consider the aggregation function as a parameter of the algorithm. Therefore, the server can try other aggregation functions than averaging. Also, it provides a more practical implementation, where the learning rate varies over the training process.\n\nIn MINI-BATCH AGGREGATION, the Model Training component trains the model with a single mini-batch of data before sending it to the server for aggregation. The Model Training component then receives the new aggregated global model, with which the training can continue. This process is repeated until a number of epochs over the full train set are completed. In MULTI-EPOCH AGGREGATION, the model is trained for all epochs at once before being sent to the server for aggregation. A potential drawback is that, as explained in [7], averaging models could have arbitrarily bad results because of the non-convexity of the objective. This problem is much more likely for MULTI-EPOCH AGGREGATION as the models are trained separately for much longer before being aggregated. In order to try to mitigate that, the training of MULTI-EPOCH AGGREGATION is repeated for = 30 rounds, with a learning rate decreasing over the rounds.\n\n\nModel Evaluation\n\nAfter the model has been trained for a satisfying number of iterations through the FL process, it is ready to be evaluated. In order to assess the robustness of the trained models, we evaluate them on different test sets. The known devices performance is given by the evaluation of the model on the test part of the data from the devices owned by the clients.\n\nThe new device performance is computed on the data from a device that is totally new to all clients in the federation (it has not been seen during the selection of the normalization values, the hyper-parameter selection nor the training). Note that the new device's test set thus has a different distribution than the training sets in general.\n\n\nServer\n\nIn the proposed framework architecture, the server is in charge of coordinating the training efforts of the federated clients. Specifically, it initializes the model at the very beginning, and it aggregates the models sent by the clients into a so-called global model. It also has to coordinate the additional steps described in Section 4.3, i.e. the collaborative normalization, the collaborative grid searches, and the collaborative threshold selection (for the anomaly-detection approach). In the B5G architecture context [38], the server component would be placed in the CLOUD SLICING layer, either on the Fog Nodes or in the Cloud Data Centres, depending on the scope of the clients covered.\n\n\nModel Initialization\n\nThe server is in charge of initializing the weights of the initial model. Once it is done, the initial model is shared with all clients, and the training process can start. It is worth noting that each client starts with the same model.\n\n\nModel Aggregation\n\nAfter receiving the updated model parameters of each client i.e. { \u2236 \u2200 \u2208 [ ]}, the server has to aggregate them to form the new global model parameters . With the baseline averaging approach, the formula for this is given by\n\u2236= \u2211 =1 1\n. When this aggregation function is used, we refer to the algorithms MINI-BATCH AGGREGATION and MULTI-EPOCH AGGREGATION as MINI-BATCH AVG and MULTI-EPOCH AVG, respectively. Note that a weighted averaging could be used if the number of samples varied among clients. Other aggregation functions can also be used to provide additional security, as indicated in Section 5.2.\n\nAlthough there is a server in charge of model aggregation in the current design of the framework due to the advantages of having an entity coordinating the process, it would be possible to move the Model Initialization and Model Aggregation steps into the clients themselves, or decentralizing the server into several entities. For this, Blockchain technologies would be used as a decentralized database where each client would share its local model and retrieve the models of other clients when performing the aggregation. Thus, the framework would be totally decentralized without an entity coordinating the generated models.\n\n\nAdditional Concerns of the Proposed Framework\n\nThis section summarizes some additional concerns that arise when performing the usual full pipeline of ML in a federated way. Specifically, the steps of normalization and hyper-parameter selection must be given attention. Besides, for the unsupervised solution, the step of threshold selection requires special considerations as well.\n\n\nCollaborative Normalization\n\nSince min-max feature scaling is used, each client can compute \u2208 \u211d 115 and \u2208 \u211d 115 locally and the server can compute the global minimum and maximum \u2208 \u211d 115 and \u2208 \u211d 115 as the element-wise minimum and maximum, respectively, of those values. This procedure is detailed in algorithm 1. Note that it gives the global minimum and maximum as if they were computed directly on the combination of the train sets of all clients. This has the drawback of requiring each client to leak its exact values of minimum and maximum for each of the 115 features.\n\n\nAlgorithm 1: COLLABORATIVE NORMALIZATION.\n\n[ ] is the set of clients and \ue230 Train is the set of datapoints used by client for training; min and max are the element-wise minimum and maximum. Since they are always applied with vectors in \u211d 115 , they also output a value in \u211d 115 . \n\n\nCollaborative Grid Search\n\nTwo types of hyper-parameters should be distinguished: the ones that need to be common to every client, mainly about the architecture of the model (number of layers, number of neurons per layer, activation functions), and the ones that could be different for each client, mainly about optimization (optimizer, learning rate, batch size, number of epochs).\n\nBecause the first type of hyper-parameters must be common between all clients, they have to communicate some validation results in order to agree on their selection. For simplicity, the other type of hyper-parameters is also made common to all clients.\n\nTo that end, the collaborative grid search is defined as a grid search in which the federated clients share their validation results for each considered set of hyper-parameters, so that the selected hyper-parameters are those that give the best results on average. Note that for the unsupervised solution, the model is validated only with benign data, so the selected hyper-parameters are those that minimize the loss. In the supervised solution, however, the selection is based on validation accuracy.\n\n\nCollaborative Threshold Selection\n\nFor the unsupervised anomaly-detection approach, additionally to training the model, the clients have to select the threshold. To that end, in our proposed federated framework, each client computes a local threshold with \ue230 Thr (using equation 1) and transmits it to the server, which then computes the global threshold as the average of the local thresholds. The global threshold is then given back to every client, which will use it for anomaly detection. Note that this is not equivalent to computing the global threshold directly with the combination of all threshold-selection sets, as the threshold formula (1) is non-linear (it uses the standard deviation). An alternative way of computing the threshold would be to share the whole set of MSE values over \ue230 Thr for each client , and let the server compute the global threshold with that.\n\nThe threshold only needs to be computed for the final testing after the model has trained for the specified number of iterations. We still decided to compute it at several steps during the training in order to show its evolution.\n\n\nAdversarial Attacks and Countermeasures\n\nThis section provides the theoretical background regarding some of the most well-known poisoning attacks, intending to reduce the model performance. Besides, it also describes different model aggregation functions that could improve the resilience of the federated model training against attacks.\n\n\nAdversarial Attacks\n\nAn honest server, a majority of honest clients and a minority of potentially colluding malicious clients are assumed through the following explanation.\n\nSuch malicious clients are often referred to as Byzantine workers [40]. The server and the honest participants could be considered as honest-but-curious as well (trying to infer as much information as possible without deviating from the protocol), but privacy issues are out of the scope of this work. Next, several data poisoning and model poisoning attacks are described, to be later implemented and evaluated in Section 6.  Table 3 Adversarial attack characteristics. The metrics shown here are defined in Section 6.\n\nThe characteristics of the described attacks are summarized in Table 3. These attacks have been selected for their simplicity and variety, but other more sophisticated and stealthy attacks exist in the literature [16,41].\n\nData poisoning attacks operate through the medium of the client dataset. The client could be malicious and intentionally modify its own data with the goal of making it misleading. Even if the client is honest, the attack could come from any part in the client data pipeline on which an external malicious entity has control. Therefore this attack category is the one that assumes the less from the clients and that is the most likely to happen. Three data poisoning attacks, all based on label flipping [17], are described for the supervised situation.\n\n\u2022 Benign label flipping. Here, the labels 0 (benign) are flipped to be 1s (attack). The goal of an attacker doing this would be to make the model always classify the traffic as attack and to make it have a TNR of 0%. Such a model would constantly raise false alarms and could be very disturbing for its users.\n\n\u2022 Attack label flipping. In this case, the labels 1 are flipped to be 0s, with the goal of making the model reach 0% TPR. Such a model would never raise alarms about attack traffic and would allow potential malware to remain undetected.\n\n\u2022 All labels flipping. In this attack all labels are flipped, i.e. 1s become 0s and 0s become 1s. The goal of such an attack would be to bring the model accuracy to 0%, combining both previous attacks.\n\nNote that the two first attacks are considered as targeted since they focus on a specific class, while the third one is considered untargeted because it concentrates on both classes. All of these attacks are parameterized by the proportion of the targeted labels that is flipped. Model poisoning attacks are conducted through corrupted model updates sent to the server. They are a very big issue when using FL because the clients can send arbitrarily bad models to the server, and, due to the privacy that FL gives, it becomes hard to check whether the models received actually correspond to the local training data or not. In a sense, data poisoning attacks could be considered as a subset of model poisoning attacks because training from wrong data produces a wrong model. Next, some of the most basic model poisoning attacks are described:\n\n\u2022 Gradient factor attack. In this case, the malicious clients multiply their gradients by a negative factor before updating their local model and sharing it with the server. This attack is inspired by the omniscient attack in [18], but instead of being aware of the estimate of the gradient, the malicious clients simply have access to the data from one device. Therefore, they are only able to compute the estimate of the gradient on their own data distribution. With total clients among which are malicious, the factor is chosen to verify\n1 ( \u2212 + \u22c5 ) = \u22121(2)\nSpecifically, the malicious clients select their update factor so that the average update factor including honest clients is \u22121 (instead of 1 in the non-adversarial case). Note that selecting a value of that solves equation 2 is not necessary in order to conduct this attack (any negative value could be considered). Only the most recent update from the honest clients remains. To that end, they simply output the original global model parameters, multiplied by a factor that has to satisfy\n\u2212 + \u22c5 = 0(3)\nSpecifically, must be selected so that the weight of the malicious clients ( \u22c5 ) cancels the weight of the honest clients ( \u2212 ). Note that this time, using the right value of is much more important, so collusion between the malicious clients is necessary so that they know their exact number ( ) at the beginning. This attack is very powerful, but at the same time, it is not stealthy at all, as the values given by the malicious clients are very different from those usually expected in terms of direction and magnitude.\n\n\nRobust Model Aggregation Functions\n\nThere are many different ways to make the system secure against attacks. One of the most extended ideas is to use model aggregation and update processing solutions that take into account the possibility of malicious clients trying to hijack the model [16]. Next, two different aggregation functions, in addition to averaging (AVG), are defined as well as a prior step to be applied to the models sent by the clients. Most of the convergence proofs of these aggregation functions do not hold in this work because the clients datasets are not from the same distributions. However, the intuition behind the use of these functions is still the same. These countermeasures have been selected for their great simplicity, as they only require a modification of the step of model aggregation, which is easy to implement. They also do not require any previous knowledge of the distribution of the client's data, which is hard to obtain in a realistic federated setting.\n\nCoordinate-wise median. This aggregation function, as proposed by [19], applies the median to each parameter individually to exclude completely any potential outlier. The \u210e coordinate of is given by ( ) = { ( ) \u2236 \u2208 [ ]}. Note that the usual definition of the median is used, i.e. when K is odd, the middle value is selected, and when K is even, the average between the two middle values is taken. We refer to this aggregation function as MED.\n\nCoordinate-wise trimmed mean. The trimmed mean, as proposed by [19], can be seen as a compromise between the averaging and the median. For each coordinate \u2208 [ ], a fraction of the largest and smallest values are removed before the mean is computed. Because of the low number of clients in the scenario that we consider, the trimmed mean algorithm is redefined using an integer number of excluded largest and lowest values instead of a proportion, but both are equivalent. Therefore, in our definition the \u210e coordinate of is given by s-Resampling. Rather than being an aggregation function, s-Resampling [20] is an additional step that can be done prior to the aggregation. In a scenario where each client's dataset has its own distribution, it aims at reducing the heterogeneity of the models sent by each client. Thus, s-Resampling is meant to be combined with a robust aggregation function to reduce the side-effects of using such a function on non-IID models. Note that combining s-Resampling with AVG is useless, as the result is always exactly the same as when only using AVG. It operates by replacing each model by the average between models randomly sampled from the clients models. Each model can be sampled a maximum of times in total. Algorithm 2 is a slightly adapted version of the second algorithm from [20]. Indeed, s-Resampling may also cause the malicious models to be diluted into several of the models that it outputs, increasing the reach of the malicious clients. For that reason, it is only expected to work satisfyingly with a small number of malicious clients, a small value of , and with an aggregation function that gets rid of a high number of extreme values, such as MED or TM(2).\n( ) = 1 \u22122 \u2211 \u2208 ( ) , where ( ) is a subset of { ( ) \u2236 \u2208 [ ]} obtained\n\nExperimental Results\n\nThis section details the results obtained in the different experiments performed to validate the proposed framework. First, it compares the performance when detecting malware Algorithm 2: Resampling with s-replacement source: [20] input \n\u2022 TPR = TP TP+FN \u2022 Accuracy = TP+TN TP+FP+TN+FN \u2022 TNR = TN TN+FP \u2022 F1-Score = TP TP+ 1 2 (FP+FN)\nAll experiments performed in this section have followed a similar methodology. In this sense, the federation consists of = 8 clients, each owning data of one of the 9 devices available in the N-BaIoT dataset. The data of one device was not used during training, keeping it as an unseen device for testing purposes. In this context, nine different combinations of devices (with an unseen one) were used in all experiments. Moreover, experiments were repeated 5 times to improve the consistency of results. Finally, the results of each experiment show the average over 45 runs in total (9 possible unseen devices and 5 executions).\n\n\nPerformance of Federated and Traditional Learning for the Detection of Malware in IoT Devices\n\nThis experiment seeks to measure the performance of our solution when detecting IoT malware using N-BaIoT dataset. To verify that the federated learning approach fits our IoT malware scenario properly, it is necessary to compare it with traditional solutions. More specifically, the compared alternatives are:\n\n\u2022 Naive decentralized approach. Each client uses its local dataset for training and testing. Since each client produces its own model, the results are compared by averaging the performance of each client.\n\n\u2022 Centralized approach. All training data is shared with a server in charge of training and testing a model with it. It does not preserve privacy.\n\n\u2022 Federated with MINI-BATCH AVG. The different clients collaborate to generate a global model using the MINI-BATCH AGGREGATION algorithm with the AVG aggregation function.\n\n\u2022 Federated with MULTI-EPOCH AVG. Similar to the previous approach but training with the MULTI-EPOCH AGGREGATION algorithm in order to greatly reduce the communication costs.\n\nThe following steps are followed both for the supervised and the unsupervised solutions. First, two important hyperparameters (the architecture of the model and the L2-regularization value ) are selected for each setup using grid searches. The MLP and autoencoder architectures considered are those described in Section 4.1.4. The values considered for are 0, 10 \u22125 and 10 \u22124 . Note that for the naive method, the hyper-parameters are selected per client because the clients do not collaborate on hyper-parameter selection. For the FL approaches, each federation used collaborative grid searches to select the hyper-parameters, as defined in Section 4.3.2. Finally, in the centralized method, the grid search is performed directly by the server that receives the whole dataset. For all experiments, a batch size of = 64 was used when training, except with MINI-BATCH AVG where the batch size was divided by the number of clients ( = 8), so that each model update is made with a total of 64 samples as well. In all of the experiments, the model updates are computed with Stochastic Gradient Descent (SGD). For the supervised solution, the training is conducted for = 4 epochs; for the unsupervised solution, it is made with = 120 epochs.\n\nSupervised situation. First, the supervised solution is verified. Here, the three different dataset splitting options explained in Section 4.1.2 (7.87%, 50% and 95% benign data) are used in repeated tests, also checking how the different class balances affect the results. Table 4 shows the results achieved in these experiments.\n\nThe first noticeable result is that the centralized method's performance is higher than the distributed naive one, especially when evaluated on an unseen device. Moreover, on all three dataset settings, the MINI-BATCH AVG results are very close to the centralized ones, even sometimes exceeding them. Although obtaining better results than in the centralized method could be surprising, this can be explained by several factors, such as the randomness of the experiments or the fact that the hyper-parameters are computed differently. Figure 4 shows how fast the models converge near the centralized performance.\n\nMULTI-EPOCH AVG also produces quite satisfying results, with an insignificant decrease in the accuracy on known devices, compensated by an accuracy always exceeding the centralized one on the new device. This can be explained by the fact that averaging the model parameters with a nonconvex loss function can have arbitrarily damaging effects on the model, as explained in [7]. However, it can also be viewed as a form of mechanism acting against overfitting, thus improving the generalization on a new device. Moreover, Naive  Table 4 Supervised results comparing both FL approaches (Multiepoch avg and Mini-batch avg) with the naive approach and the centralized approach. The percentages of benign data of the datasets used are indicated in color on the left.\n\nthese results could probably be slightly improved by using a higher number of federation rounds. Figure 4 shows that for the datasets with 50% and 95% benign data, the accuracy seems to have not exactly converged after 30 rounds.\n\nUnsupervised situation. Once the supervised performance is verified, the next step is to evaluate the unsupervised one.\n\nHere, only the benign traffic is used for training, so the final model does not depend on the class balance in the dataset. In order to make our results independent of the class balance used, we only show the TPR and the TNR for this solution (and not the accuracy). The equation used to define the threshold is described in Section 4.1.4. Among the possible architectures, the first one (Autoencoder A) is always the one giving the best validation loss during all hyper-parameter selections. All results from the unsupervised situation are further produced with Autoencoder A. Table 5 shows the unsupervised results of the system. Here centralizing the data presents overall a high performance improvement over the naive method. Furthermore, the FL algorithms also very successfully deal with the unsupervised fingerprinting task. Specifically, the centralized performance is almost reached by both the MULTI-EPOCH AVG and the MINI-BATCH AVG methods. Once again, MULTI-EPOCH AVG seems to help the model to generalize better, as it demonstrates on the new device a marginally better TNR than MINI-BATCH AVG. Interestingly, the threshold, as displayed 1 3 5 7 9 11 13 15 17 19 21 23 25 27 Table 5 Unsupervised results comparing both FL approaches (Multiepoch avg and Mini-batch avg) with the naive approach and the centralized approach.\n\nin Figure 5, converges to a larger value, in the case of MULTI-EPOCH AVG than what the centralized method achieves. As explained earlier, the collaborative threshold selection is not equivalent to selecting the threshold directly on the whole threshold-selection set (as in the centralized method), so this result is not surprising. With the previous experiments, it has been verified that in this particular scenario of malware detection in IoT devices, using more data to train the model presents a significant improvement, especially on previously unseen devices. Besides, FL-based training successfully reaches the centralized performance in a privacy-preserving manner.\n\n\nImpact of Adversarial Attacks and Countermeasures when Detecting Malware\n\nOnce the performance of the federated approach has been verified, the next step is to evaluate how the different adversarial attacks proposed in Section 5 affect the federated approach. Besides, different aggregation functions are applied to test how they improve the model resilience against the different attacks. For conciseness, these experiments focus on the supervised situation and use only the dataset balance with 95% of benign data. Moreover, they are conducted with the MINI-BATCH AGGREGATION federated algorithm. A batch size of = 64 (instead of = 8) is used for all the adversarial experiments, as it allows smoother updates for the robust aggregation functions.\n\nAs explained earlier, s-Resampling is only expected to work with a small value of , and combined with MED or TM(2) (or other robust aggregation functions that we did not implement). Because TM(2) computes its output by taking more values into account than MED, s-Resampling was only experimented for TM (2) and with = 2. This combination is referred as TM(2) \u2022 2-Resampling.\n\nIn the experiments implementing data poisoning attacks, the All labels flipping attack is selected for testing, as it combines both benign and attack label flipping. Since the focus is placed on intentional data poisoning, = 1 is always used. This approach enables the verification of the maximum impact of the attack in the generated model.\n\nRegarding  Figure 6 shows how the F1-Score of the model tested on the devices owned by the clients (the known devices) varies in the different implemented attacks according to the aggregation function. It also shows the evolution of the metric when the number of malicious clients grows from 0 to 3 (or 37.5% of the total number of clients in the setup). It has to be noted that these results have a large variance due to the randomness of the selection of which client is malicious. Even though each experiment was run a total of 45 times, this can lead to unanticipated results, such as sometimes having a better average F1-Score with more malicious clients. Nonetheless, these experiments are sufficient to get a wellfounded idea of the seriousness of the adversarial problem.\n\nAs we can observe, averaging (AVG) is the best aggregation function when all clients are honest. However, when malicious clients are involved, its performance is heavily affected depending on the attack. Specifically, under the gradient factor and the model cancelling attacks, even a single malicious client is sufficient to consistently turn the model into a constant predictor (note that a constant positive predictor has an F1-Score of \u223c10% and a constant negative predictor has an F1-Score of 0%). This demonstrates the necessity of using more robust methods when assuming a threat model in which even only one client could be malicious.\n\nCoordinate-wise median aggregation (MED) presents more resilience against most attack scenarios considered. Overall it has the best results among the tested aggregation functions in the adversarial setup. However, this is still far from being robust enough, especially when considering 3 malicious clients, as the all labels flipping attack makes its F1-Score reach an average value of around 14%. Even with a single malicious client, when performing all labels flipping and model cancelling attacks, although the average F1-Scores are respectively 90% and 92%, their minimum value over the 45 runs is 0% in both cases, making it still highly unreliable.\n\nUnsurprisingly, Coordinate-wise trimmed mean (TM( )) fails when used against more than malicious clients, as  clearly demonstrated in the model cancelling attack results ( Figure 6c). However, it does not mean that this aggregation function performs well when \u2265 , as the minimum F1-Score reaches 0% even for a single malicious client under the all labels flipping attack (Figure 6a). The only benefit of TM(1) and TM(2) over MED lies in the performance when no malicious client is involved, which is a bit better as more parameters are considered during the computation of the global model. This advantage might be higher in a use case with more clients, but in our case it is too low to justify the usage of TM.\n\nFinally, 2-Resampling shows an improvement of accuracy on the known devices when no malicious client is involved. However, this comes at the cost of reducing the robustness of the system, making TM(2) \u2022 2-Resampling have similar results as TM(1) most of the time. Still, a small improvement over TM (2), shown in Figure 6a, has to be noted with 2 and 3 malicious clients. Similarly to TM, s-Resampling does not provide enough advantage to be used in such a small federation, but it could become more useful at a larger scale.\n\nAs general remarks, although the resilience of the models has been greatly improved using MED under model poisoning attacks (gradient factor and model cancelling attacks), the performance of the model is still reduced substantially. In addition, in the case of the all labels flipping attack, AVG still performs better than other functions that seek to improve the robustness of the model. These results show that, although the model performance has been improved, further research on aggregation functions that are resilient to adversarial attacks is still required. We believe that in the case of other attacks that greatly affect the weights, results would be similar to those of gradient factor and model cancelling attacks. It is however unknown how performance would be affected in the case of other more sophisticated and stealthy attacks.\n\n\nDiscussion\n\nThis section discusses relevant aspects of performance and architecture design that must be considered when deployed on a real B5G environment. Although the performance in the malware detection experiments has proven to be high, aspects such as communication costs or framework centralization should be discussed.\n\n\nNumber of clients and adversarial results\n\nOne of the limitations in the experimentation has been the low number of clients used, 8 for training, due to the availability of datasets suitable for federated learning. In a real B5G scenario, device deployments will reach up to 10M devices per km 2 according to ITU (International Telecommunication Union) requirements [42]. However, we consider that the experiments are valid since, although the number of adversaries is low, namely 1, 2 and 3, the percentage they represent over the total number of clients performing the training is relatively high, 12.5%, 25% and 37.5%, respectively (see Figure 6). Thus, the results can be extrapolated to environments with a much larger number of clients but where the adversaries represent a small percentage of the total, no more than 50%.\n\nIn addition, other robust aggregation algorithms should be tested since the current ones do not offer sufficient attack resilience when the number of malicious clients exceeds 25%. In this regard, there are interesting proposals on aggregation algorithms that already take into account the possible presence of malicious clients and evaluate variations in the models it shares. The most interesting ones to be assessed as future work are Krum [18], Bulyan [43] and AUROR [44].\n\n\nCommunication and computation costs\n\nAlthough B5G throughput requirements (100 Mbps in [42]) exceed by far the requirements of the proposed solution, since the framework is designed for clients to be located at or near the access points, communication and computation costs should be considered. They are critical in order not to influence the regular operation of the wireless interfaces of the IoT objects and the network elements that provide access to them.\n\nMINI-BATCH AGGREGATION has much higher communication costs than MULTI-EPOCH AGGREGATION as it requires \u22c5 model transmissions per client for the full training,\n\nwhere is the batch size, is the number of epochs and is the number of training samples of client . Note that in terms of computation cost, it also indicates the number of local model updates performed by each client. On the other hand, MULTI-EPOCH AGGREGATION just requires the clients to transmit the model to the server once per round, for a total of transmissions per client. However, the number of local model updates is also times larger, i.e. \u22c5 \u22c5 for client . Table 6 shows the comparison between both aggregation algorithms in the experiments of Section 6.1 in terms of computation and communication costs. MULTI-EPOCH AVG shows much lower communication costs than MINI-BATCH AVG, \u22481300 times less in the case of the supervised approach and \u22482000 times less in the unsupervised counterpart. However, the number of local training iterations is 3.75 times higher for the hyper-parameters that have been selected. The throughput in a real 5G or B5G network should be sufficient to deploy any of the two algorithms. In addition, as stated in Section 4, the framework clients will be B5G base stations and other access points, which have a relatively high computational power. However, if the communication cost becomes a critical issue, it would be natural to opt for an approach based on MULTI-EPOCH AVG.\n\n\nDecentralization and non-synchronization\n\nAlthough the training of the models is decentralized at each client, having a server in charge of model aggregation has many advantages, such as controlling the common model generated, coordination between clients, etc. However, this design also brings with it some disadvantages.\n\nThe server becomes a central point of failure, where a bottleneck or attack can make it no longer possible to aggregate the local models, and only the local models can be used on each client. Therefore, it is necessary to ensure the correct scaling of the server functionalities to ensure that there are no bottlenecks and use the appropriate security solutions to prevent attacks on the server as much as possible. An additional solution would be to adapt the platform towards a purely decentralized approach where models are shared using Blockchain and each client performs the aggregation locally, eliminating the need for a coordinator in the process.\n\nAnother disadvantage is the synchronization required between clients when submitting their models for aggregation. A client that fails or is slow due to asynchrony may cause the server not to perform the training correctly [45]. Currently, the framework addresses this problem by setting a timeout for sending the models so that if one of the clients does not respond in time, it is skipped from that aggregation step. In this case, a Blockchain-based solution is also beneficial since it can be used as an asynchronous repository where each client can publish its models each time it trains them locally.\n\nDespite its benefits to solve both disadvantages, it is essential to consider that the use of Blockchain also brings with it a series of threats to cover, such as majority attacks or block validation attacks [46]. (b) Computation and communication costs in the unsupervised approach. When using MULTI-EPOCH AVG, = 3950 64 \u2243 62, and using MINI-BATCH AVG, = 3950 8 \u2243 494. Table 6 Computation and communication costs per client. The communication cost is from the client's perspective and has to be considered in both directions (download and upload). The assumed model sizes correspond to the largest architectures that were used in our experiments, for both the supervised and the unsupervised approaches.\n\n\nConclusions and Future Work\n\nThis work proposes a privacy-preserving framework for IoT malware detection that leverages FL to train and evaluate both supervised and unsupervised models without sharing sensitive data. This framework is designed to be deployed on the network nodes providing access to the IoT devices in Wifi, 5G or B5G networks, offloading the computation from the IoT device itself. In this sense, the client side is designed to be deployed on the RAN while the server side is intended for Fog/Cloud deployment. To demonstrate its feasibility in a realistic IoT scenario, the N-BaIoT dataset has been used due to its heterogeneity and divisibility in terms of IoT devices and malware samples. Using N-BaIoT, we compared the performance of: i) a federated approach, where all device owners train their own model, which are periodically aggregated in a server, ii) a non privacy-preserving setup, in which the whole dataset is centralized and trained by the server, and iii) a local setup where each device owner trains one isolated and individual model. This comparison has shown that the use of more diverse and larger data, as done in the federated and centralized methods, has a considerable positive impact on the model performance both in a supervised and in an unsupervised scenario. Besides, it has been demonstrated that the privacy of the data can be preserved without losing model performance by following the federated approach. The resilience of the federated models against malicious clients has been tested through the following adversarial attacks: i) a data poisoning attack flipping all labels, ii) a model poisoning attack multiplying gradients by a negative factor, and iii) a model cancelling attack. The results showed that without using a robust technique to aggregate the models, a single malicious client in the federation can ruin the model. Several robust aggregation functions, acting as countermeasures against adversarial attacks, have been applied to solve this problem, with median aggregation showing promising yet insufficient improvements. This first step in the direction of making the system robust against attacks shows that a lot of effort is still required to reach satisfying outcomes.\n\nAs future work, we plan to evaluate the impact of adversarial attacks in the unsupervised scenario to verify that they affect the results in a similar way as in the supervised counterpart. Moreover, testing the robustness of the model against evasion attacks, using forged adversarial samples to avoid detection at evaluation time, could also be an interesting future direction. Additionally, this work plans further research on the existing countermeasures against adversarial attacks, such as Krum, Bulyan and AUROR.\n\nScalability in real B5G scenarios is also a matter that could not be studied with any of the available datasets, raising a need for generating a much larger and much more diverse one. The deployment of the architecture in a fully distributed manner using Blockchain for the exchange of the federated models is also considered. Besides, Blockchain incorporation into the framework could improve possible security and privacy concerns of the clients.\n\nFigure 1 :\n1Framework architecture and its components. The sharing of normalization values and the collaborative hyperparameter selection are omitted for simplicity.\n\nFigure 2 :\n2Detailed view of the client architecture during training and evaluation. The initial model sharing (by the server) is omitted for simplicity. Steps 1, 2, 3 and 4 are meant to be repeated several times before the model is evaluated (step 5).\n\nFigure 3 :\n3Initial splitting of the dataset owned by client k for the supervised and the unsupervised situations. The relative size of the benign part with respect to the attack part is not respected for readability.\n\n\u2022\nModel cancelling attack. In this attack, malicious clients try to bring all the global model parameters to the value 0. They select their model in such a way that when averaged with the honest clients models, the original global model vanishes, i.e. ( ) = 0, \u2200 \u2208 [ ].\n\n\nby removing the largest and the smallest of its elements. The number of excluded elements is 2 . This aggregation function is referred as TM( ).\n\nFigure 4 :\n4Evolution of the known devices accuracy. The accuracies obtained with the centralized methods are displayed with dotted lines for comparison.\n\nFigure 5 :\n5Over the training epoch (MINI-BATCH AVG) Evolution of the global threshold values with both FL algorithms. The threshold obtained in the centralized method is displayed with a dotted line for comparison.\n\n\nmodel poisoning attacks, in the case of gradient factor attack, solving equation 2 gives = \u22122 . For a total of 8 clients including 1, 2, and 3 malicious clients, the values chosen for are respectively \u221215, \u22127 and \u2212 13 3 . In the case of model cancelling attack, solving equation 3 gives = \u2212 . For a total of 8 clients including 1, 2, and 3 malicious clients, the values chosen for are respectively \u22127, \u22123 and \u2212 5 3 .\n\nFigure 6 :\n6F1-Scores under the different tested attacks for each aggregation function, with = 0, 1, 2 or 3 malicious clients (respectively 0%, 12.5%, 25% and 37.5% of the total clients). The minimum and maximum values (over the 45 runs) of the F1-Scores are displayed with capped bars.\n\n\nNumber of benign and attack samples for each device.Device \nBenign \nsamples \n\nAttack \nsamples \n\nDanmini Doorbell \n49 548 \n968 750 \n\nEcobee Thermostat \n13 113 \n822 763 \n\nEnnio Doorbell \n39 100 \n316 400 \n\nPhilips B120N10 \nBaby Monitor \n175 240 \n923 437 \n\nProvision PT-737E \nSecurity Camera \n62 154 \n766 106 \n\nProvision PT-838 \nSecurity Camera \n98 514 \n738 377 \n\nSamsung SNH-1011-N \nWebcam \n52 150 \n323 072 \n\nSimpleHome XCS7-1002 \n-WHT Security Camera \n46 585 \n816 471 \n\nSimpleHome XCS7-1003 \n-WHT Security Camera \n19 528 \n831 298 \n\nTotal \n555 932 \n(7.87%) \n\n6 506 674 \n(92.13%) \n\nTable 2 \n\n\n\nbetween federated and traditional approaches when following both a supervised or an unsupervised solution. After that, it shows the impact of the adversarial attacks proposed in Section 5, and how the different aggregation functions mitigate those attacks.The metrics used to evaluate and compare the performance of each approach are the following(TP: True Positives, TN: True Negatives, FP: False Positives, FN: False Negatives, TPR: True Positive Rate, TNR: True Negative Rate)::{ \n\u2236 \u2208 [ ]}, , { [ ] \u2236= 0 \u2236 \u2208 [ ]} \nfor \u2032 \u2236= 1, \u2026 , do \nfor \u2236= 1, \u2026 , do \nwhile Select \u223c Uniform([ ]) do \nif [ ] < then \n[ ] += 1 \nbreak \nCompute average\u0304 \u2032 \u2236= 1 \u2211 \n\n=1 \n\nreturn {\u0304 \u2032 \u2236 \u2032 \u2208 [ ]} \n\n\n\n\n(a) Computation and communication costs in the supervised approach. When using MULTI-EPOCH AVG, = 79000 64 \u2243 1234, and using MINI-BATCH AVG, = 79000Multi-epoch \navg \n\nMini-batch \navg \n\nNumber of model \ntransmissions \n= 30 \n\n\u22c5 \n= 4 \u22c5 9875 \n= 39500 \nCommunication cost \nassuming a model \nof size 94 kB \n\n2.82 MB \n3.713 GB \n\nNumber of local \ntraining steps \n\n\u22c5 \u22c5 \n\u2243 30 \u22c5 4 \u22c5 1234 \n= 148080 \n\n\u22c5 \n= 4 \u22c5 9875 \n= 39500 \n\n8 \n\n= 9875. \n\nMulti-epoch \navg \n\nMini-batch \navg \n\nNumber of model \ntransmissions \n= 30 \n\n\u22c5 \n\u2243 120 \u22c5 494 \n= 59280 \nCommunication cost \nassuming a model \nof size 27 kB \n\n810 kB \n1.6 GB \n\nNumber of local \ntraining steps \n\n\u22c5 \u22c5 \n\u2243 30 \u22c5 120 \u22c5 62 \n= 223200 \n\n\u22c5 \n\u2243 120 \u22c5 494 \n= 59280 \n\n\nAcknowledgementsThis work has been partially supported by (a) the Swiss Federal Office for Defense Procurement (armasuisse) with the TREASURE (R-3210/047-31) and CyberSpec (CYD-C-2020003) projects, by (b) the European Commission through 5GZORRO project (Grant No. 871533) part of the 5G PPP in Horizon 2020, and by (c) the University of Z\u00fcrich UZH. We also thank Freepik for the icons used to represent the IoT devices inFigure 1.\n. IP. scenario [26] TON_IoT 2019 IP, scenarioIP, scenario [26] TON_IoT 2019 IP, scenario\n\nIoT benign & attack traces 2019 IP, scenario. IoT benign & attack traces 2019 IP, scenario\n\nA dynamic and hierarchical access control for iot in multi-authority cloud storage. K Riad, T Huang, L Ke, Journal of Network and Computer Applications. 160102633K. Riad, T. Huang, and L. Ke, \"A dynamic and hierarchical access control for iot in multi-authority cloud storage,\" Journal of Network and Computer Applications, vol. 160, p. 102633, 2020.\n\nIot-based big data secure management in the fog over a 6g wireless network. C L Stergiou, K E Psannis, B B Gupta, IEEE Internet of Things Journal. 87C. L. Stergiou, K. E. Psannis, and B. B. Gupta, \"Iot-based big data secure management in the fog over a 6g wireless network,\" IEEE Internet of Things Journal, vol. 8, no. 7, pp. 5164-5171, 2020.\n\nSecurity in internet of things: issues, challenges, taxonomy, and architecture. V Adat, B B Gupta, Telecommunication Systems. 673V. Adat and B. B. Gupta, \"Security in internet of things: issues, challenges, taxonomy, and architecture,\" Telecommunication Systems, vol. 67, no. 3, pp. 423-441, 2018.\n\nA Survey on Device Behavior Fingerprinting: Data Sources, Techniques, Application Scenarios, and Datasets. P M S S\u00e1nchez, J M J Valero, A H Celdr\u00e1n, G Bovet, M G P\u00e9rez, G M P\u00e9rez, IEEE Communications Surveys & Tutorials. In pressP. M. S. S\u00e1nchez, J. M. J. Valero, A. H. Celdr\u00e1n, G. Bovet, , M. G. P\u00e9rez, and G. M. P\u00e9rez, \"A Survey on Device Behavior Fingerprinting: Data Sources, Techniques, Application Scenarios, and Datasets,\" IEEE Communications Surveys & Tutorials, In press.\n\nIntrusion detection systems for iot-based smart environments: a survey. M F Elrawy, A I Awad, H F Hamed, Journal of Cloud Computing. 71M. F. Elrawy, A. I. Awad, and H. F. Hamed, \"Intrusion detection systems for iot-based smart environments: a survey,\" Journal of Cloud Computing, vol. 7, no. 1, pp. 1-20, 2018.\n\nEmpowering the edge intelligence by air-ground integrated federated learning in 6g networks. Y Qu, C Dong, J Zheng, Q Wu, Y Shen, F Wu, A Anpalagan, arXiv:2007.13054arXiv preprintY. Qu, C. Dong, J. Zheng, Q. Wu, Y. Shen, F. Wu, and A. Anpalagan, \"Empowering the edge intelligence by air-ground integrated federated learning in 6g networks,\" arXiv preprint arXiv:2007.13054, 2020.\n\nCommunication-efficient learning of deep networks from decentralized data. B Mcmahan, E Moore, D Ramage, S Hampson, B A Arcas, Artificial Intelligence and Statistics, ser. Proceedings of Machine Learning. Research, A. Singh and J. ZhuLauderdale, FL, USAPMLR54B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, \"Communication-efficient learning of deep networks from decentralized data,\" in Artificial Intelligence and Statistics, ser. Proceedings of Machine Learning Research, A. Singh and J. Zhu, Eds., vol. 54. Fort Lauderdale, FL, USA: PMLR, 20-22 Apr 2017, pp. 1273-1282. [Online]. Available: http: //proceedings.mlr.press/v54/mcmahan17a.html\n\nFederated machine learning: Concept and applications. Q Yang, Y Liu, T Chen, Y Tong, 10.1145/3298981ACM Trans. Intell. Syst. Technol. 102Q. Yang, Y. Liu, T. Chen, and Y. Tong, \"Federated machine learning: Concept and applications,\" ACM Trans. Intell. Syst. Technol., vol. 10, no. 2, Jan. 2019. [Online]. Available: https://doi.org/10.1145/3298981\n\nFederated learning for 6g communications: Challenges, methods, and future directions. Y Liu, X Yuan, Z Xiong, J Kang, X Wang, D Niyato, China Communications. 179Y. Liu, X. Yuan, Z. Xiong, J. Kang, X. Wang, and D. Niyato, \"Feder- ated learning for 6g communications: Challenges, methods, and future directions,\" China Communications, vol. 17, no. 9, pp. 105-118, 2020.\n\nFed-iiot: A robust federated malware detection architecture in industrial iot. R Taheri, M Shojafar, M Alazab, R Tafazolli, IEEE Transactions on Industrial Informatics. R. Taheri, M. Shojafar, M. Alazab, and R. Tafazolli, \"Fed-iiot: A robust federated malware detection architecture in industrial iot,\" IEEE Transactions on Industrial Informatics, 2020.\n\nCommunication-efficient federated learning for anomaly detection in industrial internet of things. Y Liu, N Kumar, Z Xiong, W Y B Lim, J Kang, D Niyato, GLOBECOM. 2020Y. Liu, N. Kumar, Z. Xiong, W. Y. B. Lim, J. Kang, and D. Niyato, \"Communication-efficient federated learning for anomaly detection in industrial internet of things,\" in GLOBECOM, vol. 2020, 2020, pp. 1-6.\n\nChained anomaly detection models for federated learning: An intrusion detection case study. D Preuveneers, V Rimmer, I Tsingenopoulos, J Spooren, W Joosen, E Ilie-Zudor, Applied Sciences. 8122663D. Preuveneers, V. Rimmer, I. Tsingenopoulos, J. Spooren, W. Joosen, and E. Ilie-Zudor, \"Chained anomaly detection models for federated learning: An intrusion detection case study,\" Applied Sciences, vol. 8, no. 12, p. 2663, 2018.\n\nEdima: Early detection of iot malware network activity using machine learning techniques. A Kumar, T J Lim, 2019 IEEE 5th World Forum on Internet of Things (WF-IoT). IEEEA. Kumar and T. J. Lim, \"Edima: Early detection of iot malware network activity using machine learning techniques,\" in 2019 IEEE 5th World Forum on Internet of Things (WF-IoT). IEEE, 2019, pp. 289-294.\n\nD\u00efot: A federated self-learning anomaly detection system for iot. T D Nguyen, S Marchal, M Miettinen, H Fereidooni, N Asokan, A.-R Sadeghi, 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS). IEEET. D. Nguyen, S. Marchal, M. Miettinen, H. Fereidooni, N. Asokan, and A.-R. Sadeghi, \"D\u00efot: A federated self-learning anomaly detec- tion system for iot,\" in 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS). IEEE, 2019, pp. 756-767.\n\nAdvances and Open Problems in Federated Learning. P Kairouz, H B Mcmahan, arXiv:1912.04977arXiv e-printsP. Kairouz, H. B. McMahan et al., \"Advances and Open Problems in Federated Learning,\" arXiv e-prints, p. arXiv:1912.04977, Dec. 2019.\n\nPrivacy and robustness in federated learning: Attacks and defenses. L Lyu, H Yu, X Ma, L Sun, J Zhao, Q Yang, P S Yu, arXiv:2012.06337arXiv preprintL. Lyu, H. Yu, X. Ma, L. Sun, J. Zhao, Q. Yang, and P. S. Yu, \"Privacy and robustness in federated learning: Attacks and defenses,\" arXiv preprint arXiv:2012.06337, 2020.\n\nPoisoning attacks against support vector machines. B Biggio, B Nelson, P Laskov, Proceedings of the 29th International Coference on International Conference on Machine Learning. the 29th International Coference on International Conference on Machine LearningB. Biggio, B. Nelson, and P. Laskov, \"Poisoning attacks against support vector machines,\" in Proceedings of the 29th International Coference on International Conference on Machine Learning, 2012, pp. 1467- 1474.\n\nMachine learning with adversaries: Byzantine tolerant gradient descent. P Blanchard, E M Mhamdi, R Guerraoui, J Stainer, Proceedings of the 31st International Conference on Neural Information Processing Systems. the 31st International Conference on Neural Information Processing SystemsP. Blanchard, E. M. El Mhamdi, R. Guerraoui, and J. Stainer, \"Machine learning with adversaries: Byzantine tolerant gradient descent,\" in Pro- ceedings of the 31st International Conference on Neural Information Processing Systems, 2017, pp. 118-128.\n\nByzantinerobust distributed learning: Towards optimal statistical rates. D Yin, Y Chen, R Kannan, P Bartlett, Proceedings of the 35th International Conference on Machine Learning, ser. Proceedings of Machine Learning. Research, J. Dy and A. Krausethe 35th International Conference on Machine Learning, ser. Machine LearningStockholm SwedenPMLR80D. Yin, Y. Chen, R. Kannan, and P. Bartlett, \"Byzantine- robust distributed learning: Towards optimal statistical rates,\" in Proceedings of the 35th International Conference on Machine Learning, ser. Proceedings of Machine Learning Research, J. Dy and A. Krause, Eds., vol. 80. Stockholmsm\u00e4ssan, Stockholm Sweden: PMLR, 10-15 Jul 2018, pp. 5650-5659. [Online]. Available: http://proceedings.mlr.press/v80/yin18a.html\n\nByzantine-robust learning on heterogeneous datasets via resampling. L He, S P Karimireddy, M Jaggi, arXiv:2006.09365arXiv preprintL. He, S. P. Karimireddy, and M. Jaggi, \"Byzantine-robust learn- ing on heterogeneous datasets via resampling,\" arXiv preprint arXiv:2006.09365, 2020.\n\nApplying the dynamics of evolution to achieve reliability in master-worker computing. E Christoforou, A F Anta, C Georgiou, M A Mosteiro, A S\u00e1nchez, Concurrency and Computation: Practice and Experience. 2517E. Christoforou, A. F. Anta, C. Georgiou, M. A. Mosteiro, and A. S\u00e1nchez, \"Applying the dynamics of evolution to achieve reliab- ility in master-worker computing,\" Concurrency and Computation: Practice and Experience, vol. 25, no. 17, pp. 2363-2380, 2013.\n\nN-baiot-network-based detection of iot botnet attacks using deep autoencoders. Y Meidan, M Bohadana, Y Mathov, Y Mirsky, A Shabtai, D Breitenbacher, Y Elovici, IEEE Pervasive Computing. 173Y. Meidan, M. Bohadana, Y. Mathov, Y. Mirsky, A. Shabtai, D. Breit- enbacher, and Y. Elovici, \"N-baiot-network-based detection of iot botnet attacks using deep autoencoders,\" IEEE Pervasive Computing, vol. 17, no. 3, pp. 12-22, 2018.\n\nMedbiot: Generation of an iot botnet dataset in a medium-sized iot network. A Guerra-Manzanares, J Medina-Galindo, H Bahsi, S N\u00f5mm, ICISSP. A. Guerra-Manzanares, J. Medina-Galindo, H. Bahsi, and S. N\u00f5mm, \"Medbiot: Generation of an iot botnet dataset in a medium-sized iot network.\" in ICISSP, 2020, pp. 207-218.\n\nKitsune: An ensemble of autoencoders for online network intrusion detection. Y Mirsky, T Doitshman, Y Elovici, A Shabtai, 25th Annual Network and Distributed System Security Symposium. San Diego, California, USAY. Mirsky, T. Doitshman, Y. Elovici, and A. Shabtai, \"Kit- sune: An ensemble of autoencoders for online network intrusion detection,\" in 25th Annual Network and Distributed System Se- curity Symposium, NDSS 2018, San Diego, California, USA, February 18-21, 2018. The Internet Society, 2018. [Online]. Avail- able: http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/ 2018/02/ndss2018_03A-3_Mirsky_paper.pdf\n\nTowards the development of realistic botnet dataset in the internet of things for network forensic analytics: Bot-iot dataset. N Koroniotis, N Moustafa, E Sitnikova, B Turnbull, Future Generation Computer Systems. 100N. Koroniotis, N. Moustafa, E. Sitnikova, and B. Turnbull, \"Towards the development of realistic botnet dataset in the internet of things for network forensic analytics: Bot-iot dataset,\" Future Generation Computer Systems, vol. 100, pp. 779-796, 2019.\n\nTon_iot telemetry dataset: a new generation dataset of iot and iiot for data-driven intrusion detection systems. A Alsaedi, N Moustafa, Z Tari, A Mahmood, A Anwar, IEEE Access. 8A. Alsaedi, N. Moustafa, Z. Tari, A. Mahmood, and A. Anwar, \"Ton_iot telemetry dataset: a new generation dataset of iot and iiot for data-driven intrusion detection systems,\" IEEE Access, vol. 8, pp. 165 130-165 150, 2020.\n\nDetecting volumetric attacks on lot devices via sdn-based monitoring of mud activity. A Hamza, H H Gharakheili, T A Benson, V Sivaraman, Proceedings of the 2019 ACM Symposium on SDN Research. the 2019 ACM Symposium on SDN ResearchA. Hamza, H. H. Gharakheili, T. A. Benson, and V. Sivaraman, \"De- tecting volumetric attacks on lot devices via sdn-based monitoring of mud activity,\" in Proceedings of the 2019 ACM Symposium on SDN Research, 2019, pp. 36-48.\n\nIot network intrusion dataset. H Kang, D H Ahn, G M Lee, J D Yoo, K H Park, H K Kim, IEEE Dataport. H. Kang, D. H. Ahn, G. M. Lee, J. D. Yoo, K. H. Park, and H. K. Kim, \"Iot network intrusion dataset,\" IEEE Dataport, 2019. [Online].\n\n. 10.21227/q70p-q449Available: https://dx.doi.org/10.21227/q70p-q449\n\nA labeled dataset with malicious and benign iot network traffic. A Parmisano, S Garcia, M J Erquiaga, Stratosphere Laboratory. A. Parmisano, S. Garcia, and M. J. Erquiaga, \"A labeled dataset with malicious and benign iot network traffic,\" Stratosphere Laboratory, 2020. [Online]. Available: https://www.stratosphereips. org/datasets-iot23\n\nThe road beyond 5g: A vision and insight of the key technologies. K Samdanis, T Taleb, IEEE Network. 342K. Samdanis and T. Taleb, \"The road beyond 5g: A vision and insight of the key technologies,\" IEEE Network, vol. 34, no. 2, pp. 135-141, 2020.\n\nHcp: Heterogeneous computing platform for federated learning based collaborative content caching towards 6g networks. Z M Fadlullah, N Kato, IEEE Transactions on Emerging Topics in Computing. Z. M. Fadlullah and N. Kato, \"Hcp: Heterogeneous computing plat- form for federated learning based collaborative content caching towards 6g networks,\" IEEE Transactions on Emerging Topics in Computing, 2020.\n\nBotnet attack detection at the iot edge based on sparse representation. C Tzagkarakis, N Petroulakis, S Ioannidis, 2019 Global IoT Summit (GIoTS). IEEEC. Tzagkarakis, N. Petroulakis, and S. Ioannidis, \"Botnet attack detec- tion at the iot edge based on sparse representation,\" in 2019 Global IoT Summit (GIoTS). IEEE, 2019, pp. 1-6.\n\nUnsupervised anomaly based botnet detection in iot networks. S N\u00f5mm, H Bah\u015fi, 2018 17th IEEE international conference on machine learning and applications (ICMLA). IEEES. N\u00f5mm and H. Bah\u015fi, \"Unsupervised anomaly based botnet detec- tion in iot networks,\" in 2018 17th IEEE international conference on machine learning and applications (ICMLA). IEEE, 2018, pp. 1048-1053.\n\nDimensionality reduction for machine learning based iot botnet detection. H Bah\u015fi, S N\u00f5mm, F B La Torre, 2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV). IEEEH. Bah\u015fi, S. N\u00f5mm, and F. B. La Torre, \"Dimensionality reduction for machine learning based iot botnet detection,\" in 2018 15th Inter- national Conference on Control, Automation, Robotics and Vision (ICARCV). IEEE, 2018, pp. 1857-1862.\n\nCollaborative learning model for cyberattack detection systems in iot industry 4.0. T V Khoa, Y M Saputra, D T Hoang, N L Trung, D Nguyen, N V Ha, E Dutkiewicz, 2020 IEEE Wireless Communications and Networking Conference (WCNC). IEEET. V. Khoa, Y. M. Saputra, D. T. Hoang, N. L. Trung, D. Nguyen, N. V. Ha, and E. Dutkiewicz, \"Collaborative learning model for cyberattack detection systems in iot industry 4.0,\" in 2020 IEEE Wireless Com- munications and Networking Conference (WCNC). IEEE, 2020, pp. 1-6.\n\nUnsupervised intelligent system based on one class support vector machine and grey wolf optimization for iot botnet detection. A Shorman, H Faris, I Aljarah, Journal of Ambient Intelligence and Humanized Computing. 117A. Al Shorman, H. Faris, and I. Aljarah, \"Unsupervised intelligent system based on one class support vector machine and grey wolf optimization for iot botnet detection,\" Journal of Ambient Intelligence and Humanized Computing, vol. 11, no. 7, pp. 2809-2825, 2020.\n\n. V Rey, Last accessV. Rey, \"fed_iot_guard,\" 2021, (Last access: 11-April-2021). [Online]. Available: https://github.com/ValerianRey/fed_iot_guard\n\nA survey on beyond 5g network with the advent of 6g: Architecture and emerging technologies. A Dogra, R K Jha, S Jain, IEEE Access. 9A. Dogra, R. K. Jha, and S. Jain, \"A survey on beyond 5g network with the advent of 6g: Architecture and emerging technologies,\" IEEE Access, vol. 9, pp. 67 512-67 547, 2020.\n\nFast and accurate deep network learning by exponential linear units (elus). D.-A Clevert, T Unterthiner, S Hochreiter, arXiv:1511.07289arXiv preprintD.-A. Clevert, T. Unterthiner, and S. Hochreiter, \"Fast and accurate deep network learning by exponential linear units (elus),\" arXiv pre- print arXiv:1511.07289, 2015.\n\nThe Byzantine Generals Problem. L Lamport, R Shostak, M Pease, 10.1145/3335772.3335936Association for Computing MachineryNew York, NY, USAL. Lamport, R. Shostak, and M. Pease, The Byzantine Generals Problem. New York, NY, USA: Association for Computing Machinery, 1982, p. 203-226. [Online]. Available: https://doi.org/10. 1145/3335772.3335936\n\nAnalyzing federated learning through an adversarial lens. A N Bhagoji, S Chakraborty, P Mittal, S Calo, PMLR, 09-15Proceedings of the 36th International Conference on Machine Learning, ser. Proceedings of Machine Learning. Research, K. Chaudhuri and R. Salakhutdinovthe 36th International Conference on Machine Learning, ser. Machine Learning97A. N. Bhagoji, S. Chakraborty, P. Mittal, and S. Calo, \"Analyzing federated learning through an adversarial lens,\" in Proceedings of the 36th International Conference on Machine Learning, ser. Proceedings of Machine Learning Research, K. Chaudhuri and R. Salakhutdinov, Eds., vol. 97. PMLR, 09-15 Jun 2019, pp. 634-643. [Online].\n\nDetailed specifications of the terrestrial radio interfaces of international mobile telecommunications-2020 (imt-2020). M Series, ReportM. Series, \"Detailed specifications of the terrestrial radio interfaces of international mobile telecommunications-2020 (imt-2020),\" Report, pp. 2410-0, 2021.\n\nThe hidden vulnerability of distributed learning in byzantium. R Guerraoui, S Rouault, International Conference on Machine Learning. PMLRR. Guerraoui, S. Rouault et al., \"The hidden vulnerability of distrib- uted learning in byzantium,\" in International Conference on Machine Learning. PMLR, 2018, pp. 3521-3530.\n\nAuror: Defending against poisoning attacks in collaborative deep learning systems. S Shen, S Tople, P Saxena, Proceedings of the 32nd Annual Conference on Computer Security Applications. the 32nd Annual Conference on Computer Security ApplicationsS. Shen, S. Tople, and P. Saxena, \"Auror: Defending against poisoning attacks in collaborative deep learning systems,\" in Proceedings of the 32nd Annual Conference on Computer Security Applications, 2016, pp. 508-519.\n\nIot transaction processing through cooperative concurrency control on fogcloud computing environment. A Al-Qerem, M Alauthman, A Almomani, B Gupta, Soft Computing. 248A. Al-Qerem, M. Alauthman, A. Almomani, and B. Gupta, \"Iot trans- action processing through cooperative concurrency control on fog- cloud computing environment,\" Soft Computing, vol. 24, no. 8, pp. 5695-5711, 2020.\n\nExploring the attack surface of blockchain: A comprehensive survey. M Saad, J Spaulding, L Njilla, C Kamhoua, S Shetty, D Nyang, D Mohaisen, IEEE Communications Surveys & Tutorials. 223M. Saad, J. Spaulding, L. Njilla, C. Kamhoua, S. Shetty, D. Nyang, and D. Mohaisen, \"Exploring the attack surface of blockchain: A comprehensive survey,\" IEEE Communications Surveys & Tutorials, vol. 22, no. 3, pp. 1977-2008, 2020.\n", "annotations": {"author": "[{\"end\":145,\"start\":59},{\"end\":271,\"start\":146},{\"end\":410,\"start\":272},{\"end\":498,\"start\":411},{\"end\":585,\"start\":499}]", "publisher": null, "author_last_name": "[{\"end\":71,\"start\":68},{\"end\":174,\"start\":152},{\"end\":295,\"start\":288},{\"end\":423,\"start\":418},{\"end\":511,\"start\":506}]", "author_first_name": "[{\"end\":67,\"start\":59},{\"end\":151,\"start\":146},{\"end\":279,\"start\":272},{\"end\":287,\"start\":280},{\"end\":417,\"start\":411},{\"end\":505,\"start\":499}]", "author_affiliation": "[{\"end\":144,\"start\":73},{\"end\":270,\"start\":176},{\"end\":409,\"start\":297},{\"end\":497,\"start\":425},{\"end\":584,\"start\":513}]", "title": "[{\"end\":56,\"start\":1},{\"end\":641,\"start\":586}]", "venue": null, "abstract": "[{\"end\":3464,\"start\":742}]", "bib_ref": "[{\"end\":3566,\"start\":3563},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3901,\"start\":3898},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4094,\"start\":4091},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4559,\"start\":4556},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4946,\"start\":4943},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5290,\"start\":5287},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6090,\"start\":6087},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6655,\"start\":6652},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7068,\"start\":7065},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7129,\"start\":7125},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7132,\"start\":7129},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7135,\"start\":7132},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11333,\"start\":11330},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11590,\"start\":11586},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11712,\"start\":11709},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12073,\"start\":12069},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12435,\"start\":12431},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12438,\"start\":12435},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12678,\"start\":12674},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13339,\"start\":13336},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13983,\"start\":13980},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":13986,\"start\":13983},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":14166,\"start\":14162},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14336,\"start\":14332},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14595,\"start\":14591},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15217,\"start\":15213},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":15449,\"start\":15445},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":16042,\"start\":16038},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":17209,\"start\":17205},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":17424,\"start\":17420},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":17726,\"start\":17722},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":17959,\"start\":17955},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":18108,\"start\":18104},{\"end\":18328,\"start\":18324},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":18601,\"start\":18597},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":18789,\"start\":18785},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":19703,\"start\":19699},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":19952,\"start\":19948},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":23404,\"start\":23400},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":23407,\"start\":23404},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":23410,\"start\":23407},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":23413,\"start\":23410},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":23416,\"start\":23413},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":23419,\"start\":23416},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":23552,\"start\":23548},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":23625,\"start\":23621},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":24209,\"start\":24205},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":25170,\"start\":25166},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":25546,\"start\":25542},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":25726,\"start\":25722},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":26426,\"start\":26422},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":26953,\"start\":26949},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":26956,\"start\":26953},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":26959,\"start\":26956},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":27053,\"start\":27049},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":32264,\"start\":32260},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":32583,\"start\":32579},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":33642,\"start\":33638},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":34219,\"start\":34215},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":34769,\"start\":34765},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":35109,\"start\":35106},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":35969,\"start\":35966},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":37625,\"start\":37621},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":43394,\"start\":43390},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":44062,\"start\":44058},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":44065,\"start\":44062},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":44575,\"start\":44571},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":46448,\"start\":46444},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":48098,\"start\":48094},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":48875,\"start\":48871},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":49316,\"start\":49312},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":49856,\"start\":49852},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":50569,\"start\":50565},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":51280,\"start\":51276},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":55685,\"start\":55682},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":59495,\"start\":59492},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":63005,\"start\":63002},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":64777,\"start\":64773},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":65684,\"start\":65680},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":65697,\"start\":65693},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":65712,\"start\":65708},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":65807,\"start\":65803},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":68858,\"start\":68854},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":69450,\"start\":69446}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":73323,\"start\":73157},{\"attributes\":{\"id\":\"fig_1\"},\"end\":73577,\"start\":73324},{\"attributes\":{\"id\":\"fig_2\"},\"end\":73796,\"start\":73578},{\"attributes\":{\"id\":\"fig_3\"},\"end\":74067,\"start\":73797},{\"attributes\":{\"id\":\"fig_4\"},\"end\":74214,\"start\":74068},{\"attributes\":{\"id\":\"fig_5\"},\"end\":74369,\"start\":74215},{\"attributes\":{\"id\":\"fig_6\"},\"end\":74586,\"start\":74370},{\"attributes\":{\"id\":\"fig_7\"},\"end\":75005,\"start\":74587},{\"attributes\":{\"id\":\"fig_9\"},\"end\":75293,\"start\":75006},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":75883,\"start\":75294},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":76563,\"start\":75884},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":77259,\"start\":76564}]", "paragraph": "[{\"end\":4265,\"start\":3480},{\"end\":4445,\"start\":4267},{\"end\":4947,\"start\":4447},{\"end\":5996,\"start\":4949},{\"end\":6876,\"start\":5998},{\"end\":7973,\"start\":6878},{\"end\":8086,\"start\":7975},{\"end\":8336,\"start\":8088},{\"end\":8610,\"start\":8338},{\"end\":9201,\"start\":8612},{\"end\":9591,\"start\":9203},{\"end\":9808,\"start\":9593},{\"end\":10755,\"start\":9810},{\"end\":11159,\"start\":10772},{\"end\":11677,\"start\":11209},{\"end\":11885,\"start\":11679},{\"end\":13008,\"start\":11887},{\"end\":13200,\"start\":13010},{\"end\":14030,\"start\":13271},{\"end\":15738,\"start\":14032},{\"end\":16043,\"start\":15740},{\"end\":17200,\"start\":16100},{\"end\":18176,\"start\":17202},{\"end\":18903,\"start\":18178},{\"end\":19143,\"start\":18905},{\"end\":19368,\"start\":19190},{\"end\":21210,\"start\":19370},{\"end\":21880,\"start\":21212},{\"end\":22293,\"start\":21882},{\"end\":23264,\"start\":22295},{\"end\":24462,\"start\":23266},{\"end\":24834,\"start\":24516},{\"end\":25173,\"start\":24836},{\"end\":26197,\"start\":25184},{\"end\":26513,\"start\":26218},{\"end\":27054,\"start\":26525},{\"end\":28225,\"start\":27056},{\"end\":28405,\"start\":28227},{\"end\":28586,\"start\":28407},{\"end\":28697,\"start\":28588},{\"end\":28856,\"start\":28699},{\"end\":29218,\"start\":28858},{\"end\":30310,\"start\":29220},{\"end\":30531,\"start\":30312},{\"end\":31002,\"start\":30554},{\"end\":31762,\"start\":31021},{\"end\":31931,\"start\":31764},{\"end\":31980,\"start\":31933},{\"end\":32037,\"start\":31982},{\"end\":32116,\"start\":32039},{\"end\":32199,\"start\":32118},{\"end\":32435,\"start\":32201},{\"end\":33686,\"start\":32437},{\"end\":33896,\"start\":33728},{\"end\":33966,\"start\":33898},{\"end\":34026,\"start\":33968},{\"end\":34220,\"start\":34028},{\"end\":34970,\"start\":34222},{\"end\":35439,\"start\":34972},{\"end\":36360,\"start\":35441},{\"end\":36740,\"start\":36381},{\"end\":37085,\"start\":36742},{\"end\":37792,\"start\":37096},{\"end\":38053,\"start\":37817},{\"end\":38299,\"start\":38075},{\"end\":38680,\"start\":38310},{\"end\":39309,\"start\":38682},{\"end\":39693,\"start\":39359},{\"end\":40270,\"start\":39725},{\"end\":40552,\"start\":40316},{\"end\":40937,\"start\":40582},{\"end\":41191,\"start\":40939},{\"end\":41695,\"start\":41193},{\"end\":42576,\"start\":41733},{\"end\":42807,\"start\":42578},{\"end\":43147,\"start\":42851},{\"end\":43322,\"start\":43171},{\"end\":43843,\"start\":43324},{\"end\":44066,\"start\":43845},{\"end\":44620,\"start\":44068},{\"end\":44931,\"start\":44622},{\"end\":45169,\"start\":44933},{\"end\":45372,\"start\":45171},{\"end\":46216,\"start\":45374},{\"end\":46758,\"start\":46218},{\"end\":47269,\"start\":46779},{\"end\":47804,\"start\":47283},{\"end\":48803,\"start\":47843},{\"end\":49247,\"start\":48805},{\"end\":50956,\"start\":49249},{\"end\":51287,\"start\":51050},{\"end\":52014,\"start\":51385},{\"end\":52421,\"start\":52112},{\"end\":52627,\"start\":52423},{\"end\":52775,\"start\":52629},{\"end\":52948,\"start\":52777},{\"end\":53124,\"start\":52950},{\"end\":54362,\"start\":53126},{\"end\":54693,\"start\":54364},{\"end\":55307,\"start\":54695},{\"end\":56070,\"start\":55309},{\"end\":56301,\"start\":56072},{\"end\":56422,\"start\":56303},{\"end\":57759,\"start\":56424},{\"end\":58435,\"start\":57761},{\"end\":59187,\"start\":58512},{\"end\":59563,\"start\":59189},{\"end\":59906,\"start\":59565},{\"end\":60687,\"start\":59908},{\"end\":61331,\"start\":60689},{\"end\":61987,\"start\":61333},{\"end\":62701,\"start\":61989},{\"end\":63228,\"start\":62703},{\"end\":64076,\"start\":63230},{\"end\":64404,\"start\":64091},{\"end\":65235,\"start\":64450},{\"end\":65713,\"start\":65237},{\"end\":66177,\"start\":65753},{\"end\":66337,\"start\":66179},{\"end\":67647,\"start\":66339},{\"end\":67972,\"start\":67692},{\"end\":68629,\"start\":67974},{\"end\":69236,\"start\":68631},{\"end\":69942,\"start\":69238},{\"end\":72186,\"start\":69974},{\"end\":72706,\"start\":72188},{\"end\":73156,\"start\":72708}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":33727,\"start\":33687},{\"attributes\":{\"id\":\"formula_1\"},\"end\":38309,\"start\":38300},{\"attributes\":{\"id\":\"formula_2\"},\"end\":46778,\"start\":46759},{\"attributes\":{\"id\":\"formula_3\"},\"end\":47282,\"start\":47270},{\"attributes\":{\"id\":\"formula_4\"},\"end\":51026,\"start\":50957},{\"attributes\":{\"id\":\"formula_5\"},\"end\":51384,\"start\":51288}]", "table_ref": "[{\"end\":16262,\"start\":16255},{\"end\":18147,\"start\":18140},{\"end\":22208,\"start\":22201},{\"end\":43758,\"start\":43751},{\"end\":43915,\"start\":43908},{\"end\":54644,\"start\":54637},{\"end\":55844,\"start\":55837},{\"end\":57009,\"start\":57002},{\"end\":57619,\"start\":57612},{\"end\":66812,\"start\":66805},{\"end\":69615,\"start\":69608}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":3478,\"start\":3466},{\"attributes\":{\"n\":\"2.\"},\"end\":10770,\"start\":10758},{\"attributes\":{\"n\":\"2.1.\"},\"end\":11207,\"start\":11162},{\"attributes\":{\"n\":\"2.2.\"},\"end\":13269,\"start\":13203},{\"attributes\":{\"n\":\"2.3.\"},\"end\":16098,\"start\":16046},{\"attributes\":{\"n\":\"3.\"},\"end\":19188,\"start\":19146},{\"attributes\":{\"n\":\"4.\"},\"end\":24514,\"start\":24465},{\"attributes\":{\"n\":\"4.1.\"},\"end\":25182,\"start\":25176},{\"attributes\":{\"n\":\"4.1.1.\"},\"end\":26216,\"start\":26200},{\"attributes\":{\"n\":\"4.1.2.\"},\"end\":26523,\"start\":26516},{\"attributes\":{\"n\":\"4.1.3.\"},\"end\":30552,\"start\":30534},{\"attributes\":{\"n\":\"4.1.4.\"},\"end\":31019,\"start\":31005},{\"attributes\":{\"n\":\"4.1.5.\"},\"end\":36379,\"start\":36363},{\"attributes\":{\"n\":\"4.2.\"},\"end\":37094,\"start\":37088},{\"attributes\":{\"n\":\"4.2.1.\"},\"end\":37815,\"start\":37795},{\"attributes\":{\"n\":\"4.2.2.\"},\"end\":38073,\"start\":38056},{\"attributes\":{\"n\":\"4.3.\"},\"end\":39357,\"start\":39312},{\"attributes\":{\"n\":\"4.3.1.\"},\"end\":39723,\"start\":39696},{\"end\":40314,\"start\":40273},{\"attributes\":{\"n\":\"4.3.2.\"},\"end\":40580,\"start\":40555},{\"attributes\":{\"n\":\"4.3.3.\"},\"end\":41731,\"start\":41698},{\"attributes\":{\"n\":\"5.\"},\"end\":42849,\"start\":42810},{\"attributes\":{\"n\":\"5.1.\"},\"end\":43169,\"start\":43150},{\"attributes\":{\"n\":\"5.2.\"},\"end\":47841,\"start\":47807},{\"attributes\":{\"n\":\"6.\"},\"end\":51048,\"start\":51028},{\"attributes\":{\"n\":\"6.1.\"},\"end\":52110,\"start\":52017},{\"attributes\":{\"n\":\"6.2.\"},\"end\":58510,\"start\":58438},{\"attributes\":{\"n\":\"7.\"},\"end\":64089,\"start\":64079},{\"attributes\":{\"n\":\"7.1.\"},\"end\":64448,\"start\":64407},{\"attributes\":{\"n\":\"7.2.\"},\"end\":65751,\"start\":65716},{\"attributes\":{\"n\":\"7.3.\"},\"end\":67690,\"start\":67650},{\"attributes\":{\"n\":\"8.\"},\"end\":69972,\"start\":69945},{\"end\":73168,\"start\":73158},{\"end\":73335,\"start\":73325},{\"end\":73589,\"start\":73579},{\"end\":73799,\"start\":73798},{\"end\":74226,\"start\":74216},{\"end\":74381,\"start\":74371},{\"end\":75017,\"start\":75007}]", "table": "[{\"end\":75883,\"start\":75348},{\"end\":76563,\"start\":76366},{\"end\":77259,\"start\":76714}]", "figure_caption": "[{\"end\":73323,\"start\":73170},{\"end\":73577,\"start\":73337},{\"end\":73796,\"start\":73591},{\"end\":74067,\"start\":73800},{\"end\":74214,\"start\":74070},{\"end\":74369,\"start\":74228},{\"end\":74586,\"start\":74383},{\"end\":75005,\"start\":74589},{\"end\":75293,\"start\":75019},{\"end\":75348,\"start\":75296},{\"end\":76366,\"start\":75886},{\"end\":76714,\"start\":76566}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":24884,\"start\":24876},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":25963,\"start\":25955},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":27622,\"start\":27614},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":55238,\"start\":55230},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":56177,\"start\":56169},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":57772,\"start\":57764},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":59927,\"start\":59919},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":62170,\"start\":62161},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":62370,\"start\":62360},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":63025,\"start\":63016},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":65055,\"start\":65047}]", "bib_author_first_name": "[{\"end\":77958,\"start\":77957},{\"end\":77966,\"start\":77965},{\"end\":77975,\"start\":77974},{\"end\":78302,\"start\":78301},{\"end\":78304,\"start\":78303},{\"end\":78316,\"start\":78315},{\"end\":78318,\"start\":78317},{\"end\":78329,\"start\":78328},{\"end\":78331,\"start\":78330},{\"end\":78651,\"start\":78650},{\"end\":78659,\"start\":78658},{\"end\":78661,\"start\":78660},{\"end\":78977,\"start\":78976},{\"end\":78981,\"start\":78978},{\"end\":78992,\"start\":78991},{\"end\":78996,\"start\":78993},{\"end\":79006,\"start\":79005},{\"end\":79008,\"start\":79007},{\"end\":79019,\"start\":79018},{\"end\":79028,\"start\":79027},{\"end\":79030,\"start\":79029},{\"end\":79039,\"start\":79038},{\"end\":79041,\"start\":79040},{\"end\":79424,\"start\":79423},{\"end\":79426,\"start\":79425},{\"end\":79436,\"start\":79435},{\"end\":79438,\"start\":79437},{\"end\":79446,\"start\":79445},{\"end\":79448,\"start\":79447},{\"end\":79757,\"start\":79756},{\"end\":79763,\"start\":79762},{\"end\":79771,\"start\":79770},{\"end\":79780,\"start\":79779},{\"end\":79786,\"start\":79785},{\"end\":79794,\"start\":79793},{\"end\":79800,\"start\":79799},{\"end\":80120,\"start\":80119},{\"end\":80131,\"start\":80130},{\"end\":80140,\"start\":80139},{\"end\":80150,\"start\":80149},{\"end\":80161,\"start\":80160},{\"end\":80163,\"start\":80162},{\"end\":80760,\"start\":80759},{\"end\":80768,\"start\":80767},{\"end\":80775,\"start\":80774},{\"end\":80783,\"start\":80782},{\"end\":81140,\"start\":81139},{\"end\":81147,\"start\":81146},{\"end\":81155,\"start\":81154},{\"end\":81164,\"start\":81163},{\"end\":81172,\"start\":81171},{\"end\":81180,\"start\":81179},{\"end\":81502,\"start\":81501},{\"end\":81512,\"start\":81511},{\"end\":81524,\"start\":81523},{\"end\":81534,\"start\":81533},{\"end\":81877,\"start\":81876},{\"end\":81884,\"start\":81883},{\"end\":81893,\"start\":81892},{\"end\":81902,\"start\":81901},{\"end\":81906,\"start\":81903},{\"end\":81913,\"start\":81912},{\"end\":81921,\"start\":81920},{\"end\":82244,\"start\":82243},{\"end\":82259,\"start\":82258},{\"end\":82269,\"start\":82268},{\"end\":82287,\"start\":82286},{\"end\":82298,\"start\":82297},{\"end\":82308,\"start\":82307},{\"end\":82669,\"start\":82668},{\"end\":82678,\"start\":82677},{\"end\":82680,\"start\":82679},{\"end\":83018,\"start\":83017},{\"end\":83020,\"start\":83019},{\"end\":83030,\"start\":83029},{\"end\":83041,\"start\":83040},{\"end\":83054,\"start\":83053},{\"end\":83068,\"start\":83067},{\"end\":83081,\"start\":83077},{\"end\":83494,\"start\":83493},{\"end\":83505,\"start\":83504},{\"end\":83507,\"start\":83506},{\"end\":83751,\"start\":83750},{\"end\":83758,\"start\":83757},{\"end\":83764,\"start\":83763},{\"end\":83770,\"start\":83769},{\"end\":83777,\"start\":83776},{\"end\":83785,\"start\":83784},{\"end\":83793,\"start\":83792},{\"end\":83795,\"start\":83794},{\"end\":84054,\"start\":84053},{\"end\":84064,\"start\":84063},{\"end\":84074,\"start\":84073},{\"end\":84546,\"start\":84545},{\"end\":84559,\"start\":84558},{\"end\":84561,\"start\":84560},{\"end\":84571,\"start\":84570},{\"end\":84584,\"start\":84583},{\"end\":85084,\"start\":85083},{\"end\":85091,\"start\":85090},{\"end\":85099,\"start\":85098},{\"end\":85109,\"start\":85108},{\"end\":85842,\"start\":85841},{\"end\":85848,\"start\":85847},{\"end\":85850,\"start\":85849},{\"end\":85865,\"start\":85864},{\"end\":86142,\"start\":86141},{\"end\":86158,\"start\":86157},{\"end\":86160,\"start\":86159},{\"end\":86168,\"start\":86167},{\"end\":86180,\"start\":86179},{\"end\":86182,\"start\":86181},{\"end\":86194,\"start\":86193},{\"end\":86599,\"start\":86598},{\"end\":86609,\"start\":86608},{\"end\":86621,\"start\":86620},{\"end\":86631,\"start\":86630},{\"end\":86641,\"start\":86640},{\"end\":86652,\"start\":86651},{\"end\":86669,\"start\":86668},{\"end\":87020,\"start\":87019},{\"end\":87041,\"start\":87040},{\"end\":87059,\"start\":87058},{\"end\":87068,\"start\":87067},{\"end\":87334,\"start\":87333},{\"end\":87344,\"start\":87343},{\"end\":87357,\"start\":87356},{\"end\":87368,\"start\":87367},{\"end\":88014,\"start\":88013},{\"end\":88028,\"start\":88027},{\"end\":88040,\"start\":88039},{\"end\":88053,\"start\":88052},{\"end\":88471,\"start\":88470},{\"end\":88482,\"start\":88481},{\"end\":88494,\"start\":88493},{\"end\":88502,\"start\":88501},{\"end\":88513,\"start\":88512},{\"end\":88846,\"start\":88845},{\"end\":88855,\"start\":88854},{\"end\":88857,\"start\":88856},{\"end\":88872,\"start\":88871},{\"end\":88874,\"start\":88873},{\"end\":88884,\"start\":88883},{\"end\":89248,\"start\":89247},{\"end\":89256,\"start\":89255},{\"end\":89258,\"start\":89257},{\"end\":89265,\"start\":89264},{\"end\":89267,\"start\":89266},{\"end\":89274,\"start\":89273},{\"end\":89276,\"start\":89275},{\"end\":89283,\"start\":89282},{\"end\":89285,\"start\":89284},{\"end\":89293,\"start\":89292},{\"end\":89295,\"start\":89294},{\"end\":89586,\"start\":89585},{\"end\":89599,\"start\":89598},{\"end\":89609,\"start\":89608},{\"end\":89611,\"start\":89610},{\"end\":89927,\"start\":89926},{\"end\":89939,\"start\":89938},{\"end\":90227,\"start\":90226},{\"end\":90229,\"start\":90228},{\"end\":90242,\"start\":90241},{\"end\":90582,\"start\":90581},{\"end\":90597,\"start\":90596},{\"end\":90612,\"start\":90611},{\"end\":90905,\"start\":90904},{\"end\":90913,\"start\":90912},{\"end\":91290,\"start\":91289},{\"end\":91299,\"start\":91298},{\"end\":91307,\"start\":91306},{\"end\":91309,\"start\":91308},{\"end\":91735,\"start\":91734},{\"end\":91737,\"start\":91736},{\"end\":91745,\"start\":91744},{\"end\":91747,\"start\":91746},{\"end\":91758,\"start\":91757},{\"end\":91760,\"start\":91759},{\"end\":91769,\"start\":91768},{\"end\":91771,\"start\":91770},{\"end\":91780,\"start\":91779},{\"end\":91790,\"start\":91789},{\"end\":91792,\"start\":91791},{\"end\":91798,\"start\":91797},{\"end\":92285,\"start\":92284},{\"end\":92296,\"start\":92295},{\"end\":92305,\"start\":92304},{\"end\":92643,\"start\":92642},{\"end\":92882,\"start\":92881},{\"end\":92891,\"start\":92890},{\"end\":92893,\"start\":92892},{\"end\":92900,\"start\":92899},{\"end\":93177,\"start\":93173},{\"end\":93188,\"start\":93187},{\"end\":93203,\"start\":93202},{\"end\":93449,\"start\":93448},{\"end\":93460,\"start\":93459},{\"end\":93471,\"start\":93470},{\"end\":93820,\"start\":93819},{\"end\":93822,\"start\":93821},{\"end\":93833,\"start\":93832},{\"end\":93848,\"start\":93847},{\"end\":93858,\"start\":93857},{\"end\":94557,\"start\":94556},{\"end\":94796,\"start\":94795},{\"end\":94809,\"start\":94808},{\"end\":95130,\"start\":95129},{\"end\":95138,\"start\":95137},{\"end\":95147,\"start\":95146},{\"end\":95615,\"start\":95614},{\"end\":95627,\"start\":95626},{\"end\":95640,\"start\":95639},{\"end\":95652,\"start\":95651},{\"end\":95964,\"start\":95963},{\"end\":95972,\"start\":95971},{\"end\":95985,\"start\":95984},{\"end\":95995,\"start\":95994},{\"end\":96006,\"start\":96005},{\"end\":96016,\"start\":96015},{\"end\":96025,\"start\":96024}]", "bib_author_last_name": "[{\"end\":77963,\"start\":77959},{\"end\":77972,\"start\":77967},{\"end\":77978,\"start\":77976},{\"end\":78313,\"start\":78305},{\"end\":78326,\"start\":78319},{\"end\":78337,\"start\":78332},{\"end\":78656,\"start\":78652},{\"end\":78667,\"start\":78662},{\"end\":78989,\"start\":78982},{\"end\":79003,\"start\":78997},{\"end\":79016,\"start\":79009},{\"end\":79025,\"start\":79020},{\"end\":79036,\"start\":79031},{\"end\":79047,\"start\":79042},{\"end\":79433,\"start\":79427},{\"end\":79443,\"start\":79439},{\"end\":79454,\"start\":79449},{\"end\":79760,\"start\":79758},{\"end\":79768,\"start\":79764},{\"end\":79777,\"start\":79772},{\"end\":79783,\"start\":79781},{\"end\":79791,\"start\":79787},{\"end\":79797,\"start\":79795},{\"end\":79810,\"start\":79801},{\"end\":80128,\"start\":80121},{\"end\":80137,\"start\":80132},{\"end\":80147,\"start\":80141},{\"end\":80158,\"start\":80151},{\"end\":80169,\"start\":80164},{\"end\":80765,\"start\":80761},{\"end\":80772,\"start\":80769},{\"end\":80780,\"start\":80776},{\"end\":80788,\"start\":80784},{\"end\":81144,\"start\":81141},{\"end\":81152,\"start\":81148},{\"end\":81161,\"start\":81156},{\"end\":81169,\"start\":81165},{\"end\":81177,\"start\":81173},{\"end\":81187,\"start\":81181},{\"end\":81509,\"start\":81503},{\"end\":81521,\"start\":81513},{\"end\":81531,\"start\":81525},{\"end\":81544,\"start\":81535},{\"end\":81881,\"start\":81878},{\"end\":81890,\"start\":81885},{\"end\":81899,\"start\":81894},{\"end\":81910,\"start\":81907},{\"end\":81918,\"start\":81914},{\"end\":81928,\"start\":81922},{\"end\":82256,\"start\":82245},{\"end\":82266,\"start\":82260},{\"end\":82284,\"start\":82270},{\"end\":82295,\"start\":82288},{\"end\":82305,\"start\":82299},{\"end\":82319,\"start\":82309},{\"end\":82675,\"start\":82670},{\"end\":82684,\"start\":82681},{\"end\":83027,\"start\":83021},{\"end\":83038,\"start\":83031},{\"end\":83051,\"start\":83042},{\"end\":83065,\"start\":83055},{\"end\":83075,\"start\":83069},{\"end\":83089,\"start\":83082},{\"end\":83502,\"start\":83495},{\"end\":83515,\"start\":83508},{\"end\":83755,\"start\":83752},{\"end\":83761,\"start\":83759},{\"end\":83767,\"start\":83765},{\"end\":83774,\"start\":83771},{\"end\":83782,\"start\":83778},{\"end\":83790,\"start\":83786},{\"end\":83798,\"start\":83796},{\"end\":84061,\"start\":84055},{\"end\":84071,\"start\":84065},{\"end\":84081,\"start\":84075},{\"end\":84556,\"start\":84547},{\"end\":84568,\"start\":84562},{\"end\":84581,\"start\":84572},{\"end\":84592,\"start\":84585},{\"end\":85088,\"start\":85085},{\"end\":85096,\"start\":85092},{\"end\":85106,\"start\":85100},{\"end\":85118,\"start\":85110},{\"end\":85845,\"start\":85843},{\"end\":85862,\"start\":85851},{\"end\":85871,\"start\":85866},{\"end\":86155,\"start\":86143},{\"end\":86165,\"start\":86161},{\"end\":86177,\"start\":86169},{\"end\":86191,\"start\":86183},{\"end\":86202,\"start\":86195},{\"end\":86606,\"start\":86600},{\"end\":86618,\"start\":86610},{\"end\":86628,\"start\":86622},{\"end\":86638,\"start\":86632},{\"end\":86649,\"start\":86642},{\"end\":86666,\"start\":86653},{\"end\":86677,\"start\":86670},{\"end\":87038,\"start\":87021},{\"end\":87056,\"start\":87042},{\"end\":87065,\"start\":87060},{\"end\":87073,\"start\":87069},{\"end\":87341,\"start\":87335},{\"end\":87354,\"start\":87345},{\"end\":87365,\"start\":87358},{\"end\":87376,\"start\":87369},{\"end\":88025,\"start\":88015},{\"end\":88037,\"start\":88029},{\"end\":88050,\"start\":88041},{\"end\":88062,\"start\":88054},{\"end\":88479,\"start\":88472},{\"end\":88491,\"start\":88483},{\"end\":88499,\"start\":88495},{\"end\":88510,\"start\":88503},{\"end\":88519,\"start\":88514},{\"end\":88852,\"start\":88847},{\"end\":88869,\"start\":88858},{\"end\":88881,\"start\":88875},{\"end\":88894,\"start\":88885},{\"end\":89253,\"start\":89249},{\"end\":89262,\"start\":89259},{\"end\":89271,\"start\":89268},{\"end\":89280,\"start\":89277},{\"end\":89290,\"start\":89286},{\"end\":89299,\"start\":89296},{\"end\":89596,\"start\":89587},{\"end\":89606,\"start\":89600},{\"end\":89620,\"start\":89612},{\"end\":89936,\"start\":89928},{\"end\":89945,\"start\":89940},{\"end\":90239,\"start\":90230},{\"end\":90247,\"start\":90243},{\"end\":90594,\"start\":90583},{\"end\":90609,\"start\":90598},{\"end\":90622,\"start\":90613},{\"end\":90910,\"start\":90906},{\"end\":90919,\"start\":90914},{\"end\":91296,\"start\":91291},{\"end\":91304,\"start\":91300},{\"end\":91318,\"start\":91310},{\"end\":91742,\"start\":91738},{\"end\":91755,\"start\":91748},{\"end\":91766,\"start\":91761},{\"end\":91777,\"start\":91772},{\"end\":91787,\"start\":91781},{\"end\":91795,\"start\":91793},{\"end\":91809,\"start\":91799},{\"end\":92293,\"start\":92286},{\"end\":92302,\"start\":92297},{\"end\":92313,\"start\":92306},{\"end\":92647,\"start\":92644},{\"end\":92888,\"start\":92883},{\"end\":92897,\"start\":92894},{\"end\":92905,\"start\":92901},{\"end\":93185,\"start\":93178},{\"end\":93200,\"start\":93189},{\"end\":93214,\"start\":93204},{\"end\":93457,\"start\":93450},{\"end\":93468,\"start\":93461},{\"end\":93477,\"start\":93472},{\"end\":93830,\"start\":93823},{\"end\":93845,\"start\":93834},{\"end\":93855,\"start\":93849},{\"end\":93863,\"start\":93859},{\"end\":94564,\"start\":94558},{\"end\":94806,\"start\":94797},{\"end\":94817,\"start\":94810},{\"end\":95135,\"start\":95131},{\"end\":95144,\"start\":95139},{\"end\":95154,\"start\":95148},{\"end\":95624,\"start\":95616},{\"end\":95637,\"start\":95628},{\"end\":95649,\"start\":95641},{\"end\":95658,\"start\":95653},{\"end\":95969,\"start\":95965},{\"end\":95982,\"start\":95973},{\"end\":95992,\"start\":95986},{\"end\":96003,\"start\":95996},{\"end\":96013,\"start\":96007},{\"end\":96022,\"start\":96017},{\"end\":96034,\"start\":96026}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":77779,\"start\":77691},{\"attributes\":{\"id\":\"b1\"},\"end\":77871,\"start\":77781},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":216373938},\"end\":78223,\"start\":77873},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":229263576},\"end\":78568,\"start\":78225},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":207250645},\"end\":78867,\"start\":78570},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":221090288},\"end\":79349,\"start\":78869},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":54444519},\"end\":79661,\"start\":79351},{\"attributes\":{\"doi\":\"arXiv:2007.13054\",\"id\":\"b7\"},\"end\":80042,\"start\":79663},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":14955348},\"end\":80703,\"start\":80044},{\"attributes\":{\"doi\":\"10.1145/3298981\",\"id\":\"b9\",\"matched_paper_id\":219878182},\"end\":81051,\"start\":80705},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":219304970},\"end\":81420,\"start\":81053},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":234514585},\"end\":81775,\"start\":81422},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":231972490},\"end\":82149,\"start\":81777},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":117692132},\"end\":82576,\"start\":82151},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":195345574},\"end\":82949,\"start\":82578},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":56482410},\"end\":83441,\"start\":82951},{\"attributes\":{\"doi\":\"arXiv:1912.04977\",\"id\":\"b16\"},\"end\":83680,\"start\":83443},{\"attributes\":{\"doi\":\"arXiv:2012.06337\",\"id\":\"b17\"},\"end\":84000,\"start\":83682},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":9089716},\"end\":84471,\"start\":84002},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":28527385},\"end\":85008,\"start\":84473},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":3708326},\"end\":85771,\"start\":85010},{\"attributes\":{\"doi\":\"arXiv:2006.09365\",\"id\":\"b21\"},\"end\":86053,\"start\":85773},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":18477106},\"end\":86517,\"start\":86055},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":13677639},\"end\":86941,\"start\":86519},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":215756686},\"end\":87254,\"start\":86943},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":3502091},\"end\":87884,\"start\":87256},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":53297457},\"end\":88355,\"start\":87886},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":221848814},\"end\":88757,\"start\":88357},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":85519384},\"end\":89214,\"start\":88759},{\"attributes\":{\"id\":\"b29\"},\"end\":89448,\"start\":89216},{\"attributes\":{\"doi\":\"10.21227/q70p-q449\",\"id\":\"b30\"},\"end\":89518,\"start\":89450},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":244984934},\"end\":89858,\"start\":89520},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":213250576},\"end\":90106,\"start\":89860},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":216362694},\"end\":90507,\"start\":90108},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":198147119},\"end\":90841,\"start\":90509},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":58671343},\"end\":91213,\"start\":90843},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":56598079},\"end\":91648,\"start\":91215},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":219989714},\"end\":92155,\"start\":91650},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":199005043},\"end\":92638,\"start\":92157},{\"attributes\":{\"id\":\"b39\"},\"end\":92786,\"start\":92640},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":230647113},\"end\":93095,\"start\":92788},{\"attributes\":{\"doi\":\"arXiv:1511.07289\",\"id\":\"b41\"},\"end\":93414,\"start\":93097},{\"attributes\":{\"doi\":\"10.1145/3335772.3335936\",\"id\":\"b42\"},\"end\":93759,\"start\":93416},{\"attributes\":{\"doi\":\"PMLR, 09-15\",\"id\":\"b43\",\"matched_paper_id\":54203999},\"end\":94434,\"start\":93761},{\"attributes\":{\"id\":\"b44\"},\"end\":94730,\"start\":94436},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":3473997},\"end\":95044,\"start\":94732},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":5976727},\"end\":95510,\"start\":95046},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":199583116},\"end\":95893,\"start\":95512},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":216023224},\"end\":96311,\"start\":95895}]", "bib_title": "[{\"end\":77955,\"start\":77873},{\"end\":78299,\"start\":78225},{\"end\":78648,\"start\":78570},{\"end\":78974,\"start\":78869},{\"end\":79421,\"start\":79351},{\"end\":80117,\"start\":80044},{\"end\":80757,\"start\":80705},{\"end\":81137,\"start\":81053},{\"end\":81499,\"start\":81422},{\"end\":81874,\"start\":81777},{\"end\":82241,\"start\":82151},{\"end\":82666,\"start\":82578},{\"end\":83015,\"start\":82951},{\"end\":84051,\"start\":84002},{\"end\":84543,\"start\":84473},{\"end\":85081,\"start\":85010},{\"end\":86139,\"start\":86055},{\"end\":86596,\"start\":86519},{\"end\":87017,\"start\":86943},{\"end\":87331,\"start\":87256},{\"end\":88011,\"start\":87886},{\"end\":88468,\"start\":88357},{\"end\":88843,\"start\":88759},{\"end\":89245,\"start\":89216},{\"end\":89583,\"start\":89520},{\"end\":89924,\"start\":89860},{\"end\":90224,\"start\":90108},{\"end\":90579,\"start\":90509},{\"end\":90902,\"start\":90843},{\"end\":91287,\"start\":91215},{\"end\":91732,\"start\":91650},{\"end\":92282,\"start\":92157},{\"end\":92879,\"start\":92788},{\"end\":93817,\"start\":93761},{\"end\":94793,\"start\":94732},{\"end\":95127,\"start\":95046},{\"end\":95612,\"start\":95512},{\"end\":95961,\"start\":95895}]", "bib_author": "[{\"end\":77965,\"start\":77957},{\"end\":77974,\"start\":77965},{\"end\":77980,\"start\":77974},{\"end\":78315,\"start\":78301},{\"end\":78328,\"start\":78315},{\"end\":78339,\"start\":78328},{\"end\":78658,\"start\":78650},{\"end\":78669,\"start\":78658},{\"end\":78991,\"start\":78976},{\"end\":79005,\"start\":78991},{\"end\":79018,\"start\":79005},{\"end\":79027,\"start\":79018},{\"end\":79038,\"start\":79027},{\"end\":79049,\"start\":79038},{\"end\":79435,\"start\":79423},{\"end\":79445,\"start\":79435},{\"end\":79456,\"start\":79445},{\"end\":79762,\"start\":79756},{\"end\":79770,\"start\":79762},{\"end\":79779,\"start\":79770},{\"end\":79785,\"start\":79779},{\"end\":79793,\"start\":79785},{\"end\":79799,\"start\":79793},{\"end\":79812,\"start\":79799},{\"end\":80130,\"start\":80119},{\"end\":80139,\"start\":80130},{\"end\":80149,\"start\":80139},{\"end\":80160,\"start\":80149},{\"end\":80171,\"start\":80160},{\"end\":80767,\"start\":80759},{\"end\":80774,\"start\":80767},{\"end\":80782,\"start\":80774},{\"end\":80790,\"start\":80782},{\"end\":81146,\"start\":81139},{\"end\":81154,\"start\":81146},{\"end\":81163,\"start\":81154},{\"end\":81171,\"start\":81163},{\"end\":81179,\"start\":81171},{\"end\":81189,\"start\":81179},{\"end\":81511,\"start\":81501},{\"end\":81523,\"start\":81511},{\"end\":81533,\"start\":81523},{\"end\":81546,\"start\":81533},{\"end\":81883,\"start\":81876},{\"end\":81892,\"start\":81883},{\"end\":81901,\"start\":81892},{\"end\":81912,\"start\":81901},{\"end\":81920,\"start\":81912},{\"end\":81930,\"start\":81920},{\"end\":82258,\"start\":82243},{\"end\":82268,\"start\":82258},{\"end\":82286,\"start\":82268},{\"end\":82297,\"start\":82286},{\"end\":82307,\"start\":82297},{\"end\":82321,\"start\":82307},{\"end\":82677,\"start\":82668},{\"end\":82686,\"start\":82677},{\"end\":83029,\"start\":83017},{\"end\":83040,\"start\":83029},{\"end\":83053,\"start\":83040},{\"end\":83067,\"start\":83053},{\"end\":83077,\"start\":83067},{\"end\":83091,\"start\":83077},{\"end\":83504,\"start\":83493},{\"end\":83517,\"start\":83504},{\"end\":83757,\"start\":83750},{\"end\":83763,\"start\":83757},{\"end\":83769,\"start\":83763},{\"end\":83776,\"start\":83769},{\"end\":83784,\"start\":83776},{\"end\":83792,\"start\":83784},{\"end\":83800,\"start\":83792},{\"end\":84063,\"start\":84053},{\"end\":84073,\"start\":84063},{\"end\":84083,\"start\":84073},{\"end\":84558,\"start\":84545},{\"end\":84570,\"start\":84558},{\"end\":84583,\"start\":84570},{\"end\":84594,\"start\":84583},{\"end\":85090,\"start\":85083},{\"end\":85098,\"start\":85090},{\"end\":85108,\"start\":85098},{\"end\":85120,\"start\":85108},{\"end\":85847,\"start\":85841},{\"end\":85864,\"start\":85847},{\"end\":85873,\"start\":85864},{\"end\":86157,\"start\":86141},{\"end\":86167,\"start\":86157},{\"end\":86179,\"start\":86167},{\"end\":86193,\"start\":86179},{\"end\":86204,\"start\":86193},{\"end\":86608,\"start\":86598},{\"end\":86620,\"start\":86608},{\"end\":86630,\"start\":86620},{\"end\":86640,\"start\":86630},{\"end\":86651,\"start\":86640},{\"end\":86668,\"start\":86651},{\"end\":86679,\"start\":86668},{\"end\":87040,\"start\":87019},{\"end\":87058,\"start\":87040},{\"end\":87067,\"start\":87058},{\"end\":87075,\"start\":87067},{\"end\":87343,\"start\":87333},{\"end\":87356,\"start\":87343},{\"end\":87367,\"start\":87356},{\"end\":87378,\"start\":87367},{\"end\":88027,\"start\":88013},{\"end\":88039,\"start\":88027},{\"end\":88052,\"start\":88039},{\"end\":88064,\"start\":88052},{\"end\":88481,\"start\":88470},{\"end\":88493,\"start\":88481},{\"end\":88501,\"start\":88493},{\"end\":88512,\"start\":88501},{\"end\":88521,\"start\":88512},{\"end\":88854,\"start\":88845},{\"end\":88871,\"start\":88854},{\"end\":88883,\"start\":88871},{\"end\":88896,\"start\":88883},{\"end\":89255,\"start\":89247},{\"end\":89264,\"start\":89255},{\"end\":89273,\"start\":89264},{\"end\":89282,\"start\":89273},{\"end\":89292,\"start\":89282},{\"end\":89301,\"start\":89292},{\"end\":89598,\"start\":89585},{\"end\":89608,\"start\":89598},{\"end\":89622,\"start\":89608},{\"end\":89938,\"start\":89926},{\"end\":89947,\"start\":89938},{\"end\":90241,\"start\":90226},{\"end\":90249,\"start\":90241},{\"end\":90596,\"start\":90581},{\"end\":90611,\"start\":90596},{\"end\":90624,\"start\":90611},{\"end\":90912,\"start\":90904},{\"end\":90921,\"start\":90912},{\"end\":91298,\"start\":91289},{\"end\":91306,\"start\":91298},{\"end\":91320,\"start\":91306},{\"end\":91744,\"start\":91734},{\"end\":91757,\"start\":91744},{\"end\":91768,\"start\":91757},{\"end\":91779,\"start\":91768},{\"end\":91789,\"start\":91779},{\"end\":91797,\"start\":91789},{\"end\":91811,\"start\":91797},{\"end\":92295,\"start\":92284},{\"end\":92304,\"start\":92295},{\"end\":92315,\"start\":92304},{\"end\":92649,\"start\":92642},{\"end\":92890,\"start\":92881},{\"end\":92899,\"start\":92890},{\"end\":92907,\"start\":92899},{\"end\":93187,\"start\":93173},{\"end\":93202,\"start\":93187},{\"end\":93216,\"start\":93202},{\"end\":93459,\"start\":93448},{\"end\":93470,\"start\":93459},{\"end\":93479,\"start\":93470},{\"end\":93832,\"start\":93819},{\"end\":93847,\"start\":93832},{\"end\":93857,\"start\":93847},{\"end\":93865,\"start\":93857},{\"end\":94566,\"start\":94556},{\"end\":94808,\"start\":94795},{\"end\":94819,\"start\":94808},{\"end\":95137,\"start\":95129},{\"end\":95146,\"start\":95137},{\"end\":95156,\"start\":95146},{\"end\":95626,\"start\":95614},{\"end\":95639,\"start\":95626},{\"end\":95651,\"start\":95639},{\"end\":95660,\"start\":95651},{\"end\":95971,\"start\":95963},{\"end\":95984,\"start\":95971},{\"end\":95994,\"start\":95984},{\"end\":96005,\"start\":95994},{\"end\":96015,\"start\":96005},{\"end\":96024,\"start\":96015},{\"end\":96036,\"start\":96024}]", "bib_venue": "[{\"end\":80297,\"start\":80278},{\"end\":84260,\"start\":84180},{\"end\":84759,\"start\":84685},{\"end\":85349,\"start\":85257},{\"end\":87467,\"start\":87441},{\"end\":88989,\"start\":88951},{\"end\":94103,\"start\":94027},{\"end\":95293,\"start\":95233},{\"end\":77695,\"start\":77693},{\"end\":77825,\"start\":77781},{\"end\":78024,\"start\":77980},{\"end\":78370,\"start\":78339},{\"end\":78694,\"start\":78669},{\"end\":79088,\"start\":79049},{\"end\":79482,\"start\":79456},{\"end\":79754,\"start\":79663},{\"end\":80247,\"start\":80171},{\"end\":80837,\"start\":80805},{\"end\":81209,\"start\":81189},{\"end\":81589,\"start\":81546},{\"end\":81938,\"start\":81930},{\"end\":82337,\"start\":82321},{\"end\":82742,\"start\":82686},{\"end\":83171,\"start\":83091},{\"end\":83491,\"start\":83443},{\"end\":83748,\"start\":83682},{\"end\":84178,\"start\":84083},{\"end\":84683,\"start\":84594},{\"end\":85226,\"start\":85120},{\"end\":85839,\"start\":85773},{\"end\":86256,\"start\":86204},{\"end\":86703,\"start\":86679},{\"end\":87081,\"start\":87075},{\"end\":87439,\"start\":87378},{\"end\":88098,\"start\":88064},{\"end\":88532,\"start\":88521},{\"end\":88949,\"start\":88896},{\"end\":89314,\"start\":89301},{\"end\":89645,\"start\":89622},{\"end\":89959,\"start\":89947},{\"end\":90298,\"start\":90249},{\"end\":90654,\"start\":90624},{\"end\":91005,\"start\":90921},{\"end\":91407,\"start\":91320},{\"end\":91877,\"start\":91811},{\"end\":92370,\"start\":92315},{\"end\":92918,\"start\":92907},{\"end\":93171,\"start\":93097},{\"end\":93446,\"start\":93416},{\"end\":93982,\"start\":93876},{\"end\":94554,\"start\":94436},{\"end\":94863,\"start\":94819},{\"end\":95231,\"start\":95156},{\"end\":95674,\"start\":95660},{\"end\":96075,\"start\":96036}]"}}}, "year": 2023, "month": 12, "day": 17}