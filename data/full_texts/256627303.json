{"id": 256627303, "updated": "2023-10-05 04:22:54.7", "metadata": {"title": "NICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM", "authors": "[{\"first\":\"Zihan\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Songyou\",\"last\":\"Peng\",\"middle\":[]},{\"first\":\"Viktor\",\"last\":\"Larsson\",\"middle\":[]},{\"first\":\"Zhaopeng\",\"last\":\"Cui\",\"middle\":[]},{\"first\":\"Martin\",\"last\":\"Oswald\",\"middle\":[\"R.\"]},{\"first\":\"Andreas\",\"last\":\"Geiger\",\"middle\":[]},{\"first\":\"Marc\",\"last\":\"Pollefeys\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Neural implicit representations have recently become popular in simultaneous localization and mapping (SLAM), especially in dense visual SLAM. However, previous works in this direction either rely on RGB-D sensors, or require a separate monocular SLAM approach for camera tracking and do not produce high-fidelity dense 3D scene reconstruction. In this paper, we present NICER-SLAM, a dense RGB SLAM system that simultaneously optimizes for camera poses and a hierarchical neural implicit map representation, which also allows for high-quality novel view synthesis. To facilitate the optimization process for mapping, we integrate additional supervision signals including easy-to-obtain monocular geometric cues and optical flow, and also introduce a simple warping loss to further enforce geometry consistency. Moreover, to further boost performance in complicated indoor scenes, we also propose a local adaptive transformation from signed distance functions (SDFs) to density in the volume rendering equation. On both synthetic and real-world datasets we demonstrate strong performance in dense mapping, tracking, and novel view synthesis, even competitive with recent RGB-D SLAM systems.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2302.03594", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2302-03594", "doi": "10.48550/arxiv.2302.03594"}}, "content": {"source": {"pdf_hash": "7378afa69055e12375d55d063af87177faf37c1b", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2302.03594v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "17f8c4147cd15148bd5da6603e7b2f39bef7a109", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/7378afa69055e12375d55d063af87177faf37c1b.txt", "contents": "\nNICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM DROID-SLAM COLMAP NICER-SLAM Ground Truth RGB input RGB-D input NICE-SLAM\n\n\nZihan Zhu \nSongyou Peng \nMPI for Intelligent Systems\nT\u00fcbingen\n\nViktor Larsson \nLund University\n\n\nZhaopeng Cui \nState Key Lab of CAD&CG\nZhejiang University\n\n\nMartin R Oswald \nUniversity of Amsterdam\n\n\nAndreas Geiger \nUniversity of T\u00fcbingen\nT\u00fcbingen AI Center 7 Microsoft\n\nMarc Pollefeys \nEth Z\u00fcrich \nNICER-SLAM: Neural Implicit Scene Encoding for RGB SLAM DROID-SLAM COLMAP NICER-SLAM Ground Truth RGB input RGB-D input NICE-SLAM\n\nFigure 1: 3D Dense Reconstruction and Rendering from Different SLAM Systems. On the Replica dataset [49], we compare to dense RGB-D SLAM method NICE-SLAM [76], and monocular SLAM approaches COLMAP [46], DROID-SLAM [57], and our proposed NICER-SLAM.AbstractNeural implicit representations have recently become popular in simultaneous localization and mapping (SLAM), especially in dense visual SLAM. However, previous works in this direction either rely on RGB-D sensors, or require a separate monocular SLAM approach for camera tracking and do not produce high-fidelity dense 3D scene reconstruction. In this paper, we present NICER-SLAM, a dense RGB SLAM system that simultaneously optimizes for camera poses and a hierarchical neural implicit map representation, which also allows for high-quality novel view synthesis. To facilitate the optimization process for mapping, we integrate additional supervision signals including easy-toobtain monocular geometric cues and optical flow, and also introduce a simple warping loss to further enforce geometry consistency. Moreover, to further boost performance in complicated indoor scenes, we also propose a local adaptive transformation from signed distance functions (SDFs) to density in the volume rendering equation. On both synthetic and real-world datasets we demonstrate strong performance in dense mapping, tracking, and novel view synthesis, even competitive with recent RGB-D SLAM systems.\n\nIntroduction\n\nSimultaneous localization and mapping (SLAM) is a fundamental computer vision problem with wide applications in autonomous driving, robotics, mixed reality, and more. Many dense visual SLAM methods have been introduced in the past years [34,47,62,63,35] and they are able to produce dense reconstructions of indoor scenes in realtime. However, most of these approaches rely on RGB-D sensors and fail on outdoor scenes or when depth sensors are not available. Moreover, for unobserved regions, they have difficulty making plausible geometry estimations. In the deep learning era, a handful of dense monocular SLAM systems [2,9,74] take only RGB sequences as input and to some extent fill in unobserved regions due to their monocular depth prediction networks. Nevertheless, these systems are typically only applicable to small scenes with limited camera movements.\n\nWith the rapid developments in neural implicit representations or neural fields [65], they have also demonstrated powerful performance in end-to-end differentiable dense visual SLAM. iMAP [51] first shows the capability of neural implicit representations in dense RGB-D SLAM, but it is only limited to room-size datasets. NICE-SLAM [76] introduces a hierarchical implicit encoding to perform map-ping and camera tracking in much larger indoor scenes. Although follow-up works [67,30,21,18,25,39] try to improve upon NICE-SLAM and iMAP from different perspectives, all of these works still rely on the reliable depth input from RGB-D sensors.\n\nVery recently, a handful of concurrent works (available as pre-prints) try to apply neural implicit representations for RGB-only SLAM [45,7]. However, their tracking and mapping pipelines are independent of each other as they rely on different scene representations for these tasks. Both approaches depend on the state-of-the-art visual odometry methods [57,33] for camera tracking, while using neural radiance fields (NeRFs) only for mapping. Moreover, they both only output and evaluate the rendered depth maps and color images, so no dense 3D model of a scene is produced. This raises an interesting research question:\n\nCan we build a unified dense SLAM system with a neural implicit scene representation for both tracking and mapping from a monocular RGB video?\n\nCompared to RGB-D SLAM, RGB-only SLAM is more challenging for multiple reasons. 1) Depth ambiguity: often several possible correspondences match the color observations well, especially with little available texture information. Hence, stronger geometric priors are required for both mapping and tracking optimizations. 2) Harder 3D reconstruction: due to the ambiguity the estimation of surfaces is less localized, leading to more complex data structure updates and increased sampling efforts. 3) Optimization convergence: as a result of the previous challenges, the resulting optimization is less constrained and more complexleading to slower convergence.\n\nTo tackle these challenges, we introduce NICER-SLAM, an implicit-based dense RGB SLAM system that is end-toend optimizable for both mapping and tracking, and also capable of learning an accurate scene representation for novel view synthesis. Our key ideas are as follows. First, for scene geometry and colors, we present coarse-to-fine hierarchical feature grids to model the signed distance functions (SDFs), which yields detailed 3D reconstructions and high-fidelity renderings. Second, to optimize neural implicit map representations with only RGB input, we integrate additional signals for supervision including easy-toobtain monocular geometric cues and optical flow, and also introduce a simple warping loss to further enforce geometry consistency. We observe that those regularizations help to significantly disambiguate the optimization process, enabling our framework to work accurately and robustly with only RGB input. Third, to better fit the sequential input for indoor scenes, we propose to use a locally adaptive transformation from SDF to density.\n\nIn summary, we make the following contributions:\n\n\u2022 We present NICER-SLAM, one of the first dense RGB-only SLAM that is end-to-end optimizable for both tracking and mapping, which also allows for high-quality novel view synthesis.\n\n\u2022 We introduce a hierarchical neural implicit encoding for SDF representations, different geometric and motion regularizations, as well as a locally adaptive SDF to volume density transformation.\n\n\u2022 We demonstrate strong performances in mapping, tracking, and novel view synthesis on both synthetic and real-world datasets, even competitive with recent RGB-D SLAM methods.\n\n\nRelated Work\n\nDense Visual SLAM. SLAM is an active field in both industry and academia, especially in the past two decades. While sparse visual SLAM algorithms [32,33,13,19] estimate accurate camera poses and only have sparse point clouds as the map representation, dense visual SLAM approaches focus on recovering a dense map of a scene. In general, map representations are categorized as either viewcentric or world-centric. The first often represents 3D geometry as depth maps for keyframes, including the seminal work DTAM [35], as well as many follow-ups [58,75,56,9,55,2,74,52,57,20]. Another line of research considers world-centric maps, and they anchor the 3D geometry of a full scene in uniform world coordinates and represent as surfels [63,47] or occupancies/TSDF values in the voxel grids [3,10,37,34]. Our work also falls into this category and uses a world-centric map representation, but instead of explicitly representing the surface, we store latent codes in multi-resolution voxel grids. This allows us to not only reconstruct high-quality geometry at low grid resolutions, but also attain plausible geometry estimation for unobserved regions.\n\nNeural Implicit-based SLAM. Neural implicit representations [65] have shown great performance in many different tasks, including object-level reconstruction reconstruction [28,4,40,41,26,36,69], scene completion [42,24,17], novel view synthesis [29,44,72,31,64], etc. In terms of SLAM-related applications, some works [70,23,61,6,1,8] try to jointly optimize a neural radiance field and camera poses, but they are only applicable to small objects or small camera movements. A series of recent works [7,45] relax such constraints, but they mainly rely on state-of-theart SLAM systems like ORB-SLAM and DROID-SLAM to obtain accurate camera poses, and do not produce 3D dense reconstruction but only novel view synthesis results. iMAP [51] and NICE-SLAM [76] are the first two unified SLAM pipelines using neural implicit representations for both mapping and camera tracking. iMAP uses a single MLP as the scene representation so they are limited to small \n\n\nInput RGB Stream\n\n\nMinimize\n\n\nWarping Loss\n4 O B 8 G Z k i J W E b Q p s Q f a 5 F k o = \" > A A A B 6 3 i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 5 E 0 D J o Y x n B x E B y h L 3 N J l m y u 3 f s z g n h y F + w s V D E 1 j 9 k 5 7 9 x L 7 l C E x 8 M P N 6 b Y W Z e l E h h 0 f e / v d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 2 z g 1 j L d Y L G P T i a j l U m j e Q o G S d x L D q Y o k f 4 w m t 7 n / + M S N F b F + w G n C Q 0 V H W g w F o 5 h L P a G x X 6 3 5 d X 8 O s k q C g t S g Q L N f / e o N Y p Y q r p F J a m 0 3 8 B M M M 2 p Q M M l n l V 5 q e U L Z h I 5 4 1 1 F N F b d h N r 9 1 R s 6 c M i D D 2 L j S S O b q 7 4 m M K m u n K n K d i u L Y L n u 5 + J / X T X F 4 H W Z C J y l y z R a L h q k k G J P 8 c T I Q h j O U U 0 c o M 8 L d S t i Y G s r Q x V N x I Q T L L 6 + S 9 k U 9 8 O v B / W W t c V P E U Y Y T O I V z C O A K G n A H T W g B g z E 8 w y u 8 e c p 7 8 d 6 9 j 0 V r y S t m j u E P v M 8 f I q i O S Q = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" M Z P z i 4 O B 8 G Z k i J W E b Q p s Q f a 5 F k o = \" > A A A B 6 3 i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 5 E 0 D J o Y x n B x E B y h L 3 N J l m y u 3 f s z g n h y F + w s V D E 1 j 9 k 5 7 9 x L 7 l C E x 8 M P N 6 b Y W Z e l E h h 0 f e / v d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 2 z g 1 j L d Y L G P T i a j l U m j e Q o G S d x L D q Y o k f 4 w m t 7 n / + M S N F b F + w G n C Q 0 V H W g w F o 5 h L P a G x X 6 3 5 d X 8 O s k q C g t S g Q L N f / e o N Y p Y q r p F J a m 0 3 8 B M M M 2 p Q M M l n l V 5 q e U L Z h I 5 4 1 1 F N F b d h N r 9 1 R s 6 c M i D D 2 L j S S O b q 7 4 m M K m u n K n K d i u L Y L n u 5 + J / X T X F 4 H W Z C J y l y z R a L h q k k G J P 8 c T I Q h j O U U 0 c o M 8 L d S t i Y G s r Q x V N x I Q T L L 6 + S 9 k U 9 8 O v B / W W t c V P E U Y Y T O I V z C O A K G n A H T W g B g z E 8 w y u 8 e c p 7 8 d 6 9 j 0 V r y S t m j u E P v M 8 f I q i O S Q = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" M Z P z i 4 O B 8 G Z k i J W E b Q p s Q f a 5 F k o = \" > A A A B 6 3 i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 5 E 0 D J o Y x n B x E B y h L 3 N J l m y u 3 f s z g n h y F + w s V D E 1 j 9 k 5 7 9 x L 7 l C E x 8 M P N 6 b Y W Z e l E h h 0 f e / v d L a + s b m V n m 7 s r O 7 t 3 9 Q P T x q 2 z g 1 j L d Y L G P T i a j l U m j e Q o G S d x L D q Y o k f 4 w m t 7 n / + M S N F b F + w G n C Q 0 V H W g w F o 5 h L P a G x X 6 3 5 d X 8 O s k q C g t S g Q L N f / e o N Y p Y q r p F J a m 0 3 8 B M M M 2 p Q M M l n l V 5 q e U L Z h I 5 4 1 1 F N F b d h N r 9 1 R s 6 c M i D D 2 L j S S O b q 7 4 m M K m u n K n K d i u L Y L n u 5 + J / X T X F 4 H W Z C J y l y z R a L h q k k G J P 8 c T I Q h j O U U 0 c o M 8 L d S t i Y G s r Q x V N x I Q T L L 6 + S 9 k U 9 8 O v B / W W t c V P E U Y Y T O I V z C O A K G n A H T W g B g z E 8 w y u 8 e c p 7 8 d 6 9 j 0 V r y S t m j u E P v M 8 f I q i O S Q = = < / l a t e x i t >\n\nDifferentiable Renderer\n\n\nNICER-SLAM\n\n\nMLP\n\n\nMapping and Tracking Output\n\nHierarchical Feature Grids\n\n\nGeometry Grids\n\nColor Grids\n\n\n\u2026 \u2026\n\nRay + Point Sampler Figure 2: System Overview. Our method takes only an RGB stream as input and outputs both the camera poses as well as a learned hierarchical scene representation for geometry and colors. To realize an end-to-end joint mapping and tracking, we render predicted colors, depths, normals and optimize wrt. the input RGB and monocular cues. Moreover, we further enforce the geometric consistency with an RGB warping loss and an optical flow loss.\n\nscenes, while NICE-SLAM can scale up to much larger indoor environments by applying hierarchical feature grids and tiny MLPs as the scene representation. Many follow-up works improve upon these two works from various perspectives, including efficient scene representation [18,21], fast optimziation [67], add IMU measurements [25], or different shape representations [39,30]. However, all of them require RGB-D inputs, which limits their applications in outdoor scenes or when only RGB sensors are available. In comparison, given only RGB sequences as input, our proposed neural-implicit-based system can output high-quality 3D reconstruction and recover accurate camera poses simultaneously. A concurrent work [22] 1 presents a system in a similar spirit to ours. While they optimize for accurate camera tracking, our method focuses on high-quality 3D reconstruction and novel view synthesis.\n\n\nMethod\n\nWe provide an overview of the NICER-SLAM pipeline in Fig. 2. Given an RGB video as input, we simultaneously estimate accurate 3D scene geometry and colors, as well as camera tracking via end-to-end optimization. We represent the scene geometry and appearance using hierarchical neural implicit representations (Sec. 3.1). With NeRF-like differentiable volume rendering, we can render color, depth, and normal values of every pixel (Sec. 3.2), which will be used for end-to-end joint optimization for camera pose, scene geometry, and color (Sec. 3.3). Finally we discuss some of the design choices made in our system (Sec. 3.4). 1 Arxiv version published on Jan 24, 2023.\n\n\nHierarchical Neural Implicit Representations\n\nWe first introduce our optimizable hierarchical scene representations that combine multi-level grid features with MLP decoders for SDF and color predictions.\n\nCoarse-level Geometric Representation. The goal of the coarse-level geometric representation is to efficiently model the coarse scene geometry (objects without capturing geometric details) and the scene layout (e.g. walls, floors) even with only partial observations. To this end, we represent the normalized scene with a dense voxel grid with a resolution of 32 \u00d7 32 \u00d7 32, and keep a 32-dim feature in each voxel. For any point x \u2208 R 3 in the space, we use a small MLP f coarse with a single 64-dim hidden layer to obtain its base SDF value s coarse \u2208 R and a geometric feature z coarse \u2208 R 32 as:\ns coarse , z coarse = f coarse \u03b3(x), \u03a6 coarse (x) ,(1)\nwhere \u03b3 corresponds to a fixed positional encoding [29,54] mapping the coordinate to higher dimension. Following [71,69,68], we set the level for positional encoding to 6. \u03a6 coarse (x) denotes that the feature grid \u03a6 coarse is trilinearly interpolated at the point x.\n\nFine-level Geometric Representation. While the coarse geometry can be obtained by our coarse-level shape representation, it is important to capture high-frequency geometric details in a scene. To realize it, we further model the high-frequency geometric details as residual SDF values with multi-resolution feature grids and an MLP decoder [5,31,76,53]. Specifically, we employ multiresolution dense feature grids {\u03a6 fine l } L 1 with resolutions R l . The resolutions are sampled in geometric space [31] to com-bine features at different frequencies:\nR l := R min b l b := exp ln R max \u2212 ln R min L \u2212 1 ,(2)\nwhere R min , R max correspond to the lowest and highest resolution, respectively. Here we consider R min = 32, R max = 128, and in total L = 8 levels. The feature dimension is 4 for each level. Now, to model the residual SDF values for a point x, we extract and concatenate the tri-linearly interpolated features at each level, and input them to an MLP f fine with 3 hidden layers of size 64:\n( \u2206s, z fine ) = f fine \u03b3(x), {\u03a6 fine l (x)} ,(3)\nwhere z fine \u2208 R 32 is the geometric feature for x at the fine level.\n\nWith the coarse-level base SDF value s coarse and the finelevel residual SDF \u2206s, the final predicted SDF value\u015d for x is simply the sum between two:\ns = s coarse + \u2206s .(4)\nColor Representation. Besides 3D geometry, we also predict color values such that our mapping and camera tracking can be optimized also with color losses. Moreover, as an additional application, we can also render images from novel views on the fly. Inspired by [31], we encode the color using another multi-resolution feature grid {\u03a6 color l } L 1 and a decoder f color parameterized with a 2-layer MLP of size 64. The number of feature grid levels is now L = 16, the features dimension is 2 at each level. The minimum and maximum resolution now become R min = 16 and R max = 2048, respectively. We predict per-point color values as:\nc = f color x,n, \u03b3(v), z coarse , z fine , {\u03a6 color l (x)} . (5)\nwheren corresponds to the normal at point x calculated from\u015d in Eq. (4), and \u03b3(v) is the viewing direction with positional encoding with a level of 4, following [68,71].\n\n\nVolume Rendering\n\nFollowing recent works on implicit-based 3D reconstruction [38,68,71,59] and dense visual SLAM [51,76], we optimize our scene representation from Sec. 3.1 using differentiable volume rendering. More specifically, in order to render a pixel, we cast a ray r from the camera center o through the pixel along its normalized view direction v. N points are then sampled along the ray, denoted as x i = o + t i v, and their predicted SDFs and color values are\u015d i and\u0109 i , respectively. For volume rendering, we follow [68] to transform the SDFs\u015d i to density values \u03c3 i :\n\u03c3 \u03b2 (s) = 1 2\u03b2 exp s \u03b2 if s \u2264 0 1 \u03b2 1 \u2212 1 2 exp \u2212 s \u03b2 if s > 0 ,(6)\nwhere \u03b2 \u2208 R is a parameter controlling the transformation from SDF to volume density. As in [29], the color\u0108 for the current ray r is calculated as:\nC = N i=1 T i \u03b1 i\u0109i T i = i\u22121 j=1 (1 \u2212 \u03b1 j ) \u03b1 i = 1 \u2212 exp (\u2212\u03c3 i \u03b4 i ) ,(7)\nwhere T i and \u03b1 i correspond to transmittance and alpha value of sample point i along ray r, respectively, and \u03b4 i is the distance between neighboring sample points. In a similar manner, we can also compute the depthD and normal N of the surface intersecting the current ray r as:\nD = N i=1 T i \u03b1 i t iN = N i=1 T i \u03b1 ini .(8)\nLocally Adaptive Transformation. The \u03b2 parameter in Eq. (6) models the smoothing amount near the object's surface. The value of \u03b2 gradually decreases during the optimization process as the network becomes more certain about the object surface. Therefore, this optimization scheme results in faster and sharper reconstructions.\n\nIn VolSDF [68], they model \u03b2 as a single global parameter. This way of modeling the transformation intrinsically assumes that the degree of optimization is the same across different regions of the scene, which is sufficient for small object-level scenes. However, for our sequential input setting within a complicated indoor scene, a global optimizable \u03b2 is sub-optimal (cf. ablation study in Sec. 4.2). Therefore, we propose to assign \u03b2 values locally so the SDFdensity transformation in Eq. (6) is also locally adaptive.\n\nIn detail, we maintain a voxel counter across the scene and count the number of point samples within every voxel during the mapping process. We empirically choose the voxel size of 64 3 (see ablation study in Sec. 4.2). Next, we heuristically design a transformation from local point samples counts T p to the \u03b2 value:\n\u03b2 = c 0 \u00b7 exp(\u2212c 1 \u00b7 T p ) + c 2 .(9)\nWe come up with the transformation by plotting \u03b2 decreasing curve with respect to the voxel count under the global input setting, and fitting a function on the curve. We empirically find that the exponential curve is the best fit.\n\n\nEnd-to-End Joint Mapping and Tracking\n\nPurely from an RGB sequential input, it is very difficult to jointly optimize 3D scene geometry and color together with camera poses, due to the high degree of ambiguity, especially for large complex scenes with many textureless and sparsely covered regions. Therefore, to enable endto-end joint mapping and tracking under our neural scene representation, we propose to use the following loss functions, including geometric and prior constraints, single-and multi-view constraints, as well as both global and local constraints.\n\nRGB Rendering Loss. Eq. (7) connects the 3D neural scene representation to 2D observations, hence, we can optimize the scene representation with a simple RGB reconstruction loss:\nL rgb = r\u2208R \u0108 (r) \u2212 C(r) 1 ,(10)\nwhere R denotes the randomly sampled pixels/rays in every iteration, and C is the input pixel color value.\n\n\nRGB Warping Loss.\n\nTo further enforce geometry consistency from only color inputs, we also add a simple per-pixel warping loss. For a pixel in frame m, denoted as r m , we first render its depth value using Eq. (8) and unproject it to 3D, and then project it to another frame n using intrinsic and extrinsic parameters of frame n. The projected pixel r m\u2192n in the nearby keyframe n is denoted as r m\u2192n . The warping loss is then defined as:\nL warp = rm\u2208R n\u2208Km C(r m ) \u2212 C(r m\u2192n ) 1 ,(11)\nwhere K m denotes the keyframe list for the current frame m, excluding frame m itself. We mask out the pixels that are projected outside the image boundary of frame n. Note that unlike [11] that optimize neural implicit surfaces with patch warping, we observed that it is way more efficient and without performance drop to simply perform warping on randomly sampled pixels.\n\nOptical Flow Loss. Both the RGB rendering and the warping loss are only point-wise terms which are prone to local minima. We therefore add a loss that is based on optical flow estimates which adhere to regional smoothness priors and help to tackle ambiguities. Suppose the sample pixel in frame m as r m and the corresponding projected pixel in frame n as r n , we can add an optical flow loss as follows:\nL flow = rm\u2208R n\u2208Km (r m \u2212 r n ) \u2212 GM(r m\u2192n ) 1 ,(12)\nwhere GM(r m\u2192n ) denotes the estimated optical flow from GMFlow [66].\n\n\nMonocular Depth Loss.\n\nGiven RGB input, one can easily obtain geometric cues (such as depths or normals) via an off-the-shelf monocular predictor [12]. Inspired by [71], we also include this information into the optimization to guide the neural implicit surface reconstruction. More specifically, to enforce depth consistency between our rendered expected depthsD and the monocular depthsD , we use the following loss [43,71]:\nL depth = r\u2208R (wD(r) + q) \u2212D(r) 2 ,(13)\nwhere w, q \u2208 R are the scale and shift used to alignD and D, sinceD is only known up to an unknown scale. We solve for w and q per image with a least-squares criterion [43], which has a closed-form solution.\n\nMonocular Normal Loss. Another geometric cue that is complementary to the monocular depth is surface normal. Unlike monocular depths that provide global surface information for the current view, surface normals are local and capture more geometric details. Similar to [71], we impose consistency on the volume-rendered normalN and the monocular normalsN from [12] with angular and L1 losses:\nL normal = r\u2208R N (r) \u2212N (r) 1 + 1 \u2212N (r) N (r) 1 .(14)\nEikonal Loss. In addition, we add the Eikonal loss [15] to regularize the output SDF values\u015d:\nL eikonal = x\u2208X ( \u2207\u015d(x) 2 \u2212 1) 2 ,(15)\nwhere X are a set of uniformly sampled near-surface points.\n\nOptimization Scheme. Finally, we provide details on how to optimize the scene geometry and appearance in the form of our hierarchical representation, and also the camera poses.\n\nMapping: To optimize the scene representation mentioned in Sec. 3.1, we uniformly sample M pixels/rays in total from the current frame and selected keyframes. Next, we perform a 3-stage optimization similar to [76] but use the following loss:\nL = L rgb + 0.5L warp + 0.001L flow + 0.1L depth + 0.05L normal + 0.1L eikonal(16)\nAt the first stage, we treat the coarse-level base SDF value s coarse in Eq. (1) as the final SDF value\u015d, and optimize the coarse feature grid \u03a6 coarse , coarse MLP parameters of f coarse , and color MLP parameters of f color with Eq. (16). Next, after 25% of the total number of iterations, we start using Eq. (4) as the final SDF value so the fine-level feature grids {\u03a6 fine l } and fine-level MLP f fine are also jointly optimized. Finally, after 75% of the total number of iterations, we conduct a local bundle adjustment (BA) with Eq. (16), where we also include the optimization of color feature grids {\u03a6 color l } as well as the extrinsic parameters of K selected mapping frames.\n\nCamera Tracking: We run in parallel camera tracking to optimize the camera pose (rotation and translation) of the current frame, while keeping the hierarchical scene representation fixed. Straightforwardly, we sample M t pixels from the current frame and use purely the RGB rendering loss in Eq. (10) for 100 iterations.\n\n\nSystem Design\n\nFrame Selection for Mapping. During the mapping process, we need to select multiple frames from which we sample rays and pixels. We introduce a simple frame selection mechanism. First, we maintain a global keyframe list for which we directly add one every 10 frames. For mapping, we select in total K = 16 frames, where 5 of them are randomly selected from the keyframe list, 10 are randomly selected from the latest 20 keyframes, and also the current frame.\n\nImplementation Details. Mapping is done every 5 frames, while tracking is done every frame. Note that with the pure RGB input, drifting is a known hard problem. To alleviate this, during the local BA stage in mapping, we freeze the camera poses for half of the 16 selected frames which are far from the current frame, and only optimize the camera poses of the other half jointly with the scene representation. For the adaptive local transformation in Eq. (9), we set c 0 = 1.208 \u00b7 10 \u22122 , c 1 = 6.26471 \u00b7 10 \u22126 and c 2 = 2.3 \u00b7 10 \u22123 . For mapping and tracking, we sample M = 8096 and M t = 1024 pixels, respectively, and optimize for 100 iterations. For every mapping iteration, we randomly sample pixels from all selected frames, instead of one frame per iteration. With our current unoptimized PyTorch implementation, it takes on average 496ms and 147ms for each mapping and tracking iteration on a single A100 GPU. The coarse geometry is initialized as a sphere following [71,68,69]. To optimize the scene representation during the first mapping step, we assign the scale and shift value as w = 20 and q = 0 in Eq. (13), so that the scaled monocular depth values are roughly reasonable (e.g. 1-5 meters). The final mesh is extracted from the scene representation using Marching Cubes [27] with a resolution of 512 3 .\n\n\nExperiments\n\nWe evaluate qualitative and quantitative comparisons against state-of-the-art (SOTA) SLAM frameworks on both synthetic and real-world datasets in Sec. 4.1. A comprehensive ablation study that supports our design choices is also provided in Sec. 4.2.\n\n\nDatasets.\n\nWe first evaluate on a synthetic dataset Replica [49], where RGB-(D) images can be rendered out with the official renderer. To verify the robustness of our approach, we compare a challenging real-world dataset 7-Scenes [48]. It consists of low-resolution images with severe motion blurs. We use COLMAP to obtain the intrinsic parameters of the RGB camera.\n\nBaselines. We compare to (a) SOTA neural implicitbased RGB-D SLAM system NICE-SLAM [76] and Vox-Fusion [67], (b) classic MVS method COLMAP [46], and (c) SOTA dense monocular SLAM system DROID-SLAM [57]. For camera tracking evaluation, we also compare to DROID-SLAM * , which does not perform the final global bundle adjustment and loop closure (identical to our NICER-SLAM setting). For DROID-SLAM's 3D reconstruction, we run TSDF fusion with their predicted depths of keyframes.\n\nMetrics. For camera tracking, we follow the conventional monocular SLAM evaluation pipeline where the estimated trajectory is aligned to the GT trajectory using evo [16], and then evaluate the accuracy of camera tracking (ATE RMSE) [50]. To evaluate scene geometry, we consider Accuracy, Completion, Completion Ratio, and Normal Consistency. The reconstructed meshes from monocular SLAM systems are aligned to the GT mesh using the ICP tool from [14]. Moreover, we use PSNR, SSIM [60] and LPIPS [73] for novel view synthesis evaluation.\n\nrm-0 rm-1 rm-2 off-0 off-1 off-2 off-3 off-4 Avg. Best results are highlighted as first , second , and third . NICER-SLAM performs the best among RGB SLAM methods, and is also on par with RGB-D methods.\n\n\nRGB-D input\n\n\nNICE-SLAM\n\nVox-Fusion COLMAP DROID-SLAM NICER-SLAM GT RGB-D input RGB input Figure 3: 3D Reconstruction Results on the Replica Dataset [49]. The second and fourth row show zoom-in normal maps.\n\nrm-0 rm-1 rm-2 off-0 off-1 off-2 off-3 off-4 Avg.  \n\n\nRGB-D input\n\n\nMapping, Tracking and Rendering Evaluations\n\nEvaluation on Replica [49]. First of all, for the evaluation of scene geometry, as shown in Table 1, our method significantly outperforms RGB-only baselines like DROID-SLAM and COLMAP, and even shows competitive performance against RGB-D SLAM approaches like NICE-SLAM and Vox-Fusion. Moreover, due to the use of monocular depth and normal cues, we show in Fig. 3 that our reconstructions can faithfully recover geometric details and attain the most visually appealing results among all methods. For camera tracking, we can clearly see on Table 2 that the state-of-the-art method DROID-SLAM outperforms all methods including those RGB-D SLAM systems. Nevertheless, our method is still on par with NICE-SLAM (1.88 vs 1.95 cm on average), while no ground truth depths are used as additional input. It is worth noting that even with the less accurate camera poses from our tracking pipeline, our results in novel view synthesis are notably better than all baseline meth-rm-0 rm-1 rm-2 off-0 off-1 off-2 off-3 off-4 Avg.    [48]. The second row shows zoomed-in normal maps. It is apparent that the quality of the scene representation is substantially worse for the other RGB-based methods despite their better tracking accuracy.\n\n\nRGB-D input\n\nods including those using additional depth inputs, see Table 3 and Fig. 4. On the one hand, the methods using traditional representations like COLMAP and DROID-SLAM suffer from rendering missing regions in the 3D reconstruction, and their renderings tend to be noisy. On the other hand, neural-implicit based approaches like NICE-SLAM and Vox-Fusion can fill in those missing areas but their renderings are normally over-smooth. We can faithfully render high-fidelity novel views even when those views are far from the training views. This illustrates the effectiveness of different losses for disambiguating the optimization of our scene representations.\n\nEvaluation on 7-Scenes [48]. We also evaluate on the challenging real-world dataset 7-Scenes to benchmark the robustness of different methods when the input images are chess fire heads office pumpkin kitchen stairs Avg.  of low resolutions and have severe motion blurs. For geometry illustrated in Fig. 5, we can notice that NICER-SLAM produces sharper and more detailed geometry over all baselines. In terms of tracking, as can be observed in Table 4, baselines with RGB-D input outperform RGB-only methods overall, indicating that the additional depth inputs play an essential role for tracking especially when RGB images are imperfect. Among RGB-only methods, COLMAP and DROID-SLAM* (without global bundle adjustment) perform poorly in the pumpkin scene because it contains large textureless and reflective regions in the RGB sequence. NICER-SLAM is more robust to such issues thanks to the predicted monocular geometric priors.\n\n\nRGB-D input\n\n\nAblation Study\n\nTo support our design choices, we investigate the effectiveness of different losses, the hierarchical architecture, SDF-density transformation, as well as the comparison between SDF and occupancy.\n\nLosses. We first verify the effectiveness of different losses for the mapping process from Sec. 3.3. In Table 5 (a), we evaluate both 3D reconstruction and tracking because we conduct local BA on the third stage of mapping. As can be noticed, using all losses together leads to the best overall performance. Without monocular depth or normal loss, both mapping and tracking accuracy drops significantly, indicating that these monocular geometric cues are important for the disambiguation of the optimization process.\n\nHierarchical Architecture. In Table 5 (b) we compare our proposed scene representations to two variations. The first one is to remove the multi-resolution color feature grids {\u03a6 color l } L 1 and only represent scene colors with the MLP f color . This change leads to large performance drops on all metrics, showing the necessity of having multi-res feature grids for colors. The second variation is to remove the coarse feature grid \u03a6 coarse and uses only fine-level feature grids to represent SDFs. This also causes inferior performance, especially in the completeness/completeness ratio, indicating that the coarse feature grid can indeed help to learn geometry better.\n\nSDF-to-Density Transformation. We also compare different design choices for the transformation from SDF to volume density (see Sec. 3.2): (a) Fixed \u03b2 value, (b) globally optimizable \u03b2 as in [68], and also (c) different voxel size for counting (our default setting uses 64 3 ). As can be seen in Table 5 (c), with the locally adaptive transformation and under the chosen voxel size, our method is able to obtain both better scene geometry and camera tracking.\n\nSDF vs. Occupancy. Unlike recent implicit-based dense SLAM systems [51,76,67] which use occupancy to implicitly represent scene geometry, we instead use SDFs. To verify this design choice, we keep the architecture identical but only replace the output in Eq. (4) to let the occupancy probability be between 0 and 1. The Eikonal loss L eikonal is also removed. In Fig. 6 we compare reconstruction results with given GT poses, and can clearly see that using SDFs leads to more accurate geometry. ATE  (c) Ablation Study on SDF-to-Density Transformation. w/ Occupancy w/ SDF GT Figure 6: Ablation Study on SDF vs. Occupancy. We conduct the ablation on one random Replica scene (office-4). The second row depicts zoomed-in normal maps for better comparison.\n\n\nConclusions\n\nWe present NICER-SLAM, a novel dense RGB SLAM system that is end-to-end optimizable for both neural implicit map representations and camera poses. We show that additional supervisions from easy-to-obtain monocular cues e.g. depths, normals, and optical flows can enable our system to reconstruct high-fidelity 3D dense maps and learn high-quality scene colors accurately and robustly in large indoor scenes.\n\nLimitations. Although we show benefits over SLAM methods using traditional scene representations in terms of mapping and novel view synthesis, our pipeline is not yet op-timized to be real-time. Also, no loop closure is performed under the current pipeline so the tracking performance should be further improvable.\n\nFigure 4 :Figure 5 :\n45Novel View Synthesis Results on the Replica the Dataset[49]. The second and fourth row show zoom-in renderings for better comparison. Note that we selected novel viewpoints far from the input views (extrapolation). 3D Reconstruction Results on the 7-Scenes Dataset\n\nTable 2 :\n2CameraTracking Results on the Replica \nDataset [49]. ATE RMSE [cm] (\u2193) is used as the evalua-\ntion metric. \n\n\n\nTable 3 :\n3NovelView Synthesis Evaluation on Replica \ndataset [49]. Best results are highlighted as first , \nsecond , and third . Our method mostly outperforms all \nother methods even the ones that additionally use depth in-\nputs. \n\n\n\nTable 4 :\n4Camera Tracking Results on the 7-Scenes Dataset[48]. ATE RMSE [cm] (\u2193) is used as the evaluation metric.\n\n\nRMSE\u2193 Acc. \u2193 Comp. \u2193 Comp. Ratio \u2191 Normal Cons. \u2191 Ablation Study on Losses in Eq. (16). ATE RMSE\u2193 Acc. \u2193 Comp. \u2193 Comp. Ratio \u2191 Normal Cons. \u2191 w/o {\u03a6 color (b) Ablation Study on Hierarchical Architecture. ATE RMSE\u2193 Acc. \u2193 Comp. \u2193 Comp. Ratio \u2191 Normal Cons. \u2191w/o L depth \n4.48 \n4.74 \n6.18 \n71.10 \n89.23 \nw/o L normal \n3.22 \n7.25 \n6.98 \n51.07 \n86.64 \nw/o Lwarp \n2.96 \n3.76 \n4.60 \n74.42 \n91.32 \nw/o L flow \n2.30 \n3.31 \n4.31 \n81.10 \n91.00 \nOurs \n2.01 \n3.03 \n3.87 \n83.98 \n90.96 \n\n(a) l \n\n} L \n\n1 \n\n9.92 \n8.32 \n8.49 \n50.13 \n87.84 \nw/o \u03a6 coarse \n3.07 \n4.51 \n5.11 \n67.29 \n90.17 \nOurs \n2.01 \n3.03 \n3.87 \n83.98 \n90.96 \n\nFixed \u03b2=0.01 \n3.81 \n7.77 \n8.28 \n39.48 \n87.52 \nFixed \u03b2=0.001 \n3.98 \n3.48 \n5.05 \n76.67 \n90.39 \nGlobal optim. \u03b2 \n2.62 \n3.64 \n4.53 \n76.35 \n90.88 \nVoxel size 32 3 \n3.00 \n3.19 \n4.35 \n81.90 \n90.65 \nVoxel size 128 3 \n2.16 \n4.35 \n4.87 \n68.96 \n90.40 \nOurs \n2.01 \n3.03 \n3.87 \n83.98 \n90.96 \n\n\n\nTable 5 :\n5Ablation Study. On a single randomly selected Replica scene (office-4), we evaluate both camera tracking and reconstruction. Best results are highlighted as first , second , and third .\nAcknowledgements. This project is partially supported by the SONY Research Award Program and a research grant by FIFA. The authors thank the Max Planck ETH Center for Learning Systems (CLS) for supporting Songyou Peng and the strategic research project ELLIIT for supporting Viktor Larsson. We thank Weicai Ye, Boyang Sun, Jianhao Zheng, and Heng Li for their helpful discussion.\nWenjing Bian, Zirui Wang, Kejie Li, Jia-Wang Bian, Victor Adrian Prisacariu, arXiv:2212.07388Nope-nerf: Optimising neural radiance field with no pose prior. arXiv preprintWenjing Bian, Zirui Wang, Kejie Li, Jia-Wang Bian, and Victor Adrian Prisacariu. Nope-nerf: Optimising neu- ral radiance field with no pose prior. arXiv preprint arXiv:2212.07388, 2022.\n\nCodeslam -learning a compact, optimisable representation for dense visual SLAM. Michael Bloesch, Jan Czarnowski, Ronald Clark, Stefan Leutenegger, Andrew J Davison, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Michael Bloesch, Jan Czarnowski, Ronald Clark, Stefan Leutenegger, and Andrew J. Davison. Codeslam -learning a compact, optimisable representation for dense visual SLAM. In Proc. IEEE Conf. on Computer Vision and Pattern Recog- nition (CVPR), pages 2560-2568, 2018.\n\nReal-time camera tracking and 3d reconstruction using signed distance functions. Erik Bylow, J\u00fcrgen Sturm, Christian Kerl, Fredrik Kahl, Daniel Cremers, Robotics: Science and Systems (RSS). 2Erik Bylow, J\u00fcrgen Sturm, Christian Kerl, Fredrik Kahl, and Daniel Cremers. Real-time camera tracking and 3d recon- struction using signed distance functions. In Robotics: Sci- ence and Systems (RSS), volume 2, page 2, 2013.\n\nLearning implicit fields for generative shape modeling. Zhiqin Chen, Hao Zhang, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Zhiqin Chen and Hao Zhang. Learning implicit fields for generative shape modeling. In Proc. IEEE Conf. on Com- puter Vision and Pattern Recognition (CVPR), pages 5939- 5948, 2019.\n\nImplicit functions in feature space for 3d shape reconstruction and completion. Julian Chibane, Thiemo Alldieck, Gerard Pons-Moll, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Julian Chibane, Thiemo Alldieck, and Gerard Pons-Moll. Implicit functions in feature space for 3d shape reconstruc- tion and completion. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pages 6970-6981, 2020.\n\nGaussian activated neural radiance fields for high fidelity reconstruction and pose estimation. Shin-Fang, Sameera Chng, Jamie Ramasinghe, Simon Sherrah, Lucey, Proc. of the European Conf. on Computer Vision (ECCV). of the European Conf. on Computer Vision (ECCV)SpringerShin-Fang Chng, Sameera Ramasinghe, Jamie Sherrah, and Simon Lucey. Gaussian activated neural radiance fields for high fidelity reconstruction and pose estimation. In Proc. of the European Conf. on Computer Vision (ECCV), pages 264-280. Springer, 2022.\n\nOrbeez-slam: A realtime monocular visual slam with orb features and nerfrealized mapping. Chi-Ming Chung, Yang-Che Tseng, Ya-Ching Hsu, Xiang-Qian Shi, Yun-Hung Hua, Jia-Fong Yeh, Wen-Chin Chen, Yi-Ting Chen, Winston H Hsu, arXiv:2209.13274arXiv preprintChi-Ming Chung, Yang-Che Tseng, Ya-Ching Hsu, Xiang- Qian Shi, Yun-Hung Hua, Jia-Fong Yeh, Wen-Chin Chen, Yi-Ting Chen, and Winston H Hsu. Orbeez-slam: A real- time monocular visual slam with orb features and nerf- realized mapping. arXiv preprint arXiv:2209.13274, 2022.\n\nVolumetric bundle adjustment for online photorealistic scene capture. Ronald Clark, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Ronald Clark. Volumetric bundle adjustment for online pho- torealistic scene capture. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pages 6124-6132, 2022.\n\nDeepfactors: Real-time probabilistic dense monocular slam. Jan Czarnowski, Tristan Laidlow, Ronald Clark, Andrew J Davison, IEEE Robotics and Automation Letters. 52Jan Czarnowski, Tristan Laidlow, Ronald Clark, and An- drew J Davison. Deepfactors: Real-time probabilistic dense monocular slam. IEEE Robotics and Automation Letters, 5(2):721-728, 2020.\n\nBundlefusion: Real-time globally consistent 3d reconstruction using on-the-fly surface reintegration. Angela Dai, Matthias Nie\u00dfner, Michael Zollh\u00f6fer, Shahram Izadi, Christian Theobalt, ACM Trans. on Graphics. 3641Angela Dai, Matthias Nie\u00dfner, Michael Zollh\u00f6fer, Shahram Izadi, and Christian Theobalt. Bundlefusion: Real-time globally consistent 3d reconstruction using on-the-fly surface reintegration. ACM Trans. on Graphics, 36(4):1, 2017.\n\nImproving neural implicit surfaces geometry with patch warping. Fran\u00e7ois Darmon, B\u00e9n\u00e9dicte Bascle, Jean-Cl\u00e9ment Devaux, Pascal Monasse, Mathieu Aubry, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Fran\u00e7ois Darmon, B\u00e9n\u00e9dicte Bascle, Jean-Cl\u00e9ment Devaux, Pascal Monasse, and Mathieu Aubry. Improving neural im- plicit surfaces geometry with patch warping. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pages 6260-6269, 2022.\n\nOmnidata: A scalable pipeline for making multitask mid-level vision datasets from 3d scans. Ainaz Eftekhar, Alexander Sax, Jitendra Malik, Amir Zamir, Proc. of the IEEE International Conf. on Computer Vision (ICCV). of the IEEE International Conf. on Computer Vision (ICCV)Ainaz Eftekhar, Alexander Sax, Jitendra Malik, and Amir Zamir. Omnidata: A scalable pipeline for making multi- task mid-level vision datasets from 3d scans. In Proc. of the IEEE International Conf. on Computer Vision (ICCV), pages 10786-10796, 2021.\n\nDirect sparse odometry. Jakob Engel, Vladlen Koltun, Daniel Cremers, IEEE Trans. on Pattern Analysis and Machine Intelligence (PAMI). 403Jakob Engel, Vladlen Koltun, and Daniel Cremers. Direct sparse odometry. IEEE Trans. on Pattern Analysis and Ma- chine Intelligence (PAMI), 40(3):611-625, 2017.\n\n. Daniel Girardeau-Montaut, Cloudcompare, France, EDF R&D Telecom ParisTech11Daniel Girardeau-Montaut. Cloudcompare. France: EDF R&D Telecom ParisTech, 11, 2016.\n\nAmos Gropp, Lior Yariv, arXiv:2002.10099Niv Haim, Matan Atzmon, and Yaron Lipman. Implicit geometric regularization for learning shapes. arXiv preprintAmos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, and Yaron Lipman. Implicit geometric regularization for learning shapes. arXiv preprint arXiv:2002.10099, 2020.\n\nevo: Python package for the evaluation of odometry and slam. Michael Grupp, Michael Grupp. evo: Python package for the evaluation of odometry and slam. https://github.com/MichaelGrupp/evo, 2017.\n\nLocal implicit grid representations for 3d scenes. Chiyu Jiang, Avneesh Sud, Ameesh Makadia, Jingwei Huang, Matthias Nie\u00dfner, Thomas Funkhouser, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Chiyu Jiang, Avneesh Sud, Ameesh Makadia, Jingwei Huang, Matthias Nie\u00dfner, and Thomas Funkhouser. Local implicit grid representations for 3d scenes. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pages 6001-6010, 2020.\n\nCamilla Mohammad Mahdi Johari, Fran\u00e7ois Carta, Fleuret, Eslam, arXiv:2211.11704Efficient dense slam system based on hybrid representation of signed distance fields. arXiv preprintMohammad Mahdi Johari, Camilla Carta, and Fran\u00e7ois Fleuret. Eslam: Efficient dense slam system based on hy- brid representation of signed distance fields. arXiv preprint arXiv:2211.11704, 2022.\n\nParallel tracking and mapping for small ar workspaces. Georg Klein, David Murray, IEEE International Symposium on Mixed and Augmented Reality (ISMAR). IEEEGeorg Klein and David Murray. Parallel tracking and map- ping for small ar workspaces. In IEEE International Sympo- sium on Mixed and Augmented Reality (ISMAR), pages 225- 234. IEEE, 2007.\n\nTandem: Tracking and dense mapping in real-time using deep multi-view stereo. Lukas Koestler, Nan Yang, Niclas Zeller, Daniel Cremers, Proc. Conf. on Robot Learning (CoRL). Conf. on Robot Learning (CoRL)PMLRLukas Koestler, Nan Yang, Niclas Zeller, and Daniel Cre- mers. Tandem: Tracking and dense mapping in real-time us- ing deep multi-view stereo. In Proc. Conf. on Robot Learn- ing (CoRL), pages 34-45. PMLR, 2022.\n\nMeslam: Memory efficient slam based on neural fields. Evgenii Kruzhkov, Alena Savinykh, Pavel Karpyshev, Mikhail Kurenkov, Evgeny Yudin, Andrei Potapov, Dzmitry Tsetserukou, 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC). IEEEEvgenii Kruzhkov, Alena Savinykh, Pavel Karpyshev, Mikhail Kurenkov, Evgeny Yudin, Andrei Potapov, and Dzmitry Tsetserukou. Meslam: Memory efficient slam based on neural fields. In 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC), pages 430-435. IEEE, 2022.\n\nDense rgb slam with neural implicit maps. Heng Li, Xiaodong Gu, Weihao Yuan, Luwei Yang, Zilong Dong, Ping Tan, Proc. of the International Conf. on Learning Representations (ICLR). of the International Conf. on Learning Representations (ICLR)2023Heng Li, Xiaodong Gu, Weihao Yuan, Luwei Yang, Zilong Dong, and Ping Tan. Dense rgb slam with neural implicit maps. In Proc. of the International Conf. on Learning Rep- resentations (ICLR), 2023.\n\nBarf: Bundleadjusting neural radiance fields. C Lin, W Ma, A Torralba, S Lucey, Proc. of the IEEE International Conf. on Computer Vision (ICCV). of the IEEE International Conf. on Computer Vision (ICCV)2021C. Lin, W. Ma, A. Torralba, and S. Lucey. Barf: Bundle- adjusting neural radiance fields. In Proc. of the IEEE Inter- national Conf. on Computer Vision (ICCV), 2021.\n\nDynamic plane convolutional occupancy networks. Stefan Lionar, Daniil Emtsev, Dusan Svilarkovic, Songyou Peng, Proc. of the IEEE Winter Conference on Applications of Computer Vision (WACV). of the IEEE Winter Conference on Applications of Computer Vision (WACV)Stefan Lionar, Daniil Emtsev, Dusan Svilarkovic, and Songyou Peng. Dynamic plane convolutional occupancy net- works. In Proc. of the IEEE Winter Conference on Applica- tions of Computer Vision (WACV), pages 1829-1838, 2021.\n\nDaniil Lisus, Connor Holmes, arXiv:2301.03102Towards open world nerfbased slam. arXiv preprintDaniil Lisus and Connor Holmes. Towards open world nerf- based slam. arXiv preprint arXiv:2301.03102, 2023.\n\nDist: Rendering deep implicit signed distance function with differentiable sphere tracing. Shaohui Liu, Yinda Zhang, Songyou Peng, Boxin Shi, Marc Pollefeys, Zhaopeng Cui, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Shaohui Liu, Yinda Zhang, Songyou Peng, Boxin Shi, Marc Pollefeys, and Zhaopeng Cui. Dist: Rendering deep implicit signed distance function with differentiable sphere tracing. In Proc. IEEE Conf. on Computer Vision and Pattern Recog- nition (CVPR), pages 2019-2028, 2020.\n\nMarching cubes: A high resolution 3d surface construction algorithm. E William, Harvey E Lorensen, Cline, ACM siggraph computer graphics. 214William E Lorensen and Harvey E Cline. Marching cubes: A high resolution 3d surface construction algorithm. ACM siggraph computer graphics, 21(4):163-169, 1987.\n\nOccupancy networks: Learning 3d reconstruction in function space. Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, Andreas Geiger, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Lars Mescheder, Michael Oechsle, Michael Niemeyer, Se- bastian Nowozin, and Andreas Geiger. Occupancy networks: Learning 3d reconstruction in function space. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pages 4460-4470, 2019.\n\nNerf: Representing scenes as neural radiance fields for view synthesis. Ben Mildenhall, P Pratul, Matthew Srinivasan, Jonathan T Tancik, Ravi Barron, Ren Ramamoorthi, Ng, Proc. of the European Conf. on Computer Vision (ECCV). of the European Conf. on Computer Vision (ECCV)2020Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. Nerf: Representing scenes as neural radiance fields for view syn- thesis. In Proc. of the European Conf. on Computer Vision (ECCV), 2020.\n\nidf-slam: End-to-end rgb-d slam with neural implicit mapping and deep feature tracking. Yuhang Ming, Weicai Ye, Andrew Calway, arXiv:2209.07919arXiv preprintYuhang Ming, Weicai Ye, and Andrew Calway. idf-slam: End-to-end rgb-d slam with neural implicit mapping and deep feature tracking. arXiv preprint arXiv:2209.07919, 2022.\n\nInstant neural graphics primitives with a multiresolution hash encoding. Thomas M\u00fcller, Alex Evans, Christoph Schied, Alexander Keller, ACM Trans. on Graphics. 4142022Thomas M\u00fcller, Alex Evans, Christoph Schied, and Alexan- der Keller. Instant neural graphics primitives with a mul- tiresolution hash encoding. ACM Trans. on Graphics, 41(4), 2022.\n\nOrb-slam: a versatile and accurate monocular slam system. Raul Mur-Artal, Jose Maria Martinez Montiel, Juan D Tardos, IEEE transactions on robotics. 31Raul Mur-Artal, Jose Maria Martinez Montiel, and Juan D Tardos. Orb-slam: a versatile and accurate monocular slam system. IEEE transactions on robotics, 31(5):1147-1163, 2015.\n\nOrb-slam2: An opensource slam system for monocular, stereo, and rgb-d cameras. Raul Mur, -Artal , Juan D Tard\u00f3s, IEEE transactions on robotics. 335Raul Mur-Artal and Juan D Tard\u00f3s. Orb-slam2: An open- source slam system for monocular, stereo, and rgb-d cam- eras. IEEE transactions on robotics, 33(5):1255-1262, 2017.\n\nKinectfusion: Real-time dense surface mapping and tracking. R A Newcombe, S Izadi, O Hilliges, D Molyneaux, D Kim, A J Davison, P Kohi, J Shotton, S Hodges, A Fitzgibbon, IEEE International Symposium on Mixed and Augmented Reality (ISMAR). R. A. Newcombe, S. Izadi, O. Hilliges, D. Molyneaux, D. Kim, A. J. Davison, P. Kohi, J. Shotton, S. Hodges, and A. Fitzgibbon. Kinectfusion: Real-time dense surface mapping and tracking. In IEEE International Symposium on Mixed and Augmented Reality (ISMAR), 2011.\n\nDtam: Dense tracking and mapping in real-time. A Richard, Newcombe, J Steven, Andrew J Lovegrove, Davison, Richard A Newcombe, Steven J Lovegrove, and Andrew J Davison. Dtam: Dense tracking and mapping in real-time.\n\nProc. of the IEEE International Conf. on Computer Vision (ICCV). of the IEEE International Conf. on Computer Vision (ICCV)IEEEIn Proc. of the IEEE International Conf. on Computer Vision (ICCV), pages 2320-2327. IEEE, 2011.\n\nDifferentiable volumetric rendering: Learning implicit 3D representations without 3D supervision. M Niemeyer, L Mescheder, M Oechsle, A Geiger, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)M. Niemeyer, L. Mescheder, M. Oechsle, and A. Geiger. Differentiable volumetric rendering: Learning implicit 3D representations without 3D supervision. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2019.\n\nReal-time 3d reconstruction at scale using voxel hashing. Matthias Nie\u00dfner, Michael Zollh\u00f6fer, Shahram Izadi, Marc Stamminger, ACM Trans. on Graphics. 326Matthias Nie\u00dfner, Michael Zollh\u00f6fer, Shahram Izadi, and Marc Stamminger. Real-time 3d reconstruction at scale us- ing voxel hashing. ACM Trans. on Graphics, 32(6):1-11, 2013.\n\nUnisurf: Unifying neural implicit surfaces and radiance fields for multi-view reconstruction. Michael Oechsle, Songyou Peng, Andreas Geiger, Proc. of the IEEE International Conf. on Computer Vision (ICCV). of the IEEE International Conf. on Computer Vision (ICCV)Michael Oechsle, Songyou Peng, and Andreas Geiger. Unisurf: Unifying neural implicit surfaces and radiance fields for multi-view reconstruction. In Proc. of the IEEE In- ternational Conf. on Computer Vision (ICCV), pages 5589- 5599, 2021.\n\nisdf: Real-time neural signed distance fields for robot perception. Joseph Ortiz, RSSAlexander Clegg, RSSJing Dong, RSSEdgar Sucar, RSSDavid Novotny, RSSMichael Zollhoefer, RSSMustafa Mukadam, RSSRobotics: Science and Systems. 2022Joseph Ortiz, Alexander Clegg, Jing Dong, Edgar Sucar, David Novotny, Michael Zollhoefer, and Mustafa Mukadam. isdf: Real-time neural signed distance fields for robot per- ception. In Robotics: Science and Systems (RSS), 2022.\n\nDeepsdf: Learning continuous signed distance functions for shape representation. Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, Steven Lovegrove, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Jeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven Lovegrove. Deepsdf: Learning con- tinuous signed distance functions for shape representation. In Proc. IEEE Conf. on Computer Vision and Pattern Recog- nition (CVPR), pages 165-174, 2019.\n\nShape as points: A differentiable poisson solver. Songyou Peng, Chiyu Jiang, Yiyi Liao, Michael Niemeyer, Marc Pollefeys, Andreas Geiger, Advances in Neural Information Processing Systems (NeurIPS). 34Songyou Peng, Chiyu Jiang, Yiyi Liao, Michael Niemeyer, Marc Pollefeys, and Andreas Geiger. Shape as points: A dif- ferentiable poisson solver. Advances in Neural Information Processing Systems (NeurIPS), 34:13032-13044, 2021.\n\nConvolutional occupancy networks. Songyou Peng, Michael Niemeyer, Lars Mescheder, Marc Pollefeys, Andreas Geiger, Proc. of the European Conf. on Computer Vision (ECCV). of the European Conf. on Computer Vision (ECCV)SpringerSongyou Peng, Michael Niemeyer, Lars Mescheder, Marc Pollefeys, and Andreas Geiger. Convolutional occupancy networks. In Proc. of the European Conf. on Computer Vi- sion (ECCV), pages 523-540. Springer, 2020.\n\nTowards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer. Ren\u00e9 Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, Vladlen Koltun, IEEE Trans. on Pattern Analysis and Machine Intelligence. 2020PAMIRen\u00e9 Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, and Vladlen Koltun. Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer. IEEE Trans. on Pattern Analysis and Machine In- telligence (PAMI), 2020.\n\nKilonerf: Speeding up neural radiance fields with thousands of tiny mlps. Christian Reiser, Songyou Peng, Yiyi Liao, Andreas Geiger, Proc. of the IEEE International Conf. on Computer Vision (ICCV). of the IEEE International Conf. on Computer Vision (ICCV)Christian Reiser, Songyou Peng, Yiyi Liao, and Andreas Geiger. Kilonerf: Speeding up neural radiance fields with thousands of tiny mlps. In Proc. of the IEEE International Conf. on Computer Vision (ICCV), pages 14335-14345, 2021.\n\nAntoni Rosinol, J John, Luca Leonard, Carlone, arXiv:2210.13641Nerfslam: Real-time dense monocular slam with neural radiance fields. arXiv preprintAntoni Rosinol, John J Leonard, and Luca Carlone. Nerf- slam: Real-time dense monocular slam with neural radiance fields. arXiv preprint arXiv:2210.13641, 2022.\n\nStructure-from-motion revisited. J L Schonberger, J M Frahm, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)J. L. Schonberger and J. M. Frahm. Structure-from-motion revisited. In Proc. IEEE Conf. on Computer Vision and Pat- tern Recognition (CVPR), 2016.\n\nBAD SLAM: bundle adjusted direct RGB-D SLAM. Thomas Sch\u00f6ps, Torsten Sattler, Marc Pollefeys, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Computer Vision Foundation / IEEEThomas Sch\u00f6ps, Torsten Sattler, and Marc Pollefeys. BAD SLAM: bundle adjusted direct RGB-D SLAM. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pages 134-144. Computer Vision Foundation / IEEE, 2019.\n\nScene coordinate regression forests for camera relocalization in rgb-d images. Jamie Shotton, Ben Glocker, Christopher Zach, Shahram Izadi, Antonio Criminisi, Andrew Fitzgibbon, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionJamie Shotton, Ben Glocker, Christopher Zach, Shahram Izadi, Antonio Criminisi, and Andrew Fitzgibbon. Scene co- ordinate regression forests for camera relocalization in rgb-d images. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2930-2937, 2013.\n\nJ Straub, T Whelan, L Ma, Y Chen, E Wijmans, S Green, J J Engel, R Mur-Artal, C R , S Verma, A Clarkson, M Yan, B Budge, Y Yan, X Pan, J Yon, Y Zou, K Leon, N Carter, J Briales, T Gillingham, E Mueggler, L Pesqueira, M Savva, D Batra, H M Strasdat, R D Nardi, M Goesele, S Lovegrove, R Newcombe, arXiv:1906.05797The Replica dataset: A digital replica of indoor spaces. arXiv preprintJ. Straub, T. Whelan, L. Ma, Y. Chen, E. Wijmans, S. Green, J. J. Engel, R. Mur-Artal, C. R., S. Verma, A. Clarkson, M. Yan, B. Budge, Y. Yan, X. Pan, J. Yon, Y. Zou, K. Leon, N. Carter, J. Briales, T. Gillingham, E. Mueggler, L. Pesqueira, M. Savva, D. Batra, H. M. Strasdat, R. D. Nardi, M. Goesele, S. Lovegrove, and R. Newcombe. The Replica dataset: A digital replica of indoor spaces. arXiv preprint arXiv:1906.05797, 2019.\n\nA benchmark for the evaluation of rgb-d slam systems. J\u00fcrgen Sturm, Nikolas Engelhard, Felix Endres, Wolfram Burgard, Daniel Cremers, Proc. IEEE International Conf. on Intelligent Robots and Systems (IROS). IEEE International Conf. on Intelligent Robots and Systems (IROS)J\u00fcrgen Sturm, Nikolas Engelhard, Felix Endres, Wolfram Burgard, and Daniel Cremers. A benchmark for the eval- uation of rgb-d slam systems. In Proc. IEEE International Conf. on Intelligent Robots and Systems (IROS), 2012.\n\nEdgar Sucar, Shikun Liu, Joseph Ortiz, Andrew J Davison, imap: Implicit mapping and positioning in real-time. Edgar Sucar, Shikun Liu, Joseph Ortiz, and Andrew J Davi- son. imap: Implicit mapping and positioning in real-time.\n\nProc. of the IEEE International Conf. on Computer Vision (ICCV). of the IEEE International Conf. on Computer Vision (ICCV)In Proc. of the IEEE International Conf. on Computer Vision (ICCV), pages 6229-6238, 2021.\n\nNodeslam: Neural object descriptors for multi-view shape reconstruction. Edgar Sucar, Kentaro Wada, Andrew Davison, Proc. of the International Conf. on 3D Vision (3DV). of the International Conf. on 3D Vision (3DV)IEEEEdgar Sucar, Kentaro Wada, and Andrew Davison. Nodeslam: Neural object descriptors for multi-view shape reconstruction. In Proc. of the International Conf. on 3D Vision (3DV), pages 949-958. IEEE, 2020.\n\nNeural geometric level of detail: Real-time rendering with implicit 3d shapes. Towaki Takikawa, Joey Litalien, Kangxue Yin, Karsten Kreis, Charles Loop, Derek Nowrouzezahrai, Alec Jacobson, Morgan Mcguire, Sanja Fidler, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Towaki Takikawa, Joey Litalien, Kangxue Yin, Karsten Kreis, Charles Loop, Derek Nowrouzezahrai, Alec Jacobson, Morgan McGuire, and Sanja Fidler. Neural geometric level of detail: Real-time rendering with implicit 3d shapes. In Proc. IEEE Conf. on Computer Vision and Pattern Recogni- tion (CVPR), pages 11358-11367, 2021.\n\nFourier features let networks learn high frequency functions in low dimensional domains. Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, Ren Ng, Advances in Neural Information Processing Systems (NeurIPS). 2020Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ra- mamoorthi, Jonathan Barron, and Ren Ng. Fourier features let networks learn high frequency functions in low dimen- sional domains. In Advances in Neural Information Process- ing Systems (NeurIPS), 2020.\n\nBa-net: Dense bundle adjustment network. Chengzhou Tang, Ping Tan, Proc. of the International Conf. on Learning Representations (ICLR). of the International Conf. on Learning Representations (ICLR)Chengzhou Tang and Ping Tan. Ba-net: Dense bundle adjust- ment network. In Proc. of the International Conf. on Learn- ing Representations (ICLR), 2019.\n\nDeepv2d: Video to depth with differentiable structure from motion. Zachary Teed, Jia Deng, Proc. of the International Conf. on Learning Representations (ICLR). of the International Conf. on Learning Representations (ICLR)2020Zachary Teed and Jia Deng. Deepv2d: Video to depth with differentiable structure from motion. In Proc. of the Interna- tional Conf. on Learning Representations (ICLR), 2020.\n\nDroid-slam: Deep visual slam for monocular, stereo, and rgb-d cameras. Zachary Teed, Jia Deng, Advances in Neural Information Processing Systems. 34Zachary Teed and Jia Deng. Droid-slam: Deep visual slam for monocular, stereo, and rgb-d cameras. In Advances in Neural Information Processing Systems, volume 34, pages 16558-16569, 2021.\n\nDemon: Depth and motion network for learning monocular stereo. Benjamin Ummenhofer, Huizhong Zhou, Jonas Uhrig, Nikolaus Mayer, Eddy Ilg, Alexey Dosovitskiy, Thomas Brox, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Benjamin Ummenhofer, Huizhong Zhou, Jonas Uhrig, Niko- laus Mayer, Eddy Ilg, Alexey Dosovitskiy, and Thomas Brox. Demon: Depth and motion network for learning monocular stereo. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pages 5038-5047, 2017.\n\nNeus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction. Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, Wenping Wang, arXiv:2106.10689arXiv preprintPeng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction. arXiv preprint arXiv:2106.10689, 2021.\n\nImage quality assessment: from error visibility to structural similarity. Zhou Wang, Alan C Bovik, R Hamid, Eero P Sheikh, Simoncelli, IEEE transactions on image processing. 134Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Si- moncelli. Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing, 13(4):600-612, 2004.\n\nZ Wang, S Wu, W Xie, M Chen, V A Prisacariu, arXiv:2102.07064Nerf-: Neural radiance fields without known camera parameters. arXiv preprintZ. Wang, S. Wu, W. Xie, M. Chen, and V. A. Prisacariu. Nerf-: Neural radiance fields without known camera param- eters. arXiv preprint arXiv:2102.07064, 2021.\n\nKintinuous: Spatially extended kinectfusion. Thomas Whelan, Michael Kaess, Maurice Fallon, Hordur Johannsson, John Leonard, John Mcdonald, RSS '12 Workshop on RGB-D: Advanced Reasoning with Depth Cameras. Thomas Whelan, Michael Kaess, Maurice Fallon, Hordur Jo- hannsson, John Leonard, and John McDonald. Kintinuous: Spatially extended kinectfusion. In RSS '12 Workshop on RGB-D: Advanced Reasoning with Depth Cameras, 2012.\n\nElasticfusion: Dense slam without a pose graph. Thomas Whelan, Stefan Leutenegger, Renato Salas-Moreno, Ben Glocker, Andrew Davison, Robotics: Science and Systems (RSS). Thomas Whelan, Stefan Leutenegger, Renato Salas-Moreno, Ben Glocker, and Andrew Davison. Elasticfusion: Dense slam without a pose graph. In Robotics: Science and Systems (RSS), 2015.\n\nScalable neural indoor scene rendering. Xiuchao Wu, Jiamin Xu, Zihan Zhu, Hujun Bao, Qixing Huang, James Tompkin, Weiwei Xu, ACM Transactions on Graphics (TOG). 414Xiuchao Wu, Jiamin Xu, Zihan Zhu, Hujun Bao, Qixing Huang, James Tompkin, and Weiwei Xu. Scalable neu- ral indoor scene rendering. ACM Transactions on Graphics (TOG), 41(4):1-16, 2022.\n\nNeural fields in visual computing and beyond. Yiheng Xie, Towaki Takikawa, Shunsuke Saito, Or Litany, Shiqin Yan, Numair Khan, Federico Tombari, James Tompkin, Vincent Sitzmann, Srinath Sridhar, Computer Graphics Forum. Wiley Online Library41Yiheng Xie, Towaki Takikawa, Shunsuke Saito, Or Litany, Shiqin Yan, Numair Khan, Federico Tombari, James Tomp- kin, Vincent Sitzmann, and Srinath Sridhar. Neural fields in visual computing and beyond. In Computer Graphics Forum, volume 41, pages 641-676. Wiley Online Library, 2022.\n\nLearning optical flow via global matching. Haofei Xu, Jing Zhang, Jianfei Cai, Hamid Rezatofighi, Dacheng Tao, Gmflow, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Haofei Xu, Jing Zhang, Jianfei Cai, Hamid Rezatofighi, and Dacheng Tao. Gmflow: Learning optical flow via global matching. In Proc. IEEE Conf. on Computer Vision and Pat- tern Recognition (CVPR), pages 8121-8130, 2022.\n\nVox-fusion: Dense tracking and mapping with voxel-based neural implicit representation. Xingrui Yang, Hai Li, Hongjia Zhai, Yuhang Ming, Yuqian Liu, Guofeng Zhang, IEEE International Symposium on Mixed and Augmented Reality (ISMAR). IEEEXingrui Yang, Hai Li, Hongjia Zhai, Yuhang Ming, Yuqian Liu, and Guofeng Zhang. Vox-fusion: Dense tracking and mapping with voxel-based neural implicit representation. In IEEE International Symposium on Mixed and Augmented Reality (ISMAR), pages 499-507. IEEE, 2022.\n\nVolume rendering of neural implicit surfaces. Lior Yariv, Jiatao Gu, Yoni Kasten, Yaron Lipman, Advances in Neural Information Processing Systems (NeurIPS). 34Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. Vol- ume rendering of neural implicit surfaces. In Advances in Neural Information Processing Systems (NeurIPS), vol- ume 34, pages 4805-4815, 2021.\n\nMultiview neural surface reconstruction by disentangling geometry and appearance. Lior Yariv, Yoni Kasten, Dror Moran, Meirav Galun, Matan Atzmon, Basri Ronen, Yaron Lipman, Advances in Neural Information Processing Systems (NeurIPS). 33Lior Yariv, Yoni Kasten, Dror Moran, Meirav Galun, Matan Atzmon, Basri Ronen, and Yaron Lipman. Multiview neu- ral surface reconstruction by disentangling geometry and ap- pearance. In Advances in Neural Information Processing Systems (NeurIPS), volume 33, pages 2492-2502, 2020.\n\niNeRF: Inverting neural radiance fields for pose estimation. L Yen-Chen, P Florence, J T Barron, A Rodriguez, P Isola, T Lin, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 2021L. Yen-Chen, P. Florence, J. T. Barron, A. Rodriguez, P. Isola, and T. Lin. iNeRF: Inverting neural radiance fields for pose estimation. In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021.\n\nMonosdf: Exploring monocular geometric cues for neural implicit surface reconstruction. Zehao Yu, Songyou Peng, Michael Niemeyer, Torsten Sattler, Andreas Geiger, Advances in Neural Information Processing Systems (NeurIPS). 2022Zehao Yu, Songyou Peng, Michael Niemeyer, Torsten Sat- tler, and Andreas Geiger. Monosdf: Exploring monocu- lar geometric cues for neural implicit surface reconstruc- tion. Advances in Neural Information Processing Systems (NeurIPS), 2022.\n\nK Zhang, G Riegler, N Snavely, V Koltun, NERF++: Analyzing and improving neural radiance fields. K. Zhang, G. Riegler, N. Snavely, and V. Koltun. NERF++: Analyzing and improving neural radiance fields. 2020.\n\nThe unreasonable effectiveness of deep features as a perceptual metric. Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, Oliver Wang, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shecht- man, and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. In Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pages 586-595, 2018.\n\nScenecode: Monocular dense semantic reconstruction using learned encoded scene representations. Shuaifeng Zhi, Michael Bloesch, Stefan Leutenegger, Andrew J Davison, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Shuaifeng Zhi, Michael Bloesch, Stefan Leutenegger, and Andrew J Davison. Scenecode: Monocular dense semantic reconstruction using learned encoded scene representations. In Proc. IEEE Conf. on Computer Vision and Pattern Recog- nition (CVPR), pages 11776-11785, 2019.\n\nDeeptam: Deep tracking and mapping. Huizhong Zhou, Benjamin Ummenhofer, Thomas Brox, Proc. of the European Conf. on Computer Vision (ECCV). of the European Conf. on Computer Vision (ECCV)Huizhong Zhou, Benjamin Ummenhofer, and Thomas Brox. Deeptam: Deep tracking and mapping. In Proc. of the Eu- ropean Conf. on Computer Vision (ECCV), pages 822-838, 2018.\n\nNice-slam: Neural implicit scalable encoding for slam. Zihan Zhu, Songyou Peng, Viktor Larsson, Weiwei Xu, Hujun Bao, Zhaopeng Cui, Martin R Oswald, Marc Pollefeys, Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Zihan Zhu, Songyou Peng, Viktor Larsson, Weiwei Xu, Hu- jun Bao, Zhaopeng Cui, Martin R. Oswald, and Marc Polle- feys. Nice-slam: Neural implicit scalable encoding for slam. In Proc. IEEE Conf. on Computer Vision and Pattern Recog- nition (CVPR), pages 12786-12796, 2022.\n", "annotations": {"author": "[{\"end\":143,\"start\":133},{\"end\":195,\"start\":144},{\"end\":229,\"start\":196},{\"end\":289,\"start\":230},{\"end\":332,\"start\":290},{\"end\":403,\"start\":333},{\"end\":419,\"start\":404},{\"end\":431,\"start\":420}]", "publisher": null, "author_last_name": "[{\"end\":142,\"start\":139},{\"end\":156,\"start\":152},{\"end\":210,\"start\":203},{\"end\":242,\"start\":239},{\"end\":305,\"start\":299},{\"end\":347,\"start\":341},{\"end\":418,\"start\":409},{\"end\":430,\"start\":424}]", "author_first_name": "[{\"end\":138,\"start\":133},{\"end\":151,\"start\":144},{\"end\":202,\"start\":196},{\"end\":238,\"start\":230},{\"end\":296,\"start\":290},{\"end\":298,\"start\":297},{\"end\":340,\"start\":333},{\"end\":408,\"start\":404},{\"end\":423,\"start\":420}]", "author_affiliation": "[{\"end\":194,\"start\":158},{\"end\":228,\"start\":212},{\"end\":288,\"start\":244},{\"end\":331,\"start\":307},{\"end\":402,\"start\":349}]", "title": "[{\"end\":130,\"start\":1},{\"end\":561,\"start\":432}]", "venue": null, "abstract": "[{\"end\":2008,\"start\":563}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b33\"},\"end\":2265,\"start\":2261},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":2268,\"start\":2265},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":2271,\"start\":2268},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":2274,\"start\":2271},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":2277,\"start\":2274},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2648,\"start\":2645},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2650,\"start\":2648},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":2653,\"start\":2650},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":2973,\"start\":2969},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":3081,\"start\":3077},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":3225,\"start\":3221},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":3369,\"start\":3365},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3372,\"start\":3369},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3375,\"start\":3372},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3378,\"start\":3375},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3381,\"start\":3378},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3384,\"start\":3381},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3670,\"start\":3666},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3672,\"start\":3670},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":3890,\"start\":3886},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3893,\"start\":3890},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6793,\"start\":6789},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":6796,\"start\":6793},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6799,\"start\":6796},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6802,\"start\":6799},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":7160,\"start\":7156},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":7193,\"start\":7189},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":7196,\"start\":7193},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":7199,\"start\":7196},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7201,\"start\":7199},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":7204,\"start\":7201},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7206,\"start\":7204},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":7209,\"start\":7206},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":7212,\"start\":7209},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":7215,\"start\":7212},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7218,\"start\":7215},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":7381,\"start\":7377},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7384,\"start\":7381},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7434,\"start\":7431},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7437,\"start\":7434},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":7440,\"start\":7437},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":7443,\"start\":7440},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":7857,\"start\":7853},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7969,\"start\":7965},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7971,\"start\":7969},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7974,\"start\":7971},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":7977,\"start\":7974},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7980,\"start\":7977},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":7983,\"start\":7980},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":7986,\"start\":7983},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8009,\"start\":8005},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8012,\"start\":8009},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8015,\"start\":8012},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8042,\"start\":8038},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":8045,\"start\":8042},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":8048,\"start\":8045},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8051,\"start\":8048},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":8054,\"start\":8051},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":8115,\"start\":8111},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8118,\"start\":8115},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":8121,\"start\":8118},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8123,\"start\":8121},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8125,\"start\":8123},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8127,\"start\":8125},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8295,\"start\":8292},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":8298,\"start\":8295},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":8529,\"start\":8525},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":8548,\"start\":8544},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":12647,\"start\":12643},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12650,\"start\":12647},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":12674,\"start\":12670},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12701,\"start\":12697},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":12742,\"start\":12738},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12745,\"start\":12742},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":13904,\"start\":13903},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":14862,\"start\":14858},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":14865,\"start\":14862},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":14924,\"start\":14920},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":14927,\"start\":14924},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":14930,\"start\":14927},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":15419,\"start\":15416},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":15422,\"start\":15419},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":15425,\"start\":15422},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":15428,\"start\":15425},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":15580,\"start\":15576},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":16638,\"start\":16634},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":17237,\"start\":17233},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":17240,\"start\":17237},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":17325,\"start\":17321},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":17328,\"start\":17325},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":17331,\"start\":17328},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":17334,\"start\":17331},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":17361,\"start\":17357},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":17364,\"start\":17361},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":17778,\"start\":17774},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":17992,\"start\":17988},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":18790,\"start\":18786},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":21456,\"start\":21452},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":22169,\"start\":22165},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":22323,\"start\":22319},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":22341,\"start\":22337},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":22595,\"start\":22591},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":22598,\"start\":22595},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":22812,\"start\":22808},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":23121,\"start\":23117},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":23212,\"start\":23208},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23351,\"start\":23347},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":23882,\"start\":23878},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":26460,\"start\":26456},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":26463,\"start\":26460},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":26466,\"start\":26463},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":26603,\"start\":26599},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":26772,\"start\":26768},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":27133,\"start\":27129},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":27303,\"start\":27299},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":27524,\"start\":27520},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":27544,\"start\":27540},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":27580,\"start\":27576},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":27638,\"start\":27634},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":28087,\"start\":28083},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":28154,\"start\":28150},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":28368,\"start\":28364},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":28402,\"start\":28398},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":28417,\"start\":28413},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":28814,\"start\":28810},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":29008,\"start\":29004},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":30006,\"start\":30002},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":30906,\"start\":30902},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":33427,\"start\":33423},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":33764,\"start\":33760},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":33767,\"start\":33764},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":33770,\"start\":33767},{\"end\":34190,\"start\":34187},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":35269,\"start\":35265},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":35895,\"start\":35891}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":35474,\"start\":35186},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":35596,\"start\":35475},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":35831,\"start\":35597},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":35948,\"start\":35832},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":36840,\"start\":35949},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":37038,\"start\":36841}]", "paragraph": "[{\"end\":2887,\"start\":2024},{\"end\":3530,\"start\":2889},{\"end\":4153,\"start\":3532},{\"end\":4297,\"start\":4155},{\"end\":4955,\"start\":4299},{\"end\":6020,\"start\":4957},{\"end\":6070,\"start\":6022},{\"end\":6252,\"start\":6072},{\"end\":6449,\"start\":6254},{\"end\":6626,\"start\":6451},{\"end\":7791,\"start\":6643},{\"end\":8746,\"start\":7793},{\"end\":11871,\"start\":11845},{\"end\":11901,\"start\":11890},{\"end\":12369,\"start\":11909},{\"end\":13264,\"start\":12371},{\"end\":13945,\"start\":13275},{\"end\":14151,\"start\":13994},{\"end\":14751,\"start\":14153},{\"end\":15074,\"start\":14807},{\"end\":15627,\"start\":15076},{\"end\":16078,\"start\":15685},{\"end\":16198,\"start\":16129},{\"end\":16348,\"start\":16200},{\"end\":17006,\"start\":16372},{\"end\":17241,\"start\":17072},{\"end\":17827,\"start\":17262},{\"end\":18044,\"start\":17896},{\"end\":18401,\"start\":18121},{\"end\":18774,\"start\":18448},{\"end\":19298,\"start\":18776},{\"end\":19618,\"start\":19300},{\"end\":19887,\"start\":19657},{\"end\":20456,\"start\":19929},{\"end\":20636,\"start\":20458},{\"end\":20776,\"start\":20670},{\"end\":21219,\"start\":20798},{\"end\":21640,\"start\":21267},{\"end\":22047,\"start\":21642},{\"end\":22170,\"start\":22101},{\"end\":22599,\"start\":22196},{\"end\":22847,\"start\":22640},{\"end\":23240,\"start\":22849},{\"end\":23389,\"start\":23296},{\"end\":23488,\"start\":23429},{\"end\":23666,\"start\":23490},{\"end\":23910,\"start\":23668},{\"end\":24681,\"start\":23994},{\"end\":25003,\"start\":24683},{\"end\":25479,\"start\":25021},{\"end\":26801,\"start\":25481},{\"end\":27066,\"start\":26817},{\"end\":27435,\"start\":27080},{\"end\":27916,\"start\":27437},{\"end\":28454,\"start\":27918},{\"end\":28658,\"start\":28456},{\"end\":28867,\"start\":28686},{\"end\":28920,\"start\":28869},{\"end\":30206,\"start\":28982},{\"end\":30877,\"start\":30222},{\"end\":31810,\"start\":30879},{\"end\":32039,\"start\":31843},{\"end\":32557,\"start\":32041},{\"end\":33231,\"start\":32559},{\"end\":33691,\"start\":33233},{\"end\":34446,\"start\":33693},{\"end\":34869,\"start\":34462},{\"end\":35185,\"start\":34871}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11769,\"start\":8792},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14806,\"start\":14752},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15684,\"start\":15628},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16128,\"start\":16079},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16371,\"start\":16349},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17071,\"start\":17007},{\"attributes\":{\"id\":\"formula_6\"},\"end\":17895,\"start\":17828},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18120,\"start\":18045},{\"attributes\":{\"id\":\"formula_8\"},\"end\":18447,\"start\":18402},{\"attributes\":{\"id\":\"formula_9\"},\"end\":19656,\"start\":19619},{\"attributes\":{\"id\":\"formula_10\"},\"end\":20669,\"start\":20637},{\"attributes\":{\"id\":\"formula_11\"},\"end\":21266,\"start\":21220},{\"attributes\":{\"id\":\"formula_12\"},\"end\":22100,\"start\":22048},{\"attributes\":{\"id\":\"formula_13\"},\"end\":22639,\"start\":22600},{\"attributes\":{\"id\":\"formula_14\"},\"end\":23295,\"start\":23241},{\"attributes\":{\"id\":\"formula_15\"},\"end\":23428,\"start\":23390},{\"attributes\":{\"id\":\"formula_16\"},\"end\":23993,\"start\":23911}]", "table_ref": "[{\"end\":29081,\"start\":29074},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":30284,\"start\":30277},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":31330,\"start\":31323},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":32152,\"start\":32145},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":32596,\"start\":32589},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":33535,\"start\":33528}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2022,\"start\":2010},{\"attributes\":{\"n\":\"2.\"},\"end\":6641,\"start\":6629},{\"end\":8765,\"start\":8749},{\"end\":8776,\"start\":8768},{\"end\":8791,\"start\":8779},{\"end\":11794,\"start\":11771},{\"end\":11807,\"start\":11797},{\"end\":11813,\"start\":11810},{\"end\":11843,\"start\":11816},{\"end\":11888,\"start\":11874},{\"end\":11907,\"start\":11904},{\"attributes\":{\"n\":\"3.\"},\"end\":13273,\"start\":13267},{\"attributes\":{\"n\":\"3.1.\"},\"end\":13992,\"start\":13948},{\"attributes\":{\"n\":\"3.2.\"},\"end\":17260,\"start\":17244},{\"attributes\":{\"n\":\"3.3.\"},\"end\":19927,\"start\":19890},{\"end\":20796,\"start\":20779},{\"end\":22194,\"start\":22173},{\"attributes\":{\"n\":\"3.4.\"},\"end\":25019,\"start\":25006},{\"attributes\":{\"n\":\"4.\"},\"end\":26815,\"start\":26804},{\"end\":27078,\"start\":27069},{\"end\":28672,\"start\":28661},{\"end\":28684,\"start\":28675},{\"end\":28934,\"start\":28923},{\"attributes\":{\"n\":\"4.1.\"},\"end\":28980,\"start\":28937},{\"end\":30220,\"start\":30209},{\"end\":31824,\"start\":31813},{\"attributes\":{\"n\":\"4.2.\"},\"end\":31841,\"start\":31827},{\"attributes\":{\"n\":\"5.\"},\"end\":34460,\"start\":34449},{\"end\":35207,\"start\":35187},{\"end\":35485,\"start\":35476},{\"end\":35607,\"start\":35598},{\"end\":35842,\"start\":35833},{\"end\":36851,\"start\":36842}]", "table": "[{\"end\":35596,\"start\":35493},{\"end\":35831,\"start\":35614},{\"end\":36840,\"start\":36208}]", "figure_caption": "[{\"end\":35474,\"start\":35210},{\"end\":35493,\"start\":35487},{\"end\":35614,\"start\":35609},{\"end\":35948,\"start\":35844},{\"end\":36208,\"start\":35951},{\"end\":37038,\"start\":36853}]", "figure_ref": "[{\"end\":11937,\"start\":11929},{\"end\":13334,\"start\":13328},{\"end\":28759,\"start\":28751},{\"end\":29345,\"start\":29339},{\"end\":30295,\"start\":30289},{\"end\":31183,\"start\":31177},{\"end\":34062,\"start\":34056},{\"end\":34276,\"start\":34268}]", "bib_author_first_name": "[{\"end\":37426,\"start\":37419},{\"end\":37438,\"start\":37433},{\"end\":37450,\"start\":37445},{\"end\":37463,\"start\":37455},{\"end\":37476,\"start\":37470},{\"end\":37483,\"start\":37477},{\"end\":37864,\"start\":37857},{\"end\":37877,\"start\":37874},{\"end\":37896,\"start\":37890},{\"end\":37910,\"start\":37904},{\"end\":37930,\"start\":37924},{\"end\":37932,\"start\":37931},{\"end\":38422,\"start\":38418},{\"end\":38436,\"start\":38430},{\"end\":38453,\"start\":38444},{\"end\":38467,\"start\":38460},{\"end\":38480,\"start\":38474},{\"end\":38816,\"start\":38810},{\"end\":38826,\"start\":38823},{\"end\":39229,\"start\":39223},{\"end\":39245,\"start\":39239},{\"end\":39262,\"start\":39256},{\"end\":39748,\"start\":39741},{\"end\":39760,\"start\":39755},{\"end\":39778,\"start\":39773},{\"end\":40257,\"start\":40249},{\"end\":40273,\"start\":40265},{\"end\":40289,\"start\":40281},{\"end\":40305,\"start\":40295},{\"end\":40319,\"start\":40311},{\"end\":40333,\"start\":40325},{\"end\":40347,\"start\":40339},{\"end\":40361,\"start\":40354},{\"end\":40377,\"start\":40368},{\"end\":40762,\"start\":40756},{\"end\":41141,\"start\":41138},{\"end\":41161,\"start\":41154},{\"end\":41177,\"start\":41171},{\"end\":41193,\"start\":41185},{\"end\":41540,\"start\":41534},{\"end\":41554,\"start\":41546},{\"end\":41571,\"start\":41564},{\"end\":41590,\"start\":41583},{\"end\":41607,\"start\":41598},{\"end\":41948,\"start\":41940},{\"end\":41966,\"start\":41957},{\"end\":41987,\"start\":41975},{\"end\":42002,\"start\":41996},{\"end\":42019,\"start\":42012},{\"end\":42504,\"start\":42499},{\"end\":42524,\"start\":42515},{\"end\":42538,\"start\":42530},{\"end\":42550,\"start\":42546},{\"end\":42960,\"start\":42955},{\"end\":42975,\"start\":42968},{\"end\":42990,\"start\":42984},{\"end\":43397,\"start\":43393},{\"end\":43409,\"start\":43405},{\"end\":43773,\"start\":43766},{\"end\":43957,\"start\":43952},{\"end\":43972,\"start\":43965},{\"end\":43984,\"start\":43978},{\"end\":44001,\"start\":43994},{\"end\":44017,\"start\":44009},{\"end\":44033,\"start\":44027},{\"end\":44425,\"start\":44418},{\"end\":44457,\"start\":44449},{\"end\":44852,\"start\":44847},{\"end\":44865,\"start\":44860},{\"end\":45220,\"start\":45215},{\"end\":45234,\"start\":45231},{\"end\":45247,\"start\":45241},{\"end\":45262,\"start\":45256},{\"end\":45617,\"start\":45610},{\"end\":45633,\"start\":45628},{\"end\":45649,\"start\":45644},{\"end\":45668,\"start\":45661},{\"end\":45685,\"start\":45679},{\"end\":45699,\"start\":45693},{\"end\":45716,\"start\":45709},{\"end\":46139,\"start\":46135},{\"end\":46152,\"start\":46144},{\"end\":46163,\"start\":46157},{\"end\":46175,\"start\":46170},{\"end\":46188,\"start\":46182},{\"end\":46199,\"start\":46195},{\"end\":46583,\"start\":46582},{\"end\":46590,\"start\":46589},{\"end\":46596,\"start\":46595},{\"end\":46608,\"start\":46607},{\"end\":46963,\"start\":46957},{\"end\":46978,\"start\":46972},{\"end\":46992,\"start\":46987},{\"end\":47013,\"start\":47006},{\"end\":47401,\"start\":47395},{\"end\":47415,\"start\":47409},{\"end\":47696,\"start\":47689},{\"end\":47707,\"start\":47702},{\"end\":47722,\"start\":47715},{\"end\":47734,\"start\":47729},{\"end\":47744,\"start\":47740},{\"end\":47764,\"start\":47756},{\"end\":48241,\"start\":48240},{\"end\":48257,\"start\":48251},{\"end\":48259,\"start\":48258},{\"end\":48544,\"start\":48540},{\"end\":48563,\"start\":48556},{\"end\":48580,\"start\":48573},{\"end\":48600,\"start\":48591},{\"end\":48617,\"start\":48610},{\"end\":49082,\"start\":49079},{\"end\":49096,\"start\":49095},{\"end\":49112,\"start\":49105},{\"end\":49133,\"start\":49125},{\"end\":49135,\"start\":49134},{\"end\":49148,\"start\":49144},{\"end\":49160,\"start\":49157},{\"end\":49619,\"start\":49613},{\"end\":49632,\"start\":49626},{\"end\":49643,\"start\":49637},{\"end\":49932,\"start\":49926},{\"end\":49945,\"start\":49941},{\"end\":49962,\"start\":49953},{\"end\":49980,\"start\":49971},{\"end\":50264,\"start\":50260},{\"end\":50295,\"start\":50276},{\"end\":50309,\"start\":50305},{\"end\":50311,\"start\":50310},{\"end\":50613,\"start\":50609},{\"end\":50625,\"start\":50619},{\"end\":50632,\"start\":50628},{\"end\":50634,\"start\":50633},{\"end\":50910,\"start\":50909},{\"end\":50912,\"start\":50911},{\"end\":50924,\"start\":50923},{\"end\":50933,\"start\":50932},{\"end\":50945,\"start\":50944},{\"end\":50958,\"start\":50957},{\"end\":50965,\"start\":50964},{\"end\":50967,\"start\":50966},{\"end\":50978,\"start\":50977},{\"end\":50986,\"start\":50985},{\"end\":50997,\"start\":50996},{\"end\":51007,\"start\":51006},{\"end\":51403,\"start\":51402},{\"end\":51424,\"start\":51423},{\"end\":51441,\"start\":51433},{\"end\":51895,\"start\":51894},{\"end\":51907,\"start\":51906},{\"end\":51920,\"start\":51919},{\"end\":51931,\"start\":51930},{\"end\":52364,\"start\":52356},{\"end\":52381,\"start\":52374},{\"end\":52400,\"start\":52393},{\"end\":52412,\"start\":52408},{\"end\":52729,\"start\":52722},{\"end\":52746,\"start\":52739},{\"end\":52760,\"start\":52753},{\"end\":53205,\"start\":53199},{\"end\":53225,\"start\":53216},{\"end\":53240,\"start\":53236},{\"end\":53255,\"start\":53250},{\"end\":53271,\"start\":53266},{\"end\":53291,\"start\":53284},{\"end\":53314,\"start\":53307},{\"end\":53681,\"start\":53671},{\"end\":53693,\"start\":53688},{\"end\":53710,\"start\":53704},{\"end\":53726,\"start\":53719},{\"end\":53743,\"start\":53737},{\"end\":54206,\"start\":54199},{\"end\":54218,\"start\":54213},{\"end\":54230,\"start\":54226},{\"end\":54244,\"start\":54237},{\"end\":54259,\"start\":54255},{\"end\":54278,\"start\":54271},{\"end\":54619,\"start\":54612},{\"end\":54633,\"start\":54626},{\"end\":54648,\"start\":54644},{\"end\":54664,\"start\":54660},{\"end\":54683,\"start\":54676},{\"end\":55113,\"start\":55109},{\"end\":55128,\"start\":55122},{\"end\":55144,\"start\":55139},{\"end\":55159,\"start\":55153},{\"end\":55178,\"start\":55171},{\"end\":55589,\"start\":55580},{\"end\":55605,\"start\":55598},{\"end\":55616,\"start\":55612},{\"end\":55630,\"start\":55623},{\"end\":55998,\"start\":55992},{\"end\":56009,\"start\":56008},{\"end\":56020,\"start\":56016},{\"end\":56335,\"start\":56334},{\"end\":56337,\"start\":56336},{\"end\":56352,\"start\":56351},{\"end\":56354,\"start\":56353},{\"end\":56689,\"start\":56683},{\"end\":56705,\"start\":56698},{\"end\":56719,\"start\":56715},{\"end\":57201,\"start\":57196},{\"end\":57214,\"start\":57211},{\"end\":57235,\"start\":57224},{\"end\":57249,\"start\":57242},{\"end\":57264,\"start\":57257},{\"end\":57282,\"start\":57276},{\"end\":57727,\"start\":57726},{\"end\":57737,\"start\":57736},{\"end\":57747,\"start\":57746},{\"end\":57753,\"start\":57752},{\"end\":57761,\"start\":57760},{\"end\":57772,\"start\":57771},{\"end\":57781,\"start\":57780},{\"end\":57783,\"start\":57782},{\"end\":57792,\"start\":57791},{\"end\":57805,\"start\":57804},{\"end\":57807,\"start\":57806},{\"end\":57811,\"start\":57810},{\"end\":57820,\"start\":57819},{\"end\":57832,\"start\":57831},{\"end\":57839,\"start\":57838},{\"end\":57848,\"start\":57847},{\"end\":57855,\"start\":57854},{\"end\":57862,\"start\":57861},{\"end\":57869,\"start\":57868},{\"end\":57876,\"start\":57875},{\"end\":57884,\"start\":57883},{\"end\":57894,\"start\":57893},{\"end\":57905,\"start\":57904},{\"end\":57919,\"start\":57918},{\"end\":57931,\"start\":57930},{\"end\":57944,\"start\":57943},{\"end\":57953,\"start\":57952},{\"end\":57962,\"start\":57961},{\"end\":57964,\"start\":57963},{\"end\":57976,\"start\":57975},{\"end\":57978,\"start\":57977},{\"end\":57987,\"start\":57986},{\"end\":57998,\"start\":57997},{\"end\":58011,\"start\":58010},{\"end\":58599,\"start\":58593},{\"end\":58614,\"start\":58607},{\"end\":58631,\"start\":58626},{\"end\":58647,\"start\":58640},{\"end\":58663,\"start\":58657},{\"end\":59039,\"start\":59034},{\"end\":59053,\"start\":59047},{\"end\":59065,\"start\":59059},{\"end\":59081,\"start\":59073},{\"end\":59553,\"start\":59548},{\"end\":59568,\"start\":59561},{\"end\":59581,\"start\":59575},{\"end\":59982,\"start\":59976},{\"end\":59997,\"start\":59993},{\"end\":60015,\"start\":60008},{\"end\":60028,\"start\":60021},{\"end\":60043,\"start\":60036},{\"end\":60055,\"start\":60050},{\"end\":60076,\"start\":60072},{\"end\":60093,\"start\":60087},{\"end\":60108,\"start\":60103},{\"end\":60664,\"start\":60657},{\"end\":60679,\"start\":60673},{\"end\":60695,\"start\":60692},{\"end\":60712,\"start\":60708},{\"end\":60735,\"start\":60729},{\"end\":60753,\"start\":60746},{\"end\":60767,\"start\":60763},{\"end\":60789,\"start\":60781},{\"end\":60801,\"start\":60798},{\"end\":61240,\"start\":61231},{\"end\":61251,\"start\":61247},{\"end\":61614,\"start\":61607},{\"end\":61624,\"start\":61621},{\"end\":62018,\"start\":62011},{\"end\":62028,\"start\":62025},{\"end\":62348,\"start\":62340},{\"end\":62369,\"start\":62361},{\"end\":62381,\"start\":62376},{\"end\":62397,\"start\":62389},{\"end\":62409,\"start\":62405},{\"end\":62421,\"start\":62415},{\"end\":62441,\"start\":62435},{\"end\":62943,\"start\":62939},{\"end\":62957,\"start\":62950},{\"end\":62967,\"start\":62963},{\"end\":62982,\"start\":62973},{\"end\":62997,\"start\":62993},{\"end\":63013,\"start\":63006},{\"end\":63344,\"start\":63340},{\"end\":63355,\"start\":63351},{\"end\":63357,\"start\":63356},{\"end\":63366,\"start\":63365},{\"end\":63380,\"start\":63374},{\"end\":63645,\"start\":63644},{\"end\":63653,\"start\":63652},{\"end\":63659,\"start\":63658},{\"end\":63666,\"start\":63665},{\"end\":63674,\"start\":63673},{\"end\":63676,\"start\":63675},{\"end\":63993,\"start\":63987},{\"end\":64009,\"start\":64002},{\"end\":64024,\"start\":64017},{\"end\":64039,\"start\":64033},{\"end\":64056,\"start\":64052},{\"end\":64070,\"start\":64066},{\"end\":64422,\"start\":64416},{\"end\":64437,\"start\":64431},{\"end\":64457,\"start\":64451},{\"end\":64475,\"start\":64472},{\"end\":64491,\"start\":64485},{\"end\":64769,\"start\":64762},{\"end\":64780,\"start\":64774},{\"end\":64790,\"start\":64785},{\"end\":64801,\"start\":64796},{\"end\":64813,\"start\":64807},{\"end\":64826,\"start\":64821},{\"end\":64842,\"start\":64836},{\"end\":65124,\"start\":65118},{\"end\":65136,\"start\":65130},{\"end\":65155,\"start\":65147},{\"end\":65165,\"start\":65163},{\"end\":65180,\"start\":65174},{\"end\":65192,\"start\":65186},{\"end\":65207,\"start\":65199},{\"end\":65222,\"start\":65217},{\"end\":65239,\"start\":65232},{\"end\":65257,\"start\":65250},{\"end\":65647,\"start\":65641},{\"end\":65656,\"start\":65652},{\"end\":65671,\"start\":65664},{\"end\":65682,\"start\":65677},{\"end\":65703,\"start\":65696},{\"end\":66160,\"start\":66153},{\"end\":66170,\"start\":66167},{\"end\":66182,\"start\":66175},{\"end\":66195,\"start\":66189},{\"end\":66208,\"start\":66202},{\"end\":66221,\"start\":66214},{\"end\":66620,\"start\":66616},{\"end\":66634,\"start\":66628},{\"end\":66643,\"start\":66639},{\"end\":66657,\"start\":66652},{\"end\":67018,\"start\":67014},{\"end\":67030,\"start\":67026},{\"end\":67043,\"start\":67039},{\"end\":67057,\"start\":67051},{\"end\":67070,\"start\":67065},{\"end\":67084,\"start\":67079},{\"end\":67097,\"start\":67092},{\"end\":67512,\"start\":67511},{\"end\":67524,\"start\":67523},{\"end\":67536,\"start\":67535},{\"end\":67538,\"start\":67537},{\"end\":67548,\"start\":67547},{\"end\":67561,\"start\":67560},{\"end\":67570,\"start\":67569},{\"end\":67972,\"start\":67967},{\"end\":67984,\"start\":67977},{\"end\":67998,\"start\":67991},{\"end\":68016,\"start\":68009},{\"end\":68033,\"start\":68026},{\"end\":68349,\"start\":68348},{\"end\":68358,\"start\":68357},{\"end\":68369,\"start\":68368},{\"end\":68380,\"start\":68379},{\"end\":68636,\"start\":68629},{\"end\":68651,\"start\":68644},{\"end\":68665,\"start\":68659},{\"end\":68667,\"start\":68666},{\"end\":68678,\"start\":68675},{\"end\":68696,\"start\":68690},{\"end\":69181,\"start\":69172},{\"end\":69194,\"start\":69187},{\"end\":69210,\"start\":69204},{\"end\":69232,\"start\":69224},{\"end\":69683,\"start\":69675},{\"end\":69698,\"start\":69690},{\"end\":69717,\"start\":69711},{\"end\":70057,\"start\":70052},{\"end\":70070,\"start\":70063},{\"end\":70083,\"start\":70077},{\"end\":70099,\"start\":70093},{\"end\":70109,\"start\":70104},{\"end\":70123,\"start\":70115},{\"end\":70135,\"start\":70129},{\"end\":70137,\"start\":70136},{\"end\":70150,\"start\":70146}]", "bib_author_last_name": "[{\"end\":37431,\"start\":37427},{\"end\":37443,\"start\":37439},{\"end\":37453,\"start\":37451},{\"end\":37468,\"start\":37464},{\"end\":37494,\"start\":37484},{\"end\":37872,\"start\":37865},{\"end\":37888,\"start\":37878},{\"end\":37902,\"start\":37897},{\"end\":37922,\"start\":37911},{\"end\":37940,\"start\":37933},{\"end\":38428,\"start\":38423},{\"end\":38442,\"start\":38437},{\"end\":38458,\"start\":38454},{\"end\":38472,\"start\":38468},{\"end\":38488,\"start\":38481},{\"end\":38821,\"start\":38817},{\"end\":38832,\"start\":38827},{\"end\":39237,\"start\":39230},{\"end\":39254,\"start\":39246},{\"end\":39272,\"start\":39263},{\"end\":39739,\"start\":39730},{\"end\":39753,\"start\":39749},{\"end\":39771,\"start\":39761},{\"end\":39786,\"start\":39779},{\"end\":39793,\"start\":39788},{\"end\":40263,\"start\":40258},{\"end\":40279,\"start\":40274},{\"end\":40293,\"start\":40290},{\"end\":40309,\"start\":40306},{\"end\":40323,\"start\":40320},{\"end\":40337,\"start\":40334},{\"end\":40352,\"start\":40348},{\"end\":40366,\"start\":40362},{\"end\":40381,\"start\":40378},{\"end\":40768,\"start\":40763},{\"end\":41152,\"start\":41142},{\"end\":41169,\"start\":41162},{\"end\":41183,\"start\":41178},{\"end\":41201,\"start\":41194},{\"end\":41544,\"start\":41541},{\"end\":41562,\"start\":41555},{\"end\":41581,\"start\":41572},{\"end\":41596,\"start\":41591},{\"end\":41616,\"start\":41608},{\"end\":41955,\"start\":41949},{\"end\":41973,\"start\":41967},{\"end\":41994,\"start\":41988},{\"end\":42010,\"start\":42003},{\"end\":42025,\"start\":42020},{\"end\":42513,\"start\":42505},{\"end\":42528,\"start\":42525},{\"end\":42544,\"start\":42539},{\"end\":42556,\"start\":42551},{\"end\":42966,\"start\":42961},{\"end\":42982,\"start\":42976},{\"end\":42998,\"start\":42991},{\"end\":43256,\"start\":43232},{\"end\":43270,\"start\":43258},{\"end\":43278,\"start\":43272},{\"end\":43403,\"start\":43398},{\"end\":43415,\"start\":43410},{\"end\":43779,\"start\":43774},{\"end\":43963,\"start\":43958},{\"end\":43976,\"start\":43973},{\"end\":43992,\"start\":43985},{\"end\":44007,\"start\":44002},{\"end\":44025,\"start\":44018},{\"end\":44044,\"start\":44034},{\"end\":44447,\"start\":44426},{\"end\":44463,\"start\":44458},{\"end\":44472,\"start\":44465},{\"end\":44479,\"start\":44474},{\"end\":44858,\"start\":44853},{\"end\":44872,\"start\":44866},{\"end\":45229,\"start\":45221},{\"end\":45239,\"start\":45235},{\"end\":45254,\"start\":45248},{\"end\":45270,\"start\":45263},{\"end\":45626,\"start\":45618},{\"end\":45642,\"start\":45634},{\"end\":45659,\"start\":45650},{\"end\":45677,\"start\":45669},{\"end\":45691,\"start\":45686},{\"end\":45707,\"start\":45700},{\"end\":45728,\"start\":45717},{\"end\":46142,\"start\":46140},{\"end\":46155,\"start\":46153},{\"end\":46168,\"start\":46164},{\"end\":46180,\"start\":46176},{\"end\":46193,\"start\":46189},{\"end\":46203,\"start\":46200},{\"end\":46587,\"start\":46584},{\"end\":46593,\"start\":46591},{\"end\":46605,\"start\":46597},{\"end\":46614,\"start\":46609},{\"end\":46970,\"start\":46964},{\"end\":46985,\"start\":46979},{\"end\":47004,\"start\":46993},{\"end\":47018,\"start\":47014},{\"end\":47407,\"start\":47402},{\"end\":47422,\"start\":47416},{\"end\":47700,\"start\":47697},{\"end\":47713,\"start\":47708},{\"end\":47727,\"start\":47723},{\"end\":47738,\"start\":47735},{\"end\":47754,\"start\":47745},{\"end\":47768,\"start\":47765},{\"end\":48249,\"start\":48242},{\"end\":48268,\"start\":48260},{\"end\":48275,\"start\":48270},{\"end\":48554,\"start\":48545},{\"end\":48571,\"start\":48564},{\"end\":48589,\"start\":48581},{\"end\":48608,\"start\":48601},{\"end\":48624,\"start\":48618},{\"end\":49093,\"start\":49083},{\"end\":49103,\"start\":49097},{\"end\":49123,\"start\":49113},{\"end\":49142,\"start\":49136},{\"end\":49155,\"start\":49149},{\"end\":49172,\"start\":49161},{\"end\":49176,\"start\":49174},{\"end\":49624,\"start\":49620},{\"end\":49635,\"start\":49633},{\"end\":49650,\"start\":49644},{\"end\":49939,\"start\":49933},{\"end\":49951,\"start\":49946},{\"end\":49969,\"start\":49963},{\"end\":49987,\"start\":49981},{\"end\":50274,\"start\":50265},{\"end\":50303,\"start\":50296},{\"end\":50318,\"start\":50312},{\"end\":50617,\"start\":50614},{\"end\":50641,\"start\":50635},{\"end\":50921,\"start\":50913},{\"end\":50930,\"start\":50925},{\"end\":50942,\"start\":50934},{\"end\":50955,\"start\":50946},{\"end\":50962,\"start\":50959},{\"end\":50975,\"start\":50968},{\"end\":50983,\"start\":50979},{\"end\":50994,\"start\":50987},{\"end\":51004,\"start\":50998},{\"end\":51018,\"start\":51008},{\"end\":51411,\"start\":51404},{\"end\":51421,\"start\":51413},{\"end\":51431,\"start\":51425},{\"end\":51451,\"start\":51442},{\"end\":51460,\"start\":51453},{\"end\":51904,\"start\":51896},{\"end\":51917,\"start\":51908},{\"end\":51928,\"start\":51921},{\"end\":51938,\"start\":51932},{\"end\":52372,\"start\":52365},{\"end\":52391,\"start\":52382},{\"end\":52406,\"start\":52401},{\"end\":52423,\"start\":52413},{\"end\":52737,\"start\":52730},{\"end\":52751,\"start\":52747},{\"end\":52767,\"start\":52761},{\"end\":53211,\"start\":53206},{\"end\":53231,\"start\":53226},{\"end\":53245,\"start\":53241},{\"end\":53261,\"start\":53256},{\"end\":53279,\"start\":53272},{\"end\":53302,\"start\":53292},{\"end\":53322,\"start\":53315},{\"end\":53686,\"start\":53682},{\"end\":53702,\"start\":53694},{\"end\":53717,\"start\":53711},{\"end\":53735,\"start\":53727},{\"end\":53753,\"start\":53744},{\"end\":54211,\"start\":54207},{\"end\":54224,\"start\":54219},{\"end\":54235,\"start\":54231},{\"end\":54253,\"start\":54245},{\"end\":54269,\"start\":54260},{\"end\":54285,\"start\":54279},{\"end\":54624,\"start\":54620},{\"end\":54642,\"start\":54634},{\"end\":54658,\"start\":54649},{\"end\":54674,\"start\":54665},{\"end\":54690,\"start\":54684},{\"end\":55120,\"start\":55114},{\"end\":55137,\"start\":55129},{\"end\":55151,\"start\":55145},{\"end\":55169,\"start\":55160},{\"end\":55185,\"start\":55179},{\"end\":55596,\"start\":55590},{\"end\":55610,\"start\":55606},{\"end\":55621,\"start\":55617},{\"end\":55637,\"start\":55631},{\"end\":56006,\"start\":55999},{\"end\":56014,\"start\":56010},{\"end\":56028,\"start\":56021},{\"end\":56037,\"start\":56030},{\"end\":56349,\"start\":56338},{\"end\":56360,\"start\":56355},{\"end\":56696,\"start\":56690},{\"end\":56713,\"start\":56706},{\"end\":56729,\"start\":56720},{\"end\":57209,\"start\":57202},{\"end\":57222,\"start\":57215},{\"end\":57240,\"start\":57236},{\"end\":57255,\"start\":57250},{\"end\":57274,\"start\":57265},{\"end\":57293,\"start\":57283},{\"end\":57734,\"start\":57728},{\"end\":57744,\"start\":57738},{\"end\":57750,\"start\":57748},{\"end\":57758,\"start\":57754},{\"end\":57769,\"start\":57762},{\"end\":57778,\"start\":57773},{\"end\":57789,\"start\":57784},{\"end\":57802,\"start\":57793},{\"end\":57817,\"start\":57812},{\"end\":57829,\"start\":57821},{\"end\":57836,\"start\":57833},{\"end\":57845,\"start\":57840},{\"end\":57852,\"start\":57849},{\"end\":57859,\"start\":57856},{\"end\":57866,\"start\":57863},{\"end\":57873,\"start\":57870},{\"end\":57881,\"start\":57877},{\"end\":57891,\"start\":57885},{\"end\":57902,\"start\":57895},{\"end\":57916,\"start\":57906},{\"end\":57928,\"start\":57920},{\"end\":57941,\"start\":57932},{\"end\":57950,\"start\":57945},{\"end\":57959,\"start\":57954},{\"end\":57973,\"start\":57965},{\"end\":57984,\"start\":57979},{\"end\":57995,\"start\":57988},{\"end\":58008,\"start\":57999},{\"end\":58020,\"start\":58012},{\"end\":58605,\"start\":58600},{\"end\":58624,\"start\":58615},{\"end\":58638,\"start\":58632},{\"end\":58655,\"start\":58648},{\"end\":58671,\"start\":58664},{\"end\":59045,\"start\":59040},{\"end\":59057,\"start\":59054},{\"end\":59071,\"start\":59066},{\"end\":59089,\"start\":59082},{\"end\":59559,\"start\":59554},{\"end\":59573,\"start\":59569},{\"end\":59589,\"start\":59582},{\"end\":59991,\"start\":59983},{\"end\":60006,\"start\":59998},{\"end\":60019,\"start\":60016},{\"end\":60034,\"start\":60029},{\"end\":60048,\"start\":60044},{\"end\":60070,\"start\":60056},{\"end\":60085,\"start\":60077},{\"end\":60101,\"start\":60094},{\"end\":60115,\"start\":60109},{\"end\":60671,\"start\":60665},{\"end\":60690,\"start\":60680},{\"end\":60706,\"start\":60696},{\"end\":60727,\"start\":60713},{\"end\":60744,\"start\":60736},{\"end\":60761,\"start\":60754},{\"end\":60779,\"start\":60768},{\"end\":60796,\"start\":60790},{\"end\":60804,\"start\":60802},{\"end\":61245,\"start\":61241},{\"end\":61255,\"start\":61252},{\"end\":61619,\"start\":61615},{\"end\":61629,\"start\":61625},{\"end\":62023,\"start\":62019},{\"end\":62033,\"start\":62029},{\"end\":62359,\"start\":62349},{\"end\":62374,\"start\":62370},{\"end\":62387,\"start\":62382},{\"end\":62403,\"start\":62398},{\"end\":62413,\"start\":62410},{\"end\":62433,\"start\":62422},{\"end\":62446,\"start\":62442},{\"end\":62948,\"start\":62944},{\"end\":62961,\"start\":62958},{\"end\":62971,\"start\":62968},{\"end\":62991,\"start\":62983},{\"end\":63004,\"start\":62998},{\"end\":63018,\"start\":63014},{\"end\":63349,\"start\":63345},{\"end\":63363,\"start\":63358},{\"end\":63372,\"start\":63367},{\"end\":63387,\"start\":63381},{\"end\":63399,\"start\":63389},{\"end\":63650,\"start\":63646},{\"end\":63656,\"start\":63654},{\"end\":63663,\"start\":63660},{\"end\":63671,\"start\":63667},{\"end\":63687,\"start\":63677},{\"end\":64000,\"start\":63994},{\"end\":64015,\"start\":64010},{\"end\":64031,\"start\":64025},{\"end\":64050,\"start\":64040},{\"end\":64064,\"start\":64057},{\"end\":64079,\"start\":64071},{\"end\":64429,\"start\":64423},{\"end\":64449,\"start\":64438},{\"end\":64470,\"start\":64458},{\"end\":64483,\"start\":64476},{\"end\":64499,\"start\":64492},{\"end\":64772,\"start\":64770},{\"end\":64783,\"start\":64781},{\"end\":64794,\"start\":64791},{\"end\":64805,\"start\":64802},{\"end\":64819,\"start\":64814},{\"end\":64834,\"start\":64827},{\"end\":64845,\"start\":64843},{\"end\":65128,\"start\":65125},{\"end\":65145,\"start\":65137},{\"end\":65161,\"start\":65156},{\"end\":65172,\"start\":65166},{\"end\":65184,\"start\":65181},{\"end\":65197,\"start\":65193},{\"end\":65215,\"start\":65208},{\"end\":65230,\"start\":65223},{\"end\":65248,\"start\":65240},{\"end\":65265,\"start\":65258},{\"end\":65650,\"start\":65648},{\"end\":65662,\"start\":65657},{\"end\":65675,\"start\":65672},{\"end\":65694,\"start\":65683},{\"end\":65707,\"start\":65704},{\"end\":65715,\"start\":65709},{\"end\":66165,\"start\":66161},{\"end\":66173,\"start\":66171},{\"end\":66187,\"start\":66183},{\"end\":66200,\"start\":66196},{\"end\":66212,\"start\":66209},{\"end\":66227,\"start\":66222},{\"end\":66626,\"start\":66621},{\"end\":66637,\"start\":66635},{\"end\":66650,\"start\":66644},{\"end\":66664,\"start\":66658},{\"end\":67024,\"start\":67019},{\"end\":67037,\"start\":67031},{\"end\":67049,\"start\":67044},{\"end\":67063,\"start\":67058},{\"end\":67077,\"start\":67071},{\"end\":67090,\"start\":67085},{\"end\":67104,\"start\":67098},{\"end\":67521,\"start\":67513},{\"end\":67533,\"start\":67525},{\"end\":67545,\"start\":67539},{\"end\":67558,\"start\":67549},{\"end\":67567,\"start\":67562},{\"end\":67574,\"start\":67571},{\"end\":67975,\"start\":67973},{\"end\":67989,\"start\":67985},{\"end\":68007,\"start\":67999},{\"end\":68024,\"start\":68017},{\"end\":68040,\"start\":68034},{\"end\":68355,\"start\":68350},{\"end\":68366,\"start\":68359},{\"end\":68377,\"start\":68370},{\"end\":68387,\"start\":68381},{\"end\":68642,\"start\":68637},{\"end\":68657,\"start\":68652},{\"end\":68673,\"start\":68668},{\"end\":68688,\"start\":68679},{\"end\":68701,\"start\":68697},{\"end\":69185,\"start\":69182},{\"end\":69202,\"start\":69195},{\"end\":69222,\"start\":69211},{\"end\":69240,\"start\":69233},{\"end\":69688,\"start\":69684},{\"end\":69709,\"start\":69699},{\"end\":69722,\"start\":69718},{\"end\":70061,\"start\":70058},{\"end\":70075,\"start\":70071},{\"end\":70091,\"start\":70084},{\"end\":70102,\"start\":70100},{\"end\":70113,\"start\":70110},{\"end\":70127,\"start\":70124},{\"end\":70144,\"start\":70138},{\"end\":70160,\"start\":70151}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:2212.07388\",\"id\":\"b0\"},\"end\":37775,\"start\":37419},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":4624670},\"end\":38335,\"start\":37777},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":996627},\"end\":38752,\"start\":38337},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":54457478},\"end\":39141,\"start\":38754},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":211817828},\"end\":39632,\"start\":39143},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":248259089},\"end\":40157,\"start\":39634},{\"attributes\":{\"doi\":\"arXiv:2209.13274\",\"id\":\"b6\"},\"end\":40684,\"start\":40159},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":250015331},\"end\":41077,\"start\":40686},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":210701396},\"end\":41430,\"start\":41079},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":32286806},\"end\":41874,\"start\":41432},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":245329664},\"end\":42405,\"start\":41876},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":238583434},\"end\":42929,\"start\":42407},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":3299195},\"end\":43228,\"start\":42931},{\"attributes\":{\"id\":\"b13\"},\"end\":43391,\"start\":43230},{\"attributes\":{\"doi\":\"arXiv:2002.10099\",\"id\":\"b14\"},\"end\":43703,\"start\":43393},{\"attributes\":{\"id\":\"b15\"},\"end\":43899,\"start\":43705},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":214606025},\"end\":44416,\"start\":43901},{\"attributes\":{\"doi\":\"arXiv:2211.11704\",\"id\":\"b17\"},\"end\":44790,\"start\":44418},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":206986664},\"end\":45135,\"start\":44792},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":237624426},\"end\":45554,\"start\":45137},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":252383426},\"end\":46091,\"start\":45556},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":256104917},\"end\":46534,\"start\":46093},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":233219786},\"end\":46907,\"start\":46536},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":226299858},\"end\":47393,\"start\":46909},{\"attributes\":{\"doi\":\"arXiv:2301.03102\",\"id\":\"b24\"},\"end\":47596,\"start\":47395},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":208512845},\"end\":48169,\"start\":47598},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":15545924},\"end\":48472,\"start\":48171},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":54465161},\"end\":49005,\"start\":48474},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":213175590},\"end\":49523,\"start\":49007},{\"attributes\":{\"doi\":\"arXiv:2209.07919\",\"id\":\"b29\"},\"end\":49851,\"start\":49525},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":246016186},\"end\":50200,\"start\":49853},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":206775100},\"end\":50528,\"start\":50202},{\"attributes\":{\"id\":\"b32\"},\"end\":50847,\"start\":50530},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":11830123},\"end\":51353,\"start\":50849},{\"attributes\":{\"id\":\"b34\"},\"end\":51570,\"start\":51355},{\"attributes\":{\"id\":\"b35\"},\"end\":51794,\"start\":51572},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":209376368},\"end\":52296,\"start\":51796},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":207207064},\"end\":52626,\"start\":52298},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":233307004},\"end\":53129,\"start\":52628},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":247957757},\"end\":53588,\"start\":53131},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":58007025},\"end\":54147,\"start\":53590},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":235358422},\"end\":54576,\"start\":54149},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":212646575},\"end\":55010,\"start\":54578},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":195776274},\"end\":55504,\"start\":55012},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":232352619},\"end\":55990,\"start\":55506},{\"attributes\":{\"doi\":\"arXiv:2210.13641\",\"id\":\"b45\"},\"end\":56299,\"start\":55992},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":1728538},\"end\":56636,\"start\":56301},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":196201321},\"end\":57115,\"start\":56638},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":8632684},\"end\":57724,\"start\":57117},{\"attributes\":{\"doi\":\"arXiv:1906.05797\",\"id\":\"b49\"},\"end\":58537,\"start\":57726},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":206942855},\"end\":59032,\"start\":58539},{\"attributes\":{\"id\":\"b51\"},\"end\":59259,\"start\":59034},{\"attributes\":{\"id\":\"b52\"},\"end\":59473,\"start\":59261},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":215547972},\"end\":59895,\"start\":59475},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":231709798},\"end\":60566,\"start\":59897},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":219791950},\"end\":61188,\"start\":60568},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":49189997},\"end\":61538,\"start\":61190},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":54482591},\"end\":61938,\"start\":61540},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":237278112},\"end\":62275,\"start\":61940},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":6159584},\"end\":62846,\"start\":62277},{\"attributes\":{\"doi\":\"arXiv:2106.10689\",\"id\":\"b60\"},\"end\":63264,\"start\":62848},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":207761262},\"end\":63642,\"start\":63266},{\"attributes\":{\"doi\":\"arXiv:2102.07064\",\"id\":\"b62\"},\"end\":63940,\"start\":63644},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":15010509},\"end\":64366,\"start\":63942},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":16413702},\"end\":64720,\"start\":64368},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":250956753},\"end\":65070,\"start\":64722},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":244478496},\"end\":65596,\"start\":65072},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":244709323},\"end\":66063,\"start\":65598},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":253223971},\"end\":66568,\"start\":66065},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":235605960},\"end\":66930,\"start\":66570},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":225077557},\"end\":67448,\"start\":66932},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":228083990},\"end\":67877,\"start\":67450},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":249240205},\"end\":68346,\"start\":67879},{\"attributes\":{\"id\":\"b73\"},\"end\":68555,\"start\":68348},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":4766599},\"end\":69074,\"start\":68557},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":80628300},\"end\":69637,\"start\":69076},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":51929808},\"end\":69995,\"start\":69639},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":245385791},\"end\":70561,\"start\":69997}]", "bib_title": "[{\"end\":37855,\"start\":37777},{\"end\":38416,\"start\":38337},{\"end\":38808,\"start\":38754},{\"end\":39221,\"start\":39143},{\"end\":39728,\"start\":39634},{\"end\":40754,\"start\":40686},{\"end\":41136,\"start\":41079},{\"end\":41532,\"start\":41432},{\"end\":41938,\"start\":41876},{\"end\":42497,\"start\":42407},{\"end\":42953,\"start\":42931},{\"end\":43950,\"start\":43901},{\"end\":44845,\"start\":44792},{\"end\":45213,\"start\":45137},{\"end\":45608,\"start\":45556},{\"end\":46133,\"start\":46093},{\"end\":46580,\"start\":46536},{\"end\":46955,\"start\":46909},{\"end\":47687,\"start\":47598},{\"end\":48238,\"start\":48171},{\"end\":48538,\"start\":48474},{\"end\":49077,\"start\":49007},{\"end\":49924,\"start\":49853},{\"end\":50258,\"start\":50202},{\"end\":50607,\"start\":50530},{\"end\":50907,\"start\":50849},{\"end\":51892,\"start\":51796},{\"end\":52354,\"start\":52298},{\"end\":52720,\"start\":52628},{\"end\":53197,\"start\":53131},{\"end\":53669,\"start\":53590},{\"end\":54197,\"start\":54149},{\"end\":54610,\"start\":54578},{\"end\":55107,\"start\":55012},{\"end\":55578,\"start\":55506},{\"end\":56332,\"start\":56301},{\"end\":56681,\"start\":56638},{\"end\":57194,\"start\":57117},{\"end\":58591,\"start\":58539},{\"end\":59546,\"start\":59475},{\"end\":59974,\"start\":59897},{\"end\":60655,\"start\":60568},{\"end\":61229,\"start\":61190},{\"end\":61605,\"start\":61540},{\"end\":62009,\"start\":61940},{\"end\":62338,\"start\":62277},{\"end\":63338,\"start\":63266},{\"end\":63985,\"start\":63942},{\"end\":64414,\"start\":64368},{\"end\":64760,\"start\":64722},{\"end\":65116,\"start\":65072},{\"end\":65639,\"start\":65598},{\"end\":66151,\"start\":66065},{\"end\":66614,\"start\":66570},{\"end\":67012,\"start\":66932},{\"end\":67509,\"start\":67450},{\"end\":67965,\"start\":67879},{\"end\":68627,\"start\":68557},{\"end\":69170,\"start\":69076},{\"end\":69673,\"start\":69639},{\"end\":70050,\"start\":69997}]", "bib_author": "[{\"end\":37433,\"start\":37419},{\"end\":37445,\"start\":37433},{\"end\":37455,\"start\":37445},{\"end\":37470,\"start\":37455},{\"end\":37496,\"start\":37470},{\"end\":37874,\"start\":37857},{\"end\":37890,\"start\":37874},{\"end\":37904,\"start\":37890},{\"end\":37924,\"start\":37904},{\"end\":37942,\"start\":37924},{\"end\":38430,\"start\":38418},{\"end\":38444,\"start\":38430},{\"end\":38460,\"start\":38444},{\"end\":38474,\"start\":38460},{\"end\":38490,\"start\":38474},{\"end\":38823,\"start\":38810},{\"end\":38834,\"start\":38823},{\"end\":39239,\"start\":39223},{\"end\":39256,\"start\":39239},{\"end\":39274,\"start\":39256},{\"end\":39741,\"start\":39730},{\"end\":39755,\"start\":39741},{\"end\":39773,\"start\":39755},{\"end\":39788,\"start\":39773},{\"end\":39795,\"start\":39788},{\"end\":40265,\"start\":40249},{\"end\":40281,\"start\":40265},{\"end\":40295,\"start\":40281},{\"end\":40311,\"start\":40295},{\"end\":40325,\"start\":40311},{\"end\":40339,\"start\":40325},{\"end\":40354,\"start\":40339},{\"end\":40368,\"start\":40354},{\"end\":40383,\"start\":40368},{\"end\":40770,\"start\":40756},{\"end\":41154,\"start\":41138},{\"end\":41171,\"start\":41154},{\"end\":41185,\"start\":41171},{\"end\":41203,\"start\":41185},{\"end\":41546,\"start\":41534},{\"end\":41564,\"start\":41546},{\"end\":41583,\"start\":41564},{\"end\":41598,\"start\":41583},{\"end\":41618,\"start\":41598},{\"end\":41957,\"start\":41940},{\"end\":41975,\"start\":41957},{\"end\":41996,\"start\":41975},{\"end\":42012,\"start\":41996},{\"end\":42027,\"start\":42012},{\"end\":42515,\"start\":42499},{\"end\":42530,\"start\":42515},{\"end\":42546,\"start\":42530},{\"end\":42558,\"start\":42546},{\"end\":42968,\"start\":42955},{\"end\":42984,\"start\":42968},{\"end\":43000,\"start\":42984},{\"end\":43258,\"start\":43232},{\"end\":43272,\"start\":43258},{\"end\":43280,\"start\":43272},{\"end\":43405,\"start\":43393},{\"end\":43417,\"start\":43405},{\"end\":43781,\"start\":43766},{\"end\":43965,\"start\":43952},{\"end\":43978,\"start\":43965},{\"end\":43994,\"start\":43978},{\"end\":44009,\"start\":43994},{\"end\":44027,\"start\":44009},{\"end\":44046,\"start\":44027},{\"end\":44449,\"start\":44418},{\"end\":44465,\"start\":44449},{\"end\":44474,\"start\":44465},{\"end\":44481,\"start\":44474},{\"end\":44860,\"start\":44847},{\"end\":44874,\"start\":44860},{\"end\":45231,\"start\":45215},{\"end\":45241,\"start\":45231},{\"end\":45256,\"start\":45241},{\"end\":45272,\"start\":45256},{\"end\":45628,\"start\":45610},{\"end\":45644,\"start\":45628},{\"end\":45661,\"start\":45644},{\"end\":45679,\"start\":45661},{\"end\":45693,\"start\":45679},{\"end\":45709,\"start\":45693},{\"end\":45730,\"start\":45709},{\"end\":46144,\"start\":46135},{\"end\":46157,\"start\":46144},{\"end\":46170,\"start\":46157},{\"end\":46182,\"start\":46170},{\"end\":46195,\"start\":46182},{\"end\":46205,\"start\":46195},{\"end\":46589,\"start\":46582},{\"end\":46595,\"start\":46589},{\"end\":46607,\"start\":46595},{\"end\":46616,\"start\":46607},{\"end\":46972,\"start\":46957},{\"end\":46987,\"start\":46972},{\"end\":47006,\"start\":46987},{\"end\":47020,\"start\":47006},{\"end\":47409,\"start\":47395},{\"end\":47424,\"start\":47409},{\"end\":47702,\"start\":47689},{\"end\":47715,\"start\":47702},{\"end\":47729,\"start\":47715},{\"end\":47740,\"start\":47729},{\"end\":47756,\"start\":47740},{\"end\":47770,\"start\":47756},{\"end\":48251,\"start\":48240},{\"end\":48270,\"start\":48251},{\"end\":48277,\"start\":48270},{\"end\":48556,\"start\":48540},{\"end\":48573,\"start\":48556},{\"end\":48591,\"start\":48573},{\"end\":48610,\"start\":48591},{\"end\":48626,\"start\":48610},{\"end\":49095,\"start\":49079},{\"end\":49105,\"start\":49095},{\"end\":49125,\"start\":49105},{\"end\":49144,\"start\":49125},{\"end\":49157,\"start\":49144},{\"end\":49174,\"start\":49157},{\"end\":49178,\"start\":49174},{\"end\":49626,\"start\":49613},{\"end\":49637,\"start\":49626},{\"end\":49652,\"start\":49637},{\"end\":49941,\"start\":49926},{\"end\":49953,\"start\":49941},{\"end\":49971,\"start\":49953},{\"end\":49989,\"start\":49971},{\"end\":50276,\"start\":50260},{\"end\":50305,\"start\":50276},{\"end\":50320,\"start\":50305},{\"end\":50619,\"start\":50609},{\"end\":50628,\"start\":50619},{\"end\":50643,\"start\":50628},{\"end\":50923,\"start\":50909},{\"end\":50932,\"start\":50923},{\"end\":50944,\"start\":50932},{\"end\":50957,\"start\":50944},{\"end\":50964,\"start\":50957},{\"end\":50977,\"start\":50964},{\"end\":50985,\"start\":50977},{\"end\":50996,\"start\":50985},{\"end\":51006,\"start\":50996},{\"end\":51020,\"start\":51006},{\"end\":51413,\"start\":51402},{\"end\":51423,\"start\":51413},{\"end\":51433,\"start\":51423},{\"end\":51453,\"start\":51433},{\"end\":51462,\"start\":51453},{\"end\":51906,\"start\":51894},{\"end\":51919,\"start\":51906},{\"end\":51930,\"start\":51919},{\"end\":51940,\"start\":51930},{\"end\":52374,\"start\":52356},{\"end\":52393,\"start\":52374},{\"end\":52408,\"start\":52393},{\"end\":52425,\"start\":52408},{\"end\":52739,\"start\":52722},{\"end\":52753,\"start\":52739},{\"end\":52769,\"start\":52753},{\"end\":53216,\"start\":53199},{\"end\":53236,\"start\":53216},{\"end\":53250,\"start\":53236},{\"end\":53266,\"start\":53250},{\"end\":53284,\"start\":53266},{\"end\":53307,\"start\":53284},{\"end\":53327,\"start\":53307},{\"end\":53688,\"start\":53671},{\"end\":53704,\"start\":53688},{\"end\":53719,\"start\":53704},{\"end\":53737,\"start\":53719},{\"end\":53755,\"start\":53737},{\"end\":54213,\"start\":54199},{\"end\":54226,\"start\":54213},{\"end\":54237,\"start\":54226},{\"end\":54255,\"start\":54237},{\"end\":54271,\"start\":54255},{\"end\":54287,\"start\":54271},{\"end\":54626,\"start\":54612},{\"end\":54644,\"start\":54626},{\"end\":54660,\"start\":54644},{\"end\":54676,\"start\":54660},{\"end\":54692,\"start\":54676},{\"end\":55122,\"start\":55109},{\"end\":55139,\"start\":55122},{\"end\":55153,\"start\":55139},{\"end\":55171,\"start\":55153},{\"end\":55187,\"start\":55171},{\"end\":55598,\"start\":55580},{\"end\":55612,\"start\":55598},{\"end\":55623,\"start\":55612},{\"end\":55639,\"start\":55623},{\"end\":56008,\"start\":55992},{\"end\":56016,\"start\":56008},{\"end\":56030,\"start\":56016},{\"end\":56039,\"start\":56030},{\"end\":56351,\"start\":56334},{\"end\":56362,\"start\":56351},{\"end\":56698,\"start\":56683},{\"end\":56715,\"start\":56698},{\"end\":56731,\"start\":56715},{\"end\":57211,\"start\":57196},{\"end\":57224,\"start\":57211},{\"end\":57242,\"start\":57224},{\"end\":57257,\"start\":57242},{\"end\":57276,\"start\":57257},{\"end\":57295,\"start\":57276},{\"end\":57736,\"start\":57726},{\"end\":57746,\"start\":57736},{\"end\":57752,\"start\":57746},{\"end\":57760,\"start\":57752},{\"end\":57771,\"start\":57760},{\"end\":57780,\"start\":57771},{\"end\":57791,\"start\":57780},{\"end\":57804,\"start\":57791},{\"end\":57810,\"start\":57804},{\"end\":57819,\"start\":57810},{\"end\":57831,\"start\":57819},{\"end\":57838,\"start\":57831},{\"end\":57847,\"start\":57838},{\"end\":57854,\"start\":57847},{\"end\":57861,\"start\":57854},{\"end\":57868,\"start\":57861},{\"end\":57875,\"start\":57868},{\"end\":57883,\"start\":57875},{\"end\":57893,\"start\":57883},{\"end\":57904,\"start\":57893},{\"end\":57918,\"start\":57904},{\"end\":57930,\"start\":57918},{\"end\":57943,\"start\":57930},{\"end\":57952,\"start\":57943},{\"end\":57961,\"start\":57952},{\"end\":57975,\"start\":57961},{\"end\":57986,\"start\":57975},{\"end\":57997,\"start\":57986},{\"end\":58010,\"start\":57997},{\"end\":58022,\"start\":58010},{\"end\":58607,\"start\":58593},{\"end\":58626,\"start\":58607},{\"end\":58640,\"start\":58626},{\"end\":58657,\"start\":58640},{\"end\":58673,\"start\":58657},{\"end\":59047,\"start\":59034},{\"end\":59059,\"start\":59047},{\"end\":59073,\"start\":59059},{\"end\":59091,\"start\":59073},{\"end\":59561,\"start\":59548},{\"end\":59575,\"start\":59561},{\"end\":59591,\"start\":59575},{\"end\":59993,\"start\":59976},{\"end\":60008,\"start\":59993},{\"end\":60021,\"start\":60008},{\"end\":60036,\"start\":60021},{\"end\":60050,\"start\":60036},{\"end\":60072,\"start\":60050},{\"end\":60087,\"start\":60072},{\"end\":60103,\"start\":60087},{\"end\":60117,\"start\":60103},{\"end\":60673,\"start\":60657},{\"end\":60692,\"start\":60673},{\"end\":60708,\"start\":60692},{\"end\":60729,\"start\":60708},{\"end\":60746,\"start\":60729},{\"end\":60763,\"start\":60746},{\"end\":60781,\"start\":60763},{\"end\":60798,\"start\":60781},{\"end\":60806,\"start\":60798},{\"end\":61247,\"start\":61231},{\"end\":61257,\"start\":61247},{\"end\":61621,\"start\":61607},{\"end\":61631,\"start\":61621},{\"end\":62025,\"start\":62011},{\"end\":62035,\"start\":62025},{\"end\":62361,\"start\":62340},{\"end\":62376,\"start\":62361},{\"end\":62389,\"start\":62376},{\"end\":62405,\"start\":62389},{\"end\":62415,\"start\":62405},{\"end\":62435,\"start\":62415},{\"end\":62448,\"start\":62435},{\"end\":62950,\"start\":62939},{\"end\":62963,\"start\":62950},{\"end\":62973,\"start\":62963},{\"end\":62993,\"start\":62973},{\"end\":63006,\"start\":62993},{\"end\":63020,\"start\":63006},{\"end\":63351,\"start\":63340},{\"end\":63365,\"start\":63351},{\"end\":63374,\"start\":63365},{\"end\":63389,\"start\":63374},{\"end\":63401,\"start\":63389},{\"end\":63652,\"start\":63644},{\"end\":63658,\"start\":63652},{\"end\":63665,\"start\":63658},{\"end\":63673,\"start\":63665},{\"end\":63689,\"start\":63673},{\"end\":64002,\"start\":63987},{\"end\":64017,\"start\":64002},{\"end\":64033,\"start\":64017},{\"end\":64052,\"start\":64033},{\"end\":64066,\"start\":64052},{\"end\":64081,\"start\":64066},{\"end\":64431,\"start\":64416},{\"end\":64451,\"start\":64431},{\"end\":64472,\"start\":64451},{\"end\":64485,\"start\":64472},{\"end\":64501,\"start\":64485},{\"end\":64774,\"start\":64762},{\"end\":64785,\"start\":64774},{\"end\":64796,\"start\":64785},{\"end\":64807,\"start\":64796},{\"end\":64821,\"start\":64807},{\"end\":64836,\"start\":64821},{\"end\":64847,\"start\":64836},{\"end\":65130,\"start\":65118},{\"end\":65147,\"start\":65130},{\"end\":65163,\"start\":65147},{\"end\":65174,\"start\":65163},{\"end\":65186,\"start\":65174},{\"end\":65199,\"start\":65186},{\"end\":65217,\"start\":65199},{\"end\":65232,\"start\":65217},{\"end\":65250,\"start\":65232},{\"end\":65267,\"start\":65250},{\"end\":65652,\"start\":65641},{\"end\":65664,\"start\":65652},{\"end\":65677,\"start\":65664},{\"end\":65696,\"start\":65677},{\"end\":65709,\"start\":65696},{\"end\":65717,\"start\":65709},{\"end\":66167,\"start\":66153},{\"end\":66175,\"start\":66167},{\"end\":66189,\"start\":66175},{\"end\":66202,\"start\":66189},{\"end\":66214,\"start\":66202},{\"end\":66229,\"start\":66214},{\"end\":66628,\"start\":66616},{\"end\":66639,\"start\":66628},{\"end\":66652,\"start\":66639},{\"end\":66666,\"start\":66652},{\"end\":67026,\"start\":67014},{\"end\":67039,\"start\":67026},{\"end\":67051,\"start\":67039},{\"end\":67065,\"start\":67051},{\"end\":67079,\"start\":67065},{\"end\":67092,\"start\":67079},{\"end\":67106,\"start\":67092},{\"end\":67523,\"start\":67511},{\"end\":67535,\"start\":67523},{\"end\":67547,\"start\":67535},{\"end\":67560,\"start\":67547},{\"end\":67569,\"start\":67560},{\"end\":67576,\"start\":67569},{\"end\":67977,\"start\":67967},{\"end\":67991,\"start\":67977},{\"end\":68009,\"start\":67991},{\"end\":68026,\"start\":68009},{\"end\":68042,\"start\":68026},{\"end\":68357,\"start\":68348},{\"end\":68368,\"start\":68357},{\"end\":68379,\"start\":68368},{\"end\":68389,\"start\":68379},{\"end\":68644,\"start\":68629},{\"end\":68659,\"start\":68644},{\"end\":68675,\"start\":68659},{\"end\":68690,\"start\":68675},{\"end\":68703,\"start\":68690},{\"end\":69187,\"start\":69172},{\"end\":69204,\"start\":69187},{\"end\":69224,\"start\":69204},{\"end\":69242,\"start\":69224},{\"end\":69690,\"start\":69675},{\"end\":69711,\"start\":69690},{\"end\":69724,\"start\":69711},{\"end\":70063,\"start\":70052},{\"end\":70077,\"start\":70063},{\"end\":70093,\"start\":70077},{\"end\":70104,\"start\":70093},{\"end\":70115,\"start\":70104},{\"end\":70129,\"start\":70115},{\"end\":70146,\"start\":70129},{\"end\":70162,\"start\":70146}]", "bib_venue": "[{\"end\":38070,\"start\":38010},{\"end\":38962,\"start\":38902},{\"end\":39402,\"start\":39342},{\"end\":39897,\"start\":39850},{\"end\":40898,\"start\":40838},{\"end\":42155,\"start\":42095},{\"end\":42680,\"start\":42623},{\"end\":44174,\"start\":44114},{\"end\":45340,\"start\":45310},{\"end\":46335,\"start\":46274},{\"end\":46738,\"start\":46681},{\"end\":47170,\"start\":47099},{\"end\":47898,\"start\":47838},{\"end\":48754,\"start\":48694},{\"end\":49280,\"start\":49233},{\"end\":51694,\"start\":51637},{\"end\":52068,\"start\":52008},{\"end\":52891,\"start\":52834},{\"end\":53883,\"start\":53823},{\"end\":54794,\"start\":54747},{\"end\":55761,\"start\":55704},{\"end\":56490,\"start\":56430},{\"end\":56859,\"start\":56799},{\"end\":57436,\"start\":57374},{\"end\":58811,\"start\":58746},{\"end\":59383,\"start\":59326},{\"end\":59689,\"start\":59644},{\"end\":60245,\"start\":60185},{\"end\":61387,\"start\":61326},{\"end\":61761,\"start\":61700},{\"end\":62576,\"start\":62516},{\"end\":65845,\"start\":65785},{\"end\":68831,\"start\":68771},{\"end\":69370,\"start\":69310},{\"end\":69826,\"start\":69779},{\"end\":70290,\"start\":70230},{\"end\":37574,\"start\":37512},{\"end\":38008,\"start\":37942},{\"end\":38525,\"start\":38490},{\"end\":38900,\"start\":38834},{\"end\":39340,\"start\":39274},{\"end\":39848,\"start\":39795},{\"end\":40247,\"start\":40159},{\"end\":40836,\"start\":40770},{\"end\":41239,\"start\":41203},{\"end\":41640,\"start\":41618},{\"end\":42093,\"start\":42027},{\"end\":42621,\"start\":42558},{\"end\":43063,\"start\":43000},{\"end\":43528,\"start\":43433},{\"end\":43764,\"start\":43705},{\"end\":44112,\"start\":44046},{\"end\":44581,\"start\":44497},{\"end\":44941,\"start\":44874},{\"end\":45308,\"start\":45272},{\"end\":45803,\"start\":45730},{\"end\":46272,\"start\":46205},{\"end\":46679,\"start\":46616},{\"end\":47097,\"start\":47020},{\"end\":47473,\"start\":47440},{\"end\":47836,\"start\":47770},{\"end\":48307,\"start\":48277},{\"end\":48692,\"start\":48626},{\"end\":49231,\"start\":49178},{\"end\":49611,\"start\":49525},{\"end\":50011,\"start\":49989},{\"end\":50349,\"start\":50320},{\"end\":50672,\"start\":50643},{\"end\":51087,\"start\":51020},{\"end\":51400,\"start\":51355},{\"end\":51635,\"start\":51572},{\"end\":52006,\"start\":51940},{\"end\":52447,\"start\":52425},{\"end\":52832,\"start\":52769},{\"end\":53356,\"start\":53327},{\"end\":53821,\"start\":53755},{\"end\":54346,\"start\":54287},{\"end\":54745,\"start\":54692},{\"end\":55243,\"start\":55187},{\"end\":55702,\"start\":55639},{\"end\":56123,\"start\":56055},{\"end\":56428,\"start\":56362},{\"end\":56797,\"start\":56731},{\"end\":57372,\"start\":57295},{\"end\":58093,\"start\":58038},{\"end\":58744,\"start\":58673},{\"end\":59142,\"start\":59091},{\"end\":59324,\"start\":59261},{\"end\":59642,\"start\":59591},{\"end\":60183,\"start\":60117},{\"end\":60865,\"start\":60806},{\"end\":61324,\"start\":61257},{\"end\":61698,\"start\":61631},{\"end\":62084,\"start\":62035},{\"end\":62514,\"start\":62448},{\"end\":62937,\"start\":62848},{\"end\":63438,\"start\":63401},{\"end\":63766,\"start\":63705},{\"end\":64145,\"start\":64081},{\"end\":64536,\"start\":64501},{\"end\":64881,\"start\":64847},{\"end\":65290,\"start\":65267},{\"end\":65783,\"start\":65717},{\"end\":66296,\"start\":66229},{\"end\":66725,\"start\":66666},{\"end\":67165,\"start\":67106},{\"end\":67650,\"start\":67576},{\"end\":68101,\"start\":68042},{\"end\":68443,\"start\":68389},{\"end\":68769,\"start\":68703},{\"end\":69308,\"start\":69242},{\"end\":69777,\"start\":69724},{\"end\":70228,\"start\":70162}]"}}}, "year": 2023, "month": 12, "day": 17}