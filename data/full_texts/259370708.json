{"id": 259370708, "updated": "2023-10-04 23:09:27.943", "metadata": {"title": "AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models", "authors": "[{\"first\":\"Siheng\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Cheng\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Yichun\",\"last\":\"Yin\",\"middle\":[]},{\"first\":\"Xinyu\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Zesen\",\"last\":\"Cheng\",\"middle\":[]},{\"first\":\"Lifeng\",\"last\":\"Shang\",\"middle\":[]},{\"first\":\"Xin\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Qun\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Yujiu\",\"last\":\"Yang\",\"middle\":[]}]", "venue": "ACL", "journal": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)", "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Information-seeking conversation, which aims to help users gather information through conversation, has achieved great progress in recent years. However, the research is still stymied by the scarcity of training data. To alleviate this problem, we propose AutoConv for synthetic conversation generation, which takes advantage of the few-shot learning ability and generation capacity of large language models (LLM). Specifically, we formulate the conversation generation problem as a language modeling task, then finetune an LLM with a few human conversations to capture the characteristics of the information-seeking process and use it for generating synthetic conversations with high quality. Experimental results on two frequently-used datasets verify that AutoConv has substantial improvements over strong baselines and alleviates the dependence on human annotation. In addition, we also provide several analysis studies to promote future research.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2308.06507", "mag": null, "acl": "2023.acl-short.149", "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2308-06507", "doi": "10.18653/v1/2023.acl-short.149"}}, "content": {"source": {"pdf_hash": "8d36390a430845849b62646a8c8be4c79f2b3d62", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclanthology.org/2023.acl-short.149.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4ddf9fca0a83934dd3511e97380a53fb73242f1f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/8d36390a430845849b62646a8c8be4c79f2b3d62.txt", "contents": "\nAutoConv: Automatically Generating Information-seeking Conversations with Large Language Models\nShort PapersCopyright Short PapersJuly 9-14, 2023\n\nSiheng Li \nShenzhen International Graduate School\nTsinghua University\n\n\nCheng Yang \nShenzhen International Graduate School\nTsinghua University\n\n\nYichun Yin \nXinyu Zhu \nShenzhen International Graduate School\nTsinghua University\n\n\nZesen Cheng \nPeking University\n\n\nLifeng Shang \nXin Jiang \nQun Liu qun.liu@huawei.com \nYujiu Yang yang.yujiu@sz.tsinghua.edu.cn \nShenzhen International Graduate School\nTsinghua University\n\n\nAutoConv: Automatically Generating Information-seeking Conversations with Large Language Models\n\nProceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nthe 61st Annual Meeting of the Association for Computational LinguisticsShort Papers2July 9-14, 20232 Huawei Noah's Ark Lab,\nInformation-seeking conversation, which aims to help users gather information through conversation, has achieved great progress in recent years. However, the research is still stymied by the scarcity of training data. To alleviate this problem, we propose AutoConv for synthetic conversation generation, which takes advantage of the few-shot learning ability and generation capacity of large language models (LLM). Specifically, we formulate the conversation generation problem as a language modeling task, then finetune an LLM with a few human conversations to capture the characteristics of the information-seeking process and use it for generating synthetic conversations with high quality. Experimental results on two frequently-used datasets verify that AutoConv has substantial improvements over strong baselines and alleviates the dependence on human annotation. In addition, we also provide several analysis studies to promote future research. . 2022. Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned. CoRR, abs/2209.07858.\n\nIntroduction\n\nIn information-seeking conversations, users repeatedly ask questions based on their interests, and the dialogue system provides answers to fulfill their information needs (Stede and Schlangen, 2004;Choi et al., 2018;Reddy et al., 2019). This scenario is important for addressing real-world open-ended questions, which requires discussions to explore in depth (Dai et al., 2022), e.g., How to learn more efficiently? Though great progress has been achieved in recent years, most existing researches depend on abundant human annotation, which can be highly costly and limited in knowledge coverage.\n\nA promising way to alleviate this problem is data augmentation . Traditional methods, including token-level manipulation (Kobayashi, 2018;Wei and Zou, 2019) Method DG Data Needs EDA (Wei and Zou, 2019) \u2717  and sentence-level paraphrasing (Sennrich et al., 2016), improve the linguistic diversity of training data. However, they cannot create conversations grounded on new documents, which are indispensable for dealing with out-of-domain scenarios. Another line of research focuses on simulation-based methods (Wu et al., 2021;Kim et al., 2022). Specifically, they can iteratively generate conversations grounded on new documents based on a span extractor and an utterance generator. Nevertheless, both the training of the extractor and the generator still require abundant human dialogues. Besides the above ways, Dai et al. (2022) propose Dialog Inpainting, which creates information-seeking dialogues by inserting utterances between neighboring sentences in documents. One potential risk is the gap between the structure of documents and that of conversations. Documents are tighter, while realworld conversations are more open-ended. To alleviate the above issues, we propose a simple yet effective method AutoConv for Automatically generating information-seeking Conversations, which takes advantage of the fewshot learning ability and generation capacity of large language models (LLM) (Brown et al., 2020). Specifically, we formulate conversation generation as a language modeling task and utilize an LLM for generating synthetic conversations grounded on external documents. Surprisingly, finetuning with a few human dialogues can help LLM capture the characteristics of the information-seeking process \n\n\nSys-2\n\nSampling Greedy Figure 1: The generation process of AutoConv. We use nucleus sampling for generating user questions and greedy search for generating system answers.\n\n(e.g., grounding, question answering) and generate high-quality synthetic conversations. Then, we can train a small task model with these dialogues. The differences between AutoConv and others are shown in Table 1. We conduct comprehensive experiments on two frequently-used datasets QuAC (Choi et al., 2018) and CoQA (Reddy et al., 2019) in the low-resource setting, where only dozens of human dialogues are available. The results show that AutoConv has substantial improvements over several strong baselines. When scaling up the synthetic dialogues, AutoConv has the improvement of up to 5.06 F1 gain compared with directly finetuning, and thus largely reduces the labor force for annotation. In addition, we find that the small task model trained with synthetic dialogues can even surpass finetuned LLM with only 1.7% parameters. Moreover, we also investigate the impact of decoding strategy and scaling laws for AutoConv.\n\n\nMethod\n\n\nTask Formulation\n\nOur goal is automatically generating informationseeking conversations. Specifically, each conversation is grounded on a document d and consists of a series of user questions and system answers.\n\n\nConversation Generation\n\nTraining. We formulate conversation generation as a language modeling task and finetune 1 an LLM with a few human dialogues (e.g., 50 from QuAC (Choi et al., 2018)) to capture the characteristics of information-seeking conversations (e.g., grounding, question answering). The objective is the negative log-likelihood of each utterance:\nL = \u2212 T t=1 L l=1 log P (u t l |u t <l , h <t , d),\nwhere u represents a user question or a system answer, h is the dialogue history, L and T are the number of tokens and turns respectively.\n\nGenerating. Based on the finetuned LLM, we can generate synthetic dialogues with unlabeled documents, as in Figure 1. In information-seeking scenarios, user questions are typically open-ended. Thus we choose nucleus sampling (Holtzman et al., 2020) for generating user questions, which has shown great performance in various open-ended generation tasks (Su et al., 2022). However, when applying a sampling decoding strategy for system answer generation, we find it results in the \"hallucination\" problem (Shuster et al., 2021), where the generation is plausible but factually incorrect based on the document. To this end, we utilize greedy search for answer generation. Neural language models often generate the same sentences repetitively . To alleviate this problem, we first compute the diversity score of each synthetic dialogue as in Su et al. (2022), which considers the repetition at different n-gram levels.\n\nThen, we filter out dialogues based on this score. After that, a two-stage training strategy is adopted (Xie et al., 2020b) for training a small task model. Specifically, we first pre-train it on the synthetic dialogues, then finetune it on the human dialogues used for finetuning the LLM. More training details are given in Appendix B.\n\n\nExperiments\n\nWe conduct experiments on QuAC (Choi et al., 2018) and CoQA (Reddy et al., 2019), more details about them are shown in Appendix A.\n\n\nImplementation\n\nWe focus on the low-resource setting, where human dialogues are scarce. To simulate this setting, we randomly sample a few human dialogues from the training set of QuAC or CoQA, and use them for finetuning the LLM. We use OPT-13B (Zhang et al., 2022) as the LLM and UnifiedQA-V2-base (222M) (Khashabi et al., 2022) as the small task model. All data augmentation methods use the same training strategy and small task model. More implementation details are shown in Appendix B.\n\n\nComparison with Baselines\n\nWe compare AutoConv with a series of baselines, and the details of them are given in Appendix C. As\n\n\nMethod QuAC\n\nCoQA F1 EM F1 EM Prompting GPT-3 Zero-shot (Brown et al., 2020) 41.5 -81.5 -GPT-3 Few-shot (Brown et al., 2020) 44.  Table 2: Comparison with baselines. All experiments are performed 4 runs with different random seeds. Finetuning means directly training with only human dialogues. All data augmentation methods use the same human dialogues and the same number of synthetic dialogues for the sake of fairness (5 times the number of human dialogues). Human annotation represents replacing the synthetic dialogues with the same number of human dialogues.\n\nshown in Table 2, AutoConv achieves better performance than GPT-3 prompting on QuAC with only 0.13% parameters and 50 human dialogues, but is less competitive on CoQA. We conjecture the reason stems from the intrinsic difference between the two datasets. CoQA contains more factoid questions, and the answers are named entities or short noun phrases like those in SQuAD (Rajpurkar et al., 2016). By training on large-scale text corpus from a web forum, GPT-3 might implicitly learn the format and structure of question answering (Sanh et al., 2022), and thus gets excellent performance on CoQA. On the other side, QuAC has more openended and exploratory questions as in natural conversations, and 86% questions are contextual (Choi et al., 2018). Therefore, it brings more difficulties for GPT-3 inference with few demonstrations, while our method learns better from both human dialogues and synthetic dialogues.\n\nCompared with data augmentation methods, Au-toConv achieves the best performance on both datasets and mitigates the gap between synthetic dialogues and human upper bounds. We find that the token-level augmentation method EDA and the sentence-level augmentation method Back-Translation even hurt the performance, which is One possible reason is that they bring too much noise. Dialog Inpainting (Dai et al., 2022) gets ordinary performance, and the reason possibly derives from the gap between the structure of natural conversations and that of the documents used for constructing synthetic dialogues.\n\n\nScaling up Human Dialogues and Synthetic Dialogues\n\nIn this part, we further analyze the performance of AutoConv when scaling up the human dialogues and synthetic dialogues. As shown in Figure 2, the  \n\n\nComparison with Finetuned Large Language Model\n\nAutoConv is a kind of symbolic knowledge distillation (West et al., 2022), where the finetuned large language model (LLM) transfers its knowledge to the small task model (STM) by generating synthetic dialogues for the training of STM. Here, we further investigate the effectiveness of AutoConv from the aspect of knowledge distillation. As shown in Table 3, finetuned LLM has substantial improvements over finetuned STM. However, it brings large memory and computation cost. On the other side, our AutoConv not only keeps the efficiency of STM, but also boosts the performance. Surprisingly, Au-toConv even outperforms its teacher model in the 200 human dialogues setting. Similar observations are found in West et al. (2022); Ye et al. (2022), while they focus on different tasks. We leave the analysis of this novel observation for future work.\n\n\nImpact of Decoding Strategy\n\nDuring our preliminary experiments, we find that the decoding strategy is important for system answer generation. More precisely, we evaluate the answer generation performance of LLM with different decoding strategies on QuAC, and the results are shown in Table 4. Though nucleus sampling (Holtzman et al., 2020) has shown great performance in various generation tasks (Su et al., 2022), it performs less competitively than maximization-   based decoding strategies for answer generation. Compared with beam search, greedy search shows competitive performance and is more efficient. Thus we use greedy search by default in this paper.\n\n\nScaling Laws\n\nWe further analyze how the benefit of AutoConv is affected by the scale of LLM. As shown in Figure  3, the performance gets better with a larger model across a various number of synthetic dialogues. In addition, when the LM is small (350M) and with limited generation ability, the synthetic dialogues can even hurt the performance when the available human dialogues are scarce. Due to the limitation of computational resources, we limit our investigation to 13B parameters and leave larger models for future work.\n\n\nCase Study\n\nIn Table 5, we present an example of our synthetic conversation for the case study. The original document describes the singer Ciara's second studio album and her acting debut. The conversation consists of seven user questions and seven system answers, covering the title and sales of the album, the duration of the tour, etc. As we can see from this\n\nTitle\n\n\n2006-2007: Ciara: The Evolution and acting debut Document\n\nOn December 5, 2006, Ciara released her second studio album, Ciara: The Evolution. According to the singer, the title of the album is \\\"about so much more than just my personal growth -it's about the evolution of music, the evolution of dance, the evolution of fashion \\\" The source of the album\u015b creativity such as the sound and edge comes from Ciara in general.  example, the user questions are diverse (e.g. what, how, did, etc.) and the conversation is informative and conversational. For example, when the system mentions \"tour\" (the fifth system utterance), the user follows by asking \"How long was the tour?\".\n\n\nError Analysis\n\nTo further analyze the limitation of our method, we conduct an error analysis by manually investigating 50 synthetic conversations generated by AutoConv, which is finetuned with 50 human conversations from QuAC (Choi et al., 2018). Particularly, we find that only 5% generated questions are not suitable (e.g., misspelled names). The reason stems from the open-ended characteristic of natural conversation that many kinds of user questions are possible under the same context. However, nearly 40% of system answers are not perfect, and we summarize the wrong answers into four major classes:\n\n(1) Irrelevant: 75% of them are totally irrelevant to user questions.\n\n(2) Related but not Accurate: 14% of them contain related knowledge from the grounded documents, but the answers are not accurate. Take an example in Table 5, the second user question asks for the name of the album, which is Ciara: The Evolution according to the document. While the LLM generates the interpretation of the album name by mistake.\n\n(3) Missing: 4% of them belong to the missing error that the system answers are \"No Answer\", while the questions actually can be answered based on the documents. (4) Hallucination: 3% of them mention hallucination knowledge, which cannot be found in the documents. In addition, we also notice that AutoConv is more likely to generate wrong answers when grounding on longer and more complex documents.\n\n\nConclusion\n\nIn this paper, we propose a simple yet effective method, AutoConv, which formulates the conversation generation problem as a language modeling task. Then, based on a large language model and a few human dialogues, AutoConv can generate synthetic dialogues with high quality. Experimental results on both QuAC and CoQA verify the effectiveness of AutoConv, which alleviates the human efforts for annotation largely. Furthermore, we also provide case study and error analysis to prompt future research.\n\n\nLimitations\n\nIn this paper, we propose a method named Au-toConv, which means automatically generating information-seeking conversations with large language models (LLM). Though it has achieved great performance on both QuAC (Choi et al., 2018) and CoQA (Reddy et al., 2019), there are still some limitations that should be noticed.\n\n\nLimitation of LLM.\n\nIn our experiments, we use OPT-13B (Zhang et al., 2022) as the LLM for generating synthetic conversations due to the limited computational resources. Larger models should be considered to further understand the potential ability of AutoConv, e.g., GPT-3 (Brown et al., 2020), OPT-175B (Zhang et al., 2022), BLOOM-176B (Scao et al., 2022), and GLM-130B (Zeng et al., 2022) etc.\n\nLimitation of Implementation. As mentioned in Section 2.2 and Appendix B, our method needs to finetune LLM and generate massive synthetic conversations based on the finetuned LLM, which has a high cost for implementation.\n\nLimitation of Synthetic Dialogues. As shown in Table 2 and Section 3.8, there is still a gap between our synthetic dialogues and human dialogues. It is important to improve the quality of synthetic dialogues so that we can further alleviate the dependence on human annotation.\n\n\nEthics Statement\n\nAutoConv is based on large language models (LLM), while LLM has some potential risks, e.g., social bias (Liang et al., 2021), offensive content (Ganguli et al., 2022) etc. Fortunately, we finetune the LLM to capture the characteristics of the information-seeking process, and the generated conversations are mostly grounded on the provided documents (take an example in Table 5). Therefore, our method alleviates the potential risks of directly using LLM. According to our manual check in error analysis (Section 3.8), we do not find any harmful content in the synthetic conversations. In addition, we also encourage considering more safety methods Sun et al., 2022) to guarantee the quality of synthetic conversations.\n\n\nA Datasets\n\nQuAC. QuAC (Choi et al., 2018) is a leading conversational question answering dataset, consists of 14K information-seeking dialogues. Different from the factoid questions in most existing QA datasets, the questions in QuAC are more open-ended and exploratory. In addition, 86% of questions are contextual, and the model needs to understand the dialogue context to resolve coreference. As the test set is only available in the QuAC challenge 2 , we evaluate the performance on the development set. For the training hyperparameters, we set the learning rate as 3e \u2212 4, batch size as 32, and use Adam optimizer (Kingma and Ba, 2015) with warmup learning rate schedule, the warmup ratio is 0.1. When comparing with baseline methods as in Section 3.2, all methods use the same small task model, the same two-stage training strategy (Xie et al., 2020b;, the same human dialogues and the same number of synthetic dialogues for fairness (5 times the number of hu-man dialogues). For the 50 human dialogues setting, we train each model for 1K gradient steps in the pre-training stage and 200 gradient steps in the fintuning stage. For the 100 human dialogues setting, the steps are 2K and 400 respectively. When scaling up the number of synthetic dialogues as in Section 3.3 and Section 3.6, the numbers of pretraining steps scale up, which are 2K, 4K, 8K, 20K and 40K for 1K, 2K, 4K, 10K and 20K synthetic dialogues respectively, and the finetuning steps are 200, 400, 800 and 2K for 50, 100, 200 and 500 human dialogues respectively. For all experiments, we randomly sample 20% dialogues as the validation set, and others as the training set. The model is validated every epoch, and we choose the checkpoint with the best F1 score on the validation set for evaluation.\n\nOurs. We use OPT-13B 8 (Zhang et al., 2022) as the LLM for generating synthetic dialogues, which is a decoder-only pre-trained language model with 13B parameters. The learning rate and batch size are set as 1e-5 and 32. Adam optimizer (Kingma and Ba, 2015) with warmup learning rate schedule is utilized for optimization and the warmup ratio is 0.1. The max training steps of LLM are 200, 400, 800 and 2K for 50, 100, 200 and 500 human dialogues respectively. According to the performance of AutoConv on the validation set of human dialogues, we find that training LLM for 4 epochs is the most suitable. We randomly sample 5K documents from the training sets of QuAC and CoQA, and generate 8 synthetic dialogues for each document. The number of turn is set as 14 for QuAC and 30 for CoQA. Then, we filter a quarter of the synthetic dialogues based on the diversity score of each dialogue as in Su et al. (2022), which takes into account the repetition at different n-gram levels. It takes around 5 hours for training LLM and 18 hours for generating synthetic dialogues with 8 Tesla V100 32GB GPUs.\n\n\nEvaluation.\n\nTo evaluate the quality of synthetic conversations, we evaluate the conversational question answering performance of the small task model, which is trained on both synthetic conversations and a few human conversations. The metrics are Exact Match and word-level F1 as in Choi et al. (2018).\n\n\nC Baselines\n\nPrompting. Prompting is a promising method for many NLP tasks. It aims to elicit the ability of large language models learned from pre-training with text demonstrations (e.g., task instruction and few-shot examples etc). In Table 2, we report the results from Brown et al. (2020).\n\nFinetuning. Train the small task model with only human annotations.\n\nEDA. Easy Data Augmentation (EDA) is a simple but effective method for text classification (Wei and Zou, 2019). Given an input text, including both the knowledge paragraph and dialogue history in our experiments, four operations are applied to create new examples, including synonym replacement, random insertion, random swap and random deletion. We use their open source code 9 for implementation.\n\nBack-Translation. Back-Translation is one of the most popular augmentation method for NLP tasks (Sennrich et al., 2016;Xie et al., 2020a). Specifically, we first translate the input text to a target language, then translate it back to the source language, thus we can get a paraphrased example. To get various augmentations for each sample, we use five target languages, including Chinese, French, German, Arabic, and Korean. Huawei Translate 10 is used for the translation process.\n\nUtterance Manipulation.  propose utterance-level manipulation to perturb the discourse relations in the conversation. Two simple operations are used: (1) random swapping, which randomly swaps two utterances to mess up the logic chain of the conversation, and (2) random deletion, which means randomly deleting an utterance to improve the discourse diversity. We randomly select one operation for each augmentation.\n\nDialog Inpainting. The state-of-the-art data augmentation method for conversational question answering. Given a document, they iteratively insert generated utterances between the consecutive sentences in the document, then the utterances and sentences can form an informative conversation (Dai et al., 2022). We randomly sample generated B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? Ethics Statement and Appendix A B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? Not applicable. Left blank.\n\nB5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? Appendix A B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. Appendix A and Appendix B C Did you run computational experiments? Section 3 C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? Appendix B\n\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance.\n\nFigure 2 :\n2The results of scaling up human dialogues and synthetic dialogues on QuAC. The number in the parentheses represents the number of human dialogues. similar to the observation in.\n\nFigure 3 :\n3The results of AutoConv with different LLM on QuAC. We use different scale of OPT(Zhang et al.,  2022)  as the LLM. All models are trained with 50 human dialogues for fairness and synthetic dialogues are generated with the corresponding LLM.\n\nCoQA.\nCoQA (Reddy et al., 2019)  consists of 127K conversational QA pairs across seven domains. Different from QuAC, CoQA focus more on factoid questions, and the answers are mostly named entities or short phrases as in SQuAD(Rajpurkar et al., 2016). The test set of CoQA is only available in the CoQA challenge 3 , therefore we evaluate the performance on the development set.B Implementation DetailsGeneral Setting. All experiments are based on Transformers 4(Wolf et al., 2020), DeepSpeed 5 (Rasley et al., 2020) and Pytorch Lightning 6 . We use UnifiedQA-V2-base 7(Khashabi et al., 2020(Khashabi et al.,  ,  2022 as the small task model, which is based on T5 architecture with 222M parameters and pre-trained on many QA tasks (the tasks in our experiments are not included in). The training of the small task model follows the original paper (Khashabi et al., 2020) in a Text-to-Text framework(Raffel et al.,  2020). The input is Dialogue History \\n Document and the output is System Answer.\n\n\nDid you discuss any potential risks of your work? Ethics Statement A3. Do the abstract and introduction summarize the paper's main claims? Abstract and Introduction A4. Have you used AI writing assistants when working on this paper? Left blank. B Did you use or create scientific artifacts? Appendix A and Appendix B B1. Did you cite the creators of artifacts you used? Appendix A B2. Did you discuss the license or terms for use and / or distribution of any artifacts? Not applicable. Left blank.\n\nTable 1 :\n1The differences between AutoConv and others. DG represents whether the augmentation is document grounded, and Data Needs denotes the scale of human conversations used for augmentation.\n\nTable 3 :\n3Comparison results on QuAC. Finetuning means training with only human dialogues. AutoConv uses the same human dialogues and 20K synthetic dialogues. LLM is large language model and STM is small task model. The number in the parentheses represents the number of human dialogues. These results verify the high quality of synthetic dialogues, and our AutoConv can largely alleviate the labor force for annotation.performance boosts when more human dialogues \nor synthetic dialogues are used. With 50 human \ndialogues, AutoConv outperforms the results of \nfinetuning with 200 human dialogues. With 500 hu-\nman dialogues, AutoConv gets competitive perfor-\nmance compared with finetuning with 2000 human \ndialogues. \n\nTable 4 :\n4The results of LLM with different decoding \nstrategies for answer generation on QuAC, 50 human \ndialogues are used for finetuning the LLM. \n\n0 \n350M \n1.3B \n2.7B \n6.7B \n13B \n\nModel Size (# Parameters) \n\n44 \n\n46 \n\n48 \n\n50 \n\n52 \n\nF1 Score \n\n1K Synthetic Dialogues \n4K Synthetic Dialogues \n10K Synthetic Dialogues \nNo Synthetic Dialogues \n\n\n\n\nWhat was the name of the album? Sys: The title of the album is \\\"about so much more than just my personal growth -it's about the evolution of music, the evolution of dance, the evolution of fashion.\\\" Usr: Did the album do well?Ciara: The Evolution became \nCiara\u015b first and only number one album on the U.S. \nBillboard 200, and her second number one on the \nTop R&B/Hip-Hop Albums charts with sales of \n338,000 in the first week . . . \nDialogue \n\nUsr: What was the evolution? \nSys: On December 5, 2006, Ciara released her sec-\nond studio album, Ciara: The Evolution. \nUsr: Sys: The album became Ciara's first number one \nalbum on the U.S. Billboard 200 and second on \nthe Top R&B/Hip-Hop Albums charts with sales \nof more than 338,000. \nUsr: What awards did she win if any? \nSys: The album went on to be certified platinum \nby the RIAA in the United States, within only five \nweeks of its release, and has sold 1.3 million copies \naccording to Nielsen SoundScan. \nUsr: What else did she accomplish during that \ntime? \nSys: In support of the album, Ciara went on her \nfirst headlining tour in October 2006. \nUsr: How long was the tour? \nSys: The tour went to seventeen different clubs in \ncities throughout the United States. \nUsr: Did she have success with any songs? \nSys: The lead single, \\\"Get Up\\\", which fea-\ntures Chamillionaire, reached number seven in the \nUnited States and gained a platinum accreditation. \n\n\n\nTable 5 :\n5An example of the synthetic conversation generated by AutoConv, the LLM is finetuned with 50 human dialogues from QuAC(Choi et al., 2018).\nIn our preliminary experiments, we try to prompt LLM without training. However, we find that the performance is poor and LLM fails to generate conversations grounded on the documents, similar to the observation in.\nhttps://quac.ai/ 3 https://stanfordnlp.github.io/coqa/ 4 https://huggingface.co/docs/transformers/ index 5 https://github.com/microsoft/DeepSpeed 6 https://github.com/Lightning-AI/lightning 7 https://huggingface.co/allenai/ unifiedqa-v2-t5-base-1363200\nhttps://huggingface.co/facebook/opt-13b\nhttps://github.com/jasonwei20/eda_nlp 10 https://www.huaweicloud.com/product/nlpmt. html dialogues from their open source data 11 . 11 https://github.com/google-research/ dialog-inpainting\nAcknowledgementsThis work was partly supported by the National Key Research and Development Program of China (No. 2020YFB1708200) , the \"Graph Neural Network Project\" of Ping An Technology (Shenzhen) Co., Ltd. and AMiner.Shenzhen SciBrain fund.D1. Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators, etc.? Not applicable. Left blank.D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)? Not applicable. Left blank.D3. Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used? Not applicable. Left blank.D4. Was the data collection protocol approved (or determined exempt) by an ethics review board? Not applicable. Left blank.D5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data? Not applicable. Left blank.\nAlec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish; NeurIPSvirtualTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.\n\nAn empirical survey of data augmentation for limited data learning in NLP. Jiaao Chen, Derek Tam, Colin Raffel, Mohit Bansal, Diyi Yang, abs/2106.07499CoRRJiaao Chen, Derek Tam, Colin Raffel, Mohit Bansal, and Diyi Yang. 2021. An empirical survey of data aug- mentation for limited data learning in NLP. CoRR, abs/2106.07499.\n\nSimple conversational data augmentation for semi-supervised abstractive dialogue summarization. Jiaao Chen, Diyi Yang, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican Republic2021Virtual Event / Punta Cana. Association for Computational LinguisticsJiaao Chen and Diyi Yang. 2021. Simple conversa- tional data augmentation for semi-supervised abstrac- tive dialogue summarization. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, pages 6605-6616. Association for Computa- tional Linguistics.\n\nQuac: Question answering in context. Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wentau Yih, Yejin Choi, Percy Liang, Luke Zettlemoyer, Association for Computational Linguistics. of the Association for Computational Linguistics: EMNLP 2021, Virtual Event. Belgium; Punta Cana, Dominican RepublicAssociation for Computational LinguisticsProceedings of the 2018 Conference on Empirical Methods in Natural Language ProcessingEunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen- tau Yih, Yejin Choi, Percy Liang, and Luke Zettle- moyer. 2018. Quac: Question answering in context. In Proceedings of the 2018 Conference on Empiri- cal Methods in Natural Language Processing, Brus- sels, Belgium, October 31 -November 4, 2018, pages 2174-2184. Association for Computational Linguis- tics. of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Domini- can Republic, 16-20 November, 2021, pages 3784- 3803. Association for Computational Linguistics.\n\nInformation-seeking chat: Dialogues driven by topic-structure. Manfred Stede, David Schlangen, Proceedings of Catalog (the. Catalog (theManfred Stede and David Schlangen. 2004. Information-seeking chat: Dialogues driven by topic-structure. In Proceedings of Catalog (the\n\n2022. A contrastive framework for neural text generation. Yixuan Su, Tian Lan, Yan Wang, Dani Yogatama, Lingpeng Kong, Nigel Collier, abs/2202.06417CoRRYixuan Su, Tian Lan, Yan Wang, Dani Yogatama, Lingpeng Kong, and Nigel Collier. 2022. A con- trastive framework for neural text generation. CoRR, abs/2202.06417.\n\nOn the safety of conversational models: Taxonomy, dataset, and benchmark. Hao Sun, Guangxuan Xu, Jiawen Deng, Jiale Cheng, Chujie Zheng, Hao Zhou, Nanyun Peng, Xiaoyan Zhu, Minlie Huang, Findings of the Association for Computational Linguistics: ACL 2022. Dublin, IrelandAssociation for Computational LinguisticsHao Sun, Guangxuan Xu, Jiawen Deng, Jiale Cheng, Chujie Zheng, Hao Zhou, Nanyun Peng, Xiaoyan Zhu, and Minlie Huang. 2022. On the safety of con- versational models: Taxonomy, dataset, and bench- mark. In Findings of the Association for Computa- tional Linguistics: ACL 2022, Dublin, Ireland, May 22-27, 2022, pages 3906-3923. Association for Com- putational Linguistics.\n\nEDA: easy data augmentation techniques for boosting performance on text classification tasks. Jason W Wei, Kai Zou, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ProcessingHong Kong, ChinaAssociation for Computational LinguisticsJason W. Wei and Kai Zou. 2019. EDA: easy data augmentation techniques for boosting performance on text classification tasks. In Proceedings of the 2019 Conference on Empirical Methods in Natu- ral Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, Novem- ber 3-7, 2019, pages 6381-6387. Association for Computational Linguistics.\n\nSymbolic knowledge distillation: from general language models to commonsense models. Peter West, Chandra Bhagavatula, Jack Hessel, Jena D Hwang, Liwei Jiang, Ximing Ronan Le Bras, Sean Lu, Yejin Welleck, Choi, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022Seattle, WA, United StatesAssociation for Computational LinguisticsPeter West, Chandra Bhagavatula, Jack Hessel, Jena D. Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu, Sean Welleck, and Yejin Choi. 2022. Symbolic knowledge distillation: from general language mod- els to commonsense models. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Hu- man Language Technologies, NAACL 2022, Seattle, WA, United States, July 10-15, 2022, pages 4602- 4625. Association for Computational Linguistics.\n\nTransformers: State-of-the-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Le Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander M Lhoest, Rush, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, EMNLP 2020 -Demos. the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, EMNLP 2020 -DemosOnlineAssociation for Computational LinguisticsThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2020. Transformers: State-of-the-art natural language processing. In Pro- ceedings of the 2020 Conference on Empirical Meth- ods in Natural Language Processing: System Demon- strations, EMNLP 2020 -Demos, Online, November 16-20, 2020, pages 38-45. Association for Computa- tional Linguistics.\n\nDG2: data augmentation through document grounded dialogue generation. Qingyang Wu, Song Feng, Derek Chen, Sachindra Joshi, Luis A Lastras, Zhou Yu, abs/2112.08342CoRRQingyang Wu, Song Feng, Derek Chen, Sachindra Joshi, Luis A. Lastras, and Zhou Yu. 2021. DG2: data augmentation through document grounded dialogue generation. CoRR, abs/2112.08342.\n\nUnsupervised data augmentation for consistency training. Qizhe Xie, Zihang Dai, Eduard H Hovy, Thang Luong, Quoc Le, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020. 2020virtualQizhe Xie, Zihang Dai, Eduard H. Hovy, Thang Luong, and Quoc Le. 2020a. Unsupervised data augmenta- tion for consistency training. In Advances in Neural Information Processing Systems 33: Annual Confer- ence on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.\n\nSelf-training with noisy student improves imagenet classification. Qizhe Xie, Minh-Thang Luong, Eduard H Hovy, V Quoc, Le, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Seattle, WA, USAIEEE2020Computer Vision FoundationQizhe Xie, Minh-Thang Luong, Eduard H. Hovy, and Quoc V. Le. 2020b. Self-training with noisy student improves imagenet classification. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recog- nition, CVPR 2020, Seattle, WA, USA, June 13-19, 2020, pages 10684-10695. Computer Vision Founda- tion / IEEE.\n\nLearning to break the loop: Analyzing and mitigating repetitions for neural text generation. Jin Xu, Xiaojiang Liu, Jianhao Yan, Deng Cai, Huayang Li, Jian Li, abs/2206.02369CoRRJin Xu, Xiaojiang Liu, Jianhao Yan, Deng Cai, Huayang Li, and Jian Li. 2022. Learning to break the loop: Analyzing and mitigating repetitions for neural text generation. CoRR, abs/2206.02369.\n\nRecipes for safety in open-domain chatbots. Jing Xu, Da Ju, Margaret Li, Y-Lan Boureau, Jason Weston, Emily Dinan, abs/2010.07079CoRRJing Xu, Da Ju, Margaret Li, Y-Lan Boureau, Jason Weston, and Emily Dinan. 2020. Recipes for safety in open-domain chatbots. CoRR, abs/2010.07079.\n\nZerogen: Efficient zero-shot learning via dataset generation. Jiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, Lingpeng Kong, abs/2202.07922CoRRJiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, and Lingpeng Kong. 2022. Zerogen: Efficient zero-shot learning via dataset generation. CoRR, abs/2202.07922.\n\n. Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Peng Zhang, Yuxiao Dong, and Jie Tang. 2022. GLM-130B: an open bilingual pre-trained model. CoRR, abs/2210.02414Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Peng Zhang, Yuxiao Dong, and Jie Tang. 2022. GLM- 130B: an open bilingual pre-trained model. CoRR, abs/2210.02414.\n\n. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona T Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer2022. OPT: open pre-trained transformer language models. CoRR, abs/2205.01068Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona T. Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shus- ter, Daniel Simig, Punit Singh Koura, Anjali Srid- har, Tianlu Wang, and Luke Zettlemoyer. 2022. OPT: open pre-trained transformer language mod- els. CoRR, abs/2205.01068.\n\nAugesc: Large-scale data augmentation for emotional support conversation with pretrained language models. Chujie Zheng, Sahand Sabour, Jiaxin Wen, Minlie Huang, abs/2202.13047CoRRChujie Zheng, Sahand Sabour, Jiaxin Wen, and Minlie Huang. 2022. Augesc: Large-scale data augmen- tation for emotional support conversation with pre- trained language models. CoRR, abs/2202.13047.\n\nDid you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? Appendix B. C2C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? Appendix B\n\nerror bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. C3. Did you report descriptive statistics about your results. or just a single run? Section 3C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run? Section 3\n\nNltk, Spacy, Rouge, C4. If you used existing packages (e.g., for preprocessing, for normalization. did you report the implementation, model, and parameter settings usedC4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)?\n", "annotations": {"author": "[{\"end\":219,\"start\":148},{\"end\":292,\"start\":220},{\"end\":304,\"start\":293},{\"end\":376,\"start\":305},{\"end\":409,\"start\":377},{\"end\":423,\"start\":410},{\"end\":434,\"start\":424},{\"end\":462,\"start\":435},{\"end\":565,\"start\":463}]", "publisher": "[{\"end\":109,\"start\":97},{\"end\":835,\"start\":823}]", "author_last_name": "[{\"end\":157,\"start\":155},{\"end\":230,\"start\":226},{\"end\":303,\"start\":300},{\"end\":314,\"start\":311},{\"end\":388,\"start\":383},{\"end\":422,\"start\":417},{\"end\":433,\"start\":428},{\"end\":442,\"start\":439},{\"end\":473,\"start\":469}]", "author_first_name": "[{\"end\":154,\"start\":148},{\"end\":225,\"start\":220},{\"end\":299,\"start\":293},{\"end\":310,\"start\":305},{\"end\":382,\"start\":377},{\"end\":416,\"start\":410},{\"end\":427,\"start\":424},{\"end\":438,\"start\":435},{\"end\":468,\"start\":463}]", "author_affiliation": "[{\"end\":218,\"start\":159},{\"end\":291,\"start\":232},{\"end\":375,\"start\":316},{\"end\":408,\"start\":390},{\"end\":564,\"start\":505}]", "title": "[{\"end\":96,\"start\":1},{\"end\":661,\"start\":566}]", "venue": "[{\"end\":750,\"start\":663}]", "abstract": "[{\"end\":1951,\"start\":876}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2165,\"start\":2138},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2183,\"start\":2165},{\"end\":2202,\"start\":2183},{\"end\":2344,\"start\":2326},{\"end\":2703,\"start\":2686},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2721,\"start\":2703},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2766,\"start\":2747},{\"end\":2825,\"start\":2802},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3091,\"start\":3074},{\"end\":3108,\"start\":3091},{\"end\":3396,\"start\":3379},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3976,\"start\":3956},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4759,\"start\":4740},{\"end\":4789,\"start\":4764},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5790,\"start\":5771},{\"end\":6403,\"start\":6380},{\"end\":6525,\"start\":6508},{\"end\":6681,\"start\":6659},{\"end\":7010,\"start\":6994},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7195,\"start\":7176},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7474,\"start\":7455},{\"end\":7504,\"start\":7479},{\"end\":7823,\"start\":7803},{\"end\":7887,\"start\":7864},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8256,\"start\":8236},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8304,\"start\":8284},{\"end\":9140,\"start\":9116},{\"end\":9294,\"start\":9275},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9491,\"start\":9472},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10588,\"start\":10569},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11240,\"start\":11222},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11258,\"start\":11242},{\"end\":11779,\"start\":11762},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13856,\"start\":13837},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15798,\"start\":15779},{\"end\":15828,\"start\":15803},{\"end\":15964,\"start\":15944},{\"end\":16183,\"start\":16157},{\"end\":16214,\"start\":16194},{\"end\":16246,\"start\":16216},{\"end\":16280,\"start\":16261},{\"end\":16973,\"start\":16951},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17473,\"start\":17456},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":17570,\"start\":17552},{\"end\":18170,\"start\":18149},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":18387,\"start\":18368},{\"end\":19347,\"start\":19327},{\"end\":19560,\"start\":19539},{\"end\":20214,\"start\":20198},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":20706,\"start\":20688},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21002,\"start\":20983},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21184,\"start\":21165},{\"end\":21593,\"start\":21570},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":21611,\"start\":21593},{\"end\":22681,\"start\":22663},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25308,\"start\":25289},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":29163,\"start\":29144}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":24571,\"start\":24381},{\"attributes\":{\"id\":\"fig_2\"},\"end\":24826,\"start\":24572},{\"attributes\":{\"id\":\"fig_3\"},\"end\":25823,\"start\":24827},{\"attributes\":{\"id\":\"fig_4\"},\"end\":26323,\"start\":25824},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":26520,\"start\":26324},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":27243,\"start\":26521},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":27592,\"start\":27244},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":29013,\"start\":27593},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":29164,\"start\":29014}]", "paragraph": "[{\"end\":2563,\"start\":1967},{\"end\":4275,\"start\":2565},{\"end\":4449,\"start\":4285},{\"end\":5376,\"start\":4451},{\"end\":5599,\"start\":5406},{\"end\":5962,\"start\":5627},{\"end\":6153,\"start\":6015},{\"end\":7070,\"start\":6155},{\"end\":7408,\"start\":7072},{\"end\":7554,\"start\":7424},{\"end\":8048,\"start\":7573},{\"end\":8177,\"start\":8078},{\"end\":8744,\"start\":8193},{\"end\":9658,\"start\":8746},{\"end\":10260,\"start\":9660},{\"end\":10464,\"start\":10315},{\"end\":11361,\"start\":10515},{\"end\":12027,\"start\":11393},{\"end\":12557,\"start\":12044},{\"end\":12922,\"start\":12572},{\"end\":12929,\"start\":12924},{\"end\":13607,\"start\":12991},{\"end\":14217,\"start\":13626},{\"end\":14288,\"start\":14219},{\"end\":14635,\"start\":14290},{\"end\":15037,\"start\":14637},{\"end\":15552,\"start\":15052},{\"end\":15886,\"start\":15568},{\"end\":16285,\"start\":15909},{\"end\":16508,\"start\":16287},{\"end\":16786,\"start\":16510},{\"end\":17526,\"start\":16807},{\"end\":19302,\"start\":17541},{\"end\":20401,\"start\":19304},{\"end\":20707,\"start\":20417},{\"end\":21003,\"start\":20723},{\"end\":21072,\"start\":21005},{\"end\":21472,\"start\":21074},{\"end\":21956,\"start\":21474},{\"end\":22372,\"start\":21958},{\"end\":23375,\"start\":22374},{\"end\":24246,\"start\":23377},{\"end\":24380,\"start\":24248}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":6014,\"start\":5963}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":4664,\"start\":4657},{\"end\":8317,\"start\":8310},{\"end\":8762,\"start\":8755},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":10871,\"start\":10864},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":11656,\"start\":11649},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":12582,\"start\":12575},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":14447,\"start\":14440},{\"end\":16564,\"start\":16557},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":17184,\"start\":17177},{\"end\":20954,\"start\":20947}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1965,\"start\":1953},{\"end\":4283,\"start\":4278},{\"attributes\":{\"n\":\"2\"},\"end\":5385,\"start\":5379},{\"attributes\":{\"n\":\"2.1\"},\"end\":5404,\"start\":5388},{\"attributes\":{\"n\":\"2.2\"},\"end\":5625,\"start\":5602},{\"attributes\":{\"n\":\"3\"},\"end\":7422,\"start\":7411},{\"attributes\":{\"n\":\"3.1\"},\"end\":7571,\"start\":7557},{\"attributes\":{\"n\":\"3.2\"},\"end\":8076,\"start\":8051},{\"end\":8191,\"start\":8180},{\"attributes\":{\"n\":\"3.3\"},\"end\":10313,\"start\":10263},{\"attributes\":{\"n\":\"3.4\"},\"end\":10513,\"start\":10467},{\"attributes\":{\"n\":\"3.5\"},\"end\":11391,\"start\":11364},{\"attributes\":{\"n\":\"3.6\"},\"end\":12042,\"start\":12030},{\"attributes\":{\"n\":\"3.7\"},\"end\":12570,\"start\":12560},{\"end\":12989,\"start\":12932},{\"attributes\":{\"n\":\"3.8\"},\"end\":13624,\"start\":13610},{\"attributes\":{\"n\":\"4\"},\"end\":15050,\"start\":15040},{\"end\":15566,\"start\":15555},{\"end\":15907,\"start\":15889},{\"end\":16805,\"start\":16789},{\"end\":17539,\"start\":17529},{\"end\":20415,\"start\":20404},{\"end\":20721,\"start\":20710},{\"end\":24392,\"start\":24382},{\"end\":24583,\"start\":24573},{\"end\":24833,\"start\":24828},{\"end\":26334,\"start\":26325},{\"end\":26531,\"start\":26522},{\"end\":27254,\"start\":27245},{\"end\":29024,\"start\":29015}]", "table": "[{\"end\":27243,\"start\":26943},{\"end\":27592,\"start\":27256},{\"end\":29013,\"start\":27823}]", "figure_caption": "[{\"end\":24571,\"start\":24394},{\"end\":24826,\"start\":24585},{\"end\":25823,\"start\":24834},{\"end\":26323,\"start\":25826},{\"end\":26520,\"start\":26336},{\"end\":26943,\"start\":26533},{\"end\":27823,\"start\":27595},{\"end\":29164,\"start\":29026}]", "figure_ref": "[{\"end\":4309,\"start\":4301},{\"end\":6271,\"start\":6263},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":10457,\"start\":10449},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":12145,\"start\":12136}]", "bib_author_first_name": "[{\"end\":31185,\"start\":31182},{\"end\":31187,\"start\":31186},{\"end\":31203,\"start\":31195},{\"end\":31214,\"start\":31210},{\"end\":31229,\"start\":31222},{\"end\":31244,\"start\":31239},{\"end\":31261,\"start\":31253},{\"end\":31278,\"start\":31272},{\"end\":31298,\"start\":31292},{\"end\":31312,\"start\":31306},{\"end\":31327,\"start\":31321},{\"end\":31344,\"start\":31336},{\"end\":31359,\"start\":31354},{\"end\":31382,\"start\":31374},{\"end\":31395,\"start\":31392},{\"end\":31411,\"start\":31406},{\"end\":31425,\"start\":31419},{\"end\":31440,\"start\":31434},{\"end\":31442,\"start\":31441},{\"end\":31459,\"start\":31452},{\"end\":31471,\"start\":31464},{\"end\":31491,\"start\":31480},{\"end\":31503,\"start\":31499},{\"end\":31514,\"start\":31510},{\"end\":31530,\"start\":31523},{\"end\":32527,\"start\":32522},{\"end\":32539,\"start\":32534},{\"end\":32550,\"start\":32545},{\"end\":32564,\"start\":32559},{\"end\":32577,\"start\":32573},{\"end\":32875,\"start\":32870},{\"end\":32886,\"start\":32882},{\"end\":33553,\"start\":33547},{\"end\":33562,\"start\":33560},{\"end\":33572,\"start\":33567},{\"end\":33584,\"start\":33580},{\"end\":33600,\"start\":33594},{\"end\":33611,\"start\":33606},{\"end\":33623,\"start\":33618},{\"end\":33635,\"start\":33631},{\"end\":34560,\"start\":34553},{\"end\":34573,\"start\":34568},{\"end\":34826,\"start\":34820},{\"end\":34835,\"start\":34831},{\"end\":34844,\"start\":34841},{\"end\":34855,\"start\":34851},{\"end\":34874,\"start\":34866},{\"end\":34886,\"start\":34881},{\"end\":35154,\"start\":35151},{\"end\":35169,\"start\":35160},{\"end\":35180,\"start\":35174},{\"end\":35192,\"start\":35187},{\"end\":35206,\"start\":35200},{\"end\":35217,\"start\":35214},{\"end\":35230,\"start\":35224},{\"end\":35244,\"start\":35237},{\"end\":35256,\"start\":35250},{\"end\":35860,\"start\":35855},{\"end\":35862,\"start\":35861},{\"end\":35871,\"start\":35868},{\"end\":36744,\"start\":36739},{\"end\":36758,\"start\":36751},{\"end\":36776,\"start\":36772},{\"end\":36789,\"start\":36785},{\"end\":36791,\"start\":36790},{\"end\":36804,\"start\":36799},{\"end\":36818,\"start\":36812},{\"end\":36838,\"start\":36834},{\"end\":36848,\"start\":36843},{\"end\":37784,\"start\":37778},{\"end\":37799,\"start\":37791},{\"end\":37813,\"start\":37807},{\"end\":37826,\"start\":37820},{\"end\":37844,\"start\":37837},{\"end\":37862,\"start\":37855},{\"end\":37875,\"start\":37868},{\"end\":37887,\"start\":37884},{\"end\":37899,\"start\":37895},{\"end\":37912,\"start\":37906},{\"end\":37927,\"start\":37924},{\"end\":37940,\"start\":37937},{\"end\":37956,\"start\":37951},{\"end\":37983,\"start\":37977},{\"end\":37994,\"start\":37988},{\"end\":38010,\"start\":38004},{\"end\":38021,\"start\":38016},{\"end\":38024,\"start\":38022},{\"end\":38036,\"start\":38029},{\"end\":38050,\"start\":38043},{\"end\":38066,\"start\":38059},{\"end\":38083,\"start\":38074},{\"end\":38085,\"start\":38084},{\"end\":39091,\"start\":39083},{\"end\":39100,\"start\":39096},{\"end\":39112,\"start\":39107},{\"end\":39128,\"start\":39119},{\"end\":39140,\"start\":39136},{\"end\":39142,\"start\":39141},{\"end\":39156,\"start\":39152},{\"end\":39423,\"start\":39418},{\"end\":39435,\"start\":39429},{\"end\":39447,\"start\":39441},{\"end\":39449,\"start\":39448},{\"end\":39461,\"start\":39456},{\"end\":39473,\"start\":39469},{\"end\":39980,\"start\":39975},{\"end\":39996,\"start\":39986},{\"end\":40010,\"start\":40004},{\"end\":40012,\"start\":40011},{\"end\":40020,\"start\":40019},{\"end\":40559,\"start\":40556},{\"end\":40573,\"start\":40564},{\"end\":40586,\"start\":40579},{\"end\":40596,\"start\":40592},{\"end\":40609,\"start\":40602},{\"end\":40618,\"start\":40614},{\"end\":40882,\"start\":40878},{\"end\":40889,\"start\":40887},{\"end\":40902,\"start\":40894},{\"end\":40912,\"start\":40907},{\"end\":40927,\"start\":40922},{\"end\":40941,\"start\":40936},{\"end\":41185,\"start\":41177},{\"end\":41196,\"start\":41190},{\"end\":41209,\"start\":41202},{\"end\":41218,\"start\":41214},{\"end\":41231,\"start\":41223},{\"end\":41245,\"start\":41238},{\"end\":41253,\"start\":41250},{\"end\":41266,\"start\":41258},{\"end\":41489,\"start\":41484},{\"end\":41500,\"start\":41496},{\"end\":41515,\"start\":41506},{\"end\":41525,\"start\":41520},{\"end\":41537,\"start\":41532},{\"end\":41547,\"start\":41543},{\"end\":41560,\"start\":41554},{\"end\":41572,\"start\":41567},{\"end\":41582,\"start\":41577},{\"end\":41594,\"start\":41590},{\"end\":41608,\"start\":41600},{\"end\":41620,\"start\":41614},{\"end\":41630,\"start\":41625},{\"end\":41642,\"start\":41636},{\"end\":41657,\"start\":41649},{\"end\":41668,\"start\":41664},{\"end\":41682,\"start\":41676},{\"end\":42079,\"start\":42074},{\"end\":42094,\"start\":42087},{\"end\":42108,\"start\":42103},{\"end\":42121,\"start\":42116},{\"end\":42135,\"start\":42131},{\"end\":42149,\"start\":42142},{\"end\":42167,\"start\":42156},{\"end\":42179,\"start\":42175},{\"end\":42181,\"start\":42180},{\"end\":42192,\"start\":42188},{\"end\":42199,\"start\":42197},{\"end\":42219,\"start\":42214},{\"end\":42234,\"start\":42230},{\"end\":42243,\"start\":42240},{\"end\":42904,\"start\":42898},{\"end\":42918,\"start\":42912},{\"end\":42933,\"start\":42927},{\"end\":42945,\"start\":42939}]", "bib_author_last_name": "[{\"end\":31193,\"start\":31188},{\"end\":31208,\"start\":31204},{\"end\":31220,\"start\":31215},{\"end\":31237,\"start\":31230},{\"end\":31251,\"start\":31245},{\"end\":31270,\"start\":31262},{\"end\":31290,\"start\":31279},{\"end\":31304,\"start\":31299},{\"end\":31319,\"start\":31313},{\"end\":31334,\"start\":31328},{\"end\":31352,\"start\":31345},{\"end\":31372,\"start\":31360},{\"end\":31390,\"start\":31383},{\"end\":31404,\"start\":31396},{\"end\":31417,\"start\":31412},{\"end\":31432,\"start\":31426},{\"end\":31450,\"start\":31443},{\"end\":31462,\"start\":31460},{\"end\":31478,\"start\":31472},{\"end\":31497,\"start\":31492},{\"end\":31508,\"start\":31504},{\"end\":31521,\"start\":31515},{\"end\":31537,\"start\":31531},{\"end\":32532,\"start\":32528},{\"end\":32543,\"start\":32540},{\"end\":32557,\"start\":32551},{\"end\":32571,\"start\":32565},{\"end\":32582,\"start\":32578},{\"end\":32880,\"start\":32876},{\"end\":32891,\"start\":32887},{\"end\":33558,\"start\":33554},{\"end\":33565,\"start\":33563},{\"end\":33578,\"start\":33573},{\"end\":33592,\"start\":33585},{\"end\":33604,\"start\":33601},{\"end\":33616,\"start\":33612},{\"end\":33629,\"start\":33624},{\"end\":33647,\"start\":33636},{\"end\":34566,\"start\":34561},{\"end\":34583,\"start\":34574},{\"end\":34829,\"start\":34827},{\"end\":34839,\"start\":34836},{\"end\":34849,\"start\":34845},{\"end\":34864,\"start\":34856},{\"end\":34879,\"start\":34875},{\"end\":34894,\"start\":34887},{\"end\":35158,\"start\":35155},{\"end\":35172,\"start\":35170},{\"end\":35185,\"start\":35181},{\"end\":35198,\"start\":35193},{\"end\":35212,\"start\":35207},{\"end\":35222,\"start\":35218},{\"end\":35235,\"start\":35231},{\"end\":35248,\"start\":35245},{\"end\":35262,\"start\":35257},{\"end\":35866,\"start\":35863},{\"end\":35875,\"start\":35872},{\"end\":36749,\"start\":36745},{\"end\":36770,\"start\":36759},{\"end\":36783,\"start\":36777},{\"end\":36797,\"start\":36792},{\"end\":36810,\"start\":36805},{\"end\":36832,\"start\":36819},{\"end\":36841,\"start\":36839},{\"end\":36856,\"start\":36849},{\"end\":36862,\"start\":36858},{\"end\":37789,\"start\":37785},{\"end\":37805,\"start\":37800},{\"end\":37818,\"start\":37814},{\"end\":37835,\"start\":37827},{\"end\":37853,\"start\":37845},{\"end\":37866,\"start\":37863},{\"end\":37882,\"start\":37876},{\"end\":37893,\"start\":37888},{\"end\":37904,\"start\":37900},{\"end\":37922,\"start\":37913},{\"end\":37935,\"start\":37928},{\"end\":37949,\"start\":37941},{\"end\":37975,\"start\":37957},{\"end\":37986,\"start\":37984},{\"end\":38002,\"start\":37995},{\"end\":38014,\"start\":38011},{\"end\":38027,\"start\":38025},{\"end\":38041,\"start\":38037},{\"end\":38057,\"start\":38051},{\"end\":38072,\"start\":38067},{\"end\":38092,\"start\":38086},{\"end\":38098,\"start\":38094},{\"end\":39094,\"start\":39092},{\"end\":39105,\"start\":39101},{\"end\":39117,\"start\":39113},{\"end\":39134,\"start\":39129},{\"end\":39150,\"start\":39143},{\"end\":39159,\"start\":39157},{\"end\":39427,\"start\":39424},{\"end\":39439,\"start\":39436},{\"end\":39454,\"start\":39450},{\"end\":39467,\"start\":39462},{\"end\":39476,\"start\":39474},{\"end\":39984,\"start\":39981},{\"end\":40002,\"start\":39997},{\"end\":40017,\"start\":40013},{\"end\":40025,\"start\":40021},{\"end\":40029,\"start\":40027},{\"end\":40562,\"start\":40560},{\"end\":40577,\"start\":40574},{\"end\":40590,\"start\":40587},{\"end\":40600,\"start\":40597},{\"end\":40612,\"start\":40610},{\"end\":40621,\"start\":40619},{\"end\":40885,\"start\":40883},{\"end\":40892,\"start\":40890},{\"end\":40905,\"start\":40903},{\"end\":40920,\"start\":40913},{\"end\":40934,\"start\":40928},{\"end\":40947,\"start\":40942},{\"end\":41188,\"start\":41186},{\"end\":41200,\"start\":41197},{\"end\":41212,\"start\":41210},{\"end\":41221,\"start\":41219},{\"end\":41236,\"start\":41232},{\"end\":41248,\"start\":41246},{\"end\":41256,\"start\":41254},{\"end\":41271,\"start\":41267},{\"end\":41494,\"start\":41490},{\"end\":41504,\"start\":41501},{\"end\":41518,\"start\":41516},{\"end\":41530,\"start\":41526},{\"end\":41541,\"start\":41538},{\"end\":41552,\"start\":41548},{\"end\":41565,\"start\":41561},{\"end\":41575,\"start\":41573},{\"end\":41588,\"start\":41583},{\"end\":41598,\"start\":41595},{\"end\":41612,\"start\":41609},{\"end\":41623,\"start\":41621},{\"end\":41634,\"start\":41631},{\"end\":41647,\"start\":41643},{\"end\":41662,\"start\":41658},{\"end\":41674,\"start\":41669},{\"end\":41687,\"start\":41683},{\"end\":42085,\"start\":42080},{\"end\":42101,\"start\":42095},{\"end\":42114,\"start\":42109},{\"end\":42129,\"start\":42122},{\"end\":42140,\"start\":42136},{\"end\":42154,\"start\":42150},{\"end\":42173,\"start\":42168},{\"end\":42186,\"start\":42182},{\"end\":42195,\"start\":42193},{\"end\":42212,\"start\":42200},{\"end\":42228,\"start\":42220},{\"end\":42238,\"start\":42235},{\"end\":42252,\"start\":42244},{\"end\":42910,\"start\":42905},{\"end\":42925,\"start\":42919},{\"end\":42937,\"start\":42934},{\"end\":42951,\"start\":42946},{\"end\":43899,\"start\":43895},{\"end\":43906,\"start\":43901},{\"end\":43913,\"start\":43908}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":218971783},\"end\":32445,\"start\":31089},{\"attributes\":{\"doi\":\"abs/2106.07499\",\"id\":\"b1\"},\"end\":32772,\"start\":32447},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":243865654},\"end\":33508,\"start\":32774},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":52057510},\"end\":34488,\"start\":33510},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":60671162},\"end\":34760,\"start\":34490},{\"attributes\":{\"doi\":\"abs/2202.06417\",\"id\":\"b5\"},\"end\":35075,\"start\":34762},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":239016893},\"end\":35759,\"start\":35077},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":59523656},\"end\":36652,\"start\":35761},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":238857304},\"end\":37716,\"start\":36654},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":208117506},\"end\":39011,\"start\":37718},{\"attributes\":{\"doi\":\"abs/2112.08342\",\"id\":\"b10\"},\"end\":39359,\"start\":39013},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":195873898},\"end\":39906,\"start\":39361},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":207853355},\"end\":40461,\"start\":39908},{\"attributes\":{\"doi\":\"abs/2206.02369\",\"id\":\"b13\"},\"end\":40832,\"start\":40463},{\"attributes\":{\"doi\":\"abs/2010.07079\",\"id\":\"b14\"},\"end\":41113,\"start\":40834},{\"attributes\":{\"doi\":\"abs/2202.07922\",\"id\":\"b15\"},\"end\":41480,\"start\":41115},{\"attributes\":{\"id\":\"b16\"},\"end\":42070,\"start\":41482},{\"attributes\":{\"id\":\"b17\"},\"end\":42790,\"start\":42072},{\"attributes\":{\"doi\":\"abs/2202.13047\",\"id\":\"b18\"},\"end\":43167,\"start\":42792},{\"attributes\":{\"id\":\"b19\"},\"end\":43417,\"start\":43169},{\"attributes\":{\"id\":\"b20\"},\"end\":43893,\"start\":43419},{\"attributes\":{\"id\":\"b21\"},\"end\":44265,\"start\":43895}]", "bib_title": "[{\"end\":31180,\"start\":31089},{\"end\":32868,\"start\":32774},{\"end\":33545,\"start\":33510},{\"end\":34551,\"start\":34490},{\"end\":35149,\"start\":35077},{\"end\":35853,\"start\":35761},{\"end\":36737,\"start\":36654},{\"end\":37776,\"start\":37718},{\"end\":39416,\"start\":39361},{\"end\":39973,\"start\":39908},{\"end\":43558,\"start\":43419}]", "bib_author": "[{\"end\":31195,\"start\":31182},{\"end\":31210,\"start\":31195},{\"end\":31222,\"start\":31210},{\"end\":31239,\"start\":31222},{\"end\":31253,\"start\":31239},{\"end\":31272,\"start\":31253},{\"end\":31292,\"start\":31272},{\"end\":31306,\"start\":31292},{\"end\":31321,\"start\":31306},{\"end\":31336,\"start\":31321},{\"end\":31354,\"start\":31336},{\"end\":31374,\"start\":31354},{\"end\":31392,\"start\":31374},{\"end\":31406,\"start\":31392},{\"end\":31419,\"start\":31406},{\"end\":31434,\"start\":31419},{\"end\":31452,\"start\":31434},{\"end\":31464,\"start\":31452},{\"end\":31480,\"start\":31464},{\"end\":31499,\"start\":31480},{\"end\":31510,\"start\":31499},{\"end\":31523,\"start\":31510},{\"end\":31539,\"start\":31523},{\"end\":32534,\"start\":32522},{\"end\":32545,\"start\":32534},{\"end\":32559,\"start\":32545},{\"end\":32573,\"start\":32559},{\"end\":32584,\"start\":32573},{\"end\":32882,\"start\":32870},{\"end\":32893,\"start\":32882},{\"end\":33560,\"start\":33547},{\"end\":33567,\"start\":33560},{\"end\":33580,\"start\":33567},{\"end\":33594,\"start\":33580},{\"end\":33606,\"start\":33594},{\"end\":33618,\"start\":33606},{\"end\":33631,\"start\":33618},{\"end\":33649,\"start\":33631},{\"end\":34568,\"start\":34553},{\"end\":34585,\"start\":34568},{\"end\":34831,\"start\":34820},{\"end\":34841,\"start\":34831},{\"end\":34851,\"start\":34841},{\"end\":34866,\"start\":34851},{\"end\":34881,\"start\":34866},{\"end\":34896,\"start\":34881},{\"end\":35160,\"start\":35151},{\"end\":35174,\"start\":35160},{\"end\":35187,\"start\":35174},{\"end\":35200,\"start\":35187},{\"end\":35214,\"start\":35200},{\"end\":35224,\"start\":35214},{\"end\":35237,\"start\":35224},{\"end\":35250,\"start\":35237},{\"end\":35264,\"start\":35250},{\"end\":35868,\"start\":35855},{\"end\":35877,\"start\":35868},{\"end\":36751,\"start\":36739},{\"end\":36772,\"start\":36751},{\"end\":36785,\"start\":36772},{\"end\":36799,\"start\":36785},{\"end\":36812,\"start\":36799},{\"end\":36834,\"start\":36812},{\"end\":36843,\"start\":36834},{\"end\":36858,\"start\":36843},{\"end\":36864,\"start\":36858},{\"end\":37791,\"start\":37778},{\"end\":37807,\"start\":37791},{\"end\":37820,\"start\":37807},{\"end\":37837,\"start\":37820},{\"end\":37855,\"start\":37837},{\"end\":37868,\"start\":37855},{\"end\":37884,\"start\":37868},{\"end\":37895,\"start\":37884},{\"end\":37906,\"start\":37895},{\"end\":37924,\"start\":37906},{\"end\":37937,\"start\":37924},{\"end\":37951,\"start\":37937},{\"end\":37977,\"start\":37951},{\"end\":37988,\"start\":37977},{\"end\":38004,\"start\":37988},{\"end\":38016,\"start\":38004},{\"end\":38029,\"start\":38016},{\"end\":38043,\"start\":38029},{\"end\":38059,\"start\":38043},{\"end\":38074,\"start\":38059},{\"end\":38094,\"start\":38074},{\"end\":38100,\"start\":38094},{\"end\":39096,\"start\":39083},{\"end\":39107,\"start\":39096},{\"end\":39119,\"start\":39107},{\"end\":39136,\"start\":39119},{\"end\":39152,\"start\":39136},{\"end\":39161,\"start\":39152},{\"end\":39429,\"start\":39418},{\"end\":39441,\"start\":39429},{\"end\":39456,\"start\":39441},{\"end\":39469,\"start\":39456},{\"end\":39478,\"start\":39469},{\"end\":39986,\"start\":39975},{\"end\":40004,\"start\":39986},{\"end\":40019,\"start\":40004},{\"end\":40027,\"start\":40019},{\"end\":40031,\"start\":40027},{\"end\":40564,\"start\":40556},{\"end\":40579,\"start\":40564},{\"end\":40592,\"start\":40579},{\"end\":40602,\"start\":40592},{\"end\":40614,\"start\":40602},{\"end\":40623,\"start\":40614},{\"end\":40887,\"start\":40878},{\"end\":40894,\"start\":40887},{\"end\":40907,\"start\":40894},{\"end\":40922,\"start\":40907},{\"end\":40936,\"start\":40922},{\"end\":40949,\"start\":40936},{\"end\":41190,\"start\":41177},{\"end\":41202,\"start\":41190},{\"end\":41214,\"start\":41202},{\"end\":41223,\"start\":41214},{\"end\":41238,\"start\":41223},{\"end\":41250,\"start\":41238},{\"end\":41258,\"start\":41250},{\"end\":41273,\"start\":41258},{\"end\":41496,\"start\":41484},{\"end\":41506,\"start\":41496},{\"end\":41520,\"start\":41506},{\"end\":41532,\"start\":41520},{\"end\":41543,\"start\":41532},{\"end\":41554,\"start\":41543},{\"end\":41567,\"start\":41554},{\"end\":41577,\"start\":41567},{\"end\":41590,\"start\":41577},{\"end\":41600,\"start\":41590},{\"end\":41614,\"start\":41600},{\"end\":41625,\"start\":41614},{\"end\":41636,\"start\":41625},{\"end\":41649,\"start\":41636},{\"end\":41664,\"start\":41649},{\"end\":41676,\"start\":41664},{\"end\":41689,\"start\":41676},{\"end\":42087,\"start\":42074},{\"end\":42103,\"start\":42087},{\"end\":42116,\"start\":42103},{\"end\":42131,\"start\":42116},{\"end\":42142,\"start\":42131},{\"end\":42156,\"start\":42142},{\"end\":42175,\"start\":42156},{\"end\":42188,\"start\":42175},{\"end\":42197,\"start\":42188},{\"end\":42214,\"start\":42197},{\"end\":42230,\"start\":42214},{\"end\":42240,\"start\":42230},{\"end\":42254,\"start\":42240},{\"end\":42912,\"start\":42898},{\"end\":42927,\"start\":42912},{\"end\":42939,\"start\":42927},{\"end\":42953,\"start\":42939},{\"end\":43901,\"start\":43895},{\"end\":43908,\"start\":43901},{\"end\":43915,\"start\":43908}]", "bib_venue": "[{\"end\":31656,\"start\":31539},{\"end\":32520,\"start\":32447},{\"end\":32979,\"start\":32893},{\"end\":33767,\"start\":33649},{\"end\":34612,\"start\":34585},{\"end\":34818,\"start\":34762},{\"end\":35331,\"start\":35264},{\"end\":36037,\"start\":35877},{\"end\":37018,\"start\":36864},{\"end\":38228,\"start\":38100},{\"end\":39081,\"start\":39013},{\"end\":39595,\"start\":39478},{\"end\":40098,\"start\":40031},{\"end\":40554,\"start\":40463},{\"end\":40876,\"start\":40834},{\"end\":41175,\"start\":41115},{\"end\":42896,\"start\":42792},{\"end\":43289,\"start\":43169},{\"end\":43620,\"start\":43560},{\"end\":43992,\"start\":43915},{\"end\":31741,\"start\":31658},{\"end\":33070,\"start\":32981},{\"end\":33808,\"start\":33769},{\"end\":34626,\"start\":34614},{\"end\":35348,\"start\":35333},{\"end\":36200,\"start\":36039},{\"end\":37185,\"start\":37020},{\"end\":38349,\"start\":38230},{\"end\":40116,\"start\":40100}]"}}}, "year": 2023, "month": 12, "day": 17}