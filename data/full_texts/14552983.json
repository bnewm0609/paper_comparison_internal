{"id": 14552983, "updated": "2023-09-26 02:44:19.292", "metadata": {"title": "Probabilistic robotics", "authors": "[{\"first\":\"Sebastian\",\"last\":\"Thrun\",\"middle\":[]}]", "venue": "CACM", "journal": "Commun. ACM", "publication_date": {"year": 2002, "month": null, "day": null}, "abstract": "Planning and navigation algorithms exploit statistics gleaned from uncertain, imperfect real-world environments to guide robots toward their goals and around obstacles.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2336416123", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "books/daglib/0014221", "doi": "10.1145/504729.504754"}}, "content": {"source": {"pdf_hash": "3e50bc266459fa25c80f37c6a9e2ca18379b14bc", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "2ca8dbfbbd3f4f19610fcc4ada9593c6cd55c544", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3e50bc266459fa25c80f37c6a9e2ca18379b14bc.txt", "contents": "\n\n\n\n\n) ( ) | ( ) ( ) | ( ) ( ) | ( ) | ( \uf03d \uf03d \uf0d7 \uf02b \uf0d7 \uf0d7 \uf03d \uf0d8 \uf0d8 \uf02b \uf03d z1 ) | ( ) | ( ) | ( ) | ( ) | ( ) | ( ) , | ( 1 2 1 2 1 2 1 2 \uf03d \uf03d \uf0d7 \uf02b \uf0d7 \uf0d7 \uf03d \uf0d8 \uf0d8 \uf02b \uf03d z\n\n3-13\n\nIntegrating the Outcome of Actions \n\uf0f2 \uf03d ' ) ' ( ) ' , | ( ) | ( dx x P x u x P u x P \uf0e5 \uf03d ) ' ( ) ' , | ( ) | ( x P x u x P u x Px P x u closed P u closed P \uf02d \uf03d \uf03d \uf02a \uf02b \uf02a \uf03d \uf02b \uf03d \uf03d \uf03d \uf02a \uf02b \uf02a \uf03d \uf02b \uf03d \uf03d \uf0e5 \uf0e5 3-15\n\nBayes Filters: Framework\n\n\u2022 Given:\n\n\u2022 Stream of observations z and action data u:\n\n\u2022 Sensor model P(z|x).\n\n\u2022 Action model P(x|u,x').\n\n\u2022 Prior probability of the system state P(x).\n\n\u2022 Wanted:\n\n\u2022 Estimate of the state X of a dynamical system. \u2022 The posterior of the state is also called Belief: \n) , , , | ( ) ( 1 1 t t t t z u z u x P x Bel \uf04b \uf03d } , , , { 1 1 t t t z u z u d \uf04b \uf03d 3-16) , | ( ) , , | ( 1 : 1 : 1 1 : 1 t t t t t t t u x x p u z x x p \uf02d \uf02d \uf03d ) | ( ) , , | ( : 1 : 1 : 0 t t t t t t x z p u z x z p \uf03d 3-19 1 1 1 ) ( ) , | ( ) | ( \uf02d \uf02d \uf02d \uf0f2 \uf03d t t t t t t t dx x Bel x u x P x z P \uf068 Bayes Filters ) , , , | ( ) , , , , | ( 1 1 1 1 t t t t t u z u x P u z u x z P \uf04b \uf04b \uf068 \uf03d \u2022Bayes \u2022z = observation \u2022u = action \u2022x = state ) , , , | ( ) ( 1 1 t t t t z u z u x P x Bel \uf04b \uf03d \u2022Markov ) , , , | ( ) | ( 1 1 t t t t u z u x P x z P \uf04b \uf068 \uf03d \u2022Markov 1 1 1 1 1 ) , , , | ( ) , | ( ) | ( \uf02d \uf02d \uf02d \uf0f2 \uf03d t t t t t t t t dx u z u x P x u x P x z P \uf04b \uf068 1 1 1 1 1 1 1 ) , , , | ( ) , , , , | ( ) | ( \uf02d \uf02d \uf02d \uf0f2 \uf03d t t t t t t t t dx u z u x P x u z u x P x z P \uf04b \uf04b \uf068 \u2022Total prob. \u2022Markov 1 1 1 1 1 1 ) , , , | ( ) , | ( ) | ( \uf02d \uf02d \uf02d \uf02d \uf0f2 \uf03d t t t t t t t t dx z z u x P x u x P x z P \uf04b \uf068 3-20 Bayes Filter Algorithm 1. Algorithm Bayes_filter( Bel(x),d ): 2. \uf068\uf03d0 3.\nIf d is a perceptual data item z then\n\n\n4.\n\nFor all x do 5. 6. 7.\n\nFor all x do 8.\n\n\n9.\n\nElse if d is an action data item u then 10.\n\nFor all x do 11. \n\n\nReturn\nBel'(x) ) ( ) | ( ) ( ' x Bel x z P x Bel \uf03d ) ( ' x Bel \uf02b \uf03d\uf068 \uf068 ) ( ' ) ( ' 1 x Bel x Bel \uf02d \uf03d\uf068 ' ) ' ( ) ' , | ( ) ( ' dx x Bel x u x P x Bel \uf0f2 \uf03d 1 1 1 ) ( ) , | ( ) | ( ) ( \uf02d \uf02d \uf02d \uf0f2 \uf03d t t t t t t t t dx x Bel x u x P x z P x Bel \uf068 3-21) ( ) , | ( ) | ( ) ( \uf02d \uf02d \uf02d \uf0f2 \uf03d t t t t t t t t dx x Bel x u x P x z P x Bel \uf068 3-22\n\nBayes Filters in Localization\n1 1 1 ) ( ) , | ( ) | ( ) ( \uf02d \uf02d \uf02d \uf0f2 \uf03d t t t t t t t t dx x Bel x u x P x z P x Bel \uf068 3-23\n\nSummary\n\n\u2022 Bayes rule allows us to compute probabilities that are hard to assess otherwise.\n\n\u2022 Under the Markov assumption, recursive Bayesian updating can be used to efficiently combine evidence.\n\n\u2022 Bayes filters are a probabilistic tool for estimating the state of dynamic systems. \n1 1 1 ) ( ) , | ( ) | ( ) ( \uf02d \uf02d \uf02d \uf0f2 \uf03d t t t t t t t t dx x Bel x u x P x z P x Bel \uf068 3-\n\n\uf068\uf03d0\n\n3.\n\nIf d is a perceptual data item z then\n\n\n4.\n\nFor all x do 5. 6. 7.\n\nFor all x do 8.\n\n\n9.\n\nElse if d is an action data item u then\n\n\n10.\n\nFor all x do 11.\n\n\nReturn\nBel'(x) ) ( ) | ( ) ( ' x Bel x z P x Bel \uf03d ) ( ' x Bel \uf02b \uf03d\uf068 \uf068 ) ( ' ) ( ' 1 x Bel x Bel \uf02d \uf03d\uf068 \uf0e5 \uf03d ' ) ' ( ) ' , | ( ) ( ' x x Bel x u x P x Bel 3-29\n\nImplementation (1)\n\n\u2022 To update the belief upon sensory input and to carry out the normalization one has to iterate over all cells of the grid.\n\n\u2022 Especially when the belief is peaked (which is generally the case during position tracking), one wants to avoid updating irrelevant aspects of the state space.\n\n\u2022 One approach is not to update entire sub-spaces of the state space.\n\n\u2022 This, however, requires to monitor whether the robot is de-localized or not.\n\n\u2022 To achieve this, one can consider the likelihood of the observations given the active components of the state space.\n\n\n3-30\n\n\nImplementation (2)\n\n\u2022 To efficiently update the belief upon robot motions, one typically assumes a bounded Gaussian model for the motion uncertainty.\n\n\u2022 This reduces the update cost from O(n 2 ) to O(n), where n is the number of states.\n\n\u2022 The update can also be realized by shifting the data in the grid according to the measured motion.\n\n\u2022 In a second step, the grid is then convolved using a separable Gaussian Kernel.\n\n\u2022 Two-dimensional example:   \nz z z p x p x z p z z z x p \uf0d5 \uf03d ) ( ) ( ) | ( ) | ( : g on distributi Sampling l l l z p x p x z p z x p \uf03d ) ,...,, ( ) |) | ( ) ( ) ( ) | ( ) ( ) | ( ) ( x z p x Bel x Bel x z p w x Bel x z p x Bel \uf061 \uf061 \uf061 \uf03d \uf0ac \uf0ac \uf02d \uf02d \uf02d Sensor Information: Importance Sampling 3-47 \u2022 \uf0f2 \uf0ac \uf02d ' d ) ' ( ) ' | ( ) ( , x x Bel x u x p x Bel Robot Motion 3-48 ) | ( ) ( ) ( ) | ( ) ( ) | ( ) ( x z p x Bel x Bel x z p w x Bel x z p x Bel \uf061 \uf061 \uf061 \uf03d \uf0ac \uf0ac \uf02d \uf02d \uf02d\n\nSensor Information: Importance Sampling\n\n\n3-49\n\n\nRobot Motion\n\uf0f2 \uf0ac \uf02d ' d ) ' ( ) ' | ( ) ( , x x Bel x u x p x Bel 3-50\n\nParticle Filter Algorithm\n0 , \uf03d \uf0c6 \uf03d \uf068 t S n i \uf04b 1 \uf03d } , { \uf03e \uf03c \uf0c8 \uf03d i t i t t t w x S S i t w \uf02b \uf03d\uf068 \uf068 i t x ) , | ( 1 1 \uf02d \uf02d t t t u x x p ) ( 1 i j t x \uf02d 1 \uf02d t u ) | ( i t t i t x z p w \uf03d n i \uf04b 1 \uf03d \uf068 / i t i t w w \uf03d 3-52 \u2022draw x i t\uf02d1 from Bel(x t\uf02d1 ) \u2022draw x i t from p(x t | x i t\uf02d1 ,u t\uf02d1 )\n\u2022Importance factor for x i t : \n) | ( ) ( ) , | ( ) ( ) , | ( ) | ( on distributi proposal on distributi target 1 1 1 1 1 1 t t t t t t t t t t t t i t x z p x Bel u x x p x Bel u x x p x z p w \uf0b5 \uf03d \uf03d \uf02d \uf02d \uf02d \uf02d \uf02d \uf02d \uf068 1 1 1 1 ) ( ) , | ( ) | ( ) ( \uf02d \uf02d \uf02d \uf02d \uf0f2 \uf03d t t t t t t t t dx x Bel u x x p x z p x Bel \uf068 Particle\n\uf0a7\nSample the next generation for particles using the proposal distribution \uf0a7 Compute the importance weights : weight = target distribution / proposal distribution \uf0a7 Resampling: \"Replace unlikely samples by more likely ones\" [Derivation of the MCL equations in book]\n\n\n\u2022 z raises the probability that the door is open.open \nP \n\nopen \np \nopen \nz \nP \nopen \np \nopen \nz \nP \n\nopen \nP \nopen \nz \nP \nz \nopen \nP \n\n3-5 \n\nCombining Evidence \n\n\u2022 Suppose our robot obtains another \n\nobservation z 2 . \n\n\u2022 How can we integrate this new \n\ninformation? \n\n\u2022 More generally, how can we estimate \n\nP(x| z 1 ...z n )? \n\n3-6 \n\nRecursive Bayesian Updating \n\n\n\n\n\u2022 z 2 lowers the probability that the door is open.open \nP \nopen \nz \nP \nz \nopen \nP \nopen \nz \nP \n\nz \nopen \nP \nopen \nz \nP \nz \nz \nopen \nP \n\n\n\n\nBayes Filters are Familiar! \u2022 Kalman filters \u2022 Particle filters \u2022 Hidden Markov models \u2022 Dynamic Bayesian networks \u2022 Partially Observable Markov DecisionProcesses (POMDPs) \n\n1 \n1 \n1 \n\n\n\n\n\uf0a7 The more particles fall into an interval, the higher the probability of that interval \uf0a7 How to draw samples form a\u20221/4 \n\n\u20221/4 \n\n\u20221/2 \n\u20221/4 \u20221/2 \u20221/4 \n\n\u2022+ \n\u2022\uf040 \n\n\u20221/16 \n\n\u20221/16 \n\n\u20221/8 \n\n\u20221/8 \n\n\u20221/8 \n\n\u20221/4 \n\n\u20221/16 \n\n\u20221/16 \n\n\u20221/8 \n\uf0a7 Particle sets can be used to approximate \n\nfunctions \n\nFunction Approximation \n\n3-37 \n\n\uf0a7 Let us assume that f(x)<1 for all x \n\uf0a7 Sample x from a uniform distribution \n\uf0a7 Sample c from [0,1] \n\uf0a7 if f(x) > c \n\nkeep the sample \notherwise \nreject the sampe \n\nRejection Sampling \n\n\u2022c \n\n\u2022x \n\n\u2022f(x \n\n) \n\n\u2022c \n\n' \n\n\u2022x \n\n' \n\n\u2022f(x \n\n') \n\n\u2022OK \n\n3-38 \n\n\uf0a7 We can even use a different distribution g to \n\ngenerate samples from f \n\n\uf0a7 By introducing an importance weight w, we \n\ncan account for the \"differences between g \nand f \" \n\n\uf0a7 w = f / g \n\uf0a7 f is often called \n\ntarget \n\n\uf0a7 g is often called \n\nproposal \n\n\uf0a7 Pre-condition: \n3-43 \n\nImportance Sampling \n\n) \n,..., \n, \n( \n\n) \n( \n) \n| \n( \n) \n,..., \n, \n| \n( \n: \nf \non \ndistributi \nTarget \n\n2 \n1 \n\n2 \n1 \nn \n\nk \n\nk \n\nn \n\n\n\n\nResampling\uf0a7 Given: Set S of weighted samples. Wanted : Random sample, where the probability of drawing x i is given by w i . \uf0a7 Typically done n times with replacement to generate new sample set S'.\u2022 Roulette wheel \u2022 Binary search, n log n \u2022 Stochastic universal sampling \u2022 Systematic resampling \u2022 Linear time complexity \u2022 Easy to implement, low varian 3-55 1. Algorithm systematic_resampling(S,n): \u2022Also called stochastic universal sampling Mobile Robot Localization \uf0a7 Each particle is a potential pose of the robot \uf0a7 Proposal distribution is the motion model of the robot (prediction step) \uf0a7 The observation model is used to compute the Alternative: Simple Counting \u2022For every cell count \u2022 hits(x,y): number of cases where a beam ended at <x,y> \u2022 misses(x,y): number of cases where a beam passed through <x,y> \u2022 Value of interest: P(reflects(x,y))Filter Algorithm \n\n3-53 \n\n\uf0a7 3-54 \n\n\u2022w \n\n2 \n\n\u2022w \n\n3 \n\n\u2022w 1 \n\u2022w \n\nn \n\n\u2022W \n\nn-1 \n\nResampling \n\n\u2022w \n\n2 \n\n\u2022w \n\n3 \n\n\u2022w 1 \n\u2022w \n\nn \n\n\u2022W \n\nn-1 \n\n2. \n\n3. For \nGenerate cdf \n4. \n5. \nInitialize threshold \n\n6. For \nDraw samples \u2026 \n7. \nWhile ( \n) \nSkip until next threshold reached \n8. \n9. \nInsert \n10. \nIncrement threshold \n\n11. Return S' \n\nResampling Algorithm \n\n1 \n1 \n\n, \n' \nw \nc \nS \n\uf03d \n\uf0c6 \n\uf03d \nn \ni \n\uf04b \n2 \n\uf03d \n\ni \ni \ni \n\nw \nc \nc \n\uf02b \n\uf03d \uf02d1 \n\n1 \n\n], \n\n, \n\n0 \n\n] \n\n1 \n1 \n\n\uf03d \n\n\uf02d \n\ni \nn \nU \nu \n\nn \nj \uf04b \n1 \n\uf03d \n\n1 \n1 \n\n\uf02d \n\uf02b \n\n\uf02b \n\uf03d \nn \nu \nu \n\nj \nj \n\ni \nj \n\nc \nu \uf03e \n\n\uf07b \n\uf07d \n\n\uf03e \n\uf03c \n\uf0c8 \n\uf03d \n\n\uf02d1 \n\n, \n\n' \n\n' \nn \nx \nS \nS \n\ni \n\n1 \n\uf02b \n\uf03d i \ni \n\n3-56 \n\nu \nz \nm \nodds \nm \nB \n\n\uf028 \uf029 \n\n) \n\n( \n\nlog \n\n: \n\n] \n\n[ \n\n] \n\n[ \nxy \nt \n\nxy \nt \n\nm \nodds \nm \nB \n\uf03d \n\n\uf028 \uf029 \n\uf028 \uf029 \uf0f7 \uf0f7 \n\n\uf0f8 \n\n\uf0f6 \n\uf0e7 \uf0e7 \n\uf0e8 \n\n\uf0e6 \n\uf02d \n\uf03d \nx \nP \n\nx \nP \nx \nodds \n1 \n\n: \n) \n( \n\n\uf028 \uf029 \n\n] \n[ \n\nlog \n\nxy \nt \n\nm \nodds \n\uf02d \n\n\uf028 \uf029 \n\n] \n\n[ \n\n1 \n\nxy \nt \n\nm \nB \uf02d \n\uf02b \n) \n, \nmisses( \n) \n, \nhits( \n\n) \n, \nhits( \n) \n( \n\n] \n[ \n\ny \nx \ny \nx \n\ny \nx \nm \nBel xy \n\uf02b \n\uf03d \n\n3-89Limitations \uf0a7 The approach described so far is able to \uf0a7 track the pose of a mobile robot and to \uf0a7 globally localize the robot.\uf0a7 How can we deal with localization errors (i.e., the kidnapped robot problem)?  Kidnapping: Approaches \uf0a7 Randomly insert samples (the robot can be teleported at any point in time).\uf0a7 Insert random samples proportional to the average likelihood of the particles (the robot has been teleported with higher probability when the likelihood of its observations drops).3-91Mapping as a Chicken and Egg Problem\u2022 So far we learned how to estimate the pose of the vehicle given the data and the map.\u2022 Mapping, however, involves to simultaneously estimate the pose of the vehicle and the map.\u2022 The general problem is therefore denoted as the simultaneous localization and mapping problem (SLAM).\u2022 Throughout this lecture we will describe how to calculate a map given we know the pose of the vehicle. This is not the SLAM problem.  \u2022corresponds to the umber of times a beam intercepted cell j without ending in it (misses(j)).3-983-118Computing the Most Likely Map \u2022 Although a cell might be occupied by an object, the reflection probability of this object might be very small. \u2022 Accordingly, the reflection probability will be 0.6. \u2022 Suppose p(occ | z) = 0.55 when a beam ends in a cell and p(occ | z) = 0.45 when a cell is intercepted by a beam that does not end in it.\u2022 Accordingly, after n measurements we will have \u2022 Whereas the reflection map yields a value of 0.6, the occupancy grid value converges to 1.Summary\u2022 Occupancy grid maps are a popular approach to represent the environment of a mobile robot given known poses.\u2022 In this approach each cell is considered independently from all others.\u2022 It stores the posterior probability that the corresponding area in the environment is occupied.\u2022 Occupancy grid maps can be learned efficiently using a probabilistic approach.\u2022 Reflection maps are an alternative representation. \u2022 They store in each cell the probability that a beam is reflected by this cell.\u2022 We provided a sensor model for computing the likelihood of measurements and showed that the counting procedure underlying reflection maps yield the optimal map.", "annotations": {"author": null, "publisher": null, "author_last_name": null, "author_first_name": null, "author_affiliation": null, "title": null, "venue": null, "abstract": null, "bib_ref": null, "figure": "[{\"attributes\":{\"id\":\"fig_2\"},\"end\":5354,\"start\":5088},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":5724,\"start\":5355},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":5864,\"start\":5725},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":6051,\"start\":5865},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":7032,\"start\":6052},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":8843,\"start\":7033}]", "paragraph": "[{\"end\":192,\"start\":157},{\"end\":393,\"start\":385},{\"end\":440,\"start\":395},{\"end\":464,\"start\":442},{\"end\":491,\"start\":466},{\"end\":538,\"start\":493},{\"end\":549,\"start\":540},{\"end\":652,\"start\":551},{\"end\":1636,\"start\":1599},{\"end\":1664,\"start\":1643},{\"end\":1681,\"start\":1666},{\"end\":1731,\"start\":1688},{\"end\":1750,\"start\":1733},{\"end\":2291,\"start\":2209},{\"end\":2396,\"start\":2293},{\"end\":2484,\"start\":2398},{\"end\":2581,\"start\":2579},{\"end\":2620,\"start\":2583},{\"end\":2648,\"start\":2627},{\"end\":2665,\"start\":2650},{\"end\":2711,\"start\":2672},{\"end\":2735,\"start\":2719},{\"end\":3038,\"start\":2915},{\"end\":3201,\"start\":3040},{\"end\":3272,\"start\":3203},{\"end\":3352,\"start\":3274},{\"end\":3472,\"start\":3354},{\"end\":3631,\"start\":3502},{\"end\":3718,\"start\":3633},{\"end\":3820,\"start\":3720},{\"end\":3903,\"start\":3822},{\"end\":3934,\"start\":3905},{\"end\":4808,\"start\":4777}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":64,\"start\":5},{\"attributes\":{\"id\":\"formula_1\"},\"end\":149,\"start\":64},{\"attributes\":{\"id\":\"formula_2\"},\"end\":285,\"start\":193},{\"attributes\":{\"id\":\"formula_3\"},\"end\":357,\"start\":285},{\"attributes\":{\"id\":\"formula_4\"},\"end\":741,\"start\":653},{\"attributes\":{\"id\":\"formula_5\"},\"end\":1598,\"start\":741},{\"attributes\":{\"id\":\"formula_6\"},\"end\":1994,\"start\":1760},{\"attributes\":{\"id\":\"formula_7\"},\"end\":2077,\"start\":1994},{\"attributes\":{\"id\":\"formula_8\"},\"end\":2198,\"start\":2109},{\"attributes\":{\"id\":\"formula_9\"},\"end\":2572,\"start\":2485},{\"attributes\":{\"id\":\"formula_10\"},\"end\":2893,\"start\":2745},{\"attributes\":{\"id\":\"formula_11\"},\"end\":4056,\"start\":3935},{\"attributes\":{\"id\":\"formula_12\"},\"end\":4364,\"start\":4056},{\"attributes\":{\"id\":\"formula_13\"},\"end\":4484,\"start\":4428},{\"attributes\":{\"id\":\"formula_14\"},\"end\":4776,\"start\":4512},{\"attributes\":{\"id\":\"formula_15\"},\"end\":5088,\"start\":4809}]", "table_ref": null, "section_header": "[{\"end\":155,\"start\":151},{\"end\":383,\"start\":359},{\"end\":1641,\"start\":1639},{\"end\":1686,\"start\":1684},{\"attributes\":{\"n\":\"12.\"},\"end\":1759,\"start\":1753},{\"end\":2108,\"start\":2079},{\"end\":2207,\"start\":2200},{\"end\":2577,\"start\":2574},{\"end\":2625,\"start\":2623},{\"end\":2670,\"start\":2668},{\"end\":2717,\"start\":2714},{\"attributes\":{\"n\":\"12.\"},\"end\":2744,\"start\":2738},{\"end\":2913,\"start\":2895},{\"end\":3479,\"start\":3475},{\"end\":3500,\"start\":3482},{\"end\":4405,\"start\":4366},{\"end\":4412,\"start\":4408},{\"end\":4427,\"start\":4415},{\"end\":4511,\"start\":4486},{\"end\":5090,\"start\":5089}]", "table": "[{\"end\":5724,\"start\":5406},{\"end\":5864,\"start\":5778},{\"end\":6051,\"start\":6020},{\"end\":7032,\"start\":6170},{\"end\":8843,\"start\":7883}]", "figure_caption": "[{\"end\":5354,\"start\":5091},{\"end\":5406,\"start\":5357},{\"end\":5778,\"start\":5727},{\"end\":6020,\"start\":5867},{\"end\":6170,\"start\":6054},{\"end\":7883,\"start\":7035}]", "figure_ref": null, "bib_author_first_name": null, "bib_author_last_name": null, "bib_entry": null, "bib_title": null, "bib_author": null, "bib_venue": null}}}, "year": 2023, "month": 12, "day": 17}