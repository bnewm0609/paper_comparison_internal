{"id": 250526428, "updated": "2023-10-05 12:48:00.095", "metadata": {"title": "Towards Grand Unification of Object Tracking", "authors": "[{\"first\":\"Bin\",\"last\":\"Yan\",\"middle\":[]},{\"first\":\"Yi\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Peize\",\"last\":\"Sun\",\"middle\":[]},{\"first\":\"Dong\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Zehuan\",\"last\":\"Yuan\",\"middle\":[]},{\"first\":\"Ping\",\"last\":\"Luo\",\"middle\":[]},{\"first\":\"Huchuan\",\"last\":\"Lu\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "We present a unified method, termed Unicorn, that can simultaneously solve four tracking problems (SOT, MOT, VOS, MOTS) with a single network using the same model parameters. Due to the fragmented definitions of the object tracking problem itself, most existing trackers are developed to address a single or part of tasks and overspecialize on the characteristics of specific tasks. By contrast, Unicorn provides a unified solution, adopting the same input, backbone, embedding, and head across all tracking tasks. For the first time, we accomplish the great unification of the tracking network architecture and learning paradigm. Unicorn performs on-par or better than its task-specific counterparts in 8 tracking datasets, including LaSOT, TrackingNet, MOT17, BDD100K, DAVIS16-17, MOTS20, and BDD100K MOTS. We believe that Unicorn will serve as a solid step towards the general vision model. Code is available at https://github.com/MasterBin-IIAU/Unicorn.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2207.07078", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/eccv/YanJSWYLL22", "doi": "10.48550/arxiv.2207.07078"}}, "content": {"source": {"pdf_hash": "802e54d116cb34c060c6190b874842d209854e9e", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2207.07078v4.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4338894d4e0ab53425f7d214dda7c91bac15c309", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/802e54d116cb34c060c6190b874842d209854e9e.txt", "contents": "\nTowards Grand Unification of Object Tracking\n\n\nYan Bin \nYi 1\u22c6 \nSchool of Information and Communication Engineering\nDalian University of Technology\nChina\n\nJiang \nPeize Sun \nThe University of Hong\nKong\n\nDong Wang \nSchool of Information and Communication Engineering\nDalian University of Technology\nChina\n\nZehuan Yuan \nPing Luo \nThe University of Hong\nKong\n\nHuchuan Lu \nSchool of Information and Communication Engineering\nDalian University of Technology\nChina\n\nPeng Cheng Laboratory\n\n\nTowards Grand Unification of Object Tracking\nobject tracking\nWe present a unified method, termed Unicorn, that can simultaneously solve four tracking problems (SOT, MOT, VOS, MOTS) with a single network using the same model parameters. Due to the fragmented definitions of the object tracking problem itself, most existing trackers are developed to address a single or part of tasks and overspecialize on the characteristics of specific tasks. By contrast, Unicorn provides a unified solution, adopting the same input, backbone, embedding, and head across all tracking tasks. For the first time, we accomplish the great unification of the tracking network architecture and learning paradigm. Unicorn performs on-par or better than its task-specific counterparts in 8 tracking datasets, including LaSOT, TrackingNet, MOT17, BDD100K, DAVIS16-17, MOTS20, and BDD100K MOTS. We believe that Unicorn will serve as a solid step towards the general vision model. Code is available at https://github.com/MasterBin-IIAU/Unicorn.\n\nIntroduction\n\nCompared with weak AI designed for solving one specific task, artificial general intelligence (AGI) is expected to understand or learn any intellectual task that a human being can. Although there is still a large gap between this ambitious goal and the intellectual algorithms of today, some recent works [20,51,81,21] have begun to explore the possibility of building general vision models to address several vision tasks simultaneously.\n\nObject tracking is one of the fundamental tasks in computer vision, which aims to build pixel-level or instance-level correspondence between frames and to output trajectories typically in the forms of boxes or masks. Over the years, according to different application scenarios, the object tracking problem has been mainly divided into four separate sub-tasks: Single Object Tracking (SOT) [18,42], Multiple Object Tracking (MOT) [40,80], Video Object Segmentation (VOS) [46], and Multi-Object Tracking and Segmentation (MOTS) [61,80]. As a result, most tracking approaches are developed for only one of or part of the sub-tasks. Despite convenience for specific applications, this fragmented situation brings into the following drawbacks: (1) Trackers may over-specialize on the characteristic of specific sub-tasks, lacking in the generalization ability. (2) Independent model designs cause redundant parameters. For example, recent deep-learningbased trackers usually adopt similar backbones architectures, but the separate design philosophy hinders the potential reuse of parameters. It is natural to ask a question: Can all main-stream tracking tasks be solved by a unified model?\n\nAlthough some works [64,36,62,70,39] attempt to unify SOT&VOS or MOT& MOTS by adding a mask branch to the existing box-level tracking system, there is still little progress towards the unification of SOT and MOT. There are mainly three obstacles hindering this process. (1) The characteristics of tracked objects vary. MOT usually tracks tens even hundreds of instances of specific categories. In contrast, SOT needs to track one target given in the reference frame no matter what class it belongs to. (2) SOT and MOT require different types of correspondence. SOT requires distinguishing the target from the background. However, MOT needs to match the currently detected objects with previous trajectories. (3) Most SOT methods [3,29,15,5,9,77] only take a small search region as the input to save computation and filter potential distractors. However, MOT algorithms [2,74,8,67,85,90,39] usually take the high-resolution full image as the input for detecting instances as completely as possible.\n\nTo conquer these challenges, we propose two core designs: the target prior and the pixel-wise correspondence. To be specific, (1) the target prior is an additional input for the detection head and serves as the switch among four tasks. For SOT&VOS, the target prior is the propagated reference target map, enabling the head to focus on the tracked target. For MOT&MOTS, by setting the target prior as zero, the head degenerates into the usual class-specific detection head smoothly. (2) The pixel-wise correspondence is the similarity between all pairs of points from the reference frame and the current frame. Both the SOT correspondence (C SOT \u2208 R h \u2032 w \u2032 \u00d7hw ) and the MOT correspondence (C MOT \u2208 R M \u00d7N ) are subsets of the pixel-wise correspondence (C pix \u2208 R hw\u00d7hw ). (3) With the help of the informative target prior and the accurate pixel-wise correspondence, the design of the search region becomes unnecessary for SOT, leading to unified inputs as the full image for SOT and MOT.\n\nTowards the unification of object tracking, we propose Unicorn, a single network architecture to solve four tracking tasks. It takes the reference frame and the current frame as the inputs and produces their visual features by a weight-shared backbone. Then a feature interaction module is exploited to build pixel-wise correspondence between two frames. Based on the correspondence, a target prior is generated by propagating the reference target to the current frame. Finally, the target prior and the visual features are fused and sent to the detection head to get the tracked objects for all tasks.\n\nWith the unified network architecture, Unicorn can learn from various sources of tracking data and address four tracking tasks with the same model parameters.\n\nExtensive experiments show that Unicorn performs on-par or better than taskspecific counterparts on 8 challenging benchmarks from four tracking tasks.\n\nWe summarize that our work has the following contributions:\n\n-For the first time, Unicorn accomplishes the great unification of the network architecture and the learning paradigm for four tracking tasks. -Unicorn bridges the gap among methods of four tracking tasks by the target prior and the pixel-wise correspondence. -Unicorn puts forwards new state-of-the-art performance on 8 challenging tracking benchmarks with the same model parameters. This achievement will serve as a solid step towards the general vision model.\n\n\nRelated Work\n\n\nTask-specific Trackers\n\nSOT typically specifies one tracked target with a bounding box on the first frame, then requires trackers to predict boxes for the tracked target in the following frames. Considering the uniqueness and the motion continuity of the tracked target, most of the algorithms in SOT [3,29,75,15,5,9,77] track on a small search region rather than the whole image to reduce computation and to filter distractors. Although achieving great success in the SOT field, search-region-based trackers suffer from the following drawbacks: (1) Due to the limited visual field, it is difficult for these methods to recover from temporary tracking failure, especially in the long-term tracking scenarios. (2) The speed of these methods drops drastically as the number of tracked instances increases. The inefficiency problem restricts the application of SOT trackers in scenarios such as MOT, where there are tens or hundreds of targets to track. To overcome the first problem, some works [25,62] propose a global-detection-based tracking paradigm. However, these methods either require large modifications to the original detection architecture to integrate the target information or rely on complicated dynamic programming to pick the best tracklet. Besides, both Global-Track [25] and Siam R-CNN [25] are developed on two-stage Faster R-CNN, whose detection pipeline is tedious and relies on hand-crafted anchors and ROI-Align. By contrast, in this work, we build our method based on a one-stage, anchor-free detector [19]. Furthermore, we demonstrate that only with minimal change to the original detector architecture, we could transform an object detector into a powerful SOT tracker. Different from SOT, MOT does not have any given prior on the first frame. Trackers of MOT are required to find and associate all instances of specific classes by themselves. The mainstream methods [67,85,90,44,53] follow the trackingby-detection paradigm. Specifically, an MOT system typically has two main components, an object detector and a certain association strategy. Commonly used detectors include Faster R-CNN [48], the YOLO series [47,19], Center-Net [91], Sparse R-CNN [54], and Deformable DETR [94], etc. Popular association methods include IoU matching [4,53], Kalman Filter [4,67,85], ReID embedding [69,44,67,85], Transformer [53,39,82], or the combination of them [84].\n\nAlthough there are some works [93,12] introducing SOT trackers for the association, these SOT trackers [14,3] are completely independent with the MOT networks, without any weight sharing. There is still a large gap between methods of SOT and MOT.\n\nThe goal of VOS is to predict masks for the tracked instances based on the high-quality mask annotations of the first frame. This field is now dominated by memory-network-based methods [43,79,10]. Although achieving great performance, these methods suffer from the following disadvantages: (1) The memory network brings huge time and space complexity, especially when dealing with high spatial resolution and the long sequence. While these scenarios are quite common in sequences of SOT and MOT. Specifically, the long-term tracking benchmarks [18,59] in SOT usually have thousands of frames per sequence, being more than 20x longer than DAVIS [46]. Meanwhile, the image size in MOT [80] can reach 720x1280, while the image size of DAVIS is usually only 480x854. (2) SOTA methods assume that there are always high-quality mask annotations on the first frame. However, high-quality masks demand expensive labor costs and are usually unavailable in real-world applications. To overcome this problem, some works [64,36,62] attempt to develop weakly-annotated VOS algorithms, which only require box annotation on the first frame.\n\nMOTS is highly related to MOT by changing the form of boxes to fine-grained representation of masks. MOTS benchmarks [61,80] are typically from the same scenarios as those of MOT [40,80]. Besides, many MOTS methods are developed upon MOT trackers. Representative approaches include 3D-convolutionbased Track R-CNN [61] and Stem-Seg [1], Transformer-based TrackFormer [39], tracking-assisting-detection Trades [70] and Prototype-based PCAN [28].\n\n\nGeneral Vision Models\n\nDespite the great success of specialized models for diverse tasks, there is still a large gap between the current AI with human-like, omnipotent Artificial General Intelligence (AGI). An important step towards this grand goal is to build a generalist model supporting a broad range of AI tasks. Recent pioneering works [20,51,81,21] attempt to approach this goal from different perspectives. Specifically, MuST [20] introduces a multi-task self-training pipeline, which harnesses the knowledge in independent specialized teacher models to train a single general student model. INTERN [51] proposes a new learning paradigm, which learns with supervisory signals from multiple sources in multiple stages. The developed general vision model generalizes well to different tasks but also has lower requirements on downstream data. Florence [81] is a new computer vision foundation model, which expands the representations to different tasks along space, time, and modality. Florence has great transferability and achieves new SOTA results on a wide range of vision benchmarks. OMNIVORE [21] proposes a modality-agnostic model which can classify images, videos, and single-view 3D data using the same model parameters. \n\n\nUnification in Object Tracking\n\nIn the literature, some works [64,70,66] attempted to design a unified framework for supporting multiple tracking tasks. Specifically, SiamMask [64] is the first work to address SOT and VOS simultaneously. Similarly, TraDes [70] can solve both MOT and MOTS by introducing an extra mask head. Besides, Uni-Track [66] proposes a high-level tracking framework, which consists of a shared appearance model and a series of unshared tracking heads. It demonstrates that different tracking tasks can share one appearance model for either propagation or association. However, the large discrepancy in tracking heads hinders it from exploiting a large amount of tracking data. Consequently, its performance lags far behind that of SOTA task-specific methods. Moreover, when used for MOT or MOTS, UniTrack requires extra, independent object detectors to provide observation. The extra object detector and the appearance model do not share the same backbone, bringing heavy burdens in parameters. By contrast, Unicorn solves four tracking tasks with one unified network with the same parameters. Besides, Unicorn can learn powerful representation from a large amount of labeled tracking data, achieving superior performance on 8 challenging benchmarks. Figure 1 shows the comparison between task-specific methods and Unicorn.\n\n\nCorrespondence Learning\n\nLearning accurate correspondence is the key to many vision tasks, such as optical flow [55], video object segmentation [86,27], geometric matching [57,58], etc. The dense correspondence is usually obtained by computing correlation between the embedding maps of two frames. Most existing methods [55,86,27] obtain the embedding maps without considering the information exchange between two images. This could lead to ambiguous or wrong matching when there are many similar patterns or instances on the input images. Although some works [57,58] attempt to relieve this problem, they usually require complex optimization or uncertainty modeling. Different from the local comparison, Transformer [60] and its variants [94] exploit the attention mechanism to capture the long-range de- pendency within the input sequence. In this work, we demonstrate that these operations can help to learn precise correspondence in object tracking.\n\n\nApproach\n\nWe propose a unified solution for object tracking, called Unicorn, which consists of three main components: unified inputs and backbone; unified embedding and unified head. Three components are responsible for obtaining powerful visual representation, building precise correspondence and detecting diverse tracked targets respectively. The framework of Unicorn is demonstrated in Figure 2. Given the reference frame I ref , the current frame I cur , and the reference targets, Unicorn aims at predicting the states of the tracked targets on the current frame for four tasks with a unified network.\n\n\nUnified Inputs and Backbone\n\nFor efficiently localizing multiple potential targets, Unicorn takes the whole image (for both the reference frame and the current frame) instead of local search regions as the inputs. This also endows Unicorn high resistance to tracking failure and the ability to re-detect tracked target after disappearance.\n\nDuring the feature extraction, the reference frame and the current frame are passed through a weight-sharing backbone to get feature pyramid representations(FPN) [32]. To maintain important details and reduce the computational burden during computing correspondence, we choose the feature map with stride 16 as the input of the following embedding module. The corresponding features from the reference and the current frame are termed F ref and F cur respectively.\n\n\nUnified Embedding\n\nThe core task of object tracking is to build accurate correspondence between frames in a video. For SOT and VOS, pixel-wise correspondence propagates the user-provided target from the reference frame (usually the 1 st frame) to the t th frame, providing strong prior information for the final box or mask prediction. Besides, for MOT and MOTS, instance-level correspondence helps to associate the detected instances on the t th frame to the existing trajectories on the reference frame (usually the t \u2212 1 th frame).\n\nIn Unicorn, given the spatially flattened reference frame embedding E ref \u2208 R hw\u00d7c and the current frame embedding E cur \u2208 R hw\u00d7c , pixel-wise correspondence C pix \u2208 R hw\u00d7hw is computed by the matrix multiplication between them. For SOT&VOS taking the full image as the inputs, the correspondence is the the pixel-wise correspondence itself. For MOT&MOTS, assume that there are M trajectories on the reference frame and N detected instances on the current frame respectively, the instance-level correspondence C inst \u2208 R N \u00d7M is the matrix multiplication of the reference instance embedding e ref \u2208 R M \u00d7c and the current instance embedding e cur \u2208 R N \u00d7c . The instance embedding e is extracted from the frame embedding E, where the center of the instance is located.\nC pix = softmax(E cur E ref T ) C inst = softmax(e cur e ref T )(1)\nIt can be seen that the instance-level correspondence C inst required by MOT and MOTS is the sub-matrix of the pixel-wise correspondence C pix . Besides, learning highly discriminative embedding {E ref , E cur } is the key to building precise correspondence for all tracking tasks.\n\nFeature Interaction. Due to its advantages of capturing long-range dependency, Transformer [60] is an intuitive choice to enhance the original feature representation {F ref , F cur }. However, this could lead to huge memory cost when dealing with high-resolution feature maps, because the memory consumption increases with the length of the input sequence quadratically. To alleviate this problem, we replace the full attention with more memory-efficient deformable attention [94]. For more accurate correspondence, the enhanced feature maps are upsampled by 2\u00d7 to obtain high-resolution embeddings on the stride of 8.\n{E ref , E cur } = Upsample(Attention(F ref , F cur ))(2)\nLoss. Ideal embedding should work well on both propagation(SOT, VOS) and association(MOT, MOTS). For SOT&VOS, although there is no human-annotated label for dense correspondence between frames, the embedding can be supervised by the difference between the propagated result T cur and the ground-truth target map T cur . Specifically, the shape of target map T is hw \u00d7 1. The regions where the tracked target exists are equal to one and the other regions are equal to zero. During the propagation, the pixel-wise correspondence C pix transforms the reference target map T ref to the estimation of the current target map T cur .\nT cur (i, j) = k C pix (i, k) \u00b7 T ref (k, j)(3)\nBesides, for MOT and MOTS, the instance-level correspondence can be learned with standard contrastive learning paradigm. Specifically, assume that the instance i from the current frame is matched with the instance j from the reference frame, then the corresponding ground-truth matrix G should satisfies that\nG i,k = 0 k \u0338 = j 1 k = j(4)\nFinally, the unified embedding can be optimized end-to-end by Dice Loss [41] for SOT&VOS or Cross-Entropy Loss for MOT&MOTS.\nL corr = Dice( T cur , T cur ) task in {SOT, VOS} CrossEntropy(C inst , G) task in {MOT, MOTS}(5)\n\nUnified Head\n\nTo achieve the grand unification of object tracking, another important and challenging problem is designing a unified head for four tracking tasks. Specifically, MOT shall detect objects of specific categories. However, SOT needs to detect any target given in the reference frame. To bridge this gap, Unicorn introduces an extra input (called target prior) to the original detector head [19,56]. Without any further modification, Unicorn can easily detect various objects needed for four tasks with this unified head. More details about the head architecture can be found in the supplementary materials.\n\nTarget Prior. As mentioned in Sec. 3.2, given the reference target map T ref , the propagated target map T cur can provide strong prior information about the state of the tracked target. This motivates us to take it as a target prior when detecting targets for SOT&VOS. To be compatible with the original input of the detection head, we first reshape it to h \u00d7 w \u00d7 1 (i.e. T reshape cur \u2208 R h\u00d7w\u00d71 ). Meanwhile, when dealing with MOT&MOTS, we can simply set this prior to zero. Formally, the target prior P satisfies that\nP = T reshape cur task in {SOT, VOS} 0 task in {MOT, MOTS}(6)\nFeature Fusion. The unified head takes the original FPN feature F \u2208 R h\u00d7w\u00d7c and the target prior P \u2208 R h\u00d7w\u00d71 as the inputs. Unicorn fuses these two inputs with broadcast sum and passes the fused feature F \u2032 \u2208 R h\u00d7w\u00d7c to the original detection head. This fusion strategy has the following advantages. (1) The fused features are seamlessly compatible with four tasks. Specifically, for MOT&MOTS, the target prior is equal to zero. Then the fused feature F \u2032 degenerates back to the original FPN feature F to detect objects of specific classes. For SOT&VOS, the target prior with strong target information can enhance the original FPN feature and makes the network focus on the tracked target. (2) The architecture is simple, without introducing complex changes to the original detection head. Furthermore, the consistent architecture also enables Unicorn to fully exploit the pretrained weights of the original object detector.\n\n\nTraining and Inference\n\nTraining. The whole training process divides into two stages: SOT-MOT joint training and VOS-MOTS joint training. In the first stage, the network is endto-end optimized with the correspondence loss and the detection loss using data from SOT&MOT. In the second stage, a mask branch is added and optimized with the mask loss using data from VOS&MOTS with other parameters fixed.\n\nInference. During the test phase, for SOT&VOS, the reference target map is generated once on the first frame and kept fixed in the following frames. Unicorn directly picks the box or mask with the highest confidence score as the final tracking result, without any hyperparameter-sensitive post-processing like cosine window. Besides, Unicorn only needs to run the heavy backbone and the correspondence once, while running the lightweight head rather than the whole network N times, leading to higher efficiency. For MOT&MOTS, Unicorn detects all objects of the given categories and simultaneously outputs corresponding instance embeddings. The later association is performed based on the embeddings and the motion model for BDD100K and MOT17 respectively.\n\n\nExperiments\n\n\nImplementation Details\n\nWhen comparing with state-of-the-art methods, we choose ConvNeXt-Large [34] as the backbone. In ablations, we report the results of our method with ConvNeXt-Tiny [34] and ResNet-50 [22] as the backbone. The input image size is 800\u00d71280 and the shortest side ranges from 736 to 864 during multi-scale training. The model is trained on 16 NVIDIA Tesla A100 GPU with a global batch size of 32. To avoid inaccurate statistics estimation, we replace all Batch Normalization [26] with Group Normalization [71]. Two training stages randomly sample data from SOT&MOT datasets and VOS&MOTS datasets, respectively. Each training stage consists of 15 epochs with 200,000 pairs of frames in every epoch. The optimizer is Adam-W [35] with weight decay of 5e \u22124 and momentum of 0.9. The initial learning rate is 2.5e \u22124 with 1 epoch warm-up and the cosine annealing schedule. More details can be found in the supplementary materials. In Section 4.2-4.5, we compare Unicorn with task-specific counterparts in 8 tracking datasets. In each benchmark, the red bold font and the blue font indicate the best two results. Unicorn in four tasks uses the same model parameters.\n\n\nEvaluations on Single Object Tracking\n\nWe compare Unicorn with state-of-the-art SOT trackers on two popular and challenging benchmarks, LaSOT [18] and TrackingNet [42]. Both datasets evaluate the tracking performance with the following measures: Success, precision(P ) and normalized precision(P norm ). All these measures are the higher the better. LaSOT. LaSOT [18] is a large-scale long-term tracking benchmark, which contains 280 videos in the test set with an average length of 2448 frames. Tab 1 shows that Unicorn achieves new state-of-the-art Success and Precision of 68.5% and 74.1% respectively. It is also worth noting that Unicorn surpasses the previous best global-detection-based tracker Siam R-CNN [62] by a large margin (68.5% vs 64.8%) with a much simpler network architecture and tracking strategy (directly picking the top-1 vs tracklet dynamic programming).\n\nTrackingNet. TrackingNet [42] is a large-scale short-term tracking benchmark containing 511 videos in the test set. As reported in Tab 1, Unicorn surpasses all previous methods with a Success of 83.0% and a Precision of 82.2%.\n\n\nEvaluations on Multiple Object Tracking\n\nWe compare Unicorn with state-of-the-art MOT trackers on two challenging benchmarks: MOT17 [40] and BDD100K [80]. The common metrics include Multiple-Object Tracking Accuracy (MOTA), Identity F1 Score (IDF1), False Positives (FP), False Negatives (FN), the percentage of Mostly Tracked Trajectories (MT) and Mostly Lost Trajectories (ML), Identity Switches (IDS). Among them, MOTA is the primary metric to measure the overall detection and tracking performance, IDF1 is used to measure the trajectory identity accuracy.\n\nMOT17. The MOT17 focuses on pedestrian tracking and includes 7 sequences in the training set and 7 sequences in the test set. We compare Unicorn with previous methods under the private detection protocol on the test set of MOT17. Tab 2 demonstrates that Unicorn achieves the best MOTA and IDF1, surpassing the previous SOTA method by 0.5% and 0.4% respectively.  BDD100K MOT. BDD100K is a large-scale dataset of visual driving scenes and requires tracking 8 categories of instances. To evaluate the average performance across 8 classes, BDD100K additionally introduces two measures: mMOTA and mIDF1. Different from MOT17, BDD100K is annotated at only 5 FPS. The low frame-rate brings difficulty to motion models commonly used for MOT17. As shown in Tab 3, Unicorn achieves the best performance, largely surpassing the previous SOTA method QDTrack [44] on the val set. Specifically, the improvement is up to 4.6% and 3.2% in terms of mMOTA and mIDF1 respectively.\n\n\nEvaluations on Video Object Segmentation\n\nWe further evaluate the ability of Unicorn to perform VOS on DAVIS [46] 2016 and 2017. Both datasets evaluate methods with the region similarity J , the contour accuracy F, and the average of them J &F.\n\nDAVIS-16. DAVIS-16 includes 20 videos in the validation set and there is only one tracked target in each sequence. Tab. 4 demonstrates that Unicorn achieves the best results among methods with bounding-box initialization, even surpassing RANet [68] and FRTM [49] with mask initialization. Meanwhile, Unicorn outperforms its multi-task counterparts SiamMask [64] by a large margin of 17.6% in terms of J &F. DAVIS-17. DAVIS-17 contains 30 videos in the validation set and there could be multiple tracked targets in each sequence. As shown in Tab. 4, compared with the previous best box-initialized method Siam R-CNN [62], Unicorn achieves competitive results with a much simpler architecture. Specifically, Siam R-CNN [62] uses an extra Box2Seg network, which is completely independent from the box-based tracker without any weight sharing. However, Unicorn can predict both boxes and masks with a unified head. Although there is still gap between the performance of Unicorn with that of SOTA VOS methods with mask initialization, Unicorn can address four tracking tasks with the same model parameters, while HMMN [50] and STCN [10] can only be used in the VOS task.\n\n\nEvaluations on Multi-Object Tracking and Segmentation\n\nFinally, we evaluate the ability of Unicorn to perform MOTS on MOTS20 [61] and the BDD100K MOTS [80]. The main evaluation metrics are sMOTSA and mMOTSA, which are the variants of MOTA and are calculated based on the mask overlap. The other metrics are the same as those in MOT.\n\nMOTS20 Challenge. MOTS20 Challenge has 4 sequences in the train set and 4 sequences in the test set. As shown in Tab. 5, Unicorn achieves state-ofthe-art performance, surpassing the second-best method PoinTrackV2 [76] by a large margin of 3.3% on sMOTSA.\n\nBDD100K MOTS Challenge. BDD100K MOTS Challenge includes 37 sequences in the validation set. Tab. 6 demonstrates that Unicorn outperforms the  previous best method PCAN [28] by a large margin (i.e. mMOTSA +2.2%, mAP +5.5%). Meanwhile, Unicorn does not use any complex design like space-time memory or prototypical network as in PCAN, bringing into a simpler pipeline.\n\n\nAblations and the Other Analysis\n\nIn this section, we conduct component-wise analysis by a series of variants, and make visualization to better understand our method. For the ablations, we choose Unicorn with ConvNeXt-Tiny [34] backbone as the baseline. The detailed results are demonstrated in Tab. 7.\n\nBackbone. We implement a variant of Unicorn with ResNet-50 [22] as the backbone. Although the overall performance of this version is lower than the baseline, this variant still achieves superior performance on four tasks.\n\nInteraction. Besides the memory-efficient deformable attention [94], we compare the full attention [60] and the convolution operation, which does not exchange information between frames. Experiments show that deformable attention obtains better performance than the full attention, while consuming much less memory. Moreover, the results of the convolution are lower than the baseline, showing the importance of interaction for accurate correspondence.\n\nFusion. To fuse the FPN features with the target prior, apart from the broadcast sum fusion, we compare other two methods: concatenation, and without the target prior. Experiments show that the performance of SOT and VOS drops significantly after removing the target prior, demonstrating the importance of this design. Besides, broadcast sum performs better than concatenation.  Single Task. We compare with training four independent models for different tasks. Experiments show that our unified model performs on-par with independently trained counterparts, while being much more parameter-efficient.\n\nSpeed. We develop a light-weight variant with a lower input resolution of 640x1024. Experiments show that the real-time version does not only achieves competitive performance but also can run in real-time at more than 20 FPS.\n\nVisualization. In Figure 3, given the tracked target (highlighted with a green box) on the reference frame, we visualize the predicted target prior on the current frame. It can be seen that Unicorn can predict accurate correspondence in challenging scenarios even though there are many similar distractors.\n\n\nConclusions\n\nWe propose Unicorn, a unified approach to address four tracking tasks using a single model with the same model parameters. For the first time, it achieves the unification of network architecture and learning paradigm for object tracking. Extensive experiments demonstrate that Unicorn performs on-par or better than task-specific counterparts on 8 challenging benchmarks. We hope that Unicorn can serve as a solid step towards the general vision model.\n\n\nA Unified Head Architecture\n\nThe detailed head architecture is shown in Fig. 4. The unified head takes the original FPN feature F \u2208 R h\u00d7w\u00d7c and the target prior P \u2208 R h\u00d7w\u00d71 as the inputs. The two inputs are first fused by broadcast sum, getting the fused feature F \u2032 \u2208 R h\u00d7w\u00d7c . Then the fused feature is passed to the detection head [19] and the instance segmentation head [56], predicting final boxes or masks. The head network is fully-convolutional, without any RoI operation such as RoI Align.\n\n\nB Training Details\n\nSince accurate mask annotations are quite expensive while bounding boxes are relatively cheap, available training data of SOT&MOT is usually dozens of times that of VOS&MOTS. Directly mixing training data from four tasks will lead to a serious data-imbalance problem. To alleviate this problem, we divide the whole training process into two stages. Specifically, in the first stage, we randomly sampled training data from SOT datasets (COCO [33], LaSOT [18], GOT-10K [24] and TrackingNet [42]) and MOT datasets (For evaluating on MOT Challenge, we use Crowdhuman [52], ETHZ [17], CityPerson [83], MOT17 [40]. For evaluating on BDD100K, we use the training set of BDD100K [80]) with a 1:1 sampling ratio to train the whole network without the mask head. In this stage, the network is optimized with the sum of the correspondence loss and the detection loss. L stage1 = L corr + L det . More details about L det can be found in the YOLOX paper. Then in the second stage, to prevent the model from overfitting on the VOS&MOTS and negatively impacting the performance of SOT&MOT, we only train the mask head with the data from VOS (COCO [33], DAVIS [46], Youtube-VOS [72]) and MOTS (MOTS [61], BDD100K [80]), leaving other parameters fixed. L stage2 = L mask  Fig. 4: Unified head architecture of the Unicorn.\n\nFig. 1 :\n1Comparison between previous solutions and Unicorn.\n\nFig. 2 :\n2Unicorn consists of three main components: (1) Unified inputs and backbone (2) Unified embedding (3) Unified head.\n\nFig. 3 :\n3Visualization of the target prior.\n\nTable 1 :\n1State-of-the-art comparison on LaSOT[18] and TrackingNet[42].Method \nSource \nLaSOT [18] \nTrackingNet [42] \nSuccess Pnorm P Success Pnorm P \nSiamFC [3] \nECCVW2016 33.6 \n42.0 33.9 57.1 \n66.3 53.3 \nUniTrack [66] NeurIPS2021 35.1 \n-\n32.6 \n-\n-\n-\nATOM [15] \nCVPR2019 \n51.5 \n57.6 50.5 70.3 \n77.1 64.8 \nSiamPRN++ [29] CVPR2019 \n49.6 \n56.9 49.1 73.3 \n80.0 69.4 \nDiMP [5] \nICCV2019 \n56.9 \n65.0 56.7 74.0 \n80.1 68.7 \nGlobalTrack [25] AAAI2020 \n52.1 \n-\n52.7 70.4 \n75.4 65.6 \nSiamFC++ [75] AAAI2020 \n54.4 \n62.3 54.7 75.4 \n80.0 70.5 \nD3S [36] \nCVPR2020 \n-\n-\n-\n72.8 \n76.8 66.4 \nPrDiMP [16] \nCVPR2020 \n59.8 \n68.8 60.8 75.8 \n81.6 70.4 \nSiam R-CNN [62] CVPR2020 \n64.8 \n72.2 \n-\n81.2 \n85.4 80.0 \nKYS [6] \nECCV2020 \n55.4 \n63.3 \n-\n74.0 \n80.0 68.8 \nOcean [88] \nECCV2020 \n56.0 \n65.1 56.6 \n-\n-\n-\nTrDiMP [63] \nCVPR2021 \n63.9 \n-\n61.4 78.4 \n83.3 73.1 \nTransT [9] \nCVPR2021 \n64.9 \n73.8 69.0 81.4 \n86.7 80.3 \nAutoMatch [87] \nICCV2021 \n58.2 \n-\n59.9 76.0 \n-\n72.6 \nSAOT [92] \nICCV2021 \n61.6 \n70.8 \n-\n-\n-\n-\nKeepTrack [38] \nICCV2021 \n67.1 77.2 70.2 \n-\n-\n-\nSTARK [77] \nICCV2021 \n67.1 \n77.0 \n-\n82.0 86.9 \n-\nUnicorn \nOurs \n68.5 76.6 74.1 83.0 86.4 82.2 \n\n\n\nTable 2 :\n2State-of-the-art comparison on MOT17 [40] test set.Tracker \nMOTA\u2191 IDF1\u2191 HOTA\u2191 MT\u2191 ML\u2193 FP\u2193 FN\u2193 IDs\u2193 \n\nChained-Tracker [45] 66.6 \n57.4 \n49.0 37.8% 18.5% 22284 160491 5529 \nCenterTrack [90] \n67.8 \n64.7 \n52.2 34.6% 24.6% 18498 160332 3039 \nQuasiDense [44] \n68.7 \n66.3 \n53.9 40.6% 21.9% 26589 146643 3378 \nTraDes [70] \n69.1 \n63.9 \n52.7 36.4% 21.5% 20892 150060 3555 \nSOTMOT [89] \n71.0 \n71.9 \n-\n42.7% 15.3% 39537 118983 5184 \nTransCenter [73] \n73.2 \n62.2 \n54.5 40.8% 18.5% 23112 123738 4614 \nMOTR [82] \n73.4 \n68.6 \n57.8 42.9% 19.1% 27939 119589 2439 \nFairMOT [85] \n73.7 \n72.3 \n59.3 43.2% 17.3% 27507 117477 3303 \nTrackFormer [39] \n74.1 \n68.0 \n-\n-\n-\n34602 108777 2829 \nCSTrack [30] \n74.9 \n72.6 \n59.3 41.5% 17.5% 23847 114303 3567 \nTransTrack [53] \n75.2 \n63.5 \n54.1 55.3% 10.2% 50157 86442 3603 \nOMC [31] \n76.3 \n72.3 \n-\n44.8% 15.5% \n-\n-\n-\nCorrTracker [65] \n76.5 \n73.6 \n60.7 47.6% 12.7% 29808 99510 3369 \nTransMOT [13] \n76.7 \n75.1 \n61.7 51.0% 16.4% 36231 93150 2346 \nUnicorn \n77.2 75.5 61.7 58.7% 11.2% 50087 73349 5379 \n\n\n\nTable 3 :\n3State-of-the-art comparison on BDD100K[80] tracking validation set.Method \nSplit mMOTA\u2191 mIDF1\u2191 MOTA\u2191 IDF1\u2191 FN\u2193 FP\u2193 ID Sw.\u2193 MT\u2191 ML\u2193 mAP\u2191 \n\nYu et al. [80] val \n25.9 \n44.5 \n56.9 \n66.8 122406 52372 8315 \n8396 3795 28.1 \nQDTrack [44] val \n36.6 \n50.8 \n63.5 \n71.5 108614 46621 6262 9481 3034 32.6 \nUnicorn \nval \n41.2 \n54.0 \n66.6 \n71.3 95454 41648 10876 10296 2505 41.4 \n\n\n\nTable 4 :\n4State-of-the-art comparison on the validation set of the DAVIS-2016 and the DAVIS-2017. OL: online learning, Memory: using an external memory bank.Init \nMethod \nOL Memory (J &F) 16 J 16 F 16 (J &F) 17 J 17 F 17 \n\nmask \n\nFAVOS [11] \n\u2717 \n\u2717 \n81.0 \n82.4 79.5 \n58.2 \n54.6 61.8 \nOSMN [37] \n\u2717 \n\u2717 \n73.5 \n74.0 72.9 \n54.8 \n52.5 57.1 \nVideoMatch [23] \u2717 \n\u2717 \n-\n81.0 -\n56.5 \n-\n-\nUniTrack [66] \n\u2717 \n\u2713 \n-\n-\n-\n-\n58.4 -\nRANet [68] \n\u2717 \n\u2717 \n85.5 \n85.5 85.4 \n65.7 \n63.2 68.2 \nFRTM [49] \n\u2713 \n\u2713 \n83.5 \n83.6 83.4 \n76.7 \n73.9 79.6 \nTVOS [86] \n\u2717 \n\u2713 \n-\n-\n-\n72.3 \n69.9 74.7 \nLWL [7] \n\u2713 \n\u2713 \n-\n-\n-\n81.6 \n79.1 84.1 \nSTM [43] \n\u2717 \n\u2713 \n89.3 \n88.7 89.9 \n81.8 \n79.2 84.3 \nCFBI [79] \n\u2717 \n\u2713 \n89.4 \n88.3 90.5 \n81.9 \n79.1 84.6 \nHMMN [50] \n\u2717 \n\u2713 \n90.8 \n89.6 92.0 \n84.7 \n81.9 87.5 \nSTCN [10] \n\u2717 \n\u2713 \n91.6 \n90.8 92.5 \n85.4 \n82.2 88.6 \n\nbbox \n\nSiamMask [64] \n\u2717 \n\u2717 \n69.8 \n71.7 67.8 \n56.4 \n54.3 58.5 \nD3S [36] \n\u2717 \n\u2717 \n74.0 \n75.4 72.6 \n60.8 \n57.8 63.8 \nSiam R-CNN [62] \u2717 \n\u2717 \n-\n-\n-\n70.6 66.1 75.0 \nUnicorn \n\u2717 \n\u2717 \n87.4 86.5 88.2 \n69.2 \n65.2 73.2 \n\n\n\nTable 5 :\n5State-of-the-art comparison on the MOTS [61] test set.Method \nsMOTSA\u2191 IDF1\u2191 MT\u2191 ML \u2193 FP\u2193 FN\u2193 ID Sw.\u2193 \n\nTrack R-CNN [61] \n40.6 \n42.4 38.7% 21.6% 1261 12641 567 \nTraDeS [70] \n50.8 \n58.7 49.4% 18.3% 1474 9169 \n492 \nTrackFormer [39] \n54.9 \n63.6 \n-\n-\n2233 7195 278 \nPointTrackV2 [76] \n62.3 \n42.9 56.7% 12.5% 963 5993 \n541 \nUnicorn \n65.3 \n65.9 64.9% 10.1% 1364 4452 398 \n\n\n\nTable 6 :\n6State-of-the-art comparison on the BDD100K MOTS validation set.Method \nOnline mMOTSA\u2191 mMOTSP\u2191 mIDF1\u2191 ID Sw.\u2193 mAP\u2191 \n\nSortIoU \n\u2713 \n10.3 \n59.9 \n21.8 \n15951 22.2 \nMaskTrackRCNN [78] \n\u2713 \n12.3 \n59.9 \n26.2 \n9116 \n22.0 \nSTEm-Seg [1] \n\u2717 \n12.2 \n58.2 \n25.4 \n8732 \n21.8 \nQDTrack-mots [44] \n\u2713 \n22.5 \n59.6 \n40.8 \n1340 \n22.4 \nQDTrack-mots-fix [44] \u2713 \n23.5 \n66.3 \n44.5 \n973 \n25.5 \nPCAN [28] \n\u2713 \n27.4 \n66.7 \n45.1 \n876 \n26.6 \nUnicorn \n\u2713 \n29.6 \n67.7 \n44.2 \n1731 32.1 \n\n\n\nTable 7 :\n7Ablations and comparisons. Our baseline model are underlined.Experiment \nMethod \nSOT \nMOT \nVOS \nMOTS \nFPS \nLaSOT(AUC) \nBDD(mMOTA) \nDAVIS17(J &F) \nBDD(mMOTSA) \n\nBackbone \nConvNeXt-Tiny \n67.7 \n39.9 \n68.0 \n29.7 \n14 \nResNet-50 \n65.3 \n35.1 \n66.2 \n30.8 \n13 \n\nInteraction \n\nDeformable Att \n67.7 \n39.9 \n68.0 \n29.7 \n14 \nFull Att \n67.1 \n38.5 \n66.9 \n26.7 \n13 \nConv \n66.8 \n37.6 \n66.6 \n27.0 \n15 \n\nFusion \n\nBroad Sum \n67.7 \n39.9 \n68.0 \n29.7 \n14 \nConcat \n66.8 \n38.3 \n66.7 \n27.2 \n14 \nW/o Prior \n50.9 \n37.6 \n29.2 \n27.8 \n14 \n\nSingle task \n\nUnification \n67.7 \n39.9 \n68.0 \n29.7 \n14 \nSOT only \n67.5 \n-\n-\n-\n14 \nMOT only \n-\n39.6 \n-\n-\n14 \nVOS only \n-\n-\n68.4 \n-\n14 \nMOTS only \n-\n-\n-\n28.1 \n14 \n\nSpeed \nOurs \n67.7 \n39.9 \n68.0 \n29.7 \n14 \nOurs-RT \n67.1 \n37.5 \n66.8 \n26.2 \n23 \n\nReference Frame \nCurrent Frame \nTarget Prior \n\n\n\nSTEm-Seg: Spatiotemporal embeddings for instance segmentation in videos. A Athar, S Mahadevan, A Osep, L Leal-Taix\u00e9, B Leibe, ECCV (2020). 413Athar, A., Mahadevan, S., Osep, A., Leal-Taix\u00e9, L., Leibe, B.: STEm-Seg: Spatio- temporal embeddings for instance segmentation in videos. In: ECCV (2020) 4, 13\n\nTracking without bells and whistles. P Bergmann, T Meinhardt, L Leal-Taixe, ICCV. 2Bergmann, P., Meinhardt, T., Leal-Taixe, L.: Tracking without bells and whistles. In: ICCV (2019) 2\n\nFullyconvolutional siamese networks for object tracking. L Bertinetto, J Valmadre, J F Henriques, A Vedaldi, P H S Torr, ECCVW210Bertinetto, L., Valmadre, J., Henriques, J.F., Vedaldi, A., Torr, P.H.S.: Fully- convolutional siamese networks for object tracking. In: ECCVW (2016) 2, 3, 4, 10\n\nSimple online and realtime tracking. A Bewley, Z Ge, L Ott, F Ramos, B Upcroft, ICIP. 3Bewley, A., Ge, Z., Ott, L., Ramos, F., Upcroft, B.: Simple online and realtime tracking. In: ICIP (2016) 3\n\nLearning discriminative model prediction for tracking. G Bhat, M Danelljan, L V Gool, R Timofte, ICCV. 210Bhat, G., Danelljan, M., Gool, L.V., Timofte, R.: Learning discriminative model prediction for tracking. In: ICCV (2019) 2, 3, 10\n\nKnow your surroundings: Exploiting scene information for object tracking. G Bhat, M Danelljan, L V Gool, R Timofte, ECCV10Bhat, G., Danelljan, M., Gool, L.V., Timofte, R.: Know your surroundings: Ex- ploiting scene information for object tracking. In: ECCV (2020) 10\n\nLearning what to learn for video object segmentation. G Bhat, F J Lawin, M Danelljan, A Robinson, M Felsberg, L V Gool, R Timofte, ECCV12Bhat, G., Lawin, F.J., Danelljan, M., Robinson, A., Felsberg, M., Gool, L.V., Timofte, R.: Learning what to learn for video object segmentation. In: ECCV (2020) 12\n\nLearning a neural solver for multiple object tracking. G Bras\u00f3, L Leal-Taix\u00e9, CVPR (2020). Bras\u00f3, G., Leal-Taix\u00e9, L.: Learning a neural solver for multiple object tracking. In: CVPR (2020) 2\n\nTransformer tracking. X Chen, B Yan, J Zhu, D Wang, X Yang, H Lu, CVPR (2021). 210Chen, X., Yan, B., Zhu, J., Wang, D., Yang, X., Lu, H.: Transformer tracking. In: CVPR (2021) 2, 3, 10\n\nRethinking space-time networks with improved memory coverage for efficient video object segmentation. H K Cheng, Y W Tai, C K Tang, NeurIPS. 412Cheng, H.K., Tai, Y.W., Tang, C.K.: Rethinking space-time networks with im- proved memory coverage for efficient video object segmentation. NeurIPS (2021) 4, 12\n\nFast and accurate online video object segmentation via tracking parts. J Cheng, Y H Tsai, W C Hung, S Wang, M H Yang, CVPR12Cheng, J., Tsai, Y.H., Hung, W.C., Wang, S., Yang, M.H.: Fast and accurate online video object segmentation via tracking parts. In: CVPR (2018) 12\n\nFAMNet: Joint learning of feature, affinity and multi-dimensional assignment for online multiple object tracking. P Chu, H Ling, ICCV4Chu, P., Ling, H.: FAMNet: Joint learning of feature, affinity and multi-dimensional assignment for online multiple object tracking. In: ICCV (2019) 4\n\nP Chu, J Wang, Q You, H Ling, Z Liu, arXiv:2104.00194TransMOT: Spatial-temporal graph transformer for multiple object tracking. 11arXiv preprintChu, P., Wang, J., You, Q., Ling, H., Liu, Z.: TransMOT: Spatial-temporal graph transformer for multiple object tracking. arXiv preprint arXiv:2104.00194 (2021) 11\n\nECO: Efficient convolution operators for tracking. M Danelljan, G Bhat, F S Khan, M Felsberg, CVPR4Danelljan, M., Bhat, G., Khan, F.S., Felsberg, M.: ECO: Efficient convolution operators for tracking. In: CVPR (2017) 4\n\nATOM: Accurate tracking by overlap maximization. M Danelljan, G Bhat, F S Khan, M Felsberg, CVPR. 210Danelljan, M., Bhat, G., Khan, F.S., Felsberg, M.: ATOM: Accurate tracking by overlap maximization. In: CVPR (2019) 2, 3, 10\n\nProbabilistic regression for visual tracking. M Danelljan, L V Gool, R Timofte, CVPR10Danelljan, M., Gool, L.V., Timofte, R.: Probabilistic regression for visual tracking. In: CVPR (2020) 10\n\nA mobile vision system for robust multi-person tracking. A Ess, B Leibe, K Schindler, L Van Gool, CVPR20Ess, A., Leibe, B., Schindler, K., Van Gool, L.: A mobile vision system for robust multi-person tracking. In: CVPR (2008) 20\n\nLaSOT: A high-quality benchmark for large-scale single object tracking. H Fan, L Lin, F Yang, P Chu, G Deng, S Yu, H Bai, Y Xu, C Liao, H Ling, CVPR (2019) 1, 4, 9. 1020Fan, H., Lin, L., Yang, F., Chu, P., Deng, G., Yu, S., Bai, H., Xu, Y., Liao, C., Ling, H.: LaSOT: A high-quality benchmark for large-scale single object tracking. In: CVPR (2019) 1, 4, 9, 10, 20\n\nZ Ge, S Liu, F Wang, Z Li, J Sun, arXiv:2107.08430YOLOX: Exceeding yolo series in 2021. 320arXiv preprintGe, Z., Liu, S., Wang, F., Li, Z., Sun, J.: YOLOX: Exceeding yolo series in 2021. arXiv preprint arXiv:2107.08430 (2021) 3, 8, 20\n\nMulti-task self-training for learning general representations. G Ghiasi, B Zoph, E D Cubuk, Q V Le, T Y Lin, ICCV (2021). 14Ghiasi, G., Zoph, B., Cubuk, E.D., Le, Q.V., Lin, T.Y.: Multi-task self-training for learning general representations. In: ICCV (2021) 1, 4\n\nOmnivore: A single model for many visual modalities. R Girdhar, M Singh, N Ravi, L Van Der Maaten, A Joulin, I Misra, arXiv:2201.0837714arXiv preprintGirdhar, R., Singh, M., Ravi, N., van der Maaten, L., Joulin, A., Misra, I.: Omni- vore: A single model for many visual modalities. arXiv preprint arXiv:2201.08377 (2022) 1, 4\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, CVPR913He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR (2016) 9, 13\n\nVideomatch: Matching based video object segmentation. Y T Hu, J B Huang, A G Schwing, ECCV12Hu, Y.T., Huang, J.B., Schwing, A.G.: Videomatch: Matching based video object segmentation. In: ECCV (2018) 12\n\nGOT-10k: A large high-diversity benchmark for generic object tracking in the wild. L Huang, X Zhao, K Huang, TPAMI. 20Huang, L., Zhao, X., Huang, K.: GOT-10k: A large high-diversity benchmark for generic object tracking in the wild. TPAMI (2019) 20\n\nGlobaltrack: A simple and strong baseline for long-term tracking. L Huang, X Zhao, K Huang, AAAI310Huang, L., Zhao, X., Huang, K.: Globaltrack: A simple and strong baseline for long-term tracking. In: AAAI (2020) 3, 10\n\nBatch Normalization: Accelerating deep network training by reducing internal covariate shift. S Ioffe, C Szegedy, ICML. 9Ioffe, S., Szegedy, C.: Batch Normalization: Accelerating deep network training by reducing internal covariate shift. In: ICML (2015) 9\n\nA Jabri, A Owens, A Efros, Space-time correspondence as a contrastive random walk. 5Jabri, A., Owens, A., Efros, A.: Space-time correspondence as a contrastive random walk. NeurIPS (2020) 5\n\nPrototypical crossattention networks for multiple object tracking and segmentation. L Ke, X Li, M Danelljan, Y W Tai, C K Tang, F Yu, NeurIPS. 413Ke, L., Li, X., Danelljan, M., Tai, Y.W., Tang, C.K., Yu, F.: Prototypical cross- attention networks for multiple object tracking and segmentation. NeurIPS (2021) 4, 13\n\nSiamRPN++: Evolution of siamese visual tracking with very deep networks. B Li, W Wu, Q Wang, F Zhang, J Xing, J Yan, CVPR. 210Li, B., Wu, W., Wang, Q., Zhang, F., Xing, J., Yan, J.: SiamRPN++: Evolution of siamese visual tracking with very deep networks. In: CVPR (2019) 2, 3, 10\n\nRethinking the competition between detection and reid in multi-object tracking. C Liang, Z Zhang, Y Lu, X Zhou, B Li, X Ye, J Zou, arXiv:2010.1213811arXiv preprintLiang, C., Zhang, Z., Lu, Y., Zhou, X., Li, B., Ye, X., Zou, J.: Rethinking the competition between detection and reid in multi-object tracking. arXiv preprint arXiv:2010.12138 (2020) 11\n\nC Liang, Z Zhang, X Zhou, B Li, Y Lu, W Hu, arXiv:2104.09441One more check: Making\" fake background\" be tracked again. 11arXiv preprintLiang, C., Zhang, Z., Zhou, X., Li, B., Lu, Y., Hu, W.: One more check: Making\" fake background\" be tracked again. arXiv preprint arXiv:2104.09441 (2021) 11\n\nFeature pyramid networks for object detection. T Y Lin, P Doll\u00e1r, R Girshick, K He, B Hariharan, S Belongie, 6Lin, T.Y., Doll\u00e1r, P., Girshick, R., He, K., Hariharan, B., Belongie, S.: Feature pyramid networks for object detection. In: CVPR (2017) 6\n\nT Y Lin, M Maire, S J Belongie, L D Bourdev, R B Girshick, J Hays, P Perona, D Ramanan, P Doll\u00e1r, C L Zitnick, Microsoft COCO: Common objects in context. ECCV20Lin, T.Y., Maire, M., Belongie, S.J., Bourdev, L.D., Girshick, R.B., Hays, J., Per- ona, P., Ramanan, D., Doll\u00e1r, P., Zitnick, C.L.: Microsoft COCO: Common objects in context. In: ECCV (2014) 20\n\nZ Liu, H Mao, C Y Wu, C Feichtenhofer, T Darrell, S Xie, arXiv:2201.03545A convnet for the 2020s. 913arXiv preprintLiu, Z., Mao, H., Wu, C.Y., Feichtenhofer, C., Darrell, T., Xie, S.: A convnet for the 2020s. arXiv preprint arXiv:2201.03545 (2022) 9, 13\n\nI Loshchilov, F Hutter, arXiv:1711.05101Decoupled weight decay regularization. 9arXiv preprintLoshchilov, I., Hutter, F.: Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 (2017) 9\n\nD3S-a discriminative single shot segmentation tracker. A Lukezic, J Matas, M Kristan, CVPR (2020) 2, 4. 1012Lukezic, A., Matas, J., Kristan, M.: D3S-a discriminative single shot segmentation tracker. In: CVPR (2020) 2, 4, 10, 12\n\nVideo object segmentation without temporal information. K K Maninis, S Caelles, Y Chen, J Pont-Tuset, L Leal-Taix\u00e9, D Cremers, L Van Gool, TPAMI. 12Maninis, K.K., Caelles, S., Chen, Y., Pont-Tuset, J., Leal-Taix\u00e9, L., Cremers, D., Van Gool, L.: Video object segmentation without temporal information. TPAMI (2018) 12\n\nLearning target candidate association to keep track of what not to track. C Mayer, M Danelljan, D P Paudel, L Van Gool, ICCV10Mayer, C., Danelljan, M., Paudel, D.P., Van Gool, L.: Learning target candidate association to keep track of what not to track. In: ICCV (2021) 10\n\nTrackFormer: Multiobject tracking with transformers. T Meinhardt, A Kirillov, L Leal-Taixe, C Feichtenhofer, arXiv:2101.0270213arXiv preprintMeinhardt, T., Kirillov, A., Leal-Taixe, L., Feichtenhofer, C.: TrackFormer: Multi- object tracking with transformers. arXiv preprint arXiv:2101.02702 (2021) 2, 3, 4, 11, 13\n\nA Milan, L Leal-Taix\u00e9, I Reid, S Roth, K Schindler, arXiv:1603.00831MOT16: A benchmark for multi-object tracking. 1120arXiv preprintMilan, A., Leal-Taix\u00e9, L., Reid, I., Roth, S., Schindler, K.: MOT16: A benchmark for multi-object tracking. arXiv preprint arXiv:1603.00831 (2016) 1, 4, 10, 11, 20\n\nV-net: Fully convolutional neural networks for volumetric medical image segmentation. F Milletari, N Navab, S A Ahmadi, 8Milletari, F., Navab, N., Ahmadi, S.A.: V-net: Fully convolutional neural networks for volumetric medical image segmentation. In: 3DV (2016) 8\n\nTrackingnet: A largescale dataset and benchmark for object tracking in the wild. M Muller, A Bibi, S Giancola, S Alsubaihi, B Ghanem, ECCV. 120Muller, M., Bibi, A., Giancola, S., Alsubaihi, S., Ghanem, B.: Trackingnet: A large- scale dataset and benchmark for object tracking in the wild. In: ECCV (2018) 1, 9, 10, 20\n\nVideo object segmentation using space-time memory networks. S W Oh, J Y Lee, N Xu, S J Kim, ICCV. 412Oh, S.W., Lee, J.Y., Xu, N., Kim, S.J.: Video object segmentation using space-time memory networks. In: ICCV (2019) 4, 12\n\nQuasi-dense similarity learning for multiple object tracking. J Pang, L Qiu, X Li, H Chen, Q Li, T Darrell, F Yu, CVPR (2021). 313Pang, J., Qiu, L., Li, X., Chen, H., Li, Q., Darrell, T., Yu, F.: Quasi-dense similarity learning for multiple object tracking. In: CVPR (2021) 3, 11, 13\n\nChained-tracker: Chaining paired attentive regression results for endto-end joint multiple-object detection and tracking. J Peng, C Wang, F Wan, Y Wu, Y Wang, Y Tai, C Wang, J Li, F Huang, Y Fu, ECCV11Peng, J., Wang, C., Wan, F., Wu, Y., Wang, Y., Tai, Y., Wang, C., Li, J., Huang, F., Fu, Y.: Chained-tracker: Chaining paired attentive regression results for end- to-end joint multiple-object detection and tracking. In: ECCV (2020) 11\n\nJ Pont-Tuset, F Perazzi, S Caelles, P Arbel\u00e1ez, A Sorkine-Hornung, L Van Gool, arXiv:1704.00675The 2017 davis challenge on video object segmentation. 120arXiv preprintPont-Tuset, J., Perazzi, F., Caelles, S., Arbel\u00e1ez, P., Sorkine-Hornung, A., Van Gool, L.: The 2017 davis challenge on video object segmentation. arXiv preprint arXiv:1704.00675 (2017) 1, 4, 11, 20\n\nJ Redmon, A Farhadi, arXiv:1804.02767YOLOv3: An incremental improvement. 3arXiv preprintRedmon, J., Farhadi, A.: YOLOv3: An incremental improvement. arXiv preprint arXiv:1804.02767 (2018) 3\n\nFaster R-CNN: Towards real-time object detection with region proposal networks. S Ren, K He, R Girshick, J Sun, NeurIPS3Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN: Towards real-time object detection with region proposal networks. In: NeurIPS (2015) 3\n\nLearning fast and robust target models for video object segmentation. A Robinson, F J Lawin, M Danelljan, F S Khan, M Felsberg, CVPR1112Robinson, A., Lawin, F.J., Danelljan, M., Khan, F.S., Felsberg, M.: Learning fast and robust target models for video object segmentation. In: CVPR (2020) 11, 12\n\nHierarchical memory matching network for video object segmentation. H Seong, S W Oh, J Y Lee, S Lee, S Lee, E Kim, ICCV12Seong, H., Oh, S.W., Lee, J.Y., Lee, S., Lee, S., Kim, E.: Hierarchical memory matching network for video object segmentation. In: ICCV (2021) 12\n\nJ Shao, S Chen, Y Li, K Wang, Z Yin, Y He, J Teng, Q Sun, M Gao, J Liu, arXiv:2111.08687INTERN: A new learning paradigm towards general vision. 14arXiv preprintShao, J., Chen, S., Li, Y., Wang, K., Yin, Z., He, Y., Teng, J., Sun, Q., Gao, M., Liu, J., et al.: INTERN: A new learning paradigm towards general vision. arXiv preprint arXiv:2111.08687 (2021) 1, 4\n\nCrowdhuman: A benchmark for detecting human in a crowd. S Shao, Z Zhao, B Li, T Xiao, G Yu, X Zhang, J Sun, arXiv:1805.0012320arXiv preprintShao, S., Zhao, Z., Li, B., Xiao, T., Yu, G., Zhang, X., Sun, J.: Crowdhuman: A benchmark for detecting human in a crowd. arXiv preprint arXiv:1805.00123 (2018) 20\n\nP Sun, Y Jiang, R Zhang, E Xie, J Cao, X Hu, T Kong, Z Yuan, C Wang, P Luo, arXiv:2012.15460TransTrack: Multiple-object tracking with transformer. 311arXiv preprintSun, P., Jiang, Y., Zhang, R., Xie, E., Cao, J., Hu, X., Kong, T., Yuan, Z., Wang, C., Luo, P.: TransTrack: Multiple-object tracking with transformer. arXiv preprint arXiv:2012.15460 (2020) 3, 11\n\nSparse r-cnn: End-to-end object detection with learnable proposals. P Sun, R Zhang, Y Jiang, T Kong, C Xu, W Zhan, M Tomizuka, L Li, Z Yuan, C Wang, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition3Sun, P., Zhang, R., Jiang, Y., Kong, T., Xu, C., Zhan, W., Tomizuka, M., Li, L., Yuan, Z., Wang, C., et al.: Sparse r-cnn: End-to-end object detection with learnable proposals. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 14454-14463 (2021) 3\n\nRaft: Recurrent all-pairs field transforms for optical flow. Z Teed, J Deng, ECCV5Teed, Z., Deng, J.: Raft: Recurrent all-pairs field transforms for optical flow. In: ECCV (2020) 5\n\nConditional convolutions for instance segmentation. Z Tian, C Shen, H Chen, ECCV (2020). 820Tian, Z., Shen, C., Chen, H.: Conditional convolutions for instance segmentation. In: ECCV (2020) 8, 20\n\nGocor: Bringing globally optimized correspondence volumes into your neural network. P Truong, M Danelljan, L V Gool, R Timofte, NeurIPS. 5Truong, P., Danelljan, M., Gool, L.V., Timofte, R.: Gocor: Bringing globally opti- mized correspondence volumes into your neural network. NeurIPS (2020) 5\n\nLearning accurate dense correspondences and when to trust them. P Truong, M Danelljan, L Van Gool, R Timofte, CVPR5Truong, P., Danelljan, M., Van Gool, L., Timofte, R.: Learning accurate dense correspondences and when to trust them. In: CVPR (2021) 5\n\nJ Valmadre, L Bertinetto, J F Henriques, R Tao, A Vedaldi, A W Smeulders, P H Torr, E Gavves, Long-term tracking in the wild: a benchmark. ECCV4Valmadre, J., Bertinetto, L., Henriques, J.F., Tao, R., Vedaldi, A., Smeulders, A.W., Torr, P.H., Gavves, E.: Long-term tracking in the wild: a benchmark. In: ECCV (2018) 4\n\nAttention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, NeurIPS (2017) 5. 713Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I.: Attention is all you need. In: NeurIPS (2017) 5, 7, 13\n\nMOTS: Multi-object tracking and segmentation. P Voigtlaender, M Krause, A Osep, J Luiten, B B G Sekar, A Geiger, B Leibe, CVPR. 1320Voigtlaender, P., Krause, M., Osep, A., Luiten, J., Sekar, B.B.G., Geiger, A., Leibe, B.: MOTS: Multi-object tracking and segmentation. In: CVPR (2019) 2, 4, 12, 13, 20\n\nSiam R-CNN: Visual tracking by re-detection. P Voigtlaender, J Luiten, P H Torr, B Leibe, 1012In: CVPR (2020) 2, 3, 4Voigtlaender, P., Luiten, J., Torr, P.H., Leibe, B.: Siam R-CNN: Visual tracking by re-detection. In: CVPR (2020) 2, 3, 4, 10, 12\n\nTransformer meets tracker: Exploiting temporal context for robust visual tracking. N Wang, W Zhou, J Wang, H Li, CVPR10Wang, N., Zhou, W., Wang, J., Li, H.: Transformer meets tracker: Exploiting temporal context for robust visual tracking. In: CVPR (2021) 10\n\nFast online object tracking and segmentation: A unifying approach. Q Wang, L Zhang, L Bertinetto, W Hu, P H S Torr, CVPR (2019) 2, 4, 5. 1112Wang, Q., Zhang, L., Bertinetto, L., Hu, W., Torr, P.H.S.: Fast online object tracking and segmentation: A unifying approach. In: CVPR (2019) 2, 4, 5, 11, 12\n\nMultiple object tracking with correlation learning. Q Wang, Y Zheng, P Pan, Y Xu, CVPR11Wang, Q., Zheng, Y., Pan, P., Xu, Y.: Multiple object tracking with correlation learning. In: CVPR (2021) 11\n\nDo different tracking tasks require different appearance models?. Z Wang, H Zhao, Y L Li, S Wang, P Torr, L Bertinetto, NeurIPS. 512Wang, Z., Zhao, H., Li, Y.L., Wang, S., Torr, P., Bertinetto, L.: Do different track- ing tasks require different appearance models? NeurIPS (2021) 5, 10, 12\n\nTowards real-time multi-object tracking. Z Wang, L Zheng, Y Liu, Y Li, S Wang, ECCV23Wang, Z., Zheng, L., Liu, Y., Li, Y., Wang, S.: Towards real-time multi-object tracking. In: ECCV (2020) 2, 3\n\nRanet: Ranking attention network for fast video object segmentation. Z Wang, J Xu, L Liu, F Zhu, L Shao, ICCV. 1112Wang, Z., Xu, J., Liu, L., Zhu, F., Shao, L.: Ranet: Ranking attention network for fast video object segmentation. In: ICCV (2019) 11, 12\n\nSimple online and realtime tracking with a deep association metric. N Wojke, A Bewley, D Paulus, ICIP. 3Wojke, N., Bewley, A., Paulus, D.: Simple online and realtime tracking with a deep association metric. In: ICIP (2017) 3\n\nTrack to detect and segment: An online multi-object tracker. J Wu, J Cao, L Song, Y Wang, M Yang, J Yuan, CVPR (2021) 2, 4, 5. 1113Wu, J., Cao, J., Song, L., Wang, Y., Yang, M., Yuan, J.: Track to detect and segment: An online multi-object tracker. In: CVPR (2021) 2, 4, 5, 11, 13\n\nY Wu, K He, Group Normalization. In: ECCV. 9Wu, Y., He, K.: Group Normalization. In: ECCV (2018) 9\n\nN Xu, L Yang, Y Fan, D Yue, Y Liang, J Yang, T Huang, arXiv:1809.03327YouTube-VOS: A large-scale video object segmentation benchmark. 20arXiv preprintXu, N., Yang, L., Fan, Y., Yue, D., Liang, Y., Yang, J., Huang, T.: YouTube- VOS: A large-scale video object segmentation benchmark. arXiv preprint arXiv:1809.03327 (2018) 20\n\nY Xu, Y Ban, G Delorme, C Gan, D Rus, X Alameda-Pineda, arXiv:2103.15145Transcenter: Transformers with dense queries for multiple-object tracking. 11arXiv preprintXu, Y., Ban, Y., Delorme, G., Gan, C., Rus, D., Alameda-Pineda, X.: Transcen- ter: Transformers with dense queries for multiple-object tracking. arXiv preprint arXiv:2103.15145 (2021) 11\n\nHow to train your deep multi-object tracker. Y Xu, A Osep, Y Ban, R Horaud, L Leal-Taix\u00e9, X Alameda-Pineda, CVPRXu, Y., Osep, A., Ban, Y., Horaud, R., Leal-Taix\u00e9, L., Alameda-Pineda, X.: How to train your deep multi-object tracker. In: CVPR (2020) 2\n\nSiamFC++: towards robust and accurate visual tracking with target estimation guidelines. Y Xu, Z Wang, Z Li, Y Yuan, G Yu, AAAI310Xu, Y., Wang, Z., Li, Z., Yuan, Y., Yu, G.: SiamFC++: towards robust and accu- rate visual tracking with target estimation guidelines. In: AAAI (2020) 3, 10\n\nSegment as points for efficient and effective online multi-object tracking and segmentation. Z Xu, W Yang, W Zhang, X Tan, H Huang, L Huang, TPAMI. 1213Xu, Z., Yang, W., Zhang, W., Tan, X., Huang, H., Huang, L.: Segment as points for efficient and effective online multi-object tracking and segmentation. TPAMI (2021) 12, 13\n\nLearning spatio-temporal transformer for visual tracking. B Yan, H Peng, J Fu, D Wang, H Lu, ICCV (2021). 210Yan, B., Peng, H., Fu, J., Wang, D., Lu, H.: Learning spatio-temporal transformer for visual tracking. In: ICCV (2021) 2, 3, 10\n\nVideo instance segmentation. L Yang, Y Fan, N Xu, ICCV. 13Yang, L., Fan, Y., Xu, N.: Video instance segmentation. In: ICCV (2019) 13\n\nCollaborative video object segmentation by foreground-background integration. Z Yang, Y Wei, Y Yang, ECCV412Yang, Z., Wei, Y., Yang, Y.: Collaborative video object segmentation by foreground-background integration. In: ECCV (2020) 4, 12\n\nBDD100K: A diverse driving dataset for heterogeneous multitask learning. F Yu, H Chen, X Wang, W Xian, Y Chen, F Liu, V Madhavan, T Darrell, CVPR (2020) 1, 2, 4. 1020Yu, F., Chen, H., Wang, X., Xian, W., Chen, Y., Liu, F., Madhavan, V., Darrell, T.: BDD100K: A diverse driving dataset for heterogeneous multitask learning. In: CVPR (2020) 1, 2, 4, 10, 11, 12, 20\n\nL Yuan, D Chen, Y L Chen, N Codella, X Dai, J Gao, H Hu, X Huang, B Li, C Li, arXiv:2111.11432Florence: A new foundation model for computer vision. 14arXiv preprintYuan, L., Chen, D., Chen, Y.L., Codella, N., Dai, X., Gao, J., Hu, H., Huang, X., Li, B., Li, C., et al.: Florence: A new foundation model for computer vision. arXiv preprint arXiv:2111.11432 (2021) 1, 4\n\nMOTR: End-to-end multipleobject tracking with transformer. F Zeng, B Dong, T Wang, X Zhang, Y Wei, arXiv:2105.03247311arXiv preprintZeng, F., Dong, B., Wang, T., Zhang, X., Wei, Y.: MOTR: End-to-end multiple- object tracking with transformer. arXiv preprint arXiv:2105.03247 (2021) 3, 11\n\nCitypersons: A diverse dataset for pedestrian detection. S Zhang, R Benenson, B Schiele, CVPR20Zhang, S., Benenson, R., Schiele, B.: Citypersons: A diverse dataset for pedestrian detection. In: CVPR (2017) 20\n\nY Zhang, P Sun, Y Jiang, D Yu, Z Yuan, P Luo, W Liu, X Wang, arXiv:2110.06864Bytetrack: Multi-object tracking by associating every detection box. 3arXiv preprintZhang, Y., Sun, P., Jiang, Y., Yu, D., Yuan, Z., Luo, P., Liu, W., Wang, X.: Bytetrack: Multi-object tracking by associating every detection box. arXiv preprint arXiv:2110.06864 (2021) 3\n\nFairMOT: On the fairness of detection and re-identification in multiple object tracking. Y Zhang, C Wang, X Wang, W Zeng, W Liu, IJCV. 211Zhang, Y., Wang, C., Wang, X., Zeng, W., Liu, W.: FairMOT: On the fairness of detection and re-identification in multiple object tracking. IJCV (2021) 2, 3, 11\n\nA transductive approach for video object segmentation. Y Zhang, Z Wu, H Peng, S Lin, CVPR512Zhang, Y., Wu, Z., Peng, H., Lin, S.: A transductive approach for video object segmentation. In: CVPR (2020) 5, 12\n\nLearn to match: Automatic matching network design for visual tracking. Z Zhang, Y Liu, X Wang, B Li, W Hu, ICCV10Zhang, Z., Liu, Y., Wang, X., Li, B., Hu, W.: Learn to match: Automatic matching network design for visual tracking. In: ICCV (2021) 10\n\nOcean: Object-aware anchor-free tracking. Z Zhang, H Peng, J Fu, B Li, W Hu, ECCV10Zhang, Z., Peng, H., Fu, J., Li, B., Hu, W.: Ocean: Object-aware anchor-free track- ing. In: ECCV (2020) 10\n\nImproving multiple object tracking with single object tracking. L Zheng, M Tang, Y Chen, G Zhu, J Wang, H Lu, CVPR11Zheng, L., Tang, M., Chen, Y., Zhu, G., Wang, J., Lu, H.: Improving multiple object tracking with single object tracking. In: CVPR (2021) 11\n\nTracking objects as points. X Zhou, V Koltun, P Kr\u00e4henb\u00fchl, ECCV (2020). 211Zhou, X., Koltun, V., Kr\u00e4henb\u00fchl, P.: Tracking objects as points. In: ECCV (2020) 2, 3, 11\n\nX Zhou, D Wang, P Kr\u00e4henb\u00fchl, arXiv:1904.07850Objects as points. 3arXiv preprintZhou, X., Wang, D., Kr\u00e4henb\u00fchl, P.: Objects as points. arXiv preprint arXiv:1904.07850 (2019) 3\n\nSaliency-associated object tracking. Z Zhou, W Pei, X Li, H Wang, F Zheng, Z He, ICCV10Zhou, Z., Pei, W., Li, X., Wang, H., Zheng, F., He, Z.: Saliency-associated object tracking. In: ICCV (2021) 10\n\nOnline multi-object tracking with dual matching attention networks. J Zhu, H Yang, N Liu, M Kim, W Zhang, M H Yang, ECCV4Zhu, J., Yang, H., Liu, N., Kim, M., Zhang, W., Yang, M.H.: Online multi-object tracking with dual matching attention networks. In: ECCV (2018) 4\n\nDeformable detr: Deformable transformers for end-to-end object detection. X Zhu, W Su, L Lu, B Li, X Wang, J Dai, ICLR (2020) 3, 5. 713Zhu, X., Su, W., Lu, L., Li, B., Wang, X., Dai, J.: Deformable detr: Deformable transformers for end-to-end object detection. In: ICLR (2020) 3, 5, 7, 13\n", "annotations": {"author": "[{\"end\":56,\"start\":48},{\"end\":154,\"start\":57},{\"end\":161,\"start\":155},{\"end\":201,\"start\":162},{\"end\":303,\"start\":202},{\"end\":316,\"start\":304},{\"end\":355,\"start\":317},{\"end\":482,\"start\":356}]", "publisher": null, "author_last_name": "[{\"end\":55,\"start\":52},{\"end\":62,\"start\":60},{\"end\":160,\"start\":155},{\"end\":171,\"start\":168},{\"end\":211,\"start\":207},{\"end\":315,\"start\":311},{\"end\":325,\"start\":322},{\"end\":366,\"start\":364}]", "author_first_name": "[{\"end\":51,\"start\":48},{\"end\":59,\"start\":57},{\"end\":167,\"start\":162},{\"end\":206,\"start\":202},{\"end\":310,\"start\":304},{\"end\":321,\"start\":317},{\"end\":363,\"start\":356}]", "author_affiliation": "[{\"end\":153,\"start\":64},{\"end\":200,\"start\":173},{\"end\":302,\"start\":213},{\"end\":354,\"start\":327},{\"end\":457,\"start\":368},{\"end\":481,\"start\":459}]", "title": "[{\"end\":45,\"start\":1},{\"end\":527,\"start\":483}]", "venue": null, "abstract": "[{\"end\":1501,\"start\":544}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b19\"},\"end\":1826,\"start\":1822},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":1829,\"start\":1826},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":1832,\"start\":1829},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":1835,\"start\":1832},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2351,\"start\":2347},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2354,\"start\":2351},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2391,\"start\":2387},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":2394,\"start\":2391},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":2432,\"start\":2428},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":2488,\"start\":2484},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":2491,\"start\":2488},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":3168,\"start\":3164},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3171,\"start\":3168},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":3174,\"start\":3171},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":3177,\"start\":3174},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3180,\"start\":3177},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3417,\"start\":3414},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3649,\"start\":3646},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3876,\"start\":3873},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3879,\"start\":3876},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3882,\"start\":3879},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3884,\"start\":3882},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3886,\"start\":3884},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":3889,\"start\":3886},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4016,\"start\":4013},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":4019,\"start\":4016},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4021,\"start\":4019},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":4024,\"start\":4021},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":4027,\"start\":4024},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":4030,\"start\":4027},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":4033,\"start\":4030},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4629,\"start\":4626},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6895,\"start\":6892},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":6898,\"start\":6895},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":6901,\"start\":6898},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6904,\"start\":6901},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6906,\"start\":6904},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6908,\"start\":6906},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":6911,\"start\":6908},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7588,\"start\":7584},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":7591,\"start\":7588},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7878,\"start\":7874},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7898,\"start\":7894},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8120,\"start\":8116},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":8487,\"start\":8483},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":8490,\"start\":8487},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":8493,\"start\":8490},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":8496,\"start\":8493},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":8499,\"start\":8496},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":8709,\"start\":8705},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8731,\"start\":8727},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8734,\"start\":8731},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":8751,\"start\":8747},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":8770,\"start\":8766},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":8796,\"start\":8792},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8855,\"start\":8852},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":8858,\"start\":8855},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8877,\"start\":8874},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":8880,\"start\":8877},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":8883,\"start\":8880},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":8904,\"start\":8900},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":8907,\"start\":8904},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":8910,\"start\":8907},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":8913,\"start\":8910},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":8931,\"start\":8927},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8934,\"start\":8931},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":8937,\"start\":8934},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":8970,\"start\":8966},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":9007,\"start\":9003},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9010,\"start\":9007},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9080,\"start\":9076},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9082,\"start\":9080},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9410,\"start\":9406},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":9413,\"start\":9410},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9416,\"start\":9413},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9769,\"start\":9765},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":9772,\"start\":9769},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":9869,\"start\":9865},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":9908,\"start\":9904},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":10234,\"start\":10230},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10237,\"start\":10234},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":10240,\"start\":10237},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":10469,\"start\":10465},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":10472,\"start\":10469},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10531,\"start\":10527},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":10534,\"start\":10531},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":10666,\"start\":10662},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":10683,\"start\":10680},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10719,\"start\":10715},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":10761,\"start\":10757},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10791,\"start\":10787},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11141,\"start\":11137},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":11144,\"start\":11141},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":11147,\"start\":11144},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11150,\"start\":11147},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":11406,\"start\":11402},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":11657,\"start\":11653},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11903,\"start\":11899},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":12100,\"start\":12096},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":12103,\"start\":12100},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":12106,\"start\":12103},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":12214,\"start\":12210},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":12294,\"start\":12290},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":12381,\"start\":12377},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":13499,\"start\":13495},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":13531,\"start\":13527},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":13534,\"start\":13531},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":13559,\"start\":13555},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":13562,\"start\":13559},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":13707,\"start\":13703},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":13710,\"start\":13707},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":13713,\"start\":13710},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":13947,\"start\":13943},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":13950,\"start\":13947},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":14104,\"start\":14100},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":14126,\"start\":14122},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":15456,\"start\":15452},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":17508,\"start\":17504},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":17893,\"start\":17889},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":19179,\"start\":19175},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":19732,\"start\":19728},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":19735,\"start\":19732},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22730,\"start\":22726},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22821,\"start\":22817},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":22840,\"start\":22836},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23128,\"start\":23124},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":23158,\"start\":23154},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":23375,\"start\":23371},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23958,\"start\":23954},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":23979,\"start\":23975},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":24179,\"start\":24175},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":24529,\"start\":24525},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":24720,\"start\":24716},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":25056,\"start\":25052},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":25073,\"start\":25069},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":26333,\"start\":26329},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":26560,\"start\":26556},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":26941,\"start\":26937},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":26955,\"start\":26951},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":27054,\"start\":27050},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":27312,\"start\":27308},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":27414,\"start\":27410},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":27810,\"start\":27806},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27824,\"start\":27820},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":27990,\"start\":27986},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":28016,\"start\":28012},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":28412,\"start\":28408},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28623,\"start\":28619},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":29047,\"start\":29043},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":29187,\"start\":29183},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":29414,\"start\":29410},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":29450,\"start\":29446},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":31746,\"start\":31742},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":31786,\"start\":31782},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":32374,\"start\":32370},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32386,\"start\":32382},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":32400,\"start\":32396},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":32421,\"start\":32417},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":32496,\"start\":32492},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":32507,\"start\":32503},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":32524,\"start\":32520},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":32536,\"start\":32532},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":32604,\"start\":32600},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":33066,\"start\":33062},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":33078,\"start\":33074},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":33096,\"start\":33092},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":33117,\"start\":33113},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":33131,\"start\":33127},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":33521,\"start\":33517},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":33541,\"start\":33537},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":35679,\"start\":35675}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33296,\"start\":33235},{\"attributes\":{\"id\":\"fig_1\"},\"end\":33422,\"start\":33297},{\"attributes\":{\"id\":\"fig_2\"},\"end\":33468,\"start\":33423},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":34598,\"start\":33469},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":35624,\"start\":34599},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":36001,\"start\":35625},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":37004,\"start\":36002},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":37383,\"start\":37005},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":37845,\"start\":37384},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":38653,\"start\":37846}]", "paragraph": "[{\"end\":1955,\"start\":1517},{\"end\":3142,\"start\":1957},{\"end\":4141,\"start\":3144},{\"end\":5132,\"start\":4143},{\"end\":5736,\"start\":5134},{\"end\":5896,\"start\":5738},{\"end\":6048,\"start\":5898},{\"end\":6109,\"start\":6050},{\"end\":6573,\"start\":6111},{\"end\":8971,\"start\":6615},{\"end\":9219,\"start\":8973},{\"end\":10346,\"start\":9221},{\"end\":10792,\"start\":10348},{\"end\":12031,\"start\":10818},{\"end\":13380,\"start\":12066},{\"end\":14336,\"start\":13408},{\"end\":14946,\"start\":14349},{\"end\":15288,\"start\":14978},{\"end\":15754,\"start\":15290},{\"end\":16291,\"start\":15776},{\"end\":17061,\"start\":16293},{\"end\":17411,\"start\":17130},{\"end\":18031,\"start\":17413},{\"end\":18716,\"start\":18090},{\"end\":19073,\"start\":18765},{\"end\":19227,\"start\":19103},{\"end\":19944,\"start\":19341},{\"end\":20466,\"start\":19946},{\"end\":21454,\"start\":20529},{\"end\":21857,\"start\":21481},{\"end\":22614,\"start\":21859},{\"end\":23809,\"start\":22655},{\"end\":24689,\"start\":23851},{\"end\":24917,\"start\":24691},{\"end\":25480,\"start\":24961},{\"end\":26444,\"start\":25482},{\"end\":26691,\"start\":26489},{\"end\":27858,\"start\":26693},{\"end\":28193,\"start\":27916},{\"end\":28449,\"start\":28195},{\"end\":28817,\"start\":28451},{\"end\":29122,\"start\":28854},{\"end\":29345,\"start\":29124},{\"end\":29799,\"start\":29347},{\"end\":30402,\"start\":29801},{\"end\":30629,\"start\":30404},{\"end\":30937,\"start\":30631},{\"end\":31405,\"start\":30953},{\"end\":31906,\"start\":31437},{\"end\":33234,\"start\":31929}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17129,\"start\":17062},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18089,\"start\":18032},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18764,\"start\":18717},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19102,\"start\":19074},{\"attributes\":{\"id\":\"formula_4\"},\"end\":19325,\"start\":19228},{\"attributes\":{\"id\":\"formula_5\"},\"end\":20528,\"start\":20467}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1515,\"start\":1503},{\"attributes\":{\"n\":\"2\"},\"end\":6588,\"start\":6576},{\"attributes\":{\"n\":\"2.1\"},\"end\":6613,\"start\":6591},{\"attributes\":{\"n\":\"2.2\"},\"end\":10816,\"start\":10795},{\"attributes\":{\"n\":\"2.3\"},\"end\":12064,\"start\":12034},{\"attributes\":{\"n\":\"2.4\"},\"end\":13406,\"start\":13383},{\"attributes\":{\"n\":\"3\"},\"end\":14347,\"start\":14339},{\"attributes\":{\"n\":\"3.1\"},\"end\":14976,\"start\":14949},{\"attributes\":{\"n\":\"3.2\"},\"end\":15774,\"start\":15757},{\"attributes\":{\"n\":\"3.3\"},\"end\":19339,\"start\":19327},{\"attributes\":{\"n\":\"3.4\"},\"end\":21479,\"start\":21457},{\"attributes\":{\"n\":\"4\"},\"end\":22628,\"start\":22617},{\"attributes\":{\"n\":\"4.1\"},\"end\":22653,\"start\":22631},{\"attributes\":{\"n\":\"4.2\"},\"end\":23849,\"start\":23812},{\"attributes\":{\"n\":\"4.3\"},\"end\":24959,\"start\":24920},{\"attributes\":{\"n\":\"4.4\"},\"end\":26487,\"start\":26447},{\"attributes\":{\"n\":\"4.5\"},\"end\":27914,\"start\":27861},{\"attributes\":{\"n\":\"4.6\"},\"end\":28852,\"start\":28820},{\"attributes\":{\"n\":\"5\"},\"end\":30951,\"start\":30940},{\"end\":31435,\"start\":31408},{\"end\":31927,\"start\":31909},{\"end\":33244,\"start\":33236},{\"end\":33306,\"start\":33298},{\"end\":33432,\"start\":33424},{\"end\":33479,\"start\":33470},{\"end\":34609,\"start\":34600},{\"end\":35635,\"start\":35626},{\"end\":36012,\"start\":36003},{\"end\":37015,\"start\":37006},{\"end\":37394,\"start\":37385},{\"end\":37856,\"start\":37847}]", "table": "[{\"end\":34598,\"start\":33542},{\"end\":35624,\"start\":34662},{\"end\":36001,\"start\":35704},{\"end\":37004,\"start\":36161},{\"end\":37383,\"start\":37071},{\"end\":37845,\"start\":37459},{\"end\":38653,\"start\":37919}]", "figure_caption": "[{\"end\":33296,\"start\":33246},{\"end\":33422,\"start\":33308},{\"end\":33468,\"start\":33434},{\"end\":33542,\"start\":33481},{\"end\":34662,\"start\":34611},{\"end\":35704,\"start\":35637},{\"end\":36161,\"start\":36014},{\"end\":37071,\"start\":37017},{\"end\":37459,\"start\":37396},{\"end\":37919,\"start\":37858}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14737,\"start\":14729},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":30657,\"start\":30649},{\"end\":31486,\"start\":31480},{\"end\":33191,\"start\":33185}]", "bib_author_first_name": "[{\"end\":38729,\"start\":38728},{\"end\":38738,\"start\":38737},{\"end\":38751,\"start\":38750},{\"end\":38759,\"start\":38758},{\"end\":38773,\"start\":38772},{\"end\":38996,\"start\":38995},{\"end\":39008,\"start\":39007},{\"end\":39021,\"start\":39020},{\"end\":39200,\"start\":39199},{\"end\":39214,\"start\":39213},{\"end\":39226,\"start\":39225},{\"end\":39228,\"start\":39227},{\"end\":39241,\"start\":39240},{\"end\":39252,\"start\":39251},{\"end\":39256,\"start\":39253},{\"end\":39472,\"start\":39471},{\"end\":39482,\"start\":39481},{\"end\":39488,\"start\":39487},{\"end\":39495,\"start\":39494},{\"end\":39504,\"start\":39503},{\"end\":39686,\"start\":39685},{\"end\":39694,\"start\":39693},{\"end\":39707,\"start\":39706},{\"end\":39709,\"start\":39708},{\"end\":39717,\"start\":39716},{\"end\":39942,\"start\":39941},{\"end\":39950,\"start\":39949},{\"end\":39963,\"start\":39962},{\"end\":39965,\"start\":39964},{\"end\":39973,\"start\":39972},{\"end\":40190,\"start\":40189},{\"end\":40198,\"start\":40197},{\"end\":40200,\"start\":40199},{\"end\":40209,\"start\":40208},{\"end\":40222,\"start\":40221},{\"end\":40234,\"start\":40233},{\"end\":40246,\"start\":40245},{\"end\":40248,\"start\":40247},{\"end\":40256,\"start\":40255},{\"end\":40493,\"start\":40492},{\"end\":40502,\"start\":40501},{\"end\":40652,\"start\":40651},{\"end\":40660,\"start\":40659},{\"end\":40667,\"start\":40666},{\"end\":40674,\"start\":40673},{\"end\":40682,\"start\":40681},{\"end\":40690,\"start\":40689},{\"end\":40918,\"start\":40917},{\"end\":40920,\"start\":40919},{\"end\":40929,\"start\":40928},{\"end\":40931,\"start\":40930},{\"end\":40938,\"start\":40937},{\"end\":40940,\"start\":40939},{\"end\":41193,\"start\":41192},{\"end\":41202,\"start\":41201},{\"end\":41204,\"start\":41203},{\"end\":41212,\"start\":41211},{\"end\":41214,\"start\":41213},{\"end\":41222,\"start\":41221},{\"end\":41230,\"start\":41229},{\"end\":41232,\"start\":41231},{\"end\":41508,\"start\":41507},{\"end\":41515,\"start\":41514},{\"end\":41680,\"start\":41679},{\"end\":41687,\"start\":41686},{\"end\":41695,\"start\":41694},{\"end\":41702,\"start\":41701},{\"end\":41710,\"start\":41709},{\"end\":42040,\"start\":42039},{\"end\":42053,\"start\":42052},{\"end\":42061,\"start\":42060},{\"end\":42063,\"start\":42062},{\"end\":42071,\"start\":42070},{\"end\":42258,\"start\":42257},{\"end\":42271,\"start\":42270},{\"end\":42279,\"start\":42278},{\"end\":42281,\"start\":42280},{\"end\":42289,\"start\":42288},{\"end\":42482,\"start\":42481},{\"end\":42495,\"start\":42494},{\"end\":42497,\"start\":42496},{\"end\":42505,\"start\":42504},{\"end\":42685,\"start\":42684},{\"end\":42692,\"start\":42691},{\"end\":42701,\"start\":42700},{\"end\":42714,\"start\":42713},{\"end\":42930,\"start\":42929},{\"end\":42937,\"start\":42936},{\"end\":42944,\"start\":42943},{\"end\":42952,\"start\":42951},{\"end\":42959,\"start\":42958},{\"end\":42967,\"start\":42966},{\"end\":42973,\"start\":42972},{\"end\":42980,\"start\":42979},{\"end\":42986,\"start\":42985},{\"end\":42994,\"start\":42993},{\"end\":43224,\"start\":43223},{\"end\":43230,\"start\":43229},{\"end\":43237,\"start\":43236},{\"end\":43245,\"start\":43244},{\"end\":43251,\"start\":43250},{\"end\":43523,\"start\":43522},{\"end\":43533,\"start\":43532},{\"end\":43541,\"start\":43540},{\"end\":43543,\"start\":43542},{\"end\":43552,\"start\":43551},{\"end\":43554,\"start\":43553},{\"end\":43560,\"start\":43559},{\"end\":43562,\"start\":43561},{\"end\":43778,\"start\":43777},{\"end\":43789,\"start\":43788},{\"end\":43798,\"start\":43797},{\"end\":43806,\"start\":43805},{\"end\":43824,\"start\":43823},{\"end\":43834,\"start\":43833},{\"end\":44098,\"start\":44097},{\"end\":44104,\"start\":44103},{\"end\":44113,\"start\":44112},{\"end\":44120,\"start\":44119},{\"end\":44294,\"start\":44293},{\"end\":44296,\"start\":44295},{\"end\":44302,\"start\":44301},{\"end\":44304,\"start\":44303},{\"end\":44313,\"start\":44312},{\"end\":44315,\"start\":44314},{\"end\":44527,\"start\":44526},{\"end\":44536,\"start\":44535},{\"end\":44544,\"start\":44543},{\"end\":44760,\"start\":44759},{\"end\":44769,\"start\":44768},{\"end\":44777,\"start\":44776},{\"end\":45008,\"start\":45007},{\"end\":45017,\"start\":45016},{\"end\":45172,\"start\":45171},{\"end\":45181,\"start\":45180},{\"end\":45190,\"start\":45189},{\"end\":45447,\"start\":45446},{\"end\":45453,\"start\":45452},{\"end\":45459,\"start\":45458},{\"end\":45472,\"start\":45471},{\"end\":45474,\"start\":45473},{\"end\":45481,\"start\":45480},{\"end\":45483,\"start\":45482},{\"end\":45491,\"start\":45490},{\"end\":45752,\"start\":45751},{\"end\":45758,\"start\":45757},{\"end\":45764,\"start\":45763},{\"end\":45772,\"start\":45771},{\"end\":45781,\"start\":45780},{\"end\":45789,\"start\":45788},{\"end\":46040,\"start\":46039},{\"end\":46049,\"start\":46048},{\"end\":46058,\"start\":46057},{\"end\":46064,\"start\":46063},{\"end\":46072,\"start\":46071},{\"end\":46078,\"start\":46077},{\"end\":46084,\"start\":46083},{\"end\":46311,\"start\":46310},{\"end\":46320,\"start\":46319},{\"end\":46329,\"start\":46328},{\"end\":46337,\"start\":46336},{\"end\":46343,\"start\":46342},{\"end\":46349,\"start\":46348},{\"end\":46651,\"start\":46650},{\"end\":46653,\"start\":46652},{\"end\":46660,\"start\":46659},{\"end\":46670,\"start\":46669},{\"end\":46682,\"start\":46681},{\"end\":46688,\"start\":46687},{\"end\":46701,\"start\":46700},{\"end\":46854,\"start\":46853},{\"end\":46856,\"start\":46855},{\"end\":46863,\"start\":46862},{\"end\":46872,\"start\":46871},{\"end\":46874,\"start\":46873},{\"end\":46886,\"start\":46885},{\"end\":46888,\"start\":46887},{\"end\":46899,\"start\":46898},{\"end\":46901,\"start\":46900},{\"end\":46913,\"start\":46912},{\"end\":46921,\"start\":46920},{\"end\":46931,\"start\":46930},{\"end\":46942,\"start\":46941},{\"end\":46952,\"start\":46951},{\"end\":46954,\"start\":46953},{\"end\":47210,\"start\":47209},{\"end\":47217,\"start\":47216},{\"end\":47224,\"start\":47223},{\"end\":47226,\"start\":47225},{\"end\":47232,\"start\":47231},{\"end\":47249,\"start\":47248},{\"end\":47260,\"start\":47259},{\"end\":47465,\"start\":47464},{\"end\":47479,\"start\":47478},{\"end\":47723,\"start\":47722},{\"end\":47734,\"start\":47733},{\"end\":47743,\"start\":47742},{\"end\":47954,\"start\":47953},{\"end\":47956,\"start\":47955},{\"end\":47967,\"start\":47966},{\"end\":47978,\"start\":47977},{\"end\":47986,\"start\":47985},{\"end\":48000,\"start\":47999},{\"end\":48014,\"start\":48013},{\"end\":48025,\"start\":48024},{\"end\":48290,\"start\":48289},{\"end\":48299,\"start\":48298},{\"end\":48312,\"start\":48311},{\"end\":48314,\"start\":48313},{\"end\":48324,\"start\":48323},{\"end\":48543,\"start\":48542},{\"end\":48556,\"start\":48555},{\"end\":48568,\"start\":48567},{\"end\":48582,\"start\":48581},{\"end\":48806,\"start\":48805},{\"end\":48815,\"start\":48814},{\"end\":48829,\"start\":48828},{\"end\":48837,\"start\":48836},{\"end\":48845,\"start\":48844},{\"end\":49189,\"start\":49188},{\"end\":49202,\"start\":49201},{\"end\":49211,\"start\":49210},{\"end\":49213,\"start\":49212},{\"end\":49449,\"start\":49448},{\"end\":49459,\"start\":49458},{\"end\":49467,\"start\":49466},{\"end\":49479,\"start\":49478},{\"end\":49492,\"start\":49491},{\"end\":49747,\"start\":49746},{\"end\":49749,\"start\":49748},{\"end\":49755,\"start\":49754},{\"end\":49757,\"start\":49756},{\"end\":49764,\"start\":49763},{\"end\":49770,\"start\":49769},{\"end\":49772,\"start\":49771},{\"end\":49973,\"start\":49972},{\"end\":49981,\"start\":49980},{\"end\":49988,\"start\":49987},{\"end\":49994,\"start\":49993},{\"end\":50002,\"start\":50001},{\"end\":50008,\"start\":50007},{\"end\":50019,\"start\":50018},{\"end\":50318,\"start\":50317},{\"end\":50326,\"start\":50325},{\"end\":50334,\"start\":50333},{\"end\":50341,\"start\":50340},{\"end\":50347,\"start\":50346},{\"end\":50355,\"start\":50354},{\"end\":50362,\"start\":50361},{\"end\":50370,\"start\":50369},{\"end\":50376,\"start\":50375},{\"end\":50385,\"start\":50384},{\"end\":50634,\"start\":50633},{\"end\":50648,\"start\":50647},{\"end\":50659,\"start\":50658},{\"end\":50670,\"start\":50669},{\"end\":50682,\"start\":50681},{\"end\":50701,\"start\":50700},{\"end\":51000,\"start\":50999},{\"end\":51010,\"start\":51009},{\"end\":51271,\"start\":51270},{\"end\":51278,\"start\":51277},{\"end\":51284,\"start\":51283},{\"end\":51296,\"start\":51295},{\"end\":51523,\"start\":51522},{\"end\":51535,\"start\":51534},{\"end\":51537,\"start\":51536},{\"end\":51546,\"start\":51545},{\"end\":51559,\"start\":51558},{\"end\":51561,\"start\":51560},{\"end\":51569,\"start\":51568},{\"end\":51819,\"start\":51818},{\"end\":51828,\"start\":51827},{\"end\":51830,\"start\":51829},{\"end\":51836,\"start\":51835},{\"end\":51838,\"start\":51837},{\"end\":51845,\"start\":51844},{\"end\":51852,\"start\":51851},{\"end\":51859,\"start\":51858},{\"end\":52019,\"start\":52018},{\"end\":52027,\"start\":52026},{\"end\":52035,\"start\":52034},{\"end\":52041,\"start\":52040},{\"end\":52049,\"start\":52048},{\"end\":52056,\"start\":52055},{\"end\":52062,\"start\":52061},{\"end\":52070,\"start\":52069},{\"end\":52077,\"start\":52076},{\"end\":52084,\"start\":52083},{\"end\":52436,\"start\":52435},{\"end\":52444,\"start\":52443},{\"end\":52452,\"start\":52451},{\"end\":52458,\"start\":52457},{\"end\":52466,\"start\":52465},{\"end\":52472,\"start\":52471},{\"end\":52481,\"start\":52480},{\"end\":52685,\"start\":52684},{\"end\":52692,\"start\":52691},{\"end\":52701,\"start\":52700},{\"end\":52710,\"start\":52709},{\"end\":52717,\"start\":52716},{\"end\":52724,\"start\":52723},{\"end\":52730,\"start\":52729},{\"end\":52738,\"start\":52737},{\"end\":52746,\"start\":52745},{\"end\":52754,\"start\":52753},{\"end\":53114,\"start\":53113},{\"end\":53121,\"start\":53120},{\"end\":53130,\"start\":53129},{\"end\":53139,\"start\":53138},{\"end\":53147,\"start\":53146},{\"end\":53153,\"start\":53152},{\"end\":53161,\"start\":53160},{\"end\":53173,\"start\":53172},{\"end\":53179,\"start\":53178},{\"end\":53187,\"start\":53186},{\"end\":53696,\"start\":53695},{\"end\":53704,\"start\":53703},{\"end\":53869,\"start\":53868},{\"end\":53877,\"start\":53876},{\"end\":53885,\"start\":53884},{\"end\":54098,\"start\":54097},{\"end\":54108,\"start\":54107},{\"end\":54121,\"start\":54120},{\"end\":54123,\"start\":54122},{\"end\":54131,\"start\":54130},{\"end\":54372,\"start\":54371},{\"end\":54382,\"start\":54381},{\"end\":54395,\"start\":54394},{\"end\":54407,\"start\":54406},{\"end\":54560,\"start\":54559},{\"end\":54572,\"start\":54571},{\"end\":54586,\"start\":54585},{\"end\":54588,\"start\":54587},{\"end\":54601,\"start\":54600},{\"end\":54608,\"start\":54607},{\"end\":54619,\"start\":54618},{\"end\":54621,\"start\":54620},{\"end\":54634,\"start\":54633},{\"end\":54636,\"start\":54635},{\"end\":54644,\"start\":54643},{\"end\":54905,\"start\":54904},{\"end\":54916,\"start\":54915},{\"end\":54927,\"start\":54926},{\"end\":54937,\"start\":54936},{\"end\":54950,\"start\":54949},{\"end\":54959,\"start\":54958},{\"end\":54961,\"start\":54960},{\"end\":54970,\"start\":54969},{\"end\":54980,\"start\":54979},{\"end\":55222,\"start\":55221},{\"end\":55238,\"start\":55237},{\"end\":55248,\"start\":55247},{\"end\":55256,\"start\":55255},{\"end\":55266,\"start\":55265},{\"end\":55270,\"start\":55267},{\"end\":55279,\"start\":55278},{\"end\":55289,\"start\":55288},{\"end\":55523,\"start\":55522},{\"end\":55539,\"start\":55538},{\"end\":55549,\"start\":55548},{\"end\":55551,\"start\":55550},{\"end\":55559,\"start\":55558},{\"end\":55809,\"start\":55808},{\"end\":55817,\"start\":55816},{\"end\":55825,\"start\":55824},{\"end\":55833,\"start\":55832},{\"end\":56053,\"start\":56052},{\"end\":56061,\"start\":56060},{\"end\":56070,\"start\":56069},{\"end\":56084,\"start\":56083},{\"end\":56090,\"start\":56089},{\"end\":56094,\"start\":56091},{\"end\":56338,\"start\":56337},{\"end\":56346,\"start\":56345},{\"end\":56355,\"start\":56354},{\"end\":56362,\"start\":56361},{\"end\":56550,\"start\":56549},{\"end\":56558,\"start\":56557},{\"end\":56566,\"start\":56565},{\"end\":56568,\"start\":56567},{\"end\":56574,\"start\":56573},{\"end\":56582,\"start\":56581},{\"end\":56590,\"start\":56589},{\"end\":56816,\"start\":56815},{\"end\":56824,\"start\":56823},{\"end\":56833,\"start\":56832},{\"end\":56840,\"start\":56839},{\"end\":56846,\"start\":56845},{\"end\":57040,\"start\":57039},{\"end\":57048,\"start\":57047},{\"end\":57054,\"start\":57053},{\"end\":57061,\"start\":57060},{\"end\":57068,\"start\":57067},{\"end\":57293,\"start\":57292},{\"end\":57302,\"start\":57301},{\"end\":57312,\"start\":57311},{\"end\":57512,\"start\":57511},{\"end\":57518,\"start\":57517},{\"end\":57525,\"start\":57524},{\"end\":57533,\"start\":57532},{\"end\":57541,\"start\":57540},{\"end\":57549,\"start\":57548},{\"end\":57733,\"start\":57732},{\"end\":57739,\"start\":57738},{\"end\":57833,\"start\":57832},{\"end\":57839,\"start\":57838},{\"end\":57847,\"start\":57846},{\"end\":57854,\"start\":57853},{\"end\":57861,\"start\":57860},{\"end\":57870,\"start\":57869},{\"end\":57878,\"start\":57877},{\"end\":58159,\"start\":58158},{\"end\":58165,\"start\":58164},{\"end\":58172,\"start\":58171},{\"end\":58183,\"start\":58182},{\"end\":58190,\"start\":58189},{\"end\":58197,\"start\":58196},{\"end\":58555,\"start\":58554},{\"end\":58561,\"start\":58560},{\"end\":58569,\"start\":58568},{\"end\":58576,\"start\":58575},{\"end\":58586,\"start\":58585},{\"end\":58600,\"start\":58599},{\"end\":58850,\"start\":58849},{\"end\":58856,\"start\":58855},{\"end\":58864,\"start\":58863},{\"end\":58870,\"start\":58869},{\"end\":58878,\"start\":58877},{\"end\":59142,\"start\":59141},{\"end\":59148,\"start\":59147},{\"end\":59156,\"start\":59155},{\"end\":59165,\"start\":59164},{\"end\":59172,\"start\":59171},{\"end\":59181,\"start\":59180},{\"end\":59433,\"start\":59432},{\"end\":59440,\"start\":59439},{\"end\":59448,\"start\":59447},{\"end\":59454,\"start\":59453},{\"end\":59462,\"start\":59461},{\"end\":59642,\"start\":59641},{\"end\":59650,\"start\":59649},{\"end\":59657,\"start\":59656},{\"end\":59825,\"start\":59824},{\"end\":59833,\"start\":59832},{\"end\":59840,\"start\":59839},{\"end\":60058,\"start\":60057},{\"end\":60064,\"start\":60063},{\"end\":60072,\"start\":60071},{\"end\":60080,\"start\":60079},{\"end\":60088,\"start\":60087},{\"end\":60096,\"start\":60095},{\"end\":60103,\"start\":60102},{\"end\":60115,\"start\":60114},{\"end\":60349,\"start\":60348},{\"end\":60357,\"start\":60356},{\"end\":60365,\"start\":60364},{\"end\":60367,\"start\":60366},{\"end\":60375,\"start\":60374},{\"end\":60386,\"start\":60385},{\"end\":60393,\"start\":60392},{\"end\":60400,\"start\":60399},{\"end\":60406,\"start\":60405},{\"end\":60415,\"start\":60414},{\"end\":60421,\"start\":60420},{\"end\":60777,\"start\":60776},{\"end\":60785,\"start\":60784},{\"end\":60793,\"start\":60792},{\"end\":60801,\"start\":60800},{\"end\":60810,\"start\":60809},{\"end\":61064,\"start\":61063},{\"end\":61073,\"start\":61072},{\"end\":61085,\"start\":61084},{\"end\":61217,\"start\":61216},{\"end\":61226,\"start\":61225},{\"end\":61233,\"start\":61232},{\"end\":61242,\"start\":61241},{\"end\":61248,\"start\":61247},{\"end\":61256,\"start\":61255},{\"end\":61263,\"start\":61262},{\"end\":61270,\"start\":61269},{\"end\":61655,\"start\":61654},{\"end\":61664,\"start\":61663},{\"end\":61672,\"start\":61671},{\"end\":61680,\"start\":61679},{\"end\":61688,\"start\":61687},{\"end\":61920,\"start\":61919},{\"end\":61929,\"start\":61928},{\"end\":61935,\"start\":61934},{\"end\":61943,\"start\":61942},{\"end\":62144,\"start\":62143},{\"end\":62153,\"start\":62152},{\"end\":62160,\"start\":62159},{\"end\":62168,\"start\":62167},{\"end\":62174,\"start\":62173},{\"end\":62365,\"start\":62364},{\"end\":62374,\"start\":62373},{\"end\":62382,\"start\":62381},{\"end\":62388,\"start\":62387},{\"end\":62394,\"start\":62393},{\"end\":62579,\"start\":62578},{\"end\":62588,\"start\":62587},{\"end\":62596,\"start\":62595},{\"end\":62604,\"start\":62603},{\"end\":62611,\"start\":62610},{\"end\":62619,\"start\":62618},{\"end\":62801,\"start\":62800},{\"end\":62809,\"start\":62808},{\"end\":62819,\"start\":62818},{\"end\":62941,\"start\":62940},{\"end\":62949,\"start\":62948},{\"end\":62957,\"start\":62956},{\"end\":63155,\"start\":63154},{\"end\":63163,\"start\":63162},{\"end\":63170,\"start\":63169},{\"end\":63176,\"start\":63175},{\"end\":63184,\"start\":63183},{\"end\":63193,\"start\":63192},{\"end\":63386,\"start\":63385},{\"end\":63393,\"start\":63392},{\"end\":63401,\"start\":63400},{\"end\":63408,\"start\":63407},{\"end\":63415,\"start\":63414},{\"end\":63424,\"start\":63423},{\"end\":63426,\"start\":63425},{\"end\":63660,\"start\":63659},{\"end\":63667,\"start\":63666},{\"end\":63673,\"start\":63672},{\"end\":63679,\"start\":63678},{\"end\":63685,\"start\":63684},{\"end\":63693,\"start\":63692}]", "bib_author_last_name": "[{\"end\":38735,\"start\":38730},{\"end\":38748,\"start\":38739},{\"end\":38756,\"start\":38752},{\"end\":38770,\"start\":38760},{\"end\":38779,\"start\":38774},{\"end\":39005,\"start\":38997},{\"end\":39018,\"start\":39009},{\"end\":39032,\"start\":39022},{\"end\":39211,\"start\":39201},{\"end\":39223,\"start\":39215},{\"end\":39238,\"start\":39229},{\"end\":39249,\"start\":39242},{\"end\":39261,\"start\":39257},{\"end\":39479,\"start\":39473},{\"end\":39485,\"start\":39483},{\"end\":39492,\"start\":39489},{\"end\":39501,\"start\":39496},{\"end\":39512,\"start\":39505},{\"end\":39691,\"start\":39687},{\"end\":39704,\"start\":39695},{\"end\":39714,\"start\":39710},{\"end\":39725,\"start\":39718},{\"end\":39947,\"start\":39943},{\"end\":39960,\"start\":39951},{\"end\":39970,\"start\":39966},{\"end\":39981,\"start\":39974},{\"end\":40195,\"start\":40191},{\"end\":40206,\"start\":40201},{\"end\":40219,\"start\":40210},{\"end\":40231,\"start\":40223},{\"end\":40243,\"start\":40235},{\"end\":40253,\"start\":40249},{\"end\":40264,\"start\":40257},{\"end\":40499,\"start\":40494},{\"end\":40513,\"start\":40503},{\"end\":40657,\"start\":40653},{\"end\":40664,\"start\":40661},{\"end\":40671,\"start\":40668},{\"end\":40679,\"start\":40675},{\"end\":40687,\"start\":40683},{\"end\":40693,\"start\":40691},{\"end\":40926,\"start\":40921},{\"end\":40935,\"start\":40932},{\"end\":40945,\"start\":40941},{\"end\":41199,\"start\":41194},{\"end\":41209,\"start\":41205},{\"end\":41219,\"start\":41215},{\"end\":41227,\"start\":41223},{\"end\":41237,\"start\":41233},{\"end\":41512,\"start\":41509},{\"end\":41520,\"start\":41516},{\"end\":41684,\"start\":41681},{\"end\":41692,\"start\":41688},{\"end\":41699,\"start\":41696},{\"end\":41707,\"start\":41703},{\"end\":41714,\"start\":41711},{\"end\":42050,\"start\":42041},{\"end\":42058,\"start\":42054},{\"end\":42068,\"start\":42064},{\"end\":42080,\"start\":42072},{\"end\":42268,\"start\":42259},{\"end\":42276,\"start\":42272},{\"end\":42286,\"start\":42282},{\"end\":42298,\"start\":42290},{\"end\":42492,\"start\":42483},{\"end\":42502,\"start\":42498},{\"end\":42513,\"start\":42506},{\"end\":42689,\"start\":42686},{\"end\":42698,\"start\":42693},{\"end\":42711,\"start\":42702},{\"end\":42723,\"start\":42715},{\"end\":42934,\"start\":42931},{\"end\":42941,\"start\":42938},{\"end\":42949,\"start\":42945},{\"end\":42956,\"start\":42953},{\"end\":42964,\"start\":42960},{\"end\":42970,\"start\":42968},{\"end\":42977,\"start\":42974},{\"end\":42983,\"start\":42981},{\"end\":42991,\"start\":42987},{\"end\":42999,\"start\":42995},{\"end\":43227,\"start\":43225},{\"end\":43234,\"start\":43231},{\"end\":43242,\"start\":43238},{\"end\":43248,\"start\":43246},{\"end\":43255,\"start\":43252},{\"end\":43530,\"start\":43524},{\"end\":43538,\"start\":43534},{\"end\":43549,\"start\":43544},{\"end\":43557,\"start\":43555},{\"end\":43566,\"start\":43563},{\"end\":43786,\"start\":43779},{\"end\":43795,\"start\":43790},{\"end\":43803,\"start\":43799},{\"end\":43821,\"start\":43807},{\"end\":43831,\"start\":43825},{\"end\":43840,\"start\":43835},{\"end\":44101,\"start\":44099},{\"end\":44110,\"start\":44105},{\"end\":44117,\"start\":44114},{\"end\":44124,\"start\":44121},{\"end\":44299,\"start\":44297},{\"end\":44310,\"start\":44305},{\"end\":44323,\"start\":44316},{\"end\":44533,\"start\":44528},{\"end\":44541,\"start\":44537},{\"end\":44550,\"start\":44545},{\"end\":44766,\"start\":44761},{\"end\":44774,\"start\":44770},{\"end\":44783,\"start\":44778},{\"end\":45014,\"start\":45009},{\"end\":45025,\"start\":45018},{\"end\":45178,\"start\":45173},{\"end\":45187,\"start\":45182},{\"end\":45196,\"start\":45191},{\"end\":45450,\"start\":45448},{\"end\":45456,\"start\":45454},{\"end\":45469,\"start\":45460},{\"end\":45478,\"start\":45475},{\"end\":45488,\"start\":45484},{\"end\":45494,\"start\":45492},{\"end\":45755,\"start\":45753},{\"end\":45761,\"start\":45759},{\"end\":45769,\"start\":45765},{\"end\":45778,\"start\":45773},{\"end\":45786,\"start\":45782},{\"end\":45793,\"start\":45790},{\"end\":46046,\"start\":46041},{\"end\":46055,\"start\":46050},{\"end\":46061,\"start\":46059},{\"end\":46069,\"start\":46065},{\"end\":46075,\"start\":46073},{\"end\":46081,\"start\":46079},{\"end\":46088,\"start\":46085},{\"end\":46317,\"start\":46312},{\"end\":46326,\"start\":46321},{\"end\":46334,\"start\":46330},{\"end\":46340,\"start\":46338},{\"end\":46346,\"start\":46344},{\"end\":46352,\"start\":46350},{\"end\":46657,\"start\":46654},{\"end\":46667,\"start\":46661},{\"end\":46679,\"start\":46671},{\"end\":46685,\"start\":46683},{\"end\":46698,\"start\":46689},{\"end\":46710,\"start\":46702},{\"end\":46860,\"start\":46857},{\"end\":46869,\"start\":46864},{\"end\":46883,\"start\":46875},{\"end\":46896,\"start\":46889},{\"end\":46910,\"start\":46902},{\"end\":46918,\"start\":46914},{\"end\":46928,\"start\":46922},{\"end\":46939,\"start\":46932},{\"end\":46949,\"start\":46943},{\"end\":46962,\"start\":46955},{\"end\":47214,\"start\":47211},{\"end\":47221,\"start\":47218},{\"end\":47229,\"start\":47227},{\"end\":47246,\"start\":47233},{\"end\":47257,\"start\":47250},{\"end\":47264,\"start\":47261},{\"end\":47476,\"start\":47466},{\"end\":47486,\"start\":47480},{\"end\":47731,\"start\":47724},{\"end\":47740,\"start\":47735},{\"end\":47751,\"start\":47744},{\"end\":47964,\"start\":47957},{\"end\":47975,\"start\":47968},{\"end\":47983,\"start\":47979},{\"end\":47997,\"start\":47987},{\"end\":48011,\"start\":48001},{\"end\":48022,\"start\":48015},{\"end\":48034,\"start\":48026},{\"end\":48296,\"start\":48291},{\"end\":48309,\"start\":48300},{\"end\":48321,\"start\":48315},{\"end\":48333,\"start\":48325},{\"end\":48553,\"start\":48544},{\"end\":48565,\"start\":48557},{\"end\":48579,\"start\":48569},{\"end\":48596,\"start\":48583},{\"end\":48812,\"start\":48807},{\"end\":48826,\"start\":48816},{\"end\":48834,\"start\":48830},{\"end\":48842,\"start\":48838},{\"end\":48855,\"start\":48846},{\"end\":49199,\"start\":49190},{\"end\":49208,\"start\":49203},{\"end\":49220,\"start\":49214},{\"end\":49456,\"start\":49450},{\"end\":49464,\"start\":49460},{\"end\":49476,\"start\":49468},{\"end\":49489,\"start\":49480},{\"end\":49499,\"start\":49493},{\"end\":49752,\"start\":49750},{\"end\":49761,\"start\":49758},{\"end\":49767,\"start\":49765},{\"end\":49776,\"start\":49773},{\"end\":49978,\"start\":49974},{\"end\":49985,\"start\":49982},{\"end\":49991,\"start\":49989},{\"end\":49999,\"start\":49995},{\"end\":50005,\"start\":50003},{\"end\":50016,\"start\":50009},{\"end\":50022,\"start\":50020},{\"end\":50323,\"start\":50319},{\"end\":50331,\"start\":50327},{\"end\":50338,\"start\":50335},{\"end\":50344,\"start\":50342},{\"end\":50352,\"start\":50348},{\"end\":50359,\"start\":50356},{\"end\":50367,\"start\":50363},{\"end\":50373,\"start\":50371},{\"end\":50382,\"start\":50377},{\"end\":50388,\"start\":50386},{\"end\":50645,\"start\":50635},{\"end\":50656,\"start\":50649},{\"end\":50667,\"start\":50660},{\"end\":50679,\"start\":50671},{\"end\":50698,\"start\":50683},{\"end\":50710,\"start\":50702},{\"end\":51007,\"start\":51001},{\"end\":51018,\"start\":51011},{\"end\":51275,\"start\":51272},{\"end\":51281,\"start\":51279},{\"end\":51293,\"start\":51285},{\"end\":51300,\"start\":51297},{\"end\":51532,\"start\":51524},{\"end\":51543,\"start\":51538},{\"end\":51556,\"start\":51547},{\"end\":51566,\"start\":51562},{\"end\":51578,\"start\":51570},{\"end\":51825,\"start\":51820},{\"end\":51833,\"start\":51831},{\"end\":51842,\"start\":51839},{\"end\":51849,\"start\":51846},{\"end\":51856,\"start\":51853},{\"end\":51863,\"start\":51860},{\"end\":52024,\"start\":52020},{\"end\":52032,\"start\":52028},{\"end\":52038,\"start\":52036},{\"end\":52046,\"start\":52042},{\"end\":52053,\"start\":52050},{\"end\":52059,\"start\":52057},{\"end\":52067,\"start\":52063},{\"end\":52074,\"start\":52071},{\"end\":52081,\"start\":52078},{\"end\":52088,\"start\":52085},{\"end\":52441,\"start\":52437},{\"end\":52449,\"start\":52445},{\"end\":52455,\"start\":52453},{\"end\":52463,\"start\":52459},{\"end\":52469,\"start\":52467},{\"end\":52478,\"start\":52473},{\"end\":52485,\"start\":52482},{\"end\":52689,\"start\":52686},{\"end\":52698,\"start\":52693},{\"end\":52707,\"start\":52702},{\"end\":52714,\"start\":52711},{\"end\":52721,\"start\":52718},{\"end\":52727,\"start\":52725},{\"end\":52735,\"start\":52731},{\"end\":52743,\"start\":52739},{\"end\":52751,\"start\":52747},{\"end\":52758,\"start\":52755},{\"end\":53118,\"start\":53115},{\"end\":53127,\"start\":53122},{\"end\":53136,\"start\":53131},{\"end\":53144,\"start\":53140},{\"end\":53150,\"start\":53148},{\"end\":53158,\"start\":53154},{\"end\":53170,\"start\":53162},{\"end\":53176,\"start\":53174},{\"end\":53184,\"start\":53180},{\"end\":53192,\"start\":53188},{\"end\":53701,\"start\":53697},{\"end\":53709,\"start\":53705},{\"end\":53874,\"start\":53870},{\"end\":53882,\"start\":53878},{\"end\":53890,\"start\":53886},{\"end\":54105,\"start\":54099},{\"end\":54118,\"start\":54109},{\"end\":54128,\"start\":54124},{\"end\":54139,\"start\":54132},{\"end\":54379,\"start\":54373},{\"end\":54392,\"start\":54383},{\"end\":54404,\"start\":54396},{\"end\":54415,\"start\":54408},{\"end\":54569,\"start\":54561},{\"end\":54583,\"start\":54573},{\"end\":54598,\"start\":54589},{\"end\":54605,\"start\":54602},{\"end\":54616,\"start\":54609},{\"end\":54631,\"start\":54622},{\"end\":54641,\"start\":54637},{\"end\":54651,\"start\":54645},{\"end\":54913,\"start\":54906},{\"end\":54924,\"start\":54917},{\"end\":54934,\"start\":54928},{\"end\":54947,\"start\":54938},{\"end\":54956,\"start\":54951},{\"end\":54967,\"start\":54962},{\"end\":54977,\"start\":54971},{\"end\":54991,\"start\":54981},{\"end\":55235,\"start\":55223},{\"end\":55245,\"start\":55239},{\"end\":55253,\"start\":55249},{\"end\":55263,\"start\":55257},{\"end\":55276,\"start\":55271},{\"end\":55286,\"start\":55280},{\"end\":55295,\"start\":55290},{\"end\":55536,\"start\":55524},{\"end\":55546,\"start\":55540},{\"end\":55556,\"start\":55552},{\"end\":55565,\"start\":55560},{\"end\":55814,\"start\":55810},{\"end\":55822,\"start\":55818},{\"end\":55830,\"start\":55826},{\"end\":55836,\"start\":55834},{\"end\":56058,\"start\":56054},{\"end\":56067,\"start\":56062},{\"end\":56081,\"start\":56071},{\"end\":56087,\"start\":56085},{\"end\":56099,\"start\":56095},{\"end\":56343,\"start\":56339},{\"end\":56352,\"start\":56347},{\"end\":56359,\"start\":56356},{\"end\":56365,\"start\":56363},{\"end\":56555,\"start\":56551},{\"end\":56563,\"start\":56559},{\"end\":56571,\"start\":56569},{\"end\":56579,\"start\":56575},{\"end\":56587,\"start\":56583},{\"end\":56601,\"start\":56591},{\"end\":56821,\"start\":56817},{\"end\":56830,\"start\":56825},{\"end\":56837,\"start\":56834},{\"end\":56843,\"start\":56841},{\"end\":56851,\"start\":56847},{\"end\":57045,\"start\":57041},{\"end\":57051,\"start\":57049},{\"end\":57058,\"start\":57055},{\"end\":57065,\"start\":57062},{\"end\":57073,\"start\":57069},{\"end\":57299,\"start\":57294},{\"end\":57309,\"start\":57303},{\"end\":57319,\"start\":57313},{\"end\":57515,\"start\":57513},{\"end\":57522,\"start\":57519},{\"end\":57530,\"start\":57526},{\"end\":57538,\"start\":57534},{\"end\":57546,\"start\":57542},{\"end\":57554,\"start\":57550},{\"end\":57736,\"start\":57734},{\"end\":57742,\"start\":57740},{\"end\":57836,\"start\":57834},{\"end\":57844,\"start\":57840},{\"end\":57851,\"start\":57848},{\"end\":57858,\"start\":57855},{\"end\":57867,\"start\":57862},{\"end\":57875,\"start\":57871},{\"end\":57884,\"start\":57879},{\"end\":58162,\"start\":58160},{\"end\":58169,\"start\":58166},{\"end\":58180,\"start\":58173},{\"end\":58187,\"start\":58184},{\"end\":58194,\"start\":58191},{\"end\":58212,\"start\":58198},{\"end\":58558,\"start\":58556},{\"end\":58566,\"start\":58562},{\"end\":58573,\"start\":58570},{\"end\":58583,\"start\":58577},{\"end\":58597,\"start\":58587},{\"end\":58615,\"start\":58601},{\"end\":58853,\"start\":58851},{\"end\":58861,\"start\":58857},{\"end\":58867,\"start\":58865},{\"end\":58875,\"start\":58871},{\"end\":58881,\"start\":58879},{\"end\":59145,\"start\":59143},{\"end\":59153,\"start\":59149},{\"end\":59162,\"start\":59157},{\"end\":59169,\"start\":59166},{\"end\":59178,\"start\":59173},{\"end\":59187,\"start\":59182},{\"end\":59437,\"start\":59434},{\"end\":59445,\"start\":59441},{\"end\":59451,\"start\":59449},{\"end\":59459,\"start\":59455},{\"end\":59465,\"start\":59463},{\"end\":59647,\"start\":59643},{\"end\":59654,\"start\":59651},{\"end\":59660,\"start\":59658},{\"end\":59830,\"start\":59826},{\"end\":59837,\"start\":59834},{\"end\":59845,\"start\":59841},{\"end\":60061,\"start\":60059},{\"end\":60069,\"start\":60065},{\"end\":60077,\"start\":60073},{\"end\":60085,\"start\":60081},{\"end\":60093,\"start\":60089},{\"end\":60100,\"start\":60097},{\"end\":60112,\"start\":60104},{\"end\":60123,\"start\":60116},{\"end\":60354,\"start\":60350},{\"end\":60362,\"start\":60358},{\"end\":60372,\"start\":60368},{\"end\":60383,\"start\":60376},{\"end\":60390,\"start\":60387},{\"end\":60397,\"start\":60394},{\"end\":60403,\"start\":60401},{\"end\":60412,\"start\":60407},{\"end\":60418,\"start\":60416},{\"end\":60424,\"start\":60422},{\"end\":60782,\"start\":60778},{\"end\":60790,\"start\":60786},{\"end\":60798,\"start\":60794},{\"end\":60807,\"start\":60802},{\"end\":60814,\"start\":60811},{\"end\":61070,\"start\":61065},{\"end\":61082,\"start\":61074},{\"end\":61093,\"start\":61086},{\"end\":61223,\"start\":61218},{\"end\":61230,\"start\":61227},{\"end\":61239,\"start\":61234},{\"end\":61245,\"start\":61243},{\"end\":61253,\"start\":61249},{\"end\":61260,\"start\":61257},{\"end\":61267,\"start\":61264},{\"end\":61275,\"start\":61271},{\"end\":61661,\"start\":61656},{\"end\":61669,\"start\":61665},{\"end\":61677,\"start\":61673},{\"end\":61685,\"start\":61681},{\"end\":61692,\"start\":61689},{\"end\":61926,\"start\":61921},{\"end\":61932,\"start\":61930},{\"end\":61940,\"start\":61936},{\"end\":61947,\"start\":61944},{\"end\":62150,\"start\":62145},{\"end\":62157,\"start\":62154},{\"end\":62165,\"start\":62161},{\"end\":62171,\"start\":62169},{\"end\":62177,\"start\":62175},{\"end\":62371,\"start\":62366},{\"end\":62379,\"start\":62375},{\"end\":62385,\"start\":62383},{\"end\":62391,\"start\":62389},{\"end\":62397,\"start\":62395},{\"end\":62585,\"start\":62580},{\"end\":62593,\"start\":62589},{\"end\":62601,\"start\":62597},{\"end\":62608,\"start\":62605},{\"end\":62616,\"start\":62612},{\"end\":62622,\"start\":62620},{\"end\":62806,\"start\":62802},{\"end\":62816,\"start\":62810},{\"end\":62830,\"start\":62820},{\"end\":62946,\"start\":62942},{\"end\":62954,\"start\":62950},{\"end\":62968,\"start\":62958},{\"end\":63160,\"start\":63156},{\"end\":63167,\"start\":63164},{\"end\":63173,\"start\":63171},{\"end\":63181,\"start\":63177},{\"end\":63190,\"start\":63185},{\"end\":63196,\"start\":63194},{\"end\":63390,\"start\":63387},{\"end\":63398,\"start\":63394},{\"end\":63405,\"start\":63402},{\"end\":63412,\"start\":63409},{\"end\":63421,\"start\":63416},{\"end\":63431,\"start\":63427},{\"end\":63664,\"start\":63661},{\"end\":63670,\"start\":63668},{\"end\":63676,\"start\":63674},{\"end\":63682,\"start\":63680},{\"end\":63690,\"start\":63686},{\"end\":63697,\"start\":63694}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":213175621},\"end\":38956,\"start\":38655},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":76665153},\"end\":39140,\"start\":38958},{\"attributes\":{\"id\":\"b2\"},\"end\":39432,\"start\":39142},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":16034699},\"end\":39628,\"start\":39434},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":118637813},\"end\":39865,\"start\":39630},{\"attributes\":{\"id\":\"b5\"},\"end\":40133,\"start\":39867},{\"attributes\":{\"id\":\"b6\"},\"end\":40435,\"start\":40135},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":209376180},\"end\":40627,\"start\":40437},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":232404168},\"end\":40813,\"start\":40629},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":235376958},\"end\":41119,\"start\":40815},{\"attributes\":{\"id\":\"b10\"},\"end\":41391,\"start\":41121},{\"attributes\":{\"id\":\"b11\"},\"end\":41677,\"start\":41393},{\"attributes\":{\"doi\":\"arXiv:2104.00194\",\"id\":\"b12\"},\"end\":41986,\"start\":41679},{\"attributes\":{\"id\":\"b13\"},\"end\":42206,\"start\":41988},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":53712235},\"end\":42433,\"start\":42208},{\"attributes\":{\"id\":\"b15\"},\"end\":42625,\"start\":42435},{\"attributes\":{\"id\":\"b16\"},\"end\":42855,\"start\":42627},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":52350875},\"end\":43221,\"start\":42857},{\"attributes\":{\"doi\":\"arXiv:2107.08430\",\"id\":\"b18\"},\"end\":43457,\"start\":43223},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":237291521},\"end\":43722,\"start\":43459},{\"attributes\":{\"doi\":\"arXiv:2201.08377\",\"id\":\"b20\"},\"end\":44049,\"start\":43724},{\"attributes\":{\"id\":\"b21\"},\"end\":44237,\"start\":44051},{\"attributes\":{\"id\":\"b22\"},\"end\":44441,\"start\":44239},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":53102207},\"end\":44691,\"start\":44443},{\"attributes\":{\"id\":\"b24\"},\"end\":44911,\"start\":44693},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":5808102},\"end\":45169,\"start\":44913},{\"attributes\":{\"id\":\"b26\"},\"end\":45360,\"start\":45171},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":235593319},\"end\":45676,\"start\":45362},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":57189581},\"end\":45957,\"start\":45678},{\"attributes\":{\"doi\":\"arXiv:2010.12138\",\"id\":\"b29\"},\"end\":46308,\"start\":45959},{\"attributes\":{\"doi\":\"arXiv:2104.09441\",\"id\":\"b30\"},\"end\":46601,\"start\":46310},{\"attributes\":{\"id\":\"b31\"},\"end\":46851,\"start\":46603},{\"attributes\":{\"id\":\"b32\"},\"end\":47207,\"start\":46853},{\"attributes\":{\"doi\":\"arXiv:2201.03545\",\"id\":\"b33\"},\"end\":47462,\"start\":47209},{\"attributes\":{\"doi\":\"arXiv:1711.05101\",\"id\":\"b34\"},\"end\":47665,\"start\":47464},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":208175650},\"end\":47895,\"start\":47667},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":9095022},\"end\":48213,\"start\":47897},{\"attributes\":{\"id\":\"b37\"},\"end\":48487,\"start\":48215},{\"attributes\":{\"doi\":\"arXiv:2101.02702\",\"id\":\"b38\"},\"end\":48803,\"start\":48489},{\"attributes\":{\"doi\":\"arXiv:1603.00831\",\"id\":\"b39\"},\"end\":49100,\"start\":48805},{\"attributes\":{\"id\":\"b40\"},\"end\":49365,\"start\":49102},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":4455970},\"end\":49684,\"start\":49367},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":90262243},\"end\":49908,\"start\":49686},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":227238613},\"end\":50193,\"start\":49910},{\"attributes\":{\"id\":\"b44\"},\"end\":50631,\"start\":50195},{\"attributes\":{\"doi\":\"arXiv:1704.00675\",\"id\":\"b45\"},\"end\":50997,\"start\":50633},{\"attributes\":{\"doi\":\"arXiv:1804.02767\",\"id\":\"b46\"},\"end\":51188,\"start\":50999},{\"attributes\":{\"id\":\"b47\"},\"end\":51450,\"start\":51190},{\"attributes\":{\"id\":\"b48\"},\"end\":51748,\"start\":51452},{\"attributes\":{\"id\":\"b49\"},\"end\":52016,\"start\":51750},{\"attributes\":{\"doi\":\"arXiv:2111.08687\",\"id\":\"b50\"},\"end\":52377,\"start\":52018},{\"attributes\":{\"doi\":\"arXiv:1805.00123\",\"id\":\"b51\"},\"end\":52682,\"start\":52379},{\"attributes\":{\"doi\":\"arXiv:2012.15460\",\"id\":\"b52\"},\"end\":53043,\"start\":52684},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":227162412},\"end\":53632,\"start\":53045},{\"attributes\":{\"id\":\"b54\"},\"end\":53814,\"start\":53634},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":212675968},\"end\":54011,\"start\":53816},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":221738910},\"end\":54305,\"start\":54013},{\"attributes\":{\"id\":\"b57\"},\"end\":54557,\"start\":54307},{\"attributes\":{\"id\":\"b58\"},\"end\":54875,\"start\":54559},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":13756489},\"end\":55173,\"start\":54877},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":60440659},\"end\":55475,\"start\":55175},{\"attributes\":{\"id\":\"b61\"},\"end\":55723,\"start\":55477},{\"attributes\":{\"id\":\"b62\"},\"end\":55983,\"start\":55725},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":54475412},\"end\":56283,\"start\":55985},{\"attributes\":{\"id\":\"b64\"},\"end\":56481,\"start\":56285},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":235732286},\"end\":56772,\"start\":56483},{\"attributes\":{\"id\":\"b66\"},\"end\":56968,\"start\":56774},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":201070350},\"end\":57222,\"start\":56970},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":74506},\"end\":57448,\"start\":57224},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":232240682},\"end\":57730,\"start\":57450},{\"attributes\":{\"id\":\"b70\"},\"end\":57830,\"start\":57732},{\"attributes\":{\"doi\":\"arXiv:1809.03327\",\"id\":\"b71\"},\"end\":58156,\"start\":57832},{\"attributes\":{\"doi\":\"arXiv:2103.15145\",\"id\":\"b72\"},\"end\":58507,\"start\":58158},{\"attributes\":{\"id\":\"b73\"},\"end\":58758,\"start\":58509},{\"attributes\":{\"id\":\"b74\"},\"end\":59046,\"start\":58760},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":235394709},\"end\":59372,\"start\":59048},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":232428140},\"end\":59610,\"start\":59374},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":152282473},\"end\":59744,\"start\":59612},{\"attributes\":{\"id\":\"b78\"},\"end\":59982,\"start\":59746},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":215415900},\"end\":60346,\"start\":59984},{\"attributes\":{\"doi\":\"arXiv:2111.11432\",\"id\":\"b80\"},\"end\":60715,\"start\":60348},{\"attributes\":{\"doi\":\"arXiv:2105.03247\",\"id\":\"b81\"},\"end\":61004,\"start\":60717},{\"attributes\":{\"id\":\"b82\"},\"end\":61214,\"start\":61006},{\"attributes\":{\"doi\":\"arXiv:2110.06864\",\"id\":\"b83\"},\"end\":61563,\"start\":61216},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":221562313},\"end\":61862,\"start\":61565},{\"attributes\":{\"id\":\"b85\"},\"end\":62070,\"start\":61864},{\"attributes\":{\"id\":\"b86\"},\"end\":62320,\"start\":62072},{\"attributes\":{\"id\":\"b87\"},\"end\":62512,\"start\":62322},{\"attributes\":{\"id\":\"b88\"},\"end\":62770,\"start\":62514},{\"attributes\":{\"id\":\"b89\",\"matched_paper_id\":214775104},\"end\":62938,\"start\":62772},{\"attributes\":{\"doi\":\"arXiv:1904.07850\",\"id\":\"b90\"},\"end\":63115,\"start\":62940},{\"attributes\":{\"id\":\"b91\"},\"end\":63315,\"start\":63117},{\"attributes\":{\"id\":\"b92\"},\"end\":63583,\"start\":63317},{\"attributes\":{\"id\":\"b93\",\"matched_paper_id\":222208633},\"end\":63873,\"start\":63585}]", "bib_title": "[{\"end\":38726,\"start\":38655},{\"end\":38993,\"start\":38958},{\"end\":39469,\"start\":39434},{\"end\":39683,\"start\":39630},{\"end\":40490,\"start\":40437},{\"end\":40649,\"start\":40629},{\"end\":40915,\"start\":40815},{\"end\":42255,\"start\":42208},{\"end\":42927,\"start\":42857},{\"end\":43520,\"start\":43459},{\"end\":44524,\"start\":44443},{\"end\":45005,\"start\":44913},{\"end\":45444,\"start\":45362},{\"end\":45749,\"start\":45678},{\"end\":47720,\"start\":47667},{\"end\":47951,\"start\":47897},{\"end\":49446,\"start\":49367},{\"end\":49744,\"start\":49686},{\"end\":49970,\"start\":49910},{\"end\":53111,\"start\":53045},{\"end\":53866,\"start\":53816},{\"end\":54095,\"start\":54013},{\"end\":54902,\"start\":54877},{\"end\":55219,\"start\":55175},{\"end\":56050,\"start\":55985},{\"end\":56547,\"start\":56483},{\"end\":57037,\"start\":56970},{\"end\":57290,\"start\":57224},{\"end\":57509,\"start\":57450},{\"end\":59139,\"start\":59048},{\"end\":59430,\"start\":59374},{\"end\":59639,\"start\":59612},{\"end\":60055,\"start\":59984},{\"end\":61652,\"start\":61565},{\"end\":62798,\"start\":62772},{\"end\":63657,\"start\":63585}]", "bib_author": "[{\"end\":38737,\"start\":38728},{\"end\":38750,\"start\":38737},{\"end\":38758,\"start\":38750},{\"end\":38772,\"start\":38758},{\"end\":38781,\"start\":38772},{\"end\":39007,\"start\":38995},{\"end\":39020,\"start\":39007},{\"end\":39034,\"start\":39020},{\"end\":39213,\"start\":39199},{\"end\":39225,\"start\":39213},{\"end\":39240,\"start\":39225},{\"end\":39251,\"start\":39240},{\"end\":39263,\"start\":39251},{\"end\":39481,\"start\":39471},{\"end\":39487,\"start\":39481},{\"end\":39494,\"start\":39487},{\"end\":39503,\"start\":39494},{\"end\":39514,\"start\":39503},{\"end\":39693,\"start\":39685},{\"end\":39706,\"start\":39693},{\"end\":39716,\"start\":39706},{\"end\":39727,\"start\":39716},{\"end\":39949,\"start\":39941},{\"end\":39962,\"start\":39949},{\"end\":39972,\"start\":39962},{\"end\":39983,\"start\":39972},{\"end\":40197,\"start\":40189},{\"end\":40208,\"start\":40197},{\"end\":40221,\"start\":40208},{\"end\":40233,\"start\":40221},{\"end\":40245,\"start\":40233},{\"end\":40255,\"start\":40245},{\"end\":40266,\"start\":40255},{\"end\":40501,\"start\":40492},{\"end\":40515,\"start\":40501},{\"end\":40659,\"start\":40651},{\"end\":40666,\"start\":40659},{\"end\":40673,\"start\":40666},{\"end\":40681,\"start\":40673},{\"end\":40689,\"start\":40681},{\"end\":40695,\"start\":40689},{\"end\":40928,\"start\":40917},{\"end\":40937,\"start\":40928},{\"end\":40947,\"start\":40937},{\"end\":41201,\"start\":41192},{\"end\":41211,\"start\":41201},{\"end\":41221,\"start\":41211},{\"end\":41229,\"start\":41221},{\"end\":41239,\"start\":41229},{\"end\":41514,\"start\":41507},{\"end\":41522,\"start\":41514},{\"end\":41686,\"start\":41679},{\"end\":41694,\"start\":41686},{\"end\":41701,\"start\":41694},{\"end\":41709,\"start\":41701},{\"end\":41716,\"start\":41709},{\"end\":42052,\"start\":42039},{\"end\":42060,\"start\":42052},{\"end\":42070,\"start\":42060},{\"end\":42082,\"start\":42070},{\"end\":42270,\"start\":42257},{\"end\":42278,\"start\":42270},{\"end\":42288,\"start\":42278},{\"end\":42300,\"start\":42288},{\"end\":42494,\"start\":42481},{\"end\":42504,\"start\":42494},{\"end\":42515,\"start\":42504},{\"end\":42691,\"start\":42684},{\"end\":42700,\"start\":42691},{\"end\":42713,\"start\":42700},{\"end\":42725,\"start\":42713},{\"end\":42936,\"start\":42929},{\"end\":42943,\"start\":42936},{\"end\":42951,\"start\":42943},{\"end\":42958,\"start\":42951},{\"end\":42966,\"start\":42958},{\"end\":42972,\"start\":42966},{\"end\":42979,\"start\":42972},{\"end\":42985,\"start\":42979},{\"end\":42993,\"start\":42985},{\"end\":43001,\"start\":42993},{\"end\":43229,\"start\":43223},{\"end\":43236,\"start\":43229},{\"end\":43244,\"start\":43236},{\"end\":43250,\"start\":43244},{\"end\":43257,\"start\":43250},{\"end\":43532,\"start\":43522},{\"end\":43540,\"start\":43532},{\"end\":43551,\"start\":43540},{\"end\":43559,\"start\":43551},{\"end\":43568,\"start\":43559},{\"end\":43788,\"start\":43777},{\"end\":43797,\"start\":43788},{\"end\":43805,\"start\":43797},{\"end\":43823,\"start\":43805},{\"end\":43833,\"start\":43823},{\"end\":43842,\"start\":43833},{\"end\":44103,\"start\":44097},{\"end\":44112,\"start\":44103},{\"end\":44119,\"start\":44112},{\"end\":44126,\"start\":44119},{\"end\":44301,\"start\":44293},{\"end\":44312,\"start\":44301},{\"end\":44325,\"start\":44312},{\"end\":44535,\"start\":44526},{\"end\":44543,\"start\":44535},{\"end\":44552,\"start\":44543},{\"end\":44768,\"start\":44759},{\"end\":44776,\"start\":44768},{\"end\":44785,\"start\":44776},{\"end\":45016,\"start\":45007},{\"end\":45027,\"start\":45016},{\"end\":45180,\"start\":45171},{\"end\":45189,\"start\":45180},{\"end\":45198,\"start\":45189},{\"end\":45452,\"start\":45446},{\"end\":45458,\"start\":45452},{\"end\":45471,\"start\":45458},{\"end\":45480,\"start\":45471},{\"end\":45490,\"start\":45480},{\"end\":45496,\"start\":45490},{\"end\":45757,\"start\":45751},{\"end\":45763,\"start\":45757},{\"end\":45771,\"start\":45763},{\"end\":45780,\"start\":45771},{\"end\":45788,\"start\":45780},{\"end\":45795,\"start\":45788},{\"end\":46048,\"start\":46039},{\"end\":46057,\"start\":46048},{\"end\":46063,\"start\":46057},{\"end\":46071,\"start\":46063},{\"end\":46077,\"start\":46071},{\"end\":46083,\"start\":46077},{\"end\":46090,\"start\":46083},{\"end\":46319,\"start\":46310},{\"end\":46328,\"start\":46319},{\"end\":46336,\"start\":46328},{\"end\":46342,\"start\":46336},{\"end\":46348,\"start\":46342},{\"end\":46354,\"start\":46348},{\"end\":46659,\"start\":46650},{\"end\":46669,\"start\":46659},{\"end\":46681,\"start\":46669},{\"end\":46687,\"start\":46681},{\"end\":46700,\"start\":46687},{\"end\":46712,\"start\":46700},{\"end\":46862,\"start\":46853},{\"end\":46871,\"start\":46862},{\"end\":46885,\"start\":46871},{\"end\":46898,\"start\":46885},{\"end\":46912,\"start\":46898},{\"end\":46920,\"start\":46912},{\"end\":46930,\"start\":46920},{\"end\":46941,\"start\":46930},{\"end\":46951,\"start\":46941},{\"end\":46964,\"start\":46951},{\"end\":47216,\"start\":47209},{\"end\":47223,\"start\":47216},{\"end\":47231,\"start\":47223},{\"end\":47248,\"start\":47231},{\"end\":47259,\"start\":47248},{\"end\":47266,\"start\":47259},{\"end\":47478,\"start\":47464},{\"end\":47488,\"start\":47478},{\"end\":47733,\"start\":47722},{\"end\":47742,\"start\":47733},{\"end\":47753,\"start\":47742},{\"end\":47966,\"start\":47953},{\"end\":47977,\"start\":47966},{\"end\":47985,\"start\":47977},{\"end\":47999,\"start\":47985},{\"end\":48013,\"start\":47999},{\"end\":48024,\"start\":48013},{\"end\":48036,\"start\":48024},{\"end\":48298,\"start\":48289},{\"end\":48311,\"start\":48298},{\"end\":48323,\"start\":48311},{\"end\":48335,\"start\":48323},{\"end\":48555,\"start\":48542},{\"end\":48567,\"start\":48555},{\"end\":48581,\"start\":48567},{\"end\":48598,\"start\":48581},{\"end\":48814,\"start\":48805},{\"end\":48828,\"start\":48814},{\"end\":48836,\"start\":48828},{\"end\":48844,\"start\":48836},{\"end\":48857,\"start\":48844},{\"end\":49201,\"start\":49188},{\"end\":49210,\"start\":49201},{\"end\":49222,\"start\":49210},{\"end\":49458,\"start\":49448},{\"end\":49466,\"start\":49458},{\"end\":49478,\"start\":49466},{\"end\":49491,\"start\":49478},{\"end\":49501,\"start\":49491},{\"end\":49754,\"start\":49746},{\"end\":49763,\"start\":49754},{\"end\":49769,\"start\":49763},{\"end\":49778,\"start\":49769},{\"end\":49980,\"start\":49972},{\"end\":49987,\"start\":49980},{\"end\":49993,\"start\":49987},{\"end\":50001,\"start\":49993},{\"end\":50007,\"start\":50001},{\"end\":50018,\"start\":50007},{\"end\":50024,\"start\":50018},{\"end\":50325,\"start\":50317},{\"end\":50333,\"start\":50325},{\"end\":50340,\"start\":50333},{\"end\":50346,\"start\":50340},{\"end\":50354,\"start\":50346},{\"end\":50361,\"start\":50354},{\"end\":50369,\"start\":50361},{\"end\":50375,\"start\":50369},{\"end\":50384,\"start\":50375},{\"end\":50390,\"start\":50384},{\"end\":50647,\"start\":50633},{\"end\":50658,\"start\":50647},{\"end\":50669,\"start\":50658},{\"end\":50681,\"start\":50669},{\"end\":50700,\"start\":50681},{\"end\":50712,\"start\":50700},{\"end\":51009,\"start\":50999},{\"end\":51020,\"start\":51009},{\"end\":51277,\"start\":51270},{\"end\":51283,\"start\":51277},{\"end\":51295,\"start\":51283},{\"end\":51302,\"start\":51295},{\"end\":51534,\"start\":51522},{\"end\":51545,\"start\":51534},{\"end\":51558,\"start\":51545},{\"end\":51568,\"start\":51558},{\"end\":51580,\"start\":51568},{\"end\":51827,\"start\":51818},{\"end\":51835,\"start\":51827},{\"end\":51844,\"start\":51835},{\"end\":51851,\"start\":51844},{\"end\":51858,\"start\":51851},{\"end\":51865,\"start\":51858},{\"end\":52026,\"start\":52018},{\"end\":52034,\"start\":52026},{\"end\":52040,\"start\":52034},{\"end\":52048,\"start\":52040},{\"end\":52055,\"start\":52048},{\"end\":52061,\"start\":52055},{\"end\":52069,\"start\":52061},{\"end\":52076,\"start\":52069},{\"end\":52083,\"start\":52076},{\"end\":52090,\"start\":52083},{\"end\":52443,\"start\":52435},{\"end\":52451,\"start\":52443},{\"end\":52457,\"start\":52451},{\"end\":52465,\"start\":52457},{\"end\":52471,\"start\":52465},{\"end\":52480,\"start\":52471},{\"end\":52487,\"start\":52480},{\"end\":52691,\"start\":52684},{\"end\":52700,\"start\":52691},{\"end\":52709,\"start\":52700},{\"end\":52716,\"start\":52709},{\"end\":52723,\"start\":52716},{\"end\":52729,\"start\":52723},{\"end\":52737,\"start\":52729},{\"end\":52745,\"start\":52737},{\"end\":52753,\"start\":52745},{\"end\":52760,\"start\":52753},{\"end\":53120,\"start\":53113},{\"end\":53129,\"start\":53120},{\"end\":53138,\"start\":53129},{\"end\":53146,\"start\":53138},{\"end\":53152,\"start\":53146},{\"end\":53160,\"start\":53152},{\"end\":53172,\"start\":53160},{\"end\":53178,\"start\":53172},{\"end\":53186,\"start\":53178},{\"end\":53194,\"start\":53186},{\"end\":53703,\"start\":53695},{\"end\":53711,\"start\":53703},{\"end\":53876,\"start\":53868},{\"end\":53884,\"start\":53876},{\"end\":53892,\"start\":53884},{\"end\":54107,\"start\":54097},{\"end\":54120,\"start\":54107},{\"end\":54130,\"start\":54120},{\"end\":54141,\"start\":54130},{\"end\":54381,\"start\":54371},{\"end\":54394,\"start\":54381},{\"end\":54406,\"start\":54394},{\"end\":54417,\"start\":54406},{\"end\":54571,\"start\":54559},{\"end\":54585,\"start\":54571},{\"end\":54600,\"start\":54585},{\"end\":54607,\"start\":54600},{\"end\":54618,\"start\":54607},{\"end\":54633,\"start\":54618},{\"end\":54643,\"start\":54633},{\"end\":54653,\"start\":54643},{\"end\":54915,\"start\":54904},{\"end\":54926,\"start\":54915},{\"end\":54936,\"start\":54926},{\"end\":54949,\"start\":54936},{\"end\":54958,\"start\":54949},{\"end\":54969,\"start\":54958},{\"end\":54979,\"start\":54969},{\"end\":54993,\"start\":54979},{\"end\":55237,\"start\":55221},{\"end\":55247,\"start\":55237},{\"end\":55255,\"start\":55247},{\"end\":55265,\"start\":55255},{\"end\":55278,\"start\":55265},{\"end\":55288,\"start\":55278},{\"end\":55297,\"start\":55288},{\"end\":55538,\"start\":55522},{\"end\":55548,\"start\":55538},{\"end\":55558,\"start\":55548},{\"end\":55567,\"start\":55558},{\"end\":55816,\"start\":55808},{\"end\":55824,\"start\":55816},{\"end\":55832,\"start\":55824},{\"end\":55838,\"start\":55832},{\"end\":56060,\"start\":56052},{\"end\":56069,\"start\":56060},{\"end\":56083,\"start\":56069},{\"end\":56089,\"start\":56083},{\"end\":56101,\"start\":56089},{\"end\":56345,\"start\":56337},{\"end\":56354,\"start\":56345},{\"end\":56361,\"start\":56354},{\"end\":56367,\"start\":56361},{\"end\":56557,\"start\":56549},{\"end\":56565,\"start\":56557},{\"end\":56573,\"start\":56565},{\"end\":56581,\"start\":56573},{\"end\":56589,\"start\":56581},{\"end\":56603,\"start\":56589},{\"end\":56823,\"start\":56815},{\"end\":56832,\"start\":56823},{\"end\":56839,\"start\":56832},{\"end\":56845,\"start\":56839},{\"end\":56853,\"start\":56845},{\"end\":57047,\"start\":57039},{\"end\":57053,\"start\":57047},{\"end\":57060,\"start\":57053},{\"end\":57067,\"start\":57060},{\"end\":57075,\"start\":57067},{\"end\":57301,\"start\":57292},{\"end\":57311,\"start\":57301},{\"end\":57321,\"start\":57311},{\"end\":57517,\"start\":57511},{\"end\":57524,\"start\":57517},{\"end\":57532,\"start\":57524},{\"end\":57540,\"start\":57532},{\"end\":57548,\"start\":57540},{\"end\":57556,\"start\":57548},{\"end\":57738,\"start\":57732},{\"end\":57744,\"start\":57738},{\"end\":57838,\"start\":57832},{\"end\":57846,\"start\":57838},{\"end\":57853,\"start\":57846},{\"end\":57860,\"start\":57853},{\"end\":57869,\"start\":57860},{\"end\":57877,\"start\":57869},{\"end\":57886,\"start\":57877},{\"end\":58164,\"start\":58158},{\"end\":58171,\"start\":58164},{\"end\":58182,\"start\":58171},{\"end\":58189,\"start\":58182},{\"end\":58196,\"start\":58189},{\"end\":58214,\"start\":58196},{\"end\":58560,\"start\":58554},{\"end\":58568,\"start\":58560},{\"end\":58575,\"start\":58568},{\"end\":58585,\"start\":58575},{\"end\":58599,\"start\":58585},{\"end\":58617,\"start\":58599},{\"end\":58855,\"start\":58849},{\"end\":58863,\"start\":58855},{\"end\":58869,\"start\":58863},{\"end\":58877,\"start\":58869},{\"end\":58883,\"start\":58877},{\"end\":59147,\"start\":59141},{\"end\":59155,\"start\":59147},{\"end\":59164,\"start\":59155},{\"end\":59171,\"start\":59164},{\"end\":59180,\"start\":59171},{\"end\":59189,\"start\":59180},{\"end\":59439,\"start\":59432},{\"end\":59447,\"start\":59439},{\"end\":59453,\"start\":59447},{\"end\":59461,\"start\":59453},{\"end\":59467,\"start\":59461},{\"end\":59649,\"start\":59641},{\"end\":59656,\"start\":59649},{\"end\":59662,\"start\":59656},{\"end\":59832,\"start\":59824},{\"end\":59839,\"start\":59832},{\"end\":59847,\"start\":59839},{\"end\":60063,\"start\":60057},{\"end\":60071,\"start\":60063},{\"end\":60079,\"start\":60071},{\"end\":60087,\"start\":60079},{\"end\":60095,\"start\":60087},{\"end\":60102,\"start\":60095},{\"end\":60114,\"start\":60102},{\"end\":60125,\"start\":60114},{\"end\":60356,\"start\":60348},{\"end\":60364,\"start\":60356},{\"end\":60374,\"start\":60364},{\"end\":60385,\"start\":60374},{\"end\":60392,\"start\":60385},{\"end\":60399,\"start\":60392},{\"end\":60405,\"start\":60399},{\"end\":60414,\"start\":60405},{\"end\":60420,\"start\":60414},{\"end\":60426,\"start\":60420},{\"end\":60784,\"start\":60776},{\"end\":60792,\"start\":60784},{\"end\":60800,\"start\":60792},{\"end\":60809,\"start\":60800},{\"end\":60816,\"start\":60809},{\"end\":61072,\"start\":61063},{\"end\":61084,\"start\":61072},{\"end\":61095,\"start\":61084},{\"end\":61225,\"start\":61216},{\"end\":61232,\"start\":61225},{\"end\":61241,\"start\":61232},{\"end\":61247,\"start\":61241},{\"end\":61255,\"start\":61247},{\"end\":61262,\"start\":61255},{\"end\":61269,\"start\":61262},{\"end\":61277,\"start\":61269},{\"end\":61663,\"start\":61654},{\"end\":61671,\"start\":61663},{\"end\":61679,\"start\":61671},{\"end\":61687,\"start\":61679},{\"end\":61694,\"start\":61687},{\"end\":61928,\"start\":61919},{\"end\":61934,\"start\":61928},{\"end\":61942,\"start\":61934},{\"end\":61949,\"start\":61942},{\"end\":62152,\"start\":62143},{\"end\":62159,\"start\":62152},{\"end\":62167,\"start\":62159},{\"end\":62173,\"start\":62167},{\"end\":62179,\"start\":62173},{\"end\":62373,\"start\":62364},{\"end\":62381,\"start\":62373},{\"end\":62387,\"start\":62381},{\"end\":62393,\"start\":62387},{\"end\":62399,\"start\":62393},{\"end\":62587,\"start\":62578},{\"end\":62595,\"start\":62587},{\"end\":62603,\"start\":62595},{\"end\":62610,\"start\":62603},{\"end\":62618,\"start\":62610},{\"end\":62624,\"start\":62618},{\"end\":62808,\"start\":62800},{\"end\":62818,\"start\":62808},{\"end\":62832,\"start\":62818},{\"end\":62948,\"start\":62940},{\"end\":62956,\"start\":62948},{\"end\":62970,\"start\":62956},{\"end\":63162,\"start\":63154},{\"end\":63169,\"start\":63162},{\"end\":63175,\"start\":63169},{\"end\":63183,\"start\":63175},{\"end\":63192,\"start\":63183},{\"end\":63198,\"start\":63192},{\"end\":63392,\"start\":63385},{\"end\":63400,\"start\":63392},{\"end\":63407,\"start\":63400},{\"end\":63414,\"start\":63407},{\"end\":63423,\"start\":63414},{\"end\":63433,\"start\":63423},{\"end\":63666,\"start\":63659},{\"end\":63672,\"start\":63666},{\"end\":63678,\"start\":63672},{\"end\":63684,\"start\":63678},{\"end\":63692,\"start\":63684},{\"end\":63699,\"start\":63692}]", "bib_venue": "[{\"end\":38792,\"start\":38781},{\"end\":39038,\"start\":39034},{\"end\":39197,\"start\":39142},{\"end\":39518,\"start\":39514},{\"end\":39731,\"start\":39727},{\"end\":39939,\"start\":39867},{\"end\":40187,\"start\":40135},{\"end\":40526,\"start\":40515},{\"end\":40706,\"start\":40695},{\"end\":40954,\"start\":40947},{\"end\":41190,\"start\":41121},{\"end\":41505,\"start\":41393},{\"end\":41805,\"start\":41732},{\"end\":42037,\"start\":41988},{\"end\":42304,\"start\":42300},{\"end\":42479,\"start\":42435},{\"end\":42682,\"start\":42627},{\"end\":43020,\"start\":43001},{\"end\":43309,\"start\":43273},{\"end\":43579,\"start\":43568},{\"end\":43775,\"start\":43724},{\"end\":44095,\"start\":44051},{\"end\":44291,\"start\":44239},{\"end\":44557,\"start\":44552},{\"end\":44757,\"start\":44693},{\"end\":45031,\"start\":45027},{\"end\":45252,\"start\":45198},{\"end\":45503,\"start\":45496},{\"end\":45799,\"start\":45795},{\"end\":46037,\"start\":45959},{\"end\":46427,\"start\":46370},{\"end\":46648,\"start\":46603},{\"end\":47005,\"start\":46964},{\"end\":47305,\"start\":47282},{\"end\":47541,\"start\":47504},{\"end\":47769,\"start\":47753},{\"end\":48041,\"start\":48036},{\"end\":48287,\"start\":48215},{\"end\":48540,\"start\":48489},{\"end\":48917,\"start\":48873},{\"end\":49186,\"start\":49102},{\"end\":49505,\"start\":49501},{\"end\":49782,\"start\":49778},{\"end\":50035,\"start\":50024},{\"end\":50315,\"start\":50195},{\"end\":50781,\"start\":50728},{\"end\":51070,\"start\":51036},{\"end\":51268,\"start\":51190},{\"end\":51520,\"start\":51452},{\"end\":51816,\"start\":51750},{\"end\":52160,\"start\":52106},{\"end\":52433,\"start\":52379},{\"end\":52829,\"start\":52776},{\"end\":53275,\"start\":53194},{\"end\":53693,\"start\":53634},{\"end\":53903,\"start\":53892},{\"end\":54148,\"start\":54141},{\"end\":54369,\"start\":54307},{\"end\":54696,\"start\":54653},{\"end\":55009,\"start\":54993},{\"end\":55301,\"start\":55297},{\"end\":55520,\"start\":55477},{\"end\":55806,\"start\":55725},{\"end\":56120,\"start\":56101},{\"end\":56335,\"start\":56285},{\"end\":56610,\"start\":56603},{\"end\":56813,\"start\":56774},{\"end\":57079,\"start\":57075},{\"end\":57325,\"start\":57321},{\"end\":57575,\"start\":57556},{\"end\":57773,\"start\":57744},{\"end\":57964,\"start\":57902},{\"end\":58303,\"start\":58230},{\"end\":58552,\"start\":58509},{\"end\":58847,\"start\":58760},{\"end\":59194,\"start\":59189},{\"end\":59478,\"start\":59467},{\"end\":59666,\"start\":59662},{\"end\":59822,\"start\":59746},{\"end\":60144,\"start\":60125},{\"end\":60494,\"start\":60442},{\"end\":60774,\"start\":60717},{\"end\":61061,\"start\":61006},{\"end\":61360,\"start\":61293},{\"end\":61698,\"start\":61694},{\"end\":61917,\"start\":61864},{\"end\":62141,\"start\":62072},{\"end\":62362,\"start\":62322},{\"end\":62576,\"start\":62514},{\"end\":62843,\"start\":62832},{\"end\":63003,\"start\":62986},{\"end\":63152,\"start\":63117},{\"end\":63383,\"start\":63317},{\"end\":63715,\"start\":63699},{\"end\":53343,\"start\":53277}]"}}}, "year": 2023, "month": 12, "day": 17}