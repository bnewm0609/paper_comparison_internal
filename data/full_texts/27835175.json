{"id": 27835175, "updated": "2022-03-10 19:16:52.795", "metadata": {"title": "Auditory-Inspired Speech Envelope Extraction Methods for Improved EEG-Based Auditory Attention Detection in a Cocktail Party Scenario", "authors": "[{\"first\":\"Wouter\",\"last\":\"Biesmans\",\"middle\":[]},{\"first\":\"Neetha\",\"last\":\"Das\",\"middle\":[]},{\"first\":\"Tom\",\"last\":\"Francart\",\"middle\":[]},{\"first\":\"Alexander\",\"last\":\"Bertrand\",\"middle\":[]}]", "venue": "IEEE Transactions on Neural Systems and Rehabilitation Engineering", "journal": "IEEE Transactions on Neural Systems and Rehabilitation Engineering", "publication_date": {"year": 2017, "month": null, "day": null}, "abstract": "This paper considers the auditory attention detection (AAD) paradigm, where the goal is to determine which of two simultaneous speakers a person is attending to. The paradigm relies on recordings of the listener\u2019s brain activity, e.g., from electroencephalography (EEG). To perform AAD, decoded EEG signals are typically correlated with the temporal envelopes of the speech signals of the separate speakers. In this paper, we study how the inclusion of various degrees of auditory modelling in this speech envelope extraction process affects the AAD performance, where the best performance is found for an auditory-inspired linear filter bank followed by power law compression. These two modelling stages are computationally cheap, which is important for implementation in wearable devices, such as future neuro-steered auditory prostheses. We also introduce a more natural way to combine recordings (over trials and subjects) to train the decoder, which reduces the dependence of the algorithm on regularization parameters. Finally, we investigate the simultaneous design of the EEG decoder and the audio subband envelope recombination weights vector using either a norm-constrained least squares or a canonical correlation analysis, but conclude that this increases computational complexity without improving AAD performance.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": "2408166852", "acl": null, "pubmed": "27244743", "pubmedcentral": null, "dblp": null, "doi": "10.1109/tnsre.2016.2571900"}}, "content": {"source": {"pdf_hash": "1730dff5e5b71d2d09161f8d6bfadf513845b64f", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": null, "status": "CLOSED"}}, "grobid": {"id": "cde2ad28eb0fba89d9adfaf1e45ec0918b9f1a65", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1730dff5e5b71d2d09161f8d6bfadf513845b64f.txt", "contents": "\nAuditory-Inspired Speech Envelope Extraction Methods for Improved EEG-Based Auditory Attention Detection in a Cocktail Party Scenario\nMAY 2017\n\nWouter Biesmans \nNeetha Das neetha.das@student.kuleuven.be \nTom Francart \nMember, IEEEAlexander Bertrand \nAuditory-Inspired Speech Envelope Extraction Methods for Improved EEG-Based Auditory Attention Detection in a Cocktail Party Scenario\n\nIEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING\n255MAY 201710.1109/TNSRE.2016.2571900Manuscript received November 26, 2015; revised April 11, 2016; accepted May 15, 2016. Date of publication May 24, 2016; date of current version May 7, 2017.402 The work of W. Biesmans was sup-ported by a Doctoral Fellowship of the Research Foundation-Flanders (FWO). This work was carried out at the ESAT and ExpORL Labo-ratories of KU Leuven, in the frame of KU Leuven Special Research Fund BOF/STG-14-005 and OT/14/119, and iMinds Medical Information Technologies: SBO 2015. Corresponding author: Neetha DasIndex Terms-Auditory attentionauditory modelscock- tail partyelectroencephalography(EEG) processingneuro- steered auditory prosthesesspeech envelope\nThis paper considers the auditory attention detection (AAD) paradigm, where the goal is to determine which of two simultaneous speakers a person is attending to. The paradigm relies on recordings of the listener's brain activity, e.g., from electroencephalography (EEG). To perform AAD, decoded EEG signals are typically correlated with the temporal envelopes of the speech signals of the separate speakers. In this paper, we study how the inclusion of various degrees of auditory modelling in this speech envelope extraction process affects the AAD performance, where the best performance is found for an auditoryinspired linear filter bank followed by power law compression. These two modelling stages are computationally cheap, which is important for implementation in wearable devices, such as future neuro-steered auditory prostheses. We also introduce a more natural way to combine recordings (over trials and subjects) to train the decoder, which reduces the dependence of the algorithm on regularization parameters. Finally, we investigate the simultaneous design of the EEG decoder and the audio subband envelope recombination weights vector using either a norm-constrained least squares or a canonical correlation analysis, but conclude that this increases computational complexity without improving AAD performance.\n\nI. INTRODUCTION\n\nT HE human auditory system has the remarkable ability to attend to one speaker and ignore the others in a so-called cocktail party scenario with multiple simultaneous speakers. Since the effect was first described in 1953 [2], it has been a topic of ongoing research in the fields of neuroscience and audiology. It was demonstrated in [3] that speech spectrograms that were reconstructed from cortical responses to a multispeaker stimulus reveal spectral and temporal features of the attended speaker, as if the unattended speakers were not there. This is very interesting from a neuroscientific point of view as it provides a new research tool that can help us to understand and map the human auditory processing. Furthermore, it allows us to detect to which speaker a subject is attending in a cocktail party scenario [4]- [6]. This auditory attention detection (AAD) paradigm might lead to a breakthrough for auditory prostheses (APs) such as hearing aids and cochlear implants. As it stands, current state-of-theart APs employ beamforming, fixed or adaptive, to enhance a signal from one direction and suppress the rest. However, the system does not know to which signal the listener intends to attend. Therefore, the integration with an AAD system to steer the beamforming algorithm to the attended speaker would be of great benefit. AAD has successfully been applied to electrocorticography [4], magnetoencephalography (MEG) [6] and EEG [5], [7], [8]. When aiming for application of AAD in portable, mainstream devices such as a AP however, EEG is the only practical noninvasive modality. Although wearable EEG devices are currently still quite bulky, significant progress has been made towards unobtrusive wearable EEG solutions [9]- [14].\n\nDifferent multi-channel approaches have been proven to be successful at performing AAD. In [8], robust features that are relevant for classification are extracted from the neural measurements, and then used to train a classifier. In [15], attention is tracked with a high temporal resolution using a state-space modelling approach. Another approach, which is currently more popular for AAD, relies on stimulus reconstruction in which a spatio-temporal linear decoder is first trained, and then used to reconstruct the envelope of the attended speaker's speech signal from the multi-channel neural measurements. The decoder can be trained using either a least squares (LS) estimation error objective function [5], [7], or by maximizing a cross-correlation ratio using a generalized eigenvector decomposition [6]. Once such a decoder has been trained, it can be applied to other neural recordings, after which the reconstructed speech envelope can be compared to the actual speech envelopes through Pearson's correlation coefficient. A final classification then marks the speaker corresponding to the envelope with highest correlation as the attended speaker.\n\nIn this paper, we follow the LS approach proposed in [5] which is a popular method for AAD, mainly because of its simplicity and computational efficiency, while at the same time being very effective, as shown in several studies [7], [16]- [18]. However, we introduce a more natural way of combining the data for training the decoder, in which we solve a single LS problem over the entire data set, rather than averaging over a multitude of per-trial LS solutions. This different training methodology not only results in better AAD performance, but also reduces the sensitivity with respect to a regularization parameter, up to a point where the latter can be fully eliminated if sufficient training data is available.\n\nA second goal of this paper is to investigate whether it is possible to improve AAD performance by including knowledge of the auditory periphery into the speech envelope extraction step. When a sound arrives at the ear, it is first filtered by the middle ear, followed by complex nonlinear processing in the inner ear where the sound wave is converted into a series of spikes in the auditory nerve. Thereafter, this spike train is processed by the brainstem, midbrain, auditory cortex and higher cortical areas. The reconstructed envelope used in the current study is probably derived from neural activity originating from the auditory cortex. While we currently only have limited knowledge of cortical processing of speech, there are good models available of the processing that takes place in the auditory periphery (outer and inner ear). As the spike trains in the auditory nerve serve as the input to the auditory cortex, it makes sense to include a model of the auditory periphery in the AAD processing chain.\n\nBearing in mind that the computational power in auditory prostheses is limited, we aim to optimize the computational complexity versus AAD performance tradeoff by including speech envelope extraction methods that model the auditory periphery with gradually increasing precision. We start from the standard envelope extraction method used in [5], and gradually include pragmatic and computationally cheap auditory-inspired signal operations, such as amplitude compression and subband processing with an auditory filter bank, and assess their individual effect on the AAD performance. Finally, envelope extraction methods based on three wellestablished and computationally complex auditory models are examined.\n\nSubband envelope methods in general pose an extra question: how should we recombine these subband envelopes into one envelope, i.e., which weights should be given to each subband? As there is no obvious way to do this, one might benefit from an algorithm that determines the optimal recombination. Canonical correlation analysis (CCA) and bimodal LS provide a framework for obtaining optimal envelope weight vectors. We apply these algorithms to the best-performing subband envelope extraction method to see if they result in any performance increase.\n\nThe different methods are assessed using experimental data with EEG recordings from 16 subjects. We note that these are all new subjects, and this excludes the seven subjects from our pilot study which was published as a conference precursor in [1], in which a different measurement protocol was used.\n\nThe paper is organized as follows: in Section II we start by reviewing the basic AAD procedure used in this paper, introducing the training methodology and detailing the evaluation strategy. In Section III, we then discuss the different auditory-inspired speech envelope extraction methods. As subband envelopes provide us with an additional challenge, we describe two extended AAD procedures in Section IV that also take care of an optimal recombination of several subband envelopes into one envelope. In Section V, we provide details of the experiment design and the key processing parameters. In Section VI, we evaluate the effect of the different envelope extraction methods on AAD performance. In Section VII, we discuss the implications of these results for future application in APs, and we elaborate on remaining open problems. Finally, we draw conclusions in Section VIII.\n\n\nII. AUDITORY ATTENTION DETECTION\n\nIn this section, we review the basic AAD procedure, covering the training and detection process in more detail.\n\n\nA. Problem Statement\n\nFor the remainder of this paper we assume that for each test subject we have a set of K measurements, referred to as trials, available. Each trial consists of a C-channel EEG recording and the corresponding attended and unattended speech signals, which were simultaneously presented to the subject during the recording of the trial. Every trial is assumed to have the same length, which we will define later. We use M(t, c) to denote the C-channel EEG recording, where t is the discrete time or sample index and c the channel index. The temporal envelopes are obtained by extracting the envelopes from both speech signals (attended and unattended) and are denoted by s a (t) and s u (t) respectively. We use the index k to indicate recordings from the kth trial when appropriate, and a tilde to refer to an estimated variable rather than the real one (e.g.,s a (t)).\n\nAAD can be achieved through an envelope reconstruction approach: a decoder is designed which reconstructs the attended speech envelope from the multi-channel EEG recordings. It has been shown that a linear, spatio-temporal decoder is capable of adequately reconstructing the attended speech envelope such that the reconstructed envelope resembles the attended speech envelope s a (t) more than the unattended speech envelope s u (t) [4]- [6]. This resemblance is quantified by Pearson's correlation coefficient and is used for the final AAD: the speech envelope that correlates best with the reconstructed envelope is ultimately classified as the attended speech envelope.\n\nThe stimulus reconstruction defining the decoder D \u2208 R N l \u00d7C can be expressed as follows:\ns a (t) = N l \u22121 n=0 C c=1 D(n, c)M(t + n, c).(1)\nHere, n denotes the time lag index, with time lags ranging from 0 to N l \u22121 samples. The spatio-temporal nature of the decoder is expressed through the channel index c and the time lag index n, and allows the attended envelope at sample time t to be reconstructed as a weighted sum of all of the C EEG channels at time t, as well as future sample times t + n. The time lags account for the physical delay between the presentation of the auditory stimulus and the moment it is actually processed by the brain. It has been found in [5] that time lags up to 250 ms are most effective at reconstructing the envelope, which was also verified in our data.\n\n\nB. Design of Decoder\n\nThe decoder D can be determined through optimization of a well-chosen objective function, for example by minimizing the expected value (E [.]) of the squared error between the estimated and the actual attended speech envelope as in [5]. Another sensible approach would be to maximize the Pearson correlation coefficient between both. Up to an irrelevant scalar, as we show in the following, both are in fact equivalent, i.e.\nD = arg min D E[|s a (t) \u2212 s a (t)| 2 ] (2) \u223c arg max D E[s a (t)s a (t)] E[s 2 a (t)]E[s 2 a (t)]\n.\n\n(3)\n\nFor ease of notation we define vectors m c (t) \u2208 R N l , containing all N l time lags of channel c, and m(t) \u2208 R N l C , containing all time lags of each of the C channels\nm c (t) = [M(t, c) M(t + 1, c) \u00b7 \u00b7 \u00b7 M(t + N l \u2212 1, c)] T (4) m(t) = [m 1 (t) T m 2 (t) T \u00b7 \u00b7 \u00b7 m C (t) T ] T .(5)\nEquation (1) can then be rewritten as\ns a (t) = d T m(t)(6)\nwhere d \u2208 R N l C is the vectorized version of D. This new notation is used in the remainder of this paper. Substituting (6) into (2) results in a standard linear minimum mean squared error (LMMSE) problem. Its analytical solution is well known and can be obtained by setting the derivative with respect to the entries of d equal to zero, resulting i\u00f1 d = R \u22121 r ms (7) where R = E[m(t)m(t) T ] \u2208 R N l C\u00d7N l C is the autocorrelation matrix of the EEG recordings, and r ms = E[m(t)s a (t)] \u2208 R N l C is a vector containing the cross-correlations of the attended speech envelope and the (time-lagged) EEG channels.\n\nTo show the equivalence between (2) and (3), we reformulate (3) as a maximization of the numerator while replacing the denominator by a norm-constraint. With the notation introduced previously, this leads to the equivalent problem\nd \u223c arg max d r T ms d s.t. d T Rd = 1( 8 )\nwhere the factor E[s 2 a (t)] in (3) is omitted as it is independent of d. This reformulation can then be solved using Lagrange multipliers, resulting in a scaled version of (7).\n\n\nC. Training\n\nIn practice, the true autocorrelation matrix R and crosscorrelation vector r ms are of course unknown, but can be estimated from the measurements through their sample estimates, denoted asR andr ms . This effectively transforms the LMMSE problem from (2) into an LS problem.\n\nAs the dimension of the decoder is large and conditions between trials might vary slightly, overfitting to the specific data used for training is a real concern. To overcome this, a cross validation approach should be taken where decoders are only applied to EEG recordings that were not used to construct the decoder. In this paper, we use a subject-specific leave-oneout cross validation. This means that the data from all K \u2212 1 other trials from the same subject are used in the design of the decoder to decode trial k. To emphasize this, we use the subscript \u2212k to denote the decoderd \u2212k for the kth trial.\n\nTo combine data from multiple trials in the design of the decoder, it is common practice to construct a preliminary set of decodersd k =R \u22121 kr ms,k for k = 1 . . . K , using only the data from a single trial [5], [7], [16], [17]. Then preliminary decoders from all trials but trial k can be averaged to obtain a decoderd \u2212k that is used to decode trial k\nd \u2212k = 1 K \u2212 1 K i=1 i =kd i , k = 1 . . . K(9)\nwhere i is used as another trial index. If a subject-independent decoder is to be trained, further averaging can be done across subjects to find a so-called \"grand-average\" decoder [5], [7]. Although, mathematically speaking, this is a rather arbitrary way of combining the data from multiple trials or subjects, this method has been proven to be successful in several papers [5], [7], [16], [17]. However, typically single trials are rather short (e.g., 60 seconds) compared to the large dimension ofR k . This contributes toR k being ill-conditioned or even (in extreme cases) rank-deficient, which is a problem when evaluating (7). The obtained decoders are very sensitive to perturbations on the training data, such that all trials may generate very different solutions. In this case, a simple averaging of the different decoders may prove ineffective.\n\nTo avoid rank-deficiency and improve conditioning, regularization is then typically applied to R k\nd k = (R k + \u03bbz k Q) \u22121r ms,k ,(10)\nwhere \u03bb is a relative regularization parameter, which is multiplied by z k , the mean eigenvalue ofR k . This mean eigenvalue z k can easily be calculated as the average of the diagonal elements ofR k . Q is the regularization matrix, typically chosen to be the identity matrix (corresponding to a ridge regression), penalizing the L2 norm of d. In the case of AAD, Q is sometimes also chosen to be\nQ = \u23a1 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a3 1 \u22121 \u22121 2 \u22121 \u22121 2 \u22121 . . . . . . . . . \u22121 2 \u22121 \u22121 1 \u23a4 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a6 .(11)\nThis choice for Q penalizes the norm of the discrete derivative of d with respect to its entry index. This can be preferred if the spatio-temporal decoder is expected to be smooth in the temporal dimension.\n\nUsing such regularization schemes, AAD performance can be boosted to an acceptable level. However, disadvantages of regularization are that it adds bias and that it requires a regularization parameter \u03bb that needs to be tuned in order to find a good balance between sufficient generalization (to avoid overfitting) and too much generalization (to avoid losing predictive power). In the Appendix, we show that the performance is rather sensitive to the choice of this regularization parameter, when the decoder is indeed computed as an average of per-trial decoders.\n\nIn this paper, we use a more natural way to combine the recordings, by minimizing the following sum of LS objective functions:\nd \u2212k = arg min d \u2212k 1 K \u2212 1 K i=1 i =k E[|s a,i (t) \u2212 s a,i (t)| 2 ], (12) s a,i (t) = d T \u2212k m i (t).(13)\nThis objective function can be maximized by plugging the average autocorrelation and cross-correlation vector from all but the kth trial (respectively denoted byR \u2212k andr ms,\u2212k ) into (7). Note that averaging sample autocorrelation and covariance matrices is equivalent to concatenating the recordings in time and training a single decoder based on this longer, concatenated recording. Again, if a subjectindependent decoder is to be designed, the summation in (12) can be extended to sum over all subjects. However, in the sequel, we only consider subject-dependent decoders. As more samples are available for the estimation ofR \u2212k compared toR k , it is naturally better conditioned, in our case 1 removing the need for a regularization scheme. In addition, we show in the Appendix that, even if the optimal value of the regularization parameter is selected in (9) and (10) through a parameter sweep, the second option still yields significantly better results. Therefore, in the remainder of this paper, we always train a single LS decoder on the full training data set as in (12) rather than averaging single-trial decoders as in (9) and (10).\n\n\nD. Detection Details\n\nOnce the decoderd \u2212k has been trained based on the data from all trials except trial k, it can be used to reconstruct the attended speech envelope from the EEG recording of trial k, as in (1). Pearson correlation coefficients can then be calculated between this reconstructed speech envelopes a (t) and both real speech envelopes s a (t) and s u (t). We refer to these coefficients as the reconstruction accuracies, and denote them by r a and r u , respectively. The speech envelope corresponding to the highest reconstruction accuracy is then naturally classified as the attended speech, e.g., if r a > r u , this results in a correct classification. This process is repeated for each trial. Note that the discriminative power of these correlation coefficients strongly depends on the trial length, which can be chosen post hoc (after the experiment).\n\n\nIII. ENVELOPE EXTRACTION METHODS\n\nThe main focus of this paper is to evaluate whether it is possible to improve the AAD performance, by gradually including more knowledge of the auditory periphery in the envelope extraction process. In this section we describe the different methods for extracting such a speech envelope s(t) from the speech signal x(t). The AAD performance using these envelope extraction methods is evaluated in Section VI. We start by describing some basic envelope extraction methods lacking any auditory motivation, and gradually increase the complexity of auditory modelling. Finally, some methods based on more accurate (but more complex) models of the auditory periphery are discussed. Concluding this section, we briefly motivate the choice of some filtering parameters relevant to the envelope extraction.\n\n\nA. Basic Envelope Extraction\n\nBasic envelope extraction methods are based on what we intuitively think of when considering envelopes of signals. The first method calculates the speech envelope by taking the absolute value |x(t)| of the broadband signal x(t) and low pass filtering the result. The process is known as full-wave rectification and is often used in electronics. We abbreviate this method as \"abs\".\n\nAs an alternative, one can compute the amplitude of the complex-valued analytic signal, which is often referred to as the mathematical envelope of a signal, as it results in the modulating signal when applied to a modulated sine wave. The analytic signal of a signal x(t) can be constructed as\nx(t) + j H (x(t))\n, where H (.) represents the Hilbert transform operator, which applies a 90 degrees phase shift to the original signal. We mention this method for completeness, but when applied to audio signals it results in nearly identical envelopes as the \"abs\" method (after subsequent band pass filtering, see Section III-E). As it is also computationally more complex, we omit this method in favor of the first.\n\nIn a second method we consider, the speech envelope is calculated as the long-term power average of the signal. As the long-term average can be obtained by integration, or equivalently, low pass filtering, we obtain the envelope by squaring the original signal and low pass filtering it afterwards. We refer to this method as \"square\".\n\n\nB. Compressed Envelopes\n\nThe human auditory system is not a linear system. For example, the relation between intensity of the stimulus and the perceived loudness is less-than-linear. This compression results in a relative attenuation of higher amplitude signals, making it Frequency response of the gammatone filterbank used to decompose the audio into frequency subbands.\n\npossible for the human ear to have a large dynamic range. The relationship between loudness, which is a perceptual measure of stimulus intensity, and the actual stimulus intensity has been studied extensively. Typical simple models used for this relation use either a power law relation, i.e., |x(t)| \u03b2 with exponent 2 \u03b2 = 0.6 [19], or a logarithmic relation [20], i.e., log(|x(t)|+ ). Here, is a small, positive number ensuring that the argument of the logarithm is strictly positive. We refer to these methods as \"p-law\" and \"log\" respectively.\n\nRemark: The power law function is scale-invariant for positive scaling factors a, i.e., |ax(t)| \u03b2 = a \u03b2 |x(t)| \u03b2 , \u2200a \u2265 0. This means that normalization of the signal has no influence on the shape of the resulting envelope, which is desirable. The logarithmic function has a similar property: scaling of the argument only results in a dc offset in the envelope log(|ax(t)|) = log(|x(t)|) + log(a), \u2200a > 0. As all envelopes are high pass filtered at a later stage, we can ignore this dc offset. Hence, for our application, the logarithmic function can also be considered scale-invariant.\n\n\nC. Subband Envelopes\n\nIn the auditory pathway, speech signals are split into frequency subbands by the basilar membrane in the cochlea before the actual envelope extraction process takes place. We mimic these auditory filters, e.g., by applying a gammatone filter bank [21], [22] to the audio signal x(t). The filter bank contains N s = 15 perceptually uniform gammatone filters, each with an equivalent rectangular bandwidth equal to 1.5, and center frequencies ranging from 150 Hz to 4 kHz (as the stimulus is also band-limited to 4 kHz, see Section V). Its frequency response is depicted in Fig. 1. Note that the filters become wider at higher frequencies, which reflects the fact that the human auditory system has a poorer spectral resolution in the higher frequencies. It was found that the actual number of subbands N s is not critical for performance, as long as the filter widths are scaled accordingly and N s \u2265 5.\n\nThe aforementioned envelope extraction methods can then be applied to each of the N s subband signals instead of the broadband signal, resulting in a vector s(t) \u2208 R N s of subband envelopes. Since the basic AAD procedure as described in Section II requires just one envelope however, some recombination of these subband envelopes is necessary. We only consider weighted linear combinations: s(t) = w T s(t), where w \u2208 R N s is the envelope weight vector. Subband envelopes could, for example, be recombined with equal weights, or with weights determined by the respective band importance (BI) [23]. The latter is used in the calculation of the speech intelligibility index, and we employ the same here to weight the frequency subbands to increase the influence of the frequency bands that contribute most to speech intelligibility. We will compare this with a uniform (all-ones) weight vector w, and additionally, in Section IV, we will also define two methods to choose a set of envelope weights that are optimal in some mathematical sense.\n\nApplying the gammatone filterbank before, and using the previously described envelope extraction methods to each of the subband signals, introduces a subband version of each. We mark these respective subband versions by the postfix \"sub\", e.g., \"abs sub\". If the postfix \"sub\" is used in the sequel, we refer to the case where the subbands are added with equal weights unless stated otherwise.\n\n\nD. Auditory Models\n\nFor even more detailed models of the auditory periphery, we refer to three well-known auditory models [24]- [26].\n\nThe first model, \"Yang\" [24], is available through the NSL Matlab Toolbox, and processes the audio in three stages. The analysis stage models the cochlear filters by applying a wavelet transform, to decompose the signal into 128 subbands. The transduction stage is applied to each subband individually and models the dynamics of the hair cells. Hair cells are the auditory system's transducers, transforming the mechanical vibrations into electrical activity. Finally, the reduction stage reduces the amount of information by extracting only certain spectral features, using a lateral inhibitory network. As the output consists of 128 subband \"envelopes\", we recombine these, by adding them using uniform weights.\n\nThe second model, \"Meddis\" [26], is implemented in the MATLAB Auditory Periphery (MAP) toolbox. It is more complex than \"Yang\", both from a modelling perspective as from a computational point of view. As a result, envelope extraction cannot be performed in real-time. Therefore the model, in its current form, might not be directly amenable for wearable devices. Still it is interesting to see how it performs. It models the auditory periphery through nine modules, each tied to a specific physiological process and its outputs each represent physically measurable values such as the instantaneous neuron firing rate at user-defined frequencies.\n\nThe third and final model, \"Zilany\" [25], models the auditory periphery using a phenomenological approach. The main stages comprise a forward control path, outer and inner hair cell sections and a synapse model. In its current implementation however, it is even more computationally demanding than \"Meddis\".\n\nBoth \"Meddis\" and \"Zilany\" provide instantaneous firing rates of the auditory nerves at neurons corresponding to user-defined frequencies as a possible output. We use these firing rates at the same 15 center frequencies as were previously used for the gammatone filter bank as subband \"envelopes\". As the output is present in the form of neuronal firing rates, they are weighted by their respective neuronal densities [27], [28] before being added together to form a single envelope.\n\n\nE. Filtering\n\nIt has been shown that speech envelope and EEG recordings correlate best within the \u03b4 and \u03b8 band frequencies [4]. We therefore digitally band pass filter both the speech envelopes and the EEG recordings between 2 and 9 Hz. Because of this, whenever any low pass filtering or integration occurs as a last step in the envelope extraction process, it is skipped, as it is redundant. All filtering is performed using a linear phase filter, where the same filter is applied to the speech envelopes and the EEG recordings.\n\n\nIV. BIMODAL AAD PROCEDURE\n\nWith the notion of subband envelopes that was introduced previously, a new question arises: can AAD performance be further improved by recombining subband envelopes through a mathematically optimal weight vector instead of the arbitrary or physiologically motivated options that we proposed before? In this section, we provide two mathematically optimal methods for simultaneously obtaining both an EEG decoder d and an envelope weight vector w. In this case data from two modalities (envelope and EEG domain) are used simultaneously, hence the term bimodal.\n\nOptimality should of course first be defined by some objective function. Two suitable objective functions, similar to those from the basic AAD processing, are considered. As in (3), we can choose to maximize the Pearson correlation between the estimated attended speech envelopes a (t) and the true attended speech envelope s a (t), which now is a recombination of multiple attended speech subband envelopes contained in s a (t). The second option is to minimize the LS estimation error between the two, similar to (2). The difference now is that in both objective functions the audio weights vector w is included as an additional optimization variable. The objective function (3) then becomes\nd,w = arg max d,w E[(d T m(t))(w T s a (t))] E[(d T m(t)) 2 ]E[(w T s a (t)) 2 ] .(14)\nThis objective function also appears in canonical correlation analysis (CCA) [29], and its solution corresponds to the first canonical weight vectors. The solution can also be derived using Lagrange multipliers after reformulating the denominator of (14) as two norm constraints. The optimal decoder and envelope weight vector are then found as\nd = GEVec 1 (R ms R \u22121 s R T ms , R)(15)w = GEVec 1 (R T ms R \u22121 R ms , R s )(16)\nwhere GEVec 1 (A, B) is used to denote the principal generalized eigenvector of the matrix pencil (A, B),\nR s = E[s a (t)s T a (t)] \u2208 R N s \u00d7N s is the subband speech envelopes'\ncovariance matrix, and R ms = E[m(t)s T a (t)] \u2208 R C\u00d7N s is a matrix containing the cross-correlations between each (timelagged) EEG channel and each subband envelope.\n\nBased on experiments, it was found that choosing R s = I N s , which corresponds to infinite regularization, yields as good results as any other choice of the regularization parameter. However, it avoids having to estimate R s , which is especially convenient in a practical setting. It is noted that CCA with one of the covariance matrices set to the identity matrix is equivalent to Orthonormalized Partial LS (OPLS), a variant of PLS [30].\n\nThe second option, which we refer to as \"bimodal LS\", corresponds to the cost function (2) which is now altered t\u00f5\nd,w = arg min d,w E[|d T m(t) \u2212 w T s a (t)| 2 ] s.t. d w 2 2 = 1.(17)\nThe norm constraint on d w is necessary to avoid the trivial solution. After writing the two-norm in full, it can be seen that the solution can be found as\nd w = EVec min (T ) (18) T = R \u2212R ms \u2212R T ms R s(19)\nwhere EVec min (A) denotes the eigenvector of the matrix A corresponding to the smallest eigenvalue. Unlike in (2) and (3), both objective functions now provide us with different solutions. However, it can be shown that if the smallest eigenvalue of T is small compared to the eigenvalues of both R and R s , both solutions are approximately equivalent (proof omitted). To limit our search space for the best performing envelope extraction method, we only apply \"CCA\" and \"bimodal LS\" to the best performing subband envelope procedure from Section III, to see if any further performance improvement can be obtained.\n\n\nV. EXPERIMENTAL PROCEDURES\n\nTo be able to evaluate the performance of the different envelope extraction methods proposed, we set up an AAD experiment, which we describe in this section.\n\nA. Setup of Experiment 1) Goal: The experiment was designed to mimic a cocktail party scenario in which the subject listens to two simultaneous speakers at two distinct spatial locations and attempts to attend to only one of them while ignoring the other.\n\n2) Subjects: Sixteen normal hearing subjects (verified by audiometry) between 17 and 30 years old participated in the experiment, eight of them were male, eight were female. All of them (and/or their legal guardian) signed an informed consent form approved by the KU Leuven ethical committee.\n\n3) Equipment: During the entire experiment, 64-channel EEG was recorded using a BioSemi ActiveTwo system. The electrodes were placed on the head according to international 10-20 standards. The experiment took place in a soundproof, electromagnetically shielded room, and auditory stimuli were presented to the subjects using insert phones (Etymotic ER3A) at 60 dBA. As the insert phones' transducer has a cut-off frequency of 4 kHz, all audio signals were low pass filtered at 4 kHz as well. 4) Stimulus Structure: As audio material, four Dutch short stories [31], narrated by different speakers (all male), were selected. Silences were truncated to 500 ms, and the resulting audio was divided into two \"tracks\", one of which was to be attended by the subject while the other was to be ignored. Each track consisted of four story \"parts\", lasting approximately six minutes each. After presenting one part to the subject (a \"presentation\"), some multiple choice questions about the content of the attended story part appeared on a screen. These questions were intended to keep the subject engaged in the task and the answers were not used further in this study. After four story parts, the subject was offered an extended break. 5) Presentation Structure: After the break, the same stimuli were presented, but the subject was asked to attend to the other track. After a second break, the subject was then asked to attend to each part of the first track again. This time however, only the first two minutes of each part was presented, without questions in between. This was repeated two more times, such that the first two minutes of each part of the first track was attended four times in total. These so-called \"repetitions\" were kept at a minimum as they are perceived as boring and might result in attention loss, and were included for a specific purpose in a related study. However, it is important to note that we do not exploit these repetitions to, e.g., improve signal-tonoise ratio by averaging them. The EEG analysis in this paper is performed on a single-trial basis, although a subset of the stimuli appears multiple times in the data set. Summarizing, the subject first attended eight unique story parts of six minutes each, before listening to the first two minutes of each part of the first track for three more times, totalling 12 repetitions. This brings the grand total at 8\u00d76 minutes+12\u00d72 minutes = 72 minutes of recorded EEG per subject. 6) Presentation Mode: In order to design a more general decoder that works in different conditions, two conditions were varied evenly in between every presentation: the ear to which the attended track was presented, and the acoustic processing of the speech signals. Either \"dry\" speech was offered, i.e., each speaker was presented to a different ear, or speech signals were processed by (dead room) head-related transfer functions, simulating a more realistic listening scenario in which the speakers are spatially located 90 degrees to the left and the right of the subject. In this case the stimuli of both ears contain both speech signals, albeit with different intensities and delays. The order of presentation of both condition types was balanced over the different subjects.\n\n\nB. Data Processing\n\nThe recorded EEG is band-pass filtered between 2 and 9 Hz, and down-sampled to 20 Hz. The auditory stimuli that were presented to the subjects are sampled at 8 kHz (as their frequency content only ranges up to 4 kHz). For both the attended and the unattended speech signals, envelopes are extracted using the different methods detailed in Section III. Afterwards these envelopes are band pass filtered between 2 and 9 Hz, and downsampled to 20 Hz as well.\n\nTrials are then created by chopping the data into pieces of equal length. Most studies on AAD employ 60-second trials. For the main analysis of this paper however, i.e., the comparison of the different envelope extraction methods, we deliberately choose a shorter trial duration of 30 seconds, because it makes the differences between methods become more apparent. Furthermore, it also means that more trials (144 instead of 72) can be evaluated, resulting in more power for the statistical tests. Nonetheless, to allow for a comparison with literature, we also provide some results with 60-second trials.\n\nFor each of the 16 subjects, a decoder D was then trained for each trial, using the data of every other trial of this subject as described in Section II-C. Note that it can be expected that all decoders for a subject are very similar, because of the leaveone-trial-out approach. The decoders are applied to the EEG recordings, resulting in 144 reconstructed speech envelopes per subject (one for each trial). Pearson correlations with both attended and unattended speech envelopes are calculated for each trial and compared (see Section II-D for details). This results in either a correct (1) or wrong (0) detection for each trial. Thus, for each tested envelope extraction method, a binary detection result vector q of length 2304 (16 subjects \u00d7 144 trials per subject = 2304 total trials) is obtained.\n\nThese can either be used as an input for a statistical test (see Section V-C), or averaged to obtain the method's so-called \"detection accuracy\", which is used as the main performance parameter.\n\n\nC. Permutation Test\n\nTo evaluate whether a method a performed significantly better than method b, permutation tests were used [32]. The test statistic S was calculated as the sum of the differences between the binary result vectors of both methods:\nq (a\u2212b) = q a \u2212 q b , S = j q (a\u2212b) ( j ),\nwhere j is the vector entry index. Note that a large positive value of the test statistic S implies that method a is more accurate than method b, whereas a large negative value implies the opposite. A value of S that is close to zero implies that both methods perform similarly. To test for statistical significance, the test statistic S was then compared to its estimated cumulative density function (CDF) under the null hypothesis of no difference between the methods. This CDF was estimated by repeatedly (n = 100 000) randomly permuting each of the 16 subjects' results among the two methods, and re-evaluating the test statistic.\n\nWe hypothesize, based on the preliminary results in our conference precursor 3 [1], that \"p-law sub\" is the best-performing method and therefore compare its performance pair-wise with every other method. To account for the multiple comparisons, an adjustment to the individual rejection criteria is made using the Holm-Bonferroni method [33].\n\n\nVI. RESULTS\n\nIn the sequel, we assume a uniform subband weighting when referring to \"subband\" methods, unless explicitly stated  otherwise (a comparison with other weighting methods is reported later). Fig. 2 shows the subject-specific (circles) and mean (bars) AAD accuracy for the different envelope extraction methods. The exact (experiment-wide) values, along with the p-values resulting from a comparison with the \"plaw sub\" method as discussed in Section V-C are also shown in Table I. An asterisk \"*\" in the last column indicates statistical significance at \u03b1 = 0.05 significance level. Even after a Holm-Bonferroni correction, \"p-law sub\" performs significantly better than all other methods, although \"log sub\" and \"abs sub\", two other simple subband methods, come close in performance. Another interesting result is that in our current paradigm, the complex models (\"Yang\", \"Meddis\", and \"Zilany\") yielded no improvement over the more basic envelope extraction methods.\n\nAs we noted before, \"abs\", \"p-law\" and \"square\" are all power law variants with different values of the exponent \u03b2. Instead of limiting the analysis to just these a priori chosen instances, we also varied \u03b2 between 0.1 and 2 for both a broadband and subband approach. Fig. 3 depicts the result, showing the evolution of the average AAD accuracy as a function of the power law exponent \u03b2. From this figure it can be seen that indeed a choice for \u03b2 of lower than 1 seems appropriate. The optimum in the figure is rather broad and  achieved for the subband approach with values for \u03b2 between 0.2 and 0.8. Another important observation here is that for most values of \u03b2, except for suboptimally high instances (like \u03b2 = 2 in the square law), the subband method clearly outperforms the broadband method. This was also the case when using a logarithmic compression (see Table I). It can therefore be concluded that dividing the speech signal in its subband components before extracting envelopes is an important factor for improving AAD performance.\n\nThe bimodal AAD procedures were applied using all basic envelope extraction methods. To provide an example, Fig. 4 shows the weights that were given to each subband envelope (p-law subbands) for each of the 16 subjects using \"CCA\" (left), and the corresponding subband signal power fractions, obtained by multiplying the weights and the power fraction of the respective subband (right). The figure shows that weights are consistent across subjects and that the subband envelopes corresponding to the lowest frequencies contribute most to the eventual envelope.\n\nOf both bimodal procedures, \"CCA\" yielded a detection accuracy equal to 81.2%, compared to 79.3% for \"bimodal LS\" when applied to p-law subbands. However, this difference in performance was found not to be statistically significant (pvalue 0.191). The same holds for two of the three other basic envelope methods, where \"CCA\" only yields significantly better performance compared to \"bimodal LS\" when applied to log envelopes (p-values: abs 0.375, log 0.018 * , square 0.250). The performance of the \"CCA\" approach was, however, found to be significantly better when applied to the p-law envelopes as compared to the log envelopes (p-value 0.034).\n\nThe performance of all the considered subband weighting methods (CCA, bimodal LS and band importance weighting) were also compared to a uniform (all-ones) weighting. The results are shown in Table II, where an asterisk \"*\" in the last column indicates statistical significance at \u03b1 = 0.05 significance level. Uniform weighting was found to be either not significantly different or significantly better than the nonuniform methods.\n\nFinally, we present performance of the best-performing envelope method (\"p-law sub\") for different trial lengths. Detection accuracy on trials of 60 seconds was equal to 87.5%. This is comparable to results mentioned in literature [5], [7], especially when considering that our experiment and subsequently our decoders were more general, spanning multiple presentation modes (switching attended ear as well as switching acoustic conditions for each subject). For a more general picture, Fig. 5 shows the evolution of the AAD accuracy for the different subband envelope extraction methods (with broadband methods omitted for clarity of the figure) as a function of the trial length (20,30,40 and 60 seconds were evaluated).\n\n\nVII. DISCUSSION\n\n\nA. Implications for Application in Auditory Prostheses\n\nComputational efficiency is an important factor that should be kept in mind when designing an AAD algorithm for future neuro-steered APs. As can be seen from Fig. 2 and Table I, a simple auditory model based on a power law in combination with a gamma tone filterbank yields better results than more complex auditory models (\"Yang\",\"Meddis\", and \"Zilany\"). This is good news, as this shows that it is possible to have a good AAD performance without the methods being computationally taxing on the implementation. Similarly, we also observe that the same advantage holds for using equal weights to recombine subband envelopes in comparison to the more computationally complex \"CCA\" or \"bimodal LS\" approach. Indeed, from Table II, we see that nonuniform weighting shows no significant improvement over uniform weighting, even when the weights are optimized with CCA or bimodal LS. Therefore, for the sake of computational complexity, uniform weighting is preferred in real applications.\n\n\nB. Future Steps Towards Neuro-Steered Auditory Prostheses\n\nIn this paper, we have investigated how auditory models influence AAD performance, showing that the tradeoff between complexity and performance is not crucial and does not lead to strong dilemmas. However, there are other complexity-versus-performance tradeoffs when considering AAD for neuro-steered APs that still need to be explored, such as the choice of number of EEG channels, number of time lags, and trial length. A long trial length reduces the variance on the correlation estimates and hence improves AAD accuracy (see Fig. 5), but also reduces the time resolution in the AAD decision. The effect of reducing the number of channels has been investigated in [7]. There is also a need to look into the effect of the acoustic environment such as reverberation and background noise, the potential to improve accuracy when training the subjects, and the effects of closed-loop feedback. Another important consideration towards the design of neurosteered APs is the extraction of speech envelopes from the speech mixtures recorded with the APs' local microphones. Multiplicative non-negative independent component analysis (M-NICA) [34] has been shown to extract speech envelopes at a low computational cost to support an AAD-assisted noise reduction algorithm [35]. Other techniques such as adaptive beamforming can also be used for unmixing speech signals, keeping in mind the limitations on computational cost, constraints on acceptable latencies, etc. Finally, it is noted that the demixing process that extracts the individual speech envelopes will never work perfectly and will inevitably result in some residual noise and cross-talk in the demixed envelopes. In [18], the effect of noisy envelopes on AAD performance was investigated, and it was found that, to some extent, decoding performance is robust to noisy reference signals.\n\n\nVIII. CONCLUSION\n\nAAD has the potential to take AP technology a step forward, by allowing enhancement of the actual attended speaker, while adapting to the acoustic scenario and shifting auditory attention. We have proposed an \"all-at-once\" methodology for training the decoder, in which we solve a single LS problem over the entire data set, rather than averaging over a multitude of per-trial LS solutions as in the existing literature on AAD. We have shown that this may result in better AAD performance, while also reducing the sensitivity with respect to a regularization parameter. The main goal of this paper was to investigate whether AAD performance could be improved by adding some auditory-inspired modifications to the envelope extraction process. We have shown that performing the envelope extraction on subband signals rather than the broadband audio signal, mimicking the physiology of the auditory periphery, and adding a nonlinear power law amplitude compression significantly improved AAD performance. Furthermore, we have shown that using complex models of the auditory periphery did not yield as good results as the simpler proposed methods. We have shown that using a mathematically optimal subband envelope weight vector, based on bimodal LS and CCA optimization methods, did not outperform the heuristic choice of equal weights for our specific dataset.\n\n\nAPPENDIX COMPARISON OF DECODER TRAINING METHODS\n\nIn Section II-C, two approaches for training the decoders were discussed. In the first approach, preliminary decoders were trained on the data of each single trial, and later averaged, necessitating one of two possible regularization strategies [5], [7], [16], [17]. The second approach, which minimizes a sum of LS objective functions, calculates decoders directly, based on a concatenation of the data from all but one trial. Fig. 6 shows the performance of both these approaches, denoted as (1) and (2) respectively, on trials with a length of 30 seconds (the same trials as described in Section V). For both regularization strategies (minimum norm and smoothness regularization), the performance evolution is shown as a function of the regularization parameter \u03bb. Note that the regularization parameter \u03bb is a relative one, scaled by the mean diagonal entry z of the EEG autocorrelation matrix R [see (10)], ensuring it to be independent of an irrelevant scaling of the data. The performance for no regularization (\u03bb = 0) is not explicitly shown in the figure, but is the same as for the negligible \u03bb = 10 \u22125 in the case of method (2).\n\nThe optimal value of \u03bb for the first approach can be read from the figure to be \u03bb = 0.01, corresponding to an AAD accuracy of 80.2% when using minimum norm regularization. As performance decreases significantly for larger and smaller values of \u03bb, optimal tuning of this regularization parameter \u03bb is key. This poses a problem, as a \u03bb that is optimal for a specific dataset is not guaranteed to be optimal for another dataset. For the second approach however, the figure shows that any non-negligible regularization decreases its AAD accuracy. Regularization is therefore to be avoided with this approach, yielding an AAD accuracy of 81.5%.\n\nOverall, the figure shows that concatenating measurements (2) rather than averaging decoders from single trials (1) yields higher AAD accuracy, with the additional benefit of not needing any regularization to boost performance. Comparing the AAD binary detection results for the optimal regularization settings for both approaches (as defined previously) using a permutation test (see Section V-C), yields a p-value equal to 0.022, indicating indeed a statistically significant difference between the two approaches. From this we conclude that optimizing the sum of LS errors objective function is to be preferred over the averaging of single-trial LS solutions.\n\nFig. 1 .\n1Fig. 1. Frequency response of the gammatone filterbank used to decompose the audio into frequency subbands.\n\nFig. 2 .\n2Mean (bars) and individual subject (circles) detection accuracies for each of the different envelope extraction methods for a trial length of 30 s. The dotted black line at 57% indicates the subject-specific detection accuracy which is only 5% likely to be surpassed by chance, based on a binomial distribution (success rate = 0.5, number of trials = 144).\n\nFig. 3 .\n3Performance of the broadband and subband powerlaw envelope extraction method for different values of the exponent \u03b2.\n\nFig. 4 .\n4Normalized subband weights (left), obtained using \"CCA\", and the relative signal power contribution of each subband to the eventual envelope (right). Each line represents results for a different subject.\n\nFig. 5 .\n5Evolution of AAD accuracy as a function of trial length for the different subband envelope extraction methods.\n\nFig. 6 .\n6Performance of the two training approaches and two regularization strategies, as detailed in Section II-C, for different values of the regularization parameter \u03bb.\n\nTABLE I RESULTS\nIFOR DIFFERENT ENVELOPE EXTRACTION METHODS\n\nTABLE II RESULTS\nIIFOR DIFFERENT SUBBAND WEIGHTING METHODS\nWe note that the necessity of regularization depends on two factors: the number of (independent) samples available to the LS problem (amount of training data), and the number of elements of the decoder (# unknowns). Thus, to avoid having to use regularization, our approach is to keep the sample rate and the number of time lags N l as low as possible, while providing a maximal number of samples for training.\nNote that \"abs\" and \"square\" are effectively also power law methods with exponents chosen as, respectively, 1 and 2.\nIt should be noted that[1] was based on a different set of measurements, independent of the measurements used in this manuscript.\nACKNOWLEDGMENTThe authors would like to thank A. Prokopiou for his help in preparing the speech models, J. Vanthornhout for his help in setting up the experiment, and M. Hofmann for his suggestions regarding the statistical testing procedure. We would also like to thank all test subjects for their participation in the experiment. The scientific responsibility is assumed by its authors. A conference precursor of this manuscript has been published in[1].He was a Visiting Researcher at UCLA, Imec-NL Eindhoven, and UC Berkeley. Since 2014, he has been an Assistant Professor in the Department of Electrical Engineering (ESAT), KU Leuven. His research involves signal processing algorithm design for high-density sensor arrays with a focus on biomedical applications.\nComparison of speech envelope extraction methods for EEG-based auditory attention detection in a cocktail party scenario. W Biesmans, J Vanthornhout, J Wouters, M Moonen, T Francart, A Bertrand, Proc. 37th Annu. Int. IEEE Conf. Eng. in Medicine and Biology Soc. (EMBC). 37th Annu. Int. IEEE Conf. Eng. in Medicine and Biology Soc. (EMBC)W. Biesmans, J. Vanthornhout, J. Wouters, M. Moonen, T. Francart, and A. Bertrand, \"Comparison of speech envelope extraction methods for EEG-based auditory attention detection in a cocktail party scenario,\" in Proc. 37th Annu. Int. IEEE Conf. Eng. in Medicine and Biology Soc. (EMBC), 2015.\n\nSome experiments on the recognition of speech, with one and with two ears. E C Cherry, J. Acoustical Soc. Amer. 255E. C. Cherry, \"Some experiments on the recognition of speech, with one and with two ears,\" J. Acoustical Soc. Amer., vol. 25, no. 5, pp. 975-979, 1953.\n\nSelective cortical representation of attended speaker in multi-talker speech perception. N Mesgarani, E F Chang, Nature. 4857397N. Mesgarani and E. F. Chang, \"Selective cortical representation of attended speaker in multi-talker speech perception,\" Nature, vol. 485, no. 7397, pp. 233-236, 2012.\n\nMechanisms underlying selective neuronal tracking of attended speech at a cocktail party. E M Z Golumbic, Neuron. 775E. M. Z. Golumbic et al., \"Mechanisms underlying selective neuronal tracking of attended speech at a cocktail party,\" Neuron, vol. 77, no. 5, pp. 980-991, 2013.\n\nAttentional selection in a cocktail party environment can be decoded from single-trial EEG. J A O&apos;sullivan, A J Power, N Mesgarani, S Rajaram, J J Foxe, B G Shinn-Cunningham, M Slaney, S A Shamma, E C Lalor, Cerebral Cortex. 257J. A. O'Sullivan, A. J. Power, N. Mesgarani, S. Rajaram, J. J. Foxe, B. G. Shinn-Cunningham, M. Slaney, S. A. Shamma, and E. C. Lalor, \"Attentional selection in a cocktail party environment can be decoded from single-trial EEG,\" Cerebral Cortex, vol. 25, no. 7, pp. 1697-1706, 2015.\n\nEmergence of neural encoding of auditory objects while listening to competing speakers. N Ding, J Z Simon, Proc. Nat. Acad. Sci. 10929N. Ding and J. Z. Simon, \"Emergence of neural encoding of auditory objects while listening to competing speakers,\" Proc. Nat. Acad. Sci., vol. 109, no. 29, pp. 11854-11859, 2012.\n\nDecoding the attended speech stream with multi-channel EEG: implications for online, daily-life applications. B Mirkovic, S Debener, M Jaeger, M. De Vos, J. Neural Eng. 12446007B. Mirkovic, S. Debener, M. Jaeger, and M. De Vos, \"Decoding the attended speech stream with multi-channel EEG: implications for online, daily-life applications,\" J. Neural Eng., vol. 12, no. 4, p. 046007, 2015.\n\nEnvelope responses in single-trial EEG indicate attended speaker in a cocktail party. C Horton, R Srinivasan, M D&apos;zmura, J. Neural Eng. 11446015C. Horton, R. Srinivasan, and M. D'Zmura, \"Envelope responses in single-trial EEG indicate attended speaker in a cocktail party,\" J. Neural Eng., vol. 11, no. 4, p. 046015, 2014.\n\nWearable EEG: What is it, why is it needed and what does it entail?. A Casson, S Smith, J Duncan, E Rodriguez-Villegas, Proc. EMBC. EMBCA. Casson, S. Smith, J. Duncan, and E. Rodriguez-Villegas, \"Wearable EEG: What is it, why is it needed and what does it entail?,\" in Proc. EMBC, 2008, pp. 5867-5870.\n\nThe in-the-ear recording concept: User-centered and wearable brain monitoring. D Looney, P Kidmose, C Park, M Ungstrup, M Rank, K Rosenkranz, D Mandic, Pulse. 3D. Looney, P. Kidmose, C. Park, M. Ungstrup, M. Rank, K. Rosenkranz, and D. Mandic, \"The in-the-ear recording concept: User-centered and wearable brain monitoring,\" Pulse, vol. 3, pp. 32-42, Nov. 2012.\n\nAn in-the-ear platform for recording electroencephalogram. D Looney, C Park, P Kidmose, M Rank, M Ungstrup, K Rosenkranz, D Mandic, Proc. EMBC. EMBCD. Looney, C. Park, P. Kidmose, M. Rank, M. Ungstrup, K. Rosenkranz, and D. Mandic, \"An in-the-ear platform for recording electroencephalo- gram,\" in Proc. EMBC, Aug. 2011, pp. 6882-6885.\n\nExploring miniaturized EEG electrodes for brain-computer interfaces. An EEG you do not see?. M G Bleichner, M Lundbeck, M Selisky, F Minow, M J\u00e4ger, R Emkes, S Debener, M. De Vos, Physiological Rep. 3M. G. Bleichner, M. Lundbeck, M. Selisky, F. Minow, M. J\u00e4ger, R. Emkes, S. Debener, and M. De Vos, \"Exploring miniaturized EEG electrodes for brain-computer interfaces. An EEG you do not see?,\" Physiological Rep., vol. 3, Apr. 2015.\n\nDistributed signal processing for wireless EEG sensor networks. A Bertrand, IEEE Trans. Neural Syst. Rehabil. 236A. Bertrand, \"Distributed signal processing for wireless EEG sensor net- works,\" IEEE Trans. Neural Syst. Rehabil., vol. 23, no. 6, pp. 923-935, Nov. 2015.\n\nUnobtrusive ambulatory EEG using a smartphone and flexible printed electrodes around the ear. S Debener, R Emkes, M De Vos, M Bleichner, Scientific Rep. 5S. Debener, R. Emkes, M. De Vos, and M. Bleichner, \"Unobtrusive ambulatory EEG using a smartphone and flexible printed electrodes around the ear,\" Scientific Rep., vol. 5, 2015.\n\nRobust decoding of selective auditory attention from MEG in a competing-speaker environment via state-space modeling. S Akram, A Presacco, J Z Simon, S A Shamma, B Babadi, NeuroImage. 124S. Akram, A. Presacco, J. Z. Simon, S. A. Shamma, and B. Babadi, \"Robust decoding of selective auditory attention from MEG in a competing-speaker environment via state-space modeling,\" NeuroImage, vol. 124, pp. 906-917, 2016.\n\nInvestigating the temporal dynamics of auditory cortical activation to silent lipreading. M J Crosse, H A Elshafei, J J Foxe, E C Lalor, Proc. IEEE/EMBS Int. Conf. on Neural Eng. IEEE/EMBS Int. Conf. on Neural EngM. J. Crosse, H. A. ElShafei, J. J. Foxe, and E. C. Lalor, \"Investigating the temporal dynamics of auditory cortical activation to silent lipread- ing,\" in Proc. IEEE/EMBS Int. Conf. on Neural Eng., 2015.\n\nDecoding of attentional selection in a cocktail party environment from single-trial EEG is robust to task. T Lauteslager, Proc. 36th Annu. Int. Conf. IEEE Eng. 36th Annu. Int. Conf. IEEE EngT. Lauteslager et al., \"Decoding of attentional selection in a cocktail party environment from single-trial EEG is robust to task,\" in Proc. 36th Annu. Int. Conf. IEEE Eng. in Medicine and Biology Soc. (EMBC), 2014, pp. 1318-1321.\n\nAuditory attention decoding with EEG recordings using noisy reference signals. A Aroudi, B Mirkovic, M De Vos, S Doclo, Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing (ICASSP). IEEE Int. Conf. Acoustics, Speech and Signal essing (ICASSP)A. Aroudi, B. Mirkovic, M. De Vos, and S. Doclo, \"Auditory attention decoding with EEG recordings using noisy reference signals,\" in Proc. IEEE Int. Conf. Acoustics, Speech and Signal Processing (ICASSP), 2016.\n\nThe measurement of loudness. S S Stevens, J. Acoustical Soc. Amer. 275S. S. Stevens, \"The measurement of loudness,\" J. Acoustical Soc. Amer., vol. 27, no. 5, pp. 815-829, 1955.\n\nHuman cortical responses to the speech envelope. S J Aiken, T W Picton, Ear and Hearing. 292S. J. Aiken and T. W. Picton, \"Human cortical responses to the speech envelope,\" Ear and Hearing, vol. 29, no. 2, pp. 139-157, 2008.\n\nTime-domain modeling of peripheral auditory processing: A modular architecture and a software platform. R D Patterson, M H Allerhand, C Giguere, J. Acoustical Soc. Amer. 984R. D. Patterson, M. H. Allerhand, and C. Giguere, \"Time-domain modeling of peripheral auditory processing: A modular architecture and a software platform,\" J. Acoustical Soc. Amer., vol. 98, no. 4, pp. 1890-1894, 1995.\n\nThe auditory modeling toolbox. P Sondergaard, P Majdak, The Technology of Binaural Listening. Berlin, GermanySpringerP. Sondergaard and P. Majdak, \"The auditory modeling toolbox,\" in The Technology of Binaural Listening, J. Blauert Ed. Berlin, Germany: Springer, 2013, pp. 33-56.\n\nAmerican National Standard Methods for Calculation of the Speech Intelligibility Index. A S , Tech. Rep., Acoust. Soc. America. A. S.3.5-1997, American National Standard Methods for Calculation of the Speech Intelligibility Index, Tech. Rep., Acoust. Soc. America 1997.\n\nAuditory representations of acoustic signals. X Yang, K Wang, S A Shamma, IEEE Trans. Inform. Theory. 382X. Yang, K. Wang, and S. A. Shamma, \"Auditory representations of acoustic signals,\" IEEE Trans. Inform. Theory, vol. 38, no. 2, pp. 824-839, Feb. 1992.\n\nA phenomenological model of the synapse between the inner hair cell and auditory nerve: long-term adaptation with power-law dynamics. M S Zilany, I C Bruce, P C Nelson, L H Carney, J. Acoustical Soc. Amer. 1265M. S. Zilany, I. C. Bruce, P. C. Nelson, and L. H. Carney, \"A phenomeno- logical model of the synapse between the inner hair cell and auditory nerve: long-term adaptation with power-law dynamics,\" J. Acoustical Soc. Amer., vol. 126, no. 5, pp. 2390-2412, 2009.\n\nA computer model of the auditory periphery and its application to the study of hearing. R Meddis, W Lecluyse, N R Clark, T J\u00fcrgens, C M Tan, M R Panda, G J Brown, Basic Aspects of Hearing. Berlin, GermanySpringerR. Meddis, W. Lecluyse, N. R. Clark, T. J\u00fcrgens, C. M. Tan, M. R. Panda, and G. J. Brown, \"A computer model of the auditory periphery and its application to the study of hearing,\" in Basic Aspects of Hearing. Berlin, Germany: Springer, 2013, pp. 11-20.\n\nThe spiral ganglion and the innervation of the human organ of corti. H Spoendlin, A Schrott, Acta Oto-Laryngologica. 1055-6H. Spoendlin and A. Schrott, \"The spiral ganglion and the innervation of the human organ of corti,\" Acta Oto-Laryngologica, vol. 105, no. 5-6, pp. 403-410, 1988.\n\nA cochlear frequency-position function for several species: 29 years later. D D Greenwood, J. Acoustical Soc. Amer. 876D. D. Greenwood, \"A cochlear frequency-position function for several species: 29 years later,\" J. Acoustical Soc. Amer., vol. 87, no. 6, pp. 2592-2605, 1990.\n\nRelations between two sets of variates. H Hotelling, Biometrika. H. Hotelling, \"Relations between two sets of variates,\" Biometrika, pp. 321-377, 1936.\n\nOn the equivalence between canonical correlation analysis and orthonormalized partial least squares. L Sun, S Ji, S Yu, J Ye, IJCAI. 9L. Sun, S. Ji, S. Yu, and J. Ye, \"On the equivalence between canonical correlation analysis and orthonormalized partial least squares,\" in IJCAI, 2009, vol. 9, pp. 1230-1235.\n\n. Radioboeken Voor Kinderen, DeBuren. Radioboeken Voor Kinderen, DeBuren, 2007, [Online]. Available: http://www.radioboeken.eu/kinderradioboeken.php?lang=NL\n\nSignificance tests which may be applied to samples from any populations. E J G Pitman, Suppl. J. Roy. Statistical Soc. 41E. J. G. Pitman, \"Significance tests which may be applied to samples from any populations,\" Suppl. J. Roy. Statistical Soc., vol. 4, no. 1, pp. 119-130, 1937.\n\nA simple sequentially rejective multiple test procedure. S Holm, Scandinavian J. Statist. S. Holm, \"A simple sequentially rejective multiple test procedure,\" Scandinavian J. Statist., pp. 65-70, 1979.\n\nBlind separation of non-negative source signals using multiplicative updates and subspace projection. A Bertrand, M Moonen, Signal Processing. 9010A. Bertrand and M. Moonen, \"Blind separation of non-negative source signals using multiplicative updates and subspace projection,\" Signal Processing, vol. 90, no. 10, pp. 2877-2890, 2010.\n\nEEG-informed attended speaker extraction from recorded speech mixtures with application in neuro-steered hearing prostheses. S Van Eyndhoven, T Francart, A Bertrand, IEEE Trans. Biomed. Eng. to be publishedS. Van Eyndhoven, T. Francart, and A. Bertrand, \"EEG-informed attended speaker extraction from recorded speech mixtures with appli- cation in neuro-steered hearing prostheses,\" IEEE Trans. Biomed. Eng., to be published.\n", "annotations": {"author": "[{\"end\":161,\"start\":145},{\"end\":204,\"start\":162},{\"end\":218,\"start\":205},{\"end\":250,\"start\":219}]", "publisher": null, "author_last_name": "[{\"end\":160,\"start\":152},{\"end\":172,\"start\":169},{\"end\":217,\"start\":209},{\"end\":249,\"start\":241}]", "author_first_name": "[{\"end\":151,\"start\":145},{\"end\":168,\"start\":162},{\"end\":208,\"start\":205},{\"end\":240,\"start\":231}]", "author_affiliation": null, "title": "[{\"end\":134,\"start\":1},{\"end\":384,\"start\":251}]", "venue": "[{\"end\":452,\"start\":386}]", "abstract": "[{\"end\":2474,\"start\":1148}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2718,\"start\":2715},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2831,\"start\":2828},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3316,\"start\":3313},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3321,\"start\":3318},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3893,\"start\":3890},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3927,\"start\":3924},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3939,\"start\":3936},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3944,\"start\":3941},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3949,\"start\":3946},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4232,\"start\":4229},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4238,\"start\":4234},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4335,\"start\":4332},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4478,\"start\":4474},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4952,\"start\":4949},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4957,\"start\":4954},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5051,\"start\":5048},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5456,\"start\":5453},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5631,\"start\":5628},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":5637,\"start\":5633},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5643,\"start\":5639},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7479,\"start\":7476},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8646,\"start\":8643},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11059,\"start\":11056},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11064,\"start\":11061},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11971,\"start\":11968},{\"end\":12253,\"start\":12250},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":12347,\"start\":12344},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13360,\"start\":13357},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":15175,\"start\":15172},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":15180,\"start\":15177},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15186,\"start\":15182},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":15192,\"start\":15188},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":15551,\"start\":15548},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":15556,\"start\":15553},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":15746,\"start\":15743},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":15751,\"start\":15748},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15757,\"start\":15753},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":15763,\"start\":15759},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16000,\"start\":15997},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":18053,\"start\":18050},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":18331,\"start\":18327},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":19229,\"start\":19226},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":22898,\"start\":22894},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":22930,\"start\":22926},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":23977,\"start\":23973},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23983,\"start\":23979},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":25228,\"start\":25224},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":26196,\"start\":26192},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26202,\"start\":26198},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":26233,\"start\":26229},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26951,\"start\":26947},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":27607,\"start\":27603},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":28298,\"start\":28294},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28304,\"start\":28300},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":28488,\"start\":28485},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":30000,\"start\":29997},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30344,\"start\":30340},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31478,\"start\":31474},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":33795,\"start\":33791},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":38690,\"start\":38686},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":39570,\"start\":39567},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":39829,\"start\":39825},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":43736,\"start\":43733},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":43741,\"start\":43738},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":44187,\"start\":44183},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":44190,\"start\":44187},{\"end\":44192,\"start\":44190},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":46017,\"start\":46014},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":46487,\"start\":46483},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":46616,\"start\":46612},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":47024,\"start\":47020},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":48869,\"start\":48866},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":48874,\"start\":48871},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":48880,\"start\":48876},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":48886,\"start\":48882},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":49530,\"start\":49526},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":49759,\"start\":49756},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":52866,\"start\":52863}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":51184,\"start\":51066},{\"attributes\":{\"id\":\"fig_1\"},\"end\":51552,\"start\":51185},{\"attributes\":{\"id\":\"fig_2\"},\"end\":51680,\"start\":51553},{\"attributes\":{\"id\":\"fig_3\"},\"end\":51895,\"start\":51681},{\"attributes\":{\"id\":\"fig_4\"},\"end\":52017,\"start\":51896},{\"attributes\":{\"id\":\"fig_5\"},\"end\":52191,\"start\":52018},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":52251,\"start\":52192},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":52311,\"start\":52252}]", "paragraph": "[{\"end\":4239,\"start\":2493},{\"end\":5398,\"start\":4241},{\"end\":6117,\"start\":5400},{\"end\":7133,\"start\":6119},{\"end\":7843,\"start\":7135},{\"end\":8396,\"start\":7845},{\"end\":8699,\"start\":8398},{\"end\":9582,\"start\":8701},{\"end\":9730,\"start\":9619},{\"end\":10621,\"start\":9755},{\"end\":11295,\"start\":10623},{\"end\":11387,\"start\":11297},{\"end\":12087,\"start\":11438},{\"end\":12536,\"start\":12112},{\"end\":12637,\"start\":12636},{\"end\":12642,\"start\":12639},{\"end\":12815,\"start\":12644},{\"end\":12968,\"start\":12931},{\"end\":13604,\"start\":12991},{\"end\":13836,\"start\":13606},{\"end\":14059,\"start\":13881},{\"end\":14349,\"start\":14075},{\"end\":14961,\"start\":14351},{\"end\":15318,\"start\":14963},{\"end\":16223,\"start\":15367},{\"end\":16323,\"start\":16225},{\"end\":16758,\"start\":16360},{\"end\":17063,\"start\":16857},{\"end\":17630,\"start\":17065},{\"end\":17758,\"start\":17632},{\"end\":19013,\"start\":17866},{\"end\":19890,\"start\":19038},{\"end\":20725,\"start\":19927},{\"end\":21138,\"start\":20758},{\"end\":21433,\"start\":21140},{\"end\":21853,\"start\":21452},{\"end\":22190,\"start\":21855},{\"end\":22565,\"start\":22218},{\"end\":23113,\"start\":22567},{\"end\":23701,\"start\":23115},{\"end\":24628,\"start\":23726},{\"end\":25672,\"start\":24630},{\"end\":26067,\"start\":25674},{\"end\":26203,\"start\":26090},{\"end\":26918,\"start\":26205},{\"end\":27565,\"start\":26920},{\"end\":27874,\"start\":27567},{\"end\":28359,\"start\":27876},{\"end\":28892,\"start\":28376},{\"end\":29480,\"start\":28922},{\"end\":30175,\"start\":29482},{\"end\":30607,\"start\":30263},{\"end\":30795,\"start\":30690},{\"end\":31035,\"start\":30868},{\"end\":31479,\"start\":31037},{\"end\":31595,\"start\":31481},{\"end\":31822,\"start\":31667},{\"end\":32491,\"start\":31876},{\"end\":32679,\"start\":32522},{\"end\":32936,\"start\":32681},{\"end\":33230,\"start\":32938},{\"end\":36471,\"start\":33232},{\"end\":36949,\"start\":36494},{\"end\":37556,\"start\":36951},{\"end\":38361,\"start\":37558},{\"end\":38557,\"start\":38363},{\"end\":38808,\"start\":38581},{\"end\":39486,\"start\":38852},{\"end\":39830,\"start\":39488},{\"end\":40812,\"start\":39846},{\"end\":41857,\"start\":40814},{\"end\":42419,\"start\":41859},{\"end\":43068,\"start\":42421},{\"end\":43500,\"start\":43070},{\"end\":44224,\"start\":43502},{\"end\":45285,\"start\":44301},{\"end\":47190,\"start\":45347},{\"end\":48569,\"start\":47211},{\"end\":49760,\"start\":48621},{\"end\":50401,\"start\":49762},{\"end\":51065,\"start\":50403}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11437,\"start\":11388},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12635,\"start\":12537},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12930,\"start\":12816},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12990,\"start\":12969},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13880,\"start\":13837},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15366,\"start\":15319},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16359,\"start\":16324},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16856,\"start\":16759},{\"attributes\":{\"id\":\"formula_8\"},\"end\":17865,\"start\":17759},{\"attributes\":{\"id\":\"formula_9\"},\"end\":21451,\"start\":21434},{\"attributes\":{\"id\":\"formula_10\"},\"end\":30262,\"start\":30176},{\"attributes\":{\"id\":\"formula_11\"},\"end\":30648,\"start\":30608},{\"attributes\":{\"id\":\"formula_12\"},\"end\":30689,\"start\":30648},{\"attributes\":{\"id\":\"formula_13\"},\"end\":30867,\"start\":30796},{\"attributes\":{\"id\":\"formula_14\"},\"end\":31666,\"start\":31596},{\"attributes\":{\"id\":\"formula_15\"},\"end\":31875,\"start\":31823},{\"attributes\":{\"id\":\"formula_16\"},\"end\":38851,\"start\":38809}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":40323,\"start\":40316},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":41685,\"start\":41678},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":43269,\"start\":43261},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":44477,\"start\":44470},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":45028,\"start\":45020}]", "section_header": "[{\"end\":2491,\"start\":2476},{\"end\":9617,\"start\":9585},{\"end\":9753,\"start\":9733},{\"end\":12110,\"start\":12090},{\"end\":14073,\"start\":14062},{\"end\":19036,\"start\":19016},{\"end\":19925,\"start\":19893},{\"end\":20756,\"start\":20728},{\"end\":22216,\"start\":22193},{\"end\":23724,\"start\":23704},{\"end\":26088,\"start\":26070},{\"end\":28374,\"start\":28362},{\"end\":28920,\"start\":28895},{\"end\":32520,\"start\":32494},{\"end\":36492,\"start\":36474},{\"end\":38579,\"start\":38560},{\"end\":39844,\"start\":39833},{\"end\":44242,\"start\":44227},{\"end\":44299,\"start\":44245},{\"end\":45345,\"start\":45288},{\"end\":47209,\"start\":47193},{\"end\":48619,\"start\":48572},{\"end\":51075,\"start\":51067},{\"end\":51194,\"start\":51186},{\"end\":51562,\"start\":51554},{\"end\":51690,\"start\":51682},{\"end\":51905,\"start\":51897},{\"end\":52027,\"start\":52019},{\"end\":52208,\"start\":52193},{\"end\":52269,\"start\":52253}]", "table": null, "figure_caption": "[{\"end\":51184,\"start\":51077},{\"end\":51552,\"start\":51196},{\"end\":51680,\"start\":51564},{\"end\":51895,\"start\":51692},{\"end\":52017,\"start\":51907},{\"end\":52191,\"start\":52029},{\"end\":52251,\"start\":52210},{\"end\":52311,\"start\":52272}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":24304,\"start\":24298},{\"end\":30710,\"start\":30704},{\"end\":30794,\"start\":30788},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":40041,\"start\":40035},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":41088,\"start\":41082},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":41973,\"start\":41967},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":43995,\"start\":43989},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":44465,\"start\":44459},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":45882,\"start\":45876},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":49055,\"start\":49049}]", "bib_author_first_name": "[{\"end\":53862,\"start\":53861},{\"end\":53874,\"start\":53873},{\"end\":53890,\"start\":53889},{\"end\":53901,\"start\":53900},{\"end\":53911,\"start\":53910},{\"end\":53923,\"start\":53922},{\"end\":54444,\"start\":54443},{\"end\":54446,\"start\":54445},{\"end\":54726,\"start\":54725},{\"end\":54739,\"start\":54738},{\"end\":54741,\"start\":54740},{\"end\":55024,\"start\":55023},{\"end\":55028,\"start\":55025},{\"end\":55305,\"start\":55304},{\"end\":55307,\"start\":55306},{\"end\":55326,\"start\":55325},{\"end\":55328,\"start\":55327},{\"end\":55337,\"start\":55336},{\"end\":55350,\"start\":55349},{\"end\":55361,\"start\":55360},{\"end\":55363,\"start\":55362},{\"end\":55371,\"start\":55370},{\"end\":55373,\"start\":55372},{\"end\":55393,\"start\":55392},{\"end\":55403,\"start\":55402},{\"end\":55405,\"start\":55404},{\"end\":55415,\"start\":55414},{\"end\":55417,\"start\":55416},{\"end\":55818,\"start\":55817},{\"end\":55826,\"start\":55825},{\"end\":55828,\"start\":55827},{\"end\":56154,\"start\":56153},{\"end\":56166,\"start\":56165},{\"end\":56177,\"start\":56176},{\"end\":56191,\"start\":56186},{\"end\":56520,\"start\":56519},{\"end\":56530,\"start\":56529},{\"end\":56544,\"start\":56543},{\"end\":56832,\"start\":56831},{\"end\":56842,\"start\":56841},{\"end\":56851,\"start\":56850},{\"end\":56861,\"start\":56860},{\"end\":57145,\"start\":57144},{\"end\":57155,\"start\":57154},{\"end\":57166,\"start\":57165},{\"end\":57174,\"start\":57173},{\"end\":57186,\"start\":57185},{\"end\":57194,\"start\":57193},{\"end\":57208,\"start\":57207},{\"end\":57488,\"start\":57487},{\"end\":57498,\"start\":57497},{\"end\":57506,\"start\":57505},{\"end\":57517,\"start\":57516},{\"end\":57525,\"start\":57524},{\"end\":57537,\"start\":57536},{\"end\":57551,\"start\":57550},{\"end\":57859,\"start\":57858},{\"end\":57861,\"start\":57860},{\"end\":57874,\"start\":57873},{\"end\":57886,\"start\":57885},{\"end\":57897,\"start\":57896},{\"end\":57906,\"start\":57905},{\"end\":57915,\"start\":57914},{\"end\":57924,\"start\":57923},{\"end\":57939,\"start\":57934},{\"end\":58264,\"start\":58263},{\"end\":58564,\"start\":58563},{\"end\":58575,\"start\":58574},{\"end\":58584,\"start\":58583},{\"end\":58587,\"start\":58585},{\"end\":58594,\"start\":58593},{\"end\":58921,\"start\":58920},{\"end\":58930,\"start\":58929},{\"end\":58942,\"start\":58941},{\"end\":58944,\"start\":58943},{\"end\":58953,\"start\":58952},{\"end\":58955,\"start\":58954},{\"end\":58965,\"start\":58964},{\"end\":59307,\"start\":59306},{\"end\":59309,\"start\":59308},{\"end\":59319,\"start\":59318},{\"end\":59321,\"start\":59320},{\"end\":59333,\"start\":59332},{\"end\":59335,\"start\":59334},{\"end\":59343,\"start\":59342},{\"end\":59345,\"start\":59344},{\"end\":59743,\"start\":59742},{\"end\":60137,\"start\":60136},{\"end\":60147,\"start\":60146},{\"end\":60159,\"start\":60158},{\"end\":60162,\"start\":60160},{\"end\":60169,\"start\":60168},{\"end\":60551,\"start\":60550},{\"end\":60553,\"start\":60552},{\"end\":60749,\"start\":60748},{\"end\":60751,\"start\":60750},{\"end\":60760,\"start\":60759},{\"end\":60762,\"start\":60761},{\"end\":61030,\"start\":61029},{\"end\":61032,\"start\":61031},{\"end\":61045,\"start\":61044},{\"end\":61047,\"start\":61046},{\"end\":61060,\"start\":61059},{\"end\":61350,\"start\":61349},{\"end\":61365,\"start\":61364},{\"end\":61688,\"start\":61687},{\"end\":61690,\"start\":61689},{\"end\":61917,\"start\":61916},{\"end\":61925,\"start\":61924},{\"end\":61933,\"start\":61932},{\"end\":61935,\"start\":61934},{\"end\":62263,\"start\":62262},{\"end\":62265,\"start\":62264},{\"end\":62275,\"start\":62274},{\"end\":62277,\"start\":62276},{\"end\":62286,\"start\":62285},{\"end\":62288,\"start\":62287},{\"end\":62298,\"start\":62297},{\"end\":62300,\"start\":62299},{\"end\":62689,\"start\":62688},{\"end\":62699,\"start\":62698},{\"end\":62711,\"start\":62710},{\"end\":62713,\"start\":62712},{\"end\":62722,\"start\":62721},{\"end\":62733,\"start\":62732},{\"end\":62735,\"start\":62734},{\"end\":62742,\"start\":62741},{\"end\":62744,\"start\":62743},{\"end\":62753,\"start\":62752},{\"end\":62755,\"start\":62754},{\"end\":63136,\"start\":63135},{\"end\":63149,\"start\":63148},{\"end\":63429,\"start\":63428},{\"end\":63431,\"start\":63430},{\"end\":63671,\"start\":63670},{\"end\":63885,\"start\":63884},{\"end\":63892,\"start\":63891},{\"end\":63898,\"start\":63897},{\"end\":63904,\"start\":63903},{\"end\":64106,\"start\":64095},{\"end\":64325,\"start\":64324},{\"end\":64329,\"start\":64326},{\"end\":64590,\"start\":64589},{\"end\":64837,\"start\":64836},{\"end\":64849,\"start\":64848},{\"end\":65196,\"start\":65195},{\"end\":65213,\"start\":65212},{\"end\":65225,\"start\":65224}]", "bib_author_last_name": "[{\"end\":53871,\"start\":53863},{\"end\":53887,\"start\":53875},{\"end\":53898,\"start\":53891},{\"end\":53908,\"start\":53902},{\"end\":53920,\"start\":53912},{\"end\":53932,\"start\":53924},{\"end\":54453,\"start\":54447},{\"end\":54736,\"start\":54727},{\"end\":54747,\"start\":54742},{\"end\":55037,\"start\":55029},{\"end\":55323,\"start\":55308},{\"end\":55334,\"start\":55329},{\"end\":55347,\"start\":55338},{\"end\":55358,\"start\":55351},{\"end\":55368,\"start\":55364},{\"end\":55390,\"start\":55374},{\"end\":55400,\"start\":55394},{\"end\":55412,\"start\":55406},{\"end\":55423,\"start\":55418},{\"end\":55823,\"start\":55819},{\"end\":55834,\"start\":55829},{\"end\":56163,\"start\":56155},{\"end\":56174,\"start\":56167},{\"end\":56184,\"start\":56178},{\"end\":56195,\"start\":56192},{\"end\":56527,\"start\":56521},{\"end\":56541,\"start\":56531},{\"end\":56557,\"start\":56545},{\"end\":56839,\"start\":56833},{\"end\":56848,\"start\":56843},{\"end\":56858,\"start\":56852},{\"end\":56880,\"start\":56862},{\"end\":57152,\"start\":57146},{\"end\":57163,\"start\":57156},{\"end\":57171,\"start\":57167},{\"end\":57183,\"start\":57175},{\"end\":57191,\"start\":57187},{\"end\":57205,\"start\":57195},{\"end\":57215,\"start\":57209},{\"end\":57495,\"start\":57489},{\"end\":57503,\"start\":57499},{\"end\":57514,\"start\":57507},{\"end\":57522,\"start\":57518},{\"end\":57534,\"start\":57526},{\"end\":57548,\"start\":57538},{\"end\":57558,\"start\":57552},{\"end\":57871,\"start\":57862},{\"end\":57883,\"start\":57875},{\"end\":57894,\"start\":57887},{\"end\":57903,\"start\":57898},{\"end\":57912,\"start\":57907},{\"end\":57921,\"start\":57916},{\"end\":57932,\"start\":57925},{\"end\":57943,\"start\":57940},{\"end\":58273,\"start\":58265},{\"end\":58572,\"start\":58565},{\"end\":58581,\"start\":58576},{\"end\":58591,\"start\":58588},{\"end\":58604,\"start\":58595},{\"end\":58927,\"start\":58922},{\"end\":58939,\"start\":58931},{\"end\":58950,\"start\":58945},{\"end\":58962,\"start\":58956},{\"end\":58972,\"start\":58966},{\"end\":59316,\"start\":59310},{\"end\":59330,\"start\":59322},{\"end\":59340,\"start\":59336},{\"end\":59351,\"start\":59346},{\"end\":59755,\"start\":59744},{\"end\":60144,\"start\":60138},{\"end\":60156,\"start\":60148},{\"end\":60166,\"start\":60163},{\"end\":60175,\"start\":60170},{\"end\":60561,\"start\":60554},{\"end\":60757,\"start\":60752},{\"end\":60769,\"start\":60763},{\"end\":61042,\"start\":61033},{\"end\":61057,\"start\":61048},{\"end\":61068,\"start\":61061},{\"end\":61362,\"start\":61351},{\"end\":61372,\"start\":61366},{\"end\":61922,\"start\":61918},{\"end\":61930,\"start\":61926},{\"end\":61942,\"start\":61936},{\"end\":62272,\"start\":62266},{\"end\":62283,\"start\":62278},{\"end\":62295,\"start\":62289},{\"end\":62307,\"start\":62301},{\"end\":62696,\"start\":62690},{\"end\":62708,\"start\":62700},{\"end\":62719,\"start\":62714},{\"end\":62730,\"start\":62723},{\"end\":62739,\"start\":62736},{\"end\":62750,\"start\":62745},{\"end\":62761,\"start\":62756},{\"end\":63146,\"start\":63137},{\"end\":63157,\"start\":63150},{\"end\":63441,\"start\":63432},{\"end\":63681,\"start\":63672},{\"end\":63889,\"start\":63886},{\"end\":63895,\"start\":63893},{\"end\":63901,\"start\":63899},{\"end\":63907,\"start\":63905},{\"end\":64120,\"start\":64107},{\"end\":64336,\"start\":64330},{\"end\":64595,\"start\":64591},{\"end\":64846,\"start\":64838},{\"end\":64856,\"start\":64850},{\"end\":65210,\"start\":65197},{\"end\":65222,\"start\":65214},{\"end\":65234,\"start\":65226}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":20671864},\"end\":54366,\"start\":53739},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":16308483},\"end\":54634,\"start\":54368},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":4320045},\"end\":54931,\"start\":54636},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":12700766},\"end\":55210,\"start\":54933},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":2934551},\"end\":55727,\"start\":55212},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15570759},\"end\":56041,\"start\":55729},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":22076362},\"end\":56431,\"start\":56043},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":6940411},\"end\":56760,\"start\":56433},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":19640885},\"end\":57063,\"start\":56762},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":14103460},\"end\":57426,\"start\":57065},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":206887861},\"end\":57763,\"start\":57428},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":9822879},\"end\":58197,\"start\":57765},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":13206504},\"end\":58467,\"start\":58199},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":8667640},\"end\":58800,\"start\":58469},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":14106822},\"end\":59214,\"start\":58802},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":44807515},\"end\":59633,\"start\":59216},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":21926817},\"end\":60055,\"start\":59635},{\"attributes\":{\"id\":\"b17\"},\"end\":60519,\"start\":60057},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":28844555},\"end\":60697,\"start\":60521},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":43037341},\"end\":60923,\"start\":60699},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":36486383},\"end\":61316,\"start\":60925},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":59630439},\"end\":61597,\"start\":61318},{\"attributes\":{\"id\":\"b22\"},\"end\":61868,\"start\":61599},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":206392091},\"end\":62126,\"start\":61870},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":7178782},\"end\":62598,\"start\":62128},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":5628786},\"end\":63064,\"start\":62600},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":40259878},\"end\":63350,\"start\":63066},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":34883486},\"end\":63628,\"start\":63352},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":122166830},\"end\":63781,\"start\":63630},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":117613981},\"end\":64091,\"start\":63783},{\"attributes\":{\"id\":\"b30\"},\"end\":64249,\"start\":64093},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":125115385},\"end\":64530,\"start\":64251},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":122415379},\"end\":64732,\"start\":64532},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":18235529},\"end\":65068,\"start\":64734},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3206129},\"end\":65495,\"start\":65070}]", "bib_title": "[{\"end\":53859,\"start\":53739},{\"end\":54441,\"start\":54368},{\"end\":54723,\"start\":54636},{\"end\":55021,\"start\":54933},{\"end\":55302,\"start\":55212},{\"end\":55815,\"start\":55729},{\"end\":56151,\"start\":56043},{\"end\":56517,\"start\":56433},{\"end\":56829,\"start\":56762},{\"end\":57142,\"start\":57065},{\"end\":57485,\"start\":57428},{\"end\":57856,\"start\":57765},{\"end\":58261,\"start\":58199},{\"end\":58561,\"start\":58469},{\"end\":58918,\"start\":58802},{\"end\":59304,\"start\":59216},{\"end\":59740,\"start\":59635},{\"end\":60134,\"start\":60057},{\"end\":60548,\"start\":60521},{\"end\":60746,\"start\":60699},{\"end\":61027,\"start\":60925},{\"end\":61347,\"start\":61318},{\"end\":61685,\"start\":61599},{\"end\":61914,\"start\":61870},{\"end\":62260,\"start\":62128},{\"end\":62686,\"start\":62600},{\"end\":63133,\"start\":63066},{\"end\":63426,\"start\":63352},{\"end\":63668,\"start\":63630},{\"end\":63882,\"start\":63783},{\"end\":64322,\"start\":64251},{\"end\":64587,\"start\":64532},{\"end\":64834,\"start\":64734},{\"end\":65193,\"start\":65070}]", "bib_author": "[{\"end\":53873,\"start\":53861},{\"end\":53889,\"start\":53873},{\"end\":53900,\"start\":53889},{\"end\":53910,\"start\":53900},{\"end\":53922,\"start\":53910},{\"end\":53934,\"start\":53922},{\"end\":54455,\"start\":54443},{\"end\":54738,\"start\":54725},{\"end\":54749,\"start\":54738},{\"end\":55039,\"start\":55023},{\"end\":55325,\"start\":55304},{\"end\":55336,\"start\":55325},{\"end\":55349,\"start\":55336},{\"end\":55360,\"start\":55349},{\"end\":55370,\"start\":55360},{\"end\":55392,\"start\":55370},{\"end\":55402,\"start\":55392},{\"end\":55414,\"start\":55402},{\"end\":55425,\"start\":55414},{\"end\":55825,\"start\":55817},{\"end\":55836,\"start\":55825},{\"end\":56165,\"start\":56153},{\"end\":56176,\"start\":56165},{\"end\":56186,\"start\":56176},{\"end\":56197,\"start\":56186},{\"end\":56529,\"start\":56519},{\"end\":56543,\"start\":56529},{\"end\":56559,\"start\":56543},{\"end\":56841,\"start\":56831},{\"end\":56850,\"start\":56841},{\"end\":56860,\"start\":56850},{\"end\":56882,\"start\":56860},{\"end\":57154,\"start\":57144},{\"end\":57165,\"start\":57154},{\"end\":57173,\"start\":57165},{\"end\":57185,\"start\":57173},{\"end\":57193,\"start\":57185},{\"end\":57207,\"start\":57193},{\"end\":57217,\"start\":57207},{\"end\":57497,\"start\":57487},{\"end\":57505,\"start\":57497},{\"end\":57516,\"start\":57505},{\"end\":57524,\"start\":57516},{\"end\":57536,\"start\":57524},{\"end\":57550,\"start\":57536},{\"end\":57560,\"start\":57550},{\"end\":57873,\"start\":57858},{\"end\":57885,\"start\":57873},{\"end\":57896,\"start\":57885},{\"end\":57905,\"start\":57896},{\"end\":57914,\"start\":57905},{\"end\":57923,\"start\":57914},{\"end\":57934,\"start\":57923},{\"end\":57945,\"start\":57934},{\"end\":58275,\"start\":58263},{\"end\":58574,\"start\":58563},{\"end\":58583,\"start\":58574},{\"end\":58593,\"start\":58583},{\"end\":58606,\"start\":58593},{\"end\":58929,\"start\":58920},{\"end\":58941,\"start\":58929},{\"end\":58952,\"start\":58941},{\"end\":58964,\"start\":58952},{\"end\":58974,\"start\":58964},{\"end\":59318,\"start\":59306},{\"end\":59332,\"start\":59318},{\"end\":59342,\"start\":59332},{\"end\":59353,\"start\":59342},{\"end\":59757,\"start\":59742},{\"end\":60146,\"start\":60136},{\"end\":60158,\"start\":60146},{\"end\":60168,\"start\":60158},{\"end\":60177,\"start\":60168},{\"end\":60563,\"start\":60550},{\"end\":60759,\"start\":60748},{\"end\":60771,\"start\":60759},{\"end\":61044,\"start\":61029},{\"end\":61059,\"start\":61044},{\"end\":61070,\"start\":61059},{\"end\":61364,\"start\":61349},{\"end\":61374,\"start\":61364},{\"end\":61693,\"start\":61687},{\"end\":61924,\"start\":61916},{\"end\":61932,\"start\":61924},{\"end\":61944,\"start\":61932},{\"end\":62274,\"start\":62262},{\"end\":62285,\"start\":62274},{\"end\":62297,\"start\":62285},{\"end\":62309,\"start\":62297},{\"end\":62698,\"start\":62688},{\"end\":62710,\"start\":62698},{\"end\":62721,\"start\":62710},{\"end\":62732,\"start\":62721},{\"end\":62741,\"start\":62732},{\"end\":62752,\"start\":62741},{\"end\":62763,\"start\":62752},{\"end\":63148,\"start\":63135},{\"end\":63159,\"start\":63148},{\"end\":63443,\"start\":63428},{\"end\":63683,\"start\":63670},{\"end\":63891,\"start\":63884},{\"end\":63897,\"start\":63891},{\"end\":63903,\"start\":63897},{\"end\":63909,\"start\":63903},{\"end\":64122,\"start\":64095},{\"end\":64338,\"start\":64324},{\"end\":64597,\"start\":64589},{\"end\":64848,\"start\":64836},{\"end\":64858,\"start\":64848},{\"end\":65212,\"start\":65195},{\"end\":65224,\"start\":65212},{\"end\":65236,\"start\":65224}]", "bib_venue": "[{\"end\":54007,\"start\":53934},{\"end\":54478,\"start\":54455},{\"end\":54755,\"start\":54749},{\"end\":55045,\"start\":55039},{\"end\":55440,\"start\":55425},{\"end\":55856,\"start\":55836},{\"end\":56210,\"start\":56197},{\"end\":56572,\"start\":56559},{\"end\":56892,\"start\":56882},{\"end\":57222,\"start\":57217},{\"end\":57570,\"start\":57560},{\"end\":57962,\"start\":57945},{\"end\":58307,\"start\":58275},{\"end\":58620,\"start\":58606},{\"end\":58984,\"start\":58974},{\"end\":59393,\"start\":59353},{\"end\":59793,\"start\":59757},{\"end\":60247,\"start\":60177},{\"end\":60586,\"start\":60563},{\"end\":60786,\"start\":60771},{\"end\":61093,\"start\":61070},{\"end\":61410,\"start\":61374},{\"end\":61725,\"start\":61693},{\"end\":61970,\"start\":61944},{\"end\":62332,\"start\":62309},{\"end\":62787,\"start\":62763},{\"end\":63181,\"start\":63159},{\"end\":63466,\"start\":63443},{\"end\":63693,\"start\":63683},{\"end\":63914,\"start\":63909},{\"end\":64129,\"start\":64122},{\"end\":64368,\"start\":64338},{\"end\":64620,\"start\":64597},{\"end\":64875,\"start\":64858},{\"end\":65259,\"start\":65236},{\"end\":54076,\"start\":54009},{\"end\":56898,\"start\":56894},{\"end\":57576,\"start\":57572},{\"end\":59429,\"start\":59395},{\"end\":59825,\"start\":59795},{\"end\":60309,\"start\":60249},{\"end\":61427,\"start\":61412},{\"end\":62804,\"start\":62789}]"}}}, "year": 2023, "month": 12, "day": 17}