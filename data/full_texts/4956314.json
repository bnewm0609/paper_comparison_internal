{"id": 4956314, "updated": "2023-10-03 10:01:24.727", "metadata": {"title": "The Limits and Potentials of Deep Learning for Robotics", "authors": "[{\"first\":\"Niko\",\"last\":\"Sunderhauf\",\"middle\":[]},{\"first\":\"Oliver\",\"last\":\"Brock\",\"middle\":[]},{\"first\":\"Walter\",\"last\":\"Scheirer\",\"middle\":[]},{\"first\":\"Raia\",\"last\":\"Hadsell\",\"middle\":[]},{\"first\":\"Dieter\",\"last\":\"Fox\",\"middle\":[]},{\"first\":\"Jurgen\",\"last\":\"Leitner\",\"middle\":[]},{\"first\":\"Ben\",\"last\":\"Upcroft\",\"middle\":[]},{\"first\":\"Pieter\",\"last\":\"Abbeel\",\"middle\":[]},{\"first\":\"Wolfram\",\"last\":\"Burgard\",\"middle\":[]},{\"first\":\"Michael\",\"last\":\"Milford\",\"middle\":[]},{\"first\":\"Peter\",\"last\":\"Corke\",\"middle\":[]}]", "venue": null, "journal": "The International Journal of Robotics Research", "publication_date": {"year": 2018, "month": 4, "day": 18}, "abstract": "The application of deep learning in robotics leads to very specific problems and research questions that are typically not addressed by the computer vision and machine learning communities. In this paper we discuss a number of robotics-specific learning, reasoning, and embodiment challenges for deep learning. We explain the need for better evaluation metrics, highlight the importance and unique challenges for deep robotic learning in simulation, and explore the spectrum between purely data-driven and model-driven approaches. We hope this paper provides a motivating overview of important research directions to overcome the current limitations, and help fulfill the promising potentials of deep learning in robotics.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1804.06557", "mag": "2964248288", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/ijrr/SunderhaufBSHFL18", "doi": "10.1177/0278364918770733"}}, "content": {"source": {"pdf_hash": "643fb5aeccce0351cac89bb8e446c8d7e48a3d99", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1804.06557v1.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://journals.sagepub.com/doi/pdf/10.1177/0278364918770733", "status": "BRONZE"}}, "grobid": {"id": "dcd5038359faa6e1da35d62a11fc51664588fd7a", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/643fb5aeccce0351cac89bb8e446c8d7e48a3d99.txt", "contents": "\nThe Limits and Potentials of Deep Learning for Robotics\n\n\nNiko S\u00fcnderhauf \nOliver Brock \nWalter Scheirer \nRaia Hadsell \nDieter Fox \nJ\u00fcrgen Leitner \nBen Upcroft \nPieter Abbeel \nWolfram Burgard \nMichael Milford \nPeter Corke \nThe Limits and Potentials of Deep Learning for Robotics\n\nThe application of deep learning in robotics leads to very specific problems and research questions that are typically not addressed by the computer vision and machine learning communities. In this paper we discuss a number of robotics-specific learning, reasoning, and embodiment challenges for deep learning. We explain the need for better evaluation metrics, highlight the importance and unique challenges for deep robotic learning in simulation, and explore the spectrum between purely data-driven and model-driven approaches. We hope this paper provides a motivating overview of important research directions to overcome the current limitations, and help fulfill the promising potentials of deep learning in robotics.\n\nI. INTRODUCTION\n\nA robot is an inherently active agent that interacts with the real world, and often operates in uncontrolled or detrimental conditions. Robots have to perceive, decide, plan, and execute actions -all based on incomplete and uncertain knowledge. Mistakes can lead to potentially catastrophic results that will not only endanger the success of the robot's mission, but can even put human lives at stake, e.g. if the robot is a driverless car.\n\nThe application of deep learning in robotics therefore motivates research questions that differ from those typically addressed in computer vision: How much trust can we put in the predictions of a deep learning system when misclassifications can have catastrophic consequences? How can we estimate the uncertainty in a deep network's predictions and how can we fuse these predictions with prior knowledge and other sensors in a probabilistic framework? How well does deep learning perform in realistic unconstrained openset scenarios where objects of unknown class and appearance are regularly encountered?\n\nIf we want to use data-driven learning approaches to generate motor commands for robots to move and act in the world, we are faced with additional challenging questions: How can we generate enough high-quality training data? Do we rely on data solely collected on robots in realworld scenarios or do we require data augmentation through simulation? How can we ensure the learned policies transfer well to different situations, from simulation to reality, or between different robots?\n\nThis leads to further fundamental questions: How can the structure, the constraints, and the physical laws that govern robotic tasks in the real world be leveraged and exploited by a deep learning system? Is there a fundamental difference between model-driven and data-driven problem solving, or are these rather two ends of a spectrum?\n\nThis paper explores some of the challenges, limits, and potentials for deep learning in robotics. The invited speakers and organizers of the workshop on The Limits and Potentials of Deep Learning for Robotics at the 2016 edition of the Robotics: Science and Systems (RSS) conference [113] provide their thoughts and opinions, and point out open research problems and questions that are yet to be answered. We hope this paper will offer the interested reader an overview of where we believe important research needs to be done, and where deep learning can have an even bigger impact in robotics over the coming years.\n\n\nII. CHALLENGES FOR DEEP LEARNING IN ROBOTIC VISION\n\nA robot is an inherently active agent that acts in, and interacts with the physical real world. It perceives the world with its different sensors, builds a coherent model of the world and updates this model over time, but ultimately a robot has to make decisions, plan actions, and execute these actions to fulfill a useful task. This is where robotic vision differs from computer vision. For robotic vision, perception is only one part of a more complex, embodied, active, and goal-driven system. Robotic vision therefore has to take into account that its immediate outputs (object detection, segmentation, depth estimates, 3D reconstruction, a description of the scene, and so on), will ultimately result in actions in the real world. In a simplified view, while computer vision takes images and translates them into information, robotic vision translates images into actions.\n\nThis fundamental difference between robotic vision and computer vision motivates a number of research challenges along three conceptually orthogonal axes: learning, embodiment, and reasoning. We position individual challenges along these axes according to their increasing complexity, and their dependencies. Tables I-III summarize \n\n\nA. Learning Challenges\n\nAlong this axis we position challenges that are specific for (deep) machine learning in a robotic vision context. These challenges comprise problems arising from deployment in open-set conditions, two flavours of incremental learning, and active learning.\n\n1) Uncertainty Estimation: In order to fully integrate deep learning into robotics, it is important that deep learning systems can reliably estimate the uncertainty in their predictions. This would allow robots to treat a deep neural network like any other sensor, and use the established Bayesian techniques [53], [58], [117] to fuse the network's predictions with prior knowledge or other sensor measurements, or to accumulate information over time. Deep learning systems, e.g. for classification or detection, typically return scores from their softmax layers that are proportional to the system's confidence, but are not calibrated probabilities, and therefore not useable in a Bayesian sensor fusion framework.\n\nCurrent approaches towards uncertainty estimation for deep learning are calibration techniques [38], [44], or Bayesian deep learning [72], [78] with approximations such as Dropout Sampling [28], [54] or ensemble methods [61].\n\n2) Identify Unknowns: A common assumption in deep learning is that trained models will be deployed under closedset conditions [11], [120], i.e. the classes encountered during deployment are known and exactly the same as during training. However, robots often have to operate in everchanging, uncontrolled real-world environments, and will inevitably encounter instances of classes, scenarios, textures, or environmental conditions that were not covered by the training data.\n\nIn these so called open-set conditions [11], [101], it is crucial to identify the unknowns: The perception system must not assign high-confidence scores to unknown objects or falsely recognize them as one of the known classes. If for example an object detection system is fooled by data outside of its training data distribution [35], [79], the consequences for a robot acting on false, but high-confidence detections can be catastrophic. One way to handle the open-set problem and identify unknowns is to utilize the epistemic uncertainty [28], [54] of the model predictions to reject predictions with low confidence [76].\n\n3) Incremental Learning: For many robotics applications the characteristics and appearance of objects can be quite different in the deployment scenario compared to the training data. To address this domain adaptation problem [23], [30], [83], a robotic vision system should be able to learn from new training samples of known classes during deployment and adopt its internal representations accordingly.\n\n\n4) Class-Incremental Learning:\n\nWhen operating in openset conditions, the deployment scenario might contain new classes of interest that were not available during training. A robot therefore needs the capability to extend its knowledge and efficiently learn new classes without forgetting the previously learned representations [34]. This class-incremental learning would preferably be data-efficient by using oneshot [13], [60], [92], [99], [124] or low-shot [27], [41], [126] learning techniques. Semi-supervised approaches [56], [82], [89] that can leverage unlabeled data are of particular interest.\n\nCurrent techniques for class-incremental learning [75], [90] still rely on supervision in the sense that the user has to specifically tell the system which samples are new data and therefore should be incorporated. The next challenge in our list, active learning, aims to overcome this and automatically selects new training samples from the available data. 5) Active Learning: A robot should be able to select the most informative samples for incremental learning techniques on its own. Since it would have to ask the human user for the true label for these selected samples, data-efficiency is key to minimize this kind of interaction with the user. Active learning [21] can also comprise retrieving annotations from other sources such as the web. Some current approaches [24], [29] leverage the uncertainty estimation techniques based on approximate Bayesian inference (see Section II-A.1) to choose the most informative samples.\n\n\nB. Embodiment Challenges\n\nEmbodiment is a corner stone of what constitutes robotic vision, and what sets it apart from computer vision. Along this axis we describe four embodiment challenges: understanding and utilizing temporal and spatial embodiment helps to improve perception, but also enables robotic vision to perform active vision, and even targeted manipulation of the environment to further improve perception.\n\n1) Temporal Embodiment: In contrast to typical recent computer vision systems that treat every image as independent, a robotic vision system perceives a stream of consecutive and therefore strongly correlated images. While current work on action recognition, learning from demonstration, and similar directions in computer vision work on video data, (e.g. by using recurrent neural networks or by simply stacking consecutive frames in the input layers), the The system is able to select the most informative samples for incremental learning on its own in a data-efficient way, e.g. by utilizing its estimated uncertainty in a prediction. It can ask the user to provide labels. 4\n\nClass-Incremental Learning\n\nThe system can learn new classes, preferably using low-shot or one-shot learning techniques, without catstrophic forgetting. The system requires the user to provide these new training samples along with correct class labels. 3 Incremental Learning\n\nThe system can learn off new instances of known classes to address domain adaptation or label shift. It requires the user to select these new training samples.\n\n\nIdentify Unknowns\n\nIn an open-set scenario, the robot can reliably identify instances of unknown classes and is not fooled by out-of distribution data. 1 Uncertainty Estimation\n\nThe system can correctly estimate its uncertainty and returns calibrated confidence scores that can be used as probabilities in a Bayesian data fusion framework. Current work on Bayesian Deep Learning falls into this category. 0\n\nClosed-Set Assumptions\n\nThe system can detect and classify objects of classes known during training. It provides uncalibrated confidence scores that are proportional to the system's belief of the label probabilities. State of the art methods, such as YOLO9000, SSD, Mask R-CNN are at this level. The system has learned to actively control the camera movements in the world, for example it can move the camera to a better viewpoint to improve its perception confidence or better deal with occlusions. 2 Spatial Embodiment\n\nThe system can exploit aspects of spatial coherency and incorporate views of objects taken from different viewpoints to improve its perception, while handling occlusions. 1 Temporal Embodiment\n\nThe system learned that it is temporally embedded and consecutive are strongly correlated. The system can accumulate evidence over time to improve its predictions. Appearance changes over time can be coped with. 0\n\nNone\n\nThe system has no understanding of any form of embodiment and treats every image as an independent from previously seen images.\n\npotential of temporal embodiment to improve the quality of the perception process for object detection or semantic segmentation, is currently rarely utilized: a robotic vision system that uses its temporal embodiment can for example accumulate evidence over time -preferably using Bayesian techniques, if uncertainty estimates are available as discussed in Section II-A.1 -or exploit small viewpoint variations that occur over time in dynamic scenes.\n\nThe new CORe50 dataset [69] is one of the few available datasets that encourages researchers to exploit temporal embodiment for object recognition, but the robotic vision research community should invest more effort to fully exploit the potentials of temporal embodiment.\n\nA challenging aspect of temporal embodiment is that the appearance of scenes changes over time. An environment can comprise dynamic objects such as cars or pedestrians moving through the field of view of a camera. An environment can also change its appearance caused by different lighting conditions (day/night), structural changes in objects (summer/winter), or differences in the presence and pose of objects (e.g. an office during and after work hours). A robotic vision system has to cope with all of those effects.\n\n2) Spatial Embodiment: In robotic vision, the camera that observes the world is part of a bigger robotic system that acts and moves in the world -the camera is spatially embodied. As the robot moves in its environment, the camera will observe the scene from different viewpoints, which poses both challenges and opportunities to a robotic vision system: Observing an object from different viewpoints can help to disambiguate its semantic properties, improve depth perception, or segregate an object from other objects or the background in cluttered scenes. On the other hand, occlusions and the resulting sudden appearance changes complicate visual perception and require capabilities such as object unity and object permanence [85] that are known to develop in the human visual system [33].\n\n3) Active Vision: One of the biggest advantages robotic vision can draw from its embodiment is the potential to control the camera, move it, and change its viewpoint in order to improve its perception or gather additional information about the scene. This is in stark contrast to most computer vision scenarios, where the camera is a passive sensor that observes the environment from where it was placed, without any means of controlling its pose.\n\nSome work is undertaken in the area of next-best viewpoint prediction to improve object detection [5], [25], [73], [130] or path planning for exploration on a mobile robot [14], but a more holistic approach to active scene understanding is still missing from current research. Such an active robotic vision system system could control camera movements through the world to improve the system's perception confidence, resolve ambiguities, mitigate the effect of occlusions, or reflections.\n\n\n4) Manipulation for Perception:\n\nAs an extension of active vision, a robotic system could purposefully manipulate the scene to aid its perception. For example a robot could move occluding objects to gain information about object hidden underneath. Planning such actions will require an understanding of the geometry of the scene, the capability to reason about how certain manipulation actions will change the scene, and if those changes will positively affect the perception processes.\n\n\nC. Reasoning Challenges\n\nIn his influential 1867 book on Physiological Optics [125], Hermann von Helmholtz formulated the idea that humans use unconscious reasoning, inference or conclusion, when processing visual information. Since then, psychologists have devised various experiments to investigate these unconscious mechanisms [33], modernized Helmholtz' original ideas [94], and reformulated them in the framework of Bayesian inference [55].\n\nInspired by their biological counterparts, we formulate the following three reasoning challenges, addressing separate and joint reasoning about the semantics and geometry of a scene and the objects therein.\n\n1) Reasoning About Object and Scene Semantics: The world around us contains many semantic regularities that humans use to aid their perception [33]: objects tend to appear more often in a certain context than in other contexts (e.g. it is more likely to find a fork in a kitchen or on a dining table, but less likely to find it in a bathroom), some objects tend to appear in groups, some objects rarely appear together in a scene, and so on. Semantic regularities also comprise the absolute pose of object in a scene, or the relative pose of an object with respect to other objects.\n\nWhile the importance of semantic regularities and contextual information for human perception processes is well known in psychology [33], [81], current object detection systems [42], [67], [91] do not exploit this rich source of information. If the many semantic regularities present in the real world can be learned or otherwise made available to the vision system in the form of prior knowledge, we can expect an improved and more robust perception performance: Context can help to disambiguate or correct predictions and detections.\n\nThe work by Lin et al. [65] is an example of a scene understanding approach that explicitly models and exploits several semantic and geometric relations between objects and the overall scene using Conditional Random Fields. A combination of place categorization and improved object detection utilizing learned scene-object priors has been demonstrated in [111]. More recent work [136] devises a method to perform holistic scene understanding using a deep neural network that learns to utilize context information from training data.\n\n2) Reasoning About Object and Scene Geometry: Many applications in robotics require knowledge about the geometry of individual objects, or the scene as a whole. Estimating the depth of the scene from a single image has become a widely researched topic [31], [32], [66]. Similarly, there is a lot of ongoing work on estimating the 3D structure of objects from a single or multiple views without having depth information available [20], [40], [131], [137]. These methods are typically evaluated on images with only one or a few prominent and clearly separated objects. However for robotic applications, cluttered scenes are very common.\n\nThe previously discussed problems of uncertainty estimation and coping with unknown objects apply here as well: a robotic vision system that uses the inferred geometry for example to grasp objects needs the ability to express uncertainty in the inferred object shape when planning grasp points. Similarly, it should be able to exploit its embodiment to move the camera to a better viewpoint to efficiently collect new information that enables a more accurate estimate of the object geometry.\n\nAs an extension of reasoning over individual objects, inference over the geometry of the whole scene is important for robotic vision, and closely related to the problems of object-based mapping or object-based SLAM [19], [86], [98], [114]. Exploiting semantic and prior knowledge can help a robotic vision system to better reason about the scene structure, for example the absolute and relative poses of objects, support surfaces, and object continuity despite occlusions.\n\n3) Joint Reasoning about Semantics and Geometry: The ability to extract information about objects, environmental structures, their various complex relations, and the scene geometry in complex environments under realistic, open-set conditions is increasingly important for robotics. Our final reasoning challenge for a robotic vision system therefore is the ability to reason jointly about the semantics and the geometry of a scene and the objects therein. Since semantics and geometry can co-inform each other, a tightly coupled inference approach can be advantageous over loosely coupled approaches where reasoning over semantics and geometry is performed separately.\n\n\nIII. ARE WE GETTING EVALUATION RIGHT IN DEEP LEARNING FOR ROBOTICS?\n\nWhy doesn't real-world deep learning performance match published performance on benchmark datasets? This is a vexing question currently facing roboticists -and the answer has to do with the nature of evaluation in computer vision. Robotics is different from much of computer vision in that a robot must interact with a dynamic environment, not just images or videos downloaded from the Internet. Therefore a successful algorithm must generalize to numerous novel settings, which shifts the emphasis away from a singular focus on computing the best summary statistic (e.g., average accuracy, area under the curve, precision, recall) over a canned dataset. Recent catastrophic failures of autonomous vehicles relying on convolutional neural networks [68] highlight this disconnect: when a summary statistic indicates that a dataset has been solved, it does not necessarily mean that the problem itself has been solved. The consequences of this observation are potentially far reaching if algorithms are deployed without a thorough understanding of their strengths and weaknesses [4]. The system jointly reasons about semantics and geometry in a tighly coupled way, allowing semantics and geometry to co-inform each other. 2 Object and Scene Geometry\n\nThe system learned to reason about the geometry and shape of individual objects, and about the general scene geometry, such as absolute and relative object pose, support surfaces, and object continuity under occlusions and in clutter. 1 Object and Scene Semantics\n\nThe system can exploit prior semantic knowledge to improve its performance. It can utilize priors about which objects are more likely to occur together in a scene, or how objects and overall scene type are correlated. 0\n\nNone\n\nThe system does not perform any sophisticated reasoning, e.g. it treats every detected object as independent from other objects or the overall scene. Estimates of semantics and geometry are treated as independent.\n\nWhile there are numerous flaws lurking in the shadows of deep learning benchmarks [12], [22], [80], [115], two key aspects are worth discussing here: 1) the open set nature of decision making in visual recognition problems related to robotics, and 2) the limitations of traditional dataset evaluation in helping us understand the capabilities of an algorithm. Open Set Recognition refers to scenarios where incomplete knowledge of the world is present at training time, and unknown classes can be submitted to an algorithm during its operation [102]. It is absolutely critical to ask what the dataset isn't capturing before setting a trained model loose to perform in the real world. Moreover, if a claim is made about the human-level (or, as we've been hearing lately, superhuman-level) performance of an algorithm, human behavior across varying conditions should be the frame of reference, not just a comparison of summary statistics on a dataset. This leads us to suggest Visual Psychophysics as a sensible alternative for evaluation.\n\n\nThe Importance of Open Set Recognition\n\nIn an autonomous vehicle setting, one can envision an object detection model trained to recognize other cars, while rejecting trees, signs, telephone poles and any other non-car object in the scene. The challenge in obtaining good performance from this model is in the necessary generalization to all non-car objects -both known and unknown. Instead of casting such a detection task as a binary decision problem like most popular classification strategies would do, it is perhaps more useful to think about it within the context of the following taxonomy [103], inspired by some memorable words spoken by Donald Rumsfeld [95]: These samples are the most problematic for machine learning. Should not the feature space produced by a deep learning method help us out with the unknown classes? After all, the advantage of deep learning is the ability to learn separable feature representations that are strongly invariant to changing scene conditions. The trouble we find is not necessarily with the features themselves, but in the read-out layer used for decision making. Consider the following problems with three popular classifiers used as read-out layers for convolutional neural networks when applied to recognition tasks where unknown classes are present. A linear SVM separates the positive and negative classes by a single linear decision boundary, establishing two half-spaces. These half-spaces are infinite in extent, meaning unknown samples far from the support of known training data can receive a positive label [103]. The Softmax function is a common choice for multi-class classification, but computing it requires calculating a summation over all of the classes. This is not possible when unknown classes are expected at testing time [12]. Along these same lines, when used to make a decision, cosine similarity requires a threshold, which can only be estimated over known data. The difficulty of establishing decision boundaries that capture a large measure of intraclass variance while rejecting unknown classes underpins several well-known deficiencies in deep learning architectures [80], [115].\n\u2022\nIt is readily apparent that we do not understand decision boundary modeling as well as we should. Accordingly, we suggest that researchers give more attention to decision making at an algorithmic level to address the limitations of existing classification mechanisms. What is needed is a new class of machine learning algorithms that minimize the risk of the unknown. Preliminary work exploring this idea has included slab-based linear classifiers to limit the risk of halfspaces [102], nearest non-outlier models [11], and extreme value theory-based calibration of decision boundaries [12], [103], [135]. Much more work is needed in this direction, including algorithms that incorporate the risk of the unknown directly into their learning objectives, and evaluation protocols that incorporate data which is both known and unknown to a model.\n\n\nThe Role Visual Psychophysics Should Play\n\nOne need not resort to tricky manipulations like noise patterns that are imperceptible to humans [115] or carefully evolved images [80] to fool recognition systems based on deep learning. Simple transformations like rotation, scale, and occlusion will do the job just fine. Remarkably, a systematic study of a recognition model's performance across an exhaustive range of object appearances is typically not done during the course of machine learning research. This is a major shortcoming of evaluation within the field. Turning to the study of biological vision systems, psychologists and neuroscientists do perform such tests on humans and animals using a set of concepts and procedures from the discipline of psychophysics. Psychophysics allows scientists to probe the inner mechanisms of visual processing through the controlled manipulation of the characteristics of visual stimuli presented to a subject. The careful management of stimulus construction, ordering and presentation allows a perceptual threshold, the inflection point at which perception transitions from success to failure, to be determined precisely. As in biological vision, we'd like to know under what conditions a machine learning model is able to operate successfully, as well as where it begins to fail. If this is to be done in an exhaustive manner, we need to leverage item response theory [26], which will let us map each stimulus condition to a performance point (e.g., model accuracy). When individual item responses are collected to form a curve, an exemplar-by-exemplar summary of the patterns of error for a model becomes available, allowing us to point exactly to the condition(s) that will lead to failure.\n\nPsychophysics is commonplace in the laboratory, but how exactly can it be applied to models? One possibility is through a computational pipeline that is able to perturb 2D natural images or 3D rendered scenes at a massive scale (e.g., millions of images per image transformation being studied) and submit them to a model, generating an itemresponse curve from the resulting recognition scores [93]. Key to the interpretability of the results is the ability to identify a model's preferred view. Work in vision science has established that humans possess an internalized canonical view (the visual appearance that is easiest to recognize) for individual object classes [15]. Similarly, recognition models have one or more preferred views of an object class, each of which leads to a maximum (or minimum) score output. A preferred view thus forms a natural starting place for model assessment. Through perturbation, the results will at best stay the same, but more likely will degrade as visual appearance moves outside the variance learned from the training dataset. With respect to the stimuli used when performing psychophysics experiments on models, there is a growing trend in robotics and computer vision to make use of simulations rendered via computer graphics. In line with this, we believe that procedurally rendered graphics hold much promise for psychophysics experiments, where the position of objects can be manipulated in 3D, and aspects of the scene, such as lighting and background, changed at will.\n\nInstead of comparing summary statistics related to benchmark dataset performance for different models, relative performance can be assessed by comparing the respective itemresponse curves. Importantly, not only can any gaps between the behaviors of different models be assessed, but also potential gaps between human and model behavior. Validation by this procedure is necessary if a claim is going to made about a model matching (or exceeding) human performance. Summary statistics only reflect one data point over a mixture of scene conditions, which obscures the patterns of error we are often most interested in. Through experimentation, we have found that human performance vastly exceeds model performance even in cases where a problem has been assumed to be solved (e.g., human face detection [100]). While the summary statistics in those cases indicated that both humans and models were at the performance ceiling for the dataset at hand, the item-response curves from psychophysics experiments showed a clear gap between human and model performance. However, psychophysics need not entirely replace datasets. After all, we still need a collection of data from which to train the model, and some indication of performance on a collection of web-scale data is still useful for model screening. Steps should be taken to explore strategies for combining datasets and visual psychophysics to address some of the obvious shortcomings of deep learning.\n\n\nIV. THE ROLE OF SIMULATION FOR PIXEL-TO-ACTION ROBOTICS\n\nRobotics, still dominated by complex processing stacks, could benefit from a similar revolution as seen in computer vision which would clear a path directly from pixels to torques and enable powerful gradient-driven end-to-end optimisation. A critical difference is that robotics constitutes an interactive domain with sequential actions where supervised learning from static datasets is not a solution.\n\nDeep reinforcement learning is a new learning paradigm that is capable of learning end-to-end robotic control tasks, but the accomplishments have been demonstrated primarily in simulation, rather than on actual robot platforms [37], [43], [62], [64], [77], [106], [107]. However, demonstrating learning capabilities on real robots remains the bar by which we must measure the practical applicability of these methods. This poses a significant challenge, given the long, datahungry training paradigm of pixel-based deep RL methods and the relative frailty of research robots and their human handlers.\n\nTo make the challenge more concrete, consider a simple pixel-to-action learning task: reaching to a randomly placed target from a random start location, using a threefingered Jaco robot arm (see Figure 2). Trained in the MuJoCo simulator using Asynchronous Advantage Actor-Critic (A3C) [77], the current state-of-the-art RL algorithm, full performance is only achieved after substantial interaction with the environment, on the order of 50 million steps -a number which is infeasible with a real robot. The simulation training, compared with the real robot, is accelerated because of fast rendering, multi-threaded learning algorithms, and the ability to continuously train without human involvement. We calculate that learning this task, which trains to convergence in 24 hours using a CPU compute cluster, would take 53 days on the real robot even with continuous training for 24 hours a day. Moreover, multiple experiments in parallel were used to explore hyperparameters in simulation; this sort of search would compound further the hypothetical real robot training time. Sample images from the real camera input image (left) and the MuJoCo-rendered image (right), demonstrating the reality gap between simulation and reality even for a simple reaching task.\n\nTaking advantage of the simulation-learnt policies to train real robots is thus critical, but there is a reality gap that often separates a simulated task and its real-world analogue, especially for raw pixel inputs. One solution is to use transfer learning methods to bridge the reality gap that separates simulation from real world domains. There exist many different paradigms for domain transfer and many approaches designed specifically for deep neural models, but substantially fewer approaches for transfer from simulation to reality for robot domains. Even more rare are methods that can be used for transfer in interactive, rich sensor domains using end-to-end (pixel-to-action) learning. A growing body of work has been investigating the ability of deep networks to transfer between domains. Some research [84], [110] considers simply augmenting the target domain data with data from the source domain where an alignment exists. Building on this work, [70] starts from the observation that as one looks at higher layers in the model, the transferability of the features decreases quickly. To correct this effect, a soft constraint is added that enforces the distribution of the features to be more similar. In [70], a 'confusion' loss is proposed which forces the model to ignore variations in the data that separate the two domains [122], [123], and [121] attempts to address the simulation to reality gap by using aligned data. The work is focused on pose estimation of the robotic arm, where training happens on a triple loss that looks at aligned simulation to real data, including the domain confusion loss. The paper does not show the efficiency of the method on learning novel complex policies. Partial success on transferring from simulation to a real robot has been reported [8], [48], [134], [138]. They focus primarily on the problem of transfer from a more restricted simpler version of a task to the full, more difficult version. Another promising recent direction is domain randomization [97], [118].\n\nA recent sim-to-real approach relies on the progressive nets architecture [96], which enables transfer learning through lateral connections which connect each layer of previously learnt deep networks to new networks, thus supporting deep compositionality of features (see Figure 3). Progressive networks are well suited for sim-to-real transfer of policies in robot control domains for multiple reasons. First, features learnt for one task may be transferred to many new tasks without destruction from fine-tuning. Second, the columns may be heterogeneous, which may be important for solving different tasks, including different input modalities, or simply to improve learning speed when transferring to the real robot. Third, progressive nets add new capacity, including new input connections, when transferring to new tasks. This is advantageous for bridging the reality gap, to accommodate dissimilar inputs between simulation and real sensors.\noutput 1 h 2 (1) h 1 (1) output 2 h 2 (2) h 1 (2) output 3 h 2 (3) h 1 (3) input simulation reality a a\nExperiments with the Jaco robot showed that the progressive architecture is valuable for sim-to-real transfer. The progressive second column gets to 34 points, while the experiment with finetuning, which starts with the simulationtrained column and continues training on the robot, does not reach the same score as the progressive network.\n\n\nV. DEEP LEARNING AND PHYSICS-BASED MODELS\n\nThe predominant approach to perception, planning, and control in robotics is to use approximate models of the physics underlying a robot, its sensors, and its interactions with the environment. These model-based techniques often capture properties such as the mass, momentum, shape, and surface friction of objects, and use these to generate controls that change the environment in a desirable way [57], [59], [105], [119]. While physics-based models are well suited for planning and predicting the outcome of actions, to function on a real robot they require that all relevant model parameters are known with sufficient accuracy and can be tracked over time. This requirement poses overly challenging demands on system identification and perception, resulting in systems that are brittle, especially when direct interaction with the environment is required.\n\nHumans, on the other hand, operate under intuitive rather than exact physical models [6], [7], [10], [45], [74], [88]. While these intuitive models have many well-documented deficiencies and inaccuracies, they have the crucial property that they are grounded in real world experience, are well suited for closed-loop control, and can be learned and Recent approaches to end-to-end training of deep networks forgo the use of explicit physics models, learning predictive models and controls from raw experiences [9], [16], [18], [36], [129], [132]. While these early applications of large scale deep learning are just the beginning, they have the potential to provide robots with highly robust perception and control mechanisms, based on an intuitive notion of physics that is fully grounded in a robot's experience. The properties of model-based and deep learned approaches can be measured along multiple dimensions, including the kind of representations used for reasoning, how generally applicable their solutions are, how robust they are in real world settings, how efficiently they make use of data, and how computationally efficient they are during operation. Model-based approaches often rely on explicit models of objects and their shape, surface, and mass properties, and use these to predict and control motion through time. In deep learning, models are typically implicitly encoded via networks and their parameters. As a consequence, modelbased approaches have wide applicability, since the physics underlying them are universal. However, at the same time, the parameters of these models are difficult to estimate from perception, resulting in rather brittle performance operating only in local basins of convergence. Deep learning on the other hand enables highly robust performance when trained on sufficiently large data sets that are representative of the operating regime of the system. However, the implicit models learned by current DL techniques do not have the general applicability of physics-based reasoning. Model-based approaches are significantly more data efficient, related to their smaller number of parameters. The optimizations required for model-based approaches can be performed efficiently, but the basin of convergence can be rather small. In contrast, deep learned solutions are often very fast and can have very large basins of convergence. However, they do not perform well if applied in a regime outside the training data. Table IV summarizes the main properties.\n\nDifferent variants of deep learning have been shown to successfully learn predictive physics models and robot control policies in a purely data driven way [2], [17], [51], [127].\n\nWhile such a learning-based paradigm could potentially inherit the robustness of intuitive physics reasoning, current approaches are nowhere near human prediction and control capabilities. Key challenges toward achieving highly robust, physics-based reasoning and control for robots are: (1) Learn general, predictive models for how the environment evolves and how it reacts to a robots actions. While the first attempts in this direction show promising results, these only capture very specific scenarios and it is not clear how they can be made to scale to general predictive models. (2) Leverage existing physics-based models to learn intuitive models from less data. Several systems approach this problem in promising ways, such as using physics-based models to generate training data for deep learning or developing deep network structures that incorporate insights from physicsbased reasoning. (3) Learn models and controllers at multiple levels of abstractions that can be reused in many contexts. Rather than training new network structures for each task, such an approach would enable robots to fully leverage previously learned knowledge and apply it in new contexts.\n\n\nVI. TOWARDS AN AUTOMATION OF INFORMATICS\n\nDeep learning will change the foundations of computer science. Already, the successes of deep learning in various domains are calling into question the dominant problemsolving paradigm: algorithm design. 1 This can easily be seen in the area of image classification, where deep learning has outperformed all prior attempts of explicitly programming image processing algorithms. And in contrast to most other applications of machine learning that require the careful design of problem-specific features, deep learning approaches require little to no knowledge of the problem domain. Sure, the search for a suitable network architectures and training procedures remains but the amount of domainspecific knowledge required to apply deep learning methods to novel problem domains is substantially lower than for programming a solution explicitly. As a result, the amount of problem-specific expertise required to solve complex problems has reached an all-time low. Whether this is good or bad remains to be seen (it is probably neither and both). But it might seem that deep learning is currently the winner in the competition between \"traditional\" programming and the clever use of large amounts of data.\n\n\nProgramming versus data\n\nSolutions to computational problems lie on a spectrum along which the relative and complementary contributions of programming and data vary. On one end of the spectrum lies traditional computer science: human experts program problem-specific algorithms that require no additional data to solve a particular problem instance, e.g. quicksort. On the other extreme lies deep learning. A generic approach to learning leverages large amounts of data to find a computational solution automatically. In between these two extremes lie algorithms that are less generic than deep learning and less specific than quicksort, including maybe decision trees for example.\n\nIt is helpful to look at the two ends of the spectrum in more detail. The act of programming on one end of the spectrum is replaced by training on the other end. The concept of program is turned into learning weights of the network. And the programming language, i.e. the language in which a solution is expressed, is replaced by network architecture, loss function, training procedure, and data. Please note that the training procedure itself is again seen as a concrete algorithm, on the opposing end of the spectrum. This already alludes to the fact that solutions to challenging problems probably must combine sub-solutions from the entire spectrum spanned by programming and deep learning.\n\nDoes understand imply one end of the spectrum?\n\nFor a programmer to solve a problem through programming, we might say that she has to understand the problem. Computer programs therefore reflect human understanding. We might also say that the further a particular solution is positioned towards the deep-learning-end of the spectrum, the less understanding about the problem it requires. As science strives for understanding, we should ultimately attempt to articulate the structure of our solutions explicitly, relying on as little data as possible for solving a particular problem instance. There are many reasons for pursuing this goal: robustness, transfer, generality, verifiability, re-use, and ultimately insight, which might lead to further progress.\n\nConsider, for example, the problem of tracking the trajectory of a quad-copter. We can certainly come up with a deep learning solution to this problem. But would we not expect the outcome of learning, given an arbitrary amount of data and computational resources, to be some kind of Bayes filter? Either we believe that the Bayes filter captures the computational structure inherent to this problem (recursive state estimation), and then a learned solution eventually has to discover and represent this solution. But at that point we might simply use the algorithm instead of the deep neural network. If, on the other hand, the deep neural network represents something else than a Bayes filter-something outperforming the Bayes filter-then we discovered that Bayes filters do not adequately capture the structure of the problem at hand. And we will naturally be curious as to what the neural network discovered.\n\nFrom this, we should draw three conclusions: First, our quest for understanding implies that we must try to move towards the programming-end of the spectrum, whenever we can. Second, we need to be able to leverage generic tools, such as deep learning, to discover problem structure; this will help us derive novel knowledge and to devise algorithms based on that knowledge. Third, we should understand how problems can be divided into parts: those parts for which we know the structure (and therefore can write algorithms for) and those for which we would like to discover the structure. This will facilitate the component-wise movement towards explicit understanding.\n\n\nGeneric tools might help us identify new structure\n\nWhen we do not know how to program a solution for a problem and instead apply a generic learning method, such as deep learning, and this generic method delivers a solution, then we have implicitly learned something about the problem. It might be difficult to extract this knowledge from a deep neural network but that should simply motivate us to develop methods for extracting this knowledge. Towards this goal, our community should a) report in detail on the limitations of deep networks and b) study in similar detail the dependencies of deep learning solutions on various parameters. This will lead the way to an ability of \"reading\" networks so as to extract algorithmifiable information.\n\nThere have been some recent results about \"distilling\" knowledge from neural networks, indicating that the extraction of problem structure from neural networks might be possible [46]. Such distilled knowledge is still far away from being algorithmifiable, but this line of work seem promising in this regard. The idea of distillation can also be combined with side information [71], further facilitating the identification of relevant problem structure.\n\nOn the other hand, it was shown that our insights about generalization-an important objective for machine learning algorithms-might not transfer easily to neural networks [133]. If it turns out that the deep neural networks we learn today simply memorize training data and then interpolate between them [133], then we must develop novel regularization methods to enforce the extraction of problem structure instead of memorization, possibly through the use of side information [52]. Or, if neural networks are only good for memorization, they are not as powerful as we thought. There might be evidence, however, that neural networks do indeed find good representations, i.e. problem structure.\n\nComplex problems should be solved by decomposition and re-composition In many cases, interesting and complex problems will exhibit complex structure because they are composed of subproblems. For each of these sub-problems, computational solutions are most appropriate that lie on different points along the programming/data-spectrum; this is because we may have more or less understanding of the sub-problem's inherent structure. It would therefore make sense to compose solutions to the original problem from sub-solutions that lie on different points on the programming/data-spectrum [50].\n\nFor many sub-problems, we already have excellent algorithmic solutions, e.g. implementations of quicksort. Sorting is a problem on one end of the spectrum: we understand it and have codified that understanding in an algorithm. But there are many other problems, such as image classification, where human programs are outperformed by deep neural networks. Those problem should be solved by neural networks and then integrated with solutions from other parts of the spectrum.\n\nThis re-composition of component solutions from different places on the spectrum can be achieved with differentiable versions of existing algorithms (one end of the spectrum) that are compatible solutions obtained with back-propagation (other end of the spectrum) [16], [39], [50], [108], [116], [128]. For example, Jonschkowski et al. [50] solve the aforementioned localization problem for quad-copters by combining a histogram filter with back-propagation-learned motion and sensing models.\n\n\nDecomposability of problems\n\nIn the previous section, I argued that complex problems often are decomposable into sub-problems that can be solved independently. A problem is called decomposable or neardecomposable [109] if there is little complexity in the interactions among sub-problems and most of the complexity is handled within those sub-problems. But are all problems decomposable in this manner? For example, Schierwagen argued that the brain is not decomposable [104] because the interactions between its components still contain much of the complexity of the original problem. Furthermore, many interpret results on end-to-end learning of deep visuomotor policies to indicate that modular sub-solutions automatically lead to poor solutions [63]. Of course, a sub-optimal factorization of a problem into sub-problems will lead to suboptimal solutions. However, the results presented by Levine et al. [63] do not lend strong support to this statement. The authors show that end-to-end learning, i.e. giving up strict boundaries between sub-problems improves their solution. However, it is unclear if this is an artifacts of overfitting, an indication of a poor initial factorization, or an indication of the fact that even correct factorizations may exclude parts of the solution space containing the optimal solution.\n\nIrrespective of the degree of decomposability of a problem (and the suitable degree of modularity of the solution), we suspect that there are optimal factorizations of problems for a defined task, agent, and environment. Such a factorization may not always lead to simple interfaces between supproblems but always facilitates finding an optimal solution.\n\n\nAutomating programming\n\nOnce we are able to 1) decompose problems into subproblems, 2) solve those sub-problems with solutions from different points along the programming/data-spectrum, 3) recompose the solutions to sub-problems, and 4) extract algo-rithmic information from data-driven solutions, we might as well automate programming (computer science?) altogether. Programming should be easy to automate, as it takes place entirely within the well-defined world of the computer. If we can successfully apply generic methods to complex problems, extract and algorithmify structural knowledge from the resulting solutions, use the resulting algorithms to solve sub-problems of the original problem, thereby making that original problem more easily solvable, and so forth-then we can also imagine an automated way of deriving computer algorithms from problem-specific data. A key challenge will be the automatic decomposition or factorization of the problem into suitably solvable sub-problems.\n\nThis view raises some fundamental questions about the differences between program in programming and weights in deep learning. Really, this view implies that there is no qualitative difference between them, only a difference of expressiveness and the amount of prior assumptions reflected in them. Programs and weights, in this view, are different instances of the same thing, namely of parameters that specify a solution, given a framework for expressing such solutions. Now it seems plausible that we can incrementally extract structure from learned parameters (weights), leading to a less generic representation with fewer parameters, until the parameters are so specific that we might call them a program.\n\nBut the opposite is also possible. It is possible that problems exists that do not exhibit algorithmifiable structure. And it is possible that these problems can (only) be solved in a data-driven manner. To speculate about this, comparisons with biological cognitive capabilities might be helpful: Can these capabilities (in principle) be encoded in a program? Do these capabilities depend on massive amounts of data? These are difficult questions that AI researchers have asked themselves for many years.\n\nPriors to reduce the amount of data A natural concern for this kind of reasoning is the necessity to acquire large amounts of data. This can be very costly, especially when this data has to be acquired from interaction with the real world, as it is the case in robotics. It will then become necessary to reduce the required amount of data by incorporating appropriate priors into learning [49]. These priors reduce all possible interpretations of data to only those consistent with the prior. If sufficiently strong priors are available, it will become possible to extract (and possibly algorithmify) the problem structure from reasonable amounts of data.\n\nIt might also be difficult to separate acquired data into those groups associated with a single task. Recent methods have shown that this separation can be performed automatically [47]. Now data can be acquired in less restrictive settings and the learning agent can differentiate the task associated with a datum by itself.\n\nWhere will this lead?\n\nMaybe in the end, the most lasting impact of deep learning will not be deep learning itself but rather the effect it had. The successes of deep learning, achieved by leveraging data and computation, have made computer scientists realize that there is a spectrum-rather than a dichotomy-between programming and data. This realization may pave the way for a computer science that fully leverages the entire breadth of this spectrum to automatically derive algorithms from reasonable amounts of data and suitable priors.\n\n\nVII. CONCLUSIONS\n\nThe rather skeptical attitude towards deep learning at the Robotics: Science and Systems (RSS) conference in Rome 2015 motivated us to organize a workshop at RSS 2016 with the title \"Are the Skeptics Right? Limits and Potentials of Deep Learning in Robotics\" [113]. As it turned out, by then there were hardly any skeptics left. The robotics community had accepted deep learning as a very powerful tool and begun to utilize and advance it. A follow-up workshop on \"New Frontiers for Deep Learning in Robotics\" [112] at RSS 2017 concentrated more on some of the robotics-specific research challenges we discussed in this paper. 2017 saw a surge of deep learning in robotics: workshops at CVPR [3] and NIPS [87] built bridges between the robotics, computer vision, and machine learning communities. Over 10% of the papers submitted to ICRA 2018 used Deep learning in robotics and automation as a keyword, making it the most frequent keyword. Furthermore, a whole new Conference on Robot Learning (CoRL) [1] was initiated.\n\nWhile much ongoing work in deep learning for robotics concentrates on either perception or acting, we hope to see more integrated approaches in the future: robots that learn to utilize their embodiment to reduce the uncertainty in perception, decision making, and execution. Robots that learn complex multi-stage tasks, while incorporating prior model knowledge or heuristics, and exploiting a semantic understanding of their environment. Robots that learn to discover and exploit the rich semantic regularities and geometric structure of the world, to operate more robustly in realistic environments with open-set characteristics.\n\nDeep learning techniques have revolutionized many aspects of computer vision over the past five years and have been rapidly adopted into robotics as well. However, robotic perception, robotic learning, and robotic control are demanding tasks that continue to pose severe challenges on the techniques typically applied. Our paper discussed some of these current research questions and challenges for deep learning in robotics. We pointed the reader into different directions worthwhile for further research and hope our paper contributes to the ongoing advancement of deep learning for robotics.\n\nFig. 1 .\n1Current Challenges for Deep Learning in Robotic Vision. We can categorize these challenges into three conceptually orthogonal axes: learning, embodiment, and reasoning.\n\n\nKnown Classes: the classes with distinctly labeled positive training examples (also serving as negative examples for other known classes). \u2022 Known Unknown Classes: labeled negative examples, not necessarily grouped into meaningful categories. \u2022 Unknown Unknown Classes: classes unseen in training.\n\nFig. 2 .\n2Fig. 2.\n\nFig. 3 .\n3Detailed schematic of progressive recurrent network architecture, where the left column is trained in simulation, then the weights are frozen while the second column is trained on the real robot. A third column may then be trained on an additional task, taking advantage of the policies and features learnt and frozen in the first two columns.\n\nTABLE I LEARNING\nICHALLENGES FOR ROBOTIC VISIONLevel Name \nDescription \n\n5 \nActive Learning \n\n\nTABLE II EMBODIMENT\nIICHALLENGES FOR ROBOTIC VISION \n\nLevel Name \nDescription \n\n4 \nActive Manipulation \nAs an extension of active vision, the system can manipulate the scene to aid perception. For example it can move \nan occluding object to gain information about object hidden underneath. \n3 \nActive Vision \n\n\nTABLE III REASONING\nIIICHALLENGES FOR ROBOTIC VISIONLevel Name \nDescription \n\n3 \nJoint Reasoning \n\n\nTABLE IV\nIVMODELS VS. DEEP LEARNING \n\nModel-based \nDeep learning \n\nRepresentation \nexplicit; based on or inspired by physics \nimplicit; network structure and parameters \nGenerality \nbroadly applicable; physics are universal \nonly in trained regime; risk of overfitting \nRobustness \nsmall basin of convergence; requires good models and esti-\nmates thereof \n\nlarge basin of convergence; highly robust in trained regime \n\nData Efficiency \nvery high; only needed for system identification \ntraining requires significant data collection effort; \nComputational \nEfficiency \n\ngood in local regime \nhighly efficient once trained \n\nadapted to new situations. As a result, humans are capable \nof robustly performing a wide variety of tasks that are \nwell beyond the reach of current robot systems, including \ndexterous manipulation, handling vastly different kinds of \ningredients when cooking a meal, or climbing a tree. \n\n\nThe term algorithm refers to the Oxford Dictionary definition: \"a process or set of rules to be followed in calculations or other problem-solving operations.\" Here, it includes physics formulae, computational models, probabilistic representations and inference, etc.\nACKNOWLEDGEMENTS\nConference on Robot Learning (CoRL). Conference on Robot Learning (CoRL). http://www. robot-learning.org, 2017.\n\nLearning to poke by poking: Experiential learning of intuitive physics. P Agrawal, A V Nair, P Abbeel, J Malik, S Levine, Advances in Neural Information Processing Systems (NIPS). P. Agrawal, AV. Nair, P. Abbeel, J. Malik, and S. Levine. Learning to poke by poking: Experiential learning of intuitive physics. In Advances in Neural Information Processing Systems (NIPS), 2016.\n\nAnelia Angelova, Gustavo Carneiro, Kevin Murphy, Niko S\u00fcnderhauf, J\u00fcrgen Leitner, Ian Lenz, Trung T Pham, Vijay Kumar, Ingmar Posner, Michael Milford, Wolfram Burgard, Ian Reid, Peter Corke, Computer Vision and Pattern Recognition (CVPR) Workshop on Deep Learning in Robotic Vision. Anelia Angelova, Gustavo Carneiro, Kevin Murphy, Niko S\u00fcnderhauf, J\u00fcrgen Leitner, Ian Lenz, Trung T. Pham, Vijay Kumar, Ingmar Posner, Michael Milford, Wolfram Burgard, Ian Reid, and Peter Corke. Computer Vision and Pattern Recognition (CVPR) Workshop on Deep Learning in Robotic Vision. http://juxi.net/workshop/ deep-learning-robotic-vision-cvpr-2017/, 2017.\n\nThe trollable self-driving car. Slate. Samuel E Anthony, 2016-12-21Samuel E. Anthony. The trollable self-driving car. Slate, March 2016. Accessed 2016-12-21 via http://goo.gl/78fglb.\n\nNonmyopic view planning for active object classification and pose estimation. Nikolay Atanasov, Bharath Sankaran, Jerome Le Ny, George J Pappas, Kostas Daniilidis, IEEE Transactions on Robotics. 305Nikolay Atanasov, Bharath Sankaran, Jerome Le Ny, George J Pappas, and Kostas Daniilidis. Nonmyopic view planning for active object classification and pose estimation. IEEE Transactions on Robotics, 30(5):1078-1090, 2014.\n\nHow do infants reason about physical events?. R Baillargeon, J Li, Y Gertner, D Wu, The Wiley-Blackwell handbook of childhood cognitive development. OxfordBlackwellsecond editionR. Baillargeon, J. Li, Y. Gertner, and D. Wu. How do infants reason about physical events? In The Wiley-Blackwell handbook of childhood cognitive development, second edition. Oxford: Blackwell, 20111.\n\nObject individuation and physical reasoning in infancy: An integrative account. R Baillargeon, M Stavans, D Wu, R Gertner, P Setoh, A K Kittredge, A Bernard, Language Learning and Development. 8R. Baillargeon, M. Stavans, D. Wu, R. Gertner, P. Setoh, A. K. Kittredge, and A. Bernard. Object individuation and physical rea- soning in infancy: An integrative account. Language Learning and Development, 8, 2012.\n\nTransfer learning for reinforcement learning on a physical robot. Samuel Barrett, Matthew E Taylor, Peter Stone, Ninth International Conference on Autonomous Agents and Multiagent Systems -Adaptive Learning Agents Workshop (AAMAS -ALA). Samuel Barrett, Matthew E. Taylor, and Peter Stone. Transfer learning for reinforcement learning on a physical robot. In Ninth International Conference on Autonomous Agents and Multiagent Systems -Adaptive Learning Agents Workshop (AAMAS -ALA), 2010.\n\nInteraction networks for learning about objects, relations and physics. Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, Advances in neural information processing systems. Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, et al. Interaction networks for learning about objects, relations and physics. In Advances in neural information processing systems, pages 4502-4510, 2016.\n\nSimulation as an engine of physical scene understanding. W Peter, Jessica B Battaglia, Joshua B Hamrick, Tenenbaum, Proceedings of the National Academy of Sciences. the National Academy of Sciences110Peter W Battaglia, Jessica B Hamrick, and Joshua B Tenenbaum. Simulation as an engine of physical scene understanding. Proceed- ings of the National Academy of Sciences, 110(45):18327-18332, 2013.\n\nTowards open world recognition. Abhijit Bendale, Terrance E Boult, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionAbhijit Bendale and Terrance E. Boult. Towards open world recog- nition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1893-1902, June 2015.\n\nTowards open set deep networks. Abhijit Bendale, Terrance E Boult, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionAbhijit Bendale and Terrance E. Boult. Towards open set deep networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1563-1572, June 2016.\n\nLearning feed-forward one-shot learners. Luca Bertinetto, F Jo\u00e3o, Jack Henriques, Philip Valmadre, Andrea Torr, Vedaldi, Advances in Neural Information Processing Systems. Luca Bertinetto, Jo\u00e3o F Henriques, Jack Valmadre, Philip Torr, and Andrea Vedaldi. Learning feed-forward one-shot learners. In Advances in Neural Information Processing Systems, pages 523-531, 2016.\n\nReceding horizon\" next-best-view\" planner for 3d exploration. Andreas Bircher, Mina Kamel, Kostas Alexis , Helen Oleynikova, Roland Siegwart, IEEE International Conference on Robotics and Automation (ICRA). IEEEAndreas Bircher, Mina Kamel, Kostas Alexis, Helen Oleynikova, and Roland Siegwart. Receding horizon\" next-best-view\" planner for 3d exploration. In IEEE International Conference on Robotics and Automation (ICRA), pages 1462-1468. IEEE, 2016.\n\nWhat object attributes determine canonical views? Perception. Volker Blanz, Michael J Tarr, Heinrich H B\u00fclthoff, 28Volker Blanz, Michael J. Tarr, and Heinrich H. B\u00fclthoff. What object attributes determine canonical views? Perception, 28(5):575-599, 1999.\n\nSE3-nets: Learning rigid body motion using deep neural networks. A Byravan, D Fox, Proc. of the IEEE International Conference on Robotics & Automation (ICRA). of the IEEE International Conference on Robotics & Automation (ICRA)A. Byravan and D. Fox. SE3-nets: Learning rigid body motion using deep neural networks. In Proc. of the IEEE International Conference on Robotics & Automation (ICRA), 2017.\n\nSE3-Pose-Nets: Structured deep dynamics models for visuomotor planning and control. A Byravan, F Leeb, F Meier, D Fox, Proc. of the IEEE International Conference on Robotics & Automation (ICRA). of the IEEE International Conference on Robotics & Automation (ICRA)A. Byravan, F. Leeb, F. Meier, and D. Fox. SE3-Pose-Nets: Structured deep dynamics models for visuomotor planning and control. In Proc. of the IEEE International Conference on Robotics & Automa- tion (ICRA), 2018.\n\nUnsupervised learning for physical interaction through video prediction. I Goodfellow, C Finn, S Levine, Advances in Neural Information Processing Systems (NIPS). I. Goodfellow C. Finn and S. Levine. Unsupervised learning for physical interaction through video prediction. In Advances in Neural Information Processing Systems (NIPS), 2016.\n\nPast, present, and future of simultaneous localization and mapping: Toward the robust-perception age. Cesar Cadena, Luca Carlone, Henry Carrillo, Yasir Latif, Davide Scaramuzza, Jos\u00e9 Neira, Ian Reid, John J Leonard, IEEE Transactions on Robotics. 326Cesar Cadena, Luca Carlone, Henry Carrillo, Yasir Latif, Davide Scaramuzza, Jos\u00e9 Neira, Ian Reid, and John J Leonard. Past, present, and future of simultaneous localization and mapping: Toward the robust-perception age. IEEE Transactions on Robotics, 32(6):1309- 1332, 2016.\n\n3d-r2n2: A unified approach for single and multiview 3d object reconstruction. B Christopher, Danfei Choy, Junyoung Xu, Kevin Gwak, Silvio Chen, Savarese, European Conference on Computer Vision (ECCV). SpringerChristopher B Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, and Silvio Savarese. 3d-r2n2: A unified approach for single and multi- view 3d object reconstruction. In European Conference on Computer Vision (ECCV), pages 628-644. Springer, 2016.\n\nActive learning with statistical models. Zoubin David A Cohn, Michael I Jordan Ghahramani, Journal of artificial intelligence research. 41David A Cohn, Zoubin Ghahramani, and Michael I Jordan. Active learning with statistical models. Journal of artificial intelligence research, 4(1):129-145, 1996.\n\nNeural networks and neuroscienceinspired computer vision. D David, Thomas Cox, Dean, Current Biology. 2418David D. Cox and Thomas Dean. Neural networks and neuroscience- inspired computer vision. Current Biology, 24(18):R921-R929, 2014.\n\nGabriela Csurka, arXiv:1702.05374Domain adaptation for visual applications: A comprehensive survey. arXiv preprintGabriela Csurka. Domain adaptation for visual applications: A comprehensive survey. arXiv preprint arXiv:1702.05374, 2017.\n\nEpisode-based active learning with bayesian neural networks. Feras Dayoub, Niko S\u00fcnderhauf, Peter Corke, arXiv:1703.07473CVPR Workshop on Deep Learning for Robotic Vision. arXiv preprintFeras Dayoub, Niko S\u00fcnderhauf, and Peter Corke. Episode-based active learning with bayesian neural networks. In CVPR Workshop on Deep Learning for Robotic Vision. arXiv preprint arXiv:1703.07473, 2017.\n\nRecovering 6d object pose and predicting nextbest-view in the crowd. Andreas Doumanoglou, Rigas Kouskouridas, Sotiris Malassiotis, Tae-Kyun Kim, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionAndreas Doumanoglou, Rigas Kouskouridas, Sotiris Malassiotis, and Tae-Kyun Kim. Recovering 6d object pose and predicting next- best-view in the crowd. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3583-3592, 2016.\n\nItem response theory for psychologists. Susan E Embretson, Steven P Reise, Lawrence Erlbaum Associates, IncSusan E. Embretson and Steven P. Reise. Item response theory for psychologists. Lawrence Erlbaum Associates, Inc., 2000.\n\nModel-agnostic meta-learning for fast adaptation of deep networks. Chelsea Finn, Pieter Abbeel, Sergey Levine, arXiv:1703.03400arXiv preprintChelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. arXiv preprint arXiv:1703.03400, 2017.\n\nDropout as a bayesian approximation: Representing model uncertainty in deep learning. Yarin Gal, Zoubin Ghahramani, International Conference on Machine Learning (ICML). Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian ap- proximation: Representing model uncertainty in deep learning. In International Conference on Machine Learning (ICML), pages 1050- 1059, 2016.\n\nYarin Gal, Riashat Islam, Zoubin Ghahramani, arXiv:1703.02910Deep bayesian active learning with image data. arXiv preprintYarin Gal, Riashat Islam, and Zoubin Ghahramani. Deep bayesian active learning with image data. arXiv preprint arXiv:1703.02910, 2017.\n\nDomain-adversarial training of neural networks. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, Victor S Lempitsky, abs/1505.07818CoRRYaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, and Victor S. Lempitsky. Domain-adversarial training of neural networks. CoRR, abs/1505.07818, 2015.\n\nUnsupervised cnn for single view depth estimation: Geometry to the rescue. Ravi Garg, Gustavo Carneiro, Ian Reid, European Conference on Computer Vision. SpringerRavi Garg, Gustavo Carneiro, and Ian Reid. Unsupervised cnn for single view depth estimation: Geometry to the rescue. In European Conference on Computer Vision, pages 740-756. Springer, 2016.\n\nUnsupervised monocular depth estimation with left-right consistency. Cl\u00e9ment Godard, Oisin Mac Aodha, Gabriel J Brostow, Computer Vision and Pattern Recognition (CVPR). Cl\u00e9ment Godard, Oisin Mac Aodha, and Gabriel J Brostow. Unsu- pervised monocular depth estimation with left-right consistency. In Computer Vision and Pattern Recognition (CVPR), 2017.\n\nSensation and perception. Cengage Learning. Bruce Goldstein, James Brockmole, E Bruce Goldstein and James Brockmole. Sensation and perception. Cengage Learning, 2016.\n\nAn empirical investigation of catastrophic forgetting in gradient-based neural networks. J Ian, Mehdi Goodfellow, Da Mirza, Aaron Xiao, Yoshua Courville, Bengio, arXiv:1312.6211arXiv preprintIan J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. An empirical investigation of catastrophic forgetting in gradient-based neural networks. arXiv preprint arXiv:1312.6211, 2013.\n\nJ Ian, Goodfellow, arXiv:1412.6572Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprintIan J Goodfellow, Jonathon Shlens, and Christian Szegedy. Ex- plaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.\n\nNeural expectation maximization. Klaus Greff, J\u00fcrgen Sjoerd Van Steenkiste, Schmidhuber, Advances in Neural Information Processing Systems. Klaus Greff, Sjoerd van Steenkiste, and J\u00fcrgen Schmidhuber. Neural expectation maximization. In Advances in Neural Information Processing Systems, pages 6694-6704, 2017.\n\nContinuous deep q-learning with model-based acceleration. Shixiang Gu, Timothy P Lillicrap, Ilya Sutskever, Sergey Levine, ICML 2016. Shixiang Gu, Timothy P. Lillicrap, Ilya Sutskever, and Sergey Levine. Continuous deep q-learning with model-based acceleration. In ICML 2016, 2016.\n\nChuan Guo, Geoff Pleiss, Yu Sun, Kilian Q Weinberger, arXiv:1706.04599On calibration of modern neural networks. arXiv preprintChuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On cali- bration of modern neural networks. arXiv preprint arXiv:1706.04599, 2017.\n\nBackprop KF: learning discriminative deterministic state estimators. Tuomas Haarnoja, Anurag Ajay, Sergey Levine, Pieter Abbeel, abs/1605.07148CoRRTuomas Haarnoja, Anurag Ajay, Sergey Levine, and Pieter Abbeel. Backprop KF: learning discriminative deterministic state estimators. CoRR, abs/1605.07148, 2016.\n\nHierarchical surface prediction for 3d object reconstruction. Christian H\u00e4ne, Shubham Tulsiani, Jitendra Malik, arXiv:1704.00710arXiv preprintChristian H\u00e4ne, Shubham Tulsiani, and Jitendra Malik. Hierarchical surface prediction for 3d object reconstruction. arXiv preprint arXiv:1704.00710, 2017.\n\nLow-shot visual recognition by shrinking and hallucinating features. Bharath Hariharan, Ross Girshick, arXiv:1606.02819arXiv preprintBharath Hariharan and Ross Girshick. Low-shot visual recog- nition by shrinking and hallucinating features. arXiv preprint arXiv:1606.02819, 2016.\n\nMask r-cnn. Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, Ross Girshick, IEEE International Conference on Computer Vision (ICCV. Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, and Ross Girshick. Mask r-cnn. In IEEE International Conference on Computer Vision (ICCV), 2017.\n\nLearning continuous control policies by stochastic value gradients. Nicolas Heess, Gregory Wayne, David Silver, Timothy P Lillicrap, Tom Erez, Yuval Tassa, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems. Montreal, Quebec, CanadaNicolas Heess, Gregory Wayne, David Silver, Timothy P. Lillicrap, Tom Erez, and Yuval Tassa. Learning continuous control policies by stochastic value gradients. In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 2944-2952, 2015.\n\nA baseline for detecting misclassified and out-of-distribution examples in neural networks. Dan Hendrycks, Kevin Gimpel, International Conference on Machine Learning (ICML). Dan Hendrycks and Kevin Gimpel. A baseline for detecting mis- classified and out-of-distribution examples in neural networks. In International Conference on Machine Learning (ICML), 2017.\n\nOcclusion is hard: Comparing predictive reaching for visible and hidden objects in infants and adults. S Hespos, G Gredeba, C Von Hofsten, E Spelke, Cognitive Science. S. Hespos, G. Gredeba, C. von Hofsten, and E. Spelke. Occlusion is hard: Comparing predictive reaching for visible and hidden objects in infants and adults. Cognitive Science, 2009.\n\nDistilling the knowledge in a neural network. Geoffrey Hinton, Oriol Vinyals, Jeff Dean, abs/1503.02531CoRRGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. CoRR, abs/1503.02531, 2015.\n\nUnsupervised learning of state representations for multiple tasks. Sebastian H\u00f6fer, Antonin Raffin, Rico Jonschkowski, Oliver Brock, Freek Stulp, Deep Learning Workshop at the Conference on Neural Information Processing Systems (NIPS). Sebastian H\u00f6fer, Antonin Raffin, Rico Jonschkowski, Oliver Brock, and Freek Stulp. Unsupervised learning of state representations for multiple tasks. In Deep Learning Workshop at the Conference on Neural Information Processing Systems (NIPS), 2016.\n\n3D Simulation for Robot Arm Control with Deep Q-Learning. S James, E Johns, ArXiv e-printsS. James and E. Johns. 3D Simulation for Robot Arm Control with Deep Q-Learning. ArXiv e-prints, 2016.\n\nLearning state representations with robotic priors. Rico Jonschkowski, Oliver Brock, Autonomous Robots. 393Rico Jonschkowski and Oliver Brock. Learning state representations with robotic priors. Autonomous Robots, 39(3):407-428, 2015.\n\nEnd-to-end learnable histogram filters. Rico Jonschkowski, Oliver Brock, Workshop on Deep Learning for Action and Interaction at the Conference on Neural Information Processing Systems (NIPS). Rico Jonschkowski and Oliver Brock. End-to-end learnable his- togram filters. In Workshop on Deep Learning for Action and Interaction at the Conference on Neural Information Processing Systems (NIPS), 2016.\n\nPves: Position-velocity encoders for unsupervised learning of structured state representations. Rico Jonschkowski, Roland Hafner, Jonathan Scholz, Martin Riedmiller, arXiv:1705.09805arXiv preprintRico Jonschkowski, Roland Hafner, Jonathan Scholz, and Mar- tin Riedmiller. Pves: Position-velocity encoders for unsuper- vised learning of structured state representations. arXiv preprint arXiv:1705.09805, 2017.\n\nContextual learning. CoRR. Rico Jonschkowski, Sebastian H\u00f6fer, Oliver Brock, abs/1511.06429Rico Jonschkowski, Sebastian H\u00f6fer, and Oliver Brock. Contextual learning. CoRR, abs/1511.06429, 2015.\n\niSAM2: Incremental Smoothing and Mapping Using the Bayes Tree. M Kaess, H Johannsson, R Roberts, V Ila, J Leonard, F Dellaert, Intl. Journal of Robotics Research. 312M. Kaess, H. Johannsson, R. Roberts, V. Ila, J. Leonard, and F. Dellaert. iSAM2: Incremental Smoothing and Mapping Using the Bayes Tree. Intl. Journal of Robotics Research, 31(2):216-235, February 2012.\n\nWhat uncertainties do we need in bayesian deep learning for computer vision?. Alex Kendall, Yarin Gal, arXiv:1703.04977arXiv preprintAlex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer vision? arXiv preprint arXiv:1703.04977, 2017.\n\nObject perception as bayesian inference. Daniel Kersten, Pascal Mamassian, Alan Yuille, Annu. Rev. Psychol. 55Daniel Kersten, Pascal Mamassian, and Alan Yuille. Object percep- tion as bayesian inference. Annu. Rev. Psychol., 55:271-304, 2004.\n\nSemi-supervised learning with deep generative models. Shakir Diederik P Kingma, Danilo Mohamed, Max Jimenez Rezende, Welling, Advances in Neural Information Processing Systems. Diederik P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-supervised learning with deep generative models. In Advances in Neural Information Processing Systems, pages 3581- 3589, 2014.\n\nOptimization-based locomotion planning, estimation, and control design for the Atlas humanoid robot. S Kuindersma, R Deits, M Fallon, A Valenzuela, H Dai, F Permenter, T Koolen, P Marion, R Tedrake, Autonomous Robots. 403S. Kuindersma, R. Deits, M. Fallon, A. Valenzuela, H. Dai, F. Per- menter, T. Koolen, P. Marion, and R. Tedrake. Optimization-based locomotion planning, estimation, and control design for the Atlas humanoid robot. Autonomous Robots, 40(3), 2016.\n\ng2o: A General Framework for Graph Optimization. R K\u00fcmmerle, G Grisetti, H Strasdat, K Konolige, W Burgard, Proc. of Intl. Conf. on Robotics and Automation (ICRA). of Intl. Conf. on Robotics and Automation (ICRA)R. K\u00fcmmerle, G. Grisetti, H. Strasdat, K. Konolige, and W. Burgard. g2o: A General Framework for Graph Optimization. In Proc. of Intl. Conf. on Robotics and Automation (ICRA), pages 3607 -3613, 2011.\n\nEnvisioning the qualitative effects of robot manipulation actions using simulation-based projections. Lars Kunze, Michael Beetz, Artificial Intelligence. Lars Kunze and Michael Beetz. Envisioning the qualitative effects of robot manipulation actions using simulation-based projections. Artificial Intelligence, 2015.\n\nHuman-level concept learning through probabilistic program induction. Ruslan Brenden M Lake, Joshua B Salakhutdinov, Tenenbaum, Science. 3506266Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. Human-level concept learning through probabilistic program induc- tion. Science, 350(6266):1332-1338, 2015.\n\nSimple and scalable predictive uncertainty estimation using deep ensembles. Balaji Lakshminarayanan, Alexander Pritzel, Charles Blundell, Advances in Neural Information Processing Systems. Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. In Advances in Neural Information Processing Systems, pages 6393-6395, 2017.\n\nLearning neural network policies with guided policy search under unknown dynamics. Sergey Levine, Pieter Abbeel, Advances in Neural Information Processing Systems. Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. WeinbergerCurran Associates, Inc27Sergey Levine and Pieter Abbeel. Learning neural network policies with guided policy search under unknown dynamics. In Z. Ghahra- mani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 27, pages 1071-1079. Curran Associates, Inc., 2014.\n\nEndto-end training of deep visuomotor policies. Sergey Levine, Chelsea Finn, Trevor Darrell, Pieter Abbeel, The Journal of Machine Learning Research. 171Sergey Levine, Chelsea Finn, Trevor Darrell, and Pieter Abbeel. End- to-end training of deep visuomotor policies. The Journal of Machine Learning Research, 17(1):1334-1373, 2015.\n\nYuval Tassa, David Silver, and Daan Wierstra. Continuous control with deep reinforcement learning. Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, abs/1509.02971CoRRTimothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, and Daan Wier- stra. Continuous control with deep reinforcement learning. CoRR, abs/1509.02971, 2015.\n\nHolistic scene understanding for 3d object detection with rgbd cameras. Dahua Lin, Sanja Fidler, Raquel Urtasun, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionDahua Lin, Sanja Fidler, and Raquel Urtasun. Holistic scene under- standing for 3d object detection with rgbd cameras. In Proceedings of the IEEE International Conference on Computer Vision, pages 1417-1424, 2013.\n\nLearning depth from single monocular images using deep convolutional neural fields. Fayao Liu, Chunhua Shen, Guosheng Lin, Ian Reid, IEEE transactions on pattern analysis and machine intelligence. 38Fayao Liu, Chunhua Shen, Guosheng Lin, and Ian Reid. Learn- ing depth from single monocular images using deep convolutional neural fields. IEEE transactions on pattern analysis and machine intelligence, 38(10):2024-2039, 2016.\n\nSsd: Single shot multibox detector. Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C Berg, European conference on computer vision. SpringerWei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C Berg. Ssd: Single shot multibox detector. In European conference on computer vision, pages 21-37. Springer, 2016.\n\nA lesson of Tesla crashes? computer vision can't do it all yet. The New York Times. Steve Lohr, 2016-12-21Steve Lohr. A lesson of Tesla crashes? computer vision can't do it all yet. The New York Times, September 2016. Accessed 2016-12-21 via http://goo.gl/5RcHVr.\n\nCore50: a new dataset and benchmark for continuous object recognition. Vincenzo Lomonaco, Davide Maltoni, Vincenzo Lomonaco and Davide Maltoni. Core50: a new dataset and benchmark for continuous object recognition.\n\nLearning transferable features with deep adaptation networks. Mingsheng Long, Yue Cao, Jianmin Wang, Michael I Jordan, Proceedings of the 32nd International Conference on Machine Learning. the 32nd International Conference on Machine LearningLille, FranceMingsheng Long, Yue Cao, Jianmin Wang, and Michael I. Jordan. Learning transferable features with deep adaptation networks. In Pro- ceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, pages 97-105, 2015.\n\nUnifying distillation and privileged information. David Lopez-Paz, L\u00e9on Bottou, Bernhard Sch\u00f6lkopf, Vladimir Vapnik, abs/1511.03643CoRRDavid Lopez-Paz, L\u00e9on Bottou, Bernhard Sch\u00f6lkopf, and Vladimir Vapnik. Unifying distillation and privileged information. CoRR, abs/1511.03643, 2016.\n\nA practical bayesian framework for backpropagation networks. J C David, Mackay, Neural computation. 43David JC MacKay. A practical bayesian framework for backpropa- gation networks. Neural computation, 4(3):448-472, 1992.\n\nDeep active object recognition by joint label and action prediction. Mohsen Malmir, Karan Sikka, Deborah Forster, Ian Fasel, Javier R Movellan, W Garrison, Cottrell, Computer Vision and Image Understanding. 156Mohsen Malmir, Karan Sikka, Deborah Forster, Ian Fasel, Javier R Movellan, and Garrison W Cottrell. Deep active object recognition by joint label and action prediction. Computer Vision and Image Understanding, 156:128-137, 2017.\n\nIntuitive physics. Michael Mccloskey, Scientific american. 2484Michael McCloskey. Intuitive physics. Scientific american, 248(4):122-130, 1983.\n\nMetric learning for large scale image classification: Generalizing to new classes at near-zero cost. Thomas Mensink, Jakob Verbeek, Florent Perronnin, Gabriela Csurka, Computer Vision-ECCV 2012. Thomas Mensink, Jakob Verbeek, Florent Perronnin, and Gabriela Csurka. Metric learning for large scale image classification: Gen- eralizing to new classes at near-zero cost. Computer Vision-ECCV 2012, pages 488-501, 2012.\n\nDropout sampling for robust object detection in open-set conditions. Dimity Miller, Lachlan Nicholson, Feras Dayoub, Niko S\u00fcnderhauf, International Conference on Robotics and Automation (ICRA). Dimity Miller, Lachlan Nicholson, Feras Dayoub, and Niko S\u00fcnderhauf. Dropout sampling for robust object detection in open-set conditions. In International Conference on Robotics and Automation (ICRA), 2017.\n\nAsynchronous methods for deep reinforcement learning. Volodymyr Mnih, Adri Puigdomnech Badia, Mehdi Mirza, Alex Graves, Timothy P Lillicrap, Tim Harley, David Silver, Koray Kavukcuoglu, Int'l Conf. on Machine Learning (ICML). Volodymyr Mnih, Adri Puigdomnech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learn- ing. In Int'l Conf. on Machine Learning (ICML), 2016.\n\nBayesian learning for neural networks. M Radford, Neal, University of TorontoPhD thesisRadford M Neal. Bayesian learning for neural networks. PhD thesis, University of Toronto, 1995.\n\nDeep neural networks are easily fooled: High confidence predictions for unrecognizable images. Anh Nguyen, Jason Yosinski, Jeff Clune, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionAnh Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 427-436, 2015.\n\nDeep neural networks are easily fooled: High confidence predictions for unrecognizable images. Anh Nguyen, Jason Yosinski, Jeff Clune, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionAnh Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 427-436, June 2015.\n\nThe role of context in object recognition. Aude Oliva, Antonio Torralba, Trends in cognitive sciences. 1112Aude Oliva and Antonio Torralba. The role of context in object recognition. Trends in cognitive sciences, 11(12):520-527, 2007.\n\nWeakly-and semi-supervised learning of a deep convolutional network for semantic image segmentation. George Papandreou, Liang-Chieh Chen, Kevin P Murphy, Alan L Yuille, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionGeorge Papandreou, Liang-Chieh Chen, Kevin P Murphy, and Alan L Yuille. Weakly-and semi-supervised learning of a deep convolutional network for semantic image segmentation. In Proceedings of the IEEE International Conference on Computer Vision, pages 1742- 1750, 2015.\n\nVisual domain adaptation: A survey of recent advances. M Vishal, Raghuraman Patel, Ruonan Gopalan, Rama Li, Chellappa, IEEE signal processing magazine. 323Vishal M Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chel- lappa. Visual domain adaptation: A survey of recent advances. IEEE signal processing magazine, 32(3):53-69, 2015.\n\nLearning deep object detectors from 3d models. Xingchao Peng, Baochen Sun, Karim Ali, Kate Saenko, 2015 IEEE International Conference on Computer Vision. Santiago, Chile, DecemberXingchao Peng, Baochen Sun, Karim Ali, and Kate Saenko. Learning deep object detectors from 3d models. In 2015 IEEE International Conference on Computer Vision, ICCV 2015, Santiago, Chile, De- cember 7-13, 2015, pages 1278-1286, 2015.\n\nThe construction of reality in the child. Jean Piaget, 82RoutledgeJean Piaget. The construction of reality in the child, volume 82. Routledge, 2013.\n\nMonocular slam supported object recognition. Sudeep Pillai, John Leonard, Robotics: Science and Systems. Sudeep Pillai and John Leonard. Monocular slam supported object recognition. In Robotics: Science and Systems, 2015.\n\nIngmar Posner, Raia Hadsell, Martin Riedmiller, Markus Wulfmeier, Rohan Paul, Neural Information Processing Systems (NIPS) Workshop on Acting and Interacting in the Real World: Challenges in Robot Learning. Ingmar Posner, Raia Hadsell, Martin Riedmiller, Markus Wulfmeier, and Rohan Paul. Neural Information Processing Systems (NIPS) Workshop on Acting and Interacting in the Real World: Chal- lenges in Robot Learning. http://sites.google.com/ view/nips17robotlearning/home, 2016.\n\nFolk physics for apes: The chimpanzee's theory of how the world works. J Daniel, Povinelli, Daniel J Povinelli. Folk physics for apes: The chimpanzee's theory of how the world works. 2000.\n\nSemi-supervised learning with ladder networks. Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, Tapani Raiko, Advances in Neural Information Processing Systems. Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semi-supervised learning with ladder networks. In Advances in Neural Information Processing Systems, pages 3546- 3554, 2015.\n\nAlexander Sylvestre-Alvise Rebuffi, Georg Kolesnikov, Christoph H Sperl, Lampert, icarl: Incremental classifier and representation learning. Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H. Lampert. icarl: Incremental classifier and representation learning.\n\nYolo9000: better, faster, stronger. Joseph Redmon, Ali Farhadi, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Joseph Redmon and Ali Farhadi. Yolo9000: better, faster, stronger. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.\n\nOne-shot generalization in deep generative models. Danilo Rezende, Ivo Danihelka, Karol Gregor, Daan Wierstra, International Conference on Machine Learning. Danilo Rezende, Ivo Danihelka, Karol Gregor, Daan Wierstra, et al. One-shot generalization in deep generative models. In International Conference on Machine Learning, pages 1521-1529, 2016.\n\nPsyphy: A psychophysics driven evaluation framework for visual recognition. Brandon Richardwebster, Samuel E Anthony, Walter J Scheirer, abs/1611.06448CoRRBrandon RichardWebster, Samuel E. Anthony, and Walter J. Scheirer. Psyphy: A psychophysics driven evaluation framework for visual recognition. CoRR, abs/1611.06448, 2016.\n\nThe logic of perception. I Rock, MIT PressCambridgeI. Rock. The logic of perception. Cambridge: MIT Press, 1983.\n\nDoD News Briefing addressing unknown unknowns. Donald Rumsfeld, 2016-12-21 via htp://goo.gl/ ph7UfVDonald Rumsfeld. DoD News Briefing addressing unknown unknowns., 2002. Accessed 2016-12-21 via htp://goo.gl/ ph7UfV.\n\nAndrei Rusu, Neil Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, arXiv:1606.04671Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprintAndrei Rusu, Neil Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprint arXiv:1606.04671, 2016.\n\nCad2rl: Real single-image flight without a single real image. Fereshteh Sadeghi, Sergey Levine, arXiv:1611.04201arXiv preprintFereshteh Sadeghi and Sergey Levine. Cad2rl: Real single-image flight without a single real image. arXiv preprint arXiv:1611.04201, 2016.\n\nSlam++: Simultaneous localisation and mapping at the level of objects. F Renato, Richard A Salas-Moreno, Hauke Newcombe, Strasdat, H J Paul, Andrew J Kelly, Davison, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionRenato F Salas-Moreno, Richard A Newcombe, Hauke Strasdat, Paul HJ Kelly, and Andrew J Davison. Slam++: Simultaneous localisation and mapping at the level of objects. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1352-1359, 2013.\n\nMeta-learning with memory-augmented neural networks. Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, Timothy Lillicrap, International conference on machine learning. Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta-learning with memory-augmented neural networks. In International conference on machine learning, pages 1842-1850, 2016.\n\nPerceptual annotation: Measuring human vision to improve computer vision. J Walter, Sam E Scheirer, Ken Anthony, David D Nakayama, Cox, IEEE Transactions on Pattern Analysis and Machine Intelligence. 368Walter J. Scheirer, Sam E. Anthony, Ken Nakayama, and David D. Cox. Perceptual annotation: Measuring human vision to improve computer vision. IEEE Transactions on Pattern Analysis and Ma- chine Intelligence, 36(8):1679-1686, Aug 2014.\n\nToward open set recognition. J Walter, Anderson Scheirer, De Rezende, Archana Rocha, Terrance E Sapkota, Boult, IEEE Transactions on Pattern Analysis and Machine Intelligence. 357Walter J Scheirer, Anderson de Rezende Rocha, Archana Sapkota, and Terrance E Boult. Toward open set recognition. IEEE Trans- actions on Pattern Analysis and Machine Intelligence, 35(7):1757- 1772, 2013.\n\nToward open set recognition. J Walter, Anderson Scheirer, De Rezende, Archana Rocha, Terrance E Sapkota, Boult, IEEE Transactions on Pattern Analysis and Machine Intelligence. 357Walter J. Scheirer, Anderson de Rezende Rocha, Archana Sapkota, and Terrance E. Boult. Toward open set recognition. IEEE Trans- actions on Pattern Analysis and Machine Intelligence, 35(7):1757- 1772, July 2013.\n\nProbability models for open set recognition. J Walter, Lalit P Scheirer, Terrance E Jain, Boult, IEEE Transactions on Pattern Analysis and Machine Intelligence. 3611Walter J. Scheirer, Lalit P. Jain, and Terrance E. Boult. Probability models for open set recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36(11):2317-2324, Nov 2014.\n\nOn reverse engineering in the brain and cognitive sciences. Andreas Schierwagen, Natural Computing. 111Andreas Schierwagen. On reverse engineering in the brain and cognitive sciences. Natural Computing, 11(1):141-150, 2012.\n\nRobust Real-Time Tracking with Visual and Physical Constraints for Robot Manipulation. T Schmidt, K Hertkorn, R Newcombe, Z Marton, S Suppa, D Fox, Proc. of the IEEE International Conference on Robotics & Automation (ICRA). of the IEEE International Conference on Robotics & Automation (ICRA)T. Schmidt, K. Hertkorn, R. Newcombe, Z. Marton, S. Suppa, and D. Fox. Robust Real-Time Tracking with Visual and Physical Con- straints for Robot Manipulation. In Proc. of the IEEE International Conference on Robotics & Automation (ICRA), 2015.\n\nTrust region policy optimization. John Schulman, Sergey Levine, Philipp Moritz, Michael I Jordan, Pieter Abbeel, Proceedings of the 32nd International Conference on Machine Learning (ICML). the 32nd International Conference on Machine Learning (ICML)John Schulman, Sergey Levine, Philipp Moritz, Michael I. Jordan, and Pieter Abbeel. Trust region policy optimization. In Proceedings of the 32nd International Conference on Machine Learning (ICML), 2015.\n\nHigh-dimensional continuous control using generalized advantage estimation. John Schulman, Philipp Moritz, Sergey Levine, Michael Jordan, Pieter Abbeel, Proceedings of the International Conference on Learning Representations (ICLR). the International Conference on Learning Representations (ICLR)John Schulman, Philipp Moritz, Sergey Levine, Michael Jordan, and Pieter Abbeel. High-dimensional continuous control using generalized advantage estimation. In Proceedings of the International Conference on Learning Representations (ICLR), 2016.\n\nNeural implementation of hierarchical bayesian inference by importance sampling. Lei Shi, Thomas L Griffiths, Proceedings of the Neural Information Processing Systems Conference (NIPS). the Neural Information Processing Systems Conference (NIPS)Lei Shi and Thomas L. Griffiths. Neural implementation of hierar- chical bayesian inference by importance sampling. In Proceedings of the Neural Information Processing Systems Conference (NIPS), 2009.\n\nThe Sciences of the Artificial. Herbert A Simon, MIT PressHerbert A. Simon. The Sciences of the Artificial. MIT Press, 1996.\n\nRender for CNN: viewpoint estimation in images using cnns trained with rendered 3d model views. Hao Su, Charles Ruizhongtai Qi, Yangyan Li, Leonidas J Guibas, 2015 IEEE International Conference on Computer Vision, ICCV 2015. Santiago, Chile, DecemberHao Su, Charles Ruizhongtai Qi, Yangyan Li, and Leonidas J. Guibas. Render for CNN: viewpoint estimation in images using cnns trained with rendered 3d model views. In 2015 IEEE International Conference on Computer Vision, ICCV 2015, Santiago, Chile, De- cember 7-13, 2015, pages 2686-2694, 2015.\n\nPlace categorization and semantic mapping on a mobile robot. Niko S\u00fcnderhauf, Feras Dayoub, Sean Mcmahon, Ben Talbot, Ruth Schulz, Peter Corke, Gordon Wyeth, Ben Upcroft, Michael Milford, Robotics and Automation (ICRA), 2016 IEEE International Conference on. IEEENiko S\u00fcnderhauf, Feras Dayoub, Sean McMahon, Ben Talbot, Ruth Schulz, Peter Corke, Gordon Wyeth, Ben Upcroft, and Michael Milford. Place categorization and semantic mapping on a mobile robot. In Robotics and Automation (ICRA), 2016 IEEE International Conference on, pages 5729-5736. IEEE, 2016.\n\nNiko S\u00fcnderhauf, J\u00fcrgen Leitner, Pieter Abbeel, Michael Milford, Peter Corke, Robotics: Science and Systems (RSS) Workshop on New Frontiers for Deep Learning in Robotics. Niko S\u00fcnderhauf, J\u00fcrgen Leitner, Pieter Abbeel, Michael Milford, and Peter Corke. Robotics: Science and Systems (RSS) Workshop on New Frontiers for Deep Learning in Robotics. http://juxi. net/workshop/deep-learning-rss-2017/, 2017.\n\nNiko S\u00fcnderhauf, J\u00fcrgen Leitner, Michael Milford, Ben Upcroft, Pieter Abbeel, Wolfram Burgard, Peter Corke, Robotics: Science and Systems (RSS) Workshop Are the Sceptics Right? Limits and Potentials of Deep Learning in Robotics. Niko S\u00fcnderhauf, J\u00fcrgen Leitner, Michael Milford, Ben Upcroft, Pieter Abbeel, Wolfram Burgard, and Peter Corke. Robotics: Science and Systems (RSS) Workshop Are the Sceptics Right? Limits and Potentials of Deep Learning in Robotics. http://juxi.net/ workshop/deep-learning-rss-2016/, 2016.\n\nMeaningful maps -object-oriented semantic mapping. Niko S\u00fcnderhauf, T Trung, Yasir Pham, Michael Latif, Ian Milford, Reid, International Conference on Intelligent Robots and Systems (IROS). Niko S\u00fcnderhauf, Trung T Pham, Yasir Latif, Michael Milford, and Ian Reid. Meaningful maps -object-oriented semantic mapping. In International Conference on Intelligent Robots and Systems (IROS), 2017.\n\nIntriguing properties of neural networks. Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J Goodfellow, Rob Fergus, abs/1312.6199CoRRChristian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus. Intriguing properties of neural networks. CoRR, abs/1312.6199, 2013.\n\nValue iteration networks. CoRR. Aviv Tamar, Sergey Levine, Pieter Abbeel, abs/1602.02867Aviv Tamar, Sergey Levine, and Pieter Abbeel. Value iteration networks. CoRR, abs/1602.02867, 2016.\n\nProbabilistic Robotics. Sebastian Thrun, Wolfram Burgard, Dieter Fox, The MIT PressSebastian Thrun, Wolfram Burgard, and Dieter Fox. Probabilistic Robotics. The MIT Press, 2005.\n\nDomain randomization for transferring deep neural networks from simulation to the real world. Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, Pieter Abbeel, Intelligent Robots and Systems (IROS), 2017 IEEE/RSJ International Conference on. IEEEJosh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, and Pieter Abbeel. Domain randomization for transfer- ring deep neural networks from simulation to the real world. In Intelligent Robots and Systems (IROS), 2017 IEEE/RSJ International Conference on, pages 23-30. IEEE, 2017.\n\nMujoco: A physics engine for model-based control. E Todorov, T Erez, Y Tassa, International Conference on Intelligent Robots and Systems IROS. E. Todorov, T. Erez, and Y. Tassa. Mujoco: A physics engine for model-based control. In International Conference on Intelligent Robots and Systems IROS, 2012.\n\nUnbiased look at dataset bias. Antonio Torralba, Alexei A Efros, Computer Vision and Pattern Recognition (CVPR). IEEEAntonio Torralba and Alexei A Efros. Unbiased look at dataset bias. In Computer Vision and Pattern Recognition (CVPR), pages 1521- 1528. IEEE, 2011.\n\nTowards adapting deep visuomotor representations from simulated to real environments. Eric Tzeng, Coline Devin, Judy Hoffman, Chelsea Finn, Xingchao Peng, Sergey Levine, Kate Saenko, Trevor Darrell, abs/1511.07111CoRREric Tzeng, Coline Devin, Judy Hoffman, Chelsea Finn, Xingchao Peng, Sergey Levine, Kate Saenko, and Trevor Darrell. Towards adapting deep visuomotor representations from simulated to real environments. CoRR, abs/1511.07111, 2015.\n\nSimultaneous deep transfer across domains and tasks. Eric Tzeng, Judy Hoffman, Trevor Darrell, Kate Saenko, 2015 IEEE International Conference on Computer Vision. Santiago, ChileEric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Si- multaneous deep transfer across domains and tasks. In 2015 IEEE International Conference on Computer Vision, ICCV 2015, Santiago, Chile, December 7-13, 2015, pages 4068-4076, 2015.\n\nDeep domain confusion: Maximizing for domain invariance. Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, Trevor Darrell, abs/1412.3474CoRREric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion: Maximizing for domain invariance. CoRR, abs/1412.3474, 2014.\n\nMatching networks for one shot learning. Oriol Vinyals, Charles Blundell, Tim Lillicrap, Daan Wierstra, Advances in Neural Information Processing Systems. Oriol Vinyals, Charles Blundell, Tim Lillicrap, Daan Wierstra, et al. Matching networks for one shot learning. In Advances in Neural Information Processing Systems, pages 3630-3638, 2016.\n\nHandbuch der physiologischen Optik. Helmholtz Hermann Von, 91867Hermann Von Helmholtz. Handbuch der physiologischen Optik, volume 9. Voss, 1867.\n\nLearning to learn: Model regression networks for easy small sample learning. Yu-Xiong Wang, Martial Hebert, European Conference on Computer Vision. SpringerYu-Xiong Wang and Martial Hebert. Learning to learn: Model regression networks for easy small sample learning. In European Conference on Computer Vision, pages 616-634. Springer, 2016.\n\nEmbed to control: A locally linear latent dynamics model for control from raw images. Manuel Watter, Jost Springenberg, Joschka Boedecker, Martin Riedmiller, Advances in Neural Information Processing Systems. Manuel Watter, Jost Springenberg, Joschka Boedecker, and Martin Riedmiller. Embed to control: A locally linear latent dynamics model for control from raw images. In Advances in Neural Information Processing Systems, pages 2728-2736, 2015.\n\nA neural implementation of the Kalman Filter. C Robert, Leif H Wilson, Finkel, Proceedings of the Neural Information Processing Systems Conference (NIPS). the Neural Information Processing Systems Conference (NIPS)Robert C. Wilson and Leif H. Finkel. A neural implementation of the Kalman Filter. In Proceedings of the Neural Information Processing Systems Conference (NIPS), 2009.\n\nGalileo: Perceiving physical object properties by integrating a physics engine with deep learning. Jiajun Wu, Ilker Yildirim, J Joseph, Bill Lim, Josh Freeman, Tenenbaum, Advances in Neural Information Processing Systems. Jiajun Wu, Ilker Yildirim, Joseph J Lim, Bill Freeman, and Josh Tenenbaum. Galileo: Perceiving physical object properties by inte- grating a physics engine with deep learning. In Advances in Neural Information Processing Systems, pages 127-135, 2015.\n\n3d shapenets: A deep representation for volumetric shapes. Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, Jianxiong Xiao, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3d shapenets: A deep representation for volumetric shapes. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.\n\nPerspective transformer nets: Learning single-view 3d object reconstruction without 3d supervision. Xinchen Yan, Jimei Yang, Ersin Yumer, Yijie Guo, Honglak Lee, Advances in Neural Information Processing Systems (NIPS). Xinchen Yan, Jimei Yang, Ersin Yumer, Yijie Guo, and Honglak Lee. Perspective transformer nets: Learning single-view 3d object reconstruction without 3d supervision. In Advances in Neural Information Processing Systems (NIPS), pages 1696-1704, 2016.\n\nPhysical problem solving: Joint planning with symbolic, geometric, and dynamic constraints. Ilker Yildirim, Tobias Gerstenberg, Basil Saeed, Marc Toussaint, Josh Tenenbaum, arXiv:1707.08212arXiv preprintIlker Yildirim, Tobias Gerstenberg, Basil Saeed, Marc Toussaint, and Josh Tenenbaum. Physical problem solving: Joint planning with symbolic, geometric, and dynamic constraints. arXiv preprint arXiv:1707.08212, 2017.\n\nUnderstanding deep learning requires rethinking generalization. Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals, abs/1611.03530CoRRChiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. CoRR, abs/1611.03530, 2016.\n\nTowards vision-based deep reinforcement learning for robotic motion control. Fangyi Zhang, J\u00fcrgen Leitner, Michael Milford, Ben Upcroft, Peter Corke, Australasian Conference on Robotics and Automation. Fangyi Zhang, J\u00fcrgen Leitner, Michael Milford, Ben Upcroft, and Peter Corke. Towards vision-based deep reinforcement learning for robotic motion control. In Australasian Conference on Robotics and Automation, 2015.\n\nSparse representation-based open set recognition. He Zhang, Vishal Patel, IEEE Transactions on Pattern Analysis and Machine Intelligence. 99PPHe Zhang and Vishal Patel. Sparse representation-based open set recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, PP(99):1-1, 2016.\n\nDeepcontext: context-encoding neural pathways for 3d holistic scene understanding. Yinda Zhang, Mingru Bai, Pushmeet Kohli, Shahram Izadi, Jianxiong Xiao, IEEE International Conference on Computer Vision (ICCV. Yinda Zhang, Mingru Bai, Pushmeet Kohli, Shahram Izadi, and Jianxiong Xiao. Deepcontext: context-encoding neural pathways for 3d holistic scene understanding. In IEEE International Conference on Computer Vision (ICCV), 2017.\n\nRethinking reprojection: Closing the loop for pose-aware shape reconstruction from a single image. Rui Zhu, Chaoyang Hamed Kiani Galoogahi, Simon Wang, Lucey, IEEE International Conference on Computer Vision (ICCV). IEEERui Zhu, Hamed Kiani Galoogahi, Chaoyang Wang, and Simon Lucey. Rethinking reprojection: Closing the loop for pose-aware shape reconstruction from a single image. In IEEE International Conference on Computer Vision (ICCV), pages 57-65. IEEE, 2017.\n\nTarget-driven visual navigation in indoor scenes using deep reinforcement learning. Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph J Lim, Abhinav Gupta, Li Fei-Fei, Ali Farhadi, abs/1609.05143CoRRYuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph J. Lim, Abhinav Gupta, Li Fei-Fei, and Ali Farhadi. Target-driven visual naviga- tion in indoor scenes using deep reinforcement learning. CoRR, abs/1609.05143, 2016.\n", "annotations": {"author": "[{\"end\":75,\"start\":59},{\"end\":89,\"start\":76},{\"end\":106,\"start\":90},{\"end\":120,\"start\":107},{\"end\":132,\"start\":121},{\"end\":148,\"start\":133},{\"end\":161,\"start\":149},{\"end\":176,\"start\":162},{\"end\":193,\"start\":177},{\"end\":210,\"start\":194},{\"end\":223,\"start\":211}]", "publisher": null, "author_last_name": "[{\"end\":74,\"start\":64},{\"end\":88,\"start\":83},{\"end\":105,\"start\":97},{\"end\":119,\"start\":112},{\"end\":131,\"start\":128},{\"end\":147,\"start\":140},{\"end\":160,\"start\":153},{\"end\":175,\"start\":169},{\"end\":192,\"start\":185},{\"end\":209,\"start\":202},{\"end\":222,\"start\":217}]", "author_first_name": "[{\"end\":63,\"start\":59},{\"end\":82,\"start\":76},{\"end\":96,\"start\":90},{\"end\":111,\"start\":107},{\"end\":127,\"start\":121},{\"end\":139,\"start\":133},{\"end\":152,\"start\":149},{\"end\":168,\"start\":162},{\"end\":184,\"start\":177},{\"end\":201,\"start\":194},{\"end\":216,\"start\":211}]", "author_affiliation": null, "title": "[{\"end\":56,\"start\":1},{\"end\":279,\"start\":224}]", "venue": null, "abstract": "[{\"end\":1003,\"start\":281}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b112\"},\"end\":3183,\"start\":3178},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":5375,\"start\":5371},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":5381,\"start\":5377},{\"attributes\":{\"ref_id\":\"b116\"},\"end\":5388,\"start\":5383},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5878,\"start\":5874},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":5884,\"start\":5880},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":5916,\"start\":5912},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":5922,\"start\":5918},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":5972,\"start\":5968},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":5978,\"start\":5974},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":6003,\"start\":5999},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6136,\"start\":6132},{\"attributes\":{\"ref_id\":\"b119\"},\"end\":6143,\"start\":6138},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6525,\"start\":6521},{\"attributes\":{\"ref_id\":\"b100\"},\"end\":6532,\"start\":6527},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":6815,\"start\":6811},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":6821,\"start\":6817},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7026,\"start\":7022},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":7032,\"start\":7028},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":7104,\"start\":7100},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7336,\"start\":7332},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7342,\"start\":7338},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":7348,\"start\":7344},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":7845,\"start\":7841},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7935,\"start\":7931},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":7941,\"start\":7937},{\"attributes\":{\"ref_id\":\"b91\"},\"end\":7947,\"start\":7943},{\"attributes\":{\"ref_id\":\"b98\"},\"end\":7953,\"start\":7949},{\"attributes\":{\"ref_id\":\"b123\"},\"end\":7960,\"start\":7955},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7977,\"start\":7973},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7983,\"start\":7979},{\"attributes\":{\"ref_id\":\"b125\"},\"end\":7990,\"start\":7985},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":8043,\"start\":8039},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":8049,\"start\":8045},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":8055,\"start\":8051},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":8172,\"start\":8168},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":8178,\"start\":8174},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8790,\"start\":8786},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8896,\"start\":8892},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8902,\"start\":8898},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10408,\"start\":10407},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":12546,\"start\":12542},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":14045,\"start\":14041},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14103,\"start\":14099},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":14656,\"start\":14653},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14662,\"start\":14658},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":14668,\"start\":14664},{\"attributes\":{\"ref_id\":\"b129\"},\"end\":14675,\"start\":14670},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":14731,\"start\":14727},{\"attributes\":{\"ref_id\":\"b124\"},\"end\":15618,\"start\":15613},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":15869,\"start\":15865},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":15912,\"start\":15908},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":15979,\"start\":15975},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":16337,\"start\":16333},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":16910,\"start\":16906},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":16916,\"start\":16912},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":16955,\"start\":16951},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":16961,\"start\":16957},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":16967,\"start\":16963},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":17338,\"start\":17334},{\"attributes\":{\"ref_id\":\"b110\"},\"end\":17671,\"start\":17666},{\"attributes\":{\"ref_id\":\"b135\"},\"end\":17695,\"start\":17690},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":18101,\"start\":18097},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":18107,\"start\":18103},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":18113,\"start\":18109},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18278,\"start\":18274},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":18284,\"start\":18280},{\"attributes\":{\"ref_id\":\"b130\"},\"end\":18291,\"start\":18286},{\"attributes\":{\"ref_id\":\"b136\"},\"end\":18298,\"start\":18293},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":19193,\"start\":19189},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":19199,\"start\":19195},{\"attributes\":{\"ref_id\":\"b97\"},\"end\":19205,\"start\":19201},{\"attributes\":{\"ref_id\":\"b113\"},\"end\":19212,\"start\":19207},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":20940,\"start\":20936},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":21268,\"start\":21265},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":21409,\"start\":21408},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21673,\"start\":21672},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":22230,\"start\":22226},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":22236,\"start\":22232},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":22242,\"start\":22238},{\"attributes\":{\"ref_id\":\"b114\"},\"end\":22249,\"start\":22244},{\"attributes\":{\"ref_id\":\"b101\"},\"end\":22693,\"start\":22688},{\"attributes\":{\"ref_id\":\"b102\"},\"end\":23784,\"start\":23779},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":23849,\"start\":23845},{\"attributes\":{\"ref_id\":\"b102\"},\"end\":24752,\"start\":24747},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":24976,\"start\":24972},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":25329,\"start\":25325},{\"attributes\":{\"ref_id\":\"b114\"},\"end\":25336,\"start\":25331},{\"attributes\":{\"ref_id\":\"b101\"},\"end\":25825,\"start\":25820},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":25858,\"start\":25854},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":25930,\"start\":25926},{\"attributes\":{\"ref_id\":\"b102\"},\"end\":25937,\"start\":25932},{\"attributes\":{\"ref_id\":\"b134\"},\"end\":25944,\"start\":25939},{\"attributes\":{\"ref_id\":\"b114\"},\"end\":26331,\"start\":26326},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":26364,\"start\":26360},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":27603,\"start\":27599},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":28322,\"start\":28318},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":28597,\"start\":28593},{\"attributes\":{\"ref_id\":\"b99\"},\"end\":30246,\"start\":30241},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":31591,\"start\":31587},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":31597,\"start\":31593},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":31603,\"start\":31599},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":31609,\"start\":31605},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":31615,\"start\":31611},{\"attributes\":{\"ref_id\":\"b105\"},\"end\":31622,\"start\":31617},{\"attributes\":{\"ref_id\":\"b106\"},\"end\":31629,\"start\":31624},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":32251,\"start\":32247},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":34045,\"start\":34041},{\"attributes\":{\"ref_id\":\"b109\"},\"end\":34052,\"start\":34047},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":34191,\"start\":34187},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":34449,\"start\":34445},{\"attributes\":{\"ref_id\":\"b121\"},\"end\":34573,\"start\":34568},{\"attributes\":{\"ref_id\":\"b122\"},\"end\":34580,\"start\":34575},{\"attributes\":{\"ref_id\":\"b120\"},\"end\":34591,\"start\":34586},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":35022,\"start\":35019},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":35028,\"start\":35024},{\"attributes\":{\"ref_id\":\"b133\"},\"end\":35035,\"start\":35030},{\"attributes\":{\"ref_id\":\"b137\"},\"end\":35042,\"start\":35037},{\"attributes\":{\"ref_id\":\"b96\"},\"end\":35241,\"start\":35237},{\"attributes\":{\"ref_id\":\"b117\"},\"end\":35248,\"start\":35243},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":35329,\"start\":35325},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":37090,\"start\":37086},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":37096,\"start\":37092},{\"attributes\":{\"ref_id\":\"b104\"},\"end\":37103,\"start\":37098},{\"attributes\":{\"ref_id\":\"b118\"},\"end\":37110,\"start\":37105},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":37636,\"start\":37633},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":37641,\"start\":37638},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":37647,\"start\":37643},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":37653,\"start\":37649},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":37659,\"start\":37655},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":37665,\"start\":37661},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":38061,\"start\":38058},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":38067,\"start\":38063},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":38073,\"start\":38069},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":38079,\"start\":38075},{\"attributes\":{\"ref_id\":\"b128\"},\"end\":38086,\"start\":38081},{\"attributes\":{\"ref_id\":\"b131\"},\"end\":38093,\"start\":38088},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":40208,\"start\":40205},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":40214,\"start\":40210},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":40220,\"start\":40216},{\"attributes\":{\"ref_id\":\"b126\"},\"end\":40227,\"start\":40222},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":41657,\"start\":41656},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":47307,\"start\":47303},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":47506,\"start\":47502},{\"attributes\":{\"ref_id\":\"b132\"},\"end\":47756,\"start\":47751},{\"attributes\":{\"ref_id\":\"b132\"},\"end\":47888,\"start\":47883},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":48061,\"start\":48057},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":48865,\"start\":48861},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":49611,\"start\":49607},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":49617,\"start\":49613},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":49623,\"start\":49619},{\"attributes\":{\"ref_id\":\"b107\"},\"end\":49630,\"start\":49625},{\"attributes\":{\"ref_id\":\"b115\"},\"end\":49637,\"start\":49632},{\"attributes\":{\"ref_id\":\"b127\"},\"end\":49644,\"start\":49639},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":49683,\"start\":49679},{\"attributes\":{\"ref_id\":\"b108\"},\"end\":50056,\"start\":50051},{\"attributes\":{\"ref_id\":\"b103\"},\"end\":50313,\"start\":50308},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":50591,\"start\":50587},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":50750,\"start\":50746},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":54129,\"start\":54125},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":54577,\"start\":54573},{\"attributes\":{\"ref_id\":\"b112\"},\"end\":55544,\"start\":55539},{\"attributes\":{\"ref_id\":\"b111\"},\"end\":55795,\"start\":55790},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":55975,\"start\":55972},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":55989,\"start\":55985},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":56284,\"start\":56281}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":57708,\"start\":57529},{\"attributes\":{\"id\":\"fig_1\"},\"end\":58008,\"start\":57709},{\"attributes\":{\"id\":\"fig_2\"},\"end\":58027,\"start\":58009},{\"attributes\":{\"id\":\"fig_3\"},\"end\":58382,\"start\":58028},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":58477,\"start\":58383},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":58788,\"start\":58478},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":58888,\"start\":58789},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":59804,\"start\":58889}]", "paragraph": "[{\"end\":1462,\"start\":1022},{\"end\":2070,\"start\":1464},{\"end\":2555,\"start\":2072},{\"end\":2893,\"start\":2557},{\"end\":3511,\"start\":2895},{\"end\":4444,\"start\":3566},{\"end\":4778,\"start\":4446},{\"end\":5060,\"start\":4805},{\"end\":5777,\"start\":5062},{\"end\":6004,\"start\":5779},{\"end\":6480,\"start\":6006},{\"end\":7105,\"start\":6482},{\"end\":7510,\"start\":7107},{\"end\":8116,\"start\":7545},{\"end\":9050,\"start\":8118},{\"end\":9472,\"start\":9079},{\"end\":10152,\"start\":9474},{\"end\":10180,\"start\":10154},{\"end\":10429,\"start\":10182},{\"end\":10590,\"start\":10431},{\"end\":10769,\"start\":10612},{\"end\":10999,\"start\":10771},{\"end\":11023,\"start\":11001},{\"end\":11521,\"start\":11025},{\"end\":11715,\"start\":11523},{\"end\":11930,\"start\":11717},{\"end\":11936,\"start\":11932},{\"end\":12065,\"start\":11938},{\"end\":12517,\"start\":12067},{\"end\":12790,\"start\":12519},{\"end\":13311,\"start\":12792},{\"end\":14104,\"start\":13313},{\"end\":14553,\"start\":14106},{\"end\":15043,\"start\":14555},{\"end\":15532,\"start\":15079},{\"end\":15980,\"start\":15560},{\"end\":16188,\"start\":15982},{\"end\":16772,\"start\":16190},{\"end\":17309,\"start\":16774},{\"end\":17843,\"start\":17311},{\"end\":18479,\"start\":17845},{\"end\":18972,\"start\":18481},{\"end\":19446,\"start\":18974},{\"end\":20116,\"start\":19448},{\"end\":21435,\"start\":20188},{\"end\":21700,\"start\":21437},{\"end\":21921,\"start\":21702},{\"end\":21927,\"start\":21923},{\"end\":22142,\"start\":21929},{\"end\":23181,\"start\":22144},{\"end\":25337,\"start\":23224},{\"end\":26183,\"start\":25340},{\"end\":27923,\"start\":26229},{\"end\":29439,\"start\":27925},{\"end\":30895,\"start\":29441},{\"end\":31358,\"start\":30955},{\"end\":31959,\"start\":31360},{\"end\":33223,\"start\":31961},{\"end\":35249,\"start\":33225},{\"end\":36198,\"start\":35251},{\"end\":36642,\"start\":36303},{\"end\":37546,\"start\":36688},{\"end\":40048,\"start\":37548},{\"end\":40228,\"start\":40050},{\"end\":41407,\"start\":40230},{\"end\":42653,\"start\":41452},{\"end\":43337,\"start\":42681},{\"end\":44033,\"start\":43339},{\"end\":44081,\"start\":44035},{\"end\":44792,\"start\":44083},{\"end\":45705,\"start\":44794},{\"end\":46375,\"start\":45707},{\"end\":47123,\"start\":46430},{\"end\":47578,\"start\":47125},{\"end\":48273,\"start\":47580},{\"end\":48866,\"start\":48275},{\"end\":49341,\"start\":48868},{\"end\":49835,\"start\":49343},{\"end\":51163,\"start\":49867},{\"end\":51519,\"start\":51165},{\"end\":52516,\"start\":51546},{\"end\":53227,\"start\":52518},{\"end\":53734,\"start\":53229},{\"end\":54391,\"start\":53736},{\"end\":54717,\"start\":54393},{\"end\":54740,\"start\":54719},{\"end\":55259,\"start\":54742},{\"end\":56299,\"start\":55280},{\"end\":56932,\"start\":56301},{\"end\":57528,\"start\":56934}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":25339,\"start\":25338},{\"attributes\":{\"id\":\"formula_1\"},\"end\":36302,\"start\":36199}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":4777,\"start\":4755},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":40016,\"start\":40008}]", "section_header": "[{\"end\":1020,\"start\":1005},{\"end\":3564,\"start\":3514},{\"end\":4803,\"start\":4781},{\"end\":7543,\"start\":7513},{\"end\":9077,\"start\":9053},{\"attributes\":{\"n\":\"2\"},\"end\":10610,\"start\":10593},{\"end\":15077,\"start\":15046},{\"end\":15558,\"start\":15535},{\"end\":20186,\"start\":20119},{\"end\":23222,\"start\":23184},{\"end\":26227,\"start\":26186},{\"end\":30953,\"start\":30898},{\"end\":36686,\"start\":36645},{\"end\":41450,\"start\":41410},{\"end\":42679,\"start\":42656},{\"end\":46428,\"start\":46378},{\"end\":49865,\"start\":49838},{\"end\":51544,\"start\":51522},{\"end\":55278,\"start\":55262},{\"end\":57538,\"start\":57530},{\"end\":58018,\"start\":58010},{\"end\":58037,\"start\":58029},{\"end\":58400,\"start\":58384},{\"end\":58498,\"start\":58479},{\"end\":58809,\"start\":58790},{\"end\":58898,\"start\":58890}]", "table": "[{\"end\":58477,\"start\":58431},{\"end\":58788,\"start\":58501},{\"end\":58888,\"start\":58842},{\"end\":59804,\"start\":58901}]", "figure_caption": "[{\"end\":57708,\"start\":57540},{\"end\":58008,\"start\":57711},{\"end\":58027,\"start\":58020},{\"end\":58382,\"start\":58039},{\"end\":58431,\"start\":58402},{\"end\":58842,\"start\":58813}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":32164,\"start\":32156},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":35531,\"start\":35523}]", "bib_author_first_name": "[{\"end\":60275,\"start\":60274},{\"end\":60286,\"start\":60285},{\"end\":60288,\"start\":60287},{\"end\":60296,\"start\":60295},{\"end\":60306,\"start\":60305},{\"end\":60315,\"start\":60314},{\"end\":60586,\"start\":60580},{\"end\":60604,\"start\":60597},{\"end\":60620,\"start\":60615},{\"end\":60633,\"start\":60629},{\"end\":60652,\"start\":60646},{\"end\":60665,\"start\":60662},{\"end\":60677,\"start\":60672},{\"end\":60679,\"start\":60678},{\"end\":60691,\"start\":60686},{\"end\":60705,\"start\":60699},{\"end\":60721,\"start\":60714},{\"end\":60738,\"start\":60731},{\"end\":60751,\"start\":60748},{\"end\":60763,\"start\":60758},{\"end\":61270,\"start\":61264},{\"end\":61272,\"start\":61271},{\"end\":61494,\"start\":61487},{\"end\":61512,\"start\":61505},{\"end\":61529,\"start\":61523},{\"end\":61532,\"start\":61530},{\"end\":61543,\"start\":61537},{\"end\":61545,\"start\":61544},{\"end\":61560,\"start\":61554},{\"end\":61877,\"start\":61876},{\"end\":61892,\"start\":61891},{\"end\":61898,\"start\":61897},{\"end\":61909,\"start\":61908},{\"end\":62291,\"start\":62290},{\"end\":62306,\"start\":62305},{\"end\":62317,\"start\":62316},{\"end\":62323,\"start\":62322},{\"end\":62334,\"start\":62333},{\"end\":62343,\"start\":62342},{\"end\":62345,\"start\":62344},{\"end\":62358,\"start\":62357},{\"end\":62693,\"start\":62687},{\"end\":62710,\"start\":62703},{\"end\":62712,\"start\":62711},{\"end\":62726,\"start\":62721},{\"end\":63187,\"start\":63182},{\"end\":63205,\"start\":63199},{\"end\":63222,\"start\":63215},{\"end\":63234,\"start\":63228},{\"end\":63588,\"start\":63587},{\"end\":63603,\"start\":63596},{\"end\":63605,\"start\":63604},{\"end\":63623,\"start\":63617},{\"end\":63625,\"start\":63624},{\"end\":63967,\"start\":63960},{\"end\":63985,\"start\":63977},{\"end\":63987,\"start\":63986},{\"end\":64359,\"start\":64352},{\"end\":64377,\"start\":64369},{\"end\":64379,\"start\":64378},{\"end\":64755,\"start\":64751},{\"end\":64769,\"start\":64768},{\"end\":64780,\"start\":64776},{\"end\":64798,\"start\":64792},{\"end\":64815,\"start\":64809},{\"end\":65151,\"start\":65144},{\"end\":65165,\"start\":65161},{\"end\":65179,\"start\":65173},{\"end\":65186,\"start\":65180},{\"end\":65194,\"start\":65189},{\"end\":65213,\"start\":65207},{\"end\":65604,\"start\":65598},{\"end\":65619,\"start\":65612},{\"end\":65621,\"start\":65620},{\"end\":65636,\"start\":65628},{\"end\":65638,\"start\":65637},{\"end\":65858,\"start\":65857},{\"end\":65869,\"start\":65868},{\"end\":66278,\"start\":66277},{\"end\":66289,\"start\":66288},{\"end\":66297,\"start\":66296},{\"end\":66306,\"start\":66305},{\"end\":66745,\"start\":66744},{\"end\":66759,\"start\":66758},{\"end\":66767,\"start\":66766},{\"end\":67119,\"start\":67114},{\"end\":67132,\"start\":67128},{\"end\":67147,\"start\":67142},{\"end\":67163,\"start\":67158},{\"end\":67177,\"start\":67171},{\"end\":67194,\"start\":67190},{\"end\":67205,\"start\":67202},{\"end\":67218,\"start\":67212},{\"end\":67618,\"start\":67617},{\"end\":67638,\"start\":67632},{\"end\":67653,\"start\":67645},{\"end\":67663,\"start\":67658},{\"end\":67676,\"start\":67670},{\"end\":68037,\"start\":68031},{\"end\":68068,\"start\":68052},{\"end\":68349,\"start\":68348},{\"end\":68363,\"start\":68357},{\"end\":68536,\"start\":68528},{\"end\":68832,\"start\":68827},{\"end\":68845,\"start\":68841},{\"end\":68863,\"start\":68858},{\"end\":69231,\"start\":69224},{\"end\":69250,\"start\":69245},{\"end\":69272,\"start\":69265},{\"end\":69294,\"start\":69286},{\"end\":69743,\"start\":69738},{\"end\":69745,\"start\":69744},{\"end\":69763,\"start\":69757},{\"end\":69765,\"start\":69764},{\"end\":70001,\"start\":69994},{\"end\":70014,\"start\":70008},{\"end\":70029,\"start\":70023},{\"end\":70314,\"start\":70309},{\"end\":70326,\"start\":70320},{\"end\":70599,\"start\":70594},{\"end\":70612,\"start\":70605},{\"end\":70626,\"start\":70620},{\"end\":70908,\"start\":70900},{\"end\":70924,\"start\":70916},{\"end\":70939,\"start\":70935},{\"end\":70954,\"start\":70948},{\"end\":70968,\"start\":70964},{\"end\":70989,\"start\":70981},{\"end\":71007,\"start\":71002},{\"end\":71024,\"start\":71018},{\"end\":71026,\"start\":71025},{\"end\":71355,\"start\":71351},{\"end\":71369,\"start\":71362},{\"end\":71383,\"start\":71380},{\"end\":71707,\"start\":71700},{\"end\":71721,\"start\":71716},{\"end\":71740,\"start\":71733},{\"end\":71742,\"start\":71741},{\"end\":72034,\"start\":72029},{\"end\":72051,\"start\":72046},{\"end\":72243,\"start\":72242},{\"end\":72254,\"start\":72249},{\"end\":72269,\"start\":72267},{\"end\":72282,\"start\":72277},{\"end\":72295,\"start\":72289},{\"end\":72549,\"start\":72548},{\"end\":72869,\"start\":72864},{\"end\":72883,\"start\":72877},{\"end\":73208,\"start\":73200},{\"end\":73220,\"start\":73213},{\"end\":73222,\"start\":73221},{\"end\":73238,\"start\":73234},{\"end\":73256,\"start\":73250},{\"end\":73430,\"start\":73425},{\"end\":73441,\"start\":73436},{\"end\":73452,\"start\":73450},{\"end\":73466,\"start\":73458},{\"end\":73768,\"start\":73762},{\"end\":73785,\"start\":73779},{\"end\":73798,\"start\":73792},{\"end\":73813,\"start\":73807},{\"end\":74073,\"start\":74064},{\"end\":74087,\"start\":74080},{\"end\":74106,\"start\":74098},{\"end\":74376,\"start\":74369},{\"end\":74392,\"start\":74388},{\"end\":74600,\"start\":74593},{\"end\":74612,\"start\":74605},{\"end\":74628,\"start\":74623},{\"end\":74641,\"start\":74637},{\"end\":74925,\"start\":74918},{\"end\":74940,\"start\":74933},{\"end\":74953,\"start\":74948},{\"end\":74969,\"start\":74962},{\"end\":74971,\"start\":74970},{\"end\":74986,\"start\":74983},{\"end\":74998,\"start\":74993},{\"end\":75593,\"start\":75590},{\"end\":75610,\"start\":75605},{\"end\":75965,\"start\":75964},{\"end\":75975,\"start\":75974},{\"end\":75986,\"start\":75985},{\"end\":76001,\"start\":76000},{\"end\":76266,\"start\":76258},{\"end\":76280,\"start\":76275},{\"end\":76294,\"start\":76290},{\"end\":76517,\"start\":76508},{\"end\":76532,\"start\":76525},{\"end\":76545,\"start\":76541},{\"end\":76566,\"start\":76560},{\"end\":76579,\"start\":76574},{\"end\":76986,\"start\":76985},{\"end\":76995,\"start\":76994},{\"end\":77177,\"start\":77173},{\"end\":77198,\"start\":77192},{\"end\":77401,\"start\":77397},{\"end\":77422,\"start\":77416},{\"end\":77858,\"start\":77854},{\"end\":77879,\"start\":77873},{\"end\":77896,\"start\":77888},{\"end\":77911,\"start\":77905},{\"end\":78199,\"start\":78195},{\"end\":78223,\"start\":78214},{\"end\":78237,\"start\":78231},{\"end\":78427,\"start\":78426},{\"end\":78436,\"start\":78435},{\"end\":78450,\"start\":78449},{\"end\":78461,\"start\":78460},{\"end\":78468,\"start\":78467},{\"end\":78479,\"start\":78478},{\"end\":78815,\"start\":78811},{\"end\":78830,\"start\":78825},{\"end\":79058,\"start\":79052},{\"end\":79074,\"start\":79068},{\"end\":79090,\"start\":79086},{\"end\":79315,\"start\":79309},{\"end\":79341,\"start\":79335},{\"end\":79354,\"start\":79351},{\"end\":79743,\"start\":79742},{\"end\":79757,\"start\":79756},{\"end\":79766,\"start\":79765},{\"end\":79776,\"start\":79775},{\"end\":79790,\"start\":79789},{\"end\":79797,\"start\":79796},{\"end\":79810,\"start\":79809},{\"end\":79820,\"start\":79819},{\"end\":79830,\"start\":79829},{\"end\":80159,\"start\":80158},{\"end\":80171,\"start\":80170},{\"end\":80183,\"start\":80182},{\"end\":80195,\"start\":80194},{\"end\":80207,\"start\":80206},{\"end\":80628,\"start\":80624},{\"end\":80643,\"start\":80636},{\"end\":80916,\"start\":80910},{\"end\":80939,\"start\":80933},{\"end\":80941,\"start\":80940},{\"end\":81237,\"start\":81231},{\"end\":81265,\"start\":81256},{\"end\":81282,\"start\":81275},{\"end\":81653,\"start\":81647},{\"end\":81668,\"start\":81662},{\"end\":82189,\"start\":82183},{\"end\":82205,\"start\":82198},{\"end\":82218,\"start\":82212},{\"end\":82234,\"start\":82228},{\"end\":82574,\"start\":82567},{\"end\":82576,\"start\":82575},{\"end\":82596,\"start\":82588},{\"end\":82598,\"start\":82597},{\"end\":82614,\"start\":82605},{\"end\":82631,\"start\":82624},{\"end\":82642,\"start\":82639},{\"end\":82958,\"start\":82953},{\"end\":82969,\"start\":82964},{\"end\":82984,\"start\":82978},{\"end\":83419,\"start\":83414},{\"end\":83432,\"start\":83425},{\"end\":83447,\"start\":83439},{\"end\":83456,\"start\":83453},{\"end\":83796,\"start\":83793},{\"end\":83810,\"start\":83802},{\"end\":83828,\"start\":83821},{\"end\":83845,\"start\":83836},{\"end\":83860,\"start\":83855},{\"end\":83877,\"start\":83867},{\"end\":83893,\"start\":83882},{\"end\":84257,\"start\":84252},{\"end\":84512,\"start\":84504},{\"end\":84529,\"start\":84523},{\"end\":84720,\"start\":84711},{\"end\":84730,\"start\":84727},{\"end\":84743,\"start\":84736},{\"end\":84757,\"start\":84750},{\"end\":84759,\"start\":84758},{\"end\":85221,\"start\":85216},{\"end\":85237,\"start\":85233},{\"end\":85254,\"start\":85246},{\"end\":85274,\"start\":85266},{\"end\":85513,\"start\":85512},{\"end\":85515,\"start\":85514},{\"end\":85749,\"start\":85743},{\"end\":85763,\"start\":85758},{\"end\":85778,\"start\":85771},{\"end\":85791,\"start\":85788},{\"end\":85819,\"start\":85818},{\"end\":86140,\"start\":86133},{\"end\":86366,\"start\":86360},{\"end\":86381,\"start\":86376},{\"end\":86398,\"start\":86391},{\"end\":86418,\"start\":86410},{\"end\":86752,\"start\":86746},{\"end\":86768,\"start\":86761},{\"end\":86785,\"start\":86780},{\"end\":86798,\"start\":86794},{\"end\":87142,\"start\":87133},{\"end\":87153,\"start\":87149},{\"end\":87165,\"start\":87154},{\"end\":87178,\"start\":87173},{\"end\":87190,\"start\":87186},{\"end\":87206,\"start\":87199},{\"end\":87208,\"start\":87207},{\"end\":87223,\"start\":87220},{\"end\":87237,\"start\":87232},{\"end\":87251,\"start\":87246},{\"end\":87588,\"start\":87587},{\"end\":87830,\"start\":87827},{\"end\":87844,\"start\":87839},{\"end\":87859,\"start\":87855},{\"end\":88349,\"start\":88346},{\"end\":88363,\"start\":88358},{\"end\":88378,\"start\":88374},{\"end\":88822,\"start\":88818},{\"end\":88837,\"start\":88830},{\"end\":89118,\"start\":89112},{\"end\":89142,\"start\":89131},{\"end\":89154,\"start\":89149},{\"end\":89156,\"start\":89155},{\"end\":89169,\"start\":89165},{\"end\":89171,\"start\":89170},{\"end\":89627,\"start\":89626},{\"end\":89646,\"start\":89636},{\"end\":89660,\"start\":89654},{\"end\":89674,\"start\":89670},{\"end\":89958,\"start\":89950},{\"end\":89972,\"start\":89965},{\"end\":89983,\"start\":89978},{\"end\":89993,\"start\":89989},{\"end\":90364,\"start\":90360},{\"end\":90519,\"start\":90513},{\"end\":90532,\"start\":90528},{\"end\":90697,\"start\":90691},{\"end\":90710,\"start\":90706},{\"end\":90726,\"start\":90720},{\"end\":90745,\"start\":90739},{\"end\":90762,\"start\":90757},{\"end\":91246,\"start\":91245},{\"end\":91416,\"start\":91411},{\"end\":91432,\"start\":91425},{\"end\":91448,\"start\":91443},{\"end\":91463,\"start\":91458},{\"end\":91479,\"start\":91473},{\"end\":91753,\"start\":91744},{\"end\":91785,\"start\":91780},{\"end\":91807,\"start\":91798},{\"end\":91809,\"start\":91808},{\"end\":92074,\"start\":92068},{\"end\":92086,\"start\":92083},{\"end\":92364,\"start\":92358},{\"end\":92377,\"start\":92374},{\"end\":92394,\"start\":92389},{\"end\":92407,\"start\":92403},{\"end\":92738,\"start\":92731},{\"end\":92761,\"start\":92755},{\"end\":92763,\"start\":92762},{\"end\":92779,\"start\":92773},{\"end\":92781,\"start\":92780},{\"end\":93008,\"start\":93007},{\"end\":93149,\"start\":93143},{\"end\":93319,\"start\":93313},{\"end\":93330,\"start\":93326},{\"end\":93352,\"start\":93343},{\"end\":93371,\"start\":93365},{\"end\":93384,\"start\":93379},{\"end\":93403,\"start\":93398},{\"end\":93788,\"start\":93779},{\"end\":93804,\"start\":93798},{\"end\":94054,\"start\":94053},{\"end\":94070,\"start\":94063},{\"end\":94072,\"start\":94071},{\"end\":94092,\"start\":94087},{\"end\":94114,\"start\":94113},{\"end\":94116,\"start\":94115},{\"end\":94131,\"start\":94123},{\"end\":94619,\"start\":94615},{\"end\":94635,\"start\":94629},{\"end\":94653,\"start\":94646},{\"end\":94669,\"start\":94665},{\"end\":94687,\"start\":94680},{\"end\":95034,\"start\":95033},{\"end\":95046,\"start\":95043},{\"end\":95048,\"start\":95047},{\"end\":95062,\"start\":95059},{\"end\":95077,\"start\":95072},{\"end\":95079,\"start\":95078},{\"end\":95428,\"start\":95427},{\"end\":95445,\"start\":95437},{\"end\":95475,\"start\":95468},{\"end\":95491,\"start\":95483},{\"end\":95493,\"start\":95492},{\"end\":95812,\"start\":95811},{\"end\":95829,\"start\":95821},{\"end\":95859,\"start\":95852},{\"end\":95875,\"start\":95867},{\"end\":95877,\"start\":95876},{\"end\":96219,\"start\":96218},{\"end\":96233,\"start\":96228},{\"end\":96235,\"start\":96234},{\"end\":96254,\"start\":96246},{\"end\":96256,\"start\":96255},{\"end\":96601,\"start\":96594},{\"end\":96847,\"start\":96846},{\"end\":96858,\"start\":96857},{\"end\":96870,\"start\":96869},{\"end\":96882,\"start\":96881},{\"end\":96892,\"start\":96891},{\"end\":96901,\"start\":96900},{\"end\":97335,\"start\":97331},{\"end\":97352,\"start\":97346},{\"end\":97368,\"start\":97361},{\"end\":97384,\"start\":97377},{\"end\":97386,\"start\":97385},{\"end\":97401,\"start\":97395},{\"end\":97832,\"start\":97828},{\"end\":97850,\"start\":97843},{\"end\":97865,\"start\":97859},{\"end\":97881,\"start\":97874},{\"end\":97896,\"start\":97890},{\"end\":98379,\"start\":98376},{\"end\":98391,\"start\":98385},{\"end\":98393,\"start\":98392},{\"end\":98781,\"start\":98774},{\"end\":98783,\"start\":98782},{\"end\":98967,\"start\":98964},{\"end\":98979,\"start\":98972},{\"end\":98991,\"start\":98980},{\"end\":99003,\"start\":98996},{\"end\":99016,\"start\":99008},{\"end\":99018,\"start\":99017},{\"end\":99480,\"start\":99476},{\"end\":99498,\"start\":99493},{\"end\":99511,\"start\":99507},{\"end\":99524,\"start\":99521},{\"end\":99537,\"start\":99533},{\"end\":99551,\"start\":99546},{\"end\":99565,\"start\":99559},{\"end\":99576,\"start\":99573},{\"end\":99593,\"start\":99586},{\"end\":99978,\"start\":99974},{\"end\":99997,\"start\":99991},{\"end\":100013,\"start\":100007},{\"end\":100029,\"start\":100022},{\"end\":100044,\"start\":100039},{\"end\":100382,\"start\":100378},{\"end\":100401,\"start\":100395},{\"end\":100418,\"start\":100411},{\"end\":100431,\"start\":100428},{\"end\":100447,\"start\":100441},{\"end\":100463,\"start\":100456},{\"end\":100478,\"start\":100473},{\"end\":100953,\"start\":100949},{\"end\":100967,\"start\":100966},{\"end\":100980,\"start\":100975},{\"end\":100994,\"start\":100987},{\"end\":101005,\"start\":101002},{\"end\":101342,\"start\":101333},{\"end\":101360,\"start\":101352},{\"end\":101374,\"start\":101370},{\"end\":101390,\"start\":101386},{\"end\":101405,\"start\":101398},{\"end\":101416,\"start\":101413},{\"end\":101418,\"start\":101417},{\"end\":101434,\"start\":101431},{\"end\":101681,\"start\":101677},{\"end\":101695,\"start\":101689},{\"end\":101710,\"start\":101704},{\"end\":101867,\"start\":101858},{\"end\":101882,\"start\":101875},{\"end\":101898,\"start\":101892},{\"end\":102111,\"start\":102107},{\"end\":102125,\"start\":102119},{\"end\":102136,\"start\":102132},{\"end\":102147,\"start\":102142},{\"end\":102167,\"start\":102159},{\"end\":102183,\"start\":102177},{\"end\":102625,\"start\":102624},{\"end\":102636,\"start\":102635},{\"end\":102644,\"start\":102643},{\"end\":102915,\"start\":102908},{\"end\":102932,\"start\":102926},{\"end\":102934,\"start\":102933},{\"end\":103234,\"start\":103230},{\"end\":103248,\"start\":103242},{\"end\":103260,\"start\":103256},{\"end\":103277,\"start\":103270},{\"end\":103292,\"start\":103284},{\"end\":103305,\"start\":103299},{\"end\":103318,\"start\":103314},{\"end\":103333,\"start\":103327},{\"end\":103650,\"start\":103646},{\"end\":103662,\"start\":103658},{\"end\":103678,\"start\":103672},{\"end\":103692,\"start\":103688},{\"end\":104077,\"start\":104073},{\"end\":104089,\"start\":104085},{\"end\":104103,\"start\":104099},{\"end\":104115,\"start\":104111},{\"end\":104130,\"start\":104124},{\"end\":104359,\"start\":104354},{\"end\":104376,\"start\":104369},{\"end\":104390,\"start\":104387},{\"end\":104406,\"start\":104402},{\"end\":104702,\"start\":104693},{\"end\":104888,\"start\":104880},{\"end\":104902,\"start\":104895},{\"end\":105237,\"start\":105231},{\"end\":105250,\"start\":105246},{\"end\":105272,\"start\":105265},{\"end\":105290,\"start\":105284},{\"end\":105641,\"start\":105640},{\"end\":105654,\"start\":105650},{\"end\":105656,\"start\":105655},{\"end\":106082,\"start\":106076},{\"end\":106092,\"start\":106087},{\"end\":106104,\"start\":106103},{\"end\":106117,\"start\":106113},{\"end\":106127,\"start\":106123},{\"end\":106517,\"start\":106510},{\"end\":106528,\"start\":106522},{\"end\":106541,\"start\":106535},{\"end\":106556,\"start\":106550},{\"end\":106569,\"start\":106561},{\"end\":106583,\"start\":106577},{\"end\":106599,\"start\":106590},{\"end\":107029,\"start\":107022},{\"end\":107040,\"start\":107035},{\"end\":107052,\"start\":107047},{\"end\":107065,\"start\":107060},{\"end\":107078,\"start\":107071},{\"end\":107490,\"start\":107485},{\"end\":107507,\"start\":107501},{\"end\":107526,\"start\":107521},{\"end\":107538,\"start\":107534},{\"end\":107554,\"start\":107550},{\"end\":107884,\"start\":107877},{\"end\":107896,\"start\":107892},{\"end\":107911,\"start\":107905},{\"end\":107927,\"start\":107919},{\"end\":107940,\"start\":107935},{\"end\":108221,\"start\":108215},{\"end\":108235,\"start\":108229},{\"end\":108252,\"start\":108245},{\"end\":108265,\"start\":108262},{\"end\":108280,\"start\":108275},{\"end\":108608,\"start\":108606},{\"end\":108622,\"start\":108616},{\"end\":108946,\"start\":108941},{\"end\":108960,\"start\":108954},{\"end\":108974,\"start\":108966},{\"end\":108989,\"start\":108982},{\"end\":109006,\"start\":108997},{\"end\":109397,\"start\":109394},{\"end\":109411,\"start\":109403},{\"end\":109440,\"start\":109435},{\"end\":109852,\"start\":109848},{\"end\":109865,\"start\":109858},{\"end\":109880,\"start\":109876},{\"end\":109894,\"start\":109888},{\"end\":109896,\"start\":109895},{\"end\":109909,\"start\":109902},{\"end\":109919,\"start\":109917},{\"end\":109932,\"start\":109929}]", "bib_author_last_name": "[{\"end\":60283,\"start\":60276},{\"end\":60293,\"start\":60289},{\"end\":60303,\"start\":60297},{\"end\":60312,\"start\":60307},{\"end\":60322,\"start\":60316},{\"end\":60595,\"start\":60587},{\"end\":60613,\"start\":60605},{\"end\":60627,\"start\":60621},{\"end\":60644,\"start\":60634},{\"end\":60660,\"start\":60653},{\"end\":60670,\"start\":60666},{\"end\":60684,\"start\":60680},{\"end\":60697,\"start\":60692},{\"end\":60712,\"start\":60706},{\"end\":60729,\"start\":60722},{\"end\":60746,\"start\":60739},{\"end\":60756,\"start\":60752},{\"end\":60769,\"start\":60764},{\"end\":61280,\"start\":61273},{\"end\":61503,\"start\":61495},{\"end\":61521,\"start\":61513},{\"end\":61535,\"start\":61533},{\"end\":61552,\"start\":61546},{\"end\":61571,\"start\":61561},{\"end\":61889,\"start\":61878},{\"end\":61895,\"start\":61893},{\"end\":61906,\"start\":61899},{\"end\":61912,\"start\":61910},{\"end\":62303,\"start\":62292},{\"end\":62314,\"start\":62307},{\"end\":62320,\"start\":62318},{\"end\":62331,\"start\":62324},{\"end\":62340,\"start\":62335},{\"end\":62355,\"start\":62346},{\"end\":62366,\"start\":62359},{\"end\":62701,\"start\":62694},{\"end\":62719,\"start\":62713},{\"end\":62732,\"start\":62727},{\"end\":63197,\"start\":63188},{\"end\":63213,\"start\":63206},{\"end\":63226,\"start\":63223},{\"end\":63250,\"start\":63235},{\"end\":63594,\"start\":63589},{\"end\":63615,\"start\":63606},{\"end\":63633,\"start\":63626},{\"end\":63644,\"start\":63635},{\"end\":63975,\"start\":63968},{\"end\":63993,\"start\":63988},{\"end\":64367,\"start\":64360},{\"end\":64385,\"start\":64380},{\"end\":64766,\"start\":64756},{\"end\":64774,\"start\":64770},{\"end\":64790,\"start\":64781},{\"end\":64807,\"start\":64799},{\"end\":64820,\"start\":64816},{\"end\":64829,\"start\":64822},{\"end\":65159,\"start\":65152},{\"end\":65171,\"start\":65166},{\"end\":65205,\"start\":65195},{\"end\":65222,\"start\":65214},{\"end\":65610,\"start\":65605},{\"end\":65626,\"start\":65622},{\"end\":65647,\"start\":65639},{\"end\":65866,\"start\":65859},{\"end\":65873,\"start\":65870},{\"end\":66286,\"start\":66279},{\"end\":66294,\"start\":66290},{\"end\":66303,\"start\":66298},{\"end\":66310,\"start\":66307},{\"end\":66756,\"start\":66746},{\"end\":66764,\"start\":66760},{\"end\":66774,\"start\":66768},{\"end\":67126,\"start\":67120},{\"end\":67140,\"start\":67133},{\"end\":67156,\"start\":67148},{\"end\":67169,\"start\":67164},{\"end\":67188,\"start\":67178},{\"end\":67200,\"start\":67195},{\"end\":67210,\"start\":67206},{\"end\":67226,\"start\":67219},{\"end\":67630,\"start\":67619},{\"end\":67643,\"start\":67639},{\"end\":67656,\"start\":67654},{\"end\":67668,\"start\":67664},{\"end\":67681,\"start\":67677},{\"end\":67691,\"start\":67683},{\"end\":68050,\"start\":68038},{\"end\":68079,\"start\":68069},{\"end\":68355,\"start\":68350},{\"end\":68367,\"start\":68364},{\"end\":68373,\"start\":68369},{\"end\":68543,\"start\":68537},{\"end\":68839,\"start\":68833},{\"end\":68856,\"start\":68846},{\"end\":68869,\"start\":68864},{\"end\":69243,\"start\":69232},{\"end\":69263,\"start\":69251},{\"end\":69284,\"start\":69273},{\"end\":69298,\"start\":69295},{\"end\":69755,\"start\":69746},{\"end\":69771,\"start\":69766},{\"end\":70006,\"start\":70002},{\"end\":70021,\"start\":70015},{\"end\":70036,\"start\":70030},{\"end\":70318,\"start\":70315},{\"end\":70337,\"start\":70327},{\"end\":70603,\"start\":70600},{\"end\":70618,\"start\":70613},{\"end\":70637,\"start\":70627},{\"end\":70914,\"start\":70909},{\"end\":70933,\"start\":70925},{\"end\":70946,\"start\":70940},{\"end\":70962,\"start\":70955},{\"end\":70979,\"start\":70969},{\"end\":71000,\"start\":70990},{\"end\":71016,\"start\":71008},{\"end\":71036,\"start\":71027},{\"end\":71360,\"start\":71356},{\"end\":71378,\"start\":71370},{\"end\":71388,\"start\":71384},{\"end\":71714,\"start\":71708},{\"end\":71731,\"start\":71722},{\"end\":71750,\"start\":71743},{\"end\":72044,\"start\":72035},{\"end\":72061,\"start\":72052},{\"end\":72247,\"start\":72244},{\"end\":72265,\"start\":72255},{\"end\":72275,\"start\":72270},{\"end\":72287,\"start\":72283},{\"end\":72305,\"start\":72296},{\"end\":72313,\"start\":72307},{\"end\":72553,\"start\":72550},{\"end\":72565,\"start\":72555},{\"end\":72875,\"start\":72870},{\"end\":72905,\"start\":72884},{\"end\":72918,\"start\":72907},{\"end\":73211,\"start\":73209},{\"end\":73232,\"start\":73223},{\"end\":73248,\"start\":73239},{\"end\":73263,\"start\":73257},{\"end\":73434,\"start\":73431},{\"end\":73448,\"start\":73442},{\"end\":73456,\"start\":73453},{\"end\":73477,\"start\":73467},{\"end\":73777,\"start\":73769},{\"end\":73790,\"start\":73786},{\"end\":73805,\"start\":73799},{\"end\":73820,\"start\":73814},{\"end\":74078,\"start\":74074},{\"end\":74096,\"start\":74088},{\"end\":74112,\"start\":74107},{\"end\":74386,\"start\":74377},{\"end\":74401,\"start\":74393},{\"end\":74603,\"start\":74601},{\"end\":74621,\"start\":74613},{\"end\":74635,\"start\":74629},{\"end\":74650,\"start\":74642},{\"end\":74931,\"start\":74926},{\"end\":74946,\"start\":74941},{\"end\":74960,\"start\":74954},{\"end\":74981,\"start\":74972},{\"end\":74991,\"start\":74987},{\"end\":75004,\"start\":74999},{\"end\":75603,\"start\":75594},{\"end\":75617,\"start\":75611},{\"end\":75972,\"start\":75966},{\"end\":75983,\"start\":75976},{\"end\":75998,\"start\":75987},{\"end\":76008,\"start\":76002},{\"end\":76273,\"start\":76267},{\"end\":76288,\"start\":76281},{\"end\":76299,\"start\":76295},{\"end\":76523,\"start\":76518},{\"end\":76539,\"start\":76533},{\"end\":76558,\"start\":76546},{\"end\":76572,\"start\":76567},{\"end\":76585,\"start\":76580},{\"end\":76992,\"start\":76987},{\"end\":77001,\"start\":76996},{\"end\":77190,\"start\":77178},{\"end\":77204,\"start\":77199},{\"end\":77414,\"start\":77402},{\"end\":77428,\"start\":77423},{\"end\":77871,\"start\":77859},{\"end\":77886,\"start\":77880},{\"end\":77903,\"start\":77897},{\"end\":77922,\"start\":77912},{\"end\":78212,\"start\":78200},{\"end\":78229,\"start\":78224},{\"end\":78243,\"start\":78238},{\"end\":78433,\"start\":78428},{\"end\":78447,\"start\":78437},{\"end\":78458,\"start\":78451},{\"end\":78465,\"start\":78462},{\"end\":78476,\"start\":78469},{\"end\":78488,\"start\":78480},{\"end\":78823,\"start\":78816},{\"end\":78834,\"start\":78831},{\"end\":79066,\"start\":79059},{\"end\":79084,\"start\":79075},{\"end\":79097,\"start\":79091},{\"end\":79333,\"start\":79316},{\"end\":79349,\"start\":79342},{\"end\":79370,\"start\":79355},{\"end\":79379,\"start\":79372},{\"end\":79754,\"start\":79744},{\"end\":79763,\"start\":79758},{\"end\":79773,\"start\":79767},{\"end\":79787,\"start\":79777},{\"end\":79794,\"start\":79791},{\"end\":79807,\"start\":79798},{\"end\":79817,\"start\":79811},{\"end\":79827,\"start\":79821},{\"end\":79838,\"start\":79831},{\"end\":80168,\"start\":80160},{\"end\":80180,\"start\":80172},{\"end\":80192,\"start\":80184},{\"end\":80204,\"start\":80196},{\"end\":80215,\"start\":80208},{\"end\":80634,\"start\":80629},{\"end\":80649,\"start\":80644},{\"end\":80931,\"start\":80917},{\"end\":80955,\"start\":80942},{\"end\":80966,\"start\":80957},{\"end\":81254,\"start\":81238},{\"end\":81273,\"start\":81266},{\"end\":81291,\"start\":81283},{\"end\":81660,\"start\":81654},{\"end\":81675,\"start\":81669},{\"end\":82196,\"start\":82190},{\"end\":82210,\"start\":82206},{\"end\":82226,\"start\":82219},{\"end\":82241,\"start\":82235},{\"end\":82586,\"start\":82577},{\"end\":82603,\"start\":82599},{\"end\":82622,\"start\":82615},{\"end\":82637,\"start\":82632},{\"end\":82647,\"start\":82643},{\"end\":82962,\"start\":82959},{\"end\":82976,\"start\":82970},{\"end\":82992,\"start\":82985},{\"end\":83423,\"start\":83420},{\"end\":83437,\"start\":83433},{\"end\":83451,\"start\":83448},{\"end\":83461,\"start\":83457},{\"end\":83800,\"start\":83797},{\"end\":83819,\"start\":83811},{\"end\":83834,\"start\":83829},{\"end\":83853,\"start\":83846},{\"end\":83865,\"start\":83861},{\"end\":83880,\"start\":83878},{\"end\":83898,\"start\":83894},{\"end\":84262,\"start\":84258},{\"end\":84521,\"start\":84513},{\"end\":84537,\"start\":84530},{\"end\":84725,\"start\":84721},{\"end\":84734,\"start\":84731},{\"end\":84748,\"start\":84744},{\"end\":84766,\"start\":84760},{\"end\":85231,\"start\":85222},{\"end\":85244,\"start\":85238},{\"end\":85264,\"start\":85255},{\"end\":85281,\"start\":85275},{\"end\":85521,\"start\":85516},{\"end\":85529,\"start\":85523},{\"end\":85756,\"start\":85750},{\"end\":85769,\"start\":85764},{\"end\":85786,\"start\":85779},{\"end\":85797,\"start\":85792},{\"end\":85816,\"start\":85799},{\"end\":85828,\"start\":85820},{\"end\":85838,\"start\":85830},{\"end\":86150,\"start\":86141},{\"end\":86374,\"start\":86367},{\"end\":86389,\"start\":86382},{\"end\":86408,\"start\":86399},{\"end\":86425,\"start\":86419},{\"end\":86759,\"start\":86753},{\"end\":86778,\"start\":86769},{\"end\":86792,\"start\":86786},{\"end\":86809,\"start\":86799},{\"end\":87147,\"start\":87143},{\"end\":87171,\"start\":87166},{\"end\":87184,\"start\":87179},{\"end\":87197,\"start\":87191},{\"end\":87218,\"start\":87209},{\"end\":87230,\"start\":87224},{\"end\":87244,\"start\":87238},{\"end\":87263,\"start\":87252},{\"end\":87596,\"start\":87589},{\"end\":87602,\"start\":87598},{\"end\":87837,\"start\":87831},{\"end\":87853,\"start\":87845},{\"end\":87865,\"start\":87860},{\"end\":88356,\"start\":88350},{\"end\":88372,\"start\":88364},{\"end\":88384,\"start\":88379},{\"end\":88828,\"start\":88823},{\"end\":88846,\"start\":88838},{\"end\":89129,\"start\":89119},{\"end\":89147,\"start\":89143},{\"end\":89163,\"start\":89157},{\"end\":89178,\"start\":89172},{\"end\":89634,\"start\":89628},{\"end\":89652,\"start\":89647},{\"end\":89668,\"start\":89661},{\"end\":89677,\"start\":89675},{\"end\":89688,\"start\":89679},{\"end\":89963,\"start\":89959},{\"end\":89976,\"start\":89973},{\"end\":89987,\"start\":89984},{\"end\":90000,\"start\":89994},{\"end\":90371,\"start\":90365},{\"end\":90526,\"start\":90520},{\"end\":90540,\"start\":90533},{\"end\":90704,\"start\":90698},{\"end\":90718,\"start\":90711},{\"end\":90737,\"start\":90727},{\"end\":90755,\"start\":90746},{\"end\":90767,\"start\":90763},{\"end\":91253,\"start\":91247},{\"end\":91264,\"start\":91255},{\"end\":91423,\"start\":91417},{\"end\":91441,\"start\":91433},{\"end\":91456,\"start\":91449},{\"end\":91471,\"start\":91464},{\"end\":91485,\"start\":91480},{\"end\":91778,\"start\":91754},{\"end\":91796,\"start\":91786},{\"end\":91815,\"start\":91810},{\"end\":91824,\"start\":91817},{\"end\":92081,\"start\":92075},{\"end\":92094,\"start\":92087},{\"end\":92372,\"start\":92365},{\"end\":92387,\"start\":92378},{\"end\":92401,\"start\":92395},{\"end\":92416,\"start\":92408},{\"end\":92753,\"start\":92739},{\"end\":92771,\"start\":92764},{\"end\":92790,\"start\":92782},{\"end\":93013,\"start\":93009},{\"end\":93158,\"start\":93150},{\"end\":93324,\"start\":93320},{\"end\":93341,\"start\":93331},{\"end\":93363,\"start\":93353},{\"end\":93377,\"start\":93372},{\"end\":93396,\"start\":93385},{\"end\":93415,\"start\":93404},{\"end\":93796,\"start\":93789},{\"end\":93811,\"start\":93805},{\"end\":94061,\"start\":94055},{\"end\":94085,\"start\":94073},{\"end\":94101,\"start\":94093},{\"end\":94111,\"start\":94103},{\"end\":94121,\"start\":94117},{\"end\":94137,\"start\":94132},{\"end\":94146,\"start\":94139},{\"end\":94627,\"start\":94620},{\"end\":94644,\"start\":94636},{\"end\":94663,\"start\":94654},{\"end\":94678,\"start\":94670},{\"end\":94697,\"start\":94688},{\"end\":95041,\"start\":95035},{\"end\":95057,\"start\":95049},{\"end\":95070,\"start\":95063},{\"end\":95088,\"start\":95080},{\"end\":95093,\"start\":95090},{\"end\":95435,\"start\":95429},{\"end\":95454,\"start\":95446},{\"end\":95466,\"start\":95456},{\"end\":95481,\"start\":95476},{\"end\":95501,\"start\":95494},{\"end\":95508,\"start\":95503},{\"end\":95819,\"start\":95813},{\"end\":95838,\"start\":95830},{\"end\":95850,\"start\":95840},{\"end\":95865,\"start\":95860},{\"end\":95885,\"start\":95878},{\"end\":95892,\"start\":95887},{\"end\":96226,\"start\":96220},{\"end\":96244,\"start\":96236},{\"end\":96261,\"start\":96257},{\"end\":96268,\"start\":96263},{\"end\":96613,\"start\":96602},{\"end\":96855,\"start\":96848},{\"end\":96867,\"start\":96859},{\"end\":96879,\"start\":96871},{\"end\":96889,\"start\":96883},{\"end\":96898,\"start\":96893},{\"end\":96905,\"start\":96902},{\"end\":97344,\"start\":97336},{\"end\":97359,\"start\":97353},{\"end\":97375,\"start\":97369},{\"end\":97393,\"start\":97387},{\"end\":97408,\"start\":97402},{\"end\":97841,\"start\":97833},{\"end\":97857,\"start\":97851},{\"end\":97872,\"start\":97866},{\"end\":97888,\"start\":97882},{\"end\":97903,\"start\":97897},{\"end\":98383,\"start\":98380},{\"end\":98403,\"start\":98394},{\"end\":98789,\"start\":98784},{\"end\":98970,\"start\":98968},{\"end\":98994,\"start\":98992},{\"end\":99006,\"start\":99004},{\"end\":99025,\"start\":99019},{\"end\":99491,\"start\":99481},{\"end\":99505,\"start\":99499},{\"end\":99519,\"start\":99512},{\"end\":99531,\"start\":99525},{\"end\":99544,\"start\":99538},{\"end\":99557,\"start\":99552},{\"end\":99571,\"start\":99566},{\"end\":99584,\"start\":99577},{\"end\":99601,\"start\":99594},{\"end\":99989,\"start\":99979},{\"end\":100005,\"start\":99998},{\"end\":100020,\"start\":100014},{\"end\":100037,\"start\":100030},{\"end\":100050,\"start\":100045},{\"end\":100393,\"start\":100383},{\"end\":100409,\"start\":100402},{\"end\":100426,\"start\":100419},{\"end\":100439,\"start\":100432},{\"end\":100454,\"start\":100448},{\"end\":100471,\"start\":100464},{\"end\":100484,\"start\":100479},{\"end\":100964,\"start\":100954},{\"end\":100973,\"start\":100968},{\"end\":100985,\"start\":100981},{\"end\":101000,\"start\":100995},{\"end\":101013,\"start\":101006},{\"end\":101019,\"start\":101015},{\"end\":101350,\"start\":101343},{\"end\":101368,\"start\":101361},{\"end\":101384,\"start\":101375},{\"end\":101396,\"start\":101391},{\"end\":101411,\"start\":101406},{\"end\":101429,\"start\":101419},{\"end\":101441,\"start\":101435},{\"end\":101687,\"start\":101682},{\"end\":101702,\"start\":101696},{\"end\":101717,\"start\":101711},{\"end\":101873,\"start\":101868},{\"end\":101890,\"start\":101883},{\"end\":101902,\"start\":101899},{\"end\":102117,\"start\":102112},{\"end\":102130,\"start\":102126},{\"end\":102140,\"start\":102137},{\"end\":102157,\"start\":102148},{\"end\":102175,\"start\":102168},{\"end\":102190,\"start\":102184},{\"end\":102633,\"start\":102626},{\"end\":102641,\"start\":102637},{\"end\":102650,\"start\":102645},{\"end\":102924,\"start\":102916},{\"end\":102940,\"start\":102935},{\"end\":103240,\"start\":103235},{\"end\":103254,\"start\":103249},{\"end\":103268,\"start\":103261},{\"end\":103282,\"start\":103278},{\"end\":103297,\"start\":103293},{\"end\":103312,\"start\":103306},{\"end\":103325,\"start\":103319},{\"end\":103341,\"start\":103334},{\"end\":103656,\"start\":103651},{\"end\":103670,\"start\":103663},{\"end\":103686,\"start\":103679},{\"end\":103699,\"start\":103693},{\"end\":104083,\"start\":104078},{\"end\":104097,\"start\":104090},{\"end\":104109,\"start\":104104},{\"end\":104122,\"start\":104116},{\"end\":104138,\"start\":104131},{\"end\":104367,\"start\":104360},{\"end\":104385,\"start\":104377},{\"end\":104400,\"start\":104391},{\"end\":104415,\"start\":104407},{\"end\":104714,\"start\":104703},{\"end\":104893,\"start\":104889},{\"end\":104909,\"start\":104903},{\"end\":105244,\"start\":105238},{\"end\":105263,\"start\":105251},{\"end\":105282,\"start\":105273},{\"end\":105301,\"start\":105291},{\"end\":105648,\"start\":105642},{\"end\":105663,\"start\":105657},{\"end\":105671,\"start\":105665},{\"end\":106085,\"start\":106083},{\"end\":106101,\"start\":106093},{\"end\":106111,\"start\":106105},{\"end\":106121,\"start\":106118},{\"end\":106135,\"start\":106128},{\"end\":106146,\"start\":106137},{\"end\":106520,\"start\":106518},{\"end\":106533,\"start\":106529},{\"end\":106548,\"start\":106542},{\"end\":106559,\"start\":106557},{\"end\":106575,\"start\":106570},{\"end\":106588,\"start\":106584},{\"end\":106604,\"start\":106600},{\"end\":107033,\"start\":107030},{\"end\":107045,\"start\":107041},{\"end\":107058,\"start\":107053},{\"end\":107069,\"start\":107066},{\"end\":107082,\"start\":107079},{\"end\":107499,\"start\":107491},{\"end\":107519,\"start\":107508},{\"end\":107532,\"start\":107527},{\"end\":107548,\"start\":107539},{\"end\":107564,\"start\":107555},{\"end\":107890,\"start\":107885},{\"end\":107903,\"start\":107897},{\"end\":107917,\"start\":107912},{\"end\":107933,\"start\":107928},{\"end\":107948,\"start\":107941},{\"end\":108227,\"start\":108222},{\"end\":108243,\"start\":108236},{\"end\":108260,\"start\":108253},{\"end\":108273,\"start\":108266},{\"end\":108286,\"start\":108281},{\"end\":108614,\"start\":108609},{\"end\":108628,\"start\":108623},{\"end\":108952,\"start\":108947},{\"end\":108964,\"start\":108961},{\"end\":108980,\"start\":108975},{\"end\":108995,\"start\":108990},{\"end\":109011,\"start\":109007},{\"end\":109401,\"start\":109398},{\"end\":109433,\"start\":109412},{\"end\":109445,\"start\":109441},{\"end\":109452,\"start\":109447},{\"end\":109856,\"start\":109853},{\"end\":109874,\"start\":109866},{\"end\":109886,\"start\":109881},{\"end\":109900,\"start\":109897},{\"end\":109915,\"start\":109910},{\"end\":109927,\"start\":109920},{\"end\":109940,\"start\":109933}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":60200,\"start\":60089},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":6026836},\"end\":60578,\"start\":60202},{\"attributes\":{\"id\":\"b2\"},\"end\":61223,\"start\":60580},{\"attributes\":{\"doi\":\"2016-12-21\",\"id\":\"b3\"},\"end\":61407,\"start\":61225},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":15909615},\"end\":61828,\"start\":61409},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":141949953},\"end\":62208,\"start\":61830},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":2673153},\"end\":62619,\"start\":62210},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":13293313},\"end\":63108,\"start\":62621},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":2200675},\"end\":63528,\"start\":63110},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":1596551},\"end\":63926,\"start\":63530},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":5700960},\"end\":64318,\"start\":63928},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":14240373},\"end\":64708,\"start\":64320},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":2169827},\"end\":65080,\"start\":64710},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":895731},\"end\":65534,\"start\":65082},{\"attributes\":{\"id\":\"b14\"},\"end\":65790,\"start\":65536},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":142734},\"end\":66191,\"start\":65792},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":27257366},\"end\":66669,\"start\":66193},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":2659157},\"end\":67010,\"start\":66671},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":2596787},\"end\":67536,\"start\":67012},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":6325059},\"end\":67988,\"start\":67538},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":9242771},\"end\":68288,\"start\":67990},{\"attributes\":{\"id\":\"b21\"},\"end\":68526,\"start\":68290},{\"attributes\":{\"doi\":\"arXiv:1702.05374\",\"id\":\"b22\"},\"end\":68764,\"start\":68528},{\"attributes\":{\"doi\":\"arXiv:1703.07473\",\"id\":\"b23\",\"matched_paper_id\":10580486},\"end\":69153,\"start\":68766},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":11133572},\"end\":69696,\"start\":69155},{\"attributes\":{\"id\":\"b25\"},\"end\":69925,\"start\":69698},{\"attributes\":{\"doi\":\"arXiv:1703.03400\",\"id\":\"b26\"},\"end\":70221,\"start\":69927},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":160705},\"end\":70592,\"start\":70223},{\"attributes\":{\"doi\":\"arXiv:1703.02910\",\"id\":\"b28\"},\"end\":70850,\"start\":70594},{\"attributes\":{\"doi\":\"abs/1505.07818\",\"id\":\"b29\"},\"end\":71274,\"start\":70852},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":299085},\"end\":71629,\"start\":71276},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":206596513},\"end\":71983,\"start\":71631},{\"attributes\":{\"id\":\"b32\"},\"end\":72151,\"start\":71985},{\"attributes\":{\"doi\":\"arXiv:1312.6211\",\"id\":\"b33\"},\"end\":72546,\"start\":72153},{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b34\"},\"end\":72829,\"start\":72548},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":1755772},\"end\":73140,\"start\":72831},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":890737},\"end\":73423,\"start\":73142},{\"attributes\":{\"doi\":\"arXiv:1706.04599\",\"id\":\"b37\"},\"end\":73691,\"start\":73425},{\"attributes\":{\"doi\":\"abs/1605.07148\",\"id\":\"b38\"},\"end\":74000,\"start\":73693},{\"attributes\":{\"doi\":\"arXiv:1704.00710\",\"id\":\"b39\"},\"end\":74298,\"start\":74002},{\"attributes\":{\"doi\":\"arXiv:1606.02819\",\"id\":\"b40\"},\"end\":74579,\"start\":74300},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":54465873},\"end\":74848,\"start\":74581},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":53604},\"end\":75496,\"start\":74850},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":13046179},\"end\":75859,\"start\":75498},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":12054066},\"end\":76210,\"start\":75861},{\"attributes\":{\"doi\":\"abs/1503.02531\",\"id\":\"b45\"},\"end\":76439,\"start\":76212},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":4390164},\"end\":76925,\"start\":76441},{\"attributes\":{\"id\":\"b47\"},\"end\":77119,\"start\":76927},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":5980504},\"end\":77355,\"start\":77121},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":46716632},\"end\":77756,\"start\":77357},{\"attributes\":{\"doi\":\"arXiv:1705.09805\",\"id\":\"b50\"},\"end\":78166,\"start\":77758},{\"attributes\":{\"doi\":\"abs/1511.06429\",\"id\":\"b51\"},\"end\":78361,\"start\":78168},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":2199941},\"end\":78731,\"start\":78363},{\"attributes\":{\"doi\":\"arXiv:1703.04977\",\"id\":\"b53\"},\"end\":79009,\"start\":78733},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":2230247},\"end\":79253,\"start\":79011},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":6377199},\"end\":79639,\"start\":79255},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":13296968},\"end\":80107,\"start\":79641},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":206849534},\"end\":80520,\"start\":80109},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":205693084},\"end\":80838,\"start\":80522},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":11790493},\"end\":81153,\"start\":80840},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":6294674},\"end\":81562,\"start\":81155},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":2341332},\"end\":82133,\"start\":81564},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":7242892},\"end\":82466,\"start\":82135},{\"attributes\":{\"doi\":\"abs/1509.02971\",\"id\":\"b63\"},\"end\":82879,\"start\":82468},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":7188439},\"end\":83328,\"start\":82881},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":15774646},\"end\":83755,\"start\":83330},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":2141740},\"end\":84166,\"start\":83757},{\"attributes\":{\"doi\":\"2016-12-21\",\"id\":\"b67\"},\"end\":84431,\"start\":84168},{\"attributes\":{\"id\":\"b68\"},\"end\":84647,\"start\":84433},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":556999},\"end\":85164,\"start\":84649},{\"attributes\":{\"doi\":\"abs/1511.03643\",\"id\":\"b70\"},\"end\":85449,\"start\":85166},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":16543854},\"end\":85672,\"start\":85451},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":1557057},\"end\":86112,\"start\":85674},{\"attributes\":{\"id\":\"b73\"},\"end\":86257,\"start\":86114},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":9296691},\"end\":86675,\"start\":86259},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":4912853},\"end\":87077,\"start\":86677},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":6875312},\"end\":87546,\"start\":87079},{\"attributes\":{\"id\":\"b77\"},\"end\":87730,\"start\":87548},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":206592585},\"end\":88249,\"start\":87732},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":206592585},\"end\":88773,\"start\":88251},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":8167104},\"end\":89009,\"start\":88775},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":8420864},\"end\":89569,\"start\":89011},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":918513},\"end\":89901,\"start\":89571},{\"attributes\":{\"id\":\"b83\",\"matched_paper_id\":554423},\"end\":90316,\"start\":89903},{\"attributes\":{\"id\":\"b84\"},\"end\":90466,\"start\":90318},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":1641504},\"end\":90689,\"start\":90468},{\"attributes\":{\"id\":\"b86\"},\"end\":91172,\"start\":90691},{\"attributes\":{\"id\":\"b87\"},\"end\":91362,\"start\":91174},{\"attributes\":{\"id\":\"b88\",\"matched_paper_id\":5855183},\"end\":91742,\"start\":91364},{\"attributes\":{\"id\":\"b89\"},\"end\":92030,\"start\":91744},{\"attributes\":{\"id\":\"b90\",\"matched_paper_id\":786357},\"end\":92305,\"start\":92032},{\"attributes\":{\"id\":\"b91\",\"matched_paper_id\":5985692},\"end\":92653,\"start\":92307},{\"attributes\":{\"doi\":\"abs/1611.06448\",\"id\":\"b92\"},\"end\":92980,\"start\":92655},{\"attributes\":{\"id\":\"b93\"},\"end\":93094,\"start\":92982},{\"attributes\":{\"doi\":\"2016-12-21 via htp://goo.gl/ ph7UfV\",\"id\":\"b94\"},\"end\":93311,\"start\":93096},{\"attributes\":{\"doi\":\"arXiv:1606.04671\",\"id\":\"b95\"},\"end\":93715,\"start\":93313},{\"attributes\":{\"doi\":\"arXiv:1611.04201\",\"id\":\"b96\"},\"end\":93980,\"start\":93717},{\"attributes\":{\"id\":\"b97\",\"matched_paper_id\":9002995},\"end\":94560,\"start\":93982},{\"attributes\":{\"id\":\"b98\",\"matched_paper_id\":6466088},\"end\":94957,\"start\":94562},{\"attributes\":{\"id\":\"b99\",\"matched_paper_id\":3462863},\"end\":95396,\"start\":94959},{\"attributes\":{\"id\":\"b100\",\"matched_paper_id\":12035411},\"end\":95780,\"start\":95398},{\"attributes\":{\"id\":\"b101\",\"matched_paper_id\":12035411},\"end\":96171,\"start\":95782},{\"attributes\":{\"id\":\"b102\",\"matched_paper_id\":9584833},\"end\":96532,\"start\":96173},{\"attributes\":{\"id\":\"b103\"},\"end\":96757,\"start\":96534},{\"attributes\":{\"id\":\"b104\"},\"end\":97295,\"start\":96759},{\"attributes\":{\"id\":\"b105\",\"matched_paper_id\":16046818},\"end\":97750,\"start\":97297},{\"attributes\":{\"id\":\"b106\",\"matched_paper_id\":3075448},\"end\":98293,\"start\":97752},{\"attributes\":{\"id\":\"b107\",\"matched_paper_id\":12020485},\"end\":98740,\"start\":98295},{\"attributes\":{\"id\":\"b108\"},\"end\":98866,\"start\":98742},{\"attributes\":{\"id\":\"b109\",\"matched_paper_id\":5544227},\"end\":99413,\"start\":98868},{\"attributes\":{\"id\":\"b110\",\"matched_paper_id\":315960},\"end\":99972,\"start\":99415},{\"attributes\":{\"id\":\"b111\"},\"end\":100376,\"start\":99974},{\"attributes\":{\"id\":\"b112\"},\"end\":100896,\"start\":100378},{\"attributes\":{\"id\":\"b113\",\"matched_paper_id\":10327918},\"end\":101289,\"start\":100898},{\"attributes\":{\"doi\":\"abs/1312.6199\",\"id\":\"b114\"},\"end\":101643,\"start\":101291},{\"attributes\":{\"doi\":\"abs/1602.02867\",\"id\":\"b115\"},\"end\":101832,\"start\":101645},{\"attributes\":{\"id\":\"b116\"},\"end\":102011,\"start\":101834},{\"attributes\":{\"id\":\"b117\",\"matched_paper_id\":2413610},\"end\":102572,\"start\":102013},{\"attributes\":{\"id\":\"b118\",\"matched_paper_id\":5230692},\"end\":102875,\"start\":102574},{\"attributes\":{\"id\":\"b119\",\"matched_paper_id\":2777306},\"end\":103142,\"start\":102877},{\"attributes\":{\"doi\":\"abs/1511.07111\",\"id\":\"b120\"},\"end\":103591,\"start\":103144},{\"attributes\":{\"id\":\"b121\",\"matched_paper_id\":2655115},\"end\":104014,\"start\":103593},{\"attributes\":{\"doi\":\"abs/1412.3474\",\"id\":\"b122\"},\"end\":104311,\"start\":104016},{\"attributes\":{\"id\":\"b123\",\"matched_paper_id\":8909022},\"end\":104655,\"start\":104313},{\"attributes\":{\"id\":\"b124\"},\"end\":104801,\"start\":104657},{\"attributes\":{\"id\":\"b125\",\"matched_paper_id\":10048432},\"end\":105143,\"start\":104803},{\"attributes\":{\"id\":\"b126\",\"matched_paper_id\":1731857},\"end\":105592,\"start\":105145},{\"attributes\":{\"id\":\"b127\",\"matched_paper_id\":418428},\"end\":105975,\"start\":105594},{\"attributes\":{\"id\":\"b128\",\"matched_paper_id\":7587278},\"end\":106449,\"start\":105977},{\"attributes\":{\"id\":\"b129\",\"matched_paper_id\":206592833},\"end\":106920,\"start\":106451},{\"attributes\":{\"id\":\"b130\",\"matched_paper_id\":1608002},\"end\":107391,\"start\":106922},{\"attributes\":{\"doi\":\"arXiv:1707.08212\",\"id\":\"b131\"},\"end\":107811,\"start\":107393},{\"attributes\":{\"doi\":\"abs/1611.03530\",\"id\":\"b132\"},\"end\":108136,\"start\":107813},{\"attributes\":{\"id\":\"b133\",\"matched_paper_id\":14147627},\"end\":108554,\"start\":108138},{\"attributes\":{\"id\":\"b134\",\"matched_paper_id\":10865487},\"end\":108856,\"start\":108556},{\"attributes\":{\"id\":\"b135\",\"matched_paper_id\":14094786},\"end\":109293,\"start\":108858},{\"attributes\":{\"id\":\"b136\",\"matched_paper_id\":13436386},\"end\":109762,\"start\":109295},{\"attributes\":{\"doi\":\"abs/1609.05143\",\"id\":\"b137\"},\"end\":110172,\"start\":109764}]", "bib_title": "[{\"end\":60272,\"start\":60202},{\"end\":61485,\"start\":61409},{\"end\":61874,\"start\":61830},{\"end\":62288,\"start\":62210},{\"end\":62685,\"start\":62621},{\"end\":63180,\"start\":63110},{\"end\":63585,\"start\":63530},{\"end\":63958,\"start\":63928},{\"end\":64350,\"start\":64320},{\"end\":64749,\"start\":64710},{\"end\":65142,\"start\":65082},{\"end\":65855,\"start\":65792},{\"end\":66275,\"start\":66193},{\"end\":66742,\"start\":66671},{\"end\":67112,\"start\":67012},{\"end\":67615,\"start\":67538},{\"end\":68029,\"start\":67990},{\"end\":68346,\"start\":68290},{\"end\":68825,\"start\":68766},{\"end\":69222,\"start\":69155},{\"end\":70307,\"start\":70223},{\"end\":71349,\"start\":71276},{\"end\":71698,\"start\":71631},{\"end\":72862,\"start\":72831},{\"end\":73198,\"start\":73142},{\"end\":74591,\"start\":74581},{\"end\":74916,\"start\":74850},{\"end\":75588,\"start\":75498},{\"end\":75962,\"start\":75861},{\"end\":76506,\"start\":76441},{\"end\":77171,\"start\":77121},{\"end\":77395,\"start\":77357},{\"end\":78424,\"start\":78363},{\"end\":79050,\"start\":79011},{\"end\":79307,\"start\":79255},{\"end\":79740,\"start\":79641},{\"end\":80156,\"start\":80109},{\"end\":80622,\"start\":80522},{\"end\":80908,\"start\":80840},{\"end\":81229,\"start\":81155},{\"end\":81645,\"start\":81564},{\"end\":82181,\"start\":82135},{\"end\":82951,\"start\":82881},{\"end\":83412,\"start\":83330},{\"end\":83791,\"start\":83757},{\"end\":84709,\"start\":84649},{\"end\":85510,\"start\":85451},{\"end\":85741,\"start\":85674},{\"end\":86131,\"start\":86114},{\"end\":86358,\"start\":86259},{\"end\":86744,\"start\":86677},{\"end\":87131,\"start\":87079},{\"end\":87825,\"start\":87732},{\"end\":88344,\"start\":88251},{\"end\":88816,\"start\":88775},{\"end\":89110,\"start\":89011},{\"end\":89624,\"start\":89571},{\"end\":89948,\"start\":89903},{\"end\":90511,\"start\":90468},{\"end\":91409,\"start\":91364},{\"end\":92066,\"start\":92032},{\"end\":92356,\"start\":92307},{\"end\":94051,\"start\":93982},{\"end\":94613,\"start\":94562},{\"end\":95031,\"start\":94959},{\"end\":95425,\"start\":95398},{\"end\":95809,\"start\":95782},{\"end\":96216,\"start\":96173},{\"end\":96592,\"start\":96534},{\"end\":96844,\"start\":96759},{\"end\":97329,\"start\":97297},{\"end\":97826,\"start\":97752},{\"end\":98374,\"start\":98295},{\"end\":98962,\"start\":98868},{\"end\":99474,\"start\":99415},{\"end\":100947,\"start\":100898},{\"end\":102105,\"start\":102013},{\"end\":102622,\"start\":102574},{\"end\":102906,\"start\":102877},{\"end\":103644,\"start\":103593},{\"end\":104352,\"start\":104313},{\"end\":104878,\"start\":104803},{\"end\":105229,\"start\":105145},{\"end\":105638,\"start\":105594},{\"end\":106074,\"start\":105977},{\"end\":106508,\"start\":106451},{\"end\":107020,\"start\":106922},{\"end\":108213,\"start\":108138},{\"end\":108604,\"start\":108556},{\"end\":108939,\"start\":108858},{\"end\":109392,\"start\":109295}]", "bib_author": "[{\"end\":60285,\"start\":60274},{\"end\":60295,\"start\":60285},{\"end\":60305,\"start\":60295},{\"end\":60314,\"start\":60305},{\"end\":60324,\"start\":60314},{\"end\":60597,\"start\":60580},{\"end\":60615,\"start\":60597},{\"end\":60629,\"start\":60615},{\"end\":60646,\"start\":60629},{\"end\":60662,\"start\":60646},{\"end\":60672,\"start\":60662},{\"end\":60686,\"start\":60672},{\"end\":60699,\"start\":60686},{\"end\":60714,\"start\":60699},{\"end\":60731,\"start\":60714},{\"end\":60748,\"start\":60731},{\"end\":60758,\"start\":60748},{\"end\":60771,\"start\":60758},{\"end\":61282,\"start\":61264},{\"end\":61505,\"start\":61487},{\"end\":61523,\"start\":61505},{\"end\":61537,\"start\":61523},{\"end\":61554,\"start\":61537},{\"end\":61573,\"start\":61554},{\"end\":61891,\"start\":61876},{\"end\":61897,\"start\":61891},{\"end\":61908,\"start\":61897},{\"end\":61914,\"start\":61908},{\"end\":62305,\"start\":62290},{\"end\":62316,\"start\":62305},{\"end\":62322,\"start\":62316},{\"end\":62333,\"start\":62322},{\"end\":62342,\"start\":62333},{\"end\":62357,\"start\":62342},{\"end\":62368,\"start\":62357},{\"end\":62703,\"start\":62687},{\"end\":62721,\"start\":62703},{\"end\":62734,\"start\":62721},{\"end\":63199,\"start\":63182},{\"end\":63215,\"start\":63199},{\"end\":63228,\"start\":63215},{\"end\":63252,\"start\":63228},{\"end\":63596,\"start\":63587},{\"end\":63617,\"start\":63596},{\"end\":63635,\"start\":63617},{\"end\":63646,\"start\":63635},{\"end\":63977,\"start\":63960},{\"end\":63995,\"start\":63977},{\"end\":64369,\"start\":64352},{\"end\":64387,\"start\":64369},{\"end\":64768,\"start\":64751},{\"end\":64776,\"start\":64768},{\"end\":64792,\"start\":64776},{\"end\":64809,\"start\":64792},{\"end\":64822,\"start\":64809},{\"end\":64831,\"start\":64822},{\"end\":65161,\"start\":65144},{\"end\":65173,\"start\":65161},{\"end\":65189,\"start\":65173},{\"end\":65207,\"start\":65189},{\"end\":65224,\"start\":65207},{\"end\":65612,\"start\":65598},{\"end\":65628,\"start\":65612},{\"end\":65649,\"start\":65628},{\"end\":65868,\"start\":65857},{\"end\":65875,\"start\":65868},{\"end\":66288,\"start\":66277},{\"end\":66296,\"start\":66288},{\"end\":66305,\"start\":66296},{\"end\":66312,\"start\":66305},{\"end\":66758,\"start\":66744},{\"end\":66766,\"start\":66758},{\"end\":66776,\"start\":66766},{\"end\":67128,\"start\":67114},{\"end\":67142,\"start\":67128},{\"end\":67158,\"start\":67142},{\"end\":67171,\"start\":67158},{\"end\":67190,\"start\":67171},{\"end\":67202,\"start\":67190},{\"end\":67212,\"start\":67202},{\"end\":67228,\"start\":67212},{\"end\":67632,\"start\":67617},{\"end\":67645,\"start\":67632},{\"end\":67658,\"start\":67645},{\"end\":67670,\"start\":67658},{\"end\":67683,\"start\":67670},{\"end\":67693,\"start\":67683},{\"end\":68052,\"start\":68031},{\"end\":68081,\"start\":68052},{\"end\":68357,\"start\":68348},{\"end\":68369,\"start\":68357},{\"end\":68375,\"start\":68369},{\"end\":68545,\"start\":68528},{\"end\":68841,\"start\":68827},{\"end\":68858,\"start\":68841},{\"end\":68871,\"start\":68858},{\"end\":69245,\"start\":69224},{\"end\":69265,\"start\":69245},{\"end\":69286,\"start\":69265},{\"end\":69300,\"start\":69286},{\"end\":69757,\"start\":69738},{\"end\":69773,\"start\":69757},{\"end\":70008,\"start\":69994},{\"end\":70023,\"start\":70008},{\"end\":70038,\"start\":70023},{\"end\":70320,\"start\":70309},{\"end\":70339,\"start\":70320},{\"end\":70605,\"start\":70594},{\"end\":70620,\"start\":70605},{\"end\":70639,\"start\":70620},{\"end\":70916,\"start\":70900},{\"end\":70935,\"start\":70916},{\"end\":70948,\"start\":70935},{\"end\":70964,\"start\":70948},{\"end\":70981,\"start\":70964},{\"end\":71002,\"start\":70981},{\"end\":71018,\"start\":71002},{\"end\":71038,\"start\":71018},{\"end\":71362,\"start\":71351},{\"end\":71380,\"start\":71362},{\"end\":71390,\"start\":71380},{\"end\":71716,\"start\":71700},{\"end\":71733,\"start\":71716},{\"end\":71752,\"start\":71733},{\"end\":72046,\"start\":72029},{\"end\":72063,\"start\":72046},{\"end\":72249,\"start\":72242},{\"end\":72267,\"start\":72249},{\"end\":72277,\"start\":72267},{\"end\":72289,\"start\":72277},{\"end\":72307,\"start\":72289},{\"end\":72315,\"start\":72307},{\"end\":72555,\"start\":72548},{\"end\":72567,\"start\":72555},{\"end\":72877,\"start\":72864},{\"end\":72907,\"start\":72877},{\"end\":72920,\"start\":72907},{\"end\":73213,\"start\":73200},{\"end\":73234,\"start\":73213},{\"end\":73250,\"start\":73234},{\"end\":73265,\"start\":73250},{\"end\":73436,\"start\":73425},{\"end\":73450,\"start\":73436},{\"end\":73458,\"start\":73450},{\"end\":73479,\"start\":73458},{\"end\":73779,\"start\":73762},{\"end\":73792,\"start\":73779},{\"end\":73807,\"start\":73792},{\"end\":73822,\"start\":73807},{\"end\":74080,\"start\":74064},{\"end\":74098,\"start\":74080},{\"end\":74114,\"start\":74098},{\"end\":74388,\"start\":74369},{\"end\":74403,\"start\":74388},{\"end\":74605,\"start\":74593},{\"end\":74623,\"start\":74605},{\"end\":74637,\"start\":74623},{\"end\":74652,\"start\":74637},{\"end\":74933,\"start\":74918},{\"end\":74948,\"start\":74933},{\"end\":74962,\"start\":74948},{\"end\":74983,\"start\":74962},{\"end\":74993,\"start\":74983},{\"end\":75006,\"start\":74993},{\"end\":75605,\"start\":75590},{\"end\":75619,\"start\":75605},{\"end\":75974,\"start\":75964},{\"end\":75985,\"start\":75974},{\"end\":76000,\"start\":75985},{\"end\":76010,\"start\":76000},{\"end\":76275,\"start\":76258},{\"end\":76290,\"start\":76275},{\"end\":76301,\"start\":76290},{\"end\":76525,\"start\":76508},{\"end\":76541,\"start\":76525},{\"end\":76560,\"start\":76541},{\"end\":76574,\"start\":76560},{\"end\":76587,\"start\":76574},{\"end\":76994,\"start\":76985},{\"end\":77003,\"start\":76994},{\"end\":77192,\"start\":77173},{\"end\":77206,\"start\":77192},{\"end\":77416,\"start\":77397},{\"end\":77430,\"start\":77416},{\"end\":77873,\"start\":77854},{\"end\":77888,\"start\":77873},{\"end\":77905,\"start\":77888},{\"end\":77924,\"start\":77905},{\"end\":78214,\"start\":78195},{\"end\":78231,\"start\":78214},{\"end\":78245,\"start\":78231},{\"end\":78435,\"start\":78426},{\"end\":78449,\"start\":78435},{\"end\":78460,\"start\":78449},{\"end\":78467,\"start\":78460},{\"end\":78478,\"start\":78467},{\"end\":78490,\"start\":78478},{\"end\":78825,\"start\":78811},{\"end\":78836,\"start\":78825},{\"end\":79068,\"start\":79052},{\"end\":79086,\"start\":79068},{\"end\":79099,\"start\":79086},{\"end\":79335,\"start\":79309},{\"end\":79351,\"start\":79335},{\"end\":79372,\"start\":79351},{\"end\":79381,\"start\":79372},{\"end\":79756,\"start\":79742},{\"end\":79765,\"start\":79756},{\"end\":79775,\"start\":79765},{\"end\":79789,\"start\":79775},{\"end\":79796,\"start\":79789},{\"end\":79809,\"start\":79796},{\"end\":79819,\"start\":79809},{\"end\":79829,\"start\":79819},{\"end\":79840,\"start\":79829},{\"end\":80170,\"start\":80158},{\"end\":80182,\"start\":80170},{\"end\":80194,\"start\":80182},{\"end\":80206,\"start\":80194},{\"end\":80217,\"start\":80206},{\"end\":80636,\"start\":80624},{\"end\":80651,\"start\":80636},{\"end\":80933,\"start\":80910},{\"end\":80957,\"start\":80933},{\"end\":80968,\"start\":80957},{\"end\":81256,\"start\":81231},{\"end\":81275,\"start\":81256},{\"end\":81293,\"start\":81275},{\"end\":81662,\"start\":81647},{\"end\":81677,\"start\":81662},{\"end\":82198,\"start\":82183},{\"end\":82212,\"start\":82198},{\"end\":82228,\"start\":82212},{\"end\":82243,\"start\":82228},{\"end\":82588,\"start\":82567},{\"end\":82605,\"start\":82588},{\"end\":82624,\"start\":82605},{\"end\":82639,\"start\":82624},{\"end\":82649,\"start\":82639},{\"end\":82964,\"start\":82953},{\"end\":82978,\"start\":82964},{\"end\":82994,\"start\":82978},{\"end\":83425,\"start\":83414},{\"end\":83439,\"start\":83425},{\"end\":83453,\"start\":83439},{\"end\":83463,\"start\":83453},{\"end\":83802,\"start\":83793},{\"end\":83821,\"start\":83802},{\"end\":83836,\"start\":83821},{\"end\":83855,\"start\":83836},{\"end\":83867,\"start\":83855},{\"end\":83882,\"start\":83867},{\"end\":83900,\"start\":83882},{\"end\":84264,\"start\":84252},{\"end\":84523,\"start\":84504},{\"end\":84539,\"start\":84523},{\"end\":84727,\"start\":84711},{\"end\":84736,\"start\":84727},{\"end\":84750,\"start\":84736},{\"end\":84768,\"start\":84750},{\"end\":85233,\"start\":85216},{\"end\":85246,\"start\":85233},{\"end\":85266,\"start\":85246},{\"end\":85283,\"start\":85266},{\"end\":85523,\"start\":85512},{\"end\":85531,\"start\":85523},{\"end\":85758,\"start\":85743},{\"end\":85771,\"start\":85758},{\"end\":85788,\"start\":85771},{\"end\":85799,\"start\":85788},{\"end\":85818,\"start\":85799},{\"end\":85830,\"start\":85818},{\"end\":85840,\"start\":85830},{\"end\":86152,\"start\":86133},{\"end\":86376,\"start\":86360},{\"end\":86391,\"start\":86376},{\"end\":86410,\"start\":86391},{\"end\":86427,\"start\":86410},{\"end\":86761,\"start\":86746},{\"end\":86780,\"start\":86761},{\"end\":86794,\"start\":86780},{\"end\":86811,\"start\":86794},{\"end\":87149,\"start\":87133},{\"end\":87173,\"start\":87149},{\"end\":87186,\"start\":87173},{\"end\":87199,\"start\":87186},{\"end\":87220,\"start\":87199},{\"end\":87232,\"start\":87220},{\"end\":87246,\"start\":87232},{\"end\":87265,\"start\":87246},{\"end\":87598,\"start\":87587},{\"end\":87604,\"start\":87598},{\"end\":87839,\"start\":87827},{\"end\":87855,\"start\":87839},{\"end\":87867,\"start\":87855},{\"end\":88358,\"start\":88346},{\"end\":88374,\"start\":88358},{\"end\":88386,\"start\":88374},{\"end\":88830,\"start\":88818},{\"end\":88848,\"start\":88830},{\"end\":89131,\"start\":89112},{\"end\":89149,\"start\":89131},{\"end\":89165,\"start\":89149},{\"end\":89180,\"start\":89165},{\"end\":89636,\"start\":89626},{\"end\":89654,\"start\":89636},{\"end\":89670,\"start\":89654},{\"end\":89679,\"start\":89670},{\"end\":89690,\"start\":89679},{\"end\":89965,\"start\":89950},{\"end\":89978,\"start\":89965},{\"end\":89989,\"start\":89978},{\"end\":90002,\"start\":89989},{\"end\":90373,\"start\":90360},{\"end\":90528,\"start\":90513},{\"end\":90542,\"start\":90528},{\"end\":90706,\"start\":90691},{\"end\":90720,\"start\":90706},{\"end\":90739,\"start\":90720},{\"end\":90757,\"start\":90739},{\"end\":90769,\"start\":90757},{\"end\":91255,\"start\":91245},{\"end\":91266,\"start\":91255},{\"end\":91425,\"start\":91411},{\"end\":91443,\"start\":91425},{\"end\":91458,\"start\":91443},{\"end\":91473,\"start\":91458},{\"end\":91487,\"start\":91473},{\"end\":91780,\"start\":91744},{\"end\":91798,\"start\":91780},{\"end\":91817,\"start\":91798},{\"end\":91826,\"start\":91817},{\"end\":92083,\"start\":92068},{\"end\":92096,\"start\":92083},{\"end\":92374,\"start\":92358},{\"end\":92389,\"start\":92374},{\"end\":92403,\"start\":92389},{\"end\":92418,\"start\":92403},{\"end\":92755,\"start\":92731},{\"end\":92773,\"start\":92755},{\"end\":92792,\"start\":92773},{\"end\":93015,\"start\":93007},{\"end\":93160,\"start\":93143},{\"end\":93326,\"start\":93313},{\"end\":93343,\"start\":93326},{\"end\":93365,\"start\":93343},{\"end\":93379,\"start\":93365},{\"end\":93398,\"start\":93379},{\"end\":93417,\"start\":93398},{\"end\":93798,\"start\":93779},{\"end\":93813,\"start\":93798},{\"end\":94063,\"start\":94053},{\"end\":94087,\"start\":94063},{\"end\":94103,\"start\":94087},{\"end\":94113,\"start\":94103},{\"end\":94123,\"start\":94113},{\"end\":94139,\"start\":94123},{\"end\":94148,\"start\":94139},{\"end\":94629,\"start\":94615},{\"end\":94646,\"start\":94629},{\"end\":94665,\"start\":94646},{\"end\":94680,\"start\":94665},{\"end\":94699,\"start\":94680},{\"end\":95043,\"start\":95033},{\"end\":95059,\"start\":95043},{\"end\":95072,\"start\":95059},{\"end\":95090,\"start\":95072},{\"end\":95095,\"start\":95090},{\"end\":95437,\"start\":95427},{\"end\":95456,\"start\":95437},{\"end\":95468,\"start\":95456},{\"end\":95483,\"start\":95468},{\"end\":95503,\"start\":95483},{\"end\":95510,\"start\":95503},{\"end\":95821,\"start\":95811},{\"end\":95840,\"start\":95821},{\"end\":95852,\"start\":95840},{\"end\":95867,\"start\":95852},{\"end\":95887,\"start\":95867},{\"end\":95894,\"start\":95887},{\"end\":96228,\"start\":96218},{\"end\":96246,\"start\":96228},{\"end\":96263,\"start\":96246},{\"end\":96270,\"start\":96263},{\"end\":96615,\"start\":96594},{\"end\":96857,\"start\":96846},{\"end\":96869,\"start\":96857},{\"end\":96881,\"start\":96869},{\"end\":96891,\"start\":96881},{\"end\":96900,\"start\":96891},{\"end\":96907,\"start\":96900},{\"end\":97346,\"start\":97331},{\"end\":97361,\"start\":97346},{\"end\":97377,\"start\":97361},{\"end\":97395,\"start\":97377},{\"end\":97410,\"start\":97395},{\"end\":97843,\"start\":97828},{\"end\":97859,\"start\":97843},{\"end\":97874,\"start\":97859},{\"end\":97890,\"start\":97874},{\"end\":97905,\"start\":97890},{\"end\":98385,\"start\":98376},{\"end\":98405,\"start\":98385},{\"end\":98791,\"start\":98774},{\"end\":98972,\"start\":98964},{\"end\":98996,\"start\":98972},{\"end\":99008,\"start\":98996},{\"end\":99027,\"start\":99008},{\"end\":99493,\"start\":99476},{\"end\":99507,\"start\":99493},{\"end\":99521,\"start\":99507},{\"end\":99533,\"start\":99521},{\"end\":99546,\"start\":99533},{\"end\":99559,\"start\":99546},{\"end\":99573,\"start\":99559},{\"end\":99586,\"start\":99573},{\"end\":99603,\"start\":99586},{\"end\":99991,\"start\":99974},{\"end\":100007,\"start\":99991},{\"end\":100022,\"start\":100007},{\"end\":100039,\"start\":100022},{\"end\":100052,\"start\":100039},{\"end\":100395,\"start\":100378},{\"end\":100411,\"start\":100395},{\"end\":100428,\"start\":100411},{\"end\":100441,\"start\":100428},{\"end\":100456,\"start\":100441},{\"end\":100473,\"start\":100456},{\"end\":100486,\"start\":100473},{\"end\":100966,\"start\":100949},{\"end\":100975,\"start\":100966},{\"end\":100987,\"start\":100975},{\"end\":101002,\"start\":100987},{\"end\":101015,\"start\":101002},{\"end\":101021,\"start\":101015},{\"end\":101352,\"start\":101333},{\"end\":101370,\"start\":101352},{\"end\":101386,\"start\":101370},{\"end\":101398,\"start\":101386},{\"end\":101413,\"start\":101398},{\"end\":101431,\"start\":101413},{\"end\":101443,\"start\":101431},{\"end\":101689,\"start\":101677},{\"end\":101704,\"start\":101689},{\"end\":101719,\"start\":101704},{\"end\":101875,\"start\":101858},{\"end\":101892,\"start\":101875},{\"end\":101904,\"start\":101892},{\"end\":102119,\"start\":102107},{\"end\":102132,\"start\":102119},{\"end\":102142,\"start\":102132},{\"end\":102159,\"start\":102142},{\"end\":102177,\"start\":102159},{\"end\":102192,\"start\":102177},{\"end\":102635,\"start\":102624},{\"end\":102643,\"start\":102635},{\"end\":102652,\"start\":102643},{\"end\":102926,\"start\":102908},{\"end\":102942,\"start\":102926},{\"end\":103242,\"start\":103230},{\"end\":103256,\"start\":103242},{\"end\":103270,\"start\":103256},{\"end\":103284,\"start\":103270},{\"end\":103299,\"start\":103284},{\"end\":103314,\"start\":103299},{\"end\":103327,\"start\":103314},{\"end\":103343,\"start\":103327},{\"end\":103658,\"start\":103646},{\"end\":103672,\"start\":103658},{\"end\":103688,\"start\":103672},{\"end\":103701,\"start\":103688},{\"end\":104085,\"start\":104073},{\"end\":104099,\"start\":104085},{\"end\":104111,\"start\":104099},{\"end\":104124,\"start\":104111},{\"end\":104140,\"start\":104124},{\"end\":104369,\"start\":104354},{\"end\":104387,\"start\":104369},{\"end\":104402,\"start\":104387},{\"end\":104417,\"start\":104402},{\"end\":104716,\"start\":104693},{\"end\":104895,\"start\":104880},{\"end\":104911,\"start\":104895},{\"end\":105246,\"start\":105231},{\"end\":105265,\"start\":105246},{\"end\":105284,\"start\":105265},{\"end\":105303,\"start\":105284},{\"end\":105650,\"start\":105640},{\"end\":105665,\"start\":105650},{\"end\":105673,\"start\":105665},{\"end\":106087,\"start\":106076},{\"end\":106103,\"start\":106087},{\"end\":106113,\"start\":106103},{\"end\":106123,\"start\":106113},{\"end\":106137,\"start\":106123},{\"end\":106148,\"start\":106137},{\"end\":106522,\"start\":106510},{\"end\":106535,\"start\":106522},{\"end\":106550,\"start\":106535},{\"end\":106561,\"start\":106550},{\"end\":106577,\"start\":106561},{\"end\":106590,\"start\":106577},{\"end\":106606,\"start\":106590},{\"end\":107035,\"start\":107022},{\"end\":107047,\"start\":107035},{\"end\":107060,\"start\":107047},{\"end\":107071,\"start\":107060},{\"end\":107084,\"start\":107071},{\"end\":107501,\"start\":107485},{\"end\":107521,\"start\":107501},{\"end\":107534,\"start\":107521},{\"end\":107550,\"start\":107534},{\"end\":107566,\"start\":107550},{\"end\":107892,\"start\":107877},{\"end\":107905,\"start\":107892},{\"end\":107919,\"start\":107905},{\"end\":107935,\"start\":107919},{\"end\":107950,\"start\":107935},{\"end\":108229,\"start\":108215},{\"end\":108245,\"start\":108229},{\"end\":108262,\"start\":108245},{\"end\":108275,\"start\":108262},{\"end\":108288,\"start\":108275},{\"end\":108616,\"start\":108606},{\"end\":108630,\"start\":108616},{\"end\":108954,\"start\":108941},{\"end\":108966,\"start\":108954},{\"end\":108982,\"start\":108966},{\"end\":108997,\"start\":108982},{\"end\":109013,\"start\":108997},{\"end\":109403,\"start\":109394},{\"end\":109435,\"start\":109403},{\"end\":109447,\"start\":109435},{\"end\":109454,\"start\":109447},{\"end\":109858,\"start\":109848},{\"end\":109876,\"start\":109858},{\"end\":109888,\"start\":109876},{\"end\":109902,\"start\":109888},{\"end\":109917,\"start\":109902},{\"end\":109929,\"start\":109917},{\"end\":109942,\"start\":109929}]", "bib_venue": "[{\"end\":61985,\"start\":61979},{\"end\":63727,\"start\":63695},{\"end\":64136,\"start\":64074},{\"end\":64528,\"start\":64466},{\"end\":66019,\"start\":65951},{\"end\":66456,\"start\":66388},{\"end\":69441,\"start\":69379},{\"end\":75144,\"start\":75120},{\"end\":80321,\"start\":80273},{\"end\":83115,\"start\":83063},{\"end\":84904,\"start\":84838},{\"end\":88008,\"start\":87946},{\"end\":88527,\"start\":88465},{\"end\":89301,\"start\":89249},{\"end\":90082,\"start\":90057},{\"end\":94289,\"start\":94227},{\"end\":97051,\"start\":96983},{\"end\":97547,\"start\":97487},{\"end\":98048,\"start\":97985},{\"end\":98540,\"start\":98481},{\"end\":99118,\"start\":99093},{\"end\":103771,\"start\":103756},{\"end\":105808,\"start\":105749},{\"end\":60124,\"start\":60089},{\"end\":60380,\"start\":60324},{\"end\":60861,\"start\":60771},{\"end\":61262,\"start\":61225},{\"end\":61602,\"start\":61573},{\"end\":61977,\"start\":61914},{\"end\":62401,\"start\":62368},{\"end\":62856,\"start\":62734},{\"end\":63301,\"start\":63252},{\"end\":63693,\"start\":63646},{\"end\":64072,\"start\":63995},{\"end\":64464,\"start\":64387},{\"end\":64880,\"start\":64831},{\"end\":65287,\"start\":65224},{\"end\":65596,\"start\":65536},{\"end\":65949,\"start\":65875},{\"end\":66386,\"start\":66312},{\"end\":66832,\"start\":66776},{\"end\":67257,\"start\":67228},{\"end\":67738,\"start\":67693},{\"end\":68124,\"start\":68081},{\"end\":68390,\"start\":68375},{\"end\":68626,\"start\":68561},{\"end\":68936,\"start\":68887},{\"end\":69377,\"start\":69300},{\"end\":69736,\"start\":69698},{\"end\":69992,\"start\":69927},{\"end\":70390,\"start\":70339},{\"end\":70700,\"start\":70655},{\"end\":70898,\"start\":70852},{\"end\":71428,\"start\":71390},{\"end\":71798,\"start\":71752},{\"end\":72027,\"start\":71985},{\"end\":72240,\"start\":72153},{\"end\":72668,\"start\":72582},{\"end\":72969,\"start\":72920},{\"end\":73274,\"start\":73265},{\"end\":73535,\"start\":73495},{\"end\":73760,\"start\":73693},{\"end\":74062,\"start\":74002},{\"end\":74367,\"start\":74300},{\"end\":74706,\"start\":74652},{\"end\":75118,\"start\":75006},{\"end\":75670,\"start\":75619},{\"end\":76027,\"start\":76010},{\"end\":76256,\"start\":76212},{\"end\":76675,\"start\":76587},{\"end\":76983,\"start\":76927},{\"end\":77223,\"start\":77206},{\"end\":77548,\"start\":77430},{\"end\":77852,\"start\":77758},{\"end\":78193,\"start\":78168},{\"end\":78524,\"start\":78490},{\"end\":78809,\"start\":78733},{\"end\":79117,\"start\":79099},{\"end\":79430,\"start\":79381},{\"end\":79857,\"start\":79840},{\"end\":80271,\"start\":80217},{\"end\":80674,\"start\":80651},{\"end\":80975,\"start\":80968},{\"end\":81342,\"start\":81293},{\"end\":81726,\"start\":81677},{\"end\":82283,\"start\":82243},{\"end\":82565,\"start\":82468},{\"end\":83061,\"start\":82994},{\"end\":83525,\"start\":83463},{\"end\":83938,\"start\":83900},{\"end\":84250,\"start\":84168},{\"end\":84502,\"start\":84433},{\"end\":84836,\"start\":84768},{\"end\":85214,\"start\":85166},{\"end\":85549,\"start\":85531},{\"end\":85879,\"start\":85840},{\"end\":86171,\"start\":86152},{\"end\":86452,\"start\":86427},{\"end\":86869,\"start\":86811},{\"end\":87303,\"start\":87265},{\"end\":87585,\"start\":87548},{\"end\":87944,\"start\":87867},{\"end\":88463,\"start\":88386},{\"end\":88876,\"start\":88848},{\"end\":89247,\"start\":89180},{\"end\":89721,\"start\":89690},{\"end\":90055,\"start\":90002},{\"end\":90358,\"start\":90318},{\"end\":90571,\"start\":90542},{\"end\":90896,\"start\":90769},{\"end\":91243,\"start\":91174},{\"end\":91536,\"start\":91487},{\"end\":91883,\"start\":91826},{\"end\":92161,\"start\":92096},{\"end\":92462,\"start\":92418},{\"end\":92729,\"start\":92655},{\"end\":93005,\"start\":92982},{\"end\":93141,\"start\":93096},{\"end\":93494,\"start\":93433},{\"end\":93777,\"start\":93717},{\"end\":94225,\"start\":94148},{\"end\":94743,\"start\":94699},{\"end\":95157,\"start\":95095},{\"end\":95572,\"start\":95510},{\"end\":95956,\"start\":95894},{\"end\":96332,\"start\":96270},{\"end\":96632,\"start\":96615},{\"end\":96981,\"start\":96907},{\"end\":97485,\"start\":97410},{\"end\":97983,\"start\":97905},{\"end\":98479,\"start\":98405},{\"end\":98772,\"start\":98742},{\"end\":99091,\"start\":99027},{\"end\":99672,\"start\":99603},{\"end\":100143,\"start\":100052},{\"end\":100605,\"start\":100486},{\"end\":101086,\"start\":101021},{\"end\":101331,\"start\":101291},{\"end\":101675,\"start\":101645},{\"end\":101856,\"start\":101834},{\"end\":102272,\"start\":102192},{\"end\":102715,\"start\":102652},{\"end\":102988,\"start\":102942},{\"end\":103228,\"start\":103144},{\"end\":103754,\"start\":103701},{\"end\":104071,\"start\":104016},{\"end\":104466,\"start\":104417},{\"end\":104691,\"start\":104657},{\"end\":104949,\"start\":104911},{\"end\":105352,\"start\":105303},{\"end\":105747,\"start\":105673},{\"end\":106197,\"start\":106148},{\"end\":106675,\"start\":106606},{\"end\":107140,\"start\":107084},{\"end\":107483,\"start\":107393},{\"end\":107875,\"start\":107813},{\"end\":108338,\"start\":108288},{\"end\":108692,\"start\":108630},{\"end\":109067,\"start\":109013},{\"end\":109509,\"start\":109454},{\"end\":109846,\"start\":109764}]"}}}, "year": 2023, "month": 12, "day": 17}