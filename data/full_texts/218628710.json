{"id": 218628710, "updated": "2023-10-06 15:35:18.635", "metadata": {"title": "Prive-HD: Privacy-Preserved Hyperdimensional Computing", "authors": "[{\"first\":\"Behnam\",\"last\":\"Khaleghi\",\"middle\":[]},{\"first\":\"Mohsen\",\"last\":\"Imani\",\"middle\":[]},{\"first\":\"Tajana\",\"last\":\"Rosing\",\"middle\":[]}]", "venue": "2020 57th ACM/IEEE Design Automation Conference (DAC)", "journal": "2020 57th ACM/IEEE Design Automation Conference (DAC)", "publication_date": {"year": 2020, "month": 5, "day": 14}, "abstract": "The privacy of data is a major challenge in machine learning as a trained model may expose sensitive information of the enclosed dataset. Besides, the limited computation capability and capacity of edge devices have made cloud-hosted inference inevitable. Sending private information to remote servers makes the privacy of inference also vulnerable because of susceptible communication channels or even untrustworthy hosts. In this paper, we target privacy-preserving training and inference of brain-inspired Hyperdimensional (HD) computing, a new learning algorithm that is gaining traction due to its light-weight computation and robustness particularly appealing for edge devices with tight constraints. Indeed, despite its promising attributes, HD computing has virtually no privacy due to its reversible computation. We present an accuracy-privacy trade-off method through meticulous quantization and pruning of hypervectors, the building blocks of HD, to realize a differentially private model as well as to obfuscate the information sent for cloud-hosted inference. Finally, we show how the proposed techniques can be also leveraged for efficient hardware implementation.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2005.06716", "mag": "3092127391", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/dac/KhaleghiIR20", "doi": "10.1109/dac18072.2020.9218493"}}, "content": {"source": {"pdf_hash": "8c057936241d77ffa86bdd1d4ea931d3d2c0aa5a", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2005.06716v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2005.06716", "status": "GREEN"}}, "grobid": {"id": "fd707b830b06acc5e47819da57490b37386fc7f7", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/8c057936241d77ffa86bdd1d4ea931d3d2c0aa5a.txt", "contents": "\nPrive-HD: Privacy-Preserved Hyperdimensional Computing\n\n\nBehnam Khaleghi bkhaleghi@ucsd.edu \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nMohsen Imani moimani@ucsd.edu \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nTajana Rosing tajana@ucsd.edu \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nPrive-HD: Privacy-Preserved Hyperdimensional Computing\n\nThe privacy of data is a major challenge in machine learning as a trained model may expose sensitive information of the enclosed dataset. Besides, the limited computation capability and capacity of edge devices have made cloud-hosted inference inevitable. Sending private information to remote servers makes the privacy of inference also vulnerable because of susceptible communication channels or even untrustworthy hosts. In this paper, we target privacy-preserving training and inference of brain-inspired Hyperdimensional (HD) computing, a new learning algorithm that is gaining traction due to its light-weight computation and robustness particularly appealing for edge devices with tight constraints. Indeed, despite its promising attributes, HD computing has virtually no privacy due to its reversible computation. We present an accuracy-privacy trade-off method through meticulous quantization and pruning of hypervectors, the building blocks of HD, to realize a differentially private model as well as to obfuscate the information sent for cloudhosted inference. Finally, we show how the proposed techniques can be also leveraged for efficient hardware implementation.\n\nI. INTRODUCTION\n\nThe efficacy of machine learning solutions in performing various tasks has made them ubiquitous in different application domains. The performance of these models is proportional to the size of the training dataset. Thus, machine learning models utilize copious proprietary and/or crowdsourced data, e.g., medical images. In this sense, different privacy concerns arise. The first issue is with model exposure [1]. Obscurity is not considered a guaranteed approach for privacy, especially parameters of a model (e.g., weights in the context of neural networks) that might be leaked through inspection. Therefore, in the presence of an adversary with full knowledge of the trained model parameters, the model should not reveal the information of constituting records.\n\nSecond, the increasing complexity of machine learning models, on the one hand, and the limited computation and capacity of edge devices, especially in the IoT domain with extreme constraints, on the other hand, have made offloading computation to the cloud indispensable [2], [3]. An immediate drawback of cloud-based inference is compromising client data privacy. The communication channel is not only susceptible to attacks, but an untrusted cloud itself may also expose the data to third-party agencies or exploit it for its benefits. Therefore, transferring the least amount of information while achieving maximal accuracy is of utmost importance. A traditional approach to deal with such privacy concerns is employing secure multi-party computation that leverages homomorphic encryption whereby the device encrypts the data, and the host performs computation on the ciphertext [4]. These techniques, however, impose a prohibitive computation cost on edge devices.\n\nPrevious work on machine learning, particularly deep neural networks, have come up with generally two approaches to preserve the privacy of training (model) or inference. For privacypreserving training, the well-known concept of differential privacy is incorporated in the training [5], [6]. Differential privacy, often known as the standard notation of guaranteed privacy, aims to apply a carefully chosen noise distribution to make the response of a query (in our concept, the model being trained on a dataset) over a database randomized enough so the singular records remain indistinguishable whilst the query result is fairly accurate. Perturbation of partially processed information, e.g., the output of the convolution layer in neural networks, before offloading to a remote server is another trend of privacy-preserving studies [7], [8], [9] that target the inference privacy. Essentially, it degrades the mutual information of the conveyed data. This approach degrades the prediction accuracy and requires (re)-training the neural network to compensate the injected noise [7] or analogously learning the parameters of a noise that can be tolerated by the network [9], [10], which are not always feasible, e.g., when the model is inaccessible.\n\nIn this paper, for the first time, we scrutinize Hyperdimensional (HD) computing from a privacy perspective. HD is a novel efficient learning paradigm that imitates the brain functionality in cognitive tasks, in the sense that the human brain computes with patterns of neural activity rather than scalar values [11], [12], [13], [14]. These patterns and underlying computations can be realized by points and light-weight operations in a hyperdimensional space, i.e., by hypervectors of \u223c10,000 dimensions. Similar to other statistical mechanisms, the privacy of HD might be preserved by noise injection, where formally the granted privacy budget is directly proportional to the amount of the introduced noise and indirectly to the sensitivity of mechanism. Nonetheless, as a query hypervector (HD's raw output) has thousands of w-bits dimensions, the sensitivity of the HD model can be extremely large, which requires a tremendous amount of noise to guarantee differential privacy, which significantly reduces accuracy. Similarly, the magnitude of each output dimension is large (each up to 2 w ), so is the intensity of the required noise to disguise the transferring information for inference. Therefore, we require more prudent approaches to augment HD with differentially private training as well as blurring the information of offloaded inference.\n\nOur main contributions are as follows. We show the privacy breach of HD and introduce different techniques including well-devised hypervector (query and/or class) quantization and dimension pruning to reduce the sensitivity, and consequently, the required noise to achieve a differentially private HD model. We also target inference privacy by showing how quantizing the query hypervector, during inference, can achieve good prediction accuracy as well as multifaceted power efficiency while significantly degrading the Peak Signal-to-Noise Ratio (PSNR) of reconstructed inputs (i.e., diminishing useful transferred information). Finally, we propose an approximate hardware implementation that benefits from the aforementioned innovations for further performance and power efficiency.\n\n\nII. PRELIMINARY\n\n\nA. Hyperdimensional Computing\n\nEncoding is the first and major operation involved in both training and inference of HD. Assume that an input vector (an image, voice, etc.) comprises D iv dimensions (elements or features). Thus, each input V iv can be represented as (1). 'v i 's are elements of the input, where each feature v i takes value among f 0 to f iv \u22121 . In a black and white image, there are only two feature levels ( iv = 2), and f 0 = 0, and f 1 = 1.\nV iv = v 0 , v 1 , \u00b7 \u00b7 \u00b7 , v Div\u22121 |v i | \u2208 F = {f 0 , f 1 , \u00b7 \u00b7 \u00b7 f iv \u22121 }(1)\nVaried HD encoding techniques with different accuracyperformance trade-off have been proposed [11], [15]. Equation (2) shows analogous encodings that yield accuracies similar to or better than the state of the art [15].\nH = Div\u22121 k=0 |v k | \u2208F \u00b7 B k (2a) H = Div\u22121 k=0 L v k \u00b7 B k (2b)\n' B k 's are randomly chosen hence orthogonal bipolar base hypervectors of dimension D hv 10 4 to retain the spatial or temporal location of features in an input. That is,\nB k \u2208 {\u22121, +1} D hv and \u03b4( B k1 , B k2 ) 0, where \u03b4 denotes the cosine similarity: \u03b4( B k1 , B k2 ) = B k 1 \u00b7 B k 2 B k 1 \u00b7 B k 2\n. Evidently, there are D iv fixed base/location hypervectors for an input (one per feature). The only difference of the encodings in (2a) and (2b) is that in (2a) the scalar value of each input feature v k (mapped/quantized to nearest f in F) is directly multiplied in the corresponding base hypervector B k . However, in (2b), there is a level hypervector of the same length (D hv ) associated with different feature values. Thus, for k th feature of the input, instead of multiplying f |v k | |v k | by location vector B k , the associated hypervector L v k performs a dotproduct with B k . As both vectors are binary, the dot-product reduces to dimension-wise XNOR operations. To maintain the closeness in features (to demonstrate closeness in original feature values), L 0 and L iv \u22121 are entirely orthogonal, and each L k+1 is obtained by flipping randomly chosen D hv 2\u00b7 iv bits of L k .\n\nTraining of HD is simple. After generating each encoding hypervector H l of inputs belonging to class/label l, the class hypervector C l can be obtained by bundling (adding) all H l s. Assuming there are J inputs having label l:\nC l = J j H l j (3)\nInference of HD has a two-step procedure. The first step encodes the input (similar to encoding during training) to produce a query hypervector H. Thereafter, the similarity (\u03b4) of H and all class hypervectors are obtained to find out the class with highest similarity:\n\u03b4( H, C l ) = H \u00b7 C l H \u00b7 C l = D hv \u22121 k=0 h k \u00b7 c l k D hv \u22121 k=0 h 2 k \u00b7 D hv \u22121 k=0 c l 2 k(4)\nNote that\nD hv \u22121 k=0\nh 2 k is a repeating factor when comparing with all classes, so can be discarded. The\nD hv \u22121 k=0 c l 2\nk factor is also constant for a classes, so only needs to be calculated once.\n\nRetraining can boost the accuracy of the HD model by discarding the mispredicted queries from corresponding mispredicted classes, and adding them to the right class. Retraining examines if the model correctly returns the label l for an encoded query H. If the model mispredicts it as label l , the model updates as follows.\nC l = C l + H C l = C l \u2212 H (5)\n\nB. Differential Privacy\n\nDifferential privacy targets the indistinguishability of a mechanism (or algorithm), meaning whether observing the output of an algorithm, i.e., computations' result, may disclose the computed data. Consider the classical example of a sum query f (n) = n 1 g(x i ) over a database with x i s being the first to n th rows, and g(x i ) \u2208 {0, 1}, i.e., the value of each record is either 0 or 1. Although the function f does not reveal the value of an arbitrary record m, it can be readily obtained by two requests as f (m) \u2212 f (m \u2212 1). Speaking formally, a randomized algorithm M is \u03b5-indistinguishable or \u03b5-differentially private if for any inputs D 1 and D 2 that differ in one entry (a.k.a adjacent inputs) and any output S of M, the following holds: This definition guarantees that observing D 1 instead of D 2 scales up the probability of any event by no more than e \u03b5 . Evidently, smaller values of non-negative \u03b5 provide stronger guaranteed privacy. Dwork et al. have shown that \u03b5-differential privacy can be ensured by adding a Laplace noise of scale Lap( \u2206f \u03b5 ) to the output of algorithm [5]. \u2206f , defined as 1 norm in Equation (7), denotes the sensitivity of the algorithm which represents the amount of change in a mechanism's output by changing one of its arguments, e.g., inclusion/exclusion of an input in training.\nP r[M(D 1 ) \u2208 S] \u2264 e \u03b5 \u00b7 P r[M(D 2 ) \u2208 S](6)\u2206f = f (D 1 ) \u2212 f (D 2 ) 1(7)\nDwork et al. have also introduced a more amiable \u03b4approximate \u03b5-indistinguishable privacy guarantee, which allows the \u03b5-privacy to be broken by a probability of \u03b4 [16].\nM(D) = f (D) + G(0, \u2206f 2 \u03c3 2 )(8)\nG(0, \u2206f 2 \u03c3 2 ) is Gaussian noise with mean zero and standard deviation of \u2206f \u00b7 \u03c3. Both f and G are D hv |C| dimensions, i.e., |C| output class hypervectors of D hv dimensions.\nHere, \u2206f = f (D 1 ) \u2212 f (D 2 ) 2 is 2 norm, which relaxes the amount of additive noise. f meets (\u03b5, \u03b4)-privacy if \u03b4 \u2265 4 5 e \u2212 (\u03c3\u03b5) 2 2 [1]\n. Achieving small \u03b5 for a given \u03b4 needs larger \u03c3, which by (8) translates to larger noise.\n\n\nIII. PROPOSED METHOD: PRIVE-HD\n\n\nA. Privacy Breach of HD\n\nIn contrast to the deep neural networks that comprise nonlinear operations that somewhat cover up the details of raw input, HD operations are fairly reversible, leaving it zero privacy. That is, the input can be reconstructed from the encoded hypervector. Consider the encoding of Equation (2a), which is also illustrated by Fig. 1. Multiplying each side of the equation to hypevector B 0 , for each dimension j gives: B 0,j \u2208 {\u22121, +1}, so B 2 0,j = 1. Summing all dimensions together yields:\nH j \u00b7 B 0,j = Div\u22121 k=0 (|v k | \u00b7 B k,j ) \u00b7 B 0,j = |v 0 | \u00b7 B 2 0,j + Div\u22121 k=1 |v k |B k,j B 0,j = |v 0 | + Div\u22121 k=1 |v k |B k,j B 0,j(9)D hv \u22121 j=0 H j \u00b7 B 0,j = D hv \u00b7 |v 0 | + Div\u22121 k=1 |v k | D hv \u22121 j=0 B k,j \u00b7 B 0,j(10)\nAs the base hypervectors are orthogonal and especially D hv is large,\nD hv \u22121 j=0\nB k,j \u00b7 B 0,j 0 in the right side of Equation (10). It means that every feature |v m | can be retrieved back by |v m | = H\u00b7 Bm D hv . Note that without lack of generality we assumed |v m | = f vm , i.e., features are not normalized or quantized. Indeed, we are retrieving the features ('f i 's), that might or might not be the exact raw elements. Also, although we showed the reversibility of the encoding in (2a), it can easily be adjusted to the other HD encodings. Fig. 2 shows the reconstructed inputs of MNIST samples by using Equation (10) to achieve each of 28 \u00d7 28 pixels, one by one.\n\nThat being said, the encoded hypervector H sent for cloudhosted inference can be inspected to reconstruct the original input. This reversibility also breaches the privacy of the HD model. Consider that, according to the definition of differential privacy, two datasets D 1 and D 2 differ by one input. If we subtract all class hypervectors of the models trained over D 1 and D 2 , the result (difference) will exactly be the encoded vector of the missing input (remember from Equation (3) that class hypervectors are simply created by adding encoded hypervectors of associated inputs). The encoded hypervector, hence, can be decoded back to obtain the missing input.\n\n\nB. Differentially Private HD Training\n\nLet f D1 and f D2 be models trained with encoding of Equation (2a) over datasets that differ in a single datum (input) present in D 2 but not in D 1 . The outputs (i.e., class hypervectors) of f (D 1 ) and f (D 2 ) thus differ in inclusion of a single D hv \u2212dimension encoded vector that misses from a particular class of f (D 1 ). The other class hypervectors will be the same. Each bipolar hypervector L v k \u00b7 B k (see Equation (2) or Fig. 1) constituting the encoding H is random and identically distributed, hence according to the central limit theorem H is approximately normally distributed with \u00b5 = 0 and \u03c3 2 = D iv , i.e., the number of vectors building H. In 1 norm, however, the absolute value of the encoded H matters. Since H has normal distribution, mean of the corresponding folded (absolute) distribution is: The 1 sensitivity will therefore be \u2206f = H 1 = 2Div \u03c0 \u00b7 D hv . For the 2 sensitivity we indeed deal with a squared Gaussian (chi-squared) distribution with freedom degree of one, thus:\n\u00b5 | H| = \u03c3 2 \u03c0 e \u2212 \u00b5 2 2\u03c3 2 + \u00b5(1 \u2212 \u03a6(\u2212 \u00b5 \u03c3 )) = 2D iv \u03c0(11)\u2206f = H 2 = D hv \u00b7 \u00b5 = D hv \u00b7 \u03c3 2 = D hv \u00b7 D iv\n(12) Note that the mean of the chi-squared distribution (\u00b5 ) is equal to the variance (\u03c3 2 ) of the original distribution of H. Both Equation (11) and (12) imply a large noise to guarantee privacy. For instance, for a modest 200-features input (D iv = 200) the 2 sensitivity is 10 3 \u221a 2 while a proportional noise will annihilate the model accuracy. In the following, we articulate the proposed techniques to shrink the variance of the required noise. In the rest of the paper, we only target Gaussian noise, i.e., (\u03b5, \u03b4)\u2212privacy, since in our case it needs a weaker noise.\n\n1) Model Pruning: An immediate observation from Equation (12) is to reduce the number of hypervectors dimension, D hv to mollify the sensitivity, hence, the required noise. Not all the dimensions of a class hypervector have the same impact on prediction. Remember, from Equation (4), that prediction is realized by a normalized dot-product between the encoded query and class hypervectors. Intuitively, we may prune out the close-to-zero class elements as their elementwise multiplication with query elements leads to less-effectual results. Notice that this concept (i.e., discarding a major portion of the weights without significant accuracy loss) does not readily hold for deep neural networks as the impact of those small weights might be amplified by large activations of previous layers. In HD, however, information is uniformly distributed over the dimensions of the query hypervector, so overlooking some of the query's information (the dimensions corresponding to discarded less-effectual dimensions of class hypervectors) should not cause unbearable accuracy loss.\n\nWe demonstrate the model pruning as an example in Fig. 3 (that belongs to a speech recognition dataset). In Fig. 3(a), after training the model, we remove all dimensions of a certain class hypervector. Then we increasingly add (return) its dimensions starting from the less-effectual dimensions. That is, we first restore the dimensions with (absolute) values close to zero. Then we perform a similarity check (i.e., prediction of a certain query hypervector via normalized dot-product) to figure out what portion of the original dot-product value is retrieved. As it can be seen in the same figure, the first 6,000 close-to- zero dimensions only retrieve 20% of the information required for a fully confident prediction. This is because of the uniform distribution of information in the encoded query hypervector: the pruned dimensions do not correspond to vital information of queries. Fig. 3(b) further clarifies our observation. Pruning the less-effectual dimensions slightly reduces the prediction information of both class A (correct class, with an initial total of 1.0) and class B (incorrect class). As more effectual dimensions of the classes are pruned, the slope of information loss plunges. It is worthy of note that in this example the ranks of classes A and B have been retained. We augment the model pruning by retraining explained in Equation (5) to partially recover the information of the pruned dimensions in the remaining ones. For this, we first nullify s% of the close-to-zero dimensions of the trained model, which perpetually remain zero. Therefore, during the encoding of query hypervectors, we do not anymore need to obtain the corresponding indexes of queries (note that operations are dimension-wise), which translates to reduced sensitivity. Thereafter, we repeatedly iterate over the training dataset and apply Equation (5) to update the classes involved in mispredictions. Fig. 4 shows 1-2 iteration(s) is sufficient to achieve the maximum accuracy (the last iteration simple shows the maximum of previous ones). In lower dimension, decreasing the number of levels ( iv in Equation (1), denoted by L in the legend), achieves slightly higher accuracy as hypervectors lose the capacity to embrace fine-grained details.\n\n2) Encoding Quantization: Previous work on HD computing have introduced the concept of model quantization for compression and energy efficiency, where both encoding and class hypervectors are quantized at the cost of significant accuracy loss [17]. We, however, only target quantizing the encoding hypervectors since the sensitivity is merely determined by the 2 norm of encoding. Equation (13) shows the 1-bit quantization of encoding in (2a). The original scalarvector product, as well as the accumulation, is performed in full-precision, and only the final hypervector is quantized. The resultant class hypervectors will also be non-binary (albeit with reduced dimension values). 10,000 dimensions, the bipolar (i.e., \u00b11 or sign) quantization achieves 93.1% accuracy while it is 88.1% in previous work [17]. This improvement comes from the fact that we do not quantize the class hypervectors. We then leveraged the aforementioned pruning approach to simultaneously employ quantization and pruning, as demonstrated in Fig. 5(a). In D hv = 1000, the 2-bit quantization ({\u22122, \u00b11, 0}) achieves 90.3% accuracy, which is only 3% below the full-precision full-dimension baseline. It should note be noted that the small oscillations in specific dimensions, e.g., lower accuracy in 5,000 dimensions compared to 4,000 dimensions in bipolar quantization, are due to randomness of the initial hypervectors and non-orthogonality that show up in smaller space. Fig. 5(b) shows the sensitivities of the corresponding models. After quantizing, the number of features, D iv (see Equation (12)), does not matter anymore. The sensitivity of a quantized model can be formulated as follows.\nH q1 = sign Div\u22121 k=0 |v k | \u2208F \u00b7 B k(13)\u2206f = H 2 = ( k\u2208|q| p k \u00b7 D hv \u00b7 k 2 ) 1/2(14)\np k shows the probability of k (e.g., \u00b11) in the quantized encoded hypervector, so p k \u00b7 D hv is the total occurrence of k quantized encoded hypervector. The rest is simply the definition of 2 norm. As hypervectors are randomly generated and i.i.d, the distribution of k \u2208 |q| is uniform. That is, in the bipolar quantization, roughly D hv /2 of encoded dimensions are 1 (or \u22121). We therefore also exploited a biased quantization to give more weight for p 0 in the ternary quantization, dubbed as 'ternary (biased)' in Fig. 5(b). Essentially the biased quantization assigns a quantization threshold to conform to p \u22121 = p 1 = 1 4 , while p 0 = 1 2 . This reduces the sensitivity by a factor of and pruning, we could shrink the 2 sensitivity to \u2206f = 22.3, which originally was \u221a 10 4 \u00b7 617 = 2484 for the speech recognition with 617-features inputs. In Section IV we will examine the impact of adding such noise on the model accuracy for varied privacy budgets.\n\n\nC. Inference Privacy\n\nBuilding upon the multi-layer structure of ML, IoT devices mostly rely on performing primary (e.g., feature extraction) computations on the edge (or edge server) and offload the decision-making final layers to the cloud [2], [3]. To tackle the privacy challenges of offloaded inference, previous work on DNN-based inference generally inject noise on the offloaded computation. This necessitates either to retrain the model to tolerate the injected noise distribution [7], or analogously, learn the parameters of a noise that maximally perturbs the information with preferably small impact on the accuracy [9], [10].\n\nIn Section III-A we demonstrated how the original feature vector can be reconstructed from the encoding hypervectors. Inspired by the encoding quantization technique explained in the previous section, we introduce a turnkey technique to obfuscate the conveyed information without manipulating or even accessing the model. Indeed, we observed that quantizing down to 1-bit (bipolar) even in the presence of model pruning could yield acceptable accuracy. As shown in Fig. 5(a), 1-bit quantization only incurred 0.25% accuracy loss. These models, however, were trained by accumulating quantized encoding hypervectors. Intuitively, we expect that performing inference with quantized query hypervectors but on full-precision classes (class hypervectors generated by nonquantized encoding hypervectors) should give the same or better accuracy as quantizing is nothing but degrading the information. In other words, in the previous case, we deal with checking the similarity of a degraded query with classes built up also from degraded information, but now we check the similarity of a degraded query with information-rich classes.\n\nTherefore, instead of sending the raw data, we propose to perform the light-weight encoding part on the edge and quantize the encoded vector before offloading to the remote host. We call it inference quantization do distinguish between encoding quantization, as inference quantization targets a fullprecision model. In addition, we also nullify a specific portion of encoded dimensions, i.e., mask out them to zero, to further obfuscate the information. Remember that our technique does not need to modify or access to the trained model. Fig. 6 shows the impact of inference 1-bit quantization on the speech recognition model. When only the offloaded information (i.e., query hypervector with 10,000 dimensions) is quantized, the prediction accuracy is 92.8%, which is merely 0.5% lower than the full-precision baseline. By masking out 5,000 dimensions, the accuracy is still above 91%, while the reconstructed image becomes blurry. While the reconstructed image (from a typical encoded hypervector) has a PSNR of 23.6 dB, in our technique, it shrinks to 13.1.\n\n\nD. Hardware Optimization\n\nThe simple bit-level operations involved in the proposed techniques and dimension-wise parallelism of the computation makes FPGA a highly efficient platform to accelerate privacyaware HD computing [18], [17]. We devise efficient implementations to further improve the performance and power. We adopt the encoding of Equation (2b) as it provides better optimization opportunity.\n\nFor the 1-bit bipolar quantization, a basic approach is adding up all bits of the same dimension, followed by a final sign/threshold operation. This is equivalent to a majority operation between '\u22121's and '+1's. Note that we can represent \u22121 by 0, and +1 by 1 in hardware, as it does not change the logic behind. We shrink this majority by approximating it as partial majorities. As shown by Fig. 7(a), we use 6-input look-up tables (LUT-6) to obtain the majority of every six bits (out of d iv bits), which are binary elements making a certain dimension. In the case an LUT has equal number of 0 and 1 inputs, it breaks the tie randomly (predetermined) We can repeat this till log d iv stages but that would degrade accuracy. Thus, we use majority LUTs only in the first stage, so the next stages are typical adder-tree [18]. This approach is not exact, however, in practice it imposes < 1% accuracy loss due to inherent error tolerance of HD, especially we use majority LUTs only in the first stage, so the next stages are typical adder-tree [18]. Total number of LUT-6s will be:\nn LUT6 = d iv 6 + 1 6 ( log div i=1 d iv 3 \u00d7 i 2 i\u22121 ) 7 18 d iv(15)\nwhich is 70.8% less than 4 3 d iv required in the exact addertree implementation.\n\nFor the ternary quantization, we first note that each dimension can be {0, \u00b11}, so requires two bits. The minimum (maximum) of adding three dimensions is therefore \u22123 (+3), which requires three bits, while typical addition of three 2bit values requires four bits. Thus, as shown in Fig. 7(b), we can pass numbers (dimensions) a 1 a 0 , b 1 b 0 and c 1 c 0 to three LUT-6 to produce the 3-bit output. Instead of using an exact adder-tree to sum up the resultant div 3 three-bits, we use saturated adder-tree where the intermediate adders maintain a bit-width of three through truncating the least-significant bit of output. In a similar fashion to Equation (15), we can show that this technique uses 2d iv LUT-6, saving 33.3% compared to 3d iv in the case of using exact adder-tree to sum up d iv ternary values.\n\n\nIV. RESULTS\n\n\nA. Differentially Private Training\n\nWe evaluate the privacy metrics of the proposed techniques by training three models on different categories: the same speech recognition dataset (ISOLET) [19] we used within the paper, the MNIST handwritten digits dataset, and Caltech web faces dataset (FACE) [20]. The goal of training evaluation is to find out the minimum \u03b5 with affordable impact on accuracy. Similar to [1], we set the \u03b4 parameter of the privacy to 10 \u22125 (which is reasonable especially the size of our datasets are smaller than 10 5 ). Accordingly, for a particular \u03b5, we can obtain the \u03c3 factor of the required Gaussian noise (see Equation (8)) from \u03b4 \u2265 4 5 e \u2212 (\u03c3\u03b5) 2 2 [1]. We iterate over different values of \u03b5 to find the minimum while the prediction accuracy remains acceptable. Fig. 8(a)-(c) shows the obtained \u03b5 for each training model and corresponding accuracy. For instance, for the FACE model ( Fig. 8(b)), \u03b5 = 1 (labeled by eps1) gives an accuracy within 1.4% of the non-private full-precision model. Shown by the same figure, slightly reducing \u03b5 to 0.5 causes significant accuracy loss. This figure also reveals where the minimum \u03b5 is obtained. For each \u03b5, using the proposed pruning and ternary quantization, we reduce the dimension to decrease the sensitivity. At each dimension, we inject a Gaussian noise with standard deviation of \u2206f \u00b7 \u03c3 with \u03c3 obtainable from \u03b4 = 10 \u22125 = 4 5 e \u2212 (\u03c3\u03b5) 2 2 , which is \u223c4.75 for a demanded \u03b5 = 1. \u2206f of different quantization schemes and dimensions is already discussed and shown by Fig. 5. When the model has large number of dimensions, its primary accuracy is better, but on the other hand has higher sensitivity (\u221d \u221a D hv ). Thus, there is a trade-off between dimension reduction to decrease sensitivity (hence, noise) and inherent accuracy degradation associated with dimension reduction itself. For FACE model, we see that optimal number of dimension to yield the minimum is 7,000. It should be noted that although there is no prior work on HD privacy (and few works on DNN training privacy) for a head-to-head comparison, we could obtain a single digit \u03b5 = 2 for the MNIST dataset with \u223c1% accuracy loss (with 5,000 ternary dimensions), which is comparable to the differentially private DNN training over the MNIST in [1] that achieved the same \u03b5 with \u223c 4% accuracy loss. In addition, differentially private DNN training requires very large number of training epochs where the per-epoch training time also increases (e.g., by 4.5\u00d7 in [1]) while we readily apply the noise after building up all class hypervectors. We also do not retrain the noisy model as it violates the concept of differential privacy. Fig. 8(d) shows the impact of training data size on the accuracy of the FACE differentially private model. Obviously, increasing the number of training inputs enhances the model accuracy. This due to the fact that, because of quantization of encoded hypervectors, the class vectors made by their bundling have smaller values. Thus, the magnitude of induced noise becomes comparable to the class values. As more data is trained, the variance of class dimensions also increases, which can better bury the same amount of noise. This can be considered a vital insight in privacy-preserved HD training.\n\n\nB. Privacy-Aware Inference\n\nHere we show a similar result of Fig. 6 on HD models trained on different datasets. Fig. 9(a) shows the impact of bipolar quantization of encoding hypervectors on the prediction accuracy. As discussed in Section III-C, here we merely quantize the encoded hypervectors (to be offloaded to cloud for inference) while the class hypervectors remain intact. Without pruning the dimensions, the accuracy of ISOLET, FACE, and MNIST degrades by 0.85% on average, while the mean squared error of the reconstructed input increases by 2.36\u00d7, compared to the data reconstructed (decoded) from conventional encoding. Since the dataset of ISOLET and FACE are extracted features (rather than raw data), we cannot visualize them, but from Fig. 9(b) we can observe that ISOLET gives a similar MSE error to MNIST (for which the visualized data can be seen in Fig. 6) while the FACE dataset leads to even higher errors.\n\nIn conjunction with quantizing the offloaded inference, as discussed before, we can also prune some of the encoded dimensions to further obfuscate the information. We can see that in the ISOLET and FACE models, discarding up to 6,000 dimensions leads to a minor accuracy degradation while the increase of their information loss (i.e., increased MSE) is considerable. In the case of MNIST, however, accuracy loss is abrupt and does not allow for large pruning. However, even pruning 1,000 of its dimensions (together with quantization) reduces the PSNR to \u223c15, meaning that reconstruction of our encoding is highly lossy.\n\n\nC. FPGA Implementation\n\nWe implemented the HD inference using the proposed encoding with the optimization detailed in Section III-D. We implemented a pipelined architecture with building blocks shown in Fig. 7(a) as in the inference we only used binary (bipolar) quantization. We used a hand-crafted design in Verilog HDL with Xilinx primitives to enable efficient implementation of the cascaded LUT chains. Except the proposed approximate adders, the rest of implementation follows an architecture similar to [18]. Table I compares the results of Prive-HD on Xilinx Kintex-7 FPGA KC705 Evaluation Kit, versus software implementation on Raspberry Pi 3 embedded processor and NVIDIA GeForce GTX 1080 Ti GPU. Throughout denotes number of inputs processed per second, and energy indicates energy (in Joule) of processing a single input. All benchmarks have have the same number of dimensions in different platforms. For FPGA, we assumed that all data resides in the off-chip DRAM, otherwise the latency will be affected but throughout remains intact as off-chip latency is eliminated in the computation pipeline. Thanks to the massive bit-level parallelism of FPGA with relatively low power consumption (\u223c7W obtained via Xilinx Power Estimator, compared to 3W of Raspberry Pi obtained by Hioki 3334 power meter, and 120W of GPU obtained through NVIDIA system management interface), the average inference throughput of Prive-HD is 105,067\u00d7 and 15.8\u00d7 of Raspberry Pi and GPU, respectively. Prive-HD improves the energy by 52,896\u00d7 and 288\u00d7 compared to Raspberry Pi and GPU, respectively.\n\n\nV. CONCLUSION\n\nIn this paper, we disclosed the privacy breach of hyperdimensional computing and presented a privacy-preserving training scheme by quantizing the encoded hypervectors involved in training, as well as reducing their dimensionality, which together enable employing differential privacy by relieving the required amount of noise. We also showed that we can leverage the same quantization approach in conjunction with nullifying particular elements of encoded hypervectors to obfuscate the information transferred for untrustworthy cloud (or link) inference. We also proposed hardware optimization for efficient implementation of the quantization schemes by essentially using approximate cascaded majority operations. Our training technique could address the discussed challenges of HD privacy and achieved single-digit privacy metric. Our proposed inference, which can be readily employed in a trained HD model, could reduce the PSNR of an image dataset to below 15 dB with affordable impact on accuracy. Eventually, we implemented the proposed encoding on an FPGA platform which achieved 15.8\u00d7 speed-up and 288.8\u00d7 energy efficiency over an optimized GPU implementation.\n\nFig. 2 .\n2Original and retrieved handwritten digits.\n\nFig. 3 .\n3Impact of increasing (left) and reducing (right) effectual dimensions.\n\nFig. 4 .\n4Retraining to recover accuracy loss.\n\nFig. 5 Fig. 5 .\n55shows the impact of quantizing the encoded hypervectors on the accuracy and the sensitivity of the same speech recognition dataset trained with such encoding. Accuracy-sensitivity trade-off of encoding quantization.\n\nFig. 6 .\n6Impact of inference quantization and dimension masking on PSNR and accuracy.\n\nFig. 7 .\n7Principal blocks of FPGA implementation.\n\nFig. 8 .Fig. 9 .\n89Investigating the optimal \u03b5, dimensions and impact of data size in the benchmark models. Impact of inference quantization (left) and dimension masking on accuracy and MSE.\n\nTABLE I COMPARING\nITHE PRIVE-HD ON FPGA VERSUS RASPBERRY PI AND GPURaspberry Pi \nGPU \nPrive-HD (FPGA) \nThroughput Energy Throughput Energy Throughput Energy \nISOLET \n19.8 \n0.155 \n135, 300 8.9 \u00d7 10 \u22124 2, 500, 000 2.7 \u00d7 10 \u22126 \nFACE \n11.9 \n0.266 \n104, 079 1.2 \u00d7 10 \u22123 694, 444 4.7 \u00d7 10 \u22126 \nMNIST \n23.9 \n0.129 \n140, 550 8.5 \u00d7 10 \u22124 3, 125, 000 3.0 \u00d7 10 \u22126 \n\n\nACKNOWLEDGEMENTSThis work was supported in part by CRISP, one of six centers in JUMP, an SRC program sponsored by DARPA, in part by SRC-Global Research Collaboration grant, and also NSF grants #1527034, #1730158, #1826967, and #1911095.\nDeep learning with differential privacy. M Abadi, A Chu, I Goodfellow, H B Mcmahan, I Mironov, K Talwar, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. the 2016 ACM SIGSAC Conference on Computer and Communications SecurityM. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar et al., \"Deep learning with differential privacy,\" in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, 2016, pp. 308-318.\n\nDistributed deep neural networks over the cloud, the edge and end devices. S Teerapittayanon, B Mcdanel, H.-T Kung, 2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS). IEEES. Teerapittayanon, B. McDanel, and H.-T. Kung, \"Distributed deep neural networks over the cloud, the edge and end devices,\" in 2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS). IEEE, 2017, pp. 328-339.\n\nLearning iot in edge: Deep learning for the internet of things with edge computing. H Li, K Ota, M Dong, IEEE network. 321H. Li, K. Ota, and M. Dong, \"Learning iot in edge: Deep learning for the internet of things with edge computing,\" IEEE network, vol. 32, no. 1, pp. 96-101, 2018.\n\nCryptonets: Applying neural networks to encrypted data with high throughput and accuracy. R Gilad-Bachrach, N Dowlin, K Laine, K Lauter, M Naehrig, J Wernsing, International Conference on Machine Learning. R. Gilad-Bachrach, N. Dowlin, K. Laine, K. Lauter, M. Naehrig, and J. Wernsing, \"Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy,\" in International Conference on Machine Learning, 2016, pp. 201-210.\n\nCalibrating noise to sensitivity in private data analysis. C Dwork, F Mcsherry, K Nissim, A Smith, Theory of cryptography conference. SpringerC. Dwork, F. McSherry, K. Nissim, and A. Smith, \"Calibrating noise to sensitivity in private data analysis,\" in Theory of cryptography conference. Springer, 2006, pp. 265-284.\n\nDifferentially private recommender systems: Building privacy into the netflix prize contenders. F Mcsherry, I Mironov, Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. the 15th ACM SIGKDD international conference on Knowledge discovery and data miningF. McSherry and I. Mironov, \"Differentially private recommender sys- tems: Building privacy into the netflix prize contenders,\" in Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, 2009, pp. 627-636.\n\nNot just privacy: Improving performance of private deep learning in mobile cloud. J Wang, J Zhang, W Bao, X Zhu, B Cao, P S Yu, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningJ. Wang, J. Zhang, W. Bao, X. Zhu, B. Cao, and P. S. Yu, \"Not just pri- vacy: Improving performance of private deep learning in mobile cloud,\" in Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2018, pp. 2407-2416.\n\nA hybrid deep learning architecture for privacypreserving mobile analytics. S A Osia, A S Shamsabadi, S Sajadmanesh, A Taheri, K Katevas, H R Rabiee, IEEE Internet of Things Journal. S. A. Osia, A. S. Shamsabadi, S. Sajadmanesh, A. Taheri, K. Katevas, H. R. Rabiee et al., \"A hybrid deep learning architecture for privacy- preserving mobile analytics,\" IEEE Internet of Things Journal, 2020.\n\nShredder: Learning noise distributions to protect inference privacy. F Mireshghallah, M Taram, P Ramrakhyani, A Jalali, D Tullsen, H Esmaeilzadeh, Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems. the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating SystemsF. Mireshghallah, M. Taram, P. Ramrakhyani, A. Jalali, D. Tullsen, and H. Esmaeilzadeh, \"Shredder: Learning noise distributions to protect inference privacy,\" in Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, 2020, pp. 3-18.\n\nA principled approach to learning stochastic representations for privacy in deep neural inference. F Mireshghallah, M Taram, A Jalali, A T Elthakeb, D Tullsen, H Esmaeilzadeh, arXiv:2003.12154arXiv preprintF. Mireshghallah, M. Taram, A. Jalali, A. T. Elthakeb, D. Tullsen, and H. Esmaeilzadeh, \"A principled approach to learning stochastic representations for privacy in deep neural inference,\" arXiv preprint arXiv:2003.12154, 2020.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, Cognitive computation. 12P. Kanerva, \"Hyperdimensional computing: An introduction to comput- ing in distributed representation with high-dimensional random vectors,\" Cognitive computation, vol. 1, no. 2, pp. 139-159, 2009.\n\nHardware optimizations of dense binary hyperdimensional computing: Rematerialization of hypervectors, binarized bundling, and combinational associative memory. M Schmuck, L Benini, A Rahimi, ACM Journal on Emerging Technologies in Computing Systems (JETC). 154M. Schmuck, L. Benini, and A. Rahimi, \"Hardware optimizations of dense binary hyperdimensional computing: Rematerialization of hyper- vectors, binarized bundling, and combinational associative memory,\" ACM Journal on Emerging Technologies in Computing Systems (JETC), vol. 15, no. 4, pp. 1-25, 2019.\n\nLearning sensorimotor control with neuromorphic sensors: Toward hyperdimensional active perception. A Mitrokhin, P Sutor, C Ferm\u00fcller, Y Aloimonos, Science Robotics. 4306736A. Mitrokhin, P. Sutor, C. Ferm\u00fcller, and Y. Aloimonos, \"Learning sen- sorimotor control with neuromorphic sensors: Toward hyperdimensional active perception,\" Science Robotics, vol. 4, no. 30, p. eaaw6736, 2019.\n\nAn introduction to hyperdimensional computing for robotics. P Neubert, S Schubert, P Protzel, KI-K\u00fcnstliche IntelligenzP. Neubert, S. Schubert, and P. Protzel, \"An introduction to hyperdimen- sional computing for robotics,\" KI-K\u00fcnstliche Intelligenz, pp. 1-12.\n\nA framework for collaborative learning in secure high-dimensional space. M Imani, Y Kim, S Riazi, J Messerly, P Liu, F Koushanfar, 2019 IEEE 12th International Conference on Cloud Computing (CLOUD). IEEEM. Imani, Y. Kim, S. Riazi, J. Messerly, P. Liu, F. Koushanfar et al., \"A framework for collaborative learning in secure high-dimensional space,\" in 2019 IEEE 12th International Conference on Cloud Computing (CLOUD). IEEE, 2019, pp. 435-446.\n\nOur data, ourselves: Privacy via distributed noise generation. C Dwork, K Kenthapadi, F Mcsherry, I Mironov, M Naor, Annual International Conference on the Theory and Applications of Cryptographic Techniques. SpringerC. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor, \"Our data, ourselves: Privacy via distributed noise generation,\" in Annual International Conference on the Theory and Applications of Cryptographic Techniques. Springer, 2006, pp. 486-503.\n\nF5-hd: Fast flexible fpga-based framework for refreshing hyperdimensional computing. S Salamat, M Imani, B Khaleghi, T Rosing, Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays. the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate ArraysACMS. Salamat, M. Imani, B. Khaleghi, and T. Rosing, \"F5-hd: Fast flexible fpga-based framework for refreshing hyperdimensional computing,\" in Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays. ACM, 2019, pp. 53-62.\n\nSparsehd: Algorithm-hardware co-optimization for efficient high-dimensional computing. M Imani, S Salamat, B Khaleghi, M Samragh, F Koushanfar, T Rosing, 2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM). IEEEM. Imani, S. Salamat, B. Khaleghi, M. Samragh, F. Koushanfar, and T. Rosing, \"Sparsehd: Algorithm-hardware co-optimization for efficient high-dimensional computing,\" in 2019 IEEE 27th Annual Interna- tional Symposium on Field-Programmable Custom Computing Machines (FCCM). IEEE, 2019, pp. 190-198.\n\nUci machine learning repository. \"Uci machine learning repository,\" http://archive.ics.uci.edu/ml/datasets/ ISOLET.\n\nCaltech-256 object category dataset. G Griffin, A Holub, P Perona, G. Griffin, A. Holub, and P. Perona, \"Caltech-256 object category dataset,\" 2007.\n", "annotations": {"author": "[{\"end\":141,\"start\":58},{\"end\":220,\"start\":142},{\"end\":299,\"start\":221}]", "publisher": null, "author_last_name": "[{\"end\":73,\"start\":65},{\"end\":154,\"start\":149},{\"end\":234,\"start\":228}]", "author_first_name": "[{\"end\":64,\"start\":58},{\"end\":148,\"start\":142},{\"end\":227,\"start\":221}]", "author_affiliation": "[{\"end\":140,\"start\":94},{\"end\":219,\"start\":173},{\"end\":298,\"start\":252}]", "title": "[{\"end\":55,\"start\":1},{\"end\":354,\"start\":300}]", "venue": null, "abstract": "[{\"end\":1533,\"start\":356}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1964,\"start\":1961},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2593,\"start\":2590},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2598,\"start\":2595},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3204,\"start\":3201},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3574,\"start\":3571},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3579,\"start\":3576},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4127,\"start\":4124},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4132,\"start\":4129},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4137,\"start\":4134},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4372,\"start\":4369},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4463,\"start\":4460},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4469,\"start\":4465},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4856,\"start\":4852},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4862,\"start\":4858},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4868,\"start\":4864},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4874,\"start\":4870},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6969,\"start\":6966},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7341,\"start\":7337},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7347,\"start\":7343},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7361,\"start\":7358},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7461,\"start\":7457},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11030,\"start\":11027},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11501,\"start\":11497},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":11915,\"start\":11912},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12858,\"start\":12854},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13353,\"start\":13349},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":14543,\"start\":14540},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":15862,\"start\":15858},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":19374,\"start\":19370},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":19936,\"start\":19932},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":22095,\"start\":22092},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":22100,\"start\":22097},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22342,\"start\":22339},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22480,\"start\":22477},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":22486,\"start\":22482},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":24905,\"start\":24901},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":24911,\"start\":24907},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":25908,\"start\":25904},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":26131,\"start\":26127},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":27339,\"start\":27335},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":27445,\"start\":27441},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":27558,\"start\":27555},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":27828,\"start\":27825},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":29431,\"start\":29428},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":29647,\"start\":29644},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32482,\"start\":32478}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":34788,\"start\":34735},{\"attributes\":{\"id\":\"fig_1\"},\"end\":34870,\"start\":34789},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34918,\"start\":34871},{\"attributes\":{\"id\":\"fig_3\"},\"end\":35153,\"start\":34919},{\"attributes\":{\"id\":\"fig_5\"},\"end\":35241,\"start\":35154},{\"attributes\":{\"id\":\"fig_6\"},\"end\":35293,\"start\":35242},{\"attributes\":{\"id\":\"fig_7\"},\"end\":35485,\"start\":35294},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":35841,\"start\":35486}]", "paragraph": "[{\"end\":2317,\"start\":1552},{\"end\":3287,\"start\":2319},{\"end\":4539,\"start\":3289},{\"end\":5893,\"start\":4541},{\"end\":6679,\"start\":5895},{\"end\":7162,\"start\":6731},{\"end\":7462,\"start\":7243},{\"end\":7700,\"start\":7529},{\"end\":8724,\"start\":7831},{\"end\":8954,\"start\":8726},{\"end\":9244,\"start\":8975},{\"end\":9353,\"start\":9344},{\"end\":9451,\"start\":9366},{\"end\":9547,\"start\":9470},{\"end\":9872,\"start\":9549},{\"end\":11259,\"start\":9931},{\"end\":11502,\"start\":11334},{\"end\":11713,\"start\":11537},{\"end\":11943,\"start\":11853},{\"end\":12496,\"start\":12004},{\"end\":12795,\"start\":12726},{\"end\":13400,\"start\":12808},{\"end\":14068,\"start\":13402},{\"end\":15118,\"start\":14110},{\"end\":15799,\"start\":15226},{\"end\":16876,\"start\":15801},{\"end\":19125,\"start\":16878},{\"end\":20799,\"start\":19127},{\"end\":21847,\"start\":20887},{\"end\":22487,\"start\":21872},{\"end\":23613,\"start\":22489},{\"end\":24675,\"start\":23615},{\"end\":25081,\"start\":24704},{\"end\":26164,\"start\":25083},{\"end\":26315,\"start\":26234},{\"end\":27128,\"start\":26317},{\"end\":30412,\"start\":27181},{\"end\":31343,\"start\":30443},{\"end\":31965,\"start\":31345},{\"end\":33549,\"start\":31992},{\"end\":34734,\"start\":33567}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7242,\"start\":7163},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7528,\"start\":7463},{\"attributes\":{\"id\":\"formula_2\"},\"end\":7830,\"start\":7701},{\"attributes\":{\"id\":\"formula_3\"},\"end\":8974,\"start\":8955},{\"attributes\":{\"id\":\"formula_4\"},\"end\":9343,\"start\":9245},{\"attributes\":{\"id\":\"formula_5\"},\"end\":9365,\"start\":9354},{\"attributes\":{\"id\":\"formula_6\"},\"end\":9469,\"start\":9452},{\"attributes\":{\"id\":\"formula_7\"},\"end\":9904,\"start\":9873},{\"attributes\":{\"id\":\"formula_8\"},\"end\":11304,\"start\":11260},{\"attributes\":{\"id\":\"formula_9\"},\"end\":11333,\"start\":11304},{\"attributes\":{\"id\":\"formula_10\"},\"end\":11536,\"start\":11503},{\"attributes\":{\"id\":\"formula_11\"},\"end\":11852,\"start\":11714},{\"attributes\":{\"id\":\"formula_12\"},\"end\":12637,\"start\":12497},{\"attributes\":{\"id\":\"formula_13\"},\"end\":12725,\"start\":12637},{\"attributes\":{\"id\":\"formula_14\"},\"end\":12807,\"start\":12796},{\"attributes\":{\"id\":\"formula_15\"},\"end\":15179,\"start\":15119},{\"attributes\":{\"id\":\"formula_16\"},\"end\":15225,\"start\":15179},{\"attributes\":{\"id\":\"formula_17\"},\"end\":20841,\"start\":20800},{\"attributes\":{\"id\":\"formula_18\"},\"end\":20886,\"start\":20841},{\"attributes\":{\"id\":\"formula_19\"},\"end\":26233,\"start\":26165}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":32491,\"start\":32484}]", "section_header": "[{\"end\":1550,\"start\":1535},{\"end\":6697,\"start\":6682},{\"end\":6729,\"start\":6700},{\"end\":9929,\"start\":9906},{\"end\":11976,\"start\":11946},{\"end\":12002,\"start\":11979},{\"end\":14108,\"start\":14071},{\"end\":21870,\"start\":21850},{\"end\":24702,\"start\":24678},{\"end\":27142,\"start\":27131},{\"end\":27179,\"start\":27145},{\"end\":30441,\"start\":30415},{\"end\":31990,\"start\":31968},{\"end\":33565,\"start\":33552},{\"end\":34744,\"start\":34736},{\"end\":34798,\"start\":34790},{\"end\":34880,\"start\":34872},{\"end\":34935,\"start\":34920},{\"end\":35163,\"start\":35155},{\"end\":35251,\"start\":35243},{\"end\":35311,\"start\":35295},{\"end\":35504,\"start\":35487}]", "table": "[{\"end\":35841,\"start\":35554}]", "figure_caption": "[{\"end\":34788,\"start\":34746},{\"end\":34870,\"start\":34800},{\"end\":34918,\"start\":34882},{\"end\":35153,\"start\":34938},{\"end\":35241,\"start\":35165},{\"end\":35293,\"start\":35253},{\"end\":35485,\"start\":35314},{\"end\":35554,\"start\":35506}]", "figure_ref": "[{\"end\":12335,\"start\":12329},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13282,\"start\":13276},{\"end\":14554,\"start\":14547},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16934,\"start\":16928},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16995,\"start\":16986},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":17772,\"start\":17766},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":18788,\"start\":18782},{\"end\":20156,\"start\":20147},{\"end\":20586,\"start\":20577},{\"end\":21415,\"start\":21406},{\"end\":22963,\"start\":22954},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":24159,\"start\":24153},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":25484,\"start\":25475},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":26608,\"start\":26599},{\"end\":27944,\"start\":27938},{\"end\":28069,\"start\":28060},{\"end\":28693,\"start\":28687},{\"end\":29824,\"start\":29815},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":30482,\"start\":30476},{\"end\":30533,\"start\":30527},{\"end\":31172,\"start\":31166},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":31290,\"start\":31284},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":32177,\"start\":32171}]", "bib_author_first_name": "[{\"end\":36121,\"start\":36120},{\"end\":36130,\"start\":36129},{\"end\":36137,\"start\":36136},{\"end\":36151,\"start\":36150},{\"end\":36153,\"start\":36152},{\"end\":36164,\"start\":36163},{\"end\":36175,\"start\":36174},{\"end\":36648,\"start\":36647},{\"end\":36667,\"start\":36666},{\"end\":36681,\"start\":36677},{\"end\":37095,\"start\":37094},{\"end\":37101,\"start\":37100},{\"end\":37108,\"start\":37107},{\"end\":37386,\"start\":37385},{\"end\":37404,\"start\":37403},{\"end\":37414,\"start\":37413},{\"end\":37423,\"start\":37422},{\"end\":37433,\"start\":37432},{\"end\":37444,\"start\":37443},{\"end\":37802,\"start\":37801},{\"end\":37811,\"start\":37810},{\"end\":37823,\"start\":37822},{\"end\":37833,\"start\":37832},{\"end\":38158,\"start\":38157},{\"end\":38170,\"start\":38169},{\"end\":38697,\"start\":38696},{\"end\":38705,\"start\":38704},{\"end\":38714,\"start\":38713},{\"end\":38721,\"start\":38720},{\"end\":38728,\"start\":38727},{\"end\":38735,\"start\":38734},{\"end\":38737,\"start\":38736},{\"end\":39264,\"start\":39263},{\"end\":39266,\"start\":39265},{\"end\":39274,\"start\":39273},{\"end\":39276,\"start\":39275},{\"end\":39290,\"start\":39289},{\"end\":39305,\"start\":39304},{\"end\":39315,\"start\":39314},{\"end\":39326,\"start\":39325},{\"end\":39328,\"start\":39327},{\"end\":39650,\"start\":39649},{\"end\":39667,\"start\":39666},{\"end\":39676,\"start\":39675},{\"end\":39691,\"start\":39690},{\"end\":39701,\"start\":39700},{\"end\":39712,\"start\":39711},{\"end\":40382,\"start\":40381},{\"end\":40399,\"start\":40398},{\"end\":40408,\"start\":40407},{\"end\":40418,\"start\":40417},{\"end\":40420,\"start\":40419},{\"end\":40432,\"start\":40431},{\"end\":40443,\"start\":40442},{\"end\":40843,\"start\":40842},{\"end\":41238,\"start\":41237},{\"end\":41249,\"start\":41248},{\"end\":41259,\"start\":41258},{\"end\":41739,\"start\":41738},{\"end\":41752,\"start\":41751},{\"end\":41761,\"start\":41760},{\"end\":41774,\"start\":41773},{\"end\":42086,\"start\":42085},{\"end\":42097,\"start\":42096},{\"end\":42109,\"start\":42108},{\"end\":42361,\"start\":42360},{\"end\":42370,\"start\":42369},{\"end\":42377,\"start\":42376},{\"end\":42386,\"start\":42385},{\"end\":42398,\"start\":42397},{\"end\":42405,\"start\":42404},{\"end\":42797,\"start\":42796},{\"end\":42806,\"start\":42805},{\"end\":42820,\"start\":42819},{\"end\":42832,\"start\":42831},{\"end\":42843,\"start\":42842},{\"end\":43289,\"start\":43288},{\"end\":43300,\"start\":43299},{\"end\":43309,\"start\":43308},{\"end\":43321,\"start\":43320},{\"end\":43846,\"start\":43845},{\"end\":43855,\"start\":43854},{\"end\":43866,\"start\":43865},{\"end\":43878,\"start\":43877},{\"end\":43889,\"start\":43888},{\"end\":43903,\"start\":43902},{\"end\":44472,\"start\":44471},{\"end\":44483,\"start\":44482},{\"end\":44492,\"start\":44491}]", "bib_author_last_name": "[{\"end\":36127,\"start\":36122},{\"end\":36134,\"start\":36131},{\"end\":36148,\"start\":36138},{\"end\":36161,\"start\":36154},{\"end\":36172,\"start\":36165},{\"end\":36182,\"start\":36176},{\"end\":36664,\"start\":36649},{\"end\":36675,\"start\":36668},{\"end\":36686,\"start\":36682},{\"end\":37098,\"start\":37096},{\"end\":37105,\"start\":37102},{\"end\":37113,\"start\":37109},{\"end\":37401,\"start\":37387},{\"end\":37411,\"start\":37405},{\"end\":37420,\"start\":37415},{\"end\":37430,\"start\":37424},{\"end\":37441,\"start\":37434},{\"end\":37453,\"start\":37445},{\"end\":37808,\"start\":37803},{\"end\":37820,\"start\":37812},{\"end\":37830,\"start\":37824},{\"end\":37839,\"start\":37834},{\"end\":38167,\"start\":38159},{\"end\":38178,\"start\":38171},{\"end\":38702,\"start\":38698},{\"end\":38711,\"start\":38706},{\"end\":38718,\"start\":38715},{\"end\":38725,\"start\":38722},{\"end\":38732,\"start\":38729},{\"end\":38740,\"start\":38738},{\"end\":39271,\"start\":39267},{\"end\":39287,\"start\":39277},{\"end\":39302,\"start\":39291},{\"end\":39312,\"start\":39306},{\"end\":39323,\"start\":39316},{\"end\":39335,\"start\":39329},{\"end\":39664,\"start\":39651},{\"end\":39673,\"start\":39668},{\"end\":39688,\"start\":39677},{\"end\":39698,\"start\":39692},{\"end\":39709,\"start\":39702},{\"end\":39725,\"start\":39713},{\"end\":40396,\"start\":40383},{\"end\":40405,\"start\":40400},{\"end\":40415,\"start\":40409},{\"end\":40429,\"start\":40421},{\"end\":40440,\"start\":40433},{\"end\":40456,\"start\":40444},{\"end\":40851,\"start\":40844},{\"end\":41246,\"start\":41239},{\"end\":41256,\"start\":41250},{\"end\":41266,\"start\":41260},{\"end\":41749,\"start\":41740},{\"end\":41758,\"start\":41753},{\"end\":41771,\"start\":41762},{\"end\":41784,\"start\":41775},{\"end\":42094,\"start\":42087},{\"end\":42106,\"start\":42098},{\"end\":42117,\"start\":42110},{\"end\":42367,\"start\":42362},{\"end\":42374,\"start\":42371},{\"end\":42383,\"start\":42378},{\"end\":42395,\"start\":42387},{\"end\":42402,\"start\":42399},{\"end\":42416,\"start\":42406},{\"end\":42803,\"start\":42798},{\"end\":42817,\"start\":42807},{\"end\":42829,\"start\":42821},{\"end\":42840,\"start\":42833},{\"end\":42848,\"start\":42844},{\"end\":43297,\"start\":43290},{\"end\":43306,\"start\":43301},{\"end\":43318,\"start\":43310},{\"end\":43328,\"start\":43322},{\"end\":43852,\"start\":43847},{\"end\":43863,\"start\":43856},{\"end\":43875,\"start\":43867},{\"end\":43886,\"start\":43879},{\"end\":43900,\"start\":43890},{\"end\":43910,\"start\":43904},{\"end\":44480,\"start\":44473},{\"end\":44489,\"start\":44484},{\"end\":44499,\"start\":44493}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":207241585},\"end\":36570,\"start\":36079},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":206779368},\"end\":37008,\"start\":36572},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":42367028},\"end\":37293,\"start\":37010},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":217485587},\"end\":37740,\"start\":37295},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":2468323},\"end\":38059,\"start\":37742},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":207173320},\"end\":38612,\"start\":38061},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":50770883},\"end\":39185,\"start\":38614},{\"attributes\":{\"id\":\"b7\"},\"end\":39578,\"start\":39187},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":203593417},\"end\":40280,\"start\":39580},{\"attributes\":{\"doi\":\"arXiv:2003.12154\",\"id\":\"b9\"},\"end\":40715,\"start\":40282},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":733980},\"end\":41075,\"start\":40717},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":49907924},\"end\":41636,\"start\":41077},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":182118830},\"end\":42023,\"start\":41638},{\"attributes\":{\"id\":\"b13\"},\"end\":42285,\"start\":42025},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":197642766},\"end\":42731,\"start\":42287},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":2495811},\"end\":43201,\"start\":42733},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":67872077},\"end\":43756,\"start\":43203},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":189824904},\"end\":44315,\"start\":43758},{\"attributes\":{\"id\":\"b18\"},\"end\":44432,\"start\":44317},{\"attributes\":{\"id\":\"b19\"},\"end\":44582,\"start\":44434}]", "bib_title": "[{\"end\":36118,\"start\":36079},{\"end\":36645,\"start\":36572},{\"end\":37092,\"start\":37010},{\"end\":37383,\"start\":37295},{\"end\":37799,\"start\":37742},{\"end\":38155,\"start\":38061},{\"end\":38694,\"start\":38614},{\"end\":39261,\"start\":39187},{\"end\":39647,\"start\":39580},{\"end\":40840,\"start\":40717},{\"end\":41235,\"start\":41077},{\"end\":41736,\"start\":41638},{\"end\":42358,\"start\":42287},{\"end\":42794,\"start\":42733},{\"end\":43286,\"start\":43203},{\"end\":43843,\"start\":43758}]", "bib_author": "[{\"end\":36129,\"start\":36120},{\"end\":36136,\"start\":36129},{\"end\":36150,\"start\":36136},{\"end\":36163,\"start\":36150},{\"end\":36174,\"start\":36163},{\"end\":36184,\"start\":36174},{\"end\":36666,\"start\":36647},{\"end\":36677,\"start\":36666},{\"end\":36688,\"start\":36677},{\"end\":37100,\"start\":37094},{\"end\":37107,\"start\":37100},{\"end\":37115,\"start\":37107},{\"end\":37403,\"start\":37385},{\"end\":37413,\"start\":37403},{\"end\":37422,\"start\":37413},{\"end\":37432,\"start\":37422},{\"end\":37443,\"start\":37432},{\"end\":37455,\"start\":37443},{\"end\":37810,\"start\":37801},{\"end\":37822,\"start\":37810},{\"end\":37832,\"start\":37822},{\"end\":37841,\"start\":37832},{\"end\":38169,\"start\":38157},{\"end\":38180,\"start\":38169},{\"end\":38704,\"start\":38696},{\"end\":38713,\"start\":38704},{\"end\":38720,\"start\":38713},{\"end\":38727,\"start\":38720},{\"end\":38734,\"start\":38727},{\"end\":38742,\"start\":38734},{\"end\":39273,\"start\":39263},{\"end\":39289,\"start\":39273},{\"end\":39304,\"start\":39289},{\"end\":39314,\"start\":39304},{\"end\":39325,\"start\":39314},{\"end\":39337,\"start\":39325},{\"end\":39666,\"start\":39649},{\"end\":39675,\"start\":39666},{\"end\":39690,\"start\":39675},{\"end\":39700,\"start\":39690},{\"end\":39711,\"start\":39700},{\"end\":39727,\"start\":39711},{\"end\":40398,\"start\":40381},{\"end\":40407,\"start\":40398},{\"end\":40417,\"start\":40407},{\"end\":40431,\"start\":40417},{\"end\":40442,\"start\":40431},{\"end\":40458,\"start\":40442},{\"end\":40853,\"start\":40842},{\"end\":41248,\"start\":41237},{\"end\":41258,\"start\":41248},{\"end\":41268,\"start\":41258},{\"end\":41751,\"start\":41738},{\"end\":41760,\"start\":41751},{\"end\":41773,\"start\":41760},{\"end\":41786,\"start\":41773},{\"end\":42096,\"start\":42085},{\"end\":42108,\"start\":42096},{\"end\":42119,\"start\":42108},{\"end\":42369,\"start\":42360},{\"end\":42376,\"start\":42369},{\"end\":42385,\"start\":42376},{\"end\":42397,\"start\":42385},{\"end\":42404,\"start\":42397},{\"end\":42418,\"start\":42404},{\"end\":42805,\"start\":42796},{\"end\":42819,\"start\":42805},{\"end\":42831,\"start\":42819},{\"end\":42842,\"start\":42831},{\"end\":42850,\"start\":42842},{\"end\":43299,\"start\":43288},{\"end\":43308,\"start\":43299},{\"end\":43320,\"start\":43308},{\"end\":43330,\"start\":43320},{\"end\":43854,\"start\":43845},{\"end\":43865,\"start\":43854},{\"end\":43877,\"start\":43865},{\"end\":43888,\"start\":43877},{\"end\":43902,\"start\":43888},{\"end\":43912,\"start\":43902},{\"end\":44482,\"start\":44471},{\"end\":44491,\"start\":44482},{\"end\":44501,\"start\":44491}]", "bib_venue": "[{\"end\":36341,\"start\":36271},{\"end\":38363,\"start\":38280},{\"end\":38921,\"start\":38840},{\"end\":39972,\"start\":39858},{\"end\":43499,\"start\":43423},{\"end\":36269,\"start\":36184},{\"end\":36768,\"start\":36688},{\"end\":37127,\"start\":37115},{\"end\":37499,\"start\":37455},{\"end\":37874,\"start\":37841},{\"end\":38278,\"start\":38180},{\"end\":38838,\"start\":38742},{\"end\":39368,\"start\":39337},{\"end\":39856,\"start\":39727},{\"end\":40379,\"start\":40282},{\"end\":40874,\"start\":40853},{\"end\":41332,\"start\":41268},{\"end\":41802,\"start\":41786},{\"end\":42083,\"start\":42025},{\"end\":42484,\"start\":42418},{\"end\":42940,\"start\":42850},{\"end\":43421,\"start\":43330},{\"end\":44012,\"start\":43912},{\"end\":44348,\"start\":44317},{\"end\":44469,\"start\":44434}]"}}}, "year": 2023, "month": 12, "day": 17}