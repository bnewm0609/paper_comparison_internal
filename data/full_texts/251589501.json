{"id": 251589501, "updated": "2023-10-05 11:26:59.145", "metadata": {"title": "Neural network fragile watermarking with no model performance degradation", "authors": "[{\"first\":\"Zhaoxia\",\"last\":\"Yin\",\"middle\":[]},{\"first\":\"Heng\",\"last\":\"Yin\",\"middle\":[]},{\"first\":\"Xinpeng\",\"last\":\"Zhang\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Deep neural networks are vulnerable to malicious fine-tuning attacks such as data poisoning and backdoor attacks. Therefore, in recent research, it is proposed how to detect malicious fine-tuning of neural network models. However, it usually negatively affects the performance of the protected model. Thus, we propose a novel neural network fragile watermarking with no model performance degradation. In the process of watermarking, we train a generative model with the specific loss function and secret key to generate triggers that are sensitive to the fine-tuning of the target classifier. In the process of verifying, we adopt the watermarked classifier to get labels of each fragile trigger. Then, malicious fine-tuning can be detected by comparing secret keys and labels. Experiments on classic datasets and classifiers show that the proposed method can effectively detect model malicious fine-tuning with no model performance degradation.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2208.07585", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icip/YinY022", "doi": "10.1109/icip46576.2022.9897413"}}, "content": {"source": {"pdf_hash": "d160b699b557f3184dd4bdfe1fbd82b9e8a33e91", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2208.07585v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "bf6811d8688b83307bc3acaa1aea77441e287916", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d160b699b557f3184dd4bdfe1fbd82b9e8a33e91.txt", "contents": "\nNEURAL NETWORK FRAGILE WATERMARKING WITH NO MODEL PERFORMANCE DEGRADATION\n\n\nZhaoxia Yin 1zxyin@cee.ecnu.edu.cn \nSchool of Communication and Electronic Engineering\nEast China Normal University\nShanghaiChina\n\nHeng Yin \nAnhui Provincial Key Laboratory of Multimodal Cognitive Computation\nAnhui University\n\n\nXinpeng Zhang 3zhangxinpeng@fudan.edu.cn \nSchool of Computer Science and Technology\nFudan University\nShanghaiChina\n\nNEURAL NETWORK FRAGILE WATERMARKING WITH NO MODEL PERFORMANCE DEGRADATION\nIndex Terms-Neural networkFragile watermarkingModel integrity protectionMalicious tuning detectionBack- door attack\nDeep neural networks are vulnerable to malicious finetuning attacks such as data poisoning and backdoor attacks. Therefore, in recent research, it is proposed how to detect malicious fine-tuning of neural network models. However, it usually negatively affects the performance of the protected model. Thus, we propose a novel neural network fragile watermarking with no model performance degradation. In the process of watermarking, we train a generative model with the specific loss function and secret key to generate triggers that are sensitive to the fine-tuning of the target classifier. In the process of verifying, we adopt the watermarked classifier to get labels of each fragile trigger. Then, malicious finetuning can be detected by comparing secret keys and labels. Experiments on classic datasets and classifiers show that the proposed method can effectively detect model malicious finetuning with no model performance degradation.\n\nINTRODUCTION\n\nThe performance of Deep Neural Network (DNN) in image recognition [1,2,3], natural language processing [4,5,6], speech recognition [7] and explainable machine learning [8,9] has achieved excellent results. Meanwhile, the requirement of powerful computing resources and a long training time Copyright 2022 IEEE. Published in 2022 IEEE International Conference on Image Processing (ICIP), scheduled for [16][17][18][19] October 2022 in Bordeaux, France. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works, must be obtained from the IEEE. Contact in obtaining a business model renders many users directly download the pre-trained DNN models from websites or use enterprise cloud-based services. However, these pre-trained models may have been injected backdoor by maliciously finetuning them to be backdoor models. It may cause a severe security accident when users unknowingly apply the backdoor model to applications like autonomous driving. Hence, we resort to the technology of model watermarking to verify the integrity of pre-trained models.\n\nThe mainstream model watermarking technologies are currently divided into two types. One is to embed the watermarking by modifying parameters of the model, like [10,11], and the other is to implement the trigger set, like [12,13,14]. Robustness is one feature of model watermarking that we cared about most, which means that model watermarking should be robust to model modification attacks such as finetuning and compression. Fragility is opposite to robustness, which means that watermarking is sensitive to model modifications. Modifications of the watermarked model can be detected immediately as long as it undergoes fine-tuning.\n\nLet's review recent neural network fragile watermarking approaches for detecting malicious fine-tuning. In [10], a reversible fragile watermarking scheme for model integrity authentication is proposed. This scheme utilizes the pruning theory of model compression technology to construct a host sequence. Then, it adopts histogram shift [15] technology to embed watermarking information. In [11], a nonreversible algorithm is applied to embed the watermarking in a secret frequency domain defined by a linear transformation, this scheme has no degradation in performances of the watermarked neural network with respect to the original one. However, research works [10,11] are white-box fragile watermarking methods that need the detail of networks, which is difficult to verify integrity of watermarked models remotely. In [12], fragile triggers are generated by adding a small perturbation to the original training data, and this method first uses designed transformed inputs as a defense to protect the integrity property of DNN. Compared with [12], research work [13] transforms all complex activation functions into polynomials to facilitate the generation of fragile triggers which apply to all neural network frameworks. Though research works [12,13] are black-box fragile watermarking methods that are convenient to verify model integrity remotely, the generation of fragile triggers still needs the parameters of target networks. [14]-KSEM 2021 puts forward an alternate two-stage training strategy with specific loss to embed the generated trigger set into target model. Though this black-box method can detect malicious fine-tuning sensitively, it needs to finetune the target classifier to embed the trigger set, and the performance of the watermarked classifier also gets degradation. Therefore, we propose a novel fragile watermarking method to mark the target classifier by generating the fragile trigger set from a generative model trained with specific loss and a secret key. Watermarking process of the target classifier and training process of the generative model happen simultaneously. No detail and modification of the target classifier is required, and we only need to query the target classifier in the whole watermarking process.\n\nOur contributions in model fragile watermarking are summarized as follows:\n\n\u2022 A novel black-box method is proposed to design the fragile trigger set for verifying the integrity of watermarked classifier.\n\n\u2022 A regularization term V ar is first utilized in training generators, we illustrate that V ar is the key for generating a fragile trigger set in Sect 4.1.\n\n\u2022 The fragile trigger set can perceive the modification of watermarked classifier in the first epoch of fine-tuning stage, which is demonstrated in Sect 4.2.\n\n\u2022 Our fragile watermarking method is compatible and effective for classifiers with increasing parameters and datasets with more categories. Corresponding experiment results are given in Sect 4.3.\n\n\nBACKGROUND\n\nBefore introducing our fragile watermarking method, we introduce the basic models in Sect 2.1, and a common malicious fine-tuning scenario is given in Sect 2.2.\n\n\nBasic Model\n\nMost image recognition tasks are supervised learning and require sample data with corresponding labels in the stage of training classifier. Denote a batch of sample data with corresponding labels as:\n{X, Y } = {x i , y i } N i=1\n, where N is size of batch, X and Y respectively represent sample data and corresponding labels. For a k classification task, the label value y \u2208 {0, ..., k \u2212 1} . Suppose there is a classification model trained on sample data D train = {X train , Y train }, and this model is named as C : X \u2192 Y , we refer to C as the base classification model.\n\nGenerative Adversarial Nets (GAN) [16] consists of generative model G and discriminative model.\nDenote {z i } n i=1 as random noise vectors, then {z i } n i=1 can be mapped to {x i } n i=1\nthrough G. In this paper, we use a generative model G to generate fragile sample data X trigger , where X trigger has the same shape as sample data of D train .\n\n\nBackdoor Attack\n\nBased on the basic classification model C, an adversary first preset backdoor [17] data X backdoor which has the same data distribution as training data D train , and there is no difference between these backdoor data and training data in human eyes. Hence, this adversary can fine-tune the model C with (X train \u222a X backdoor ) to inject backdoor data. Denote C as the backdoor model after fine-tuning which nearly has the same performance as C, but C recognizes backdoor data as preset results and model performance declines sharply if the adversary uses X backdoor as input data.\n\n\nFRAGILE WATERMARKING\n\n\nOverview\n\nLet's consider an application scenario, and there are three parties: model provider, model user, and adversary. The model provider uploads a trained model to cloud for serving, an adversary may use backdoor model to instead the original one. In the situation that without detail of pre-trained model from cloud, the model user wants to verify if the model served by model provider is actually the one he uploaded. Hence, we introduce a black-box fragile watermarking method without model performance degradation to verify the integrity of watermarked models.\n\nOur idea is that the model provider first generates a fragile watermarking trigger set to mark C before uploading trained C to cloud. The model provider utilizes a generative model with a secret key Y sk = {s i } n i=1 to generate these fragile samples, whose labels predicted by C are the same as Y sk . Then, the model provider can send generated fragile samples and Y sk to the model user directly. The model user inputs these samples into the provided model from cloud and obtains the output Y . The model integrity can be verified by comparing Y and Y sk . Fig. 1 shows our proposed fragile watermarking framework to mark the target classification model. We first generate n random noise vectors {z i } n i=1 whose size is 1 \u00d7 512 as inputs of generative model and a secret key\n\n\nWatermarking Methodology\nY sk = {s i } n i=1 . Then, {z i } n i=1 are input into generative model G to get gen- erated fragile samples X f ragile = {x i } n i=1 . Next, we input X f ragile into the target classification model C to get output results Y f ragile = {y i } n i=1 , and {p i } n i=1\n. Y f ragile is the predicted category of generated fragile samples, and {p i } n i=1 are predicted outcomes for each generated fragile sample after softmax operation. At the first epoch, Y f ragile is different from Y sk , and X f ragile is insensitive to target classification model modification too. Hence, generative model G is optimized with the loss function L until Y f ragile is the same as Y sk , the composition of L is listed as follows:\n\n\u2022 L cla (Y f ragile , Y sk ) : L cla is the cross entropy loss, we adopt it to calculate the distance between Y f ragile and Y sk .\n\n\u2022 V ar (P ) : This item is to calculate the variance of P = {p i } n i=1 , we add this regularization term in the stage of training G to make X f ragile more sensitive to model modification.\n\nThen, the L loss funciton is writed as :\nL = L cla (Y f ragile , Y sk ) + a \u00b7 V ar (P ) (1)\na is a weight coefficient, larger a can improve the sensitivity of generated samples. In the verification phase, we denote AccT ri as the authentication metrics to calculate the difference between predicted results of generated samples and Y sk . The value of AccT ri can verify whether the classifier model has been modified, the AccT ri is defined as follows:\nAccT ri = n i=1 1 condition (C (x i ) = y i ) n(2)\nIn AccT ri, 1 condition is a conditional function that returns 1 if the condition is true else returns 0. If AccT ri < 1.0, it indicates that the watermarked classifier has been modified.\n\n\nEXPERIMENTS\n\nExperiments consist of three subsections verifying our contributions. In Table 1, we compare recent fragile watermarking methods with our approach, and Table 2 further illustrates the difference between watermarking scheme [14] and ours in impacting the performance of the original model. The proposed watermarking method is utilized in the following subsections to obtain triggers and watermark the target classifier.\n\nResnet [2] is adopted as the default classifier C, and the last layer of classifiers refers to conv5 x, average pool, and fully connected layer in [2]. PGAN [18] is utilized as default generative model G. In the watermarking stage, we preset a secret key Y sk as {s i } n i=1 = {i%M | i = 0, 1, ..., n \u2212 1}, M is the total number of categories in train dataset, and the number of generated fragile triggers is 100. There are 60 epochs of finetuning the watermarked classifier in the verifying stage. We adopt Stochastic Gradient Descent [19] to fine-tune Resnet18 [2] with a learning rate of 1e \u2212 3 and Adam [20] to fine-tune larger resnet with a learning rate of 1e \u2212 5. Since there is no modification to model C in the proposed fragile watermarking method, there is no impact on the performance of model C.  [14] 90.3% \u22120.9% Watermarked Model(ours) 91.2% 0\n\n\nAblation Study on Generating Trigger\n\nThis part ablates the components of loss function L to evaluate the effect on training generative model G. We train three generators G cla , G f ull , G V ar with different components of L. G cla is trained with L cla and Y sk , G f ull adopts full loss function L and Y sk which weight a is 200, G V ar is just trained with regularization term V ar and weight a is 200, G non is the initial generative model without training. Except for G non , all of them are trained for 300 epochs. We adopt Resnet18 as default classifier C which is trained on CIFAR10. Table  3 shows that prediction probabilities of one or two categories are much higher than others when input generated triggers from G non and G cla . For generated triggers from G f ull and G V ar , almost half of the categories have very similar prediction probabilities. Thus, an additional regularization term V ar helps generate triggers in which more categories have similar prediction probability. Table 3. The softmax prediction probabilities of categories for four generated triggers, and each trigger is randomly selected from the corresponding generative model. \u2212 is adopted to instead corresponding values which are less than 1 * 10 \u22122 . \n\n\nTrigger Set Sensitivity Test\n\nNext, we examine the sensitivity of trigger set from above generative models. Generated triggers from G non and G V ar are first input into C to get corresponding initial labels. Then, we adopt BIM [22] method to transform original training samples into backdoor data, utilize original training data with these backdoor data to fine-tune the classifier C. In Fig.2, AccT ri of generated triggers from G non , G cla , G f ull , and G var in each epoch is respectively recorded by Line a, b, c, and d. As can be seen, Line c drops rapidly in the first epoch of fine-tuning and is much lower than Line a, b in the whole process. It means that generated samples from G f ull are much more sensitive than G non and G cla . Hence, our proposed loss function in training generative models is valid to generate a fragile trigger set sensitive to model fine-tuning.\n\n\nTrigger Set Extensibility Test\n\nIn this part, we evaluate whether increasing parameters of classification models impact the sensitivity of generated frag-  Table  4 records the mean AccT ri values of fragile watermarking triggers generated from these generative models in the whole test process. If weight a is set as 1, the AccT ri is not decline in the first epoch of fine-tuning. In this situation, our fragile watermarking method may have omissions for detecting fine-tuning of the target classifier. When weight a exceeds or equals 100, the AccT ri declines sharply in the first epoch of fine-tuning. And larger weight a can decrease the mean AccT ri, the lower AccT ri means that fine-tuned classification models misclassify more trigger samples. Hence, the generator trained with larger a can get a fragile trigger set which is more sensitive to model modification, and our model fragile watermarking method is effective for larger classification models. We also consider the possible impact from increased categories of training dataset and then train Resnet18 with CI-FAR100 [21] as default classification model C. The total number of categories increased from 10 to 100. A generative model G is trained with weight value 4000, and only the last layer of default classification model is fine-tuned in testing. In 60 epochs of fine-tuning model C, the max AccT ri of generated fragile trigger set is 0.97 and the mean is 0.68, the AccT ri still declines in the first epoch of fine-tuning. It shows that the generated fragile trigger set is still sensitive to modificaiton of classification models with 100 predicted categories.\n\n\nCONCLUSION AND FUTURE WORK\n\nIn this paper, we propose a novel neural network fragile watermarking with no model performance degradation. In our approach, watermarking process of classifier and training process of generative model are done simultaneously, there is no detail and modification of the target classifier are required in the whole process of watermarking. We demonstrate that generators trained with proposed loss effectively get fragile trig-ger sets sensitive to model fine-tuning and our approach is compatible to watermark enormous classifiers. In the future, we will incorporate an explainable framework as part of the model watermarking evaluation and comparison.\n\nFig. 1 .\n1The framework of generating fragile trigger set.\n\nFig. 2 .\n2The AccT ri of generated samples from G non , G cla , G f ull , and G var in each test epoch. Experimental verifications are carried out in (a) where all model parameters can be modified and (b) where only the last model layer is modified.\n\n\nnon .015 \u2212 \u2212 .975 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 G cla \u2212 \u2212 \u2212 \u2212 \u2212 .998 \u2212 \u2212 \u2212 \u2212 G f ull .149 .146 .146 .148 \u2212 .245 \u2212 \u2212 .014 .147 G var \u2212 \u2212 .201 .184 .211 \u2212 .216 \u2212 \u2212 .182\n\n\n: Manager, Copyrights and Permissions / IEEE Service Center / 445 Hoes Lane / P.O. Box 1331 / Piscataway, NJ 08855-1331, USA. Telephone: + Intl. 908-562-3966. This work is supported by National Natural Science Foundation of China under Grant No.62172001, U1936214.\n\nTable 1 .\n1Comparison of recent fragile model watermarking methods with our approach.Method \nMethod \nType \n\nModel \nAccuracy \n\nTrigger \nGeneration \n[10]-ACMMM 2020 White-box \n\u2193 \nN/A \n[11]-INS 2021 \nWhite-box \n= \nN/A \n[12]-CVPR 2019 \nBlack-box \n= \nWhite-box \n[13]-ACSAC 2020 Black-box \n= \nWhite-box \n[14]-KSEM 2021 \nBlack-box \n\u2193 \nBlack-box \nOurs \nBlack-box \n= \nBlack-box \n\nTable 2. Impact comparison results of [14]-KSEM 2021 and \nour model watermarking method on the performance of the \noriginal model, in which the original model is Resnet18 [2], \nand the training dataset is CIFAR10 [21]. \nModel \nAccuracy Difference \nOriginal Model \n91.2% \nN/A \nWatermarked Model\n\nTable 4 .\n4The mean AccT ri of fragile samples generated with larger weight a and classification models. The corresponding item is crossed if AccT ri has not changed in each fine-tuning epoch. ] are selected as default classification model for testing, only the last layer of model parameters can be modified. Different weight coefficient a is used to train generative models with full loss function.Resnet-18 Resnet-50 Resnet-101 Resnet-152 \na = 1 \n\u00d7 \n\u00d7 \n\u00d7 \n\u00d7 \na = 100 \n0.56 \n0.46 \n0.37 \n0.47 \na = 200 \n0.43 \n0.38 \n0.31 \n0.38 \na = 400 \n0.34 \n0.32 \n0.26 \n0.33 \na = 800 \n0.26 \n0.25 \n0.23 \n0.27 \n\nile watermarking triggers. Therefore, Resnet18, Resnet50 [2], \nResnet101 [2], and Resnet152 [2\n\nImagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Advances in neural information processing systems. 25Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hin- ton, \"Imagenet classification with deep convolutional neural networks,\" Advances in neural information pro- cessing systems, vol. 25, pp. 1097-1105, 2012.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, \"Deep residual learning for image recognition,\" in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770-778.\n\nAn image is worth 16x16 words: Transformers for image recognition at scale. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, arXiv:2010.11929arXiv preprintAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al., \"An image is worth 16x16 words: Transformers for image recognition at scale,\" arXiv preprint arXiv:2010.11929, 2020.\n\nA unified architecture for natural language processing: Deep neural networks with multitask learning. Ronan Collobert, Jason Weston, Proceedings of the 25th international conference on Machine learning. the 25th international conference on Machine learningRonan Collobert and Jason Weston, \"A unified archi- tecture for natural language processing: Deep neural networks with multitask learning,\" in Proceedings of the 25th international conference on Machine learning, 2008, pp. 160-167.\n\nEffective approaches to attentionbased neural machine translation. Minh-Thang Luong, Hieu Pham, Christopher D Manning, arXiv:1508.04025arXiv preprintMinh-Thang Luong, Hieu Pham, and Christopher D Manning, \"Effective approaches to attention- based neural machine translation,\" arXiv preprint arXiv:1508.04025, 2015.\n\nBert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei , Chang Kenton, Lee Kristina Toutanova, Proceedings of NAACL-HLT. NAACL-HLTJacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova, \"Bert: Pre-training of deep bidirectional transformers for language understanding,\" in Proceed- ings of NAACL-HLT, 2019, pp. 4171-4186.\n\nContext-dependent pre-trained deep neural networks for large-vocabulary speech recognition. E George, Dong Dahl, Li Yu, Alex Deng, Acero, IEEE Transactions on audio, speech, and language processing. 20George E Dahl, Dong Yu, Li Deng, and Alex Acero, \"Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition,\" IEEE Trans- actions on audio, speech, and language processing, vol. 20, no. 1, pp. 30-42, 2011.\n\nTowards explainable artificial intelligence. Wojciech Samek, Klaus-Robert M\u00fcller, Explainable AI: interpreting, explaining and visualizing deep learning. SpringerWojciech Samek and Klaus-Robert M\u00fcller, \"Towards explainable artificial intelligence,\" in Explainable AI: interpreting, explaining and visualizing deep learning, pp. 5-22. Springer, 2019.\n\nExplainable artificial intelligence applications in nlp, biomedical, and malware classification: a literature review. Mary Sherin, Mathews, Springerin Intelligent computingproceedings of the computing conferenceSherin Mary Mathews, \"Explainable artificial intelli- gence applications in nlp, biomedical, and malware clas- sification: a literature review,\" in Intelligent computing- proceedings of the computing conference. Springer, 2019, pp. 1269-1292.\n\nReversible watermarking in deep convolutional neural networks for integrity authentication. Xiquan Guan, Huamin Feng, Weiming Zhang, Hang Zhou, Jie Zhang, Nenghai Yu, Proceedings of the 28th ACM International Conference on Multimedia. the 28th ACM International Conference on MultimediaXiquan Guan, Huamin Feng, Weiming Zhang, Hang Zhou, Jie Zhang, and Nenghai Yu, \"Reversible wa- termarking in deep convolutional neural networks for integrity authentication,\" in Proceedings of the 28th ACM International Conference on Multimedia, 2020, pp. 2273-2280.\n\nNeunac: A novel fragile watermarking algorithm for integrity protection of neural networks. Marco Botta, Davide Cavagnino, Roberto Esposito, Information Sciences. 576Marco Botta, Davide Cavagnino, and Roberto Esposito, \"Neunac: A novel fragile watermarking algorithm for integrity protection of neural networks,\" Information Sciences, vol. 576, pp. 228-241, 2021.\n\nSensitivesample fingerprinting of deep neural networks. Zecheng He, Tianwei Zhang, Ruby Lee, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionZecheng He, Tianwei Zhang, and Ruby Lee, \"Sensitive- sample fingerprinting of deep neural networks,\" in Pro- ceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition, 2019, pp. 4729-4737.\n\nSecure and verifiable inference in deep neural networks. Guowen Xu, Hongwei Li, Jianfei Hao Ren, Shengmin Sun, Jianting Xu, Haomiao Ning, Kan Yang, Robert H Yang, Deng, Annual Computer Security Applications Conference. Guowen Xu, Hongwei Li, Hao Ren, Jianfei Sun, Sheng- min Xu, Jianting Ning, Haomiao Yang, Kan Yang, and Robert H Deng, \"Secure and verifiable inference in deep neural networks,\" in Annual Computer Security Appli- cations Conference, 2020, pp. 784-797.\n\nFragile neural network watermarking with trigger image set. Renjie Zhu, Ping Wei, Sheng Li, Zhaoxia Yin, Xinpeng Zhang, Zhenxing Qian, International Conference on Knowledge Science, Engineering and Management. SpringerRenjie Zhu, Ping Wei, Sheng Li, Zhaoxia Yin, Xin- peng Zhang, and Zhenxing Qian, \"Fragile neural net- work watermarking with trigger image set,\" in Interna- tional Conference on Knowledge Science, Engineering and Management. Springer, 2021, pp. 280-293.\n\nReversible data hiding. Zhicheng Ni, Yun-Qing Shi, Nirwan Ansari, Wei Su, IEEE Transactions on circuits and systems for video technology. 16Zhicheng Ni, Yun-Qing Shi, Nirwan Ansari, and Wei Su, \"Reversible data hiding,\" IEEE Transactions on circuits and systems for video technology, vol. 16, no. 3, pp. 354-362, 2006.\n\nGenerative adversarial nets. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, Advances in neural information processing systems. 27Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio, \"Generative adversar- ial nets,\" Advances in neural information processing systems, vol. 27, 2014.\n\nBadnets: Identifying vulnerabilities in the machine learning model supply chain. Tianyu Gu, Brendan Dolan-Gavitt, Siddharth Garg, arXiv:1708.06733arXiv preprintTianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg, \"Badnets: Identifying vulnerabilities in the ma- chine learning model supply chain,\" arXiv preprint arXiv:1708.06733, 2017.\n\nProgressive growing of gans for improved quality, stability, and variation. Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen, arXiv:1710.10196arXiv preprintTero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen, \"Progressive growing of gans for im- proved quality, stability, and variation,\" arXiv preprint arXiv:1710.10196, 2017.\n\nOn the momentum term in gradient descent learning algorithms. Ning Qian, Neural Networks. 121Ning Qian, \"On the momentum term in gradient descent learning algorithms,\" Neural Networks, vol. 12, no. 1, pp. 145-151, 1999.\n\nA method for stochastic optimization. Kingma Da, arXiv:1412.6980arXiv preprintKingma Da, \"A method for stochastic optimization,\" arXiv preprint arXiv:1412.6980, 2014.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Geoffrey Hinton, University of TorontoTechnical reportAlex Krizhevsky and Geoffrey Hinton, \"Learning mul- tiple layers of features from tiny images,\" Technical re- port, University of Toronto, 2009.\n\nAdversarial examples in the physical world. Alexey Kurakin, J Ian, Samy Goodfellow, Bengio, Artificial intelligence safety and security. Hall/CRCAlexey Kurakin, Ian J Goodfellow, and Samy Bengio, \"Adversarial examples in the physical world,\" in Artifi- cial intelligence safety and security, pp. 99-112. Chap- man and Hall/CRC, 2018.\n", "annotations": {"author": "[{\"end\":207,\"start\":77},{\"end\":304,\"start\":208},{\"end\":420,\"start\":305}]", "publisher": null, "author_last_name": "[{\"end\":88,\"start\":85},{\"end\":216,\"start\":213},{\"end\":318,\"start\":313}]", "author_first_name": "[{\"end\":84,\"start\":77},{\"end\":212,\"start\":208},{\"end\":312,\"start\":305}]", "author_affiliation": "[{\"end\":206,\"start\":113},{\"end\":303,\"start\":218},{\"end\":419,\"start\":347}]", "title": "[{\"end\":74,\"start\":1},{\"end\":494,\"start\":421}]", "venue": null, "abstract": "[{\"end\":1553,\"start\":611}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1638,\"start\":1635},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1640,\"start\":1638},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1642,\"start\":1640},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1675,\"start\":1672},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":1677,\"start\":1675},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":1679,\"start\":1677},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":1703,\"start\":1700},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":1740,\"start\":1737},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":1742,\"start\":1740},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":1974,\"start\":1970},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":1978,\"start\":1974},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":1982,\"start\":1978},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":1986,\"start\":1982},{\"end\":2353,\"start\":2346},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3021,\"start\":3017},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3024,\"start\":3021},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3082,\"start\":3078},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3085,\"start\":3082},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3088,\"start\":3085},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3603,\"start\":3599},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3832,\"start\":3828},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3886,\"start\":3882},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4159,\"start\":4155},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4162,\"start\":4159},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4318,\"start\":4314},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4541,\"start\":4537},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4561,\"start\":4557},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4744,\"start\":4740},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4747,\"start\":4744},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4933,\"start\":4929},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7267,\"start\":7263},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7680,\"start\":7676},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11565,\"start\":11561},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11768,\"start\":11765},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11908,\"start\":11905},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11919,\"start\":11915},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12299,\"start\":12295},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12325,\"start\":12322},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12370,\"start\":12366},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12572,\"start\":12568},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":14099,\"start\":14095},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15844,\"start\":15840}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":17134,\"start\":17075},{\"attributes\":{\"id\":\"fig_1\"},\"end\":17385,\"start\":17135},{\"attributes\":{\"id\":\"fig_2\"},\"end\":17536,\"start\":17386},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":17803,\"start\":17537},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":18469,\"start\":17804},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":19160,\"start\":18470}]", "paragraph": "[{\"end\":2854,\"start\":1569},{\"end\":3490,\"start\":2856},{\"end\":5744,\"start\":3492},{\"end\":5820,\"start\":5746},{\"end\":5949,\"start\":5822},{\"end\":6106,\"start\":5951},{\"end\":6265,\"start\":6108},{\"end\":6462,\"start\":6267},{\"end\":6637,\"start\":6477},{\"end\":6852,\"start\":6653},{\"end\":7227,\"start\":6882},{\"end\":7324,\"start\":7229},{\"end\":7578,\"start\":7418},{\"end\":8179,\"start\":7598},{\"end\":8773,\"start\":8215},{\"end\":9557,\"start\":8775},{\"end\":10303,\"start\":9855},{\"end\":10436,\"start\":10305},{\"end\":10628,\"start\":10438},{\"end\":10670,\"start\":10630},{\"end\":11083,\"start\":10722},{\"end\":11322,\"start\":11135},{\"end\":11756,\"start\":11338},{\"end\":12616,\"start\":11758},{\"end\":13864,\"start\":12657},{\"end\":14753,\"start\":13897},{\"end\":16391,\"start\":14788},{\"end\":17074,\"start\":16422}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":6881,\"start\":6853},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7417,\"start\":7325},{\"attributes\":{\"id\":\"formula_2\"},\"end\":9854,\"start\":9585},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10721,\"start\":10671},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11134,\"start\":11084}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":11418,\"start\":11411},{\"end\":11497,\"start\":11490},{\"end\":13222,\"start\":13214},{\"end\":13626,\"start\":13619},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":14920,\"start\":14912}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1567,\"start\":1555},{\"attributes\":{\"n\":\"2.\"},\"end\":6475,\"start\":6465},{\"attributes\":{\"n\":\"2.1.\"},\"end\":6651,\"start\":6640},{\"attributes\":{\"n\":\"2.2.\"},\"end\":7596,\"start\":7581},{\"attributes\":{\"n\":\"3.\"},\"end\":8202,\"start\":8182},{\"attributes\":{\"n\":\"3.1.\"},\"end\":8213,\"start\":8205},{\"attributes\":{\"n\":\"3.2.\"},\"end\":9584,\"start\":9560},{\"attributes\":{\"n\":\"4.\"},\"end\":11336,\"start\":11325},{\"attributes\":{\"n\":\"4.1.\"},\"end\":12655,\"start\":12619},{\"attributes\":{\"n\":\"4.2.\"},\"end\":13895,\"start\":13867},{\"attributes\":{\"n\":\"4.3.\"},\"end\":14786,\"start\":14756},{\"attributes\":{\"n\":\"5.\"},\"end\":16420,\"start\":16394},{\"end\":17084,\"start\":17076},{\"end\":17144,\"start\":17136},{\"end\":17814,\"start\":17805},{\"end\":18480,\"start\":18471}]", "table": "[{\"end\":18469,\"start\":17890},{\"end\":19160,\"start\":18871}]", "figure_caption": "[{\"end\":17134,\"start\":17086},{\"end\":17385,\"start\":17146},{\"end\":17536,\"start\":17388},{\"end\":17803,\"start\":17539},{\"end\":17890,\"start\":17816},{\"end\":18871,\"start\":18482}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9343,\"start\":9337},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14261,\"start\":14256}]", "bib_author_first_name": "[{\"end\":19231,\"start\":19227},{\"end\":19248,\"start\":19244},{\"end\":19268,\"start\":19260},{\"end\":19270,\"start\":19269},{\"end\":19594,\"start\":19587},{\"end\":19606,\"start\":19599},{\"end\":19622,\"start\":19614},{\"end\":19632,\"start\":19628},{\"end\":20066,\"start\":20060},{\"end\":20085,\"start\":20080},{\"end\":20102,\"start\":20093},{\"end\":20119,\"start\":20115},{\"end\":20140,\"start\":20133},{\"end\":20153,\"start\":20147},{\"end\":20174,\"start\":20167},{\"end\":20193,\"start\":20185},{\"end\":20209,\"start\":20204},{\"end\":20226,\"start\":20219},{\"end\":20671,\"start\":20666},{\"end\":20688,\"start\":20683},{\"end\":21130,\"start\":21120},{\"end\":21142,\"start\":21138},{\"end\":21162,\"start\":21149},{\"end\":21456,\"start\":21451},{\"end\":21473,\"start\":21465},{\"end\":21481,\"start\":21476},{\"end\":21493,\"start\":21490},{\"end\":21502,\"start\":21494},{\"end\":21842,\"start\":21841},{\"end\":21855,\"start\":21851},{\"end\":21864,\"start\":21862},{\"end\":21873,\"start\":21869},{\"end\":22243,\"start\":22235},{\"end\":22263,\"start\":22251},{\"end\":22663,\"start\":22659},{\"end\":23094,\"start\":23088},{\"end\":23107,\"start\":23101},{\"end\":23121,\"start\":23114},{\"end\":23133,\"start\":23129},{\"end\":23143,\"start\":23140},{\"end\":23158,\"start\":23151},{\"end\":23647,\"start\":23642},{\"end\":23661,\"start\":23655},{\"end\":23680,\"start\":23673},{\"end\":23978,\"start\":23971},{\"end\":23990,\"start\":23983},{\"end\":24002,\"start\":23998},{\"end\":24433,\"start\":24427},{\"end\":24445,\"start\":24438},{\"end\":24457,\"start\":24450},{\"end\":24475,\"start\":24467},{\"end\":24489,\"start\":24481},{\"end\":24501,\"start\":24494},{\"end\":24511,\"start\":24508},{\"end\":24526,\"start\":24518},{\"end\":24907,\"start\":24901},{\"end\":24917,\"start\":24913},{\"end\":24928,\"start\":24923},{\"end\":24940,\"start\":24933},{\"end\":24953,\"start\":24946},{\"end\":24969,\"start\":24961},{\"end\":25346,\"start\":25338},{\"end\":25359,\"start\":25351},{\"end\":25371,\"start\":25365},{\"end\":25383,\"start\":25380},{\"end\":25666,\"start\":25663},{\"end\":25683,\"start\":25679},{\"end\":25704,\"start\":25699},{\"end\":25716,\"start\":25712},{\"end\":25726,\"start\":25721},{\"end\":25748,\"start\":25741},{\"end\":25761,\"start\":25756},{\"end\":25779,\"start\":25773},{\"end\":26157,\"start\":26151},{\"end\":26169,\"start\":26162},{\"end\":26193,\"start\":26184},{\"end\":26488,\"start\":26484},{\"end\":26501,\"start\":26497},{\"end\":26514,\"start\":26508},{\"end\":26528,\"start\":26522},{\"end\":27013,\"start\":27007},{\"end\":27196,\"start\":27192},{\"end\":27217,\"start\":27209},{\"end\":27459,\"start\":27453},{\"end\":27470,\"start\":27469},{\"end\":27480,\"start\":27476}]", "bib_author_last_name": "[{\"end\":19242,\"start\":19232},{\"end\":19258,\"start\":19249},{\"end\":19277,\"start\":19271},{\"end\":19597,\"start\":19595},{\"end\":19612,\"start\":19607},{\"end\":19626,\"start\":19623},{\"end\":19636,\"start\":19633},{\"end\":20078,\"start\":20067},{\"end\":20091,\"start\":20086},{\"end\":20113,\"start\":20103},{\"end\":20131,\"start\":20120},{\"end\":20145,\"start\":20141},{\"end\":20165,\"start\":20154},{\"end\":20183,\"start\":20175},{\"end\":20202,\"start\":20194},{\"end\":20217,\"start\":20210},{\"end\":20232,\"start\":20227},{\"end\":20681,\"start\":20672},{\"end\":20695,\"start\":20689},{\"end\":21136,\"start\":21131},{\"end\":21147,\"start\":21143},{\"end\":21170,\"start\":21163},{\"end\":21463,\"start\":21457},{\"end\":21488,\"start\":21482},{\"end\":21512,\"start\":21503},{\"end\":21849,\"start\":21843},{\"end\":21860,\"start\":21856},{\"end\":21867,\"start\":21865},{\"end\":21878,\"start\":21874},{\"end\":21885,\"start\":21880},{\"end\":22249,\"start\":22244},{\"end\":22270,\"start\":22264},{\"end\":22670,\"start\":22664},{\"end\":22679,\"start\":22672},{\"end\":23099,\"start\":23095},{\"end\":23112,\"start\":23108},{\"end\":23127,\"start\":23122},{\"end\":23138,\"start\":23134},{\"end\":23149,\"start\":23144},{\"end\":23161,\"start\":23159},{\"end\":23653,\"start\":23648},{\"end\":23671,\"start\":23662},{\"end\":23689,\"start\":23681},{\"end\":23981,\"start\":23979},{\"end\":23996,\"start\":23991},{\"end\":24006,\"start\":24003},{\"end\":24436,\"start\":24434},{\"end\":24448,\"start\":24446},{\"end\":24465,\"start\":24458},{\"end\":24479,\"start\":24476},{\"end\":24492,\"start\":24490},{\"end\":24506,\"start\":24502},{\"end\":24516,\"start\":24512},{\"end\":24531,\"start\":24527},{\"end\":24537,\"start\":24533},{\"end\":24911,\"start\":24908},{\"end\":24921,\"start\":24918},{\"end\":24931,\"start\":24929},{\"end\":24944,\"start\":24941},{\"end\":24959,\"start\":24954},{\"end\":24974,\"start\":24970},{\"end\":25349,\"start\":25347},{\"end\":25363,\"start\":25360},{\"end\":25378,\"start\":25372},{\"end\":25386,\"start\":25384},{\"end\":25677,\"start\":25667},{\"end\":25697,\"start\":25684},{\"end\":25710,\"start\":25705},{\"end\":25719,\"start\":25717},{\"end\":25739,\"start\":25727},{\"end\":25754,\"start\":25749},{\"end\":25771,\"start\":25762},{\"end\":25786,\"start\":25780},{\"end\":26160,\"start\":26158},{\"end\":26182,\"start\":26170},{\"end\":26198,\"start\":26194},{\"end\":26495,\"start\":26489},{\"end\":26506,\"start\":26502},{\"end\":26520,\"start\":26515},{\"end\":26537,\"start\":26529},{\"end\":26819,\"start\":26810},{\"end\":27016,\"start\":27014},{\"end\":27207,\"start\":27197},{\"end\":27224,\"start\":27218},{\"end\":27467,\"start\":27460},{\"end\":27474,\"start\":27471},{\"end\":27491,\"start\":27481},{\"end\":27499,\"start\":27493}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":195908774},\"end\":19539,\"start\":19162},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":206594692},\"end\":19982,\"start\":19541},{\"attributes\":{\"doi\":\"arXiv:2010.11929\",\"id\":\"b2\"},\"end\":20562,\"start\":19984},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2617020},\"end\":21051,\"start\":20564},{\"attributes\":{\"doi\":\"arXiv:1508.04025\",\"id\":\"b4\"},\"end\":21367,\"start\":21053},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":52967399},\"end\":21747,\"start\":21369},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":14862572},\"end\":22188,\"start\":21749},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":202579608},\"end\":22539,\"start\":22190},{\"attributes\":{\"id\":\"b8\"},\"end\":22994,\"start\":22541},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":222278549},\"end\":23548,\"start\":22996},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":237711226},\"end\":23913,\"start\":23550},{\"attributes\":{\"id\":\"b11\"},\"end\":24368,\"start\":23915},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":227910894},\"end\":24839,\"start\":24370},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":237206715},\"end\":25312,\"start\":24841},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":1322184},\"end\":25632,\"start\":25314},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":1033682},\"end\":26068,\"start\":25634},{\"attributes\":{\"doi\":\"arXiv:1708.06733\",\"id\":\"b16\"},\"end\":26406,\"start\":26070},{\"attributes\":{\"doi\":\"arXiv:1710.10196\",\"id\":\"b17\"},\"end\":26746,\"start\":26408},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":2783597},\"end\":26967,\"start\":26748},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b19\"},\"end\":27135,\"start\":26969},{\"attributes\":{\"id\":\"b20\"},\"end\":27407,\"start\":27137},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":1257772},\"end\":27742,\"start\":27409}]", "bib_title": "[{\"end\":19225,\"start\":19162},{\"end\":19585,\"start\":19541},{\"end\":20664,\"start\":20564},{\"end\":21449,\"start\":21369},{\"end\":21839,\"start\":21749},{\"end\":22233,\"start\":22190},{\"end\":23086,\"start\":22996},{\"end\":23640,\"start\":23550},{\"end\":23969,\"start\":23915},{\"end\":24425,\"start\":24370},{\"end\":24899,\"start\":24841},{\"end\":25336,\"start\":25314},{\"end\":25661,\"start\":25634},{\"end\":26808,\"start\":26748},{\"end\":27451,\"start\":27409}]", "bib_author": "[{\"end\":19244,\"start\":19227},{\"end\":19260,\"start\":19244},{\"end\":19279,\"start\":19260},{\"end\":19599,\"start\":19587},{\"end\":19614,\"start\":19599},{\"end\":19628,\"start\":19614},{\"end\":19638,\"start\":19628},{\"end\":20080,\"start\":20060},{\"end\":20093,\"start\":20080},{\"end\":20115,\"start\":20093},{\"end\":20133,\"start\":20115},{\"end\":20147,\"start\":20133},{\"end\":20167,\"start\":20147},{\"end\":20185,\"start\":20167},{\"end\":20204,\"start\":20185},{\"end\":20219,\"start\":20204},{\"end\":20234,\"start\":20219},{\"end\":20683,\"start\":20666},{\"end\":20697,\"start\":20683},{\"end\":21138,\"start\":21120},{\"end\":21149,\"start\":21138},{\"end\":21172,\"start\":21149},{\"end\":21465,\"start\":21451},{\"end\":21476,\"start\":21465},{\"end\":21490,\"start\":21476},{\"end\":21514,\"start\":21490},{\"end\":21851,\"start\":21841},{\"end\":21862,\"start\":21851},{\"end\":21869,\"start\":21862},{\"end\":21880,\"start\":21869},{\"end\":21887,\"start\":21880},{\"end\":22251,\"start\":22235},{\"end\":22272,\"start\":22251},{\"end\":22672,\"start\":22659},{\"end\":22681,\"start\":22672},{\"end\":23101,\"start\":23088},{\"end\":23114,\"start\":23101},{\"end\":23129,\"start\":23114},{\"end\":23140,\"start\":23129},{\"end\":23151,\"start\":23140},{\"end\":23163,\"start\":23151},{\"end\":23655,\"start\":23642},{\"end\":23673,\"start\":23655},{\"end\":23691,\"start\":23673},{\"end\":23983,\"start\":23971},{\"end\":23998,\"start\":23983},{\"end\":24008,\"start\":23998},{\"end\":24438,\"start\":24427},{\"end\":24450,\"start\":24438},{\"end\":24467,\"start\":24450},{\"end\":24481,\"start\":24467},{\"end\":24494,\"start\":24481},{\"end\":24508,\"start\":24494},{\"end\":24518,\"start\":24508},{\"end\":24533,\"start\":24518},{\"end\":24539,\"start\":24533},{\"end\":24913,\"start\":24901},{\"end\":24923,\"start\":24913},{\"end\":24933,\"start\":24923},{\"end\":24946,\"start\":24933},{\"end\":24961,\"start\":24946},{\"end\":24976,\"start\":24961},{\"end\":25351,\"start\":25338},{\"end\":25365,\"start\":25351},{\"end\":25380,\"start\":25365},{\"end\":25388,\"start\":25380},{\"end\":25679,\"start\":25663},{\"end\":25699,\"start\":25679},{\"end\":25712,\"start\":25699},{\"end\":25721,\"start\":25712},{\"end\":25741,\"start\":25721},{\"end\":25756,\"start\":25741},{\"end\":25773,\"start\":25756},{\"end\":25788,\"start\":25773},{\"end\":26162,\"start\":26151},{\"end\":26184,\"start\":26162},{\"end\":26200,\"start\":26184},{\"end\":26497,\"start\":26484},{\"end\":26508,\"start\":26497},{\"end\":26522,\"start\":26508},{\"end\":26539,\"start\":26522},{\"end\":26821,\"start\":26810},{\"end\":27018,\"start\":27007},{\"end\":27209,\"start\":27192},{\"end\":27226,\"start\":27209},{\"end\":27469,\"start\":27453},{\"end\":27476,\"start\":27469},{\"end\":27493,\"start\":27476},{\"end\":27501,\"start\":27493}]", "bib_venue": "[{\"end\":19328,\"start\":19279},{\"end\":19715,\"start\":19638},{\"end\":20058,\"start\":19984},{\"end\":20765,\"start\":20697},{\"end\":21118,\"start\":21053},{\"end\":21538,\"start\":21514},{\"end\":21946,\"start\":21887},{\"end\":22342,\"start\":22272},{\"end\":22657,\"start\":22541},{\"end\":23229,\"start\":23163},{\"end\":23711,\"start\":23691},{\"end\":24089,\"start\":24008},{\"end\":24587,\"start\":24539},{\"end\":25049,\"start\":24976},{\"end\":25450,\"start\":25388},{\"end\":25837,\"start\":25788},{\"end\":26149,\"start\":26070},{\"end\":26482,\"start\":26408},{\"end\":26836,\"start\":26821},{\"end\":27005,\"start\":26969},{\"end\":27190,\"start\":27137},{\"end\":27544,\"start\":27501},{\"end\":19779,\"start\":19717},{\"end\":20820,\"start\":20767},{\"end\":21549,\"start\":21540},{\"end\":23282,\"start\":23231},{\"end\":24157,\"start\":24091}]"}}}, "year": 2023, "month": 12, "day": 17}