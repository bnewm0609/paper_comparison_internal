{"id": 260061199, "updated": "2023-09-07 14:21:15.874", "metadata": {"title": "mmEavesdropper: Signal Augmentation-based Directional Eavesdropping with mmWave Radar", "authors": "[{\"first\":\"Yiwen\",\"last\":\"Feng\",\"middle\":[]},{\"first\":\"Kai\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Chuyu\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Lei\",\"last\":\"Xie\",\"middle\":[]},{\"first\":\"Jingyi\",\"last\":\"Ning\",\"middle\":[]},{\"first\":\"Shijia\",\"last\":\"Chen\",\"middle\":[]}]", "venue": "IEEE INFOCOM 2023 - IEEE Conference on Computer Communications", "journal": "IEEE INFOCOM 2023 - IEEE Conference on Computer Communications", "publication_date": {"year": 2023, "month": 5, "day": 17}, "abstract": "With the popularity of online meetings equipped with speakers, voice privacy security has drawn increasing attention because eavesdropping on the speakers can quickly obtain sensitive information. In this paper, we propose mmEavesdropper, a mmWave based eavesdropping system, which focuses on augmenting the micro-vibration signal via theoretical models for voice recovery. Particularly, to augment the receiving signal of the target vibration, we propose to use beam-forming to facilitate the directional augmentation by suppressing other orientations and use Chirp-Z transform to facilitate the distance augmentation by increasing the range resolution compared with traditional FFT. To augment the vibration signal in the IQ plane, we build a theoretical model to analyze the distortion and propose a segmentation-based fitting method to calibrate the vibration signal. To augment the spectrum for sound recovery, we propose to combine multiple channels and leverage an encoder-decoder based neural network to reconstruct the spectrogram for voice recovery. We perform extensive experiments on mmEavesdropper and the results show that mmEavesdropper can reach the accuracy of 93% on digit and letter recognition. Moreover, mmEavesdropper can reconstruct the voice with an average SNR of 5dB and peak SNR of 17dB.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/infocom/FengZWXNC23", "doi": "10.1109/infocom53939.2023.10229095"}}, "content": {"source": {"pdf_hash": "3ff499bf44f00c904f0f4c419f21c45d795b5b7e", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "55bd5abcff0cf22ed1d9ab4ea5c7eca2e88d6de3", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3ff499bf44f00c904f0f4c419f21c45d795b5b7e.txt", "contents": "\nmmEavesdropper: Signal Augmentation-based Directional Eavesdropping with mmWave Radar\n\n\nYiwen Feng \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nKai Zhang \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nChuyu Wang \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nLei Xie lxie@nju.edu.cn \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nJingyi Ning \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nShijia Chen \nState Key Laboratory for Novel Software Technology\nNanjing University\nChina\n\nmmEavesdropper: Signal Augmentation-based Directional Eavesdropping with mmWave Radar\n10.1109/INFOCOM53939.2023.10229095Index Terms-mmWaveSound vibrationSignal augmenta- tionEavesdropping\nWith the popularity of online meetings equipped with speakers, voice privacy security has drawn increasing attention because eavesdropping on the speakers can quickly obtain sensitive information. In this paper, we propose mmEavesdropper, a mmWave based eavesdropping system, which focuses on augmenting the micro-vibration signal via theoretical models for voice recovery. Particularly, to augment the receiving signal of the target vibration, we propose to use beam-forming to facilitate the directional augmentation by suppressing other orientations and use Chirp-Z transform to facilitate the distance augmentation by increasing the range resolution compared with traditional FFT. To augment the vibration signal in the IQ plane, we build a theoretical model to analyze the distortion and propose a segmentation-based fitting method to calibrate the vibration signal. To augment the spectrum for sound recovery, we propose to combine multiple channels and leverage an encoder-decoder based neural network to reconstruct the spectrogram for voice recovery. We perform extensive experiments on mmEavesdropper and the results show that mmEavesdropper can reach the accuracy of 93% on digit and letter recognition. Moreover, mmEavesdropper can reconstruct the voice with an average SNR of 5dB and peak SNR of 17dB.\n\nI. INTRODUCTION\n\nAcoustic eavesdropping is regarded as one of the critical privacy leakage problems because the human voice is the easiest way to obtain sensitive information. On one hand, intelligent voice assistant systems are widely deployed in people's homes, which extend the usage of speakers and bring new risks of being attacked. For example, the Remember function of google home may replay passwords, private messages, and schedules, which may be leaked and cause privacy problems. On the other hand, with the growth of remote cooperation in international companies and the prevalence of working from home during the COVID-19 pandemic, online meetings have been widely used, where different kinds of confidential information may be mentioned during the meeting. The speaker plays these sensitive voices during the meetings and is probably leaked to the adversary. For instance, information including trade secrets and passwords may be leaked when someone discusses them in online meetings, which can bring unpredictable dangers of economic losses and even personal safety.\n\nTraditionally, acoustic eavesdropping is based on an embedded wiretapping device, which can record the original sounds. However, it is affected by environmental noise and other sound. Researchers have recently proposed new approaches to sense the sound source's vibration for eavesdropping directly. private information emitted by the speaker Sensor-based approaches use the vibration effect caused by sound pressure to reconstruct the voice [1]- [3]. However, these approaches are limited by the contact sensing manner, and usually, they can only realize audio classification instead of voice reconstruction. Vision-based approaches [4] use highspeed cameras to capture the sound-related vibration of tiny objects for sound reconstruction. However, it is vulnerable to illumination and can be obscured. Wireless-based approaches have gained more interest in recent years. Researchers use the reflected signal pattern of RFID [5] [6] and mmWave [7] to sense the sound vibration. However, most work can only classify specific words instead of reconstructing the sound, which has obvious limitations. MILLIEAR [7] and mmPhone [8] realize audio reconstruction based on mmWave. However, they focus on directly using the original mmWave signal for reconstruction with a well-trained neural network, which usually depends on the specific sensing environment.\n\nIn this paper, we propose mmEavesdropper, a mmWavebased approach to eavesdrop on the speaker's sound based on the received signal. Compared with the traditional wiretap, mmEavesdropper can leverage the multiple receiving antennas to perform beam-forming such that only the vibration of the target orientation can be captured. Specifically, we focus on augmenting the vibration caused by the sound. We model the sound vibration and optimize the Frequency Modulated Continuous Wave (FMCW) signal data processing algorithm with Commercial Off The Shelf (COTS) mmWave radar. We augment the vibration effect from the following three aspects. Firstly, to obtain the exact vibration signal from the mmWave signal, we augment the received signal by focusing on the orientation and distance of the target vibration membrane with the beam-forming technique and Chirp-Z transform. Secondly, to extract the exact signal feature from the vibration signal, we augment the vibration signal by proposing an IQ-based distortion model and a segmentation-based fitting method to calibrate the vibration signal. Finally, to completely recover the frequency spectrum of the sound, we propose to fuse the vibration signal feature of multiple channels and train an encoder-decoder network to reconstruct the sound.\n\nThere are three key challenges to be addressed in this paper. The first challenge is to accurately extract the vibration signal from the raw received signal. Traditionally, the Fast Fourier Transform (FFT) method is used to determine the distance of the vibrating membrane. After that, we can extract the corresponding range bin signal. However, due to the limitation of sampling rate, the resolution of such method is only 4 cm, which is not accurate enough to extract the exact vibration signal. To address this challenge, we propose to apply the Chirp-Z transform (CZT), which can efficiently increase the resolution of the FFT algorithm without increasing the computation overhead significantly. Instead of getting the uniform spectrum over the whole frequency band, CZT can define the target frequency band within a specific range and increase the sampling precision of based on sparse point FFT. As a result, we can get higher resolution for the frequency spectrum of the target band, such that we can accurately determine the exact distance of the target with higher resolution.\n\nThe second challenge is to calibrate the signal distortion due to the multiple path effect. Theoretically, the signal samples tend to rotate on an arc-like trace in the IQ plane. However, according to our empirical study, the vibration signals in the IQ plane are distorted due to the complicated multi-path effect and approximate treatment of peak frequency in CZT. Such distortion can import massive noise on both the phase and strength of the vibration signal, making the vibration signal's spectrum different from the original human voice. To address this challenge, we build a theoretical model of the signal in the IQ plane, which can quantitatively derive the phase error due to the Fourier transform and strength error due to the variation of the multi-path effect. Based on this model, we propose a segmentation-based fitting method of phase augmentation, which can efficiently divide the signal into two parts according to the model. After that, each part is a complete arc consisting of the fundamental vibration, and we can leverage the phase of the arc to estimate the vibration.\n\nThe third challenge is to augment the frequency spectrum due to the frequency response issue of the speaker. Usually, low-frequency sound has a larger vibration amplitude for the same loudness than the high-frequency sound due to the specific frequency response curve of the speaker [9]. As a result, since the vibration signal measured from the mmWave represents the vibration amplitude, the high-frequency band has weaker power than the low-frequency band, although the high-frequency vibration is also captured. To address this challenge, we propose a channel fusion-based learning method to compensate for the frequency band. Although the vibration signal of the target bin is more accurate, we find that the vibration spectrum also appears in the vibration of the nearby range bins. Therefore, we propose to comprehensively consider the vibration signal of multiple channels, which all contain sound vibration. After that, we leverage an encoderdecoder network to learn the frequency features from these vibration signals and then reconstruct the human voice based on these features. Based on the above mechanism, we can efficiently recover the human voice from multiple channels of the vibration signal.\n\nIn this paper, we make the following contributions. First, we comprehensively investigate the capability of sound eavesdropping with mmWave radar and propose a novel system mmEavesdropper to sense the sound vibration based on the augmentation of mmWave signal. Second, we propose theoretical models to augment the receiving signal by focusing on the accurate orientation and distance of the vibration target, augment the vibration signal by calibrating the IQ signal distortion, and augment the frequency spectrum by fusing multiple channels with high-frequency compensating. The proposed models can provide essential insights to extract and study the micro-vibration based on the COTS mmWave radars. Third, we implement a real system prototype based on COTS mmWave radar and train an encoder-decoder based neural network to recover the human voice. According to extensive experiments, our system can efficiently eavesdrop on the human voice with 93% accuracy.\n\n\nII. RELATED WORK\n\nSensor-based Approach. Sensor-based eavesdropping approaches mainly convert vibration displacement caused by audio signal to an electrical signal to reconstruct the audio signal. Researchers propose to use mobile phone built-in sensors such as gyroscope [10], accelerometer [11] and Inertial Measurement Unit (IMU) [2] [12]. These approaches utilize the vibration effect caused by sound pressure to recognize the sound. Kwong et al. [3] use disk drives to eavesdrop. However, these approaches require contact sensing and have low sampling rates. Additionally, they only classify audio signals rather than recovering the signals.\n\nCV-based Approach. Approaches based on Computer vision (CV) mainly leverage high-speed cameras and lidars. Researchers use cameras to capture the vibration of tiny objects in the environment caused by sound waves and apply CV algorithms to videos or image sequences [4]. Some researchers utilize customized lidar sensors to sense the audible vibration [13] [14]. For example, Sami et al. [1] propose an eavesdropping scheme using lidar equipped on a cleaning robot. Specifically, thin and light objects such as clothes and plastic bags vibrate due to the audio source, and lidars can scan the vibration to restore sound. Unfortunately, these perception methods depend on the illumination condition, and the sensing target must be in a non-line-of-sight scene. Meanwhile, the sampling rate of cheap household lidars is often low, which reduces their availability.\n\nWireless-based Approach. Wireless signals provide inspiring solutions for sensing [15]- [26]. The mechanism of the Wireless-based approach is that the vibration target modulates the reflected signals, and the signal processing algorithms can demodulate the original sound signal. There are many solutions based on centimeter-wave. Wei et al. [27] use WIFI beam-forming technology with an antenna array to sense speaker vibration and realize eavesdropping through walls. Some researchers use RFID signals to sense the vibration of objects [28] [29]. Li et al. [6] propose that RFID tags can use harmonic signals to sense single-frequency sound and improve the single-frequency vibration sensing ability of RFID to 2.5kHz. In recent years, the development and application of millimeter-wave have provided new possibilities for eavesdropping. Xu et al. [30] realize human voice reconstruction through a customized mmWave radar. Wavoice [31] use the commercial mmWave radar to capture information in the human voice and recognize the speech.\n\nUnlike the previous work, mmEavesdropper is implemented on a portable COTS device and can realize directional sensing. It has no limit of illumination and can work in dark scenarios. Besides word classification, mmEavesdropper can recover sound with high SNR, which is human recognizable.\n\n\nIII. EMPIRICAL STUDY\n\nIn order to investigate the sensing ability of mmWave, we execute some empirical experiments to extract the sound vibration from the mmWave signal. As shown in Fig. 2(a), we place the mmWave radar in front of the speaker at 1m and try to leverage the radar to sense the sound vibration. Similar to the existing solutions [8] [7] [31], we first conduct range-FFT to determine the range bin of the target vibrating membrane and then extract the sound vibration from the phase of the signal belonging to the target bin.\n\nA. Feasibility of sound sensing Observation 1. The mmWave can clearly capture the monotone sound vibration from the frequency spectrum with much noise, but it is challenging to capture the clear human voice with a complicated frequency spectrum.\n\nWe first directly verify the sound-capturing ability of the mmWave by playing two monotone sounds of 300Hz and 500Hz with the speaker. We extract the target bin based on the strongest reflection signal power by applying an FFT and present the time-frequency spectrogram by applying Shorttime Fourier transform (STFT) on the signal phase. The spectrograms are shown in Fig. 2(b) and Fig. 2(c). There are two predominant frequencies at the corresponding values, meaning the potential for audio sensing. However, there are also harmonic wave interference and noise interference, which can severely affect the sensing performance. Hence, it is necessary to filter the noise to obtain a stable vibration signal.\n\nMoreover, we further try to sense the human voice with a complicated frequency spectrum played by the speaker. As shown in Fig. 2(d), we apply STFT to the received signal phase and present the time-frequency spectrogram. Compared to the original voice signal, as shown in Fig. 2(e), it is evident that the mmWave radar has captured the human voice. Notably, due to the constraint of the sampling rate, the captured frequency is below 2.5 kHz, which is still sufficient to cover the human voice. However, there is also a lot of noise interference on the spectrogram, which unfortunately submerges the vibration signal completely. As a result, the spectrogram of human voices is unclear, so removing such noise is necessary.\n\n\nB. Interference related range bin estimation\n\nObservation 2. The estimated bin of the target vibration based on the range-FFT can only determine the coarse position of the target, leading to the noise of the signal phase.\n\nWe firstly play a monotone sound on the speaker and apply FFT on the captured signal. Then we get the bin with the strongest reflection, corresponding to 1.23m. The Signal Noise Ratio (SNR) of the signal phase in this bin is 12.15dB. After that, we move the speaker 2cm away from the radar and repeat the experiment above. The result indicates that the strongest reflection still occurs at 1.23m, which is equal to the initial position. However, after a 2cm movement, the SNR of the signal in the target bin reduces to 9.35dB. The experiments show that range-FFT cannot catch this change in the frequency domain when we move the speaker. Furthermore, a coarse range bin also reduces the SNR of the phase frequency, which will significantly damage the performance of sound reconstruction.\n\nHowever, the radar resolution is 4cm, which is relatively ambiguous. As a result, signals from that wide range bin can be mixed up with some irrelevant components of other objects, leading to interference to the target voice portion. Therefore, it is essential to find an efficient method to confirm the speaker's location accurately.\n\n\nC. Phase distortion\n\nObservation 3. The extracted signal does not ideally rotate as an arc in the IQ plane due to the multi-path effect.\n\nIn addition to the accurate distance of the target vibrating membrane, we further investigate the signal pattern of the target range bin. According to the theoretical models [32] [30], as the speaker vibrates back and forth, the signal tends to rotate on an arc on the IQ plane ideally. However, our experiments find that the signal variation pattern is not always an arc, as shown in Fig. 2(f). Since the phase changes are inherently sensitive, especially for the slight vibration estimation, such distortion can dramatically destroy the sound sensing. Hence, it is essential to determine the reason for this distorted pattern and remove them.\n\n\nD. Signal in multiple channels\n\nObservation 4. Signals of different channels show associated patterns, which can be used to sense the micro-vibration comprehensively.\n\nThe mmWave radar in the experiment has multiple Receiving (RX) antennas. Usually, only one channel's data is used, while the others are be discarded, which may lose much vibration information. As shown in Fig. 2(g) and Fig. 2(h), signals from two RX antennas have associated patterns, although they still have some differences. Therefore, it is necessary to take \n\n\nIV. MILLIMETER-WAVE EAVESDROPPING MODEL\n\nThis section introduces the theoretical model of vibration sensing based on the mmWave radar. Mainly, we introduce the CZT (Chirp-Z transform) to optimize the resolution of range-FFT and then analyze the IQ distortion from the view of FFT calculation and multi-path effect.\n\n\nA. Basic Vibration Sensing Model\n\nThe mmWave radar leverages the FMCW (Frequency-Modulated Continuous Wave) technology, which transmits a sinusoid signal called \"chirp\" with linearly increasing frequency. A chirp is transmitted from the transmitting(TX) antenna, then reaches an object with distance R(t) and bounces back to the receiving (RX) antenna. We compare the RX signal with the TX signal to estimate the distance. The TX signal s T X and RX signal s RX can be expressed as [33] [34]:\ns T X (t) = exp [j(2\u21e1f c t + \u21e1Kt 2 )], s RX (t) = \u21b5s T X [t 2R(t)/c],(1)\nwhere f c and K are the starting frequency and the chirp slope of the FMCW signal, respectively, \u21b5 is the path loss. Then a mixer is used to generate the Intermediate Frequency (IF) signal as [34]:\ns IF (t) = s T X (t) \u00b7 conj[(s RX (t)] \u21e1 \u21b5 exp \u21e5 2\u21e1j(2f c R(t)/c + 2KR(t)/c \u00b7 t) \u21e4 ,(2)\nwhere conj[(s RX (t)] means conjugate of s RX (t). Therefore, we can use the Fourier Transform on the IF signal to get the target frequency [35] as: where is Dirac Delta function [36]. It means that when f = 2KR(t)/c, there is a frequency peak. Then we substitute f = 2KR(t)/c into Eq. (3) and get the signal of the corresponding frequency as \u21b5 exp [j4\u21e1f c R(t)/c]. It indicates that for the IF signal, there is a linear connection between the signal frequency and the reflection distance R(t). We can extract the signal of corresponding frequency to represent the signal of the distance.\nS IF (f ) = F(s IF (t)) = A (f 2KR(t)/c), A = \u21b5 exp [j4\u21e1f c R(t)/c],(3)\nIf the reflected object is vibrating, i.e., R(t) = R 0 + d(t), where R 0 is the static distance and d(t) is the vibrating function related to time t. Therefore, for each chirp, we can set f = 2KR(t)/c to get the signal of frequency peak, and the continuous chirp can form a continuous signal x(t) related to the vibrations as:\nx(t) = \u21b5 exp [j4\u21e1f c R(t)/c].(4)\nAccording to Eq.(4), when R = R 0 + d(t), the vibration d(t) can lead to the phase change of x(t), where the phase \u2713(t) = 4\u21e1d(t) . Therefore, we can first estimate the frequency peak to determine R 0 and then extract x(t) to perceive the sound vibration.\n\n\nB. Optimization of Target Detection\n\nBased on the above model, it is vital to accurately estimate the vibration distance, i.e., R 0 . Conventional methods use FFT to determine the target range bin where the vibration is located. However, the locating accuracy is limited because the resolution of FFT is determined by the sampling rate and data size of a chirp according to Nyquist sampling theory [37]. For the IF signal s IF (t) with N samples, the formula of FFT can be presented as [38]:\nS IF (k) = N 1 X t=0 s IF (t)e j2\u21e1k/N ,(5)\nwhere k is the frequency index. Supposing F s is the sampling rate, the FFT method divides the target frequency band [ F s /2, F s /2] into N bins, where the resolution is F s /N . This bin is called a \"range bin\". Therefore, if the actual frequency of IF signal for an object is f actual and the corresponding range bin frequency estimated from the peak of FFT is f F F T , it means:\nf actual 2 [f F F T F s 2N , f F F T + F s 2N ].(6)\nTherefore, it is inaccurate to directly use the estimated frequency f F F T to indicate the location. According to the empirical experiment result, inaccurate location will lead to noise in the signal.\n\nTo solve the problem, we import Chirp-Z transform (CZT) [39], which can sufficiently improve the resolution. CZT can zoom out the spectrum of a specific frequency band to improve the resolution. For the same IF signal s IF (t), we can calculate the CZT as:\nS CZT (k) = N 1 X t=0 s IF (t)G t W tk , k = 0, . . . , M 1 G = G 0 e j2\u21e1\u27130 W = W 0 e i2\u21e1 0 .(7)\n\u2713 0 and 0 are the unit circle's start angle and angular spacing. Based on Eq. (7), CZT can be considered as M-points sampling of original FFT result, whose starting frequency and interval are G = G 0 e j2\u21e1\u27130 and W = W 0 e i2\u21e1 0 , respectively. When G = 1 and W = e j2\u21e1k/N , CZT degenerates into FFT. Compared to FFT, CZT only focuses on a specific frequency band instead of the whole frequency band, which guarantees precision and also reduces computational complexity.\n\nIn our scenario, we first determine the range bin according to the FFT peaks as f F F T . In order to find the more precise peak in the fft range bin, we set the range of CZT as\n[f F F T 2Fs N , f F F T + 2Fs N ]\n. Now, we use M-points CZT to search for the peaks in the spectrum, which can improve the resolution M times compared with the FFT. For example, In Fig. 3, the result of FFT indicates the speaker is at 1m. Nevertheless, the peak coverage of FFT is coarse, but CZT can find a more fine-grained result within an FFT range bin, which is 1.018m.\n\n\nC. Signal Distortion in the IQ Plane\n\nAfter determining the range bin of the vibrating membrane, we can extract the corresponding signal related to the distance of the vibrating membrane for sound sensing. The basic idea is to extract the signal x(t) based on the estimating range bin from the CZT method and then estimate the vibration  Fig. 4(a):\nx(t) = s membrane + s static .(8)\nSince only s membrane varies the phase due to the vibrating, the signal moves along an arc in the IQ plane as shown in Fig. 4(b). Here, the center of the arc is related to s static instead of the origin, and the variation phase of x(t) is related to the vibration displacement d(t). Thus, the traditional method can leverage the fitting method to estimate the center and extract the vibration displacement accordingly. However, due to reciprocating motion during vibrating, the position of the vibrating membrane is not static at the original range bin but may slightly move out of the range bin. Thus, the signal directly extracted from the range bin may be distorted, which cannot accurately reflect the vibration. Next, we analyze this distortion and propose to resolve the problem.\n\n\n1) Phase Distortion:\n\nFor the phase distortion, we find it is caused by approximate treatment in signal processing. For simplicity, we take the FFT as an example to analyze the distortion, which can be extended to the CZT.\n\nConventionally, before applying the FFT on the IF signal to get the frequency spectrum, we need to add a rectangular window on the IF signal. Therefore, instead of the theoretical Fourier Transform function of Eq. (3), the actual frequency spectrum of FFT is:\nS IF (f ) 0 = F s IF (t) \u00b7 W T (t) = F s IF (t) \u21e4 F W T (t) = [A (f 2KR(t)/c)] \u21e4 [T Sinc(fT ) exp ( j \u21e1fT )], where W T (t) = ( 1, 0 \uf8ff t < T 0, else.(9)\nHere, \u21e4 means convolution. It represents multiplication in the time domain and convolution in the frequency domain. W T (t) is the rectangular window, and Sinc(f ) = sin (\u21e1f ) \u21e1f is sinc function for calculating the spectrum of W T (t) [40]. Moreover, since a convolution with Dirac Delta function is equal to graph translation on coordinates [41], we can write Eq.(9) as:\nS IF (f ) 0 = ASinc(f 2KR(t)/c) exp [ j\u21e1T(f 2KR(t)/c)].(10)\nHere, if we can accurately calculate the value of R(t) from f regardless of the variation of R(t) due to the vibration, i.e.,  . However, since we need to fix the range bin to investigate the signal change for vibration sensing, i.e., f = f static = 2KR 0 /c, the distance R(t) is continuously changing due to the vibration, which is not always matching the frequency. Then, by substituting f = f static and R = R 0 + d(t) into Eq.(10) and we get:\nS dist (f ) 0 = \u21b5 0 exp h j \u21e3 4\u21e1R 0 + 4\u21e1d(t) + 2\u21e1T Kd(t) c \u2318i .(11)\nHere \u21b5 0 is a generalization of coefficients, which varies in a small range around one related to d(t). Therefore, we can easily omit the variation of amplitude. Under this circumstance, the actual phase \u2713 real = \u2713 ideal + 2\u21e1T Kd(t) c . Compared to the ideal phase \u2713 ideal , the additional error is:\n\u2713 = 2\u21e1T Kd(t) c .(12)\nIn our system, T \u00b7 K = 4GHz represents the radar band. for a speaker's micro-vibration d(t) = 5mm, the phase error ranges from 0.1\u21e1 \u21e0 0.12\u21e1. Therefore, the phase distortion can be up to 21.6 , which is non-negligible.\n\n2) Amplitude Distortion: When the speaker plays the sound, not only the vibrating membrane but also the body of the speaker is vibrating. As a result, the vibration signal is the superposition of all the vibration signals:\nx(t) 0 = s static + s membrane + s speaker .(13)\nSince the reflection coefficient of the speaker depends on the multi-path effect and the sound vibration, it may either enhance or reduce the strength of the raw vibration signal x(t), leading to amplitude distortion. As shown in Fig. 5, the extra interference of s speaker will affect vibration signal x(t), and make both the amplitude and the rotation radius either increase in Fig. 5(a) or decrease in Fig. 5(b). Moreover, the amplitude of s speaker is related to the vibrating membrane, which means that when the phase distortion is more significant, the amplitude distortion is also more considerable.\n\n\n3) Analysis of Signal Distortion:\n\nTo verify the above model, we have collected different sounds played by the speaker and summarized three kinds of signal distortion in the IQ plane as shown in Fig. 6. We find that instead of varying along an arc theoretically, the practical signal in the IQ place may show different patterns. To analyze that pattern, we try to use the above model to explain the distortion in Fig. 6. Particularly, we define P static as the stationary point, when d(t) = 0. Based on the stationary point and the surrounding  Fig. 6. Based on the P static and the arc, the signal can be divided into two part, corresponding to d(t) > 0 and d(t) < 0. Here, we find the phase distortion is relatively regular: when the phase is larger than P static , the phase variation is smaller than the theoretical value, and vice versa. But for the amplitude, the distortion of different cases show different patterns: reduced on both sides or enhanced on one side and reduced on the other. Based on the above model and analysis, we need to handle the distortion of the signal in the IQ plane and efficiently extract the phase signal linearly proportional to the vibration, which is later introduced in Section V-C.\n\n\nV. SYSTEM DESIGN\n\n\nA. System Overview\n\nIn this paper, we propose a novel system to eavesdrop the speaker via mmWave radar, by efficiently calibrating and augmenting the vibration effect on the mmWave. Particularly, we augment the vibration signal from three aspects: Target Focusing-based Signal Augmentation, IQ Calibration-based Vibration Augmentation and Channel Fusion-based Voice Augmentation. Firstly, Target focusing-based Signal Augmentation leverages the Beam-forming technology and the Chirp-Z transform to augment the receiving IF signal, which extracts the signal of the target vibration by focusing on the target orientation and distance, respectively. Secondly, IQ Calibrationbased Vibration Augmentation calibrates the phase distortion and strength distortion by efficiently segmenting the IQ signal into two arcs and then extract the augmented corresponding phase for vibration sensing. Finally, Channel Fusion-based Voice Augmentation combines the vibration signal of multiple adjacent channels and leverages an encoder-encoder network to extract the sound-related fundamental vibration information, which can be further used to recover the human voice.\n\nB. Target Focusing-based Signal Augmentation 1) Beam-forming-based Augmentation: Traditionally, only one RX antenna is used to perceive the sound vibration. Since the receiving antenna is omni-directional, leading to interference from other orientations, we firstly exploit the beam-forming technology to focus on the target orientation. Beam-forming can help to direct the signal and improve the amplitude of the RX signals. According to the layout of the antennas and the rule of beam-forming, we can combine the multiple channels with different coefficient weights. For example, as shown in Fig. 7, the distance between the adjacent RX antennas is d a and the incidence angle of the receiving signal is . Therefore, there is a distance difference d = d a cos during propagation between the adjacent antennas, which will cause a phase difference. Hence, beam-forming can manually reduce the phase difference with the specific coefficient and then combine the signal of multiple channels as:\ns BF (t) = N X i=1 s IF,i (t) exp \u21e3 j d a sin \u21e5 (i 1)\u21e1 \u2318 ,(14)\nwhere N is the number of antennas, i.e., 4 in our system. By applying beam-forming, we can not only focus on the target orientation, but also combine the multiple channels to augment the IF signal efficiently. In practical, we can alter the orientation of RX signals when the speaker vary the relative orientations, which also helps to expand the scope of eavesdropping.\n\n2) CZT-based Augmentation: After focusing on the target orientation based on the beam-forming, we next leverage the Chirp-Z Transform to focus on the accurate range bin related to the distance. Based on the model in Section IV-B, after RX beam-forming, we apply 256-points FFT on each chirp and locate the speaker's range bin based on the peak in the frequency spectrum. Then, we determine the frequency band of CZT, and leverage the CZT to estimate the fine-grained range bin of the speaker. Finally, we can connect the CZT signal of the target rang bin of continuous chirp, which form the vibration signal x(t).\n\n\nC. IQ Calibration-based Vibration Augmentation\n\nAfter extracting the vibration signal x(t), we further augment the signal by calibrating the IQ distortion based on the model in Section IV-C. According to the model, although the vibration signal x(t) should vary along an arc theoretically, the distortion of both the phase and strength can dramatically affect the IQ pattern, leading to large error for sensing. To handle the problem, we propose a segmentation-based fitting method, which leverages the distortion model and divides the arc of IQ signal into two parts for calibration.\n\nFor all the samples of x(t), they are all points in the IQ plane, so we alternatively use the point set P to represent according to the model, we divide the arc points into two parts based on the stationary point P static . The basic deviation idea is that the angle from each point in P to P static is opposite when the points are belong to different parts. Therefore, we firstly move all the points in P to origin O by subtracting P static as: P 0 = P P static . Then, we leverage a clustering method to divide these points based on the idea that two points P 1 , P 2 belong to the same part if \\P 1 OP 2 < as shown in Fig. 8(a). Here, is an angle threshold, which is set to 45 in practice. Finally, we can get two point set P p and P n , representing the positive and negative part, respectively. After getting the two part, we apply the least square method on each part to fit the 2 arcs, which can get the circle center O p and O n as shown in Fig. 8(b). Then the vibration signal related to the sound is extracted as:\n\u2713 vib (t) = ( \\O p OP, P 2 P p \\O n OP, P 2 P n(15)\n\nD. Channel Fusion-based Voice Augmentation\n\nAfter calibrating the IQ signal, the phase sequence \u2713 vib (t) can indicate the vibration of the membrane, especially when the sound is monotone. However, such phase sequence is still insufficient to directly reveal the human voice played by the speaker due to the following reasons: 1) The vibration amplitude of different frequencies are different due to the frequency response pattern of the speaker. Thus, for the same loudness, the amplitude of high frequency sound is much smaller than the low frequency sound. Therefore, the spectrum of vibration extracted based on mmWave is concentrated on the low frequency band. 2) MmWave radar utilizes Voltage Controlled Oscillator to generate FMCW, which brings multiplicative noise distortion in TX signal [42]. As a result, there are always periodic frequency noise in the spectrum.\n\nTo solve the above problem, we propose a channel fusionbased solution to augment the phase sequence. The basic idea is that besides the target bin, the phase sequences of other nearby bins also contain the information of sound vibration according to our study. Because the vibration information of different bins are all generated by the same sound source, we can fuse multiple channels together to augment the vibration of the same source and mitigate the other noise.\n\nTo fuse the multiple channels and augment the vibration signal, we propose to leverage an encoder-decoder based  After that, we use the last convolution layer to generate the output spectrogram, such that the size the same at the input. We use the spectrogram of the voice audio as the groundtruth to train the network, such that the decoder tend to generate the spectrogram similar to the voice audio.\n\n\nVI. PERFORMANCE EVALUATION\n\nA. Experiment setting We implement our system on COTS mmWave radar system, which includes an evaluation module IWR1843BOOST [43] and a real-time capture card DCA1000EVM. We enable 1 transmitter and 4 receiver antennas. The experiment setup is shown in Fig. 10. The speaker is placed on a desk and the mmWave radar is 1m in front of the speaker. The captured data are transmitted to a Lenovo ThinkPad laptop with Intel Core i7 CPU and 16GB memory. The raw data are preprocessed with MATLAB, and the further deep learning algorithm is implemented with Python.\n\nThe playing voice contains the digits 0 \u21e0 9 and letters a \u21e0 z, including male and female voices. We collect the voice signal in a total of 1000 minutes. Among them, 80% are taken as training sets, and the others 20% are testing sets.\n\nB. Metrics 1) Signal-to-noise ratio (SNR) and Peak signal-to-noise ratio (PSNR): SNR can be represented as SN R = 10 log Es E N . PSNR has a good performance in evaluating speech noise  Fig. 11: Spectrogram comparison reduction [44]. Therefore, it is an objective index for speech articulation measurement. PSNR can be defined as:\nP SNR = 10 log 10 \u21e3 V 2 max MSE \u2318 V max = max(max(V en (k)), max(V origin(k) )) MSE = 1 N N X k=1 [V origin (k) V en (k)] 2 ,\nwhere V en is the voice information captured by our system and V origin is the unambiguous primitive audio signal.\n\n2) Recognition accuracy: In order to estimate the ability of voice restoration, we design a recognition network for voice spectrogram based on LeNEet-5 [45]. The network classifies letters and numbers and gets recognition accuracy.\n\nC. Spectrogram recovery mmEavesdropper can recover the mmWave-captured spectrogram with high quality. Our system can recover audio signals of high quality while eavesdropping. Fig. 11 illustrates that the primitive mmWave signals are reconstructed into relatively pure signals by the augmentation network. Compared with the microphone-captured voice, the high-frequency parts of mmWave-captured signals are augmented, and the details of low-frequency parts are enriched after training. Moreover, the noise on the mmWave-captured spectrogram is eliminated. As a result, the reconstructed signals have little noise and are quite similar to the microphone-captured signals. The results intuitively show that mmEavesdropper has the ability to restore the sound spectrogram.\n\nD. Audio reconstruction mmEavesdropper can reconstruct the mmWave-captured voice with the average SNR and PSNR of 4.8dB and 17dB, respectively. As introduced in VI-B, we use SNR and PSNR to evaluate the quality of the reconstructed voice signal based on mmEavesdropper. As shown in Fig. 12, the average SNR of reconstructed voice for all digits and letters is 4.8dB. In general, SNR is always over 3dB. Furthermore, the maximum value of SNR is 8.2dB, i.e., the letter \"e\". The average PSNR reaches 17dB. PSNR is always over 15dB, and the maximum PSNR is 22dB, which appears at the digit \"6\". The results prove that the information components of the voice signal are always more dominant than the noise components, i.e., our system can realize effective human voice eavesdropping. The results of digit recognition are shown in Fig. 13. The average accuracy of digit recognition can reach 95%. The highest recognition accuracy is digit \"5\", and the lowest is \"3\". Fig. 14 shows the results of letter recognition. The average letter recognition accuracy is 93%. Letter \"r\" has the lowest accuracy. It is because the pronunciation characteristics of \"r\" are insufficient. In summary, mmEavesdroppercan reach the average recognition accuracy of 93%, meaning the recovered voice is of high quality and can be distinguished.\n\nF. Distance robustness mmEavesdropper can recover the voice with high quality with 1 \u21e0 3m and achieve the recognition accuracy over 94%. Since the speaker can be at any location in a real scenario, mmEavesdropper is supposed to be able to recover the voice from speakers at different distances. Therefore, we execute the experiments in different ranges to evaluate the diatance robustness. Fig. 15(a) shows the influence of distance on the system's performance. When the radar is 1 \u21e0 3m from the speaker, SNR of the reconstructed voice always exceeds 5dB, and PSNR is always greater than 17dB. Additionally, SNR and PSNR do not get affected as the distance increases. Fig. 15(b) illustrates that recognition accuracy will slightly decline with the distance increasing but will consistently exceed 94%. The experiments prove that mmEavesdropper can work stably within the distance of 1 \u21e0 3m.\n\nG. Volume robustness mmEavesdropper can recover the voice with high quality and achieve the recognition accuracy over 93% as the volume changes from 60dB to 90dB. In practice, the speaker volume can be set to different levels, affecting the eavesdropping effect. To evaluate this impact on our system, we adjust the speakers' volume within the common range of 60dB \u21e0 90dB. As shown in Fig. 15(c), SNR and PSNR are over 5dB and 17dB, respectively. As for recognition accuracy, it is always greater than 93% as shown in Fig 15(d). Furthermore, the results indicate that SNR, PSNR, and accuracy are not affected significantly according to the the volume change. Therefore, mmEavesdropper can work at high performance as the volume changes from 60dB to 90dB.\n\n\nVII. CONCLUSION\n\nThe popularity of virtual online meeting has stimulated the increasing usage of speakers, which brings new threats to human privacy due to different kinds of eavesdropping. This paper proposes mmEavesdropper, the mmWave-based solution to eavesdrop on the speaker by augmenting the micor-vibration signal from three aspects. Particularly, we augment the receiving signal by focusing on the target orientation and distance. Then, we augment the vibration signal by calibration the signal on the IQ plane. Finally, we augment the frequency spectrum by fusing multiple channels. We have evaluated the system via extensive experiments, which show that mmEavesdropper can efficiently eavesdrop on the human voice with 93% accuracy. \n\n\nVIII. ACKNOWLEDGEMENT\n\nFig. 1 :\n1mmEavesdropper can reconstruct the voice with\n\n\nall the RX antennas and propose a fusion method to combine all the valuable vibration information to sense the micro-vibration of the sound.\n\nFig. 3 :\n3Comparison of localization between FFT and CZT\n\nFig. 4 :\n4Principle of vibration perception based on x(t) in the IQ plane. Usually, the received signal of x(t) is a superposition of the vibration signal s membrane from the vibrating membrane and the signal of the other static reflections s static as shown in\n\n\nlicensed use limited to the terms of the applicable license agreement with IEEE. Restrictions apply.\n\nFig. 5 :\n5Amplitude distortion model f = 2KR(t)/c, the underline part in this equation is equal to 1 and Eq. (10) degenerates to Eq. (3)\n\nFig. 6 :\n6Signal patterns in IQ plane and analysis models samples, we can estimate the theoretical signal due to the vibrating membrane, as S theory in\n\nFig. 7 :\n7Beam-forming based signal augmentation\n\nFig. 8 :\n8Arc division and fitting in double circle fitting the vibration samples. Since the distortion may show different patterns according to the sign of vibration distance d(t)\n\nFig. 9 :Fig. 10 :\n910EncoderExperimental setting for eavesdropping neural network to get the final recovered human voice as shown inFig. 9. To better represent the feature of human voice, we conduct STFT on recovered signal, which transfer the timeseries signal into spectrogram, which can efficiently express the features of human voice from both the time and frequency domain. Then we use 4 convolution layers for downsampling in the encoder and 4 deconvolution layers for upsampling in the decoder. Moreover, 3 skip connection layers are utilized to connect convolution layers and the corresponding deconvolution layer, which ensures the integration of both the deep and shallow features in the final output of deconvolution layer.\n\nFig. 15 :\n15E. recognition accuracy mmEavesdropper can reach the totally average recognition accuracy of 93%. In order to visually show the restoration Robustness performance effect of the system, we take the augmented spectrograms as the input and train the recognition network based on LeNet-5.\n\n\nThis work is supported in part by National Key R&D Program of China under Grant No. 2022YFB3303900; National Natural Science Foundation of China under Grant Nos. 61902175, 61872174, 61832008, 62272216; The Key R&D Program of Jiangsu Province under Grant BE2020001-3. This work is partially supported by Collaborative Innovation Center of Novel Software Technology and Industrialization. This work is partially supported by the Fundamental Research Funds for the Central Universities No. 2022300296 (020214380096). Chuyu Wang is the corresponding author.\n\nSpying with your robot vacuum cleaner: eavesdropping via lidar sensors. S Sami, Y Dai, S R X Tan, N Roy, J Han, Proceedings of the 18th Conference on Embedded Networked Sensor Systems. the 18th Conference on Embedded Networked Sensor SystemsS. Sami, Y. Dai, S. R. X. Tan, N. Roy, and J. Han, \"Spying with your robot vacuum cleaner: eavesdropping via lidar sensors,\" in Proceedings of the 18th Conference on Embedded Networked Sensor Systems, 2020, pp. 354-367.\n\nInertiear: Automatic and device-independent imu-based eavesdropping on smartphones. M Gao, Y Liu, Y Chen, Y Li, Z Ba, X Xu, J Han, IEEE INFOCOM 2022-IEEE Conference on Computer Communications. IEEEM. Gao, Y. Liu, Y. Chen, Y. Li, Z. Ba, X. Xu, and J. Han, \"Iner- tiear: Automatic and device-independent imu-based eavesdropping on smartphones,\" in IEEE INFOCOM 2022-IEEE Conference on Computer Communications. IEEE, 2022, pp. 1129-1138.\n\nHard drive of hearing: Disks that eavesdrop with a synthesized microphone. A Kwong, W Xu, K Fu, 2019 IEEE symposium on security and privacy (SP). IEEEA. Kwong, W. Xu, and K. Fu, \"Hard drive of hearing: Disks that eavesdrop with a synthesized microphone,\" in 2019 IEEE symposium on security and privacy (SP). IEEE, 2019, pp. 905-919.\n\nSimple and effective speech enhancement for visual microphone. J Ahn, D Kim, 2017 4th IAPR Asian Conference on Pattern Recognition (ACPR). IEEEJ. Ahn and D. Kim, \"Simple and effective speech enhancement for visual microphone,\" in 2017 4th IAPR Asian Conference on Pattern Recognition (ACPR). IEEE, 2017, pp. 694-699.\n\nThru-the-wall eavesdropping on loudspeakers via rfid by capturing submm level vibration. C Wang, L Xie, Y Lin, W Wang, Y Chen, Y Bu, K Zhang, S Lu, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies5C. Wang, L. Xie, Y. Lin, W. Wang, Y. Chen, Y. Bu, K. Zhang, and S. Lu, \"Thru-the-wall eavesdropping on loudspeakers via rfid by capturing sub- mm level vibration,\" Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, vol. 5, no. 4, pp. 1-25, 2021.\n\nTowards physical-layer vibration sensing with rfids. P Li, Z An, L Yang, P Yang, IEEE INFOCOM 2019-IEEE Conference on Computer Communications. IEEEP. Li, Z. An, L. Yang, and P. Yang, \"Towards physical-layer vibration sensing with rfids,\" in IEEE INFOCOM 2019-IEEE Conference on Computer Communications. IEEE, 2019, pp. 892-900.\n\nMilliear: Millimeter-wave acoustic eavesdropping with unconstrained vocabulary. P Hu, Y Ma, P S Santhalingam, P H Pathak, X Cheng, IEEE INFOCOM 2022-IEEE Conference on Computer Communications. IEEEP. Hu, Y. Ma, P. S. Santhalingam, P. H. Pathak, and X. Cheng, \"Milliear: Millimeter-wave acoustic eavesdropping with unconstrained vocabulary,\" in IEEE INFOCOM 2022-IEEE Conference on Computer Communications. IEEE, 2022, pp. 11-20.\n\nmmphone: Acoustic eavesdropping on loudspeakers via mmwave-characterized piezoelectric effect. C Wang, F Lin, T Liu, Z Liu, Y Shen, Z Ba, L Lu, W Xu, K Ren, IEEE INFOCOM 2022-IEEE Conference on Computer Communications. IEEEC. Wang, F. Lin, T. Liu, Z. Liu, Y. Shen, Z. Ba, L. Lu, W. Xu, and K. Ren, \"mmphone: Acoustic eavesdropping on loudspeakers via mmwave-characterized piezoelectric effect,\" in IEEE INFOCOM 2022- IEEE Conference on Computer Communications. IEEE, 2022, pp. 820- 829.\n\nAudio engineering explained. D Self, RoutledgeD. Self, Audio engineering explained. Routledge, 2012.\n\nGyrophone: Recognizing speech from gyroscope signals. Y Michalevsky, D Boneh, G Nakibly, 23rd USENIX Security Symposium (USENIX Security 14. Y. Michalevsky, D. Boneh, and G. Nakibly, \"Gyrophone: Recognizing speech from gyroscope signals,\" in 23rd USENIX Security Symposium (USENIX Security 14), 2014, pp. 1053-1067.\n\nAccear: Accelerometer acoustic eavesdropping with unconstrained vocabulary. P Hu, H Zhuang, P S Santhalingam, R Spolaor, P Pathak, G Zhang, X Cheng, 2022 IEEE Symposium on Security and Privacy (SP). IEEE Computer SocietyP. Hu, H. Zhuang, P. S. Santhalingam, R. Spolaor, P. Pathak, G. Zhang, and X. Cheng, \"Accear: Accelerometer acoustic eavesdropping with unconstrained vocabulary,\" in 2022 IEEE Symposium on Security and Privacy (SP). IEEE Computer Society, 2022, pp. 1530-1530.\n\nMandipass: Secure and usable user authentication via earphone imu. J Liu, W Song, L Shen, J Han, X Xu, K Ren, 2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS). J. Liu, W. Song, L. Shen, J. Han, X. Xu, and K. Ren, \"Mandipass: Secure and usable user authentication via earphone imu,\" in 2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS).\n\n. IEEE. IEEE, 2021, pp. 674-684.\n\nLaser microphone. R P Muscatell, The Journal of the Acoustical Society of America. 764R. P. Muscatell, \"Laser microphone,\" The Journal of the Acoustical Society of America, vol. 76, no. 4, pp. 1284-1284, 1984.\n\nLaser doppler vibrometry: Development of advanced solutions answering to technology's needs. P Castellini, M Martarelli, E P Tomasini, Mechanical systems and signal processing. 20P. Castellini, M. Martarelli, and E. P. Tomasini, \"Laser doppler vi- brometry: Development of advanced solutions answering to technology's needs,\" Mechanical systems and signal processing, vol. 20, no. 6, pp. 1265-1285, 2006.\n\nTowards flexible wireless charging for medical implants using distributed antenna system. X Fan, L Shangguan, R Howard, Y Zhang, Y Peng, J Xiong, Y Ma, X.-Y. Li, Proceedings of the 26th annual international conference on mobile computing and networking. the 26th annual international conference on mobile computing and networkingX. Fan, L. Shangguan, R. Howard, Y. Zhang, Y. Peng, J. Xiong, Y. Ma, and X.-Y. Li, \"Towards flexible wireless charging for medical implants using distributed antenna system,\" in Proceedings of the 26th annual international conference on mobile computing and networking, 2020, pp. 1-15.\n\nRface: anti-spoofing facial authentication using cots rfid. W Xu, J Liu, S Zhang, Y Zheng, F Lin, J Han, F Xiao, K Ren, IEEE INFOCOM 2021-IEEE Conference on Computer Communications. IEEEW. Xu, J. Liu, S. Zhang, Y. Zheng, F. Lin, J. Han, F. Xiao, and K. Ren, \"Rface: anti-spoofing facial authentication using cots rfid,\" in IEEE INFOCOM 2021-IEEE Conference on Computer Communications. IEEE, 2021, pp. 1-10.\n\nWira: Enabling crosstechnology communication from wifi to lora with ieee 802.11 ax. D Xia, X Zheng, F Yu, L Liu, H Ma, Proceedings of IEEE INFOCOM. IEEE INFOCOMD. Xia, X. Zheng, F. Yu, L. Liu, and H. Ma, \"Wira: Enabling cross- technology communication from wifi to lora with ieee 802.11 ax,\" in Proceedings of IEEE INFOCOM, 2022.\n\nA fingertip profiled rf identifier. C Zhao, Z Li, H Ding, W Xi, T Liu, R Gui, J Han, IEEE Transactions on Mobile Computing. C. Zhao, Z. Li, H. Ding, W. Xi, T. Liu, R. Gui, and J. Han, \"A fingertip profiled rf identifier,\" IEEE Transactions on Mobile Computing, 2020.\n\nContinuous user authentication by contactless wireless sensing. F Wang, Z Li, J Han, IEEE Internet of Things Journal. 65F. Wang, Z. Li, and J. Han, \"Continuous user authentication by contact- less wireless sensing,\" IEEE Internet of Things Journal, vol. 6, no. 5, pp. 8323-8331, 2019.\n\nLoradar: An efficient lora channel occupancy acquirer based on cross-channel scanning. F Yu, X Zheng, L Liu, H Ma, IEEE INFO-COM 2022-IEEE Conference on Computer Communications. IEEEF. Yu, X. Zheng, L. Liu, and H. Ma, \"Loradar: An efficient lora channel occupancy acquirer based on cross-channel scanning,\" in IEEE INFO- COM 2022-IEEE Conference on Computer Communications. IEEE, 2022, pp. 540-549.\n\nOmnitrack: Orientation-aware rfid tracking with centimeter-level accuracy. C Jiang, Y He, X Zheng, Y Liu, IEEE Transactions on Mobile Computing. 202C. Jiang, Y. He, X. Zheng, and Y. Liu, \"Omnitrack: Orientation-aware rfid tracking with centimeter-level accuracy,\" IEEE Transactions on Mobile Computing, vol. 20, no. 2, pp. 634-646, 2019.\n\nVocalprint: A mmwave-based unmediated vocal sensing system for secure authentication. H Li, C Xu, A S Rathore, Z Li, H Zhang, C Song, K Wang, L Su, F Lin, K Ren, IEEE Transactions on Mobile Computing. H. Li, C. Xu, A. S. Rathore, Z. Li, H. Zhang, C. Song, K. Wang, L. Su, F. Lin, K. Ren et al., \"Vocalprint: A mmwave-based unmediated vocal sensing system for secure authentication,\" IEEE Transactions on Mobile Computing, 2021.\n\nmmEcho: A mmWave-based Acoustic Eavesdropping Method. P Hu, W Li, R Spolaor, X Cheng, 2023 IEEE Symposium on Security and Privacy (SP). San Francisco, CA, USAIEEEP. Hu, W. Li, R. Spolaor, and X. Cheng, \"mmEcho: A mmWave-based Acoustic Eavesdropping Method,\" in 2023 IEEE Symposium on Security and Privacy (SP). San Francisco, CA, USA: IEEE, May 2023.\n\nTowards unconstrained vocabulary eavesdropping with mmwave radar using gan. P Hu, W Li, Y Ma, P Santhalingam, P Pathak, H Li, H Zhang, G Zhang, X Cheng, P Mohapatra, IEEE Transactions on Mobile Computing. Early AccessP. Hu, W. Li, Y. Ma, P. Santhalingam, P. Pathak, H. Li, H. Zhang, G. Zhang, X. Cheng, and P. Mohapatra, \"Towards unconstrained vocab- ulary eavesdropping with mmwave radar using gan,\" IEEE Transactions on Mobile Computing, Early Access.\n\nRf-badge: Vital sign-based authentication via rfid tag array on badges. J Ning, L Xie, C Wang, Y Bu, F Xu, D.-W Zhou, S Lu, B Ye, IEEE Transactions on Mobile Computing. J. Ning, L. Xie, C. Wang, Y. Bu, F. Xu, D.-W. Zhou, S. Lu, and B. Ye, \"Rf-badge: Vital sign-based authentication via rfid tag array on badges,\" IEEE Transactions on Mobile Computing, 2021.\n\nRevolving scanning on tagged objects: 3d structure detection of logistics packages via rfid systems. J Ning, L Xie, C Wang, Y Bu, F Xiao, B Ye, S Lu, ACM Transactions on Sensor Networks (TOSN). 182J. Ning, L. Xie, C. Wang, Y. Bu, F. Xiao, B. Ye, and S. Lu, \"Revolving scanning on tagged objects: 3d structure detection of logistics packages via rfid systems,\" ACM Transactions on Sensor Networks (TOSN), vol. 18, no. 2, pp. 1-29, 2022.\n\nAcoustic eavesdropping through wireless vibrometry. T Wei, S Wang, A Zhou, X Zhang, Proceedings of the 21st Annual International Conference on Mobile Computing and Networking. the 21st Annual International Conference on Mobile Computing and NetworkingT. Wei, S. Wang, A. Zhou, and X. Zhang, \"Acoustic eavesdropping through wireless vibrometry,\" in Proceedings of the 21st Annual Inter- national Conference on Mobile Computing and Networking, 2015, pp. 130-141.\n\nRobust spinning sensing with dual-rfid-tags in noisy settings. C Duan, L Yang, Q Lin, Y Liu, L Xie, IEEE Transactions on Mobile Computing. 1811C. Duan, L. Yang, Q. Lin, Y. Liu, and L. Xie, \"Robust spinning sensing with dual-rfid-tags in noisy settings,\" IEEE Transactions on Mobile Computing, vol. 18, no. 11, pp. 2647-2659, 2018.\n\nMaking sense of mechanical vibration period with sub-millisecond accuracy using backscatter signals. L Yang, Y Li, Q Lin, X.-Y. Li, Y Liu, Proceedings of the 22nd Annual International Conference on Mobile Computing and Networking. the 22nd Annual International Conference on Mobile Computing and NetworkingL. Yang, Y. Li, Q. Lin, X.-Y. Li, and Y. Liu, \"Making sense of mechan- ical vibration period with sub-millisecond accuracy using backscatter signals,\" in Proceedings of the 22nd Annual International Conference on Mobile Computing and Networking, 2016, pp. 16-28.\n\nWaveear: Exploring a mmwave-based noise-resistant speech sensing for voice-user interface. C Xu, Z Li, H Zhang, A S Rathore, H Li, C Song, K Wang, W Xu, Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services. the 17th Annual International Conference on Mobile Systems, Applications, and ServicesC. Xu, Z. Li, H. Zhang, A. S. Rathore, H. Li, C. Song, K. Wang, and W. Xu, \"Waveear: Exploring a mmwave-based noise-resistant speech sensing for voice-user interface,\" in Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services, 2019, pp. 14-26.\n\nWavoice: A noise-resistant multi-modal speech recognition system fusing mmwave and audio signals. T Liu, M Gao, F Lin, C Wang, Z Ba, J Han, W Xu, K Ren, Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems. the 19th ACM Conference on Embedded Networked Sensor SystemsT. Liu, M. Gao, F. Lin, C. Wang, Z. Ba, J. Han, W. Xu, and K. Ren, \"Wavoice: A noise-resistant multi-modal speech recognition system fusing mmwave and audio signals,\" in Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems, 2021, pp. 97-110.\n\nSecure mmwave-radar-based speaker verification for iot smart home. Y Dong, Y.-D Yao, IEEE Internet of Things Journal. 85Y. Dong and Y.-D. Yao, \"Secure mmwave-radar-based speaker verifica- tion for iot smart home,\" IEEE Internet of Things Journal, vol. 8, no. 5, pp. 3500-3511, 2020.\n\nmmvib: micrometerlevel vibration measurement with mmwave radar. C Jiang, J Guo, Y He, M Jin, S Li, Y Liu, Proceedings of the 26th Annual International Conference on Mobile Computing and Networking. the 26th Annual International Conference on Mobile Computing and NetworkingC. Jiang, J. Guo, Y. He, M. Jin, S. Li, and Y. Liu, \"mmvib: micrometer- level vibration measurement with mmwave radar,\" in Proceedings of the 26th Annual International Conference on Mobile Computing and Networking, 2020, pp. 1-13.\n\nIntroduction to mmwave radar sensing: Fmcw radars. C Lovescu, S Rao, C. Lovescu and S. Rao, \"Introduction to mmwave radar sensing: Fmcw radars,\" https://training.ti.com/node/1139153, 2017.\n\nVibration parameter estimation using fmcw radar. L Ding, M Ali, S Patole, A Dabak, 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEEL. Ding, M. Ali, S. Patole, and A. Dabak, \"Vibration parameter estimation using fmcw radar,\" in 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2016, pp. 2224-2228.\n\nA short course in mathematical methods with Maple. H Aratyn, C Rasinariu, World Scientific Publishing CompanyH. Aratyn and C. Rasinariu, A short course in mathematical methods with Maple. World Scientific Publishing Company, 2005.\n\nCommunication in the presence of noise. C E Shannon, Proceedings of the IRE. 371C. E. Shannon, \"Communication in the presence of noise,\" Proceedings of the IRE, vol. 37, no. 1, pp. 10-21, 1949.\n\nA V Oppenheim, A S Willsky, S H Nawab, G M Hern\u00e1ndez, Signals & systems. Pearson Educaci\u00f3n. A. V. Oppenheim, A. S. Willsky, S. H. Nawab, G. M. Hern\u00e1ndez et al., Signals & systems. Pearson Educaci\u00f3n, 1997.\n\nThe role of millimeter-waves in the distance measurement accuracy of an fmcw radar sensor. A Bhutani, S Marahrens, M Gehringer, B G\u00f6ttel, M Pauli, T Zwick, Sensors. 19183938A. Bhutani, S. Marahrens, M. Gehringer, B. G\u00f6ttel, M. Pauli, and T. Zwick, \"The role of millimeter-waves in the distance measurement accuracy of an fmcw radar sensor,\" Sensors, vol. 19, no. 18, p. 3938, 2019.\n\nCommunication Systems,2E. McGraw-Hill Education (India) Pvt Limited. R Singh, S Sapre, R. Singh and S. Sapre, Communication Systems,2E. McGraw- Hill Education (India) Pvt Limited, 2008. [Online]. Available: https://books.google.com/books?id=WkOPPEhK7SYC\n\nA V Oppenheim, J R Buck, R W Schafer, Discrete-time signal processing. Saddle River, NJPrentice Hall2A. V. Oppenheim, J. R. Buck, and R. W. Schafer, Discrete-time signal processing. Vol. 2. Upper Saddle River, NJ: Prentice Hall, 2001.\n\nPhase noise analysis of component cascades. K V Puglia, IEEE Microwave Magazine. 34K. V. Puglia, \"Phase noise analysis of component cascades,\" IEEE Microwave Magazine, vol. 3, no. 4, pp. 71-75, 2002.\n\nIwr1843 single-chip 76-ghz to 81-ghz industrial radar sensor evaluation module. T Instruments, T. Instruments, \"Iwr1843 single-chip 76-ghz to 81-ghz industrial radar sensor evaluation module,\" https://www.ti.com/tool/IWR1843BOOST.\n\nThe signal-to-noise ratio for speech intelligibility-an auditorium acoustics design index. H G Latham, Applied Acoustics. 124H. G. Latham, \"The signal-to-noise ratio for speech intelligibility-an auditorium acoustics design index,\" Applied Acoustics, vol. 12, no. 4, pp. 253-320, 1979.\n\nLenet-5, convolutional neural networks. Y Lecun, 2014Y. LeCun et al., \"Lenet-5, convolutional neural networks,\" URL: http://yann. lecun. com/exdb/lenet, vol. 20, no. 5, p. 14, 2015.\n", "annotations": {"author": "[{\"end\":177,\"start\":89},{\"end\":265,\"start\":178},{\"end\":354,\"start\":266},{\"end\":456,\"start\":355},{\"end\":546,\"start\":457},{\"end\":636,\"start\":547}]", "publisher": null, "author_last_name": "[{\"end\":99,\"start\":95},{\"end\":187,\"start\":182},{\"end\":276,\"start\":272},{\"end\":362,\"start\":359},{\"end\":468,\"start\":464},{\"end\":558,\"start\":554}]", "author_first_name": "[{\"end\":94,\"start\":89},{\"end\":181,\"start\":178},{\"end\":271,\"start\":266},{\"end\":358,\"start\":355},{\"end\":463,\"start\":457},{\"end\":553,\"start\":547}]", "author_affiliation": "[{\"end\":176,\"start\":101},{\"end\":264,\"start\":189},{\"end\":353,\"start\":278},{\"end\":455,\"start\":380},{\"end\":545,\"start\":470},{\"end\":635,\"start\":560}]", "title": "[{\"end\":86,\"start\":1},{\"end\":722,\"start\":637}]", "venue": null, "abstract": "[{\"end\":2139,\"start\":825}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3669,\"start\":3666},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3674,\"start\":3671},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3861,\"start\":3858},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4153,\"start\":4150},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4157,\"start\":4154},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4172,\"start\":4169},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4335,\"start\":4332},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4351,\"start\":4348},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8338,\"start\":8335},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10502,\"start\":10498},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10522,\"start\":10518},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":10562,\"start\":10559},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10567,\"start\":10563},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10680,\"start\":10677},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11143,\"start\":11140},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11230,\"start\":11226},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11235,\"start\":11231},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":11265,\"start\":11262},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11824,\"start\":11820},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11830,\"start\":11826},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":12084,\"start\":12080},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":12280,\"start\":12276},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12285,\"start\":12281},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":12300,\"start\":12297},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12592,\"start\":12588},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":12675,\"start\":12671},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13414,\"start\":13411},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13418,\"start\":13415},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":16953,\"start\":16949},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":16958,\"start\":16954},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":18759,\"start\":18755},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":19035,\"start\":19031},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":19269,\"start\":19265},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":19308,\"start\":19304},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":20805,\"start\":20801},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":20893,\"start\":20889},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":21638,\"start\":21634},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":25008,\"start\":25004},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":25115,\"start\":25111},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":34043,\"start\":34039},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":35150,\"start\":35146},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":36048,\"start\":36044},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":36545,\"start\":36541}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":41185,\"start\":41129},{\"attributes\":{\"id\":\"fig_1\"},\"end\":41328,\"start\":41186},{\"attributes\":{\"id\":\"fig_2\"},\"end\":41386,\"start\":41329},{\"attributes\":{\"id\":\"fig_3\"},\"end\":41649,\"start\":41387},{\"attributes\":{\"id\":\"fig_4\"},\"end\":41752,\"start\":41650},{\"attributes\":{\"id\":\"fig_5\"},\"end\":41890,\"start\":41753},{\"attributes\":{\"id\":\"fig_6\"},\"end\":42043,\"start\":41891},{\"attributes\":{\"id\":\"fig_7\"},\"end\":42093,\"start\":42044},{\"attributes\":{\"id\":\"fig_8\"},\"end\":42275,\"start\":42094},{\"attributes\":{\"id\":\"fig_9\"},\"end\":43011,\"start\":42276},{\"attributes\":{\"id\":\"fig_10\"},\"end\":43309,\"start\":43012},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":43865,\"start\":43310}]", "paragraph": "[{\"end\":3222,\"start\":2158},{\"end\":4576,\"start\":3224},{\"end\":5869,\"start\":4578},{\"end\":6956,\"start\":5871},{\"end\":8050,\"start\":6958},{\"end\":9261,\"start\":8052},{\"end\":10223,\"start\":9263},{\"end\":10872,\"start\":10244},{\"end\":11736,\"start\":10874},{\"end\":12775,\"start\":11738},{\"end\":13065,\"start\":12777},{\"end\":13606,\"start\":13090},{\"end\":13853,\"start\":13608},{\"end\":14561,\"start\":13855},{\"end\":15285,\"start\":14563},{\"end\":15509,\"start\":15334},{\"end\":16298,\"start\":15511},{\"end\":16634,\"start\":16300},{\"end\":16773,\"start\":16658},{\"end\":17419,\"start\":16775},{\"end\":17588,\"start\":17454},{\"end\":17953,\"start\":17590},{\"end\":18270,\"start\":17997},{\"end\":18765,\"start\":18307},{\"end\":19036,\"start\":18839},{\"end\":19713,\"start\":19125},{\"end\":20112,\"start\":19786},{\"end\":20400,\"start\":20146},{\"end\":20894,\"start\":20440},{\"end\":21322,\"start\":20938},{\"end\":21576,\"start\":21375},{\"end\":21834,\"start\":21578},{\"end\":22401,\"start\":21932},{\"end\":22580,\"start\":22403},{\"end\":22957,\"start\":22616},{\"end\":23308,\"start\":22998},{\"end\":24128,\"start\":23343},{\"end\":24353,\"start\":24153},{\"end\":24614,\"start\":24355},{\"end\":25140,\"start\":24768},{\"end\":25648,\"start\":25201},{\"end\":26016,\"start\":25717},{\"end\":26256,\"start\":26039},{\"end\":26480,\"start\":26258},{\"end\":27136,\"start\":26530},{\"end\":28360,\"start\":27174},{\"end\":29533,\"start\":28402},{\"end\":30527,\"start\":29535},{\"end\":30961,\"start\":30591},{\"end\":31576,\"start\":30963},{\"end\":32163,\"start\":31627},{\"end\":33188,\"start\":32165},{\"end\":34116,\"start\":33286},{\"end\":34587,\"start\":34118},{\"end\":34991,\"start\":34589},{\"end\":35579,\"start\":35022},{\"end\":35814,\"start\":35581},{\"end\":36146,\"start\":35816},{\"end\":36387,\"start\":36273},{\"end\":36620,\"start\":36389},{\"end\":37391,\"start\":36622},{\"end\":38710,\"start\":37393},{\"end\":39602,\"start\":38712},{\"end\":40358,\"start\":39604},{\"end\":41104,\"start\":40378}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":18838,\"start\":18766},{\"attributes\":{\"id\":\"formula_1\"},\"end\":19124,\"start\":19037},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19785,\"start\":19714},{\"attributes\":{\"id\":\"formula_3\"},\"end\":20145,\"start\":20113},{\"attributes\":{\"id\":\"formula_4\"},\"end\":20937,\"start\":20895},{\"attributes\":{\"id\":\"formula_5\"},\"end\":21374,\"start\":21323},{\"attributes\":{\"id\":\"formula_6\"},\"end\":21931,\"start\":21835},{\"attributes\":{\"id\":\"formula_7\"},\"end\":22615,\"start\":22581},{\"attributes\":{\"id\":\"formula_8\"},\"end\":23342,\"start\":23309},{\"attributes\":{\"id\":\"formula_9\"},\"end\":24767,\"start\":24615},{\"attributes\":{\"id\":\"formula_10\"},\"end\":25200,\"start\":25141},{\"attributes\":{\"id\":\"formula_11\"},\"end\":25716,\"start\":25649},{\"attributes\":{\"id\":\"formula_12\"},\"end\":26038,\"start\":26017},{\"attributes\":{\"id\":\"formula_13\"},\"end\":26529,\"start\":26481},{\"attributes\":{\"id\":\"formula_14\"},\"end\":30590,\"start\":30528},{\"attributes\":{\"id\":\"formula_15\"},\"end\":33240,\"start\":33189},{\"attributes\":{\"id\":\"formula_16\"},\"end\":36272,\"start\":36147}]", "table_ref": null, "section_header": "[{\"end\":2156,\"start\":2141},{\"end\":10242,\"start\":10226},{\"end\":13088,\"start\":13068},{\"end\":15332,\"start\":15288},{\"end\":16656,\"start\":16637},{\"end\":17452,\"start\":17422},{\"end\":17995,\"start\":17956},{\"end\":18305,\"start\":18273},{\"end\":20438,\"start\":20403},{\"end\":22996,\"start\":22960},{\"end\":24151,\"start\":24131},{\"end\":27172,\"start\":27139},{\"end\":28379,\"start\":28363},{\"end\":28400,\"start\":28382},{\"end\":31625,\"start\":31579},{\"end\":33284,\"start\":33242},{\"end\":35020,\"start\":34994},{\"end\":40376,\"start\":40361},{\"end\":41128,\"start\":41107},{\"end\":41138,\"start\":41130},{\"end\":41338,\"start\":41330},{\"end\":41396,\"start\":41388},{\"end\":41762,\"start\":41754},{\"end\":41900,\"start\":41892},{\"end\":42053,\"start\":42045},{\"end\":42103,\"start\":42095},{\"end\":42294,\"start\":42277},{\"end\":43022,\"start\":43013}]", "table": null, "figure_caption": "[{\"end\":41185,\"start\":41140},{\"end\":41328,\"start\":41188},{\"end\":41386,\"start\":41340},{\"end\":41649,\"start\":41398},{\"end\":41752,\"start\":41652},{\"end\":41890,\"start\":41764},{\"end\":42043,\"start\":41902},{\"end\":42093,\"start\":42055},{\"end\":42275,\"start\":42105},{\"end\":43011,\"start\":42298},{\"end\":43309,\"start\":43025},{\"end\":43865,\"start\":43312}]", "figure_ref": "[{\"end\":13256,\"start\":13250},{\"end\":14229,\"start\":14223},{\"end\":14243,\"start\":14237},{\"end\":14692,\"start\":14686},{\"end\":14841,\"start\":14835},{\"end\":17169,\"start\":17160},{\"end\":17801,\"start\":17795},{\"end\":17818,\"start\":17809},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22770,\"start\":22764},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23307,\"start\":23298},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23471,\"start\":23462},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":26766,\"start\":26760},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":26916,\"start\":26910},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":26944,\"start\":26935},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":27340,\"start\":27334},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":27558,\"start\":27552},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":27690,\"start\":27684},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":30135,\"start\":30129},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":32795,\"start\":32786},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":33123,\"start\":33114},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35281,\"start\":35274},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36009,\"start\":36002},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36805,\"start\":36798},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":37682,\"start\":37675},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":38226,\"start\":38219},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":38362,\"start\":38355},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39112,\"start\":39102},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39387,\"start\":39380},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39999,\"start\":39989},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":40131,\"start\":40122}]", "bib_author_first_name": "[{\"end\":43940,\"start\":43939},{\"end\":43948,\"start\":43947},{\"end\":43955,\"start\":43954},{\"end\":43959,\"start\":43956},{\"end\":43966,\"start\":43965},{\"end\":43973,\"start\":43972},{\"end\":44414,\"start\":44413},{\"end\":44421,\"start\":44420},{\"end\":44428,\"start\":44427},{\"end\":44436,\"start\":44435},{\"end\":44442,\"start\":44441},{\"end\":44448,\"start\":44447},{\"end\":44454,\"start\":44453},{\"end\":44841,\"start\":44840},{\"end\":44850,\"start\":44849},{\"end\":44856,\"start\":44855},{\"end\":45163,\"start\":45162},{\"end\":45170,\"start\":45169},{\"end\":45507,\"start\":45506},{\"end\":45515,\"start\":45514},{\"end\":45522,\"start\":45521},{\"end\":45529,\"start\":45528},{\"end\":45537,\"start\":45536},{\"end\":45545,\"start\":45544},{\"end\":45551,\"start\":45550},{\"end\":45560,\"start\":45559},{\"end\":46054,\"start\":46053},{\"end\":46060,\"start\":46059},{\"end\":46066,\"start\":46065},{\"end\":46074,\"start\":46073},{\"end\":46410,\"start\":46409},{\"end\":46416,\"start\":46415},{\"end\":46422,\"start\":46421},{\"end\":46424,\"start\":46423},{\"end\":46440,\"start\":46439},{\"end\":46442,\"start\":46441},{\"end\":46452,\"start\":46451},{\"end\":46855,\"start\":46854},{\"end\":46863,\"start\":46862},{\"end\":46870,\"start\":46869},{\"end\":46877,\"start\":46876},{\"end\":46884,\"start\":46883},{\"end\":46892,\"start\":46891},{\"end\":46898,\"start\":46897},{\"end\":46904,\"start\":46903},{\"end\":46910,\"start\":46909},{\"end\":47277,\"start\":47276},{\"end\":47404,\"start\":47403},{\"end\":47419,\"start\":47418},{\"end\":47428,\"start\":47427},{\"end\":47743,\"start\":47742},{\"end\":47749,\"start\":47748},{\"end\":47759,\"start\":47758},{\"end\":47761,\"start\":47760},{\"end\":47777,\"start\":47776},{\"end\":47788,\"start\":47787},{\"end\":47798,\"start\":47797},{\"end\":47807,\"start\":47806},{\"end\":48215,\"start\":48214},{\"end\":48222,\"start\":48221},{\"end\":48230,\"start\":48229},{\"end\":48238,\"start\":48237},{\"end\":48245,\"start\":48244},{\"end\":48251,\"start\":48250},{\"end\":48600,\"start\":48599},{\"end\":48602,\"start\":48601},{\"end\":48886,\"start\":48885},{\"end\":48900,\"start\":48899},{\"end\":48914,\"start\":48913},{\"end\":48916,\"start\":48915},{\"end\":49289,\"start\":49288},{\"end\":49296,\"start\":49295},{\"end\":49309,\"start\":49308},{\"end\":49319,\"start\":49318},{\"end\":49328,\"start\":49327},{\"end\":49336,\"start\":49335},{\"end\":49345,\"start\":49344},{\"end\":49355,\"start\":49350},{\"end\":49875,\"start\":49874},{\"end\":49881,\"start\":49880},{\"end\":49888,\"start\":49887},{\"end\":49897,\"start\":49896},{\"end\":49906,\"start\":49905},{\"end\":49913,\"start\":49912},{\"end\":49920,\"start\":49919},{\"end\":49928,\"start\":49927},{\"end\":50307,\"start\":50306},{\"end\":50314,\"start\":50313},{\"end\":50323,\"start\":50322},{\"end\":50329,\"start\":50328},{\"end\":50336,\"start\":50335},{\"end\":50590,\"start\":50589},{\"end\":50598,\"start\":50597},{\"end\":50604,\"start\":50603},{\"end\":50612,\"start\":50611},{\"end\":50618,\"start\":50617},{\"end\":50625,\"start\":50624},{\"end\":50632,\"start\":50631},{\"end\":50886,\"start\":50885},{\"end\":50894,\"start\":50893},{\"end\":50900,\"start\":50899},{\"end\":51195,\"start\":51194},{\"end\":51201,\"start\":51200},{\"end\":51210,\"start\":51209},{\"end\":51217,\"start\":51216},{\"end\":51583,\"start\":51582},{\"end\":51592,\"start\":51591},{\"end\":51598,\"start\":51597},{\"end\":51607,\"start\":51606},{\"end\":51933,\"start\":51932},{\"end\":51939,\"start\":51938},{\"end\":51945,\"start\":51944},{\"end\":51947,\"start\":51946},{\"end\":51958,\"start\":51957},{\"end\":51964,\"start\":51963},{\"end\":51973,\"start\":51972},{\"end\":51981,\"start\":51980},{\"end\":51989,\"start\":51988},{\"end\":51995,\"start\":51994},{\"end\":52002,\"start\":52001},{\"end\":52330,\"start\":52329},{\"end\":52336,\"start\":52335},{\"end\":52342,\"start\":52341},{\"end\":52353,\"start\":52352},{\"end\":52704,\"start\":52703},{\"end\":52710,\"start\":52709},{\"end\":52716,\"start\":52715},{\"end\":52722,\"start\":52721},{\"end\":52738,\"start\":52737},{\"end\":52748,\"start\":52747},{\"end\":52754,\"start\":52753},{\"end\":52763,\"start\":52762},{\"end\":52772,\"start\":52771},{\"end\":52781,\"start\":52780},{\"end\":53155,\"start\":53154},{\"end\":53163,\"start\":53162},{\"end\":53170,\"start\":53169},{\"end\":53178,\"start\":53177},{\"end\":53184,\"start\":53183},{\"end\":53193,\"start\":53189},{\"end\":53201,\"start\":53200},{\"end\":53207,\"start\":53206},{\"end\":53543,\"start\":53542},{\"end\":53551,\"start\":53550},{\"end\":53558,\"start\":53557},{\"end\":53566,\"start\":53565},{\"end\":53572,\"start\":53571},{\"end\":53580,\"start\":53579},{\"end\":53586,\"start\":53585},{\"end\":53931,\"start\":53930},{\"end\":53938,\"start\":53937},{\"end\":53946,\"start\":53945},{\"end\":53954,\"start\":53953},{\"end\":54404,\"start\":54403},{\"end\":54412,\"start\":54411},{\"end\":54420,\"start\":54419},{\"end\":54427,\"start\":54426},{\"end\":54434,\"start\":54433},{\"end\":54774,\"start\":54773},{\"end\":54782,\"start\":54781},{\"end\":54788,\"start\":54787},{\"end\":54799,\"start\":54794},{\"end\":54805,\"start\":54804},{\"end\":55334,\"start\":55333},{\"end\":55340,\"start\":55339},{\"end\":55346,\"start\":55345},{\"end\":55355,\"start\":55354},{\"end\":55357,\"start\":55356},{\"end\":55368,\"start\":55367},{\"end\":55374,\"start\":55373},{\"end\":55382,\"start\":55381},{\"end\":55390,\"start\":55389},{\"end\":55975,\"start\":55974},{\"end\":55982,\"start\":55981},{\"end\":55989,\"start\":55988},{\"end\":55996,\"start\":55995},{\"end\":56004,\"start\":56003},{\"end\":56010,\"start\":56009},{\"end\":56017,\"start\":56016},{\"end\":56023,\"start\":56022},{\"end\":56500,\"start\":56499},{\"end\":56511,\"start\":56507},{\"end\":56781,\"start\":56780},{\"end\":56790,\"start\":56789},{\"end\":56797,\"start\":56796},{\"end\":56803,\"start\":56802},{\"end\":56810,\"start\":56809},{\"end\":56816,\"start\":56815},{\"end\":57273,\"start\":57272},{\"end\":57284,\"start\":57283},{\"end\":57461,\"start\":57460},{\"end\":57469,\"start\":57468},{\"end\":57476,\"start\":57475},{\"end\":57486,\"start\":57485},{\"end\":57850,\"start\":57849},{\"end\":57860,\"start\":57859},{\"end\":58071,\"start\":58070},{\"end\":58073,\"start\":58072},{\"end\":58226,\"start\":58225},{\"end\":58228,\"start\":58227},{\"end\":58241,\"start\":58240},{\"end\":58243,\"start\":58242},{\"end\":58254,\"start\":58253},{\"end\":58256,\"start\":58255},{\"end\":58265,\"start\":58264},{\"end\":58267,\"start\":58266},{\"end\":58523,\"start\":58522},{\"end\":58534,\"start\":58533},{\"end\":58547,\"start\":58546},{\"end\":58560,\"start\":58559},{\"end\":58570,\"start\":58569},{\"end\":58579,\"start\":58578},{\"end\":58884,\"start\":58883},{\"end\":58893,\"start\":58892},{\"end\":59070,\"start\":59069},{\"end\":59072,\"start\":59071},{\"end\":59085,\"start\":59084},{\"end\":59087,\"start\":59086},{\"end\":59095,\"start\":59094},{\"end\":59097,\"start\":59096},{\"end\":59350,\"start\":59349},{\"end\":59352,\"start\":59351},{\"end\":59587,\"start\":59586},{\"end\":59830,\"start\":59829},{\"end\":59832,\"start\":59831},{\"end\":60066,\"start\":60065}]", "bib_author_last_name": "[{\"end\":43945,\"start\":43941},{\"end\":43952,\"start\":43949},{\"end\":43963,\"start\":43960},{\"end\":43970,\"start\":43967},{\"end\":43977,\"start\":43974},{\"end\":44418,\"start\":44415},{\"end\":44425,\"start\":44422},{\"end\":44433,\"start\":44429},{\"end\":44439,\"start\":44437},{\"end\":44445,\"start\":44443},{\"end\":44451,\"start\":44449},{\"end\":44458,\"start\":44455},{\"end\":44847,\"start\":44842},{\"end\":44853,\"start\":44851},{\"end\":44859,\"start\":44857},{\"end\":45167,\"start\":45164},{\"end\":45174,\"start\":45171},{\"end\":45512,\"start\":45508},{\"end\":45519,\"start\":45516},{\"end\":45526,\"start\":45523},{\"end\":45534,\"start\":45530},{\"end\":45542,\"start\":45538},{\"end\":45548,\"start\":45546},{\"end\":45557,\"start\":45552},{\"end\":45563,\"start\":45561},{\"end\":46057,\"start\":46055},{\"end\":46063,\"start\":46061},{\"end\":46071,\"start\":46067},{\"end\":46079,\"start\":46075},{\"end\":46413,\"start\":46411},{\"end\":46419,\"start\":46417},{\"end\":46437,\"start\":46425},{\"end\":46449,\"start\":46443},{\"end\":46458,\"start\":46453},{\"end\":46860,\"start\":46856},{\"end\":46867,\"start\":46864},{\"end\":46874,\"start\":46871},{\"end\":46881,\"start\":46878},{\"end\":46889,\"start\":46885},{\"end\":46895,\"start\":46893},{\"end\":46901,\"start\":46899},{\"end\":46907,\"start\":46905},{\"end\":46914,\"start\":46911},{\"end\":47282,\"start\":47278},{\"end\":47416,\"start\":47405},{\"end\":47425,\"start\":47420},{\"end\":47436,\"start\":47429},{\"end\":47746,\"start\":47744},{\"end\":47756,\"start\":47750},{\"end\":47774,\"start\":47762},{\"end\":47785,\"start\":47778},{\"end\":47795,\"start\":47789},{\"end\":47804,\"start\":47799},{\"end\":47813,\"start\":47808},{\"end\":48219,\"start\":48216},{\"end\":48227,\"start\":48223},{\"end\":48235,\"start\":48231},{\"end\":48242,\"start\":48239},{\"end\":48248,\"start\":48246},{\"end\":48255,\"start\":48252},{\"end\":48612,\"start\":48603},{\"end\":48897,\"start\":48887},{\"end\":48911,\"start\":48901},{\"end\":48925,\"start\":48917},{\"end\":49293,\"start\":49290},{\"end\":49306,\"start\":49297},{\"end\":49316,\"start\":49310},{\"end\":49325,\"start\":49320},{\"end\":49333,\"start\":49329},{\"end\":49342,\"start\":49337},{\"end\":49348,\"start\":49346},{\"end\":49358,\"start\":49356},{\"end\":49878,\"start\":49876},{\"end\":49885,\"start\":49882},{\"end\":49894,\"start\":49889},{\"end\":49903,\"start\":49898},{\"end\":49910,\"start\":49907},{\"end\":49917,\"start\":49914},{\"end\":49925,\"start\":49921},{\"end\":49932,\"start\":49929},{\"end\":50311,\"start\":50308},{\"end\":50320,\"start\":50315},{\"end\":50326,\"start\":50324},{\"end\":50333,\"start\":50330},{\"end\":50339,\"start\":50337},{\"end\":50595,\"start\":50591},{\"end\":50601,\"start\":50599},{\"end\":50609,\"start\":50605},{\"end\":50615,\"start\":50613},{\"end\":50622,\"start\":50619},{\"end\":50629,\"start\":50626},{\"end\":50636,\"start\":50633},{\"end\":50891,\"start\":50887},{\"end\":50897,\"start\":50895},{\"end\":50904,\"start\":50901},{\"end\":51198,\"start\":51196},{\"end\":51207,\"start\":51202},{\"end\":51214,\"start\":51211},{\"end\":51220,\"start\":51218},{\"end\":51589,\"start\":51584},{\"end\":51595,\"start\":51593},{\"end\":51604,\"start\":51599},{\"end\":51611,\"start\":51608},{\"end\":51936,\"start\":51934},{\"end\":51942,\"start\":51940},{\"end\":51955,\"start\":51948},{\"end\":51961,\"start\":51959},{\"end\":51970,\"start\":51965},{\"end\":51978,\"start\":51974},{\"end\":51986,\"start\":51982},{\"end\":51992,\"start\":51990},{\"end\":51999,\"start\":51996},{\"end\":52006,\"start\":52003},{\"end\":52333,\"start\":52331},{\"end\":52339,\"start\":52337},{\"end\":52350,\"start\":52343},{\"end\":52359,\"start\":52354},{\"end\":52707,\"start\":52705},{\"end\":52713,\"start\":52711},{\"end\":52719,\"start\":52717},{\"end\":52735,\"start\":52723},{\"end\":52745,\"start\":52739},{\"end\":52751,\"start\":52749},{\"end\":52760,\"start\":52755},{\"end\":52769,\"start\":52764},{\"end\":52778,\"start\":52773},{\"end\":52791,\"start\":52782},{\"end\":53160,\"start\":53156},{\"end\":53167,\"start\":53164},{\"end\":53175,\"start\":53171},{\"end\":53181,\"start\":53179},{\"end\":53187,\"start\":53185},{\"end\":53198,\"start\":53194},{\"end\":53204,\"start\":53202},{\"end\":53210,\"start\":53208},{\"end\":53548,\"start\":53544},{\"end\":53555,\"start\":53552},{\"end\":53563,\"start\":53559},{\"end\":53569,\"start\":53567},{\"end\":53577,\"start\":53573},{\"end\":53583,\"start\":53581},{\"end\":53589,\"start\":53587},{\"end\":53935,\"start\":53932},{\"end\":53943,\"start\":53939},{\"end\":53951,\"start\":53947},{\"end\":53960,\"start\":53955},{\"end\":54409,\"start\":54405},{\"end\":54417,\"start\":54413},{\"end\":54424,\"start\":54421},{\"end\":54431,\"start\":54428},{\"end\":54438,\"start\":54435},{\"end\":54779,\"start\":54775},{\"end\":54785,\"start\":54783},{\"end\":54792,\"start\":54789},{\"end\":54802,\"start\":54800},{\"end\":54809,\"start\":54806},{\"end\":55337,\"start\":55335},{\"end\":55343,\"start\":55341},{\"end\":55352,\"start\":55347},{\"end\":55365,\"start\":55358},{\"end\":55371,\"start\":55369},{\"end\":55379,\"start\":55375},{\"end\":55387,\"start\":55383},{\"end\":55393,\"start\":55391},{\"end\":55979,\"start\":55976},{\"end\":55986,\"start\":55983},{\"end\":55993,\"start\":55990},{\"end\":56001,\"start\":55997},{\"end\":56007,\"start\":56005},{\"end\":56014,\"start\":56011},{\"end\":56020,\"start\":56018},{\"end\":56027,\"start\":56024},{\"end\":56505,\"start\":56501},{\"end\":56515,\"start\":56512},{\"end\":56787,\"start\":56782},{\"end\":56794,\"start\":56791},{\"end\":56800,\"start\":56798},{\"end\":56807,\"start\":56804},{\"end\":56813,\"start\":56811},{\"end\":56820,\"start\":56817},{\"end\":57281,\"start\":57274},{\"end\":57288,\"start\":57285},{\"end\":57466,\"start\":57462},{\"end\":57473,\"start\":57470},{\"end\":57483,\"start\":57477},{\"end\":57492,\"start\":57487},{\"end\":57857,\"start\":57851},{\"end\":57870,\"start\":57861},{\"end\":58081,\"start\":58074},{\"end\":58238,\"start\":58229},{\"end\":58251,\"start\":58244},{\"end\":58262,\"start\":58257},{\"end\":58277,\"start\":58268},{\"end\":58531,\"start\":58524},{\"end\":58544,\"start\":58535},{\"end\":58557,\"start\":58548},{\"end\":58567,\"start\":58561},{\"end\":58576,\"start\":58571},{\"end\":58585,\"start\":58580},{\"end\":58890,\"start\":58885},{\"end\":58899,\"start\":58894},{\"end\":59082,\"start\":59073},{\"end\":59092,\"start\":59088},{\"end\":59105,\"start\":59098},{\"end\":59359,\"start\":59353},{\"end\":59599,\"start\":59588},{\"end\":59839,\"start\":59833},{\"end\":60072,\"start\":60067}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":227154660},\"end\":44327,\"start\":43867},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":249905867},\"end\":44763,\"start\":44329},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":132878678},\"end\":45097,\"start\":44765},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":57201277},\"end\":45415,\"start\":45099},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":243760215},\"end\":45998,\"start\":45417},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":139350110},\"end\":46327,\"start\":46000},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":245019338},\"end\":46757,\"start\":46329},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":249901105},\"end\":47245,\"start\":46759},{\"attributes\":{\"id\":\"b8\"},\"end\":47347,\"start\":47247},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":942903},\"end\":47664,\"start\":47349},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":250164367},\"end\":48145,\"start\":47666},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":238416185},\"end\":48545,\"start\":48147},{\"attributes\":{\"id\":\"b12\"},\"end\":48579,\"start\":48547},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":106403756},\"end\":48790,\"start\":48581},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":108829016},\"end\":49196,\"start\":48792},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":210839713},\"end\":49812,\"start\":49198},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":236481463},\"end\":50220,\"start\":49814},{\"attributes\":{\"id\":\"b17\"},\"end\":50551,\"start\":50222},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":225427681},\"end\":50819,\"start\":50553},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":54445579},\"end\":51105,\"start\":50821},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":249904219},\"end\":51505,\"start\":51107},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":208118071},\"end\":51844,\"start\":51507},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":236409543},\"end\":52273,\"start\":51846},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":260003907},\"end\":52625,\"start\":52275},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":254344451},\"end\":53080,\"start\":52627},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":238853512},\"end\":53439,\"start\":53082},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":247506650},\"end\":53876,\"start\":53441},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":1875264},\"end\":54338,\"start\":53878},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":46936121},\"end\":54670,\"start\":54340},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":24079269},\"end\":55240,\"start\":54672},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":189926717},\"end\":55874,\"start\":55242},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":243942547},\"end\":56430,\"start\":55876},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":226567199},\"end\":56714,\"start\":56432},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":221785132},\"end\":57219,\"start\":56716},{\"attributes\":{\"id\":\"b34\"},\"end\":57409,\"start\":57221},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":1360404},\"end\":57796,\"start\":57411},{\"attributes\":{\"id\":\"b36\"},\"end\":58028,\"start\":57798},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":12037187},\"end\":58223,\"start\":58030},{\"attributes\":{\"id\":\"b38\"},\"end\":58429,\"start\":58225},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":202746504},\"end\":58812,\"start\":58431},{\"attributes\":{\"id\":\"b40\"},\"end\":59067,\"start\":58814},{\"attributes\":{\"id\":\"b41\"},\"end\":59303,\"start\":59069},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":109899016},\"end\":59504,\"start\":59305},{\"attributes\":{\"id\":\"b43\"},\"end\":59736,\"start\":59506},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":109134477},\"end\":60023,\"start\":59738},{\"attributes\":{\"id\":\"b45\"},\"end\":60206,\"start\":60025}]", "bib_title": "[{\"end\":43937,\"start\":43867},{\"end\":44411,\"start\":44329},{\"end\":44838,\"start\":44765},{\"end\":45160,\"start\":45099},{\"end\":45504,\"start\":45417},{\"end\":46051,\"start\":46000},{\"end\":46407,\"start\":46329},{\"end\":46852,\"start\":46759},{\"end\":47401,\"start\":47349},{\"end\":47740,\"start\":47666},{\"end\":48212,\"start\":48147},{\"end\":48597,\"start\":48581},{\"end\":48883,\"start\":48792},{\"end\":49286,\"start\":49198},{\"end\":49872,\"start\":49814},{\"end\":50304,\"start\":50222},{\"end\":50587,\"start\":50553},{\"end\":50883,\"start\":50821},{\"end\":51192,\"start\":51107},{\"end\":51580,\"start\":51507},{\"end\":51930,\"start\":51846},{\"end\":52327,\"start\":52275},{\"end\":52701,\"start\":52627},{\"end\":53152,\"start\":53082},{\"end\":53540,\"start\":53441},{\"end\":53928,\"start\":53878},{\"end\":54401,\"start\":54340},{\"end\":54771,\"start\":54672},{\"end\":55331,\"start\":55242},{\"end\":55972,\"start\":55876},{\"end\":56497,\"start\":56432},{\"end\":56778,\"start\":56716},{\"end\":57458,\"start\":57411},{\"end\":58068,\"start\":58030},{\"end\":58520,\"start\":58431},{\"end\":59347,\"start\":59305},{\"end\":59827,\"start\":59738}]", "bib_author": "[{\"end\":43947,\"start\":43939},{\"end\":43954,\"start\":43947},{\"end\":43965,\"start\":43954},{\"end\":43972,\"start\":43965},{\"end\":43979,\"start\":43972},{\"end\":44420,\"start\":44413},{\"end\":44427,\"start\":44420},{\"end\":44435,\"start\":44427},{\"end\":44441,\"start\":44435},{\"end\":44447,\"start\":44441},{\"end\":44453,\"start\":44447},{\"end\":44460,\"start\":44453},{\"end\":44849,\"start\":44840},{\"end\":44855,\"start\":44849},{\"end\":44861,\"start\":44855},{\"end\":45169,\"start\":45162},{\"end\":45176,\"start\":45169},{\"end\":45514,\"start\":45506},{\"end\":45521,\"start\":45514},{\"end\":45528,\"start\":45521},{\"end\":45536,\"start\":45528},{\"end\":45544,\"start\":45536},{\"end\":45550,\"start\":45544},{\"end\":45559,\"start\":45550},{\"end\":45565,\"start\":45559},{\"end\":46059,\"start\":46053},{\"end\":46065,\"start\":46059},{\"end\":46073,\"start\":46065},{\"end\":46081,\"start\":46073},{\"end\":46415,\"start\":46409},{\"end\":46421,\"start\":46415},{\"end\":46439,\"start\":46421},{\"end\":46451,\"start\":46439},{\"end\":46460,\"start\":46451},{\"end\":46862,\"start\":46854},{\"end\":46869,\"start\":46862},{\"end\":46876,\"start\":46869},{\"end\":46883,\"start\":46876},{\"end\":46891,\"start\":46883},{\"end\":46897,\"start\":46891},{\"end\":46903,\"start\":46897},{\"end\":46909,\"start\":46903},{\"end\":46916,\"start\":46909},{\"end\":47284,\"start\":47276},{\"end\":47418,\"start\":47403},{\"end\":47427,\"start\":47418},{\"end\":47438,\"start\":47427},{\"end\":47748,\"start\":47742},{\"end\":47758,\"start\":47748},{\"end\":47776,\"start\":47758},{\"end\":47787,\"start\":47776},{\"end\":47797,\"start\":47787},{\"end\":47806,\"start\":47797},{\"end\":47815,\"start\":47806},{\"end\":48221,\"start\":48214},{\"end\":48229,\"start\":48221},{\"end\":48237,\"start\":48229},{\"end\":48244,\"start\":48237},{\"end\":48250,\"start\":48244},{\"end\":48257,\"start\":48250},{\"end\":48614,\"start\":48599},{\"end\":48899,\"start\":48885},{\"end\":48913,\"start\":48899},{\"end\":48927,\"start\":48913},{\"end\":49295,\"start\":49288},{\"end\":49308,\"start\":49295},{\"end\":49318,\"start\":49308},{\"end\":49327,\"start\":49318},{\"end\":49335,\"start\":49327},{\"end\":49344,\"start\":49335},{\"end\":49350,\"start\":49344},{\"end\":49360,\"start\":49350},{\"end\":49880,\"start\":49874},{\"end\":49887,\"start\":49880},{\"end\":49896,\"start\":49887},{\"end\":49905,\"start\":49896},{\"end\":49912,\"start\":49905},{\"end\":49919,\"start\":49912},{\"end\":49927,\"start\":49919},{\"end\":49934,\"start\":49927},{\"end\":50313,\"start\":50306},{\"end\":50322,\"start\":50313},{\"end\":50328,\"start\":50322},{\"end\":50335,\"start\":50328},{\"end\":50341,\"start\":50335},{\"end\":50597,\"start\":50589},{\"end\":50603,\"start\":50597},{\"end\":50611,\"start\":50603},{\"end\":50617,\"start\":50611},{\"end\":50624,\"start\":50617},{\"end\":50631,\"start\":50624},{\"end\":50638,\"start\":50631},{\"end\":50893,\"start\":50885},{\"end\":50899,\"start\":50893},{\"end\":50906,\"start\":50899},{\"end\":51200,\"start\":51194},{\"end\":51209,\"start\":51200},{\"end\":51216,\"start\":51209},{\"end\":51222,\"start\":51216},{\"end\":51591,\"start\":51582},{\"end\":51597,\"start\":51591},{\"end\":51606,\"start\":51597},{\"end\":51613,\"start\":51606},{\"end\":51938,\"start\":51932},{\"end\":51944,\"start\":51938},{\"end\":51957,\"start\":51944},{\"end\":51963,\"start\":51957},{\"end\":51972,\"start\":51963},{\"end\":51980,\"start\":51972},{\"end\":51988,\"start\":51980},{\"end\":51994,\"start\":51988},{\"end\":52001,\"start\":51994},{\"end\":52008,\"start\":52001},{\"end\":52335,\"start\":52329},{\"end\":52341,\"start\":52335},{\"end\":52352,\"start\":52341},{\"end\":52361,\"start\":52352},{\"end\":52709,\"start\":52703},{\"end\":52715,\"start\":52709},{\"end\":52721,\"start\":52715},{\"end\":52737,\"start\":52721},{\"end\":52747,\"start\":52737},{\"end\":52753,\"start\":52747},{\"end\":52762,\"start\":52753},{\"end\":52771,\"start\":52762},{\"end\":52780,\"start\":52771},{\"end\":52793,\"start\":52780},{\"end\":53162,\"start\":53154},{\"end\":53169,\"start\":53162},{\"end\":53177,\"start\":53169},{\"end\":53183,\"start\":53177},{\"end\":53189,\"start\":53183},{\"end\":53200,\"start\":53189},{\"end\":53206,\"start\":53200},{\"end\":53212,\"start\":53206},{\"end\":53550,\"start\":53542},{\"end\":53557,\"start\":53550},{\"end\":53565,\"start\":53557},{\"end\":53571,\"start\":53565},{\"end\":53579,\"start\":53571},{\"end\":53585,\"start\":53579},{\"end\":53591,\"start\":53585},{\"end\":53937,\"start\":53930},{\"end\":53945,\"start\":53937},{\"end\":53953,\"start\":53945},{\"end\":53962,\"start\":53953},{\"end\":54411,\"start\":54403},{\"end\":54419,\"start\":54411},{\"end\":54426,\"start\":54419},{\"end\":54433,\"start\":54426},{\"end\":54440,\"start\":54433},{\"end\":54781,\"start\":54773},{\"end\":54787,\"start\":54781},{\"end\":54794,\"start\":54787},{\"end\":54804,\"start\":54794},{\"end\":54811,\"start\":54804},{\"end\":55339,\"start\":55333},{\"end\":55345,\"start\":55339},{\"end\":55354,\"start\":55345},{\"end\":55367,\"start\":55354},{\"end\":55373,\"start\":55367},{\"end\":55381,\"start\":55373},{\"end\":55389,\"start\":55381},{\"end\":55395,\"start\":55389},{\"end\":55981,\"start\":55974},{\"end\":55988,\"start\":55981},{\"end\":55995,\"start\":55988},{\"end\":56003,\"start\":55995},{\"end\":56009,\"start\":56003},{\"end\":56016,\"start\":56009},{\"end\":56022,\"start\":56016},{\"end\":56029,\"start\":56022},{\"end\":56507,\"start\":56499},{\"end\":56517,\"start\":56507},{\"end\":56789,\"start\":56780},{\"end\":56796,\"start\":56789},{\"end\":56802,\"start\":56796},{\"end\":56809,\"start\":56802},{\"end\":56815,\"start\":56809},{\"end\":56822,\"start\":56815},{\"end\":57283,\"start\":57272},{\"end\":57290,\"start\":57283},{\"end\":57468,\"start\":57460},{\"end\":57475,\"start\":57468},{\"end\":57485,\"start\":57475},{\"end\":57494,\"start\":57485},{\"end\":57859,\"start\":57849},{\"end\":57872,\"start\":57859},{\"end\":58083,\"start\":58070},{\"end\":58240,\"start\":58225},{\"end\":58253,\"start\":58240},{\"end\":58264,\"start\":58253},{\"end\":58279,\"start\":58264},{\"end\":58533,\"start\":58522},{\"end\":58546,\"start\":58533},{\"end\":58559,\"start\":58546},{\"end\":58569,\"start\":58559},{\"end\":58578,\"start\":58569},{\"end\":58587,\"start\":58578},{\"end\":58892,\"start\":58883},{\"end\":58901,\"start\":58892},{\"end\":59084,\"start\":59069},{\"end\":59094,\"start\":59084},{\"end\":59107,\"start\":59094},{\"end\":59361,\"start\":59349},{\"end\":59601,\"start\":59586},{\"end\":59841,\"start\":59829},{\"end\":60074,\"start\":60065}]", "bib_venue": "[{\"end\":44050,\"start\":43979},{\"end\":44520,\"start\":44460},{\"end\":44909,\"start\":44861},{\"end\":45236,\"start\":45176},{\"end\":45648,\"start\":45565},{\"end\":46141,\"start\":46081},{\"end\":46520,\"start\":46460},{\"end\":46976,\"start\":46916},{\"end\":47274,\"start\":47247},{\"end\":47488,\"start\":47438},{\"end\":47863,\"start\":47815},{\"end\":48337,\"start\":48257},{\"end\":48553,\"start\":48549},{\"end\":48662,\"start\":48614},{\"end\":48967,\"start\":48927},{\"end\":49450,\"start\":49360},{\"end\":49994,\"start\":49934},{\"end\":50368,\"start\":50341},{\"end\":50675,\"start\":50638},{\"end\":50937,\"start\":50906},{\"end\":51283,\"start\":51222},{\"end\":51650,\"start\":51613},{\"end\":52045,\"start\":52008},{\"end\":52409,\"start\":52361},{\"end\":52830,\"start\":52793},{\"end\":53249,\"start\":53212},{\"end\":53633,\"start\":53591},{\"end\":54052,\"start\":53962},{\"end\":54477,\"start\":54440},{\"end\":54901,\"start\":54811},{\"end\":55496,\"start\":55395},{\"end\":56104,\"start\":56029},{\"end\":56548,\"start\":56517},{\"end\":56912,\"start\":56822},{\"end\":57270,\"start\":57221},{\"end\":57580,\"start\":57494},{\"end\":57847,\"start\":57798},{\"end\":58105,\"start\":58083},{\"end\":58315,\"start\":58279},{\"end\":58594,\"start\":58587},{\"end\":58881,\"start\":58814},{\"end\":59138,\"start\":59107},{\"end\":59384,\"start\":59361},{\"end\":59584,\"start\":59506},{\"end\":59858,\"start\":59841},{\"end\":60063,\"start\":60025},{\"end\":44108,\"start\":44052},{\"end\":45718,\"start\":45650},{\"end\":49527,\"start\":49452},{\"end\":50382,\"start\":50370},{\"end\":52433,\"start\":52411},{\"end\":54129,\"start\":54054},{\"end\":54978,\"start\":54903},{\"end\":55584,\"start\":55498},{\"end\":56166,\"start\":56106},{\"end\":56989,\"start\":56914},{\"end\":59156,\"start\":59140}]"}}}, "year": 2023, "month": 12, "day": 17}