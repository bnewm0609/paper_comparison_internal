{"id": 235571722, "updated": "2022-01-11 13:04:47.85", "metadata": {"title": "Modeling Multiple Coexisting Category-Level Intentions for Next Item Recommendation", "authors": "[{\"middle\":[],\"last\":\"Xu\",\"first\":\"Yanan\"},{\"middle\":[],\"last\":\"Zhu\",\"first\":\"Yanmin\"},{\"middle\":[],\"last\":\"Yu\",\"first\":\"Jiadi\"}]", "venue": null, "journal": "ACM Transactions on Information Systems (TOIS)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Purchase intentions have a great impact on future purchases and thus can be exploited for making recommendations. However, purchase intentions are typically complex and may change from time to time. Through empirical study with two e-commerce datasets, we observe that behaviors of multiple types can indicate user intentions and a user may have multiple coexisting category-level intentions that evolve over time. In this article, we propose a novel Intention-Aware Recommender System (IARS) which consists of four components for mining such complex intentions from user behaviors of multiple types. In the first component, we utilize several Recurrent Neural Networks (RNNs) and an attention layer to model diverse user intentions simultaneously and design two kinds of Multi-behavior GRU (MGRU) cells to deal with heterogeneous behaviors. To reveal user intentions, we carefully design three tasks that share representations from MGRUs. The next-item recommendation is the main task and leverages attention to select user intentions according to candidate items. The remaining two (item prediction and sequence comparison) are auxiliary tasks and can reveal user intentions. Extensive experiments on the two real-world datasets demonstrate the effectiveness of our models compared with several state-of-the-art recommendation methods in terms of hit ratio and NDCG.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3157278747", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tois/XuZY21", "doi": "10.1145/3441642"}}, "content": {"source": {"pdf_hash": "195be3b71c380ef983295de2f130afdccef0b874", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4902df1bf562c4fdd51e9a43edbbfc8f6dbab3d8", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/195be3b71c380ef983295de2f130afdccef0b874.txt", "contents": "\nModeling Multiple Coexisting Category-Level Intentions for Next Item Recommendation\n2021. May 2021\n\nYanan Xu \nShanghai Jiao Tong University\n\n\nYanmin Zhu \nShanghai Jiao Tong University\n\n\nJiadi Yu \nShanghai Jiao Tong University\n\n\nYanan Xu \nShanghai Jiao Tong University\n\n\nYanmin Zhu \nShanghai Jiao Tong University\n\n\nJiadi Yu \nShanghai Jiao Tong University\n\n\nModeling Multiple Coexisting Category-Level Intentions for Next Item Recommendation\n\nACM Trans. Inf. Syst\n3932021. May 202110.1145/344164223CCS Concepts: \u2022 Information systems \u2192 Recommender systemsLearning to rank\u2022 Applied comput- ing \u2192 Online shoppingAdditional Key Words and Phrases: Recurrent neural networks, recommender system ACM Reference format:\nPurchase intentions have a great impact on future purchases and thus can be exploited for making recommendations. However, purchase intentions are typically complex and may change from time to time. Through empirical study with two e-commerce datasets, we observe that behaviors of multiple types can indicate user intentions and a user may have multiple coexisting category-level intentions that evolve over time. In this article, we propose a novel Intention-Aware Recommender System (IARS) which consists of four components for mining such complex intentions from user behaviors of multiple types. In the first component, we utilize several Recurrent Neural Networks (RNNs) and an attention layer to model diverse user intentions simultaneously and design two kinds of Multi-behavior GRU (MGRU) cells to deal with heterogeneous behaviors. To reveal user intentions, we carefully design three tasks that share representations from MGRUs. The nextitem recommendation is the main task and leverages attention to select user intentions according to candidate items. The remaining two (item prediction and sequence comparison) are auxiliary tasks and can reveal user intentions. Extensive experiments on the two real-world datasets demonstrate the effectiveness of our models compared with several state-of-the-art recommendation methods in terms of hit ratio and NDCG.\n\nINTRODUCTION\n\nRecommender systems have become an essential component of online retail websites and aim to recommend items that a user will most likely to purchase in the future. With the fast development of e-commerce, these websites recorded a massive amount of heterogeneous interaction behaviors 23:2 Y. Xu et al. (e.g., view, cart, and purchase) between users and items. These interaction records provide opportunities for understanding user purchase intentions.\n\nAlong this line, recommendation with data of behaviors of multiple types (multi-behavior data for short) has attracted wide concerns. Existing studies leveraging multi-behavior data can be divided into two main categories. The first category is extending matrix factorization models. These studies aim to learn the relevance between users and items based on multiple interaction matrices [7,9,18,34]. However, these methods take user-item relationships into consideration from static views and neglect the evolution of users' intentions and the context of purchase behavior. The second kind of work recommends next items by mining sequential patterns or modeling dependency between items [17,35]. In these studies, researchers show more interest in mining the user intentions in short sessions for recommendation. But they model behaviors of different types independently and convert a sequence to a single latent vector which may fail to handle complex intentions.\n\nIn this article, we aim to exploit the multi-behavior data to mine user purchase intentions for the next-item recommendation. Behaviors are the ways (e.g., click, add-to-cart, purchase) that users interact with items on websites. Users usually have multiple kinds of behaviors (e.g., click many related items) before they finally buy a product. We find that behaviors of multiple types can indicate user intentions and users may have multiple coexisting purchase intentions on items of several categories through an empirical study (see details in Section 3). Intentions denote the purpose or goal of one purchase interaction. For example, a user wants to buy both a T-shirt and a pair of shorts (i.e., two kinds of intentions) when summer comes (see Figure 1). He may have click behaviors on products of the two categories alternately before he buys them. Therefore, users can have more than one intention simultaneously. If we can learn such latent complex user intentions from multi-behavior data with item category information and dynamically determine which intention is the most important for the purchase of next item, we will improve the recommendation performance greatly. For better modeling such multiple coexisting intentions based on interaction behaviors, our proposed model should satisfy the following several characteristics:\n\n\u2022 Exploiting Different Behaviors Discriminately. Behaviors of various types have different importance for indicating user intentions. Casual viewing behaviors may be generated with curiosity while purchasing behaviors usually confirm users' preference on items. Therefore, they should be exploited discriminately.\n\n\u2022 Reserving the Dependency among Behaviors of Diverse Types. On the one hand, the interaction data should be seen as sequences for retaining the dependency among items and evolving trends of user intentions. On the other hand, behaviors of different types should be seen as the context of adjacent behaviors rather than be utilized independently. \u2022 Modeling Multiples User Purchase Intentions Simultaneously. Previous research presents user intentions with a single latent vector which lacks the ability for modeling multiple intentions. Our approach should learn several intentions on item category levels simultaneously. Previous research usually mines user hidden intentions from interaction sequences of item IDs. But categories of items in interaction records can explicitly reflect user intentions which need to be further studied.\n\nTo achieve the above goals, we propose a novel neural network model named IARS to model user purchase intentions with the sequences of multiple kinds of behaviors. The model consists of four components, i.e., one RNN-based module and three task modules. The RNN-based module is used as one encoder to learn latent representations encoding user intentions from sequences of behaviors. It discriminately processes different behaviors using two proposed Multi-behavior Gated Recurrent Unit (MGRU) cells. In addition, for modeling users' multiple intentions, we utilize several RNNs to process behaviors simultaneously and adopt attention in recommendation to enable each RNN to learn different intentions. The other three modules are designed for solving diverse tasks based on the learned representations. The first task is to predict next item and category. The second task is to judge whether two sequences are of the same user and whether they are adjacent sequences. These two tasks are aimed to reveal user intentions from record levels and sequence levels, respectively. As far as we know, we are the first to propose sequence comparison tasks to improve recommendation performance. The third task is to estimate user preference over items which is the main task of our model. In this task, we utilize an attention layer to select user intentions according to candidate items.\n\nTo summarize, the main contributions of this article are as follows:\n\n\u2022 We conduct an empirical study on two real-world e-commerce datasets and observe that users have multiple coexisting category-level intentions in interaction sequences of diverse behaviors. \u2022 We propose a novel neural model named IARS to mine user complex intentions for recommendation. It includes several recurrent neural networks for learning latent multiple user intentions from behaviors and three diverse tasks. The various auxiliary behaviors are utilized to reveal user intentions before purchase behavior. Item category prediction task and sequence comparison task are proposed to further reveal user intentions. \u2022 We conduct experiments on the two real-world datasets. The results show that our model significantly outperforms other state-of-the-art methods from various aspects.\n\nThe remainder of this article is organized as follows: In Section 2, we first introduce related work. In Section 3, we analyze two real-world datasets and show several key observations. Next, we introduce our proposed models in Section 4. Then, we evaluate our models based on the two e-commerce datasets in Section 5. Finally, we conclude this article.\n\n\nRELATED WORK\n\n\nMulti-Behavior Recommendation\n\nIn recent years, it has been very popular in the recommendation area to study users' long-term and short-term interests from interaction sequences for improving recommendation performance [20,32]. Ma et al. [20] proposed a hierarchical gating network to capture both long-term and short-term user interests with feature gating and instance gating modules. They also captured relations between items with an item-item product module. Zhang et al. [32] utilized self-attention to learn item-item relations as short-term user interests and assigned each user a latent vector to model long-term preference. The above two studies both learn users' long-term and short-term interests, but their models can only deal with datasets having a single kind of behavior. Sun et al. [27] modeled user interaction sequences with the deep bidirectional self-attention network BERT which neglects the order of interaction records and is trained by randomly masked some items as inferred targets. Wang et al. [31] proposed a mixture-channel purpose routing network to learn users' complex purposes from interaction sequences and assigned interaction records into the different purpose channels using a routing function. This work can learn users' multiple intentions. But it can not deal with multi-behavior data and does not take advantage of category information which is proved very useful in our experiments. In addition, its routing function is not continuous and may make it hard to learn parameters with gradient descent methods.\n\nMulti-behavior recommendation utilizes interaction data of multiple kinds of behaviors and improves recommendation performance of one target behavior with other types [9,17,18,26]. Some work extended matrix factorization to deal with the multi-behavior scenarios [16,26,34]. Singh and Gordon [26] designed a Collective Matrix Factorization (CMF) model by simultaneously factorizing several user-item matrices and sharing latent factors of items. The CMF model is further extended to deal with datasets of various behaviors [16,34]. Krohn-Grimberghe et al. [16] proposed to factorize both a user-item matrix from interactions and a user-user matrix from social networks, and share user embeddings. Zhao et al. [34] combined user-topic matrices of different behavior groups and built user topic profiles by factorizing these matrices.\n\nSome other work deals with multi-behavior data from the perspective of learning [7,9,18,23]. Loni et al. [18] proposed a multi-channel Bayesian Personalized Ranking (BPR) which samples negative items from different behaviors with different sampling rules. Qiu et al. [23] proposed BPRH model for heterogeneous implicit feedbacks considering the correlation between auxiliary action and target action with co-occurrence of them. Wan and McAuley [29] proposed a structure called monotonic behavior chains to describe that strong signals can imply the presence of a weaker signal, and designed a model named chainRec to learn such dependencies among different behaviors. Loni et al. [19] treated multiple kinds of behaviors as channels and provided different sampling methods to sample negative instances for training an FM model. Ding et al. [7] proposed a margin-based pairwise learning model and assigned different margins for different behaviors. Chen [3] built a Behavior2Vec model to generate distributed representation for users' multiple behaviors on products. Gao et al. [9] designed a cascaded neural network to exploit user behaviors of multiple types and treated each kind of behavior as one task for recommendation.\n\nThe above research considers user behaviors of multiple types, but omits the sequential dependency between behaviors. For exploiting multiple behaviors and behavior dependency, Li et al. [17] proposed to model different behaviors with different RNNs. However, they omit the dependency between different kinds of behaviors. Chen et al. [4] proposed a method called AIR which consists of two steps. They first predicted item category for obtaining user intention representation and then recommended next interacted item based on user intentions with an FM model. But AIR is not an end-to-end model which can limit its performance. Zhou et al. [35] projected behaviors of different types into multiple latent semantic spaces for modeling users' complex interests and the influence among behaviors is modeled via self-attention. But this model processes interaction records independently and can not learn the sequential patterns in sequences. Li et al. [17] first learned item embeddings with multi-behavior sequences using an item2vec model. Then, they divided behaviors into auxiliary behaviors and a target behavior, and processed them with two LSTMs to learn users' current motivation and historical preference, repectively. However, this method does not consider that users may have several interests or motivations over a period of time. Zhu et al. [36] proposed to build an interactive recommender system to mine user intentions by asking users questions and exploits their various feedbacks. Their model relies on dynamically interacting with users and the problem formulation is quite different from ours.\n\nTanjim et al. [28] used a Temporal Convolutional Network layer to capture users' latent intent from sequences of item categories and guide an attentive model with learned intentions to predict the next item. The proposed model can deal with various behaviors and item category information. But the model can not process different behaviors discriminately.\n\n\nMulti-task Learning\n\nThe high performance of machine learning methods depends on good data representations to a great extent [1]. Representation learning of a single task can only capture the information needed by the task and discarded other information. In contrast, multi-task learning allows statistical strength sharing and knowledge transfer, thus the representations can capture more underlying factors and have higher generalization abilities [2]. In some studies of multi-task learning, researchers treat tasks equally and try to improve the performance of all tasks. Chen et al. [5] proposed an adversarial multi-criteria learning method for solving the Chinese word segmentation task and designed an adversarial strategy to force shared network layers to learn criteria-invariant features. In other research, tasks are divided into one main task and other auxiliary tasks. The auxiliary tasks are utilized for improving the performance of the main tasks. Seltzer and Droppo [25] performed a primary classification task and other auxiliary tasks by sharing representations in a deep neural network, and proved that multi-task learning can reduce greatly the classification errors. Zhang et al. [33] proposed to solve the problem of facial landmark detection together with head pose estimation and facial attribute inference to improve detection performance.\n\nIn recommendation areas, many studies utilize multi-task learning framework [15,22]. Wang et al. [30] utilized a knowledge graph embedding task to assist recommendation task and associated two tasks with cross&compress units to share latent features between items and entities. Huang et al. [13] studied the problem of entity recommendation and web page retrieval by sharing context representations based on search logs from search engines. Elkahky et al. [8] studied the cross-domain recommendation problem and their model shared user representation across different domains. Their work can also be seen as multi-task research and treated recommendations in each domain as one task. Multi-behavior data in the recommendation domain can also be utilized to construct multiple tasks and each behavior is treated as one task [9,34]. Zhu et al. [37] used brand information to improve performance.\n\n\nPRELIMINARIES\n\nIn this section, we first introduce two datasets and empirical studies on them. Then, we formally define the next-item recommendation task with multi-behavior data.\n\n\nData Analysis\n\nWe utilize two e-commerce datasets, i.e., Taobao and Retailrocket, which contain multiple kinds of user behaviors. The two datasets are collected from Taobao app and a retail website, respectively. The statistics of the two datasets are shown in Table 1. The descriptions of the datasets are shown as follows:\n\n\u2022 Taobao 1 dataset is collected on the Taobao app which belongs to the largest electric business company (i.e., Alibaba) in China within the time period from 2014/11/18 to 2014/12/18. According to the statistic information in Table 1, we observe that the datasets both have item category information and have a large number of click/view records though they are not the most concerning interactions for e-commerce companies. The findings inspire us whether we can utilize the two kinds of information. We conduct two empirical studies on the datasets.\n\nWe first show the distribution of interaction records belonging to a user or an item. The results are shown in Figure 2. It should be noticed that axes are in log scales. We can see that (1) for all kinds of behaviors, the number of records belonging to one user/item follows power-law distributions.\n\n(2) The number of records for click/view is much larger than that of other behaviors. Retailrocket is sparser than Taobao dataset.\n\nNext, we study users' intentions over item categories in behaviors. In daily life, people usually search for products with categories according to their demands. They will compare several items of the same categories and buy a suitable one. It inspires us that the recent behaviors, especially click/view, can indicate users' intentions for buying products. In this experiment, we sort interaction records of each user by timestamps and split them at the positions of purchase behavior records (see Figure 3 as one example). As a result, each user has several interaction sequences of items (e.g., S 1 , S 2 , and S 3 ). For each sequence, we can further split it into two subsequences of the same length (e.g., S 4 and S 5 ).\n\nThen, we can calculate the distribution of items over categories in every sequence with the following equation:\np(c = i |S ) = |{r |r .c = i, r in S}| |S | ,(1)\nwhere c denotes category, r is one record in sequence S and |S | is the number of records in it.\n\nIt should be noted that if one item was interacted with for more than one time in a sequence, we treat the interactions as different records because their timestamps are different. Based on the distributions, we can compute the Kullback-Leibler divergence (KL divergence) between arbitrary two sequences to show their similarities with Equation (2).  The interaction records are divided into several sequences, i.e., S 1 to S 5 , according to purchase records.\nD K L (S j , S k ) = i p(c = i |S j ) log p(c = i |S j ) p(c = i |S k ) .(2)\nConsidering KL divergence is asymmetrical, we further compute average value of\nD K L (S j , S k ) and D K L (S k , S j ) which is denoted by D K (S j , S k ).\nWhen the KL divergence is smaller, the two sequences are more similar on item distribution over item categories. We consider four kinds of sequence pairs. For a user, we consider adjacent subsequences between two adjacent purchases (S 4 and S 5 ), adjacent sequences (S 1 and S 2 ), and nonadjacent sequences of a user (S 1 and S 3 ). The last kind of pair is the sequences of different users. It should be noted that adjacent subsequences must be two subsequences split from one sequence. The histograms of their KL divergences are shown in Figure 4. For each plot, the abscissa is the KL divergence and vertical is the number of sequence pairs. As the total number of sequence pairs is different in the four plots, the histograms are all normalized.\n\nFrom the figures, we have several observations.\n\n(1) Users have purchase intentions. The KL divergence of the first row is usually lower than that of the other three rows. It means that the interacted items between two purchased behaviors are Fig. 4. Histograms of KL divergences between two interaction sequences in terms of item categories on two E-commerce datasets. For each user, his interaction records can form sequences of items and the interaction sequences are split according to purchase behaviors. From top to down, the first plot shows KL divergences between adjacent subsequences of the same users. The second plot shows KL divergences adjacent sequences separated by purchase behaviors of the same user. The third plot is KL divergence of two nonadjacent sequences of the same user. The fourth plot is divergences between sequences from different users. For each plot, the horizontal is KL divergence and the vertical is the number of sequence pairs. usually very similar in terms of item categories. Thus, the plots in the first row have the smallest KL divergence (e.g., D K (S 4 , S 5 )) than other plots. When the user has bought one item, his intention on the category of that item ends. Thus, the KL divergences become larger in the second row (D K (S 1 , S 2 ) > D K (S 4 , S 5 )). As time goes on, users' intention changes and his intention is also very different from that of other users. As a result, the plots in the third row and fourth row have larger KL divergence.\n\n(2) Users may have multiple coexisting category-level intentions. If a user has only one intent, his/her item sequences between two purchases should belong to one category. But the plots in the first row show that the KL divergences are usually larger than 0, e.g., D K (S 4 , S 5 ) > 0.\n\n(3) Users' intentions evolve over time. Comparing the first three rows, we can see that the KL divergences grow with the time interval between two sequences. KL divergences of nonadjacent sequences are obviously larger than that of adjacent sequences and subsequences, e.g.,\nD K (S 1 , S 3 ) > D K (S 1 , S 2 ) > D K (S 4 , S 5 ).\nWe also compute the average KL divergences for each kind of sequence pairs as shown in Table 2. We can see it clearly that from top to down, the mean values of KL divergences grow. \n\n\nProblem Definition\n\nNext-item recommendation is the task of predicting which item a user will interact with based on his/her historical interaction records. In what follows, we will present some notifications and formulate the recommendation problem.\n\nInteractions with items of one user naturally form a sequence over time. Therefore, interaction history H from an e-commerce platform can be seen as a set of interaction sequences, i.e., H = {S 1 , S 2 , . . . , S u , . . . , S N }, where S u denotes the interaction sequence of user u and N is the number of users. For a user u, his/her interaction sequence is\nS u = {(x 1 , c 1 , b 1 ), (x 2 , c 2 , b 2 ), . . . , (x T , c T , b T )}, where (x t , c t , b t )\nis one interaction record, x t denotes an item, c t is the category of x t , and b t denotes the behavior type (e.g., view, cart, purchase). We use B = {b 1 , b 2 , . . . ,b R } to denote the set of all behaviors and R is the number of behavior types. As we aim to improve the recommendation performance of purchase, we treat purchase b R as the target behavior and the rest as auxiliary behaviors. Then, we can define the next-item recommendation problem.\n\nGiven a user u and his/her interaction sequence\nS u = {(x 1 , c 1 , b 1 ), (x 2 , c 2 , b 2 ), . . . , (x T , c T , b T )\n} of all behavior types, we aim to recommend a new item x that the user u will most likely purchase at T + 1.\n\n\nIARS: INTENTION-AWARE RECOMMENDER SYSTEM\n\nIn this section, we introduce our model, i.e., IARS, for the next-item recommendation based on multi-behavior data. We first provide an overview of our model and describe its main components. Finally, we show the training steps.\n\n\nOverview of IARS\n\nBefore introducing the implementation details, we give an overview of our proposed model. As we have said in the previous section, we want to utilize rich data of various behaviors to mine user intentions. Our model should satisfy three requirements. First, it should retain the dependency between behaviors of multiple types in sequences and not process them independently. Second, it should model different behaviors discriminately as various behaviors have different importance. Third, it should capture multiple coexisting intentions at the same time. To meet these requirements, we propose a model named Intention-Aware Recommender System (IARS), whose structure is shown in Figure 5. It consists of four components, i.e., one encoder for mining user intentions from behaviors with multiple RNNs and the other three components as decoders for different tasks based on user intentions.\n\nThe encoder can encode a sequence of behaviors into several sequences of latent vectors. The encoder can satisfy all the requirements we mentioned. First, the interaction records of different kinds of behaviors are treated as one sequence for each user. The sequences of behaviors retain dependency among them. Second, we use behavior types as the input and propose two kinds of Multi-behavior GRU (MGRU) cells including Hard-MGRU and Soft-MGRU for RNNs to deal with behavior types. Third, we utilize several RNNs to capture multiple intentions of one user. In addition, the categories of items are also used as the input of the encoder for learning users' intentions on categories.\n\nThe sequences of latent vectors generated by RNNs contain information about user intentions and will be used for finishing three kinds of tasks. The first two tasks are used as auxiliary tasks to further reveal users' intentions and the third task is our main task, i.e., recommendation task. The first task is predicting the next item and item category. The second task is given two sequences, judge whether they are from the same user and whether they are adjacent sequences of the same user. In the third task, we use the last hidden states of MGRU as the representation of users and calculate his/her preference score on each item. What is more, in each task, we offer different kinds of methods to merge multiple hidden states from RNNs. For the recommendation task, we leverage an attention layer to merge multiple hidden states and let each RNN learn different intentions.\n\n\nHard-MGRU and Soft-MGRU\n\nIn this part, we introduce the encoder component. This component is proposed to detect users' intentions from behaviors of multiple types and retain the item dependency information in sequences. Inspired by [11], the encoder consists of several RNNs and each RNN is used to learn one kind of user intention using different parameters. For each RNN, its input includes sequences of behavior types (b t ), item IDs (x t ), and item category IDs (c t ).\n\nTo reserve the dependencies between records of various behavior types, we organize records of all behavior types in one sequence for each user, and process them using a unified MGRU network. The information of extracted user intentions is passed between adjacent records with hidden states of MGRU. To deal with the behavior types, we propose two kinds of MGRU cells, i.e., Hard-MGRU and Soft-MGRU. Hard-MGRU processes various behaviors with different parameter sets. It can extract different information from them and adapts to different behavior patterns (e.g., click records generate faster than purchase records). Soft-MGRU processes behavior types with gates to determine the importance of each kind of behavior. Considering behavior types contain little information about user intentions, we do not use them in the computation of candidate hidden states in Soft-MGRU.\n\nAs all RNNs in the encoder have identical structures but different parameters, we omit the notations for distinguishing them. In what follows, we will introduce Hard-MGRU and Soft-MGRU. , , and denote matrix multiplication, element-wise product, and element-wise addition, respectively. Biases are omitted for simplicity.\n\n\nHard-MGRU.\n\nHard-MGRU models different behaviors with different parameters and transfers information between adjacent interaction behaviors with hidden states of RNN. The structure of Hard-MGRU is shown in Figure 6(a).\n\nFor behavior types, items, and categories, we use their IDs as input of our MGRU. We first convert one-hot vectors of items and categories into embeddings of low dimensions with the following equations:\np t = E I x t ,(3)q t = E C c t ,(4)\nwhere E I \u2208 R D\u00d7M and E C \u2208 R D\u00d7L are corresponding embedding matrices. M and L are the number of items and categories, respectively, and D is the size of embeddings. For simplicity, items and categories have the same embedding size. x t and c t are the one-hot vectors of items and categories, respectively. Item-embedding p t and category-embedding q t will be concatenated as input of our MGRU cells. Next, Hard-MGRU will choose parameters for each interaction record according to its behavior type with equations:\nW r b t = W r b t , W z b t = W z b t , W h b t = W h b t .\nW r , W z , and W h are parameters of all kinds of behaviors for reset gate, update gate, and candidate hidden state generation, respectively. Their sizes are R \u00d7 (D * 2D) where R is the number of behavior types. Each column of them denotes parameters of one kind of behavior. W r b t , W r b t , and W r b t are selected parameters according to behavior type b t . They are reshaped to weight matrices of MGRU cells and the weight matrices belong to R D\u00d72D . For bias parameters, they have similar process.\n\nWe use h t to denote the hidden state of the tth step of MGRU. h t is produced based on previous hidden state h t \u22121 and current input p t and q t . The equations are as follows: where r t and z t are reset gate and update gate, respectively. W b t s and b b t s are weight matrices and biases of behavior b t , respectively. \u03c3 denotes the sigmoid function. p t and q t are concatenated as input. The last equation is for normalizing hidden states. It should be noted that our Hard-GRU is different from traditional GRU in two aspects: (1) The parameters in our MGRU cell are conditioned on behavior types and (2) Our MGRU cell has one normalization equation before outputting hidden states, which is proved effective in our experiments. What is more, we only modify the GRU cell, and other popular RNN cells like LSTM can also be modified. We leave it to be studied in the future. Finally, our MGRU network will output a sequence of hidden states, i.e., {h 1 , h 2 , . . . , h T }. Considering that we adopt several RNNs to capture multiple coexisting intentions of users, we use {h j 1 , h j 2 , . . . , h j T } to denote hidden states of the jth RNN. Different RNNs have different parameters and use reset gate r t and update gate z t to decide whether the information of current behavior type should be learned by them.\nr t = \u03c3 W r b t [p t , q t ] + b r b t ,(5)z t = \u03c3 W z b t [p t , q t ] + b z b t ,(6)h t = tanh W h b t [r t * h t \u22121 , p t ] ,(7)h t = (1 \u2212 z t ) * h t \u22121 + z t * h t ,(8)h t =\u0125 t \u0125 t ,(9)\n\nSoft-MGRU.\n\nHard-MGRU learns parameters for each kind of behavior which will cause a large space complexity. Therefore, we further propose Soft-MGRU to take advantage of gates in RNN cells to determine the importance of different behaviors and all behavior types share parameters in cells. The structure of Soft-MGRU is shown in Figure 6(b). It should be noticed that behavior types are utilized only in the computation of gates as they only determine how much information should be learned from current interaction records and contain little information about user intentions.\n\nThe input of Soft-MGRU includes behavior types, items, and categories and is the same as that of Hard-MGRU. It should be noted that, in Soft-MGRU, behavior types are also converted to embeddings of low dimensions with the following equation:\na t = E B b t ,(10)\nwhere b t is the one-hot vector of behavior types and E B \u2208 R D\u00d7R is the embedding matrix. Next, the embeddings are sent to Soft-MGRU cells. For simplicity, we only introduce one cell in the multiple RNNs as they share the identical structures. The equations of Soft-MGRU are as follows:\nr t = \u03c3 (W r [p t , q t , a t ] + b r ),(11)z t = \u03c3 (W z [p t , q t , a t ] + b z ),(12)h t = tanh(W h [r t * h t \u22121 , p t , q t ]),(13)h t = (1 \u2212 z t ) * h t \u22121 + z t * h t ,(14)h t =\u0125 t \u0125 t ,(15)\nwhere weight matricesW r ,W z , andW h are of the same size which is R D\u00d73D . All bias bs are scalars. At last, Soft-MGRU outputs a sequence of hidden states, i.e., {h j 1 , h j 2 , . . . , h j T } for RNN j. The difference between Hard-MGRU and Soft-MGRU lies in two aspects: (1) The parameters of Hard-MGRU are conditioned on behavior types while Soft-MGRU shares parameters for all kinds of behaviors and (2) Soft-MGRU utilizes behavior embeddings in the reset gate and update gate while Hard-MGRU does not include them in cells.\n\n\nMultiple Tasks with MGRU\n\nWe propose an MGRU network to encode item dependency in behavior sequences and represent user intentions with hidden states. Now, we can take advantage of these hidden states to finish various tasks with different decoders. As mentioned above, we consider three tasks in this article and two of them are as auxiliary tasks.\n\n\nTask 1: Next Item and Category Prediction.\n\nThe first task is to predict the next item and its category that a user will interact with for all kinds of behaviors. It can be divided into two subtasks including item prediction and category prediction. In previous studies, categories are usually only used as input. The reasons for using category prediction as one subtask lie in three aspects. First, category prediction can narrow down the prediction space and solve data sparsity problem to a certain extent. Because the number of categories is much less than the number of items and category prediction will be much easier than item prediction. Second, item category can reveal user coarsegrained intentions. When users buy products, they will search for them by categories that meet their needs. Third, item category can be seen as regularization for the representations of items. Items of the same categories will be mapped to near points in a latent space which retains semantic information and reduces the risk of overfitting.\n\nConsidering that it is the tth step in a sequence, we aim to predict IDs of items and category of the t + 1 step. In the encoder, an RNN j will provide a hidden state h j t . We need to merge these hidden state {h 1 t , . . . , h j t , . . . , h J t } from all J MGRUs. As we do not know which kind of action a user will take and which intention a user will show in the next behavior, we calculate the average values of these hidden states with Equation (16).\nh t = mean({h j t |j = 1 . . . J }).(16)\nNext, we predict the item and category with the following softmax functions:\ny I t = so f tmax (W I h t ),(17)y C t = so f tmax (W C h t ),(18)\nwhere W I \u2208 R M \u00d7D and W C \u2208 R L\u00d7D are the parameter matrices of items and categories, respectively.\u0177 I t \u2208 R M and\u0177 C t \u2208 R L are the predicted probabilities of next items and categories.\n\n\nTask 2: Sequence Comparison.\n\nThe second task is that, given two sequences (see the preliminary section), we judge (1) whether two sequences belong to the same user and (2) whether they are adjacent sequences. Therefore, we have two binary classification subtasks. For this task, we are inspired by BERT [6] which learns word embeddings with the task of predicting next sentence. Different from item prediction task, we only utilize the last hidden states of MGRU, i.e., {h j T |j = 1, . . . , J }, as representations of one sequence. We merge the last hidden states from multiple MGRU networks with mean function. The merged latent vector is denoted by h T . We utilize MGRU twice and encode two sequences into two hidden states which are denoted by h T and h T , respectively. Next, we employ a fully connected neural network to generate classification results:\ny S = f (h T , h T ),(19)\nwhere f denotes a fully connected neural network,\u0177 S \u2208 R 2 is a vector, and the range of values in it is between 0 and 1.\n\n\nTask 3: Item Recommendation.\n\nThe above two tasks are auxiliary tasks. Our main task is to recommend the next new item that a user will purchase. It should be noticed that Task 1 is designed for predicting next behavior of all types. But Task 3 is used for recommending next purchased item. Similar to Task 2, we first merge the last hidden states from MGRU. Instead of using mean function, we propose an attention network to select intentions according to candidate items. The attention layer will enable each RNN to learn different user intentions. The equations of attention network are as follows:\n\u03b2 j = \u0434 h j T , e i ,(20)\u03b1 j = \u03b2 j k \u03b2 k ,(21)h = \u03b1 j h j T ,(22)\nwhere \u0434(\u00b7) is a function to calculate the similarity between two vectors and can be inner product or a fully connected neural network. e i is the embedding of item i and e i = W I x i which shares parameters with prediction tasks. h is the merged latent vector which indicates users' intention. Finally, we can calculate users' preference score y r on item i with inner product:\ny r u,i = h T e i .(23)\nIf user u bought item i, y r u,i = 1 otherwise y r u,i = 0. The inner product can also be replaced by a more complex interaction function like fully-connected neural networks [10].\n\n\nTraining\n\nFor the first task, we adopt the following loss function:\nL 1 = \u2212 u t y I t lo\u0434 \u0177 I t + \u03b3y C t lo\u0434 \u0177 C t ,(24)\nwhere the two parts are losses of predicted items and categories, respectively. For the second task, we use the squared loss.\nL 2 = \u2212 i \u0177 S \u2212 y S 2 2 .(25)\nWhen preparing the training dataset, we split interaction sequences of all users according to the purchase behavior records in the same way as we did in Section 3. For each user, we first select one interaction sequence S u i and its adjacent sequence S u i+1 as one training sample and set their two labels as [1,1]. The two labels indicate that S u i and S u i+1 are of the same user and are adjacent sequences, respectively. Next, we randomly sample one nonadjacent sequence S u j , and combine it with S u i as another training instance whose labels are set to [1,0]. Then, we randomly select another user and sample one interaction sequence S u k . The sampled sequence pair S u k and S u i is as the third kinds of training instance and its two labels are [0, 0]. The two labels indicate that the sampled two sequences are from different users. The ratio of the above three kinds of training instances is set to 1 : 2 : 3 to construct a balanced training dataset in our experiments.\n\nWe use cross entropy as the loss function for recommendation task.\nL 3 = \u2212 y r \u2208Y y r lo\u0434\u03c3 (y r ) + (1 \u2212 y r )lo\u0434(1 \u2212 \u03c3 (y r )),(26)\nwhere Y = Y + \u222a Y \u2212 is a collection of positive instances and sampled negative instances. For each positive instance, we will sample four items that the user has not interacted with as negative instances. At last, we combine the losses from different tasks with weights.\nL = \u03bb 1 L 1 + \u03bb 2 L 2 + \u03bb 3 L 3 ,(27)\nwhere \u03bb i is weight of task i. We adopt mini-batch gradient decent algorithm and adam optimizer to optimize it which converges faster than other optimizers [14].\n\n\nEXPERIMENTS\n\nIn this section, we conduct extensive experiments on two real-world datasets to answer the following research questions:\n\n\u2022 RQ1. How does our proposed model perform as compared with state-of-the-art recommendation methods? \u2022 RQ2. Are the auxiliary behaviors helpful for improving the recommendation performance of the target behavior? \u2022 RQ3. Are the designed various tasks useful for the recommendation task? \u2022 RQ4. Can our models learn users' intentions and improve recommendation performance with them? \u2022 RQ5. Can our proposed model help address the data sparsity problem with mined coarsegrained intentions?\n\n\nExperimental Settings\n\n\nDatasets and Preprocessing.\n\nWe evaluate our models with two real-world e-commerce datasets i.e., Taobao and Retailrocket. Since the statistics of the datasets have been presented, we only introduce the preprocessing steps to reduce the sparsity. We filter out users and items in Taobao datasets having fewer than 10 and 20 interaction records, respectively. For Retailrocket, we keep users and items with more than 5 and 10 records, respectively. In addition, each user should have at least one purchase record. The Retailrocket dataset consists of hierarchical (treelike) category information. Thus, each item may belong to several categories of different levels. We only use the category information of the lowest level in our experiments. We set the maximum length of sequences to be 20. For Taobao dataset, the average length of processed sequences is about 19. For Retailrocket dataset, it is about 17.\n\n\nEvaluation Methodology.\n\nWe adopt leave-one-out performance validation which is widely used in previous research [7,10]. Specifically, we leave the last purchased item as test dataset and use the rest interaction records as the training dataset. As our task is recommending next new items which will be bought by users, we delete records of the test items in the training dataset for each user. In the test dataset, we couple each instance with 99 items that the user has never interacted with as negative instances. For each user, the 100 items are ranked with the predicted preference scores from our model. The top-ranked items are treated as recommendation results. We adopt two popular evaluation metrics, i.e., HR@K (Hit ratio) [10] and NDCG@K (Normalized Discounted Cumulative Gain) [7]. K is the number of recommended items. The details of the two metrics are as follows:\n\n\u2022 HR@K. A recall-based measure, i.e., HR@K = #hits@K |U | where #hits@K is the number of hits and |U | denotes the number of users in the test dataset. It can indicate whether the test item is in the list of top-K recommended items.\n\n\u2022 NDCG@K. A ranking-based measure. For each user, we compute N DCG@K = Z k K i=1 2 r el i \u22121 lo\u0434 2 (i+1) which assigns higher scores to items with top ranks. rel i is the graded relevance value of the item at position i and Z K is the normalization. In our experiment, we set rel i \u2208 {1, 0}, which depends on whether i is the purchased item. We report the average N DCG@K over all users.\n\n\nBaselines.\n\nWe compare our proposed model with the following baselines:\n\n\u2022 BPR [24]. BPR is a matrix-factorization-based method and lets positive instance have a higher preference score than negative ones of the same user with a pairwise learning framework.\n\n\u2022 GRU [12]. This work adopts GRU to model item dependence based on interaction sequences. It is designed for single-behavior data. \u2022 CMF [34]. This method factorizes matrices of multiple behaviors simultaneously.\n\n\u2022 MC-BPR [18]. Multi-Channel BPR adopts different sampling rules for records of different behaviors. \u2022 VALS [7]. This method extends matrix factorization methods to model pairwise ranking relations among purchased, viewed, and non-viewed interactions. \u2022 NMTR [9]. NMTR accounts for the cascading relationship among different behaviors with a neural network and shares embeddings of users and items among different behaviors. \u2022 AIR [4]. AIR consists of two steps. First, it predicts user intention as an action-category tuple to discover category-wise sequential patterns and to capture effects of various actions for recommendation. Then, it proposes an intention-aware factorization machine to perform sequential recommendation based on the predicted intentions. \u2022 ASLI [28]. ASLI learns item similarity from interaction histories with a self-attention network, obtains users' intent with a convolution network applied to item category sequences, and uses the learned intent to select the most related purchased items to predict the next item. \u2022 ATRank [35]. ATRank models various user behaviors independently and the interactions between different behaviors are captured using the self-attention layers. \u2022 MCPRN [31]. MCPRN utilizes several Recurrent Neural Networks to learn users' complex intentions and uses a purpose router layer to decide which RNN should be updated with current interaction records. The learned users' intentions from RNNs are selected with an attention layer to predict users' current preference score on a specific item. \u2022 BINN [17]. BINN uses an item2vec method to generate embeddings of items and discriminately exploits user behaviors with two LSTM-based networks to learn historical preference and present motivation. \u2022 HGN [20]. HGN applies a hierarchical gating neural network to learn the group-level representations of one sequence and utilizes item-item product to capture relations between relevant items in interaction sequences.\n\n\nHyperparameter Settings.\n\nWe implement all methods with TensorFlow. 3 Since we have two choices of MGRUs (i.e., Hard-MGRU and Soft-MGRU), we name the respective methods as IARS-H and IARS-S. For each user, we recommend K items and set K to [2,6,10]. For each positive instance, we sample four items as negative instances to construct a training dataset. For tuning the hyperparameters of our methods and baselines, we leave the last purchased item of each user in the training dataset for evaluation. In what follows, we report the optimal settings. The weights of loss functions of the three tasks are set to [0.5, 0.2, 1]. And the weight \u03b3 of category prediction is set to 0.5. The batch size of samples is 512. Since the findings are consistent across the number of latent factors, we report the results with the size of latent vectors and embeddings set to 64 only. The initial values of parameters in our model follow a Gaussian distribution with mean and variance equal to 0 and 0.1, respectively. The initial learning rate is set to 0.01. For ATRank, we use the code provided by the authors. 4 For all compared methods, we tune their hyperparameters and report the best performance. For all methods, the size of latent vectors is set to 64 and initial learning rate is 0.01. BPR samples four negative instances for each positive one. The maximum length of interaction sequences is 20 for GRU, AIR, ATRank, BINN, and HGN. For VALS, the \u03b3 and \u03bb is set to 0.3 and 0.2, respectively. NMTR sets weights of four behavior types to \u03bb = [0.5, 1, 1, 2]. For ASLI, different from the original model in [28], we not only utilize category embeddings in the TCN layer, but also add them to the self-attention layer. With such settings, ASLI has better results. For ATRank, the number of latent semantic spaces is set to 8. For MCPRN, the number of channels is set to 4 which is the same as ours. MCPRN does not consider the item category information. For a fair comparison between MCPRN and our methods, we concatenate item embeddings and category embeddings as the input of MCPRN. MCPRN can not deal with behaviors of multiple types. We add behavior embeddings to item embeddings for each interaction record. For HGN, we use the original implementation code provided by its authors. 5 The initial learning rate and the regularization parameter are set to 0.001 and 0.001, respectively. The embedding size is set to 64. As HGN is not designed to deal with various behaviors, we use records of all behavior types to train HGN and neglect their behavior types. Furthermore, we concatenate category embeddings with item embeddings as the input of HGN to process item category information.\n\n\nExperimental Results\n\n\nPerformance Comparison (RQ1).\n\nTo demonstrate the significance of our models, we first compare IARS with other methods. The results are shown in Table 3. We test all methods using HR@K and NDCG@K with K set to [2,6,10]. From overall views, our IARS models significantly outperform all compared methods on both datasets.\n\nBPR and GRU only utilize the data of purchase behaviors while other methods use records of all behaviors. We can see that models using all behaviors perform significantly better than BPR and GRU. GRU as one RNN-based method considers the dependency between items and has better performance than BPR. CMF method performs worse than other baselines utilizing all behaviors. It is because CMF learns several user embeddings for different behaviors which may lack training data for purchase behavior. For the rest methods, they share embeddings of users and items for all kinds of behaviors. VALS models the relative preference orders among different behaviors and achieves better performance than MC-BPR and NMTR. Unlike the above methods using only item IDs, AIR, ATRank, and BINN utilize both item IDs and categories as input and perform significantly better than other baselines. Because item categories can reveal user intentions. AIR has two steps and is not an end-to-end model. As a result, it fails to outperform ATRank and BINN. ATRank leverages self-attention to model the item dependency. But ATRank treats historical records independently and can not learn the sequential patterns among them. Similar to ATRank, ASLI also utilizes self-attention to learn item dependency. But ATRank adopts multi-head attention and ASLI has only one attention head. Therefore, ATRank can learn more complex dependency between items and performs better than ASLI in Taobao Dataset. As Retailrocket dataset is very sparse and ATRank has more parameters which may be not trained well, ATRank fails to beat ASLI. MCPRN utilizes a mixture-channel purpose routing network to learn user intentions with several RNNs and achieves good performance. But the routing delta function is not continuous and may make it hard to train the model. BINN treats purchases as the target behavior and the rest as auxiliary behaviors. It leverages two LSTMs to process the two kinds of behaviors and learn users' historical preferences and present motivations, and achieves good performance. HGN applies a hierarchical gating network to capture feature-level and group-level dependency and learns dependencies between nonadjacent items. It outperforms most baselines. HGN has better performance than BINN on Retailrocket, but fails to outperform it on Taobao dataset. The reason may be that HGN is an attention-based method and is better at processing sparse datasets (e.g., Retailrocket) than RNN-based methods like BINN.\n\nOur models perform better than all baselines, especially when K is small which proves that our models have better ranking abilities. It is because our models can learn user intentions from several aspects. First, our models utilize behaviors of multiple types and auxiliary behaviors can indicate user intentions. Second, we design various tasks to reveal user intentions in behavior sequences. We not only take item categories as input, but also predict next item category as output which makes the models learn fundamental category-level intentions of users. Third, our approach model multiple coexisting intentions by using several RNNs and attention layers, thus they have stronger representation abilities than baselines. AIR, ATRank, and BINN also utilize heterogeneous behaviors and learn user intentions to some extent. AIR tries to predict item categories and behavior types in the next interaction record as user intentions in its first step. But AIR is not an end-to-end model. ATRank utilizes the self-attention layers and learns user interests in several semantic spaces. However, it fails to model the sequential patterns in behaviors. BINN considers long-term and short-term user interests, but can not distinguish various intentions in recent behaviors. Among our proposed models, Soft-MGRU seems to perform a little better than Hard-MGRU. We think it is because that Hard-MGRU does not share parameters for different behaviors in RNN cells. The parameters of purchase behaviors may not be trained very well due to the data sparsity problem.\n\nTo further prove that our proposed approaches have better performance than baselines, we adopt another evaluation method and other three metrics which are the same as that in [20] to evaluate our approaches. For each user, we leverage 70% of the interaction records as the training set and the next 10% of records for tuning hyper-parameters. The remaining 20% of records generated by users are as the test set. For each user, we remove the records of items in the test set from training set to ensure that the items did not appear in the user's history sequences. We utilize our approaches and baselines to rank all items and calculate precision, recall and NDCG with the top 10 recommended items for each user. We report the average values of the three metrics.\n\nThe experimental results of several best baselines and our approaches are shown in Table 4. We can see that our proposed approaches still outperform all baselines on both datasets. This experiment further proves the effectiveness of our approaches. \n\n\nImpact of Multiple Behaviors (RQ2).\n\nAs we exploit heterogeneous behaviors to learn user intentions and assist the recommendation task, we investigate the influence of various behaviors on recommendation performance. The results of our models with different kinds of behaviors are shown in Figure 7. We can see that with only purchase behaviors, the performance of our models drops a lot. But it is still better than that of BPR and GRU in Table 3 which proves the effectiveness of normalization in our cells. Among all auxiliary behaviors, click and view are the most important behaviors for improving performance as they have more records than other behaviors and frequent-occurring item categories can reveal users' category-level intentions.\n\n\nImpact of Auxiliary Tasks (RQ3).\n\nTo clarify the effectiveness of auxiliary tasks, we show the results of our models with different tasks in Figure 8. As the next-item prediction task includes item ID prediction and category prediction, we split it into two tasks. In the figure, our models with all tasks have the best performance. The sequence comparison task improves the performance of the models with only recommendation task. However, it seems that the improvement of adding prediction tasks is much larger. It may be because item IDs and categories contain more intention information than the labels (only 0 and 1) in the comparison task. Item ID and category prediction tasks both play important roles in improving recommendation performance.\n\n\nVisualization of Item Embeddings (RQ4).\n\nWe visualize the embeddings of items to show whether our models learn the semantic information of item category. However, the size of item embeddings is 64 which can not be visualized. We use the T-SNE [21] to reduce the dimension of embeddings and show the embeddings in Figure 9. Each item point is colored according to its category. For comparison, we also show the item embeddings from BINN which is the best baselines Fig. 8. Effect of auxiliary tasks. R and C denote recommendation task and sequence comparison task, respectively. PC and PI denote item ID and category prediction tasks. in our experiments. We can see that for our models, items of the same categories cluster together. Such a phenomenon is not very clear for BINN. It proves that our models learn the category information which is quite important for mining user intentions. It seems that Hard-MGRU is better at bringing together items of the same categories than Soft-MGRU.\n\n\nEffect of the Number of MGRU Cells (RQ4).\n\nWe study the effectiveness of utilizing several RNNs to model users' complex intentions. The performance of our models with a different number of MGRU cells is shown in Figure 10. From the figure, we can see that the performance of our models grows at first. With more RNNs, our approach can model more complex user intention which improves the performance. It seems that when the number of cells is four, our models achieve the best performance for both datasets which proves the effectiveness of utilizing multiple RNNs to  model users' complex intentions. And then it drops a little as the number of cells continues to grow which may be caused by overfitting.\n\n\nVisualization of Attention (RQ4).\n\nWe select ten samples and visualize the attention scores of items in Figure 11 to show whether different MGRUs can learn different user intentions. In the figure, the first row and the second row show attention scores of Taobao dataset and Retailrocket dataset, respectively. The figures in the two columns are results of Hard-MGRU and Soft-MGRU, respectively. The figure shows that attention scores of MGRUs vary for items. The variance of attention scores of Hard-MGRU seems larger than that of Soft-MGRU. It may be because that Hard-MGRUs have different parameters for complex interaction behaviors. It proves that Hard-MGRU is more suitable to distinguish various intentions.\n\n\nImpact of Data Sparsity (RQ5).\n\nWe further study the impact of data sparsity on the performance of our proposed methods. As our models can learn users' intentions, they should have better performance than baselines. We randomly remove some samples from the training dataset. The ratio of removed training samples ranges from 0 to 0.7. We choose two baselines, i.e., VALS and  BINN, to be compared with our models. Because BINN performs the best among all baselines and can leverage categories of items to reveal users' coarse-grained intentions to some extent. VALS utilizes behaviors of multiple types, but cannot use item category information. In other words, VALS is weak in learning users' intentions.\n\nThe experimental results in terms of HR@10 are shown in Figure 12. We can observe that our models outperform the other two methods. As the ratio of removed samples rises, the performances of all compared models drop. But the decreasing rate of our model is smaller than that of other methods. The phenomenon is very clear on the Taobao dataset. Furthermore, the performance of BINN drops slower than VALS, especially on the Retailrocket dataset. It is because that our models and BINN utilize item category information to reveal users' coarse-grained intentions. When the training dataset is sparse, they can achieve acceptable performance. In addition, our models try to predict interacted categories in the future and implicitly learn the users' intention information. As a result, our model achieves better performance than BINN which uses categories only in input.\n\n\nCONCLUSION\n\nIn this article, we propose to exploit behaviors of multiple types for next-item recommendation. Through empirical studies, we find that users have multiple coexisting category-level intentions which evolve with time. To process the multi-behavior data and mine the evolving user intentions, we offer two kinds of RNN cells, i.e., Hard-MGRU and Soft-MGRU, and design two auxiliary tasks including next item category prediction and sequence comparison. Considering the purchase intentions are complex, we propose to leverage multiple MGRUs and an attention layer to learn these coexisting intentions. Extensive experiments on two real-world datasets show that our models outperform several state-of-the-art methods.\n\nFig. 1 .\n1An example of multiple coexisting category-level intentions indicated by interaction behaviors of a user.\n\nFig. 2 .\n2Distributions of number of records that one user/item has.\n\nFig. 3 .\n3Interaction records of a user. The figure shows two kinds of behaviors including click and purchase.\n\nFig. 5 .\n5The overview of our model. Multiple MGRU networks are denoted by different colors.\n\nFig. 6 .\n6Structure of two kinds of MGRU cells. Embedding layers and item categories are omitted for simplicity.\n\nFig. 9 .\n9T-SNE embedding for item vectors produced by BINN, IARS-H and IARS-S. Items of different categories are denoted by points of different colors.\n\nFig. 10 .\n10Effect of the number of MGRU cells.\n\nFig. 11 .\n11Visualization of attention scores on MGRU cells.\n\nFig. 12 .\n12Effect of data sparsity.\n\nTable 1 .\n1Statistics of DatasetsDataset Description \nValue \nDataset \nDescription \nValue \n\nTaobao \n\n# users \n10,000 \n\nRetailrocket \n\n# users \n1,407,580 \n# items \n2,876,947 \n# items \n417,053 \n# categories \n8,916 \n# categories \n1,086 \nClick \n11,550,581 \nView \n2,664,312 \nCollect \n242,556 \nCart \n69,332 \nCart \n343,564 \nPurchase \n22,457 \nPurchase \n120,205 \n\nThis dataset contains four kinds user behaviors including click, collect, cart, and purchase. \nThe total number of all interactions is 12, 256, 906. \n\u2022 Retailrocket 2 is from a real online retail website within the time period from 2015/05/03 \nto 2015/09/18. It records three kinds of behaviors including view, cart, and purchase. The \nnumber of interactions is 2, 756, 101. \n\n\n\nTable 2 .\n2The Average KL Divergences for Different Kinds of Sequence PairsDataset \nTaobao Retailrocket \nAdjacent subsequences \n5.90 \n5.73 \nAdjacent sequences \n6.33 \n7.40 \nNonadjacent sequences \n9.42 \n7.81 \nSequences of different users \n11.56 \n13.69 \n\n\n\nTable 3 .\n3Recommendation Performance (%) of Compared MethodsK = 2 \nK = 6 \nK = 10 \nTaobao \nRetailrocket \nTaobao \nRetailrocket \nTaobao \nRetailrocket \nMethods HR NDCG HR NDCG HR NDCG HR NDCG HR NDCG HR NDCG \nBPR \n7.66 \n6.59 10.01 9.10 16.04 10.14 17.05 12.03 21.67 11.89 21.93 13.53 \nGRU \n9.89 \n8.50 10.30 9.65 21.13 13.28 18.27 12.45 29.71 16.00 23.23 14.36 \n\nCMF \n11.42 10.15 10.39 10.28 20.53 13.99 21.74 13.63 26.70 15.92 31.04 16.54 \nMC-BPR 12.01 10.09 19.53 17.10 24.21 15.32 33.96 23.37 32.64 17.94 41.93 25.87 \nVALS 17.27 15.05 28.20 25.03 30.64 20.71 44.26 31.94 39.94 23.60 52.98 34.65 \nNMTR 12.24 10.73 26.80 23.87 25.02 16.13 41.66 30.22 33.27 18.71 50.41 32.95 \nAIR \n23.63 19.08 34.90 33.01 35.87 25.90 50.56 40.05 43.69 28.93 60.13 42.15 \nASLI \n21.86 20.19 41.65 38.62 36.26 27.54 55.27 44.60 44.24 30.27 64.23 46.98 \nATRank 25.88 22.75 36.86 35.73 37.53 28.57 53.63 42.46 44.59 31.11 64.13 45.25 \nMCPRN 27.53 25.64 30.71 29.44 39.68 31.14 49.69 38.28 46.21 33.28 61.06 42.07 \nBINN 28.71 26.58 35.64 34.18 39.45 32.72 52.28 41.51 45.99 35.62 62.31 43.70 \nHGN 25.52 23.81 38.27 34.61 38.98 29.58 55.74 42.15 46.55 32.10 63.05 44.43 \n\nIARS-H 32.61 32.52 43.14 40.46 43.17 36.56 57.19 46.46 49.39 38.15 65.17 48.95 \nIARS-S 36.10 33.64 47.70 44.86 45.12 37.54 60.51 50.39 50.43 39.20 67.16 52.48 \n\n\n\nTable 4 .\n4Recommendation Performance with Non-Sampled Evaluation Metrics (k = 10) Fig. 7. Effect of auxiliary behaviors.Taobao \nRetailrocket \nMethods Precision Recall \nNDCG Precision Recall \nNDCG \nATRank 0.0234 \n0.0250 0.0318 0.0209 \n0.0470 0.0403 \nMCPRN 0.0256 \n0.0281 0.0315 0.0194 \n0.0459 0.0367 \nBINN \n0.0279 \n0.0317 0.0345 0.0211 \n0.0566 0.0497 \nHGN \n0.0276 \n0.0286 0.0387 0.0201 \n0.0647 0.0540 \nIARS-H \n0.0301 \n0.0341 0.0363 0.0239 \n0.0826 0.0565 \nIARS-S \n0.0349 \n0.0388 0.0401 0.0253 \n0.0830 0.0601 \n\n\nACM Transactions on Information Systems, Vol. 39, No. 3, Article 23. Publication date: May 2021.\nhttps://tianchi.aliyun.com/dataset/dataDetail?dataId=46. ACM Transactions on Information Systems, Vol. 39, No. 3, Article 23. Publication date: May 2021.\nhttps://www.kaggle.com/retailrocket/ecommerce-dataset. ACM Transactions on Information Systems, Vol. 39, No. 3, Article 23. Publication date: May 2021.\nhttps://www.tensorflow.org/. 4 https://github.com/jinze1994/ATRank. ACM Transactions on Information Systems, Vol. 39, No. 3, Article 23. Publication date: May 2021.\nhttps://github.com/allenjack/HGN.\n\nRepresentation learning: A review and new perspectives. Yoshua Bengio, Aaron Courville, Pascal Vincent, IEEE Transactions on Pattern Analysis and Machine Intelligence. 35Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence 35, 8 (2013), 1798-1828.\n\nOn the expressive power of deep architectures. Yoshua Bengio, Olivier Delalleau, International Conference on Algorithmic Learning Theory. Yoshua Bengio and Olivier Delalleau. 2011. On the expressive power of deep architectures. In International Conference on Algorithmic Learning Theory. 18-36.\n\nBehavior2Vec: Generating distributed representations of users' behaviors on products for recommender systems. Hung-Hsuan Chen, TKDD. 1243Hung-Hsuan Chen. 2018. Behavior2Vec: Generating distributed representations of users' behaviors on products for recommender systems. TKDD 12, 4 (2018), 43.\n\nAIR: Attentional intention-aware recommender systems. Tong Chen, Hongzhi Yin, Hongxu Chen, Rui Yan, Quoc Viet Hung, Xue Nguyen, Li, Tong Chen, Hongzhi Yin, Hongxu Chen, Rui Yan, Quoc Viet Hung Nguyen, and Xue Li. 2019. AIR: Attentional intention-aware recommender systems. In ICDE. 304-315.\n\nAdversarial multi-criteria learning for chinese word segmentation. Xinchi Chen, Zhan Shi, Xipeng Qiu, Xuanjing Huang, arXiv:1704.07556arXiv preprintXinchi Chen, Zhan Shi, Xipeng Qiu, and Xuanjing Huang. 2017. Adversarial multi-criteria learning for chinese word segmentation. arXiv preprint arXiv:1704.07556 (2017).\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.04805Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprintJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).\n\nImproving implicit recommender systems with view data. Jingtao Ding, Guanghui Yu, Xiangnan He, Yuhan Quan, Yong Li, Tat-Seng Chua, Depeng Jin, Jiajie Yu, Jingtao Ding, Guanghui Yu, Xiangnan He, Yuhan Quan, Yong Li, Tat-Seng Chua, Depeng Jin, and Jiajie Yu. 2018. Improving implicit recommender systems with view data. In IJCAI. 3343-3349.\n\nA multi-view deep learning approach for cross domain user modeling in recommendation systems. Ali Mamdouh Elkahky, Yang Song, Xiaodong He, Ali Mamdouh Elkahky, Yang Song, and Xiaodong He. 2015. A multi-view deep learning approach for cross domain user modeling in recommendation systems. In WWW. 278-288.\n\nNeural multi-task recommendation from multi-behavior data. Chen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, Fuli Feng, Yong Li, Tat-Seng Chua, and Depeng Jin. Chen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, Fuli Feng, Yong Li, Tat-Seng Chua, and Depeng Jin. 2019. Neural multi-task recommendation from multi-behavior data. In ICDE. 1554-1557.\n\nXiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Neural collaborative filtering. In WWW. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In WWW. 173-182.\n\nTracking the world state with recurrent entity networks. Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, Yann Lecun, ICLR. Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, and Yann LeCun. 2017. Tracking the world state with recurrent entity networks. In ICLR.\n\nBal\u00e1zs Hidasi, Alexandros Karatzoglou, arXiv:1511.06939Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprintBal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015).\n\nImproving entity recommendation with search log and multi-task learning. Jizhou Huang, Wei Zhang, Yaming Sun, Haifeng Wang, Ting Liu, IJCAI. Jizhou Huang, Wei Zhang, Yaming Sun, Haifeng Wang, and Ting Liu. 2018. Improving entity recommendation with search log and multi-task learning. In IJCAI. 4107-4114.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, ICLR. Diederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In ICLR.\n\nImagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, NIPS. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. Imagenet classification with deep convolutional neural networks. In NIPS. 1097-1105.\n\nMultirelational matrix factorization using bayesian personalized ranking for social network data. Artus Krohn-Grimberghe, Lucas Drumond, Christoph Freudenthaler, Lars Schmidt-Thieme, WSDM. Artus Krohn-Grimberghe, Lucas Drumond, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2012. Multi- relational matrix factorization using bayesian personalized ranking for social network data. In WSDM. 173-182.\n\nLearning from history and present: Next-item recommendation via discriminatively exploiting user behaviors. Zhi Li, Hongke Zhao, Qi Liu, Zhenya Huang, Tao Mei, Enhong Chen, SIGKDD. Zhi Li, Hongke Zhao, Qi Liu, Zhenya Huang, Tao Mei, and Enhong Chen. 2018. Learning from history and present: Next-item recommendation via discriminatively exploiting user behaviors. In SIGKDD. 1734-1743.\n\nBayesian personalized ranking with multichannel user feedback. Babak Loni, Roberto Pagano, Martha Larson, Alan Hanjalic, Proceedings of the 10th ACM Conference on Recommender Systems. the 10th ACM Conference on Recommender SystemsBabak Loni, Roberto Pagano, Martha Larson, and Alan Hanjalic. 2016. Bayesian personalized ranking with multi- channel user feedback. In Proceedings of the 10th ACM Conference on Recommender Systems. 361-364.\n\nTop-N recommendation with multi-channel positive feedback using factorization machines. Babak Loni, Roberto Pagano, Martha Larson, Alan Hanjalic, ACM Trans. Inf. Syst. 3723Babak Loni, Roberto Pagano, Martha Larson, and Alan Hanjalic. 2019. Top-N recommendation with multi-channel positive feedback using factorization machines. ACM Trans. Inf. Syst. 37, 2 (2019), 15:1-15:23.\n\nHierarchical gating networks for sequential recommendation. Chen Ma, Peng Kang, Xue Liu, SIGKDD. Chen Ma, Peng Kang, and Xue Liu. 2019. Hierarchical gating networks for sequential recommendation. In SIGKDD. 825-833.\n\nVisualizing data using t-SNE. Laurens Van Der Maaten, Geoffrey Hinton, Journal of Machine Learning Research. 9Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. Journal of Machine Learning Re- search 9, Nov (2008), 2579-2605.\n\nPerceive your users in depth: Learning universal user representations from multiple e-commerce tasks. Yabo Ni, Dan Ou, Shichen Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, Luo Si, SIGKDD. Yabo Ni, Dan Ou, Shichen Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, and Luo Si. 2018. Perceive your users in depth: Learning universal user representations from multiple e-commerce tasks. In SIGKDD. 596-605.\n\nBPRH: Bayesian personalized ranking for heterogeneous implicit feedback. Huihuai Qiu, Yun Liu, Guibing Guo, Zhu Sun, Jie Zhang, Hai Thanh Nguyen, Information Sciences. 453Huihuai Qiu, Yun Liu, Guibing Guo, Zhu Sun, Jie Zhang, and Hai Thanh Nguyen. 2018. BPRH: Bayesian personalized ranking for heterogeneous implicit feedback. Information Sciences 453 (2018), 80-98.\n\nBPR: Bayesian personalized ranking from implicit feedback. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, 25th Conference on Uncertainty in Artificial Intelligence. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In 25th Conference on Uncertainty in Artificial Intelligence. 452-461.\n\nMulti-task learning in deep neural networks for improved phoneme recognition. L Michael, Jasha Seltzer, Droppo, IEEE International Conference on Acoustics, Speech and Signal Processing. Michael L. Seltzer and Jasha Droppo. 2013. Multi-task learning in deep neural networks for improved phoneme recog- nition. In IEEE International Conference on Acoustics, Speech and Signal Processing. 6965-6969.\n\nRelational learning via collective matrix factorization. P Ajit, Geoffrey J Singh, Gordon, SIGKDD. Ajit P. Singh and Geoffrey J. Gordon. 2008. Relational learning via collective matrix factorization. In SIGKDD. 650-658.\n\nBERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, Peng Jiang, CIKM. Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recom- mendation with bidirectional encoder representations from transformer. In CIKM. 1441-1450.\n\nAttentive sequential models of latent intent for next item recommendation. Congzhe Md Mehrab Tanjim, Ethan Su, Diane Benjamin, Liangjie Hu, Julian Hong, Mcauley, Md Mehrab Tanjim, Congzhe Su, Ethan Benjamin, Diane Hu, Liangjie Hong, and Julian McAuley. 2020. Attentive sequential models of latent intent for next item recommendation. In WWW. 2528-2534.\n\nItem recommendation on monotonic behavior chains. Mengting Wan, Julian J Mcauley, RecSys. Mengting Wan and Julian J. McAuley. 2018. Item recommendation on monotonic behavior chains. In RecSys. 86-94.\n\nMulti-task feature learning for knowledge graph enhanced recommendation. Hongwei Wang, Fuzheng Zhang, Miao Zhao, Wenjie Li, Xing Xie, Minyi Guo, Hongwei Wang, Fuzheng Zhang, Miao Zhao, Wenjie Li, Xing Xie, and Minyi Guo. 2019. Multi-task feature learning for knowledge graph enhanced recommendation. In WWW. 2000-2010.\n\nModeling multipurpose sessions for next-item recommendations via mixture-channel purpose routing networks. Shoujin Wang, Liang Hu, Yan Wang, Z Quan, Mehmet A Sheng, Longbing Orgun, Cao, IJCAI. Shoujin Wang, Liang Hu, Yan Wang, Quan Z. Sheng, Mehmet A. Orgun, and Longbing Cao. 2019. Modeling multi- purpose sessions for next-item recommendations via mixture-channel purpose routing networks. In IJCAI. 3771- 3777.\n\nNext item recommendation with self-attentive metric learning. Shuai Zhang, Yi Tay, Lina Yao, Aixin Sun, Jake An, AAAI Workshop on Recommender Systems and Natural Language Processing. 9Shuai Zhang, Yi Tay, Lina Yao, Aixin Sun, and Jake An. 2019. Next item recommendation with self-attentive metric learning. In AAAI Workshop on Recommender Systems and Natural Language Processing, Vol. 9.\n\nFacial landmark detection by deep multi-task learning. Zhanpeng Zhang, Ping Luo, Chen Change Loy, Xiaoou Tang, European Conference on Computer Vision. Zhanpeng Zhang, Ping Luo, Chen Change Loy, and Xiaoou Tang. 2014. Facial landmark detection by deep multi-task learning. In European Conference on Computer Vision. 94-108.\n\nImproving user topic interest profiles by behavior factorization. Zhe Zhao, Zhiyuan Cheng, Lichan Hong, Ed H Chi, Zhe Zhao, Zhiyuan Cheng, Lichan Hong, and Ed H. Chi. 2015. Improving user topic interest profiles by behavior factorization. In WWW. 1406-1416.\n\nATRank: An attention-based user behavior modeling framework for recommendation. Chang Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao Zhao, Xiusi Chen, Jun Gao, AAAI. Chang Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao Zhao, Xiusi Chen, and Jun Gao. 2018. ATRank: An attention-based user behavior modeling framework for recommendation. In AAAI. 4564-4571.\n\nQuery-based interactive recommendation by meta-path and adapted attention-GRU. Yu Zhu, Yu Gong, Qingwen Liu, Yingcai Ma, Wenwu Ou, Junxiong Zhu, Beidou Wang, Ziyu Guan, Deng Cai, CIKM. Yu Zhu, Yu Gong, Qingwen Liu, Yingcai Ma, Wenwu Ou, Junxiong Zhu, Beidou Wang, Ziyu Guan, and Deng Cai. 2019. Query-based interactive recommendation by meta-path and adapted attention-GRU. In CIKM. 2585-2593.\n\nA brand-level ranking system with the customized attention-GRU model. Yu Zhu, Junxiong Zhu, Jie Hou, Yongliang Li, Beidou Wang, Ziyu Guan, Deng Cai, Yu Zhu, Junxiong Zhu, Jie Hou, Yongliang Li, Beidou Wang, Ziyu Guan, and Deng Cai. 2018. A brand-level ranking system with the customized attention-GRU model. In IJCAI. 3947-3953.\n", "annotations": {"author": "[{\"start\":\"101\",\"end\":\"142\"},{\"start\":\"143\",\"end\":\"186\"},{\"start\":\"187\",\"end\":\"228\"},{\"start\":\"229\",\"end\":\"270\"},{\"start\":\"271\",\"end\":\"314\"},{\"start\":\"315\",\"end\":\"356\"}]", "publisher": null, "author_last_name": "[{\"start\":\"107\",\"end\":\"109\"},{\"start\":\"150\",\"end\":\"153\"},{\"start\":\"193\",\"end\":\"195\"},{\"start\":\"235\",\"end\":\"237\"},{\"start\":\"278\",\"end\":\"281\"}]", "author_first_name": "[{\"start\":\"101\",\"end\":\"106\"},{\"start\":\"143\",\"end\":\"149\"},{\"start\":\"187\",\"end\":\"192\"},{\"start\":\"229\",\"end\":\"234\"},{\"start\":\"271\",\"end\":\"277\"},{\"start\":\"315\",\"end\":\"320\"},{\"start\":\"321\",\"end\":\"323\"}]", "author_affiliation": "[{\"start\":\"111\",\"end\":\"141\"},{\"start\":\"155\",\"end\":\"185\"},{\"start\":\"197\",\"end\":\"227\"},{\"start\":\"239\",\"end\":\"269\"},{\"start\":\"283\",\"end\":\"313\"},{\"start\":\"325\",\"end\":\"355\"}]", "title": "[{\"start\":\"1\",\"end\":\"84\"},{\"start\":\"357\",\"end\":\"440\"}]", "venue": "[{\"start\":\"442\",\"end\":\"462\"}]", "abstract": "[{\"start\":\"711\",\"end\":\"2078\"}]", "bib_ref": "[{\"start\":\"2936\",\"end\":\"2939\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"2939\",\"end\":\"2941\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"2941\",\"end\":\"2944\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"2944\",\"end\":\"2947\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"3236\",\"end\":\"3240\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"3240\",\"end\":\"3243\",\"attributes\":{\"ref_id\":\"b34\"}},{\"start\":\"8847\",\"end\":\"8851\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"8851\",\"end\":\"8854\",\"attributes\":{\"ref_id\":\"b31\"}},{\"start\":\"8866\",\"end\":\"8870\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"9105\",\"end\":\"9109\",\"attributes\":{\"ref_id\":\"b31\"}},{\"start\":\"9428\",\"end\":\"9432\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"9650\",\"end\":\"9654\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"10346\",\"end\":\"10349\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"10349\",\"end\":\"10352\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"10352\",\"end\":\"10355\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"10355\",\"end\":\"10358\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"10442\",\"end\":\"10446\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"10446\",\"end\":\"10449\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"10449\",\"end\":\"10452\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"10471\",\"end\":\"10475\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"10702\",\"end\":\"10706\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"10706\",\"end\":\"10709\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"10735\",\"end\":\"10739\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"10888\",\"end\":\"10892\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"11093\",\"end\":\"11096\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"11096\",\"end\":\"11098\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"11098\",\"end\":\"11101\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"11101\",\"end\":\"11104\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"11118\",\"end\":\"11122\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"11280\",\"end\":\"11284\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"11457\",\"end\":\"11461\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"11693\",\"end\":\"11697\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"11853\",\"end\":\"11856\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"11966\",\"end\":\"11969\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"12090\",\"end\":\"12093\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"12427\",\"end\":\"12431\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"12575\",\"end\":\"12578\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"12881\",\"end\":\"12885\",\"attributes\":{\"ref_id\":\"b34\"}},{\"start\":\"13190\",\"end\":\"13194\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"13592\",\"end\":\"13596\",\"attributes\":{\"ref_id\":\"b35\"}},{\"start\":\"13867\",\"end\":\"13871\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"14336\",\"end\":\"14339\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"14662\",\"end\":\"14665\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"14800\",\"end\":\"14803\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"15196\",\"end\":\"15200\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"15415\",\"end\":\"15419\",\"attributes\":{\"ref_id\":\"b32\"}},{\"start\":\"15656\",\"end\":\"15660\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"15660\",\"end\":\"15663\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"15677\",\"end\":\"15681\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"15871\",\"end\":\"15875\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"16036\",\"end\":\"16039\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"16403\",\"end\":\"16406\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"16406\",\"end\":\"16409\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"16422\",\"end\":\"16426\",\"attributes\":{\"ref_id\":\"b36\"}},{\"start\":\"19303\",\"end\":\"19306\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"27095\",\"end\":\"27099\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"35990\",\"end\":\"35993\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"37946\",\"end\":\"37950\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"38542\",\"end\":\"38545\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"38545\",\"end\":\"38547\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"38796\",\"end\":\"38799\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"38799\",\"end\":\"38801\"},{\"start\":\"39819\",\"end\":\"39823\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"41501\",\"end\":\"41504\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"41504\",\"end\":\"41507\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"42122\",\"end\":\"42126\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"42178\",\"end\":\"42181\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"42972\",\"end\":\"42976\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"43158\",\"end\":\"43162\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"43289\",\"end\":\"43293\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"43375\",\"end\":\"43379\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"43474\",\"end\":\"43477\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"43625\",\"end\":\"43628\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"43797\",\"end\":\"43800\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"44137\",\"end\":\"44141\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"44420\",\"end\":\"44424\",\"attributes\":{\"ref_id\":\"b34\"}},{\"start\":\"44580\",\"end\":\"44584\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"44921\",\"end\":\"44925\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"45121\",\"end\":\"45125\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"45404\",\"end\":\"45405\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"45576\",\"end\":\"45579\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"45579\",\"end\":\"45581\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"45581\",\"end\":\"45584\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"46435\",\"end\":\"46436\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"46934\",\"end\":\"46938\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"47613\",\"end\":\"47614\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"48250\",\"end\":\"48253\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"48253\",\"end\":\"48255\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"48255\",\"end\":\"48258\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"52588\",\"end\":\"52592\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"55174\",\"end\":\"55178\",\"attributes\":{\"ref_id\":\"b20\"}}]", "figure": "[{\"start\":\"59652\",\"end\":\"59768\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"59769\",\"end\":\"59838\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"59839\",\"end\":\"59950\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"59951\",\"end\":\"60044\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"60045\",\"end\":\"60158\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"60159\",\"end\":\"60312\",\"attributes\":{\"id\":\"fig_5\"}},{\"start\":\"60313\",\"end\":\"60361\",\"attributes\":{\"id\":\"fig_6\"}},{\"start\":\"60362\",\"end\":\"60423\",\"attributes\":{\"id\":\"fig_7\"}},{\"start\":\"60424\",\"end\":\"60461\",\"attributes\":{\"id\":\"fig_9\"}},{\"start\":\"60462\",\"end\":\"61194\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"61195\",\"end\":\"61448\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"61449\",\"end\":\"62756\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}},{\"start\":\"62757\",\"end\":\"63267\",\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"2094\",\"end\":\"2546\"},{\"start\":\"2548\",\"end\":\"3513\"},{\"start\":\"3515\",\"end\":\"4857\"},{\"start\":\"4859\",\"end\":\"5172\"},{\"start\":\"5174\",\"end\":\"6011\"},{\"start\":\"6013\",\"end\":\"7393\"},{\"start\":\"7395\",\"end\":\"7463\"},{\"start\":\"7465\",\"end\":\"8255\"},{\"start\":\"8257\",\"end\":\"8610\"},{\"start\":\"8659\",\"end\":\"10177\"},{\"start\":\"10179\",\"end\":\"11011\"},{\"start\":\"11013\",\"end\":\"12238\"},{\"start\":\"12240\",\"end\":\"13851\"},{\"start\":\"13853\",\"end\":\"14208\"},{\"start\":\"14232\",\"end\":\"15578\"},{\"start\":\"15580\",\"end\":\"16473\"},{\"start\":\"16491\",\"end\":\"16655\"},{\"start\":\"16673\",\"end\":\"16982\"},{\"start\":\"16984\",\"end\":\"17535\"},{\"start\":\"17537\",\"end\":\"17837\"},{\"start\":\"17839\",\"end\":\"17969\"},{\"start\":\"17971\",\"end\":\"18697\"},{\"start\":\"18699\",\"end\":\"18810\"},{\"start\":\"18860\",\"end\":\"18956\"},{\"start\":\"18958\",\"end\":\"19418\"},{\"start\":\"19496\",\"end\":\"19574\"},{\"start\":\"19655\",\"end\":\"20406\"},{\"start\":\"20408\",\"end\":\"20455\"},{\"start\":\"20457\",\"end\":\"21902\"},{\"start\":\"21904\",\"end\":\"22191\"},{\"start\":\"22193\",\"end\":\"22467\"},{\"start\":\"22524\",\"end\":\"22705\"},{\"start\":\"22728\",\"end\":\"22958\"},{\"start\":\"22960\",\"end\":\"23321\"},{\"start\":\"23423\",\"end\":\"23879\"},{\"start\":\"23881\",\"end\":\"23928\"},{\"start\":\"24003\",\"end\":\"24112\"},{\"start\":\"24157\",\"end\":\"24385\"},{\"start\":\"24406\",\"end\":\"25295\"},{\"start\":\"25297\",\"end\":\"25979\"},{\"start\":\"25981\",\"end\":\"26860\"},{\"start\":\"26888\",\"end\":\"27338\"},{\"start\":\"27340\",\"end\":\"28213\"},{\"start\":\"28215\",\"end\":\"28536\"},{\"start\":\"28551\",\"end\":\"28757\"},{\"start\":\"28759\",\"end\":\"28961\"},{\"start\":\"28999\",\"end\":\"29516\"},{\"start\":\"29577\",\"end\":\"30084\"},{\"start\":\"30086\",\"end\":\"31409\"},{\"start\":\"31614\",\"end\":\"32179\"},{\"start\":\"32181\",\"end\":\"32422\"},{\"start\":\"32443\",\"end\":\"32730\"},{\"start\":\"32929\",\"end\":\"33461\"},{\"start\":\"33490\",\"end\":\"33813\"},{\"start\":\"33860\",\"end\":\"34848\"},{\"start\":\"34850\",\"end\":\"35309\"},{\"start\":\"35351\",\"end\":\"35427\"},{\"start\":\"35495\",\"end\":\"35683\"},{\"start\":\"35716\",\"end\":\"36549\"},{\"start\":\"36576\",\"end\":\"36697\"},{\"start\":\"36730\",\"end\":\"37301\"},{\"start\":\"37368\",\"end\":\"37746\"},{\"start\":\"37771\",\"end\":\"37951\"},{\"start\":\"37964\",\"end\":\"38021\"},{\"start\":\"38075\",\"end\":\"38200\"},{\"start\":\"38231\",\"end\":\"39219\"},{\"start\":\"39221\",\"end\":\"39287\"},{\"start\":\"39354\",\"end\":\"39624\"},{\"start\":\"39663\",\"end\":\"39824\"},{\"start\":\"39840\",\"end\":\"39960\"},{\"start\":\"39962\",\"end\":\"40450\"},{\"start\":\"40506\",\"end\":\"41385\"},{\"start\":\"41413\",\"end\":\"42267\"},{\"start\":\"42269\",\"end\":\"42501\"},{\"start\":\"42503\",\"end\":\"42890\"},{\"start\":\"42905\",\"end\":\"42964\"},{\"start\":\"42966\",\"end\":\"43150\"},{\"start\":\"43152\",\"end\":\"43364\"},{\"start\":\"43366\",\"end\":\"45333\"},{\"start\":\"45362\",\"end\":\"48014\"},{\"start\":\"48071\",\"end\":\"48359\"},{\"start\":\"48361\",\"end\":\"50852\"},{\"start\":\"50854\",\"end\":\"52411\"},{\"start\":\"52413\",\"end\":\"53176\"},{\"start\":\"53178\",\"end\":\"53427\"},{\"start\":\"53467\",\"end\":\"54175\"},{\"start\":\"54212\",\"end\":\"54928\"},{\"start\":\"54972\",\"end\":\"55919\"},{\"start\":\"55965\",\"end\":\"56627\"},{\"start\":\"56665\",\"end\":\"57344\"},{\"start\":\"57379\",\"end\":\"58052\"},{\"start\":\"58054\",\"end\":\"58922\"},{\"start\":\"58937\",\"end\":\"59651\"}]", "formula": "[{\"start\":\"18811\",\"end\":\"18859\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"19419\",\"end\":\"19495\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"19575\",\"end\":\"19654\",\"attributes\":{\"id\":\"formula_2\"}},{\"start\":\"22468\",\"end\":\"22523\",\"attributes\":{\"id\":\"formula_3\"}},{\"start\":\"23322\",\"end\":\"23422\",\"attributes\":{\"id\":\"formula_4\"}},{\"start\":\"23929\",\"end\":\"24002\",\"attributes\":{\"id\":\"formula_5\"}},{\"start\":\"28962\",\"end\":\"28980\",\"attributes\":{\"id\":\"formula_6\"}},{\"start\":\"28980\",\"end\":\"28998\",\"attributes\":{\"id\":\"formula_7\"}},{\"start\":\"29517\",\"end\":\"29576\",\"attributes\":{\"id\":\"formula_8\"}},{\"start\":\"31410\",\"end\":\"31453\",\"attributes\":{\"id\":\"formula_9\"}},{\"start\":\"31453\",\"end\":\"31496\",\"attributes\":{\"id\":\"formula_10\"}},{\"start\":\"31496\",\"end\":\"31541\",\"attributes\":{\"id\":\"formula_11\"}},{\"start\":\"31541\",\"end\":\"31583\",\"attributes\":{\"id\":\"formula_12\"}},{\"start\":\"31583\",\"end\":\"31600\",\"attributes\":{\"id\":\"formula_13\"}},{\"start\":\"32423\",\"end\":\"32442\",\"attributes\":{\"id\":\"formula_14\"}},{\"start\":\"32731\",\"end\":\"32775\",\"attributes\":{\"id\":\"formula_15\"}},{\"start\":\"32775\",\"end\":\"32819\",\"attributes\":{\"id\":\"formula_16\"}},{\"start\":\"32819\",\"end\":\"32867\",\"attributes\":{\"id\":\"formula_17\"}},{\"start\":\"32867\",\"end\":\"32910\",\"attributes\":{\"id\":\"formula_18\"}},{\"start\":\"32910\",\"end\":\"32928\",\"attributes\":{\"id\":\"formula_19\"}},{\"start\":\"35310\",\"end\":\"35350\",\"attributes\":{\"id\":\"formula_20\"}},{\"start\":\"35428\",\"end\":\"35461\",\"attributes\":{\"id\":\"formula_21\"}},{\"start\":\"35461\",\"end\":\"35494\",\"attributes\":{\"id\":\"formula_22\"}},{\"start\":\"36550\",\"end\":\"36575\",\"attributes\":{\"id\":\"formula_23\"}},{\"start\":\"37302\",\"end\":\"37327\",\"attributes\":{\"id\":\"formula_24\"}},{\"start\":\"37327\",\"end\":\"37348\",\"attributes\":{\"id\":\"formula_25\"}},{\"start\":\"37348\",\"end\":\"37367\",\"attributes\":{\"id\":\"formula_26\"}},{\"start\":\"37747\",\"end\":\"37770\",\"attributes\":{\"id\":\"formula_27\"}},{\"start\":\"38022\",\"end\":\"38074\",\"attributes\":{\"id\":\"formula_28\"}},{\"start\":\"38201\",\"end\":\"38230\",\"attributes\":{\"id\":\"formula_29\"}},{\"start\":\"39288\",\"end\":\"39353\",\"attributes\":{\"id\":\"formula_30\"}},{\"start\":\"39625\",\"end\":\"39662\",\"attributes\":{\"id\":\"formula_31\"}}]", "table_ref": "[{\"start\":\"16919\",\"end\":\"16926\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"17210\",\"end\":\"17217\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"22611\",\"end\":\"22618\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"48185\",\"end\":\"48192\",\"attributes\":{\"ref_id\":\"tab_3\"}},{\"start\":\"53261\",\"end\":\"53268\",\"attributes\":{\"ref_id\":\"tab_4\"}},{\"start\":\"53870\",\"end\":\"53877\",\"attributes\":{\"ref_id\":\"tab_3\"}}]", "section_header": "[{\"start\":\"2080\",\"end\":\"2092\",\"attributes\":{\"n\":\"1\"}},{\"start\":\"8613\",\"end\":\"8625\",\"attributes\":{\"n\":\"2\"}},{\"start\":\"8628\",\"end\":\"8657\",\"attributes\":{\"n\":\"2.1\"}},{\"start\":\"14211\",\"end\":\"14230\",\"attributes\":{\"n\":\"2.2\"}},{\"start\":\"16476\",\"end\":\"16489\",\"attributes\":{\"n\":\"3\"}},{\"start\":\"16658\",\"end\":\"16671\",\"attributes\":{\"n\":\"3.1\"}},{\"start\":\"22708\",\"end\":\"22726\",\"attributes\":{\"n\":\"3.2\"}},{\"start\":\"24115\",\"end\":\"24155\",\"attributes\":{\"n\":\"4\"}},{\"start\":\"24388\",\"end\":\"24404\",\"attributes\":{\"n\":\"4.1\"}},{\"start\":\"26863\",\"end\":\"26886\",\"attributes\":{\"n\":\"4.2\"}},{\"start\":\"28539\",\"end\":\"28549\",\"attributes\":{\"n\":\"4.2.1\"}},{\"start\":\"31602\",\"end\":\"31612\",\"attributes\":{\"n\":\"4.2.2\"}},{\"start\":\"33464\",\"end\":\"33488\",\"attributes\":{\"n\":\"4.3\"}},{\"start\":\"33816\",\"end\":\"33858\",\"attributes\":{\"n\":\"4.3.1\"}},{\"start\":\"35686\",\"end\":\"35714\",\"attributes\":{\"n\":\"4.3.2\"}},{\"start\":\"36700\",\"end\":\"36728\",\"attributes\":{\"n\":\"4.3.3\"}},{\"start\":\"37954\",\"end\":\"37962\",\"attributes\":{\"n\":\"4.4\"}},{\"start\":\"39827\",\"end\":\"39838\",\"attributes\":{\"n\":\"5\"}},{\"start\":\"40453\",\"end\":\"40474\",\"attributes\":{\"n\":\"5.1\"}},{\"start\":\"40477\",\"end\":\"40504\",\"attributes\":{\"n\":\"5.1.1\"}},{\"start\":\"41388\",\"end\":\"41411\",\"attributes\":{\"n\":\"5.1.2\"}},{\"start\":\"42893\",\"end\":\"42903\",\"attributes\":{\"n\":\"5.1.3\"}},{\"start\":\"45336\",\"end\":\"45360\",\"attributes\":{\"n\":\"5.1.4\"}},{\"start\":\"48017\",\"end\":\"48037\",\"attributes\":{\"n\":\"5.2\"}},{\"start\":\"48040\",\"end\":\"48069\",\"attributes\":{\"n\":\"5.2.1\"}},{\"start\":\"53430\",\"end\":\"53465\",\"attributes\":{\"n\":\"5.2.2\"}},{\"start\":\"54178\",\"end\":\"54210\",\"attributes\":{\"n\":\"5.2.3\"}},{\"start\":\"54931\",\"end\":\"54970\",\"attributes\":{\"n\":\"5.2.4\"}},{\"start\":\"55922\",\"end\":\"55963\",\"attributes\":{\"n\":\"5.2.5\"}},{\"start\":\"56630\",\"end\":\"56663\",\"attributes\":{\"n\":\"5.2.6\"}},{\"start\":\"57347\",\"end\":\"57377\",\"attributes\":{\"n\":\"5.2.7\"}},{\"start\":\"58925\",\"end\":\"58935\",\"attributes\":{\"n\":\"6\"}},{\"start\":\"59653\",\"end\":\"59661\"},{\"start\":\"59770\",\"end\":\"59778\"},{\"start\":\"59840\",\"end\":\"59848\"},{\"start\":\"59952\",\"end\":\"59960\"},{\"start\":\"60046\",\"end\":\"60054\"},{\"start\":\"60160\",\"end\":\"60168\"},{\"start\":\"60314\",\"end\":\"60323\"},{\"start\":\"60363\",\"end\":\"60372\"},{\"start\":\"60425\",\"end\":\"60434\"},{\"start\":\"60463\",\"end\":\"60472\"},{\"start\":\"61196\",\"end\":\"61205\"},{\"start\":\"61450\",\"end\":\"61459\"},{\"start\":\"62758\",\"end\":\"62767\"}]", "table": "[{\"start\":\"60496\",\"end\":\"61194\"},{\"start\":\"61271\",\"end\":\"61448\"},{\"start\":\"61511\",\"end\":\"62756\"},{\"start\":\"62879\",\"end\":\"63267\"}]", "figure_caption": "[{\"start\":\"59663\",\"end\":\"59768\"},{\"start\":\"59780\",\"end\":\"59838\"},{\"start\":\"59850\",\"end\":\"59950\"},{\"start\":\"59962\",\"end\":\"60044\"},{\"start\":\"60056\",\"end\":\"60158\"},{\"start\":\"60170\",\"end\":\"60312\"},{\"start\":\"60326\",\"end\":\"60361\"},{\"start\":\"60375\",\"end\":\"60423\"},{\"start\":\"60437\",\"end\":\"60461\"},{\"start\":\"60474\",\"end\":\"60496\"},{\"start\":\"61207\",\"end\":\"61271\"},{\"start\":\"61461\",\"end\":\"61511\"},{\"start\":\"62769\",\"end\":\"62879\"}]", "figure_ref": "[{\"start\":\"4266\",\"end\":\"4274\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"17648\",\"end\":\"17656\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"18470\",\"end\":\"18478\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"20197\",\"end\":\"20205\"},{\"start\":\"20651\",\"end\":\"20657\"},{\"start\":\"25086\",\"end\":\"25094\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"28745\",\"end\":\"28753\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"31931\",\"end\":\"31939\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"53720\",\"end\":\"53728\"},{\"start\":\"54319\",\"end\":\"54327\"},{\"start\":\"55244\",\"end\":\"55252\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"55395\",\"end\":\"55401\"},{\"start\":\"56134\",\"end\":\"56143\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"56734\",\"end\":\"56743\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"58110\",\"end\":\"58119\",\"attributes\":{\"ref_id\":\"fig_0\"}}]", "bib_author_first_name": "[{\"start\":\"63927\",\"end\":\"63933\"},{\"start\":\"63942\",\"end\":\"63947\"},{\"start\":\"63959\",\"end\":\"63965\"},{\"start\":\"64291\",\"end\":\"64297\"},{\"start\":\"64306\",\"end\":\"64313\"},{\"start\":\"64650\",\"end\":\"64660\"},{\"start\":\"64888\",\"end\":\"64892\"},{\"start\":\"64899\",\"end\":\"64906\"},{\"start\":\"64912\",\"end\":\"64918\"},{\"start\":\"64925\",\"end\":\"64928\"},{\"start\":\"64934\",\"end\":\"64938\"},{\"start\":\"64950\",\"end\":\"64953\"},{\"start\":\"65193\",\"end\":\"65199\"},{\"start\":\"65206\",\"end\":\"65210\"},{\"start\":\"65216\",\"end\":\"65222\"},{\"start\":\"65228\",\"end\":\"65236\"},{\"start\":\"65443\",\"end\":\"65448\"},{\"start\":\"65457\",\"end\":\"65465\"},{\"start\":\"65473\",\"end\":\"65479\"},{\"start\":\"65485\",\"end\":\"65493\"},{\"start\":\"65867\",\"end\":\"65874\"},{\"start\":\"65881\",\"end\":\"65889\"},{\"start\":\"65894\",\"end\":\"65902\"},{\"start\":\"65907\",\"end\":\"65912\"},{\"start\":\"65919\",\"end\":\"65923\"},{\"start\":\"65928\",\"end\":\"65936\"},{\"start\":\"65943\",\"end\":\"65949\"},{\"start\":\"65955\",\"end\":\"65961\"},{\"start\":\"66246\",\"end\":\"66249\"},{\"start\":\"66267\",\"end\":\"66271\"},{\"start\":\"66278\",\"end\":\"66286\"},{\"start\":\"66517\",\"end\":\"66521\"},{\"start\":\"66527\",\"end\":\"66535\"},{\"start\":\"66540\",\"end\":\"66545\"},{\"start\":\"66551\",\"end\":\"66560\"},{\"start\":\"66567\",\"end\":\"66571\"},{\"start\":\"66578\",\"end\":\"66582\"},{\"start\":\"66805\",\"end\":\"66813\"},{\"start\":\"66818\",\"end\":\"66822\"},{\"start\":\"66829\",\"end\":\"66836\"},{\"start\":\"66844\",\"end\":\"66851\"},{\"start\":\"66857\",\"end\":\"66860\"},{\"start\":\"66865\",\"end\":\"66873\"},{\"start\":\"67112\",\"end\":\"67118\"},{\"start\":\"67127\",\"end\":\"67132\"},{\"start\":\"67141\",\"end\":\"67147\"},{\"start\":\"67155\",\"end\":\"67162\"},{\"start\":\"67171\",\"end\":\"67175\"},{\"start\":\"67337\",\"end\":\"67343\"},{\"start\":\"67352\",\"end\":\"67362\"},{\"start\":\"67767\",\"end\":\"67773\"},{\"start\":\"67781\",\"end\":\"67784\"},{\"start\":\"67792\",\"end\":\"67798\"},{\"start\":\"67804\",\"end\":\"67811\"},{\"start\":\"67818\",\"end\":\"67822\"},{\"start\":\"68045\",\"end\":\"68046\"},{\"start\":\"68057\",\"end\":\"68062\"},{\"start\":\"68239\",\"end\":\"68243\"},{\"start\":\"68256\",\"end\":\"68260\"},{\"start\":\"68272\",\"end\":\"68280\"},{\"start\":\"68281\",\"end\":\"68282\"},{\"start\":\"68544\",\"end\":\"68549\"},{\"start\":\"68568\",\"end\":\"68573\"},{\"start\":\"68583\",\"end\":\"68592\"},{\"start\":\"68608\",\"end\":\"68612\"},{\"start\":\"68957\",\"end\":\"68960\"},{\"start\":\"68965\",\"end\":\"68971\"},{\"start\":\"68978\",\"end\":\"68980\"},{\"start\":\"68986\",\"end\":\"68992\"},{\"start\":\"69000\",\"end\":\"69003\"},{\"start\":\"69009\",\"end\":\"69015\"},{\"start\":\"69299\",\"end\":\"69304\"},{\"start\":\"69311\",\"end\":\"69318\"},{\"start\":\"69327\",\"end\":\"69333\"},{\"start\":\"69342\",\"end\":\"69346\"},{\"start\":\"69763\",\"end\":\"69768\"},{\"start\":\"69775\",\"end\":\"69782\"},{\"start\":\"69791\",\"end\":\"69797\"},{\"start\":\"69806\",\"end\":\"69810\"},{\"start\":\"70112\",\"end\":\"70116\"},{\"start\":\"70121\",\"end\":\"70125\"},{\"start\":\"70132\",\"end\":\"70135\"},{\"start\":\"70299\",\"end\":\"70306\"},{\"start\":\"70323\",\"end\":\"70331\"},{\"start\":\"70627\",\"end\":\"70631\"},{\"start\":\"70636\",\"end\":\"70639\"},{\"start\":\"70644\",\"end\":\"70651\"},{\"start\":\"70657\",\"end\":\"70662\"},{\"start\":\"70667\",\"end\":\"70672\"},{\"start\":\"70677\",\"end\":\"70684\"},{\"start\":\"70691\",\"end\":\"70694\"},{\"start\":\"70985\",\"end\":\"70992\"},{\"start\":\"70998\",\"end\":\"71001\"},{\"start\":\"71007\",\"end\":\"71014\"},{\"start\":\"71020\",\"end\":\"71023\"},{\"start\":\"71029\",\"end\":\"71032\"},{\"start\":\"71040\",\"end\":\"71043\"},{\"start\":\"71044\",\"end\":\"71049\"},{\"start\":\"71339\",\"end\":\"71346\"},{\"start\":\"71355\",\"end\":\"71364\"},{\"start\":\"71380\",\"end\":\"71384\"},{\"start\":\"71394\",\"end\":\"71398\"},{\"start\":\"71769\",\"end\":\"71770\"},{\"start\":\"71780\",\"end\":\"71785\"},{\"start\":\"72146\",\"end\":\"72147\"},{\"start\":\"72154\",\"end\":\"72162\"},{\"start\":\"72163\",\"end\":\"72164\"},{\"start\":\"72407\",\"end\":\"72410\"},{\"start\":\"72416\",\"end\":\"72419\"},{\"start\":\"72425\",\"end\":\"72429\"},{\"start\":\"72434\",\"end\":\"72442\"},{\"start\":\"72448\",\"end\":\"72452\"},{\"start\":\"72458\",\"end\":\"72463\"},{\"start\":\"72468\",\"end\":\"72472\"},{\"start\":\"72764\",\"end\":\"72771\"},{\"start\":\"72790\",\"end\":\"72795\"},{\"start\":\"72800\",\"end\":\"72805\"},{\"start\":\"72816\",\"end\":\"72824\"},{\"start\":\"72829\",\"end\":\"72835\"},{\"start\":\"73093\",\"end\":\"73101\"},{\"start\":\"73107\",\"end\":\"73113\"},{\"start\":\"73114\",\"end\":\"73115\"},{\"start\":\"73317\",\"end\":\"73324\"},{\"start\":\"73331\",\"end\":\"73338\"},{\"start\":\"73346\",\"end\":\"73350\"},{\"start\":\"73357\",\"end\":\"73363\"},{\"start\":\"73368\",\"end\":\"73372\"},{\"start\":\"73378\",\"end\":\"73383\"},{\"start\":\"73671\",\"end\":\"73678\"},{\"start\":\"73685\",\"end\":\"73690\"},{\"start\":\"73695\",\"end\":\"73698\"},{\"start\":\"73705\",\"end\":\"73706\"},{\"start\":\"73713\",\"end\":\"73719\"},{\"start\":\"73720\",\"end\":\"73721\"},{\"start\":\"73729\",\"end\":\"73737\"},{\"start\":\"74041\",\"end\":\"74046\"},{\"start\":\"74054\",\"end\":\"74056\"},{\"start\":\"74062\",\"end\":\"74066\"},{\"start\":\"74072\",\"end\":\"74077\"},{\"start\":\"74083\",\"end\":\"74087\"},{\"start\":\"74423\",\"end\":\"74431\"},{\"start\":\"74439\",\"end\":\"74443\"},{\"start\":\"74449\",\"end\":\"74453\"},{\"start\":\"74454\",\"end\":\"74460\"},{\"start\":\"74466\",\"end\":\"74472\"},{\"start\":\"74758\",\"end\":\"74761\"},{\"start\":\"74768\",\"end\":\"74775\"},{\"start\":\"74783\",\"end\":\"74789\"},{\"start\":\"74796\",\"end\":\"74798\"},{\"start\":\"74799\",\"end\":\"74800\"},{\"start\":\"75031\",\"end\":\"75036\"},{\"start\":\"75043\",\"end\":\"75048\"},{\"start\":\"75054\",\"end\":\"75062\"},{\"start\":\"75069\",\"end\":\"75076\"},{\"start\":\"75082\",\"end\":\"75091\"},{\"start\":\"75098\",\"end\":\"75103\"},{\"start\":\"75110\",\"end\":\"75113\"},{\"start\":\"75403\",\"end\":\"75405\"},{\"start\":\"75411\",\"end\":\"75413\"},{\"start\":\"75420\",\"end\":\"75427\"},{\"start\":\"75433\",\"end\":\"75440\"},{\"start\":\"75445\",\"end\":\"75450\"},{\"start\":\"75455\",\"end\":\"75463\"},{\"start\":\"75469\",\"end\":\"75475\"},{\"start\":\"75482\",\"end\":\"75486\"},{\"start\":\"75493\",\"end\":\"75497\"},{\"start\":\"75789\",\"end\":\"75791\"},{\"start\":\"75797\",\"end\":\"75805\"},{\"start\":\"75811\",\"end\":\"75814\"},{\"start\":\"75820\",\"end\":\"75829\"},{\"start\":\"75834\",\"end\":\"75840\"},{\"start\":\"75847\",\"end\":\"75851\"},{\"start\":\"75858\",\"end\":\"75862\"}]", "bib_author_last_name": "[{\"start\":\"63934\",\"end\":\"63940\"},{\"start\":\"63948\",\"end\":\"63957\"},{\"start\":\"63966\",\"end\":\"63973\"},{\"start\":\"64298\",\"end\":\"64304\"},{\"start\":\"64314\",\"end\":\"64323\"},{\"start\":\"64661\",\"end\":\"64665\"},{\"start\":\"64893\",\"end\":\"64897\"},{\"start\":\"64907\",\"end\":\"64910\"},{\"start\":\"64919\",\"end\":\"64923\"},{\"start\":\"64929\",\"end\":\"64932\"},{\"start\":\"64939\",\"end\":\"64948\"},{\"start\":\"64954\",\"end\":\"64960\"},{\"start\":\"64962\",\"end\":\"64964\"},{\"start\":\"65200\",\"end\":\"65204\"},{\"start\":\"65211\",\"end\":\"65214\"},{\"start\":\"65223\",\"end\":\"65226\"},{\"start\":\"65237\",\"end\":\"65242\"},{\"start\":\"65449\",\"end\":\"65455\"},{\"start\":\"65466\",\"end\":\"65471\"},{\"start\":\"65480\",\"end\":\"65483\"},{\"start\":\"65494\",\"end\":\"65503\"},{\"start\":\"65875\",\"end\":\"65879\"},{\"start\":\"65890\",\"end\":\"65892\"},{\"start\":\"65903\",\"end\":\"65905\"},{\"start\":\"65913\",\"end\":\"65917\"},{\"start\":\"65924\",\"end\":\"65926\"},{\"start\":\"65937\",\"end\":\"65941\"},{\"start\":\"65950\",\"end\":\"65953\"},{\"start\":\"65962\",\"end\":\"65964\"},{\"start\":\"66250\",\"end\":\"66265\"},{\"start\":\"66272\",\"end\":\"66276\"},{\"start\":\"66287\",\"end\":\"66289\"},{\"start\":\"66522\",\"end\":\"66525\"},{\"start\":\"66536\",\"end\":\"66538\"},{\"start\":\"66546\",\"end\":\"66549\"},{\"start\":\"66561\",\"end\":\"66565\"},{\"start\":\"66572\",\"end\":\"66576\"},{\"start\":\"66583\",\"end\":\"66585\"},{\"start\":\"66814\",\"end\":\"66816\"},{\"start\":\"66823\",\"end\":\"66827\"},{\"start\":\"66837\",\"end\":\"66842\"},{\"start\":\"66852\",\"end\":\"66855\"},{\"start\":\"66861\",\"end\":\"66863\"},{\"start\":\"66874\",\"end\":\"66878\"},{\"start\":\"67119\",\"end\":\"67125\"},{\"start\":\"67133\",\"end\":\"67139\"},{\"start\":\"67148\",\"end\":\"67153\"},{\"start\":\"67163\",\"end\":\"67169\"},{\"start\":\"67176\",\"end\":\"67181\"},{\"start\":\"67344\",\"end\":\"67350\"},{\"start\":\"67363\",\"end\":\"67374\"},{\"start\":\"67774\",\"end\":\"67779\"},{\"start\":\"67785\",\"end\":\"67790\"},{\"start\":\"67799\",\"end\":\"67802\"},{\"start\":\"67812\",\"end\":\"67816\"},{\"start\":\"67823\",\"end\":\"67826\"},{\"start\":\"68047\",\"end\":\"68055\"},{\"start\":\"68063\",\"end\":\"68069\"},{\"start\":\"68071\",\"end\":\"68073\"},{\"start\":\"68244\",\"end\":\"68254\"},{\"start\":\"68261\",\"end\":\"68270\"},{\"start\":\"68283\",\"end\":\"68289\"},{\"start\":\"68550\",\"end\":\"68566\"},{\"start\":\"68574\",\"end\":\"68581\"},{\"start\":\"68593\",\"end\":\"68606\"},{\"start\":\"68613\",\"end\":\"68627\"},{\"start\":\"68961\",\"end\":\"68963\"},{\"start\":\"68972\",\"end\":\"68976\"},{\"start\":\"68981\",\"end\":\"68984\"},{\"start\":\"68993\",\"end\":\"68998\"},{\"start\":\"69004\",\"end\":\"69007\"},{\"start\":\"69016\",\"end\":\"69020\"},{\"start\":\"69305\",\"end\":\"69309\"},{\"start\":\"69319\",\"end\":\"69325\"},{\"start\":\"69334\",\"end\":\"69340\"},{\"start\":\"69347\",\"end\":\"69355\"},{\"start\":\"69769\",\"end\":\"69773\"},{\"start\":\"69783\",\"end\":\"69789\"},{\"start\":\"69798\",\"end\":\"69804\"},{\"start\":\"69811\",\"end\":\"69819\"},{\"start\":\"70117\",\"end\":\"70119\"},{\"start\":\"70126\",\"end\":\"70130\"},{\"start\":\"70136\",\"end\":\"70139\"},{\"start\":\"70307\",\"end\":\"70321\"},{\"start\":\"70332\",\"end\":\"70338\"},{\"start\":\"70632\",\"end\":\"70634\"},{\"start\":\"70640\",\"end\":\"70642\"},{\"start\":\"70652\",\"end\":\"70655\"},{\"start\":\"70663\",\"end\":\"70665\"},{\"start\":\"70673\",\"end\":\"70675\"},{\"start\":\"70685\",\"end\":\"70689\"},{\"start\":\"70695\",\"end\":\"70697\"},{\"start\":\"70993\",\"end\":\"70996\"},{\"start\":\"71002\",\"end\":\"71005\"},{\"start\":\"71015\",\"end\":\"71018\"},{\"start\":\"71024\",\"end\":\"71027\"},{\"start\":\"71033\",\"end\":\"71038\"},{\"start\":\"71050\",\"end\":\"71056\"},{\"start\":\"71347\",\"end\":\"71353\"},{\"start\":\"71365\",\"end\":\"71378\"},{\"start\":\"71385\",\"end\":\"71392\"},{\"start\":\"71399\",\"end\":\"71413\"},{\"start\":\"71771\",\"end\":\"71778\"},{\"start\":\"71786\",\"end\":\"71793\"},{\"start\":\"71795\",\"end\":\"71801\"},{\"start\":\"72148\",\"end\":\"72152\"},{\"start\":\"72165\",\"end\":\"72170\"},{\"start\":\"72172\",\"end\":\"72178\"},{\"start\":\"72411\",\"end\":\"72414\"},{\"start\":\"72420\",\"end\":\"72423\"},{\"start\":\"72430\",\"end\":\"72432\"},{\"start\":\"72443\",\"end\":\"72446\"},{\"start\":\"72453\",\"end\":\"72456\"},{\"start\":\"72464\",\"end\":\"72466\"},{\"start\":\"72473\",\"end\":\"72478\"},{\"start\":\"72772\",\"end\":\"72788\"},{\"start\":\"72796\",\"end\":\"72798\"},{\"start\":\"72806\",\"end\":\"72814\"},{\"start\":\"72825\",\"end\":\"72827\"},{\"start\":\"72836\",\"end\":\"72840\"},{\"start\":\"72842\",\"end\":\"72849\"},{\"start\":\"73102\",\"end\":\"73105\"},{\"start\":\"73116\",\"end\":\"73123\"},{\"start\":\"73325\",\"end\":\"73329\"},{\"start\":\"73339\",\"end\":\"73344\"},{\"start\":\"73351\",\"end\":\"73355\"},{\"start\":\"73364\",\"end\":\"73366\"},{\"start\":\"73373\",\"end\":\"73376\"},{\"start\":\"73384\",\"end\":\"73387\"},{\"start\":\"73679\",\"end\":\"73683\"},{\"start\":\"73691\",\"end\":\"73693\"},{\"start\":\"73699\",\"end\":\"73703\"},{\"start\":\"73707\",\"end\":\"73711\"},{\"start\":\"73722\",\"end\":\"73727\"},{\"start\":\"73738\",\"end\":\"73743\"},{\"start\":\"73745\",\"end\":\"73748\"},{\"start\":\"74047\",\"end\":\"74052\"},{\"start\":\"74057\",\"end\":\"74060\"},{\"start\":\"74067\",\"end\":\"74070\"},{\"start\":\"74078\",\"end\":\"74081\"},{\"start\":\"74088\",\"end\":\"74090\"},{\"start\":\"74432\",\"end\":\"74437\"},{\"start\":\"74444\",\"end\":\"74447\"},{\"start\":\"74461\",\"end\":\"74464\"},{\"start\":\"74473\",\"end\":\"74477\"},{\"start\":\"74762\",\"end\":\"74766\"},{\"start\":\"74776\",\"end\":\"74781\"},{\"start\":\"74790\",\"end\":\"74794\"},{\"start\":\"74801\",\"end\":\"74804\"},{\"start\":\"75037\",\"end\":\"75041\"},{\"start\":\"75049\",\"end\":\"75052\"},{\"start\":\"75063\",\"end\":\"75067\"},{\"start\":\"75077\",\"end\":\"75080\"},{\"start\":\"75092\",\"end\":\"75096\"},{\"start\":\"75104\",\"end\":\"75108\"},{\"start\":\"75114\",\"end\":\"75117\"},{\"start\":\"75406\",\"end\":\"75409\"},{\"start\":\"75414\",\"end\":\"75418\"},{\"start\":\"75428\",\"end\":\"75431\"},{\"start\":\"75441\",\"end\":\"75443\"},{\"start\":\"75451\",\"end\":\"75453\"},{\"start\":\"75464\",\"end\":\"75467\"},{\"start\":\"75476\",\"end\":\"75480\"},{\"start\":\"75487\",\"end\":\"75491\"},{\"start\":\"75498\",\"end\":\"75501\"},{\"start\":\"75792\",\"end\":\"75795\"},{\"start\":\"75806\",\"end\":\"75809\"},{\"start\":\"75815\",\"end\":\"75818\"},{\"start\":\"75830\",\"end\":\"75832\"},{\"start\":\"75841\",\"end\":\"75845\"},{\"start\":\"75852\",\"end\":\"75856\"},{\"start\":\"75863\",\"end\":\"75866\"}]", "bib_entry": "[{\"start\":\"63871\",\"end\":\"64242\",\"attributes\":{\"matched_paper_id\":\"393948\",\"id\":\"b0\"}},{\"start\":\"64244\",\"end\":\"64538\",\"attributes\":{\"matched_paper_id\":\"320049\",\"id\":\"b1\"}},{\"start\":\"64540\",\"end\":\"64832\",\"attributes\":{\"matched_paper_id\":\"4891850\",\"id\":\"b2\"}},{\"start\":\"64834\",\"end\":\"65124\",\"attributes\":{\"id\":\"b3\"}},{\"start\":\"65126\",\"end\":\"65441\",\"attributes\":{\"id\":\"b4\",\"doi\":\"arXiv:1704.07556\"}},{\"start\":\"65443\",\"end\":\"65810\",\"attributes\":{\"id\":\"b5\",\"doi\":\"arXiv:1810.04805\"}},{\"start\":\"65812\",\"end\":\"66150\",\"attributes\":{\"id\":\"b6\"}},{\"start\":\"66152\",\"end\":\"66456\",\"attributes\":{\"id\":\"b7\"}},{\"start\":\"66458\",\"end\":\"66803\",\"attributes\":{\"matched_paper_id\":\"160030052\",\"id\":\"b8\"}},{\"start\":\"66805\",\"end\":\"67053\",\"attributes\":{\"id\":\"b9\"}},{\"start\":\"67055\",\"end\":\"67335\",\"attributes\":{\"matched_paper_id\":\"11243593\",\"id\":\"b10\"}},{\"start\":\"67337\",\"end\":\"67692\",\"attributes\":{\"id\":\"b11\",\"doi\":\"arXiv:1511.06939\"}},{\"start\":\"67694\",\"end\":\"67999\",\"attributes\":{\"matched_paper_id\":\"51607268\",\"id\":\"b12\"}},{\"start\":\"68001\",\"end\":\"68172\",\"attributes\":{\"matched_paper_id\":\"6628106\",\"id\":\"b13\"}},{\"start\":\"68174\",\"end\":\"68444\",\"attributes\":{\"matched_paper_id\":\"195908774\",\"id\":\"b14\"}},{\"start\":\"68446\",\"end\":\"68847\",\"attributes\":{\"id\":\"b15\"}},{\"start\":\"68849\",\"end\":\"69234\",\"attributes\":{\"matched_paper_id\":\"50768534\",\"id\":\"b16\"}},{\"start\":\"69236\",\"end\":\"69673\",\"attributes\":{\"matched_paper_id\":\"757461\",\"id\":\"b17\"}},{\"start\":\"69675\",\"end\":\"70050\",\"attributes\":{\"matched_paper_id\":\"67871601\",\"id\":\"b18\"}},{\"start\":\"70052\",\"end\":\"70267\",\"attributes\":{\"matched_paper_id\":\"195316714\",\"id\":\"b19\"}},{\"start\":\"70269\",\"end\":\"70523\",\"attributes\":{\"matched_paper_id\":\"5855042\",\"id\":\"b20\"}},{\"start\":\"70525\",\"end\":\"70910\",\"attributes\":{\"matched_paper_id\":\"44145233\",\"id\":\"b21\"}},{\"start\":\"70912\",\"end\":\"71278\",\"attributes\":{\"matched_paper_id\":\"49418345\",\"id\":\"b22\"}},{\"start\":\"71280\",\"end\":\"71689\",\"attributes\":{\"matched_paper_id\":\"10795036\",\"id\":\"b23\"}},{\"start\":\"71691\",\"end\":\"72087\",\"attributes\":{\"matched_paper_id\":\"14873729\",\"id\":\"b24\"}},{\"start\":\"72089\",\"end\":\"72308\",\"attributes\":{\"matched_paper_id\":\"9683534\",\"id\":\"b25\"}},{\"start\":\"72310\",\"end\":\"72687\",\"attributes\":{\"matched_paper_id\":\"119181611\",\"id\":\"b26\"}},{\"start\":\"72689\",\"end\":\"73041\",\"attributes\":{\"id\":\"b27\"}},{\"start\":\"73043\",\"end\":\"73242\",\"attributes\":{\"matched_paper_id\":\"52084596\",\"id\":\"b28\"}},{\"start\":\"73244\",\"end\":\"73562\",\"attributes\":{\"id\":\"b29\"}},{\"start\":\"73564\",\"end\":\"73977\",\"attributes\":{\"matched_paper_id\":\"199466144\",\"id\":\"b30\"}},{\"start\":\"73979\",\"end\":\"74366\",\"attributes\":{\"matched_paper_id\":\"198180588\",\"id\":\"b31\"}},{\"start\":\"74368\",\"end\":\"74690\",\"attributes\":{\"matched_paper_id\":\"14181993\",\"id\":\"b32\"}},{\"start\":\"74692\",\"end\":\"74949\",\"attributes\":{\"id\":\"b33\"}},{\"start\":\"74951\",\"end\":\"75322\",\"attributes\":{\"matched_paper_id\":\"19112718\",\"id\":\"b34\"}},{\"start\":\"75324\",\"end\":\"75717\",\"attributes\":{\"matched_paper_id\":\"195791567\",\"id\":\"b35\"}},{\"start\":\"75719\",\"end\":\"76047\",\"attributes\":{\"id\":\"b36\"}}]", "bib_title": "[{\"start\":\"63871\",\"end\":\"63925\"},{\"start\":\"64244\",\"end\":\"64289\"},{\"start\":\"64540\",\"end\":\"64648\"},{\"start\":\"66458\",\"end\":\"66515\"},{\"start\":\"67055\",\"end\":\"67110\"},{\"start\":\"67694\",\"end\":\"67765\"},{\"start\":\"68001\",\"end\":\"68043\"},{\"start\":\"68174\",\"end\":\"68237\"},{\"start\":\"68446\",\"end\":\"68542\"},{\"start\":\"68849\",\"end\":\"68955\"},{\"start\":\"69236\",\"end\":\"69297\"},{\"start\":\"69675\",\"end\":\"69761\"},{\"start\":\"70052\",\"end\":\"70110\"},{\"start\":\"70269\",\"end\":\"70297\"},{\"start\":\"70525\",\"end\":\"70625\"},{\"start\":\"70912\",\"end\":\"70983\"},{\"start\":\"71280\",\"end\":\"71337\"},{\"start\":\"71691\",\"end\":\"71767\"},{\"start\":\"72089\",\"end\":\"72144\"},{\"start\":\"72310\",\"end\":\"72405\"},{\"start\":\"73043\",\"end\":\"73091\"},{\"start\":\"73564\",\"end\":\"73669\"},{\"start\":\"73979\",\"end\":\"74039\"},{\"start\":\"74368\",\"end\":\"74421\"},{\"start\":\"74951\",\"end\":\"75029\"},{\"start\":\"75324\",\"end\":\"75401\"}]", "bib_author": "[{\"start\":\"63927\",\"end\":\"63942\"},{\"start\":\"63942\",\"end\":\"63959\"},{\"start\":\"63959\",\"end\":\"63975\"},{\"start\":\"64291\",\"end\":\"64306\"},{\"start\":\"64306\",\"end\":\"64325\"},{\"start\":\"64650\",\"end\":\"64667\"},{\"start\":\"64888\",\"end\":\"64899\"},{\"start\":\"64899\",\"end\":\"64912\"},{\"start\":\"64912\",\"end\":\"64925\"},{\"start\":\"64925\",\"end\":\"64934\"},{\"start\":\"64934\",\"end\":\"64950\"},{\"start\":\"64950\",\"end\":\"64962\"},{\"start\":\"64962\",\"end\":\"64966\"},{\"start\":\"65193\",\"end\":\"65206\"},{\"start\":\"65206\",\"end\":\"65216\"},{\"start\":\"65216\",\"end\":\"65228\"},{\"start\":\"65228\",\"end\":\"65244\"},{\"start\":\"65443\",\"end\":\"65457\"},{\"start\":\"65457\",\"end\":\"65473\"},{\"start\":\"65473\",\"end\":\"65485\"},{\"start\":\"65485\",\"end\":\"65505\"},{\"start\":\"65867\",\"end\":\"65881\"},{\"start\":\"65881\",\"end\":\"65894\"},{\"start\":\"65894\",\"end\":\"65907\"},{\"start\":\"65907\",\"end\":\"65919\"},{\"start\":\"65919\",\"end\":\"65928\"},{\"start\":\"65928\",\"end\":\"65943\"},{\"start\":\"65943\",\"end\":\"65955\"},{\"start\":\"65955\",\"end\":\"65966\"},{\"start\":\"66246\",\"end\":\"66267\"},{\"start\":\"66267\",\"end\":\"66278\"},{\"start\":\"66278\",\"end\":\"66291\"},{\"start\":\"66517\",\"end\":\"66527\"},{\"start\":\"66527\",\"end\":\"66540\"},{\"start\":\"66540\",\"end\":\"66551\"},{\"start\":\"66551\",\"end\":\"66567\"},{\"start\":\"66567\",\"end\":\"66578\"},{\"start\":\"66578\",\"end\":\"66587\"},{\"start\":\"66805\",\"end\":\"66818\"},{\"start\":\"66818\",\"end\":\"66829\"},{\"start\":\"66829\",\"end\":\"66844\"},{\"start\":\"66844\",\"end\":\"66857\"},{\"start\":\"66857\",\"end\":\"66865\"},{\"start\":\"66865\",\"end\":\"66880\"},{\"start\":\"67112\",\"end\":\"67127\"},{\"start\":\"67127\",\"end\":\"67141\"},{\"start\":\"67141\",\"end\":\"67155\"},{\"start\":\"67155\",\"end\":\"67171\"},{\"start\":\"67171\",\"end\":\"67183\"},{\"start\":\"67337\",\"end\":\"67352\"},{\"start\":\"67352\",\"end\":\"67376\"},{\"start\":\"67767\",\"end\":\"67781\"},{\"start\":\"67781\",\"end\":\"67792\"},{\"start\":\"67792\",\"end\":\"67804\"},{\"start\":\"67804\",\"end\":\"67818\"},{\"start\":\"67818\",\"end\":\"67828\"},{\"start\":\"68045\",\"end\":\"68057\"},{\"start\":\"68057\",\"end\":\"68071\"},{\"start\":\"68071\",\"end\":\"68075\"},{\"start\":\"68239\",\"end\":\"68256\"},{\"start\":\"68256\",\"end\":\"68272\"},{\"start\":\"68272\",\"end\":\"68291\"},{\"start\":\"68544\",\"end\":\"68568\"},{\"start\":\"68568\",\"end\":\"68583\"},{\"start\":\"68583\",\"end\":\"68608\"},{\"start\":\"68608\",\"end\":\"68629\"},{\"start\":\"68957\",\"end\":\"68965\"},{\"start\":\"68965\",\"end\":\"68978\"},{\"start\":\"68978\",\"end\":\"68986\"},{\"start\":\"68986\",\"end\":\"69000\"},{\"start\":\"69000\",\"end\":\"69009\"},{\"start\":\"69009\",\"end\":\"69022\"},{\"start\":\"69299\",\"end\":\"69311\"},{\"start\":\"69311\",\"end\":\"69327\"},{\"start\":\"69327\",\"end\":\"69342\"},{\"start\":\"69342\",\"end\":\"69357\"},{\"start\":\"69763\",\"end\":\"69775\"},{\"start\":\"69775\",\"end\":\"69791\"},{\"start\":\"69791\",\"end\":\"69806\"},{\"start\":\"69806\",\"end\":\"69821\"},{\"start\":\"70112\",\"end\":\"70121\"},{\"start\":\"70121\",\"end\":\"70132\"},{\"start\":\"70132\",\"end\":\"70141\"},{\"start\":\"70299\",\"end\":\"70323\"},{\"start\":\"70323\",\"end\":\"70340\"},{\"start\":\"70627\",\"end\":\"70636\"},{\"start\":\"70636\",\"end\":\"70644\"},{\"start\":\"70644\",\"end\":\"70657\"},{\"start\":\"70657\",\"end\":\"70667\"},{\"start\":\"70667\",\"end\":\"70677\"},{\"start\":\"70677\",\"end\":\"70691\"},{\"start\":\"70691\",\"end\":\"70699\"},{\"start\":\"70985\",\"end\":\"70998\"},{\"start\":\"70998\",\"end\":\"71007\"},{\"start\":\"71007\",\"end\":\"71020\"},{\"start\":\"71020\",\"end\":\"71029\"},{\"start\":\"71029\",\"end\":\"71040\"},{\"start\":\"71040\",\"end\":\"71058\"},{\"start\":\"71339\",\"end\":\"71355\"},{\"start\":\"71355\",\"end\":\"71380\"},{\"start\":\"71380\",\"end\":\"71394\"},{\"start\":\"71394\",\"end\":\"71415\"},{\"start\":\"71769\",\"end\":\"71780\"},{\"start\":\"71780\",\"end\":\"71795\"},{\"start\":\"71795\",\"end\":\"71803\"},{\"start\":\"72146\",\"end\":\"72154\"},{\"start\":\"72154\",\"end\":\"72172\"},{\"start\":\"72172\",\"end\":\"72180\"},{\"start\":\"72407\",\"end\":\"72416\"},{\"start\":\"72416\",\"end\":\"72425\"},{\"start\":\"72425\",\"end\":\"72434\"},{\"start\":\"72434\",\"end\":\"72448\"},{\"start\":\"72448\",\"end\":\"72458\"},{\"start\":\"72458\",\"end\":\"72468\"},{\"start\":\"72468\",\"end\":\"72480\"},{\"start\":\"72764\",\"end\":\"72790\"},{\"start\":\"72790\",\"end\":\"72800\"},{\"start\":\"72800\",\"end\":\"72816\"},{\"start\":\"72816\",\"end\":\"72829\"},{\"start\":\"72829\",\"end\":\"72842\"},{\"start\":\"72842\",\"end\":\"72851\"},{\"start\":\"73093\",\"end\":\"73107\"},{\"start\":\"73107\",\"end\":\"73125\"},{\"start\":\"73317\",\"end\":\"73331\"},{\"start\":\"73331\",\"end\":\"73346\"},{\"start\":\"73346\",\"end\":\"73357\"},{\"start\":\"73357\",\"end\":\"73368\"},{\"start\":\"73368\",\"end\":\"73378\"},{\"start\":\"73378\",\"end\":\"73389\"},{\"start\":\"73671\",\"end\":\"73685\"},{\"start\":\"73685\",\"end\":\"73695\"},{\"start\":\"73695\",\"end\":\"73705\"},{\"start\":\"73705\",\"end\":\"73713\"},{\"start\":\"73713\",\"end\":\"73729\"},{\"start\":\"73729\",\"end\":\"73745\"},{\"start\":\"73745\",\"end\":\"73750\"},{\"start\":\"74041\",\"end\":\"74054\"},{\"start\":\"74054\",\"end\":\"74062\"},{\"start\":\"74062\",\"end\":\"74072\"},{\"start\":\"74072\",\"end\":\"74083\"},{\"start\":\"74083\",\"end\":\"74092\"},{\"start\":\"74423\",\"end\":\"74439\"},{\"start\":\"74439\",\"end\":\"74449\"},{\"start\":\"74449\",\"end\":\"74466\"},{\"start\":\"74466\",\"end\":\"74479\"},{\"start\":\"74758\",\"end\":\"74768\"},{\"start\":\"74768\",\"end\":\"74783\"},{\"start\":\"74783\",\"end\":\"74796\"},{\"start\":\"74796\",\"end\":\"74806\"},{\"start\":\"75031\",\"end\":\"75043\"},{\"start\":\"75043\",\"end\":\"75054\"},{\"start\":\"75054\",\"end\":\"75069\"},{\"start\":\"75069\",\"end\":\"75082\"},{\"start\":\"75082\",\"end\":\"75098\"},{\"start\":\"75098\",\"end\":\"75110\"},{\"start\":\"75110\",\"end\":\"75119\"},{\"start\":\"75403\",\"end\":\"75411\"},{\"start\":\"75411\",\"end\":\"75420\"},{\"start\":\"75420\",\"end\":\"75433\"},{\"start\":\"75433\",\"end\":\"75445\"},{\"start\":\"75445\",\"end\":\"75455\"},{\"start\":\"75455\",\"end\":\"75469\"},{\"start\":\"75469\",\"end\":\"75482\"},{\"start\":\"75482\",\"end\":\"75493\"},{\"start\":\"75493\",\"end\":\"75503\"},{\"start\":\"75789\",\"end\":\"75797\"},{\"start\":\"75797\",\"end\":\"75811\"},{\"start\":\"75811\",\"end\":\"75820\"},{\"start\":\"75820\",\"end\":\"75834\"},{\"start\":\"75834\",\"end\":\"75847\"},{\"start\":\"75847\",\"end\":\"75858\"},{\"start\":\"75858\",\"end\":\"75868\"}]", "bib_venue": "[{\"start\":\"63975\",\"end\":\"64037\"},{\"start\":\"64325\",\"end\":\"64380\"},{\"start\":\"64667\",\"end\":\"64671\"},{\"start\":\"64834\",\"end\":\"64886\"},{\"start\":\"65126\",\"end\":\"65191\"},{\"start\":\"65521\",\"end\":\"65601\"},{\"start\":\"65812\",\"end\":\"65865\"},{\"start\":\"66152\",\"end\":\"66244\"},{\"start\":\"66587\",\"end\":\"66616\"},{\"start\":\"66880\",\"end\":\"66918\"},{\"start\":\"67183\",\"end\":\"67187\"},{\"start\":\"67392\",\"end\":\"67494\"},{\"start\":\"67828\",\"end\":\"67833\"},{\"start\":\"68075\",\"end\":\"68079\"},{\"start\":\"68291\",\"end\":\"68295\"},{\"start\":\"68629\",\"end\":\"68633\"},{\"start\":\"69022\",\"end\":\"69028\"},{\"start\":\"69357\",\"end\":\"69418\"},{\"start\":\"69821\",\"end\":\"69841\"},{\"start\":\"70141\",\"end\":\"70147\"},{\"start\":\"70340\",\"end\":\"70376\"},{\"start\":\"70699\",\"end\":\"70705\"},{\"start\":\"71058\",\"end\":\"71078\"},{\"start\":\"71415\",\"end\":\"71472\"},{\"start\":\"71803\",\"end\":\"71875\"},{\"start\":\"72180\",\"end\":\"72186\"},{\"start\":\"72480\",\"end\":\"72484\"},{\"start\":\"72689\",\"end\":\"72762\"},{\"start\":\"73125\",\"end\":\"73131\"},{\"start\":\"73244\",\"end\":\"73315\"},{\"start\":\"73750\",\"end\":\"73755\"},{\"start\":\"74092\",\"end\":\"74160\"},{\"start\":\"74479\",\"end\":\"74517\"},{\"start\":\"74692\",\"end\":\"74756\"},{\"start\":\"75119\",\"end\":\"75123\"},{\"start\":\"75503\",\"end\":\"75507\"},{\"start\":\"75719\",\"end\":\"75787\"},{\"start\":\"69420\",\"end\":\"69466\"}]"}}}, "year": 2023, "month": 12, "day": 17}