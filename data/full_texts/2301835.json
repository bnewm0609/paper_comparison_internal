{"id": 2301835, "updated": "2023-09-26 22:29:37.669", "metadata": {"title": "A Gang of Bandits", "authors": "[{\"first\":\"Nicolo\",\"last\":\"Cesa-Bianchi\",\"middle\":[]},{\"first\":\"Claudio\",\"last\":\"Gentile\",\"middle\":[]},{\"first\":\"Giovanni\",\"last\":\"Zappella\",\"middle\":[]}]", "venue": "NIPS", "journal": "737-745", "publication_date": {"year": 2013, "month": 6, "day": 4}, "abstract": "Multi-armed bandit problems are receiving a great deal of attention because they adequately formalize the exploration-exploitation trade-offs arising in several industrially relevant applications, such as online advertisement and, more generally, recommendation systems. In many cases, however, these applications have a strong social component, whose integration in the bandit algorithm could lead to a dramatic performance increase. For instance, we may want to serve content to a group of users by taking advantage of an underlying network of social relationships among them. In this paper, we introduce novel algorithmic approaches to the solution of such networked bandit problems. More specifically, we design and analyze a global strategy which allocates a bandit algorithm to each network node (user) and allows it to\"share\"signals (contexts and payoffs) with the neghboring nodes. We then derive two more scalable variants of this strategy based on different ways of clustering the graph nodes. We experimentally compare the algorithm and its variants to state-of-the-art methods for contextual bandits that do not use the relational information. Our experiments, carried out on synthetic and real-world datasets, show a marked increase in prediction performance obtained by exploiting the network structure.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1306.0811", "mag": "2950978108", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/Cesa-BianchiGZ13", "doi": null}}, "content": {"source": {"pdf_hash": "fbe46e0a1bfea20c1290d4f29b9a1a57a0feea50", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1306.0811v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "959ec482bffb9f8b6706552bd398f4ba12726314", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/fbe46e0a1bfea20c1290d4f29b9a1a57a0feea50.txt", "contents": "\nA Gang of Bandits\nMay 7, 2014\n\nNicol\u00f2 Cesa-Bianchi nicolo.cesa-bianchi@unimi.it \nDI\nUniversity of Milan\nItaly\n\nClaudio Gentile claudio.gentile@uninsubria.it \nDept. of Mathematics\nUniversity of Insubria\nItaly\n\nGiovanni Zappella giovanni.zappella@unimi.it \nUniversity of Milan\nItaly\n\nA Gang of Bandits\nMay 7, 2014\nMulti-armed bandit problems are receiving a great deal of attention because they adequately formalize the exploration-exploitation trade-offs arising in several industrially relevant applications, such as online advertisement and, more generally, recommendation systems. In many cases, however, these applications have a strong social component, whose integration in the bandit algorithm could lead to a dramatic performance increase. For instance, we may want to serve content to a group of users by taking advantage of an underlying network of social relationships among them. In this paper, we introduce novel algorithmic approaches to the solution of such networked bandit problems. More specifically, we design and analyze a global strategy which allocates a bandit algorithm to each network node (user) and allows it to \"share\" signals (contexts and payoffs) with the neghboring nodes. We then derive two more scalable variants of this strategy based on different ways of clustering the graph nodes. We experimentally compare the algorithm and its variants to state-of-the-art methods for contextual bandits that do not use the relational information.Our experiments, carried out on synthetic and real-world datasets, show a marked increase in prediction performance obtained by exploiting the network structure.\n\nIntroduction\n\nThe ability of a website to present personalized content recommendations is playing an increasingly crucial role in achieving user satisfaction. Because of the appearance of new content, and due to the ever-changing nature of content popularity, modern approaches to content recommendation are strongly adaptive, and attempt to match as closely as possible users' interests by learning good mappings between available content and users. These mappings are based on \"contexts\", that is sets of features that, typically, are extracted from both contents and users. The need to focus on content that raises the user interest and, simultaneously, the need of exploring new content in order to globally improve the user experience creates an exploration-exploitation dilemma, which is commonly formalized as a multi-armed bandit problem. Indeed, contextual bandits have become a reference model for the study of adaptive techniques in recommender systems (e.g, [5,7,15] ). In many cases, however, the users targeted by a recommender system form a social network. The network structure provides an important additional source of information, revealing potential affinities between pairs of users. The exploitation of such affinities could lead to a dramatic increase in the quality of the recommendations. This is because the knowledge gathered about the interests of a given user may be exploited to improve the recommendation to the user's friends. In this work, an algorithmic approach to networked contextual bandits is proposed which is provably able to leverage user similarities represented as a graph. Our approach consists in running an instance of a contextual bandit algorithm at each network node. These instances are allowed to interact during the learning process, sharing contexts and user feedbacks. Under the modeling assumption that user similarities are properly reflected by the network structure, interactions allow to effectively speed up the learning process that takes place at each node. This mechanism is implemented by running instances of a linear contextual bandit algorithm in a specific reproducing kernel Hilbert space (RKHS). The underlying kernel, previously used for solving online multitask classification problems (e.g., [8]), is defined in terms of the Laplacian matrix of the graph. The Laplacian matrix provides the information we rely upon to share user feedbacks from one node to the others, according to the network structure. Since the Laplacian kernel is linear, the implementation in kernel space is straightforward. Moreover, the existing performance guarantees for the specific bandit algorithm we use can be directly lifted to the RKHS, and expressed in terms of spectral properties of the user network. Despite its crispness, the principled approach described above has two drawbacks hindering its practical usage. First, running a network of linear contextual bandit algorithms with a Laplacian-based feedback sharing mechanism may cause significant scaling problems, even on small to medium sized social networks. Second, the social information provided by the network structure at hand need not be fully reliable in accounting for user behavior similarities. Clearly enough, the more such algorithms hinge on the network to improve learning rates, the more they are penalized if the network information is noisy and/or misleading. After collecting empirical evidence on the sensitivity of networked bandit methods to graph noise, we propose two simple modifications to our basic strategy, both aimed at circumventing the above issues by clustering the graph nodes. The first approach reduces graph noise simply by deleting edges between pairs of clusters. By doing that, we end up running a scaled down independent instance of our original strategy on each cluster. The second approach treats each cluster as a single node of a much smaller cluster network. In both cases, we are able to empirically improve prediction performance, and simultaneously achieve dramatic savings in running times. We run experiments on two real-world datasets: one is extracted from the social bookmarking web service Delicious, and the other one from the music streaming platform Last.fm.\n\n\nRelated work\n\nThe benefit of using social relationships in order to improve the quality of recommendations is a recognized fact in the literature of content recommender systems -see e.g., [5,13,18] and the survey [3]. Linear models for contextual bandits were introduced in [4]. Their application to personalized content recommendation was pioneered in [15], where the LinUCB algorithm was introduced. An analysis of LinUCB was provided in the subsequent work [9]. To the best of our knowledge, this is the first work that combines contextual bandits with the social graph information. However, non-contextual stochastic bandits in social networks were studied in a recent independent work [20]. Other works, such as [2,19], consider contextual bandits assuming metric or probabilistic dependencies on the product space of contexts and actions. A different viewpoint, where each action reveals information about other actions' payoffs, is the one studied in [7,16], though without the context provided by feature vectors. A non-contextual model of bandit algorithms running on the nodes of a graph was studied in [14]. In that work, only one node reveals its payoffs, and the statistical information acquired by this node over time is spread across the entire network following the graphical structure. The main result shows that the information flow rate is sufficient to control regret at each node of the network. More recently, a new model of distributed non-contextual bandit algorithms has been presented in [21], where the number of communications among the nodes is limited, and all the nodes in the network have the same best action.\n\n\nLearning model\n\nWe assume the social relationships over users are encoded as a known undirected and connected graph G = (V, E), where V = {1, . . . , n} represents a set of n users, and the edges in E represent the social links over pairs of users. Recall that a graph G can be equivalently defined in terms of its Laplacian matrix L = L i,j n i,j=1 , where L i,i is the degree of node i (i.e., the number of incoming/outgoing edges) and, for i = j, L i,j equals \u22121 if (i, j) \u2208 E, and 0 otherwise.\n\nLearning proceeds in a sequential fashion: At each time step t = 1, 2, . . . , the learner receives a user index i t \u2208 V together with a set of context vectors C it = {x t,1 , x t,2 , . . . , x t,ct } \u2286 R d . The learner then selects some k t \u2208 C it to recommend to user i t and observes some payoff a t \u2208 [\u22121, 1], a function of i t and x t = x t,kt . No assumptions whatsoever are made on the way index i t and set C it are generated, in that they can arbitrarily depend on past choices made by the algorithm. 1 A standard modeling assumption for bandit problems with contextual information (one that is also adopted here) is to assume that rewards are generated by noisy versions of unknown linear functions of the context vectors. That is, we assume each node i \u2208 V hosts an unknown parameter vector u i \u2208 R d , and that the reward value a i (x) associated with node i and context vector x \u2208 R d is given by the random variable a i (x) = u i x + i (x), where i (x) is a conditionally zero-mean and bounded variance noise term. Specifically, denoting by E t [ \u00b7 ] the conditional expectation E \u00b7 (i 1 , C i1 , a 1 ), . . . , (i t\u22121 , C it\u22121 , a t\u22121 ) , we take the general approach of [1], and assume that for any fixed i \u2208 V and x \u2208 R d , the variable i (x) is conditionally sub-Gaussian with variance parameter \u03c3 2 > 0, namely, E t exp(\u03b3 i (x)) \u2264 exp \u03c3 2 \u03b3 2 /2 for all \u03b3 \u2208 R and all x, i.\nThis implies E t [ i (x)] = 0 and V t i (x) \u2264 \u03c3 2 , where V t [\u00b7] is a shorthand for the conditional variance V \u00b7 (i 1 , C i1 , a 1 ), . . . , (i t\u22121 , C it\u22121 , a t\u22121 ) . So we clearly have E t [a i (x)] = u i x and V t a i (x) \u2264 \u03c3 2 .\nTherefore, u i x is the expected reward observed at node i for context vector x. In the special case when the\nnoise i (x) is a bounded random variable taking values in the range [\u22121, 1], this implies V t [a i (x)] \u2264 4.\nThe regret r t of the learner at time t is the amount by which the average reward of the best choice in hindsight at node i t exceeds the average reward of the algorithm's choice, i.e.,\nr t = max x\u2208Ci t u it x \u2212 u itxt .\nThe goal of the algorithm is to bound with high probability (over the noise variables it ) the cumulative regret T t=1 r t for the given sequence of nodes i 1 , . . . , i T and observed context vector sets C i1 , . . . , C i T . We model the similarity among users in V by making the assumption that nearby users hold similar underlying vectors u i , so that reward signals received at a given node i t at time t are also, to some extent, informative to learn the behavior of other users j connected to i t within G. We make this more precise by taking the perspective of known multitask learning settings (e.g., [8]), and assume that\n(i,j)\u2208E u i \u2212 u j 2 (1)\nis small compared to i\u2208V u i 2 , where \u00b7 denotes the standard Euclidean norm of vectors. That is, although (1) may possibly contain a quadratic number of terms, the closeness of vectors lying on adjacent nodes in G makes this sum comparatively smaller than the actual length of such vectors. This will be our working assumption throughout, one that motivates the Laplacian-regularized algorithm presented in Section 4, and empirically tested in Section 5.\n\n\nAlgorithm and regret analysis\n\nOur bandit algorithm maintains at time t an estimate w i,t for vector u i . Vectors w i,t are updated based on the reward signals as in a standard linear bandit algorithm (e.g., [9]) operating on the context vectors contained in C it . Every node i of G hosts a linear bandit algorithm like the one described in Figure 1. The algorithm in Figure 1 maintains at time t a prototype vector w t which is the result of a standard linear least-squares approximation to the unknown parameter vector u associated with the node under consideration. In particular, w t\u22121 is obtained by multiplying the inverse correlation matrix M t\u22121 and the bias vector b t\u22121 . At each time t = 1, 2, . . . , the algorithm receives context vectors x t,1 , . . . , x t,ct contained in C t , and must select one among them. The linear bandit algorithm selectsx t = x t,kt as the vector in C t that maximizes an upper-confidence-corrected estimation of the expected reward achieved over context vectors x t,k . The estimation is based on the current w t\u22121 , while the upper confidence level cb t is suggested by the standard analysis of linear bandit algorithms -see, e.g., [1,9,10]. Once the actual reward a t associated with x t is observed, the algorithm usesx t for updating M t\u22121 to M t via a rankone adjustment, and b t\u22121 to b t via an additive update whose learning rate is precisely a t . This algorithm can be seen as a version of LinUCB [9], a linear bandit algorithm derived from LinRel [4].\n\nWe now turn to describing our GOB.Lin (Gang Of Bandits, Linear version) algorithm. GOB.Lin lets the algorithm in Figure 1 operate on each node i of G (we should then add subscript i throughout, replacing w t by w i,t , M t by M i,t , and so forth). The updates M i,t\u22121 \u2192 M i,t and b i,t\u22121 \u2192 b i,t are performed at node i through vectorx t both when i = i t (i.e., when node i is the one which the context vectors in C it refer to) and to a lesser extent when i = i t (i.e., when node i is not the one which the vectors in C it refer to). This is because, as we said, the payoff a t received for node i t is somehow informative also for all other nodes i = i t . In other words, because we are assuming the underlying parameter vectors u i are close to each other, we should let the corresponding prototype vectors w i,t undergo similar updates, so as to also keep the w i,t close to each other over time.\n\nWith this in mind, we now describe GOB.Lin in more detail. It is convenient to introduce first some extra matrix notation. Let A = I n + L, where L is the Laplacian matrix associated with G, and I n is the n \u00d7 n identity matrix. Set A \u2297 = A \u2297 I d , the Kronecker product 2 of matrices A and I d . Moreover, the  \nInit: b0 = 0 \u2208 R d and M0 = I \u2208 R d\u00d7d ; for t = 1, 2, . . . , T do Set wt\u22121 = M \u22121 t\u22121 bt\u22121; Get context Ct = {xt,1, . . . , xt,c t }; Set kt = argmax k=1,...,c t w t\u22121 x t,k + cbt(x t,k ) where cbt(x t,k ) = x t,k M \u22121 t\u22121 x t,k \u03c3 ln |Mt| \u03b4 + u Setxt = x t,k t ; Observe reward at \u2208 [\u22121, 1]; Update \u2022 Mt = Mt\u22121 +xtx t , \u2022 bt = bt\u22121 + atxt .Init: b0 = 0 \u2208 R dn and M0 = I \u2208 R dn\u00d7dn ; for t = 1, 2, . . . , T do Set wt\u22121 = M \u22121 t\u22121 bt\u22121; Get it \u2208 V , context Ci t = {xt,1, . . . , xt,c t }; Construct vectors \u03c6 i t (xt,1), . . . , \u03c6 i t (xt,c t ), and modified vectors \u03c6 t,1 , . . . , \u03c6 t,c t , where \u03c6 t,k = A \u22121/2 \u2297 \u03c6 i t (x t,k ), k = 1, . . . , ct; Set kt = argmax k=1,...,c t w t\u22121 \u03c6 t,k + cbt( \u03c6 t,k ) where cbt( \u03c6 t,k ) = \u03c6 t,k M \u22121 t\u22121 \u03c6 t,k \u03c3 ln |Mt| \u03b4 + U\nObserve reward at \u2208 [\u22121, 1] at node it; Update\n\u2022 Mt = Mt\u22121 + \u03c6 t,k t \u03c6 t,k t , \u2022 bt = bt\u22121 + at \u03c6 t,k .\nend for Figure 2: Pseudocode of the GOB.Lin algorithm.\n\n\"compound\" descriptor for the pairing (i, x) is given by the long (and sparse)\nvector \u03c6 i (x) \u2208 R dn defined as \u03c6 i (x) = 0, . . . , 0 (i\u22121)d times , x , 0, . . . , 0 (n\u2212i)d times .\nWith the above notation handy, a compact description of GOB.Lin is presented in Figure 2, where we deliberately tried to mimic the pseudocode of Figure 1.\n\nNotice that in Figure 2 we overloaded the notation for the confidence bound cb t , which is now defined in terms of the Laplacian L of G. In particular, u in Figure 1 is replaced in Figure 2 by U , where U = A 1/2 \u2297 U and we define U = (u 1 , u 2 , . . . , u n ) \u2208 R dn . Clearly enough, the potentially unknown quantities u and U in the two expressions for cb t can be replaced by suitable upper bounds.\n\nWe now explain how the modified long vectors \u03c6 t,k = A \u22121/2 \u2297 \u03c6 it (x t,k ) act in the update of matrix M t and vector b t . First, observe that if A \u2297 were the identity matrix then, according to how the long vectors \u03c6 it (x t,k ) are defined,\nM t would be a block-diagonal matrix M t = diag(D 1 , . . . , D n ), whose i-th block D i is the d \u00d7 d matrix D i = I d + t : kt=i x t x t .\nSimilarly, b t would be the dnlong vector whose i-th d-dimensional block contains t : kt=i a t x t . This would be equivalent to running n independent linear bandit algorithms (Figure 1), one per node of G. Now, because A \u2297 is not the identity, but contains graph G represented through its Laplacian matrix, the selected vector x t,kt \u2208 C it for node i t gets spread via A \u22121/2 \u2297 from the i t -th block over all other blocks, thereby making the contextual information contained in x t,kt available to update the internal status of all other nodes. Yet, the only reward signal observed at time t is the one available at node i t . A theoretical analysis of GOB.Lin relying on the learning model of Section 3 is sketched in Section 4.1.\n\nGOB.Lin's running time is mainly affected by the inversion of the dn \u00d7 dn matrix M t , which can be performed in time of order (dn) 2 per round by using well-known formulas for incremental matrix inversions. The same quadratic dependence holds for memory requirements. In our experiments, we observed that projecting the contexts on the principal components improved performance. Hence, the quadratic dependence on the context vector dimension d is not really hurting us in practice. On the other hand, the quadratic dependence on the number of nodes n may be a significant limitation to GOB.Lin's practical deployment. In the next section, we show that simple graph compression schemes (like node clustering) can conveniently be applied to both reduce edge noise and bring the algorithm to reasonable scaling behaviors.\n\n\nRegret Analysis\n\nWe now provide a regret analysis for GOB.Lin that relies on the high probability analysis contained in [1] (Theorem 2 therein). The analysis can be seen as a combination of the multitask kernel contained in, e.g., [8,17,12] and a version of the linear bandit algorithm described and analyzed in [1]. Theorem 1. Let the GOB.Lin algorithm of Figure 2 be run on graph G = (V, E), V = {1, . . . , n}, hosting at each node i \u2208 V vector u i \u2208 R d . Define\nL(u 1 , . . . , u n ) = i\u2208V u i 2 + (i,j)\u2208E u i \u2212 u j 2 .\nLet also the sequence of context vectors x t,k be such that x t,k \u2264 B, for all k = 1, . . . , c t , and t = 1, . . . , T . Then the cumulative regret satisfies\nT t=1 r t \u2264 2 T 2\u03c3 2 ln |M T | \u03b4 + 2L(u 1 , . . . , u n ) (1 + B 2 ) ln |M T |\nwith probability at least 1 \u2212 \u03b4.\n\nCompared to running n independent bandit algorithms (which corresponds to A \u2297 being the identity matrix), the bound in the above theorem has an extra term (i,j)\u2208E u i \u2212 u j 2 , which we assume small according to our working assumption. However, the bound has also a significantly smaller log determinant ln |M T | on the resulting matrix M T , due to the construction of \u03c6 t,k via A \u22121/2 \u2297 . In particular, when the graph is very dense, the log determinant in GOB.Lin is a factor n smaller than the corresponding term for the n independent bandit case (see, e.g., [8], Section 4.2 therein). To make things clear, consider two extreme situations. When G has no edges then tr(M T ) = tr(I) + T = nd + T , hence ln |M T | \u2264 dn ln(1 + T /(dn)). On the other hand, When G is the complete graph then tr(M T ) = tr(I) + 2t/(n + 1) = nd + 2T /(n + 1), hence ln |M T | \u2264 dn ln(1 + 2T /(dn(n + 1))). The exact behavior of ln |M t | (one that would ensure a significant advantage in practice) depends on the actual interplay between the data and the graph, so that the above linear dependence on dn is really a coarse upper bound.\n\n\nExperiments\n\nIn this section, we present an empirical comparison of GOB.Lin (and its variants) to linear bandit algorithms which do not exploit the relational information provided by the graph. We run our experiments by approximating the cb t function in Figure 1 with the simplified expression \u03b1 x t,k M \u22121 t\u22121 x t,k log(t + 1), and the cb t function in Figure 2 with the corresponding expression in which x t,k is replaced by \u03c6 t,k . In both cases, the factor \u03b1 is used as tunable parameter. Our preliminary experiments show that this approximation does not affect the predictive performances of the algorithms, while it speeds up computation significantly. We tested our algorithm and its competitors on a synthetic dataset and two freely available real-world datasets extracted from the social bookmarking web service Delicious and from the music streaming service Last.fm. These datasets are structured as follows.\n\n4Cliques. This is an artificial dataset whose graph contains four cliques of 25 nodes each to which we added graph noise. This noise consists in picking a random pair of nodes and deleting or creating an edge between them. More precisely, we created a n \u00d7 n symmetric noise matrix of random numbers in [0, 1], and we selected a threshold value such that the expected number of matrix elements above this value is exactly some chosen noise rate parameter. Then we set to 1 all the entries whose content is above the threshold, and to zero the remaining ones. Finally, we XORed the noise matrix with the graph adjacency matrix, thus obtaining a noisy version of the original graph.\n\nLast.fm. This is a social network containing 1,892 nodes and 12,717 edges. There are 17,632 items (artists), described by 11,946 tags. The dataset contains information about the listened artists, and we used this information in order to create the payoffs: if a user listened to an artist at least once the payoff is 1, otherwise the payoff is 0.\n\nDelicious. This is a network with 1,861 nodes and 7,668 edges. There are 69,226 items (URLs) described by 53,388 tags. The payoffs were created using the information about the bookmarked URLs for each user: the payoff is 1 if the user bookmarked the URL, otherwise the payoff is 0.\n\nLast.fm and Delicious were created by the Information Retrieval group at Universidad Autonoma de Madrid for the HetRec 2011 Workshop [6] with the goal of investigating the usage of heterogeneous information in recommendation systems. 3 These two networks are structurally different: on Delicious, payoffs depend on users more strongly than on Last.fm. In other words, there are more popular artists, whom everybody listens to, than popular websites, which everybody bookmarks -see Figure ??. This makes a huge difference in practice, and the choice of these two datasets allow us to make a more realistic comparison of recommendation techniques. Since we did not remove any items from these datasets (neither the most frequent nor the least frequent), these differences do influence the behavior of all algorithms -see below.\n\nSome statistics about Last.fm and Delicious are reported in Table 1. In Figure ?? we plotted the distribution of the number of preferences per item in order to make clear and visible the differences explained in the previous paragraphs. 4 Items counts the overall number of items, across all users, from which C t is selected. Nonzero payoffs is the number of pairs (user, item) for which we have a nonzero payoff. Tags is the number of distinct tags that were used to describe the items.\n\n\nLast.fm Delicious\n\nWe preprocessed datasets by breaking down the tags into smaller tags made up of single words. In fact, many users tend to create tags like \"webdesign tutorial css\". This tag has been splitted into three smaller tags corresponding to the three words therein. More generally, we splitted all compound tags containing underscores, hyphens and apexes. This makes sense because users create tags independently, and we may have both \"rock and roll\" and \"rock n roll\". Because of this splitting operation, the number of unique tags decreased from 11,946 to 6,036 on Last.fm and from 53,388 to 9,949 on Delicious. On Delicious, we also removed all tags occurring less than ten times. 5 The algorithms we tested do not use any prior information about which user provided a specific tag. We used all tags associated with a single item to create a TF-IDF context vector that uniquely represents that item, independent of which user the item is proposed to. In both datasets, we only retained the first 25 principal components of context vectors, so that x t,k \u2208 R 25 for all t and k. We generated random context sets C it of size 25 for Last.fm and Delicious, and of size 10 for 4Cliques. In practical scenarios, these numbers would be varying over time, but we kept them fixed so as to simplify the experimental setting. In 4Cliques we assigned the same unit norm random vector u i to every node in the same clique i of the original graph (before adding graph noise). Payoffs were then generated according to the following stochastic model:\na i (x) = u i x + ,\nwhere (the payoff noise) is uniformly distributed in a bounded interval centered around zero. For Delicious and Last.fm, we created a set of context vectors for every round t as follows: we first picked i t uniformly at random in {1, . . . , n}. Then, we generated context vectors x t,1 , . . . , x t,25 in C it by picking 24 vectors at random from the dataset and one among those vectors with nonzero payoff for user i t . This is necessary in order to avoid a meaningless comparison: with high probability, a purely random selection would result in payoffs equal to zero for all the context vectors in C it .  Table 2: Normalized cumulated reward for different levels of graph noise (expected fraction of perturbed edges) and payoff noise (largest absolute value of noise term ) on the 4Cliques dataset. Graph noise increases from top to bottom, payoff noise increases from left to right. GOB.Lin is clearly more robust to payoff noise than its competitors. On the other hand, GOB.Lin is sensitive to high levels of graph noise. In the last row, graph noise is 41.7%, i.e., the number of perturbed edges is 500 out of 1200 edges of the original graph.\n\nIn our experimental comparison, we tested GOB.Lin and its variants against two baselines: a baseline LinUCB-IND that runs an independent instance of the algorithm in Figure 1 at each node (this is equivalent to running GOB.Lin in Figure 2 with A \u2297 = I dn ) and a baseline LinUCB-SIN, which runs a single instance of the algorithm in Figure 1 shared by all the nodes. LinUCB-IND lends itself to be a reasonable comparator when, as in the Delicious dataset, there are many moderately popular items. On the other hand, LinUCB-SIN is a competitive baseline when, as in the Last.fm dataset, there are few very popular items. The two scalable variants of GOB.Lin which we empirically  analyzed are based on node clustering, 6 and are defined as follows.\n\nGOB.Lin.MACRO: GOB.Lin is run on a weighted graph whose nodes are the clusters of the original graph. The edges are weighted by the number of inter-cluster edges in the original graph. When all nodes are clustered together, then GOB.Lin.MACRO recovers the baseline LinUCB-SIN as a special case. In order to strike a good trade-off between the speed of the algorithms and the loss of information resulting from clustering, we tested three different cluster sizes: 50, 100, and 200. Our plots refer to the best performing choice.\n\nGOB.Lin.BLOCK: GOB.Lin is run on a disconnected graph whose connected components are the clusters. This makes A \u2297 and M t (Figure 2) block-diagonal matrices. When each node is clustered individually, then GOB.Lin.BLOCK recovers the baseline LinUCB-IND as a special case. Similar to GOB.Lin.MACRO, in order to trade-off running time and cluster sizes, we tested three different cluster sizes (5, 10, and 20), and report only on the best performing choice.\n\nAs the running time of GOB.Lin scales quadratically with the number of nodes, the computational savings provided by the clustering are also quadratic. Moreover, as we will see in the experiments, the clustering acts as a regularizer, limiting the influence of noise. In all cases, the parameter \u03b1 in Figures 1 and 2 was selected based on the scale of instance vectorsx t and \u03c6 t,kt , respectively, and tuned across appropriate ranges. Table 2 and Figure 3 show the cumulative reward for each algorithm, as compared (\"normalized\") to that of the random predictor, that is t (a t \u2212\u0101 t ), where a t is the payoff obtained by the algorithm and\u0101 t is the payoff obtained by the random predictor, i.e., the average payoff over the context vectors available at time t. Table 2 (synthetic datasets) shows that GOB.Lin and LinUCB-SIN are more robust to payoff noise than LinUCB-IND. Clearly, LinUCB-SIN is also unaffected by graph noise, but it never outperforms GOB.Lin. When the payoff noise is low and the graph noise grows GOB.Lin's performance tends to degrade. Figure 3 reports the results on the two real-world datasets. Notice that GOB.Lin and its variants always outperform the baselines (not relying on graphical information) on both datasets. As expected, GOB.Lin.MACRO works best on Last.fm, where many users gave positive payoffs to the same few items. Hence, macro nodes apparently help GOB.Lin.MACRO to perform better than its corresponding baseline LinUCB-SIN. In fact, GOB.Lin.MACRO also outperforms GOB.Lin, thus showing the regularization effect of using macro nodes. On Delicious, where we have many moderately popular items, GOB.Lin.BLOCK tends to perform best, GOB.Lin being the runner-up. As expected, LinUCB-IND works better than LinUCB-SIN, since the former is clearly more prone to personalize item recommendation than the latter. In summary, we may conclude that our system is able to exploit the information provided by the graphical structure. Moreover, regularization via graph clustering seems to be of significant help. Future work will consider experiments against different methods for sharing contextual and feedback information in a set of users, such as the feature hashing technique of [22]. gives the desired bound.\n\nFigure 1\n1Figure 1: Pseudocode of the linear bandit algorithm sitting at each node i of the given graph.\n\nFigure 3 :\n3Cumulative reward for all the bandit algorithms introduced in this section.\n\n\n(a + b) 2 \u2264 2a 2 + 2b 2 applied with a = \u03c3 ln |M T | \u03b4 and b = U yields T t=1 r t \u2264 2 T 2\u03c3 2 ln |M T | \u03b4 + 2 U 2 (1 + B 2 ) ln |M T | .Finally, observing thatU 2 = U A \u2297 U = L(u 1 , . . . , u n )\nFormally, it and C i t can be arbitrary (measurable) functions of past rewards a 1 , . . . , a t\u22121 , indices i 1 , . . . , i t\u22121 , and sets C i 1 , . . . , C i t\u22121 .\nThe Kronecker product between two matrices M \u2208 R m\u00d7n and N \u2208 R q\u00d7r is the block matrix M \u2297 N of dimension mq \u00d7 nr whose block on row i and column j is the q \u00d7 r matrix M i,j N .\nDatasets and their full descriptions are available at www.grouplens.org/node/462.4 In the context of recommender systems, these two datasets may be seen as representatives of two \"markets\" whose products have significantly different market shares (the well-known dichotomy of hit vs. niche products). Niche product markets give rise to power laws in user preference statistics (as in the blue plot ofFigure ??).\nWe did not repeat the same operation on Last.fm because this dataset was already extremely sparse.\nWe used the freely available Graclus graph clustering tool, whose interns are described, e.g., in[11]. We used Graclus with normalized cut, zero local search steps, and no spectral clustering options.\nA AppendixThis appendix contains the proof of Theorem 1.Proof. Recall thatLet then t be a fixed time step, and introduce the following shorthand notation:Notice that, for any k we haveHence we decompose the time-t regret r t as follows:At this point, we rely on[1](Theorem 2 therein with \u03bb = 1) to show thatboth hold simultaneously for all t with probability at least 1 \u2212 \u03b4 over the noise sequence. Hence, with the same probability,holds uniformly over t. Thus the cumulative regret\nImproved algorithms for linear stochastic bandits. Y Abbasi-Yadkori, D P\u00e1l, C Szepesv\u00e1ri, Advances in Neural Information Processing Systems. Y. Abbasi-Yadkori, D. P\u00e1l, and C. Szepesv\u00e1ri. Improved algorithms for linear stochastic bandits. Advances in Neural Information Processing Sys- tems, 2011.\n\nGraphical models for bandit problems. K Amin, M Kearns, U Syed, Proceedings of the Twenty-Seventh Conference Uncertainty in Artificial Intelligence. the Twenty-Seventh Conference Uncertainty in Artificial IntelligenceK. Amin, M. Kearns, and U. Syed. Graphical models for bandit problems. Proceedings of the Twenty-Seventh Conference Uncertainty in Artificial In- telligence, 2011.\n\nAlgorithms and methods in recommender systems. D Asanov, Berlin, GermanyBerlin Institute of TechnologyD. Asanov. Algorithms and methods in recommender systems. Berlin Institute of Technology, Berlin, Germany, 2011.\n\nUsing confidence bounds for exploration-exploitation trade-offs. P Auer, Journal of Machine Learning Research. 3P. Auer. Using confidence bounds for exploration-exploitation trade-offs. Journal of Machine Learning Research, 3:397-422, 2002.\n\nMovie recommendation using random walks over the contextual graph. T Bogers, CARS'10: Proceedings of the 2nd Workshop on Context-Aware Recommender Systems. T. Bogers. Movie recommendation using random walks over the contextual graph. In CARS'10: Proceedings of the 2nd Workshop on Context-Aware Recommender Systems, 2010.\n\nI Cantador, P Brusilovsky, T Kuflik, 2nd Workshop on Information Heterogeneity and Fusion in Recommender Systems. ACMProceedings of the 5th ACM Conference on Recommender SystemsI. Cantador, P. Brusilovsky, and T. Kuflik. 2nd Workshop on Information Heterogeneity and Fusion in Recommender Systems (HetRec 2011). In Proceedings of the 5th ACM Conference on Recommender Systems, RecSys 2011. ACM, 2011.\n\nLeveraging side observations in stochastic bandits. S Caron, B Kveton, M Lelarge, S Bhagat, Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence. the 28th Conference on Uncertainty in Artificial IntelligenceS. Caron, B. Kveton, M. Lelarge, and S. Bhagat. Leveraging side obser- vations in stochastic bandits. In Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence, pages 142-151, 2012.\n\nLinear algorithms for online multitask classification. G Cavallanti, N Cesa-Bianchi, C Gentile, Journal of Machine Learning Research. 11G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear algorithms for online multitask classification. Journal of Machine Learning Research, 11:2597- 2630, 2010.\n\nContextual bandits with linear payoff functions. W Chu, L Li, L Reyzin, R E Schapire, Proceedings of the International Conference on Artificial Intelligence and Statistics. the International Conference on Artificial Intelligence and StatisticsW. Chu, L. Li, L. Reyzin, and R. E. Schapire. Contextual bandits with linear payoff functions. In Proceedings of the International Conference on Artificial Intelligence and Statistics, pages 208-214, 2011.\n\nMulticlass classification with bandit feedback using adaptive regularization. K Crammer, C Gentile, Machine Learning. 90K. Crammer and C. Gentile. Multiclass classification with bandit feedback using adaptive regularization. Machine Learning, 90(3):347-383, 2013.\n\nWeighted graph cuts without eigenvectors a multilevel approach. Pattern Analysis and Machine Intelligence. I S Dhillon, Y Guan, B Kulis, IEEE Transactions on. 2911I. S. Dhillon, Y. Guan, and B. Kulis. Weighted graph cuts without eigen- vectors a multilevel approach. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 29(11):1944-1957, 2007.\n\nRegularized multi-task learning. T Evgeniou, M Pontil, Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD '04. the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD '04New York, NY, USAACMT. Evgeniou and M. Pontil. Regularized multi-task learning. In Proceed- ings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD '04, pages 109-117, New York, NY, USA, 2004. ACM.\n\nPersonalized recommendation of social software items based on social relations. I Guy, N Zwerdling, D Carmel, I Ronen, E Uziel, S Yogev, S Ofek-Koifman, Proceedings of the Third ACM Conference on Recommender Sarxiv ystems. the Third ACM Conference on Recommender Sarxiv ystemsACMI. Guy, N. Zwerdling, D. Carmel, I. Ronen, E. Uziel, S. Yogev, and S. Ofek- Koifman. Personalized recommendation of social software items based on social relations. In Proceedings of the Third ACM Conference on Recom- mender Sarxiv ystems, pages 53-60. ACM, 2009.\n\nBandit problems in networks: Asymptotically efficient distributed allocation rules. S Kar, H V Poor, S Cui, Decision and Control and European Control Conference (CDC-ECC), 2011 50th IEEE Conference on. IEEES. Kar, H. V. Poor, and S. Cui. Bandit problems in networks: Asymp- totically efficient distributed allocation rules. In Decision and Control and European Control Conference (CDC-ECC), 2011 50th IEEE Conference on, pages 1771-1778. IEEE, 2011.\n\nA contextual-bandit approach to personalized news article recommendation. L Li, W Chu, J Langford, R E Schapire, Proceedings of the 19th International Conference on World Wide Web. the 19th International Conference on World Wide WebACML. Li, W. Chu, J. Langford, and R. E. Schapire. A contextual-bandit approach to personalized news article recommendation. In Proceedings of the 19th International Conference on World Wide Web, pages 661-670. ACM, 2010.\n\nFrom bandits to experts: On the value of sideobservations. S Mannor, O Shamir, Advances in Neural Information Processing Systems. S. Mannor and O. Shamir. From bandits to experts: On the value of side- observations. In Advances in Neural Information Processing Systems, pages 684-692, 2011.\n\nKernels for multi-task learning. C A Micchelli, M Pontil, Advances in Neural Information Processing Systems. C. A. Micchelli and M. Pontil. Kernels for multi-task learning. In Advances in Neural Information Processing Systems, pages 921-928, 2004.\n\nHow social relationships affect user similarities. A Said, E W De Luca, S Albayrak, Proceedings of the 2010 Workshop on Social Recommender Systems. the 2010 Workshop on Social Recommender SystemsA. Said, E. W. De Luca, and S. Albayrak. How social relationships affect user similarities. In Proceedings of the 2010 Workshop on Social Recom- mender Systems, pages 1-4, 2010.\n\nContextual bandits with similarity information. A Slivkins, Journal of Machine Learning Research -Proceedings Track. 19A. Slivkins. Contextual bandits with similarity information. Journal of Machine Learning Research -Proceedings Track, 19:679-702, 2011.\n\nMulti-armed bandits in the presence of side observations in social networks. B Swapna, A Eryilmaz, N B Shroff, Proceedings of 52nd IEEE Conference on Decision and Control (CDC). 52nd IEEE Conference on Decision and Control (CDC)B. Swapna, A. Eryilmaz, and N. B. Shroff. Multi-armed bandits in the presence of side observations in social networks. In Proceedings of 52nd IEEE Conference on Decision and Control (CDC), 2013.\n\nGossip-based distributed stochastic bandit algorithms. B Sz\u00f6r\u00e9nyi, R Busa-Fekete, I Hegedus, R Orm\u00e1ndi, M Jelasity, B K\u00e9gl, Proceedings of the 30th International Conference on Machine Learning. the 30th International Conference on Machine LearningB. Sz\u00f6r\u00e9nyi, R. Busa-Fekete, I. Hegedus, R. Orm\u00e1ndi, M. Jelasity, and B. K\u00e9gl. Gossip-based distributed stochastic bandit algorithms. Proceedings of the 30th International Conference on Machine Learning, 2013.\n\nFeature hashing for large scale multitask learning. K Weinberger, A Dasgupta, J Langford, A Smola, J Attenberg, Proceedings of the 26th International Conference on Machine Learning. the 26th International Conference on Machine LearningOmnipressK. Weinberger, A. Dasgupta, J. Langford, A. Smola, and J. Attenberg. Fea- ture hashing for large scale multitask learning. In Proceedings of the 26th International Conference on Machine Learning, pages 1113-1120. Omni- press, 2009.\n", "annotations": {"author": "[{\"end\":111,\"start\":32},{\"end\":209,\"start\":112},{\"end\":282,\"start\":210}]", "publisher": null, "author_last_name": "[{\"end\":51,\"start\":39},{\"end\":127,\"start\":120},{\"end\":227,\"start\":219}]", "author_first_name": "[{\"end\":38,\"start\":32},{\"end\":119,\"start\":112},{\"end\":218,\"start\":210}]", "author_affiliation": "[{\"end\":110,\"start\":82},{\"end\":208,\"start\":159},{\"end\":281,\"start\":256}]", "title": "[{\"end\":18,\"start\":1},{\"end\":300,\"start\":283}]", "venue": null, "abstract": "[{\"end\":1631,\"start\":313}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2606,\"start\":2603},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2608,\"start\":2606},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2611,\"start\":2608},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3902,\"start\":3899},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6057,\"start\":6054},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6060,\"start\":6057},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6063,\"start\":6060},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6082,\"start\":6079},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6143,\"start\":6140},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6223,\"start\":6219},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6329,\"start\":6326},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6560,\"start\":6556},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6586,\"start\":6583},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6589,\"start\":6586},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6827,\"start\":6824},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6830,\"start\":6827},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6983,\"start\":6979},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7384,\"start\":7380},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8522,\"start\":8521},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9200,\"start\":9197},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10696,\"start\":10693},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11409,\"start\":11406},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":12377,\"start\":12374},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12379,\"start\":12377},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12382,\"start\":12379},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12650,\"start\":12647},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":12701,\"start\":12698},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17659,\"start\":17656},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":17770,\"start\":17767},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":17773,\"start\":17770},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":17776,\"start\":17773},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17851,\"start\":17848},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":18901,\"start\":18898},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":21825,\"start\":21822},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23703,\"start\":23702},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":26451,\"start\":26450},{\"end\":27416,\"start\":27401},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":29685,\"start\":29681},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":30531,\"start\":30530},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":31061,\"start\":31057}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":29817,\"start\":29712},{\"attributes\":{\"id\":\"fig_4\"},\"end\":29906,\"start\":29818},{\"attributes\":{\"id\":\"fig_5\"},\"end\":30104,\"start\":29907}]", "paragraph": "[{\"end\":5863,\"start\":1647},{\"end\":7508,\"start\":5880},{\"end\":8008,\"start\":7527},{\"end\":9403,\"start\":8010},{\"end\":9749,\"start\":9640},{\"end\":10044,\"start\":9859},{\"end\":10714,\"start\":10080},{\"end\":11194,\"start\":10739},{\"end\":12702,\"start\":11228},{\"end\":13608,\"start\":12704},{\"end\":13922,\"start\":13610},{\"end\":14734,\"start\":14688},{\"end\":14846,\"start\":14792},{\"end\":14926,\"start\":14848},{\"end\":15184,\"start\":15030},{\"end\":15590,\"start\":15186},{\"end\":15835,\"start\":15592},{\"end\":16711,\"start\":15977},{\"end\":17533,\"start\":16713},{\"end\":18002,\"start\":17553},{\"end\":18220,\"start\":18061},{\"end\":18332,\"start\":18300},{\"end\":19453,\"start\":18334},{\"end\":20375,\"start\":19469},{\"end\":21056,\"start\":20377},{\"end\":21404,\"start\":21058},{\"end\":21687,\"start\":21406},{\"end\":22514,\"start\":21689},{\"end\":23004,\"start\":22516},{\"end\":24556,\"start\":23026},{\"end\":25730,\"start\":24577},{\"end\":26479,\"start\":25732},{\"end\":27008,\"start\":26481},{\"end\":27464,\"start\":27010},{\"end\":29711,\"start\":27466}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9639,\"start\":9404},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9858,\"start\":9750},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10079,\"start\":10045},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10738,\"start\":10715},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14264,\"start\":13923},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14687,\"start\":14264},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14791,\"start\":14735},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15029,\"start\":14927},{\"attributes\":{\"id\":\"formula_8\"},\"end\":15976,\"start\":15836},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18060,\"start\":18003},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18299,\"start\":18221},{\"attributes\":{\"id\":\"formula_11\"},\"end\":24576,\"start\":24557}]", "table_ref": "[{\"end\":22583,\"start\":22576},{\"end\":25196,\"start\":25189},{\"end\":27908,\"start\":27901},{\"end\":28235,\"start\":28228}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1645,\"start\":1633},{\"attributes\":{\"n\":\"2\"},\"end\":5878,\"start\":5866},{\"attributes\":{\"n\":\"3\"},\"end\":7525,\"start\":7511},{\"attributes\":{\"n\":\"4\"},\"end\":11226,\"start\":11197},{\"attributes\":{\"n\":\"4.1\"},\"end\":17551,\"start\":17536},{\"attributes\":{\"n\":\"5\"},\"end\":19467,\"start\":19456},{\"end\":23024,\"start\":23007},{\"end\":29721,\"start\":29713},{\"end\":29829,\"start\":29819}]", "table": null, "figure_caption": "[{\"end\":29817,\"start\":29723},{\"end\":29906,\"start\":29831},{\"end\":30104,\"start\":29909}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11548,\"start\":11540},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11575,\"start\":11567},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12825,\"start\":12817},{\"end\":14808,\"start\":14800},{\"end\":15118,\"start\":15110},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15183,\"start\":15175},{\"end\":15209,\"start\":15201},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15352,\"start\":15344},{\"end\":15376,\"start\":15368},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16162,\"start\":16153},{\"end\":17901,\"start\":17893},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19719,\"start\":19711},{\"end\":19819,\"start\":19811},{\"end\":22178,\"start\":22170},{\"end\":22596,\"start\":22588},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":25906,\"start\":25898},{\"end\":25970,\"start\":25962},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":26073,\"start\":26065},{\"end\":27141,\"start\":27132},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27781,\"start\":27766},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":27921,\"start\":27913},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":28532,\"start\":28524}]", "bib_author_first_name": "[{\"end\":31696,\"start\":31695},{\"end\":31714,\"start\":31713},{\"end\":31721,\"start\":31720},{\"end\":31981,\"start\":31980},{\"end\":31989,\"start\":31988},{\"end\":31999,\"start\":31998},{\"end\":32372,\"start\":32371},{\"end\":32606,\"start\":32605},{\"end\":32850,\"start\":32849},{\"end\":33106,\"start\":33105},{\"end\":33118,\"start\":33117},{\"end\":33133,\"start\":33132},{\"end\":33560,\"start\":33559},{\"end\":33569,\"start\":33568},{\"end\":33579,\"start\":33578},{\"end\":33590,\"start\":33589},{\"end\":33999,\"start\":33998},{\"end\":34013,\"start\":34012},{\"end\":34029,\"start\":34028},{\"end\":34292,\"start\":34291},{\"end\":34299,\"start\":34298},{\"end\":34305,\"start\":34304},{\"end\":34315,\"start\":34314},{\"end\":34317,\"start\":34316},{\"end\":34771,\"start\":34770},{\"end\":34782,\"start\":34781},{\"end\":35065,\"start\":35064},{\"end\":35067,\"start\":35066},{\"end\":35078,\"start\":35077},{\"end\":35086,\"start\":35085},{\"end\":35348,\"start\":35347},{\"end\":35360,\"start\":35359},{\"end\":35894,\"start\":35893},{\"end\":35901,\"start\":35900},{\"end\":35914,\"start\":35913},{\"end\":35924,\"start\":35923},{\"end\":35933,\"start\":35932},{\"end\":35942,\"start\":35941},{\"end\":35951,\"start\":35950},{\"end\":36442,\"start\":36441},{\"end\":36449,\"start\":36448},{\"end\":36451,\"start\":36450},{\"end\":36459,\"start\":36458},{\"end\":36883,\"start\":36882},{\"end\":36889,\"start\":36888},{\"end\":36896,\"start\":36895},{\"end\":36908,\"start\":36907},{\"end\":36910,\"start\":36909},{\"end\":37323,\"start\":37322},{\"end\":37333,\"start\":37332},{\"end\":37589,\"start\":37588},{\"end\":37591,\"start\":37590},{\"end\":37604,\"start\":37603},{\"end\":37856,\"start\":37855},{\"end\":37864,\"start\":37863},{\"end\":37866,\"start\":37865},{\"end\":37877,\"start\":37876},{\"end\":38227,\"start\":38226},{\"end\":38512,\"start\":38511},{\"end\":38522,\"start\":38521},{\"end\":38534,\"start\":38533},{\"end\":38536,\"start\":38535},{\"end\":38914,\"start\":38913},{\"end\":38926,\"start\":38925},{\"end\":38941,\"start\":38940},{\"end\":38952,\"start\":38951},{\"end\":38963,\"start\":38962},{\"end\":38975,\"start\":38974},{\"end\":39369,\"start\":39368},{\"end\":39383,\"start\":39382},{\"end\":39395,\"start\":39394},{\"end\":39407,\"start\":39406},{\"end\":39416,\"start\":39415}]", "bib_author_last_name": "[{\"end\":31711,\"start\":31697},{\"end\":31718,\"start\":31715},{\"end\":31732,\"start\":31722},{\"end\":31986,\"start\":31982},{\"end\":31996,\"start\":31990},{\"end\":32004,\"start\":32000},{\"end\":32379,\"start\":32373},{\"end\":32611,\"start\":32607},{\"end\":32857,\"start\":32851},{\"end\":33115,\"start\":33107},{\"end\":33130,\"start\":33119},{\"end\":33140,\"start\":33134},{\"end\":33566,\"start\":33561},{\"end\":33576,\"start\":33570},{\"end\":33587,\"start\":33580},{\"end\":33597,\"start\":33591},{\"end\":34010,\"start\":34000},{\"end\":34026,\"start\":34014},{\"end\":34037,\"start\":34030},{\"end\":34296,\"start\":34293},{\"end\":34302,\"start\":34300},{\"end\":34312,\"start\":34306},{\"end\":34326,\"start\":34318},{\"end\":34779,\"start\":34772},{\"end\":34790,\"start\":34783},{\"end\":35075,\"start\":35068},{\"end\":35083,\"start\":35079},{\"end\":35092,\"start\":35087},{\"end\":35357,\"start\":35349},{\"end\":35367,\"start\":35361},{\"end\":35898,\"start\":35895},{\"end\":35911,\"start\":35902},{\"end\":35921,\"start\":35915},{\"end\":35930,\"start\":35925},{\"end\":35939,\"start\":35934},{\"end\":35948,\"start\":35943},{\"end\":35964,\"start\":35952},{\"end\":36446,\"start\":36443},{\"end\":36456,\"start\":36452},{\"end\":36463,\"start\":36460},{\"end\":36886,\"start\":36884},{\"end\":36893,\"start\":36890},{\"end\":36905,\"start\":36897},{\"end\":36919,\"start\":36911},{\"end\":37330,\"start\":37324},{\"end\":37340,\"start\":37334},{\"end\":37601,\"start\":37592},{\"end\":37611,\"start\":37605},{\"end\":37861,\"start\":37857},{\"end\":37874,\"start\":37867},{\"end\":37886,\"start\":37878},{\"end\":38236,\"start\":38228},{\"end\":38519,\"start\":38513},{\"end\":38531,\"start\":38523},{\"end\":38543,\"start\":38537},{\"end\":38923,\"start\":38915},{\"end\":38938,\"start\":38927},{\"end\":38949,\"start\":38942},{\"end\":38960,\"start\":38953},{\"end\":38972,\"start\":38964},{\"end\":38980,\"start\":38976},{\"end\":39380,\"start\":39370},{\"end\":39392,\"start\":39384},{\"end\":39404,\"start\":39396},{\"end\":39413,\"start\":39408},{\"end\":39426,\"start\":39417}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":1713123},\"end\":31940,\"start\":31644},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":13932951},\"end\":32322,\"start\":31942},{\"attributes\":{\"id\":\"b2\"},\"end\":32538,\"start\":32324},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":10485293},\"end\":32780,\"start\":32540},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":14871685},\"end\":33103,\"start\":32782},{\"attributes\":{\"id\":\"b5\"},\"end\":33505,\"start\":33105},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":6874536},\"end\":33941,\"start\":33507},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":1443517},\"end\":34240,\"start\":33943},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1452971},\"end\":34690,\"start\":34242},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":971452},\"end\":34955,\"start\":34692},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":9402790},\"end\":35312,\"start\":34957},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":719551},\"end\":35811,\"start\":35314},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":7108068},\"end\":36355,\"start\":35813},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1544223},\"end\":36806,\"start\":36357},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":207178795},\"end\":37261,\"start\":36808},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":456598},\"end\":37553,\"start\":37263},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":7051002},\"end\":37802,\"start\":37555},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":55651430},\"end\":38176,\"start\":37804},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":15132124},\"end\":38432,\"start\":38178},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":17675302},\"end\":38856,\"start\":38434},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":10720415},\"end\":39314,\"start\":38858},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":291713},\"end\":39791,\"start\":39316}]", "bib_title": "[{\"end\":31693,\"start\":31644},{\"end\":31978,\"start\":31942},{\"end\":32603,\"start\":32540},{\"end\":32847,\"start\":32782},{\"end\":33557,\"start\":33507},{\"end\":33996,\"start\":33943},{\"end\":34289,\"start\":34242},{\"end\":34768,\"start\":34692},{\"end\":35062,\"start\":34957},{\"end\":35345,\"start\":35314},{\"end\":35891,\"start\":35813},{\"end\":36439,\"start\":36357},{\"end\":36880,\"start\":36808},{\"end\":37320,\"start\":37263},{\"end\":37586,\"start\":37555},{\"end\":37853,\"start\":37804},{\"end\":38224,\"start\":38178},{\"end\":38509,\"start\":38434},{\"end\":38911,\"start\":38858},{\"end\":39366,\"start\":39316}]", "bib_author": "[{\"end\":31713,\"start\":31695},{\"end\":31720,\"start\":31713},{\"end\":31734,\"start\":31720},{\"end\":31988,\"start\":31980},{\"end\":31998,\"start\":31988},{\"end\":32006,\"start\":31998},{\"end\":32381,\"start\":32371},{\"end\":32613,\"start\":32605},{\"end\":32859,\"start\":32849},{\"end\":33117,\"start\":33105},{\"end\":33132,\"start\":33117},{\"end\":33142,\"start\":33132},{\"end\":33568,\"start\":33559},{\"end\":33578,\"start\":33568},{\"end\":33589,\"start\":33578},{\"end\":33599,\"start\":33589},{\"end\":34012,\"start\":33998},{\"end\":34028,\"start\":34012},{\"end\":34039,\"start\":34028},{\"end\":34298,\"start\":34291},{\"end\":34304,\"start\":34298},{\"end\":34314,\"start\":34304},{\"end\":34328,\"start\":34314},{\"end\":34781,\"start\":34770},{\"end\":34792,\"start\":34781},{\"end\":35077,\"start\":35064},{\"end\":35085,\"start\":35077},{\"end\":35094,\"start\":35085},{\"end\":35359,\"start\":35347},{\"end\":35369,\"start\":35359},{\"end\":35900,\"start\":35893},{\"end\":35913,\"start\":35900},{\"end\":35923,\"start\":35913},{\"end\":35932,\"start\":35923},{\"end\":35941,\"start\":35932},{\"end\":35950,\"start\":35941},{\"end\":35966,\"start\":35950},{\"end\":36448,\"start\":36441},{\"end\":36458,\"start\":36448},{\"end\":36465,\"start\":36458},{\"end\":36888,\"start\":36882},{\"end\":36895,\"start\":36888},{\"end\":36907,\"start\":36895},{\"end\":36921,\"start\":36907},{\"end\":37332,\"start\":37322},{\"end\":37342,\"start\":37332},{\"end\":37603,\"start\":37588},{\"end\":37613,\"start\":37603},{\"end\":37863,\"start\":37855},{\"end\":37876,\"start\":37863},{\"end\":37888,\"start\":37876},{\"end\":38238,\"start\":38226},{\"end\":38521,\"start\":38511},{\"end\":38533,\"start\":38521},{\"end\":38545,\"start\":38533},{\"end\":38925,\"start\":38913},{\"end\":38940,\"start\":38925},{\"end\":38951,\"start\":38940},{\"end\":38962,\"start\":38951},{\"end\":38974,\"start\":38962},{\"end\":38982,\"start\":38974},{\"end\":39382,\"start\":39368},{\"end\":39394,\"start\":39382},{\"end\":39406,\"start\":39394},{\"end\":39415,\"start\":39406},{\"end\":39428,\"start\":39415}]", "bib_venue": "[{\"end\":31783,\"start\":31734},{\"end\":32089,\"start\":32006},{\"end\":32369,\"start\":32324},{\"end\":32649,\"start\":32613},{\"end\":32936,\"start\":32859},{\"end\":33217,\"start\":33142},{\"end\":33675,\"start\":33599},{\"end\":34075,\"start\":34039},{\"end\":34413,\"start\":34328},{\"end\":34808,\"start\":34792},{\"end\":35114,\"start\":35094},{\"end\":35477,\"start\":35369},{\"end\":36034,\"start\":35966},{\"end\":36557,\"start\":36465},{\"end\":36987,\"start\":36921},{\"end\":37391,\"start\":37342},{\"end\":37662,\"start\":37613},{\"end\":37950,\"start\":37888},{\"end\":38293,\"start\":38238},{\"end\":38610,\"start\":38545},{\"end\":39050,\"start\":38982},{\"end\":39496,\"start\":39428},{\"end\":32159,\"start\":32091},{\"end\":33738,\"start\":33677},{\"end\":34485,\"start\":34415},{\"end\":35589,\"start\":35479},{\"end\":36089,\"start\":36036},{\"end\":37040,\"start\":36989},{\"end\":37999,\"start\":37952},{\"end\":38662,\"start\":38612},{\"end\":39105,\"start\":39052},{\"end\":39551,\"start\":39498}]"}}}, "year": 2023, "month": 12, "day": 17}