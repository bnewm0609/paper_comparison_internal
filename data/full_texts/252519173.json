{"id": 252519173, "updated": "2023-10-05 10:31:56.174", "metadata": {"title": "Promptagator: Few-shot Dense Retrieval From 8 Examples", "authors": "[{\"first\":\"Zhuyun\",\"last\":\"Dai\",\"middle\":[]},{\"first\":\"Vincent\",\"last\":\"Zhao\",\"middle\":[\"Y.\"]},{\"first\":\"Ji\",\"last\":\"Ma\",\"middle\":[]},{\"first\":\"Yi\",\"last\":\"Luan\",\"middle\":[]},{\"first\":\"Jianmo\",\"last\":\"Ni\",\"middle\":[]},{\"first\":\"Jing\",\"last\":\"Lu\",\"middle\":[]},{\"first\":\"Anton\",\"last\":\"Bakalov\",\"middle\":[]},{\"first\":\"Kelvin\",\"last\":\"Guu\",\"middle\":[]},{\"first\":\"Keith\",\"last\":\"Hall\",\"middle\":[\"B.\"]},{\"first\":\"Ming-Wei\",\"last\":\"Chang\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, this overlooks the fact that there are many diverse and unique retrieval tasks, each targeting different search intents, queries, and search domains. In this paper, we suggest to work on Few-shot Dense Retrieval, a setting where each task comes with a short description and a few examples. To amplify the power of a few examples, we propose Prompt-base Query Generation for Retriever (Promptagator), which leverages large language models (LLM) as a few-shot query generator, and creates task-specific retrievers based on the generated data. Powered by LLM's generalization ability, Promptagator makes it possible to create task-specific end-to-end retrievers solely based on a few examples {without} using Natural Questions or MS MARCO to train %question generators or dual encoders. Surprisingly, LLM prompting with no more than 8 examples allows dual encoders to outperform heavily engineered models trained on MS MARCO like ColBERT v2 by more than 1.2 nDCG on average on 11 retrieval sets. Further training standard-size re-rankers using the same generated data yields another 5.0 point nDCG improvement. Our studies determine that query generation can be far more effective than previously observed, especially when a small amount of task-specific knowledge is given.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2209.11755", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iclr/DaiZMLNLBGHC23", "doi": "10.48550/arxiv.2209.11755"}}, "content": {"source": {"pdf_hash": "e86009d9f9b1cdf083a48d087552bc4153784451", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2209.11755v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "5b816fb6909f08166387d6a75c2e5893d8123a6e", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/e86009d9f9b1cdf083a48d087552bc4153784451.txt", "contents": "\nPROMPTAGATOR : FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES\n\n\nZhuyun Dai zhuyundai@google.com*equalcontributions\u2020correspondingauthors \nGoogle Research\n\n\nVincent Y Zhao vzhao@google.com*equalcontributions\u2020correspondingauthors \nGoogle Research\n\n\nJi Ma maji@google.com*equalcontributions\u2020correspondingauthors \nGoogle Research\n\n\nYi Luan luanyi@google.com*equalcontributions\u2020correspondingauthors \nGoogle Research\n\n\nJianmo Ni \nGoogle Research\n\n\nJing Lu \nGoogle Research\n\n\nAnton Bakalov \nGoogle Research\n\n\nKelvin Guu \nGoogle Research\n\n\nKeith B Hall \nGoogle Research\n\n\nMing-Wei Chang mingweichang@google.com*equalcontributions\u2020correspondingauthors \nGoogle Research\n\n\nPROMPTAGATOR : FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES\n\nMuch recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, this overlooks the fact that there are many diverse and unique retrieval tasks, each targeting different search intents, queries, and search domains. In this paper, we suggest to work on Few-shot Dense Retrieval, a setting where each task comes with a short description and a few examples. To amplify the power of a few examples, we propose Promptbase Query Generation for Retriever (PROMPTAGATOR ), which leverages large language models (LLM) as a few-shot query generator, and creates task-specific retrievers based on the generated data. Powered by LLM's generalization ability, PROMPTAGATOR makes it possible to create task-specific end-to-end retrievers solely based on a few examples without using Natural Questions(Kwiatkowski et al., 2019)or MS MARCO (Nguyen et al., 2016)  to train dual encoders. Surprisingly, LLM prompting with no more than 8 examples allows dual encoders to outperform heavily engineered models trained on MS MARCO like ColBERT v2(Santhanam et al., 2022)by more than 1.2 nDCG on average on 11 retrieval sets. Further training standard-size re-rankers using the same generated data yields another 5.0 point nDCG improvement. Our studies determine that query generation can be far more effective than previously observed, especially when a small amount of task-specific knowledge is given.\n\nINTRODUCTION\n\nRecently, major progress has been made on neural retrieval models such as dual encoders, which can retrieve knowledge from a large collection of documents containing millions to billions of passages (Yih et al., 2011;Karpukhin et al., 2020). However, Thakur et al. (2021) recently proposed the BEIR heterogeneous retrieval benchmark, and showed that it is still difficult for neural retrievers to perform well on a wide variety of retrieval tasks that lack dedicated training data. Thus, previous approaches focus on transferring knowledge from question answering (QA) datasets such as MS MARCO (Nguyen et al., 2016). To best transfer from QA datasets, expressive retrievers are developed that allow fine-grained token-level interaction such as ColBERT (Khattab & Zaharia, 2020;Santhanam et al., 2022) and SPLADE (Formal et al., 2021) but with higher inference cost. Data augmentation via synthetic question generation has previously been explored Shakeri et al., 2020), but these question generators are typically only trained on popular QA datasets.\n\nWe argue that it is hard to expect models based on one or two QA datasets to perform well across different retrieval tasks. First, different retrieval tasks have very different search intents; in other words, different definitions of \"relevance\". For example, as illustrated in Figure 1(a), both Dbpedia-Entity (Hasibi et al., 2017) and FEVER (Thorne et al., 2018) are tasks to retrieve documents from Wikipedia. Dbpedia-Entity is a task to retrieve entities that are mentioned in the query, while FEVER is a task to find evidence that either supports or refutes a given statement. Which document is relevant to the query can be very different from one task to another task even if they share the same (2) which trains model on a large QA retrieval datasets and transfer to other retrieval tasks. Right (c): Few-shot PROMPTAGATOR performance. Average nDCG@10 on 11 datasets from BEIR from our PROMPTAGATOR models and previously MS MARCO-supervised models (SPLADE v2).\n\ndomain. Moreover, different tasks have distinct distributions of queries even when their search intents are similar. For example, in the BEIR benchmark, queries in HotpotQA (Yang et al., 2018) are long compositional questions, while queries in FiQA (Maia et al., 2018) are short financial questions.\n\nIn this paper, we advocate to work on the setting of Few-shot Retrieval for diverse retrieval ( \u00a72), where each task comes with a short description and a few annotated examples to clearly illustrate the search intents. Given that only a few examples are available, we propose Prompt-base Query Generation for Retriever (PROMPTAGATOR) ( \u00a73) which aims to resolve the data scarcity issue while retaining the efficiency of a small dual encoder, by harnessing the power of large language models (LLM) such as FLAN (Wei et al., 2022a). PROMPTAGATOR combines prompting with LLMs as a query generator without fine-tuning ( \u00a73.1), and can generate good queries with minimal supervision -shown in Figure 1(b), it solely relies on a few supervised examples from the target task without using annotated query-document pairs from Natural Questions (Kwiatkowski et al., 2019) or MS MARCO (Nguyen et al., 2016) to train the retriever directly. The key insight of PROMPTAGATOR is to amplify the power of few-shot examples by creating task-specific prompting, which in turn enables generating a large set of synthetic queries for training retrievers suited for the task. To ensure the generated data quality, we develop a filtering technique that ensures round-trip consistency using generated data only ( \u00a73.2). Our filter is tailored to retrieval, which removes ambiguous, generic, and low-quality questions, and significantly improves retrieval performance.\n\nWhile PROMPTAGATOR is not the first application of LLM for retrieval, prior attempts of using LLMs often come with higher serving cost. Neelakantan et al. (2022) proposes to use the GPT-3 (Brown et al., 2020) embeddings in dual encoder models. However, the embedding size is 12k and hence makes the search index footprint and inference cost high. Sachan et al. (2022) and Bonifacio et al. (2022) have applied prompting and LLMs for reranking, while leaving the retriever untouched. With PROMPTAGATOR, we show that LLMs can be used to generate efficient end-to-end retriever with high accuracy. The contributions of the paper are as follows:\n\n\u2022 We analyze the previously overlooked differences across retrieval tasks in their search intents and query distributions, and propose a Few-Shot Retrieval setting for the BEIR dataset. Our prompt and fewshot examples will be released to facilitate future research.\n\n\u2022 We propose PROMPTAGATOR, a simple recipe for few-shot retrieval by prompting with a LLM to generate synthetic task-specific training data. For the first time, end-to-end retrievers solely based on a few supervised examples can be strong and efficient to serve with PROMPTAGATOR.\n\n\u2022 Our experimental results show that, surprisingly, PROMPTAGATOR with two-to-eight examples produced significantly better retrievers compared to recent models trained on MS MARCO or NQ that have over 500K human annotated examples (Figure 1(c)). PROMPTA-GATOR outperforms ColBERT v2 and SPLADE v2 on 11 retrieval tasks we tested, while reranking boosts results by another 5 points on standard retrieval evaluation metric.\n\n\nFEW-SHOT RETRIEVAL TASK\n\nIn this section, we first introduce the definition of a retrieval task and the differences among different retrieval tasks. We then propose a new Few-Shot Retrieval setting for the BEIR benchmark.\n\n\nRETRIEVAL TASK\n\nGiven a large corpus, a retrieval model is responsible to find documents that are most relevant to a provided query q according to a pre-defined relevancy. Formally, we define a retrieval task as:\nT = {D, Q, I},\nwhere D = {d 1 , d 2 , ..., d n } is a large corpus of documents for retrieval, Q is a query distribution, and I is the underlying search intent for the task. Depending on the task, D can be any document collection, such as web or Wikipedia. Q also varies across tasks, e.g., short keyword search queries, questions, arguments, etc. If I(q, d) = 1, it means search intent of q has been satisfied by the document d. For example, in QA tasks such as Natural Questions (NQ) the search intent is to find passages that provide the answer to the question, meaning I NQ (q, d) = 1 if d answers q. Importantly, for the same pair of (q, d), their relevance can be completely different under different search intents. For example, some argument retrieval tasks look for supporting arguments, while other tasks need to retrieve counter arguments.\n\nIn this work, we target the scenario where a target retrieval corpus D T is available, but the amount of annotated query-document pairs for the new task is limited. Most prior of research efforts were put into adapting retrievers to new corpus D T , but the divergence in queries Q T and intents I T remains under-explored. Next, we explore how search intent can be expressed with a short description and very few number of examples.\n\n\nFEW-SHOT BEIR SETTING\n\nIn this paper, we argue that it is important to let retrievers be aware of task-specific query distribution and search intent, as opposed to merely focusing on the domain adaptation of D. Prior belief is that it is expensive to collect enough in-distribution queries and relevance labels to train a neural retriever, but intuitively, a person can understand a retrieval task by reading a short instruction and going over a few examples. In this work, we ask if a few (8 or fewer) examples are sufficient for the machines to learn a task-specific retriever. To facilitate our study and future research of few-shot retrieval, we define a new few-shot retrieval evaluation setting built upon the BEIR heterogeneous retrieval benchmark (Thakur et al., 2021).\n\nBEIR has 18 information retrieval datasets across 9 domains, including Bio-Medical, Finance, News, Twitter, Wikipedia, StackExchange, Quora, Scientific, and Misc. These datasets also cover a diverse range of search intents: QA retrieval (question-to-document), duplicate question discovery (questionto-question), fact checking (claim-to-document), etc. Following Santhanam et al. (2022) and Formal et al. (2021), we narrow our focus to the publicly-available datasets in BEIR. The original BEIR evaluation used a zero-shot set up, where no queries or relevant query-document pairs from the evaluation datasets can be used to train the retrievers.\n\nWe extend BEIR to the few-shot setting by randomly taking a few ( PROMPTAGATOR consists of three components: prompt-based query generation, consistency filtering, and retriever training. During prompt-based query generation, a task-specific prompt will be combined with a large language model to produce queries for the target task using D T . Then a filtering step cleans the generated data based on round-trip consistency; surprisingly, we found a retriever trained only on the synthetic data can be used to filter the synthetic data. Finally, a retriever (in this paper, dual encoders) and a cross attention reranker will be trained based on the generated data. Figure 5 in Appendix shows the overall procedure.\n\n3.1 PROMPT-BASE QUERY GENERATION PROMPTAGATOR constructs instruction prompt that consists task-specific query passage descriptions and k annotated query-document examples from the target dataset. Specifically, let{(q i , d i )} k be k relevant query-document pairs from the target task T , where q i \u223c Q T , d i \u2208 D T , and I T (q i , d i ) = 1. Following FLAN (Wei et al., 2022a), we use instruction prompts with the following form:\n(e doc (d i ), e query (q 1 ), . . . , e doc (d k ), e query (q k ), e doc (d))\nwhere e doc (d) and e query (q) are task-specific document, query descriptions respectively, and d is a new document. Take ArguAna for example, we set e doc (d) = \"Argument:{d}\" and e query = \"Counter Argument:{q}\" to inform the LLM to generate counter arguments. The LLM will is expected to generate e query (q). If the LLM does not generate query description correctly, we consider it a generation failure and drop the output; otherwise we accept q and form a synthetic relevant example (q, d).\n\nRunning the prompt on all documents from D T , we can create a large set of synthetic (q, d) examples, amplifying the information from few examples into a large synthetic dataset whose query distribution is similar to true task distribution Q T and query-document pairs convey the true search intent I T .\n\nWe use FLAN (Wei et al., 2022a) as the LLM for query generation in this work. FLAN is trained on a collection of tasks described via instructions and was shown to have good zero/few-shot performance on unseen tasks. We use the 137B FLAN checkpoint provided by the authors. During prompt engineering, we use at most 8 examples, and reduce the number if they exceed the input length limit of FLAN. we also manually truncate individual query and document in the examples if they are too long. We randomly sample up to 1 million documents from each corpus and generate 8 questions per document using sampling decoding with temperature 0.7. The set of templates can be found in Table 4 in the Appendix.\n\n\nCONSISTENCY FILTERING USING ONLY GENERATED DATA\n\nThe filtering step improves the quality of generated queries by ensuring the round-trip consistency (Alberti et al., 2019): a query should be answered by the passage from which the query was generated. In our retrieval case, the query should retrieve its source passage. Consistency filtering  has been shown crucial for synthetic question generation on QA tasks. However, these techniques typically rely on an external question-answering model as the filter, trained on existing supervised QA data. Since we want to address different search intents, using a single external filtering model does not work for us.\n\nSurprisingly, we find out that consistency filtering based on the generated data alone can work well over the different search intents observed in BEIR. We first use the generated query and document pairs to train an initial retriever. Given a synthetic query-document pair (q, d), we use the initial retriever to predict the most relevant passages for q. We keep q only when d occurs among the Top-K passages returned by the retriever. This may seem unintuitive because the filtering model (the initial retriever) is trained on the same noisy synthetic data that it will filter. We show this filter substantially reduces the number of synthetic queries and significantly improves retrieval performance.\n\n\nFEW-SHOT PROMPTAGATOR RETRIEVER\n\nOur synthetically generated data allows training task-specific neutral retrievers for tasks where supervised in-domain fine-tuning is challenging due to data scarcity. In this work, we use the standard dual-encoder retrieval architecture and we propose a simple pretrain/fine-tune recipe.\n\n\nRetrieval Supervision\n\n\nCross-Attn Distillation\n\nRetriever Token-level Retrieval Serving Model Size # Reranking Doc.\n\nQGen Model Table 1: Comparison of settings, resources and model size for different frameworks. Our models are just a 110M-size dual encoder PROMPTAGATOR and a 110M-size reranker PROMPTAGATOR++, as good quality generated data allows simple models/pipeline to achieve strong performance. See text for more details for UPR's QGen model 1 .\nContriever NA self 110M 0 GTR-XXL MS MARCO(500K) self 6B 0 Splade v2 MS MARCO(500K) self 110M 0 ColBERT v2 MS MARCO(500K) self 110M 0 GenQ MS MARCO(500K) self 110M 0 T5 (MS MARCO) GPL MS MARCO(500K) self 110M 0 T5 (MS MARCO) MonoT5 MS MARCO(500K) BM25 3B 1000 InPars Few (3) BM25 3B 1000 GPT-3 UPR NA Contriever 110M+3B 1000 T0 * PROMPTAGATOR Few (0-8) self 110M 0 FLAN PROMPTAGATOR++ Few (0-8) PROMPTAGATOR 110M+110M 200 FLAN\nFollowing prior work , we initialize the dual encoder using the Transformer encoder from a T5 (Raffel et al., 2020) checkpoint. We then pretrain our retriever on C4 with the independent cropping task from Contriever (Izacard et al., 2022a), where we treat two random crops from the same document as positive retrieval pairs and train with a cross-entropy loss over in-batch random negatives. Next, we fine-tune the dual-encoder on the query-document pairs generated from our prompt-base QGen, again with cross-entropy loss over in-batch random negatives. After training for a set number of epochs, we apply round-trip filtering on our synthetic data as described in ( \u00a73.2) using this initial dual encoder, and continue to fine-tune the dual encoder on the filtered data.\n\nWe also propose PROMPTAGATOR++, a reranker trained on the same synthetic data generated from our prompt-base QGen, which refines the retrieved candidates using a slower but more accurate cross-attention model. We train the reranker using a cross-entropy loss with 31 sampled negatives from top 200 passages retrieved by the PROMPTAGATOR retriever, which approximates the inference time distribution (reranking top 200 from the retriever).\n\n\nZERO-SHOT PROMPTAGATOR RETRIEVER\n\nThe prompt-based query generation can also run in a zero-shot manner, where we universally apply the following prompt irrespective of the target task: f'{d} Read the passage and generate a query.'. Here d denotes the document text. We train retrievers and rerankers on the zero-shot prompt generated data, leading to zero-shot PROMPTAGATOR and zero-shot PROMPTAGATOR++. Table 1 compares the PROMPTAGATOR recipe to some recently proposed approaches. Our dual encoder does not rely on hard negative mining or distillation; it uses a standard dual encoder model without adding the token-level matching inductive biases that ColBERT and SPLADE have. Our reranker also uses a 110M model instead of larger models. We aim to use this simplified recipe to highlight the power of few-shot data, as we will shown in ( \u00a74.3). Comparing PROMPTAGATOR to these approaches, the ability to use a prompt and few-shot examples with a LLM makes PROMPTAGATOR be able to generate efficient models with high accuracy. While other LLM approaches such as InPars (Bonifacio et al., 2022) and UPR (Sachan et al., 2022) have focused on reranking, PROMPTAGATOR focuses on retrieval.\n\n\nDISCUSSION\n\n\nEXPERIMENTS\n\nWe report quantitative evaluation of PROMPTAGATOR by measuring its retrieval performance on the BEIR benchmark. We then dive deeper into the results through ablation studies and qualitative analysis.\n\n\nIMPLEMENTATION\n\nThe original FLAN training set overlapped with 2 datasets in the BEIR benchmark: NQ 2 and Quora 3 . Most of existing systems use all of the supervised data from MS MARCO in their system. Therefore we exclude MS MARCO, NQ and Quora from our main evaluations. We report nDCG@10, the standard retrieval evaluation metric on BEIR.\n\nFor PROMPTAGATOR's prompt-based query generation, we sample questions from the LLM with a temperature of 0.7. For round-trip filtering, we use MS MARCO as validation set and tune K. We find setting K to 1 leads to the best results and thus use 1 for all BEIR datasets, i.e. we keep a (q, d) pair only when d is ranked in the top 1 place by the initial dual encoder.\n\nWe implement PROMPTAGATOR's dual encoders following GTR ; in particular, we use a shared Transformer encoder initialized from T5, take the mean pooling of the top encoder layer, and project it to a fixed 768-dimensional embedding. To ensure efficiency, we use the T5-base version 1.1 encoder architecture consisting of 110M parameters. For PROMPTAGATOR++ reranking models, we use the standard Transformer cross attention encoder, also initialized with a 110M T5-base encoder checkpoint. At inference time, we rerank the top 200 candidates retrieved from the PROMPTAGATOR dual encoder retriever.\n\nWe mostly follow the hyper-parameters used in the . The default batch size in this recipe is 6k; however, some of the corpora in BEIR contain only a few thousand documents, making multiple relevant documents appear in the same batch which interacts negatively with the in-batch softmax loss. We found it important to use appropriate batch sizes and training steps for those small datasets. We split the datasets into three groups based on corpus size: small datasets (<50k), middle datasets (50k-500k), large datasets (>500k). For dual encoder training, we use 128 batch size for small datasets and 6k for others. We finetune for 5k steps for large datasets and 1k for others. For ranking models, we use batch size of 64 for all datasets and finetune large datasets for 20k steps, 5k for others. Table 2 shows the experimental results. We first notice that zero-shot PROMPTAGATOR already serves as a strong baseline, comparing favorably to other retrieval baselines trained on O(100K) examples from MS MARCO. Nonetheless, few-shot PROMPTAGATOR markedly improves upon zeroshot PROMPTAGATOR, increasing the averaged nDCG@10 by over 2 points, which highlights the impact of adapting the LLM to the target task. Few-shot PROMPTAGATOR, being relatively simple in training steps and model architecture, outperforms strong baselines such as GenQ (Thakur et al., 2021) and GPL  which also use query generation to augment training data, as well as ColBERT v2 (Santhanam et al., 2022) and SPLADE v2 (Formal et al., 2021) which rely on token level interaction architectures and distillation recipes.\n\n\nMAIN RESULTS\n\nOur reranker PROMPTAGATOR++ further boosts performance with another 5 points gain on nDCG@10. It significantly outperforms UPR (Sachan et al., 2022) whose reranker uses T0 (Sanh et al., 2021), an instruction tuned LLM similar to FLAN. It also outperforms monoT5-3B , which achieved previous state-of-the-art reranking performance on BEIR in a recent study by Rosa et al. (2022). Note most of these reranker approach uses a 3B model for its better generalization ability than smaller models, while PROMPTAGATOR++ uses a standard 110M rereanker.\n\nComparing few-shot PROMPTAGATOR to baselines, the biggest improvement is on Touche-2020 (touch\u00e9), followed by ArguAna (arg) . Touche-2020's goal is to retrieve documents for a controversial topic, e.g., \"should felons who have completed their sentence be allowed to vote?\". ArguAna's goal is to find the counter-arguments that oppose the input argument, and the input arguments are often several-sentence long.  In the scenario where speed is not a concern, reranker is often used. We train PROMPTAGATOR++ use the same generated data and get significant improvement. See text for more details for Climate-Fever. 4 models use, which are dominated by factoid questions. On the other hand, few-shot PROMPTAGATOR can successfully adapt to this task with a few examples.\n\n\nABLATION STUDY\n\nNext, we study our results in greater detail and analyze factors contributing to performance.\n\nImpact of consistency filtering. In Figure 2(a), we show quality difference between few-shot PROMPTAGATOR with and without round-trip filtering. We can see that filtering improves performance on 8 out of 11 datasets, and leads to 2.5 points improvement on average. These results demonstrate the effectiveness of our fitlering strategy. There are nonetheless datasets where filtering hurts model quality such as NFCorpus and SciFact. Note these are the smallest datasets in terms of generated queries. We conjecture further tuning dual encoder models on the filtered data results in overfitting.\n\nManually examining the query document pairs removed by the filter, we find the majority cases are either the query being too general which matches many documents, or the query contains hallucination irrelevant to the document. There are also cases where high quality query document pairs were incorrectly removed since the initial dual encoder model ranks other documents higher. We suspect designing query-specific K values would help retain such query document pairs and further improve model performance. We leave this to future exploration.\n\nCan generated queries replace human annotated queries? In Figure 2(  fine-tuned on NQ. The figure shows the advantages of zero-shot PROMPTAGATOR, outperforming both fine-tuned QGen models by large margins. NQ-QGen uses the same filtering, dual-encoder training, batch sizes and training steps as PROMPTAGATOR, providing an apple-to-apple comparison of the query generators. These results indicate that the main contributing factor to PROMPTAGATOR is the prompted LLM query generation, not the specific training recipe or hype-parameters.\n\nDoes Few-shot always improve over Zero-shot? As shown in Table 2, few-shot PROMPTAGATOR almost always outperforms zero-shot PROMPTAGATOR. The only exception is Climate-FEVER (climate). After examining this dataset, we realized that in the original Climate-FEVER dataset, a query-document pair can be annotated as either \"supports\", \"refutes\", or \"not enough info\". BEIR treats these three annotations all as relevant; however, a \"not enough info\" document may not be related to the query. Using such pairs in the few-shot prompts can hurt query generation. Therefore, we tried switching to FEVER's few-shot prompt, as the two datasets share same corpus and similar search intents.  \n\n\nImpact of FLAN versions\n\nIn the main experiments we have used the FLAN model described in Wei et al. (2022a). This model was trained on a collection of datasets including question-answer datasets; specifically, it includes Natural Questions (NQ) and Quora. FLAN was not trained on query-document pairs from NQ or Quora; however, in order to determine whether the inclusion of this data biased the results on the final retrieval evaluation, we designed an additional ablation experiment. Following the recipe from Wei et al. (2022a) used to train the original FLAN models, we trained an additional LLM excluding both the NQ and Quora datasets.   (Figure 4).\n\n\nQUALITATIVE ANALYSIS\n\nIn order to understand the advantages of few-shot PROMPTAGATOR, we analyze the distribution of the first words of the queries generated by different query generation methods for the ArguAna task in Figure 3. Note that the distribution of few-shot PROMPTAGATOR (Fig. 3b) is much closer to the real distribution ( Fig. 3a) while the NQ-QGen (Fig. 3c) mostly generated questions even when query of the tasks are arguments. Examples are showcased in Table 5 in the Appendix.\n\n\nRELATED WORK\n\nNeural retrieval models The success of pre-trained large language models Raffel et al., 2020;Brown et al., 2020) has fostered a lush growth in the field of neural retrieval models. Neural retrieval models can be grouped into two categories, namely representation based models and interaction based models.\n\nRepresentation based models (Palangi et al., 2016;Gillick et al., 2018;Karpukhin et al., 2020) encode a query and passage independently into a common dense space, and scores their relevance based on vector dot-product or cosine similarity. Recent research on representation based models has primarily focused on the following aspects: developing better pre-training tasks Chang et al., 2020;Khattab & Zaharia, 2020;Izacard et al., 2022a;Oguz et al., 2022) or pre-training architectures (Gao & Callan, 2021;, improving expressiveness using multi-vector representations , improving negative contrast Xiong et al., 2021;, and improving generalization across different domains (Thakur et al., 2021;Ren et al., 2022). Different techniques have been explored to improve the generalization, such as using query generation for data augmentation , using contrastive learning for better pre-training (Izacard et al., 2022a), using knowledge distillation ) and scaling the model size .\n\nAlthough encoding the query and document into a single vector enables fast retrieval via approximate nearest neighbor search (Johnson et al., 2021;Wu et al., 2019), it also constrains the representational power of these models thus leading to sub-optimal predictions. Interaction based models on the other hand explicitly model the interaction between query and document terms (Guo et al., 2016;Hui et al., 2017;Dai et al., 2018;McDonald et al., 2018;Nogueira & Cho, 2019), and therefore make more informed decisions. These models are typically more expensive, and thus are used for reranking or rescoring. Distilling interaction based models into representation based models has been shown effective in closing the gap between the two (Hofst\u00e4tter et al., 2020;Ren et al., 2021a;Lin et al., 2021;Ren et al., 2021b;Reddi et al., 2021;Zhang et al., 2022). Another attempt to combine the best of both worlds is by postponing the interaction until the last layer of the model (Gao et al., 2021a;Khattab & Zaharia, 2020), blurring the boundary between representation and interaction models.\n\nFew-shot Learning The development of pre-trained large language models also popularize the few-shot learning paradigm, which utilizes a few examples as context for model inputs (Brown et al., 2020;Wei et al., 2022b). Two approaches are commonly used. One approach is to provide the LLM an instruction of the task in natural language with a few examples and do not update any parameter of LLM (Brown et al., 2020;Bonifacio et al., 2022). The other approach provides the LLM the instruction, a few examples and also performs model fine-tuning (Schick & Sch\u00fctze, 2021a;b;c;Gao et al., 2021b;Logan IV et al., 2022;Izacard et al., 2022b). Our work adopts the first approach. Usually 10-100 examples are used. For example, 32 examples are used in the few-shot setting in GPT3. In the context of retrieval, Bonifacio et al. (2022) provides GPT3 three question-document pairs and uses it as the question generator for training interaction based models.\n\nPrompt-based Query Generation The idea of using prompted LLMs for query generation has previously been proposed for improving retrieval reranking. In UPR (Sachan et al., 2022), they proposed to use prompted LLMs to rerank the passages directly. InPars (Bonifacio et al., 2022) is probably the most closely related work to ours, where they proposed to use few-shot prompting with GPT-3 to generate synthetic data for training a T5-based reranker applied to a BM25 retriever. In this paper, we propose few-shot prompted LLMs and show that generated data can produce efficient and strong end-to-end retrievers. Moreover, we show the quality of generated data can be improved by task-specific prompts and consistency filtering.\n\nRetrievers with late interactions While dual encoder models are very efficient at retrieval due to the MIPS algorithms, their expressivity is limited due to the fact that their score is just a dot-product between the query vector and the document vector. ColBERT (Santhanam et al., 2022;Khattab & Zaharia, 2020) and SPLADE (Formal et al., 2021) are the models to increase the interactions between the query and document by allowing token-level interactions. Because these models are not just dot product between queries and documents, MIPS algorithms can not be used directly. Hence, these models usually have much higher serving cost compared to dual encoders.\n\n\nCONCLUSION AND DISCUSSIONS\n\nIn this paper, we have presented PROMPTAGATOR, a novel approach to few-shot retrieval. We showed that it is possible to create task-specific, end-to-end retrievers with only a few annotated examples. The few-shot examples, amplified by prompt-based LLM query generation, simplifies the complexity of training neural retrievers for a new tasks and leads to promising retrieval performance gains. It hopefully inspires future research to further push the limit of few-shot retrieval, towards generalizable retrieval systems that can seamlessly and efficiently adapt to many tasks.\n\nWhile we demonstrate that query generation can be very effective, many questions remain for the roles of question generation and large language models. One of the key issue that needs thorough investigation is on the generated data efficiency. We have not yet explored exactly how many querydocument pairs are needed for each task, or how to use these generated examples more efficiently. Another issue that is worthwhile understanding is the sensitivity of final retriever's performance with respect to the prompt. Finally, we would like to draw a connection from PROMPTAGATOR to distillation, as the final dual encoders definitely benefit a lot from the large language model. Analyzing the headroom and understanding how we can better transfer knowledge from LLMs to retrievers would be a critical topic for the future.\n\n\nCOMPUTE USAGE AND ENVIRONMENTAL IMPACT\n\nWe used the 137B large language model FLAN for query generation. FLAN is based on the same pretrained model as LaMDA (Thoppilan et al., 2022). LaMDA was pre-trained on a large corpus consisting of 1.56T words, costing 451 MWh energy and 25.2 tCO2e carbon footprint. In PROMPTAGATOR, we generated 29.23M queries * 2 prompts = 58.46M queries, for a total of 610M words. As mentioned in ( \u00a76), PROMPTAGATOR can be viewed as distilling LLM to standard-sized dual encoders via prompt-based query generation. While the distillation process is computationally expensive, it significantly reduces cost for inference. Table 4 shows the list of prompt templates on different BEIR datasets. In order to further analysis the difference between zero-shot and few-shot prompts, we compare the few-shot and zero-shot generated queries given the same paragraph, randomly sampled from three datasets in Table 5. We observe that in general, the few-shot generated queries are closer to the original queries, while zero-shot queries are mostly questions. For example, in the ArguAna dataset, the few-shot queries are in general longer and more claim-like. In contrary, the zero-shot queries are most short question-like queries. Interestingly, for the HotpotQA dataset, even though both few-shot and zero-shot queries are generating questions-like queries, few-shot queries sometimes generate multi-hop questions, while zero-shot mostly generates single-hop questions. We further conduct first word distribution across different generation models for all datasets in Figure 4.  B DETAILED IMPLEMENTATION Figure 5 shows the overall process of PROMPTAGATOR++, the details of which are in Section 3.  Table 6: Average query length.\n\n\nA ANALYSIS ON PROMPTS\n\n\nC QUERY GENERATION STATISTICS\n\nIn Table 6, we analyze the length of the generated questions by different query generation systems. Note that NQ-QGen always generates short queries due to the query generation models being fine-tuned on the NQ dataset, and all of the generated questions have similar length to those questions of NQ. Interestingly, zero-shot PROMPTAGATOR already obtains more variance in terms of length compared to NQ-QGen. Finally, few-shot PROMPTAGATOR offers significantly more variance in terms of the length of generated queries. ArguAna: Banning skin whitening on such a basis also requires the acceptance of the racial overtones. Some form of tan is popular in many societies of people of European ethnic origins -that is not a racial matter, it is more based on economic social perceptions (that of holidays to warmer climates). Ascribing a racial element to everything to do with skin tone is at best a lazy analysis. Irrespective of issues of race and perceptions of ethnic origins, and its intersection with beauty standards, some people will be given advantages in life due to their appearance. Banning a certain form of cosmetic, even if it can have some racial and ethnic undertones, won't change that.\n\n\nD AUTHOR CONTRIBUTIONS\n\nQuery 1: Banning skin whitening on such a basis also requires the acceptance of the racial overtones. However, the racial overtones are simply a side effect of the product being used incorrectly in order to attain a lighter skin tone than they are naturally born with. The product itself is not racist, but rather the people who use it. For example, a person of Asian descent may use a skin whitening cream to attain a lighter skin tone so that they may fit into a more white-dominant society. The cream itself is not racist, but rather the fact that the person has used it to attain a lighter skin tone so that they may fit into a more white-dominant society.\n\nQuery 1: What did they try to ban? Query 2: Is skin whitening racist? Query 3: Banning skin whitening on such a basis also requires the acceptance of the racial overtones. Some form of tan is popular in many societies of people of European ethnic origins -that is not a racial matter, it is more based on economic social perceptions (that of holidays to warmer climates). Query 4: What are some of the racial overtones in skinwhitening? Query 5: Are tans a sign of affluence?\n\nIn ArguAna dataset, the few-shot examples are more statement like and are longer than zero-shot.\n\nTouch\u00e9-2020: Psychologically,diet-wise and academically. Housewives can be both educated and uneducated but the fact that they spend more time with their children means that they put in a greater effort and since they are not preoccupied with their job(read: cellphone); they pay the close attention needed to keep their children out of trouble. Think of housewives as inspectors in your home...   \n\nFigure 1 :\n1Few-shot retrieval with PROMPTAGATOR. Left (a): Retrieval tasks from BEIR differ in query distribution, retrieval corpus, and search intents. Middle (b): Most prior work uses supervised setting\n\n000 Figure 2 :\n0002How does PROMPTAGATOR compare to other query generation approaches?Figure 2(c) compares zero-shot PROMPTAGATOR to two query generation approaches: GenQ(Thakur et al., 2021) uses a MS MARCO trained T5 query generation model, and NQ-QGen is our in-house T5 QGen modelN=50,Left (a): Consistency filter. Delta in nDCG@10 between few-shot PROMPTAGATOR with and without round-trip filter. Middle (b): Comparing the effect of the generated data versus the number of supervised data on MS MARCO. The LLM can amplify the power of the few examples, making 8 examples to catch up with 50k labeled examples, when simple dual encoders are used. Right (c):Ablation on query generation model. GenQ is a prior query generation system fromThakur  et al. (2021), while NQ-QGen is our in-house T5 query generation model trained on NQ. Other than the generated data, NQ-QGen and PROMPTAGATOR uses the same hyper parameters.\n\nFigure 3 :\n3Top first word distribution on queries generated from different models in the ArguAna dataset. Left (a)(b)(c): Compare gold queries (a) and generated queries (b)(c). Queries generated by few-shot models has closer distribution to the gold queries, while the NQ-QGen queries are mostly questions. Right (d): The few shot FLAN can generate diverse queries even though there are only 4 examples in the prompt. Statistics of more datasets are available in the Appendix\n\nFigure 5 :\n5PROMPTAGATOR++ Training pipeline.\n\n\nBoth tasks are extremely different from traditional QA retrieval data that otherarg \n\ntouch\u00e9 covid \nnfc \nhotpot \ndbp \nclimate \nfever scifact scidocs fiqa \nAVG. \n\nRetriever \n\nUnsupervised \nBM25 \n31.5 \n36.7 \n65.6 \n32.5 \n60.3 \n31.3 \n21.3 \n75.3 \n66.5 \n15.8 \n23.6 \n41.8 \nContriever \n37.9 \n19.3 \n27.4 \n31.7 \n48.1 \n29.2 \n15.5 \n68.2 \n64.9 \n14.9 \n24.5 \n34.7 \nSupervised [MS MARCO] \nGTR-XXL \n54.0 \n25.6 \n50.1 \n34.2 \n59.9 \n40.8 \n26.7 \n74.0 \n66.2 \n16.1 \n46.7 \n44.9 \nSPLADE v2 \n47.9 \n27.2 \n71.0 \n33.4 \n68.4 \n43.5 \n23.5 \n78.6 \n69.3 \n15.8 \n33.6 \n46.6 \nColBERT v2 \n46.3 \n26.3 \n73.8 \n33.8 \n66.7 \n44.6 \n17.6 \n78.5 \n69.3 \n15.4 \n35.6 \n46.2 \nGenQ \n49.3 \n18.2 \n61.9 \n31.9 \n53.4 \n32.8 \n17.5 \n66.9 \n64.4 \n14.3 \n30.8 \n40.1 \nGPL \n55.7 \n25.5 \n70.0 \n34.5 \n58.2 \n38.4 \n23.5 \n75.9 \n67.4 \n16.9 \n34.4 \n45.5 \n\nPROMPTAGATOR (110M) \nZero-shot \n53.8 \n26.6 \n72.7 \n33.4 \n60.4 \n36.4 \n21.4 \n76.2 \n62.3 \n16.3 \n40.4 \n45.5 \nFew-shot \n59.4 \n34.5 \n75.6 \n33.4 \n61.4 \n38.0 16.8 (24.0  *  ) 77.0 \n65.0 \n18.4 \n46.2 \n47.8 \n\nRetriever + Reranker \n\nUnsupervised \nUPR (3B) \n50.3 \n21.3 \n60.4 \n33.3 \n72.2 \n33.8 \n9.5 \n57.3 \n69.6 \n17.3 \n45.0 \n42.7 \nInPars (3B) \n-\n-\n78.4 \n-\n-\n-\n-\n-\n-\n-\n-\n-\nSupervised [MS MARCO] \nmonoT5 (220M) 13.2 \n27.7 \n77.8 \n35.7 \n69.5 \n41.9 \n24.5 \n80.2 \n73.6 \n16.5 \n41.4 \n45.6 \nmonoT5 (3B) \n28.8 \n20.0 \n79.5 \n38.4 \n75.9 \n47.8 \n28.0 \n85.0 \n77.7 \n19.7 \n51.4 \n51.1 \n\nPROMPTAGATOR++ (110M + 110M) \nZero-shot \n52.1 \n27.8 \n76.0 \n36.0 \n71.2 \n41.3 \n22.6 \n83.8 \n73.2 \n19.1 \n45.9 \n49.9 \nFew-shot \n63.0 \n38.1 \n76.2 \n37.0 \n73.6 \n43.4 20.3 (24.1  *  ) 86.6 \n73.1 \n20.1 \n49.4 \n52.8 \n\n\n\nTable 2 :\n2Main Results. nDCG@10 on BEIR. Retriever Comparisons (Upper Half): Among the various kind of retrievers, both zero-shot and few-shot PROMPTAGATOR produce strong results . Note that ColBERT v2 and SPLADE v2 allows token-level interactions, but PROMPTAGATOR DE models do not. Retriever+Reranker Comparisons (Lower Half):\n\n\nb), we compare the dual encoders trained on examples generated from the 8-shot PROMPTAGATOR vs the dual encoders trained on supervised data. Note that we did not add other components to make the comparison simple. We choose MS MARCO as there are enough labeled data for this task and neither FLAN nor our models are trained on MS MARCO examples. The results showed that the eight examples plus LLM can replace a significant portion of the supervised examples.\n\n\nWith the better annotated examples, few-shot PROMPTAGATOR indeed surpass zeroshot. This result provides some evidence that low quality few-shot examples negatively affectPROMPTAGATOR. \n\narg \ntouch\u00e9 covid \nnfc \nhotpot dbp climate fever scifact scidocs fiqa \nAVG. \n\nFLAN original \n59.4 \n34.5 \n75.6 \n33.4 \n61.4 \n38.0 (24.0*) 77.0 \n65.0 \n18.4 \n46.2 \n48.5 \nFLAN w/o NQ and Quora 58.8 \n33.3 \n70.2 \n33.7 \n61.7 \n34.4 (23.5*) 76.2 \n63.8 \n18.3 \n43.0 \n47.0 \n\n\n\nTable 3 :\n3Impact of different FLAN version. We use Fever model for Climte Fever for this study.See ( \u00a74.3) for more details. \n\n\n\nTable 3\n3shows the results for PROMPTAGATOR trained with and without NQ and Quora. While the accuracy drops slightly, the overall performance still outperform prior retrievers.OTHER \n\n72.4 \nthe \n15.2 \na 4.3 \nit 3.7 \nthere 2.3 \nthis 1.2 \nif 0.8 \n\n(a) Gold queries \n\nOTHERS \n63.1 \nthe \n23.2 \na 1.7 \nit 4.3 \nthere 4.1 \nthis 1.9 \nprogressive 1.7 \n\n(b) Few-shot \n\nOTHERS \n10.6 \nwhat \n30.4 \nwho \n28.4 \nthe \n9.1 \nwhen \n8.3 \nwhere \n6.8 \nwhy \n6.5 \n\n(c) NQ-QGen \n\nwhile \n25.0 \nit \n25.0 \nnew \n25.0 \nthe \n25.0 \n\n\n\nTable 4 :\n4Prompt template for each dataset.\n\n\nQuery 1: Housewives are better parents Query 2: Should housewives be considered better parents? Query 1: ,diet-wise and academically. Query 2: People want to be relaxed all the time(At home AND at work) that is why all the research on work-life balance. Query 3:has shown that homemakers are more relaxed, less stressed, healthier, happierthe list goes on. HotpotQA: The Yung See San Fong House, or \u0178oung's Home in the Heart of the Hills, is a house in Los Gatos in the U.S. state of California. It is a combination of Asian decorative motifs and pagoda roofs together with Western massing and layout. It was completed in 1917 for Ruth Comfort Mitchell Young, a writer, and her husband, Sanborn Young, a gentleman farmer, conservationist and later California State Senator. Query 1: Which author was the husband of Ruth Comfort Mitchell Young? Query 2: Which is known as the Yount-Lee House Query 3: Who is the architect of the Yung See San Fong House? Query 4: The Yung See San Fong House, or \u0178oung's Home in the Heart of the Hills, is a house in which U.S. state? Query 1: Yung See San Fong House was completed in 1917 for Ruth Comfort Mitchell Young, a writer, and her husband, Sanborn Young. Query 2: How old is the Yung See San Fong House? Query 3: Yung See San Fong House was completed in 1917 for Ruth Comfort Mitchell Young, a writer, and her husband, Sanborn Young.The few-shot gener-\nates argument-like \nqueries that are more \ncontroversial, while \nzero-shot generate \nrandom statements \nthat \nsometimes \neven have grammar \nproblems. \n\nFew-shot examples \nsometimes will create \nmultihop questions \nindicated in blue, \nwhich rarely hap-\npens in zero-shot \nexamples. \n\n\n\nTable 5 :\n5Few-shot and zero-shot generated queries randomly sampled from ArguAna, FiQA and HotpotQA dataset.Few-shot examples Figure 4: Top first word distribution on queries generated from different models in all other BEIR datasets. Argument: {doc1} Counter-argument: {query1} X Argument {doc2} Counter-argument: {query2} X Argument: {document} XSciFact \n\n\nUPR uses T0 query generation for reranking, instead of for synthetic data augmentation that other QGen approaches do.\nFLAN is only trained on question-to-answer tasks and never observes the question-passage supervision needed for retrieval training. Additionally, FLAN has not been fine-tuned on query generation tasks on QA datasets.3  We study the impact of NQ and Quora on FLAN query generation in ( \u00a74.3) 4 Climate-FEVER's relevant (q, d) pairs in BEIR are not well-defined ( \u00a74.3), so we also tried running querygeneration with FEVER's few-shot prompt on Climate-FEVER. We report the results with FEVER prompt in (), but they are not used for computing the average.\nPrompts (3 examples)\nACKNOWLEDGEMENTSWe thank Kenton Lee, Tom Kwiatkowski, and Daniel Gillick for technical discussion and providing feedback on our manuscript. We thank Alex Salcianu for developing a bulk inference pipeline for large language models.\nSynthetic QA corpora generation with roundtrip consistency. Chris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin, Michael Collins, 10.18653/v1/P19-1620Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational LinguisticsChris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin, and Michael Collins. Synthetic QA corpora generation with roundtrip consistency. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 6168-6173, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1620. URL https://aclanthology. org/P19-1620.\n\nInpars: Unsupervised dataset generation for information retrieval. Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Rodrigo Nogueira, 10.1145/3477495.3531863Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '22. the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '22New York, NY, USA, 2022Association for Computing MachineryLuiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, and Rodrigo Nogueira. Inpars: Unsupervised dataset generation for information retrieval. In Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '22, pp. 2387-2392, New York, NY, USA, 2022. Association for Computing Machinery. ISBN 9781450387323. doi: 10.1145/3477495.3531863. URL https://doi.org/10.1145/3477495.3531863.\n\nLanguage models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems. H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. LinScott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec RadfordCurran Associates, Inc33Ilya Sutskever, and Dario AmodeiTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Ben- jamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 1877-1901. Curran Associates, Inc., 2020. URL https://proceedings.neurips. cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.\n\nPre-training tasks for embedding-based large-scale retrieval. Wei-Cheng Chang, Felix X Yu, Yin-Wen Chang, Yiming Yang, Sanjiv Kumar, International Conference on Learning Representations. Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, and Sanjiv Kumar. Pre-training tasks for embedding-based large-scale retrieval. In International Conference on Learning Representa- tions, 2020. URL https://openreview.net/forum?id=rkg-mA4FDr.\n\nSalient phrase aware dense retrieval: Can a dense retriever imitate a sparse one? CoRR. Xilun Chen, Kushal Lakhotia, Barlas Oguz, Anchit Gupta, Patrick Lewis, Stan Peshterliev, Yashar Mehdad, Sonal Gupta, Wen-Tau Yih, Xilun Chen, Kushal Lakhotia, Barlas Oguz, Anchit Gupta, Patrick Lewis, Stan Peshterliev, Yashar Mehdad, Sonal Gupta, and Wen-tau Yih. Salient phrase aware dense retrieval: Can a dense retriever imitate a sparse one? CoRR, 2021. URL https://arxiv.org/abs/2110.06918.\n\nConvolutional neural networks for soft-matching n-grams in ad-hoc search. Zhuyun Dai, Chenyan Xiong, Jamie Callan, Zhiyuan Liu, 10.1145/3159652.3159659Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, WSDM '18. the Eleventh ACM International Conference on Web Search and Data Mining, WSDM '18New York, NY, USAAssociation for Computing MachineryZhuyun Dai, Chenyan Xiong, Jamie Callan, and Zhiyuan Liu. Convolutional neural networks for soft-matching n-grams in ad-hoc search. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, WSDM '18, pp. 126-134, New York, NY, USA, 2018. Association for Computing Machinery. URL https://doi.org/10.1145/3159652.\n\nBERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational Linguistics1Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171-4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. URL https://aclanthology.org/ N19-1423.\n\nSPLADE v2: Sparse lexical and expansion model for information retrieval. CoRR, abs/2109.10086. Thibault Formal, Carlos Lassance, Benjamin Piwowarski, St\u00e9phane Clinchant, Thibault Formal, Carlos Lassance, Benjamin Piwowarski, and St\u00e9phane Clinchant. SPLADE v2: Sparse lexical and expansion model for information retrieval. CoRR, abs/2109.10086, 2021. URL https://arxiv.org/abs/2109.10086.\n\nCondenser: a pre-training architecture for dense retrieval. Luyu Gao, Jamie Callan, 10.18653/v1/2021.emnlp-main.75Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingOnline and Punta Cana, Dominican RepublicAssociation for Computational LinguisticsLuyu Gao and Jamie Callan. Condenser: a pre-training architecture for dense retrieval. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 981-993, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.75. URL https://aclanthology.org/ 2021.emnlp-main.75.\n\nUnsupervised corpus aware language model pre-training for dense passage retrieval. Luyu Gao, Jamie Callan, 10.18653/v1/2022.acl-long.203Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics1Luyu Gao and Jamie Callan. Unsupervised corpus aware language model pre-training for dense passage retrieval. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2843-2853, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.203. URL https://aclanthology.org/2022.acl-long.203.\n\nCOIL: Revisit exact lexical match in information retrieval with contextualized inverted list. Luyu Gao, Zhuyun Dai, Jamie Callan, 10.18653/v1/2021.naacl-main.241Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnlineAssociation for Computational LinguisticsLuyu Gao, Zhuyun Dai, and Jamie Callan. COIL: Revisit exact lexical match in information retrieval with contextualized inverted list. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 3030-3042, Online, June 2021a. Association for Computational Linguistics. doi: 10.18653/v1/ 2021.naacl-main.241. URL https://aclanthology.org/2021.naacl-main.241.\n\nMaking pre-trained language models better few-shot learners. Tianyu Gao, Adam Fisch, Danqi Chen, 10.18653/v1/2021.acl-long.295Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingAssociation for Computational Linguistics1Tianyu Gao, Adam Fisch, and Danqi Chen. Making pre-trained language models better few-shot learners. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguis- tics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 3816-3830, Online, August 2021b. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.295. URL https://aclanthology.org/2021.acl-long.\n\nEnd-to-end retrieval in continuous space. Daniel Gillick, Alessandro Presta, Gaurav Singh Tomar, abs/1811.08008CoRR. Daniel Gillick, Alessandro Presta, and Gaurav Singh Tomar. End-to-end retrieval in continuous space. CoRR, abs/1811.08008, 2018. URL https://arxiv.org/abs/1811.08008.\n\nA deep relevance matching model for ad-hoc retrieval. Jiafeng Guo, Yixing Fan, Qingyao Ai, W Bruce Croft, 10.1145/2983323.2983769Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, CIKM '16. the 25th ACM International on Conference on Information and Knowledge Management, CIKM '16New York, NY, USAJiafeng Guo, Yixing Fan, Qingyao Ai, and W. Bruce Croft. A deep relevance matching model for ad-hoc retrieval. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, CIKM '16, pp. 55-64, New York, NY, USA, 2016. URL https: //doi.org/10.1145/2983323.2983769.\n\nDbpedia-entity v2: A test collection for entity search. Faegheh Hasibi, Fedor Nikolaev, Chenyan Xiong, Krisztian Balog, Svein Erik Bratsberg, Alexander Kotov, Jamie Callan, 10.1145/3077136.3080751Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '17. the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '17New York, NY, USAFaegheh Hasibi, Fedor Nikolaev, Chenyan Xiong, Krisztian Balog, Svein Erik Bratsberg, Alexander Kotov, and Jamie Callan. Dbpedia-entity v2: A test collection for entity search. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '17, pp. 1265-1268, New York, NY, USA, 2017. ISBN 9781450350228. URL https://doi.org/10.1145/3077136.3080751.\n\nImproving efficient neural ranking models with cross-architecture knowledge distillation. ArXiv, abs. Sebastian Hofst\u00e4tter, Sophia Althammer, Michael Schr\u00f6der, Mete Sertkan, Allan Hanbury, Sebastian Hofst\u00e4tter, Sophia Althammer, Michael Schr\u00f6der, Mete Sertkan, and Allan Hanbury. Improving efficient neural ranking models with cross-architecture knowledge distillation. ArXiv, abs/2010.02666, 2020. URL https://arxiv.org/abs/2010.02666.\n\nPACRR: A position-aware neural IR model for relevance matching. Kai Hui, Andrew Yates, Klaus Berberich, Gerard De Melo, 10.18653/v1/D17-1110Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational LinguisticsKai Hui, Andrew Yates, Klaus Berberich, and Gerard de Melo. PACRR: A position-aware neu- ral IR model for relevance matching. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 1049-1058, Copenhagen, Denmark, Septem- ber 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1110. URL https://www.aclweb.org/anthology/D17-1110.\n\nUnsupervised dense information retrieval with contrastive learning. Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, Edouard Grave, Transactions on Machine Learning Research. Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. Unsupervised dense information retrieval with contrastive learning. Transactions on Machine Learning Research, 2022a. URL https://openreview.net/ forum?id=jKN1pXi7b0.\n\nFew-shot learning with retrieval augmented language models. Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, Edouard Grave, Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. Few-shot learning with retrieval augmented language models, 2022b. URL https://arxiv.org/abs/2208.03299.\n\nBillion-scale similarity search with gpus. Jeff Johnson, Matthijs Douze, Herv\u00e9 J\u00e9gou, 10.1109/TBDATA.2019.2921572IEEE Transactions on Big Data. 73Jeff Johnson, Matthijs Douze, and Herv\u00e9 J\u00e9gou. Billion-scale similarity search with gpus. IEEE Transactions on Big Data, 7(3):535-547, 2021. doi: 10.1109/TBDATA.2019.2921572. URL https://doi.org/10.1109/TBDATA.2019.2921572.\n\nDense passage retrieval for open-domain question answering. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, 10.18653/v1/2020.emnlp-main.550Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational LinguisticsVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. Dense passage retrieval for open-domain question answering. In Proceed- ings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 6769-6781, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/ 2020.emnlp-main.550. URL https://aclanthology.org/2020.emnlp-main.550.\n\nEfficient and effective passage search via contextualized late interaction over BERT. Omar Khattab, Matei Zaharia, Colbert, 10.1145/3397271.3401075Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event. Jimmy Huang, Yi Chang, Xueqi Cheng, Jaap Kamps, Vanessa Murdock, Ji-Rong Wen, and Yiqun Liuthe 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual EventChinaACM2020Omar Khattab and Matei Zaharia. ColBERT: Efficient and effective passage search via contextualized late interaction over BERT. In Jimmy Huang, Yi Chang, Xueqi Cheng, Jaap Kamps, Vanessa Murdock, Ji-Rong Wen, and Yiqun Liu (eds.), Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020, pp. 39-48. ACM, 2020. doi: 10.1145/3397271.3401075. URL https: //doi.org/10.1145/3397271.3401075.\n\nNatural questions: A benchmark for question answering research. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M Dai, Jakob Uszkoreit, Quoc Le, Slav Petrov, 10.1162/tacl_a_00276Transactions of the Association for Computational Linguistics. 7Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:452-466, March 2019. doi: 10.1162/tacl_a_00276. URL https://aclanthology.org/Q19-1026.\n\nLatent retrieval for weakly supervised open domain question answering. Kenton Lee, Ming-Wei Chang, Kristina Toutanova, 10.18653/v1/P19-1612Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational LinguisticsKenton Lee, Ming-Wei Chang, and Kristina Toutanova. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association for Com- putational Linguistics, pp. 6086-6096, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1612. URL https://aclanthology.org/P19-1612.\n\nPAQ: 65 million probably-asked questions and what you can do with them. Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich K\u00fcttler, Aleksandra Piktus, Pontus Stenetorp, Sebastian Riedel, 10.1162/tacl_a_00415Transactions of the Association for Computational Linguistics. 9Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich K\u00fcttler, Aleksandra Piktus, Pontus Stenetorp, and Sebastian Riedel. PAQ: 65 million probably-asked questions and what you can do with them. Transactions of the Association for Computational Linguistics, 9:1098-1115, 2021. doi: 10.1162/tacl_a_00415. URL https://aclanthology.org/2021.tacl-1.\n\nIn-batch negatives for knowledge distillation with tightly-coupled teachers for dense retrieval. Jheng-Hong Sheng-Chieh Lin, Jimmy Yang, Lin, 10.18653/v1/2021.repl4nlp-1.17Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021). the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)Association for Computational LinguisticsSheng-Chieh Lin, Jheng-Hong Yang, and Jimmy Lin. In-batch negatives for knowledge dis- tillation with tightly-coupled teachers for dense retrieval. In Proceedings of the 6th Work- shop on Representation Learning for NLP (RepL4NLP-2021), pp. 163-173, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.repl4nlp-1.17. URL https://aclanthology.org/2021.repl4nlp-1.17.\n\nCutting down on prompts and parameters: Simple few-shot learning with language models. Robert Logan, I V , Ivana Balazevic, Eric Wallace, Fabio Petroni, Sameer Singh, Sebastian Riedel, 10.18653/v1/2022.findings-acl.222Findings of the Association for Computational Linguistics: ACL 2022. Dublin, IrelandAssociation for Computational LinguisticsRobert Logan IV, Ivana Balazevic, Eric Wallace, Fabio Petroni, Sameer Singh, and Sebastian Riedel. Cutting down on prompts and parameters: Simple few-shot learning with language models. In Findings of the Association for Computational Linguistics: ACL 2022, pp. 2824-2835, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.findings-acl. 222. URL https://aclanthology.org/2022.findings-acl.222.\n\nMulti-stage training with improved negative contrast for neural passage retrieval. Jing Lu, Gustavo Hernandez Abrego, Ji Ma, Jianmo Ni, Yinfei Yang, 10.18653/v1/2021.emnlp-main.492Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational LinguisticsOnline and Punta Cana, Dominican RepublicJing Lu, Gustavo Hernandez Abrego, Ji Ma, Jianmo Ni, and Yinfei Yang. Multi-stage training with improved negative contrast for neural passage retrieval. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 6091-6103, Online and Punta Cana, Do- minican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/ 2021.emnlp-main.492. URL https://aclanthology.org/2021.emnlp-main.492.\n\nSparse, Dense, and Attentional Representations for Text Retrieval. Yi Luan, Jacob Eisenstein, Kristina Toutanova, Michael Collins, 10.1162/tacl_a_00369Transactions of the Association for Computational Linguistics. 9Yi Luan, Jacob Eisenstein, Kristina Toutanova, and Michael Collins. Sparse, Dense, and Attentional Representations for Text Retrieval. Transactions of the Association for Computational Linguistics, 9:329-345, 04 2021. ISSN 2307-387X. doi: 10.1162/tacl_a_00369. URL https://doi.org/ 10.1162/tacl_a_00369.\n\nZero-shot neural passage retrieval via domain-targeted synthetic question generation. Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, Ryan Mcdonald, 10.18653/v1/2021.eacl-main.92Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeAssociation for Computational LinguisticsJi Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, and Ryan McDonald. Zero-shot neural passage retrieval via domain-targeted synthetic question generation. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 1075-1088, Online, April 2021. Association for Computational Linguistics. doi: 10.18653/v1/ 2021.eacl-main.92. URL https://aclanthology.org/2021.eacl-main.92.\n\nWww'18 open challenge: financial opinion mining and question answering. Macedo Maia, Siegfried Handschuh, Andr\u00e9 Freitas, Brian Davis, Ross Mcdermott, Manel Zarrouk, Alexandra Balahur, 10.1145/3184558.3192301In Companion proceedings of the the web conference 2018Macedo Maia, Siegfried Handschuh, Andr\u00e9 Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, and Alexandra Balahur. Www'18 open challenge: financial opinion mining and question answering. In Companion proceedings of the the web conference 2018, pp. 1941-1942, 2018. URL https: //doi.org/10.1145/3184558.3192301.\n\nDeep relevance ranking using enhanced document-query interactions. Ryan Mcdonald, George Brokos, Ion Androutsopoulos, 10.18653/v1/D18-1211Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational LinguisticsRyan McDonald, George Brokos, and Ion Androutsopoulos. Deep relevance ranking using enhanced document-query interactions. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1849-1860, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1211. URL https://www. aclweb.org/anthology/D18-1211.\n\n. Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas A Tezak, Jong Wook Kim, Chris Hallacy, Johannes Heidecke, Pranav Shyam, Boris Power, Tyna Eloundou Nekoul, Girish Sastry, Gretchen Krueger, David P Schnurr, Felipe Petroski Such, Kenny Sai-Kin Hsu, Madeleine Thompson, Tabarak Khan, Toki Sherbakov, Joanne Jang, Peter Welinder, and Lilian WengText and code embeddings by contrastive pre-training. ArXiv, abs/2201.10005, 2022Arvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas A. Tezak, Jong Wook Kim, Chris Hallacy, Johannes Heidecke, Pranav Shyam, Boris Power, Tyna Eloundou Nekoul, Girish Sastry, Gretchen Krueger, David P. Schnurr, Felipe Petroski Such, Kenny Sai-Kin Hsu, Madeleine Thompson, Tabarak Khan, Toki Sherbakov, Joanne Jang, Peter Welinder, and Lilian Weng. Text and code embeddings by contrastive pre-training. ArXiv, abs/2201.10005, 2022. URL https://arxiv.org/abs/2201.10005.\n\nMs marco: A human generated machine reading comprehension dataset. Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, CoCo@NIPS. Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng. Ms marco: A human generated machine reading comprehension dataset. In CoCo@NIPS, 2016. URL http://ceur-ws.org/Vol-1773/CoCoNIPS_2016_paper9.pdf.\n\nLarge dual encoders are generalizable retrievers. Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hern\u00e1ndez \u00c1brego, Ji Ma, Vincent Y Zhao, Yi Luan, Keith B Hall, Ming-Wei Chang, Yinfei Yang, abs/2112.07899CoRRJianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hern\u00e1ndez \u00c1brego, Ji Ma, Vincent Y. Zhao, Yi Luan, Keith B. Hall, Ming-Wei Chang, and Yinfei Yang. Large dual encoders are generalizable retrievers. CoRR, abs/2112.07899, 2021. URL https://arxiv.org/abs/2112.07899.\n\nRodrigo Nogueira, Kyunghyun Cho, Passage re-ranking with bert. arXiv. Rodrigo Nogueira and Kyunghyun Cho. Passage re-ranking with bert. arXiv, 2019. URL https: //arxiv.org/abs/1901.04085.\n\nDocument ranking with a pretrained sequence-to-sequence model. Rodrigo Nogueira, Zhiying Jiang, Ronak Pradeep, Jimmy Lin, 10.18653/v1/2020.findings-emnlp.63Findings of the Association for Computational Linguistics: EMNLP 2020. Trevor Cohn, Yulan He, and Yang LiuAssociation for Computational Linguistics2020EMNLP 2020 of Findings of ACLRodrigo Nogueira, Zhiying Jiang, Ronak Pradeep, and Jimmy Lin. Document ranking with a pretrained sequence-to-sequence model. In Trevor Cohn, Yulan He, and Yang Liu (eds.), Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020, volume EMNLP 2020 of Findings of ACL, pp. 708-718. Association for Computational Linguistics, 2020. doi: 10.18653/v1/2020.findings-emnlp.63. URL https://doi.org/10. 18653/v1/2020.findings-emnlp.63.\n\nDomain-matched pre-training tasks for dense retrieval. Barlas Oguz, Kushal Lakhotia, Anchit Gupta, Patrick Lewis, Vladimir Karpukhin, Aleksandra Piktus, Xilun Chen, Sebastian Riedel, Scott Yih, Sonal Gupta, Yashar Mehdad, 10.18653/v1/2022.findings-naacl.114Findings of the Association for Computational Linguistics: NAACL 2022. Seattle, United StatesAssociation for Computational LinguisticsBarlas Oguz, Kushal Lakhotia, Anchit Gupta, Patrick Lewis, Vladimir Karpukhin, Aleksandra Piktus, Xilun Chen, Sebastian Riedel, Scott Yih, Sonal Gupta, and Yashar Mehdad. Domain-matched pre-training tasks for dense retrieval. In Findings of the Association for Computational Linguistics: NAACL 2022, pp. 1524-1534, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.findings-naacl.114. URL https://aclanthology. org/2022.findings-naacl.114.\n\nDeep sentence embedding using long short-term memory networks: Analysis and application to information retrieval. Hamid Palangi, Li Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying Song, Rabab Ward, 10.1109/TASLP.2016.2520371IEEE/ACM Transactions on Audio, Speech, and Language Processing. 244Hamid Palangi, Li Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying Song, and Rabab Ward. Deep sentence embedding using long short-term memory networks: Anal- ysis and application to information retrieval. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 24(4):694-707, 2016. URL https://doi.org/10.1109/TASLP. 2016.2520371.\n\nRocketQA: An optimized training approach to dense passage retrieval for open-domain question answering. Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, 10.18653/v1/2021.naacl-main.466Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesYingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, and Haifeng Wang. RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 5835-5847, June 2021. doi: 10.18653/v1/2021.naacl-main.466. URL https: //aclanthology.org/2021.naacl-main.466.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam M Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, W Li, Peter J Liu, Journal of Machine Learning Research. 21Colin Raffel, Noam M. Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, W. Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21/140:1-67, 2020. URL http://jmlr.org/papers/v21/20-074.html.\n\nRankdistil: Knowledge distillation for ranking. J Sashank, Rama Reddi, Aditya Krishna Kumar Pasumarthi, Ankit Menon, Felix X Singh Rawat, Seungyeon Yu, Andreas Kim, Sanjiv Veit, Kumar, AISTATS. Sashank J. Reddi, Rama Kumar Pasumarthi, Aditya Krishna Menon, Ankit Singh Rawat, Felix X. Yu, Seungyeon Kim, Andreas Veit, and Sanjiv Kumar. Rankdistil: Knowledge distillation for ranking. In AISTATS, pp. 2368-2376, 2021. URL http://proceedings.mlr.press/ v130/reddi21a.html.\n\nPAIR: Leveraging passage-centric similarity relation for improving dense passage retrieval. Ruiyang Ren, Shangwen Lv, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Ji-Rong Wen, doi: 10.18653/ v1/2021.findings-acl.191Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Association for Computational LinguisticsRuiyang Ren, Shangwen Lv, Yingqi Qu, Jing Liu, Wayne Xin Zhao, QiaoQiao She, Hua Wu, Haifeng Wang, and Ji-Rong Wen. PAIR: Leveraging passage-centric similarity relation for improving dense passage retrieval. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 2173-2183, Online, August 2021a. Association for Computational Linguistics. doi: 10.18653/ v1/2021.findings-acl.191. URL https://aclanthology.org/2021.findings-acl.\n\nRocketQAv2: A joint training method for dense passage retrieval and passage re-ranking. Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Ji-Rong Wen, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicOnline and Punta CanaRuiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, QiaoQiao She, Hua Wu, Haifeng Wang, and Ji-Rong Wen. RocketQAv2: A joint training method for dense passage retrieval and passage re-ranking. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 2825-2835, Online and Punta Cana, Dominican Republic, November 2021b.\n\n. 10.18653/v1/2021.emnlp-main.224Association for Computational LinguisticsAssociation for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.224. URL https: //aclanthology.org/2021.emnlp-main.224.\n\nA thorough examination on zero-shot dense retrieval. Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qifei Wu, Yuchen Ding, Hua Wu, Haifeng Wang, Ji-Rong Wen, Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qifei Wu, Yuchen Ding, Hua Wu, Haifeng Wang, and Ji-Rong Wen. A thorough examination on zero-shot dense retrieval, 2022. URL https://arxiv.org/abs/2204.12755.\n\nNo parameter left behind: How distillation and model size affect zero-shot retrieval. Luiz Guilherme Moraes Rosa, Vitor Bonifacio, Hugo Jeronymo, Marzieh Abonizio, Roberto Fadaee, Rodrigo Lotufo, Nogueira, arXiv:2206.02873arXiv preprintGuilherme Moraes Rosa, Luiz Bonifacio, Vitor Jeronymo, Hugo Abonizio, Marzieh Fadaee, Roberto Lotufo, and Rodrigo Nogueira. No parameter left behind: How distillation and model size affect zero-shot retrieval. arXiv preprint arXiv:2206.02873, 2022.\n\nImproving passage retrieval with zero-shot question generation. Devendra Singh Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-Tau Yih, Joelle Pineau, Luke Zettlemoyer, arXivDevendra Singh Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke Zettlemoyer. Improving passage retrieval with zero-shot question generation. arXiv, 2022. URL https://arxiv.org/abs/2204.07496.\n\nMultitask prompted training enables zero-shot task generalization. Victor Sanh, Albert Webson, Colin Raffel, H Stephen, Lintang Bach, Zaid Sutawika, Antoine Alyafeai, Arnaud Chaffin, Teven Le Stiegler, Arun Scao, Raja, arXiv:2110.08207arXiv preprintVictor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. Multitask prompted training enables zero-shot task generalization. arXiv preprint arXiv:2110.08207, 2021.\n\nColBERTv2: Effective and efficient retrieval via lightweight late interaction. Keshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, Matei Zaharia, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesKeshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, and Matei Zaharia. ColBERTv2: Effective and efficient retrieval via lightweight late interaction. In Proceed- ings of the 2022 Conference of the North American Chapter of the Association for Com- putational Linguistics: Human Language Technologies, pp. 3715-3734, July 2022. URL https://aclanthology.org/2022.naacl-main.272.\n\nExploiting cloze-questions for few-shot text classification and natural language inference. Timo Schick, Hinrich Sch\u00fctze, 10.18653/v1/2021.eacl-main.20Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeAssociation for Computational LinguisticsTimo Schick and Hinrich Sch\u00fctze. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 255-269, Online, April 2021a. Association for Computational Linguistics. doi: 10.18653/v1/2021.eacl-main.20. URL https://aclanthology.org/2021.eacl-main.20.\n\nIt's not just size that matters: Small language models are also few-shot learners. Timo Schick, Hinrich Sch\u00fctze, 10.18653/v1/2021.naacl-main.185Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnlineAssociation for Computational LinguisticsTimo Schick and Hinrich Sch\u00fctze. It's not just size that matters: Small language models are also few-shot learners. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2339-2352, Online, June 2021b. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main. 185. URL https://aclanthology.org/2021.naacl-main.185.\n\nFew-shot text generation with natural language instructions. Timo Schick, Hinrich Sch\u00fctze, 10.18653/v1/2021.emnlp-main.32Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingOnline and Punta Cana, Dominican RepublicAssociation for Computational LinguisticsTimo Schick and Hinrich Sch\u00fctze. Few-shot text generation with natural language instructions. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Process- ing, pp. 390-402, Online and Punta Cana, Dominican Republic, November 2021c. Associ- ation for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.32. URL https: //aclanthology.org/2021.emnlp-main.32.\n\nEnd-to-end synthetic data generation for domain adaptation of question answering systems. Siamak Shakeri, Cicero Nogueira, Henghui Santos, Patrick Zhu, Feng Ng, Zhiguo Nan, Ramesh Wang, Bing Nallapati, Xiang, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational LinguisticsSiamak Shakeri, Cicero Nogueira dos Santos, Henghui Zhu, Patrick Ng, Feng Nan, Zhiguo Wang, Ramesh Nallapati, and Bing Xiang. End-to-end synthetic data generation for domain adaptation of question answering systems. In Proceedings of the 2020 Conference on Empirical Methods in Nat- ural Language Processing (EMNLP), pp. 5445-5460. Association for Computational Linguistics, 2020. URL https://aclanthology.org/2020.emnlp-main.439.\n\nBEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models. Nandan Thakur, Nils Reimers, Andreas R\u00fcckl\u00e9, Abhishek Srivastava, Iryna Gurevych, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2021Nandan Thakur, Nils Reimers, Andreas R\u00fcckl\u00e9, Abhishek Srivastava, and Iryna Gurevych. BEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2021. URL https://openreview.net/forum?id=wCu6T5xFjeJ.\n\n. Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze, Alicia Cheng, Taylor Jin, Leslie Bos, Yu Baker, Yaguang Du, Hongrae Li, Lee, Amin Huaixiu Steven Zheng, Marcelo Ghafouri, Yanping Menegali, Maxim Huang, Dmitry Krikun, James Lepikhin, Dehao Qin, Yuanzhong Chen, Zhifeng Xu, Adam Chen, Maarten Roberts, Yanqi Bosma, Chung-Ching Zhou, Igor Chang, Will Krivokon, Marc Rusch, Kathleen S Pickett, Meier-Hellstern, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc LeMeredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben HutchinsonLamda: Language models for dialog applications. CoRR, abs/2201.08239, 2022Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S. Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed H. Chi, and Quoc Le. Lamda: Language models for dialog applications. CoRR, abs/2201.08239, 2022. URL https://arxiv.org/abs/2201.\n\nFEVER: a large-scale dataset for fact extraction and VERification. James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit Mittal, 10.18653/v1/N18-1074Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, LouisianaAssociation for Computational Linguistics1James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-scale dataset for fact extraction and VERification. In Proceedings of the 2018 Confer- ence of the North American Chapter of the Association for Computational Linguistics: Hu- man Language Technologies, Volume 1 (Long Papers), pp. 809-819, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1074. URL https://aclanthology.org/N18-1074.\n\nGPL: Generative pseudo labeling for unsupervised domain adaptation of dense retrieval. Kexin Wang, Nandan Thakur, Nils Reimers, Iryna Gurevych, 10.18653/v1/2022.naacl-main.168Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSeattle, United StatesAssociation for Computational LinguisticsKexin Wang, Nandan Thakur, Nils Reimers, and Iryna Gurevych. GPL: Generative pseudo labeling for unsupervised domain adaptation of dense retrieval. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2345-2360, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.168. URL https://aclanthology.org/ 2022.naacl-main.168.\n\nFinetuned language models are zero-shot learners. Jason Wei, Maarten Paul Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew Mingbo Dai, Quoc V Le, International Conference on Learning Representations. Jason Wei, Maarten Paul Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew Mingbo Dai, and Quoc V. Le. Finetuned language models are zero-shot learners. In International Conference on Learning Representations, 2022a. URL https://openreview. net/forum?id=gEZrGCozdqR.\n\nEmergent abilities of large language models. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, William Fedus, Transactions on Machine Learning Research. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. Emergent abilities of large language models. Trans- actions on Machine Learning Research, 2022b. URL https://openreview.net/forum? id=yzkSU5zdwD.\n\nEfficient inner product approximation in hybrid spaces. Xiang Wu, Ruiqi Guo, David Simcha, Dave Dopson, Sanjiv Kumar, arXivXiang Wu, Ruiqi Guo, David Simcha, Dave Dopson, and Sanjiv Kumar. Efficient inner product ap- proximation in hybrid spaces. arXiv, 2019. URL https://arxiv.org/abs/1903.08690.\n\nEnd-to-end neural adhoc ranking with kernel pooling. Chenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, Russell Power, 10.1145/3077136.3080809Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '17. the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '17New York, NY, USAChenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, and Russell Power. End-to-end neural ad- hoc ranking with kernel pooling. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '17, pp. 55-64, New York, NY, USA, 2017. URL https://doi.org/10.1145/3077136.3080809.\n\nApproximate nearest neighbor negative contrastive learning for dense text retrieval. Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N Bennett, Junaid Ahmed, Arnold Overwijk, International Conference on Learning Representations. Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N. Bennett, Junaid Ahmed, and Arnold Overwijk. Approximate nearest neighbor negative contrastive learning for dense text retrieval. In International Conference on Learning Representations, 2021. URL https: //openreview.net/forum?id=zeFrfgyZln.\n\nHotpotQA: A dataset for diverse, explainable multi-hop question answering. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, Christopher D Manning, 10.18653/v1/D18-1259Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational LinguisticsZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. HotpotQA: A dataset for diverse, explainable multi-hop question answer- ing. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 2369-2380, Brussels, Belgium, October-November 2018. Association for Computational Lin- guistics. doi: 10.18653/v1/D18-1259. URL https://aclanthology.org/D18-1259.\n\nLearning discriminative projections for text similarity measures. Kristina Wen-Tau Yih, John C Toutanova, Christopher Platt, Meek, Proceedings of the Fifteenth Conference on Computational Natural Language Learning. the Fifteenth Conference on Computational Natural Language LearningPortland, Oregon, USAAssociation for Computational LinguisticsWen-tau Yih, Kristina Toutanova, John C. Platt, and Christopher Meek. Learning discriminative pro- jections for text similarity measures. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pp. 247-256, Portland, Oregon, USA, June 2011. Association for Computational Linguistics. URL https://aclanthology.org/W11-0329.\n\nAdversarial retriever-ranker for dense text retrieval. Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng Lv, Nan Duan, Weizhu Chen, International Conference on Learning Representations. Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng Lv, Nan Duan, and Weizhu Chen. Adversarial retriever-ranker for dense text retrieval. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=MR7XubKUFB.\n\nConduct all PROMPTAGATOR++ experiments. Analyzing PROMPTAGATOR generated data. Early distillation experiments. Yi Luan, Yi Luan: Conduct all PROMPTAGATOR++ experiments. Analyzing PROMPTAGATOR generated data. Early distillation experiments.\n\nMain developer for transformer dual encoder and reranking modeling development. Jianmo Ni, PROMPTAGATOR experimentJianmo Ni: Main developer for transformer dual encoder and reranking modeling development. PROMPTAGATOR experiment.\n\nEarly distillation experiments. Reranking modeling development. Jing Lu, Jing Lu: Early distillation experiments. Reranking modeling development.\n\nReranking evaluation code support. Discussion. Anton Bakalov, Anton Bakalov: Reranking evaluation code support. Discussion.\n\nEarly few-shot retrieval idea. Advise research directions. Kelvin Guu, Kelvin Guu: Early few-shot retrieval idea. Advise research directions.\n\nHall: Advise research directions. Mentor researchers. Prompt design and analysis. B Keith, Keith B. Hall: Advise research directions. Mentor researchers. Prompt design and analysis.\n\nMing-Wei Chang, Project initiator. Team organization. Advise research directions. Mentor researchers. Prompt design and analysis. Ming-Wei Chang: Project initiator. Team organization. Advise research directions. Mentor researchers. Prompt design and analysis.\n", "annotations": {"author": "[{\"end\":149,\"start\":59},{\"end\":240,\"start\":150},{\"end\":321,\"start\":241},{\"end\":406,\"start\":322},{\"end\":435,\"start\":407},{\"end\":462,\"start\":436},{\"end\":495,\"start\":463},{\"end\":525,\"start\":496},{\"end\":557,\"start\":526},{\"end\":655,\"start\":558}]", "publisher": null, "author_last_name": "[{\"end\":69,\"start\":66},{\"end\":164,\"start\":160},{\"end\":246,\"start\":244},{\"end\":329,\"start\":325},{\"end\":416,\"start\":414},{\"end\":443,\"start\":441},{\"end\":476,\"start\":469},{\"end\":506,\"start\":503},{\"end\":538,\"start\":534},{\"end\":572,\"start\":567}]", "author_first_name": "[{\"end\":65,\"start\":59},{\"end\":157,\"start\":150},{\"end\":159,\"start\":158},{\"end\":243,\"start\":241},{\"end\":324,\"start\":322},{\"end\":413,\"start\":407},{\"end\":440,\"start\":436},{\"end\":468,\"start\":463},{\"end\":502,\"start\":496},{\"end\":531,\"start\":526},{\"end\":533,\"start\":532},{\"end\":566,\"start\":558}]", "author_affiliation": "[{\"end\":148,\"start\":132},{\"end\":239,\"start\":223},{\"end\":320,\"start\":304},{\"end\":405,\"start\":389},{\"end\":434,\"start\":418},{\"end\":461,\"start\":445},{\"end\":494,\"start\":478},{\"end\":524,\"start\":508},{\"end\":556,\"start\":540},{\"end\":654,\"start\":638}]", "title": "[{\"end\":56,\"start\":1},{\"end\":711,\"start\":656}]", "venue": null, "abstract": "[{\"end\":2318,\"start\":713}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b64\"},\"end\":2551,\"start\":2533},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2574,\"start\":2551},{\"end\":2605,\"start\":2585},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":2950,\"start\":2929},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3112,\"start\":3087},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":3135,\"start\":3112},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3168,\"start\":3147},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":3303,\"start\":3282},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3719,\"start\":3698},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":3751,\"start\":3730},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":4548,\"start\":4529},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":4623,\"start\":4605},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":5186,\"start\":5167},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5519,\"start\":5493},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5553,\"start\":5532},{\"end\":6264,\"start\":6239},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6311,\"start\":6291},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":6470,\"start\":6450},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":6498,\"start\":6475},{\"end\":10218,\"start\":10197},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":10607,\"start\":10584},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10632,\"start\":10612},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":11965,\"start\":11946},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":12935,\"start\":12916},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":16294,\"start\":16273},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":16418,\"start\":16395},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":18489,\"start\":18465},{\"end\":18519,\"start\":18494},{\"end\":21479,\"start\":21458},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":21593,\"start\":21569},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21629,\"start\":21608},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":21915,\"start\":21896},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":22101,\"start\":22083},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":25622,\"start\":25604},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":26045,\"start\":26027},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":26775,\"start\":26755},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":26794,\"start\":26775},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":27039,\"start\":27017},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":27060,\"start\":27039},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":27082,\"start\":27060},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":27380,\"start\":27361},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":27404,\"start\":27380},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":27426,\"start\":27404},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":27444,\"start\":27426},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":27495,\"start\":27475},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":27606,\"start\":27587},{\"end\":27683,\"start\":27662},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":27700,\"start\":27683},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":27902,\"start\":27879},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":28112,\"start\":28090},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":28128,\"start\":28112},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":28360,\"start\":28342},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":28377,\"start\":28360},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":28394,\"start\":28377},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":28416,\"start\":28394},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":28437,\"start\":28416},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":28726,\"start\":28701},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":28744,\"start\":28726},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":28761,\"start\":28744},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":28779,\"start\":28761},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":28798,\"start\":28779},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":28817,\"start\":28798},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":28956,\"start\":28937},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":28980,\"start\":28956},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":29249,\"start\":29229},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":29267,\"start\":29249},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":29464,\"start\":29444},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":29487,\"start\":29464},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":29618,\"start\":29593},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":29620,\"start\":29618},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":29622,\"start\":29620},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":29640,\"start\":29622},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":29662,\"start\":29640},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":29684,\"start\":29662},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":29875,\"start\":29852},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":30173,\"start\":30152},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":30274,\"start\":30250},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":31010,\"start\":30986},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":31034,\"start\":31010},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":31067,\"start\":31046},{\"end\":33000,\"start\":32976}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":37696,\"start\":37490},{\"attributes\":{\"id\":\"fig_1\"},\"end\":38620,\"start\":37697},{\"attributes\":{\"id\":\"fig_2\"},\"end\":39098,\"start\":38621},{\"attributes\":{\"id\":\"fig_3\"},\"end\":39145,\"start\":39099},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40682,\"start\":39146},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41013,\"start\":40683},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41475,\"start\":41014},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":41926,\"start\":41476},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42056,\"start\":41927},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":42558,\"start\":42057},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":42604,\"start\":42559},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":44284,\"start\":42605},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":44645,\"start\":44285}]", "paragraph": "[{\"end\":3385,\"start\":2334},{\"end\":4354,\"start\":3387},{\"end\":4655,\"start\":4356},{\"end\":6101,\"start\":4657},{\"end\":6743,\"start\":6103},{\"end\":7010,\"start\":6745},{\"end\":7292,\"start\":7012},{\"end\":7714,\"start\":7294},{\"end\":7938,\"start\":7742},{\"end\":8153,\"start\":7957},{\"end\":9004,\"start\":8169},{\"end\":9439,\"start\":9006},{\"end\":10219,\"start\":9465},{\"end\":10867,\"start\":10221},{\"end\":11583,\"start\":10869},{\"end\":12018,\"start\":11585},{\"end\":12595,\"start\":12099},{\"end\":12902,\"start\":12597},{\"end\":13601,\"start\":12904},{\"end\":14265,\"start\":13653},{\"end\":14970,\"start\":14267},{\"end\":15294,\"start\":15006},{\"end\":15413,\"start\":15346},{\"end\":15751,\"start\":15415},{\"end\":16950,\"start\":16179},{\"end\":17390,\"start\":16952},{\"end\":18581,\"start\":17427},{\"end\":18809,\"start\":18610},{\"end\":19154,\"start\":18828},{\"end\":19521,\"start\":19156},{\"end\":20117,\"start\":19523},{\"end\":21707,\"start\":20119},{\"end\":22267,\"start\":21724},{\"end\":23034,\"start\":22269},{\"end\":23146,\"start\":23053},{\"end\":23742,\"start\":23148},{\"end\":24288,\"start\":23744},{\"end\":24827,\"start\":24290},{\"end\":25511,\"start\":24829},{\"end\":26170,\"start\":25539},{\"end\":26665,\"start\":26195},{\"end\":26987,\"start\":26682},{\"end\":27963,\"start\":26989},{\"end\":29050,\"start\":27965},{\"end\":29996,\"start\":29052},{\"end\":30721,\"start\":29998},{\"end\":31384,\"start\":30723},{\"end\":31993,\"start\":31415},{\"end\":32816,\"start\":31995},{\"end\":34568,\"start\":32859},{\"end\":35827,\"start\":34626},{\"end\":36514,\"start\":35854},{\"end\":36991,\"start\":36516},{\"end\":37089,\"start\":36993},{\"end\":37489,\"start\":37091}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8168,\"start\":8154},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12098,\"start\":12019},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16178,\"start\":15752}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":13584,\"start\":13577},{\"end\":15433,\"start\":15426},{\"end\":17804,\"start\":17797},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":20922,\"start\":20915},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24893,\"start\":24886},{\"attributes\":{\"ref_id\":\"tab_12\"},\"end\":26648,\"start\":26641},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":33475,\"start\":33468},{\"attributes\":{\"ref_id\":\"tab_12\"},\"end\":33752,\"start\":33745},{\"end\":34545,\"start\":34538},{\"end\":34636,\"start\":34629}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2332,\"start\":2320},{\"attributes\":{\"n\":\"2\"},\"end\":7740,\"start\":7717},{\"attributes\":{\"n\":\"2.1\"},\"end\":7955,\"start\":7941},{\"attributes\":{\"n\":\"2.2\"},\"end\":9463,\"start\":9442},{\"attributes\":{\"n\":\"3.2\"},\"end\":13651,\"start\":13604},{\"attributes\":{\"n\":\"3.3\"},\"end\":15004,\"start\":14973},{\"end\":15318,\"start\":15297},{\"end\":15344,\"start\":15321},{\"attributes\":{\"n\":\"3.4\"},\"end\":17425,\"start\":17393},{\"attributes\":{\"n\":\"3.5\"},\"end\":18594,\"start\":18584},{\"attributes\":{\"n\":\"4\"},\"end\":18608,\"start\":18597},{\"attributes\":{\"n\":\"4.1\"},\"end\":18826,\"start\":18812},{\"attributes\":{\"n\":\"4.2\"},\"end\":21722,\"start\":21710},{\"attributes\":{\"n\":\"4.3\"},\"end\":23051,\"start\":23037},{\"end\":25537,\"start\":25514},{\"attributes\":{\"n\":\"4.4\"},\"end\":26193,\"start\":26173},{\"attributes\":{\"n\":\"5\"},\"end\":26680,\"start\":26668},{\"attributes\":{\"n\":\"6\"},\"end\":31413,\"start\":31387},{\"attributes\":{\"n\":\"7\"},\"end\":32857,\"start\":32819},{\"end\":34592,\"start\":34571},{\"end\":34624,\"start\":34595},{\"end\":35852,\"start\":35830},{\"end\":37501,\"start\":37491},{\"end\":37712,\"start\":37698},{\"end\":38632,\"start\":38622},{\"end\":39110,\"start\":39100},{\"end\":40693,\"start\":40684},{\"end\":41937,\"start\":41928},{\"end\":42065,\"start\":42058},{\"end\":42569,\"start\":42560},{\"end\":44295,\"start\":44286}]", "table": "[{\"end\":40682,\"start\":39228},{\"end\":41926,\"start\":41648},{\"end\":42056,\"start\":42024},{\"end\":42558,\"start\":42234},{\"end\":44284,\"start\":43981},{\"end\":44645,\"start\":44635}]", "figure_caption": "[{\"end\":37696,\"start\":37503},{\"end\":38620,\"start\":37717},{\"end\":39098,\"start\":38634},{\"end\":39145,\"start\":39112},{\"end\":39228,\"start\":39148},{\"end\":41013,\"start\":40695},{\"end\":41475,\"start\":41016},{\"end\":41648,\"start\":41478},{\"end\":42024,\"start\":41939},{\"end\":42234,\"start\":42067},{\"end\":42604,\"start\":42571},{\"end\":43981,\"start\":42607},{\"end\":44635,\"start\":44297}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3673,\"start\":3665},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5353,\"start\":5345},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7536,\"start\":7524},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":11542,\"start\":11534},{\"end\":23192,\"start\":23184},{\"end\":24357,\"start\":24348},{\"end\":26168,\"start\":26159},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":26401,\"start\":26393},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":26464,\"start\":26455},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":26515,\"start\":26507},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":26542,\"start\":26534},{\"end\":34415,\"start\":34407},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":34452,\"start\":34444}]", "bib_author_first_name": "[{\"end\":45634,\"start\":45629},{\"end\":45650,\"start\":45644},{\"end\":45663,\"start\":45658},{\"end\":45677,\"start\":45672},{\"end\":45693,\"start\":45686},{\"end\":46395,\"start\":46391},{\"end\":46411,\"start\":46407},{\"end\":46429,\"start\":46422},{\"end\":46445,\"start\":46438},{\"end\":47246,\"start\":47243},{\"end\":47262,\"start\":47254},{\"end\":47273,\"start\":47269},{\"end\":47288,\"start\":47281},{\"end\":47303,\"start\":47298},{\"end\":47305,\"start\":47304},{\"end\":47322,\"start\":47314},{\"end\":47339,\"start\":47333},{\"end\":47359,\"start\":47353},{\"end\":47373,\"start\":47367},{\"end\":47388,\"start\":47382},{\"end\":47405,\"start\":47397},{\"end\":47420,\"start\":47415},{\"end\":47443,\"start\":47435},{\"end\":47456,\"start\":47453},{\"end\":47472,\"start\":47467},{\"end\":47486,\"start\":47480},{\"end\":47501,\"start\":47495},{\"end\":47518,\"start\":47511},{\"end\":47530,\"start\":47523},{\"end\":47544,\"start\":47539},{\"end\":47556,\"start\":47552},{\"end\":47567,\"start\":47563},{\"end\":47583,\"start\":47576},{\"end\":48713,\"start\":48704},{\"end\":48726,\"start\":48721},{\"end\":48728,\"start\":48727},{\"end\":48740,\"start\":48733},{\"end\":48754,\"start\":48748},{\"end\":48767,\"start\":48761},{\"end\":49174,\"start\":49169},{\"end\":49187,\"start\":49181},{\"end\":49204,\"start\":49198},{\"end\":49217,\"start\":49211},{\"end\":49232,\"start\":49225},{\"end\":49244,\"start\":49240},{\"end\":49264,\"start\":49258},{\"end\":49278,\"start\":49273},{\"end\":49293,\"start\":49286},{\"end\":49646,\"start\":49640},{\"end\":49659,\"start\":49652},{\"end\":49672,\"start\":49667},{\"end\":49688,\"start\":49681},{\"end\":50381,\"start\":50376},{\"end\":50398,\"start\":50390},{\"end\":50412,\"start\":50406},{\"end\":50426,\"start\":50418},{\"end\":51339,\"start\":51331},{\"end\":51354,\"start\":51348},{\"end\":51373,\"start\":51365},{\"end\":51394,\"start\":51386},{\"end\":51689,\"start\":51685},{\"end\":51700,\"start\":51695},{\"end\":52447,\"start\":52443},{\"end\":52458,\"start\":52453},{\"end\":53208,\"start\":53204},{\"end\":53220,\"start\":53214},{\"end\":53231,\"start\":53226},{\"end\":54105,\"start\":54099},{\"end\":54115,\"start\":54111},{\"end\":54128,\"start\":54123},{\"end\":55020,\"start\":55014},{\"end\":55040,\"start\":55030},{\"end\":55061,\"start\":55049},{\"end\":55318,\"start\":55311},{\"end\":55330,\"start\":55324},{\"end\":55343,\"start\":55336},{\"end\":55349,\"start\":55348},{\"end\":55355,\"start\":55350},{\"end\":55967,\"start\":55960},{\"end\":55981,\"start\":55976},{\"end\":55999,\"start\":55992},{\"end\":56016,\"start\":56007},{\"end\":56029,\"start\":56024},{\"end\":56034,\"start\":56030},{\"end\":56055,\"start\":56046},{\"end\":56068,\"start\":56063},{\"end\":56869,\"start\":56860},{\"end\":56888,\"start\":56882},{\"end\":56907,\"start\":56900},{\"end\":56922,\"start\":56918},{\"end\":56937,\"start\":56932},{\"end\":57263,\"start\":57260},{\"end\":57275,\"start\":57269},{\"end\":57288,\"start\":57283},{\"end\":57306,\"start\":57300},{\"end\":58019,\"start\":58012},{\"end\":58037,\"start\":58029},{\"end\":58050,\"start\":58045},{\"end\":58070,\"start\":58061},{\"end\":58084,\"start\":58079},{\"end\":58103,\"start\":58097},{\"end\":58119,\"start\":58112},{\"end\":58524,\"start\":58517},{\"end\":58541,\"start\":58534},{\"end\":58554,\"start\":58549},{\"end\":58568,\"start\":58563},{\"end\":58584,\"start\":58579},{\"end\":58598,\"start\":58594},{\"end\":58611,\"start\":58607},{\"end\":58630,\"start\":58624},{\"end\":58648,\"start\":58639},{\"end\":58664,\"start\":58657},{\"end\":58984,\"start\":58980},{\"end\":59002,\"start\":58994},{\"end\":59015,\"start\":59010},{\"end\":59376,\"start\":59368},{\"end\":59394,\"start\":59388},{\"end\":59406,\"start\":59401},{\"end\":59419,\"start\":59412},{\"end\":59433,\"start\":59427},{\"end\":59444,\"start\":59438},{\"end\":59458,\"start\":59453},{\"end\":59472,\"start\":59465},{\"end\":60261,\"start\":60257},{\"end\":60276,\"start\":60271},{\"end\":61245,\"start\":61242},{\"end\":61269,\"start\":61259},{\"end\":61286,\"start\":61280},{\"end\":61304,\"start\":61297},{\"end\":61319,\"start\":61314},{\"end\":61333,\"start\":61328},{\"end\":61351,\"start\":61343},{\"end\":61366,\"start\":61361},{\"end\":61384,\"start\":61379},{\"end\":61399,\"start\":61393},{\"end\":61413,\"start\":61405},{\"end\":61430,\"start\":61425},{\"end\":61445,\"start\":61438},{\"end\":61462,\"start\":61454},{\"end\":61476,\"start\":61470},{\"end\":61478,\"start\":61477},{\"end\":61489,\"start\":61484},{\"end\":61505,\"start\":61501},{\"end\":61514,\"start\":61510},{\"end\":62187,\"start\":62181},{\"end\":62201,\"start\":62193},{\"end\":62217,\"start\":62209},{\"end\":62915,\"start\":62908},{\"end\":62930,\"start\":62923},{\"end\":62942,\"start\":62935},{\"end\":62956,\"start\":62948},{\"end\":62976,\"start\":62968},{\"end\":62996,\"start\":62986},{\"end\":63011,\"start\":63005},{\"end\":63032,\"start\":63023},{\"end\":63593,\"start\":63583},{\"end\":63616,\"start\":63611},{\"end\":64344,\"start\":64338},{\"end\":64353,\"start\":64352},{\"end\":64355,\"start\":64354},{\"end\":64363,\"start\":64358},{\"end\":64379,\"start\":64375},{\"end\":64394,\"start\":64389},{\"end\":64410,\"start\":64404},{\"end\":64427,\"start\":64418},{\"end\":65118,\"start\":65114},{\"end\":65130,\"start\":65123},{\"end\":65151,\"start\":65149},{\"end\":65162,\"start\":65156},{\"end\":65173,\"start\":65167},{\"end\":65973,\"start\":65971},{\"end\":65985,\"start\":65980},{\"end\":66006,\"start\":65998},{\"end\":66025,\"start\":66018},{\"end\":66512,\"start\":66510},{\"end\":66521,\"start\":66517},{\"end\":66538,\"start\":66532},{\"end\":66550,\"start\":66545},{\"end\":66561,\"start\":66557},{\"end\":67388,\"start\":67382},{\"end\":67404,\"start\":67395},{\"end\":67421,\"start\":67416},{\"end\":67436,\"start\":67431},{\"end\":67448,\"start\":67444},{\"end\":67465,\"start\":67460},{\"end\":67484,\"start\":67475},{\"end\":67956,\"start\":67952},{\"end\":67973,\"start\":67967},{\"end\":67985,\"start\":67982},{\"end\":68637,\"start\":68631},{\"end\":68654,\"start\":68651},{\"end\":68663,\"start\":68659},{\"end\":68674,\"start\":68670},{\"end\":68689,\"start\":68684},{\"end\":68697,\"start\":68690},{\"end\":68708,\"start\":68703},{\"end\":68723,\"start\":68717},{\"end\":68737,\"start\":68730},{\"end\":68739,\"start\":68738},{\"end\":68751,\"start\":68747},{\"end\":68756,\"start\":68752},{\"end\":68767,\"start\":68762},{\"end\":68785,\"start\":68777},{\"end\":68802,\"start\":68796},{\"end\":68815,\"start\":68810},{\"end\":68827,\"start\":68823},{\"end\":68836,\"start\":68828},{\"end\":68851,\"start\":68845},{\"end\":68868,\"start\":68860},{\"end\":68883,\"start\":68878},{\"end\":68885,\"start\":68884},{\"end\":69706,\"start\":69703},{\"end\":69718,\"start\":69715},{\"end\":69733,\"start\":69730},{\"end\":69748,\"start\":69740},{\"end\":69761,\"start\":69754},{\"end\":69776,\"start\":69770},{\"end\":69789,\"start\":69787},{\"end\":70106,\"start\":70100},{\"end\":70115,\"start\":70111},{\"end\":70124,\"start\":70120},{\"end\":70135,\"start\":70129},{\"end\":70148,\"start\":70141},{\"end\":70158,\"start\":70149},{\"end\":70169,\"start\":70167},{\"end\":70181,\"start\":70174},{\"end\":70183,\"start\":70182},{\"end\":70192,\"start\":70190},{\"end\":70204,\"start\":70199},{\"end\":70206,\"start\":70205},{\"end\":70221,\"start\":70213},{\"end\":70235,\"start\":70229},{\"end\":70532,\"start\":70525},{\"end\":70552,\"start\":70543},{\"end\":70784,\"start\":70777},{\"end\":70802,\"start\":70795},{\"end\":70815,\"start\":70810},{\"end\":70830,\"start\":70825},{\"end\":71589,\"start\":71583},{\"end\":71602,\"start\":71596},{\"end\":71619,\"start\":71613},{\"end\":71634,\"start\":71627},{\"end\":71650,\"start\":71642},{\"end\":71672,\"start\":71662},{\"end\":71686,\"start\":71681},{\"end\":71702,\"start\":71693},{\"end\":71716,\"start\":71711},{\"end\":71727,\"start\":71722},{\"end\":71741,\"start\":71735},{\"end\":72529,\"start\":72524},{\"end\":72541,\"start\":72539},{\"end\":72554,\"start\":72548},{\"end\":72569,\"start\":72561},{\"end\":72583,\"start\":72575},{\"end\":72595,\"start\":72588},{\"end\":72609,\"start\":72602},{\"end\":72621,\"start\":72616},{\"end\":73192,\"start\":73186},{\"end\":73203,\"start\":73197},{\"end\":73214,\"start\":73210},{\"end\":73223,\"start\":73220},{\"end\":73236,\"start\":73229},{\"end\":73247,\"start\":73242},{\"end\":73251,\"start\":73248},{\"end\":73265,\"start\":73258},{\"end\":73275,\"start\":73272},{\"end\":73287,\"start\":73280},{\"end\":74163,\"start\":74158},{\"end\":74176,\"start\":74172},{\"end\":74178,\"start\":74177},{\"end\":74192,\"start\":74188},{\"end\":74211,\"start\":74202},{\"end\":74223,\"start\":74217},{\"end\":74239,\"start\":74232},{\"end\":74253,\"start\":74248},{\"end\":74261,\"start\":74260},{\"end\":74271,\"start\":74266},{\"end\":74273,\"start\":74272},{\"end\":74681,\"start\":74680},{\"end\":74695,\"start\":74691},{\"end\":74709,\"start\":74703},{\"end\":74717,\"start\":74710},{\"end\":74741,\"start\":74736},{\"end\":74754,\"start\":74749},{\"end\":74756,\"start\":74755},{\"end\":74779,\"start\":74770},{\"end\":74791,\"start\":74784},{\"end\":74803,\"start\":74797},{\"end\":75203,\"start\":75196},{\"end\":75217,\"start\":75209},{\"end\":75228,\"start\":75222},{\"end\":75237,\"start\":75233},{\"end\":75248,\"start\":75243},{\"end\":75252,\"start\":75249},{\"end\":75267,\"start\":75259},{\"end\":75276,\"start\":75273},{\"end\":75288,\"start\":75281},{\"end\":75302,\"start\":75295},{\"end\":76016,\"start\":76009},{\"end\":76028,\"start\":76022},{\"end\":76037,\"start\":76033},{\"end\":76048,\"start\":76043},{\"end\":76052,\"start\":76049},{\"end\":76067,\"start\":76059},{\"end\":76076,\"start\":76073},{\"end\":76088,\"start\":76081},{\"end\":76102,\"start\":76095},{\"end\":76930,\"start\":76923},{\"end\":76942,\"start\":76936},{\"end\":76951,\"start\":76947},{\"end\":76962,\"start\":76957},{\"end\":76966,\"start\":76963},{\"end\":76978,\"start\":76973},{\"end\":76989,\"start\":76983},{\"end\":76999,\"start\":76996},{\"end\":77011,\"start\":77004},{\"end\":77025,\"start\":77018},{\"end\":77331,\"start\":77327},{\"end\":77360,\"start\":77355},{\"end\":77376,\"start\":77372},{\"end\":77394,\"start\":77387},{\"end\":77412,\"start\":77405},{\"end\":77428,\"start\":77421},{\"end\":77799,\"start\":77791},{\"end\":77818,\"start\":77814},{\"end\":77832,\"start\":77826},{\"end\":77845,\"start\":77840},{\"end\":77865,\"start\":77858},{\"end\":77877,\"start\":77871},{\"end\":77890,\"start\":77886},{\"end\":78215,\"start\":78209},{\"end\":78228,\"start\":78222},{\"end\":78242,\"start\":78237},{\"end\":78252,\"start\":78251},{\"end\":78269,\"start\":78262},{\"end\":78280,\"start\":78276},{\"end\":78298,\"start\":78291},{\"end\":78315,\"start\":78309},{\"end\":78330,\"start\":78325},{\"end\":78333,\"start\":78331},{\"end\":78348,\"start\":78344},{\"end\":78741,\"start\":78735},{\"end\":78757,\"start\":78753},{\"end\":78770,\"start\":78767},{\"end\":78795,\"start\":78784},{\"end\":78808,\"start\":78803},{\"end\":79579,\"start\":79575},{\"end\":79595,\"start\":79588},{\"end\":80401,\"start\":80397},{\"end\":80417,\"start\":80410},{\"end\":81272,\"start\":81268},{\"end\":81288,\"start\":81281},{\"end\":82057,\"start\":82051},{\"end\":82073,\"start\":82067},{\"end\":82091,\"start\":82084},{\"end\":82107,\"start\":82100},{\"end\":82117,\"start\":82113},{\"end\":82128,\"start\":82122},{\"end\":82140,\"start\":82134},{\"end\":82151,\"start\":82147},{\"end\":82914,\"start\":82908},{\"end\":82927,\"start\":82923},{\"end\":82944,\"start\":82937},{\"end\":82961,\"start\":82953},{\"end\":82979,\"start\":82974},{\"end\":83438,\"start\":83433},{\"end\":83456,\"start\":83450},{\"end\":83459,\"start\":83457},{\"end\":83474,\"start\":83469},{\"end\":83485,\"start\":83481},{\"end\":83501,\"start\":83495},{\"end\":83532,\"start\":83526},{\"end\":83546,\"start\":83540},{\"end\":83558,\"start\":83552},{\"end\":83566,\"start\":83564},{\"end\":83581,\"start\":83574},{\"end\":83593,\"start\":83586},{\"end\":83607,\"start\":83603},{\"end\":83637,\"start\":83630},{\"end\":83655,\"start\":83648},{\"end\":83671,\"start\":83666},{\"end\":83685,\"start\":83679},{\"end\":83699,\"start\":83694},{\"end\":83715,\"start\":83710},{\"end\":83730,\"start\":83721},{\"end\":83744,\"start\":83737},{\"end\":83753,\"start\":83749},{\"end\":83767,\"start\":83760},{\"end\":83782,\"start\":83777},{\"end\":83801,\"start\":83790},{\"end\":83812,\"start\":83808},{\"end\":83824,\"start\":83820},{\"end\":83839,\"start\":83835},{\"end\":83855,\"start\":83847},{\"end\":83857,\"start\":83856},{\"end\":85430,\"start\":85425},{\"end\":85446,\"start\":85439},{\"end\":85464,\"start\":85456},{\"end\":85490,\"start\":85485},{\"end\":86424,\"start\":86419},{\"end\":86437,\"start\":86431},{\"end\":86450,\"start\":86446},{\"end\":86465,\"start\":86460},{\"end\":87374,\"start\":87369},{\"end\":87387,\"start\":87380},{\"end\":87392,\"start\":87388},{\"end\":87407,\"start\":87400},{\"end\":87420,\"start\":87414},{\"end\":87431,\"start\":87426},{\"end\":87435,\"start\":87432},{\"end\":87445,\"start\":87440},{\"end\":87457,\"start\":87454},{\"end\":87468,\"start\":87462},{\"end\":87475,\"start\":87469},{\"end\":87485,\"start\":87481},{\"end\":87487,\"start\":87486},{\"end\":87889,\"start\":87884},{\"end\":87897,\"start\":87895},{\"end\":87908,\"start\":87903},{\"end\":87925,\"start\":87920},{\"end\":87940,\"start\":87934},{\"end\":87956,\"start\":87947},{\"end\":87971,\"start\":87967},{\"end\":87989,\"start\":87982},{\"end\":88002,\"start\":87997},{\"end\":88015,\"start\":88009},{\"end\":88027,\"start\":88025},{\"end\":88029,\"start\":88028},{\"end\":88044,\"start\":88035},{\"end\":88061,\"start\":88056},{\"end\":88076,\"start\":88071},{\"end\":88088,\"start\":88084},{\"end\":88102,\"start\":88095},{\"end\":88592,\"start\":88587},{\"end\":88602,\"start\":88597},{\"end\":88613,\"start\":88608},{\"end\":88626,\"start\":88622},{\"end\":88641,\"start\":88635},{\"end\":88890,\"start\":88883},{\"end\":88904,\"start\":88898},{\"end\":88915,\"start\":88910},{\"end\":88931,\"start\":88924},{\"end\":88944,\"start\":88937},{\"end\":89648,\"start\":89645},{\"end\":89663,\"start\":89656},{\"end\":89673,\"start\":89671},{\"end\":89687,\"start\":89678},{\"end\":89700,\"start\":89694},{\"end\":89710,\"start\":89706},{\"end\":89712,\"start\":89711},{\"end\":89728,\"start\":89722},{\"end\":89742,\"start\":89736},{\"end\":90199,\"start\":90193},{\"end\":90210,\"start\":90206},{\"end\":90223,\"start\":90215},{\"end\":90237,\"start\":90231},{\"end\":90253,\"start\":90246},{\"end\":90267,\"start\":90261},{\"end\":90294,\"start\":90283},{\"end\":90296,\"start\":90295},{\"end\":91072,\"start\":91064},{\"end\":91090,\"start\":91086},{\"end\":91092,\"start\":91091},{\"end\":91115,\"start\":91104},{\"end\":91756,\"start\":91752},{\"end\":91769,\"start\":91764},{\"end\":91782,\"start\":91776},{\"end\":91798,\"start\":91789},{\"end\":91806,\"start\":91803},{\"end\":91819,\"start\":91813},{\"end\":92238,\"start\":92236},{\"end\":92452,\"start\":92446},{\"end\":92665,\"start\":92661},{\"end\":92796,\"start\":92791},{\"end\":92934,\"start\":92928},{\"end\":93095,\"start\":93094},{\"end\":93203,\"start\":93195}]", "bib_author_last_name": "[{\"end\":45642,\"start\":45635},{\"end\":45656,\"start\":45651},{\"end\":45670,\"start\":45664},{\"end\":45684,\"start\":45678},{\"end\":45701,\"start\":45694},{\"end\":46405,\"start\":46396},{\"end\":46420,\"start\":46412},{\"end\":46436,\"start\":46430},{\"end\":46454,\"start\":46446},{\"end\":47252,\"start\":47247},{\"end\":47267,\"start\":47263},{\"end\":47279,\"start\":47274},{\"end\":47296,\"start\":47289},{\"end\":47312,\"start\":47306},{\"end\":47331,\"start\":47323},{\"end\":47351,\"start\":47340},{\"end\":47365,\"start\":47360},{\"end\":47380,\"start\":47374},{\"end\":47395,\"start\":47389},{\"end\":47413,\"start\":47406},{\"end\":47433,\"start\":47421},{\"end\":47451,\"start\":47444},{\"end\":47465,\"start\":47457},{\"end\":47478,\"start\":47473},{\"end\":47493,\"start\":47487},{\"end\":47509,\"start\":47502},{\"end\":47521,\"start\":47519},{\"end\":47537,\"start\":47531},{\"end\":47550,\"start\":47545},{\"end\":47561,\"start\":47557},{\"end\":47574,\"start\":47568},{\"end\":47590,\"start\":47584},{\"end\":48719,\"start\":48714},{\"end\":48731,\"start\":48729},{\"end\":48746,\"start\":48741},{\"end\":48759,\"start\":48755},{\"end\":48773,\"start\":48768},{\"end\":49179,\"start\":49175},{\"end\":49196,\"start\":49188},{\"end\":49209,\"start\":49205},{\"end\":49223,\"start\":49218},{\"end\":49238,\"start\":49233},{\"end\":49256,\"start\":49245},{\"end\":49271,\"start\":49265},{\"end\":49284,\"start\":49279},{\"end\":49297,\"start\":49294},{\"end\":49650,\"start\":49647},{\"end\":49665,\"start\":49660},{\"end\":49679,\"start\":49673},{\"end\":49692,\"start\":49689},{\"end\":50388,\"start\":50382},{\"end\":50404,\"start\":50399},{\"end\":50416,\"start\":50413},{\"end\":50436,\"start\":50427},{\"end\":51346,\"start\":51340},{\"end\":51363,\"start\":51355},{\"end\":51384,\"start\":51374},{\"end\":51404,\"start\":51395},{\"end\":51693,\"start\":51690},{\"end\":51707,\"start\":51701},{\"end\":52451,\"start\":52448},{\"end\":52465,\"start\":52459},{\"end\":53212,\"start\":53209},{\"end\":53224,\"start\":53221},{\"end\":53238,\"start\":53232},{\"end\":54109,\"start\":54106},{\"end\":54121,\"start\":54116},{\"end\":54133,\"start\":54129},{\"end\":55028,\"start\":55021},{\"end\":55047,\"start\":55041},{\"end\":55067,\"start\":55062},{\"end\":55322,\"start\":55319},{\"end\":55334,\"start\":55331},{\"end\":55346,\"start\":55344},{\"end\":55361,\"start\":55356},{\"end\":55974,\"start\":55968},{\"end\":55990,\"start\":55982},{\"end\":56005,\"start\":56000},{\"end\":56022,\"start\":56017},{\"end\":56044,\"start\":56035},{\"end\":56061,\"start\":56056},{\"end\":56075,\"start\":56069},{\"end\":56880,\"start\":56870},{\"end\":56898,\"start\":56889},{\"end\":56916,\"start\":56908},{\"end\":56930,\"start\":56923},{\"end\":56945,\"start\":56938},{\"end\":57267,\"start\":57264},{\"end\":57281,\"start\":57276},{\"end\":57298,\"start\":57289},{\"end\":57314,\"start\":57307},{\"end\":58027,\"start\":58020},{\"end\":58043,\"start\":58038},{\"end\":58059,\"start\":58051},{\"end\":58077,\"start\":58071},{\"end\":58095,\"start\":58085},{\"end\":58110,\"start\":58104},{\"end\":58125,\"start\":58120},{\"end\":58532,\"start\":58525},{\"end\":58547,\"start\":58542},{\"end\":58561,\"start\":58555},{\"end\":58577,\"start\":58569},{\"end\":58592,\"start\":58585},{\"end\":58605,\"start\":58599},{\"end\":58622,\"start\":58612},{\"end\":58637,\"start\":58631},{\"end\":58655,\"start\":58649},{\"end\":58670,\"start\":58665},{\"end\":58992,\"start\":58985},{\"end\":59008,\"start\":59003},{\"end\":59021,\"start\":59016},{\"end\":59386,\"start\":59377},{\"end\":59399,\"start\":59395},{\"end\":59410,\"start\":59407},{\"end\":59425,\"start\":59420},{\"end\":59436,\"start\":59434},{\"end\":59451,\"start\":59445},{\"end\":59463,\"start\":59459},{\"end\":59476,\"start\":59473},{\"end\":60269,\"start\":60262},{\"end\":60284,\"start\":60277},{\"end\":60293,\"start\":60286},{\"end\":61257,\"start\":61246},{\"end\":61278,\"start\":61270},{\"end\":61295,\"start\":61287},{\"end\":61312,\"start\":61305},{\"end\":61326,\"start\":61320},{\"end\":61341,\"start\":61334},{\"end\":61359,\"start\":61352},{\"end\":61377,\"start\":61367},{\"end\":61391,\"start\":61385},{\"end\":61403,\"start\":61400},{\"end\":61423,\"start\":61414},{\"end\":61436,\"start\":61431},{\"end\":61452,\"start\":61446},{\"end\":61468,\"start\":61463},{\"end\":61482,\"start\":61479},{\"end\":61499,\"start\":61490},{\"end\":61508,\"start\":61506},{\"end\":61521,\"start\":61515},{\"end\":62191,\"start\":62188},{\"end\":62207,\"start\":62202},{\"end\":62227,\"start\":62218},{\"end\":62921,\"start\":62916},{\"end\":62933,\"start\":62931},{\"end\":62946,\"start\":62943},{\"end\":62966,\"start\":62957},{\"end\":62984,\"start\":62977},{\"end\":63003,\"start\":62997},{\"end\":63021,\"start\":63012},{\"end\":63039,\"start\":63033},{\"end\":63609,\"start\":63594},{\"end\":63621,\"start\":63617},{\"end\":63626,\"start\":63623},{\"end\":64350,\"start\":64345},{\"end\":64373,\"start\":64364},{\"end\":64387,\"start\":64380},{\"end\":64402,\"start\":64395},{\"end\":64416,\"start\":64411},{\"end\":64434,\"start\":64428},{\"end\":65121,\"start\":65119},{\"end\":65147,\"start\":65131},{\"end\":65154,\"start\":65152},{\"end\":65165,\"start\":65163},{\"end\":65178,\"start\":65174},{\"end\":65978,\"start\":65974},{\"end\":65996,\"start\":65986},{\"end\":66016,\"start\":66007},{\"end\":66033,\"start\":66026},{\"end\":66515,\"start\":66513},{\"end\":66530,\"start\":66522},{\"end\":66543,\"start\":66539},{\"end\":66555,\"start\":66551},{\"end\":66570,\"start\":66562},{\"end\":67393,\"start\":67389},{\"end\":67414,\"start\":67405},{\"end\":67429,\"start\":67422},{\"end\":67442,\"start\":67437},{\"end\":67458,\"start\":67449},{\"end\":67473,\"start\":67466},{\"end\":67492,\"start\":67485},{\"end\":67965,\"start\":67957},{\"end\":67980,\"start\":67974},{\"end\":68001,\"start\":67986},{\"end\":68649,\"start\":68638},{\"end\":68657,\"start\":68655},{\"end\":68668,\"start\":68664},{\"end\":68682,\"start\":68675},{\"end\":68701,\"start\":68698},{\"end\":68715,\"start\":68709},{\"end\":68728,\"start\":68724},{\"end\":68745,\"start\":68740},{\"end\":68760,\"start\":68757},{\"end\":68775,\"start\":68768},{\"end\":68794,\"start\":68786},{\"end\":68808,\"start\":68803},{\"end\":68821,\"start\":68816},{\"end\":68843,\"start\":68837},{\"end\":68858,\"start\":68852},{\"end\":68876,\"start\":68869},{\"end\":68893,\"start\":68886},{\"end\":69713,\"start\":69707},{\"end\":69728,\"start\":69719},{\"end\":69738,\"start\":69734},{\"end\":69752,\"start\":69749},{\"end\":69768,\"start\":69762},{\"end\":69785,\"start\":69777},{\"end\":69794,\"start\":69790},{\"end\":70109,\"start\":70107},{\"end\":70118,\"start\":70116},{\"end\":70127,\"start\":70125},{\"end\":70139,\"start\":70136},{\"end\":70165,\"start\":70159},{\"end\":70172,\"start\":70170},{\"end\":70188,\"start\":70184},{\"end\":70197,\"start\":70193},{\"end\":70211,\"start\":70207},{\"end\":70227,\"start\":70222},{\"end\":70240,\"start\":70236},{\"end\":70541,\"start\":70533},{\"end\":70556,\"start\":70553},{\"end\":70793,\"start\":70785},{\"end\":70808,\"start\":70803},{\"end\":70823,\"start\":70816},{\"end\":70834,\"start\":70831},{\"end\":71594,\"start\":71590},{\"end\":71611,\"start\":71603},{\"end\":71625,\"start\":71620},{\"end\":71640,\"start\":71635},{\"end\":71660,\"start\":71651},{\"end\":71679,\"start\":71673},{\"end\":71691,\"start\":71687},{\"end\":71709,\"start\":71703},{\"end\":71720,\"start\":71717},{\"end\":71733,\"start\":71728},{\"end\":71748,\"start\":71742},{\"end\":72537,\"start\":72530},{\"end\":72546,\"start\":72542},{\"end\":72559,\"start\":72555},{\"end\":72573,\"start\":72570},{\"end\":72586,\"start\":72584},{\"end\":72600,\"start\":72596},{\"end\":72614,\"start\":72610},{\"end\":72626,\"start\":72622},{\"end\":73195,\"start\":73193},{\"end\":73208,\"start\":73204},{\"end\":73218,\"start\":73215},{\"end\":73227,\"start\":73224},{\"end\":73240,\"start\":73237},{\"end\":73256,\"start\":73252},{\"end\":73270,\"start\":73266},{\"end\":73278,\"start\":73276},{\"end\":73292,\"start\":73288},{\"end\":74170,\"start\":74164},{\"end\":74186,\"start\":74179},{\"end\":74200,\"start\":74193},{\"end\":74215,\"start\":74212},{\"end\":74230,\"start\":74224},{\"end\":74246,\"start\":74240},{\"end\":74258,\"start\":74254},{\"end\":74264,\"start\":74262},{\"end\":74277,\"start\":74274},{\"end\":74689,\"start\":74682},{\"end\":74701,\"start\":74696},{\"end\":74734,\"start\":74718},{\"end\":74747,\"start\":74742},{\"end\":74768,\"start\":74757},{\"end\":74782,\"start\":74780},{\"end\":74795,\"start\":74792},{\"end\":74808,\"start\":74804},{\"end\":74815,\"start\":74810},{\"end\":75207,\"start\":75204},{\"end\":75220,\"start\":75218},{\"end\":75231,\"start\":75229},{\"end\":75241,\"start\":75238},{\"end\":75257,\"start\":75253},{\"end\":75271,\"start\":75268},{\"end\":75279,\"start\":75277},{\"end\":75293,\"start\":75289},{\"end\":75306,\"start\":75303},{\"end\":76020,\"start\":76017},{\"end\":76031,\"start\":76029},{\"end\":76041,\"start\":76038},{\"end\":76057,\"start\":76053},{\"end\":76071,\"start\":76068},{\"end\":76079,\"start\":76077},{\"end\":76093,\"start\":76089},{\"end\":76106,\"start\":76103},{\"end\":76934,\"start\":76931},{\"end\":76945,\"start\":76943},{\"end\":76955,\"start\":76952},{\"end\":76971,\"start\":76967},{\"end\":76981,\"start\":76979},{\"end\":76994,\"start\":76990},{\"end\":77002,\"start\":77000},{\"end\":77016,\"start\":77012},{\"end\":77029,\"start\":77026},{\"end\":77353,\"start\":77332},{\"end\":77370,\"start\":77361},{\"end\":77385,\"start\":77377},{\"end\":77403,\"start\":77395},{\"end\":77419,\"start\":77413},{\"end\":77435,\"start\":77429},{\"end\":77445,\"start\":77437},{\"end\":77812,\"start\":77800},{\"end\":77824,\"start\":77819},{\"end\":77838,\"start\":77833},{\"end\":77856,\"start\":77846},{\"end\":77869,\"start\":77866},{\"end\":77884,\"start\":77878},{\"end\":77902,\"start\":77891},{\"end\":78220,\"start\":78216},{\"end\":78235,\"start\":78229},{\"end\":78249,\"start\":78243},{\"end\":78260,\"start\":78253},{\"end\":78274,\"start\":78270},{\"end\":78289,\"start\":78281},{\"end\":78307,\"start\":78299},{\"end\":78323,\"start\":78316},{\"end\":78342,\"start\":78334},{\"end\":78353,\"start\":78349},{\"end\":78359,\"start\":78355},{\"end\":78751,\"start\":78742},{\"end\":78765,\"start\":78758},{\"end\":78782,\"start\":78771},{\"end\":78801,\"start\":78796},{\"end\":78816,\"start\":78809},{\"end\":79586,\"start\":79580},{\"end\":79603,\"start\":79596},{\"end\":80408,\"start\":80402},{\"end\":80425,\"start\":80418},{\"end\":81279,\"start\":81273},{\"end\":81296,\"start\":81289},{\"end\":82065,\"start\":82058},{\"end\":82082,\"start\":82074},{\"end\":82098,\"start\":82092},{\"end\":82111,\"start\":82108},{\"end\":82120,\"start\":82118},{\"end\":82132,\"start\":82129},{\"end\":82145,\"start\":82141},{\"end\":82161,\"start\":82152},{\"end\":82168,\"start\":82163},{\"end\":82921,\"start\":82915},{\"end\":82935,\"start\":82928},{\"end\":82951,\"start\":82945},{\"end\":82972,\"start\":82962},{\"end\":82988,\"start\":82980},{\"end\":83448,\"start\":83439},{\"end\":83467,\"start\":83460},{\"end\":83479,\"start\":83475},{\"end\":83493,\"start\":83486},{\"end\":83514,\"start\":83502},{\"end\":83524,\"start\":83516},{\"end\":83538,\"start\":83533},{\"end\":83550,\"start\":83547},{\"end\":83562,\"start\":83559},{\"end\":83572,\"start\":83567},{\"end\":83584,\"start\":83582},{\"end\":83596,\"start\":83594},{\"end\":83601,\"start\":83598},{\"end\":83628,\"start\":83608},{\"end\":83646,\"start\":83638},{\"end\":83664,\"start\":83656},{\"end\":83677,\"start\":83672},{\"end\":83692,\"start\":83686},{\"end\":83708,\"start\":83700},{\"end\":83719,\"start\":83716},{\"end\":83735,\"start\":83731},{\"end\":83747,\"start\":83745},{\"end\":83758,\"start\":83754},{\"end\":83775,\"start\":83768},{\"end\":83788,\"start\":83783},{\"end\":83806,\"start\":83802},{\"end\":83818,\"start\":83813},{\"end\":83833,\"start\":83825},{\"end\":83845,\"start\":83840},{\"end\":83865,\"start\":83858},{\"end\":83882,\"start\":83867},{\"end\":85437,\"start\":85431},{\"end\":85454,\"start\":85447},{\"end\":85483,\"start\":85465},{\"end\":85497,\"start\":85491},{\"end\":86429,\"start\":86425},{\"end\":86444,\"start\":86438},{\"end\":86458,\"start\":86451},{\"end\":86474,\"start\":86466},{\"end\":87378,\"start\":87375},{\"end\":87398,\"start\":87393},{\"end\":87412,\"start\":87408},{\"end\":87424,\"start\":87421},{\"end\":87438,\"start\":87436},{\"end\":87452,\"start\":87446},{\"end\":87460,\"start\":87458},{\"end\":87479,\"start\":87476},{\"end\":87490,\"start\":87488},{\"end\":87893,\"start\":87890},{\"end\":87901,\"start\":87898},{\"end\":87918,\"start\":87909},{\"end\":87932,\"start\":87926},{\"end\":87945,\"start\":87941},{\"end\":87965,\"start\":87957},{\"end\":87980,\"start\":87972},{\"end\":87995,\"start\":87990},{\"end\":88007,\"start\":88003},{\"end\":88023,\"start\":88016},{\"end\":88033,\"start\":88030},{\"end\":88054,\"start\":88045},{\"end\":88069,\"start\":88062},{\"end\":88082,\"start\":88077},{\"end\":88093,\"start\":88089},{\"end\":88108,\"start\":88103},{\"end\":88595,\"start\":88593},{\"end\":88606,\"start\":88603},{\"end\":88620,\"start\":88614},{\"end\":88633,\"start\":88627},{\"end\":88647,\"start\":88642},{\"end\":88896,\"start\":88891},{\"end\":88908,\"start\":88905},{\"end\":88922,\"start\":88916},{\"end\":88935,\"start\":88932},{\"end\":88950,\"start\":88945},{\"end\":89654,\"start\":89649},{\"end\":89669,\"start\":89664},{\"end\":89676,\"start\":89674},{\"end\":89692,\"start\":89688},{\"end\":89704,\"start\":89701},{\"end\":89720,\"start\":89713},{\"end\":89734,\"start\":89729},{\"end\":89751,\"start\":89743},{\"end\":90204,\"start\":90200},{\"end\":90213,\"start\":90211},{\"end\":90229,\"start\":90224},{\"end\":90244,\"start\":90238},{\"end\":90259,\"start\":90254},{\"end\":90281,\"start\":90268},{\"end\":90304,\"start\":90297},{\"end\":91084,\"start\":91073},{\"end\":91102,\"start\":91093},{\"end\":91121,\"start\":91116},{\"end\":91127,\"start\":91123},{\"end\":91762,\"start\":91757},{\"end\":91774,\"start\":91770},{\"end\":91787,\"start\":91783},{\"end\":91801,\"start\":91799},{\"end\":91811,\"start\":91807},{\"end\":91824,\"start\":91820},{\"end\":92243,\"start\":92239},{\"end\":92455,\"start\":92453},{\"end\":92668,\"start\":92666},{\"end\":92804,\"start\":92797},{\"end\":92938,\"start\":92935},{\"end\":93101,\"start\":93096},{\"end\":93209,\"start\":93204}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.18653/v1/P19-1620\",\"id\":\"b0\",\"matched_paper_id\":189762081},\"end\":46322,\"start\":45569},{\"attributes\":{\"doi\":\"10.1145/3477495.3531863\",\"id\":\"b1\",\"matched_paper_id\":250340449},\"end\":47202,\"start\":46324},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":218971783},\"end\":48640,\"start\":47204},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":211068995},\"end\":49079,\"start\":48642},{\"attributes\":{\"id\":\"b4\"},\"end\":49564,\"start\":49081},{\"attributes\":{\"doi\":\"10.1145/3159652.3159659\",\"id\":\"b5\",\"matched_paper_id\":33169397},\"end\":50292,\"start\":49566},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":52967399},\"end\":51234,\"start\":50294},{\"attributes\":{\"id\":\"b7\"},\"end\":51623,\"start\":51236},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.75\",\"id\":\"b8\",\"matched_paper_id\":237581068},\"end\":52358,\"start\":51625},{\"attributes\":{\"doi\":\"10.18653/v1/2022.acl-long.203\",\"id\":\"b9\",\"matched_paper_id\":236987190},\"end\":53108,\"start\":52360},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.241\",\"id\":\"b10\",\"matched_paper_id\":233241070},\"end\":54036,\"start\":53110},{\"attributes\":{\"doi\":\"10.18653/v1/2021.acl-long.295\",\"id\":\"b11\",\"matched_paper_id\":229923710},\"end\":54970,\"start\":54038},{\"attributes\":{\"doi\":\"abs/1811.08008\",\"id\":\"b12\",\"matched_paper_id\":53735999},\"end\":55255,\"start\":54972},{\"attributes\":{\"doi\":\"10.1145/2983323.2983769\",\"id\":\"b13\",\"matched_paper_id\":5688521},\"end\":55902,\"start\":55257},{\"attributes\":{\"doi\":\"10.1145/3077136.3080751\",\"id\":\"b14\",\"matched_paper_id\":3675602},\"end\":56756,\"start\":55904},{\"attributes\":{\"id\":\"b15\"},\"end\":57194,\"start\":56758},{\"attributes\":{\"doi\":\"10.18653/v1/D17-1110\",\"id\":\"b16\",\"matched_paper_id\":6246996},\"end\":57942,\"start\":57196},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":249097975},\"end\":58455,\"start\":57944},{\"attributes\":{\"id\":\"b18\"},\"end\":58935,\"start\":58457},{\"attributes\":{\"doi\":\"10.1109/TBDATA.2019.2921572\",\"id\":\"b19\",\"matched_paper_id\":926364},\"end\":59306,\"start\":58937},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.550\",\"id\":\"b20\",\"matched_paper_id\":215737187},\"end\":60169,\"start\":59308},{\"attributes\":{\"doi\":\"10.1145/3397271.3401075\",\"id\":\"b21\",\"matched_paper_id\":216553223},\"end\":61176,\"start\":60171},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00276\",\"id\":\"b22\",\"matched_paper_id\":86611921},\"end\":62108,\"start\":61178},{\"attributes\":{\"doi\":\"10.18653/v1/P19-1612\",\"id\":\"b23\",\"matched_paper_id\":173990818},\"end\":62834,\"start\":62110},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00415\",\"id\":\"b24\",\"matched_paper_id\":231924957},\"end\":63484,\"start\":62836},{\"attributes\":{\"doi\":\"10.18653/v1/2021.repl4nlp-1.17\",\"id\":\"b25\",\"matched_paper_id\":235720578},\"end\":64249,\"start\":63486},{\"attributes\":{\"doi\":\"10.18653/v1/2022.findings-acl.222\",\"id\":\"b26\",\"matched_paper_id\":235652287},\"end\":65029,\"start\":64251},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.492\",\"id\":\"b27\",\"matched_paper_id\":243865679},\"end\":65902,\"start\":65031},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00369\",\"id\":\"b28\",\"matched_paper_id\":218470027},\"end\":66422,\"start\":65904},{\"attributes\":{\"doi\":\"10.18653/v1/2021.eacl-main.92\",\"id\":\"b29\",\"matched_paper_id\":231704318},\"end\":67308,\"start\":66424},{\"attributes\":{\"doi\":\"10.1145/3184558.3192301\",\"id\":\"b30\"},\"end\":67883,\"start\":67310},{\"attributes\":{\"doi\":\"10.18653/v1/D18-1211\",\"id\":\"b31\",\"matched_paper_id\":52169526},\"end\":68627,\"start\":67885},{\"attributes\":{\"id\":\"b32\"},\"end\":69634,\"start\":68629},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":1289517},\"end\":70048,\"start\":69636},{\"attributes\":{\"doi\":\"abs/2112.07899\",\"id\":\"b34\"},\"end\":70523,\"start\":70050},{\"attributes\":{\"id\":\"b35\"},\"end\":70712,\"start\":70525},{\"attributes\":{\"doi\":\"10.18653/v1/2020.findings-emnlp.63\",\"id\":\"b36\",\"matched_paper_id\":212725651},\"end\":71526,\"start\":70714},{\"attributes\":{\"doi\":\"10.18653/v1/2022.findings-naacl.114\",\"id\":\"b37\",\"matched_paper_id\":236493551},\"end\":72408,\"start\":71528},{\"attributes\":{\"doi\":\"10.1109/TASLP.2016.2520371\",\"id\":\"b38\",\"matched_paper_id\":3337266},\"end\":73080,\"start\":72410},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.466\",\"id\":\"b39\",\"matched_paper_id\":231815627},\"end\":74073,\"start\":73082},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":204838007},\"end\":74630,\"start\":74075},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":233237266},\"end\":75102,\"start\":74632},{\"attributes\":{\"doi\":\"doi: 10.18653/ v1/2021.findings-acl.191\",\"id\":\"b42\",\"matched_paper_id\":236477844},\"end\":75919,\"start\":75104},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":238857121},\"end\":76661,\"start\":75921},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.224\",\"id\":\"b44\"},\"end\":76868,\"start\":76663},{\"attributes\":{\"id\":\"b45\"},\"end\":77239,\"start\":76870},{\"attributes\":{\"doi\":\"arXiv:2206.02873\",\"id\":\"b46\"},\"end\":77725,\"start\":77241},{\"attributes\":{\"id\":\"b47\"},\"end\":78140,\"start\":77727},{\"attributes\":{\"doi\":\"arXiv:2110.08207\",\"id\":\"b48\"},\"end\":78654,\"start\":78142},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":244799249},\"end\":79481,\"start\":78656},{\"attributes\":{\"doi\":\"10.18653/v1/2021.eacl-main.20\",\"id\":\"b50\",\"matched_paper_id\":210838924},\"end\":80312,\"start\":79483},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.185\",\"id\":\"b51\",\"matched_paper_id\":221703107},\"end\":81205,\"start\":80314},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.32\",\"id\":\"b52\",\"matched_paper_id\":238260199},\"end\":81959,\"start\":81207},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":222310116},\"end\":82816,\"start\":81961},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":233296016},\"end\":83429,\"start\":82818},{\"attributes\":{\"id\":\"b55\"},\"end\":85356,\"start\":83431},{\"attributes\":{\"doi\":\"10.18653/v1/N18-1074\",\"id\":\"b56\",\"matched_paper_id\":4711425},\"end\":86330,\"start\":85358},{\"attributes\":{\"doi\":\"10.18653/v1/2022.naacl-main.168\",\"id\":\"b57\",\"matched_paper_id\":245131402},\"end\":87317,\"start\":86332},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":237416585},\"end\":87837,\"start\":87319},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":249674500},\"end\":88529,\"start\":87839},{\"attributes\":{\"id\":\"b60\"},\"end\":88828,\"start\":88531},{\"attributes\":{\"doi\":\"10.1145/3077136.3080809\",\"id\":\"b61\",\"matched_paper_id\":5878197},\"end\":89558,\"start\":88830},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":220302524},\"end\":90116,\"start\":89560},{\"attributes\":{\"doi\":\"10.18653/v1/D18-1259\",\"id\":\"b63\",\"matched_paper_id\":52822214},\"end\":90996,\"start\":90118},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":1965270},\"end\":91695,\"start\":90998},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":238419331},\"end\":92123,\"start\":91697},{\"attributes\":{\"id\":\"b66\"},\"end\":92364,\"start\":92125},{\"attributes\":{\"id\":\"b67\"},\"end\":92595,\"start\":92366},{\"attributes\":{\"id\":\"b68\"},\"end\":92742,\"start\":92597},{\"attributes\":{\"id\":\"b69\"},\"end\":92867,\"start\":92744},{\"attributes\":{\"id\":\"b70\"},\"end\":93010,\"start\":92869},{\"attributes\":{\"id\":\"b71\"},\"end\":93193,\"start\":93012},{\"attributes\":{\"id\":\"b72\"},\"end\":93454,\"start\":93195}]", "bib_title": "[{\"end\":45627,\"start\":45569},{\"end\":46389,\"start\":46324},{\"end\":47241,\"start\":47204},{\"end\":48702,\"start\":48642},{\"end\":49638,\"start\":49566},{\"end\":50374,\"start\":50294},{\"end\":51683,\"start\":51625},{\"end\":52441,\"start\":52360},{\"end\":53202,\"start\":53110},{\"end\":54097,\"start\":54038},{\"end\":55012,\"start\":54972},{\"end\":55309,\"start\":55257},{\"end\":55958,\"start\":55904},{\"end\":57258,\"start\":57196},{\"end\":58010,\"start\":57944},{\"end\":58978,\"start\":58937},{\"end\":59366,\"start\":59308},{\"end\":60255,\"start\":60171},{\"end\":61240,\"start\":61178},{\"end\":62179,\"start\":62110},{\"end\":62906,\"start\":62836},{\"end\":63581,\"start\":63486},{\"end\":64336,\"start\":64251},{\"end\":65112,\"start\":65031},{\"end\":65969,\"start\":65904},{\"end\":66508,\"start\":66424},{\"end\":67950,\"start\":67885},{\"end\":69701,\"start\":69636},{\"end\":70775,\"start\":70714},{\"end\":71581,\"start\":71528},{\"end\":72522,\"start\":72410},{\"end\":73184,\"start\":73082},{\"end\":74156,\"start\":74075},{\"end\":74678,\"start\":74632},{\"end\":75194,\"start\":75104},{\"end\":76007,\"start\":75921},{\"end\":78733,\"start\":78656},{\"end\":79573,\"start\":79483},{\"end\":80395,\"start\":80314},{\"end\":81266,\"start\":81207},{\"end\":82049,\"start\":81961},{\"end\":82906,\"start\":82818},{\"end\":85423,\"start\":85358},{\"end\":86417,\"start\":86332},{\"end\":87367,\"start\":87319},{\"end\":87882,\"start\":87839},{\"end\":88881,\"start\":88830},{\"end\":89643,\"start\":89560},{\"end\":90191,\"start\":90118},{\"end\":91062,\"start\":90998},{\"end\":91750,\"start\":91697}]", "bib_author": "[{\"end\":45644,\"start\":45629},{\"end\":45658,\"start\":45644},{\"end\":45672,\"start\":45658},{\"end\":45686,\"start\":45672},{\"end\":45703,\"start\":45686},{\"end\":46407,\"start\":46391},{\"end\":46422,\"start\":46407},{\"end\":46438,\"start\":46422},{\"end\":46456,\"start\":46438},{\"end\":47254,\"start\":47243},{\"end\":47269,\"start\":47254},{\"end\":47281,\"start\":47269},{\"end\":47298,\"start\":47281},{\"end\":47314,\"start\":47298},{\"end\":47333,\"start\":47314},{\"end\":47353,\"start\":47333},{\"end\":47367,\"start\":47353},{\"end\":47382,\"start\":47367},{\"end\":47397,\"start\":47382},{\"end\":47415,\"start\":47397},{\"end\":47435,\"start\":47415},{\"end\":47453,\"start\":47435},{\"end\":47467,\"start\":47453},{\"end\":47480,\"start\":47467},{\"end\":47495,\"start\":47480},{\"end\":47511,\"start\":47495},{\"end\":47523,\"start\":47511},{\"end\":47539,\"start\":47523},{\"end\":47552,\"start\":47539},{\"end\":47563,\"start\":47552},{\"end\":47576,\"start\":47563},{\"end\":47592,\"start\":47576},{\"end\":48721,\"start\":48704},{\"end\":48733,\"start\":48721},{\"end\":48748,\"start\":48733},{\"end\":48761,\"start\":48748},{\"end\":48775,\"start\":48761},{\"end\":49181,\"start\":49169},{\"end\":49198,\"start\":49181},{\"end\":49211,\"start\":49198},{\"end\":49225,\"start\":49211},{\"end\":49240,\"start\":49225},{\"end\":49258,\"start\":49240},{\"end\":49273,\"start\":49258},{\"end\":49286,\"start\":49273},{\"end\":49299,\"start\":49286},{\"end\":49652,\"start\":49640},{\"end\":49667,\"start\":49652},{\"end\":49681,\"start\":49667},{\"end\":49694,\"start\":49681},{\"end\":50390,\"start\":50376},{\"end\":50406,\"start\":50390},{\"end\":50418,\"start\":50406},{\"end\":50438,\"start\":50418},{\"end\":51348,\"start\":51331},{\"end\":51365,\"start\":51348},{\"end\":51386,\"start\":51365},{\"end\":51406,\"start\":51386},{\"end\":51695,\"start\":51685},{\"end\":51709,\"start\":51695},{\"end\":52453,\"start\":52443},{\"end\":52467,\"start\":52453},{\"end\":53214,\"start\":53204},{\"end\":53226,\"start\":53214},{\"end\":53240,\"start\":53226},{\"end\":54111,\"start\":54099},{\"end\":54123,\"start\":54111},{\"end\":54135,\"start\":54123},{\"end\":55030,\"start\":55014},{\"end\":55049,\"start\":55030},{\"end\":55069,\"start\":55049},{\"end\":55324,\"start\":55311},{\"end\":55336,\"start\":55324},{\"end\":55348,\"start\":55336},{\"end\":55363,\"start\":55348},{\"end\":55976,\"start\":55960},{\"end\":55992,\"start\":55976},{\"end\":56007,\"start\":55992},{\"end\":56024,\"start\":56007},{\"end\":56046,\"start\":56024},{\"end\":56063,\"start\":56046},{\"end\":56077,\"start\":56063},{\"end\":56882,\"start\":56860},{\"end\":56900,\"start\":56882},{\"end\":56918,\"start\":56900},{\"end\":56932,\"start\":56918},{\"end\":56947,\"start\":56932},{\"end\":57269,\"start\":57260},{\"end\":57283,\"start\":57269},{\"end\":57300,\"start\":57283},{\"end\":57316,\"start\":57300},{\"end\":58029,\"start\":58012},{\"end\":58045,\"start\":58029},{\"end\":58061,\"start\":58045},{\"end\":58079,\"start\":58061},{\"end\":58097,\"start\":58079},{\"end\":58112,\"start\":58097},{\"end\":58127,\"start\":58112},{\"end\":58534,\"start\":58517},{\"end\":58549,\"start\":58534},{\"end\":58563,\"start\":58549},{\"end\":58579,\"start\":58563},{\"end\":58594,\"start\":58579},{\"end\":58607,\"start\":58594},{\"end\":58624,\"start\":58607},{\"end\":58639,\"start\":58624},{\"end\":58657,\"start\":58639},{\"end\":58672,\"start\":58657},{\"end\":58994,\"start\":58980},{\"end\":59010,\"start\":58994},{\"end\":59023,\"start\":59010},{\"end\":59388,\"start\":59368},{\"end\":59401,\"start\":59388},{\"end\":59412,\"start\":59401},{\"end\":59427,\"start\":59412},{\"end\":59438,\"start\":59427},{\"end\":59453,\"start\":59438},{\"end\":59465,\"start\":59453},{\"end\":59478,\"start\":59465},{\"end\":60271,\"start\":60257},{\"end\":60286,\"start\":60271},{\"end\":60295,\"start\":60286},{\"end\":61259,\"start\":61242},{\"end\":61280,\"start\":61259},{\"end\":61297,\"start\":61280},{\"end\":61314,\"start\":61297},{\"end\":61328,\"start\":61314},{\"end\":61343,\"start\":61328},{\"end\":61361,\"start\":61343},{\"end\":61379,\"start\":61361},{\"end\":61393,\"start\":61379},{\"end\":61405,\"start\":61393},{\"end\":61425,\"start\":61405},{\"end\":61438,\"start\":61425},{\"end\":61454,\"start\":61438},{\"end\":61470,\"start\":61454},{\"end\":61484,\"start\":61470},{\"end\":61501,\"start\":61484},{\"end\":61510,\"start\":61501},{\"end\":61523,\"start\":61510},{\"end\":62193,\"start\":62181},{\"end\":62209,\"start\":62193},{\"end\":62229,\"start\":62209},{\"end\":62923,\"start\":62908},{\"end\":62935,\"start\":62923},{\"end\":62948,\"start\":62935},{\"end\":62968,\"start\":62948},{\"end\":62986,\"start\":62968},{\"end\":63005,\"start\":62986},{\"end\":63023,\"start\":63005},{\"end\":63041,\"start\":63023},{\"end\":63611,\"start\":63583},{\"end\":63623,\"start\":63611},{\"end\":63628,\"start\":63623},{\"end\":64352,\"start\":64338},{\"end\":64358,\"start\":64352},{\"end\":64375,\"start\":64358},{\"end\":64389,\"start\":64375},{\"end\":64404,\"start\":64389},{\"end\":64418,\"start\":64404},{\"end\":64436,\"start\":64418},{\"end\":65123,\"start\":65114},{\"end\":65149,\"start\":65123},{\"end\":65156,\"start\":65149},{\"end\":65167,\"start\":65156},{\"end\":65180,\"start\":65167},{\"end\":65980,\"start\":65971},{\"end\":65998,\"start\":65980},{\"end\":66018,\"start\":65998},{\"end\":66035,\"start\":66018},{\"end\":66517,\"start\":66510},{\"end\":66532,\"start\":66517},{\"end\":66545,\"start\":66532},{\"end\":66557,\"start\":66545},{\"end\":66572,\"start\":66557},{\"end\":67395,\"start\":67382},{\"end\":67416,\"start\":67395},{\"end\":67431,\"start\":67416},{\"end\":67444,\"start\":67431},{\"end\":67460,\"start\":67444},{\"end\":67475,\"start\":67460},{\"end\":67494,\"start\":67475},{\"end\":67967,\"start\":67952},{\"end\":67982,\"start\":67967},{\"end\":68003,\"start\":67982},{\"end\":68651,\"start\":68631},{\"end\":68659,\"start\":68651},{\"end\":68670,\"start\":68659},{\"end\":68684,\"start\":68670},{\"end\":68703,\"start\":68684},{\"end\":68717,\"start\":68703},{\"end\":68730,\"start\":68717},{\"end\":68747,\"start\":68730},{\"end\":68762,\"start\":68747},{\"end\":68777,\"start\":68762},{\"end\":68796,\"start\":68777},{\"end\":68810,\"start\":68796},{\"end\":68823,\"start\":68810},{\"end\":68845,\"start\":68823},{\"end\":68860,\"start\":68845},{\"end\":68878,\"start\":68860},{\"end\":68895,\"start\":68878},{\"end\":69715,\"start\":69703},{\"end\":69730,\"start\":69715},{\"end\":69740,\"start\":69730},{\"end\":69754,\"start\":69740},{\"end\":69770,\"start\":69754},{\"end\":69787,\"start\":69770},{\"end\":69796,\"start\":69787},{\"end\":70111,\"start\":70100},{\"end\":70120,\"start\":70111},{\"end\":70129,\"start\":70120},{\"end\":70141,\"start\":70129},{\"end\":70167,\"start\":70141},{\"end\":70174,\"start\":70167},{\"end\":70190,\"start\":70174},{\"end\":70199,\"start\":70190},{\"end\":70213,\"start\":70199},{\"end\":70229,\"start\":70213},{\"end\":70242,\"start\":70229},{\"end\":70543,\"start\":70525},{\"end\":70558,\"start\":70543},{\"end\":70795,\"start\":70777},{\"end\":70810,\"start\":70795},{\"end\":70825,\"start\":70810},{\"end\":70836,\"start\":70825},{\"end\":71596,\"start\":71583},{\"end\":71613,\"start\":71596},{\"end\":71627,\"start\":71613},{\"end\":71642,\"start\":71627},{\"end\":71662,\"start\":71642},{\"end\":71681,\"start\":71662},{\"end\":71693,\"start\":71681},{\"end\":71711,\"start\":71693},{\"end\":71722,\"start\":71711},{\"end\":71735,\"start\":71722},{\"end\":71750,\"start\":71735},{\"end\":72539,\"start\":72524},{\"end\":72548,\"start\":72539},{\"end\":72561,\"start\":72548},{\"end\":72575,\"start\":72561},{\"end\":72588,\"start\":72575},{\"end\":72602,\"start\":72588},{\"end\":72616,\"start\":72602},{\"end\":72628,\"start\":72616},{\"end\":73197,\"start\":73186},{\"end\":73210,\"start\":73197},{\"end\":73220,\"start\":73210},{\"end\":73229,\"start\":73220},{\"end\":73242,\"start\":73229},{\"end\":73258,\"start\":73242},{\"end\":73272,\"start\":73258},{\"end\":73280,\"start\":73272},{\"end\":73294,\"start\":73280},{\"end\":74172,\"start\":74158},{\"end\":74188,\"start\":74172},{\"end\":74202,\"start\":74188},{\"end\":74217,\"start\":74202},{\"end\":74232,\"start\":74217},{\"end\":74248,\"start\":74232},{\"end\":74260,\"start\":74248},{\"end\":74266,\"start\":74260},{\"end\":74279,\"start\":74266},{\"end\":74691,\"start\":74680},{\"end\":74703,\"start\":74691},{\"end\":74736,\"start\":74703},{\"end\":74749,\"start\":74736},{\"end\":74770,\"start\":74749},{\"end\":74784,\"start\":74770},{\"end\":74797,\"start\":74784},{\"end\":74810,\"start\":74797},{\"end\":74817,\"start\":74810},{\"end\":75209,\"start\":75196},{\"end\":75222,\"start\":75209},{\"end\":75233,\"start\":75222},{\"end\":75243,\"start\":75233},{\"end\":75259,\"start\":75243},{\"end\":75273,\"start\":75259},{\"end\":75281,\"start\":75273},{\"end\":75295,\"start\":75281},{\"end\":75308,\"start\":75295},{\"end\":76022,\"start\":76009},{\"end\":76033,\"start\":76022},{\"end\":76043,\"start\":76033},{\"end\":76059,\"start\":76043},{\"end\":76073,\"start\":76059},{\"end\":76081,\"start\":76073},{\"end\":76095,\"start\":76081},{\"end\":76108,\"start\":76095},{\"end\":76936,\"start\":76923},{\"end\":76947,\"start\":76936},{\"end\":76957,\"start\":76947},{\"end\":76973,\"start\":76957},{\"end\":76983,\"start\":76973},{\"end\":76996,\"start\":76983},{\"end\":77004,\"start\":76996},{\"end\":77018,\"start\":77004},{\"end\":77031,\"start\":77018},{\"end\":77355,\"start\":77327},{\"end\":77372,\"start\":77355},{\"end\":77387,\"start\":77372},{\"end\":77405,\"start\":77387},{\"end\":77421,\"start\":77405},{\"end\":77437,\"start\":77421},{\"end\":77447,\"start\":77437},{\"end\":77814,\"start\":77791},{\"end\":77826,\"start\":77814},{\"end\":77840,\"start\":77826},{\"end\":77858,\"start\":77840},{\"end\":77871,\"start\":77858},{\"end\":77886,\"start\":77871},{\"end\":77904,\"start\":77886},{\"end\":78222,\"start\":78209},{\"end\":78237,\"start\":78222},{\"end\":78251,\"start\":78237},{\"end\":78262,\"start\":78251},{\"end\":78276,\"start\":78262},{\"end\":78291,\"start\":78276},{\"end\":78309,\"start\":78291},{\"end\":78325,\"start\":78309},{\"end\":78344,\"start\":78325},{\"end\":78355,\"start\":78344},{\"end\":78361,\"start\":78355},{\"end\":78753,\"start\":78735},{\"end\":78767,\"start\":78753},{\"end\":78784,\"start\":78767},{\"end\":78803,\"start\":78784},{\"end\":78818,\"start\":78803},{\"end\":79588,\"start\":79575},{\"end\":79605,\"start\":79588},{\"end\":80410,\"start\":80397},{\"end\":80427,\"start\":80410},{\"end\":81281,\"start\":81268},{\"end\":81298,\"start\":81281},{\"end\":82067,\"start\":82051},{\"end\":82084,\"start\":82067},{\"end\":82100,\"start\":82084},{\"end\":82113,\"start\":82100},{\"end\":82122,\"start\":82113},{\"end\":82134,\"start\":82122},{\"end\":82147,\"start\":82134},{\"end\":82163,\"start\":82147},{\"end\":82170,\"start\":82163},{\"end\":82923,\"start\":82908},{\"end\":82937,\"start\":82923},{\"end\":82953,\"start\":82937},{\"end\":82974,\"start\":82953},{\"end\":82990,\"start\":82974},{\"end\":83450,\"start\":83433},{\"end\":83469,\"start\":83450},{\"end\":83481,\"start\":83469},{\"end\":83495,\"start\":83481},{\"end\":83516,\"start\":83495},{\"end\":83526,\"start\":83516},{\"end\":83540,\"start\":83526},{\"end\":83552,\"start\":83540},{\"end\":83564,\"start\":83552},{\"end\":83574,\"start\":83564},{\"end\":83586,\"start\":83574},{\"end\":83598,\"start\":83586},{\"end\":83603,\"start\":83598},{\"end\":83630,\"start\":83603},{\"end\":83648,\"start\":83630},{\"end\":83666,\"start\":83648},{\"end\":83679,\"start\":83666},{\"end\":83694,\"start\":83679},{\"end\":83710,\"start\":83694},{\"end\":83721,\"start\":83710},{\"end\":83737,\"start\":83721},{\"end\":83749,\"start\":83737},{\"end\":83760,\"start\":83749},{\"end\":83777,\"start\":83760},{\"end\":83790,\"start\":83777},{\"end\":83808,\"start\":83790},{\"end\":83820,\"start\":83808},{\"end\":83835,\"start\":83820},{\"end\":83847,\"start\":83835},{\"end\":83867,\"start\":83847},{\"end\":83884,\"start\":83867},{\"end\":85439,\"start\":85425},{\"end\":85456,\"start\":85439},{\"end\":85485,\"start\":85456},{\"end\":85499,\"start\":85485},{\"end\":86431,\"start\":86419},{\"end\":86446,\"start\":86431},{\"end\":86460,\"start\":86446},{\"end\":86476,\"start\":86460},{\"end\":87380,\"start\":87369},{\"end\":87400,\"start\":87380},{\"end\":87414,\"start\":87400},{\"end\":87426,\"start\":87414},{\"end\":87440,\"start\":87426},{\"end\":87454,\"start\":87440},{\"end\":87462,\"start\":87454},{\"end\":87481,\"start\":87462},{\"end\":87492,\"start\":87481},{\"end\":87895,\"start\":87884},{\"end\":87903,\"start\":87895},{\"end\":87920,\"start\":87903},{\"end\":87934,\"start\":87920},{\"end\":87947,\"start\":87934},{\"end\":87967,\"start\":87947},{\"end\":87982,\"start\":87967},{\"end\":87997,\"start\":87982},{\"end\":88009,\"start\":87997},{\"end\":88025,\"start\":88009},{\"end\":88035,\"start\":88025},{\"end\":88056,\"start\":88035},{\"end\":88071,\"start\":88056},{\"end\":88084,\"start\":88071},{\"end\":88095,\"start\":88084},{\"end\":88110,\"start\":88095},{\"end\":88597,\"start\":88587},{\"end\":88608,\"start\":88597},{\"end\":88622,\"start\":88608},{\"end\":88635,\"start\":88622},{\"end\":88649,\"start\":88635},{\"end\":88898,\"start\":88883},{\"end\":88910,\"start\":88898},{\"end\":88924,\"start\":88910},{\"end\":88937,\"start\":88924},{\"end\":88952,\"start\":88937},{\"end\":89656,\"start\":89645},{\"end\":89671,\"start\":89656},{\"end\":89678,\"start\":89671},{\"end\":89694,\"start\":89678},{\"end\":89706,\"start\":89694},{\"end\":89722,\"start\":89706},{\"end\":89736,\"start\":89722},{\"end\":89753,\"start\":89736},{\"end\":90206,\"start\":90193},{\"end\":90215,\"start\":90206},{\"end\":90231,\"start\":90215},{\"end\":90246,\"start\":90231},{\"end\":90261,\"start\":90246},{\"end\":90283,\"start\":90261},{\"end\":90306,\"start\":90283},{\"end\":91086,\"start\":91064},{\"end\":91104,\"start\":91086},{\"end\":91123,\"start\":91104},{\"end\":91129,\"start\":91123},{\"end\":91764,\"start\":91752},{\"end\":91776,\"start\":91764},{\"end\":91789,\"start\":91776},{\"end\":91803,\"start\":91789},{\"end\":91813,\"start\":91803},{\"end\":91826,\"start\":91813},{\"end\":92245,\"start\":92236},{\"end\":92457,\"start\":92446},{\"end\":92670,\"start\":92661},{\"end\":92806,\"start\":92791},{\"end\":92940,\"start\":92928},{\"end\":93103,\"start\":93094},{\"end\":93211,\"start\":93195}]", "bib_venue": "[{\"end\":45810,\"start\":45723},{\"end\":46601,\"start\":46479},{\"end\":47641,\"start\":47592},{\"end\":48827,\"start\":48775},{\"end\":49167,\"start\":49081},{\"end\":49813,\"start\":49717},{\"end\":50580,\"start\":50438},{\"end\":51329,\"start\":51236},{\"end\":51825,\"start\":51739},{\"end\":52583,\"start\":52496},{\"end\":53413,\"start\":53271},{\"end\":54326,\"start\":54164},{\"end\":55087,\"start\":55083},{\"end\":55491,\"start\":55386},{\"end\":56222,\"start\":56100},{\"end\":56858,\"start\":56758},{\"end\":57422,\"start\":57336},{\"end\":58168,\"start\":58127},{\"end\":58515,\"start\":58457},{\"end\":59079,\"start\":59050},{\"end\":59603,\"start\":59509},{\"end\":60456,\"start\":60318},{\"end\":61604,\"start\":61543},{\"end\":62336,\"start\":62249},{\"end\":63122,\"start\":63061},{\"end\":63740,\"start\":63658},{\"end\":64536,\"start\":64469},{\"end\":65297,\"start\":65211},{\"end\":66116,\"start\":66055},{\"end\":66721,\"start\":66601},{\"end\":67380,\"start\":67310},{\"end\":68109,\"start\":68023},{\"end\":69805,\"start\":69796},{\"end\":70098,\"start\":70050},{\"end\":70593,\"start\":70558},{\"end\":70939,\"start\":70870},{\"end\":71854,\"start\":71785},{\"end\":72717,\"start\":72654},{\"end\":73467,\"start\":73325},{\"end\":74315,\"start\":74279},{\"end\":74824,\"start\":74817},{\"end\":75421,\"start\":75347},{\"end\":76194,\"start\":76108},{\"end\":76921,\"start\":76870},{\"end\":77325,\"start\":77241},{\"end\":77789,\"start\":77727},{\"end\":78207,\"start\":78142},{\"end\":78960,\"start\":78818},{\"end\":79754,\"start\":79634},{\"end\":80600,\"start\":80458},{\"end\":81414,\"start\":81328},{\"end\":82264,\"start\":82170},{\"end\":83084,\"start\":82990},{\"end\":85661,\"start\":85519},{\"end\":86649,\"start\":86507},{\"end\":87544,\"start\":87492},{\"end\":88151,\"start\":88110},{\"end\":88585,\"start\":88531},{\"end\":89097,\"start\":88975},{\"end\":89805,\"start\":89753},{\"end\":90412,\"start\":90326},{\"end\":91211,\"start\":91129},{\"end\":91878,\"start\":91826},{\"end\":92234,\"start\":92125},{\"end\":92444,\"start\":92366},{\"end\":92659,\"start\":92597},{\"end\":92789,\"start\":92744},{\"end\":92926,\"start\":92869},{\"end\":93092,\"start\":93012},{\"end\":93323,\"start\":93211},{\"end\":45899,\"start\":45812},{\"end\":46733,\"start\":46603},{\"end\":47793,\"start\":47705},{\"end\":49913,\"start\":49815},{\"end\":50731,\"start\":50582},{\"end\":51939,\"start\":51827},{\"end\":52672,\"start\":52585},{\"end\":53548,\"start\":53415},{\"end\":54475,\"start\":54328},{\"end\":55600,\"start\":55493},{\"end\":56348,\"start\":56224},{\"end\":57514,\"start\":57424},{\"end\":59684,\"start\":59605},{\"end\":60677,\"start\":60549},{\"end\":62425,\"start\":62338},{\"end\":63809,\"start\":63742},{\"end\":64553,\"start\":64538},{\"end\":65370,\"start\":65299},{\"end\":66828,\"start\":66723},{\"end\":68199,\"start\":68111},{\"end\":71878,\"start\":71856},{\"end\":73596,\"start\":73469},{\"end\":76285,\"start\":76196},{\"end\":79089,\"start\":78962},{\"end\":79861,\"start\":79756},{\"end\":80735,\"start\":80602},{\"end\":81528,\"start\":81416},{\"end\":82345,\"start\":82266},{\"end\":85812,\"start\":85663},{\"end\":86800,\"start\":86651},{\"end\":89223,\"start\":89099},{\"end\":90502,\"start\":90414},{\"end\":91301,\"start\":91213}]"}}}, "year": 2023, "month": 12, "day": 17}