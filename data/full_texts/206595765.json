{"id": 206595765, "updated": "2023-09-28 16:19:20.603", "metadata": {"title": "Re-ranking Person Re-identification with k-reciprocal Encoding", "authors": "[{\"first\":\"Zhun\",\"last\":\"Zhong\",\"middle\":[]},{\"first\":\"Liang\",\"last\":\"Zheng\",\"middle\":[]},{\"first\":\"Donglin\",\"last\":\"Cao\",\"middle\":[]},{\"first\":\"Shaozi\",\"last\":\"Li\",\"middle\":[]}]", "venue": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "journal": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "publication_date": {"year": 2017, "month": 1, "day": 29}, "abstract": "When considering person re-identification (re-ID) as a retrieval process, re-ranking is a critical step to improve its accuracy. Yet in the re-ID community, limited effort has been devoted to re-ranking, especially those fully automatic, unsupervised solutions. In this paper, we propose a k-reciprocal encoding method to re-rank the re-ID results. Our hypothesis is that if a gallery image is similar to the probe in the k-reciprocal nearest neighbors, it is more likely to be a true match. Specifically, given an image, a k-reciprocal feature is calculated by encoding its k-reciprocal nearest neighbors into a single vector, which is used for re-ranking under the Jaccard distance. The final distance is computed as the combination of the original distance and the Jaccard distance. Our re-ranking method does not require any human interaction or any labeled data, so it is applicable to large-scale datasets. Experiments on the large-scale Market-1501, CUHK03, MARS, and PRW datasets confirm the effectiveness of our method.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1701.08398", "mag": "2952956153", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/ZhongZCL17", "doi": "10.1109/cvpr.2017.389"}}, "content": {"source": {"pdf_hash": "af44501827603202d3b6489ecd866b3f83b87c65", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1701.08398v1.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://opus.lib.uts.edu.au/bitstream/10453/118077/4/6FE4BDE0-2335-4423-BA25-603F4FFF0AF2.pdf", "status": "GREEN"}}, "grobid": {"id": "f5c378135f13979d07fce02ba4c89068b2e844d2", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/af44501827603202d3b6489ecd866b3f83b87c65.txt", "contents": "\nRe-ranking Person Re-identification with k-reciprocal Encoding\n\n\nZhun Zhong zhunzhong007@gmail.com \nXiamen University \u00a7 University of Technology Sydney\n\n\nLiang Zheng liangzheng06@gmail.com \nXiamen University \u00a7 University of Technology Sydney\n\n\nDonglin Cao \nXiamen University \u00a7 University of Technology Sydney\n\n\nShaozi Li \nXiamen University \u00a7 University of Technology Sydney\n\n\nRe-ranking Person Re-identification with k-reciprocal Encoding\n\nWhen considering person re-identification (re-ID) as a retrieval process, re-ranking is a critical step to improve its accuracy. Yet in the re-ID community, limited effort has been devoted to re-ranking, especially those fully automatic, unsupervised solutions. In this paper, we propose a k-reciprocal encoding method to re-rank the re-ID results. Our hypothesis is that if a gallery image is similar to the probe in the k-reciprocal nearest neighbors, it is more likely to be a true match. Specifically, given an image, a k-reciprocal feature is calculated by encoding its k-reciprocal nearest neighbors into a single vector, which is used for re-ranking under the Jaccard distance. The final distance is computed as the combination of the original distance and the Jaccard distance. Our re-ranking method does not require any human interaction or any labeled data, so it is applicable to large-scale datasets. Experiments on the large-scale Market-1501, CUHK03, MARS, and PRW datasets confirm the effectiveness of our method. Our code will be released soon.\n\nIntroduction\n\nPerson re-identification (re-ID) [50,3,23,31,27,29] is a challenging task in computer vision. In general, re-ID can be regarded as a retrieval problem. Given a probe person, we want to search in the gallery for images containing the same person in a cross-camera mode. After an initial ranking list is obtained, a good practice consists of adding a re-ranking step, with the expectation that the relevant images will receive higher ranks. In this paper, we thus focus on the re-ranking issue.\n\nRe-ranking has been mostly studied in generic instance retrieval [5,14,34,35]. The main advantage of many reranking methods is that it can be implemented without requiring additional training samples, and that it can be applied to any initial ranking result.\n\nThe effectiveness of re-ranking depends heavily on the quality of the initial ranking list. A number of previous works exploit the similarity relationships between top- ranked images (such as the k-nearest neighbors) in the initial ranking list [5,14,34,35,43,44]. An underlying assumption is that if a returned image ranks within the knearest neighbors of the probe, it is likely to be a true match which can be used for the subsequent re-ranking. Nevertheless, situation may deviate from optimal cases: false matches may well be included in the k-nearest neighbors of the probe. For example, in Fig. 1, P1, P2, P3 and P4 are four true matches to the probe, but all of them are not included in the top-4 ranks. We observe some false matches (N1-N6) receive high ranks. As a result, directly using the top-k ranked images may introduce noise in the re-ranking systems and compromise the final result.\nProbe P1 N1 P2 N2 P3 N3 N4 N5 P4 N6\nIn literature, the k-reciprocal nearest neighbor [14,34] is an effective solution to the above-mentioned problem, i.e., the pollution of false matches to the top-k images. When two images are called k-reciprocal nearest neighbors, they are both ranked top-k when the other image is taken as the probe. Therefore, the k-reciprocal nearest neighbor serves as a stricter rule whether two images are true matches or not. In Fig. 1, we observe that the probe is a reciprocal Figure 2. Proposed re-ranking framework for person re-identification. Given a probe p and a gallery, the appearance feature and k-reciprocal feature are extracted for each person. Then the original distance d and Jaccard distance dJ are calculated for each pair of the probe person and gallery person. The final distance d * is computed as the combination of d and dJ , which is used to obtain the proposed ranking list.\n\nneighbor to the true matched images, but not to the false matches. This observation identifies the true matches in the initial ranking list to improve the re-ranking results.\n\nGiven the above considerations, this paper introduces a k-reciprocal encoding method for re-ID re-ranking. Our approach consists of three steps. First, we encode the weighted k-reciprocal neighbor set into a vector to form the k-reciprocal feature. Then, the Jaccard distance between two images can be computed by their k-reciprocal features. Second, to obtain a more robust k-reciprocal feature, we develop a local query expansion approach to further improve the re-ID performance. Finally, the final distance is calculated as the weighted aggregation of the original distance and the Jaccard distance. It is subsequently used to acquire the re-ranking list. The framework of the proposed approach is illustrated in Fig. 2. To summarize, the contributions of this paper are:\n\n\u2022 We propose a k-reciprocal feature by encoding the kreciprocal feature into a singe vector. The re-ranking process can be easily performed by vector comparison.\n\n\u2022 Our approach does not require any human interaction or annotated data, and can be applied to any person re-ID ranking result in an automatic and unsupervised way.\n\n\u2022 The proposed method effectively improves the person re-ID performance on several datasets, including Market-1501, CUHK03, MARS, and PRW. In particular, we achieve the state-of-the-art accuracy on Market-1501 in both rank-1 and mAP.\n\n\nRelated Work\n\nWe refer the interested readers to [3,50] for a detailed review of person re-identification (re-ID). Here we focus on research that aims at re-ranking methods for object retrieval and particularly for re-ID.\n\nRe-ranking for object retrieval. Re-ranking methods have been successfully studied to improve object retrieval accuracy [51]. A number of works utilize the k-nearest neighbors to explore similarity relationships to address the re-ranking problem. Chum et al. [5] propose the average query expansion (AQE) method, where a new query vector is obtained by averaging the vectors in the top-k returned results, and is used to re-query the database. To take advantage of the negative sample which is far away from the query image, Arandjelovi\u0107 and Zisserman [1] develop the discriminative query expansion (DQE) to use a linear SVM to obtain a weight vector. The distance from the decision boundary is employed to revise the initial ranking list. Shen et al. [35] make use of the k-nearest neighbors of the initial ranking list as new queries to produce new ranking lists. The new score of each image is calculated depending on its positions in the produced ranking lists. More recently, sparse contextual activation (SCA) [2] propose to encode the neighbor set into a vector, and to indicate samples similarity by generalized Jaccard distance. To prevent the pollution of false matches to the top-k images, the concept of k-reciprocal nearest neighbors is adopted in [14,34]. In [14], the contextual dissimilarity measure (CDM) is proposed to refine the similarity by iteratively regularizing the average distance of each point to its neighborhood. Qin et al. [34] formally present the concept of k-reciprocal nearest neighbors. The k-reciprocal nearest neighbors are con-sidered as highly relevant candidates, and used to construct closed set for re-ranking the rest of dataset. Our work departs from both works in several aspects. We do not symmetrize nearest neighborhood relationship to refine the similarity as [14], or directly consider the k-reciprocal nearest neighbors as top ranked samples like [34]. Instead we calculate a new distance between two images by comparing their k-reciprocal nearest neighbors.\n\nRe-ranking for re-ID. Most existing person reidentification methods mainly focus on feature representation [41,12,23,48,21] or metric learning [23,17,9,32,45]. Recently, several researchers [10,33,28,24,49,20,11,19,42,44] have paid attention to re-ranking based method in the re-ID community. Li et al. [20] develop a re-ranking model by analyzing the relative information and direct information of near neighbors of each pair of images. In [11], an unsupervised re-ranking model is learnt by jointly considering the content and context information in the ranking list, which effectively remove ambiguous samples to improve the performance of re-ID. Leng et al. [19] propose a bidirectional ranking method to revise the initial ranking list with the new similarity computed as the fusion of both content and contextual similarity. Recently, the common nearest neighbors of different baseline methods are exploited to re-ranking task [42,44]. Ye et al. [42] combine the common nearest neighbors of global and local features as new queries, and revise the initial ranking list by aggregating the new ranking lists of global and local features. In [44], the k-nearest neighbor set is utilized to calculate both similarity and dissimilarity from different baseline method, then the aggregation of similarity and dissimilarity is performed to optimize the initial ranking list. Continues progress of these mentioned methods in re-ranking promises to make future contributions to discovering further information from k-nearest neighbors. However, using the k-nearest neighbors to implement re-ranking directly may restrict the overall performance since false matches are often included. To tackle this problem, in this paper, we investigate the importance of k-reciprocal neighbors in person re-ID and hence design a simple but effective re-ranking method.\n\n\nProposed Approach\n\n\nProblem Definition\n\nGiven a probe person p and the gallery set with N images G = {g i | i = 1, 2, ...N }, the original distance between two persons p and g i can be measured by Mahalanobis distance,\nd(p, g i ) = (x p \u2212 x gi ) M(x p \u2212 x gi )(1)\nwhere x p and x gi represents the appearance feature of probe p and gallery g i , respectively, and M is a positive semidefinite matrix.\n\nThe initial ranking list L(p, G) = {g 0 1 , g 0 2 , ...g 0 N } can be obtained according to the pairwise original distance between probe p and gallery g i , where d(p, g 0 i ) < d(p, g 0 i+1 ). Our goal is to re-rank L(p, G), so that more positive samples rank top in the list, and thus to improve the performance of person re-identification (re-ID).\n\n\nK-reciprocal Nearest Neighbors\n\nFollowing [34], we define N (p, k) as the k-nearest neighbors (i.e. the top-k samples of the ranking list) of a probe p:\nN (p, k) = {g 0 1 , g 0 2 , ..., g 0 k }, |N (p, k)| = k(2)\nwhere |\u00b7| denotes the number of candidates in the set. The k-reciprocal nearest neighbors R(p, k) can be defined as,\nR(p, k) = {(g i \u2208 N (p, k)) \u2229 (p \u2208 N (g i , k))}(3)\nAccording to the previous description, the k-reciprocal nearest neighbors are more related to probe p than k-nearest neighbors. However, due to variations in illuminations, poses, views and occlusions, the positive images may be excluded from the k-nearest neighbors, and subsequently not be included in the k-reciprocal nearest neighbors. To address this problem, we incrementally add the 1 2 k-reciprocal nearest neighbors of each candidate in R(p, k) into a more robust set R * (p, k) according to the following condition\nR * (p, k) \u2190 R(p, k) \u222a R(q, 1 2 k) s.t. R(p, k) \u2229 R(q, 1 2 k) 2 3 R(q, 1 2 k) , \u2200q \u2208 R(p, k)(4)\nBy this operation, we can add into R * (p, k) more positive samples which are more similar to the candidates in R(p, k) than to the probe p. This is stricter against including too many negative samples compared to [34]. In Fig. 3, we show an example of the expansion process. Initially, the hard positive G is missed out in R(Q, 20). Interestingly, G is included in R(C, 10), which is beneficial information for bringing positive G back. Then, we can apply Eq. 4 to add G into R * (Q, 20). Therefore, after expansion process, more positive samples could be added into R * (p, k). Different from [34], we do not directly take the candidates in R * (p, k) as top ranked images. Instead, we consider R * (p, k) as contextual knowledge to re-calculate the distance between the probe and gallery.\n\n\nJaccard Distance\n\nIn this subsection, we re-calculate the pairwise distance between the probe p and the gallery g i by comparing their k-reciprocal nearest neighbor set. As described earlier [2] \nQ B C A D E G Q B F B C A D E Q F G \u211b * (, 20)\n\u211b( , 20)\n\u211b( , 10) \u211b(, 20)\n\u211b( , 10) [44], we believe that if two images are similar, their kreciprocal nearest neighbor sets overlap, i.e., there are some duplicate samples in the sets. And the more duplicate samples, the more similar the two images are. The new distance between p and g i can be calculated by the Jaccard metric of their k-reciprocal features as:\nd J (p, g i ) = 1 \u2212 |R * (p, k) \u2229 R * (g i , k)| |R * (p, k) \u222a R * (g i , k)|(5)\nwhere |\u00b7| denotes the number of candidates in the set. We adopt Jaccard distance to name this new distance. Although the above method could capture the similarity relationships between two images, there still remains three obvious shortcomings:\n\n\u2022 It is very time-consuming to get the intersection and union of two neighbor sets R * (p, k) and R * (g i , k) in many cases, and it becomes more challenging while the Jaccard distance is needed to be calculated for all image pairs. An alternative way is to encode the neighbor set into an easier but equivalent vector, reducing the computational complexity greatly, while maintaining original structure in neighbor set.\n\n\u2022 The distance calculation method weighs all neighbors equally, leading to a simple but not discriminative neighbor set. In fact, neighbors that are closer to probe p are more likely to be true positives. Therefore, it is convincing and reasonable to re-calculate weights based on the original distance, and assign large weights to nearer samples.\n\n\u2022 Simply taking the contextual information into account will pose considerable barriers when attempting to measure similarity between two persons, since unavoidable variation makes it difficult to discriminate sufficient contextual information. Hence, incorporating original distance and Jaccard distance becomes important for a robust distance.\n\nTo address the first two shortcomings, the k-reciprocal feature is proposed, by encoding the k-reciprocal nearest neighbor set into a vector\nV p = [V p,g1 , V p,g2 , ..., V p,g N ],\nwhere V p,gi is initially defined by a binary indicator function as\nV p,gi = 1 if g i \u2208 R * (p, k) 0 otherwise.(6)\nIn this way, the k-reciprocal neighbor set can be represented as an N -dimensional vector, with each item of the vector indicating whether the corresponding image is included in R * (p, k). However, this function still consider each neighbor as equal. Intuitively, the neighbor who is closer to the probe p should be more similar with the probe p. Thus, we reassign weights according to the original distance between the probe and its neighbor, we redefine Eq. 6 by the Gaussian kernel of the pairwise distance as\nV p,gi = e \u2212d(p,gi) if g i \u2208 R * (p, k) 0 otherwise.(7)\nIn this way, the hard weighting (0 or 1) is converted into soft weighting, with closer neighbors assigned larger weights while farther neighbors smaller weights. Based on the above definition, the number of candidates in the intersection and union set can be calculated as\n|R * (p, k) \u2229 R * (g i , k)| = min(V p , V gi ) 1 (8) |R * (p, k) \u222a R * (g i , k)| = max(V p , V gi ) 1(9)\nwhere min and max operate the element-based minimization and maximization for two input vectors. \u00b7 1 is L 1 norm. Thus we can rewrite the Jaccard distance in Eq. 5 as\nd J (p, g i ) = 1 \u2212 N j=1 min(V p,gj , V gi,gj ) N j=1 max(V p,gj , V gi,gj )(10)\nBy formula transformation from Eq. 5 to Eq. 10, we have succeed in converting the set comparison problem into pure vector calculation, which is much easier practically.\n\n\nLocal Query Expansion\n\nEmulating the idea that the images from the same class may share similar features, we use the k-nearest neighbors of the probe p to implement the local query expansion. The local query expansion is defined as\nV p = 1 |N (p, k)| gi\u2208N (p,k) V gi(11)\nAs a result, the k-reciprocal feature V p is expanded by the k-nearest neighbors of probe p. Note that, we implement this query expansion both on the probe p and galleries g i . Since there will be noise in the k-nearest neighbors, we limit the size of N (p, k) used in the local query expansion to a smaller value. In order to distinguish between the size of R * (g i , k) and N (p, k) used in Eq. 7 and Eq. 11, we denote the former as k 1 and the latter as k 2 , respectively, where k 1 > k 2 .\n\n\nFinal Distance\n\nIn this subsection, we focus on the third shortcoming of Eq. 5. While most existing re-ranking methods ignore the importance of original distance in re-ranking, we jointly aggregate the original distance and Jaccard distance to revise the initial ranking list, the final distance d * is defined as\nd * (p, g i ) = (1 \u2212 \u03bb)d J (p, g i ) + \u03bbd(p, g i )(12)\nwhere \u03bb \u2208 [0, 1] denotes the penalty factor, it penalizes galleries far away from the probe p. When \u03bb = 0, only the k-reciprocal distance is considered. On the contrary, when \u03bb = 1, only the original distance is considered. The effect of \u03bb is discussed in section 4. Finally, the revised ranking list L * (p, G) can be obtained by ascending sort of the final distance.\n\n\nComplexity Analysis\n\nIn the proposed method, most of the computation costs focus on pairwise distance computing for all gallery pairs. Suppose the size of the gallery set is N , the computation complexity required for the distance measure and the ranking process is O(N 2 ) and O (N 2 logN ), respectively. However, in practical applications, we can calculate the pairwise distance and obtain the ranking lists for the gallery in advance offline. As a result, given a new probe p, we only need to compute the pairwise distance between p and gallery with computation complexity O(N ) and to rank all final distance with computation complexity O(N logN ).\n\n\nExperiments\n\n\nDatasets and Settings\n\nDatasets Because our re-ranking approach is based on the comparison of similar neighbors between two persons, we conducted experiments on four large-scale person reidentification (re-ID) benchmark datasets that contain multiple positive samples for each probe in the gallery : including two image-based datasets, Market-1501 [48], CUHK03 [22] , a video-based dataset MARS [47], and an end-to-end dataset PRW [52] (see Table 1 for an overview).\n\nMarket-1501 [48] is currently the largest image-based re-ID benchmark dataset. It contains 32,668 labeled bounding boxes of 1,501 identities captured from 6 different view points. The bounding boxes are detected using Deformable Part Model (DPM) [8]. The dataset is split into two parts: 12,936 images with 751 identities for training and 19,732 images with 750 identities for testing. In testing, 3,368 hand-drawn images with 750 identities are used as probe set to identify the correct identities on the testing set. We report the single-query evaluation results for this dataset. CUHK03 [22] is another large scale image-based dataset, which contains 13,164 images of 1,360 identities. Each identity is captured from two cameras in the CUHK campus, and has an average of 4.8 images in each camera. The dataset provides both manually labeled bounding boxes and DPM-detected bounding boxes. Since a real-world re-ID system has to rely on a person detector, the latter version of the data is ideal for testing performance given detector errors. In this paper, both experimental results on 'labeled' and 'detected' data are presented. Following the protocol in [22], we split the dataset into a training set consist of 1,160 identities and a testing set consist of 100 identities, and repeat 20 times for evaluation. The average result over all tests is reported.\n\nMARS [47] is the largest video-based re-ID benchmark dataset to date, containing 1,261 identities and around 20,000 video sequences. These sequences are collected from 6 different cameras and each identity has 13.2 sequences on average. Each sequence is automatically obtained by the DPM as pedestrian detector and the GMMCP [6] as tracker. In addition, the dataset also contains 3,248 distractor sequences. The dataset is fixedly split into training and test sets, with 631 and 630 identities, respectively. In testing, 2,009 probes are selected for query.\n\nPRW [52] is an end-to-end large-scale dataset. It is composed of 11,816 frames of 932 identities captured from six different cameras. A total of 43,110 annotated person bounding boxes are generated from these frames. Given a query bounding box, the dataset aims to first perform pedestrian detection on the raw frames to generate the gallery, and identify the correct bounding boxes from the gallery. The dataset is divided into a training set with 5,704 frames of 482 identities and a test set with 6,112 frames of 450 identities. In testing, 2,057 query images for 450 identities are selected for evaluation. A detected bounding box is considered correct if its IoU value with the ground truth is above 0.5.\n\nEvaluation metrics We use two evaluation metrics to evaluate the performance of re-ID methods on all datasets.\n\nThe first one is the Cumulated Matching Characteristics (CMC). Considering re-ID as a ranking problem, we report the cumulated matching accuracy at rank-1. The other one is the mean average precision (mAP) considering re-ID as an object retrieval problem, as described in [48].\n\nFeature representations The Local Maximal Occurrence (LOMO) features are used to represent the person appearance [23]. The LOMO extractor generate a 26,960dimensional feature for each image. This feature is robust to view changes and illumination variations by concatenating the maximal pattern of joint HSV histogram and SILTP descriptor, and is also discriminative, by capturing local region characteristics of a person. In addition, the IDdiscriminative Embedding (IDE) feature proposed in [52] is used. The IDE extractor is effectively trained on classification model including CaffeNet [18] and ResNet-50 [13]. It generates a 1,024-dim (or 2,048-dim) vector for each image, which is effective in large-scale re-ID datasets. For the convenience of description, we abbreviate the IDE trained on CaffeNet and ResNet-50 to IDE (C) and IDE (R) respectively. We use these two methods as the baseline of our re-id framework.\n\n\nExperiments on Market-1501\n\nWe first evaluate our method on the largest image-based re-ID dataset. In this dataset, in addition to using LOMO and IDE features, we also use the BOW [48] feature. We trained the IDE feature on CaffeNet [18] and ResNet-50 [13]. We set k 1 to 20, k 2 to 6, and \u03bb to 0.3. Results among various methods with our method are shown in Table 2. Our method consistently improves the rank-1 accuracy and mAP with all features, even with the IDE (R) which is trained on the powerful ResNet-50 model. Our method gains 3.06% improvement in rank-1 accuracy and significant 13.99% improvement in mAP for IDE (R). Comparing with two popular re-ranking methods, average query expansion (AQE) [5] and contextual dissimilarity measure (CDM) [14], our method outperforms them both in rank-1 accuracy and mAP. Moreover, experiments conducted with two metrics, KISSME [17] and XQDA [23] verify the effectiveness of our method on different distance metrics. Table 3 compares the performance of our best approach, IDE (R) + KISSME + ours, with other state-of-the-art methods. Our best method impressively outperforms the previous work and achieves large margin advances compared with the state-of-the-art results in rank-1 accuracy, particularly in mAP.\n\n\nExperiments on CUHK03\n\nWe evaluate our experiments on two settings, singleshot, and multi-shot. Following the protocol in [22], the single-shot setting randomly selects one image for each identity from each camera. In multi-shot setting, for each  identity, we randomly select the query image from one camera, and use all images in another camera to construct the gallery set. We set k 1 to 7, k 2 to 3, and \u03bb to 0.85 for singleshot, and k 1 to 10, k 2 to 5, and \u03bb to 0.85 for multi-shot, respectively. Results for single-shot are shown in Table 4.\n\nAs we can see that, when using IDE feature, our re-ranking results are almost equivalent to raw results. It is reasonable that our approach does not work. Since there is only one positive for each identity in the gallery, our approach could not obtain sufficient contextual information. Even so, our approach gains nearly 1% improvement for rank-1 accuracy and mAP while applying LOMO feature on both 'labeled' and 'detected' setting, except LOMO + XQDA in 'labeled' setting. Experiments show that, in the case of single-shot, our method does no harm to results, and has the chance to improve the performance. To further demonstrate the effectiveness of our method, we conduct experiments in multishot setting. Results in Table 5 show that, in all cases, our method significantly improves mAP, and also slightly improves rank-1 accuracy. Especially for LOMO + XQDA, our method gains an increase of 2.4% in rank-1 accuracy and 8.7% in mAP on 'labeled' setting.\n\n\nExperiments on MARS\n\nWe also evaluate our method on video-based dataset. On this dataset, we employ two features as the baseline methods, LOMO and IDE. For each sequence, we first extract feature for each image, and use max pooling to combine all features into a fixed-length vector. We set k 1 to 20, k 2 to 6, and \u03bb to 0.3 in this dataset. The performance of our method on different features and metrics are reported in Table 6. As we can see, our re-ranking method consistently improves the rank-1 accuracy and mAP of the two different features. Results compared with average query expansion (AQE) [5] and contextual dissimilarity measure (CDM) [14] show our method outperforms them in both rank-1 accuracy and mAP. Moreover, our method can even improve the rank-1 accuracy and mAP in all cases while discrimina-  [47] 61.72 41.17 IDE (C) + AQE [5] 61.83 47.02 IDE (C) + CDM [14] 62.05 44.23 IDE (C) + Ours 62.78 51.47 IDE (C) + KISSME [47] 65. 25   tive metrics are used. In particular, our method (IDE (R) + XQDA + Ours), based on the IDE (R) + XQDA proposed in [47], improves the rank-1 accuracy from 70.51% to 73.94% and the mAP from 55.12% to 68.45%. Experimental results demonstrate that our re-ranking method is also effective on video-based re-ID problem. We believe that results of this problem will be further improved by combining more sophisticated feature model with our method.\n\n\nExperiments on PRW\n\nWe also evaluate our method on the end-to-end re-ID dataset. This dataset is more challenging than image-based and video-based datasets, since it requires to detect person from a raw image and identify the correct person from the detected galleries. Following [52], we first use DPM to detect candidate bounding boxes of persons on a large raw image, and then query on the detected bounding boxes. We use LOMO and IDE to extract features for each bounding box, and take these two methods as baselines. We set k 1 to 20, k 2 to 6, and \u03bb to 0.3. Experiment results are shown in Table 7. It can be seen that, our method consistently improves the rank-1 accuracy and mAP of both LOMO and IDE feature, demonstrating that our method is effective on end-to-end re-ID task.   \n\n\nParameters Analysis\n\nThe parameters of our method are analyzed in this subsection. The baseline methods are LOMO [23] and IDE [52] trained on CaffeNet. We evaluate the influence of k 1 , k 2 , and \u03bb on rank-1 accuracy and mAP on the Market-1501 dataset. To conduct experimental analyses, we randomly split the original training set into training and validation sets, with 425 and 200 identities respectively. Fig. 4 shows the impact of the size of k-reciprocal neighbors set on rank-1 accuracy and mAP. It can be seen that, our method consistently outperforms the baselines both on the rank-1 accuracy and mAP with various values of k 1 . The mAP first increases with the growth of k 1 , and then begins a slow decline after k 1 surpasses a threshold. Similarly, as k 1 grows, the rank-1 accuracy first rises with fluctuations; and after arriving at the optimal point around k 1 = 20, it starts to drop. With a too large value of k 1 , there will be more false matches included in the k-reciprocal set, resulting in a decline in performance.\n\nThe impact of k 2 are shown in Fig. 5. When k 2 is equal to 1, the local query expansion is not considered. Obviously, the performance grows as k 2 increases in a reasonable range. Notice that, assigning a much too large value to k 2 reduces the performance. Since it may lead to exponentially containing false matches in local query expansion, which undoubtedly harm the feature and thus the performance. As a matter of fact, the local query expansion is very beneficial for further enhancing the performance when setting an appropriate value to k 2 .\n\nThe impact of the parameter \u03bb is shown in Fig. 6. Notice that, when \u03bb is set to 0, we only consider the Jaccard distance as the final distance; in contrast, when \u03bb equal to 1, the Jaccard distance is left out, and the result is exactly the base- line result obtained using pure original distance. It can be observed that when only Jaccard distance is considered, our method consistently outperforms the baseline. This demonstrates that the proposed Jaccard distance is effective for reranking. Moreover, when simultaneously considering both the original distance and the Jaccard distance, the performance obtains a further improvement when the value of \u03bb is around 0.3, demonstrating that the original distance is also important for re-ranking.\n\nIn Fig. 7, four example results are shown. The proposed method, IDE + Ours, effectively ranks more true persons in the top of ranking list which are missed in the ranking list of IDE.\n\n\nConclusion\n\nIn this paper, we address the re-ranking problem in person re-identification (re-ID). We propose a k-reciprocal feature by encoding the k-reciprocal nearest neighbors into a single vector, thus the re-ranking process can be readily performed by vector comparison. To capture the similarity relationships from similar samples, the local expansion query is proposed to obtain a more robust k-reciprocal feature. The final distance based on the combination of the original distance and Jaccard distance produces effective improvement of the re-ID performance on several large-scale datasets. It is worth mentioning that our approach is fully automatic and unsupervised, and can be easily implemented to any ranking result.\n\nFigure 1 .\n1Illustration of the nearest neighborhoods of a person re-identification application. Top: The query and its 10-nearest neighbors, where P1-P4 are positives, N1-N6 are negatives. Bottom: Each two columns shows 10-nearest neighbors of the corresponding person. Blue and green box correspond to the probe and positives, respectively. We can observe that the probe person and positive persons are 10-nearest neighbors reciprocally.\n\nFigure 3 .\n3Example of the k-reciprocal neighbors expansion process. The positive person G which is similar to C is added into R * (Q, 20).\n\nFigure 4 .\n4The impact of the parameter k1 on re-ID performance on the Market-1501 dataset. We fix the k2 at 6 and \u03bb at 0.3.\n\nFigure 5 .\n5The impact of the parameter k2 on re-ID performance on the Market-1501 dataset. We fix the k1 at 20 and \u03bb at 0.3.\n\nFigure 6 .Figure 7 .\n67The impact of the parameter \u03bb on re-ID performance on the Market-1501 dataset. We fix the k1 at 20 and k2 at 6. Example results of four probes on the Market-1501 dataset. For each probe, the first row and the second correspond to the ranking results produced by IDE and IDE + Ours, respectively. Person surrounded by green box denotes the same person as the probe.\n\nTable 1 .\n1The details of datasets used in our experiments.Datasets \n# ID \n# box \n# box/ID \n# cam \nMarket-1501 [48] \n1,501 \n32,643 \n19.9 \n6 \nCUHK03 [22] \n1,360 \n13,164 \n9.7 \n2 \nMARS [47] \n1,261 \n1,067,516 \n13.2 \n6 \nPRW [52] \n932 \n34,304 \n36.8 \n6 \n\n\n\nTable 2 .\n2Comparison among various methods with our re-ranking approach on the Market-1501 dataset.Method \nRank 1 \nmAP \n\nBOW \n35.84 \n14.75 \nBOW + Ours \n39.85 \n19.90 \nBOW + KISSME \n42.90 \n19.41 \nBOW + KISSME + Ours \n44.77 \n25.64 \nBOW + XQDA \n41.39 \n19.72 \nBOW + XQDA + Ours \n42.61 \n24.98 \nLOMO + KISSME \n41.12 \n19.02 \nLOMO + KISSME + Ours \n45.22 \n28.44 \nLOMO + XQDA \n43.56 \n22.44 \nLOMO + XQDA + Ours \n48.34 \n32.21 \nIDE (C) \n55.87 \n31.34 \nIDE (C) + AQE [5] \n57.69 \n35.25 \nIDE (C) + CDM [14] \n58.02 \n34.54 \nIDE (C) + Ours \n58.79 \n42.06 \nIDE (C) + XQDA \n57.72 \n35.95 \nIDE (C) + XQDA + Ours \n61.25 \n46.79 \nIDE (C) + KISSME \n58.61 \n35.40 \nIDE (C) + KISSME + Ours \n61.82 \n46.81 \nIDE (R) \n72.54 \n46.00 \nIDE (R) + AQE [5] \n73.20 \n50.14 \nIDE (R) + CDM [14] \n73.66 \n49.53 \nIDE (R) + Ours \n74.85 \n59.87 \nIDE (R) + XQDA \n71.41 \n48.89 \nIDE (R) + XQDA + Ours \n75.14 \n61.87 \nIDE (R) + KISSME \n73.60 \n49.05 \nIDE (R) + KISSME + Ours \n77.11 \n63.63 \n\n\n\nTable 3 .\n3Comparison of our method with state-of-the-art on the Market-1501 dataset.Method \nRank 1 \nmAP \n\nSDALF [7] \n20.53 \n8.20 \neSDC [46] \n33.54 \n13.54 \nBOW [48] \n34.40 \n14.09 \nPersonNet [40] \n37.21 \n18.57 \ndCNN [36] \n39.40 \n19.60 \nLOMO + XQDA [23] \n43.79 \n22.22 \nMSTCNN [26] \n45.10 \n-\nWARCA [15] \n45.16 \n-\nMBCNN [37] \n45.58 \n26.11 \nHistLBP+kLFDA [16] \n46.50 \n-\nTMA [30] \n47.92 \n22.31 \nDLDA [39] \n48.15 \n29.94 \nCAN [25] \n48.24 \n24.43 \nSCSP [4] \n51.90 \n26.35 \nDNS [45] \n61.02 \n35.68 \nGated [38] \n65.88 \n39.55 \nIDE (R) + KISSME + Ours \n77.11 \n63.63 \n\n\n\nTable 4 .\n4Comparison among various methods with our re-ranking approach on the CUHK03 dataset in single-shot setting.Method \nLabeled \nDetected \nRank 1 \nmAP \nRank 1 \nmAP \n\nLOMO + XQDA [23] \n49.7 \n56.4 \n44.6 \n51.5 \nLOMO + XQDA + Ours \n50.0 \n56.8 \n45.9 \n52.6 \nIDE (C) [52] \n57.0 \n63.1 \n54.1 \n60.4 \nIDE (C) + Ours \n57.2 \n63.2 \n54.2 \n60.5 \nIDE (C) + XQDA [52] \n61.7 \n67.6 \n58.9 \n64.9 \nIDE (C) + XQDA + Ours \n61.6 \n67.6 \n58.5 \n64.7 \n\nTable 5. Comparison among various methods with our re-ranking \napproach on the CUHK03 dataset in multi-shot setting. \n\nMethod \nLabeled \nDetected \nRank \n1 \n\nmAP \nRank \n1 \n\nmAP \n\nLOMO + XQ. [23] \n57.4 \n50.7 \n52.0 \n45.1 \nLOMO + XQDA + Ours \n59.8 \n58.0 \n52.9 \n51.9 \nIDE (C) [52] \n64.7 \n59.0 \n60.8 \n55.5 \nIDE (C) + Ours \n64.9 \n63.2 \n61.5 \n59.7 \nIDE (C) + XQDA [52] \n68.6 \n63.8 \n64.4 \n60.3 \nIDE (C) + XQDA + Ours \n69.1 \n68.4 \n64.6 \n64.5 \nIDE (R) + XQDA [52] \n69.80 \n66.16 \n69.62 \n65.75 \nIDE (R) + XQDA + Ours \n69.90 \n70.89 \n69.67 \n72.45 \n\n\n\nTable 6 .\n6Comparison among various methods with our re-ranking approach on the MARS dataset.Method \nRank 1 \nmAP \n\nLOMO + KISSME [17] \n30.86 \n15.36 \nLOMO + KISSME + Ours \n31.31 \n22.38 \nLOMO + XQDA [23] \n31.82 \n17.00 \nLOMO + XQDA + Ours \n33.99 \n23.20 \nIDE (C) \n\nTable 7 .\n7Comparison among various methods with our re-ranking approach on the PRW dataset.Method \nRank 1 \nmAP \n\nLOMO + XQDA [23] \n34.9 \n13.4 \nLOMO + XQDA + Ours \n37.1 \n19.2 \nIDE (C) \n51.03 \n25.09 \nIDE (C) + Ours \n52.54 \n31.51 \n\n\n\nThree things everyone should know to improve object retrieval. R Arandjelovi\u0107, A Zisserman, CVPR. R. Arandjelovi\u0107 and A. Zisserman. Three things everyone should know to improve object retrieval. In CVPR, 2012. 2\n\nSparse contextual activation for efficient visual re-ranking. S Bai, X Bai, IEEE TIP. 23S. Bai and X. Bai. Sparse contextual activation for efficient visual re-ranking. IEEE TIP, 2016. 2, 3\n\nA survey of approaches and trends in person re-identification. Image and Vision Computing. A Bedagkar-Gala, S K Shah, 1A. Bedagkar-Gala and S. K. Shah. A survey of approaches and trends in person re-identification. Image and Vision Computing, 2014. 1, 2\n\nSimilarity learning with spatial constraints for person re-identification. D Chen, Z Yuan, B Chen, N Zheng, CVPR. D. Chen, Z. Yuan, B. Chen, and N. Zheng. Similarity learn- ing with spatial constraints for person re-identification. In CVPR, 2016. 6\n\nTotal recall: Automatic query expansion with a generative feature model for object retrieval. O Chum, J Philbin, J Sivic, M Isard, A Zisserman, ICCV. 7O. Chum, J. Philbin, J. Sivic, M. Isard, and A. Zisserman. Total recall: Automatic query expansion with a generative feature model for object retrieval. In ICCV, 2007. 1, 2, 6, 7\n\nGmmcp tracker: Globally optimal generalized maximum multi clique problem for multiple object tracking. A Dehghan, S Modiri Assari, M Shah, CVPR. A. Dehghan, S. Modiri Assari, and M. Shah. Gmmcp tracker: Globally optimal generalized maximum multi clique prob- lem for multiple object tracking. In CVPR, 2015. 5\n\nPerson re-identification by symmetry-driven accumulation of local features. M Farenzena, L Bazzani, A Perina, V Murino, M Cristani, CVPR. M. Farenzena, L. Bazzani, A. Perina, V. Murino, and M. Cristani. Person re-identification by symmetry-driven ac- cumulation of local features. In CVPR, 2010. 6\n\nObject detection with discriminatively trained partbased models. P F Felzenszwalb, R B Girshick, D Mcallester, D Ramanan, IEEE TPAMI. 5P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ra- manan. Object detection with discriminatively trained part- based models. IEEE TPAMI, 2010. 5\n\nModeling feature distances by orientation driven classifiers for person re-identification. J Garc\u00eda, N Martinel, A Gardel, I Bravo, G L Foresti, C Micheloni, Elsevier VCIPJ. Garc\u00eda, N. Martinel, A. Gardel, I. Bravo, G. L. Foresti, and C. Micheloni. Modeling feature distances by orientation driven classifiers for person re-identification. Elsevier VCIP, 2016. 3\n\nDiscriminant context information analysis for post-ranking person re-identification. J Garcia, N Martinel, A Gardel, I Bravo, G L Foresti, C Micheloni, IEEEJ. Garcia, N. Martinel, A. Gardel, I. Bravo, G. L. Foresti, and C. Micheloni. Discriminant context information analysis for post-ranking person re-identification. IEEE TIP, 2017. 3\n\nPerson re-identification ranking optimisation by discriminant context information analysis. J Garcia, N Martinel, C Micheloni, A Gardel, ICCV. J. Garcia, N. Martinel, C. Micheloni, and A. Gardel. Person re-identification ranking optimisation by discriminant con- text information analysis. In ICCV, 2015. 3\n\nViewpoint invariant pedestrian recognition with an ensemble of localized features. D Gray, H Tao, ECCV. D. Gray and H. Tao. Viewpoint invariant pedestrian recogni- tion with an ensemble of localized features. In ECCV, 2008. 3\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, CVPR. K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016. 6\n\nA contextual dissimilarity measure for accurate and efficient image search. H Jegou, H Harzallah, C Schmid, CVPR. H. Jegou, H. Harzallah, and C. Schmid. A contextual dis- similarity measure for accurate and efficient image search. In CVPR, 2007. 1, 2, 3, 6, 7\n\nScalable metric learning via weighted approximate rank component analysis. C Jose, F Fleuret, ECCV. C. Jose and F. Fleuret. Scalable metric learning via weighted approximate rank component analysis. In ECCV, 2016. 6\n\nA comprehensive evaluation and benchmark for person re-identification: Features, metrics, and datasets. S Karanam, M Gou, Z Wu, A Rates-Borras, O Camps, R J Radke, arXiv:1605.09653arXiv preprintS. Karanam, M. Gou, Z. Wu, A. Rates-Borras, O. Camps, and R. J. Radke. A comprehensive evaluation and benchmark for person re-identification: Features, metrics, and datasets. arXiv preprint arXiv:1605.09653, 2016. 6\n\nLarge scale metric learning from equivalence constraints. M K\u00f6stinger, M Hirzer, P Wohlhart, P M Roth, H Bischof, CVPR. 67M. K\u00f6stinger, M. Hirzer, P. Wohlhart, P. M. Roth, and H. Bischof. Large scale metric learning from equivalence constraints. In CVPR, 2012. 3, 6, 7\n\nImagenet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, NIPS. A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012. 6\n\nPerson reidentification with content and context re-ranking. Q Leng, R Hu, C Liang, Y Wang, J Chen, Springer MTAPQ. Leng, R. Hu, C. Liang, Y. Wang, and J. Chen. Person re- identification with content and context re-ranking. Springer MTAP, 2015. 3\n\nCommon-nearneighbor analysis for person re-identification. W Li, Y Wu, M Mukunoki, M Minoh, ICIP. W. Li, Y. Wu, M. Mukunoki, and M. Minoh. Common-near- neighbor analysis for person re-identification. In ICIP, 2012. 3\n\nDeepreid: Deep filter pairing neural network for person re-identification. W Li, R Zhao, T Xiao, X Wang, CVPR. W. Li, R. Zhao, T. Xiao, and X. Wang. Deepreid: Deep filter pairing neural network for person re-identification. In CVPR, 2014. 3\n\nDeepreid: Deep filter pairing neural network for person re-identification. W Li, R Zhao, T Xiao, X Wang, CVPR. 56W. Li, R. Zhao, T. Xiao, and X. Wang. Deepreid: Deep filter pairing neural network for person re-identification. In CVPR, 2014. 5, 6\n\nPerson re-identification by local maximal occurrence representation and metric learning. S Liao, Y Hu, X Zhu, S Z Li, CVPR. 7S. Liao, Y. Hu, X. Zhu, and S. Z. Li. Person re-identification by local maximal occurrence representation and metric learning. In CVPR, 2015. 1, 3, 6, 7, 8\n\nPop: Person re-identification post-rank optimisation. C Liu, C Loy, S Gong, G Wang, ICCV. C. Liu, C. Change Loy, S. Gong, and G. Wang. Pop: Person re-identification post-rank optimisation. In ICCV, 2013. 3\n\nEnd-to-end comparative attention networks for person re-identification. H Liu, J Feng, M Qi, J Jiang, S Yan, arXiv:1606.04404arXiv preprintH. Liu, J. Feng, M. Qi, J. Jiang, and S. Yan. End-to-end comparative attention networks for person re-identification. arXiv preprint arXiv:1606.04404, 2016. 6\n\nMulti-scale triplet cnn for person re-identification. J Liu, Z.-J Zha, Q Tian, D Liu, T Yao, Q Ling, T Mei, ACM MM. J. Liu, Z.-J. Zha, Q. Tian, D. Liu, T. Yao, Q. Ling, and T. Mei. Multi-scale triplet cnn for person re-identification. In ACM MM, 2016. 6\n\nCross-domain person reidentification using domain adaptation ranking svms. A J Ma, J Li, P C Yuen, P Li, IEEE TIP. 1A. J. Ma, J. Li, P. C. Yuen, and P. Li. Cross-domain person reidentification using domain adaptation ranking svms. IEEE TIP, 2015. 1\n\nQuery based adaptive re-ranking for person re-identification. A J Ma, P Li, ACCV. A. J. Ma and P. Li. Query based adaptive re-ranking for per- son re-identification. In ACCV, 2014. 3\n\nDomain transfer support vector ranking for person re-identification without target camera label information. A J Ma, P C Yuen, J Li, ICCV. A. J. Ma, P. C. Yuen, and J. Li. Domain transfer support vec- tor ranking for person re-identification without target camera label information. In ICCV, 2013. 1\n\nTemporal model adaptation for person reidentification. N Martinel, A Das, C Micheloni, A K Roy-Chowdhury, ECCV. N. Martinel, A. Das, C. Micheloni, and A. K. Roy- Chowdhury. Temporal model adaptation for person re- identification. In ECCV, 2016. 6\n\nPerson reidentification in a distributed camera network framework. N Martinel, G L Foresti, C Micheloni, IEEE transactions on cybernetics. 1N. Martinel, G. L. Foresti, and C. Micheloni. Person reiden- tification in a distributed camera network framework. IEEE transactions on cybernetics, 2016. 1\n\nKernelized saliency-based person re-identification through multiple metric learning. N Martinel, C Micheloni, G L Foresti, IEEE TIP. 3N. Martinel, C. Micheloni, and G. L. Foresti. Kernel- ized saliency-based person re-identification through multiple metric learning. IEEE TIP, 2015. 3\n\nRe-ranking for person reidentification. V.-H Nguyen, T D Ngo, K M Nguyen, D A Duong, K Nguyen, D.-D Le, SoCPaR. IEEEV.-H. Nguyen, T. D. Ngo, K. M. Nguyen, D. A. Duong, K. Nguyen, and D.-D. Le. Re-ranking for person re- identification. In SoCPaR. IEEE, 2013. 3\n\nHello neighbor: Accurate object retrieval with k-reciprocal nearest neighbors. D Qin, S Gammeter, L Bossard, T Quack, L Van Gool, CVPR. 3D. Qin, S. Gammeter, L. Bossard, T. Quack, and L. Van Gool. Hello neighbor: Accurate object retrieval with k-reciprocal nearest neighbors. In CVPR, 2011. 1, 2, 3\n\nObject retrieval and localization with spatially-constrained similarity measure and k-nn re-ranking. X Shen, Z Lin, J Brandt, S Avidan, Y Wu, CVPR. 1X. Shen, Z. Lin, J. Brandt, S. Avidan, and Y. Wu. Object re- trieval and localization with spatially-constrained similarity measure and k-nn re-ranking. In CVPR, 2012. 1, 2\n\nDeep attributes driven multi-camera person re-identification. C Su, S Zhang, J Xing, W Gao, Q Tian, ECCV. C. Su, S. Zhang, J. Xing, W. Gao, and Q. Tian. Deep attributes driven multi-camera person re-identification. In ECCV, 2016. 6\n\nMultiregion bilinear convolutional neural networks for person reidentification. E Ustinova, Y Ganin, V Lempitsky, arXiv:1512.05300arXiv preprintE. Ustinova, Y. Ganin, and V. Lempitsky. Multire- gion bilinear convolutional neural networks for person re- identification. arXiv preprint arXiv:1512.05300, 2015. 6\n\nGated siamese convolutional neural network architecture for human reidentification. R R Varior, M Haloi, G Wang, ECCV. R. R. Varior, M. Haloi, and G. Wang. Gated siamese convolutional neural network architecture for human re- identification. In ECCV, 2016. 6\n\nDeep linear discriminant analysis on fisher networks: A hybrid architecture for person re-identification. L Wu, C Shen, A V D Hengel, arXiv:1606.01595arXiv preprintL. Wu, C. Shen, and A. v. d. Hengel. Deep linear discrim- inant analysis on fisher networks: A hybrid architecture for person re-identification. arXiv preprint arXiv:1606.01595, 2016. 6\n\nL Wu, C Shen, A V D Hengel, arXiv:1601.07255Personnet: Person re-identification with deep convolutional neural networks. arXiv preprintL. Wu, C. Shen, and A. v. d. Hengel. Personnet: Person re-identification with deep convolutional neural networks. arXiv preprint arXiv:1601.07255, 2016. 6\n\nSalient color names for person re-identification. Y Yang, J Yang, J Yan, S Liao, D Yi, S Z Li, ECCV. Y. Yang, J. Yang, J. Yan, S. Liao, D. Yi, and S. Z. Li. Salient color names for person re-identification. In ECCV, 2014. 3\n\nCoupled-view based ranking optimization for person reidentification. M Ye, J Chen, Q Leng, C Liang, Z Wang, K Sun, MMM. SpringerM. Ye, J. Chen, Q. Leng, C. Liang, Z. Wang, and K. Sun. Coupled-view based ranking optimization for person re- identification. In MMM. Springer, 2015. 3\n\nRanking optimization for person re-identification via similarity and dissimilarity. M Ye, C Liang, Z Wang, Q Leng, J Chen, ACM MM. M. Ye, C. Liang, Z. Wang, Q. Leng, and J. Chen. Ranking optimization for person re-identification via similarity and dissimilarity. In ACM MM, 2015. 1\n\nPerson re-identification via ranking aggregation of similarity pulling and dissimilarity pushing. M Ye, C Liang, Y Yu, Z Wang, Q Leng, C Xiao, J Chen, R Hu, IEEE TMM. 13M. Ye, C. Liang, Y. Yu, Z. Wang, Q. Leng, C. Xiao, J. Chen, and R. Hu. Person re-identification via ranking aggregation of similarity pulling and dissimilarity pushing. IEEE TMM, 2016. 1, 3\n\nLearning a discriminative null space for person re-identification. L Zhang, T Xiang, S Gong, CVPR. 36L. Zhang, T. Xiang, and S. Gong. Learning a discriminative null space for person re-identification. In CVPR, 2016. 3, 6\n\nUnsupervised salience learning for person re-identification. R Zhao, W Ouyang, X Wang, CVPR. R. Zhao, W. Ouyang, and X. Wang. Unsupervised salience learning for person re-identification. In CVPR, 2013. 6\n\nMars: A video benchmark for large-scale person re-identification. L Zheng, Z Bie, Y Sun, J Wang, C Su, S Wang, Q Tian, ECCV. 57L. Zheng, Z. Bie, Y. Sun, J. Wang, C. Su, S. Wang, and Q. Tian. Mars: A video benchmark for large-scale person re-identification. In ECCV, 2016. 5, 7\n\nScalable person re-identification: A benchmark. L Zheng, L Shen, L Tian, S Wang, J Wang, Q Tian, ICCV. 36L. Zheng, L. Shen, L. Tian, S. Wang, J. Wang, and Q. Tian. Scalable person re-identification: A benchmark. In ICCV, 2015. 3, 5, 6\n\nQuery-adaptive late fusion for image search and person reidentification. L Zheng, S Wang, L Tian, F He, Z Liu, Q Tian, CVPR. L. Zheng, S. Wang, L. Tian, F. He, Z. Liu, and Q. Tian. Query-adaptive late fusion for image search and person re- identification. In CVPR, 2015. 3\n\nPerson reidentification: Past, present and future. L Zheng, Y Yang, A G Hauptmann, arXiv:1610.029841arXiv preprintL. Zheng, Y. Yang, and A. G. Hauptmann. Person re- identification: Past, present and future. arXiv preprint arXiv:1610.02984, 2016. 1, 2\n\nSift meets cnn: a decade survey of instance retrieval. L Zheng, Y Yang, Q Tian, arXiv:1608.01807arXiv preprintL. Zheng, Y. Yang, and Q. Tian. Sift meets cnn: a decade sur- vey of instance retrieval. arXiv preprint arXiv:1608.01807, 2016. 2\n\nL Zheng, H Zhang, S Sun, M Chandraker, Q Tian, arXiv:1604.02531Person re-identification in the wild. 7arXiv preprintL. Zheng, H. Zhang, S. Sun, M. Chandraker, and Q. Tian. Person re-identification in the wild. arXiv preprint arXiv:1604.02531, 2016. 5, 6, 7, 8\n", "annotations": {"author": "[{\"end\":154,\"start\":66},{\"end\":244,\"start\":155},{\"end\":311,\"start\":245},{\"end\":376,\"start\":312}]", "publisher": null, "author_last_name": "[{\"end\":76,\"start\":71},{\"end\":166,\"start\":161},{\"end\":256,\"start\":253},{\"end\":321,\"start\":319}]", "author_first_name": "[{\"end\":70,\"start\":66},{\"end\":160,\"start\":155},{\"end\":252,\"start\":245},{\"end\":318,\"start\":312}]", "author_affiliation": "[{\"end\":153,\"start\":101},{\"end\":243,\"start\":191},{\"end\":310,\"start\":258},{\"end\":375,\"start\":323}]", "title": "[{\"end\":63,\"start\":1},{\"end\":439,\"start\":377}]", "venue": null, "abstract": "[{\"end\":1501,\"start\":441}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b49\"},\"end\":1554,\"start\":1550},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1556,\"start\":1554},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1559,\"start\":1556},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":1562,\"start\":1559},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":1565,\"start\":1562},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":1568,\"start\":1565},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2079,\"start\":2076},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2082,\"start\":2079},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":2085,\"start\":2082},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":2088,\"start\":2085},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2519,\"start\":2516},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2522,\"start\":2519},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":2525,\"start\":2522},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":2528,\"start\":2525},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":2531,\"start\":2528},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":2533,\"start\":2531},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3261,\"start\":3257},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3264,\"start\":3261},{\"end\":3686,\"start\":3678},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5670,\"start\":5667},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":5673,\"start\":5670},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":5965,\"start\":5961},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6103,\"start\":6100},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6396,\"start\":6393},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":6597,\"start\":6593},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6860,\"start\":6857},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7106,\"start\":7102},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":7109,\"start\":7106},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7118,\"start\":7114},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":7299,\"start\":7295},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7655,\"start\":7651},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":7744,\"start\":7740},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7964,\"start\":7960},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7967,\"start\":7964},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7970,\"start\":7967},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7973,\"start\":7970},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7976,\"start\":7973},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8000,\"start\":7996},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8003,\"start\":8000},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8005,\"start\":8003},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8008,\"start\":8005},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":8011,\"start\":8008},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8047,\"start\":8043},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8050,\"start\":8047},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8053,\"start\":8050},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8056,\"start\":8053},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":8059,\"start\":8056},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8062,\"start\":8059},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8065,\"start\":8062},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8068,\"start\":8065},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8071,\"start\":8068},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":8074,\"start\":8071},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8160,\"start\":8156},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8298,\"start\":8294},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8519,\"start\":8515},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8790,\"start\":8786},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":8793,\"start\":8790},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8809,\"start\":8805},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":9002,\"start\":8998},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10507,\"start\":10503},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11682,\"start\":11678},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12063,\"start\":12059},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12452,\"start\":12449},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":18510,\"start\":18506},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":18523,\"start\":18519},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":18557,\"start\":18553},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":18593,\"start\":18589},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":18642,\"start\":18638},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":18875,\"start\":18872},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":19220,\"start\":19216},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":19790,\"start\":19786},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":19999,\"start\":19995},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":20318,\"start\":20315},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":20557,\"start\":20553},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":21648,\"start\":21644},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":21768,\"start\":21764},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":22148,\"start\":22144},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22246,\"start\":22242},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22265,\"start\":22261},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":22760,\"start\":22756},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22813,\"start\":22809},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22832,\"start\":22828},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23285,\"start\":23282},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":23333,\"start\":23329},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":23457,\"start\":23453},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":23471,\"start\":23467},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23965,\"start\":23961},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25955,\"start\":25952},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":26003,\"start\":25999},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":26172,\"start\":26168},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":26202,\"start\":26199},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":26233,\"start\":26229},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":26294,\"start\":26290},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":26301,\"start\":26299},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":26422,\"start\":26418},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":27032,\"start\":27028},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":27656,\"start\":27652},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":27669,\"start\":27665}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":31240,\"start\":30800},{\"attributes\":{\"id\":\"fig_1\"},\"end\":31381,\"start\":31241},{\"attributes\":{\"id\":\"fig_3\"},\"end\":31507,\"start\":31382},{\"attributes\":{\"id\":\"fig_4\"},\"end\":31634,\"start\":31508},{\"attributes\":{\"id\":\"fig_5\"},\"end\":32023,\"start\":31635},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":32273,\"start\":32024},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":33207,\"start\":32274},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33761,\"start\":33208},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":34725,\"start\":33762},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":34986,\"start\":34726},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":35218,\"start\":34987}]", "paragraph": "[{\"end\":2009,\"start\":1517},{\"end\":2269,\"start\":2011},{\"end\":3171,\"start\":2271},{\"end\":4098,\"start\":3208},{\"end\":4274,\"start\":4100},{\"end\":5051,\"start\":4276},{\"end\":5214,\"start\":5053},{\"end\":5380,\"start\":5216},{\"end\":5615,\"start\":5382},{\"end\":5839,\"start\":5632},{\"end\":7851,\"start\":5841},{\"end\":9703,\"start\":7853},{\"end\":9924,\"start\":9746},{\"end\":10106,\"start\":9970},{\"end\":10458,\"start\":10108},{\"end\":10613,\"start\":10493},{\"end\":10790,\"start\":10674},{\"end\":11367,\"start\":10843},{\"end\":12255,\"start\":11464},{\"end\":12453,\"start\":12276},{\"end\":12509,\"start\":12501},{\"end\":12864,\"start\":12527},{\"end\":13190,\"start\":12946},{\"end\":13613,\"start\":13192},{\"end\":13962,\"start\":13615},{\"end\":14309,\"start\":13964},{\"end\":14451,\"start\":14311},{\"end\":14560,\"start\":14493},{\"end\":15121,\"start\":14608},{\"end\":15450,\"start\":15178},{\"end\":15724,\"start\":15558},{\"end\":15975,\"start\":15807},{\"end\":16209,\"start\":16001},{\"end\":16745,\"start\":16249},{\"end\":17061,\"start\":16764},{\"end\":17485,\"start\":17117},{\"end\":18141,\"start\":17509},{\"end\":18624,\"start\":18181},{\"end\":19988,\"start\":18626},{\"end\":20547,\"start\":19990},{\"end\":21258,\"start\":20549},{\"end\":21370,\"start\":21260},{\"end\":21649,\"start\":21372},{\"end\":22573,\"start\":21651},{\"end\":23836,\"start\":22604},{\"end\":24387,\"start\":23862},{\"end\":25348,\"start\":24389},{\"end\":26745,\"start\":25372},{\"end\":27536,\"start\":26768},{\"end\":28580,\"start\":27560},{\"end\":29134,\"start\":28582},{\"end\":29880,\"start\":29136},{\"end\":30065,\"start\":29882},{\"end\":30799,\"start\":30080}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":3207,\"start\":3172},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9969,\"start\":9925},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10673,\"start\":10614},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10842,\"start\":10791},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11463,\"start\":11368},{\"attributes\":{\"id\":\"formula_5\"},\"end\":12500,\"start\":12454},{\"attributes\":{\"id\":\"formula_6\"},\"end\":12526,\"start\":12510},{\"attributes\":{\"id\":\"formula_7\"},\"end\":12945,\"start\":12865},{\"attributes\":{\"id\":\"formula_8\"},\"end\":14492,\"start\":14452},{\"attributes\":{\"id\":\"formula_9\"},\"end\":14607,\"start\":14561},{\"attributes\":{\"id\":\"formula_10\"},\"end\":15177,\"start\":15122},{\"attributes\":{\"id\":\"formula_11\"},\"end\":15557,\"start\":15451},{\"attributes\":{\"id\":\"formula_12\"},\"end\":15806,\"start\":15725},{\"attributes\":{\"id\":\"formula_13\"},\"end\":16248,\"start\":16210},{\"attributes\":{\"id\":\"formula_14\"},\"end\":17116,\"start\":17062}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":18606,\"start\":18599},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23549,\"start\":23542},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":24386,\"start\":24379},{\"end\":25118,\"start\":25111},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":27351,\"start\":27344}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1515,\"start\":1503},{\"attributes\":{\"n\":\"2.\"},\"end\":5630,\"start\":5618},{\"attributes\":{\"n\":\"3.\"},\"end\":9723,\"start\":9706},{\"attributes\":{\"n\":\"3.1.\"},\"end\":9744,\"start\":9726},{\"attributes\":{\"n\":\"3.2.\"},\"end\":10491,\"start\":10461},{\"attributes\":{\"n\":\"3.3.\"},\"end\":12274,\"start\":12258},{\"attributes\":{\"n\":\"3.4.\"},\"end\":15999,\"start\":15978},{\"attributes\":{\"n\":\"3.5.\"},\"end\":16762,\"start\":16748},{\"attributes\":{\"n\":\"3.6.\"},\"end\":17507,\"start\":17488},{\"attributes\":{\"n\":\"4.\"},\"end\":18155,\"start\":18144},{\"attributes\":{\"n\":\"4.1.\"},\"end\":18179,\"start\":18158},{\"attributes\":{\"n\":\"4.2.\"},\"end\":22602,\"start\":22576},{\"attributes\":{\"n\":\"4.3.\"},\"end\":23860,\"start\":23839},{\"attributes\":{\"n\":\"4.4.\"},\"end\":25370,\"start\":25351},{\"attributes\":{\"n\":\"4.5.\"},\"end\":26766,\"start\":26748},{\"attributes\":{\"n\":\"4.6.\"},\"end\":27558,\"start\":27539},{\"attributes\":{\"n\":\"5.\"},\"end\":30078,\"start\":30068},{\"end\":30811,\"start\":30801},{\"end\":31252,\"start\":31242},{\"end\":31393,\"start\":31383},{\"end\":31519,\"start\":31509},{\"end\":31656,\"start\":31636},{\"end\":32034,\"start\":32025},{\"end\":32284,\"start\":32275},{\"end\":33218,\"start\":33209},{\"end\":33772,\"start\":33763},{\"end\":34736,\"start\":34727},{\"end\":34997,\"start\":34988}]", "table": "[{\"end\":32273,\"start\":32084},{\"end\":33207,\"start\":32375},{\"end\":33761,\"start\":33294},{\"end\":34725,\"start\":33881},{\"end\":34986,\"start\":34820},{\"end\":35218,\"start\":35080}]", "figure_caption": "[{\"end\":31240,\"start\":30813},{\"end\":31381,\"start\":31254},{\"end\":31507,\"start\":31395},{\"end\":31634,\"start\":31521},{\"end\":32023,\"start\":31659},{\"end\":32084,\"start\":32036},{\"end\":32375,\"start\":32286},{\"end\":33294,\"start\":33220},{\"end\":33881,\"start\":33774},{\"end\":34820,\"start\":34738},{\"end\":35080,\"start\":34999}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2874,\"start\":2868},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3634,\"start\":3628},{\"end\":4999,\"start\":4993},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11693,\"start\":11687},{\"end\":17779,\"start\":17768},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":27954,\"start\":27948},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":28619,\"start\":28613},{\"end\":29184,\"start\":29178},{\"end\":29891,\"start\":29885}]", "bib_author_first_name": "[{\"end\":35284,\"start\":35283},{\"end\":35300,\"start\":35299},{\"end\":35496,\"start\":35495},{\"end\":35503,\"start\":35502},{\"end\":35716,\"start\":35715},{\"end\":35733,\"start\":35732},{\"end\":35735,\"start\":35734},{\"end\":35955,\"start\":35954},{\"end\":35963,\"start\":35962},{\"end\":35971,\"start\":35970},{\"end\":35979,\"start\":35978},{\"end\":36224,\"start\":36223},{\"end\":36232,\"start\":36231},{\"end\":36243,\"start\":36242},{\"end\":36252,\"start\":36251},{\"end\":36261,\"start\":36260},{\"end\":36564,\"start\":36563},{\"end\":36575,\"start\":36574},{\"end\":36582,\"start\":36576},{\"end\":36592,\"start\":36591},{\"end\":36848,\"start\":36847},{\"end\":36861,\"start\":36860},{\"end\":36872,\"start\":36871},{\"end\":36882,\"start\":36881},{\"end\":36892,\"start\":36891},{\"end\":37136,\"start\":37135},{\"end\":37138,\"start\":37137},{\"end\":37154,\"start\":37153},{\"end\":37156,\"start\":37155},{\"end\":37168,\"start\":37167},{\"end\":37182,\"start\":37181},{\"end\":37454,\"start\":37453},{\"end\":37464,\"start\":37463},{\"end\":37476,\"start\":37475},{\"end\":37486,\"start\":37485},{\"end\":37495,\"start\":37494},{\"end\":37497,\"start\":37496},{\"end\":37508,\"start\":37507},{\"end\":37812,\"start\":37811},{\"end\":37822,\"start\":37821},{\"end\":37834,\"start\":37833},{\"end\":37844,\"start\":37843},{\"end\":37853,\"start\":37852},{\"end\":37855,\"start\":37854},{\"end\":37866,\"start\":37865},{\"end\":38157,\"start\":38156},{\"end\":38167,\"start\":38166},{\"end\":38179,\"start\":38178},{\"end\":38192,\"start\":38191},{\"end\":38456,\"start\":38455},{\"end\":38464,\"start\":38463},{\"end\":38646,\"start\":38645},{\"end\":38652,\"start\":38651},{\"end\":38661,\"start\":38660},{\"end\":38668,\"start\":38667},{\"end\":38858,\"start\":38857},{\"end\":38867,\"start\":38866},{\"end\":38880,\"start\":38879},{\"end\":39118,\"start\":39117},{\"end\":39126,\"start\":39125},{\"end\":39364,\"start\":39363},{\"end\":39375,\"start\":39374},{\"end\":39382,\"start\":39381},{\"end\":39388,\"start\":39387},{\"end\":39404,\"start\":39403},{\"end\":39413,\"start\":39412},{\"end\":39415,\"start\":39414},{\"end\":39729,\"start\":39728},{\"end\":39742,\"start\":39741},{\"end\":39752,\"start\":39751},{\"end\":39764,\"start\":39763},{\"end\":39766,\"start\":39765},{\"end\":39774,\"start\":39773},{\"end\":40006,\"start\":40005},{\"end\":40020,\"start\":40019},{\"end\":40033,\"start\":40032},{\"end\":40035,\"start\":40034},{\"end\":40242,\"start\":40241},{\"end\":40250,\"start\":40249},{\"end\":40256,\"start\":40255},{\"end\":40265,\"start\":40264},{\"end\":40273,\"start\":40272},{\"end\":40488,\"start\":40487},{\"end\":40494,\"start\":40493},{\"end\":40500,\"start\":40499},{\"end\":40512,\"start\":40511},{\"end\":40722,\"start\":40721},{\"end\":40728,\"start\":40727},{\"end\":40736,\"start\":40735},{\"end\":40744,\"start\":40743},{\"end\":40964,\"start\":40963},{\"end\":40970,\"start\":40969},{\"end\":40978,\"start\":40977},{\"end\":40986,\"start\":40985},{\"end\":41225,\"start\":41224},{\"end\":41233,\"start\":41232},{\"end\":41239,\"start\":41238},{\"end\":41246,\"start\":41245},{\"end\":41248,\"start\":41247},{\"end\":41472,\"start\":41471},{\"end\":41479,\"start\":41478},{\"end\":41486,\"start\":41485},{\"end\":41494,\"start\":41493},{\"end\":41697,\"start\":41696},{\"end\":41704,\"start\":41703},{\"end\":41712,\"start\":41711},{\"end\":41718,\"start\":41717},{\"end\":41727,\"start\":41726},{\"end\":41978,\"start\":41977},{\"end\":41988,\"start\":41984},{\"end\":41995,\"start\":41994},{\"end\":42003,\"start\":42002},{\"end\":42010,\"start\":42009},{\"end\":42017,\"start\":42016},{\"end\":42025,\"start\":42024},{\"end\":42254,\"start\":42253},{\"end\":42256,\"start\":42255},{\"end\":42262,\"start\":42261},{\"end\":42268,\"start\":42267},{\"end\":42270,\"start\":42269},{\"end\":42278,\"start\":42277},{\"end\":42491,\"start\":42490},{\"end\":42493,\"start\":42492},{\"end\":42499,\"start\":42498},{\"end\":42722,\"start\":42721},{\"end\":42724,\"start\":42723},{\"end\":42730,\"start\":42729},{\"end\":42732,\"start\":42731},{\"end\":42740,\"start\":42739},{\"end\":42969,\"start\":42968},{\"end\":42981,\"start\":42980},{\"end\":42988,\"start\":42987},{\"end\":43001,\"start\":43000},{\"end\":43003,\"start\":43002},{\"end\":43229,\"start\":43228},{\"end\":43241,\"start\":43240},{\"end\":43243,\"start\":43242},{\"end\":43254,\"start\":43253},{\"end\":43545,\"start\":43544},{\"end\":43557,\"start\":43556},{\"end\":43570,\"start\":43569},{\"end\":43572,\"start\":43571},{\"end\":43789,\"start\":43785},{\"end\":43799,\"start\":43798},{\"end\":43801,\"start\":43800},{\"end\":43808,\"start\":43807},{\"end\":43810,\"start\":43809},{\"end\":43820,\"start\":43819},{\"end\":43822,\"start\":43821},{\"end\":43831,\"start\":43830},{\"end\":43844,\"start\":43840},{\"end\":44086,\"start\":44085},{\"end\":44093,\"start\":44092},{\"end\":44105,\"start\":44104},{\"end\":44116,\"start\":44115},{\"end\":44125,\"start\":44124},{\"end\":44408,\"start\":44407},{\"end\":44416,\"start\":44415},{\"end\":44423,\"start\":44422},{\"end\":44433,\"start\":44432},{\"end\":44443,\"start\":44442},{\"end\":44692,\"start\":44691},{\"end\":44698,\"start\":44697},{\"end\":44707,\"start\":44706},{\"end\":44715,\"start\":44714},{\"end\":44722,\"start\":44721},{\"end\":44943,\"start\":44942},{\"end\":44955,\"start\":44954},{\"end\":44964,\"start\":44963},{\"end\":45258,\"start\":45257},{\"end\":45260,\"start\":45259},{\"end\":45270,\"start\":45269},{\"end\":45279,\"start\":45278},{\"end\":45540,\"start\":45539},{\"end\":45546,\"start\":45545},{\"end\":45554,\"start\":45553},{\"end\":45558,\"start\":45555},{\"end\":45785,\"start\":45784},{\"end\":45791,\"start\":45790},{\"end\":45799,\"start\":45798},{\"end\":45803,\"start\":45800},{\"end\":46126,\"start\":46125},{\"end\":46134,\"start\":46133},{\"end\":46142,\"start\":46141},{\"end\":46149,\"start\":46148},{\"end\":46157,\"start\":46156},{\"end\":46163,\"start\":46162},{\"end\":46165,\"start\":46164},{\"end\":46370,\"start\":46369},{\"end\":46376,\"start\":46375},{\"end\":46384,\"start\":46383},{\"end\":46392,\"start\":46391},{\"end\":46401,\"start\":46400},{\"end\":46409,\"start\":46408},{\"end\":46667,\"start\":46666},{\"end\":46673,\"start\":46672},{\"end\":46682,\"start\":46681},{\"end\":46690,\"start\":46689},{\"end\":46698,\"start\":46697},{\"end\":46964,\"start\":46963},{\"end\":46970,\"start\":46969},{\"end\":46979,\"start\":46978},{\"end\":46985,\"start\":46984},{\"end\":46993,\"start\":46992},{\"end\":47001,\"start\":47000},{\"end\":47009,\"start\":47008},{\"end\":47017,\"start\":47016},{\"end\":47293,\"start\":47292},{\"end\":47302,\"start\":47301},{\"end\":47311,\"start\":47310},{\"end\":47509,\"start\":47508},{\"end\":47517,\"start\":47516},{\"end\":47527,\"start\":47526},{\"end\":47719,\"start\":47718},{\"end\":47728,\"start\":47727},{\"end\":47735,\"start\":47734},{\"end\":47742,\"start\":47741},{\"end\":47750,\"start\":47749},{\"end\":47756,\"start\":47755},{\"end\":47764,\"start\":47763},{\"end\":47979,\"start\":47978},{\"end\":47988,\"start\":47987},{\"end\":47996,\"start\":47995},{\"end\":48004,\"start\":48003},{\"end\":48012,\"start\":48011},{\"end\":48020,\"start\":48019},{\"end\":48240,\"start\":48239},{\"end\":48249,\"start\":48248},{\"end\":48257,\"start\":48256},{\"end\":48265,\"start\":48264},{\"end\":48271,\"start\":48270},{\"end\":48278,\"start\":48277},{\"end\":48492,\"start\":48491},{\"end\":48501,\"start\":48500},{\"end\":48509,\"start\":48508},{\"end\":48511,\"start\":48510},{\"end\":48748,\"start\":48747},{\"end\":48757,\"start\":48756},{\"end\":48765,\"start\":48764},{\"end\":48934,\"start\":48933},{\"end\":48943,\"start\":48942},{\"end\":48952,\"start\":48951},{\"end\":48959,\"start\":48958},{\"end\":48973,\"start\":48972}]", "bib_author_last_name": "[{\"end\":35297,\"start\":35285},{\"end\":35310,\"start\":35301},{\"end\":35500,\"start\":35497},{\"end\":35507,\"start\":35504},{\"end\":35730,\"start\":35717},{\"end\":35740,\"start\":35736},{\"end\":35960,\"start\":35956},{\"end\":35968,\"start\":35964},{\"end\":35976,\"start\":35972},{\"end\":35985,\"start\":35980},{\"end\":36229,\"start\":36225},{\"end\":36240,\"start\":36233},{\"end\":36249,\"start\":36244},{\"end\":36258,\"start\":36253},{\"end\":36271,\"start\":36262},{\"end\":36572,\"start\":36565},{\"end\":36589,\"start\":36583},{\"end\":36597,\"start\":36593},{\"end\":36858,\"start\":36849},{\"end\":36869,\"start\":36862},{\"end\":36879,\"start\":36873},{\"end\":36889,\"start\":36883},{\"end\":36901,\"start\":36893},{\"end\":37151,\"start\":37139},{\"end\":37165,\"start\":37157},{\"end\":37179,\"start\":37169},{\"end\":37190,\"start\":37183},{\"end\":37461,\"start\":37455},{\"end\":37473,\"start\":37465},{\"end\":37483,\"start\":37477},{\"end\":37492,\"start\":37487},{\"end\":37505,\"start\":37498},{\"end\":37518,\"start\":37509},{\"end\":37819,\"start\":37813},{\"end\":37831,\"start\":37823},{\"end\":37841,\"start\":37835},{\"end\":37850,\"start\":37845},{\"end\":37863,\"start\":37856},{\"end\":37876,\"start\":37867},{\"end\":38164,\"start\":38158},{\"end\":38176,\"start\":38168},{\"end\":38189,\"start\":38180},{\"end\":38199,\"start\":38193},{\"end\":38461,\"start\":38457},{\"end\":38468,\"start\":38465},{\"end\":38649,\"start\":38647},{\"end\":38658,\"start\":38653},{\"end\":38665,\"start\":38662},{\"end\":38672,\"start\":38669},{\"end\":38864,\"start\":38859},{\"end\":38877,\"start\":38868},{\"end\":38887,\"start\":38881},{\"end\":39123,\"start\":39119},{\"end\":39134,\"start\":39127},{\"end\":39372,\"start\":39365},{\"end\":39379,\"start\":39376},{\"end\":39385,\"start\":39383},{\"end\":39401,\"start\":39389},{\"end\":39410,\"start\":39405},{\"end\":39421,\"start\":39416},{\"end\":39739,\"start\":39730},{\"end\":39749,\"start\":39743},{\"end\":39761,\"start\":39753},{\"end\":39771,\"start\":39767},{\"end\":39782,\"start\":39775},{\"end\":40017,\"start\":40007},{\"end\":40030,\"start\":40021},{\"end\":40042,\"start\":40036},{\"end\":40247,\"start\":40243},{\"end\":40253,\"start\":40251},{\"end\":40262,\"start\":40257},{\"end\":40270,\"start\":40266},{\"end\":40278,\"start\":40274},{\"end\":40491,\"start\":40489},{\"end\":40497,\"start\":40495},{\"end\":40509,\"start\":40501},{\"end\":40518,\"start\":40513},{\"end\":40725,\"start\":40723},{\"end\":40733,\"start\":40729},{\"end\":40741,\"start\":40737},{\"end\":40749,\"start\":40745},{\"end\":40967,\"start\":40965},{\"end\":40975,\"start\":40971},{\"end\":40983,\"start\":40979},{\"end\":40991,\"start\":40987},{\"end\":41230,\"start\":41226},{\"end\":41236,\"start\":41234},{\"end\":41243,\"start\":41240},{\"end\":41251,\"start\":41249},{\"end\":41476,\"start\":41473},{\"end\":41483,\"start\":41480},{\"end\":41491,\"start\":41487},{\"end\":41499,\"start\":41495},{\"end\":41701,\"start\":41698},{\"end\":41709,\"start\":41705},{\"end\":41715,\"start\":41713},{\"end\":41724,\"start\":41719},{\"end\":41731,\"start\":41728},{\"end\":41982,\"start\":41979},{\"end\":41992,\"start\":41989},{\"end\":42000,\"start\":41996},{\"end\":42007,\"start\":42004},{\"end\":42014,\"start\":42011},{\"end\":42022,\"start\":42018},{\"end\":42029,\"start\":42026},{\"end\":42259,\"start\":42257},{\"end\":42265,\"start\":42263},{\"end\":42275,\"start\":42271},{\"end\":42281,\"start\":42279},{\"end\":42496,\"start\":42494},{\"end\":42502,\"start\":42500},{\"end\":42727,\"start\":42725},{\"end\":42737,\"start\":42733},{\"end\":42743,\"start\":42741},{\"end\":42978,\"start\":42970},{\"end\":42985,\"start\":42982},{\"end\":42998,\"start\":42989},{\"end\":43017,\"start\":43004},{\"end\":43238,\"start\":43230},{\"end\":43251,\"start\":43244},{\"end\":43264,\"start\":43255},{\"end\":43554,\"start\":43546},{\"end\":43567,\"start\":43558},{\"end\":43580,\"start\":43573},{\"end\":43796,\"start\":43790},{\"end\":43805,\"start\":43802},{\"end\":43817,\"start\":43811},{\"end\":43828,\"start\":43823},{\"end\":43838,\"start\":43832},{\"end\":43847,\"start\":43845},{\"end\":44090,\"start\":44087},{\"end\":44102,\"start\":44094},{\"end\":44113,\"start\":44106},{\"end\":44122,\"start\":44117},{\"end\":44134,\"start\":44126},{\"end\":44413,\"start\":44409},{\"end\":44420,\"start\":44417},{\"end\":44430,\"start\":44424},{\"end\":44440,\"start\":44434},{\"end\":44446,\"start\":44444},{\"end\":44695,\"start\":44693},{\"end\":44704,\"start\":44699},{\"end\":44712,\"start\":44708},{\"end\":44719,\"start\":44716},{\"end\":44727,\"start\":44723},{\"end\":44952,\"start\":44944},{\"end\":44961,\"start\":44956},{\"end\":44974,\"start\":44965},{\"end\":45267,\"start\":45261},{\"end\":45276,\"start\":45271},{\"end\":45284,\"start\":45280},{\"end\":45543,\"start\":45541},{\"end\":45551,\"start\":45547},{\"end\":45565,\"start\":45559},{\"end\":45788,\"start\":45786},{\"end\":45796,\"start\":45792},{\"end\":45810,\"start\":45804},{\"end\":46131,\"start\":46127},{\"end\":46139,\"start\":46135},{\"end\":46146,\"start\":46143},{\"end\":46154,\"start\":46150},{\"end\":46160,\"start\":46158},{\"end\":46168,\"start\":46166},{\"end\":46373,\"start\":46371},{\"end\":46381,\"start\":46377},{\"end\":46389,\"start\":46385},{\"end\":46398,\"start\":46393},{\"end\":46406,\"start\":46402},{\"end\":46413,\"start\":46410},{\"end\":46670,\"start\":46668},{\"end\":46679,\"start\":46674},{\"end\":46687,\"start\":46683},{\"end\":46695,\"start\":46691},{\"end\":46703,\"start\":46699},{\"end\":46967,\"start\":46965},{\"end\":46976,\"start\":46971},{\"end\":46982,\"start\":46980},{\"end\":46990,\"start\":46986},{\"end\":46998,\"start\":46994},{\"end\":47006,\"start\":47002},{\"end\":47014,\"start\":47010},{\"end\":47020,\"start\":47018},{\"end\":47299,\"start\":47294},{\"end\":47308,\"start\":47303},{\"end\":47316,\"start\":47312},{\"end\":47514,\"start\":47510},{\"end\":47524,\"start\":47518},{\"end\":47532,\"start\":47528},{\"end\":47725,\"start\":47720},{\"end\":47732,\"start\":47729},{\"end\":47739,\"start\":47736},{\"end\":47747,\"start\":47743},{\"end\":47753,\"start\":47751},{\"end\":47761,\"start\":47757},{\"end\":47769,\"start\":47765},{\"end\":47985,\"start\":47980},{\"end\":47993,\"start\":47989},{\"end\":48001,\"start\":47997},{\"end\":48009,\"start\":48005},{\"end\":48017,\"start\":48013},{\"end\":48025,\"start\":48021},{\"end\":48246,\"start\":48241},{\"end\":48254,\"start\":48250},{\"end\":48262,\"start\":48258},{\"end\":48268,\"start\":48266},{\"end\":48275,\"start\":48272},{\"end\":48283,\"start\":48279},{\"end\":48498,\"start\":48493},{\"end\":48506,\"start\":48502},{\"end\":48521,\"start\":48512},{\"end\":48754,\"start\":48749},{\"end\":48762,\"start\":48758},{\"end\":48770,\"start\":48766},{\"end\":48940,\"start\":48935},{\"end\":48949,\"start\":48944},{\"end\":48956,\"start\":48953},{\"end\":48970,\"start\":48960},{\"end\":48978,\"start\":48974}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":14678946},\"end\":35431,\"start\":35220},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":14145019},\"end\":35622,\"start\":35433},{\"attributes\":{\"id\":\"b2\"},\"end\":35877,\"start\":35624},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":14811466},\"end\":36127,\"start\":35879},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":570516},\"end\":36458,\"start\":36129},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15005943},\"end\":36769,\"start\":36460},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":7973738},\"end\":37068,\"start\":36771},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":3198903},\"end\":37360,\"start\":37070},{\"attributes\":{\"id\":\"b8\"},\"end\":37724,\"start\":37362},{\"attributes\":{\"id\":\"b9\"},\"end\":38062,\"start\":37726},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":3041327},\"end\":38370,\"start\":38064},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":3961724},\"end\":38597,\"start\":38372},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":206594692},\"end\":38779,\"start\":38599},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":15141406},\"end\":39040,\"start\":38781},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":14618732},\"end\":39257,\"start\":39042},{\"attributes\":{\"doi\":\"arXiv:1605.09653\",\"id\":\"b15\"},\"end\":39668,\"start\":39259},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":10070153},\"end\":39938,\"start\":39670},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":195908774},\"end\":40178,\"start\":39940},{\"attributes\":{\"id\":\"b18\"},\"end\":40426,\"start\":40180},{\"attributes\":{\"id\":\"b19\"},\"end\":40644,\"start\":40428},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":938105},\"end\":40886,\"start\":40646},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":938105},\"end\":41133,\"start\":40888},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":14124239},\"end\":41415,\"start\":41135},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":8223206},\"end\":41622,\"start\":41417},{\"attributes\":{\"doi\":\"arXiv:1606.04404\",\"id\":\"b24\"},\"end\":41921,\"start\":41624},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":2024800},\"end\":42176,\"start\":41923},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":6746533},\"end\":42426,\"start\":42178},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":16863381},\"end\":42610,\"start\":42428},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":10519398},\"end\":42911,\"start\":42612},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":7379933},\"end\":43159,\"start\":42913},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":2374122},\"end\":43457,\"start\":43161},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":15352079},\"end\":43743,\"start\":43459},{\"attributes\":{\"id\":\"b32\"},\"end\":44004,\"start\":43745},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":5741831},\"end\":44304,\"start\":44006},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":1918026},\"end\":44627,\"start\":44306},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":5231143},\"end\":44860,\"start\":44629},{\"attributes\":{\"doi\":\"arXiv:1512.05300\",\"id\":\"b36\"},\"end\":45171,\"start\":44862},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":15172651},\"end\":45431,\"start\":45173},{\"attributes\":{\"doi\":\"arXiv:1606.01595\",\"id\":\"b38\"},\"end\":45782,\"start\":45433},{\"attributes\":{\"doi\":\"arXiv:1601.07255\",\"id\":\"b39\"},\"end\":46073,\"start\":45784},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":564273},\"end\":46298,\"start\":46075},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":45166711},\"end\":46580,\"start\":46300},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":8897399},\"end\":46863,\"start\":46582},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":4646089},\"end\":47223,\"start\":46865},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":480975},\"end\":47445,\"start\":47225},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":11864530},\"end\":47650,\"start\":47447},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":2214158},\"end\":47928,\"start\":47652},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":14991802},\"end\":48164,\"start\":47930},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":11406417},\"end\":48438,\"start\":48166},{\"attributes\":{\"doi\":\"arXiv:1610.02984\",\"id\":\"b49\"},\"end\":48690,\"start\":48440},{\"attributes\":{\"doi\":\"arXiv:1608.01807\",\"id\":\"b50\"},\"end\":48931,\"start\":48692},{\"attributes\":{\"doi\":\"arXiv:1604.02531\",\"id\":\"b51\"},\"end\":49192,\"start\":48933}]", "bib_title": "[{\"end\":35281,\"start\":35220},{\"end\":35493,\"start\":35433},{\"end\":35952,\"start\":35879},{\"end\":36221,\"start\":36129},{\"end\":36561,\"start\":36460},{\"end\":36845,\"start\":36771},{\"end\":37133,\"start\":37070},{\"end\":38154,\"start\":38064},{\"end\":38453,\"start\":38372},{\"end\":38643,\"start\":38599},{\"end\":38855,\"start\":38781},{\"end\":39115,\"start\":39042},{\"end\":39726,\"start\":39670},{\"end\":40003,\"start\":39940},{\"end\":40485,\"start\":40428},{\"end\":40719,\"start\":40646},{\"end\":40961,\"start\":40888},{\"end\":41222,\"start\":41135},{\"end\":41469,\"start\":41417},{\"end\":41975,\"start\":41923},{\"end\":42251,\"start\":42178},{\"end\":42488,\"start\":42428},{\"end\":42719,\"start\":42612},{\"end\":42966,\"start\":42913},{\"end\":43226,\"start\":43161},{\"end\":43542,\"start\":43459},{\"end\":44083,\"start\":44006},{\"end\":44405,\"start\":44306},{\"end\":44689,\"start\":44629},{\"end\":45255,\"start\":45173},{\"end\":46123,\"start\":46075},{\"end\":46367,\"start\":46300},{\"end\":46664,\"start\":46582},{\"end\":46961,\"start\":46865},{\"end\":47290,\"start\":47225},{\"end\":47506,\"start\":47447},{\"end\":47716,\"start\":47652},{\"end\":47976,\"start\":47930},{\"end\":48237,\"start\":48166}]", "bib_author": "[{\"end\":35299,\"start\":35283},{\"end\":35312,\"start\":35299},{\"end\":35502,\"start\":35495},{\"end\":35509,\"start\":35502},{\"end\":35732,\"start\":35715},{\"end\":35742,\"start\":35732},{\"end\":35962,\"start\":35954},{\"end\":35970,\"start\":35962},{\"end\":35978,\"start\":35970},{\"end\":35987,\"start\":35978},{\"end\":36231,\"start\":36223},{\"end\":36242,\"start\":36231},{\"end\":36251,\"start\":36242},{\"end\":36260,\"start\":36251},{\"end\":36273,\"start\":36260},{\"end\":36574,\"start\":36563},{\"end\":36591,\"start\":36574},{\"end\":36599,\"start\":36591},{\"end\":36860,\"start\":36847},{\"end\":36871,\"start\":36860},{\"end\":36881,\"start\":36871},{\"end\":36891,\"start\":36881},{\"end\":36903,\"start\":36891},{\"end\":37153,\"start\":37135},{\"end\":37167,\"start\":37153},{\"end\":37181,\"start\":37167},{\"end\":37192,\"start\":37181},{\"end\":37463,\"start\":37453},{\"end\":37475,\"start\":37463},{\"end\":37485,\"start\":37475},{\"end\":37494,\"start\":37485},{\"end\":37507,\"start\":37494},{\"end\":37520,\"start\":37507},{\"end\":37821,\"start\":37811},{\"end\":37833,\"start\":37821},{\"end\":37843,\"start\":37833},{\"end\":37852,\"start\":37843},{\"end\":37865,\"start\":37852},{\"end\":37878,\"start\":37865},{\"end\":38166,\"start\":38156},{\"end\":38178,\"start\":38166},{\"end\":38191,\"start\":38178},{\"end\":38201,\"start\":38191},{\"end\":38463,\"start\":38455},{\"end\":38470,\"start\":38463},{\"end\":38651,\"start\":38645},{\"end\":38660,\"start\":38651},{\"end\":38667,\"start\":38660},{\"end\":38674,\"start\":38667},{\"end\":38866,\"start\":38857},{\"end\":38879,\"start\":38866},{\"end\":38889,\"start\":38879},{\"end\":39125,\"start\":39117},{\"end\":39136,\"start\":39125},{\"end\":39374,\"start\":39363},{\"end\":39381,\"start\":39374},{\"end\":39387,\"start\":39381},{\"end\":39403,\"start\":39387},{\"end\":39412,\"start\":39403},{\"end\":39423,\"start\":39412},{\"end\":39741,\"start\":39728},{\"end\":39751,\"start\":39741},{\"end\":39763,\"start\":39751},{\"end\":39773,\"start\":39763},{\"end\":39784,\"start\":39773},{\"end\":40019,\"start\":40005},{\"end\":40032,\"start\":40019},{\"end\":40044,\"start\":40032},{\"end\":40249,\"start\":40241},{\"end\":40255,\"start\":40249},{\"end\":40264,\"start\":40255},{\"end\":40272,\"start\":40264},{\"end\":40280,\"start\":40272},{\"end\":40493,\"start\":40487},{\"end\":40499,\"start\":40493},{\"end\":40511,\"start\":40499},{\"end\":40520,\"start\":40511},{\"end\":40727,\"start\":40721},{\"end\":40735,\"start\":40727},{\"end\":40743,\"start\":40735},{\"end\":40751,\"start\":40743},{\"end\":40969,\"start\":40963},{\"end\":40977,\"start\":40969},{\"end\":40985,\"start\":40977},{\"end\":40993,\"start\":40985},{\"end\":41232,\"start\":41224},{\"end\":41238,\"start\":41232},{\"end\":41245,\"start\":41238},{\"end\":41253,\"start\":41245},{\"end\":41478,\"start\":41471},{\"end\":41485,\"start\":41478},{\"end\":41493,\"start\":41485},{\"end\":41501,\"start\":41493},{\"end\":41703,\"start\":41696},{\"end\":41711,\"start\":41703},{\"end\":41717,\"start\":41711},{\"end\":41726,\"start\":41717},{\"end\":41733,\"start\":41726},{\"end\":41984,\"start\":41977},{\"end\":41994,\"start\":41984},{\"end\":42002,\"start\":41994},{\"end\":42009,\"start\":42002},{\"end\":42016,\"start\":42009},{\"end\":42024,\"start\":42016},{\"end\":42031,\"start\":42024},{\"end\":42261,\"start\":42253},{\"end\":42267,\"start\":42261},{\"end\":42277,\"start\":42267},{\"end\":42283,\"start\":42277},{\"end\":42498,\"start\":42490},{\"end\":42504,\"start\":42498},{\"end\":42729,\"start\":42721},{\"end\":42739,\"start\":42729},{\"end\":42745,\"start\":42739},{\"end\":42980,\"start\":42968},{\"end\":42987,\"start\":42980},{\"end\":43000,\"start\":42987},{\"end\":43019,\"start\":43000},{\"end\":43240,\"start\":43228},{\"end\":43253,\"start\":43240},{\"end\":43266,\"start\":43253},{\"end\":43556,\"start\":43544},{\"end\":43569,\"start\":43556},{\"end\":43582,\"start\":43569},{\"end\":43798,\"start\":43785},{\"end\":43807,\"start\":43798},{\"end\":43819,\"start\":43807},{\"end\":43830,\"start\":43819},{\"end\":43840,\"start\":43830},{\"end\":43849,\"start\":43840},{\"end\":44092,\"start\":44085},{\"end\":44104,\"start\":44092},{\"end\":44115,\"start\":44104},{\"end\":44124,\"start\":44115},{\"end\":44136,\"start\":44124},{\"end\":44415,\"start\":44407},{\"end\":44422,\"start\":44415},{\"end\":44432,\"start\":44422},{\"end\":44442,\"start\":44432},{\"end\":44448,\"start\":44442},{\"end\":44697,\"start\":44691},{\"end\":44706,\"start\":44697},{\"end\":44714,\"start\":44706},{\"end\":44721,\"start\":44714},{\"end\":44729,\"start\":44721},{\"end\":44954,\"start\":44942},{\"end\":44963,\"start\":44954},{\"end\":44976,\"start\":44963},{\"end\":45269,\"start\":45257},{\"end\":45278,\"start\":45269},{\"end\":45286,\"start\":45278},{\"end\":45545,\"start\":45539},{\"end\":45553,\"start\":45545},{\"end\":45567,\"start\":45553},{\"end\":45790,\"start\":45784},{\"end\":45798,\"start\":45790},{\"end\":45812,\"start\":45798},{\"end\":46133,\"start\":46125},{\"end\":46141,\"start\":46133},{\"end\":46148,\"start\":46141},{\"end\":46156,\"start\":46148},{\"end\":46162,\"start\":46156},{\"end\":46170,\"start\":46162},{\"end\":46375,\"start\":46369},{\"end\":46383,\"start\":46375},{\"end\":46391,\"start\":46383},{\"end\":46400,\"start\":46391},{\"end\":46408,\"start\":46400},{\"end\":46415,\"start\":46408},{\"end\":46672,\"start\":46666},{\"end\":46681,\"start\":46672},{\"end\":46689,\"start\":46681},{\"end\":46697,\"start\":46689},{\"end\":46705,\"start\":46697},{\"end\":46969,\"start\":46963},{\"end\":46978,\"start\":46969},{\"end\":46984,\"start\":46978},{\"end\":46992,\"start\":46984},{\"end\":47000,\"start\":46992},{\"end\":47008,\"start\":47000},{\"end\":47016,\"start\":47008},{\"end\":47022,\"start\":47016},{\"end\":47301,\"start\":47292},{\"end\":47310,\"start\":47301},{\"end\":47318,\"start\":47310},{\"end\":47516,\"start\":47508},{\"end\":47526,\"start\":47516},{\"end\":47534,\"start\":47526},{\"end\":47727,\"start\":47718},{\"end\":47734,\"start\":47727},{\"end\":47741,\"start\":47734},{\"end\":47749,\"start\":47741},{\"end\":47755,\"start\":47749},{\"end\":47763,\"start\":47755},{\"end\":47771,\"start\":47763},{\"end\":47987,\"start\":47978},{\"end\":47995,\"start\":47987},{\"end\":48003,\"start\":47995},{\"end\":48011,\"start\":48003},{\"end\":48019,\"start\":48011},{\"end\":48027,\"start\":48019},{\"end\":48248,\"start\":48239},{\"end\":48256,\"start\":48248},{\"end\":48264,\"start\":48256},{\"end\":48270,\"start\":48264},{\"end\":48277,\"start\":48270},{\"end\":48285,\"start\":48277},{\"end\":48500,\"start\":48491},{\"end\":48508,\"start\":48500},{\"end\":48523,\"start\":48508},{\"end\":48756,\"start\":48747},{\"end\":48764,\"start\":48756},{\"end\":48772,\"start\":48764},{\"end\":48942,\"start\":48933},{\"end\":48951,\"start\":48942},{\"end\":48958,\"start\":48951},{\"end\":48972,\"start\":48958},{\"end\":48980,\"start\":48972}]", "bib_venue": "[{\"end\":35316,\"start\":35312},{\"end\":35517,\"start\":35509},{\"end\":35713,\"start\":35624},{\"end\":35991,\"start\":35987},{\"end\":36277,\"start\":36273},{\"end\":36603,\"start\":36599},{\"end\":36907,\"start\":36903},{\"end\":37202,\"start\":37192},{\"end\":37451,\"start\":37362},{\"end\":37809,\"start\":37726},{\"end\":38205,\"start\":38201},{\"end\":38474,\"start\":38470},{\"end\":38678,\"start\":38674},{\"end\":38893,\"start\":38889},{\"end\":39140,\"start\":39136},{\"end\":39361,\"start\":39259},{\"end\":39788,\"start\":39784},{\"end\":40048,\"start\":40044},{\"end\":40239,\"start\":40180},{\"end\":40524,\"start\":40520},{\"end\":40755,\"start\":40751},{\"end\":40997,\"start\":40993},{\"end\":41257,\"start\":41253},{\"end\":41505,\"start\":41501},{\"end\":41694,\"start\":41624},{\"end\":42037,\"start\":42031},{\"end\":42291,\"start\":42283},{\"end\":42508,\"start\":42504},{\"end\":42749,\"start\":42745},{\"end\":43023,\"start\":43019},{\"end\":43298,\"start\":43266},{\"end\":43590,\"start\":43582},{\"end\":43783,\"start\":43745},{\"end\":44140,\"start\":44136},{\"end\":44452,\"start\":44448},{\"end\":44733,\"start\":44729},{\"end\":44940,\"start\":44862},{\"end\":45290,\"start\":45286},{\"end\":45537,\"start\":45433},{\"end\":45903,\"start\":45828},{\"end\":46174,\"start\":46170},{\"end\":46418,\"start\":46415},{\"end\":46711,\"start\":46705},{\"end\":47030,\"start\":47022},{\"end\":47322,\"start\":47318},{\"end\":47538,\"start\":47534},{\"end\":47775,\"start\":47771},{\"end\":48031,\"start\":48027},{\"end\":48289,\"start\":48285},{\"end\":48489,\"start\":48440},{\"end\":48745,\"start\":48692},{\"end\":49032,\"start\":48996}]"}}}, "year": 2023, "month": 12, "day": 17}