{"id": 249306984, "updated": "2022-07-06 13:42:20.913", "metadata": {"title": "Automated handling of anaphoric ambiguity in requirements: a multi-solution study", "authors": "[{\"first\":\"Saad\",\"last\":\"Ezzini\",\"middle\":[]},{\"first\":\"Sallam\",\"last\":\"Abualhaija\",\"middle\":[]},{\"first\":\"Chetan\",\"last\":\"Arora\",\"middle\":[]},{\"first\":\"Mehrdad\",\"last\":\"Sabetzadeh\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 44th International Conference on Software Engineering", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Ambiguity is a pervasive issue in natural-language requirements. A common source of ambiguity in requirements is when a pronoun is anaphoric. In requirements engineering, anaphoric ambiguity occurs when a pronoun can plausibly refer to different entities and thus be interpreted differently by different readers. In this paper, we develop an accurate and practical automated approach for handling anaphoric ambiguity in requirements, addressing both ambiguity detection and anaphora interpretation. In view of the multiple competing natural language processing (NLP) and machine learning (ML) technologies that one can utilize, we simultaneously pursue six alternative solutions, empirically assessing each using a collection of \u22481,350 industrial requirements. The alternative solution strategies that we consider are natural choices induced by the existing technologies; these choices frequently arise in other automation tasks involving natural-language requirements. A side-by-side empirical examination of these choices helps develop insights about the usefulness of different state-of-the-art NLP and ML technologies for addressing requirements engineering problems. For the ambiguity detection task, we observe that supervised ML outperforms both a large-scale language model, SpanBERT (a variant of BERT), as well as a solution assembled from off-the-shelf NLP coreference re-solvers. In contrast, for anaphora interpretation, SpanBERT yields the most accurate solution. In our evaluation, (1) the best solution for anaphoric ambiguity detection has an average precision of \u224860% and a recall of 100%, and (2) the best solution for anaphora interpretation (resolution) has an average success rate of \u224898%.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icse/EzziniA0S22", "doi": "10.1145/3510003.3510157"}}, "content": {"source": {"pdf_hash": "b6c1f2a0807e24edb22da1166163f7b8d0b65681", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "3614106959d08a6e4aa8f2e49c620fd714295393", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/b6c1f2a0807e24edb22da1166163f7b8d0b65681.txt", "contents": "\nAutomated Handling of Anaphoric Ambiguity in Requirements: A Multi-solution Study\n\n\nSaad Ezzini saad.ezzini@uni.lu \nUniversity of Luxembourg\nLuxembourg\n\nSallam Abualhaija sallam.abualhaija@uni.lu \nUniversity of Luxembourg\nLuxembourg\n\nChetan Arora chetan.arora@deakin.edu.au \nDeakin University\nAustralia\n\nMehrdad Sabetzadeh m.sabetzadeh@uottawa.ca \nUniversity of Ottawa\nPittsburghPACanada, USA\n\nAutomated Handling of Anaphoric Ambiguity in Requirements: A Multi-solution Study\n10.1145/3510003.3510157Requirements EngineeringNatural-language RequirementsAmbi- guityNatural Language Processing (NLP)Machine Learning (ML)Language ModelsBERT\nAmbiguity is a pervasive issue in natural-language requirements. A common source of ambiguity in requirements is when a pronoun is anaphoric. In requirements engineering, anaphoric ambiguity occurs when a pronoun can plausibly refer to different entities and thus be interpreted differently by different readers. In this paper, we develop an accurate and practical automated approach for handling anaphoric ambiguity in requirements, addressing both ambiguity detection and anaphora interpretation. In view of the multiple competing natural language processing (NLP) and machine learning (ML) technologies that one can utilize, we simultaneously pursue six alternative solutions, empirically assessing each using a collection of \u22481,350 industrial requirements. The alternative solution strategies that we consider are natural choices induced by the existing technologies; these choices frequently arise in other automation tasks involving natural-language requirements. A side-by-side empirical examination of these choices helps develop insights about the usefulness of different state-of-the-art NLP and ML technologies for addressing requirements engineering problems. For the ambiguity detection task, we observe that supervised ML outperforms both a large-scale language model, SpanBERT (a variant of BERT), as well as a solution assembled from off-the-shelf NLP coreference resolvers. In contrast, for anaphora interpretation, SpanBERT yields the most accurate solution. In our evaluation, (1) the best solution for anaphoric ambiguity detection has an average precision of \u224860% and a recall of 100%, and (2) the best solution for anaphora interpretation (resolution) has an average success rate of \u224898%.\n\nINTRODUCTION\n\nNatural language (NL) is the most common medium for specifying systems and software requirements. NL enables communication between stakeholders who may have different backgrounds, often requiring little or no additional training [71]. NL requirements are nonetheless prone to defects such as ambiguity [10,20,71]. Ambiguity occurs when a word, phrase or sentence is open to multiple interpretations [69]. Ambiguity can have a negative impact on the quality of requirements and also potentially jeopardize the success of a project [24,41]. A common cause of ambiguity in requirements is anaphora [28,39,81,95].\n\nAnaphora means repetition in Greek and is defined as references to entities mentioned earlier in the text. These references are called anaphors and the entities to which they refer are called antecedents [60]. Anaphoric ambiguity occurs when there is more than one plausible antecedent [24,61]. In linguistics, there are several types of anaphora [60]. In requirements engineering (RE), anaphora is typically scoped to pronominal anaphora, i.e., when the anaphor is a pronoun [25,95]. This is because pronominal anaphora has been clearly established as a genuine source of ambiguity in requirements [39]. Anaphoric ambiguity detection in RE is thus the task of identifying ambiguous occurrences of pronouns [94]. The closely related task of anaphora resolution (interpretation) is concerned with finding the most likely antecedent for a given pronoun [61].\n\nTo illustrate, consider the example in Figure 1. Here, the anaphor is it, occurring in the second sentence. The potential antecedents are the preceding noun phrases (NPs), namely \"the S&T component\", \"approval requests\", \"the DBS\", \"the request\" and \"storage parameters\". The pronoun it is unlikely to refer to \"approval requests\" or \"storage parameters\" due to number disagreement (here, singular pronoun versus plural NPs). Similarly, it is unlikely to refer to \"the request\", since it is the subject of the verb \"create\", and \"the request\" is not a suitable replacement for the subject of this verb. It is not entirely clear though whether it refers to \"the S&T component\" or \"the DBS\". Depending on which antecedent -\"the S&T component\" or \"the DBS\" -is selected, there are two different interpretations as to which subsystem should create a configuration record. To properly deal with this situation, the pronoun it has to be either detected as ambiguous or resolved as referring to the correct antecedent, which happens to be \"the S&T component\". We note that identifying the correct antecedent in this example would likely be impossible without domain knowledge.\n? x ?\nThe S&T component shall send all approval requests to the DBS.\n\nIf the request contains storage parameters, it shall create a configuration record from the parameters.  In RE, unconscious disambiguation of requirements is common, particularly by stakeholders who have domain knowledge or a good understanding of the system under development [78]. Not all stakeholders in a project, however, share the same level of domain knowledge or familiarity with the system-to-be. For example, it is known that developers are prone to interpreting requirements inaccurately [63]. To reduce the potential for misinterpretation and the ensuing consequences, it is desirable to deal with ambiguity in requirements as early as possible. Typically, and somewhat in contrast to the literature on Natural Language Processing (NLP), RE prioritizes ambiguity detection over anaphora resolution. The rationale is that any genuine ambiguity in requirements needs to be inspected by human analysts and mitigated by rephrasing or other means, as opposed to the ambiguity being subjected to automated interpretation, i.e., what is commonly done in NLP [25].\n\nAnaphoric ambiguity is prevalent in NL requirements. Estimates from the RE literature suggest that nearly 20% of industrial requirements contain anaphora [25,81]. Current RE research on anaphoric ambiguity [7,22,25,94,95], as we elaborate in Section 2.2, does not adequately explore two important facets. First, the existing work relies primarily on the traditional methods in NLP and machine learning (ML). With the rapid emergence and adoption of new technologies such as pre-trained language models, BERT [18] being a notable example, the landscape for the processing (and generation) of NL content has changed drastically. This, on the one hand, provides an opportunity to develop new solutions, and, on the other hand, necessitates a revamp and reexamination of the existing solutions, now using better enabling technologies. Second, the existing RE solutions for anaphoric ambiguity have been evaluated on either a single application domain (e.g., railway) or on very small datasets. As such, empirical results remain scarce on the usefulness of automated techniques for dealing with anaphora in requirements documents.\n\nOn the surface, it may seem that one can readily adopt existing solutions from the NLP community to deal with anaphoric ambiguity in requirements. In the NLP literature, anaphora is typically addressed as part of coreference resolution, which is concerned with finding mentions that refer to the same entity in a given text [38,76]. Coreference resolution is often an intermediate step for more advanced NLP tasks such as question answering and sentiment analysis [61]. As noted earlier, in RE, we prioritize detection over resolution, since we want to bring ambiguous cases to the analysts' attention for further examination. Existing coreference resolvers have not been built to support ambiguity detection, thus complicating the application of an individual resolver for this task.\n\nOur aim in this paper is to arrive at a practical and effective solution for handling anaphoric ambiguity in textual requirements. By \"handling\" anaphoric ambiguity, we mean the primary task of detecting genuine cases of anaphoric ambiguity and the secondary task of interpreting (resolving) anaphora when the risk of ambiguity is sufficiently low. We achieve our aim by empirically investigating multiple solution strategies. Some of the investigated strategies are new and some are adaptations of existing work that are implemented using state-of-the-art technologies. The alternative strategies considered are choices that, in our experience, recurrently arise when engineering requirements automation solutions using NLP and ML. These choices particularly include: (1) whether to use hand-crafted language features, word embeddings or a combination thereof for classification, (2) whether pre-trained language models like BERT are a viable replacement for the more traditional techniques, and (3) whether a mashup of existing (and often generic) NLP tools would be adequate for specific RE tasks.\n\nOur decision to examine and report on multiple solution strategies is motivated by building empirical insights about the mentioned choices. Naturally, our findings in this paper are limited to the task at hand, i.e., handling anaphoric ambiguity. Nonetheless, we believe that our mode of investigation contributes to establishing a framework for comparing the choices available in other requirements automation tasks that are addressed via NLP and/or ML.\n\nContributions. This paper makes the following contributions:\n\n(1) We develop six alternative solutions for automated handling of anaphoric ambiguity in requirements. The solutions span both traditional as well as more recently established NLP and ML technologies. We implement all six solutions using Jupyter Notebooks [42], and make the solutions publicly available 1 .\n\n(2) We empirically evaluate the above-mentioned alternatives on two industrial datasets. The first dataset is a pre-existing one [2], containing 98 requirements with 109 pronoun occurrences. The second dataset was curated as part of our work using third-party (non-author) annotators. This second dataset is a collection of 22 industrial requirements specifications from eight different application domains and containing a total of 1,251 requirements with 737 pronoun occurrences. Over these datasets, for detecting anaphoric ambiguity, supervised ML classification yields the best results with an average precision of \u224860% and a recall of 100%. As for anaphora resolution, a fine-tuned language model from the BERT family of models turns out to be the best solution with a success rate of \u224898%. The fact that different best solutions emerge for two closely related tasks further signifies the usefulness of running multi-solution studies like ours.\n\nSignificance. The significance of our work is two-fold: (1) ambiguity handling is a major concern in RE. We devise an accurate automated solution to address a prevalent (and problematic) ambiguity type, namely anaphoric ambiguity; (2) the NLP landscape has evolved drastically in recent years. Comparing the more traditional techniques against new advancements is beneficial and relevant to many AI-based RE automation tasks beyond ambiguity handling.\n\nWe demonstrate how such comparisons can be made systematically. We further provide insights and lessons learned, and shed light on potential challenges.\n\nStructure. Section 2 discusses background and positions our work against the related literature in NLP and RE. Section 3 presents our alternative solutions for handling anaphoric ambiguity in requirements. Section 4 reports on our empirical evaluation. Section 5 addresses threats to validity. Section 6 concludes the paper.\n\n\nBACKGROUND AND RELATED WORK\n\nThis section presents the necessary background for our solutions and further discusses the related literature in RE and NLP.\n\n\nBackground\n\nBelow, we discuss the enabling technologies used by our solutions marked x to } in Figure 3. The precise design of these alternative solutions will be elaborated in Section 3. Language Models (LMs). LMs are statistical models that assign probabilities to words or phrases given some training corpus. For example, an LM would assign a higher probability to the phrase \"briefed reporters on\" than the phrase \"briefed to reporters\" [37]. BERT, standing for Bidirectional Encoder Representations from Transformers, is a pre-trained masked language model (MLM) introduced by Devlin et al. [18]. MLMs randomly mask a fraction of the tokens in the pre-training text (the BooksCorpus and English Wikipedia in the case of BERT); the pre-training objective is then to predict the original vocabulary of these masked tokens based on the surrounding context. For example, BERT should predict the masked token \"briefed\" in the phrase \"[MASK] reporters on\".\n\nPre-trained LMs can be employed to directly solve downstream NLP tasks such as anaphoric ambiguity handling (the focus of our work). We integrate LMs into our solutions using two strategies. The first strategy is to fine-tune the parameters of a pre-trained LM on a labeled dataset for anaphoric ambiguity handling. We apply this strategy to devise solutions x and y based on SpanBERT [36], a variant of BERT. In contrast to BERT, SpanBERT is pre-trained to predict masked text spans (rather than masked tokens). SpanBERT is better suited than BERT for tasks such as anaphora resolution and question answering where the output is a text span, e.g., a noun phrase rather than an individual noun [44]. The second strategy is to extract contextual embeddings from the pre-trained LM and use these embeddings as learning features in ML-based text classification. Embeddings are mathematical representations capturing the syntactic and semantic characteristics of text. For developing solution {, we use embeddings from both BERT [18] and SBERT [77].\n\nWhile BERT derives embeddings for individual tokens, SBERT is optimized for deriving semantically meaningful embeddings for an entire text sequence. Machine Learning (ML). Supervised ML (including text classification [87]) requires labeled data consisting of datapoints described as a set of features and a class label. Using this labeled data, an ML classifier is trained to discriminate among the different classes based on the features. Subsequently, the classifier will be able to predict the class of a previously unseen datapoint described by the features. For text classification, different types of learning features can be used [3]. Among them, we apply in our work both manuallycrafted features collected from the literature as well as contextual embeddings, presented earlier.\n\nSolutions z and { -and also | which is a combination of z and { -are ML-based. In our labeled data, each datapoint is the combination of a pronoun and a candidate antecedent, both occurring in some context. Each datapoint is labeled correct, incorrect or inconclusive, as we explain in Section 3. Our empirical evaluation examines several widely used ML classification algorithms, namely decision tree (DT), feed-forward neural network (FNN), k-nearest neighbour (kNN), logistic regression (LR), na\u00efve Bayes (NB), random forest (RF) and support vector machine (SVM). We refer the reader to textbooks for more details about these algorithms [30,91]. Natural Language Processing (NLP) Pipeline. In our work, we apply an NLP pipeline composed of eight modules: (1) tokenizer for splitting the text into tokens; (2) sentence splitter for breaking up the text into individual sentences; (3) part-of-speech (POS) tagger for assigning a POS tag, e.g., noun, verb or pronoun, to each token in each sentence; (4) lemmatizer for identifying the canonical form (lemma) of each token, e.g., the lemma for \"playing\" is \"play\"; (5) constituency parser for identifying the structural units of sentences, e.g., NPs; (6) dependency parser for defining the grammatical dependencies between the tokens in sentences; (7) coreference resolver for finding mentions that refer to the same textual entity; and finally, (8) semantic parser for extracting information about words' meanings. Modules 1 to 6 are prerequisites for all our solutions (see the preprocessing step in Section 3.2). Our ML-based solutions additionally use modules 7 and 8 for extracting language features. Module 7 is the basis for solution }.\n\n\nRelated Work\n\nAmbiguity in natural language has been studied extensively [28,54,61]. In RE, different dimensions of ambiguity have been explored, including understanding the significance of ambiguity in requirements [24,28,32,78,84], analyzing the linguistic causes of ambiguity [10,21,39,54], ambiguity prevention [4,5,55,58,80], and ambiguity detection and resolution [5,17,20,23,25,29,40,43,64,81,83,88,90,95]. Below, we discuss related work on anaphoric ambiguity detection and anaphora resolution, covering both the RE and NLP communities.\n\nIn RE, anaphoric ambiguity has been addressed only to a limited extent, despite (pronominal) anaphora being a common source of misunderstandings in requirements [28]. Yang et al. [94,95] propose an ML-based solution over language features for detecting cases of anaphoric ambiguity leading to misunderstandings. Using 200 anaphoric pronouns from different domains, they report an accuracy of \u224876% for classifying whether an antecedent is correct for a given pronoun. Detecting potential anaphoric ambiguity has also been addressed as a sub-topic of defects detection, with some basic solutions having been proposed, e.g., generating potential ambiguity warnings for all pronouns or only for pronouns whose surrounding text matches some simple syntactic patterns [5,28,81].\n\nThe approaches outlined above have two limitations. First, they are based on traditional technologies from NLP and ML -two fields that have advanced significantly over the past few years. Second, these approaches have been evaluated on small datasets or single domains. We address the first limitation by (i) devising solutions in view of recent advances in NLP and ML, particularly the emergence of pre-trained language models; and (ii) re-examining the state-ofthe-art approach by Yang et al. [94,95], enhanced with several new language features gleaned from the literature [13,19,47,56,62,75]. To address the second limitation, we conduct a multi-solution empirical study including a relatively large RE dataset that covers eight different application domains.\n\nIn the NLP community, dealing with anaphora is a long-standing problem [61]. As already noted in the introduction section, compared to RE, the focus in NLP is primarily on anaphora resolution, given the needs of the NLP tasks that are further downstream [47,70]. Despite numerous attempts at addressing anaphora resolution, the complex nature of the task has slowed progress for several anaphora types [86]. The anaphora resolution techniques in the NLP community are broadly classified into three categories: syntactic, semantic and neural-network-based [46]. The syntactic and semantic approaches focus on designing ML features based on grammatical structure and word meanings in sentences. In the neural-network-based approaches, anaphora resolution is often reformulated as a question-answering problem. Recent solutions in this category achieve promising results [33,93].\n\nIn addition to being focused on resolution, the techniques developed by the NLP community are trained on generic corpora, e.g., Wikipedia. Due to the major differences between the terminology and style applied in requirements writing versus what is available in generic corpora [26], NLP tools usually do not work well if applied as-is to requirements documents [20,90]. To address this problem, we collect and annotate, as part of our work, a dataset of industrial requirements. Taking inspiration from the state-of-the-art NLP directions, we build multiple solutions for handling anaphoric ambiguity, while ensuring that anaphoric ambiguity detection is explicitly addressed and prioritized over anaphora resolution.\n\n\nSOLUTIONS DESIGN\n\nWe start this section by defining in an analytical manner anaphoric ambiguity detection and anaphora resolution. This is followed by a discussion of the preprocessing required for automating these tasks. We then present the design of six alternative solutions for automated handling of anaphoric ambiguity in requirements; these solutions will be tuned and evaluated in Section 4.\n\n\nProblem Definition\n\nLet R = ( 1 , 2 , . . . , ) be a sequence of requirements, where each represents a single requirements sentence. Let P = ( 1 , 2 , . . . , ) be all the pronouns in R in their order of appearance. Following best practice [95], we define the context of a pronoun as two consecutive sentences = ( \u22121 , ); 2 \u2264 \u2264 , 1 \u2264 \u2264 , where is the sentence in which occurs. If occurs in 1 , then the context is one sentence only, i.e., = (\u2212, 1 ). Each pronoun occurrence is represented by a distinct \u2208 P. This means that multiple occurrences of the same pronoun constitute different elements in P, even when the occurrences are within the same sentence. For each \u2208 P, the context of , i.e., , induces a set of candidate antecedents denoted A = { 1 , 2 , \u00b7 \u00b7 \u00b7 , }.\n\nTo illustrate our notation, we recall the example of Figure 1. Let 1 and 2 be the two consecutive sentences in that example. Then, R = ( 1 , 2 ). There is only one pronoun in R; therefore, P = ( 1 ) where 1 = it. The context for 1 is 1 = ( 1 , 2 ), and the set of candidate antecedents for 1 is A 1 = { 11 , 12 , 13 , 14 , 15 } where 11 = \"the S&T component\", 12 = \"approval requests\", 13 = \"the DBS\", 14 = \"the request\" and 15 = \"storage parameters\". For easier referral later in the paper, we visually show in Figure 2 how our notation is applied to the example of Figure 1.\n\nUsing our notation, anaphoric ambiguity detection is to decide whether a given pronoun occurrence is ambiguous or unambiguous in its context . Anaphora resolution is to identify the most likely antecedent for .\n\n\nPreprocessing\n\nThe preprocessing step generates the input for the alternative ambiguity handling solutions that we consider in this paper. We first apply the NLP pipeline, discussed in Section 2.1, on a given requirements specification (RS) to parse its textual content. We create the list of all pronouns (i.e., P) occurring in RS; this is done by selecting the words that the POS tagger marks as PRP (personal pronoun) or PRP$ (possessive pronoun) [52]. For each \u2208 P, we identify the context as the requirement in which occurs and the preceding requirement \u22121 (for \u2265 2). Finally, for each , we generate the set of all candidate antecedents A . Since antecedents are NPs, as noted in Section 1, we generate A by including all NPs that precede in , as automatically identified by the constituency parser module in the NLP pipeline. We further include any segment following the pattern [NP and/or NP] (e.g., \"the sender and the receiver\") and [NP preposition NP] (e.g., \"the component of the system\"). Doing so improves the set of candidate antecedents by covering the cases where refers to a compound NP [6,95].\n\n\nAlternative Solutions\n\nWe consider six alternative solutions for handling anaphoric ambiguity. These are shown in Figure 3. Alternatives x and y are based on SpanBERT; alternatives z, { and | are based on supervised ML; and, alternative } is based on existing NLP coreference resolvers. We note that the expected input differs across solutions: The solutions based on SpanBERT take as input tuples of the form , ; the ML-based solutions take as input triples of the form , ,\n\n; and, the NLP-based solution take as input merely the context information ( ) for pronoun occurrences. The input for all solutions is directly constructible from the preprocessing results.  Figure 3: Overview of Solution Alternatives (marked x to }).  , where \u2113 is a label characterizing the referential relation between and in and where pr is the prediction probability for \u2113 . For anaphora resolution, the labels admitted by \u2113 are correct and incorrect; for ambiguity detection, \u2113 additionally admits inconclusive. R: (Anaphora Resolution * ) For a given , if there is exactly one such that \u2113 = correct with any probability, then is the most likely antecedent of . Otherwise, if multiple \u2113 are predicted as correct for , then we deem 's most likely antecedent to be where is the index at which \u2113 has the highest probability pr . (Ambiguity Detection) For a given , if there is exactly one label \u2113 = correct, then is unambiguous if, additionally, either of the following conditions hold: (a) pr is \u2265 a fixed (empirically tuned) threshold, or (b) there is no label \u2113 that is inconclusive. Otherwise, is ambiguous. } I: Contexts ( ) of pronoun occurrences. O: Each pronoun occurrence alongside mentions 1 and 2 found by Coref 1 and Coref 2 , respectively. R: (Anaphora Resolution * ) If 1 = 2 , then 1 (= 2 ) is the most likely antecedent of . (Ambiguity Detection) If an antecedent is identified by the anaphora resolution rule, then is unambiguous; otherwise, is ambiguous. * If no anaphora resolution rule is triggered for a given pronoun occurrence, then no antecedent is predicted.\np 1 p 2 . . . { Legend p m c j , p j SpanBERT RE Pre-trained SpanBERT SpanBERT NLP Encode Input (i) SpanBERT-based CoNLL2011 Fine-tune (1) Fine-tune (2) DAMIR T 2 1 A\nrules produce the final results for anaphora resolution and ambiguity detection. We elaborate our alternative solutions next.\n\n\n(i) Solutions based on SpanBERT.\n\nWe employ the recent language model SpanBERT [36], introduced in Section 2.1, to develop solutions x and y, referred to as SpanBERT NLP and SpanBERT RE , respectively. We first fine-tune the pre-trained SpanBERT model to generate SpanBERT NLP using the CoNLL2011 dataset [34,53,72] -a large dataset of generic text with about 7,000 pronoun occurrences. This fine-tuning step -fine-tune (1) in Figure 3 -aims to adjust the parameters of the general SpanBERT model using the inputs and outputs of CoNLL2011 on the anaphora resolution task. Next, we fine-tune SpanBERT NLP to generate SpanBERT RE on a subset of DAMIR -a dataset of NL requirements, which we have constructed as part of our work. The second fine-tuning -fine-tune (2) in Figure 3 -enhances SpanBERT NLP by exposing it to examples of ambiguous and unambiguous pronouns from the RE domain. The hypothesis we would like to examine using the resulting solution, i.e., SpanBERT RE , is whether requirements-specific knowledge improves the accuracy of anaphoric ambiguity handling in RE. The CoNLL2011 and DAMIR datasets are discussed in Section 4.3.\n\nThe input to BERT and its variants needs to be tokenized and encoded into the same format used by the pre-trained models. The SpanBERT-based solutions, x and y, handle ambiguity using the respective rules provided in Table 1. There is a threshold for controlling the resolution results. We recommend = 0.9 based on our tuning, discussed in Section 4.5. For the example in Fig Thus, 1 would be detected as unambiguous. Note that x and y do no necessarily demarcate all possible text spans in , but rather only those that the solutions find relevant for anaphora resolution.\n\n(ii) Solutions based on supervised ML. We refer to our three ML-based solutions, z, { and |, as ML LF , ML FE and ML ensemble , respectively. ML LF is trained on 45 language features (LFs) collated from the existing NLP and RE literature on anaphora resolution [13,19,47,56,62,75,95]. The description of the LFs is provided online [82]. ML FE is trained on feature embeddings (FEs) which are contextual representations of the input, as explained in Section 2.1. ML ensemble is an ensemble classifier which combines the results of ML LF and ML FE .\n\nEach triple , , in the input to the ML-based solutions needs to be transformed into a feature vector. ML LF is built over 45-dimensional feature vectors encoding the LFs. The values for the LFs are computed using the NLP pipeline. The LFs characterize the referential relation between and its candidate antecedent , e.g., number agreement when both are plurals or singulars. ML FE is built over 768-dimensional feature vectors representing the FEs extracted from BERT [18] and SBERT [77]. The FEs capture the semantic and syntactic regularities of a text sequence [57]. There are other pretrained models, e.g., GloVe [67] and word2vec [59], that can be used for deriving the FEs. We favor embeddings derived from BERT (and SBERT), because these embeddings are contextual and known to better capture sequence-level semantics, including referential relations, when compared to the (non-contextual) embeddings from GloVe and word2vec [48]. In Section 4.5, we experiment with three different ways of deriving FEs from BERT.\n\nFor a triple , , , the intermediate output of the ML-based solutions is a predicted label that assumes one of the following three values: correct (meaning that refers to ), incorrect (meaning that does not refer to ) or inconclusive (meaning that the referential relation between and is not clear enough to be classified as either correct or incorrect). ML ensemble generates its intermediate output by combining the predictions from ML LF and ML FE . If ML LF and ML FE agree on the label predicted for a given triple, then ML ensemble assigns this label to the triple as well. If ML LF and ML FE disagree, then ML ensemble assigns to the triple the label predicted with the higher probability, but only if the difference between the two probabilities is greater than or equal to a threshold . If the probability difference falls short of , then ML ensemble assigns the label inconclusive. Based on our tuning presented in Section 4.5, we recommend = 0.1.\n\nFor ambiguity detection, we train the classifiers underlying our ML-based solutions on a subset of the DAMIR dataset, with datapoints covering all three outcome classes (correct, incorrect and inconclusive). Doing so enables the classifiers to distinguish unambiguous cases (correct and incorrect) from ambiguous ones (inconclusive). For anaphora resolution, we train the classifiers on only the datapoints labeled correct or incorrect. For this task, the datapoints labeled inconclusive are not useful and may even mislead the learning of correct and incorrect referential relations.\n\nThe rules used by our ML-based solutions for ambiguity handling are inspired by Yang et al. [95] and provided in Table 1. There is a threshold in the rules for controlling the detection results. We recommend = 0.5, based on the tuning results of Section 4.5. To illustrate the ML-based solutions, recall the example of Figure 2. For that example, the input would be five triples: 1 , 1 , 1 ; 1 \u2264 \u2264 5. For ambiguity detection, when trained and tuned as we explain in Section 4.5, ML LF predicts inconclusive for all triples, whereas ML FE predicts inconclusive for \u2208 {1, 2, 5} and incorrect for the rest. These predictions jointly lead to ML ensemble predicting inconclusive for all triples. Due to space, we do not show and argue through the probability scores that ML ensemble uses for deriving its results for our illustrative example. When the ambiguity-handling rules are applied to these intermediate results, none of the ML-based solutions provide a resolution for 1 , and all three detect 1 as ambiguous.\n\n\n(iii) Solution based on NLP coreference resolvers.\n\nWe refer to our final solution, numbered } in Figure 3, as NLP coref . This solution requires two independent coreference resolvers and can easily be implemented using the NLP pipeline. Let us denote the two resolvers by Coref 1 and Coref 2 . NLP coref , as shown in Table 1, combines the results of Coref 1 and Coref 2 via consensus. We instantiate Coref 1 and Coref 2 using two popular coreference resolvers [14]: the resolver in the CoreNLP toolkit [15,16] and the one in the SpaCy library [31]. For the example of Figure 2, NLP coref resolves 1 as referring to 14 (\"the request\"), thus deeming 1 as unambiguous.\n\n\nEMPIRICAL EVALUATION\n\nIn this section, we tune and assess the alternative solutions presented in Section 3.\n\n\nResearch Questions (RQs)\n\nOur evaluation tackles the following three research questions (RQs):\n\n\nRQ1. Which solution alternative is the most accurate for detecting anaphoric ambiguity in requirements?\n\nBy comparing the accuracy of the alternative solutions in Figure 3, we identify, in RQ1, the best-performing solution for detecting anaphoric ambiguity in requirements.\n\n\nRQ2. Which solution alternative is the most accurate for resolving anaphora in requirements?\n\nIn RQ2, we identify among the alternatives in Figure 3, the one that is most accurate for resolving anaphora. Having an accurate anaphora resolver is beneficial for RE in at least two ways: First, during requirements reviews, the machine-generated interpretations are a good indicator for the risk of misunderstandings. Notably, if the requirements analyst(s) settle on an interpretation that differs from the one (if any) offered by automated resolution, then there is an increased chance that other stakeholders, e.g. developers, may misinterpret the anaphora in question, with this misinterpretation potentially happening much later in the development process and thus potentially being more costly to fix. Second, for automated information extraction purposes, e.g., the extraction of conceptual models from requirements [8,79], one would typically want to use the results of automated anaphora resolution as-is and without additional manual processing. \n\n\nRQ3. What is the execution time of each solution alternative?\n\nExecution time is an important factor for ensuring practicality. RQ3 examines the execution time of each of the alternatives in Figure 3.\n\n\nImplementation and Availability\n\nWe use Python 3.8 [89] for implementing the preprocessing step (Section 3.2) as well as for the high-level scripting of the alternative solutions shown in Figure 3. The NLP pipeline and language-feature extraction are implemented using SpaCy 3.0.5 [ \n\n\nDatasets\n\nWe use three datasets in our evaluation. The first dataset has been curated using two external (non-author) annotators, as we elaborate momentarily. We call this dataset DAMIR, which stands for Dataset for Anaphoric aMbiguity In Requirements. The other two datasets are borrowed from the literature. These are CoNLL2011 [34,53,72], the NLP dataset on coreference resolution released in the 2011 edition of the Computational Natural Language Learning conference (CoNLL2011); and ReqEval [1], the RE dataset on anaphoric ambiguity released in the 2020 edition of the NLP4RE workshop. We use the CoNLL2011 dataset for fine-tuning the SpanBERT-based solutions. We use the ReqEval dataset to evaluate the solution alternatives. The DAMIR dataset is split into two portions, as we explain later; one portion is used for development and tuning, and the other portion is used for evaluating the solution alternatives. Table 2 provides summary statistics for DAMIR and the adapted versions of CoNLL2011 and ReqEval. Specifically, the table shows the number of unique sentences in each dataset, the number of pronouns marked as ambiguous and unambiguous, and the number of triples marked as correct, incorrect and inconclusive. We discuss the three datasets next. Note that the number of correct antecedents is greater than the number of unambiguous pronouns since the correct antecedent can occur in the context multiple times, in which case it will be counted more than once. DAMIR. We collected 22 industrial requirements specifications (RSs) from eight application domains: satellite communications, medicine, aerospace, security, digitization, automotive, railway, and defence. The requirements in these specifications were independently analyzed by two third-party annotators with expertise in linguistics. The first annotator, who has a Masters degree in cultural studies and multilingualism, had, prior to her engagement in our work, done a six-month internship, focusing on investigating the linguistic characteristics of requirements. The second annotator has a computer-science background with a Masters degree in quality management. This annotator further has a professional certificate in English translation. Both annotators received training on anaphoric ambiguity in requirements. The annotators' work spanned two months, with a total of 44 and 56 hours declared by the annotators, respectively. To mitigate fatigue effects, the annotators were encouraged to limit their periods of work to two hours at a time. In addition to the original RSs, we shared with the annotators the lists of automatically generated triples ( , ,\n\n). The annotators were asked to examine the list of triples associated with each pronoun occurrence . If they were confident that a candidate antecedent is the likely one in a triple, then they were instructed to label that triple as correct and all other triples involving as incorrect. In case of doubt, the annotators were asked to label all the triples involving as inconclusive. The annotators could also select the label invalid if some automatically generated triple had an error caused by, e.g., inaccurate splitting of the sentence constituents. All such invalid triples were filtered out.\n\nTo construct the DAMIR dataset, we checked the annotations for the triples associated with each . If the annotators agreed that a triple should be labeled as correct (meaning that they also agreed that the other triples for should be labeled as incorrect), we considered as unambiguous. In this case, the triples associated with received the same labels as indicated by the annotators. If the annotators disagreed on the label for any triple associated with , then we regarded as ambiguous, and consequently, labeled all the associated triples as inconclusive. We identified two types of disagreement between the annotators: (i) one annotator found ambiguous and labeled its triples as inconclusive, while the other annotator found unambiguous and labeled some triple as correct; or (ii) the annotators labeled two different triples as correct, i.e., they unconsciously disagreed on the interpretation. We define as an agreement any case other than (i) and (ii) above. Using Fleiss' kappa ( ) [27], we obtain an inter-rater agreement of = 0.54, which indicates moderate agreement [45] between the annotators. We note that for datasets related to ambiguity analysis, this level of agreement is to be expected [20], considering that disagreements are indicators for ambiguous cases.\n\nWe split the pronoun occurrences in DAMIR into two disjoint subsets: DAMIR and DAMIR . The contexts for the elements in DAMIR are also distinct from those for the elements in DAMIR , i.e., all triples associated with a pronoun including the candidate antecedents of appear in either DAMIR or DAMIR but not in both. DAMIR contains 80% of the dataset and is used for developing and tuning the solutions. DAMIR contains the remaining 20% and is used for evaluation. Our empirical evaluation, presented in Section 4, is conducted using DAMIR only. CoNLL2011. We extracted from the original CoNLL2011 dataset only the annotations relevant to anaphoric ambiguity analysis, i.e., the annotations where a pronoun has been labeled with the antecedent it refers to. We used the source documents released alongside CoNLL2011 in order to identify a context of size two for each pronoun occurrence. To adapt this dataset to our work, we generated , , triples through preprocessing (Section 3.2). We then assigned labels to the triples in a backward manner: A triple , , is labeled correct if represents the selected antecedent for . Otherwise, the triple is labeled incorrect. We note that no triple is marked as inconclusive here, since CoNLL2011 was not created for ambiguity detection; all pronoun occurrences in CoNLL2011 are regarded as unambiguous. ReqEval. The ReqEval dataset is composed of a set of independent requirements, each with at least one pronoun occurrence. Each pronoun occurrence is labeled as either ambiguous or unambiguous. In the latter case, the correct antecedent is provided. To adapt ReqEval to our work, we generated , , triples through preprocessing. In contrast to the DAMIR and CoNLL2011 datasets where we set the context size to two when generating the triples, for ReqEval, we use a context of size one. This is because we could not ascertain that the requirements were in any particular order; a context beyond the immediate sentence where a pronoun appears was not intended in ReqEval. For each ambiguous , we assigned the label inconclusive to all triples associated with . For each unambiguous , we assigned the label correct to the triple where matches the antecedent provided for and incorrect to all other triples.\n\n\nEvaluation Metrics\n\nAnaphoric ambiguity detection. We evaluate ambiguity detection using precision (P), recall (R) and F -score computed as = /( + ), = /( + ), and = (1 + 2 )( * )/( 2 * + ), respectively. A true positive (TP) is a case where the solution correctly predicts as ambiguous. A true negative (TN) is a case where the solution correctly predicts as unambiguous. A false positive (FP) is a case where the solution falsely predicts as ambiguous, and a false negative (FN) is a case where the solution falsely predicts as unambiguous. As is common for many requirements analysis tasks including ambiguity analysis [11,95], we favor recall over precision. We thus use and report F 2 -scores (i.e., = 2). Anaphora resolution. We evaluate resolution using the following metric, which we call success rate: the ratio of correctly resolved pronoun occurrences to the total number of pronoun occurrences labeled as unambiguous in the ground truth. We apply two modes to decide whether the antecedent identified by a solution is correct as per the ground truth. In the full matching mode, we consider the identified antecedent to be correct only when it fully matches the text span in the ground truth. In the partial matching mode, we consider the identified antecedent to be correct if it overlaps with the text span in the ground truth. For example, the identified antecedent \"all approval requests\" compared to \"approval requests\" (in the ground truth) is considered as correctly resolved in partial matching but not in full matching. The rationale for considering partial matching is that, when the matching results are destined for a manual review, pinpointing the location of the text span of interest is highly useful, even though the identified span may be incomplete or only partially correct.\n\n\nSolutions Tuning\n\nIn this section, we describe the tuning of our solutions. The resulting tuned solutions are used in Section 4.6 for answering RQ1-3. Tuning SpanBERT. We fine-tune the SpanBERT-based solutions to maximize F 2 -score for ambiguity detection. We follow the recommendations in the literature for fine-tuning pre-trained language models [18,36,68]. To generate SpanBERT (solution x in Figure 3), we fine-tune SpanBERT on the CoNLL2011 dataset for 20 epochs with 2e-5 learning rate and 32 batch size. We then generate SpanBERT (solution y in Figure 3) by fine-tuning SpanBERT for 3 epochs on the DAMIR dataset with the same learning rate and batch size as used in solution x.\n\nWe apply a threshold as the lower bound for accepting a text span identified by solution x or y as the antecedent of a pronoun occurrence (see Section 3.3). We tune on DAMIR via exhaustive search. Specifically, we experiment with 10 values [0.1, 0.2, \u00b7 \u00b7 \u00b7 , 1.0]. The optimal value is = 0.9.\n\nTuning ML. We optimize ML LF and ML FE (solutions z and { in Figure 3) on DAMIR . We consider different configurations that arise from varying the ML classification algorithm and the FEs.\n\nFor both z and {, we experiment with seven widely used classification algorithms, namely decision tree (DT), feedforward neural network (FNN), k-nearest neighbor (kNN), logistic regression (LR), na\u00efve Bayes (NB), random forest (RF) and support vector machine (SVM) [50,74,95]. Following best practice [18,77], we explore four options for extracting FEs for solution {. In the first option, We further tune the solutions for maximizing the success rate of anaphora resolution (using only the datapoints labeled correct or incorrect, and excluding those labeled inconclusive). Since correct is the minority class in anaphora resolution, we downsize the incorrect class using random under-sampling [35]. We evaluate all configurations using 10-fold cross-validation [91]. We note that standard 10-fold cross-validation would partition DAMIR at the triple level, implying that some of the triples associated with a pronoun occurrence could land in the training set and the others in the test set. Such splitting of the triples associated with the same pronoun is undesirable. We therefore develop a variant of 10-fold cross-validation where we first group the datapoints in DAMIR by pronoun occurrence, perform random shuffling and only then split the dataset into ten equal partitions. This ensures that all the triples associated with a single pronoun occurrence are placed in one partition only, used either for training or for testing. Tables 3 and 4 list the various configurations and the results obtained for each. We note that, in Table 4, we apply the full matching  mode for computing accuracy. This is because the ML-based solutions predict an exact candidate antecedent from a pre-generated list instead of demarcating a text span. The best results for each solution are highlighted in bold. We select as the best-performing configuration for ML LF the NB algorithm for ambiguity detection, and the SVM algorithm for anaphora resolution. We select as the best-performing configuration for ML FE the RF algorithm trained over FE 4 for ambiguity detection, and the FNN algorithm trained over FE 1 for anaphora resolution. Following the above decisions, we apply grid search [9] to optimize the hyperparameters of the best-performing configurations; hyperparameter optimization for all possible configurations would have been too expensive due to the high dimensionality of feature embeddings. Finally, there are two fixed thresholds in the ML-based solutions, and , which we tune after hyperparameter optimization. The role of is the same as that of , discussed earlier for the SpanBERT-based solutions. The threshold is tuned in the same manner as . The optimal value is = 0.5. As for , the threshold is used by ML ensemble to ensure that one candidate antecedent is not favored over another when the predicted probabilities are too close (see Section 3.3). We tune using exhaustive search on DAMIR and over the same ten values tried for and . The optimal value is = 0.1.\n\n\nAnswers to the RQs\n\n\nRQ1.\n\nWhich solution alternative is the most accurate for detecting anaphoric ambiguity in requirements? Table 5 (left side) shows the precision (P), recall (R) and F 2 -score (F 2 ) of the different solutions measured on the DAMIR and ReqEval datasets.\n\nAs shown by the table, all alternatives perform better on ReqEval than DAMIR . The difference in accuracy is particularly notable for the precision of SpanBERT-based solutions. We believe that this difference can be explained by the different context sizes used for pronoun occurrences in the two datasets. In ReqEval, the context is one sentence with an average length of 25 words, where both the pronouns and their antecedents occur. In this dataset, the average number of candidate antecedents for a pronoun is four. In contrast, in DAMIR , the context is composed of two sentences with an average of 47 words. For this dataset, the average number of candidate antecedents is nine, i.e., more than twice as many as for ReqEval. Parsing larger contexts and having to deal with more candidate antecedents allow more room for error. Overall, we believe that the results for DAMIR are more reflective of practice, since analysts often consider a broader context for a pronoun than the sentence where the pronoun appears. As noted earlier, this broader context information is unavailable in ReqEval, hence our evaluation using single sentences as context in this dataset.\n\nAs seen from Table 5, the ML-based solutions have the best recall (and also precision) on both datasets. We believe that the superior accuracy of the ML-based solutions has to do with the fact that these solutions are explicitly trained to distinguish ambiguous and unambiguous pronoun occurrences. We further observe that the choice of features in ML-based solutions, i.e., LFs versus FEs, has little impact on the accuracy of ambiguity detection. Overall ML ensemble leads to the best F 2 -scores, including perfect recall on both datasets. In terms of precision, the ML-based solutions are the superior ones as well. We note that ML LF and ML FE neither achieve perfect recall on ReqEval nor offer tangible gains over ML ensemble in terms of precision. Across ReqEval and DAMIR , ML ensemble has an average precision of 59.9%. We believe that this level of precision is acceptable in practice. The implication of a \u224860% precision is the manual effort needed for filtering out the pronouns wrongly marked as ambiguous (FPs). Discarding FPs is still easier and requires less effort than finding FNs, i.e., the ambiguous cases that are missed.\n\nThe answer to RQ1 is that ML ensemble (solution | in Figure 3) with an average precision of \u224860% and a recall of 100% is the most accurate solution for detecting anaphoric ambiguity in requirements.  ReqEval. We apply both the full and partial matching modes (see Section 4.4). We note though that only full matching applies to the ML-based solutions, since these solutions identify the antecedent of a pronoun from a pre-calculated list of candidate antecedents. As Table 5 shows, for anaphora resolution, no solution outperforms all the others on both datasets. For instance, the ML-based solutions (z -|) perform well on one dataset but not the other.\n\n\nRQ2. Which solution alternative is the most accurate for resolving anaphora in requirements?\n\nML ensemble is the best-performing solution on DAMIR , but performs rather poorly on ReqEval. As highlighted in the table, the SpanBERT-based solutions clearly outperform all other solutions in partial matching mode, with SpanBERT RE achieving the highest success rate. We thus believe that SpanBERT RE is the most useful solution in terms of providing assistance to analysts during manual requirements reviews.\n\nThe answer to RQ2 is that SpanBERT RE (solution y in Figure 3) with an average success rate of \u224898% is the most accurate solution for resolving anaphora in requirements.\n\n\nRQ3. What is the execution time of each solution alternative?\n\nWe consider the execution time of our solutions both from the perspective of a solution developer and that of an end-user.\n\nA developer would be interested in how long it takes to tune the SpanBERT-and ML-based solutions, as discussed in Section 4.5. Tuning is a one-off activity and not pertinent to end-users. We used Google Colaboratory [12] for developing and tuning the SpanBERTbased solutions. Fine-tuning SpanBERT on CoNLL2011 (with 6,757 pronouns) to generate SpanBERT NLP took \u22484 hours. Fine-tuning SpanBERT NLP on DAMIR (with 533 pronouns) to generate SpanBERT RE took \u224823 minutes. For tuning the ML-based solutions, we used a workstation equipped with a 12-core processor (AMD Ryzen 9 5900X 3.7 GHz) and 64 GB of memory. Recall from Section 4.5 that the ML-based solutions are tuned separately for ambiguity detection and anaphora resolution. Tuning time is directly impacted by the best-performing configuration picked for each task (which will then be subjected to hyperparamater optimization). Tuning ML LF required 30 minutes for detection and 53 minutes for resolution. Tuning ML FE was more expensive, requiring 6.5 hours for detection and 45 minutes for resolution.\n\nTo measure execution time from an end-user's perspective, we used a normal laptop with a 2.3 GHz CPU and 16 GB of memory. We picked from our evaluation set a random selection of 100 pronoun occurrences. These occurrences span 96 requirements sentences and induce 842 triples. We combined the 96 sentences into a single document. The resulting document is not meant to represent a real-world RS. Rather, we want this document to emulate a representative situation for pronoun occurrences (e.g., in terms of having different pronoun types and different numbers of candidate antecedents in context). In a real setting, before one applies any of our solutions to an RS, all the material in the RS other than the sentences within the context of some pronoun occurrence can be removed.\n\nThe resulting document was used for measuring per-pronoun execution time. The measured times are representative for larger samples as well, with the overall execution time increasing linearly as the number of pronoun occurrences increases.\n\nThe answer to RQ3 is as follows. The average time (in seconds) required for handling an individual pronoun occurrence is: 1.5s using SpanBERT NLP or SpanBERT RE ; 8s for detection and 8s for resolution using ML LF ; 7.5s for detection and 6s for resolution using ML FE ; 14.5s for detection and 13s for resolution using ML ensemble ; and 7s using NLP Coref .\n\nThe practical implication of these execution times is as follows: Based on the literature [25], one can expect that 20% of the requirements in a given RS would contain (pronominal) anaphora. Processing a large RS with, say, 2000 requirements would then require processing 400 (give or take) requirements sentences. Extrapolating from our datasets, one can expect 1.2 pronouns per sentence and thus 480 pronouns in our hypothetical RS with 2000 requirements. Using the most accurate solutions from RQ1 and RQ2, one would require about 2 hours for detecting ambiguity using ML ensemble and about 4 minutes for resolving anaphora using SpanBERT RE . The execution time of ambiguity detection can be cut by almost half if one applies either ML LF or ML FE , potentially at the cost of a slight decrease in recall. These execution times are acceptable for offline processing, e.g., during a break or overnight. As for online (i.e., interactive) processing, we observe that, at any given time, an analyst likely works on only a small fragment of a large document. For interactive usage, anaphoric ambiguity handling can be localized to the document segment (e.g., sentences) that the analyst is working on.\n\n\nDiscussion\n\nBelow, we make two remarks: the first one is the overall conclusion of our empirical evaluation; the second one is a lesson learned about using pre-trained language models in RE.\n\n(1) Given the accuracy results (RQ1 and RQ2) and the execution times (RQ3), we propose a hybrid solution for handling anaphoric ambiguity in requirements. This hybrid solution combines supervised ML for ambiguity detection and SpanBERT for anaphora resolution. For the detection task, ML ensemble is the most accurate. One may nonetheless elect to use the slightly less accurate ML LF or ML FE to reduce execution time. For the resolution task, we recommend SpanBERT RE . This solution is highly accurate in pinpointing the location of antecedents.\n\n(2) We benefited from the CoNLL2011 dataset for the initial finetuning of SpanBERT, before further fine-tuning it with RE-specific data. Our preliminary experimentation indicated that, without the intermediate fine-tuning step over CoNLL2011, SpanBERT would not lead to a viable solution through fine-tuning on our RE datasets alone. We believe that, due to the general scarcity of tailor-made datasets for RE tasks, one should take into account the possibility that intermediate fine-tuning data may be required, when attempting to design requirements automation solutions based on pre-trained language models. To this end, RE researchers may need to look for complementary datasets in other communities, e.g., NLP, to be able to get the best traction from pre-trained language models.\n\n\nTHREATS TO VALIDITY\n\nThe validity concerns most pertinent to our evaluation are internal and external validity. Internal Validity. The main concern regarding internal validity is bias. This concern applies mainly to the DAMIR dataset, which was developed on the authors' initiative. To mitigate bias, the labelling of DAMIR was performed exclusively by two independent (nonauthor) annotators. To avoid learning bias, the annotators were never exposed to either the design or the results of any of the alternative solutions in our study. External Validity. We evaluated all solutions on two datasets -DAMIR and ReqEval, the latter being an external dataset. The individual solutions show comparable results across the two datasets. In terms of domain coverage, DAMIR spans eight different application domains. The consistency of the results across the DAMIR and ReqEval datasets, taken alongside the domain coverage of DAMIR, provides confidence about the generalizability of our empirical findings. That said, further evaluation using additional documents and user studies can help further mitigate external-validity threats.\n\n\nCONCLUSION\n\nIn this paper, we developed and evaluated six alternative automation solutions for handling anaphoric ambiguity in requirements. Each solution addresses both the detection of anaphoric ambiguity as well as the resolution of anaphora. Our motivation for conducting a multi-solution study stems from the availability of competing NLP and ML technologies that we could build on. Without an empirical examination of different solution designs, we would not be able to ascertain which technologies would be the most suitable for our analytical needs. This situation is not limited to our work per se; choosing the right set of technologies for the task at hand is a consideration that one increasingly has to contend with in AI-enabled automation.\n\nOur evaluation involved two datasets with a total of \u22481,350 industrial requirements. Our results indicate that, for anaphoric ambiguity detection, supervised ML is more accurate than both SpanBERT (a variant of BERT) and a solution built using off-the-shelf coreference resolvers. Our best solution for ambiguity detection has an average precision of \u224860% and a recall of 100%. Differently from the ambiguity detection task, for anaphora resolution, SpanBERT yields the best solution with an average success rate of \u224898%. Based on these results, we recommend a hybrid solution for anaphoric ambiguity handling, where ambiguity detection and anaphora resolution are realized using different technological platforms.\n\nAnaphoric ambiguity is an important but still a single aspect of the broader problem of ambiguity. In requirements engineering, where ambiguity handling is closely associated with quality assurance, analysts are likely interested in a more holistic treatment that addresses a wider range of ambiguity types. In the future, we would like to expand our work to other ambiguity types, particularly semantic ones, that are still under-explored. Furthermore, and to more conclusively evaluate the usefulness of our current results, we plan to conduct user studies involving practicing engineers.\n\n\"\nS&T\" and \"DBS\" stand for \"Surveillance and Tracking\" and \"Database Server\", respectively.\n\nFigure 1 :\n1Example of Anaphoric Ambiguity.\n\nr 2 [Figure 2 :\n22If the request contains storage parameters, it shall create a configuration record from the parameters.] r 1 [ The S&T component shall send all approval requests to the DBS. Illustration of our Notation.\n\n\n, tuples. O: Tuples of the form , , where is a text span and is the probability of being the antecedent for . R: (Anaphora Resolution * ) For a pronoun , if there is exactly one in such that is \u2265 a fixed (empirically tuned) threshold, then is the most likely antecedent of . (Ambiguity Detection) If such is identified, then is unambiguous; otherwise is ambiguous. z { | I: , , triples. O: Tuples of the form \u2113 ,\n\n\ninput to x and y is 1 , 1 , encoded as [CLS] 1 [SEP] 1 . The intermediate output of both solutions would be a tuple like 1 =\"the S&T component\", pr 1 = 0.99 . The text span 1 would be the antecedent of 1 , since it is identified with a probability \u2265 0.9.\n\nFE 1 ,\n1the embeddings are extracted from SBERT. The other three options, FE 2 -FE 4 , are based on embeddings from BERT. FE 2 are the embeddings from the second-to-last hidden layer; FE 3 are the concatenation of the embeddings from the last four hidden layers; and FE 4 are the summation of the embeddings from these four layers.The various options explained above induce seven configurations for solution z and 28 for solution {. We tune solutions z and { for maximizing F 2 -score for ambiguity detection in DAMIR .\n\nTable 1\n1outlines for each solution the inputs, the intermediate outputs and the rules for processing the intermediate outputs. TheInput RS \n\nPreprocess \n\nAmbiguous? \nMost likely antecedent \n\nA: Tuples of the form \n(context and pronoun) \nB: Triples of the form \n(context, pronoun, candidate antecedent) \nC: Contexts of pronoun occurrences \nLFs: language features \nFEs: feature embeddings \n\nc j , p j , a jk \n\nc j \n\n[CLS]c j [SEP]p j \n\nNLP Coref \n\n6 \n\n(iii) NLP-based \n\nCoref 1 \nCoref 2 \n\nC \n\nML LF \n\nML FE \nExtract \nFeatures \n\n(ii) ML-based \n\nML ensemble \n\n3 \n\n4 \n\n5 \n\nLFs \n\nFEs \n\nB \nC \n\nAmbiguous? \nMost likely antecedent \nAmbiguous? \nMost likely antecedent \nAmbiguous? \nMost likely antecedent \n\nOutput \n\n\n\nTable 1 :\n1Inputs, Intermediate Outputs and Ambiguity-handling Rules for Solution Alternatives.\n\n\nSpecifically, we encode each tuple , as [CLS] [SEP] . Two special tokens are automatically added by BERT's tokenizer: [CLS] to represent the classification output and [SEP] to separate from . Any repeated occurrence of the same pronoun is replaced with # , where \u2265 1 is a unique identifier. The multiple occurrences are then encoded as [CLS] [SEP] # . The [CLS] token is relevant for SpanBERT's pre-training, which is not part of our analysis. [CLS] thus has no significance for our analytical purposes.\n\nTable 2 :\n2Summary Statistics for our Datasets.DAMIR ReqEval CoNLL2011 \n\nUnique Sentences \n1,251 \n98 \n6,888 \n\nPronouns \nAmbiguous \n342 \n62 \n-\nUnambiguous \n395 \n47 \n6,757 \n\nTriples \n\nCorrect \n404 \n66 \n6,866 \nIncorrect \n2,814 \n104 \n14,666 \nInconclusive \n3,448 \n272 \n-\n\n\n\n\nhttps://huggingface.co/) and operated in PyTorch[65]. For the ML-based solutions, we use Scikit-learn 0.24.1[66]. We use the Transformers library for extracting embeddings. BERT's embeddings are extracted from the bert-base-cased model. For extracting SBERT's embeddings, we use the paraphrase-MPNet-base-v231], NLTK 3.5 [49], \nStanza 1.2 [73], and CoreNLP 4.2.2 [51]. The SpanBERT-based solu-\ntions use the Transformers 4.6.1 library [92] provided by Hugging \nFace (model [85], also available in the Transformers library. Finally, for \nimplementing the solution that uses existing NLP resolvers, we use \nthe coreference resolution modules available in SpaCy 3.0.5 [31] \nand CoreNLP 4.2.2 [15, 16]. The different solutions proposed in this \npaper are implemented using Jupyter Notebooks [42]. \n\n\n\nTable 3 :\n3Accuracy of Different Configurations of Solutions z and { for Anaphoric Ambiguity Detection.DT \nFNN \nkNN \nLR \nNB \nRF \nSVM \n\nP \nR \nF 2 \nP \nR \nF 2 \nP \nR \nF 2 \nP \nR \nF 2 \nP \nR \nF 2 \nP \nR \nF 2 \nP \nR \nF 2 \n\nz LF 50.9 94.0 80.3 50.2 96.2 81.2 50.3 91.0 78.3 49.5 89.0 76.6 50.4 99.7 83.3 49.9 94.3 80.0 50.0 94.4 80.1 \n\n{ \n\nFE 1 51.0 86.3 75.7 51.6 99.2 83.6 50.2 98.2 82.4 50.3 95.3 80.6 50.8 98.3 82.8 50.3 94.5 80.3 50.0 97.2 81.7 \nFE 2 49.8 89.0 76.7 51.1 98.0 82.7 49.8 96.8 81.4 50.4 95.9 81.2 50.1 96.9 81.5 51.1 96.7 82.0 50.4 97.7 82.2 \nFE 3 51.9 89.0 77.7 49.9 94.0 79.8 50.2 97.7 82.1 51.2 97.2 82.3 50.6 98.7 82.9 50.6 95.5 80.9 50.4 97.7 82.2 \nFE 4 56.9 87.3 77.5 55.5 96.9 83.6 55.7 98.3 84.7 52.5 90.4 78.3 55.0 95.3 82.8 57.7 100 85.9 56.0 92.6 80.3 \n\n \u2020 FE 1 : FEs from SBERT, FE 2 : FEs from BERT's second-to-last layer, FE 3 : concatenation of FEs from BERT's last four layers, FE 4 : summation \nof FEs from the same four layers. \n\n\n\nTable 4 :\n4Success Rate of Different Configurations of Solutions z and { for Anaphora Resolution.DT \nFNN kNN \nLR \nNB \nRF \nSVM \n\nz \n\nLF \n32.2 \n81.4 \n61.0 \n86.4 \n18.6 \n71.1 \n91.5 \n\n{ \n\nFE 1 \n6.8 \n74.6 \n13.6 \n66.1 \n62.7 \n66.1 \n69.4 \nFE 2 \n0.0 \n59.3 \n16.9 \n66.1 \n55.9 \n67.8 \n71.1 \nFE 3 \n8.5 \n61.0 \n16.9 \n66.1 \n18.6 \n67.8 \n66.1 \nFE 4 \n6.8 \n57.6 \n15.2 \n62.7 \n52.5 \n57.6 \n66.1 \n\n\n\nTable 5 (\n5right side) shows the resolution success rate (defined in Section 4.4) for DAMIR and ReqEval. Our evaluation covers 96 unambiguous pronouns in DAMIR and 62 in\n\nTable 5 :\n5Accuracy Results for Different Anaphoric Ambiguity Handling Solutions. Precision, Recall and F 2 of Ambiguity Detection (RQ1) Success Rate (%) of Anaphora Resolution (RQ2) For each dataset, the best values of P, R, F 2 and success rate are highlighted in bold.DAMIR \nReqEval \nDAMIR \nReqEval \n\nP (%) \nR (%) \nF 2 (%) \nP (%) \nR (%) \nF 2 (%) \nFull \nPartial \nFull \nPartial \n\nx SpanBERT \n\n40.0 \n81.8 \n67.6 \n60.2 \n75.8 \n72.1 \n73.5 \n88.2 \n97.8 \n97.8 \n\ny SpanBERT \n\n36.9 \n77.2 \n63.3 \n57.6 \n96.8 \n85.2 \n68.9 \n96.1 \n97.8 \n100 \n\nz ML \n\n57.6 \n100 \n87.2 \n61.8 \n98.9 \n88.3 \n81.2 \n-\n57.4 \n-\n\n{ ML \n\n57.5 \n100 \n87.1 \n62.2 \n98.2 \n88.0 \n51.0 \n-\n82.9 \n-\n\n| ML ensemble \n\n58.2 \n100 \n87.5 \n61.5 \n100 \n88.9 \n82.3 \n-\n57.4 \n-\n\n} NLP Coref \n\n52.4 \n48.5 \n49.2 \n56.7 \n51.5 \n52.5 \n52.5 \n52.5 \n39.6 \n51.7 \n\n \u2020 \nhttps://tinyurl.com/mww2w46t\n\nPreface: 3rd Workshop on Natural Language Processing for Requirements Engineering (NLP4RE'20). Sallam Abualhaija, Davide Fucci, Fabiano Dalpiaz, Xavier Franch, Joint Proceedings of REFSQ-2020 Workshops, Doctoral Symposium, Live Studies Track, and Poster Track co-located with the 26th International Conference on Requirements Engineering: Foundation for Software Quality. Sallam Abualhaija, Davide Fucci, Fabiano Dalpiaz, and Xavier Franch. 2020. Preface: 3rd Workshop on Natural Language Processing for Requirements En- gineering (NLP4RE'20). In Joint Proceedings of REFSQ-2020 Workshops, Doctoral Symposium, Live Studies Track, and Poster Track co-located with the 26th Interna- tional Conference on Requirements Engineering: Foundation for Software Quality.\n\nReqEval: The shared task on anaphora ambiguity detection and disambiguation. Sallam Abualhaija, Davide Fucci, Fabiano Dalpiaz, Xavier Franch, Alessio Ferrari, Sallam Abualhaija, Davide Fucci, Fabiano Dalpiaz, Xavier Franch, and Alessio Ferrari. 2020. ReqEval: The shared task on anaphora ambiguity detection and disambiguation. https://github.com/frieden84/nlp4re-reqeval last accessed: July 2021.\n\nMachine learning for text. C Charu, Aggarwal, SpringerCharu C Aggarwal. 2018. Machine learning for text. Springer.\n\nOn the Systematic Analysis of Natural Language Requirements with CIRCE. Vincenzo Ambriola, Vincenzo Gervasi, Automated Software Engineering. 131Vincenzo Ambriola and Vincenzo Gervasi. 2006. On the Systematic Analysis of Natural Language Requirements with CIRCE. Automated Software Engineering 13, 1 (2006).\n\nAutomated Checking of Conformance to Requirements Templates Using Natural Language Processing. Chetan Arora, Mehrdad Sabetzadeh, Lionel Briand, Frank Zimmer, IEEE Transactions on Software Engineering (TSE'15). 4110Chetan Arora, Mehrdad Sabetzadeh, Lionel Briand, and Frank Zimmer. 2015. Automated Checking of Conformance to Requirements Templates Using Natural Language Processing. IEEE Transactions on Software Engineering (TSE'15) 41, 10 (2015).\n\nAutomated Extraction and Clustering of Requirements Glossary Terms. Chetan Arora, Mehrdad Sabetzadeh, Lionel Briand, Frank Zimmer, IEEE Transactions on Software Engineering. 4310Chetan Arora, Mehrdad Sabetzadeh, Lionel Briand, and Frank Zimmer. 2017. Automated Extraction and Clustering of Requirements Glossary Terms. IEEE Transactions on Software Engineering 43, 10 (2017).\n\nRUBRIC: A Flexible Tool for Automated Checking of Conformance to Requirement Boilerplates. Chetan Arora, Mehrdad Sabetzadeh, Lionel Briand, Frank Zimmer, Raul Gnaga, Proceedings of the 9th joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE'13). the 9th joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE'13)Chetan Arora, Mehrdad Sabetzadeh, Lionel Briand, Frank Zimmer, and Raul Gnaga. 2013. RUBRIC: A Flexible Tool for Automated Checking of Conformance to Requirement Boilerplates. In Proceedings of the 9th joint meeting of the Euro- pean Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE'13).\n\nAn Active Learning Approach for Improving the Accuracy of Automated Domain Model Extraction. Chetan Arora, Mehrdad Sabetzadeh, Shiva Nejati, Lionel Briand, ACM Transactions on Software Engineering and Methodology. 281Chetan Arora, Mehrdad Sabetzadeh, Shiva Nejati, and Lionel Briand. 2019. An Active Learning Approach for Improving the Accuracy of Automated Domain Model Extraction. ACM Transactions on Software Engineering and Methodology 28, 1 (2019).\n\nAlgorithms for hyper-parameter optimization. James Bergstra, R\u00e9mi Bardenet, Yoshua Bengio, Bal\u00e1zs K\u00e9gl, Advances in neural information processing systems. 24James Bergstra, R\u00e9mi Bardenet, Yoshua Bengio, and Bal\u00e1zs K\u00e9gl. 2011. Algorithms for hyper-parameter optimization. Advances in neural information processing systems 24 (2011).\n\nD Berry, E Kamsties, M Krieger, From Contract Drafting to Software Specification: Linguistic Sources of Ambiguity, A Handbook. D. Berry, E. Kamsties, and M. Krieger. 2003. From Contract Drafting to Software Specification: Linguistic Sources of Ambiguity, A Handbook. http://se.uwaterloo. ca/~dberry/handbook/ambiguityHandbook.pdf\n\nEmpirical evaluation of tools for hairy requirements engineering tasks. M Daniel, Berry, Empirical Software Engineering. 266Daniel M Berry. 2021. Empirical evaluation of tools for hairy requirements engineering tasks. Empirical Software Engineering 26, 6 (2021).\n\nBuilding machine learning and deep learning models on Google cloud platform: A comprehensive guide for beginners. Ekaba Bisong, ApressEkaba Bisong. 2019. Building machine learning and deep learning models on Google cloud platform: A comprehensive guide for beginners. Apress.\n\nBART: A multilingual anaphora resolution system. Samuel Broscheit, Massimo Poesio, Simone Paolo Ponzetto, Kepa Joseba Rodriguez, Lorenza Romano, Olga Uryupina, Yannick Versley, Roberto Zanoli, Proceedings of the 5th international workshop on semantic evaluation. the 5th international workshop on semantic evaluationSamuel Broscheit, Massimo Poesio, Simone Paolo Ponzetto, Kepa Joseba Ro- driguez, Lorenza Romano, Olga Uryupina, Yannick Versley, and Roberto Zanoli. 2010. BART: A multilingual anaphora resolution system. In Proceedings of the 5th international workshop on semantic evaluation.\n\nA Combined Method for Usage of NLP Libraries Towards Analyzing Software Documents. Xinyun Cheng, Xianglong Kong, Li Liao, Bixin Li, International Conference on Advanced Information Systems Engineering. Xinyun Cheng, Xianglong Kong, Li Liao, and Bixin Li. 2020. A Combined Method for Usage of NLP Libraries Towards Analyzing Software Documents. In Interna- tional Conference on Advanced Information Systems Engineering.\n\nDeep Reinforcement Learning for Mention-Ranking Coreference Models. Kevin Clark, Christopher D Manning, Empirical Methods on Natural Language Processing. Kevin Clark and Christopher D. Manning. 2016. Deep Reinforcement Learning for Mention-Ranking Coreference Models. In Empirical Methods on Natural Language Processing.\n\nImproving Coreference Resolution by Learning Entity-Level Distributed Representations. Kevin Clark, Christopher D Manning, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsKevin Clark and Christopher D. Manning. 2016. Improving Coreference Resolu- tion by Learning Entity-Level Distributed Representations. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.\n\nDetecting terminological ambiguity in user stories: Tool and experimentation. Fabiano Dalpiaz, Ivor Van Der, Sjaak Schalk, Fatma Brinkkemper, Garm Aydemir, Lucassen, Information and Software Technology. 110Fabiano Dalpiaz, Ivor van der Schalk, Sjaak Brinkkemper, Fatma Aydemir, and Garm Lucassen. 2019. Detecting terminological ambiguity in user stories: Tool and experimentation. Information and Software Technology 110 (2019).\n\nBERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:arXiv:1810.04805Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of deep bidirectional transformers for language understanding. (2018). arXiv:arXiv:1810.04805\n\nApplying machine learning toward an automatic classification of it. Richard Evans, Literary and linguistic computing. 16Richard Evans. 2001. Applying machine learning toward an automatic classifica- tion of it. Literary and linguistic computing 16, 1 (2001), 45-58.\n\nUsing domain-specific corpora for improved handling of ambiguity in requirements. Sallam Saad Ezzini, Chetan Abualhaija, Mehrdad Arora, Lionel C Sabetzadeh, Briand, 2021 IEEE/ACM 43rd International Conference on Software Engineering. Saad Ezzini, Sallam Abualhaija, Chetan Arora, Mehrdad Sabetzadeh, and Lionel C Briand. 2021. Using domain-specific corpora for improved handling of ambiguity in requirements. In 2021 IEEE/ACM 43rd International Conference on Software Engineering.\n\nThe linguistic approach to the natural language requirements quality: Benefit of the use of an automatic tool. Fabrizio Fabbrini, Mario Fusani, Stefania Gnesi, Giuseppe Lami, Proceedings of the 26th Annual NASA Goddard Software Engineering Workshop. the 26th Annual NASA Goddard Software Engineering WorkshopFabrizio Fabbrini, Mario Fusani, Stefania Gnesi, and Giuseppe Lami. 2001. The linguistic approach to the natural language requirements quality: Benefit of the use of an automatic tool. In Proceedings of the 26th Annual NASA Goddard Software Engineering Workshop.\n\nRapid requirements checks with requirements smells: Two case studies. Henning Femmer, Daniel M\u00e9ndez Fern\u00e1ndez, Elmar Juergens, Michael Klose, Ilona Zimmer, J\u00f6rg Zimmer, Proceedings of the 1st International Workshop on Rapid Continuous Software Engineering. the 1st International Workshop on Rapid Continuous Software EngineeringHenning Femmer, Daniel M\u00e9ndez Fern\u00e1ndez, Elmar Juergens, Michael Klose, Ilona Zimmer, and J\u00f6rg Zimmer. 2014. Rapid requirements checks with require- ments smells: Two case studies. In Proceedings of the 1st International Workshop on Rapid Continuous Software Engineering.\n\nRapid quality assurance with Requirements Smells. Henning Femmer, Daniel M\u00e9ndez Fern\u00e1ndez, Stefan Wagner, Sebastian Eder, Journal of Systems and Software. 123Henning Femmer, Daniel M\u00e9ndez Fern\u00e1ndez, Stefan Wagner, and Sebastian Eder. 2017. Rapid quality assurance with Requirements Smells. Journal of Systems and Software 123 (2017).\n\nAn NLP approach for cross-domain ambiguity detection in requirements engineering. Alessio Ferrari, Andrea Esuli, Automated Software Engineering. 263Alessio Ferrari and Andrea Esuli. 2019. An NLP approach for cross-domain am- biguity detection in requirements engineering. Automated Software Engineering 26, 3 (2019).\n\nDetecting requirements defects with NLP patterns: An industrial experience in the railway domain. Alessio Ferrari, Gloria Gori, Benedetta Rosadini, Iacopo Trotta, Stefano Bacherini, Alessandro Fantechi, Stefania Gnesi, Empirical Software Engineering. 236Alessio Ferrari, Gloria Gori, Benedetta Rosadini, Iacopo Trotta, Stefano Bacherini, Alessandro Fantechi, and Stefania Gnesi. 2018. Detecting requirements defects with NLP patterns: An industrial experience in the railway domain. Empirical Software Engineering 23, 6 (2018).\n\nPure: A dataset of public requirements documents. Alessio Ferrari, Giorgio Oronzo Spagnolo, Stefania Gnesi, 2017 IEEE 25th International Requirements Engineering Conference. Alessio Ferrari, Giorgio Oronzo Spagnolo, and Stefania Gnesi. 2017. Pure: A dataset of public requirements documents. In 2017 IEEE 25th International Re- quirements Engineering Conference.\n\nMeasuring nominal scale agreement among many raters. Joseph L Fleiss, Psychol. Bull. 765Joseph L. Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychol. Bull. 76, 5 (1971).\n\nAmbiguity in Requirements Engineering: Towards a Unifying Framework. Vincenzo Gervasi, Alessio Ferrari, Didar Zowghi, Paola Spoletini, From Software Engineering to Formal Methods and Tools, and Back. SpringerVincenzo Gervasi, Alessio Ferrari, Didar Zowghi, and Paola Spoletini. 2019. Ambiguity in Requirements Engineering: Towards a Unifying Framework. In From Software Engineering to Formal Methods and Tools, and Back. Springer.\n\nAmbiguity Detection: Towards a Tool Explaining Ambiguity Sources. Benedikt Gleich, Oliver Creighton, Leonid Kof, Proceedings of the 16th Working Conference on Requirements Engineering: Foundation for Software Quality. the 16th Working Conference on Requirements Engineering: Foundation for Software QualityBenedikt Gleich, Oliver Creighton, and Leonid Kof. 2010. Ambiguity Detection: Towards a Tool Explaining Ambiguity Sources. In Proceedings of the 16th Working Conference on Requirements Engineering: Foundation for Software Quality.\n\nIan Goodfellow, Yoshua Bengio, Aaron Courville, Deep Learning. MIT Press1st ed.Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning (1st ed.). MIT Press.\n\n2020. spaCy: Industrial-strength Natural Language Processing in Python. Matthew Honnibal, Ines Montani, Sofie Van Landeghem, Adriane Boyd, 10.5281/zenodo.1212303Matthew Honnibal, Ines Montani, Sofie Van Landeghem, and Adriane Boyd. 2020. spaCy: Industrial-strength Natural Language Processing in Python. https: //doi.org/10.5281/zenodo.1212303\n\nDisambiguating Requirements Through Syntax-Driven Semantic Analysis of Information Types. Mitra Bokaei Hosseini, Rocky Slavin, Travis Breaux, Xiaoyin Wang, Jianwei Niu, Proceedings of the 26th Working Conference on Requirements Engineering: Foundation for Software Quality. the 26th Working Conference on Requirements Engineering: Foundation for Software QualityMitra Bokaei Hosseini, Rocky Slavin, Travis Breaux, Xiaoyin Wang, and Jianwei Niu. 2020. Disambiguating Requirements Through Syntax-Driven Semantic Analysis of Information Types. In Proceedings of the 26th Working Conference on Requirements Engineering: Foundation for Software Quality.\n\nBridging Anaphora Resolution as Question Answering. Yufang Hou, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsYufang Hou. 2020. Bridging Anaphora Resolution as Question Answering. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\n\nMultiple-Translation Chinese Corpus LDC2002T01. Web download file. Philadelphia: Linguistic Data Consortium. David Graff Huang, Shudong , George Doddington, David Graff Huang, Shudong and George Doddington. 2002. Multiple-Translation Chinese Corpus LDC2002T01. Web download file. Philadelphia: Linguistic Data Consortium.\n\nThe class imbalance problem: Significance and strategies. Nathalie Japkowicz, Proceedings of the International Conference on Artificial Intelligence. the International Conference on Artificial IntelligenceNathalie Japkowicz. 2000. The class imbalance problem: Significance and strate- gies. In Proceedings of the International Conference on Artificial Intelligence.\n\nSpanBERT: Improving pre-training by representing and predicting spans. Mandar Joshi, Danqi Chen, Yinhan Liu, S Daniel, Luke Weld, Omer Zettlemoyer, Levy, Transactions of the Association for Computational Linguistics. 8Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S Weld, Luke Zettlemoyer, and Omer Levy. 2020. SpanBERT: Improving pre-training by representing and pre- dicting spans. Transactions of the Association for Computational Linguistics 8 (2020).\n\nDan Jurafsky, James H Martin, Speech and Language Processing. 3rd ed.. visited 2021-06-04Dan Jurafsky and James H. Martin. 2020. Speech and Language Processing (3rd ed.). https://web.stanford.edu/~jurafsky/slp3/(visited 2021-06-04).\n\nUnderstanding Ambiguity in Requirements Engineering. Erik Kamsties, SpringerBerlin HeidelbergErik Kamsties. 2005. Understanding Ambiguity in Requirements Engineering. Springer Berlin Heidelberg.\n\nTaming ambiguity in natural language requirements. Erik Kamsties, Barbara Peach, Proceedings of the 13th International Conference on Software and Systems Engineering and Applications. the 13th International Conference on Software and Systems Engineering and ApplicationsErik Kamsties and Barbara Peach. 2000. Taming ambiguity in natural language requirements. In Proceedings of the 13th International Conference on Software and Systems Engineering and Applications.\n\nRequirements for tools for ambiguity identification and measurement in natural language requirements specifications. Nadzeya Kiyavitskaya, Nicola Zeni, Luisa Mich, Daniel Berry, Requirements Engineering. 133Nadzeya Kiyavitskaya, Nicola Zeni, Luisa Mich, and Daniel Berry. 2008. Re- quirements for tools for ambiguity identification and measurement in natural language requirements specifications. Requirements Engineering 13, 3 (2008).\n\nPohl Klaus, Rupp Chris, Requirements Engineering Fundamentals. Rocky NookPohl Klaus and Rupp Chris. 2011. Requirements Engineering Fundamentals (1st ed.). Rocky Nook.\n\nJupyter Notebooks -a publishing format for reproducible computational workflows. Thomas Kluyver, Benjamin Ragan-Kelley, Fernando P\u00e9rez, Brian Granger, Matthias Bussonnier, Jonathan Frederic, Kyle Kelley, Jessica Hamrick, Jason Grout, Sylvain Corlay, Paul Ivanov, Dami\u00e1n Avila, Positioning and Power in Academic Publishing: Players, Agents and Agendas. Safia Abdalla, and Carol WillingThomas Kluyver, Benjamin Ragan-Kelley, Fernando P\u00e9rez, Brian Granger, Matthias Bussonnier, Jonathan Frederic, Kyle Kelley, Jessica Hamrick, Jason Grout, Sylvain Corlay, Paul Ivanov, Dami\u00e1n Avila, Safia Abdalla, and Carol Willing. 2016. Jupyter Notebooks -a publishing format for reproducible com- putational workflows. In Positioning and Power in Academic Publishing: Players, Agents and Agendas.\n\nQuARS: A Pioneer Tool for NL Requirement Analysis. Giuseppe Lami, Mario Fusani, Gianluca Trentanni, From Software Engineering to Formal Methods and Tools, and Back. SpringerGiuseppe Lami, Mario Fusani, and Gianluca Trentanni. 2019. QuARS: A Pioneer Tool for NL Requirement Analysis. In From Software Engineering to Formal Methods and Tools, and Back. Springer.\n\nQed: A framework and dataset for explanations in question answering. Matthew Lamm, Jennimaria Palomaki, Chris Alberti, Daniel Andor, Eunsol Choi, Livio Baldini Soares, Michael Collins, Transactions of the Association for Computational Linguistics. 9Matthew Lamm, Jennimaria Palomaki, Chris Alberti, Daniel Andor, Eunsol Choi, Livio Baldini Soares, and Michael Collins. 2021. Qed: A framework and dataset for explanations in question answering. Transactions of the Association for Com- putational Linguistics 9 (2021).\n\nAn Application of Hierarchical Kappatype Statistics in the Assessment of Majority Agreement among Multiple Observers. J , Richard Landis, Gary G Koch, Biometrics. 33J. Richard Landis and Gary G. Koch. 1977. An Application of Hierarchical Kappa- type Statistics in the Assessment of Majority Agreement among Multiple Ob- servers. Biometrics 33, 2 (1977).\n\nA comprehensive review on feature set used for anaphora resolution. Kusum Lata, Pardeep Singh, Kamlesh Dutta, Artificial Intelligence Review. 544Kusum Lata, Pardeep Singh, and Kamlesh Dutta. 2021. A comprehensive review on feature set used for anaphora resolution. Artificial Intelligence Review 54, 4 (2021).\n\nQA-It: classifying non-referential it for question answer pairs. Timothy Lee, Alex Lutz, Jinho D Choi, Proceedings of the ACL 2016 Student Research Workshop. the ACL 2016 Student Research WorkshopTimothy Lee, Alex Lutz, and Jinho D Choi. 2016. QA-It: classifying non-referential it for question answer pairs. In Proceedings of the ACL 2016 Student Research Workshop.\n\n2020. A survey on contextual embeddings. Qi Liu, J Matt, Phil Kusner, Blunsom, arXiv:arXiv:2003.07278Qi Liu, Matt J Kusner, and Phil Blunsom. 2020. A survey on contextual embed- dings. (2020). arXiv:arXiv:2003.07278\n\nNLTK: The Natural Language Toolkit. Edward Loper, Steven Bird, Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics. the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational LinguisticsEdward Loper and Steven Bird. 2002. NLTK: The Natural Language Toolkit. In Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics.\n\n. Panos Louridas, Christof Ebert, Machine Learning. IEEE Software. 33Panos Louridas and Christof Ebert. 2016. Machine Learning. IEEE Software 33, 5 (2016).\n\nThe Stanford CoreNLP Natural Language Processing Toolkit. Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, David Mcclosky, Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations. 52nd Annual Meeting of the Association for Computational Linguistics: System DemonstrationsChristopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, and David McClosky. 2014. The Stanford CoreNLP Natural Language Processing Toolkit. In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations.\n\nBuilding a Large Annotated Corpus of English: The Penn Treebank. Mitch Marcus, Beatrice Santorini, Mary Ann Marcinkiewicz, Computational Linguistics. 19Mitch Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Build- ing a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics 19, 2 (1993).\n\nEmotional Prosody Speech and Transcripts LDC2002S28. CD-ROM. Philadelphia: Linguistic Data Consortium. Murray Grossman Nii Martey John Bell Mark Liberman, Kelly DavisMurray Grossman Nii Martey John Bell Mark Liberman, Kelly Davis. 2002. Emo- tional Prosody Speech and Transcripts LDC2002S28. CD-ROM. Philadelphia: Linguistic Data Consortium.\n\nIdentifying and classifying ambiguity for regulatory requirements. Aaron Massey, Richard Rutledge, Annie Anton, Peter Swire, Proceedings of the 22nd IEEE International Requirements Engineering Conference. the 22nd IEEE International Requirements Engineering ConferenceAaron Massey, Richard Rutledge, Annie Anton, and Peter Swire. 2014. Identifying and classifying ambiguity for regulatory requirements. In Proceedings of the 22nd IEEE International Requirements Engineering Conference.\n\nEasy Approach to Requirements Syntax (EARS). Alistair Mavin, Philip Wilkinson, Adrian Harwood, Mark Novak, Proceedings of the 17th IEEE International Requirements Engineering Conference. the 17th IEEE International Requirements Engineering ConferenceAlistair Mavin, Philip Wilkinson, Adrian Harwood, and Mark Novak. 2009. Easy Approach to Requirements Syntax (EARS). In Proceedings of the 17th IEEE Inter- national Requirements Engineering Conference.\n\nUsing Decision Trees for Coreference Resolution. F Joseph, Wendy G Mccarthy, Lehnert, International Joint Conferences on Artificial Intelligence. Joseph F McCarthy and Wendy G Lehnert. 1995. Using Decision Trees for Coref- erence Resolution. In International Joint Conferences on Artificial Intelligence.\n\nContextual and Non-Contextual Word Embeddings: an in-depth Linguistic Investigation. Alessio Miaschi, Felice Dell&apos;orletta, Proceedings of the 5th Workshop on Representation Learning for NLP. the 5th Workshop on Representation Learning for NLPAssociation for Computational LinguisticsAlessio Miaschi and Felice Dell'Orletta. 2020. Contextual and Non-Contextual Word Embeddings: an in-depth Linguistic Investigation. In Proceedings of the 5th Workshop on Representation Learning for NLP. Association for Computational Linguistics.\n\nNL-OOPS: From natural language to object oriented requirements using the natural language processing system LOLITA. L Mich, Natural Language Engineering. 22L. Mich. 1996. NL-OOPS: From natural language to object oriented require- ments using the natural language processing system LOLITA. Natural Language Engineering 2, 2 (1996).\n\nEfficient estimation of word representations in vector space. Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean, arXiv:arXiv:1301.3781Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. (2013). arXiv:arXiv:1301.3781\n\nAnaphora resolution: the state of the art. Ruslan Mitkov, CiteseerRuslan Mitkov. 1999. Anaphora resolution: the state of the art. Citeseer.\n\nAnaphora resolution. Ruslan Mitkov, RoutledgeRuslan Mitkov. 2014. Anaphora resolution. Routledge.\n\nUsing the web in machine learning for other-anaphora resolution. Katja Natalia N Modjeska, Malvina Markert, Nissim, Proceedings of the 2003 conference on Empirical methods in natural language processing. the 2003 conference on Empirical methods in natural language processingNatalia N Modjeska, Katja Markert, and Malvina Nissim. 2003. Using the web in machine learning for other-anaphora resolution. In Proceedings of the 2003 conference on Empirical methods in natural language processing.\n\nDomain understanding is the key to successful system development. Ray Offen, Requirements engineering. 73Ray Offen. 2002. Domain understanding is the key to successful system develop- ment. Requirements engineering 7, 3 (2002).\n\nScore-based automatic detection and resolution of syntactic ambiguity in natural language requirements. Mohamed Osama, Aya Zaki-Ismail, Mohamed Abdelrazek, John Grundy, Amani Ibrahim, 2020 IEEE International Conference on Software Maintenance and Evolution. Mohamed Osama, Aya Zaki-Ismail, Mohamed Abdelrazek, John Grundy, and Amani Ibrahim. 2020. Score-based automatic detection and resolution of syntactic ambiguity in natural language requirements. In 2020 IEEE International Conference on Software Maintenance and Evolution.\n\nPyTorch: An Imperative Style, High-Performance Deep Learning Library. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary Devito, Advances in Neural Information Processing Systems. Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu FangCurran Associates, Inc32Junjie Bai, and Soumith ChintalaAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Des- maison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep Learn- ing Library. In Advances in Neural Information Processing Systems 32. Curran Associates, Inc.\n\nScikit-learn: Machine Learning in Python. Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Journal of Machine Learning Research. 12Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 12 (2011), 2825-2830.\n\nGloVe: Global Vectors for Word Representation. Jeffrey Pennington, Richard Socher, Christopher D Manning, Empirical Methods in Natural Language Processing. Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. In Empirical Methods in Natural Lan- guage Processing.\n\nSentence encoders on stilts: Supplementary training on intermediate labeled-data tasks. Jason Phang, Thibault F\u00e9vry, Samuel R Bowman, arXiv:arXiv:1811.01088Jason Phang, Thibault F\u00e9vry, and Samuel R Bowman. 2018. Sentence encoders on stilts: Supplementary training on intermediate labeled-data tasks. (2018). arXiv:arXiv:1811.01088\n\nThe communicative function of ambiguity in language. Steven Piantadosi, Harry Tily, Edward Gibson, Cognition. 1223Steven Piantadosi, Harry Tily, and Edward Gibson. 2012. The communicative function of ambiguity in language. Cognition 122, 3 (2012).\n\nAnaphora resolution. Massimo Poesio, Roland Stuckardt, Yannick Versley, SpringerMassimo Poesio, Roland Stuckardt, and Yannick Versley. 2016. Anaphora resolu- tion. Springer.\n\nKlaus Pohl, Requirements Engineering. Springer1st ed.Klaus Pohl. 2010. Requirements Engineering (1st ed.). Springer.\n\nCoNLL-2011 shared task: Modeling unrestricted coreference in ontonotes. Sameer Pradhan, Lance Ramshaw, Mitch Marcus, Martha Palmer, Ralph Weischedel, Nianwen Xue, Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task. the Fifteenth Conference on Computational Natural Language Learning: Shared TaskSameer Pradhan, Lance Ramshaw, Mitch Marcus, Martha Palmer, Ralph Weischedel, and Nianwen Xue. 2011. CoNLL-2011 shared task: Modeling unre- stricted coreference in ontonotes. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task. 1-27.\n\nStanza: A Python Natural Language Processing Toolkit for Many Human Languages. Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, Christopher D Manning, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations. the 58th Annual Meeting of the Association for Computational Linguistics: System DemonstrationsPeng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, and Christopher D. Man- ning. 2020. Stanza: A Python Natural Language Processing Toolkit for Many Human Languages. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations.\n\nCoupling for Coreference Resolution in a Never-ending Learning System. Felipe Quecole, Cristina Maisa, Estevam Rafael Duarte, Hruschka, Journal of Information and Data Management. 9Felipe Quecole, Maisa Cristina Duarte, and Estevam Rafael Hruschka. 2018. Cou- pling for Coreference Resolution in a Never-ending Learning System. Journal of Information and Data Management 9, 2 (2018).\n\nA multipass sieve for coreference resolution. Heeyoung Karthik Raghunathan, Sudarshan Lee, Nathanael Rangarajan, Mihai Chambers, Dan Surdeanu, Christopher D Jurafsky, Manning, Proceedings of the 2010 conference on empirical methods in natural language processing. the 2010 conference on empirical methods in natural language processingKarthik Raghunathan, Heeyoung Lee, Sudarshan Rangarajan, Nathanael Cham- bers, Mihai Surdeanu, Dan Jurafsky, and Christopher D Manning. 2010. A multi- pass sieve for coreference resolution. In Proceedings of the 2010 conference on empirical methods in natural language processing.\n\nSemeval-2010 task 1: Coreference resolution in multiple languages. Marta Recasens, Llu\u00eds M\u00e0rquez, Emili Sapena, Ant\u00f2nia Mart\u00ed, Mariona Taul\u00e9, V\u00e9ronique Hoste, Massimo Poesio, Yannick Versley, Proceedings of the 5th International Workshop on Semantic Evaluation. the 5th International Workshop on Semantic EvaluationMarta Recasens, Llu\u00eds M\u00e0rquez, Emili Sapena, M Ant\u00f2nia Mart\u00ed, Mariona Taul\u00e9, V\u00e9ronique Hoste, Massimo Poesio, and Yannick Versley. 2010. Semeval-2010 task 1: Coreference resolution in multiple languages. In Proceedings of the 5th International Workshop on Semantic Evaluation.\n\nSentence-bert: Sentence embeddings using siamese bert-networks. Nils Reimers, Iryna Gurevych, arXiv:arXiv:1908.10084Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. (2019). arXiv:arXiv:1908.10084\n\n2020. The prevalence and severity of persistent ambiguity in software requirements specifications: Is a special effort needed to find them?. Cristina Ribeiro, Daniel Berry, Science of Computer Programming. 195Cristina Ribeiro and Daniel Berry. 2020. The prevalence and severity of persistent ambiguity in software requirements specifications: Is a special effort needed to find them? Science of Computer Programming 195 (2020).\n\nAutomated Extraction of Conceptual Models from User Stories via NLP. Marcel Robeer, Garm Lucassen, Jan Martijn, E M Van Der Werf, Fabiano Dalpiaz, Sjaak Brinkkemper, Proceedings of the 24th IEEE International Requirements Engineering Conference. the 24th IEEE International Requirements Engineering ConferenceMarcel Robeer, Garm Lucassen, Jan Martijn E.M. van der Werf, Fabiano Dalpiaz, and Sjaak Brinkkemper. 2016. Automated Extraction of Conceptual Models from User Stories via NLP. In Proceedings of the 24th IEEE International Requirements Engineering Conference.\n\nAn efficient wikipedia-based approach for better understanding of natural language text related to user requirements. Danissa Rodriguez, Doris Carver, Anas Mahmoud, Proceedings of the 39th IEEE Aerospace Conference. the 39th IEEE Aerospace ConferenceDanissa Rodriguez, Doris Carver, and Anas Mahmoud. 2018. An efficient wikipedia-based approach for better understanding of natural language text related to user requirements. In Proceedings of the 39th IEEE Aerospace Confer- ence.\n\nUsing NLP to Detect Requirements Defects: An Industrial Experience in the Railway Domain. Benedetta Rosadini, Alessio Ferrari, Gloria Gori, Alessandro Fantechi, Stefania Gnesi, Iacopo Trotta, Stefano Bacherini, Proceedings of the 23rd Working Conference on Requirements Engineering: Foundation for Software Quality. the 23rd Working Conference on Requirements Engineering: Foundation for Software QualityBenedetta Rosadini, Alessio Ferrari, Gloria Gori, Alessandro Fantechi, Stefania Gnesi, Iacopo Trotta, and Stefano Bacherini. 2017. Using NLP to Detect Require- ments Defects: An Industrial Experience in the Railway Domain. In Proceedings of the 23rd Working Conference on Requirements Engineering: Foundation for Software Quality.\n\nOnline Annex (online. Chetan Arora Mehrdad Sabetzadeh Saad EzziniChetan Arora Mehrdad Sabetzadeh Saad Ezzini, Sallam Abualhaija. 2021. \"Online Annex (online)\". Available at https://tinyurl.com/2p9k2zf2, August 2021.\n\nAn automated framework for detection and resolution of cross references in legal texts. Nicolas Sannier, Morayo Adedjouma, Mehrdad Sabetzadeh, Lionel Briand, Requirements Engineering. 22Nicolas Sannier, Morayo Adedjouma, Mehrdad Sabetzadeh, and Lionel Briand. 2017. An automated framework for detection and resolution of cross references in legal texts. Requirements Engineering 22, 2 (2017).\n\nUnnati Shah, Devesh Jinwala, Resolving Ambiguities in Natural Language Software Requirements: A Comprehensive Survey. 405Unnati Shah and Devesh Jinwala. 2015. Resolving Ambiguities in Natural Lan- guage Software Requirements: A Comprehensive Survey. SIGSOFT Software Engineering Notes 40, 5 (2015).\n\nMpnet: Masked and permuted pre-training for language understanding. Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu, arXiv:arXiv:2004.09297Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2020. Mp- net: Masked and permuted pre-training for language understanding. (2020). arXiv:arXiv:2004.09297\n\nAnaphora and coreference resolution: A review. Rhea Sukthanker, Soujanya Poria, Erik Cambria, Ramkumar Thirunavukarasu, Information Fusion. 59Rhea Sukthanker, Soujanya Poria, Erik Cambria, and Ramkumar Thirunavukarasu. 2020. Anaphora and coreference resolution: A review. Information Fusion 59 (2020).\n\nIntroduction to data mining. Pang-Ning Tan, Michael Steinbach, Vipin Kumar, Pearson Education IndiaPang-Ning Tan, Michael Steinbach, and Vipin Kumar. 2016. Introduction to data mining. Pearson Education India.\n\nThe design of SREE-a prototype potential ambiguity finder for requirements specifications and lessons learned. Sri Tjong, Daniel Berry, Proceedings of the 19th Working Conference on Requirements Engineering: Foundation for Software Quality. the 19th Working Conference on Requirements Engineering: Foundation for Software QualitySri Tjong and Daniel Berry. 2013. The design of SREE-a prototype potential ambiguity finder for requirements specifications and lessons learned. In Proceed- ings of the 19th Working Conference on Requirements Engineering: Foundation for Software Quality.\n\nPython 3 Reference Manual. CreateSpace. Guido Van Rossum, Fred L Drake, Guido Van Rossum and Fred L. Drake. 2009. Python 3 Reference Manual. CreateS- pace.\n\nA Deep Context-wise Method for Coreference Detection in Natural Language Requirements. Yawen Wang, Lin Shi, Mingyang Li, Qing Wang, Yun Yang, 2020 IEEE 28th International Requirements Engineering Conference. Yawen Wang, Lin Shi, Mingyang Li, Qing Wang, and Yun Yang. 2020. A Deep Context-wise Method for Coreference Detection in Natural Language Require- ments. In 2020 IEEE 28th International Requirements Engineering Conference.\n\nIan Witten, Eibe Frank, Mark Hall, Christopher Pal, Data Mining: Practical Machine Learning Tools and Techniques. Elsevier4th ed.Ian Witten, Eibe Frank, Mark Hall, and Christopher Pal. 2011. Data Mining: Practical Machine Learning Tools and Techniques (4th ed.). Elsevier.\n\nTransformers: State-of-the-Art Natural Language Processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Le Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander M Lhoest, Rush, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. the 2020 Conference on Empirical Methods in Natural Language Processing: System DemonstrationsAssociation for Computational LinguisticsThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2020. Transformers: State-of-the-Art Natural Language Processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Association for Computational Linguistics.\n\nCorefQA: Coreference resolution as query-based span prediction. Wei Wu, Fei Wang, Arianna Yuan, Fei Wu, Jiwei Li, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsWei Wu, Fei Wang, Arianna Yuan, Fei Wu, and Jiwei Li. 2020. CorefQA: Corefer- ence resolution as query-based span prediction. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\n\nExtending nocuous ambiguity analysis for anaphora in natural language requirements. Hui Yang, Anne De Roeck, Vincenzo Gervasi, Proceedings of the 18th IEEE International Requirements Engineering Conference. the 18th IEEE International Requirements Engineering ConferenceIEEEAlistair Willis, and Bashar NuseibehHui Yang, Anne De Roeck, Vincenzo Gervasi, Alistair Willis, and Bashar Nu- seibeh. 2010. Extending nocuous ambiguity analysis for anaphora in natural language requirements. In Proceedings of the 18th IEEE International Requirements Engineering Conference. IEEE.\n\nAnalysing anaphoric ambiguity in natural language requirements. Hui Yang, Anne De Roeck, Vincenzo Gervasi, Requirements Engineering. 163Alistair Willis, and Bashar NuseibehHui Yang, Anne de Roeck, Vincenzo Gervasi, Alistair Willis, and Bashar Nu- seibeh. 2011. Analysing anaphoric ambiguity in natural language requirements. Requirements Engineering 16, 3 (2011).\n", "annotations": {"author": "[{\"end\":153,\"start\":85},{\"end\":234,\"start\":154},{\"end\":304,\"start\":235},{\"end\":394,\"start\":305}]", "publisher": null, "author_last_name": "[{\"end\":96,\"start\":90},{\"end\":171,\"start\":161},{\"end\":247,\"start\":242},{\"end\":323,\"start\":313}]", "author_first_name": "[{\"end\":89,\"start\":85},{\"end\":160,\"start\":154},{\"end\":241,\"start\":235},{\"end\":312,\"start\":305}]", "author_affiliation": "[{\"end\":152,\"start\":117},{\"end\":233,\"start\":198},{\"end\":303,\"start\":276},{\"end\":393,\"start\":349}]", "title": "[{\"end\":82,\"start\":1},{\"end\":476,\"start\":395}]", "venue": null, "abstract": "[{\"end\":2348,\"start\":638}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b70\"},\"end\":2597,\"start\":2593},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2670,\"start\":2666},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2673,\"start\":2670},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":2676,\"start\":2673},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":2767,\"start\":2763},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2898,\"start\":2894},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":2901,\"start\":2898},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2963,\"start\":2959},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":2966,\"start\":2963},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":2969,\"start\":2966},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":2972,\"start\":2969},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":3183,\"start\":3179},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3265,\"start\":3261},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":3268,\"start\":3265},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":3326,\"start\":3322},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3455,\"start\":3451},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":3458,\"start\":3455},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3578,\"start\":3574},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":3686,\"start\":3682},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":3830,\"start\":3826},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":5354,\"start\":5350},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":5576,\"start\":5572},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6140,\"start\":6136},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6301,\"start\":6297},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":6304,\"start\":6301},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6352,\"start\":6349},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6355,\"start\":6352},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6358,\"start\":6355},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":6361,\"start\":6358},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":6364,\"start\":6361},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6655,\"start\":6651},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":7598,\"start\":7594},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":7601,\"start\":7598},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":7738,\"start\":7734},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":9937,\"start\":9933},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":10118,\"start\":10115},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12473,\"start\":12469},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":12628,\"start\":12624},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":13374,\"start\":13370},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":13683,\"start\":13679},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":14014,\"start\":14010},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":14029,\"start\":14025},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":14253,\"start\":14249},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14672,\"start\":14669},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":15465,\"start\":15461},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":15468,\"start\":15465},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16593,\"start\":16589},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":16596,\"start\":16593},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":16599,\"start\":16596},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":16736,\"start\":16732},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16739,\"start\":16736},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":16742,\"start\":16739},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":16745,\"start\":16742},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":16748,\"start\":16745},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16799,\"start\":16795},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":16802,\"start\":16799},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":16805,\"start\":16802},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":16808,\"start\":16805},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":16834,\"start\":16831},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16836,\"start\":16834},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":16839,\"start\":16836},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":16842,\"start\":16839},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":16845,\"start\":16842},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16889,\"start\":16886},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":16892,\"start\":16889},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":16895,\"start\":16892},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":16898,\"start\":16895},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":16901,\"start\":16898},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":16904,\"start\":16901},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":16907,\"start\":16904},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":16910,\"start\":16907},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":16913,\"start\":16910},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":16916,\"start\":16913},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":16919,\"start\":16916},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":16922,\"start\":16919},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":16925,\"start\":16922},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":16928,\"start\":16925},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":17227,\"start\":17223},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":17245,\"start\":17241},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":17248,\"start\":17245},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":17827,\"start\":17824},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":17830,\"start\":17827},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":17833,\"start\":17830},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":18335,\"start\":18331},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":18338,\"start\":18335},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":18416,\"start\":18412},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":18419,\"start\":18416},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":18422,\"start\":18419},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":18425,\"start\":18422},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":18428,\"start\":18425},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":18431,\"start\":18428},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":18676,\"start\":18672},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":18859,\"start\":18855},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":18862,\"start\":18859},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":19007,\"start\":19003},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":19160,\"start\":19156},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":19473,\"start\":19469},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":19476,\"start\":19473},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":19761,\"start\":19757},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":19845,\"start\":19841},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":19848,\"start\":19845},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":20845,\"start\":20841},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":21732,\"start\":21730},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":21758,\"start\":21756},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":22615,\"start\":22611},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":23268,\"start\":23265},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":23271,\"start\":23268},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":25716,\"start\":25712},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":25942,\"start\":25938},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":25945,\"start\":25942},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":25948,\"start\":25945},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":27615,\"start\":27611},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":27618,\"start\":27615},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":27621,\"start\":27618},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":27624,\"start\":27621},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":27627,\"start\":27624},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":27630,\"start\":27627},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":27633,\"start\":27630},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":27685,\"start\":27681},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":28371,\"start\":28367},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":28386,\"start\":28382},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":28467,\"start\":28463},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":28520,\"start\":28516},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":28538,\"start\":28534},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":28834,\"start\":28830},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":30560,\"start\":30556},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":31944,\"start\":31940},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":31986,\"start\":31982},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":31989,\"start\":31986},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":32027,\"start\":32023},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":32097,\"start\":32095},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":33553,\"start\":33550},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":33556,\"start\":33553},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":33944,\"start\":33940},{\"end\":34171,\"start\":34170},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":34509,\"start\":34505},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":34512,\"start\":34509},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":34515,\"start\":34512},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":34674,\"start\":34671},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":38414,\"start\":38410},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":38501,\"start\":38497},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":38629,\"start\":38625},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":41571,\"start\":41567},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":41574,\"start\":41571},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":43106,\"start\":43102},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":43109,\"start\":43106},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":43112,\"start\":43109},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":44193,\"start\":44189},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":44196,\"start\":44193},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":44199,\"start\":44196},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":44229,\"start\":44225},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":44232,\"start\":44229},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":44623,\"start\":44619},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":44691,\"start\":44687},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":46107,\"start\":46104},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":51240,\"start\":51236},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":53557,\"start\":53553},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":62576,\"start\":62572},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":62636,\"start\":62632}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":59480,\"start\":59388},{\"attributes\":{\"id\":\"fig_1\"},\"end\":59525,\"start\":59481},{\"attributes\":{\"id\":\"fig_2\"},\"end\":59748,\"start\":59526},{\"attributes\":{\"id\":\"fig_3\"},\"end\":60163,\"start\":59749},{\"attributes\":{\"id\":\"fig_4\"},\"end\":60420,\"start\":60164},{\"attributes\":{\"id\":\"fig_5\"},\"end\":60941,\"start\":60421},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":61649,\"start\":60942},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":61746,\"start\":61650},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":62252,\"start\":61747},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":62521,\"start\":62253},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":63319,\"start\":62522},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":64277,\"start\":63320},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":64651,\"start\":64278},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":64822,\"start\":64652},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":65615,\"start\":64823}]", "paragraph": "[{\"end\":2973,\"start\":2364},{\"end\":3831,\"start\":2975},{\"end\":5002,\"start\":3833},{\"end\":5071,\"start\":5009},{\"end\":6141,\"start\":5073},{\"end\":7268,\"start\":6143},{\"end\":8054,\"start\":7270},{\"end\":9156,\"start\":8056},{\"end\":9612,\"start\":9158},{\"end\":9674,\"start\":9614},{\"end\":9984,\"start\":9676},{\"end\":10936,\"start\":9986},{\"end\":11389,\"start\":10938},{\"end\":11543,\"start\":11391},{\"end\":11869,\"start\":11545},{\"end\":12025,\"start\":11901},{\"end\":12983,\"start\":12040},{\"end\":14030,\"start\":12985},{\"end\":14819,\"start\":14032},{\"end\":16513,\"start\":14821},{\"end\":17060,\"start\":16530},{\"end\":17834,\"start\":17062},{\"end\":18599,\"start\":17836},{\"end\":19477,\"start\":18601},{\"end\":20197,\"start\":19479},{\"end\":20598,\"start\":20218},{\"end\":21368,\"start\":20621},{\"end\":21946,\"start\":21370},{\"end\":22158,\"start\":21948},{\"end\":23272,\"start\":22176},{\"end\":23749,\"start\":23298},{\"end\":25337,\"start\":23751},{\"end\":25630,\"start\":25505},{\"end\":26774,\"start\":25667},{\"end\":27348,\"start\":26776},{\"end\":27897,\"start\":27350},{\"end\":28918,\"start\":27899},{\"end\":29876,\"start\":28920},{\"end\":30462,\"start\":29878},{\"end\":31475,\"start\":30464},{\"end\":32145,\"start\":31530},{\"end\":32255,\"start\":32170},{\"end\":32352,\"start\":32284},{\"end\":32628,\"start\":32460},{\"end\":33683,\"start\":32725},{\"end\":33886,\"start\":33749},{\"end\":34172,\"start\":33922},{\"end\":36815,\"start\":34185},{\"end\":37415,\"start\":36817},{\"end\":38697,\"start\":37417},{\"end\":40942,\"start\":38699},{\"end\":42749,\"start\":40965},{\"end\":43439,\"start\":42770},{\"end\":43733,\"start\":43441},{\"end\":43922,\"start\":43735},{\"end\":46902,\"start\":43924},{\"end\":47179,\"start\":46932},{\"end\":48350,\"start\":47181},{\"end\":49495,\"start\":48352},{\"end\":50151,\"start\":49497},{\"end\":50659,\"start\":50248},{\"end\":50830,\"start\":50661},{\"end\":51018,\"start\":50896},{\"end\":52079,\"start\":51020},{\"end\":52860,\"start\":52081},{\"end\":53101,\"start\":52862},{\"end\":53461,\"start\":53103},{\"end\":54663,\"start\":53463},{\"end\":54856,\"start\":54678},{\"end\":55406,\"start\":54858},{\"end\":56194,\"start\":55408},{\"end\":57322,\"start\":56218},{\"end\":58079,\"start\":57337},{\"end\":58795,\"start\":58081},{\"end\":59387,\"start\":58797}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":5008,\"start\":5003},{\"attributes\":{\"id\":\"formula_1\"},\"end\":25504,\"start\":25338}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":27000,\"start\":26993},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":30584,\"start\":30577},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":31804,\"start\":31797},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":35102,\"start\":35095},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":45374,\"start\":45360},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":45466,\"start\":45459},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":47038,\"start\":47031},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":48372,\"start\":48365},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":49971,\"start\":49964}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2362,\"start\":2350},{\"attributes\":{\"n\":\"2\"},\"end\":11899,\"start\":11872},{\"attributes\":{\"n\":\"2.1\"},\"end\":12038,\"start\":12028},{\"attributes\":{\"n\":\"2.2\"},\"end\":16528,\"start\":16516},{\"attributes\":{\"n\":\"3\"},\"end\":20216,\"start\":20200},{\"attributes\":{\"n\":\"3.1\"},\"end\":20619,\"start\":20601},{\"attributes\":{\"n\":\"3.2\"},\"end\":22174,\"start\":22161},{\"attributes\":{\"n\":\"3.3\"},\"end\":23296,\"start\":23275},{\"end\":25665,\"start\":25633},{\"end\":31528,\"start\":31478},{\"attributes\":{\"n\":\"4\"},\"end\":32168,\"start\":32148},{\"attributes\":{\"n\":\"4.1\"},\"end\":32282,\"start\":32258},{\"end\":32458,\"start\":32355},{\"end\":32723,\"start\":32631},{\"end\":33747,\"start\":33686},{\"attributes\":{\"n\":\"4.2\"},\"end\":33920,\"start\":33889},{\"attributes\":{\"n\":\"4.3\"},\"end\":34183,\"start\":34175},{\"attributes\":{\"n\":\"4.4\"},\"end\":40963,\"start\":40945},{\"attributes\":{\"n\":\"4.5\"},\"end\":42768,\"start\":42752},{\"attributes\":{\"n\":\"4.6\"},\"end\":46923,\"start\":46905},{\"end\":46930,\"start\":46926},{\"end\":50246,\"start\":50154},{\"end\":50894,\"start\":50833},{\"attributes\":{\"n\":\"4.7\"},\"end\":54676,\"start\":54666},{\"attributes\":{\"n\":\"5\"},\"end\":56216,\"start\":56197},{\"attributes\":{\"n\":\"6\"},\"end\":57335,\"start\":57325},{\"end\":59390,\"start\":59389},{\"end\":59492,\"start\":59482},{\"end\":59542,\"start\":59527},{\"end\":60428,\"start\":60422},{\"end\":60950,\"start\":60943},{\"end\":61660,\"start\":61651},{\"end\":62263,\"start\":62254},{\"end\":63330,\"start\":63321},{\"end\":64288,\"start\":64279},{\"end\":64662,\"start\":64653},{\"end\":64833,\"start\":64824}]", "table": "[{\"end\":61649,\"start\":61074},{\"end\":62521,\"start\":62301},{\"end\":63319,\"start\":62831},{\"end\":64277,\"start\":63424},{\"end\":64651,\"start\":64376},{\"end\":65615,\"start\":65095}]", "figure_caption": "[{\"end\":59480,\"start\":59391},{\"end\":59525,\"start\":59494},{\"end\":59748,\"start\":59545},{\"end\":60163,\"start\":59751},{\"end\":60420,\"start\":60166},{\"end\":60941,\"start\":60430},{\"end\":61074,\"start\":60952},{\"end\":61746,\"start\":61662},{\"end\":62252,\"start\":61749},{\"end\":62301,\"start\":62265},{\"end\":62831,\"start\":62524},{\"end\":63424,\"start\":63332},{\"end\":64376,\"start\":64290},{\"end\":64822,\"start\":64664},{\"end\":65095,\"start\":64835}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":3880,\"start\":3872},{\"end\":12131,\"start\":12123},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":21431,\"start\":21423},{\"end\":21890,\"start\":21882},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":21945,\"start\":21937},{\"end\":23397,\"start\":23389},{\"end\":23950,\"start\":23942},{\"end\":26068,\"start\":26060},{\"end\":26409,\"start\":26401},{\"end\":27151,\"start\":27148},{\"end\":30791,\"start\":30783},{\"end\":31584,\"start\":31576},{\"end\":32056,\"start\":32048},{\"end\":32526,\"start\":32518},{\"end\":32779,\"start\":32771},{\"end\":33885,\"start\":33877},{\"end\":34085,\"start\":34077},{\"end\":43156,\"start\":43150},{\"end\":43314,\"start\":43306},{\"end\":43804,\"start\":43796},{\"end\":49559,\"start\":49550},{\"end\":50723,\"start\":50714}]", "bib_author_first_name": "[{\"end\":65747,\"start\":65741},{\"end\":65766,\"start\":65760},{\"end\":65781,\"start\":65774},{\"end\":65797,\"start\":65791},{\"end\":66491,\"start\":66485},{\"end\":66510,\"start\":66504},{\"end\":66525,\"start\":66518},{\"end\":66541,\"start\":66535},{\"end\":66557,\"start\":66550},{\"end\":66835,\"start\":66834},{\"end\":67003,\"start\":66995},{\"end\":67022,\"start\":67014},{\"end\":67332,\"start\":67326},{\"end\":67347,\"start\":67340},{\"end\":67366,\"start\":67360},{\"end\":67380,\"start\":67375},{\"end\":67754,\"start\":67748},{\"end\":67769,\"start\":67762},{\"end\":67788,\"start\":67782},{\"end\":67802,\"start\":67797},{\"end\":68154,\"start\":68148},{\"end\":68169,\"start\":68162},{\"end\":68188,\"start\":68182},{\"end\":68202,\"start\":68197},{\"end\":68215,\"start\":68211},{\"end\":69006,\"start\":69000},{\"end\":69021,\"start\":69014},{\"end\":69039,\"start\":69034},{\"end\":69054,\"start\":69048},{\"end\":69412,\"start\":69407},{\"end\":69427,\"start\":69423},{\"end\":69444,\"start\":69438},{\"end\":69459,\"start\":69453},{\"end\":69696,\"start\":69695},{\"end\":69705,\"start\":69704},{\"end\":69717,\"start\":69716},{\"end\":70099,\"start\":70098},{\"end\":70409,\"start\":70404},{\"end\":70622,\"start\":70616},{\"end\":70641,\"start\":70634},{\"end\":70656,\"start\":70650},{\"end\":70662,\"start\":70657},{\"end\":70684,\"start\":70673},{\"end\":70703,\"start\":70696},{\"end\":70716,\"start\":70712},{\"end\":70734,\"start\":70727},{\"end\":70751,\"start\":70744},{\"end\":71251,\"start\":71245},{\"end\":71268,\"start\":71259},{\"end\":71277,\"start\":71275},{\"end\":71289,\"start\":71284},{\"end\":71655,\"start\":71650},{\"end\":71674,\"start\":71663},{\"end\":71676,\"start\":71675},{\"end\":71996,\"start\":71991},{\"end\":72015,\"start\":72004},{\"end\":72017,\"start\":72016},{\"end\":72501,\"start\":72494},{\"end\":72515,\"start\":72511},{\"end\":72530,\"start\":72525},{\"end\":72544,\"start\":72539},{\"end\":72562,\"start\":72558},{\"end\":72933,\"start\":72928},{\"end\":72950,\"start\":72942},{\"end\":72964,\"start\":72958},{\"end\":72978,\"start\":72970},{\"end\":73273,\"start\":73266},{\"end\":73553,\"start\":73547},{\"end\":73573,\"start\":73567},{\"end\":73593,\"start\":73586},{\"end\":73607,\"start\":73601},{\"end\":73609,\"start\":73608},{\"end\":74066,\"start\":74058},{\"end\":74082,\"start\":74077},{\"end\":74099,\"start\":74091},{\"end\":74115,\"start\":74107},{\"end\":74596,\"start\":74589},{\"end\":74611,\"start\":74605},{\"end\":74618,\"start\":74612},{\"end\":74635,\"start\":74630},{\"end\":74653,\"start\":74646},{\"end\":74666,\"start\":74661},{\"end\":74679,\"start\":74675},{\"end\":75177,\"start\":75170},{\"end\":75192,\"start\":75186},{\"end\":75199,\"start\":75193},{\"end\":75217,\"start\":75211},{\"end\":75235,\"start\":75226},{\"end\":75544,\"start\":75537},{\"end\":75560,\"start\":75554},{\"end\":75878,\"start\":75871},{\"end\":75894,\"start\":75888},{\"end\":75910,\"start\":75901},{\"end\":75927,\"start\":75921},{\"end\":75943,\"start\":75936},{\"end\":75965,\"start\":75955},{\"end\":75984,\"start\":75976},{\"end\":76359,\"start\":76352},{\"end\":76376,\"start\":76369},{\"end\":76383,\"start\":76377},{\"end\":76402,\"start\":76394},{\"end\":76725,\"start\":76719},{\"end\":76727,\"start\":76726},{\"end\":76938,\"start\":76930},{\"end\":76955,\"start\":76948},{\"end\":76970,\"start\":76965},{\"end\":76984,\"start\":76979},{\"end\":77367,\"start\":77359},{\"end\":77382,\"start\":77376},{\"end\":77400,\"start\":77394},{\"end\":77834,\"start\":77831},{\"end\":77853,\"start\":77847},{\"end\":77867,\"start\":77862},{\"end\":78084,\"start\":78077},{\"end\":78099,\"start\":78095},{\"end\":78114,\"start\":78109},{\"end\":78137,\"start\":78130},{\"end\":78445,\"start\":78440},{\"end\":78452,\"start\":78446},{\"end\":78468,\"start\":78463},{\"end\":78483,\"start\":78477},{\"end\":78499,\"start\":78492},{\"end\":78513,\"start\":78506},{\"end\":79058,\"start\":79052},{\"end\":79508,\"start\":79497},{\"end\":79523,\"start\":79516},{\"end\":79532,\"start\":79526},{\"end\":79777,\"start\":79769},{\"end\":80155,\"start\":80149},{\"end\":80168,\"start\":80163},{\"end\":80181,\"start\":80175},{\"end\":80188,\"start\":80187},{\"end\":80201,\"start\":80197},{\"end\":80212,\"start\":80208},{\"end\":80537,\"start\":80534},{\"end\":80553,\"start\":80548},{\"end\":80555,\"start\":80554},{\"end\":80825,\"start\":80821},{\"end\":81019,\"start\":81015},{\"end\":81037,\"start\":81030},{\"end\":81555,\"start\":81548},{\"end\":81576,\"start\":81570},{\"end\":81588,\"start\":81583},{\"end\":81601,\"start\":81595},{\"end\":81872,\"start\":81868},{\"end\":81884,\"start\":81880},{\"end\":82123,\"start\":82117},{\"end\":82141,\"start\":82133},{\"end\":82164,\"start\":82156},{\"end\":82177,\"start\":82172},{\"end\":82195,\"start\":82187},{\"end\":82216,\"start\":82208},{\"end\":82231,\"start\":82227},{\"end\":82247,\"start\":82240},{\"end\":82262,\"start\":82257},{\"end\":82277,\"start\":82270},{\"end\":82290,\"start\":82286},{\"end\":82305,\"start\":82299},{\"end\":82877,\"start\":82869},{\"end\":82889,\"start\":82884},{\"end\":82906,\"start\":82898},{\"end\":83256,\"start\":83249},{\"end\":83273,\"start\":83263},{\"end\":83289,\"start\":83284},{\"end\":83305,\"start\":83299},{\"end\":83319,\"start\":83313},{\"end\":83339,\"start\":83326},{\"end\":83355,\"start\":83348},{\"end\":83818,\"start\":83817},{\"end\":83828,\"start\":83821},{\"end\":83841,\"start\":83837},{\"end\":83843,\"start\":83842},{\"end\":84127,\"start\":84122},{\"end\":84141,\"start\":84134},{\"end\":84156,\"start\":84149},{\"end\":84437,\"start\":84430},{\"end\":84447,\"start\":84443},{\"end\":84461,\"start\":84454},{\"end\":84776,\"start\":84774},{\"end\":84783,\"start\":84782},{\"end\":84794,\"start\":84790},{\"end\":84992,\"start\":84986},{\"end\":85006,\"start\":85000},{\"end\":85511,\"start\":85506},{\"end\":85530,\"start\":85522},{\"end\":85730,\"start\":85719},{\"end\":85745,\"start\":85740},{\"end\":85760,\"start\":85756},{\"end\":85773,\"start\":85768},{\"end\":85788,\"start\":85782},{\"end\":85803,\"start\":85798},{\"end\":86358,\"start\":86353},{\"end\":86375,\"start\":86367},{\"end\":86391,\"start\":86387},{\"end\":86395,\"start\":86392},{\"end\":87031,\"start\":87026},{\"end\":87047,\"start\":87040},{\"end\":87063,\"start\":87058},{\"end\":87076,\"start\":87071},{\"end\":87499,\"start\":87491},{\"end\":87513,\"start\":87507},{\"end\":87531,\"start\":87525},{\"end\":87545,\"start\":87541},{\"end\":87949,\"start\":87948},{\"end\":87963,\"start\":87958},{\"end\":87965,\"start\":87964},{\"end\":88297,\"start\":88290},{\"end\":88313,\"start\":88307},{\"end\":88857,\"start\":88856},{\"end\":89139,\"start\":89134},{\"end\":89152,\"start\":89149},{\"end\":89163,\"start\":89159},{\"end\":89180,\"start\":89173},{\"end\":89413,\"start\":89407},{\"end\":89532,\"start\":89526},{\"end\":89674,\"start\":89669},{\"end\":89702,\"start\":89695},{\"end\":90166,\"start\":90163},{\"end\":90437,\"start\":90430},{\"end\":90448,\"start\":90445},{\"end\":90469,\"start\":90462},{\"end\":90486,\"start\":90482},{\"end\":90500,\"start\":90495},{\"end\":90930,\"start\":90926},{\"end\":90942,\"start\":90939},{\"end\":90959,\"start\":90950},{\"end\":90971,\"start\":90967},{\"end\":90984,\"start\":90979},{\"end\":91002,\"start\":90995},{\"end\":91017,\"start\":91011},{\"end\":91033,\"start\":91027},{\"end\":91046,\"start\":91039},{\"end\":91063,\"start\":91059},{\"end\":91077,\"start\":91072},{\"end\":91096,\"start\":91089},{\"end\":91109,\"start\":91103},{\"end\":91123,\"start\":91116},{\"end\":91841,\"start\":91835},{\"end\":91857,\"start\":91853},{\"end\":91878,\"start\":91869},{\"end\":91896,\"start\":91889},{\"end\":91913,\"start\":91905},{\"end\":91930,\"start\":91923},{\"end\":91946,\"start\":91939},{\"end\":91961,\"start\":91956},{\"end\":91979,\"start\":91976},{\"end\":91994,\"start\":91987},{\"end\":92382,\"start\":92375},{\"end\":92402,\"start\":92395},{\"end\":92422,\"start\":92411},{\"end\":92424,\"start\":92423},{\"end\":92750,\"start\":92745},{\"end\":92766,\"start\":92758},{\"end\":92782,\"start\":92774},{\"end\":93048,\"start\":93042},{\"end\":93066,\"start\":93061},{\"end\":93079,\"start\":93073},{\"end\":93266,\"start\":93259},{\"end\":93281,\"start\":93275},{\"end\":93300,\"start\":93293},{\"end\":93418,\"start\":93413},{\"end\":93609,\"start\":93603},{\"end\":93624,\"start\":93619},{\"end\":93639,\"start\":93634},{\"end\":93654,\"start\":93648},{\"end\":93668,\"start\":93663},{\"end\":93688,\"start\":93681},{\"end\":94236,\"start\":94232},{\"end\":94246,\"start\":94241},{\"end\":94259,\"start\":94254},{\"end\":94272,\"start\":94267},{\"end\":94292,\"start\":94281},{\"end\":94294,\"start\":94293},{\"end\":94868,\"start\":94862},{\"end\":94886,\"start\":94878},{\"end\":94908,\"start\":94894},{\"end\":95230,\"start\":95222},{\"end\":95261,\"start\":95252},{\"end\":95276,\"start\":95267},{\"end\":95294,\"start\":95289},{\"end\":95308,\"start\":95305},{\"end\":95332,\"start\":95319},{\"end\":95865,\"start\":95860},{\"end\":95881,\"start\":95876},{\"end\":95896,\"start\":95891},{\"end\":95912,\"start\":95905},{\"end\":95927,\"start\":95920},{\"end\":95944,\"start\":95935},{\"end\":95959,\"start\":95952},{\"end\":95975,\"start\":95968},{\"end\":96454,\"start\":96450},{\"end\":96469,\"start\":96464},{\"end\":96786,\"start\":96778},{\"end\":96802,\"start\":96796},{\"end\":97141,\"start\":97135},{\"end\":97154,\"start\":97150},{\"end\":97168,\"start\":97165},{\"end\":97179,\"start\":97178},{\"end\":97181,\"start\":97180},{\"end\":97203,\"start\":97196},{\"end\":97218,\"start\":97213},{\"end\":97760,\"start\":97753},{\"end\":97777,\"start\":97772},{\"end\":97790,\"start\":97786},{\"end\":98216,\"start\":98207},{\"end\":98234,\"start\":98227},{\"end\":98250,\"start\":98244},{\"end\":98267,\"start\":98257},{\"end\":98286,\"start\":98278},{\"end\":98300,\"start\":98294},{\"end\":98316,\"start\":98309},{\"end\":99165,\"start\":99158},{\"end\":99181,\"start\":99175},{\"end\":99200,\"start\":99193},{\"end\":99219,\"start\":99213},{\"end\":99470,\"start\":99464},{\"end\":99483,\"start\":99477},{\"end\":99838,\"start\":99832},{\"end\":99847,\"start\":99845},{\"end\":99856,\"start\":99853},{\"end\":99870,\"start\":99862},{\"end\":99882,\"start\":99875},{\"end\":100129,\"start\":100125},{\"end\":100150,\"start\":100142},{\"end\":100162,\"start\":100158},{\"end\":100180,\"start\":100172},{\"end\":100419,\"start\":100410},{\"end\":100432,\"start\":100425},{\"end\":100449,\"start\":100444},{\"end\":100706,\"start\":100703},{\"end\":100720,\"start\":100714},{\"end\":101222,\"start\":101217},{\"end\":101239,\"start\":101235},{\"end\":101241,\"start\":101240},{\"end\":101426,\"start\":101421},{\"end\":101436,\"start\":101433},{\"end\":101450,\"start\":101442},{\"end\":101459,\"start\":101455},{\"end\":101469,\"start\":101466},{\"end\":101769,\"start\":101766},{\"end\":101782,\"start\":101778},{\"end\":101794,\"start\":101790},{\"end\":101812,\"start\":101801},{\"end\":102106,\"start\":102100},{\"end\":102121,\"start\":102113},{\"end\":102135,\"start\":102129},{\"end\":102148,\"start\":102142},{\"end\":102166,\"start\":102159},{\"end\":102184,\"start\":102177},{\"end\":102197,\"start\":102190},{\"end\":102209,\"start\":102206},{\"end\":102221,\"start\":102217},{\"end\":102234,\"start\":102228},{\"end\":102249,\"start\":102246},{\"end\":102262,\"start\":102259},{\"end\":102278,\"start\":102273},{\"end\":102305,\"start\":102299},{\"end\":102316,\"start\":102310},{\"end\":102332,\"start\":102326},{\"end\":102343,\"start\":102338},{\"end\":102346,\"start\":102344},{\"end\":102358,\"start\":102351},{\"end\":102372,\"start\":102365},{\"end\":102388,\"start\":102381},{\"end\":102405,\"start\":102396},{\"end\":102407,\"start\":102406},{\"end\":103286,\"start\":103283},{\"end\":103294,\"start\":103291},{\"end\":103308,\"start\":103301},{\"end\":103318,\"start\":103315},{\"end\":103328,\"start\":103323},{\"end\":103800,\"start\":103797},{\"end\":103811,\"start\":103807},{\"end\":103814,\"start\":103812},{\"end\":103830,\"start\":103822},{\"end\":104353,\"start\":104350},{\"end\":104364,\"start\":104360},{\"end\":104383,\"start\":104375}]", "bib_author_last_name": "[{\"end\":65758,\"start\":65748},{\"end\":65772,\"start\":65767},{\"end\":65789,\"start\":65782},{\"end\":65804,\"start\":65798},{\"end\":66502,\"start\":66492},{\"end\":66516,\"start\":66511},{\"end\":66533,\"start\":66526},{\"end\":66548,\"start\":66542},{\"end\":66565,\"start\":66558},{\"end\":66841,\"start\":66836},{\"end\":66851,\"start\":66843},{\"end\":67012,\"start\":67004},{\"end\":67030,\"start\":67023},{\"end\":67338,\"start\":67333},{\"end\":67358,\"start\":67348},{\"end\":67373,\"start\":67367},{\"end\":67387,\"start\":67381},{\"end\":67760,\"start\":67755},{\"end\":67780,\"start\":67770},{\"end\":67795,\"start\":67789},{\"end\":67809,\"start\":67803},{\"end\":68160,\"start\":68155},{\"end\":68180,\"start\":68170},{\"end\":68195,\"start\":68189},{\"end\":68209,\"start\":68203},{\"end\":68221,\"start\":68216},{\"end\":69012,\"start\":69007},{\"end\":69032,\"start\":69022},{\"end\":69046,\"start\":69040},{\"end\":69061,\"start\":69055},{\"end\":69421,\"start\":69413},{\"end\":69436,\"start\":69428},{\"end\":69451,\"start\":69445},{\"end\":69464,\"start\":69460},{\"end\":69702,\"start\":69697},{\"end\":69714,\"start\":69706},{\"end\":69725,\"start\":69718},{\"end\":70106,\"start\":70100},{\"end\":70113,\"start\":70108},{\"end\":70416,\"start\":70410},{\"end\":70632,\"start\":70623},{\"end\":70648,\"start\":70642},{\"end\":70671,\"start\":70663},{\"end\":70694,\"start\":70685},{\"end\":70710,\"start\":70704},{\"end\":70725,\"start\":70717},{\"end\":70742,\"start\":70735},{\"end\":70758,\"start\":70752},{\"end\":71257,\"start\":71252},{\"end\":71273,\"start\":71269},{\"end\":71282,\"start\":71278},{\"end\":71292,\"start\":71290},{\"end\":71661,\"start\":71656},{\"end\":71684,\"start\":71677},{\"end\":72002,\"start\":71997},{\"end\":72025,\"start\":72018},{\"end\":72509,\"start\":72502},{\"end\":72523,\"start\":72516},{\"end\":72537,\"start\":72531},{\"end\":72556,\"start\":72545},{\"end\":72570,\"start\":72563},{\"end\":72580,\"start\":72572},{\"end\":72940,\"start\":72934},{\"end\":72956,\"start\":72951},{\"end\":72968,\"start\":72965},{\"end\":72988,\"start\":72979},{\"end\":73279,\"start\":73274},{\"end\":73565,\"start\":73554},{\"end\":73584,\"start\":73574},{\"end\":73599,\"start\":73594},{\"end\":73620,\"start\":73610},{\"end\":73628,\"start\":73622},{\"end\":74075,\"start\":74067},{\"end\":74089,\"start\":74083},{\"end\":74105,\"start\":74100},{\"end\":74120,\"start\":74116},{\"end\":74603,\"start\":74597},{\"end\":74628,\"start\":74619},{\"end\":74644,\"start\":74636},{\"end\":74659,\"start\":74654},{\"end\":74673,\"start\":74667},{\"end\":74686,\"start\":74680},{\"end\":75184,\"start\":75178},{\"end\":75209,\"start\":75200},{\"end\":75224,\"start\":75218},{\"end\":75240,\"start\":75236},{\"end\":75552,\"start\":75545},{\"end\":75566,\"start\":75561},{\"end\":75886,\"start\":75879},{\"end\":75899,\"start\":75895},{\"end\":75919,\"start\":75911},{\"end\":75934,\"start\":75928},{\"end\":75953,\"start\":75944},{\"end\":75974,\"start\":75966},{\"end\":75990,\"start\":75985},{\"end\":76367,\"start\":76360},{\"end\":76392,\"start\":76384},{\"end\":76408,\"start\":76403},{\"end\":76734,\"start\":76728},{\"end\":76946,\"start\":76939},{\"end\":76963,\"start\":76956},{\"end\":76977,\"start\":76971},{\"end\":76994,\"start\":76985},{\"end\":77374,\"start\":77368},{\"end\":77392,\"start\":77383},{\"end\":77404,\"start\":77401},{\"end\":77845,\"start\":77835},{\"end\":77860,\"start\":77854},{\"end\":77877,\"start\":77868},{\"end\":78093,\"start\":78085},{\"end\":78107,\"start\":78100},{\"end\":78128,\"start\":78115},{\"end\":78142,\"start\":78138},{\"end\":78461,\"start\":78453},{\"end\":78475,\"start\":78469},{\"end\":78490,\"start\":78484},{\"end\":78504,\"start\":78500},{\"end\":78517,\"start\":78514},{\"end\":79062,\"start\":79059},{\"end\":79514,\"start\":79509},{\"end\":79543,\"start\":79533},{\"end\":79787,\"start\":79778},{\"end\":80161,\"start\":80156},{\"end\":80173,\"start\":80169},{\"end\":80185,\"start\":80182},{\"end\":80195,\"start\":80189},{\"end\":80206,\"start\":80202},{\"end\":80224,\"start\":80213},{\"end\":80230,\"start\":80226},{\"end\":80546,\"start\":80538},{\"end\":80562,\"start\":80556},{\"end\":80834,\"start\":80826},{\"end\":81028,\"start\":81020},{\"end\":81043,\"start\":81038},{\"end\":81568,\"start\":81556},{\"end\":81581,\"start\":81577},{\"end\":81593,\"start\":81589},{\"end\":81607,\"start\":81602},{\"end\":81878,\"start\":81873},{\"end\":81890,\"start\":81885},{\"end\":82131,\"start\":82124},{\"end\":82154,\"start\":82142},{\"end\":82170,\"start\":82165},{\"end\":82185,\"start\":82178},{\"end\":82206,\"start\":82196},{\"end\":82225,\"start\":82217},{\"end\":82238,\"start\":82232},{\"end\":82255,\"start\":82248},{\"end\":82268,\"start\":82263},{\"end\":82284,\"start\":82278},{\"end\":82297,\"start\":82291},{\"end\":82311,\"start\":82306},{\"end\":82882,\"start\":82878},{\"end\":82896,\"start\":82890},{\"end\":82916,\"start\":82907},{\"end\":83261,\"start\":83257},{\"end\":83282,\"start\":83274},{\"end\":83297,\"start\":83290},{\"end\":83311,\"start\":83306},{\"end\":83324,\"start\":83320},{\"end\":83346,\"start\":83340},{\"end\":83363,\"start\":83356},{\"end\":83835,\"start\":83829},{\"end\":83848,\"start\":83844},{\"end\":84132,\"start\":84128},{\"end\":84147,\"start\":84142},{\"end\":84162,\"start\":84157},{\"end\":84441,\"start\":84438},{\"end\":84452,\"start\":84448},{\"end\":84466,\"start\":84462},{\"end\":84780,\"start\":84777},{\"end\":84788,\"start\":84784},{\"end\":84801,\"start\":84795},{\"end\":84810,\"start\":84803},{\"end\":84998,\"start\":84993},{\"end\":85011,\"start\":85007},{\"end\":85520,\"start\":85512},{\"end\":85536,\"start\":85531},{\"end\":85738,\"start\":85731},{\"end\":85754,\"start\":85746},{\"end\":85766,\"start\":85761},{\"end\":85780,\"start\":85774},{\"end\":85796,\"start\":85789},{\"end\":85812,\"start\":85804},{\"end\":86365,\"start\":86359},{\"end\":86385,\"start\":86376},{\"end\":86409,\"start\":86396},{\"end\":87038,\"start\":87032},{\"end\":87056,\"start\":87048},{\"end\":87069,\"start\":87064},{\"end\":87082,\"start\":87077},{\"end\":87505,\"start\":87500},{\"end\":87523,\"start\":87514},{\"end\":87539,\"start\":87532},{\"end\":87551,\"start\":87546},{\"end\":87956,\"start\":87950},{\"end\":87974,\"start\":87966},{\"end\":87983,\"start\":87976},{\"end\":88305,\"start\":88298},{\"end\":88331,\"start\":88314},{\"end\":88862,\"start\":88858},{\"end\":89147,\"start\":89140},{\"end\":89157,\"start\":89153},{\"end\":89171,\"start\":89164},{\"end\":89185,\"start\":89181},{\"end\":89420,\"start\":89414},{\"end\":89539,\"start\":89533},{\"end\":89693,\"start\":89675},{\"end\":89710,\"start\":89703},{\"end\":89718,\"start\":89712},{\"end\":90172,\"start\":90167},{\"end\":90443,\"start\":90438},{\"end\":90460,\"start\":90449},{\"end\":90480,\"start\":90470},{\"end\":90493,\"start\":90487},{\"end\":90508,\"start\":90501},{\"end\":90937,\"start\":90931},{\"end\":90948,\"start\":90943},{\"end\":90965,\"start\":90960},{\"end\":90977,\"start\":90972},{\"end\":90993,\"start\":90985},{\"end\":91009,\"start\":91003},{\"end\":91025,\"start\":91018},{\"end\":91037,\"start\":91034},{\"end\":91057,\"start\":91047},{\"end\":91070,\"start\":91064},{\"end\":91087,\"start\":91078},{\"end\":91101,\"start\":91097},{\"end\":91114,\"start\":91110},{\"end\":91130,\"start\":91124},{\"end\":91851,\"start\":91842},{\"end\":91867,\"start\":91858},{\"end\":91887,\"start\":91879},{\"end\":91903,\"start\":91897},{\"end\":91921,\"start\":91914},{\"end\":91937,\"start\":91931},{\"end\":91954,\"start\":91947},{\"end\":91974,\"start\":91962},{\"end\":91985,\"start\":91980},{\"end\":92002,\"start\":91995},{\"end\":92393,\"start\":92383},{\"end\":92409,\"start\":92403},{\"end\":92432,\"start\":92425},{\"end\":92756,\"start\":92751},{\"end\":92772,\"start\":92767},{\"end\":92789,\"start\":92783},{\"end\":93059,\"start\":93049},{\"end\":93071,\"start\":93067},{\"end\":93086,\"start\":93080},{\"end\":93273,\"start\":93267},{\"end\":93291,\"start\":93282},{\"end\":93308,\"start\":93301},{\"end\":93423,\"start\":93419},{\"end\":93617,\"start\":93610},{\"end\":93632,\"start\":93625},{\"end\":93646,\"start\":93640},{\"end\":93661,\"start\":93655},{\"end\":93679,\"start\":93669},{\"end\":93692,\"start\":93689},{\"end\":94239,\"start\":94237},{\"end\":94252,\"start\":94247},{\"end\":94265,\"start\":94260},{\"end\":94279,\"start\":94273},{\"end\":94302,\"start\":94295},{\"end\":94876,\"start\":94869},{\"end\":94892,\"start\":94887},{\"end\":94915,\"start\":94909},{\"end\":94925,\"start\":94917},{\"end\":95250,\"start\":95231},{\"end\":95265,\"start\":95262},{\"end\":95287,\"start\":95277},{\"end\":95303,\"start\":95295},{\"end\":95317,\"start\":95309},{\"end\":95341,\"start\":95333},{\"end\":95350,\"start\":95343},{\"end\":95874,\"start\":95866},{\"end\":95889,\"start\":95882},{\"end\":95903,\"start\":95897},{\"end\":95918,\"start\":95913},{\"end\":95933,\"start\":95928},{\"end\":95950,\"start\":95945},{\"end\":95966,\"start\":95960},{\"end\":95983,\"start\":95976},{\"end\":96462,\"start\":96455},{\"end\":96478,\"start\":96470},{\"end\":96794,\"start\":96787},{\"end\":96808,\"start\":96803},{\"end\":97148,\"start\":97142},{\"end\":97163,\"start\":97155},{\"end\":97176,\"start\":97169},{\"end\":97194,\"start\":97182},{\"end\":97211,\"start\":97204},{\"end\":97230,\"start\":97219},{\"end\":97770,\"start\":97761},{\"end\":97784,\"start\":97778},{\"end\":97798,\"start\":97791},{\"end\":98225,\"start\":98217},{\"end\":98242,\"start\":98235},{\"end\":98255,\"start\":98251},{\"end\":98276,\"start\":98268},{\"end\":98292,\"start\":98287},{\"end\":98307,\"start\":98301},{\"end\":98326,\"start\":98317},{\"end\":99173,\"start\":99166},{\"end\":99191,\"start\":99182},{\"end\":99211,\"start\":99201},{\"end\":99226,\"start\":99220},{\"end\":99475,\"start\":99471},{\"end\":99491,\"start\":99484},{\"end\":99843,\"start\":99839},{\"end\":99851,\"start\":99848},{\"end\":99860,\"start\":99857},{\"end\":99873,\"start\":99871},{\"end\":99886,\"start\":99883},{\"end\":100140,\"start\":100130},{\"end\":100156,\"start\":100151},{\"end\":100170,\"start\":100163},{\"end\":100196,\"start\":100181},{\"end\":100423,\"start\":100420},{\"end\":100442,\"start\":100433},{\"end\":100455,\"start\":100450},{\"end\":100712,\"start\":100707},{\"end\":100726,\"start\":100721},{\"end\":101233,\"start\":101223},{\"end\":101247,\"start\":101242},{\"end\":101431,\"start\":101427},{\"end\":101440,\"start\":101437},{\"end\":101453,\"start\":101451},{\"end\":101464,\"start\":101460},{\"end\":101474,\"start\":101470},{\"end\":101776,\"start\":101770},{\"end\":101788,\"start\":101783},{\"end\":101799,\"start\":101795},{\"end\":101816,\"start\":101813},{\"end\":102111,\"start\":102107},{\"end\":102127,\"start\":102122},{\"end\":102140,\"start\":102136},{\"end\":102157,\"start\":102149},{\"end\":102175,\"start\":102167},{\"end\":102188,\"start\":102185},{\"end\":102204,\"start\":102198},{\"end\":102215,\"start\":102210},{\"end\":102226,\"start\":102222},{\"end\":102244,\"start\":102235},{\"end\":102257,\"start\":102250},{\"end\":102271,\"start\":102263},{\"end\":102297,\"start\":102279},{\"end\":102308,\"start\":102306},{\"end\":102324,\"start\":102317},{\"end\":102336,\"start\":102333},{\"end\":102349,\"start\":102347},{\"end\":102363,\"start\":102359},{\"end\":102379,\"start\":102373},{\"end\":102394,\"start\":102389},{\"end\":102414,\"start\":102408},{\"end\":102420,\"start\":102416},{\"end\":103289,\"start\":103287},{\"end\":103299,\"start\":103295},{\"end\":103313,\"start\":103309},{\"end\":103321,\"start\":103319},{\"end\":103331,\"start\":103329},{\"end\":103805,\"start\":103801},{\"end\":103820,\"start\":103815},{\"end\":103838,\"start\":103831},{\"end\":104358,\"start\":104354},{\"end\":104373,\"start\":104365},{\"end\":104391,\"start\":104384}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":214730562},\"end\":66406,\"start\":65646},{\"attributes\":{\"id\":\"b1\"},\"end\":66805,\"start\":66408},{\"attributes\":{\"id\":\"b2\"},\"end\":66921,\"start\":66807},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2317283},\"end\":67229,\"start\":66923},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":2187134},\"end\":67678,\"start\":67231},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":24746895},\"end\":68055,\"start\":67680},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":10891934},\"end\":68905,\"start\":68057},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":59337129},\"end\":69360,\"start\":68907},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":11688126},\"end\":69693,\"start\":69362},{\"attributes\":{\"id\":\"b9\"},\"end\":70024,\"start\":69695},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":237298391},\"end\":70288,\"start\":70026},{\"attributes\":{\"id\":\"b11\"},\"end\":70565,\"start\":70290},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":11541972},\"end\":71160,\"start\":70567},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":219266488},\"end\":71580,\"start\":71162},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":2012188},\"end\":71902,\"start\":71582},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":6235360},\"end\":72414,\"start\":71904},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":69898063},\"end\":72844,\"start\":72416},{\"attributes\":{\"doi\":\"arXiv:arXiv:1810.04805\",\"id\":\"b17\"},\"end\":73196,\"start\":72846},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":1439328},\"end\":73463,\"start\":73198},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":232221967},\"end\":73945,\"start\":73465},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":62262576},\"end\":74517,\"start\":73947},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":10279448},\"end\":75118,\"start\":74519},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":9602750},\"end\":75453,\"start\":75120},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":186207291},\"end\":75771,\"start\":75455},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":3396453},\"end\":76300,\"start\":75773},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":32950061},\"end\":76664,\"start\":76302},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":143544759},\"end\":76859,\"start\":76666},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":203979411},\"end\":77291,\"start\":76861},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1569926},\"end\":77829,\"start\":77293},{\"attributes\":{\"id\":\"b29\"},\"end\":78003,\"start\":77831},{\"attributes\":{\"doi\":\"10.5281/zenodo.1212303\",\"id\":\"b30\"},\"end\":78348,\"start\":78005},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":213185845},\"end\":78998,\"start\":78350},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":215814427},\"end\":79386,\"start\":79000},{\"attributes\":{\"id\":\"b33\"},\"end\":79709,\"start\":79388},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":9885187},\"end\":80076,\"start\":79711},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":198229624},\"end\":80532,\"start\":80078},{\"attributes\":{\"id\":\"b36\"},\"end\":80766,\"start\":80534},{\"attributes\":{\"id\":\"b37\"},\"end\":80962,\"start\":80768},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":2362230},\"end\":81429,\"start\":80964},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":10425845},\"end\":81866,\"start\":81431},{\"attributes\":{\"id\":\"b40\"},\"end\":82034,\"start\":81868},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":36928206},\"end\":82816,\"start\":82036},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":203979371},\"end\":83178,\"start\":82818},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":221655495},\"end\":83697,\"start\":83180},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":40673292},\"end\":84052,\"start\":83699},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":225154954},\"end\":84363,\"start\":84054},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":8829812},\"end\":84731,\"start\":84365},{\"attributes\":{\"doi\":\"arXiv:arXiv:2003.07278\",\"id\":\"b47\"},\"end\":84948,\"start\":84733},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":1438450},\"end\":85502,\"start\":84950},{\"attributes\":{\"id\":\"b49\"},\"end\":85659,\"start\":85504},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":14068874},\"end\":86286,\"start\":85661},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":252796},\"end\":86614,\"start\":86288},{\"attributes\":{\"id\":\"b52\"},\"end\":86957,\"start\":86616},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":15246407},\"end\":87444,\"start\":86959},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":34495464},\"end\":87897,\"start\":87446},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":1366616},\"end\":88203,\"start\":87899},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":220273459},\"end\":88738,\"start\":88205},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":8178023},\"end\":89070,\"start\":88740},{\"attributes\":{\"doi\":\"arXiv:arXiv:1301.3781\",\"id\":\"b58\"},\"end\":89362,\"start\":89072},{\"attributes\":{\"id\":\"b59\"},\"end\":89503,\"start\":89364},{\"attributes\":{\"id\":\"b60\"},\"end\":89602,\"start\":89505},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":693910},\"end\":90095,\"start\":89604},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":7614686},\"end\":90324,\"start\":90097},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":226265901},\"end\":90854,\"start\":90326},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":202786778},\"end\":91791,\"start\":90856},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":10659969},\"end\":92326,\"start\":91793},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":1957433},\"end\":92655,\"start\":92328},{\"attributes\":{\"doi\":\"arXiv:arXiv:1811.01088\",\"id\":\"b67\"},\"end\":92987,\"start\":92657},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":13726095},\"end\":93236,\"start\":92989},{\"attributes\":{\"id\":\"b69\"},\"end\":93411,\"start\":93238},{\"attributes\":{\"id\":\"b70\"},\"end\":93529,\"start\":93413},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":11898554},\"end\":94151,\"start\":93531},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":212725611},\"end\":94789,\"start\":94153},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":221462646},\"end\":95174,\"start\":94791},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":7691746},\"end\":95791,\"start\":95176},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":935332},\"end\":96384,\"start\":95793},{\"attributes\":{\"doi\":\"arXiv:arXiv:1908.10084\",\"id\":\"b76\"},\"end\":96635,\"start\":96386},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":219001332},\"end\":97064,\"start\":96637},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":19466488},\"end\":97633,\"start\":97066},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":49538599},\"end\":98115,\"start\":97635},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":28898017},\"end\":98851,\"start\":98117},{\"attributes\":{\"id\":\"b81\"},\"end\":99068,\"start\":98853},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":4657452},\"end\":99462,\"start\":99070},{\"attributes\":{\"id\":\"b83\"},\"end\":99762,\"start\":99464},{\"attributes\":{\"doi\":\"arXiv:arXiv:2004.09297\",\"id\":\"b84\"},\"end\":100076,\"start\":99764},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":44093698},\"end\":100379,\"start\":100078},{\"attributes\":{\"id\":\"b86\"},\"end\":100590,\"start\":100381},{\"attributes\":{\"id\":\"b87\",\"matched_paper_id\":5031395},\"end\":101175,\"start\":100592},{\"attributes\":{\"id\":\"b88\"},\"end\":101332,\"start\":101177},{\"attributes\":{\"id\":\"b89\",\"matched_paper_id\":222297818},\"end\":101764,\"start\":101334},{\"attributes\":{\"id\":\"b90\"},\"end\":102038,\"start\":101766},{\"attributes\":{\"id\":\"b91\",\"matched_paper_id\":208117506},\"end\":103217,\"start\":102040},{\"attributes\":{\"id\":\"b92\",\"matched_paper_id\":220045465},\"end\":103711,\"start\":103219},{\"attributes\":{\"id\":\"b93\",\"matched_paper_id\":14807242},\"end\":104284,\"start\":103713},{\"attributes\":{\"id\":\"b94\",\"matched_paper_id\":15676954},\"end\":104649,\"start\":104286}]", "bib_title": "[{\"end\":65739,\"start\":65646},{\"end\":66993,\"start\":66923},{\"end\":67324,\"start\":67231},{\"end\":67746,\"start\":67680},{\"end\":68146,\"start\":68057},{\"end\":68998,\"start\":68907},{\"end\":69405,\"start\":69362},{\"end\":70096,\"start\":70026},{\"end\":70614,\"start\":70567},{\"end\":71243,\"start\":71162},{\"end\":71648,\"start\":71582},{\"end\":71989,\"start\":71904},{\"end\":72492,\"start\":72416},{\"end\":73264,\"start\":73198},{\"end\":73545,\"start\":73465},{\"end\":74056,\"start\":73947},{\"end\":74587,\"start\":74519},{\"end\":75168,\"start\":75120},{\"end\":75535,\"start\":75455},{\"end\":75869,\"start\":75773},{\"end\":76350,\"start\":76302},{\"end\":76717,\"start\":76666},{\"end\":76928,\"start\":76861},{\"end\":77357,\"start\":77293},{\"end\":78438,\"start\":78350},{\"end\":79050,\"start\":79000},{\"end\":79767,\"start\":79711},{\"end\":80147,\"start\":80078},{\"end\":81013,\"start\":80964},{\"end\":81546,\"start\":81431},{\"end\":82115,\"start\":82036},{\"end\":82867,\"start\":82818},{\"end\":83247,\"start\":83180},{\"end\":83815,\"start\":83699},{\"end\":84120,\"start\":84054},{\"end\":84428,\"start\":84365},{\"end\":84984,\"start\":84950},{\"end\":85717,\"start\":85661},{\"end\":86351,\"start\":86288},{\"end\":87024,\"start\":86959},{\"end\":87489,\"start\":87446},{\"end\":87946,\"start\":87899},{\"end\":88288,\"start\":88205},{\"end\":88854,\"start\":88740},{\"end\":89667,\"start\":89604},{\"end\":90161,\"start\":90097},{\"end\":90428,\"start\":90326},{\"end\":90924,\"start\":90856},{\"end\":91833,\"start\":91793},{\"end\":92373,\"start\":92328},{\"end\":93040,\"start\":92989},{\"end\":93601,\"start\":93531},{\"end\":94230,\"start\":94153},{\"end\":94860,\"start\":94791},{\"end\":95220,\"start\":95176},{\"end\":95858,\"start\":95793},{\"end\":96776,\"start\":96637},{\"end\":97133,\"start\":97066},{\"end\":97751,\"start\":97635},{\"end\":98205,\"start\":98117},{\"end\":99156,\"start\":99070},{\"end\":100123,\"start\":100078},{\"end\":100701,\"start\":100592},{\"end\":101419,\"start\":101334},{\"end\":102098,\"start\":102040},{\"end\":103281,\"start\":103219},{\"end\":103795,\"start\":103713},{\"end\":104348,\"start\":104286}]", "bib_author": "[{\"end\":65760,\"start\":65741},{\"end\":65774,\"start\":65760},{\"end\":65791,\"start\":65774},{\"end\":65806,\"start\":65791},{\"end\":66504,\"start\":66485},{\"end\":66518,\"start\":66504},{\"end\":66535,\"start\":66518},{\"end\":66550,\"start\":66535},{\"end\":66567,\"start\":66550},{\"end\":66843,\"start\":66834},{\"end\":66853,\"start\":66843},{\"end\":67014,\"start\":66995},{\"end\":67032,\"start\":67014},{\"end\":67340,\"start\":67326},{\"end\":67360,\"start\":67340},{\"end\":67375,\"start\":67360},{\"end\":67389,\"start\":67375},{\"end\":67762,\"start\":67748},{\"end\":67782,\"start\":67762},{\"end\":67797,\"start\":67782},{\"end\":67811,\"start\":67797},{\"end\":68162,\"start\":68148},{\"end\":68182,\"start\":68162},{\"end\":68197,\"start\":68182},{\"end\":68211,\"start\":68197},{\"end\":68223,\"start\":68211},{\"end\":69014,\"start\":69000},{\"end\":69034,\"start\":69014},{\"end\":69048,\"start\":69034},{\"end\":69063,\"start\":69048},{\"end\":69423,\"start\":69407},{\"end\":69438,\"start\":69423},{\"end\":69453,\"start\":69438},{\"end\":69466,\"start\":69453},{\"end\":69704,\"start\":69695},{\"end\":69716,\"start\":69704},{\"end\":69727,\"start\":69716},{\"end\":70108,\"start\":70098},{\"end\":70115,\"start\":70108},{\"end\":70418,\"start\":70404},{\"end\":70634,\"start\":70616},{\"end\":70650,\"start\":70634},{\"end\":70673,\"start\":70650},{\"end\":70696,\"start\":70673},{\"end\":70712,\"start\":70696},{\"end\":70727,\"start\":70712},{\"end\":70744,\"start\":70727},{\"end\":70760,\"start\":70744},{\"end\":71259,\"start\":71245},{\"end\":71275,\"start\":71259},{\"end\":71284,\"start\":71275},{\"end\":71294,\"start\":71284},{\"end\":71663,\"start\":71650},{\"end\":71686,\"start\":71663},{\"end\":72004,\"start\":71991},{\"end\":72027,\"start\":72004},{\"end\":72511,\"start\":72494},{\"end\":72525,\"start\":72511},{\"end\":72539,\"start\":72525},{\"end\":72558,\"start\":72539},{\"end\":72572,\"start\":72558},{\"end\":72582,\"start\":72572},{\"end\":72942,\"start\":72928},{\"end\":72958,\"start\":72942},{\"end\":72970,\"start\":72958},{\"end\":72990,\"start\":72970},{\"end\":73281,\"start\":73266},{\"end\":73567,\"start\":73547},{\"end\":73586,\"start\":73567},{\"end\":73601,\"start\":73586},{\"end\":73622,\"start\":73601},{\"end\":73630,\"start\":73622},{\"end\":74077,\"start\":74058},{\"end\":74091,\"start\":74077},{\"end\":74107,\"start\":74091},{\"end\":74122,\"start\":74107},{\"end\":74605,\"start\":74589},{\"end\":74630,\"start\":74605},{\"end\":74646,\"start\":74630},{\"end\":74661,\"start\":74646},{\"end\":74675,\"start\":74661},{\"end\":74688,\"start\":74675},{\"end\":75186,\"start\":75170},{\"end\":75211,\"start\":75186},{\"end\":75226,\"start\":75211},{\"end\":75242,\"start\":75226},{\"end\":75554,\"start\":75537},{\"end\":75568,\"start\":75554},{\"end\":75888,\"start\":75871},{\"end\":75901,\"start\":75888},{\"end\":75921,\"start\":75901},{\"end\":75936,\"start\":75921},{\"end\":75955,\"start\":75936},{\"end\":75976,\"start\":75955},{\"end\":75992,\"start\":75976},{\"end\":76369,\"start\":76352},{\"end\":76394,\"start\":76369},{\"end\":76410,\"start\":76394},{\"end\":76736,\"start\":76719},{\"end\":76948,\"start\":76930},{\"end\":76965,\"start\":76948},{\"end\":76979,\"start\":76965},{\"end\":76996,\"start\":76979},{\"end\":77376,\"start\":77359},{\"end\":77394,\"start\":77376},{\"end\":77406,\"start\":77394},{\"end\":77847,\"start\":77831},{\"end\":77862,\"start\":77847},{\"end\":77879,\"start\":77862},{\"end\":78095,\"start\":78077},{\"end\":78109,\"start\":78095},{\"end\":78130,\"start\":78109},{\"end\":78144,\"start\":78130},{\"end\":78463,\"start\":78440},{\"end\":78477,\"start\":78463},{\"end\":78492,\"start\":78477},{\"end\":78506,\"start\":78492},{\"end\":78519,\"start\":78506},{\"end\":79064,\"start\":79052},{\"end\":79516,\"start\":79497},{\"end\":79526,\"start\":79516},{\"end\":79545,\"start\":79526},{\"end\":79789,\"start\":79769},{\"end\":80163,\"start\":80149},{\"end\":80175,\"start\":80163},{\"end\":80187,\"start\":80175},{\"end\":80197,\"start\":80187},{\"end\":80208,\"start\":80197},{\"end\":80226,\"start\":80208},{\"end\":80232,\"start\":80226},{\"end\":80548,\"start\":80534},{\"end\":80564,\"start\":80548},{\"end\":80836,\"start\":80821},{\"end\":81030,\"start\":81015},{\"end\":81045,\"start\":81030},{\"end\":81570,\"start\":81548},{\"end\":81583,\"start\":81570},{\"end\":81595,\"start\":81583},{\"end\":81609,\"start\":81595},{\"end\":81880,\"start\":81868},{\"end\":81892,\"start\":81880},{\"end\":82133,\"start\":82117},{\"end\":82156,\"start\":82133},{\"end\":82172,\"start\":82156},{\"end\":82187,\"start\":82172},{\"end\":82208,\"start\":82187},{\"end\":82227,\"start\":82208},{\"end\":82240,\"start\":82227},{\"end\":82257,\"start\":82240},{\"end\":82270,\"start\":82257},{\"end\":82286,\"start\":82270},{\"end\":82299,\"start\":82286},{\"end\":82313,\"start\":82299},{\"end\":82884,\"start\":82869},{\"end\":82898,\"start\":82884},{\"end\":82918,\"start\":82898},{\"end\":83263,\"start\":83249},{\"end\":83284,\"start\":83263},{\"end\":83299,\"start\":83284},{\"end\":83313,\"start\":83299},{\"end\":83326,\"start\":83313},{\"end\":83348,\"start\":83326},{\"end\":83365,\"start\":83348},{\"end\":83821,\"start\":83817},{\"end\":83837,\"start\":83821},{\"end\":83850,\"start\":83837},{\"end\":84134,\"start\":84122},{\"end\":84149,\"start\":84134},{\"end\":84164,\"start\":84149},{\"end\":84443,\"start\":84430},{\"end\":84454,\"start\":84443},{\"end\":84468,\"start\":84454},{\"end\":84782,\"start\":84774},{\"end\":84790,\"start\":84782},{\"end\":84803,\"start\":84790},{\"end\":84812,\"start\":84803},{\"end\":85000,\"start\":84986},{\"end\":85013,\"start\":85000},{\"end\":85522,\"start\":85506},{\"end\":85538,\"start\":85522},{\"end\":85740,\"start\":85719},{\"end\":85756,\"start\":85740},{\"end\":85768,\"start\":85756},{\"end\":85782,\"start\":85768},{\"end\":85798,\"start\":85782},{\"end\":85814,\"start\":85798},{\"end\":86367,\"start\":86353},{\"end\":86387,\"start\":86367},{\"end\":86411,\"start\":86387},{\"end\":87040,\"start\":87026},{\"end\":87058,\"start\":87040},{\"end\":87071,\"start\":87058},{\"end\":87084,\"start\":87071},{\"end\":87507,\"start\":87491},{\"end\":87525,\"start\":87507},{\"end\":87541,\"start\":87525},{\"end\":87553,\"start\":87541},{\"end\":87958,\"start\":87948},{\"end\":87976,\"start\":87958},{\"end\":87985,\"start\":87976},{\"end\":88307,\"start\":88290},{\"end\":88333,\"start\":88307},{\"end\":88864,\"start\":88856},{\"end\":89149,\"start\":89134},{\"end\":89159,\"start\":89149},{\"end\":89173,\"start\":89159},{\"end\":89187,\"start\":89173},{\"end\":89422,\"start\":89407},{\"end\":89541,\"start\":89526},{\"end\":89695,\"start\":89669},{\"end\":89712,\"start\":89695},{\"end\":89720,\"start\":89712},{\"end\":90174,\"start\":90163},{\"end\":90445,\"start\":90430},{\"end\":90462,\"start\":90445},{\"end\":90482,\"start\":90462},{\"end\":90495,\"start\":90482},{\"end\":90510,\"start\":90495},{\"end\":90939,\"start\":90926},{\"end\":90950,\"start\":90939},{\"end\":90967,\"start\":90950},{\"end\":90979,\"start\":90967},{\"end\":90995,\"start\":90979},{\"end\":91011,\"start\":90995},{\"end\":91027,\"start\":91011},{\"end\":91039,\"start\":91027},{\"end\":91059,\"start\":91039},{\"end\":91072,\"start\":91059},{\"end\":91089,\"start\":91072},{\"end\":91103,\"start\":91089},{\"end\":91116,\"start\":91103},{\"end\":91132,\"start\":91116},{\"end\":91853,\"start\":91835},{\"end\":91869,\"start\":91853},{\"end\":91889,\"start\":91869},{\"end\":91905,\"start\":91889},{\"end\":91923,\"start\":91905},{\"end\":91939,\"start\":91923},{\"end\":91956,\"start\":91939},{\"end\":91976,\"start\":91956},{\"end\":91987,\"start\":91976},{\"end\":92004,\"start\":91987},{\"end\":92395,\"start\":92375},{\"end\":92411,\"start\":92395},{\"end\":92434,\"start\":92411},{\"end\":92758,\"start\":92745},{\"end\":92774,\"start\":92758},{\"end\":92791,\"start\":92774},{\"end\":93061,\"start\":93042},{\"end\":93073,\"start\":93061},{\"end\":93088,\"start\":93073},{\"end\":93275,\"start\":93259},{\"end\":93293,\"start\":93275},{\"end\":93310,\"start\":93293},{\"end\":93425,\"start\":93413},{\"end\":93619,\"start\":93603},{\"end\":93634,\"start\":93619},{\"end\":93648,\"start\":93634},{\"end\":93663,\"start\":93648},{\"end\":93681,\"start\":93663},{\"end\":93694,\"start\":93681},{\"end\":94241,\"start\":94232},{\"end\":94254,\"start\":94241},{\"end\":94267,\"start\":94254},{\"end\":94281,\"start\":94267},{\"end\":94304,\"start\":94281},{\"end\":94878,\"start\":94862},{\"end\":94894,\"start\":94878},{\"end\":94917,\"start\":94894},{\"end\":94927,\"start\":94917},{\"end\":95252,\"start\":95222},{\"end\":95267,\"start\":95252},{\"end\":95289,\"start\":95267},{\"end\":95305,\"start\":95289},{\"end\":95319,\"start\":95305},{\"end\":95343,\"start\":95319},{\"end\":95352,\"start\":95343},{\"end\":95876,\"start\":95860},{\"end\":95891,\"start\":95876},{\"end\":95905,\"start\":95891},{\"end\":95920,\"start\":95905},{\"end\":95935,\"start\":95920},{\"end\":95952,\"start\":95935},{\"end\":95968,\"start\":95952},{\"end\":95985,\"start\":95968},{\"end\":96464,\"start\":96450},{\"end\":96480,\"start\":96464},{\"end\":96796,\"start\":96778},{\"end\":96810,\"start\":96796},{\"end\":97150,\"start\":97135},{\"end\":97165,\"start\":97150},{\"end\":97178,\"start\":97165},{\"end\":97196,\"start\":97178},{\"end\":97213,\"start\":97196},{\"end\":97232,\"start\":97213},{\"end\":97772,\"start\":97753},{\"end\":97786,\"start\":97772},{\"end\":97800,\"start\":97786},{\"end\":98227,\"start\":98207},{\"end\":98244,\"start\":98227},{\"end\":98257,\"start\":98244},{\"end\":98278,\"start\":98257},{\"end\":98294,\"start\":98278},{\"end\":98309,\"start\":98294},{\"end\":98328,\"start\":98309},{\"end\":99175,\"start\":99158},{\"end\":99193,\"start\":99175},{\"end\":99213,\"start\":99193},{\"end\":99228,\"start\":99213},{\"end\":99477,\"start\":99464},{\"end\":99493,\"start\":99477},{\"end\":99845,\"start\":99832},{\"end\":99853,\"start\":99845},{\"end\":99862,\"start\":99853},{\"end\":99875,\"start\":99862},{\"end\":99888,\"start\":99875},{\"end\":100142,\"start\":100125},{\"end\":100158,\"start\":100142},{\"end\":100172,\"start\":100158},{\"end\":100198,\"start\":100172},{\"end\":100425,\"start\":100410},{\"end\":100444,\"start\":100425},{\"end\":100457,\"start\":100444},{\"end\":100714,\"start\":100703},{\"end\":100728,\"start\":100714},{\"end\":101235,\"start\":101217},{\"end\":101249,\"start\":101235},{\"end\":101433,\"start\":101421},{\"end\":101442,\"start\":101433},{\"end\":101455,\"start\":101442},{\"end\":101466,\"start\":101455},{\"end\":101476,\"start\":101466},{\"end\":101778,\"start\":101766},{\"end\":101790,\"start\":101778},{\"end\":101801,\"start\":101790},{\"end\":101818,\"start\":101801},{\"end\":102113,\"start\":102100},{\"end\":102129,\"start\":102113},{\"end\":102142,\"start\":102129},{\"end\":102159,\"start\":102142},{\"end\":102177,\"start\":102159},{\"end\":102190,\"start\":102177},{\"end\":102206,\"start\":102190},{\"end\":102217,\"start\":102206},{\"end\":102228,\"start\":102217},{\"end\":102246,\"start\":102228},{\"end\":102259,\"start\":102246},{\"end\":102273,\"start\":102259},{\"end\":102299,\"start\":102273},{\"end\":102310,\"start\":102299},{\"end\":102326,\"start\":102310},{\"end\":102338,\"start\":102326},{\"end\":102351,\"start\":102338},{\"end\":102365,\"start\":102351},{\"end\":102381,\"start\":102365},{\"end\":102396,\"start\":102381},{\"end\":102416,\"start\":102396},{\"end\":102422,\"start\":102416},{\"end\":103291,\"start\":103283},{\"end\":103301,\"start\":103291},{\"end\":103315,\"start\":103301},{\"end\":103323,\"start\":103315},{\"end\":103333,\"start\":103323},{\"end\":103807,\"start\":103797},{\"end\":103822,\"start\":103807},{\"end\":103840,\"start\":103822},{\"end\":104360,\"start\":104350},{\"end\":104375,\"start\":104360},{\"end\":104393,\"start\":104375}]", "bib_venue": "[{\"end\":66016,\"start\":65806},{\"end\":66483,\"start\":66408},{\"end\":66832,\"start\":66807},{\"end\":67062,\"start\":67032},{\"end\":67439,\"start\":67389},{\"end\":67852,\"start\":67811},{\"end\":68394,\"start\":68223},{\"end\":69119,\"start\":69063},{\"end\":69515,\"start\":69466},{\"end\":69820,\"start\":69727},{\"end\":70145,\"start\":70115},{\"end\":70402,\"start\":70290},{\"end\":70828,\"start\":70760},{\"end\":71362,\"start\":71294},{\"end\":71734,\"start\":71686},{\"end\":72114,\"start\":72027},{\"end\":72617,\"start\":72582},{\"end\":72926,\"start\":72846},{\"end\":73314,\"start\":73281},{\"end\":73697,\"start\":73630},{\"end\":74195,\"start\":74122},{\"end\":74774,\"start\":74688},{\"end\":75273,\"start\":75242},{\"end\":75598,\"start\":75568},{\"end\":76022,\"start\":75992},{\"end\":76474,\"start\":76410},{\"end\":76749,\"start\":76736},{\"end\":77059,\"start\":76996},{\"end\":77509,\"start\":77406},{\"end\":77892,\"start\":77879},{\"end\":78075,\"start\":78005},{\"end\":78622,\"start\":78519},{\"end\":79151,\"start\":79064},{\"end\":79495,\"start\":79388},{\"end\":79859,\"start\":79789},{\"end\":80293,\"start\":80232},{\"end\":80594,\"start\":80564},{\"end\":80819,\"start\":80768},{\"end\":81146,\"start\":81045},{\"end\":81633,\"start\":81609},{\"end\":81929,\"start\":81892},{\"end\":82386,\"start\":82313},{\"end\":82981,\"start\":82918},{\"end\":83426,\"start\":83365},{\"end\":83860,\"start\":83850},{\"end\":84194,\"start\":84164},{\"end\":84521,\"start\":84468},{\"end\":84772,\"start\":84733},{\"end\":85155,\"start\":85013},{\"end\":85569,\"start\":85538},{\"end\":85920,\"start\":85814},{\"end\":86436,\"start\":86411},{\"end\":86717,\"start\":86616},{\"end\":87162,\"start\":87084},{\"end\":87631,\"start\":87553},{\"end\":88043,\"start\":87985},{\"end\":88399,\"start\":88333},{\"end\":88892,\"start\":88864},{\"end\":89132,\"start\":89072},{\"end\":89405,\"start\":89364},{\"end\":89524,\"start\":89505},{\"end\":89806,\"start\":89720},{\"end\":90198,\"start\":90174},{\"end\":90582,\"start\":90510},{\"end\":91181,\"start\":91132},{\"end\":92040,\"start\":92004},{\"end\":92482,\"start\":92434},{\"end\":92743,\"start\":92657},{\"end\":93097,\"start\":93088},{\"end\":93257,\"start\":93238},{\"end\":93449,\"start\":93425},{\"end\":93789,\"start\":93694},{\"end\":94414,\"start\":94304},{\"end\":94969,\"start\":94927},{\"end\":95438,\"start\":95352},{\"end\":96053,\"start\":95985},{\"end\":96448,\"start\":96386},{\"end\":96841,\"start\":96810},{\"end\":97310,\"start\":97232},{\"end\":97849,\"start\":97800},{\"end\":98431,\"start\":98328},{\"end\":98873,\"start\":98853},{\"end\":99252,\"start\":99228},{\"end\":99580,\"start\":99493},{\"end\":99830,\"start\":99764},{\"end\":100216,\"start\":100198},{\"end\":100408,\"start\":100381},{\"end\":100831,\"start\":100728},{\"end\":101215,\"start\":101177},{\"end\":101540,\"start\":101476},{\"end\":101878,\"start\":101818},{\"end\":102531,\"start\":102422},{\"end\":103420,\"start\":103333},{\"end\":103918,\"start\":103840},{\"end\":104417,\"start\":104393},{\"end\":68552,\"start\":68396},{\"end\":70883,\"start\":70830},{\"end\":72188,\"start\":72116},{\"end\":74255,\"start\":74197},{\"end\":74847,\"start\":74776},{\"end\":77599,\"start\":77511},{\"end\":78712,\"start\":78624},{\"end\":79225,\"start\":79153},{\"end\":79916,\"start\":79861},{\"end\":81234,\"start\":81148},{\"end\":84561,\"start\":84523},{\"end\":85284,\"start\":85157},{\"end\":86013,\"start\":85922},{\"end\":87227,\"start\":87164},{\"end\":87696,\"start\":87633},{\"end\":88452,\"start\":88401},{\"end\":89879,\"start\":89808},{\"end\":91258,\"start\":91183},{\"end\":93871,\"start\":93791},{\"end\":94511,\"start\":94416},{\"end\":95511,\"start\":95440},{\"end\":96108,\"start\":96055},{\"end\":97375,\"start\":97312},{\"end\":97885,\"start\":97851},{\"end\":98521,\"start\":98433},{\"end\":100921,\"start\":100833},{\"end\":102627,\"start\":102533},{\"end\":103494,\"start\":103422},{\"end\":103983,\"start\":103920}]"}}}, "year": 2023, "month": 12, "day": 17}