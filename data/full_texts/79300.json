{"id": 79300, "updated": "2022-07-12 20:33:32.812", "metadata": {"title": "HDRF: Stream-Based Partitioning for Power-Law Graphs", "authors": "[{\"first\":\"Fabio\",\"last\":\"Petroni\",\"middle\":[]},{\"first\":\"Leonardo\",\"last\":\"Querzoni\",\"middle\":[]},{\"first\":\"Khuzaima\",\"last\":\"Daudjee\",\"middle\":[]},{\"first\":\"Shahin\",\"last\":\"Kamali\",\"middle\":[]},{\"first\":\"Giorgio\",\"last\":\"Iacoboni\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management", "publication_date": {"year": 2015, "month": null, "day": null}, "abstract": "Balanced graph partitioning is a fundamental problem that is receiving growing attention with the emergence of distributed graph-computing (DGC) frameworks. In these frameworks, the partitioning strategy plays an important role since it drives the communication cost and the workload balance among computing nodes, thereby affecting system performance. However, existing solutions only partially exploit a key characteristic of natural graphs commonly found in the real-world: their highly skewed power-law degree distributions. In this paper, we propose High-Degree (are) Replicated First (HDRF), a novel streaming vertex-cut graph partitioning algorithm that effectively exploits skewed degree distributions by explicitly taking into account vertex degree in the placement decision. We analytically and experimentally evaluate HDRF on both synthetic and real-world graphs and show that it outperforms all existing algorithms in partitioning quality.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2031709923", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cikm/PetroniQDKI15", "doi": "10.1145/2806416.2806424"}}, "content": {"source": {"pdf_hash": "f7c1d38d3970bdacb9d219d893e203e8f5aeeaec", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "22206eb96434237c4ebfa1daa25d130562582b89", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f7c1d38d3970bdacb9d219d893e203e8f5aeeaec.txt", "contents": "\nHDRF: Stream-Based Partitioning for Power-Law Graphs *\nOctober 19-23, 2015\n\nFabio Petroni petroni@dis.uniroma1.it \nDepartment of Computer Control\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nSchool of Computer Science\nSchool of Computer Science\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nManagement Engineering Antonio Ruberti Sapienza University of Rome\nSapienza University of Rome\nUniversity of Waterloo\nUniversity of Waterloo\nSapienza University of Rome\n\n\nLeonardo Querzoni querzoni@dis.uniroma1.it \nDepartment of Computer Control\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nSchool of Computer Science\nSchool of Computer Science\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nManagement Engineering Antonio Ruberti Sapienza University of Rome\nSapienza University of Rome\nUniversity of Waterloo\nUniversity of Waterloo\nSapienza University of Rome\n\n\nKhuzaima Daudjee kdaudjee@uwaterloo.ca \nDepartment of Computer Control\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nSchool of Computer Science\nSchool of Computer Science\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nManagement Engineering Antonio Ruberti Sapienza University of Rome\nSapienza University of Rome\nUniversity of Waterloo\nUniversity of Waterloo\nSapienza University of Rome\n\n\nDavid R Cheriton \nDepartment of Computer Control\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nSchool of Computer Science\nSchool of Computer Science\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nManagement Engineering Antonio Ruberti Sapienza University of Rome\nSapienza University of Rome\nUniversity of Waterloo\nUniversity of Waterloo\nSapienza University of Rome\n\n\nShahin Kamali s3kamali@uwaterloo.ca \nDepartment of Computer Control\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nSchool of Computer Science\nSchool of Computer Science\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nManagement Engineering Antonio Ruberti Sapienza University of Rome\nSapienza University of Rome\nUniversity of Waterloo\nUniversity of Waterloo\nSapienza University of Rome\n\n\nDavid R Cheriton \nDepartment of Computer Control\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nSchool of Computer Science\nSchool of Computer Science\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nManagement Engineering Antonio Ruberti Sapienza University of Rome\nSapienza University of Rome\nUniversity of Waterloo\nUniversity of Waterloo\nSapienza University of Rome\n\n\nGiorgio Iacoboni g.iacoboni@gmail.com \nDepartment of Computer Control\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nSchool of Computer Science\nSchool of Computer Science\nDepartment of Computer Control and Management Engineering Antonio Ruberti\nManagement Engineering Antonio Ruberti Sapienza University of Rome\nSapienza University of Rome\nUniversity of Waterloo\nUniversity of Waterloo\nSapienza University of Rome\n\n\nHDRF: Stream-Based Partitioning for Power-Law Graphs *\n\nCIKM'15\nMelbourne, VIC, AustraliaOctober 19-23, 201510.1145/2806416.2806424E1 [Data Structures]: Graphs and Networks Keywords Graph PartitioningStreaming AlgorithmsDistributed Graph-Computing FrameworksReplicationLoad Balancing\nBalanced graph partitioning is a fundamental problem that is receiving growing attention with the emergence of distributed graph-computing (DGC) frameworks. In these frameworks, the partitioning strategy plays an important role since it drives the communication cost and the workload balance among computing nodes, thereby affecting system performance. However, existing solutions only partially exploit a key characteristic of natural graphs commonly found in the real-world: their highly skewed power-law degree distributions. In this paper, we propose High-Degree (are) Replicated First (HDRF ), a novel streaming vertex-cut graph partitioning algorithm that effectively exploits skewed degree distributions by explicitly taking into account vertex degree in the placement decision. We analytically and experimentally evaluate HDRF on both synthetic and real-world graphs and show that it outperforms all existing algorithms in partitioning quality.\n\nINTRODUCTION\n\nThe last few years have witnessed a huge growth in information production. Some corporations like IBM estimate that \"2.5 quintillion bytes of data are created every day\", amounting to 90% of the data in the world today having been created in the last two years [10]. On the face of this growth, researchers from both academia and industry have focussed their efforts on the design of new, efficient, approaches for parallel data analysis able to withstand the deluge of data expected in forthcoming years.\n\nGiven the proliferation of data which can be represented as graphs of interconnected vertices, a graph-based computation paradigm provides a nice, suitable, abstraction to perform computation on it. Large amounts of data, particularly scale-free graphs or power-law graphs 1 , fall within this paradigm. An example is recommendation systems where the input data is usually provided in the form of votes (edges) that users (vertices) express on products (vertices). Additionally, graph-based computation finds application in many diverse and important fields such as social networks, computational biology, chemistry, and computer security. A key problem in graph computation is that it is often difficult to scale with increasing input data sizes as graphs are not easily partitionable into independent subgraphs that can be computed in parallel.\n\nTo be able to work on large datasets, distributed graphcomputing (DGC) frameworks (such as GraphLab [18] or Pregel [20]) forcibly partition the input graph by placing its constituting elements, be they either vertices or edges, in distinct partitions, one for each available computing resource. During the partitioning phase, data elements that share connections with other elements already placed in other partitions result in having remote connections amongst them. Since these partitions are usually placed on different machines, this can incur unnecessary or excessive network and computation costs. To address this issue, one frequently used technique is to create and locally place replicas of remotely connected data among these partitions. While this reduces the access cost, replicated data elements must be synchronized during computation so as to avoid replica states from diverging and generating meaningless computation results. This synchronization can significantly hinder performance as it forces replicas to coordinate and exchange data several times during computation.\n\nThe way the input dataset is partitioned has a large impact on the performance of the graph computation. A naive partitioning strategy may end up replicating a large fraction of the input elements on several partitions, severely hampering performance by inducing a large replica synchronization overhead during the computation phase. Furthermore, the partitioning phase should produce evenly balanced partitions (i.e. partitions with similar sizes) to avoid possible load skews in a cluster of machines over which the data is partitioned. Several recent approaches have looked at this problem. Here we focus our attention on stream-based graph partitioning algorithms, i.e. algorithms that partition incoming elements one at a time on the basis of only the current element properties and on previous assignments to partitions (no global knowledge on the input graph). Furthermore, these algorithms are usually one-pass, i.e. they refrain from changing the assignment of a data element to a partition once this has been done. These algorithms are the ideal candidates in settings where input data size and constraints on available resources restrict the type of solutions that can be employed.\n\nOther characteristics of input data also play an important role in partitioning. It has been shown that vertex-cut algorithms are the best approach to deal with input graphs characterized by power-law degree distributions [1,12]. This previous work also clearly outlined the important role highdegree nodes play from a partitioning quality standpoint. Nevertheless, few algorithms take this aspect into account [27,24]. Understandably, this is a challenging problem to solve for stream-based approaches due to their one-pass nature.\n\nIn this paper, we leverage the idea that a partitioning algorithm should do its best to cut, i.e., replicate, highdegree vertices. In particular, we introduce High Degree (are) Replicated First (HDRF ), a stream-based graph partitioning algorithm based on a greedy vertex-cut approach that leverages information on vertex degrees. HDRF is characterized by the following desirable properties: (i) it outputs partitions with the smallest average replication factor among all competing solutions when applied on power-law graphs ( Figure 2) while (ii) providing close to optimal load balancing ( Figure 3). The former is obtained by greedily replicating vertices with larger degrees, while the latter is provided by a parametrizable balancing term whose impact can be tuned to adapt the algorithm behavior to any data input order. On the one hand, lowering the average replication factor is important to reduce network bandwidth cost, memory usage and replica synchronization overhead at computation time. A fair distribution of load on partitions, on the other hand, allows a more efficient usage of available computing resources. HDRF takes into account both of these aspects in an integrated way, significantly reducing the time needed to perform computations on large-scale graphs.\n\nSumming up, this paper provides the following contributions:\n\n\u2022 a novel stream-based graph partitioning algorithm, namely HDRF, that performs better than any competing solution (i.e. processes less vertex-cuts while balancing the load) when applied on power-law graphs;\n\n\u2022 a theoretical analysis of HDRF that provides an averagecase upper bound for the vertex replication factor;\n\n\u2022 a comprehensive experimental evaluation based both on simulations and on a working prototype integrated with GraphLab [19] that shows how a system using HDRF achieves up to 2\u00d7 speedup than adopting a standard greedy placement, and close to 3\u00d7 speedup than using a constrained solution.\n\nThe rest of this paper is organized as follows: we define the problem in Section 2; we briefly describe existing solutions in Section 3; we introduce HDRF in Section 4; we show theoretical bounds for HDRF in Section 5; we present the results of an extensive experimental evaluation in Section 6 and we conclude the paper in Section 7.\n\n\nPROBLEM DEFINITION\n\nThe problem of optimally partitioning a graph to minimize vertex-cuts while maintaining load balance is a fundamental problem in parallel and distributed applications as input placement significantly affects the efficiency of algorithm execution [25]. An edge-cut partitioning scheme results in partitions that are vertex disjoint while a vertex-cut approach results in partitions that are edge disjoint. Both variants are known to be NP-Hard [16,11,2] but have different characteristics and difficulties [16]; for instance, one fundamental difference between the two is that a vertex can be cut in multiple ways and span several partitions while an edge can only connect two partitions.\n\nOne characteristic observed in real-world graphs from social networks or the Web is their skewed power-law degree distribution: most vertices have relatively few connections while a few vertices have many. It has been shown that vertex-cut techniques perform better than edge-cut ones on such graphs (i.e., create less storage and network overhead) [12]. For this reason modern graph parallel processing frameworks, like GraphLab [19], adopt a vertex-cut approach to partition the input data over a cluster of computing nodes. The focus of this paper is on streaming vertex-cut partitioning schemes able to efficiently handle graphs with skewed power-law degree distribution. Notation -Consider a graph G = (V, E), where V = (v1, \u00b7 \u00b7 \u00b7 , vn) is the set of vertices and E = (e1, \u00b7 \u00b7 \u00b7 , em) the set of edges. We define a partition of edges P = (p1, .., p k ) to be a family of pairwise disjoint sets of edges (i.e. pi, pj \u2286 E, pi \u2229 pj = \u2205 for every i = j). Let A(v) \u2286 P be the set of partitions each vertex v \u2208 V is replicated. The size |p| of each partition p \u2208 P is defined as its edge cardinality, because computation steps are usually associated with edges. Since we consider G having a power-law degree distribution, the probability that a vertex has degree d is P (d) \u221d d \u2212\u03b1 , where \u03b1 is a positive constant that controls the \"skewness\" of the degree distribution, i.e. the smaller the value of \u03b1, the more skewed the distribution. Balanced k-way vertex-cut problem -The problem consists in defining a partition of edges such that (i) the average number of vertex replicas (i.e. the number of partitions each vertex is associated to as a consequence of edge partitioning) is minimized and (ii) the partition load (i.e. the number of edges associated to a partition) is within a given bound from the theoretical optimum (i.e. |E|/|P |) [2].\n\nMore formally, the balanced |P |-way vertex-cut partitioning problem aims at solving the following optimization problem:\nmin 1 |V | v\u2208V |A(v)| s.t. max p\u2208P |p| < \u03c3 |E| |P | (1)\nwhere \u03c3 \u2265 1 is a small constant that defines the system tolerance to load imbalance. The objective function (Equation (1)) is called replication factor (RF ), which is the average number of replicas per vertex.\n\nStreaming setting -Without loss of generality, here we assume that the input data is a list of edges, each identified by the two connecting vertices and characterized by some application-related data. We consider algorithms that consume this list in a streaming fashion, requiring only a single pass. This is a common choice for several reasons: (i) it handles situations in which the input data is large enough that fitting it completely in the main memory of a single computing node is impractical; (ii) it can efficiently process dynamic graphs; (iii) it imposes the minimum overhead in time and (iv) it's scalable, providing for straightforward parallel and distributed implementations. A limitation of this approach is that the assignment decision taken on an input element (i.e., an edge) can be based only on previously analyzed data and cannot be later changed.\n\n\nSTREAMING ALGORITHMS\n\nBalanced graph partitioning is a well known NP-hard problem with a wide range of applications in different domains. We do not discuss offline and edge-cut partitioning techniques since they are out of the scope of the paper. It is possible to divide existing streaming vertex-cut partitioning techniques in two main families: hashing and constrained partitioning algorithms and greedy partitioning algorithms.\n\nHashing and constrained partitioning algorithms -All of these algorithms ignore the history of the edge assignments and rely on the presence of a predefined hash function h : N \u2192 N. The input of the hash function h can be either the unique identifier of a vertex or of an edge. All these algorithms can be applied in a streaming setting and achieve good load balance if h guarantees uniformity. Four well-known existing heuristics to solve the partitioning problem belong to this family: hashing, DBH, grid and PDS. The simplest solution is given by the hashing technique that (pseudo-)randomly assigns each edge to a partition: for each input edge e \u2208 E, A(e) = h(e) mod |P | is the identifier of the target partition. This heuristic results in a large number of vertex-cuts in general and performs poorly on powerlaw graphs [12]. A recent paper describes the Degree-Based Hashing (DBH ) algorithm [27], a variation of the hashing heuristic that explicitly considers the degree of the vertices for the placement decision. DBH leverages some of the same intuition as HDRF by cutting vertices with higher degrees to obtain better performance. Concretely, when processing edge e \u2208 E connecting vertices vi, vj \u2208 V with degrees di and dj, DBH defines the hash function h(e) as follows:\nh(e) = h(vi), if di < dj h(vj), otherwise\nThen, it operates as the hashing algorithm. The grid and PDS techniques belong to the constrained partitioning family of algorithms [14]. The general idea of these solutions is to allow each vertex v \u2208 V to be replicated only in a small subset of partitions S(v) \u2282 P that is called the constrained set of v. The constrained set must guarantees some properties; in particular, for each vi, vj \u2208 V : (i)\nS(vi) \u2229 S(vj) = \u2205; (ii) S(vi) \u2286 S(vj) and S(vj) \u2286 S(vi); (iii) |S(vi)| = |S(vj)|.\nIt is easy to observe that this approach naturally imposes an upper bound on the replication factor. To position a new edge e connecting vertices vi and vj, it picks a partition from the intersection between S(vi) and S(vj) either randomly or by choosing the least loaded one. Different solutions differ in the composition of the vertex constrained sets. The grid solution arranges partitions in a X \u00d7 Y matrix such that |P | = XY . It maps each vertex v to a matrix cell using a hash function h, then S(v) is the set of all the partitions in the corresponding row and column. It this way each constrained sets pair has at least two partitions in their intersection. PDS generates constrained sets using Perfect Difference Sets [13]. This ensure that each pair of constrained sets has exactly one partition in the intersection. PDS can be applied only if |P | = x 2 + x + 1, where x is a prime number.\n\nGreedy partitioning algorithms -This family of methods uses the entire history of the edge assignments to make the next decision. The standard greedy approach [12] breaks the randomness of the hashing and constrained solutions by maintaining some global status information. In particular, the system stores the set of partitions A(v) to which each already observed vertex v has been assigned and the current partition sizes. Concretely, when processing edge e \u2208 E connecting vertices vi, vj \u2208 V , the greedy technique follows this simple set of rules:\n\nCase 1: If neither vi nor vj have been assigned to a partition, then e is placed in the partition with the smallest size in P . Case 2: If only one of the two vertices has been already assigned (without loss of generality assume that vi is the assigned vertex) then e is placed in the partition with the smallest size in A(vi). Symmetry is broken with random choices. An equivalent formulation consists of computing a score C greedy (vi, vj, p) for all partitions p \u2208 P , and then assigning e to the partition p * that maximizes C greedy . The score consists of two elements: (i) a replication term C greedy REP (vi, vj, p) and (ii) a balance term C greedy BAL (p). It is defined as follows:\nC greedy (vi, vj, p) = C greedy REP (vi, vj, p) + C greedy BAL (p) (2) C greedy REP (vi, vj, p) = f (vi, p) + f (vj, p) (3) f (v, p) = 1, if p \u2208 A(v) 0, otherwise C greedy BAL (p) = maxsize \u2212 |p| + maxsize \u2212 minsize(4)\nwhere maxsize is the maximum partition size, minsize is the minimum partition size, and is a small constant value.\n\nA recent paper [24] proposes an hybrid solution that tries to combine both edge-cut and vertex-cut approaches together. The resulting heuristic, called Ginger, aims at optimizing the partitioning in a DGC framework. However, Ginger is not a streaming solution, since it needs extra reassignment phases after the original streaming graph partitioning.\n\nWe remark there are other facets of graph partitioning that may affect performance of a DGC framework and have been addressed in other works. For example, some applications are based on dynamic graphs and provided a hashingbased partitioning solution to manage such type of input [21]. Another aspect is the use of other metrics for optimization. For example [28] proposes a solution aimed at aggressively replicating vertices to improve the performance of queries on the graph and to keep them local to each single partition as much as possible. Further contributions along these lines are orthogonal and out of the scope of this paper.\n\n\nTHE HDRF ALGORITHM\n\nIn this section, we present HDRF, a greedy algorithm tailored for skewed power-law graphs.\n\nIn the context of robustness to network failure, Cohen et al. [7,8] and Callaway et al [6] have analytically shown that if only a few high-degree vertices (hubs) are removed from a power-law graph then it is turned into a set of isolated clusters. Moreover, in power-law graphs, the clustering coefficient distribution decreases with increase in the vertex degree [9]. This implies that low-degree vertices often belong to very dense sub-graphs and those sub-graphs are connected to each other through high-degree vertices.\n\nOur partitioning scheme leverages these properties by focusing on the locality of low-degree vertices. In particular, it tries to place each strongly connected component with lowdegree vertices into a single partition by cutting high-degree vertices and replicating them on a large number of partitions. As the number of high-degree vertices in power-law graphs is very low, encouraging replication for only these vertices leads to an overall reduction of the replication factor.\n\nConcretely, when HDRF creates a replica, it does so for the vertex with the highest degree. However, obtaining degrees of vertices for a graph that is consumed in a streaming fashion is not trivial. To avoid the overhead of a preprocessing step (where the input graph should be fully scanned to calculate the vertex exact degrees), a table with partial degrees of the vertices can be maintained that is continuously updated while input is analyzed. As each new edge is considered in the input, the degree values for the corresponding vertices are updated in the table. The partial degree values collected at runtime are usually a good indicator for the actual degree of a vertex since it is more likely that an observed edge belongs to a high-degree vertex rather than to a low-degree one. 2 More formally, when processing edge e \u2208 E connecting vertices vi and vj, the HDRF algorithm retrieves their partial degrees and increments them by one. Let \u03b4(vi) be the partial degree of vi and \u03b4(vj) be the partial degree of vj.\n\nThe degree values are then normalized such that they sum up to one:\n\u03b8(vi) = \u03b4(vi) \u03b4(vi) + \u03b4(vj) = 1 \u2212 \u03b8(vj)(5)\nAs for the greedy heuristic, the HDRF algorithm computes a score C HDRF (vi, vj, p) for all partitions p \u2208 P , and then assigns e to the partition p * that maximizes C HDRF . The score for each partition p \u2208 P is defined as follows:\nC HDRF (vi, vj, p) = C HDRF REP (vi, vj, p) + C HDRF BAL (p) (6) C HDRF REP (vi, vj, p) = g(vi, p) + g(vj, p) (7) g(v, p) = 1 + (1 \u2212 \u03b8(v)), if p \u2208 A(v) 0, otherwise C HDRF BAL (p) = \u03bb \u00b7 C greedy BAL (p) = \u03bb \u00b7 maxsize \u2212 |p| + maxsize \u2212 minsize(8)\nThe \u03bb parameter allows control of the extent of partition size imbalance in the score computation. We introduced this parameter because the standard greedy heuristic may result in highly imbalanced partition sizes, especially when the input is ordered somehow. To see this problem note that C greedy BAL (p) ( Equation 4) is always smaller than one, while C greedy REP and C HDRF REP are either zero or greater than one. For this reason, the balance term CBAL in the greedy algorithm or when 0 < \u03bb \u2264 1 is used only to choose among partitions that exhibit the same value for the replication term CREP, thereby breaking symmetry.\n\nHowever, this may not be enough to ensure load balance. For instance, if the stream of edges is ordered according to some visit order on the graph (e.g., breadth first search or depth first search), when processing edge e \u2208 E connecting vertices vi and vj there is always a single partition p * with C greedy REP (vi, vj, p * ) \u2265 1 (resp. C HDRF REP (vi, vj, p * ) > 1) and all the other partitions p \u2208 P s.t. p = p * have C greedy REP (vi, vj, p) = 0 (resp. C HDRF REP (vi, vj, p) = 0). In this case, the balance term is useless as there is no symmetry to break, and the heuristic ends up placing all edges in a single partition p * . This problem can be solved by setting a value for \u03bb > 1. In our evaluation (Section 6), we empirically studied the trend of the replication factor and the load balance by varying \u03bb (Figure 6). Moreover, note that when \u03bb \u2192 \u221e the algorithm resembles a random heuristic, where past observations are ignored and it only matters to have partitions with equal size. The following summarizes the behavior of the HDRF algorithm with respect to the \u03bb parameter:\n\uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f3 \u03bb = 0,\nagnostic of the load balance 0 < \u03bb \u2264 1, balance used to break the symmetry \u03bb > 1, balance importance proportional to \u03bb \u03bb \u2192 \u221e, random edge assignment When \u03bb = 1 the HDRF algorithm can be represented by a set of simple rules, exactly as in greedy, with the exception of Case 4 that is modified as follows: -if \u03b4(vj) < \u03b4(vi), e is assigned to the partition with the smallest size p * \u2208 A(vj) and a new replica of vi is created in p * .\n\nHDRF can be run as a single process or in parallel instances to speed up the partitioning phase. As with greedy, HDRF also needs some state to be shared among parallel instances during partitioning. In particular, we noticed that sharing the values of A(v), \u2200v \u2208 V is sufficient to let HDRF perform at its best. Note that optimizing the execution time of HDRF was a goal beyond the scope of this work; we will consider it as part of our future work.\n\n\nTHEORETICAL ANALYSIS\n\nIn this section we characterize the HDRF algorithm behavior from a theoretical perspective, focussing on the vertex replication factor. In particular we are interested in an average-case analysis of HDRF. A worst-case analysis would provide poor performance, as expected for any similar greedy algorithm, while failing to capture the typical behavior of HDRF in real cases. In the rest of this section we assume \u03bb = 1 for the sake of simplicity.\n\nCohen et al. [8] considered the problem of a scale-free network (characterized as a power-law graph) attacked by an adversary able to remove a fraction c of vertices with the largest degrees. In particular they characterized the approximate maximum degreeM observable in the graph's largest component after the attack. If |V | 1/c this value can be approximated by the following equation:\nM = mc 1/(1\u2212\u03b1)(9)\nwhere m is the (global) minimum vertex degree and \u03b1 is the parameter characterizing the initial vertex degree distribution.\n\nLet us now consider the algorithm aHDRF as an approximation of HDRF : aHDRF performs exactly as HDRF, but for the fact that we assume it knows the exact degree of each input vertex (and not the observed degree as for HDRF ).\n\nTheorem 1. Algorithm aHDRF achieves a replication factor, when applied to partition a graph with |V | vertices on |P | partitions, that can be bounded by:\nRF \u2264 \u03c4 |P | + 1 |V |(1 \u2212 \u03c4 ) |V |(1\u2212\u03c4 )\u22121 i=0 1 + m \u03c4 + i |V | 1 1\u2212\u03b1 \u03c4 = |P | \u2212 1 m 1\u2212\u03b1\nProof. The replication factor bound is the sum of two distinct parts. The first part considers the fraction \u03c4 of vertices with the largest degrees in the graph, referred to as hubs. The worst case for hubs is to be replicated in all the partitions, with a corresponding replication factor of \u03c4 |P |. \u03c4 represents the fraction of vertices that must be removed from the graph such that the maximum vertex degree in the remaining graph is |P | \u2212 1; this value is obtainable through Equation (9) by imposingM = |P | \u2212 1.\n\nThe second part of the equation consider the contribution to the replication factor from non-hub vertices, i.e. all vertices whose degree is expected to be smaller than |P | \u2212 1 after the \u03c4 vertices with the largest degrees have been removed from the graph (together with their edges). When aHDRF processes an edge connecting a hub vertex with a non-hub vertices, it always favors the replication the hub vertex (that has a larger degree) and replicates the non-hub vertex only if executes Case 1 or Case 2, that is only if it is the first time it observes that vertex. Since the degree of non-hub vertices, ignoring the connections with hub vertices, is bounded by m\u03c4 1/(1\u2212\u03b1) , and since the connections with hub vertices can produce at most one replica, the worst case replication factor for non-hub vertices is bounded by:\n1 |V |(1 \u2212 \u03c4 ) 1 + m\u03c4 1 1\u2212\u03b1\nThis bound can be further improved by considering what happens to the graph once the non-hub vertex v0 with the largest degree is removed. The previous bound is valid for v0. However, the removal of v0 from the graph will change the degree distribution, thus also reducing the bound for the next non-hub vertex with the largest degree. Using this consideration, it is possible to iteratively bound the degree of each non-hub vertex vi with m(\u03c4 + i/|V |) 1/(1\u2212\u03b1) where 0 \u2264 i \u2264 |V |(1\u2212\u03c4 )\u22121. Hence, the total worst case replication factor for non-hub vertices, is bounded by:\n1 |V |(1 \u2212 \u03c4 ) |V |(1\u2212\u03c4 )\u22121 i=0 1 + m \u03c4 + i |V | 1 1\u2212\u03b1\nIf edges arrive in random order, aHDRF gives an approximation of HDRF. In this case, the observed values for vertex degrees are a good estimate for the actual degrees. We can conclude that, assuming random order arrival for edges, HDRF is expected to achieve a replication factor, when applied to partition a graph with |V | vertices on |P | partitions, of at most RF of Theorem 1.\n\nFor example, consider a graph with \u03b1 = 2.2, |P | = 128, m = 1 and 1M vertices. The average-case upper bound for the replication factor of HDRF is \u2248 5.12 while the actual result it achieves is \u2248 1.37. The bounds for DBH and hashing [12,27] with this configuration are respectively \u2248 5.54 and \u2248 5.88, while the actual results they achieve are \u2248 1.89 and \u2248 2.52.\n\nThe upper bound given by Theorem 1 cannot be extended to other algorithms (e.g., greedy). Informally, HDRF breaks network at hubs by replicating a small fraction of vertices with large degrees. In contrast, greedy and other algorithms are agnostic to the degree of vertices when replicating them. Intuitively, these algorithms try to break network by removing random vertices. Unfortunately, power-law graphs are resilient against removing random vertices (see [7] for details). This implies that, in order to fragment a scale-free network, a very large number of random vertices should be removed. In other words, greedy and other algorithms tend to replicate a large number of vertices in different partitions. This intuition is verified in our experiments (see Section 6).\n\n\nEVALUATION\n\nThis section presents experimental results for the HDRF partitioning algorithm. The evaluation was performed on real-world graphs by running the proposed algorithm both in a stand-alone partitioner (useful for scaling up to large partition numbers) and running an implementation of HDRF  integrated into GraphLab 3 . The evaluation also reports experiments on synthetic graphs generated randomly with increasingly skewed distributions to study the extent to which HDRF performance is sensitive to workload characteristics.\n\n\nExperimental Settings and Test Datasets\n\nEvaluation Metrics -We evaluate the performance of HDRF by measuring the following metrics: Replication factor: is the average number of replicas per vertex. This metric is a good measure of the synchronization overhead and should be minimized.\n\nLoad relative standard deviation: is the relative standard deviation of the number of edges hosted in target partitions. An optimal partitioning strategy should have a value for this metric close to 0.\n\nMax partition size: is the number of either vertices or edges hosted in the largest partition. We consider this metric with respect to both vertices and edges as each conveys different information. Edges are the main input for the computation phase, thus more edges in a partition mean more computation for the computing node hosting it; conversely, the number of vertices in the system, and, therefore, in the largest partition, also depends on the number of replicas generated by the partitioning algorithm.\n\nExecution time: is the number of seconds needed by the DGC framework to perform the indicated computation on the whole input graph. Better partitioning, by reducing the number of replicas, is expected to reduce the synchronization overhead at runtime and thus reduce the execution time as well.\n\nDatasets -In our evaluation, we used as datasets both synthetic power-law graphs and real-word graphs. The former were used to study how HDRF performance vary when the degree distribution skewness of the input graph gradually increases. In particular, each synthetic graph was generated with 1M vertices, minimum degree of 5 and edges using a power law distribution with \u03b1 ranging from 1.8 to 4.0. Therefore, the number of edges in the graphs ranges 3 The stand-alone software and the GraphLab patch are available at https://github.com/fabiopetroni/VGP. from \u223c 60M (\u03b1 = 1.8) to \u223c 3M (\u03b1 = 4). Graphs were generated with gengraph [26]. We also tested the performance of HDRF on real-world graphs: twitter-2010 from LAW (Laboratory for Web Algorithmics) [5,4], Tencent Weibo from the KDD-Cup 2012 [22], Netflix from the Netflix Prize [3] and MovieLens 10M from the GroupLens research lab (http://grouplens.org). Table 1 reports some statistics for these 4 datasets. System Setup -We implemented a stand-alone version of a graph partitioner that captures the behavior of a DGC framework during the graph loading and partitioning phase. Within our partitioner, we implemented the five different algorithms described so far: hashing, DBH, grid, PDS, greedy and HDRF. Furthermore, we compared our solution against two offline methods: Ginger [24] and METIS [15], a wellknown edge-cut partitioning algorithm. To compute the replication factor delivered by METIS, we used the same strategy of [12]: every edge-cut forces the two spanned partitions in maintaining a replica of both vertices and a copy of the edge data. To run realistic tests needed to measure execution time, we implemented and integrated HDRF into GraphLab v2.2. Experiments with GraphLab where conducted on a cluster consisting of 8 machines with dual 16core Intel Xeon CPUs and 128GB of memory each. We experimented with 32, 64 and 128 partitions by running multiple instances on a single machine. Data input order -Since the input dataset is consumed as a stream of edges, the input order can affect the performance of the partitioning algorithm. We considered three different stream orders as in [25]: random, where edges arrive according to a random permutation; BFS, where the edge order is generated by selecting a vertex uniformly at random and performing a breadth first search visit starting from that vertex; DFS, that works as BFS except for the visit algorithm that is depth-first search. All reported results are based on a random input order unless otherwise mentioned in the text.\n\n\nPerformance Evaluation\n\nThe experimental results reported in this section are organized as follows: we first report on experiments that show the ability of HDRF to deliver the best overall performance in terms of execution time with the smallest overhead (replication factor) and close to optimal load balance when executed on real-world graphs. We then study how HDRF performance is affected by changes in the characteristics of the input dataset and changes in the target number of partitions. Finally, the last set of results analyze the sensitivity of HDRF to input stream ordering.  \n\n\nRuntime comparison\n\nWe first measured HDRF performance against other streaming partitioning algorithms on our set of real-world graphs. These experiments were run by partitioning the input graphs on a set of target partitions in the range [3,256] with our stand-alone partitioner. Figure 1 reports the replication factor that the considered partitioning algorithms achieve on different input graphs 4 . Moreover, Figure 2a provides a snapshot of the evaluation, by setting the number of target partition to 133, a number compliant with PDS constraints. It can be observed that HDRF is the algorithm that provides the smallest replication factor for all the considered datasets.\n\nIn particular, for the Weibo dataset, characterized by large edge count differences among high-degree and low-degree vertices, it is possible to observe how HDRF and DBH are the best performers as they both exploit vertex degrees. In all the other datasets HDRF is always the best performer, albeit with larger absolute RF values. Summarizing, on the considered datasets HDRF achieves on average a replication factor about 40% smaller than DBH, more than 50% smaller than greedy, almost 3\u00d7 smaller than PDS, more than 4\u00d7 smaller than grid and almost 14\u00d7 smaller than hashing. We experimented with other datasets as well (i.e. arabic-2005, uk-2002, indochina-2004 from LAW, and Yahoo! Music from the KDD-Cup 2011). In all our test HDRF outperforms competing solutions, simultaneously guaranteeing close to perfect load balance (results omitted due to space constraints).\n\nNext, we compared HDRF against two offline partitioning algorithms: Ginger and METIS. Note that these offline solutions have full knowledge of the input graph that can be exploited to drive their partitioning choices. Figure 2b compares the replication factor achieved by these two solutions and HDRF (we maintain |P | = 133 to be coherent with Figure 2a). We do not report the results for the twitter-2010 dataset since METIS produced greatly unbalanced parti- 4 Due to specific constraints imposed by the PDS and grid algorithms on the total number of partitions, their data points are not aligned with those of the other algorithms.  tions 5 , making a comparison on this dataset unfair. The poor performance of METIS was an expected result since it has been proved that edge-cut approaches perform worse than vertex-cut ones on power-law graphs [12]. However, HDRF outperforms Ginger as well, by reducing its replication factor by 10% on average. In addition, HDRF has the clear advantage of consuming the graph in a one-pass fashion while Ginger needs several passes over the input data to converge. These results show that HDRF is always able to provide a smaller average replication factor with respect to all other algorithms, both streaming and offline, when used to partition graphs with power-law degree distributions. Figure 3 reports the load relative standard deviation produced by the tested streaming algorithms when run on the MovieLens 10M dataset with a variable number of target partitions (results for other datasets showed similar behavior so we omit them). The curves show that HDRF and greedy provide the best performance as the number of target partitions grows. As expected, hashing provides well bal- anced partitions, but it still performs worse that the other algorithms as its expected behavior with respect to load balancing is only probabilistic. Grid performs similarly, even if its more complex constraints induce some skew in load. DBH and PDS are the worse performers, with load skew growing at a fast pace as the number of target partitions grows. Note that replication factor reflects communication cost, and edge-imbalance reflects workload-imbalance; providing good performance with these two metrics means that HDRF can provide partitioning results that make the execution of application algorithms more efficient.\n\nTo this end, we studied how much all of this translates to a performance improvement with respect to the execution time. Since a DGC framework has to periodically synchronize all the vertex replicas, having fewer replicas in the system is expected to provide an advantage and to speed up the execution time. To investigate the impact of the different partitioning techniques we ran the Stochastic Gradient Descent (SGD) algorithm for matrix completion [17,23] on GraphLab, using the Tencent Weibo dataset and 100 latent factors, with 32, 64 and 128 partitions respectively. Figure 4 reports the measured speed-up, obtained by using HDRF to partition the input over greedy and PDS 6 . The SGD algorithm runs up to 2\u00d7 faster using HDRF as input partitioner with respect to greedy, and close to 3\u00d7 faster than PDS. The actual improvement is larger as the number of target partitions grows. Moreover, the speedup is proportional to the gain in RF (see Figure 1a) and, as already shown in [12], halving the replication factor approximately halves runtime. Furthermore, having partitions with fewer replicas also help SGD to converge faster [23].\n\nWe tested the speedup for other datasets and algorithms as well, namely Single Source Shortest Path (SSSP), Weakly Connected Components (WCC), Page Rank (PR) and Alternating Least Squares (ALS). The results (not reported here due to space constraints) confirmed our intuitions: the speedup is proportional to both the advantage in replication factor and the actual network usage of the algorithm. The speedup it is larger for IO-intensive algorithms (e.g. SGD, ALS and PR) and smaller for algorithm with less network IO (SSSP and WCC). None of the tests we conducted with HDRF showed a slowdown with respect to other solutions.\n\nOur results show that HDRF is the best solution to partition input graphs characterized by skewed power-law degree distributions. HDRF achieves the smallest replication factor with close to optimal load balance. These two characteristics combined make application algorithms execute more efficiently in the DGC framework.\n\n\nPerformance sensitivity to input shape\n\nWe next analyze how the input graph degree distribution affects HDRF performance. To this end, we used HDRF to partition a set of synthetic power-law graphs. In doing so, we experimentally characterize the sensitivity of the average replication factor on the power-law shape parameter \u03b1, and on the number of partitions. Figure 5a reports the replication factor improvement for HDRF with respect to other algorithms, expressed as a multiplicative factor, by varying \u03b1 in the range [1.8, 4.0] with |P | = 128 target partitions (|P | = 133 and |P | = 121 for PDS and grid respectively). The curves show two important aspects of HDRF behavior: (1) with highly skewed degree distributions (i.e. small values of \u03b1), its performance is significantly better than greedy and other algorithms (with the exception of DBH); (2) with less skewed degree distributions, the performance of HDRF approaches that provided by greedy, while all the other solutions (including DBH ) perform worse. These results show how HDRF behavior approximates greedy's behavior as the number of high degree vertices in the input graph grows as in this case making a different partitioning choice on highdegree vertices is less useful (as there are a lot of them). Note that Gonzalez et al. [12] showed that the effective gain of a vertex-cut approach relative to an edge-cut approach actually increases with smaller \u03b1. Our solution boosts this gain, not only with respect to constrained techniques but also over the greedy algorithm. Figure 5b reports the replication factor, and clearly shows that HDRF is able to outperform all competing algorithms for all values of \u03b1. At the extremes, HDRF is better than DBH when \u03b1 is very small and performs slightly better than greedy when \u03b1 is very large.\n\n\nPerformance sensitivity to input order\n\nA shortcoming of the standard greedy algorithm is its inability to effectively handle streams of input edges when they are ordered. If the input stream is ordered such that two subsequent edges always share a vertex, greedy always places all the edges and their adjacent vertices in a single partition, whatever the target partition number is. The final result is clearly far from being desirable as all of the computation load will be incurred by a single node in the computing cluster.\n\nTo overcome this limitation, we explicitly introduced the parameter \u03bb in the computation of the score for each partition in HDRF (Equations (6) and (8)), that defines the importance of the load balance in the edge placement decision (Section 4). Figure 6 shows the result of an experiment run on the Netflix dataset, where the input stream of edges is ordered according to either a depth-first-search (DFS) or a breadth-first-search (BFS) visit on the graph. The figure shows the average replication factor (Figure 6a), the size of the largest partition expressed as number of contained edges (Figure 6b) and the size of the largest partition ex-    All three figures report the performance obtained with the greedy, hashing and PDS algorithms as horizontal grey lines for reference. With \u03bb \u2264 1 HDRF behaves exactly as greedy (curves BFS and DFS): all edges are placed in a single partition and no vertex is replicated. This behavior is confirmed by the size of the largest partition that in this case contains exactly |E| edges and |V | vertices (Figures 6b and 6c). For \u03bb > 1 the CBAL factor starts to play a fundamental role in balancing the load among the available partitions: the average replication factor for HDRF with both DFS and BFS inputs is just slightly larger than what is achievable with a random input 7 and still substantially lower than what is achievable with PDS or hashing (Figure 6a). At the same time, the size of the largest partition drops to its minimum (Figures 6b and  6c) indicating that the algorithm immediately delivers close to perfect load balancing (i.e. |E|/|P | edges per partition), while the number of vertices hosted in the largest partition reaches its minimum. By further increasing \u03bb toward larger values, the effect of CBAL dominates the HDRF score computation and the algorithms behavior quickly approaches the behavior typical of hashing: large average replication factor, with close to perfect load balancing.\n\nThese results show that i) the CBAL term in HDRF score computation plays an effective role in providing close-toperfect load balancing among partitions while keeping a low average replication factor, and ii) by setting the value of \u03bb slightly larger than 1, it is possible to let HDRF work at a \"sweet spot\" where it can deliver the best performance, even when working on an ordered stream of edges. This last point makes HDRF particularly suitable for application settings where it is not possible to randomize the input stream before feeding it to the graph partitioning algorithm.\n\n\nCONCLUSION\n\nDistributed graph-computing frameworks provide programmers with convenient abstractions to enable computation on large datasets. In these frameworks, system performance is often determined by the graph data partitioning strategy, which impacts the communication cost and the workload balance among compute resources. In this paper, we pro-posed HDRF, a novel stream-based graph partitioning algorithm for distributed graph-computing frameworks. HDRF is based on a greedy vertex-cut approach that leverages information on vertex degrees. Through a theoretical analysis and an extensive experimental evaluation on real-world as well as synthetic graphs using both a stand-alone partitioner and implementation of HDRF in GraphLab, we showed that HDRF is overall the best performing partitioning algorithm for graphs characterized by power-law degree distributions. In particular, HDRF provides the smallest average replication factor with close to optimal load balance. These two characteristics put together allow HDRF to significantly reduce the time needed to perform computation on graphs and makes it the best choice for partitioning graph data.\n\nCase 3 :\n3If A(vi) \u2229 A(vj) = \u2205, then edge e is placed in the partition with the smallest size in A(vi) \u2229 A(vj). Case 4: If A(vi) = \u2205, A(vj) = \u2205 and A(vi)\u2229A(vj) = \u2205, then e is placed in the partition with the smallest size in A(vi) \u222a A(vj) and a new vertex replica is created accordingly.\n\nCase 4\n4If A(vi) = \u2205, A(vj) = \u2205 and A(vi) \u2229 A(vj) = \u2205, then -if \u03b4(vi) < \u03b4(vj), e is assigned to the partition with the smallest size p * \u2208 A(vi) and a new replica of vj is created in p * ;\n\nFigure 1 :\n1Replication factor varying the number of target partitions (log-log scale).\n\nFigure 2 :\n2Replication factor (log scale) with |P | = 133. HDRF is compared against streaming (a) and offline (b) solutions.\n\nFigure 3 :\n3Load relative standard deviation produced by different partitioning algorithms on the Movie-Lens 10M dataset.\n\nFigure 4 :\n4Speedup in the execution time for the SGD algorithm on the Tencent Weibo dataset by applying HDRF with respect to greedy and PDS, with 32, 64 and 128 partitions.\n\nFigure 5 :\n5Replication factor improvement for HDRF in synthetically generated graphs (log-log scale).Figure (a) reports the replication factor increment and Figure (b) the actual replication factor when \u03b1 grows (|P | = 128 except for PDS, where |P | = 133, and grid, where |P | = 121). For Figure (a) HDRF represents the baseline.\n\nFigure 6 :\n6HDRF behavior on the Netflix dataset varying \u03bb, with input edge stream either random or ordered (DFS or BFS graph visits). Reference grey lines represent greedy, hashing and PDS performance.pressed as number of contained vertices (Figure 6c) all while varying the value of \u03bb in the range [0.1, 100] (log-log axes).\n\nTable 1 :\n1Statistics for real-world graphs.\nWe use scale-free and power-law graphs synonymously.\nDuring experiments, we noticed no significant improvements in the algorithm performance when using exact degrees instead of their approximate values.\nNote that the scope of Metis is to balance vertex load among partitions.\nWe needed to use respectively 31, 57 and 133 partitions, to fit PDS constraints.\nThe difference is due to HDRF 's usage of partial information on vertex degrees. Such values are not a good proxy of real vertex degrees if the input stream is not random.\n\nError and attack tolerance of complex networks. R Albert, H Jeong, A.-L Barab\u00e1si, Nature. 4066794R. Albert, H. Jeong, and A.-L. Barab\u00e1si. Error and attack tolerance of complex networks. Nature, 406(6794):378-382, 2000.\n\nBalanced graph partitioning. K Andreev, H R\u00e4cke, Proceedings of the 16th Annual ACM Symposium on Parallelism in Algorithms and Architectures. the 16th Annual ACM Symposium on Parallelism in Algorithms and ArchitecturesK. Andreev and H. R\u00e4cke. Balanced graph partitioning. In Proceedings of the 16th Annual ACM Symposium on Parallelism in Algorithms and Architectures, 2004.\n\nThe netflix prize. J Bennett, S Lanning, Proceedings of KDD cup and workshop. KDD cup and workshopJ. Bennett and S. Lanning. The netflix prize. In Proceedings of KDD cup and workshop, 2007.\n\nLayered label propagation: A multiresolution coordinate-free ordering for compressing social networks. P Boldi, M Rosa, M Santini, S Vigna, Proceedings of the 20th international conference on World Wide Web. the 20th international conference on World Wide WebP. Boldi, M. Rosa, M. Santini, and S. Vigna. Layered label propagation: A multiresolution coordinate-free ordering for compressing social networks. In Proceedings of the 20th international conference on World Wide Web, 2011.\n\nThe webgraph framework i: compression techniques. P Boldi, S Vigna, Proceedings of the 13th international conference on World Wide Web. the 13th international conference on World Wide WebP. Boldi and S. Vigna. The webgraph framework i: compression techniques. In Proceedings of the 13th international conference on World Wide Web, 2004.\n\nNetwork robustness and fragility: Percolation on random graphs. D S Callaway, M E Newman, S H Strogatz, D J Watts, Physical review letters. 85255468D. S. Callaway, M. E. Newman, S. H. Strogatz, and D. J. Watts. Network robustness and fragility: Percolation on random graphs. Physical review letters, 85(25):5468, 2000.\n\nResilience of the internet to random breakdowns. R Cohen, K Erez, D Ben-Avraham, S Havlin, Physical review letters. 85214626R. Cohen, K. Erez, D. Ben-Avraham, and S. Havlin. Resilience of the internet to random breakdowns. Physical review letters, 85(21):4626, 2000.\n\nBreakdown of the internet under intentional attack. R Cohen, K Erez, D Ben-Avraham, S Havlin, Physical review letters. 86163682R. Cohen, K. Erez, D. Ben-Avraham, and S. Havlin. Breakdown of the internet under intentional attack. Physical review letters, 86(16):3682, 2001.\n\nEvolution of networks. S N Dorogovtsev, J F Mendes, Advances in physics. 514S. N. Dorogovtsev and J. F. Mendes. Evolution of networks. Advances in physics, 51(4):1079-1187, 2002.\n\nUnderstanding Big Data. C Eaton, D Deroos, T Deutsch, G Lapis, P Zikopoulos, Mc Graw HillC. Eaton, D. Deroos, T. Deutsch, G. Lapis, and P. Zikopoulos. Understanding Big Data. Mc Graw Hill, 2012.\n\nImproved approximation algorithms for minimum weight vertex separators. U Feige, M Hajiaghayi, J R Lee, SIAM Journal on Computing. 382U. Feige, M. Hajiaghayi, and J. R. Lee. Improved approximation algorithms for minimum weight vertex separators. SIAM Journal on Computing, 38(2):629-657, 2008.\n\nPowergraph: Distributed graph-parallel computation on natural graphs. J E Gonzalez, Y Low, H Gu, D Bickson, C Guestrin, Proceedings of the 10th USENIX Symposium on Operating Systems Design and Implementation. the 10th USENIX Symposium on Operating Systems Design and ImplementationJ. E. Gonzalez, Y. Low, H. Gu, D. Bickson, and C. Guestrin. Powergraph: Distributed graph-parallel computation on natural graphs. In Proceedings of the 10th USENIX Symposium on Operating Systems Design and Implementation, 2012.\n\nPerfect difference sets. H Halberstam, R Laxton, Proceedings of the Glasgow Mathematical Association. the Glasgow Mathematical AssociationH. Halberstam and R. Laxton. Perfect difference sets. In Proceedings of the Glasgow Mathematical Association, 1964.\n\nGraphbuilder: Scalable graph etl framework. N Jain, G Liao, T L Willke, 1st International Workshop on Graph Data Management Experiences and Systems. N. Jain, G. Liao, and T. L. Willke. Graphbuilder: Scalable graph etl framework. In 1st International Workshop on Graph Data Management Experiences and Systems, 2013.\n\nA fast and high quality multilevel scheme for partitioning irregular graphs. G Karypis, V Kumar, SIAM Journal on scientific Computing. 201G. Karypis and V. Kumar. A fast and high quality multilevel scheme for partitioning irregular graphs. SIAM Journal on scientific Computing, 20(1):359-392, 1998.\n\nSBV-Cut: Vertex-cut based graph partitioning using structural balance vertices. M Kim, K S Candan, Data & Knowledge Engineering. 72M. Kim and K. S. Candan. SBV-Cut: Vertex-cut based graph partitioning using structural balance vertices. Data & Knowledge Engineering, 72:285-303, 2012.\n\nMatrix factorization techniques for recommender systems. Y Koren, R Bell, C Volinsky, Computer. 428Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. Computer, 42(8):30-37, 2009.\n\nDistributed graphlab: a framework for machine learning and data mining in the cloud. Y Low, D Bickson, J Gonzalez, C Guestrin, A Kyrola, J M Hellerstein, Proceedings of the VLDB Endowment. 58Y. Low, D. Bickson, J. Gonzalez, C. Guestrin, A. Kyrola, and J. M. Hellerstein. Distributed graphlab: a framework for machine learning and data mining in the cloud. Proceedings of the VLDB Endowment, 5(8):716-727, 2012.\n\nGraphlab: A new framework for parallel machine learning. Y Low, J Gonzalez, A Kyrola, D Bickson, C Guestrin, J M Hellerstein, Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence. the 26th Conference on Uncertainty in Artificial IntelligenceY. Low, J. Gonzalez, A. Kyrola, D. Bickson, C. Guestrin, and J. M. Hellerstein. Graphlab: A new framework for parallel machine learning. In Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence, 2010.\n\nPregel: a system for large-scale graph processing. G Malewicz, M H Austern, A J Bik, J C Dehnert, I Horn, N Leiser, G Czajkowski, Proceedings of the 2010 ACM SIGMOD International Conference on Management of data. the 2010 ACM SIGMOD International Conference on Management of dataG. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert, I. Horn, N. Leiser, and G. Czajkowski. Pregel: a system for large-scale graph processing. In Proceedings of the 2010 ACM SIGMOD International Conference on Management of data, 2010.\n\nManaging large dynamic graphs efficiently. J Mondal, A Deshpande, Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data. the 2012 ACM SIGMOD International Conference on Management of DataJ. Mondal and A. Deshpande. Managing large dynamic graphs efficiently. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, 2012.\n\nThe tencent dataset and kdd-cup'12. Y Niu, Y Wang, G Sun, A Yue, B Dalessandro, C Perlich, B Hamner, KDD-Cup Workshop. Y. Niu, Y. Wang, G. Sun, A. Yue, B. Dalessandro, C. Perlich, and B. Hamner. The tencent dataset and kdd-cup'12. In KDD-Cup Workshop, 2012.\n\nGasgd: stochastic gradient descent for distributed asynchronous matrix completion via graph partitioning. F Petroni, L Querzoni, Proceedings of the 8th ACM Conference on Recommender systems. the 8th ACM Conference on Recommender systemsF. Petroni and L. Querzoni. Gasgd: stochastic gradient descent for distributed asynchronous matrix completion via graph partitioning. In Proceedings of the 8th ACM Conference on Recommender systems, 2014.\n\nPowerlyra: Differentiated graph computation and partitioning on skewed graphs. Y C R Chen, J Shi, H Chen, Proceedings of the 10th ACM SIGOPS European Conference on Computer Systems. the 10th ACM SIGOPS European Conference on Computer SystemsY. C. R. Chen, J. Shi and H. Chen. Powerlyra: Differentiated graph computation and partitioning on skewed graphs. In Proceedings of the 10th ACM SIGOPS European Conference on Computer Systems, 2015.\n\nFennel: Streaming graph partitioning for massive scale graphs. C Tsourakakis, C Gkantsidis, B Radunovic, M Vojnovic, Proceedings of the 7th ACM international conference on Web search and data mining. the 7th ACM international conference on Web search and data miningC. Tsourakakis, C. Gkantsidis, B. Radunovic, and M. Vojnovic. Fennel: Streaming graph partitioning for massive scale graphs. In Proceedings of the 7th ACM international conference on Web search and data mining, 2014.\n\nEfficient and simple generation of random simple connected graphs with prescribed degree sequence. F Viger, M Latapy, Computing and Combinatorics. SpringerF. Viger and M. Latapy. Efficient and simple generation of random simple connected graphs with prescribed degree sequence. In Computing and Combinatorics. Springer, 2005.\n\nDistributed power-law graph computing: Theoretical and empirical analysis. C Xie, L Yan, W.-J Li, Z Zhang, Advances in Neural Information Processing Systems. C. Xie, L. Yan, W.-J. Li, and Z. Zhang. Distributed power-law graph computing: Theoretical and empirical analysis. In Advances in Neural Information Processing Systems, 2014.\n\nTowards effective partition management for large graphs. S Yang, X Yan, B Zong, A Khan, Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data. the 2012 ACM SIGMOD International Conference on Management of DataS. Yang, X. Yan, B. Zong, and A. Khan. Towards effective partition management for large graphs. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, 2012.\n", "annotations": {"author": "[{\"end\":519,\"start\":77},{\"end\":967,\"start\":520},{\"end\":1411,\"start\":968},{\"end\":1833,\"start\":1412},{\"end\":2274,\"start\":1834},{\"end\":2696,\"start\":2275},{\"end\":3139,\"start\":2697}]", "publisher": null, "author_last_name": "[{\"end\":90,\"start\":83},{\"end\":537,\"start\":529},{\"end\":984,\"start\":977},{\"end\":1428,\"start\":1420},{\"end\":1847,\"start\":1841},{\"end\":2291,\"start\":2283},{\"end\":2713,\"start\":2705}]", "author_first_name": "[{\"end\":82,\"start\":77},{\"end\":528,\"start\":520},{\"end\":976,\"start\":968},{\"end\":1417,\"start\":1412},{\"end\":1419,\"start\":1418},{\"end\":1840,\"start\":1834},{\"end\":2280,\"start\":2275},{\"end\":2282,\"start\":2281},{\"end\":2704,\"start\":2697}]", "author_affiliation": "[{\"end\":518,\"start\":116},{\"end\":966,\"start\":564},{\"end\":1410,\"start\":1008},{\"end\":1832,\"start\":1430},{\"end\":2273,\"start\":1871},{\"end\":2695,\"start\":2293},{\"end\":3138,\"start\":2736}]", "title": "[{\"end\":55,\"start\":1},{\"end\":3194,\"start\":3140}]", "venue": "[{\"end\":3203,\"start\":3196}]", "abstract": "[{\"end\":4376,\"start\":3424}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4657,\"start\":4653},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5851,\"start\":5847},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5866,\"start\":5862},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8255,\"start\":8252},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8258,\"start\":8255},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8445,\"start\":8441},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8448,\"start\":8445},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10353,\"start\":10349},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11125,\"start\":11121},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11322,\"start\":11318},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":11325,\"start\":11322},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11327,\"start\":11325},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11384,\"start\":11380},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":11917,\"start\":11913},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11998,\"start\":11994},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13407,\"start\":13404},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":15934,\"start\":15930},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16007,\"start\":16003},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16565,\"start\":16561},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":17645,\"start\":17641},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":17979,\"start\":17975},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":19415,\"start\":19411},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20032,\"start\":20028},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":20111,\"start\":20107},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":20565,\"start\":20562},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20567,\"start\":20565},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":20590,\"start\":20587},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20867,\"start\":20864},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":22297,\"start\":22296},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":26232,\"start\":26229},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":29836,\"start\":29832},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":29839,\"start\":29836},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":30426,\"start\":30423},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":33025,\"start\":33024},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":33206,\"start\":33202},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":33328,\"start\":33325},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33330,\"start\":33328},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":33372,\"start\":33368},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":33408,\"start\":33405},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":33913,\"start\":33909},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":33928,\"start\":33924},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":34062,\"start\":34058},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":34737,\"start\":34733},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":35965,\"start\":35962},{\"end\":35969,\"start\":35965},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":37736,\"start\":37735},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":38126,\"start\":38122},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":40086,\"start\":40082},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":40089,\"start\":40086},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":40618,\"start\":40614},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":40769,\"start\":40765},{\"end\":42253,\"start\":42246},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":43027,\"start\":43023},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":44204,\"start\":44201}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":48054,\"start\":47766},{\"attributes\":{\"id\":\"fig_1\"},\"end\":48244,\"start\":48055},{\"attributes\":{\"id\":\"fig_2\"},\"end\":48333,\"start\":48245},{\"attributes\":{\"id\":\"fig_4\"},\"end\":48460,\"start\":48334},{\"attributes\":{\"id\":\"fig_6\"},\"end\":48583,\"start\":48461},{\"attributes\":{\"id\":\"fig_7\"},\"end\":48758,\"start\":48584},{\"attributes\":{\"id\":\"fig_8\"},\"end\":49091,\"start\":48759},{\"attributes\":{\"id\":\"fig_10\"},\"end\":49419,\"start\":49092},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":49465,\"start\":49420}]", "paragraph": "[{\"end\":4897,\"start\":4392},{\"end\":5745,\"start\":4899},{\"end\":6834,\"start\":5747},{\"end\":8028,\"start\":6836},{\"end\":8562,\"start\":8030},{\"end\":9846,\"start\":8564},{\"end\":9908,\"start\":9848},{\"end\":10117,\"start\":9910},{\"end\":10227,\"start\":10119},{\"end\":10516,\"start\":10229},{\"end\":10852,\"start\":10518},{\"end\":11562,\"start\":10875},{\"end\":13408,\"start\":11564},{\"end\":13530,\"start\":13410},{\"end\":13797,\"start\":13587},{\"end\":14668,\"start\":13799},{\"end\":15102,\"start\":14693},{\"end\":16386,\"start\":15104},{\"end\":16830,\"start\":16429},{\"end\":17814,\"start\":16913},{\"end\":18367,\"start\":17816},{\"end\":19060,\"start\":18369},{\"end\":19394,\"start\":19280},{\"end\":19746,\"start\":19396},{\"end\":20385,\"start\":19748},{\"end\":20498,\"start\":20408},{\"end\":21023,\"start\":20500},{\"end\":21504,\"start\":21025},{\"end\":22526,\"start\":21506},{\"end\":22595,\"start\":22528},{\"end\":22871,\"start\":22639},{\"end\":23745,\"start\":23118},{\"end\":24835,\"start\":23747},{\"end\":25293,\"start\":24861},{\"end\":25744,\"start\":25295},{\"end\":26214,\"start\":25769},{\"end\":26604,\"start\":26216},{\"end\":26746,\"start\":26623},{\"end\":26972,\"start\":26748},{\"end\":27128,\"start\":26974},{\"end\":27733,\"start\":27217},{\"end\":28560,\"start\":27735},{\"end\":29162,\"start\":28589},{\"end\":29599,\"start\":29218},{\"end\":29960,\"start\":29601},{\"end\":30737,\"start\":29962},{\"end\":31274,\"start\":30752},{\"end\":31562,\"start\":31318},{\"end\":31765,\"start\":31564},{\"end\":32276,\"start\":31767},{\"end\":32572,\"start\":32278},{\"end\":35129,\"start\":32574},{\"end\":35720,\"start\":35156},{\"end\":36400,\"start\":35743},{\"end\":37271,\"start\":36402},{\"end\":39628,\"start\":37273},{\"end\":40770,\"start\":39630},{\"end\":41399,\"start\":40772},{\"end\":41722,\"start\":41401},{\"end\":43529,\"start\":41765},{\"end\":44059,\"start\":43572},{\"end\":46018,\"start\":44061},{\"end\":46603,\"start\":46020},{\"end\":47765,\"start\":46618}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13586,\"start\":13531},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16428,\"start\":16387},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16912,\"start\":16831},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19279,\"start\":19061},{\"attributes\":{\"id\":\"formula_4\"},\"end\":22638,\"start\":22596},{\"attributes\":{\"id\":\"formula_5\"},\"end\":23117,\"start\":22872},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24860,\"start\":24836},{\"attributes\":{\"id\":\"formula_7\"},\"end\":26622,\"start\":26605},{\"attributes\":{\"id\":\"formula_8\"},\"end\":27216,\"start\":27129},{\"attributes\":{\"id\":\"formula_9\"},\"end\":28588,\"start\":28561},{\"attributes\":{\"id\":\"formula_10\"},\"end\":29217,\"start\":29163}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":33490,\"start\":33483}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":4390,\"start\":4378},{\"attributes\":{\"n\":\"2.\"},\"end\":10873,\"start\":10855},{\"attributes\":{\"n\":\"3.\"},\"end\":14691,\"start\":14671},{\"attributes\":{\"n\":\"4.\"},\"end\":20406,\"start\":20388},{\"attributes\":{\"n\":\"5.\"},\"end\":25767,\"start\":25747},{\"attributes\":{\"n\":\"6.\"},\"end\":30750,\"start\":30740},{\"attributes\":{\"n\":\"6.1\"},\"end\":31316,\"start\":31277},{\"attributes\":{\"n\":\"6.2\"},\"end\":35154,\"start\":35132},{\"attributes\":{\"n\":\"6.2.1\"},\"end\":35741,\"start\":35723},{\"attributes\":{\"n\":\"6.2.2\"},\"end\":41763,\"start\":41725},{\"attributes\":{\"n\":\"6.2.3\"},\"end\":43570,\"start\":43532},{\"attributes\":{\"n\":\"7.\"},\"end\":46616,\"start\":46606},{\"end\":47775,\"start\":47767},{\"end\":48062,\"start\":48056},{\"end\":48256,\"start\":48246},{\"end\":48345,\"start\":48335},{\"end\":48472,\"start\":48462},{\"end\":48595,\"start\":48585},{\"end\":48770,\"start\":48760},{\"end\":49103,\"start\":49093},{\"end\":49430,\"start\":49421}]", "table": null, "figure_caption": "[{\"end\":48054,\"start\":47777},{\"end\":48244,\"start\":48064},{\"end\":48333,\"start\":48258},{\"end\":48460,\"start\":48347},{\"end\":48583,\"start\":48474},{\"end\":48758,\"start\":48597},{\"end\":49091,\"start\":48772},{\"end\":49419,\"start\":49105},{\"end\":49465,\"start\":49432}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":9100,\"start\":9092},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9165,\"start\":9157},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":24573,\"start\":24564},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":36012,\"start\":36004},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":36145,\"start\":36136},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":37500,\"start\":37491},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":37628,\"start\":37618},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":38611,\"start\":38603},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":40212,\"start\":40204},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":40588,\"start\":40578},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":42095,\"start\":42086},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":43276,\"start\":43267},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":44315,\"start\":44307},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":44578,\"start\":44568},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":44664,\"start\":44654},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":45127,\"start\":45108},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":45466,\"start\":45456},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":45562,\"start\":45542}]", "bib_author_first_name": "[{\"end\":50045,\"start\":50044},{\"end\":50055,\"start\":50054},{\"end\":50067,\"start\":50063},{\"end\":50246,\"start\":50245},{\"end\":50257,\"start\":50256},{\"end\":50611,\"start\":50610},{\"end\":50622,\"start\":50621},{\"end\":50886,\"start\":50885},{\"end\":50895,\"start\":50894},{\"end\":50903,\"start\":50902},{\"end\":50914,\"start\":50913},{\"end\":51318,\"start\":51317},{\"end\":51327,\"start\":51326},{\"end\":51670,\"start\":51669},{\"end\":51672,\"start\":51671},{\"end\":51684,\"start\":51683},{\"end\":51686,\"start\":51685},{\"end\":51696,\"start\":51695},{\"end\":51698,\"start\":51697},{\"end\":51710,\"start\":51709},{\"end\":51712,\"start\":51711},{\"end\":51975,\"start\":51974},{\"end\":51984,\"start\":51983},{\"end\":51992,\"start\":51991},{\"end\":52007,\"start\":52006},{\"end\":52246,\"start\":52245},{\"end\":52255,\"start\":52254},{\"end\":52263,\"start\":52262},{\"end\":52278,\"start\":52277},{\"end\":52491,\"start\":52490},{\"end\":52493,\"start\":52492},{\"end\":52508,\"start\":52507},{\"end\":52510,\"start\":52509},{\"end\":52672,\"start\":52671},{\"end\":52681,\"start\":52680},{\"end\":52691,\"start\":52690},{\"end\":52702,\"start\":52701},{\"end\":52711,\"start\":52710},{\"end\":52916,\"start\":52915},{\"end\":52925,\"start\":52924},{\"end\":52939,\"start\":52938},{\"end\":52941,\"start\":52940},{\"end\":53209,\"start\":53208},{\"end\":53211,\"start\":53210},{\"end\":53223,\"start\":53222},{\"end\":53230,\"start\":53229},{\"end\":53236,\"start\":53235},{\"end\":53247,\"start\":53246},{\"end\":53674,\"start\":53673},{\"end\":53688,\"start\":53687},{\"end\":53948,\"start\":53947},{\"end\":53956,\"start\":53955},{\"end\":53964,\"start\":53963},{\"end\":53966,\"start\":53965},{\"end\":54297,\"start\":54296},{\"end\":54308,\"start\":54307},{\"end\":54600,\"start\":54599},{\"end\":54607,\"start\":54606},{\"end\":54609,\"start\":54608},{\"end\":54862,\"start\":54861},{\"end\":54871,\"start\":54870},{\"end\":54879,\"start\":54878},{\"end\":55112,\"start\":55111},{\"end\":55119,\"start\":55118},{\"end\":55130,\"start\":55129},{\"end\":55142,\"start\":55141},{\"end\":55154,\"start\":55153},{\"end\":55164,\"start\":55163},{\"end\":55166,\"start\":55165},{\"end\":55496,\"start\":55495},{\"end\":55503,\"start\":55502},{\"end\":55515,\"start\":55514},{\"end\":55525,\"start\":55524},{\"end\":55536,\"start\":55535},{\"end\":55548,\"start\":55547},{\"end\":55550,\"start\":55549},{\"end\":55980,\"start\":55979},{\"end\":55992,\"start\":55991},{\"end\":55994,\"start\":55993},{\"end\":56005,\"start\":56004},{\"end\":56007,\"start\":56006},{\"end\":56014,\"start\":56013},{\"end\":56016,\"start\":56015},{\"end\":56027,\"start\":56026},{\"end\":56035,\"start\":56034},{\"end\":56045,\"start\":56044},{\"end\":56488,\"start\":56487},{\"end\":56498,\"start\":56497},{\"end\":56860,\"start\":56859},{\"end\":56867,\"start\":56866},{\"end\":56875,\"start\":56874},{\"end\":56882,\"start\":56881},{\"end\":56889,\"start\":56888},{\"end\":56904,\"start\":56903},{\"end\":56915,\"start\":56914},{\"end\":57189,\"start\":57188},{\"end\":57200,\"start\":57199},{\"end\":57604,\"start\":57603},{\"end\":57608,\"start\":57605},{\"end\":57616,\"start\":57615},{\"end\":57623,\"start\":57622},{\"end\":58029,\"start\":58028},{\"end\":58044,\"start\":58043},{\"end\":58058,\"start\":58057},{\"end\":58071,\"start\":58070},{\"end\":58549,\"start\":58548},{\"end\":58558,\"start\":58557},{\"end\":58852,\"start\":58851},{\"end\":58859,\"start\":58858},{\"end\":58869,\"start\":58865},{\"end\":58875,\"start\":58874},{\"end\":59168,\"start\":59167},{\"end\":59176,\"start\":59175},{\"end\":59183,\"start\":59182},{\"end\":59191,\"start\":59190}]", "bib_author_last_name": "[{\"end\":50052,\"start\":50046},{\"end\":50061,\"start\":50056},{\"end\":50076,\"start\":50068},{\"end\":50254,\"start\":50247},{\"end\":50263,\"start\":50258},{\"end\":50619,\"start\":50612},{\"end\":50630,\"start\":50623},{\"end\":50892,\"start\":50887},{\"end\":50900,\"start\":50896},{\"end\":50911,\"start\":50904},{\"end\":50920,\"start\":50915},{\"end\":51324,\"start\":51319},{\"end\":51333,\"start\":51328},{\"end\":51681,\"start\":51673},{\"end\":51693,\"start\":51687},{\"end\":51707,\"start\":51699},{\"end\":51718,\"start\":51713},{\"end\":51981,\"start\":51976},{\"end\":51989,\"start\":51985},{\"end\":52004,\"start\":51993},{\"end\":52014,\"start\":52008},{\"end\":52252,\"start\":52247},{\"end\":52260,\"start\":52256},{\"end\":52275,\"start\":52264},{\"end\":52285,\"start\":52279},{\"end\":52505,\"start\":52494},{\"end\":52517,\"start\":52511},{\"end\":52678,\"start\":52673},{\"end\":52688,\"start\":52682},{\"end\":52699,\"start\":52692},{\"end\":52708,\"start\":52703},{\"end\":52722,\"start\":52712},{\"end\":52922,\"start\":52917},{\"end\":52936,\"start\":52926},{\"end\":52945,\"start\":52942},{\"end\":53220,\"start\":53212},{\"end\":53227,\"start\":53224},{\"end\":53233,\"start\":53231},{\"end\":53244,\"start\":53237},{\"end\":53256,\"start\":53248},{\"end\":53685,\"start\":53675},{\"end\":53695,\"start\":53689},{\"end\":53953,\"start\":53949},{\"end\":53961,\"start\":53957},{\"end\":53973,\"start\":53967},{\"end\":54305,\"start\":54298},{\"end\":54314,\"start\":54309},{\"end\":54604,\"start\":54601},{\"end\":54616,\"start\":54610},{\"end\":54868,\"start\":54863},{\"end\":54876,\"start\":54872},{\"end\":54888,\"start\":54880},{\"end\":55116,\"start\":55113},{\"end\":55127,\"start\":55120},{\"end\":55139,\"start\":55131},{\"end\":55151,\"start\":55143},{\"end\":55161,\"start\":55155},{\"end\":55178,\"start\":55167},{\"end\":55500,\"start\":55497},{\"end\":55512,\"start\":55504},{\"end\":55522,\"start\":55516},{\"end\":55533,\"start\":55526},{\"end\":55545,\"start\":55537},{\"end\":55562,\"start\":55551},{\"end\":55989,\"start\":55981},{\"end\":56002,\"start\":55995},{\"end\":56011,\"start\":56008},{\"end\":56024,\"start\":56017},{\"end\":56032,\"start\":56028},{\"end\":56042,\"start\":56036},{\"end\":56056,\"start\":56046},{\"end\":56495,\"start\":56489},{\"end\":56508,\"start\":56499},{\"end\":56864,\"start\":56861},{\"end\":56872,\"start\":56868},{\"end\":56879,\"start\":56876},{\"end\":56886,\"start\":56883},{\"end\":56901,\"start\":56890},{\"end\":56912,\"start\":56905},{\"end\":56922,\"start\":56916},{\"end\":57197,\"start\":57190},{\"end\":57209,\"start\":57201},{\"end\":57613,\"start\":57609},{\"end\":57620,\"start\":57617},{\"end\":57628,\"start\":57624},{\"end\":58041,\"start\":58030},{\"end\":58055,\"start\":58045},{\"end\":58068,\"start\":58059},{\"end\":58080,\"start\":58072},{\"end\":58555,\"start\":58550},{\"end\":58565,\"start\":58559},{\"end\":58856,\"start\":58853},{\"end\":58863,\"start\":58860},{\"end\":58872,\"start\":58870},{\"end\":58881,\"start\":58876},{\"end\":59173,\"start\":59169},{\"end\":59180,\"start\":59177},{\"end\":59188,\"start\":59184},{\"end\":59196,\"start\":59192}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":1545338},\"end\":50214,\"start\":49996},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":7330838},\"end\":50589,\"start\":50216},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":9528522},\"end\":50780,\"start\":50591},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":1689835},\"end\":51265,\"start\":50782},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":14428620},\"end\":51603,\"start\":51267},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2325768},\"end\":51923,\"start\":51605},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":15372152},\"end\":52191,\"start\":51925},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":3852896},\"end\":52465,\"start\":52193},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":429546},\"end\":52645,\"start\":52467},{\"attributes\":{\"id\":\"b9\"},\"end\":52841,\"start\":52647},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":14097859},\"end\":53136,\"start\":52843},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":13396177},\"end\":53646,\"start\":53138},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":121993333},\"end\":53901,\"start\":53648},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1447679},\"end\":54217,\"start\":53903},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3628209},\"end\":54517,\"start\":54219},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":10859149},\"end\":54802,\"start\":54519},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":58370896},\"end\":55024,\"start\":54804},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":11819780},\"end\":55436,\"start\":55026},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":61494},\"end\":55926,\"start\":55438},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":53034533},\"end\":56442,\"start\":55928},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":16166412},\"end\":56821,\"start\":56444},{\"attributes\":{\"id\":\"b21\"},\"end\":57080,\"start\":56823},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":14290237},\"end\":57522,\"start\":57082},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":59337241},\"end\":57963,\"start\":57524},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":9590483},\"end\":58447,\"start\":57965},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":5931272},\"end\":58774,\"start\":58449},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":5957760},\"end\":59108,\"start\":58776},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":13923918},\"end\":59534,\"start\":59110}]", "bib_title": "[{\"end\":50042,\"start\":49996},{\"end\":50243,\"start\":50216},{\"end\":50608,\"start\":50591},{\"end\":50883,\"start\":50782},{\"end\":51315,\"start\":51267},{\"end\":51667,\"start\":51605},{\"end\":51972,\"start\":51925},{\"end\":52243,\"start\":52193},{\"end\":52488,\"start\":52467},{\"end\":52913,\"start\":52843},{\"end\":53206,\"start\":53138},{\"end\":53671,\"start\":53648},{\"end\":53945,\"start\":53903},{\"end\":54294,\"start\":54219},{\"end\":54597,\"start\":54519},{\"end\":54859,\"start\":54804},{\"end\":55109,\"start\":55026},{\"end\":55493,\"start\":55438},{\"end\":55977,\"start\":55928},{\"end\":56485,\"start\":56444},{\"end\":56857,\"start\":56823},{\"end\":57186,\"start\":57082},{\"end\":57601,\"start\":57524},{\"end\":58026,\"start\":57965},{\"end\":58546,\"start\":58449},{\"end\":58849,\"start\":58776},{\"end\":59165,\"start\":59110}]", "bib_author": "[{\"end\":50054,\"start\":50044},{\"end\":50063,\"start\":50054},{\"end\":50078,\"start\":50063},{\"end\":50256,\"start\":50245},{\"end\":50265,\"start\":50256},{\"end\":50621,\"start\":50610},{\"end\":50632,\"start\":50621},{\"end\":50894,\"start\":50885},{\"end\":50902,\"start\":50894},{\"end\":50913,\"start\":50902},{\"end\":50922,\"start\":50913},{\"end\":51326,\"start\":51317},{\"end\":51335,\"start\":51326},{\"end\":51683,\"start\":51669},{\"end\":51695,\"start\":51683},{\"end\":51709,\"start\":51695},{\"end\":51720,\"start\":51709},{\"end\":51983,\"start\":51974},{\"end\":51991,\"start\":51983},{\"end\":52006,\"start\":51991},{\"end\":52016,\"start\":52006},{\"end\":52254,\"start\":52245},{\"end\":52262,\"start\":52254},{\"end\":52277,\"start\":52262},{\"end\":52287,\"start\":52277},{\"end\":52507,\"start\":52490},{\"end\":52519,\"start\":52507},{\"end\":52680,\"start\":52671},{\"end\":52690,\"start\":52680},{\"end\":52701,\"start\":52690},{\"end\":52710,\"start\":52701},{\"end\":52724,\"start\":52710},{\"end\":52924,\"start\":52915},{\"end\":52938,\"start\":52924},{\"end\":52947,\"start\":52938},{\"end\":53222,\"start\":53208},{\"end\":53229,\"start\":53222},{\"end\":53235,\"start\":53229},{\"end\":53246,\"start\":53235},{\"end\":53258,\"start\":53246},{\"end\":53687,\"start\":53673},{\"end\":53697,\"start\":53687},{\"end\":53955,\"start\":53947},{\"end\":53963,\"start\":53955},{\"end\":53975,\"start\":53963},{\"end\":54307,\"start\":54296},{\"end\":54316,\"start\":54307},{\"end\":54606,\"start\":54599},{\"end\":54618,\"start\":54606},{\"end\":54870,\"start\":54861},{\"end\":54878,\"start\":54870},{\"end\":54890,\"start\":54878},{\"end\":55118,\"start\":55111},{\"end\":55129,\"start\":55118},{\"end\":55141,\"start\":55129},{\"end\":55153,\"start\":55141},{\"end\":55163,\"start\":55153},{\"end\":55180,\"start\":55163},{\"end\":55502,\"start\":55495},{\"end\":55514,\"start\":55502},{\"end\":55524,\"start\":55514},{\"end\":55535,\"start\":55524},{\"end\":55547,\"start\":55535},{\"end\":55564,\"start\":55547},{\"end\":55991,\"start\":55979},{\"end\":56004,\"start\":55991},{\"end\":56013,\"start\":56004},{\"end\":56026,\"start\":56013},{\"end\":56034,\"start\":56026},{\"end\":56044,\"start\":56034},{\"end\":56058,\"start\":56044},{\"end\":56497,\"start\":56487},{\"end\":56510,\"start\":56497},{\"end\":56866,\"start\":56859},{\"end\":56874,\"start\":56866},{\"end\":56881,\"start\":56874},{\"end\":56888,\"start\":56881},{\"end\":56903,\"start\":56888},{\"end\":56914,\"start\":56903},{\"end\":56924,\"start\":56914},{\"end\":57199,\"start\":57188},{\"end\":57211,\"start\":57199},{\"end\":57615,\"start\":57603},{\"end\":57622,\"start\":57615},{\"end\":57630,\"start\":57622},{\"end\":58043,\"start\":58028},{\"end\":58057,\"start\":58043},{\"end\":58070,\"start\":58057},{\"end\":58082,\"start\":58070},{\"end\":58557,\"start\":58548},{\"end\":58567,\"start\":58557},{\"end\":58858,\"start\":58851},{\"end\":58865,\"start\":58858},{\"end\":58874,\"start\":58865},{\"end\":58883,\"start\":58874},{\"end\":59175,\"start\":59167},{\"end\":59182,\"start\":59175},{\"end\":59190,\"start\":59182},{\"end\":59198,\"start\":59190}]", "bib_venue": "[{\"end\":50434,\"start\":50358},{\"end\":50689,\"start\":50669},{\"end\":51041,\"start\":50990},{\"end\":51454,\"start\":51403},{\"end\":53419,\"start\":53347},{\"end\":53786,\"start\":53750},{\"end\":55703,\"start\":55642},{\"end\":56207,\"start\":56141},{\"end\":56659,\"start\":56593},{\"end\":57318,\"start\":57273},{\"end\":57765,\"start\":57706},{\"end\":58231,\"start\":58165},{\"end\":59347,\"start\":59281},{\"end\":50084,\"start\":50078},{\"end\":50356,\"start\":50265},{\"end\":50667,\"start\":50632},{\"end\":50988,\"start\":50922},{\"end\":51401,\"start\":51335},{\"end\":51743,\"start\":51720},{\"end\":52039,\"start\":52016},{\"end\":52310,\"start\":52287},{\"end\":52538,\"start\":52519},{\"end\":52669,\"start\":52647},{\"end\":52972,\"start\":52947},{\"end\":53345,\"start\":53258},{\"end\":53748,\"start\":53697},{\"end\":54050,\"start\":53975},{\"end\":54352,\"start\":54316},{\"end\":54646,\"start\":54618},{\"end\":54898,\"start\":54890},{\"end\":55213,\"start\":55180},{\"end\":55640,\"start\":55564},{\"end\":56139,\"start\":56058},{\"end\":56591,\"start\":56510},{\"end\":56940,\"start\":56924},{\"end\":57271,\"start\":57211},{\"end\":57704,\"start\":57630},{\"end\":58163,\"start\":58082},{\"end\":58594,\"start\":58567},{\"end\":58932,\"start\":58883},{\"end\":59279,\"start\":59198}]"}}}, "year": 2023, "month": 12, "day": 17}