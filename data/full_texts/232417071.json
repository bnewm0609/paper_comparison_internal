{"id": 232417071, "updated": "2023-10-06 05:39:21.224", "metadata": {"title": "Complementary Relation Contrastive Distillation", "authors": "[{\"first\":\"Jinguo\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Shixiang\",\"last\":\"Tang\",\"middle\":[]},{\"first\":\"Dapeng\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Shijie\",\"last\":\"Yu\",\"middle\":[]},{\"first\":\"Yakun\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Aijun\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Mingzhe\",\"last\":\"Rong\",\"middle\":[]},{\"first\":\"Xiaohua\",\"last\":\"Wang\",\"middle\":[]}]", "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "journal": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "publication_date": {"year": 2021, "month": 3, "day": 29}, "abstract": "Knowledge distillation aims to transfer representation ability from a teacher model to a student model. Previous approaches focus on either individual representation distillation or inter-sample similarity preservation. While we argue that the inter-sample relation conveys abundant information and needs to be distilled in a more effective way. In this paper, we propose a novel knowledge distillation method, namely Complementary Relation Contrastive Distillation (CRCD), to transfer the structural knowledge from the teacher to the student. Specifically, we estimate the mutual relation in an anchor-based way and distill the anchor-student relation under the supervision of its corresponding anchor-teacher relation. To make it more robust, mutual relations are modeled by two complementary elements: the feature and its gradient. Furthermore, the low bound of mutual information between the anchor-teacher relation distribution and the anchor-student relation distribution is maximized via relation contrastive loss, which can distill both the sample representation and the inter-sample relations. Experiments on different benchmarks demonstrate the effectiveness of our proposed CRCD.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2103.16367", "mag": "3144033074", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/ZhuTCYLRYW21", "doi": "10.1109/cvpr46437.2021.00914"}}, "content": {"source": {"pdf_hash": "fdc369b826bafb1eb0c4e1ff03dff3517896f80b", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2103.16367v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2103.16367", "status": "GREEN"}}, "grobid": {"id": "145a9d4fdd3fee36a75db1aa2aae35c0d6c8aa4c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/fdc369b826bafb1eb0c4e1ff03dff3517896f80b.txt", "contents": "\nComplementary Relation Contrastive Distillation\n\n\nJinguo Zhu \nXi'an Jiaotong University\n\n\nShixiang Tang tangshixiang@sensetime.com \nThe University of Sydney\n\n\nDapeng Chen \nSensetime Group Limited\n\n\n\u2021 Shijie \nShenzhen Institutes of Advanced Technology\nCAS\n\nYu \nYakun Liu liuyakun1@sensetime.com \nSensetime Group Limited\n\n\nMingzhe Rong mzrong@mail.xjtu.edu.cn \nXi'an Jiaotong University\n\n\nAijun Yang yangaijun@mail.xjtu.edu.cn \nXi'an Jiaotong University\n\n\nXiaohua Wang \nXi'an Jiaotong University\n\n\nComplementary Relation Contrastive Distillation\n\nKnowledge distillation aims to transfer representation ability from a teacher model to a student model. Previous approaches focus on either individual representation distillation or inter-sample similarity preservation. While we argue that the inter-sample relation conveys abundant information and needs to be distilled in a more effective way. In this paper, we propose a novel knowledge distillation method, namely Complementary Relation Contrastive Distillation (CRCD), to transfer the structural knowledge from the teacher to the student. Specifically, we estimate the mutual relation in an anchor-based way and distill the anchorstudent relation under the supervision of its corresponding anchor-teacher relation. To make it more robust, mutual relations are modeled by two complementary elements: the feature and its gradient. Furthermore, the low bound of mutual information between the anchor-teacher relation distribution and the anchor-student relation distribution is maximized via relation contrastive loss, which can distill both the sample representation and the inter-sample relations. Experiments on different benchmarks demonstrate the effectiveness of our proposed CRCD.\n\nIntroduction\n\nKnowledge distillation aims to transfer the knowledge from one deep learning model (the teacher) to another (the student), such as distilling a large network into a smaller one [19,49,2,48,12] or ensembling a collection of models into a single model [29,37,27,45]. It has a wide range of applications in the industry especially when a neural network needs to be efficiently deployed on devices with limited computational resources [9,54,38]. Although great progress has been achieved in the knowledge distillation \u2020 This work was done when Jinguo Zhu was an intern at SenseTime. \u2021 Corresponding authors. A closer to f T A , sample contrastive distillation will simultaneously push f S A away from f T B , f T C and f T D without distinction, whereas relation preserving distillation preserves the feature relations across the feature space, thus f S A can be optimized along the optimal direction. regime, there is still no consensus on what kind of knowledge really needs to be preserved in the distillation [14].\n\nAs one of the most effective distillation methods, CRD [41] holds the view that the representational knowledge is structured. So It tries to capture the correlations and higherorder output dependencies for each sample, which is different from the original KD objective introduced in [19] that treats all dimensions as independent information. CRD leverages the family of contrastive objectives [20,40,46,4] to maximize a lower-bound of the mutual information between the teacher and student representations. It essentially performs knowledge distillation based on the individual samples, enforcing the representation consistency between the teacher model and the student model.\n\nHowever, neither CRD nor other sample-based distillation methods can effectively preserve inter-sample relations, which are more valuable than the sample representations themselves in many practical tasks, e.g., retrieval and classification. As shown in Fig. 1, when using sample contrastive distillation methods, e.g., CRD, the optimized forces from other neighbors just push the student representation of sample A away when contrasted negatively, which may not be optimal and can break the latent structural geometry of neighboring samples. Some recent works have shown that transferring the mutual similarity instead of actual representation is beneficial to student representation learning [43,32,34,33]. These methods directly estimate the relations in teacher space by computing the intersample similarities, then mimic these similarities in the student space via L 2 loss or KL divergence, ignoring the highorder dependency within the representation in both relation estimation and knowledge distillation.\n\nTo robustly distill the structural knowledge of the teacher space, we define a new cross-space relation between two samples and supervise this new relation by its corresponding relation in the teacher representation space. More specifically, given the teacher and student representation of one sample, we select a neighboring sample's representation from the teacher representation space as an anchor. The anchor-student relation is encouraged to be consistent with the anchor-teacher relation. Our method brings at least three merits for distillation. (1) It simultaneously optimizes the representation and relation. When the anchor-student relation is pushed to be consistent with the anchor-teacher relation, the student representation is actually optimized along the optimal direction of representation learning. (2) The anchor-student relation is more effective for distillation compared with the student-student relation (where two representations are both from the student space) in the conventional KD family [43,32,34]. The student-student relation is unstable because the two representations in the student space are not well optimized and they will drift significantly during distillation, while the anchor representation within the anchor-student relation is fixed, which can effectively optimize the representation in the student space. (3) As the anchor can be randomly selected from the neighborhood of the considered sample, the student representation of one sample is supervised by multiple relations from different anchors, which guarantees the robustness of the distillation.\n\nThe representation relation is modeled by two complementary elements: the feature and its gradient. The fea-ture relation reflects the structural information in representational space, and the gradient relation is computed by the feature gradients after backward propagation. As gradients measure the fastest rate and direction for loss minimization, gradient relation can explore the structural information of optimization kinetics in representational space [18,39]. During the distillation, we maximize the mutual information between the anchor-teacher relation and the anchorstudent relation for both two elements. The maximization problem can further surrogate to maximize the lower bound of mutual information which has been well solved by contrastive learning [46]. Our method is therefore denoted by Complementary Relation Contrastive Distillation(CRCD).\n\nIn summary, the main contributions of CRCD are threefold. First, we define a new anchor-based cross space relation and adopt it to effectively and robustly distill both sample representations and inter-sample relations. Second, the new relation is modeled by two complementary elements, i.e., the feature and its gradients, which capture the structure information of the feature and the optimization kinetics, respectively. Last, we maximize the low bound of mutual information between the anchor-teacher relation and the anchor-student relation and derive an efficient solution in the form of contrastive learning. Extensive experiments empirically validate the effectiveness of CRCD and further improve the current state-of-the-art in various benchmarks.\n\n\nRelated Work\n\nKnowledge Distillation. There has been a rising interest in distilling knowledge from one model to another, in which the core issue is that what is the knowledge learned by a teacher and how to best distill the knowledge into a student. In [19], the soft probability distribution is transferred by using a higher temperature value. Compared to the onehot label, soft targets can contain much more valuable information that defines a rich similarity structure over the data. Furthermore, not only the soft labels but also the hints from intermediate layers are used to train student networks in [35]. Moreover, the attention map [51] and the flow of solution procedure (FSP) [50] are used to transfer knowledge between networks. These works focus on distilling the knowledge modeled by learned presentations of samples themselves, however, ignore the mutual relations between samples, which contain rich structural information learned by the teacher.\n\nThere are a few recent works analyzing and exploiting the mutual relation between data samples [28,34,32,33,6,5,7,25]. In particular, similarity-preserving knowledge [43] proposes to transfer the knowledge presented as similar activation between input pairs. In [34] and [32], the sample relations are modeled explicitly to transfer knowledge. However, these methods all use low-dimensional relation methods, such as cosine similarity [43] or gaus- To distill the structural knowledge from the teacher model \u2126 T to the student model \u2126 S , two complementary elements, the feature f and its gradient g, are utilized to model the representation relations. For each element, auxiliary subnetworks M T and M T,S are used to estimate the anchor-teacher relation R T in the teacher space and anchor-student relation R T,S across space respectively. Meanwhile, the cross-space R T,S is supervised by its corresponding R T . By this way, not only the relation estimation but also the representation learning can be achieved.\n\nsian RBF [34] between features, to model the mutual relation, which may be suboptimal for modeling complex intersample interdependencies. Instead, in our paper, we design sub-networks to learn the high-dimensional across-space relations which can capture the complex mutual dependencies of deep representations from any two feature spaces. Contrastive Learning. Contrastive Learning serves as the core idea of several recent works on self-supervised representation learning [8,16,30,20,15,44,42,13]. Contrastive losses such as NCE [31,20] measure the similarities of data samples in a deep representation space, which learn representation by contrasting positive and negative representation pairs. For knowledge distillation, CRD [41] is the first study that combines contrastive learning with knowledge distillation, which aims to maximize mutual information [3] between the teacher and student representations. Besides, SSKD [47] proposes to use contrastive tasks as selfsupervised pretext tasks, which can facilitate the extraction of richer knowledge from the teacher to the student. From the usage of the contrastive loss, our method is more similar to CRD, but our objective is the mutual relations of deep representations, instead of the representations themselves.\n\n\nMethodology\n\nFig . 1 presents the overall flowchart of our proposed CRCD. Given a teacher network \u2126 T and a student network \u2126 S , we denote the representation of an input x produced by the two networks as \u03c6 T (x) and \u03c6 S (x), respectively. Let x i and x j be two training samples randomly chosen from the sample set X. We denote the relation in the teacher space as r T i,j , where r T i,j is a vector computed by a sub-network M T that takes \u03c6 T (x i ) and \u03c6 T (x j ) as inputs. We further define a new relation r T,S i,j computed by another sub-network M T,S . It is noteworthy that the inputs \u03c6 T (x i ) and \u03c6 S (x j ) for M T,S are from different spaces. Regarding \u03c6 T (x i ) as an anchor representation, the cross-space anchor-student relation r T,S i,j is expected to be consistent with the teacher-space anchor-teacher relation r T i,j , which not only preserves the relation between x i and x j , but also drives the \u03c6 S (x j ) to be consistent with \u03c6 T (x j ).\n\nIn the following sub-sections, we first demonstrate how to use contrastive learning to perform the relation distillation, then two complementary elements are introduced to model the representation relations, and the implementation details and some discussions will be presented at last. The complete mathematical derivation refers to the supplementary materials.\n\n\nRelation Contrastive Distillation\n\nAssume that we are given a set of training examples with empirical data distribution p(X), the sampling procedure for the conditional marginal distributions p(R T |X), p(R T,S |X) are modeled as\nxi, xj \u223c p(X), r T i,j = M T (\u03c6 T (xi), \u03c6 T (xj)), xm, xn \u223c p(X), r T,S m,n = M T,S (\u03c6 T (xm), \u03c6 S (xn))(1)\nrespectively. While the sampling procedure of the conditional joint distribution p(R T , R T,S |X) is modeled as:\nxi, xj \u223c p(X), r T i,j = M T (\u03c6 T (xi), \u03c6 T (xj)), r T,S i,j = M T,S (\u03c6 T (xi), \u03c6 S (xj)).\n(2)\n\nFor ease of notation, we utilize p(R T ), p(R T,S ) and p(R T , R T,S ) to briefly represent p(R T |X), p(R T,S |X) and p(R T , R T,S |X). Intuitively, we aim to maximize the mutual information (MI) of the two relation distributions from R T and R T,S , which is\nI(R T , R T,S ) = E p(R T ,R T ,S ) log p(R T , R T,S ) p(R T )p(R T,S ) . (3)\nMI Lower Bound. To derive a solvable loss function, we define a distribution q with latent variable C which indicates whether the relation tuple (r T , r T,S ) is drawn from the joint distribution or the product of marginal distributions:\nq(R T , R T,S |C = 1) = p(R T , R T,S ) q(R T , R T,S |C = 0) = p(R T )p(R T,S ).(4)\nMore specifically, C = 1 means r T and r T,S are computed based on the same input pair as in Eq. 2, and C = 0 means r T and r T,S are independently selected as in Eq. 1. In our data, we provide 1 relevant relation pair (C = 1) with N irrelevant relation pair (C = 0). Then the prior q(C = 1) = 1/(N + 1) and q(C = 0) = N/(N + 1). Combing the priors with the Bayes' rule, the posterior for C = 1 is given by:\nq(C = 1|R T , R T,S ) = p(R T , R T,S ) p(R T , R T,S ) + N p(R T )p(R T,S )\n. (5) By connection to the mutual information, the posterior\nlog q(C = 1|R T , R T,S ) \u2264 \u2212 log(N ) + log p(R T ,R T ,S ) p(R T )p(R T ,S )\n. Taking the expectation on both sides w.r.t. p(R T , R T,S ), which is also equivalent to q(R T , R T,S |C = 1), we have:\nI(R T , R T,S ) \u2265 log(N )+ E q(R T ,R T ,S |C=1) log q(C = 1|R T , R T,S ) (6) where log(N )+E q(R T ,R T ,S |C=1) log q(C = 1|R T , R T,S ) is a lower bound of the mutual information. Distribution Approximation.\nAs there is no knowledge about the true distribution of q(C = 1|R T , R T,S ), we approximate the distribution by fitting a parameterized model h: {R T , R T,S } \u2192 [0, 1] with the samples from q(C = 1|R T , R T,S ). The log-likelihood of the sampled data under this model is defined as:\nI(h) = E q(R T ,R T ,S |C=1) [log h(R T , R T,S )] + N E q(R T ,R T ,S |C=0) [log(1 \u2212 h(R T , R T,S ))].(7)\nTo achieve a good approximation to q(C = 1|R T , R T,S ), we need to maximize the log likelihood. Consider the bound in Eq. 6 and the fact that\nN E q(R T ,R T ,S |C=0) [log(1 \u2212 h(R T , R T,S ))] is non-positive, we have I(R T , R T,S ) \u2265 log N +E q(R T ,R T ,S |C=1) [log h(R T , R T,S )] + N E q(R T ,R T ,S |C=0) [log(1 \u2212 h(R T , R T,S ))] \u2265 log N + I(h),(8)\nwhere log N + I(h) is the lower bound of the mutual information with the parameterized model h. The maximization of the log-likelihood is also to maximize the lower bound. Relation Contrastive Loss. In our method, the inputs for the function h are teacher-space relation r T and cross-space relations r T,S , which are the results of the teacher \u2126 T , the student \u2126 S , and the two sub-networks M T , M T,S . Except the teacher \u2126 T , the other three networks \u2126 S , M T and M T,S also need to be optimized during the distillation. We aim to maximize the mutual information, which is equivalent to minimizing the relation contrastive loss L RC :\nLRC (h, \u2126 S , M T , M T,S ) = \u2212 q(C=1) log h(r T , r T,S ) \u2212 N q(C=0) log[1\u2212h(r T , r T,S )](9)\nwhere {(r T , r T,S )|C = 1} act as positive pairs while {(r T , r T,S )|C = 0} act as negative pairs. Due to Eq. 8, the contrastive loss can fit the distribution q(C|R T , R T,S ) to increase the lower-bound of mutual information of R T and R T,S , by which not only the parameterized model h, but also the other three networks \u2126 S , M T and M T,S can be jointly optimized.\n\n\nComplementary Relation\n\nModeling relation between sample representations is the prerequisite for distilling the structural information. We therefore propose two learnable sub-networks M T,S and M T to estimate the relation.\n\nThe sub-network M T,S is to compute the anchor-student relation with representation \u03c6 T (x i ) and \u03c6 S (x j ):\nr T,S i,j = M T,S (\u03c6 T (xi), \u03c6 S (xj)) = W A (\u03c3(W A i \u03c6 T (xi) \u2212 W A j \u03c6 S (xj))),(10)\nwhere W A i and W A j are linear transformations that can solve the dimension mismatch problem. \u03c3 is ReLU function and W A is used for transformation. The anchor-student relation is supervised by the fixed anchor-teacher relation r T (x i , x j ), computed by another sub-network M T :\nr T i,j = M T (\u03c6 T (xi), \u03c6 T (xj)) = W B (\u03c3(W B i \u03c6 T (xi) \u2212 W B j \u03c6 T (xj))).(11)\nIt is noteworthy that the relations r T,S and r T are not scalar values but high-dimensional vectors. We claim that the high-dimensional relation can more accurately capture the structural information of deep representations than lowdimensional relation e.g., cosine similarity, which will be validated in section 4.2. Furthermore, the small learnable networks also increases relation flexibility. The relations are modeled by two complementary elements: feature f and its gradient g. Specifically, the representation \u03c6(x) in Eq. 10 and Eq. 11 can be either the feature of the teacher/student model or its gradient. Feature Element. The feature element is the 2 normalized output of teacher/student's backbone. With the feature element f , the representations \u03c6 T (x) and \u03c6 S (x) reflect the direct activation relative to the input x:\n\u03c6 T (x) = f T (x); \u03c6 S (x) = f S (x)(12)\nGradient Element. The gradient element is the gradient with respect to the feature. It reflects the optimization kinetics in the feature space, encoding important structural information. Given an input sample x into a teacher/student network \u2126, the gradient of task loss L cls relative to the feature f is computed as:\ng(x ) = \u2202 \u2202f L cls (\u2126, x).(13)\nWith gradient elements, the representation \u03c6 T (x) and \u03c6 S (x) can reflect the optimization kinetics:\n\u03c6 T (x) = g T (x); \u03c6 S (x) = g S (x)(14)\nElement Combination. Complementary relation is modeled to leverage feature and gradient elements simultaneously. Specifically, after the one-sided relations: feature relation r f and gradient relation r g , are computed with feature and gradient elements respectively, their corresponding relation contrastive losses can also be calculated by Eq. 9. By optimizing these two losses simultaneously, these two elements can both be utilized.\n\n\nImplementation\n\nCritic Function. We specify the parameterized critic function h in Eq. 7 to distinguish whether the relation pair (r T , r T,S ) is sampled from the joint distribution p(R T , R T,S ) or the product of marginal distribution p(R T )p(R T,S ). The formulation is similar to NCE [46]:\nh(r T , r T,S ) = e h 1 (r T )h 2 (r T ,S )/\u03c4 e 1/\u03c4(15)\nwhere \u03c4 is a temperature hyperparameter, and h 1 and h 2 first perform the linear transformation on relations, then normalize the transformed relations with 2 norm. Sampling Policy. We adopt the following sampling policy: in each forward-propagation, the anchor relation r T ij and positive relation r T,S ij are calculated using representations from any two samples x i and x j in the current minibatch, while the negative relations r T,S ik are calculated using the anchor representation from x i and the representations (indexed with k) sampled from the buffer where features and gradients are stored. Considering a B-size min-batch, we construct the anchor/positive relation for each sample pair thus the number of these two relations can be B 2 . For each anchor relation, we sample N feature/gradient from the buffer to construct N negatives for contrastive learning.\n\nTo make the feature/gradient buffer reflect the current network state better, we propose a queuing sampling method instead of a randomly sampling strategy. The queue records the N sample indices from the immediate preceding mini-batches and is updated after each forward-propagation by replacing the oldest indices with the current mini-batch. According to these recorded indices, the representations of these samples are used to calculated relation contrastive loss, whose effectiveness will be studied in Sec. 4.2. Loss Function. To achieve the superior performance and conduct a fair comparison with other methods, we also incorporate the naive knowledge distillation loss L kd [19] along with our relation contrastive loss. Given the presoftmax logits z T and z S for teacher and student, the naive KD loss can be expressed as\nL kd = \u03c1 2 H(\u03c3(z T /\u03c1), \u03c3(z S /\u03c1))(16)\nwhere \u03c1 is the temperature, H refers to the cross-entropy and \u03c3 is softmax function. The complete objective is: (17) where L f RC and L g RC are the relation contrastive loss computed with the feature (f ) and gradient (g), respectively. L cls is the cross entropy loss for classification. We set hyper-parameters to \u03b1 = 1 and \u03b2 1 = \u03b2 2 = 0.5 empirically. Discussion. CRD [41] aims to maximize the mutual information between the representations of the sample themselves from teacher/student models. Meanwhile, the proposed CRCD seeks the consistency between the teacherspace relation and cross-space relation. Indeed, if i = j in Eq. 9, the loss of CRCD essentially optimizes the crossspace relation of one sample, which degrades to the loss of CRD. Moreover, the number of pair-wise relations is at quadratic level relative to the number of samples, which also increases the optimized stability of contrastive loss.\nL = L cls + \u03b1LKD + \u03b21L f RC + \u03b22L g RC\n\nExperiments\n\n\nDatasets and Experimental Setup\n\nDatasets. Our experiments are conducted on two widely used classification datasets, i.e., CIFAR100 [24] and Im-ageNet [10]. CIFAR100 contains 60000 images for 100 classes, and there are 500 and 100 images per class for Top-1(%) r f r g r f &r g Figure 3: Accuracy of different relation elements. The feature relation r f , gradident relation r g , and complementary relation r f &r g are distilled on three teacher-student pairs.\n\ntraining and testing respectively. ImageNet is a wellknown large-scale image classification benchmark with 1000 classes, consisting of 1281167 images for training and 50000 images for testing. Parameter Setting. For CIFAR, mini-batch size is set to 64 in 1 GPU. SGD optimizer is used with weight decay and momentum of 0.0001 and 0.9 respectively. And the learning rate and schedule strategy follow [41], which is included in supplementary materials. For ImageNet, batchsize is set to 256 in 8 GPUs, and the standard training settings for Ima-geNet is adopted. For other competing methods, we use the implementation settings in papers or official shared codes. The relation dimension computed by sub-networks M T,S and M T is set to 256-d since the representation dimension in most of our experimental networks is 256-d.\n\n\nAblation Study\n\nThree teacher-student pairs are selected for ablation study. Their model names and top-1 accuracy (%) when trained individually on CIFAR100 are shown below:   The first two are with similar architectures, while the last one is with a very different architecture. These experiments are conducted on CIFAR100, and results are averaged over 3 runs. Effectiveness of relation modeling method. We first demonstrate the effectiveness of anchor-based relation. In contrast to conventional modeling methods, our relation is cross-space and high-dimensional. To verify its superiority, we compare it with four methods using low-dimensional relations: 1) RKD [32]; 2) CC [34]; 3) SP [43]; and 4) PKT [33]. For a fair comparison, we also use L 2 loss to preserve representation relations and only feature relation is involved. The results are shown in Tab. 1. Over all three teacher-student pairs, our proposed relation boosts the test accuracy by a large margin even with L 2 loss, which means that our relation modelling method is superior. Effectiveness of complementary relation elements. We propose two elements: feature and its gradient, to model representation relation. To verify their complementarity, we test the distilling accuracy of these two elements when used alone and when used simultaneously. As Fig. 3 shows, their combination can get the best result, which indicates that the feature and the gradient are complementary to each other and can more comprehensively present the representation interdependences. Table 3: Contrastive loss functions. To simplify, the anchor relation r T ij , positive relation r T,S ij , and negative relation r T,S ik j =k after critic transformation are denoted as u, v + and v \u2212 respectively. All relations are 2 normalized before inner product. \u03c4 is the temperature weight, and m is the margin parameter. Additionally, \u03c3 is sigmoid function.\n\n\nName\n\nLoss function Effectiveness of critic function h. We propose the critic function h in Eq. 15 to estimate the distribution q(C = 1|R T , R T,S ). To investigate the effectiveness of h 1 and h 2 selection, we conduct three experiments, including specifying the h 1 and h 2 functions with identity mapping, nonlinear projection and linear transformation(default). In particular, h is degraded to cosine similarity estimation when identity mapping is adopted. For nonlinear projection, we use a MLP with one hidden layer h(r) = W (2) \u03c3(W (1) r) where r is input relation and \u03c3 is a ReLU nonlinearity. In this study, the output dimension of linear or nonlinear transformation are both 256. Table 2 shows testing results using different transformations. We observe that both the linear and nonlinear projection achieve better results than identity mapping under the same projection dimension, which means that critic function with learnable parameters can better fit the distribution q(C = 1|R T , R T,S ). Effectiveness of relation contrastive loss. We compare our relation contrastive loss L RC with other commonly used contrastive loss, such as triplet loss with margin (L M T ) [36] and contrastive logistic loss (L CL ) [26,11]. Tab. 3 shows the formulations of four contrastive loss function.\nLMT [36] max(u v \u2212 \u2212 u v + + m, 0) LCL [26] \u2212 log \u03c3(u v + /\u03c4 ) \u2212 log (1 \u2212 \u03c3(u v \u2212 /\u03c4 )) LNCE [31] \u2212u v + /\u03c4 + log e u v \u2212 /\u03c4 LRC \u2212 log e u v + /\u03c4 e 1/\u03c4 \u2212 N log (1 \u2212 e u v \u2212 /\u03c4 e 1/\u03c4 )\nTo better analyze the loss function, we only use the feature element and gradient is not employed. The hyperparameters in these losses, i.e., temperature \u03c4 and margin m, are tuned to achieve the best results. Results reported in Tab. 4 show that, L N CE and L RC can significantly outperform L M T and L CL , because they can benefit from large number of negative samples. While our objective function L RC is better than L N CE in most of teacher-student combinations.\n\n\nHyper-parameter analysis\n\nSeveral hyper-parameters are worth investigating in our proposed CRCD method. (1) The number of negative samples N ; (2) The temperature used to scale the critic scores in Eq. 15; (3) The sampling policy to construct negative relations; (4) The projection dimension of critic function h. We adopt resnet56-resnet20 pair on CIFAR100 for analysis. Number of negative samples. We validate different N : 100, 200, 500, 1000, 2000. As shown in Tab. 4a, increasing the negative number leads to better performance, and the performance is saturated when n > 500. We therefore utilize N = 500 in all other experiments to save computational cost. Compared to CRD [41], our CRCD requires fewer negative features to reduce the need of memory. This is because CRCD can utilize few samples to generate a large number of relations, while CRD only depends on the number of samples. Temperature \u03c4 . Fig. 4b reports the results when \u03c4 varies from 0.02 to 0.2. We find that both extremely high or low temperature leads to inferior performance. In general, a temperature between 0.03 to 0.07 works well. We set \u03c4 = 0.05 for all other experiments. Sampling policy. To ensure that negative samples are as up-to-date as possible, we store features and gradients in a queue way which will remove the oldest sample when adding the latest sample. We compare the randomly sampling policy and the queuing sampling policy in Fig. 4. The queuing sampling policy (denoted as queue) can consistently outperform the naive randomly sampling policy (denoted as random) when varying negative number N and temperature \u03c4 . Projection dimension. We investigate the influence of output dimension for critic function h by setting output dimension to 64, 128, and 256 (the input relation dimension is 256-d). As shown in Tab. 2, compared to 128-d or 256-d, transformation with lower dimension (64-d) has some accuracy degradation. We utilize the 128-d linear transformation to make a trade-off between effectiveness and computational cost.\n\n\nComparison with\n\nState-of-the-arts CIFAR100. We compare our CRCD with other advanced knowledge distillation methods in Tab. 5. Various modern CNN architectures [17,21,53,52] are selected as teacher networks or student networks. For a fair comparison, we combine all distillation methods with conventional KD [19]. From Tab. 5, we can observe that our distillation Table 5: The top-1 accuracies (%) of seven different student-teacher pairs on CIFAR100. The accuracies of the teachers' and students' performance when they are trained individually are presented in the second partition after the header. FRCD (or GRCD) is the incomplete version of CRCD which means that only feature relation (or gradient relation) is employed in distillation. The best results are bolded and the best in competing methods are underlined.  Table 6: Top-1 and Top-5 error rate (%) on ImageNet validation set. We compare our CRCD with competing methods including AT [51], KD [19], SP [43], CC [34], CRD [41] and SSKD [47], and folow the training settings in [41]. method CRCD can consistently outperform all other distillation methods with a large margin, including the recent state-of-the-arts, CRD and SSKD. Additionally, even only one element (feature or its gradient) is used in the relation distillation, our method can still achieve the competing accuracy when compared to CRD or SSKD. When the feature and its gradient are employed in the representation relation distillation simultaneously, our CRCD can significantly outperform the other methods. In particular, the accuracy gap between CRCD and the other best performing method is 0.9% (averaged over 7 pairs in Tab. 5).\n\nTo evaluate the distillation effectiveness across very different network architectures, we also carry out detailed comparisons in supplementary materials.\n\nImageNet. Following [41,47], we adopt the ResNet34-ResNet18 pair to evaluate the effectiveness of CRCD on ImageNet. As shown in Tab. 6, the Top-1 and Top-5 accuracy between the teacher and student without distillation is 3.56% and 2.43%. Our CRCD reaches the best distillation performance by narrowing the performance gap by 2.21% and 1.87% respectively. Results on ImageNet demonstrates the scalability of our CRCD to large-scale benchmarks.\n\n\nConclusion\n\nIn this work, we have proposed a novel knowledge distillation method, CRCD, to distill important structural information from a teacher to a student. To better distill the relation knowledge, two sub-networks are used to estimate the cross-space relation and teacher-space relation, respectively. We maximized the mutual information between the two kinds of relations by a newly proposed relation contrastive distillation loss, and utilized two complementary elements, the feature and its gradient, to enhance the representative ability of the relation. With the design of the loss function, the inter-sample relation and representation learning can be optimized simultaneously. Extensive experiments demonstrate the effectiveness of our approach and suggest that the structural information of deep representation can be better exploited during distillation.\n\nFigure 1 :\n1Sample contrastive distillation vs. Relation preserving distillation. Four neighboring samples and their corresponding features are displayed, and capital letters are used to identify them. While pulling f S\n\nFigure 2 :\n2Anchor-student R T,SAnchor-teacher R TAnchor-student R T,SThe Flowchart of CRCD.\n\nFigure 4 :\n4Accuracy of varying negative number N and temperature \u03c4 with different sample policies.\n\nTable 1 :\n1Testing accuracy (%) on CIFAR100 with different relation modeling methods. L 2 loss and relation contrastive loss L RC are used to distill the feature relation r f .teacher \nresnet56 resnet110 ResNet50 \nstudent \nresnet20 \nresnet20 \nvgg8 \n\nRKD [32] \n70.54 \n70.98 \n73.65 \nCC [34] \n71.42 \n70.96 \n73.76 \nSP [43] \n71.59 \n71.15 \n73.95 \nPKT [33] \n71.68 \n71.08 \n74.01 \nr f + L2 \n71.93 \n71.54 \n74.15 \nr f + LRC \n72.70 \n72.02 \n74.69 \n\nresnet56-resnet20 \nresnet110-resnet20 \nResNet50-vgg8 \n\nTeacher-Student pairs \n\n70 \n\n71 \n\n72 \n\n73 \n\n74 \n\n75 \n\n76 \n\n\n\nTable 2 :\n2Testing accuracy (%) on CIFAR100 with different \ntransformations for critic function h. IM : identity map-\nping; LP : linear projection; N P : nonlinear projection. The \ntransformation dimensions are appended as subscripts. \n\nteacher resnet56 resnet110 ResNet50 \nstudent resnet20 \nresnet20 \nvgg8 \n\nIM \n72.35 \n71.84 \n74.25 \nN P256 \n72.52 \n71.98 \n74.49 \n\nLP64 \n72.45 \n71.92 \n74.34 \nLP128 \n72.70 \n72.02 \n74.69 \nLP256 \n72.65 \n72.12 \n74.57 \n\n\n\nTable 4 :\n4Testing accuracy (%) on CIFAR100 with different \ncontrastive loss functions. \n\nteacher \nresnet56 resnet110 ResNet50 \nstudent \nresnet20 \nresnet20 \nvgg8 \n\nL2 \n71.93 \n71.54 \n73.89 \nLMT \nm = 0.4 \n72.21 \n71.83 \n74.25 \nLCL \n\u03c4 = 0.05 \n72.15 \n71.72 \n74.07 \nLNCE \u03c4 = 0.05 \n72.53 \n72.09 \n74.44 \nLRC \n\u03c4 = 0.05 \n72.70 \n72.02 \n74.69 \n\n\n\nVariational information distillation for knowledge transfer. Sungsoo Ahn, Shell Xu Hu, Andreas Damianou, D Neil, Zhenwen Lawrence, Dai, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionSungsoo Ahn, Shell Xu Hu, Andreas Damianou, Neil D Lawrence, and Zhenwen Dai. Variational information distil- lation for knowledge transfer. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9163-9171, 2019. 8\n\nAdversarial network compression. Vasileios Belagiannis, Azade Farshad, Fabio Galasso, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)Vasileios Belagiannis, Azade Farshad, and Fabio Galasso. Adversarial network compression. In Proceedings of the Eu- ropean Conference on Computer Vision (ECCV), pages 0-0, 2018. 1\n\nMohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeswar, Sherjil Ozair, Yoshua Bengio, Aaron Courville, R Devon Hjelm, arXiv:1801.04062Mine: mutual information neural estimation. arXiv preprintMohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeswar, Sherjil Ozair, Yoshua Bengio, Aaron Courville, and R Devon Hjelm. Mine: mutual information neural estimation. arXiv preprint arXiv:1801.04062, 2018. 3\n\nUnsupervised learning of visual features by contrasting cluster assignments. Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, Armand Joulin, arXiv:2006.09882arXiv preprintMathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Pi- otr Bojanowski, and Armand Joulin. Unsupervised learning of visual features by contrasting cluster assignments. arXiv preprint arXiv:2006.09882, 2020. 2\n\nVideo person re-identification with competitive snippet-similarity aggregation and co-attentive snippet embedding. Dapeng Chen, Hongsheng Li, Tong Xiao, Shuai Yi, Xiaogang Wang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Dapeng Chen, Hongsheng Li, Tong Xiao, Shuai Yi, and Xi- aogang Wang. Video person re-identification with compet- itive snippet-similarity aggregation and co-attentive snippet embedding. In Proceedings of the IEEE Conference on Com- puter Vision and Pattern Recognition (CVPR), June 2018. 2\n\nGroup consistent similarity learning via deep crf for person re-identification. Dapeng Chen, Dan Xu, Hongsheng Li, Nicu Sebe, Xiaogang Wang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Dapeng Chen, Dan Xu, Hongsheng Li, Nicu Sebe, and Xi- aogang Wang. Group consistent similarity learning via deep crf for person re-identification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018. 2\n\nSimilarity learning with spatial constraints for person re-identification. Dapeng Chen, Zejian Yuan, Badong Chen, Nanning Zheng, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Dapeng Chen, Zejian Yuan, Badong Chen, and Nanning Zheng. Similarity learning with spatial constraints for per- son re-identification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016. 2\n\nA simple framework for contrastive learning of visual representations. Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, arXiv:2002.05709arXiv preprintTing Chen, Simon Kornblith, Mohammad Norouzi, and Ge- offrey Hinton. A simple framework for contrastive learning of visual representations. arXiv preprint arXiv:2002.05709, 2020. 3\n\nBig self-supervised models are strong semi-supervised learners. Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, Geoffrey Hinton, arXiv:2006.10029arXiv preprintTing Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey Hinton. Big self-supervised mod- els are strong semi-supervised learners. arXiv preprint arXiv:2006.10029, 2020. 1\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, 2009 IEEE conference on computer vision and pattern recognition. IeeeJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248-255. Ieee, 2009. 5\n\nImage-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification. Weijian Deng, Liang Zheng, Qixiang Ye, Guoliang Kang, Yi Yang, Jianbin Jiao, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Weijian Deng, Liang Zheng, Qixiang Ye, Guoliang Kang, Yi Yang, and Jianbin Jiao. Image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification. In Proceedings of the IEEE Confer- ence on Computer Vision and Pattern Recognition (CVPR), June 2018. 7\n\nMutual meanteaching: Pseudo label refinery for unsupervised domain adaptation on person re-identification. Yixiao Ge, Dapeng Chen, Hongsheng Li, International Conference on Learning Representations. 2020Yixiao Ge, Dapeng Chen, and Hongsheng Li. Mutual mean- teaching: Pseudo label refinery for unsupervised domain adaptation on person re-identification. In International Con- ference on Learning Representations, 2020. 1\n\nSelf-paced contrastive learning with hybrid memory for domain adaptive object re-id. Yixiao Ge, Feng Zhu, Dapeng Chen, Rui Zhao, Hongsheng Li, Advances in Neural Information Processing Systems. Yixiao Ge, Feng Zhu, Dapeng Chen, Rui Zhao, and Hong- sheng Li. Self-paced contrastive learning with hybrid mem- ory for domain adaptive object re-id. In Advances in Neural Information Processing Systems, 2020. 3\n\nKnowledge distillation: A survey. Jianping Gou, Baosheng Yu, Stephen John Maybank, Dacheng Tao, arXiv:2006.05525arXiv preprintJianping Gou, Baosheng Yu, Stephen John Maybank, and Dacheng Tao. Knowledge distillation: A survey. arXiv preprint arXiv:2006.05525, 2020. 1\n\nBootstrap your own latent: A new approach to self-supervised learning. Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, H Pierre, Elena Richemond, Carl Buchatskaya, Bernardo Doersch, Zhaohan Daniel Avila Pires, Mohammad Gheshlaghi Guo, Azar, arXiv:2006.07733arXiv preprintJean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, Pierre H Richemond, Elena Buchatskaya, Carl Do- ersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Moham- mad Gheshlaghi Azar, et al. Bootstrap your own latent: A new approach to self-supervised learning. arXiv preprint arXiv:2006.07733, 2020. 3\n\nMomentum contrast for unsupervised visual representation learning. Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, Ross Girshick, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionKaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In Proceedings of the IEEE/CVF Con- ference on Computer Vision and Pattern Recognition, pages 9729-9738, 2020. 3\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 770-778, 2016. 7\n\nKnowledge transfer via distillation of activation boundaries formed by hidden neurons. Byeongho Heo, Minsik Lee, Sangdoo Yun, Jin Young Choi, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence33Byeongho Heo, Minsik Lee, Sangdoo Yun, and Jin Young Choi. Knowledge transfer via distillation of activation boundaries formed by hidden neurons. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 3779-3787, 2019. 2, 8\n\nGeoffrey Hinton, Oriol Vinyals, Jeff Dean, arXiv:1503.02531Distilling the knowledge in a neural network. 7arXiv preprintGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distill- ing the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015. 1, 2, 5, 7, 8\n\nLearning deep representations by mutual information estimation and maximization. Alex R Devon Hjelm, Samuel Fedorov, Karan Lavoie-Marchildon, Phil Grewal, Adam Bachman, Yoshua Trischler, Bengio, arXiv:1808.0667023arXiv preprintR Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio. Learning deep representations by mutual in- formation estimation and maximization. arXiv preprint arXiv:1808.06670, 2018. 2, 3\n\nG Andrew, Menglong Howard, Bo Zhu, Dmitry Chen, Weijun Kalenichenko, Tobias Wang, Marco Weyand, Hartwig Andreetto, Adam, arXiv:1704.04861Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprintAndrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco An- dreetto, and Hartwig Adam. Mobilenets: Efficient convolu- tional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017. 7\n\nLike what you like: Knowledge distill via neuron selectivity transfer. Zehao Huang, Naiyan Wang, arXiv:1707.01219arXiv preprintZehao Huang and Naiyan Wang. Like what you like: Knowl- edge distill via neuron selectivity transfer. arXiv preprint arXiv:1707.01219, 2017. 8\n\nParaphrasing complex network: Network compression via factor transfer. Jangho Kim, Seonguk Park, Nojun Kwak, Advances in neural information processing systems. Jangho Kim, SeongUk Park, and Nojun Kwak. Paraphrasing complex network: Network compression via factor transfer. In Advances in neural information processing systems, pages 2760-2769, 2018. 8\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Geoffrey Hinton, Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009. 5\n\nMemory-based neighbourhood embedding for visual recognition. Suichan Li, Dapeng Chen, Bin Liu, Nenghai Yu, Rui Zhao, Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). the IEEE/CVF International Conference on Computer Vision (ICCV)Suichan Li, Dapeng Chen, Bin Liu, Nenghai Yu, and Rui Zhao. Memory-based neighbourhood embedding for visual recognition. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), October 2019. 2\n\nDeepreid: Deep filter pairing neural network for person reidentification. Wei Li, Rui Zhao, Tong Xiao, Xiaogang Wang, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionWei Li, Rui Zhao, Tong Xiao, and Xiaogang Wang. Deep- reid: Deep filter pairing neural network for person re- identification. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 152-159, 2014. 7\n\nIou-Jen Liu, Jian Peng, Alexander G Schwing, arXiv:1904.05878Improve upon your teachers. arXiv preprintIou-Jen Liu, Jian Peng, and Alexander G Schwing. Knowl- edge flow: Improve upon your teachers. arXiv preprint arXiv:1904.05878, 2019. 1\n\nKnowledge distillation via instance relationship graph. Yufan Liu, Jiajiong Cao, Bing Li, Chunfeng Yuan, Weiming Hu, Yangxi Li, Yunqiang Duan, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionYufan Liu, Jiajiong Cao, Bing Li, Chunfeng Yuan, Weim- ing Hu, Yangxi Li, and Yunqiang Duan. Knowledge distil- lation via instance relationship graph. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recogni- tion, pages 7096-7104, 2019. 2\n\n. Andrey Malinin, Bruno Mlodozeniec, Mark Gales, arXiv:1905.00076Ensemble distribution distillation. arXiv preprintAndrey Malinin, Bruno Mlodozeniec, and Mark Gales. Ensemble distribution distillation. arXiv preprint arXiv:1905.00076, 2019. 1\n\nRepresentation learning with contrastive predictive coding. Aaron Van Den Oord, Yazhe Li, Oriol Vinyals, arXiv:1807.03748arXiv preprintAaron van den Oord, Yazhe Li, and Oriol Vinyals. Repre- sentation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018. 3\n\nRepresentation learning with contrastive predictive coding. Aaron Van Den Oord, Yazhe Li, Oriol Vinyals, arXiv:1807.0374837arXiv preprintAaron van den Oord, Yazhe Li, and Oriol Vinyals. Repre- sentation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018. 3, 7\n\nRelational knowledge distillation. Wonpyo Park, Dongju Kim, Yan Lu, Minsu Cho, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionWonpyo Park, Dongju Kim, Yan Lu, and Minsu Cho. Rela- tional knowledge distillation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3967-3976, 2019. 2, 6, 8\n\nLearning deep representations with probabilistic knowledge transfer. Nikolaos Passalis, Anastasios Tefas, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)Nikolaos Passalis and Anastasios Tefas. Learning deep rep- resentations with probabilistic knowledge transfer. In Pro- ceedings of the European Conference on Computer Vision (ECCV), pages 268-284, 2018. 2, 6, 8\n\nCorrelation congruence for knowledge distillation. Baoyun Peng, Xiao Jin, Jiaheng Liu, Dongsheng Li, Yichao Wu, Yu Liu, Shunfeng Zhou, Zhaoning Zhang, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision6Baoyun Peng, Xiao Jin, Jiaheng Liu, Dongsheng Li, Yichao Wu, Yu Liu, Shunfeng Zhou, and Zhaoning Zhang. Correla- tion congruence for knowledge distillation. In Proceedings of the IEEE International Conference on Computer Vision, pages 5007-5016, 2019. 2, 3, 6, 8\n\nAdriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, Yoshua Bengio, arXiv:1412.6550Fitnets: Hints for thin deep nets. 2arXiv preprintAdriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, and Yoshua Bengio. Fitnets: Hints for thin deep nets. arXiv preprint arXiv:1412.6550, 2014. 2, 8\n\nFacenet: A unified embedding for face recognition and clustering. Florian Schroff, Dmitry Kalenichenko, James Philbin, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet: A unified embedding for face recognition and clus- tering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015. 7\n\nMeal: Multi-model ensemble via adversarial learning. Zhiqiang Shen, Zhankui He, Xiangyang Xue, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence33Zhiqiang Shen, Zhankui He, and Xiangyang Xue. Meal: Multi-model ensemble via adversarial learning. In Proceed- ings of the AAAI Conference on Artificial Intelligence, vol- ume 33, pages 4886-4893, 2019. 1\n\nMutual crf-gnn for few shot learning. Shixiang Tang, Dapeng Chen, Lei Bai, Yixiao Ge, Wanli Ouyang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionShixiang Tang, Dapeng Chen, Lei Bai, Yixiao Ge, and Wanli Ouyang. Mutual crf-gnn for few shot learning. In Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition, 2021. 1\n\nLayerwise optimization by gradient decomposition for continual learning. Shixiang Tang, Dapeng Chen, Jinguo Zhu, Shijie Yu, Wanli Ouyang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionShixiang Tang, Dapeng Chen, Jinguo Zhu, Shijie Yu, and Wanli Ouyang. Layerwise optimization by gradient decom- position for continual learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2021. 2\n\nYonglong Tian, Dilip Krishnan, Phillip Isola, arXiv:1906.05849Contrastive multiview coding. arXiv preprintYonglong Tian, Dilip Krishnan, and Phillip Isola. Con- trastive multiview coding. arXiv preprint arXiv:1906.05849, 2019. 2\n\nYonglong Tian, Dilip Krishnan, Phillip Isola, arXiv:1910.10699Contrastive representation distillation. 7arXiv preprintYonglong Tian, Dilip Krishnan, and Phillip Isola. Contrastive representation distillation. arXiv preprint arXiv:1910.10699, 2019. 1, 3, 5, 6, 7, 8\n\nWhat makes for good views for contrastive learning. Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, Phillip Isola, arXiv:2005.10243arXiv preprintYonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, and Phillip Isola. What makes for good views for contrastive learning. arXiv preprint arXiv:2005.10243, 2020. 3\n\nSimilarity-preserving knowledge distillation. Frederick Tung, Greg Mori, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionFrederick Tung and Greg Mori. Similarity-preserving knowl- edge distillation. In Proceedings of the IEEE International Conference on Computer Vision, pages 1365-1374, 2019. 2, 6, 8\n\nUnderstanding contrastive representation learning through alignment and uniformity on the hypersphere. Tongzhou Wang, Phillip Isola, arXiv:2005.10242arXiv preprintTongzhou Wang and Phillip Isola. Understanding contrastive representation learning through alignment and uniformity on the hypersphere. arXiv preprint arXiv:2005.10242, 2020. 3\n\nDistilled person re-identification: Towards a more scalable system. Ancong Wu, Wei-Shi Zheng, Xiaowei Guo, Jian-Huang Lai, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionAncong Wu, Wei-Shi Zheng, Xiaowei Guo, and Jian-Huang Lai. Distilled person re-identification: Towards a more scalable system. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1187- 1196, 2019. 1\n\nUnsupervised feature learning via non-parametric instance discrimination. Zhirong Wu, Yuanjun Xiong, X Stella, Dahua Yu, Lin, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition25Zhirong Wu, Yuanjun Xiong, Stella X Yu, and Dahua Lin. Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3733- 3742, 2018. 2, 5\n\nKnowledge distillation meets self-supervision. Guodong Xu, Ziwei Liu, Xiaoxiao Li, Chen Change Loy, arXiv:2006.071143arXiv preprintGuodong Xu, Ziwei Liu, Xiaoxiao Li, and Chen Change Loy. Knowledge distillation meets self-supervision. arXiv preprint arXiv:2006.07114, 2020. 3, 8\n\nTraining shallow and thin networks for acceleration via knowledge distillation with conditional adversarial networks. Zheng Xu, Yen-Chang Hsu, Jiawei Huang, arXiv:1709.00513arXiv preprintZheng Xu, Yen-Chang Hsu, and Jiawei Huang. Training shallow and thin networks for acceleration via knowledge distillation with conditional adversarial networks. arXiv preprint arXiv:1709.00513, 2017. 1\n\nA gift from knowledge distillation: Fast optimization, network minimization and transfer learning. Junho Yim, Donggyu Joo, Jihoon Bae, Junmo Kim, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionJunho Yim, Donggyu Joo, Jihoon Bae, and Junmo Kim. A gift from knowledge distillation: Fast optimization, network minimization and transfer learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recogni- tion, pages 4133-4141, 2017. 1\n\nA gift from knowledge distillation: Fast optimization, network minimization and transfer learning. Junho Yim, Donggyu Joo, Jihoon Bae, Junmo Kim, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionJunho Yim, Donggyu Joo, Jihoon Bae, and Junmo Kim. A gift from knowledge distillation: Fast optimization, network minimization and transfer learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recogni- tion, pages 4133-4141, 2017. 2\n\nPaying more attention to attention: Improving the performance of convolutional neural networks via attention transfer. Sergey Zagoruyko, Nikos Komodakis, arXiv:1612.039282arXiv preprintSergey Zagoruyko and Nikos Komodakis. Paying more at- tention to attention: Improving the performance of convolu- tional neural networks via attention transfer. arXiv preprint arXiv:1612.03928, 2016. 2, 8\n\n. Sergey Zagoruyko, Nikos Komodakis, arXiv:1605.07146Wide residual networks. arXiv preprintSergey Zagoruyko and Nikos Komodakis. Wide residual net- works. arXiv preprint arXiv:1605.07146, 2016. 7\n\nShufflenet: An extremely efficient convolutional neural network for mobile devices. Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, Jian Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionXiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. Shufflenet: An extremely efficient convolutional neural net- work for mobile devices. In Proceedings of the IEEE con- ference on computer vision and pattern recognition, pages 6848-6856, 2018. 7\n\nCrowded human detection via an anchor-pair network. Jinguo Zhu, Zejian Yuan, Chong Zhang, Wanchao Chi, Yonggen Ling, Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. the IEEE/CVF Winter Conference on Applications of Computer VisionJinguo Zhu, Zejian Yuan, Chong Zhang, Wanchao Chi, Yonggen Ling, et al. Crowded human detection via an anchor-pair network. In Proceedings of the IEEE/CVF Win- ter Conference on Applications of Computer Vision, pages 1391-1399, 2020. 1\n", "annotations": {"author": "[{\"end\":90,\"start\":51},{\"end\":159,\"start\":91},{\"end\":198,\"start\":160},{\"end\":256,\"start\":199},{\"end\":260,\"start\":257},{\"end\":321,\"start\":261},{\"end\":387,\"start\":322},{\"end\":454,\"start\":388},{\"end\":496,\"start\":455}]", "publisher": null, "author_last_name": "[{\"end\":61,\"start\":58},{\"end\":104,\"start\":100},{\"end\":171,\"start\":167},{\"end\":207,\"start\":201},{\"end\":270,\"start\":267},{\"end\":334,\"start\":330},{\"end\":398,\"start\":394},{\"end\":467,\"start\":463}]", "author_first_name": "[{\"end\":57,\"start\":51},{\"end\":99,\"start\":91},{\"end\":166,\"start\":160},{\"end\":200,\"start\":199},{\"end\":259,\"start\":257},{\"end\":266,\"start\":261},{\"end\":329,\"start\":322},{\"end\":393,\"start\":388},{\"end\":462,\"start\":455}]", "author_affiliation": "[{\"end\":89,\"start\":63},{\"end\":158,\"start\":133},{\"end\":197,\"start\":173},{\"end\":255,\"start\":209},{\"end\":320,\"start\":296},{\"end\":386,\"start\":360},{\"end\":453,\"start\":427},{\"end\":495,\"start\":469}]", "title": "[{\"end\":48,\"start\":1},{\"end\":544,\"start\":497}]", "venue": null, "abstract": "[{\"end\":1735,\"start\":546}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b18\"},\"end\":1932,\"start\":1928},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":1935,\"start\":1932},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1937,\"start\":1935},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":1940,\"start\":1937},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":1943,\"start\":1940},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2005,\"start\":2001},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":2008,\"start\":2005},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":2011,\"start\":2008},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":2014,\"start\":2011},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2185,\"start\":2182},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":2188,\"start\":2185},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":2191,\"start\":2188},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2764,\"start\":2760},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":2826,\"start\":2822},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3054,\"start\":3050},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3165,\"start\":3161},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3168,\"start\":3165},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3171,\"start\":3168},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3173,\"start\":3171},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":4144,\"start\":4140},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":4147,\"start\":4144},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":4150,\"start\":4147},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":4153,\"start\":4150},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5280,\"start\":5277},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":5481,\"start\":5477},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":5484,\"start\":5481},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5487,\"start\":5484},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6519,\"start\":6515},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":6522,\"start\":6519},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":6826,\"start\":6822},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7936,\"start\":7932},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8290,\"start\":8286},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":8324,\"start\":8320},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":8370,\"start\":8366},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8742,\"start\":8738},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8745,\"start\":8742},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8748,\"start\":8745},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8751,\"start\":8748},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8753,\"start\":8751},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8755,\"start\":8753},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8757,\"start\":8755},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8760,\"start\":8757},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8813,\"start\":8809},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8909,\"start\":8905},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8918,\"start\":8914},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9082,\"start\":9078},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9673,\"start\":9669},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10137,\"start\":10134},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10140,\"start\":10137},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10143,\"start\":10140},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10146,\"start\":10143},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10149,\"start\":10146},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":10152,\"start\":10149},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":10155,\"start\":10152},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10158,\"start\":10155},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10195,\"start\":10191},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10198,\"start\":10195},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10394,\"start\":10390},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10523,\"start\":10520},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":10591,\"start\":10587},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":19215,\"start\":19211},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20833,\"start\":20829},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":21134,\"start\":21130},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":21394,\"start\":21390},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22125,\"start\":22121},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":22144,\"start\":22140},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":22855,\"start\":22851},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":23944,\"start\":23940},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23956,\"start\":23952},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":23968,\"start\":23964},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":23985,\"start\":23981},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":26361,\"start\":26357},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26404,\"start\":26400},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":26407,\"start\":26404},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":27276,\"start\":27273},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":27813,\"start\":27809},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29320,\"start\":29316},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":29323,\"start\":29320},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":29326,\"start\":29323},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":29329,\"start\":29326},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":29468,\"start\":29464},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":30104,\"start\":30100},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":30113,\"start\":30109},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":30122,\"start\":30118},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":30131,\"start\":30127},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":30141,\"start\":30137},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":30155,\"start\":30151},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":30196,\"start\":30192},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":30996,\"start\":30992},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":30999,\"start\":30996}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":32507,\"start\":32287},{\"attributes\":{\"id\":\"fig_1\"},\"end\":32601,\"start\":32508},{\"attributes\":{\"id\":\"fig_2\"},\"end\":32702,\"start\":32602},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":33254,\"start\":32703},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33704,\"start\":33255},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":34039,\"start\":33705}]", "paragraph": "[{\"end\":2765,\"start\":1751},{\"end\":3444,\"start\":2767},{\"end\":4458,\"start\":3446},{\"end\":6054,\"start\":4460},{\"end\":6917,\"start\":6056},{\"end\":7675,\"start\":6919},{\"end\":8641,\"start\":7692},{\"end\":9658,\"start\":8643},{\"end\":10932,\"start\":9660},{\"end\":11904,\"start\":10948},{\"end\":12268,\"start\":11906},{\"end\":12500,\"start\":12306},{\"end\":12722,\"start\":12609},{\"end\":12817,\"start\":12814},{\"end\":13081,\"start\":12819},{\"end\":13399,\"start\":13161},{\"end\":13892,\"start\":13485},{\"end\":14030,\"start\":13970},{\"end\":14231,\"start\":14109},{\"end\":14731,\"start\":14445},{\"end\":14983,\"start\":14840},{\"end\":15844,\"start\":15201},{\"end\":16315,\"start\":15941},{\"end\":16541,\"start\":16342},{\"end\":16653,\"start\":16543},{\"end\":17026,\"start\":16741},{\"end\":17944,\"start\":17110},{\"end\":18304,\"start\":17986},{\"end\":18437,\"start\":18336},{\"end\":18916,\"start\":18479},{\"end\":19216,\"start\":18935},{\"end\":20146,\"start\":19273},{\"end\":20978,\"start\":20148},{\"end\":21934,\"start\":21018},{\"end\":22451,\"start\":22022},{\"end\":23272,\"start\":22453},{\"end\":25172,\"start\":23291},{\"end\":26473,\"start\":25181},{\"end\":27127,\"start\":26658},{\"end\":29153,\"start\":27156},{\"end\":30814,\"start\":29173},{\"end\":30970,\"start\":30816},{\"end\":31414,\"start\":30972},{\"end\":32286,\"start\":31429}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12608,\"start\":12501},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12813,\"start\":12723},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13160,\"start\":13082},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13484,\"start\":13400},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13969,\"start\":13893},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14108,\"start\":14031},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14444,\"start\":14232},{\"attributes\":{\"id\":\"formula_7\"},\"end\":14839,\"start\":14732},{\"attributes\":{\"id\":\"formula_8\"},\"end\":15200,\"start\":14984},{\"attributes\":{\"id\":\"formula_9\"},\"end\":15940,\"start\":15845},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16740,\"start\":16654},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17109,\"start\":17027},{\"attributes\":{\"id\":\"formula_12\"},\"end\":17985,\"start\":17945},{\"attributes\":{\"id\":\"formula_13\"},\"end\":18335,\"start\":18305},{\"attributes\":{\"id\":\"formula_14\"},\"end\":18478,\"start\":18438},{\"attributes\":{\"id\":\"formula_15\"},\"end\":19272,\"start\":19217},{\"attributes\":{\"id\":\"formula_16\"},\"end\":21017,\"start\":20979},{\"attributes\":{\"id\":\"formula_17\"},\"end\":21973,\"start\":21935},{\"attributes\":{\"id\":\"formula_18\"},\"end\":26657,\"start\":26474}]", "table_ref": "[{\"end\":24814,\"start\":24807},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":25873,\"start\":25866},{\"end\":29527,\"start\":29520},{\"end\":29983,\"start\":29976}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1749,\"start\":1737},{\"attributes\":{\"n\":\"2.\"},\"end\":7690,\"start\":7678},{\"attributes\":{\"n\":\"3.\"},\"end\":10946,\"start\":10935},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12304,\"start\":12271},{\"attributes\":{\"n\":\"3.2.\"},\"end\":16340,\"start\":16318},{\"attributes\":{\"n\":\"3.3.\"},\"end\":18933,\"start\":18919},{\"attributes\":{\"n\":\"4.\"},\"end\":21986,\"start\":21975},{\"attributes\":{\"n\":\"4.1.\"},\"end\":22020,\"start\":21989},{\"attributes\":{\"n\":\"4.2.\"},\"end\":23289,\"start\":23275},{\"end\":25179,\"start\":25175},{\"attributes\":{\"n\":\"4.3.\"},\"end\":27154,\"start\":27130},{\"attributes\":{\"n\":\"4.4.\"},\"end\":29171,\"start\":29156},{\"attributes\":{\"n\":\"5.\"},\"end\":31427,\"start\":31417},{\"end\":32298,\"start\":32288},{\"end\":32519,\"start\":32509},{\"end\":32613,\"start\":32603},{\"end\":32713,\"start\":32704},{\"end\":33265,\"start\":33256},{\"end\":33715,\"start\":33706}]", "table": "[{\"end\":33254,\"start\":32880},{\"end\":33704,\"start\":33267},{\"end\":34039,\"start\":33717}]", "figure_caption": "[{\"end\":32507,\"start\":32300},{\"end\":32601,\"start\":32521},{\"end\":32702,\"start\":32615},{\"end\":32880,\"start\":32715}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3706,\"start\":3700},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10955,\"start\":10952},{\"end\":22275,\"start\":22267},{\"end\":24600,\"start\":24594},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":28045,\"start\":28038},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":28558,\"start\":28552}]", "bib_author_first_name": "[{\"end\":34109,\"start\":34102},{\"end\":34120,\"start\":34115},{\"end\":34123,\"start\":34121},{\"end\":34135,\"start\":34128},{\"end\":34147,\"start\":34146},{\"end\":34161,\"start\":34154},{\"end\":34609,\"start\":34600},{\"end\":34628,\"start\":34623},{\"end\":34643,\"start\":34638},{\"end\":34956,\"start\":34949},{\"end\":34964,\"start\":34957},{\"end\":34983,\"start\":34975},{\"end\":34996,\"start\":34993},{\"end\":35014,\"start\":35007},{\"end\":35028,\"start\":35022},{\"end\":35042,\"start\":35037},{\"end\":35061,\"start\":35054},{\"end\":35438,\"start\":35430},{\"end\":35451,\"start\":35446},{\"end\":35465,\"start\":35459},{\"end\":35479,\"start\":35474},{\"end\":35492,\"start\":35487},{\"end\":35511,\"start\":35505},{\"end\":35886,\"start\":35880},{\"end\":35902,\"start\":35893},{\"end\":35911,\"start\":35907},{\"end\":35923,\"start\":35918},{\"end\":35936,\"start\":35928},{\"end\":36475,\"start\":36469},{\"end\":36485,\"start\":36482},{\"end\":36499,\"start\":36490},{\"end\":36508,\"start\":36504},{\"end\":36523,\"start\":36515},{\"end\":37016,\"start\":37010},{\"end\":37029,\"start\":37023},{\"end\":37042,\"start\":37036},{\"end\":37056,\"start\":37049},{\"end\":37532,\"start\":37528},{\"end\":37544,\"start\":37539},{\"end\":37564,\"start\":37556},{\"end\":37582,\"start\":37574},{\"end\":37871,\"start\":37867},{\"end\":37883,\"start\":37878},{\"end\":37900,\"start\":37895},{\"end\":37918,\"start\":37910},{\"end\":37936,\"start\":37928},{\"end\":38221,\"start\":38218},{\"end\":38231,\"start\":38228},{\"end\":38245,\"start\":38238},{\"end\":38260,\"start\":38254},{\"end\":38268,\"start\":38265},{\"end\":38275,\"start\":38273},{\"end\":38699,\"start\":38692},{\"end\":38711,\"start\":38706},{\"end\":38726,\"start\":38719},{\"end\":38739,\"start\":38731},{\"end\":38748,\"start\":38746},{\"end\":38762,\"start\":38755},{\"end\":39339,\"start\":39333},{\"end\":39350,\"start\":39344},{\"end\":39366,\"start\":39357},{\"end\":39739,\"start\":39733},{\"end\":39748,\"start\":39744},{\"end\":39760,\"start\":39754},{\"end\":39770,\"start\":39767},{\"end\":39786,\"start\":39777},{\"end\":40098,\"start\":40090},{\"end\":40112,\"start\":40104},{\"end\":40124,\"start\":40117},{\"end\":40129,\"start\":40125},{\"end\":40146,\"start\":40139},{\"end\":40407,\"start\":40395},{\"end\":40422,\"start\":40415},{\"end\":40437,\"start\":40430},{\"end\":40454,\"start\":40446},{\"end\":40464,\"start\":40463},{\"end\":40478,\"start\":40473},{\"end\":40494,\"start\":40490},{\"end\":40516,\"start\":40508},{\"end\":40533,\"start\":40526},{\"end\":40540,\"start\":40534},{\"end\":40562,\"start\":40554},{\"end\":40573,\"start\":40563},{\"end\":41002,\"start\":40995},{\"end\":41012,\"start\":41007},{\"end\":41023,\"start\":41018},{\"end\":41035,\"start\":41028},{\"end\":41045,\"start\":41041},{\"end\":41506,\"start\":41499},{\"end\":41518,\"start\":41511},{\"end\":41534,\"start\":41526},{\"end\":41544,\"start\":41540},{\"end\":41995,\"start\":41987},{\"end\":42007,\"start\":42001},{\"end\":42020,\"start\":42013},{\"end\":42029,\"start\":42026},{\"end\":42035,\"start\":42030},{\"end\":42413,\"start\":42405},{\"end\":42427,\"start\":42422},{\"end\":42441,\"start\":42437},{\"end\":42759,\"start\":42755},{\"end\":42781,\"start\":42775},{\"end\":42796,\"start\":42791},{\"end\":42820,\"start\":42816},{\"end\":42833,\"start\":42829},{\"end\":42849,\"start\":42843},{\"end\":43148,\"start\":43147},{\"end\":43165,\"start\":43157},{\"end\":43176,\"start\":43174},{\"end\":43188,\"start\":43182},{\"end\":43201,\"start\":43195},{\"end\":43222,\"start\":43216},{\"end\":43234,\"start\":43229},{\"end\":43250,\"start\":43243},{\"end\":43712,\"start\":43707},{\"end\":43726,\"start\":43720},{\"end\":43984,\"start\":43978},{\"end\":43997,\"start\":43990},{\"end\":44009,\"start\":44004},{\"end\":44319,\"start\":44315},{\"end\":44340,\"start\":44332},{\"end\":44522,\"start\":44515},{\"end\":44533,\"start\":44527},{\"end\":44543,\"start\":44540},{\"end\":44556,\"start\":44549},{\"end\":44564,\"start\":44561},{\"end\":45012,\"start\":45009},{\"end\":45020,\"start\":45017},{\"end\":45031,\"start\":45027},{\"end\":45046,\"start\":45038},{\"end\":45433,\"start\":45426},{\"end\":45443,\"start\":45439},{\"end\":45459,\"start\":45450},{\"end\":45461,\"start\":45460},{\"end\":45727,\"start\":45722},{\"end\":45741,\"start\":45733},{\"end\":45751,\"start\":45747},{\"end\":45764,\"start\":45756},{\"end\":45778,\"start\":45771},{\"end\":45789,\"start\":45783},{\"end\":45802,\"start\":45794},{\"end\":46219,\"start\":46213},{\"end\":46234,\"start\":46229},{\"end\":46252,\"start\":46248},{\"end\":46520,\"start\":46515},{\"end\":46540,\"start\":46535},{\"end\":46550,\"start\":46545},{\"end\":46808,\"start\":46803},{\"end\":46828,\"start\":46823},{\"end\":46838,\"start\":46833},{\"end\":47077,\"start\":47071},{\"end\":47090,\"start\":47084},{\"end\":47099,\"start\":47096},{\"end\":47109,\"start\":47104},{\"end\":47532,\"start\":47524},{\"end\":47553,\"start\":47543},{\"end\":47945,\"start\":47939},{\"end\":47956,\"start\":47952},{\"end\":47969,\"start\":47962},{\"end\":47984,\"start\":47975},{\"end\":47995,\"start\":47989},{\"end\":48002,\"start\":48000},{\"end\":48016,\"start\":48008},{\"end\":48031,\"start\":48023},{\"end\":48432,\"start\":48425},{\"end\":48448,\"start\":48441},{\"end\":48463,\"start\":48457},{\"end\":48472,\"start\":48464},{\"end\":48487,\"start\":48480},{\"end\":48503,\"start\":48498},{\"end\":48517,\"start\":48511},{\"end\":48848,\"start\":48841},{\"end\":48864,\"start\":48858},{\"end\":48884,\"start\":48879},{\"end\":49338,\"start\":49330},{\"end\":49352,\"start\":49345},{\"end\":49366,\"start\":49357},{\"end\":49735,\"start\":49727},{\"end\":49748,\"start\":49742},{\"end\":49758,\"start\":49755},{\"end\":49770,\"start\":49764},{\"end\":49780,\"start\":49775},{\"end\":50208,\"start\":50200},{\"end\":50221,\"start\":50215},{\"end\":50234,\"start\":50228},{\"end\":50246,\"start\":50240},{\"end\":50256,\"start\":50251},{\"end\":50649,\"start\":50641},{\"end\":50661,\"start\":50656},{\"end\":50679,\"start\":50672},{\"end\":50879,\"start\":50871},{\"end\":50891,\"start\":50886},{\"end\":50909,\"start\":50902},{\"end\":51197,\"start\":51189},{\"end\":51208,\"start\":51204},{\"end\":51217,\"start\":51214},{\"end\":51230,\"start\":51225},{\"end\":51249,\"start\":51241},{\"end\":51265,\"start\":51258},{\"end\":51540,\"start\":51531},{\"end\":51551,\"start\":51547},{\"end\":51972,\"start\":51964},{\"end\":51986,\"start\":51979},{\"end\":52276,\"start\":52270},{\"end\":52288,\"start\":52281},{\"end\":52303,\"start\":52296},{\"end\":52319,\"start\":52309},{\"end\":52783,\"start\":52776},{\"end\":52795,\"start\":52788},{\"end\":52804,\"start\":52803},{\"end\":52818,\"start\":52813},{\"end\":53266,\"start\":53259},{\"end\":53276,\"start\":53271},{\"end\":53290,\"start\":53282},{\"end\":53306,\"start\":53295},{\"end\":53615,\"start\":53610},{\"end\":53629,\"start\":53620},{\"end\":53641,\"start\":53635},{\"end\":53986,\"start\":53981},{\"end\":53999,\"start\":53992},{\"end\":54011,\"start\":54005},{\"end\":54022,\"start\":54017},{\"end\":54533,\"start\":54528},{\"end\":54546,\"start\":54539},{\"end\":54558,\"start\":54552},{\"end\":54569,\"start\":54564},{\"end\":55101,\"start\":55095},{\"end\":55118,\"start\":55113},{\"end\":55375,\"start\":55369},{\"end\":55392,\"start\":55387},{\"end\":55655,\"start\":55648},{\"end\":55668,\"start\":55663},{\"end\":55683,\"start\":55675},{\"end\":55693,\"start\":55689},{\"end\":56149,\"start\":56143},{\"end\":56161,\"start\":56155},{\"end\":56173,\"start\":56168},{\"end\":56188,\"start\":56181},{\"end\":56201,\"start\":56194}]", "bib_author_last_name": "[{\"end\":34113,\"start\":34110},{\"end\":34126,\"start\":34124},{\"end\":34144,\"start\":34136},{\"end\":34152,\"start\":34148},{\"end\":34170,\"start\":34162},{\"end\":34175,\"start\":34172},{\"end\":34621,\"start\":34610},{\"end\":34636,\"start\":34629},{\"end\":34651,\"start\":34644},{\"end\":34973,\"start\":34965},{\"end\":34991,\"start\":34984},{\"end\":35005,\"start\":34997},{\"end\":35020,\"start\":35015},{\"end\":35035,\"start\":35029},{\"end\":35052,\"start\":35043},{\"end\":35067,\"start\":35062},{\"end\":35444,\"start\":35439},{\"end\":35457,\"start\":35452},{\"end\":35472,\"start\":35466},{\"end\":35485,\"start\":35480},{\"end\":35503,\"start\":35493},{\"end\":35518,\"start\":35512},{\"end\":35891,\"start\":35887},{\"end\":35905,\"start\":35903},{\"end\":35916,\"start\":35912},{\"end\":35926,\"start\":35924},{\"end\":35941,\"start\":35937},{\"end\":36480,\"start\":36476},{\"end\":36488,\"start\":36486},{\"end\":36502,\"start\":36500},{\"end\":36513,\"start\":36509},{\"end\":36528,\"start\":36524},{\"end\":37021,\"start\":37017},{\"end\":37034,\"start\":37030},{\"end\":37047,\"start\":37043},{\"end\":37062,\"start\":37057},{\"end\":37537,\"start\":37533},{\"end\":37554,\"start\":37545},{\"end\":37572,\"start\":37565},{\"end\":37589,\"start\":37583},{\"end\":37876,\"start\":37872},{\"end\":37893,\"start\":37884},{\"end\":37908,\"start\":37901},{\"end\":37926,\"start\":37919},{\"end\":37943,\"start\":37937},{\"end\":38226,\"start\":38222},{\"end\":38236,\"start\":38232},{\"end\":38252,\"start\":38246},{\"end\":38263,\"start\":38261},{\"end\":38271,\"start\":38269},{\"end\":38283,\"start\":38276},{\"end\":38704,\"start\":38700},{\"end\":38717,\"start\":38712},{\"end\":38729,\"start\":38727},{\"end\":38744,\"start\":38740},{\"end\":38753,\"start\":38749},{\"end\":38767,\"start\":38763},{\"end\":39342,\"start\":39340},{\"end\":39355,\"start\":39351},{\"end\":39369,\"start\":39367},{\"end\":39742,\"start\":39740},{\"end\":39752,\"start\":39749},{\"end\":39765,\"start\":39761},{\"end\":39775,\"start\":39771},{\"end\":39789,\"start\":39787},{\"end\":40102,\"start\":40099},{\"end\":40115,\"start\":40113},{\"end\":40137,\"start\":40130},{\"end\":40150,\"start\":40147},{\"end\":40413,\"start\":40408},{\"end\":40428,\"start\":40423},{\"end\":40444,\"start\":40438},{\"end\":40461,\"start\":40455},{\"end\":40471,\"start\":40465},{\"end\":40488,\"start\":40479},{\"end\":40506,\"start\":40495},{\"end\":40524,\"start\":40517},{\"end\":40552,\"start\":40541},{\"end\":40577,\"start\":40574},{\"end\":40583,\"start\":40579},{\"end\":41005,\"start\":41003},{\"end\":41016,\"start\":41013},{\"end\":41026,\"start\":41024},{\"end\":41039,\"start\":41036},{\"end\":41054,\"start\":41046},{\"end\":41509,\"start\":41507},{\"end\":41524,\"start\":41519},{\"end\":41538,\"start\":41535},{\"end\":41548,\"start\":41545},{\"end\":41999,\"start\":41996},{\"end\":42011,\"start\":42008},{\"end\":42024,\"start\":42021},{\"end\":42040,\"start\":42036},{\"end\":42420,\"start\":42414},{\"end\":42435,\"start\":42428},{\"end\":42446,\"start\":42442},{\"end\":42773,\"start\":42760},{\"end\":42789,\"start\":42782},{\"end\":42814,\"start\":42797},{\"end\":42827,\"start\":42821},{\"end\":42841,\"start\":42834},{\"end\":42859,\"start\":42850},{\"end\":42867,\"start\":42861},{\"end\":43155,\"start\":43149},{\"end\":43172,\"start\":43166},{\"end\":43180,\"start\":43177},{\"end\":43193,\"start\":43189},{\"end\":43214,\"start\":43202},{\"end\":43227,\"start\":43223},{\"end\":43241,\"start\":43235},{\"end\":43260,\"start\":43251},{\"end\":43266,\"start\":43262},{\"end\":43718,\"start\":43713},{\"end\":43731,\"start\":43727},{\"end\":43988,\"start\":43985},{\"end\":44002,\"start\":43998},{\"end\":44014,\"start\":44010},{\"end\":44330,\"start\":44320},{\"end\":44347,\"start\":44341},{\"end\":44525,\"start\":44523},{\"end\":44538,\"start\":44534},{\"end\":44547,\"start\":44544},{\"end\":44559,\"start\":44557},{\"end\":44569,\"start\":44565},{\"end\":45015,\"start\":45013},{\"end\":45025,\"start\":45021},{\"end\":45036,\"start\":45032},{\"end\":45051,\"start\":45047},{\"end\":45437,\"start\":45434},{\"end\":45448,\"start\":45444},{\"end\":45469,\"start\":45462},{\"end\":45731,\"start\":45728},{\"end\":45745,\"start\":45742},{\"end\":45754,\"start\":45752},{\"end\":45769,\"start\":45765},{\"end\":45781,\"start\":45779},{\"end\":45792,\"start\":45790},{\"end\":45807,\"start\":45803},{\"end\":46227,\"start\":46220},{\"end\":46246,\"start\":46235},{\"end\":46258,\"start\":46253},{\"end\":46533,\"start\":46521},{\"end\":46543,\"start\":46541},{\"end\":46558,\"start\":46551},{\"end\":46821,\"start\":46809},{\"end\":46831,\"start\":46829},{\"end\":46846,\"start\":46839},{\"end\":47082,\"start\":47078},{\"end\":47094,\"start\":47091},{\"end\":47102,\"start\":47100},{\"end\":47113,\"start\":47110},{\"end\":47541,\"start\":47533},{\"end\":47559,\"start\":47554},{\"end\":47950,\"start\":47946},{\"end\":47960,\"start\":47957},{\"end\":47973,\"start\":47970},{\"end\":47987,\"start\":47985},{\"end\":47998,\"start\":47996},{\"end\":48006,\"start\":48003},{\"end\":48021,\"start\":48017},{\"end\":48037,\"start\":48032},{\"end\":48439,\"start\":48433},{\"end\":48455,\"start\":48449},{\"end\":48478,\"start\":48473},{\"end\":48496,\"start\":48488},{\"end\":48509,\"start\":48504},{\"end\":48524,\"start\":48518},{\"end\":48856,\"start\":48849},{\"end\":48877,\"start\":48865},{\"end\":48892,\"start\":48885},{\"end\":49343,\"start\":49339},{\"end\":49355,\"start\":49353},{\"end\":49370,\"start\":49367},{\"end\":49740,\"start\":49736},{\"end\":49753,\"start\":49749},{\"end\":49762,\"start\":49759},{\"end\":49773,\"start\":49771},{\"end\":49787,\"start\":49781},{\"end\":50213,\"start\":50209},{\"end\":50226,\"start\":50222},{\"end\":50238,\"start\":50235},{\"end\":50249,\"start\":50247},{\"end\":50263,\"start\":50257},{\"end\":50654,\"start\":50650},{\"end\":50670,\"start\":50662},{\"end\":50685,\"start\":50680},{\"end\":50884,\"start\":50880},{\"end\":50900,\"start\":50892},{\"end\":50915,\"start\":50910},{\"end\":51202,\"start\":51198},{\"end\":51212,\"start\":51209},{\"end\":51223,\"start\":51218},{\"end\":51239,\"start\":51231},{\"end\":51256,\"start\":51250},{\"end\":51271,\"start\":51266},{\"end\":51545,\"start\":51541},{\"end\":51556,\"start\":51552},{\"end\":51977,\"start\":51973},{\"end\":51992,\"start\":51987},{\"end\":52279,\"start\":52277},{\"end\":52294,\"start\":52289},{\"end\":52307,\"start\":52304},{\"end\":52323,\"start\":52320},{\"end\":52786,\"start\":52784},{\"end\":52801,\"start\":52796},{\"end\":52811,\"start\":52805},{\"end\":52821,\"start\":52819},{\"end\":52826,\"start\":52823},{\"end\":53269,\"start\":53267},{\"end\":53280,\"start\":53277},{\"end\":53293,\"start\":53291},{\"end\":53310,\"start\":53307},{\"end\":53618,\"start\":53616},{\"end\":53633,\"start\":53630},{\"end\":53647,\"start\":53642},{\"end\":53990,\"start\":53987},{\"end\":54003,\"start\":54000},{\"end\":54015,\"start\":54012},{\"end\":54026,\"start\":54023},{\"end\":54537,\"start\":54534},{\"end\":54550,\"start\":54547},{\"end\":54562,\"start\":54559},{\"end\":54573,\"start\":54570},{\"end\":55111,\"start\":55102},{\"end\":55128,\"start\":55119},{\"end\":55385,\"start\":55376},{\"end\":55402,\"start\":55393},{\"end\":55661,\"start\":55656},{\"end\":55673,\"start\":55669},{\"end\":55687,\"start\":55684},{\"end\":55697,\"start\":55694},{\"end\":56153,\"start\":56150},{\"end\":56166,\"start\":56162},{\"end\":56179,\"start\":56174},{\"end\":56192,\"start\":56189},{\"end\":56206,\"start\":56202}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":118649278},\"end\":34565,\"start\":34041},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":4375646},\"end\":34947,\"start\":34567},{\"attributes\":{\"doi\":\"arXiv:1801.04062\",\"id\":\"b2\"},\"end\":35351,\"start\":34949},{\"attributes\":{\"doi\":\"arXiv:2006.09882\",\"id\":\"b3\"},\"end\":35763,\"start\":35353},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":52086912},\"end\":36387,\"start\":35765},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":52024680},\"end\":36933,\"start\":36389},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":14811466},\"end\":37455,\"start\":36935},{\"attributes\":{\"doi\":\"arXiv:2002.05709\",\"id\":\"b7\"},\"end\":37801,\"start\":37457},{\"attributes\":{\"doi\":\"arXiv:2006.10029\",\"id\":\"b8\"},\"end\":38163,\"start\":37803},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":57246310},\"end\":38574,\"start\":38165},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":40461189},\"end\":39224,\"start\":38576},{\"attributes\":{\"id\":\"b11\"},\"end\":39646,\"start\":39226},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":219305432},\"end\":40054,\"start\":39648},{\"attributes\":{\"doi\":\"arXiv:2006.05525\",\"id\":\"b13\"},\"end\":40322,\"start\":40056},{\"attributes\":{\"doi\":\"arXiv:2006.07733\",\"id\":\"b14\"},\"end\":40926,\"start\":40324},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":207930212},\"end\":41451,\"start\":40928},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":206594692},\"end\":41898,\"start\":41453},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":53213211},\"end\":42403,\"start\":41900},{\"attributes\":{\"doi\":\"arXiv:1503.02531\",\"id\":\"b18\"},\"end\":42672,\"start\":42405},{\"attributes\":{\"doi\":\"arXiv:1808.06670\",\"id\":\"b19\"},\"end\":43145,\"start\":42674},{\"attributes\":{\"doi\":\"arXiv:1704.04861\",\"id\":\"b20\"},\"end\":43634,\"start\":43147},{\"attributes\":{\"doi\":\"arXiv:1707.01219\",\"id\":\"b21\"},\"end\":43905,\"start\":43636},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":3608236},\"end\":44258,\"start\":43907},{\"attributes\":{\"id\":\"b23\"},\"end\":44452,\"start\":44260},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":199577547},\"end\":44933,\"start\":44454},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":938105},\"end\":45424,\"start\":44935},{\"attributes\":{\"doi\":\"arXiv:1904.05878\",\"id\":\"b26\"},\"end\":45664,\"start\":45426},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":198185886},\"end\":46209,\"start\":45666},{\"attributes\":{\"doi\":\"arXiv:1905.00076\",\"id\":\"b28\"},\"end\":46453,\"start\":46211},{\"attributes\":{\"doi\":\"arXiv:1807.03748\",\"id\":\"b29\"},\"end\":46741,\"start\":46455},{\"attributes\":{\"doi\":\"arXiv:1807.03748\",\"id\":\"b30\"},\"end\":47034,\"start\":46743},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":131765296},\"end\":47453,\"start\":47036},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":52012952},\"end\":47886,\"start\":47455},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":102483463},\"end\":48423,\"start\":47888},{\"attributes\":{\"doi\":\"arXiv:1412.6550\",\"id\":\"b34\"},\"end\":48773,\"start\":48425},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":206592766},\"end\":49275,\"start\":48775},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":54447578},\"end\":49687,\"start\":49277},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":235719188},\"end\":50125,\"start\":49689},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":234742637},\"end\":50639,\"start\":50127},{\"attributes\":{\"doi\":\"arXiv:1906.05849\",\"id\":\"b39\"},\"end\":50869,\"start\":50641},{\"attributes\":{\"doi\":\"arXiv:1910.10699\",\"id\":\"b40\"},\"end\":51135,\"start\":50871},{\"attributes\":{\"doi\":\"arXiv:2005.10243\",\"id\":\"b41\"},\"end\":51483,\"start\":51137},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":198179476},\"end\":51859,\"start\":51485},{\"attributes\":{\"doi\":\"arXiv:2005.10242\",\"id\":\"b43\"},\"end\":52200,\"start\":51861},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":195492859},\"end\":52700,\"start\":52202},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":4591284},\"end\":53210,\"start\":52702},{\"attributes\":{\"doi\":\"arXiv:2006.07114\",\"id\":\"b46\"},\"end\":53490,\"start\":53212},{\"attributes\":{\"doi\":\"arXiv:1709.00513\",\"id\":\"b47\"},\"end\":53880,\"start\":53492},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":206596723},\"end\":54427,\"start\":53882},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":206596723},\"end\":54974,\"start\":54429},{\"attributes\":{\"doi\":\"arXiv:1612.03928\",\"id\":\"b50\"},\"end\":55365,\"start\":54976},{\"attributes\":{\"doi\":\"arXiv:1605.07146\",\"id\":\"b51\"},\"end\":55562,\"start\":55367},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":24982157},\"end\":56089,\"start\":55564},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":214603165},\"end\":56590,\"start\":56091}]", "bib_title": "[{\"end\":34100,\"start\":34041},{\"end\":34598,\"start\":34567},{\"end\":35878,\"start\":35765},{\"end\":36467,\"start\":36389},{\"end\":37008,\"start\":36935},{\"end\":38216,\"start\":38165},{\"end\":38690,\"start\":38576},{\"end\":39331,\"start\":39226},{\"end\":39731,\"start\":39648},{\"end\":40993,\"start\":40928},{\"end\":41497,\"start\":41453},{\"end\":41985,\"start\":41900},{\"end\":43976,\"start\":43907},{\"end\":44513,\"start\":44454},{\"end\":45007,\"start\":44935},{\"end\":45720,\"start\":45666},{\"end\":47069,\"start\":47036},{\"end\":47522,\"start\":47455},{\"end\":47937,\"start\":47888},{\"end\":48839,\"start\":48775},{\"end\":49328,\"start\":49277},{\"end\":49725,\"start\":49689},{\"end\":50198,\"start\":50127},{\"end\":51529,\"start\":51485},{\"end\":52268,\"start\":52202},{\"end\":52774,\"start\":52702},{\"end\":53979,\"start\":53882},{\"end\":54526,\"start\":54429},{\"end\":55646,\"start\":55564},{\"end\":56141,\"start\":56091}]", "bib_author": "[{\"end\":34115,\"start\":34102},{\"end\":34128,\"start\":34115},{\"end\":34146,\"start\":34128},{\"end\":34154,\"start\":34146},{\"end\":34172,\"start\":34154},{\"end\":34177,\"start\":34172},{\"end\":34623,\"start\":34600},{\"end\":34638,\"start\":34623},{\"end\":34653,\"start\":34638},{\"end\":34975,\"start\":34949},{\"end\":34993,\"start\":34975},{\"end\":35007,\"start\":34993},{\"end\":35022,\"start\":35007},{\"end\":35037,\"start\":35022},{\"end\":35054,\"start\":35037},{\"end\":35069,\"start\":35054},{\"end\":35446,\"start\":35430},{\"end\":35459,\"start\":35446},{\"end\":35474,\"start\":35459},{\"end\":35487,\"start\":35474},{\"end\":35505,\"start\":35487},{\"end\":35520,\"start\":35505},{\"end\":35893,\"start\":35880},{\"end\":35907,\"start\":35893},{\"end\":35918,\"start\":35907},{\"end\":35928,\"start\":35918},{\"end\":35943,\"start\":35928},{\"end\":36482,\"start\":36469},{\"end\":36490,\"start\":36482},{\"end\":36504,\"start\":36490},{\"end\":36515,\"start\":36504},{\"end\":36530,\"start\":36515},{\"end\":37023,\"start\":37010},{\"end\":37036,\"start\":37023},{\"end\":37049,\"start\":37036},{\"end\":37064,\"start\":37049},{\"end\":37539,\"start\":37528},{\"end\":37556,\"start\":37539},{\"end\":37574,\"start\":37556},{\"end\":37591,\"start\":37574},{\"end\":37878,\"start\":37867},{\"end\":37895,\"start\":37878},{\"end\":37910,\"start\":37895},{\"end\":37928,\"start\":37910},{\"end\":37945,\"start\":37928},{\"end\":38228,\"start\":38218},{\"end\":38238,\"start\":38228},{\"end\":38254,\"start\":38238},{\"end\":38265,\"start\":38254},{\"end\":38273,\"start\":38265},{\"end\":38285,\"start\":38273},{\"end\":38706,\"start\":38692},{\"end\":38719,\"start\":38706},{\"end\":38731,\"start\":38719},{\"end\":38746,\"start\":38731},{\"end\":38755,\"start\":38746},{\"end\":38769,\"start\":38755},{\"end\":39344,\"start\":39333},{\"end\":39357,\"start\":39344},{\"end\":39371,\"start\":39357},{\"end\":39744,\"start\":39733},{\"end\":39754,\"start\":39744},{\"end\":39767,\"start\":39754},{\"end\":39777,\"start\":39767},{\"end\":39791,\"start\":39777},{\"end\":40104,\"start\":40090},{\"end\":40117,\"start\":40104},{\"end\":40139,\"start\":40117},{\"end\":40152,\"start\":40139},{\"end\":40415,\"start\":40395},{\"end\":40430,\"start\":40415},{\"end\":40446,\"start\":40430},{\"end\":40463,\"start\":40446},{\"end\":40473,\"start\":40463},{\"end\":40490,\"start\":40473},{\"end\":40508,\"start\":40490},{\"end\":40526,\"start\":40508},{\"end\":40554,\"start\":40526},{\"end\":40579,\"start\":40554},{\"end\":40585,\"start\":40579},{\"end\":41007,\"start\":40995},{\"end\":41018,\"start\":41007},{\"end\":41028,\"start\":41018},{\"end\":41041,\"start\":41028},{\"end\":41056,\"start\":41041},{\"end\":41511,\"start\":41499},{\"end\":41526,\"start\":41511},{\"end\":41540,\"start\":41526},{\"end\":41550,\"start\":41540},{\"end\":42001,\"start\":41987},{\"end\":42013,\"start\":42001},{\"end\":42026,\"start\":42013},{\"end\":42042,\"start\":42026},{\"end\":42422,\"start\":42405},{\"end\":42437,\"start\":42422},{\"end\":42448,\"start\":42437},{\"end\":42775,\"start\":42755},{\"end\":42791,\"start\":42775},{\"end\":42816,\"start\":42791},{\"end\":42829,\"start\":42816},{\"end\":42843,\"start\":42829},{\"end\":42861,\"start\":42843},{\"end\":42869,\"start\":42861},{\"end\":43157,\"start\":43147},{\"end\":43174,\"start\":43157},{\"end\":43182,\"start\":43174},{\"end\":43195,\"start\":43182},{\"end\":43216,\"start\":43195},{\"end\":43229,\"start\":43216},{\"end\":43243,\"start\":43229},{\"end\":43262,\"start\":43243},{\"end\":43268,\"start\":43262},{\"end\":43720,\"start\":43707},{\"end\":43733,\"start\":43720},{\"end\":43990,\"start\":43978},{\"end\":44004,\"start\":43990},{\"end\":44016,\"start\":44004},{\"end\":44332,\"start\":44315},{\"end\":44349,\"start\":44332},{\"end\":44527,\"start\":44515},{\"end\":44540,\"start\":44527},{\"end\":44549,\"start\":44540},{\"end\":44561,\"start\":44549},{\"end\":44571,\"start\":44561},{\"end\":45017,\"start\":45009},{\"end\":45027,\"start\":45017},{\"end\":45038,\"start\":45027},{\"end\":45053,\"start\":45038},{\"end\":45439,\"start\":45426},{\"end\":45450,\"start\":45439},{\"end\":45471,\"start\":45450},{\"end\":45733,\"start\":45722},{\"end\":45747,\"start\":45733},{\"end\":45756,\"start\":45747},{\"end\":45771,\"start\":45756},{\"end\":45783,\"start\":45771},{\"end\":45794,\"start\":45783},{\"end\":45809,\"start\":45794},{\"end\":46229,\"start\":46213},{\"end\":46248,\"start\":46229},{\"end\":46260,\"start\":46248},{\"end\":46535,\"start\":46515},{\"end\":46545,\"start\":46535},{\"end\":46560,\"start\":46545},{\"end\":46823,\"start\":46803},{\"end\":46833,\"start\":46823},{\"end\":46848,\"start\":46833},{\"end\":47084,\"start\":47071},{\"end\":47096,\"start\":47084},{\"end\":47104,\"start\":47096},{\"end\":47115,\"start\":47104},{\"end\":47543,\"start\":47524},{\"end\":47561,\"start\":47543},{\"end\":47952,\"start\":47939},{\"end\":47962,\"start\":47952},{\"end\":47975,\"start\":47962},{\"end\":47989,\"start\":47975},{\"end\":48000,\"start\":47989},{\"end\":48008,\"start\":48000},{\"end\":48023,\"start\":48008},{\"end\":48039,\"start\":48023},{\"end\":48441,\"start\":48425},{\"end\":48457,\"start\":48441},{\"end\":48480,\"start\":48457},{\"end\":48498,\"start\":48480},{\"end\":48511,\"start\":48498},{\"end\":48526,\"start\":48511},{\"end\":48858,\"start\":48841},{\"end\":48879,\"start\":48858},{\"end\":48894,\"start\":48879},{\"end\":49345,\"start\":49330},{\"end\":49357,\"start\":49345},{\"end\":49372,\"start\":49357},{\"end\":49742,\"start\":49727},{\"end\":49755,\"start\":49742},{\"end\":49764,\"start\":49755},{\"end\":49775,\"start\":49764},{\"end\":49789,\"start\":49775},{\"end\":50215,\"start\":50200},{\"end\":50228,\"start\":50215},{\"end\":50240,\"start\":50228},{\"end\":50251,\"start\":50240},{\"end\":50265,\"start\":50251},{\"end\":50656,\"start\":50641},{\"end\":50672,\"start\":50656},{\"end\":50687,\"start\":50672},{\"end\":50886,\"start\":50871},{\"end\":50902,\"start\":50886},{\"end\":50917,\"start\":50902},{\"end\":51204,\"start\":51189},{\"end\":51214,\"start\":51204},{\"end\":51225,\"start\":51214},{\"end\":51241,\"start\":51225},{\"end\":51258,\"start\":51241},{\"end\":51273,\"start\":51258},{\"end\":51547,\"start\":51531},{\"end\":51558,\"start\":51547},{\"end\":51979,\"start\":51964},{\"end\":51994,\"start\":51979},{\"end\":52281,\"start\":52270},{\"end\":52296,\"start\":52281},{\"end\":52309,\"start\":52296},{\"end\":52325,\"start\":52309},{\"end\":52788,\"start\":52776},{\"end\":52803,\"start\":52788},{\"end\":52813,\"start\":52803},{\"end\":52823,\"start\":52813},{\"end\":52828,\"start\":52823},{\"end\":53271,\"start\":53259},{\"end\":53282,\"start\":53271},{\"end\":53295,\"start\":53282},{\"end\":53312,\"start\":53295},{\"end\":53620,\"start\":53610},{\"end\":53635,\"start\":53620},{\"end\":53649,\"start\":53635},{\"end\":53992,\"start\":53981},{\"end\":54005,\"start\":53992},{\"end\":54017,\"start\":54005},{\"end\":54028,\"start\":54017},{\"end\":54539,\"start\":54528},{\"end\":54552,\"start\":54539},{\"end\":54564,\"start\":54552},{\"end\":54575,\"start\":54564},{\"end\":55113,\"start\":55095},{\"end\":55130,\"start\":55113},{\"end\":55387,\"start\":55369},{\"end\":55404,\"start\":55387},{\"end\":55663,\"start\":55648},{\"end\":55675,\"start\":55663},{\"end\":55689,\"start\":55675},{\"end\":55699,\"start\":55689},{\"end\":56155,\"start\":56143},{\"end\":56168,\"start\":56155},{\"end\":56181,\"start\":56168},{\"end\":56194,\"start\":56181},{\"end\":56208,\"start\":56194}]", "bib_venue": "[{\"end\":34318,\"start\":34256},{\"end\":34768,\"start\":34719},{\"end\":36098,\"start\":36029},{\"end\":36685,\"start\":36616},{\"end\":37219,\"start\":37150},{\"end\":38924,\"start\":38855},{\"end\":41205,\"start\":41139},{\"end\":41691,\"start\":41629},{\"end\":42151,\"start\":42105},{\"end\":44714,\"start\":44651},{\"end\":45194,\"start\":45132},{\"end\":45950,\"start\":45888},{\"end\":47256,\"start\":47194},{\"end\":47676,\"start\":47627},{\"end\":48160,\"start\":48108},{\"end\":49049,\"start\":48980},{\"end\":49481,\"start\":49435},{\"end\":49930,\"start\":49868},{\"end\":50406,\"start\":50344},{\"end\":51679,\"start\":51627},{\"end\":52466,\"start\":52404},{\"end\":52969,\"start\":52907},{\"end\":54169,\"start\":54107},{\"end\":54716,\"start\":54654},{\"end\":55840,\"start\":55778},{\"end\":56355,\"start\":56290},{\"end\":34254,\"start\":34177},{\"end\":34717,\"start\":34653},{\"end\":35127,\"start\":35085},{\"end\":35428,\"start\":35353},{\"end\":36027,\"start\":35943},{\"end\":36614,\"start\":36530},{\"end\":37148,\"start\":37064},{\"end\":37526,\"start\":37457},{\"end\":37865,\"start\":37803},{\"end\":38348,\"start\":38285},{\"end\":38853,\"start\":38769},{\"end\":39423,\"start\":39371},{\"end\":39840,\"start\":39791},{\"end\":40088,\"start\":40056},{\"end\":40393,\"start\":40324},{\"end\":41137,\"start\":41056},{\"end\":41627,\"start\":41550},{\"end\":42103,\"start\":42042},{\"end\":42508,\"start\":42464},{\"end\":42753,\"start\":42674},{\"end\":43366,\"start\":43284},{\"end\":43705,\"start\":43636},{\"end\":44065,\"start\":44016},{\"end\":44313,\"start\":44260},{\"end\":44649,\"start\":44571},{\"end\":45130,\"start\":45053},{\"end\":45513,\"start\":45487},{\"end\":45886,\"start\":45809},{\"end\":46513,\"start\":46455},{\"end\":46801,\"start\":46743},{\"end\":47192,\"start\":47115},{\"end\":47625,\"start\":47561},{\"end\":48106,\"start\":48039},{\"end\":48574,\"start\":48541},{\"end\":48978,\"start\":48894},{\"end\":49433,\"start\":49372},{\"end\":49866,\"start\":49789},{\"end\":50342,\"start\":50265},{\"end\":50731,\"start\":50703},{\"end\":50972,\"start\":50933},{\"end\":51187,\"start\":51137},{\"end\":51625,\"start\":51558},{\"end\":51962,\"start\":51861},{\"end\":52402,\"start\":52325},{\"end\":52905,\"start\":52828},{\"end\":53257,\"start\":53212},{\"end\":53608,\"start\":53492},{\"end\":54105,\"start\":54028},{\"end\":54652,\"start\":54575},{\"end\":55093,\"start\":54976},{\"end\":55776,\"start\":55699},{\"end\":56288,\"start\":56208}]"}}}, "year": 2023, "month": 12, "day": 17}