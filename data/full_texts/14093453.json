{"id": 14093453, "updated": "2023-09-28 16:20:22.904", "metadata": {"title": "Multi-behavioral Sequential Prediction with Recurrent Log-bilinear Model", "authors": "[{\"first\":\"Qiang\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Shu\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Liang\",\"last\":\"Wang\",\"middle\":[]}]", "venue": "IEEE Transactions on Knowledge and Data Engineering", "journal": "IEEE Transactions on Knowledge and Data Engineering", "publication_date": {"year": 2017, "month": null, "day": null}, "abstract": "With the rapid growth of Internet applications, sequential prediction in collaborative filtering has become an emerging and crucial task. Given the behavioral history of a specific user, predicting his or her next choice plays a key role in improving various online services. Meanwhile, there are more and more scenarios with multiple types of behaviors, while existing works mainly study sequences with a single type of behavior. As a widely used approach, Markov chain based models are based on a strong independence assumption. As two classical neural network methods for modeling sequences, recurrent neural networks cannot well model short-term contexts, and the log-bilinear model is not suitable for long-term contexts. In this paper, we propose a Recurrent Log-BiLinear (RLBL) model. It can model multiple types of behaviors in historical sequences with behavior-specific transition matrices. RLBL applies a recurrent structure for modeling long-term contexts. It models several items in each hidden layer and employs position-specific transition matrices for modeling short-term contexts. Moreover, considering continuous time difference in behavioral history is a key factor for dynamic prediction, we further extend RLBL and replace position-specific transition matrices with time-specific transition matrices, and accordingly propose a Time-Aware Recurrent Log-BiLinear (TA-RLBL) model. Experimental results show that the proposed RLBL model and TA-RLBL model yield significant improvements over the competitive compared methods on three datasets, i.e., Movielens-1M dataset, Global Terrorism Database and Tmall dataset with different numbers of behavior types.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1608.07102", "mag": "2962825837", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tkde/LiuWW17", "doi": "10.1109/tkde.2017.2661760"}}, "content": {"source": {"pdf_hash": "2ac113d5cc36d2adaea0148c6a568f2951d5fc15", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1608.07102v4.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1608.07102", "status": "GREEN"}}, "grobid": {"id": "b781b0059359a476279ee3615e8f042316fd8c13", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/2ac113d5cc36d2adaea0148c6a568f2951d5fc15.txt", "contents": "\nMulti-behavioral Sequential Prediction with Recurrent Log-bilinear Model\nAUGUST 2015 1\n\nJournal Of L A T E X Class \nFiles \nMulti-behavioral Sequential Prediction with Recurrent Log-bilinear Model\n148AUGUST 2015 1Index Terms-Collaborative filteringsequential predictionmulti-behaviorrecurrent log-bilinear !\nWith the rapid growth of Internet applications, sequential prediction in collaborative filtering has become an emerging and crucial task. Given the behavioral history of a specific user, predicting his or her next choice plays a key role in improving various online services. Meanwhile, there are more and more scenarios with multiple types of behaviors, while existing works mainly study sequences with a single type of behavior. As a widely used approach, Markov chain based models are based on a strong independence assumption. As two classical neural network methods for modeling sequences, recurrent neural networks cannot well model short-term contexts, and the log-bilinear model is not suitable for long-term contexts. In this paper, we propose a Recurrent Log-BiLinear (RLBL) model. It can model multiple types of behaviors in historical sequences with behavior-specific transition matrices. RLBL applies a recurrent structure for modeling long-term contexts. It models several items in each hidden layer and employs position-specific transition matrices for modeling short-term contexts. Moreover, considering continuous time difference in behavioral history is a key factor for dynamic prediction, we further extend RLBL and replace position-specific transition matrices with time-specific transition matrices, and accordingly propose a Time-Aware Recurrent Log-BiLinear (TA-RLBL) model. Experimental results show that the proposed RLBL model and TA-RLBL model yield significant improvements over the competitive compared methods on three datasets, i.e., Movielens-1M dataset, Global Terrorism Database and Tmall dataset with different numbers of behavior types.\n\nINTRODUCTION\n\nN OWADAYS, Collaborative Filtering (CF) [14] plays an important role in a large number of applications, e.g., recommender systems, information retrieval and social network analysis. Conventional CF methods focus on modeling users preference based on their historical choices of items and always ignore the sequential information. It is reasonable to assume that user preferences change with his or her behavioral sequence. Meanwhile, rather than with merely one type of behaviors, e.g., purchasing in e-commerce and clicking on websites, there are many sequential scenarios with multiple types of behaviors towards items, e.g., clicking, purchasing, adding to favorites in e-commerce and downloading, using, uninstalling in app usage. Accordingly, it is necessary to model multi-behavioral sequences and collaboratively predict what a user will prefer next under a specific behavior. For instance, multiple types of behaviors, i.e., posting, sharing and commenting, on social media has been separately modeled and studied recently, which makes great contribution to user interest detection [47]. Besides ecommerce and other Internet applications, multi-behavioral sequential prediction can be implemented for social good, such as predicting security events in a specific area [21] [41] or predicting air quality [48]. Nowadays, some efforts have been put into developing CF methods with sequential information [3] [21] [33] [40] [46]. To the best of our knowledge, none of existing methods are designed for modeling sequences with multiple types of behaviors. And if we directly treat different behaviors towards one item as different elements in sequences, or simply ignore the differences among behaviors, conventional methods will have difficulty in revealing the correlations among behaviors and items. As shown in the example of app usage in Figure 1, different behaviors reveal users' different attitudes towards apps. Downloading and using means you may like the app, while uninstalling means you do not like the app and similar ones should not be recommended. So, it is essential to find a proper way to reveal the correlations among behaviors and items.\n\nMoreover, existing methods still have their own limitations even for single-behavioral sequences. Markov Chain (MC) based models [44] [33] [30] have become the most popular methods for sequential prediction. MC based models aim to predict the users' next behavior based on the past behaviors. A transition matrix is estimated, which can give the probability of an action based on the previous ones. However, a major problem of MC based models is that all the components are independently combined, indicating that it makes strong independence assumption among multiple factors [40].\n\nRecently, Recurrent Neural Networks (RNN) have been successfully employed to model temporal dependency for different applications, such as sentence modeling tasks [23] [24] [25], video modeling [8], sequential click prediction [46] and location prediction [21]. When modeling the sequential data, RNN assumes that the temporal dependency changes monotonously along with positions in a sequence. This Taking app usage prediction as an example of multi-behavioral sequential prediction. This example shows a user's behaviors towards apps in an hour, including downloading, using and uninstalling. We can predict what app the user is going to download or use next. means that, one element, e.g., a word, a frame and a product, in a sequence usually has more significant effect than the previous one for prediction. Such rules may well model words in a sentence or frames in a video, since adjacent words or frames have significant correlation. The larger the distance between two words or two frames, the smaller the correlation. However, for behavior prediction tasks, this assumption does not confirm to complex real situations, especially for the most recent elements in historical sequences. Sometimes, several most recent elements have similar effects on users' next behavior. For instance, if you went to a gym, a restaurant and a shopping market yesterday morning, afternoon and evening respectively, these three behaviors may have similar effects on your behaviors today. Sometimes, most recent elements have more complex effects on the future. For instance, going to a gym yesterday has dominant effects on how you exercise today, and what you ate at a restaurant yesterday or what you bought at a shopping market yesterday can affect what you want to eat today a lot. There is no guarantee that one element has more or less significant effect than the previous one. The effects of most recent elements in modeling human behaviors are much more complicated than that in modeling sentences or videos. But RNN can only tell us that behaviors in yesterday morning have more significant effects than behaviors in yesterday afternoon, and behaviors in yesterday afternoon have more significant effects than behaviors in yesterday evening. Accordingly, we can say that, RNN cannot well model short-term contexts in a sequence.\n\nDifferent from the recurrent architecture in RNN based language models [23] [24] [25], the Log-BiLinear (LBL) model [27] represents each word in a sentence, i.e., each position in a sequence, with a specific matrix. It can better model the complex situations of local contexts in sequences. But when the sequence is too long, a maximal length is usually set. And in real behavior prediction scenarios, length of behavioral sequences is usually not fixed. So, LBL cannot well model long-term contexts in a sequence. Furthermore, time difference between input elements, e.g., continuous time difference between apps that the user has behaviors on in Figure 1, is another key factor in sequential modeling. However, to our best knowledge, none of existing models, including above MC based methods, RNN and LBL, can jointly model sequential information and time difference information in one framework.\n\nIn this paper, to overcome above shortcomings of conventional methods and model multi-behavioral sequences, we propose two novel sequential prediction methods, i.e., Recurrent Log-BiLinear (RLBL) model and Time-Aware Recurrent Log-BiLinear (TA-RLBL) model. First, to capture the properties of different types of behaviors in historical sequences, we employ behavior-specific transition matrices in our model. To the best of our knowledge, this is the first work which is designed for predicting multi-behavioral sequences Second, we design RLBL model as a recurrent architecture to capture long-term contexts in sequences. It models several elements in each hidden layer and uses position-specific transition matrices to capture short-term contexts of the historical sequence. Our RLBL not only can model the subtle characteristics of the most recent items in a sequence, but also can deal with long-term contexts with a recurrent structure. Third, we further extend the RLBL model based on time difference information, and propose the TA-RLBL model. Rather than specific matrices for each position in RLBL, we use specific matrices, i.e., time-specific transition matrices, for each time difference value between input elements in TA-RLBL. Since it is difficult to estimate matrices for all the continuous time difference values, we divide all the possible temporal values into discrete bins. For a specific time difference value in one time bin, we can calculate the corresponding transition matrix via a linear interpolation of transition matrices of the upper bound and lower bound. Incorporating continuous time difference information, TA-RLBL can further improve the performance of RLBL.\n\nThe main contributions of this work are listed as follows:\n\n\u2022 We firstly address the problem of multi-behavioral sequential prediction, which is a significant problem in sequential prediction. And we use behaviorspecific matrices to represent the effects of different types of behaviors.\n\n\n\u2022\n\nThe RLBL model incorporates position-specific matrices and the recurrent structure, which can well model both short-and long-term contexts in historical sequences.\n\n\u2022 TA-RLBL uses time-specific matrices to jointly model sequential information and time difference information in one framework, which further improves the performance of RLBL.\n\n\u2022 Experiments conducted on three real-world datasets show that RLBL and TA-RLBL are effective and clearly outperform state-of-the-art methods.\n\nThe rest of the paper is organized as follows. In section 2, we review some related work on sequential prediction. Then we give the problem definition of multi-behavioral sequential prediction in section 3. Section 4 and 5 detail our RLBL model and TA-RLBL model respectively. In section 6, we introduce the learning methods of our proposed models. In section 7, we conduct experiments on three real-world datasets and compare with several state-of-the-art methods. Section 8 concludes our work and discusses future research.\n\n\nRELATED WORKS\n\nIn this section, we review several types of methods for sequential prediction and time-aware prediction, i.e., timeaware neighborhood based methods, time-aware factorization methods, markov chain based methods and neural network based methods.\n\n\nTime-aware Neighborhood\n\nTime-aware neighborhood models [7] [17] [18] may be the most natural methods for modeling sequential information. These methods employ neighborhood based algorithms to capture temporal effects via giving more relevance to recent observations and less to past observations. However, though these methods may confirm to our first instinct and properties of sequential information, neighborhood based methods are unable to reveal the underlying properties in users' historical sequences.\n\n\nTime-aware Factorization Methods\n\nMatrix factorization (MF) based methods [29] [15] [14] have become the state-of-the-art approach to collaborative filtering. Nowadays, MF based methods have been extended for more general and complex situations [31] [34]. Among them, time-aware factorization based models have been extensively studied. Tensor Factorization (TF) [1] [42] treats time slices as another dimension and generates latent vectors of time slices via factorization to capture the underlying properties in the behavioral history. TimeSVD++ [13] learns timeaware representations for users and items in different time slices. However, factorization based models have difficulties in generating latent representations for time slices which has never or seldom appeared in the training data. Thus, factorization based models are not able to accurately predict item in the future time slices.\n\n\nMarkov Chain Based Methods\n\nBased on the Markov assumption, MC based methods are widely used models for sequential prediction tasks [44]. MC based models predict users' next behaviors via estimating a transition matrix, which gives the probability of an action based on the previous ones. Via factorization of the personalized probability transition matrices of users, Factorizing Personalized Markov Chain (FPMC) [33] can provide more accurate prediction for each sequence. FPMC is also extended by using the user group [30] or incorporating the location constraint [5]. Recently, some factors of human brain have been added into MC based methods, including interest-forgetting curve [4] and dynamics of boredom [11].\n\nHowever, the main drawback of MC based models is the independent combination of the past components, which lies in a strong independence assumption and confines the prediction accuracy. Then MC based methods are extended by using representation learning. Hierarchical Representation Model (HRM) [40] learns the hierarchical representation of behaviors in the last transaction and in the past history of a user to predict behaviors in the next transaction. And Personalized Ranking Metric Embedding (PRME) [10] learns embeddings of users according to distances between locations. These methods still face a problem that they only model items in the most recent history and previous items can only be modeled by constant user latent vectors. Thus, except items in the most recent history, other items after model training will be ignored. User representations cannot change dynamically along with behavioral sequences.\n\n\nNeural Network Based Methods\n\nRecently, some prediction models, especially language models [26], are proposed based on neural networks. The most classical neural language model is proposed via a single layer neural network [2]. Among variety language models, RNN has been the most successful one in modeling sentences [23] [24] [25]. It has successfully applied in variety natural language processing tasks, such as machine translation [6] [38], conversation machine [36] [37] and image caption [22] [39]. Recently, RNN based models also achieve successive results in other areas. For video analyzing, RNN brings satisfying results for action recognition [8]. Incorporating users' each clicking as an input element of each layer, RNN has greatly improved the performance of sequential click prediction [46]. Spatial-Temporal Recurrent Neural Netwrks (ST-RNN) [21] learns geographical distance-specific transition matrices in RNN framework for location prediction. And Dynamic REcurrent bAsket Model (DREAM) [45] uses pooling methods in each layer of RNN for aggregating items in one transaction and achieves state-of-the-art performance in next basket recommendation [45]. Context-Aware Recurrent Neural Netwrks (CA-RNN) [20] incorporates variety of contextual information in the RNN structure for recommender systems. However, when modeling sequential data, RNN assumes that temporal dependency changes monotonously along with the positions in a sequence, which means one element in a sequence usually has more significant effect than the previous one for prediction. This is usually suitable for words in sentences or frames in videos. But it does not confirm to practical situations for predicting behaviors, especially for the most recent elements of a historical sequence. Several most recent elements may usually have similar or even more complex effects on a user's next choice. But RNN can only tell us that the most recent item has more significant effect than the previous items. So, we can say that RNN cannot well model short-term contexts in behavior modeling.\n\nLBL [27] is another widely-used language model, which represents elements at each position in a sequence with specific matrices. And a hierarchical softmax [28] is utilized to accelerate LBL model. However, when sequences are too long, a maximal length is usually set and long-term contexts are discarded. So, LBL cannot well model long-term contexts  in sequences, which often exist in real behavior prediction situations.\n\nThere also exist some studies on RNN based methods taking insight in modeling short-term and long-term contexts, e.g., Multi-timescale RNN [43] [19] and Clockwork RNN [16]. Based on a hierarchical RNN structure [9], these methods model short-term dependencies and long-term dependencies separately with multiple RNNs. These multiple RNNs are at different timescales, where the fastest one operates every input element, and relatively slower ones take delays and skip some input elements according to corresponding timescales. However, these RNN structures aim to better capture long-term dependencies in sequences via incorporating larger timescales in some of the many RNNs. Although they can indeed achieve better performance comparing with conventional structures in some applications [43] [16] [19], they still model input elements according to sequential orders in a RNN structure. Accordingly, they cannot overcome the drawback of RNN that temporal dependency changes monotonously. It is still hard for these methods to well model short-term contexts in behavior modeling scenarios.\n\n\nPROBLEM DEFINITION\n\nThe multi-behavioral sequential prediction problem we study in this work can be formulated as follows. We have a set of users and a set of items denoted as U = {u 1 , u 2 , ...} and V = {v 1 , v 2 , ...} respectively. Multiple types of behaviors are denoted as B = {b 1 , b 2 , ...}. Each behavior of user u is associated with a behavioral type and a timestamp. Then the sequential behavioral history of user u consists\nof items V u = {v u 1 , v u 2 , ...}, corresponding behavioral types B u = {b u 1 , b u 2 , .\n..} and timestamps T u = {t u 1 , t u 2 , ...}. Given behavioral history of users towards items, the task is to predict what a specific user will choose next under a specific behavior.\n\n... Fig. 3. Illustration of the Log-BiLinear (LBL) model. LBL is a feedforward neural network with a single linear hidden layer. In LBL, each position in sequences is modeled with a specific transition matrix. And a maximal number of modeled elements is usually set. LBL has difficulty in modeling long-term contexts in behavioral sequences.\n\nHere, taking the application in e-commerce as an example, there will be four types of behaviors (i.e., clicking, purchasing, adding to favorites and adding to shopping chart) denoted as {b 1 , b 2 , b 3 , b 4 }. The task is to predict which item a user would like to click, purchase, add to favorites or add to shopping chart next. Similarly, in the app usage, there will be three types of behaviors (i.e., downloading, using and uninstalling) denoted as {b 1 , b 2 , b 3 }. Then the task becomes predicting which app a user would like to download, use or uninstall next.\n\n\nRECURRENT LOG-BILINEAR MODEL (RLBL)\n\nIn this section, we present the recurrent log-bilinear model. We first introduce the RNN model and LBL model, then detail the architecture of RLBL with a single type of behaviors and introduce how RLBL can be employed to model multiple types of behaviors.\n\n\nRecurrent Neural Networks\n\nThe architecture of RNN is shown in Figure 2. It consists of an input layer, an output unit, multiple hidden layers, as well as inner weight matrices [46]. The activation values of the hidden layers are computed as:\nh u k = f Wh u k\u22121 + Cr v u k ,(1)\nwhere h u k \u2208 R d denotes the hidden representation of user u at position k in a sequence, r v u k \u2208 R d denotes the representation of the kth input item of user u. f (x) is the activation function. C \u2208 R d\u00d7d and W \u2208 R d\u00d7d mean the transition matrix for the current items and the previous status respectively. W can propagate sequential signals, and C can capture users' current behavior. This activation process can be repeated iteratively and then the status at each position in a sequence can be calculated.\n\n\nLog-bilinear Model\n\nThe Log-BiLinear (LBL) model [27] is a deterministic model that may be viewed as a feedforward neural network with a single linear hidden layer [12]. Using LBL for the sequential prediction problem, the final predicted representation of a sequence is generated based on the input items and the transition matrices at each position. As shown in Figure 3, in the LBL model, the representation at next position is a linear prediction:\nh u k = n\u22121 i=0 C i r v u k\u2212i ,(2)\nwhere C i \u2208 R d\u00d7d denotes the transition matrix for the corresponding position in a sequence, and n is the number of elements modeled in a sequence.\n\n\nModeling Single Type of Behaviors\n\nAs discussed in the previous sections, though both RNN and LBL have achieved satisfying results, they still have their own drawbacks. RNN cannot well handle short-term contexts in a sequence, while LBL cannot well model longterm contexts.\n\nTo capture short-term and long-term contexts in historical sequences simultaneously, instead of modeling only one element in each hidden layer in RNN, we model several elements in each hidden layer and incorporate position-specific matrices into the recurrent architecture. As illustrated in Figure 4(a), given a user u, the hidden representation of the user at the position k in a sequence can be computed as:\nh u k = Wh u k\u2212n + n\u22121 i=0 C i r v u k\u2212i ,(3)\nwhere n is the number of input items modeled in one layer of RLBL, which is called the window width in this paper. The position-specific transition matrices C i \u2208 R d\u00d7d captures the impact of short-term contexts, i.e., the ith item in one layer of RLBL, on user behaviors. And the characteristics of users' long-term history are modeled via the recurrent framework. Moreover, when we only consider one input item in each layer and set the window width n = 1, the formulation of RLBL will be as the same as that of RNN ignoring the nonlinear activation function. Notice that, when the sequence is shorter than the window width or the predicted position is at the very first part of a sequence, i.e., k < n. Equation 3 should be rewritten as:\nh u k = Wh u 0 + k\u22121 i=0 C i r v u k\u2212i ,(4)\nwhere h u 0 = u 0 , denoting the initial status of users. The initial status of all users should be the same because personal information does not exist when a user has not selected an item. This representation u 0 can be used to model cold start users. The equation in this special situation can be viewed as the same as that of a regular LBL model.\n\n\nModeling Multiple Types of Behaviors\n\nAlthough there exist some scenarios with one type of behavior, e.g., purchasing in e-commerce and clicking on websites, there are much more applications with multiple types of behaviors towards items. For instance, users will click items, purchase items and add items to favorites in e-commerce. And users may download apps, use apps and uninstall apps. Thus, it is necessary to model multi-behavioral sequences and collaboratively predict what a user will choose next under a specific behavior.\n\nWe can simply ignore different types of behaviors, or treat different behaviors towards one item as different elements in conventional models. However, it is hard to model the correlation among different behaviors towards one item. Here, we incorporate behavior-specific matrices to capture properties of multiple types of behaviors. Then, the representation of user u at position k can be calculated as:\nh u k = Wh u k\u2212n + n\u22121 i=0 C i M b u k\u2212i r v u k\u2212i ,(5)\nwhere M b u i \u2208 R d\u00d7d denotes a behavior-specific transition matrix modeling the corresponding behavior on the ith item of user u. Note that, behavior-specific matrices can be omitted if there is only one type of behavior. Incorporating behavior-specific matrices, RLBL is the first approach which can be used to model the underlying properties of different types of behaviors in historical sequences. Now, via calculating inner product, the prediction of whether user u would conduct behavior b on item v at the sequential position k + 1 can be made as:\ny u,k+1,b,v = (s u k ) T M b r v = (h u k + u u ) T M b r v ,(6)\nwhere s u k denotes the representation for the status of user u at the sequential position k, containing dynamic representation h u k and static latent representation u u \u2208 R d .\n\n\nTIME-AWARE RLBL MODEL (TA-RLBL)\n\nSequential models often ignore the continuous time difference between input elements. The time difference information is important for prediction considering that shorter time differences usually have more significant impact on the future comparing with longer time differences. For instance, suppose there are two items, v a and v b , in a user's purchasing history. The user bought item v a last night and item v b last month. It is probably that the user's choice about what to buy next is mainly influenced by item v a . In contrast, if item v b is bought last mourning, it is probably that both item v a and v b have similar impact to the user's choice because of similar interests in a short period. Moreover, as the purchasing behavior of some items is periodical such as buying tooth paste every month, the effect of time difference becomes more significant in such situations. Accordingly, in this section, we extend our RLBL model with time difference information and introduce the timeaware recurrent log-bilinear model.\n\n\nProposed Model\n\nAs discussed above, it will be reasonable if we incorporate time difference information in our RLBL model. Here, we replace position-specific transition matrices with time-specific transition matrices and propose a time-aware RLBL model. As shown in Figure 4(b), given a user u, representation at position k can be calculated as:\nh u k = Wh u k\u2212n + n\u22121 i=0 T t u k \u2212t u k\u2212i r v u k\u2212i ,(7)\nwhere t u k denotes the current timestamp, t u k\u2212i means the timestamp of each item in one layer of TA-RLBL, and    Moreover, similar to RLBL, when k < n, Equation 7 should be rewritten as:\nh u k = Wh u 0 + k\u22121 i=0 T t u k \u2212t u k\u2212i r v u k\u2212i ,(8)\nwhere h u 0 = u 0 , denoting the initial status of users. To model multiple types of behavior, behavior-specific transition matrices are also applied in TA-RLBL model:\nh u k = Wh u k\u2212n + n\u22121 i=0 T t u k \u2212t u k\u2212i M b u k\u2212i r v u k\u2212i .(9)\nThen, similar to RLBL, the prediction of whether user u would conduct behavior b on item v at sequential position k + 1 can be computed as: \ny u,k+1,b,v = (s u k ) T M b r v = (h u k + u u ) T M b r v .(10)\n\nLinear Interpolation for Learning Transition Matrices\nT t d = T L(t d ) (U (t d ) \u2212 t d ) + T U (t d ) (t d \u2212 L(t d )) [(U (t d ) \u2212 t d ) + (t d \u2212 L(t d ))] ,(11)\nwhere U (t For instance, if the range of all the possible time difference values is partitioned into one-hour bins, and we want to calculate the transition matrix for time difference value 1.6h, the upper bound and lower bound of 1.6h will be 2h and 1h respectively, and the corresponding time-specific transition matrix T 1.6h can be calculated as:\nT 1.6h = [T 1h (2h \u2212 1.6h) + T 2h (1.6h \u2212 1h)] [(2h \u2212 1.6h) + (1.6h \u2212 1h)] = 0.4T 1h + 0.6T 2h .(12)\nUntil now, we have detailed the RLBL and TA-RLBL model. Both models can well capture sequential information. If there exists explicit time information, TA-RLBL model is more suitable than that of RLBL model. And if the dataset is not associated with detailed time information, RLBL mode will be more suitable than TA-RLBL model. Both models are constructed under the same framework and can be applied according to actual situations.\n\n\nPARAMETER LEARNING\n\nIn this section, we introduce the learning process of our proposed RLBL and TA-RLBL model with Bayesian Personalized Ranking (BPR) [32] and Back Propagation Through Time (BPTT) [35].\n\n\nLearning of RLBL\n\nBPR [32] is a state-of-the-art pairwise ranking framework for the implicit feedback data. BPR has been used as objective function for learning of RNN based models in behavioral prediction tasks [21] [45]. The basic assumption of BPR is that a user prefers a selected element than a negative one. Formally, we need to maximize the following probability:\np(u, k + 1, b, v v ) = g(y u,k+1,b,v \u2212 y u,k+1,b,v ) ,(13)\nwhere v denotes a negative sample, and g(x) is a nonlinear function which is selected as:\ng(x) = 1 1 + e \u2212x .(14)\nIncorporating the negative log likelihood, we can minimize the following objective function equivalently:\nJ 1 = ln(1 + e \u2212(y u,k+1,b,v \u2212y u,k+1,b,v ) ) + \u03bb 2 \u0398 1 2 ,(15)\nwhere \u0398 1 = {U, R, W, C, M} denotes all the parameters to be estimated, \u03bb is a parameter to control the power of regularization. And the derivations of J 1 with respect to the parameters can be calculated as:\n\u2202J 1 \u2202u u = M b (r v \u2212 r v )l(u, k + 1, b, v v ) 1 + l(u, k + 1, b, v v ) + \u03bbu u , \u2202J 1 \u2202r v = \u2212 (M b ) T (h u k + u u )l(u, k + 1, b, v v ) 1 + l(u, k + 1, b, v v ) + \u03bbr v , \u2202J 1 \u2202r v = (M b ) T (h u k + u u )l(u, k + 1, b, v v ) 1 + l(u, k + 1, b, v v ) + \u03bbr v , \u2202J 1 \u2202M b = (h u k + u u )(r v \u2212 r v ) T l(u, k + 1, b, v v ) 1 + l(u, k + 1, b, v v ) +\u03bbM b , \u2202J 1 \u2202h u k = \u2212 M b (r v \u2212 r v )l(u, k + 1, b, v v ) 1 + l(u, k + 1, b, v v ) , where l(u, k + 1, b, v v ) = e \u2212(y u,k+1,b,v \u2212y u,k+1,b,v ) .\nThe derivations of the output layer have been calculated. Under each layer of the recurrent structure, similar to the conventional RNN model, RLBL can be trained by using the Back Propagation Through Time (BPTT) algorithm [35], which has been used in practical sequential prediction models [21] [46]. For user u, given the derivation \u2202J1 \u2202h u k of the representation h u k at sequential position k, the corresponding gradient of parameters at the hidden layer can be calculated as:\n\u2202J 1 \u2202h u k\u2212n = W T \u2202J 1 \u2202h u k , \u2202J 1 \u2202W T = \u2202J 1 \u2202h u k (h u k\u2212n ) T , \u2202J 1 \u2202r v u k\u2212i = (M b u k\u2212i ) T (C i ) T \u2202J 1 \u2202h u k , \u2202J 1 \u2202C i = \u2202J 1 \u2202h u k (r v u k\u2212i ) T (M b u k\u2212i ) T , \u2202J 1 \u2202M b u k\u2212i = (C i ) T \u2202J 1 \u2202h u k (r v u k\u2212i ) T .\nThis process can be repeated iteratively, and the gradients of all the parameters are obtained. Then, the model can be learned via Stochastic Gradient Descent (SGD) until converge.\n\n\nLearning of TA-RLBL\n\nFor learning of TA-RLBL, using BPR [32], similar to Equation 14 and 15, we need to minimize the following objective function:\nJ 2 = ln(1 + e \u2212(y u,k+1,b,v \u2212y u,k+1,b,v ) ) + \u03bb 2 \u0398 2 2 ,(16)\nwhere \u0398 2 = {U, R, W, T, M} denotes all the parameters to be estimated in TA-RLBL. Similarly, the derivations of J 2 with respect to the parameters can be computed as:\n\u2202J 2 \u2202u u = M b (r v \u2212 r v )l(u, k + 1, b, v v ) 1 + l(u, k + 1, b, v v ) + \u03bbu u , \u2202J 2 \u2202r v = \u2212 (M b ) T (h u k + u u )l(u, k + 1, b, v v ) 1 + l(u, k + 1, b, v v ) + \u03bbr v , \u2202J 2 \u2202r v = (M b ) T (h u k + u u )l(u, k + 1, b, v v ) 1 + l(u, k + 1, b, v v ) + \u03bbr v , \u2202J 2 \u2202M b = (h u k + u u )(r v \u2212 r v ) T l(u, k + 1, b, v v ) 1 + l(u, k + 1, b, v v ) +\u03bbM b , \u2202J 2 \u2202h u k = \u2212 M b (r v \u2212 r v )l(u, k + 1, b, v v ) 1 + l(u, k + 1, b, v v ) , where l(u, k + 1, b, v v ) = e \u2212(y u,k+1,b,v \u2212y u,k+1,b,v ) .\nThen, similar to RLBL, using BPTT [35], for user u, given the derivation \u2202J2 \u2202h u k of the representation h u k at the sequential position k, the corresponding gradient of parameters at the hidden layer can be calculated as:\n\u2202J 2 \u2202h u k\u2212n = W T \u2202J 2 \u2202h u k , \u2202J 2 \u2202W T = \u2202J 2 \u2202h u k (h u k\u2212n ) T , \u2202J 2 \u2202r v u k\u2212i = (M b u k\u2212i ) T (T t u k \u2212t u k\u2212i ) T \u2202J 2 \u2202h u k , \u2202J 2 \u2202T t u k \u2212t u k\u2212i = \u2202J 2 \u2202h u k (r v u k\u2212i ) T (M b u k\u2212i ) T , \u2202J 2 \u2202M b u k\u2212i = (T t u k \u2212t u k\u2212i ) T \u2202J 2 \u2202h u k (r v u k\u2212i ) T .\nThe process above can be repeated iteratively, and we can obtain all the gradients. After that, the model can be trained via SGD until converge.\n\n\nEXPERIMENTS\n\nIn this section, we empirically investigate the performance of RLBL and TA-RLBL. As shown in Table 1, we conduct our experiments on three scenarios with different numbers of behavioral types. We first introduce our experimental settings. Then we conduct experiments to compare RLBL and TA-RLBL with different window width and experiments to compare performances of single behavior and multiple behaviors. We also give comparison of our models and some state-of-the-art methods with varying dimensionality. Then, we study the performance of models under different length of behavioral history. Finally, we analyse the computational time and convergence of our proposed methods. \n\n\nExperimental Settings\n\nOur experiments are conducted on three real datasets with different numbers of behavioral types. Details of these datasets are illustrated in Table 1.\n\n\u2022 Movielens-1M 1 is a widely used dataset, associated with timestamps, for the rating prediction in recommender systems. It contains about 1,000,000 rating records of 4,000 movies by 6,000 users. The ratings are divided into five levels, indicating users' different levels of preference, which can be viewed as five different types of behaviors. With this dataset, we aim to predict which movie a user will rate 5 or 4 stars next, i.e., which movie a user will prefer next.\n\n\u2022 Global Terrorism Database 2 includes more than 125,000 terrorist incidents that have occurred all around the world since 1970 conducted by about 3,000 terrorist organizations. This dataset consists of 7 behavioral types, i.e., different attacking types, as indicated in Table 1. For social good, we would like to predict which province or state a terrorist organization will attack. Thus, it is available for us to take action before accidents happen and save people's life.\n\n\u2022 Tmall 3 is a dataset collected from Tmall 4 , one of the biggest online shopping websites in China. It contains about 200,000 shopping records belonging to 1,000 users on 10,000 items. The temporal information of the dataset is extracted based on the day level. It contains four different types of behaviors: clicking, purchasing, adding to favorites and adding to shopping cart. It suits for the task of collaborative prediction on multi-behavioral sequences. On this dataset, we aim to predict what users will purchase next.\n\nFor each behavioral sequence of these three datasets, we use first 70% of the items in the sequence for training, following 10% data as the validation set for tuning parameters, e.g., the dimensionality of latent representations, and remaining 20% for testing. The regularization parameter is set as \u03bb = 0.01. And we use line search to select learning rates in each iteration.\n\nWe compare RLBL and TA-RLBL with both conventional and state-of-the-art sequential methods.\n\n\u2022 POP is a naive baseline method that recommends the most popular items to users.\n\n\u2022 MF [29] is one of the state-of-the-art methods for conventional collaborative filtering. It factorizes a 1. http://grouplens.org/datasets/movielens/ 2. http://www.start.umd.edu/gtd/ 3. https://102.alibaba.com/competition/addDiscovery/index.htm 4. https://www.tmall.com/ user-item matrix into two low rank matrices, each of which represents the latent factors of users or items.\n\n\u2022 MC is a classical sequential model based on markov assumption, and is used as a sequential baseline method.\n\n\u2022 TF [42] is an extension of MF method. It extends MF from two dimensions to three dimensions, and the temporal information is modeled as the additional dimension.\n\n\u2022 FPMC [33] extends conventional MC methods and factorizes personalized probability transition matrices of users. It is a widely-used method for sequential prediction and next basket recommendation.\n\n\u2022 HRM [40] learns the representation of behaviors in the previous transaction and predicts next behaviors. It has become a state-of-the-art method for next basket recommendation.\n\n\u2022 RNN [45] is a state-of-the-art method for the sequential prediction. It has been successfully applied in some applications, such as sentence modeling, click prediction, location prediction and next basket recommendation.\n\nConsidering TF learns latent vectors for time slices, and MC, FPMC and HRM predict future behaviors according to behaviors in the last transaction, we need to split transactions in different datasets according to corresponding application scenarios. So, we set the length of transaction in the Movielens dataset, the Global Terrorism Database and the Tmall dataset as one week, one month and one day respectively.\n\nAs above methods cannot model multi-behavioral sequences, when conducting compared methods on multibehavioral datasets, we ignore different types of behaviors in behavioral histories. This means we treat different behaviors towards one item as the same.\n\nMoreover, to investigate the performance of our proposed methods and compared methods, we select several widely-used evaluation metrics for our experiments.\n\n\u2022 Recall@k and F1-score@k are two important metrics for ranking tasks. The evaluation score for our experiments is computed according to where the next selected item appears in the predicted list. We report recall@k and F1-score@k with k = 1, 2, 5 and 10 in our experiments. The larger the value, the better the performance.\n\n\n\u2022\n\n\nMean Average Precision (MAP)\n\nis another widely used global evaluation in ranking tasks, which measure the quality of the whole ranking list. Top-bias property of MAP is particularly significant in evaluating ranking tasks such as top-n recommendation. The larger the value, the better the performance. \n\n\nRLBL VS. TA-RLBL\n\nTo compare the performances of our proposed RLBL and TA-RLBL, and investigate their performances with different window size, we conduct experiments on the three datasets with varying window size n. The results evaluated by recall, F1-score and MAP are illustrated in Table 2. We can clearly observe that, TA-RLBL performs better that RLBL in most cases. On the Movielens dataset, TA-RLBL clearly achieves a better performance evaluated by all the metrics with all the window width and the performance difference between the two models are stable. On the Global Terror-ism Database, TA-RLBL performs better than RLBL mostly, especially evaluated by the global metrics MAP. But under window width n = 9, the RLBL model achieves a slightly better recall@10 and F1-score@10 scores. These observations clearly indicate that replacing position-specific transition with time-specific transition can achieve better performance when there exists explicit time information. However, on the Tmall dataset, RLBL performs better than TA-RLBL in most cases. The reason may be that time information in the Tmall dataset is detailed to the day level. In the Tmall dataset, there are averagely 5.56 times of clicking, 1.65 times of purchasing, 1.42 times of adding to favorites, and 1.25 times of adding to shopping chart in one day conducted by one user. For these behaviors happening in the same day, there exists only sequential information of behaviors on items, but no more detailed time information. Accordingly, timespecific transition matrices for behaviors in one day will become the same, and orders among them will be discarded. Therefore, time-specific transition in TA-RLBL brings slight performance decrease on the Tmall dataset. Accordingly, it is necessary to select a proper model between RLBL and TA-RLBL according to whether there exists enough detailed time information in the dataset. For TA-RLBL incorporates time difference information, when the dataset has detailed time information, TA-RLBL will perform better. Otherwise, RLBL will be a better choice. The experimental results in Table 2 provide some hints in selecting the best window width n for RLBL and TA-RLBL in our experiments. Performances of our models on Movielens are stable and the best performances are obviously achieved at n = 6. On the Tmall dataset and the Global Terrorism Database, the performances are not so stable evaluated by different metrics. We can select the best parameters according to the global metric MAP, which considers all the positions in a ranking list. Then the best window width for the Global Terrorism Database is n = 9, and the best window width for the Tmall dataset is n = 5. For the rest of our experiments, we report the performances of RLBL and TA-RLBL under the best window width. Moreover, for metrics recall@p and F1-score@p, there seems existing a rough pattern. For smaller p, better recall values and F1-score values of RLBL and TA-RLBL are achieved with smaller window width n. While for larger p, better recall values and F1-score values of RLBL and TA-RLBL are achieved with larger window width n.\n\n\nMultiple Behaviors VS. Single Behavior\n\nWe have analyzed performances of RLBL and TA-RLBL modeling multiple behaviors. To investigate the impact of multiple behaviors and single behavior on prediction effectiveness, we need to obtain performances of RLBL and TA-RLBL modeling a single behavior. As we ignore different types of behaviors when implementing compared methods, we also ignore multiple types of behaviors conducted on items in sequences when implementing RLBL and TA-RLBL in this experiment. Thus, the data of a user becomes a sequence consisting of items without behavioral types. Then, performances of the proposed methods under a single type of behavior can be obtained. To be noted, the partition of three datasets among training, testing and validation stays the same.\n\nThe performance comparison of modeling multiple behaviors and single behavior evaluated by recall, F1-score and MAP on three datasets is shown in Table 3. We can clearly observe the significant improvements brought by modeling multiple behaviors. Comparing with modeling single behavior, MAP improvements of RLBL modeling multiple behaviors are 2.92%, 10.52% and 6.41% on three datasets respectively. And for TA-RLBL modeling multiple behaviors, comparing with modeling single behavior, the MAP improvements become 2.96%, 10.46% and 6.42%, which are close to previous ones. Moreover, we can also  Table 2 with results of RNN in Table 3, even not with the best window width, most of the results of RLBL and TA-RLBL are still better than the performance of RNN. This indicates the effectiveness and stability of RLBL and TA-RLBL with varying window width.\n\n\nPerformance Comparison with Different Methods\n\nWe compare RLBL, TA-RLBL and competitive methods with varying dimensionality d evaluated by recall and MAP on the three datasets. The results on the Movielens dataset, the Global Terrorism Database and the Tmall dataset are illustrated in Figure 5, 6 and 7 respectively. Compared to the baseline performance of POP, the performances of MF, MC and TF have very similar improvement on the three datasets. They all have their shortcomings. Since MF cannot model sequential information, MC cannot model collaborative information, and TF has difficulty in predicting future behaviors, none of them achieves very satisfactory results. Jointly modeling sequential information and collaborative information, FPMC achieves great improvement comparing with these three methods. Learning latent representations of recent behaviors, HRM further improves the performance of FPMC. Furthermore, RNN brings another large improvement on the three datasets, and is clearly the best one among all the compared methods. Moreover, we can observe that, our proposed RLBL model and TA-RLBL model achieve the best performance on all the three datasets in terms of all the metrics. Using the performances with the best dimensionality of each method, comparing with RNN, the MAP improvements of RLBL are 9.18%, 21.27% and %16.64 on the Movielens dataset, the Global Terrorism Database and the Tmall dataset respectively. And the MAP improvements of TA-RLBL are 11.62%, 23.04% and 15.31% on the three datasets respectively. These results show the superiority of our methods brought by multi-behavior modeling and incorporating position-specific in RLBL or time-specific transition in TA-RLBL. In Figure 5, 6 and 7, we can also observe the performance curves of all the methods growing along with dimensionality n. All the curves clearly show the great advantages of RLBL and TA-RLBL comparing with other compared methods with different dimensionality. The performance difference between RLBL and TA-RLBL discussed above can also be observed from the performance curves. Moreover, the curves show that the performances of our models are stable in a large range on different datasets evaluated by different metrics. And even not with the best dimensionality, our methods can still outperform compared methods. According to the curves, we select the dimensionality as d = 8, and we report corresponding performances in the rest of our experiments.\n\n\nComparison with Different Length of Behavioral History\n\nSimilar to the strategy in [40], we split behavior sequences into three different types according to their length: short, medium and long. Thus, we can investigate the performance of models under different situations. In our experiments, for roughly equal splitting of behavioral sequences, we set the thresholds for the Movielens dataset as 50 and 200, the thresholds for the Global Terrorism Database as 50 and 200, and the thresholds for the Tmall dataset as 100 and 500.\n\nThe performance comparison of FPMC, HRM, RNN, RLBL and TA-RLBL with different length of behavioral history evaluated by recall, F1-score and MAP is shown in Table 4. From the results, we can see that RLBL and TA-RLBL performs better than compared methods, i.e., FPMC, HRM and RNN, in all the situations. This shows  the flexibility of our methods with variety length of behavioral history. Moreover, FPMC and HRM have the best performances on medium-length sequences, followed by long-length sequences. This also confirms the results and consequences in [40], where FPMC and HRM perform best on medium-length sequences. For RNN, RLBL and TA-RLBL, the longer the sequences, the better the performances. This may because FPMC and HRM only model the most recent behaviors when making prediction, and previous behaviors can only be revealed by constant user latent vectors. Then, except most recent behaviors, other behaviors after model training will be ignored. So, with longer behavioral sequences, there will be more behaviors ignored, and poorer performances will be achieved. While models with recurrent structure, i.e., RNN, RLBL and TA-RLBL, can take the whole sequence into consideration, and user representations can change dynamically along with behavioral sequences. Thus, our RLBL and TA-RLBL can easily deal with the situation when sequences are too long.\n\n\nAnalysis on Computational Time and Convergence\n\nTo investigate the efficiency of our proposed methods, we illustrate the computational time of RNN, RLBL and TA-RLBL in each iteration during training on three datasets in  Table 5. The computation time is measured in seconds. Here, according to previous experimental results, the dimensionality is chosen to be d = 8. And the window width is n = 6, n = 9 and n = 5 on Movielens, GTD and Tmall respectively. Experiments are conducted on a computer with an 8 core 3.0 GHz CPU, 16 GB RAM, and a NVIDIA TITAN X GPU. From results in Table 5, we can observe that all three methods can be trained in an acceptable time. RLBL is a little faster than TA-RLBL, indicating that time-specific transition is a little more time consuming than position-specific transition. Moreover, the computational time of RLBL and TA-RLBL is less than twice of that of conventional RNN. This means that, the significant performance improvement brought by RLBL and TA-RLBL only requires no more than double computational time. Moreover, we illustrate the convergence curves of RLBL and TA-RLBL in Figure 8 and 9 respectively. To illustrate curves measured by different evaluation metrics in one figure, we calculate normalized recall and MAP of RLBL and TA-RLBL on three datasets. We normalize the values of recall and MAP into [0, 1], and illustrate the corresponding convergence curves. From the convergence curves, we can observe that, both RLBL and TA-RLBL can achieve convergence in a relatively small number of iterations. Moreover, recall@1 values achieves convergence faster than recall@5 values, and recall@5 values achieve convergence faster than recall@10 values. This may indicate that, the more items generated in the ranking list, the more iterations are needed during training.\n\n\nCONCLUSIONS AND FUTURE WORK\n\nIn this paper, we have proposed two novel multi-behavioral sequential prediction methods, i.e. recurrent log-bilinear model and time-aware recurrent log-bilinear model. We build our model under a recurrent structure. RLBL models several elements in each hidden layer and incorporate position-specific transition matrices. With such architecture, RLBL can well model both short-and long-term contexts in a historical sequence. Besides, to capture multiple types of behavior in behavioral sequences, behavior-specific matrices are designed and applied for each type of behavior. Then, to incorporate time difference information in behavioral sequences, we further extend the RLBL model and propose a time-aware recurrent log-bilinear model with time-specific transition matrices. Modeling time difference information, TA-RLBL can further improves the performance of RLBL in sequential prediction. The experimental results on three real datasets show that both RLBL and TA-RLBL outperforms state-of-the-art sequential prediction models.\n\nIn the future, we can further investigate the following direction. In RLBL and TA-RLBL, transition matrices are the same for different users, which does not confirm to practical situations. So, we need to find a method to determine different transition matrices for different users or different user groups. Moreover, we didn't take items' features, e.g., categories, descriptions and images of items, into considera-        tion. Thus, incorporating RLBL and TA-RLBL with features of items may also be our next step.\n\n\u2022\nQiang Liu, Shu Wu and Liang Wang are with the Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA) and the University of Chinese Academy of Sciences (UCAS), Beijing, 100000, China. E-mail: {qiang.liu, shu.wu, wangliang}@nlpr.ia.ac.cn.\n\n\nFig. 1. Taking app usage prediction as an example of multi-behavioral sequential prediction. This example shows a user's behaviors towards apps in an hour, including downloading, using and uninstalling. We can predict what app the user is going to download or use next.\n\nFig. 2 .\n2Illustration of the Recurrent Neural Networks (RNN) model. RNN is a recurrent architecture with multiple hidden layers. The hidden status of RNN changes dynamically along with sequences, where the trend is monotonous. RNN has difficulty in modeling short-term contexts in behavioral sequences.\n\nFig. 4 .\n4Illustration of the Recurrent Log-BiLinear (RLBL) model and the Time-Aware Recurrent Log-BiLinear (TA-RLBL) model. RLBL employs a recurrent architecture to capture long-term contexts. It models several elements in each hidden layer and incorporates position-specific transition matrices to capture short-term contexts in a historical sequence. TA-RLBL further extends the RLBL model. It replaces position-specific transition matrices with time-specific transition matrices to model time difference information. Behavior-specific matrices can be incorporated in RLBL and TA-RLBL to capture multiple types of behaviors in sequences.\n\n\ni \u2208 R d\u00d7d denotes the time-specific transition matrix for the time difference t u k \u2212 t u k\u2212i between timestamp t u k\u2212i and t u k . The time-specific transition can capture the timeaware impacts of the most recent behavioral history.\n\n\nd ) and L(t d ) denote the upper bound and lower bound of time difference t d , T U (t d ) and T L(t d ) denote the time-specific transition matrices for U (t d ) and L(t d ) respectively. Such a linear interpolation method can solve the problem of learning time-specific transition matrices for continuous time differences. To be noted, although the change of time-specific matrices in each discrete time bin is linear, the global change in the entire range of all the possible time difference values is nonlinear.\n\nFig. 5 .\n5Performance comparison on the Movielens dataset with varying dimensionality d and window width n = 6.\n\nFig. 6 .\n6Performance comparison on the Global Terrorism Database with varying dimensionality d and window width n = 9.\n\nFig. 7 .\n7Performance comparison on the Tmall dataset with varying dimensionality d and window width n = 5.\n\nFig. 8 .\n8Convergence curves of RLBL measured by normalized recall and MAP.\n\nFig. 9 .\n9Convergence curves of TA-RLBL measured by normalized recall and MAP.\n\nTABLE 1\n1Experimental summarization.dataset \nscenario \n#behavioral types \nbehaviors \nbehavior to predict \n\nMovielens \nwatching movies \n5 \nrating 5, 4, 3, 2, 1 stars \nrating 5 or 4 stars \nGlobal Terrorism Database \nterrorist attack \n7 \narmed, unarmed, assassination, bombing, facility, hijacking, hostage \nattack (all types) \nTmall \ne-commerce \n4 \nclicking, purchasing, adding to favorites, adding to shopping cart \npurchasing \n\n\n\nTABLE 2\n2Comparison of RLBL and TA-RLBL with varying window width n and dimensionality d = 8.(a) Performance on the Movielens dataset.method \nn \nrecall@1 recall@2 recall@5 recall@10 F1-score@1 F1-score@2 F1-score@5 F1-score@10 \nMAP \n\nRLBL \n\n2 \n0.0067 \n0.0103 \n0.0333 \n0.0508 \n0.0067 \n0.0069 \n0.0111 \n0.0093 \n0.0377 \n3 \n0.0070 \n0.0104 \n0.0334 \n0.0510 \n0.0070 \n0.0070 \n0.0111 \n0.0093 \n0.0381 \n4 \n0.0070 \n0.0107 \n0.0338 \n0.0520 \n0.0070 \n0.0072 \n0.0113 \n0.0095 \n0.0385 \n5 \n0.0070 \n0.0108 \n0.0343 \n0.0527 \n0.0070 \n0.0072 \n0.0114 \n0.0096 \n0.0386 \n6 \n0.0071 \n0.0112 \n0.0354 \n0.0538 \n0.0071 \n0.0074 \n0.0118 \n0.0098 \n0.0395 \n7 \n0.0070 \n0.0111 \n0.0354 \n0.0543 \n0.0070 \n0.0074 \n0.0118 \n0.0099 \n0.0393 \n8 \n0.0070 \n0.0108 \n0.0351 \n0.0535 \n0.0070 \n0.0072 \n0.0117 \n0.0097 \n0.0390 \n\nTA-RLBL \n\n2 \n0.0070 \n0.0106 \n0.0343 \n0.0529 \n0.0070 \n0.0071 \n0.0114 \n0.0096 \n0.0388 \n3 \n0.0071 \n0.0105 \n0.0338 \n0.0523 \n0.0071 \n0.0071 \n0.0113 \n0.0094 \n0.0385 \n4 \n0.0071 \n0.0108 \n0.0337 \n0.0522 \n0.0071 \n0.0073 \n0.0113 \n0.0095 \n0.0388 \n5 \n0.0070 \n0.0110 \n0.0366 \n0.0553 \n0.0068 \n0.0074 \n0.0123 \n0.0101 \n0.0396 \n6 \n0.0072 \n0.0115 \n0.0372 \n0.0554 \n0.0072 \n0.0076 \n0.0124 \n0.0101 \n0.0404 \n7 \n0.0070 \n0.0115 \n0.0362 \n0.0549 \n0.0070 \n0.0076 \n0.0121 \n0.0100 \n0.0398 \n8 \n0.0070 \n0.0110 \n0.0348 \n0.0539 \n0.0070 \n0.0073 \n0.0118 \n0.0100 \n0.0392 \n\n(b) Performance on the Global Terrorism Database. \n\nmethod \nn \nrecall@1 recall@2 recall@5 recall@10 F1-score@1 F1-score@2 F1-score@5 F1-score@10 \nMAP \n\nRLBL \n\n2 \n0.1577 \n0.2448 \n0.4378 \n0.6104 \n0.1577 \n0.1632 \n0.1459 \n0.1110 \n0.2930 \n4 \n0.1642 \n0.2691 \n0.4676 \n0.6395 \n0.1642 \n0.1794 \n0.1559 \n0.1163 \n0.3082 \n6 \n0.1624 \n0.2686 \n0.4768 \n0.6468 \n0.1624 \n0.1791 \n0.1589 \n0.1176 \n0.3090 \n9 \n0.1580 \n0.2848 \n0.4865 \n0.6748 \n0.1580 \n0.1899 \n0.1622 \n0.1227 \n0.3153 \n10 \n0.1569 \n0.2806 \n0.4846 \n0.6659 \n0.1569 \n0.1871 \n0.1615 \n0.1211 \n0.3130 \n15 \n0.1567 \n0.2660 \n0.4682 \n0.6470 \n0.1567 \n0.1773 \n0.1561 \n0.1176 \n0.3053 \n20 \n0.1690 \n0.2775 \n0.4872 \n0.6572 \n0.1690 \n0.1850 \n0.1624 \n0.1195 \n0.3165 \n\nTA-RLBL \n\n2 \n0.1642 \n0.2763 \n0.4740 \n0.6451 \n0.1697 \n0.1842 \n0.1580 \n0.1173 \n0.3117 \n4 \n0.1681 \n0.2758 \n0.4719 \n0.6411 \n0.1686 \n0.1839 \n0.1573 \n0.1166 \n0.3187 \n6 \n0.1678 \n0.2758 \n0.4833 \n0.6524 \n0.1678 \n0.1839 \n0.1611 \n0.1186 \n0.3146 \n9 \n0.1634 \n0.2895 \n0.4926 \n0.6730 \n0.1634 \n0.1930 \n0.1642 \n0.1224 \n0.3199 \n10 \n0.1622 \n0.2864 \n0.4910 \n0.6672 \n0.1622 \n0.1909 \n0.1637 \n0.1213 \n0.3180 \n15 \n0.1618 \n0.2731 \n0.4746 \n0.6527 \n0.1618 \n0.1821 \n0.1582 \n0.1187 \n0.3107 \n20 \n0.1697 \n0.2849 \n0.4839 \n0.6629 \n0.1697 \n0.1899 \n0.1613 \n0.1205 \n0.3197 \n\n(c) Performance on the Tmall dataset. \n\nmethod \nn \nrecall@1 recall@2 recall@5 recall@10 F1-score@1 F1-score@2 F1-score@5 F1-score@10 \nMAP \n\nRLBL \n\n2 \n0.1507 \n0.2170 \n0.3712 \n0.4690 \n0.1507 \n0.1447 \n0.1237 \n0.0853 \n0.2704 \n3 \n0.1480 \n0.2515 \n0.4118 \n0.5176 \n0.1480 \n0.1677 \n0.1373 \n0.0941 \n0.2781 \n4 \n0.1467 \n0.2311 \n0.3646 \n0.4953 \n0.1467 \n0.1541 \n0.1215 \n0.0901 \n0.2689 \n5 \n0.1600 \n0.2158 \n0.3975 \n0.5519 \n0.1600 \n0.1439 \n0.1325 \n0.1003 \n0.2836 \n6 \n0.1502 \n0.2272 \n0.3822 \n0.5596 \n0.1502 \n0.1515 \n0.1274 \n0.1017 \n0.2806 \n7 \n0.1493 \n0.2553 \n0.4074 \n0.5272 \n0.1493 \n0.1702 \n0.1358 \n0.0959 \n0.2819 \n8 \n0.1387 \n0.2324 \n0.4019 \n0.5395 \n0.1387 \n0.1549 \n0.1340 \n0.0981 \n0.2770 \n\nTA-RLBL \n\n2 \n0.1351 \n0.2302 \n0.3669 \n0.4493 \n0.1351 \n0.1535 \n0.1223 \n0.0817 \n0.2608 \n3 \n0.1268 \n0.1931 \n0.3497 \n0.4541 \n0.1268 \n0.1287 \n0.1166 \n0.0826 \n0.2579 \n4 \n0.1441 \n0.2450 \n0.4084 \n0.4780 \n0.1441 \n0.1633 \n0.1361 \n0.0869 \n0.2820 \n5 \n0.1413 \n0.2366 \n0.3871 \n0.5461 \n0.1413 \n0.1577 \n0.1290 \n0.0993 \n0.2804 \n6 \n0.1253 \n0.2039 \n0.4081 \n0.4454 \n0.1253 \n0.1359 \n0.1360 \n0.0810 \n0.2521 \n7 \n0.1234 \n0.2213 \n0.3556 \n0.4412 \n0.1234 \n0.1475 \n0.1185 \n0.0802 \n0.2523 \n8 \n0.1198 \n0.2063 \n0.3472 \n0.4247 \n0.1198 \n0.1375 \n0.1157 \n0.0772 \n0.2454 \n\n\n\nTABLE 3\n3Comparison of multiple behaviors and single behavior.(a) Performance on the Movielens dataset with dimensionality d = 8 and window width n = 6.behaviors \nmethod \nrecall@1 recall@5 recall@10 \nMAP \n\nsingle \n\nRNN \n0.0063 \n0.0318 \n0.0484 \n0.0362 \nRLBL \n0.0068 \n0.0343 \n0.0519 \n0.0384 \nTA-RLBL \n0.0068 \n0.0360 \n0.0535 \n0.0392 \n\nmultiple \nRLBL \n0.0071 \n0.0354 \n0.0538 \n0.0395 \nTA-RLBL \n0.0072 \n0.0372 \n0.0554 \n0.0404 \n\n(b) Performance on the Global Terrorism Database with dimensionality \nd = 8 and window width n = 9. \n\nbehaviors \nmethod \nrecall@1 recall@5 recall@10 \nMAP \n\nsingle \n\nRNN \n0.1216 \n0.4168 \n0.5912 \n0.2600 \nRLBL \n0.1254 \n0.4723 \n0.6665 \n0.2853 \nTA-RLBL \n0.1298 \n0.4783 \n0.6648 \n0.2896 \n\nmultiple \nRLBL \n0.1580 \n0.4865 \n0.6748 \n0.3153 \nTA-RLBL \n0.1634 \n0.4926 \n0.6730 \n0.3199 \n\n(c) Performance on the Tmall dataset with dimensionality d = 8 and \nwindow width n = 5. \n\nbehaviors \nmethod \nrecall@1 recall@5 recall@10 \nMAP \n\nsingle \n\nRNN \n0.1283 \n0.3410 \n0.4397 \n0.2432 \nRLBL \n0.1389 \n0.3581 \n0.5277 \n0.2666 \nTA-RLBL \n0.1227 \n0.3824 \n0.5221 \n0.2636 \n\nmultiple \nRLBL \n0.1600 \n0.3822 \n0.5519 \n0.2836 \nTA-RLBL \n0.1413 \n0.4081 \n0.5461 \n0.2804 \n\nsee that, even ignoring multiple types of behaviors, RLBL \nand TA-RLBL can still outperform RNN with a relatively \nsignificant advantage, which indicates the effectiveness of \nposition-specific and time-specific transition. Meanwhile, \ncomparing results of RLBL and TA-RLBL in \n\nTABLE 4\n4Performance comparison with different behavioral history length.(a) Performance on the Movielens dataset with dimensionality d = 8 and window width n = 6. Performance on the Global Terrorism Database with dimensionality d = 8 and window width n = 9.(c) Performance on the Tmall dataset with dimensionality d = 8 and window width n = 5.length \nmethod \nrecall@1 recall@5 recall@10 \nMAP \n\nshort \n\nFPMC \n0.0052 \n0.0250 \n0.0433 \n0.0325 \nHRM \n0.0057 \n0.0283 \n0.0456 \n0.0339 \nRNN \n0.0062 \n0.0313 \n0.0478 \n0.0357 \nRLBL \n0.0070 \n0.0351 \n0.0535 \n0.0391 \nTA-RLBL \n0.0071 \n0.0368 \n0.0550 \n0.0400 \n\nmedium \n\nFPMC \n0.0054 \n0.0257 \n0.0441 \n0.0333 \nHRM \n0.0060 \n0.0290 \n0.0464 \n0.0346 \nRNN \n0.0063 \n0.0317 \n0.0483 \n0.0361 \nRLBL \n0.0072 \n0.0356 \n0.0540 \n0.0397 \nTA-RLBL \n0.0073 \n0.0373 \n0.0556 \n0.0405 \n\nlong \n\nFPMC \n0.0053 \n0.0254 \n0.0438 \n0.0330 \nHRM \n0.0059 \n0.0287 \n0.0460 \n0.0344 \nRNN \n0.0064 \n0.0320 \n0.0487 \n0.0364 \nRLBL \n0.0073 \n0.0359 \n0.0544 \n0.0400 \nTA-RLBL \n0.0074 \n0.0377 \n0.0561 \n0.0409 \n\n(b) length \nmethod \nrecall@1 recall@5 recall@10 \nMAP \n\nshort \n\nFPMC \n0.0935 \n0.3834 \n0.5658 \n0.2341 \nHRM \n0.0966 \n0.3980 \n0.5725 \n0.2410 \nRNN \n0.1180 \n0.4066 \n0.5833 \n0.2544 \nRLBL \n0.1507 \n0.4728 \n0.6639 \n0.3073 \nTA-RLBL \n0.1557 \n0.4770 \n0.6621 \n0.3124 \n\nmedium \n\nFPMC \n0.0981 \n0.4006 \n0.5748 \n0.2422 \nHRM \n0.1029 \n0.4124 \n0.5830 \n0.2503 \nRNN \n0.1216 \n0.4168 \n0.5912 \n0.2600 \nRLBL \n0.1567 \n0.4840 \n0.6734 \n0.3140 \nTA-RLBL \n0.1620 \n0.4906 \n0.6710 \n0.3183 \n\nlong \n\nFPMC \n0.0964 \n0.3944 \n0.5741 \n0.2385 \nHRM \n0.1007 \n0.4068 \n0.5824 \n0.2468 \nRNN \n0.1239 \n0.4233 \n0.5918 \n0.2642 \nRLBL \n0.1599 \n0.4916 \n0.6790 \n0.3178 \nTA-RLBL \n0.1649 \n0.4985 \n0.6766 \n0.3227 \n\nlength \nmethod \nrecall@1 recall@5 recall@10 \nMAP \n\nshort \n\nFPMC \n0.0837 \n0.2330 \n0.3350 \n0.1807 \nHRM \n0.0934 \n0.2588 \n0.3668 \n0.1990 \nRNN \n0.1251 \n0.3363 \n0.4350 \n0.2401 \nRLBL \n0.1566 \n0.3786 \n0.5494 \n0.2811 \nTA-RLBL \n0.1381 \n0.4041 \n0.5432 \n0.2780 \n\nmedium \n\nFPMC \n0.0872 \n0.2393 \n0.3412 \n0.1848 \nHRM \n0.0971 \n0.2653 \n0.3734 \n0.2032 \nRNN \n0.1282 \n0.3410 \n0.4396 \n0.2432 \nRLBL \n0.1608 \n0.3841 \n0.5547 \n0.2850 \nTA-RLBL \n0.1420 \n0.4102 \n0.5491 \n0.2818 \n\nlong \n\nFPMC \n0.0859 \n0.2369 \n0.3387 \n0.1831 \nHRM \n0.0957 \n0.2627 \n0.3703 \n0.2016 \nRNN \n0.1303 \n0.3445 \n0.4433 \n0.2447 \nRLBL \n0.1633 \n0.3879 \n0.5588 \n0.2876 \nTA-RLBL \n0.1439 \n0.4143 \n0.5532 \n0.2842 \n\n\n\nTABLE 5\n5The computational time of RNN, RLBL and TA-RLBL in each iteration during training on three datasets.method \nMovielens GTD Tmall \n\nRNN \n902s \n115s \n335s \nRLBL \n1628s \n196s \n638s \nTA-RLBL \n1664s \n210s \n668s \n\n\n\nFast multivariate spatiotemporal analysis via low rank tensor learning. M T Bahadori, Q R Yu, Y Liu, NIPS. M. T. Bahadori, Q. R. Yu, and Y. Liu. Fast multivariate spatio- temporal analysis via low rank tensor learning. In NIPS, pages 3491-3499, 2014.\n\nA neural probabilistic language model. Y Bengio, R Ducharme, P Vincent, C Janvin, JMLR. 3Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. A neural probabilistic language model. JMLR, 3:1137-1155, 2003.\n\nTime-aware recommender systems: a comprehensive survey and analysis of existing evaluation protocols. P G Campos, F D\u00edez, I Cantador, User Modeling and User-Adapted Interaction. 241-2P. G. Campos, F. D\u00edez, and I. Cantador. Time-aware recommender systems: a comprehensive survey and analysis of existing evalu- ation protocols. User Modeling and User-Adapted Interaction, 24(1- 2):67-119, 2014.\n\nA personalized interest-forgetting markov model for recommendations. J Chen, C Wang, J Wang, AAAI. J. Chen, C. Wang, and J. Wang. A personalized interest-forgetting markov model for recommendations. In AAAI, pages 16-22, 2015.\n\nWhere you like to go next: Successive point-of-interest recommendation. C Cheng, H Yang, M R Lyu, I King, IJCAI. C. Cheng, H. Yang, M. R. Lyu, and I. King. Where you like to go next: Successive point-of-interest recommendation. In IJCAI, pages 2605-2611, 2013.\n\nLearning phrase representations using rnn encoder-decoder for statistical machine translation. K Cho, B Van Merri\u00ebnboer, C Gulcehre, D Bahdanau, F Bougares, H Schwenk, Y Bengio, EMNLP. K. Cho, B. Van Merri\u00ebnboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase rep- resentations using rnn encoder-decoder for statistical machine translation. EMNLP, pages 1724-1734, 2014.\n\nTime weight collaborative filtering. Y Ding, X Li, CIKM. Y. Ding and X. Li. Time weight collaborative filtering. In CIKM, pages 485-492, 2005.\n\nHierarchical recurrent neural network for skeleton based action recognition. Y Du, W Wang, L Wang, CVPR. Y. Du, W. Wang, and L. Wang. Hierarchical recurrent neural network for skeleton based action recognition. In CVPR, pages 1110-1118, 2015.\n\nHierarchical recurrent neural networks for long-term dependencies. S El Hihi, Y Bengio, NIPS. S. El Hihi and Y. Bengio. Hierarchical recurrent neural networks for long-term dependencies. In NIPS, pages 493-499, 1995.\n\nPersonalized ranking metric embedding for next new poi recommendation. S Feng, X Li, Y Zeng, G Cong, Y M Chee, Q Yuan, IJCAI. S. Feng, X. Li, Y. Zeng, G. Cong, Y. M. Chee, and Q. Yuan. Personal- ized ranking metric embedding for next new poi recommendation. In IJCAI, pages 2069-2075, 2015.\n\nJust in time recommendations: Modeling the dynamics of boredom in activity streams. K Kapoor, K Subbian, J Srivastava, P Schrater, WSDM. K. Kapoor, K. Subbian, J. Srivastava, and P. Schrater. Just in time recommendations: Modeling the dynamics of boredom in activity streams. In WSDM, pages 233-242, 2015.\n\nA multiplicative model for learning distributed text-based attribute representations. R Kiros, R Zemel, R R Salakhutdinov, NIPS. R. Kiros, R. Zemel, and R. R. Salakhutdinov. A multiplicative model for learning distributed text-based attribute representa- tions. In NIPS, pages 2348-2356, 2014.\n\nCollaborative filtering with temporal dynamics. Y Koren, Communications of the ACM. 534Y. Koren. Collaborative filtering with temporal dynamics. Com- munications of the ACM, 53(4):89-97, 2010.\n\nAdvances in collaborative filtering. Y Koren, R Bell, Recommender Systems Handbook. Y. Koren and R. Bell. Advances in collaborative filtering. In Recommender Systems Handbook, pages 145-186. 2011.\n\nMatrix factorization techniques for recommender systems. Y Koren, R Bell, C Volinsky, IEEE Computer. 428Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. IEEE Computer, 42(8):30-37, 2009.\n\nA clockwork rnn. J Koutnik, K Greff, F Gomez, J Schmidhuber, J. Koutnik, K. Greff, F. Gomez, and J. Schmidhuber. A clockwork rnn. pages 1863-1871, 2014.\n\nTemporal collaborative filtering with adaptive neighbourhoods. N Lathia, S Hailes, L Capra, SIGIR. N. Lathia, S. Hailes, and L. Capra. Temporal collaborative filtering with adaptive neighbourhoods. In SIGIR, pages 796-797, 2009.\n\nOnline evolutionary collaborative filtering. N N Liu, M Zhao, E Xiang, Q Yang, RecSys. N. N. Liu, M. Zhao, E. Xiang, and Q. Yang. Online evolutionary collaborative filtering. In RecSys, pages 95-102, 2010.\n\nMulti-timescale long short-term memory neural network for modelling sentences and documents. P Liu, X Qiu, X Chen, S Wu, X Huang, EMNLP. P. Liu, X. Qiu, X. Chen, S. Wu, and X. Huang. Multi-timescale long short-term memory neural network for modelling sentences and documents. In EMNLP, pages 2326-2335, 2015.\n\nContext-aware sequential recommendation. Q Liu, S Wu, D Wang, Z Li, L Wang, ICDM. Q. Liu, S. Wu, D. Wang, Z. Li, and L. Wang. Context-aware sequential recommendation. In ICDM, pages 1053-1058, 2016.\n\nPredicting the next location: A recurrent model with spatial and temporal contexts. Q Liu, S Wu, L Wang, T Tan, AAAI. Q. Liu, S. Wu, L. Wang, and T. Tan. Predicting the next location: A recurrent model with spatial and temporal contexts. In AAAI, pages 194-200, 2016.\n\nJ Mao, W Xu, Y Yang, J Wang, Z Huang, A Yuille, Deep captioning with multimodal recurrent neural networks. m-rnnJ. Mao, W. Xu, Y. Yang, J. Wang, Z. Huang, and A. Yuille. Deep captioning with multimodal recurrent neural networks (m-rnn).\n\nRecurrent neural network based language model. T Mikolov, M Karafi\u00e1t, L Burget, J Cernock\u1ef3, S Khudanpur, INTER-SPEECH. 23T. Mikolov, M. Karafi\u00e1t, L. Burget, J. Cernock\u1ef3, and S. Khudanpur. Recurrent neural network based language model. In INTER- SPEECH, volume 2, page 3, 2010.\n\nExtensions of recurrent neural network language model. T Mikolov, S Kombrink, L Burget, J H Cernocky, S Khudanpur, ICASSP. T. Mikolov, S. Kombrink, L. Burget, J. H. Cernocky, and S. Khu- danpur. Extensions of recurrent neural network language model. In ICASSP, pages 5528-5531, 2011.\n\nRnnlm-recurrent neural network language modeling toolkit. T Mikolov, S Kombrink, A Deoras, L Burget, J Cernocky, ASRU Workshop. T. Mikolov, S. Kombrink, A. Deoras, L. Burget, and J. Cernocky. Rnnlm-recurrent neural network language modeling toolkit. In ASRU Workshop, pages 196-201, 2011.\n\nDistributed representations of words and phrases and their compositionality. T Mikolov, I Sutskever, K Chen, G S Corrado, J Dean, NIPS. T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their com- positionality. In NIPS, pages 3111-3119, 2013.\n\nThree new graphical models for statistical language modelling. A Mnih, G Hinton, ICML. A. Mnih and G. Hinton. Three new graphical models for statistical language modelling. In ICML, pages 641-648, 2007.\n\nA scalable hierarchical distributed language model. A Mnih, G E Hinton, NIPS. A. Mnih and G. E. Hinton. A scalable hierarchical distributed language model. In NIPS, pages 1081-1088, 2009.\n\nProbabilistic matrix factorization. A Mnih, R Salakhutdinov, NIPS. A. Mnih and R. Salakhutdinov. Probabilistic matrix factorization. In NIPS, pages 1257-1264, 2007.\n\nWhich app will you use next?: Collaborative filtering with interactional context. N Natarajan, D Shin, I S Dhillon, RecSys. N. Natarajan, D. Shin, and I. S. Dhillon. Which app will you use next?: Collaborative filtering with interactional context. In RecSys, pages 201-208, 2013.\n\nFactorization machines with libfm. S Rendle, ACM Transactions on Intelligent Systems and Technology. 3357S. Rendle. Factorization machines with libfm. ACM Transactions on Intelligent Systems and Technology, 3(3):57, 2012.\n\nBpr: Bayesian personalized ranking from implicit feedback. S Rendle, C Freudenthaler, Z Gantner, L Schmidt-Thieme, UAI. S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme. Bpr: Bayesian personalized ranking from implicit feedback. In UAI, pages 452-461, 2009.\n\nFactorizing personalized markov chains for next-basket recommendation. S Rendle, C Freudenthaler, L Schmidt-Thieme, WWW. S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. Factorizing personalized markov chains for next-basket recommendation. In WWW, pages 811-820, 2010.\n\nFast context-aware recommendations with factorization machines. S Rendle, Z Gantner, C Freudenthaler, L Schmidt-Thieme, SIGIR. S. Rendle, Z. Gantner, C. Freudenthaler, and L. Schmidt-Thieme. Fast context-aware recommendations with factorization machines. In SIGIR, pages 635-644, 2011.\n\nLearning representations by back-propagating errors. D E Rumelhart, G E Hinton, R J Williams, Cognitive Modeling. 53D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning representations by back-propagating errors. Cognitive Modeling, 5:3, 1988.\n\nBuilding end-to-end dialogue systems using generative hierarchical neural network models. I V Serban, A Sordoni, Y Bengio, A Courville, J Pineau, AAAI. I. V. Serban, A. Sordoni, Y. Bengio, A. Courville, and J. Pineau. Building end-to-end dialogue systems using generative hierarchi- cal neural network models. In AAAI, pages 3776-3784, 2016.\n\nNeural responding machine for shorttext conversation. L Shang, Z Lu, H Li, ACL. L. Shang, Z. Lu, and H. Li. Neural responding machine for short- text conversation. ACL, pages 1577-1586, 2015.\n\nSequence to sequence learning with neural networks. I Sutskever, O Vinyals, Q V Le, NIPS. I. Sutskever, O. Vinyals, and Q. V. Le. Sequence to sequence learning with neural networks. In NIPS, pages 3104-3112, 2014.\n\nShow and tell: A neural image caption generator. O Vinyals, A Toshev, S Bengio, D Erhan, CVPR. O. Vinyals, A. Toshev, S. Bengio, and D. Erhan. Show and tell: A neural image caption generator. In CVPR, pages 3156-3164, 2015.\n\nLearning hierarchical representation model for next basket recommendation. P Wang, J Guo, Y Lan, J Xu, S Wan, X Cheng, SIGIR. P. Wang, J. Guo, Y. Lan, J. Xu, S. Wan, and X. Cheng. Learning hi- erarchical representation model for next basket recommendation. In SIGIR, pages 403-412, 2015.\n\nSape: A system for situation-aware public security evaluation. S Wu, Q Liu, P Bai, L Wang, T Tan, AAAI. S. Wu, Q. Liu, P. Bai, L. Wang, and T. Tan. Sape: A system for situation-aware public security evaluation. In AAAI, pages 4401- 4402, 2016.\n\nCarbonell. Temporal collaborative filtering with bayesian probabilistic tensor factorization. L Xiong, X Chen, T.-K Huang, J G Schneider, J , SDM. L. Xiong, X. Chen, T.-K. Huang, J. G. Schneider, and J. G. Car- bonell. Temporal collaborative filtering with bayesian probabilistic tensor factorization. In SDM, pages 211-222, 2010.\n\nEmergence of functional hierarchy in a multiple timescale neural network model: a humanoid robot experiment. Y Yamashita, J Tani, PLoS Computational Biology. 411Y. Yamashita and J. Tani. Emergence of functional hierarchy in a multiple timescale neural network model: a humanoid robot experiment. PLoS Computational Biology, 4(11):1-18, 2008.\n\nPersonalizing web page recommendation via collaborative filtering and topic-aware markov model. Q Yang, J Fan, J Wang, L Zhou, ICDM. Q. Yang, J. Fan, J. Wang, and L. Zhou. Personalizing web page rec- ommendation via collaborative filtering and topic-aware markov model. In ICDM, pages 1145-1150, 2010.\n\nA dynamic recurrent basket recommendation model. F Yu, Q Liu, S Wu, L Wang, T Tan, SIGIR. F. Yu, Q. Liu, S. Wu, L. Wang, and T. Tan. A dynamic recurrent basket recommendation model. In SIGIR, pages 729-732, 2016.\n\nSequential click prediction for sponsored search with recurrent neural networks. Y Zhang, H Dai, C Xu, J Feng, T Wang, J Bian, B Wang, T.-Y Liu, In AAAI. Y. Zhang, H. Dai, C. Xu, J. Feng, T. Wang, J. Bian, B. Wang, and T.-Y. Liu. Sequential click prediction for sponsored search with recurrent neural networks. In AAAI, pages 1369-1376, 2014.\n\nImproving user topic interest profiles by behavior factorization. Z Zhao, Z Cheng, L Hong, E H Chi, WWW. Z. Zhao, Z. Cheng, L. Hong, and E. H. Chi. Improving user topic interest profiles by behavior factorization. In WWW, pages 1406- 1416, 2015.\n\nForecasting fine-grained air quality based on big data. Y Zheng, X Yi, M Li, R Li, Z Shan, E Chang, T Li, SIGKDD. Y. Zheng, X. Yi, M. Li, R. Li, Z. Shan, E. Chang, and T. Li. Forecasting fine-grained air quality based on big data. In SIGKDD, pages 2267-2276, 2015.\n", "annotations": {"author": "[{\"end\":116,\"start\":89},{\"end\":123,\"start\":117}]", "publisher": null, "author_last_name": "[{\"end\":115,\"start\":89},{\"end\":122,\"start\":117}]", "author_first_name": null, "author_affiliation": null, "title": "[{\"end\":73,\"start\":1},{\"end\":196,\"start\":124}]", "venue": null, "abstract": "[{\"end\":1981,\"start\":308}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2041,\"start\":2037},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3091,\"start\":3087},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3277,\"start\":3273},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":3282,\"start\":3278},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":3313,\"start\":3309},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3410,\"start\":3407},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3420,\"start\":3416},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3430,\"start\":3426},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":4294,\"start\":4290},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":4304,\"start\":4300},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":4742,\"start\":4738},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":4912,\"start\":4908},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4922,\"start\":4918},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4942,\"start\":4939},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":4976,\"start\":4972},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5005,\"start\":5001},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7148,\"start\":7144},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7158,\"start\":7154},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7193,\"start\":7189},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11295,\"start\":11292},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11305,\"start\":11301},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11826,\"start\":11822},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11836,\"start\":11832},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":11997,\"start\":11993},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12002,\"start\":11998},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":12114,\"start\":12111},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":12119,\"start\":12115},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12300,\"start\":12296},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":12782,\"start\":12778},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":13064,\"start\":13060},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":13171,\"start\":13167},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13216,\"start\":13213},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13334,\"start\":13331},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13363,\"start\":13359},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":13665,\"start\":13661},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13875,\"start\":13871},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14380,\"start\":14376},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":14511,\"start\":14508},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14607,\"start\":14603},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14617,\"start\":14613},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":14724,\"start\":14721},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":14756,\"start\":14752},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":14761,\"start\":14757},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":14784,\"start\":14780},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":14789,\"start\":14785},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":14943,\"start\":14940},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":15091,\"start\":15087},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15148,\"start\":15144},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":15296,\"start\":15292},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":15456,\"start\":15452},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":15510,\"start\":15506},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16368,\"start\":16364},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16520,\"start\":16516},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":16928,\"start\":16924},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":16933,\"start\":16929},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":16956,\"start\":16952},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16999,\"start\":16996},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":17577,\"start\":17573},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":17587,\"start\":17583},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":19989,\"start\":19985},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20652,\"start\":20648},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":20767,\"start\":20763},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":28272,\"start\":28268},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":28318,\"start\":28314},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":28348,\"start\":28344},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":28538,\"start\":28534},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":28543,\"start\":28539},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":29973,\"start\":29969},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":30041,\"start\":30037},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":30046,\"start\":30042},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":30713,\"start\":30709},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":31572,\"start\":31568},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":35100,\"start\":35096},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":35592,\"start\":35588},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":35759,\"start\":35755},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":35958,\"start\":35954},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":36138,\"start\":36134},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":45146,\"start\":45142},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":46149,\"start\":46145}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":50723,\"start\":50357},{\"attributes\":{\"id\":\"fig_1\"},\"end\":50995,\"start\":50724},{\"attributes\":{\"id\":\"fig_3\"},\"end\":51300,\"start\":50996},{\"attributes\":{\"id\":\"fig_6\"},\"end\":51942,\"start\":51301},{\"attributes\":{\"id\":\"fig_7\"},\"end\":52178,\"start\":51943},{\"attributes\":{\"id\":\"fig_8\"},\"end\":52696,\"start\":52179},{\"attributes\":{\"id\":\"fig_9\"},\"end\":52809,\"start\":52697},{\"attributes\":{\"id\":\"fig_10\"},\"end\":52930,\"start\":52810},{\"attributes\":{\"id\":\"fig_11\"},\"end\":53039,\"start\":52931},{\"attributes\":{\"id\":\"fig_15\"},\"end\":53116,\"start\":53040},{\"attributes\":{\"id\":\"fig_19\"},\"end\":53196,\"start\":53117},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":53626,\"start\":53197},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":57367,\"start\":53627},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":58800,\"start\":57368},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":61103,\"start\":58801},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":61321,\"start\":61104}]", "paragraph": "[{\"end\":4159,\"start\":1997},{\"end\":4743,\"start\":4161},{\"end\":7071,\"start\":4745},{\"end\":7971,\"start\":7073},{\"end\":9666,\"start\":7973},{\"end\":9726,\"start\":9668},{\"end\":9955,\"start\":9728},{\"end\":10124,\"start\":9961},{\"end\":10301,\"start\":10126},{\"end\":10445,\"start\":10303},{\"end\":10972,\"start\":10447},{\"end\":11233,\"start\":10990},{\"end\":11745,\"start\":11261},{\"end\":12643,\"start\":11782},{\"end\":13364,\"start\":12674},{\"end\":14282,\"start\":13366},{\"end\":16358,\"start\":14315},{\"end\":16783,\"start\":16360},{\"end\":17873,\"start\":16785},{\"end\":18315,\"start\":17896},{\"end\":18594,\"start\":18410},{\"end\":18937,\"start\":18596},{\"end\":19510,\"start\":18939},{\"end\":19805,\"start\":19550},{\"end\":20050,\"start\":19835},{\"end\":20596,\"start\":20086},{\"end\":21050,\"start\":20619},{\"end\":21234,\"start\":21086},{\"end\":21510,\"start\":21272},{\"end\":21922,\"start\":21512},{\"end\":22709,\"start\":21969},{\"end\":23104,\"start\":22754},{\"end\":23640,\"start\":23145},{\"end\":24046,\"start\":23642},{\"end\":24657,\"start\":24103},{\"end\":24901,\"start\":24723},{\"end\":25968,\"start\":24937},{\"end\":26316,\"start\":25987},{\"end\":26565,\"start\":26376},{\"end\":26790,\"start\":26623},{\"end\":27000,\"start\":26860},{\"end\":27580,\"start\":27231},{\"end\":28114,\"start\":27682},{\"end\":28319,\"start\":28137},{\"end\":28692,\"start\":28340},{\"end\":28841,\"start\":28752},{\"end\":28971,\"start\":28866},{\"end\":29244,\"start\":29036},{\"end\":30228,\"start\":29747},{\"end\":30650,\"start\":30470},{\"end\":30799,\"start\":30674},{\"end\":31031,\"start\":30864},{\"end\":31758,\"start\":31534},{\"end\":32183,\"start\":32039},{\"end\":32876,\"start\":32199},{\"end\":33052,\"start\":32902},{\"end\":33527,\"start\":33054},{\"end\":34005,\"start\":33529},{\"end\":34535,\"start\":34007},{\"end\":34913,\"start\":34537},{\"end\":35006,\"start\":34915},{\"end\":35089,\"start\":35008},{\"end\":35470,\"start\":35091},{\"end\":35581,\"start\":35472},{\"end\":35746,\"start\":35583},{\"end\":35946,\"start\":35748},{\"end\":36126,\"start\":35948},{\"end\":36350,\"start\":36128},{\"end\":36765,\"start\":36352},{\"end\":37020,\"start\":36767},{\"end\":37178,\"start\":37022},{\"end\":37504,\"start\":37180},{\"end\":37814,\"start\":37541},{\"end\":40947,\"start\":37835},{\"end\":41734,\"start\":40990},{\"end\":42589,\"start\":41736},{\"end\":45056,\"start\":42639},{\"end\":45589,\"start\":45115},{\"end\":46956,\"start\":45591},{\"end\":48772,\"start\":47007},{\"end\":49837,\"start\":48804},{\"end\":50356,\"start\":49839}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":18409,\"start\":18316},{\"attributes\":{\"id\":\"formula_1\"},\"end\":20085,\"start\":20051},{\"attributes\":{\"id\":\"formula_2\"},\"end\":21085,\"start\":21051},{\"attributes\":{\"id\":\"formula_3\"},\"end\":21968,\"start\":21923},{\"attributes\":{\"id\":\"formula_4\"},\"end\":22753,\"start\":22710},{\"attributes\":{\"id\":\"formula_5\"},\"end\":24102,\"start\":24047},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24722,\"start\":24658},{\"attributes\":{\"id\":\"formula_7\"},\"end\":26375,\"start\":26317},{\"attributes\":{\"id\":\"formula_8\"},\"end\":26622,\"start\":26566},{\"attributes\":{\"id\":\"formula_9\"},\"end\":26859,\"start\":26791},{\"attributes\":{\"id\":\"formula_10\"},\"end\":27066,\"start\":27001},{\"attributes\":{\"id\":\"formula_11\"},\"end\":27230,\"start\":27122},{\"attributes\":{\"id\":\"formula_12\"},\"end\":27681,\"start\":27581},{\"attributes\":{\"id\":\"formula_13\"},\"end\":28751,\"start\":28693},{\"attributes\":{\"id\":\"formula_14\"},\"end\":28865,\"start\":28842},{\"attributes\":{\"id\":\"formula_15\"},\"end\":29035,\"start\":28972},{\"attributes\":{\"id\":\"formula_16\"},\"end\":29746,\"start\":29245},{\"attributes\":{\"id\":\"formula_17\"},\"end\":30469,\"start\":30229},{\"attributes\":{\"id\":\"formula_18\"},\"end\":30863,\"start\":30800},{\"attributes\":{\"id\":\"formula_19\"},\"end\":31533,\"start\":31032},{\"attributes\":{\"id\":\"formula_20\"},\"end\":32038,\"start\":31759}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":32299,\"start\":32292},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":33051,\"start\":33044},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":33808,\"start\":33801},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":38109,\"start\":38102},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":39931,\"start\":39924},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":41889,\"start\":41882},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":42340,\"start\":42333},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":42371,\"start\":42364},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":45755,\"start\":45748},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":47187,\"start\":47180},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":47543,\"start\":47536}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1995,\"start\":1983},{\"end\":9959,\"start\":9958},{\"attributes\":{\"n\":\"2\"},\"end\":10988,\"start\":10975},{\"attributes\":{\"n\":\"2.1\"},\"end\":11259,\"start\":11236},{\"attributes\":{\"n\":\"2.2\"},\"end\":11780,\"start\":11748},{\"attributes\":{\"n\":\"2.3\"},\"end\":12672,\"start\":12646},{\"attributes\":{\"n\":\"2.4\"},\"end\":14313,\"start\":14285},{\"attributes\":{\"n\":\"3\"},\"end\":17894,\"start\":17876},{\"attributes\":{\"n\":\"4\"},\"end\":19548,\"start\":19513},{\"attributes\":{\"n\":\"4.1\"},\"end\":19833,\"start\":19808},{\"attributes\":{\"n\":\"4.2\"},\"end\":20617,\"start\":20599},{\"attributes\":{\"n\":\"4.3\"},\"end\":21270,\"start\":21237},{\"attributes\":{\"n\":\"4.4\"},\"end\":23143,\"start\":23107},{\"attributes\":{\"n\":\"5\"},\"end\":24935,\"start\":24904},{\"attributes\":{\"n\":\"5.1\"},\"end\":25985,\"start\":25971},{\"attributes\":{\"n\":\"5.2\"},\"end\":27121,\"start\":27068},{\"attributes\":{\"n\":\"6\"},\"end\":28135,\"start\":28117},{\"attributes\":{\"n\":\"6.1\"},\"end\":28338,\"start\":28322},{\"attributes\":{\"n\":\"6.2\"},\"end\":30672,\"start\":30653},{\"attributes\":{\"n\":\"7\"},\"end\":32197,\"start\":32186},{\"attributes\":{\"n\":\"7.1\"},\"end\":32900,\"start\":32879},{\"end\":37508,\"start\":37507},{\"end\":37539,\"start\":37511},{\"attributes\":{\"n\":\"7.2\"},\"end\":37833,\"start\":37817},{\"attributes\":{\"n\":\"7.3\"},\"end\":40988,\"start\":40950},{\"attributes\":{\"n\":\"7.4\"},\"end\":42637,\"start\":42592},{\"attributes\":{\"n\":\"7.5\"},\"end\":45113,\"start\":45059},{\"attributes\":{\"n\":\"7.6\"},\"end\":47005,\"start\":46959},{\"attributes\":{\"n\":\"8\"},\"end\":48802,\"start\":48775},{\"end\":50359,\"start\":50358},{\"end\":51005,\"start\":50997},{\"end\":51310,\"start\":51302},{\"end\":52706,\"start\":52698},{\"end\":52819,\"start\":52811},{\"end\":52940,\"start\":52932},{\"end\":53049,\"start\":53041},{\"end\":53126,\"start\":53118},{\"end\":53205,\"start\":53198},{\"end\":53635,\"start\":53628},{\"end\":57376,\"start\":57369},{\"end\":58809,\"start\":58802},{\"end\":61112,\"start\":61105}]", "table": "[{\"end\":53626,\"start\":53234},{\"end\":57367,\"start\":53762},{\"end\":58800,\"start\":57521},{\"end\":61103,\"start\":59146},{\"end\":61321,\"start\":61214}]", "figure_caption": "[{\"end\":50723,\"start\":50360},{\"end\":50995,\"start\":50726},{\"end\":51300,\"start\":51007},{\"end\":51942,\"start\":51312},{\"end\":52178,\"start\":51945},{\"end\":52696,\"start\":52181},{\"end\":52809,\"start\":52708},{\"end\":52930,\"start\":52821},{\"end\":53039,\"start\":52942},{\"end\":53116,\"start\":53051},{\"end\":53196,\"start\":53128},{\"end\":53234,\"start\":53207},{\"end\":53762,\"start\":53637},{\"end\":57521,\"start\":57378},{\"end\":59146,\"start\":58811},{\"end\":61214,\"start\":61114}]", "figure_ref": "[{\"end\":3852,\"start\":3844},{\"end\":7729,\"start\":7721},{\"end\":18606,\"start\":18600},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19879,\"start\":19871},{\"end\":20971,\"start\":20963},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":21812,\"start\":21804},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":26245,\"start\":26237},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":42886,\"start\":42878},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":44316,\"start\":44308},{\"attributes\":{\"ref_id\":\"fig_15\"},\"end\":48085,\"start\":48077}]", "bib_author_first_name": "[{\"end\":61396,\"start\":61395},{\"end\":61398,\"start\":61397},{\"end\":61410,\"start\":61409},{\"end\":61412,\"start\":61411},{\"end\":61418,\"start\":61417},{\"end\":61615,\"start\":61614},{\"end\":61625,\"start\":61624},{\"end\":61637,\"start\":61636},{\"end\":61648,\"start\":61647},{\"end\":61883,\"start\":61882},{\"end\":61885,\"start\":61884},{\"end\":61895,\"start\":61894},{\"end\":61903,\"start\":61902},{\"end\":62245,\"start\":62244},{\"end\":62253,\"start\":62252},{\"end\":62261,\"start\":62260},{\"end\":62476,\"start\":62475},{\"end\":62485,\"start\":62484},{\"end\":62493,\"start\":62492},{\"end\":62495,\"start\":62494},{\"end\":62502,\"start\":62501},{\"end\":62761,\"start\":62760},{\"end\":62768,\"start\":62767},{\"end\":62787,\"start\":62786},{\"end\":62799,\"start\":62798},{\"end\":62811,\"start\":62810},{\"end\":62823,\"start\":62822},{\"end\":62834,\"start\":62833},{\"end\":63110,\"start\":63109},{\"end\":63118,\"start\":63117},{\"end\":63294,\"start\":63293},{\"end\":63300,\"start\":63299},{\"end\":63308,\"start\":63307},{\"end\":63528,\"start\":63527},{\"end\":63531,\"start\":63529},{\"end\":63539,\"start\":63538},{\"end\":63750,\"start\":63749},{\"end\":63758,\"start\":63757},{\"end\":63764,\"start\":63763},{\"end\":63772,\"start\":63771},{\"end\":63780,\"start\":63779},{\"end\":63782,\"start\":63781},{\"end\":63790,\"start\":63789},{\"end\":64055,\"start\":64054},{\"end\":64065,\"start\":64064},{\"end\":64076,\"start\":64075},{\"end\":64090,\"start\":64089},{\"end\":64364,\"start\":64363},{\"end\":64373,\"start\":64372},{\"end\":64382,\"start\":64381},{\"end\":64384,\"start\":64383},{\"end\":64621,\"start\":64620},{\"end\":64804,\"start\":64803},{\"end\":64813,\"start\":64812},{\"end\":65022,\"start\":65021},{\"end\":65031,\"start\":65030},{\"end\":65039,\"start\":65038},{\"end\":65214,\"start\":65213},{\"end\":65225,\"start\":65224},{\"end\":65234,\"start\":65233},{\"end\":65243,\"start\":65242},{\"end\":65414,\"start\":65413},{\"end\":65424,\"start\":65423},{\"end\":65434,\"start\":65433},{\"end\":65626,\"start\":65625},{\"end\":65628,\"start\":65627},{\"end\":65635,\"start\":65634},{\"end\":65643,\"start\":65642},{\"end\":65652,\"start\":65651},{\"end\":65881,\"start\":65880},{\"end\":65888,\"start\":65887},{\"end\":65895,\"start\":65894},{\"end\":65903,\"start\":65902},{\"end\":65909,\"start\":65908},{\"end\":66139,\"start\":66138},{\"end\":66146,\"start\":66145},{\"end\":66152,\"start\":66151},{\"end\":66160,\"start\":66159},{\"end\":66166,\"start\":66165},{\"end\":66382,\"start\":66381},{\"end\":66389,\"start\":66388},{\"end\":66395,\"start\":66394},{\"end\":66403,\"start\":66402},{\"end\":66567,\"start\":66566},{\"end\":66574,\"start\":66573},{\"end\":66580,\"start\":66579},{\"end\":66588,\"start\":66587},{\"end\":66596,\"start\":66595},{\"end\":66605,\"start\":66604},{\"end\":66852,\"start\":66851},{\"end\":66863,\"start\":66862},{\"end\":66875,\"start\":66874},{\"end\":66885,\"start\":66884},{\"end\":66897,\"start\":66896},{\"end\":67138,\"start\":67137},{\"end\":67149,\"start\":67148},{\"end\":67161,\"start\":67160},{\"end\":67171,\"start\":67170},{\"end\":67173,\"start\":67172},{\"end\":67185,\"start\":67184},{\"end\":67426,\"start\":67425},{\"end\":67437,\"start\":67436},{\"end\":67449,\"start\":67448},{\"end\":67459,\"start\":67458},{\"end\":67469,\"start\":67468},{\"end\":67735,\"start\":67734},{\"end\":67746,\"start\":67745},{\"end\":67759,\"start\":67758},{\"end\":67767,\"start\":67766},{\"end\":67769,\"start\":67768},{\"end\":67780,\"start\":67779},{\"end\":68032,\"start\":68031},{\"end\":68040,\"start\":68039},{\"end\":68225,\"start\":68224},{\"end\":68233,\"start\":68232},{\"end\":68235,\"start\":68234},{\"end\":68398,\"start\":68397},{\"end\":68406,\"start\":68405},{\"end\":68610,\"start\":68609},{\"end\":68623,\"start\":68622},{\"end\":68631,\"start\":68630},{\"end\":68633,\"start\":68632},{\"end\":68844,\"start\":68843},{\"end\":69091,\"start\":69090},{\"end\":69101,\"start\":69100},{\"end\":69118,\"start\":69117},{\"end\":69129,\"start\":69128},{\"end\":69376,\"start\":69375},{\"end\":69386,\"start\":69385},{\"end\":69403,\"start\":69402},{\"end\":69643,\"start\":69642},{\"end\":69653,\"start\":69652},{\"end\":69664,\"start\":69663},{\"end\":69681,\"start\":69680},{\"end\":69919,\"start\":69918},{\"end\":69921,\"start\":69920},{\"end\":69934,\"start\":69933},{\"end\":69936,\"start\":69935},{\"end\":69946,\"start\":69945},{\"end\":69948,\"start\":69947},{\"end\":70208,\"start\":70207},{\"end\":70210,\"start\":70209},{\"end\":70220,\"start\":70219},{\"end\":70231,\"start\":70230},{\"end\":70241,\"start\":70240},{\"end\":70254,\"start\":70253},{\"end\":70515,\"start\":70514},{\"end\":70524,\"start\":70523},{\"end\":70530,\"start\":70529},{\"end\":70706,\"start\":70705},{\"end\":70719,\"start\":70718},{\"end\":70730,\"start\":70729},{\"end\":70732,\"start\":70731},{\"end\":70918,\"start\":70917},{\"end\":70929,\"start\":70928},{\"end\":70939,\"start\":70938},{\"end\":70949,\"start\":70948},{\"end\":71169,\"start\":71168},{\"end\":71177,\"start\":71176},{\"end\":71184,\"start\":71183},{\"end\":71191,\"start\":71190},{\"end\":71197,\"start\":71196},{\"end\":71204,\"start\":71203},{\"end\":71446,\"start\":71445},{\"end\":71452,\"start\":71451},{\"end\":71459,\"start\":71458},{\"end\":71466,\"start\":71465},{\"end\":71474,\"start\":71473},{\"end\":71722,\"start\":71721},{\"end\":71731,\"start\":71730},{\"end\":71742,\"start\":71738},{\"end\":71751,\"start\":71750},{\"end\":71753,\"start\":71752},{\"end\":71766,\"start\":71765},{\"end\":72069,\"start\":72068},{\"end\":72082,\"start\":72081},{\"end\":72399,\"start\":72398},{\"end\":72407,\"start\":72406},{\"end\":72414,\"start\":72413},{\"end\":72422,\"start\":72421},{\"end\":72655,\"start\":72654},{\"end\":72661,\"start\":72660},{\"end\":72668,\"start\":72667},{\"end\":72674,\"start\":72673},{\"end\":72682,\"start\":72681},{\"end\":72901,\"start\":72900},{\"end\":72910,\"start\":72909},{\"end\":72917,\"start\":72916},{\"end\":72923,\"start\":72922},{\"end\":72931,\"start\":72930},{\"end\":72939,\"start\":72938},{\"end\":72947,\"start\":72946},{\"end\":72958,\"start\":72954},{\"end\":73230,\"start\":73229},{\"end\":73238,\"start\":73237},{\"end\":73247,\"start\":73246},{\"end\":73255,\"start\":73254},{\"end\":73257,\"start\":73256},{\"end\":73467,\"start\":73466},{\"end\":73476,\"start\":73475},{\"end\":73482,\"start\":73481},{\"end\":73488,\"start\":73487},{\"end\":73494,\"start\":73493},{\"end\":73502,\"start\":73501},{\"end\":73511,\"start\":73510}]", "bib_author_last_name": "[{\"end\":61407,\"start\":61399},{\"end\":61415,\"start\":61413},{\"end\":61422,\"start\":61419},{\"end\":61622,\"start\":61616},{\"end\":61634,\"start\":61626},{\"end\":61645,\"start\":61638},{\"end\":61655,\"start\":61649},{\"end\":61892,\"start\":61886},{\"end\":61900,\"start\":61896},{\"end\":61912,\"start\":61904},{\"end\":62250,\"start\":62246},{\"end\":62258,\"start\":62254},{\"end\":62266,\"start\":62262},{\"end\":62482,\"start\":62477},{\"end\":62490,\"start\":62486},{\"end\":62499,\"start\":62496},{\"end\":62507,\"start\":62503},{\"end\":62765,\"start\":62762},{\"end\":62784,\"start\":62769},{\"end\":62796,\"start\":62788},{\"end\":62808,\"start\":62800},{\"end\":62820,\"start\":62812},{\"end\":62831,\"start\":62824},{\"end\":62841,\"start\":62835},{\"end\":63115,\"start\":63111},{\"end\":63121,\"start\":63119},{\"end\":63297,\"start\":63295},{\"end\":63305,\"start\":63301},{\"end\":63313,\"start\":63309},{\"end\":63536,\"start\":63532},{\"end\":63546,\"start\":63540},{\"end\":63755,\"start\":63751},{\"end\":63761,\"start\":63759},{\"end\":63769,\"start\":63765},{\"end\":63777,\"start\":63773},{\"end\":63787,\"start\":63783},{\"end\":63795,\"start\":63791},{\"end\":64062,\"start\":64056},{\"end\":64073,\"start\":64066},{\"end\":64087,\"start\":64077},{\"end\":64099,\"start\":64091},{\"end\":64370,\"start\":64365},{\"end\":64379,\"start\":64374},{\"end\":64398,\"start\":64385},{\"end\":64627,\"start\":64622},{\"end\":64810,\"start\":64805},{\"end\":64818,\"start\":64814},{\"end\":65028,\"start\":65023},{\"end\":65036,\"start\":65032},{\"end\":65048,\"start\":65040},{\"end\":65222,\"start\":65215},{\"end\":65231,\"start\":65226},{\"end\":65240,\"start\":65235},{\"end\":65255,\"start\":65244},{\"end\":65421,\"start\":65415},{\"end\":65431,\"start\":65425},{\"end\":65440,\"start\":65435},{\"end\":65632,\"start\":65629},{\"end\":65640,\"start\":65636},{\"end\":65649,\"start\":65644},{\"end\":65657,\"start\":65653},{\"end\":65885,\"start\":65882},{\"end\":65892,\"start\":65889},{\"end\":65900,\"start\":65896},{\"end\":65906,\"start\":65904},{\"end\":65915,\"start\":65910},{\"end\":66143,\"start\":66140},{\"end\":66149,\"start\":66147},{\"end\":66157,\"start\":66153},{\"end\":66163,\"start\":66161},{\"end\":66171,\"start\":66167},{\"end\":66386,\"start\":66383},{\"end\":66392,\"start\":66390},{\"end\":66400,\"start\":66396},{\"end\":66407,\"start\":66404},{\"end\":66571,\"start\":66568},{\"end\":66577,\"start\":66575},{\"end\":66585,\"start\":66581},{\"end\":66593,\"start\":66589},{\"end\":66602,\"start\":66597},{\"end\":66612,\"start\":66606},{\"end\":66860,\"start\":66853},{\"end\":66872,\"start\":66864},{\"end\":66882,\"start\":66876},{\"end\":66894,\"start\":66886},{\"end\":66907,\"start\":66898},{\"end\":67146,\"start\":67139},{\"end\":67158,\"start\":67150},{\"end\":67168,\"start\":67162},{\"end\":67182,\"start\":67174},{\"end\":67195,\"start\":67186},{\"end\":67434,\"start\":67427},{\"end\":67446,\"start\":67438},{\"end\":67456,\"start\":67450},{\"end\":67466,\"start\":67460},{\"end\":67478,\"start\":67470},{\"end\":67743,\"start\":67736},{\"end\":67756,\"start\":67747},{\"end\":67764,\"start\":67760},{\"end\":67777,\"start\":67770},{\"end\":67785,\"start\":67781},{\"end\":68037,\"start\":68033},{\"end\":68047,\"start\":68041},{\"end\":68230,\"start\":68226},{\"end\":68242,\"start\":68236},{\"end\":68403,\"start\":68399},{\"end\":68420,\"start\":68407},{\"end\":68620,\"start\":68611},{\"end\":68628,\"start\":68624},{\"end\":68641,\"start\":68634},{\"end\":68851,\"start\":68845},{\"end\":69098,\"start\":69092},{\"end\":69115,\"start\":69102},{\"end\":69126,\"start\":69119},{\"end\":69144,\"start\":69130},{\"end\":69383,\"start\":69377},{\"end\":69400,\"start\":69387},{\"end\":69418,\"start\":69404},{\"end\":69650,\"start\":69644},{\"end\":69661,\"start\":69654},{\"end\":69678,\"start\":69665},{\"end\":69696,\"start\":69682},{\"end\":69931,\"start\":69922},{\"end\":69943,\"start\":69937},{\"end\":69957,\"start\":69949},{\"end\":70217,\"start\":70211},{\"end\":70228,\"start\":70221},{\"end\":70238,\"start\":70232},{\"end\":70251,\"start\":70242},{\"end\":70261,\"start\":70255},{\"end\":70521,\"start\":70516},{\"end\":70527,\"start\":70525},{\"end\":70533,\"start\":70531},{\"end\":70716,\"start\":70707},{\"end\":70727,\"start\":70720},{\"end\":70735,\"start\":70733},{\"end\":70926,\"start\":70919},{\"end\":70936,\"start\":70930},{\"end\":70946,\"start\":70940},{\"end\":70955,\"start\":70950},{\"end\":71174,\"start\":71170},{\"end\":71181,\"start\":71178},{\"end\":71188,\"start\":71185},{\"end\":71194,\"start\":71192},{\"end\":71201,\"start\":71198},{\"end\":71210,\"start\":71205},{\"end\":71449,\"start\":71447},{\"end\":71456,\"start\":71453},{\"end\":71463,\"start\":71460},{\"end\":71471,\"start\":71467},{\"end\":71478,\"start\":71475},{\"end\":71728,\"start\":71723},{\"end\":71736,\"start\":71732},{\"end\":71748,\"start\":71743},{\"end\":71763,\"start\":71754},{\"end\":72079,\"start\":72070},{\"end\":72087,\"start\":72083},{\"end\":72404,\"start\":72400},{\"end\":72411,\"start\":72408},{\"end\":72419,\"start\":72415},{\"end\":72427,\"start\":72423},{\"end\":72658,\"start\":72656},{\"end\":72665,\"start\":72662},{\"end\":72671,\"start\":72669},{\"end\":72679,\"start\":72675},{\"end\":72686,\"start\":72683},{\"end\":72907,\"start\":72902},{\"end\":72914,\"start\":72911},{\"end\":72920,\"start\":72918},{\"end\":72928,\"start\":72924},{\"end\":72936,\"start\":72932},{\"end\":72944,\"start\":72940},{\"end\":72952,\"start\":72948},{\"end\":72962,\"start\":72959},{\"end\":73235,\"start\":73231},{\"end\":73244,\"start\":73239},{\"end\":73252,\"start\":73248},{\"end\":73261,\"start\":73258},{\"end\":73473,\"start\":73468},{\"end\":73479,\"start\":73477},{\"end\":73485,\"start\":73483},{\"end\":73491,\"start\":73489},{\"end\":73499,\"start\":73495},{\"end\":73508,\"start\":73503},{\"end\":73514,\"start\":73512}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":2421236},\"end\":61573,\"start\":61323},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":221275765},\"end\":61778,\"start\":61575},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":207251655},\"end\":62173,\"start\":61780},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":10252703},\"end\":62401,\"start\":62175},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":12592499},\"end\":62663,\"start\":62403},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":5590763},\"end\":63070,\"start\":62665},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":1487925},\"end\":63214,\"start\":63072},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":8040013},\"end\":63458,\"start\":63216},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":2843869},\"end\":63676,\"start\":63460},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":14873341},\"end\":63968,\"start\":63678},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":14037713},\"end\":64275,\"start\":63970},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":890889},\"end\":64570,\"start\":64277},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":3022077},\"end\":64764,\"start\":64572},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":14698210},\"end\":64962,\"start\":64766},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":58370896},\"end\":65194,\"start\":64964},{\"attributes\":{\"id\":\"b15\"},\"end\":65348,\"start\":65196},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":4619905},\"end\":65578,\"start\":65350},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":14630147},\"end\":65785,\"start\":65580},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":6764076},\"end\":66095,\"start\":65787},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":15624722},\"end\":66295,\"start\":66097},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":10894889},\"end\":66564,\"start\":66297},{\"attributes\":{\"id\":\"b21\"},\"end\":66802,\"start\":66566},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":17048224},\"end\":67080,\"start\":66804},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":14850173},\"end\":67365,\"start\":67082},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":14679942},\"end\":67655,\"start\":67367},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":16447573},\"end\":67966,\"start\":67657},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":577005},\"end\":68170,\"start\":67968},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":10097073},\"end\":68359,\"start\":68172},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":467086},\"end\":68525,\"start\":68361},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":8411717},\"end\":68806,\"start\":68527},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":5499886},\"end\":69029,\"start\":68808},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":10795036},\"end\":69302,\"start\":69031},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":207178809},\"end\":69576,\"start\":69304},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":207189080},\"end\":69863,\"start\":69578},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":205001834},\"end\":70115,\"start\":69865},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":6126582},\"end\":70458,\"start\":70117},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":7356547},\"end\":70651,\"start\":70460},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":7961699},\"end\":70866,\"start\":70653},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":1169492},\"end\":71091,\"start\":70868},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":4002880},\"end\":71380,\"start\":71093},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":34898320},\"end\":71625,\"start\":71382},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":1173916},\"end\":71957,\"start\":71627},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":6346152},\"end\":72300,\"start\":71959},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":14329144},\"end\":72603,\"start\":72302},{\"attributes\":{\"id\":\"b44\"},\"end\":72817,\"start\":72605},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":9655225},\"end\":73161,\"start\":72819},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":14692499},\"end\":73408,\"start\":73163},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":12440971},\"end\":73674,\"start\":73410}]", "bib_title": "[{\"end\":61393,\"start\":61323},{\"end\":61612,\"start\":61575},{\"end\":61880,\"start\":61780},{\"end\":62242,\"start\":62175},{\"end\":62473,\"start\":62403},{\"end\":62758,\"start\":62665},{\"end\":63107,\"start\":63072},{\"end\":63291,\"start\":63216},{\"end\":63525,\"start\":63460},{\"end\":63747,\"start\":63678},{\"end\":64052,\"start\":63970},{\"end\":64361,\"start\":64277},{\"end\":64618,\"start\":64572},{\"end\":64801,\"start\":64766},{\"end\":65019,\"start\":64964},{\"end\":65411,\"start\":65350},{\"end\":65623,\"start\":65580},{\"end\":65878,\"start\":65787},{\"end\":66136,\"start\":66097},{\"end\":66379,\"start\":66297},{\"end\":66849,\"start\":66804},{\"end\":67135,\"start\":67082},{\"end\":67423,\"start\":67367},{\"end\":67732,\"start\":67657},{\"end\":68029,\"start\":67968},{\"end\":68222,\"start\":68172},{\"end\":68395,\"start\":68361},{\"end\":68607,\"start\":68527},{\"end\":68841,\"start\":68808},{\"end\":69088,\"start\":69031},{\"end\":69373,\"start\":69304},{\"end\":69640,\"start\":69578},{\"end\":69916,\"start\":69865},{\"end\":70205,\"start\":70117},{\"end\":70512,\"start\":70460},{\"end\":70703,\"start\":70653},{\"end\":70915,\"start\":70868},{\"end\":71166,\"start\":71093},{\"end\":71443,\"start\":71382},{\"end\":71719,\"start\":71627},{\"end\":72066,\"start\":71959},{\"end\":72396,\"start\":72302},{\"end\":72652,\"start\":72605},{\"end\":72898,\"start\":72819},{\"end\":73227,\"start\":73163},{\"end\":73464,\"start\":73410}]", "bib_author": "[{\"end\":61409,\"start\":61395},{\"end\":61417,\"start\":61409},{\"end\":61424,\"start\":61417},{\"end\":61624,\"start\":61614},{\"end\":61636,\"start\":61624},{\"end\":61647,\"start\":61636},{\"end\":61657,\"start\":61647},{\"end\":61894,\"start\":61882},{\"end\":61902,\"start\":61894},{\"end\":61914,\"start\":61902},{\"end\":62252,\"start\":62244},{\"end\":62260,\"start\":62252},{\"end\":62268,\"start\":62260},{\"end\":62484,\"start\":62475},{\"end\":62492,\"start\":62484},{\"end\":62501,\"start\":62492},{\"end\":62509,\"start\":62501},{\"end\":62767,\"start\":62760},{\"end\":62786,\"start\":62767},{\"end\":62798,\"start\":62786},{\"end\":62810,\"start\":62798},{\"end\":62822,\"start\":62810},{\"end\":62833,\"start\":62822},{\"end\":62843,\"start\":62833},{\"end\":63117,\"start\":63109},{\"end\":63123,\"start\":63117},{\"end\":63299,\"start\":63293},{\"end\":63307,\"start\":63299},{\"end\":63315,\"start\":63307},{\"end\":63538,\"start\":63527},{\"end\":63548,\"start\":63538},{\"end\":63757,\"start\":63749},{\"end\":63763,\"start\":63757},{\"end\":63771,\"start\":63763},{\"end\":63779,\"start\":63771},{\"end\":63789,\"start\":63779},{\"end\":63797,\"start\":63789},{\"end\":64064,\"start\":64054},{\"end\":64075,\"start\":64064},{\"end\":64089,\"start\":64075},{\"end\":64101,\"start\":64089},{\"end\":64372,\"start\":64363},{\"end\":64381,\"start\":64372},{\"end\":64400,\"start\":64381},{\"end\":64629,\"start\":64620},{\"end\":64812,\"start\":64803},{\"end\":64820,\"start\":64812},{\"end\":65030,\"start\":65021},{\"end\":65038,\"start\":65030},{\"end\":65050,\"start\":65038},{\"end\":65224,\"start\":65213},{\"end\":65233,\"start\":65224},{\"end\":65242,\"start\":65233},{\"end\":65257,\"start\":65242},{\"end\":65423,\"start\":65413},{\"end\":65433,\"start\":65423},{\"end\":65442,\"start\":65433},{\"end\":65634,\"start\":65625},{\"end\":65642,\"start\":65634},{\"end\":65651,\"start\":65642},{\"end\":65659,\"start\":65651},{\"end\":65887,\"start\":65880},{\"end\":65894,\"start\":65887},{\"end\":65902,\"start\":65894},{\"end\":65908,\"start\":65902},{\"end\":65917,\"start\":65908},{\"end\":66145,\"start\":66138},{\"end\":66151,\"start\":66145},{\"end\":66159,\"start\":66151},{\"end\":66165,\"start\":66159},{\"end\":66173,\"start\":66165},{\"end\":66388,\"start\":66381},{\"end\":66394,\"start\":66388},{\"end\":66402,\"start\":66394},{\"end\":66409,\"start\":66402},{\"end\":66573,\"start\":66566},{\"end\":66579,\"start\":66573},{\"end\":66587,\"start\":66579},{\"end\":66595,\"start\":66587},{\"end\":66604,\"start\":66595},{\"end\":66614,\"start\":66604},{\"end\":66862,\"start\":66851},{\"end\":66874,\"start\":66862},{\"end\":66884,\"start\":66874},{\"end\":66896,\"start\":66884},{\"end\":66909,\"start\":66896},{\"end\":67148,\"start\":67137},{\"end\":67160,\"start\":67148},{\"end\":67170,\"start\":67160},{\"end\":67184,\"start\":67170},{\"end\":67197,\"start\":67184},{\"end\":67436,\"start\":67425},{\"end\":67448,\"start\":67436},{\"end\":67458,\"start\":67448},{\"end\":67468,\"start\":67458},{\"end\":67480,\"start\":67468},{\"end\":67745,\"start\":67734},{\"end\":67758,\"start\":67745},{\"end\":67766,\"start\":67758},{\"end\":67779,\"start\":67766},{\"end\":67787,\"start\":67779},{\"end\":68039,\"start\":68031},{\"end\":68049,\"start\":68039},{\"end\":68232,\"start\":68224},{\"end\":68244,\"start\":68232},{\"end\":68405,\"start\":68397},{\"end\":68422,\"start\":68405},{\"end\":68622,\"start\":68609},{\"end\":68630,\"start\":68622},{\"end\":68643,\"start\":68630},{\"end\":68853,\"start\":68843},{\"end\":69100,\"start\":69090},{\"end\":69117,\"start\":69100},{\"end\":69128,\"start\":69117},{\"end\":69146,\"start\":69128},{\"end\":69385,\"start\":69375},{\"end\":69402,\"start\":69385},{\"end\":69420,\"start\":69402},{\"end\":69652,\"start\":69642},{\"end\":69663,\"start\":69652},{\"end\":69680,\"start\":69663},{\"end\":69698,\"start\":69680},{\"end\":69933,\"start\":69918},{\"end\":69945,\"start\":69933},{\"end\":69959,\"start\":69945},{\"end\":70219,\"start\":70207},{\"end\":70230,\"start\":70219},{\"end\":70240,\"start\":70230},{\"end\":70253,\"start\":70240},{\"end\":70263,\"start\":70253},{\"end\":70523,\"start\":70514},{\"end\":70529,\"start\":70523},{\"end\":70535,\"start\":70529},{\"end\":70718,\"start\":70705},{\"end\":70729,\"start\":70718},{\"end\":70737,\"start\":70729},{\"end\":70928,\"start\":70917},{\"end\":70938,\"start\":70928},{\"end\":70948,\"start\":70938},{\"end\":70957,\"start\":70948},{\"end\":71176,\"start\":71168},{\"end\":71183,\"start\":71176},{\"end\":71190,\"start\":71183},{\"end\":71196,\"start\":71190},{\"end\":71203,\"start\":71196},{\"end\":71212,\"start\":71203},{\"end\":71451,\"start\":71445},{\"end\":71458,\"start\":71451},{\"end\":71465,\"start\":71458},{\"end\":71473,\"start\":71465},{\"end\":71480,\"start\":71473},{\"end\":71730,\"start\":71721},{\"end\":71738,\"start\":71730},{\"end\":71750,\"start\":71738},{\"end\":71765,\"start\":71750},{\"end\":71769,\"start\":71765},{\"end\":72081,\"start\":72068},{\"end\":72089,\"start\":72081},{\"end\":72406,\"start\":72398},{\"end\":72413,\"start\":72406},{\"end\":72421,\"start\":72413},{\"end\":72429,\"start\":72421},{\"end\":72660,\"start\":72654},{\"end\":72667,\"start\":72660},{\"end\":72673,\"start\":72667},{\"end\":72681,\"start\":72673},{\"end\":72688,\"start\":72681},{\"end\":72909,\"start\":72900},{\"end\":72916,\"start\":72909},{\"end\":72922,\"start\":72916},{\"end\":72930,\"start\":72922},{\"end\":72938,\"start\":72930},{\"end\":72946,\"start\":72938},{\"end\":72954,\"start\":72946},{\"end\":72964,\"start\":72954},{\"end\":73237,\"start\":73229},{\"end\":73246,\"start\":73237},{\"end\":73254,\"start\":73246},{\"end\":73263,\"start\":73254},{\"end\":73475,\"start\":73466},{\"end\":73481,\"start\":73475},{\"end\":73487,\"start\":73481},{\"end\":73493,\"start\":73487},{\"end\":73501,\"start\":73493},{\"end\":73510,\"start\":73501},{\"end\":73516,\"start\":73510}]", "bib_venue": "[{\"end\":61428,\"start\":61424},{\"end\":61661,\"start\":61657},{\"end\":61956,\"start\":61914},{\"end\":62272,\"start\":62268},{\"end\":62514,\"start\":62509},{\"end\":62848,\"start\":62843},{\"end\":63127,\"start\":63123},{\"end\":63319,\"start\":63315},{\"end\":63552,\"start\":63548},{\"end\":63802,\"start\":63797},{\"end\":64105,\"start\":64101},{\"end\":64404,\"start\":64400},{\"end\":64654,\"start\":64629},{\"end\":64848,\"start\":64820},{\"end\":65063,\"start\":65050},{\"end\":65211,\"start\":65196},{\"end\":65447,\"start\":65442},{\"end\":65665,\"start\":65659},{\"end\":65922,\"start\":65917},{\"end\":66177,\"start\":66173},{\"end\":66413,\"start\":66409},{\"end\":66671,\"start\":66614},{\"end\":66921,\"start\":66909},{\"end\":67203,\"start\":67197},{\"end\":67493,\"start\":67480},{\"end\":67791,\"start\":67787},{\"end\":68053,\"start\":68049},{\"end\":68248,\"start\":68244},{\"end\":68426,\"start\":68422},{\"end\":68649,\"start\":68643},{\"end\":68907,\"start\":68853},{\"end\":69149,\"start\":69146},{\"end\":69423,\"start\":69420},{\"end\":69703,\"start\":69698},{\"end\":69977,\"start\":69959},{\"end\":70267,\"start\":70263},{\"end\":70538,\"start\":70535},{\"end\":70741,\"start\":70737},{\"end\":70961,\"start\":70957},{\"end\":71217,\"start\":71212},{\"end\":71484,\"start\":71480},{\"end\":71772,\"start\":71769},{\"end\":72115,\"start\":72089},{\"end\":72433,\"start\":72429},{\"end\":72693,\"start\":72688},{\"end\":72971,\"start\":72964},{\"end\":73266,\"start\":73263},{\"end\":73522,\"start\":73516}]"}}}, "year": 2023, "month": 12, "day": 17}