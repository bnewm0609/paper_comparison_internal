{"id": 57757287, "updated": "2022-02-27 05:31:44.825", "metadata": {"title": "An abstract domain for certifying neural networks", "authors": "[{\"first\":\"Gagandeep\",\"last\":\"Singh\",\"middle\":[]},{\"first\":\"Timon\",\"last\":\"Gehr\",\"middle\":[]},{\"first\":\"Markus\",\"last\":\"P\u00fcschel\",\"middle\":[]},{\"first\":\"Martin\",\"last\":\"Vechev\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the ACM on Programming Languages", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "We present a novel method for scalable and precise certification of deep neural networks. The key technical insight behind our approach is a new abstract domain which combines floating point polyhedra with intervals and is equipped with abstract transformers specifically tailored to the setting of neural networks. Concretely, we introduce new transformers for affine transforms, the rectified linear unit (ReLU), sigmoid, tanh, and maxpool functions. We implemented our method in a system called DeepPoly and evaluated it extensively on a range of datasets, neural architectures (including defended networks), and specifications. Our experimental results indicate that DeepPoly is more precise than prior work while scaling to large networks. We also show how to combine DeepPoly with a form of abstraction refinement based on trace partitioning. This enables us to prove, for the first time, the robustness of the network when the input image is subjected to complex perturbations such as rotations that employ linear interpolation.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2900153411", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/pacmpl/SinghGPV19", "doi": "10.1145/3290354"}}, "content": {"source": {"pdf_hash": "412709433c2bdb07cf661cb4c848bd4e06ad8d62", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://dl.acm.org/doi/pdf/10.1145/3290354", "status": "GOLD"}}, "grobid": {"id": "e1eb6cbbc81b0828ce4e67984f0bb638ec6f53a8", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/412709433c2bdb07cf661cb4c848bd4e06ad8d62.txt", "contents": "\nAn Abstract Domain for Certifying Neural Networks\n\n\nGagandeep Singh \nEth Zurich \nTimon Switzerland \nEth Gehr \nZurich \nMarkus Switzerland \nEth P\u00fcschel \nZurich \nMartin Switzerland \nEth Vechev \nZurich \nSwitzerland \nAn Abstract Domain for Certifying Neural Networks\n10.1145/329035441 ACM Reference Format: Gagandeep Singh, Timon Gehr, Markus P\u00fcschel, and Martin Vechev. 2019. An Abstract Domain for Certifying Neural Networks. Proc. ACM Program. Lang. 3, POPL, Article 41 (January 2019), 30 pages. https://doi.org/10. 1145/3290354CCS Concepts: \u2022 Theory of computation \u2192 Program verificationAbstraction\u2022 Computing method- ologies \u2192 Neural networksAdditional Key Words and Phrases: Abstract Interpretation, Deep Learning, Adversarial attacks\nWe present a novel method for scalable and precise certification of deep neural networks. The key technical insight behind our approach is a new abstract domain which combines floating point polyhedra with intervals and is equipped with abstract transformers specifically tailored to the setting of neural networks. Concretely, we introduce new transformers for affine transforms, the rectified linear unit (ReLU), sigmoid, tanh, and maxpool functions.We implemented our method in a system called DeepPoly and evaluated it extensively on a range of datasets, neural architectures (including defended networks), and specifications. Our experimental results indicate that DeepPoly is more precise than prior work while scaling to large networks.We also show how to combine DeepPoly with a form of abstraction refinement based on trace partitioning. This enables us to prove, for the first time, the robustness of the network when the input image is subjected to complex perturbations such as rotations that employ linear interpolation.\n\nINTRODUCTION\n\nOver the last few years, deep neural networks have become increasingly popular and have now started penetrating safety critical domains such as autonomous driving [Bojarski et al. 2016] and medical diagnosis [Amato et al. 2013] where they are often relied upon for making important decisions. As a result of this widespread adoption, it has become even more important to ensure that neural networks behave reliably and as expected. Unfortunately, reasoning about these systems is challenging due to their \u0142black box\u017e nature: it is difficult to understand what the network does since it is typically parameterized with thousands or millions of real-valued weights that are hard to interpret. Further, it has been discovered that neural nets can sometimes be surprisingly brittle and exhibit non-robust behaviors, for instance, by classifying two very similar inputs (e.g., images that differ only in brightness or in one pixel) to different labels [Goodfellow et al. 2015]. To address the challenge of reasoning about neural networks, recent research has started exploring new methods and systems which can automatically prove that a given network satisfies a specific property of interest (e.g., robustness to certain perturbations, pre/post conditions). State-of-the-art works include methods based on SMT solving ], linear approximations [Weng et al. 2018], and abstract interpretation Singh et al. 2018a].\n\nDespite the progress made by these works, more research is needed to reach the point where we are able to solve the overall neural network reasoning challenge successfully. In particular, we still lack an analyzer that can scale to large networks, is able to handle popular neural architectures (e.g., feedforward, convolutional), and yet is sufficiently precise to prove relevant properties required by applications. For example, the work by  is precise yet can only handle very small networks. At the same time,  can analyze larger networks than , but relies on existing generic abstract domains which either do not scale to larger neural networks (such as Convex Polyhedra [Cousot and Halbwachs 1978]) or are too imprecise (e.g., Zonotope [Ghorbal et al. 2009]). Recent work by Weng et al. [2018] scales better than  but only handles feedforward networks and cannot handle the widely used convolutional networks. Both  and Weng et al. [2018] are in fact unsound for floating point arithmetic, which is heavily used in neural nets, and thus they can suffer from false negatives. Recent work by Singh et al. [2018a] handles feedforward and convolutional networks and is sound for floating point arithmetic, however, as we demonstrate experimentally, it can lose significant precision when dealing with larger perturbations.\n\nThis work. In this work, we propose a new method and system, called DeepPoly, that makes a step forward in addressing the challenge of verifying neural networks with respect to both scalability and precision. The key technical idea behind DeepPoly is a novel abstract interpreter specifically tailored to the setting of neural networks. Concretely, our abstract domain is a combination of floating-point polyhedra with intervals, coupled with abstract transformers for common neural network functions such as affine transforms, the rectified linear unit (ReLU), sigmoid and tanh activations, and the maxpool operator. These abstract transformers are carefully designed to exploit key properties of these functions and balance analysis scalability and precision. As a result, DeepPoly is more precise than Weng et al. [2018],  and Singh et al. [2018a], yet can handle large convolutional networks and is sound for floating point arithmetic.\n\nProving robustness: illustrative examples. To provide an intuition for the kind of problems that DeepPoly can solve, consider the images shown in Fig. 1. Here, we will illustrate two kinds of robustness properties: L \u221e -norm based perturbations (first row) and image rotations (second row).\n\nIn the first row, we are given an image of the digit 7 (under \u0142Original\u017e). Then, we consider an attack where we allow a small perturbation to every pixel in the original image (visually this may correspond to darkening or lightening the image). That is, instead of a number, each pixel now contains an interval. If each of these intervals has the same size, we say that we have formed an L \u221e ball around the image (typically with a given epsilon \u03f5). This ball is captured visually by the Lower image (in which each pixel contains the smallest value allowed by its interval) and the Upper image (in which each pixel contains the largest value allowed by its interval). We call the modification of the original image to a perturbed version inside this ball an attack, reflecting an adversary who aims to trick the network. There have been various works which aim to find such an attack, otherwise called an adversarial example (e.g., Carlini and Wagner [2017]), typically using gradient-based methods. For our setting however, the question is: are all possible images \u0142sitting between\u017e the Lower and the Upper image classified to the same label as the original? Or, in other words, is the neural net robust to this kind of attack?\n\nThe set of possible images induced by the attack is also called an adversarial region. Note that enumerating all possible images in this region and simply running the network on each to check if it is classified correctly, is practically infeasible. For example, an image from the standard MNIST [Lecun et al. 1998] dataset contains 784 pixels and a perturbation that allows for even two values for every pixel will lead to 2 784 images that one would need to consider. In contrast, our system DeepPoly can automatically prove that all images in the adversarial region classify correctly (that is, no attack is possible) by soundly propagating the entire input adversarial region through the abstract transformers of the network.\n\nWe also consider a more complex type of perturbation in the second row. Here, we rotate the image by an angle and our goal is to show that any rotation up to this angle classifies to the same label. In fact, we consider an even more challenging problem where we not only rotate an image but first form an adversarial region around the image and then reason about all possible rotations of any image in that region. This is challenging, as again, enumeration of images is infeasible when using geometric transformations that perform linear interpolation (which is needed to improve output image quality). Further, because rotation is a transform, the entire set of possible images represented by a rotation up to a given angle needs to somehow be captured. Directly approximating this set is too imprecise and the analysis fails to prove the wanted property. Thus, we introduce a method where we refine the initial approximation into smaller regions that correspond to smaller angles (a form of trace partitioning [Rival and Mauborgne 2007]), use DeepPoly to prove the property on each smaller region, and then deduce the property holds for the initial, larger approximation. To our best knowledge this is the first work which shows how to prove robustness of a neural network under complex input perturbations such as rotations.\n\nMain contributions. Our main contributions are:\n\n\u2022 A new abstract domain for the certification of neural nets. The domain combines floating point polyhedra and intervals with custom abstract transformers for affine transforms, ReLU, sigmoid, tanh, and maxpool functions. These abstract transformers carefully balance scalability and precision of the analysis (Section 4). \u2022 An approach for proving more complex perturbation specifications than considered so far, including rotations using linear interpolation, based on refinement of the abstract input. To our best knowledge, this is the first time such perturbations have been verified (Section 5). \u2022 A complete, parallelized implementation of our approach in a system called DeepPoly, which can handle both feedforward and convolutional neural networks (Section 6). Our entire system is fully available at http://safeai.ethz.ch. \u2022 An extensive evaluation on a range of datasets and networks including defended ones,\n\nshowing DeepPoly is more precise than prior work yet scales to large networks (Section 6). We believe DeepPoly is a promising step towards addressing the challenge of reasoning about neural networks and a useful building block for proving complex specifications (e.g., rotations) and other applications of analysis. As an example, a promising direction for a future application is using our analysis during training. Specifically, because our abstract transformers for the output of a neuron are \u0142point-wise\u017e (i.e., can be computed in parallel), we can directly plug in these transformers into the latest systems which train neural networks using abstract interpretation on GPUs . As our transformers are substantially more precise than those of , we expect they can help improve the overall robustness of the trained network.\n\n\nOVERVIEW\n\nIn this section, we provide an overview of our abstract domain on a small illustrative example. Full formal details are provided in later sections.\n\nRunning example on a feedforward network with ReLU activation. We consider the simple fully connected feedforward neural network with ReLU activations shown in Fig. 2. This network has already been trained and we have the learned weights shown in the figure. The network consists of four layers: an input layer, two hidden layers, and an output layer with two neurons each. The weights on the edges represent the learned coefficients of the weight matrix used by the affine transformations done at each layer. Note that these values are usually detailed floating point numbers (e.g., 0.031), however, here we use whole numbers to simplify the presentation. The learned bias for each neuron is shown above or below it. All of the biases in one layer constitute the translation vector of the affine transformation.\n\nTo compute its output, each neuron in the hidden layer applies an affine transformation based on the weight matrix and bias to its inputs (these inputs are the outputs of the neurons in the previous layer), producing a value v. Then, the neuron applies an activation function to v, in our example ReLU, which outputs v, if v > 0, and 0 otherwise. Thus, the input to every neuron goes through two stages: first, an affine transformation, followed by an activation function application. In the last layer, a final affine transform is applied to yield the output of the entire network, typically a class label that describes how the input is classified.\n\nSpecification. Suppose we work with a hypothetical image that contains only two pixels and the perturbation is such that it places both pixels in the range [\u22121, 1] (pixels are usually in the range [0, 1], however, we use [\u22121, 1] to better illustrate our analysis). Our goal will be to prove that the output of the network at one of the output neurons is always greater than the output at the other one, for any possible input of two pixels in the range [\u22121, 1]. If the proof is successful, it implies that the network produces the same classification label for all of these images.\n\nAbstract domain. To perform the analysis, we introduce an abstract domain with the appropriate abstract transformers that propagate the (abstract) input of the network through the layers, computing an over-approximation of the possible values at each neuron. Concretely, for our example, we need to propagate both intervals [\u22121, 1] (one for each pixel) simultaneously. We now briefly discuss our abstract domain, which aims to balance analysis scalability and precision. Then we illustrate\n\nx 1\n\nx 2\n\nx 3\n\nx 4\n\nx 5\n\nx 6\n\nx 7\n\nx 8\n\nx 9\n\nx 10\n\nx 11\n\nx 12\n1 -1 1 1 max (0, x 3 ) max (0, x 4 ) 1 -1 1 1 max (0, x 7 ) max (0, x 8 ) [-1,1] [-1,1] 1 1 0 1 \u27e8x 1 \u2265 \u22121, x 1 \u2264 1, l 1 = \u22121, u 1 = 1\u27e9 \u27e8x 2 \u2265 \u22121, x 2 \u2264 1, l 2 = \u22121, u 2 = 1\u27e9 \u27e8x 3 \u2265 x 1 + x 2 , x 3 \u2264 x 1 + x 2 , l 3 = \u22122, u 3 = 2\u27e9 0 \u27e8x 4 \u2265 x 1 \u2212 x 2 , x 4 \u2264 x 1 \u2212 x 2 , l 4 = \u22122, u 4 = 2\u27e9 0 \u27e8x 5 \u2265 0, x 5 \u2264 0.5 \u00b7 x 3 + 1, l 5 = 0, u 5 = 2\u27e9 \u27e8x 6 \u2265 0, x 6 \u2264 0.5 \u00b7 x 4 + 1, l 6 = 0, u 6 = 2\u27e9 \u27e8x 7 \u2265 x 5 + x 6 , x 7 \u2264 x 5 + x 6 , l 7 = 0, u 7 = 3\u27e9 0 \u27e8x 8 \u2265 x 5 \u2212 x 6 , x 8 \u2264 x 5 \u2212 x 6 , l 8 = \u22122, u 8 = 2\u27e9 0 \u27e8x 9 \u2265 x 7 ,\nx 9 \u2264 x 7 , l 9 = 0, u 9 = 3\u27e9 \u27e8x 10 \u2265 0,\n\nx 10 \u2264 0.5 \u00b7 x 8 + 1,\nl 10 = 0, u 10 = 2\u27e9\n\u27e8x 11 \u2265 x 9 + x 10 + 1,\n\nx 11 \u2264 x 9 + x 10 + 1,\nl 11 = 1, u 11 = 5.5\u27e9 1 \u27e8x 12 \u2265 x 10 ,\nx 11 \u2264 x 10 , l 12 = 0, its effect on our example network and discuss why we made certain choices in the approximation over others.\nu 12 = 2\u27e9\nTo perform the analysis, we first rewrite the network by expanding each neuron into two nodes: one for the associated affine transform and one for the ReLU activation. Transforming the network of Fig. 2 in this manner produces the network shown in Fig. 3. Because we assign a variable to each node, the network of Fig. 3 consists of n = 12 variables. Our abstract domain, formally described in Section 4, associates two constraints with each variable x i : an upper polyhedral constraint and a lower polyhedral constraint. Additionally, the domain tracks auxiliary (concrete) bounds, one upper bound and one lower bound for each variable, describing a bounding box of the concretization of the abstract element. Our domain is less expressive than the Polyhedra domain [Cousot and Halbwachs 1978] because it bounds the number of conjuncts that can appear in the overall formula to 2n where n is the number of variables of the network. Such careful restrictions are necessary because supporting the full expressive power of convex polyhedra leads to an exponential number of constraints that make the analysis for thousands of neurons practically infeasible. We now discuss the two types of constraints and the two types of bounds, and show how they are computed on our example.\n\nFirst, the lower (a \u2264 i ) and upper (a \u2265 i ) relational polyhedral constraints associated with\nx i have the form v + j w j \u00b7 x j where v \u2208 R \u222a {\u2212\u221e, +\u221e}, w \u2208 R n , \u2200j \u2265 i. w j = 0.\nThat is, a polyhedral constraint for x i can consider and refer to variables \u0142before\u017e x i in the network, but cannot refer to variables \u0142after\u017e x i (because their coefficient is set to 0). Second, for the concrete lower and upper bounds of x i , we use l i , u i \u2208 R \u222a {\u2212\u221e, +\u221e}, respectively. All abstract elements a in our domain satisfy the additional invariant that the interval [l i , u i ] overapproximates the set of values that the variable x i can take (we formalize this requirement in Section 4).\n\nAbstract interpretation of the network. We now illustrate the operation of our abstract interpreter (using the abstract domain above) on our example network, abstract input ([\u22121, 1] for both pixels), and specification (which is to prove that any image in the concretization of [\u22121, 1] \u00d7 [\u22121, 1] classifies to the same label).\n\nThe analysis starts at the input layer, i.e., in our example from x 1 and x 2 , and simply propagates the inputs, resulting in a \u2264 1 = a \u2264 2 = \u22121, a \u2265 1 = a \u2265 2 = 1, l 1 = l 2 = \u22121, and u 1 = u 2 = 1. Next, the affine transform at the first layer updates the constraints for x 3 and x 4 . The abstract transformer first 41:6 Gagandeep Singh, Timon Gehr, Markus P\u00fcschel, and Martin Vechev adds the constraints\nx i x j u i l i x j = \u03bb \u00b7 xi + \u00b5 (b) x i x j u i l i x j = \u03bb \u00b7 xi + \u00b5 x j = x i (c) x i x j u i l i x j = \u03bb \u00b7 xi + \u00b5 x j = x i (a)x 1 + x 2 \u2264 x 3 \u2264 x 1 + x 2 x 1 \u2212 x 2 \u2264 x 4 \u2264 x 1 \u2212 x 2(1)\nThe transformer uses these constraints and the constraints for x 1 , x 2 to compute l 3 = l 4 = \u22122 and u 3 = u 4 = 2. Next, the transformer for the ReLU activation is applied. In general, the output x j of the ReLU activation on variable x i is equivalent to the assignment x j := max(0, x i ). If u i \u2264 0, then our abstract transformer sets the state of the variable x j to 0 \u2264 x j \u2264 0, l j = u j = 0. In this case, our abstract transformer is exact. If l i \u2265 0, then our abstract transformer adds\nx i \u2264 x j \u2264 x i , l j = l i , u j = u i .\nAgain, our abstract transformer is exact in this case.\n\nHowever, when l i < 0 and u i > 0, the result cannot be captured exactly by our abstraction and we need to decide how to lose information. Fig. 4 shows several candidate convex approximations of the ReLU assignment in this case. The approximation of Fig. 4 (a) minimizes the area in the x i , x j plane, and would add the following relational constraints and concrete bounds for x j :\nx i \u2264 x j , 0 \u2264 x j , x j \u2264 u i (x i \u2212 l i )/(u i \u2212 l i ). l j = 0, u j = u i .(2)\nHowever, the approximation in (2) contains two lower polyhedra constraints for x j , which we disallow in our abstract domain. The reason for this is the potential blowup in the number of constraints as the analysis proceeds. We will explain this effect in more detail later in this section.\n\nTo avoid this explosion we further approximate (2) by allowing only one lower bound. There are two ways of accomplish this, shown in Fig. 4 (b) and (c), both of which can be expressed in our domain. During analysis we always consider both and choose the one with the least area.\n\nThe approximation from Fig. 4 (b) adds the following constraints and bounds for x j :\n0 \u2264 x j \u2264 u i (x i \u2212 l i )/(u i \u2212 l i ), l j = 0, u j = u i .(3)\nThe approximation from Fig. 4 (c) adds the following constraints and bounds:\nx i \u2264 x j \u2264 u i (x i \u2212 l i )/(u i \u2212 l i ), l j = l i , u j = u i .(4)\nNote that it would be incorrect to set l j = 0 in (4) above (instead of l j = l i ). The reason is that this would break a key domain invariant which we aim to maintain, namely that the concretization of the two symbolic bounds for x j is contained inside the concretization of the concrete bounds l j and u j (we discuss this domain invariant later in Section 4). In particular, if we only consider the two symbolic bounds for x j , then x j would be allowed to take on negative values and these negative values would not be included in the region [0, u i ]. This domain invariant is important to ensure efficiency of our transformers and as we prove later, all of our abstract transformers maintain it.\n\nReturning to our example, the area of the approximation in Fig. 4 (b) is 0.5 \u00b7 u i \u00b7 (u i \u2212 l i ) whereas the area in Fig. 4 (c) is 0.5 \u00b7 \u2212l i \u00b7 (u i \u2212 l i ). We choose the tighter approximation, i.e., when u i \u2264 \u2212l i , we add the constraints and the bounds from (3), otherwise we add the constraints and the bounds from (4). We note that the approximations in Fig. 4 (b) and (c) cannot be captured by the Zonotope abstraction as used in Singh et al. 2018a].\n\nIn our example, for both x 3 and x 4 , we have l 3 = l 4 = \u22122 and u 3 = u 4 = 2. The areas are equal in this case; thus we choose (3) and get the following constraints and bounds for x 5 and x 6 :\n0 \u2264 x 5 \u2264 0.5 \u00b7 x 3 + 1, l 5 = 0, u 5 = 2, 0 \u2264 x 6 \u2264 0.5 \u00b7 x 4 + 1, l 6 = 0, u 6 = 2.(5)\nNext, we apply the abstract affine transformer, which first adds the following constraints for x 7 and x 8 :\nx 5 + x 6 \u2264 x 7 \u2264 x 5 + x 6 , x 5 \u2212 x 6 \u2264 x 8 \u2264 x 5 \u2212 x 6 .(6)\nIt is possible to compute bounds for x 7 and x 8 from the above equations by substituting the concrete bounds for x 5 and x 6 . However, the resulting bounds are in general too imprecise. Instead, we can obtain better bounds by recursively substituting the polyhedral constraints until the bounds only depend on the input variables for which we then use their concrete bounds. In our example we substitute the relational constraints for x 5 , x 6 from equation (5) to obtain:\n0 \u2264 x 7 \u2264 0.5 \u00b7 x 3 + 0.5 \u00b7 x 4 + 2, \u22120.5 \u00b7 x 4 \u2212 1 \u2264 x 8 \u2264 0.5 \u00b7 x 3 + 1.(7)\nReplacing x 3 and x 4 with the constraints in (1), we get:\n0 \u2264 x 7 \u2264 x 1 + 2, \u22120.5 \u00b7 x 1 + 0.5 \u00b7 x 2 \u2212 1 \u2264 x 8 \u2264 0.5 \u00b7 x 1 + 0.5 \u00b7 x 2 + 1.(8)\nNow we use the concrete bounds of \u00b11 for x 1 , x 2 to obtain l 7 = 0, u 7 = 3 and l 8 = \u22122, u 8 = 2. Indeed, this is more precise than if we had directly substituted the concrete bounds for x 5 and x 6 in (6) because that would have produced concrete bounds l 7 = 0, u 7 = 4 (which are not as tight as the ones above).\n\nAvoiding exponential blowup of the analysis. As seen above, to avoid the state space explosion, our analysis introduces exactly one polyhedral constraint for the lower bound of a variable. It is instructive to understand the effect of introducing more than one constraint via the ReLU approximation of Fig. 4 (a). This ReLU approximation introduces two lower relational constraints for both x 5 and x 6 . Substituting them in (6) would have created four lower relational constraints for x 7 . More generally, if the affine expression for a variable x i contains p variables with positive coefficients and n variables with negative coefficients, then the number of possible lower and upper relational constraints is 2 p and 2 n , respectively, leading to an exponential blowup. This is the reason why we keep only one lower relational constraint for each variable in the network, and use either the ReLU transformer illustrated in Fig. 4 (b) or the one in Fig. 4 (c).\n\nAsymptotic runtime. The computation of concrete bounds by the abstract affine transformer in the hidden layers is the most expensive step of our analysis. If there are L network layers and the maximum number of variables in a layer is n max , then this step for one variable is in O(n 2 max \u00b7 L). Storing the concrete bounds ensures that the subsequent ReLU transformer has constant cost.\n\nAll our transformers work point-wise, i.e., they are independent for different variables since they only read constraints and bounds from the previous layers. This makes it possible to parallelize our analysis on both CPUs and GPUs. The work of ] defines pointwise Zonotope transformers for training neural networks on GPUs to be more robust against adversarial attacks. Our pointwise transformers are more precise than those used in ] and can be used to train more robust neural networks.\n\nPrecision vs. performance trade-off. We also note that our approach allows one to easily vary the precision-performance knob of the affine transformer in the hidden layers: (i) we can select a subset of variables for which to perform complete substitution all the way back to the first layer (the example above showed this for all variables), and (ii) we can decide at which layer we would like to stop the substitution and select the concrete bounds at that layer.\n\nReturning to our example, next, the ReLU transformers are applied again. Since l 7 = 0, the ReLU transformer is exact for the assignment to x 9 and adds the relational constraints x 7 \u2264 x 9 \u2264 x 7 and the bounds l 9 = 0, u 9 = 3 for x 9 . However, the transformer is not exact for the assignment to x 10 and the following constraints and bounds for x 10 are added:\n0 \u2264 x 10 \u2264 0.5 \u00b7 x 8 + 1, l 10 = 0, u 10 = 2.(9)\nFinally, the analysis reaches the output layer and the abstract affine transformer adds the following constraints for x 11 and x 12 :\nx 9 + x 10 + 1 \u2264 x 11 \u2264 x 9 + x 10 + 1 x 10 \u2264 x 12 \u2264 x 10(10)\nAgain, backsubstitution up to the input layer yields l 11 = 1, u 11 = 5.5 and l 12 = 0, u 12 = 2. This completes our analysis of the neural network.\n\nChecking the specification. Next, we check our specification, namely whether all concrete output values of one neuron are always greater than all concrete output values of the other neuron, i.e., if\n\u2200i 1 , i 2 \u2208 [\u22121, 1] \u00d7 [\u22121, 1], x 11 > x 12 or \u2200i 1 , i 2 \u2208 [\u22121, 1] \u00d7 [\u22121, 1], x 12 > x 11 , where x 11 , x 12 = N f f (i 1 , i 2 )\nare the concrete values for variables x 11 and x 12 produced by our small feedforward (ff) neural network N f f for inputs i 1 , i 2 .\n\nIn our simple example, this amounts to proving whether x 11 \u2212x 12 > 0 or x 12 \u2212x 11 > 0 holds given the abstract results computed by our analysis. Note that using the concrete bounds for x 11 and x 12 , that is, l 11 , l 12 , u 11 , and u 12 leads to the bound [\u22121, 5.5] for x 11 \u2212 x 12 and [\u22125.5, 1] for x 12 \u2212 x 11 and hence we cannot prove that either constraint holds. To address this imprecision, we first create a new temporary variable x 13 and apply our abstract transformer for the assignment x 13 := x 11 \u2212 x 12 . Our transformer adds the following constraint:\nx 11 \u2212 x 12 \u2264 x 13 \u2264 x 11 \u2212 x 12(11)\nThe transformer then computes bounds for x 13 by backsubstitution (to the first layer), as described so far, which produces l 13 = 1 and u 13 = 4. As the (concrete) lower bound of x 13 is greater than 0, our analysis concludes that x 11 \u2212 x 12 > 0 holds. Hence, we have proved our (robustness) specification.\n\nOf course, if we had failed to prove the property, we would have tried the same analysis using the second constraint (i.e., x 12 > x 11 ). And if that would fail, then we would declare that we are unable to prove the property. For our example, this was not needed since we were able to prove the first constraint.\n\n\nBACKGROUND: NEURAL NETWORKS AND ADVERSARIAL REGIONS\n\nIn this section, we provide the minimal necessary background on neural networks and adversarial regions. Further, we show how we represent neural networks for our analysis.\n\nNeural networks. Neural networks are functions N : R m \u2192 R n that can be implemented using straight-line programs (i.e., without loops) of a certain form. In this work, we focus on neural networks that follow a layered architecture, but all our methods can be used unchanged for more general neural network shapes. A layered neural network is given by a composition of l layers\nf 1 : R m \u2192 R n 1 , . . . , f l : R n l \u22121 \u2192 R n . Each layer f i is one of the following: (i) an affine transformation f i (x) = Ax + b for some A \u2208 R n i \u00d7n i \u22121 and b \u2208 R n i (in particular, convolution with one or more filters is an affine transformation), (ii) the ReLU activation function f (x) = max(0, x), where the maximum is applied componentwise, (iii) the sigmoid (\u03c3 (x) = e x e x +1 ) or the tanh (tanh(x) = e x \u2212e \u2212x e\nx +e \u2212x ) activation function (again applied componentwise), or (iv) a max pool activation function, which subdivides the input x into multiple parts, and returns the maximal value in each part.\n\nNeurons and activations. Each component of one of the vectors passed along through the layers is called a neuron, and its value is called an activation. There are three types of neurons: m input neurons whose activations form the input to the network, n output neurons whose activations form the output of the network, and all other neurons, called hidden, as they are not directly observed.\n\nClassification. For a neural network that classifies its inputs to multiple possible labels, n is the number of distinct classes, and the neural network classifies a given input x to a given class k if N (x) k > N (x) j for all j with 1 \u2264 j \u2264 n and j k.\n\nAdversarial region. In our evaluation, we consider the following (standard, e.g., see Carlini and Wagner [2017]) threat model: an input is drawn from the input distribution, perturbed by an adversary and then classified by the neural network. The perturbations that the adversary can perform are restricted and the set X \u2286 R n of possible perturbations for a given input is called an adversarial region. The maximal possible error (i.e., the fraction of misclassified inputs) that the adversary can obtain by picking a worst-case input from each adversarial region is called the adversarial error. A neural network is robust for a given adversarial region if it classifies all inputs in that region the same way. This means that it is impossible for an adversary to influence the classification by picking an input from the adversarial region.\n\nIn our evaluation, we focus on verifying robustness for adversarial regions that can be represented using a set of interval constraints, i.e.,\nX = m i=1 [l i , u i ] for l i , u i \u2208 R \u222a {\u2212\u221e, +\u221e}.\nWe also show how to use our analyzer to verify robustness against rotations which employ linear interpolation.\n\nNetwork representation. For our analysis, we represent neural networks as a sequence of assignments, one per hidden and per output neuron. We need four kinds of assignments: ReLU assignments x i \u2190 max(0, x j ), sigmoid/tanh assignments x i \u2190 \u0434(x j ) for \u0434 = \u03c3 or \u0434 = tanh, max pool assignments x i \u2190 max j \u2208J x j and affine assignments x i \u2190 v + j w j \u00b7 x j . Convolutional layers can be described with affine assignments ).\n\nFor example, we represent the neural network from Fig. 2 as the following program:\nx 3 \u2190 x 1 + x 2 , x 4 \u2190 x 1 \u2212 x 2 , x 5 \u2190 max(0, x 3 ), x 6 \u2190 max(0, x 4 ), x 7 \u2190 x 5 + x 6 , x 8 \u2190 x 5 \u2212 x 6 , x 9 \u2190 max(0, x 7 ), x 10 \u2190 max(0, x 8 ), x 11 \u2190 x 9 + x 10 + 1, x 12 \u2190 x 10 .\nIn Fig. 2, the adversarial region is given by\nX = [\u22121, 1] \u00d7 [\u22121, 1].\nThe variables x 1 and x 2 are the input to the neural network, and the variables x 11 and x 12 are the outputs of the network. Therefore, the final class of an input (x 1 , x 2 ) is 1 if x 11 > x 12 , and 2 if x 11 < x 12 . To prove robustness we either need to prove that \u2200(\nx 1 , x 2 ) \u2208 X . x 11 > x 12 or that \u2200(x 1 , x 2 ) \u2208 X . x 12 > x 11 .\nWe note that even though our experimental evaluation focuses on different kinds of robustness, our method and abstract domain are general and can be used to prove other properties as well.\n\n\nABSTRACT DOMAIN AND TRANSFORMERS\n\nIn this section, we introduce our abstract domain as well as the abstract transformers needed to analyze the four kinds of assignment statements mentioned previously.\n\nElements in our abstract domain A n consist of a set of polyhedral constraints of a specific form, over n variables. Each constraint relates one variable to a linear combination of the variables of a smaller index. Each variable has two associated polyhedral constraints: one lower bound and one upper bound. In addition, the abstract element records derived interval bounds for each variable. Formally, an abstract element a \u2208 A n over n variables can be written as a tuple a = \u27e8a \u2264 , a \u2265 , l, u\u27e9 where\na \u2264 i , a \u2265 i \u2208 {x \u2192 v + j \u2208[i\u22121] w j \u00b7 x j | v \u2208 R \u222a {\u2212\u221e, +\u221e}, w \u2208 R i\u22121 } for i \u2208 [n]\nand l, u \u2208 (R \u222a {\u2212\u221e, +\u221e}) n . Here, we use the notation [n] := {1, 2, . . . , n}. The concretization function \u03b3 n : A n \u2192 P(R n ) is then given by\n\u03b3 n (a) = {x \u2208 R n | \u2200i \u2208 [n]. a \u2264 i (x) \u2264 x i \u2227 a \u2265 i (x) \u2265 x i }.\nDomain Invariant. All abstract elements in our domain additionally satisfy the following invariant:\n\u03b3 n (a) \u2286 i \u2208[n] [l i , u i ].\nIn other words, every abstract element in our domain maintains concrete lower and upper bounds which over-approximate the two symbolic bounds. This property is essential for creating efficient abstract transformers.\n\nTo simplify our exposition of abstract transformers, we will only consider the case where all variables are bounded, which is always the case when our analysis is applied to neural networks. Further, we require that variables are assigned exactly once, in increasing order of their indices. Our abstract transformers T # f for a deterministic function f : A m \u2192 A n satisfy the following soundness property:\nT f (\u03b3 m (a)) \u2286 \u03b3 n (T # f (a)) for all a \u2208 A m , where T f is the corresponding concrete transformer of f , given by T f (X ) = { f (x) | x \u2208 X }. 4.1 ReLU Abstract Transformer Let f : R i\u22121 \u2192 R i be a function that executes the assignment x i \u2190 max(0, x j ) for some j < i.\nThe corresponding abstract ReLU transformer is\nT # f (\u27e8a \u2264 , a \u2265 , l, u\u27e9) = \u27e8a \u2032\u2264 , a \u2032\u2265 , l \u2032 , u \u2032 \u27e9 where a \u2032\u2264 k =a \u2264 k , a \u2032\u2265 k = a \u2265 k , l \u2032 k = l k and u \u2032 k = u k for k < i. For the new component i, there are three cases. If u j \u2264 0, then a \u2032\u2264 i (x) = a \u2032\u2265 i (x) = 0 and l \u2032 i = u \u2032 i = 0. If 0 \u2264 l j , then a \u2032\u2264 i (x) = a \u2032\u2265 i (x) = x j , l \u2032 i = l j and u \u2032 i = u j .\nOtherwise, the abstract ReLU transformer approximates the assignment by a set of linear constraints forming its convex hull when it is restricted to the interval [l j , u j ]:\n0 \u2264 x i , x j \u2264 x i , x i \u2264 u j (x j \u2212 l j )/(u j \u2212 l j ).\nAs there is only one upper bound for x i , we obtain the following rule:\na \u2032\u2265 i (x) = u j (x j \u2212 l j )/(u j \u2212 l j ).\nOn the other hand, we have two lower bounds for x i : x j and 0. Any convex combination of those two constraints is still a valid lower bound. Therefore, we can set a \u2032\u2264 i (x) = \u03bb \u00b7 x j , for any \u03bb \u2208 [0, 1]. We select the \u03bb \u2208 {0, 1} that minimizes the area of the resulting shape in the (x i , x j )-plane. Finally, we set l \u2032 i = \u03bb \u00b7 l j and u \u2032 i = u j .\n\n\nSigmoid and Tanh Abstract Transformers\n\nLet \u0434 : R \u2192 R be a continuous, twice-differentiable function with \u0434 \u2032 (x) > 0 and 0 \u2264 \u0434 \u2032\u2032 (x) \u21d4 x \u2264 0 for all x \u2208 R where \u0434 \u2032 and \u0434 \u2032\u2032 are the first and second derivatives of \u0434. The sigmoid function \u03c3 (x) = e x e x +1 and the tanh function tanh(x) = e x \u2212e \u2212x e x +e \u2212x both satisfy these conditions. For such a function \u0434, let f : R i\u22121 \u2192 R i be the function that executes the assignment\nx i \u2190 \u0434(x j ) for j < i. The corresponding abstract transformer is T # f (\u27e8a \u2264 , a \u2265 , l, u\u27e9) = \u27e8a \u2032\u2264 , a \u2032\u2265 , l \u2032 , u \u2032 \u27e9 where a \u2032\u2264 k =a \u2264 k , a \u2032\u2265 k = a \u2265 k , l \u2032 k = l k and u \u2032 k = u k for k < i. For the new component i, we set l \u2032 i = \u0434(l j ) and u \u2032 i = \u0434(u j ). If l j = u j , then a \u2032\u2264 i (x) = a \u2032\u2265 i (x) = \u0434(l j ).\nOtherwise, we consider a \u2032\u2264 i (x) and a \u2032\u2265 i (x) separately. Let \u03bb = (\u0434(u j ) \u2212 \u0434(l j ))/(u j \u2212 l j ) and \u03bb \u2032 = min(\u0434 \u2032 (l j ), \u0434 \u2032 (u j )). If 0 < l j , then a \u2032\u2264\ni (x) = \u0434(l j ) + \u03bb \u00b7 (x j \u2212 l j ), otherwise a \u2032\u2264 i (x) = \u0434(l j ) + \u03bb \u2032 \u00b7 (x j \u2212 l j ). Similarly, if u j \u2264 0, then a \u2032\u2265 i (x) = \u0434(u j ) + \u03bb \u00b7 (x j \u2212 u j ) and a \u2032\u2265 i (x) = \u0434(u j ) + \u03bb \u2032 \u00b7 (x j \u2212 u j ) otherwise.\n\nMax Pool Abstract Transformer\nLet f : R i\u22121 \u2192 R i be a function that executes x i \u2190 max j \u2208J x j for some J \u2286 [i \u2212 1]. The correspond- ing abstract max pool transformer is T # f (\u27e8a \u2264 , a \u2265 , l, u\u27e9) = \u27e8a \u2032\u2264 , a \u2032\u2265 , l \u2032 , u \u2032 \u27e9 where a \u2032\u2264 k =a \u2264 k , a \u2032\u2265 k = a \u2265 k , l \u2032 k = l k and u \u2032 k = u k for k < i. For the new component i, there are two cases. If there is some k \u2208 J with u j < l k for all j \u2208 J \\ {k}, then a \u2032\u2264 i (x) = a \u2032\u2265 i (x) = x k , l \u2032 i = l k and u \u2032 i = u k . Otherwise, we choose k \u2208 J such that l k is maximized and set a \u2032\u2264 i (x) = x k , l \u2032 i = l k and a \u2032\u2265 i (x) = u \u2032 i = max j \u2208J u j .\n\nAffine Abstract Transformer\n\nLet f :\nR i\u22121 \u2192 R i be a function that executes x i \u2190 v + j \u2208[i\u22121] w j \u00b7 x j for some w \u2208 R i\u22121 . The corresponding abstract affine transformer is T # f (\u27e8a \u2264 , a \u2265 , l, u\u27e9) = \u27e8a \u2032\u2264 , a \u2032\u2265 , l \u2032 , u \u2032 \u27e9 where a \u2032\u2264 k =a \u2264 k , a \u2032\u2265 k = a \u2265 k , l \u2032 k = l k and u \u2032 k = u k for k < i. Further, a \u2032\u2264 i (x) = a \u2032\u2265 i (x) = v + j \u2208[i\u22121] w j \u00b7 x j .\nTo compute l i and u i , we repeatedly substitute bounds for x j into the constraint, until no further substitution is possible. Formally, if we want to obtain l \u2032 i , we start with b 1 (\nx) = a \u2032\u2264 i (x). If we have b s (x) = v \u2032 + j \u2208[k ] w \u2032 j \u00b7 x j for some k \u2208 [i \u2212 1], v \u2032 \u2208 R, w \u2032 \u2208 R k , then b s+1 (x) = v \u2032 + j \u2208[k] max(0, w \u2032 j ) \u00b7 a \u2032\u2264 j (x) + min(w \u2032 j , 0) \u00b7 a \u2032\u2265 j (x) .\nWe iterate until we reach b s \u2032 with b s \u2032 (x) = v \u2032\u2032 (i.e., s \u2032 is the smallest number with this property). We then set l \u2032 i = v \u2032\u2032 .\n\n\n41:12\n\nGagandeep Singh, Timon Gehr, Markus P\u00fcschel, and Martin Vechev\n\nWe compute u \u2032 i in an analogous fashion: to obtain u \u2032 i , we start with c 1 (\nx) = a \u2032\u2265 i (x). If we have c t (x) = v \u2032 + j \u2208[k ] w \u2032 j \u00b7 x j for some k \u2208 [i \u2212 1], v \u2032 \u2208 R, w \u2032 \u2208 R k , then c t +1 (x) = v \u2032 + j \u2208[k] max(0, w \u2032 j ) \u00b7 a \u2032\u2265 j (x) + min(w \u2032 j , 0) \u00b7 a \u2032\u2264 j (x) .\nWe iterate until we reach c t \u2032 with c t \u2032 (x) = v \u2032\u2032 . We then set u \u2032 i = v \u2032\u2032 .\n\n\nNeural Network Robustness Analysis\n\nWe now show how to use our analysis to prove robustness of a neural network with p inputs, q hidden activations and r output classes, resulting in a total of p + q + r activations. More explicitly, our goal is to prove that the neural network classifies all inputs satisfying the given interval constraints (the adversarial region) to a particular class k.\n\nWe first create an abstract element a = \u27e8a \u2264 , a \u2265 , l, r \u27e9 over p variables, where a \u2264 i (x) = l i and a \u2265 i (x) = u i for all i. The bounds l i and u i are initialized such that they describe the adversarial region. For example, for the adversarial region in Fig. 2, we get\na = \u27e8(x \u2192 l 1 , x \u2192 l 2 ), (x \u2192 u 1 , x \u2192 u 2 ), (\u22121, \u22121), (1, 1)\u27e9.\nThen, the analysis proceeds by processing assignments for all q hidden activations and the r output activations of the neural network, layer by layer, processing nodes in ascending order of variable indices, using their respective abstract transformers. Finally, the analysis executes the following r \u2212 1 (affine) assignments in the abstract:\nx p+q+r +1 \u2190 x p+q+k \u2212 x p+q+1 , . . . , x p+q+r +(k \u22121) \u2190 x p+q+k \u2212 x p+q+(k \u22121) , x p+q+r +k \u2190 x p+q+k \u2212 x p+q+(k +1) , . . . , x p+q+r +(r \u22121) \u2190 x p+q+k \u2212 x p+q+r .\nAs output class k has the highest activation if and only if those differences are all positive, the neural network is proved robust if for all i \u2208 {p + q + r + 1, . . . , p + q + r + (r \u2212 1)} we have 0 < l i . Otherwise, our robustness analysis fails to verify.\n\nFor the neural network in Fig. 2, if we want to prove that class 1 is most likely, this means we execute one additional assignment x 13 \u2190 x 11 \u2212 x 12 . Abstract interpretation derives the bounds l 13 = 1, u 13 = 4. The neural network is proved robust, because l 13 is positive.\n\nThe above discussion showed how to use our abstract transformers to prove robustness. However, a similar procedure could be used to prove standard pre/post conditions (by performing the analysis starting with the pre-condition).\n\n\nCorrectness of Abstract Transformers\n\nIn this section, we prove that our abstract transformers are sound, and that they preserve the invariant. Formally, for\nT # f (a) = a \u2032 we have T f (\u03b3 i\u22121 (a)) \u2286 \u03b3 i (a \u2032 ) and \u03b3 i (a \u2032 ) \u2286 k \u2208[i] [l \u2032 k , u \u2032 k ].\nSoundness. We first prove a lemma that is needed to prove soundness of our ReLU transformer.\nLemma 4.1. For l < 0, 0 < u, l \u2264 x \u2264 u, and \u03bb \u2208 [0, 1] we have \u03bb \u00b7 x \u2264 max(0, x) \u2264 u \u00b7 x \u2212l u\u2212l . Proof. If x < 0, then \u03bb \u00b7 x < 0 = max(0, x). If x \u2265 0, then \u03bb \u00b7 x \u2264 x = max(0, x). If x < 0, then max(0, x) = 0 \u2264 u \u00b7 x \u2212l u\u2212l . If x \u2265 0 then max(0, x) = x \u2264 u \u00b7 x \u2212l u\u2212l because x \u00b7 (\u2212l) \u2264 u \u00b7 (\u2212l) \u21d4 x \u00b7 u \u2212 x \u00b7 l \u2264 x \u00b7 u \u2212 u \u00b7 l \u21d4 x \u00b7 (u \u2212 l) \u2264 u \u00b7 (x \u2212 l). \u25a1\nTheorem 4.2. The ReLU abstract transformer is sound.\n\nProof. Let f : R i\u22121 \u2192 R i execute the assignment x i \u2190 max(0, x j ) for some j < i, and let a \u2208 A i\u22121 be arbitrary. We have\n\u03b3 i\u22121 (a) \u2286 k \u2208[i\u22121] [l k , u k ] and T f (\u03b3 i\u22121 (a)) = { f (x) | x \u2208 \u03b3 i\u22121 (a)} = {(x 1 , . . . , x i\u22121 , max(0, x j )) | (x 1 , . . . , x i\u22121 ) \u2208 \u03b3 i\u22121 (a)} = {x \u2208 R i | (x 1 , . . . , x i\u22121 ) \u2208 \u03b3 i\u22121 (a) \u2227 x i = max(0, x j )} = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = max(0, x j )}. If u j \u2264 0, we have that (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) implies x j \u2264 0, and T f (\u03b3 i\u22121 (a)) = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = max(0, x j ) \u2227 x j \u2264 0} = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = 0} = {x \u2208 R i | \u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k } = \u03b3 i (T # f (a)). Otherwise, if 0 \u2264 l j , we have that (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) implies 0 \u2264 x j , and T f (\u03b3 i\u22121 (a)) = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = max(0, x j ) \u2227 0 \u2264 x j } = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = x j } = {x \u2208 R i | \u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k } = \u03b3 i (T # f (a)).\nOtherwise, we have l j < 0 and 0 < u j and that (\u2200k \u2208\n[i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) implies l j \u2264 x j \u2264 u j and therefore T f (\u03b3 i\u22121 (a)) = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = max(0, x j )} \u2286 {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i \u2264 u j \u00b7 x j \u2212 l j u j \u2212 l j \u2227 x i \u2265 \u03bb \u00b7 x j } = {x \u2208 R i | \u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k } = \u03b3 i (T # f (a)).\nTherefore, in all cases, T f (\u03b3 i\u22121 (a)) \u2286 \u03b3 i (T # f (a)). Note that we lose precision only in the last case. \u25a1 Theorem 4.3. The sigmoid and tanh abstract transformers are sound.\n\nProof. A function \u0434 : R \u2192 R with \u0434 \u2032 (x) > 0 and 0 \u2264 \u0434 \u2032\u2032 (x) \u21d4 0 \u2264 x is monotonically increasing, and furthermore, \u0434| (\u2212\u221e,0] (the restriction to (\u2212\u221e, 0]) is convex and \u0434| (0,\u221e) is concave.\n\nLet f : R i\u22121 \u2192 R i execute the assignment x i \u2190 \u0434(x j ) for some j < i, and let a \u2208 A i\u22121 be arbitrary. We have\nT f (\u03b3 i\u22121 (a)) = { f (x) | x \u2208 \u03b3 i\u22121 (a)} = {(x 1 , . . . , x i\u22121 , \u0434(x j )) | (x 1 , . . . , x i\u22121 ) \u2208 \u03b3 i\u22121 (a)} = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = \u0434(x j )}. If l j = u j , then (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) implies x j = l j and therefore T f (\u03b3 i\u22121 (a)) = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = \u0434(x j )}. = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = \u0434(l j )} = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 \u0434(l j ) \u2264 x i \u2227 x j \u2264 \u0434(l j )} = {x \u2208 R i | \u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k } = \u03b3 i (T # f (a)).\nTherefore, the transformer is exact in this case. Otherwise, we need to show that (\u2200k \u2208\n[i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = \u0434(x j ) implies a \u2032\u2264 i (x) \u2264 x i and a \u2032\u2265 i (x) \u2265 x i . We let x \u2208 R i be arbitrary with (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = \u0434(x j )\nand consider a \u2032\u2264 i (x) and a \u2032\u2265 i (x) separately. Recall that \u03bb = (\u0434(u j ) \u2212 \u0434(l j ))/(u j \u2212 l j ) and \u03bb \u2032 = min(\u0434 \u2032 (l j ), \u0434 \u2032 (u j )). If 0 \u2264 l j , then, because \u0434 is concave on positive inputs,\na \u2032\u2264 i (x) = \u0434(l j ) + \u03bb \u00b7 (x j \u2212 l j ) = 1 \u2212 x j \u2212 l j u j \u2212 l j \u00b7 \u0434(l j ) + x j \u2212 l j u j \u2212 l j \u00b7 \u0434(u j ) \u2264 \u0434 1 \u2212 x j \u2212 l j u j \u2212 l j \u00b7 l j + x j \u2212 l j u j \u2212 l j \u00b7 u j = \u0434(x j ) = x i .\nOtherwise, because \u0434 \u2032 is non-decreasing on (\u2212\u221e, 0] and decreasing on (0, \u221e), we have that\n\u03bb \u2032 = min(\u0434 \u2032 (l j ), \u0434 \u2032 (u j )) \u2264 \u0434 \u2032 (\u03be ) for all \u03be \u2208 [l j , u j ]. Therefore, a \u2032\u2264 i (x) = \u0434(l j ) + \u03bb \u2032 \u00b7 (x j \u2212 l j ) = \u0434(l j ) + \u222b x j l j \u03bb \u2032 d\u03be \u2264 \u0434(l j ) + \u222b x j l j \u0434 \u2032 (\u03be )d\u03be = \u0434(x j ).\nThe proof of a \u2032\u2265 i (x) \u2265 x i is analogous. We conclude\nT f (\u03b3 i\u22121 (a)) = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = \u0434(x j )}. \u2286 {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 a \u2032\u2264 k (x) \u2264 x i \u2227 a \u2032\u2265 i (x) \u2265 x i } = {x \u2208 R i | (\u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k )} = \u03b3 i (T # f (a)),\nwhere the inclusion is strict because we have dropped the constraint x i = \u0434(x j ). Therefore, the abstract transformer is sound. \u25a1 Theorem 4.4. The max pool abstract transformer is sound.\n\nProof. Let f : R i\u22121 \u2192 R i execute the assignment x i \u2190 max j \u2208J (0, x j ) for some J \u2286 [i \u2212 1], and let a \u2208 A i\u22121 be arbitrary. We have\nT f (\u03b3 i\u22121 (a)) = { f (x) | x \u2208 \u03b3 i\u22121 (a)} = {(x 1 , . . . , x i\u22121 , max j \u2208J x j ) | (x 1 , . . . , x i\u22121 ) \u2208 \u03b3 i\u22121 (a)} = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = max j \u2208J x j }.\nThere are two cases. If there is some k \u2208 J with u j < l k for all j \u2208 J \\ {k}, then (\u2200k \u2208\n[i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) implies that max j \u2208J x j = x k and therefore T f (\u03b3 i\u22121 (a)) = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = max j \u2208J x j } = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = x k } = {x \u2208 R i | \u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k } = \u03b3 i (T # f (a)\n). Otherwise, the transformer chooses a k with maximal l k . We also know that (\u2200k \u2208\n[i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) implies x j \u2264 u j for all j \u2208 J , and therefore T f (\u03b3 i\u22121 (a)) = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = max j \u2208J x j )} \u2286 {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x k \u2264 x i \u2227 max j \u2208J u j \u2265 x i )} = {x \u2208 R i | \u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k } = \u03b3 i (T # f (a)). In summary, in both cases, T f (\u03b3 i\u22121 (a)) \u2286 \u03b3 i (T # f (a))\n. \u25a1 Theorem 4.5. The affine abstract transformer is sound and exact.\n\nProof. Let f :\nR i\u22121 \u2192 R i execute the assignment x i \u2190 v+ j \u2208[i\u22121] w j \u00b7x j for some v \u2208 R,w \u2208 R i\u22121 , and let a \u2208 A i\u22121 be arbitrary. We have T f (\u03b3 i\u22121 (a)) = { f (x) | x \u2208 \u03b3 i\u22121 (a)} = {(x 1 , . . . , x i\u22121 , v + j \u2208[i\u22121] w j \u00b7 x j ) | (x 1 , . . . , x i\u22121 ) \u2208 \u03b3 i\u22121 (a)} = {x \u2208 R i | (x 1 , . . . , x i\u22121 ) \u2208 \u03b3 i\u22121 (a) \u2227 x i = v + j \u2208[i\u22121] w j \u00b7 x j )} = {x \u2208 R i | (\u2200k \u2208 [i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) \u2227 x i = v + j \u2208[i\u22121] w j \u00b7 x j )} = {x \u2208 R i | \u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k } = \u03b3 i (T # f (a)). Thus, T f (\u03b3 i\u22121 (a)) = \u03b3 i (T # f (a)). \u25a1\n\nInvariant. We now prove that our abstract transformers preserve the invariant. For each of our abstract transformers\nT # f , we have to show that for T # f (a) = a \u2032 , we have \u03b3 i (a \u2032 ) \u2286 j \u2208[i] [l \u2032 j , u \u2032 j ]. Note that the constraints (\u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k )\ninclude all constraints of a. We first assume that the invariant holds for a, thus (\u2200k \u2208\n[i \u2212 1]. a \u2264 k (x) \u2264 x k \u2227 a \u2265 k (x) \u2265 x k ) implies the bounds (\u2200k \u2208 [i \u2212 1]. l k \u2264 x k \u2264 u k ), which are equivalent to (\u2200k \u2208 [i \u2212 1]. l \u2032 k \u2264 x k \u2264 u \u2032 k )\n, because our abstract transformers preserve the bounds of existing variables. It therefore suffices to show that (\u2200k \u2208\n[i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k ) implies l \u2032 i \u2264 x i \u2264 u \u2032 i .\nTheorem 4.6. The ReLU abstract transformer preserves the invariant.\nProof. If u j \u2264 0, we have a \u2032\u2264 i (x) = a \u2032\u2265 i (x) = 0 and therefore (\u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227a \u2032\u2265 k (x) \u2265 x k ) implies 0 = l \u2032 i = a \u2032\u2264 i (x) \u2264 x i \u2264 a \u2032\u2265 i (x) = u \u2032 i = 0. If 0 \u2264 l j , we have a \u2032\u2264 i (x) = a \u2032\u2265 i (x) = x j and therefore (\u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k ) implies l \u2032 i = l j \u2264 x j = x i \u2264 u j = u \u2032 i .\nOtherwise, we have l j < 0 and 0 < u j , as well as a \u2032\u2264 (\nx) i = \u03bb \u00b7 x j , a \u2032\u2265 (x) i = u j \u00b7 x j \u2212l j u j \u2212l j , and so (\u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k ) implies l \u2032 i = \u03bb \u00b7 l j \u2264 x i \u2264 u j = u \u2032 j . \u25a1\nTheorem 4.7. The sigmoid and tanh abstract transformers preserve the invariant.\nProof. The constraints (\u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k ) imply l j \u2264 x j \u2264 u j and by monotonicity of \u0434, we obtain l \u2032 i = \u0434(l j ) \u2264 x i \u2264 \u0434(u j ) = u \u2032 j using x i = \u0434(x j ). \u25a1\nTheorem 4.8. The max pool abstract transformer preserves the invariant.\n\nProof. The max pool transformer either sets a \u2032\u2264\ni (x) = a \u2032\u2265 i (x) = x k and l \u2032 i = l k and u \u2032 i = u k , in which case (\u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k ) implies l \u2032 i = l k \u2264 x k = x i \u2264 u k = u \u2032 k , or it sets a \u2032\u2264 i (x) = x k , l \u2032 i = l k and u \u2032 i = a \u2032\u2265 i (x), such that (\u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k ), which implies l \u2032 i \u2264 x k \u2264 u \u2032 i \u25a1\nTheorem 4.9. The affine abstract transformer preserves the invariant.\n\nProof. Note that s \u2032 and t \u2032 are finite, because in each step, the maximal index of a variable whose coefficient in, respectively, b s and c t is nonzero decreases by at least one. Assume \u2200k \u2208\n[i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k . We have to show that b s \u2032 (x) \u2264 x i and c t \u2032 (x) \u2265 x i . It suffices to show that \u2200s \u2208 [s \u2032 ]. b s (x) \u2264 x i and \u2200t \u2208 [t \u2032 ]. c t (x) \u2265 x i . To show \u2200s \u2208 [s \u2032 ]. b s (x) \u2264 x i , we use induction on s. We have b 1 (x) = a \u2032\u2264 i (x) \u2264 x i . Assuming b s (x) \u2264 x i and b s (x) = v \u2032 + j \u2208[k ] w \u2032 j \u00b7 x j for some k \u2208 [i \u2212 1], v \u2032 \u2208 R, w \u2032 \u2208 R k , we have x i \u2265 b s (x) = v \u2032 + j \u2208[k ] w \u2032 j \u00b7 x j = v \u2032 + j \u2208[k ] (max(0, w \u2032 j ) \u22650 \u00b7x j + min(w \u2032 j , 0) \u22640 \u00b7x j ) \u2265 v \u2032 + j \u2208[k ] (max(0, w \u2032 j ) \u00b7 a \u2032\u2264 j (x) + min(w \u2032 j , 0) \u00b7 a \u2032\u2265 j (x)) = b s+1 (x). To show \u2200t \u2208 [t \u2032 ]. c t (x) \u2265 x i , we use induction on t. We have c 1 (x) = a \u2032\u2265 i (x) \u2265 x i . Assuming c t (x) \u2265 x i and c t (x) = v \u2032 + j \u2208[k ] w \u2032 j \u00b7 x j for some k \u2208 [i \u2212 1], v \u2032 \u2208 R, w \u2032 \u2208 R k , we have x i \u2264 c t (x) = v \u2032 + j \u2208[k ] w \u2032 j \u00b7 x j = v \u2032 + j \u2208[k ] (max(0, w \u2032 j ) \u22650 \u00b7x j + min(w \u2032 j , 0) \u22640 \u00b7x j ) \u2264 v \u2032 + j \u2208[k] (max(0, w \u2032 j ) \u00b7 a \u2032\u2265 j (x) + min(w \u2032 j , 0) \u00b7 a \u2032\u2264 j (x)) = c t +1 (x). Therefore, (\u2200k \u2208 [i]. a \u2032\u2264 k (x) \u2264 x k \u2227 a \u2032\u2265 k (x) \u2265 x k ) implies l \u2032 i \u2264 x i \u2264 u \u2032 i . \u25a1\n\nSoundness under Floating Point Arithmetic\n\nThe abstract domain and its transformers above are sound under real arithmetic but unsound under floating point arithmetic if one does not take care of the rounding errors. To obtain soundness, let F be the set of floating point values and \u2295 f , \u2296 f , \u2297 f , \u2298 f be the floating point interval addition, subtraction, multiplication, and division, respectively, as defined in [Min\u00e9 2004] with lower bounds rounded towards \u2212\u221e and upper bounds rounded towards +\u221e. For a real constant c, we use c \u2212 , c + \u2208 F to denote the floating point representation of c with rounding towards \u2212\u221e and +\u221e respectively.\n\nAlgorithm 1 Rotate image I by \u03b8 degrees.\n\nprocedure Rotate(I , \u03b8 )\nInput: I \u2208 [0, 1] m\u00d7n , \u03b8 \u2208 [\u2212\u03c0 , \u03c0 ], Output: R \u2208 [0, 1] m\u00d7n for i \u2208 {1, . . . , m}, j \u2208 {1, . . . , n} do (x, y) \u2190 (j \u2212 (n + 1)/2, (m + 1)/2 \u2212 i) (x \u2032 , y \u2032 ) \u2190 (cos(\u2212\u03b8 ) \u00b7 x \u2212 sin(\u2212\u03b8 ) \u00b7 y, sin(\u2212\u03b8 ) \u00b7 x + cos(\u2212\u03b8 ) \u00b7 y) (i \u2032 low , i \u2032 high ) \u2190 (max(1, \u230a(m + 1)/2 \u2212 y \u2032 \u230b), min(m, \u2308(m + 1)/2 \u2212 y \u2032 \u2309)) (j \u2032 low , j \u2032 high ) \u2190 (max(1, \u230ax \u2032 + (n + 1)/2\u230b), min(n, \u2308x \u2032 + (n + 1)/2\u2309)) t \u2190 i \u2032 high i \u2032 =i \u2032 low j \u2032 high j \u2032 =j \u2032 low max(0, 1 \u2212 (j \u2032 \u2212 x \u2032 ) 2 + (i \u2032 \u2212 y \u2032 ) 2 ) if t 0 then R i, j \u2190 (1/t) \u00b7 i \u2032 high i \u2032 =i \u2032 low j \u2032 high j \u2032 =j \u2032 low max(0, 1 \u2212 (j \u2032 \u2212 x \u2032 ) 2 + (i \u2032 \u2212 y \u2032 ) 2 ) \u00b7 I i \u2032 , j \u2032 else R i, j \u2190 0 end if end for return R end procedure\nVerifying robustness against image rotations. Consider Algorithm 1, which rotates an m \u00d7 n-pixel (grayscale) image by an angle \u03b8 . To compute the intensity R i, j of a given output pixel, it first computes the (real-valued) position (x \u2032 , y \u2032 ) that would be mapped to the position of the center of the pixel. Then, it performs linear interpolation: it forms a convex combination of pixels in the neighborhood of (x \u2032 , y \u2032 ), such that the contribution of each pixel is proportional to the distance to (x \u2032 , y \u2032 ), cutting off contributions at distance 1.\n\nOur goal is to verify that a neural network N : R m\u00d7n \u2192 R r classifies all images obtained by rotating an input image using Algorithm 1 with an angle \u03b8 \u2208 [\u03b1, \u03b2] \u2286 [\u2212\u03c0 , \u03c0 ] in the same way. More generally, if we have an adversarial region X \u2286 R m\u00d7n (represented using componentwise interval constraints), we would like to verify that for any image I \u2208 X and any angle \u03b8 \u2208 [\u03b1, \u03b2], the neural network N classifies Rotate(I , \u03b8 ) to a given class k. This induces a new adversarial region X \u2032 = {Rotate(I, \u03b8 ) | I \u2208 X , \u03b8 \u2208 [\u03b1, \u03b2]}. Note that because we deal with regions (and not only concrete images) as well as rotations that employ linear interpolation, we cannot simply enumerate all possible rotations as done for simpler rotation algorithms and concrete images [Pei et al. 2017b].\n\nInterval specification of X \u2032 . We verify robustness against rotations by deriving lower and upper bounds on the intensities of all pixels of the rotated image. We then verify that the neural network classifies all images satisfying those bounds to class k. To obtain bounds, we apply abstract interpretation to Algorithm 1, using the interval domain (more powerful numerical domains could be applied). We use standard interval domain transformers, except to derive bounds on t and R i, j , which we compute (at the same time), by enumerating all possible integer values of i \u2032 low , i \u2032 high , j \u2032 low and j \u2032 high (respecting the constraints i \u2032 low + 1 \u2265 i \u2032 high and j \u2032 low + 1 \u2265 j \u2032 high , and refining the intervals for x \u2032 and y \u2032 based on the known values i \u2032 low and j \u2032 low ) and joining the intervals resulting from each case. For each case, we compute intervals for R i, j in two ways: once using interval arithmetic, restricting partial sums to the interval [0, 1], and once by observing that a convex combination of pixel values will be contained in the union of intervals for the individual values. We intersect the intervals resulting from both approaches. [\u03b1, \u03b2], the derived bounds often become too imprecise. Thus, when our analyzer is invoked with these bounds, it may fail to verify the property, even though it actually holds. We can make the following simple observation: if we have n sets X \u2032 1 , . . . , X \u2032 n that cover the adversarial region X \u2032 , i.e. X \u2032 \u2286 n i=1 X \u2032 i , then it suffices to verify that the neural network N classifies all input images to class k for each individual input region X \u2032 i for i \u2208 {1, . . . , n}. We obtain X \u2032 1 , . . . , X \u2032 n by subdividing the interval [\u03b1, \u03b2] into n equal parts: {Rotate(I , \u03b8 ) | I \u2208 X , \u03b8 \u2208 [(i \u2212 1)/n \u00b7 (\u03b2 \u2212 \u03b1) + \u03b1, i/n \u00b7 (\u03b2 \u2212 \u03b1) + \u03b1]} \u2286 X \u2032 i . Note that each X \u2032 i is obtained by running the interval analysis on the rotation code with the given angle interval and the adversarial region X . After obtaining all X \u2032 i 's, we run our neural network analyzer separately with each X \u2032 i as input. Batching. As interval analysis tends to be imprecise for large input intervals, we usually need to subdivide the interval [\u03b1, \u03b2] into many parts to obtain precise enough output intervals from the interval analysis (a form of trace partitioning [Rival and Mauborgne 2007]). Running our neural network analysis for each of these can be too expensive. Instead, we use a separate refinement step to obtain more precise interval bounds for larger input intervals. We further subdivide each of the n intervals into m parts each, for a total of n \u00b7 m intervals in n batches. For each of the n batches, we then run interval analysis m times, once for each part, and combine the results using a join, i.e., we compute the smallest common bounding box of all output regions in a batch. The additional refinement within each batch preserves dependencies between variables that a plain interval analysis would ignore, and thus yields more precise boxes X \u2032 1 , . . . , X \u2032 n , on which we run the neural network analysis.\n\n\nRefinement of abstract inputs by trace partitioning. For large enough intervals\n\nUsing the approach outlined above, we were able to verify, for the first time, that the neural network is robust to non-trivial rotations of all images inside an adversarial region.\n\n\nEXPERIMENTAL EVALUATION\n\nIn this section we evaluate the effectiveness of our approach for verifying the robustness properties of large, challenging, and diverse set of neural networks. We implemented our method in an analyzer called DeepPoly. The analyzer is written in Python and the abstract transformers of our domain are implemented on top of the ELINA library [Singh et al. 2017[Singh et al. , 2018b for numerical abstractions. We have implemented both a sequential and a parallel version of our transformers. All code, networks, datasets, and results used in our evaluation are available at http://safeai.ethz.ch. We compared the precision and performance of DeepPoly against the three state-of-the-art systems that can scale to larger networks:\n\n\u2022 AI 2 by  uses the Zonotope abstract domain [Ghorbal et al. 2009] implemented in ELINA for performing abstract interpretation of feedforward and convolutional ReLU networks. Their transformers are generic and do not exploit the structure of ReLU. As a result, AI 2 is often slow and imprecise. \u2022 Fast-Lin by Weng et al. [2018] performs layerwise linear approximations tailored to exploit the structure of ReLU feedforward networks. We note that Fast-Lin is not sound under floating point arithmetic and does not support convolutional networks. Nonetheless, we still compare to it despite the fact it may contain false negatives (adapting their method to be sound in floating point arithmetic is non-trivial). \u2022 DeepZ by Singh et al. [2018a] provides specialized Zonotope transformers for handling ReLU, sigmoid, and tanh activations, and supports both feedforward and convolutional networks. It is worth mentioning that although Fast-Lin and DeepZ employ very different techniques for robustness analysis, both can be shown to have the same precision on feedforward neural networks with ReLU activations. On our benchmarks, DeepZ was often faster than Fast-Lin. Our experimental results indicate that DeepPoly is always more precise than all three competing tools on our benchmarks while maintaining scalability. This demonstrates the suitability of DeepPoly for the task of robustness verification of larger neural networks.\n\n\nExperimental Setup\n\nAll of our experiments for the feedforward networks were run on a 3.3 GHz 10 core Intel i9-7900X Skylake CPU with a main memory of 64 GB; our experiments for the convolutional networks were run on a 2.6 GHz 14 core Intel Xeon CPU E5-2690 with 512 GB of main memory. We next describe our experimental setup including the datasets, neural networks, and robustness properties.\n\nEvaluation datasets. We used the popular MNIST [Lecun et al. 1998] and CIFAR10 [Krizhevsky 2009] image datasets for our experiments. MNIST contains grayscale images of size 28 \u00d7 28 pixels and CIFAR10 consists of RGB images of size 32 \u00d7 32 pixels. For our evaluation, we chose the first 100 images from the test set of each dataset. For the task of robustness certification, out of these 100 images, we considered only those that were correctly classified by the neural network.\n\nNeural networks. Table 1 shows the MNIST and the CIFAR10 neural network architectures used in our experiments. The architectures considered in our evaluation contain up to 88K hidden units. We use networks trained with adversarial training, i.e., defended against adversarial attacks, as well as undefended networks. We used DiffAI by  and projected gradient descent (PGD) from Dong et al. [2018] for adversarial training. In our evaluation, when we consider the certified robustness of the defended and undefended networks with the same architecture together, we append the suffix Point to the name of a neural network trained without adversarial training and the name of the training procedure (either DiffAI or PGD) to the name of a defended network. In the table, the FFNNSigmoid and FFNNTanh networks use sigmoid and tanh activations, respectively. All other networks use ReLU activations. The FFNNSmall and FFNNMed network architectures for both MNIST and CIFAR10 datasets were taken from  whereas the FFNNBig architectures were taken from Weng et al. [2018]. The ConvSmall, ConvBig, and ConvSuper architectures were taken from .\n\nRobustness properties. We consider the following robustness properties:\n\n(1) L \u221e -norm [Carlini and Wagner 2017]: This attack is parameterized by a constant \u03f5. The adversarial region contains all perturbed images x \u2032 where each pixel x \u2032 i has a distance of at most \u03f5 from the corresponding pixel x i in the original input x. We use different values of \u03f5 in our experiments. In general, we use smaller \u03f5 values for the CIFAR10 dataset compared to the MNIST dataset since the CIFAR10 networks are known to be less robust against L \u221e -norm attacks for larger \u03f5 values [Weng et al. 2018].\n\n(2) Rotation: The input image is first perturbed using a perturbation bounded by \u03f5 in the L \u221enorm. The resulting image is then rotated by Algorithm 1 using an arbitrary \u03b8 \u2208 [\u03b1, \u03b2]. The region R x,\u03f5, [\u03b1, \u03b2 ] contains all images that can be obtained in this way.  \n\n\nL \u221e -Norm Perturbation\n\nWe first compare the precision and performance of DeepPoly vs AI 2 , Fast-Lin, and DeepZ for robustness certification against L \u221e -norm based adversarial attacks on the MNIST FFNNSmall network. We note that it is straightforward to parallelize Fast-Lin, DeepZ, and DeepPoly. However, the abstract transformers in AI 2 cannot be efficiently parallelized. To ensure fairness, we ran all four analyzers in single threaded mode. Fig. 5 compares the percent of robustness properties proved and the average runtime per \u03f5-value of all four analyzers. We used six different values for \u03f5 shown on the x-axis. For all analyzers, the number of proved properties decreases with increasing values of \u03f5. As can be seen, DeepPoly is the fastest and the most precise analyzer on the FFNNSmall network. DeepZ has the exact same precision as Fast-Lin but is up to 2.5x faster. AI 2 has significantly worse precision and higher runtime than all other analyzers.\n\nFor all of our remaining experiments, we compare the precision and performance of the parallelized versions of DeepPoly and DeepZ.\n\nMNIST fully connected feedforward networks. robustness for \u03f5 = 0.01, we notice that DeepPoly proves 69% of properties on the FFNNMed network whereas DeepZ proves 46%. The corresponding numbers on the FFNNBig network are 79% and 58% respectively. DeepPoly is also significantly faster than DeepZ on both networks achieving a speedup of up to 4x and 2.5x on the FFNNMed and FFNNBig networks.\n\nWe compare the average percentage of the number of hidden units that can take both positive and negative values per \u03f5-value for the MNIST FFNNSmall and FFNNMed neural networks in Fig. 7. Since the ReLU transformer in both DeepPoly and DeepZ is inexact for such hidden units, it is important to reduce their percentage. For both networks, DeepPoly produces strictly less hidden units for which the ReLU transformer is inexact than DeepZ.\n\nIn Fig. 8, we compare the precision of DeepPoly and DeepZ on the MNIST FFNNSigmoid and FFNNTanh networks. Both networks were trained using PGD-based adversarial training. On both networks, DeepPoly is strictly more precise than DeepZ. For the FFNNSigmoid network, there is a sharp decline in the number of proved properties by DeepZ starting at \u03f5 = 0.02. DeepZ proves only 23% of the properties when \u03f5 = 0.03; in contrast, DeepPoly proves 80%. Similarly, for the FFNNTanh network, DeepZ only proves 1% of properties when \u03f5 = 0.015, whereas DeepPoly proves 94%. We also note that DeepPoly is more than 2x faster than DeepZ on both these networks (we omit the MNIST convolutional networks. Fig. 9 compares the precision and the average runtime of DeepPoly vs DeepZ on the MNIST ConvSmall networks. We consider three types of ConvSmall networks based on their training method: (a) undefended (Point), (b) defended with PGD (PGD), and (c) defended with DiffAI (DiffAI). Note that our convolutional networks are more robust than the feedforward networks and thus the values of \u03f5 considered in our experiments are higher than those for feedforward networks.\n\nAs expected, both DeepPoly and DeepZ prove more properties on the defended networks than on the undefended one. We notice that the ConvSmall network trained with DiffAI is provably more  robust. Overall, DeepPoly proves more properties than DeepZ on all neural networks. The difference between the number of properties proved by DeepPoly and DeepZ is higher for larger values of \u03f5. It is interesting to note that on the DiffAI defended network, DeepZ proves slightly more properties than DeepPoly for \u03f5 \u2264 0.10. However, for \u03f5 = 0.12, the percentage of properties proved by DeepZ drops to 53% whereas DeepPoly proves 70% of the robustness properties. We notice that DeepPoly is slower than DeepZ on all ConvSmall networks. This is due to the fact that the assigned expressions during affine transforms in the convolutional layers are sparse. The Zonotope representation in DeepZ allows the corresponding transformers to utilize this sparsity better than our domain. We also note that DeepPoly is up to 2x faster on the DiffAI network as compared to the other two networks. Table 2 shows our experimental results on the larger MNIST convolutional networks trained using DiffAI. For the ConvBig network, DeepPoly proves significantly more than DeepZ for \u03f5 = 0.3. For the ConvSuper network, DeepPoly has the same precision as DeepZ for \u03f5 = 0.1 and proves 97% of robustness properties. On both these networks, DeepPoly is slower than DeepZ. CIFAR10 feedforward networks. Fig. 10 compares DeepPoly against DeepZ on the CIFAR10 feedforward networks. As with the MNIST feedforward networks, DeepPoly verifies more properties than DeepZ and is faster on all the considered networks. Considering \u03f5 = 0.001, DeepPoly proves 65%, 53%, and 84% of properties on the FFNNSmall, FFNNMed, and FFNNBig networks respectively whereas DeepZ proves 42%, 33%, and 64% of properties. Notice that the average runtime of both DeepPoly and DeepZ on the CIFAR10 FFNNMed is higher than on the MNIST FFNNMed network even though the number of hidden units is the same. The slowdown on the CIFAR10 networks is due to the higher number of input pixels. DeepPoly is up to 7x, 5x, and 4.5x faster than DeepZ on the FFNNSmall, FFNNMed, and FFNNBig networks, respectively. CIFAR10 convolutional networks. Fig. 11 evaluates DeepPoly and DeepZ on the CIFAR10 ConvSmall networks. We again consider undefended (Point) networks and networks defended with PGD and DiffAI. We again notice that the ConvSmall network trained with DiffAI is the most provably robust network. DeepPoly overall proves more properties than DeepZ on all networks. As with the MNIST ConvSmall network defended with DiffAI, DeepZ is slightly more precise than DeepPoly for \u03f5 = 0.008; however, DeepPoly proves more properties for \u03f5 = 0.012. DeepPoly is slower than DeepZ on all the considered ConvSmall networks.\n\nThe last two rows in Table 2 compare the precision and performance of DeepPoly and DeepZ on the CIFAR10 ConvBig convolutional network trained with DiffAI. It can be seen that DeepPoly proves more properties than DeepZ for both \u03f5 = 0.006 and \u03f5 = 0.008. \n\n\nRotation Perturbation\n\nAs described in earlier sections, we can apply refinement to the input so to prove a neural network robust against rotations of a certain input image. Specifically, our analysis can prove that the MNIST FFNNSmall network classifies a given image of the digit 3 correctly, even if each pixel is first L \u221e -perturbed with \u03f5 \u2264 0.001 and then rotated using an arbitrary angle \u03b8 between \u221245 and 65 degrees. Fig. 12 shows example regions and analysis times for a number of choices of parameters to the refinement approach. For example, #Batches = 220, Batch Size = 300 means that we split the interval [\u03b1, \u03b2] into n = 220 batches. To analyze a batch, we split the corresponding interval into m = 300 input intervals for interval analysis, resulting in 300 regions for each batch. We then run DeepPoly on the smallest common bounding boxes of all regions in each batch, 220 times in total. Fig. 12 shows a few such bounding boxes in the Regions column. Note that it is not sufficient to compute a single region that captures all rotated images. Fig. 12 shows two such attempts: one where we did not use batching (therefore, our interval analysis approach was applied  to the rotation algorithm using an abstract \u03b8 covering the entire range), and one where we used a batch size of 10, 000 to compute the bounding box of the perturbations rather precisely. However, those perturbations cannot be captured well using interval constraints, therefore the bounding box contains many spurious inputs and the verification fails. We then considered two verification attempts with 220 batches, with each batch covering a range of \u03b8 of length 0.5 degrees. It was not sufficient to use a batch size of 1, as some input intervals become large. Using a batch size of 300, the neural network can be proved robust for this perturbation.\n\n\nRELATED WORK\n\nWe already extensively discussed the works that are most closely related throughout the paper, here we additionally elaborate on several others.  Bastani et al. [2016] under-approximate the behavior of the network under L \u221e -norm based perturbation and formally define metrics of adversarial frequency and adversarial severity to evaluate the robustness of a neural network against adversarial attack.\n\nFormal verification of neural network robustness. Existing formal verifiers of neural network robustness can be broadly classified as either complete or incomplete. Complete verifiers do not have false positives but have limited scalability and cannot handle neural networks containing more than a few hundred hidden units whereas incomplete verifiers approximate for better scalability. Complete verifiers are based on SMT solving [Ehlers 2017;, mixed integer linear programming [Tjeng and Tedrake 2017] or input refinement [Wang et al. 2018] whereas existing incomplete verifiers are based on duality [Dvijotham et al. 2018;Raghunathan et al. 2018], abstract interpretation Singh et al. 2018a], and linear approximations [Weng et al. 2018;Wong and Kolter 2018]. We note that although our verifier is designed to be incomplete for better scalability, it can be made complete by refining the input iteratively.\n\nAdversarial training. There is growing interest in adversarial training where neural networks are trained against a model of adversarial attacks. Gu and Rigazio [2014] add Gaussian noise to the training set and remove it statistically for defending against adversarial examples. The approach of Goodfellow et al. [2015] first generates adversarial examples misclassified by neural networks and then designs a defense against this attack by explicitly training against perturbations generated by the attack. Madry et al. [2018] shows that training against an optimal attack also guards against nonoptimal attacks. While this was effective in experiments,  demonstrated an attack for the safety-critical problem of ground-truthing, where this defense occasionally exacerbated the problem.  train neural networks against adversarial attacks using abstract transformers for the Zonotope domain. As mentioned earlier, our abstract transformers can be plugged into such a framework to potentially improve the training results.\n\n\nCONCLUSION\n\nWe introduced a new method for certifying deep neural networks which balances analysis precision and scalability. The core idea is an abstract domain based on floating point polyhedra and intervals equipped with abstract transformers specifically designed for common neural network functions such as affine transforms, ReLU, sigmoid, tanh, and maxpool. These abstract transformers enable us to soundly handle both, feed-forward and convolutional networks.\n\nWe implemented our method in an analyzer, called DeepPoly, and evaluated it extensively on a wide range of networks of different sizes including defended and undefended networks. Our experimental results demonstrate that DeepPoly is more precise than prior work yet can handle large networks.\n\nWe also showed how to use DeepPoly to prove, for the first time, the robustness of a neural network when the input image is perturbed by complex transformations such as rotations employing linear interpolation.\n\nWe believe this work is a promising step towards more effective reasoning about deep neural networks and a useful building block for proving interesting specifications as well as other applications of analysis (for example, training more robust networks).\n\n\nACKNOWLEDGMENTS\n\nWe would like to thank the anonymous reviewers for their constructive feedback. This research was supported by the Swiss National Science Foundation (SNF) grant number 163117.\n\nFig. 1 .\n1Two different attacks applied to MNIST images.\n\nFig. 2 .\n2Example feedforward neural network with ReLU activations.\n\n0 Fig. 3 .\n03The neural network from Fig. 2 transformed for analysis with the abstract domain.\n\nFig. 4 .\n4Convex approximations for the ReLU function: (a) shows the convex approximation with the minimum area in the input-output plane, (b) and (c) show the two convex approximations proposed in this paper. In the figure, \u03bb = u i /(u i \u2212 l i ) and \u00b5 = \u2212l i u i /(u i \u2212 l i ).\n\nFig. 5 .\n5Verified robustness and runtime for L \u221e -norm perturbations by DeepPoly against AI 2 , Fast-Lin, and DeepZ on the MNIST FFNNSmall. DeepZ and Fast-Lin are equivalent in robustness.\n\nFig. 6 .\n6Fig. 6compares the percentage of verified robustness properties and the average runtime of DeepPoly against DeepZ on the MNIST FFNNMed and FFNNBig neural networks. Both networks were trained without adversarial training. DeepPoly proves more properties than DeepZ on both networks. As an example, considering the verified Verified robustness and runtime for L \u221e -norm perturbations by DeepPoly vs. DeepZ on the MNIST FFNNMed and FFNNBig networks.\n\nFig. 7 .Fig. 8 .\n78Average percentage of hidden units that can take both positive and negative values for DeepPoly vs. DeepZ on the MNIST FFNNSmall and FFNNMed networks. Verified robustness and runtime for L \u221e -norm perturbations by DeepPoly vs. DeepZ on the MNIST FFNNSigmoid and FFNNTanh networks. relevant plots here as timings do not change with increasing values of \u03f5): DeepZ has an average runtime of \u2264 35 seconds on both networks whereas DeepPoly has an average runtime of \u2264 15 seconds on both.\n\nFig. 9 .\n9Verified robustness and runtime for L \u221e -norm perturbations by DeepPoly vs. DeepZ on the MNIST ConvSmall networks.\n\nFig. 10 .\n10Verified robustness and runtime for L \u221e -norm perturbations by DeepPoly vs. DeepZ on the CIFAR10 fully connected feedforward networks.\n\nFig. 12 .\n12Results for robustness against rotations with the MNIST FFNNSmall network. Each row shows a different attempt to prove that the given image of the digit 3 can be perturbed within an L \u221e ball of radius \u03f5 = 0.001 and rotated by an arbitrary angle \u03b8 between \u221245 to 65 degrees without changing its classification. For the second two attempts, we show 4 representative combined regions (out of 220, one per batch). The running time is split into two components: (i) the time used for interval analysis on the rotation algorithm and (ii), the time used to prove the neural network robust with all of the computed bounding boxes (using DeepPoly).\n\nTable 1 .\n1Neural network architectures used in our experiments.Dataset \nModel \nType \n#Hidden units #Hidden layers \n\nMNIST \nFFNNSmall \nfully connected \n610 \n6 \nFFNNMed \nfully connected \n1 810 \n9 \nFFNNBig \nfully connected \n4 106 \n4 \nFFNNSigmoid \nfully connected \n3 010 \n6 \n\nFFNNTanh \nfully connected \n3 010 \n6 \nConvSmall \nconvolutional \n3 604 \n3 \nConvBig \nconvolutional \n34 688 \n6 \nConvSuper \nconvolutional \n88 500 \n6 \n\nCIFAR10 FFNNSmall \nfully connected \n6 10 \n6 \nFFNNMed \nfully connected \n1 810 \n9 \n\nFFNNBig \nfully connected \n7 178 \n7 \n\nConvSmall \nconvolutional \n4 852 \n3 \n\nConvBig \nconvolutional \n62 464 \n6 \n\n\n\nTable 2 .\n2Verified robustness by DeepZ and DeepPoly on the large convolutional networks trained with DiffAI.Dataset \nModel \n\u03f5 % Verified robustness \nAverage runtime \n\nDeepZ \nDeepPoly \nDeepZ DeepPoly \n\nMNIST \nConvBig \n0.1 \n97 \n97 \n5 \n50 \nConvBig \n0.2 \n79 \n78 \n7 \n61 \nConvBig \n0.3 \n37 \n43 \n17 \n88 \nConvSuper \n0.1 \n97 \n97 \n133 \n400 \n\nCIFAR10 ConvBig \n0.006 \n50 \n52 \n39 \n322 \nConvBig \n0.008 \n33 \n40 \n46 \n331 \n\n\n\n\nFig. 11. Verified robustness and runtime for L \u221e -norm perturbations by DeepPoly vs. DeepZ on the CIFAR10 ConvSmall networks.0.002 \n0.004 \n0.006 \n0.008 \n0.010 \n0.012 \n\n0% \n\n50% \n\n100% \n\nVerified robustness \n\nDiffAI_DeepZ \nDiffAI_DeepPoly \nPGD_DeepZ \nPGD_DeepPoly \nPoint_DeepZ \nPoint_DeepPoly \n\n(a) CIFAR10 ConvSmall \n\n0.002 \n0.004 \n0.006 \n0.008 \n0.010 \n0.012 \n\n0 \n\n10 \n\n20 \n\n30 \n\n40 \n\nTime (s) \n\nDiffAI_DeepZ \nDiffAI_DeepPoly \nPGD_DeepZ \nPGD_DeepPoly \nPoint_DeepZ \nPoint_DeepPoly \n\n(b) CIFAR10 ConvSmall \n\n\n\n\nGenerating adversarial examples. There is considerable interest in constructing examples that make the neural network misclassify an input. Nguyen et al. [2015] find adversarial examples without starting from a test point, Tabacof and Valle [2016] use random perturbations for generating adversarial examples, Sabour et al. [2015] demonstrate non-robustness of intermediate layers, and Grosse et al. [2016] generate adversarial examples for malware classification. Pei et al. [2017a] systematically generate adversarial examples covering all neurons in the network.\nProc. ACM Program. Lang., Vol. 3, No. POPL, Article 41. Publication date: January 2019.\nWe use the standard interval linear form, where the coefficients in the constraints are intervals instead of scalars, to define an abstract element a \u2208 A n over n variables in our domain as a tuple a = \u27e8a \u2264 , a \u2265 , l, u\u27e9 where for i \u2208 [n]:For a floating point interval[l, u], let inf and sup be functions that return its lower and upper bound. The concretization function \u03b3 n : A n \u2192 P(F n ) is given byWe next modify our abstract transformers for soundness under floating point arithmetic. It is straightforward to modify the maxpool transformer so we only show our modifications for the ReLU, sigmoid, tanh, and affine abstract transformers assigning to the variable x i .ReLU abstract transformer. It is straightforward to handle the cases l j \u2265 0 or u j \u2264 0. For the remaining case, we add the following constraints:. Finally, we set l i = \u03bb \u00b7 l j and u i = u j . Sigmoid and tanh abstract transformers. We consider the case when l j < 0. We soundly compute an interval for the possible values of \u03bb under any rounding mode as. Similarly, both \u0434 \u2032 (l j ) and \u0434 \u2032 (u j ) are soundly abstracted by the intervals [\u0434 \u2032 (l j ) \u2212 , \u0434 \u2032 (l j ) + ] and [\u0434 \u2032 (u j ) \u2212 , \u0434 \u2032 (u j ) + ], respectively. Because of the limitations of the floating point format, it can happen that the upper polyhedral constraint with slope \u03bb passing through l j intersects the curve at a point < u j . This happens frequently for smaller perturbations. To ensure soundness, we detect such cases and return the box [\u0434(l j ) \u2212 , \u0434(u j ) + ]. Other computations for the transformers can be handled similarly.Affine abstract transformer. The affine abstract transformerWe modify the backsubstitution for the computation of l i and u i . Formally, if we want to obtainHere, [\u03b8 \u2212 l , \u03b8 + l ] \u2208 F are the floating point values of the lower bound of the interval [w \u2032\u2212 j , w \u2032+ j ]\u2297 f [l j , u j ] rounded towards \u2212\u221e and +\u221e respectively. We iterate until we reachi.e., s \u2032 is the smallest number with this property. We then set l \u2032 i = v \u2032\u2032\u2212 . We compute u \u2032 i analogously.REFINEMENT OF ANALYSIS RESULTSIn this section, we show how to apply a form of abstraction refinement based on trace partitioning[Rival and Mauborgne 2007]in order to verify robustness for more complex adversarial regions, which cannot be accurately represented using a set of interval constraints. In particular, we will show how to handle adversarial regions that, in addition to permitting small perturbations to each pixel, allow the adversary to rotate the input image by an angle \u03b8 \u2208 [\u03b1, \u03b2] within an interval.\nArtificial neural networks in medical diagnosis. Filippo Amato, Alberto L\u00f3pez, Eladia Mar\u00eda Pe\u00f1a-M\u00e9ndez, Petr Va\u0148hara, Ale\u0161 Hampl, Josef Havel, Journal of Applied Biomedicine. 11Filippo Amato, Alberto L\u00f3pez, Eladia Mar\u00eda Pe\u00f1a-M\u00e9ndez, Petr Va\u0148hara, Ale\u0161 Hampl, and Josef Havel. 2013. Artificial neural networks in medical diagnosis. Journal of Applied Biomedicine 11, 2 (2013), 47 \u015b 58.\n\nMeasuring Neural Net Robustness with Constraints. Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vytiniotis, Aditya V Nori, Antonio Criminisi, Proc. Neural Information Processing Systems (NIPS). 2621\u015b2629. Neural Information essing Systems (NIPS). 2621\u015b2629Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vytiniotis, Aditya V. Nori, and Antonio Criminisi. 2016. Measuring Neural Net Robustness with Constraints. In Proc. Neural Information Processing Systems (NIPS). 2621\u015b2629.\n\nEnd to End Learning for Self-Driving Cars. Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, Karol Zieba, CoRR abs/1604.07316Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, and Karol Zieba. 2016. End to End Learning for Self-Driving Cars. CoRR abs/1604.07316 (2016).\n\n. Nicholas Carlini, Guy Katz, Clark Barrett, David L Dill, abs/1709.10207Ground-Truth Adversarial Examples. CoRRNicholas Carlini, Guy Katz, Clark Barrett, and David L. Dill. 2017. Ground-Truth Adversarial Examples. CoRR abs/1709.10207 (2017).\n\nTowards Evaluating the Robustness of Neural Networks. Nicholas Carlini, David A Wagner, Proc. IEEE Symposium on Security and Privacy (SP). IEEE Symposium on Security and Privacy (SP)Nicholas Carlini and David A. Wagner. 2017. Towards Evaluating the Robustness of Neural Networks. In Proc. IEEE Symposium on Security and Privacy (SP). 39\u015b57.\n\nAutomatic Discovery of Linear Restraints Among Variables of a Program. Patrick Cousot, Nicolas Halbwachs, Proc. Principles of Programming Languages (POPL). 84\u015b96. Principles of Programming Languages (POPL). 84\u015b96Patrick Cousot and Nicolas Halbwachs. 1978. Automatic Discovery of Linear Restraints Among Variables of a Program. In Proc. Principles of Programming Languages (POPL). 84\u015b96.\n\nBoosting adversarial attacks with momentum. Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, Jianguo Li, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and Jianguo Li. 2018. Boosting adversarial attacks with momentum. In Proc. Computer Vision and Pattern Recognition (CVPR).\n\nA Dual Approach to Scalable Verification of Deep Networks. Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, Pushmeet Kohli, Proc. Uncertainty in Artificial Intelligence (UAI). 162\u015b171. Uncertainty in Artificial Intelligence (UAI). 162\u015b171Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, and Pushmeet Kohli. 2018. A Dual Approach to Scalable Verification of Deep Networks. In Proc. Uncertainty in Artificial Intelligence (UAI). 162\u015b171.\n\nFormal Verification of Piece-Wise Linear Feed-Forward Neural Networks. R\u00fcdiger Ehlers, Proc. Automated Technology for Verification and Analysis (ATVA). 269\u015b286. Automated Technology for Verification and Analysis (ATVA). 269\u015b286R\u00fcdiger Ehlers. 2017. Formal Verification of Piece-Wise Linear Feed-Forward Neural Networks. In Proc. Automated Technology for Verification and Analysis (ATVA). 269\u015b286.\n\nAI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation. Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, Martin Vechev, Proc. IEEE Symposium on Security and Privacy (SP). IEEE Symposium on Security and Privacy (SP)Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Martin Vechev. 2018. AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation. In Proc. IEEE Symposium on Security and Privacy (SP), Vol. 00. 948\u015b963.\n\nThe Zonotope Abstract Domain Taylor1+. Khalil Ghorbal, Eric Goubault, Sylvie Putot, Proc. Computer Aided Verification (CAV). 627\u015b633. Computer Aided Verification (CAV). 627\u015b633Khalil Ghorbal, Eric Goubault, and Sylvie Putot. 2009. The Zonotope Abstract Domain Taylor1+. In Proc. Computer Aided Verification (CAV). 627\u015b633.\n\nExplaining and Harnessing Adversarial Examples. Ian Goodfellow, Jonathon Shlens, Christian Szegedy, Proc. International Conference on Learning Representations. International Conference on Learning RepresentationsICLRIan Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and Harnessing Adversarial Examples. In Proc. International Conference on Learning Representations (ICLR).\n\nAdversarial Perturbations Against Deep Neural Networks for Malware Classification. Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, Patrick D Mcdaniel, CoRR abs/1606.04435Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, and Patrick D. McDaniel. 2016. Adversarial Perturbations Against Deep Neural Networks for Malware Classification. CoRR abs/1606.04435 (2016). http://arxiv.org/ abs/1606.04435\n\nShixiang Gu, Luca Rigazio, arXiv:1412.5068Towards deep neural network architectures robust to adversarial examples. arXiv preprintShixiang Gu and Luca Rigazio. 2014. Towards deep neural network architectures robust to adversarial examples. arXiv preprint arXiv:1412.5068 (2014).\n\nReluplex: An Efficient SMT Solver for Verifying Deep Neural Networks. Guy Katz, Clark W Barrett, David L Dill, Kyle Julian, Mykel J Kochenderfer, Proc. International Conference on Computer Aided Verification (CAV). 97\u015b117. International Conference on Computer Aided Verification (CAV). 97\u015b117Guy Katz, Clark W. Barrett, David L. Dill, Kyle Julian, and Mykel J. Kochenderfer. 2017. Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks. In Proc. International Conference on Computer Aided Verification (CAV). 97\u015b117.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Technical ReportAlex Krizhevsky. 2009. Learning multiple layers of features from tiny images. Technical Report.\n\nGradient-based learning applied to document recognition. Yann Lecun, L\u00e9on Bottou, Yoshua Bengio, Patrick Haffner, Proc. of the IEEE. of the IEEEYann Lecun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-based learning applied to document recognition. In Proc. of the IEEE. 2278\u015b2324.\n\nTowards deep learning models resistant to adversarial attacks. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu, Proc. International Conference on Learning Representations. International Conference on Learning RepresentationsICLRAleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. 2018. Towards deep learning models resistant to adversarial attacks. In Proc. International Conference on Learning Representations (ICLR).\n\nRelational Abstract Domains for the Detection of Floating-Point Run-Time Errors. Antoine Min\u00e9, Proc. European Symposium on Programming (ESOP). European Symposium on Programming (ESOP)Antoine Min\u00e9. 2004. Relational Abstract Domains for the Detection of Floating-Point Run-Time Errors. In Proc. European Symposium on Programming (ESOP). 3\u015b17.\n\nDifferentiable Abstract Interpretation for Provably Robust Neural Networks. Matthew Mirman, Timon Gehr, Martin Vechev, Proc. International Conference on Machine Learning (ICML). International Conference on Machine Learning (ICML)Matthew Mirman, Timon Gehr, and Martin Vechev. 2018. Differentiable Abstract Interpretation for Provably Robust Neural Networks. In Proc. International Conference on Machine Learning (ICML). 3575\u015b3583.\n\nDeep neural networks are easily fooled: High confidence predictions for unrecognizable images. Anh Mai Nguyen, Jason Yosinski, Jeff Clune, Proc. IEEE Computer Vision and Pattern Recognition (CVPR). 427\u015b436. IEEE Computer Vision and Pattern Recognition (CVPR). 427\u015b436Anh Mai Nguyen, Jason Yosinski, and Jeff Clune. 2015. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proc. IEEE Computer Vision and Pattern Recognition (CVPR). 427\u015b436.\n\nDeepXplore: Automated Whitebox Testing of Deep Learning Systems. Kexin Pei, Yinzhi Cao, Junfeng Yang, Suman Jana, Proc. Symposium on Operating Systems Principles (SOSP). 1\u015b18. Symposium on Operating Systems Principles (SOSP). 1\u015b18Kexin Pei, Yinzhi Cao, Junfeng Yang, and Suman Jana. 2017a. DeepXplore: Automated Whitebox Testing of Deep Learning Systems. In Proc. Symposium on Operating Systems Principles (SOSP). 1\u015b18.\n\nTowards Practical Verification of Machine Learning: The Case of Computer Vision Systems. Kexin Pei, Yinzhi Cao, Junfeng Yang, Suman Jana, CoRR abs/1712.01785Kexin Pei, Yinzhi Cao, Junfeng Yang, and Suman Jana. 2017b. Towards Practical Verification of Machine Learning: The Case of Computer Vision Systems. CoRR abs/1712.01785 (2017).\n\nCertified Defenses against Adversarial Examples. Aditi Raghunathan, Jacob Steinhardt, Percy Liang, Proc. International Conference on Machine Learning (ICML). International Conference on Machine Learning (ICML)Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. 2018. Certified Defenses against Adversarial Examples. In Proc. International Conference on Machine Learning (ICML).\n\nThe Trace Partitioning Abstract Domain. Xavier Rival, Laurent Mauborgne, ACM Trans. Program. Lang. Syst. 295Xavier Rival and Laurent Mauborgne. 2007. The Trace Partitioning Abstract Domain. ACM Trans. Program. Lang. Syst. 29, 5 (2007).\n\nAdversarial Manipulation of Deep Representations. Sara Sabour, Yanshuai Cao, Fartash Faghri, David J Fleet, CoRR abs/1511.05122Sara Sabour, Yanshuai Cao, Fartash Faghri, and David J. Fleet. 2015. Adversarial Manipulation of Deep Representations. CoRR abs/1511.05122 (2015).\n\nFast and Effective Robustness Certification. Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus P\u00fcschel, Martin Vechev, Proc. Neural Information Processing Systems (NIPS). Neural Information essing Systems (NIPS)Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus P\u00fcschel, and Martin Vechev. 2018a. Fast and Effective Robustness Certification. In Proc. Neural Information Processing Systems (NIPS).\n\nFast Polyhedra Abstract Domain. Gagandeep Singh, Markus P\u00fcschel, Martin Vechev, Proc. Principles of Programming Languages (POPL). 46\u015b59. Principles of Programming Languages (POPL). 46\u015b59Gagandeep Singh, Markus P\u00fcschel, and Martin Vechev. 2017. Fast Polyhedra Abstract Domain. In Proc. Principles of Programming Languages (POPL). 46\u015b59.\n\nA Practical Construction for Decomposing Numerical Abstract Domains. Gagandeep Singh, Markus P\u00fcschel, Martin Vechev, Proc. ACM Program. Lang. 228POPLGagandeep Singh, Markus P\u00fcschel, and Martin Vechev. 2018b. A Practical Construction for Decomposing Numerical Abstract Domains. Proc. ACM Program. Lang. 2, POPL (2018), 55:1\u015b55:28.\n\nExploring the space of adversarial images. Pedro Tabacof, Eduardo Valle, Proc. International Joint Conference on Neural Networks (IJCNN). 426\u015b433. International Joint Conference on Neural Networks (IJCNN). 426\u015b433Pedro Tabacof and Eduardo Valle. 2016. Exploring the space of adversarial images. In Proc. International Joint Conference on Neural Networks (IJCNN). 426\u015b433.\n\nVerifying Neural Networks with Mixed Integer Programming. Vincent Tjeng, Russ Tedrake, CoRR abs/1711.07356Vincent Tjeng and Russ Tedrake. 2017. Verifying Neural Networks with Mixed Integer Programming. CoRR abs/1711.07356 (2017).\n\nFormal Security Analysis of Neural Networks using Symbolic Intervals. Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, Suman Jana, Proc. USENIX Security Symposium (USENIX Security 18). 1599\u015b1614. USENIX Security Symposium (USENIX Security 18). 1599\u015b1614Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. 2018. Formal Security Analysis of Neural Networks using Symbolic Intervals. In Proc. USENIX Security Symposium (USENIX Security 18). 1599\u015b1614.\n\nTowards Fast Computation of Certified Robustness for ReLU Networks. Huan Tsui-Wei Weng, Hongge Zhang, Zhao Chen, Cho-Jui Song, Luca Hsieh, Daniel, Proc. International Conference on Machine Learning (ICML). International Conference on Machine Learning (ICML)Duane Boning, and Inderjit DhillonTsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane Boning, and Inderjit Dhillon. 2018. Towards Fast Computation of Certified Robustness for ReLU Networks. In Proc. International Conference on Machine Learning (ICML). 5273\u015b5282.\n\nProvable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope. Eric Wong, Zico Kolter, Proc. International Conference on Machine Learning (ICML). International Conference on Machine Learning (ICML)Eric Wong and Zico Kolter. 2018. Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope. In Proc. International Conference on Machine Learning (ICML). 5283\u015b5292.\n", "annotations": {"author": "[{\"end\":69,\"start\":53},{\"end\":81,\"start\":70},{\"end\":100,\"start\":82},{\"end\":110,\"start\":101},{\"end\":118,\"start\":111},{\"end\":138,\"start\":119},{\"end\":151,\"start\":139},{\"end\":159,\"start\":152},{\"end\":179,\"start\":160},{\"end\":191,\"start\":180},{\"end\":199,\"start\":192},{\"end\":212,\"start\":200}]", "publisher": null, "author_last_name": "[{\"end\":68,\"start\":63},{\"end\":80,\"start\":74},{\"end\":99,\"start\":88},{\"end\":109,\"start\":105},{\"end\":117,\"start\":111},{\"end\":137,\"start\":126},{\"end\":150,\"start\":143},{\"end\":158,\"start\":152},{\"end\":178,\"start\":167},{\"end\":190,\"start\":184},{\"end\":198,\"start\":192},{\"end\":211,\"start\":200}]", "author_first_name": "[{\"end\":62,\"start\":53},{\"end\":73,\"start\":70},{\"end\":87,\"start\":82},{\"end\":104,\"start\":101},{\"end\":125,\"start\":119},{\"end\":142,\"start\":139},{\"end\":166,\"start\":160},{\"end\":183,\"start\":180}]", "author_affiliation": null, "title": "[{\"end\":50,\"start\":1},{\"end\":262,\"start\":213}]", "venue": null, "abstract": "[{\"end\":1770,\"start\":737}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1970,\"start\":1949},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2013,\"start\":1994},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2757,\"start\":2733},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3144,\"start\":3126},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3193,\"start\":3174},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3899,\"start\":3872},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3960,\"start\":3938},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3995,\"start\":3977},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":4140,\"start\":4122},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4312,\"start\":4292},{\"end\":5345,\"start\":5339},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5372,\"start\":5352},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6712,\"start\":6687},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7299,\"start\":7281},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8755,\"start\":8729},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":15230,\"start\":15203},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20425,\"start\":20406},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":28672,\"start\":28647},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":50107,\"start\":50097},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":52392,\"start\":52375},{\"end\":53576,\"start\":53570},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":54745,\"start\":54719},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":56136,\"start\":56118},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":56157,\"start\":56136},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":56571,\"start\":56551},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":56833,\"start\":56815},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":57247,\"start\":57227},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":58395,\"start\":58377},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":58425,\"start\":58409},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":59205,\"start\":59187},{\"end\":59873,\"start\":59867},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":60058,\"start\":60033},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":60529,\"start\":60512},{\"end\":60739,\"start\":60732},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":68999,\"start\":68978},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":69680,\"start\":69667},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":69739,\"start\":69715},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":69778,\"start\":69760},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":69861,\"start\":69838},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":69884,\"start\":69861},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":69930,\"start\":69911},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":69976,\"start\":69958},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":69997,\"start\":69976},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":70314,\"start\":70293},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":70466,\"start\":70442},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":70673,\"start\":70654}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":72653,\"start\":72596},{\"attributes\":{\"id\":\"fig_1\"},\"end\":72722,\"start\":72654},{\"attributes\":{\"id\":\"fig_2\"},\"end\":72818,\"start\":72723},{\"attributes\":{\"id\":\"fig_3\"},\"end\":73098,\"start\":72819},{\"attributes\":{\"id\":\"fig_4\"},\"end\":73289,\"start\":73099},{\"attributes\":{\"id\":\"fig_5\"},\"end\":73747,\"start\":73290},{\"attributes\":{\"id\":\"fig_6\"},\"end\":74250,\"start\":73748},{\"attributes\":{\"id\":\"fig_7\"},\"end\":74376,\"start\":74251},{\"attributes\":{\"id\":\"fig_8\"},\"end\":74524,\"start\":74377},{\"attributes\":{\"id\":\"fig_9\"},\"end\":75177,\"start\":74525},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":75790,\"start\":75178},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":76199,\"start\":75791},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":76708,\"start\":76200},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":77276,\"start\":76709}]", "paragraph": "[{\"end\":3194,\"start\":1786},{\"end\":4520,\"start\":3196},{\"end\":5461,\"start\":4522},{\"end\":5753,\"start\":5463},{\"end\":6983,\"start\":5755},{\"end\":7714,\"start\":6985},{\"end\":9044,\"start\":7716},{\"end\":9093,\"start\":9046},{\"end\":10014,\"start\":9095},{\"end\":10842,\"start\":10016},{\"end\":11002,\"start\":10855},{\"end\":11816,\"start\":11004},{\"end\":12468,\"start\":11818},{\"end\":13051,\"start\":12470},{\"end\":13542,\"start\":13053},{\"end\":13547,\"start\":13544},{\"end\":13552,\"start\":13549},{\"end\":13557,\"start\":13554},{\"end\":13562,\"start\":13559},{\"end\":13567,\"start\":13564},{\"end\":13572,\"start\":13569},{\"end\":13577,\"start\":13574},{\"end\":13582,\"start\":13579},{\"end\":13587,\"start\":13584},{\"end\":13593,\"start\":13589},{\"end\":13599,\"start\":13595},{\"end\":13605,\"start\":13601},{\"end\":14162,\"start\":14122},{\"end\":14185,\"start\":14164},{\"end\":14229,\"start\":14206},{\"end\":14253,\"start\":14231},{\"end\":14424,\"start\":14293},{\"end\":15711,\"start\":14435},{\"end\":15807,\"start\":15713},{\"end\":16399,\"start\":15893},{\"end\":16726,\"start\":16401},{\"end\":17136,\"start\":16728},{\"end\":17824,\"start\":17326},{\"end\":17921,\"start\":17867},{\"end\":18307,\"start\":17923},{\"end\":18682,\"start\":18391},{\"end\":18962,\"start\":18684},{\"end\":19049,\"start\":18964},{\"end\":19191,\"start\":19115},{\"end\":19966,\"start\":19262},{\"end\":20426,\"start\":19968},{\"end\":20624,\"start\":20428},{\"end\":20822,\"start\":20714},{\"end\":21361,\"start\":20886},{\"end\":21498,\"start\":21440},{\"end\":21901,\"start\":21583},{\"end\":22869,\"start\":21903},{\"end\":23259,\"start\":22871},{\"end\":23750,\"start\":23261},{\"end\":24217,\"start\":23752},{\"end\":24582,\"start\":24219},{\"end\":24765,\"start\":24632},{\"end\":24976,\"start\":24828},{\"end\":25176,\"start\":24978},{\"end\":25443,\"start\":25309},{\"end\":26015,\"start\":25445},{\"end\":26361,\"start\":26053},{\"end\":26676,\"start\":26363},{\"end\":26904,\"start\":26732},{\"end\":27283,\"start\":26906},{\"end\":27911,\"start\":27717},{\"end\":28304,\"start\":27913},{\"end\":28559,\"start\":28306},{\"end\":29404,\"start\":28561},{\"end\":29548,\"start\":29406},{\"end\":29712,\"start\":29602},{\"end\":30138,\"start\":29714},{\"end\":30222,\"start\":30140},{\"end\":30458,\"start\":30413},{\"end\":30757,\"start\":30482},{\"end\":31018,\"start\":30830},{\"end\":31221,\"start\":31055},{\"end\":31726,\"start\":31223},{\"end\":31961,\"start\":31815},{\"end\":32129,\"start\":32030},{\"end\":32376,\"start\":32161},{\"end\":32785,\"start\":32378},{\"end\":33108,\"start\":33062},{\"end\":33614,\"start\":33439},{\"end\":33746,\"start\":33674},{\"end\":34147,\"start\":33791},{\"end\":34579,\"start\":34190},{\"end\":35068,\"start\":34905},{\"end\":35932,\"start\":35925},{\"end\":36453,\"start\":36266},{\"end\":36786,\"start\":36651},{\"end\":36858,\"start\":36796},{\"end\":36939,\"start\":36860},{\"end\":37220,\"start\":37138},{\"end\":37615,\"start\":37259},{\"end\":37892,\"start\":37617},{\"end\":38303,\"start\":37961},{\"end\":38733,\"start\":38472},{\"end\":39012,\"start\":38735},{\"end\":39242,\"start\":39014},{\"end\":39402,\"start\":39283},{\"end\":39590,\"start\":39498},{\"end\":40004,\"start\":39952},{\"end\":40130,\"start\":40006},{\"end\":41245,\"start\":41192},{\"end\":41806,\"start\":41627},{\"end\":41997,\"start\":41808},{\"end\":42111,\"start\":41999},{\"end\":42856,\"start\":42769},{\"end\":43264,\"start\":43066},{\"end\":43543,\"start\":43453},{\"end\":43796,\"start\":43741},{\"end\":44269,\"start\":44081},{\"end\":44407,\"start\":44271},{\"end\":44708,\"start\":44618},{\"end\":45143,\"start\":45059},{\"end\":45650,\"start\":45582},{\"end\":45666,\"start\":45652},{\"end\":46609,\"start\":46521},{\"end\":46888,\"start\":46769},{\"end\":47029,\"start\":46962},{\"end\":47430,\"start\":47372},{\"end\":47670,\"start\":47591},{\"end\":47935,\"start\":47864},{\"end\":47985,\"start\":47937},{\"end\":48387,\"start\":48318},{\"end\":48581,\"start\":48389},{\"end\":50321,\"start\":49723},{\"end\":50363,\"start\":50323},{\"end\":50389,\"start\":50365},{\"end\":51609,\"start\":51051},{\"end\":52394,\"start\":51611},{\"end\":55484,\"start\":52396},{\"end\":55749,\"start\":55568},{\"end\":56504,\"start\":55777},{\"end\":57932,\"start\":56506},{\"end\":58328,\"start\":57955},{\"end\":58807,\"start\":58330},{\"end\":59944,\"start\":58809},{\"end\":60017,\"start\":59946},{\"end\":60531,\"start\":60019},{\"end\":60795,\"start\":60533},{\"end\":61764,\"start\":60822},{\"end\":61896,\"start\":61766},{\"end\":62287,\"start\":61898},{\"end\":62725,\"start\":62289},{\"end\":63878,\"start\":62727},{\"end\":66722,\"start\":63880},{\"end\":66976,\"start\":66724},{\"end\":68815,\"start\":67002},{\"end\":69233,\"start\":68832},{\"end\":70145,\"start\":69235},{\"end\":71167,\"start\":70147},{\"end\":71637,\"start\":71182},{\"end\":71931,\"start\":71639},{\"end\":72143,\"start\":71933},{\"end\":72400,\"start\":72145},{\"end\":72595,\"start\":72420}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14121,\"start\":13606},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14205,\"start\":14186},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14292,\"start\":14254},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14434,\"start\":14425},{\"attributes\":{\"id\":\"formula_4\"},\"end\":15892,\"start\":15808},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17267,\"start\":17137},{\"attributes\":{\"id\":\"formula_6\"},\"end\":17325,\"start\":17267},{\"attributes\":{\"id\":\"formula_7\"},\"end\":17866,\"start\":17825},{\"attributes\":{\"id\":\"formula_8\"},\"end\":18390,\"start\":18308},{\"attributes\":{\"id\":\"formula_9\"},\"end\":19114,\"start\":19050},{\"attributes\":{\"id\":\"formula_10\"},\"end\":19261,\"start\":19192},{\"attributes\":{\"id\":\"formula_11\"},\"end\":20713,\"start\":20625},{\"attributes\":{\"id\":\"formula_12\"},\"end\":20885,\"start\":20823},{\"attributes\":{\"id\":\"formula_13\"},\"end\":21439,\"start\":21362},{\"attributes\":{\"id\":\"formula_14\"},\"end\":21582,\"start\":21499},{\"attributes\":{\"id\":\"formula_15\"},\"end\":24631,\"start\":24583},{\"attributes\":{\"id\":\"formula_16\"},\"end\":24827,\"start\":24766},{\"attributes\":{\"id\":\"formula_17\"},\"end\":25308,\"start\":25177},{\"attributes\":{\"id\":\"formula_18\"},\"end\":26052,\"start\":26016},{\"attributes\":{\"id\":\"formula_19\"},\"end\":27716,\"start\":27284},{\"attributes\":{\"id\":\"formula_20\"},\"end\":29601,\"start\":29549},{\"attributes\":{\"id\":\"formula_21\"},\"end\":30412,\"start\":30223},{\"attributes\":{\"id\":\"formula_22\"},\"end\":30481,\"start\":30459},{\"attributes\":{\"id\":\"formula_23\"},\"end\":30829,\"start\":30758},{\"attributes\":{\"id\":\"formula_24\"},\"end\":31814,\"start\":31727},{\"attributes\":{\"id\":\"formula_25\"},\"end\":32029,\"start\":31962},{\"attributes\":{\"id\":\"formula_26\"},\"end\":32160,\"start\":32130},{\"attributes\":{\"id\":\"formula_27\"},\"end\":33061,\"start\":32786},{\"attributes\":{\"id\":\"formula_28\"},\"end\":33438,\"start\":33109},{\"attributes\":{\"id\":\"formula_29\"},\"end\":33673,\"start\":33615},{\"attributes\":{\"id\":\"formula_30\"},\"end\":33790,\"start\":33747},{\"attributes\":{\"id\":\"formula_31\"},\"end\":34904,\"start\":34580},{\"attributes\":{\"id\":\"formula_32\"},\"end\":35282,\"start\":35069},{\"attributes\":{\"id\":\"formula_33\"},\"end\":35894,\"start\":35314},{\"attributes\":{\"id\":\"formula_34\"},\"end\":36265,\"start\":35933},{\"attributes\":{\"id\":\"formula_35\"},\"end\":36650,\"start\":36454},{\"attributes\":{\"id\":\"formula_36\"},\"end\":37137,\"start\":36940},{\"attributes\":{\"id\":\"formula_37\"},\"end\":37960,\"start\":37893},{\"attributes\":{\"id\":\"formula_38\"},\"end\":38471,\"start\":38304},{\"attributes\":{\"id\":\"formula_39\"},\"end\":39497,\"start\":39403},{\"attributes\":{\"id\":\"formula_40\"},\"end\":39951,\"start\":39591},{\"attributes\":{\"id\":\"formula_41\"},\"end\":41191,\"start\":40131},{\"attributes\":{\"id\":\"formula_42\"},\"end\":41626,\"start\":41246},{\"attributes\":{\"id\":\"formula_43\"},\"end\":42768,\"start\":42112},{\"attributes\":{\"id\":\"formula_44\"},\"end\":43065,\"start\":42857},{\"attributes\":{\"id\":\"formula_45\"},\"end\":43452,\"start\":43265},{\"attributes\":{\"id\":\"formula_46\"},\"end\":43740,\"start\":43544},{\"attributes\":{\"id\":\"formula_47\"},\"end\":44080,\"start\":43797},{\"attributes\":{\"id\":\"formula_48\"},\"end\":44617,\"start\":44408},{\"attributes\":{\"id\":\"formula_49\"},\"end\":45058,\"start\":44709},{\"attributes\":{\"id\":\"formula_50\"},\"end\":45581,\"start\":45144},{\"attributes\":{\"id\":\"formula_51\"},\"end\":46230,\"start\":45667},{\"attributes\":{\"id\":\"formula_52\"},\"end\":46520,\"start\":46349},{\"attributes\":{\"id\":\"formula_53\"},\"end\":46768,\"start\":46610},{\"attributes\":{\"id\":\"formula_54\"},\"end\":46961,\"start\":46889},{\"attributes\":{\"id\":\"formula_55\"},\"end\":47371,\"start\":47030},{\"attributes\":{\"id\":\"formula_56\"},\"end\":47590,\"start\":47431},{\"attributes\":{\"id\":\"formula_57\"},\"end\":47863,\"start\":47671},{\"attributes\":{\"id\":\"formula_58\"},\"end\":48317,\"start\":47986},{\"attributes\":{\"id\":\"formula_59\"},\"end\":49678,\"start\":48582},{\"attributes\":{\"id\":\"formula_60\"},\"end\":51050,\"start\":50390}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":58833,\"start\":58826},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":64959,\"start\":64952},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":66752,\"start\":66745}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1784,\"start\":1772},{\"attributes\":{\"n\":\"2\"},\"end\":10853,\"start\":10845},{\"attributes\":{\"n\":\"3\"},\"end\":26730,\"start\":26679},{\"attributes\":{\"n\":\"4\"},\"end\":31053,\"start\":31021},{\"attributes\":{\"n\":\"4.2\"},\"end\":34188,\"start\":34150},{\"attributes\":{\"n\":\"4.3\"},\"end\":35313,\"start\":35284},{\"attributes\":{\"n\":\"4.4\"},\"end\":35923,\"start\":35896},{\"end\":36794,\"start\":36789},{\"attributes\":{\"n\":\"4.5\"},\"end\":37257,\"start\":37223},{\"attributes\":{\"n\":\"4.6\"},\"end\":39281,\"start\":39245},{\"end\":46348,\"start\":46232},{\"attributes\":{\"n\":\"4.7\"},\"end\":49721,\"start\":49680},{\"end\":55566,\"start\":55487},{\"attributes\":{\"n\":\"6\"},\"end\":55775,\"start\":55752},{\"attributes\":{\"n\":\"6.1\"},\"end\":57953,\"start\":57935},{\"attributes\":{\"n\":\"6.2\"},\"end\":60820,\"start\":60798},{\"attributes\":{\"n\":\"6.3\"},\"end\":67000,\"start\":66979},{\"attributes\":{\"n\":\"7\"},\"end\":68830,\"start\":68818},{\"attributes\":{\"n\":\"8\"},\"end\":71180,\"start\":71170},{\"end\":72418,\"start\":72403},{\"end\":72605,\"start\":72597},{\"end\":72663,\"start\":72655},{\"end\":72734,\"start\":72724},{\"end\":72828,\"start\":72820},{\"end\":73108,\"start\":73100},{\"end\":73299,\"start\":73291},{\"end\":73765,\"start\":73749},{\"end\":74260,\"start\":74252},{\"end\":74387,\"start\":74378},{\"end\":74535,\"start\":74526},{\"end\":75188,\"start\":75179},{\"end\":75801,\"start\":75792}]", "table": "[{\"end\":75790,\"start\":75243},{\"end\":76199,\"start\":75901},{\"end\":76708,\"start\":76327}]", "figure_caption": "[{\"end\":72653,\"start\":72607},{\"end\":72722,\"start\":72665},{\"end\":72818,\"start\":72737},{\"end\":73098,\"start\":72830},{\"end\":73289,\"start\":73110},{\"end\":73747,\"start\":73301},{\"end\":74250,\"start\":73768},{\"end\":74376,\"start\":74262},{\"end\":74524,\"start\":74390},{\"end\":75177,\"start\":74538},{\"end\":75243,\"start\":75190},{\"end\":75901,\"start\":75803},{\"end\":76327,\"start\":76202},{\"end\":77276,\"start\":76711}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5615,\"start\":5609},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11170,\"start\":11164},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14637,\"start\":14631},{\"end\":14689,\"start\":14683},{\"end\":14755,\"start\":14749},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18068,\"start\":18062},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18179,\"start\":18173},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18827,\"start\":18817},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18993,\"start\":18987},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19144,\"start\":19138},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20033,\"start\":20027},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20092,\"start\":20086},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20339,\"start\":20329},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":22215,\"start\":22205},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":22839,\"start\":22833},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":22868,\"start\":22858},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":30196,\"start\":30190},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":30422,\"start\":30416},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":37884,\"start\":37878},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":38767,\"start\":38761},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":61253,\"start\":61247},{\"end\":62474,\"start\":62468},{\"end\":62736,\"start\":62730},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":63421,\"start\":63415},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":65353,\"start\":65346},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":66155,\"start\":66148},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":67411,\"start\":67404},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":67892,\"start\":67885},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":68047,\"start\":68040}]", "bib_author_first_name": "[{\"end\":79975,\"start\":79968},{\"end\":79990,\"start\":79983},{\"end\":80004,\"start\":79998},{\"end\":80010,\"start\":80005},{\"end\":80028,\"start\":80024},{\"end\":80042,\"start\":80038},{\"end\":80055,\"start\":80050},{\"end\":80362,\"start\":80356},{\"end\":80376,\"start\":80372},{\"end\":80394,\"start\":80386},{\"end\":80418,\"start\":80409},{\"end\":80437,\"start\":80431},{\"end\":80439,\"start\":80438},{\"end\":80453,\"start\":80446},{\"end\":80866,\"start\":80859},{\"end\":80883,\"start\":80877},{\"end\":80887,\"start\":80884},{\"end\":80901,\"start\":80895},{\"end\":80923,\"start\":80915},{\"end\":80936,\"start\":80932},{\"end\":80951,\"start\":80944},{\"end\":80967,\"start\":80959},{\"end\":80969,\"start\":80968},{\"end\":80984,\"start\":80978},{\"end\":80997,\"start\":80994},{\"end\":81012,\"start\":81006},{\"end\":81023,\"start\":81020},{\"end\":81035,\"start\":81031},{\"end\":81047,\"start\":81042},{\"end\":81363,\"start\":81355},{\"end\":81376,\"start\":81373},{\"end\":81388,\"start\":81383},{\"end\":81403,\"start\":81398},{\"end\":81405,\"start\":81404},{\"end\":81659,\"start\":81651},{\"end\":81674,\"start\":81669},{\"end\":81676,\"start\":81675},{\"end\":82017,\"start\":82010},{\"end\":82033,\"start\":82026},{\"end\":82378,\"start\":82371},{\"end\":82393,\"start\":82385},{\"end\":82406,\"start\":82400},{\"end\":82417,\"start\":82413},{\"end\":82425,\"start\":82422},{\"end\":82438,\"start\":82431},{\"end\":82450,\"start\":82443},{\"end\":82823,\"start\":82810},{\"end\":82841,\"start\":82835},{\"end\":82857,\"start\":82853},{\"end\":82872,\"start\":82865},{\"end\":82887,\"start\":82879},{\"end\":83306,\"start\":83299},{\"end\":83721,\"start\":83716},{\"end\":83735,\"start\":83728},{\"end\":83748,\"start\":83744},{\"end\":83771,\"start\":83766},{\"end\":83787,\"start\":83781},{\"end\":83805,\"start\":83799},{\"end\":84224,\"start\":84218},{\"end\":84238,\"start\":84234},{\"end\":84255,\"start\":84249},{\"end\":84554,\"start\":84551},{\"end\":84575,\"start\":84567},{\"end\":84593,\"start\":84584},{\"end\":84990,\"start\":84983},{\"end\":85006,\"start\":84999},{\"end\":85024,\"start\":85017},{\"end\":85043,\"start\":85036},{\"end\":85059,\"start\":85052},{\"end\":85061,\"start\":85060},{\"end\":85344,\"start\":85336},{\"end\":85353,\"start\":85349},{\"end\":85689,\"start\":85686},{\"end\":85701,\"start\":85696},{\"end\":85703,\"start\":85702},{\"end\":85718,\"start\":85713},{\"end\":85720,\"start\":85719},{\"end\":85731,\"start\":85727},{\"end\":85745,\"start\":85740},{\"end\":85747,\"start\":85746},{\"end\":86207,\"start\":86203},{\"end\":86394,\"start\":86390},{\"end\":86406,\"start\":86402},{\"end\":86421,\"start\":86415},{\"end\":86437,\"start\":86430},{\"end\":86708,\"start\":86698},{\"end\":86726,\"start\":86716},{\"end\":86742,\"start\":86736},{\"end\":86760,\"start\":86752},{\"end\":86776,\"start\":86770},{\"end\":87218,\"start\":87211},{\"end\":87555,\"start\":87548},{\"end\":87569,\"start\":87564},{\"end\":87582,\"start\":87576},{\"end\":88002,\"start\":87999},{\"end\":88020,\"start\":88015},{\"end\":88035,\"start\":88031},{\"end\":88462,\"start\":88457},{\"end\":88474,\"start\":88468},{\"end\":88487,\"start\":88480},{\"end\":88499,\"start\":88494},{\"end\":88907,\"start\":88902},{\"end\":88919,\"start\":88913},{\"end\":88932,\"start\":88925},{\"end\":88944,\"start\":88939},{\"end\":89202,\"start\":89197},{\"end\":89221,\"start\":89216},{\"end\":89239,\"start\":89234},{\"end\":89575,\"start\":89569},{\"end\":89590,\"start\":89583},{\"end\":89820,\"start\":89816},{\"end\":89837,\"start\":89829},{\"end\":89850,\"start\":89843},{\"end\":89864,\"start\":89859},{\"end\":89866,\"start\":89865},{\"end\":90095,\"start\":90086},{\"end\":90108,\"start\":90103},{\"end\":90122,\"start\":90115},{\"end\":90137,\"start\":90131},{\"end\":90153,\"start\":90147},{\"end\":90483,\"start\":90474},{\"end\":90497,\"start\":90491},{\"end\":90513,\"start\":90507},{\"end\":90857,\"start\":90848},{\"end\":90871,\"start\":90865},{\"end\":90887,\"start\":90881},{\"end\":91158,\"start\":91153},{\"end\":91175,\"start\":91168},{\"end\":91548,\"start\":91541},{\"end\":91560,\"start\":91556},{\"end\":91789,\"start\":91784},{\"end\":91801,\"start\":91796},{\"end\":91813,\"start\":91807},{\"end\":91833,\"start\":91826},{\"end\":91845,\"start\":91840},{\"end\":92263,\"start\":92259},{\"end\":92285,\"start\":92279},{\"end\":92297,\"start\":92293},{\"end\":92311,\"start\":92304},{\"end\":92322,\"start\":92318},{\"end\":92839,\"start\":92835},{\"end\":92850,\"start\":92846}]", "bib_author_last_name": "[{\"end\":79981,\"start\":79976},{\"end\":79996,\"start\":79991},{\"end\":80022,\"start\":80011},{\"end\":80036,\"start\":80029},{\"end\":80048,\"start\":80043},{\"end\":80061,\"start\":80056},{\"end\":80370,\"start\":80363},{\"end\":80384,\"start\":80377},{\"end\":80407,\"start\":80395},{\"end\":80429,\"start\":80419},{\"end\":80444,\"start\":80440},{\"end\":80463,\"start\":80454},{\"end\":80875,\"start\":80867},{\"end\":80893,\"start\":80888},{\"end\":80913,\"start\":80902},{\"end\":80930,\"start\":80924},{\"end\":80942,\"start\":80937},{\"end\":80957,\"start\":80952},{\"end\":80976,\"start\":80970},{\"end\":80992,\"start\":80985},{\"end\":81004,\"start\":80998},{\"end\":81018,\"start\":81013},{\"end\":81029,\"start\":81024},{\"end\":81040,\"start\":81036},{\"end\":81053,\"start\":81048},{\"end\":81371,\"start\":81364},{\"end\":81381,\"start\":81377},{\"end\":81396,\"start\":81389},{\"end\":81410,\"start\":81406},{\"end\":81667,\"start\":81660},{\"end\":81683,\"start\":81677},{\"end\":82024,\"start\":82018},{\"end\":82043,\"start\":82034},{\"end\":82383,\"start\":82379},{\"end\":82398,\"start\":82394},{\"end\":82411,\"start\":82407},{\"end\":82420,\"start\":82418},{\"end\":82429,\"start\":82426},{\"end\":82441,\"start\":82439},{\"end\":82453,\"start\":82451},{\"end\":82833,\"start\":82824},{\"end\":82851,\"start\":82842},{\"end\":82863,\"start\":82858},{\"end\":82877,\"start\":82873},{\"end\":82893,\"start\":82888},{\"end\":83313,\"start\":83307},{\"end\":83726,\"start\":83722},{\"end\":83742,\"start\":83736},{\"end\":83764,\"start\":83749},{\"end\":83779,\"start\":83772},{\"end\":83797,\"start\":83788},{\"end\":83812,\"start\":83806},{\"end\":84232,\"start\":84225},{\"end\":84247,\"start\":84239},{\"end\":84261,\"start\":84256},{\"end\":84565,\"start\":84555},{\"end\":84582,\"start\":84576},{\"end\":84601,\"start\":84594},{\"end\":84997,\"start\":84991},{\"end\":85015,\"start\":85007},{\"end\":85034,\"start\":85025},{\"end\":85050,\"start\":85044},{\"end\":85070,\"start\":85062},{\"end\":85347,\"start\":85345},{\"end\":85361,\"start\":85354},{\"end\":85694,\"start\":85690},{\"end\":85711,\"start\":85704},{\"end\":85725,\"start\":85721},{\"end\":85738,\"start\":85732},{\"end\":85760,\"start\":85748},{\"end\":86218,\"start\":86208},{\"end\":86400,\"start\":86395},{\"end\":86413,\"start\":86407},{\"end\":86428,\"start\":86422},{\"end\":86445,\"start\":86438},{\"end\":86714,\"start\":86709},{\"end\":86734,\"start\":86727},{\"end\":86750,\"start\":86743},{\"end\":86768,\"start\":86761},{\"end\":86782,\"start\":86777},{\"end\":87223,\"start\":87219},{\"end\":87562,\"start\":87556},{\"end\":87574,\"start\":87570},{\"end\":87589,\"start\":87583},{\"end\":88013,\"start\":88003},{\"end\":88029,\"start\":88021},{\"end\":88041,\"start\":88036},{\"end\":88466,\"start\":88463},{\"end\":88478,\"start\":88475},{\"end\":88492,\"start\":88488},{\"end\":88504,\"start\":88500},{\"end\":88911,\"start\":88908},{\"end\":88923,\"start\":88920},{\"end\":88937,\"start\":88933},{\"end\":88949,\"start\":88945},{\"end\":89214,\"start\":89203},{\"end\":89232,\"start\":89222},{\"end\":89245,\"start\":89240},{\"end\":89581,\"start\":89576},{\"end\":89600,\"start\":89591},{\"end\":89827,\"start\":89821},{\"end\":89841,\"start\":89838},{\"end\":89857,\"start\":89851},{\"end\":89872,\"start\":89867},{\"end\":90101,\"start\":90096},{\"end\":90113,\"start\":90109},{\"end\":90129,\"start\":90123},{\"end\":90145,\"start\":90138},{\"end\":90160,\"start\":90154},{\"end\":90489,\"start\":90484},{\"end\":90505,\"start\":90498},{\"end\":90520,\"start\":90514},{\"end\":90863,\"start\":90858},{\"end\":90879,\"start\":90872},{\"end\":90894,\"start\":90888},{\"end\":91166,\"start\":91159},{\"end\":91181,\"start\":91176},{\"end\":91554,\"start\":91549},{\"end\":91568,\"start\":91561},{\"end\":91794,\"start\":91790},{\"end\":91805,\"start\":91802},{\"end\":91824,\"start\":91814},{\"end\":91838,\"start\":91834},{\"end\":91850,\"start\":91846},{\"end\":92277,\"start\":92264},{\"end\":92291,\"start\":92286},{\"end\":92302,\"start\":92298},{\"end\":92316,\"start\":92312},{\"end\":92328,\"start\":92323},{\"end\":92336,\"start\":92330},{\"end\":92844,\"start\":92840},{\"end\":92857,\"start\":92851}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":2568270},\"end\":80304,\"start\":79919},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":5213597},\"end\":80814,\"start\":80306},{\"attributes\":{\"doi\":\"CoRR abs/1604.07316\",\"id\":\"b2\"},\"end\":81351,\"start\":80816},{\"attributes\":{\"doi\":\"abs/1709.10207\",\"id\":\"b3\"},\"end\":81595,\"start\":81353},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":2893830},\"end\":81937,\"start\":81597},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":16411662},\"end\":82325,\"start\":81939},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":4119221},\"end\":82749,\"start\":82327},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":3972365},\"end\":83226,\"start\":82751},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1931807},\"end\":83624,\"start\":83228},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":206579396},\"end\":84177,\"start\":83626},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":9119506},\"end\":84501,\"start\":84179},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":6706414},\"end\":84898,\"start\":84503},{\"attributes\":{\"doi\":\"CoRR abs/1606.04435\",\"id\":\"b12\"},\"end\":85334,\"start\":84900},{\"attributes\":{\"doi\":\"arXiv:1412.5068\",\"id\":\"b13\"},\"end\":85614,\"start\":85336},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":516928},\"end\":86146,\"start\":85616},{\"attributes\":{\"id\":\"b15\"},\"end\":86331,\"start\":86148},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":14542261},\"end\":86633,\"start\":86333},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3488815},\"end\":87128,\"start\":86635},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":253329},\"end\":87470,\"start\":87130},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":51872670},\"end\":87902,\"start\":87472},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":206592585},\"end\":88390,\"start\":87904},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":793610},\"end\":88811,\"start\":88392},{\"attributes\":{\"doi\":\"CoRR abs/1712.01785\",\"id\":\"b22\"},\"end\":89146,\"start\":88813},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":11217889},\"end\":89527,\"start\":89148},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":4607168},\"end\":89764,\"start\":89529},{\"attributes\":{\"doi\":\"CoRR abs/1511.05122\",\"id\":\"b25\"},\"end\":90039,\"start\":89766},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":53960414},\"end\":90440,\"start\":90041},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":15378666},\"end\":90777,\"start\":90442},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":36262837},\"end\":91108,\"start\":90779},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":883252},\"end\":91481,\"start\":91110},{\"attributes\":{\"doi\":\"CoRR abs/1711.07356\",\"id\":\"b30\"},\"end\":91712,\"start\":91483},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":13745458},\"end\":92189,\"start\":91714},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":13750928},\"end\":92743,\"start\":92191},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":3659467},\"end\":93164,\"start\":92745}]", "bib_title": "[{\"end\":79966,\"start\":79919},{\"end\":80354,\"start\":80306},{\"end\":81649,\"start\":81597},{\"end\":82008,\"start\":81939},{\"end\":82369,\"start\":82327},{\"end\":82808,\"start\":82751},{\"end\":83297,\"start\":83228},{\"end\":83714,\"start\":83626},{\"end\":84216,\"start\":84179},{\"end\":84549,\"start\":84503},{\"end\":85684,\"start\":85616},{\"end\":86388,\"start\":86333},{\"end\":86696,\"start\":86635},{\"end\":87209,\"start\":87130},{\"end\":87546,\"start\":87472},{\"end\":87997,\"start\":87904},{\"end\":88455,\"start\":88392},{\"end\":89195,\"start\":89148},{\"end\":89567,\"start\":89529},{\"end\":90084,\"start\":90041},{\"end\":90472,\"start\":90442},{\"end\":90846,\"start\":90779},{\"end\":91151,\"start\":91110},{\"end\":91782,\"start\":91714},{\"end\":92257,\"start\":92191},{\"end\":92833,\"start\":92745}]", "bib_author": "[{\"end\":79983,\"start\":79968},{\"end\":79998,\"start\":79983},{\"end\":80024,\"start\":79998},{\"end\":80038,\"start\":80024},{\"end\":80050,\"start\":80038},{\"end\":80063,\"start\":80050},{\"end\":80372,\"start\":80356},{\"end\":80386,\"start\":80372},{\"end\":80409,\"start\":80386},{\"end\":80431,\"start\":80409},{\"end\":80446,\"start\":80431},{\"end\":80465,\"start\":80446},{\"end\":80877,\"start\":80859},{\"end\":80895,\"start\":80877},{\"end\":80915,\"start\":80895},{\"end\":80932,\"start\":80915},{\"end\":80944,\"start\":80932},{\"end\":80959,\"start\":80944},{\"end\":80978,\"start\":80959},{\"end\":80994,\"start\":80978},{\"end\":81006,\"start\":80994},{\"end\":81020,\"start\":81006},{\"end\":81031,\"start\":81020},{\"end\":81042,\"start\":81031},{\"end\":81055,\"start\":81042},{\"end\":81373,\"start\":81355},{\"end\":81383,\"start\":81373},{\"end\":81398,\"start\":81383},{\"end\":81412,\"start\":81398},{\"end\":81669,\"start\":81651},{\"end\":81685,\"start\":81669},{\"end\":82026,\"start\":82010},{\"end\":82045,\"start\":82026},{\"end\":82385,\"start\":82371},{\"end\":82400,\"start\":82385},{\"end\":82413,\"start\":82400},{\"end\":82422,\"start\":82413},{\"end\":82431,\"start\":82422},{\"end\":82443,\"start\":82431},{\"end\":82455,\"start\":82443},{\"end\":82835,\"start\":82810},{\"end\":82853,\"start\":82835},{\"end\":82865,\"start\":82853},{\"end\":82879,\"start\":82865},{\"end\":82895,\"start\":82879},{\"end\":83315,\"start\":83299},{\"end\":83728,\"start\":83716},{\"end\":83744,\"start\":83728},{\"end\":83766,\"start\":83744},{\"end\":83781,\"start\":83766},{\"end\":83799,\"start\":83781},{\"end\":83814,\"start\":83799},{\"end\":84234,\"start\":84218},{\"end\":84249,\"start\":84234},{\"end\":84263,\"start\":84249},{\"end\":84567,\"start\":84551},{\"end\":84584,\"start\":84567},{\"end\":84603,\"start\":84584},{\"end\":84999,\"start\":84983},{\"end\":85017,\"start\":84999},{\"end\":85036,\"start\":85017},{\"end\":85052,\"start\":85036},{\"end\":85072,\"start\":85052},{\"end\":85349,\"start\":85336},{\"end\":85363,\"start\":85349},{\"end\":85696,\"start\":85686},{\"end\":85713,\"start\":85696},{\"end\":85727,\"start\":85713},{\"end\":85740,\"start\":85727},{\"end\":85762,\"start\":85740},{\"end\":86220,\"start\":86203},{\"end\":86402,\"start\":86390},{\"end\":86415,\"start\":86402},{\"end\":86430,\"start\":86415},{\"end\":86447,\"start\":86430},{\"end\":86716,\"start\":86698},{\"end\":86736,\"start\":86716},{\"end\":86752,\"start\":86736},{\"end\":86770,\"start\":86752},{\"end\":86784,\"start\":86770},{\"end\":87225,\"start\":87211},{\"end\":87564,\"start\":87548},{\"end\":87576,\"start\":87564},{\"end\":87591,\"start\":87576},{\"end\":88015,\"start\":87999},{\"end\":88031,\"start\":88015},{\"end\":88043,\"start\":88031},{\"end\":88468,\"start\":88457},{\"end\":88480,\"start\":88468},{\"end\":88494,\"start\":88480},{\"end\":88506,\"start\":88494},{\"end\":88913,\"start\":88902},{\"end\":88925,\"start\":88913},{\"end\":88939,\"start\":88925},{\"end\":88951,\"start\":88939},{\"end\":89216,\"start\":89197},{\"end\":89234,\"start\":89216},{\"end\":89247,\"start\":89234},{\"end\":89583,\"start\":89569},{\"end\":89602,\"start\":89583},{\"end\":89829,\"start\":89816},{\"end\":89843,\"start\":89829},{\"end\":89859,\"start\":89843},{\"end\":89874,\"start\":89859},{\"end\":90103,\"start\":90086},{\"end\":90115,\"start\":90103},{\"end\":90131,\"start\":90115},{\"end\":90147,\"start\":90131},{\"end\":90162,\"start\":90147},{\"end\":90491,\"start\":90474},{\"end\":90507,\"start\":90491},{\"end\":90522,\"start\":90507},{\"end\":90865,\"start\":90848},{\"end\":90881,\"start\":90865},{\"end\":90896,\"start\":90881},{\"end\":91168,\"start\":91153},{\"end\":91183,\"start\":91168},{\"end\":91556,\"start\":91541},{\"end\":91570,\"start\":91556},{\"end\":91796,\"start\":91784},{\"end\":91807,\"start\":91796},{\"end\":91826,\"start\":91807},{\"end\":91840,\"start\":91826},{\"end\":91852,\"start\":91840},{\"end\":92279,\"start\":92259},{\"end\":92293,\"start\":92279},{\"end\":92304,\"start\":92293},{\"end\":92318,\"start\":92304},{\"end\":92330,\"start\":92318},{\"end\":92338,\"start\":92330},{\"end\":92846,\"start\":92835},{\"end\":92859,\"start\":92846}]", "bib_venue": "[{\"end\":80093,\"start\":80063},{\"end\":80526,\"start\":80465},{\"end\":80857,\"start\":80816},{\"end\":81734,\"start\":81685},{\"end\":82100,\"start\":82045},{\"end\":82507,\"start\":82455},{\"end\":82954,\"start\":82895},{\"end\":83387,\"start\":83315},{\"end\":83863,\"start\":83814},{\"end\":84311,\"start\":84263},{\"end\":84661,\"start\":84603},{\"end\":84981,\"start\":84900},{\"end\":85450,\"start\":85378},{\"end\":85837,\"start\":85762},{\"end\":86201,\"start\":86148},{\"end\":86464,\"start\":86447},{\"end\":86842,\"start\":86784},{\"end\":87271,\"start\":87225},{\"end\":87648,\"start\":87591},{\"end\":88109,\"start\":88043},{\"end\":88566,\"start\":88506},{\"end\":88900,\"start\":88813},{\"end\":89304,\"start\":89247},{\"end\":89632,\"start\":89602},{\"end\":89814,\"start\":89766},{\"end\":90212,\"start\":90162},{\"end\":90577,\"start\":90522},{\"end\":90919,\"start\":90896},{\"end\":91255,\"start\":91183},{\"end\":91539,\"start\":91483},{\"end\":91915,\"start\":91852},{\"end\":92395,\"start\":92338},{\"end\":92916,\"start\":92859},{\"end\":80579,\"start\":80528},{\"end\":81779,\"start\":81736},{\"end\":82151,\"start\":82102},{\"end\":82555,\"start\":82509},{\"end\":83009,\"start\":82956},{\"end\":83455,\"start\":83389},{\"end\":83908,\"start\":83865},{\"end\":84355,\"start\":84313},{\"end\":84715,\"start\":84663},{\"end\":85908,\"start\":85839},{\"end\":86477,\"start\":86466},{\"end\":86896,\"start\":86844},{\"end\":87313,\"start\":87273},{\"end\":87701,\"start\":87650},{\"end\":88171,\"start\":88111},{\"end\":88622,\"start\":88568},{\"end\":89357,\"start\":89306},{\"end\":90254,\"start\":90214},{\"end\":90628,\"start\":90579},{\"end\":91323,\"start\":91257},{\"end\":91974,\"start\":91917},{\"end\":92448,\"start\":92397},{\"end\":92969,\"start\":92918}]"}}}, "year": 2023, "month": 12, "day": 17}