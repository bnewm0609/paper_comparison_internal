{"id": 204837888, "updated": "2023-10-07 22:02:18.671", "metadata": {"title": "Tropical Cyclone Track Forecasting Using Fused Deep Learning From Aligned Reanalysis Data", "authors": "[{\"first\":\"Sophie\",\"last\":\"Giffard-Roisin\",\"middle\":[]},{\"first\":\"Mo\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Guillaume\",\"last\":\"Charpiat\",\"middle\":[]},{\"first\":\"Christina\",\"last\":\"Kumler Bonfanti\",\"middle\":[]},{\"first\":\"Bal\u00e1zs\",\"last\":\"K\u00e9gl\",\"middle\":[]},{\"first\":\"Claire\",\"last\":\"Monteleoni\",\"middle\":[]}]", "venue": "Frontiers in Big Data", "journal": "Frontiers in Big Data", "publication_date": {"year": 2020, "month": 1, "day": 28}, "abstract": "The forecast of tropical cyclone trajectories is crucial for the protection of people and property. Although forecast dynamical models can provide high-precision short-term forecasts, they are computationally demanding, and current statistical forecasting models have much room for improvement given that the database of past hurricanes is constantly growing. Machine learning methods, that can capture non-linearities and complex relations, have only been scarcely tested for this application. We propose a neural network model fusing past trajectory data and reanalysis atmospheric images (wind and pressure 3D fields). We use a moving frame of reference that follows the storm center for the 24 h tracking forecast. The network is trained to estimate the longitude and latitude displacement of tropical cyclones and depressions from a large database from both hemispheres (more than 3,000 storms since 1979, sampled at a 6 h frequency). The advantage of the fused network is demonstrated and a comparison with current forecast models shows that deep learning methods could provide a valuable and complementary prediction. Moreover, our method can give a forecast for a new storm in a few seconds, which is an important asset for real-time forecasts compared to traditional forecasts.", "fields_of_study": "[\"Physics\",\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1910.10566", "mag": "3002152246", "acl": null, "pubmed": "33693376", "pubmedcentral": "7931887", "dblp": "journals/fdata/Giffard-RoisinY20", "doi": "10.3389/fdata.2020.00001"}}, "content": {"source": {"pdf_hash": "5b4413e60d5430c4374bfec32fedc19d7d4b1c04", "pdf_src": "PubMedCentral", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://doi.org/10.3389/fdata.2020.00001", "status": "GOLD"}}, "grobid": {"id": "46cba990828eef74878c59e72ba8c54b36830e1b", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/5b4413e60d5430c4374bfec32fedc19d7d4b1c04.txt", "contents": "\na section of the journal Frontiers in Big Data Tropical Cyclone Track Forecasting Using Fused Deep Learning From Aligned Reanalysis Data\nJanuary 2020\n\nForrest M Hoffman \nKarthik Kashinath \nHui Lu \nSophie Giffard-Roisin \nSophie Giffard-Roisin \nComputer Science Department\nUniversity of Colorado Boulder\nBoulderCOUnited States\n\nUniv. Grenoble Alpes\nIRD, IFSTTAR, ISTerre\nUniv. Savoie Mont Blanc\nCNRS\nGrenobleFrance\n\nMo Yang \nLinear Accelerator Laboratory\nUniversit\u00e9 Paris-Sud\nCNRS\n\u00cele-de-France, France, 4 Inria Saclay-Ile-de-France, LRI\n\nUniversit\u00e9 Paris-Sud\nPalaiseauFrance\n\nGuillaume Charpiat \nChristina Kumler Bonfanti \nNOAA/OAR/ESRL/Global Systems Division\nCooperative Institute for Research in Environmental Sciences\nUniversity of Colorado Boulder\nBoulderCOUnited States\n\nBal\u00e1zs K\u00e9gl \nLinear Accelerator Laboratory\nUniversit\u00e9 Paris-Sud\nCNRS\n\u00cele-de-France, France, 4 Inria Saclay-Ile-de-France, LRI\n\nUniversit\u00e9 Paris-Sud\nPalaiseauFrance\n\nClaire Monteleoni \nComputer Science Department\nUniversity of Colorado Boulder\nBoulderCOUnited States\n\n\nLawrence Berkeley National Laboratory\nOak Ridge National Laboratory (DOE)\nUnited States, United States\n\n\nTsinghua University\nChina\n\na section of the journal Frontiers in Big Data Tropical Cyclone Track Forecasting Using Fused Deep Learning From Aligned Reanalysis Data\n\nFrontiers in Big Data | www.frontiersin.org\n11January 202010.3389/fdata.2020.00001Specialty section: This article was submitted to Data-driven Climate Sciences, Received: 23 October 2020 Accepted: 10 January 2020 Published: 28 January 2020ORIGINAL RESEARCH Edited by: Reviewed by: *Correspondence: Citation: Giffard-Roisin S, Yang M, Charpiat G, Kumler Bonfanti C, K\u00e9gl B and Monteleoni C (2020) Tropical Cyclone Track Forecasting Using Fused Deep Learning From Aligned Reanalysis Data.tropical cyclonesmachine learningfused deep learningtracking forecastreanalysis data\nThe forecast of tropical cyclone trajectories is crucial for the protection of people and property. Although forecast dynamical models can provide high-precision short-term forecasts, they are computationally demanding, and current statistical forecasting models have much room for improvement given that the database of past hurricanes is constantly growing. Machine learning methods, that can capture non-linearities and complex relations, have only been scarcely tested for this application. We propose a neural network model fusing past trajectory data and reanalysis atmospheric images (wind and pressure 3D fields). We use a moving frame of reference that follows the storm center for the 24 h tracking forecast. The network is trained to estimate the longitude and latitude displacement of tropical cyclones and depressions from a large database from both hemispheres (more than 3,000 storms since 1979, sampled at a 6 h frequency). The advantage of the fused network is demonstrated and a comparison with current forecast models shows that deep learning methods could provide a valuable and complementary prediction. Moreover, our method can give a forecast for a new storm in a few seconds, which is an important asset for real-time forecasts compared to traditional forecasts.\n\nINTRODUCTION\n\nCyclones, hurricanes, and typhoons are words designating the same phenomena: a rare and complex event characterized by strong winds surrounding a low pressure area. The ability to forecast their trajectory and intensity forecasts is crucial for the protection of people and property. However, their evolution depends on many factors at different scales, altitudes, and times, which leads to modeling difficulties (Emanuel, 2003). As the dynamical models evolve, their forecast accuracy improves; however, historical tropical cyclone databases have scarcely been utilized by machine learning and deep learning methods, to further improve forecast accuracy.\n\n\nExisting Storm Forecasts Methods\n\nToday, the forecasts (track and intensity) are provided by numerous guidance models 1 . Dynamical models solve the physical equations governing motions in the atmosphere and they are influenced by physical models -convective schemes (such as Kain-Fritsch or Simplified Arakawa Schubert), cloud microphysics, land surface model, ocean model, sea/land ice model, planetary boundary layer scheme, surface layer scheme, longwave and shortwave radiation schemes, subgrid-scale diffusion-and by their data assimilation methods (such as 4D-VAR). They are computationally demanding and in current practice older model runs are adjusted in order to be considered early methods, i.e., available in real time. Current forecasts produced by regional specialized meteorological centers, like the American Official NHC Forecast (OFCL), are driven by consensus or ensemble methods able to combine different dynamical models 1 (up to 20 models for the Global Ensemble Forecast System 2 ). Statistical models, in contrast, are based on historical relationships between storm behavior and various other parameters (DeMaria et al., 2005). However, they are based on simple regressions on few statistical features. By incorporating large spatial atmospheric data in a statistical model, using state-of-the-art machine learning methods, we can improve the accuracy while reducing the calculation time.\n\n\nDeep Learning and Convolutional Neural Networks (CNN)\n\nA convolutional neural network (CNN) is a deep learning architecture widely adopted as a very effective model for analyzing images or image-like data for pattern recognition (Krizhevsky et al., 2012;Milletari et al., 2016). A CNN is structured in layers: an input layer connected to the data, an output layer connected to the quantities to estimate, and multiple hidden layers in between. The hidden layers of a CNN typically consist of convolutional layers, pooling layers, fully connected layers and normalization layers. The convolutional operations are inspired by the cortex visual system, where each neuron only processes data for its receptive field. Fully connected (FC) layers, usually at the end of the network, connect every neuron in one layer to every neuron in another layer. The advantage of CNN is that it can learn to recognize spatial patterns by exploiting translation invariance (i.e., all parts of the image are processed in a similar way), and thus can extract features automatically while considerably reducing the number of parameters.\n\nRecurrent neural networks (RNN) are a class of artificial neural networks that can model temporal dynamic behavior for a time sequence. Unlike feedforward neural networks (like CNNs), RNNs can use their internal state (memory) to process sequences of inputs. An LSTM (long short term memory) network is a particular RNN used in different time-series applications. Even though the long-short-term memory (LSTM) networks are among the most successful methods for predicting timeseries events, they are still difficult to train, and simpler CNNs may outperform LSTMs (Bai et al., 2018). Moreover, encoding time frames as different input channels in a CNN architecture already proved its efficiency if the history size is fixed (de Bezenac et al., 2017). In our forecast problem we are dealing with spatial and time-varying meteorological data, with a short history size\n\n\nMachine Learning and Deep Learning in Forecasting Problems\n\nCurrent statistical forecasting models still perform poorly with respect to dynamical models, even though the database made of past tropical cyclones is constantly growing 3 . Machine learning methods, which are able to capture non-linearities and complex relations, have only been scarcely tested for tropical cyclone tracking. Yet, they have recently shown their efficiency in a number of various other forecasting tasks. In particular, CNNs have raised attention as they are suited for large imaging (2D or 3D) data. In Shi et al. (2015), a convolutional LSTM model was used for precipitation forecast. Another recent study predicts the evolution of sea surface temperature maps by combining CNNs with physical knowledge (de Bezenac et al., 2017). CNNs have also been used for the detection of extreme weather events like tropical cyclones from weather model variables such as integrated water vapor, as in Racah et al. (2017) or in Kim et al. (2019). These studies show that inputs from meteorological fields are suited for training CNN models in various forecastings and detection problems.\n\nHowever, only few preliminary studies have tackled tropical cyclone forecast tracking using machine learning. Two studies used RNN from only trajectory information.\n\nMoradi Kordmahalleh et al. (2016) was tested on 6 h-and 12 h-forecast on only 4 tropical cyclones, while Gao et al. (2018) was tested on only Northwest Pacific tracks. Yet, the trajectory data information is limited so the use of local meteorological fields is crucial for this complex problem. R\u00fcttgers et al. (2019) proposes to use a generative adversarial network (GAN) to generate the future RGB atmospheric image (harder problem), but only for a 6 h prediction. The GAN method is interesting, but the forecast errors are large. To be noticed, the authors are suggesting using in the future some meteorological fields such as the velocity to improve the results. Other studies uses storm tracks and reanalysis maps as input for a hybrid CNN-LSTM network in order to learn the (x,y) tracking coordinates (Mudigonda et al., 2017;Kim et al., 2019). While these methods are usually not compared with existing forecasts methods, some of them seem to even perform worse than a baseline of constant speed and direction, see Giffard-Roisin et al. (2018b). Based on this review and to the best of our knowledge, recent efforts have been made in developing innovative machine learning forecast methods but the results are still poor, the forecast time is always less than 15 h and a good evaluation is usually lacking.\n\n\nFrame of Reference\n\nIn order to overcome these limitations, we developed a different strategy to use image-like data as inputs for training a deep learning network. All of the current machine learning forecasts consider a fixed regional map for tracking storms, of size 160 \u00d7 80 \u2022 (longitude/latitude) for Mudigonda et al. (2017) and  Frontiers in Big Data | www.frontiersin.org Kim et al. (2019) and of the size of the Korean peninsula area (around 30 \u00d7 30 \u2022 ) for R\u00fcttgers et al. (2019). However, a fixed region for tropical cyclone forecast has three major limitations. First, the tracked storm must stay in the region even though tracks often cross oceans (see Figure 1), forcing the uses of a large region, even if it leads to memory issues (Mudigonda et al., 2017). Moreover, learning local phenomena on a large and noncentered image can be difficult. Finally, it prevents information transfer between storms coming from different basins or regions, where ground truth data is scarce. In our recent work (Giffard-Roisin et al., 2018b), we showed the advantage of using a moving reference CNN model for forecasting tropical cyclone tracks 6 h into the future. This gave roughly a 30 km mean error whereas all other learning methods have a mean error larger than 60 km (Moradi Kordmahalleh et al., 2016;Kim et al., 2019;R\u00fcttgers et al., 2019) and a constant speed baseline gave 46 km mean error. However, a 6 h-forecast is of little use for catastrophe planning and it is not possible to compare to existing forecast methods as the smallest standard is 24 h.\n\n\nContributions\n\nIn this work, we propose to answer the following questions: Can we develop a statistical forecast model, using state-of-the-art deep learning techniques, that is able to compete with current forecast models at a 24 h time lag? How can we take the best advantage of the worldwide historical track database and the reanalysis meteorological fields?\n\nWe propose to extend our previous work by using a moving frame of reference that follows the storm center for a 24h-forecast tracking task. We pose the tracking problem as the estimation of the displacement vector, d, between current and future locations. Moreover, we propose to use the reanalysis data as cropped images (25 \u00d7 25 \u2022 ) centered on the storm location. That way, the computation time is reduced and we can infer information from storms coming from a large number of tropical cyclone basins from both hemispheres. In particular, our database is made up of slightly more than 3,000 storms since 1979, sampled at a 6 h frequency (more than 90,000 time steps). We include past temporal information by adding the reanalysis maps from previous time steps. We propose a fusion convolutional neural network taking into account past trajectories and different fields from reanalysis images (wind fields and pressure). Using every time step of a storm as a unique sample (thus having 90 K samples) allows us to train CNN algorithms that require big data to optimize their large number of parameters (here of the order of 10 6 ). This paper focuses on a 24 h-forecast as a proof of concept, and could be easily extended to larger forecast times.\n\nWe aim at building an end-to-end model using two types of data (track data and 3D reanalysis) as input. For each time step of each storm, we want to independently estimate its future displacement. After presenting the data, we will show how we designed CNNs to learn from the reanalysis and then improved the result by combining it with history tracks and other 0D features (such as longitude, latitude, and maximal sustained windspeed). Figure 2 summarizes the fusion pipeline that predicts the 24 h storm displacement. Lastly, we will show the results on the test set and compare these with current forecast models.\n\n\nDATA DESCRIPTION\n\n\nStorm Tracks\n\nThe raw storm track data used in this study is composed of more than 3,000 tropical and extra-tropical storm tracks since 1979, extracted from the NOAA database IBTrACS (International Best Track Archive for Climate Stewardship, Knapp et al., 2010), FIGURE 3 | Global atmospheric grids centered on the storm location: wind fields (u and v) and geopotential height (z). The depth of the configuration increases from left to right, as more layers are added. conv3-32 indicates a convolution of size 3 \u00d7 3 with 32 output features. FC means fully connected layer. maxpool indicates a 3 \u00d7 3 max-pooling layer. The ReLU activation and batch normalization layers (applied after each conv. or FC layer) are not shown in the figure.\n\nFrontiers in Big Data | www.frontiersin.org shown in Figure 1. The tracks were produced by multiple governmental agencies, depending on the basin. They are defined by the 6-hourly center locations (latitude and longitude), and the database also includes some associated descriptors such as the windspeed (see section 2.3). It includes both hemispheres and the number of records per storm varies from 2 to 120 time steps. In total, the database counts more than 90,000 time steps and we used our method to predict the 24-h track forecast for each single time step.\n\n\nReanalysis Data\n\nThe trajectory of a storm depends on large-scale atmospheric flows. We chose to extract analyzed atmospheric fields from  reanalysis data, not the forecast fields. We used the ERA-Interim database (Dee et al., 2011), which is one of the reanalysis datasets covering the data-rich period since 1979. Reanalysis is a systematic approach to produce datasets for climate monitoring and research, covering the entire globe from the Earth's surface to well above the stratosphere and estimate hundreds of available variables. ERA-Interim is a global atmospheric reanalysis produced by the European Centre for Medium-Range Weather Forecasts (ECMWF) and is produced in near to real time. The spectral resolution is T255 (around 80 km), the time resolution is 6 h, and there are 60 vertical pressure levels until 0.1 hPa (altitude around 64 km).\n\n\nFeature Selection\n\nIn this work, we used storm track data and reanalysis outputs to forecast tropical cyclone tracks. We can classify them into 4 types of information:\n\n\u2022 Past displacements (1D). We define a displacement as the values (\u03b4long t , \u03b4lat t ) between the locations of a storm's center, as recorded in the storm track data, at different times. The time difference, t, being in a multiple of 6 h. The historical displacements of a storm help predict its future displacement (\u03b4long 24h , \u03b4lat 24h ). We used the current displacement (i.e., between times t \u2212 6 h and t) and the past displacement (between t \u2212 12 h and t \u2212 6 h). These features are 1D in the sense that they are defined for each past time step (1D temporal data). \u2022 Meta data (0D). We use all of the features extracted from the IBTrACS database, as they contain crucial information related to the TCs: the current center-point latitude and longitude, the current windspeed at the center of the storm, the current distance to land, and the Jday predictor (Gaussian function of Julian day of storm init-peak day of the tropical cyclone season in the hemisphere, see DeMaria et al., 2005). We refer to such features as 0D because they are not defined on a spatial grid. \u2022 Wind fields u and v (spatial fields, 3D). We applied a sparse feature selection technique (Automatic Relevance Determination, based on linear regression to the target displacement shift) over the 10 available reanalysis fields on pressure levels, which highlighted the usefulness of two reanalysis fields in particular: wind fields and the geopotential height. Wind fields are the direct observations of the atmospheric flows, so their importance is clear. In order to have a moving frame of reference, we extracted the wind fields of the neighborhood of the storm at every time step from the ERA-interim reanalysis database, see Figure 3. Specifically, we extracted the u-wind and v-wind fields on a 25 \u00d7 25 \u2022 grid centered on the current storm location, at three atmospheric pressure levels (700, 500, and 225 hPa). The choice of the three pressure levels was inspired by the literature on statistical forecast models (DeMaria et al., 2005) a well as on a sensitivity analysis. The idea is to capture the air movements at the different levels of the troposphere: low, mid and high clouds. The size of the grid was motivated by the fact that meaningful information is extractable from the movement of air masses around the storm, while focusing on the storm only (10 \u00d7 10 \u2022 ) bounds most historic extreme storms (which was confirmed by preliminary training experiments). \u2022 Geopotential height fields z (spatial fields, 3D). As previously mentioned, the geopotential height was also found relevant for this task from the ARD regression. Similar to wind fields, we extracted the geopotential height (or iso-pressure latitude) fields of the neighborhood of the storm at every time step on a 25 \u00d7 25 \u2022 grid centered on the current storm location, at three atmospheric pressure levels (700, 500, and 225 hPa).\n\nIn order to capture the dynamics, we extracted the wind fields and the geopotential height measured at times t and t \u2212 6 h at the same location. These fields are thus 3D (spatial) \u00d7 1D (temporal).\n\nWe point out that we first used surface reanalysis data, including sea surface temperature, sea level pressure and 10 m winds, but because of no significant impacts to the result, we concentrated our efforts to atmospheric wind and geopotential fields.\n\n\nSet Separation\n\nThe storms were randomly separated in three sets as following: training (60%)/validation (20%)/testing (20%). Thus, the storms in the test set have never been seen before by the learning algorithm. Then, within each set, all time instants were treated independently. The training set was used for optimizing the parameters of the neural networks (back-propagation). The validation set was used to select the architecture of the network (section 3). Finally, the test set was kept hidden and was only used to show the final prediction accuracy at test-time (section 4).\n\n\nMETHODOLOGY: A DEEP FUSION MODEL\n\n\nOverview\n\nBecause of the differing nature of the data sources, it is not straightforward to mix all the data into a neural network (NN); different learning rates are needed. We propose a new fusion NN architecture taking into account the four sources of information. An overview of the architecture we developed is shown in Figure 2. We divided our fusion architecture into three branches: a Wind CNN, a Pressure CNN and a Past tracks + meta NN. The Wind CNN and Pressure CNN are 2D CNNs that take atmospheric fields (long, lat, stacked over height and time) as input, while the Past tracks + meta NN is a small neural network which takes 0D features as input (stacked over time). Each branch of the network makes its predictions independently. We train the parameters of each individual branch of the network for the same task, i.e., predicting the 24 h-forecast track. We then integrate the three networks into a fused network and finetune the parameters. The different steps will be outlined in the following sections.\n\n\nConvolutional Neural Network for Reanalysis\n\nThe reanalysis data are 2D fields on a grid of fixed size. Treating them as images has the advantage to give access to a large literature on image processing, where CNN is the current state-of-the-art. We propose two similar CNN networks for Mean error in km and relative mean error wrt. the mean 24 h displacement distance.\n\nFIGURE 5 | 24 h-forecast mean errors on the whole test set with respect to (A) the current Saffir-Simpson hurricane category (a higher category means a stronger hurricane, dep means tropical depression, storm means tropical storm); (B) its current distance to land.\n\nthe wind and the pressure fields. We separate them into two networks because the type of data is different and thus different learning rates were needed. We stacked the data over height (pressure level) and time, such that the inputs of the CNNs consist of multiple 2D (long, lat) frames or channels. The Pressure CNN has six input channels (each one of size 25 \u00d7 25), while the Wind CNN input consists of 12 channels (u and v are stacked). We used a typical CNN architecture, alternating convolutional layers (Conv layer) and max-pooling layers, with fully connected layers at the end (Simonyan and Zisserman, 2014). Following conventional wisdom in the computer vision literature, all hidden layers are equipped with the rectification (ReLU) non-linearity and batch normalization. In order to select the best architecture, the different configurations that we have evaluated for Wind CNN and Pressure CNN are outlined in Table 1, one per column. All configurations follow the generic design described above and differ only in depth, which is determined by the number of convolutional layers. As shown in Table 2, in order to have fair comparisons among the architectures, we designed configurations with approximately the same number of parameters to estimate. We evaluated the performance on 24-h storm track prediction for the Wind CNN. The result of the architecture evaluation on the validation set is shown in Table 3. We give two scores: Root Mean Square Error (RMSE) and Mean Absolute Error (MAE), in kilometers. With the increase of model depth, there is no clear improvement on the result. Since adding more convolutional layers allows the network to learn features at more levels of abstraction, we chose the intermediate Network C, which consists of 3 convolutional layers and one maxpooling, followed by 4 fully connected layers.\n\nWe also evaluated how adding more historical features from past time steps in the input data can improve performance. In addition to t and t \u2212 6 h, we did not observe any noticeable improvement by including more data from the same location at previous time steps. We thus only kept the times t and t \u2212 6 h.\n\n\nPast Tracks + Meta Neural Network\n\nAnother important source of information are the previous displacements and the other IBTrACS features (see section 2). We chose to use all of the available features, which can be treated as a size-9 vector of 0D components. We designed a small NN of two small fully connected layers (the green branch in Figure 2) to learn the future track from the 0D features. For such 0D features, we also tested other machine learning methods (support vector regression and random forests), giving similar results. We kept the neural network for a better compatibility with the CNNs. We use two past displacements from t \u2212 12 h to t \u2212 6 h and from t \u2212 6 h to t because more past tracks did not improve the performance.\n\n\nFused Neural Network for Wind, Altitude, and Tracks\n\nBecause of the differing natures between the wind fields, pressure fields and past track data, it is not straightforward to mix them as an input of a NN. Indeed, our preliminary experimentation on training a network combining these three types of inputs simultaneously did not give satisfactory enough results. Instead, we first train separately the three individual branches of the network. We then concatenate their two last layers and add a layer at the end of the network (see Figure 2). The new concatenated layers consist of the same weights as before in each branch, plus new connections from each branch to the other ones, which we initialize to zero. That way, the function computed is (at start) the same as previously. We then re-train the whole fused network by allowing every weight to be re-optimized. The number of fused layers (here two) was determined by comparing four different configurations on the validation set, and a different learning rate was tuned on the validation data set for this final optimization.\n\n\nAlgorithmic Details\n\nWe trained our networks using the root mean square error (RMSE) in kilometers between the forecast and the true storm location at t + 24 h as the loss function. We used the Haversine formula, giving great-circle distances between two points on a sphere from their longitudes and latitudes. We added a regularization term in the loss as an L2 penalty on the weights of the model in order to avoid overfitting. The tuning parameter was optimized empirically on the validation set to 0.01. The training was performed by the Adam optimizer, and each model converged within 200 epochs. Every evaluation was repeated three times and an average score was computed in order to assess the robustness to the random weights initialization. Although the training takes nearly 8 h using PyTorch 4.0 on 4 TitanX GPUs with data parallelism (Krizhevsky, 2014), the testing time or inference is only a few seconds.  \n\n\nEXPERIMENTAL EVALUATION\n\n\nResults on the Whole Dataset (All Basins)\n\nWe have compared the fused network, fusing all three branches, with the three single branches of the networks. Figure 4 shows the 24 h-forecast results on the test set, which was 14,256 time steps in total, in absolute distance error. We can see the improvement of fusing networks (mean error: 130 km) with respect to the Wind CNN (mean: 148.9 km), the Pressure CNN (mean: 172.7 km) and the Past tracks + meta NN (mean: 186.6 km) alone. We can also see the importance of separately pre-training the three networks before the fusion, as it improves the mean result by 5 km.\n\nWe have also calculated a persistence forecast baseline: a 24h prediction that is four times the storm's last displacement from t \u2212 6 h to t. The mean error of this baseline on the test set is 196 km, which is more than 60 km higher than our method.\n\nMoreover, if we only test on tropical cyclone time steps excluding depressions, which are storms of lower intensity, our mean prediction error drops from 130 to 109.3 km. Observe in Figure 5A the global trend, showing that tracks from more intense storms are predicted with a lower mean error than less intense storms. The mean error from tropical cyclones of categories 4 and 5 is below 90 km. Figure 5B shows the forecast errors with respect to the current distance to land. We can see that a small distance to land, 200 km or less, is one of the factors impacting the prediction quality. Lastly, we can see in Table 4 for the results on the test set for the different regions or basins that the best results are in the North Atlantic with a mean error of 130.2 km, or 26.5% of the 24 h displacement mean distance. The larger error is found in the South Pacific basin, but it is also the basin where we have the smaller number of samples. It is also worth notice that the IBTrACS database is made of different source agencies depending on the location of the storm, and their reliability are not equal: this might also explain why some basins show higher errors.\n\n\nComparison With Statistical/Consensus Forecasts Methods\n\nWe also compared our fusion model CNN with two existing forecasting models: CLP5 4 , a statistical model which is often used to benchmark other storm track forecasting methods, and OFCL, the National Hurricane Center official forecast (consensus of dynamical models) 5 . We extracted the CLP5 prediction results of years 1989-2016 in the Atlantic and Eastern Pacific basins. We compare in Table 5 our fused network with the statistical CLP5 on the test tropical cyclone time instants at which both methods provided a forecast. This means we compared only when there is a one-to-one correspondence, which is 4,349 time steps from 258 storms. On both basins, our fused network performs better than the CLP5 model on average and in standard deviation. Moreover, the frequency of forecast errors larger to 200 km, or busts, is also lower for our method, especially in the Atlantic (10% compared to 18%). Such comparison is not possible with the OFCL as this model is modified every year and they only provide forecasts of the version N of the model for the year N. We don't know the performance of the recent OFCL models on previous years and it would be unfair for them to compare with old results that were potentially obtained with earlier, less efficient models.\n\nThat is why we compared the yearly results of our fused network performance with the two models on the same subset of the test set. These results (mean and standard deviation) per year are shown in Figure 6. The number of storms and time steps each year for this comparison is presented in Figure 7. From the plot, we can see that our fused network behaves better than the statistical approach CLP5 in most of the years. Our deep learning model performs better than the OFCL forecast until year 2010 for the Pacific basin (2006 for the Atlantic). During the 2010s, the OFCL method improved and its mean errors per year were smaller than ours. We can also notice that none of the large error peaks (ATL: 1993(ATL: , 2003(ATL: , 2012EPAC: 1993EPAC: , 2009EPAC: , 2013 involve our model, which seems to indicate that our method is robust.\n\nFinally, we qualitatively compared the predictions with both OFCL and CLP5 models for recent storms of the test set, such as Tropical Cyclone Odile in 2014 (Figure 8), Tropical Cyclone Hermine in 2016 (Figure 9), and Tropical Cyclone Blas in 2016 (Figure 10). The small bars connect each pair of predicted and ground truth location after 24 h. The longer the length, the larger the error. Even though the official OFCL model has globally smaller forecast errors, on some time points our model outperforms the OFCL. It seems that our method still perform poorly on the land (see Figure 10). A future improvement could be to add the sea/land map as additional feature. Moreover, the three forecasts often have different directions. Quantitatively, we calculated the Pearson correlation coefficient between the errors of the proposed method and the baselines: c fusion,OFCL = 0.33, c fusion,CLP5 = 0.55, also suggesting that the methods behave very differently. A neural network model can thus help the current forecast modelers by providing a complementary prediction that  could be integrated in a consensus method, as their mistakes are different.\n\n\nDISCUSSION\n\nOur method only needs to be trained once, although this training can be improved with more data. After that, only a few seconds are needed to give a forecast for a new storm because prediction or inference using such models is much faster than training them. This is a significant time improvement over dynamical models, whose bottleneck is the computing speed. However, one has to keep in mind that our method needs current and past reanalysis fields. While they are usually quickly calculated, within few hours, it does increase the total forecast time accordingly.\n\nWe have shown a proof-of-concept for 24-h forecasting, and Giffard-Roisin et al. (2018b) shows that the 6-h results are also very satisfactory. Yet, more long-term forecasts could be made using the same structure. We conjecture that for very long forecasts, larger than 25 \u00d7 25 \u2022 images might be needed. Moreover, we worked here on trajectory prediction, yet this model can be easily modified by changing the last layer and be trained for another task, such as intensity prediction (see Giffard-Roisin et al., 2018a). The data was limited to the period 1979-2017, but more data will be acquired each year and the method can improve significantly by adding the new storms in the training set, as for now we still have fewer samples than parameters. With new TC data available each year and with larger image sizes, it will be necessary to scale our method to a larger number of GPUs and make full profit of data parallelism techniques (Krizhevsky, 2014).\n\nOther useful features could be found by using different reanalysis fields. Although our choice of wind and geopotential height fields was driven by an automated feature selection method, we did not test all the possible configurations at every pressure level. Potentially, a more refined selection could increase the overall performance. As an example, for the intensity prediction, we think that surface fields such as sea surface temperature should be reconsidered. Moreover, as it was shown that the storms close to the land or on the land have higher forecast errors, we think that some improvements can be made by adding the land-sea mask image to the 2D features. We could also represent the wind field by streamfunction and velocity potential as opposed to u-and v-wind components, which might help to have less correlated features. Moreover, while the machine learning algorithm could learn the differences of flow direction between North and South, a future improvement could be to FIGURE 10 | 24-h forecast errors (4 time steps ahead) on Tropical Cyclone Hermine in 2016. The bars connect each pair of predicted and ground truth location. The longer the length, the larger the error. At the beginning and at the end of the track, the forecasts were not always available (a complete absence of an error bar should be interpreted as no forecast).\n\nflip the fields North-South and to change the sign of the vwind component. The recent release of the new version of ERA reanalysis, ERA 5, might also increase the accuracy. As Hodges et al. (2017) show, the mean offset in tropical cyclone center position in the ERA-Interm reanalysis product can be up to 1 degree for the period from 1979 to 2012, so moving to ERA 5 and using the GFDL Vortex Tracker (Marchok, 2002) would increase our performance. A comparison to other baseline forecasts, such as TVCN (Track Variable ConseNsus), would also be interesting. Finally, our method could be easily transferred to operational Numerical Weather Prediction data by filtering it to the same spatial resolution.\n\n\nCONCLUSION\n\nWe designed a neural network for the 24 h-cyclone storm track forecasting using a moving frame of reference that makes use of a common dataset and a unique trained NN for every tropical cyclone of both hemispheres. When a new tropical cyclone occurs, our network can give a forecast in only few seconds. We demonstrated the benefit of coupling past displacements and aligned reanalysis images. Moreover, we also compared with traditional forecasting methods and showed the improvement with respect to the statistical CLP5 model. This is only a proofof-concept of deep learning for tropical cyclone forecasting, yet we think that such a different approach as machine learning and NN can be very beneficial if integrated in a consensus method.\n\n\nDATA AVAILABILITY STATEMENT\n\nThe datasets generated for this study are available on request to the corresponding author.\n\n\nAUTHOR CONTRIBUTIONS\n\nSG-R, MY, CM, and GC have designed the architecture. SG-R and MY have developed the codes. GC and BK have provided the infrastructure to develop and train the models. CK has proofread the manuscript.\n\nFIGURE 1 |\n1Database: more than 3,000 tropical/extra-tropical storm tracks since 1979. Dots = initial position, colors = maximal storm strength according to the Saffir-Simpson scale.\n\nFIGURE 2 |\n2General architecture: the three types of data feed three neural networks trained separately. The final fused network is re-trained before predicting the 24 h-forecast displacement.\n\nFIGURE 6 |\n6Yearly average of 24-h storm track forecasting errors (km) and standard deviation on the test set (top figure for storms in Atlantic, bottom figure for storms in East Pacific) for our fused network forecasts (blue), the CLP5 model forecasts (green) and the official NHC forecasts (red), 1989-2016.\n\nFIGURE 8 |\n824-h forecast errors (4 time steps ahead) on Tropical Cyclone Odile in 2016. The bars connect each pair of predicted and ground truth location. The longer the length, the larger the error. At the beginning, the forecasts were not always available (a complete absence of an error bar should be interpreted as no forecast).\n\nFIGURE 9 |\n924-h forecast errors (4 time steps ahead) on Tropical Cyclone Blas in 2016. The bars connect each pair of predicted and ground truth location. The longer the length, the larger the error. At the beginning and at the end of the track, the forecasts were not always available (a complete absence of an error bar should be interpreted as no forecast).\n\nTABLE 1 |\n1Different configurations of Wind CNN tested.ConvNet configurations \n\nA \nB \nC \nD \n\n7 layers \n8 layers \n9 layers \n10 layers \n\ninput (12 channels of size 25*25) \n\nconv3-32 \nmaxpool \n\nconv3-32 \nconv3-32 \nmaxpool \n\nconv3-64 \nconv3-64 \nmaxpool \n\nconv3-256 \n\nconv3-64 \nconv3-64 \nmaxpool \n\nconv3-128 \nconv3-256 \nmaxpool \n\nFC-576 \n\nFC-128 \n\nFC-64 \n\nFC-2 \n\n\n\nTABLE 2 |\n2Number of parameters (in millions) of the four network configurations tested inTable 1.Network \nA \nB \nC \nD \n\nNumber of parameters (\u00d7 10 6 ) \n2.27 \n2.33 \n2.75 \n2.67 \n\n\n\nTABLE 3 |\n3Performance of candidate configurations (Wind CNN) on 24 h storm track prediction, on the validation set using wind fields.FIGURE 4 | Comparison between the three simple networks (the 0D Neural Network, the Pressure CNN and the Wind CNN), the fused network without separate pre-training (gray), and the fused network with pre-training (red, proposed method). 24 h-forecast results on the test set (storms coming from all oceanic basins), in distance between predicted and real locations.Model (from Table 1) \nRoot mean \nsquare error \n(km) \n\nMean absolute \nerror (km) \n\nA \n177.2 \n145.4 \n\nB \n178.2 \n146.6 \n\nC \n177.6 \n145.6 \n\nD \n178.2 \n146.7 \n\n\n\nTABLE 4 |\n424 h-forecast results for the different regions (basins), on the test set.Basin \nMean error (km) Rel. to mean disp. (%) Num. time points \n\nNorth Atlantic \n130.2 \n26.5 \n2,413 \n\nWest Pacific \n136.1 \n27.9 \n4,080 \n\nEast Pacific \n106.9 \n29.3 \n2,142 \n\nSouth Pacific \n161.7 \n41.6 \n693 \n\nNorth Indian \n138.9 \n51.3 \n2,286 \n\nSouth Indian \n136.1 \n41.2 \n3,050 \n\n\n\nTABLE 5 |\n5Mean and standard deviation 24 h-forecast errors for the Atlantic and Pacific basins on the subset of the test set where both predictions were available (total = 4,349 time steps).Model \nAtlantic errors (km) \nEast Pacific errors (km) \n\nMean \nStd \nBusts > 200 km \nBusts > 250 km \nMean \nStd \nBusts > 200 km \nBusts > 250 km \n\nCLP5 \n125 \n90 \n18.3% \n9.8% \n112 \n78 \n4.4% \n2.3% \n\nFusion \n112 \n71 \n10.3% \n4.5% \n88 \n52 \n4.1% \n1.9% \n\nBusts correspond to the ratio of track errors exceeding 200 km (and 250 km). \n\nFrontiers in Big Data | www.frontiersin.org \nNHC track and intensity models, https://www.nhc.noaa.gov/modelsummary.shtml, accessed: 2018-07-04.\nGEFS, https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/ global-ensemble-forecast-system-gefs, accessed: 2018-12-12. needed (few time steps): the CNN encoding time frames as different input channels is more suited than the LSTM model.\nNHC track and intensity models, https://www.nhc.noaa.gov/verification/verify6. shtml, accessed: 2018-07-04. Frontiers in Big Data | www.frontiersin.org\nJanuary 2020 | Volume 3 | Article 1\nFrontiers in Big Data | www.frontiersin.org\nBest track decay, combination of CLIPER5 (Climatology and Persistence model 5 day) and Decay-SHIFOR (Decay Statistical Hurricane Intensity Forecast). 5 National Hurricane Center Forecast Verification, https://www.nhc.noaa.gov/ verification/verify6.shtml, accessed: 2018-07-31.\nFUNDINGThis research leading to these results has received funding from the Jean D'Alembert fellowship from the Fondation Campus Paris-Saclay and DirtyData (ANR-17-CE23-0018) grant.ACKNOWLEDGMENTSWe thank the National Oceanic and Atmospheric Administration (NOAA) and the European Centre for Medium-Range Weather Forecasts (ECMWF) for their online databases IBTrACS and ERA-Interim. This manuscript has been released as a preprint at arXiv(Giffard-Roisin et al., 2019).\nAn empirical evaluation of generic convolutional and recurrent networks for sequence modeling. S Bai, J Z Kolter, V Koltun, arXiv:1803.01271Bai, S., Kolter, J. Z., and Koltun, V. (2018). An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv:1803.01271.\n\nDeep learning for physical processes: incorporating prior scientific knowledge. M De Bezenac, A Pajot, P Gallinari, 10.1088/1742-5468/ab3195J. Stat. Mech. Theory Exp. de Bezenac, M., Pajot, A., and Gallinari, P. (2017). Deep learning for physical processes: incorporating prior scientific knowledge. J. Stat. Mech. Theory Exp. arXiv: 1711.07970. doi: 10.1088/1742-5468/ab3195\n\nThe era-interim reanalysis: configuration and performance of the data assimilation system. D P Dee, S M Uppala, A Simmons, P Berrisford, P Poli, S Kobayashi, 10.1002/qj.828doi: 10.10 02/qj.828Q. J. R. Meteorol. Soc. 137Dee, D. P., Uppala, S. M., Simmons, A., Berrisford, P., Poli, P., Kobayashi, S., et al. (2011). The era-interim reanalysis: configuration and performance of the data assimilation system. Q. J. R. Meteorol. Soc. 137, 553-597. doi: 10.10 02/qj.828\n\nFurther improvements to the statistical hurricane intensity prediction scheme (ships). M Demaria, M Mainelli, L K Shay, J A Knaff, J Kaplan, DeMaria, M., Mainelli, M., Shay, L. K., Knaff, J. A., and Kaplan, J. (2005). Further improvements to the statistical hurricane intensity prediction scheme (ships).\n\n. 10.1175/WAF862.1Weat. Forecast. 20Weat. Forecast. 20, 531-543. doi: 10.1175/WAF862.1\n\nTropical cyclones. K Emanuel, 10.1146/annurev.earth.31.100901.141259Annu. Rev. Earth Planet. Sci. 31Emanuel, K. (2003). Tropical cyclones. Annu. Rev. Earth Planet. Sci. 31, 75-104. doi: 10.1146/annurev.earth.31.100901.141259\n\nA nowcasting model for the prediction of typhoon tracks based on a long short term memory neural network. S Gao, P Zhao, B Pan, Y Li, M Zhou, J Xu, 10.1007/s13131-018-1219-zActa Oceanol. Sin. 37Gao, S., Zhao, P., Pan, B., Li, Y., Zhou, M., Xu, J., et al. (2018). A nowcasting model for the prediction of typhoon tracks based on a long short term memory neural network. Acta Oceanol. Sin. 37, 8-12. doi: 10.1007/s13131-018-1219-z\n\nThe 2018 climate informatics hackathon: hurricane intensity forecast. S Giffard-Roisin, D Gagne, A Boucaud, B K\u00e9gl, M Yang, G Charpiat, 8th International Workshop on Climate Informatics. Boulder, COGiffard-Roisin, S., Gagne, D., Boucaud, A., K\u00e9gl, B., Yang, M., Charpiat, G., et al. (2018a). \"The 2018 climate informatics hackathon: hurricane intensity forecast, \" in 8th International Workshop on Climate Informatics (Boulder, CO), XVII-XX.\n\nFused deep learning for hurricane track forecast from reanalysis data. S Giffard-Roisin, M Yang, G Charpiat, B K\u00e9gl, C Monteleoni, Climate Informatics Workshop Proceedings. Boulder, COGiffard-Roisin, S., Yang, M., Charpiat, G., K\u00e9gl, B., and Monteleoni, C. (2018b). \"Fused deep learning for hurricane track forecast from reanalysis data, \" in Climate Informatics Workshop Proceedings 2018 (Boulder, CO).\n\nTropical cyclone track forecasting using fused deep learning from aligned reanalysis data. S Giffard-Roisin, M Yang, G Charpiat, C Kumler-Bonfanti, B K\u00e9gl, C Monteleoni, arXiv:1910.10566Giffard-Roisin, S., Yang, M., Charpiat, G., Kumler-Bonfanti, C., K\u00e9gl, B., and Monteleoni, C. (2019). Tropical cyclone track forecasting using fused deep learning from aligned reanalysis data. arXiv: 1910.10566.\n\nHow well are tropical cyclones represented in reanalysis datasets?. K Hodges, A Cobb, P L Vidale, 10.1175/JCLI-D-16-0557.1J. Clim. 30Hodges, K., Cobb, A., and Vidale, P. L. (2017). How well are tropical cyclones represented in reanalysis datasets? J. Clim. 30, 5243-5264. doi: 10.1175/JCLI-D-16-0557.1\n\nDeep-hurricane-tracker: tracking and forecasting extreme climate events. S Kim, H Kim, J Lee, S Yoon, S E Kahou, K Kashinath, 2019 IEEE Winter Conference on Applications of Computer Vision (WACV). Waikoloa Village, HIIEEEKim, S., Kim, H., Lee, J., Yoon, S., Kahou, S. E., Kashinath, K., et al. (2019). \"Deep-hurricane-tracker: tracking and forecasting extreme climate events, \" in 2019 IEEE Winter Conference on Applications of Computer Vision (WACV) (Waikoloa Village, HI: IEEE), 1761-1769.\n\nThe international best track archive for climate stewardship (ibtracs) unifying tropical cyclone data. K R Knapp, M C Kruk, D H Levinson, H J Diamond, C J Neumann, 10.1175/2009BAMS2755.1Bull. Am. Meteorol. Soc. 91Knapp, K. R., Kruk, M. C., Levinson, D. H., Diamond, H. J., and Neumann, C. J. (2010). The international best track archive for climate stewardship (ibtracs) unifying tropical cyclone data. Bull. Am. Meteorol. Soc. 91, 363-376. doi: 10.1175/2009BAMS2755.1\n\nA Krizhevsky, arXiv:1404.5997One weird trick for parallelizing convolutional neural networks. CoRR. Krizhevsky, A. (2014). One weird trick for parallelizing convolutional neural networks. CoRR. arXiv:1404.5997.\n\nImagenet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, Advances in Neural Information Processing Systems. Lake TahoeKrizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). \"Imagenet classification with deep convolutional neural networks, \" in Advances in Neural Information Processing Systems (Lake Tahoe), 1097-1105.\n\nHow the ncep tropical cyclone tracker works. T P Marchok, Preprints, 25th Conference on Hurricanes and Tropical Meteorology. San Diego, CAAmerican Meteorological Society1Marchok, T. P. (2002). \"How the ncep tropical cyclone tracker works, \" in Preprints, 25th Conference on Hurricanes and Tropical Meteorology, Vol. 1 (San Diego, CA: American Meteorological Society).\n\nV-net: fully convolutional neural networks for volumetric medical image segmentation. F Milletari, N Navab, S.-A Ahmadi, 2016Milletari, F., Navab, N., and Ahmadi, S.-A. (2016). \"V-net: fully convolutional neural networks for volumetric medical image segmentation, \" in 2016\n\nFourth International Conference on 3D Vision (3DV). Stanford, CAIEEEFourth International Conference on 3D Vision (3DV) (Stanford, CA: IEEE), 565-571.\n\nA sparse recurrent neural network for trajectory prediction of atlantic hurricanes. M Moradi Kordmahalleh, M Gorji Sefidmazgi, A Homaifar, Proceedings of the Genetic and Evolutionary Computation Conference. the Genetic and Evolutionary Computation ConferenceDenver, COACMMoradi Kordmahalleh, M., Gorji Sefidmazgi, M., and Homaifar, A. (2016). \"A sparse recurrent neural network for trajectory prediction of atlantic hurricanes, \" in Proceedings of the Genetic and Evolutionary Computation Conference 2016 (Denver, CO: ACM), 957-964.\n\nSegmenting and tracking extreme climate events using neural networks. M Mudigonda, S Kim, A Mahesh, S Kahou, K Kashinath, D Williams, Deep Learning for Physical Sciences (DLPS) Workshop, held with NIPS Conference. Montreal, QCMudigonda, M., Kim, S., Mahesh, A., Kahou, S., Kashinath, K., Williams, D., et al. (2017). \"Segmenting and tracking extreme climate events using neural networks, \" in Deep Learning for Physical Sciences (DLPS) Workshop, held with NIPS Conference (Montreal, QC).\n\nExtremeweather: a large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events. E Racah, C Beckham, T Maharaj, S E Kahou, M Prabhat, C Pal, Advances in Neural Information Processing Systems. Montreal, QCRacah, E., Beckham, C., Maharaj, T., Kahou, S. E., Prabhat, M., and Pal, C. (2017). \"Extremeweather: a large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events, \" in Advances in Neural Information Processing Systems (Montreal, QC), 3402-3413.\n\nPrediction of a typhoon track using a generative adversarial network and satellite images. M R\u00fcttgers, S Lee, S Jeon, D You, 10.1038/s41598-019-42339-ySci. Rep. 96057R\u00fcttgers, M., Lee, S., Jeon, S., and You, D. (2019). Prediction of a typhoon track using a generative adversarial network and satellite images. Sci. Rep. 9:6057. doi: 10.1038/s41598-019-42339-y\n\nConvolutional LSTM network: a machine learning approach for precipitation nowcasting. X Shi, Z Chen, H Wang, D.-Y Yeung, W.-K Wong, W Woo, Advances in Neural Information Processing Systems. Montreal, QCShi, X., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., and Woo, W.-c. (2015). \"Convolutional LSTM network: a machine learning approach for precipitation nowcasting, \" in Advances in Neural Information Processing Systems (Montreal, QC), 802-810.\n\nK Simonyan, A Zisserman, arXiv:1409.1556Very deep convolutional networks for large-scale image recognition. Simonyan, K., and Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv:1409.1556.\n", "annotations": {"author": "[{\"end\":170,\"start\":152},{\"end\":189,\"start\":171},{\"end\":197,\"start\":190},{\"end\":220,\"start\":198},{\"end\":414,\"start\":221},{\"end\":575,\"start\":415},{\"end\":595,\"start\":576},{\"end\":776,\"start\":596},{\"end\":941,\"start\":777},{\"end\":1043,\"start\":942},{\"end\":1148,\"start\":1044},{\"end\":1176,\"start\":1149}]", "publisher": null, "author_last_name": "[{\"end\":169,\"start\":162},{\"end\":188,\"start\":179},{\"end\":196,\"start\":194},{\"end\":219,\"start\":205},{\"end\":242,\"start\":228},{\"end\":422,\"start\":418},{\"end\":594,\"start\":586},{\"end\":621,\"start\":613},{\"end\":788,\"start\":784},{\"end\":959,\"start\":949}]", "author_first_name": "[{\"end\":159,\"start\":152},{\"end\":161,\"start\":160},{\"end\":178,\"start\":171},{\"end\":193,\"start\":190},{\"end\":204,\"start\":198},{\"end\":227,\"start\":221},{\"end\":417,\"start\":415},{\"end\":585,\"start\":576},{\"end\":605,\"start\":596},{\"end\":612,\"start\":606},{\"end\":783,\"start\":777},{\"end\":948,\"start\":942}]", "author_affiliation": "[{\"end\":325,\"start\":244},{\"end\":413,\"start\":327},{\"end\":536,\"start\":424},{\"end\":574,\"start\":538},{\"end\":775,\"start\":623},{\"end\":902,\"start\":790},{\"end\":940,\"start\":904},{\"end\":1042,\"start\":961},{\"end\":1147,\"start\":1045},{\"end\":1175,\"start\":1150}]", "title": "[{\"end\":137,\"start\":1},{\"end\":1313,\"start\":1177}]", "venue": "[{\"end\":1358,\"start\":1315}]", "abstract": "[{\"end\":3172,\"start\":1886}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3616,\"start\":3601},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4998,\"start\":4976},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5517,\"start\":5492},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5540,\"start\":5517},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6961,\"start\":6943},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7128,\"start\":7103},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7848,\"start\":7831},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8057,\"start\":8032},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8237,\"start\":8218},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8261,\"start\":8244},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8604,\"start\":8578},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8693,\"start\":8676},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8888,\"start\":8866},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9402,\"start\":9378},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9419,\"start\":9402},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9621,\"start\":9592},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10215,\"start\":10192},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10282,\"start\":10265},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10374,\"start\":10352},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10656,\"start\":10632},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10926,\"start\":10896},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11193,\"start\":11159},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":11210,\"start\":11193},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11232,\"start\":11210},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":13964,\"start\":13945},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15239,\"start\":15221},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":17021,\"start\":17000},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18047,\"start\":18025},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22265,\"start\":22235},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":26496,\"start\":26478},{\"end\":30644,\"start\":30634},{\"end\":30656,\"start\":30644},{\"end\":30668,\"start\":30656},{\"end\":30678,\"start\":30668},{\"end\":30690,\"start\":30678},{\"end\":30702,\"start\":30690},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":32593,\"start\":32564},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":33021,\"start\":32992},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":33457,\"start\":33439},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":35012,\"start\":34992},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":35232,\"start\":35217}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36806,\"start\":36623},{\"attributes\":{\"id\":\"fig_1\"},\"end\":37000,\"start\":36807},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37311,\"start\":37001},{\"attributes\":{\"id\":\"fig_3\"},\"end\":37646,\"start\":37312},{\"attributes\":{\"id\":\"fig_4\"},\"end\":38008,\"start\":37647},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":38368,\"start\":38009},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":38547,\"start\":38369},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":39201,\"start\":38548},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":39564,\"start\":39202},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":40124,\"start\":39565}]", "paragraph": "[{\"end\":3843,\"start\":3188},{\"end\":5260,\"start\":3880},{\"end\":6377,\"start\":5318},{\"end\":7245,\"start\":6379},{\"end\":8403,\"start\":7308},{\"end\":8569,\"start\":8405},{\"end\":9883,\"start\":8571},{\"end\":11448,\"start\":9906},{\"end\":11812,\"start\":11466},{\"end\":13062,\"start\":11814},{\"end\":13681,\"start\":13064},{\"end\":14439,\"start\":13717},{\"end\":15004,\"start\":14441},{\"end\":15860,\"start\":15024},{\"end\":16030,\"start\":15882},{\"end\":18910,\"start\":16032},{\"end\":19108,\"start\":18912},{\"end\":19362,\"start\":19110},{\"end\":19949,\"start\":19381},{\"end\":21008,\"start\":19997},{\"end\":21380,\"start\":21056},{\"end\":21647,\"start\":21382},{\"end\":23492,\"start\":21649},{\"end\":23800,\"start\":23494},{\"end\":24543,\"start\":23838},{\"end\":25629,\"start\":24599},{\"end\":26552,\"start\":25653},{\"end\":27196,\"start\":26624},{\"end\":27447,\"start\":27198},{\"end\":28613,\"start\":27449},{\"end\":29935,\"start\":28673},{\"end\":30772,\"start\":29937},{\"end\":31921,\"start\":30774},{\"end\":32503,\"start\":31936},{\"end\":33458,\"start\":32505},{\"end\":34814,\"start\":33460},{\"end\":35519,\"start\":34816},{\"end\":36275,\"start\":35534},{\"end\":36398,\"start\":36307},{\"end\":36622,\"start\":36423}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22579,\"start\":22572},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":22762,\"start\":22755},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23073,\"start\":23066},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":28069,\"start\":28062},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":29069,\"start\":29062}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":3186,\"start\":3174},{\"attributes\":{\"n\":\"1.1.\"},\"end\":3878,\"start\":3846},{\"attributes\":{\"n\":\"1.2.\"},\"end\":5316,\"start\":5263},{\"attributes\":{\"n\":\"1.3.\"},\"end\":7306,\"start\":7248},{\"attributes\":{\"n\":\"1.4.\"},\"end\":9904,\"start\":9886},{\"attributes\":{\"n\":\"1.5.\"},\"end\":11464,\"start\":11451},{\"attributes\":{\"n\":\"2.\"},\"end\":13700,\"start\":13684},{\"attributes\":{\"n\":\"2.1.\"},\"end\":13715,\"start\":13703},{\"attributes\":{\"n\":\"2.2.\"},\"end\":15022,\"start\":15007},{\"attributes\":{\"n\":\"2.3.\"},\"end\":15880,\"start\":15863},{\"attributes\":{\"n\":\"2.4.\"},\"end\":19379,\"start\":19365},{\"attributes\":{\"n\":\"3.\"},\"end\":19984,\"start\":19952},{\"attributes\":{\"n\":\"3.1.\"},\"end\":19995,\"start\":19987},{\"attributes\":{\"n\":\"3.2.\"},\"end\":21054,\"start\":21011},{\"attributes\":{\"n\":\"3.3.\"},\"end\":23836,\"start\":23803},{\"attributes\":{\"n\":\"3.4.\"},\"end\":24597,\"start\":24546},{\"attributes\":{\"n\":\"3.5.\"},\"end\":25651,\"start\":25632},{\"attributes\":{\"n\":\"4.\"},\"end\":26578,\"start\":26555},{\"attributes\":{\"n\":\"4.1.\"},\"end\":26622,\"start\":26581},{\"attributes\":{\"n\":\"4.2.\"},\"end\":28671,\"start\":28616},{\"attributes\":{\"n\":\"5.\"},\"end\":31934,\"start\":31924},{\"attributes\":{\"n\":\"6.\"},\"end\":35532,\"start\":35522},{\"end\":36305,\"start\":36278},{\"end\":36421,\"start\":36401},{\"end\":36634,\"start\":36624},{\"end\":36818,\"start\":36808},{\"end\":37012,\"start\":37002},{\"end\":37323,\"start\":37313},{\"end\":37658,\"start\":37648},{\"end\":38019,\"start\":38010},{\"end\":38379,\"start\":38370},{\"end\":38558,\"start\":38549},{\"end\":39212,\"start\":39203},{\"end\":39575,\"start\":39566}]", "table": "[{\"end\":38368,\"start\":38065},{\"end\":38547,\"start\":38468},{\"end\":39201,\"start\":39047},{\"end\":39564,\"start\":39288},{\"end\":40124,\"start\":39757}]", "figure_caption": "[{\"end\":36806,\"start\":36636},{\"end\":37000,\"start\":36820},{\"end\":37311,\"start\":37014},{\"end\":37646,\"start\":37325},{\"end\":38008,\"start\":37660},{\"end\":38065,\"start\":38021},{\"end\":38468,\"start\":38381},{\"end\":39047,\"start\":38560},{\"end\":39288,\"start\":39214},{\"end\":39757,\"start\":39577}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10559,\"start\":10551},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":13510,\"start\":13502},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14502,\"start\":14494},{\"end\":17743,\"start\":17735},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":20319,\"start\":20311},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":24150,\"start\":24142},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":25089,\"start\":25080},{\"end\":26743,\"start\":26735},{\"end\":27640,\"start\":27631},{\"end\":27853,\"start\":27844},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":30143,\"start\":30135},{\"end\":30235,\"start\":30227},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":30940,\"start\":30930},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":30985,\"start\":30975},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":31032,\"start\":31021},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":31362,\"start\":31352}]", "bib_author_first_name": "[{\"end\":41548,\"start\":41547},{\"end\":41555,\"start\":41554},{\"end\":41557,\"start\":41556},{\"end\":41567,\"start\":41566},{\"end\":41834,\"start\":41833},{\"end\":41848,\"start\":41847},{\"end\":41857,\"start\":41856},{\"end\":42222,\"start\":42221},{\"end\":42224,\"start\":42223},{\"end\":42231,\"start\":42230},{\"end\":42233,\"start\":42232},{\"end\":42243,\"start\":42242},{\"end\":42254,\"start\":42253},{\"end\":42268,\"start\":42267},{\"end\":42276,\"start\":42275},{\"end\":42684,\"start\":42683},{\"end\":42695,\"start\":42694},{\"end\":42707,\"start\":42706},{\"end\":42709,\"start\":42708},{\"end\":42717,\"start\":42716},{\"end\":42719,\"start\":42718},{\"end\":42728,\"start\":42727},{\"end\":43010,\"start\":43009},{\"end\":43323,\"start\":43322},{\"end\":43330,\"start\":43329},{\"end\":43338,\"start\":43337},{\"end\":43345,\"start\":43344},{\"end\":43351,\"start\":43350},{\"end\":43359,\"start\":43358},{\"end\":43717,\"start\":43716},{\"end\":43735,\"start\":43734},{\"end\":43744,\"start\":43743},{\"end\":43755,\"start\":43754},{\"end\":43763,\"start\":43762},{\"end\":43771,\"start\":43770},{\"end\":44161,\"start\":44160},{\"end\":44179,\"start\":44178},{\"end\":44187,\"start\":44186},{\"end\":44199,\"start\":44198},{\"end\":44207,\"start\":44206},{\"end\":44586,\"start\":44585},{\"end\":44604,\"start\":44603},{\"end\":44612,\"start\":44611},{\"end\":44624,\"start\":44623},{\"end\":44643,\"start\":44642},{\"end\":44651,\"start\":44650},{\"end\":44962,\"start\":44961},{\"end\":44972,\"start\":44971},{\"end\":44980,\"start\":44979},{\"end\":44982,\"start\":44981},{\"end\":45270,\"start\":45269},{\"end\":45277,\"start\":45276},{\"end\":45284,\"start\":45283},{\"end\":45291,\"start\":45290},{\"end\":45299,\"start\":45298},{\"end\":45301,\"start\":45300},{\"end\":45310,\"start\":45309},{\"end\":45793,\"start\":45792},{\"end\":45795,\"start\":45794},{\"end\":45804,\"start\":45803},{\"end\":45806,\"start\":45805},{\"end\":45814,\"start\":45813},{\"end\":45816,\"start\":45815},{\"end\":45828,\"start\":45827},{\"end\":45830,\"start\":45829},{\"end\":45841,\"start\":45840},{\"end\":45843,\"start\":45842},{\"end\":46160,\"start\":46159},{\"end\":46437,\"start\":46436},{\"end\":46451,\"start\":46450},{\"end\":46464,\"start\":46463},{\"end\":46466,\"start\":46465},{\"end\":46786,\"start\":46785},{\"end\":46788,\"start\":46787},{\"end\":47196,\"start\":47195},{\"end\":47209,\"start\":47208},{\"end\":47221,\"start\":47217},{\"end\":47620,\"start\":47619},{\"end\":47643,\"start\":47642},{\"end\":47663,\"start\":47662},{\"end\":48140,\"start\":48139},{\"end\":48153,\"start\":48152},{\"end\":48160,\"start\":48159},{\"end\":48170,\"start\":48169},{\"end\":48179,\"start\":48178},{\"end\":48192,\"start\":48191},{\"end\":48695,\"start\":48694},{\"end\":48704,\"start\":48703},{\"end\":48715,\"start\":48714},{\"end\":48726,\"start\":48725},{\"end\":48728,\"start\":48727},{\"end\":48737,\"start\":48736},{\"end\":48748,\"start\":48747},{\"end\":49213,\"start\":49212},{\"end\":49225,\"start\":49224},{\"end\":49232,\"start\":49231},{\"end\":49240,\"start\":49239},{\"end\":49569,\"start\":49568},{\"end\":49576,\"start\":49575},{\"end\":49584,\"start\":49583},{\"end\":49595,\"start\":49591},{\"end\":49607,\"start\":49603},{\"end\":49615,\"start\":49614},{\"end\":49932,\"start\":49931},{\"end\":49944,\"start\":49943}]", "bib_author_last_name": "[{\"end\":41552,\"start\":41549},{\"end\":41564,\"start\":41558},{\"end\":41574,\"start\":41568},{\"end\":41845,\"start\":41835},{\"end\":41854,\"start\":41849},{\"end\":41867,\"start\":41858},{\"end\":42228,\"start\":42225},{\"end\":42240,\"start\":42234},{\"end\":42251,\"start\":42244},{\"end\":42265,\"start\":42255},{\"end\":42273,\"start\":42269},{\"end\":42286,\"start\":42277},{\"end\":42692,\"start\":42685},{\"end\":42704,\"start\":42696},{\"end\":42714,\"start\":42710},{\"end\":42725,\"start\":42720},{\"end\":42735,\"start\":42729},{\"end\":43018,\"start\":43011},{\"end\":43327,\"start\":43324},{\"end\":43335,\"start\":43331},{\"end\":43342,\"start\":43339},{\"end\":43348,\"start\":43346},{\"end\":43356,\"start\":43352},{\"end\":43362,\"start\":43360},{\"end\":43732,\"start\":43718},{\"end\":43741,\"start\":43736},{\"end\":43752,\"start\":43745},{\"end\":43760,\"start\":43756},{\"end\":43768,\"start\":43764},{\"end\":43780,\"start\":43772},{\"end\":44176,\"start\":44162},{\"end\":44184,\"start\":44180},{\"end\":44196,\"start\":44188},{\"end\":44204,\"start\":44200},{\"end\":44218,\"start\":44208},{\"end\":44601,\"start\":44587},{\"end\":44609,\"start\":44605},{\"end\":44621,\"start\":44613},{\"end\":44640,\"start\":44625},{\"end\":44648,\"start\":44644},{\"end\":44662,\"start\":44652},{\"end\":44969,\"start\":44963},{\"end\":44977,\"start\":44973},{\"end\":44989,\"start\":44983},{\"end\":45274,\"start\":45271},{\"end\":45281,\"start\":45278},{\"end\":45288,\"start\":45285},{\"end\":45296,\"start\":45292},{\"end\":45307,\"start\":45302},{\"end\":45320,\"start\":45311},{\"end\":45801,\"start\":45796},{\"end\":45811,\"start\":45807},{\"end\":45825,\"start\":45817},{\"end\":45838,\"start\":45831},{\"end\":45851,\"start\":45844},{\"end\":46171,\"start\":46161},{\"end\":46448,\"start\":46438},{\"end\":46461,\"start\":46452},{\"end\":46473,\"start\":46467},{\"end\":46796,\"start\":46789},{\"end\":47206,\"start\":47197},{\"end\":47215,\"start\":47210},{\"end\":47228,\"start\":47222},{\"end\":47640,\"start\":47621},{\"end\":47660,\"start\":47644},{\"end\":47672,\"start\":47664},{\"end\":48150,\"start\":48141},{\"end\":48157,\"start\":48154},{\"end\":48167,\"start\":48161},{\"end\":48176,\"start\":48171},{\"end\":48189,\"start\":48180},{\"end\":48201,\"start\":48193},{\"end\":48701,\"start\":48696},{\"end\":48712,\"start\":48705},{\"end\":48723,\"start\":48716},{\"end\":48734,\"start\":48729},{\"end\":48745,\"start\":48738},{\"end\":48752,\"start\":48749},{\"end\":49222,\"start\":49214},{\"end\":49229,\"start\":49226},{\"end\":49237,\"start\":49233},{\"end\":49244,\"start\":49241},{\"end\":49573,\"start\":49570},{\"end\":49581,\"start\":49577},{\"end\":49589,\"start\":49585},{\"end\":49601,\"start\":49596},{\"end\":49612,\"start\":49608},{\"end\":49619,\"start\":49616},{\"end\":49941,\"start\":49933},{\"end\":49954,\"start\":49945}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1803.01271\",\"id\":\"b0\"},\"end\":41751,\"start\":41452},{\"attributes\":{\"doi\":\"10.1088/1742-5468/ab3195\",\"id\":\"b1\",\"matched_paper_id\":2808403},\"end\":42128,\"start\":41753},{\"attributes\":{\"doi\":\"10.1002/qj.828\",\"id\":\"b2\",\"matched_paper_id\":123221960},\"end\":42594,\"start\":42130},{\"attributes\":{\"id\":\"b3\"},\"end\":42900,\"start\":42596},{\"attributes\":{\"id\":\"b4\"},\"end\":42988,\"start\":42902},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2582686},\"end\":43214,\"start\":42990},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":134354772},\"end\":43644,\"start\":43216},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":85440850},\"end\":44087,\"start\":43646},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":53597239},\"end\":44492,\"start\":44089},{\"attributes\":{\"id\":\"b9\"},\"end\":44891,\"start\":44494},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":38698717},\"end\":45194,\"start\":44893},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":71152001},\"end\":45687,\"start\":45196},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":118909294},\"end\":46157,\"start\":45689},{\"attributes\":{\"id\":\"b13\"},\"end\":46369,\"start\":46159},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":195908774},\"end\":46738,\"start\":46371},{\"attributes\":{\"id\":\"b15\"},\"end\":47107,\"start\":46740},{\"attributes\":{\"id\":\"b16\"},\"end\":47382,\"start\":47109},{\"attributes\":{\"id\":\"b17\"},\"end\":47533,\"start\":47384},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":18070585},\"end\":48067,\"start\":47535},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":201703393},\"end\":48556,\"start\":48069},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":3694256},\"end\":49119,\"start\":48558},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":115153377},\"end\":49480,\"start\":49121},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":6352419},\"end\":49929,\"start\":49482},{\"attributes\":{\"id\":\"b23\"},\"end\":50163,\"start\":49931}]", "bib_title": "[{\"end\":41831,\"start\":41753},{\"end\":42219,\"start\":42130},{\"end\":43007,\"start\":42990},{\"end\":43320,\"start\":43216},{\"end\":43714,\"start\":43646},{\"end\":44158,\"start\":44089},{\"end\":44959,\"start\":44893},{\"end\":45267,\"start\":45196},{\"end\":45790,\"start\":45689},{\"end\":46434,\"start\":46371},{\"end\":46783,\"start\":46740},{\"end\":47617,\"start\":47535},{\"end\":48137,\"start\":48069},{\"end\":48692,\"start\":48558},{\"end\":49210,\"start\":49121},{\"end\":49566,\"start\":49482}]", "bib_author": "[{\"end\":41554,\"start\":41547},{\"end\":41566,\"start\":41554},{\"end\":41576,\"start\":41566},{\"end\":41847,\"start\":41833},{\"end\":41856,\"start\":41847},{\"end\":41869,\"start\":41856},{\"end\":42230,\"start\":42221},{\"end\":42242,\"start\":42230},{\"end\":42253,\"start\":42242},{\"end\":42267,\"start\":42253},{\"end\":42275,\"start\":42267},{\"end\":42288,\"start\":42275},{\"end\":42694,\"start\":42683},{\"end\":42706,\"start\":42694},{\"end\":42716,\"start\":42706},{\"end\":42727,\"start\":42716},{\"end\":42737,\"start\":42727},{\"end\":43020,\"start\":43009},{\"end\":43329,\"start\":43322},{\"end\":43337,\"start\":43329},{\"end\":43344,\"start\":43337},{\"end\":43350,\"start\":43344},{\"end\":43358,\"start\":43350},{\"end\":43364,\"start\":43358},{\"end\":43734,\"start\":43716},{\"end\":43743,\"start\":43734},{\"end\":43754,\"start\":43743},{\"end\":43762,\"start\":43754},{\"end\":43770,\"start\":43762},{\"end\":43782,\"start\":43770},{\"end\":44178,\"start\":44160},{\"end\":44186,\"start\":44178},{\"end\":44198,\"start\":44186},{\"end\":44206,\"start\":44198},{\"end\":44220,\"start\":44206},{\"end\":44603,\"start\":44585},{\"end\":44611,\"start\":44603},{\"end\":44623,\"start\":44611},{\"end\":44642,\"start\":44623},{\"end\":44650,\"start\":44642},{\"end\":44664,\"start\":44650},{\"end\":44971,\"start\":44961},{\"end\":44979,\"start\":44971},{\"end\":44991,\"start\":44979},{\"end\":45276,\"start\":45269},{\"end\":45283,\"start\":45276},{\"end\":45290,\"start\":45283},{\"end\":45298,\"start\":45290},{\"end\":45309,\"start\":45298},{\"end\":45322,\"start\":45309},{\"end\":45803,\"start\":45792},{\"end\":45813,\"start\":45803},{\"end\":45827,\"start\":45813},{\"end\":45840,\"start\":45827},{\"end\":45853,\"start\":45840},{\"end\":46173,\"start\":46159},{\"end\":46450,\"start\":46436},{\"end\":46463,\"start\":46450},{\"end\":46475,\"start\":46463},{\"end\":46798,\"start\":46785},{\"end\":47208,\"start\":47195},{\"end\":47217,\"start\":47208},{\"end\":47230,\"start\":47217},{\"end\":47642,\"start\":47619},{\"end\":47662,\"start\":47642},{\"end\":47674,\"start\":47662},{\"end\":48152,\"start\":48139},{\"end\":48159,\"start\":48152},{\"end\":48169,\"start\":48159},{\"end\":48178,\"start\":48169},{\"end\":48191,\"start\":48178},{\"end\":48203,\"start\":48191},{\"end\":48703,\"start\":48694},{\"end\":48714,\"start\":48703},{\"end\":48725,\"start\":48714},{\"end\":48736,\"start\":48725},{\"end\":48747,\"start\":48736},{\"end\":48754,\"start\":48747},{\"end\":49224,\"start\":49212},{\"end\":49231,\"start\":49224},{\"end\":49239,\"start\":49231},{\"end\":49246,\"start\":49239},{\"end\":49575,\"start\":49568},{\"end\":49583,\"start\":49575},{\"end\":49591,\"start\":49583},{\"end\":49603,\"start\":49591},{\"end\":49614,\"start\":49603},{\"end\":49621,\"start\":49614},{\"end\":49943,\"start\":49931},{\"end\":49956,\"start\":49943}]", "bib_venue": "[{\"end\":41545,\"start\":41452},{\"end\":41918,\"start\":41893},{\"end\":42344,\"start\":42322},{\"end\":42681,\"start\":42596},{\"end\":42934,\"start\":42920},{\"end\":43086,\"start\":43058},{\"end\":43406,\"start\":43389},{\"end\":43831,\"start\":43782},{\"end\":44260,\"start\":44220},{\"end\":44583,\"start\":44494},{\"end\":45022,\"start\":45015},{\"end\":45391,\"start\":45322},{\"end\":45898,\"start\":45875},{\"end\":46257,\"start\":46188},{\"end\":46524,\"start\":46475},{\"end\":46863,\"start\":46798},{\"end\":47193,\"start\":47109},{\"end\":47434,\"start\":47384},{\"end\":47740,\"start\":47674},{\"end\":48281,\"start\":48203},{\"end\":48803,\"start\":48754},{\"end\":49280,\"start\":49272},{\"end\":49670,\"start\":49621},{\"end\":50037,\"start\":49971},{\"end\":43844,\"start\":43833},{\"end\":44273,\"start\":44262},{\"end\":45413,\"start\":45393},{\"end\":46536,\"start\":46526},{\"end\":46878,\"start\":46865},{\"end\":47448,\"start\":47436},{\"end\":47803,\"start\":47742},{\"end\":48295,\"start\":48283},{\"end\":48817,\"start\":48805},{\"end\":49684,\"start\":49672}]"}}}, "year": 2023, "month": 12, "day": 17}