{"id": 247594053, "updated": "2023-10-05 16:13:13.521", "metadata": {"title": "LeHDC: Learning-Based Hyperdimensional Computing Classifier", "authors": "[{\"first\":\"Shijin\",\"last\":\"Duan\",\"middle\":[]},{\"first\":\"Yejia\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Shaolei\",\"last\":\"Ren\",\"middle\":[]},{\"first\":\"Xiaolin\",\"last\":\"Xu\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Thanks to the tiny storage and efficient execution, hyperdimensional Computing (HDC) is emerging as a lightweight learning framework on resource-constrained hardware. Nonetheless, the existing HDC training relies on various heuristic methods, significantly limiting their inference accuracy. In this paper, we propose a new HDC framework, called LeHDC, which leverages a principled learning approach to improve the model accuracy. Concretely, LeHDC maps the existing HDC framework into an equivalent Binary Neural Network architecture, and employs a corresponding training strategy to minimize the training loss. Experimental validation shows that LeHDC outperforms previous HDC training strategies and can improve on average the inference accuracy over 15% compared to the baseline HDC.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2203.09680", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/dac/DuanLRX22", "doi": "10.1145/3489517.3530593"}}, "content": {"source": {"pdf_hash": "3e7939c6baa390ab7596c5ab7bb52834ec7dfc69", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2203.09680v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "da705daebb2cf134313a0c872dba2eee1f8fffcf", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3e7939c6baa390ab7596c5ab7bb52834ec7dfc69.txt", "contents": "\nLeHDC: Learning-Based Hyperdimensional Computing Classifier\n\n\nShijin Duan duan.s@northeastern.edu \nNortheastern University Boston\nMAUSA\n\nYejia Liu \nUC Riverside Riverside\nCAUSA\n\nShaolei Ren sren@ece.ucr.edu \nUC Riverside Riverside\nCAUSA\n\nXiaolin Xu x.xu@northeastern.edu \nNortheastern University Boston\nMAUSA\n\nLeHDC: Learning-Based Hyperdimensional Computing Classifier\n\nThanks to the tiny storage and efficient execution, hyperdimensional Computing (HDC) is emerging as a lightweight learning framework on resource-constrained hardware. Nonetheless, the existing HDC training relies on various heuristic methods, significantly limiting their inference accuracy. In this paper, we propose a new HDC framework, called LeHDC, which leverages a principled learning approach to improve the model accuracy. Concretely, LeHDC maps the existing HDC framework into an equivalent Binary Neural Network architecture, and employs a corresponding training strategy to minimize the training loss. Experimental validation shows that LeHDC outperforms previous HDC training strategies and can improve on average the inference accuracy over 15% compared to the baseline HDC.\n\nINTRODUCTION\n\nBrain-inspired hyperdimensional computing (HDC) is raised to represent samples by projecting them to extremely high-dimensional vectors, i.e., hypervector [9]. As an emerging method, HDC is a promising alternative to conventional machine learning models like deep neural networks (DNNs), with less storage usage and higher efficiency. Although HDC is not meant to replace DNNs on all complex classification tasks, it indeed shows impressive performance on lightweight tasks and fits well in highly resource-limited Internet-of-Things (IoTs) devices. Given these characteristics, the studies on HDC have been quickly proliferating, including energy efficiency improvement [4,8] and applications on tiny devices [7,18]. Meanwhile, HDC models have also been adopted on various acceleration platforms, such as FPGA [4], GPU [11], and in-memory computing [10], thanks to their high parallelism capacity.\n\nDepending on the format of hypervectors, HDC can be broadly divided into binary HDC and non-binary HDC: the hypervectors and computations in binary HDC are all binarized, while binarization is not used in non-binary HDC. Naturally, non-binary HDC contains richer information expression on hypervectors, but it also costs more computing resources than binary HDC. On the other hand, binary HDC consumes lower energy and resources and is more friendly to hardware implementation. More recently, some heuristic approaches, such as retraining (i.e., fine-tune the class hypervectors after initial training) [4], have been proposed to improve the inference accuracy, making binary HDC achieve a competitive accuracy performance compared to its non-binary counterpart.\n\nNonetheless, the initial training process for an HDC model, binary and non-binary, still heavily depends on a simple strategy of averaging the sample hypervectors to obtain class hypervectors. In other words, there have been no principled approaches to optimally train an HDC model and rigorously learn the class hypervectors that provide the best possible accuracy performance for HDC.\n\nIn this paper, we demonstrate for the first time that a binary HDC classifier is equivalent to a wide single-layer binary neural network (BNN). 1 Specifically, the binary weights in the BNN can be viewed as the class hypervectors in binary HDC, and the Hamming distance between the encoded hypervector and the class hypervectors in binary HDC can be linearly transformed into multiplication of the encoded hypervector and the binary weights. By viewing the class hypervector training process from the BNN perspective, we reveal the key limitations of the current HDC training strategy: heavily relying on heuristic approaches to search for class hypervectors. To address this limitation, we propose a learning-based HDC training strategy, namely LeHDC. Specifically, LeHDC takes the sample hypervector as input, assigns one-hot labels, and optimizes the BNN weights in the training process. The binary weights in the BNN are trained with state-of-the-art learning algorithms, and consequently, these binary weights can be directly converted to class hypervectors for the binary HDC classification. The binary HDC with obtained class hypervectors can achieve significantly higher accuracy than the current retraining strategies. Importantly, LeHDC introduces a completely new training process, but does not modify the encoding or inference processes used in the existing HDC. As a result, LeHDC can be integrated into any existing HDC framework to improve the accuracy performance, yet without any extra resource or execution overhead during the inference.\n\nThe main contributions of this work are as follows:\n\n\u2022 We transform the existing binary HDC classifier into an equivalent BNN, and then reveal the key limitations in the current HDC training process that limit them from obtaining the optimal class hypervectors and achieving the best accuracy. \u2022 We propose a new training strategy, LeHDC, on binary HDC classification, by leveraging state-of-the-art BNN learning algorithms. To the best of our knowledge, this is the first work 1 Our result also applies to non-binary HDC models by changing the BNN to a wide single-layer neural newtork with non-binary weights.\n\nusing learning-based methods to train HDC classifications in a principled manner. \u2022 We show empirically that LeHDC can significantly outperform current HDC models and provide over 15% accuracy improvement against the baseline HDC, while introducing zero resource and time overhead during inference.\n\nOur paper organization is: In Sec. 2, we briefly discuss the HDC classification and current training strategies. Sec. 3 reveals the limitations of the current HDC training process and equivalently expresses the HDC model in a wide single-layer BNN structure. Sec. 4 illustrates the proposed training strategy in LeHDC, and Sec. 5 presents the feasibility of our strategy and compares the performance with other training strategies. The conclusion and discussion on our work are addressed in Sec. 6.\n\n\nHDC CLASSIFICATION TASKS\n\nBinary HDC has been emerging as a novel paradigm that represent attributes with hyperdimensional bi-polar vectors {1, \u22121} [9]. For a specific sample F = { 1 , 2 , ..., } where is the value of the -th feature for = 1, \u00b7 \u00b7 \u00b7 , , its feature positions and feature values are represented by randomly generated hypervectors, whose dimension (e.g., = 10, 000) is much larger than the number of features/values. In a typical HDC model [4], feature position hypervectors (F ) are orthogonal to identify an individual feature, i.e., the normalized Hamming distance \n\n\nBinary HDC\n\nBinary HDC costs much lower power and computational resources, and is also the mainstream HDC framework [4]. By binding feature position hypervectors and value hypervectors, a sample can be described as a new hypervector (H \u2208 {1, \u22121} ):\nH = \u2211\ufe01 =1 F \u2022 V(1)\nwhere this sample has features, and \u2022 denotes the Hadamard product to multiply two hypervectors in element-wise.\n\n(\u00b7) is the sign function to binarize the sum of hypervectors; here we assume (0) is randomly assigned with 1 or -1. In general, an HDC classifier can use record-based or -gram-based encoders [3]. While our training approach applies to any encoding methods (including advanced ones [20] based on sophisticated feature extractions), 2 for a concrete case study, we adopt the commonly-used record-based encoding which, shown in Eq. 1, has higher accuracy than thegram-based method for many applications [3]. Note that LeHDC does not modify the encoding process, and hence can work with any encoders.\n\nTraining. The basic training strategy in HDC is to simply accumulate all the samples belonging to that class, in order to obtain  Figure 1: Binary HDC classification framework.\n\nthe class hypervectors C:\n= \u2211\ufe01 H \u2208\u03a9 H(2)\nwhere denotes the -th class hypervector in C, and \u03a9 is the set of sample hypervectors belonging to class . Inference. A query sample is first encoded using Eq. 1. Then, the similarities, measured in terms of the Hamming distance between the query hypervector and class hypervectors in C are calculated. The most similar one, i.e., the class with the lowest Hamming distance, is labeled as the predicted class. For the ease of understanding the HDC flow, we show the scheme of binary HDC classification in Fig. 1. This procedure is similar to the nearest centroid classification in machine learning [14], which searches for an optimal centroid for each class.\n\n\nTraining Enhancement\n\nVarious training strategies have been proposed to increase accuracy. Here, we introduce a state-of-the-art approach: retraining [4].\n\nEq. 2 gives the initial training results for class hypervectors. The retraining strategy [4] further fine-tunes the initial class hypervectors, in which both non-binary and binary class hypervectors are used for the training. Specifically, the binary class hypervectors are utilized for validation and non-binary ones are used for updating. As shown in Fig. 2, in each retraining iteration, training samples are classified based on the current binary class hypervectors. If a training sample is misclassified, then the non-binary class hypervectors will be updated regarding to the encoded hypervector (H ):\n+ = + + H \u2212 = \u2212 \u2212 H(3)\nwhere + and \u2212 are the correct and misclassified non-binary class hypervectors, respectively, and is referred to as the learning rate. This retraining step intends to increase the influence of misclassified sample on the correct class while reducing it on the misclassified class. The retraining stops when the updating on class hypervectors is negligible.\n\nIn addition, an ensemble approach (e.g., multi-model HDC where multiple models collectively classify each sample [8]) can also increase the accuracy, but the storage size will grow when the number of ensembled HDC models increases. \n\n\nINNER MECHANISM OF HDC CLASSIFIERS\n\nIn this section, we demonstrate the equivalence of a binary HDC classifier to a corresponding BNN for inference. Importantly, we highlight that the existing training strategies for HDC, are mostly heuristics and hence not optimal.\n\n\nFrom Binary HDC to BNN\n\nConsidering a binary HDC classifier, we denote the input feature of a sample as \u2208 R . The encoder in binary HDC will transfer the real-valued input feature to a binary hypervectors:\n( ) : R \u21a6 \u2192 {\u22121, 1} ,\nwhere stands for the dimension of each hypervector, i.e., projecting the sample input from a low dimensional space to a much higher dimension. Assuming there are classes for this HDC classifier, a trained class hypervector set is\nC = { 1 , 2 , ..., } \u2208 {\u22121, 1} \u00d7 ,\nwhere is the -th class hypervector. The predicted label for the sample is\n\u2605 = ( ( ), ),(4)\nwhere A key property is that the hamming distance can be equivalently projected to the cosine similarity:\n(H 1 , H 2 ) = | H 1 \u2260H 2 | represents(H 1 , H 2 ) = 1 \u2212 2 \u00b7 (H 1 , H 2 )\n. To see this point more concretely, we write the cosine similarity of two binary hypervectors H 1 and H 2 as\n(H 1 , H 2 ) = H 1 H 2 \u2225H 1 \u2225 \u2225H 2 \u2225(5)\nwhere \u2225H 1 \u2225 and \u2225H 2 \u2225 denote the 2 norms of H 1 and H 2 , respectively. Due to the bipolar values {1, \u22121} in hypervectors, we have\nH 1 H 2 = (|H 1 = H 2 | \u2212 |H 1 \u2260 H 2 |)\n. Plus the fact that \u2225H 1 \u2225 \u2225H 2 \u2225 = and (|H 1 \u2260 H 2 | + |H 1 = H 2 |) = , we can conclude the equivalence between the Hamming distance and cosine similarity. Therefore, the predicted label \u2605 can be equivalently represented as\n\u2605 = ( ( ), ) = ( ( ), ) = ( )(6)\nRemark. From Eq. 6, we argue that the computation ( ) is actually the same as forward propagation in a BNN. Specifically, as illustrated in Fig. 4, the single-layer BNN takes ( ) as its input and has output neurons that represent classes. The binary connection weights between the input ( ) \u2208 {\u22121, 1} and the -th output neuron is \u2208 {\u22121, 1} , while the -th output is ( ) and non-binary.\n\nWhile binary HDC is the mainstream choice for HDC classifiers, our analysis also applies to non-binary HDC, where the encoded hypervector ( ) and class hypervector can take both nonbinary values. In this case, cosine similarity is directly used as the measure between ( ) and for classification, and a non-binary HDC can be equivalently viewed as a simple single-layer neural network (i.e., perceptron).\n\n\nLimitations in Current HDC Training\n\nBy establishing the equivalence between a binary HDC model and a BNN, we can see that the HDC training process (i.e., finding class hypervectors { 1 , \u00b7 \u00b7 \u00b7 , }) is essentially the same as training the BNN weights 1 , \u00b7 \u00b7 \u00b7 , .\n\nIn the basic HDC training process, each class hypervector is obtained by simply averaging the sample hypervectors ( ) of all the samples belonging to that class. Clearly, this naive approach does not optimize the BNN weight at all. Next, we also highlight the key limitations in the state-of-the-art retraining strategy.\n\n(1) Retraining only updates non-binary class hypervectors that correspond to the misclassified class and the true class, while other class hypervectors stay the unchanged. Intuitively, when a training sample is misclassified, the retraining step can partially mitigate the impact of ( ) on the misclassified class hypervector while enhancing its impact on the true one; when a training sample is correctly classified, no action is taken. However, this strategy neglects two scenarios that could occur during the retraining phase: 1 If a training sample is misclassified, while there are multiple wrong labels with high similarity, only the class hypervector corresponding to the wrong label with the highest similarity is updated. Hence, other wrong class hypervectors can only be updated in the future iterations, or even never get updated. 2 If a training sample is correctly classified, even though the correct label has a slightly higher similarity than other classes (i.e., the other class hypervectors also have high similarities to this sample), no class hypervectors are updated. In this case, albeit correctly classified, this sample is very close to the classification border. If more samples of this kind occur during the training process, over-fitting is likely to happen, thus weakening the generalization of the HDC model. In contrast, there are various mechanisms, such as dropout and regularization, which mitigate the over-fitting in BNNs. Thus, by training the equivalent BNN, we can systematically improve the testing accuracy of HDC models.\n\n(2) All the weights along the updating class hypervector have to be updated with a fixed step size. In the retraining strategy [4], the updating scale is only determined by the encoded hypervector ( ) and a fixed learning rate , as shown in Eq.3. On the other hand, the general updating rule for a (single-layer) DNN is:\n+1 , = , \u2212 L ,(7)\nwhere , is one weight parameter for iteration , L denotes the loss function, is the learning rate, and stands for the sample input equivalent to ( ) in the HDC model. By comparing Eq.3 and Eq.7, we can directly observe that the derivative of the error L , is overlooked in the retraining strategy. For this single-layer network, the derivative of loss function can reflect the similarity between the input ( ) and the class hypervectors , \u2208 {1, 2, ..., }. However, the retraining strategy indeed does not consider the similarity during the updating. As an improved version, adaptive learning rate is proposed in [6], but the adaptability is still determined on the validation error rate or the difference between the similarities of ( ( ), ) and ( ( ), ), not the similarities themselves on all class hypervectors. Consequently, the state-of-the-art retraining strategy will converge very slowly due to updating with incomplete information.\n\n\nCase Study\n\nWe now practically demonstrate how thes limitations can affect HDC training. For the case study, we use Fashion-MNIST dataset [19] to illustrate the inner mechanism of HDC learning. Fashion-MNIST consists of = 60, 000 training images which are classified into = 10 classes, and we set the hypervector dimension as = 10, 000. In Fig. 3, we compare the performance of enhanced retraining against that of the default retraining. We make modifications on top of the existing retraining strategy to enhance the retraining process. Specifically, once a training sample is misclassified, all the class hypervectors that have higher similarities than the correct class hypervector will be updated, instead of only the one with the highest similarity. During the updating, we add the similarity influence. We specify that the ideal Hamming distance between the training sample and the correct/wrong class hypervector is 0/0.5. Then, we calculate the difference between the Hamming distance and the ideal one, and use it as a scaling factor for updating a class hypervector during retraining. This is equivalent to Eq. 7 when the loss function is the squared error.\n\nThe result shows that, for both the training and testing procedures, the enhanced retraining strategy can start with and converge at a higher accuracy, affirming that the discussed limitations indeed limit the retraining strategy. On the other hand, the basic retraining strategy starts to oscillate after the initial convergence. In contrast, the enhanced retraining can make the training/testing procedure more stable, due to the introduction of similarity metric for scaling the updating steps. Nonetheless, the enhancements we make are still heuristic, lacking principled guidance to optimize the class hypervectors in HDC.  \n\n\nLEHDC: THE LEARNING-BASED HDC\n\nWe now present LeHDC as an alternative and principled approach to train the class hypervectors in an HDC classifier. Based on the discovered equivalence between an HDC model and a single-layer BNN, LeHDC leverages state-of-the-art principled learning algorithms to train the BNN weights. Compared to non-binary neural networks, BNN is more challenging to train, as the weights and output values are all binary. For instance, a large learning rate may successfully flip the binary weights but introduce severe oscillation at the same time; while a small learning rate may not be powerful enough to flip binary bits, resulting in the updating trapped in local optima. A BNN model for the binary HDC learning is demonstrated in Fig. 4. Here, ( ) is an encoded sample hypervector and the input to the BNN, C represents the class hypervectors and are the BNN weights, and output o is ( ( ) 1 , \u00b7 \u00b7 \u00b7 , ( ) ) and equivalently measures the similarities between the input and each class. In this paper, we adopt the state-of-the-art BNN training strategy in [15], and propose the following approach to obtaining the optimal class hypervectors. Unlike other BNN models, our single-layer BNN corresponding to the binary HDC model does not require the binary activation function at each output neuron, since the non-binary BNN outputs (i.e., ( ) , for = 1, \u00b7 \u00b7 \u00b7 , ) are directly used to determine the classification result. For the binary weights C \u2208 {\u22121, 1} \u00d7 (i.e., class hypervectors), both binary (C) and non-binary (C ) forms are stored during training. The non-binary hypervectors are utilized to accumulate small gradients, and they are updated during the back propagation. The binary hypervectors are utilized for feed-forward and updated after each iteration as:\nC = (C ) = \u22121 if C < 0 +1 otherwise.(8)\nFor each sample , the true label is one-hot encoded at the output layer. During the training, the softmax function is applied to the output, and the cross entropy is used as the training loss function. Thus, the loss function of the output o = (X) \u00d7 C can be denoted as\nLoss = CrossEntropy(softmax(o), )(9)\nBesides, weight decay is also an important step in BNN training. Weight decay usually behaves as a 2-norm penalty to prevent the weights from evolving too large, which is an effective strategy to mitigate over-fitting during the training. Combined with small gradients accumulated on non-binary class hypervectors, weight decay makes C more sensitive to the input patterns and less dependent on the weight initialization. Hence, the final empirical loss is given as\nL = \u2211\ufe01 CrossEntropy(softmax( ( ) C), ) + 2 \u2225C \u2225 2 (10)\nwhere ( , ) is the training sample and is a regularization weight. As the training configuration, is selected as the optimizer. Regarding the evaluations in [15], can outperform other -based algorithms on the BNN optimization. Moreover, the dropout strategy also plays an indispensable role in the equivalent single-layer BNN training. Since updating all weights is likely to introduces over-fitting, dropout is proposed to greatly prevent the over-fitting [17]. Here, despite that LeHDC only has one layer without a complex architecture, its width is large and all the values corresponding to each class hypervector are straightforwardly updated, based on the gradient of loss. This may force the class hypervectors adapt to the training samples, leading to over-fitting. Hence, dropout is necessary to obtain the better performance on the HDC classification.\n\nWith the equivalent BNN model, we propose LeHDC for binary HDC classification. Our training method solves the mentioned limitations in current HDC training strategies and mitigates the overfitting issue in a principled manner, providing better generalization ability. The cross entropy function along with the weight decay and dropout strategies are only used for training the equivalent BNN. After training, the weight matrix C = (C ) can be directly used as the class hypervectors. The HDC inference process remains the unchanged, without requiring extra resources. Hence, LeHDC induces zero resource and time overhead during inference. Further, our method is inspired by modern BNN training techniques, which have theoretical support to approach the optimum of HDC training, rather than using heuristic training strategies in the existing HDC models.\n\n\nEXPERIMENTS\n\nWe evaluate the proposed LeHDC on several selected benchmarks: CV classification tasks (MNIST [13], Fashion-MNIST [19], and CIFAR-10 [12]) and datasets used in the original retraining work [4] (UCIHAR [1], ISOLET [2], and PAMAP [16]). Our goal is to highlight the advantages of LeHDC over the existing HDC training processes, and hence we mainly compare LeHDC against the existing HDC models. Note that the pros and cons between a general HDC and conventional machine learning models have been extensively studied in the literature, which is thus not the focus in this work [5].\n\nUnless otherwise stated, we adopt the follow configurations in our evaluation. 3 For the retraining strategy, the learning rate is = 0.05, and = 1.5 in the first iteration. We run 150 iterations to ensure the retraining has converged. For the multi-model strategy, we follow the approach in [8] and choose 64 hypervectors per class. For our proposed BNN-training strategy, the hyper-parameters are shown in Table 2. As a baseline reference, we test the benchmarks on binary HDC without any retraining. All the experiments are evaluated with Python on an 3.60GHz Intel i7-9700K CPU with 16GB memory and Tesla P100 GPU with 16GB memory.\n\n\nModel Evaluation\n\nFirst, we validate the significance of weight decay and dropout in LeHDC. In Fig. 5, we show the training and testing trajectories along the iterations on the CIFAR-10 dataset. By considering the weight decay and dropout during training, the testing accuracy can be increased. An interesting observation is that, if considering both the weight decay and dropout, the training accuracy will decrease. However, the testing accuracy in this case is the highest one. This is due to over-fitting that occurs when either weight decay or dropout is not included. Hence, the trained class hypervectors have better generality.  Further, we evaluate the scalability of LeHDC. We show the accuracy degradation along the dimension reduction across different training strategies in Fig. 6. We can see that LeHDC always outperforms other training strategies. Additionally, it achieves the same accuracy as = 2, 000 as the retraining strategy with a much higher dimension = 10, 000. Another observation is that the multi-model strategy sometimes may even perform worse than the baseline binary HDC, such as on the ISOLET dataset.\n\nMoreover, we discuss the computational resource required for different binary HDC frameworks. Since LeHDC only optimizes the  training procedure, without inducing extra computation during inference, it has the same time consumption and resource occupation as the baseline and retraining binary HDC. However, multi-model strategy costs more storage due to the multiple class hypervectors. Also, hardware acceleration on FPGA and in-memory computing is explored to support the inference in microseconds [4,8]. Thus, LeHDC improves the accuracy performance, with the same energy, latency, and size during inference.\n\n\nAccuracy Improvement\n\nWe evaluate the accuracy performance of LeHDC with other HDC training strategies. We fine-tune the training configuration for each dataset, as shown in Table 2. Note that we still use = 10, 000 for the evaluation, in order to make the comparison fair with other strategies. The learning rate will decay during the training, if the training loss increasing is detected. The inference accuracy comparison is shown in Table 1. As shown in the results, baseline HDC performs the worst in most benchmarks. However, the multi-model strategy sometimes even performs worse than the baseline HDC, such as on the CIFAR-10 and ISOLET datasets. By observing the characteristic of these benchmarks, we find that these two datasets have a large number of features or classes, but relatively fewer training samples; thus, the multi-model cannot deal with a complicated HDC classification task without sufficient training samples. Meanwhile, the retraining strategy enhances the training procedure, and has good accuracy improvement against the baseline HDC. On the other hand, our proposed LeHDC further improves the inference accuracy against the retraining. Hence, LeHDC can make the HDC classification closer to an optimum with zero resource and time overhead during inference.\n\n\nCONCLUSION AND DISCUSSION\n\nIn this work, we investigate the existing limitations in current HDC training strategies and construct an equivalent BNN to the binary HDC model. Accordingly, we propose LeHDC to train the class hypervectors on the BNN structure in a principled manner. The evaluation shows that the learning-based BNN strategy can outperform other HDC training strategies, achieving the best close-to-optimal accuracy performance out, while introducing zero resource and time overhead during the HDC inference.\n\nDespite that we only fine-tune the explicit hyper-parameters, the LeHDC strategy outperforms other training strategies on the selected benchmarks. However, we note there are other implicit ones, such as the ratio of validation set and the learning rate decay along the training. Moreover, since HDC model can be equivalently represented as neural network models, along with the advances in training BNNs, we expect that the HDC model performance can be further improved by training an equivalent BNN.\n\nAlthough significantly improving the inference accuracy with the same energy consumption and latency, we admit that the HDCbased inference is still not as powerful as modern DNN framework. For example, a Convolutional Neural Network (CNN) can easily achieve over 90% accuracy on CIFAR-10. This is mainly due to the fundamental limitations of the existing HDC framework, which is essentially a simple single-layer BNN.\n\n\n(F , F ) \u2248 0.5, , \u2208 {1, 2, ..., }. Differently, feature value hypervectors (V) are correlated to reflect the correlations in real values, i.e., (V , are two samples in the value range, , \u2208 [ , ].\n\nFigure 2 :\n2Retraining strategy to adjust class hypervectors against misclassified samples.\n\nFigure 3 :\n3Iteration comparison on the basic[4] and the enhanced retraining strategy. The enhanced method adds similarity consideration and multiple updates during retraining.\n\nFigure 4 :\n4The equivalent BNN model for binary HDC.\n\nFigure 5 :\n5The training and testing accuracy of CIFAR-10 along the iterations. We consider the cases that have weight decay, dropout, and both.\n\nFigure 6 :\n6The change of inference accuracy along with the dimension reduction on Fashion-MNIST and ISOLET datasets.\n\n\nthe normalized Hamming distance operator between any two hypervectors H 1 and H 2 , and |H 1 \u2260 H 2 | denotes the number of different bits in H 1 and H 2 .\n\nTable 1 :\n1Inference accuracy (%) comparison between LeHDC and other strategies. Data are shown with format \u00b1 . Baseline Binary HDC 80.36 \u00b10.11 68.04 \u00b10.17 29.55 \u00b10.35 82.46 \u00b10.11 87.42 \u00b10.15 77.66 \u00b10.01MNIST \nFashion-MNIST CIFAR-10 \nUCIHAR \nISOLET \nPAMAP \nAvg Increment \n\n\u2212 \nMulti-Model [8] \n84.43 \u00b10.5 \n74.05 \u00b10.5 \n22.66 \u00b10.59 82.31 \u00b10.89 83.47 \u00b10.43 91.87 \u00b10.85 \n+2.22 \nRetraining [4] \n89.28 \u00b10.07 \n80.26 \u00b10.27 \n28.42 \u00b11.46 91.25 \u00b10.21 92.70 \u00b10.12 95.64 \u00b10.03 \n+8.67 \n\nLeHDC \n94.74 \u00b10.18 \n87.11 \u00b10.08 \n46.10 \u00b10.20 95.23 \u00b10.16 94.89 \u00b10.17 99.55 \u00b10.05 \n+15.32 \n\n\n\nTable 2 :\n2Hyper-parameters used in LeHDC configurations. WD = Weight Decay 2 LR = Learning Rate 3 B = Batch Size 4 DR = Dropout RateDataset \nParameters \nWD 1 LR 2 \nB 3 DR 4 \nEpochs \nMNIST \n0.05 \n0.01 \n64 \n0.5 \n100 \nFashion-MNIST \n0.03 \n0.1 \n256 0.3 \n200 \nCIAFR-10 \n0.03 0.001 512 0.3 \n200 \nUCIHAR, ISOLET, PAMAP 0.05 \n0.01 \n64 \n0.5 \n100 \n1 \nPer the DAC'22 policy, we are not allowed to make significant non-editorial changes to papers once accepted. Thus, as Ref.[20] (arXiv date 2/10/2022) was not available or cited at the time of our DAC'22 submission on 11/22/2021, it will not be included in the final camera-ready version of this paper.\nSince the existing HDC models in[4,8] are not open-sourced, we build the retraining and multi-model HDC frameworks by ourselves, and the actual numerical values might differ.\n\nA public domain dataset for human activity recognition using smartphones. Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge Luis Reyes-Ortiz , Esann. 3Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, and Jorge Luis Reyes-Ortiz. 2013. A public domain dataset for human activity recognition using smartphones.. In Esann, Vol. 3. 3.\n\nDheeru Dua, Casey Graff, UCI Machine Learning Repository. Dheeru Dua and Casey Graff. 2017. UCI Machine Learning Repository. http: //archive.ics.uci.edu/ml\n\nClassification using hyperdimensional computing: A review. Lulu Ge, K Keshab, Parhi, IEEE Circuits and Systems Magazine. 20Lulu Ge and Keshab K Parhi. 2020. Classification using hyperdimensional com- puting: A review. IEEE Circuits and Systems Magazine 20, 2 (2020), 30-47.\n\nQuantHD: A quantization framework for hyperdimensional computing. Mohsen Imani, Samuel Bosch, Sohum Datta, Sharadhi Ramakrishna, Sahand Salamat, Jan M Rabaey, Tajana Rosing, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. Mohsen Imani, Samuel Bosch, Sohum Datta, Sharadhi Ramakrishna, Sahand Salamat, Jan M Rabaey, and Tajana Rosing. 2019. QuantHD: A quantization framework for hyperdimensional computing. IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems (2019).\n\nA framework for collaborative learning in secure high-dimensional space. Mohsen Imani, Yeseong Kim, Sadegh Riazi, John Messerly, Patric Liu, Farinaz Koushanfar, Tajana Rosing, 2019 IEEE 12th International Conference on Cloud Computing (CLOUD). IEEEMohsen Imani, Yeseong Kim, Sadegh Riazi, John Messerly, Patric Liu, Farinaz Koushanfar, and Tajana Rosing. 2019. A framework for collaborative learning in secure high-dimensional space. In 2019 IEEE 12th International Conference on Cloud Computing (CLOUD). IEEE, 435-446.\n\nAdapthd: Adaptive efficient training for brain-inspired hyperdimensional computing. Mohsen Imani, Justin Morris, Samuel Bosch, Helen Shu, Giovanni De Micheli, Tajana Rosing, IEEE Biomedical Circuits and Systems Conference (BioCAS). IEEE. Mohsen Imani, Justin Morris, Samuel Bosch, Helen Shu, Giovanni De Micheli, and Tajana Rosing. 2019. Adapthd: Adaptive efficient training for brain-inspired hyperdimensional computing. In 2019 IEEE Biomedical Circuits and Systems Con- ference (BioCAS). IEEE, 1-4.\n\nHdna: Energy-efficient dna sequencing using hyperdimensional computing. Mohsen Imani, Tarek Nassar, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI). Abbas Rahimi, and Tajana RosingMohsen Imani, Tarek Nassar, Abbas Rahimi, and Tajana Rosing. 2018. Hdna: Energy-efficient dna sequencing using hyperdimensional computing. In 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI).\n\n. IEEE. IEEE, 271-274.\n\nSearchd: A memory-centric hyperdimensional computing with stochastic training. Mohsen Imani, Xunzhao Yin, John Messerly, Saransh Gupta, Michael Niemier, Sharon Xiaobo, Tajana Hu, Rosing, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. 39Mohsen Imani, Xunzhao Yin, John Messerly, Saransh Gupta, Michael Niemier, Xiaobo Sharon Hu, and Tajana Rosing. 2019. Searchd: A memory-centric hyper- dimensional computing with stochastic training. IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems 39, 10 (2019), 2422-2433.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. Pentti Kanerva, Cognitive computation. 1Pentti Kanerva. 2009. Hyperdimensional computing: An introduction to com- puting in distributed representation with high-dimensional random vectors. Cognitive computation 1, 2 (2009), 139-159.\n\nIn-memory hyperdimensional computing. Geethan Karunaratne, Manuel Le Gallo, Giovanni Cherubini, Luca Benini, Abbas Rahimi, Abu Sebastian, Nature Electronics. Geethan Karunaratne, Manuel Le Gallo, Giovanni Cherubini, Luca Benini, Abbas Rahimi, and Abu Sebastian. 2020. In-memory hyperdimensional computing. Nature Electronics (2020), 1-11.\n\nGenieHD: Efficient DNA pattern matching accelerator using hyperdimensional computing. Yeseong Kim, Mohsen Imani, Niema Moshiri, Tajana Rosing, 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE). Yeseong Kim, Mohsen Imani, Niema Moshiri, and Tajana Rosing. 2020. GenieHD: Efficient DNA pattern matching accelerator using hyperdimensional computing. In 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE).\n\n. IEEE. IEEE, 115-120.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Geoffrey Hinton, Alex Krizhevsky, Geoffrey Hinton, et al. 2009. Learning multiple layers of features from tiny images. (2009).\n\nGradient-based learning applied to document recognition. Y Lecun, L Bottou, Y Bengio, P Haffner, 10.1109/5.726791Proc. IEEE. 86Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. 1998. Gradient-based learning applied to document recognition. Proc. IEEE 86, 11 (1998), 2278-2324. https: //doi.org/10.1109/5.726791\n\nFeature selection and nearest centroid classification for protein mass spectrometry. Ilya Levner, BMC bioinformatics. 6Ilya Levner. 2005. Feature selection and nearest centroid classification for protein mass spectrometry. BMC bioinformatics 6, 1 (2005), 1-14.\n\nZechun Liu, Zhiqiang Shen, Shichao Li, Koen Helwegen, arXiv:2106.11309Dong Huang, and Kwang-Ting Cheng. 2021. How Do Adam and Training Strategies Help BNNs Optimization? arXiv preprint. Zechun Liu, Zhiqiang Shen, Shichao Li, Koen Helwegen, Dong Huang, and Kwang-Ting Cheng. 2021. How Do Adam and Training Strategies Help BNNs Optimization? arXiv preprint arXiv:2106.11309 (2021).\n\nIntroducing a new benchmarked dataset for activity monitoring. Attila Reiss, Didier Stricker, 2012 16th international symposium on wearable computers. IEEEAttila Reiss and Didier Stricker. 2012. Introducing a new benchmarked dataset for activity monitoring. In 2012 16th international symposium on wearable computers. IEEE, 108-109.\n\nImproving neural networks with dropout. Nitish Srivastava, 1827University of TorontoNitish Srivastava. 2013. Improving neural networks with dropout. University of Toronto 182, 566 (2013), 7.\n\nSpamHD: Memory-Efficient Text Spam Detection using Brain-Inspired Hyperdimensional Computing. Rahul Thapa, Bikal Lamichhane, Dongning Ma, Xun Jiao, 2021 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). Rahul Thapa, Bikal Lamichhane, Dongning Ma, and Xun Jiao. 2021. SpamHD: Memory-Efficient Text Spam Detection using Brain-Inspired Hyperdimensional Computing. In 2021 IEEE Computer Society Annual Symposium on VLSI (ISVLSI).\n\n. IEEE. IEEE, 84-89.\n\nHan Xiao, Kashif Rasul, Roland Vollgraf, arXiv:cs.LG/1708.07747 [cs.LG]Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, and Roland Vollgraf. 2017. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. arXiv:cs.LG/1708.07747 [cs.LG]\n\nTao Yu, Yichi Zhang, Zhiru Zhang, Christopher De Sa, arXiv:2202.048052022. Understanding Hyperdimensional Computing for Parallel Single-Pass Learning. arXiv preprintTao Yu, Yichi Zhang, Zhiru Zhang, and Christopher De Sa. 2022. Understanding Hyperdimensional Computing for Parallel Single-Pass Learning. arXiv preprint arXiv:2202.04805 (2022).\n", "annotations": {"author": "[{\"end\":137,\"start\":63},{\"end\":178,\"start\":138},{\"end\":238,\"start\":179},{\"end\":310,\"start\":239}]", "publisher": null, "author_last_name": "[{\"end\":74,\"start\":70},{\"end\":147,\"start\":144},{\"end\":190,\"start\":187},{\"end\":249,\"start\":247}]", "author_first_name": "[{\"end\":69,\"start\":63},{\"end\":143,\"start\":138},{\"end\":186,\"start\":179},{\"end\":246,\"start\":239}]", "author_affiliation": "[{\"end\":136,\"start\":100},{\"end\":177,\"start\":149},{\"end\":237,\"start\":209},{\"end\":309,\"start\":273}]", "title": "[{\"end\":60,\"start\":1},{\"end\":370,\"start\":311}]", "venue": null, "abstract": "[{\"end\":1159,\"start\":372}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b9\"},\"end\":1333,\"start\":1330},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1849,\"start\":1846},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":1851,\"start\":1849},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":1888,\"start\":1885},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":1891,\"start\":1888},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1989,\"start\":1986},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":1999,\"start\":1995},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2029,\"start\":2025},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2681,\"start\":2678},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3372,\"start\":3371},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5263,\"start\":5262},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6349,\"start\":6346},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6655,\"start\":6652},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6902,\"start\":6899},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7359,\"start\":7356},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7450,\"start\":7446},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7668,\"start\":7665},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8584,\"start\":8580},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8796,\"start\":8793},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8891,\"start\":8888},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9903,\"start\":9900},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14711,\"start\":14708},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":15535,\"start\":15532},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":16005,\"start\":16001},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18749,\"start\":18745},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20486,\"start\":20482},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20786,\"start\":20782},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22154,\"start\":22150},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":22174,\"start\":22170},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22193,\"start\":22189},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":22248,\"start\":22245},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":22260,\"start\":22257},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":22272,\"start\":22269},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22288,\"start\":22284},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":22633,\"start\":22630},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":22716,\"start\":22715},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22930,\"start\":22927},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":24911,\"start\":24908},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":24913,\"start\":24911},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":28095,\"start\":28092},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":29734,\"start\":29730},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":29945,\"start\":29942},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":29947,\"start\":29945}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":27952,\"start\":27755},{\"attributes\":{\"id\":\"fig_1\"},\"end\":28045,\"start\":27953},{\"attributes\":{\"id\":\"fig_3\"},\"end\":28223,\"start\":28046},{\"attributes\":{\"id\":\"fig_4\"},\"end\":28277,\"start\":28224},{\"attributes\":{\"id\":\"fig_6\"},\"end\":28423,\"start\":28278},{\"attributes\":{\"id\":\"fig_7\"},\"end\":28542,\"start\":28424},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":28699,\"start\":28543},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":29264,\"start\":28700},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":29607,\"start\":29265}]", "paragraph": "[{\"end\":2073,\"start\":1175},{\"end\":2837,\"start\":2075},{\"end\":3225,\"start\":2839},{\"end\":4782,\"start\":3227},{\"end\":4835,\"start\":4784},{\"end\":5395,\"start\":4837},{\"end\":5695,\"start\":5397},{\"end\":6195,\"start\":5697},{\"end\":6780,\"start\":6224},{\"end\":7031,\"start\":6795},{\"end\":7163,\"start\":7051},{\"end\":7761,\"start\":7165},{\"end\":7939,\"start\":7763},{\"end\":7966,\"start\":7941},{\"end\":8640,\"start\":7982},{\"end\":8797,\"start\":8665},{\"end\":9406,\"start\":8799},{\"end\":9785,\"start\":9430},{\"end\":10019,\"start\":9787},{\"end\":10288,\"start\":10058},{\"end\":10496,\"start\":10315},{\"end\":10748,\"start\":10519},{\"end\":10857,\"start\":10784},{\"end\":10980,\"start\":10875},{\"end\":11164,\"start\":11055},{\"end\":11337,\"start\":11205},{\"end\":11604,\"start\":11378},{\"end\":12023,\"start\":11638},{\"end\":12428,\"start\":12025},{\"end\":12695,\"start\":12468},{\"end\":13017,\"start\":12697},{\"end\":14579,\"start\":13019},{\"end\":14901,\"start\":14581},{\"end\":15860,\"start\":14920},{\"end\":17030,\"start\":15875},{\"end\":17661,\"start\":17032},{\"end\":19456,\"start\":17695},{\"end\":19766,\"start\":19497},{\"end\":20269,\"start\":19804},{\"end\":21185,\"start\":20325},{\"end\":22040,\"start\":21187},{\"end\":22634,\"start\":22056},{\"end\":23270,\"start\":22636},{\"end\":24405,\"start\":23291},{\"end\":25019,\"start\":24407},{\"end\":26309,\"start\":25044},{\"end\":26833,\"start\":26339},{\"end\":27335,\"start\":26835},{\"end\":27754,\"start\":27337}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7050,\"start\":7032},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7981,\"start\":7967},{\"attributes\":{\"id\":\"formula_2\"},\"end\":9429,\"start\":9407},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10518,\"start\":10497},{\"attributes\":{\"id\":\"formula_4\"},\"end\":10783,\"start\":10749},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10874,\"start\":10858},{\"attributes\":{\"id\":\"formula_6\"},\"end\":11019,\"start\":10981},{\"attributes\":{\"id\":\"formula_7\"},\"end\":11054,\"start\":11019},{\"attributes\":{\"id\":\"formula_8\"},\"end\":11204,\"start\":11165},{\"attributes\":{\"id\":\"formula_9\"},\"end\":11377,\"start\":11338},{\"attributes\":{\"id\":\"formula_10\"},\"end\":11637,\"start\":11605},{\"attributes\":{\"id\":\"formula_11\"},\"end\":14919,\"start\":14902},{\"attributes\":{\"id\":\"formula_12\"},\"end\":19496,\"start\":19457},{\"attributes\":{\"id\":\"formula_13\"},\"end\":19803,\"start\":19767},{\"attributes\":{\"id\":\"formula_14\"},\"end\":20324,\"start\":20270}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":23050,\"start\":23043},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":25203,\"start\":25196},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":25466,\"start\":25459}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1173,\"start\":1161},{\"attributes\":{\"n\":\"2\"},\"end\":6222,\"start\":6198},{\"attributes\":{\"n\":\"2.1\"},\"end\":6793,\"start\":6783},{\"attributes\":{\"n\":\"2.2\"},\"end\":8663,\"start\":8643},{\"attributes\":{\"n\":\"3\"},\"end\":10056,\"start\":10022},{\"attributes\":{\"n\":\"3.1\"},\"end\":10313,\"start\":10291},{\"attributes\":{\"n\":\"3.2\"},\"end\":12466,\"start\":12431},{\"attributes\":{\"n\":\"3.3\"},\"end\":15873,\"start\":15863},{\"attributes\":{\"n\":\"4\"},\"end\":17693,\"start\":17664},{\"attributes\":{\"n\":\"5\"},\"end\":22054,\"start\":22043},{\"attributes\":{\"n\":\"5.1\"},\"end\":23289,\"start\":23273},{\"attributes\":{\"n\":\"5.2\"},\"end\":25042,\"start\":25022},{\"attributes\":{\"n\":\"6\"},\"end\":26337,\"start\":26312},{\"end\":27964,\"start\":27954},{\"end\":28057,\"start\":28047},{\"end\":28235,\"start\":28225},{\"end\":28289,\"start\":28279},{\"end\":28435,\"start\":28425},{\"end\":28710,\"start\":28701},{\"end\":29275,\"start\":29266}]", "table": "[{\"end\":29264,\"start\":28904},{\"end\":29607,\"start\":29399}]", "figure_caption": "[{\"end\":27952,\"start\":27757},{\"end\":28045,\"start\":27966},{\"end\":28223,\"start\":28059},{\"end\":28277,\"start\":28237},{\"end\":28423,\"start\":28291},{\"end\":28542,\"start\":28437},{\"end\":28699,\"start\":28545},{\"end\":28904,\"start\":28712},{\"end\":29399,\"start\":29277}]", "figure_ref": "[{\"end\":7901,\"start\":7893},{\"end\":8493,\"start\":8487},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9158,\"start\":9152},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":11784,\"start\":11778},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16209,\"start\":16203},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18426,\"start\":18420},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":23374,\"start\":23368},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":24066,\"start\":24060}]", "bib_author_first_name": "[{\"end\":30166,\"start\":30160},{\"end\":30186,\"start\":30176},{\"end\":30197,\"start\":30193},{\"end\":30211,\"start\":30205},{\"end\":30241,\"start\":30219},{\"end\":30448,\"start\":30442},{\"end\":30459,\"start\":30454},{\"end\":30662,\"start\":30658},{\"end\":30668,\"start\":30667},{\"end\":30946,\"start\":30940},{\"end\":30960,\"start\":30954},{\"end\":30973,\"start\":30968},{\"end\":30989,\"start\":30981},{\"end\":31009,\"start\":31003},{\"end\":31022,\"start\":31019},{\"end\":31024,\"start\":31023},{\"end\":31039,\"start\":31033},{\"end\":31478,\"start\":31472},{\"end\":31493,\"start\":31486},{\"end\":31505,\"start\":31499},{\"end\":31517,\"start\":31513},{\"end\":31534,\"start\":31528},{\"end\":31547,\"start\":31540},{\"end\":31566,\"start\":31560},{\"end\":32010,\"start\":32004},{\"end\":32024,\"start\":32018},{\"end\":32039,\"start\":32033},{\"end\":32052,\"start\":32047},{\"end\":32066,\"start\":32058},{\"end\":32069,\"start\":32067},{\"end\":32085,\"start\":32079},{\"end\":32500,\"start\":32494},{\"end\":32513,\"start\":32508},{\"end\":32969,\"start\":32963},{\"end\":32984,\"start\":32977},{\"end\":32994,\"start\":32990},{\"end\":33012,\"start\":33005},{\"end\":33027,\"start\":33020},{\"end\":33043,\"start\":33037},{\"end\":33058,\"start\":33052},{\"end\":33587,\"start\":33581},{\"end\":33860,\"start\":33853},{\"end\":33880,\"start\":33874},{\"end\":33883,\"start\":33881},{\"end\":33899,\"start\":33891},{\"end\":33915,\"start\":33911},{\"end\":33929,\"start\":33924},{\"end\":33941,\"start\":33938},{\"end\":34248,\"start\":34241},{\"end\":34260,\"start\":34254},{\"end\":34273,\"start\":34268},{\"end\":34289,\"start\":34283},{\"end\":34684,\"start\":34680},{\"end\":34705,\"start\":34697},{\"end\":34883,\"start\":34882},{\"end\":34892,\"start\":34891},{\"end\":34902,\"start\":34901},{\"end\":34912,\"start\":34911},{\"end\":35224,\"start\":35220},{\"end\":35403,\"start\":35397},{\"end\":35417,\"start\":35409},{\"end\":35431,\"start\":35424},{\"end\":35440,\"start\":35436},{\"end\":35847,\"start\":35841},{\"end\":35861,\"start\":35855},{\"end\":36158,\"start\":36152},{\"end\":36403,\"start\":36398},{\"end\":36416,\"start\":36411},{\"end\":36437,\"start\":36429},{\"end\":36445,\"start\":36442},{\"end\":36763,\"start\":36760},{\"end\":36776,\"start\":36770},{\"end\":36790,\"start\":36784},{\"end\":37083,\"start\":37080},{\"end\":37093,\"start\":37088},{\"end\":37106,\"start\":37101},{\"end\":37128,\"start\":37114}]", "bib_author_last_name": "[{\"end\":30174,\"start\":30167},{\"end\":30191,\"start\":30187},{\"end\":30203,\"start\":30198},{\"end\":30217,\"start\":30212},{\"end\":30452,\"start\":30449},{\"end\":30465,\"start\":30460},{\"end\":30665,\"start\":30663},{\"end\":30675,\"start\":30669},{\"end\":30682,\"start\":30677},{\"end\":30952,\"start\":30947},{\"end\":30966,\"start\":30961},{\"end\":30979,\"start\":30974},{\"end\":31001,\"start\":30990},{\"end\":31017,\"start\":31010},{\"end\":31031,\"start\":31025},{\"end\":31046,\"start\":31040},{\"end\":31484,\"start\":31479},{\"end\":31497,\"start\":31494},{\"end\":31511,\"start\":31506},{\"end\":31526,\"start\":31518},{\"end\":31538,\"start\":31535},{\"end\":31558,\"start\":31548},{\"end\":31573,\"start\":31567},{\"end\":32016,\"start\":32011},{\"end\":32031,\"start\":32025},{\"end\":32045,\"start\":32040},{\"end\":32056,\"start\":32053},{\"end\":32077,\"start\":32070},{\"end\":32092,\"start\":32086},{\"end\":32506,\"start\":32501},{\"end\":32520,\"start\":32514},{\"end\":32975,\"start\":32970},{\"end\":32988,\"start\":32985},{\"end\":33003,\"start\":32995},{\"end\":33018,\"start\":33013},{\"end\":33035,\"start\":33028},{\"end\":33050,\"start\":33044},{\"end\":33061,\"start\":33059},{\"end\":33069,\"start\":33063},{\"end\":33595,\"start\":33588},{\"end\":33872,\"start\":33861},{\"end\":33889,\"start\":33884},{\"end\":33909,\"start\":33900},{\"end\":33922,\"start\":33916},{\"end\":33936,\"start\":33930},{\"end\":33951,\"start\":33942},{\"end\":34252,\"start\":34249},{\"end\":34266,\"start\":34261},{\"end\":34281,\"start\":34274},{\"end\":34296,\"start\":34290},{\"end\":34695,\"start\":34685},{\"end\":34712,\"start\":34706},{\"end\":34889,\"start\":34884},{\"end\":34899,\"start\":34893},{\"end\":34909,\"start\":34903},{\"end\":34920,\"start\":34913},{\"end\":35231,\"start\":35225},{\"end\":35407,\"start\":35404},{\"end\":35422,\"start\":35418},{\"end\":35434,\"start\":35432},{\"end\":35449,\"start\":35441},{\"end\":35853,\"start\":35848},{\"end\":35870,\"start\":35862},{\"end\":36169,\"start\":36159},{\"end\":36409,\"start\":36404},{\"end\":36427,\"start\":36417},{\"end\":36440,\"start\":36438},{\"end\":36450,\"start\":36446},{\"end\":36768,\"start\":36764},{\"end\":36782,\"start\":36777},{\"end\":36799,\"start\":36791},{\"end\":37086,\"start\":37084},{\"end\":37099,\"start\":37094},{\"end\":37112,\"start\":37107},{\"end\":37131,\"start\":37129}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":6975432},\"end\":30440,\"start\":30086},{\"attributes\":{\"id\":\"b1\"},\"end\":30597,\"start\":30442},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":216080530},\"end\":30872,\"start\":30599},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":211016154},\"end\":31397,\"start\":30874},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":197642766},\"end\":31918,\"start\":31399},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":203651142},\"end\":32420,\"start\":31920},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":4708051},\"end\":32858,\"start\":32422},{\"attributes\":{\"id\":\"b7\"},\"end\":32882,\"start\":32860},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":209093915},\"end\":33454,\"start\":32884},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":733980},\"end\":33813,\"start\":33456},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":174797921},\"end\":34153,\"start\":33815},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":219858990},\"end\":34599,\"start\":34155},{\"attributes\":{\"id\":\"b12\"},\"end\":34623,\"start\":34601},{\"attributes\":{\"id\":\"b13\"},\"end\":34823,\"start\":34625},{\"attributes\":{\"doi\":\"10.1109/5.726791\",\"id\":\"b14\",\"matched_paper_id\":14542261},\"end\":35133,\"start\":34825},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":5193327},\"end\":35395,\"start\":35135},{\"attributes\":{\"doi\":\"arXiv:2106.11309\",\"id\":\"b16\"},\"end\":35776,\"start\":35397},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":10337279},\"end\":36110,\"start\":35778},{\"attributes\":{\"id\":\"b18\"},\"end\":36302,\"start\":36112},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":235806322},\"end\":36736,\"start\":36304},{\"attributes\":{\"id\":\"b20\"},\"end\":36758,\"start\":36738},{\"attributes\":{\"doi\":\"arXiv:cs.LG/1708.07747 [cs.LG]\",\"id\":\"b21\"},\"end\":37078,\"start\":36760},{\"attributes\":{\"doi\":\"arXiv:2202.04805\",\"id\":\"b22\"},\"end\":37423,\"start\":37080}]", "bib_title": "[{\"end\":30158,\"start\":30086},{\"end\":30656,\"start\":30599},{\"end\":30938,\"start\":30874},{\"end\":31470,\"start\":31399},{\"end\":32002,\"start\":31920},{\"end\":32492,\"start\":32422},{\"end\":32961,\"start\":32884},{\"end\":33579,\"start\":33456},{\"end\":33851,\"start\":33815},{\"end\":34239,\"start\":34155},{\"end\":34880,\"start\":34825},{\"end\":35218,\"start\":35135},{\"end\":35839,\"start\":35778},{\"end\":36396,\"start\":36304}]", "bib_author": "[{\"end\":30176,\"start\":30160},{\"end\":30193,\"start\":30176},{\"end\":30205,\"start\":30193},{\"end\":30219,\"start\":30205},{\"end\":30244,\"start\":30219},{\"end\":30454,\"start\":30442},{\"end\":30467,\"start\":30454},{\"end\":30667,\"start\":30658},{\"end\":30677,\"start\":30667},{\"end\":30684,\"start\":30677},{\"end\":30954,\"start\":30940},{\"end\":30968,\"start\":30954},{\"end\":30981,\"start\":30968},{\"end\":31003,\"start\":30981},{\"end\":31019,\"start\":31003},{\"end\":31033,\"start\":31019},{\"end\":31048,\"start\":31033},{\"end\":31486,\"start\":31472},{\"end\":31499,\"start\":31486},{\"end\":31513,\"start\":31499},{\"end\":31528,\"start\":31513},{\"end\":31540,\"start\":31528},{\"end\":31560,\"start\":31540},{\"end\":31575,\"start\":31560},{\"end\":32018,\"start\":32004},{\"end\":32033,\"start\":32018},{\"end\":32047,\"start\":32033},{\"end\":32058,\"start\":32047},{\"end\":32079,\"start\":32058},{\"end\":32094,\"start\":32079},{\"end\":32508,\"start\":32494},{\"end\":32522,\"start\":32508},{\"end\":32977,\"start\":32963},{\"end\":32990,\"start\":32977},{\"end\":33005,\"start\":32990},{\"end\":33020,\"start\":33005},{\"end\":33037,\"start\":33020},{\"end\":33052,\"start\":33037},{\"end\":33063,\"start\":33052},{\"end\":33071,\"start\":33063},{\"end\":33597,\"start\":33581},{\"end\":33874,\"start\":33853},{\"end\":33891,\"start\":33874},{\"end\":33911,\"start\":33891},{\"end\":33924,\"start\":33911},{\"end\":33938,\"start\":33924},{\"end\":33953,\"start\":33938},{\"end\":34254,\"start\":34241},{\"end\":34268,\"start\":34254},{\"end\":34283,\"start\":34268},{\"end\":34298,\"start\":34283},{\"end\":34697,\"start\":34680},{\"end\":34714,\"start\":34697},{\"end\":34891,\"start\":34882},{\"end\":34901,\"start\":34891},{\"end\":34911,\"start\":34901},{\"end\":34922,\"start\":34911},{\"end\":35233,\"start\":35220},{\"end\":35409,\"start\":35397},{\"end\":35424,\"start\":35409},{\"end\":35436,\"start\":35424},{\"end\":35451,\"start\":35436},{\"end\":35855,\"start\":35841},{\"end\":35872,\"start\":35855},{\"end\":36171,\"start\":36152},{\"end\":36411,\"start\":36398},{\"end\":36429,\"start\":36411},{\"end\":36442,\"start\":36429},{\"end\":36452,\"start\":36442},{\"end\":36770,\"start\":36760},{\"end\":36784,\"start\":36770},{\"end\":36801,\"start\":36784},{\"end\":37088,\"start\":37080},{\"end\":37101,\"start\":37088},{\"end\":37114,\"start\":37101},{\"end\":37133,\"start\":37114}]", "bib_venue": "[{\"end\":30249,\"start\":30244},{\"end\":30498,\"start\":30467},{\"end\":30718,\"start\":30684},{\"end\":31125,\"start\":31048},{\"end\":31641,\"start\":31575},{\"end\":32156,\"start\":32094},{\"end\":32602,\"start\":32522},{\"end\":32866,\"start\":32862},{\"end\":33148,\"start\":33071},{\"end\":33618,\"start\":33597},{\"end\":33971,\"start\":33953},{\"end\":34369,\"start\":34298},{\"end\":34607,\"start\":34603},{\"end\":34678,\"start\":34625},{\"end\":34948,\"start\":34938},{\"end\":35251,\"start\":35233},{\"end\":35581,\"start\":35467},{\"end\":35927,\"start\":35872},{\"end\":36150,\"start\":36112},{\"end\":36512,\"start\":36452},{\"end\":36744,\"start\":36740},{\"end\":36912,\"start\":36831},{\"end\":37229,\"start\":37149}]"}}}, "year": 2023, "month": 12, "day": 17}