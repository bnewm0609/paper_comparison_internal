{"id": 246823233, "updated": "2023-10-05 16:55:12.172", "metadata": {"title": "Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning", "authors": "[{\"first\":\"Zihan\",\"last\":\"Lin\",\"middle\":[]},{\"first\":\"Changxin\",\"last\":\"Tian\",\"middle\":[]},{\"first\":\"Yupeng\",\"last\":\"Hou\",\"middle\":[]},{\"first\":\"Wayne\",\"last\":\"Zhao\",\"middle\":[\"Xin\"]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Recently, graph collaborative filtering methods have been proposed as an effective recommendation approach, which can capture users' preference over items by modeling the user-item interaction graphs. In order to reduce the influence of data sparsity, contrastive learning is adopted in graph collaborative filtering for enhancing the performance. However, these methods typically construct the contrastive pairs by random sampling, which neglect the neighboring relations among users (or items) and fail to fully exploit the potential of contrastive learning for recommendation. To tackle the above issue, we propose a novel contrastive learning approach, named Neighborhood-enriched Contrastive Learning, named NCL, which explicitly incorporates the potential neighbors into contrastive pairs. Specifically, we introduce the neighbors of a user (or an item) from graph structure and semantic space respectively. For the structural neighbors on the interaction graph, we develop a novel structure-contrastive objective that regards users (or items) and their structural neighbors as positive contrastive pairs. In implementation, the representations of users (or items) and neighbors correspond to the outputs of different GNN layers. Furthermore, to excavate the potential neighbor relation in semantic space, we assume that users with similar representations are within the semantic neighborhood, and incorporate these semantic neighbors into the prototype-contrastive objective. The proposed NCL can be optimized with EM algorithm and generalized to apply to graph collaborative filtering methods. Extensive experiments on five public datasets demonstrate the effectiveness of the proposed NCL, notably with 26% and 17% performance gain over a competitive graph collaborative filtering base model on the Yelp and Amazon-book datasets respectively. Our code is available at: https://github.com/RUCAIBox/NCL.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2202.06200", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/www/LinTHZ22", "doi": "10.1145/3485447.3512104"}}, "content": {"source": {"pdf_hash": "3fe92dae73a1d98a52a73c1c46a5be3dafd0c14d", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2202.06200v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "3d5688dd3b6d1b3892e58eae5e0e2e0cbc106a98", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3fe92dae73a1d98a52a73c1c46a5be3dafd0c14d.txt", "contents": "\nImproving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning\nApril 25-29, 2022. 2022. April\n\nZihan Lin \nSchool of Information\nRenmin University of China\nChina\n\nChangxin Tian \nSchool of Information\nRenmin University of China\nChina\n\n\u2020 \nYupeng Hou houyupeng@ruc.edu.cn \nGaoling School of Artificial Intelligence\nRenmin University of China\nChina\n\n\u2020 \nWayne Xin Zhao \nGaoling School of Artificial Intelligence\nRenmin University of China\nChina\n\nBeijing Key Laboratory of Big Data Management and Analysis Methods\nChina\n\nZihan Lin \nChangxin Tian \nYupeng Hou \nWayne Xin \nZhao \nImproving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning\n\nProceedings of the ACM Web Conference 2022 (WWW '22)\nthe ACM Web Conference 2022 (WWW '22)Lyon, FranceApril 25-29, 2022. 2022. April10.1145/3485447.3512104ACM ISBN 978-1-4503-9096-5/22/04. . . $15.00 25-29, 2022, Virtual Event, Lyon, France. ACM, New York, NY, USA, 10 pages.CCS CONCEPTS \u2022 Information systems \u2192 Recommender systems \u2020 Equal contribution Corresponding author\nRecently, graph collaborative filtering methods have been proposed as an effective recommendation approach, which can capture users' preference over items by modeling the user-item interaction graphs. Despite the effectiveness, these methods suffer from data sparsity in real scenarios. In order to reduce the influence of data sparsity, contrastive learning is adopted in graph collaborative filtering for enhancing the performance. However, these methods typically construct the contrastive pairs by random sampling, which neglect the neighboring relations among users (or items) and fail to fully exploit the potential of contrastive learning for recommendation.To tackle the above issue, we propose a novel contrastive learning approach, named Neighborhood-enriched Contrastive Learning, named NCL, which explicitly incorporates the potential neighbors into contrastive pairs. Specifically, we introduce the neighbors of a user (or an item) from graph structure and semantic space respectively. For the structural neighbors on the interaction graph, we develop a novel structure-contrastive objective that regards users (or items) and their structural neighbors as positive contrastive pairs. In implementation, the representations of users (or items) and neighbors correspond to the outputs of different GNN layers. Furthermore, to excavate the potential neighbor relation in semantic space, we assume that users with similar representations are within the semantic neighborhood, and incorporate these semantic neighbors into the prototype-contrastive objective. The proposed NCL can be optimized with EM algorithm and generalized to apply to graph collaborative filtering methods. Extensive experiments on five public datasets demonstrate the effectiveness of the proposed NCL, notably with 26% and 17% performance gain over a competitive graph collaborative filtering base model on the Yelp and Amazon-book datasets, respectively. Our implementation code is available at: https://github.com/RUCAIBox/NCL.\n\nINTRODUCTION\n\nIn the age of information explosion, recommender systems occupy an important position to discover users' preferences and deliver online services efficiently [23]. As a classic approach, collaborative filtering (CF) [10,24] is a fundamental technique that can produce effective recommendations from implicit feedback (expression, click, transaction et al.). Recently, CF is further enhanced by the powerful graph neural networks (GNN) [9,31], which models the interaction data as graphs (e.g., the user-item interaction graph) and then applies GNN to learn effective node representations [9,31] for recommendation, called graph collaborative filtering.\n\nDespite the remarkable success, existing neural graph collaborative filtering methods still suffer from two major issues. Firstly, user-item interaction data is usually sparse or noisy, and it may not be able to learn reliable representations since the graph-based methods are potentially more vulnerable to data sparsity [33]. Secondly, existing GNN based CF approaches rely on explicit interaction links for learning node representations, while high-order relations or constraints (e.g., user or item similarity) cannot be explicitly utilized for enriching the graph information, which has been shown essentially useful in recommendation tasks [24,27,35]. Although several recent studies leverage constative learning to alleviate the sparsity of interaction data [33,39], they construct the contrastive pairs by randomly sampling nodes or corrupting subgraphs. It lacks consideration on how to construct more meaningful contrastive learning tasks tailored for the recommendation task [24,27,35].\n\nBesides direct user-item interactions, there exist multiple kinds of potential relations (e.g., user similarity) that are useful to the recommendation task, and we aim to design more effective constative learning approaches for leveraging such useful relations in neural graph collaborative filtering. Specially, we consider node-level relations w.r.t. a user (or an item), which is more efficient than the graph-level relations. We characterize these additional relations as enriched neighborhood of nodes, which can be defined in two aspects: (1) structural neighbors refer to structurally connected nodes by high-order paths, and (2) Figure 1: Comparison of existing self-supervised learning approaches (e.g., SGL [33]) that neglect the correlation among users (or items) and the proposed neighborhoodenriched contrastive learning approach (our approach).\n\nsemantically similar neighbors which may not be directly reachable on graphs. We aim to leverage these enriched node relations for improving the learning of node representations (i.e., encoding user preference or item characteristics). To integrate and model the enriched neighborhood, we propose Neighborhood-enriched Contrastive Learning (NCL for short), a model-agnostic constative learning framework for the recommendation. As introduced before, NCL constructs node-level contrastive objectives based on two kinds of extended neighbors. We present a comparison between NCL and existing constative learning methods in Figure 1. However, node-level contrastive objectives usually require pairwise learning for each node pair, which is time-consuming for large-sized neighborhoods. Considering the efficiency issue, we learn a single representative embedding for each kind of neighbor, such that the constative learning for a node can be accomplished with two representative embeddings (either structural or semantic).\n\nTo be specific, for structural neighbors, we note that the outputs of -th layer of GNN involve the aggregated information of -hop neighbors. Therefore, we utilize the -th layer output from GNN as the representations of -hop neighbors for a node. We design a structure-aware contrastive learning objective that pulls the representations of a node (a user or item) and the representative embedding for its structural neighbors. For the semantic neighbors, we design a prototypical contrastive learning objective to capture the correlations between a node (a user or item) and its prototype. Roughly speaking, a prototype can be regarded as the centroid of the cluster of semantically similar neighbors in representation space. Since the prototype is latent, we further propose to use an expectation-maximization (EM) algorithm [19] to infer the prototypes. By incorporating these additional relations, our experiments show that it can largely improve the original GNN based approaches (also better than existing constative learning methods) for implicit feedback recommendation. Our contributions can be summarized threefold:\n\n\u2022 We propose a model-agnostic contrastive learning framework named NCL, which incorporates both structural and semantic neighbors for improving the neural graph collaborative filtering.\n\n\u2022 We propose to learn representative embeddings for both kinds of neighbors, such that the constative learning can be only performed between a node and the corresponding representative embeddings, which largely improves the algorithm efficiency.\n\n\u2022 Extensive experiments are conducted on five public datasets, demonstrating that our approach is consistently better than a number of competitive baselines, including GNN and contrastive learningbased recommendation methods.\n\n\nPRELIMINARY\n\nAs the fundamental recommender system, collaborative filtering (CF) aims to recommend relevant items that users might be interested in based on the observed implicit feedback (e.g., expression, click and transaction). Specifically, given the user set U = { } and item set I = { }, the observed implicit feedback matrix is denoted as R \u2208 {0, 1} |U |\u00d7|I | , where each entry , = 1 if there exists an interaction between the user and item , otherwise , = 0. Based on the interaction data R, the learned recommender systems can predict potential interactions for recommendation. Furthermore, Graph Neural Network (GNN) based collaborative filtering methods organize the interaction data R as an interaction graph G = {V, E}, where V = {U \u222a I} denotes the set of nodes and E = {( , ) | \u2208 U, \u2208 I, , = 1} denotes the set of edges.\n\nIn general, GNN-based collaborative filtering methods [9,31,32] produce informative representations for users and items based on the aggregation scheme, which can be formulated to two stages:\n( ) = propagate ({ ( \u22121) | \u2208 N \u222a { }}), = readout ([ (0) ,(1)\n, ...,\n( ) ]),(1)\nwhere N denotes the neighbor set of user in the interaction graph G and denotes the number of GNN layers. Here, (0) is initialized by the learnable embedding vector e . For the user , the propagation function propagate (\u00b7) aggregates the ( \u2212 1)-th layer's representations of its neighbors to generate the -th layer's representation z ( ) . After times iteratively propagation, the information of -hop neighbors is encoded in z ( ) . And the readout function readout (\u00b7) further summarizes all of the representations [\n(0) ,(1)\n, ..., ( ) ] to obtain the final representations of user for recommendation. The informative representations of items can be obtained analogously.\n\n\nMETHODOLOGY\n\nIn this section, we introduce the proposed Neighborhood-enriched Contrastive Learning method in three parts. We first introduce the base graph collaborative filtering approach in Section 3.1, which outputs the final representations for recommendation along with the integrant representations for structural neighbors. Then, we introduce the structure-contrastive strategies and prototype-contrastive strategies in Section 3.2 and Section 3.3 respectively, which integrate the relation of neighbors into contrastive learning to coordinate with collaborative filtering properly. Finally, we propose a multi-task learning strategy in Section 3.4 and further present the theoretical analysis and discussion in Section 3.5. The overall framework of NCL is depicted in Figure 2.\n\n\nGraph Collaborative Filtering BackBone\n\nAs mentioned in Section 2, GNN-based methods produce user and item representations by applying the propagation and prediction function on the interaction graph G. In NCL, we utilize GNN to model the observed interactions between users and items. Specifically, following LightGCN [9], we discard the nonlinear activation and feature transformation in the propagation function as:\n( +1) = \u2211\ufe01 \u2208 1 \u221a\ufe01 |N | |N | ( ) , ( +1) = \u2211\ufe01 \u2208N 1 \u221a\ufe01 |N | |N | ( ) ,(2)\nAfter propagating with layers, we adopt the weighted sum function as the readout function to combine the representations of all layers and obtain the final representations as follows:\n= 1 + 1 \u2211\ufe01 =0 ( ) , = 1 + 1 \u2211\ufe01 =0 ( ) ,(3)\nwhere and denote the final representations of user and item . With the final representations, we adopt inner product to predict how likely a user would interact with items :\n, = z \u22a4 z ,(4)\nwhere\u02c6, is the prediction score of user and items .\n\nTo capture the information from interactions directly, we adopt Bayesian Personalized Ranking (BPR) loss [22], which is a welldesigned ranking objective function for recommendation. Specifically, BPR loss enforces the prediction score of the observed interactions higher than sampled unobserved ones. Formally, the objective function of BPR loss is as follows:\nL = \u2211\ufe01 ( , , ) \u2208 O \u2212 log (\u02c6, \u2212\u02c6, ).(5)\nwhere (\u00b7) is the sigmoid function, O = {( , , )| , = 1, , = 0} denotes the pairwise training data, and denotes the sampled item that user has not interacted with. By optimizing the BPR loss L , our proposed NCL can model the interactions between users and items. However, high-order neighbor relations within users (or within items) are also valuable for recommendations. For example, users are more likely to buy the same product as their neighbors. Next, we will propose two contrastive learning objectives to capture the potential neighborhood relationships of users and items.\n\n\nContrastive Learning with Structural Neighbors\n\nExisting graph collaborative filtering models are mainly trained with the observed interactions (e.g., user-item pairs), while the potential relationships among users or items cannot be explicitly captured by learning from the observed data. In order to fully exploit the advantages of contrastive learning, we propose to contrast each user (or item) with his/her structural neighbors whose representations are aggregated through layer propagation of GNN. Formally, the initial feature or learnable embedding of users/items are denoted by (0) in the graph collaborative filtering model [9]. And the final output can be seen as a combination of the embeddings within a subgraph that contains multiple neighbors at different hops. Specifically, the -th layer's output ( ) of the base GNN model is the weighted sum of \u2212hop structural neighbors of each node, as there is no transformation and self-loop when propagation [9]. Considering that the interaction graph G is a bipartite graph, information propagation with GNN-based model for even times on the graph naturally aggregates information of homogeneous structural neighbors which makes it convenient to extract the potential neighbors within users or items. In this way, we can obtain the representations of homogeneous neighborhoods from the even layer (e.g., 2, 4, 6) output of the GNN model. With these representations, we can efficiently model the relation between users/items and their homogeneous structural neighbors. Specifically, we treat the embedding of users themself and the embedding of the corresponding output of the even-numbered layer GNN as positive pairs. Based on InfoNCE [20], we propose the structure-contrastive learning objective to minimize the distance between them as follows:\nL = \u2211\ufe01 \u2208U \u2212 log exp((z ( ) \u00b7 z (0) / )) \u2208U exp((z ( ) \u00b7 z (0) / )) ,(6)\nwhere z ( ) is the normalized output of GNN layer and is even number. is the temperature hyper-parameter of softmax. In a similar way, the structure-contrastive loss of the item side L can be obtained as:\nL = \u2211\ufe01 \u2208I \u2212 log exp((z ( ) \u00b7 z (0) / )) \u2208I exp((z ( ) \u00b7 z (0) / )) ,(7)\nAnd the complete structure-contrastive objective function is the weighted sum of the above two losses:\nL = L + L .(8)\nwhere is a hyper-parameter to balance the weight of the two losses in structure-contrastive learning.\n\n\nContrastive Learning with Semantic Neighbors\n\nThe structure-contrastive loss explicitly excavates the neighbors defined by the interaction graph. However, the structure-contrastive loss treats the homogeneous neighbors of users/items equally, which inevitably introduces noise information to contrastive pairs. To reduce the influence of noise from structural neighbors, we consider extending the contrastive pairs by incorporating semantic neighbors, which refer to unreachable nodes on the graph but with similar characteristics (item nodes) or preferences (user nodes). Inspired by previous works [16], we can identify the semantic neighbors by learning the latent prototype for each user and item. Based on this idea, we further propose the prototype-contrastive objective to explore potential semantic neighbors and incorporate them into contrastive learning to better capture the semantic characteristics of users and items in collaborative filtering. In particular, similar users/items tend to fall in neighboring embedding space, and the prototypes are the center of clusters that represent a group of semantic neighbors. Thus, we apply a clustering algorithm on the embeddings of users and items to obtain the prototypes of users or items. Since this process cannot be end-to-end optimized, we learn the proposed prototype-contrastive objective with EM algorithm. Formally, the goal of GNN model is to maximize the following log-likelihood function:\n\u2211\ufe01 \u2208U log (e |\u0398, R) = \u2211\ufe01 \u2208U log \u2211\ufe01 c \u2208 (e , c |\u0398, R),(9)\nwhere \u0398 is a set of model parameters and R is the interaction matrix.\n\nAnd is the latent prototype of user . Similarly, we can define the optimization objective for items. After that, the proposed prototype-contrastive learning objective is to minimize the following function based on InfoNCE [20]:\nL = \u2211\ufe01 \u2208U \u2212 log exp(e \u00b7 c / ) c \u2208 exp(e \u00b7 c / ) .(10)\nwhere is the prototype of user which is got by clustering over all the user embeddings with -means algorithm and there are clusters over all the users. The objective on the item side is identical:\nL = \u2211\ufe01 \u2208I \u2212 log exp(e \u00b7 c / ) c \u2208 exp(e \u00b7 c / ) .(11)\nwhere c is the protype of item . The final prototype-contrastive objective is the weighted sum of user objective and item objective:\nL = L + L .(12)\nIn this way, we explicitly incorporate the semantic neighbors of users/items into contrastive learning to alleviate the data sparsity.\n\n\nOptimization\n\nIn this section, we introduce the overall loss and the optimization of the proposed prototype-contrastive objective with EM algorithm.\n\nOverall Training Objective. As the main target of the collaborative filter is to model the interactions between users and items, we treat the proposed two contrastive learning losses as supplementary and leverage a multi-task learning strategy to jointly train the traditional ranking loss and the proposed contrastive loss.\nL = L + 1 L + 2 L + 3 ||\u0398|| 2 ,(13)\nwhere 1 , 2 and 3 are the hyper-parameters to control the weights of the proposed two objectives and the regularization term, respectively, and \u0398 denotes the set of GNN model parameters.\n\nOptimize L with EM algorithm. As Eq. (9) is hard to optimize, we obtain its Lower-Bound (LB) by Jensen's inequality:\n= \u2211\ufe01 \u2208U \u2211\ufe01 c \u2208 (c |e ) log (e , c |\u0398, R) (c |e ) ,(14)\nwhere (c |e ) denotes the distribution of latent variable c when is observed. The target can be redirected to maximize the function over when (c |e ) is estimated. The optimization process is formulated in EM algorithm.\n\nIn the E-step, e is fixed and (c |e ) can be estimated by Kmeans algorithm over the embeddings of all users E. If user belongs to cluster , then the cluster center c is the prototype of the user. And the distribution is estimated by a hard indicator (c |e ) = 1 for c and\u02c6(c |e ) = 0 for other prototypes c .\n\nIn the M-step, the target function can be rewritten with\u02c6( | ):\nL = \u2212 \u2211\ufe01 \u2208U \u2211\ufe01 c \u2208\u02c6( c |e ) log (e , c |\u0398, R),(15)\nwe can assume that the distrubution of users is isotropic Gaussian over all the clusters. So the function can be written as:\nL = \u2212 \u2211\ufe01 \u2208U log exp(\u2212(e \u2212 c ) 2 /2 2 ) c \u2208 exp(\u2212(e \u2212 c ) 2 /2 2 ) ,(16)\nAs and are normalizated beforehand, then (e \u2212 c ) 2 = 2 \u2212 2e \u00b7c . Here we make an assumption that each Gussian distribution has the same derivation, which is written to the temperature hyperparameter . Therefore, the function can be simplified as Eq. (10).\n\n\nDiscussion\n\nNovelty and Differences. For graph collaborative filtering, the construction of neighborhood is more important than other collaborative filtering methods [36], since it is based on the graph structure. To our knowledge, it is the first attempt that leverages both structural and semantic neighbors for graph collaborative filtering. Although several works [14,16,21] treat either structural or sematic neighbors as positive contrastive pairs, our work differs from them in several aspects. For structural neighbors, existing graph contrastive learning methods [8,17,33,34,44] mainly take augmented representations as positive samples, while we take locally aggregated representations as positive samples. Besides, we don't introduce additional graph construction or neighborhood iteration, making NCL more efficient than previous works (e.g., SGL [33]). Besides, some works [21,34,44] make the contrast between the learned node representations and the input node features, while we make the contrast with representations of homogeneous neighbors, which is more suited to the recommendation task.\n\nFurthermore, semantic neighbors have seldom been explored in GNNs for recommendation, while semantic neighbors are necessary to be considered for graph collaborative filtering due to the sparse, noisy interaction graphs. In this work, we apply the prototype learning technique to capture the semantic information, which is different from previous works from computer vision [14] and graph mining [11,16,38]. First, they aim to learn the inherent hierarchical structure among instances, while we aim to identify nodes with similar preferences/characteristics by capturing underlying associations. Second, they model prototypes as clusters of Time and Space Complexity. In the proposed two contrastive learning objectives, assume that we sample users or items as negative samples. Then, the time complexity of the proposed method can be roughly estimated as O \u00b7 ( + ) \u00b7 where is the total number of users and items, is the number of prototypes we defined and is the dimension embedding vector. When we set \u226a and \u226a the total time complexity is approximately linear with the number of users and items. As for the space complexity, the proposed method does not introduce additional parameters besides the GNN backbone. In particular, our NCL save nearly half of space compared to other self-supervised methods (e.g., SGL [33]), as we explicitly utilize the relation within users and items instead of explicit data augmentation. In a word, the proposed NCL is an efficient and effective contrastive learning paradigm aiming at collaborative filtering tasks.\n\n\nEXPERIMENTS\n\nTo verify the effectiveness of the proposed NCL, we conduct extensive experiments and report detailed analysis results. \u2212 Multi-GCCF [27] propagates information among high-order correlation users (and items) besides user-item bipartite graph. \u2212 DGCF [32] produces disentangled representations for user and item to improve the performance of recommendation. \u2212 LightGCN [9] simplifies the design of GCN to make it more concise and appropriate for recommendation. \u2212 SGL [33] introduces self-supervised learning to enhance recommendation. We adopt SGL-ED as the instantiation of SGL.\n\n\nExperimental Setup\n\n\nEvaluation Metrics.\n\nTo evaluate the performance of toprecommendation, we adopt two widely used metrics Recall@ and NDCG@ , where is set to 10, 20 and 50 for consistency. Following [9,33], we adopt the full-ranking strategy [42], which ranks all the candidate items that the user has not interacted with.  Table 2 shows the performance comparison of the proposed NCL and other baseline methods on five datasets. From the table, we find several observations:\n\n\nOverall Performance\n\n(1) Compared to the traditional methods, such as BPRMF, GNNbased methods outperform as they encode the high-order information of bipartite graphs into representations. Among all the graph collaborative filtering baseline models, LightGCN performs best in most datasets, which shows the effectiveness and robustness of the simplified architecture [9]. Surprisingly, Multi-GCCF performs worse than NGCF on ML-1M, probably because the projection graphs built directly from user-item graphs are so dense that the neighborhoods of different users or items on the projection graphs are overlapping and indistinguishable. Besides, the disentangled representation learning method DGCF is worse than LightGCN, especially on the sparse dataset. We speculate that the dimension of disentangled representation may be too low to carry adequate characteristics as we astrict the overall dimension. In addition, FISM performs better than NGCF on three datasets (ML-1M, Yelp, and AmazonBooks), indicating that a heavy GNN architecture is likely to overfit over sparse user-item interaction data.\n\n(2) For the self-supervised method, SGL [33] consistently outperforms other supervised methods on five datasets, which shows the effectiveness of contrastive learning for improving the recommendation performance. However, SGL contrasts the representations derived from the original graph with an augmented graph, which neglects other potential relations (e.g., user similarity) in recommender systems. The best result is bolded and the runner-up is underlined. * indicates the statistical significance for < 0.01 compared to the best baseline.\n\n(3) Finally, we can see that the proposed NCL consistently performs better than baselines. This advantage is brought by the neighborhood-enriched contrastive learning objectives. Besides, the improvement at smaller positions (e.g., top 10 ranks) is greater than that at larger positions (e.g., top 50 ranks), indicating that NCL tends to rank the relevant items higher, which is significative in real-world recommendation scenario. In addition, our method yields more improvement on small datasets, such as ML-1M and Yelp datasets. We speculate that a possible reason is that the interaction data of those datasets are more sparse, and there are not sufficient neighbors to construct the contrastive pairs.\n\n\nFurther Analysis of NCL\n\nIn this section, we further perform a series of detailed analysis on the proposed NCL to confirm its effectiveness. Due to the limited space, we only report the results on ML-1M and Yelp datasets, and the observations are similar on other datasets.\n\n\nAblation Study of NCL.\n\nOur proposed approach NCL leverages the potential neighbors in two aspects. To verify the effectiveness of each kind of neighbor, we conduct the ablation study to analyze their contribution. The results are reported in Figure 3, where \"w/o s-n\" and \"w/o p-n\" denote the variants by removing structural neighbors and semantic neighbors, respectively. From this figure, we can observe that removing each of the relations leads to the performance decrease while the two variants are both perform better than the baseline LightGCN. It indicates that explicitly modeling both kinds of relations will benefit the performance in graph collaborative filtering. Besides, these two relations complement each other and improve the performance in different aspects. performance of NCL and LightGCN on these five groups of users and report the results in Figure 4. From this figure, we can find that the performance of NCL is consistently better than LightGCN. Meanwhile, as the number of interactions decreases, the performance gain brought by NCL increases. This implies that NCL can perform high-quality recommendation with sparse interaction data, benefited by the proposed neighborhood modeling techniques.\n\n\nEffect of Structural Neighbors.\n\nIn NCL , the structural neighbors correspond to different layers of GNN. To investigate the impact of different structural neighbors, we select the nodes in one-, two-, and three-hop as the structural neighbors and test the effectiveness when incorporating them with contrastive learning. The results are shown in Table 3. We can find that the three variants of NCL all perform similar or better than LightGCN, which further indicates the effectiveness of the proposed hop-contrastive strategy. Specifically, the results of the first even layer are the best among these variants. This accords with the intuition that users or items should be more similar to their direct neighbors than indirect neighbors. Besides, in our experiments, one-hop neighbors seem to be sufficient for NCL , making a good trade-off between effectiveness and efficiency.\n\n\nImpact of the Coefficient .\n\nIn the structure-contrastive loss defined in Eq. (8), the coefficient can balance the two losses for structural neighborhood modeling. To analyze the influence of , we vary in the range of 0.1 to 2 and report the results in Figure 5a. It shows that an appropriate can effectively improve the performance of NCL. Specifically, when the hyper-parameter is set to around 1, the performance is better on both datasets, indicating that the high-order similarities of both users and goods are valuable. In addition, with different , the performance of NCL is  consistently better than that of LightGCN, which indicates that NCL is robust to parameter .\n\n4.3.5 Impact of the Temperature . As in previous works mentioned [2,41], the temperature defined in Eq.(6) and Eq.(10) plays an important role in contrastive learning. To analyze the impact of temperature on NCL, we vary in the range of 0.05 to 0.15 and show the results in Figure 5(b). We can observe that a too large value of will cause poor performance, which is consistent with the experimental results reported in [41]. In addition, the suitable temperature corresponding to Yelp dataset is smaller, which indicates that the temperature of NCL should be smaller on more sparse datasets. Generally, a temperature in the range of [0.05, 0.1] can lead to good recommendation performance.\n\n\nImpact of the Prototype Number .\n\nTo study the effect of prototype-contrastive objective, we set the number of prototypes from hundreds to thousands and remove it by setting as zero. The results are reported in Figure 5(c). As shown in Figure 5(c), NCL with different consistently outperforms the baseline and the best result is achieved when is around 1000. It indicates that a large number of prototypes can better mitigate the noise introduced by structural neighbors. When we set as zero, the performance decreases significantly, which shows that semantic neighbors are very useful to improve the recommendation performance.\n\n\n4.3.7\n\nApplying NCL on Other GNN Backbones. As the proposed NCL architecture is model agnostic, we further test its performance with other GNN architectures. The results are reported in Table 4.  From this table, we can observe that the proposed method can consistently improve the performance of NGCF, DGCF, and LightGCN, which further verifies the effectiveness of the proposed method. Besides, the improvement on NGCF and DGCF is not as remarkable as the improvement on LightGCN. A possible reason is that Light-GCN removes the parameter and non-linear activation in layer propagation which ensures the output of different layers in the same representation space for structural neighborhood modeling.\n\n\nVisualizing the Distribution of Representations.\n\nA key contribution of the proposed NCL is to integrate two kinds of neighborhood relations in the contrastive tasks for graph collaborative filtering. To better understand the benefits brought by NCL, we visualize the learned embeddings in Figure 6 to show how the proposed approach affects representation learning. We plot item embedding distributions with Gaussian kernel density estimation (KDE) in two-dimensional space. We can see that, embeddings learned by LightGCN fall into several coherent clusters, while those representations learned by NCL clearly exhibit a more uniform distribution. We speculate that a more uniform distribution of embeddings endows a better capacity to model the diverse user preferences or item characteristics. As shown in previous studies [30], there exists strong correlation between contrastive learning and uniformity of the learned representations, where it prefers a feature distribution that preserves maximal information about representations.\n\n\nRELATED WORK\n\nIn this section, we briefly review the related works in two aspects, namely graph-based collaborative filtering and contrastive learning.\n\nGraph-based collaborative filtering. Different from traditional CF methods, such as matrix factorization-based methods [13,22] and auto-encoder-based methods [15,25], graph-based collaborative filtering organize interaction data into an interaction graph and learn meaningful node representations from the graph structure information. Early studies [1,6] extract the structure information through random walks in the graph. Next, Graph Neural Networks (GNN) are adopted on collaborative filtering [9,31,32,40]. For instance, NGCF [31] and LightGCN [9] leverage the high-order relations on the interaction graph to enhance the recommendation performance. Besides, some studies [27] further propose to construct more interaction graphs to capture more rich association relations among users and items. Despite the effectiveness, they don't explicilty address the data sparsity issue. More recently, selfsupervised learning is introduced into graph collaborative filtering to improve the generalization of recommendation. For example, SGL [33] devise random data argumentation operator and construct the contrastive objective to improve the accuracy and robustness of GCNs for recommendation. However, most of the graph-based methods only focus on interaction records but neglect the potential neighbor relations among users or items.\n\nContrastive learning. Since the success of contrastive learning in CV [2], contrastive learning has been widely applied on NLP [5], graph data mining [17,34] and recommender systems [28,37]. As for graph contrastive learning, existing studies can be categorized into node-level contrastive learning [29,45] and graph-level contrastive learning [26,41]. For instance, GRACE [44] proposes a framework for node-level graph contrastive learning, and performs corruption by removing edges and masking node features. MV-GRL [8] transforms graphs by graph diffusion, which considers the augmentations in both feature and structure spaces on graphs. Besides,inspired by the pioneer study in computer vision [14], several methods [11,16,38] are proposed to adopt prototypical contrastive learning to capture the semantic information in graphs. Related to our work, several studies also apply contrastive learning to recommendation, such as SGL [33]. However, existing methods construct the contrastive pairs by random sampling, and do not fully consider the relations among users (or items) in recommendation scenario. In this paper, we propose to explicilty model these potential neighbor relations via contrastive learning.\n\n\nCONCLUSION AND FUTURE WORK\n\nIn this work, we propose a novel contrastive learning paradigm, named Neighborhood-enriched Contrastive Learning (NCL), to explicitly capture potential node relatedness into contrastive learning for graph collaborative filtering. We consider the neighbors of users (or items) from the two aspects of graph structure and semantic space, respectively. Firstly, to leverage structural neighbors on the interaction graph, we develop a novel structure-contrastive objective that can be combined with GNN-based collaborative filtering methods. Secondly, to leverage semantic neighbors, we derive the prototypes of users/items by clustering the embeddings and incorporating the semantic neighbors into the prototype-contrastive objective. Extensive experiments on five public datasets demonstrate the effectiveness of the proposed NCL .\n\nAs future work, we will extend our framework to other recommendation tasks, such as sequential recommendation. Besides, we will also consider developing a more unified formulation for leveraging and utilizing different kinds of neighbors. \n\n\nB CASE STUDY ON SELECTED NEIGHBORS\n\nTo further analyze the difference between structural neighbors and semantic neighbors, we randomly select a central item on Alibaba-iFashion dataset and extract its structural neighbors and semantic neighbors, respectively. For the two types of neighbors extracted, we count the number of items in each category, respectively. The number is normalized and visualized in Fig. 7. For comparison, we also report the collection of randomly sampled items. As shown in the figure, the randomly sampled neighbors are uncontrollable, which astrict the potential of contrastive learning. Meanwhile, the proposed structural and semantic neighbors are more related, which are more suitable to be contrastive pairs.\n\nFigure 2 :\n2Overall framework of our proposed neighborhoodenriched contrastive collaborative filtering method.\n\nFigure 3 :Figure 4 :\n34of Data Sparsity Levels. To further verify the proposed NCL can alleviate the sparsity of interaction data, we evaluate the performance of NCL on users with different sparsity levels in this part. Concretely, we split all the users into five groups based on their interaction number, while keeping the total number of interactions in each group constant. Then, we compare the recommendation Performance of NCL on two datasets without structural neighbors and semantic neighbors (Recall@10). Performance analysis for different sparsity-level users (Recall@10). 1 denotes the group of users with the lowest average number of interactions.\n\nFigure 5 :\n5Performance comparison w.r.t. different , and . The top shows the Recall@10 results on MovieLens-1M and the bottom shows the results on Yelp.\n\nFigure 6 :\n6Visualization of item embeddings. Items from ML-1M and Yelp are illustrated in (a), (b) and (c), (d), respectively.\n\nFigure 7 :,\n7Case study of the contrastive items sampled from random and proposed structural and semantic neighbors. A PSEUDO-CODE FOR NCL Algorithm 1: Neighborhood-enriched Constrastive Learning (NCL) Input: bipartite graph G = {U \u222a I, E}, training dataset X, number of clusters = { } 2 =1 , learning rate ; Output: user and item representations { , }; 1 Initialize: random initialize user embeddings and item embeddings ; 2 while Not Convergence do // E-step 3 for m=1 to M do 4 = k-means( , ) ; // k \u210e user prototype 5 = k-means( , + ) ; // k \u210e item prototype in Dataloader(X) do // load minibatch data 8 , = GraphConv(G, , ); = GraphConv(G, , ); 15 return ,\n\nTable 1 :\n1Statistics of the datasets Datasets #Users #Items #Interactions DensityML-1M \n6,040 \n3,629 \n836,478 \n0.03816 \nYelp \n45,478 \n30,709 \n1,777,765 \n0.00127 \nBooks \n58,145 \n58,052 \n2,517,437 \n0.00075 \nGowalla \n29,859 \n40,989 \n1,027,464 \n0.00084 \nAlibaba 300,000 \n81,614 \n1,607,813 \n0.00007 \n\nindependent instances, while we model prototypes as clusters of \nhighly related users (or items) with similar interaction behaviors. \n\n\n\nTable 2 :\n2Performance Comparison of Different Recommendation ModelsDataset \nMetric \nBPRMF NeuMF FISM NGCF MultiGCCF DGCF LightGCN \nSGL \nNCL \nImprov. \n\nMovieLens-1M \n\nRecall@10 0.1804 \n0.1657 0.1887 0.1846 \n0.1830 \n0.1881 \n0.1876 \n0.1888 0.2057  *  \n+8.95% \nNDCG@10 0.2463 \n0.2295 0.2494 0.2528 \n0.2510 \n0.2520 \n0.2514 \n0.2526 0.2732  *  \n+8.07% \nRecall@20 0.2714 \n0.2520 0.2798 0.2741 \n0.2759 \n0.2779 \n0.2796 \n0.2848 0.3037  *  \n+6.63% \nNDCG@20 0.2569 \n0.2400 0.2607 0.2614 \n0.2617 \n0.2615 \n0.2620 \n0.2649 0.2843  *  \n+7.32% \nRecall@50 0.4300 \n0.4122 0.4421 0.4341 \n0.4364 \n0.4424 \n0.4469 \n0.4487 0.4686  *  \n+4.44% \nNDCG@50 0.3014 \n0.2851 0.3078 0.3055 \n0.3056 \n0.3078 \n0.3091 \n0.3111 0.3300  *  \n+6.08% \n\nYelp \n\nRecall@10 0.0643 \n0.0531 0.0714 0.0630 \n0.0646 \n0.0723 \n0.0730 \n0.0833 0.0920  *  +10.44% \nNDCG@10 0.0458 \n0.0377 0.0510 0.0446 \n0.0450 \n0.0514 \n0.0520 \n0.0601 0.0678  *  +12.81% \nRecall@20 0.1043 \n0.0885 0.1119 0.1026 \n0.1053 \n0.1135 \n0.1163 \n0.1288 0.1377  *  \n+6.91% \nNDCG@20 0.0580 \n0.0486 0.0636 0.0567 \n0.0575 \n0.0641 \n0.0652 \n0.0739 0.0817  *  +10.55% \nRecall@50 0.1862 \n0.1654 0.1963 0.1864 \n0.1882 \n0.1989 \n0.2016 \n0.2140 0.2247  *  \n+5.00% \nNDCG@50 0.0793 \n0.0685 0.0856 0.0784 \n0.0790 \n0.0862 \n0.0875 \n0.0964 0.1046  *  \n+8.51% \n\nAmazon-Books \n\nRecall@10 0.0607 \n0.0507 0.0721 0.0617 \n0.0625 \n0.0737 \n0.0797 \n0.0898 0.0933  *  \n+3.90% \nNDCG@10 \n0.043 \n0.0351 0.0504 0.0427 \n0.0433 \n0.0521 \n0.0565 \n0.0645 0.0679  *  \n+5.27% \nRecall@20 0.0956 \n0.0823 0.1099 0.0978 \n0.0991 \n0.1128 \n0.1206 \n0.1331 0.1381  *  \n+3.76% \nNDCG@20 0.0537 \n0.0447 0.0622 0.0537 \n0.0545 \n0.064 \n0.0689 \n0.0777 0.0815  *  \n+4.89% \nRecall@50 0.1681 \n0.1447 \n0.183 0.1699 \n0.1688 \n0.1908 \n0.2012 \n0.2157 0.2175  *  \n+0.83% \nNDCG@50 0.0726 \n0.061 \n0.0815 0.0725 \n0.0727 \n0.0843 \n0.0899 \n0.0992 0.1024  *  \n+3.23% \n\nGowalla \n\nRecall@10 0.1158 \n0.1039 0.1081 0.1192 \n0.1108 \n0.1252 \n0.1362 \n0.1465 0.1500  *  \n+2.39% \nNDCG@10 0.0833 \n0.0731 0.0755 0.0852 \n0.0791 \n0.0902 \n0.0876 \n0.1048 0.1082  *  \n+3.24% \nRecall@20 0.1695 \n0.1535 0.1620 0.1755 \n0.1626 \n0.1829 \n0.1976 \n0.2084 0.2133  *  \n+2.35% \nNDCG@20 0.0988 \n0.0873 0.0913 0.1013 \n0.0940 \n0.1066 \n0.1152 \n0.1225 0.1265  *  \n+3.27% \nRecall@50 0.2756 \n0.2510 0.2673 0.2811 \n0.2631 \n0.2877 \n0.3044 \n0.3197 0.3259  *  \n+1.94% \nNDCG@50 0.1450 \n0.1110 0.1169 0.1270 \n0.1184 \n0.1322 \n0.1414 \n0.1497 0.1542  *  \n+3.01% \n\nAlibaba-iFashion \n\nRecall@10 \n0.303 \n0.182 \n0.0357 0.0382 \n0.0401 \n0.0447 \n0.0457 \n0.0461 0.0477  *  \n+3.47% \nNDCG@10 0.0161 \n0.0092 0.0190 0.0198 \n0.0207 \n0.0241 \n0.0246 \n0.0248 0.0259  *  \n+4.44% \nRecall@20 0.0467 \n0.0302 0.0553 0.0615 \n0.0634 \n0.0677 \n0.0692 \n0.0692 0.0713  *  \n+3.03% \nNDCG@20 0.0203 \n0.0123 0.0239 0.0257 \n0.0266 \n0.0299 \n0.0246 \n0.0307 0.0319  *  \n+3.01% \nRecall@50 0.0799 \n0.0576 0.0943 0.1081 \n0.1107 \n0.1120 \n0.1144 \n0.1141 0.1165  *  \n+1.84% \nNDCG@50 0.0269 \n0.0177 0.0317 0.0349 \n0.0360 \n0.0387 \n0.0396 \n0.0396 0.0409  *  \n+3.28% \n\n\n\nTable 3 :\n3Performance comparison w.r.t. different hop of structural neighbors.Hop \nMovieLens-1M \nYelp \nRecall@10 NDCG@10 Recall@10 NDCG@10 \n\nw/o s-n \n0.1876 \n0.2514 \n0.0730 \n0.0520 \n1 \n0.2057 \n0.2732 \n0.0920 \n0.0678 \n2 \n0.1838 \n0.2516 \n0.0837 \n0.0602 \n3 \n0.1839 \n0.2507 \n0.0787 \n0.0557 \n\n\n\n\n5HFDOO# \n\n1&/ \n/LJKW*&1 \n\n\n\n\n5HFDOO# \n\n1&/ \n/LJKW*&1 \n\n\n\nTable 4 :\n4Performance comparison w.r.t. different GNN backbones.Method \nMovieLens-1M \nYelp \nRecall@10 NDCG@10 Recall@10 NDCG@10 \n\nNGCF \n0.1846 \n0.2528 \n0.0630 \n0.0446 \n+NCL \n0.1852 \n0.2542 \n0.0663 \n0.0465 \n\nDGCF \n0.1853 \n0.2500 \n0.0723 \n0.0514 \n+NCL \n0.1877 \n0.2522 \n0.0739 \n0.0528 \n\nLightGCN \n0.1888 \n0.2526 \n0.0833 \n0.0601 \n+NCL \n0.2057 \n0.2732 \n0.0920 \n0.0678 \n\n\nhttps://github.com/RUCAIBox/RecBole\nACKNOWLEDGMENTS\nVideo suggestion and discovery for youtube: taking random walks through the view graph. Shumeet Baluja, Rohan Seth, Dharshi Sivakumar, Yushi Jing, Jay Yagnik, Shankar Kumar, Deepak Ravichandran, Mohamed Aly, Proceedings of the 17th international conference on World Wide Web. the 17th international conference on World Wide WebShumeet Baluja, Rohan Seth, Dharshi Sivakumar, Yushi Jing, Jay Yagnik, Shankar Kumar, Deepak Ravichandran, and Mohamed Aly. 2008. Video suggestion and dis- covery for youtube: taking random walks through the view graph. In Proceedings of the 17th international conference on World Wide Web. 895-904.\n\nA simple framework for contrastive learning of visual representations. Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, PMLRInternational conference on machine learning. Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A simple framework for contrastive learning of visual representations. In Interna- tional conference on machine learning. PMLR, 1597-1607.\n\nPOG: personalized outfit generation for fashion recommendation at Alibaba iFashion. Wen Chen, Pipei Huang, Jiaming Xu, Xin Guo, Cheng Guo, Fei Sun, Chao Li, Andreas Pfadler, Huan Zhao, Binqiang Zhao, Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining. the 25th ACM SIGKDD international conference on knowledge discovery & data miningWen Chen, Pipei Huang, Jiaming Xu, Xin Guo, Cheng Guo, Fei Sun, Chao Li, Andreas Pfadler, Huan Zhao, and Binqiang Zhao. 2019. POG: personalized outfit generation for fashion recommendation at Alibaba iFashion. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining. 2662-2670.\n\nFriendship and mobility: user movement in location-based social networks. Eunjoon Cho, A Seth, Jure Myers, Leskovec, Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. the 17th ACM SIGKDD international conference on Knowledge discovery and data miningEunjoon Cho, Seth A Myers, and Jure Leskovec. 2011. Friendship and mobility: user movement in location-based social networks. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. 1082-1090.\n\nOsvald John M Giorgi, Nitski, D Gary, Bo Bader, Wang, arXiv:2006.03659Declutr: Deep contrastive learning for unsupervised textual representations. arXiv preprintJohn M Giorgi, Osvald Nitski, Gary D Bader, and Bo Wang. 2020. Declutr: Deep contrastive learning for unsupervised textual representations. arXiv preprint arXiv:2006.03659 (2020).\n\nItemrank: A random-walk based scoring algorithm for recommender engines. Marco Gori, Augusto Pucci, I Roma, Siena, IJCAI. 7Marco Gori, Augusto Pucci, V Roma, and I Siena. 2007. Itemrank: A random-walk based scoring algorithm for recommender engines.. In IJCAI, Vol. 7. 2766-2771.\n\nMaxwell Harper, Joseph A Konstan, The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis). 5F Maxwell Harper and Joseph A Konstan. 2015. The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis) 5, 4 (2015), 1-19.\n\nContrastive multi-view representation learning on graphs. Kaveh Hassani, Amir Hosein Khasahmadi, International Conference on Machine Learning. PMLR. Kaveh Hassani and Amir Hosein Khasahmadi. 2020. Contrastive multi-view rep- resentation learning on graphs. In International Conference on Machine Learning. PMLR, 4116-4126.\n\nLightgcn: Simplifying and powering graph convolution network for recommendation. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, Meng Wang, Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval. the 43rd International ACM SIGIR conference on research and development in Information RetrievalXiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for recommendation. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval. 639-648.\n\nNeural collaborative filtering. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Proceedings of the 26th international conference on world wide web. the 26th international conference on world wide webXiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web. 173-182.\n\nBaoyu Jing, Yuejia Xiang, Xi Chen, Yu Chen, Hanghang Tong, arXiv:2109.03560Graph-MVP: Multi-View Prototypical Contrastive Learning for Multiplex Graphs. arXiv preprintBaoyu Jing, Yuejia Xiang, Xi Chen, Yu Chen, and Hanghang Tong. 2021. Graph- MVP: Multi-View Prototypical Contrastive Learning for Multiplex Graphs. arXiv preprint arXiv:2109.03560 (2021).\n\nFism: factored item similarity models for top-n recommender systems. Santosh Kabbur, Xia Ning, George Karypis, Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. the 19th ACM SIGKDD international conference on Knowledge discovery and data miningSantosh Kabbur, Xia Ning, and George Karypis. 2013. Fism: factored item simi- larity models for top-n recommender systems. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. 659- 667.\n\nMatrix factorization techniques for recommender systems. Yehuda Koren, Robert Bell, Chris Volinsky, Computer. Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech- niques for recommender systems. Computer (2009).\n\nJunnan Li, Pan Zhou, Caiming Xiong, C H Steven, Hoi, arXiv:2005.04966Prototypical contrastive learning of unsupervised representations. arXiv preprintJunnan Li, Pan Zhou, Caiming Xiong, and Steven CH Hoi. 2020. Prototypical con- trastive learning of unsupervised representations. arXiv preprint arXiv:2005.04966 (2020).\n\nVariational autoencoders for collaborative filtering. Dawen Liang, G Rahul, Krishnan, D Matthew, Tony Hoffman, Jebara, Proceedings of the 2018 world wide web conference. the 2018 world wide web conferenceDawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. 2018. Variational autoencoders for collaborative filtering. In Proceedings of the 2018 world wide web conference. 689-698.\n\nShuai Lin, Pan Zhou, Zi-Yuan Hu, Shuojia Wang, Ruihui Zhao, Yefeng Zheng, Liang Lin, arXiv:2106.09645Eric Xing, and Xiaodan Liang. 2021. Prototypical Graph Contrastive Learning. arXiv preprintShuai Lin, Pan Zhou, Zi-Yuan Hu, Shuojia Wang, Ruihui Zhao, Yefeng Zheng, Liang Lin, Eric Xing, and Xiaodan Liang. 2021. Prototypical Graph Contrastive Learning. arXiv preprint arXiv:2106.09645 (2021).\n\nGraph self-supervised learning: A survey. Yixin Liu, Shirui Pan, Ming Jin, Chuan Zhou, Feng Xia, Philip S Yu, arXiv:2103.00111arXiv preprintYixin Liu, Shirui Pan, Ming Jin, Chuan Zhou, Feng Xia, and Philip S Yu. 2021. Graph self-supervised learning: A survey. arXiv preprint arXiv:2103.00111 (2021).\n\nImage-based recommendations on styles and substitutes. Julian Mcauley, Christopher Targett, Qinfeng Shi, Anton Van Den, Hengel, Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval. the 38th international ACM SIGIR conference on research and development in information retrievalJulian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes. In Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval. 43-52.\n\nThe expectation-maximization algorithm. K Todd, Moon, IEEE Signal processing magazine. 13Todd K Moon. 1996. The expectation-maximization algorithm. IEEE Signal processing magazine 13, 6 (1996), 47-60.\n\nAaron Van Den Oord, Yazhe Li, Oriol Vinyals, arXiv:1807.03748Representation learning with contrastive predictive coding. arXiv preprintAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748 (2018).\n\nGraph representation learning via graphical mutual information maximization. Zhen Peng, Wenbing Huang, Minnan Luo, Qinghua Zheng, Yu Rong, Tingyang Xu, Junzhou Huang, Proceedings of The Web Conference 2020. The Web Conference 2020Zhen Peng, Wenbing Huang, Minnan Luo, Qinghua Zheng, Yu Rong, Tingyang Xu, and Junzhou Huang. 2020. Graph representation learning via graphical mutual information maximization. In Proceedings of The Web Conference 2020. 259-270.\n\nBPR: Bayesian personalized ranking from implicit feedback. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. the Twenty-Fifth Conference on Uncertainty in Artificial IntelligenceSteffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. 452-461.\n\nIntroduction to recommender systems handbook. Francesco Ricci, Lior Rokach, Bracha Shapira, Recommender systems handbook. Francesco Ricci, Lior Rokach, and Bracha Shapira. 2011. Introduction to recom- mender systems handbook. In Recommender systems handbook.\n\nItem-based collaborative filtering recommendation algorithms. Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl, Proceedings of the 10th international conference on World Wide Web. the 10th international conference on World Wide WebBadrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based collaborative filtering recommendation algorithms. In Proceedings of the 10th international conference on World Wide Web. 285-295.\n\nCollaborative filtering with stacked denoising autoencoders and sparse inputs. Florian Strub, Jeremie Mary, NIPS workshop on machine learning for eCommerce. Florian Strub and Jeremie Mary. 2015. Collaborative filtering with stacked de- noising autoencoders and sparse inputs. In NIPS workshop on machine learning for eCommerce.\n\nInfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization. Fan-Yun Sun, Jordan Hoffman, Vikas Verma, Jian Tang, ICLR. Fan-Yun Sun, Jordan Hoffman, Vikas Verma, and Jian Tang. 2019. InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization. In ICLR.\n\nMulti-graph convolution collaborative filtering. Jianing Sun, Yingxue Zhang, Chen Ma, Mark Coates, Huifeng Guo, 2019 IEEE International Conference on Data Mining (ICDM). IEEERuiming Tang, and Xiuqiang HeJianing Sun, Yingxue Zhang, Chen Ma, Mark Coates, Huifeng Guo, Ruiming Tang, and Xiuqiang He. 2019. Multi-graph convolution collaborative filtering. In 2019 IEEE International Conference on Data Mining (ICDM). IEEE, 1306-1311.\n\nHao Tang, Guoshuai Zhao, arXiv:2109.00217Yuxia Wu, and Xueming Qian. 2021. Multi-Sample based Contrastive Loss for Top-k Recommendation. arXiv preprintHao Tang, Guoshuai Zhao, Yuxia Wu, and Xueming Qian. 2021. Multi- Sample based Contrastive Loss for Top-k Recommendation. arXiv preprint arXiv:2109.00217 (2021).\n\nDeep Graph Infomax. Petar Veli\u010dkovi\u0107, William Fedus, L William, Pietro Hamilton, Yoshua Li\u00f2, R Devon Bengio, Hjelm, ICLR. Petar Veli\u010dkovi\u0107, William Fedus, William L Hamilton, Pietro Li\u00f2, Yoshua Bengio, and R Devon Hjelm. 2018. Deep Graph Infomax. In ICLR.\n\nUnderstanding contrastive representation learning through alignment and uniformity on the hypersphere. Tongzhou Wang, Phillip Isola, International Conference on Machine Learning. PMLR. Tongzhou Wang and Phillip Isola. 2020. Understanding contrastive representation learning through alignment and uniformity on the hypersphere. In International Conference on Machine Learning. PMLR, 9929-9939.\n\nNeural graph collaborative filtering. Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, Tat-Seng Chua, Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval. the 42nd international ACM SIGIR conference on Research and development in Information RetrievalXiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural graph collaborative filtering. In Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval. 165-174.\n\nDisentangled graph collaborative filtering. Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, Tat-Seng Chua, Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval. the 43rd international ACM SIGIR conference on research and development in information retrievalXiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua. 2020. Disentangled graph collaborative filtering. In Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval. 1001-1010.\n\nSelf-supervised graph learning for recommendation. Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, Xing Xie, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 44th International ACM SIGIR Conference on Research and Development in Information RetrievalJiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, and Xing Xie. 2021. Self-supervised graph learning for recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 726-735.\n\nLirong Wu, Haitao Lin, Zhangyang Gao, Cheng Tan, Stan Li, arXiv:2105.07342Selfsupervised on Graphs: Contrastive, Generative, or Predictive. arXiv preprintLirong Wu, Haitao Lin, Zhangyang Gao, Cheng Tan, Stan Li, et al. 2021. Self- supervised on Graphs: Contrastive, Generative, or Predictive. arXiv preprint arXiv:2105.07342 (2021).\n\nA neural influence diffusion model for social recommendation. Le Wu, Peijie Sun, Yanjie Fu, Richang Hong, Xiting Wang, Meng Wang, Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval. the 42nd international ACM SIGIR conference on research and development in information retrievalLe Wu, Peijie Sun, Yanjie Fu, Richang Hong, Xiting Wang, and Meng Wang. 2019. A neural influence diffusion model for social recommendation. In Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval. 235-244.\n\nShiwen Wu, Fei Sun, Wentao Zhang, Bin Cui, arXiv:2011.02260Graph neural networks in recommender systems: a survey. arXiv preprintShiwen Wu, Fei Sun, Wentao Zhang, and Bin Cui. 2020. Graph neural networks in recommender systems: a survey. arXiv preprint arXiv:2011.02260 (2020).\n\nSelf-supervised hypergraph convolutional networks for sessionbased recommendation. Xin Xia, Hongzhi Yin, Junliang Yu, Qinyong Wang, Lizhen Cui, Xiangliang Zhang, arXiv:2012.06852arXiv preprintXin Xia, Hongzhi Yin, Junliang Yu, Qinyong Wang, Lizhen Cui, and Xiangliang Zhang. 2020. Self-supervised hypergraph convolutional networks for session- based recommendation. arXiv preprint arXiv:2012.06852 (2020).\n\nSelfsupervised Graph-level Representation Learning with Local and Global Structure. Minghao Xu, Hang Wang, Bingbing Ni, Hongyu Guo, Jian Tang, arXiv:2106.04113arXiv preprintMinghao Xu, Hang Wang, Bingbing Ni, Hongyu Guo, and Jian Tang. 2021. Self- supervised Graph-level Representation Learning with Local and Global Structure. arXiv preprint arXiv:2106.04113 (2021).\n\nSelf-supervised learning for deep models in recommendations. Tiansheng Yao, Xinyang Yi, Derek Zhiyuan Cheng, Felix Yu, Ting Chen, Aditya Menon, Lichan Hong, H Ed, Steve Chi, Jieqi Tjoa, Kang, arXiv e-printsTiansheng Yao, Xinyang Yi, Derek Zhiyuan Cheng, Felix Yu, Ting Chen, Aditya Menon, Lichan Hong, Ed H Chi, Steve Tjoa, Jieqi Kang, et al. 2020. Self-supervised learning for deep models in recommendations. arXiv e-prints (2020).\n\nGraph convolutional neural networks for web-scale recommender systems. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, L William, Jure Hamilton, Leskovec, Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining. the 24th ACM SIGKDD international conference on knowledge discovery & data miningRex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining. 974-983.\n\nGraph contrastive learning with augmentations. Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, Yang Shen, Advances in Neural Information Processing Systems. 33Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang Shen. 2020. Graph contrastive learning with augmentations. Advances in Neural Information Processing Systems 33 (2020), 5812-5823.\n\nRevisiting Alternative Experimental Settings for Evaluating Top-N Item Recommendation Algorithms. Junhua Wayne Xin Zhao, Pengfei Chen, Qi Wang, Ji-Rong Gu, Wen, Proceedings of the 29th ACM International Conference on Information & Knowledge Management. the 29th ACM International Conference on Information & Knowledge ManagementWayne Xin Zhao, Junhua Chen, Pengfei Wang, Qi Gu, and Ji-Rong Wen. 2020. Revisiting Alternative Experimental Settings for Evaluating Top-N Item Recom- mendation Algorithms. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2329-2332.\n\nRecbole: Towards a unified, comprehensive and efficient framework for recommendation algorithms. Shanlei Wayne Xin Zhao, Yupeng Mu, Zihan Hou, Yushuo Lin, Xingyu Chen, Kaiyuan Pan, Yujie Li, Hui Lu, Changxin Wang, Tian, Proceedings of the 30th ACM International Conference on Information & Knowledge Management. the 30th ACM International Conference on Information & Knowledge ManagementWayne Xin Zhao, Shanlei Mu, Yupeng Hou, Zihan Lin, Yushuo Chen, Xingyu Pan, Kaiyuan Li, Yujie Lu, Hui Wang, Changxin Tian, et al. 2021. Recbole: Towards a unified, comprehensive and efficient framework for recommendation algorithms. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management. 4653-4664.\n\nYanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, Liang Wang, arXiv:2006.04131Deep graph contrastive representation learning. arXiv preprintYanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, and Liang Wang. 2020. Deep graph contrastive representation learning. arXiv preprint arXiv:2006.04131 (2020).\n\nGraph contrastive learning with adaptive augmentation. Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, Liang Wang, Proceedings of the Web Conference 2021. the Web Conference 2021Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, and Liang Wang. 2021. Graph contrastive learning with adaptive augmentation. In Proceedings of the Web Conference 2021. 2069-2080.\n", "annotations": {"author": "[{\"end\":187,\"start\":121},{\"end\":258,\"start\":188},{\"end\":261,\"start\":259},{\"end\":370,\"start\":262},{\"end\":373,\"start\":371},{\"end\":539,\"start\":374},{\"end\":550,\"start\":540},{\"end\":565,\"start\":551},{\"end\":577,\"start\":566},{\"end\":588,\"start\":578},{\"end\":594,\"start\":589}]", "publisher": null, "author_last_name": "[{\"end\":130,\"start\":127},{\"end\":201,\"start\":197},{\"end\":272,\"start\":269},{\"end\":388,\"start\":384},{\"end\":549,\"start\":546},{\"end\":564,\"start\":560},{\"end\":576,\"start\":573},{\"end\":587,\"start\":584}]", "author_first_name": "[{\"end\":126,\"start\":121},{\"end\":196,\"start\":188},{\"end\":260,\"start\":259},{\"end\":268,\"start\":262},{\"end\":372,\"start\":371},{\"end\":379,\"start\":374},{\"end\":383,\"start\":380},{\"end\":545,\"start\":540},{\"end\":559,\"start\":551},{\"end\":572,\"start\":566},{\"end\":583,\"start\":578},{\"end\":593,\"start\":589}]", "author_affiliation": "[{\"end\":186,\"start\":132},{\"end\":257,\"start\":203},{\"end\":369,\"start\":295},{\"end\":464,\"start\":390},{\"end\":538,\"start\":466}]", "title": "[{\"end\":88,\"start\":1},{\"end\":682,\"start\":595}]", "venue": "[{\"end\":736,\"start\":684}]", "abstract": "[{\"end\":3069,\"start\":1058}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3246,\"start\":3242},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3304,\"start\":3300},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3307,\"start\":3304},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3522,\"start\":3519},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3525,\"start\":3522},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3675,\"start\":3672},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3678,\"start\":3675},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":4064,\"start\":4060},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4388,\"start\":4384},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4391,\"start\":4388},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":4394,\"start\":4391},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":4507,\"start\":4503},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":4510,\"start\":4507},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4728,\"start\":4724},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4731,\"start\":4728},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":4734,\"start\":4731},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5373,\"start\":5370},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":5458,\"start\":5454},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7447,\"start\":7443},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9300,\"start\":9297},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9303,\"start\":9300},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9306,\"start\":9303},{\"end\":10052,\"start\":10049},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11301,\"start\":11298},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12048,\"start\":12044},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13559,\"start\":13556},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13889,\"start\":13886},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14619,\"start\":14615},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15902,\"start\":15898},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":17111,\"start\":17107},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":19847,\"start\":19843},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20049,\"start\":20045},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":20052,\"start\":20049},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20055,\"start\":20052},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20252,\"start\":20249},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20255,\"start\":20252},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":20258,\"start\":20255},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":20261,\"start\":20258},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":20264,\"start\":20261},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":20540,\"start\":20536},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20567,\"start\":20563},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":20570,\"start\":20567},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":20573,\"start\":20570},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21164,\"start\":21160},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":21186,\"start\":21182},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":21189,\"start\":21186},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":21192,\"start\":21189},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22106,\"start\":22102},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":22490,\"start\":22486},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":22607,\"start\":22603},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22724,\"start\":22721},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22824,\"start\":22820},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23140,\"start\":23137},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":23143,\"start\":23140},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":23184,\"start\":23180},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23786,\"start\":23783},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":24562,\"start\":24558},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":28900,\"start\":28897},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":28903,\"start\":28900},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":29255,\"start\":29251},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31690,\"start\":31686},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":32176,\"start\":32172},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":32179,\"start\":32176},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":32215,\"start\":32211},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":32218,\"start\":32215},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":32405,\"start\":32402},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":32407,\"start\":32405},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":32553,\"start\":32550},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":32556,\"start\":32553},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":32559,\"start\":32556},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":32562,\"start\":32559},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":32587,\"start\":32583},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":32604,\"start\":32601},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":32733,\"start\":32729},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":33093,\"start\":33089},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":33459,\"start\":33456},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":33516,\"start\":33513},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":33540,\"start\":33536},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":33543,\"start\":33540},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":33572,\"start\":33568},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":33575,\"start\":33572},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":33689,\"start\":33685},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":33692,\"start\":33689},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":33734,\"start\":33730},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":33737,\"start\":33734},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":33763,\"start\":33759},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":33907,\"start\":33904},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":34089,\"start\":34085},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":34111,\"start\":34107},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":34114,\"start\":34111},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":34117,\"start\":34114},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":34325,\"start\":34321}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":36557,\"start\":36446},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37218,\"start\":36558},{\"attributes\":{\"id\":\"fig_3\"},\"end\":37373,\"start\":37219},{\"attributes\":{\"id\":\"fig_4\"},\"end\":37502,\"start\":37374},{\"attributes\":{\"id\":\"fig_5\"},\"end\":38165,\"start\":37503},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":38599,\"start\":38166},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41523,\"start\":38600},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":41872,\"start\":41524},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42240,\"start\":41873}]", "paragraph": "[{\"end\":3736,\"start\":3085},{\"end\":4735,\"start\":3738},{\"end\":5595,\"start\":4737},{\"end\":6616,\"start\":5597},{\"end\":7741,\"start\":6618},{\"end\":7928,\"start\":7743},{\"end\":8175,\"start\":7930},{\"end\":8402,\"start\":8177},{\"end\":9241,\"start\":8418},{\"end\":9434,\"start\":9243},{\"end\":9503,\"start\":9497},{\"end\":10032,\"start\":9515},{\"end\":10188,\"start\":10042},{\"end\":10976,\"start\":10204},{\"end\":11397,\"start\":11019},{\"end\":11653,\"start\":11470},{\"end\":11870,\"start\":11697},{\"end\":11937,\"start\":11886},{\"end\":12299,\"start\":11939},{\"end\":12919,\"start\":12339},{\"end\":14726,\"start\":12970},{\"end\":15003,\"start\":14799},{\"end\":15178,\"start\":15076},{\"end\":15295,\"start\":15194},{\"end\":16756,\"start\":15344},{\"end\":16883,\"start\":16814},{\"end\":17112,\"start\":16885},{\"end\":17363,\"start\":17167},{\"end\":17550,\"start\":17418},{\"end\":17701,\"start\":17567},{\"end\":17852,\"start\":17718},{\"end\":18178,\"start\":17854},{\"end\":18401,\"start\":18215},{\"end\":18519,\"start\":18403},{\"end\":18794,\"start\":18575},{\"end\":19104,\"start\":18796},{\"end\":19169,\"start\":19106},{\"end\":19345,\"start\":19221},{\"end\":19674,\"start\":19418},{\"end\":20784,\"start\":19689},{\"end\":22337,\"start\":20786},{\"end\":22932,\"start\":22353},{\"end\":23413,\"start\":22977},{\"end\":24516,\"start\":23437},{\"end\":25061,\"start\":24518},{\"end\":25769,\"start\":25063},{\"end\":26045,\"start\":25797},{\"end\":27270,\"start\":26072},{\"end\":28152,\"start\":27306},{\"end\":28830,\"start\":28184},{\"end\":29521,\"start\":28832},{\"end\":30152,\"start\":29558},{\"end\":30858,\"start\":30162},{\"end\":31897,\"start\":30911},{\"end\":32051,\"start\":31914},{\"end\":33384,\"start\":32053},{\"end\":34602,\"start\":33386},{\"end\":35462,\"start\":34633},{\"end\":35703,\"start\":35464},{\"end\":36445,\"start\":35742}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9496,\"start\":9435},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9514,\"start\":9504},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10041,\"start\":10033},{\"attributes\":{\"id\":\"formula_3\"},\"end\":11469,\"start\":11398},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11696,\"start\":11654},{\"attributes\":{\"id\":\"formula_5\"},\"end\":11885,\"start\":11871},{\"attributes\":{\"id\":\"formula_6\"},\"end\":12338,\"start\":12300},{\"attributes\":{\"id\":\"formula_7\"},\"end\":14798,\"start\":14727},{\"attributes\":{\"id\":\"formula_8\"},\"end\":15075,\"start\":15004},{\"attributes\":{\"id\":\"formula_9\"},\"end\":15193,\"start\":15179},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16813,\"start\":16757},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17166,\"start\":17113},{\"attributes\":{\"id\":\"formula_12\"},\"end\":17417,\"start\":17364},{\"attributes\":{\"id\":\"formula_13\"},\"end\":17566,\"start\":17551},{\"attributes\":{\"id\":\"formula_14\"},\"end\":18214,\"start\":18179},{\"attributes\":{\"id\":\"formula_15\"},\"end\":18574,\"start\":18520},{\"attributes\":{\"id\":\"formula_16\"},\"end\":19220,\"start\":19170},{\"attributes\":{\"id\":\"formula_17\"},\"end\":19417,\"start\":19346}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":23269,\"start\":23262},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":27627,\"start\":27620},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":30348,\"start\":30341}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":3083,\"start\":3071},{\"attributes\":{\"n\":\"2\"},\"end\":8416,\"start\":8405},{\"attributes\":{\"n\":\"3\"},\"end\":10202,\"start\":10191},{\"attributes\":{\"n\":\"3.1\"},\"end\":11017,\"start\":10979},{\"attributes\":{\"n\":\"3.2\"},\"end\":12968,\"start\":12922},{\"attributes\":{\"n\":\"3.3\"},\"end\":15342,\"start\":15298},{\"attributes\":{\"n\":\"3.4\"},\"end\":17716,\"start\":17704},{\"attributes\":{\"n\":\"3.5\"},\"end\":19687,\"start\":19677},{\"attributes\":{\"n\":\"4\"},\"end\":22351,\"start\":22340},{\"attributes\":{\"n\":\"4.1\"},\"end\":22953,\"start\":22935},{\"attributes\":{\"n\":\"4.1.3\"},\"end\":22975,\"start\":22956},{\"attributes\":{\"n\":\"4.2\"},\"end\":23435,\"start\":23416},{\"attributes\":{\"n\":\"4.3\"},\"end\":25795,\"start\":25772},{\"attributes\":{\"n\":\"4.3.1\"},\"end\":26070,\"start\":26048},{\"attributes\":{\"n\":\"4.3.3\"},\"end\":27304,\"start\":27273},{\"attributes\":{\"n\":\"4.3.4\"},\"end\":28182,\"start\":28155},{\"attributes\":{\"n\":\"4.3.6\"},\"end\":29556,\"start\":29524},{\"end\":30160,\"start\":30155},{\"attributes\":{\"n\":\"4.3.8\"},\"end\":30909,\"start\":30861},{\"attributes\":{\"n\":\"5\"},\"end\":31912,\"start\":31900},{\"attributes\":{\"n\":\"6\"},\"end\":34631,\"start\":34605},{\"end\":35740,\"start\":35706},{\"end\":36457,\"start\":36447},{\"end\":36579,\"start\":36559},{\"end\":37230,\"start\":37220},{\"end\":37385,\"start\":37375},{\"end\":37515,\"start\":37504},{\"end\":38176,\"start\":38167},{\"end\":38610,\"start\":38601},{\"end\":41534,\"start\":41525},{\"end\":41883,\"start\":41874}]", "table": "[{\"end\":38599,\"start\":38249},{\"end\":41523,\"start\":38669},{\"end\":41872,\"start\":41604},{\"end\":42240,\"start\":41939}]", "figure_caption": "[{\"end\":36557,\"start\":36459},{\"end\":37218,\"start\":36582},{\"end\":37373,\"start\":37232},{\"end\":37502,\"start\":37387},{\"end\":38165,\"start\":37517},{\"end\":38249,\"start\":38178},{\"end\":38669,\"start\":38612},{\"end\":41604,\"start\":41536},{\"end\":41939,\"start\":41885}]", "figure_ref": "[{\"end\":5382,\"start\":5374},{\"end\":6226,\"start\":6218},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":10975,\"start\":10967},{\"end\":26299,\"start\":26291},{\"end\":26922,\"start\":26914},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":28417,\"start\":28408},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":29114,\"start\":29106},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":29743,\"start\":29735},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":29768,\"start\":29760},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":31159,\"start\":31151},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":36118,\"start\":36112}]", "bib_author_first_name": "[{\"end\":42388,\"start\":42381},{\"end\":42402,\"start\":42397},{\"end\":42416,\"start\":42409},{\"end\":42433,\"start\":42428},{\"end\":42443,\"start\":42440},{\"end\":42459,\"start\":42452},{\"end\":42473,\"start\":42467},{\"end\":42495,\"start\":42488},{\"end\":42996,\"start\":42992},{\"end\":43008,\"start\":43003},{\"end\":43028,\"start\":43020},{\"end\":43046,\"start\":43038},{\"end\":43405,\"start\":43402},{\"end\":43417,\"start\":43412},{\"end\":43432,\"start\":43425},{\"end\":43440,\"start\":43437},{\"end\":43451,\"start\":43446},{\"end\":43460,\"start\":43457},{\"end\":43470,\"start\":43466},{\"end\":43482,\"start\":43475},{\"end\":43496,\"start\":43492},{\"end\":43511,\"start\":43503},{\"end\":44101,\"start\":44094},{\"end\":44108,\"start\":44107},{\"end\":44119,\"start\":44115},{\"end\":44567,\"start\":44561},{\"end\":44592,\"start\":44591},{\"end\":44601,\"start\":44599},{\"end\":44981,\"start\":44976},{\"end\":44995,\"start\":44988},{\"end\":45004,\"start\":45003},{\"end\":45191,\"start\":45184},{\"end\":45206,\"start\":45200},{\"end\":45208,\"start\":45207},{\"end\":45556,\"start\":45551},{\"end\":45906,\"start\":45898},{\"end\":45915,\"start\":45911},{\"end\":45927,\"start\":45922},{\"end\":45937,\"start\":45934},{\"end\":45950,\"start\":45942},{\"end\":45962,\"start\":45958},{\"end\":46506,\"start\":46498},{\"end\":46515,\"start\":46511},{\"end\":46529,\"start\":46522},{\"end\":46544,\"start\":46537},{\"end\":46553,\"start\":46550},{\"end\":46566,\"start\":46558},{\"end\":46895,\"start\":46890},{\"end\":46908,\"start\":46902},{\"end\":46918,\"start\":46916},{\"end\":46927,\"start\":46925},{\"end\":46942,\"start\":46934},{\"end\":47322,\"start\":47315},{\"end\":47334,\"start\":47331},{\"end\":47347,\"start\":47341},{\"end\":47840,\"start\":47834},{\"end\":47854,\"start\":47848},{\"end\":47866,\"start\":47861},{\"end\":48023,\"start\":48017},{\"end\":48031,\"start\":48028},{\"end\":48045,\"start\":48038},{\"end\":48054,\"start\":48053},{\"end\":48056,\"start\":48055},{\"end\":48397,\"start\":48392},{\"end\":48406,\"start\":48405},{\"end\":48425,\"start\":48424},{\"end\":48439,\"start\":48435},{\"end\":48738,\"start\":48733},{\"end\":48747,\"start\":48744},{\"end\":48761,\"start\":48754},{\"end\":48773,\"start\":48766},{\"end\":48786,\"start\":48780},{\"end\":48799,\"start\":48793},{\"end\":48812,\"start\":48807},{\"end\":49175,\"start\":49170},{\"end\":49187,\"start\":49181},{\"end\":49197,\"start\":49193},{\"end\":49208,\"start\":49203},{\"end\":49219,\"start\":49215},{\"end\":49233,\"start\":49225},{\"end\":49490,\"start\":49484},{\"end\":49511,\"start\":49500},{\"end\":49528,\"start\":49521},{\"end\":49539,\"start\":49534},{\"end\":50068,\"start\":50067},{\"end\":50234,\"start\":50229},{\"end\":50254,\"start\":50249},{\"end\":50264,\"start\":50259},{\"end\":50601,\"start\":50597},{\"end\":50615,\"start\":50608},{\"end\":50629,\"start\":50623},{\"end\":50642,\"start\":50635},{\"end\":50652,\"start\":50650},{\"end\":50667,\"start\":50659},{\"end\":50679,\"start\":50672},{\"end\":51046,\"start\":51039},{\"end\":51064,\"start\":51055},{\"end\":51084,\"start\":51080},{\"end\":51098,\"start\":51094},{\"end\":51569,\"start\":51560},{\"end\":51581,\"start\":51577},{\"end\":51596,\"start\":51590},{\"end\":51842,\"start\":51836},{\"end\":51857,\"start\":51851},{\"end\":51873,\"start\":51867},{\"end\":51887,\"start\":51883},{\"end\":52312,\"start\":52305},{\"end\":52327,\"start\":52320},{\"end\":52679,\"start\":52672},{\"end\":52691,\"start\":52685},{\"end\":52706,\"start\":52701},{\"end\":52718,\"start\":52714},{\"end\":52977,\"start\":52970},{\"end\":52990,\"start\":52983},{\"end\":53002,\"start\":52998},{\"end\":53011,\"start\":53007},{\"end\":53027,\"start\":53020},{\"end\":53355,\"start\":53352},{\"end\":53370,\"start\":53362},{\"end\":53691,\"start\":53686},{\"end\":53711,\"start\":53704},{\"end\":53720,\"start\":53719},{\"end\":53736,\"start\":53730},{\"end\":53753,\"start\":53747},{\"end\":53766,\"start\":53759},{\"end\":54034,\"start\":54026},{\"end\":54048,\"start\":54041},{\"end\":54360,\"start\":54355},{\"end\":54375,\"start\":54367},{\"end\":54384,\"start\":54380},{\"end\":54395,\"start\":54391},{\"end\":54410,\"start\":54402},{\"end\":54911,\"start\":54906},{\"end\":54924,\"start\":54918},{\"end\":54932,\"start\":54930},{\"end\":54948,\"start\":54940},{\"end\":54957,\"start\":54953},{\"end\":54970,\"start\":54962},{\"end\":55497,\"start\":55490},{\"end\":55507,\"start\":55502},{\"end\":55518,\"start\":55514},{\"end\":55533,\"start\":55525},{\"end\":55543,\"start\":55538},{\"end\":55557,\"start\":55550},{\"end\":55568,\"start\":55564},{\"end\":56060,\"start\":56054},{\"end\":56071,\"start\":56065},{\"end\":56086,\"start\":56077},{\"end\":56097,\"start\":56092},{\"end\":56107,\"start\":56103},{\"end\":56452,\"start\":56450},{\"end\":56463,\"start\":56457},{\"end\":56475,\"start\":56469},{\"end\":56487,\"start\":56480},{\"end\":56500,\"start\":56494},{\"end\":56511,\"start\":56507},{\"end\":56999,\"start\":56993},{\"end\":57007,\"start\":57004},{\"end\":57019,\"start\":57013},{\"end\":57030,\"start\":57027},{\"end\":57358,\"start\":57355},{\"end\":57371,\"start\":57364},{\"end\":57385,\"start\":57377},{\"end\":57397,\"start\":57390},{\"end\":57410,\"start\":57404},{\"end\":57426,\"start\":57416},{\"end\":57770,\"start\":57763},{\"end\":57779,\"start\":57775},{\"end\":57794,\"start\":57786},{\"end\":57805,\"start\":57799},{\"end\":57815,\"start\":57811},{\"end\":58118,\"start\":58109},{\"end\":58131,\"start\":58124},{\"end\":58141,\"start\":58136},{\"end\":58149,\"start\":58142},{\"end\":58162,\"start\":58157},{\"end\":58171,\"start\":58167},{\"end\":58184,\"start\":58178},{\"end\":58198,\"start\":58192},{\"end\":58206,\"start\":58205},{\"end\":58216,\"start\":58211},{\"end\":58227,\"start\":58222},{\"end\":58556,\"start\":58553},{\"end\":58570,\"start\":58563},{\"end\":58582,\"start\":58575},{\"end\":58593,\"start\":58589},{\"end\":58609,\"start\":58608},{\"end\":58623,\"start\":58619},{\"end\":59158,\"start\":59152},{\"end\":59172,\"start\":59164},{\"end\":59186,\"start\":59179},{\"end\":59196,\"start\":59192},{\"end\":59212,\"start\":59203},{\"end\":59223,\"start\":59219},{\"end\":59595,\"start\":59589},{\"end\":59619,\"start\":59612},{\"end\":59628,\"start\":59626},{\"end\":59642,\"start\":59635},{\"end\":60203,\"start\":60196},{\"end\":60226,\"start\":60220},{\"end\":60236,\"start\":60231},{\"end\":60248,\"start\":60242},{\"end\":60260,\"start\":60254},{\"end\":60274,\"start\":60267},{\"end\":60285,\"start\":60280},{\"end\":60293,\"start\":60290},{\"end\":60306,\"start\":60298},{\"end\":60833,\"start\":60826},{\"end\":60845,\"start\":60839},{\"end\":60854,\"start\":60850},{\"end\":60864,\"start\":60859},{\"end\":60873,\"start\":60870},{\"end\":60883,\"start\":60878},{\"end\":61193,\"start\":61186},{\"end\":61205,\"start\":61199},{\"end\":61214,\"start\":61210},{\"end\":61224,\"start\":61219},{\"end\":61233,\"start\":61230},{\"end\":61243,\"start\":61238}]", "bib_author_last_name": "[{\"end\":42395,\"start\":42389},{\"end\":42407,\"start\":42403},{\"end\":42426,\"start\":42417},{\"end\":42438,\"start\":42434},{\"end\":42450,\"start\":42444},{\"end\":42465,\"start\":42460},{\"end\":42486,\"start\":42474},{\"end\":42499,\"start\":42496},{\"end\":43001,\"start\":42997},{\"end\":43018,\"start\":43009},{\"end\":43036,\"start\":43029},{\"end\":43053,\"start\":43047},{\"end\":43410,\"start\":43406},{\"end\":43423,\"start\":43418},{\"end\":43435,\"start\":43433},{\"end\":43444,\"start\":43441},{\"end\":43455,\"start\":43452},{\"end\":43464,\"start\":43461},{\"end\":43473,\"start\":43471},{\"end\":43490,\"start\":43483},{\"end\":43501,\"start\":43497},{\"end\":43516,\"start\":43512},{\"end\":44105,\"start\":44102},{\"end\":44113,\"start\":44109},{\"end\":44125,\"start\":44120},{\"end\":44135,\"start\":44127},{\"end\":44581,\"start\":44568},{\"end\":44589,\"start\":44583},{\"end\":44597,\"start\":44593},{\"end\":44607,\"start\":44602},{\"end\":44613,\"start\":44609},{\"end\":44986,\"start\":44982},{\"end\":45001,\"start\":44996},{\"end\":45009,\"start\":45005},{\"end\":45016,\"start\":45011},{\"end\":45198,\"start\":45192},{\"end\":45216,\"start\":45209},{\"end\":45564,\"start\":45557},{\"end\":45588,\"start\":45566},{\"end\":45909,\"start\":45907},{\"end\":45920,\"start\":45916},{\"end\":45932,\"start\":45928},{\"end\":45940,\"start\":45938},{\"end\":45956,\"start\":45951},{\"end\":45967,\"start\":45963},{\"end\":46509,\"start\":46507},{\"end\":46520,\"start\":46516},{\"end\":46535,\"start\":46530},{\"end\":46548,\"start\":46545},{\"end\":46556,\"start\":46554},{\"end\":46571,\"start\":46567},{\"end\":46900,\"start\":46896},{\"end\":46914,\"start\":46909},{\"end\":46923,\"start\":46919},{\"end\":46932,\"start\":46928},{\"end\":46947,\"start\":46943},{\"end\":47329,\"start\":47323},{\"end\":47339,\"start\":47335},{\"end\":47355,\"start\":47348},{\"end\":47846,\"start\":47841},{\"end\":47859,\"start\":47855},{\"end\":47875,\"start\":47867},{\"end\":48026,\"start\":48024},{\"end\":48036,\"start\":48032},{\"end\":48051,\"start\":48046},{\"end\":48063,\"start\":48057},{\"end\":48068,\"start\":48065},{\"end\":48403,\"start\":48398},{\"end\":48412,\"start\":48407},{\"end\":48422,\"start\":48414},{\"end\":48433,\"start\":48426},{\"end\":48447,\"start\":48440},{\"end\":48455,\"start\":48449},{\"end\":48742,\"start\":48739},{\"end\":48752,\"start\":48748},{\"end\":48764,\"start\":48762},{\"end\":48778,\"start\":48774},{\"end\":48791,\"start\":48787},{\"end\":48805,\"start\":48800},{\"end\":48816,\"start\":48813},{\"end\":49179,\"start\":49176},{\"end\":49191,\"start\":49188},{\"end\":49201,\"start\":49198},{\"end\":49213,\"start\":49209},{\"end\":49223,\"start\":49220},{\"end\":49236,\"start\":49234},{\"end\":49498,\"start\":49491},{\"end\":49519,\"start\":49512},{\"end\":49532,\"start\":49529},{\"end\":49547,\"start\":49540},{\"end\":49555,\"start\":49549},{\"end\":50073,\"start\":50069},{\"end\":50079,\"start\":50075},{\"end\":50247,\"start\":50235},{\"end\":50257,\"start\":50255},{\"end\":50272,\"start\":50265},{\"end\":50606,\"start\":50602},{\"end\":50621,\"start\":50616},{\"end\":50633,\"start\":50630},{\"end\":50648,\"start\":50643},{\"end\":50657,\"start\":50653},{\"end\":50670,\"start\":50668},{\"end\":50685,\"start\":50680},{\"end\":51053,\"start\":51047},{\"end\":51078,\"start\":51065},{\"end\":51092,\"start\":51085},{\"end\":51113,\"start\":51099},{\"end\":51575,\"start\":51570},{\"end\":51588,\"start\":51582},{\"end\":51604,\"start\":51597},{\"end\":51849,\"start\":51843},{\"end\":51865,\"start\":51858},{\"end\":51881,\"start\":51874},{\"end\":51893,\"start\":51888},{\"end\":52318,\"start\":52313},{\"end\":52332,\"start\":52328},{\"end\":52683,\"start\":52680},{\"end\":52699,\"start\":52692},{\"end\":52712,\"start\":52707},{\"end\":52723,\"start\":52719},{\"end\":52981,\"start\":52978},{\"end\":52996,\"start\":52991},{\"end\":53005,\"start\":53003},{\"end\":53018,\"start\":53012},{\"end\":53031,\"start\":53028},{\"end\":53360,\"start\":53356},{\"end\":53375,\"start\":53371},{\"end\":53702,\"start\":53692},{\"end\":53717,\"start\":53712},{\"end\":53728,\"start\":53721},{\"end\":53745,\"start\":53737},{\"end\":53757,\"start\":53754},{\"end\":53773,\"start\":53767},{\"end\":53780,\"start\":53775},{\"end\":54039,\"start\":54035},{\"end\":54054,\"start\":54049},{\"end\":54365,\"start\":54361},{\"end\":54378,\"start\":54376},{\"end\":54389,\"start\":54385},{\"end\":54400,\"start\":54396},{\"end\":54415,\"start\":54411},{\"end\":54916,\"start\":54912},{\"end\":54928,\"start\":54925},{\"end\":54938,\"start\":54933},{\"end\":54951,\"start\":54949},{\"end\":54960,\"start\":54958},{\"end\":54975,\"start\":54971},{\"end\":55500,\"start\":55498},{\"end\":55512,\"start\":55508},{\"end\":55523,\"start\":55519},{\"end\":55536,\"start\":55534},{\"end\":55548,\"start\":55544},{\"end\":55562,\"start\":55558},{\"end\":55572,\"start\":55569},{\"end\":56063,\"start\":56061},{\"end\":56075,\"start\":56072},{\"end\":56090,\"start\":56087},{\"end\":56101,\"start\":56098},{\"end\":56110,\"start\":56108},{\"end\":56455,\"start\":56453},{\"end\":56467,\"start\":56464},{\"end\":56478,\"start\":56476},{\"end\":56492,\"start\":56488},{\"end\":56505,\"start\":56501},{\"end\":56516,\"start\":56512},{\"end\":57002,\"start\":57000},{\"end\":57011,\"start\":57008},{\"end\":57025,\"start\":57020},{\"end\":57034,\"start\":57031},{\"end\":57362,\"start\":57359},{\"end\":57375,\"start\":57372},{\"end\":57388,\"start\":57386},{\"end\":57402,\"start\":57398},{\"end\":57414,\"start\":57411},{\"end\":57432,\"start\":57427},{\"end\":57773,\"start\":57771},{\"end\":57784,\"start\":57780},{\"end\":57797,\"start\":57795},{\"end\":57809,\"start\":57806},{\"end\":57820,\"start\":57816},{\"end\":58122,\"start\":58119},{\"end\":58134,\"start\":58132},{\"end\":58155,\"start\":58150},{\"end\":58165,\"start\":58163},{\"end\":58176,\"start\":58172},{\"end\":58190,\"start\":58185},{\"end\":58203,\"start\":58199},{\"end\":58209,\"start\":58207},{\"end\":58220,\"start\":58217},{\"end\":58232,\"start\":58228},{\"end\":58238,\"start\":58234},{\"end\":58561,\"start\":58557},{\"end\":58573,\"start\":58571},{\"end\":58587,\"start\":58583},{\"end\":58606,\"start\":58594},{\"end\":58617,\"start\":58610},{\"end\":58632,\"start\":58624},{\"end\":58642,\"start\":58634},{\"end\":59162,\"start\":59159},{\"end\":59177,\"start\":59173},{\"end\":59190,\"start\":59187},{\"end\":59201,\"start\":59197},{\"end\":59217,\"start\":59213},{\"end\":59228,\"start\":59224},{\"end\":59610,\"start\":59596},{\"end\":59624,\"start\":59620},{\"end\":59633,\"start\":59629},{\"end\":59645,\"start\":59643},{\"end\":59650,\"start\":59647},{\"end\":60218,\"start\":60204},{\"end\":60229,\"start\":60227},{\"end\":60240,\"start\":60237},{\"end\":60252,\"start\":60249},{\"end\":60265,\"start\":60261},{\"end\":60278,\"start\":60275},{\"end\":60288,\"start\":60286},{\"end\":60296,\"start\":60294},{\"end\":60311,\"start\":60307},{\"end\":60317,\"start\":60313},{\"end\":60837,\"start\":60834},{\"end\":60848,\"start\":60846},{\"end\":60857,\"start\":60855},{\"end\":60868,\"start\":60865},{\"end\":60876,\"start\":60874},{\"end\":60888,\"start\":60884},{\"end\":61197,\"start\":61194},{\"end\":61208,\"start\":61206},{\"end\":61217,\"start\":61215},{\"end\":61228,\"start\":61225},{\"end\":61236,\"start\":61234},{\"end\":61248,\"start\":61244}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":2125158},\"end\":42919,\"start\":42293},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b1\",\"matched_paper_id\":211096730},\"end\":43316,\"start\":42921},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":146120595},\"end\":44018,\"start\":43318},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":1480192},\"end\":44559,\"start\":44020},{\"attributes\":{\"doi\":\"arXiv:2006.03659\",\"id\":\"b4\"},\"end\":44901,\"start\":44561},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2625992},\"end\":45182,\"start\":44903},{\"attributes\":{\"id\":\"b6\"},\"end\":45491,\"start\":45184},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":219558740},\"end\":45815,\"start\":45493},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":211043589},\"end\":46464,\"start\":45817},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":13907106},\"end\":46888,\"start\":46466},{\"attributes\":{\"doi\":\"arXiv:2109.03560\",\"id\":\"b10\"},\"end\":47244,\"start\":46890},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":207204749},\"end\":47775,\"start\":47246},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":58370896},\"end\":48015,\"start\":47777},{\"attributes\":{\"doi\":\"arXiv:2005.04966\",\"id\":\"b13\"},\"end\":48336,\"start\":48017},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3361310},\"end\":48731,\"start\":48338},{\"attributes\":{\"doi\":\"arXiv:2106.09645\",\"id\":\"b15\"},\"end\":49126,\"start\":48733},{\"attributes\":{\"doi\":\"arXiv:2103.00111\",\"id\":\"b16\"},\"end\":49427,\"start\":49128},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":1012652},\"end\":50025,\"start\":49429},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":11846408},\"end\":50227,\"start\":50027},{\"attributes\":{\"doi\":\"arXiv:1807.03748\",\"id\":\"b19\"},\"end\":50518,\"start\":50229},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":211020745},\"end\":50978,\"start\":50520},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":10795036},\"end\":51512,\"start\":50980},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":35569873},\"end\":51772,\"start\":51514},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":8047550},\"end\":52224,\"start\":51774},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":65132009},\"end\":52553,\"start\":52226},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":199441876},\"end\":52919,\"start\":52555},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":209531818},\"end\":53350,\"start\":52921},{\"attributes\":{\"doi\":\"arXiv:2109.00217\",\"id\":\"b27\"},\"end\":53664,\"start\":53352},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":52877454},\"end\":53921,\"start\":53666},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":218718310},\"end\":54315,\"start\":53923},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":150380651},\"end\":54860,\"start\":54317},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":220347145},\"end\":55437,\"start\":54862},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":224814335},\"end\":56052,\"start\":55439},{\"attributes\":{\"doi\":\"arXiv:2105.07342\",\"id\":\"b33\"},\"end\":56386,\"start\":56054},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":128358994},\"end\":56991,\"start\":56388},{\"attributes\":{\"doi\":\"arXiv:2011.02260\",\"id\":\"b35\"},\"end\":57270,\"start\":56993},{\"attributes\":{\"doi\":\"arXiv:2012.06852\",\"id\":\"b36\"},\"end\":57677,\"start\":57272},{\"attributes\":{\"doi\":\"arXiv:2106.04113\",\"id\":\"b37\"},\"end\":58046,\"start\":57679},{\"attributes\":{\"id\":\"b38\"},\"end\":58480,\"start\":58048},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":46949657},\"end\":59103,\"start\":58482},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":225076220},\"end\":59489,\"start\":59105},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":222271955},\"end\":60097,\"start\":59491},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":226237553},\"end\":60824,\"start\":60099},{\"attributes\":{\"doi\":\"arXiv:2006.04131\",\"id\":\"b43\"},\"end\":61129,\"start\":60826},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":225094367},\"end\":61495,\"start\":61131}]", "bib_title": "[{\"end\":42379,\"start\":42293},{\"end\":42990,\"start\":42921},{\"end\":43400,\"start\":43318},{\"end\":44092,\"start\":44020},{\"end\":44974,\"start\":44903},{\"end\":45549,\"start\":45493},{\"end\":45896,\"start\":45817},{\"end\":46496,\"start\":46466},{\"end\":47313,\"start\":47246},{\"end\":47832,\"start\":47777},{\"end\":48390,\"start\":48338},{\"end\":49482,\"start\":49429},{\"end\":50065,\"start\":50027},{\"end\":50595,\"start\":50520},{\"end\":51037,\"start\":50980},{\"end\":51558,\"start\":51514},{\"end\":51834,\"start\":51774},{\"end\":52303,\"start\":52226},{\"end\":52670,\"start\":52555},{\"end\":52968,\"start\":52921},{\"end\":53684,\"start\":53666},{\"end\":54024,\"start\":53923},{\"end\":54353,\"start\":54317},{\"end\":54904,\"start\":54862},{\"end\":55488,\"start\":55439},{\"end\":56448,\"start\":56388},{\"end\":58551,\"start\":58482},{\"end\":59150,\"start\":59105},{\"end\":59587,\"start\":59491},{\"end\":60194,\"start\":60099},{\"end\":61184,\"start\":61131}]", "bib_author": "[{\"end\":42397,\"start\":42381},{\"end\":42409,\"start\":42397},{\"end\":42428,\"start\":42409},{\"end\":42440,\"start\":42428},{\"end\":42452,\"start\":42440},{\"end\":42467,\"start\":42452},{\"end\":42488,\"start\":42467},{\"end\":42501,\"start\":42488},{\"end\":43003,\"start\":42992},{\"end\":43020,\"start\":43003},{\"end\":43038,\"start\":43020},{\"end\":43055,\"start\":43038},{\"end\":43412,\"start\":43402},{\"end\":43425,\"start\":43412},{\"end\":43437,\"start\":43425},{\"end\":43446,\"start\":43437},{\"end\":43457,\"start\":43446},{\"end\":43466,\"start\":43457},{\"end\":43475,\"start\":43466},{\"end\":43492,\"start\":43475},{\"end\":43503,\"start\":43492},{\"end\":43518,\"start\":43503},{\"end\":44107,\"start\":44094},{\"end\":44115,\"start\":44107},{\"end\":44127,\"start\":44115},{\"end\":44137,\"start\":44127},{\"end\":44583,\"start\":44561},{\"end\":44591,\"start\":44583},{\"end\":44599,\"start\":44591},{\"end\":44609,\"start\":44599},{\"end\":44615,\"start\":44609},{\"end\":44988,\"start\":44976},{\"end\":45003,\"start\":44988},{\"end\":45011,\"start\":45003},{\"end\":45018,\"start\":45011},{\"end\":45200,\"start\":45184},{\"end\":45218,\"start\":45200},{\"end\":45566,\"start\":45551},{\"end\":45590,\"start\":45566},{\"end\":45911,\"start\":45898},{\"end\":45922,\"start\":45911},{\"end\":45934,\"start\":45922},{\"end\":45942,\"start\":45934},{\"end\":45958,\"start\":45942},{\"end\":45969,\"start\":45958},{\"end\":46511,\"start\":46498},{\"end\":46522,\"start\":46511},{\"end\":46537,\"start\":46522},{\"end\":46550,\"start\":46537},{\"end\":46558,\"start\":46550},{\"end\":46573,\"start\":46558},{\"end\":46902,\"start\":46890},{\"end\":46916,\"start\":46902},{\"end\":46925,\"start\":46916},{\"end\":46934,\"start\":46925},{\"end\":46949,\"start\":46934},{\"end\":47331,\"start\":47315},{\"end\":47341,\"start\":47331},{\"end\":47357,\"start\":47341},{\"end\":47848,\"start\":47834},{\"end\":47861,\"start\":47848},{\"end\":47877,\"start\":47861},{\"end\":48028,\"start\":48017},{\"end\":48038,\"start\":48028},{\"end\":48053,\"start\":48038},{\"end\":48065,\"start\":48053},{\"end\":48070,\"start\":48065},{\"end\":48405,\"start\":48392},{\"end\":48414,\"start\":48405},{\"end\":48424,\"start\":48414},{\"end\":48435,\"start\":48424},{\"end\":48449,\"start\":48435},{\"end\":48457,\"start\":48449},{\"end\":48744,\"start\":48733},{\"end\":48754,\"start\":48744},{\"end\":48766,\"start\":48754},{\"end\":48780,\"start\":48766},{\"end\":48793,\"start\":48780},{\"end\":48807,\"start\":48793},{\"end\":48818,\"start\":48807},{\"end\":49181,\"start\":49170},{\"end\":49193,\"start\":49181},{\"end\":49203,\"start\":49193},{\"end\":49215,\"start\":49203},{\"end\":49225,\"start\":49215},{\"end\":49238,\"start\":49225},{\"end\":49500,\"start\":49484},{\"end\":49521,\"start\":49500},{\"end\":49534,\"start\":49521},{\"end\":49549,\"start\":49534},{\"end\":49557,\"start\":49549},{\"end\":50075,\"start\":50067},{\"end\":50081,\"start\":50075},{\"end\":50249,\"start\":50229},{\"end\":50259,\"start\":50249},{\"end\":50274,\"start\":50259},{\"end\":50608,\"start\":50597},{\"end\":50623,\"start\":50608},{\"end\":50635,\"start\":50623},{\"end\":50650,\"start\":50635},{\"end\":50659,\"start\":50650},{\"end\":50672,\"start\":50659},{\"end\":50687,\"start\":50672},{\"end\":51055,\"start\":51039},{\"end\":51080,\"start\":51055},{\"end\":51094,\"start\":51080},{\"end\":51115,\"start\":51094},{\"end\":51577,\"start\":51560},{\"end\":51590,\"start\":51577},{\"end\":51606,\"start\":51590},{\"end\":51851,\"start\":51836},{\"end\":51867,\"start\":51851},{\"end\":51883,\"start\":51867},{\"end\":51895,\"start\":51883},{\"end\":52320,\"start\":52305},{\"end\":52334,\"start\":52320},{\"end\":52685,\"start\":52672},{\"end\":52701,\"start\":52685},{\"end\":52714,\"start\":52701},{\"end\":52725,\"start\":52714},{\"end\":52983,\"start\":52970},{\"end\":52998,\"start\":52983},{\"end\":53007,\"start\":52998},{\"end\":53020,\"start\":53007},{\"end\":53033,\"start\":53020},{\"end\":53362,\"start\":53352},{\"end\":53377,\"start\":53362},{\"end\":53704,\"start\":53686},{\"end\":53719,\"start\":53704},{\"end\":53730,\"start\":53719},{\"end\":53747,\"start\":53730},{\"end\":53759,\"start\":53747},{\"end\":53775,\"start\":53759},{\"end\":53782,\"start\":53775},{\"end\":54041,\"start\":54026},{\"end\":54056,\"start\":54041},{\"end\":54367,\"start\":54355},{\"end\":54380,\"start\":54367},{\"end\":54391,\"start\":54380},{\"end\":54402,\"start\":54391},{\"end\":54417,\"start\":54402},{\"end\":54918,\"start\":54906},{\"end\":54930,\"start\":54918},{\"end\":54940,\"start\":54930},{\"end\":54953,\"start\":54940},{\"end\":54962,\"start\":54953},{\"end\":54977,\"start\":54962},{\"end\":55502,\"start\":55490},{\"end\":55514,\"start\":55502},{\"end\":55525,\"start\":55514},{\"end\":55538,\"start\":55525},{\"end\":55550,\"start\":55538},{\"end\":55564,\"start\":55550},{\"end\":55574,\"start\":55564},{\"end\":56065,\"start\":56054},{\"end\":56077,\"start\":56065},{\"end\":56092,\"start\":56077},{\"end\":56103,\"start\":56092},{\"end\":56112,\"start\":56103},{\"end\":56457,\"start\":56450},{\"end\":56469,\"start\":56457},{\"end\":56480,\"start\":56469},{\"end\":56494,\"start\":56480},{\"end\":56507,\"start\":56494},{\"end\":56518,\"start\":56507},{\"end\":57004,\"start\":56993},{\"end\":57013,\"start\":57004},{\"end\":57027,\"start\":57013},{\"end\":57036,\"start\":57027},{\"end\":57364,\"start\":57355},{\"end\":57377,\"start\":57364},{\"end\":57390,\"start\":57377},{\"end\":57404,\"start\":57390},{\"end\":57416,\"start\":57404},{\"end\":57434,\"start\":57416},{\"end\":57775,\"start\":57763},{\"end\":57786,\"start\":57775},{\"end\":57799,\"start\":57786},{\"end\":57811,\"start\":57799},{\"end\":57822,\"start\":57811},{\"end\":58124,\"start\":58109},{\"end\":58136,\"start\":58124},{\"end\":58157,\"start\":58136},{\"end\":58167,\"start\":58157},{\"end\":58178,\"start\":58167},{\"end\":58192,\"start\":58178},{\"end\":58205,\"start\":58192},{\"end\":58211,\"start\":58205},{\"end\":58222,\"start\":58211},{\"end\":58234,\"start\":58222},{\"end\":58240,\"start\":58234},{\"end\":58563,\"start\":58553},{\"end\":58575,\"start\":58563},{\"end\":58589,\"start\":58575},{\"end\":58608,\"start\":58589},{\"end\":58619,\"start\":58608},{\"end\":58634,\"start\":58619},{\"end\":58644,\"start\":58634},{\"end\":59164,\"start\":59152},{\"end\":59179,\"start\":59164},{\"end\":59192,\"start\":59179},{\"end\":59203,\"start\":59192},{\"end\":59219,\"start\":59203},{\"end\":59230,\"start\":59219},{\"end\":59612,\"start\":59589},{\"end\":59626,\"start\":59612},{\"end\":59635,\"start\":59626},{\"end\":59647,\"start\":59635},{\"end\":59652,\"start\":59647},{\"end\":60220,\"start\":60196},{\"end\":60231,\"start\":60220},{\"end\":60242,\"start\":60231},{\"end\":60254,\"start\":60242},{\"end\":60267,\"start\":60254},{\"end\":60280,\"start\":60267},{\"end\":60290,\"start\":60280},{\"end\":60298,\"start\":60290},{\"end\":60313,\"start\":60298},{\"end\":60319,\"start\":60313},{\"end\":60839,\"start\":60826},{\"end\":60850,\"start\":60839},{\"end\":60859,\"start\":60850},{\"end\":60870,\"start\":60859},{\"end\":60878,\"start\":60870},{\"end\":60890,\"start\":60878},{\"end\":61199,\"start\":61186},{\"end\":61210,\"start\":61199},{\"end\":61219,\"start\":61210},{\"end\":61230,\"start\":61219},{\"end\":61238,\"start\":61230},{\"end\":61250,\"start\":61238}]", "bib_venue": "[{\"end\":42620,\"start\":42569},{\"end\":43697,\"start\":43616},{\"end\":44320,\"start\":44237},{\"end\":46178,\"start\":46082},{\"end\":46692,\"start\":46641},{\"end\":47540,\"start\":47457},{\"end\":48542,\"start\":48508},{\"end\":49766,\"start\":49670},{\"end\":50750,\"start\":50727},{\"end\":51270,\"start\":51201},{\"end\":52014,\"start\":51963},{\"end\":54626,\"start\":54530},{\"end\":55186,\"start\":55090},{\"end\":55783,\"start\":55687},{\"end\":56727,\"start\":56631},{\"end\":58823,\"start\":58742},{\"end\":59819,\"start\":59744},{\"end\":60486,\"start\":60411},{\"end\":61313,\"start\":61290},{\"end\":42567,\"start\":42501},{\"end\":43103,\"start\":43059},{\"end\":43614,\"start\":43518},{\"end\":44235,\"start\":44137},{\"end\":44706,\"start\":44631},{\"end\":45023,\"start\":45018},{\"end\":45321,\"start\":45218},{\"end\":45640,\"start\":45590},{\"end\":46080,\"start\":45969},{\"end\":46639,\"start\":46573},{\"end\":47041,\"start\":46965},{\"end\":47455,\"start\":47357},{\"end\":47885,\"start\":47877},{\"end\":48151,\"start\":48086},{\"end\":48506,\"start\":48457},{\"end\":48909,\"start\":48834},{\"end\":49168,\"start\":49128},{\"end\":49668,\"start\":49557},{\"end\":50112,\"start\":50081},{\"end\":50348,\"start\":50290},{\"end\":50725,\"start\":50687},{\"end\":51199,\"start\":51115},{\"end\":51634,\"start\":51606},{\"end\":51961,\"start\":51895},{\"end\":52381,\"start\":52334},{\"end\":52729,\"start\":52725},{\"end\":53089,\"start\":53033},{\"end\":53487,\"start\":53393},{\"end\":53786,\"start\":53782},{\"end\":54106,\"start\":54056},{\"end\":54528,\"start\":54417},{\"end\":55088,\"start\":54977},{\"end\":55685,\"start\":55574},{\"end\":56192,\"start\":56128},{\"end\":56629,\"start\":56518},{\"end\":57106,\"start\":57052},{\"end\":57353,\"start\":57272},{\"end\":57761,\"start\":57679},{\"end\":58107,\"start\":58048},{\"end\":58740,\"start\":58644},{\"end\":59279,\"start\":59230},{\"end\":59742,\"start\":59652},{\"end\":60409,\"start\":60319},{\"end\":60952,\"start\":60906},{\"end\":61288,\"start\":61250}]"}}}, "year": 2023, "month": 12, "day": 17}