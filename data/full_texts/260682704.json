{"id": 260682704, "updated": "2023-10-04 21:31:09.501", "metadata": {"title": "SAAM: Stealthy Adversarial Attack on Monoculor Depth Estimation", "authors": "[{\"first\":\"Amira\",\"last\":\"Guesmi\",\"middle\":[]},{\"first\":\"Muhammad\",\"last\":\"Hanif\",\"middle\":[\"Abdullah\"]},{\"first\":\"Bassem\",\"last\":\"Ouni\",\"middle\":[]},{\"first\":\"Muhammad\",\"last\":\"Shafique\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "In this paper, we investigate the vulnerability of MDE to adversarial patches. We propose a novel \\underline{S}tealthy \\underline{A}dversarial \\underline{A}ttacks on \\underline{M}DE (SAAM) that compromises MDE by either corrupting the estimated distance or causing an object to seamlessly blend into its surroundings. Our experiments, demonstrate that the designed stealthy patch successfully causes a DNN-based MDE to misestimate the depth of objects. In fact, our proposed adversarial patch achieves a significant 60\\% depth error with 99\\% ratio of the affected region. Importantly, despite its adversarial nature, the patch maintains a naturalistic appearance, making it inconspicuous to human observers. We believe that this work sheds light on the threat of adversarial attacks in the context of MDE on edge devices. We hope it raises awareness within the community about the potential real-life harm of such attacks and encourages further research into developing more robust and adaptive defense mechanisms.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2308.03108", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2308-03108", "doi": "10.48550/arxiv.2308.03108"}}, "content": {"source": {"pdf_hash": "a260d4bf2433dbb9032a4f650b0c7b80a45cccc9", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2308.03108v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "ee133173129fcb1c079683c13069ecb28547f911", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a260d4bf2433dbb9032a4f650b0c7b80a45cccc9.txt", "contents": "\nDate of publication xxxx 00, 0000, date of current version xxxx 00, 0000. SAAM: Stealthy Adversarial Attack on Monoculor Depth Estimation\n\n\nAmira Guesmi \nDivision of Engineering\neBrain Lab\nNew York University (NYU) Abu Dhabi\nUAE\n\nMuhammad Abdullah Hanif \nDivision of Engineering\neBrain Lab\nNew York University (NYU) Abu Dhabi\nUAE\n\nBassem Ouni \nAI and Digital Science Research Center\nTechnology Innovation Institute (TII)\nAbu DhabiUAE\n\nANDMuhammad Shafique \nDivision of Engineering\neBrain Lab\nNew York University (NYU) Abu Dhabi\nUAE\n\nAmira Guesmi \nDate of publication xxxx 00, 0000, date of current version xxxx 00, 0000. SAAM: Stealthy Adversarial Attack on Monoculor Depth Estimation\n10.1109/ACCESS.2017.DOICorresponding author:INDEX TERMS Adversarial AttacksAdversarial PatchCNNCollision AvoidanceLocalizationMachine LearningMonoculor Depth EstimationNavigation TasksObstacle AvoidanceRoboticsStealthySecurityVisual SLAM\nMonocular depth estimation (MDE) is an important task in scene understanding, and significant improvements in its performance have been witnessed with the utilization of convolutional neural networks (CNNs). These models can now be deployed on edge devices, thanks to advancements in CNN optimization, enabling effective depth estimation in safety-critical and security-sensitive systems like robots, rovers, drones, and autonomous cars. However, CNNs used for MDE are susceptible to adversarial attacks, which can be exploited for malicious purposes by generating plausible images containing carefully crafted perturbations that distort the model's output. To assess the vulnerability of CNN-based depth prediction methods, recent studies have attempted to design adversarial patches specifically targeting MDE. However, these methods have not been powerful enough to fully deceive the vision system in a systemically threatening manner. Their impact is less effective, misleading the depth prediction of only certain parts within the overlapping region of the input image by using conspicuous and eye-catching patterns. In this paper, we investigate the vulnerability of MDE to adversarial patches. We propose a novel Stealthy Adversarial Attacks on MDE (SAAM) that compromises MDE by either corrupting the estimated distance or causing an object to seamlessly blend into its surroundings. Our experiments, demonstrate that the designed stealthy patch successfully causes a CNN to misestimate the depth of objects. In fact, our proposed adversarial patch achieves a significant 60% depth error with 99% ratio of the affected region. Importantly, despite its adversarial nature, the patch maintains a naturalistic appearance, making it inconspicuous to human observers. We believe that this work sheds light on the threat of adversarial attacks in the context of MDE on edge devices. We hope it raises awareness within the community about the potential real-life harm of such attacks and encourages further research into developing more robust and adaptive defense mechanisms.\n\nI. INTRODUCTION\n\nM ONOCULAR depth estimation (MDE) is increasingly being utilized in a wide array of real-world applications, ranging from autonomous driving to robotics. Its main purpose is to acquire depth data, enabling a deeper and more comprehensive comprehension of the surrounding scene. MDE plays a critical and indispensable role in various tasks, including obstacle avoidance [1], object detection [2], visual SLAM [3], [4], visual re-localization [5], and numerous others.\n\nSeveral methods for estimating depth rely on sensors like RGB-D cameras, radar, lidar, or ultrasound to collect the depth information directly from a scene. These latter, however, have serious shortcomings. In fact, ultrasound devices suffer from inherently imprecise measurements, LIDAR and radar produce sparse information, and RGB-D cameras have a narrow measuring range. The aforementioned devices are extremely large and power hungry for small-sized systems, especially those that must adhere to rigorous real-world design constraints. Contrarily, RGB cameras are lightweight and less expensive. More importantly, they can offer more detailed environmental information. Several  tasks can now be accomplished totally using MDE's measurement and attain competitive performance thanks to MDE's rapid developments. These remarkable improvements can be attributed to the successful integration of deep neural networks, which have significantly enhanced MDE's capabilities.\n\nHowever, the increasing reliance on deep neural networks also brings attention to their vulnerability to adversarial attacks. As shown in various studies, these networks can be susceptible to manipulations that intentionally deceive their predictions. Hence, it becomes crucial to prioritize the security of MDE models to ensure their reliability and trustworthiness in practical applications. Safeguarding MDE systems against adversarial attacks is vital for preserving their integrity and preventing potential misinterpretations and misjudgments in real-world scenarios.\n\nPatch-based adversarial attacks [6]- [8] are a type of adversarial attack in computer vision, where carefully crafted perturbations are applied to specific patches or regions of an input image to deceive a deep learning model. The goal of patch-based adversarial attacks is to cause the model to misclassify the entire image or produce incorrect predictions for targeted regions. In contrast to traditional global adversarial attacks that perturb the entire input image, patch-based attacks are more localized, focusing on specific regions of interest.\n\nPatch-based adversarial attacks have implications in various applications, including object detection, image segmentation, and scene understanding. They demonstrate the vulnerability of deep learning models to localized adversarial perturbations and highlight the importance of developing robust defense mechanisms to protect against such attacks.\n\nOnly a limited number of studies have explored the realm of patch-based adversarial attacks on depth estimation. This particular direction of research remains relatively unexplored compared to other adversarial attack methods in computer vision. Previous work for patch-based adversarial attacks on MDE [7], [9], [10] aiming at tricking the perception module of an autonomous vehicle. Their effectiveness is limited, as they only mislead the depth prediction of specific parts within the overlapping region between the input image and the patch, usually utilizing conspicuous and eye-catching patterns. In this work, we investigate stealthy adversarial patches that can either fully conceal a particular object or trick the target methods into estimating the depth of that object incorrectly at a target depth.\n\nThis paper introduces a technique for deceiving a CNN-based monocular depth estimation system by leveraging naturalistic adversarial patches (See Figure  3). These patches are strategically designed to manipulate the system's predictions, resulting in the generation of false distance estimates. The proposed approach allows the adversarial patch to seamlessly blend into its surroundings while for example resembling a painting on a wall or a poster, and can be applied to conceal specific objects or areas of interest effectively. In fact, we set out to achieve two key goals: depth manipulation and object concealment (i.e., object-background blending). Through our proposed techniques, we can intentionally alter the perceived depth of specific objects in a scene, leading to inaccurate depth estimations. Additionally, we have developed a method to completely conceal certain objects from the depth estimation process, making them effectively invisible to the system. Moreover, our approach enables selected objects to seamlessly blend with the background, creating a visual effect where they appear to be part of the scenery, thus reducing their conspicuousness and detection. An overview of our novel contributions is shown in Figure 1. In summary, the contributions of this work are:\n\n\u2022 We present a novel patch-based adversarial attack that targets DNN-based monocular depth estimation. \u2022 Our framework generates a stealthy adversarial patch (SAAM) that can seamlessly blend into its surroundings (e.g., resembling a painting on a wall or a poster). \u2022 Our patch (SAAM) has the ability to withstand diverse transformations and adapt to different scenarios. It demonstrated robustness against a range of deformations, including rotation, perspective change, and lighting variation. Additionally, the patch can be placed at arbitrary locations within the scene, even under occlusion. \u2022 Our proposed adversarial patch extends its applicability to multiple use cases such as navigation tasks, obstacle Ratio of affected region detection, localization, etc. With a patch size as small as 0.7% of the input image, we achieve an impressive 60% depth estimation error. Moreover, the adversarial patch nearly covers the entire target region, with an almost 100% ratio of the affected region. These findings highlight the effectiveness and potency of our attack in disrupting the depth estimation process.\n\nThe structure of the remaining article is organized as follows. Section II provides a comprehensive overview of related work in the field of patch-based adversarial attacks on monocular depth estimation. In Section III, we present our proposed methodology to generate the adversarial patch. This section outlines the step-by-step process of crafting the patch and explains the techniques employed to achieve effective depth manipulation and visual realism. Section IV details the experimental setup used to evaluate the performance of the proposed adversarial attack. In Section V, we delve into the evaluation of the proposed attack. We present the results obtained from various metrics, such as depth error, affected region ratio, and SSIM, to assess the attack's potency and visual similarity of the generated patch. In Section VI, we thoroughly discuss the findings and implications of our experiments. We analyze the strengths and limitations of the proposed attack and interpret the results in the context of real-world applications. Section VII provides a succinct summary and conclusion of our study.\n\n\nII. BACKGROUND AND RELATED WORK\n\n\nA. MONOCULAR DEPTH ESTIMATION\n\nMonocular depth estimation is a prominent computer vision task that involves predicting the depth information of a scene from a single 2D image [11], [12]. It holds fundamental significance in computer vision and finds applications in a wide range of fields, including robotics, augmented reality, and autonomous vehicles. The main objective of monocular depth estimation is to infer the 3D structure of the scene solely from a single 2D image. Unlike stereo depth estimation, which relies on multiple images captured from slightly different viewpoints, monocular depth estimation's practicality lies in its ability to work with just one image, making it well-suited for various real-world scenarios.\n\n\nB. ADVERSARIAL EXAMPLES\n\nAn attacker possesses the flexibility to modify the input image of a victim model at the pixel level. These attacks inherently assume that the attacker has control over the DNN's input system, such as a camera. The first adversarial example, proposed in [13], involved adding small imperceptible noise to steer the prediction of the input image towards an incorrect class. Numerous attacks have been developed, advancing the algorithms for generating adversarial examples [14]- [18]. Although there have been efforts to enhance the power of these attacks by crafting real-time attacks [19], [20] that are generated on the fly, a more robust and realistic threat model would consider the scenario where the attacker has exclusive control over the system's external environment or external objects, rather than its internal sensors and data pipelines. In the following sections, we will explore some state-of-the-art patch-based attacks on object detectors.\n\n\nC. PATCH-BASED ADVERSARIAL ATTACKS ON MDE\n\nPatch-based attacks are a specific form of adversarial perturbation that focuses on modifying localized patches or regions within an image with the intention of deceiving machine learning models. These perturbations are carefully designed and printed on physical surfaces, such as images or objects, to exploit the vulnerabilities of computer vision systems. They aim to introduce imperceptible alterations that can lead to misclassifications or incorrect interpretations by the targeted models. This method involves substituting a section of the targeted image with an image patch to impede the performance of DNN-based models. The adversarial patch is prevalent because it is simple to use and can usually be printed out with ease.\n\nYamanaka et al. [9] was the first to propose a method for generating printable adversarial patches for corrupting MDE-based systems. However, the patches generated in their approach had eye-catching patterns, making them easily noticeable. Cheng et al. [10] focused on addressing the issue of stealthiness in the generated patch, aiming to ensure that the patch is inconspicuous and does not draw attention. However, a drawback of the generated patch is that it is object-specific, meaning that a separate patch needs to be trained for each target object. Additionally, the patch had a limited affected region and was trained for a specific setting with a fixed distance between the object and the camera, making it ineffective for other distances. Guesmi et al. [7] proposed an adaptive adversarial patch optimized to be shape and scale-aware, and its impact adapts to the target object instead of being limited to the immediate neighborhood. Although this patch was effective but didn't VOLUME 4, 2016  \nM White-box \u00d7 A Outdoor AOP [10] M White-box \u2713 O Outdoor APARATE [7] M, H White-box \u00d7 O Outdoor SAAM (ours) M, H White-box \u2713 O, A Indoor\nconsider the appearance and the stealthiness of the generated patterns. TFigure 2 illustrates the state-of-the-art patch-based adversarial attacks on Monocular Depth Estimation (MDE). Meanwhile, Table 2 provides a comprehensive comparison of these attack methods, considering various aspects: attack goal, attacker's Knowledge, attack stealthiness, the placement of the patch, and the setting specifying whether the attack is designed for indoor or outdoor scenes.\n\n\nIII. PROPOSED APPROACH A. PROBLEM FORMULATION\n\nIn the context of Monocular Depth Estimation, when presented with a benign image I, the objective of the adversarial attack is to compromise the depth estimation process by employing a maliciously designed adversarial patch P \u03b4 . This patch is strategically crafted to introduce stealthy perturbations into the original image, transforming it into an adversarial example denoted as I * . Technically, the adversarial example with generated patch can be formulated as:\nI * = (1 \u2212 M P ) \u2299 I + M P \u2299 T \u03b8 (P \u03b4 )(1)\n\u2299 is the component-wise multiplication, P \u03b4 is the adversarial patch, T \u03b8 is the ensemble of patch transformations, and M P is a mask matrix to constrain the shape, the size and pasting position of the patch, where the value of the pasting area is 1 and 0 elsewhere. The adversarial depth, i.e., the output of the victim model when taking as input the adversarial example is:\nd adv = F ((1 \u2212 M P ) \u2299 I + M P \u2299 T \u03b8 (P \u03b4 ))(2)\nThe problem of generating an adversarial example can be formulated as a constrained optimization 3, given an original\ninput image I and a DNN-based MDE model F (.): min \u03b4 \u2225\u03b4\u2225 \u221e s.t. F ((1 \u2212 M P ) \u2299 I + M P \u2299 T \u03b8 (P \u03b4 )) \u0338 = d clean(3)\nThe objective is to find a minimal adversarial noise, denoted as \u03b4 used to form the adversarial patch P \u03b4 , which, when applied at any arbitrary placement in the scene, selectively undermines the underlying MDE model F (.) by causing the objects to appear farther or closer than they really are. It is important to note that a closed-form solution cannot be obtained for this optimization problem due to the non-convex nature of the DNN-based MDE model F (.). Therefore, Equation 3 can be reformulated as follows to enable numerical approximation of the problem using empirical techniques:\narg max P I\u2208U loss(F ((1 \u2212 M P ) \u2299 I + M P \u2299 P ), d clean ) (4)\nWhere loss is a predefined loss function and U \u2282 U is the attacker's training dataset. We can use existing optimization techniques (e.g., Adam [21]) to solve this problem. In each iteration of the training the optimizer updates the adversarial patch P .\n\n\nB. ADVERSARIAL PATCH EVALUATION\n\nIn the evaluation of physical adversarial attacks, three key aspects are commonly considered: effectiveness, robustness under real-world conditions, and stealthiness to human observers.\n\n\u2022 Effectiveness: Attack effectiveness is a critical aspect to consider when assessing the impact of physical attacks. These attacks have demonstrated their effectiveness in significantly degrading the performance of the targeted task, thereby compromising FIGURE 3: Overview of our proposed attack SAAM. In the first row, the depth estimation for objects in a clean scene is accurate and correctly predicted by the MDE-based system. However, in the second row, when the objects are manipulated using our adversarial patch, the depth estimation for these objects becomes incorrect and cannot be accurately estimated by the system. the reliability and accuracy of the victim system. Adversarial manipulations in the physical space can cause misclassifications, incorrect predictions, or erroneous decisions, leading to potentially severe consequences.\n\n\u2022 Robustness: Attack robustness is a key factor in evaluating the resilience of physical attacks in dynamic environments. Maintaining attack ability despite variations in the environment is crucial for the sustained effectiveness of adversarial manipulations. One aspect of robustness is being able to maintain attack efficacy across different scenes. This means that the perturbations should remain effective and capable of deceiving the system, regardless of changes in lighting conditions, backgrounds, or other scene-specific factors. \u2022 Stealthiness: Attack stealthiness is a critical characteristic that determines the effectiveness of physical attacks. To be successful, these attacks should ideally go unnoticed by both the observer and the victim, remaining imperceptible to human eyes. The ability to maintain stealthiness ensures that the adversary can carry out their attack without raising suspicion or triggering any defensive mechanisms.\n\n\nC. OVERVIEW OF OUR METHODOLOGY\n\nIn our approach, illustrated by Figure 4, we start by introducing randomly initialized noise to a selected natural image. This noise serves as the basis for our adversarial patch generation. To enhance the robustness of the patch and mimic real-world scenarios, we apply various data augmentation techniques, such as resizing, adjusting brightness and contrast, rotation, and perspective changes. These transformations help us create diverse versions of the patch that could occur in practical situations. Next, we proceed with the patch rendering process. We utilize generated masks, representing different and random placements of the patch within the scene, to superimpose the patch on the clean image of the scene. This composite image, which now contains the adversarial patch, is then fed into the deep neural network-based monocular depth estimation (MDE) model to generate the corresponding depth map. To optimize the adversarial perturbation and ensure its effectiveness, we compute the loss function based on the discrepancy between the depth map generated with the adversarial patch and the clean depth values. Our goal is to maximize this loss function to achieve the highest impact in manipulating the depth prediction. However, it is crucial to maintain the semantic meaning of the patch and retain visual similarity to the original natural image. To address this, we enforce a semantic constraint on the adversarial perturbation. We project the noise onto the surface of an L p norm-ball with a predefined radius \u03f5. This constraint helps to preserve the meaningful appearance of the patch while keeping it within a reasonable perturbation range. By following these steps, we can generate effective adversarial patches capable of concealing objects or altering their perceived depth in the scene. Our approach ensures that the patches are practically applicable, maintain visual realism, and successfully deceive the deep neural network-based MDE model.\n\n\nD. PATCH STEALTHINESS: SEMANTIC CONSTRAINT\n\nTaking inspiration from the imperceptibility constraint commonly employed in Lp-norm based adversarial perturbations, we incorporate a projection function (Equation 6) to ensure that the generated adversarial patterns maintain visual similarity to natural images throughout the optimization process. By enforcing this constraint, we achieve high-quality semantic patterns that closely resemble a predefined natural image, for example, a painting on a wall. Empirical results demonstrate the effectiveness of optimizing with this constraint, as it facilitates the creation of visually convincing adversarial patterns that seamlessly VOLUME 4, 2016 blend into their surroundings.\nP \u03b4 = N + \u03b4(5)\nWhere N is a chosen natural images to ensure the generated camouflage patterns are semantically meaningful.\n\u03b4 t = P roj \u221e (\u03b4 (t\u22121) + \u2206\u03b4, N, \u03f5)(6)\nwhere \u03b4 t and \u2206\u03b4 denote the adversarial pattern and its updated vector at iteration t, respectively. P roj \u221e projects generated pattern onto the surface of L \u221e norm-balls with radius \u03f5 and centered at N. Here we choose N as natural images to ensure the generated camouflage patterns are semantically meaningful. For our experiments we set \u03f5 = 0.3.\n\n\nE. PATCH ROBUSTNESS 1) Data Augmentation\n\nIn order to effectively deceive CNN-based monocular depth estimation models in real-world scenarios, we incorporate the considerations of physical world conditions during the optimization process of adversarial patches. Real-world scenarios often involve various conditions, including changing lighting, different viewpoints, natural noise, and more. To simulate such dynamic factors, we apply several physical transformations. These transformations encompass various aspects, such as adding noise, random rotation, varying scales, random brightness and contrast adjustments, and more. These physical transformation operations are encapsulated within the patch transformer.\n\nThe geometric transformations performed include randomly scaling the patch [0. 25, 1.25]. Additionally, random rotations (\u00b120 \u2022 ) are applied to the patch P \u03b4 . This simulates uncertainties in patch placement, size, and distance with respect to the camera. Color space transformations are conducted by introducing random noise (\u00b10.1) to pixel intensity values, applying random contrast adjustments within the range of [0.8, 1.2], and implementing random brightness adjustments (\u00b10.1). Furthermore, we perform patch cropping and perspective change. Different performed transformations are presented in Table 3. This process leads to the formation of the resulting patch T \u03b8 (P \u03b4 ), which is then forward propagated through the monocular depth estimator. By accounting for these physical transformations and incorporating them into the optimization process, we aim to create adversarial patches that can successfully deceive CNN-based monocular depth estimation models in real-world scenarios. In typical real-world applications, the object detection model scales the adversarial sample along with the image to a square shape, which can reduce the effectiveness of the patch. To address this limitation, SAAM directly scales the adversarial patch along with the targeted images. This scaling operation introduces additional deformation to the patch, making it more challenging to optimize.\n\n\n2) Total Variation Norm (TV loss)\n\nThe characteristics of natural images include smooth and consistent patches with gradual color changes within each patch [22]. Therefore, To increase the plausibility of physical attacks, smooth and consistent perturbations are preferred. Additionally, extreme differences between adjacent pixels in the perturbation may not be accurately captured by cameras due to sampling noise. This means that non-smooth perturbations may not be physically realizable [23]. To address these issues, the total variation (TV) [22] loss is introduced to maintain the smoothness of the perturbation. For a perturbation P , TV loss is defined as: It is defined as:\nL tv = i,j (P i+1,j \u2212 P i,j ) 2 + (P i,j+1 \u2212 P i,j ) 2(7)\nwhere the subindices i and j refer to the pixel coordinate of the patch P .\n\n\nF. ADVERSARIAL PATCH GENERATION\n\nWe iteratively perform gradient updates on the adversarial patch (P \u03b4 ) in the pixel space in a way that optimizes our objective function defined as follows:\nL total = \u03b1L depth + \u03b2L tv(8)\nL depth is the adversarial depth loss.\nd adv = F ((1 \u2212 M P ) \u2299 I + M P \u2299 T \u03b8 (P \u03b4 ))(9)\nThe adversarial losses are defined as the distance between the estimated adversarial depth (Eq. 9) and the estimated clean depth or the target depth and calculated as follows:\n\nFor un-targeted attacks:\nL depth = \u2212(|d clean \u2212 d adv | \u2299 M P )(10)\nFor targeted attacks:\nL depth = d clean \u2299 (M P \u00d7 c)(11)\nWhere c is the target depth. L tv is the total variation loss on the generated image to encourage smoothness.\n\n\u03b1, and \u03b2 are hyper-parameters used to scale the losses. For our experiments we set \u03b1 = 1 and \u03b2 = 0.5. We optimize the total loss using Adam [21] optimizer. We try to minimize the object function L total and optimize the adversarial patch. We freeze all weights and biases in the depth estimator and only update the pixel values of the adversarial patch. The patch is randomly initialized.\n\n\nIV. EXPERIMENTAL SETUP\n\nIn order to assess the effectiveness of our proposed attack, we analyzed vulnerabilities of two DNN-based MDE models; The self-supervised depth prediction models are chosen based on their practicality and open source codes. Networks: DiverseDepth [24] trained on depth prediction on multiple data sources including high-quality LiDAR sensor data [25], and low-quality web stereo data [26]- [28]. The model has a backbone ResNet-50 and ResNet-101. The DiverseDepth model, is a cutting-edge deep learning architecture specifically designed for monocular depth estimation. It addresses the challenge of handling diverse real-world scenarios by introducing an affine-invariant representation of the depth map, ensuring accurate predictions regardless of camera orientation or viewpoint changes. Leveraging multi-task learning, the model combines depth estimation with tasks like normal estimation and instance segmentation, enhancing overall scene understanding and boosting depth prediction robustness. The model benefits from extensive data augmentation, simulating diverse and realistic scenarios through geometric transformations to enrich the training dataset. Trained on a large-scale dataset encompassing various scenes, camera poses, and lighting conditions, the DiverseDepth model excels in predicting depths accurately under real-world VOLUME 4, 2016 variations. Additionally, it estimates depth uncertainty, crucial for assessing the reliability of predictions in different image regions. As a result, DiverseDepth achieves state-of-the-art performance on benchmark datasets, demonstrating its significant contribution to advancing monocular depth estimation.\n\nMonodepth2 [11] is based on the general U-Net architecture, i.e. an encoder-decoder network, enabling the representation of both deep abstract features as well as local information. The ResNet18 [29] pretrained on ImageNet [30] was used as the encoder and the decoder was based on several convolution and upsampling layers with skip connections used to decode the output back to the input resolution. Monodepth2 builds upon the original Monodepth model, significantly improving depth estimation performance. Notably, Monodepth2 adopts an unsupervised learning approach, utilizing monocular video sequences for training without the need for ground truth depth annotations. The model employs a geometry-based loss to enforce consistency in predicted depth and ego-motion across consecutive frames, encouraging accurate depth estimation aligned with the scene's geometry. Its encoder-decoder architecture captures multi-scale features and employs skip connections for enhanced depth prediction. Furthermore, Monodepth2 offers the capability of estimating monocular ego-motion, making it valuable for comprehensive scene understanding and visual odometry tasks. The model's unsupervised nature and ability to predict both depth and ego-motion have made it a significant advancement in monocular depth estimation, yielding competitive results on benchmark datasets while reducing the reliance on costly ground truth annotations. Datasets: The patch was trained on indoor scenes from NYUv2 dataset [31]. The NYUv2 dataset is a widely used benchmark dataset for depth estimation and 3D scene understanding in computer vision. It was introduced by Silberman et al. in 2012 and is an extension of the original NYU Depth dataset. The NYUv2 dataset provides RGB-D data, consisting of RGB images and corresponding depth maps, captured from a variety of indoor scenes. The dataset contains images and depth maps from a diverse set of indoor scenes, captured with Microsoft Kinect cameras. The scenes include various rooms, objects, and furniture arrangements. Each RGB-D data sample in the dataset includes a high-resolution RGB image (640x480 pixels). The RGB images capture the color information of the indoor scenes. The dataset provides aligned depth maps for each RGB image, obtained from the Kinect depth sensor. The depth maps contain per-pixel depth information, allowing researchers to perform monocular depth estimation and other 3D scene understanding tasks. The NYUv2 dataset comprises a significant amount of data, with over 1449 RGB-D samples. This large-scale nature makes it suitable for training and evaluating deep learning models. The indoor scenes in the dataset cover a wide range of challenging scenarios, including occlusions, cluttered environments, and varying lighting conditions.\n\nFor the optimization, we use Adam optimizer with a learning rate l r of 0.001, \u03b21 = 0.9 and \u03b22 = 0.999.\n\n\nV. EXPERIMENTS\n\nTo validate the effectiveness of our proposed method, we conducted a thorough analysis of the vulnerabilities exhibited by an MDE model trained on indoor scene data. Our approach involved generating adversarial examples to evaluate the model's robustness to potential attacks. By crafting adversarial examples using our proposed technique, we were able to manipulate the input data in subtle yet strategic ways, aiming to deceive the MDE model during its depth estimation process. These adversarial examples were carefully designed to conceal specific objects, alter their perceived depths, or induce other misinterpretations, challenging the model's ability to accurately understand the scene. We systematically evaluated the performance of the MDE model by feeding it these adversarial examples and comparing the resulting depth estimations with the ground truth data. Through comprehensive experimentation and analysis, we gained insights into the model's vulnerabilities and potential weaknesses, highlighting the need for robustness against adversarial attacks.\n\n\nA. EVALUATION METRICS\n\nTo assess the efficacy of our proposed adversarial attack, we rely on two widely used metrics employed in previous works [7], [9]: the mean depth estimation error (E d ) and the ratio of the affected region (R a ).\n\nFor calculating E d , we consider the depth prediction of the adversarial object and compare it with the depth prediction of the benign object, using the latter as the ground truth. This metric quantifies the extent of the attack's effectiveness in altering the perceived depth of the affected region. A higher value of E d indicates a more successful attack, as it signifies a larger divergence between the predicted depth and the ground truth. The R a metric, on the other hand, measures the ratio of the affected region, i.e., the proportion of the scene where the depth estimation has been altered by the adversarial patch. A higher value of R a indicates a larger portion of the scene being affected by the attack, highlighting the patch's ability to conceal objects or modify their depth over a significant area.\n\nBy utilizing these metrics, we quantitatively evaluate the performance of our proposed adversarial attack, providing valuable insights into its effectiveness and impact on the depth estimation process. A higher mean depth estimation error and a larger affected region ratio indicate a more potent attack, reinforcing the significance of our findings and the need for robust defenses against such adversarial attacks on depth-based computer vision systems.\n\n\nThe depth estimation error (E d ) is defined as follow:\nE d = i,j (|d clean \u2212 d adv | \u2299 M P ) i,j M P(12)\nR a measures the ratio of pixels that their depth value has changed above a certain threshold with respect to the number of pixels in M P . Any change in pixel's depth value above 0.1, that pixel is considered as affected. I(x) is the indicator function that evaluates to 1 only when the condition x is true.\n\nThe ratio of affected region (R a ) is defined as follow:\nR a = i,j I((|d clean \u2212 d adv | \u2299 M P ) > 0.1) i,j M P(13)\n\nB. SAAM EFFECTIVENESS 1) In corrupting the depth of objects\n\nIn the initial experiment, we evaluated the impact of adversarial patch attacks on the performance of the victim depth estimation model. We examined how the presence of the adversarial patch affected the accuracy and reliability of the depth predictions produced by the model. By comparing the results obtained with and without the adversarial patch, we were able to assess the effectiveness and potential vulnerabilities of the victim depth estimation model under adversarial conditions. In un-targeted attacks, the objective of the attacker is to corrupt the depth estimation of objects in the scene without setting a specific target depth. In our experiments, as depicted in Figure 5, we demonstrate the effectiveness of our proposed adversarial patch in achieving this goal. By crafting a patch that covers only 1% of the input image, we were able to generate an adversarial patch capable of significantly disrupting the target regions depth estimation.\n\nThe results presented in Table 4 illustrate the effectiveness of our proposed untargeted adversarial attack. Remarkably, even with a patch size as small as 0.7% of the input image, we were able to achieve a substantial 57% depth error. The findings in Table 5 indicate that the adversarial patch's impact on the depth estimation is extensive, with an almost VOLUME 4, 2016  100% ratio of the affected region. This means that the vast majority of the overlapped region from the scene is influenced by the patch, leading to significant distortions in the depth perception. The ability to disrupt the scene depth without a specific target depth in mind highlights the far-reaching consequences of adversarial attacks and raises important concerns for applications relying on accurate depth estimation, such as autonomous vehicles, robotics, and augmented reality.\n\nIn a targeted attack setting, we use the depth loss presented in equation 11, we set c = 1 to indicate that the attacker's goal is to alter the depth of the target region to the farthest point in the scene as illustrated in Figure 6. By crafting a patch that covers 5% of the input image, we were able to generate an adversarial patch capable of significantly disrupting the overall scene depth estimation. The patch strategically alters the depth perception of multiple objects in the scene, causing distortions and misinterpretations by the depth estimation model. The same patch achieves 60% depth error with 99% affected region. These findings further emphasize the substantial disruption caused by the adversarial patch on the depth estimation process. The high depth error and near-complete coverage of the scene's affected region indicate a widespread and significant distortion of the perceived depth across multiple objects and regions within the image.\n\n\n2) In concealing objects\n\nIn this section, we assess the effectiveness of our attack in achieving the objective of concealing objects and making them blend with the background. By applying the patch strategically to specific objects within the scene, we analyze the resulting depth estimations and observe how effectively the objects remain concealed. We explore the capability of our adversarial attack to seamlessly blend targeted objects with the background. By manipulating the depth estimations, we aim to achieve a visual effect where the objects appear as natural components of the scene, effectively reducing their visibility and distinctiveness. We evaluate the blending performance through both quantitative metrics and visual assessments, comparing the modified scenes with their original counterparts to discern the extent of successful blending. As shown in Figure 7, by setting the variable c equal to the depth of the surroundings, our proposed adversarial patch successfully achieves the effect of making the target object blend seamlessly with its environment.\n\n\nC. SAAM STEALTHINESS\n\nThe Structural Similarity Index (SSIM) is a widely used metric to quantify the similarity between two images, assessing how close the generated patch is to the original benign target image. In our evaluation, as presented in Table  8, the computed SSIM value between the generated patch and the natural image is exceptionally high, with a score of 0.91 for a patch scale equal to 1%. Such a high SSIM score indicates that the adversarial patch is highly similar to the natural image, making it visually indistinguishable to human observers. \n\n\nD. SAAM VS EXISTING ATTACKS\n\nIn addition to its stealthiness, our adversarial patch also demonstrated superior performance in deceiving the monocular depth estimation model. Through careful design and optimization, the patch was able to effectively exploit the vulnerabilities of the model, leading to significantly altered and inaccurate depth predictions. Compared to other attack methods, our patch exhibited a higher success rate in fooling the depth estimation model, highlighting its effectiveness in undermining the model's performance. In fact, For a patch size of 5%, SAAM achieves a substantial 58% depth error, while the Adversarial patch method achieves a lower 40% depth error.  : SAAM vs Adversarial patch [9]: A comparison of the two methods in terms of their effectiveness and impact on model performance.\n\n\nE. SAAM VS RANDOM PATCH\n\nWhile adversarial patches are purposefully designed to exploit model vulnerabilities and achieve specific objectives, random patches are not designed with any specific objective in mind. They are typically generated by randomly selecting or generating patterns or images, without considering their impact on the model's output. Random patches lack the intentional manipulation and optimization seen in adversarial patches, and therefore do not possess the same level of effectiveness in influencing the model's decision-making process. In Figure 8, (1) \n\n\nVI. DISCUSSION\n\n\nA. IMPACT OF OCCLUSION ON PATCH EFFECTIVENESS\n\nDespite only a portion of the patch being visible in the captured image, its presence still had a significant impact on the depth prediction, leading to an inaccurate estimation. This observation highlights the vulnerability of the depth estimation model to adversarial perturbations, even when only a fraction of the perturbation is visible. The effectiveness of the patch in influencing the depth prediction can be attributed to the model's reliance on local image features and its susceptibility to small perturbations in those features. The adversarial patch, carefully designed to exploit these vulnerabilities, can disrupt the model's perception of depth by introducing misleading cues or altering the local features relevant to depth estimation.\n\n\nB. SAAM ROBUSTNESS AGAINST INPUT TRANSFORMATION-BASED DEFENSES\n\nWe thoroughly evaluate the capability of our technique to withstand diverse sets of transformations, we use three commonly used defense approaches that perform input transformations without re-training the victim models to assess the robustness of our patch against these defenses. We use JPEG compression [32], add Gaussian noise [33], Median blurring [34].\n\nThe outcomes of our experiments, as showcased in Tables  10, 11, and 12, substantiate the superiority of our proposed technique over the adversarial patch by Yamanaka et al. [9]. Our method consistently yields a higher attack success rate across the diverse transformations considered. This serves as compelling evidence of the resilience and effectiveness of our approach when facing real-world distortions, affirming its potential for practical application in adversarial attacks on the targeted system.   \n\n\nVII. CONCLUSION\n\nIn this paper, we introduce a novel patch-based adversarial attack named SAAM, specifically designed to compromise Monocular Depth Estimation (MDE)-based vision systems. SAAM is a carefully crafted patch that can completely conceal objects or manipulate their perceived depth within a scene. The experimental results confirm that the SAAM patch can successfully compromise MDE-based vision systems, highlighting the vulnerability of such systems to physical adversarial attacks. This research sheds light on the potential risks posed by adversarial attacks in real-world applications where MDE plays a crucial role, such as autonomous vehicles, robotics, and augmented reality. In fact, our patch achieves almost 60% mean depth estimation error, with almost 100% of the target region being affected. Our proposed method is designed to be applicable to the real world and practical scenarios. The generated adversarial patch is optimized to be effective in real-world settings and is designed to deceive depth estimation systems when observed through cameras or sensors. Once the patch is generated, it can be easily printed and used in the physical world without the need for any specialized equipment or complex setup. By demonstrating the susceptibility of depth estimation systems to such adversarial attacks, our research emphasizes the need for robust defense mechanisms to enhance the reliability and security of depth-based computer vision applications, including those in autonomous vehicles, surveillance, and augmented reality.\n\nFIGURE 1 :\n1Overview of our Novel Contributions.\n\nFIGURE 2 :\n2State of the art patch-based adversarial attacks on MDE.\n\nFIGURE 4 :\n4Overview of the stealthy adversarial patch (SAAM) framework used to generate patches for monocular depth estimation. This framework leverages a semantic constraint to ensure the stealthiness of the generates adversarial patch and a data augmentation technique which takes potential transformation in the real world into account during the optimization.\n\nFIGURE 5 :\n5Estimated depth for different patch locations (patch scale: 1%): the patch is designed to create an illusion of the target region appearing closer.\n\nFIGURE 6 :\n6Estimated depth for different patch locations (patch scale: 5%): the patch is designed to create an illusion of the target region appearing farther.\n\nFIGURE 7 :\n7Effectiveness of SAAM in concealing objects: Placing the patch on a target objects changes its predicted depth in a way that the object is blended with the background.\n\nFIGURE 8 :\n8The comparison of the impact of (a) Random noise and (b) SAAM on the model performance under different transformations reveals distinct effects on the depth estimation model.\n\nFIGURE 9\n9FIGURE 9: SAAM vs Adversarial patch [9]: A comparison of the two methods in terms of their effectiveness and impact on model performance.\n\nFIGURE 10 :\n10Impact of Occlusion on Patch effectiveness. a wide range of scenarios.\n\nTABLE 1 :\n1Notations used in this paper.Notation Description \nI \nClean Image \nI  *  \nAdversarial Image \nN \nNatural Image \nMp \nMask matrix to constrain the size, the shape and placement \nT \u03b8 \nEnsemble of transformations \nP \u03b4 \nThe adversarial patch \nF \nDNN-based MDE model \nd clean \nClean depth estimation \nd adv \nAdversarial depth estimation \n\u2225.\u2225 p \nLp norm \n\u03b4 \nAdversarial noise \n\u03f5 \nMaximum allowable magnitude of perturbation \nLtv \nTotal Variation loss \nL depth \nDepth loss \nL total \nTotal loss \nc \nTarget depth \n\u03b1, \u03b2 \nLoss weights, \u03b1 = 1, \u03b2 = 0.5 \n\u03b2 1 , \u03b2 2 \nOptimizer parameters, \u03b2 1 = 0.9, \u03b2 2 = 0.999 \nlr \nLearning rate, lr = 0.001 \nE d \nDepth estimation error \nRa \n\n\nTABLE 2 :\n2Comparison of attack methods. M -Manipulate estimation; H -Hiding objects. A -Anywhere in the frame; O -On the target object(s)Method \nAttack goal Attacker's Knowledge Stealthy \nPlacement \nSetting \nAdversarial patch [9] \n\n\nTABLE 3 :\n3Transformation distribution.Transformations Parameters \nRemark \nRandom Noise \n\u00b10.1 \nNoise \nRotation \n\u00b120 \u2022 \nCamera Simulation \nBrightness \n\u00b10.1 \nIllumination \nContrast \n[0.8, 1.2] \nCamera Parameters \nCropping \n-0.7 \u223c 1.0 \nPhotograph/Occlude Simulation \nAffine \n0.7 \nPerspective/Deformed Transforms \nScale \n[0.25, 1.25] \nDistance/Resize \n\n\n\nTABLE 4 :\n4Effect of un-targeted adversarial patch on victim models in terms of depth estimation error (E d ).Scale \nDiverseDepth Monodepth2 \n0.7% \n0.57 \n0.53 \n1% \n0.58 \n0.56 \n2% \n0.6 \n0.57 \n5% \n0.62 \n0.59 \n\n\n\nTABLE 5 :\n5Effect of un-targeted adversarial patch on victim \nmodels in terms of ratio of affected region (R a ). \n\nScale \nDiverseDepth Monodepth2 \n0.7% \n0.98 \n0.98 \n1% \n0.99 \n0.98 \n2% \n0.99 \n0.99 \n5% \n0.99 \n0.99 \n\n\n\nTABLE 6 :\n6Effect of targeted adversarial patch on victim models in terms of depth estimation error (E d ).Scale \nDiverseDepth Monodepth2 \n0.7% \n0.48 \n0.49 \n1% \n0.58 \n0.55 \n2% \n0.56 \n0.54 \n5% \n0.6 \n0.57 \n\n\n\nTABLE 7 :\n7Effect of targeted adversarial patch on victim models in terms of ratio of affected region (R a ).Scale \nDiverseDepth Monodepth2 \n0.7% \n0.97 \n0.97 \n1% \n0.99 \n0.98 \n2% \n0.98 \n0.98 \n5% \n0.99 \n0.99 \n\n\n\nTABLE 8 :\n8Structural Similarity Index (SSIM) between the benign target image and the generated patch for different patch scales.Scale \n1% \n5% \nSSIM 0.91 \n0.93 \n\n\n\nTABLE 9 :\n9SAAM vs Existing attacks.Metric SAAM Adversarial patch [9] \nE d \n0.58 \n0.4 \nRa \n0.99 \n0.98 \n\n\n\n\n& (2) illustrates how placing random noise in the scene doesn't have an impact on the depth prediction. However, for (3) & (4), SAAM is effective in manipulating the predicted depth even under perspective changes and rotations. Regardless of rotation, perspective changes, resizing, or other transformations applied to the scene, our patch retains its effectiveness in manipulating the model's predictions. This robustness enables the patch to maintain its adversarial impact under different real-world conditions and ensures that it can be successfully deployed inVOLUME 4, 2016 \n\n\nTABLE 10 :\n10Mean depth error when applying JPEG compression.Parameters \n90 \n70 \n50 \n30 \nE d \n0.25 \n0.23 \n0.2 \n0.17 \n\n\n\nTABLE 11 :\n11Mean depth error when applying median blur.Parameters \n5 \n10 \n15 \n20 \nE d \n0.18 \n0.16 \n0.15 0.14 \n\n\n\nTABLE 12 :\n12Mean depth error when applying Gaussian noise.Parameters 0.01 \n0.02 \n0.05 \n0.1 \nE d \n0.25 \n0.23 \n0.21 \n0.2 \n\n\nVOLUME 4, 2016 Guesmi et al.: SAAM: Stealthy Adversarial Attack on Monoculor Depth Estimation\nACKNOWLEDGMENTThis research was funded by TII for the \"CASTLE: Cross-Layer Security for Machine Learning Systems IoT\" project.\nFast depth prediction and obstacle avoidance on a monocular drone using probabilistic convolutional neural network. Xin Yang, Jingyu Chen, Yuanjie Dang, Hongcheng Luo, Yuesheng Tang, Chunyuan Liao, Peng Chen, Kwang-Ting Cheng, IEEE Transactions on Intelligent Transportation Systems. 221Xin Yang, Jingyu Chen, Yuanjie Dang, Hongcheng Luo, Yuesheng Tang, Chunyuan Liao, Peng Chen, and Kwang-Ting Cheng. Fast depth prediction and obstacle avoidance on a monocular drone using probabilistic convolutional neural network. IEEE Transactions on Intelligent Transportation Systems, 22(1):156-167, 2021.\n\nPseudo-lidar from visual depth estimation: Bridging the gap in 3d object detection for autonomous driving. Yan Wang, Wei-Lun Chao, Divyansh Garg, Bharath Hariharan, Mark Campbell, Kilian Q Weinberger, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Yan Wang, Wei-Lun Chao, Divyansh Garg, Bharath Hariharan, Mark Campbell, and Kilian Q. Weinberger. Pseudo-lidar from visual depth estimation: Bridging the gap in 3d object detection for autonomous driving. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 8437-8445, 2019.\n\nCnn-slam: Real-time dense monocular slam with learned depth prediction. Keisuke Tateno, Federico Tombari, Iro Laina, Nassir Navab, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Keisuke Tateno, Federico Tombari, Iro Laina, and Nassir Navab. Cnn-slam: Real-time dense monocular slam with learned depth prediction. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 6565-6574, 2017.\n\nMonorec: Semi-supervised dense reconstruction in dynamic environments from a single moving camera. Felix Wimbauer, Nan Yang, Niclas Lukas Von Stumberg, Daniel Zeller, Cremers, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Felix Wimbauer, Nan Yang, Lukas von Stumberg, Niclas Zeller, and Daniel Cremers. Monorec: Semi-supervised dense reconstruction in dynamic environments from a single moving camera. In 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 6108-6118, 2021.\n\nLm-reloc: Levenberg-marquardt based direct visual relocalization. Patrick Lukas Von Stumberg, Nan Wenzel, Daniel Yang, Cremers, abs/2010.06323Lukas von Stumberg, Patrick Wenzel, Nan Yang, and Daniel Cremers. Lm-reloc: Levenberg-marquardt based direct visual relocalization. CoRR, abs/2010.06323, 2020.\n\nDap: A dynamic adversarial patch for evading person detectors. Amira Guesmi, Ruitian Ding, Muhammad Abdullah Hanif, Ihsen Alouani, Muhammad Shafique, Amira Guesmi, Ruitian Ding, Muhammad Abdullah Hanif, Ihsen Alouani, and Muhammad Shafique. Dap: A dynamic adversarial patch for evading person detectors, 2023.\n\nAparate: Adaptive adversarial patch for cnn-based monocular depth estimation for autonomous navigation. Amira Guesmi, Muhammad Abdullah Hanif, Ihsen Alouani, Muhammad Shafique, Amira Guesmi, Muhammad Abdullah Hanif, Ihsen Alouani, and Muhammad Shafique. Aparate: Adaptive adversarial patch for cnn-based monocular depth estimation for autonomous navigation, 2023.\n\nAdvart: Adversarial art for camouflaged object detection attacks. Amira Guesmi, Marius Ioan, Muhammad Bilasco, Ihsen Shafique, Alouani, Amira Guesmi, Ioan Marius Bilasco, Muhammad Shafique, and Ihsen Alouani. Advart: Adversarial art for camouflaged object detection attacks, 2023.\n\nAdversarial patch attacks on monocular depth estimation networks. Koichiro Yamanaka, Ryutaroh Matsumoto, Keita Takahashi, Toshiaki Fujii, IEEE Access. 8Koichiro Yamanaka, Ryutaroh Matsumoto, Keita Takahashi, and Toshiaki Fujii. Adversarial patch attacks on monocular depth estimation networks. IEEE Access, 8:179094-179104, 2020.\n\nPhysical attack on monocular depth estimation with optimal adversarial patches. Zhiyuan Cheng, James Liang, Hongjun Choi, Guanhong Tao, Zhiwen Cao, Dongfang Liu, Xiangyu Zhang, Zhiyuan Cheng, James Liang, Hongjun Choi, Guanhong Tao, Zhiwen Cao, Dongfang Liu, and Xiangyu Zhang. Physical attack on monocular depth estimation with optimal adversarial patches, 2022.\n\nDigging into self-supervised monocular depth estimation. Cl\u00e9ment Godard, Oisin Mac Aodha, Gabriel J Brostow, abs/1806.01260CoRRCl\u00e9ment Godard, Oisin Mac Aodha, and Gabriel J. Brostow. Digging into self-supervised monocular depth estimation. CoRR, abs/1806.01260, 2018.\n\nDigging into self-supervised monocular depth estimation. Cl\u00e9ment Godard, Oisin Mac Aodha, Michael Firman, Gabriel Brostow, Cl\u00e9ment Godard, Oisin Mac Aodha, Michael Firman, and Gabriel Brostow. Digging into self-supervised monocular depth estimation, 2019.\n\nIntriguing properties of neural networks. Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J Goodfellow, Rob Fergus, 2nd International Conference on Learning Representations. Banff, AB, CanadaConference Track ProceedingsChristian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus. Intriguing properties of neural networks. In Yoshua Bengio and Yann LeCun, editors, 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings, 2014.\n\nTowards evaluating the robustness of neural networks. N Carlini, D A Wagner, abs/1608.04644CoRRN. Carlini and D. A. Wagner. Towards evaluating the robustness of neural networks. CoRR, abs/1608.04644, 2016.\n\nExplaining and harnessing adversarial examples. Ian J Goodfellow, Jonathon Shlens, Christian Szegedy, Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples, 2014.\n\nDecision-based adversarial attacks: Reliable attacks against black-box machine learning models. W Brendel, J Rauber, M Bethge, W. Brendel, J. Rauber, and M. Bethge. Decision-based adversarial attacks: Reliable attacks against black-box machine learning models, 2017.\n\nSimple black-box adversarial perturbations for deep networks. N Narodytska, S P Kasiviswanathan, abs/1612.06299CoRRN. Narodytska and S. P. Kasiviswanathan. Simple black-box adversarial perturbations for deep networks. CoRR, abs/1612.06299, 2016.\n\nBoundary attack++: Query-efficient decision-based adversarial attack. J Chen, M I Jordan, abs/1904.02144CoRRJ. Chen and M. I. Jordan. Boundary attack++: Query-efficient decision-based adversarial attack. CoRR, abs/1904.02144, 2019.\n\nUniversal adversarial perturbations. Alhussein Seyed-Mohsen Moosavi-Dezfooli, Omar Fawzi, Pascal Fawzi, Frossard, Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. Universal adversarial perturbations, 2017.\n\nRoom: Adversarial machine learning attacks under real-time constraints. Amira Guesmi, N Khaled, Nael Khasawneh, Ihsen Abu-Ghazaleh, Alouani, 2022 International Joint Conference on Neural Networks (IJCNN). Amira Guesmi, Khaled N. Khasawneh, Nael Abu-Ghazaleh, and Ihsen Alouani. Room: Adversarial machine learning attacks under real-time constraints. In 2022 International Joint Conference on Neural Networks (IJCNN), pages 1-10, 2022.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2014.\n\nUnderstanding deep image representations by inverting them. Aravindh Mahendran, Andrea Vedaldi, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionAravindh Mahendran and Andrea Vedaldi. Understanding deep image representations by inverting them. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5188-5196, 2015.\n\nAccessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, Michael K Reiter, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. Edgar R. Weippl, Stefan Katzenbeisser, Christopher Kruegel, Andrew C. Myers, and Shai Halevithe 2016 ACM SIGSAC Conference on Computer and Communications SecurityVienna, AustriaACMMahmood Sharif, Sruti Bhagavatula, Lujo Bauer, and Michael K. Reiter. Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. In Edgar R. Weippl, Stefan Katzenbeisser, Christopher Kruegel, Andrew C. Myers, and Shai Halevi, editors, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security, Vienna, Austria, October 24-28, 2016, pages 1528-1540. ACM, 2016.\n\nLearning to recover 3d scene shape from a single image. Wei Yin, Jianming Zhang, Oliver Wang, Simon Niklaus, Long Mai, Simon Chen, Chunhua Shen, Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (CVPR). IEEE Conf. Comp. Vis. Patt. Recogn. (CVPR)2021Wei Yin, Jianming Zhang, Oliver Wang, Simon Niklaus, Long Mai, Simon Chen, and Chunhua Shen. Learning to recover 3d scene shape from a single image. In Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (CVPR), 2021.\n\nTaskonomy: Disentangling task transfer learning. R Amir, Alexander Zamir, William Sax, Leonidas J Shen, Jitendra Guibas, Silvio Malik, Savarese, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Amir R. Zamir, Alexander Sax, William Shen, Leonidas J. Guibas, Jitendra Malik, and Silvio Savarese. Taskonomy: Disentangling task transfer learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018.\n\nTowards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer. Katrin Lasinger, Ren\u00e9 Ranftl, Konrad Schindler, Vladlen Koltun, abs/1907.01341CoRRKatrin Lasinger, Ren\u00e9 Ranftl, Konrad Schindler, and Vladlen Koltun. Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer. CoRR, abs/1907.01341, 2019.\n\nWeb stereo video supervision for depth prediction from dynamic scenes. CoRR, abs. Chaoyang Wang, Simon Lucey, Federico Perazzi, Oliver Wang, Chaoyang Wang, Simon Lucey, Federico Perazzi, and Oliver Wang. Web stereo video supervision for depth prediction from dynamic scenes. CoRR, abs/1904.11112, 2019.\n\nStructure-guided ranking loss for single image depth prediction. Ke Xian, Jianming Zhang, Oliver Wang, Long Mai, Zhe Lin, Zhiguo Cao, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionKe Xian, Jianming Zhang, Oliver Wang, Long Mai, Zhe Lin, and Zhiguo Cao. Structure-guided ranking loss for single image depth prediction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 611-620, 2020.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770-778, 2016.\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, 2009 IEEE Conference on Computer Vision and Pattern Recognition. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 248-255, 2009.\n\nIndoor segmentation and support inference from rgbd images. Derek Pushmeet Kohli Nathan Silberman, Rob Hoiem, Fergus, ECCV. Pushmeet Kohli Nathan Silberman, Derek Hoiem and Rob Fergus. Indoor segmentation and support inference from rgbd images. In ECCV, 2012.\n\nA study of the effect of JPG compression on adversarial images. Zoubin Gintare Karolina Dziugaite, Daniel M Ghahramani, Roy, abs/1608.00853Gintare Karolina Dziugaite, Zoubin Ghahramani, and Daniel M. Roy. A study of the effect of JPG compression on adversarial images. CoRR, abs/1608.00853, 2016.\n\nDefending against whitebox adversarial attacks via randomized discretization. Yuchen Zhang, Percy Liang, PMLRProceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics. Kamalika Chaudhuri and Masashi Sugiyamathe Twenty-Second International Conference on Artificial Intelligence and Statistics89Yuchen Zhang and Percy Liang. Defending against whitebox adversarial attacks via randomized discretization. In Kamalika Chaudhuri and Masashi Sugiyama, editors, Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics, volume 89 of Proceedings of Machine Learning Research, pages 684-693. PMLR, 16-18 Apr 2019.\n\nFeature squeezing: Detecting adversarial examples in deep neural networks. Weilin Xu, David Evans, Yanjun Qi, abs/1704.01155CoRR4Weilin Xu, David Evans, and Yanjun Qi. Feature squeezing: Detecting adversarial examples in deep neural networks. CoRR, abs/1704.01155, 2017. VOLUME 4, 2016\n", "annotations": {"author": "[{\"end\":230,\"start\":141},{\"end\":331,\"start\":231},{\"end\":435,\"start\":332},{\"end\":533,\"start\":436},{\"end\":547,\"start\":534}]", "publisher": null, "author_last_name": "[{\"end\":153,\"start\":147},{\"end\":254,\"start\":249},{\"end\":343,\"start\":339},{\"end\":456,\"start\":448},{\"end\":546,\"start\":540}]", "author_first_name": "[{\"end\":146,\"start\":141},{\"end\":239,\"start\":231},{\"end\":248,\"start\":240},{\"end\":338,\"start\":332},{\"end\":447,\"start\":439},{\"end\":539,\"start\":534}]", "author_affiliation": "[{\"end\":229,\"start\":155},{\"end\":330,\"start\":256},{\"end\":434,\"start\":345},{\"end\":532,\"start\":458}]", "title": "[{\"end\":138,\"start\":1},{\"end\":685,\"start\":548}]", "venue": null, "abstract": "[{\"end\":3001,\"start\":924}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3392,\"start\":3389},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3414,\"start\":3411},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3431,\"start\":3428},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3436,\"start\":3433},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3464,\"start\":3461},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5072,\"start\":5069},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5077,\"start\":5074},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6246,\"start\":6243},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6251,\"start\":6248},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6257,\"start\":6253},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10481,\"start\":10477},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10487,\"start\":10483},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11319,\"start\":11315},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11537,\"start\":11533},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11543,\"start\":11539},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11650,\"start\":11646},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11656,\"start\":11652},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12816,\"start\":12813},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13054,\"start\":13050},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13563,\"start\":13560},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":16426,\"start\":16422},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":20772,\"start\":20771},{\"end\":22600,\"start\":22591},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":24062,\"start\":24058},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":24397,\"start\":24393},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":24453,\"start\":24449},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":25586,\"start\":25582},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":26108,\"start\":26104},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":26207,\"start\":26203},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26245,\"start\":26241},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":26251,\"start\":26247},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":27540,\"start\":27536},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":27724,\"start\":27720},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":27752,\"start\":27748},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":29021,\"start\":29017},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":31658,\"start\":31655},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":31663,\"start\":31660},{\"end\":34954,\"start\":34940},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":38778,\"start\":38775},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":40653,\"start\":40649},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":40678,\"start\":40674},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":40700,\"start\":40696},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":40880,\"start\":40877}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":42818,\"start\":42769},{\"attributes\":{\"id\":\"fig_2\"},\"end\":42888,\"start\":42819},{\"attributes\":{\"id\":\"fig_3\"},\"end\":43254,\"start\":42889},{\"attributes\":{\"id\":\"fig_4\"},\"end\":43415,\"start\":43255},{\"attributes\":{\"id\":\"fig_5\"},\"end\":43577,\"start\":43416},{\"attributes\":{\"id\":\"fig_6\"},\"end\":43758,\"start\":43578},{\"attributes\":{\"id\":\"fig_7\"},\"end\":43946,\"start\":43759},{\"attributes\":{\"id\":\"fig_8\"},\"end\":44095,\"start\":43947},{\"attributes\":{\"id\":\"fig_9\"},\"end\":44181,\"start\":44096},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":44854,\"start\":44182},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":45088,\"start\":44855},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":45439,\"start\":45089},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":45649,\"start\":45440},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":45866,\"start\":45650},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":46073,\"start\":45867},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":46283,\"start\":46074},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":46447,\"start\":46284},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":46553,\"start\":46448},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":47137,\"start\":46554},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":47257,\"start\":47138},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":47371,\"start\":47258},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":47495,\"start\":47372}]", "paragraph": "[{\"end\":3486,\"start\":3020},{\"end\":4461,\"start\":3488},{\"end\":5035,\"start\":4463},{\"end\":5589,\"start\":5037},{\"end\":5938,\"start\":5591},{\"end\":6750,\"start\":5940},{\"end\":8043,\"start\":6752},{\"end\":9155,\"start\":8045},{\"end\":10265,\"start\":9157},{\"end\":11033,\"start\":10333},{\"end\":12016,\"start\":11061},{\"end\":12795,\"start\":12062},{\"end\":13802,\"start\":12797},{\"end\":14404,\"start\":13940},{\"end\":14921,\"start\":14454},{\"end\":15340,\"start\":14965},{\"end\":15507,\"start\":15390},{\"end\":16214,\"start\":15625},{\"end\":16532,\"start\":16279},{\"end\":16753,\"start\":16568},{\"end\":17604,\"start\":16755},{\"end\":18557,\"start\":17606},{\"end\":20559,\"start\":18592},{\"end\":21283,\"start\":20606},{\"end\":21406,\"start\":21299},{\"end\":21792,\"start\":21445},{\"end\":22510,\"start\":21837},{\"end\":23899,\"start\":22512},{\"end\":24584,\"start\":23937},{\"end\":24718,\"start\":24643},{\"end\":24911,\"start\":24754},{\"end\":24980,\"start\":24942},{\"end\":25205,\"start\":25030},{\"end\":25231,\"start\":25207},{\"end\":25296,\"start\":25275},{\"end\":25440,\"start\":25331},{\"end\":25830,\"start\":25442},{\"end\":27523,\"start\":25857},{\"end\":30318,\"start\":27525},{\"end\":30423,\"start\":30320},{\"end\":31508,\"start\":30442},{\"end\":31748,\"start\":31534},{\"end\":32568,\"start\":31750},{\"end\":33025,\"start\":32570},{\"end\":33442,\"start\":33134},{\"end\":33501,\"start\":33444},{\"end\":34580,\"start\":33623},{\"end\":35442,\"start\":34582},{\"end\":36406,\"start\":35444},{\"end\":37486,\"start\":36435},{\"end\":38052,\"start\":37511},{\"end\":38876,\"start\":38084},{\"end\":39457,\"start\":38904},{\"end\":40276,\"start\":39524},{\"end\":40701,\"start\":40343},{\"end\":41211,\"start\":40703},{\"end\":42768,\"start\":41231}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13939,\"start\":13803},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14964,\"start\":14922},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15389,\"start\":15341},{\"attributes\":{\"id\":\"formula_3\"},\"end\":15624,\"start\":15508},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16278,\"start\":16215},{\"attributes\":{\"id\":\"formula_5\"},\"end\":21298,\"start\":21284},{\"attributes\":{\"id\":\"formula_6\"},\"end\":21444,\"start\":21407},{\"attributes\":{\"id\":\"formula_7\"},\"end\":24642,\"start\":24585},{\"attributes\":{\"id\":\"formula_8\"},\"end\":24941,\"start\":24912},{\"attributes\":{\"id\":\"formula_9\"},\"end\":25029,\"start\":24981},{\"attributes\":{\"id\":\"formula_10\"},\"end\":25274,\"start\":25232},{\"attributes\":{\"id\":\"formula_11\"},\"end\":25330,\"start\":25297},{\"attributes\":{\"id\":\"formula_12\"},\"end\":33133,\"start\":33084},{\"attributes\":{\"id\":\"formula_13\"},\"end\":33560,\"start\":33502}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":14142,\"start\":14135},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23120,\"start\":23113},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":34614,\"start\":34607},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":34841,\"start\":34834},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":37744,\"start\":37736},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":40766,\"start\":40752}]", "section_header": "[{\"end\":3018,\"start\":3003},{\"end\":10299,\"start\":10268},{\"end\":10331,\"start\":10302},{\"end\":11059,\"start\":11036},{\"end\":12060,\"start\":12019},{\"end\":14452,\"start\":14407},{\"end\":16566,\"start\":16535},{\"end\":18590,\"start\":18560},{\"end\":20604,\"start\":20562},{\"end\":21835,\"start\":21795},{\"end\":23935,\"start\":23902},{\"end\":24752,\"start\":24721},{\"end\":25855,\"start\":25833},{\"end\":30440,\"start\":30426},{\"end\":31532,\"start\":31511},{\"end\":33083,\"start\":33028},{\"end\":33621,\"start\":33562},{\"end\":36433,\"start\":36409},{\"end\":37509,\"start\":37489},{\"end\":38082,\"start\":38055},{\"end\":38902,\"start\":38879},{\"end\":39474,\"start\":39460},{\"end\":39522,\"start\":39477},{\"end\":40341,\"start\":40279},{\"end\":41229,\"start\":41214},{\"end\":42780,\"start\":42770},{\"end\":42830,\"start\":42820},{\"end\":42900,\"start\":42890},{\"end\":43266,\"start\":43256},{\"end\":43427,\"start\":43417},{\"end\":43589,\"start\":43579},{\"end\":43770,\"start\":43760},{\"end\":43956,\"start\":43948},{\"end\":44108,\"start\":44097},{\"end\":44192,\"start\":44183},{\"end\":44865,\"start\":44856},{\"end\":45099,\"start\":45090},{\"end\":45450,\"start\":45441},{\"end\":45660,\"start\":45651},{\"end\":45877,\"start\":45868},{\"end\":46084,\"start\":46075},{\"end\":46294,\"start\":46285},{\"end\":46458,\"start\":46449},{\"end\":47149,\"start\":47139},{\"end\":47269,\"start\":47259},{\"end\":47383,\"start\":47373}]", "table": "[{\"end\":44854,\"start\":44223},{\"end\":45088,\"start\":44994},{\"end\":45439,\"start\":45129},{\"end\":45649,\"start\":45551},{\"end\":45866,\"start\":45662},{\"end\":46073,\"start\":45975},{\"end\":46283,\"start\":46184},{\"end\":46447,\"start\":46414},{\"end\":46553,\"start\":46485},{\"end\":47137,\"start\":47121},{\"end\":47257,\"start\":47200},{\"end\":47371,\"start\":47315},{\"end\":47495,\"start\":47432}]", "figure_caption": "[{\"end\":42818,\"start\":42782},{\"end\":42888,\"start\":42832},{\"end\":43254,\"start\":42902},{\"end\":43415,\"start\":43268},{\"end\":43577,\"start\":43429},{\"end\":43758,\"start\":43591},{\"end\":43946,\"start\":43772},{\"end\":44095,\"start\":43958},{\"end\":44181,\"start\":44111},{\"end\":44223,\"start\":44194},{\"end\":44994,\"start\":44867},{\"end\":45129,\"start\":45101},{\"end\":45551,\"start\":45452},{\"end\":45975,\"start\":45879},{\"end\":46184,\"start\":46086},{\"end\":46414,\"start\":46296},{\"end\":46485,\"start\":46460},{\"end\":47121,\"start\":46556},{\"end\":47200,\"start\":47152},{\"end\":47315,\"start\":47272},{\"end\":47432,\"start\":47386}]", "figure_ref": "[{\"end\":6907,\"start\":6898},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":7994,\"start\":7986},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18632,\"start\":18624},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":34309,\"start\":34301},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":35676,\"start\":35668},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":37288,\"start\":37280},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":39451,\"start\":39443}]", "bib_author_first_name": "[{\"end\":47836,\"start\":47833},{\"end\":47849,\"start\":47843},{\"end\":47863,\"start\":47856},{\"end\":47879,\"start\":47870},{\"end\":47893,\"start\":47885},{\"end\":47908,\"start\":47900},{\"end\":47919,\"start\":47915},{\"end\":47936,\"start\":47926},{\"end\":48424,\"start\":48421},{\"end\":48438,\"start\":48431},{\"end\":48453,\"start\":48445},{\"end\":48467,\"start\":48460},{\"end\":48483,\"start\":48479},{\"end\":48500,\"start\":48494},{\"end\":48502,\"start\":48501},{\"end\":48979,\"start\":48972},{\"end\":48996,\"start\":48988},{\"end\":49009,\"start\":49006},{\"end\":49023,\"start\":49017},{\"end\":49433,\"start\":49428},{\"end\":49447,\"start\":49444},{\"end\":49460,\"start\":49454},{\"end\":49487,\"start\":49481},{\"end\":49937,\"start\":49930},{\"end\":49961,\"start\":49958},{\"end\":49976,\"start\":49970},{\"end\":50235,\"start\":50230},{\"end\":50251,\"start\":50244},{\"end\":50266,\"start\":50258},{\"end\":50275,\"start\":50267},{\"end\":50288,\"start\":50283},{\"end\":50306,\"start\":50298},{\"end\":50587,\"start\":50582},{\"end\":50604,\"start\":50596},{\"end\":50613,\"start\":50605},{\"end\":50626,\"start\":50621},{\"end\":50644,\"start\":50636},{\"end\":50914,\"start\":50909},{\"end\":50929,\"start\":50923},{\"end\":50944,\"start\":50936},{\"end\":50959,\"start\":50954},{\"end\":51199,\"start\":51191},{\"end\":51218,\"start\":51210},{\"end\":51235,\"start\":51230},{\"end\":51255,\"start\":51247},{\"end\":51543,\"start\":51536},{\"end\":51556,\"start\":51551},{\"end\":51571,\"start\":51564},{\"end\":51586,\"start\":51578},{\"end\":51598,\"start\":51592},{\"end\":51612,\"start\":51604},{\"end\":51625,\"start\":51618},{\"end\":51885,\"start\":51878},{\"end\":51899,\"start\":51894},{\"end\":51918,\"start\":51911},{\"end\":51920,\"start\":51919},{\"end\":52155,\"start\":52148},{\"end\":52169,\"start\":52164},{\"end\":52173,\"start\":52170},{\"end\":52188,\"start\":52181},{\"end\":52204,\"start\":52197},{\"end\":52399,\"start\":52390},{\"end\":52417,\"start\":52409},{\"end\":52431,\"start\":52427},{\"end\":52447,\"start\":52443},{\"end\":52462,\"start\":52455},{\"end\":52473,\"start\":52470},{\"end\":52475,\"start\":52474},{\"end\":52491,\"start\":52488},{\"end\":53001,\"start\":53000},{\"end\":53012,\"start\":53011},{\"end\":53014,\"start\":53013},{\"end\":53204,\"start\":53201},{\"end\":53206,\"start\":53205},{\"end\":53227,\"start\":53219},{\"end\":53245,\"start\":53236},{\"end\":53466,\"start\":53465},{\"end\":53477,\"start\":53476},{\"end\":53487,\"start\":53486},{\"end\":53700,\"start\":53699},{\"end\":53714,\"start\":53713},{\"end\":53716,\"start\":53715},{\"end\":53955,\"start\":53954},{\"end\":53963,\"start\":53962},{\"end\":53965,\"start\":53964},{\"end\":54163,\"start\":54154},{\"end\":54199,\"start\":54195},{\"end\":54213,\"start\":54207},{\"end\":54433,\"start\":54428},{\"end\":54443,\"start\":54442},{\"end\":54456,\"start\":54452},{\"end\":54473,\"start\":54468},{\"end\":54837,\"start\":54836},{\"end\":54853,\"start\":54848},{\"end\":55018,\"start\":55010},{\"end\":55036,\"start\":55030},{\"end\":55487,\"start\":55480},{\"end\":55501,\"start\":55496},{\"end\":55519,\"start\":55515},{\"end\":55534,\"start\":55527},{\"end\":55536,\"start\":55535},{\"end\":56289,\"start\":56286},{\"end\":56303,\"start\":56295},{\"end\":56317,\"start\":56311},{\"end\":56329,\"start\":56324},{\"end\":56343,\"start\":56339},{\"end\":56354,\"start\":56349},{\"end\":56368,\"start\":56361},{\"end\":56730,\"start\":56729},{\"end\":56746,\"start\":56737},{\"end\":56761,\"start\":56754},{\"end\":56775,\"start\":56767},{\"end\":56777,\"start\":56776},{\"end\":56792,\"start\":56784},{\"end\":56807,\"start\":56801},{\"end\":57334,\"start\":57328},{\"end\":57349,\"start\":57345},{\"end\":57364,\"start\":57358},{\"end\":57383,\"start\":57376},{\"end\":57694,\"start\":57686},{\"end\":57706,\"start\":57701},{\"end\":57722,\"start\":57714},{\"end\":57738,\"start\":57732},{\"end\":57975,\"start\":57973},{\"end\":57990,\"start\":57982},{\"end\":58004,\"start\":57998},{\"end\":58015,\"start\":58011},{\"end\":58024,\"start\":58021},{\"end\":58036,\"start\":58030},{\"end\":58490,\"start\":58483},{\"end\":58502,\"start\":58495},{\"end\":58518,\"start\":58510},{\"end\":58528,\"start\":58524},{\"end\":58860,\"start\":58857},{\"end\":58870,\"start\":58867},{\"end\":58884,\"start\":58877},{\"end\":58899,\"start\":58893},{\"end\":58907,\"start\":58904},{\"end\":58914,\"start\":58912},{\"end\":59268,\"start\":59263},{\"end\":59305,\"start\":59302},{\"end\":59534,\"start\":59528},{\"end\":59569,\"start\":59563},{\"end\":59571,\"start\":59570},{\"end\":59846,\"start\":59840},{\"end\":59859,\"start\":59854},{\"end\":60533,\"start\":60527},{\"end\":60543,\"start\":60538},{\"end\":60557,\"start\":60551}]", "bib_author_last_name": "[{\"end\":47841,\"start\":47837},{\"end\":47854,\"start\":47850},{\"end\":47868,\"start\":47864},{\"end\":47883,\"start\":47880},{\"end\":47898,\"start\":47894},{\"end\":47913,\"start\":47909},{\"end\":47924,\"start\":47920},{\"end\":47942,\"start\":47937},{\"end\":48429,\"start\":48425},{\"end\":48443,\"start\":48439},{\"end\":48458,\"start\":48454},{\"end\":48477,\"start\":48468},{\"end\":48492,\"start\":48484},{\"end\":48513,\"start\":48503},{\"end\":48986,\"start\":48980},{\"end\":49004,\"start\":48997},{\"end\":49015,\"start\":49010},{\"end\":49029,\"start\":49024},{\"end\":49442,\"start\":49434},{\"end\":49452,\"start\":49448},{\"end\":49479,\"start\":49461},{\"end\":49494,\"start\":49488},{\"end\":49503,\"start\":49496},{\"end\":49956,\"start\":49938},{\"end\":49968,\"start\":49962},{\"end\":49981,\"start\":49977},{\"end\":49990,\"start\":49983},{\"end\":50242,\"start\":50236},{\"end\":50256,\"start\":50252},{\"end\":50281,\"start\":50276},{\"end\":50296,\"start\":50289},{\"end\":50315,\"start\":50307},{\"end\":50594,\"start\":50588},{\"end\":50619,\"start\":50614},{\"end\":50634,\"start\":50627},{\"end\":50653,\"start\":50645},{\"end\":50921,\"start\":50915},{\"end\":50934,\"start\":50930},{\"end\":50952,\"start\":50945},{\"end\":50968,\"start\":50960},{\"end\":50977,\"start\":50970},{\"end\":51208,\"start\":51200},{\"end\":51228,\"start\":51219},{\"end\":51245,\"start\":51236},{\"end\":51261,\"start\":51256},{\"end\":51549,\"start\":51544},{\"end\":51562,\"start\":51557},{\"end\":51576,\"start\":51572},{\"end\":51590,\"start\":51587},{\"end\":51602,\"start\":51599},{\"end\":51616,\"start\":51613},{\"end\":51631,\"start\":51626},{\"end\":51892,\"start\":51886},{\"end\":51909,\"start\":51900},{\"end\":51928,\"start\":51921},{\"end\":52162,\"start\":52156},{\"end\":52179,\"start\":52174},{\"end\":52195,\"start\":52189},{\"end\":52212,\"start\":52205},{\"end\":52407,\"start\":52400},{\"end\":52425,\"start\":52418},{\"end\":52441,\"start\":52432},{\"end\":52453,\"start\":52448},{\"end\":52468,\"start\":52463},{\"end\":52486,\"start\":52476},{\"end\":52498,\"start\":52492},{\"end\":53009,\"start\":53002},{\"end\":53021,\"start\":53015},{\"end\":53217,\"start\":53207},{\"end\":53234,\"start\":53228},{\"end\":53253,\"start\":53246},{\"end\":53474,\"start\":53467},{\"end\":53484,\"start\":53478},{\"end\":53494,\"start\":53488},{\"end\":53711,\"start\":53701},{\"end\":53732,\"start\":53717},{\"end\":53960,\"start\":53956},{\"end\":53972,\"start\":53966},{\"end\":54193,\"start\":54164},{\"end\":54205,\"start\":54200},{\"end\":54219,\"start\":54214},{\"end\":54229,\"start\":54221},{\"end\":54440,\"start\":54434},{\"end\":54450,\"start\":54444},{\"end\":54466,\"start\":54457},{\"end\":54486,\"start\":54474},{\"end\":54495,\"start\":54488},{\"end\":54846,\"start\":54838},{\"end\":54860,\"start\":54854},{\"end\":54864,\"start\":54862},{\"end\":55028,\"start\":55019},{\"end\":55044,\"start\":55037},{\"end\":55494,\"start\":55488},{\"end\":55513,\"start\":55502},{\"end\":55525,\"start\":55520},{\"end\":55543,\"start\":55537},{\"end\":56293,\"start\":56290},{\"end\":56309,\"start\":56304},{\"end\":56322,\"start\":56318},{\"end\":56337,\"start\":56330},{\"end\":56347,\"start\":56344},{\"end\":56359,\"start\":56355},{\"end\":56373,\"start\":56369},{\"end\":56735,\"start\":56731},{\"end\":56752,\"start\":56747},{\"end\":56765,\"start\":56762},{\"end\":56782,\"start\":56778},{\"end\":56799,\"start\":56793},{\"end\":56813,\"start\":56808},{\"end\":56823,\"start\":56815},{\"end\":57343,\"start\":57335},{\"end\":57356,\"start\":57350},{\"end\":57374,\"start\":57365},{\"end\":57390,\"start\":57384},{\"end\":57699,\"start\":57695},{\"end\":57712,\"start\":57707},{\"end\":57730,\"start\":57723},{\"end\":57743,\"start\":57739},{\"end\":57980,\"start\":57976},{\"end\":57996,\"start\":57991},{\"end\":58009,\"start\":58005},{\"end\":58019,\"start\":58016},{\"end\":58028,\"start\":58025},{\"end\":58040,\"start\":58037},{\"end\":58493,\"start\":58491},{\"end\":58508,\"start\":58503},{\"end\":58522,\"start\":58519},{\"end\":58532,\"start\":58529},{\"end\":58865,\"start\":58861},{\"end\":58875,\"start\":58871},{\"end\":58891,\"start\":58885},{\"end\":58902,\"start\":58900},{\"end\":58910,\"start\":58908},{\"end\":58922,\"start\":58915},{\"end\":59300,\"start\":59269},{\"end\":59311,\"start\":59306},{\"end\":59319,\"start\":59313},{\"end\":59561,\"start\":59535},{\"end\":59582,\"start\":59572},{\"end\":59587,\"start\":59584},{\"end\":59852,\"start\":59847},{\"end\":59865,\"start\":59860},{\"end\":60536,\"start\":60534},{\"end\":60549,\"start\":60544},{\"end\":60560,\"start\":60558}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":213840327},\"end\":48312,\"start\":47717},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":56177594},\"end\":48898,\"start\":48314},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":206596482},\"end\":49327,\"start\":48900},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":227151533},\"end\":49862,\"start\":49329},{\"attributes\":{\"doi\":\"abs/2010.06323\",\"id\":\"b4\"},\"end\":50165,\"start\":49864},{\"attributes\":{\"id\":\"b5\"},\"end\":50476,\"start\":50167},{\"attributes\":{\"id\":\"b6\"},\"end\":50841,\"start\":50478},{\"attributes\":{\"id\":\"b7\"},\"end\":51123,\"start\":50843},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":222177159},\"end\":51454,\"start\":51125},{\"attributes\":{\"id\":\"b9\"},\"end\":51819,\"start\":51456},{\"attributes\":{\"doi\":\"abs/1806.01260\",\"id\":\"b10\"},\"end\":52089,\"start\":51821},{\"attributes\":{\"id\":\"b11\"},\"end\":52346,\"start\":52091},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":604334},\"end\":52944,\"start\":52348},{\"attributes\":{\"doi\":\"abs/1608.04644\",\"id\":\"b13\"},\"end\":53151,\"start\":52946},{\"attributes\":{\"id\":\"b14\"},\"end\":53367,\"start\":53153},{\"attributes\":{\"id\":\"b15\"},\"end\":53635,\"start\":53369},{\"attributes\":{\"doi\":\"abs/1612.06299\",\"id\":\"b16\"},\"end\":53882,\"start\":53637},{\"attributes\":{\"doi\":\"abs/1904.02144\",\"id\":\"b17\"},\"end\":54115,\"start\":53884},{\"attributes\":{\"id\":\"b18\"},\"end\":54354,\"start\":54117},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":245704523},\"end\":54790,\"start\":54356},{\"attributes\":{\"id\":\"b20\"},\"end\":54948,\"start\":54792},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":206593185},\"end\":55390,\"start\":54950},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":207241700},\"end\":56228,\"start\":55392},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":229298063},\"end\":56678,\"start\":56230},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":5046249},\"end\":57229,\"start\":56680},{\"attributes\":{\"doi\":\"abs/1907.01341\",\"id\":\"b25\"},\"end\":57602,\"start\":57231},{\"attributes\":{\"id\":\"b26\"},\"end\":57906,\"start\":57604},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":219633501},\"end\":58435,\"start\":57908},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":206594692},\"end\":58802,\"start\":58437},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":57246310},\"end\":59201,\"start\":58804},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":545361},\"end\":59462,\"start\":59203},{\"attributes\":{\"doi\":\"abs/1608.00853\",\"id\":\"b31\"},\"end\":59760,\"start\":59464},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b32\",\"matched_paper_id\":85518376},\"end\":60450,\"start\":59762},{\"attributes\":{\"doi\":\"abs/1704.01155\",\"id\":\"b33\"},\"end\":60737,\"start\":60452}]", "bib_title": "[{\"end\":47831,\"start\":47717},{\"end\":48419,\"start\":48314},{\"end\":48970,\"start\":48900},{\"end\":49426,\"start\":49329},{\"end\":51189,\"start\":51125},{\"end\":52388,\"start\":52348},{\"end\":54426,\"start\":54356},{\"end\":55008,\"start\":54950},{\"end\":55478,\"start\":55392},{\"end\":56284,\"start\":56230},{\"end\":56727,\"start\":56680},{\"end\":57971,\"start\":57908},{\"end\":58481,\"start\":58437},{\"end\":58855,\"start\":58804},{\"end\":59261,\"start\":59203},{\"end\":59838,\"start\":59762}]", "bib_author": "[{\"end\":47843,\"start\":47833},{\"end\":47856,\"start\":47843},{\"end\":47870,\"start\":47856},{\"end\":47885,\"start\":47870},{\"end\":47900,\"start\":47885},{\"end\":47915,\"start\":47900},{\"end\":47926,\"start\":47915},{\"end\":47944,\"start\":47926},{\"end\":48431,\"start\":48421},{\"end\":48445,\"start\":48431},{\"end\":48460,\"start\":48445},{\"end\":48479,\"start\":48460},{\"end\":48494,\"start\":48479},{\"end\":48515,\"start\":48494},{\"end\":48988,\"start\":48972},{\"end\":49006,\"start\":48988},{\"end\":49017,\"start\":49006},{\"end\":49031,\"start\":49017},{\"end\":49444,\"start\":49428},{\"end\":49454,\"start\":49444},{\"end\":49481,\"start\":49454},{\"end\":49496,\"start\":49481},{\"end\":49505,\"start\":49496},{\"end\":49958,\"start\":49930},{\"end\":49970,\"start\":49958},{\"end\":49983,\"start\":49970},{\"end\":49992,\"start\":49983},{\"end\":50244,\"start\":50230},{\"end\":50258,\"start\":50244},{\"end\":50283,\"start\":50258},{\"end\":50298,\"start\":50283},{\"end\":50317,\"start\":50298},{\"end\":50596,\"start\":50582},{\"end\":50621,\"start\":50596},{\"end\":50636,\"start\":50621},{\"end\":50655,\"start\":50636},{\"end\":50923,\"start\":50909},{\"end\":50936,\"start\":50923},{\"end\":50954,\"start\":50936},{\"end\":50970,\"start\":50954},{\"end\":50979,\"start\":50970},{\"end\":51210,\"start\":51191},{\"end\":51230,\"start\":51210},{\"end\":51247,\"start\":51230},{\"end\":51263,\"start\":51247},{\"end\":51551,\"start\":51536},{\"end\":51564,\"start\":51551},{\"end\":51578,\"start\":51564},{\"end\":51592,\"start\":51578},{\"end\":51604,\"start\":51592},{\"end\":51618,\"start\":51604},{\"end\":51633,\"start\":51618},{\"end\":51894,\"start\":51878},{\"end\":51911,\"start\":51894},{\"end\":51930,\"start\":51911},{\"end\":52164,\"start\":52148},{\"end\":52181,\"start\":52164},{\"end\":52197,\"start\":52181},{\"end\":52214,\"start\":52197},{\"end\":52409,\"start\":52390},{\"end\":52427,\"start\":52409},{\"end\":52443,\"start\":52427},{\"end\":52455,\"start\":52443},{\"end\":52470,\"start\":52455},{\"end\":52488,\"start\":52470},{\"end\":52500,\"start\":52488},{\"end\":53011,\"start\":53000},{\"end\":53023,\"start\":53011},{\"end\":53219,\"start\":53201},{\"end\":53236,\"start\":53219},{\"end\":53255,\"start\":53236},{\"end\":53476,\"start\":53465},{\"end\":53486,\"start\":53476},{\"end\":53496,\"start\":53486},{\"end\":53713,\"start\":53699},{\"end\":53734,\"start\":53713},{\"end\":53962,\"start\":53954},{\"end\":53974,\"start\":53962},{\"end\":54195,\"start\":54154},{\"end\":54207,\"start\":54195},{\"end\":54221,\"start\":54207},{\"end\":54231,\"start\":54221},{\"end\":54442,\"start\":54428},{\"end\":54452,\"start\":54442},{\"end\":54468,\"start\":54452},{\"end\":54488,\"start\":54468},{\"end\":54497,\"start\":54488},{\"end\":54848,\"start\":54836},{\"end\":54862,\"start\":54848},{\"end\":54866,\"start\":54862},{\"end\":55030,\"start\":55010},{\"end\":55046,\"start\":55030},{\"end\":55496,\"start\":55480},{\"end\":55515,\"start\":55496},{\"end\":55527,\"start\":55515},{\"end\":55545,\"start\":55527},{\"end\":56295,\"start\":56286},{\"end\":56311,\"start\":56295},{\"end\":56324,\"start\":56311},{\"end\":56339,\"start\":56324},{\"end\":56349,\"start\":56339},{\"end\":56361,\"start\":56349},{\"end\":56375,\"start\":56361},{\"end\":56737,\"start\":56729},{\"end\":56754,\"start\":56737},{\"end\":56767,\"start\":56754},{\"end\":56784,\"start\":56767},{\"end\":56801,\"start\":56784},{\"end\":56815,\"start\":56801},{\"end\":56825,\"start\":56815},{\"end\":57345,\"start\":57328},{\"end\":57358,\"start\":57345},{\"end\":57376,\"start\":57358},{\"end\":57392,\"start\":57376},{\"end\":57701,\"start\":57686},{\"end\":57714,\"start\":57701},{\"end\":57732,\"start\":57714},{\"end\":57745,\"start\":57732},{\"end\":57982,\"start\":57973},{\"end\":57998,\"start\":57982},{\"end\":58011,\"start\":57998},{\"end\":58021,\"start\":58011},{\"end\":58030,\"start\":58021},{\"end\":58042,\"start\":58030},{\"end\":58495,\"start\":58483},{\"end\":58510,\"start\":58495},{\"end\":58524,\"start\":58510},{\"end\":58534,\"start\":58524},{\"end\":58867,\"start\":58857},{\"end\":58877,\"start\":58867},{\"end\":58893,\"start\":58877},{\"end\":58904,\"start\":58893},{\"end\":58912,\"start\":58904},{\"end\":58924,\"start\":58912},{\"end\":59302,\"start\":59263},{\"end\":59313,\"start\":59302},{\"end\":59321,\"start\":59313},{\"end\":59563,\"start\":59528},{\"end\":59584,\"start\":59563},{\"end\":59589,\"start\":59584},{\"end\":59854,\"start\":59840},{\"end\":59867,\"start\":59854},{\"end\":60538,\"start\":60527},{\"end\":60551,\"start\":60538},{\"end\":60562,\"start\":60551}]", "bib_venue": "[{\"end\":47999,\"start\":47944},{\"end\":48589,\"start\":48515},{\"end\":49096,\"start\":49031},{\"end\":49579,\"start\":49505},{\"end\":49928,\"start\":49864},{\"end\":50228,\"start\":50167},{\"end\":50580,\"start\":50478},{\"end\":50907,\"start\":50843},{\"end\":51274,\"start\":51263},{\"end\":51534,\"start\":51456},{\"end\":51876,\"start\":51821},{\"end\":52146,\"start\":52091},{\"end\":52556,\"start\":52500},{\"end\":52998,\"start\":52946},{\"end\":53199,\"start\":53153},{\"end\":53463,\"start\":53369},{\"end\":53697,\"start\":53637},{\"end\":53952,\"start\":53884},{\"end\":54152,\"start\":54117},{\"end\":54559,\"start\":54497},{\"end\":54834,\"start\":54792},{\"end\":55123,\"start\":55046},{\"end\":55630,\"start\":55545},{\"end\":56423,\"start\":56375},{\"end\":56909,\"start\":56825},{\"end\":57326,\"start\":57231},{\"end\":57684,\"start\":57604},{\"end\":58123,\"start\":58042},{\"end\":58604,\"start\":58534},{\"end\":58987,\"start\":58924},{\"end\":59325,\"start\":59321},{\"end\":59526,\"start\":59464},{\"end\":59970,\"start\":59871},{\"end\":60525,\"start\":60452},{\"end\":52575,\"start\":52558},{\"end\":55187,\"start\":55125},{\"end\":55809,\"start\":55724},{\"end\":56467,\"start\":56425},{\"end\":56980,\"start\":56911},{\"end\":58191,\"start\":58125},{\"end\":60095,\"start\":60011}]"}}}, "year": 2023, "month": 12, "day": 17}