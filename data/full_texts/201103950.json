{"id": 201103950, "updated": "2023-10-06 23:27:28.757", "metadata": {"title": "ARAML: A Stable Adversarial Training Framework for Text Generation", "authors": "[{\"first\":\"Pei\",\"last\":\"Ke\",\"middle\":[]},{\"first\":\"Fei\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Minlie\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Xiaoyan\",\"last\":\"Zhu\",\"middle\":[]}]", "venue": "EMNLP", "journal": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "Most of the existing generative adversarial networks (GAN) for text generation suffer from the instability of reinforcement learning training algorithms such as policy gradient, leading to unstable performance. To tackle this problem, we propose a novel framework called Adversarial Reward Augmented Maximum Likelihood (ARAML). During adversarial training, the discriminator assigns rewards to samples which are acquired from a stationary distribution near the data rather than the generator\u2019s distribution. The generator is optimized with maximum likelihood estimation augmented by the discriminator\u2019s rewards instead of policy gradient. Experiments show that our model can outperform state-of-the-art text GANs with a more stable training process.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1908.07195", "mag": "2971089354", "acl": "D19-1436", "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/KeHHZ19", "doi": "10.18653/v1/d19-1436"}}, "content": {"source": {"pdf_hash": "f696879a5459d4ceaa4a403e61b804050ebdedf0", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/D19-1436.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/D19-1436.pdf", "status": "HYBRID"}}, "grobid": {"id": "0c43ea6acf4c83da0f0b44c73e498dccd9851e98", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f696879a5459d4ceaa4a403e61b804050ebdedf0.txt", "contents": "\nARAML: A Stable Adversarial Training Framework for Text Generation\nNovember 3-7, 2019\n\nPei Ke \nInstitute for Artificial Intelligence\nState Key Lab of Intelligent Technology and Systems Beijing National Research Center for Information Science and Technology Department of Computer Science and Technology\nTsinghua University\n100084BeijingChina\n\nFei Huang f-huang18@mails.tsinghua.edu.cnaihuang@tsinghua.edu.cn \nInstitute for Artificial Intelligence\nState Key Lab of Intelligent Technology and Systems Beijing National Research Center for Information Science and Technology Department of Computer Science and Technology\nTsinghua University\n100084BeijingChina\n\nMinlie Huang \nInstitute for Artificial Intelligence\nState Key Lab of Intelligent Technology and Systems Beijing National Research Center for Information Science and Technology Department of Computer Science and Technology\nTsinghua University\n100084BeijingChina\n\nXiaoyan Zhu \nInstitute for Artificial Intelligence\nState Key Lab of Intelligent Technology and Systems Beijing National Research Center for Information Science and Technology Department of Computer Science and Technology\nTsinghua University\n100084BeijingChina\n\nARAML: A Stable Adversarial Training Framework for Text Generation\n\nProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing\nthe 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ProcessingHong Kong, ChinaNovember 3-7, 20194271\nMost of the existing generative adversarial networks (GAN) for text generation suffer from the instability of reinforcement learning training algorithms such as policy gradient, leading to unstable performance. To tackle this problem, we propose a novel framework called Adversarial Reward Augmented Maximum Likelihood (ARAML). During adversarial training, the discriminator assigns rewards to samples which are acquired from a stationary distribution near the data rather than the generator's distribution. The generator is optimized with maximum likelihood estimation augmented by the discriminator's rewards instead of policy gradient. Experiments show that our model can outperform state-of-the-art text GANs with a more stable training process.\n\nIntroduction\n\nNatural text generation, as a key task in NLP, has been advanced substantially thanks to the flourish of neural models (Bengio et al., 2003;Mikolov et al., 2010). Typical frameworks such as sequence-to-sequence (seq2seq) have been applied to various generation tasks, including machine translation (Sutskever et al., 2014) and dialogue generation (Vinyals and Le, 2015). The standard paradigm to train such neural models is maximum likelihood estimation (MLE), which maximizes the log-likelihood of observing each word in the text given the ground-truth proceeding context (Graves, 2013).\n\nAlthough widely used, MLE suffers from the exposure bias problem (Bengio et al., 2015;Ranzato et al., 2016): during test, the model sequentially predicts the next word conditioned on its previous generated words while during training conditioned on ground-truth words. To tackle this * Equal contribution \u2020 Corresponding author: Minlie Huang problem, generative adversarial networks (GAN) with reinforcement learning (RL) training approaches have been introduced to text generation tasks Che et al., 2017;Lin et al., 2017;Shi et al., 2018;, where the discriminator is trained to distinguish real and generated text samples to provide reward signals for the generator, and the generator is optimized via policy gradient . However, recent studies have shown that potential issues of training GANs on discrete data are more severe than exposure bias (Semeniuta1 et al., 2018;Caccia et al., 2018). One of the fundamental issues when generating discrete text samples with GANs is training instability. Updating the generator with policy gradient always leads to an unstable training process because it's difficult for the generator to derive positive and stable reward signals from the discriminator even with careful pretraining (Che et al., 2017). As a result, the generator gets lost due to the high variance of reward signals and the training process may finally collapse .\n\nIn this paper, we propose a novel adversarial training framework called Adversarial Reward Augmented Maximum Likelihood (ARAML) to deal with the instability issue of training GANs for text generation. At each iteration of adversarial training, we first train the discriminator to assign higher rewards to real data than to generated samples. Then, inspired by reward augmented maximum likelihood (RAML) (Norouzi et al., 2016), the generator is updated on the samples acquired from a stationary distribution with maximum likelihood estimation (MLE), weighted by the discriminator's rewards. This stationary distribution is designed to guarantee that training samples are surrounding the real data, thus the exploration space of our generator is indeed restricted by the MLE training objective, resulting in more stable training. Compared to other text GANs with RL training techniques, our framework acquires samples from the stationary distribution rather than the generator's distribution, and uses RAML training paradigm to optimize the generator instead of policy gradient. Our contributions are mainly as follows:\n\n\u2022 We analyze the fundamental issue of current GANs for text generation from the perspectives of training instability.\n\n\u2022 We propose a novel framework called Adversarial Reward Augmented Maximum Likelihood (ARAML), which incorporates stable RAML training into adversarial training paradigm. Experimental results on three text generation tasks show the effectiveness of our method.\n\n\nRelated Work\n\nRecently, text generation has been widely studied with neural models trained with maximum likelihood estimation (Graves, 2013). However, MLE tends to generate universal text . Various methods have been proposed to enhance the generation quality by refining the objective function Mou et al., 2016) or modifying the generation distribution with external information like topic (Xing et al., 2017), sentence type (Ke et al., 2018), emotion (Zhou et al., 2018a) and knowledge (Zhou et al., 2018b). As mentioned above, MLE suffers from the exposure bias problem (Bengio et al., 2015;Ranzato et al., 2016). Thus, reinforcement learning has been introduced to text generation tasks such as policy gradient (Ranzato et al., 2016) and actorcritic (Bahdanau et al., 2017). (Norouzi et al., 2016) proposed an efficient and stable approach called Reward Augmented Maximum Likelihood (RAML), which connects the log-likelihood and expected rewards to incorporate MLE training objective into RL framework.\n\nSince some text generation tasks have no explicit metrics to be directly optimized, adversarial training has been applied to generating discrete text samples with a discriminator to learn a proper reward. For instance, SeqGAN  devised a discriminator to distinguish the real data and generated samples, and a generator to maximize the reward from the discriminator via pol-icy gradient. Other variants of GANs have been proposed to improve the generator or the discriminator. To improve the generator, MaliGAN (Che et al., 2017) developed a normalized maximum likelihood optimization target for the generator to stably model the discrete sequences. LeakGAN  guided the generator with reward signals leaked from the discriminator at all generation steps to deal with long text generation task. MaskGAN  employed an actor-critic architecture to make the generator fill in missing text conditioned on the surrounding context, which is expected to mitigate the problem of mode collapse. As for the discriminator, RankGAN (Lin et al., 2017) replaced traditional discriminator with a ranker to learn the relative ranking information between the real texts and generated ones. Inverse reinforcement learning (Shi et al., 2018) used a trainable reward approximator as the discriminator to provide dense reward signals at each generation step. DPGAN ) introduced a language model based discriminator and regarded cross-entropy as rewards to promote the diversity of generation results.\n\nThe most similar works to our model are RAML (Norouzi et al., 2016) and MaliGAN (Che et al., 2017): 1) Compared with RAML, our model adds a discriminator to learn the reward signals instead of choosing existing metrics as rewards. We believe that our model can adapt to various text generation tasks, particularly those without explicit evaluation metrics. 2) Unlike MaliGAN, we acquire samples from a fixed distribution near the real data rather than the generator's distribution, which is expected to make the training process more stable.\n\n\nModel\n\n\nTask Definition and Model Overview\n\nText generation can be formulated as follows: given the real data distribution P data (X), the task is to train a generative model G \u03b8 where P G \u03b8 (X) can fit P data (X) well. In this formulation, X = x 1 x 2 \u00b7 \u00b7 \u00b7 x m and x t (1 \u2264 t \u2264 m) denotes a word in the vocabulary V. Figure 1 shows the overview of our model ARAML. This adversarial training framework consists of two phases: 1) The discriminator is trained to assign higher rewards to real data than to generated data. 2) The generator is trained on the samples acquired from a stationary distribu-  Figure 1: Overview of ARAML. The training samples are acquired from a stationary distribution P s based on the real data. The generator is then trained on the samples augmented by the discriminator's rewards. The discriminator is trained to distinguish real data and generated data. tion with reward augmented MLE training objective. This training paradigm of the generator indeed constrains the search space with the MLE training objective, which alleviates the issue of unstable training.\n\n\nDiscriminator\n\nThe discriminator D \u03c6 aims to distinguish real data and generated data like other GANs. Inspired by Least-Square GAN (Mao et al., 2017), we devise the loss function as follows:\nL D \u03c6 = 1 2 E X\u223cP data (X) (D \u03c6 (X) \u2212 1) 2 + 1 2 E X\u223cP G \u03b8 (X) (D \u03c6 (X)) 2 (1)\nThis loss function forces the discriminator to assign higher rewards to real data than to generated data, so the discriminator can learn to provide more proper rewards as the training proceeds.\n\n\nGenerator\n\nThe training objective of our generator G \u03b8 is derived from the objective of other discrete GANs with RL training method:\nL RL,\u03b8 = \u2212E X\u223cP G \u03b8 (X) [r \u03c6 (X)] \u2212 \u03c4 H(P G \u03b8 (X))(2)\nwhere r \u03c6 (X) denotes the rewards from the discriminator D \u03c6 and the entropy regularized term H(P G \u03b8 (X)) encourages G \u03b8 to generate diverse text samples. \u03c4 is a temperature hyper-parameter to balance these two terms.\n\nAs mentioned above, discrete GANs suffer from the instability issue due to policy gradient, thus they are consequently difficult to train. Inspired by RAML (Norouzi et al., 2016), we introduce an exponential payoff distribution Q \u03c6 (X) to connect RL loss with RAML loss:\nQ \u03c6 (X) = 1 Z exp(r \u03c6 (X)/\u03c4 )(3)\nwhere Z = X exp(r \u03c6 (X)/\u03c4 ). Thus, we can rewrite L RL,\u03b8 with P G \u03b8 (X) and Q \u03c6 (X) as follows:\nL RL,\u03b8 = \u03c4 KL(P G \u03b8 (X)||Q \u03c6 (X)) + constant(4)\nFollowing RAML, we remove the constant term and optimize the KL divergence in the opposite direction: (5) where H(Q \u03c6 (X)) is a constant in the training phase of the generator. It has been proved that L RL,\u03b8 and L RAML,\u03b8 are equivalent up to their first order Taylor approximations, and they have the same global optimum (Norouzi et al., 2016). L RAML,\u03b8 can be trained in a MLE-like fashion but sampling from the distribution Q \u03c6 (X) is intractable in the adversarial setting, because Q \u03c6 (X) varies with the discriminator D \u03c6 . Thus, we introduce importance sampling to separate sampling process from D \u03c6 and obtain the final loss function:\nL RAML,\u03b8 = KL(Q \u03c6 (X)||P G \u03b8 (X)) = \u2212E X\u223cQ \u03c6 (X) [log P G \u03b8 (X)] \u2212 H(Q \u03c6 (X)) = \u2212E X\u223cQ \u03c6 (X) [log P G \u03b8 (X)] + constantL G \u03b8 = \u2212E X\u223cPs(X) [W \u03c6 (X) log P G \u03b8 (X)] (6)\nwhere P s (X) denotes a stationary distribution and W \u03c6 (X) \u221d Q \u03c6 (X)/P s (X). To optimize this loss function, we first construct the fixed distribution P s (X) to get samples, and devise the proper reward function r \u03c6 (X) to train the generator in a stable and effective way.\n\n\nSampling\n\nWe construct the distribution P s based on P data :\nP s (X) = E X\u223cP data (X) [P s (X s |X)](7)\nIn this way, P s (X s |X) can be designed to guarantee that P s (X) is near P data (X), leading to a more stable training process. To obtain a new sample X s from a real data sample X, we can design three steps which contain sampling an edit distance d, the positions {p 1 , p 2 , \u00b7 \u00b7 \u00b7 , p d } for substitution and the new words {w 1 , w 2 , \u00b7 \u00b7 \u00b7 , w d } filled into the corresponding positions. Thus, P s (X s |X) can be decomposed into three terms:\nP s (X s |X) = P (d, p, w|X) = P (d|X)P (p|X, d)P (w|X, d, p) (8)\nThe first step is to sample an edit distance based on a real data sample X, where X = x 1 x 2 \u00b7 \u00b7 \u00b7 x m is a sequence of length m. The number of sentences which have the edit distance e to some input sentence can be computed approximately as below:\nc(e, m) = m e \u00b7 (|V| \u2212 1) e(9)\nwhere c(e, m) denotes the number of sentences which have an edit distance e(e \u2208 {0, 1, ..., m}) to a sentence of length m, and |V| indicates the size of vocabulary. We then follow (Norouzi et al., 2016) to re-scale the counts by exp{\u2212e/\u03c4 } and do normalization, so that we can sample an edit distance d * from:\nP (d = d * |X) = exp{\u2212d * /\u03c4 }c(d * , m) m e=0 exp{\u2212e/\u03c4 }c(e, m)(10)\nwhere \u03c4 , as a temperature hyper-parameter, restricts the search space surrounding the original sentence. Larger \u03c4 brings more samples with long edit distances.\n\nThe next step is to select positions for substitution based on the sampled edit distance d * . Intuitively, we can randomly choose d * distinct positions in X to be replaced by new words. The probability of choosing the position p * is calculated as follows:\nP (p = p * |X, d = d * ) = d * m(11)\nFollowing this sampling strategy, we can obtain the position set {p 1 , p 2 , \u00b7 \u00b7 \u00b7 , p d * }. This strategy approximately guarantees that the edit distance between a new sentence and the original sentence is d * .\n\nAt the final step, our model determines new words for substitution at each sampled position p j (j = 1, 2, ..., d * ). We can formulate this sampling process from the original sequence X to a new sample X s as a sequential transition X = X 0 \u2192 X 1 \u2192 \u00b7 \u00b7 \u00b7 \u2192 X d * = X s . At each step from X j\u22121 to X j (j = 1, \u00b7 \u00b7 \u00b7 , d * ), we first sample a new word w j from the distribution P (w|X j\u22121 , p = p j ), then replace the old word at position p j of X j\u22121 to obtain X j . The whole sampling process can be decomposed as follows:\nP (w|X, d = d * ,p = {p 1 , p 2 , \u00b7 \u00b7 \u00b7 , p d * }) = d * j=1 P (w j |X j\u22121 , p = p j ) (12)\nThere are two common sampling strategies to model P (w|X j\u22121 , p = p j ), i.e. random sampling and constrained sampling. Random sampling strategy samples a new word w j according to the uniform distribution over the vocabulary V (Norouzi et al., 2016), while constrained sampling strategy samples w j to maximize the language model score of the target sentence X j (Su et al., 2018;Miao et al., 2019). Here, we adopt constrained sampling in our model and compare the performances of two strategies in the experiment.\n\n\nTraining\n\nWe devise the reward function r \u03c6 (X) according to the discriminator's output D \u03c6 (X) and the stationary distribution P s (X):\nr \u03c6 (X) = \u03c4 \u00b7 [log P s (X) + D \u03c6 (X)](13)\nIntuitively, this reward function encourages the generator to generate sentences with large sampling probability and high rewards from the discriminator. Thus, the weight of samples W \u03c6 (X) can be calculated as follows:\nW \u03c6 (X) \u221d Q \u03c6 (X) P s (X) \u221d exp {D \u03c6 (X)}(14)\nSo far, we can successfully optimize the generator's loss L G \u03b8 via Equation 6. This training paradigm makes our generator avoid possible variances caused by policy gradient and get more stable reward signals from the discriminator, because our generator is restricted to explore the training samples near the real data.\n\nAlgorithm 1 Adversarial Reward Augmented Maximum Likelihood Require: Total adversarial training iterations: N iters Steps of training generator: G steps Steps of training discriminator: D steps 1: Pre-train the generator G \u03b8 with MLE loss 2: Generate samples from P G \u03b8 3: Pre-train the discriminator D \u03c6 via Eq.(1) 4: Construct P s (X) via Eq. (7) \n\n\nExtension to Conditional Text Generation\n\nWe have shown our adversarial training framework for text generation tasks without an input. Actually, it can also be extended to conditional text generation tasks like dialogue generation. Given the data distribution P data (C, X) where C, X denote contexts and responses respectively, the objective function of ARAML's generator can be modified as below:\nL G \u03b8 = \u2212E (C,X)\u223cP data (C,X) E Xs\u223cPs(Xs|C,X) [W \u03c6 (C, X s ) log P G \u03b8 (X s |C)](15)\nwhere W \u03c6 (C, X s ) \u221d exp{D \u03c6 (C, X s )} and D \u03c6 (C, X s ) is trained to distinguish whether X s is the true response to C.\n\n\nComparison with RAML and MaliGAN\n\nThe most similar works to our framework are RAML (Norouzi et al., 2016) and MaliGAN (Che et al., 2017). The main difference among them is the training objective of their generators. We have shown different objective functions in Table 1. For comparison, we use the form with no input for all the three models. Our model is greatly inspired by RAML, which gets samples from a non-parametric distribution Q(X) constructed based on a specific reward. Compared to RAML, our reward comes from a learnable discriminator which varies as the adversarial training proceeds rather than a specific reward function. This difference equips our framework with the ability to adapt to the text generation tasks with no explicit evaluation metrics as rewards.\n\nOur model is also similar to MaliGAN, which gets samples from the generator's distribution. In MaliGAN's training objective, G \u03b8 also indicates the generator's distribution but it's used in the sampling phase and fixed at each optimization step. The weight of samples W \u03c6 (X) \u221d D \u03c6 (X) 1\u2212D \u03c6 (X) . Different from our model, MaliGAN acquires samples from the generator's distribution P G \u03b8 , which usually brings samples with low rewards even with careful pre-training for the generator, leading to training instability. Instead, our framework gets samples from a stationary distribution P s around real data, thus our training process is more stable.\n\n\nModel\n\nTraining Objective of Generator RAML\n\nLG  We evaluated ARAML on three datasets: COCO image caption dataset (Chen et al., 2015), EMNLP2017 WMT dataset 1 and Weibo-Dial single-turn dialogue dataset (Qian et al., 2018). COCO and EMNLP2017 WMT are the common benchmarks with no input to evaluate the performance of discrete GANs, and we followed the existing works to preprocess these datasets (Shi et al., 2018;. WeiboDial, as a dialogue dataset, was applied to test the performance of our model with input trigger. We simply removed post-response pairs containing lowfrequency words and randomly selected a subset for our training/test set. The statistics of three datasets are presented in Table 2.\n\u03b8 = \u2212E X\u223cQ(X) [log PG \u03b8 (X)] MaliGAN LG \u03b8 = \u2212E X\u223cP G \u03b8 (X) [W \u03c6 (X) log PG \u03b8 (X)] ARAML LG \u03b8 = \u2212E X\u223cPs(X) [W \u03c6 (X) log PG \u03b8 (X)]\n\nBaselines\n\nWe compared our model with MLE, RL and GAN baselines. Since COCO and EMNLP2017 WMT don't have input while WeiboDial regards posts as input, we chose the following baselines respectively: MLE: a RNN model trained with MLE objective (Graves, 2013). Its extension, Seq2Seq, can work on the dialogue dataset (Sutskever et al., 2014). SeqGAN: The first text GAN model that updates the generator with policy gradient based on the rewards from the discriminator . LeakGAN: A variant of SeqGAN that provides rewards based on the leaked information of the discriminator for the generator . MaliGAN: A variant of SeqGAN that optimizes the generator with a normalized maximum likelihood objective (Che et al., 2017). IRL: This inverse reinforcement learning method replaces the discriminator with a reward approximator to provide dense rewards (Shi et al., 2018). RAML: A RL approach to incorporate MLE objective into RL training framework, which regards BLEU as rewards (Norouzi et al., 2016). DialogGAN: An extension of SeqGAN tuned to dialogue generation task with MLE objective added to the adversarial objective . DPGAN: A variant of DialogGAN which uses a language model based discriminator and regards cross-entropy as rewards .\n\nNote that MLE, SeqGAN, LeakGAN, Mali-GAN and IRL are the baselines on COCO and EMNLP2017 WMT, while MLE, RAML, Dialog-GAN, and DPGAN on WeiboDial. The original codes are used to test the baselines.\n\n\nImplementation Details\n\nThe implementation details of our model are shown in Table 3. For COCO / EMNLP2017, the  generator is a LSTM unit (Hochreiter and Schmidhuber, 1997) with 128 cells, and the discriminator is implemented based on . For WeiboDial, the generator is an encoder-decoder structure with attention mechanism, where both the encoder and the decoder consist of a two-layer GRU (Cho et al., 2014) with 128 cells. The discriminator is implemented based on (Tao et al., 2018). The language model used in the constrained sampling of ARAML is implemented in the same setting as the generators, and is pretrained on the training set of each dataset. The codes and the datasets are available at https: //github.com/kepei1106/ARAML. As for the details of the baselines, the generators of all the baselines except LeakGAN are the same as ours. Note that the generator of Leak-GAN consists of a hierarchical LSTM unit, thus we followed the implementation in the original paper. In terms of the differences, the discriminators of GAN baselines are implemented based on the original papers. Other hyper-parameters of baselines including batch size, learning rate, and pre-training epochs, were set based on the original codes, because the convergence of baselines is sensitive to these hyper-parameters.\n\n\nLanguage Generation on COCO and EMNLP2017 WMT\n\nWe adopted forward/reverse perplexity  and Self-BLEU  to evaluate the quality of generated texts. Forward perplexity (PPL-F) indicates the perplexity on the generated data provided by a language model trained on real data to measure the fluency of generated samples. Reverse perplexity (PPL-R) switches the roles of generated data and real data  to reflect the discrepancy between the generated distribution and the data distribution. Self-BLEU (S-BLEU) regards each sentence in the generated collection as hypothesis and the others as reference to obtain BLEU scores, which evaluates the diversity of generated results. Results are shown in Table 4. LeakGAN performs best on forward perplexity because it can generate more fluent samples. As for reverse perplexity, our model ARAML beats other baselines, showing that our model can fit the data distribution better. Other GANs, particularly LeakGAN, obtain high reverse perplexity due to mode collapse (Shi et al., 2018), thus they only capture limited fluent expressions, resulting in large discrepancy between the generated distribution and data distribution. ARAML also outperforms the baselines in terms of Self-BLEU, indicating that our model doesn't fall into mode collapse with the help of the MLE training objective and has the ability to generate more diverse sentences.\n\nWe also provide standard deviation of each metric in Table 4, reflecting the stability of each model's performance. Our model ARAML nearly achieves the smallest standard deviation in all the metrics, indicating that our framework outperforms policy gradient in the stability of adversarial training.\n\n\nDialogue Generation on WeiboDial\n\nDialogue evaluation is an open problem and existing works have found that automatic metrics have low correlation to human evaluation (Liu et al., 2016;Novikova et al., 2017;Chaganty et al., 2018). Thus, we resorted to manual evaluation to assess the generation quality on WeiboDial. We randomly sampled 200 posts from the test set and collected the generated results from all the models. For each pair of responses (one from ARAML and the other from a baseline, given the same input post), five annotators were hired to label which response is better (i.e. win, lose or tie) in terms of grammaticality (whether a response itself is gram-matical and logical) and relevance (whether a response is appropriate and relevant to the post). The two metrics were evaluated independently.\n\nThe evaluation results are shown in Table 5. To measure the inter-annotator agreement, we calculated Fleiss' kappa (Fleiss, 1971) for each pairwise comparison where results show moderate agreement (0.4 \u2264 \u03ba \u2264 0.6). We also conducted sign test to check the significance of the differences.\n\nAs shown in Table 5, ARAML performs significantly better than other baselines in all the cases. This result indicates that the samples surrounding true responses provide stable rewards for the generator, and stable RAML training paradigm significantly enhances the performance in both metrics. To verify the training stability, we conducted experiments on COCO many times and chose the best 5 trials for SeqGAN, LeakGAN, IRL, Mali-GAN and ARAML, respectively. Then, we presented the forward/reverse perplexity in the train-  ing process in Figure 2. We can see that our model with smaller standard deviation is more stable than other GAN baselines in both metrics. Although LeakGAN reaches the best forward perplexity, its standard deviation is extremely large and it performs badly in reverse perplexity, indicating that it generates limited expressions that are grammatical yet divergent from the data distribution.\n\n\nFurther Analysis on Stability\n\n\nAblation Study\n\n\nImpact of Temperature\n\nThe temperature \u03c4 controls the search space surrounding the real data as we analyze in Section 3.3.1. To investigate its impact on the performance of our model, we fixed all the other hyperparameters and test ARAML with different temperatures on COCO. The experimental results are shown in Figure 3. We can see that as the temperature becomes larger, forward perplexity increases gradually while Self-BLEU decreases. As mentioned in Section 3.3.1, large temperatures encourage our generator to explore the samples that are distant from real data distribution, thus the diversity of generated results will be improved. However, these samples distant from the data distribution are more likely to be poor in fluency, leading to worse forward perplexity. Reverse perplexity is influenced by both generation quality and diversity, so the correlation between temperature and reverse perplexity is not intuitive. We can observe that the model with \u03c4 = 0.95 reaches the best reverse perplexity.\n\n\nImpact of Sampling Strategy\n\nWe have mentioned two common sampling strategies in Section 3.3.1, i.e. random sampling and constrained sampling. To analyze their impact, we keep all the model structures and hyperparameters fixed and test ARAML with these two strategies on COCO.  Table 6: PPL-F, PPL-R and S-BLEU of ARAML with random sampling (ARAML-R) and constrained sampling (ARAML-C) on COCO. Table 6 shows the results. It's obvious that random sampling hurts the model performance except Self-BLEU-1, because it indeed allows lowquality samples available to the generator. Exploring these samples degrades the quality and diversity of generated results. Despite the worse performance on automatic metrics, random sampling doesn't affect the training stability of our framework. The standard deviation of ARAML-R is still smaller than other GAN baselines. Table 7 presents the examples generated by the models on COCO. We can find that other baselines suffer from grammatical errors (e.g. \"in front of flying her kite\" from MLE), repetitive expressions Model Generated Samples MLE A little girl sitting on a beach in front of flying her kite at the beach. A little boy standing in a room next to a desk. SeqGAN A man sitting on a bench with snow board in the background. A brown gray cat is in the corner of a street. LeakGAN A person that is holding something while another kid is standing in the water. A room with a television, mantle, and a chair. MaliGAN A man with a shirt on holding one large pink giant and white kite. A couple and vases are outside on the bed. IRL A group of people wearing helmet sitting down on a cell phone. A group of people sitting in the middle of tracks. ARAML A man is wearing a hat and holding a toothbrush as he stands on the grass of a field. A boy reading a book on a sofa in a room. (e.g. \"A group of people\" from IRL) and incoherent statements (e.g. \"A group of people sitting on a cell phone\" from IRL). By contrast, our model performs well in these sentences and has the ability to generate grammatical and coherent results.   Table 8 shows the generated examples on Wei-boDial. It's obvious that other baselines don't capture the topic word \"late\" in the post, thus generate irrelevant responses. ARAML can provide a response that is grammatical and closely relevant to the post.\n\n\nCase Study\n\n\nConclusion\n\nWe propose a novel adversarial training framework to deal with the instability problem of current GANs for text generation. To address the instability issue caused by policy gradient, we incorporate RAML into the adversarial training paradigm to make our generator acquire stable rewards. Experiments show that our model performs better than several state-of-the-art GAN baselines with lower training variance, yet producing better performance on three text generation tasks.\n\n\n-Eq.(12) 5: for each s = 1, 2, ..., N iters do 6:for each j = 1, 2, ...\n\nFigure 2 :\n2PPL-F/PPL-R curves of ARAML, SeqGAN, LeakGAN, MaliGAN and IRL in the training process. The shade area indicates the standard deviation at each data point. The dotted vertical lines separate pre-training and adversarial training phases (50 for ARAML, IRL and MaliGAN, 80 for SeqGAN and LeakGAN).\n\nFigure 3 :\n3PPL-F, PPL-R and S-BLEU of ARAML with different temperatures \u03c4 \u2208 {0.8, 0.85, 0.9, 0.95} on COCO.\n\n\n37.48\u00b10.53 37.44\u00b10.56 0.752/0.571/0.384 ARAML-C 26.97\u00b10.55 35.79\u00b10.49 0.777/0.560/0.366\n\nTable 1 :\n1Training objectives of generators for RAML, MaliGAN and ARAML.4 Experiment \n\n4.1 Datasets \n\nDataset \nAmount(Train/Test) Vocabulary Length \nCOCO \n80,000/5,000 \n4,839 \n12.8 \nEMNLP2017 \n49,996/10,000 \n5,721 \n27.8 \nWeiboDial \n100,000/5,000 \n7,998 \n7.3/10.8 \n\n\n\nTable 2 :\n2Statistics of COCO, EMNLP2017 WMT and \nWeiboDial. The average lengths 7.3/10.8 of Weibo-\nDial indicate the lengths of posts and responses, respec-\ntively. \n\n\n\nTable 3 :\n3Implementation details of ARAML. G/D/LM \nindicates the generator / discriminator / language model \nused in constrained sampling, respectively. \n\n\n\nTable 4 :\n4Automatic evaluation on COCO and EMNLP2017 WMT. Each metric is presented with mean and standard deviation.\n\nTable 5 :\n5Human evaluation on WeiboDial. The scores represent the percentages of Win, Lose or Tie when our model is compared with a baseline. \u03ba denotes Fleiss' kappa (all are moderate agreement).The scores marked with \n\n\nTable 7 :\n7Examples of generated sentences on COCO. Grammatical errors are in red, while blue text represents repetitive expressions and green part indicates incoherent statements.\n\nPost :\nPost\u4f60\u8fd8\u8fdf\u5230\u54ea\uff1f\u4f60\u6ca1\u8fd9\u4e60\u60ef\u554a Are you late? You don't have this habit. MLE: \u4f60\u662f\u4e0d\u662f\u8981\u597d\u597d\u7167\u987e\u81ea\u5df1\u7684\uff01\uff01\uff01 Would you take care of yourself !!! RAML: \u8fd9\u662f\u6211\u7684\u751f\u6d3b\uff0c\u6211\u4e5f\u4e0d\u60f3\u5e72 This is my life. I don't want to do this. DialogGAN: \u8fd9\u793e\u4f1a\u7684\u6e29\u5ea6\u5feb\u5230\u4e86\u3002\u5468\u672b\uff0c\u8981\u8eba\u5e8a\u4e0a\uff01 The temperature of the society has nearly reached. I'll lie on my bed on the weekend! DPGAN: \u6211\u5728\u4e0a\u73ed\uff0c\u6211\u5c31\u4e0d\u4e60\u60ef\u4e86 I'm working and I'm used to doing this. ARAML: \u55ef\uff0c\u5468\u672b\u5c31\u4e0d\u8fdf\u5230\u4e86\uff01 Hum. I won't be late on the weekend!\n\nTable 8 :\n8Examples of generated responses on Weibo-Dial.\nhttp://statmt.org/wmt17/translation-task.html\nAcknowledgmentsThis work was supported by the National Science Foundation of China (Grant No. 61936010/61876096) and the National Key R&D Program of China (Grant No. 2018YFC0830200). We would like to thank THUNUS NExT Joint-Lab for the support.\nAn actor-critic algorithm for sequence prediction. Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron Courville, Yoshua Bengio, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsDzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron Courville, and Yoshua Bengio. 2017. An actor-critic algorithm for sequence prediction. In Proceedings of International Conference on Learning Represen- tations.\n\nScheduled sampling for sequence prediction with recurrent neural networks. Samy Bengio, Oriol Vinyals, Navdeep Jaitly, Noam Shazeer, Advances in Neural Information Processing Systems. Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. 2015. Scheduled sampling for se- quence prediction with recurrent neural networks. In Advances in Neural Information Processing Sys- tems, pages 1171-1179.\n\nA neural probabilistic language model. Yoshua Bengio, R\u00e9jean Ducharme, Pascal Vincent, Christian Jauvin, Journal of Machine Learning Research. 3Yoshua Bengio, R\u00e9jean Ducharme, Pascal Vincent, and Christian Jauvin. 2003. A neural probabilistic lan- guage model. Journal of Machine Learning Re- search, 3:1137-1155.\n\nMassimo Caccia, Lucas Caccia, William Fedus, Hugo Larochelle, Joelle Pineau, Laurent Charlin, arXiv:1811.02549Language gans falling short. arXiv preprintMassimo Caccia, Lucas Caccia, William Fedus, Hugo Larochelle, Joelle Pineau, and Laurent Charlin. 2018. Language gans falling short. arXiv preprint arXiv: 1811.02549.\n\nThe price of debiasing automatic metrics in natural language evaluation. Stephen Arun Tejasvi Chaganty, Percy Mussmann, Liang, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsArun Tejasvi Chaganty, Stephen Mussmann, and Percy Liang. 2018. The price of debiasing automatic met- rics in natural language evaluation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pages 643-653.\n\nYanran Tong Che, Ruixiang Li, Devon Zhang, Wenjie Hjelm, Li, arXiv:1702.07983Yangqiu Song, and Yoshua Bengio. 2017. Maximum-likelihood augmented discrete generative adversarial networks. arXiv preprintTong Che, Yanran Li, Ruixiang Zhang, R Devon Hjelm, Wenjie Li, Yangqiu Song, and Yoshua Ben- gio. 2017. Maximum-likelihood augmented discrete generative adversarial networks. arXiv preprint arXiv: 1702.07983.\n\nMicrosoft coco captions: Data collection and evaluation server. Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr Dollar, C Lawrence Zitnick, arXiv:1504.00325arXiv preprintXinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakr- ishna Vedantam, Saurabh Gupta, Piotr Dollar, and C. Lawrence Zitnick. 2015. Microsoft coco cap- tions: Data collection and evaluation server. arXiv preprint arXiv: 1504.00325.\n\nOn the properties of neural machine translation: Encoder-decoder approaches. Kyunghyun Cho, Bart Van Merrienboer, Dzmitry Bahdanau, Yoshua Bengio, Proceedings of Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation. Eighth Workshop on Syntax, Semantics and Structure in Statistical TranslationKyunghyun Cho, Bart Van Merrienboer, Dzmitry Bah- danau, and Yoshua Bengio. 2014. On the proper- ties of neural machine translation: Encoder-decoder approaches. In Proceedings of Eighth Workshop on Syntax, Semantics and Structure in Statistical Trans- lation, pages 103-111.\n\nMaskgan: Better text generation via filling in the. William Fedus, Ian J Goodfellow, Andrew M Dai, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsWilliam Fedus, Ian J. Goodfellow, and Andrew M. Dai. 2018. Maskgan: Better text generation via filling in the . In Proceedings of International Confer- ence on Learning Representations.\n\nMeasuring nominal scale agreement among many raters. L Joseph, Fleiss, Psychological Bulletin. 765Joseph L Fleiss. 1971. Measuring nominal scale agree- ment among many raters. Psychological Bulletin, 76(5):378-382.\n\nGenerating sequences with recurrent neural networks. Alex Graves, arXiv:1308.0850arXiv preprintAlex Graves. 2013. Generating sequences with re- current neural networks. arXiv preprint arXiv: 1308.0850.\n\nLong text generation via adversarial training with leaked information. Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, Jun Wang, Proceedings of AAAI conference on Artificial Intelligence. AAAI conference on Artificial IntelligenceJiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, and Jun Wang. 2018. Long text generation via adversarial training with leaked information. In Pro- ceedings of AAAI conference on Artificial Intelli- gence, pages 5141-5148.\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural Computation. 98Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural Computation, 9(8):1735-1780.\n\nGenerating informative responses with controlled sentence function. Pei Ke, Jian Guan, Minlie Huang, Xiaoyan Zhu, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsPei Ke, Jian Guan, Minlie Huang, and Xiaoyan Zhu. 2018. Generating informative responses with con- trolled sentence function. In Proceedings of the 56th Annual Meeting of the Association for Compu- tational Linguistics, pages 1499-1508.\n\nA diversity-promoting objective function for neural conversation models. Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, Bill Dolan, Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016. A diversity-promoting ob- jective function for neural conversation models. In Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 110-119.\n\nAdversarial learning for neural dialogue generation. Jiwei Li, Will Monroe, Tianlin Shi, Sebastien Jean, Alan Ritter, Dan Jurafsky, Proceedings of the Conference on Empirical Methods in Natural Language Processing. the Conference on Empirical Methods in Natural Language ProcessingJiwei Li, Will Monroe, Tianlin Shi, Sebastien Jean, Alan Ritter, and Dan Jurafsky. 2017. Adversarial learning for neural dialogue generation. In Proceed- ings of the Conference on Empirical Methods in Nat- ural Language Processing, pages 2157-2169.\n\nAdversarial ranking for language generation. Kevin Lin, Dianqi Li, Xiaodong He, Zhengyou Zhang, Ming-Ting Sun, Advances in Neural Information Processing Systems. Kevin Lin, Dianqi Li, Xiaodong He, Zhengyou Zhang, and Ming-Ting Sun. 2017. Adversarial ranking for language generation. In Advances in Neural Infor- mation Processing Systems, pages 3155-3165.\n\nHow not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation. Chia Wei Liu, Ryan Lowe, V Iulian, Michael Serban, Laurent Noseworthy, Joelle Charlin, Pineau, Proceedings of the Conference on Empirical Methods in Natural Language Processing. the Conference on Empirical Methods in Natural Language ProcessingChia Wei Liu, Ryan Lowe, Iulian V. Serban, Michael Noseworthy, Laurent Charlin, and Joelle Pineau. 2016. How not to evaluate your dialogue system: An empirical study of unsupervised evaluation met- rics for dialogue response generation. In Proceed- ings of the Conference on Empirical Methods in Nat- ural Language Processing, pages 2122-2132.\n\nLeast squares generative adversarial networks. Xudong Mao, Qing Li, Haoran Xie, Y K Raymond, Zhen Lau, Stephen Paul Wang, Smolley, International Conference on Computer Vision. Xudong Mao, Qing Li, Haoran Xie, Raymond Y. K. Lau, Zhen Wang, and Stephen Paul Smolley. 2017. Least squares generative adversarial net- works. In International Conference on Computer Vision, pages 2813-2821.\n\nCgmh: Constrained sentence generation by metropolis-hastings sampling. Ning Miao, Hao Zhou, Lili Mou, Rui Yan, Lei Li, Proceedings of AAAI conference on Artificial Intelligence. AAAI conference on Artificial IntelligenceNing Miao, Hao Zhou, Lili Mou, Rui Yan, and Lei Li. 2019. Cgmh: Constrained sentence generation by metropolis-hastings sampling. In Proceedings of AAAI conference on Artificial Intelligence.\n\nRecurrent neural network based language model. Tomas Mikolov, Martin Karafiat, Lukas Burget, Proceedings of the 11st Annual Conference of the International Speech Communication Association. the 11st Annual Conference of the International Speech Communication AssociationHonza Cernock, and Sanjeev KhudanpurTomas Mikolov, Martin Karafiat, Lukas Burget, Jan Honza Cernock, and Sanjeev Khudanpur. 2010. Recurrent neural network based language model. In Proceedings of the 11st Annual Conference of the International Speech Communication Association, pages 1045-1048.\n\nSequence to backward and forward sequences: A content-introducing approach to generative short-text conversation. Lili Mou, Yiping Song, Rui Yan, Ge Li, Lu Zhang, Zhi Jin, Proceedings of 26th International Conference on Computational Linguistics. 26th International Conference on Computational LinguisticsLili Mou, Yiping Song, Rui Yan, Ge Li, Lu Zhang, and Zhi Jin. 2016. Sequence to backward and for- ward sequences: A content-introducing approach to generative short-text conversation. In Proceedings of 26th International Conference on Computational Linguistics, pages 3349-3358.\n\nReward augmented maximum likelihood for neural structured prediction. Mohammad Norouzi, Samy Bengio, Zhifeng Chen, Navdeep Jaitly, Mike Schuster, Yonghui Wu, Dale Schuurmans, Advances in Neural Information Processing Systems. Mohammad Norouzi, Samy Bengio, Zhifeng Chen, Navdeep Jaitly, Mike Schuster, Yonghui Wu, and Dale Schuurmans. 2016. Reward augmented max- imum likelihood for neural structured prediction. In Advances in Neural Information Processing Sys- tems, pages 1723-1731.\n\nWhy we need new evaluation metrics for NLG. Jekaterina Novikova, Ondrej Dusek, Amanda Cercas Curry, Verena Rieser, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingJekaterina Novikova, Ondrej Dusek, Amanda Cercas Curry, and Verena Rieser. 2017. Why we need new evaluation metrics for NLG. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2241-2252.\n\nAssigning personality/profile to a chatting machine for coherent conversation generation. Qiao Qian, Minlie Huang, Haizhou Zhao, Jingfang Xu, Xiaoyan Zhu, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence. the Twenty-Seventh International Joint Conference on Artificial IntelligenceQiao Qian, Minlie Huang, Haizhou Zhao, Jingfang Xu, and Xiaoyan Zhu. 2018. Assigning personal- ity/profile to a chatting machine for coherent con- versation generation. In Proceedings of the Twenty- Seventh International Joint Conference on Artificial Intelligence, pages 4279-4285.\n\nSequence level training with recurrent neural networks. Aurelio Marc, Sumit Ranzato, Michael Chopra, Wojciech Auli, Zaremba, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsMarc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2016. Sequence level train- ing with recurrent neural networks. In Proceedings of International Conference on Learning Represen- tations.\n\nOn accurate evaluation of gans for language generation. Aliaksei Stanislau Semeniuta1, Sylvain Severyn, Gelly, arXiv:1806.04936arXiv preprintStanislau Semeniuta1, Aliaksei Severyn, and Syl- vain Gelly. 2018. On accurate evaluation of gans for language generation. arXiv preprint arXiv: 1806.04936.\n\nToward diverse text generation with inverse reinforcement learning. Zhan Shi, Xinchi Chen, Xipeng Qiu, Xuanjing Huang, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence. the Twenty-Seventh International Joint Conference on Artificial IntelligenceZhan Shi, Xinchi Chen, Xipeng Qiu, and Xuanjing Huang. 2018. Toward diverse text generation with inverse reinforcement learning. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, pages 4361-4367.\n\nIncorporating discriminator in sentence generation: A gibbs sampling method. Jinyue Su, Jiacheng Xu, Xipeng Qiu, Xuanjing Huang, Proceedings of AAAI conference on Artificial Intelligence. AAAI conference on Artificial IntelligenceJinyue Su, Jiacheng Xu, Xipeng Qiu, and Xuanjing Huang. 2018. Incorporating discriminator in sen- tence generation: A gibbs sampling method. In Proceedings of AAAI conference on Artificial Intel- ligence, pages 5496-5503.\n\nSequence to sequence learning with neural networks. Ilya Sutskever, Oriol Vinyals, Quoc V Le, Advances in Neural Information Processing Systems. Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural net- works. In Advances in Neural Information Process- ing Systems, pages 3104-3112.\n\nRuber: An unsupervised method for automatic evaluation of open-domain dialog systems. Chongyang Tao, Lili Mou, Dongyan Zhao, Rui Yan, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence. the Thirty-Second AAAI Conference on Artificial IntelligenceChongyang Tao, Lili Mou, Dongyan Zhao, and Rui Yan. 2018. Ruber: An unsupervised method for au- tomatic evaluation of open-domain dialog systems. In Proceedings of the Thirty-Second AAAI Confer- ence on Artificial Intelligence, pages 722-729.\n\nA neural conversational model. Oriol Vinyals, Quoc Le, International Conference on Machine Learning Deep Learning Workshop. Oriol Vinyals and Quoc Le. 2015. A neural conversa- tional model. In International Conference on Ma- chine Learning Deep Learning Workshop.\n\nTopic aware neural response generation. Chen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang, Ming Zhou, Wei-Ying Ma, Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence. the Thirty-First AAAI Conference on Artificial IntelligenceChen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang, Ming Zhou, and Wei-Ying Ma. 2017. Topic aware neural response generation. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelli- gence, pages 3351-3357.\n\nDiversity-promoting gan: A crossentropy based generative adversarial network for diversified text generation. Jingjing Xu, Xuancheng Ren, Junyang Lin, Xu Sun, Conference on Empirical Methods in Natural Language Processing. Jingjing Xu, Xuancheng Ren, Junyang Lin, and Xu Sun. 2018. Diversity-promoting gan: A cross- entropy based generative adversarial network for di- versified text generation. In Conference on Empiri- cal Methods in Natural Language Processing, page 3940-3949.\n\nSeqgan: Sequence generative adversarial nets with policy gradient. Lantao Yu, Weinan Zhang, Jun Wang, Yong Yu, Proceedings of AAAI conference on Artificial Intelligence. AAAI conference on Artificial IntelligenceLantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. 2017. Seqgan: Sequence generative adversarial nets with policy gradient. In Proceedings of AAAI con- ference on Artificial Intelligence, pages 2852-2858.\n\nAdversarially regularized autoencoders. Jake Junbo, Yoon Zhao, Kelly Kim, Alexander M Zhang, Yann Rush, Lecun, Proceedings of the 35th International Conference on Machine Learning. the 35th International Conference on Machine LearningJunbo Jake Zhao, Yoon Kim, Kelly Zhang, Alexan- der M. Rush, and Yann LeCun. 2018. Adversari- ally regularized autoencoders. In Proceedings of the 35th International Conference on Machine Learn- ing, pages 5897-5906.\n\nEmotional chatting machine: Emotional conversation generation with internal and external memory. Hao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan Zhu, Bing Liu, Proceedings of AAAI conference on Artificial Intelligence. AAAI conference on Artificial IntelligenceHao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan Zhu, and Bing Liu. 2018a. Emotional chatting ma- chine: Emotional conversation generation with in- ternal and external memory. In Proceedings of AAAI conference on Artificial Intelligence.\n\nCommonsense knowledge aware conversation generation with graph attention. Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, Xiaoyan Zhu, Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence. the Twenty-Seventh International Joint Conference on Artificial IntelligenceHao Zhou, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, and Xiaoyan Zhu. 2018b. Com- monsense knowledge aware conversation generation with graph attention. In Proceedings of the Twenty- Seventh International Joint Conference on Artificial Intelligence, pages 4623-4629.\n\nTexygen: A benchmarking platform for text generation models. Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, Yong Yu, Proceedings of the 41st International ACM SIGIR Conference on Research Development in Information Retrieval. the 41st International ACM SIGIR Conference on Research Development in Information RetrievalYaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, and Yong Yu. 2018. Texygen: A benchmarking platform for text gener- ation models. In Proceedings of the 41st Interna- tional ACM SIGIR Conference on Research Devel- opment in Information Retrieval, pages 1097-1100.\n", "annotations": {"author": "[{\"end\":343,\"start\":88},{\"end\":657,\"start\":344},{\"end\":919,\"start\":658},{\"end\":1180,\"start\":920}]", "publisher": null, "author_last_name": "[{\"end\":94,\"start\":92},{\"end\":353,\"start\":348},{\"end\":670,\"start\":665},{\"end\":931,\"start\":928}]", "author_first_name": "[{\"end\":91,\"start\":88},{\"end\":347,\"start\":344},{\"end\":664,\"start\":658},{\"end\":927,\"start\":920}]", "author_affiliation": "[{\"end\":342,\"start\":96},{\"end\":656,\"start\":410},{\"end\":918,\"start\":672},{\"end\":1179,\"start\":933}]", "title": "[{\"end\":67,\"start\":1},{\"end\":1247,\"start\":1181}]", "venue": "[{\"end\":1409,\"start\":1249}]", "abstract": "[{\"end\":2343,\"start\":1594}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2499,\"start\":2478},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2520,\"start\":2499},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2681,\"start\":2657},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2728,\"start\":2706},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2946,\"start\":2932},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3035,\"start\":3014},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3056,\"start\":3035},{\"end\":3454,\"start\":3437},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3471,\"start\":3454},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3488,\"start\":3471},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3821,\"start\":3796},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3841,\"start\":3821},{\"end\":4192,\"start\":4174},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":4748,\"start\":4726},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5964,\"start\":5950},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6135,\"start\":6118},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":6233,\"start\":6214},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6266,\"start\":6249},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":6296,\"start\":6276},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":6331,\"start\":6311},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6417,\"start\":6396},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6438,\"start\":6417},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6560,\"start\":6538},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6600,\"start\":6577},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6624,\"start\":6602},{\"end\":7359,\"start\":7333},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7866,\"start\":7848},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8050,\"start\":8032},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8376,\"start\":8354},{\"end\":8407,\"start\":8381},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10098,\"start\":10080},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":11000,\"start\":10978},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":11613,\"start\":11591},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":13463,\"start\":13441},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":15185,\"start\":15163},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":15316,\"start\":15299},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":15334,\"start\":15316},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":17287,\"start\":17265},{\"end\":17318,\"start\":17292},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":18747,\"start\":18728},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":18836,\"start\":18817},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":19029,\"start\":19011},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":19705,\"start\":19691},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":19788,\"start\":19764},{\"end\":20164,\"start\":20146},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":20311,\"start\":20293},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20442,\"start\":20420},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":21058,\"start\":21024},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21294,\"start\":21276},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21371,\"start\":21353},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":23211,\"start\":23193},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":24059,\"start\":24041},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":24081,\"start\":24059},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":24103,\"start\":24081},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24818,\"start\":24804}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":29861,\"start\":29788},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30169,\"start\":29862},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30279,\"start\":30170},{\"attributes\":{\"id\":\"fig_4\"},\"end\":30369,\"start\":30280},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":30637,\"start\":30370},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":30807,\"start\":30638},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":30965,\"start\":30808},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":31084,\"start\":30966},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":31306,\"start\":31085},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":31488,\"start\":31307},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":31902,\"start\":31489},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":31961,\"start\":31903}]", "paragraph": "[{\"end\":2947,\"start\":2359},{\"end\":4321,\"start\":2949},{\"end\":5440,\"start\":4323},{\"end\":5559,\"start\":5442},{\"end\":5821,\"start\":5561},{\"end\":6829,\"start\":5838},{\"end\":8307,\"start\":6831},{\"end\":8850,\"start\":8309},{\"end\":9945,\"start\":8897},{\"end\":10139,\"start\":9963},{\"end\":10412,\"start\":10219},{\"end\":10547,\"start\":10426},{\"end\":10820,\"start\":10602},{\"end\":11092,\"start\":10822},{\"end\":11221,\"start\":11126},{\"end\":11911,\"start\":11270},{\"end\":12354,\"start\":12078},{\"end\":12418,\"start\":12367},{\"end\":12914,\"start\":12462},{\"end\":13229,\"start\":12981},{\"end\":13571,\"start\":13261},{\"end\":13801,\"start\":13641},{\"end\":14061,\"start\":13803},{\"end\":14313,\"start\":14099},{\"end\":14841,\"start\":14315},{\"end\":15450,\"start\":14934},{\"end\":15589,\"start\":15463},{\"end\":15851,\"start\":15632},{\"end\":16218,\"start\":15898},{\"end\":16569,\"start\":16220},{\"end\":16970,\"start\":16614},{\"end\":17179,\"start\":17056},{\"end\":17959,\"start\":17216},{\"end\":18611,\"start\":17961},{\"end\":18657,\"start\":18621},{\"end\":19318,\"start\":18659},{\"end\":20684,\"start\":19460},{\"end\":20883,\"start\":20686},{\"end\":22190,\"start\":20910},{\"end\":23570,\"start\":22240},{\"end\":23871,\"start\":23572},{\"end\":24687,\"start\":23908},{\"end\":24976,\"start\":24689},{\"end\":25895,\"start\":24978},{\"end\":26957,\"start\":25970},{\"end\":29284,\"start\":26989},{\"end\":29787,\"start\":29312}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10218,\"start\":10140},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10601,\"start\":10548},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11125,\"start\":11093},{\"attributes\":{\"id\":\"formula_3\"},\"end\":11269,\"start\":11222},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12031,\"start\":11912},{\"attributes\":{\"id\":\"formula_5\"},\"end\":12077,\"start\":12031},{\"attributes\":{\"id\":\"formula_6\"},\"end\":12461,\"start\":12419},{\"attributes\":{\"id\":\"formula_7\"},\"end\":12980,\"start\":12915},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13260,\"start\":13230},{\"attributes\":{\"id\":\"formula_9\"},\"end\":13640,\"start\":13572},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14098,\"start\":14062},{\"attributes\":{\"id\":\"formula_11\"},\"end\":14933,\"start\":14842},{\"attributes\":{\"id\":\"formula_12\"},\"end\":15631,\"start\":15590},{\"attributes\":{\"id\":\"formula_13\"},\"end\":15897,\"start\":15852},{\"attributes\":{\"id\":\"formula_14\"},\"end\":17055,\"start\":16971},{\"attributes\":{\"id\":\"formula_15\"},\"end\":19447,\"start\":19319}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":17452,\"start\":17445},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":19317,\"start\":19310},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":20970,\"start\":20963},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":22889,\"start\":22882},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":23632,\"start\":23625},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":24732,\"start\":24725},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":24997,\"start\":24990},{\"end\":27245,\"start\":27238},{\"end\":27362,\"start\":27355},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":27825,\"start\":27818},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":29038,\"start\":29031}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2357,\"start\":2345},{\"attributes\":{\"n\":\"2\"},\"end\":5836,\"start\":5824},{\"attributes\":{\"n\":\"3\"},\"end\":8858,\"start\":8853},{\"attributes\":{\"n\":\"3.1\"},\"end\":8895,\"start\":8861},{\"attributes\":{\"n\":\"3.2\"},\"end\":9961,\"start\":9948},{\"attributes\":{\"n\":\"3.3\"},\"end\":10424,\"start\":10415},{\"attributes\":{\"n\":\"3.3.1\"},\"end\":12365,\"start\":12357},{\"attributes\":{\"n\":\"3.3.2\"},\"end\":15461,\"start\":15453},{\"attributes\":{\"n\":\"3.4\"},\"end\":16612,\"start\":16572},{\"attributes\":{\"n\":\"3.5\"},\"end\":17214,\"start\":17182},{\"end\":18619,\"start\":18614},{\"attributes\":{\"n\":\"4.2\"},\"end\":19458,\"start\":19449},{\"attributes\":{\"n\":\"4.3\"},\"end\":20908,\"start\":20886},{\"attributes\":{\"n\":\"4.4\"},\"end\":22238,\"start\":22193},{\"attributes\":{\"n\":\"4.5\"},\"end\":23906,\"start\":23874},{\"attributes\":{\"n\":\"4.6\"},\"end\":25927,\"start\":25898},{\"attributes\":{\"n\":\"4.7\"},\"end\":25944,\"start\":25930},{\"attributes\":{\"n\":\"4.7.1\"},\"end\":25968,\"start\":25947},{\"attributes\":{\"n\":\"4.7.2\"},\"end\":26987,\"start\":26960},{\"attributes\":{\"n\":\"4.8\"},\"end\":29297,\"start\":29287},{\"attributes\":{\"n\":\"5\"},\"end\":29310,\"start\":29300},{\"end\":29873,\"start\":29863},{\"end\":30181,\"start\":30171},{\"end\":30380,\"start\":30371},{\"end\":30648,\"start\":30639},{\"end\":30818,\"start\":30809},{\"end\":30976,\"start\":30967},{\"end\":31095,\"start\":31086},{\"end\":31317,\"start\":31308},{\"end\":31496,\"start\":31490},{\"end\":31913,\"start\":31904}]", "table": "[{\"end\":30637,\"start\":30444},{\"end\":30807,\"start\":30650},{\"end\":30965,\"start\":30820},{\"end\":31306,\"start\":31282}]", "figure_caption": "[{\"end\":29861,\"start\":29790},{\"end\":30169,\"start\":29875},{\"end\":30279,\"start\":30183},{\"end\":30369,\"start\":30282},{\"end\":30444,\"start\":30382},{\"end\":31084,\"start\":30978},{\"end\":31282,\"start\":31097},{\"end\":31488,\"start\":31319},{\"end\":31902,\"start\":31501},{\"end\":31961,\"start\":31915}]", "figure_ref": "[{\"end\":9180,\"start\":9172},{\"end\":9463,\"start\":9455},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":25526,\"start\":25518},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26268,\"start\":26260}]", "bib_author_first_name": "[{\"end\":32311,\"start\":32304},{\"end\":32330,\"start\":32322},{\"end\":32345,\"start\":32339},{\"end\":32357,\"start\":32350},{\"end\":32369,\"start\":32365},{\"end\":32382,\"start\":32376},{\"end\":32396,\"start\":32391},{\"end\":32414,\"start\":32408},{\"end\":32878,\"start\":32874},{\"end\":32892,\"start\":32887},{\"end\":32909,\"start\":32902},{\"end\":32922,\"start\":32918},{\"end\":33247,\"start\":33241},{\"end\":33262,\"start\":33256},{\"end\":33279,\"start\":33273},{\"end\":33298,\"start\":33289},{\"end\":33524,\"start\":33517},{\"end\":33538,\"start\":33533},{\"end\":33554,\"start\":33547},{\"end\":33566,\"start\":33562},{\"end\":33585,\"start\":33579},{\"end\":33601,\"start\":33594},{\"end\":33918,\"start\":33911},{\"end\":33947,\"start\":33942},{\"end\":34379,\"start\":34373},{\"end\":34398,\"start\":34390},{\"end\":34408,\"start\":34403},{\"end\":34422,\"start\":34416},{\"end\":34854,\"start\":34848},{\"end\":34864,\"start\":34861},{\"end\":34879,\"start\":34871},{\"end\":34896,\"start\":34885},{\"end\":34914,\"start\":34907},{\"end\":34927,\"start\":34922},{\"end\":34937,\"start\":34936},{\"end\":34946,\"start\":34938},{\"end\":35294,\"start\":35285},{\"end\":35304,\"start\":35300},{\"end\":35329,\"start\":35322},{\"end\":35346,\"start\":35340},{\"end\":35861,\"start\":35854},{\"end\":35872,\"start\":35869},{\"end\":35874,\"start\":35873},{\"end\":35893,\"start\":35887},{\"end\":35895,\"start\":35894},{\"end\":36263,\"start\":36262},{\"end\":36482,\"start\":36478},{\"end\":36706,\"start\":36699},{\"end\":36716,\"start\":36712},{\"end\":36724,\"start\":36721},{\"end\":36736,\"start\":36730},{\"end\":36748,\"start\":36744},{\"end\":36756,\"start\":36753},{\"end\":37121,\"start\":37117},{\"end\":37140,\"start\":37134},{\"end\":37354,\"start\":37351},{\"end\":37363,\"start\":37359},{\"end\":37376,\"start\":37370},{\"end\":37391,\"start\":37384},{\"end\":37874,\"start\":37869},{\"end\":37885,\"start\":37879},{\"end\":37899,\"start\":37894},{\"end\":37918,\"start\":37910},{\"end\":37928,\"start\":37924},{\"end\":38405,\"start\":38400},{\"end\":38414,\"start\":38410},{\"end\":38430,\"start\":38423},{\"end\":38445,\"start\":38436},{\"end\":38456,\"start\":38452},{\"end\":38468,\"start\":38465},{\"end\":38928,\"start\":38923},{\"end\":38940,\"start\":38934},{\"end\":38953,\"start\":38945},{\"end\":38966,\"start\":38958},{\"end\":38983,\"start\":38974},{\"end\":39369,\"start\":39365},{\"end\":39373,\"start\":39370},{\"end\":39383,\"start\":39379},{\"end\":39391,\"start\":39390},{\"end\":39407,\"start\":39400},{\"end\":39423,\"start\":39416},{\"end\":39442,\"start\":39436},{\"end\":40007,\"start\":40001},{\"end\":40017,\"start\":40013},{\"end\":40028,\"start\":40022},{\"end\":40035,\"start\":40034},{\"end\":40037,\"start\":40036},{\"end\":40051,\"start\":40047},{\"end\":40064,\"start\":40057},{\"end\":40069,\"start\":40065},{\"end\":40415,\"start\":40411},{\"end\":40425,\"start\":40422},{\"end\":40436,\"start\":40432},{\"end\":40445,\"start\":40442},{\"end\":40454,\"start\":40451},{\"end\":40804,\"start\":40799},{\"end\":40820,\"start\":40814},{\"end\":40836,\"start\":40831},{\"end\":41435,\"start\":41431},{\"end\":41447,\"start\":41441},{\"end\":41457,\"start\":41454},{\"end\":41465,\"start\":41463},{\"end\":41472,\"start\":41470},{\"end\":41483,\"start\":41480},{\"end\":41980,\"start\":41972},{\"end\":41994,\"start\":41990},{\"end\":42010,\"start\":42003},{\"end\":42024,\"start\":42017},{\"end\":42037,\"start\":42033},{\"end\":42055,\"start\":42048},{\"end\":42064,\"start\":42060},{\"end\":42443,\"start\":42433},{\"end\":42460,\"start\":42454},{\"end\":42474,\"start\":42468},{\"end\":42481,\"start\":42475},{\"end\":42495,\"start\":42489},{\"end\":42991,\"start\":42987},{\"end\":43004,\"start\":42998},{\"end\":43019,\"start\":43012},{\"end\":43034,\"start\":43026},{\"end\":43046,\"start\":43039},{\"end\":43568,\"start\":43561},{\"end\":43580,\"start\":43575},{\"end\":43597,\"start\":43590},{\"end\":43614,\"start\":43606},{\"end\":44026,\"start\":44018},{\"end\":44056,\"start\":44049},{\"end\":44333,\"start\":44329},{\"end\":44345,\"start\":44339},{\"end\":44358,\"start\":44352},{\"end\":44372,\"start\":44364},{\"end\":44875,\"start\":44869},{\"end\":44888,\"start\":44880},{\"end\":44899,\"start\":44893},{\"end\":44913,\"start\":44905},{\"end\":45301,\"start\":45297},{\"end\":45318,\"start\":45313},{\"end\":45334,\"start\":45328},{\"end\":45665,\"start\":45656},{\"end\":45675,\"start\":45671},{\"end\":45688,\"start\":45681},{\"end\":45698,\"start\":45695},{\"end\":46121,\"start\":46116},{\"end\":46135,\"start\":46131},{\"end\":46394,\"start\":46390},{\"end\":46404,\"start\":46401},{\"end\":46411,\"start\":46409},{\"end\":46419,\"start\":46416},{\"end\":46430,\"start\":46425},{\"end\":46442,\"start\":46438},{\"end\":46457,\"start\":46449},{\"end\":46936,\"start\":46928},{\"end\":46950,\"start\":46941},{\"end\":46963,\"start\":46956},{\"end\":46971,\"start\":46969},{\"end\":47373,\"start\":47367},{\"end\":47384,\"start\":47378},{\"end\":47395,\"start\":47392},{\"end\":47406,\"start\":47402},{\"end\":47759,\"start\":47755},{\"end\":47771,\"start\":47767},{\"end\":47783,\"start\":47778},{\"end\":47798,\"start\":47789},{\"end\":47800,\"start\":47799},{\"end\":47812,\"start\":47808},{\"end\":48267,\"start\":48264},{\"end\":48280,\"start\":48274},{\"end\":48296,\"start\":48288},{\"end\":48311,\"start\":48304},{\"end\":48321,\"start\":48317},{\"end\":48743,\"start\":48740},{\"end\":48753,\"start\":48750},{\"end\":48767,\"start\":48761},{\"end\":48782,\"start\":48775},{\"end\":48797,\"start\":48789},{\"end\":48809,\"start\":48802},{\"end\":49329,\"start\":49322},{\"end\":49339,\"start\":49335},{\"end\":49347,\"start\":49344},{\"end\":49362,\"start\":49355},{\"end\":49374,\"start\":49368},{\"end\":49385,\"start\":49382},{\"end\":49396,\"start\":49392}]", "bib_author_last_name": "[{\"end\":32320,\"start\":32312},{\"end\":32337,\"start\":32331},{\"end\":32348,\"start\":32346},{\"end\":32363,\"start\":32358},{\"end\":32374,\"start\":32370},{\"end\":32389,\"start\":32383},{\"end\":32406,\"start\":32397},{\"end\":32421,\"start\":32415},{\"end\":32885,\"start\":32879},{\"end\":32900,\"start\":32893},{\"end\":32916,\"start\":32910},{\"end\":32930,\"start\":32923},{\"end\":33254,\"start\":33248},{\"end\":33271,\"start\":33263},{\"end\":33287,\"start\":33280},{\"end\":33305,\"start\":33299},{\"end\":33531,\"start\":33525},{\"end\":33545,\"start\":33539},{\"end\":33560,\"start\":33555},{\"end\":33577,\"start\":33567},{\"end\":33592,\"start\":33586},{\"end\":33609,\"start\":33602},{\"end\":33940,\"start\":33919},{\"end\":33956,\"start\":33948},{\"end\":33963,\"start\":33958},{\"end\":34388,\"start\":34380},{\"end\":34401,\"start\":34399},{\"end\":34414,\"start\":34409},{\"end\":34428,\"start\":34423},{\"end\":34432,\"start\":34430},{\"end\":34859,\"start\":34855},{\"end\":34869,\"start\":34865},{\"end\":34883,\"start\":34880},{\"end\":34905,\"start\":34897},{\"end\":34920,\"start\":34915},{\"end\":34934,\"start\":34928},{\"end\":34954,\"start\":34947},{\"end\":35298,\"start\":35295},{\"end\":35320,\"start\":35305},{\"end\":35338,\"start\":35330},{\"end\":35353,\"start\":35347},{\"end\":35867,\"start\":35862},{\"end\":35885,\"start\":35875},{\"end\":35899,\"start\":35896},{\"end\":36270,\"start\":36264},{\"end\":36278,\"start\":36272},{\"end\":36489,\"start\":36483},{\"end\":36710,\"start\":36707},{\"end\":36719,\"start\":36717},{\"end\":36728,\"start\":36725},{\"end\":36742,\"start\":36737},{\"end\":36751,\"start\":36749},{\"end\":36761,\"start\":36757},{\"end\":37132,\"start\":37122},{\"end\":37152,\"start\":37141},{\"end\":37357,\"start\":37355},{\"end\":37368,\"start\":37364},{\"end\":37382,\"start\":37377},{\"end\":37395,\"start\":37392},{\"end\":37877,\"start\":37875},{\"end\":37892,\"start\":37886},{\"end\":37908,\"start\":37900},{\"end\":37922,\"start\":37919},{\"end\":37934,\"start\":37929},{\"end\":38408,\"start\":38406},{\"end\":38421,\"start\":38415},{\"end\":38434,\"start\":38431},{\"end\":38450,\"start\":38446},{\"end\":38463,\"start\":38457},{\"end\":38477,\"start\":38469},{\"end\":38932,\"start\":38929},{\"end\":38943,\"start\":38941},{\"end\":38956,\"start\":38954},{\"end\":38972,\"start\":38967},{\"end\":38987,\"start\":38984},{\"end\":39377,\"start\":39374},{\"end\":39388,\"start\":39384},{\"end\":39398,\"start\":39392},{\"end\":39414,\"start\":39408},{\"end\":39434,\"start\":39424},{\"end\":39450,\"start\":39443},{\"end\":39458,\"start\":39452},{\"end\":40011,\"start\":40008},{\"end\":40020,\"start\":40018},{\"end\":40032,\"start\":40029},{\"end\":40045,\"start\":40038},{\"end\":40055,\"start\":40052},{\"end\":40074,\"start\":40070},{\"end\":40083,\"start\":40076},{\"end\":40420,\"start\":40416},{\"end\":40430,\"start\":40426},{\"end\":40440,\"start\":40437},{\"end\":40449,\"start\":40446},{\"end\":40457,\"start\":40455},{\"end\":40812,\"start\":40805},{\"end\":40829,\"start\":40821},{\"end\":40843,\"start\":40837},{\"end\":41439,\"start\":41436},{\"end\":41452,\"start\":41448},{\"end\":41461,\"start\":41458},{\"end\":41468,\"start\":41466},{\"end\":41478,\"start\":41473},{\"end\":41487,\"start\":41484},{\"end\":41988,\"start\":41981},{\"end\":42001,\"start\":41995},{\"end\":42015,\"start\":42011},{\"end\":42031,\"start\":42025},{\"end\":42046,\"start\":42038},{\"end\":42058,\"start\":42056},{\"end\":42075,\"start\":42065},{\"end\":42452,\"start\":42444},{\"end\":42466,\"start\":42461},{\"end\":42487,\"start\":42482},{\"end\":42502,\"start\":42496},{\"end\":42996,\"start\":42992},{\"end\":43010,\"start\":43005},{\"end\":43024,\"start\":43020},{\"end\":43037,\"start\":43035},{\"end\":43050,\"start\":43047},{\"end\":43573,\"start\":43569},{\"end\":43588,\"start\":43581},{\"end\":43604,\"start\":43598},{\"end\":43619,\"start\":43615},{\"end\":43628,\"start\":43621},{\"end\":44047,\"start\":44027},{\"end\":44064,\"start\":44057},{\"end\":44071,\"start\":44066},{\"end\":44337,\"start\":44334},{\"end\":44350,\"start\":44346},{\"end\":44362,\"start\":44359},{\"end\":44378,\"start\":44373},{\"end\":44878,\"start\":44876},{\"end\":44891,\"start\":44889},{\"end\":44903,\"start\":44900},{\"end\":44919,\"start\":44914},{\"end\":45311,\"start\":45302},{\"end\":45326,\"start\":45319},{\"end\":45337,\"start\":45335},{\"end\":45669,\"start\":45666},{\"end\":45679,\"start\":45676},{\"end\":45693,\"start\":45689},{\"end\":45702,\"start\":45699},{\"end\":46129,\"start\":46122},{\"end\":46138,\"start\":46136},{\"end\":46399,\"start\":46395},{\"end\":46407,\"start\":46405},{\"end\":46414,\"start\":46412},{\"end\":46423,\"start\":46420},{\"end\":46436,\"start\":46431},{\"end\":46447,\"start\":46443},{\"end\":46460,\"start\":46458},{\"end\":46939,\"start\":46937},{\"end\":46954,\"start\":46951},{\"end\":46967,\"start\":46964},{\"end\":46975,\"start\":46972},{\"end\":47376,\"start\":47374},{\"end\":47390,\"start\":47385},{\"end\":47400,\"start\":47396},{\"end\":47409,\"start\":47407},{\"end\":47765,\"start\":47760},{\"end\":47776,\"start\":47772},{\"end\":47787,\"start\":47784},{\"end\":47806,\"start\":47801},{\"end\":47817,\"start\":47813},{\"end\":47824,\"start\":47819},{\"end\":48272,\"start\":48268},{\"end\":48286,\"start\":48281},{\"end\":48302,\"start\":48297},{\"end\":48315,\"start\":48312},{\"end\":48325,\"start\":48322},{\"end\":48748,\"start\":48744},{\"end\":48759,\"start\":48754},{\"end\":48773,\"start\":48768},{\"end\":48787,\"start\":48783},{\"end\":48800,\"start\":48798},{\"end\":48813,\"start\":48810},{\"end\":49333,\"start\":49330},{\"end\":49342,\"start\":49340},{\"end\":49353,\"start\":49348},{\"end\":49366,\"start\":49363},{\"end\":49380,\"start\":49375},{\"end\":49390,\"start\":49386},{\"end\":49399,\"start\":49397}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":14096841},\"end\":32797,\"start\":32253},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":1820089},\"end\":33200,\"start\":32799},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":221275765},\"end\":33515,\"start\":33202},{\"attributes\":{\"doi\":\"arXiv:1811.02549\",\"id\":\"b3\"},\"end\":33836,\"start\":33517},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":49568810},\"end\":34371,\"start\":33838},{\"attributes\":{\"doi\":\"arXiv:1702.07983\",\"id\":\"b5\"},\"end\":34782,\"start\":34373},{\"attributes\":{\"doi\":\"arXiv:1504.00325\",\"id\":\"b6\"},\"end\":35206,\"start\":34784},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":11336213},\"end\":35800,\"start\":35208},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":3655946},\"end\":36207,\"start\":35802},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":143544759},\"end\":36423,\"start\":36209},{\"attributes\":{\"doi\":\"arXiv:1308.0850\",\"id\":\"b10\"},\"end\":36626,\"start\":36425},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":3389583},\"end\":37091,\"start\":36628},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":1915014},\"end\":37281,\"start\":37093},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":51788338},\"end\":37794,\"start\":37283},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":7287895},\"end\":38345,\"start\":37796},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":98180},\"end\":38876,\"start\":38347},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":4857922},\"end\":39233,\"start\":38878},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":9197196},\"end\":39952,\"start\":39235},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":206771128},\"end\":40338,\"start\":39954},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":53737130},\"end\":40750,\"start\":40340},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":17048224},\"end\":41315,\"start\":40752},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":5165773},\"end\":41900,\"start\":41317},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":3631537},\"end\":42387,\"start\":41902},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":1929239},\"end\":42895,\"start\":42389},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":51608471},\"end\":43503,\"start\":42897},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":7147309},\"end\":43960,\"start\":43505},{\"attributes\":{\"doi\":\"arXiv:1806.04936\",\"id\":\"b26\"},\"end\":44259,\"start\":43962},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":46950555},\"end\":44790,\"start\":44261},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":3509921},\"end\":45243,\"start\":44792},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":7961699},\"end\":45568,\"start\":45245},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":11567842},\"end\":46083,\"start\":45570},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":12300158},\"end\":46348,\"start\":46085},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":9514751},\"end\":46816,\"start\":46350},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":53081554},\"end\":47298,\"start\":46818},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3439214},\"end\":47713,\"start\":47300},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":21140441},\"end\":48165,\"start\":47715},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":2024574},\"end\":48664,\"start\":48167},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":51608183},\"end\":49259,\"start\":48666},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":3636178},\"end\":49886,\"start\":49261}]", "bib_title": "[{\"end\":32302,\"start\":32253},{\"end\":32872,\"start\":32799},{\"end\":33239,\"start\":33202},{\"end\":33909,\"start\":33838},{\"end\":35283,\"start\":35208},{\"end\":35852,\"start\":35802},{\"end\":36260,\"start\":36209},{\"end\":36697,\"start\":36628},{\"end\":37115,\"start\":37093},{\"end\":37349,\"start\":37283},{\"end\":37867,\"start\":37796},{\"end\":38398,\"start\":38347},{\"end\":38921,\"start\":38878},{\"end\":39363,\"start\":39235},{\"end\":39999,\"start\":39954},{\"end\":40409,\"start\":40340},{\"end\":40797,\"start\":40752},{\"end\":41429,\"start\":41317},{\"end\":41970,\"start\":41902},{\"end\":42431,\"start\":42389},{\"end\":42985,\"start\":42897},{\"end\":43559,\"start\":43505},{\"end\":44327,\"start\":44261},{\"end\":44867,\"start\":44792},{\"end\":45295,\"start\":45245},{\"end\":45654,\"start\":45570},{\"end\":46114,\"start\":46085},{\"end\":46388,\"start\":46350},{\"end\":46926,\"start\":46818},{\"end\":47365,\"start\":47300},{\"end\":47753,\"start\":47715},{\"end\":48262,\"start\":48167},{\"end\":48738,\"start\":48666},{\"end\":49320,\"start\":49261}]", "bib_author": "[{\"end\":32322,\"start\":32304},{\"end\":32339,\"start\":32322},{\"end\":32350,\"start\":32339},{\"end\":32365,\"start\":32350},{\"end\":32376,\"start\":32365},{\"end\":32391,\"start\":32376},{\"end\":32408,\"start\":32391},{\"end\":32423,\"start\":32408},{\"end\":32887,\"start\":32874},{\"end\":32902,\"start\":32887},{\"end\":32918,\"start\":32902},{\"end\":32932,\"start\":32918},{\"end\":33256,\"start\":33241},{\"end\":33273,\"start\":33256},{\"end\":33289,\"start\":33273},{\"end\":33307,\"start\":33289},{\"end\":33533,\"start\":33517},{\"end\":33547,\"start\":33533},{\"end\":33562,\"start\":33547},{\"end\":33579,\"start\":33562},{\"end\":33594,\"start\":33579},{\"end\":33611,\"start\":33594},{\"end\":33942,\"start\":33911},{\"end\":33958,\"start\":33942},{\"end\":33965,\"start\":33958},{\"end\":34390,\"start\":34373},{\"end\":34403,\"start\":34390},{\"end\":34416,\"start\":34403},{\"end\":34430,\"start\":34416},{\"end\":34434,\"start\":34430},{\"end\":34861,\"start\":34848},{\"end\":34871,\"start\":34861},{\"end\":34885,\"start\":34871},{\"end\":34907,\"start\":34885},{\"end\":34922,\"start\":34907},{\"end\":34936,\"start\":34922},{\"end\":34956,\"start\":34936},{\"end\":35300,\"start\":35285},{\"end\":35322,\"start\":35300},{\"end\":35340,\"start\":35322},{\"end\":35355,\"start\":35340},{\"end\":35869,\"start\":35854},{\"end\":35887,\"start\":35869},{\"end\":35901,\"start\":35887},{\"end\":36272,\"start\":36262},{\"end\":36280,\"start\":36272},{\"end\":36491,\"start\":36478},{\"end\":36712,\"start\":36699},{\"end\":36721,\"start\":36712},{\"end\":36730,\"start\":36721},{\"end\":36744,\"start\":36730},{\"end\":36753,\"start\":36744},{\"end\":36763,\"start\":36753},{\"end\":37134,\"start\":37117},{\"end\":37154,\"start\":37134},{\"end\":37359,\"start\":37351},{\"end\":37370,\"start\":37359},{\"end\":37384,\"start\":37370},{\"end\":37397,\"start\":37384},{\"end\":37879,\"start\":37869},{\"end\":37894,\"start\":37879},{\"end\":37910,\"start\":37894},{\"end\":37924,\"start\":37910},{\"end\":37936,\"start\":37924},{\"end\":38410,\"start\":38400},{\"end\":38423,\"start\":38410},{\"end\":38436,\"start\":38423},{\"end\":38452,\"start\":38436},{\"end\":38465,\"start\":38452},{\"end\":38479,\"start\":38465},{\"end\":38934,\"start\":38923},{\"end\":38945,\"start\":38934},{\"end\":38958,\"start\":38945},{\"end\":38974,\"start\":38958},{\"end\":38989,\"start\":38974},{\"end\":39379,\"start\":39365},{\"end\":39390,\"start\":39379},{\"end\":39400,\"start\":39390},{\"end\":39416,\"start\":39400},{\"end\":39436,\"start\":39416},{\"end\":39452,\"start\":39436},{\"end\":39460,\"start\":39452},{\"end\":40013,\"start\":40001},{\"end\":40022,\"start\":40013},{\"end\":40034,\"start\":40022},{\"end\":40047,\"start\":40034},{\"end\":40057,\"start\":40047},{\"end\":40076,\"start\":40057},{\"end\":40085,\"start\":40076},{\"end\":40422,\"start\":40411},{\"end\":40432,\"start\":40422},{\"end\":40442,\"start\":40432},{\"end\":40451,\"start\":40442},{\"end\":40459,\"start\":40451},{\"end\":40814,\"start\":40799},{\"end\":40831,\"start\":40814},{\"end\":40845,\"start\":40831},{\"end\":41441,\"start\":41431},{\"end\":41454,\"start\":41441},{\"end\":41463,\"start\":41454},{\"end\":41470,\"start\":41463},{\"end\":41480,\"start\":41470},{\"end\":41489,\"start\":41480},{\"end\":41990,\"start\":41972},{\"end\":42003,\"start\":41990},{\"end\":42017,\"start\":42003},{\"end\":42033,\"start\":42017},{\"end\":42048,\"start\":42033},{\"end\":42060,\"start\":42048},{\"end\":42077,\"start\":42060},{\"end\":42454,\"start\":42433},{\"end\":42468,\"start\":42454},{\"end\":42489,\"start\":42468},{\"end\":42504,\"start\":42489},{\"end\":42998,\"start\":42987},{\"end\":43012,\"start\":42998},{\"end\":43026,\"start\":43012},{\"end\":43039,\"start\":43026},{\"end\":43052,\"start\":43039},{\"end\":43575,\"start\":43561},{\"end\":43590,\"start\":43575},{\"end\":43606,\"start\":43590},{\"end\":43621,\"start\":43606},{\"end\":43630,\"start\":43621},{\"end\":44049,\"start\":44018},{\"end\":44066,\"start\":44049},{\"end\":44073,\"start\":44066},{\"end\":44339,\"start\":44329},{\"end\":44352,\"start\":44339},{\"end\":44364,\"start\":44352},{\"end\":44380,\"start\":44364},{\"end\":44880,\"start\":44869},{\"end\":44893,\"start\":44880},{\"end\":44905,\"start\":44893},{\"end\":44921,\"start\":44905},{\"end\":45313,\"start\":45297},{\"end\":45328,\"start\":45313},{\"end\":45339,\"start\":45328},{\"end\":45671,\"start\":45656},{\"end\":45681,\"start\":45671},{\"end\":45695,\"start\":45681},{\"end\":45704,\"start\":45695},{\"end\":46131,\"start\":46116},{\"end\":46140,\"start\":46131},{\"end\":46401,\"start\":46390},{\"end\":46409,\"start\":46401},{\"end\":46416,\"start\":46409},{\"end\":46425,\"start\":46416},{\"end\":46438,\"start\":46425},{\"end\":46449,\"start\":46438},{\"end\":46462,\"start\":46449},{\"end\":46941,\"start\":46928},{\"end\":46956,\"start\":46941},{\"end\":46969,\"start\":46956},{\"end\":46977,\"start\":46969},{\"end\":47378,\"start\":47367},{\"end\":47392,\"start\":47378},{\"end\":47402,\"start\":47392},{\"end\":47411,\"start\":47402},{\"end\":47767,\"start\":47755},{\"end\":47778,\"start\":47767},{\"end\":47789,\"start\":47778},{\"end\":47808,\"start\":47789},{\"end\":47819,\"start\":47808},{\"end\":47826,\"start\":47819},{\"end\":48274,\"start\":48264},{\"end\":48288,\"start\":48274},{\"end\":48304,\"start\":48288},{\"end\":48317,\"start\":48304},{\"end\":48327,\"start\":48317},{\"end\":48750,\"start\":48740},{\"end\":48761,\"start\":48750},{\"end\":48775,\"start\":48761},{\"end\":48789,\"start\":48775},{\"end\":48802,\"start\":48789},{\"end\":48815,\"start\":48802},{\"end\":49335,\"start\":49322},{\"end\":49344,\"start\":49335},{\"end\":49355,\"start\":49344},{\"end\":49368,\"start\":49355},{\"end\":49382,\"start\":49368},{\"end\":49392,\"start\":49382},{\"end\":49401,\"start\":49392}]", "bib_venue": "[{\"end\":32490,\"start\":32423},{\"end\":32981,\"start\":32932},{\"end\":33343,\"start\":33307},{\"end\":33654,\"start\":33627},{\"end\":34052,\"start\":33965},{\"end\":34558,\"start\":34450},{\"end\":34846,\"start\":34784},{\"end\":35447,\"start\":35355},{\"end\":35968,\"start\":35901},{\"end\":36302,\"start\":36280},{\"end\":36476,\"start\":36425},{\"end\":36820,\"start\":36763},{\"end\":37172,\"start\":37154},{\"end\":37484,\"start\":37397},{\"end\":38054,\"start\":37936},{\"end\":38560,\"start\":38479},{\"end\":39038,\"start\":38989},{\"end\":39541,\"start\":39460},{\"end\":40128,\"start\":40085},{\"end\":40516,\"start\":40459},{\"end\":40940,\"start\":40845},{\"end\":41562,\"start\":41489},{\"end\":42126,\"start\":42077},{\"end\":42590,\"start\":42504},{\"end\":43143,\"start\":43052},{\"end\":43697,\"start\":43630},{\"end\":44016,\"start\":43962},{\"end\":44471,\"start\":44380},{\"end\":44978,\"start\":44921},{\"end\":45388,\"start\":45339},{\"end\":45779,\"start\":45704},{\"end\":46207,\"start\":46140},{\"end\":46536,\"start\":46462},{\"end\":47039,\"start\":46977},{\"end\":47468,\"start\":47411},{\"end\":47894,\"start\":47826},{\"end\":48384,\"start\":48327},{\"end\":48906,\"start\":48815},{\"end\":49508,\"start\":49401},{\"end\":32544,\"start\":32492},{\"end\":34126,\"start\":34054},{\"end\":35526,\"start\":35449},{\"end\":36022,\"start\":35970},{\"end\":36864,\"start\":36822},{\"end\":37558,\"start\":37486},{\"end\":38628,\"start\":38562},{\"end\":39609,\"start\":39543},{\"end\":40560,\"start\":40518},{\"end\":41022,\"start\":40942},{\"end\":41622,\"start\":41564},{\"end\":42663,\"start\":42592},{\"end\":43221,\"start\":43145},{\"end\":43751,\"start\":43699},{\"end\":44549,\"start\":44473},{\"end\":45022,\"start\":44980},{\"end\":45841,\"start\":45781},{\"end\":46597,\"start\":46538},{\"end\":47512,\"start\":47470},{\"end\":47949,\"start\":47896},{\"end\":48428,\"start\":48386},{\"end\":48984,\"start\":48908},{\"end\":49602,\"start\":49510}]"}}}, "year": 2023, "month": 12, "day": 17}