{"id": 219636253, "updated": "2023-10-06 14:48:08.142", "metadata": {"title": "Incorporating User Micro-behaviors and Item Knowledge into Multi-task Learning for Session-based Recommendation", "authors": "[{\"first\":\"Wenjing\",\"last\":\"Meng\",\"middle\":[]},{\"first\":\"Deqing\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Yanghua\",\"last\":\"Xiao\",\"middle\":[]}]", "venue": "SIGIR 2020", "journal": null, "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Session-based recommendation (SR) has become an important and popular component of various e-commerce platforms, which aims to predict the next interacted item based on a given session. Most of existing SR models only focus on exploiting the consecutive items in a session interacted by a certain user, to capture the transition pattern among the items. Although some of them have been proven effective, the following two insights are often neglected. First, a user's micro-behaviors, such as the manner in which the user locates an item, the activities that the user commits on an item (e.g., reading comments, adding to cart), offer fine-grained and deep understanding of the user's preference. Second, the item attributes, also known as item knowledge, provide side information to model the transition pattern among interacted items and alleviate the data sparsity problem. These insights motivate us to propose a novel SR model MKM-SR in this paper, which incorporates user Micro-behaviors and item Knowledge into Multi-task learning for Session-based Recommendation. Specifically, a given session is modeled on micro-behavior level in MKM-SR, i.e., with a sequence of item-operation pairs rather than a sequence of items, to capture the transition pattern in the session sufficiently. Furthermore, we propose a multi-task learning paradigm to involve learning knowledge embeddings which plays a role as an auxiliary task to promote the major task of SR. It enables our model to obtain better session representations, resulting in more precise SR recommendation results. The extensive evaluations on two benchmark datasets demonstrate MKM-SR's superiority over the state-of-the-art SR models, justifying the strategy of incorporating knowledge learning.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2006.06922", "mag": "3104492324", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigir/MengYX20", "doi": "10.1145/3397271.3401098"}}, "content": {"source": {"pdf_hash": "94dd90120eb6f376093d80b643bbb9d2cfa3bac1", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2006.06922v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2006.06922", "status": "GREEN"}}, "grobid": {"id": "7f4e41595dcaf926ebaf52649d62d9922b473ab0", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/94dd90120eb6f376093d80b643bbb9d2cfa3bac1.txt", "contents": "\nIncorporating User Micro-behaviors and Item Knowledge into Multi-task Learning for Session-based Recommendation\nVirtual Event, China. ACMCopyright Virtual Event, China. ACMJuly 25-30, 2020. July 25-30, 2020\n\nWenjing Meng wjmeng18@fudan.edu.cn \nDeqing Yang yangdeqing@fudan.edu.cn \nYanghua Xiao \n\nSchool of Data Science\nSchool of Computer Science\nFudan University\n200433ShanghaiChina\n\n\nFudan University\n200433ShanghaiChina\n\nIncorporating User Micro-behaviors and Item Knowledge into Multi-task Learning for Session-based Recommendation\n\nVirtual Event, China Conference on Research and Development in Information Retrieval (SIGIR '20)\nNew York, NY, USAVirtual Event, China. ACM10July 25-30, 2020. July 25-30, 202010.1145/3397271.3401098ACM Reference Format: Wenjing Meng, Deqing Yang and Yanghua Xiao. 2020. Incorporating User Micro-behaviors and Item Knowledge into Multi-task Learning for Session-based Recommendation. In Proceedings of the 43rd International ACM SIGIR * Corresponding author. ACM ISBN 978-1-4503-8016-4/20/07. . . $15.00session-based recommendationmicro-behaviormulti-task learn- ingknowledge\nSession-based recommendation (SR) has become an important and popular component of various e-commerce platforms, which aims to predict the next interacted item based on a given session. Most of existing SR models only focus on exploiting the consecutive items in a session interacted by a certain user, to capture the transition pattern among the items. Although some of them have been proven effective, the following two insights are often neglected. First, a user's micro-behaviors, such as the manner in which the user locates an item, the activities that the user commits on an item (e.g., reading comments, adding to cart), offer fine-grained and deep understanding of the user's preference. Second, the item attributes, also known as item knowledge, provide side information to model the transition pattern among interacted items and alleviate the data sparsity problem. These insights motivate us to propose a novel SR model MKM-SR in this paper, which incorporates user Micro-behaviors and item Knowledge into Multi-task learning for Session-based Recommendation. Specifically, a given session is modeled on microbehavior level in MKM-SR, i.e., with a sequence of item-operation pairs rather than a sequence of items, to capture the transition pattern in the session sufficiently. Furthermore, we propose a multitask learning paradigm to involve learning knowledge embeddings which plays a role as an auxiliary task to promote the major task of SR. It enables our model to obtain better session representations, resulting in more precise SR recommendation results. The extensive evaluations on two benchmark datasets demonstrate MKM-SR\u00e2\u0102\u0179s superiority over the state-of-the-art SR models, justifying the strategy of incorporating knowledge learning.\n\nINTRODUCTION\n\nRecommender systems have played a very important role in many web applications including web search, e-commerce, entertainment and so on. On many web sites, a user often exhibits a specific shortterm intention [10]. The natural characteristics of a session data reflect a user's behavior pattern and current preference precisely. Therefore, modeling a user's current intention based on his/her behaviors in a recent session often results in satisfactory recommendation results, which is the basic principle of session-based recommendation (SR for short) [33]. As a representative class of sequential recommendation, SR systems aim to predict an item that would be interacted by a target user in the next interaction, based on the recent behaviors committed by the user in a session.\n\nIn order to achieve precise recommendations, an SR model generally uses a certain algorithm to leverage the sequential information in a session. The existing algorithms include Markov-based models and deep neural network (DNN for short) based models. For example, the basic idea of FPMC [24] is to calculate transition probability between the items in a session based on Markov chain. In recent years, recurrent neural networks (RNNs for short) have been applied in different ways to learn a user's dynamic and time-shifted preference [6,12,17,20], exhibiting better performance than traditional methods. Although these deep SR models have been proven effective, there still exist some issues as follows.\n\nThe first issue is the lack of exploiting user micro-behaviors. Most of previous session-based models [6,12,17] only model a session from a macro perspective, i.e., regard a session as a sequence of items, without taking into account different operations of users. Even though a user interacts with the same item in a session, different operations committed on this item reflect the user's different intentions in this session and different preferences on this item. In this paper, we regard a user's specific operation on a certain item as a micro-behavior which has finer granularity and offers deeper understanding of the user than a macro-behavior of item-level, i.e., a user-item interaction. We use a toy example in Fig.1 which was extracted from a real music dataset, to illustrate the significance of incorporating micro-behaviors into SR's session modeling.\n\nIn Fig. 1, the user in session s 1 first searches song i 1 which is a hip-pop song sung by a certain American band Maroon 5. Then, he adds it into his playlist and favorites in turn. Next, he clicks button Artist More to get more Maroon 5's songs listed on a page, and then listens to song i 2 on the page. After adding i 2 into his favorites, he further listens to another Maroon 5's song i 3 Figure 1: A toy example of user micro-behaviors (depicted by red dashed rectangles) in two sessions (depicted by green dashed rectangles) from a music site. Different operations may be committed on the same item sequence which reflect different intensions and preferences of a user on a finegrained level. Therefore, modeling a session based on user micro-behaviors consisting of items and operations is helpful to achieve preciser SR.\n\npage. Song i 3 belongs to a genre different from hip-pop although it is also sung by Maroon 5. In session s 2 , the user also first searches song i 1 and then clicks button Genre More to get more hip-pop songs. Next, he also selects i 2 from the Genre More page. After adding i 2 into his favorites, he further listens to song i 4 which also belongs to hip-pop but was sung by the singer other than Maroon 5. Suppose that we already have the session information in the green dashed rectangles for the two sessions, we need to predict which item the user will interact with subsequently. According to traditional SR's paradigm of modeling a session only based on the historical item sequence, s 1 and s 2 are learned as the same representation since they both consist of song i 1 and i 2 . Thus the same item may be recommended as the next interaction, which is not consistent with the observations in Fig. 1. If we take user micro-behaviors which are depicted by red dashed rectangles rather than items to model the sessions, s 1 and s 2 have different representations. Based on such fine-grained session representations, i 3 will be recommended to the user in s 1 because the transition pattern between i 2 and i 3 (having the same singer) is the same as the one between i 1 and i 2 . Similarly, i 4 will be recommended to the user in s 2 . The second issue is the insufficient utilization of item knowledge towards the sparsity problem of user-item interactions. Since most of previous SR systems model a session only based on the interacted item sequence in the session, they can not learn session representations sufficiently when historical user-item interactions are sparse, especially for the cold-start items. Inspired by [37,38], we can also import item attributes as side information which are generally distilled from open knowledge graphs (KGs for short) and recognized as item knowledge in this paper, to alleviate the data sparsity problem. Furthermore, the item transitions in terms of micro-behavior can also be indicated by item knowledge. Recall the example in Fig. 1, transition i 2 Ar t ist Mor e \u2212 \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212 \u2192 i 3 is indicated by two knowledge triplets <i 1 , song-artist, Maroon 5> and <i 2 , song-artist, Maroon 5>. Therefore, incorporating item knowledge is helpful for micro-behavior based modeling. In this paper, we regard such latent relationships among the items in a session as semantic correlations.\n\nTo address above issues, we propose a novel SR model MKM-SR in this paper, which incorporates user Micro-behaviors and item Knowledge into Multi-task learning for Session-based Recommendation. In MKM-SR, a user's sequential pattern in a session is modeled on micro-behavior level rather than item-level. Specifically, a session is constituted by a sequence of user micro-behaviors. Each microbehavior is actually a combination of an item and its corresponding operation. As a result, learning item embeddings and operation embeddings is the premise of learning micro-behavior embeddings, based on which a session's representation is generated. For this goal, we feed the operation sequence and the item sequence of a session into Gated Recurrent Unit (GRU for short) [2] and Gated Graph Neural Network (GGNN for short) [14,35], respectively. In this step, we adopt different learning mechanisms due to the different characteristics of operations and items. What's more, we incorporate item knowledge to learn better item embeddings by TransH [34] which has been proven an effective KG embedding model on handling many-to-many/one relations. Unlike previous models using knowledge embeddings as pre-trained item embeddings [32,37,38], we take knowledge embedding learning as an auxiliary task and add it into a multi-task learning (MTL for short) paradigm in which the major task is to predict the next interacted item. Our extensive experiments verify that our MTL paradigm is more effective than previous pre-training paradigm in terms of promoting SR performance.\n\nIn summary, our contributions in this paper are as follows: 1. In order to improve SR performance, we incorporate user micro-behaviors into session modeling to capture the transition pattern between the successive items in a session on a fine-grained level, and further investigate the effects of different algorithms on modeling micro-behaviors.\n\n2. We incorporate item knowledge into our model through an MTL paradigm which takes knowledge embedding learning as an auxiliary (sub) task of SR. Furthermore, we validate an optimal training strategy for our MTL through extensive comparisons.\n\n3. We provide deep insights on the rationales of our model's design mechanisms and extensive evaluation results over two realistic datasets (KKBOX and JDATA), to justify our model's superiority over the state-of-the-art recommendation models.\n\nIn the rest of this paper, we introduce related work in Section 2 followed by the detailed description of our model in Section 3. We display our extensive experiment results in Section 4 and conclude our work in Section 5.\n\n\nRELATED WORK\n\nIn this section, we provide a brief overview of the research related to our work in this paper.\n\n\nSession-based and Sequential Recommendation\n\nAs a sub-task of sequential recommendation, the objective of SR is to predict the successive item(s) that an anonymous user likely to interact with, according to the implicit feedbacks in a session. In general, there are two major classes of approaches to leverage sequential information from users' historical records, i.e., Markovbased models and DNN-based models. In the first class, [9,28] use Markov chains to capture sequential patterns between consecutive user-item interactions. [15,26] try to characterize users' latest preferences with the last click, but neglect the previous clicks and discard the useful information in the long sequence. Rendel et.al proposed a hybrid model FPMC [22], which combines Matrix Factorization (MF for short) and Markov Chain (MC for short) to model sequential behaviors for next basket recommendation. A major problem of FPMC is that it still adopts the static representations for user intentions. Recently, inspired by the power of DNNs in modeling sequences in NLP, some DNN-based solutions have been developed and demonstrated state-of-the-art performance for SR. Particularly, the RNN-based models including LSTM and GRU, are widely used to capture users' general interests and current interests together through encoding historical interactions into a hidden state (vector). As the pioneers to employ RNNs for SR, Hidasi et al. [6] proposed a deep SR model which encodes items into one-hot embeddings and then feed them into GRUs to achieve recommendation. Afterwards, Jing et al. [12] further improved the RNN-based solution through adding extra mechanism to tackle the short memory problem inherent in RNNs. In addition, the model in [17] utilizes an attention net to model user's general states and current states separately. This model takes into account the effects of users' current actions on their next moves explicitly. Besides, Hidasi et al. proposed [7] and [5] to improve their model performance through adjust loss functions. More recently, the authors in [35] adopted GGNN to capture the complex transition pattern among the items in a session rather than the transition pattern of single way. Although these models show promising performance for SR tasks, there is still room for improvement since they all neglect user micro-behaviors in sessions. [4,16,30,41] are the rare models considering micro-behaviors. [30] only models monotonic behavior chains where user behaviors are supposed to follow the same chain, ignoring the multiple types of behaviors. To tackle this problem, [41] and [4] both adopt LSTM to model micro-behaviors. However, they ignored the different transition pattern between items and operations. In this paper, we adopt RNN and GNN simultaneously to model the micro-behaviors, which not only consider the differences of items and operations, but also keep the logic of operation order as mentioned in [4,30].\n\n\nKnowledge-based Recommendation\n\nKnowledge-based recommendation has already been recognized as an important family of recommender systems [1]. Traditionally, the knowledge includes various item attributes which are used as the constraints of filtering out a user's favorite items. As more open linked data emerge, many researchers use abundant knowledge in KGs as side information to improve the performance of recommender systems. In [39] a heterogeneous information network (HIN for short) is constructed based movie knowledge, and then the relatedness between movies is measured through the volume of meta-paths. The authors in [19] applied Node2Vec [3] to learn user/item representations according to different relations between entities in KGs, but it is still collaborative filtering (CF for short) based method resulting in poor performance when user-item interactions are sparse. In recent years, many researchers utilized DNNs to learn knowledge embeddings which are fed into the downstream recommendation models. For example, Wang et al. proposed a deep model DKN [32] for news recommendation, in which they also used a translation-based KG embedding model TransD [11] to learn knowledge embeddings to enrich news representations. The authors in [37,38] utilized Metapath2Vec [29] to learn knowledge embeddings which are used to generate the representations of users and items. Different with MKM-SR's multi-task learning solution, these models use knowledge embeddings as the pre-trained item embeddings. Another representative deep recommendation model incorporating knowledge is RippleNet [31] where user representations are learned through an iterative propagation among a KG including the entities of items and their attributes. KGs have also been employed for sequential recommendation. For example, [8] proposes a key-value memory network to incorporate movie attributes from KGs, in order to improve sequential movie recommendation. FDSA [40] is a feature-level sequential recommendation model with self-attentions, in which the item features can be regarded as the item knowledge used to enrich user representations. Unlike our model, these two KG-based sequential recommendation models model user behavior sequences on macro (item) level rather than micro level. What's more, our model incorporates item knowledge through an MTL paradigm which takes knowledge embedding learning as an auxiliary (sub) task of SR, guaranteeing the information is shared among user micro-behaviors and item attributes, thus representations are learned better.\n\n\nMETHODOLOGY\n\nIn this section, we introduce the details of MKM-SR including the related algorithms involved in the model. We first formalize the problem addressed in this paper, and then summarize the pipeline of MKM-SR followed by the detailed descriptions of each step (component). In the following introductions, we use a bold lowercase to represent a vector and a bold uppercase to represent a set, matrix or a cube (tensor).\n\n\nProblem Definition\n\nIn this paper, since we focus on user micro-behaviors rather than interacted items in sessions in this paper, we first use {m 1 , m 2 , ..., m L } to denote the micro-behavior sequence in a session s where L is the length of the sequence. Specifically, m t (1 \u2264 t \u2264 L) is the t-th micro-behavior which is actually a combination of an item and its corresponding operation. Furthermore, the item knowledge we incorporate into MKM-SR is represented by the form of triplet. Formally, a knowledge triplet < i, r , a > represents that a is the value of item i's attribute r which is often recognized as a relation. For example, <Sugar, song-artist, Maroon 5> describes that Maroon 5 is the singer of song Sugar. MKM-SR is trained with the observed user micro-behaviors in sessions and obtained item knowledge. The goal of our SR model is to predict the next interacted item based on a given session. To achieve this goal, our model is fed with the given session s and a (next interacted) candidate item j to generate a matching score (probability)\u0177 s j between s and j. Wit\u0125 y s j , a top-k ranking list can be generated for a given session (one sample). In general, the item with the highest score will be predicted as the next interacted item.  At first, an item sequence and an operation sequence are extracted from a given session simultaneously, and then fed into GGNN and GRU to learn item embeddings and operation embeddings, respectively. These two types of embeddings assemble a sequence of micro-behavior embeddings which are used to generate the session's representation s. The final score\u0177 s j is computed by an MLP followed by softmax operation. Furthermore, the knowledge embeddings learned by TransH are incorporated into a multi-task learning loss function to learn better item embeddings resulting in superior SR.\nTransH ! \" ! # $# %& ! \" # , \" % , \u2026 , \" ' e.g., ( , ) , 0 , 1 , 0 ( 3 ( 3 ( 3 ) 3 ) 3( 3 )\n\nModel Overview\n\nThe framework of MKM-SR is illustrated in Fig. 2. In model training, besides the operations and items involved in training samples, item knowledge is also input into MKM-SR to learn better operation embeddings and item embeddings, then better session representations are also obtained which are crucial to compute precise scores.\n\nFor more clear explanation, we reversely introduce the pipeline of MKM-SR from the right side of Fig. 2. For a given session s and a candidate item j, the final score\u0177 s j is computed by a multilayer perceptron (MLP for short) fed with s's representation and j's embedding which are both a vector of d dimensions. Specifically, s's representation s is obtained by aggregating a group of micro-behavior embeddings. Given that different objects in a session (sequence) have different levels of priority on representing this session, we adopt a soft-attention mechanism [36] to generate s's global representation which reflects a user's long-term preference. Furthermore, a micro-behavior embedding is the concatenation of of its item embedding (green rectangles in Fig. 2) and operation embedding (red rectangles in Fig. 2) since we believe an operation and an item have different roles to represent a user's microbehavior. The item embedding and the operation embedding in a micro-behavior embedding are learned respectively by different models, i.e., GGNN and GRU. The reason of such manipulations will be explained subsequently. The GGNN and the GRU in MKM-SR are fed with an item sequence and an operation sequence respectively, both of which have the same length as the micro-behavior sequence, i.e., L.\n\nAs we mentioned before, the item knowledge is helpful to discover the semantic correlations between the items in a session. As a result, we add knowledge learning as an auxiliary task into an MTL paradigm through designing a weighted sum of different loss functions. Specifically, we import TransH's [34] loss function as the loss of our knowledge learning, since it is a KG embedding model which can model many-to-many/one relations effectively. In addition, we adopt alternating training [21] strategy for training MKM-SR.\n\n\nEncoding Session Information\n\nIn this subsection, we introduce how to obtain the representation of a given session which is crucial for our model to compute the final score\u0177. Based on the basic principle of SR [6,12], the premise of obtaining a session representation is to learn each object's embedding in the session. In the setting of this paper, an object in the sequence of a session is a micro-behavior. According to our definition of micro-behavior, a micro-behavior is the combination of an item and an operation committed on the item. In MKM-SR, we first learn item embeddings and operation embeddings separately, and then concatenate an item embedding and an operation embedding as the embedding of the micro-behavior, rather than directly learn a micro-behavior embedding as whole. Our experiment results shown in the subsequent section verify that our solution is better than the latter. We adopt such solution due to the following intuitions.\n\n\nIntuitions of Embedding Learning.\n\nWe argue that item sequences and operation sequences have different effects on session modeling, and exhibit different transition patterns. For the item sequence of a session, its transition pattern is actually more complex than the single way transitions between successive items which were captured by previous RNN-based sequential models [6,12,20]. In other words, not only the subsequent items are correlated to the preceding ones in a sequence, but also the preceding items are correlated to the subsequent ones. It is also the reason that a user often interacted with an item that he/she has already interacted with before. Obviously, such transition pattern relies on the bidirectional contexts (preceding items and subsequent items) rather than the unidirectional contexts, which can be modeled by a graphbased model rather than a sequential model of single way such as GRU. Consequently, inspired by [35] we adopt GGNN to model item sequences to obtain item embeddings in MKM-SR.\n\nAlthough the operations committed by a user in a session also assemble a sequence, their transition pattern is different with the one of item sequences. Therefore, GGNN is not appropriate to model operation sequences due to the following reasons. First, the unique types of operations are very limited in most platforms. One operation may recur in a sequence with big probability, resulting in that most nodes (operations) have similar neighbor groups if we convert operation sequences into a directed graph. Thus, most operation embeddings learned through applying GGNN over such a graph are very similar, which can not well characterize the diversity of a user's preference. On the other hand, the transitions between two successive operations often demonstrate a certain of sequential pattern. For example, a user often adds a product to cart after he/she reads its comments, or purchases the product after he/she adds it to cart. Therefore, we adopt GRU rather than GGNN to learn operation embeddings. Next, we introduce the details of learning item embeddings and operation embeddings in turn.\n\n\nLearning Item Embeddings.\n\nIn order to learn item embeddings by GGNN, we should convert an item sequence into a directed graph at first.\n\nFormally, given a micro-level item sequence S i = {i t 1 , i t 2 , ..., i t L } in a session in which each object is the item in a micro-behavior, the corresponding directed graph is G = (V, E). In G, each node represents a unique item in S i , and each directed edge (i t k \u22121 , i t k ) \u2208 E(2 \u2264 k \u2264 L) links two successive items in S i . Please note that an item often recurs in a session. For example, the item sequence of session s 1 in Fig. 1 is {i 1 , i 1 \n, i 1 , i 2 , i 2 }. As a result, |V | \u2264 L and self-loops exist in G if i t k \u2212m = i t k , (1 \u2264 m \u2264 k \u2212 1).\nTo better model G, we further construct it as a weighted directed graph. The normalized weight of edge (i t k \u22121 , i t k ) is calculated as the occurrence frequency of {i t k \u22121 , i t k } in S i divided by the frequency that item i t k \u22121 occurs as a preceding item in S i .\n\nIn the initial step of GGNN, for a given item node v in G, its initial embedding i 0 v \u2208 R d is obtained by the lookup of item embedding matrix, and used as its initial hidden state h 0 v . Based on the basic principle of iterative propagation in GNN [27], we use the hidden state in the h-th (1 \u2264 h \u2264 H ) step as v's item embedding after h steps, i.e., i h v = h h v . Since G is a weighted directed graph, we use A + \u2208 R | V |\u00d7 | V | and A \u2212 \u2208 R | V |\u00d7 | V | to denote G's incoming adjacency matrix and outgoing adjacency matrix, respectively. The entries of these two adjacency matrices are edge weights indicating the extent to which the nodes in G communicate with each other.\n\nThen, h h v 's is computed according to the following update functions,\na h v = (A + v: + A \u2212 v: )[h h\u22121 1 , h h\u22121 2 , ..., h h\u22121 |V | ] \u22a4 + b z h v = \u03c3 (W az a h v + W hz h h\u22121 v ) r h v = \u03c3 (W ar a h v + W hr h h\u22121 v ) c h v = tanh W ac a h v + W hc (r h v \u2299 h h\u22121 v ) h h v = (1 \u2212 z h v ) \u2299 h h\u22121 v + z h v \u2299 c h v(1)\nwhere all bold lowercases are the vectors of d dimensions and all Ws are d \u00d7 d matrices. \u03c3 is Sigmoid function and \u2299 is element-wise multiplication. In addition, r h v and z h v are reset gate and update gate respectively. As described in Eq. 1, the hidden state in the h-th step for item v, i.e., h h v , is calculated based on its previous state h h\u22121 v and the candidate state c h v . After H steps, we can get the learned embeddings of all item nodes in G, based on which the item embeddings in S i are obtained as\nI = [i t 1 , i t 2 ..., i t L ] \u22a4 = [h H t 1 , h H t 2 ..., h H t L ] \u22a4 \u2208 R L\u00d7d(2)\nAccording to G's construction, given a session, an item has only one learned embedding no matter whether it recurs in the sequence. Consequently, I may have recurrent item embeddings. If an item occurs in multiple sessions, they may have different learned embeddings since different sessions correspond to different Gs.\n\n\nLearning Operation Embeddings.\n\nDue to the aforementioned reasons, we adopt a GRU [2] fed with operation sequences to learn operation embeddings. GRU is an improved version of standard RNN to model dynamic temporal behaviors, which aims to solve the vanishing gradient problem.\n\nFormally, we use S o = {o t 1 , o t 2 , ..., o t L } to denote an operation sequence fed into our GRU. For an operation o t k (1 \u2264 k \u2264 L) in S o , its initial embedding o 0 t k is also obtained by the lookup in operation embedding matrix. Then, its learned embedding o t k is the hidden state (vector) in the k-th step output by GRU, which is calculated based on o 0 t k and the hidden state in the (k-1)-th step as follows,\no t k = h t k = GRU (h t k \u22121 , o 0 t k ; \u03a6 GRU )(3)\nwhere GRU (\u00b7) represents the calculation in one GRU unit, and \u03a6 GRU denotes all GRU parameters. In fact, h t k \u22121 is o t k \u22121 's learned embedding. To calculate h t 1 , we set h t 0 = o 0 t 1 . Thus, we obtain the learned embeddings of all operations in S o as\nO = [o t 1 , o t 2 , ..., o t L ] \u22a4 \u2208 R L\u00d7d(4)\nPlease note that an operation may also recur as an item in the sequence. According to GRU's principle, an operation recurring in an operation sequence has multiple different embeddings. For example, the operation sequence of s 1 in Fig. 1 is {o 1 , o 2 , o 3 , o 4 , o 3 }. o 3 's learned embedding in the third position is different to its learned embedding in the fifth position in the sequence. As a result, O has no recurrent embeddings, which is different to I.\n\nThen, we concatenate O and I to obtain the embeddings of the L micro-behaviors in the given session as shown in Fig. 2\n\n\n. So we have\nM = [m 1 , m 2 , ..., m L ] \u22a4 = [i t 1 \u2295o t 1 , i t 2 \u2295o t 2 , ..., i t L \u2295o t L ] \u22a4 \u2208 R L\u00d72d(5)\nwhere \u2295 is concatenation operation. Based on such micro-behavior embeddings, two sessions having the same item sequence but different operation sequences still have different representations which can capture users' fine-grainded intentions.\n\n\nGenerating Session Representations.\n\nTo obtain a session representation, we should aggregate the embeddings of all microbehaviors in this session. Inspired by [35], we take into account a session's local preference and global preference. A session's local preference is directly represented by the embedding of the most recent micro-behavior, i.e., m L . For representing a session's global preference, we use soft-attention mechanism [36] to assign proper weight for each micro-behavior's embedding in the session since different micro-behaviors have different levels of priority. Specifically, given a micro-behavior m t (1 \u2264 t \u2264 L), its attention weight is computed as\n\u03b1 t = \u03b2 \u22a4 \u03c3 (W 1 m L + W 2 m t + b \u03b1 )(6)\nwhere b \u03b1 , \u03b2 \u2208 R 2d and W 1 , W 2 \u2208 R 2d \u00d72d . Then, the global representation of the session is\ns \u0434 = L t =1 \u03b1 i m t(7)\nAt last, the session's final representation is\ns = W 3 [m L ; s \u0434 ] \u2208 R d(8)\nwhere W 3 \u2208 R d \u00d74d .\n\nAfter obtaining the representation of session s, we compute the final score\u0177 s j through an MLP fed with s and the candidate item's embedding i j , followed by a Softmax operation. Thus we hav\u00ea\ny s j = so f tmax MLP(s \u2295 i j )(9)\nTo train MKM-SR, we first collect sufficient training samples denoted as < s, j, y s j > where y s j = 1 if item j is the next interacted item of the user following session s, otherwise y s j = 0. Then we adopt binary cross-entropy as the loss function of SR task as follows,\nL S = \u2212 s \u2208S j \u2208I y s j log(\u0177 s j ) + (1 \u2212 y s j ) log(1 \u2212\u0177 s j )(10)\nwhere S and I are the session set and item set in training samples.\n\n\nLearning Knowledge Embeddings\n\nRecall the toy example of Fig. 1, song i 3 and i 4 are the next interacted item of session s 1 and s 2 respectively. In fact, they are both semantically correlated to the previous items i 1 and i 2 in terms of shared knowledge (the same singer or genre). As a result, the item embeddings learned based on such shared knowledge are often in consonance with interaction sequences, which are regarded as knowledge embeddings in this paper. Such observations inspire us to use knowledge embeddings to enhance SR performance. In this subsection, we introduce how to learn knowledge embeddings given observed item knowledge. In a KG containing items, many-to-one and many-to-many relations are often observed. For example, many songs are sung by a singer, a movie may belong to several genres and a movie genre includes many movies. Among the state-of-the-art KG embedding models, transH [34] imports hyperplanes to handle manyto-many/one relations effectively. Therefore, we import the training loss of TransH to learn knowledge embeddings in our model.\n\nSpecifically, for each attribute relation r , we first position a relation-specific translation vector d r in the relation-specific hyperplane w r . Given a triplet < i, r, a >, item i's embedding i and attribute a's embedding a are first projected to the hyperplane with w r as the normal vectors. The projections are denoted as i \u22a5 and a \u22a5 . We expect that i \u22a5 and a \u22a5 can be connected by a translation vector d r on the hyperplane with a low error if < i, r , a > is correct. Thus the score function \u2225i \u22a5 + d r \u2212 a \u22a5 \u2225 2 2 is used to measure the plausibility that the triplet is incorrect. We can use w r and i to represent i \u22a5 as follows since \u2225w r \u2225 2 = 1.\ni \u22a5 = i \u2212 w \u22a4 r iw r(11)\nTherefore, the loss function for knowledge embedding learning is\nL K = <i,r,a > \u2208K \u2225(i \u2212 w \u22a4 r iw r ) + d r \u2212 (a \u2212 w \u22a4 r aw r )\u2225 2 2 (12)\nwhere K is the set of all knowledge triplets.\n\n\nThe Objective of Multi-task Learning\n\nMany previous recommendation models based on knowledge [32,37,38] generally learn knowledge embeddings in advance which are used as pre-trained item embeddings. In other words, L K is used to pre-train item embedding i in advance of using L S to fine-tune i. In such scenario, knowledge embedding learning and recommendation are two separate learning tasks. In general, incorporating two learning tasks into an MTL paradigm is more effective than achieving their respective goals separately, if the two tasks are related to each other. In MTL, the learning results of one task can be used as the hints to guide another task to learn better [25]. Inspired by the observations on the example in Fig. 1, learning knowledge embeddings can be regarded as an auxiliary task to predict the features (item embeddings) which are used for SR's prediction task. Consequently, in MKM-SR we import knowledge embedding learning as an auxiliary task into an MTL paradigm, to assist SR task.\n\nIn our scenario, the MTL's objective is to maximize the following posterior probability of our model's parameters \u03a6 given knowledge triplet set K and SR's training set Y. According to Bayes rule, this objective is\nmax p(\u03a6|K, Y) = max p(\u03a6, K, Y) p(K, Y) = max p(\u03a6)p(K |\u03a6)p(Y|\u03a6, K)(13)\nwhere p(\u03a6) is \u03a6's prior probability which is set to follow a Gaussian distribution of zero mean and 0.1 standard deviation. p(K |\u03a6) is the likelihood of observing K given \u03a6, and p(Y|\u03a6, K) is the likelihood of observing Y given K and \u03a6, which is defined as the product of Bernoulli distributions. Then, the comprehensive loss function of our MTL's objective is\nL = L S + \u03bb 1 L K + \u03bb 2 \u2225\u03a6\u2225 2 2 (14)\nwhere \u2225\u03a6\u2225 2 2 is the regularization term to prevent over-fitting, and \u03bb 1 , \u03bb 2 are control parameters. We obtain the values of \u03bb 1 and \u03bb 2 through tuning experiments.\n\nDuring the optimization of loss L, there are two training strategies of MTL, alternating training and joint training [21]. For alternating training, we have\nL al t er = \u2212 s \u2208S j \u2208I y s j log(\u0177 s j ) + (1 \u2212 y s j ) log(1 \u2212\u0177 s j ) + \u03bb 1 <i,r,a > \u2208K \u2225(i \u2212 w \u22a4 r iw r ) + d r \u2212 (a \u2212 w \u22a4 r aw r )\u2225 2 2 + \u03bb 2 \u2225\u03a6\u2225 2 2(15)\nwhere S and I represent the set of sessions and candidate items in the training set Y, respectively. For joint learning, we have\nL joint = s \u2208S \u2212 j \u2208I y s j log(\u0177 s j ) + (1 \u2212 y s j ) log(1 \u2212\u0177 s j ) + \u03bb 1 <i,r,a > \u2208K\u2227i \u2208s \u2225(i \u2212 w \u22a4 r iw r ) + d r \u2212 (a \u2212 w \u22a4 r aw r )\u2225 2 2 + \u03bb 2 \u2225\u03a6\u2225 2 2(16)\nThrough empirical comparisons, we have verified that alternating training is a better strategy for MKM-SR.\n\n\nEXPERIMENTS\n\nIn this section, we try to answer the following research questions (RQs for short) through extensive experiments.\n\nRQ1: Can our model MKM-SR outperform the state-of-the-art SR models?\n\nRQ2: Is it useful to incorporate micro-behaviors and knowledge into our model?\n\nRQ3: Is it rational to obtain a session's representation through learning item embeddings by GGNN and learning operation embeddings by GRU separately?\n\nRQ4: Which training strategy is better for incorporating knowledge learning into MKM-SR?\n\n\nExperiment Settings\n\n\nDatasets.\n\nWe evaluate all compared models on the following realistic datasets: KKBOX 1 : This dataset was provided by a famous music service KKBOX, which contains many users' historical records of listening to music in a given period. We take the 'source system tab' as user operations, such as 'tab my library' (manipulation on local storage) and 'tab search'. The music attributes used in our experiments include artist (singer), genre, language and release year. JDATA 2 : This dataset was extracted from JD.com which is a famous Chinese e-commerce website. It contains a stream of user actions on JD.com within two months. The operation types include clicking, ordering, commenting, adding to cart and favorite. The product attributes used in our experiments include brand, shop, category and launch year.\n\nFor both of the two datasets, we considered four item attributes (relations) as knowledge which were incorporated in our model. As in [6,35], we set the duration time threshold of sessions in JDATA to one hour, and set the index gap of sessions in KKBOX to 2000 (according to statistic analysis), to divide different sessions. We also filtered out the sessions of length 1 and the items that appear less than 3 times in the datasets. For both datasets, we took the earlier 90% user behaviors as the training set, and took the subsequent (recent) 10% user behaviors as the test set. In model prediction, given a test session the models first computed the matching scores of all items and then generated a top-k list according to the scores.\n\nIn order to demonstrate the effectiveness of incorporating item knowledge to alleviate the problem of cold-start items, we added two additional manipulations on our datasets unlike the previous SR evaluations. The first is to retain the items that only appear in the test set, i.e., the cold-start items. The second is to simulate a sparse JDATA dataset, denoted as Demo, through only retaining the early 1% user behaviors. Such sparse dataset has a bigger proportion of cold-start items. In the previous SR models such as [17,35,41], these cold-start items' embeddings are initialized in random, and can not be tuned during model training since they are not involved in any training sample. Thus, the recommendations about these items are often unsatisfactory.\n\nThe statistics of our datasets are shown in Table .1, where '(N)' indicates the datasets having some cold-start items, and 'new%' is the proportion of the behaviors involving cold-start items to all behaviors in the test set. We have taken into account all operation types provided by the two datasets. To reproduce our experiment results conveniently, our experiment samples and MKM-SR's source codes have been published on https://github.com/ciecus/MKM-SR. : It is a sequential prediction method based on personalized Markov chain which is often used as SR baseline.\n\nGRU4REC+BPR/CE [5]: These two baselines are the improved versions of GRU4REC [6] which is a state-of-the-art SR model. GRU4REC+BPR uses Bayes personalized ranking [23] as loss function, and GRU4REC+CE uses cross-entropy as loss function.\n\nNARM [12]: It is a GRU-based SR model with an attention to consider the long-term dependency of user preferences.\n\nSTAMP [17]: This SR model considers both current interests and general interests of users. In particular, STAMP uses an additional neural network to model current interests.\n\nSR-GNN [35]: It also utilizes GGNN to capture the complex transition patterns among the items in a session, but does not incorporate micro-behaviors and knowledge.\n\nRIB [41]: It also incorporates user operations of which the embeddings are learned by Word2Vec [18], and adopts GRU to model the sequence of user micro-behaviors.\n\nIn addition, to justify the necessity and validity of incorporating micro-behaviors and knowledge in our model, we further propose some variants of MKM-SR to be compared as follows.\n\nKM-SR: It removes all modules related to operations and the rest components are the same as MKM-SR. We compared MKM-SR with KM-SR to verify the significance of incorporating micro-behaviors.\n\nM-SR: It removes the auxiliary task of learning knowledge embeddings, i.e., L K in Eq. 14, and the rest components are the same as MKM-SR. All of the following variants remove the task of learning knowledge embeddings, between which the differences are the manipulations on session modeling.\n\nM(GRU/GGNN)-SR: Unlike MKM-SR, these two variants directly learn micro-behavior embeddings (m t ). The only difference between them is, M(GRU)-SR feeds micro-behavior sequences to GRU and M(GGNN)-SR feeds micro-behavior sequences to GGNN.\n\nM(GGNNx2)-SR It uses two GGNNs to learn operation embeddings and item embeddings respectively.\n\n\nEvaluation Metrics.\n\nWe use the following metrics to evaluate all models' performance which have been widely used in previous SR evaluations.\n\nHit@k: It is the proportion of hit samples to all samples that have the correct next interacted item in the top-k ranking lists.\n\nMRR@k: The average reciprocal rank of the correct next interacted item in the top-k ranking list. The reciprocal rank is set to zero if the correct item is ranked behind top-k.\n\n\nHyper-parameter Setup.\n\nFor fair comparisons, we adopted the same dimension of operation and item embeddings for MKM-SR and all baselines. Due to space limitation, we only display the results of 100-dim embeddings. The consistent conclusions were drawn based on the experiment results of the embeddings of other dimensions. In addition, all embeddings were initialized by a Gaussian distribution with a mean of 0 and a standard deviation of 0.1.\n\nWe set GGNN's step number H to 1. MKM-SR was learned by alternating training rather than joint training, of which the reason will be verified in the following experiments. In addition, we used Adam [13] optimizer with learning rate 0.001 and batch size 128. For the baselines, we used their default hyper-parameter settings in their papers except for embedding dimension. About the control parameters in Eq. 14, we set \u03bb 1 in Eq. 14 to 0.0001 for each dataset, which was decided through our tuning experiments. For L2 penalty \u03bb 2 , we set it to 10 \u22125 as previous SR models [33].\n\nNext, we display the results of our evaluations to answer the aforementioned RQs, based on which we provide some insights on the reasons causing the superiority or inferiority of compared models .\n\n\nGlobal Performance Comparisons\n\nAt first, we compared all models' SR performance over different datasets to answer RQ1, of which the Hit@20 and MRR@20 scores (percentage value) are listed in Table 2. The displayed scores are the average of five runnings for each model.\n\nThe comparison results show that, MKM-SR outperforms all baselines and variants in all dataset (answer yes to RQ1). Especially in the datasets with cold-start items and Demo, MKM-SR and KM-SR have more remarkable superiority. Such results justify the effects of incorporating knowledge to alleviate the sparsity problem of cold-start items (answer yes to RQ2). As shown in Table 1, KKBOX has more unique operations than JDATA which are useful to better capture user preferences on fine-grained level. Therefore, besides MKM-SR and M-SR, another model incorporating user operations RIB also has more remarkable advantage in KKBOX than in JDATA, compared with the GRU-based baselines that do not incorporate operations. These results justify the effects of incorporating microbehaviors (answer yes to RQ2).\n\nIn addition, a user is more likely to interact with the same item in a session of JDATA. The transition pattern between the successive items in such scenario can be captured by GGNN better than GRU. It is the reason that SR-GNN has greater advantage in JDATA than in KKBOX, compared with the GRU-based models including GRU4REC+BPR/CE and NARM.\n\n\nAblation Study\n\nWe further compared MKM-SR with its variants to answer RQ2, RQ3. We have the following conclusions drawn based on the results in Table 2. MKM-SR's advantage over KM-SR and M-SR shows that, both micro-behaviors (operations) and item knowledge deserve to be incorporated w.r.t. improve SR performance (answer yes to RQ2). In addition, M-SR outperforms M(GRU)-SR and M(GGNN)-SR indicating that modeling a session through learning item embeddings and learning operation embeddings separately is more effective than learning micro-behavior embeddings directly. As we stated before, the transition pattern of item sequences is different to that of operation sequence. Therefore, it is less effective to combine an item with an operation as a micro-behavior and then learn the micro-behavior sequence only by a certain model. Furthermore, M-SR's superiority over M(GGNNx2)-SR shows that operation sequences should be learned by GRU rather than GGNN, of which the reason has been explained in Subsec. 3.3. These results provide yes answer to RQ3.\n\n\nStrategies of Incorporating Knowledge Learning\n\nAs we mentioned before, there are two training strategies for our MTL loss Eq. 14, i.e., alternating training (Eq. 15) and joint training (Eq. 16). To answer RQ4, we trained KM-SR respectively with the two training strategies and compared their learning curves. Furthermore, we added a pre-training variant to be compared, in which the item embeddings are first pre-trained by TransH and then input into KM-SR to be tuned only by loss L S in Eq. 10. We did not adopt MKM-SR in this comparison experiment because the three training strategies are not relevant to operation embedding learning.  Figure 3: The learning curves of three different strategies to incorporate knowledge learning show that, incorporating knowledge learning into the MTL of alternating training is the best strategy for our SR task.\n\nIn Fig. 3, we only display the learning curves of MRR@20 in KKBOX(N) and JDATA(N) since MRR@k reflects ranking performance better than Hit@k. The curves in the figure show that, although the pre-training model has a better learning start, it is overtaken by the other two rivals on the stage of convergence. Such results demonstrate MTL's superiority over the knowledge-based pre-training. According to Eq. 16, the items often occurring in the sessions of training set will be tuned multiple times by loss L K in each epoch of joint training. It makes the learned embeddings bias to the auxiliary task L K too much, shrinking the learning effect of the main task L S . Therefore, alternating training is better than joint training in our SR scenario.  To further verify the significance of incorporating knowledge learning into the MTL paradigm (Eq. 14), we visualize the embedding distributions of some items sampled from KKBOX(N), which were learned respectively by different mechanisms in Fig. 4 where the points of different colors represent the songs of different genres. In Fig. 4(a), the item embeddings were learned by feeding item sequences of sessions into Word2Vec, thus two items are close in the space if they often cooccur in some sessions. As shown in the sub-figure, such learned embeddings make many songs of different genres too converged and thus can not discriminate different genres. In Fig. 4(b), the item embeddings were learned solely by TransH. Although such learned embeddings discriminate different genres obviously, the gap between two groups of different genres is too big. It makes the model based on embedding distances hard to predict the item of different genre as the next interacted item, which does not conform to some facts, such as the song i 3 in s 1 's item sequence shown in Fig. 1. It is also the reason why the pre-training model is defeated by the joint-training model and alter-training model in Fig. 3. The item embeddings shown in Fig. 4(c) were learned by MKM-SR through MTL, and exhibit two characteristics, i.e., they can discriminate different genres for most items, meanwhile keep close distances across different genres. Such item embeddings with the two characteristics well indicate two kinds of correlations between the successive items in a session. The former characteristic indicates the semantic correlations among items, and the latter characteristic indicate the items' co-occurrence correlations across different sessions. In fact, these two correlations can be captured respectively through the learning task of L K and the learning task of L S . Obviously, it is useful for improving SR to capture these two correlations simultaneously.\n\n\nMTL's Control Parameter Tuning\n\nAt last, we investigate the influence of \u03bb 1 's in the MLT's loss L to MKM-SR's final recommendation performance. Fig. 5 shows MKM-SR's MRR@20 scores in KKBOX(N), from which we find that MKM-SR's performance varies marginally (\u223c1%) when \u03bb 1 is set in [0.00001, 0.1]. What's more, MKM-SR gains the best score when \u03bb 1 = 0.0001. It implies that, as an auxiliary task knowledge embedding learning will disturb the main task of SR if it is assigned with more weight. \n\n\nCONCLUSION\n\nIn this paper, we propose a novel session-based recommendation (SR) model, namely MKM-SR, which incorporates user micro-behaviors and item knowledge simultaneously. According to the different intuitions about item sequences and operation sequences in a session, we adopt different mechanisms to learn item embeddings and operation embeddings which are used to generate fine-grained session representations. We also investigate the significance of learning knowledge embeddings and the influences of different training strategies through sufficient comparison studies. MKM-SR's superiority over the state-of-the-art SR models is justified by our extensive experiments and inspires a promising direction of improving SR.\n\nFigure 2 :\n2The overall framework of our proposed MKM-SR. The arrows in the figure indicate data flows.\n\nFigure 4 :\n4KKBOX(N)'s item embedding distributions under different learning mechanisms show that, the song embeddings learned by the MTL keep close distances across different groups (genres) on the premise of discriminating different groups. It conforms to the fact that the successive songs in a session may belong to different genres.\n\nFigure 5 :\n5MKM-SR's performance on KKBOX(N) with different \u03bb 1 shows that \u03bb 1 = 0.0001 is the best setting.\n\n\nthrough the Artist More\" \n\nSearch Add to \nPlaylist \n\nAdd to \nFavorites \n\nArtist \nMore \n\nArtist \nMore \n\nAdd to \nFavorites \n\n# \n\nSearch \nGenre \nMore \n\nAdd to \nFavorites \n\nGenre \nMore \n\nitem sequence \n(macro-behaviors) \n\noperation sequence \n\nmicro-behaviors \n\ni2 : One More Night \n\n\u2026 \n\ni3 : It Was Always You \ni 1 : Sugar \n\nitem sequence \n(macro-behaviors) \n\noperation sequence \n\ni 1 : Sugar \n\n\u2026 \n\n\u2026 \n\n\u2026 \n\n\u2026 \n\n\" \n# \n% \n% \n\n% \n& \n\" \n& \n\n' \n' \n\ni2 : One More Night \ni4 : Centuries \n\nmicro-behaviors \n\n\n\nTable 1 :\n1Dataset statisticsseesion# session \nlength \n\nitem#(new%) item fre-\nquency \n\noperation# \n\nKKBOX \n180,047 4.713 \n33,454 \n25.365 \n23 \nKKBOX(N) 180,096 4.726 \n34,120(0.99%) 24.942 \n23 \nJDATA \n455,481 5.372 \n134,548 \n18.186 \n5 \nJDATA(N) 456,005 5.383 \n139,099(3.69%) 17.654 \n5 \nDemo \n5,633 \n5.330 \n12,195 \n2.301 \n5 \nDemo(N) 5,696 \n4.992 \n12,917(40.45%) 2.192 \n5 \n\n4.1.2 Compared Models. To emphasize MKM-SR's superiority per-\nformance, we compared it with the following state-of-the-art SR \nmodels: \nFPMC [24]\nhttps://www.kaggle.com/c/kkbox-music-recommendation-challenge/data 2 https://jdata.jd.com/html/detail.html?id=8\n\nKnowledge-Based Recommender Systems. Robin Burke, Robin Burke. 2000. Knowledge-Based Recommender Systems. (2000).\n\nOn the Properties of Neural Machine Translation: Encoder-Decoder Approaches. Kyunghyun Cho, Bart Van Merrienboer, Dzmitry Bahdanau, Yoshua Bengio, Computer Science. Kyunghyun Cho, Bart Van Merrienboer, Dzmitry Bahdanau, and Yoshua Ben- gio. 2014. On the Properties of Neural Machine Translation: Encoder-Decoder Approaches. Computer Science (2014).\n\nnode2vec: Scalable Feature Learning for Networks. Aditya Grover, Jure Leskovec, Proc. of KDD. of KDDAditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In Proc. of KDD.\n\nHierarchical User Profiling for E-commerce Recommender Systems. Yulong Gu, Zhuoye Ding, Shuaiqiang Wang, Dawei Yin, Proceedings of WSDM. WSDMYulong Gu, Zhuoye Ding, Shuaiqiang Wang, and Dawei Yin. 2020. Hierarchical User Profiling for E-commerce Recommender Systems. In Proceedings of WSDM. 223-231.\n\nRecurrent neural networks with top-k gains for session-based recommendations. Bal\u00e1zs Hidasi, Alexandros Karatzoglou, Proceedings of CIKM. ACM. CIKM. ACMBal\u00e1zs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks with top-k gains for session-based recommendations. In Proceedings of CIKM. ACM, 843-852.\n\nSession-based recommendations with recurrent neural networks. B Hidasi, A Karatzoglou, L Baltrunas, D Tikk, Proc. of ICLR. of ICLRB. Hidasi, A. Karatzoglou, L. Baltrunas, and D. Tikk. 2016. Session-based recom- mendations with recurrent neural networks. In Proc. of ICLR.\n\nParallel Recurrent Neural Network Architectures for Feature-rich Session-based Recommendations. Bal\u00e3\u0105zs Hidasi, Massimo Quadrana, Alexandros Karatzoglou, Domonkos Tikk, Proc. of RecSys. of RecSysBal\u00c3\u0105zs Hidasi, Massimo Quadrana, Alexandros Karatzoglou, and Domonkos Tikk. 2016. Parallel Recurrent Neural Network Architectures for Feature-rich Session-based Recommendations. In Proc. of RecSys.\n\nImproving Sequential Recommendation with Knowledge-Enhanced Memory Networks. Jin Huang, Wayne Xin Zhao, Hongjian Dou, Ji-Rong Wen, Edward Y Chang, Proc. of SIGIR. of SIGIRJin Huang, Wayne Xin Zhao, Hongjian Dou, Ji-Rong Wen, and Edward Y. Chang. 2018. Improving Sequential Recommendation with Knowledge-Enhanced Mem- ory Networks. In Proc. of SIGIR.\n\nA Markov-based Recommendation Model for Exploring the Transfer of Learning on the Web. Yueh Min, Tien Chi Huang, Kun Te Huang, Wang, Wu Yuin, Hwang, Journal of Educational Technology & Society. 12Yueh Min Huang, Tien Chi Huang, Kun Te Wang, and Wu Yuin Hwang. 2009. A Markov-based Recommendation Model for Exploring the Transfer of Learning on the Web. Journal of Educational Technology & Society 12, 2 (2009), 144-162.\n\nAdaptation and Evaluation of Recommendations for Short-term Shopping Goals. Dietmar Jannach, Lukas Lerche, Michael Jugovac, Dietmar Jannach, Lukas Lerche, and Michael Jugovac. 2015. Adaptation and Evaluation of Recommendations for Short-term Shopping Goals. 211-218.\n\nKnowledge Graph Embedding via Dynamic Mapping Matrix. Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu, Jun Zhao, Proc. of ACL. of ACLGuoliang Ji, Shizhu He, Liheng Xu, Kang Liu, and Jun Zhao. 2015. Knowledge Graph Embedding via Dynamic Mapping Matrix. In Proc. of ACL.\n\nNeural Attentive Session-based Recommendation. Li Jing, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Jun Ma, Proc. of CIKM. of CIKMLi Jing, Pengjie Ren, Zhumin Chen, Zhaochun Ren, and Jun Ma. 2017. Neural Attentive Session-based Recommendation. In Proc. of CIKM.\n\nAdam: A Method for Stochastic Optimization. Jdiederik Kingma, Jimmy Ba, Proc. of ICLR. of ICLRJDiederik Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Opti- mization. In Proc. of ICLR.\n\nGATED GRAPH SEQUENCE NEURAL NETWORKS. Yujia Li, Richard Zemel, Marc Brockschmidt, Daniel Tarlow, Proceedings of ICLR. ICLRYujia Li, Richard Zemel, Marc Brockschmidt, and Daniel Tarlow. 2016. GATED GRAPH SEQUENCE NEURAL NETWORKS. In Proceedings of ICLR.\n\nAmazon.Com Recommendations: Item-to-Item Collaborative Filtering. Greg Linden, Brent Smith, Jeremy York, 10.1109/MIC.2003.1167344IEEE Internet Computing. 7Greg Linden, Brent Smith, and Jeremy York. 2003. Amazon.Com Recommenda- tions: Item-to-Item Collaborative Filtering. IEEE Internet Computing 7, 1 (Jan. 2003), 76-80. https://doi.org/10.1109/MIC.2003.1167344\n\nMulti-behavioral sequential prediction with recurrent log-bilinear model. Qiang Liu, Shu Wu, Liang Wang, IEEE Transactions on Knowledge and Data Engineering. 29Qiang Liu, Shu Wu, and Liang Wang. 2017. Multi-behavioral sequential prediction with recurrent log-bilinear model. IEEE Transactions on Knowledge and Data Engineering 29, 6 (2017), 1254-1267.\n\nSTAMP: Short-Term Attention/Memory Priority Model for Session-based Recommendation. Qiao Liu, Yifu Zeng, Refuoe Mokhosi, Haibin Zhang, Proc. of SIGKDD. of SIGKDDQiao Liu, Yifu Zeng, Refuoe Mokhosi, and Haibin Zhang. 2018. STAMP: Short- Term Attention/Memory Priority Model for Session-based Recommendation. In Proc. of SIGKDD.\n\nEfficient Estimation of Word Representations in Vector Space. Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean, arXiv:1301.3781Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. In arXiv:1301.3781.\n\nLearning User-Item Relatedness from Knowledge Graphs for Top-N Item Recommendation. Enrico Palumbo, Giuseppe Rizzo, Rapha\u00e3\u0144l Troncy, Proc. of RecSys. of RecSys2Enrico Palumbo, Giuseppe Rizzo, and Rapha\u00c3\u0144l Troncy. 2017. entity2rec: Learn- ing User-Item Relatedness from Knowledge Graphs for Top-N Item Recommen- dation. In Proc. of RecSys.\n\nPersonalizing session-based recommendations with hierarchical recurrent neural networks. Massimo Quadrana, Alexandros Karatzoglou, Bal\u00e3\u0105zs Hidasi, Paolo Cremonesi, Proc. of RecSys. of RecSysMassimo Quadrana, Alexandros Karatzoglou, Bal\u00c3\u0105zs Hidasi, and Paolo Cre- monesi. 2017. Personalizing session-based recommendations with hierarchical recurrent neural networks. In Proc. of RecSys.\n\nFaster r-cnn: Towards real-time object detection with region proposal networks. Kaiming Shaoqing Ren, Ross He, Jian Girshick, Sun, Advances in neural information processing systems. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2015. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems. 91-99.\n\nFactorization Machines with libFM. Steffen Rendle, Acm Transactions on Intelligent Systems and Technology. 3Steffen Rendle. 2012. Factorization Machines with libFM. Acm Transactions on Intelligent Systems and Technology 3, 3 (2012), 1-22.\n\nBPR: Bayesian personalized ranking from implicit feedback. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2012. BPR: Bayesian personalized ranking from implicit feedback. (2012), 452- 461.\n\nFactorizing personalized Markov chains for next-basket recommendation. Steffen Rendle, Christoph Freudenthaler, Lars Schmidt-Thieme, Proc. of WWW. of WWWSteffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factor- izing personalized Markov chains for next-basket recommendation. In Proc. of WWW.\n\nAn overview of multi-task learning in. Sebastian Ruder, arXiv:1706.05098deep neural networks. arXiv preprintSebastian Ruder. 2017. An overview of multi-task learning in deep neural net- works. arXiv preprint arXiv:1706.05098 (2017).\n\nItem-based collaborative filtering recommendation algorithms. Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl, Proceedings of WWW. WWWBadrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based collaborative filtering recommendation algorithms. In Proceedings of WWW. 285- 295.\n\nThe Graph Neural Network Model. Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, Gabriele Monfardini, 10.1109/TNN.2008.2005605IEEE Trans. Neural Networks. 20Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2009. The Graph Neural Network Model. IEEE Trans. Neural Networks 20, 1 (2009), 61-80. https://doi.org/10.1109/TNN.2008.2005605\n\nAn MDP-based Recommender System. Guy Shani, Ronen I Brafman, David Heckerman, Journal of Machine Learning Research. 6Guy Shani, Ronen I. Brafman, and David Heckerman. 2005. An MDP-based Recommender System. Journal of Machine Learning Research 6, 1 (2005), 1265- 1295.\n\nmetap-ath2vec: Scalable Representation Learning for Heterogeneous Networks. Ananthram Swami, Ananthram Swami, Ananthram Swami, Proc. of KDD. of KDDAnanthram Swami, Ananthram Swami, and Ananthram Swami. 2017. metap- ath2vec: Scalable Representation Learning for Heterogeneous Networks. In Proc. of KDD.\n\nItem recommendation on monotonic behavior chains. Mengting Wan, Julian Mcauley, Proceedings of the 12th ACM Conference on Recommender Systems. the 12th ACM Conference on Recommender SystemsMengting Wan and Julian McAuley. 2018. Item recommendation on monotonic behavior chains. In Proceedings of the 12th ACM Conference on Recommender Systems. 86-94.\n\nRippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems. Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, Minyi Guo, Proc. of CIKM. of CIKMHongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, and Minyi Guo. 2018. RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems. In Proc. of CIKM.\n\nDKN: Deep Knowledge-Aware Network for News Recommendation. Hongwei Wang, Fuzheng Zhang, Xing Xie, Minyi Guo, Proceedings of WWW. WWWHongwei Wang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2018. DKN: Deep Knowledge-Aware Network for News Recommendation. In Proceedings of WWW.\n\nA Survey on Session-based Recommender Systems. Shoujin Wang, Longbing Cao, Yan Wang, CoRR abs/1902.04864Shoujin Wang, Longbing Cao, and Yan Wang. 2019. A Survey on Session-based Recommender Systems. CoRR abs/1902.04864 (2019).\n\nKnowledge graph embedding by translating on hyperplanes. Zhen Wang, Jianwen Zhang, Jianlin Feng, Zheng Chen, Twenty-Eighth AAAI conference on artificial intelligence. Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyperplanes. In Twenty-Eighth AAAI confer- ence on artificial intelligence.\n\nSession-based recommendation with graph neural networks. Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, Tieniu Tan, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence33Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 346-353.\n\nShow, Attend and Tell: Neural Image Caption Generation with Visual Attention. Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C Courville, Ruslan Salakhutdinov, Richard S Zemel, Yoshua Bengio, Proc. of ICML. of ICMLKelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C. Courville, Ruslan Salakhutdinov, Richard S. Zemel, and Yoshua Bengio:. 2015. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. In Proc. of ICML.\n\nKnowledge embedding towards the recommendation with sparse user-item interactions. Deqing Yang, Zikai Guo, Ziyi Wang, Junyang Jiang, Yanghua Xiao, Wei Wang, Proceedings of ICDM. ICDMDeqing Yang, Zikai Guo, Ziyi Wang, Junyang Jiang, Yanghua Xiao, and Wei Wang. 2018. Knowledge embedding towards the recommendation with sparse user-item interactions. In Proceedings of ICDM.\n\nKnowledge embedding towards the recommendation with sparse user-item interactions. Deqing Yang, Ziyi Wang, Junyang Jiang, Yanghua Xiao, Proceedings of ASONAM. ASONAMDeqing Yang, Ziyi Wang, Junyang Jiang, and Yanghua Xiao. 2019. Knowledge embedding towards the recommendation with sparse user-item interactions. In Proceedings of ASONAM.\n\nPersonalized Entity Recommendation: A Heterogeneous Information Network Approach. X Yu, X Ren, Y Sun, Q Gu, B Sturt, U Khandelwal, B Norick, J Han, Proc. of WSDM. of WSDMX. Yu, X. Ren, Y. Sun, Q. Gu, B. Sturt, U. Khandelwal, B. Norick, and J. Han. 2014. Personalized Entity Recommendation: A Heterogeneous Information Network Approach. In Proc. of WSDM.\n\nFeature-level Deeper Self-Attention Network for Sequential Recommendation. Tingting Zhang, Pengpeng Zhao, Yanchi Liu, Victor S Sheng, Jiajie Xu, Deqing Wang, Guanfeng Liu, Xiaofang Zhou, Proc. of IJCAI. of IJCAITingting Zhang, Pengpeng Zhao, Yanchi Liu, Victor S. Sheng, Jiajie Xu, De- qing Wang, Guanfeng Liu, and Xiaofang Zhou. 2019. Feature-level Deeper Self-Attention Network for Sequential Recommendation. In Proc. of IJCAI.\n\nMicro Behaviors: A New Perspective in E-commerce Recommender Systems. Meizi Zhou, Zhouye Ding, Jiliang Tang, Dawei Yin, Proc. of WSDM. of WSDMMeizi Zhou, Zhouye Ding, Jiliang Tang, and Dawei Yin. 2018. Micro Behaviors: A New Perspective in E-commerce Recommender Systems. In Proc. of WSDM.\n", "annotations": {"author": "[{\"end\":244,\"start\":209},{\"end\":281,\"start\":245},{\"end\":295,\"start\":282},{\"end\":384,\"start\":296},{\"end\":423,\"start\":385}]", "publisher": "[{\"end\":138,\"start\":113},{\"end\":676,\"start\":651}]", "author_last_name": "[{\"end\":221,\"start\":217},{\"end\":256,\"start\":252},{\"end\":294,\"start\":290}]", "author_first_name": "[{\"end\":216,\"start\":209},{\"end\":251,\"start\":245},{\"end\":289,\"start\":282}]", "author_affiliation": "[{\"end\":383,\"start\":297},{\"end\":422,\"start\":386}]", "title": "[{\"end\":112,\"start\":1},{\"end\":535,\"start\":424}]", "venue": "[{\"end\":633,\"start\":537}]", "abstract": "[{\"end\":2869,\"start\":1112}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3099,\"start\":3095},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3443,\"start\":3439},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3960,\"start\":3956},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4207,\"start\":4204},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4210,\"start\":4207},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4213,\"start\":4210},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4216,\"start\":4213},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4480,\"start\":4477},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4483,\"start\":4480},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4486,\"start\":4483},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5636,\"start\":5635},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":7808,\"start\":7804},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":7811,\"start\":7808},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9277,\"start\":9274},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9330,\"start\":9326},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9333,\"start\":9330},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9553,\"start\":9549},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9733,\"start\":9729},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":9736,\"start\":9733},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":9739,\"start\":9736},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11683,\"start\":11680},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11686,\"start\":11683},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11784,\"start\":11780},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":11787,\"start\":11784},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11990,\"start\":11986},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":12671,\"start\":12668},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12825,\"start\":12821},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12980,\"start\":12976},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13204,\"start\":13201},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13212,\"start\":13209},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":13313,\"start\":13309},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13607,\"start\":13604},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":13610,\"start\":13607},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":13613,\"start\":13610},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":13616,\"start\":13613},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":13670,\"start\":13666},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":13839,\"start\":13835},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13847,\"start\":13844},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14183,\"start\":14180},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14186,\"start\":14183},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":14330,\"start\":14327},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":14628,\"start\":14624},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14824,\"start\":14820},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14845,\"start\":14842},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":15267,\"start\":15263},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":15367,\"start\":15363},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":15449,\"start\":15445},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":15452,\"start\":15449},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":15479,\"start\":15475},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":15795,\"start\":15791},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16008,\"start\":16005},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":16149,\"start\":16145},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":20039,\"start\":20035},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":21080,\"start\":21076},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":21270,\"start\":21266},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":21516,\"start\":21513},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":21519,\"start\":21516},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":22640,\"start\":22637},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":22643,\"start\":22640},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":22646,\"start\":22643},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":23209,\"start\":23205},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":25626,\"start\":25622},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":27384,\"start\":27381},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":29470,\"start\":29466},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":29746,\"start\":29742},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":31805,\"start\":31801},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":32939,\"start\":32935},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":32942,\"start\":32939},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":32945,\"start\":32942},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":33524,\"start\":33520},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":34828,\"start\":34824},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36913,\"start\":36910},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":36916,\"start\":36913},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":38044,\"start\":38040},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":38047,\"start\":38044},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":38050,\"start\":38047},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":38868,\"start\":38865},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":38930,\"start\":38927},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":39017,\"start\":39013},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":39098,\"start\":39094},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":39214,\"start\":39210},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":39390,\"start\":39386},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":39552,\"start\":39548},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":39643,\"start\":39639},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":41814,\"start\":41810},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":42189,\"start\":42185},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":45064,\"start\":45062}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":49763,\"start\":49659},{\"attributes\":{\"id\":\"fig_4\"},\"end\":50102,\"start\":49764},{\"attributes\":{\"id\":\"fig_5\"},\"end\":50212,\"start\":50103},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":50711,\"start\":50213},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":51228,\"start\":50712}]", "paragraph": "[{\"end\":3667,\"start\":2885},{\"end\":4373,\"start\":3669},{\"end\":5241,\"start\":4375},{\"end\":6072,\"start\":5243},{\"end\":8505,\"start\":6074},{\"end\":10072,\"start\":8507},{\"end\":10420,\"start\":10074},{\"end\":10665,\"start\":10422},{\"end\":10909,\"start\":10667},{\"end\":11133,\"start\":10911},{\"end\":11245,\"start\":11150},{\"end\":14187,\"start\":11293},{\"end\":16749,\"start\":14222},{\"end\":17180,\"start\":16765},{\"end\":19027,\"start\":17203},{\"end\":19466,\"start\":19137},{\"end\":20774,\"start\":19468},{\"end\":21300,\"start\":20776},{\"end\":22258,\"start\":21333},{\"end\":23284,\"start\":22296},{\"end\":24384,\"start\":23286},{\"end\":24523,\"start\":24414},{\"end\":24986,\"start\":24525},{\"end\":25369,\"start\":25095},{\"end\":26052,\"start\":25371},{\"end\":26125,\"start\":26054},{\"end\":26893,\"start\":26375},{\"end\":27296,\"start\":26977},{\"end\":27576,\"start\":27331},{\"end\":28002,\"start\":27578},{\"end\":28316,\"start\":28056},{\"end\":28830,\"start\":28364},{\"end\":28950,\"start\":28832},{\"end\":29304,\"start\":29063},{\"end\":29978,\"start\":29344},{\"end\":30118,\"start\":30021},{\"end\":30189,\"start\":30143},{\"end\":30241,\"start\":30220},{\"end\":30436,\"start\":30243},{\"end\":30747,\"start\":30472},{\"end\":30885,\"start\":30818},{\"end\":31967,\"start\":30919},{\"end\":32630,\"start\":31969},{\"end\":32720,\"start\":32656},{\"end\":32839,\"start\":32794},{\"end\":33855,\"start\":32880},{\"end\":34070,\"start\":33857},{\"end\":34500,\"start\":34141},{\"end\":34705,\"start\":34538},{\"end\":34863,\"start\":34707},{\"end\":35150,\"start\":35022},{\"end\":35418,\"start\":35312},{\"end\":35547,\"start\":35434},{\"end\":35617,\"start\":35549},{\"end\":35697,\"start\":35619},{\"end\":35849,\"start\":35699},{\"end\":35939,\"start\":35851},{\"end\":36774,\"start\":35975},{\"end\":37515,\"start\":36776},{\"end\":38278,\"start\":37517},{\"end\":38848,\"start\":38280},{\"end\":39087,\"start\":38850},{\"end\":39202,\"start\":39089},{\"end\":39377,\"start\":39204},{\"end\":39542,\"start\":39379},{\"end\":39706,\"start\":39544},{\"end\":39889,\"start\":39708},{\"end\":40081,\"start\":39891},{\"end\":40374,\"start\":40083},{\"end\":40614,\"start\":40376},{\"end\":40710,\"start\":40616},{\"end\":40854,\"start\":40734},{\"end\":40984,\"start\":40856},{\"end\":41162,\"start\":40986},{\"end\":41610,\"start\":41189},{\"end\":42190,\"start\":41612},{\"end\":42388,\"start\":42192},{\"end\":42660,\"start\":42423},{\"end\":43466,\"start\":42662},{\"end\":43811,\"start\":43468},{\"end\":44868,\"start\":43830},{\"end\":45724,\"start\":44919},{\"end\":48427,\"start\":45726},{\"end\":48925,\"start\":48462},{\"end\":49658,\"start\":48940}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":19119,\"start\":19028},{\"attributes\":{\"id\":\"formula_1\"},\"end\":25094,\"start\":24987},{\"attributes\":{\"id\":\"formula_2\"},\"end\":26374,\"start\":26126},{\"attributes\":{\"id\":\"formula_3\"},\"end\":26976,\"start\":26894},{\"attributes\":{\"id\":\"formula_4\"},\"end\":28055,\"start\":28003},{\"attributes\":{\"id\":\"formula_5\"},\"end\":28363,\"start\":28317},{\"attributes\":{\"id\":\"formula_6\"},\"end\":29062,\"start\":28966},{\"attributes\":{\"id\":\"formula_7\"},\"end\":30020,\"start\":29979},{\"attributes\":{\"id\":\"formula_8\"},\"end\":30142,\"start\":30119},{\"attributes\":{\"id\":\"formula_9\"},\"end\":30219,\"start\":30190},{\"attributes\":{\"id\":\"formula_10\"},\"end\":30471,\"start\":30437},{\"attributes\":{\"id\":\"formula_11\"},\"end\":30817,\"start\":30748},{\"attributes\":{\"id\":\"formula_12\"},\"end\":32655,\"start\":32631},{\"attributes\":{\"id\":\"formula_13\"},\"end\":32793,\"start\":32721},{\"attributes\":{\"id\":\"formula_14\"},\"end\":34140,\"start\":34071},{\"attributes\":{\"id\":\"formula_15\"},\"end\":34537,\"start\":34501},{\"attributes\":{\"id\":\"formula_16\"},\"end\":35021,\"start\":34864},{\"attributes\":{\"id\":\"formula_17\"},\"end\":35311,\"start\":35151}]", "table_ref": "[{\"end\":38331,\"start\":38324},{\"end\":42589,\"start\":42582},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":43042,\"start\":43035},{\"end\":43966,\"start\":43959}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2883,\"start\":2871},{\"attributes\":{\"n\":\"2\"},\"end\":11148,\"start\":11136},{\"attributes\":{\"n\":\"2.1\"},\"end\":11291,\"start\":11248},{\"attributes\":{\"n\":\"2.2\"},\"end\":14220,\"start\":14190},{\"attributes\":{\"n\":\"3\"},\"end\":16763,\"start\":16752},{\"attributes\":{\"n\":\"3.1\"},\"end\":17201,\"start\":17183},{\"attributes\":{\"n\":\"3.2\"},\"end\":19135,\"start\":19121},{\"attributes\":{\"n\":\"3.3\"},\"end\":21331,\"start\":21303},{\"attributes\":{\"n\":\"3.3.1\"},\"end\":22294,\"start\":22261},{\"attributes\":{\"n\":\"3.3.2\"},\"end\":24412,\"start\":24387},{\"attributes\":{\"n\":\"3.3.3\"},\"end\":27329,\"start\":27299},{\"end\":28965,\"start\":28953},{\"attributes\":{\"n\":\"3.3.4\"},\"end\":29342,\"start\":29307},{\"attributes\":{\"n\":\"3.4\"},\"end\":30917,\"start\":30888},{\"attributes\":{\"n\":\"3.5\"},\"end\":32878,\"start\":32842},{\"attributes\":{\"n\":\"4\"},\"end\":35432,\"start\":35421},{\"attributes\":{\"n\":\"4.1\"},\"end\":35961,\"start\":35942},{\"attributes\":{\"n\":\"4.1.1\"},\"end\":35973,\"start\":35964},{\"attributes\":{\"n\":\"4.1.3\"},\"end\":40732,\"start\":40713},{\"attributes\":{\"n\":\"4.1.4\"},\"end\":41187,\"start\":41165},{\"attributes\":{\"n\":\"4.2\"},\"end\":42421,\"start\":42391},{\"attributes\":{\"n\":\"4.3\"},\"end\":43828,\"start\":43814},{\"attributes\":{\"n\":\"4.4\"},\"end\":44917,\"start\":44871},{\"attributes\":{\"n\":\"4.5\"},\"end\":48460,\"start\":48430},{\"attributes\":{\"n\":\"5\"},\"end\":48938,\"start\":48928},{\"end\":49670,\"start\":49660},{\"end\":49775,\"start\":49765},{\"end\":50114,\"start\":50104},{\"end\":50722,\"start\":50713}]", "table": "[{\"end\":50711,\"start\":50238},{\"end\":51228,\"start\":50742}]", "figure_caption": "[{\"end\":49763,\"start\":49672},{\"end\":50102,\"start\":49777},{\"end\":50212,\"start\":50116},{\"end\":50238,\"start\":50215},{\"end\":50742,\"start\":50724}]", "figure_ref": "[{\"end\":5102,\"start\":5097},{\"end\":5252,\"start\":5246},{\"end\":5645,\"start\":5637},{\"end\":6981,\"start\":6975},{\"end\":8159,\"start\":8153},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19185,\"start\":19179},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19571,\"start\":19565},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":20237,\"start\":20231},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":20288,\"start\":20282},{\"end\":24985,\"start\":24965},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":28628,\"start\":28596},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":28950,\"start\":28944},{\"end\":30951,\"start\":30945},{\"end\":33579,\"start\":33573},{\"end\":45520,\"start\":45512},{\"end\":45735,\"start\":45729},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":46724,\"start\":46718},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":46815,\"start\":46806},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":47143,\"start\":47134},{\"end\":47548,\"start\":47542},{\"end\":47673,\"start\":47667},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":47710,\"start\":47704},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":48582,\"start\":48576}]", "bib_author_first_name": "[{\"end\":51384,\"start\":51379},{\"end\":51543,\"start\":51534},{\"end\":51553,\"start\":51549},{\"end\":51578,\"start\":51571},{\"end\":51595,\"start\":51589},{\"end\":51863,\"start\":51857},{\"end\":51876,\"start\":51872},{\"end\":52084,\"start\":52078},{\"end\":52095,\"start\":52089},{\"end\":52112,\"start\":52102},{\"end\":52124,\"start\":52119},{\"end\":52399,\"start\":52393},{\"end\":52418,\"start\":52408},{\"end\":52695,\"start\":52694},{\"end\":52705,\"start\":52704},{\"end\":52720,\"start\":52719},{\"end\":52733,\"start\":52732},{\"end\":53008,\"start\":53001},{\"end\":53024,\"start\":53017},{\"end\":53045,\"start\":53035},{\"end\":53067,\"start\":53059},{\"end\":53380,\"start\":53377},{\"end\":53393,\"start\":53388},{\"end\":53397,\"start\":53394},{\"end\":53412,\"start\":53404},{\"end\":53425,\"start\":53418},{\"end\":53437,\"start\":53431},{\"end\":53439,\"start\":53438},{\"end\":53752,\"start\":53748},{\"end\":53756,\"start\":53753},{\"end\":53770,\"start\":53764},{\"end\":54155,\"start\":54148},{\"end\":54170,\"start\":54165},{\"end\":54186,\"start\":54179},{\"end\":54402,\"start\":54394},{\"end\":54413,\"start\":54407},{\"end\":54424,\"start\":54418},{\"end\":54433,\"start\":54429},{\"end\":54442,\"start\":54439},{\"end\":54655,\"start\":54653},{\"end\":54669,\"start\":54662},{\"end\":54681,\"start\":54675},{\"end\":54696,\"start\":54688},{\"end\":54705,\"start\":54702},{\"end\":54918,\"start\":54909},{\"end\":54932,\"start\":54927},{\"end\":55104,\"start\":55099},{\"end\":55116,\"start\":55109},{\"end\":55128,\"start\":55124},{\"end\":55149,\"start\":55143},{\"end\":55385,\"start\":55381},{\"end\":55399,\"start\":55394},{\"end\":55413,\"start\":55407},{\"end\":55757,\"start\":55752},{\"end\":55766,\"start\":55763},{\"end\":55776,\"start\":55771},{\"end\":56119,\"start\":56115},{\"end\":56129,\"start\":56125},{\"end\":56142,\"start\":56136},{\"end\":56158,\"start\":56152},{\"end\":56426,\"start\":56421},{\"end\":56439,\"start\":56436},{\"end\":56450,\"start\":56446},{\"end\":56467,\"start\":56460},{\"end\":56725,\"start\":56719},{\"end\":56743,\"start\":56735},{\"end\":56759,\"start\":56751},{\"end\":57071,\"start\":57064},{\"end\":57092,\"start\":57082},{\"end\":57113,\"start\":57106},{\"end\":57127,\"start\":57122},{\"end\":57449,\"start\":57442},{\"end\":57468,\"start\":57464},{\"end\":57477,\"start\":57473},{\"end\":58053,\"start\":58046},{\"end\":58071,\"start\":58062},{\"end\":58091,\"start\":58087},{\"end\":58105,\"start\":58101},{\"end\":58364,\"start\":58357},{\"end\":58382,\"start\":58373},{\"end\":58402,\"start\":58398},{\"end\":58650,\"start\":58641},{\"end\":58904,\"start\":58898},{\"end\":58919,\"start\":58913},{\"end\":58935,\"start\":58929},{\"end\":58949,\"start\":58945},{\"end\":59183,\"start\":59177},{\"end\":59200,\"start\":59195},{\"end\":59209,\"start\":59207},{\"end\":59228,\"start\":59222},{\"end\":59251,\"start\":59243},{\"end\":59575,\"start\":59572},{\"end\":59588,\"start\":59583},{\"end\":59590,\"start\":59589},{\"end\":59605,\"start\":59600},{\"end\":59893,\"start\":59884},{\"end\":59910,\"start\":59901},{\"end\":59927,\"start\":59918},{\"end\":60169,\"start\":60161},{\"end\":60181,\"start\":60175},{\"end\":60558,\"start\":60551},{\"end\":60572,\"start\":60565},{\"end\":60586,\"start\":60580},{\"end\":60597,\"start\":60593},{\"end\":60610,\"start\":60604},{\"end\":60619,\"start\":60615},{\"end\":60630,\"start\":60625},{\"end\":60926,\"start\":60919},{\"end\":60940,\"start\":60933},{\"end\":60952,\"start\":60948},{\"end\":60963,\"start\":60958},{\"end\":61189,\"start\":61182},{\"end\":61204,\"start\":61196},{\"end\":61213,\"start\":61210},{\"end\":61424,\"start\":61420},{\"end\":61438,\"start\":61431},{\"end\":61453,\"start\":61446},{\"end\":61465,\"start\":61460},{\"end\":61773,\"start\":61770},{\"end\":61784,\"start\":61778},{\"end\":61798,\"start\":61791},{\"end\":61809,\"start\":61804},{\"end\":61820,\"start\":61816},{\"end\":61832,\"start\":61826},{\"end\":62253,\"start\":62247},{\"end\":62263,\"start\":62258},{\"end\":62272,\"start\":62268},{\"end\":62289,\"start\":62280},{\"end\":62300,\"start\":62295},{\"end\":62302,\"start\":62301},{\"end\":62320,\"start\":62314},{\"end\":62343,\"start\":62336},{\"end\":62345,\"start\":62344},{\"end\":62359,\"start\":62353},{\"end\":62710,\"start\":62704},{\"end\":62722,\"start\":62717},{\"end\":62732,\"start\":62728},{\"end\":62746,\"start\":62739},{\"end\":62761,\"start\":62754},{\"end\":62771,\"start\":62768},{\"end\":63084,\"start\":63078},{\"end\":63095,\"start\":63091},{\"end\":63109,\"start\":63102},{\"end\":63124,\"start\":63117},{\"end\":63416,\"start\":63415},{\"end\":63422,\"start\":63421},{\"end\":63429,\"start\":63428},{\"end\":63436,\"start\":63435},{\"end\":63442,\"start\":63441},{\"end\":63451,\"start\":63450},{\"end\":63465,\"start\":63464},{\"end\":63475,\"start\":63474},{\"end\":63771,\"start\":63763},{\"end\":63787,\"start\":63779},{\"end\":63800,\"start\":63794},{\"end\":63812,\"start\":63806},{\"end\":63814,\"start\":63813},{\"end\":63828,\"start\":63822},{\"end\":63839,\"start\":63833},{\"end\":63854,\"start\":63846},{\"end\":63868,\"start\":63860},{\"end\":64194,\"start\":64189},{\"end\":64207,\"start\":64201},{\"end\":64221,\"start\":64214},{\"end\":64233,\"start\":64228}]", "bib_author_last_name": "[{\"end\":51390,\"start\":51385},{\"end\":51547,\"start\":51544},{\"end\":51569,\"start\":51554},{\"end\":51587,\"start\":51579},{\"end\":51602,\"start\":51596},{\"end\":51870,\"start\":51864},{\"end\":51885,\"start\":51877},{\"end\":52087,\"start\":52085},{\"end\":52100,\"start\":52096},{\"end\":52117,\"start\":52113},{\"end\":52128,\"start\":52125},{\"end\":52406,\"start\":52400},{\"end\":52430,\"start\":52419},{\"end\":52702,\"start\":52696},{\"end\":52717,\"start\":52706},{\"end\":52730,\"start\":52721},{\"end\":52738,\"start\":52734},{\"end\":53015,\"start\":53009},{\"end\":53033,\"start\":53025},{\"end\":53057,\"start\":53046},{\"end\":53072,\"start\":53068},{\"end\":53386,\"start\":53381},{\"end\":53402,\"start\":53398},{\"end\":53416,\"start\":53413},{\"end\":53429,\"start\":53426},{\"end\":53445,\"start\":53440},{\"end\":53746,\"start\":53738},{\"end\":53762,\"start\":53757},{\"end\":53776,\"start\":53771},{\"end\":53782,\"start\":53778},{\"end\":53791,\"start\":53784},{\"end\":53798,\"start\":53793},{\"end\":54163,\"start\":54156},{\"end\":54177,\"start\":54171},{\"end\":54194,\"start\":54187},{\"end\":54405,\"start\":54403},{\"end\":54416,\"start\":54414},{\"end\":54427,\"start\":54425},{\"end\":54437,\"start\":54434},{\"end\":54447,\"start\":54443},{\"end\":54660,\"start\":54656},{\"end\":54673,\"start\":54670},{\"end\":54686,\"start\":54682},{\"end\":54700,\"start\":54697},{\"end\":54708,\"start\":54706},{\"end\":54925,\"start\":54919},{\"end\":54935,\"start\":54933},{\"end\":55107,\"start\":55105},{\"end\":55122,\"start\":55117},{\"end\":55141,\"start\":55129},{\"end\":55156,\"start\":55150},{\"end\":55392,\"start\":55386},{\"end\":55405,\"start\":55400},{\"end\":55418,\"start\":55414},{\"end\":55761,\"start\":55758},{\"end\":55769,\"start\":55767},{\"end\":55781,\"start\":55777},{\"end\":56123,\"start\":56120},{\"end\":56134,\"start\":56130},{\"end\":56150,\"start\":56143},{\"end\":56164,\"start\":56159},{\"end\":56434,\"start\":56427},{\"end\":56444,\"start\":56440},{\"end\":56458,\"start\":56451},{\"end\":56472,\"start\":56468},{\"end\":56733,\"start\":56726},{\"end\":56749,\"start\":56744},{\"end\":56766,\"start\":56760},{\"end\":57080,\"start\":57072},{\"end\":57104,\"start\":57093},{\"end\":57120,\"start\":57114},{\"end\":57137,\"start\":57128},{\"end\":57462,\"start\":57450},{\"end\":57471,\"start\":57469},{\"end\":57486,\"start\":57478},{\"end\":57491,\"start\":57488},{\"end\":57796,\"start\":57782},{\"end\":58060,\"start\":58054},{\"end\":58085,\"start\":58072},{\"end\":58099,\"start\":58092},{\"end\":58120,\"start\":58106},{\"end\":58371,\"start\":58365},{\"end\":58396,\"start\":58383},{\"end\":58417,\"start\":58403},{\"end\":58656,\"start\":58651},{\"end\":58911,\"start\":58905},{\"end\":58927,\"start\":58920},{\"end\":58943,\"start\":58936},{\"end\":58955,\"start\":58950},{\"end\":59193,\"start\":59184},{\"end\":59205,\"start\":59201},{\"end\":59220,\"start\":59210},{\"end\":59241,\"start\":59229},{\"end\":59262,\"start\":59252},{\"end\":59581,\"start\":59576},{\"end\":59598,\"start\":59591},{\"end\":59615,\"start\":59606},{\"end\":59899,\"start\":59894},{\"end\":59916,\"start\":59911},{\"end\":59933,\"start\":59928},{\"end\":60173,\"start\":60170},{\"end\":60189,\"start\":60182},{\"end\":60563,\"start\":60559},{\"end\":60578,\"start\":60573},{\"end\":60591,\"start\":60587},{\"end\":60602,\"start\":60598},{\"end\":60613,\"start\":60611},{\"end\":60623,\"start\":60620},{\"end\":60634,\"start\":60631},{\"end\":60931,\"start\":60927},{\"end\":60946,\"start\":60941},{\"end\":60956,\"start\":60953},{\"end\":60967,\"start\":60964},{\"end\":61194,\"start\":61190},{\"end\":61208,\"start\":61205},{\"end\":61218,\"start\":61214},{\"end\":61429,\"start\":61425},{\"end\":61444,\"start\":61439},{\"end\":61458,\"start\":61454},{\"end\":61470,\"start\":61466},{\"end\":61776,\"start\":61774},{\"end\":61789,\"start\":61785},{\"end\":61802,\"start\":61799},{\"end\":61814,\"start\":61810},{\"end\":61824,\"start\":61821},{\"end\":61836,\"start\":61833},{\"end\":62256,\"start\":62254},{\"end\":62266,\"start\":62264},{\"end\":62278,\"start\":62273},{\"end\":62293,\"start\":62290},{\"end\":62312,\"start\":62303},{\"end\":62334,\"start\":62321},{\"end\":62351,\"start\":62346},{\"end\":62366,\"start\":62360},{\"end\":62715,\"start\":62711},{\"end\":62726,\"start\":62723},{\"end\":62737,\"start\":62733},{\"end\":62752,\"start\":62747},{\"end\":62766,\"start\":62762},{\"end\":62776,\"start\":62772},{\"end\":63089,\"start\":63085},{\"end\":63100,\"start\":63096},{\"end\":63115,\"start\":63110},{\"end\":63129,\"start\":63125},{\"end\":63419,\"start\":63417},{\"end\":63426,\"start\":63423},{\"end\":63433,\"start\":63430},{\"end\":63439,\"start\":63437},{\"end\":63448,\"start\":63443},{\"end\":63462,\"start\":63452},{\"end\":63472,\"start\":63466},{\"end\":63479,\"start\":63476},{\"end\":63777,\"start\":63772},{\"end\":63792,\"start\":63788},{\"end\":63804,\"start\":63801},{\"end\":63820,\"start\":63815},{\"end\":63831,\"start\":63829},{\"end\":63844,\"start\":63840},{\"end\":63858,\"start\":63855},{\"end\":63873,\"start\":63869},{\"end\":64199,\"start\":64195},{\"end\":64212,\"start\":64208},{\"end\":64226,\"start\":64222},{\"end\":64237,\"start\":64234}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":51455,\"start\":51342},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":11336213},\"end\":51805,\"start\":51457},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":207238980},\"end\":52012,\"start\":51807},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":210883769},\"end\":52313,\"start\":52014},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":1159769},\"end\":52630,\"start\":52315},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":11810482},\"end\":52903,\"start\":52632},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":8264369},\"end\":53298,\"start\":52905},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":49644765},\"end\":53649,\"start\":53300},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":9921636},\"end\":54070,\"start\":53651},{\"attributes\":{\"id\":\"b9\"},\"end\":54338,\"start\":54072},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":11202498},\"end\":54604,\"start\":54340},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":21066930},\"end\":54863,\"start\":54606},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":6628106},\"end\":55059,\"start\":54865},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":8393918},\"end\":55313,\"start\":55061},{\"attributes\":{\"doi\":\"10.1109/MIC.2003.1167344\",\"id\":\"b14\",\"matched_paper_id\":14604122},\"end\":55676,\"start\":55315},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":14093453},\"end\":56029,\"start\":55678},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":50775765},\"end\":56357,\"start\":56031},{\"attributes\":{\"doi\":\"arXiv:1301.3781\",\"id\":\"b17\"},\"end\":56633,\"start\":56359},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":12349227},\"end\":56973,\"start\":56635},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":10174110},\"end\":57360,\"start\":56975},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":10328909},\"end\":57745,\"start\":57362},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":5499886},\"end\":57985,\"start\":57747},{\"attributes\":{\"id\":\"b22\"},\"end\":58284,\"start\":57987},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":207178809},\"end\":58600,\"start\":58286},{\"attributes\":{\"doi\":\"arXiv:1706.05098\",\"id\":\"b24\",\"matched_paper_id\":90063862},\"end\":58834,\"start\":58602},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":8047550},\"end\":59143,\"start\":58836},{\"attributes\":{\"doi\":\"10.1109/TNN.2008.2005605\",\"id\":\"b26\",\"matched_paper_id\":206756462},\"end\":59537,\"start\":59145},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":875571},\"end\":59806,\"start\":59539},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":3919301},\"end\":60109,\"start\":59808},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":52084596},\"end\":60461,\"start\":60111},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":3766110},\"end\":60858,\"start\":60463},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":4889971},\"end\":61133,\"start\":60860},{\"attributes\":{\"doi\":\"CoRR abs/1902.04864\",\"id\":\"b32\"},\"end\":61361,\"start\":61135},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":15027084},\"end\":61711,\"start\":61363},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":53219431},\"end\":62167,\"start\":61713},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":1055111},\"end\":62619,\"start\":62169},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":210715229},\"end\":62993,\"start\":62621},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":210715229},\"end\":63331,\"start\":62995},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":207209998},\"end\":63686,\"start\":63333},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":199465766},\"end\":64117,\"start\":63688},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":32370905},\"end\":64408,\"start\":64119}]", "bib_title": "[{\"end\":51532,\"start\":51457},{\"end\":51855,\"start\":51807},{\"end\":52076,\"start\":52014},{\"end\":52391,\"start\":52315},{\"end\":52692,\"start\":52632},{\"end\":52999,\"start\":52905},{\"end\":53375,\"start\":53300},{\"end\":53736,\"start\":53651},{\"end\":54392,\"start\":54340},{\"end\":54651,\"start\":54606},{\"end\":54907,\"start\":54865},{\"end\":55097,\"start\":55061},{\"end\":55379,\"start\":55315},{\"end\":55750,\"start\":55678},{\"end\":56113,\"start\":56031},{\"end\":56717,\"start\":56635},{\"end\":57062,\"start\":56975},{\"end\":57440,\"start\":57362},{\"end\":57780,\"start\":57747},{\"end\":58355,\"start\":58286},{\"end\":58639,\"start\":58602},{\"end\":58896,\"start\":58836},{\"end\":59175,\"start\":59145},{\"end\":59570,\"start\":59539},{\"end\":59882,\"start\":59808},{\"end\":60159,\"start\":60111},{\"end\":60549,\"start\":60463},{\"end\":60917,\"start\":60860},{\"end\":61418,\"start\":61363},{\"end\":61768,\"start\":61713},{\"end\":62245,\"start\":62169},{\"end\":62702,\"start\":62621},{\"end\":63076,\"start\":62995},{\"end\":63413,\"start\":63333},{\"end\":63761,\"start\":63688},{\"end\":64187,\"start\":64119}]", "bib_author": "[{\"end\":51392,\"start\":51379},{\"end\":51549,\"start\":51534},{\"end\":51571,\"start\":51549},{\"end\":51589,\"start\":51571},{\"end\":51604,\"start\":51589},{\"end\":51872,\"start\":51857},{\"end\":51887,\"start\":51872},{\"end\":52089,\"start\":52078},{\"end\":52102,\"start\":52089},{\"end\":52119,\"start\":52102},{\"end\":52130,\"start\":52119},{\"end\":52408,\"start\":52393},{\"end\":52432,\"start\":52408},{\"end\":52704,\"start\":52694},{\"end\":52719,\"start\":52704},{\"end\":52732,\"start\":52719},{\"end\":52740,\"start\":52732},{\"end\":53017,\"start\":53001},{\"end\":53035,\"start\":53017},{\"end\":53059,\"start\":53035},{\"end\":53074,\"start\":53059},{\"end\":53388,\"start\":53377},{\"end\":53404,\"start\":53388},{\"end\":53418,\"start\":53404},{\"end\":53431,\"start\":53418},{\"end\":53447,\"start\":53431},{\"end\":53748,\"start\":53738},{\"end\":53764,\"start\":53748},{\"end\":53778,\"start\":53764},{\"end\":53784,\"start\":53778},{\"end\":53793,\"start\":53784},{\"end\":53800,\"start\":53793},{\"end\":54165,\"start\":54148},{\"end\":54179,\"start\":54165},{\"end\":54196,\"start\":54179},{\"end\":54407,\"start\":54394},{\"end\":54418,\"start\":54407},{\"end\":54429,\"start\":54418},{\"end\":54439,\"start\":54429},{\"end\":54449,\"start\":54439},{\"end\":54662,\"start\":54653},{\"end\":54675,\"start\":54662},{\"end\":54688,\"start\":54675},{\"end\":54702,\"start\":54688},{\"end\":54710,\"start\":54702},{\"end\":54927,\"start\":54909},{\"end\":54937,\"start\":54927},{\"end\":55109,\"start\":55099},{\"end\":55124,\"start\":55109},{\"end\":55143,\"start\":55124},{\"end\":55158,\"start\":55143},{\"end\":55394,\"start\":55381},{\"end\":55407,\"start\":55394},{\"end\":55420,\"start\":55407},{\"end\":55763,\"start\":55752},{\"end\":55771,\"start\":55763},{\"end\":55783,\"start\":55771},{\"end\":56125,\"start\":56115},{\"end\":56136,\"start\":56125},{\"end\":56152,\"start\":56136},{\"end\":56166,\"start\":56152},{\"end\":56436,\"start\":56421},{\"end\":56446,\"start\":56436},{\"end\":56460,\"start\":56446},{\"end\":56474,\"start\":56460},{\"end\":56735,\"start\":56719},{\"end\":56751,\"start\":56735},{\"end\":56768,\"start\":56751},{\"end\":57082,\"start\":57064},{\"end\":57106,\"start\":57082},{\"end\":57122,\"start\":57106},{\"end\":57139,\"start\":57122},{\"end\":57464,\"start\":57442},{\"end\":57473,\"start\":57464},{\"end\":57488,\"start\":57473},{\"end\":57493,\"start\":57488},{\"end\":57798,\"start\":57782},{\"end\":58062,\"start\":58046},{\"end\":58087,\"start\":58062},{\"end\":58101,\"start\":58087},{\"end\":58122,\"start\":58101},{\"end\":58373,\"start\":58357},{\"end\":58398,\"start\":58373},{\"end\":58419,\"start\":58398},{\"end\":58658,\"start\":58641},{\"end\":58913,\"start\":58898},{\"end\":58929,\"start\":58913},{\"end\":58945,\"start\":58929},{\"end\":58957,\"start\":58945},{\"end\":59195,\"start\":59177},{\"end\":59207,\"start\":59195},{\"end\":59222,\"start\":59207},{\"end\":59243,\"start\":59222},{\"end\":59264,\"start\":59243},{\"end\":59583,\"start\":59572},{\"end\":59600,\"start\":59583},{\"end\":59617,\"start\":59600},{\"end\":59901,\"start\":59884},{\"end\":59918,\"start\":59901},{\"end\":59935,\"start\":59918},{\"end\":60175,\"start\":60161},{\"end\":60191,\"start\":60175},{\"end\":60565,\"start\":60551},{\"end\":60580,\"start\":60565},{\"end\":60593,\"start\":60580},{\"end\":60604,\"start\":60593},{\"end\":60615,\"start\":60604},{\"end\":60625,\"start\":60615},{\"end\":60636,\"start\":60625},{\"end\":60933,\"start\":60919},{\"end\":60948,\"start\":60933},{\"end\":60958,\"start\":60948},{\"end\":60969,\"start\":60958},{\"end\":61196,\"start\":61182},{\"end\":61210,\"start\":61196},{\"end\":61220,\"start\":61210},{\"end\":61431,\"start\":61420},{\"end\":61446,\"start\":61431},{\"end\":61460,\"start\":61446},{\"end\":61472,\"start\":61460},{\"end\":61778,\"start\":61770},{\"end\":61791,\"start\":61778},{\"end\":61804,\"start\":61791},{\"end\":61816,\"start\":61804},{\"end\":61826,\"start\":61816},{\"end\":61838,\"start\":61826},{\"end\":62258,\"start\":62247},{\"end\":62268,\"start\":62258},{\"end\":62280,\"start\":62268},{\"end\":62295,\"start\":62280},{\"end\":62314,\"start\":62295},{\"end\":62336,\"start\":62314},{\"end\":62353,\"start\":62336},{\"end\":62368,\"start\":62353},{\"end\":62717,\"start\":62704},{\"end\":62728,\"start\":62717},{\"end\":62739,\"start\":62728},{\"end\":62754,\"start\":62739},{\"end\":62768,\"start\":62754},{\"end\":62778,\"start\":62768},{\"end\":63091,\"start\":63078},{\"end\":63102,\"start\":63091},{\"end\":63117,\"start\":63102},{\"end\":63131,\"start\":63117},{\"end\":63421,\"start\":63415},{\"end\":63428,\"start\":63421},{\"end\":63435,\"start\":63428},{\"end\":63441,\"start\":63435},{\"end\":63450,\"start\":63441},{\"end\":63464,\"start\":63450},{\"end\":63474,\"start\":63464},{\"end\":63481,\"start\":63474},{\"end\":63779,\"start\":63763},{\"end\":63794,\"start\":63779},{\"end\":63806,\"start\":63794},{\"end\":63822,\"start\":63806},{\"end\":63833,\"start\":63822},{\"end\":63846,\"start\":63833},{\"end\":63860,\"start\":63846},{\"end\":63875,\"start\":63860},{\"end\":64201,\"start\":64189},{\"end\":64214,\"start\":64201},{\"end\":64228,\"start\":64214},{\"end\":64239,\"start\":64228}]", "bib_venue": "[{\"end\":51907,\"start\":51901},{\"end\":52155,\"start\":52151},{\"end\":52467,\"start\":52458},{\"end\":52762,\"start\":52755},{\"end\":53100,\"start\":53091},{\"end\":53471,\"start\":53463},{\"end\":54469,\"start\":54463},{\"end\":54732,\"start\":54725},{\"end\":54959,\"start\":54952},{\"end\":55183,\"start\":55179},{\"end\":56192,\"start\":56183},{\"end\":56794,\"start\":56785},{\"end\":57165,\"start\":57156},{\"end\":58439,\"start\":58433},{\"end\":58980,\"start\":58977},{\"end\":59955,\"start\":59949},{\"end\":60300,\"start\":60254},{\"end\":60658,\"start\":60651},{\"end\":60992,\"start\":60989},{\"end\":61947,\"start\":61901},{\"end\":62390,\"start\":62383},{\"end\":62803,\"start\":62799},{\"end\":63160,\"start\":63154},{\"end\":63503,\"start\":63496},{\"end\":63899,\"start\":63891},{\"end\":64261,\"start\":64254},{\"end\":51377,\"start\":51342},{\"end\":51620,\"start\":51604},{\"end\":51899,\"start\":51887},{\"end\":52149,\"start\":52130},{\"end\":52456,\"start\":52432},{\"end\":52753,\"start\":52740},{\"end\":53089,\"start\":53074},{\"end\":53461,\"start\":53447},{\"end\":53843,\"start\":53800},{\"end\":54146,\"start\":54072},{\"end\":54461,\"start\":54449},{\"end\":54723,\"start\":54710},{\"end\":54950,\"start\":54937},{\"end\":55177,\"start\":55158},{\"end\":55467,\"start\":55444},{\"end\":55834,\"start\":55783},{\"end\":56181,\"start\":56166},{\"end\":56419,\"start\":56359},{\"end\":56783,\"start\":56768},{\"end\":57154,\"start\":57139},{\"end\":57542,\"start\":57493},{\"end\":57852,\"start\":57798},{\"end\":58044,\"start\":57987},{\"end\":58431,\"start\":58419},{\"end\":58694,\"start\":58674},{\"end\":58975,\"start\":58957},{\"end\":59315,\"start\":59288},{\"end\":59653,\"start\":59617},{\"end\":59947,\"start\":59935},{\"end\":60252,\"start\":60191},{\"end\":60649,\"start\":60636},{\"end\":60987,\"start\":60969},{\"end\":61180,\"start\":61135},{\"end\":61528,\"start\":61472},{\"end\":61899,\"start\":61838},{\"end\":62381,\"start\":62368},{\"end\":62797,\"start\":62778},{\"end\":63152,\"start\":63131},{\"end\":63494,\"start\":63481},{\"end\":63889,\"start\":63875},{\"end\":64252,\"start\":64239}]"}}}, "year": 2023, "month": 12, "day": 17}