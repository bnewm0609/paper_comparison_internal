{"id": 259108339, "updated": "2023-10-05 00:11:20.894", "metadata": {"title": "RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit", "authors": "[{\"first\":\"Jiongnan\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Jiajie\",\"last\":\"Jin\",\"middle\":[]},{\"first\":\"Zihan\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Jiehan\",\"last\":\"Cheng\",\"middle\":[]},{\"first\":\"Zhicheng\",\"last\":\"Dou\",\"middle\":[]},{\"first\":\"Ji-Rong\",\"last\":\"Wen\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Although Large Language Models (LLMs) have demonstrated extraordinary capabilities in many domains, they still have a tendency to hallucinate and generate fictitious responses to user requests. This problem can be alleviated by augmenting LLMs with information retrieval (IR) systems (also known as retrieval-augmented LLMs). Applying this strategy, LLMs can generate more factual texts in response to user input according to the relevant content retrieved by IR systems from external corpora as references. In addition, by incorporating external knowledge, retrieval-augmented LLMs can answer in-domain questions that cannot be answered by solely relying on the world knowledge stored in parameters. To support research in this area and facilitate the development of retrieval-augmented LLM systems, we develop RETA-LLM, a {RET}reival-{A}ugmented LLM toolkit. In RETA-LLM, we create a complete pipeline to help researchers and users build their customized in-domain LLM-based systems. Compared with previous retrieval-augmented LLM systems, RETA-LLM provides more plug-and-play modules to support better interaction between IR systems and LLMs, including {request rewriting, document retrieval, passage extraction, answer generation, and fact checking} modules. Our toolkit is publicly available at https://github.com/RUC-GSAI/YuLan-IR/tree/main/RETA-LLM.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2306.05212", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2306-05212", "doi": "10.48550/arxiv.2306.05212"}}, "content": {"source": {"pdf_hash": "cc78babfacce48e715dac56886d7dd9746cfcab0", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2306.05212v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "aad0982fb7bc812247eb8ee3df41a475a9fcd61e", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/cc78babfacce48e715dac56886d7dd9746cfcab0.txt", "contents": "\nRETA-LLM: A Retrieval-Augmented Large Language Model Toolkit\n\n\nJiongnan Liu \nGaoling School of Artificial Intelligence\nRenmin University of China\n\n\nJiajie Jin \nUniversity of Science and Technology of China\n\n\nZihan Wang \nGaoling School of Artificial Intelligence\nRenmin University of China\n\n\nJiehan Cheng \nGaoling School of Artificial Intelligence\nRenmin University of China\n\n\nZhicheng Dou \nGaoling School of Artificial Intelligence\nRenmin University of China\n\n\nJi-Rong Wen jrwen@ruc.edu.cn2jinjiajie@mail.ustc.edu.cn \nGaoling School of Artificial Intelligence\nRenmin University of China\n\n\nRETA-LLM: A Retrieval-Augmented Large Language Model Toolkit\n\nAlthough Large Language Models (LLMs) have demonstrated extraordinary capabilities in many domains, they still have a tendency to hallucinate and generate fictitious responses to user requests. This problem can be alleviated by augmenting LLMs with information retrieval (IR) systems (also known as retrievalaugmented LLMs). Applying this strategy, LLMs can generate more factual texts in response to user input according to the relevant content retrieved by IR systems from external corpora as references. In addition, by incorporating external knowledge, retrieval-augmented LLMs can answer in-domain questions that cannot be answered by solely relying on the world knowledge stored in parameters. To support research in this area and facilitate the development of retrieval-augmented LLM systems, we develop RETA-LLM, a RETreival-Augmented LLM toolkit. In RETA-LLM, we create a complete pipeline to help researchers and users build their customized in-domain LLM-based systems. Compared with previous retrieval-augmented LLM systems, RETA-LLM provides more plug-and-play modules to support better interaction between IR systems and LLMs, including request rewriting, document retrieval, passage extraction, answer generation, and fact checking modules. Our toolkit is publicly available at https://github.com/ RUC-GSAI/YuLan-IR/tree/main/RETA-LLM.\n\nIntroduction\n\nLarge language models (LLMs) have attracted increasing attention from both research community and industry (Brown et al., 2020;OpenAI, 2023;Touvron et al., 2023;Chowdhery et al., 2022;Zeng et al., 2022). With tremendous world knowledge stored in parameters (Petroni et al., 2019;Roberts et al., 2020;Jiang et al., 2020) and the Reinforcement Learning * Corresponding author.\n\nfrom Human Feedback (RLHF) techniques (Christiano et al., 2017;Ziegler et al., 2019), LLMs can generate helpful, detailed, and polite texts in response to user inputs. Many studies have demonstrated LLMs' extraordinary abilities in various areas, including nature language processing (Moslem et al., 2023), information retrieval (Sun et al., 2023;Wang et al., 2023;Mao et al., 2023), and recommendation .\n\nHowever, LLMs still tend to hallucinate and sometimes generate texts opposite to facts (Zhou et al., 2021;. To tackle these problems, researchers have proposed a new paradigm to strengthen LLMs with information retrieval systems (retrieval-augmented LLMs) (Shi et al., 2023;Jiang et al., 2023;Nakano et al., 2022), which enables LLMs to retrieve relevant contents from an external repository (knowledge corpus) to generate texts based on them. It has been verified that retrieval-augmented LLMs can generate texts in response to user input with fewer hallucinations (Nakano et al., 2022). Furthermore, by incorporating customized private data resources, retrieval-augmented LLMs can respond to in-domain queries that cannot be answered by LLMs trained with public data.\n\nTo support research in this area and help users build their own in-domain LLM-based systems, we devise RETA-LLM, a RETreival-Augmented LLM toolkit. Different from previous general LLMenhanced toolkits such as LangChain, 1 RETA-LLM focuses on the retrieval-augmented LLMs and provides more plug-in modules. Typically, retrieval-augmented LLMs use a retrieve-andgenerate strategy with two modules: First, they retrieve documents or passages based on user request (document retrieval module); then, they generate answers utilizing these relevant documents as references (answer generation module). In addi-\n\n\nLLMs\n\nUser Request \"How about School of Economics\"\n\nStep 1 request rewriting module \n\n\nIR Systems\n\nStep 2 document retrieval module\n\nStep 3 passage extraction module References [\"Economics major \u2026\", \"Digital economics major \u2026\", \u2026]\n\nStep 4 answer generation module Generated Answers \"There are three majors in this school.\n\nEconomics major \u2026\"\n\nStep 5 fact checking module  tion to these two basic modules, our RETA-LLM provides three optional modules: (1) a request rewriting module to make user's current request more complete and clear; (2) a passage extraction module to extract relevant passages or fragments from the whole retrieved document contents; and (3) a fact checking module to verify whether there exist factual errors in the generated answers. These optional modules can make the interaction between IR systems and LLMs more effective and smooth. The disentanglement between LLMs and IR systems in our RETA-LLM is more thorough, which makes the customization of search engines and LLMs more convenient. Furthermore, to make the usage easier, we provide a complete and ready-touse pipeline for researchers and users to build their RETA-LLM toolkits based on their own repository for in-domain LLM-based systems from scratch.\n\nRETA-LLM is part of YuLan, a open source LLM initiative proposed by Gaoling School of Artificial Intelligence, Renmin University of China. RETA-LLM is still under development and there are many issues that need to be solved with great efforts. We sincerely welcome contributions on this open source toolkit.\n\n\nRETA-LLM Framework\n\nAs aforementioned, compared with Langchain, which is a common LLM-augmented toolkit, our RETA-LLM toolkit focuses specifically on retrieval-augmented LLMs. We provide five plugin modules in RETA-LLM to interact with LLMs and IR systems. The modules include request rewriting, document retrieval, passage extraction, answer generation, and fact checking modules. The framework of our RETA-LLM is shown in Figure 1. The workflow of RETA-LLM is as follows:\n\nFirst, RETA-LLM uses the request rewriting module to revise the current user request to make it complete and clear. Because users can issue a series of questions to the RETA-LLM, the semantics of the current user request may be incomplete. For example, A user may ask \"How about the School of Economics?\" while the historical request is \"Introduce the majors in School of Information\". In this case, the precise meaning of the user is \"Introduce the majors in School of Economics\". Since LLMs have shown remarkable abilities in rewriting queries in conversational dense retrieval (Mao et al., 2023), we feed the current user request and the previous conversation histories to LLMs to perform rewriting.\n\nThen, RETA-LLM uses the document retrieval module to retrieve relevant documents from the external corpus based on the revised user request. The document retrieval module is the module connected to the IR system. It retrieves relevant documents from the external knowledge corpus and returns top-K of them. The K is set to 3 in our default configuration. We provide a default dense retriever in our repository. The detailed description can be found in the next section.\n\nNext, RETA-LLM uses the passage extraction module to extract fragments related to the user request from the retrieved documents to form the references. Because of the input length limitations (typically 2048 or 4096 tokens) of LLMs, it is impossible to directly concatenate the contents of all top-K relevant document contents as references for them to generate answers. Trivial methods by truncating the document contents may lose important information in them. Therefore, we reuse the LLMs themselves to extract related fragments from retrieved documents based on the revised request. Since the length of one document may also exceed the limitations, we apply the sliding window strategy to extract fragments step by step. The sliding window size and step are set to 512 and 256 in our default configuration. These fragments are then concatenated together as the references.\n\nBesides, RETA-LLM uses the answer generation module to generate answers for the user request. As previous researches (Nakano et al., 2022;Shi et al., 2023;Jiang et al., 2023) suggest, by feeding the references retrieved from the external corpus, LLMs can generate more factual answers.\n\nFinally, RETA-LLM uses the fact checking module to verify whether the generated answers contain factual mistakes and output final responses for the user request. Though providing additional evidence for generation, LLMs may also hallucinate (Nakano et al., 2022). It is necessary to devise a module to conduct further fact verification. Because of the strong natural language understanding abilities of LLMs, we feed the references and generated answers to them to make judgments. Therefore, RETA-LLM can decide whether to output the generated answers or just say \"I cannot answer this question\".\n\nNoticed that all the inputs to the LLMs are wrapped in instructions or prompts. As shown in Figure 1, we disentangle the IR systems and LLMs entirely in our RETA-LLM. This separate design in our RETA-LLM leads users can customize their personal search engines and LLMs.\n\n\nRETA-LLM Usage Pipeline\n\nTo make the toolkit more convenient for personal usage, we provide a complete pipeline to build in-domain LLM-based system based on html resources. The pipeline is as follows:\n\nFirst, RETA-LLM uses Beautiful Soup package to convert the raw html files into json data in our HTML Converter. 2 Second, RETA-LLM follows the implementation of disentangled-retriever (Zhan et al., 2022) to build dense indexes and to conduct domain adaption from the converted json data in our Index Builder. 3 Specifically, our method supports unsupervised training of dense retrieval models on local document collections, enabling the model to learn domain-specific knowledge in advance. Compared with the retrieval module in the popular LangChain library, our retrieval method has two advantages:\n\n(1) the model learns knowledge within the domain of local documents, enabling it to match queries more accurately, and (2) our method does not segment text, thus avoiding any negative impact on the overall semantic information of the text. We also provide a sparse retriever applying faiss (Johnson et al., 2019) package to build sparse indexes. 4 Otherwise, users can also use their customized search engines as the document retrieval module.\n\nThird, users need to prepare LLMs for question answering. For LLM loading and responding, we provide the template for Alpaca (Taori et al., 2023), 5 , YuLan-Chat, 6 ChatGLM (Zeng et al., 2022;, 7 and GPT-3.5 API   More details about the usage pipeline can be found on our GitHub repository.\n\n\nA RETA-LLM Service Case\n\nBased on the RETA-LLM and the usage pipeline, we use the web pages on Renmin University of China's enrollment online platform, 10 to build an RUC-enrollment-assistant system. The system uses a dense document retrieval module and adopts YuLan-13B as the backbone LLM. A using case is shown in 2. By enhancing the IR systems, LLMs can answer in-domain questions which cannot be answered by their own knowledge.\n\n\nConclusion and Future Work\n\nIn this paper, we propose RETA-LLM to facilitate research and development of retrieval-augmented LLMs. We provide five independent modules: request rewriting, document retrieval, passage extraction, answer generation, and fact checking modules in our toolkit. Furthermore, we provide a pipeline to help users build their in-domain LLM-based systems. In the future, we are going to include more retrieval-augmented LLM strategies such as active retrieval augmented generation (Jiang et al., 2023). Besides, we plan to make RETA-LLM more modulized and configurable.\n\n:\nEconomics major's web page. 2 : Digital economics major's web page. 3 : International economics and trade major's web page. \u22ef : School of Applied Economics' web page\n\nFigure 1 :\n1The RETA-LLM framework. Examples are taken from an intelligent university information seeking system powered by RETA-LLM.\n\nFigure 2 :\n2A case in RUC-enrollment-assistant system.\n\n\n). 8 If users use other LLMs, they can edit the codes and configurations in our toolkit.Finally, users can start their own RETA-LLM services using streamlit package. 9 Alpaca,https://github.com/tatsu-lab/stanford_ alpaca YuLan-Chat, https://github.com/RUC-GSAI/ YuLan-Chat 7 ChatGLM, https://github.com/THUDM/ChatGLM-6B2 Beautiful \nSoup, \nhttps://beautiful-soup-4. \nreadthedocs.io/en/latest/ \n3 disentagled-retriever, \nhttps://github.com/ \njingtaozhan/disentangled-retriever \n4 Faiss, \nhttps://github.com/facebookresearch/ \nfaiss \n5 6 \n\n8 OpenAI's \nAPI, \nhttps://api.openai.com/v1/ \ncompletions \n9 streamlit, \nhttps://github.com/streamlit/ \nstreamlit \n\n\nLangChain, https://github.com/hwchase17/ langchain\nRenmin University of China's enrollment online platform, https://rdzs.ruc.edu.cn\n\nIlya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec RadfordCurran Associates, Inc33Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma- teusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems, volume 33, pages 1877-1901. Curran Associates, Inc.\n\n. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won, Charles Chung, Sebastian Sutton, Parker Gehrmann, Kensen Schuh, Sasha Shi, Joshua Tsvyashchenko, Abhishek Maynez, Parker Rao, Yi Barnes, Noam Tay, Vinodkumar Shazeer, Emily Prabhakaran, Nan Reif, Ben Du, Reiner Hutchinson, James Pope, Jacob Bradbury, Michael Austin, Guy Isard, Pengcheng Gur-Ari, Toju Yin, Anselm Duke, Sanjay Levskaya, Sunipa Ghemawat, Henryk Dev, Xavier Michalewski, Vedant Garcia, Kevin Misra, Liam Robinson, Denny Fedus, Daphne Zhou, David Ippolito, Hyeontaek Luan, Lim, M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-HellsternBarret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick; Douglas Eck, Jeff Dean, Slav Petrovand Noah Fiedel. 2022. Palm: Scaling language modeling with pathways. CoRR, abs/2204.02311Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin- odkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, An- drew M. Dai, Thanumalayan Sankaranarayana Pil- lai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. 2022. Palm: Scaling language mod- eling with pathways. CoRR, abs/2204.02311.\n\nDeep reinforcement learning from human preferences. Paul F Christiano, Jan Leike, Tom B Brown, Miljan Martic, Shane Legg, Dario Amodei, NIPS. Paul F. Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, and Dario Amodei. 2017. Deep reinforcement learning from human preferences. In NIPS, pages 4299-4307.\n\nGlm: General language model pretraining with autoregressive blank infilling. Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, Jie Tang, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsLong Papers1Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. Glm: General language model pretraining with autoregres- sive blank infilling. In Proceedings of the 60th An- nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 320-335.\n\nLarge language models are zero-shot rankers for recommender systems. Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian Mcauley, Wayne Xin Zhao, Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, and Wayne Xin Zhao. 2023. Large language models are zero-shot rankers for recommender systems.\n\nHow Can We Know What Language Models Know?. Zhengbao Jiang, Frank F Xu, Jun Araki, Graham Neubig, 10.1162/tacl_a_00324Transactions of the Association for Computational Linguistics. 8Zhengbao Jiang, Frank F. Xu, Jun Araki, and Graham Neubig. 2020. How Can We Know What Language Models Know? Transactions of the Association for Computational Linguistics, 8:423-438.\n\n. Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie\n\nActive retrieval augmented generation. Graham Callan, Neubig, Callan, and Graham Neubig. 2023. Active retrieval augmented generation.\n\nBillion-scale similarity search with GPUs. Jeff Johnson, Matthijs Douze, Herv\u00e9 J\u00e9gou, IEEE Transactions on Big Data. 73Jeff Johnson, Matthijs Douze, and Herv\u00e9 J\u00e9gou. 2019. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data, 7(3):535-547.\n\nLarge language models know your contextual search intent: A prompting framework for conversational search. Kelong Mao, Zhicheng Dou, Haonan Chen, Fengran Mo, Hongjin Qian, Kelong Mao, Zhicheng Dou, Haonan Chen, Fengran Mo, and Hongjin Qian. 2023. Large language models know your contextual search intent: A prompting framework for conversational search.\n\nAdaptive machine translation with large language models. Yasmin Moslem, Rejwanul Haque, John D Kelleher, Andy Way, Yasmin Moslem, Rejwanul Haque, John D. Kelleher, and Andy Way. 2023. Adaptive machine translation with large language models.\n\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Webgpt: Browserassisted question-answering with human feedback. Kevin Button, Matthew Knight, Benjamin Chess, and John SchulmanReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. 2022. Webgpt: Browser- assisted question-answering with human feedback.\n\n. OpenAI. 2023. Gpt-4 technical report. OpenAI. 2023. Gpt-4 technical report.\n\nTraining language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, NeurIPS. Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda AskellPaul F. ChristianoPeter WelinderLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welin- der, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instruc- tions with human feedback. In NeurIPS.\n\nLanguage models as knowledge bases?. Fabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander Miller, 10.18653/v1/D19-1250Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational LinguisticsFabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. Language models as knowl- edge bases? In Proceedings of the 2019 Confer- ence on Empirical Methods in Natural Language Pro- cessing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2463-2473, Hong Kong, China. Association for Computational Linguistics.\n\nHow much knowledge can you pack into the parameters of a language model. Adam Roberts, Colin Raffel, Noam Shazeer, 10.18653/v1/2020.emnlp-main.437Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational LinguisticsAdam Roberts, Colin Raffel, and Noam Shazeer. 2020. How much knowledge can you pack into the param- eters of a language model? In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5418-5426, Online. Association for Computational Linguistics.\n\nREPLUG: retrieval-augmented black-box language models. Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, Wen-Tau Yih, abs/2301.12652CoRRWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023. REPLUG: retrieval-augmented black-box language models. CoRR, abs/2301.12652.\n\nIs chatgpt good at search? investigating large language models as re-ranking agent. Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren, Dawei Yin, Zhaochun Ren, Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren, Dawei Yin, and Zhaochun Ren. 2023. Is chatgpt good at search? investigating large language models as re-ranking agent.\n\nStanford alpaca: An instruction-following llama model. Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, Tatsunori B Hashimoto, Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford alpaca: An instruction-following llama model. https:// github.com/tatsu-lab/stanford_alpaca.\n\n. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Naman Baptiste Rozi\u00e8re, Eric Goyal, Faisal Hambro, Aur\u00e9lien Azhar, Armand Rodriguez, Joulin, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models. CoRR, abs/2302.13971Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aur\u00e9lien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. Llama: Open and efficient foundation language models. CoRR, abs/2302.13971.\n\nQuery2doc: Query expansion with large language models. Liang Wang, Nan Yang, Furu Wei, abs/2303.07678CoRRLiang Wang, Nan Yang, and Furu Wei. 2023. Query2doc: Query expansion with large language models. CoRR, abs/2303.07678.\n\nAohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, arXiv:2210.02414Glm-130b: An open bilingual pre-trained model. arXiv preprintAohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414.\n\nDisentangled modeling of domain and relevance for adaptable dense retrieval. Jingtao Zhan, Qingyao Ai, Yiqun Liu, Jiaxin Mao, Xiaohui Xie, Min Zhang, Shaoping Ma, arXiv:2208.05753arXiv preprintJingtao Zhan, Qingyao Ai, Yiqun Liu, Jiaxin Mao, Xi- aohui Xie, Min Zhang, and Shaoping Ma. 2022. Disentangled modeling of domain and relevance for adaptable dense retrieval. arXiv preprint arXiv:2208.05753.\n\nRecommendation as instruction following: A large language model empowered recommendation approach. Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, Ji-Rong Wen, abs/2305.07001CoRRJunjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, and Ji-Rong Wen. 2023. Recom- mendation as instruction following: A large lan- guage model empowered recommendation approach. CoRR, abs/2305.07001.\n\n. Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Yifan Dong, Chen Du, Yushuo Yang, Zhipeng Chen, Jinhao Chen, Ruiyang Jiang, Yifan Ren, Xinyu Li, Zikang Tang, Peiyu Liu, Jian-Yun Liu, Ji-Rong Nie, Wen, 2023. A survey of large language modelsWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A survey of large language models.\n\nDetecting hallucinated content in conditional neural sequence generation. Chunting Zhou, Graham Neubig, Jiatao Gu, Mona Diab, Francisco Guzm\u00e1n, Luke Zettlemoyer, Marjan Ghazvininejad, 10.18653/v1/2021.findings-acl.120Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Online. Association for Computational LinguisticsChunting Zhou, Graham Neubig, Jiatao Gu, Mona Diab, Francisco Guzm\u00e1n, Luke Zettlemoyer, and Marjan Ghazvininejad. 2021. Detecting hallucinated content in conditional neural sequence generation. In Find- ings of the Association for Computational Linguis- tics: ACL-IJCNLP 2021, pages 1393-1404, Online. Association for Computational Linguistics.\n\nFine-tuning language models from human preferences. M Daniel, Nisan Ziegler, Jeffrey Stiennon, Tom B Wu, Alec Brown, Dario Radford, Paul F Amodei, Geoffrey Christiano, Irving, abs/1909.08593CoRRDaniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul F. Chris- tiano, and Geoffrey Irving. 2019. Fine-tuning lan- guage models from human preferences. CoRR, abs/1909.08593.\n", "annotations": {"author": "[{\"end\":148,\"start\":64},{\"end\":208,\"start\":149},{\"end\":291,\"start\":209},{\"end\":376,\"start\":292},{\"end\":461,\"start\":377},{\"end\":589,\"start\":462}]", "publisher": null, "author_last_name": "[{\"end\":76,\"start\":73},{\"end\":159,\"start\":156},{\"end\":219,\"start\":215},{\"end\":304,\"start\":299},{\"end\":389,\"start\":386},{\"end\":473,\"start\":470}]", "author_first_name": "[{\"end\":72,\"start\":64},{\"end\":155,\"start\":149},{\"end\":214,\"start\":209},{\"end\":298,\"start\":292},{\"end\":385,\"start\":377},{\"end\":469,\"start\":462}]", "author_affiliation": "[{\"end\":147,\"start\":78},{\"end\":207,\"start\":161},{\"end\":290,\"start\":221},{\"end\":375,\"start\":306},{\"end\":460,\"start\":391},{\"end\":588,\"start\":519}]", "title": "[{\"end\":61,\"start\":1},{\"end\":650,\"start\":590}]", "venue": null, "abstract": "[{\"end\":2002,\"start\":652}]", "bib_ref": "[{\"end\":2145,\"start\":2125},{\"end\":2158,\"start\":2145},{\"end\":2179,\"start\":2158},{\"end\":2202,\"start\":2179},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2220,\"start\":2202},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2297,\"start\":2275},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2318,\"start\":2297},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2337,\"start\":2318},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2457,\"start\":2432},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":2478,\"start\":2457},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2699,\"start\":2678},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2741,\"start\":2723},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2759,\"start\":2741},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2776,\"start\":2759},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2906,\"start\":2887},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3074,\"start\":3056},{\"end\":3093,\"start\":3074},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3113,\"start\":3093},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3387,\"start\":3366},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6799,\"start\":6781},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8392,\"start\":8371},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8409,\"start\":8392},{\"end\":8428,\"start\":8409},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8803,\"start\":8782},{\"end\":9726,\"start\":9725},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9816,\"start\":9797},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10526,\"start\":10504},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10804,\"start\":10784},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10851,\"start\":10832},{\"end\":11911,\"start\":11891}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":12148,\"start\":11980},{\"attributes\":{\"id\":\"fig_1\"},\"end\":12283,\"start\":12149},{\"attributes\":{\"id\":\"fig_2\"},\"end\":12339,\"start\":12284},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":12995,\"start\":12340}]", "paragraph": "[{\"end\":2392,\"start\":2018},{\"end\":2798,\"start\":2394},{\"end\":3569,\"start\":2800},{\"end\":4174,\"start\":3571},{\"end\":4227,\"start\":4183},{\"end\":4261,\"start\":4229},{\"end\":4308,\"start\":4276},{\"end\":4407,\"start\":4310},{\"end\":4498,\"start\":4409},{\"end\":4518,\"start\":4500},{\"end\":5414,\"start\":4520},{\"end\":5723,\"start\":5416},{\"end\":6199,\"start\":5746},{\"end\":6903,\"start\":6201},{\"end\":7374,\"start\":6905},{\"end\":8252,\"start\":7376},{\"end\":8539,\"start\":8254},{\"end\":9137,\"start\":8541},{\"end\":9408,\"start\":9139},{\"end\":9611,\"start\":9436},{\"end\":10212,\"start\":9613},{\"end\":10657,\"start\":10214},{\"end\":10949,\"start\":10659},{\"end\":11385,\"start\":10977},{\"end\":11979,\"start\":11416}]", "formula": null, "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2016,\"start\":2004},{\"end\":4181,\"start\":4177},{\"end\":4274,\"start\":4264},{\"attributes\":{\"n\":\"2\"},\"end\":5744,\"start\":5726},{\"attributes\":{\"n\":\"3\"},\"end\":9434,\"start\":9411},{\"attributes\":{\"n\":\"4\"},\"end\":10975,\"start\":10952},{\"attributes\":{\"n\":\"5\"},\"end\":11414,\"start\":11388},{\"end\":11982,\"start\":11981},{\"end\":12160,\"start\":12150},{\"end\":12295,\"start\":12285}]", "table": "[{\"end\":12995,\"start\":12661}]", "figure_caption": "[{\"end\":12148,\"start\":11983},{\"end\":12283,\"start\":12162},{\"end\":12339,\"start\":12297},{\"end\":12661,\"start\":12342}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":6158,\"start\":6150},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9239,\"start\":9231}]", "bib_author_first_name": "[{\"end\":13211,\"start\":13208},{\"end\":13227,\"start\":13219},{\"end\":13238,\"start\":13234},{\"end\":13253,\"start\":13246},{\"end\":13268,\"start\":13263},{\"end\":13270,\"start\":13269},{\"end\":13287,\"start\":13279},{\"end\":13304,\"start\":13298},{\"end\":13324,\"start\":13318},{\"end\":13338,\"start\":13332},{\"end\":13353,\"start\":13347},{\"end\":13370,\"start\":13362},{\"end\":13385,\"start\":13380},{\"end\":13408,\"start\":13400},{\"end\":13421,\"start\":13418},{\"end\":13437,\"start\":13432},{\"end\":13451,\"start\":13445},{\"end\":13466,\"start\":13460},{\"end\":13483,\"start\":13476},{\"end\":13495,\"start\":13488},{\"end\":13509,\"start\":13504},{\"end\":13521,\"start\":13517},{\"end\":13532,\"start\":13528},{\"end\":13548,\"start\":13541},{\"end\":14360,\"start\":14351},{\"end\":14378,\"start\":14372},{\"end\":14392,\"start\":14387},{\"end\":14408,\"start\":14401},{\"end\":14422,\"start\":14416},{\"end\":14435,\"start\":14431},{\"end\":14449,\"start\":14445},{\"end\":14476,\"start\":14469},{\"end\":14493,\"start\":14484},{\"end\":14508,\"start\":14502},{\"end\":14525,\"start\":14519},{\"end\":14538,\"start\":14533},{\"end\":14550,\"start\":14544},{\"end\":14574,\"start\":14566},{\"end\":14589,\"start\":14583},{\"end\":14597,\"start\":14595},{\"end\":14610,\"start\":14606},{\"end\":14626,\"start\":14616},{\"end\":14641,\"start\":14636},{\"end\":14658,\"start\":14655},{\"end\":14668,\"start\":14665},{\"end\":14679,\"start\":14673},{\"end\":14697,\"start\":14692},{\"end\":14709,\"start\":14704},{\"end\":14727,\"start\":14720},{\"end\":14739,\"start\":14736},{\"end\":14756,\"start\":14747},{\"end\":14770,\"start\":14766},{\"end\":14782,\"start\":14776},{\"end\":14795,\"start\":14789},{\"end\":14812,\"start\":14806},{\"end\":14829,\"start\":14823},{\"end\":14841,\"start\":14835},{\"end\":14861,\"start\":14855},{\"end\":14875,\"start\":14870},{\"end\":14887,\"start\":14883},{\"end\":14903,\"start\":14898},{\"end\":14917,\"start\":14911},{\"end\":14929,\"start\":14924},{\"end\":14949,\"start\":14940},{\"end\":16592,\"start\":16588},{\"end\":16594,\"start\":16593},{\"end\":16610,\"start\":16607},{\"end\":16621,\"start\":16618},{\"end\":16623,\"start\":16622},{\"end\":16637,\"start\":16631},{\"end\":16651,\"start\":16646},{\"end\":16663,\"start\":16658},{\"end\":16939,\"start\":16930},{\"end\":16949,\"start\":16944},{\"end\":16960,\"start\":16956},{\"end\":16970,\"start\":16966},{\"end\":16985,\"start\":16977},{\"end\":16997,\"start\":16991},{\"end\":17007,\"start\":17004},{\"end\":17569,\"start\":17563},{\"end\":17581,\"start\":17575},{\"end\":17594,\"start\":17589},{\"end\":17606,\"start\":17600},{\"end\":17618,\"start\":17611},{\"end\":17630,\"start\":17624},{\"end\":17649,\"start\":17640},{\"end\":17881,\"start\":17873},{\"end\":17894,\"start\":17889},{\"end\":17896,\"start\":17895},{\"end\":17904,\"start\":17901},{\"end\":17918,\"start\":17912},{\"end\":18204,\"start\":18196},{\"end\":18217,\"start\":18212},{\"end\":18219,\"start\":18218},{\"end\":18228,\"start\":18224},{\"end\":18241,\"start\":18234},{\"end\":18251,\"start\":18247},{\"end\":18261,\"start\":18257},{\"end\":18280,\"start\":18274},{\"end\":18431,\"start\":18425},{\"end\":18568,\"start\":18564},{\"end\":18586,\"start\":18578},{\"end\":18599,\"start\":18594},{\"end\":18895,\"start\":18889},{\"end\":18909,\"start\":18901},{\"end\":18921,\"start\":18915},{\"end\":18935,\"start\":18928},{\"end\":18947,\"start\":18940},{\"end\":19200,\"start\":19194},{\"end\":19217,\"start\":19209},{\"end\":19229,\"start\":19225},{\"end\":19231,\"start\":19230},{\"end\":19246,\"start\":19242},{\"end\":19388,\"start\":19379},{\"end\":19402,\"start\":19397},{\"end\":19417,\"start\":19411},{\"end\":19430,\"start\":19426},{\"end\":19439,\"start\":19435},{\"end\":19457,\"start\":19448},{\"end\":19474,\"start\":19463},{\"end\":19490,\"start\":19482},{\"end\":19503,\"start\":19497},{\"end\":19521,\"start\":19514},{\"end\":19534,\"start\":19532},{\"end\":19546,\"start\":19542},{\"end\":19558,\"start\":19554},{\"end\":19577,\"start\":19569},{\"end\":20212,\"start\":20208},{\"end\":20228,\"start\":20221},{\"end\":20235,\"start\":20233},{\"end\":20248,\"start\":20243},{\"end\":20265,\"start\":20258},{\"end\":20267,\"start\":20266},{\"end\":20286,\"start\":20280},{\"end\":20301,\"start\":20296},{\"end\":20317,\"start\":20309},{\"end\":20335,\"start\":20327},{\"end\":20347,\"start\":20343},{\"end\":20357,\"start\":20353},{\"end\":20908,\"start\":20903},{\"end\":20921,\"start\":20918},{\"end\":20944,\"start\":20935},{\"end\":20960,\"start\":20953},{\"end\":20973,\"start\":20968},{\"end\":20990,\"start\":20983},{\"end\":21004,\"start\":20995},{\"end\":21925,\"start\":21921},{\"end\":21940,\"start\":21935},{\"end\":21953,\"start\":21949},{\"end\":22574,\"start\":22568},{\"end\":22585,\"start\":22580},{\"end\":22600,\"start\":22591},{\"end\":22618,\"start\":22611},{\"end\":22628,\"start\":22624},{\"end\":22640,\"start\":22636},{\"end\":22652,\"start\":22648},{\"end\":22673,\"start\":22666},{\"end\":22986,\"start\":22980},{\"end\":23000,\"start\":22992},{\"end\":23011,\"start\":23006},{\"end\":23023,\"start\":23016},{\"end\":23034,\"start\":23029},{\"end\":23048,\"start\":23040},{\"end\":23283,\"start\":23278},{\"end\":23297,\"start\":23291},{\"end\":23315,\"start\":23309},{\"end\":23327,\"start\":23323},{\"end\":23343,\"start\":23336},{\"end\":23354,\"start\":23348},{\"end\":23370,\"start\":23365},{\"end\":23387,\"start\":23378},{\"end\":23389,\"start\":23388},{\"end\":23644,\"start\":23640},{\"end\":23661,\"start\":23654},{\"end\":23677,\"start\":23670},{\"end\":23693,\"start\":23687},{\"end\":23714,\"start\":23704},{\"end\":23732,\"start\":23724},{\"end\":23747,\"start\":23742},{\"end\":23770,\"start\":23766},{\"end\":23784,\"start\":23778},{\"end\":23801,\"start\":23793},{\"end\":23815,\"start\":23809},{\"end\":24312,\"start\":24307},{\"end\":24322,\"start\":24319},{\"end\":24333,\"start\":24329},{\"end\":24482,\"start\":24477},{\"end\":24493,\"start\":24489},{\"end\":24508,\"start\":24499},{\"end\":24518,\"start\":24513},{\"end\":24530,\"start\":24525},{\"end\":24540,\"start\":24536},{\"end\":24553,\"start\":24547},{\"end\":24565,\"start\":24560},{\"end\":24575,\"start\":24570},{\"end\":24587,\"start\":24583},{\"end\":24964,\"start\":24957},{\"end\":24978,\"start\":24971},{\"end\":24988,\"start\":24983},{\"end\":25000,\"start\":24994},{\"end\":25013,\"start\":25006},{\"end\":25022,\"start\":25019},{\"end\":25038,\"start\":25030},{\"end\":25387,\"start\":25381},{\"end\":25402,\"start\":25395},{\"end\":25414,\"start\":25408},{\"end\":25425,\"start\":25420},{\"end\":25429,\"start\":25426},{\"end\":25440,\"start\":25436},{\"end\":25453,\"start\":25446},{\"end\":25696,\"start\":25693},{\"end\":25718,\"start\":25713},{\"end\":25731,\"start\":25725},{\"end\":25743,\"start\":25736},{\"end\":25756,\"start\":25750},{\"end\":25771,\"start\":25763},{\"end\":25784,\"start\":25777},{\"end\":25796,\"start\":25790},{\"end\":25809,\"start\":25804},{\"end\":25822,\"start\":25817},{\"end\":25833,\"start\":25829},{\"end\":25844,\"start\":25838},{\"end\":25858,\"start\":25851},{\"end\":25871,\"start\":25865},{\"end\":25885,\"start\":25878},{\"end\":25898,\"start\":25893},{\"end\":25909,\"start\":25904},{\"end\":25920,\"start\":25914},{\"end\":25932,\"start\":25927},{\"end\":25946,\"start\":25938},{\"end\":25959,\"start\":25952},{\"end\":26414,\"start\":26406},{\"end\":26427,\"start\":26421},{\"end\":26442,\"start\":26436},{\"end\":26451,\"start\":26447},{\"end\":26467,\"start\":26458},{\"end\":26480,\"start\":26476},{\"end\":26500,\"start\":26494},{\"end\":27073,\"start\":27072},{\"end\":27087,\"start\":27082},{\"end\":27104,\"start\":27097},{\"end\":27118,\"start\":27115},{\"end\":27120,\"start\":27119},{\"end\":27129,\"start\":27125},{\"end\":27142,\"start\":27137},{\"end\":27156,\"start\":27152},{\"end\":27158,\"start\":27157},{\"end\":27175,\"start\":27167}]", "bib_author_last_name": "[{\"end\":13217,\"start\":13212},{\"end\":13232,\"start\":13228},{\"end\":13244,\"start\":13239},{\"end\":13261,\"start\":13254},{\"end\":13277,\"start\":13271},{\"end\":13296,\"start\":13288},{\"end\":13316,\"start\":13305},{\"end\":13330,\"start\":13325},{\"end\":13345,\"start\":13339},{\"end\":13360,\"start\":13354},{\"end\":13378,\"start\":13371},{\"end\":13398,\"start\":13386},{\"end\":13416,\"start\":13409},{\"end\":13430,\"start\":13422},{\"end\":13443,\"start\":13438},{\"end\":13458,\"start\":13452},{\"end\":13474,\"start\":13467},{\"end\":13486,\"start\":13484},{\"end\":13502,\"start\":13496},{\"end\":13515,\"start\":13510},{\"end\":13526,\"start\":13522},{\"end\":13539,\"start\":13533},{\"end\":13555,\"start\":13549},{\"end\":14370,\"start\":14361},{\"end\":14385,\"start\":14379},{\"end\":14399,\"start\":14393},{\"end\":14414,\"start\":14409},{\"end\":14429,\"start\":14423},{\"end\":14443,\"start\":14436},{\"end\":14456,\"start\":14450},{\"end\":14467,\"start\":14458},{\"end\":14482,\"start\":14477},{\"end\":14500,\"start\":14494},{\"end\":14517,\"start\":14509},{\"end\":14531,\"start\":14526},{\"end\":14542,\"start\":14539},{\"end\":14564,\"start\":14551},{\"end\":14581,\"start\":14575},{\"end\":14593,\"start\":14590},{\"end\":14604,\"start\":14598},{\"end\":14614,\"start\":14611},{\"end\":14634,\"start\":14627},{\"end\":14653,\"start\":14642},{\"end\":14663,\"start\":14659},{\"end\":14671,\"start\":14669},{\"end\":14690,\"start\":14680},{\"end\":14702,\"start\":14698},{\"end\":14718,\"start\":14710},{\"end\":14734,\"start\":14728},{\"end\":14745,\"start\":14740},{\"end\":14764,\"start\":14757},{\"end\":14774,\"start\":14771},{\"end\":14787,\"start\":14783},{\"end\":14804,\"start\":14796},{\"end\":14821,\"start\":14813},{\"end\":14833,\"start\":14830},{\"end\":14853,\"start\":14842},{\"end\":14868,\"start\":14862},{\"end\":14881,\"start\":14876},{\"end\":14896,\"start\":14888},{\"end\":14909,\"start\":14904},{\"end\":14922,\"start\":14918},{\"end\":14938,\"start\":14930},{\"end\":14954,\"start\":14950},{\"end\":14959,\"start\":14956},{\"end\":16605,\"start\":16595},{\"end\":16616,\"start\":16611},{\"end\":16629,\"start\":16624},{\"end\":16644,\"start\":16638},{\"end\":16656,\"start\":16652},{\"end\":16670,\"start\":16664},{\"end\":16942,\"start\":16940},{\"end\":16954,\"start\":16950},{\"end\":16964,\"start\":16961},{\"end\":16975,\"start\":16971},{\"end\":16989,\"start\":16986},{\"end\":17002,\"start\":16998},{\"end\":17012,\"start\":17008},{\"end\":17573,\"start\":17570},{\"end\":17587,\"start\":17582},{\"end\":17598,\"start\":17595},{\"end\":17609,\"start\":17607},{\"end\":17622,\"start\":17619},{\"end\":17638,\"start\":17631},{\"end\":17654,\"start\":17650},{\"end\":17887,\"start\":17882},{\"end\":17899,\"start\":17897},{\"end\":17910,\"start\":17905},{\"end\":17925,\"start\":17919},{\"end\":18210,\"start\":18205},{\"end\":18222,\"start\":18220},{\"end\":18232,\"start\":18229},{\"end\":18245,\"start\":18242},{\"end\":18255,\"start\":18252},{\"end\":18272,\"start\":18262},{\"end\":18285,\"start\":18281},{\"end\":18438,\"start\":18432},{\"end\":18446,\"start\":18440},{\"end\":18576,\"start\":18569},{\"end\":18592,\"start\":18587},{\"end\":18605,\"start\":18600},{\"end\":18899,\"start\":18896},{\"end\":18913,\"start\":18910},{\"end\":18926,\"start\":18922},{\"end\":18938,\"start\":18936},{\"end\":18952,\"start\":18948},{\"end\":19207,\"start\":19201},{\"end\":19223,\"start\":19218},{\"end\":19240,\"start\":19232},{\"end\":19250,\"start\":19247},{\"end\":19395,\"start\":19389},{\"end\":19409,\"start\":19403},{\"end\":19424,\"start\":19418},{\"end\":19433,\"start\":19431},{\"end\":19446,\"start\":19440},{\"end\":19461,\"start\":19458},{\"end\":19480,\"start\":19475},{\"end\":19495,\"start\":19491},{\"end\":19512,\"start\":19504},{\"end\":19530,\"start\":19522},{\"end\":19540,\"start\":19535},{\"end\":19552,\"start\":19547},{\"end\":19567,\"start\":19559},{\"end\":19585,\"start\":19578},{\"end\":20219,\"start\":20213},{\"end\":20231,\"start\":20229},{\"end\":20241,\"start\":20236},{\"end\":20256,\"start\":20249},{\"end\":20278,\"start\":20268},{\"end\":20294,\"start\":20287},{\"end\":20307,\"start\":20302},{\"end\":20325,\"start\":20318},{\"end\":20341,\"start\":20336},{\"end\":20351,\"start\":20348},{\"end\":20366,\"start\":20358},{\"end\":20916,\"start\":20909},{\"end\":20933,\"start\":20922},{\"end\":20951,\"start\":20945},{\"end\":20966,\"start\":20961},{\"end\":20981,\"start\":20974},{\"end\":20993,\"start\":20991},{\"end\":21011,\"start\":21005},{\"end\":21933,\"start\":21926},{\"end\":21947,\"start\":21941},{\"end\":21961,\"start\":21954},{\"end\":22578,\"start\":22575},{\"end\":22589,\"start\":22586},{\"end\":22609,\"start\":22601},{\"end\":22622,\"start\":22619},{\"end\":22634,\"start\":22629},{\"end\":22646,\"start\":22641},{\"end\":22664,\"start\":22653},{\"end\":22677,\"start\":22674},{\"end\":22990,\"start\":22987},{\"end\":23004,\"start\":23001},{\"end\":23014,\"start\":23012},{\"end\":23027,\"start\":23024},{\"end\":23038,\"start\":23035},{\"end\":23052,\"start\":23049},{\"end\":23289,\"start\":23284},{\"end\":23307,\"start\":23298},{\"end\":23321,\"start\":23316},{\"end\":23334,\"start\":23328},{\"end\":23346,\"start\":23344},{\"end\":23363,\"start\":23355},{\"end\":23376,\"start\":23371},{\"end\":23399,\"start\":23390},{\"end\":23652,\"start\":23645},{\"end\":23668,\"start\":23662},{\"end\":23685,\"start\":23678},{\"end\":23702,\"start\":23694},{\"end\":23722,\"start\":23715},{\"end\":23740,\"start\":23733},{\"end\":23764,\"start\":23748},{\"end\":23776,\"start\":23771},{\"end\":23791,\"start\":23785},{\"end\":23807,\"start\":23802},{\"end\":23825,\"start\":23816},{\"end\":23833,\"start\":23827},{\"end\":24317,\"start\":24313},{\"end\":24327,\"start\":24323},{\"end\":24337,\"start\":24334},{\"end\":24487,\"start\":24483},{\"end\":24497,\"start\":24494},{\"end\":24511,\"start\":24509},{\"end\":24523,\"start\":24519},{\"end\":24534,\"start\":24531},{\"end\":24545,\"start\":24541},{\"end\":24558,\"start\":24554},{\"end\":24568,\"start\":24566},{\"end\":24581,\"start\":24576},{\"end\":24591,\"start\":24588},{\"end\":24969,\"start\":24965},{\"end\":24981,\"start\":24979},{\"end\":24992,\"start\":24989},{\"end\":25004,\"start\":25001},{\"end\":25017,\"start\":25014},{\"end\":25028,\"start\":25023},{\"end\":25041,\"start\":25039},{\"end\":25393,\"start\":25388},{\"end\":25406,\"start\":25403},{\"end\":25418,\"start\":25415},{\"end\":25434,\"start\":25430},{\"end\":25444,\"start\":25441},{\"end\":25457,\"start\":25454},{\"end\":25711,\"start\":25697},{\"end\":25723,\"start\":25719},{\"end\":25734,\"start\":25732},{\"end\":25748,\"start\":25744},{\"end\":25761,\"start\":25757},{\"end\":25775,\"start\":25772},{\"end\":25788,\"start\":25785},{\"end\":25802,\"start\":25797},{\"end\":25815,\"start\":25810},{\"end\":25827,\"start\":25823},{\"end\":25836,\"start\":25834},{\"end\":25849,\"start\":25845},{\"end\":25863,\"start\":25859},{\"end\":25876,\"start\":25872},{\"end\":25891,\"start\":25886},{\"end\":25902,\"start\":25899},{\"end\":25912,\"start\":25910},{\"end\":25925,\"start\":25921},{\"end\":25936,\"start\":25933},{\"end\":25950,\"start\":25947},{\"end\":25963,\"start\":25960},{\"end\":25968,\"start\":25965},{\"end\":26419,\"start\":26415},{\"end\":26434,\"start\":26428},{\"end\":26445,\"start\":26443},{\"end\":26456,\"start\":26452},{\"end\":26474,\"start\":26468},{\"end\":26492,\"start\":26481},{\"end\":26514,\"start\":26501},{\"end\":27080,\"start\":27074},{\"end\":27095,\"start\":27088},{\"end\":27113,\"start\":27105},{\"end\":27123,\"start\":27121},{\"end\":27135,\"start\":27130},{\"end\":27150,\"start\":27143},{\"end\":27165,\"start\":27159},{\"end\":27186,\"start\":27176},{\"end\":27194,\"start\":27188}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":218971783},\"end\":14347,\"start\":13129},{\"attributes\":{\"id\":\"b1\"},\"end\":16534,\"start\":14349},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":4787508},\"end\":16851,\"start\":16536},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":247519241},\"end\":17492,\"start\":16853},{\"attributes\":{\"id\":\"b4\"},\"end\":17827,\"start\":17494},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00324\",\"id\":\"b5\",\"matched_paper_id\":208513249},\"end\":18192,\"start\":17829},{\"attributes\":{\"id\":\"b6\"},\"end\":18384,\"start\":18194},{\"attributes\":{\"id\":\"b7\"},\"end\":18519,\"start\":18386},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":926364},\"end\":18780,\"start\":18521},{\"attributes\":{\"id\":\"b9\"},\"end\":19135,\"start\":18782},{\"attributes\":{\"id\":\"b10\"},\"end\":19377,\"start\":19137},{\"attributes\":{\"id\":\"b11\"},\"end\":20058,\"start\":19379},{\"attributes\":{\"id\":\"b12\"},\"end\":20137,\"start\":20060},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":246426909},\"end\":20864,\"start\":20139},{\"attributes\":{\"doi\":\"10.18653/v1/D19-1250\",\"id\":\"b14\",\"matched_paper_id\":202539551},\"end\":21846,\"start\":20866},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.437\",\"id\":\"b15\",\"matched_paper_id\":211205183},\"end\":22511,\"start\":21848},{\"attributes\":{\"doi\":\"abs/2301.12652\",\"id\":\"b16\"},\"end\":22894,\"start\":22513},{\"attributes\":{\"id\":\"b17\"},\"end\":23221,\"start\":22896},{\"attributes\":{\"id\":\"b18\"},\"end\":23636,\"start\":23223},{\"attributes\":{\"id\":\"b19\"},\"end\":24250,\"start\":23638},{\"attributes\":{\"doi\":\"abs/2303.07678\",\"id\":\"b20\"},\"end\":24475,\"start\":24252},{\"attributes\":{\"doi\":\"arXiv:2210.02414\",\"id\":\"b21\"},\"end\":24878,\"start\":24477},{\"attributes\":{\"doi\":\"arXiv:2208.05753\",\"id\":\"b22\"},\"end\":25280,\"start\":24880},{\"attributes\":{\"doi\":\"abs/2305.07001\",\"id\":\"b23\"},\"end\":25689,\"start\":25282},{\"attributes\":{\"id\":\"b24\"},\"end\":26330,\"start\":25691},{\"attributes\":{\"doi\":\"10.18653/v1/2021.findings-acl.120\",\"id\":\"b25\",\"matched_paper_id\":226254579},\"end\":27018,\"start\":26332},{\"attributes\":{\"doi\":\"abs/1909.08593\",\"id\":\"b26\"},\"end\":27427,\"start\":27020}]", "bib_title": "[{\"end\":13206,\"start\":13129},{\"end\":16586,\"start\":16536},{\"end\":16928,\"start\":16853},{\"end\":17871,\"start\":17829},{\"end\":18562,\"start\":18521},{\"end\":20206,\"start\":20139},{\"end\":20901,\"start\":20866},{\"end\":21919,\"start\":21848},{\"end\":26404,\"start\":26332}]", "bib_author": "[{\"end\":13219,\"start\":13208},{\"end\":13234,\"start\":13219},{\"end\":13246,\"start\":13234},{\"end\":13263,\"start\":13246},{\"end\":13279,\"start\":13263},{\"end\":13298,\"start\":13279},{\"end\":13318,\"start\":13298},{\"end\":13332,\"start\":13318},{\"end\":13347,\"start\":13332},{\"end\":13362,\"start\":13347},{\"end\":13380,\"start\":13362},{\"end\":13400,\"start\":13380},{\"end\":13418,\"start\":13400},{\"end\":13432,\"start\":13418},{\"end\":13445,\"start\":13432},{\"end\":13460,\"start\":13445},{\"end\":13476,\"start\":13460},{\"end\":13488,\"start\":13476},{\"end\":13504,\"start\":13488},{\"end\":13517,\"start\":13504},{\"end\":13528,\"start\":13517},{\"end\":13541,\"start\":13528},{\"end\":13557,\"start\":13541},{\"end\":14372,\"start\":14351},{\"end\":14387,\"start\":14372},{\"end\":14401,\"start\":14387},{\"end\":14416,\"start\":14401},{\"end\":14431,\"start\":14416},{\"end\":14445,\"start\":14431},{\"end\":14458,\"start\":14445},{\"end\":14469,\"start\":14458},{\"end\":14484,\"start\":14469},{\"end\":14502,\"start\":14484},{\"end\":14519,\"start\":14502},{\"end\":14533,\"start\":14519},{\"end\":14544,\"start\":14533},{\"end\":14566,\"start\":14544},{\"end\":14583,\"start\":14566},{\"end\":14595,\"start\":14583},{\"end\":14606,\"start\":14595},{\"end\":14616,\"start\":14606},{\"end\":14636,\"start\":14616},{\"end\":14655,\"start\":14636},{\"end\":14665,\"start\":14655},{\"end\":14673,\"start\":14665},{\"end\":14692,\"start\":14673},{\"end\":14704,\"start\":14692},{\"end\":14720,\"start\":14704},{\"end\":14736,\"start\":14720},{\"end\":14747,\"start\":14736},{\"end\":14766,\"start\":14747},{\"end\":14776,\"start\":14766},{\"end\":14789,\"start\":14776},{\"end\":14806,\"start\":14789},{\"end\":14823,\"start\":14806},{\"end\":14835,\"start\":14823},{\"end\":14855,\"start\":14835},{\"end\":14870,\"start\":14855},{\"end\":14883,\"start\":14870},{\"end\":14898,\"start\":14883},{\"end\":14911,\"start\":14898},{\"end\":14924,\"start\":14911},{\"end\":14940,\"start\":14924},{\"end\":14956,\"start\":14940},{\"end\":14961,\"start\":14956},{\"end\":16607,\"start\":16588},{\"end\":16618,\"start\":16607},{\"end\":16631,\"start\":16618},{\"end\":16646,\"start\":16631},{\"end\":16658,\"start\":16646},{\"end\":16672,\"start\":16658},{\"end\":16944,\"start\":16930},{\"end\":16956,\"start\":16944},{\"end\":16966,\"start\":16956},{\"end\":16977,\"start\":16966},{\"end\":16991,\"start\":16977},{\"end\":17004,\"start\":16991},{\"end\":17014,\"start\":17004},{\"end\":17575,\"start\":17563},{\"end\":17589,\"start\":17575},{\"end\":17600,\"start\":17589},{\"end\":17611,\"start\":17600},{\"end\":17624,\"start\":17611},{\"end\":17640,\"start\":17624},{\"end\":17656,\"start\":17640},{\"end\":17889,\"start\":17873},{\"end\":17901,\"start\":17889},{\"end\":17912,\"start\":17901},{\"end\":17927,\"start\":17912},{\"end\":18212,\"start\":18196},{\"end\":18224,\"start\":18212},{\"end\":18234,\"start\":18224},{\"end\":18247,\"start\":18234},{\"end\":18257,\"start\":18247},{\"end\":18274,\"start\":18257},{\"end\":18287,\"start\":18274},{\"end\":18440,\"start\":18425},{\"end\":18448,\"start\":18440},{\"end\":18578,\"start\":18564},{\"end\":18594,\"start\":18578},{\"end\":18607,\"start\":18594},{\"end\":18901,\"start\":18889},{\"end\":18915,\"start\":18901},{\"end\":18928,\"start\":18915},{\"end\":18940,\"start\":18928},{\"end\":18954,\"start\":18940},{\"end\":19209,\"start\":19194},{\"end\":19225,\"start\":19209},{\"end\":19242,\"start\":19225},{\"end\":19252,\"start\":19242},{\"end\":19397,\"start\":19379},{\"end\":19411,\"start\":19397},{\"end\":19426,\"start\":19411},{\"end\":19435,\"start\":19426},{\"end\":19448,\"start\":19435},{\"end\":19463,\"start\":19448},{\"end\":19482,\"start\":19463},{\"end\":19497,\"start\":19482},{\"end\":19514,\"start\":19497},{\"end\":19532,\"start\":19514},{\"end\":19542,\"start\":19532},{\"end\":19554,\"start\":19542},{\"end\":19569,\"start\":19554},{\"end\":19587,\"start\":19569},{\"end\":20221,\"start\":20208},{\"end\":20233,\"start\":20221},{\"end\":20243,\"start\":20233},{\"end\":20258,\"start\":20243},{\"end\":20280,\"start\":20258},{\"end\":20296,\"start\":20280},{\"end\":20309,\"start\":20296},{\"end\":20327,\"start\":20309},{\"end\":20343,\"start\":20327},{\"end\":20353,\"start\":20343},{\"end\":20368,\"start\":20353},{\"end\":20918,\"start\":20903},{\"end\":20935,\"start\":20918},{\"end\":20953,\"start\":20935},{\"end\":20968,\"start\":20953},{\"end\":20983,\"start\":20968},{\"end\":20995,\"start\":20983},{\"end\":21013,\"start\":20995},{\"end\":21935,\"start\":21921},{\"end\":21949,\"start\":21935},{\"end\":21963,\"start\":21949},{\"end\":22580,\"start\":22568},{\"end\":22591,\"start\":22580},{\"end\":22611,\"start\":22591},{\"end\":22624,\"start\":22611},{\"end\":22636,\"start\":22624},{\"end\":22648,\"start\":22636},{\"end\":22666,\"start\":22648},{\"end\":22679,\"start\":22666},{\"end\":22992,\"start\":22980},{\"end\":23006,\"start\":22992},{\"end\":23016,\"start\":23006},{\"end\":23029,\"start\":23016},{\"end\":23040,\"start\":23029},{\"end\":23054,\"start\":23040},{\"end\":23291,\"start\":23278},{\"end\":23309,\"start\":23291},{\"end\":23323,\"start\":23309},{\"end\":23336,\"start\":23323},{\"end\":23348,\"start\":23336},{\"end\":23365,\"start\":23348},{\"end\":23378,\"start\":23365},{\"end\":23401,\"start\":23378},{\"end\":23654,\"start\":23640},{\"end\":23670,\"start\":23654},{\"end\":23687,\"start\":23670},{\"end\":23704,\"start\":23687},{\"end\":23724,\"start\":23704},{\"end\":23742,\"start\":23724},{\"end\":23766,\"start\":23742},{\"end\":23778,\"start\":23766},{\"end\":23793,\"start\":23778},{\"end\":23809,\"start\":23793},{\"end\":23827,\"start\":23809},{\"end\":23835,\"start\":23827},{\"end\":24319,\"start\":24307},{\"end\":24329,\"start\":24319},{\"end\":24339,\"start\":24329},{\"end\":24489,\"start\":24477},{\"end\":24499,\"start\":24489},{\"end\":24513,\"start\":24499},{\"end\":24525,\"start\":24513},{\"end\":24536,\"start\":24525},{\"end\":24547,\"start\":24536},{\"end\":24560,\"start\":24547},{\"end\":24570,\"start\":24560},{\"end\":24583,\"start\":24570},{\"end\":24593,\"start\":24583},{\"end\":24971,\"start\":24957},{\"end\":24983,\"start\":24971},{\"end\":24994,\"start\":24983},{\"end\":25006,\"start\":24994},{\"end\":25019,\"start\":25006},{\"end\":25030,\"start\":25019},{\"end\":25043,\"start\":25030},{\"end\":25395,\"start\":25381},{\"end\":25408,\"start\":25395},{\"end\":25420,\"start\":25408},{\"end\":25436,\"start\":25420},{\"end\":25446,\"start\":25436},{\"end\":25459,\"start\":25446},{\"end\":25713,\"start\":25693},{\"end\":25725,\"start\":25713},{\"end\":25736,\"start\":25725},{\"end\":25750,\"start\":25736},{\"end\":25763,\"start\":25750},{\"end\":25777,\"start\":25763},{\"end\":25790,\"start\":25777},{\"end\":25804,\"start\":25790},{\"end\":25817,\"start\":25804},{\"end\":25829,\"start\":25817},{\"end\":25838,\"start\":25829},{\"end\":25851,\"start\":25838},{\"end\":25865,\"start\":25851},{\"end\":25878,\"start\":25865},{\"end\":25893,\"start\":25878},{\"end\":25904,\"start\":25893},{\"end\":25914,\"start\":25904},{\"end\":25927,\"start\":25914},{\"end\":25938,\"start\":25927},{\"end\":25952,\"start\":25938},{\"end\":25965,\"start\":25952},{\"end\":25970,\"start\":25965},{\"end\":26421,\"start\":26406},{\"end\":26436,\"start\":26421},{\"end\":26447,\"start\":26436},{\"end\":26458,\"start\":26447},{\"end\":26476,\"start\":26458},{\"end\":26494,\"start\":26476},{\"end\":26516,\"start\":26494},{\"end\":27082,\"start\":27072},{\"end\":27097,\"start\":27082},{\"end\":27115,\"start\":27097},{\"end\":27125,\"start\":27115},{\"end\":27137,\"start\":27125},{\"end\":27152,\"start\":27137},{\"end\":27167,\"start\":27152},{\"end\":27188,\"start\":27167},{\"end\":27196,\"start\":27188}]", "bib_venue": "[{\"end\":13696,\"start\":13608},{\"end\":17175,\"start\":17103},{\"end\":20447,\"start\":20377},{\"end\":21386,\"start\":21210},{\"end\":22169,\"start\":22090},{\"end\":13606,\"start\":13557},{\"end\":16676,\"start\":16672},{\"end\":17101,\"start\":17014},{\"end\":17561,\"start\":17494},{\"end\":18008,\"start\":17947},{\"end\":18423,\"start\":18386},{\"end\":18636,\"start\":18607},{\"end\":18887,\"start\":18782},{\"end\":19192,\"start\":19137},{\"end\":19649,\"start\":19587},{\"end\":20098,\"start\":20062},{\"end\":20375,\"start\":20368},{\"end\":21208,\"start\":21033},{\"end\":22088,\"start\":21994},{\"end\":22566,\"start\":22513},{\"end\":22978,\"start\":22896},{\"end\":23276,\"start\":23223},{\"end\":24305,\"start\":24252},{\"end\":24654,\"start\":24609},{\"end\":24955,\"start\":24880},{\"end\":25379,\"start\":25282},{\"end\":26623,\"start\":26549},{\"end\":27070,\"start\":27020}]"}}}, "year": 2023, "month": 12, "day": 17}