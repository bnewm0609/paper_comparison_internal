{"id": 221836648, "updated": "2023-11-11 00:55:57.411", "metadata": {"title": "Constructing interval variables via faceted Rasch measurement and multitask deep learning: a hate speech application", "authors": "[{\"first\":\"Chris\",\"last\":\"Kennedy\",\"middle\":[\"J.\"]},{\"first\":\"Geoff\",\"last\":\"Bacon\",\"middle\":[]},{\"first\":\"Alexander\",\"last\":\"Sahn\",\"middle\":[]},{\"first\":\"Claudia\",\"last\":\"Vacano\",\"middle\":[\"von\"]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": 9, "day": 22}, "abstract": "We propose a general method for measuring complex variables on a continuous, interval spectrum by combining supervised deep learning with the Constructing Measures approach to faceted Rasch item response theory (IRT). We decompose the target construct, hate speech in our case, into multiple constituent components that are labeled as ordinal survey items. Those survey responses are transformed via IRT into a debiased, continuous outcome measure. Our method estimates the survey interpretation bias of the human labelers and eliminates that influence on the generated continuous measure. We further estimate the response quality of each labeler using faceted IRT, allowing responses from low-quality labelers to be removed. Our faceted Rasch scaling procedure integrates naturally with a multitask deep learning architecture for automated prediction on new data. The ratings on the theorized components of the target outcome are used as supervised, ordinal variables for the neural networks' internal concept learning. We test the use of an activation function (ordinal softmax) and loss function (ordinal cross-entropy) designed to exploit the structure of ordinal outcome variables. Our multitask architecture leads to a new form of model interpretation because each continuous prediction can be directly explained by the constituent components in the penultimate layer. We demonstrate this new method on a dataset of 50,000 social media comments sourced from YouTube, Twitter, and Reddit and labeled by 11,000 U.S.-based Amazon Mechanical Turk workers to measure a continuous spectrum from hate speech to counterspeech. We evaluate Universal Sentence Encoders, BERT, and RoBERTa as language representation models for the comment text, and compare our predictive accuracy to Google Jigsaw's Perspective API models, showing significant improvement over this standard benchmark.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3088784738", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2009-10277", "doi": null}}, "content": {"source": {"pdf_hash": "a888bcf2cc7ad2c0d597344b3ee7e0ceb9847469", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2009.10277v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "848cf9232c69ee2d575e90b83f4e0d48a8690c40", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a888bcf2cc7ad2c0d597344b3ee7e0ceb9847469.txt", "contents": "\nConstructing interval variables via faceted Rasch measurement and multitask deep learning: a hate speech application\nSeptember 23, 2020 22 Sep 2020\n\nChris J Kennedy \nD-Lab\nUniversity of California\nBerkeley\n\nDepartment of Biomedical Informatics\nHarvard Medical School\n\n\nGeoff Bacon \nD-Lab\nUniversity of California\nBerkeley\n\nDepartment of Linguistics\nUC Berkeley\n\n\nAlexander Sahn \nD-Lab\nUniversity of California\nBerkeley\n\nTravers Department of Political Science\nUC Berkeley 5. Digital HumanitiesBerkeleyUC\n\nClaudia Von Vacano \nD-Lab\nUniversity of California\nBerkeley\n\nConstructing interval variables via faceted Rasch measurement and multitask deep learning: a hate speech application\nSeptember 23, 2020 22 Sep 2020Version:Rasch measurement theoryordinal deep learningmany-facet Rasch modelsmultitask learninghate speech\nWe propose a general method for measuring complex variables on a continuous, interval spectrum by combining supervised deep learning with the Constructing Measures approach to faceted Rasch item response theory (IRT). We decompose the target construct, hate speech in our case, into multiple constituent components that are labeled as ordinal survey items. Those survey responses are transformed via an IRT nonlinear activation into a debiased, continuous outcome measure. Our method estimates the survey interpretation bias of the human labelers and eliminates that influence on the generated continuous measure; removing labeling bias supersedes the use of inter-rater reliability as a quality diagnostic. We further estimate the response quality of each individual labeler using faceted IRT, allowing responses from low-quality labelers to be removed.Our faceted Rasch scaling procedure integrates naturally with a multitask, weight-sharing deep learning architecture for automated prediction on new data. The ratings on the theorized components of the target outcome are used as supervised, ordinal latent variables for the neural networks' internal concept learning, improving sample efficiency and promoting generalizability. We test the use of a neural activation function (ordinal softmax) and loss function (ordinal cross-entropy) designed to exploit the structure of ordinal outcome variables. Our multitask architecture leads to a new form of model interpretation because each continuous prediction can be directly explained by the constituent components in the penultimate layer.We demonstrate this new method on a dataset of 50,000 social media comments sourced from YouTube, Twitter, and Reddit and labeled by 10,000 United States-based Amazon Mechanical Turk workers to measure a continuous spectrum from hate speech to counterspeech. We evaluate Universal Sentence Encoders, BERT, and RoBERTa as language representation models for the comment text, and compare our predictive accuracy to Google Jigsaw's Perspective API models, showing significant improvement over this standard benchmark.\n\nIntroduction\n\nAcross fields of knowledge (science, engineering, medicine, etc.) phenomena of interest are often labeled by humans as discrete, dichotomous variables: speech is toxic or not, an MRI scan shows cancer or is clear, a stoplight is red or green. Simple variables may be inherently binary or ordinal in nature. For example, an online advertisement might be clicked by a person viewing a webpage, or might not -a partial click between 0 and 1 does not make sense. But if a discrete variable represents a concept with complexity or granularity, those {0, 1} values may reflect the simplification of an underlying continuous spectrum or latent variable. Consider an online message that is rated for its sentiment using the discrete, ordered labels of \"positive\", \"neutral\", or \"negative\" (B. Liu 2015). Those labels can reasonably be viewed as summarizing what is ultimately a continuous, infinitely divisible spectrum ranging from extremely negative to extremely positive sentiment.\n\nPhysical quantities such as temperature and weight can be measured as interval variables where magnitudes are meaningful: we can subtract the measurements of two units and have an estimate of distance on the original scale. We can make factual statements such as \"today's temperature is 5 degrees warmer than yesterday\" or \"I lost 10 pounds after dieting\". The development of physical measurement systems required major, long-term investments in scientific and engineering that led to a theory of those physical systems (Chang 2004). Thanks to those fixed scales we can receive a weather report with specific temperatures provided, or stand on a scale and view our current weight. But in the fields of machine learning, natural language processing, and many other areas, current practice would provide a binary prediction. As a mental exercise, what if today's expected weather forecast were reported as two values: hot or cold? Classification models could only estimate P r(Weather = Hot | Data) and we might hear: \"Today's weather forecast: expected hot, with 55% probability, but a 45% chance of being cold.\" It sounds absurd, but that is how we treat many variables in science today, including our construct of interest in this paper: hate speech. \"Classification\" of discrete outcome variables has seemingly become synonymous with \"supervised learning\", so rarely are continuous variables analyzed. Our question becomes: how can we aspire to emulate physical scales like temperature, which we take for granted in our daily lives, and construct interval measurements for arbitrary variables?\n\nA method to estimate a continuous spectrum for human-generated variables could be valuable for several reasons. If the variable is recorded in order to determine the application of interventions, a continuous measurement would allow many different thresholds to be defined with varied policy prescriptions. A binary outcome would support only two policy alternatives, and research based on the binary version would lose most of its underlying value if the implicit threshold of interest changed (Streiner 2002). When the construct of interest is an outcome variable, such as in a randomized trial or an observational study, having a continuous measurement will increase statistical power compared to a dichotomous or ordinal variable (Cohen 1983;Senn 2003). If the variable is a confounder in a causal inference analysis, a continuous measurement would more strongly reduce residual confounding compared to a discretized version of that variable (Royston et al. 2006). Similarly, if the variable is a pre-treatment adjustment variable in a randomized trial, the variable will more effectively improve precision if continuous rather than binary (Dawson et al. 2012).\n\nIn this work we propose a methodology to construct continuous, interval variables by combining two complementary techniques: many-facet Rasch measurement, a form of item response theory, and supervised deep learning. Rasch measurement theory involves the application of a probabilistic multilevel statistical model to create continuous, interval scales out of multiple survey questions, measured as binary or ordinal variables. When those survey items (or \"components\") are completed by human test-takers we need a way to automate the human ratings for unseen future data, otherwise we would need human test-takers to review any future observation in order to create its measurement on the scale. Supervised deep learning provides an automated approximation of the human ratings by learning to predict those ratings on arbitrary new observations, which also serves as a new form of model explanation. The deep learning model can alternatively predict the continuous scale directly and skip the intermediate step of predicting the ratings. Our methodology can be applied to any variable that can be theorized as a continuous spectrum and is based on human ratings. The underlying source data is also general: it might be text, images, videos, time series, waveform, or audio. As long as the underlying data source is unstructured and reviewed by humans, the deep learning model has the potential to approximate those human ratings for automation purposes.\n\nWe apply this novel method to the measurement of hate speech, a social problem that has received extensive attention from policymakers, researchers, and firms. While existing attempts to detect hate speech use predictions derived from discrete labels, our method measures the hateful content of speech by scaling multiple labels of multiple components.\n\nOur manuscript is structured as follows: we begin by providing background on the theoretical foundations of hate speech and previous machine learning approaches. We then describe our methodology, starting with the theoretical development of a hate speech spectrum, which is operationalized as a survey instrument, the collection of social media comments and crowdsourced labeling process, use of faceted Rasch theory to statistically transform the labeled data into an interval variable, and application of deep learning models to predict that interval variable using only the text of the comment. We next present the results of our work, which consist of the Rasch scaling followed by the deep learning performance evaluation. We conclude with a discussion of current limitations and the many possible extensions of this method. We hope that this work can help spur wider usage of Rasch measurement theory to go beyond simplified discrete variables and instead develop continuous, interval variables across fields.\n\n\nApplication to hate speech\n\nWe demonstrate the effectiveness of our method in measuring hate speech, a complex linguistic phenomenon with consequential social and political impacts. The accurate measurement of, and intervention to counter, hate speech may prevent psychological harm, dissipate extremist groups and prevent downstream violent, even genocidal events. However, the difficultly of identifying this rare and complex phenomenon has made interventions costly, error-prone, and rare.\n\nThe harm in hate speech is significant. Within niche extremist communities, hate speech serves as a mechanism for recruitment and as a radicalizing influence, building cultures of hatred that can lead to hate crimes and terrorist violence (Tsesis 2002). In areas with long-term ethnic conflicts, hate speech may precipitate or otherwise foment mass genocidal violence (R. A. Wilson 2017).\n\nEven given the many harms of hate speech, legislation, corporate content moderation, or outright censorship to combat hate speech also cause harm. Laws intended to protect groups that are minorities in numbers within the power structure can be used against the very people they were intended to protect (Strossen 2018). Research on online hate speech is often conducted behind corporate walls given the centrality of large internet firms in addressing its harms. Open, transparent, and reproducible research on hate speech is vital to balancing the relative harms of hate speech against content removal.\n\n\n2/33\n\nComputationally analyzing hate speech is a challenging task for several reasons. First, there is no consensus on a systematic definition of hate speech (Sellars 2016) or existing measurement instrument. Second, the scale of communication and the different linguistic forms it takes necessitates algorithmic approaches. Third, hate speech constitutes a small proportion of online communication (1% or less), making it difficult to create well-powered training datasets for algorithmic approaches. Fourth, human reviewers that generate the training data often do not agree on how to label training observations, even when given detailed criteria and intensive training to evaluate speech (Kiela et al. 2020). Finally, extremist groups often use sarcasm, ambiguity, and coded language to obscure the hateful nature of their communications, to evade moderation, and ultimately, to organize actions. The combined impact of this mixture of challenges is that we cannot currently track hate speech in a consistent manner over time.\n\nLike many social or linguistic phenomena, definitions of hate speech are contested and vary over temporal and geographic contexts. Even if a definition were readily agreed upon, hate speech would be difficult to measure numerically. Many existing approaches use a binary theoretical construct-speech either contains hate speech or not. In identifying hate speech, whether at small, medium, or large-scale, human raters, novice or expert, label texts based on a common definition. Due to the binary construct, these labels are also frequently binary and in large-scale computational analyses, out-of-sample predictions produce a prediction along the binary construct with associated error. Table 1 summarises some prominent existing approaches, noting the number of construct levels and outcome measurement granularity. Our approach improves on the existing literature in two ways: in our integration of the hate speech and counter-speech literature, we create a theoretical construct with 8 levels, allowing for more categories of hateful content in speech. We then create a labeling instrument with 32-48 measurement levels. These levels, which are described in the labeling instrument section in detail, reduce measurement error by using multiple items per construct and allow us to accurately distinguish between the 8 theorized construct levels. We validate the measurement of these levels in section 4.2.\n\n\nPrior computational work\n\nThe scale of online communications has made computational approaches a necessity for characterizing hate speech patterns. In particular, machine learning for hate speech analysis has become a well-studied topic over the past decade. Early work (e.g. Warner et al. 2012) used simple, non-deep learning algorithms for estimation, such as naive Bayes, support vector machines, or linear regression. Text features were typically unigram TF-IDF scores, and sometimes additional syntactic features like part-of-speech tagging (Davidson et al. 2017). The field gradually transitioned to word embeddings, often pre-trained, where the best featurization approach was comment word embedding averages or paragraph embeddings (Djuric et al. 2015;Nobata et al. 2016). Those features could then be combined with gradient boosted decision trees or Bayesian additive regression trees. 1 More recently there has been a shift to deep learning methods, beginning with long short-term memory networks (LSTMs), convolutional neural networks (CNNs), and gated recurrent unit networks (GRUs), that either use pre-trained word embeddings or learn their own embeddings from the raw text (Badjatiya et al. 2017;Zhang et al. 2018). Adding attention mechanisms to deep learning is beginning to be used in hate speech research (Founta et al. 2018), but their successor transformer units (Vaswani et al. 2017) have not yet been widely adopted for hate speech research.\n\n1 These were our best results from a pilot study we completed in October 2017.\n\n\n3/33\n\nModel-based transfer learning methods provided a further breakthrough in supervised natural language processing (Ruder 2018), including best in class architectures OpenAI's GPT-2 (Radford et al. 2019), fast.ai's ULMFiT (Howard et al. 2018), and Google's BERT (Devlin et al. 2018). Those contextualized word representation methods are only beginning to be used in hate speech research. The algorithms column of Table 1 summarises the existing approaches in prominent previous work. Developing a labeled corpus to produce an accurate measurement tool for hate speech on social media requires overcoming two obstacles: the rarity of hate speech across all posts and differences in linguistic styles of different social media platforms. We overcome the first challenge by pre-processing 54 million total comments with a hypothesis score model, then labeling comments from different quantiles of likely hate content. To overcome the second problem, we sample comments from three platforms: YouTube, the most used social media platform globally, Twitter, a platform with heavily political content that engage with identity, and Reddit, a longer-format forum home to some radical communities. The 50,000 labeled comments across 3 platforms form the most representative, and one of the largest training sets of hate speech data.\n\nReviewer reliability is a particularly difficult challenge in hate speech research. Definitional variation, along with differences in labeler knowledge, context, and ideology can result in inconsistent labels. Prior approaches refine their definition and measurement interest to try to maximize inter-coder reliability. We take a different approach, adjusting the final continuous score based on estimated labeler bias from our faceted Rasch IRT model.\n\n\nMethods and Data\n\nWe use our method to measure hate speech, a complex social phenomenon that is difficult to define, measure, and analyze at scale. Our methodological approach begins with constructing a systematic conceptualization of hate speech in online communication, operationalized through a survey instrument, and proposes an efficient, debiased prediction algorithm using deep learning. In the following sections, we describe the process of construct theorization using a reference set of comments, the measurement of sub-constructs (components) using a labeling instrument, the crowdsourcing of labeling to a network of interlinked reviewers, the debiased scaling of labeled data using faceted Rasch measurement theory, and the integration of the Rasch model into a novel multitask deep learning architecture for debiased, explainable, interval prediction.\n\n\nConstruct theorization from a reference set\n\nHate speech has many definitions across academic disciplines, legal and regulatory doctrines, and in common vernacular. When attempting to systematically measure a social concept, \"I know it when I see it\" will vary greatly on who is doing the identification: life experience, familiarity with language, and historical context all vary across individuals, whether experts or laypeople. Difficult-to-measure phenomena like hate speech are an ideal application of our method, but require careful theorization and translation to measurement instruments.\n\nWe draw from the legal definition of hate crimes in the United States that protects against discriminatory actions targeting one of the following protected groups: race, religion, ethnicity, nationality, gender, sexual orientation, gender identity, and disability. In identifying groups within these broad categories, we include subjugated groups that have been discriminated against in the United States, as well as power-dominant groups who have not. Targeting of a group or an individual on the basis of their membership in a group is common to most definitions of hate speech (Sellars 2016). Not only do we adopt this convention, but we allow for intersectional or overlapping identities to be selected for further analysis. We consider intersectional identities and the possibility of compounding hate speech directed at an individual who belongs to multiple groups.\n\nSpeech can also lead to individual acts of violence and when targeted against a group, genocide and extermination. The \"dangerous speech\" framework ties the effects of hateful speech to actions that it can incite (Benesch et al. 2018). Dehumanization, such as radio broadcasts in Rwanda referring to the Tutsi people as cockroaches, is directly linked to later genocidal killing of that group. Incitement towards violence is a narrowly defined concept under US law, and the dangerous speech framework that we use takes a broader view of the link between cause and effect. Sellars (2016) points out that the accumulated affects of anti-Semitic or racist speech can have multi-generational impacts on the well-being of individuals in a group born long after hateful speech was original created. Given the complexities of these concepts, we focus on calls to individual violence or collective extermination, with the idea that these are the final step after expression of hate and deeming a group inferior or inhuman. Table 2 describes the eight levels of our theorized hate speech scale. The positive levels on the scale designate hate speech of increasing severity. Unlike many existing scales, our typology includes both neutral and positive identity speech, represented by 0 and negative values, respectively. Following Anti-Defamation League (2016) and Stanton (2013), we place speech supporting the systematic killing of a specific group as the most severe form of hate speech. Viewing other types of hate speech as pathways to genocide, we pay special attention to individuals threats of violence and dehumanization that may justify violence.\n\nFrom a manual review of social media comments, we curated a reference set, a small corpus of example text for each conceptual level. We selected 10 comments to serve as examples of each of our theoretical levels, totalling 80 comments. In concert with construct development using existing literature, we manually reviewed thousands of comments from our corpus, oversampling on comments with high hypothesis scores. We also selected reference set comments for each level that yielded a diversity of target groups, text length, and linguistic styles. Iteratively, we selected comments that we Genocide Support for or intention of systematically killing all or a large number of a protected identity group 4\n\nViolence Threat or support of physical force or emotional abuse intended to hurt or kill members of a protected identity group 3\n\nDehumanization Depriving a protected group of human-like qualities, such as comparison to an animal, insect, or disease 2 Hostility Unfriendliness or opposition to a protected identity group, such as through slurs, profantiy, or insults 1 Bias Inclination or preference against a protected identity group, including prejudice 0 Neutral Descriptive or other non-harmful references to identity groups -1 Supportive Respectful, prideful, or other solidarity-based messaging about a protected identity group(s) -2\n\nCounterspeech Response to hate speech that seeks to undermine its impact and standing felt best exemplified levels of hate speech, and when we found ambiguities, used the comments to refine the definitions of each level. This allowed us to identify distinguishing features of speech and create measurement items to capture these distinctions. These reference set comments served two purposes: to aid in construct development by providing clear examples between levels and as empirical scaffolding to link human raters in our crowdsourced measurement. We describe the importance of the reference set for construct theorization and measure development below and its integration with linking labelers in Section 3.4. Example comments from each level of the reference set are shown in Table 3.\n\n\nLabeling instrument\n\nIn order to evaluate the comments we needed one or more human reviewers (also called \"annotators\", \"labelers\", \"judges\", \"raters\", or \"moderators\") to examine the comment text and provide data to estimate where each comment fell on each of our theorized components of hate speech. Most labeling tasks for training data give the labeler a detailed definition of the construct and then ask them to assign a binary label to each data point (e.g. designating a block of text as hate speech or not, designating whether an image contains a stop sign). This approach has to two shortcomings: labelers cannot indicate uncertainty and if the construct has multiple components that labelers differ on, the label does not indicate which element they disagree in. The approach described below overcomes both of these issues by decomposing the construct of hate speech into multiple labeling items and by giving labelers Likert-style response options to incorporate uncertainty. The labeling instrument, similar to a a survey instrument, has three sections: 1) 6/33 identity target items, which establish whether the comment targets a protected group , 2) scale items that measure the content of the comment along several distinguishing features of hate speech, and 3) a set of demographic questions asked about the labelers. The target items and scale items are asked for each of the comments that labelers review, and then are followed by the demographic items. One of the scale items, sentiment, is asked before the target items, to get one measure for items that target a non-protected group or no group at all. If no identity groups were mentioned they were not asked any remaining scale items and proceeded to the next comment. If at least one identity group was mentioned they were asked to specify the sub-identity group(s), 2 and then asked the remaining scale items. All comments were also rated on a binary hate speech item sourced from Siegel et al. (2019) to allow comparison to the current best practice in binary hate-speech measurement. Differences in labeler knowledge and views make consistent annotations difficult to obtain. We address differences in labeler knowledge by providing a dictionary tool for niche slurs that appear in the comments we showed to labelers. Using a new dictionary, slur words were underlined in our survey user interface. If the user moved their mouse over the underlined slur word they would be shown a tooltip stating \"This word may be a slur against identity group [X]\" (see Figure 1 for an example). This user interface feature was intended to reduce response variation due to varying awareness of slur terms, as well as to make noticeable any coded slur language in the comment (for more details on the problem of covert slurs see Magu et al. 2017). After rating the comments reviewers were asked a series of demographic questions about themselves, followed by an optional free response feedback item. The demographic items included the reviewer's gender, education, race, year of birth, income, religion, sexual orientation, and political ideology.\n\n\nComment collection\n\nWe sourced our comments from three major social media platforms: YouTube, Twitter, and Reddit. We chose these platforms for their popularity, as respectively, they are used by 73%, 22%, and 11% of U.S. adults (Perrin et al. 2019). Prior work on hate speech has often focused on a single platform, commonly Twitter, but our goal was to study hate speech in a variety of settings and to ultimately build an algorithmic model to accurately measure hate speech across multiple platforms (Fortuna et al. 2018). We used public APIs to download recent comments posted to each site. Comments were considered eligible for labeling if they were written primarily in English and were not too short (< 4 characters) or too long (> 600 characters) after removing URLs, phone numbers and contiguous whitespace. Our comment collection took place between March and August 2019.\n\nOn Reddit we collected all comments from the real-time stream of the subreddit \"/r/all\". For Twitter, we collected tweets from Twitter's streaming API, which is a random sample of all tweets on Twitter. YouTube required additional consideration because one must first select videos and then download comments associated with the selected videos. We searched for videos within proximity of the top 300 most populated U.S. cities in order to focus on videos originating in the U.S. and most likely to contain English comments with U.S.-based authors. From those videos we then downloaded all comments and responses.\n\n\nCrowdsourced labeling\n\nHate speech is a rare phenomenon, estimated at less than 1% of online comments when viewed as a binary outcome, so randomly sampling from the collected comments would not have been efficient. That is, the outcome in the labeled data would be highly imbalanced at < 1% hate speech and 99% non-hate speech, which would make it difficult for statistical machine learning analysis to find patterns that differentiate between hate speech and non-hate speech and costly for our labeling process. Instead, we used a sampling method that would increase the relevance of the labeled comments to our theorized levels of hate speech; we targeted an even distribution of labeled comments across our 8 levels (12.5% each). We also wanted to avoid common shortcuts to increase rates of hate speech in labeled text, such as filtering on slur terms or Twitter hashtags. Those approaches would artificially reduce the linguistic variation in the comments and allow the deep learning to learn those shortcuts (confounded associations) without capturing true patterns (i.e. causal relationships), which is known as the \"Clever Hans\" effect (Heinzerling 2019;Niven et al. 2019). In an effort to maximize the generalizability of our deep learning algorithm, we maintained a positive probability of selection for all sampled comments (i.e. no comments would be excluded based on their word usage).\n\nOur sampling method relied on two dimensions for stratified sampling: 1) a relevance estimate of how likely the comment was to contain a target identity group, and 2) a hypothesis score for how hateful the comment was estimated to be. Both scores were built from a pilot set of 4,000 labeled comments, using pre-trained Universal Sentence Encoder representations (TensorFlow) plus a genetically optimized prediction head (Olson, Urbanowicz, et al. 2016). For identity prediction the genetic optimization algorithm selected a multilayer perceptron model while for the hypothesis score it selected a random forest. 3 With each future iteration of the project we can leverage the models developed in the prior iteration to improve the stratified sampling efficiency.\n\nWe used the identity relevance and hate speech hypothesis scores to create five stratification bins: 1) irrelevant (i.e. estimated to contain no references to identity groups), 2) relevant and low on predicted hate speech score (potential counterspeech or positive identity speech), 3) relevant and moderate on predicted hate speech score (neutral), 4) relevant and high on predicted hate speech score (low or moderate intensity hate speech), and 5) relevant and very high on predicted hate speech score (violent hate speech). We heavily oversampled bins 2, 4, and 5, and undersampled bins 1 and 3. Because this stratification scheme covered all comments, each comment had a positive probability of being sampled, but we improved the likelihood of labeling comments that were some form of hate speech or counterspeech. As in a case-control study, this biased sample could be re-weighted back to the original population of comments through inverse probability weighting (Horvitz et al. 1952). We incorporated platform sample size targets such that our labeled data consisted of 40% sourced from Reddit, 40% from Twitter, and 20% from YouTube.\n\nThe sampled comments were then compiled into groups of 4 \"original comments\", stratified across our bins so that each group contained comments across the hypothesized hate speech spectrum. Each comment group was randomly allocated to 4 comment batches to ensure 4 ratings per comment, and each batch also included 6 reference set comments stratified across our 6 reference set levels. This design was chosen to generate a single network across all raters, which were linked through the comment groups plus the random selection from the reference set. In Figure 2 we show a simplified example of overlapping comment ratings that yield a single network across reviewers. This experimental design further ensured that every reviewer would receive comments across our hate speech scale; we eliminated the risk that by random chance some raters would only review comments in a narrow range of the scale. We connected the labeling instrument, hosted on Qualtrics, to a comment batch server using web service requests in order to reserve comment batches and then mark them as completed. The comment batch server was hosted as a Python serverless function in Google Cloud with a MySQL database backend. Each reviewer was given a random comment batch of 26 comments that was not already reserved by another worker and that had not yet been completed. If a given comment batch was not completed with 10 hours it was returned to the pool of unreserved comments.\n\nHuman reviewers were recruited from Amazon Mechanical Turk to complete our labeling instrument hosted on an external site. Each labeler was given 26 comments-6 reference set comments and 20 \"original comments\"-to label. Median time to complete the instrument was 49 minutes. Participants were compensated $7 for their participation in our study, yielding a median pay rate of $8.57 per hour. A manual review of the worker feedback on the task showed high satisfaction with the compensation for the task, and appreciation that the results would contribute to an understanding of social media conversations.\n\n\nConstructing a scale with Rasch measurement theory\n\nOur scaling procedure, as described in this section, converted the collection of ordinal ratings from crowdsourced human reviewers into a continuous, linear hate speech scale. We identified Rasch item response theory (IRT) as the appropriate psychometric framework to analyze the ratings and to transform them into the continuous score.\n\n\n9/33\n\nWe selected the Rasch family of item response models because their theoretical properties have provably distinct advantages over other forms of IRT, leading to their elevated status as \"the necessary and sufficient process for measurement\" (Wright 1992). Rasch (1960Rasch ( , 1980 first described the requirements for objective measurement. Only Rasch models are founded on Fisherian sufficient statistics (Fisher 1934) that allow the latent variable, rater, and item parameters to be estimated separately using additive models (Andrich 2011).\n\nNotably, Rasch models satisfy the five requirements of invariant measurement (Engelhard Jr 2013, Ch. 1) as translated into our hate speech application:\n\n1. Item invariance: measurement of comments must be independent of the particular items (survey questions) used for data collection.\n\n2. Non-crossing comment response functions: a more hateful comment must always have a higher probability of a more hateful response option than a less hateful comment.\n\n3. Comment invariance: The calibration of items and response options must be independent of the particular comments that were labeled.\n\n4. Non-crossing item response functions: A comment must have a higher (more indicative of hatefulness) expected response on an easier item (lower difficulty) compared to a harder item (higher difficulty).\n\n\nConstruct map:\n\nComments, items, item responses, and raters must be simultaneously located on a single underlying continuous latent variable.\n\nThe benefit of the invariant measurement is that the resulting scale is not specific to the particular survey items, raters, or comments that we analyzed in this study. Instead, we have created a measurement system for hate speech that can be applied to future text, incorporate improved survey items, and use different raters, while maintaining the ability to analyze all such objects on the original scale we have constructed in this initial work. In other words, we are able to construct a measurement device for hate speech that provides stability of meaning over a long time period, rather than an arbitrary metric that is valid only for our currently acquired data and instrument. More detailed discussions of the \"Rasch rationale\" are provided in M. Wilson (2004, Ch. 6) and Wright and Masters (1982, Ch. 1). The partial credit model (Masters 1982) was the appropriate model within the Rasch family because our labeling instrument did not use the same set of response options for each item. We avoided the two-parameter or three-parameter families of IRT models such as the graded response model (Samejima 2016) or generalized partial credit model (Muraki 1992). Those non-Rasch models do not admit the invariance properties of Rasch measurement. Specifically, the estimation of item discrimination parameters (aka \"slope parameter\") in a 2-or 3-parameter model implicitly results in the item difficulties no longer being separable from person (comment) abilities (Wright and Masters 1982, Ch. 1, p. 8). That result can be visualized by comparing the item characteristic curves from such models and noting that they must cross, because they do not have the same shape (M. Wilson 2004, Ch. 6, p. 110 -113).\n\nWe further avoided principal component analysis and factor analysis because they also do not transform raw scores into objective measures. Rather, they analyze the item responses as though they were already linear measures, when in fact they are only ordinal categorical ratings (Wright 1996). Moreover, neither method is sample invariant: they generate results that are intrinsically limited to the specific comments, items, and raters that were observed (Rasch 1953).\n\n\nFaceted Rasch measurement\n\nIn the late 1980s Linacre extended the Rasch family of models to include judge-mediated assessments (Linacre 1987(Linacre , 1989, which applies to our labeled dataset generation where a human reviewer completed a survey in which they analyzed textual comments. Treating the rater as an additional facet of the scaling procedure enabled the estimation of a rater \"fixed effect\" or \"severity\" parameter with the same hate speech scale units as the comment scores, item difficulty estimates, and item step thresholds. This severity parameter can be viewed as an estimate of survey interpretation bias, where raters vary in how aggressively or loosely they interpret the scale items. Those rater fixed effects then no longer influence the statistical estimation of the comment abilities, item difficulties, or item steps. The result is a more objective estimate of the hate speech score for an individual comment that is independent of the severity of the raters who happen to be assigned to review that comment. Extensive details on faceted Rasch models can be found in Engelhard Jr and Wind (2018), Eckes (2015), and Linacre (1989).\n\nWith the faceted partial credit model the probability of a given response to an item can be written formally as the following equation (Eckes 2015;Linacre and Wright 2002):\nlog p nijk p nijk\u22121 = \u03b8 n \u2212 \u03b4 i \u2212 \u03b1 j \u2212 \u03c4 k(1)\nwhere:\n\n\u2022 p nijk is the probability of comment n being rated as response k by rater j on item i,\n\n\u2022 p nijk\u22121 is the probability of comment n being rated as response k \u2212 1 by rater j on item i,\n\n\u2022 \u03b8 n is the ability of comment n,\n\n\u2022 \u03b4 i is the difficulty of item i,\n\n\u2022 \u03b1 j is the first-order bias (\"severity\") of rater j,\n\n\u2022 \u03c4 k is the difficulty of receiving rating k relative to rating k \u2212 1.\n\nFaceted Rasch models include a noteworthy implication for inter-rater (kappa) reliability: it is not essential that different raters provide the same responses to an item when analyzing a certain comment. There is a growing body of related literature showing that a single \"true\" labeled response is often unrealistic (Aroyo et al. 2019;Geva et al. 2019;Palomaki et al. 2018). Instead, we want within-rater consistency in item interpretation so that their estimated severity acts as a strong summary measure of their individual style of rating. In fact, for raters with very different estimated severities, we would expect them to provide different ratings on an item when analyzing the same comment -that would be consistent with the measurement model (and common sense). Reliability of ratings and unbiasedness are two distinct phenomena; for example, a given comment may exhibit high reliability due to multiple raters agreeing on an biased assessment (Henning 1996). This is a marked psychometric departure from prior studies of hate speech or other supervised natural language processing topics, which have commonly relied on inter-rater reliability as the primary quality metric for dataset labeling (Ross et al. 2016).\n\nWe used Facets software (Linacre 2019) to conduct the many-facet Rasch scaling. A sequence of four scaling estimates were conducted, in which increasing percentages of low-quality raters were removed, and response options were collapsed to reduce 11/33 noise in the estimates. The details of the rater quality analysis and response collapsing are described in the appendix.\n\n\nAutomated score prediction with deep learning\n\nAfter scaling, we trained an algorithm to estimate a mapping from the raw text to our latent hate speech score. Deep learning has shown the best performance for this type of task, provided that sample size is not too small. The current best architectures are based on transfer learning (Pan et al. 2009) and Transformer units, such as T5, ALBERT, and RoBERTa. These architectures consist of a language model that is first trained in an unsupervised fashion on large amounts of general text, typically millions of Wikipedia articles and about 10,000 books. This teaches the algorithm the meaning of words within their context, allowing it to read new types of text.\n\nWe then conducted the supervised learning: we supplied the raw comment text as our input observations, with the ultimate goal of predicting the latent hate speech score. We made four novel changes in our supervised approach: 1) rather than predict the hate speech score directly, we instead predicted the responses to each survey item using a multitask architecture (i.e. multiple outputs within a single model) (Ruder 2017), 2) each survey item was directly analyzed as an ordinal outcome using the consistent rank logits method of ordinal softmax activation and ordinal cross-entropy loss (Cao et al. 2019), 3) we supplied the rater's estimated survey interpretation bias (severity) as an additional non-text input to allow the model to adjust its understanding of the likely item response, and 4) we tagged known slurs in the raw text of the comments, giving the deep learning models comparable information to what the human annotators were provided. The individual item response predictions could then be transformed into latent scores using the estimated IRT parameters. See Figure 3 for a depiction of this architecture. We believe that this approach represents a new way of integrating deep learning with item response theory for measuring phenomena that can be decomposed into multiple items that are reviewed by human raters. We now describe the details of those steps.\n\nThe simplest supervised learning strategy would be to predict the continuous hate score directly, and to ignore the intermediate item ratings that led to that score. With this architecture the data structure would consist of one observation per comment. The estimated severity (bias) for each labeler would not need to be incorporated as an auxiliary input because the score was already debiased through the IRT scaling. The loss function could simply be mean-squared error and the architecture could consist of a Transformer-based representation subnetwork applied to the raw text, followed by one or more dense layers to learn the mapping to the continuous score. In lieu of the dense layers, the language representation could be applied to generate a summary feature vector for each observation, and traditional machine learning such as XGBoost , BART (Chipman et al. 2010), SuperLearner ensembling (Polley et al. 2019), etc. could be applied to predict the continuous score. We implemented both the full neural architecture (dense layers) as well as the traditional machine learning structure with TPOT optimization (Olson and Moore 2019) as benchmark options.\n\n\nSurvey items as supervised concept learning\n\nWe hypothesized that an improved supervised learning architecture would instead attempt to predict the human rating on each of the survey items (as listed in Table  A1). Those intermediate predictions could then be transformed into the continuous score using the IRT parameters estimated during the scaling process. The exciting insight of this approach is that the items facilitate what could be called directly Comment text is fed into a deep natural language processing algorithm to convert it into a fixed vector representation. Then a series of fully connected layers learns how to combine that vector representation into latent variables that can predict the response to each item on the labeling instrument. The fully connected layers also take as input the estimated rater bias for each comment rating to adjust their expected item response predictions. The predicted item responses are then transformed via IRT into the continuous hate speech score. Comment text is fed into a deep natural language processing algorithm to convert it into a fixed vector representation. One or more hidden layers, or traditional machine learning algorithms, learn a function to map that fixed representation to minimize meansquared error loss for predicting the continuous hate score. supervised concept learning. In a typical neural architecture the final hidden layer has developed the highest level concepts that best predict the outcomes in the output layer based on the architectural hyperparameters: loss function, number of hidden units, activation function, random initialization of weights, dropout, and optimization over multiple epochs of a certain batch size. Exactly what those final concepts mean is not immediately obvious, and is the result of a greedy stochastic process that reflects a local optimum. In contrast with our method we know from our theorization and development of the construct the exact concepts that need to be learned as well as the nonlinear function that transforms those constructs to the continuous score, and we have labeled data for each of those concepts: the survey item responses from the human labelers. This is a powerful shortcut in the supervised learning process that largely eliminates the need for architecture search or hyperparameter optimization in that final concept layer of the neural network. We know how many hidden units there are, the form of the loss function for those units, and the nonlinear activation function to transform those units into the final output. And it provides direct supervision during the optimization process for those concepts: we don't have to rely on backpropagation of errors from the final continuous output.\n\n\nMultitask architecture\n\nWhile there could be a separate model for each item, a multitask architecture was advantageous for three reasons: efficiency, generalizability, and convenience. Multitask architectures can improve efficiency and generalization because they bias the network to learn a shared representation of concepts that explains multiple related outputs (Caruana 1997;Goodfellow et al. 2016, \u00a77.7). Multitask architectures are gaining increasing adoption across deep learning tasks, include face analysis (Ranjan et al. 2017), language modeling (CITE), self-driving cars (Karpathy 2019), etc. We examined the relatedness of items in our scale through a correlation heatmap ( Figure  8) and found strong levels of correlation, supporting the likely benefit of multitask learning. Multitask items offer convenience through packaging multiple outputs into a single architecture, reducing the lines of code needed for training and prediction.\n\n\nOrdinal loss and activation functions\n\nEach item served as an output in the network, and the label was an ordinal Likert-style variable with 5 response options typically, such as: {strongly disagree, disagree, neutral, agree, strongly agree}. The loss function for each output (task) would benefit from acknowledging the ordinal nature of the outcomes: predicted probability mass assigned farther from the true label is worse than probability mass allocated to the adjacent label(s) (Hou et al. 2016). For example, when a human rater labels a comment as \"strongly disagree\" on the \"calls for violence\" item, the predicted probability of \"strongly agree\" should contribute much more to the loss than \"disagree\", because it is a much worse prediction. This has been recognized as a desire for unimodal probability distributions when conducting ordinal classification (Beckham et al. 2017;Costa et al. 2008). Cross entropy, the standard loss function used for discrete labels, does not do this. It only examines the probability placed on the true label and encourages that probability to be maximized.\n\nWe incorporated the method of Cao et al. (2019) termed consistent rank logits (CORAL), to explicitly handle the ordinal nature of predicting the rating on each item. When applied to an item with k possible ratings (e.g. 5 for a Likert-style item), the CORAL method decomposes an ordinal regression into k \u2212 1 binary classification tasks in which the model learns to predict if the expected response is greater than or equal to each possible rating; the highest rating value is skipped because its 14/33 probability prediction will be the remainder. The loss function becomes the (possibly weighted) sum of the cross-entropies of each of these binary classification tasks, which we call ordinal cross-entropy. The set of binary classifiers uses shared weights combined with separate trainable bias parameters, which guarantees that the output yields a unimodal probability distribution over the possible item ratings; for this reason we term the ordinal activation function ordinal softmax. We implemented a Keras version of the CORAL method for this work (Kennedy 2020).\n\n\nPartial credit IRT transformation of predictions\n\nOnce the multi-task deep learning model has been trained to generate item-level predictions (i.e. probability distribution over each response option), those predictions need to be fed into an anchored faceted Rasch model to be converted into the predicted hate score. The simplest approach would be, for each of the 10 items, to predict the response option (label) with the highest estimated probability. For example, if the model estimated that the genocide item would be answered as \"yes\" at 10% probability and \"no\" at 90% probability, the model's label prediction would be \"no\". So the model would generate estimated item labels for each comment, and those predicted ratings would be scaled by running the partial credit scaling procedure with item and response parameters anchored (fixed) to the values from the original faceted Rasch scaling. The measurement model for this deep learning scaling differs from the Rasch scaling we used to create the continuous outcome variable because we have only a single rater -the deep learning model itself. That is the reason that we use the partial credit model for this step, rather than a faceted Rasch model that estimates a severity parameter for each rater.\n\n\nPlausible value sampling\n\nThere are two key downsides to the partial credit scaling as described:\n\n1. The number of unique predictions generated by the partial credit model is limited to the cardinality of the raw scores. This is because the raw score (the sum of the individual item ratings) is a sufficient statistic for the continuous latent variable generated by Rasch measurement models. In our case the final item setup had 33 possible raw scores (0 -32), so only 33 unique point estimates could be generated by the partial credit model transformation. Although certainly more granular than predicting a yes/no or ordinal label, that seems somewhat coarse when covering a continuous spectrum from -8 to +5, which could limit the predictive performance of this version of the model.\n\n2. Possibly more importantly, in selecting the most probable rating we discard the information contained in the predicted probability distribution for each item, i.e. how confident the model is about a predicted item rating for a given comment. That information seems quite valuable, and is missing from the original labeled data from the human raters -we only know the single response option that they selected (presumably the highest probability response option from their mental model of the rating task). 4 Incorporating that probability information will also improve the sensitivity of overall model performance to improvements in the multi-task item predictions: architecture improvements will translate into improved probability predictions more efficiently than improved label (rating) predictions.\n\nHow best to solve these problems then, generating more precise predictions that incorporate the confidence information from the predicted probability distributions? We chose to take a plausible value sampling approach, which resolved both issues. Rather than select the most probable response for each item, we sampled many possible item ratings for each comment based on the probability distribution for each item. Each \"plausible value\" for an item rating was selected at random from the possible response options, with discrete probability equal to the model's predicted probability for each response option. In other words, we asked the model to rate each comment many times, and to select each item rating by a probability-weighted sample of the response options. Those replicated ratings were then scaled simultaneously in the anchored partial credit model to yield an estimated hate score for each comment. We tested different replication counts (1,2,4,8,10,16,24,32,64,128,256) to examine the trade-offs of predictive performance and computation time.\n\n3.6.6 Dynamic adjustment via revised slur tagging As noted previously, the raw comment text was processed so that any known slurs that had been highlighted during the annotation process were also tagged for use in the deep learning model training. This gave the models the potential to incorporate slur tagging into their contextual language representation, if it was found to be useful. While our intent with the slur tagging was primarily to improve the quality of the labeled data, it has an interesting implication for the deep learning side as well. In effect, it partially decouples the understanding of slur terms from the model's predictions, meaning that we do not have to keep fixed the slur tagging as it was implemented during human annotation. This has a major advantage: as coded slur terms and other covert language evolve in the future, or as we simply develop a more strongly theorized list of slur terms, we can update our slur dictionary to reflect those changes and improve our model's ability to measure contemporary hate speech, even when those terms were never seen in the original training data. We call this dynamic adjustment of slur tagging during prediction.\n\nFor example, our training data predates the coronavirus epidemic, so the training data contains no examples of COVID-related hate speech, such as the racist phrase \"kung flu.\" However, if we add that phrase to our slur dictionary and tag it appropriately in future raw comments, our model prediction then incorporates that side knowledge to better measure the hatefulness of comments that adopt that novel racial slur. We can also do the chronological reverse: when applying our model to older text, such as historical literature, we can modify the slur tagging preprocessing to reflect the slurs as they were used at that time. This slur tagging process can further benefit from improvements in the tagging methodology: model-based tagging, rather than simple dictionary lookups, can reduce false positives where context demonstrates that a word or phrase is unlikely to intended as a slur.\n\n\nResults\n\nWe now report on our observed results from the evaluation of the allocation of comments to raters (judging plan), application of faceted IRT to our labeled comments (scaling), and our accuracy at predicting the hate score using deep learning on the raw comment text.\n\n\n16/33\n\n\nNetwork analysis for comment batch annotation\n\nWe evaluated the network linkage across the raters, original comments, and reference set comments. We confirmed that our batch creation procedure generated a single linked network, with no disjoint subsets, that would allow the estimation of rater severity (\"fixed effects\"). The diameter of the network was 6, meaning that any two points were connected by traveling across no more than 6 edges. The average distance was 3.6, meaning that any two nodes were typically about 4 edges apart.\n\n\nRasch measurement theory scaling\n\nOur faceted partial credit model achieved a case (comment) reliability of 0.94. Our estimated rater separation reliability was also 0.94, suggesting that our judging plan resulted in high accuracy at estimating the individual severity for the labelers. Following Linacre (1999), we confirmed that for each item the average hate score increased monotonically with more hateful response options.\n\nThe calibrated Wright Map showing our scale across comments, items, item steps, and raters is shown in Figure 5.  (Table 4 and Figure 5) were consistent with our hypothesized item difficulties, which speaks to the construct validity of our instrument. Our item fit statistics exhibited reasonable fit to our assumed Rasch model. Both infit (inlier sensitive) and outfit (outlier sensitive) mean-squares fell We reviewed the scaling results on our reference set comments, which were each rated 500 -1200 times. Figure 6 displays the ability point estimates for each reference set comment grouped into its qualitative level. The average score within each level showed the expected monotonic increase in hate speech for increasing levels. However, the level pairs 2 & 3 and 4 & 5 did not show large absolute differences in their average hate speech scores. We also noted that some comments appeared to be better moved into adjacent levels based on their hate speech scores. These results imply that we should revisit our theorization for the reference set, review the criteria for the comments to determine if they are better placed in adjacent levels, and consider substituting ambiguous comments with more clearly exemplary comments. We may want to simplify the reference set by merging levels 2 & 3 and levels 4 & 5. Figure 6. Evaluation of scaling on reference set Ability estimate for each reference set comment. The horizontal blue line is the average score within the theorized qualitative level.\n\nWe examined the distribution of the hate speech score across our three platforms (Figure 7). YouTube and Reddit looked very comparable. Twitter showed a similar distribution but shifted to the left, with a noticeable reduction in scores at the high end of our hate speech scale. This result suggests that we may need to improve the allocation of Twitter comments into batches in order to increase the percentage of comments on the hateful side of the spectrum. Our observed results may also indicate that Twitter already conducts some sort of automated filtering of hateful comments before allowing the comments to be downloaded through their API, or that the Perspective API is less accurate on Twitter comments. Alternatively, this may suggest differential item functioning of our labeling instrument for Twitter comments, if they have linguistic characteristics that cause the raters to interpret them differently from comments sourced from YouTube or Reddit. It is important to note though that these results reflect the unweighted distribution of our labeled sample, which was intentionally skewed during the comment collection and batch creation process. Therefore these distributions should not be seen as population estimates of the true score distribution on each platform, but rather as descriptions of our training data. Future work will apply weighting corrections to the training data to estimate population-level parameters. A review of the correlation across items, shown in Figure 8, was suggestive that a multi-task deep learning architecture could benefit from sharing information across each item rating prediction.\n\n\nDeep natural language processing\n\nAfter scaling, we used supervised deep learning to estimate a mapping from the raw text to the continuous hate speech score. Our current best models used a RoBERTa-Large contextual language base to process the raw text into a vector representation (Y. Liu et al. 2019), followed by a 64-unit hidden layer with 10% dropout, and included fine-tuning of the language representation subnetwork using HuggingFace software's Keras implementation (Chollet et al. 2015;Wolf et al. 2019). Results from our model testing are shown in Table 5. Direct prediction of the continuous hate score has currently achieved the lowest root mean-squared error (RMSE), although our proposed multitask networks that are transformed via IRT achieved comparable performance and slightly lower mean absolute error with the benefit of explainability. In the multitask outcome representation we did not find a benefit from ordinal modeling of the items compared to categorical modeling. Table 5. Supervised learning results.. FE = feature extraction (i.e. freezing the weights in the language representation layers). FT = fine-tuning of a transformer-based architecture, as compared to feature extraction. WWM = whole-word model, referring to the form of masked language modeling. CV = cross-validation. RMSE = root mean-squared error. Corr = linear (Pearson) correlation. MAE = mean absolute error.\n\nPrediction Algorithm Outcome Representation a Because this is a probability prediction for a binary outcome, we linearly calibrate the probability output to our continuous outcome by fitting an OLS regression on the training set with the probability output as the only feature, then apply the prediction of that regression estimator to the validation data.\n\n\nDiscussion\n\nGrounded by theorization, our empirical results showed that we were successful in both major sub-projects of this work: 1) creating a 10-item labeling instrument 20/33 processed with faceted Rasch modeling to yield a continuous scale for hate speech, including counterspeech, and 2) predicting that scale on unseen social media comments using Transformer-based natural language processing. That prediction could be accomplished either by directly predicting the hate score from the raw text, or by taking advantage of the Rasch transformation by first predicting the human ratings on the ten constituent components of hate speech (i.e. the multitask architecture), and then aggregating multiple possible ratings of each comment (plausible values) into a predicted hate score with a fixed-parameter Rasch scaling. The two prongs of this work allow arbitrary text to be placed on an interval spectrum ranging from genocidal hate speech on one extreme to supportive identity speech on the other extreme. In sum, we successfully created an initial measurement system for hate speech. Future work will no doubt provide further improvements to the scale creation and prediction algorithm, as well as the source data collection and the comment labeling system.\n\nWhile we have focused on our hate speech problem of interest, the methodology we have developed is applicable whenever humans review data to make a judgment, and that summary judgment could be based on multiple component parts. That data could be images or video just as well as text, or other data structures such as time series. Within natural language processing, sentiment analysis is one of the most widely used supervised learning problems; we suspect that the application of our method to measure sentiment would lead to substantial improvements in that subfield. Automated essay grading might be an even more straight-forward application of our method. Possible video applications include the automated evaluation of technical skill derived from videos of surgical procedures, where a multi-component labeling instrument is already used by human judges, called \"OSATS\" (Martin et al. 1997), and the assessment of the quality of surgical wound closure (Blencowe et al. 2019). Numerous other applications could likely be developed in future years.\n\n\nLimitations and future work\n\nOur work thus far is promising but with some known limitations. The ten items used for scaling deserve further comparison and development; we may be able to remove certain items or add additional items to increase reliability. During the scale development our estimated item fit statistics encouraged the collapsing of response options to improve invariance. This suggests that reviewers had difficulty with consistently differentiating between response options for several items. This is quite reasonable given that our response options were primarily Likert-style \"strongly agree\" to \"strongly disagree\" -those options are inherently subjective and ambiguous. Additional theorization, qualitative review, and pilot testing of improved response options could lead to better measurement characteristics, particularly for the items with greater estimated difficulty such as genocide and violence. Clearer, more objective response options that are consistently interpreted should then result in reduced variance in the rater severity parameter, and increased precision for the latent variable. That increased precision may better separate the latent variable estimates for the different theorized levels in our reference set. Further refinement of the reference set and theorized levels may help to provide even more granular distinct levels of measurement. Incorporation of the rater bundle model into our estimation procedure will also provide a more accurate estimate of instrument reliability (M. Wilson and Hoskens 2001).\n\nIn addition to those incremental improvements, our leveraging of item response modeling opens up powerful methods for the analysis of bias and fairness. The field of measurement has long examined bias in exam questions through the lenses of differential item functioning (DIF) and differential rater severity (Myford et al. 2003). DIF methods can test if one of our 10 components of hate speech does not operate 21/33 consistently for certain subsets of comments. For example, if reviewers are more likely to rate comments with a racial dialect as being disrespectful (Sap et al. 2019), we can statistically identify the issue and work to create alternative item wording that mitigates the bias. If certain individual reviewers interpret the items more harshly for comments that include sexist speech, we can also identify that statistically and correct for that bias in our analysis. These types of analyses are standard practice when analyzing item response theory scales, and can be executed within a formal statistical framework that is comprehensive for the wide variety of identity groups that are included in our labeled data. Evaluation and improvement of bias & fairness will be a significant part of our future work in this line of research.\n\nWith regard to the deep learning modeling, we have not yet reached the limits of supervised performance using our existing training data. The language representation backend can be continually upgraded as new language models are developed, such as T5 (Raffel et al. 2019). In-domain pretraining of the language model on our own corpus of social media comments would likely improve performance, which is an upgrade we are currently exploring. Both the multi-task architecture and implementation of ordinal loss and activation likely have untapped performance improvements, such as those that might be discovered through neural architecture search or through customized task weighting (Klyuchnikov et al. 2020). The integration of the IRT transformation with the multi-task predictions bears substantial future experimentation to answer key questions. Can we approximate the IRT transformation through an integrated neural subnetwork? Is plausible value sampling the best way to capture uncertainty in the predicted ratings? What about using the item ratings as a pretraining objective for a two-stage model that predicts the continuous score directly, or integrating the item ratings and the continuous score into a single multi-task network? Robustness to misspellings or other adversarial orthography would be yet another helpful improvement (Sun et al. 2020). Lastly, numerous low-level optimization improvements are likely possible for the training of deep models, including learning rate scheduling, next-generation optimizers (e.g. Yogi - Zaheer et al. (2018)), and differential learning rates.\n\nWe have a number of longer term goals for future work in our hate speech research agenda. Most urgently, there is a need to apply this measurement technology to causal inference problems such as estimating the effects of policy changes, current events, and user interface interventions on hate speech, as well as purely descriptive work to report on temporal hate speech trends. Extending our current model to English-speaking countries outside of the United States (e.g. the United Kingdom, Canada, or English-speaking African states) will require a broader theorization of hate speech for variation in culture and configurations of vulnerable populations. Expanding our platform sources will likely continue to be fruitful for generalizability and linguistic robustness; we hope to include data from Facebook, Instagram, Wikipedia, Twitch, and WhatsApp in later work. Expanding to additional languages, especially Sinhala, Khmer, Arabic, Hindi, and Portuguese, will allow our work to be relevant to developing countries where ethnic conflict, genocide, and extremist violence may be more overt than in the United States. Application of our model and methodology to low-resource languages will be facilitated by our dynamic slur tagging approach, where existing slur lexicons can facilitate early pilot models prior to the development of a full labeled corpus. Releasing our models to select partners through an API will facilitate incorporating them into browser plugins, social media platforms, and other user interface interventions. We also plan to apply our models to extremist literature, such as The Turner Diaries (Pierce et al. 1978) and Hitler's Mein Kampf, to better understand the role of hate speech in radicalizing literary works.\n\n\n22/33\n\nIn this paper we described the development of a novel, holistic methodology for measuring hate speech in a scalable, debiased, explainable manner. Based on prior literature, we theorized eight qualitative levels on a scale ranging from genocidal hate speech to counterspeech and collected empirical observations as examples of each level (the reference set). We developed a labeling instrument to record ordinal ratings on 10 components of hate speech through a reviewing process. We collected online comments from three major social media platforms (YouTube, Twitter, and Reddit) and sampled them in such a way as to focus our labeling on comments more likely to be hate speech or counterspeech, but maintaining generalizability by ensuring that all collected comments had a positive probability of selection in our sampling procedure. We created a crowdsourcing-based labeling procedure to allocate comments to reviewers and yield a network linking all reviewers to each other through overlapping comment reviews, facilitating the estimation of the survey interpretation bias of each reviewer (a rater \"fixed effect\"). We fit the faceted Rasch partial credit model to create a sample-invariant scale for hate speech that placed comments, survey instrument items, and raters on the same continuous metric, and adjusted the estimated comment hate speech score for the estimated survey interpretation bias of the raters who happened to rate that comment. The statistical diagnostics from the Rasch model allowed us to evaluate the quality of each reviewer and remove crowdsource workers with low-quality responses. Finally, we applied supervised, multitask, Transformer-based deep learning with rater bias as an auxiliary input, followed by an IRT nonlinear post-processsing transformation with plausible value sampling, to learn an estimator that maps raw text to the hate speech score in a robust, explainable manner. That deep learning model was encouraged to gain a more general understanding of language through training on data from three separate social media platforms.\n\nSeparately, each of these steps represents a novel contribution to the hate speech literature. In combination, we believe our methodology proposes a paradigm shift in the understanding and measurement of hate speech, and in supervised learning of human-labeled data more broadly. We hope that our work will encourage other researchers to adopt Constructing Measures-style theoretical development & measurement in the study of complex social phenomena, including a transition from dichotomous or ordinal outcomes to continuous, linear scales estimated via Rasch-based item response modeling, corrected for survey interpretation bias of reviewers, and integrated into explainable multitask deep learning architectures. For future updates on our project, data, and models, please visit hatespeech.berkeley.edu.\n\n\nFunding\n\nThis work was funded by the UC Berkeley D-Lab, the Anti-Defamation League, the Berkeley Institute for Data Science, and Google Jigsaw.\n\n\nA Appendix\n\nA.1 Scale items from labeling instrument Table A1. Scale items from labeling instrument. These items operationalize our hate speech construct and are aggregated into a continuous score via Rasch measurement theory. The tenth item, a binary label for hate speech, was included for benchmarking purposes, however because it was part of the annotation process we also incorporated it into our scaling procedure.\n\nItem Does this comment contain hate speech, defined as \"bias-motivated, hostile and malicious language targeted at a person/group because of their actual or perceived innate characteristics, especially when the group is unnecessarily labeled (e.g., \"jew bankers\", \"n\u00e2\u0102\u015e hooligans\").\" The comment contains hate speech if slurs or derogatory language are used toward any person or group regardless of whether or not the target is a member of the slur-target group. (e.g. a comment calling Trump a faggot or a n***** still contains hate speech).\n\n\nYes, no, unclear\n\na This item is converted to a binary value of 0 if no identities are present and 1 if any identities are present. It is not directly used in the scale but if a comment is not flagged as having at least one identity group target then the remaining scale items are skipped in our labeling instrument.\n\nb The question wording and response options for this item are sourced from Siegel et al. (2019).\n\nA.2 Identity group targets from labeling instrument 29/33 People with physical disabilities (e.g., use of wheelchair), people with cognitive disorders (e.g., autism) or learning disabilities (e.g., Down syndrome), people with mental health problems (e.g., depression, addiction), visually impaired people, hearing impaired people, no specific disability\n\n\nA.3 Data structure for deep learning\n\nOur data structure for the supervised deep learning treated each review of a comment as an observational unit. For a typical comment that was reviewed four times there would be four observations in our training data. Each observation would have the same raw comment text but a unique rater severity for each reviewer, plus the corresponding item ratings that the reviewer provided for that comment. This differs from prior studies which have generally aggregated the data to have one observation per comment, taking the mean or mode of the binary outcome label(s) from the reviewers, and usually discarding comments where inter-rater agreement did not exceed a certain threshold. See Table A3 for an example of the supervised learning data structure. Due to this repeated measures (or hierarchical) data structure we could not use simple randomization to create training/test splits. By random chance it would be likely that some of the reviews for each individual comment would be in the training set and some in the test set, making the test set performance no longer an unbiased estimator of performance on future unseen comments (i.e. due to \"data leakage\" across the training/test partitioning). Therefore it was important to conduct clustered randomization at the comment level when creating training/test splits, taking into account the hierarchical data structure so that reviews of a given comment would all 30/33 be assigned either to training or to test, and not both.\n\n\nA.4 Rater quality analysis\n\nCrowdsourced labeling is thought to generally provide research-quality data with improved diversity over convenience samples such as undergraduate students (Berinsky et al. 2012). However, it remained important to evaluate the quality of raters that created our labeled data. A subset of workers seek to maximize their effective hourly compensation by completing Amazon Mechanical Turk tasks as quickly as possible, even though their answers may be less accurate than a slower completion speed. That is a rational pursuit of self-interest, provided that it does not lead to their work being rejected upon review. In the case of our study, and academic research in general, ethical considerations precluded us from rejecting the compensation of any study participants, even if their answers were not usable. Experienced crowdsourced workers might be aware of that protocol for academic studies, which could incentivize response satisficing. The main effects of poor quality labeler data include increased variability in the item fit statistics and ability scores, and reduced reliability estimates for the scores, raters, and items.\n\nIn order to evaluate the quality of raters' responses, we first examined the percentage of comments for which the rater had flagged one or more identity groups as being the targeted of the message. Our experimental design ensured that all comment batches contained six comments from our reference set, excluding the neutral level. That meant that at least 6 out of the 26 comments in the batch were known to include an identity group target (23%). The remaining 20 \"original\" comments were sourced from a pool of comments that were stratified on our identity model. 90% of those comments exceeded a threshold of 82% probability of containing an identity group, with the remaining 10% of comments being downsampled from those that scored less than 82% probability. The threshold of 82% was chosen based on manual inspection. The average predicted identity probability in comments exceeding the threshold was 90.4%, and whereas for comments below the threshold the average was 27.1%. Therefore the expected identity rate in the 20 original comments was 60%, or 12 comments. The overall 26-comment batch was expected to contain roughly 18 comments with identity group targets (71%). Figure A1a displays a histogram of the identity rate across all 11,143 raters. It is a bimodal distribution, with a peak at 73%, corresponding to 19 comments out of 26 being flagged as having an identity, and at 4%, corresponding to 1 out of 26 comments being flagged as having an identity. As noted previously, each batch consisted of at least 23% of comments containing an identity group target.\n\nWe layered on a second dimension of rater quality: the infit mean-squared statistic, a rater fit diagnostic that is calculated during the Rasch scaling (Linacre 2002). Infit mean-squared has a minimum value of 0 and a maximum of infinity, with an expected value of 1 (or 0 on the log scale). Raters with an infit mean-squared greater than 1 had more randomness or noise in their responses than expected by the Rasch model. Those with a statistic less than 1 had less randomness than expected, suggesting that they may have favored certain response options. Values greater than 2 have been interpreted as degrading the measurement system (ibid.).\n\nWe reviewed potential exclusions on both infit mean-squared statistic and the identity percentage statistic. We chose to exclude raters with an infit mean-squared statistic exceeding 1.9 or less than 0.37, or with an identity rate less than 20%. Those thresholds led to 24% of raters being removed, leaving 8,472 as providing acceptable data quality. The post-exclusion scatter plot appeared to have a reasonable bivariate normal distribution and the smoothed identity rate became nearly flat across the infit mean-squared statistic.\n\n\n31/33\n\n(a) Rate of flagging one or more identities in labeled comments (b) Comparison of identity rate versus infit mean-square statistic, with lowess smooth in blue.\n\n(c) Potential cutpoints for excluding lowquality raters (d) Updated rater distribution after applying exclusions Figure A1. Analysis of rater quality and exclusion of low-quality raters 32/33\n\nRaters were also excluded based on the number of demographic questions that were skipped, number of submissions from each unique IP, reverse geocoding of the response IP to not be located in the United States, matching of the IP to known proxies, duration to complete the survey, or an extreme value for estimated survey interpretation bias. After all exclusions we included the labels from 7,619 raters out of 11,143 total (31.6% excluded). More details on these filters will be included in future versions of this document. Following all rater exclusions we re-fit the item response model and used those estimates as our primary scaling result.\n\n\nA.5 Inadequacy of a binary hate speech item\n\nOur inclusion of a binary hate speech item in our labeling instrument allows the comparison of our interval measure to what would be possible with only a binary item response. An initial question might be: can rater agreement on the hate speech item approximate the magnitude provided by the continuous scale? Figure A2 shows that rater agreement on a single hate speech item is unfortunately a poor approximation of an interval measure. The statistical association is moderate (correlation = 60%), though highly significant (p < 0.00001), with rater agreement explaining 36% of the variance of the measure. In addition to other benefits (invariance, debiasing, explainability, interval measurement), the continuous measure contains approximately three times the information of the single-item rater agreement approximation. Figure A2. Insufficiency of a binary hate speech item. Rater agreement on a binary hate speech item fails to capture the magnitude or extremity of speech on a continuous hate speech spectrum.\n\nFigure 1 .\n1Highlighting slurs for human labelers. We highlighted known slurs for our human labelers in the annotation interface.\n\nFigure 2 .\n2Simplified annotation example showing linkage across all reviewers.\n\nFigure 3 .\n3Neural architecture for predicting a continuous score with multiple intermediate outcomes, labeler bias adjustment, and IRT activation.\n\nFigure 4 .\n4Neural architecture for predicting a continuous score directly.\n\nFigure 5 .\n5Calibrated Wright map. Comments. Histogram of the comment ability estimates from weighted likelihood estimation. Items. Item difficulty parameter estimates. Raters. Histogram of the rater severity estimates Our estimated item difficulties\n\nFigure 7 .\n7Scaling results by platform. Density of the ability estimates by platform. The lines are the proposed thresholds separating the revised theoretical construct levels.\n\nFigure 8 .\n8Polychoric correlations between the items in our study. All items have a positive correlation with each other, varying from 0.31 to 0.93. The most highly correlated pair is genocide and violence (0.93), followed by insult and respect (0.89).\n\nTable 1 .\n1Comparison of related work. Outcome measurement granularity refers to the measurement model for the raw scores (i.e. cardinality). CTT = Classical Test Theory. IRT = Item Response Theory. Obs = Observations. SVM = Support Vector Machine. CNN = Convolutional Neural Network. LSTM = Long Short-Term Memory Neural Network.Paper \nConstruct \nlevels \n\nOutcome \nmeasurement \ngranularity \n\nMeasurement \ntheory \n\nIdentity \ncategories \n\nAlgorithms Obs. \nPlatforms Ratings \nper \ncom-\nment \n\nReviewer \nbias ad-\njustment \n\nCoded lan-\nguage an-\nnotation \n\nWarner et \nal. 2012 \n\n2 \n2 \nCTT \n1 \nLinear SVM 1,000 \nYahoo! \nGroups \n\n3 \nNo \nNo \n\nDavidson \net al. 2017 \n\n3 \n3 \nCTT \n1 \nLasso, \nRidge \n\n24,802 Twitter \n3 \nNo \nNo \n\nDel Vigna \net al. 2017 \n\n3 \n3 \nCTT \n3 \nLSTM \n3,685 \n-\n6,502 \n\nFacebook \n1-3 \nNo \nNo \n\nDixon \net al. 2018 \n\n2 \n2 \nCTT \n30 \nCNNs \n127,820 Wikipedia 3? \nNo \nNo \n\nSiegel \net al. 2019 \n\n2 \n2 \nCTT \n1 \nNaive Bayes 25,000 Twitter, \nReddit \n\n3 \nNo \nNo \n\nThis \nstudy \n\n8 \n32 -48 \nFaceted Rasch \nIRT \n\n50 \nUSE, \nBERT, \nRoBERTa \n\n50,000 YouTube, \nTwitter, \nReddit \n\n4 \nYes \nYes \n\n\n\nTable 2 .\n2Theorized qualitative levels of the hate speech -counterspeech spectrum.Level Summary \nDescription \n5 \n\n\nTable 3 .\n3Example comment per theorized level of the proposed hate speech -counterspeech spectrum. Dehumanization You're all a bunch of human cockroaches is what you are... You ch**ks...Level \nText \n\n\nTable 4 .\n4Item parameter estimates and fit statistics. MnSq = mean-squared, discrm = discrimination, ptmea = point-measure correlation.Item \nDifficulty Infit MnSq Outfit MnSq Discrm PtMea \n\nSentiment \n-2.62 \n1.04 \n1.05 \n1.00 \n0.83 \nRespect \n-2.26 \n0.94 \n1.01 \n1.09 \n0.85 \nAttack-Defend \n-1.10 \n1.05 \n1.07 \n0.93 \n0.80 \nInsult \n-0.94 \n0.96 \n1.04 \n1.04 \n0.84 \nStatus \n-0.51 \n1.04 \n1.19 \n0.93 \n0.65 \n\nDehumanize \n0.61 \n1.09 \n1.09 \n0.87 \n0.60 \nHumiliate \n0.63 \n1.10 \n1.05 \n0.90 \n0.72 \nHate speech (binary) \n0.86 \n0.97 \n0.89 \n1.04 \n0.62 \nViolence \n2.22 \n0.91 \n0.89 \n1.09 \n0.51 \nGenocide \n3.11 \n0.85 \n0.90 \n1.12 \n0.44 \n\nwithin the [0.7, 1.3] heuristic target for statistical agreement between the proposed \nRasch model and the observed ratings (Eckes 2015, 5.1.2, p. 77). \n\n\n\nIs the comment above directed at or about any individual or groups based on: (multiple selections allowed) Insult Do you agree or disagree with the following statement: This comment is insulting towards the group(s) you previously identified.Strongly disagree, disagree, neither disagree nor agree, agree, strongly agree 4. Humiliate Do you agree or disagree with the following statement: This comment is humiliating towards the group(s) you previously identified.Strongly inferior, inferior, neither superior nor inferior, superior, strongly superior 6. Dehumanize Do you agree or disagree with the following statement: This comment dehumanizes the group(s) you previously identified (e.g., by comparing them to an animal).Strongly disagree, disagree, neither disagree nor agree, agree, strongly agree 7. Violence Do you agree or disagree with the following statement: This comment calls for using violence against the group(s) you previously identified.Strongly disagree, disagree, neither disagree nor agree, agree, strongly agree 8. Genocide Do you agree or disagree with the following statement: This comment calls for the deliberate killing of a large group of people from the group(s) you previously identified.Strongly disagree, disagree, neither disagree nor agree, agree, strongly agree 9. Attack-Defend Is the comment attacking or defending the group(s) you previously identified?name \nPrompt \nResponse options \nIdentities a \nRace or ethnicity, religion, national ori-\ngin or citizenship status, gender, sex-\nual orientation, age, disability status, or \nnone of the above \n1. Sentiment \nHow would you describe the sentiment of this comment? \nStrongly negative, somewhat negative, \nneutral, somewhat positive, strongly \npositive \n2. Respect \nIs this comment respectful towards the group(s) you previously \nidentified? \n\nStrongly disrespectful, disrespectful, \nneutral, respectful, strongly respectful \n3. Strongly disagree, disagree, neither dis-\nagree nor agree, agree, strongly agree \n5. Status \nThis comment states that the group(s) you previously identified \nis: \n\nStrongly defending, defending, nei-\nther defending nor attacking, attacking, \nstrongly attacking \n10. Hate speech \n(binary) b \n\n\n\nTable A2 .\nA2Identity group targets in labeling instrument. Dominant subgroups noted in italics, when present. For each list of subgroups, respondents were given an \"Other\" category with free response. Subgroups were randomly ordered for each respondent.Race or EthnicityBlack or African American, Latino or non-white Hispanic, Asian, Middle Eastern, Native American or Alaska Native, Pacific Islander, Non-hispanic white Religion Jews, Christians, Buddhists, Hindus, Mormons, Atheists, Muslims National Origin or Citizenship Status A specific country, immigrant, migrant worker, undocumented personIdentity Group \nIdentity Subgroups \n\nGender Identity \nWomen, men, non-binary or third gender, transgender women, transgender men, \ntransgender (unspecified) \nSexual Orientation \nBisexual, gay, lesbian, heterosexual \n\nAge \nChildren (0 -12 years old), adolescents / teenagers (13 -17), young adults / adults (18 -39), \nmiddle-aged (40 -64), seniors (65 or older) \n\nDisability Status \n\n\n\nTable A3 .\nA3Data structure for supervised multitask learning.Comment \nId \n\nRaw text \nRater Rater \nseverity \n\nItem \nratings \n\nHate speech \nscore \n\nTraining \nor test set \n1 \nExample A \n1 \n0.9 \n1, 3, 0, . . . \n1.92 \nTrain \n1 \nExample A \n2 \n-0.1 \n0, 2, 3, . . . \n1.92 \nTrain \n1 \nExample A \n3 \n-0.5 \n1, 1, 2, . . . \n1.92 \nTrain \n1 \nExample A \n4 \n1.2 \n1, 4, 1, . . . \n1.92 \nTrain \n2 \nExample B \n5 \n0.3 \n0, 1, 4, . . . \n-0.43 \nTest \n2 \nExample B \n6 \n0.4 \n0, 3, 4, . . . \n-0.43 \nTest \n2 \nExample B \n7 \n-0.6 \n0, 2, 1, . . . \n-0.43 \nTest \n2 \nExample B \n8 \n-1.5 \n1, 0, 2, . . . \n-0.43 \nTest \n\n\nAs described in the construct theorization section, groups consisted of the categories protected under US law (e.g., religion), while the sub-identity groups are a short list of the most commonly occurring groups within these categories (e.g., Muslims). See Appendix zz for full list of identity and sub-identity groups.\nIn the pilot set we used simpler scores to create the stratification bins. The maximum cosine similarity to an identity-term dictionary was used for relevance estimation in the pilot. For our pilot hypothesis score we used the Perspective API's identity attack model, which gave a predicted probability of the comment being hate speech (https://perspectiveapi.com).\nThis begs the question: could we ask human raters to provide a probability distribution over the response options, rather than selecting a single rating? Perhaps this has already been proposed or studied.\nAcknowledgmentsWe thank Nora Broege, Laura Jakli, Ben Gebre-Medhin, Christopher Hench, Simal Ozen Irmak, Aniket Kesari, Renata Barreto-Montenegro, Aaron Culich, and Kimberly Izar for their valuable contributions to the project. For research assistance we acknowledge the thoughtful work of Andy Chu, Chengzhi Huang, Jinlin He, Eshaan Pathak, and Violet Yao. For helpful comments and collaboration we are grateful to Rachel Rosen, Sebastian Raschka, Victor Vargas, Brittan Heller, D. Alex Hughes,23/33Ahmad Sultan, Adam Anderson, David Mongeau, Karen Draney, Daniel Kelley, Perman Gochyev, Alan Hubbard, Mark van der Laan, and especially Mark Wilson. We thank our item panel pilot testers and study participants for their comment reviews, particularly given the emotionally taxing nature of the material.\nRating scales and Rasch measurement. David Andrich, Expert review of pharmacoeconomics & outcomes research 11. Andrich, David (2011). \"Rating scales and Rasch measurement\". In: Expert review of pharmacoeconomics & outcomes research 11.5, pp. 571-585.\n\nEmpowering young people in the aftermath of hate. Anti-Defamation League, Anti-Defamation League (2016). Empowering young people in the aftermath of hate. url: https://www.adl.org/education/resources/tools-and- strategies/empowering-young-people-in-the-aftermath-of-hate-en.\n\nCrowdsourcing Subjective Tasks: The Case Study of Understanding Toxicity in Online Discussions. Lora Aroyo, Lucas Dixon, Nithum Thain, Olivia Redfield, Rachel Rosen, Companion Proceedings of The 2019 World Wide Web Conference. ACMAroyo, Lora, Lucas Dixon, Nithum Thain, Olivia Redfield, and Rachel Rosen (2019). \"Crowdsourcing Subjective Tasks: The Case Study of Understanding Toxicity in Online Discussions\". In: Companion Proceedings of The 2019 World Wide Web Conference. ACM, pp. 1100-1105.\n\nDeep learning for hate speech detection in tweets. Pinkesh Badjatiya, Shashank Gupta, Manish Gupta, Vasudeva Varma, Proceedings of the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee. the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering CommitteeBadjatiya, Pinkesh, Shashank Gupta, Manish Gupta, and Vasudeva Varma (2017). \"Deep learning for hate speech detection in tweets\". In: Proceedings of the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee, pp. 759-760.\n\nUnimodal probability distributions for deep ordinal classification. Christopher Beckham, Christopher Pal, arXiv:1705.05278arXiv preprintBeckham, Christopher and Christopher Pal (2017). \"Unimodal probability distributions for deep ordinal classification\". In: arXiv preprint arXiv:1705.05278.\n\nDangerous Speech: A Practical Guide. Susan Benesch, Cathy Buerger, Tonei Glavinic, Sean Manion, Dangerous Speech ProjectBenesch, Susan, Cathy Buerger, Tonei Glavinic, and Sean Manion (2018). \"Dangerous Speech: A Practical Guide\". In: Dangerous Speech Project.\n\nEvaluating online labor markets for experimental research: Amazon. com's Mechanical Turk. Adam J Berinsky, A Gregory, Gabriel S Huber, Lenz, In: Political analysis 20.3Berinsky, Adam J, Gregory A Huber, and Gabriel S Lenz (2012). \"Evaluating online labor markets for experimental research: Amazon. com's Mechanical Turk\". In: Political analysis 20.3, pp. 351-368.\n\nA qualitative study to identify indicators of the quality of wound closure. N S Blencowe, Rooshenas, Tolkien, Bera, Gould Brown, Elliott, J M Bc Reeves, Blazeby, Journal of Infection Prevention. 20Blencowe, NS, L Rooshenas, Z Tolkien, KD Bera, H Gould Brown, D Elliott, BC Reeves, and JM Blazeby (2019). \"A qualitative study to identify indicators of the quality of wound closure\". In: Journal of Infection Prevention 20.5, pp. 214-223.\n\nRank-consistent ordinal regression for neural networks. Wenzhi Cao, Vahid Mirjalili, Sebastian Raschka, arXiv:1901.07884arXiv preprintCao, Wenzhi, Vahid Mirjalili, and Sebastian Raschka (2019). \"Rank-consistent ordinal regression for neural networks\". In: arXiv preprint arXiv:1901.07884.\n\nMultitask learning. Rich Caruana, Machine learning 28.1. Caruana, Rich (1997). \"Multitask learning\". In: Machine learning 28.1, pp. 41-75.\n\nInventing temperature: Measurement and scientific progress. Hasok Chang, Oxford University PressChang, Hasok (2004). Inventing temperature: Measurement and scientific progress. Oxford University Press.\n\nXgboost: A scalable tree boosting system. Tianqi Chen, Carlos Guestrin, Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. the 22nd acm sigkdd international conference on knowledge discovery and data miningChen, Tianqi and Carlos Guestrin (2016). \"Xgboost: A scalable tree boosting system\". In: Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pp. 785-794.\n\nBART: Bayesian additive regression trees. Hugh A Chipman, I Edward, Robert E George, Mcculloch, The Annals of. Applied Statistics 4.1Chipman, Hugh A, Edward I George, Robert E McCulloch, et al. (2010). \"BART: Bayesian additive regression trees\". In: The Annals of Applied Statistics 4.1, pp. 266-298.\n\n. Francois Chollet, Chollet, Francois et al. (2015). Keras. https://keras.io.\n\nThe cost of dichotomization. Jacob Cohen, Cohen, Jacob (1983). \"The cost of dichotomization\". In: Applied psychological measurement 7.3, pp. 249-253.\n\nThe unimodal model for the classification of ordinal data. Joaquim F Pinto Costa, Hugo Da, Jaime S Alonso, Cardoso, Neural Networks 21.1. Costa, Joaquim F Pinto da, Hugo Alonso, and Jaime S Cardoso (2008). \"The unimodal model for the classification of ordinal data\". In: Neural Networks 21.1, pp. 78-91.\n\nAutomated hate speech detection and the problem of offensive language. Thomas Davidson, Dana Warmsley, Michael Macy, Ingmar Weber, Eleventh International AAAI Conference on Web and Social Media. Davidson, Thomas, Dana Warmsley, Michael Macy, and Ingmar Weber (2017). \"Automated hate speech detection and the problem of offensive language\". In: Eleventh International AAAI Conference on Web and Social Media.\n\nDichotomizing continuous variables in statistical analysis: a practice to avoid. Neal V Dawson, Robert Weiss, Dawson, Neal V and Robert Weiss (2012). \"Dichotomizing continuous variables in statistical analysis: a practice to avoid.\" In: 24/33\n\nHate me, hate me not: Hate speech detection on Facebook. Del Vigna, Andrea Fabio, Felice Cimino, Marinella Dell&apos;orletta, Maurizio Petrocchi, Tesconi, Del Vigna, Fabio, Andrea Cimino, Felice Dell'Orletta, Marinella Petrocchi, and Maurizio Tesconi (2017). \"Hate me, hate me not: Hate speech detection on Facebook\". In:\n\nBert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.04805arXiv preprintDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova (2018). \"Bert: Pre-training of deep bidirectional transformers for language understanding\". In: arXiv preprint arXiv:1810.04805.\n\nMeasuring and mitigating unintended bias in text classification. Lucas Dixon, John Li, Jeffrey Sorensen, Nithum Thain, Lucy Vasserman, Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society. the 2018 AAAI/ACM Conference on AI, Ethics, and SocietyACMDixon, Lucas, John Li, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman (2018). \"Measuring and mitigating unintended bias in text classification\". In: Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society. ACM, pp. 67-73.\n\nHate speech detection with comment embeddings. Nemanja Djuric, Jing Zhou, Robin Morris, Mihajlo Grbovic, Vladan Radosavljevic, Narayan Bhamidipati, Proceedings of the 24th international conference on world wide web. the 24th international conference on world wide webACMDjuric, Nemanja, Jing Zhou, Robin Morris, Mihajlo Grbovic, Vladan Radosavljevic, and Narayan Bhamidipati (2015). \"Hate speech detection with comment embeddings\". In: Proceedings of the 24th international conference on world wide web. ACM, pp. 29-30.\n\nIntroduction to many-facet Rasch measurement. Thomas Eckes, Peter LangFrankfurt2nd EdEckes, Thomas (2015). Introduction to many-facet Rasch measurement, 2nd Ed. Frankfurt: Peter Lang.\n\nInvariant measurement: Using Rasch models in the social, behavioral, and health sciences. Engelhard Jr, George , RoutledgeEngelhard Jr, George (2013). Invariant measurement: Using Rasch models in the social, behavioral, and health sciences. Routledge.\n\nInvariant measurement with raters and rating scales: Rasch models for rater-mediated assessments. George EngelhardJr, Stefanie Wind, RoutledgeEngelhard Jr, George and Stefanie Wind (2018). Invariant measurement with raters and rating scales: Rasch models for rater-mediated assessments. Routledge.\n\nContaining Papers of a Mathematical and Physical Character 144. Ronald Fisher, Aylmer, Proceedings of the Royal Society of London. Series A. 852Two new properties of mathematical likelihoodFisher, Ronald Aylmer (1934). \"Two new properties of mathematical likelihood\". In: Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character 144.852, pp. 285-307.\n\nA survey on automatic detection of hate speech in text. Paula Fortuna, Sergio Nunes, ACM Computing Surveys (CSUR) 51. 485Fortuna, Paula and Sergio Nunes (2018). \"A survey on automatic detection of hate speech in text\". In: ACM Computing Surveys (CSUR) 51.4, p. 85.\n\nA unified deep learning architecture for abuse detection. Antigoni-Maria Founta, Ilias LeontiadisDespoina Chatzakou, Ilias LeontiadisNicolas Kourtellis, Ilias LeontiadisJeremy Blackburn, Ilias LeontiadisAthena Vakali, Ilias LeontiadisarXiv:1802.00385arXiv preprintFounta, Antigoni-Maria, Despoina Chatzakou, Nicolas Kourtellis, Jeremy Blackburn, Athena Vakali, and Ilias Leontiadis (2018). \"A unified deep learning architecture for abuse detection\". In: arXiv preprint arXiv:1802.00385.\n\nAre We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets. Mor Geva, Yoav Goldberg, Jonathan Berant, arXiv:1908.07898arXiv preprintGeva, Mor, Yoav Goldberg, and Jonathan Berant (2019). \"Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets\". In: arXiv preprint arXiv:1908.07898.\n\nDeep learning. Ian Goodfellow, Yoshua Bengio, Aaron Courville, MIT pressGoodfellow, Ian, Yoshua Bengio, and Aaron Courville (2016). Deep learning. MIT press.\n\nNLP's Clever Hans Moment has Arrived. The Gradient. Benjamin Heinzerling, Heinzerling, Benjamin (2019). NLP's Clever Hans Moment has Arrived. The Gradient. url: https://thegradient.pub/nlps-clever-hans-moment-has-arrived/.\n\nAccounting for nonsystematic error in performance ratings. Grant Henning, Language Testing 13.1. Henning, Grant (1996). \"Accounting for nonsystematic error in performance ratings\". In: Language Testing 13.1, pp. 53-61.\n\nA generalization of sampling without replacement from a finite universe. Daniel G Horvitz, J Donovan, Thompson, Journal of the American statistical Association. 47Horvitz, Daniel G and Donovan J Thompson (1952). \"A generalization of sampling without replacement from a finite universe\". In: Journal of the American statistical Association 47.260, pp. 663-685.\n\nSquared earth mover's distance-based loss for training deep neural networks. Le Hou, Chen-Ping Yu, Dimitris Samaras, arXiv:1611.05916arXiv preprintHou, Le, Chen-Ping Yu, and Dimitris Samaras (2016). \"Squared earth mover's distance-based loss for training deep neural networks\". In: arXiv preprint arXiv:1611.05916.\n\nUniversal language model fine-tuning for text classification. Jeremy Howard, Sebastian Ruder, arXiv:1801.06146arXiv preprintHoward, Jeremy and Sebastian Ruder (2018). \"Universal language model fine-tuning for text classification\". In: arXiv preprint arXiv:1801.06146.\n\nMulti-Task Learning in the Wilderness. Andrej Karpathy, Karpathy, Andrej (2019). \"Multi-Task Learning in the Wilderness\". ICML. url: https://slideslive.com/38917690/multitask-learning-in-the-wilderness.\n\nCORAL: Ordinal Regression in Keras. Chris Kennedy, Kennedy, Chris (2020). CORAL: Ordinal Regression in Keras. url: https://github.com/ck37/coral-ordinal.\n\nThe Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes. Douwe Kiela, Hamed Firooz, Aravind Mohan, Vedanuj Goswami, Amanpreet Singh, Pratik Ringshia, Davide Testuggine, arXiv:2005.04790.25/33arXiv preprintKiela, Douwe, Hamed Firooz, Aravind Mohan, Vedanuj Goswami, Amanpreet Singh, Pratik Ringshia, and Davide Testuggine (2020). \"The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes\". In: arXiv preprint arXiv:2005.04790. 25/33\n\nNas-bench-nlp: Neural architecture search benchmark for natural language processing. Nikita Klyuchnikov, Ilya Trofimov, Ekaterina Artemova, Mikhail Salnikov, Maxim Fedorov, Evgeny Burnaev, arXiv:2006.07116arXiv preprintKlyuchnikov, Nikita, Ilya Trofimov, Ekaterina Artemova, Mikhail Salnikov, Maxim Fedorov, and Evgeny Burnaev (2020). \"Nas-bench-nlp: Neural architecture search benchmark for natural language processing\". In: arXiv preprint arXiv:2006.07116.\n\nAn extension of the Rasch model to multi-facet situations. John M Linacre, MESA PressChicago, ILChicago: University of Chicago, Department of EducationMany-facet Rasch measurementLinacre, John M (1987). \"An extension of the Rasch model to multi-facet situations\". In: Chicago: University of Chicago, Department of Education. -(1989). Many-facet Rasch measurement. Chicago, IL: MESA Press. url: https://www.winsteps.com/a/Linacre-MFRM-book.pdf.\n\nInvestigating rating scale category utility. Journal of outcome measurement. 3-(1999). \"Investigating rating scale category utility\". In: Journal of outcome measurement 3, pp. 103-122.\n\nWhat do infit and outfit, mean-square and standardized mean?. In: Rasch Measurement Transactions. 16878Facets computer program for many-facet Rasch measurement. version 3.83.0-(2002). \"What do infit and outfit, mean-square and standardized mean?\" In: Rasch Measurement Transactions 16.2, p. 878. url: https://www.rasch.org/rmt/rmt162f.htm. -(2019). Facets computer program for many-facet Rasch measurement, version 3.83.0.\n\nConstruction of measures from many-facet data. John M Linacre, D Benjamin, Wright, Journal of Applied Measurement. Linacre, John M and Benjamin D Wright (2002). \"Construction of measures from many-facet data.\" In: Journal of Applied Measurement.\n\nSentiment analysis: Mining opinions, sentiments, and emotions. Bing Liu, Cambridge University PressLiu, Bing (2015). Sentiment analysis: Mining opinions, sentiments, and emotions. Cambridge University Press.\n\nRoberta: A robustly optimized bert pretraining approach. Yinhan Liu, arXiv:1907.11692arXiv preprintLiu, Yinhan et al. (2019). \"Roberta: A robustly optimized bert pretraining approach\". In: arXiv preprint arXiv:1907.11692.\n\nDetecting the hate code on social media. Rijul Magu, Kshitij Joshi, Jiebo Luo, Eleventh International AAAI Conference on Web and Social Media. Magu, Rijul, Kshitij Joshi, and Jiebo Luo (2017). \"Detecting the hate code on social media\". In: Eleventh International AAAI Conference on Web and Social Media.\n\nObjective structured assessment of technical skill (OSATS) for surgical residents. J A Martin, Glenn Regehr, Richard Reznick, Helen Macrae, John Murnaghan, Carol Hutchison, M Brown, British journal of surgery 84. 2Martin, JA, Glenn Regehr, Richard Reznick, Helen Macrae, John Murnaghan, Carol Hutchison, and M Brown (1997). \"Objective structured assessment of technical skill (OSATS) for surgical residents\". In: British journal of surgery 84.2, pp. 273-278.\n\nA Rasch model for partial credit scoring. Geoff N Masters, Psychometrika 47. 2Masters, Geoff N (1982). \"A Rasch model for partial credit scoring\". In: Psychometrika 47.2, pp. 149-174.\n\nA generalized partial credit model: Application of an EM algorithm. Eiji Muraki, In: ETS Research Report Series 1992.1, pp. i-30Muraki, Eiji (1992). \"A generalized partial credit model: Application of an EM algorithm\". In: ETS Research Report Series 1992.1, pp. i-30.\n\nDetecting and measuring rater effects using many-facet Rasch measurement: Part I. Carol M Myford, Edward W Wolfe, Journal of applied measurement. 4Myford, Carol M and Edward W Wolfe (2003). \"Detecting and measuring rater effects using many-facet Rasch measurement: Part I\". In: Journal of applied measurement 4.4, pp. 386-422.\n\nProbing Neural Network Comprehension of Natural Language Arguments. Timothy Niven, Hung-Yu Kao, 10.18653/v1/P19-1459Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational LinguisticsNiven, Timothy and Hung-Yu Kao (2019). \"Probing Neural Network Comprehension of Natural Language Arguments\". In: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Florence, Italy: Association for Computational Linguistics, pp. 4658-4664. doi: 10.18653/v1/P19-1459. url: https://www.aclweb.org/anthology/P19-1459.\n\nAbusive language detection in online user content. Chikashi Nobata, Joel Tetreault, Achint Thomas, Yashar Mehdad, Yi Chang, Proceedings of the 25th international conference on world wide web. International World Wide Web Conferences Steering Committee. the 25th international conference on world wide web. International World Wide Web Conferences Steering CommitteeNobata, Chikashi, Joel Tetreault, Achint Thomas, Yashar Mehdad, and Yi Chang (2016). \"Abusive language detection in online user content\". In: Proceedings of the 25th international conference on world wide web. International World Wide Web Conferences Steering Committee, pp. 145-153.\n\nTPOT: A tree-based pipeline optimization tool for automating machine learning. Randal S Olson, Jason H Moore, Automated Machine Learning. SpringerOlson, Randal S and Jason H Moore (2019). \"TPOT: A tree-based pipeline optimization tool for automating machine learning\". In: Automated Machine Learning. Springer, pp. 151-160.\n\nAutomating Biomedical Data Science Through Tree-Based Pipeline Optimization. Randal S Olson, J Ryan, Urbanowicz, C Peter, Nicole A Andrews, La Creis Lavender, Jason H Kidd, Moore, isbn: 26/33Proceedings, Part I\". In: ed. by Giovanni Squillero and Paolo Burelli. Part I\". In: ed. by Giovanni Squillero and Paolo BurelliEvoApplications; Porto, PortugalSpringer International Publishing. ChapApplications of Evolutionary Computation: 19th European ConferenceOlson, Randal S, Ryan J Urbanowicz, Peter C Andrews, Nicole A Lavender, La Creis Kidd, and Jason H Moore (2016). \"Applications of Evolutionary Computation: 19th European Conference, EvoApplications 2016, Porto, Portugal, March 30 -April 1, 2016, Proceedings, Part I\". In: ed. by Giovanni Squillero and Paolo Burelli. Springer International Publishing. Chap. Automating Biomedical Data Science Through Tree-Based Pipeline Optimization, pp. 123-137. isbn: 26/33\n\n. 10.1007/978-3-319-31204-0_9978-3-319-31204-0. doi: 10.1007/978-3-319-31204-0_9. url: http://dx.doi.org/10.1007/978-3-319-31204-0_9.\n\nA Case for a Range of Acceptable Annotations. Jennimaria Palomaki, Olivia Rhinehart, Michael Tseng, SAD/CrowdBias@ HCOMP. Palomaki, Jennimaria, Olivia Rhinehart, and Michael Tseng (2018). \"A Case for a Range of Acceptable Annotations.\" In: SAD/CrowdBias@ HCOMP, pp. 19-31.\n\nA survey on transfer learning. Sinno Pan, Qiang Jialin, Yang, IEEE Transactions on knowledge and data engineering. 22Pan, Sinno Jialin and Qiang Yang (2009). \"A survey on transfer learning\". In: IEEE Transactions on knowledge and data engineering 22.10, pp. 1345-1359.\n\nShare of U.S. adults using social media, including Facebook, is mostly unchanged since. Andrew Perrin, Monica Anderson, Tech. rep. Pew Research Center: Internet, Science & Technology. url. Perrin, Andrew and Monica Anderson (2019). Share of U.S. adults using social media, including Facebook, is mostly unchanged since 2018. Tech. rep. Pew Research Center: Internet, Science & Technology. url: https://www.pewresearch.org/fact-tank/2019/04/10/share-of-u-s- adults-using-social-media-including-facebook-is-mostly-unchanged- since-2018/.\n\nThe Turner Diaries. William Pierce, Andrew Luther, Macdonald, William Luther PiercePierce, William Luther and Andrew MacDonald (1978). The Turner Diaries. William Luther Pierce.\n\n. Eric Polley, Erin Ledell, Chris Kennedy, Sam Lendle, Mark Van Der Laan, Polley, Eric, Erin LeDell, Chris Kennedy, Sam Lendle, and Mark van der Laan (2019). Package 'SuperLearner'.\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI Blog 1. 8Radford, Alec, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever (2019). \"Language models are unsupervised multitask learners\". In: OpenAI Blog 1, p. 8.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, arXiv:1910.10683arXiv preprintRaffel, Colin, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu (2019). \"Exploring the limits of transfer learning with a unified text-to-text transformer\". In: arXiv preprint arXiv:1910.10683.\n\nAn all-in-one convolutional neural network for face analysis. Rajeev Ranjan, Swami Sankaranarayanan, D Carlos, Rama Castillo, Chellappa, 2017 12th IEEE International Conference on Automatic Face & Gesture Recognition. IEEERanjan, Rajeev, Swami Sankaranarayanan, Carlos D Castillo, and Rama Chellappa (2017). \"An all-in-one convolutional neural network for face analysis\". In: 2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017). IEEE, pp. 17-24.\n\nOn simultaneous factor analysis in several populations. G Rasch, Uppsala Symposium on Psychological Factor Analysis. Taylor & FrancisRasch, G (1953). \"On simultaneous factor analysis in several populations\". In: Uppsala Symposium on Psychological Factor Analysis, 17-19 March 1953. Taylor & Francis, pp. 65-71.\n\nProbabilistic models for some intelligence and attainment tests. Copenhagen, DenmarkDanish Institute for Educational Research-(1980). \"Probabilistic models for some intelligence and attainment tests. 1960\". In: Copenhagen, Denmark: Danish Institute for Educational Research.\n\nMeasuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis. Bjirn Ross, Michael Rist, Guillermo Carbonell, Benjamin Cabrera, Nils Kurowsky, Michael Wojatzki, Proceedings of NLP4CMC III: 3rd Workshop on Natural Language Processing for Computer-Mediated Communication. Michael Beisswenger, Michael Wojatzki, and Torsten ZeschNLP4CMC III: 3rd Workshop on Natural Language Processing for Computer-Mediated CommunicationBochum17Bochumer Linguistische ArbeitsberichteRoss, Bjirn, Michael Rist, Guillermo Carbonell, Benjamin Cabrera, Nils Kurowsky, and Michael Wojatzki (2016). \"Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis\". In: Proceedings of NLP4CMC III: 3rd Workshop on Natural Language Processing for Computer-Mediated Communication. Ed. by Michael Beisswenger, Michael Wojatzki, and Torsten Zesch. Vol. 17. Bochumer Linguistische Arbeitsberichte. Bochum, pp. 6-9.\n\nDichotomizing continuous predictors in multiple regression: a bad idea. Patrick Royston, Willi Douglas G Altman, Sauerbrei, Statistics in medicine 25.1. Royston, Patrick, Douglas G Altman, and Willi Sauerbrei (2006). \"Dichotomizing continuous predictors in multiple regression: a bad idea\". In: Statistics in medicine 25.1, pp. 127-141.\n\nAn overview of multi-task learning in deep neural networks. Sebastian Ruder, arXiv:1706.05098.-arXiv preprintNLP's ImageNet moment has arrivedRuder, Sebastian (2017). \"An overview of multi-task learning in deep neural networks\". In: arXiv preprint arXiv:1706.05098. -(2018). NLP's ImageNet moment has arrived. url: https://thegradient.pub/nlp-imagenet/.\n\nGraded response models. Fumiko Samejima, Handbook of item response theory. Samejima, Fumiko (2016). \"Graded response models\". In: Handbook of item response theory, volume one. Chapman and Hall/CRC, pp. 123-136.\n\nThe risk of racial bias in hate speech detection. Maarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi, Noah A Smith, Proceedings of the 57th. the 57thSap, Maarten, Dallas Card, Saadia Gabriel, Yejin Choi, and Noah A Smith (2019). \"The risk of racial bias in hate speech detection\". In: Proceedings of the 57th\n\nAnnual Meeting of the Association for Computational Linguistics. 2733Annual Meeting of the Association for Computational Linguistics, pp. 1668-1678. 27/33\n\nDefining hate speech. Andrew Sellars, 10.2139/ssrn.2882244Berkman Klein Center. Tech. repSellars, Andrew (2016). Defining hate speech. Tech. rep. Berkman Klein Center. url: https://dx.doi.org/10.2139/ssrn.2882244.\n\nDisappointing dichotomies. Stephen Senn, Pharmaceutical Statistics: The Journal of Applied Statistics in the Pharmaceutical Industry. 24Senn, Stephen (2003). \"Disappointing dichotomies\". In: Pharmaceutical Statistics: The Journal of Applied Statistics in the Pharmaceutical Industry 2.4, pp. 239-240.\n\nTrumping Hate on Twitter? Online Hate Speech in the 2016 US Election Campaign and its Aftermath. Alexandra Siegel, Evgenii Nikitin, Pablo Barbera, Joanna Sterling, Bethany Pullen, Richard Bonneau, Jonathan Nagler, Joshua A Tucker, Siegel, Alexandra, Evgenii Nikitin, Pablo Barbera, Joanna Sterling, Bethany Pullen, Richard Bonneau, Jonathan Nagler, and Joshua A Tucker (2019). \"Trumping Hate on Twitter? Online Hate Speech in the 2016 US Election Campaign and its Aftermath\". In:\n\nThe Ten Stages of Genocide. Genocide Watch. Gregory Stanton, Stanton, Gregory (2013). The Ten Stages of Genocide. Genocide Watch. url: https://www.genocidewatch.com/ten-stages-of-genocide.\n\nBreaking up is hard to do: the heartbreak of dichotomizing continuous data. David L Streiner, The Canadian Journal of Psychiatry. 47Streiner, David L (2002). \"Breaking up is hard to do: the heartbreak of dichotomizing continuous data\". In: The Canadian Journal of Psychiatry 47.3, pp. 262-266.\n\nHate: Why we should resist it with free speech, not censorship. Nadine Strossen, Oxford University PressStrossen, Nadine (2018). Hate: Why we should resist it with free speech, not censorship. Oxford University Press.\n\nAdv-BERT: BERT is not robust on misspellings! Generating nature adversarial samples on BERT. Lichao Sun, Kazuma Hashimoto, Wenpeng Yin, Akari Asai, Jia Li, Philip Yu, Caiming Xiong, arXiv:2003.04985arXiv preprintSun, Lichao, Kazuma Hashimoto, Wenpeng Yin, Akari Asai, Jia Li, Philip Yu, and Caiming Xiong (2020). \"Adv-BERT: BERT is not robust on misspellings! Generating nature adversarial samples on BERT\". In: arXiv preprint arXiv:2003.04985.\n\nDestructive messages: How hate speech paves the way for harmful social movements. Alexander Tsesis, NYU Press778Tsesis, Alexander (2002). Destructive messages: How hate speech paves the way for harmful social movements. Vol. 778. NYU Press.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin (2017). \"Attention is all you need\". In: Advances in neural information processing systems, pp. 5998-6008.\n\nDetecting hate speech on the world wide web. William Warner, Julia Hirschberg, Proceedings of the second workshop on language in social media. the second workshop on language in social mediaAssociation for Computational LinguisticsWarner, William and Julia Hirschberg (2012). \"Detecting hate speech on the world wide web\". In: Proceedings of the second workshop on language in social media. Association for Computational Linguistics, pp. 19-26.\n\nConstructing measures: An item response modeling approach. Mark Wilson, RoutledgeWilson, Mark (2004). Constructing measures: An item response modeling approach. Routledge.\n\nThe rater bundle model. Mark Wilson, Machteld Hoskens, Journal of Educational and Behavioral Statistics. 26Wilson, Mark and Machteld Hoskens (2001). \"The rater bundle model\". In: Journal of Educational and Behavioral Statistics 26.3, pp. 283-306.\n\nIncitement on trial: prosecuting international speech crimes. Richard Wilson, Ashby, Cambridge University PressWilson, Richard Ashby (2017). Incitement on trial: prosecuting international speech crimes. Cambridge University Press.\n\nHuggingFace's Transformers: State-of-the-art Natural Language Processing. Thomas Wolf, arXiv-1910ArXivWolf, Thomas et al. (2019). \"HuggingFace's Transformers: State-of-the-art Natural Language Processing\". In: ArXiv, arXiv-1910.\n\nThe International Objective Measurement Workshops: Past and future. Benjamin D Wright, Structural Equation Modeling: A Multidisciplinary. Mark WilsonNorwood, NJAblex Publishing Corporation1Comparing Rasch measurement and factor analysis. Journal 3.1Wright, Benjamin D (1992). \"The International Objective Measurement Workshops: Past and future\". In: Objective measurement: Theory into practice. Ed. by Mark Wilson. Vol. 1. Norwood, NJ: Ablex Publishing Corporation. Chap. 2. -(1996). \"Comparing Rasch measurement and factor analysis\". In: Structural Equation Modeling: A Multidisciplinary Journal 3.1, pp. 3-24.\n\nRating scale analysis. Benjamin D Wright, Geoff N Masters, MESA pressWright, Benjamin D and Geoff N Masters (1982). Rating scale analysis. MESA press. url: https://research.acer.edu.au/measurement/2/.\n\nAdaptive methods for nonconvex optimization. Manzil Zaheer, Sashank Reddi, Devendra Sachan, Satyen Kale, Sanjiv Kumar, Advances in neural information processing systems. Zaheer, Manzil, Sashank Reddi, Devendra Sachan, Satyen Kale, and Sanjiv Kumar (2018). \"Adaptive methods for nonconvex optimization\". In: Advances in neural information processing systems, pp. 9793-9803.\n\nDetecting hate speech on twitter using a convolution-gru based deep neural network. Ziqi Zhang, David Robinson, Jonathan Tepper, European Semantic Web Conference. Springer2833Zhang, Ziqi, David Robinson, and Jonathan Tepper (2018). \"Detecting hate speech on twitter using a convolution-gru based deep neural network\". In: European Semantic Web Conference. Springer, pp. 745-760. 28/33\n", "annotations": {"author": "[{\"end\":269,\"start\":150},{\"end\":363,\"start\":270},{\"end\":505,\"start\":364},{\"end\":566,\"start\":506}]", "publisher": null, "author_last_name": "[{\"end\":165,\"start\":158},{\"end\":281,\"start\":276},{\"end\":378,\"start\":374},{\"end\":524,\"start\":514}]", "author_first_name": "[{\"end\":155,\"start\":150},{\"end\":157,\"start\":156},{\"end\":275,\"start\":270},{\"end\":373,\"start\":364},{\"end\":513,\"start\":506}]", "author_affiliation": "[{\"end\":206,\"start\":167},{\"end\":268,\"start\":208},{\"end\":322,\"start\":283},{\"end\":362,\"start\":324},{\"end\":419,\"start\":380},{\"end\":504,\"start\":421},{\"end\":565,\"start\":526}]", "title": "[{\"end\":117,\"start\":1},{\"end\":683,\"start\":567}]", "venue": null, "abstract": "[{\"end\":2925,\"start\":820}]", "bib_ref": "[{\"end\":3006,\"start\":2968},{\"end\":3735,\"start\":3722},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4451,\"start\":4439},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":6026,\"start\":6011},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6262,\"start\":6250},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":6272,\"start\":6262},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":6483,\"start\":6462},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6680,\"start\":6660},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":10257,\"start\":10244},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":10392,\"start\":10380},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":10713,\"start\":10698},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":11173,\"start\":11159},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":11712,\"start\":11693},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":13739,\"start\":13721},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":14013,\"start\":13991},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":14205,\"start\":14185},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":14224,\"start\":14205},{\"end\":14341,\"start\":14340},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14656,\"start\":14633},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":14674,\"start\":14656},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":14788,\"start\":14769},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":14850,\"start\":14829},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":15122,\"start\":15110},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":15198,\"start\":15177},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":15237,\"start\":15217},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":15277,\"start\":15257},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":18834,\"start\":18820},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":19347,\"start\":19326},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":19699,\"start\":19685},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20463,\"start\":20450},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":20482,\"start\":20468},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":24876,\"start\":24856},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":25707,\"start\":25690},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":26260,\"start\":26240},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":26535,\"start\":26514},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":28672,\"start\":28654},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":28690,\"start\":28672},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":29363,\"start\":29331},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":30665,\"start\":30644},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":33528,\"start\":33515},{\"end\":33541,\"start\":33530},{\"end\":33555,\"start\":33541},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":33693,\"start\":33681},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":33817,\"start\":33803},{\"end\":35538,\"start\":35519},{\"end\":35576,\"start\":35544},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":35616,\"start\":35603},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":35880,\"start\":35865},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":35930,\"start\":35917},{\"end\":36271,\"start\":36233},{\"end\":36473,\"start\":36441},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":36768,\"start\":36755},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":36944,\"start\":36932},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":37088,\"start\":37075},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":37103,\"start\":37088},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":38070,\"start\":38042},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":38084,\"start\":38072},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":38104,\"start\":38090},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":38254,\"start\":38242},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":38278,\"start\":38254},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":39059,\"start\":39040},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":39076,\"start\":39059},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":39097,\"start\":39076},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":39691,\"start\":39677},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":39946,\"start\":39928},{\"end\":39987,\"start\":39973},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":40674,\"start\":40658},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":41462,\"start\":41450},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":41646,\"start\":41629},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":43294,\"start\":43273},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":43340,\"start\":43320},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":46700,\"start\":46686},{\"end\":46729,\"start\":46700},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":46857,\"start\":46837},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":47773,\"start\":47756},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":48159,\"start\":48138},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":48177,\"start\":48159},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":48420,\"start\":48403},{\"end\":53260,\"start\":53257},{\"end\":53262,\"start\":53260},{\"end\":53264,\"start\":53262},{\"end\":53266,\"start\":53264},{\"end\":53269,\"start\":53266},{\"end\":53272,\"start\":53269},{\"end\":53275,\"start\":53272},{\"end\":53278,\"start\":53275},{\"end\":53281,\"start\":53278},{\"end\":53285,\"start\":53281},{\"end\":53289,\"start\":53285},{\"end\":56582,\"start\":56568},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":60141,\"start\":60125},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":60334,\"start\":60313},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":60351,\"start\":60334},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":63768,\"start\":63748},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":63852,\"start\":63830},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":65479,\"start\":65455},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":65811,\"start\":65791},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":66067,\"start\":66050},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":67006,\"start\":66986},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":67443,\"start\":67418},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":68095,\"start\":68078},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":68299,\"start\":68279},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":69978,\"start\":69959},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":74505,\"start\":74485},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":76589,\"start\":76568},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":79290,\"start\":79276}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":82509,\"start\":82379},{\"attributes\":{\"id\":\"fig_1\"},\"end\":82590,\"start\":82510},{\"attributes\":{\"id\":\"fig_2\"},\"end\":82739,\"start\":82591},{\"attributes\":{\"id\":\"fig_3\"},\"end\":82816,\"start\":82740},{\"attributes\":{\"id\":\"fig_4\"},\"end\":83068,\"start\":82817},{\"attributes\":{\"id\":\"fig_5\"},\"end\":83247,\"start\":83069},{\"attributes\":{\"id\":\"fig_6\"},\"end\":83502,\"start\":83248},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":84590,\"start\":83503},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":84706,\"start\":84591},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":84908,\"start\":84707},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":85677,\"start\":84909},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":87887,\"start\":85678},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":88871,\"start\":87888},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":89456,\"start\":88872}]", "paragraph": "[{\"end\":3917,\"start\":2941},{\"end\":5514,\"start\":3919},{\"end\":6681,\"start\":5516},{\"end\":8137,\"start\":6683},{\"end\":8491,\"start\":8139},{\"end\":9508,\"start\":8493},{\"end\":10003,\"start\":9539},{\"end\":10393,\"start\":10005},{\"end\":10998,\"start\":10395},{\"end\":12031,\"start\":11007},{\"end\":13442,\"start\":12033},{\"end\":14909,\"start\":13471},{\"end\":14989,\"start\":14911},{\"end\":16318,\"start\":14998},{\"end\":16772,\"start\":16320},{\"end\":17640,\"start\":16793},{\"end\":18238,\"start\":17688},{\"end\":19111,\"start\":18240},{\"end\":20759,\"start\":19113},{\"end\":21465,\"start\":20761},{\"end\":21595,\"start\":21467},{\"end\":22106,\"start\":21597},{\"end\":22897,\"start\":22108},{\"end\":26008,\"start\":22921},{\"end\":26892,\"start\":26031},{\"end\":27507,\"start\":26894},{\"end\":28908,\"start\":27533},{\"end\":29673,\"start\":28910},{\"end\":30816,\"start\":29675},{\"end\":32268,\"start\":30818},{\"end\":32875,\"start\":32270},{\"end\":33266,\"start\":32930},{\"end\":33818,\"start\":33275},{\"end\":33971,\"start\":33820},{\"end\":34105,\"start\":33973},{\"end\":34274,\"start\":34107},{\"end\":34410,\"start\":34276},{\"end\":34616,\"start\":34412},{\"end\":34760,\"start\":34635},{\"end\":36474,\"start\":34762},{\"end\":36945,\"start\":36476},{\"end\":38105,\"start\":36975},{\"end\":38279,\"start\":38107},{\"end\":38333,\"start\":38327},{\"end\":38423,\"start\":38335},{\"end\":38519,\"start\":38425},{\"end\":38555,\"start\":38521},{\"end\":38591,\"start\":38557},{\"end\":38647,\"start\":38593},{\"end\":38720,\"start\":38649},{\"end\":39947,\"start\":38722},{\"end\":40322,\"start\":39949},{\"end\":41036,\"start\":40372},{\"end\":42416,\"start\":41038},{\"end\":43582,\"start\":42418},{\"end\":46318,\"start\":43630},{\"end\":47270,\"start\":46345},{\"end\":48371,\"start\":47312},{\"end\":49443,\"start\":48373},{\"end\":50704,\"start\":49496},{\"end\":50804,\"start\":50733},{\"end\":51494,\"start\":50806},{\"end\":52302,\"start\":51496},{\"end\":53363,\"start\":52304},{\"end\":54551,\"start\":53365},{\"end\":55444,\"start\":54553},{\"end\":55722,\"start\":55456},{\"end\":56268,\"start\":55780},{\"end\":56698,\"start\":56305},{\"end\":58200,\"start\":56700},{\"end\":59836,\"start\":58202},{\"end\":61243,\"start\":59873},{\"end\":61601,\"start\":61245},{\"end\":62869,\"start\":61616},{\"end\":63924,\"start\":62871},{\"end\":65480,\"start\":63956},{\"end\":66733,\"start\":65482},{\"end\":68334,\"start\":66735},{\"end\":70081,\"start\":68336},{\"end\":72167,\"start\":70091},{\"end\":72976,\"start\":72169},{\"end\":73122,\"start\":72988},{\"end\":73545,\"start\":73137},{\"end\":74089,\"start\":73547},{\"end\":74408,\"start\":74110},{\"end\":74506,\"start\":74410},{\"end\":74861,\"start\":74508},{\"end\":76381,\"start\":74902},{\"end\":77543,\"start\":76412},{\"end\":79122,\"start\":77545},{\"end\":79769,\"start\":79124},{\"end\":80304,\"start\":79771},{\"end\":80473,\"start\":80314},{\"end\":80666,\"start\":80475},{\"end\":81314,\"start\":80668},{\"end\":82378,\"start\":81362}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":38326,\"start\":38280}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":12729,\"start\":12722},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":15415,\"start\":15408},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":20135,\"start\":20128},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22896,\"start\":22889},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":43797,\"start\":43788},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":56822,\"start\":56814},{\"end\":60404,\"start\":60397},{\"end\":60838,\"start\":60831},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":73186,\"start\":73178},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":75594,\"start\":75586}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2939,\"start\":2927},{\"attributes\":{\"n\":\"2\"},\"end\":9537,\"start\":9511},{\"end\":11005,\"start\":11001},{\"attributes\":{\"n\":\"2.1\"},\"end\":13469,\"start\":13445},{\"end\":14996,\"start\":14992},{\"attributes\":{\"n\":\"3\"},\"end\":16791,\"start\":16775},{\"attributes\":{\"n\":\"3.1\"},\"end\":17686,\"start\":17643},{\"attributes\":{\"n\":\"3.2\"},\"end\":22919,\"start\":22900},{\"attributes\":{\"n\":\"3.3\"},\"end\":26029,\"start\":26011},{\"attributes\":{\"n\":\"3.4\"},\"end\":27531,\"start\":27510},{\"attributes\":{\"n\":\"3.5\"},\"end\":32928,\"start\":32878},{\"end\":33273,\"start\":33269},{\"attributes\":{\"n\":\"5.\"},\"end\":34633,\"start\":34619},{\"attributes\":{\"n\":\"3.5.1\"},\"end\":36973,\"start\":36948},{\"attributes\":{\"n\":\"3.6\"},\"end\":40370,\"start\":40325},{\"attributes\":{\"n\":\"3.6.1\"},\"end\":43628,\"start\":43585},{\"attributes\":{\"n\":\"3.6.2\"},\"end\":46343,\"start\":46321},{\"attributes\":{\"n\":\"3.6.3\"},\"end\":47310,\"start\":47273},{\"attributes\":{\"n\":\"3.6.4\"},\"end\":49494,\"start\":49446},{\"attributes\":{\"n\":\"3.6.5\"},\"end\":50731,\"start\":50707},{\"attributes\":{\"n\":\"4\"},\"end\":55454,\"start\":55447},{\"end\":55730,\"start\":55725},{\"attributes\":{\"n\":\"4.1\"},\"end\":55778,\"start\":55733},{\"attributes\":{\"n\":\"4.2\"},\"end\":56303,\"start\":56271},{\"attributes\":{\"n\":\"4.3\"},\"end\":59871,\"start\":59839},{\"attributes\":{\"n\":\"5\"},\"end\":61614,\"start\":61604},{\"attributes\":{\"n\":\"5.1\"},\"end\":63954,\"start\":63927},{\"end\":70089,\"start\":70084},{\"end\":72986,\"start\":72979},{\"end\":73135,\"start\":73125},{\"end\":74108,\"start\":74092},{\"end\":74900,\"start\":74864},{\"end\":76410,\"start\":76384},{\"end\":80312,\"start\":80307},{\"end\":81360,\"start\":81317},{\"end\":82390,\"start\":82380},{\"end\":82521,\"start\":82511},{\"end\":82602,\"start\":82592},{\"end\":82751,\"start\":82741},{\"end\":82828,\"start\":82818},{\"end\":83080,\"start\":83070},{\"end\":83259,\"start\":83249},{\"end\":83513,\"start\":83504},{\"end\":84601,\"start\":84592},{\"end\":84717,\"start\":84708},{\"end\":84919,\"start\":84910},{\"end\":87899,\"start\":87889},{\"end\":88883,\"start\":88873}]", "table": "[{\"end\":84590,\"start\":83834},{\"end\":84706,\"start\":84675},{\"end\":84908,\"start\":84895},{\"end\":85677,\"start\":85046},{\"end\":87887,\"start\":87071},{\"end\":88871,\"start\":88488},{\"end\":89456,\"start\":88935}]", "figure_caption": "[{\"end\":82509,\"start\":82392},{\"end\":82590,\"start\":82523},{\"end\":82739,\"start\":82604},{\"end\":82816,\"start\":82753},{\"end\":83068,\"start\":82830},{\"end\":83247,\"start\":83082},{\"end\":83502,\"start\":83261},{\"end\":83834,\"start\":83515},{\"end\":84675,\"start\":84603},{\"end\":84895,\"start\":84719},{\"end\":85046,\"start\":84921},{\"end\":87071,\"start\":85680},{\"end\":88488,\"start\":87902},{\"end\":88935,\"start\":88886}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":25440,\"start\":25432},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":31380,\"start\":31372},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":42126,\"start\":42118},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":47016,\"start\":47007},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":56811,\"start\":56803},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":56835,\"start\":56827},{\"end\":57218,\"start\":57210},{\"end\":58025,\"start\":58017},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":58293,\"start\":58283},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":59700,\"start\":59692},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":78735,\"start\":78725},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":80597,\"start\":80588},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":81681,\"start\":81672},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":82196,\"start\":82187}]", "bib_author_first_name": "[{\"end\":91195,\"start\":91190},{\"end\":91470,\"start\":91455},{\"end\":91781,\"start\":91777},{\"end\":91794,\"start\":91789},{\"end\":91808,\"start\":91802},{\"end\":91822,\"start\":91816},{\"end\":91839,\"start\":91833},{\"end\":92235,\"start\":92228},{\"end\":92255,\"start\":92247},{\"end\":92269,\"start\":92263},{\"end\":92285,\"start\":92277},{\"end\":92920,\"start\":92909},{\"end\":92941,\"start\":92930},{\"end\":93176,\"start\":93171},{\"end\":93191,\"start\":93186},{\"end\":93206,\"start\":93201},{\"end\":93221,\"start\":93217},{\"end\":93489,\"start\":93485},{\"end\":93491,\"start\":93490},{\"end\":93503,\"start\":93502},{\"end\":93522,\"start\":93513},{\"end\":93837,\"start\":93836},{\"end\":93839,\"start\":93838},{\"end\":93899,\"start\":93898},{\"end\":93901,\"start\":93900},{\"end\":94260,\"start\":94254},{\"end\":94271,\"start\":94266},{\"end\":94292,\"start\":94283},{\"end\":94512,\"start\":94508},{\"end\":94693,\"start\":94688},{\"end\":94879,\"start\":94873},{\"end\":94892,\"start\":94886},{\"end\":95335,\"start\":95331},{\"end\":95337,\"start\":95336},{\"end\":95348,\"start\":95347},{\"end\":95363,\"start\":95357},{\"end\":95365,\"start\":95364},{\"end\":95601,\"start\":95593},{\"end\":95704,\"start\":95699},{\"end\":95895,\"start\":95880},{\"end\":95907,\"start\":95903},{\"end\":95917,\"start\":95912},{\"end\":95919,\"start\":95918},{\"end\":96203,\"start\":96197},{\"end\":96218,\"start\":96214},{\"end\":96236,\"start\":96229},{\"end\":96249,\"start\":96243},{\"end\":96620,\"start\":96616},{\"end\":96622,\"start\":96621},{\"end\":96637,\"start\":96631},{\"end\":96839,\"start\":96836},{\"end\":96853,\"start\":96847},{\"end\":96867,\"start\":96861},{\"end\":96885,\"start\":96876},{\"end\":96913,\"start\":96905},{\"end\":97189,\"start\":97184},{\"end\":97206,\"start\":97198},{\"end\":97220,\"start\":97214},{\"end\":97234,\"start\":97226},{\"end\":97542,\"start\":97537},{\"end\":97554,\"start\":97550},{\"end\":97566,\"start\":97559},{\"end\":97583,\"start\":97577},{\"end\":97595,\"start\":97591},{\"end\":98033,\"start\":98026},{\"end\":98046,\"start\":98042},{\"end\":98058,\"start\":98053},{\"end\":98074,\"start\":98067},{\"end\":98090,\"start\":98084},{\"end\":98113,\"start\":98106},{\"end\":98552,\"start\":98546},{\"end\":98784,\"start\":98775},{\"end\":98795,\"start\":98789},{\"end\":99042,\"start\":99036},{\"end\":99064,\"start\":99056},{\"end\":99307,\"start\":99301},{\"end\":99706,\"start\":99701},{\"end\":99722,\"start\":99716},{\"end\":99983,\"start\":99969},{\"end\":100016,\"start\":100008},{\"end\":100051,\"start\":100044},{\"end\":100086,\"start\":100080},{\"end\":100120,\"start\":100114},{\"end\":100524,\"start\":100521},{\"end\":100535,\"start\":100531},{\"end\":100554,\"start\":100546},{\"end\":100827,\"start\":100824},{\"end\":100846,\"start\":100840},{\"end\":100860,\"start\":100855},{\"end\":101028,\"start\":101020},{\"end\":101256,\"start\":101251},{\"end\":101491,\"start\":101485},{\"end\":101493,\"start\":101492},{\"end\":101504,\"start\":101503},{\"end\":101852,\"start\":101850},{\"end\":101867,\"start\":101858},{\"end\":101880,\"start\":101872},{\"end\":102157,\"start\":102151},{\"end\":102175,\"start\":102166},{\"end\":102403,\"start\":102397},{\"end\":102603,\"start\":102598},{\"end\":102794,\"start\":102789},{\"end\":102807,\"start\":102802},{\"end\":102823,\"start\":102816},{\"end\":102838,\"start\":102831},{\"end\":102857,\"start\":102848},{\"end\":102871,\"start\":102865},{\"end\":102888,\"start\":102882},{\"end\":103270,\"start\":103264},{\"end\":103288,\"start\":103284},{\"end\":103308,\"start\":103299},{\"end\":103326,\"start\":103319},{\"end\":103342,\"start\":103337},{\"end\":103358,\"start\":103352},{\"end\":103702,\"start\":103698},{\"end\":103704,\"start\":103703},{\"end\":104745,\"start\":104741},{\"end\":104747,\"start\":104746},{\"end\":104758,\"start\":104757},{\"end\":105008,\"start\":105004},{\"end\":105213,\"start\":105207},{\"end\":105419,\"start\":105414},{\"end\":105433,\"start\":105426},{\"end\":105446,\"start\":105441},{\"end\":105762,\"start\":105761},{\"end\":105764,\"start\":105763},{\"end\":105778,\"start\":105773},{\"end\":105794,\"start\":105787},{\"end\":105809,\"start\":105804},{\"end\":105822,\"start\":105818},{\"end\":105839,\"start\":105834},{\"end\":105852,\"start\":105851},{\"end\":106185,\"start\":106180},{\"end\":106187,\"start\":106186},{\"end\":106395,\"start\":106391},{\"end\":106679,\"start\":106674},{\"end\":106681,\"start\":106680},{\"end\":106995,\"start\":106988},{\"end\":107010,\"start\":107003},{\"end\":107665,\"start\":107657},{\"end\":107678,\"start\":107674},{\"end\":107696,\"start\":107690},{\"end\":107711,\"start\":107705},{\"end\":107722,\"start\":107720},{\"end\":108341,\"start\":108335},{\"end\":108343,\"start\":108342},{\"end\":108356,\"start\":108351},{\"end\":108358,\"start\":108357},{\"end\":108664,\"start\":108658},{\"end\":108666,\"start\":108665},{\"end\":108675,\"start\":108674},{\"end\":108695,\"start\":108694},{\"end\":108709,\"start\":108703},{\"end\":108711,\"start\":108710},{\"end\":108723,\"start\":108721},{\"end\":108729,\"start\":108724},{\"end\":108745,\"start\":108740},{\"end\":108747,\"start\":108746},{\"end\":109688,\"start\":109678},{\"end\":109705,\"start\":109699},{\"end\":109724,\"start\":109717},{\"end\":109942,\"start\":109937},{\"end\":109953,\"start\":109948},{\"end\":110270,\"start\":110264},{\"end\":110285,\"start\":110279},{\"end\":110740,\"start\":110733},{\"end\":110755,\"start\":110749},{\"end\":110898,\"start\":110894},{\"end\":110911,\"start\":110907},{\"end\":110925,\"start\":110920},{\"end\":110938,\"start\":110935},{\"end\":110951,\"start\":110947},{\"end\":111132,\"start\":111128},{\"end\":111149,\"start\":111142},{\"end\":111159,\"start\":111154},{\"end\":111172,\"start\":111167},{\"end\":111184,\"start\":111179},{\"end\":111197,\"start\":111193},{\"end\":111487,\"start\":111482},{\"end\":111500,\"start\":111496},{\"end\":111514,\"start\":111510},{\"end\":111533,\"start\":111524},{\"end\":111545,\"start\":111539},{\"end\":111561,\"start\":111554},{\"end\":111575,\"start\":111570},{\"end\":111585,\"start\":111582},{\"end\":111597,\"start\":111590},{\"end\":111957,\"start\":111951},{\"end\":111971,\"start\":111966},{\"end\":111991,\"start\":111990},{\"end\":112004,\"start\":112000},{\"end\":112431,\"start\":112430},{\"end\":113062,\"start\":113057},{\"end\":113076,\"start\":113069},{\"end\":113092,\"start\":113083},{\"end\":113112,\"start\":113104},{\"end\":113126,\"start\":113122},{\"end\":113144,\"start\":113137},{\"end\":113989,\"start\":113982},{\"end\":114004,\"start\":113999},{\"end\":114317,\"start\":114308},{\"end\":114633,\"start\":114627},{\"end\":114872,\"start\":114865},{\"end\":114884,\"start\":114878},{\"end\":114897,\"start\":114891},{\"end\":114912,\"start\":114907},{\"end\":114925,\"start\":114919},{\"end\":115311,\"start\":115305},{\"end\":115532,\"start\":115525},{\"end\":115906,\"start\":115897},{\"end\":115922,\"start\":115915},{\"end\":115937,\"start\":115932},{\"end\":115953,\"start\":115947},{\"end\":115971,\"start\":115964},{\"end\":115987,\"start\":115980},{\"end\":116005,\"start\":115997},{\"end\":116020,\"start\":116014},{\"end\":116022,\"start\":116021},{\"end\":116332,\"start\":116325},{\"end\":116552,\"start\":116547},{\"end\":116554,\"start\":116553},{\"end\":116836,\"start\":116830},{\"end\":117084,\"start\":117078},{\"end\":117096,\"start\":117090},{\"end\":117115,\"start\":117108},{\"end\":117126,\"start\":117121},{\"end\":117136,\"start\":117133},{\"end\":117147,\"start\":117141},{\"end\":117159,\"start\":117152},{\"end\":117522,\"start\":117513},{\"end\":117706,\"start\":117700},{\"end\":117720,\"start\":117716},{\"end\":117734,\"start\":117730},{\"end\":117748,\"start\":117743},{\"end\":117765,\"start\":117760},{\"end\":117778,\"start\":117773},{\"end\":117780,\"start\":117779},{\"end\":117794,\"start\":117788},{\"end\":117808,\"start\":117803},{\"end\":118157,\"start\":118150},{\"end\":118171,\"start\":118166},{\"end\":118614,\"start\":118610},{\"end\":118752,\"start\":118748},{\"end\":118769,\"start\":118761},{\"end\":119041,\"start\":119034},{\"end\":119284,\"start\":119278},{\"end\":119510,\"start\":119502},{\"end\":119512,\"start\":119511},{\"end\":120078,\"start\":120070},{\"end\":120080,\"start\":120079},{\"end\":120094,\"start\":120089},{\"end\":120096,\"start\":120095},{\"end\":120300,\"start\":120294},{\"end\":120316,\"start\":120309},{\"end\":120332,\"start\":120324},{\"end\":120347,\"start\":120341},{\"end\":120360,\"start\":120354},{\"end\":120711,\"start\":120707},{\"end\":120724,\"start\":120719},{\"end\":120743,\"start\":120735}]", "bib_author_last_name": "[{\"end\":91203,\"start\":91196},{\"end\":91477,\"start\":91471},{\"end\":91787,\"start\":91782},{\"end\":91800,\"start\":91795},{\"end\":91814,\"start\":91809},{\"end\":91831,\"start\":91823},{\"end\":91845,\"start\":91840},{\"end\":92245,\"start\":92236},{\"end\":92261,\"start\":92256},{\"end\":92275,\"start\":92270},{\"end\":92291,\"start\":92286},{\"end\":92928,\"start\":92921},{\"end\":92945,\"start\":92942},{\"end\":93184,\"start\":93177},{\"end\":93199,\"start\":93192},{\"end\":93215,\"start\":93207},{\"end\":93228,\"start\":93222},{\"end\":93500,\"start\":93492},{\"end\":93511,\"start\":93504},{\"end\":93528,\"start\":93523},{\"end\":93534,\"start\":93530},{\"end\":93848,\"start\":93840},{\"end\":93859,\"start\":93850},{\"end\":93868,\"start\":93861},{\"end\":93874,\"start\":93870},{\"end\":93887,\"start\":93876},{\"end\":93896,\"start\":93889},{\"end\":93911,\"start\":93902},{\"end\":93920,\"start\":93913},{\"end\":94264,\"start\":94261},{\"end\":94281,\"start\":94272},{\"end\":94300,\"start\":94293},{\"end\":94520,\"start\":94513},{\"end\":94699,\"start\":94694},{\"end\":94884,\"start\":94880},{\"end\":94901,\"start\":94893},{\"end\":95345,\"start\":95338},{\"end\":95355,\"start\":95349},{\"end\":95372,\"start\":95366},{\"end\":95383,\"start\":95374},{\"end\":95609,\"start\":95602},{\"end\":95710,\"start\":95705},{\"end\":95901,\"start\":95896},{\"end\":95910,\"start\":95908},{\"end\":95926,\"start\":95920},{\"end\":95935,\"start\":95928},{\"end\":96212,\"start\":96204},{\"end\":96227,\"start\":96219},{\"end\":96241,\"start\":96237},{\"end\":96255,\"start\":96250},{\"end\":96629,\"start\":96623},{\"end\":96643,\"start\":96638},{\"end\":96845,\"start\":96840},{\"end\":96859,\"start\":96854},{\"end\":96874,\"start\":96868},{\"end\":96903,\"start\":96886},{\"end\":96923,\"start\":96914},{\"end\":96932,\"start\":96925},{\"end\":97196,\"start\":97190},{\"end\":97212,\"start\":97207},{\"end\":97224,\"start\":97221},{\"end\":97244,\"start\":97235},{\"end\":97548,\"start\":97543},{\"end\":97557,\"start\":97555},{\"end\":97575,\"start\":97567},{\"end\":97589,\"start\":97584},{\"end\":97605,\"start\":97596},{\"end\":98040,\"start\":98034},{\"end\":98051,\"start\":98047},{\"end\":98065,\"start\":98059},{\"end\":98082,\"start\":98075},{\"end\":98104,\"start\":98091},{\"end\":98125,\"start\":98114},{\"end\":98558,\"start\":98553},{\"end\":98787,\"start\":98785},{\"end\":99052,\"start\":99043},{\"end\":99069,\"start\":99065},{\"end\":99314,\"start\":99308},{\"end\":99322,\"start\":99316},{\"end\":99714,\"start\":99707},{\"end\":99728,\"start\":99723},{\"end\":99990,\"start\":99984},{\"end\":100026,\"start\":100017},{\"end\":100062,\"start\":100052},{\"end\":100096,\"start\":100087},{\"end\":100127,\"start\":100121},{\"end\":100529,\"start\":100525},{\"end\":100544,\"start\":100536},{\"end\":100561,\"start\":100555},{\"end\":100838,\"start\":100828},{\"end\":100853,\"start\":100847},{\"end\":100870,\"start\":100861},{\"end\":101040,\"start\":101029},{\"end\":101264,\"start\":101257},{\"end\":101501,\"start\":101494},{\"end\":101512,\"start\":101505},{\"end\":101522,\"start\":101514},{\"end\":101856,\"start\":101853},{\"end\":101870,\"start\":101868},{\"end\":101888,\"start\":101881},{\"end\":102164,\"start\":102158},{\"end\":102181,\"start\":102176},{\"end\":102412,\"start\":102404},{\"end\":102611,\"start\":102604},{\"end\":102800,\"start\":102795},{\"end\":102814,\"start\":102808},{\"end\":102829,\"start\":102824},{\"end\":102846,\"start\":102839},{\"end\":102863,\"start\":102858},{\"end\":102880,\"start\":102872},{\"end\":102899,\"start\":102889},{\"end\":103282,\"start\":103271},{\"end\":103297,\"start\":103289},{\"end\":103317,\"start\":103309},{\"end\":103335,\"start\":103327},{\"end\":103350,\"start\":103343},{\"end\":103366,\"start\":103359},{\"end\":103712,\"start\":103705},{\"end\":104755,\"start\":104748},{\"end\":104767,\"start\":104759},{\"end\":104775,\"start\":104769},{\"end\":105012,\"start\":105009},{\"end\":105217,\"start\":105214},{\"end\":105424,\"start\":105420},{\"end\":105439,\"start\":105434},{\"end\":105450,\"start\":105447},{\"end\":105771,\"start\":105765},{\"end\":105785,\"start\":105779},{\"end\":105802,\"start\":105795},{\"end\":105816,\"start\":105810},{\"end\":105832,\"start\":105823},{\"end\":105849,\"start\":105840},{\"end\":105858,\"start\":105853},{\"end\":106195,\"start\":106188},{\"end\":106402,\"start\":106396},{\"end\":106688,\"start\":106682},{\"end\":106704,\"start\":106690},{\"end\":107001,\"start\":106996},{\"end\":107014,\"start\":107011},{\"end\":107672,\"start\":107666},{\"end\":107688,\"start\":107679},{\"end\":107703,\"start\":107697},{\"end\":107718,\"start\":107712},{\"end\":107728,\"start\":107723},{\"end\":108349,\"start\":108344},{\"end\":108364,\"start\":108359},{\"end\":108672,\"start\":108667},{\"end\":108680,\"start\":108676},{\"end\":108692,\"start\":108682},{\"end\":108701,\"start\":108696},{\"end\":108719,\"start\":108712},{\"end\":108738,\"start\":108730},{\"end\":108752,\"start\":108748},{\"end\":108759,\"start\":108754},{\"end\":109697,\"start\":109689},{\"end\":109715,\"start\":109706},{\"end\":109730,\"start\":109725},{\"end\":109946,\"start\":109943},{\"end\":109960,\"start\":109954},{\"end\":109966,\"start\":109962},{\"end\":110277,\"start\":110271},{\"end\":110294,\"start\":110286},{\"end\":110747,\"start\":110741},{\"end\":110762,\"start\":110756},{\"end\":110773,\"start\":110764},{\"end\":110905,\"start\":110899},{\"end\":110918,\"start\":110912},{\"end\":110933,\"start\":110926},{\"end\":110945,\"start\":110939},{\"end\":110964,\"start\":110952},{\"end\":111140,\"start\":111133},{\"end\":111152,\"start\":111150},{\"end\":111165,\"start\":111160},{\"end\":111177,\"start\":111173},{\"end\":111191,\"start\":111185},{\"end\":111207,\"start\":111198},{\"end\":111494,\"start\":111488},{\"end\":111508,\"start\":111501},{\"end\":111522,\"start\":111515},{\"end\":111537,\"start\":111534},{\"end\":111552,\"start\":111546},{\"end\":111568,\"start\":111562},{\"end\":111580,\"start\":111576},{\"end\":111588,\"start\":111586},{\"end\":111601,\"start\":111598},{\"end\":111964,\"start\":111958},{\"end\":111988,\"start\":111972},{\"end\":111998,\"start\":111992},{\"end\":112013,\"start\":112005},{\"end\":112024,\"start\":112015},{\"end\":112437,\"start\":112432},{\"end\":113067,\"start\":113063},{\"end\":113081,\"start\":113077},{\"end\":113102,\"start\":113093},{\"end\":113120,\"start\":113113},{\"end\":113135,\"start\":113127},{\"end\":113153,\"start\":113145},{\"end\":113997,\"start\":113990},{\"end\":114021,\"start\":114005},{\"end\":114032,\"start\":114023},{\"end\":114323,\"start\":114318},{\"end\":114642,\"start\":114634},{\"end\":114876,\"start\":114873},{\"end\":114889,\"start\":114885},{\"end\":114905,\"start\":114898},{\"end\":114917,\"start\":114913},{\"end\":114931,\"start\":114926},{\"end\":115319,\"start\":115312},{\"end\":115537,\"start\":115533},{\"end\":115913,\"start\":115907},{\"end\":115930,\"start\":115923},{\"end\":115945,\"start\":115938},{\"end\":115962,\"start\":115954},{\"end\":115978,\"start\":115972},{\"end\":115995,\"start\":115988},{\"end\":116012,\"start\":116006},{\"end\":116029,\"start\":116023},{\"end\":116340,\"start\":116333},{\"end\":116563,\"start\":116555},{\"end\":116845,\"start\":116837},{\"end\":117088,\"start\":117085},{\"end\":117106,\"start\":117097},{\"end\":117119,\"start\":117116},{\"end\":117131,\"start\":117127},{\"end\":117139,\"start\":117137},{\"end\":117150,\"start\":117148},{\"end\":117165,\"start\":117160},{\"end\":117529,\"start\":117523},{\"end\":117714,\"start\":117707},{\"end\":117728,\"start\":117721},{\"end\":117741,\"start\":117735},{\"end\":117758,\"start\":117749},{\"end\":117771,\"start\":117766},{\"end\":117786,\"start\":117781},{\"end\":117801,\"start\":117795},{\"end\":117819,\"start\":117809},{\"end\":118164,\"start\":118158},{\"end\":118182,\"start\":118172},{\"end\":118621,\"start\":118615},{\"end\":118759,\"start\":118753},{\"end\":118777,\"start\":118770},{\"end\":119048,\"start\":119042},{\"end\":119055,\"start\":119050},{\"end\":119289,\"start\":119285},{\"end\":119519,\"start\":119513},{\"end\":120087,\"start\":120081},{\"end\":120104,\"start\":120097},{\"end\":120307,\"start\":120301},{\"end\":120322,\"start\":120317},{\"end\":120339,\"start\":120333},{\"end\":120352,\"start\":120348},{\"end\":120366,\"start\":120361},{\"end\":120717,\"start\":120712},{\"end\":120733,\"start\":120725},{\"end\":120750,\"start\":120744}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":42914167},\"end\":91403,\"start\":91153},{\"attributes\":{\"id\":\"b1\"},\"end\":91679,\"start\":91405},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":153314098},\"end\":92175,\"start\":91681},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2880908},\"end\":92839,\"start\":92177},{\"attributes\":{\"doi\":\"arXiv:1705.05278\",\"id\":\"b4\"},\"end\":93132,\"start\":92841},{\"attributes\":{\"id\":\"b5\"},\"end\":93393,\"start\":93134},{\"attributes\":{\"id\":\"b6\"},\"end\":93758,\"start\":93395},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":190879355},\"end\":94196,\"start\":93760},{\"attributes\":{\"doi\":\"arXiv:1901.07884\",\"id\":\"b8\"},\"end\":94486,\"start\":94198},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":45998148},\"end\":94626,\"start\":94488},{\"attributes\":{\"id\":\"b10\"},\"end\":94829,\"start\":94628},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":4650265},\"end\":95287,\"start\":94831},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":12852360},\"end\":95589,\"start\":95289},{\"attributes\":{\"id\":\"b13\"},\"end\":95668,\"start\":95591},{\"attributes\":{\"id\":\"b14\"},\"end\":95819,\"start\":95670},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":10114943},\"end\":96124,\"start\":95821},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":1733167},\"end\":96533,\"start\":96126},{\"attributes\":{\"id\":\"b17\"},\"end\":96777,\"start\":96535},{\"attributes\":{\"id\":\"b18\"},\"end\":97100,\"start\":96779},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b19\"},\"end\":97470,\"start\":97102},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":54997157},\"end\":97977,\"start\":97472},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":2039295},\"end\":98498,\"start\":97979},{\"attributes\":{\"id\":\"b22\"},\"end\":98683,\"start\":98500},{\"attributes\":{\"id\":\"b23\"},\"end\":98936,\"start\":98685},{\"attributes\":{\"id\":\"b24\"},\"end\":99235,\"start\":98938},{\"attributes\":{\"id\":\"b25\"},\"end\":99643,\"start\":99237},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":52184457},\"end\":99909,\"start\":99645},{\"attributes\":{\"doi\":\"arXiv:1802.00385\",\"id\":\"b27\"},\"end\":100397,\"start\":99911},{\"attributes\":{\"doi\":\"arXiv:1908.07898\",\"id\":\"b28\"},\"end\":100807,\"start\":100399},{\"attributes\":{\"id\":\"b29\"},\"end\":100966,\"start\":100809},{\"attributes\":{\"id\":\"b30\"},\"end\":101190,\"start\":100968},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":145686038},\"end\":101410,\"start\":101192},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":120274071},\"end\":101771,\"start\":101412},{\"attributes\":{\"doi\":\"arXiv:1611.05916\",\"id\":\"b33\"},\"end\":102087,\"start\":101773},{\"attributes\":{\"doi\":\"arXiv:1801.06146\",\"id\":\"b34\"},\"end\":102356,\"start\":102089},{\"attributes\":{\"id\":\"b35\"},\"end\":102560,\"start\":102358},{\"attributes\":{\"id\":\"b36\"},\"end\":102715,\"start\":102562},{\"attributes\":{\"doi\":\"arXiv:2005.04790.25/33\",\"id\":\"b37\"},\"end\":103177,\"start\":102717},{\"attributes\":{\"doi\":\"arXiv:2006.07116\",\"id\":\"b38\"},\"end\":103637,\"start\":103179},{\"attributes\":{\"id\":\"b39\"},\"end\":104082,\"start\":103639},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":14991215},\"end\":104268,\"start\":104084},{\"attributes\":{\"id\":\"b41\"},\"end\":104692,\"start\":104270},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":25647409},\"end\":104939,\"start\":104694},{\"attributes\":{\"id\":\"b43\"},\"end\":105148,\"start\":104941},{\"attributes\":{\"doi\":\"arXiv:1907.11692\",\"id\":\"b44\"},\"end\":105371,\"start\":105150},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":16176790},\"end\":105676,\"start\":105373},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":22247086},\"end\":106136,\"start\":105678},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":119660742},\"end\":106321,\"start\":106138},{\"attributes\":{\"id\":\"b48\"},\"end\":106590,\"start\":106323},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":44899700},\"end\":106918,\"start\":106592},{\"attributes\":{\"doi\":\"10.18653/v1/P19-1459\",\"id\":\"b50\",\"matched_paper_id\":196181887},\"end\":107604,\"start\":106920},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":11546523},\"end\":108254,\"start\":107606},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":12399099},\"end\":108579,\"start\":108256},{\"attributes\":{\"doi\":\"isbn: 26/33\",\"id\":\"b53\",\"matched_paper_id\":9709316},\"end\":109495,\"start\":108581},{\"attributes\":{\"doi\":\"10.1007/978-3-319-31204-0_9\",\"id\":\"b54\"},\"end\":109630,\"start\":109497},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":56487787},\"end\":109904,\"start\":109632},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":740063},\"end\":110174,\"start\":109906},{\"attributes\":{\"id\":\"b57\"},\"end\":110711,\"start\":110176},{\"attributes\":{\"id\":\"b58\"},\"end\":110890,\"start\":110713},{\"attributes\":{\"id\":\"b59\"},\"end\":111073,\"start\":110892},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":160025533},\"end\":111397,\"start\":111075},{\"attributes\":{\"doi\":\"arXiv:1910.10683\",\"id\":\"b61\"},\"end\":111887,\"start\":111399},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":5896299},\"end\":112372,\"start\":111889},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":54844053},\"end\":112684,\"start\":112374},{\"attributes\":{\"id\":\"b64\"},\"end\":112960,\"start\":112686},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":5444991},\"end\":113908,\"start\":112962},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":23857970},\"end\":114246,\"start\":113910},{\"attributes\":{\"doi\":\"arXiv:1706.05098.-\",\"id\":\"b67\"},\"end\":114601,\"start\":114248},{\"attributes\":{\"id\":\"b68\"},\"end\":114813,\"start\":114603},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":196211238},\"end\":115125,\"start\":114815},{\"attributes\":{\"id\":\"b70\"},\"end\":115281,\"start\":115127},{\"attributes\":{\"doi\":\"10.2139/ssrn.2882244\",\"id\":\"b71\",\"matched_paper_id\":152136830},\"end\":115496,\"start\":115283},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":236636469},\"end\":115798,\"start\":115498},{\"attributes\":{\"id\":\"b73\"},\"end\":116279,\"start\":115800},{\"attributes\":{\"id\":\"b74\"},\"end\":116469,\"start\":116281},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":14114751},\"end\":116764,\"start\":116471},{\"attributes\":{\"id\":\"b76\"},\"end\":116983,\"start\":116766},{\"attributes\":{\"doi\":\"arXiv:2003.04985\",\"id\":\"b77\"},\"end\":117429,\"start\":116985},{\"attributes\":{\"id\":\"b78\"},\"end\":117671,\"start\":117431},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":13756489},\"end\":118103,\"start\":117673},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":12477446},\"end\":118549,\"start\":118105},{\"attributes\":{\"id\":\"b81\"},\"end\":118722,\"start\":118551},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":122920708},\"end\":118970,\"start\":118724},{\"attributes\":{\"id\":\"b83\"},\"end\":119202,\"start\":118972},{\"attributes\":{\"doi\":\"arXiv-1910\",\"id\":\"b84\"},\"end\":119432,\"start\":119204},{\"attributes\":{\"id\":\"b85\"},\"end\":120045,\"start\":119434},{\"attributes\":{\"id\":\"b86\"},\"end\":120247,\"start\":120047},{\"attributes\":{\"id\":\"b87\",\"matched_paper_id\":54063095},\"end\":120621,\"start\":120249},{\"attributes\":{\"id\":\"b88\",\"matched_paper_id\":46939253},\"end\":121007,\"start\":120623}]", "bib_title": "[{\"end\":91188,\"start\":91153},{\"end\":91775,\"start\":91681},{\"end\":92226,\"start\":92177},{\"end\":93834,\"start\":93760},{\"end\":94506,\"start\":94488},{\"end\":94871,\"start\":94831},{\"end\":95329,\"start\":95289},{\"end\":95878,\"start\":95821},{\"end\":96195,\"start\":96126},{\"end\":97535,\"start\":97472},{\"end\":98024,\"start\":97979},{\"end\":99299,\"start\":99237},{\"end\":99699,\"start\":99645},{\"end\":101249,\"start\":101192},{\"end\":101483,\"start\":101412},{\"end\":104127,\"start\":104084},{\"end\":104330,\"start\":104270},{\"end\":104739,\"start\":104694},{\"end\":105412,\"start\":105373},{\"end\":105759,\"start\":105678},{\"end\":106178,\"start\":106138},{\"end\":106672,\"start\":106592},{\"end\":106986,\"start\":106920},{\"end\":107655,\"start\":107606},{\"end\":108333,\"start\":108256},{\"end\":108656,\"start\":108581},{\"end\":109676,\"start\":109632},{\"end\":109935,\"start\":109906},{\"end\":110262,\"start\":110176},{\"end\":111126,\"start\":111075},{\"end\":111949,\"start\":111889},{\"end\":112428,\"start\":112374},{\"end\":113055,\"start\":112962},{\"end\":113980,\"start\":113910},{\"end\":114625,\"start\":114603},{\"end\":114863,\"start\":114815},{\"end\":115303,\"start\":115283},{\"end\":115523,\"start\":115498},{\"end\":116545,\"start\":116471},{\"end\":117698,\"start\":117673},{\"end\":118148,\"start\":118105},{\"end\":118746,\"start\":118724},{\"end\":119500,\"start\":119434},{\"end\":120292,\"start\":120249},{\"end\":120705,\"start\":120623}]", "bib_author": "[{\"end\":91205,\"start\":91190},{\"end\":91479,\"start\":91455},{\"end\":91789,\"start\":91777},{\"end\":91802,\"start\":91789},{\"end\":91816,\"start\":91802},{\"end\":91833,\"start\":91816},{\"end\":91847,\"start\":91833},{\"end\":92247,\"start\":92228},{\"end\":92263,\"start\":92247},{\"end\":92277,\"start\":92263},{\"end\":92293,\"start\":92277},{\"end\":92930,\"start\":92909},{\"end\":92947,\"start\":92930},{\"end\":93186,\"start\":93171},{\"end\":93201,\"start\":93186},{\"end\":93217,\"start\":93201},{\"end\":93230,\"start\":93217},{\"end\":93502,\"start\":93485},{\"end\":93513,\"start\":93502},{\"end\":93530,\"start\":93513},{\"end\":93536,\"start\":93530},{\"end\":93850,\"start\":93836},{\"end\":93861,\"start\":93850},{\"end\":93870,\"start\":93861},{\"end\":93876,\"start\":93870},{\"end\":93889,\"start\":93876},{\"end\":93898,\"start\":93889},{\"end\":93913,\"start\":93898},{\"end\":93922,\"start\":93913},{\"end\":94266,\"start\":94254},{\"end\":94283,\"start\":94266},{\"end\":94302,\"start\":94283},{\"end\":94522,\"start\":94508},{\"end\":94701,\"start\":94688},{\"end\":94886,\"start\":94873},{\"end\":94903,\"start\":94886},{\"end\":95347,\"start\":95331},{\"end\":95357,\"start\":95347},{\"end\":95374,\"start\":95357},{\"end\":95385,\"start\":95374},{\"end\":95611,\"start\":95593},{\"end\":95712,\"start\":95699},{\"end\":95903,\"start\":95880},{\"end\":95912,\"start\":95903},{\"end\":95928,\"start\":95912},{\"end\":95937,\"start\":95928},{\"end\":96214,\"start\":96197},{\"end\":96229,\"start\":96214},{\"end\":96243,\"start\":96229},{\"end\":96257,\"start\":96243},{\"end\":96631,\"start\":96616},{\"end\":96645,\"start\":96631},{\"end\":96847,\"start\":96836},{\"end\":96861,\"start\":96847},{\"end\":96876,\"start\":96861},{\"end\":96905,\"start\":96876},{\"end\":96925,\"start\":96905},{\"end\":96934,\"start\":96925},{\"end\":97198,\"start\":97184},{\"end\":97214,\"start\":97198},{\"end\":97226,\"start\":97214},{\"end\":97246,\"start\":97226},{\"end\":97550,\"start\":97537},{\"end\":97559,\"start\":97550},{\"end\":97577,\"start\":97559},{\"end\":97591,\"start\":97577},{\"end\":97607,\"start\":97591},{\"end\":98042,\"start\":98026},{\"end\":98053,\"start\":98042},{\"end\":98067,\"start\":98053},{\"end\":98084,\"start\":98067},{\"end\":98106,\"start\":98084},{\"end\":98127,\"start\":98106},{\"end\":98560,\"start\":98546},{\"end\":98789,\"start\":98775},{\"end\":98798,\"start\":98789},{\"end\":99056,\"start\":99036},{\"end\":99071,\"start\":99056},{\"end\":99316,\"start\":99301},{\"end\":99324,\"start\":99316},{\"end\":99716,\"start\":99701},{\"end\":99730,\"start\":99716},{\"end\":100008,\"start\":99969},{\"end\":100044,\"start\":100008},{\"end\":100080,\"start\":100044},{\"end\":100114,\"start\":100080},{\"end\":100145,\"start\":100114},{\"end\":100531,\"start\":100521},{\"end\":100546,\"start\":100531},{\"end\":100563,\"start\":100546},{\"end\":100840,\"start\":100824},{\"end\":100855,\"start\":100840},{\"end\":100872,\"start\":100855},{\"end\":101042,\"start\":101020},{\"end\":101266,\"start\":101251},{\"end\":101503,\"start\":101485},{\"end\":101514,\"start\":101503},{\"end\":101524,\"start\":101514},{\"end\":101858,\"start\":101850},{\"end\":101872,\"start\":101858},{\"end\":101890,\"start\":101872},{\"end\":102166,\"start\":102151},{\"end\":102183,\"start\":102166},{\"end\":102414,\"start\":102397},{\"end\":102613,\"start\":102598},{\"end\":102802,\"start\":102789},{\"end\":102816,\"start\":102802},{\"end\":102831,\"start\":102816},{\"end\":102848,\"start\":102831},{\"end\":102865,\"start\":102848},{\"end\":102882,\"start\":102865},{\"end\":102901,\"start\":102882},{\"end\":103284,\"start\":103264},{\"end\":103299,\"start\":103284},{\"end\":103319,\"start\":103299},{\"end\":103337,\"start\":103319},{\"end\":103352,\"start\":103337},{\"end\":103368,\"start\":103352},{\"end\":103714,\"start\":103698},{\"end\":104757,\"start\":104741},{\"end\":104769,\"start\":104757},{\"end\":104777,\"start\":104769},{\"end\":105014,\"start\":105004},{\"end\":105219,\"start\":105207},{\"end\":105426,\"start\":105414},{\"end\":105441,\"start\":105426},{\"end\":105452,\"start\":105441},{\"end\":105773,\"start\":105761},{\"end\":105787,\"start\":105773},{\"end\":105804,\"start\":105787},{\"end\":105818,\"start\":105804},{\"end\":105834,\"start\":105818},{\"end\":105851,\"start\":105834},{\"end\":105860,\"start\":105851},{\"end\":106197,\"start\":106180},{\"end\":106404,\"start\":106391},{\"end\":106690,\"start\":106674},{\"end\":106706,\"start\":106690},{\"end\":107003,\"start\":106988},{\"end\":107016,\"start\":107003},{\"end\":107674,\"start\":107657},{\"end\":107690,\"start\":107674},{\"end\":107705,\"start\":107690},{\"end\":107720,\"start\":107705},{\"end\":107730,\"start\":107720},{\"end\":108351,\"start\":108335},{\"end\":108366,\"start\":108351},{\"end\":108674,\"start\":108658},{\"end\":108682,\"start\":108674},{\"end\":108694,\"start\":108682},{\"end\":108703,\"start\":108694},{\"end\":108721,\"start\":108703},{\"end\":108740,\"start\":108721},{\"end\":108754,\"start\":108740},{\"end\":108761,\"start\":108754},{\"end\":109699,\"start\":109678},{\"end\":109717,\"start\":109699},{\"end\":109732,\"start\":109717},{\"end\":109948,\"start\":109937},{\"end\":109962,\"start\":109948},{\"end\":109968,\"start\":109962},{\"end\":110279,\"start\":110264},{\"end\":110296,\"start\":110279},{\"end\":110749,\"start\":110733},{\"end\":110764,\"start\":110749},{\"end\":110775,\"start\":110764},{\"end\":110907,\"start\":110894},{\"end\":110920,\"start\":110907},{\"end\":110935,\"start\":110920},{\"end\":110947,\"start\":110935},{\"end\":110966,\"start\":110947},{\"end\":111142,\"start\":111128},{\"end\":111154,\"start\":111142},{\"end\":111167,\"start\":111154},{\"end\":111179,\"start\":111167},{\"end\":111193,\"start\":111179},{\"end\":111209,\"start\":111193},{\"end\":111496,\"start\":111482},{\"end\":111510,\"start\":111496},{\"end\":111524,\"start\":111510},{\"end\":111539,\"start\":111524},{\"end\":111554,\"start\":111539},{\"end\":111570,\"start\":111554},{\"end\":111582,\"start\":111570},{\"end\":111590,\"start\":111582},{\"end\":111603,\"start\":111590},{\"end\":111966,\"start\":111951},{\"end\":111990,\"start\":111966},{\"end\":112000,\"start\":111990},{\"end\":112015,\"start\":112000},{\"end\":112026,\"start\":112015},{\"end\":112439,\"start\":112430},{\"end\":113069,\"start\":113057},{\"end\":113083,\"start\":113069},{\"end\":113104,\"start\":113083},{\"end\":113122,\"start\":113104},{\"end\":113137,\"start\":113122},{\"end\":113155,\"start\":113137},{\"end\":113999,\"start\":113982},{\"end\":114023,\"start\":113999},{\"end\":114034,\"start\":114023},{\"end\":114325,\"start\":114308},{\"end\":114644,\"start\":114627},{\"end\":114878,\"start\":114865},{\"end\":114891,\"start\":114878},{\"end\":114907,\"start\":114891},{\"end\":114919,\"start\":114907},{\"end\":114933,\"start\":114919},{\"end\":115321,\"start\":115305},{\"end\":115539,\"start\":115525},{\"end\":115915,\"start\":115897},{\"end\":115932,\"start\":115915},{\"end\":115947,\"start\":115932},{\"end\":115964,\"start\":115947},{\"end\":115980,\"start\":115964},{\"end\":115997,\"start\":115980},{\"end\":116014,\"start\":115997},{\"end\":116031,\"start\":116014},{\"end\":116342,\"start\":116325},{\"end\":116565,\"start\":116547},{\"end\":116847,\"start\":116830},{\"end\":117090,\"start\":117078},{\"end\":117108,\"start\":117090},{\"end\":117121,\"start\":117108},{\"end\":117133,\"start\":117121},{\"end\":117141,\"start\":117133},{\"end\":117152,\"start\":117141},{\"end\":117167,\"start\":117152},{\"end\":117531,\"start\":117513},{\"end\":117716,\"start\":117700},{\"end\":117730,\"start\":117716},{\"end\":117743,\"start\":117730},{\"end\":117760,\"start\":117743},{\"end\":117773,\"start\":117760},{\"end\":117788,\"start\":117773},{\"end\":117803,\"start\":117788},{\"end\":117821,\"start\":117803},{\"end\":118166,\"start\":118150},{\"end\":118184,\"start\":118166},{\"end\":118623,\"start\":118610},{\"end\":118761,\"start\":118748},{\"end\":118779,\"start\":118761},{\"end\":119050,\"start\":119034},{\"end\":119057,\"start\":119050},{\"end\":119291,\"start\":119278},{\"end\":119521,\"start\":119502},{\"end\":120089,\"start\":120070},{\"end\":120106,\"start\":120089},{\"end\":120309,\"start\":120294},{\"end\":120324,\"start\":120309},{\"end\":120341,\"start\":120324},{\"end\":120354,\"start\":120341},{\"end\":120368,\"start\":120354},{\"end\":120719,\"start\":120707},{\"end\":120735,\"start\":120719},{\"end\":120752,\"start\":120735}]", "bib_venue": "[{\"end\":92554,\"start\":92432},{\"end\":95086,\"start\":95003},{\"end\":97734,\"start\":97679},{\"end\":98246,\"start\":98195},{\"end\":107212,\"start\":107125},{\"end\":107971,\"start\":107859},{\"end\":108931,\"start\":108843},{\"end\":113418,\"start\":113320},{\"end\":114966,\"start\":114958},{\"end\":118295,\"start\":118248},{\"end\":119594,\"start\":119583},{\"end\":91262,\"start\":91205},{\"end\":91453,\"start\":91405},{\"end\":91906,\"start\":91847},{\"end\":92430,\"start\":92293},{\"end\":92907,\"start\":92841},{\"end\":93169,\"start\":93134},{\"end\":93483,\"start\":93395},{\"end\":93953,\"start\":93922},{\"end\":94252,\"start\":94198},{\"end\":94543,\"start\":94522},{\"end\":94686,\"start\":94628},{\"end\":95001,\"start\":94903},{\"end\":95398,\"start\":95385},{\"end\":95697,\"start\":95670},{\"end\":95957,\"start\":95937},{\"end\":96319,\"start\":96257},{\"end\":96614,\"start\":96535},{\"end\":96834,\"start\":96779},{\"end\":97182,\"start\":97102},{\"end\":97677,\"start\":97607},{\"end\":98193,\"start\":98127},{\"end\":98544,\"start\":98500},{\"end\":98773,\"start\":98685},{\"end\":99034,\"start\":98938},{\"end\":99376,\"start\":99324},{\"end\":99761,\"start\":99730},{\"end\":99967,\"start\":99911},{\"end\":100519,\"start\":100399},{\"end\":100822,\"start\":100809},{\"end\":101018,\"start\":100968},{\"end\":101287,\"start\":101266},{\"end\":101571,\"start\":101524},{\"end\":101848,\"start\":101773},{\"end\":102149,\"start\":102089},{\"end\":102395,\"start\":102358},{\"end\":102596,\"start\":102562},{\"end\":102787,\"start\":102717},{\"end\":103262,\"start\":103179},{\"end\":103696,\"start\":103639},{\"end\":104159,\"start\":104129},{\"end\":104366,\"start\":104332},{\"end\":104807,\"start\":104777},{\"end\":105002,\"start\":104941},{\"end\":105205,\"start\":105150},{\"end\":105514,\"start\":105452},{\"end\":105889,\"start\":105860},{\"end\":106213,\"start\":106197},{\"end\":106389,\"start\":106323},{\"end\":106736,\"start\":106706},{\"end\":107123,\"start\":107036},{\"end\":107857,\"start\":107730},{\"end\":108392,\"start\":108366},{\"end\":108841,\"start\":108772},{\"end\":109752,\"start\":109732},{\"end\":110019,\"start\":109968},{\"end\":110363,\"start\":110296},{\"end\":110731,\"start\":110713},{\"end\":111222,\"start\":111209},{\"end\":111480,\"start\":111399},{\"end\":112105,\"start\":112026},{\"end\":112489,\"start\":112439},{\"end\":112749,\"start\":112686},{\"end\":113262,\"start\":113155},{\"end\":114061,\"start\":114034},{\"end\":114306,\"start\":114248},{\"end\":114676,\"start\":114644},{\"end\":114956,\"start\":114933},{\"end\":115190,\"start\":115127},{\"end\":115361,\"start\":115341},{\"end\":115630,\"start\":115539},{\"end\":115895,\"start\":115800},{\"end\":116323,\"start\":116281},{\"end\":116599,\"start\":116565},{\"end\":116828,\"start\":116766},{\"end\":117076,\"start\":116985},{\"end\":117511,\"start\":117431},{\"end\":117870,\"start\":117821},{\"end\":118246,\"start\":118184},{\"end\":118608,\"start\":118551},{\"end\":118827,\"start\":118779},{\"end\":119032,\"start\":118972},{\"end\":119276,\"start\":119204},{\"end\":119570,\"start\":119521},{\"end\":120068,\"start\":120047},{\"end\":120417,\"start\":120368},{\"end\":120784,\"start\":120752}]"}}}, "year": 2023, "month": 12, "day": 17}