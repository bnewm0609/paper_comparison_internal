{"id": 248512587, "updated": "2023-10-05 14:58:08.206", "metadata": {"title": "Measuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment", "authors": "[{\"first\":\"Yujian\",\"last\":\"Gan\",\"middle\":[]},{\"first\":\"Xinyun\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Qiuping\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Matthew\",\"last\":\"Purver\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "In text-to-SQL tasks -- as in much of NLP -- compositional generalization is a major challenge: neural networks struggle with compositional generalization where training and test distributions differ. However, most recent attempts to improve this are based on word-level synthetic data or specific dataset splits to generate compositional biases. In this work, we propose a clause-level compositional example generation method. We first split the sentences in the Spider text-to-SQL dataset into sub-sentences, annotating each sub-sentence with its corresponding SQL clause, resulting in a new dataset Spider-SS. We then construct a further dataset, Spider-CG, by composing Spider-SS sub-sentences in different combinations, to test the ability of models to generalize compositionally. Experiments show that existing models suffer significant performance degradation when evaluated on Spider-CG, even though every sub-sentence is seen during training. To deal with this problem, we modify a number of state-of-the-art models to train on the segmented data of Spider-SS, and we show that this method improves the generalization performance.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2205.02054", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/naacl/GanCHP22", "doi": "10.18653/v1/2022.findings-naacl.62"}}, "content": {"source": {"pdf_hash": "a40693eefd351659cdeb3885917b1506ea01c38a", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2205.02054v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "702afed66bb1e4700dcb3ca609423458d3130627", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a40693eefd351659cdeb3885917b1506ea01c38a.txt", "contents": "\nMeasuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment\n\n\nYujian Gan y.gan@qmul.ac.uk \nQueen Mary University of London\n\n\nXinyun Chen xinyun.chen@berkeley.edu \nBerkeley\n\nQiuping Huang qiuping_h@foxmail.com \nMatthew Purver m.purver@qmul.ac.uk \nQueen Mary University of London\n\n\nJo\u017eef Stefan Institute\n\n\nMeasuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment\n4 Nanning Central Sub-branch of the People's Bank of China\nIn text-to-SQL tasks -as in much of NLPcompositional generalization is a major challenge: neural networks struggle with compositional generalization where training and test distributions differ. However, most recent attempts to improve this are based on word-level synthetic data or specific dataset splits to generate compositional biases. In this work, we propose a clause-level compositional example generation method. We first split the sentences in the Spider text-to-SQL dataset into subsentences, annotating each sub-sentence with its corresponding SQL clause, resulting in a new dataset Spider-SS. We then construct a further dataset, Spider-CG, by composing Spider-SS sub-sentences in different combinations, to test the ability of models to generalize compositionally. Experiments show that existing models suffer significant performance degradation when evaluated on Spider-CG, even though every sub-sentence is seen during training. To deal with this problem, we modify a number of state-of-the-art models to train on the segmented data of Spider-SS, and we show that this method improves the generalization performance. 1\n\nIntroduction\n\nNeural models in supervised learning settings show good performance on data drawn from the training distribution. However, generalization performance can be poor on out-of-distribution (OOD) samples (Finegan-Dollak et al., 2018;Suhr et al., 2020;Kaushik et al., 2020;Sagawa et al., 2020). This might be the case even when the new samples are composed of known constituents; e.g., on the SCAN dataset (Lake and Baroni, 2018), many models give incorrect predictions for the input \"jump twice and walk\", even when \"jump twice\", \"walk\", and \"walk twice\" are seen during training. This 1 Our code and dataset are available at https://github.com/ygan/SpiderSS-SpiderCG (often lacking) ability to generalize to novel combinations of elements observed during training is referred to as compositional generalization.\n\nPrevious work on compositional generalization in text-to-SQL focuses on query split. For example, Shaw et al. (2021) propose TMCD split based on SQL atoms and compounds analysis and question split based on length. Finegan-Dollak et al. (2018) proposes a query template-based split with word substitution that was much more challenging than the question split. However, these splits are limited by the dataset content, making it difficult to construct a challenging benchmark while ensuring that every question phrase (sub-sentence) appears in the training set.\n\nPrevious works  improve generalization by enhancing the model's component awareness. Similarly, Yin et al. (2021) and Herzig and Berant (2021) propose span-based semantic parsers that predict a sub-program over an utterance span. However, these works are based on datasets where component alignment is relatively easy to achieve; but for more complex text-to-SQL, their methods cannot be used directly. For example, as shown in the lower part of Figure 1, to align the sub-sentence with the sub-SQL, the algorithm needs to know that 'youngest' corresponds to 'age', and 'weigh' corresponds to 'weight'. For small or single-domain settings, such an alignment algorithm can be built by establishing rules; however, there is currently no simple and feasible alignment method for large complex cross-domain text-to-SQL, as in e.g. the Spider benchmark (Yu et al., 2018b).\n\nIn this work, we first introduce a new dataset, Spider-SS (SS stands for sub-sentence), derived from Spider (Yu et al., 2018b); Figure 1 compares the two. To build Spider-SS, we first design a sentence split algorithm to split every Spider sentence into several sub-sentences until indivisible. Next, we annotate every sub-sentence with its cor- , and how much does it weigh?\n\nSubSentence:\n\n\nSELECT Pets.Weight\n\nNatSQL:\n\nis the youngest animal SubSentence:\n\nORDER BY Pets.Pet_Age LIMIT 1 NatSQL: Figure 1: A natural language sentence in the original Spider benchmark is split into three sub-sentences in Spider-SS, where each sub-sentence has a corresponding NatSQL clause.\n\nresponding SQL clause, reducing the difficulty of this task by using the intermediate representation language NatSQL (Gan et al., 2021b), which is simpler and syntactically aligns better with natural language (NL). Spider-SS thus provides a new resource for designing models with better generalization capabilities without designing a complex alignment algorithm. Furthermore, it can also be used as a benchmark for evaluating future alignment algorithms. To our knowledge, this is the first sub-sentence-based text-to-SQL dataset.\n\nOur annotated Spider-SS provides us with subsentences paired with NatSQL clauses, which serve as our elements. Based on Spider-SS, we then construct a further dataset Spider-CG (CG stands for compositional generalization), by substituting sub-sentences with those from other samples, or composing two sub-sentences to form a more complicated sample. Spider-CG contains two subsets; Figure 2 shows one example for each. The first subset contains 23,569 examples generated by substituting sub-sentences; we consider most data in this subset as in-distribution. The second subset contains 22,030 examples generated by appending sub-sentences, increasing the length and complexity of the sentence and the SQL query compared to the original samples; we consider this subset as OOD. We demonstrate that when models are trained only on the original Spider dataset, they suffer a significant performance drop on the second OOD subset of Spider-CG, even though the domain appears in the training set.\n\nTo improve the generalization performance of text-to-SQL models, we modify several previous state-of-the-art models so that they can be applied Subset-2: Example-1 append a sub-sentence from Example-2 Figure 2: Two Spider-CG samples generated by: (1) substituting the sub-sentence with one from another example; or (2) composing sub-sentences from 2 examples in Spider-SS.\n\nto the Spider-SS dataset, with the model trained sub-sentence by sub-sentence. This modification obtains more than 7.8% accuracy improvement on the OOD subset of Spider-CG. In short, we make the following contributions:\n\n\u2022 Besides the sentence split algorithm, we introduce Spider-SS, a human-curated subsentence-based text-to-SQL dataset built upon the Spider benchmark, by splitting its NL questions into sub-sentences.\n\n\u2022 We introduce the Spider-CG benchmark for measuring the compositional generalization performance of text-to-SQL models.\n\n\u2022 We show that text-to-SQL models can be adapted to sub-sentence-based training, improving their generalization performance.\n\n2 Spider-SS 2.1 Overview Figure 1 presents a comparison between Spider and Spider-SS. Unlike Spider, which annotates a whole SQL query to an entire sentence, Spider-SS annotates the SQL clauses to sub-sentences. Spider-SS uses NatSQL (Gan et al., 2021b) Figure 3: Dependency structure of a sentence and how to split this sentence into three sub-sentences.\n\nSQL clauses due to the SQL language design. The Spider-SS provides a combination algorithm that collects all NatSQL clauses and then generates the NatSQL query, where the NatSQL query can be converted into an SQL query. The purpose of building Spider-SS is to attain clause-level text-to-SQL data avoiding the need for an alignment algorithm that is hard to build based on the complex large cross-domain text-to-SQL dataset, e.g., Spider benchmark. Besides, we can generate more complex examples through different combination of clauses from Spider-SS. Consistent with Spider, Spider-SS contains 7000 training and 1034 development examples, but Spider-SS does not contain a test set since the Spider test set is not public. There are two steps to build Spider-SS. First, design a sentence split algorithm to cut the sentence into sub-sentences, and then manually annotate the NatSQL clause corresponding to each sub-sentence.\n\n\nSentence Split Algorithm\n\nWe build our sentence split algorithm upon the NL dependency parser spaCy 2 , which provides the grammatical structure of a sentence. Basically, we split the sentence with the following dependencies: prep, relcl, advcl, acl, nsubj, npadvmod, csubj, nsubjpass and conj. According to (de Marnee and Manning, 2016), these dependencies help us separate the main clause, subordinate clauses, and modifiers. Figure 3 shows the dependency structure of a sentence and how to split this sentence into three sub-sentences. However, not every sentence would be split since there are some non-splittable sentences, such as the third example in Figure 4, with the same annotation as the Spider dataset. Although this method can separate sentences well in most cases, due to the variability of natural language, some examples cannot be perfectly split.\n\nTo address the remaining issues in sentence split, we design some refinement steps tailored to text-to-SQL applications. For example, when the phase of 2 https://github.com/explosion/spaCy Example-3: Some sentences cannot be split d\n\n\nNO MENTIONED\n\nFind the emails and phone numbers of all the customers, and phone numbers. a schema column or table is accidentally divided into two sub-sentences, these two sub-sentences are automatically concatenated. Besides, when there is only one word in a sub-sentence, the corresponding split should also be undone.\n\nWe sampled 500 examples from the Spider-SS development set to evaluate the acceptability of splitting results manually, and only < 3% of the splitting results are unsatisfactory. For example, in the splitting results of the first example in Figure 4, the last two sub-sentence should be combined to correspond to \"ORDER BY Customer.Email_Address, Customer.Phone_Number ASC \". In this example, we did not simply give an \"ORDER BY Customer.Phone_Number ASC \" to the last sub-sentence, because it does not mention anything related to \"ORDER BY \". Here, we introduce \"extra\", a new NatSQL keyword designed for the Spider-SS dataset, indicating that this subsentence mentions a column that temporarily does not fit in any other NatSQL clauses. When combining NatSQL clauses into the final NatSQL query, the combining algorithm determines the final position for the \"extra\" column based on the clauses before and after. Note that even if there is a small proportion of unsatisfactory splitting results, as long as the model trained on Spider-SS can give the correct output according to the input sub-sentence, the quality of the sub-sentences itself does not strongly affect the model utility.\n\n\nData Annotation\n\nWhen we get the split results from the last step, we can start data annotation. We give precise annotations based on the sub-sentence content, such as the \"extra\" column annotation discussed in the last subsection. Besides, if the description of the schema column is missing in the sub-sentence, we will give the schema column an additional \"NO MENTIONED\" mark. For example, in the second example of Figure 4, the \"in ascending order\" subsentence does not mention the \"Farm.Total_Horses\" column. Therefore, we add a \"NO MENTIONED\" mark for it. For those sub-sentences that do not mention anything related to the query, we give a \"NONE\" mark, representing there are no NatSQL clauses.\n\nSince the annotation is carried out according to the sub-sentence content, the equivalent SQL that is more consistent with the sub-sentence will be preferred to the original SQL. Similarly, if the original SQL annotation is wrong, we correct it according to the content.\n\nWe annotate the sub-sentence using NatSQL instead of SQL, where NatSQL is an intermediate representation of SQL, only keeping the SE-LECT, WHERE, and ORDER BY clauses from SQL. Since some sub-sentences need to be annotated with GROUP BY clause, we choose the version of NatSQL augmented with GROUP BY. We did not use SQL directly because it is difficult to annotate in some cases, such as the SQL example in Figure 5. The difficulty is that there are two SELECT clauses in this SQL query, but none of the sub-sentences seem to correspond to two SELECT clauses. In addition, considering that the two WHERE conditions correspond to different SELECT clauses, the annotation work based on SQL is far more difficult to complete. As shown in Figure 5, we can use Nat-SQL to complete the annotation quickly, while the NatSQL can be converted back to the target SQL. The detail of the annotation steps can be found in Appendix C.\n\n\nSpider-CG\n\n\nOverview\n\nSpider-CG is a synthetic dataset, which is generated by recombining the sub-sentences of Spider-SS. There are two recombination methods. The first is sub-sentence substitution between different examples, and the other is to append a sub-sentence into another sentence. To facilitate the follow-up What are the locations that have both tracks with more than 90000 seats, and tracks with fewer than 70000 seats?\n\n\nSentence:\n\nA sentence and its corresponding SQL and NatSQL:  \n\n\nGeneration Algorithm\n\nAccording to Algorithm 1, we can generate the CG-SUB and CG-APP based on compositional elements. Each element contains one or more sub-sentences with corresponding NatSQL clauses from Spider-SS, where these NatSQL can only be WHERE or ORDER BY clauses. Thus, Algorithm 1 only substitute and append the WHERE and OR-DER BY clauses, and does not modify the SELECT clause. We collect the sub-sentences for compositional elements by scanning all sub-sentence from start to end or from end to start and stopping when encountering clauses except WHERE and ORDER BY. For example, we generate a compositional element containing the last two sub-sentences of the Spider-SS example in Figure 5. In contrast, no element is extracted from the example in for Every element 2 in e_list do 3:\n\nif element 1 != element 2 then 4:\n\nif element 1 .can_be_substituted_by( element 2 ) then 5:\n\ncg_sub.append( element 1 .generate_substitution_example( element 2 ) ) 6:\n\nif element 1 .can_append( element 2 ) then 7:\n\ncg_app.append( element 1 .generate_appending_example( element 2 ) ) 8: return cg_sub, cg_app\n\nQues Show the name of employees named Mark Young ? SQL SELECT name FROM employee WHERE name = 'Mark Young' main cannot be used in another because the schema items are different. So as many domains as there are, it needs to run Algorithm 1 as many times. We recommend reading Appendix A for details of can_be_substituted_by and can_append functions.\n\n\nQuality Evaluation\n\nWe consider that the quality of a text-to-SQL sentence is determined by two criteria: containing the required information and being reasonable. The 'information' criterion requires a sentence that contains all the information needed to derive the target NatSQL. The 'reasonable' criterion requires a sentence that is logically correct and whose representation is fluent and easy to understand. \nEncoder V 0 V 1 V 2 V 3 V 4 V 5 V 6 V 7 V 8\nEncoder Vectors:\n\nDecoder WHERE Student.Age > 10 Figure 6: A example of encoding the whole sentence but decoding only the sub-sentence.\n\nfuture.\n\n\nModel\n\nExisting text-to-SQL models input a sentence and output the corresponding SQL query. So the easiest way to think of using the Spider-SS dataset is to train the model where inputting sub-sentence and outputting the corresponding NatSQL clauses. However, this method is not workable because it will lose some essential schema information. For example, if you only look at the third sub-sentence in Figure 1, you do not know whether it enquires about the weight of pets or people. In order to take into account the context and the sub-sentence data of Spider-SS, we propose that a seq2seq model can encode the whole sentence but decode only the sub-sentence. Figure 6 presents the workflow of encoding the whole sentence but only decoding the sub-sentence of 'who is older than ten' and outputting the corresponding NatSQL clause. Based on this modification, a seq2seq text-to-SQL List name of student who is older than ten 0:3  model can be adapted to the Spider-SS. Although previous span-based semantic parsers (Yin et al., 2021;Herzig and Berant, 2021) can work with aligned annotations based on the Spider-SS dataset, none of them are designed for complex text-to-SQL problems. Our modification idea is similar in principle to the span-based semantic parsers, but we did not change the existing model according to the span-based because our modification idea has a smaller workload.\n\nIn general, we can make the seq2seq-based textto-SQL models adapt to the Spider-SS in three steps. (1) Data preprocess. Split the Spider-SS examples by sub-sentence. For example, the example in Figure  (2) Model modification. After data preprocessing, there are two input data for a model. The first input is an entire question that directly goes to the encoder. The second input is the sub-sentence indexes, which are used to select the encoder output, as shown in Figure 6. (3) Output combination. Since the model output may be only a clause, not a complete NatSQL query, we generate the final Nat-SQL query after the model outputting all NatSQL clauses.\n\n\nExperiment\n\n\nExperimental Setup\n\nDataset. We evaluate the previous state-of-theart models on the Spider-CG and Spider (Yu et al., 2018b) datasets. Since the Spider test set is not publicly accessible, Spider-CG does not contain a test set. As discussed in Section 3.1, we divide the Spider-CG into two subsets: CG-SUB and CG-APP. Therefore, there are five evaluation sets:    by NatSQL, this subscript also indicates that the model uses NatSQL instead of SQL.\n\nImplementations. All experiments were performed on a machine with an Intel i5 9600 3.1GHz processor and a 24GB RTX3090 GPU. All models keep their original hyperparameters except the RATSQL B(S) . RATSQL B(S) cannot converge on the original parameters until we reduce the learning rate of model from 7.444e-04 to 1e-04 and raise the learning rate of BERT from 3e-06 to 1e-05. We did not conduct a hyperparameter search, so the model trained on Spider-SS may improve performance through other parameters.\n\n\nDataset Analysis\n\nSpider-SS. Table 2 presents the difference between the SQL in Spider and the SQL generated by NatSQL in Spider-SS. Our evaluation results are lower than the original NatSQL dataset (Gan et al., 2021b) because the Spider-SS uses equivalent SQL and corrects some errors, as discussed in Section 2.3. Some equivalent and corrected SQL cannot get positive results in exact match metric and execution match. Therefore, the model trained on Spider-SS may not be ideal for chasing the Spider benchmark, especially based on the exact match metric. Similarly, the RATSQL G extending Nat-SQL had achieved a previous SOTA result in the execution match of the Spider test set but get a worse result than the original in the exact match (Gan et al., 2021b). Thus, we recommend using NatSQL-based datasets to evaluate models trained on NatSQL.\n\nSpider-CG. Table 3 presents the difficulty distribution of five different evaluation sets. The difficulty criteria are defined by Spider benchmark, including easy, medium, hard and extra hard. Experiments show that the more difficult the SQL is, the more difficult it is to predict correctly Shi et al., 2021;Gan et al., 2021b). It can be found from Table 3 that the difficulty distribution of CG-SUB T and CG-SUB D is similar to that of Spider D . The similar distributions among CG-SUB T , CG-SUB D , and Spider D support the view discussed in Section 1 that the examples generated by the substitution method are in-distribution.\n\nOn the other hand, the difficulty distributions of CG-APP T and CG-APP D are obviously different from that of Spider D . Due to appending the subsentence, the NL and SQL in CG-APP become more complex, where the proportion of SQL in extra hard increased significantly, while easy was the opposite.\n\n\nSentence Split Algorithm Evaluation\n\nWe generate the Spider-CG based on the combination of Spider-SS sub-sentences split by the algorithm introduced in Section 2.2. We can reuse this algorithm to split the sentence in Spider-CG and then compare the splitting results with the Spider-SS sub-sentences to evaluate the stability of the splitting algorithm. We consider that a deviation of one or two tokens in the splitting result is acceptable. For example, in Figure 1, we consider that putting the comma of the third sub-sentence into the second sub-sentence does not change the meaning of sub-sentences, same for moving both the comma and the word 'and'. Table 4 presents the similarity between subsentences in Spider-SS and Spider-CG, which are generated by the same split algorithm under the deviation of one or two words. The similarity exceeds 90% in all evaluation set when two deviation words are allowed. Considering that the model trained on the Spider-SS does not require consistent split results, as discussed in Section 2.2, the similarity results of the splitting algorithm are good enough. The similarity of CG-SUB is higher than that of CG-APP, which means the more complex the sentence, the greater the challenge to the algorithm. Although the algorithm has been refined on the training set, the similarity between training and development in CG-SUB and CG-APP is close,  showing that the algorithm performs consistently for sentences in unseen domains. In summary, we consider that as long as the sentences are not more complex than CG-APP, the algorithm can be used stably in other text-to-SQL datasets. Table 5 presents the exact match accuracy on the five different evaluation sets. In the two OOD datasets, CG-APP T and CG-APP D , the performance of all models has dropped by about 10% to 30%. However, the models trained on Spider-SS significantly outperform those trained on Spider when evaluated on the OOD datasets. We use the sentence split algorithm to split every sentence before inputting the models with subscript (S). Although the split sub-sentences are not completely consistent with those seen during training, it did not prevent the models with subscript (S) from getting good performance, i.e., the RATSQL G(S) consistently outperforms all other models on all evaluation sets. These results demonstrate that the subsentence-based method can improve the generalization performance. The limitation is that the method may not be compatible with the original model, e.g., original hyperparameters in RATSQL B(S) are not workable, and the performance of GNN on the Spider D and CG-SUB D is degraded. Each model has a close result between the unseen Spider D and CG-SUB D , indicating that from the perspective of the model, the synthetic sentences are pretty similar to NL. Therefore, we believe the performance on CG-SUB D can be generalized to the real world. Moreover, considering that the algorithms for generating CG-SUB D and CG-APP D are close (see Appendix A), we can further speculate that the synthetic sentences of CG-APP D are also close to natural language.\n\n\nModel Results\n\nThe models with NatSQL is significantly better than that without NatSQL when evaluated on Spider-CG. One of the reasons is that the training data of Spider and Spider-SS are about 10% different, which leads to the performance degradation in the model trained on Spider when evaluated on the SQL generated by the NatSQL of Spider-SS, and vice versa. On the other hand, experiments in (Gan et al., 2021b) show that NatSQL improve the model performance in extra hard SQL. Therefore, RATSQL G(N) and RATSQL B(N) suffer less performance degradation in CG-APP T and CG-APP D than RATSQL G and RATSQL B .\n\n\nLimitation of this Work\n\nThe Spider-SS and Spider-CG are based on Spider, an English large-scale text-to-SQL dataset, and we did not extend the experiment to other language and text-to-SQL datasets. Therefore, we did not verify whether these methods work well in other languages and datasets. Besides, since this work is based on NatSQL, there will be around 5% of NatSQL that can not be converted to the correct SQL.\n\n\nRelated Work\n\nData augmentation for text-to-SQL models. Data augmentation has been commonly used for improving performance (Xiong and Sun, 2019;Li et al., 2019). In the context of text-to-SQL generation, Yu et al. (2018a) generate synthetic training samples from some pre-defined SQL and NL question templates. Parikh et al. (2020) introduces an table-to-text dataset with over 120,000 examples that proposes a controlled generation task: given a Wikipedia table and a set of highlighted table  cells, produce a  Compositional generalization for semantic parsing. Compositional generalization for semantic parsing has captured wide attention recently (Finegan-Dollak et al., 2018;Oren et al., 2020;Furrer et al., 2020;Conklin et al., 2021). Most prior works on text-to-SQL tasks focus on the crossdomain generalization, which mainly assess how the models generalize the domain knowledge to  new database schemas (Suhr et al., 2020;Gan et al., 2021a). On the other hand, Shaw et al. (2021) introduces TMCD splits for studying compositional generalization in semantic parsing, where they aim to maximize the divergence of SQL compounds between the training and test sets.\n\nAlthough both the TMCD split and our Spider-CG can be used to evaluate the text-to-SQL compositional generalization ability, their problem setting is different. TMCD split is based on SQL syntax structure, while Spider-CG is based on the natural language syntax, which leads to different requirements for compositional generalization ability. For example, TMCD splits requires model learning \"Give me the name of students who is the oldest\" can predict the \"Give me the name of the oldest student\" since their SQL is the same. Spider-CG does not expect the model to do so because the syntax of questions is different, i.e., \"Give me the name of students who is the oldest\" contains two sub-sentences, and none of them is close to the \"Give me the name of the oldest student\". In other words, Spider-CG requires the model learning \"List the id of the oldest dog\" can predict the \"Give me the name of the oldest student\".\n\nOur model is inspired by prior works on neural parsers constructed to capture granular information from a whole. Yin et al. (2021) describe a span-level supervised attention loss that improves compositional generalization in semantic parsers. Herzig and Berant (2021) propose SpanBasedSP, a parser that predicts a span tree over an input utterance, and dramatically improves performance on splits that require compositional generalization.  propose the Neural-Symbolic Stack machine (NeSS), which integrates a symbolic stack machine into a seq2seq generation framework, and learns a neural network as the controller to operate the machine. However, these works are based on datasets where component alignment is relatively easy to achieve; but for more complex text-to-SQL, their methods cannot be used directly. Our proposed Spider-SS can be used to replace or evaluate the alignment algorithm.\n\n\nConclusion\n\nWe introduce Spider-SS and Spider-CG for measuring compositional generalization of text-to-SQL models. Specifically, Spider-SS is a human-curated sub-sentence-based text-to-SQL dataset built upon the Spider benchmark. Spider-CG is a synthetic text-to-SQL dataset constructed by substituting and appending sub-sentences of different samples, so that the training and test sets consist of different compositions of sub-sentences. We found that the performance of previous text-to-SQL models drop dramatically on the Spider-CG OOD subset, while modifying the models to fit the segmented data of Spider-SS improves compositional generalization performance.\n\nA Further Discussion of Algorithm 1\n\nAs discussed in Section 3.3, we need to ensure that the Spider-CG examples meet the criteria of containing required information and being reasonable. To ensure that the generated Spider-CG sentence contains the required information, the compositional element needs to contain all the information needed to derive the target NatSQL clause. Thus some sub-sentence can not be a compositional element, such as the last sub-sentence of examples 1 and 2 in Figure 4. Among them, example 1 misses ORDER BY information; example 2 misses Total_Horses column information. In contrast, the sub-sentence of the two Spider-SS examples in Figure 2 contains the required information and can be compositional elements. So, we can filter out the sub-sentences containing the \"NO MENTIONED\" and \"extra\" label, and collect the rest as compositional elements.\n\nThe 'can_be_substituted_by' and 'can_append' function in Algorithm 1 are used to ensure that the generated sentences are reasonable. For the convenience of discussion, we refer to them as 'sub' and 'app' functions for short. These two functions examine the generated sentences from complexity, logic and coherence.\n\nComplexity checks are used to limit the complexity of the generated examples to no more complex than the upper bound of the Spider dataset. On the NatSQL side, both functions do not allow the generated NatSQL containing: 1) more than one subqueries; 2) more than one HAVING condition; 3) more than three WHERE conditions; 4) more than one ORDER BY clause; 5) new conditions for a subquery. On the NL side, since the substitution did not clearly increase the sentence complexity, only the 'app' function performs the NL complexity checks to restrict the number of sub-sentence to less than 4.\n\nLogic checks are used to prevent generating contradictory examples. First, logic checks filter out examples with repeated WHERE conditions. Then, it filters out examples whose WHERE condition negates the query content, e.g., what is name of student that do not have any student. Finally, since the GROUP BY clause is often expressed implicitly, substituting or appending elements containing the GROUP BY clause may introduce logical errors. Thus, logic checks require the GROUP BY clauses to be the same if they exist.\n\nCoherence checks are used to ensure that the expression of the generated sentence is coherent. As discussed in Section 2.2, we separate a sentence into main clause, subordinate clauses, and modifiers. The main clause expresses what you want to query, i.e., corresponding to the SELECT clause. Subordinate clauses and modifiers are restrictions on the query, i.e., corresponding to WHERE and ORDER BY clauses. Therefore, compositional elements only contain subordinate clauses and modifiers. The way to ensure the coherence of sentences by sub function is to require the substitution sub-sentences modify the same noun. Suppose the schema table of the NatSQL in a compositional element appears in advance. In that case, we consider its sub-sentence modifies the table noun because repeating a known object 4 can only be a further modification. However, if the schema table has not appeared before, we consider that the sub-sentence modifies its previous word since a subordinate clause usually comes immediately after the noun it describes.\n\nThere is a high similarity between the app and sub function, but the inspection between the substituted elements is changed to the inspection between the new element and the last element in the original sentence. Therefore, the appended subsentence must modify the same noun as the last sub-sentence. If a compositional element passes the app function, we use the word 'and' or 'or' to connect it where the word 'or' can only connect a WHERE condition. \n\n\nC Spider-SS Annotation Steps\n\nWe build an annotation tool to show the subsentence and sub-SQL split from a question-NatSQL pair. During annotation, the annotators select the corresponding sub-SQL for sub-sentences. In rare cases, if there is no suitable sub-SQL, the annotators would write a new one, such as the example-1 in Figure4. We recruit two graduate students major in computer science to annotate the dataset manually. They are trained with a detailed annotation guideline and some samples. One is allowed to start after his trial samples are approved by the whole team. Each example is annotated twice. If the annotations are different, the final annotation will be decided by a discussion. If two annotators discuss and conclude that one of the annotations is wrong and the other is correct, the correct annotation is retained. Otherwise, the authors will annotate this example if no such conclusion can be drawn.\n\n\nD Execution Match\n\nThe execution match metric measures whether the query results from the predicted query are the same as the gold query results. The original RAT-SQL can not generate the executable SQL until extending the NatSQL. The NatSQL2SQL conversion would analyze the utterance and generate executable SQL, irrelevant to the RATSQL model. Thus we only report the results of models with Nat-SQL. Since the execution match is similar to the exact match, we only report the top models in Table  7. Similar to the exact match, RATSQL G(S) outperform other models in most evaluation set except on the CG-APP T . Spider sentence: Show name for all singers ordered by age from the oldest to the youngest. How many concerts are there in year 2014 or 2015?\n\nGenerate new sentence by appending: Show name for all singers ordered by age from the oldest to the youngest and in year 2014 or 2015?\n\nCoherence checks: Failed to pass the coherence checks due to the modified noun of the two sub-sentences being different. In the same way, the 'Show name for all singers in year 2014 or 2015?' can not pass. Spider sentence: Show name for all singers ordered by age from the oldest to the youngest. What is the nation of the singer who have a song having ' Hey ' in its name?\n\nGenerate new sentence by appending: What is ... who have a song having ' Hey ' in its name and ordered by age from the oldest to the youngest.\n\nCoherence checks: Pass the coherence checks. In the same way, the 'what is ... singer ordered by age from the oldest to the youngest .' also pass. Spider sentence: What are the titles of the books whose writer is not 'Elaine Lee'? List the writers who have written more than one book.\n\nGenerate new sentence by appending: What are the titles of the books whose writer is not 'Elaine Lee' and who have written more than one book.\n\nCoherence checks: Failed to pass the coherence checks due to the modified noun of the two sub-sentences being different. In the same way, the 'What are the titles of the books who have written more than one book.?' can not pass. Spider sentence: List the writers who have written more than one book. Show writers who have published a book with price more than 40.\n\nGenerate new sentence by appending and substituting: List the writers who have written more than one book and who have published a book with price more than 40. List the writers who have written more than one book or who have published a book with price more than 40 . Show writers who have published a book with price more than 40 and who have written more than one book . Show writers who have published a book with price more than 40 or who have written more than one book. List the writers who have written more than one book. Show writers who have written more than one book.\n\nCoherence checks: All these sentence pass the coherence checks.  \n\nFigure 4 :\n4Spider-SS examples in three special cases.\n\nFigure 5 :\n5It is difficult to annotate if using the SQL instead of NatSQL. discussion, we named the Spider-CG subset generated by the sub-sentence substitution method CG-SUB, and the other named CG-APP.InCG-SUB, there are 20,686 examples generated from the Spider-SS training set, while 2,883 examples are generated from the development set. In CG-APP, examples generated from training and development sets are 18,793 and 3,237, respectively. Therefore, the Spider-CG contains 45,599 examples, around six times the Spider dataset. We can further append sub-sentences to the CG-SUB examples if more data is needed.\n\n\nFigure 1. It should be noted that elements in a do-Algorithm 1 Generate CG-SUB and CG-APP dataset in a certain domain Input: e_list All compositional elements in a domain Output: cg_sub and cg_app CG-SUB and CG-APP dataset in a certain domain 1: for Every element 1 in e_list do 2:\n\nFigure 7 :\n7A Spider-SS example is split into two examples for training and evaluation.\n\n\n6 is split to two examples shown in Figure 7.\n\n\u2022\nSpider D : the original Spider development set with 1,034 examples for cross-domain indistribution text-to-SQL evaluation. \u2022 CG-SUB T : the CG-SUB training set, containing 20,686 examples generated from Spider-SS training set by substituting sub-sentences. CG-SUB T can be used for in-domain in-distribution text-to-SQL evaluation. \u2022 CG-SUB D : the CG-SUB development set containing 2,883 examples for cross-domain indistribution text-to-SQL evaluation. \u2022 CG-APP T : the CG-APP training set, containing 18,793 examples generated from Spider-SS training set by appending sub-sentences. CG-APP T can be used for in-domain out-of-distribution 3 text-to-SQL evaluation. \u2022 CG-APP D : the CG-APP development set containing 3,237 examples for cross-domain out-ofdistribution text-to-SQL evaluation. Our evaluation is based on the exact match metric defined in the original Spider benchmark. The exact match metric measures whether the syntax tree of the predicted query without condition values is the same as that of the gold query. All models are only trained on 7000 Spider or Spider-SS training examples. Models. We evaluate the following open-source models that reach competitive performance on Spider: \u2022 GNN: The GNN (Bogin et al., 2019) model using the GLOVE (Pennington et al., 2014) embeddings. \u2022 RATSQL: The RATSQL (Wang et al., 2020) model using the GLOVE embeddings. \u2022 RATSQL B : The RATSQL model using the BERT (Devlin et al., 2019) embeddings. \u2022 RATSQL G : The RATSQL model using the GAP (Shi et al., 2021) embeddings. \u2022 (N) : This subscript indicates that the model use NatSQL instead of SQL. \u2022 (S) : This subscript indicates that the model is modified according to Section 4 and trained on Spider-SS. Besides, since Spider-SS is annotated\n\n\none-sentence description.Yu et al. (2021) sample from the given examples and then give a large number of tables to generate new synthetic examples. Shi et al. (2021) present a model pre-training framework that jointly learns representations of NL utterances and table schemas by leveraging generation models to generate pre-train data. Our proposed Spider-CG dataset can be used for data augmentation.\n\n\nWhat type of pet is the youngest animal, and how much does it weigh? SELECT PetType , Weight FROM Pets ORDER BY Pet_Age LIMIT 1Sentence: \n\nSQL: \n\nWhat type of pet \n\nSubSentence: \n\nSpider Example: \n\nSpider-SS Example: \n\nSELECT Pets.Pettype \n\nNatSQL: \n\n\n\n\nWhat is the name and nation of the singer What are the names of the singers who have a song having 'Hey' in its name?WHERE Concert.Song_Name like '%Hey%'What is the name and nation of the singer who performed in a concert in 2014?SubSentence: \n\nSpider-SS : \n\nSELECT Singer.Name \nSELECT Singer.Country \n\nNatSQL: \n\nSubSentence: \n\nSELECT Singer.Name \n\nNatSQL: \n\nSubSentence: \n\nNatSQL: \n\nExample-1: \n\nwho performed in a concert in 2014? \n\nSubSentence: \n\nWHERE Concert.Year = 2014 \n\nNatSQL: \n\nExample-2: \n\nSentence: \n\nSpider-CG : \n\nSELECT Singer.Name, Singer.Country \nWHERE Concert.Year = 2014 \n\nNatSQL: \n\nSubset-1: sub-sentence substitution in Example 1 and 2 \n2 \n\nWhat is the name and nation of the singer \nwho have a song having 'Hey' in its name and \nwho performed in a concert in 2014? \n\nSentence: \n\nSELECT Singer.Name, Singer.Country \nWHERE Concert.Song_Name like '%Hey%' \nAND Concert.Year = 2014 \n\nNatSQL: \n\n\n\n\nFor the 4 cylinder cars, | which model | has the most horsepower?instead of SQL \nfor annotation, because it is sometimes difficult \nto annotate the sub-sentences with corresponding \n\nFor \n\nthe 4 cylinder cars, \nwhich model \nhas \nthe most horsepower? \n\npobj \n\nrelcl \n\nnsubj \ndobj \n\n\n\n\nList the total number of horses on farms ORDER BY Customers.Email_Address ASCSubSentence: \n\nSpider-SS : \n\nSELECT Customers.Email_Address \nSELECT Customers.Phone_Number \n\nNatSQL: \n\nSubSentence: \n\nSELECT Farm.Total_Horses \n\nNatSQL: \n\nordered by email address \n\nSubSentence: \n\nNatSQL: \n\nExample-1: Use the \"extra\" keyword. \nd \nto compensate for split errors \nd \n\nin ascending order. \n\nSubSentence: \n\nORDER BY Farm.Total_Horses ASC \n\nNatSQL: \n\nExample-2: Columns that are not mentioned in the d \nsub-sentence are specifically annotated \n\nWho advises student 1004? \n\nSubSentence: \n\nSELECT Student.Advisor \nWHERE Student.StuID = 2014 \n\nNatSQL: \n\n\n\n\nWe can think about how to correctly annotate the INTERSECT clause if using the SQL query and tracks with fewer than 70000 seats? AND Track.Seating < 70000SELECT Location FROM Track WHERE seating \n> 90000 \nINTERSECT SELECT Location FROM Track \nWHERE seating < 70000 \n\nSQL: \n\nSpider-SS : \n\nSELECT Track.Location \nWHERE Track. Seating > 90000 \nAND Track.Seating < 70000 \n\nNatSQL: \n\nWhat are the locations \n\nSubSentence: \n\nSELECT Track.Location \n\nNatSQL: \n\nthat have both tracks with more than 90000 \nseats, \n\nSubSentence: \n\nWHERE Track. Seating > 90000 \n\nNatSQL: \n\nSubSentence: \n\nNatSQL: \n\n\n\nTable 1 :\n1One acceptable but not perfect examples in the Spider-CG.\n\n\nWe randomly sampled 2000 examples from the Spider-CG dataset, around 99% of which are acceptable, i.e., they meet the two criteria. The evaluation is conducted manually by a computer science graduate with good knowledge of text-to-SQL. However, these acceptable examples do not mean that there are no grammatical errors and they may be meaningless. We give one acceptable but not perfect examples inTable 1, where the sentence is meaningless because the content it wants to query is the condition it gave. Besides, there are around 5% Nat-SQL queries in these acceptable examples that can not be converted to the correct SQL. This problem can be solved by a well-designed database schema or updating the NatSQL conversion function in the List name of student who is older than tensub-sentence-1:d \n\nList name of student \n\n0 \n1 \n2 \n3 \n4 5 \n6 \n7 \n8 \n\nsub-sentence-2:d \n\nwho is older than ten \n\n\n\nTable 2 :\n2Use exact match and execution match metrics to evaluate the difference between the SQL in Spider and the SQL generated by NatSQL in Spider-SS.Dataset \neasy medium hard \nextra \nSpider D \n24.1% \n43.1% \n16.8% 16.1% \nCG-SUB T 28.6% \n38.0% \n21.1% 12.3% \nCG-SUB D 37.6% \n38.4% \n12.0% 12.0% \nCG-APP T 3.3% \n31.4% \n26.0% 39.3% \nCG-APP D 2.4% \n44.3% \n22.9% 30.4% \n\n\n\nTable 3 :\n3The difficulty distribution of five different evaluation sets.\n\nTable 4 :\n4The similarity between sub-sentences in Spider-SS and Spider-CG generated by the same split algorithm under the deviation of one or two tokens.\n\n\nApproachSpider D CG-SUB T CG-SUB D CG-APP T CG-APP DRATSQL G \n72.7% \n80.9% \n70.3% \n45.2% \n44.2% \nRATSQL G(N) \n73.9% \n90.2% \n75.0% \n67.8% \n60.5% \nRATSQL G(S) \n74.5% \n91.4% \n76.7% \n82.5% \n68.3% \nRATSQL B \n72.0% \n79.5% \n72.0% \n45.1% \n47.2% \nRATSQL B(N) \n72.1% \n83.2% \n69.4% \n54.6% \n53.1% \nRATSQL B(S) \n71.9% \n91.0% \n72.6% \n79.8% \n61.5% \nRATSQL (N) \n63.2% \n79.1% \n60.7% \n40.6% \n34.5% \nRATSQL (S) \n64.7% \n88.8% \n63.3% \n72.1% \n44.1% \nGNN (N) \n54.4% \n67.3% \n57.5% \n30.4% \n25.1% \nGNN (S) \n49.3% \n71.9% \n51.8% \n52.1% \n34.6% \n\n\n\nTable 5 :\n5Exact match accuracy on evaluation sets.\n\nTable 6\n6discuss some examples for ease of understanding. B Unseen SQL Structure Template in Spider-CG Although we limit the complexity of the generated examples lower than the upper bound of the Spider dataset, Spider-CG still contains unseen SQL structure templates. For example, the NatSQL 4 A table is usually an object whose attributes are its columns in relational databases. template 'SELECT COL WHERE COL > VAL or count(TABLE.*) >=VAL GROUP BY COL' and corresponding SQL can not be found in the original Spider. The new templates may degrade the performance of models.\n\nTable 6 :\n6Some examples of successful or unsuccessful passing the coherence checks. Spider D CG-SUB T CG-SUB D CG-APP T CG-APP DApproach \nRATSQL G(N) \n75.8% \n86.7% \n78.0% \n70.4 % \n68.9% \nRATSQL B(S) \n74.7% \n87.9% \n76.4% \n82.0% \n72.5% \nRATSQL G(S) \n76.7% \n88.3% \n80.4% \n78.8% \n75.1% \n\n\n\nTable 7 :\n7Execution match accuracy on evaluation sets.\nOut-of-distribution means that the difficulty distribution is different from the Spider; seeTable 3. Appendix A discusses the removal of overly complex examples to ensure that Spider-CG's SQL does not exceed the complexity upper bound of the Spider.\nAcknowledgementsWe thank the anonymous reviewers for their helpful comments. Matthew Purver acknowledges financial support from the UK EPSRC under grant EP/S033564/1, and from the Slovenian Research Agency for research core funding . Xinyun Chen is supported by the Facebook Fellowship.\nRepresenting schema structure with graph neural networks for text-to-SQL parsing. Ben Bogin, Jonathan Berant, Matt Gardner, 10.18653/v1/P19-1448Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational LinguisticsBen Bogin, Jonathan Berant, and Matt Gardner. 2019. Representing schema structure with graph neural networks for text-to-SQL parsing. In Proceedings of the 57th Annual Meeting of the Association for Com- putational Linguistics, pages 4560-4565, Florence, Italy. Association for Computational Linguistics.\n\nCompositional generalization via neural-symbolic stack machines. Xinyun Chen, Chen Liang, Adams Wei Yu, Dawn Song, Denny Zhou, Advances in Neural Information Processing Systems. Curran Associates, Inc33Xinyun Chen, Chen Liang, Adams Wei Yu, Dawn Song, and Denny Zhou. 2020. Compositional gen- eralization via neural-symbolic stack machines. In Advances in Neural Information Processing Systems, volume 33, pages 1690-1701. Curran Associates, Inc.\n\nMeta-learning to compositionally generalize. Henry Conklin, Bailin Wang, Kenny Smith, Ivan Titov, 10.18653/v1/2021.acl-long.258Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingLong Papers1Henry Conklin, Bailin Wang, Kenny Smith, and Ivan Titov. 2021. Meta-learning to compositionally gen- eralize. In Proceedings of the 59th Annual Meet- ing of the Association for Computational Linguistics and the 11th International Joint Conference on Nat- ural Language Processing (Volume 1: Long Papers), pages 3322-3335, Online. Association for Computa- tional Linguistics.\n\n. Marie-Catherine De Marnee, Christopher D Manning, Stanford typed dependencies manualMarie-Catherine de Marnee and Christopher D. Man- ning. 2016. Stanford typed dependencies manual.\n\nBERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaLong and Short Papers1Association for Computational LinguisticsJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language under- standing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Associ- ation for Computational Linguistics.\n\nImproving text-to-SQL evaluation methodology. Catherine Finegan-Dollak, Jonathan K Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, Dragomir Radev, 10.18653/v1/P18-1033Catherine Finegan-Dollak, Jonathan K. Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, and Dragomir Radev. 2018. Improving text-to-SQL evaluation methodology. pages 351- 360.\n\nCompositional generalization in semantic parsing: Pre-training vs. Daniel Furrer, Nathan Marc Van Zee, Nathanael Scales, Sch\u00e4rli, specialized architectures. CoRR, abs/2007.08970Daniel Furrer, Marc van Zee, Nathan Scales, and Nathanael Sch\u00e4rli. 2020. Compositional generaliza- tion in semantic parsing: Pre-training vs. specialized architectures. CoRR, abs/2007.08970.\n\nExploring underexplored limitations of cross-domain text-to-sql generalization. Yujian Gan, Xinyun Chen, Matthew Purver, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. the 2020 Conference on Empirical Methods in Natural Language ProcessingEMNLPYujian Gan, Xinyun Chen, and Matthew Purver. 2021a. Exploring underexplored limitations of cross-domain text-to-sql generalization. In Proceed- ings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP).\n\nNatural sql: Making sql easier to infer from natural language specifications. Yujian Gan, Xinyun Chen, Jinxia Xie, Matthew Purver, John R Woodward, John Drake, Qiaofu Zhang, Yujian Gan, Xinyun Chen, Jinxia Xie, Matthew Purver, John R. Woodward, John Drake, and Qiaofu Zhang. 2021b. Natural sql: Making sql easier to infer from natural language specifications.\n\nSpanbased semantic parsing for compositional generalization. Jonathan Herzig, Jonathan Berant, 10.18653/v1/2021.acl-long.74Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingLong Papers1Jonathan Herzig and Jonathan Berant. 2021. Span- based semantic parsing for compositional general- ization. In Proceedings of the 59th Annual Meet- ing of the Association for Computational Linguistics and the 11th International Joint Conference on Nat- ural Language Processing (Volume 1: Long Papers), pages 908-921, Online. Association for Computa- tional Linguistics.\n\nLearning the difference that makes a difference with counterfactually-augmented data. Divyansh Kaushik, Eduard Hovy, Zachary Lipton, International Conference on Learning Representations. Divyansh Kaushik, Eduard Hovy, and Zachary Lipton. 2020. Learning the difference that makes a differ- ence with counterfactually-augmented data. In Inter- national Conference on Learning Representations.\n\nGeneralization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. Brenden Lake, Marco Baroni, PMLRProceedings of the 35th International Conference on Machine Learning. the 35th International Conference on Machine Learning80Brenden Lake and Marco Baroni. 2018. Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In Pro- ceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Ma- chine Learning Research, pages 2873-2882. PMLR.\n\nSpatialNLI: A spatial domain natural language interface to databases using spatial comprehension. Jingjing Li, Wenlu Wang, Wei Shinn Ku, Yingtao Tian, Haixun Wang, 10.1145/3347146.3359069GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems. New York, NY, USAAssociation for Computing MachineryJingjing Li, Wenlu Wang, Wei Shinn Ku, Yingtao Tian, and Haixun Wang. 2019. SpatialNLI: A spatial do- main natural language interface to databases using spatial comprehension. In GIS: Proceedings of the ACM International Symposium on Advances in Ge- ographic Information Systems, pages 339-348, New York, NY, USA. Association for Computing Machin- ery.\n\nCompositional generalization by learning analytical expressions. Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao, Bin Zhou, Nanning Zheng, Dongmei Zhang, Advances in Neural Information Processing Systems. Curran Associates, Inc33Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao, Bin Zhou, Nanning Zheng, and Dongmei Zhang. 2020. Compositional gener- alization by learning analytical expressions. In Ad- vances in Neural Information Processing Systems, volume 33, pages 11416-11427. Curran Associates, Inc.\n\nImproving compositional generalization in semantic parsing. Inbar Oren, Jonathan Herzig, Nitish Gupta, Matt Gardner, Jonathan Berant, 10.18653/v1/2020.findings-emnlp.225Findings of the Association for Computational Linguistics: EMNLP 2020. Online. Association for Computational LinguisticsInbar Oren, Jonathan Herzig, Nitish Gupta, Matt Gard- ner, and Jonathan Berant. 2020. Improving compo- sitional generalization in semantic parsing. In Find- ings of the Association for Computational Linguis- tics: EMNLP 2020, pages 2482-2495, Online. As- sociation for Computational Linguistics.\n\nToTTo: A controlled table-totext generation dataset. Ankur Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, Dipanjan Das, 10.18653/v1/2020.emnlp-main.89Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational LinguisticsOnlineAnkur Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, and Dipanjan Das. 2020. ToTTo: A controlled table-to- text generation dataset. In Proceedings of the 2020 Conference on Empirical Methods in Natural Lan- guage Processing (EMNLP), pages 1173-1186, On- line. Association for Computational Linguistics.\n\nGlove: Global vectors for word representation. Jeffrey Pennington, Richard Socher, Christopher Manning, 10.3115/v1/D14-1162Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)Doha, QatarAssociation for Computational LinguisticsJeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word rep- resentation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Process- ing (EMNLP), pages 1532-1543, Doha, Qatar. Asso- ciation for Computational Linguistics.\n\nDistributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, Percy Liang, Shiori Sagawa, Pang Wei Koh, Tatsunori B. Hashimoto, and Percy Liang. 2020. Distributionally robust neu- ral networks for group shifts: On the importance of regularization for worst-case generalization.\n\nCompositional generalization and natural language variation: Can a semantic parsing approach handle both?. Peter Shaw, Ming-Wei Chang, Panupong Pasupat, Kristina Toutanova, 10.18653/v1/2021.acl-long.75Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingOnlineAssociation for Computational Linguistics1Peter Shaw, Ming-Wei Chang, Panupong Pasupat, and Kristina Toutanova. 2021. Compositional general- ization and natural language variation: Can a se- mantic parsing approach handle both? In Proceed- ings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th Interna- tional Joint Conference on Natural Language Pro- cessing (Volume 1: Long Papers), pages 922-938, Online. Association for Computational Linguistics.\n\nCicero Nogueira dos Santos, and Bing Xiang. 2021. Learning contextual representations for semantic parsing with generation-augmented pre-training. Peng Shi, Patrick Ng, Zhiguo Wang, Henghui Zhu, Alexander Hanbo Li, Jun Wang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence35Peng Shi, Patrick Ng, Zhiguo Wang, Henghui Zhu, Alexander Hanbo Li, Jun Wang, Cicero Nogueira dos Santos, and Bing Xiang. 2021. Learn- ing contextual representations for semantic parsing with generation-augmented pre-training. Proceed- ings of the AAAI Conference on Artificial Intelli- gence, 35(15):13806-13814.\n\nExploring unexplored generalization challenges for cross-database semantic parsing. Alane Suhr, Ming-Wei Chang, Peter Shaw, Kenton Lee, 10.18653/v1/2020.acl-main.742Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsAlane Suhr, Ming-Wei Chang, Peter Shaw, and Ken- ton Lee. 2020. Exploring unexplored generalization challenges for cross-database semantic parsing. In Proceedings of the 58th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 8372- 8388, Online. Association for Computational Lin- guistics.\n\nStructured reordering for modeling latent alignments in sequence transduction. Bailin Wang, Mirella Lapata, Ivan Titov, Thirty-Fifth Conference on Neural Information Processing Systems. Bailin Wang, Mirella Lapata, and Ivan Titov. 2021. Structured reordering for modeling latent align- ments in sequence transduction. In Thirty-Fifth Con- ference on Neural Information Processing Systems.\n\nRAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers. Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, Matthew Richardson, 10.18653/v1/2020.acl-main.677Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational LinguisticsBailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and Matthew Richardson. 2020. RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers. In Proceedings of the 58th An- nual Meeting of the Association for Computational Linguistics, pages 7567-7578, Online. Association for Computational Linguistics.\n\nTransferable Natural Language Interface to Structured Queries Aided by Adversarial Generation. Hongvu Xiong, Ruixiao Sun, 10.1109/ICOSC.2019.86654992019 IEEE 13th International Conference on Semantic Computing (ICSC). IEEEHongvu Xiong and Ruixiao Sun. 2019. Transferable Natural Language Interface to Structured Queries Aided by Adversarial Generation. In 2019 IEEE 13th International Conference on Semantic Comput- ing (ICSC), pages 255-262. IEEE.\n\nCompositional generalization for neural semantic parsing via spanlevel supervised attention. Pengcheng Yin, Hao Fang, Graham Neubig, Adam Pauls, Yu Emmanouil Antonios Platanios, Sam Su, Jacob Thomson, Andreas, 10.18653/v1/2021.naacl-main.225Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesAssociation for Computational LinguisticsOnlinePengcheng Yin, Hao Fang, Graham Neubig, Adam Pauls, Emmanouil Antonios Platanios, Yu Su, Sam Thomson, and Jacob Andreas. 2021. Compositional generalization for neural semantic parsing via span- level supervised attention. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Hu- man Language Technologies, pages 2810-2823, On- line. Association for Computational Linguistics.\n\nDragomir Radev, Richard Socher, and Caiming Xiong. 2021. Grappa: Grammar-augmented pre-training for table semantic parsing. Tao Yu, Chien-Sheng Wu, Xi Victoria Lin, Bailin Wang, Yi Chern Tan, Xinyi Yang, Tao Yu, Chien-Sheng Wu, Xi Victoria Lin, Bailin Wang, Yi Chern Tan, Xinyi Yang, Dragomir Radev, Richard Socher, and Caiming Xiong. 2021. Grappa: Grammar-augmented pre-training for table semantic parsing.\n\nSyntaxSQLNet: Syntax tree networks for complex and cross-domain text-to-SQL task. Tao Yu, Michihiro Yasunaga, Kai Yang, Rui Zhang, Dongxu Wang, Zifan Li, Dragomir Radev, 10.18653/v1/D18-1193Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational LinguisticsTao Yu, Michihiro Yasunaga, Kai Yang, Rui Zhang, Dongxu Wang, Zifan Li, and Dragomir Radev. 2018a. SyntaxSQLNet: Syntax tree networks for complex and cross-domain text-to-SQL task. In Pro- ceedings of the 2018 Conference on Empirical Meth- ods in Natural Language Processing, pages 1653- 1663, Brussels, Belgium. Association for Computa- tional Linguistics.\n\nSpider: A largescale human-labeled dataset for complex and crossdomain semantic parsing and text-to-SQL task. Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, Dragomir Radev, 10.18653/v1/D18-1425Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational LinguisticsTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, and Dragomir Radev. 2018b. Spider: A large- scale human-labeled dataset for complex and cross- domain semantic parsing and text-to-SQL task. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3911-3921, Brussels, Belgium. Association for Computational Linguistics.\n", "annotations": {"author": "[{\"end\":157,\"start\":95},{\"end\":205,\"start\":158},{\"end\":242,\"start\":206},{\"end\":337,\"start\":243}]", "publisher": null, "author_last_name": "[{\"end\":105,\"start\":102},{\"end\":169,\"start\":165},{\"end\":219,\"start\":214},{\"end\":257,\"start\":251}]", "author_first_name": "[{\"end\":101,\"start\":95},{\"end\":164,\"start\":158},{\"end\":213,\"start\":206},{\"end\":250,\"start\":243}]", "author_affiliation": "[{\"end\":156,\"start\":124},{\"end\":204,\"start\":196},{\"end\":311,\"start\":279},{\"end\":336,\"start\":313}]", "title": "[{\"end\":92,\"start\":1},{\"end\":429,\"start\":338}]", "venue": null, "abstract": "[{\"end\":1623,\"start\":489}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b5\"},\"end\":1867,\"start\":1838},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":1885,\"start\":1867},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":1906,\"start\":1885},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":1926,\"start\":1906},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2062,\"start\":2039},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2564,\"start\":2546},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2690,\"start\":2662},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3123,\"start\":3106},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3152,\"start\":3128},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3876,\"start\":3858},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":4005,\"start\":3987},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4690,\"start\":4671},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7378,\"start\":7359},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8747,\"start\":8718},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":16522,\"start\":16504},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16546,\"start\":16522},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":17674,\"start\":17656},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18722,\"start\":18703},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19265,\"start\":19246},{\"end\":19662,\"start\":19645},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19680,\"start\":19662},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23806,\"start\":23787},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":24568,\"start\":24547},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":24584,\"start\":24568},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24645,\"start\":24628},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":24755,\"start\":24735},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":25104,\"start\":25075},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":25122,\"start\":25104},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25142,\"start\":25122},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25163,\"start\":25142},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":25355,\"start\":25336},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":25373,\"start\":25355},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":25412,\"start\":25394},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":26646,\"start\":26629},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":26783,\"start\":26759},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":38552,\"start\":38536}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":35720,\"start\":35665},{\"attributes\":{\"id\":\"fig_1\"},\"end\":36336,\"start\":35721},{\"attributes\":{\"id\":\"fig_2\"},\"end\":36620,\"start\":36337},{\"attributes\":{\"id\":\"fig_3\"},\"end\":36709,\"start\":36621},{\"attributes\":{\"id\":\"fig_4\"},\"end\":36757,\"start\":36710},{\"attributes\":{\"id\":\"fig_5\"},\"end\":38508,\"start\":36758},{\"attributes\":{\"id\":\"fig_6\"},\"end\":38912,\"start\":38509},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":39166,\"start\":38913},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40079,\"start\":39167},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":40363,\"start\":40080},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41006,\"start\":40364},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":41596,\"start\":41007},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":41666,\"start\":41597},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":42561,\"start\":41667},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":42930,\"start\":42562},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":43005,\"start\":42931},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":43161,\"start\":43006},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":43681,\"start\":43162},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":43734,\"start\":43682},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":44312,\"start\":43735},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":44599,\"start\":44313},{\"attributes\":{\"id\":\"tab_17\",\"type\":\"table\"},\"end\":44656,\"start\":44600}]", "paragraph": "[{\"end\":2446,\"start\":1639},{\"end\":3008,\"start\":2448},{\"end\":3877,\"start\":3010},{\"end\":4254,\"start\":3879},{\"end\":4268,\"start\":4256},{\"end\":4298,\"start\":4291},{\"end\":4335,\"start\":4300},{\"end\":4552,\"start\":4337},{\"end\":5085,\"start\":4554},{\"end\":6078,\"start\":5087},{\"end\":6452,\"start\":6080},{\"end\":6673,\"start\":6454},{\"end\":6875,\"start\":6675},{\"end\":6997,\"start\":6877},{\"end\":7123,\"start\":6999},{\"end\":7480,\"start\":7125},{\"end\":8407,\"start\":7482},{\"end\":9274,\"start\":8436},{\"end\":9508,\"start\":9276},{\"end\":9831,\"start\":9525},{\"end\":11020,\"start\":9833},{\"end\":11723,\"start\":11040},{\"end\":11995,\"start\":11725},{\"end\":12918,\"start\":11997},{\"end\":13352,\"start\":12943},{\"end\":13416,\"start\":13366},{\"end\":14218,\"start\":13441},{\"end\":14253,\"start\":14220},{\"end\":14311,\"start\":14255},{\"end\":14386,\"start\":14313},{\"end\":14433,\"start\":14388},{\"end\":14527,\"start\":14435},{\"end\":14877,\"start\":14529},{\"end\":15294,\"start\":14900},{\"end\":15355,\"start\":15339},{\"end\":15474,\"start\":15357},{\"end\":15483,\"start\":15476},{\"end\":16877,\"start\":15493},{\"end\":17535,\"start\":16879},{\"end\":17997,\"start\":17571},{\"end\":18501,\"start\":17999},{\"end\":19351,\"start\":18522},{\"end\":19984,\"start\":19353},{\"end\":20282,\"start\":19986},{\"end\":23386,\"start\":20322},{\"end\":24001,\"start\":23404},{\"end\":24421,\"start\":24029},{\"end\":25593,\"start\":24438},{\"end\":26514,\"start\":25595},{\"end\":27411,\"start\":26516},{\"end\":28078,\"start\":27426},{\"end\":28115,\"start\":28080},{\"end\":28956,\"start\":28117},{\"end\":29272,\"start\":28958},{\"end\":29865,\"start\":29274},{\"end\":30385,\"start\":29867},{\"end\":31426,\"start\":30387},{\"end\":31881,\"start\":31428},{\"end\":32808,\"start\":31914},{\"end\":33565,\"start\":32830},{\"end\":33701,\"start\":33567},{\"end\":34076,\"start\":33703},{\"end\":34220,\"start\":34078},{\"end\":34506,\"start\":34222},{\"end\":34650,\"start\":34508},{\"end\":35015,\"start\":34652},{\"end\":35597,\"start\":35017},{\"end\":35664,\"start\":35599}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15338,\"start\":15295}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":18540,\"start\":18533},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":19371,\"start\":19364},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":19710,\"start\":19703},{\"attributes\":{\"ref_id\":\"tab_12\"},\"end\":20948,\"start\":20941},{\"attributes\":{\"ref_id\":\"tab_14\"},\"end\":21914,\"start\":21907},{\"end\":24935,\"start\":24871},{\"attributes\":{\"ref_id\":\"tab_17\"},\"end\":33311,\"start\":33303}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1637,\"start\":1625},{\"end\":4289,\"start\":4271},{\"attributes\":{\"n\":\"2.2\"},\"end\":8434,\"start\":8410},{\"end\":9523,\"start\":9511},{\"attributes\":{\"n\":\"2.3\"},\"end\":11038,\"start\":11023},{\"attributes\":{\"n\":\"3\"},\"end\":12930,\"start\":12921},{\"attributes\":{\"n\":\"3.1\"},\"end\":12941,\"start\":12933},{\"end\":13364,\"start\":13355},{\"attributes\":{\"n\":\"3.2\"},\"end\":13439,\"start\":13419},{\"attributes\":{\"n\":\"3.3\"},\"end\":14898,\"start\":14880},{\"attributes\":{\"n\":\"4\"},\"end\":15491,\"start\":15486},{\"attributes\":{\"n\":\"5\"},\"end\":17548,\"start\":17538},{\"attributes\":{\"n\":\"5.1\"},\"end\":17569,\"start\":17551},{\"attributes\":{\"n\":\"5.2\"},\"end\":18520,\"start\":18504},{\"attributes\":{\"n\":\"5.3\"},\"end\":20320,\"start\":20285},{\"attributes\":{\"n\":\"5.4\"},\"end\":23402,\"start\":23389},{\"attributes\":{\"n\":\"6\"},\"end\":24027,\"start\":24004},{\"attributes\":{\"n\":\"7\"},\"end\":24436,\"start\":24424},{\"attributes\":{\"n\":\"8\"},\"end\":27424,\"start\":27414},{\"end\":31912,\"start\":31884},{\"end\":32828,\"start\":32811},{\"end\":35676,\"start\":35666},{\"end\":35732,\"start\":35722},{\"end\":36632,\"start\":36622},{\"end\":36760,\"start\":36759},{\"end\":41607,\"start\":41598},{\"end\":42572,\"start\":42563},{\"end\":42941,\"start\":42932},{\"end\":43016,\"start\":43007},{\"end\":43692,\"start\":43683},{\"end\":43743,\"start\":43736},{\"end\":44323,\"start\":44314},{\"end\":44610,\"start\":44601}]", "table": "[{\"end\":39166,\"start\":39042},{\"end\":40079,\"start\":39399},{\"end\":40363,\"start\":40147},{\"end\":41006,\"start\":40443},{\"end\":41596,\"start\":41163},{\"end\":42561,\"start\":42449},{\"end\":42930,\"start\":42716},{\"end\":43681,\"start\":43216},{\"end\":44599,\"start\":44443}]", "figure_caption": "[{\"end\":35720,\"start\":35678},{\"end\":36336,\"start\":35734},{\"end\":36620,\"start\":36339},{\"end\":36709,\"start\":36634},{\"end\":36757,\"start\":36712},{\"end\":38508,\"start\":36761},{\"end\":38912,\"start\":38511},{\"end\":39042,\"start\":38915},{\"end\":39399,\"start\":39169},{\"end\":40147,\"start\":40082},{\"end\":40443,\"start\":40366},{\"end\":41163,\"start\":41009},{\"end\":41666,\"start\":41609},{\"end\":42449,\"start\":41669},{\"end\":42716,\"start\":42574},{\"end\":43005,\"start\":42943},{\"end\":43161,\"start\":43018},{\"end\":43216,\"start\":43164},{\"end\":43734,\"start\":43694},{\"end\":44312,\"start\":43745},{\"end\":44443,\"start\":44325},{\"end\":44656,\"start\":44612}]", "figure_ref": "[{\"end\":3464,\"start\":3456},{\"end\":4015,\"start\":4007},{\"end\":4383,\"start\":4375},{\"end\":5477,\"start\":5469},{\"end\":6289,\"start\":6281},{\"end\":7158,\"start\":7150},{\"end\":7387,\"start\":7379},{\"end\":8846,\"start\":8838},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9076,\"start\":9068},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10082,\"start\":10074},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11448,\"start\":11440},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12413,\"start\":12405},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12741,\"start\":12733},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14124,\"start\":14116},{\"end\":15396,\"start\":15388},{\"end\":15897,\"start\":15889},{\"end\":16157,\"start\":16149},{\"end\":17079,\"start\":17073},{\"end\":17354,\"start\":17345},{\"end\":20752,\"start\":20744},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":28576,\"start\":28568},{\"end\":28750,\"start\":28742}]", "bib_author_first_name": "[{\"end\":45279,\"start\":45276},{\"end\":45295,\"start\":45287},{\"end\":45308,\"start\":45304},{\"end\":45932,\"start\":45926},{\"end\":45943,\"start\":45939},{\"end\":45956,\"start\":45951},{\"end\":45960,\"start\":45957},{\"end\":45969,\"start\":45965},{\"end\":45981,\"start\":45976},{\"end\":46359,\"start\":46354},{\"end\":46375,\"start\":46369},{\"end\":46387,\"start\":46382},{\"end\":46399,\"start\":46395},{\"end\":47152,\"start\":47137},{\"end\":47175,\"start\":47164},{\"end\":47177,\"start\":47176},{\"end\":47407,\"start\":47402},{\"end\":47424,\"start\":47416},{\"end\":47438,\"start\":47432},{\"end\":47452,\"start\":47444},{\"end\":48319,\"start\":48310},{\"end\":48344,\"start\":48336},{\"end\":48346,\"start\":48345},{\"end\":48361,\"start\":48359},{\"end\":48376,\"start\":48369},{\"end\":48393,\"start\":48389},{\"end\":48408,\"start\":48405},{\"end\":48424,\"start\":48416},{\"end\":48721,\"start\":48715},{\"end\":48736,\"start\":48730},{\"end\":48760,\"start\":48751},{\"end\":49103,\"start\":49097},{\"end\":49115,\"start\":49109},{\"end\":49129,\"start\":49122},{\"end\":49620,\"start\":49614},{\"end\":49632,\"start\":49626},{\"end\":49645,\"start\":49639},{\"end\":49658,\"start\":49651},{\"end\":49671,\"start\":49667},{\"end\":49673,\"start\":49672},{\"end\":49688,\"start\":49684},{\"end\":49702,\"start\":49696},{\"end\":49966,\"start\":49958},{\"end\":49983,\"start\":49975},{\"end\":50809,\"start\":50801},{\"end\":50825,\"start\":50819},{\"end\":50839,\"start\":50832},{\"end\":51224,\"start\":51217},{\"end\":51236,\"start\":51231},{\"end\":51783,\"start\":51775},{\"end\":51793,\"start\":51788},{\"end\":51803,\"start\":51800},{\"end\":51809,\"start\":51804},{\"end\":51821,\"start\":51814},{\"end\":51834,\"start\":51828},{\"end\":52438,\"start\":52434},{\"end\":52452,\"start\":52444},{\"end\":52467,\"start\":52457},{\"end\":52476,\"start\":52473},{\"end\":52487,\"start\":52483},{\"end\":52496,\"start\":52493},{\"end\":52505,\"start\":52502},{\"end\":52519,\"start\":52512},{\"end\":52534,\"start\":52527},{\"end\":52978,\"start\":52973},{\"end\":52993,\"start\":52985},{\"end\":53008,\"start\":53002},{\"end\":53020,\"start\":53016},{\"end\":53038,\"start\":53030},{\"end\":53557,\"start\":53552},{\"end\":53572,\"start\":53566},{\"end\":53588,\"start\":53579},{\"end\":53605,\"start\":53599},{\"end\":53621,\"start\":53615},{\"end\":53635,\"start\":53631},{\"end\":53650,\"start\":53642},{\"end\":54303,\"start\":54296},{\"end\":54323,\"start\":54316},{\"end\":54343,\"start\":54332},{\"end\":55023,\"start\":55017},{\"end\":55036,\"start\":55032},{\"end\":55055,\"start\":55046},{\"end\":55057,\"start\":55056},{\"end\":55074,\"start\":55069},{\"end\":55398,\"start\":55393},{\"end\":55413,\"start\":55405},{\"end\":55429,\"start\":55421},{\"end\":55447,\"start\":55439},{\"end\":56447,\"start\":56443},{\"end\":56460,\"start\":56453},{\"end\":56471,\"start\":56465},{\"end\":56485,\"start\":56478},{\"end\":56500,\"start\":56491},{\"end\":56506,\"start\":56501},{\"end\":56514,\"start\":56511},{\"end\":57036,\"start\":57031},{\"end\":57051,\"start\":57043},{\"end\":57064,\"start\":57059},{\"end\":57077,\"start\":57071},{\"end\":57672,\"start\":57666},{\"end\":57686,\"start\":57679},{\"end\":57699,\"start\":57695},{\"end\":58060,\"start\":58054},{\"end\":58074,\"start\":58067},{\"end\":58089,\"start\":58081},{\"end\":58104,\"start\":58095},{\"end\":58121,\"start\":58114},{\"end\":58804,\"start\":58798},{\"end\":58819,\"start\":58812},{\"end\":59255,\"start\":59246},{\"end\":59264,\"start\":59261},{\"end\":59277,\"start\":59271},{\"end\":59290,\"start\":59286},{\"end\":59300,\"start\":59298},{\"end\":59334,\"start\":59331},{\"end\":59344,\"start\":59339},{\"end\":60281,\"start\":60278},{\"end\":60297,\"start\":60286},{\"end\":60304,\"start\":60302},{\"end\":60325,\"start\":60319},{\"end\":60334,\"start\":60332},{\"end\":60351,\"start\":60346},{\"end\":60648,\"start\":60645},{\"end\":60662,\"start\":60653},{\"end\":60676,\"start\":60673},{\"end\":60686,\"start\":60683},{\"end\":60700,\"start\":60694},{\"end\":60712,\"start\":60707},{\"end\":60725,\"start\":60717},{\"end\":61442,\"start\":61439},{\"end\":61450,\"start\":61447},{\"end\":61461,\"start\":61458},{\"end\":61477,\"start\":61468},{\"end\":61494,\"start\":61488},{\"end\":61506,\"start\":61501},{\"end\":61516,\"start\":61511},{\"end\":61526,\"start\":61521},{\"end\":61539,\"start\":61531},{\"end\":61553,\"start\":61545},{\"end\":61566,\"start\":61561},{\"end\":61582,\"start\":61574}]", "bib_author_last_name": "[{\"end\":45285,\"start\":45280},{\"end\":45302,\"start\":45296},{\"end\":45316,\"start\":45309},{\"end\":45937,\"start\":45933},{\"end\":45949,\"start\":45944},{\"end\":45963,\"start\":45961},{\"end\":45974,\"start\":45970},{\"end\":45986,\"start\":45982},{\"end\":46367,\"start\":46360},{\"end\":46380,\"start\":46376},{\"end\":46393,\"start\":46388},{\"end\":46405,\"start\":46400},{\"end\":47162,\"start\":47153},{\"end\":47185,\"start\":47178},{\"end\":47414,\"start\":47408},{\"end\":47430,\"start\":47425},{\"end\":47442,\"start\":47439},{\"end\":47462,\"start\":47453},{\"end\":48334,\"start\":48320},{\"end\":48357,\"start\":48347},{\"end\":48367,\"start\":48362},{\"end\":48387,\"start\":48377},{\"end\":48403,\"start\":48394},{\"end\":48414,\"start\":48409},{\"end\":48430,\"start\":48425},{\"end\":48728,\"start\":48722},{\"end\":48749,\"start\":48737},{\"end\":48767,\"start\":48761},{\"end\":48776,\"start\":48769},{\"end\":49107,\"start\":49104},{\"end\":49120,\"start\":49116},{\"end\":49136,\"start\":49130},{\"end\":49624,\"start\":49621},{\"end\":49637,\"start\":49633},{\"end\":49649,\"start\":49646},{\"end\":49665,\"start\":49659},{\"end\":49682,\"start\":49674},{\"end\":49694,\"start\":49689},{\"end\":49708,\"start\":49703},{\"end\":49973,\"start\":49967},{\"end\":49990,\"start\":49984},{\"end\":50817,\"start\":50810},{\"end\":50830,\"start\":50826},{\"end\":50846,\"start\":50840},{\"end\":51229,\"start\":51225},{\"end\":51243,\"start\":51237},{\"end\":51786,\"start\":51784},{\"end\":51798,\"start\":51794},{\"end\":51812,\"start\":51810},{\"end\":51826,\"start\":51822},{\"end\":51839,\"start\":51835},{\"end\":52442,\"start\":52439},{\"end\":52455,\"start\":52453},{\"end\":52471,\"start\":52468},{\"end\":52481,\"start\":52477},{\"end\":52491,\"start\":52488},{\"end\":52500,\"start\":52497},{\"end\":52510,\"start\":52506},{\"end\":52525,\"start\":52520},{\"end\":52540,\"start\":52535},{\"end\":52983,\"start\":52979},{\"end\":53000,\"start\":52994},{\"end\":53014,\"start\":53009},{\"end\":53028,\"start\":53021},{\"end\":53045,\"start\":53039},{\"end\":53564,\"start\":53558},{\"end\":53577,\"start\":53573},{\"end\":53597,\"start\":53589},{\"end\":53613,\"start\":53606},{\"end\":53629,\"start\":53622},{\"end\":53640,\"start\":53636},{\"end\":53654,\"start\":53651},{\"end\":54314,\"start\":54304},{\"end\":54330,\"start\":54324},{\"end\":54351,\"start\":54344},{\"end\":55030,\"start\":55024},{\"end\":55044,\"start\":55037},{\"end\":55067,\"start\":55058},{\"end\":55080,\"start\":55075},{\"end\":55403,\"start\":55399},{\"end\":55419,\"start\":55414},{\"end\":55437,\"start\":55430},{\"end\":55457,\"start\":55448},{\"end\":56451,\"start\":56448},{\"end\":56463,\"start\":56461},{\"end\":56476,\"start\":56472},{\"end\":56489,\"start\":56486},{\"end\":56509,\"start\":56507},{\"end\":56519,\"start\":56515},{\"end\":57041,\"start\":57037},{\"end\":57057,\"start\":57052},{\"end\":57069,\"start\":57065},{\"end\":57081,\"start\":57078},{\"end\":57677,\"start\":57673},{\"end\":57693,\"start\":57687},{\"end\":57705,\"start\":57700},{\"end\":58065,\"start\":58061},{\"end\":58079,\"start\":58075},{\"end\":58093,\"start\":58090},{\"end\":58112,\"start\":58105},{\"end\":58132,\"start\":58122},{\"end\":58810,\"start\":58805},{\"end\":58823,\"start\":58820},{\"end\":59259,\"start\":59256},{\"end\":59269,\"start\":59265},{\"end\":59284,\"start\":59278},{\"end\":59296,\"start\":59291},{\"end\":59329,\"start\":59301},{\"end\":59337,\"start\":59335},{\"end\":59352,\"start\":59345},{\"end\":59361,\"start\":59354},{\"end\":60284,\"start\":60282},{\"end\":60300,\"start\":60298},{\"end\":60317,\"start\":60305},{\"end\":60330,\"start\":60326},{\"end\":60344,\"start\":60335},{\"end\":60356,\"start\":60352},{\"end\":60651,\"start\":60649},{\"end\":60671,\"start\":60663},{\"end\":60681,\"start\":60677},{\"end\":60692,\"start\":60687},{\"end\":60705,\"start\":60701},{\"end\":60715,\"start\":60713},{\"end\":60731,\"start\":60726},{\"end\":61445,\"start\":61443},{\"end\":61456,\"start\":61451},{\"end\":61466,\"start\":61462},{\"end\":61486,\"start\":61478},{\"end\":61499,\"start\":61495},{\"end\":61509,\"start\":61507},{\"end\":61519,\"start\":61517},{\"end\":61529,\"start\":61527},{\"end\":61543,\"start\":61540},{\"end\":61559,\"start\":61554},{\"end\":61572,\"start\":61567},{\"end\":61588,\"start\":61583}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.18653/v1/P19-1448\",\"id\":\"b0\",\"matched_paper_id\":155092736},\"end\":45859,\"start\":45194},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":221139844},\"end\":46307,\"start\":45861},{\"attributes\":{\"doi\":\"10.18653/v1/2021.acl-long.258\",\"id\":\"b2\",\"matched_paper_id\":235367710},\"end\":47133,\"start\":46309},{\"attributes\":{\"id\":\"b3\"},\"end\":47318,\"start\":47135},{\"attributes\":{\"doi\":\"10.18653/v1/N19-1423\",\"id\":\"b4\",\"matched_paper_id\":52967399},\"end\":48262,\"start\":47320},{\"attributes\":{\"doi\":\"10.18653/v1/P18-1033\",\"id\":\"b5\"},\"end\":48646,\"start\":48264},{\"attributes\":{\"id\":\"b6\"},\"end\":49015,\"start\":48648},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":237491444},\"end\":49534,\"start\":49017},{\"attributes\":{\"id\":\"b8\"},\"end\":49895,\"start\":49536},{\"attributes\":{\"doi\":\"10.18653/v1/2021.acl-long.74\",\"id\":\"b9\",\"matched_paper_id\":221655744},\"end\":50713,\"start\":49897},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":203591519},\"end\":51105,\"start\":50715},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b11\",\"matched_paper_id\":46761158},\"end\":51675,\"start\":51107},{\"attributes\":{\"doi\":\"10.1145/3347146.3359069\",\"id\":\"b12\",\"matched_paper_id\":201671304},\"end\":52367,\"start\":51677},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":219792319},\"end\":52911,\"start\":52369},{\"attributes\":{\"doi\":\"10.18653/v1/2020.findings-emnlp.225\",\"id\":\"b14\",\"matched_paper_id\":222291650},\"end\":53497,\"start\":52913},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.89\",\"id\":\"b15\",\"matched_paper_id\":216641852},\"end\":54247,\"start\":53499},{\"attributes\":{\"doi\":\"10.3115/v1/D14-1162\",\"id\":\"b16\",\"matched_paper_id\":1957433},\"end\":54890,\"start\":54249},{\"attributes\":{\"id\":\"b17\"},\"end\":55284,\"start\":54892},{\"attributes\":{\"doi\":\"10.18653/v1/2021.acl-long.75\",\"id\":\"b18\",\"matched_paper_id\":225066984},\"end\":56294,\"start\":55286},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":229331741},\"end\":56945,\"start\":56296},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.742\",\"id\":\"b20\",\"matched_paper_id\":220047209},\"end\":57585,\"start\":56947},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":235358760},\"end\":57975,\"start\":57587},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.677\",\"id\":\"b22\",\"matched_paper_id\":207863446},\"end\":58701,\"start\":57977},{\"attributes\":{\"doi\":\"10.1109/ICOSC.2019.8665499\",\"id\":\"b23\",\"matched_paper_id\":54445709},\"end\":59151,\"start\":58703},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.225\",\"id\":\"b24\",\"matched_paper_id\":235097473},\"end\":60152,\"start\":59153},{\"attributes\":{\"id\":\"b25\"},\"end\":60561,\"start\":60154},{\"attributes\":{\"doi\":\"10.18653/v1/D18-1193\",\"id\":\"b26\",\"matched_paper_id\":52979524},\"end\":61327,\"start\":60563},{\"attributes\":{\"doi\":\"10.18653/v1/D18-1425\",\"id\":\"b27\",\"matched_paper_id\":52815560},\"end\":62272,\"start\":61329}]", "bib_title": "[{\"end\":45274,\"start\":45194},{\"end\":45924,\"start\":45861},{\"end\":46352,\"start\":46309},{\"end\":47400,\"start\":47320},{\"end\":49095,\"start\":49017},{\"end\":49956,\"start\":49897},{\"end\":50799,\"start\":50715},{\"end\":51215,\"start\":51107},{\"end\":51773,\"start\":51677},{\"end\":52432,\"start\":52369},{\"end\":52971,\"start\":52913},{\"end\":53550,\"start\":53499},{\"end\":54294,\"start\":54249},{\"end\":55391,\"start\":55286},{\"end\":56441,\"start\":56296},{\"end\":57029,\"start\":56947},{\"end\":57664,\"start\":57587},{\"end\":58052,\"start\":57977},{\"end\":58796,\"start\":58703},{\"end\":59244,\"start\":59153},{\"end\":60643,\"start\":60563},{\"end\":61437,\"start\":61329}]", "bib_author": "[{\"end\":45287,\"start\":45276},{\"end\":45304,\"start\":45287},{\"end\":45318,\"start\":45304},{\"end\":45939,\"start\":45926},{\"end\":45951,\"start\":45939},{\"end\":45965,\"start\":45951},{\"end\":45976,\"start\":45965},{\"end\":45988,\"start\":45976},{\"end\":46369,\"start\":46354},{\"end\":46382,\"start\":46369},{\"end\":46395,\"start\":46382},{\"end\":46407,\"start\":46395},{\"end\":47164,\"start\":47137},{\"end\":47187,\"start\":47164},{\"end\":47416,\"start\":47402},{\"end\":47432,\"start\":47416},{\"end\":47444,\"start\":47432},{\"end\":47464,\"start\":47444},{\"end\":48336,\"start\":48310},{\"end\":48359,\"start\":48336},{\"end\":48369,\"start\":48359},{\"end\":48389,\"start\":48369},{\"end\":48405,\"start\":48389},{\"end\":48416,\"start\":48405},{\"end\":48432,\"start\":48416},{\"end\":48730,\"start\":48715},{\"end\":48751,\"start\":48730},{\"end\":48769,\"start\":48751},{\"end\":48778,\"start\":48769},{\"end\":49109,\"start\":49097},{\"end\":49122,\"start\":49109},{\"end\":49138,\"start\":49122},{\"end\":49626,\"start\":49614},{\"end\":49639,\"start\":49626},{\"end\":49651,\"start\":49639},{\"end\":49667,\"start\":49651},{\"end\":49684,\"start\":49667},{\"end\":49696,\"start\":49684},{\"end\":49710,\"start\":49696},{\"end\":49975,\"start\":49958},{\"end\":49992,\"start\":49975},{\"end\":50819,\"start\":50801},{\"end\":50832,\"start\":50819},{\"end\":50848,\"start\":50832},{\"end\":51231,\"start\":51217},{\"end\":51245,\"start\":51231},{\"end\":51788,\"start\":51775},{\"end\":51800,\"start\":51788},{\"end\":51814,\"start\":51800},{\"end\":51828,\"start\":51814},{\"end\":51841,\"start\":51828},{\"end\":52444,\"start\":52434},{\"end\":52457,\"start\":52444},{\"end\":52473,\"start\":52457},{\"end\":52483,\"start\":52473},{\"end\":52493,\"start\":52483},{\"end\":52502,\"start\":52493},{\"end\":52512,\"start\":52502},{\"end\":52527,\"start\":52512},{\"end\":52542,\"start\":52527},{\"end\":52985,\"start\":52973},{\"end\":53002,\"start\":52985},{\"end\":53016,\"start\":53002},{\"end\":53030,\"start\":53016},{\"end\":53047,\"start\":53030},{\"end\":53566,\"start\":53552},{\"end\":53579,\"start\":53566},{\"end\":53599,\"start\":53579},{\"end\":53615,\"start\":53599},{\"end\":53631,\"start\":53615},{\"end\":53642,\"start\":53631},{\"end\":53656,\"start\":53642},{\"end\":54316,\"start\":54296},{\"end\":54332,\"start\":54316},{\"end\":54353,\"start\":54332},{\"end\":55032,\"start\":55017},{\"end\":55046,\"start\":55032},{\"end\":55069,\"start\":55046},{\"end\":55082,\"start\":55069},{\"end\":55405,\"start\":55393},{\"end\":55421,\"start\":55405},{\"end\":55439,\"start\":55421},{\"end\":55459,\"start\":55439},{\"end\":56453,\"start\":56443},{\"end\":56465,\"start\":56453},{\"end\":56478,\"start\":56465},{\"end\":56491,\"start\":56478},{\"end\":56511,\"start\":56491},{\"end\":56521,\"start\":56511},{\"end\":57043,\"start\":57031},{\"end\":57059,\"start\":57043},{\"end\":57071,\"start\":57059},{\"end\":57083,\"start\":57071},{\"end\":57679,\"start\":57666},{\"end\":57695,\"start\":57679},{\"end\":57707,\"start\":57695},{\"end\":58067,\"start\":58054},{\"end\":58081,\"start\":58067},{\"end\":58095,\"start\":58081},{\"end\":58114,\"start\":58095},{\"end\":58134,\"start\":58114},{\"end\":58812,\"start\":58798},{\"end\":58825,\"start\":58812},{\"end\":59261,\"start\":59246},{\"end\":59271,\"start\":59261},{\"end\":59286,\"start\":59271},{\"end\":59298,\"start\":59286},{\"end\":59331,\"start\":59298},{\"end\":59339,\"start\":59331},{\"end\":59354,\"start\":59339},{\"end\":59363,\"start\":59354},{\"end\":60286,\"start\":60278},{\"end\":60302,\"start\":60286},{\"end\":60319,\"start\":60302},{\"end\":60332,\"start\":60319},{\"end\":60346,\"start\":60332},{\"end\":60358,\"start\":60346},{\"end\":60653,\"start\":60645},{\"end\":60673,\"start\":60653},{\"end\":60683,\"start\":60673},{\"end\":60694,\"start\":60683},{\"end\":60707,\"start\":60694},{\"end\":60717,\"start\":60707},{\"end\":60733,\"start\":60717},{\"end\":61447,\"start\":61439},{\"end\":61458,\"start\":61447},{\"end\":61468,\"start\":61458},{\"end\":61488,\"start\":61468},{\"end\":61501,\"start\":61488},{\"end\":61511,\"start\":61501},{\"end\":61521,\"start\":61511},{\"end\":61531,\"start\":61521},{\"end\":61545,\"start\":61531},{\"end\":61561,\"start\":61545},{\"end\":61574,\"start\":61561},{\"end\":61590,\"start\":61574}]", "bib_venue": "[{\"end\":45425,\"start\":45338},{\"end\":46037,\"start\":45988},{\"end\":46598,\"start\":46436},{\"end\":47626,\"start\":47484},{\"end\":48308,\"start\":48264},{\"end\":48713,\"start\":48648},{\"end\":49224,\"start\":49138},{\"end\":49612,\"start\":49536},{\"end\":50182,\"start\":50020},{\"end\":50900,\"start\":50848},{\"end\":51317,\"start\":51249},{\"end\":51961,\"start\":51864},{\"end\":52591,\"start\":52542},{\"end\":53151,\"start\":53082},{\"end\":53780,\"start\":53686},{\"end\":54466,\"start\":54372},{\"end\":55015,\"start\":54892},{\"end\":55649,\"start\":55487},{\"end\":56582,\"start\":56521},{\"end\":57199,\"start\":57112},{\"end\":57771,\"start\":57707},{\"end\":58250,\"start\":58163},{\"end\":58919,\"start\":58851},{\"end\":59536,\"start\":59394},{\"end\":60276,\"start\":60154},{\"end\":60839,\"start\":60753},{\"end\":61696,\"start\":61610},{\"end\":45514,\"start\":45427},{\"end\":46747,\"start\":46600},{\"end\":47777,\"start\":47628},{\"end\":49297,\"start\":49226},{\"end\":50331,\"start\":50184},{\"end\":51372,\"start\":51319},{\"end\":51980,\"start\":51963},{\"end\":53861,\"start\":53782},{\"end\":54558,\"start\":54468},{\"end\":55804,\"start\":55651},{\"end\":56630,\"start\":56584},{\"end\":57273,\"start\":57201},{\"end\":58324,\"start\":58252},{\"end\":59665,\"start\":59538},{\"end\":60929,\"start\":60841},{\"end\":61786,\"start\":61698}]"}}}, "year": 2023, "month": 12, "day": 17}