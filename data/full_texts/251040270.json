{"id": 251040270, "updated": "2023-10-05 12:11:13.596", "metadata": {"title": "Behind Every Domain There is a Shift: Adapting Distortion-aware Vision Transformers for Panoramic Semantic Segmentation", "authors": "[{\"first\":\"Jiaming\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Kailun\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Hao\",\"last\":\"Shi\",\"middle\":[]},{\"first\":\"Simon\",\"last\":\"Reiss\",\"middle\":[]},{\"first\":\"Kunyu\",\"last\":\"Peng\",\"middle\":[]},{\"first\":\"Chaoxiang\",\"last\":\"Ma\",\"middle\":[]},{\"first\":\"Haodong\",\"last\":\"Fu\",\"middle\":[]},{\"first\":\"Philip\",\"last\":\"Torr\",\"middle\":[\"H.\",\"S.\"]},{\"first\":\"Kaiwei\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Rainer\",\"last\":\"Stiefelhagen\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "In this paper, we address panoramic semantic segmentation which is under-explored due to two critical challenges: (1) image distortions and object deformations on panoramas; (2) lack of semantic annotations in the 360-degree imagery. To tackle these problems, first, we propose the upgraded Transformer for Panoramic Semantic Segmentation, i.e., Trans4PASS+, equipped with Deformable Patch Embedding (DPE) and Deformable MLP (DMLPv2) modules for handling object deformations and image distortions whenever (before or after adaptation) and wherever (shallow or deep levels). Second, we enhance the Mutual Prototypical Adaptation (MPA) strategy via pseudo-label rectification for unsupervised domain adaptive panoramic segmentation. Third, aside from Pinhole-to-Panoramic (Pin2Pan) adaptation, we create a new dataset (SynPASS) with 9,080 panoramic images, facilitating Synthetic-to-Real (Syn2Real) adaptation scheme in 360-degree imagery. Extensive experiments are conducted, which cover indoor and outdoor scenarios, and each of them is investigated with Pin2Pan and Syn2Real regimens. Trans4PASS+ achieves state-of-the-art performances on four domain adaptive panoramic semantic segmentation benchmarks. Code is available at https://github.com/jamycheung/Trans4PASS.", "fields_of_study": "[\"Computer Science\",\"Engineering\"]", "external_ids": {"arxiv": "2207.11860", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2207-11860", "doi": "10.48550/arxiv.2207.11860"}}, "content": {"source": {"pdf_hash": "31742de5690c117b54e7ae1faeac35897ece000e", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2207.11860v4.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "478a50a2c54c22d9fc06373f1a4a7f3c98a3f375", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/31742de5690c117b54e7ae1faeac35897ece000e.txt", "contents": "\nBehind Every Domain There is a Shift: Adapting Distortion-aware Vision Transformers for Panoramic Semantic Segmentation\n\n\nJiaming Zhang \nKailun Yang \nHao Shi \nSimon Rei\u00df \nKunyu Peng \nChaoxiang Ma \nHaodong Fu \nPhilip H S Torr \nKaiwei Wang \nRainer Stiefelhagen \nBehind Every Domain There is a Shift: Adapting Distortion-aware Vision Transformers for Panoramic Semantic Segmentation\n1Index Terms-Semantic SegmentationPanoramic ImagesDomain AdaptationVision TransformersScene Understanding\nIn this paper, we address panoramic semantic segmentation which is under-explored due to two critical challenges: (1) image distortions and object deformations on panoramas; (2) lack of semantic annotations in the 360 \u2022 imagery. To tackle these problems, first, we propose the upgraded Transformer for Panoramic Semantic Segmentation, i.e., Trans4PASS+, equipped with Deformable Patch Embedding (DPE) and Deformable MLP (DMLPv2) modules for handling object deformations and image distortions whenever (before or after adaptation) and wherever (shallow or deep levels). Second, we enhance the Mutual Prototypical Adaptation (MPA) strategy via pseudo-label rectification for unsupervised domain adaptive panoramic segmentation. Third, aside from Pinhole-to-Panoramic (PIN2PAN) adaptation, we create a new dataset (SynPASS) with 9,080 panoramic images, facilitating Synthetic-to-Real (SYN2REAL) adaptation scheme in 360 \u2022 imagery. Extensive experiments are conducted, which cover indoor and outdoor scenarios, and each of them is investigated with PIN2PAN and SYN2REAL regimens. Trans4PASS+ achieves state-of-the-art performances on four domain adaptive panoramic semantic segmentation benchmarks. Code is available at https://github.com/jamycheung/Trans4PASS.\n\nINTRODUCTION\n\nP ANORAMIC semantic segmentation offers an omnidirectional and dense visual understanding regimen that integrates 360 \u2022 perception of surrounding scenes and pixel-wise predictions of input images [1]. The attracted attention of 360 \u2022 cameras is manifesting, with an increasing number of learning systems and practical applications, such as holistic sensing in autonomous vehicles [2], [3], [4] and immersive viewing in augmented-and virtual reality (AR/VR) devices [5], [6], [7]. In contrast to images captured by pinhole cameras (see Fig. 3a-(1)&(4)) with a narrow Field of View (FoV), panoramic images with an ultra-wide FoV of 360 \u2022 , deliver complete scene perception in outdoor driving environments ( Fig. 3a- (2)) and indoor scenarios ( Fig. 3a-(5)).\n\nHowever, panoramic images often have large image distortions and object deformations due to the intrinsic equirectangular projection [8], [9]. This renders a vast number of methods a suboptimal solution for panoramic segmentation [10], [11], as they are tailored for pinhole images and cannot handle severe deformations. In Fig. 1, we observed that with an increase in FoV, the performance of the baseline model [12] drops. To solve this problem, we propose a novel distortion-aware model, i.e., Transformer for PAnoramic Semantic Segmentation (Trans4PASS). Specifically, compared with standard Patch Embedding (PE), our newly designed Deformable Patch Embedding (DPE) helps to learn the prior knowledge of panorama characteristics during patchifying the image. In addition, the proposed Deformable MLP (DMLP) \u2022   enables the model to better adapt to panoramas during feature parsing. Building upon the success of the deformable structure, we further propose a simple yet highly effective version, i.e., Trans4PASS+, which is enhanced by DMLPv2 with parallel token mixing mechanisms. Compared to Trans4PASS, the new model benefits more from larger FoV due to its advanced token mixing design, showing inherent robustness against FoV changes (Fig. 1). Meanwhile, it demonstrates significant performance gains in the source-only setting in both indoor (SPin SPan) and outdoor (CS DP) scenarios (Fig. 2). Apart from the deformation of panoramic images, the scarcity of annotated data is another key difficulty that hinders the progress of panoramic semantic segmentation. Notoriously, it is extremely time-consuming and expensive to produce dense annotations for training success [13], [14], and this difficulty is further exacerbated for panoramas with ultra-wide FoV and many small and distorted scene elements concurrently appearing in complex environments. Unsupervised Domain Adaptation (UDA) is a strategy commonly employed to adapt models from a source domain to a target domain, with its extensive application observed in pinhole imagery. However, UDA in the panoramic domain remains limited within the existing literature. In this work, we propose a Mutual Prototypical Adaptation (MPA) strategy for domain adaptive panoramic segmentation. Compared with other adversarial-learning [15] and pseudo-label self-learning [16] methods, the advantage of MPA is that mutual prototypes are generated from both source and target domains. In this manner, large-scale labeled source data and unlabeled target data are taken into account at the same time. The MPA strategy further unleashes the potential of our adapted model when combining stronger mask generators (e.g., SAM [17]), which alleviates the negative effect of target samples with noisy and incomplete pseudo labels. It enables our unsupervised models to outperform SAM combined with self-supervised learning (SSL) or superior to previous fully-supervised models. More comparisons are presented in Sec. 5.5.\n\nBased on the MPA strategy, we first revisit the Pinhole-to-Panoramic (PIN2PAN) paradigm as previous works [3], [9], by considering the label-rich pinhole images as the source domain and the label-scare panoramic images as the target domain. Furthermore, a new dataset (SynPASS) with 9,080 synthetic panoramic images is created, which brings two benefits: (1) The large-scale annotations enable training data-hungry models for panoramic semantic segmentation; (2) A new Synthetic-to-Real (SYN2REAL) domain adaptive panoramic segmentation scheme is established apart from PIN2PAN. Based on the new dataset, we thoroughly investigate the two adaptation paradigms in both indoor and outdoor scenarios (Fig. 3a). The feature distributions of the sidewalk class from two sources (S1, S2) and one target (T) domains are presented in Fig. 3b, and the floor class from indoor domains are in Fig. 3c. Upon close inspection, two insights become clear: (1) The marginal distributions of the synthetic and real domains are close in one dimension (e.g., the shape), whereas the marginal distributions in another dimension (e.g., the appearance) are far apart. (2) The patterns are reversed between the pinhole and panoramic domains. The insights are intuitive and consistent with common observations, as objects (e.g., sidewalks or floors) in synthetic-and real images are shape-deformed, while real pinhole-and panoramic images are similar in appearance. We unfold a comprehensive discussion and results in Sec. 5.6.\n\nExtensive experiments -both indoor and outdoor scenarios and each investigated under PIN2PAN and SYN2REAL paradigms -demonstrate the superiority of the proposed distortion-aware architecture. Our new Trans4PASS+ model with the MPA strategy attains state-of-the-art performances on four panoramic segmentation benchmarks. On the Stanford2D3D dataset [18], our unsupervised model outperforms the fully-supervised methods for the first time. On the Structured3D dataset [19], our SYN2REALadapted model surpasses the model trained with extra 1,400 annotated data. On the DensePASS dataset [3], our source-only model obtains 49.94% in mIoU with a +10.92% gain over the baseline, and our Pin2Pan-adapted model obtains 59.43% in mIoU with a +17.44% boost over the previous best method [20].\n\nThis work is built upon our previous conference version [11] by introducing an improved model architecture, a new panoramic segmentation benchmark, a SAM-enhanced adaptation method, and a more comprehensive study on panoramic semantic segmentation with various UDA schemes. At a glance, the additional contributions of this work can be summarized as follows:\n\n(1) A new panoramic semantic segmentation benchmark Syn-PASS is established with 9,080 images. It delivers an alternative Synthetic-to-Real (SYN2REAL) UDA paradigm in panoramic segmentation, which is compared with the Pinhole-to-Panoramic (PIN2PAN) one. (2) We advance the Trans4PASS+ model with a more lightweight yet effective decoder, which is extended with a DMLPv2 module with parallel token mixing mechanisms to reinforce the flexibility in modeling discriminative information. (3) We present a Mutual Prototypical Adaptation (MPA) strategy for domain adaptive panoramic segmentation via dualdomain prototypes. For the first time, we boost MPA by using the Segment Anything Model (SAM) as a pseudo-label rectification strategy, which shows better performance over standalone SAM or combined with the SSL method. (4) We conduct more comprehensive comparative experiments.\n\nOur proposed method outperforms recent state-of-the-art token mixing [21], [22], [23], [24], deformable patchbased learning [25], transformer domain adaptation [26], and panoramic segmentation [3], [9], [10], [20] methods. (5) On four panoramic datasets, our framework yields superior results, spanning indoor and outdoor scenarios, before and after PIN2PAN and SYN2REAL domain adaptation.\n\n\nRELATED WORK\n\n\nSemantic Segmentation\n\nDense image semantic segmentation has experienced a steep increase in attention and great progress since Fully Convolutional Networks (FCN) [27] addressed it as an end-to-end per-pixel classification task. Following FCN, subsequent efforts enhance the segmentation performance by using encoder-decoder architectures [28], [29], aggregating high-resolution representations [30], [31], widening receptive fields [32], [33], [34] and collecting contextual priors [35], [36], [37]. Inspired by the non-local blocks [38], self-attention [39] is leveraged to establish longrange dependencies [40], [41], [42], [43], [44] within FCNs. Then, contemporary architectures appear to substitute convolutional backbones with transformer ones [45], [46]. Thus, image understanding can be viewed via a perspective of sequence-tosequence learning with dense prediction transformers [12], [47], [48], [49], [50] and semantic segmentation transformers [14], [51], [52], [53], [54]. More recently, MLP-like architectures [22], [23], [55], [56] that alternate spatial-and channel mixing have sparked enormous interest in tackling visual recognition tasks. However, most of these methods are designed for narrow-FoV pinhole images and often have large accuracy downgrades when applied in the 360 \u2022 domain for holistic panorama-based perception. In this work, we address panoramic semantic segmentation, with a novel distortion-aware transformer architecture that considers a broad FoV already in its design and handles the panorama-specific semantic distribution via parallel MLP-based, channel-wise mixing, and pooling mixing mechanisms.\n\n\nPanoramic Segmentation\n\nCapturing wide-FoV scenes, panoramic images [4] act as a starting point for a more complete scene understanding. Mainstream outdoor omnidirectional semantic segmentation systems rely on fisheye cameras [57], [58], [59] or panoramic images [60], [61], [62]. Panoramic panoptic segmentation is also addressed in recent surrounding parsing systems [63], [64], [65], where the video segmentation pipeline with the Waymo open dataset [64] has a coverage of 220 \u2022 . Indoor methods, on the other hand, focus on either distortion-mitigated representations [66], [67], [68], [69], [70] or multi-tasks schemes [8], [71], [72]. Yet, most of these works are developed based on the assumption that densely labeled images are implicitly or partially available in the target domain of panoramic images for training a segmentation model. However, the acquisition of dense pixel-wise labels is extremely labor-intensive and time-consuming, in particular for panoramas with higher complexities and more small objects implicated in wide-FoV observations. We cut the requirement for labeled target data and circumvent the prohibitively expensive annotation process of determining pixel-level semantics in unstructured real-world surroundings. Different from previous works, we look into panoramic semantic segmentation via the lens of unsupervised transfer learning and investigate both Syntheticto-Real (SYN2REAL) and Pinhole-to-Panoramic (PIN2PAN) adaptation strategies to profit from rich, readily available datasets like synthetic panoramic or annotated pinhole datasets. In experiments, our panoramic segmentation transformer architecture generalizes to both indoor and outdoor 360 \u2022 scenes.\n\n\nDynamic and Deformable Vision Transformers\n\nWith the prosperity of vision transformers in the field, some research works develop architectures with dynamic properties. In earlier works, the anchor-based DPT [25] and the non-overlapping DAT [73] use deformable designs only in later stages of the encoder and borrow Feature Pyramid Network (FPN) decoders from CNN counterparts. PS-ViT [74] utilizes a progressive sampling module to locate discriminative regions, whereas Deformable DETR [75] leverages deformable attention to enhance feature maps. Further, some methods aim to improve the efficiency of vision transformers by adaptively optimizing the number of informative tokens [76], [77], [78], [79] or dynamically modeling relevant dependencies via query grouping [80]. Unlike these previous works limited to narrow-FoV images, our distortion-aware segmentation transformer is designed for pixel-dense prediction tasks on wide-FoV images, and can better adapt to panoramas by learning to counteract severe deformations in the data.\n\n\nUnsupervised Domain Adaptation\n\nDomain adaptation has been thoroughly studied to improve model generalization to unseen domains, e.g., adapting to the real world from synthetic data collections [81], [82]. Two predominant categories of unsupervised domain adaptation fall either in self-training [83], [84], [85], [86], [87], [88] or adversarial learning [89], [90], [91]. Self-training methods usually generate pseudo-labels to gradually adapt through iterative improvement [92], whereas adversarial solutions build on the idea of GANs [93] to conduct image translation [89], [94], or enforce alignment in layout matching [95], [96] and feature agreement [3], [15]. Further adaptation flavors, consider uncertainty reduction [97], [98], model ensembling [99], [100], category-level alignment [101], [102], adversarial entropy minimization [103], [104], and vision transformers [26].\n\nRelevant to our task, PIT [105] handles the gap of camera intrinsic parameters with FoV-varying adaptation, whereas P2PDA [3] first tackles PIN2PAN transfer by learning attention correspondences. Aside from distortion-adaptive architecture design, we revisit panoramic semantic segmentation from a prototype adaptation-based perspective where panoramic knowledge is distilled via class-wise prototypes. Differing from recent methods utilizing individual prototypes for source-and target domain [106], [107], we present mutual prototypical adaptation, which jointly exploits dual-domain feature embeddings. Besides, we enhance MPA by using SAM [17] to rectify target pseudo labels, which boosts transfer beyond the FoV. Moreover, we study both PIN2PAN and SYN2REAL for learning robust panoramic semantic segmentation.\n\n\nMETHODOLOGY\n\nHere, we detail the proposed panoramic semantic segmentation framework in the following structure: the Trans4PASS+ architecture in Sec. 3.1; the deformable patch embedding module in Sec. 3.2; two deformable MLP variants in Sec. 3.3; and the mutual prototypical adaptation in Sec. 3.4.\n\n\nTrans4PASS+ Architecture\n\nAs newly emerged learning architectures, transformer models are evolving and have attained outstanding performance in vision tasks [14], [45]. In this work, we put forward a novel distortion-aware Trans4PASS architecture in order to explore the However, the raw 360 \u2022 data is generally formulated in the spherical coordinate system (the latitude \u03b8\u2208[0, 2\u03c0) and longitude \u03d5\u2208[\u2212 1 2 \u03c0, 1 2 \u03c0]). To convert it to the Cartesian coordinate system (the x-and y-axes), the equirectangular projection in Eq. 1 is commonly used to transfer 360 \u2022 data as a 2D flat panorama.\nx = (\u03b8 \u2212 \u03b8 0 ) cos \u03d5 1 , y = (\u03d5 \u2212 \u03d5 1 ),(1)\nwhere (\u03b8 0 , \u03d5 1 )=(0, 0) is the central latitude and central longitude.\n\nConsidering the simple equirectangular projection from Eq. 1 as x=\u03b8 and y=\u03d5, the Area Distortion (AD) is approximated by the Jacobian determinant [109] in Eq. 2 and Eq. 3.\nJ (\u03b8, \u03d5) = \u2202(x) \u2202(\u03b8) \u2202(x) \u2202(\u03d5) \u2202(y) \u2202(\u03b8) \u2202(y) \u2202(\u03d5)\n.\n\n(2)\nAD(x, y) = cos(\u03d5)|d\u03b8d\u03d5| |dxdy| = cos(\u03d5) J (\u03b8, \u03d5) .(3)\nThe AD is associated with cos(\u03d5). Thus, the areas (\u03d5\u0338 =0) located in any panoramic image all include object distortions and deformations. The above observations motivate us to design a distortionaware vision transformer model for panoramic scene parsing. Compared with previous state-of-the-art segmentation transformers [14], [52] shown in Fig. 4a and Fig. 4b, our Trans4PASS model (Fig. 4c) is able to address the severe distortions in panoramas via two vital designs: (1) a Deformable Patch Embedding (DPE) module is proposed and applied in the encoder and decoder, enabling the model to extract and parse the feature hierarchy uniformly; (2) a Deformable MLP (DMLP) module is proposed to better collaborate with DPE in the decoder, by adaptively mixing and interpreting the feature token extracted via DPE. Furthermore, a new DMLPv2 module is constructed with a parallel token mixing mechanism. Based on DMLPv2, our architecture is upgraded to Trans4PASS+, being more lightweight yet more effective for panoramic semantic segmentation. The DPE and DMLPs are detailed in the following sections.\n\n\nDeformable Patch Embedding\n\nPreliminaries on Patch Embedding. Given a 2D C in -channel input image or feature map f \u2208R H\u00d7W \u00d7Cin , the standard Patch Embedding (PE) module reshapes it into a sequence of flattened patches z\u2208R ( HW s 2 )\u00d7(s 2 \u00b7Cin) , where (H, W ) is the resolution of the input, (s, s) is the resolution of each patch, and HW s 2 is the number of patches (i.e. the length of the patch sequence). Each element in this sequence is passed through a trainable linear projection layer transforming it into C out dimensional embeddings. The number of input channels C in is equal to the one of output channels C out in a typical patchifying process.\n\nConsider one patch in z representing a rectangle area s\u00d7s with s 2 positions. The position offset relative to the patch-center (s/2, s/2) at a location (i,j)|i, j\u2208 [1,s] in the patch is defined as \u2206 (i,j) \u2208N 2 . In standard PE, these offsets of a single patch grid are fixed and fall into:\n\u2206 f ixed (i,j) \u2208[\u230a\u2212 s 2 \u230b, \u230a+ s 2 \u230b] 2 .(4)\nTake e.g. a 3\u00d73 patch, offsets \u2206 f ixed (i,j) relative to the patch center (1, 1) will lie in [\u22121, 1]\u00d7[\u22121, 1]. They are fixed as:\n\u2206 f ixed = {(\u22121, \u22121),(\u22121, 0), ...,(1, 0),(1, 1)}.(5)\nHowever, the aforementioned equirectangular projection process leads to severe shape distortions in the projected panoramic image, as seen in Fig. 3. A standard PE module with fixed patchifying positions makes the Transformer model neglect these shape distortions of objects and the panoramas. Inspired by deformable convolution [110] and overlapping PE [52], we propose Deformable Patch Embeddings (DPE) to perform the patchifying process respectively for the input image in the encoder and the feature maps in the decoder. The DPE module enables the model to learn a data-dependent and distortion-aware offset \u2206 DP E \u2208N H\u00d7W \u00d72 , thus, the spatial connections of objects presenting in distorted patches can be featured by the model. DPE is learnable and able to predict the adaptive offsets regarding the original input f . Compared to the fixed offset in Eq. (4), the learned offset \u2206 DP E\n(i,j)\nis calculated as depicted in Eq. (6). where g(\u00b7) is the offset prediction function, which we implement via the deformable convolution operation [110]. The hyperparameter r in Eq. (6) puts a constraint onto the leaned offsets and is better set as 4 based on our experiments. The learned offsets make DPE adaptive and as a result distortion-aware.\n\u2206 DP E (i,j) = min(max(\u2212 H r , g(f ) (i,j) ), H r ) min(max(\u2212 W r , g(f ) (i,j) ), W r ) ,(6)\n\nDeformable MLP\n\nToken mixers play a major role in the competitive modeling ability of attention-based Transformer models. The recent MLPbased models [22], [55] heuristically relax attention-based feature constraints by spatially mixing tokens via MLP projections. Inspired by the success of MLP-based mixers, we design a Deformable MLP (DMLP) token mixer to conduct the adaptive feature parsing for panoramic semantic segmentation. Vanilla-MLP [55] based modules lack adaptivity which weakens the token mixing of panoramic data. In contrast, linked with the aforementioned DPE module, our DMLP-based decoder performs adaptive token mixing during the overall feature parsing, being aware of the deformation properties in 360 \u2022 images. DMLPv1 token mixer. Concerning the comparison between MLP-based modules depicted in Fig. 5, the vanilla MLP ( Fig. 5a) lacks the spatial context modeling, CycleMLP ( Fig. 5b) has the narrow projected receptive field due to fixed offsets, and our DMLP module ( Fig. 5c) generates learned adaptive spatial offsets during mixing tokens and leads to a wider projected grid (i.e., the green panel). Specifically, given a DPE-processed C in -dimensional feature map f \u2208R H\u00d7W \u00d7Cin , the spatial offset \u2206 DM LP (i,j,c) is first predicted channel-wise by using Eq. (6). Then, the offset is flattened as a sequence in the shape of \u2206 DM LP (k,c)\n\n, where k\u2208HW and c\u2208C in . While the given feature map is projected into a sequence z with the equal shape, the offsets are used to select tokens during mixing the flattened token/patch features z\u2208R HW \u00d7Cin . The mixed token is calculated as:\nz (k,c) = HW k=1 Cin c=1 w T (k,c) \u00b7 z (k+\u2206 DM LP (k,c) ,c) ,(7)\nwhere w\u2208R Cin\u00d7Cout is the weight matrix of a fully-connected layer. As shown in Fig 6d, the DMLPv1 token mixer has a residual structure, consisting of DPE, two DMLPs, and an MLP module. Formally, the entire four-stage decoder is constructed by DMLPv1 token mixers and is denoted as: where Up(\u00b7) and LN(\u00b7) refer to the Upsample-and LayerNorm operations, and p is the prediction of K classes. DMLPv2 token mixer. Achieving the distortion-aware property and maintaining manageable computational complexity, we put forward a simple yet effective DMLPv2 toking mixer structure, which is demonstrated in Fig. 6e. Compared to recent token mixers, such as PoolFormer [21] (Fig. 6c) and FAN [24] (Fig. 6b), the advanced DMLPv2 is upgraded to a novel parallel token mixing mechanism by using a Squeeze&Excite (SE) [111] based Channel Mixer (CX) and a non-parametric multi-scale Pooling Mixer (PX). Such a parallel token mixing mechanism brings two vital perspectives in the advanced DMLPv2 module: (1) the CX considers space-consistent but channel-wise feature reweighting, enhancing the feature by spotlighting informative channels; (2) the multi-scale PX and DMLP focus on spatial-wise sampling via fixed or adaptive offsets, yielding mixed tokens highlighted in relevant positions. Thus, it improves the flexibility in modeling discriminative information and thereby reinforces the generalization capacity against domain shifts. Furthermore, thanks to the sufficient token mixing of PX, the new DMLPv2 structure reduces the model complexity by using a single MLP layer, thus making the model more lightweight. Based on Eq. (8), the DMLPv2-based decoder is upgraded to:\nz l := DPE(C l , C emb )(z l ), \u2200 l \u2208{1,2,3,4} z l := DMLP(C emb , C emb )(\u1e91 l ) +\u1e91 l , \u2200 l z l := MLP(C emb , C emb )(\u1e91 l ) +\u1e91 l , \u2200 l z l := Up(H/4, W/4)(\u1e91 l ), \u2200 l p := LN(C emb , C K )( l=1\u1e91 l ),(8)z l := DPE(C l , C emb )(z l ), \u2200 l \u2208{1,2,3,4} z l := s\u2208{3,5,11} PX s\u00d7s (C emb , C emb )(\u1e91 l ) + CX(\u1e91 l ), \u2200 l z l := DMLP(C emb , C emb )(\u1e91 l ) + CX(\u1e91 l ), \u2200 l z l := Up(H/4, W/4)(\u1e91 l ), \u2200 l p := LN(C emb , C K )( l=1\u1e91 l ),(9)\nwhere PX s\u00d7s (\u00b7) represents the average pooling operator in size of s\u00d7s and CX(\u00b7) denotes the channel-wise attention operator. Based on our experimental findings, we observed that setting the multiscale pooling as {3,5,11} yields superior results. More analysis of multi-scale pooling operations and the ablation study of PX and CX in DMLPv2 are presented in Sec. 5.4. In general, the DMLPbased decoder delivers a spatial-and channel-wise token mixing in an efficient manner, but with a larger receptive field, which improves the expressivity of features in the panoramic imagery.\n\n\nMutual Prototypical Adaptation\n\nTo unfold the potential of panoramic segmentation models, a largescale dataset is crucial for success. However, labeling panoramic images is extremely time-consuming and expensive, due to the ultra-wide FoV and small elements of panoramas. Thus, we look into Domain Adaptation (DA) to exploit the sub-optimal but label-rich resources for training panoramic models, i.e., exploring Pinhole-to-Panoramic (PIN2PAN) adaptation and the Synthetic-to-Real (SYN2REAL) adaptation in this work. Preliminaries on domain adaptation. Given the source (i.e., the pinhole or the synthetic) dataset with a set of labeled images D s ={(x s , y s )|x s \u2208R H\u00d7W \u00d73 , y s \u2208{0,1} H\u00d7W \u00d7K } and the target (i.e., the panoramic) dataset D t ={(x t )|x t \u2208R H\u00d7W \u00d73 } without annotations, the objective of DA is to adapt models from the source to the target domain with K shared classes. The model is trained in the source domain D s via the segmentation loss:\nL s SEG = \u2212 H,W,K i,j,k=1 y s (i,j,k) log(p s (i,j,k) ),(10)\nwhere p s (i,j,k) is the probability of the source pixel x s (i,j) predicted as the k-th class. To transfer models to the target data, the target pseudo label\u0177 t (i,j,k) of pixels x t (i,j) in Eq. (11) is calculated based on the most probable class given by the source pre-trained model.\ny t (i,j,k) = 1 k . =arg max p t (i,j,:)\n.\n\n(11)\n\nThe Self-Supervised Learning (SSL) in Eq. (12) is used to optimize the model based on the target pseudo labels\u0177 t (i,j,k) .\nL t SSL = \u2212 H,W,K i,j,k=1\u0177 t (i,j,k) log(p t (i,j,k) ).(12)\nProposed Mutual Prototypical Adaptation. As shown in Fig. 7, a novel Mutual Prototypical Adaptation (MPA) method is proposed and applied to distill mutual knowledge via the dualdomain prototypes. Using hard pseudo-labels in the output space results in a limited adaptation of SSL methods. To reduce the negative effect of hard pseudo-labels, our prototype-based method has two characteristics: (1) it softens the hard pseudo-labels by using them in feature space instead of as direct targets; (2) it performs complementary alignment of semantic similarities in feature space. Thus, it makes the self-supervised learning effect by using prototypes more robust. Further, the non-trivial design of prototype construction includes: (1) Prototypes are generated by using the source ground truth labels and the target pseudo labels, making full usage of labeled data and maintaining the similar properties between domains, such as appearance cues of PIN2PAN and shape priors of SYN2REAL; (2) Prototypes are constructed by using multi-scale feature embeddings, becoming more robust and more expressive; (3) Prototypes are stored in memory and updated along with the model optimization process, keeping the mechanism adaptable between iterations. To further eliminate the negative effect of using noisy and incomplete pseudo labels, we boost MPA by using the Segment Anything Model [17]. Specifically, as shown in Fig. 7, the pseudo labels generated by source-only models are incomplete and affect the adaptation training. SAM trained with SA-1B dataset [17] is adopted as a readily available mask generator, which can effectively reconstruct the missing parts of the pseudo-label, such as roads in Fig. 7. Compared to using standalone SAM or combined with SSL-based The mutual prototypes are reconstructed by using dual-domain features of source and target domains. The target pseudo-labels are rectified by SAM [17] to eliminate the negative effect of missing parts, e.g., roads. Zoom in for a better view. methods, our MPA strategy with SAM can achieve better results on UDA due to the robust mutual prototypical design.\n\nSpecifically, a set of n s source-and n t target feature maps is constructed as\nF ={f s 1 , . . . ,f s ns } {f t 1 , . . . ,f t nt }, where f is fused from four-stage multi-scale features f = 4\nl=1 f l and is associated either with its respective source ground-truth label or a target pseudo-label. Each prototype P k is calculated by the mean of all feature vectors (pixel-embeddings) from F that share the class label k. We initialize the mutual prototype memory M={P 1 ,...,P K } by computing the class-wise mean embeddings through the whole dataset. During the training process, the prototype P k is updated at timestep t by P t+1\nk \u2190mP t\u22121 k +(1\u2212m)P t k\nwith momentum m= 0.999, where P t k is the mean feature vector among embeddings that share the class-label k in the current minibatch. Based on the dynamic memory, the prototypical feature map f is reconstructed by stacking the prototypes P k \u2208M according to the pixel-wise class distribution in either the source label or the pseudo-label. Inspired by the knowledge distillation loss [112], the MPA loss is applied to drive the feature alignment between the feature embedding f and the reconstructed feature mapf . The MPA loss only in the source domain is depicted in Eq. (13):\nL s M P A = \u2212 \u03bbT 2 KL(\u03d5(f s /T )||\u03d5(f s /T )) \u2212 (1 \u2212 \u03bb)CE(y s ,\u03d5(f s )),(13)\nwhere KL(\u00b7), CE(\u00b7), and \u03d5(\u00b7) are Kullback-Leibler divergence, Cross-Entropy, and Softmax function, respectively. The temperature T and hyper-parameter \u03bb are 20 and 0.9 in our experiments. Similarly, the target MPA loss is constructed as in Eq. (14).\nL t M P A = \u2212 \u03bbT 2 KL(\u03d5(f t /T )||\u03d5(f t /T )) \u2212 (1 \u2212 \u03bb)CE(\u0177 t ,\u03d5(f t )),(14)\nwhere the pseudo label\u0177 t is generated by Eq. (11). The final loss is combined by Eq. (10) (12) (13) (14) with a weight of \u03b1=0.001 as:  \nL=L s SEG +L t SSL +\u03b1(L s M P A +L t M P A ).(15)\n\nSYNPASS: PROPOSED SYNTHETIC DATASET\n\nRecently, the continuous emergence of panoramic semantic segmentation datasets [3], [18], [19], [58], [113] has facilitated the development of surrounding perception, and simulators have been used to generate multi-modal data [114], [115]. However, there is currently not a readily available large-scale semantic segmentation dataset for outdoor synthetic panoramas, considering that the OmniScape dataset [116] is still not released as of writing this paper. To explore the domain adaptation problem of SYN2REAL under urban street scenes, we create the SynPASS dataset using the CARLA simulator [117]. Our virtual sensor suite consists of 6 pinhole cameras located at the same viewpoint to obtain a cubemap panorama image [68]. The FoV of each pinhole camera was set to 91 \u2022 \u00d791 \u2022 to ensure the overlapping area between adjacent images. We then re-project the acquired cubemap panorama into a common equirectangular format using the cubemap-to-equirectangular projection algorithm. Given a equirectangular image grid (\u03d5, \u03b8), we need to find the corresponding coordinates (x, y) of each grid position on the cubemap C={I F , I R , I B , I L , I U , I D } to look up the value, where \u03d5\u2208(\u2212\u03c0, \u03c0), \u03b8\u2208(\u2212 1 2 \u03c0, 1 2 \u03c0), {I F , I R , I B , I L , I U , I D }\u2208R H\u00d7W are the front, right, back, left, top, and bottom view in the cubemap format, respectively. For {I F , I R , I B , I L } indexed by i={1,2,3,4}, we have:\nx = W 2 \u00b7 tan(\u03d5 \u2212 i \u03c0 2 ), y = \u2212 H\u00b7tan\u03b8 2cos(\u03d5\u2212i \u03c0 2 ) .(16)\nFor {I U , I D } indexed by j={0,1}, we have:\nx = W 2 \u00b7 cot\u03b8sin\u03d5, y = H 2 \u00b7 cot\u03b8cos(\u03d5 + j\u03c0).(17)\nRGB images and semantic labels are captured simultaneously. In order to ensure the diversity of semantics, we benefit from 8 opensource city maps and set 100\u223c120 initial collection points in every map. Our virtual collection vehicle drives according to the simulator traffic rules. We sample every 50 frames and keep the first 10 key-frames of images at each initial collection point. To further improve the diversity of data, we modulate the collected weather and time conditions. The weather conditions consist of sunny (25%), cloudy (25%), foggy (25%), and rainy (25%) conditions. The time changes include daytime (85%) and nighttime (15%). In summary, our newly collected SynPASS dataset contains 9,080 panoramic RGB images and semantic labels with a resolution of 1,024\u00d72,048. Some examples are shown in Fig. 8, and detailed statistical information is reported in Table 1.\n\nThe distributions of SynPASS, the panoramic DensePASS [3], and the pinhole Cityscapes [13] datasets are depicted in Fig. 9. The class-wise pixel numbers are accumulated over all images in the respective datasets. Apart from the overlapping 13 classes, the SynPASS dataset has 22 classes in total, including 9 additional classes: other, roadline, ground, bridge, railtrack, groundrail, static, dynamic, and water. It provides more semantic categories to enrich the 360 \u2022 scene understanding.\n\n\nEXPERIMENTS\n\n\nDatasets and Settings\n\nWe experiment with six datasets, including two source domains and one target domain in respective indoor and outdoor scenes: (4) Outdoor SYN2REAL: SP13 DP13. Implementation settings. We train our models with 4 A100 GPUs with an initial learning rate of 5e \u22125 , which is scheduled by the poly strategy with power 0.9 over 200 epochs. The optimizer is AdamW [118] with epsilon 1e \u22128 , weight decay 1e \u22124 , and batch size is 4 on each GPU. The images are augmented by the random resize with ratio 0.5-2.0, random horizontal flipping, and random cropping to 512\u00d7512. For outdoor datasets, the resolution is 1,080\u00d71,080 and the batch size is 1. When adapting the models from PIN2PAN, the resolution of indoor pinhole and panoramic images are 1,080\u00d71,080 and 1,024\u00d7512 for training. In SYN2REAL, the resolution of synthetic panoramic images is 1,024\u00d7512. The outdoor pinhole-and synthetic images are set to 1,024\u00d7512 and the panoramic images are with a resolution of 2,048\u00d7400. The image size of indoor and outdoor validation sets are 2,048\u00d71024 and 2,048\u00d7400, respectively. Adaptation models are trained within 10K iterations on one GPU.\n\n\nSynPASS Benchmark\n\nIn order to study the performance of panoramic semantic segmentation of current existing approaches and our approach Trans4PASS+ on the proposed synthetic dataset, the SynPASS benchmark with the full 22 classes is established. As shown in Table 2, we conduct experiments for panoramic semantic segmentation on the SynPASS dataset using either CNN-based approaches (e.g., Fast-SCNN [119], DeepLabv3+ [29], and HRNet [31]) or transformer-based approaches (e.g., PVT [12], SegFormer [52], and the proposed Trans4PASS and Trans4PASS+). All the investigations among transformer-based approaches are conducted considering the trade-off between efficiency and model size within a fair comparison. The models are trained on the overall training set and their performances are reported in different weather and day/night conditions. Compared with existing approaches, Trans4PASS+ (Tiny) surpasses HRNet with the best performance among all the listed CNN-based methods by +5.37% in mIoU on the validation set. Trans4PASS and Trans4PASS+ consistently outperform PVT and SegFormer in all conditions. Compared to SegFormer-B2, our small model achieves respective +4.12% and +3.48% gains on the validation-and test set. The largest improvement lies in the rainy condition with a +5.03% gain. The results showcase that our models have a strong capability to capture panoramic segmentation cues on the synthetic dataset even considering different weather and day/night scenarios.\n\nCompared to Trans4PASS, the advanced Trans4PASS+ model performs more accurately in all conditions and clearly elevates the overall mIoU scores on both validation-and testing sets. According to Table 1, the samples are equally distributed among different scenarios and Trans4PASS+ also yields balanced segmentation performance across different kinds of weather and illuminating conditions, which demonstrates the robustness of our new model in different scenarios. The results of all the investigated models illustrate that there is still remarkable improvement space on the newly established benchmark, since the best performance is 40.72% on the SynPASS test set, indicating that the new benchmark is challenging due to its high diversity.\n\n\nPIN2PAN and SYN2REAL Gaps\n\nPIN2PAN gaps. We first quantify the PIN2PAN domain gap in outdoor scenarios by assessing >15 off-the-shelf convolutional-and vision-transformer-based semantic segmentation models learned from Cityscapes. 1 Table 3 presents the results evaluated on Cityscapes [13] and DensePASS [3] validation sets. It can be observed that traditional CNN-based methods such as PSPNet [33] and DANet [40] suffer huge performance downgrades and have a mIoU degradation of \u223c50% when directly transferred to work on panoramic data. The transformer architectures SETR [14] and SegFormer [52] still have a large mIoU gap of \u223c40%. The proposed Trans4PASS architectures have high performances on pinhole image semantic segmentation, e.g., Trans4PASS (S)   Table 4 based on the Stanford2D3D dataset [18]. The pinhole-and panoramic images from Stanford2D3D are collected under the same setting, and the PIN2PAN gap is smaller compared to the outdoor scenario. Still, in light of other convolutional-and attentional transformer-based architectures, the small Trans4PASS+ variant leads to top mIoU scores of 51.48% and 49.76% for pinhole-and panoramic image semantic segmen- tation, while its accuracy drop is also largely reduced compared to former state-of-the-art models like Trans4Trans [128]. SYN2REAL gaps. To measure the SYN2REAL domain gap, for outdoor road-driving scenes, we leverage our SynPASS (SP13) and DensePASS (DP13) datasets by using their overlapping 13 classes for training and testing. Compared to the versatile dense prediction transformer [12], Trans4PASS consistently improves the performance in Table. 5-2 , surpassing the corresponding PVT variant by >5% on the target domain, and resulting in more robust omni-segmentation as shown in Fig. 1. Similarly, for the indoor situation, we experiment on Structured3D (S3D8) panoramic [19] and Stanford2D3D panoramic (SPan8) sets by using their sharing 8 categories. The results are presented in Table. 5-4 . The benefit of using Trans4PASS+ with DMLPv2 is pronounced, as it brings a mIoU gain of +8.25% compared to the tiny PVT baseline. We will further conduct an in-depth architecture analysis on the noveldesigned Trans4PASS+ in Sec. 5.4. PIN2PAN vs. SYN2REAL. In Table 5, we also study the domain gap comparison between PIN2PAN and SYN2REAL paradigms, to inspect the shift behind each imagery and to answer the key question: which adaptation scheme is more promising for panoramic semantic segmentation. Here, a short answer is provided. For the outdoor scenario, the model overall benefits more from real pinhole scenes than from synthetic panoramic scenes, when transferred to the target domain without any adaptation. The PIN2PAN-learned small Trans4PASS+ ( 1 ) reaches 51.48% in mIoU, while the SYN2REAL-transferred variant ( 2 ) only achieves 43.83% falling behind by a clear margin. We conjecture that without any domain adaptation, the rich detailed texture cues available in the real pinhole outdoor dataset play an important role in attaining generalizable segmentation. We further delve into this comparison quantitatively in Sec. 5.6 and qualitatively in Sec. 5.7.\n\nFor the indoor scenario, as shown in Table 5-3 , the PIN2PAN model also achieves higher performance, as both pinhole-and  In Sec. 5.6, we will further assess how our proposed adaptation strategy mitigates the SYN2REAL performance drop. Moreover, as shown in Table 6, we note that our proposed Trans4PASS+ shows strong zero-shot generalization capacity when only learning from synthetic images and testing on real panoramic data. It achieves 52.09% in mIoU, which surprisingly outperforms the previous state-of-the-art HRNet [31] (52.00%) trained with both synthetic-and real (extra 1,063 annotations) datasets as suggested in [19].\n\n\nStudy of Trans4PASS+ Structure\n\nAblation of different components.\n\nWe first ablate the effectiveness of the proposed DPE, DMLPv1, and DMLPv2 in Table 7. In the first group without using DPE, both of our DMLP methods achieve better performance with lower computational complexity, which have respective 45.14% and 46.94% in mIoU on the DensePASS dataset. Besides, the new DMLPv2 method can bring additional improvement (+1.8% mIoU) as compared to DMLPv1. In the second group with DPE, consistent performance improvements of both DMLP methods are observed. The DMLPv2 has mIoU of 49.94% with +4.05% gains compared to DMLPv1, which indicates the advantage of DMLPv2 using sufficient token mixing. However, in cross-group comparisons, both DMLP methods with DPE can obtain substantial performance gains than their non-DPE implementations. Specifically, thanks to the effective DPE, the DMLPv2 method improves the mIoU score from 46.94% to 49.94%. Through the ablation study, it is proved that the proposed components are effective, yielding an enhanced Trans4PASS+ model for handling omnidirectional scene segmentation. Ablation of PX and CX. In Table 8, we further study the effectiveness of two token mixers, i.e., the pooling mixer (PX) and the channel mixer (CX) in our advanced DMLPv2. In the case of applying PX and CX separately, there are +7.64% and +8.64%   [25] proposes patches shifting around object proposals, our DPE method is flexible to split image patches and is decoupled from object proposals. As compared to DPT, our DPE brings +9.39% gains in mIoU on the DensePASS dataset, which shows the efficacy of our deformable patch embedding design. To ablate the impacts of different MLPlike modules integrated into the decoder of Trans4PASS+, we compared the DMLPv2 module with vanilla MLP, CycleMLP [22] and ASMLP [23] modules. Our DMLPv2 method is more adaptive as opposed to the fixed offsets in CycleMLP, as depicted in Fig. 5.\n\nThe results also confirm the benefit as DMLPv2 outstrips these modules with a clear margin of 6\u223c9% in mIoU. Comparison of token mixing methods. In Table 10, we compare our parallel token mixing method with existing methods, including the average-pooling-based mixer from PoolFormer [21], the channel mixer from FAN block [24], and a combination of FAN and PoolFormer. They are combined in a similar parallel way but without adding any deformable designs. However, compared to the PoolFormer and the FAN methods, our DMLPv2 method obtains respective +6.76% and +7.40% gains in mIoU on the DensePASS dataset. Besides, our parallel token mixing design further outperforms the combination of PoolFormer and FAN. The comparison illustrates that DMLPv2 offers a sweet spot and an optimal path to follow for attaining robust and effective panoramic segmentation against domain shift problems.\n\n\nStudy of MPA Strategy\n\n\nOutdoor scenario: Cityscapes\u2192DensePASS\n\nComparison with outdoor state-of-the-art methods. Table 11a shows the adaptation from Cityscapes to DensePASS. We compare Trans4PASS+ with previous state-of-the-art segmentation frameworks specifically developed for panoramic images, including Panoramic Annular Semantic Segmentation (PASS) [10] and Efficient Concurrent Attention Network (ECANet) [9]. Both of them are sub-optimal for robust omnidirectional surrounding parsing on the dense 19-class segmentation benchmark of DensePASS [3]. Then, we compare MPA-Trans4PASS+ against representative UDA pipelines including some built on adversarial learning such as CLAN [15] and P2PDA [20], and self-training schemes like CRST [16], SIM [101], PCS [106], HRDA [130], MIC [129], and DAFormer [26], both adapted from Cityscapes to DensePASS. Among these methods, P2PDA is the previous best solution for domain adaptive panoramic segmentation on DensePASS, whereas DAFormer serves as a recent well-known state-of-theart transformer-based domain adaptation method. Yet, MPA-Trans4PASS arrives at 56.38%. Thanks to the advanced DMLPv2 module and the SAM-based MPA method, Trans4PASS+ scores the highest 59.43% in mIoU, which outstrips P2PDA-SSL by a large margin of +17.44%. Meanwhile, it exceeds the prototypical approach PCS and the transformer-driven DAFormer with +5.60% and +4.87%, respectively.\n\nWe further broaden the comparison by adding multisupervision methods [131], [132], [133] which require much more data. USSS [131] relies on multi-source semi-supervised learning, while Seamless-Scene-Segmentation [132] uses instance-specific labels for auxiliary supervision. ISSAFE [133] merges training data from Cityscapes, KITTI-360 [113], and BDD [137] for robustifying segmentation. The semantic outputs of these models are projected to the 19 classes in DensePASS to be comparable with others. However, these multi-supervision approaches are less effective for panoramic semantic segmentation. As seen in  DANet [40] used in P2PDA [3] are replaced by Trans4PASS and Trans4PASS+, as displayed in Table 11b. Trans4PASS comes with >10% performance gains due to the collected long-range dependencies and distortion-aware features. In the second and third ablation groups of Table 11b, our tiny and small Trans4PASS+ models with MPA and SAM can achieve respective 57.67% and 59.43% in mIoU, yielding +2.95% and +3.05% gains over the one with SSL. These results certify that MPA works collaboratively with pseudo labels rectified by SAM and offers a complementary feature alignment incentive. Omnidiretional segmentation. To showcase the effectiveness of MPA on omnidirectional segmentation, the panorama is divided into 8 directions and mIoU scores are calculated in each direction separately. The polar diagram in Fig. 11 demonstrates that MPA consistently and reliably improves the adaptation performance while using PVTv2 [138], TransPASS, or Trans4PASS+.\n\n\nIndoor scenario: SPin\u2192SPan\n\nComparison with indoor state-of-the-art methods. Table 11c shows adaptation from Stanford2D3D [18] pinhole to panoramic domains (SPin\u2192SPan). Surprisingly, Trans4PASS+ (\u223c14M parameters) outperforms existing fully-supervised and transferlearning methods that use ResNet-101 (\u223c44M parameters). For example, the versatile HoHoNet [8] obtains 52.0%, whereas some methods [67], [134], [135], [139] use RGB-D input to exploit cross-modal complementary information. Still, our lighter TransPASS+ achieves 52.3% while being unsupervised. However, our supervised counterpart can reach 54.1%. These results further verify the distortion adaptability of the proposed Trans4PASS+ architecture for panoramic semantic understanding. Ablation on Stanford2D3D. Table 11d presents the ablation study conducted in the fold-1 data splitting [18]. Our MPA-Trans4PASS (Tiny) exceeds the previous state-of-the-art P2PDAdriven DANet and it is even better than the one adapted with a PVT-Small backbone. Overall, Trans4PASS+ (Small) achieves the highest mIoU score (53.49%), even reaching the level of the fullysupervised Trans4PASS+ (54.1%) which does have full access to panoramic image annotations of 1,400 target samples.\n\n\nPIN2PAN and SYN2REAL Adaptation\n\nThe results and comparisons between PIN2PAN and SYN2REAL adaptation paradigms are detailed in Table 12. We respectively analyze the results according to outdoor and indoor scenarios. Comparison in the outdoor scenario. In Sec. 5.3, we have briefly assessed the comparison between PIN2PAN and SYN2REAL performance. In Table 12a, we inspect this in greater detail by using the two 13-class benchmarks. Before adaptation, PIN2PAN models generally perform better than their corresponding SYN2REAL (a) Per-class results on DensePASS. Comparison with state-of-the-art panoramic segmentation [9], [10], domain adaptation [15], [16], [20], [26], [101], [106], [129], [130], and multi-supervision methods [131], [132], [133]. * denotes performing Multi-Scale (MS) evaluation. ones. This is due to that the rich and detailed texture information available in the pinhole datasets, provides important cues for semantic segmentation. Yet, when stepping further to look into per-class accuracy, we find that SYN2REAL often achieves higher performance on sidewalk (40.52% vs. 42.36%). Sidewalks can get stretched and appear at multiple positions across the 360 \u2022 , which is uncommon in pinhole data, and thereby they are difficult for source-only PIN2PAN models. In SYN2REAL, the spatial distribution-and position priors available in the panoramic synthetic dataset, can help context-aware vision transformer models to better detect sidewalks. After adaptation, PIN2PAN model largely improves the accuracy of sidewalk, from 40.52% to 54.74%, and outperforms the SYN2REAL-adapted one which has 51.39%. In mIoU, PIN2PAN-adapted model has a better result with 55.24% than the SYN2REAL one with 50.88%. This result reveals that the PIN2PAN method benefits more from the pinhole imagery, while the SYN2REAL one benefits more from the mutual adaptation. Comparison in the indoor scenario. Table 12b shows that PIN2PAN yields better performances in both adaptation-free and MPA settings. The SYN2REAL indoor models come with unsatisfactory performance on the segmentation of sofa due to their different appearances in synthetic and real scenes. It further affects the overall mIoU after adaptation, which shows the challenges of adapting panoramic segmentation models from the synthetic to the real indoor domain. Nonetheless, MPA improves the performance via PIN2PAN domain adaptation, yielding 67.16% mIoU. Analysis of using SAM. Fig. 12 Fig. 12: Analysis of using SAM [17] for panoramic semantic segmentation, including source-only, SAM-enhanced, SAM+SSL, and our SAM+MPA methods.\n\nusing SAM, SSL, and our MPA for panoramic semantic segmentation. The comparison is conducted with two UDA settings of SP13\u2192DP13 and CS13\u2192DP13. Solely using SAM as a mask correction method, there is a limited improvement over the sourceonly model, yielding a +2.66% and a +1.29% gain, respectively. We note that using SAM to enhance pseudo labels for the conventional SSL method cannot guarantee a further boost compared to using SAM solely. One reason is the negative effect of the hard pseudo labels. However, thanks to the mutual prototypical design, our MPA with SAM can bring significant improvements, yielding 50.88% and 55.24% in mIoU, with respective gains of +4.39% and +2.47% over standalone SAM. It proves the effectiveness and advantage of using SAM to eliminate the negative impact of pseudo labels and highlights the robustness of MPA.  \n\n\nQualitative Analysis\n\nPanoramic semantic segmentation visualizations. In Fig. 13a and Fig. 13b, Trans4PASS and Trans4PASS+ models can obtain better panoramic segmentation results than the indoor [12] and outdoor [52] baseline models. In outdoor cases (Fig. 13a), the Trans4PASS+ model has more accurate classifications and boundary distinctions in e.g., trucks, sidewalks, and pedestrians. The baseline model has difficulty distinguishing distorted objects since they lack long-range contexts and distortion-aware features. In indoor cases (Fig. 13b), the challenging objects, like doors and tables, are scarcely identified by the baseline model, but our Trans4PASS+ can segment both objects with precise masks. SAM-based visualization. Fig. 14 shows a visualization com-parison between using SAM alone for correcting the prediction and combining it with our MPA method. The truck class can be correctly recognized by the Trans4PASS+ model after being adapted by MPA with SAM, while it is missing in the SAMenhanced prediction. A similar situation occurs in the sidewalk class. The visualization results indicate the effectiveness of our proposed MPA method, which is enhanced by using SAM as the pseudo-label correction.\n\nPIN2PAN vs. SYN2REAL. With the visualizations in Fig. 15, we discuss the two domain adaptation paradigms. Before leveraging the MPA approach, the source-trained PIN2PAN model ( 1 ) fails to fully detect the sidewalk, as the shapes and positional priors of sidewalks in pinhole imagery significantly differ from those in the panoramic domain. In contrast, the source-trained SYN2REAL model ( 3 ) handles the sidewalk parsing well. This is consistent with the feature embedding observation in Fig. 3 aware MPA-adapted Trans4PASS+ successfully fixes the large gap in shape-deformations and position-priors. However, the adapted SYN2REAL model ( 4 ) has difficulty discovering the traffic signs, which lack diverse textures in the simulated data. These segmentation maps corroborate the numerical results in Table 12.\n\nFeature embedding comparison. In order to intuitively illustrate the effect of the proposed MPA method on the feature space, the t-SNE visualization of feature embeddings before and after outdoor PIN2PAN domain adaptation is shown in Fig. 16. Each dot represents the center of all pixels that share the same class in its image, and these images are from the training set of the respective domain. The blue triangle ( ) in the source and target domains and the black triangle ( ) in the mutual domain are the respective domain prototype of a certain class. Before domain adaptation, the feature embeddings of the source domain, the target domain, and their mutual domain are shown in Fig. 16a, Fig. 16b, and Fig. 16c, respectively, while after adaptation they are shown in Fig. 16d, Fig. 16e, and Fig. 16f, respectively. As our proposed MPA method acts on the feature space and provides complementary feature alignment to both domains, their features are supposed to be more closely tied to their mutual prototypes, i.e., both domains go closer to each other bidirectionally. Comparing Fig. 16c and Fig. 16f, the proposed MPA method bridges the domain gap in the feature space and ties the feature distribution closer, such as mutual prototypes of sidewalk, person, rider, and truck.\n\n\nCONCLUSION\n\nIn this paper, we propose a universal framework with two variants of the In the future, we will explore the combination of cubemap and equirectangular projections, along with the fusion of LiDAR data and panoramic images. Furthermore, it would be interesting to combine two sources, such as pinhole and synthetic datasets, and investigate multi-source domain adaptive panoramic segmentation.\n\n\nACKNOWLEDGMENTS\n\nThis work was supported in part by the Federal Ministry of Labor and Social Affairs (BMAS) through the AccessibleMaps project under Grant 01KM151112, in part by the University of Excellence through the \"KIT Future Fields\" project, in part by the Helmholtz Association Initiative and Networking Fund on the HAICORE@KIT partition, and in part by Hangzhou SurImage Technology Company Ltd.\n\n\nAPPENDIX A MORE QUANTITATIVE RESULTS\n\n\nA.1 Analysis of hyper-parameters\n\nAs the spatial correspondence problem indicated in [110], if the deformable convolution is added to the shallow or middle layers, the spatial structures are susceptible to fluctuation [57]. To solve this issue, the regional restriction of learned offsets is used to stabilize the training of our early-stage and four-stage Deformable Patch Embedding (DPE) module.   We analyze the weight \u03b1 and the temperature T as shown in Fig. A.1a and Fig. A.1b. The Mutual Prototypical Adaptation (MPA) loss and the source-and target segmentation losses are combined by the weight \u03b1. As \u03b1 decreases from 0.1 to 0, we set the temperature T =35 in the MPA loss and evaluate the mIoU(%) results on the DensePASS dataset [3]. If \u03b1=0, the final loss is equivalent to that of the SSL-based method, i.e., the MPA loss is excluded. When \u03b1=0.001 for combining both, MPA and SSL, Trans4PASS obtains a better result. We further investigate the effect of the temperature T in the MPA loss. As shown in Fig. A.1b, the performance is not sensitive to the distillation temperature, which illustrates the robustness of our MPA method. Nevertheless, we found that MPA performs better when the temperature is lower, so T =20 is set as default.\n\n\nA.2 Computational complexity\n\nWe report the complexity of Deformable Patch Embedding (DPE) and two Deformable MLP (DMLP) modules on DensePASS in Table A \n\n\nAPPENDIX B MORE QUALITATIVE RESULTS\n\n\nB.1 Panoramic semantic segmentation\n\nTo verify the proposed model, more qualitative comparisons based on the DensePASS dataset are displayed in Fig. B.1. Specifically, Trans4PASS models can better segment deformed foreground objects, such as trucks in Fig. B.1a. Apart from the foreground object, Trans4PASS models yield high-quality segmentation results in the distorted background categories, e.g., fence and sidewalk.\n\nFor indoor scenarios, more qualitative comparisons are shown in Fig. B.1b, which are from the fold-1 Stanford2D3D-Panoramic dataset [18]. Our models produce better segmentation results in those categories, such as columns and tables, while the baseline model can hardly identify these deformed objects.\n\n\nB.2 DPE and DMLP visualizations\n\nTo investigate the effectiveness of two distortion-aware designs, the visualizations of DPE and DMLP (v1) are shown in Fig. B.2. The RGB images and DPE from four stages of Trans4PASS are visualized in the top five rows in Fig. B.2, where the red dots are the centers of the s\u00d7s patch sequence and the s 2 yellow dots are the learned offsets from DPE. The offsets result that each pixel is adaptive to distorted objects and space, such as the deformed building and sidewalk in Stage-4 DPE in the outdoor case (Fig. B.2-(a)) and the chairs in the indoor case (Fig. B.2-(b)). Furthermore, two feature map pairs from the 75 th channel before and after DMLP are displayed in the bottom two rows in Fig. B.2. Compared to the feature maps before DMLP, the feature maps are enhanced by the DMLP-based token mixer and present semantically recognizable responses, e.g. on regions of distorted sidewalks or objects of deformed cars. Table. B.1 presents per-class results on the SynPASS benchmark. The small Trans4PASS+ model obtains 39.16% mIoU and sufficient improvements, as compared to the CNN-based HRNet model (+5.07%) and the SegFormer model (+1.92%). Besides, our Trans4PASS models achieve top scores on 17 of 22 classes. However, there is still a lot to be excavated on the SynPASS benchmark, such as the wall, ground, bridge, and dynamic categories, which are challenging cases in the synthetic panoramic images.\n\n\nB.3 Segmentation on the SynPASS benchmark\n\nA montage of panoramic semantic segmentation results generated from the validation set of the SynPASS dataset is presented in Fig. B.3. Compared with the baseline PVTv2 model [138], our Trans4PASS+ model is more robust against adverse situations and obtains more accurate segmentation results, such as the pedestrian in cloudy and sunny scenes, the sidewalk in the foggy and rainy scenes, and the vehicles in the night scenes.\n\n\nB.4 PIN2PAN vs. SYN2REAL visualization\n\nFor a more comprehensive analysis of the two different adaptation paradigms, additional visualization samples are shown in Fig. B.4. In the first case, before MPA, there is not a significant deformation in the target-domain sidewalk highlighted by the blue box, thus, the pinhole-trained model obtains more accurate segmentation results than the synthetic-trained model. That means if no distortion appears, the pinhole-trained model benefits more from the same realistic scene appearance as the target domain and can perform better than the synthetic-trained model. However, in the second case before MPA, the situation is reversed due to the existence of distortion in the highlighted sidewalk from the target domain, which appears in an uncommon position compared to that in the pinhole domain. At this point, the synthetic-source trained model benefits more from the similar shape and position prior   as in the target domain sidewalk. Nonetheless, after our MPA, both paradigms obtain more complete and accurate segmentation results. This verifies the effectiveness of our proposed mutual prototypical adaptation strategy, which jointly uses ground-truth labels from the source and pseudo-labels from the target, and drives the domain alignment on the feature and output spaces.\n\n\nB.5 Failure Case Analysis\n\nSome failure cases of panoramic semantic segmentation are presented in Fig. B.5. Some erroneous segmentation samples from the three models are presented in Fig. B.5. In the outdoor scene, while the PVTv2 baseline [138] recognizes the truck as a car, the Trans4PASS model can only segment a part of the truck. All three models have difficulty segmenting the building that looks similar to a truck. In the indoor scene, the baseline and the Trans4PASS+ model fail to differentiate between the distorted door and wall, as both are similar in appearance and shape in this case. This issue can potentially be addressed by using complementary panoramic depth information to obtain discriminative features. \n\nFig. 2 :\n2Performance gains of Trans4PASS+ in the settings of Source-Only (SO) and panoramic Unsupervised Domain Adaptation (UDA), transferring from Stanford2D3D Pinhole to Panoramic (SPin SPan) and from Cityscapes to DensePASS (CS DP) domains.\n\nFig. 3 :\n3Domain adaptations for panoramic semantic segmentation include Pinhole-to-Panoramic (PIN2PAN) and Synthetic-to-Real (SYN2REAL) paradigms in both indoor and outdoor scenarios. The feature distributions between the target domain and two source domains are compared in the tSNE-reduced manifold space, including sidewalks and floors. The marginal distributions are plotted along respective axes.\n\nFig. 4 :\n4Comparison of segmentation transformers. Transformers (a) borrow an FPN-like decoder[14] from CNN counterparts or (b) adopt a vanilla-MLP decoder[52] for feature fusion. (c) Trans4PASS integrates Deformable Patch Embeddings (DPE) and the Deformable MLP (DMLP) module for capabilities to handle distortions (see warped terrain) and mix patches.panoramic semantic segmentation task. Considering the tradeoff between efficiency and accuracy, there are two different model sizes: the tiny (T) model and the small (S) model. Following traditional CNN/Transformer models[12],[52],[108], both versions of Trans4PASS keep the multi-scale pyramid feature structure in the form of four stages. The layer numbers of four stages in the tiny model are {2, 2, 2, 2}, while in the small model, they are {3, 4, 6, 3}. In one segmentation process, given an input image in the shape of H\u00d7W \u00d73, the Trans4PASS model first performs image patchifying. The encoder gradually down-samples feature maps f l \u2208{f 1 ,f 2 ,f 3 ,f 4 } in the l th stage with strides s l \u2208{4, 8, 16, 32} and channel dimensions C l \u2208{64,128,320,512}. Then, the decoder parses multi-scale feature maps f l into a unified shape of H 4 \u00d7 W 4 \u00d7C emb , where the number of resulting embedding channels is set as C emb =128. Finally, a prediction layer outputs the final semantic segmentation result according to the number of semantic classes of the respective task, and with the same size as the input image.\n\nFig. 5 :\n5Comparison of MLP modules. The spatial offsets of DMLP are learned adaptively from the input feature map.\n\nFig. 6 :\n6Comparison of token mixing structures. PE: Patch Embedding, DPE: Deformable PE, Self-Attn: Self-Attention, CX: Channel Mixer, PX: Pooling Mixer, and DMLP: Deformable MLP.\n\nFig. 7 :\n7Diagram of Mutual Prototypical Adaptation (MPA).\n\nFig. 9 :\n9Distributions of SynPASS, DensePASS, and Cityscapes in terms of class-wise pixel counts per image. We use the logarithmic scaling of the vertical axis and insert the pixel count above the bar. There are 13 classes overlapping across three datasets.\n\n( 1 )\n1Indoor Panoramic and Real dataset as the target domain: Stanford2D3D[18] Panoramic (SPan) has 1,413 panoramas and 13 classes. Results are averaged by the official three folds, following[18] unless otherwise stated.(2) Indoor Pinhole and Real dataset as the first source domain:Stanford2D3D[18] Pinhole (SPin) has 70,496 pinhole images and the same 13 classes as its panoramic dataset.(3) Indoor Panoramic and Synthetic dataset as the second source domain: Structured3D [19] (S3D) has 21,835 synthetic panoramic images and 29 classes. (4) Outdoor Panoramic and Real dataset as the target domain: DensePASS [3] (DP) collected from cities around the world has 2,000 images for transfer optimization and 100 labeled images for testing, annotated with 19 classes. (5) Outdoor Pinhole and Real dataset as the first source domain: Cityscapes [13] (CS) has 2,979 and 500 images in the training and validation sets, and has the same 19 classes as DensePASS. (6) Outdoor Panoramic and Synthetic dataset as the second source domain: SynPASS (SP) contains 9,080 panoramic images and 22 categories. More details are in Sec. 4. Four domain adaptation settings are investigated: (1) Indoor PIN2PAN: SPin SPan. (2) Indoor SYN2REAL: S3D SPan. (3) Outdoor PIN2PAN: CS DP. (4) Outdoor SYN2REAL: SP DP. Overlapping classes. To compare PIN2PAN and SYN2REAL adaptations, only the overlapping classes are involved. The indoor datasets have 8 classes, and the outdoor datasets have 13 classes. Thus, the adaptation settings are reformed as: (1) Indoor PIN2PAN: SPin8 SPan8. (2) Indoor SYN2REAL: S3D8 SPan8. (3) Outdoor PIN2PAN: CS13 DP13.\n\nFig. 11 :\n11Omnidirectional segmentation before (light blue lines) and after (blue lines) mutual prototypical adaptation. The mIoU (%) scores in eight directions are reported.\n\nFig. 13 :Fig. 14 :\n1314Panoramic semantic segmentation visualizations. The baseline model[138] has no deformable designs. Zoom in for a better view. Visualization of using SAM-enhanced and our SAM-based MPA adaptation methods. Zoom in for a better view.\n\nFig. A. 1 :\n1Analysis of hyper-parameters on DensePASS.\n\nFig. B. 1 :\n1More panoramic semantic segmentation visualizations. Zoom in for a better view.\n\nFig. B. 2 :\n2DPE and DMLP visualizations. The \u2022 dots in four stages are sampling points shifted by learned offsets w.r.t. the \u2022 patch center of DPE (from decoder). The bottom two rows show the #75 channel maps of stage-3 before and after DMLP. Zoom in for a better view.\n\nFig. B. 3 :Fig. B. 4 :Fig. B. 5 :\n345SynPASS segmentation visualizations. Zoom in for a better view. More PIN2PAN vs. SYN2REAL visualizations before and after MPA, respectively. Zoom in for a better view. Failure case visualizations from indoor and outdoor scenarios.\n\n\nJiaming Zhang, Simon Rei\u00df, Kunyu Peng, and Rainer Stiefelhagen are with Karlsruhe Institute of Technology, Germany. \u2022 Kailun Yang is with Hunan University, China. \u2022 Jiaming Zhang and Philip H. S. Torr are with University of Oxford, UK. \u2022 Hao Shi and Kaiwei Wang are with Zhejiang University, China. \u2022 Chaoxiang Ma is with ByteDance Inc., China. \u2022 Haodong Fu is with Beihang University, China. \u2022 * corresponding author (kailun.yang@hnu.edu.cn).45 \n\n47 \n\n49 \n\n51 \n\n1 1 \n\n0\u00b01 \n5 \n0\u00b01 \n9 \n0\u00b02 \n3 \n0\u00b02 \n7 \n0\u00b03 \n1 \n0\u00b03 \n5 0\u00b0P \n\nVT Trans4PASS \nTrans4PASS+ \n\n(a) Performance of PIN2PAN \n\n37 \n\n39 \n\n41 \n\n43 \n\n1 1 0\u00b01 \n5 0\u00b01 \n9 0\u00b02 \n3 0\u00b02 \n7 0\u00b03 \n1 0\u00b03 \n5 0\u00b0P \n\nVT Trans4PASS \nTrans4PASS+ \n\n(b) Performance of SYN2REAL \n\nFig. 1: Model robustness (mIoU) against various Fields of View \n\n(FoV) in both Pinhole-to-Panoramic (PIN2PAN) and Synthetic-to-\nReal (SYN2REAL) settings. Trans4PASS+ models perform stably. \n\n58.12 \n\n53.07 \n\n52.91 \n\n49.76 \n\n56.38 \n\n48.73 \n\n52.15 \n\n48.34 \n\nCS\u2192DP, UDA \n\nCS\u2192DP, SO \n\nSPin\u2192SPan, UDA \n\nSPin\u2192SPan, SO \nTrans4PASS \nTrans4PASS+ \n\n\n\n\nFig. 8: Examples of images and semantic labels in different conditions from the established SynPASS dataset.Cloudy \nFoggy \nRainy \nSunny \nNight \n\n1.00E+1 \n\n1.00E+3 \n\n1.00E+5 \n\n1.00E+7 \n\nB u il d in \n\ng \nF e n c e \nO \nt h e r \n\nP e d e s t r ia \n\nn \nP o le \n\nR \no a d L in \n\ne \nR \no a d \n\nS id \ne W \n\na lk \n\nV e g e t a t io \n\nn \n\nV e h ic \n\nle \n\ns \nW \na ll \n\nT r a f f ic \n\nS ig \n\nn \nS k y \nG \nr o u n d \nB r id \ng e R \n\na il T r a c k \nG \nr o u n d R \n\na i \n\nT r a f f ic \n\nL ig \n\nh t \nS t a t ic D \ny n a m \n\nic \nW \na t e r \nT e r r a in \n\nSynPASS \nDensePASS \nCityscapes \n\n\n\nTABLE 1 .\n1SynPASS dataset for panoramic semantic segmentation, including four adverse weather conditions and two illuminations. Split train / val / test train / val / test train / val / test train / val / test train / val / test #Frames 1420 / 420 / 430 1420 / 430 / 420 1420 / 430 / 420 1440 / 410 / 420 5700 / 1690 / 1690Cloudy \nFoggy \nRainy \nSunny \nALL \n\nSplit \nday / night \nday / night \nday / night \nday / night \nday / night \n#Frames \n1980 / 290 \n1710 / 560 \n2040 / 230 \n1970 / 300 \n7700 / 1380 \n\nTotal \n2270 \n2270 \n2270 \n2270 \n9080 \n\n\n\nTABLE 2 .\n2SynPASS benchmark is evaluated on full 22 classes and is divided into four weather conditions, day-and night-time.Method \nCloudy Foggy Rainy Sunny Day Night \nALL \nval \nval \nval \nval \nval val val test \n\nFast-SCNN \n30.84 22.68 26.16 27.19 29.68 24.75 26.31 21.30 \nDeepLabv3+ (MNv2) 38.94 35.19 35.43 37.73 36.01 30.55 36.72 29.66 \nHRNet (W18Small) \n42.92 37.94 37.37 41.45 39.19 32.22 39.80 34.09 \n\nPVT (Tiny) \n39.92 34.99 34.01 39.84 36.71 27.36 36.83 32.37 \nPVT (Small) \n40.75 36.14 34.29 40.14 37.92 28.80 37.47 32.68 \nSegFormer (B1) \n45.34 41.43 40.33 44.36 42.97 33.15 42.68 37.36 \nSegFormer (B2) \n46.07 40.99 40.10 44.35 44.08 33.99 42.49 37.24 \nTrans4PASS (Tiny) \n46.90 41.97 41.61 45.52 44.48 34.73 43.68 38.53 \nTrans4PASS (Small) 46.74 43.49 43.39 45.94 45.52 37.03 44.80 38.57 \nTrans4PASS+ (Tiny) 47.85 43.38 43.40 46.83 45.99 36.46 45.17 39.42 \nTrans4PASS+ (Small) 48.85 44.64 45.13 48.29 46.49 37.33 46.61 40.72 \nw.r.t. SegFormer (B2) +2.78 +3.65 +5.03 +3.94 +2.41 +3.34 +4.12 +3.48 \n\n\n\nTABLE 3 .\n3Performance gaps of CNN-and transformer-based models from Cityscapes (CS) @ 1024\u00d7512 to DensePASS (DP). Trans4PASS+ * models apply DMLPv2 in Mask2Former head.Network \nBackbone \nCS \nDP mIoU Gaps \n\nSwiftNet [120] \nResNet-18 \n75.4 25.7 \n-49.7 \nFast-SCNN [119] \nFast-SCNN \n69.1 24.6 \n-44.5 \nERFNet [121] \nERFNet \n72.1 16.7 \n-55.4 \nFANet [122] \nResNet-34 \n71.3 26.9 \n-44.4 \nPSPNet [33] \nResNet-50 \n78.6 29.5 \n-49.1 \nOCRNet [123] \nHRNetV2p-W18 \n78.6 30.8 \n-47.8 \nDeepLabV3+ [29] \nResNet-101 \n80.9 32.5 \n-48.4 \nDANet [40] \nResNet-101 \n80.4 28.5 \n-51.9 \nDNL [124] \nResNet-101 \n80.4 32.1 \n-48.3 \nSemantic-FPN [125] ResNet-101 \n75.8 28.8 \n-47.0 \nResNeSt [126] \nResNeSt-101 \n79.6 28.8 \n-50.8 \nOCRNet [123] \nHRNetV2p-W48 \n80.7 32.8 \n-47.9 \n\nSETR-Naive [14] \nTransformer-L \n77.9 36.1 \n-41.8 \nSETR-MLA [14] \nTransformer-L \n77.2 35.6 \n-41.6 \nSETR-PUP [14] \nTransformer-L \n79.3 35.7 \n-43.6 \nSegFormer [52] \nSegFormer-B1 \n78.5 38.5 \n-40.0 \nSegFormer [52] \nSegFormer-B2 \n81.0 42.4 \n-38.6 \nTrans4PASS \nTrans4PASS (T) \n79.1 41.5 \n-37.6 \nTrans4PASS \nTrans4PASS (S) \n81.1 44.8 \n-36.3 \nMaskFormer [53] \nSegFormer-B1 \n66.9 35.0 \n-31.9 \nMaskFormer [53] \nSegFormer-B2 \n78.8 46.1 \n-32.7 \nMask2Former [127] \nSegFormer-B1 \n77.6 46.5 \n-31.1 \nMask2Former [127] \nSegFormer-B2 \n80.2 46.4 \n-33.8 \nTrans4PASS+ \nTrans4PASS+ (T) \n78.6 41.6 \n-37.0 \nTrans4PASS+ \nTrans4PASS+ (S) \n80.7 46.5 \n-34.2 \nTrans4PASS+  *  \nTrans4PASS+ (T) \n77.8 46.8 \n-31.0 \nTrans4PASS+  *  \nTrans4PASS+ (S) \n79.6 48.4 \n-31.2 \n\n\n\nTABLE 4 .\n4Performance gaps from Stanford2D3D-Pinhole (SPin) to Stanford2D3D-Panoramic (SPan) dataset on fold-1.Network \nBackbone \nSPin \nSPan mIoU Gaps \n\nFast-SCNN [119] \nFast-SCNN \n41.71 26.86 \n-14.85 \nSwiftNet [120] \nResNet-18 \n42.28 34.95 \n-7.87 \nDANet [40] \nResNet-50 \n43.33 37.76 \n-5.57 \nDANet [40] \nResNet-101 \n40.09 31.81 \n-8.28 \n\nTrans4Trans-T [128] PVT-T \n41.28 24.45 \n-16.83 \nTrans4Trans-S [128] \nPVT-S \n44.47 23.11 \n-21.36 \nTrans4PASS (T) \nTrans4PASS (T) \n49.05 46.08 \n-2.97 \nTrans4PASS (S) \nTrans4PASS (S) \n50.20 48.34 \n-1.86 \nTrans4PASS+ (T) \nTrans4PASS+ (T) \n48.69 46.32 \n-2.37 \nTrans4PASS+ (S) \nTrans4PASS+ (S) \n51.48 49.76 \n-1.72 \n\nreaches 81.1% in mIoU on Cityscapes, but more importantly, it \nattains a clearly higher performance of 44.8% on DensePASS. \nTrans4PASS+ further enhances the performance on the target \npanoramic dataset with a mIoU of 46.5% for Trans4PASS+ \n(S) and the mIoU gap decreases to 34.2%. When combining \nMask2Former [127], our small model achieves the highest 48.4% \nwith additional +2.0% mIoU gains on the DensePASS dataset, \nshowing the flexibility and effectiveness of the new proposed \nDMLPv2 modules. These results reveal that both distortion-aware \nfeatures and omni-range dependencies learned in both shallow-\nand high levels of vision transformers, as opposed to the context \nmodeled only in higher levels of CNNs, are critical for wide-FoV \nomnidirectional semantic segmentation. \nThen, we look into the PIN2PAN domain gap in indoor scenes, \nas analyzed in \n\nTABLE 5 .\n5SYN2REAL vs. PIN2PAN domain gaps.1 Outdoor PIN2PAN: \nCS13 \nDP13 \nmIoU Gaps \n\nPVT (Tiny) \n63.70 \n44.04 \n-19.66 \nPVT (Small) \n65.88 \n46.19 \n-19.69 \nTrans4PASS (Tiny) \n71.63 \n49.21 (+5.17) \n-22.42 \nTrans4PASS (Small) \n75.21 \n50.96 (+4.77) \n-24.25 \nTrans4PASS+ (Tiny) \n74.82 \n49.27 (+5.23) \n-25.55 \nTrans4PASS+ (Small) \n77.04 \n51.48 (+5.29) \n-25.56 \n\n2 Outdoor SYN2REAL: \nSP13 \nDP13 \nmIoU Gaps \n\nPVT (Tiny) \n51.05 \n35.26 \n-15.79 \nPVT (Small) \n52.94 \n38.74 \n-14.20 \nTrans4PASS (Tiny) \n61.08 \n39.68 (+4.42) \n-21.40 \nTrans4PASS (Small) \n62.76 \n43.18 (+4.44) \n-19.58 \nTrans4PASS+ (Tiny) \n62.92 \n40.40 (+5.14) \n-22.52 \nTrans4PASS+ (Small) \n63.21 \n43.83 (+5.09) \n-19.38 \n\n3 Indoor PIN2PAN: \nSPin8 \nSPan8 \nmIoU Gaps \n\nPVT (Tiny) \n59.70 \n53.98 \n-5.72 \nPVT (Small) \n60.46 \n57.71 \n-2.75 \nTrans4PASS (Tiny) \n64.25 \n58.93 (+4.95) \n-5.32 \nTrans4PASS (Small) \n66.51 \n62.39 (+4.68) \n-4.12 \nTrans4PASS+ (Tiny) \n66.41 \n61.48 (+7.50) \n-4.93 \nTrans4PASS+ (Small) \n67.28 \n63.73 (+6.02) \n-3.55 \n\n4 Indoor SYN2REAL: \nS3D8 \nSPan8 \nmIoU Gaps \n\nPVT (Tiny) \n68.90 \n42.04 \n-26.86 \nPVT (Small) \n66.46 \n45.82 \n-20.64 \nTrans4PASS (Tiny) \n76.84 \n48.63 (+6.59) \n-28.21 \nTrans4PASS (Small) \n77.29 \n51.70 (+5.88) \n-25.59 \nTrans4PASS+ (Tiny) \n77.03 \n50.29 (+8.25) \n-26.74 \nTrans4PASS+ (Small) \n76.04 \n52.09 (+6.27) \n-23.95 \n\n\n\nTABLE 6 .\n6Comparison of SYN2REAL transfer learning between methods followed Structured3D[19]. Synthetic: S3D8, Real: SPan8.Indoor SYN2REAL: \nData \nS3D8 \nSPan8 \n\nUPerNet (ResNet-50) \nSynthetic \n-\n28.75 \nUPerNet (ResNet-50) \nSynthetic+Real \n-\n49.60 \nHRNet (W18) \nSynthetic \n-\n37.92 \nHRNet (W18) \nSynthetic+Real \n-\n52.00 \n\nTrans4PASS+ (Tiny) \nSynthetic \n77.03 \n50.29 \nTrans4PASS+ (Small) \nSynthetic \n76.04 \n52.09 \n\n\n\nTABLE 7 .\n7Ablation study of Trans4PASS+, including DEP, DMLPv1,and DMLPv2. Models are trained on Cityscapes (CS) @ 512\u00d7512 and \ntested on DensePASS (DP) @ 2048\u00d7400. #P: #parameters in millions. \n\nDPE DMLPv1 DMLPv2 \nGFLOPs \n#P \nCS \nDP \n\n13.27 \n13.66 74.93 39.02 \n\u2713 \n11.82 \n13.92 73.10 45.14 \n\u2713 \n11.53 \n13.94 65.86 46.94 \n\n\u2713 \n08.90 \n13.29 71.70 43.11 \n\u2713 \n\u2713 \n12.02 \n13.93 72.49 45.89 \n\u2713 \n\u2713 \n11.74 \n13.96 72.63 49.94 \n\npanoramic images are captured from the Stanford2D3D dataset \nunder the same setting. In contrast, transferring from the synthetic \nS3D8 dataset to real SPan8 (Table 5-4 ) causes a mIoU gap \nof >20%. Yet, we find that Trans4PASS+, with parallel token \nmixing, attains smaller SYN2REAL mIoU gaps than Trans4PASS. \n\n\nTABLE 8 .\n8Ablation study of PX and CX in DMLPv2 of Trans4PASS+. CX: Channel Mixer, PX: Pooling Mixer.PX \nCX \nGFLOPs \n#P \nCS \nDP \n\n13.27 \n13.66 \n74.93 \n39.02 \n\u2713 \n10.22 \n13.60 \n72.62 \n46.66 \n\u2713 \n10.96 \n13.78 \n74.07 \n47.66 \n\u2713 \n\u2713 \n11.74 \n13.96 \n72.63 \n49.94 \n\n\n\nTABLE 9 .\n9Comparison of different PE and MLP methods.Fig. 10: Analysis of single-/multi-scale pooling operations and combinations in DMLPv2 module. {s} means a s\u00d7s pooling.PE \nMLP \nGFLOPs \n#P \nCS \nDP \n\nVanilla PE \nVanilla MLP \n13.27 \n13.66 74.93 39.02 \n\nDPT [25] \nDMLPv1 \n13.11 \n13.10 69.48 36.50 \nVanilla PE \nDMLPv1 \n11.82 \n13.92 73.10 45.14 \nDPE \nDMLPv1 \n12.02 \n13.93 72.49 45.89 \n\nDPE \nVanilla MLP \n08.90 \n13.29 71.70 43.11 \nDPE \nCycleMLP [22] \n09.83 \n13.60 73.49 40.16 \nDPE \nASMLP [23] \n13.40 \n14.19 73.65 42.05 \nDPE \nDMLPv1 \n12.02 \n13.93 72.49 45.89 \nDPE \nDMLPv2 \n11.74 \n13.96 72.63 49.94 \n\nDeformable Conv DMLPv2 \n11.70 \n13.95 72.20 45.74 \nVanilla PE \nDMLPv2 \n11.54 \n13.94 73.39 47.08 \nDPE \nDMLPv2 \n11.74 \n13.96 72.63 49.94 \n\n44 \n\n46 \n\n48 \n\n50 \n\n52 \n\n64 \n\n66 \n\n68 \n\n70 \n\n72 \n\n74 \n\n{3} \n{5} \n{7} \n{11} \n{3,5,7} {3,5,11} {5,7,11} \n\nCityscapes \nDensePASS \n\ngains compared with the baseline. However, coupled with both PX \nand CX, our Trans4PASS+ model with DMLPv2 strikingly boosts \nthe mIoU on DensePASS to 49.94% in mIoU, having +10.92% \ngains over the baseline. It shows that PX and CX both contribute \nsignificantly, forming an effective parallel token mixing to unleash \nthe potential of Trans4PASS+ in handling panoramas. \nAnalysis of multi-scale pooling. To verify the pooling operation \nselections, we conduct seven variants in the DMLPv2 module, \nwhich include four single pooling and three multi-scale pooling \ncombinations. In Fig. 10, we found that the multi-scale pooling of \n{3,5,11} achieves a better performance on the DensePASS dataset. \nComparison of PE and MLP methods. In Table 9, we per-\nform a comprehensive comparison between various PE and MLP \nmethods. Compared to the baseline with vanilla PE and vanilla \nMLP, our DPE with DMLPv1 improves the panoramic segmen-\ntation from 39.02% to 45.89% with +6.87% gains in mIoU \non the DensePASS dataset. While DPT \n\nTABLE 10 .\n10Comparison of different token mixing methods.GFLOPs \n#P \nCS \nDP \n\nPoolFormer [21] \n09.47 \n13.47 \n70.52 \n43.18 \nFAN [24] \n10.96 \n13.81 \n71.15 \n42.54 \nPoolFormer+FAN \n10.96 \n13.81 \n72.21 \n45.97 \nDMLPv2 \n11.74 \n13.96 \n72.63 \n49.94 \n\n\n\nTable 11a ,\n11aour Trans4PASS+ models harvest top segmentation IoU scores on 11 out of all 19 categories. Ablation on DensePASS. To confirm the generalization capacity of applying Trans4PASS in adaptation methods, FANet [122] andTrans4PASS+ \n51.23% \n48.85% \n49.04% \n46.75% \n53.55% \n51.63% \n53.92% \n53.78% \n\nTrans4PASS+ (MPA) \n54.39% \n51.17% \n50.97% \n50.74% \n56.28% \n55.15% \n56.56% \n58.19% \n\n\n\nTABLE 11 .\n11Comparisons and ablation studies of PIN2PAN domain adaptation in indoor and outdoor scenarios.Method \nmIoU \nRoad \nS.walk \nBuild. \nWall \nFence \nPole \nTr. light \nTr. sign \nVeget. \nTerrain \nSky \nPerson \nRider \nCar \nTruck \nBus \nTrain \nM.cycle \nBicycle \n\nERFNet [121] \n16.65 63.59 18.22 47.01 9.45 12.79 17.00 8.12 6.41 34.24 10.15 18.43 4.96 2.31 46.03 3.19 0.59 0.00 8.30 5.55 \nPASS (ERFNet) [10] \n23.66 67.84 28.75 59.69 19.96 29.41 8.26 4.54 8.07 64.96 13.75 33.50 12.87 3.17 48.26 2.17 0.82 0.29 23.76 19.46 \nECANet (Omni-supervised) [9] 43.02 81.60 19.46 81.00 32.02 39.47 25.54 3.85 17.38 79.01 39.75 94.60 46.39 12.98 81.96 49.25 28.29 0.00 55.36 29.47 \n\nCLAN (Adversarial) [15] \n31.46 65.39 21.14 69.10 17.29 25.49 11.17 3.14 7.61 71.03 28.19 55.55 18.86 2.76 71.60 26.42 17.99 59.53 9.44 15.91 \nMIC (Self-training) [129] \n31.65 62.94 26.19 71.90 11.41 19.44 20.16 01.77 11.41 69.06 25.24 93.76 30.01 07.64 65.00 26.97 0.78 19.28 27.98 10.50 \nCRST (Self-training) [16] \n31.67 68.18 15.72 76.78 14.06 26.11 9.90 0.82 2.66 69.36 21.95 80.06 9.71 1.25 65.12 38.76 27.22 48.85 7.10 18.08 \nHRDA (Adversarial) [130] \n38.84 69.77 29.57 73.90 18.40 18.99 19.73 3.09 8.34 72.69 18.63 93.11 37.82 12.82 73.65 50.22 21.39 59.35 46.15 10.29 \nP2PDA (Adversarial) [20] \n41.99 70.21 30.24 78.44 26.72 28.44 14.02 11.67 5.79 68.54 38.20 85.97 28.14 0.00 70.36 60.49 38.90 77.80 39.85 24.02 \nSIM (Self-training) [101] \n44.58 68.16 32.59 80.58 25.68 31.38 23.60 19.39 14.09 72.65 26.41 87.88 41.74 16.09 73.56 47.08 42.81 56.35 47.72 39.30 \nPCS (Self-training) [106] \n53.83 78.10 46.24 86.24 30.33 45.78 34.04 22.74 13.00 79.98 33.07 93.44 47.69 22.53 79.20 61.59 67.09 83.26 58.68 39.80 \nDAFormer (Self-training) [26] 54.56 71.96 27.70 87.49 36.70 45.17 35.55 28.58 13.69 79.24 26.62 94.95 54.59 21.51 77.99 70.90 56.40 94.47 65.34 47.73 \n\nUSSS (IDD) [131] \n26.98 68.85 5.41 67.39 15.10 21.79 13.18 0.12 7.73 70.27 8.84 85.53 22.05 1.71 58.69 16.41 12.01 0.00 23.58 13.90 \nUSSS (Mapillary) [131] \n30.87 71.01 31.85 76.79 12.13 23.61 11.93 3.23 10.15 73.11 31.24 89.59 16.05 3.86 65.27 24.46 18.72 0.00 9.08 14.48 \nSeamless (Mapillary) [132] \n34.14 59.26 24.48 77.35 12.82 30.91 12.63 15.89 17.73 75.61 33.30 87.30 19.69 4.59 63.94 25.81 57.16 0.00 11.59 19.04 \nSwiftNet (Cityscapes) [120] \n25.67 50.73 32.76 70.24 12.63 24.02 18.79 7.18 4.01 64.93 23.70 84.29 14.91 0.97 43.46 8.92 0.04 4.45 12.77 8.77 \nSwiftNet (Merge3) [133] \n32.04 68.31 38.59 81.48 15.65 23.91 20.74 5.95 0.00 70.64 25.09 90.93 32.66 0.00 66.91 42.30 5.97 0.07 6.85 12.66 \n\nTrans4PASS (S) (ours) \n55.25 78.39 41.62 86.47 31.56 45.47 34.02 22.98 18.33 79.63 41.35 93.80 49.02 22.99 81.05 67.43 69.64 86.04 60.85 39.20 \nTrans4PASS (S) (ours)* \n56.38 79.91 42.68 86.26 30.68 42.32 36.61 24.81 19.64 78.80 44.73 93.84 50.71 24.39 81.72 68.86 66.18 88.62 63.87 46.62 \nTrans4PASS+ (S) (ours) \n57.03 79.74 50.27 86.59 29.57 44.38 29.82 24.81 18.51 79.25 45.91 93.34 52.68 25.00 81.15 70.35 76.80 89.08 63.83 42.45 \nTrans4PASS+ (S) (ours)* \n59.43 82.02 55.24 86.71 28.97 47.94 30.67 28.03 19.75 80.01 45.42 94.20 56.35 37.79 84.16 70.44 72.95 91.40 67.92 49.12 \n\n\n\nTABLE 12 .\n12PIN2PAN and SYN2REAL domain adaptation results and comparisons in both indoor and outdoor scenarios.Network \nMethod \nmIoU Road S.walk Build. Wall Fence Pole Tr. light Tr. sign Veget. Terrain Sky Person Car \n\n(1) Outdoor PIN2PAN: CS13\u2192DP13 \nTrans4PASS+ (S) Source-only 51.48 76.45 40.52 86.16 28.70 43.77 26.93 15.75 \n16.71 \n79.91 32.48 93.76 49.21 78.87 \nTrans4PASS+ (S) \nMPA \n55.24 82.25 54.74 85.80 31.55 47.24 31.44 21.95 \n17.45 \n79.05 45.07 93.42 50.12 78.04 \n\n(2) Outdoor SYN2REAL: SP13\u2192DP13 \nTrans4PASS+ (S) Source-only 43.83 70.26 42.36 80.22 12.88 20.55 19.32 17.01 \n03.44 \n71.43 31.28 90.14 44.64 66.21 \nTrans4PASS+ (S) \nMPA \n50.88 77.74 51.39 82.53 29.33 43.37 25.18 20.09 \n08.37 \n76.36 41.56 91.07 45.43 68.98 \n\n(a) Per-class results in CS13\u2192DP13 and SP13\u2192DP13, before and after MPA. \n\nNetwork \nMethod \nmIoU \nCeiling \nChair \nDoor \nFloor \nSofa \nTable \nWall \nWindow \n\n(3) Indoor PIN2PAN: SPin8\u2192SPan8 \nTrans4PASS+ (S) \nSource-only \n63.73 \n90.63 \n62.30 \n24.79 \n92.62 \n35.73 \n73.16 \n78.74 \n51.78 \nTrans4PASS+ (S) \nMPA \n67.16 \n90.04 \n64.04 \n42.89 \n91.74 \n38.34 \n71.45 \n81.24 \n57.54 \n\n(4) Indoor SYN2REAL: S3D8\u2192SPan8 \nTrans4PASS+ (S) \nSource-only \n51.75 \n85.37 \n49.90 \n09.63 \n89.75 \n21.40 \n32.10 \n71.49 \n54.34 \nTrans4PASS+ (S) \nMPA \n52.73 \n85.86 \n52.89 \n15.30 \n90.74 \n07.83 \n37.78 \n71.15 \n60.24 \n\n(b) Per-class results in SPin8\u2192SPan8 and S3D8\u2192SPan8, before and after MPA. \n\n\n\n\nwhich are successfully recognized via the PIN2PAN model that exploits the rich textures learned from pinhole realistic scenes, as the pinhole-source and panoramic-target domains are close in another dimension encoding appearance cues. Yet, after MPA-based domain adaptation, the PIN2PAN model ( 2 ) can also seamlessly detect the sidewalk, which indicates that our distortion-Fig. 15: PIN2PAN vs. SYN2REAL visualizations before and after MPA, respectively. The black areas indicate misprediction., where the \nmarginal distributions of the synthetic and real domains are close \nin one dimension encoding information like deformed shapes and \npositional priors. Yet, the SYN2REAL model cannot identify the \ntraffic signs, RGB \nGT \n\nPin2Pan before \nPin2Pan after \n\nSyn2Real before \nSyn2Real after \n\nSyn2Real MPA \n\nPin vs. Syn before MPA \nPin vs. Syn after MPA \n\nPin2Pan MPA \n\n1 \n2 \n\n3 \n4 \n\n3 \n\n1 \n2 \n\n4 \n\n\n\n\nTransformer for PAnoramic Semantic Segmentation (Trans4PASS) architecture to revitalize 360 \u2022 scene understanding. The Deformable Patch Embedding (DPE) and the Deformable MLP (DMLP) modules empower Trans4PASS with distortion awareness. A Mutual Prototypical Adaptation (MPA) strategy is introduced for transferring semantic information from the labelrich source domain to the label-scarce target domain, by combining source labels and target pseudo-label for feature alignment inFig. 16: t-SNE visualizations before and after domain adaptation in outdoor scenes. are the prototype of source or target domain and represents the mutual prototype. Zoom in for a better view.feature and output space. A new dataset, termed SynPASS, is created. It enables the supervised training of panoramic segmentation models, and it further provides an alternative Synthetic-to-Real (SYN2REAL) domain adaptation paradigm, which is compared to the Pinhole-to-Panoramic (PIN2PAN) adaptation scenario. The framework obtains state-of-the-art accuracy on four competitive domain adaptive panoramic semantic segmentation benchmarks.Sidewalk \nBuidling \nWall \nFence \nPole \nTerrain \nSky \nPerson \nRider \nCar \nTruck \nBus \n\nVoid \nRoad \nTraffic Light Traffic Sign Vegetation \nTrain \nMotorcycle \nBicycle \n\n(a) Source before \n(b) Target before \n(c) Mutual before \n\n(d) Source after \n(e) Target after \n(f) Mutual after \n\n\n\n\nTable A.1 shows that r=4 has a better result, and we set it as default in our experiments.\n\nTABLE A .\nA1. Effect of regional restriction (r) on DensePASS.None \nr=1 \nr=2 \nr=4 \nr=8 \n\nmIoU(%) \n45.74 \n44.51 \n45.59 \n45.89 \n45.57 \n\nAlpha (\u03b1) \nTemperature (\u03a4) \n\n0.1 \n54.25 \n100 \n54.9 \n\n0.01 \n54.33 \n35 \n54.89 \n\n0.001 \n54.9 \n20 \n55.25 \n\n0.0001 \n54.7 \n10 \n54.96 \n\n0 \n54.67 \n1 \n54.95 \n\n\n\n\n.2. The comparison indicates that our methods have better results with the same order of complexity.TABLE A.2. Computational complexity. GFLOPs @512\u00d7512. PE [52] DPE DPT [25] CycleMLP [22] ASMLP [23] DMLP DMLPv2GFLOPs \n0.16 0.36 \n7.65 \n1.25 \n4.83 \n3.45 \n3.13 \n#Params(M) 0.01 0.02 \n2.90 \n0.45 \n1.04 \n0.79 \n0.80 \n\nmIoU(%) 45.14 49.94 36.50 \n40.16 \n42.05 \n45.89 49.94 \n\n\n\nTABLE B . 1 .\nB1Per-class results on the test set of the SynPASS benchmark. MobileNetv2) 29.66 75.14 11.50 00.00 25.04 11.05 39.90 89.19 43.73 62.44 62.41 01.59 00.00 91.86 00.54 00.01 26.13 43.72 08.30 12.67 01.06 05.03 41.21 HRNet (W18Small) 34.09 75.94 28.76 00.00 29.59 23.74 59.21 91.68 52.63 63.94 64.63 00.70 00.00 93.02 00.81 00.01 27.42 65.54 08.08 16.32 01.10 03.80 42.99 PVT (Tiny) 32.37 74.83 19.94 00.24 21.82 13.15 62.59 93.14 49.09 67.27 46.44 01.69 09.63 96.09 00.18 02.64 08.81 61.11 14.09 12.04 00.99 05.05 51.33 PVT (Small) 32.68 78.02 27.12 00.27 23.48 16.51 59.81 92.87 50.21 66.22 43.50 01.12 08.67 96.34 00.44 00.15 02.82 63.88 13.78 15.15 01.58 08.78 48.29 SegFormer (B1) 37.36 78.24 20.59 00.00 38.28 21.09 68.72 94.50 59.72 68.43 67.51 00.83 09.86 96.08 00.56 01.38 20.79 69.59 23.38 19.91 01.38 08.97 52.07 SegFormer (B2) 37.24 79.25 23.58 00.00 40.01 20.14 65.28 92.80 46.92 68.64 77.45 01.42 15.00 96.33 00.57 00.58 02.68 67.60 25.86 20.80 01.99 20.92 51.53 Trans4PASS (Tiny) 38.53 79.17 28.18 00.13 36.04 23.69 69.16 95.51 61.71 69.77 71.12 01.53 16.98 96.50 00.56 01.60 15.22 70.48 26.03 23.11 02.08 09.24 49.77 Trans4PASS (Small) 38.57 80.02 24.56 00.07 41.49 25.23 72.00 95.89 59.88 69.07 77.08 01.04 13.72 96.69 00.67 00.73 05.60 72.56 25.93 22.45 02.78 08.34 52.65 Trans4PASS+ (Tiny) 39.42 79.63 24.45 00.21 44.23 26.71 70.32 95.86 61.80 69.25 78.85 01.09 13.81 97.12 00.91 03.48 19.32 72.44 21.08 25.56 02.67 05.03 53.20 Trans4PASS+ (Small) 40.72 80.91 20.78 00.23 45.36 24.08 72.51 96.79 67.15 70.46 81.39 04.28 26.19 97.21 01.24 01.74 16.56 67.08 28.64 23.68 03.35 08.48 57.57Method \nmIoU \nBuilding \nFence \nOther \nPedestrian \n\nPole \nRoadLine \n\nRoad \nSideWalk \nVegetation \nVehicles \n\nWall \nTrafficSign \n\nSky \nGround \nBridge \nRailTrack \nGroundRail \nTrafficLight \n\nStatic \nDynamic \nWater \nTerrain \n\nFast-SCNN (Fast-SCNN) \n21.30 64.14 10.22 00.00 00.08 07.77 26.68 80.63 33.87 60.93 32.91 00.14 00.00 89.61 01.37 00.01 03.80 20.81 00.00 01.02 00.00 00.01 34.68 \nDeepLabv3+ (Stage-1 DPE \n\nStage-2 DPE \n\nStage-3 DPE \n\nStage-4 DPE \n\nStage-1 DPE \n\nStage-2 DPE \n\nStage-3 DPE \n\nStage-4 DPE \n\nBefore DMLP \nBefore DMLP \n\nAfter DMLP \nAfter DMLP \n\nRGB \nRGB \n\n\n. MMSegmentation: https://github.com/open-mmlab/mmsegmentation.\n\nIs context-aware CNN ready for the surroundings? Panoramic semantic segmentation in the wild. K Yang, X Hu, R Stiefelhagen, TIP. 301K. Yang, X. Hu, and R. Stiefelhagen, \"Is context-aware CNN ready for the surroundings? Panoramic semantic segmentation in the wild,\" TIP, vol. 30, pp. 1866-1881, 2021. 1\n\nEliminating the blind spot: Adapting 3D object detection and monocular depth estimation to 360 \u2022 panoramic imagery. G P De La Garanderie, A A Abarghouei, T P Breckon, ECCV. G. P. de La Garanderie, A. A. Abarghouei, and T. P. Breckon, \"Eliminat- ing the blind spot: Adapting 3D object detection and monocular depth estimation to 360 \u2022 panoramic imagery,\" in ECCV, 2018. 1\n\nDenseP-ASS: Dense panoramic semantic segmentation via unsupervised domain adaptation with attention-augmented context exchange. C Ma, J Zhang, K Yang, A Roitberg, R Stiefelhagen, ITSC. 811C. Ma, J. Zhang, K. Yang, A. Roitberg, and R. Stiefelhagen, \"DenseP- ASS: Dense panoramic semantic segmentation via unsupervised domain adaptation with attention-augmented context exchange,\" in ITSC, 2021. 1, 2, 3, 7, 8, 11\n\nReview on panoramic imaging and its applications in scene understanding. S Gao, K Yang, H Shi, K Wang, J Bai, TIM. 713S. Gao, K. Yang, H. Shi, K. Wang, and J. Bai, \"Review on panoramic imaging and its applications in scene understanding,\" TIM, vol. 71, pp. 1-34, 2022. 1, 3\n\nPredicting head movement in panoramic video: A deep reinforcement learning approach. M Xu, Y Song, J Wang, M Qiao, L Huo, Z Wang, TPAMI. 4111M. Xu, Y. Song, J. Wang, M. Qiao, L. Huo, and Z. Wang, \"Predicting head movement in panoramic video: A deep reinforcement learning approach,\" TPAMI, vol. 41, no. 11, pp. 2693-2708, 2019. 1\n\nSpherical DNNs and their applications in 360 \u2022 images and videos. Y Xu, Z Zhang, S Gao, TPAMI. 4410Y. Xu, Z. Zhang, and S. Gao, \"Spherical DNNs and their applications in 360 \u2022 images and videos,\" TPAMI, vol. 44, no. 10, pp. 7235-7252, 2022. 1\n\nDeep learning for omnidirectional vision: A survey and new perspectives. H Ai, Z Cao, J Zhu, H Bai, Y Chen, L Wang, arXiv:2205.10468arXiv preprintH. Ai, Z. Cao, J. Zhu, H. Bai, Y. Chen, and L. Wang, \"Deep learning for omnidirectional vision: A survey and new perspectives,\" arXiv preprint arXiv:2205.10468, 2022. 1\n\nHoHoNet: 360 indoor holistic understanding with latent horizontal features. C Sun, M Sun, H.-T Chen, CVPR. 1112C. Sun, M. Sun, and H.-T. Chen, \"HoHoNet: 360 indoor holistic understanding with latent horizontal features,\" in CVPR, 2021. 1, 3, 11, 12\n\nCapturing omni-range context for omnidirectional segmentation. K Yang, J Zhang, S Rei\u00df, X Hu, R Stiefelhagen, CVPR. 12K. Yang, J. Zhang, S. Rei\u00df, X. Hu, and R. Stiefelhagen, \"Capturing omni-range context for omnidirectional segmentation,\" in CVPR, 2021. 1, 2, 11, 12\n\nPASS: Panoramic annular semantic segmentation. K Yang, X Hu, L M Bergasa, E Romera, K Wang, T-ITS. 211012K. Yang, X. Hu, L. M. Bergasa, E. Romera, and K. Wang, \"PASS: Panoramic annular semantic segmentation,\" T-ITS, vol. 21, no. 10, pp. 4171-4185, 2020. 1, 2, 11, 12\n\nBending reality: Distortion-aware transformers for adapting to panoramic semantic segmentation. J Zhang, K Yang, C Ma, S Rei\u00df, K Peng, R Stiefelhagen, CVPR. 1J. Zhang, K. Yang, C. Ma, S. Rei\u00df, K. Peng, and R. Stiefelhagen, \"Bend- ing reality: Distortion-aware transformers for adapting to panoramic semantic segmentation,\" in CVPR, 2022. 1, 2\n\nPyramid vision transformer: A versatile backbone for dense prediction without convolutions. W Wang, E Xie, X Li, D Fan, K Song, D Liang, T Lu, P Luo, L Shao, ICCV. 13W. Wang, E. Xie, X. Li, D. Fan, K. Song, D. Liang, T. Lu, P. Luo, and L. Shao, \"Pyramid vision transformer: A versatile backbone for dense prediction without convolutions,\" in ICCV, 2021. 1, 3, 4, 8, 9, 13\n\nThe cityscapes dataset for semantic urban scene understanding. M Cordts, M Omran, S Ramos, T Rehfeld, M Enzweiler, R Benenson, U Franke, S Roth, B Schiele, CVPR. 72M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benen- son, U. Franke, S. Roth, and B. Schiele, \"The cityscapes dataset for semantic urban scene understanding,\" in CVPR, 2016. 2, 7, 8\n\nRethinking semantic segmentation from a sequence-to-sequence perspective with transformers. S Zheng, J Lu, H Zhao, X Zhu, Z Luo, Y Wang, Y Fu, J Feng, T Xiang, P H S Torr, L Zhang, CVPR. 89S. Zheng, J. Lu, H. Zhao, X. Zhu, Z. Luo, Y. Wang, Y. Fu, J. Feng, T. Xiang, P. H. S. Torr, and L. Zhang, \"Rethinking semantic segmen- tation from a sequence-to-sequence perspective with transformers,\" in CVPR, 2021. 2, 3, 4, 8, 9\n\nTaking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation. Y Luo, L Zheng, T Guan, J Yu, Y Yang, CVPR. 1112Y. Luo, L. Zheng, T. Guan, J. Yu, and Y. Yang, \"Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation,\" in CVPR, 2019. 2, 3, 11, 12\n\nConfidence regularized self-training. Y Zou, Z Yu, X Liu, B V K V Kumar, J Wang, ICCV. 1112Y. Zou, Z. Yu, X. Liu, B. V. K. V. Kumar, and J. Wang, \"Confidence regularized self-training,\" in ICCV, 2019. 2, 11, 12\n\nSegment anything. A Kirillov, E Mintun, N Ravi, H Mao, C Rolland, L Gustafson, T Xiao, S Whitehead, A C Berg, W Lo, P Doll\u00e1r, R B Girshick, arXiv:2304.02643612arXiv preprintA. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead, A. C. Berg, W. Lo, P. Doll\u00e1r, and R. B. Girshick, \"Segment anything,\" arXiv preprint arXiv:2304.02643, 2023. 2, 3, 6, 12\n\nJoint 2D-3D-semantic data for indoor scene understanding. I Armeni, S Sax, A R Zamir, S Savarese, arXiv:1702.01105111arXiv preprintI. Armeni, S. Sax, A. R. Zamir, and S. Savarese, \"Joint 2D-3D-semantic data for indoor scene understanding,\" arXiv preprint arXiv:1702.01105, 2017. 2, 7, 8, 9, 11, 1\n\nStructured3D: A large photo-realistic dataset for structured 3D modeling. J Zheng, J Zhang, J Li, R Tang, S Gao, Z Zhou, ECCV. 10J. Zheng, J. Zhang, J. Li, R. Tang, S. Gao, and Z. Zhou, \"Structured3D: A large photo-realistic dataset for structured 3D modeling,\" in ECCV, 2020. 2, 7, 8, 9, 10\n\nTransfer beyond the field of view: Dense panoramic semantic segmentation via unsupervised domain adaptation. J Zhang, C Ma, K Yang, A Roitberg, K Peng, R Stiefelhagen, T-ITS. 23712J. Zhang, C. Ma, K. Yang, A. Roitberg, K. Peng, and R. Stiefelhagen, \"Transfer beyond the field of view: Dense panoramic semantic segmen- tation via unsupervised domain adaptation,\" T-ITS, vol. 23, no. 7, pp. 9478-9491, 2022. 2, 11, 12\n\nMetaFormer is actually what you need for vision. W Yu, M Luo, P Zhou, C Si, Y Zhou, X Wang, J Feng, S Yan, CVPR, 2022. 511W. Yu, M. Luo, P. Zhou, C. Si, Y. Zhou, X. Wang, J. Feng, and S. Yan, \"MetaFormer is actually what you need for vision,\" in CVPR, 2022. 2, 5, 11\n\nCycleMLP: A MLP-like architecture for dense prediction. S Chen, E Xie, C Ge, D Liang, P Luo, ICLR. 101S. Chen, E. Xie, C. Ge, D. Liang, and P. Luo, \"CycleMLP: A MLP-like architecture for dense prediction,\" in ICLR, 2022. 2, 3, 5, 10, 1\n\nAS-MLP: An axial shifted MLP architecture for vision. D Lian, Z Yu, X Sun, S Gao, ICLR. 101D. Lian, Z. Yu, X. Sun, and S. Gao, \"AS-MLP: An axial shifted MLP architecture for vision,\" in ICLR, 2022. 2, 3, 10, 1\n\nUnderstanding the robustness in vision transformers. D Zhou, Z Yu, E Xie, C Xiao, A Anandkumar, J Feng, J M Alvarez, ICML, 2022. 511D. Zhou, Z. Yu, E. Xie, C. Xiao, A. Anandkumar, J. Feng, and J. M. Alvarez, \"Understanding the robustness in vision transformers,\" in ICML, 2022. 2, 5, 11\n\nDPT: Deformable patch-based transformer for visual recognition. Z Chen, Y Zhu, C Zhao, G Hu, W Zeng, J Wang, M Tang, MM. 101Z. Chen, Y. Zhu, C. Zhao, G. Hu, W. Zeng, J. Wang, and M. Tang, \"DPT: Deformable patch-based transformer for visual recognition,\" in MM, 2021. 2, 3, 10, 1\n\nDAFormer: Improving network architectures and training strategies for domain-adaptive semantic segmentation. L Hoyer, D Dai, L Van Gool, CVPR. 1112L. Hoyer, D. Dai, and L. Van Gool, \"DAFormer: Improving network architectures and training strategies for domain-adaptive semantic seg- mentation,\" in CVPR, 2022. 2, 3, 11, 12\n\nFully convolutional networks for semantic segmentation. J Long, E Shelhamer, T Darrell, CVPR. J. Long, E. Shelhamer, and T. Darrell, \"Fully convolutional networks for semantic segmentation,\" in CVPR, 2015. 3\n\nSegNet: A deep convolutional encoder-decoder architecture for image segmentation. V Badrinarayanan, A Kendall, R Cipolla, TPAMI. 3912V. Badrinarayanan, A. Kendall, and R. Cipolla, \"SegNet: A deep convolutional encoder-decoder architecture for image segmentation,\" TPAMI, vol. 39, no. 12, pp. 2481-2495, 2017. 3\n\nEncoderdecoder with atrous separable convolution for semantic image segmentation. L.-C Chen, Y Zhu, G Papandreou, F Schroff, H Adam, in ECCV. 839L.-C. Chen, Y. Zhu, G. Papandreou, F. Schroff, and H. Adam, \"Encoder- decoder with atrous separable convolution for semantic image segmen- tation,\" in ECCV, 2018. 3, 8, 9\n\nRefineNet: Multi-path refinement networks for high-resolution semantic segmentation. G Lin, A Milan, C Shen, I Reid, CVPR. G. Lin, A. Milan, C. Shen, and I. Reid, \"RefineNet: Multi-path refine- ment networks for high-resolution semantic segmentation,\" in CVPR, 2017. 3\n\nDeep high-resolution representation learning for visual recognition. J Wang, K Sun, T Cheng, B Jiang, C Deng, Y Zhao, D Liu, Y Mu, M Tan, X Wang, W Liu, B Xiao, TPAMI. 431010J. Wang, K. Sun, T. Cheng, B. Jiang, C. Deng, Y. Zhao, D. Liu, Y. Mu, M. Tan, X. Wang, W. Liu, and B. Xiao, \"Deep high-resolution representation learning for visual recognition,\" TPAMI, vol. 43, no. 10, pp. 3349-3364, 2021. 3, 8, 10\n\nDeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs. L.-C Chen, G Papandreou, I Kokkinos, K Murphy, A L Yuille, TPAMI. 404L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, \"DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs,\" TPAMI, vol. 40, no. 4, pp. 834-848, 2018. 3\n\nPyramid scene parsing network. H Zhao, J Shi, X Qi, X Wang, J Jia, CVPR. 89H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \"Pyramid scene parsing network,\" in CVPR, 2017. 3, 8, 9\n\nStrip pooling: Rethinking spatial pooling for scene parsing. Q Hou, L Zhang, M.-M Cheng, J Feng, CVPR. 2020Q. Hou, L. Zhang, M.-M. Cheng, and J. Feng, \"Strip pooling: Rethink- ing spatial pooling for scene parsing,\" in CVPR, 2020. 3\n\nContext encoding for semantic segmentation. H Zhang, K J Dana, J Shi, Z Zhang, X Wang, A Tyagi, A , in CVPR. 3H. Zhang, K. J. Dana, J. Shi, Z. Zhang, X. Wang, A. Tyagi, and A. Agrawal, \"Context encoding for semantic segmentation,\" in CVPR, 2018. 3\n\nContext prior for scene segmentation. C Yu, J Wang, C Gao, G Yu, C Shen, N Sang, CVPR. 2020C. Yu, J. Wang, C. Gao, G. Yu, C. Shen, and N. Sang, \"Context prior for scene segmentation,\" in CVPR, 2020. 3\n\nMining contextual information beyond image for semantic segmentation. Z Jin, T Gong, D Yu, Q Chu, J Wang, C Wang, J Shao, ICCV. Z. Jin, T. Gong, D. Yu, Q. Chu, J. Wang, C. Wang, and J. Shao, \"Mining contextual information beyond image for semantic segmentation,\" in ICCV, 2021. 3\n\nNon-local neural networks. X Wang, R Girshick, A Gupta, K He, CVPR. X. Wang, R. Girshick, A. Gupta, and K. He, \"Non-local neural net- works,\" in CVPR, 2018. 3\n\nAttention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, NeurIPS. 3A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, \"Attention is all you need,\" in NeurIPS, 2017. 3\n\nDual attention network for scene segmentation. J Fu, J Liu, H Tian, Y Li, Y Bao, Z Fang, H Lu, CVPR. 911J. Fu, J. Liu, H. Tian, Y. Li, Y. Bao, Z. Fang, and H. Lu, \"Dual attention network for scene segmentation,\" in CVPR, 2019. 3, 8, 9, 11\n\nCCNet: Criss-cross attention for semantic segmentation. Z Huang, X Wang, L Huang, C Huang, Y Wei, W Liu, ICCV. Z. Huang, X. Wang, L. Huang, C. Huang, Y. Wei, and W. Liu, \"CCNet: Criss-cross attention for semantic segmentation,\" in ICCV, 2019. 3\n\nOCNet: Object context for semantic segmentation. Y Yuan, L Huang, J Guo, C Zhang, X Chen, J Wang, IJCV. 1298Y. Yuan, L. Huang, J. Guo, C. Zhang, X. Chen, and J. Wang, \"OCNet: Object context for semantic segmentation,\" IJCV, vol. 129, no. 8, pp. 2375-2398, 2021. 3\n\nCovariance attention for semantic segmentation. Y Liu, Y Chen, P Lasang, Q Sun, TPAMI. 444Y. Liu, Y. Chen, P. Lasang, and Q. Sun, \"Covariance attention for semantic segmentation,\" TPAMI, vol. 44, no. 4, pp. 1805-1818, 2022. 3\n\nCTNet: Context-based tandem network for semantic segmentation. Z Li, Y Sun, L Zhang, J Tang, TPAMI. 4412Z. Li, Y. Sun, L. Zhang, and J. Tang, \"CTNet: Context-based tandem network for semantic segmentation,\" TPAMI, vol. 44, no. 12, pp. 9904- 9917, 2022. 3\n\nAn image is worth 16x16 words: Transformers for image recognition at scale. A Dosovitskiy, L Beyer, A Kolesnikov, D Weissenborn, X Zhai, T Unterthiner, M Dehghani, M Minderer, G Heigold, S Gelly, J Uszkoreit, N Houlsby, ICLR. A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby, \"An image is worth 16x16 words: Transformers for image recognition at scale,\" in ICLR, 2021. 3\n\nTraining data-efficient image transformers & distillation through attention. H Touvron, M Cord, M Douze, F Massa, A Sablayrolles, H J\u00e9gou, 2021. 3ICML. H. Touvron, M. Cord, M. Douze, F. Massa, A. Sablayrolles, and H. J\u00e9gou, \"Training data-efficient image transformers & distillation through attention,\" in ICML, 2021. 3\n\nSwin transformer: Hierarchical vision transformer using shifted windows. Z Liu, Y Lin, Y Cao, H Hu, Y Wei, Z Zhang, S Lin, B Guo, ICCV. Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo, \"Swin transformer: Hierarchical vision transformer using shifted win- dows,\" in ICCV, 2021. 3\n\nCSWin transformer: A general vision transformer backbone with cross-shaped windows. X Dong, J Bao, D Chen, W Zhang, N Yu, L Yuan, D Chen, B Guo, CVPR. 2022X. Dong, J. Bao, D. Chen, W. Zhang, N. Yu, L. Yuan, D. Chen, and B. Guo, \"CSWin transformer: A general vision transformer backbone with cross-shaped windows,\" in CVPR, 2022. 3\n\nContextual transformer networks for visual recognition. Y Li, T Yao, Y Pan, T Mei, TPAMI. 452Y. Li, T. Yao, Y. Pan, and T. Mei, \"Contextual transformer networks for visual recognition,\" TPAMI, vol. 45, no. 2, pp. 1489-1500, 2023. 3\n\nP2T: Pyramid pooling transformer for scene understanding. Y.-H Wu, Y Liu, X Zhan, M.-M Cheng, 2022. 3TPAMI. Y.-H. Wu, Y. Liu, X. Zhan, and M.-M. Cheng, \"P2T: Pyramid pooling transformer for scene understanding,\" TPAMI, 2022. 3\n\nSegmenter: Transformer for semantic segmentation. R Strudel, R Garcia, I Laptev, C Schmid, 2021. 3ICCV. R. Strudel, R. Garcia, I. Laptev, and C. Schmid, \"Segmenter: Trans- former for semantic segmentation,\" in ICCV, 2021. 3\n\nSegFormer: Simple and efficient design for semantic segmentation with transformers. E Xie, W Wang, Z Yu, A Anandkumar, J M Alvarez, P Luo, 131in NeurIPS, 2021. 3, 4, 8, 9E. Xie, W. Wang, Z. Yu, A. Anandkumar, J. M. Alvarez, and P. Luo, \"SegFormer: Simple and efficient design for semantic segmentation with transformers,\" in NeurIPS, 2021. 3, 4, 8, 9, 13, 1\n\nPer-pixel classification is not all you need for semantic segmentation. B Cheng, A G Schwing, A Kirillov, NeurIPS. 39B. Cheng, A. G. Schwing, and A. Kirillov, \"Per-pixel classification is not all you need for semantic segmentation,\" in NeurIPS, 2021. 3, 9\n\nMulti-scale high-resolution vision transformer for semantic segmentation. J Gu, H Kwon, D Wang, W Ye, M Li, Y.-H Chen, L Lai, V Chandra, D Z Pan, CVPR. 2022J. Gu, H. Kwon, D. Wang, W. Ye, M. Li, Y.-H. Chen, L. Lai, V. Chandra, and D. Z. Pan, \"Multi-scale high-resolution vision transformer for semantic segmentation,\" in CVPR, 2022. 3\n\nMLP-mixer: An all-MLP architecture for vision. I O Tolstikhin, N Houlsby, A Kolesnikov, L Beyer, X Zhai, T Unterthiner, J Yung, A Steiner, D Keysers, J Uszkoreit, M Lucic, A Dosovitskiy, NeurIPS. 35I. O. Tolstikhin, N. Houlsby, A. Kolesnikov, L. Beyer, X. Zhai, T. Un- terthiner, J. Yung, A. Steiner, D. Keysers, J. Uszkoreit, M. Lucic, and A. Dosovitskiy, \"MLP-mixer: An all-MLP architecture for vision,\" in NeurIPS, 2021. 3, 5\n\nVision permutator: A permutable MLP-like architecture for visual recognition. Q Hou, Z Jiang, L Yuan, M.-M Cheng, S Yan, J Feng, TPAMI. 451Q. Hou, Z. Jiang, L. Yuan, M.-M. Cheng, S. Yan, and J. Feng, \"Vision permutator: A permutable MLP-like architecture for visual recognition,\" TPAMI, vol. 45, no. 1, pp. 1328-1334, 2023. 3\n\nRestricted deformable convolution-based road scene semantic segmentation using surround view cameras. L Deng, M Yang, H Li, T Li, B Hu, C Wang, T-ITS. 21101L. Deng, M. Yang, H. Li, T. Li, B. Hu, and C. Wang, \"Restricted deformable convolution-based road scene semantic segmentation using surround view cameras,\" T-ITS, vol. 21, no. 10, pp. 4350-4362, 2020. 3, 1\n\nWood-Scape: A multi-task, multi-camera fisheye dataset for autonomous driving. S K Yogamani, C Witt, H Rashed, S Nayak, S Mansoor, P Varley, X Perrotton, D O&apos;dea, P P\u00e9rez, C Hughes, J Horgan, G Sistu, S Chennupati, M Uric\u00e1r, S Milz, M Simon, K Amende, ICCV. 37S. K. Yogamani, C. Witt, H. Rashed, S. Nayak, S. Mansoor, P. Varley, X. Perrotton, D. O'Dea, P. P\u00e9rez, C. Hughes, J. Horgan, G. Sistu, S. Chennupati, M. Uric\u00e1r, S. Milz, M. Simon, and K. Amende, \"Wood- Scape: A multi-task, multi-camera fisheye dataset for autonomous driving,\" in ICCV, 2019. 3, 7\n\nSemantic cameras for 360-degree environment perception in automated urban driving. A Petrovai, S Nedevschi, T-ITS. 2310A. Petrovai and S. Nedevschi, \"Semantic cameras for 360-degree environment perception in automated urban driving,\" T-ITS, vol. 23, no. 10, pp. 17 271-17 283, 2022. 3\n\nSemantic segmentation of panoramic images using a synthetic dataset. Y Xu, K Wang, K Yang, D Sun, J Fu, SPIE. Y. Xu, K. Wang, K. Yang, D. Sun, and J. Fu, \"Semantic segmentation of panoramic images using a synthetic dataset,\" in SPIE, 2019. 3\n\nSemantic segmentation of outdoor panoramic images. S Orhan, Y Bastanlar, SIVP. 163S. Orhan and Y. Bastanlar, \"Semantic segmentation of outdoor panoramic images,\" SIVP, vol. 16, no. 3, pp. 643-650, 2022. 3\n\nDistortion convolution module for semantic segmentation of panoramic images based on the imageforming principle. X Hu, Y An, C Shao, H Hu, TIM. 713X. Hu, Y. An, C. Shao, and H. Hu, \"Distortion convolution module for semantic segmentation of panoramic images based on the image- forming principle,\" TIM, vol. 71, pp. 1-12, 2022. 3\n\nPanoramic panoptic segmentation: Towards complete surrounding understanding via unsupervised contrastive learning. A Jaus, K Yang, R Stiefelhagen, 2021. 3IVA. Jaus, K. Yang, and R. Stiefelhagen, \"Panoramic panoptic segmen- tation: Towards complete surrounding understanding via unsupervised contrastive learning,\" in IV, 2021. 3\n\nWaymo open dataset: Panoramic video panoptic segmentation. J Mei, A Z Zhu, X Yan, H Yan, S Qiao, Y Zhu, L.-C Chen, H Kretzschmar, D Anguelov, ECCV. 2022J. Mei, A. Z. Zhu, X. Yan, H. Yan, S. Qiao, Y. Zhu, L.-C. Chen, H. Kretzschmar, and D. Anguelov, \"Waymo open dataset: Panoramic video panoptic segmentation,\" in ECCV, 2022. 3\n\nPanoramic panoptic segmentation: Insights into surrounding parsing for mobile agents via unsupervised contrastive learning. A Jaus, K Yang, R Stiefelhagen, T-ITS. 244A. Jaus, K. Yang, and R. Stiefelhagen, \"Panoramic panoptic seg- mentation: Insights into surrounding parsing for mobile agents via unsupervised contrastive learning,\" T-ITS, vol. 24, no. 4, pp. 4438-4453, 2023. 3\n\nDistortion-aware convolutional filters for dense prediction in panoramic images. K Tateno, N Navab, F Tombari, ECCV. K. Tateno, N. Navab, and F. Tombari, \"Distortion-aware convolutional filters for dense prediction in panoramic images,\" in ECCV, 2018. 3\n\nSpherical CNNs on unstructured grids. C M Jiang, J Huang, K Kashinath, P Prabhat, M Marcus, Nie\u00dfner, ICLR. 1112C. M. Jiang, J. Huang, K. Kashinath, Prabhat, P. Marcus, and M. Nie\u00dfner, \"Spherical CNNs on unstructured grids,\" in ICLR, 2019. 3, 11, 12\n\nSpherePHD: Applying CNNs on a spherical PolyHeDron representation of 360\u00b0i mages. Y Lee, J Jeong, J Yun, W Cho, K.-J Yoon, CVPR. 37Y. Lee, J. Jeong, J. Yun, W. Cho, and K.-J. Yoon, \"SpherePHD: Applying CNNs on a spherical PolyHeDron representation of 360\u00b0i mages,\" in CVPR, 2019. 3, 7\n\nEquivariant networks for pixelized spheres. M Shakerinava, S Ravanbakhsh, 2021. 3ICML. M. Shakerinava and S. Ravanbakhsh, \"Equivariant networks for pix- elized spheres,\" in ICML, 2021. 3\n\nComplementary bi-directional feature compression for indoor 360\u00b0semantic segmentation with self-distillation. Z Zheng, C Lin, L Nie, K Liao, Z Shen, Y Zhao, arXiv:2207.024372022arXiv preprintZ. Zheng, C. Lin, L. Nie, K. Liao, Z. Shen, and Y. Zhao, \"Comple- mentary bi-directional feature compression for indoor 360\u00b0semantic segmentation with self-distillation,\" arXiv preprint arXiv:2207.02437, 2022. 3\n\nPano-SfMLearner: Self-Supervised multi-task learning of depth and semantics in panoramic videos. M Liu, S Wang, Y Guo, Y He, H Xue, SPL. 283M. Liu, S. Wang, Y. Guo, Y. He, and H. Xue, \"Pano-SfMLearner: Self- Supervised multi-task learning of depth and semantics in panoramic videos,\" SPL, vol. 28, pp. 832-836, 2021. 3\n\nDeepPanoContext: Panoramic 3D scene understanding with holistic scene context graph and relation-based optimization. C Zhang, Z Cui, C Chen, S Liu, B Zeng, H Bao, Y Zhang, ICCV. C. Zhang, Z. Cui, C. Chen, S. Liu, B. Zeng, H. Bao, and Y. Zhang, \"DeepPanoContext: Panoramic 3D scene understanding with holistic scene context graph and relation-based optimization,\" in ICCV, 2021. 3\n\nVision transformer with deformable attention. Z Xia, X Pan, S Song, L E Li, G Huang, CVPR. 2022Z. Xia, X. Pan, S. Song, L. E. Li, and G. Huang, \"Vision transformer with deformable attention,\" in CVPR, 2022. 3\n\nVision transformer with progressive sampling. X Yue, S Sun, Z Kuang, M Wei, P H S Torr, W Zhang, D Lin, ICCV. X. Yue, S. Sun, Z. Kuang, M. Wei, P. H. S. Torr, W. Zhang, and D. Lin, \"Vision transformer with progressive sampling,\" in ICCV, 2021. 3\n\nDeformable DETR: Deformable transformers for end-to-end object detection. X Zhu, W Su, L Lu, B Li, X Wang, J Dai, 2021. 3ICLR. X. Zhu, W. Su, L. Lu, B. Li, X. Wang, and J. Dai, \"Deformable DETR: Deformable transformers for end-to-end object detection,\" in ICLR, 2021. 3\n\nNot all images are worth 16x16 words: Dynamic vision transformers with adaptive sequence length. Y Wang, R Huang, S Song, Z Huang, G Huang, NeurIPS. 3Y. Wang, R. Huang, S. Song, Z. Huang, and G. Huang, \"Not all images are worth 16x16 words: Dynamic vision transformers with adaptive sequence length,\" in NeurIPS, 2021. 3\n\nDynamicViT: Efficient vision transformers with dynamic token sparsification. Y Rao, W Zhao, B Liu, J Lu, J Zhou, C.-J Hsieh, NeurIPS. 3Y. Rao, W. Zhao, B. Liu, J. Lu, J. Zhou, and C.-J. Hsieh, \"DynamicViT: Efficient vision transformers with dynamic token sparsification,\" in NeurIPS, 2021. 3\n\nA-ViT: Adaptive tokens for efficient vision transformer. H Yin, A Vahdat, J M Alvarez, A Mallya, J Kautz, P Molchanov, CVPR. 2022H. Yin, A. Vahdat, J. M. Alvarez, A. Mallya, J. Kautz, and P. Molchanov, \"A-ViT: Adaptive tokens for efficient vision transformer,\" in CVPR, 2022. 3\n\nEvo-ViT: Slow-fast token evolution for dynamic vision transformer. Y Xu, Z Zhang, M Zhang, K Sheng, K Li, W Dong, L Zhang, C Xu, X Sun, AAAI. Y. Xu, Z. Zhang, M. Zhang, K. Sheng, K. Li, W. Dong, L. Zhang, C. Xu, and X. Sun, \"Evo-ViT: Slow-fast token evolution for dynamic vision transformer,\" in AAAI, 2021. 3\n\nDynamic group transformer: A general vision transformer backbone with dynamic group attention. K Liu, T Wu, C Liu, G Guo, IJCAI. 20223K. Liu, T. Wu, C. Liu, and G. Guo, \"Dynamic group transformer: A general vision transformer backbone with dynamic group attention,\" in IJCAI, 2022. 3\n\nThe SYNTHIA dataset: A large collection of synthetic images for semantic segmentation of urban scenes. G Ros, L Sellart, J Materzynska, D Vazquez, A M Lopez, CVPR. G. Ros, L. Sellart, J. Materzynska, D. Vazquez, and A. M. Lopez, \"The SYNTHIA dataset: A large collection of synthetic images for semantic segmentation of urban scenes,\" in CVPR, 2016. 3\n\nPlaying for data: Ground truth from computer games. S R Richter, V Vineet, S Roth, V Koltun, ECCV. S. R. Richter, V. Vineet, S. Roth, and V. Koltun, \"Playing for data: Ground truth from computer games,\" in ECCV, 2016. 3\n\nCurriculum domain adaptation for semantic segmentation of urban scenes. Y Zhang, P David, B Gong, ICCV. Y. Zhang, P. David, and B. Gong, \"Curriculum domain adaptation for semantic segmentation of urban scenes,\" in ICCV, 2017. 3\n\nClass-balanced pixel-level self-labeling for domain adaptive semantic segmentation. R Li, S Li, C He, Y Zhang, X Jia, L Zhang, CVPR. 2022R. Li, S. Li, C. He, Y. Zhang, X. Jia, and L. Zhang, \"Class-balanced pixel-level self-labeling for domain adaptive semantic segmentation,\" in CVPR, 2022. 3\n\nDomain-agnostic prior for transfer semantic segmentation. X Huo, L Xie, H Hu, W Zhou, H Li, Q Tian, CVPR. 2022X. Huo, L. Xie, H. Hu, W. Zhou, H. Li, and Q. Tian, \"Domain-agnostic prior for transfer semantic segmentation,\" in CVPR, 2022. 3\n\nImproving semantic segmentation via efficient self-training. Y Zhu, Z Zhang, C Wu, Z Zhang, T He, H Zhang, R Manmatha, M Li, A J Smola, TPAMI. 3Y. Zhu, Z. Zhang, C. Wu, Z. Zhang, T. He, H. Zhang, R. Manmatha, M. Li, and A. J. Smola, \"Improving semantic segmentation via efficient self-training,\" TPAMI, 2021. 3\n\nDecoupleNet: Decoupled network for domain adaptive semantic segmentation. X Lai, Z Tian, X Xu, Y Chen, S Liu, H Zhao, L Wang, J Jia, ECCV. 2022X. Lai, Z. Tian, X. Xu, Y. Chen, S. Liu, H. Zhao, L. Wang, and J. Jia, \"DecoupleNet: Decoupled network for domain adaptive semantic segmentation,\" in ECCV, 2022. 3\n\nSePiCo: Semantic-guided pixel contrast for domain adaptive semantic segmentation. B Xie, S Li, M Li, C H Liu, G Huang, G Wang, TPAMI. 457B. Xie, S. Li, M. Li, C. H. Liu, G. Huang, and G. Wang, \"SePiCo: Semantic-guided pixel contrast for domain adaptive semantic segmen- tation,\" TPAMI, vol. 45, no. 7, pp. 9004-9021, 2023. 3\n\nCyCADA: Cycle-consistent adversarial domain adaptation. J Hoffman, E Tzeng, T Park, J Zhu, P Isola, K Saenko, A A Efros, T Darrell, in ICML. 3J. Hoffman, E. Tzeng, T. Park, J. Zhu, P. Isola, K. Saenko, A. A. Efros, and T. Darrell, \"CyCADA: Cycle-consistent adversarial domain adaptation,\" in ICML, 2018. 3\n\nLearning to adapt structured output space for semantic segmentation. Y.-H Tsai, W.-C Hung, S Schulter, K Sohn, M.-H Yang, M Chandraker, in CVPR. 3Y.-H. Tsai, W.-C. Hung, S. Schulter, K. Sohn, M.-H. Yang, and M. Chandraker, \"Learning to adapt structured output space for semantic segmentation,\" in CVPR, 2018. 3\n\nAll about structure: Adapting structural information across domains for boosting semantic segmentation. W.-L Chang, H.-P Wang, W.-H Peng, W.-C Chiu, CVPR. W.-L. Chang, H.-P. Wang, W.-H. Peng, and W.-C. Chiu, \"All about structure: Adapting structural information across domains for boosting semantic segmentation,\" in CVPR, 2019. 3\n\nConstructing self-motivated pyramid curriculums for cross-domain semantic segmentation: A nonadversarial approach. Q Lian, L Duan, F Lv, B Gong, ICCV. Q. Lian, L. Duan, F. Lv, and B. Gong, \"Constructing self-motivated pyramid curriculums for cross-domain semantic segmentation: A non- adversarial approach,\" in ICCV, 2019. 3\n\nGenerative adversarial nets. I J Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A C Courville, Y Bengio, NeurIPS. 3I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. C. Courville, and Y. Bengio, \"Generative adversarial nets,\" in NeurIPS, 2014. 3\n\nBidirectional learning for domain adaptation of semantic segmentation. Y Li, L Yuan, N Vasconcelos, CVPR. Y. Li, L. Yuan, and N. Vasconcelos, \"Bidirectional learning for domain adaptation of semantic segmentation,\" in CVPR, 2019. 3\n\nContextual-relation consistent domain adaptation for semantic segmentation. J Huang, S Lu, D Guan, X Zhang, ECCV. 2020J. Huang, S. Lu, D. Guan, and X. Zhang, \"Contextual-relation consistent domain adaptation for semantic segmentation,\" in ECCV, 2020. 3\n\nContent-consistent matching for domain adaptive semantic segmentation. G Li, G Kang, W Liu, Y Wei, Y Yang, ECCV. 2020G. Li, G. Kang, W. Liu, Y. Wei, and Y. Yang, \"Content-consistent matching for domain adaptive semantic segmentation,\" in ECCV, 2020. 3\n\nRectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation. Z Zheng, Y Yang, IJCV. 1294Z. Zheng and Y. Yang, \"Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation,\" IJCV, vol. 129, no. 4, pp. 1106-1120, 2021. 3\n\nUncertainty reduction for model adaptation in semantic segmentation. P T Sivaprasad, F Fleuret, 2021. 3CVPR. P. T. Sivaprasad and F. Fleuret, \"Uncertainty reduction for model adaptation in semantic segmentation,\" in CVPR, 2021. 3\n\nFDA: Fourier domain adaptation for semantic segmentation. Y Yang, S Soatto, CVPR. 2020Y. Yang and S. Soatto, \"FDA: Fourier domain adaptation for semantic segmentation,\" in CVPR, 2020. 3\n\nDomain adaptation for semantic segmentation with maximum squares loss. M Chen, H Xue, D Cai, ICCV. M. Chen, H. Xue, and D. Cai, \"Domain adaptation for semantic segmentation with maximum squares loss,\" in ICCV, 2019. 3\n\nDifferential treatment for stuff and things: A simple unsupervised domain adaptation method for semantic segmentation. Z Wang, M Yu, Y Wei, R Feris, J Xiong, W Hwu, T S Huang, H Shi, CVPR. 1112Z. Wang, M. Yu, Y. Wei, R. Feris, J. Xiong, W. Hwu, T. S. Huang, and H. Shi, \"Differential treatment for stuff and things: A simple unsupervised domain adaptation method for semantic segmentation,\" in CVPR, 2020. 3, 11, 12\n\nPrototypical contrast adaptation for domain adaptive semantic segmentation. Z Jiang, Y Li, C Yang, P Gao, Y Wang, Y Tai, C Wang, ECCV. 2022Z. Jiang, Y. Li, C. Yang, P. Gao, Y. Wang, Y. Tai, and C. Wang, \"Proto- typical contrast adaptation for domain adaptive semantic segmentation,\" in ECCV, 2022. 3\n\nADVENT: Adversarial entropy minimization for domain adaptation in semantic segmentation. T.-H Vu, H Jain, M Bucher, M Cord, P P\u00e9rez, CVPR. T.-H. Vu, H. Jain, M. Bucher, M. Cord, and P. P\u00e9rez, \"ADVENT: Adversarial entropy minimization for domain adaptation in semantic segmentation,\" in CVPR, 2019. 3\n\nUnsupervised intra-domain adaptation for semantic segmentation through selfsupervision. F Pan, I Shin, F Rameau, S Lee, I S Kweon, CVPR. 2020F. Pan, I. Shin, F. Rameau, S. Lee, and I. S. Kweon, \"Unsuper- vised intra-domain adaptation for semantic segmentation through self- supervision,\" in CVPR, 2020. 3\n\nPIT: Position-invariant transform for cross-FoV domain adaptation. Q Gu, Q Zhou, M Xu, Z Feng, G Cheng, X Lu, J Shi, L Ma, ICCV. Q. Gu, Q. Zhou, M. Xu, Z. Feng, G. Cheng, X. Lu, J. Shi, and L. Ma, \"PIT: Position-invariant transform for cross-FoV domain adaptation,\" in ICCV, 2021. 3\n\nPrototypical cross-domain self-supervised learning for few-shot unsupervised domain adaptation. X Yue, Z Zheng, S Zhang, Y Gao, T Darrell, K Keutzer, A L Sangiovanni-Vincentelli, CVPR. 1112X. Yue, Z. Zheng, S. Zhang, Y. Gao, T. Darrell, K. Keutzer, and A. L. Sangiovanni-Vincentelli, \"Prototypical cross-domain self-supervised learning for few-shot unsupervised domain adaptation,\" in CVPR, 2021. 3, 11, 12\n\nPrototypical pseudo label denoising and target structure learning for domain adaptive semantic segmentation. P Zhang, B Zhang, T Zhang, D Chen, Y Wang, F Wen, CVPR. P. Zhang, B. Zhang, T. Zhang, D. Chen, Y. Wang, and F. Wen, \"Prototypical pseudo label denoising and target structure learning for domain adaptive semantic segmentation,\" in CVPR, 2021. 3\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, CVPR. K. He, X. Zhang, S. Ren, and J. Sun, \"Deep residual learning for image recognition,\" in CVPR, 2016. 4\n\nSemantic-driven generation of hyperlapse from 360 degree video. W.-S Lai, Y Huang, N Joshi, C Buehler, M.-H Yang, S B Kang, TVCG. 249W.-S. Lai, Y. Huang, N. Joshi, C. Buehler, M.-H. Yang, and S. B. Kang, \"Semantic-driven generation of hyperlapse from 360 degree video,\" TVCG, vol. 24, no. 9, pp. 2610-2621, 2018. 4\n\nDeformable convolutional networks. J Dai, H Qi, Y Xiong, Y Li, G Zhang, H Hu, Y Wei, ICCV. 41J. Dai, H. Qi, Y. Xiong, Y. Li, G. Zhang, H. Hu, and Y. Wei, \"Deformable convolutional networks,\" in ICCV, 2017. 4, 5, 1\n\nSqueeze-and-excitation networks. J Hu, L Shen, G Sun, CVPR. J. Hu, L. Shen, and G. Sun, \"Squeeze-and-excitation networks,\" in CVPR, 2018. 5\n\nBig self-supervised models are strong semi-supervised learners. T Chen, S Kornblith, K Swersky, M Norouzi, G Hinton, NeurIPS. 6T. Chen, S. Kornblith, K. Swersky, M. Norouzi, and G. Hinton, \"Big self-supervised models are strong semi-supervised learners,\" in NeurIPS, 2020. 6\n\nKITTI-360: A novel dataset and benchmarks for urban scene understanding in 2D and 3D. Y Liao, J Xie, A Geiger, TPAMI. 45311Y. Liao, J. Xie, and A. Geiger, \"KITTI-360: A novel dataset and benchmarks for urban scene understanding in 2D and 3D,\" TPAMI, vol. 45, no. 3, pp. 3292-3310, 2023. 7, 11\n\nSELMA: Semantic large-scale multimodal acquisitions in variable weather, daytime and viewpoints. P Testolina, F Barbato, U Michieli, M Giordani, P Zanuttigh, M Zorzi, 2023. 7P. Testolina, F. Barbato, U. Michieli, M. Giordani, P. Zanuttigh, and M. Zorzi, \"SELMA: Semantic large-scale multimodal acquisitions in variable weather, daytime and viewpoints,\" T-ITS, 2023. 7\n\nSynWoodScape: Synthetic surround-view fisheye camera dataset for autonomous driving. A R Sekkat, Y Dupuis, V R Kumar, H Rashed, S K Yogamani, P Vasseur, P Honeine, RA-L. 73A. R. Sekkat, Y. Dupuis, V. R. Kumar, H. Rashed, S. K. Yogamani, P. Vasseur, and P. Honeine, \"SynWoodScape: Synthetic surround-view fisheye camera dataset for autonomous driving,\" RA-L, vol. 7, no. 3, pp. 8502-8509, 2022. 7\n\nThe OmniScape dataset. A R Sekkat, Y Dupuis, P Vasseur, P Honeine, 2020. 7ICRA. A. R. Sekkat, Y. Dupuis, P. Vasseur, and P. Honeine, \"The OmniScape dataset,\" in ICRA, 2020. 7\n\nCARLA: An open urban driving simulator. A Dosovitskiy, G Ros, F Codevilla, A Lopez, V Koltun, CoRLA. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V. Koltun, \"CARLA: An open urban driving simulator,\" in CoRL, 2017. 7\n\nAdam: A method for stochastic optimization. D P Kingma, J Ba, ICLR. D. P. Kingma and J. Ba, \"Adam: A method for stochastic optimization,\" in ICLR, 2015. 8\n\nFast-SCNN: Fast semantic segmentation network. R P K Poudel, S Liwicki, R Cipolla, BMVC. 89R. P. K. Poudel, S. Liwicki, and R. Cipolla, \"Fast-SCNN: Fast semantic segmentation network,\" in BMVC, 2019. 8, 9\n\nIn defense of pretrained ImageNet architectures for real-time semantic segmentation of road-driving images. M Orsic, I Kreso, P Bevandic, S Segvic, CVPR. 912M. Orsic, I. Kreso, P. Bevandic, and S. Segvic, \"In defense of pre- trained ImageNet architectures for real-time semantic segmentation of road-driving images,\" in CVPR, 2019. 9, 12\n\nERFNet: Efficient residual factorized ConvNet for real-time semantic segmentation. E Romera, J M Alvarez, L M Bergasa, R Arroyo, T-ITS. 19112E. Romera, J. M. Alvarez, L. M. Bergasa, and R. Arroyo, \"ERFNet: Efficient residual factorized ConvNet for real-time semantic segmenta- tion,\" T-ITS, vol. 19, no. 1, pp. 263-272, 2018. 9, 12\n\nReal-time semantic segmentation with fast attention. P Hu, F Perazzi, F C Heilbron, O Wang, Z Lin, K Saenko, S Sclaroff, RA-L. 6111P. Hu, F. Perazzi, F. C. Heilbron, O. Wang, Z. Lin, K. Saenko, and S. Sclaroff, \"Real-time semantic segmentation with fast attention,\" RA- L, vol. 6, no. 1, pp. 263-270, 2021. 9, 11\n\nObject-contextual representations for semantic segmentation. Y Yuan, X Chen, J Wang, ECCV. 2020Y. Yuan, X. Chen, and J. Wang, \"Object-contextual representations for semantic segmentation,\" in ECCV, 2020. 9\n\nDisentangled non-local neural networks. M Yin, Z Yao, Y Cao, X Li, Z Zhang, S Lin, H Hu, ECCV. 2020M. Yin, Z. Yao, Y. Cao, X. Li, Z. Zhang, S. Lin, and H. Hu, \"Disentan- gled non-local neural networks,\" in ECCV, 2020. 9\n\nPanoptic feature pyramid networks. A Kirillov, R Girshick, K He, P Doll\u00e1r, CVPR. A. Kirillov, R. Girshick, K. He, and P. Doll\u00e1r, \"Panoptic feature pyramid networks,\" in CVPR, 2019. 9\n\nResNeSt: Splitattention networks. H Zhang, C Wu, Z Zhang, Y Zhu, Z Zhang, H Lin, Y Sun, T He, J Mueller, R Manmatha, M Li, A J Smola, CVPRW2022H. Zhang, C. Wu, Z. Zhang, Y. Zhu, Z. Zhang, H. Lin, Y. Sun, T. He, J. Mueller, R. Manmatha, M. Li, and A. J. Smola, \"ResNeSt: Split- attention networks,\" in CVPRW, 2022. 9\n\nMasked-attention mask transformer for universal image segmentation. B Cheng, I Misra, A G Schwing, A Kirillov, R Girdhar, CVPR. 2022B. Cheng, I. Misra, A. G. Schwing, A. Kirillov, and R. Girdhar, \"Masked-attention mask transformer for universal image segmentation,\" in CVPR, 2022. 9\n\nTrans4Trans: Efficient transformer for transparent object segmentation to help visually impaired people navigate in the real world. J Zhang, K Yang, A Constantinescu, K Peng, K M\u00fcller, R Stiefelhagen, ICCVWJ. Zhang, K. Yang, A. Constantinescu, K. Peng, K. M\u00fcller, and R. Stiefelhagen, \"Trans4Trans: Efficient transformer for transparent object segmentation to help visually impaired people navigate in the real world,\" in ICCVW, 2021. 9\n\nMIC: Masked image consistency for context-enhanced domain adaptation. L Hoyer, D Dai, H Wang, L Van Gool, CVPR. 1112L. Hoyer, D. Dai, H. Wang, and L. Van Gool, \"MIC: Masked image consistency for context-enhanced domain adaptation,\" in CVPR, 2023. 11, 12\n\nHRDA: Context-aware highresolution domain-adaptive semantic segmentation. L Hoyer, D Dai, L Van Gool, ECCV. 1112L. Hoyer, D. Dai, and L. Van Gool, \"HRDA: Context-aware high- resolution domain-adaptive semantic segmentation,\" in ECCV, 2022. 11, 12\n\nUniversal semi-supervised semantic segmentation. T Kalluri, G Varma, M Chandraker, C V Jawahar, ICCV. 1112T. Kalluri, G. Varma, M. Chandraker, and C. V. Jawahar, \"Universal semi-supervised semantic segmentation,\" in ICCV, 2019. 11, 12\n\nSeamless scene segmentation. L Porzi, S R Bul\u00f2, A Colovic, P Kontschieder, CVPR. 1112L. Porzi, S. R. Bul\u00f2, A. Colovic, and P. Kontschieder, \"Seamless scene segmentation,\" in CVPR, 2019. 11, 12\n\nISSAFE: Improving semantic segmentation in accidents by fusing event-based data. J Zhang, K Yang, R Stiefelhagen, IROS. 1112J. Zhang, K. Yang, and R. Stiefelhagen, \"ISSAFE: Improving semantic segmentation in accidents by fusing event-based data,\" in IROS, 2020. 11, 12\n\nGauge equivariant convolutional networks and the icosahedral CNN. T Cohen, M Weiler, B Kicanaoglu, M Welling, ICML. 1112T. Cohen, M. Weiler, B. Kicanaoglu, and M. Welling, \"Gauge equivari- ant convolutional networks and the icosahedral CNN,\" in ICML, 2019. 11, 12\n\nOrientation-aware semantic segmentation on icosahedron spheres. C Zhang, S Liwicki, W Smith, R Cipolla, ICCV. 1112C. Zhang, S. Liwicki, W. Smith, and R. Cipolla, \"Orientation-aware semantic segmentation on icosahedron spheres,\" in ICCV, 2019. 11, 12\n\nTangent images for mitigating spherical distortion. M Eder, M Shvets, J Lim, J.-M Frahm, 2020. 12CVPR. M. Eder, M. Shvets, J. Lim, and J.-M. Frahm, \"Tangent images for mitigating spherical distortion,\" in CVPR, 2020. 12\n\nBDD100K: A diverse driving dataset for heterogeneous multitask learning. F Yu, H Chen, X Wang, W Xian, Y Chen, F Liu, V Madhavan, T Darrell, CVPR. 11F. Yu, H. Chen, X. Wang, W. Xian, Y. Chen, F. Liu, V. Madhavan, and T. Darrell, \"BDD100K: A diverse driving dataset for heterogeneous multitask learning,\" in CVPR, 2020. 11\n\nPVT v2: Improved baselines with pyramid vision transformer. W Wang, E Xie, X Li, D Fan, K Song, D Liang, T Lu, P Luo, L Shao, CVM. 83W. Wang, E. Xie, X. Li, D. Fan, K. Song, D. Liang, T. Lu, P. Luo, and L. Shao, \"PVT v2: Improved baselines with pyramid vision trans- former,\" CVM, vol. 8, no. 3, pp. 415-424, 2022. 11, 13, 1, 2\n\nU-net: convolutional networks for biomedical image segmentation. O Ronneberger, P Fischer, T Brox, MICCAI. 11O. Ronneberger, P. Fischer, and T. Brox, \"U-net: convolutional networks for biomedical image segmentation,\" in MICCAI, 2015. 11\n", "annotations": {"author": "[{\"end\":137,\"start\":123},{\"end\":150,\"start\":138},{\"end\":159,\"start\":151},{\"end\":171,\"start\":160},{\"end\":183,\"start\":172},{\"end\":197,\"start\":184},{\"end\":209,\"start\":198},{\"end\":226,\"start\":210},{\"end\":239,\"start\":227},{\"end\":260,\"start\":240}]", "publisher": null, "author_last_name": "[{\"end\":136,\"start\":131},{\"end\":149,\"start\":145},{\"end\":158,\"start\":155},{\"end\":170,\"start\":166},{\"end\":182,\"start\":178},{\"end\":196,\"start\":194},{\"end\":208,\"start\":206},{\"end\":225,\"start\":221},{\"end\":238,\"start\":234},{\"end\":259,\"start\":247}]", "author_first_name": "[{\"end\":130,\"start\":123},{\"end\":144,\"start\":138},{\"end\":154,\"start\":151},{\"end\":165,\"start\":160},{\"end\":177,\"start\":172},{\"end\":193,\"start\":184},{\"end\":205,\"start\":198},{\"end\":216,\"start\":210},{\"end\":220,\"start\":217},{\"end\":233,\"start\":227},{\"end\":246,\"start\":240}]", "author_affiliation": null, "title": "[{\"end\":120,\"start\":1},{\"end\":380,\"start\":261}]", "venue": null, "abstract": "[{\"end\":1744,\"start\":487}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1959,\"start\":1956},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2143,\"start\":2140},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2148,\"start\":2145},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2153,\"start\":2150},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2228,\"start\":2225},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2233,\"start\":2230},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2238,\"start\":2235},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2478,\"start\":2475},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2654,\"start\":2651},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2659,\"start\":2656},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2752,\"start\":2748},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2758,\"start\":2754},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2934,\"start\":2930},{\"end\":3329,\"start\":3328},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4199,\"start\":4195},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4205,\"start\":4201},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4809,\"start\":4805},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4845,\"start\":4841},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5193,\"start\":5189},{\"end\":5481,\"start\":5478},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5593,\"start\":5590},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5598,\"start\":5595},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5946,\"start\":5943},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6428,\"start\":6425},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6633,\"start\":6630},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7342,\"start\":7338},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7460,\"start\":7456},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7577,\"start\":7574},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7771,\"start\":7767},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7834,\"start\":7830},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8391,\"start\":8388},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9085,\"start\":9081},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9091,\"start\":9087},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9097,\"start\":9093},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9103,\"start\":9099},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9140,\"start\":9136},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9176,\"start\":9172},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9208,\"start\":9205},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9213,\"start\":9210},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9219,\"start\":9215},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9225,\"start\":9221},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9586,\"start\":9582},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9762,\"start\":9758},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9768,\"start\":9764},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9818,\"start\":9814},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9824,\"start\":9820},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9856,\"start\":9852},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9862,\"start\":9858},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9868,\"start\":9864},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9906,\"start\":9902},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":9912,\"start\":9908},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":9918,\"start\":9914},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":9957,\"start\":9953},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":9978,\"start\":9974},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10032,\"start\":10028},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10038,\"start\":10034},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":10044,\"start\":10040},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":10050,\"start\":10046},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":10056,\"start\":10052},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":10174,\"start\":10170},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":10180,\"start\":10176},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10311,\"start\":10307},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":10317,\"start\":10313},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":10323,\"start\":10319},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":10329,\"start\":10325},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":10335,\"start\":10331},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10379,\"start\":10375},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":10385,\"start\":10381},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":10391,\"start\":10387},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":10397,\"start\":10393},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":10403,\"start\":10399},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10447,\"start\":10443},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10453,\"start\":10449},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":10459,\"start\":10455},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":10465,\"start\":10461},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11132,\"start\":11129},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":11291,\"start\":11287},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":11297,\"start\":11293},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":11303,\"start\":11299},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":11328,\"start\":11324},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":11334,\"start\":11330},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":11340,\"start\":11336},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":11434,\"start\":11430},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":11440,\"start\":11436},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":11446,\"start\":11442},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":11518,\"start\":11514},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":11637,\"start\":11633},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":11643,\"start\":11639},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":11649,\"start\":11645},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":11655,\"start\":11651},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":11661,\"start\":11657},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":11688,\"start\":11685},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":11694,\"start\":11690},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":11700,\"start\":11696},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12975,\"start\":12971},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":13008,\"start\":13004},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":13152,\"start\":13148},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":13254,\"start\":13250},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":13448,\"start\":13444},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":13454,\"start\":13450},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":13460,\"start\":13456},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":13466,\"start\":13462},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":13536,\"start\":13532},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":14000,\"start\":13996},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":14006,\"start\":14002},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":14102,\"start\":14098},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":14108,\"start\":14104},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":14114,\"start\":14110},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":14120,\"start\":14116},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":14126,\"start\":14122},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":14132,\"start\":14128},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":14161,\"start\":14157},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":14167,\"start\":14163},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":14173,\"start\":14169},{\"attributes\":{\"ref_id\":\"b91\"},\"end\":14281,\"start\":14277},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":14343,\"start\":14339},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":14377,\"start\":14373},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":14383,\"start\":14379},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":14429,\"start\":14425},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":14435,\"start\":14431},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14461,\"start\":14458},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":14467,\"start\":14463},{\"attributes\":{\"ref_id\":\"b96\"},\"end\":14532,\"start\":14528},{\"attributes\":{\"ref_id\":\"b97\"},\"end\":14538,\"start\":14534},{\"attributes\":{\"ref_id\":\"b98\"},\"end\":14561,\"start\":14557},{\"attributes\":{\"ref_id\":\"b99\"},\"end\":14568,\"start\":14563},{\"attributes\":{\"ref_id\":\"b100\"},\"end\":14600,\"start\":14595},{\"attributes\":{\"ref_id\":\"b101\"},\"end\":14607,\"start\":14602},{\"attributes\":{\"ref_id\":\"b102\"},\"end\":14647,\"start\":14642},{\"attributes\":{\"ref_id\":\"b103\"},\"end\":14654,\"start\":14649},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14684,\"start\":14680},{\"attributes\":{\"ref_id\":\"b104\"},\"end\":14718,\"start\":14713},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14812,\"start\":14809},{\"attributes\":{\"ref_id\":\"b105\"},\"end\":15186,\"start\":15181},{\"attributes\":{\"ref_id\":\"b106\"},\"end\":15193,\"start\":15188},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":15334,\"start\":15330},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":15967,\"start\":15963},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":15973,\"start\":15969},{\"attributes\":{\"ref_id\":\"b108\"},\"end\":16664,\"start\":16659},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":17122,\"start\":17118},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":17128,\"start\":17124},{\"end\":18726,\"start\":18721},{\"attributes\":{\"ref_id\":\"b109\"},\"end\":19408,\"start\":19403},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":19432,\"start\":19428},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":20008,\"start\":20005},{\"attributes\":{\"ref_id\":\"b109\"},\"end\":20121,\"start\":20116},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20566,\"start\":20562},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":20572,\"start\":20568},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":20861,\"start\":20857},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":21706,\"start\":21703},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":22753,\"start\":22749},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22776,\"start\":22772},{\"attributes\":{\"ref_id\":\"b110\"},\"end\":22899,\"start\":22894},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":27692,\"start\":27688},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":27864,\"start\":27860},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":28223,\"start\":28219},{\"attributes\":{\"ref_id\":\"b111\"},\"end\":29480,\"start\":29475},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":29995,\"start\":29991},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":30124,\"start\":30120},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":30381,\"start\":30378},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":30387,\"start\":30383},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":30393,\"start\":30389},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":30399,\"start\":30395},{\"attributes\":{\"ref_id\":\"b112\"},\"end\":30406,\"start\":30401},{\"attributes\":{\"ref_id\":\"b113\"},\"end\":30530,\"start\":30525},{\"attributes\":{\"ref_id\":\"b114\"},\"end\":30537,\"start\":30532},{\"attributes\":{\"ref_id\":\"b115\"},\"end\":30710,\"start\":30705},{\"attributes\":{\"ref_id\":\"b116\"},\"end\":30900,\"start\":30895},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":31026,\"start\":31022},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":32804,\"start\":32801},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":32837,\"start\":32833},{\"attributes\":{\"ref_id\":\"b117\"},\"end\":33638,\"start\":33633},{\"attributes\":{\"ref_id\":\"b118\"},\"end\":34817,\"start\":34812},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":34834,\"start\":34830},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":34850,\"start\":34846},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":34899,\"start\":34895},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":34915,\"start\":34911},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":36871,\"start\":36870},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":36929,\"start\":36925},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":36947,\"start\":36944},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":37038,\"start\":37034},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":37053,\"start\":37049},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":37217,\"start\":37213},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":37236,\"start\":37232},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":37444,\"start\":37440},{\"attributes\":{\"ref_id\":\"b127\"},\"end\":37934,\"start\":37929},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":38204,\"start\":38200},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":38496,\"start\":38492},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":40317,\"start\":40313},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":40419,\"start\":40415},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":41790,\"start\":41786},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":42237,\"start\":42233},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":42252,\"start\":42248},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":42652,\"start\":42648},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":42691,\"start\":42687},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":43613,\"start\":43609},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":43669,\"start\":43666},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":43808,\"start\":43805},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":43942,\"start\":43938},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":43957,\"start\":43953},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":43999,\"start\":43995},{\"attributes\":{\"ref_id\":\"b100\"},\"end\":44010,\"start\":44005},{\"attributes\":{\"ref_id\":\"b105\"},\"end\":44021,\"start\":44016},{\"attributes\":{\"ref_id\":\"b129\"},\"end\":44033,\"start\":44028},{\"attributes\":{\"ref_id\":\"b128\"},\"end\":44044,\"start\":44039},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":44063,\"start\":44059},{\"attributes\":{\"ref_id\":\"b130\"},\"end\":44739,\"start\":44734},{\"attributes\":{\"ref_id\":\"b131\"},\"end\":44746,\"start\":44741},{\"attributes\":{\"ref_id\":\"b132\"},\"end\":44753,\"start\":44748},{\"attributes\":{\"ref_id\":\"b130\"},\"end\":44794,\"start\":44789},{\"attributes\":{\"ref_id\":\"b131\"},\"end\":44883,\"start\":44878},{\"attributes\":{\"ref_id\":\"b132\"},\"end\":44953,\"start\":44948},{\"attributes\":{\"ref_id\":\"b112\"},\"end\":45007,\"start\":45002},{\"attributes\":{\"ref_id\":\"b136\"},\"end\":45022,\"start\":45017},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":45288,\"start\":45284},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":45306,\"start\":45303},{\"attributes\":{\"ref_id\":\"b137\"},\"end\":46197,\"start\":46192},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":46354,\"start\":46350},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":46585,\"start\":46582},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":46626,\"start\":46622},{\"attributes\":{\"ref_id\":\"b133\"},\"end\":46633,\"start\":46628},{\"attributes\":{\"ref_id\":\"b134\"},\"end\":46640,\"start\":46635},{\"attributes\":{\"ref_id\":\"b138\"},\"end\":46647,\"start\":46642},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":47081,\"start\":47077},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":48080,\"start\":48077},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":48086,\"start\":48082},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":48110,\"start\":48106},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":48116,\"start\":48112},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":48122,\"start\":48118},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":48128,\"start\":48124},{\"attributes\":{\"ref_id\":\"b100\"},\"end\":48135,\"start\":48130},{\"attributes\":{\"ref_id\":\"b105\"},\"end\":48142,\"start\":48137},{\"attributes\":{\"ref_id\":\"b128\"},\"end\":48149,\"start\":48144},{\"attributes\":{\"ref_id\":\"b129\"},\"end\":48156,\"start\":48151},{\"attributes\":{\"ref_id\":\"b130\"},\"end\":48193,\"start\":48188},{\"attributes\":{\"ref_id\":\"b131\"},\"end\":48200,\"start\":48195},{\"attributes\":{\"ref_id\":\"b132\"},\"end\":48207,\"start\":48202},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":49945,\"start\":49941},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":51107,\"start\":51103},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":51124,\"start\":51120},{\"attributes\":{\"ref_id\":\"b109\"},\"end\":55171,\"start\":55166},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":55303,\"start\":55299},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":55822,\"start\":55819},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":57082,\"start\":57078},{\"attributes\":{\"ref_id\":\"b137\"},\"end\":58920,\"start\":58915},{\"attributes\":{\"ref_id\":\"b137\"},\"end\":60740,\"start\":60735},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":61972,\"start\":61968},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":62033,\"start\":62029},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":62452,\"start\":62448},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":62457,\"start\":62453},{\"attributes\":{\"ref_id\":\"b107\"},\"end\":62463,\"start\":62458},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":64040,\"start\":64036},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":64157,\"start\":64153},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":64261,\"start\":64257},{\"attributes\":{\"ref_id\":\"b137\"},\"end\":65855,\"start\":65850},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":74265,\"start\":74261}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":61468,\"start\":61223},{\"attributes\":{\"id\":\"fig_1\"},\"end\":61872,\"start\":61469},{\"attributes\":{\"id\":\"fig_2\"},\"end\":63340,\"start\":61873},{\"attributes\":{\"id\":\"fig_3\"},\"end\":63457,\"start\":63341},{\"attributes\":{\"id\":\"fig_4\"},\"end\":63639,\"start\":63458},{\"attributes\":{\"id\":\"fig_5\"},\"end\":63699,\"start\":63640},{\"attributes\":{\"id\":\"fig_6\"},\"end\":63959,\"start\":63700},{\"attributes\":{\"id\":\"fig_7\"},\"end\":65582,\"start\":63960},{\"attributes\":{\"id\":\"fig_8\"},\"end\":65759,\"start\":65583},{\"attributes\":{\"id\":\"fig_9\"},\"end\":66014,\"start\":65760},{\"attributes\":{\"id\":\"fig_10\"},\"end\":66071,\"start\":66015},{\"attributes\":{\"id\":\"fig_11\"},\"end\":66165,\"start\":66072},{\"attributes\":{\"id\":\"fig_12\"},\"end\":66437,\"start\":66166},{\"attributes\":{\"id\":\"fig_13\"},\"end\":66706,\"start\":66438},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":67758,\"start\":66707},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":68335,\"start\":67759},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":68877,\"start\":68336},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":69885,\"start\":68878},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":71362,\"start\":69886},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":72871,\"start\":71363},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":74170,\"start\":72872},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":74585,\"start\":74171},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":75315,\"start\":74586},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":75573,\"start\":75316},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":77459,\"start\":75574},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":77704,\"start\":77460},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":78097,\"start\":77705},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":81225,\"start\":78098},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":82618,\"start\":81226},{\"attributes\":{\"id\":\"tab_17\",\"type\":\"table\"},\"end\":83523,\"start\":82619},{\"attributes\":{\"id\":\"tab_18\",\"type\":\"table\"},\"end\":84914,\"start\":83524},{\"attributes\":{\"id\":\"tab_19\",\"type\":\"table\"},\"end\":85007,\"start\":84915},{\"attributes\":{\"id\":\"tab_20\",\"type\":\"table\"},\"end\":85293,\"start\":85008},{\"attributes\":{\"id\":\"tab_21\",\"type\":\"table\"},\"end\":85664,\"start\":85294},{\"attributes\":{\"id\":\"tab_22\",\"type\":\"table\"},\"end\":87849,\"start\":85665}]", "paragraph": "[{\"end\":2516,\"start\":1760},{\"end\":5482,\"start\":2518},{\"end\":6987,\"start\":5484},{\"end\":7772,\"start\":6989},{\"end\":8132,\"start\":7774},{\"end\":9010,\"start\":8134},{\"end\":9401,\"start\":9012},{\"end\":11058,\"start\":9442},{\"end\":12761,\"start\":11085},{\"end\":13799,\"start\":12808},{\"end\":14685,\"start\":13834},{\"end\":15503,\"start\":14687},{\"end\":15803,\"start\":15519},{\"end\":16394,\"start\":15832},{\"end\":16511,\"start\":16439},{\"end\":16684,\"start\":16513},{\"end\":16737,\"start\":16736},{\"end\":16742,\"start\":16739},{\"end\":17894,\"start\":16797},{\"end\":18555,\"start\":17925},{\"end\":18846,\"start\":18557},{\"end\":19020,\"start\":18891},{\"end\":19965,\"start\":19074},{\"end\":20317,\"start\":19972},{\"end\":21781,\"start\":20429},{\"end\":22024,\"start\":21783},{\"end\":23751,\"start\":22090},{\"end\":24762,\"start\":24182},{\"end\":25730,\"start\":24797},{\"end\":26079,\"start\":25792},{\"end\":26122,\"start\":26121},{\"end\":26128,\"start\":26124},{\"end\":26253,\"start\":26130},{\"end\":28429,\"start\":26314},{\"end\":28510,\"start\":28431},{\"end\":29065,\"start\":28625},{\"end\":29669,\"start\":29090},{\"end\":29996,\"start\":29747},{\"end\":30210,\"start\":30074},{\"end\":31709,\"start\":30299},{\"end\":31816,\"start\":31771},{\"end\":32745,\"start\":31868},{\"end\":33237,\"start\":32747},{\"end\":34409,\"start\":33277},{\"end\":35894,\"start\":34431},{\"end\":36636,\"start\":35896},{\"end\":39787,\"start\":36666},{\"end\":40420,\"start\":39789},{\"end\":40488,\"start\":40455},{\"end\":42364,\"start\":40490},{\"end\":43251,\"start\":42366},{\"end\":44663,\"start\":43318},{\"end\":46225,\"start\":44665},{\"end\":47456,\"start\":46256},{\"end\":50053,\"start\":47492},{\"end\":50905,\"start\":50055},{\"end\":52129,\"start\":50930},{\"end\":52944,\"start\":52131},{\"end\":54228,\"start\":52946},{\"end\":54634,\"start\":54243},{\"end\":55039,\"start\":54654},{\"end\":56327,\"start\":55115},{\"end\":56483,\"start\":56360},{\"end\":56944,\"start\":56561},{\"end\":57248,\"start\":56946},{\"end\":58694,\"start\":57284},{\"end\":59166,\"start\":58740},{\"end\":60492,\"start\":59209},{\"end\":61222,\"start\":60522}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":16438,\"start\":16395},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16735,\"start\":16685},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16796,\"start\":16743},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18890,\"start\":18847},{\"attributes\":{\"id\":\"formula_4\"},\"end\":19073,\"start\":19021},{\"attributes\":{\"id\":\"formula_5\"},\"end\":19971,\"start\":19966},{\"attributes\":{\"id\":\"formula_6\"},\"end\":20411,\"start\":20318},{\"attributes\":{\"id\":\"formula_7\"},\"end\":22089,\"start\":22025},{\"attributes\":{\"id\":\"formula_8\"},\"end\":23954,\"start\":23752},{\"attributes\":{\"id\":\"formula_9\"},\"end\":24181,\"start\":23954},{\"attributes\":{\"id\":\"formula_10\"},\"end\":25791,\"start\":25731},{\"attributes\":{\"id\":\"formula_11\"},\"end\":26120,\"start\":26080},{\"attributes\":{\"id\":\"formula_12\"},\"end\":26313,\"start\":26254},{\"attributes\":{\"id\":\"formula_13\"},\"end\":28624,\"start\":28511},{\"attributes\":{\"id\":\"formula_14\"},\"end\":29089,\"start\":29066},{\"attributes\":{\"id\":\"formula_15\"},\"end\":29746,\"start\":29670},{\"attributes\":{\"id\":\"formula_16\"},\"end\":30073,\"start\":29997},{\"attributes\":{\"id\":\"formula_17\"},\"end\":30260,\"start\":30211},{\"attributes\":{\"id\":\"formula_18\"},\"end\":31770,\"start\":31710},{\"attributes\":{\"id\":\"formula_19\"},\"end\":31867,\"start\":31817}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":32744,\"start\":32737},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":34677,\"start\":34670},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":36096,\"start\":36089},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":36879,\"start\":36872},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":37405,\"start\":37398},{\"attributes\":{\"ref_id\":\"tab_20\"},\"end\":38264,\"start\":38258},{\"attributes\":{\"ref_id\":\"tab_20\"},\"end\":38609,\"start\":38603},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":38882,\"start\":38875},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":39833,\"start\":39826},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":40054,\"start\":40047},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":40574,\"start\":40567},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":41572,\"start\":41565},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":42521,\"start\":42513},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":43377,\"start\":43368},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":45376,\"start\":45367},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":45551,\"start\":45542},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":46314,\"start\":46305},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":47009,\"start\":47000},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":47594,\"start\":47586},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":47818,\"start\":47809},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":49369,\"start\":49360},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":52943,\"start\":52935},{\"attributes\":{\"ref_id\":\"tab_20\"},\"end\":56482,\"start\":56475},{\"attributes\":{\"ref_id\":\"tab_20\"},\"end\":58212,\"start\":58206}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1758,\"start\":1746},{\"attributes\":{\"n\":\"2\"},\"end\":9416,\"start\":9404},{\"attributes\":{\"n\":\"2.1\"},\"end\":9440,\"start\":9419},{\"attributes\":{\"n\":\"2.2\"},\"end\":11083,\"start\":11061},{\"attributes\":{\"n\":\"2.3\"},\"end\":12806,\"start\":12764},{\"attributes\":{\"n\":\"2.4\"},\"end\":13832,\"start\":13802},{\"attributes\":{\"n\":\"3\"},\"end\":15517,\"start\":15506},{\"attributes\":{\"n\":\"3.1\"},\"end\":15830,\"start\":15806},{\"attributes\":{\"n\":\"3.2\"},\"end\":17923,\"start\":17897},{\"attributes\":{\"n\":\"3.3\"},\"end\":20427,\"start\":20413},{\"attributes\":{\"n\":\"3.4\"},\"end\":24795,\"start\":24765},{\"attributes\":{\"n\":\"4\"},\"end\":30297,\"start\":30262},{\"attributes\":{\"n\":\"5\"},\"end\":33251,\"start\":33240},{\"attributes\":{\"n\":\"5.1\"},\"end\":33275,\"start\":33254},{\"attributes\":{\"n\":\"5.2\"},\"end\":34429,\"start\":34412},{\"attributes\":{\"n\":\"5.3\"},\"end\":36664,\"start\":36639},{\"attributes\":{\"n\":\"5.4\"},\"end\":40453,\"start\":40423},{\"attributes\":{\"n\":\"5.5\"},\"end\":43275,\"start\":43254},{\"attributes\":{\"n\":\"5.5.1\"},\"end\":43316,\"start\":43278},{\"attributes\":{\"n\":\"5.5.2\"},\"end\":46254,\"start\":46228},{\"attributes\":{\"n\":\"5.6\"},\"end\":47490,\"start\":47459},{\"attributes\":{\"n\":\"5.7\"},\"end\":50928,\"start\":50908},{\"attributes\":{\"n\":\"6\"},\"end\":54241,\"start\":54231},{\"end\":54652,\"start\":54637},{\"end\":55078,\"start\":55042},{\"end\":55113,\"start\":55081},{\"end\":56358,\"start\":56330},{\"end\":56521,\"start\":56486},{\"end\":56559,\"start\":56524},{\"end\":57282,\"start\":57251},{\"end\":58738,\"start\":58697},{\"end\":59207,\"start\":59169},{\"end\":60520,\"start\":60495},{\"end\":61232,\"start\":61224},{\"end\":61478,\"start\":61470},{\"end\":61882,\"start\":61874},{\"end\":63350,\"start\":63342},{\"end\":63467,\"start\":63459},{\"end\":63649,\"start\":63641},{\"end\":63709,\"start\":63701},{\"end\":63966,\"start\":63961},{\"end\":65593,\"start\":65584},{\"end\":65779,\"start\":65761},{\"end\":66027,\"start\":66016},{\"end\":66084,\"start\":66073},{\"end\":66178,\"start\":66167},{\"end\":66472,\"start\":66439},{\"end\":68346,\"start\":68337},{\"end\":68888,\"start\":68879},{\"end\":69896,\"start\":69887},{\"end\":71373,\"start\":71364},{\"end\":72882,\"start\":72873},{\"end\":74181,\"start\":74172},{\"end\":74596,\"start\":74587},{\"end\":75326,\"start\":75317},{\"end\":75584,\"start\":75575},{\"end\":77471,\"start\":77461},{\"end\":77717,\"start\":77706},{\"end\":78109,\"start\":78099},{\"end\":81237,\"start\":81227},{\"end\":85018,\"start\":85009},{\"end\":85679,\"start\":85666}]", "table": "[{\"end\":67758,\"start\":67152},{\"end\":68335,\"start\":67869},{\"end\":68877,\"start\":68661},{\"end\":69885,\"start\":69004},{\"end\":71362,\"start\":70056},{\"end\":72871,\"start\":71476},{\"end\":74170,\"start\":72917},{\"end\":74585,\"start\":74296},{\"end\":75315,\"start\":74651},{\"end\":75573,\"start\":75419},{\"end\":77459,\"start\":75748},{\"end\":77704,\"start\":77519},{\"end\":78097,\"start\":77935},{\"end\":81225,\"start\":78206},{\"end\":82618,\"start\":81340},{\"end\":83523,\"start\":83117},{\"end\":84914,\"start\":84635},{\"end\":85293,\"start\":85071},{\"end\":85664,\"start\":85507},{\"end\":87849,\"start\":87280}]", "figure_caption": "[{\"end\":61468,\"start\":61234},{\"end\":61872,\"start\":61480},{\"end\":63340,\"start\":61884},{\"end\":63457,\"start\":63352},{\"end\":63639,\"start\":63469},{\"end\":63699,\"start\":63651},{\"end\":63959,\"start\":63711},{\"end\":65582,\"start\":63968},{\"end\":65759,\"start\":65596},{\"end\":66014,\"start\":65784},{\"end\":66071,\"start\":66029},{\"end\":66165,\"start\":66086},{\"end\":66437,\"start\":66180},{\"end\":66706,\"start\":66476},{\"end\":67152,\"start\":66709},{\"end\":67869,\"start\":67761},{\"end\":68661,\"start\":68348},{\"end\":69004,\"start\":68890},{\"end\":70056,\"start\":69898},{\"end\":71476,\"start\":71375},{\"end\":72917,\"start\":72884},{\"end\":74296,\"start\":74183},{\"end\":74651,\"start\":74598},{\"end\":75419,\"start\":75328},{\"end\":75748,\"start\":75586},{\"end\":77519,\"start\":77474},{\"end\":77935,\"start\":77721},{\"end\":78206,\"start\":78112},{\"end\":81340,\"start\":81240},{\"end\":83117,\"start\":82621},{\"end\":84635,\"start\":83526},{\"end\":85007,\"start\":84917},{\"end\":85071,\"start\":85020},{\"end\":85507,\"start\":85296},{\"end\":87280,\"start\":85682}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":2302,\"start\":2295},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":2474,\"start\":2466},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":2514,\"start\":2503},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":2848,\"start\":2842},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":3767,\"start\":3759},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3918,\"start\":3910},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":6190,\"start\":6181},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":6317,\"start\":6310},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":6373,\"start\":6366},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17145,\"start\":17138},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17157,\"start\":17150},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17189,\"start\":17180},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19222,\"start\":19216},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21237,\"start\":21231},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21264,\"start\":21257},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21320,\"start\":21313},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21414,\"start\":21407},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22177,\"start\":22170},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22695,\"start\":22688},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22762,\"start\":22754},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22786,\"start\":22777},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":26373,\"start\":26367},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27726,\"start\":27720},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":28011,\"start\":28005},{\"end\":32683,\"start\":32677},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":32869,\"start\":32863},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":38406,\"start\":38400},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":42363,\"start\":42357},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":46089,\"start\":46082},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":49909,\"start\":49902},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":49917,\"start\":49910},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":50989,\"start\":50981},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":51002,\"start\":50994},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":51168,\"start\":51159},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":51458,\"start\":51448},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":51652,\"start\":51645},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":52187,\"start\":52180},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":52628,\"start\":52622},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":53187,\"start\":53180},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":53647,\"start\":53629},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":53661,\"start\":53653},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":53726,\"start\":53718},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":53736,\"start\":53728},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":53750,\"start\":53742},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":54039,\"start\":54031},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":54052,\"start\":54044},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":55560,\"start\":55539},{\"end\":56099,\"start\":56092},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":56676,\"start\":56668},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":56785,\"start\":56776},{\"end\":57016,\"start\":57010},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":57411,\"start\":57403},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":57514,\"start\":57506},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":57805,\"start\":57792},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":57854,\"start\":57841},{\"end\":57984,\"start\":57977},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":58874,\"start\":58866},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":59340,\"start\":59332},{\"end\":60599,\"start\":60593},{\"end\":60684,\"start\":60678}]", "bib_author_first_name": "[{\"end\":88010,\"start\":88009},{\"end\":88018,\"start\":88017},{\"end\":88024,\"start\":88023},{\"end\":88335,\"start\":88334},{\"end\":88337,\"start\":88336},{\"end\":88357,\"start\":88356},{\"end\":88359,\"start\":88358},{\"end\":88373,\"start\":88372},{\"end\":88375,\"start\":88374},{\"end\":88719,\"start\":88718},{\"end\":88725,\"start\":88724},{\"end\":88734,\"start\":88733},{\"end\":88742,\"start\":88741},{\"end\":88754,\"start\":88753},{\"end\":89077,\"start\":89076},{\"end\":89084,\"start\":89083},{\"end\":89092,\"start\":89091},{\"end\":89099,\"start\":89098},{\"end\":89107,\"start\":89106},{\"end\":89364,\"start\":89363},{\"end\":89370,\"start\":89369},{\"end\":89378,\"start\":89377},{\"end\":89386,\"start\":89385},{\"end\":89394,\"start\":89393},{\"end\":89401,\"start\":89400},{\"end\":89676,\"start\":89675},{\"end\":89682,\"start\":89681},{\"end\":89691,\"start\":89690},{\"end\":89927,\"start\":89926},{\"end\":89933,\"start\":89932},{\"end\":89940,\"start\":89939},{\"end\":89947,\"start\":89946},{\"end\":89954,\"start\":89953},{\"end\":89962,\"start\":89961},{\"end\":90246,\"start\":90245},{\"end\":90253,\"start\":90252},{\"end\":90263,\"start\":90259},{\"end\":90483,\"start\":90482},{\"end\":90491,\"start\":90490},{\"end\":90500,\"start\":90499},{\"end\":90508,\"start\":90507},{\"end\":90514,\"start\":90513},{\"end\":90735,\"start\":90734},{\"end\":90743,\"start\":90742},{\"end\":90749,\"start\":90748},{\"end\":90751,\"start\":90750},{\"end\":90762,\"start\":90761},{\"end\":90772,\"start\":90771},{\"end\":91052,\"start\":91051},{\"end\":91061,\"start\":91060},{\"end\":91069,\"start\":91068},{\"end\":91075,\"start\":91074},{\"end\":91083,\"start\":91082},{\"end\":91091,\"start\":91090},{\"end\":91392,\"start\":91391},{\"end\":91400,\"start\":91399},{\"end\":91407,\"start\":91406},{\"end\":91413,\"start\":91412},{\"end\":91420,\"start\":91419},{\"end\":91428,\"start\":91427},{\"end\":91437,\"start\":91436},{\"end\":91443,\"start\":91442},{\"end\":91450,\"start\":91449},{\"end\":91736,\"start\":91735},{\"end\":91746,\"start\":91745},{\"end\":91755,\"start\":91754},{\"end\":91764,\"start\":91763},{\"end\":91775,\"start\":91774},{\"end\":91788,\"start\":91787},{\"end\":91800,\"start\":91799},{\"end\":91810,\"start\":91809},{\"end\":91818,\"start\":91817},{\"end\":92126,\"start\":92125},{\"end\":92135,\"start\":92134},{\"end\":92141,\"start\":92140},{\"end\":92149,\"start\":92148},{\"end\":92156,\"start\":92155},{\"end\":92163,\"start\":92162},{\"end\":92171,\"start\":92170},{\"end\":92177,\"start\":92176},{\"end\":92185,\"start\":92184},{\"end\":92194,\"start\":92193},{\"end\":92198,\"start\":92195},{\"end\":92206,\"start\":92205},{\"end\":92564,\"start\":92563},{\"end\":92571,\"start\":92570},{\"end\":92580,\"start\":92579},{\"end\":92588,\"start\":92587},{\"end\":92594,\"start\":92593},{\"end\":92837,\"start\":92836},{\"end\":92844,\"start\":92843},{\"end\":92850,\"start\":92849},{\"end\":92857,\"start\":92856},{\"end\":92863,\"start\":92858},{\"end\":92872,\"start\":92871},{\"end\":93029,\"start\":93028},{\"end\":93041,\"start\":93040},{\"end\":93051,\"start\":93050},{\"end\":93059,\"start\":93058},{\"end\":93066,\"start\":93065},{\"end\":93077,\"start\":93076},{\"end\":93090,\"start\":93089},{\"end\":93098,\"start\":93097},{\"end\":93111,\"start\":93110},{\"end\":93113,\"start\":93112},{\"end\":93121,\"start\":93120},{\"end\":93127,\"start\":93126},{\"end\":93137,\"start\":93136},{\"end\":93139,\"start\":93138},{\"end\":93454,\"start\":93453},{\"end\":93464,\"start\":93463},{\"end\":93471,\"start\":93470},{\"end\":93473,\"start\":93472},{\"end\":93482,\"start\":93481},{\"end\":93768,\"start\":93767},{\"end\":93777,\"start\":93776},{\"end\":93786,\"start\":93785},{\"end\":93792,\"start\":93791},{\"end\":93800,\"start\":93799},{\"end\":93807,\"start\":93806},{\"end\":94096,\"start\":94095},{\"end\":94105,\"start\":94104},{\"end\":94111,\"start\":94110},{\"end\":94119,\"start\":94118},{\"end\":94131,\"start\":94130},{\"end\":94139,\"start\":94138},{\"end\":94453,\"start\":94452},{\"end\":94459,\"start\":94458},{\"end\":94466,\"start\":94465},{\"end\":94474,\"start\":94473},{\"end\":94480,\"start\":94479},{\"end\":94488,\"start\":94487},{\"end\":94496,\"start\":94495},{\"end\":94504,\"start\":94503},{\"end\":94728,\"start\":94727},{\"end\":94736,\"start\":94735},{\"end\":94743,\"start\":94742},{\"end\":94749,\"start\":94748},{\"end\":94758,\"start\":94757},{\"end\":94963,\"start\":94962},{\"end\":94971,\"start\":94970},{\"end\":94977,\"start\":94976},{\"end\":94984,\"start\":94983},{\"end\":95173,\"start\":95172},{\"end\":95181,\"start\":95180},{\"end\":95187,\"start\":95186},{\"end\":95194,\"start\":95193},{\"end\":95202,\"start\":95201},{\"end\":95216,\"start\":95215},{\"end\":95224,\"start\":95223},{\"end\":95226,\"start\":95225},{\"end\":95472,\"start\":95471},{\"end\":95480,\"start\":95479},{\"end\":95487,\"start\":95486},{\"end\":95495,\"start\":95494},{\"end\":95501,\"start\":95500},{\"end\":95509,\"start\":95508},{\"end\":95517,\"start\":95516},{\"end\":95797,\"start\":95796},{\"end\":95806,\"start\":95805},{\"end\":95813,\"start\":95812},{\"end\":96068,\"start\":96067},{\"end\":96076,\"start\":96075},{\"end\":96089,\"start\":96088},{\"end\":96303,\"start\":96302},{\"end\":96321,\"start\":96320},{\"end\":96332,\"start\":96331},{\"end\":96618,\"start\":96614},{\"end\":96626,\"start\":96625},{\"end\":96633,\"start\":96632},{\"end\":96647,\"start\":96646},{\"end\":96658,\"start\":96657},{\"end\":96935,\"start\":96934},{\"end\":96942,\"start\":96941},{\"end\":96951,\"start\":96950},{\"end\":96959,\"start\":96958},{\"end\":97189,\"start\":97188},{\"end\":97197,\"start\":97196},{\"end\":97204,\"start\":97203},{\"end\":97213,\"start\":97212},{\"end\":97222,\"start\":97221},{\"end\":97230,\"start\":97229},{\"end\":97238,\"start\":97237},{\"end\":97245,\"start\":97244},{\"end\":97251,\"start\":97250},{\"end\":97258,\"start\":97257},{\"end\":97266,\"start\":97265},{\"end\":97273,\"start\":97272},{\"end\":97644,\"start\":97640},{\"end\":97652,\"start\":97651},{\"end\":97666,\"start\":97665},{\"end\":97678,\"start\":97677},{\"end\":97688,\"start\":97687},{\"end\":97690,\"start\":97689},{\"end\":97970,\"start\":97969},{\"end\":97978,\"start\":97977},{\"end\":97985,\"start\":97984},{\"end\":97991,\"start\":97990},{\"end\":97999,\"start\":97998},{\"end\":98177,\"start\":98176},{\"end\":98184,\"start\":98183},{\"end\":98196,\"start\":98192},{\"end\":98205,\"start\":98204},{\"end\":98394,\"start\":98393},{\"end\":98403,\"start\":98402},{\"end\":98405,\"start\":98404},{\"end\":98413,\"start\":98412},{\"end\":98420,\"start\":98419},{\"end\":98429,\"start\":98428},{\"end\":98437,\"start\":98436},{\"end\":98446,\"start\":98445},{\"end\":98637,\"start\":98636},{\"end\":98643,\"start\":98642},{\"end\":98651,\"start\":98650},{\"end\":98658,\"start\":98657},{\"end\":98664,\"start\":98663},{\"end\":98672,\"start\":98671},{\"end\":98871,\"start\":98870},{\"end\":98878,\"start\":98877},{\"end\":98886,\"start\":98885},{\"end\":98892,\"start\":98891},{\"end\":98899,\"start\":98898},{\"end\":98907,\"start\":98906},{\"end\":98915,\"start\":98914},{\"end\":99109,\"start\":99108},{\"end\":99117,\"start\":99116},{\"end\":99129,\"start\":99128},{\"end\":99138,\"start\":99137},{\"end\":99269,\"start\":99268},{\"end\":99280,\"start\":99279},{\"end\":99291,\"start\":99290},{\"end\":99301,\"start\":99300},{\"end\":99314,\"start\":99313},{\"end\":99323,\"start\":99322},{\"end\":99325,\"start\":99324},{\"end\":99334,\"start\":99333},{\"end\":99344,\"start\":99343},{\"end\":99567,\"start\":99566},{\"end\":99573,\"start\":99572},{\"end\":99580,\"start\":99579},{\"end\":99588,\"start\":99587},{\"end\":99594,\"start\":99593},{\"end\":99601,\"start\":99600},{\"end\":99609,\"start\":99608},{\"end\":99816,\"start\":99815},{\"end\":99825,\"start\":99824},{\"end\":99833,\"start\":99832},{\"end\":99842,\"start\":99841},{\"end\":99851,\"start\":99850},{\"end\":99858,\"start\":99857},{\"end\":100055,\"start\":100054},{\"end\":100063,\"start\":100062},{\"end\":100072,\"start\":100071},{\"end\":100079,\"start\":100078},{\"end\":100088,\"start\":100087},{\"end\":100096,\"start\":100095},{\"end\":100319,\"start\":100318},{\"end\":100326,\"start\":100325},{\"end\":100334,\"start\":100333},{\"end\":100344,\"start\":100343},{\"end\":100561,\"start\":100560},{\"end\":100567,\"start\":100566},{\"end\":100574,\"start\":100573},{\"end\":100583,\"start\":100582},{\"end\":100830,\"start\":100829},{\"end\":100845,\"start\":100844},{\"end\":100854,\"start\":100853},{\"end\":100868,\"start\":100867},{\"end\":100883,\"start\":100882},{\"end\":100891,\"start\":100890},{\"end\":100906,\"start\":100905},{\"end\":100918,\"start\":100917},{\"end\":100930,\"start\":100929},{\"end\":100941,\"start\":100940},{\"end\":100950,\"start\":100949},{\"end\":100963,\"start\":100962},{\"end\":101313,\"start\":101312},{\"end\":101324,\"start\":101323},{\"end\":101332,\"start\":101331},{\"end\":101341,\"start\":101340},{\"end\":101350,\"start\":101349},{\"end\":101366,\"start\":101365},{\"end\":101630,\"start\":101629},{\"end\":101637,\"start\":101636},{\"end\":101644,\"start\":101643},{\"end\":101651,\"start\":101650},{\"end\":101657,\"start\":101656},{\"end\":101664,\"start\":101663},{\"end\":101673,\"start\":101672},{\"end\":101680,\"start\":101679},{\"end\":101941,\"start\":101940},{\"end\":101949,\"start\":101948},{\"end\":101956,\"start\":101955},{\"end\":101964,\"start\":101963},{\"end\":101973,\"start\":101972},{\"end\":101979,\"start\":101978},{\"end\":101987,\"start\":101986},{\"end\":101995,\"start\":101994},{\"end\":102245,\"start\":102244},{\"end\":102251,\"start\":102250},{\"end\":102258,\"start\":102257},{\"end\":102265,\"start\":102264},{\"end\":102483,\"start\":102479},{\"end\":102489,\"start\":102488},{\"end\":102496,\"start\":102495},{\"end\":102507,\"start\":102503},{\"end\":102700,\"start\":102699},{\"end\":102711,\"start\":102710},{\"end\":102721,\"start\":102720},{\"end\":102731,\"start\":102730},{\"end\":102959,\"start\":102958},{\"end\":102966,\"start\":102965},{\"end\":102974,\"start\":102973},{\"end\":102980,\"start\":102979},{\"end\":102994,\"start\":102993},{\"end\":102996,\"start\":102995},{\"end\":103007,\"start\":103006},{\"end\":103306,\"start\":103305},{\"end\":103315,\"start\":103314},{\"end\":103317,\"start\":103316},{\"end\":103328,\"start\":103327},{\"end\":103565,\"start\":103564},{\"end\":103571,\"start\":103570},{\"end\":103579,\"start\":103578},{\"end\":103587,\"start\":103586},{\"end\":103593,\"start\":103592},{\"end\":103602,\"start\":103598},{\"end\":103610,\"start\":103609},{\"end\":103617,\"start\":103616},{\"end\":103628,\"start\":103627},{\"end\":103630,\"start\":103629},{\"end\":103874,\"start\":103873},{\"end\":103876,\"start\":103875},{\"end\":103890,\"start\":103889},{\"end\":103901,\"start\":103900},{\"end\":103915,\"start\":103914},{\"end\":103924,\"start\":103923},{\"end\":103932,\"start\":103931},{\"end\":103947,\"start\":103946},{\"end\":103955,\"start\":103954},{\"end\":103966,\"start\":103965},{\"end\":103977,\"start\":103976},{\"end\":103990,\"start\":103989},{\"end\":103999,\"start\":103998},{\"end\":104335,\"start\":104334},{\"end\":104342,\"start\":104341},{\"end\":104351,\"start\":104350},{\"end\":104362,\"start\":104358},{\"end\":104371,\"start\":104370},{\"end\":104378,\"start\":104377},{\"end\":104686,\"start\":104685},{\"end\":104694,\"start\":104693},{\"end\":104702,\"start\":104701},{\"end\":104708,\"start\":104707},{\"end\":104714,\"start\":104713},{\"end\":104720,\"start\":104719},{\"end\":105026,\"start\":105025},{\"end\":105028,\"start\":105027},{\"end\":105040,\"start\":105039},{\"end\":105048,\"start\":105047},{\"end\":105058,\"start\":105057},{\"end\":105067,\"start\":105066},{\"end\":105078,\"start\":105077},{\"end\":105088,\"start\":105087},{\"end\":105101,\"start\":105100},{\"end\":105115,\"start\":105114},{\"end\":105124,\"start\":105123},{\"end\":105134,\"start\":105133},{\"end\":105144,\"start\":105143},{\"end\":105153,\"start\":105152},{\"end\":105167,\"start\":105166},{\"end\":105177,\"start\":105176},{\"end\":105185,\"start\":105184},{\"end\":105194,\"start\":105193},{\"end\":105593,\"start\":105592},{\"end\":105605,\"start\":105604},{\"end\":105865,\"start\":105864},{\"end\":105871,\"start\":105870},{\"end\":105879,\"start\":105878},{\"end\":105887,\"start\":105886},{\"end\":105894,\"start\":105893},{\"end\":106090,\"start\":106089},{\"end\":106099,\"start\":106098},{\"end\":106358,\"start\":106357},{\"end\":106364,\"start\":106363},{\"end\":106370,\"start\":106369},{\"end\":106378,\"start\":106377},{\"end\":106691,\"start\":106690},{\"end\":106699,\"start\":106698},{\"end\":106707,\"start\":106706},{\"end\":106965,\"start\":106964},{\"end\":106972,\"start\":106971},{\"end\":106974,\"start\":106973},{\"end\":106981,\"start\":106980},{\"end\":106988,\"start\":106987},{\"end\":106995,\"start\":106994},{\"end\":107003,\"start\":107002},{\"end\":107013,\"start\":107009},{\"end\":107021,\"start\":107020},{\"end\":107036,\"start\":107035},{\"end\":107358,\"start\":107357},{\"end\":107366,\"start\":107365},{\"end\":107374,\"start\":107373},{\"end\":107695,\"start\":107694},{\"end\":107705,\"start\":107704},{\"end\":107714,\"start\":107713},{\"end\":107907,\"start\":107906},{\"end\":107909,\"start\":107908},{\"end\":107918,\"start\":107917},{\"end\":107927,\"start\":107926},{\"end\":107940,\"start\":107939},{\"end\":107951,\"start\":107950},{\"end\":108201,\"start\":108200},{\"end\":108208,\"start\":108207},{\"end\":108217,\"start\":108216},{\"end\":108224,\"start\":108223},{\"end\":108234,\"start\":108230},{\"end\":108449,\"start\":108448},{\"end\":108464,\"start\":108463},{\"end\":108703,\"start\":108702},{\"end\":108712,\"start\":108711},{\"end\":108719,\"start\":108718},{\"end\":108726,\"start\":108725},{\"end\":108734,\"start\":108733},{\"end\":108742,\"start\":108741},{\"end\":109094,\"start\":109093},{\"end\":109101,\"start\":109100},{\"end\":109109,\"start\":109108},{\"end\":109116,\"start\":109115},{\"end\":109122,\"start\":109121},{\"end\":109434,\"start\":109433},{\"end\":109443,\"start\":109442},{\"end\":109450,\"start\":109449},{\"end\":109458,\"start\":109457},{\"end\":109465,\"start\":109464},{\"end\":109473,\"start\":109472},{\"end\":109480,\"start\":109479},{\"end\":109744,\"start\":109743},{\"end\":109751,\"start\":109750},{\"end\":109758,\"start\":109757},{\"end\":109766,\"start\":109765},{\"end\":109768,\"start\":109767},{\"end\":109774,\"start\":109773},{\"end\":109954,\"start\":109953},{\"end\":109961,\"start\":109960},{\"end\":109968,\"start\":109967},{\"end\":109977,\"start\":109976},{\"end\":109984,\"start\":109983},{\"end\":109988,\"start\":109985},{\"end\":109996,\"start\":109995},{\"end\":110005,\"start\":110004},{\"end\":110229,\"start\":110228},{\"end\":110236,\"start\":110235},{\"end\":110242,\"start\":110241},{\"end\":110248,\"start\":110247},{\"end\":110254,\"start\":110253},{\"end\":110262,\"start\":110261},{\"end\":110523,\"start\":110522},{\"end\":110531,\"start\":110530},{\"end\":110540,\"start\":110539},{\"end\":110548,\"start\":110547},{\"end\":110557,\"start\":110556},{\"end\":110825,\"start\":110824},{\"end\":110832,\"start\":110831},{\"end\":110840,\"start\":110839},{\"end\":110847,\"start\":110846},{\"end\":110853,\"start\":110852},{\"end\":110864,\"start\":110860},{\"end\":111098,\"start\":111097},{\"end\":111105,\"start\":111104},{\"end\":111115,\"start\":111114},{\"end\":111117,\"start\":111116},{\"end\":111128,\"start\":111127},{\"end\":111138,\"start\":111137},{\"end\":111147,\"start\":111146},{\"end\":111387,\"start\":111386},{\"end\":111393,\"start\":111392},{\"end\":111402,\"start\":111401},{\"end\":111411,\"start\":111410},{\"end\":111420,\"start\":111419},{\"end\":111426,\"start\":111425},{\"end\":111434,\"start\":111433},{\"end\":111443,\"start\":111442},{\"end\":111449,\"start\":111448},{\"end\":111726,\"start\":111725},{\"end\":111733,\"start\":111732},{\"end\":111739,\"start\":111738},{\"end\":111746,\"start\":111745},{\"end\":112019,\"start\":112018},{\"end\":112026,\"start\":112025},{\"end\":112037,\"start\":112036},{\"end\":112052,\"start\":112051},{\"end\":112063,\"start\":112062},{\"end\":112065,\"start\":112064},{\"end\":112320,\"start\":112319},{\"end\":112322,\"start\":112321},{\"end\":112333,\"start\":112332},{\"end\":112343,\"start\":112342},{\"end\":112351,\"start\":112350},{\"end\":112561,\"start\":112560},{\"end\":112570,\"start\":112569},{\"end\":112579,\"start\":112578},{\"end\":112802,\"start\":112801},{\"end\":112808,\"start\":112807},{\"end\":112814,\"start\":112813},{\"end\":112820,\"start\":112819},{\"end\":112829,\"start\":112828},{\"end\":112836,\"start\":112835},{\"end\":113070,\"start\":113069},{\"end\":113077,\"start\":113076},{\"end\":113084,\"start\":113083},{\"end\":113090,\"start\":113089},{\"end\":113098,\"start\":113097},{\"end\":113104,\"start\":113103},{\"end\":113313,\"start\":113312},{\"end\":113320,\"start\":113319},{\"end\":113329,\"start\":113328},{\"end\":113335,\"start\":113334},{\"end\":113344,\"start\":113343},{\"end\":113350,\"start\":113349},{\"end\":113359,\"start\":113358},{\"end\":113371,\"start\":113370},{\"end\":113377,\"start\":113376},{\"end\":113379,\"start\":113378},{\"end\":113638,\"start\":113637},{\"end\":113645,\"start\":113644},{\"end\":113653,\"start\":113652},{\"end\":113659,\"start\":113658},{\"end\":113667,\"start\":113666},{\"end\":113674,\"start\":113673},{\"end\":113682,\"start\":113681},{\"end\":113690,\"start\":113689},{\"end\":113954,\"start\":113953},{\"end\":113961,\"start\":113960},{\"end\":113967,\"start\":113966},{\"end\":113973,\"start\":113972},{\"end\":113975,\"start\":113974},{\"end\":113982,\"start\":113981},{\"end\":113991,\"start\":113990},{\"end\":114254,\"start\":114253},{\"end\":114265,\"start\":114264},{\"end\":114274,\"start\":114273},{\"end\":114282,\"start\":114281},{\"end\":114289,\"start\":114288},{\"end\":114298,\"start\":114297},{\"end\":114308,\"start\":114307},{\"end\":114310,\"start\":114309},{\"end\":114319,\"start\":114318},{\"end\":114577,\"start\":114573},{\"end\":114588,\"start\":114584},{\"end\":114596,\"start\":114595},{\"end\":114608,\"start\":114607},{\"end\":114619,\"start\":114615},{\"end\":114627,\"start\":114626},{\"end\":114924,\"start\":114920},{\"end\":114936,\"start\":114932},{\"end\":114947,\"start\":114943},{\"end\":114958,\"start\":114954},{\"end\":115264,\"start\":115263},{\"end\":115272,\"start\":115271},{\"end\":115280,\"start\":115279},{\"end\":115286,\"start\":115285},{\"end\":115504,\"start\":115503},{\"end\":115506,\"start\":115505},{\"end\":115520,\"start\":115519},{\"end\":115537,\"start\":115536},{\"end\":115546,\"start\":115545},{\"end\":115552,\"start\":115551},{\"end\":115568,\"start\":115567},{\"end\":115577,\"start\":115576},{\"end\":115579,\"start\":115578},{\"end\":115592,\"start\":115591},{\"end\":115847,\"start\":115846},{\"end\":115853,\"start\":115852},{\"end\":115861,\"start\":115860},{\"end\":116085,\"start\":116084},{\"end\":116094,\"start\":116093},{\"end\":116100,\"start\":116099},{\"end\":116108,\"start\":116107},{\"end\":116334,\"start\":116333},{\"end\":116340,\"start\":116339},{\"end\":116348,\"start\":116347},{\"end\":116355,\"start\":116354},{\"end\":116362,\"start\":116361},{\"end\":116619,\"start\":116618},{\"end\":116628,\"start\":116627},{\"end\":116889,\"start\":116888},{\"end\":116891,\"start\":116890},{\"end\":116905,\"start\":116904},{\"end\":117109,\"start\":117108},{\"end\":117117,\"start\":117116},{\"end\":117309,\"start\":117308},{\"end\":117317,\"start\":117316},{\"end\":117324,\"start\":117323},{\"end\":117576,\"start\":117575},{\"end\":117584,\"start\":117583},{\"end\":117590,\"start\":117589},{\"end\":117597,\"start\":117596},{\"end\":117606,\"start\":117605},{\"end\":117615,\"start\":117614},{\"end\":117622,\"start\":117621},{\"end\":117624,\"start\":117623},{\"end\":117633,\"start\":117632},{\"end\":117950,\"start\":117949},{\"end\":117959,\"start\":117958},{\"end\":117965,\"start\":117964},{\"end\":117973,\"start\":117972},{\"end\":117980,\"start\":117979},{\"end\":117988,\"start\":117987},{\"end\":117995,\"start\":117994},{\"end\":118267,\"start\":118263},{\"end\":118273,\"start\":118272},{\"end\":118281,\"start\":118280},{\"end\":118291,\"start\":118290},{\"end\":118299,\"start\":118298},{\"end\":118564,\"start\":118563},{\"end\":118571,\"start\":118570},{\"end\":118579,\"start\":118578},{\"end\":118589,\"start\":118588},{\"end\":118596,\"start\":118595},{\"end\":118598,\"start\":118597},{\"end\":118849,\"start\":118848},{\"end\":118855,\"start\":118854},{\"end\":118863,\"start\":118862},{\"end\":118869,\"start\":118868},{\"end\":118877,\"start\":118876},{\"end\":118886,\"start\":118885},{\"end\":118892,\"start\":118891},{\"end\":118899,\"start\":118898},{\"end\":119162,\"start\":119161},{\"end\":119169,\"start\":119168},{\"end\":119178,\"start\":119177},{\"end\":119187,\"start\":119186},{\"end\":119194,\"start\":119193},{\"end\":119205,\"start\":119204},{\"end\":119216,\"start\":119215},{\"end\":119218,\"start\":119217},{\"end\":119583,\"start\":119582},{\"end\":119592,\"start\":119591},{\"end\":119601,\"start\":119600},{\"end\":119610,\"start\":119609},{\"end\":119618,\"start\":119617},{\"end\":119626,\"start\":119625},{\"end\":119874,\"start\":119873},{\"end\":119880,\"start\":119879},{\"end\":119889,\"start\":119888},{\"end\":119896,\"start\":119895},{\"end\":120079,\"start\":120075},{\"end\":120086,\"start\":120085},{\"end\":120095,\"start\":120094},{\"end\":120104,\"start\":120103},{\"end\":120118,\"start\":120114},{\"end\":120126,\"start\":120125},{\"end\":120128,\"start\":120127},{\"end\":120363,\"start\":120362},{\"end\":120370,\"start\":120369},{\"end\":120376,\"start\":120375},{\"end\":120385,\"start\":120384},{\"end\":120391,\"start\":120390},{\"end\":120400,\"start\":120399},{\"end\":120406,\"start\":120405},{\"end\":120576,\"start\":120575},{\"end\":120582,\"start\":120581},{\"end\":120590,\"start\":120589},{\"end\":120748,\"start\":120747},{\"end\":120756,\"start\":120755},{\"end\":120769,\"start\":120768},{\"end\":120780,\"start\":120779},{\"end\":120791,\"start\":120790},{\"end\":121046,\"start\":121045},{\"end\":121054,\"start\":121053},{\"end\":121061,\"start\":121060},{\"end\":121351,\"start\":121350},{\"end\":121364,\"start\":121363},{\"end\":121375,\"start\":121374},{\"end\":121387,\"start\":121386},{\"end\":121399,\"start\":121398},{\"end\":121412,\"start\":121411},{\"end\":121708,\"start\":121707},{\"end\":121710,\"start\":121709},{\"end\":121720,\"start\":121719},{\"end\":121730,\"start\":121729},{\"end\":121732,\"start\":121731},{\"end\":121741,\"start\":121740},{\"end\":121751,\"start\":121750},{\"end\":121753,\"start\":121752},{\"end\":121765,\"start\":121764},{\"end\":121776,\"start\":121775},{\"end\":122043,\"start\":122042},{\"end\":122045,\"start\":122044},{\"end\":122055,\"start\":122054},{\"end\":122065,\"start\":122064},{\"end\":122076,\"start\":122075},{\"end\":122236,\"start\":122235},{\"end\":122251,\"start\":122250},{\"end\":122258,\"start\":122257},{\"end\":122271,\"start\":122270},{\"end\":122280,\"start\":122279},{\"end\":122461,\"start\":122460},{\"end\":122463,\"start\":122462},{\"end\":122473,\"start\":122472},{\"end\":122620,\"start\":122619},{\"end\":122624,\"start\":122621},{\"end\":122634,\"start\":122633},{\"end\":122645,\"start\":122644},{\"end\":122887,\"start\":122886},{\"end\":122896,\"start\":122895},{\"end\":122905,\"start\":122904},{\"end\":122917,\"start\":122916},{\"end\":123201,\"start\":123200},{\"end\":123211,\"start\":123210},{\"end\":123213,\"start\":123212},{\"end\":123224,\"start\":123223},{\"end\":123226,\"start\":123225},{\"end\":123237,\"start\":123236},{\"end\":123504,\"start\":123503},{\"end\":123510,\"start\":123509},{\"end\":123521,\"start\":123520},{\"end\":123523,\"start\":123522},{\"end\":123535,\"start\":123534},{\"end\":123543,\"start\":123542},{\"end\":123550,\"start\":123549},{\"end\":123560,\"start\":123559},{\"end\":123826,\"start\":123825},{\"end\":123834,\"start\":123833},{\"end\":123842,\"start\":123841},{\"end\":124012,\"start\":124011},{\"end\":124019,\"start\":124018},{\"end\":124026,\"start\":124025},{\"end\":124033,\"start\":124032},{\"end\":124039,\"start\":124038},{\"end\":124048,\"start\":124047},{\"end\":124055,\"start\":124054},{\"end\":124228,\"start\":124227},{\"end\":124240,\"start\":124239},{\"end\":124252,\"start\":124251},{\"end\":124258,\"start\":124257},{\"end\":124411,\"start\":124410},{\"end\":124420,\"start\":124419},{\"end\":124426,\"start\":124425},{\"end\":124435,\"start\":124434},{\"end\":124442,\"start\":124441},{\"end\":124451,\"start\":124450},{\"end\":124458,\"start\":124457},{\"end\":124465,\"start\":124464},{\"end\":124471,\"start\":124470},{\"end\":124482,\"start\":124481},{\"end\":124494,\"start\":124493},{\"end\":124500,\"start\":124499},{\"end\":124502,\"start\":124501},{\"end\":124762,\"start\":124761},{\"end\":124771,\"start\":124770},{\"end\":124780,\"start\":124779},{\"end\":124782,\"start\":124781},{\"end\":124793,\"start\":124792},{\"end\":124805,\"start\":124804},{\"end\":125110,\"start\":125109},{\"end\":125119,\"start\":125118},{\"end\":125127,\"start\":125126},{\"end\":125145,\"start\":125144},{\"end\":125153,\"start\":125152},{\"end\":125163,\"start\":125162},{\"end\":125486,\"start\":125485},{\"end\":125495,\"start\":125494},{\"end\":125502,\"start\":125501},{\"end\":125510,\"start\":125509},{\"end\":125745,\"start\":125744},{\"end\":125754,\"start\":125753},{\"end\":125761,\"start\":125760},{\"end\":125968,\"start\":125967},{\"end\":125979,\"start\":125978},{\"end\":125988,\"start\":125987},{\"end\":126002,\"start\":126001},{\"end\":126004,\"start\":126003},{\"end\":126184,\"start\":126183},{\"end\":126193,\"start\":126192},{\"end\":126195,\"start\":126194},{\"end\":126203,\"start\":126202},{\"end\":126214,\"start\":126213},{\"end\":126430,\"start\":126429},{\"end\":126439,\"start\":126438},{\"end\":126447,\"start\":126446},{\"end\":126685,\"start\":126684},{\"end\":126694,\"start\":126693},{\"end\":126704,\"start\":126703},{\"end\":126718,\"start\":126717},{\"end\":126948,\"start\":126947},{\"end\":126957,\"start\":126956},{\"end\":126968,\"start\":126967},{\"end\":126977,\"start\":126976},{\"end\":127187,\"start\":127186},{\"end\":127195,\"start\":127194},{\"end\":127205,\"start\":127204},{\"end\":127215,\"start\":127211},{\"end\":127429,\"start\":127428},{\"end\":127435,\"start\":127434},{\"end\":127443,\"start\":127442},{\"end\":127451,\"start\":127450},{\"end\":127459,\"start\":127458},{\"end\":127467,\"start\":127466},{\"end\":127474,\"start\":127473},{\"end\":127486,\"start\":127485},{\"end\":127739,\"start\":127738},{\"end\":127747,\"start\":127746},{\"end\":127754,\"start\":127753},{\"end\":127760,\"start\":127759},{\"end\":127767,\"start\":127766},{\"end\":127775,\"start\":127774},{\"end\":127784,\"start\":127783},{\"end\":127790,\"start\":127789},{\"end\":127797,\"start\":127796},{\"end\":128073,\"start\":128072},{\"end\":128088,\"start\":128087},{\"end\":128099,\"start\":128098}]", "bib_author_last_name": "[{\"end\":88015,\"start\":88011},{\"end\":88021,\"start\":88019},{\"end\":88037,\"start\":88025},{\"end\":88354,\"start\":88338},{\"end\":88370,\"start\":88360},{\"end\":88383,\"start\":88376},{\"end\":88722,\"start\":88720},{\"end\":88731,\"start\":88726},{\"end\":88739,\"start\":88735},{\"end\":88751,\"start\":88743},{\"end\":88767,\"start\":88755},{\"end\":89081,\"start\":89078},{\"end\":89089,\"start\":89085},{\"end\":89096,\"start\":89093},{\"end\":89104,\"start\":89100},{\"end\":89111,\"start\":89108},{\"end\":89367,\"start\":89365},{\"end\":89375,\"start\":89371},{\"end\":89383,\"start\":89379},{\"end\":89391,\"start\":89387},{\"end\":89398,\"start\":89395},{\"end\":89406,\"start\":89402},{\"end\":89679,\"start\":89677},{\"end\":89688,\"start\":89683},{\"end\":89695,\"start\":89692},{\"end\":89930,\"start\":89928},{\"end\":89937,\"start\":89934},{\"end\":89944,\"start\":89941},{\"end\":89951,\"start\":89948},{\"end\":89959,\"start\":89955},{\"end\":89967,\"start\":89963},{\"end\":90250,\"start\":90247},{\"end\":90257,\"start\":90254},{\"end\":90268,\"start\":90264},{\"end\":90488,\"start\":90484},{\"end\":90497,\"start\":90492},{\"end\":90505,\"start\":90501},{\"end\":90511,\"start\":90509},{\"end\":90527,\"start\":90515},{\"end\":90740,\"start\":90736},{\"end\":90746,\"start\":90744},{\"end\":90759,\"start\":90752},{\"end\":90769,\"start\":90763},{\"end\":90777,\"start\":90773},{\"end\":91058,\"start\":91053},{\"end\":91066,\"start\":91062},{\"end\":91072,\"start\":91070},{\"end\":91080,\"start\":91076},{\"end\":91088,\"start\":91084},{\"end\":91104,\"start\":91092},{\"end\":91397,\"start\":91393},{\"end\":91404,\"start\":91401},{\"end\":91410,\"start\":91408},{\"end\":91417,\"start\":91414},{\"end\":91425,\"start\":91421},{\"end\":91434,\"start\":91429},{\"end\":91440,\"start\":91438},{\"end\":91447,\"start\":91444},{\"end\":91455,\"start\":91451},{\"end\":91743,\"start\":91737},{\"end\":91752,\"start\":91747},{\"end\":91761,\"start\":91756},{\"end\":91772,\"start\":91765},{\"end\":91785,\"start\":91776},{\"end\":91797,\"start\":91789},{\"end\":91807,\"start\":91801},{\"end\":91815,\"start\":91811},{\"end\":91826,\"start\":91819},{\"end\":92132,\"start\":92127},{\"end\":92138,\"start\":92136},{\"end\":92146,\"start\":92142},{\"end\":92153,\"start\":92150},{\"end\":92160,\"start\":92157},{\"end\":92168,\"start\":92164},{\"end\":92174,\"start\":92172},{\"end\":92182,\"start\":92178},{\"end\":92191,\"start\":92186},{\"end\":92203,\"start\":92199},{\"end\":92212,\"start\":92207},{\"end\":92568,\"start\":92565},{\"end\":92577,\"start\":92572},{\"end\":92585,\"start\":92581},{\"end\":92591,\"start\":92589},{\"end\":92599,\"start\":92595},{\"end\":92841,\"start\":92838},{\"end\":92847,\"start\":92845},{\"end\":92854,\"start\":92851},{\"end\":92869,\"start\":92864},{\"end\":92877,\"start\":92873},{\"end\":93038,\"start\":93030},{\"end\":93048,\"start\":93042},{\"end\":93056,\"start\":93052},{\"end\":93063,\"start\":93060},{\"end\":93074,\"start\":93067},{\"end\":93087,\"start\":93078},{\"end\":93095,\"start\":93091},{\"end\":93108,\"start\":93099},{\"end\":93118,\"start\":93114},{\"end\":93124,\"start\":93122},{\"end\":93134,\"start\":93128},{\"end\":93148,\"start\":93140},{\"end\":93461,\"start\":93455},{\"end\":93468,\"start\":93465},{\"end\":93479,\"start\":93474},{\"end\":93491,\"start\":93483},{\"end\":93774,\"start\":93769},{\"end\":93783,\"start\":93778},{\"end\":93789,\"start\":93787},{\"end\":93797,\"start\":93793},{\"end\":93804,\"start\":93801},{\"end\":93812,\"start\":93808},{\"end\":94102,\"start\":94097},{\"end\":94108,\"start\":94106},{\"end\":94116,\"start\":94112},{\"end\":94128,\"start\":94120},{\"end\":94136,\"start\":94132},{\"end\":94152,\"start\":94140},{\"end\":94456,\"start\":94454},{\"end\":94463,\"start\":94460},{\"end\":94471,\"start\":94467},{\"end\":94477,\"start\":94475},{\"end\":94485,\"start\":94481},{\"end\":94493,\"start\":94489},{\"end\":94501,\"start\":94497},{\"end\":94508,\"start\":94505},{\"end\":94733,\"start\":94729},{\"end\":94740,\"start\":94737},{\"end\":94746,\"start\":94744},{\"end\":94755,\"start\":94750},{\"end\":94762,\"start\":94759},{\"end\":94968,\"start\":94964},{\"end\":94974,\"start\":94972},{\"end\":94981,\"start\":94978},{\"end\":94988,\"start\":94985},{\"end\":95178,\"start\":95174},{\"end\":95184,\"start\":95182},{\"end\":95191,\"start\":95188},{\"end\":95199,\"start\":95195},{\"end\":95213,\"start\":95203},{\"end\":95221,\"start\":95217},{\"end\":95234,\"start\":95227},{\"end\":95477,\"start\":95473},{\"end\":95484,\"start\":95481},{\"end\":95492,\"start\":95488},{\"end\":95498,\"start\":95496},{\"end\":95506,\"start\":95502},{\"end\":95514,\"start\":95510},{\"end\":95522,\"start\":95518},{\"end\":95803,\"start\":95798},{\"end\":95810,\"start\":95807},{\"end\":95822,\"start\":95814},{\"end\":96073,\"start\":96069},{\"end\":96086,\"start\":96077},{\"end\":96097,\"start\":96090},{\"end\":96318,\"start\":96304},{\"end\":96329,\"start\":96322},{\"end\":96340,\"start\":96333},{\"end\":96623,\"start\":96619},{\"end\":96630,\"start\":96627},{\"end\":96644,\"start\":96634},{\"end\":96655,\"start\":96648},{\"end\":96663,\"start\":96659},{\"end\":96939,\"start\":96936},{\"end\":96948,\"start\":96943},{\"end\":96956,\"start\":96952},{\"end\":96964,\"start\":96960},{\"end\":97194,\"start\":97190},{\"end\":97201,\"start\":97198},{\"end\":97210,\"start\":97205},{\"end\":97219,\"start\":97214},{\"end\":97227,\"start\":97223},{\"end\":97235,\"start\":97231},{\"end\":97242,\"start\":97239},{\"end\":97248,\"start\":97246},{\"end\":97255,\"start\":97252},{\"end\":97263,\"start\":97259},{\"end\":97270,\"start\":97267},{\"end\":97278,\"start\":97274},{\"end\":97649,\"start\":97645},{\"end\":97663,\"start\":97653},{\"end\":97675,\"start\":97667},{\"end\":97685,\"start\":97679},{\"end\":97697,\"start\":97691},{\"end\":97975,\"start\":97971},{\"end\":97982,\"start\":97979},{\"end\":97988,\"start\":97986},{\"end\":97996,\"start\":97992},{\"end\":98003,\"start\":98000},{\"end\":98181,\"start\":98178},{\"end\":98190,\"start\":98185},{\"end\":98202,\"start\":98197},{\"end\":98210,\"start\":98206},{\"end\":98400,\"start\":98395},{\"end\":98410,\"start\":98406},{\"end\":98417,\"start\":98414},{\"end\":98426,\"start\":98421},{\"end\":98434,\"start\":98430},{\"end\":98443,\"start\":98438},{\"end\":98640,\"start\":98638},{\"end\":98648,\"start\":98644},{\"end\":98655,\"start\":98652},{\"end\":98661,\"start\":98659},{\"end\":98669,\"start\":98665},{\"end\":98677,\"start\":98673},{\"end\":98875,\"start\":98872},{\"end\":98883,\"start\":98879},{\"end\":98889,\"start\":98887},{\"end\":98896,\"start\":98893},{\"end\":98904,\"start\":98900},{\"end\":98912,\"start\":98908},{\"end\":98920,\"start\":98916},{\"end\":99114,\"start\":99110},{\"end\":99126,\"start\":99118},{\"end\":99135,\"start\":99130},{\"end\":99141,\"start\":99139},{\"end\":99277,\"start\":99270},{\"end\":99288,\"start\":99281},{\"end\":99298,\"start\":99292},{\"end\":99311,\"start\":99302},{\"end\":99320,\"start\":99315},{\"end\":99331,\"start\":99326},{\"end\":99341,\"start\":99335},{\"end\":99355,\"start\":99345},{\"end\":99570,\"start\":99568},{\"end\":99577,\"start\":99574},{\"end\":99585,\"start\":99581},{\"end\":99591,\"start\":99589},{\"end\":99598,\"start\":99595},{\"end\":99606,\"start\":99602},{\"end\":99612,\"start\":99610},{\"end\":99822,\"start\":99817},{\"end\":99830,\"start\":99826},{\"end\":99839,\"start\":99834},{\"end\":99848,\"start\":99843},{\"end\":99855,\"start\":99852},{\"end\":99862,\"start\":99859},{\"end\":100060,\"start\":100056},{\"end\":100069,\"start\":100064},{\"end\":100076,\"start\":100073},{\"end\":100085,\"start\":100080},{\"end\":100093,\"start\":100089},{\"end\":100101,\"start\":100097},{\"end\":100323,\"start\":100320},{\"end\":100331,\"start\":100327},{\"end\":100341,\"start\":100335},{\"end\":100348,\"start\":100345},{\"end\":100564,\"start\":100562},{\"end\":100571,\"start\":100568},{\"end\":100580,\"start\":100575},{\"end\":100588,\"start\":100584},{\"end\":100842,\"start\":100831},{\"end\":100851,\"start\":100846},{\"end\":100865,\"start\":100855},{\"end\":100880,\"start\":100869},{\"end\":100888,\"start\":100884},{\"end\":100903,\"start\":100892},{\"end\":100915,\"start\":100907},{\"end\":100927,\"start\":100919},{\"end\":100938,\"start\":100931},{\"end\":100947,\"start\":100942},{\"end\":100960,\"start\":100951},{\"end\":100971,\"start\":100964},{\"end\":101321,\"start\":101314},{\"end\":101329,\"start\":101325},{\"end\":101338,\"start\":101333},{\"end\":101347,\"start\":101342},{\"end\":101363,\"start\":101351},{\"end\":101372,\"start\":101367},{\"end\":101634,\"start\":101631},{\"end\":101641,\"start\":101638},{\"end\":101648,\"start\":101645},{\"end\":101654,\"start\":101652},{\"end\":101661,\"start\":101658},{\"end\":101670,\"start\":101665},{\"end\":101677,\"start\":101674},{\"end\":101684,\"start\":101681},{\"end\":101946,\"start\":101942},{\"end\":101953,\"start\":101950},{\"end\":101961,\"start\":101957},{\"end\":101970,\"start\":101965},{\"end\":101976,\"start\":101974},{\"end\":101984,\"start\":101980},{\"end\":101992,\"start\":101988},{\"end\":101999,\"start\":101996},{\"end\":102248,\"start\":102246},{\"end\":102255,\"start\":102252},{\"end\":102262,\"start\":102259},{\"end\":102269,\"start\":102266},{\"end\":102486,\"start\":102484},{\"end\":102493,\"start\":102490},{\"end\":102501,\"start\":102497},{\"end\":102513,\"start\":102508},{\"end\":102708,\"start\":102701},{\"end\":102718,\"start\":102712},{\"end\":102728,\"start\":102722},{\"end\":102738,\"start\":102732},{\"end\":102963,\"start\":102960},{\"end\":102971,\"start\":102967},{\"end\":102977,\"start\":102975},{\"end\":102991,\"start\":102981},{\"end\":103004,\"start\":102997},{\"end\":103011,\"start\":103008},{\"end\":103312,\"start\":103307},{\"end\":103325,\"start\":103318},{\"end\":103337,\"start\":103329},{\"end\":103568,\"start\":103566},{\"end\":103576,\"start\":103572},{\"end\":103584,\"start\":103580},{\"end\":103590,\"start\":103588},{\"end\":103596,\"start\":103594},{\"end\":103607,\"start\":103603},{\"end\":103614,\"start\":103611},{\"end\":103625,\"start\":103618},{\"end\":103634,\"start\":103631},{\"end\":103887,\"start\":103877},{\"end\":103898,\"start\":103891},{\"end\":103912,\"start\":103902},{\"end\":103921,\"start\":103916},{\"end\":103929,\"start\":103925},{\"end\":103944,\"start\":103933},{\"end\":103952,\"start\":103948},{\"end\":103963,\"start\":103956},{\"end\":103974,\"start\":103967},{\"end\":103987,\"start\":103978},{\"end\":103996,\"start\":103991},{\"end\":104011,\"start\":104000},{\"end\":104339,\"start\":104336},{\"end\":104348,\"start\":104343},{\"end\":104356,\"start\":104352},{\"end\":104368,\"start\":104363},{\"end\":104375,\"start\":104372},{\"end\":104383,\"start\":104379},{\"end\":104691,\"start\":104687},{\"end\":104699,\"start\":104695},{\"end\":104705,\"start\":104703},{\"end\":104711,\"start\":104709},{\"end\":104717,\"start\":104715},{\"end\":104725,\"start\":104721},{\"end\":105037,\"start\":105029},{\"end\":105045,\"start\":105041},{\"end\":105055,\"start\":105049},{\"end\":105064,\"start\":105059},{\"end\":105075,\"start\":105068},{\"end\":105085,\"start\":105079},{\"end\":105098,\"start\":105089},{\"end\":105112,\"start\":105102},{\"end\":105121,\"start\":105116},{\"end\":105131,\"start\":105125},{\"end\":105141,\"start\":105135},{\"end\":105150,\"start\":105145},{\"end\":105164,\"start\":105154},{\"end\":105174,\"start\":105168},{\"end\":105182,\"start\":105178},{\"end\":105191,\"start\":105186},{\"end\":105201,\"start\":105195},{\"end\":105602,\"start\":105594},{\"end\":105615,\"start\":105606},{\"end\":105868,\"start\":105866},{\"end\":105876,\"start\":105872},{\"end\":105884,\"start\":105880},{\"end\":105891,\"start\":105888},{\"end\":105897,\"start\":105895},{\"end\":106096,\"start\":106091},{\"end\":106109,\"start\":106100},{\"end\":106361,\"start\":106359},{\"end\":106367,\"start\":106365},{\"end\":106375,\"start\":106371},{\"end\":106381,\"start\":106379},{\"end\":106696,\"start\":106692},{\"end\":106704,\"start\":106700},{\"end\":106720,\"start\":106708},{\"end\":106969,\"start\":106966},{\"end\":106978,\"start\":106975},{\"end\":106985,\"start\":106982},{\"end\":106992,\"start\":106989},{\"end\":107000,\"start\":106996},{\"end\":107007,\"start\":107004},{\"end\":107018,\"start\":107014},{\"end\":107033,\"start\":107022},{\"end\":107045,\"start\":107037},{\"end\":107363,\"start\":107359},{\"end\":107371,\"start\":107367},{\"end\":107387,\"start\":107375},{\"end\":107702,\"start\":107696},{\"end\":107711,\"start\":107706},{\"end\":107722,\"start\":107715},{\"end\":107915,\"start\":107910},{\"end\":107924,\"start\":107919},{\"end\":107937,\"start\":107928},{\"end\":107948,\"start\":107941},{\"end\":107958,\"start\":107952},{\"end\":107967,\"start\":107960},{\"end\":108205,\"start\":108202},{\"end\":108214,\"start\":108209},{\"end\":108221,\"start\":108218},{\"end\":108228,\"start\":108225},{\"end\":108239,\"start\":108235},{\"end\":108461,\"start\":108450},{\"end\":108476,\"start\":108465},{\"end\":108709,\"start\":108704},{\"end\":108716,\"start\":108713},{\"end\":108723,\"start\":108720},{\"end\":108731,\"start\":108727},{\"end\":108739,\"start\":108735},{\"end\":108747,\"start\":108743},{\"end\":109098,\"start\":109095},{\"end\":109106,\"start\":109102},{\"end\":109113,\"start\":109110},{\"end\":109119,\"start\":109117},{\"end\":109126,\"start\":109123},{\"end\":109440,\"start\":109435},{\"end\":109447,\"start\":109444},{\"end\":109455,\"start\":109451},{\"end\":109462,\"start\":109459},{\"end\":109470,\"start\":109466},{\"end\":109477,\"start\":109474},{\"end\":109486,\"start\":109481},{\"end\":109748,\"start\":109745},{\"end\":109755,\"start\":109752},{\"end\":109763,\"start\":109759},{\"end\":109771,\"start\":109769},{\"end\":109780,\"start\":109775},{\"end\":109958,\"start\":109955},{\"end\":109965,\"start\":109962},{\"end\":109974,\"start\":109969},{\"end\":109981,\"start\":109978},{\"end\":109993,\"start\":109989},{\"end\":110002,\"start\":109997},{\"end\":110009,\"start\":110006},{\"end\":110233,\"start\":110230},{\"end\":110239,\"start\":110237},{\"end\":110245,\"start\":110243},{\"end\":110251,\"start\":110249},{\"end\":110259,\"start\":110255},{\"end\":110266,\"start\":110263},{\"end\":110528,\"start\":110524},{\"end\":110537,\"start\":110532},{\"end\":110545,\"start\":110541},{\"end\":110554,\"start\":110549},{\"end\":110563,\"start\":110558},{\"end\":110829,\"start\":110826},{\"end\":110837,\"start\":110833},{\"end\":110844,\"start\":110841},{\"end\":110850,\"start\":110848},{\"end\":110858,\"start\":110854},{\"end\":110870,\"start\":110865},{\"end\":111102,\"start\":111099},{\"end\":111112,\"start\":111106},{\"end\":111125,\"start\":111118},{\"end\":111135,\"start\":111129},{\"end\":111144,\"start\":111139},{\"end\":111157,\"start\":111148},{\"end\":111390,\"start\":111388},{\"end\":111399,\"start\":111394},{\"end\":111408,\"start\":111403},{\"end\":111417,\"start\":111412},{\"end\":111423,\"start\":111421},{\"end\":111431,\"start\":111427},{\"end\":111440,\"start\":111435},{\"end\":111446,\"start\":111444},{\"end\":111453,\"start\":111450},{\"end\":111730,\"start\":111727},{\"end\":111736,\"start\":111734},{\"end\":111743,\"start\":111740},{\"end\":111750,\"start\":111747},{\"end\":112023,\"start\":112020},{\"end\":112034,\"start\":112027},{\"end\":112049,\"start\":112038},{\"end\":112060,\"start\":112053},{\"end\":112071,\"start\":112066},{\"end\":112330,\"start\":112323},{\"end\":112340,\"start\":112334},{\"end\":112348,\"start\":112344},{\"end\":112358,\"start\":112352},{\"end\":112567,\"start\":112562},{\"end\":112576,\"start\":112571},{\"end\":112584,\"start\":112580},{\"end\":112805,\"start\":112803},{\"end\":112811,\"start\":112809},{\"end\":112817,\"start\":112815},{\"end\":112826,\"start\":112821},{\"end\":112833,\"start\":112830},{\"end\":112842,\"start\":112837},{\"end\":113074,\"start\":113071},{\"end\":113081,\"start\":113078},{\"end\":113087,\"start\":113085},{\"end\":113095,\"start\":113091},{\"end\":113101,\"start\":113099},{\"end\":113109,\"start\":113105},{\"end\":113317,\"start\":113314},{\"end\":113326,\"start\":113321},{\"end\":113332,\"start\":113330},{\"end\":113341,\"start\":113336},{\"end\":113347,\"start\":113345},{\"end\":113356,\"start\":113351},{\"end\":113368,\"start\":113360},{\"end\":113374,\"start\":113372},{\"end\":113385,\"start\":113380},{\"end\":113642,\"start\":113639},{\"end\":113650,\"start\":113646},{\"end\":113656,\"start\":113654},{\"end\":113664,\"start\":113660},{\"end\":113671,\"start\":113668},{\"end\":113679,\"start\":113675},{\"end\":113687,\"start\":113683},{\"end\":113694,\"start\":113691},{\"end\":113958,\"start\":113955},{\"end\":113964,\"start\":113962},{\"end\":113970,\"start\":113968},{\"end\":113979,\"start\":113976},{\"end\":113988,\"start\":113983},{\"end\":113996,\"start\":113992},{\"end\":114262,\"start\":114255},{\"end\":114271,\"start\":114266},{\"end\":114279,\"start\":114275},{\"end\":114286,\"start\":114283},{\"end\":114295,\"start\":114290},{\"end\":114305,\"start\":114299},{\"end\":114316,\"start\":114311},{\"end\":114327,\"start\":114320},{\"end\":114582,\"start\":114578},{\"end\":114593,\"start\":114589},{\"end\":114605,\"start\":114597},{\"end\":114613,\"start\":114609},{\"end\":114624,\"start\":114620},{\"end\":114638,\"start\":114628},{\"end\":114930,\"start\":114925},{\"end\":114941,\"start\":114937},{\"end\":114952,\"start\":114948},{\"end\":114963,\"start\":114959},{\"end\":115269,\"start\":115265},{\"end\":115277,\"start\":115273},{\"end\":115283,\"start\":115281},{\"end\":115291,\"start\":115287},{\"end\":115517,\"start\":115507},{\"end\":115534,\"start\":115521},{\"end\":115543,\"start\":115538},{\"end\":115549,\"start\":115547},{\"end\":115565,\"start\":115553},{\"end\":115574,\"start\":115569},{\"end\":115589,\"start\":115580},{\"end\":115599,\"start\":115593},{\"end\":115850,\"start\":115848},{\"end\":115858,\"start\":115854},{\"end\":115873,\"start\":115862},{\"end\":116091,\"start\":116086},{\"end\":116097,\"start\":116095},{\"end\":116105,\"start\":116101},{\"end\":116114,\"start\":116109},{\"end\":116337,\"start\":116335},{\"end\":116345,\"start\":116341},{\"end\":116352,\"start\":116349},{\"end\":116359,\"start\":116356},{\"end\":116367,\"start\":116363},{\"end\":116625,\"start\":116620},{\"end\":116633,\"start\":116629},{\"end\":116902,\"start\":116892},{\"end\":116913,\"start\":116906},{\"end\":117114,\"start\":117110},{\"end\":117124,\"start\":117118},{\"end\":117314,\"start\":117310},{\"end\":117321,\"start\":117318},{\"end\":117328,\"start\":117325},{\"end\":117581,\"start\":117577},{\"end\":117587,\"start\":117585},{\"end\":117594,\"start\":117591},{\"end\":117603,\"start\":117598},{\"end\":117612,\"start\":117607},{\"end\":117619,\"start\":117616},{\"end\":117630,\"start\":117625},{\"end\":117637,\"start\":117634},{\"end\":117956,\"start\":117951},{\"end\":117962,\"start\":117960},{\"end\":117970,\"start\":117966},{\"end\":117977,\"start\":117974},{\"end\":117985,\"start\":117981},{\"end\":117992,\"start\":117989},{\"end\":118000,\"start\":117996},{\"end\":118270,\"start\":118268},{\"end\":118278,\"start\":118274},{\"end\":118288,\"start\":118282},{\"end\":118296,\"start\":118292},{\"end\":118305,\"start\":118300},{\"end\":118568,\"start\":118565},{\"end\":118576,\"start\":118572},{\"end\":118586,\"start\":118580},{\"end\":118593,\"start\":118590},{\"end\":118604,\"start\":118599},{\"end\":118852,\"start\":118850},{\"end\":118860,\"start\":118856},{\"end\":118866,\"start\":118864},{\"end\":118874,\"start\":118870},{\"end\":118883,\"start\":118878},{\"end\":118889,\"start\":118887},{\"end\":118896,\"start\":118893},{\"end\":118902,\"start\":118900},{\"end\":119166,\"start\":119163},{\"end\":119175,\"start\":119170},{\"end\":119184,\"start\":119179},{\"end\":119191,\"start\":119188},{\"end\":119202,\"start\":119195},{\"end\":119213,\"start\":119206},{\"end\":119242,\"start\":119219},{\"end\":119589,\"start\":119584},{\"end\":119598,\"start\":119593},{\"end\":119607,\"start\":119602},{\"end\":119615,\"start\":119611},{\"end\":119623,\"start\":119619},{\"end\":119630,\"start\":119627},{\"end\":119877,\"start\":119875},{\"end\":119886,\"start\":119881},{\"end\":119893,\"start\":119890},{\"end\":119900,\"start\":119897},{\"end\":120083,\"start\":120080},{\"end\":120092,\"start\":120087},{\"end\":120101,\"start\":120096},{\"end\":120112,\"start\":120105},{\"end\":120123,\"start\":120119},{\"end\":120133,\"start\":120129},{\"end\":120367,\"start\":120364},{\"end\":120373,\"start\":120371},{\"end\":120382,\"start\":120377},{\"end\":120388,\"start\":120386},{\"end\":120397,\"start\":120392},{\"end\":120403,\"start\":120401},{\"end\":120410,\"start\":120407},{\"end\":120579,\"start\":120577},{\"end\":120587,\"start\":120583},{\"end\":120594,\"start\":120591},{\"end\":120753,\"start\":120749},{\"end\":120766,\"start\":120757},{\"end\":120777,\"start\":120770},{\"end\":120788,\"start\":120781},{\"end\":120798,\"start\":120792},{\"end\":121051,\"start\":121047},{\"end\":121058,\"start\":121055},{\"end\":121068,\"start\":121062},{\"end\":121361,\"start\":121352},{\"end\":121372,\"start\":121365},{\"end\":121384,\"start\":121376},{\"end\":121396,\"start\":121388},{\"end\":121409,\"start\":121400},{\"end\":121418,\"start\":121413},{\"end\":121717,\"start\":121711},{\"end\":121727,\"start\":121721},{\"end\":121738,\"start\":121733},{\"end\":121748,\"start\":121742},{\"end\":121762,\"start\":121754},{\"end\":121773,\"start\":121766},{\"end\":121784,\"start\":121777},{\"end\":122052,\"start\":122046},{\"end\":122062,\"start\":122056},{\"end\":122073,\"start\":122066},{\"end\":122084,\"start\":122077},{\"end\":122248,\"start\":122237},{\"end\":122255,\"start\":122252},{\"end\":122268,\"start\":122259},{\"end\":122277,\"start\":122272},{\"end\":122287,\"start\":122281},{\"end\":122470,\"start\":122464},{\"end\":122476,\"start\":122474},{\"end\":122631,\"start\":122625},{\"end\":122642,\"start\":122635},{\"end\":122653,\"start\":122646},{\"end\":122893,\"start\":122888},{\"end\":122902,\"start\":122897},{\"end\":122914,\"start\":122906},{\"end\":122924,\"start\":122918},{\"end\":123208,\"start\":123202},{\"end\":123221,\"start\":123214},{\"end\":123234,\"start\":123227},{\"end\":123244,\"start\":123238},{\"end\":123507,\"start\":123505},{\"end\":123518,\"start\":123511},{\"end\":123532,\"start\":123524},{\"end\":123540,\"start\":123536},{\"end\":123547,\"start\":123544},{\"end\":123557,\"start\":123551},{\"end\":123569,\"start\":123561},{\"end\":123831,\"start\":123827},{\"end\":123839,\"start\":123835},{\"end\":123847,\"start\":123843},{\"end\":124016,\"start\":124013},{\"end\":124023,\"start\":124020},{\"end\":124030,\"start\":124027},{\"end\":124036,\"start\":124034},{\"end\":124045,\"start\":124040},{\"end\":124052,\"start\":124049},{\"end\":124058,\"start\":124056},{\"end\":124237,\"start\":124229},{\"end\":124249,\"start\":124241},{\"end\":124255,\"start\":124253},{\"end\":124265,\"start\":124259},{\"end\":124417,\"start\":124412},{\"end\":124423,\"start\":124421},{\"end\":124432,\"start\":124427},{\"end\":124439,\"start\":124436},{\"end\":124448,\"start\":124443},{\"end\":124455,\"start\":124452},{\"end\":124462,\"start\":124459},{\"end\":124468,\"start\":124466},{\"end\":124479,\"start\":124472},{\"end\":124491,\"start\":124483},{\"end\":124497,\"start\":124495},{\"end\":124508,\"start\":124503},{\"end\":124768,\"start\":124763},{\"end\":124777,\"start\":124772},{\"end\":124790,\"start\":124783},{\"end\":124802,\"start\":124794},{\"end\":124813,\"start\":124806},{\"end\":125116,\"start\":125111},{\"end\":125124,\"start\":125120},{\"end\":125142,\"start\":125128},{\"end\":125150,\"start\":125146},{\"end\":125160,\"start\":125154},{\"end\":125176,\"start\":125164},{\"end\":125492,\"start\":125487},{\"end\":125499,\"start\":125496},{\"end\":125507,\"start\":125503},{\"end\":125519,\"start\":125511},{\"end\":125751,\"start\":125746},{\"end\":125758,\"start\":125755},{\"end\":125770,\"start\":125762},{\"end\":125976,\"start\":125969},{\"end\":125985,\"start\":125980},{\"end\":125999,\"start\":125989},{\"end\":126012,\"start\":126005},{\"end\":126190,\"start\":126185},{\"end\":126200,\"start\":126196},{\"end\":126211,\"start\":126204},{\"end\":126227,\"start\":126215},{\"end\":126436,\"start\":126431},{\"end\":126444,\"start\":126440},{\"end\":126460,\"start\":126448},{\"end\":126691,\"start\":126686},{\"end\":126701,\"start\":126695},{\"end\":126715,\"start\":126705},{\"end\":126726,\"start\":126719},{\"end\":126954,\"start\":126949},{\"end\":126965,\"start\":126958},{\"end\":126974,\"start\":126969},{\"end\":126985,\"start\":126978},{\"end\":127192,\"start\":127188},{\"end\":127202,\"start\":127196},{\"end\":127209,\"start\":127206},{\"end\":127221,\"start\":127216},{\"end\":127432,\"start\":127430},{\"end\":127440,\"start\":127436},{\"end\":127448,\"start\":127444},{\"end\":127456,\"start\":127452},{\"end\":127464,\"start\":127460},{\"end\":127471,\"start\":127468},{\"end\":127483,\"start\":127475},{\"end\":127494,\"start\":127487},{\"end\":127744,\"start\":127740},{\"end\":127751,\"start\":127748},{\"end\":127757,\"start\":127755},{\"end\":127764,\"start\":127761},{\"end\":127772,\"start\":127768},{\"end\":127781,\"start\":127776},{\"end\":127787,\"start\":127785},{\"end\":127794,\"start\":127791},{\"end\":127802,\"start\":127798},{\"end\":128085,\"start\":128074},{\"end\":128096,\"start\":128089},{\"end\":128104,\"start\":128100}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":231594940},\"end\":88216,\"start\":87915},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":52047481},\"end\":88588,\"start\":88218},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":237091695},\"end\":89001,\"start\":88590},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":248693612},\"end\":89276,\"start\":89003},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":51720757},\"end\":89607,\"start\":89278},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":236472027},\"end\":89851,\"start\":89609},{\"attributes\":{\"doi\":\"arXiv:2205.10468\",\"id\":\"b6\"},\"end\":90167,\"start\":89853},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":227126786},\"end\":90417,\"start\":90169},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":232170379},\"end\":90685,\"start\":90419},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":203134135},\"end\":90953,\"start\":90687},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":247222902},\"end\":91297,\"start\":90955},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":232035922},\"end\":91670,\"start\":91299},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":502946},\"end\":92031,\"start\":91672},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":229924195},\"end\":92452,\"start\":92033},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":52825087},\"end\":92796,\"start\":92454},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":201646241},\"end\":93008,\"start\":92798},{\"attributes\":{\"doi\":\"arXiv:2304.02643\",\"id\":\"b16\"},\"end\":93393,\"start\":93010},{\"attributes\":{\"doi\":\"arXiv:1702.01105\",\"id\":\"b17\"},\"end\":93691,\"start\":93395},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":199064623},\"end\":93984,\"start\":93693},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":239050215},\"end\":94401,\"start\":93986},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":244478080},\"end\":94669,\"start\":94403},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":236154781},\"end\":94906,\"start\":94671},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":236087421},\"end\":95117,\"start\":94908},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":248392231},\"end\":95405,\"start\":95119},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":236635525},\"end\":95685,\"start\":95407},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":244729413},\"end\":96009,\"start\":95687},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":1629541},\"end\":96218,\"start\":96011},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":60814714},\"end\":96530,\"start\":96220},{\"attributes\":{\"id\":\"b28\"},\"end\":96847,\"start\":96532},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":5696978},\"end\":97117,\"start\":96849},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":201124533},\"end\":97525,\"start\":97119},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":3429309},\"end\":97936,\"start\":97527},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":5299559},\"end\":98113,\"start\":97938},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":214713957},\"end\":98347,\"start\":98115},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":4324021},\"end\":98596,\"start\":98349},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":214794959},\"end\":98798,\"start\":98598},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":237303937},\"end\":99079,\"start\":98800},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":4852647},\"end\":99239,\"start\":99081},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":13756489},\"end\":99517,\"start\":99241},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":52180375},\"end\":99757,\"start\":99519},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":53846561},\"end\":100003,\"start\":99759},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":236378539},\"end\":100268,\"start\":100005},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":221939487},\"end\":100495,\"start\":100270},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":233306940},\"end\":100751,\"start\":100497},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":225039882},\"end\":101233,\"start\":100753},{\"attributes\":{\"doi\":\"2021. 3\",\"id\":\"b45\",\"matched_paper_id\":229363322},\"end\":101554,\"start\":101235},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":232352874},\"end\":101854,\"start\":101556},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":235694312},\"end\":102186,\"start\":101856},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":236429065},\"end\":102419,\"start\":102188},{\"attributes\":{\"doi\":\"2022. 3\",\"id\":\"b49\",\"matched_paper_id\":235606084},\"end\":102647,\"start\":102421},{\"attributes\":{\"doi\":\"2021. 3\",\"id\":\"b50\",\"matched_paper_id\":234470051},\"end\":102872,\"start\":102649},{\"attributes\":{\"id\":\"b51\"},\"end\":103231,\"start\":102874},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":235829267},\"end\":103488,\"start\":103233},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":244488722},\"end\":103824,\"start\":103490},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":233714958},\"end\":104254,\"start\":103826},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":235606034},\"end\":104581,\"start\":104256},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":35903402},\"end\":104944,\"start\":104583},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":146121106},\"end\":105507,\"start\":104946},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":247470774},\"end\":105793,\"start\":105509},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":202541027},\"end\":106036,\"start\":105795},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":238683992},\"end\":106242,\"start\":106038},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":245694835},\"end\":106573,\"start\":106244},{\"attributes\":{\"doi\":\"2021. 3\",\"id\":\"b62\"},\"end\":106903,\"start\":106575},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":249674827},\"end\":107231,\"start\":106905},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":249926450},\"end\":107611,\"start\":107233},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":52086927},\"end\":107866,\"start\":107613},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":57721134},\"end\":108116,\"start\":107868},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":198165883},\"end\":108402,\"start\":108118},{\"attributes\":{\"doi\":\"2021. 3\",\"id\":\"b68\",\"matched_paper_id\":235422361},\"end\":108590,\"start\":108404},{\"attributes\":{\"doi\":\"arXiv:2207.02437\",\"id\":\"b69\"},\"end\":108994,\"start\":108592},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":233990511},\"end\":109314,\"start\":108996},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":237278052},\"end\":109695,\"start\":109316},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":245650206},\"end\":109905,\"start\":109697},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":236912833},\"end\":110152,\"start\":109907},{\"attributes\":{\"doi\":\"2021. 3\",\"id\":\"b74\",\"matched_paper_id\":222208633},\"end\":110423,\"start\":110154},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":235254787},\"end\":110745,\"start\":110425},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":235313562},\"end\":111038,\"start\":110747},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":245131572},\"end\":111317,\"start\":111040},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":236881638},\"end\":111628,\"start\":111319},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":247315103},\"end\":111913,\"start\":111630},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":206594095},\"end\":112265,\"start\":111915},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":5844139},\"end\":112486,\"start\":112267},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":11824004},\"end\":112715,\"start\":112488},{\"attributes\":{\"id\":\"b83\",\"matched_paper_id\":247594735},\"end\":113009,\"start\":112717},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":247996730},\"end\":113249,\"start\":113011},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":245475533},\"end\":113561,\"start\":113251},{\"attributes\":{\"id\":\"b86\",\"matched_paper_id\":250698828},\"end\":113869,\"start\":113563},{\"attributes\":{\"id\":\"b87\",\"matched_paper_id\":248240040},\"end\":114195,\"start\":113871},{\"attributes\":{\"id\":\"b88\",\"matched_paper_id\":7646250},\"end\":114502,\"start\":114197},{\"attributes\":{\"id\":\"b89\",\"matched_paper_id\":3556146},\"end\":114814,\"start\":114504},{\"attributes\":{\"id\":\"b90\",\"matched_paper_id\":88522535},\"end\":115146,\"start\":114816},{\"attributes\":{\"id\":\"b91\",\"matched_paper_id\":201665971},\"end\":115472,\"start\":115148},{\"attributes\":{\"id\":\"b92\",\"matched_paper_id\":1033682},\"end\":115773,\"start\":115474},{\"attributes\":{\"id\":\"b93\",\"matched_paper_id\":129944996},\"end\":116006,\"start\":115775},{\"attributes\":{\"id\":\"b94\",\"matched_paper_id\":220364556},\"end\":116260,\"start\":116008},{\"attributes\":{\"id\":\"b95\",\"matched_paper_id\":226840200},\"end\":116513,\"start\":116262},{\"attributes\":{\"id\":\"b96\",\"matched_paper_id\":212634017},\"end\":116817,\"start\":116515},{\"attributes\":{\"doi\":\"2021. 3\",\"id\":\"b97\",\"matched_paper_id\":233017520},\"end\":117048,\"start\":116819},{\"attributes\":{\"id\":\"b98\",\"matched_paper_id\":215745272},\"end\":117235,\"start\":117050},{\"attributes\":{\"id\":\"b99\",\"matched_paper_id\":203593505},\"end\":117454,\"start\":117237},{\"attributes\":{\"id\":\"b100\",\"matched_paper_id\":212747800},\"end\":117871,\"start\":117456},{\"attributes\":{\"id\":\"b101\",\"matched_paper_id\":250526798},\"end\":118172,\"start\":117873},{\"attributes\":{\"id\":\"b102\",\"matched_paper_id\":54216961},\"end\":118473,\"start\":118174},{\"attributes\":{\"id\":\"b103\",\"matched_paper_id\":215786096},\"end\":118779,\"start\":118475},{\"attributes\":{\"id\":\"b104\",\"matched_paper_id\":237091087},\"end\":119063,\"start\":118781},{\"attributes\":{\"id\":\"b105\",\"matched_paper_id\":232428002},\"end\":119471,\"start\":119065},{\"attributes\":{\"id\":\"b106\",\"matched_paper_id\":231709665},\"end\":119825,\"start\":119473},{\"attributes\":{\"id\":\"b107\",\"matched_paper_id\":206594692},\"end\":120009,\"start\":119827},{\"attributes\":{\"id\":\"b108\",\"matched_paper_id\":21290110},\"end\":120325,\"start\":120011},{\"attributes\":{\"id\":\"b109\",\"matched_paper_id\":4028864},\"end\":120540,\"start\":120327},{\"attributes\":{\"id\":\"b110\",\"matched_paper_id\":140309863},\"end\":120681,\"start\":120542},{\"attributes\":{\"id\":\"b111\",\"matched_paper_id\":219721239},\"end\":120957,\"start\":120683},{\"attributes\":{\"id\":\"b112\",\"matched_paper_id\":238198653},\"end\":121251,\"start\":120959},{\"attributes\":{\"doi\":\"2023. 7\",\"id\":\"b113\"},\"end\":121620,\"start\":121253},{\"attributes\":{\"id\":\"b114\",\"matched_paper_id\":247362954},\"end\":122017,\"start\":121622},{\"attributes\":{\"doi\":\"2020. 7\",\"id\":\"b115\",\"matched_paper_id\":221847109},\"end\":122193,\"start\":122019},{\"attributes\":{\"id\":\"b116\"},\"end\":122414,\"start\":122195},{\"attributes\":{\"id\":\"b117\",\"matched_paper_id\":6628106},\"end\":122570,\"start\":122416},{\"attributes\":{\"id\":\"b118\",\"matched_paper_id\":60441195},\"end\":122776,\"start\":122572},{\"attributes\":{\"id\":\"b119\",\"matched_paper_id\":84186897},\"end\":123115,\"start\":122778},{\"attributes\":{\"id\":\"b120\",\"matched_paper_id\":25093571},\"end\":123448,\"start\":123117},{\"attributes\":{\"id\":\"b121\",\"matched_paper_id\":220404266},\"end\":123762,\"start\":123450},{\"attributes\":{\"id\":\"b122\",\"matched_paper_id\":202734362},\"end\":123969,\"start\":123764},{\"attributes\":{\"id\":\"b123\",\"matched_paper_id\":219573794},\"end\":124190,\"start\":123971},{\"attributes\":{\"id\":\"b124\",\"matched_paper_id\":57721164},\"end\":124374,\"start\":124192},{\"attributes\":{\"id\":\"b125\"},\"end\":124691,\"start\":124376},{\"attributes\":{\"id\":\"b126\",\"matched_paper_id\":244799297},\"end\":124975,\"start\":124693},{\"attributes\":{\"id\":\"b127\"},\"end\":125413,\"start\":124977},{\"attributes\":{\"id\":\"b128\",\"matched_paper_id\":254220923},\"end\":125668,\"start\":125415},{\"attributes\":{\"id\":\"b129\",\"matched_paper_id\":248427223},\"end\":125916,\"start\":125670},{\"attributes\":{\"id\":\"b130\",\"matched_paper_id\":53774686},\"end\":126152,\"start\":125918},{\"attributes\":{\"id\":\"b131\",\"matched_paper_id\":145047913},\"end\":126346,\"start\":126154},{\"attributes\":{\"id\":\"b132\",\"matched_paper_id\":221186954},\"end\":126616,\"start\":126348},{\"attributes\":{\"id\":\"b133\",\"matched_paper_id\":61153622},\"end\":126881,\"start\":126618},{\"attributes\":{\"id\":\"b134\",\"matched_paper_id\":198985698},\"end\":127132,\"start\":126883},{\"attributes\":{\"doi\":\"2020. 12\",\"id\":\"b135\",\"matched_paper_id\":209414882},\"end\":127353,\"start\":127134},{\"attributes\":{\"id\":\"b136\",\"matched_paper_id\":215415900},\"end\":127676,\"start\":127355},{\"attributes\":{\"id\":\"b137\",\"matched_paper_id\":235652212},\"end\":128005,\"start\":127678},{\"attributes\":{\"id\":\"b138\",\"matched_paper_id\":3719281},\"end\":128243,\"start\":128007}]", "bib_title": "[{\"end\":88007,\"start\":87915},{\"end\":88332,\"start\":88218},{\"end\":88716,\"start\":88590},{\"end\":89074,\"start\":89003},{\"end\":89361,\"start\":89278},{\"end\":89673,\"start\":89609},{\"end\":90243,\"start\":90169},{\"end\":90480,\"start\":90419},{\"end\":90732,\"start\":90687},{\"end\":91049,\"start\":90955},{\"end\":91389,\"start\":91299},{\"end\":91733,\"start\":91672},{\"end\":92123,\"start\":92033},{\"end\":92561,\"start\":92454},{\"end\":92834,\"start\":92798},{\"end\":93765,\"start\":93693},{\"end\":94093,\"start\":93986},{\"end\":94450,\"start\":94403},{\"end\":94725,\"start\":94671},{\"end\":94960,\"start\":94908},{\"end\":95170,\"start\":95119},{\"end\":95469,\"start\":95407},{\"end\":95794,\"start\":95687},{\"end\":96065,\"start\":96011},{\"end\":96300,\"start\":96220},{\"end\":96612,\"start\":96532},{\"end\":96932,\"start\":96849},{\"end\":97186,\"start\":97119},{\"end\":97638,\"start\":97527},{\"end\":97967,\"start\":97938},{\"end\":98174,\"start\":98115},{\"end\":98391,\"start\":98349},{\"end\":98634,\"start\":98598},{\"end\":98868,\"start\":98800},{\"end\":99106,\"start\":99081},{\"end\":99266,\"start\":99241},{\"end\":99564,\"start\":99519},{\"end\":99813,\"start\":99759},{\"end\":100052,\"start\":100005},{\"end\":100316,\"start\":100270},{\"end\":100558,\"start\":100497},{\"end\":100827,\"start\":100753},{\"end\":101310,\"start\":101235},{\"end\":101627,\"start\":101556},{\"end\":101938,\"start\":101856},{\"end\":102242,\"start\":102188},{\"end\":102477,\"start\":102421},{\"end\":102697,\"start\":102649},{\"end\":103303,\"start\":103233},{\"end\":103562,\"start\":103490},{\"end\":103871,\"start\":103826},{\"end\":104332,\"start\":104256},{\"end\":104683,\"start\":104583},{\"end\":105023,\"start\":104946},{\"end\":105590,\"start\":105509},{\"end\":105862,\"start\":105795},{\"end\":106087,\"start\":106038},{\"end\":106355,\"start\":106244},{\"end\":106962,\"start\":106905},{\"end\":107355,\"start\":107233},{\"end\":107692,\"start\":107613},{\"end\":107904,\"start\":107868},{\"end\":108198,\"start\":108118},{\"end\":108446,\"start\":108404},{\"end\":109091,\"start\":108996},{\"end\":109431,\"start\":109316},{\"end\":109741,\"start\":109697},{\"end\":109951,\"start\":109907},{\"end\":110226,\"start\":110154},{\"end\":110520,\"start\":110425},{\"end\":110822,\"start\":110747},{\"end\":111095,\"start\":111040},{\"end\":111384,\"start\":111319},{\"end\":111723,\"start\":111630},{\"end\":112016,\"start\":111915},{\"end\":112317,\"start\":112267},{\"end\":112558,\"start\":112488},{\"end\":112799,\"start\":112717},{\"end\":113067,\"start\":113011},{\"end\":113310,\"start\":113251},{\"end\":113635,\"start\":113563},{\"end\":113951,\"start\":113871},{\"end\":114251,\"start\":114197},{\"end\":114571,\"start\":114504},{\"end\":114918,\"start\":114816},{\"end\":115261,\"start\":115148},{\"end\":115501,\"start\":115474},{\"end\":115844,\"start\":115775},{\"end\":116082,\"start\":116008},{\"end\":116331,\"start\":116262},{\"end\":116616,\"start\":116515},{\"end\":116886,\"start\":116819},{\"end\":117106,\"start\":117050},{\"end\":117306,\"start\":117237},{\"end\":117573,\"start\":117456},{\"end\":117947,\"start\":117873},{\"end\":118261,\"start\":118174},{\"end\":118561,\"start\":118475},{\"end\":118846,\"start\":118781},{\"end\":119159,\"start\":119065},{\"end\":119580,\"start\":119473},{\"end\":119871,\"start\":119827},{\"end\":120073,\"start\":120011},{\"end\":120360,\"start\":120327},{\"end\":120573,\"start\":120542},{\"end\":120745,\"start\":120683},{\"end\":121043,\"start\":120959},{\"end\":121705,\"start\":121622},{\"end\":122040,\"start\":122019},{\"end\":122458,\"start\":122416},{\"end\":122617,\"start\":122572},{\"end\":122884,\"start\":122778},{\"end\":123198,\"start\":123117},{\"end\":123501,\"start\":123450},{\"end\":123823,\"start\":123764},{\"end\":124009,\"start\":123971},{\"end\":124225,\"start\":124192},{\"end\":124759,\"start\":124693},{\"end\":125483,\"start\":125415},{\"end\":125742,\"start\":125670},{\"end\":125965,\"start\":125918},{\"end\":126181,\"start\":126154},{\"end\":126427,\"start\":126348},{\"end\":126682,\"start\":126618},{\"end\":126945,\"start\":126883},{\"end\":127184,\"start\":127134},{\"end\":127426,\"start\":127355},{\"end\":127736,\"start\":127678},{\"end\":128070,\"start\":128007}]", "bib_author": "[{\"end\":88017,\"start\":88009},{\"end\":88023,\"start\":88017},{\"end\":88039,\"start\":88023},{\"end\":88356,\"start\":88334},{\"end\":88372,\"start\":88356},{\"end\":88385,\"start\":88372},{\"end\":88724,\"start\":88718},{\"end\":88733,\"start\":88724},{\"end\":88741,\"start\":88733},{\"end\":88753,\"start\":88741},{\"end\":88769,\"start\":88753},{\"end\":89083,\"start\":89076},{\"end\":89091,\"start\":89083},{\"end\":89098,\"start\":89091},{\"end\":89106,\"start\":89098},{\"end\":89113,\"start\":89106},{\"end\":89369,\"start\":89363},{\"end\":89377,\"start\":89369},{\"end\":89385,\"start\":89377},{\"end\":89393,\"start\":89385},{\"end\":89400,\"start\":89393},{\"end\":89408,\"start\":89400},{\"end\":89681,\"start\":89675},{\"end\":89690,\"start\":89681},{\"end\":89697,\"start\":89690},{\"end\":89932,\"start\":89926},{\"end\":89939,\"start\":89932},{\"end\":89946,\"start\":89939},{\"end\":89953,\"start\":89946},{\"end\":89961,\"start\":89953},{\"end\":89969,\"start\":89961},{\"end\":90252,\"start\":90245},{\"end\":90259,\"start\":90252},{\"end\":90270,\"start\":90259},{\"end\":90490,\"start\":90482},{\"end\":90499,\"start\":90490},{\"end\":90507,\"start\":90499},{\"end\":90513,\"start\":90507},{\"end\":90529,\"start\":90513},{\"end\":90742,\"start\":90734},{\"end\":90748,\"start\":90742},{\"end\":90761,\"start\":90748},{\"end\":90771,\"start\":90761},{\"end\":90779,\"start\":90771},{\"end\":91060,\"start\":91051},{\"end\":91068,\"start\":91060},{\"end\":91074,\"start\":91068},{\"end\":91082,\"start\":91074},{\"end\":91090,\"start\":91082},{\"end\":91106,\"start\":91090},{\"end\":91399,\"start\":91391},{\"end\":91406,\"start\":91399},{\"end\":91412,\"start\":91406},{\"end\":91419,\"start\":91412},{\"end\":91427,\"start\":91419},{\"end\":91436,\"start\":91427},{\"end\":91442,\"start\":91436},{\"end\":91449,\"start\":91442},{\"end\":91457,\"start\":91449},{\"end\":91745,\"start\":91735},{\"end\":91754,\"start\":91745},{\"end\":91763,\"start\":91754},{\"end\":91774,\"start\":91763},{\"end\":91787,\"start\":91774},{\"end\":91799,\"start\":91787},{\"end\":91809,\"start\":91799},{\"end\":91817,\"start\":91809},{\"end\":91828,\"start\":91817},{\"end\":92134,\"start\":92125},{\"end\":92140,\"start\":92134},{\"end\":92148,\"start\":92140},{\"end\":92155,\"start\":92148},{\"end\":92162,\"start\":92155},{\"end\":92170,\"start\":92162},{\"end\":92176,\"start\":92170},{\"end\":92184,\"start\":92176},{\"end\":92193,\"start\":92184},{\"end\":92205,\"start\":92193},{\"end\":92214,\"start\":92205},{\"end\":92570,\"start\":92563},{\"end\":92579,\"start\":92570},{\"end\":92587,\"start\":92579},{\"end\":92593,\"start\":92587},{\"end\":92601,\"start\":92593},{\"end\":92843,\"start\":92836},{\"end\":92849,\"start\":92843},{\"end\":92856,\"start\":92849},{\"end\":92871,\"start\":92856},{\"end\":92879,\"start\":92871},{\"end\":93040,\"start\":93028},{\"end\":93050,\"start\":93040},{\"end\":93058,\"start\":93050},{\"end\":93065,\"start\":93058},{\"end\":93076,\"start\":93065},{\"end\":93089,\"start\":93076},{\"end\":93097,\"start\":93089},{\"end\":93110,\"start\":93097},{\"end\":93120,\"start\":93110},{\"end\":93126,\"start\":93120},{\"end\":93136,\"start\":93126},{\"end\":93150,\"start\":93136},{\"end\":93463,\"start\":93453},{\"end\":93470,\"start\":93463},{\"end\":93481,\"start\":93470},{\"end\":93493,\"start\":93481},{\"end\":93776,\"start\":93767},{\"end\":93785,\"start\":93776},{\"end\":93791,\"start\":93785},{\"end\":93799,\"start\":93791},{\"end\":93806,\"start\":93799},{\"end\":93814,\"start\":93806},{\"end\":94104,\"start\":94095},{\"end\":94110,\"start\":94104},{\"end\":94118,\"start\":94110},{\"end\":94130,\"start\":94118},{\"end\":94138,\"start\":94130},{\"end\":94154,\"start\":94138},{\"end\":94458,\"start\":94452},{\"end\":94465,\"start\":94458},{\"end\":94473,\"start\":94465},{\"end\":94479,\"start\":94473},{\"end\":94487,\"start\":94479},{\"end\":94495,\"start\":94487},{\"end\":94503,\"start\":94495},{\"end\":94510,\"start\":94503},{\"end\":94735,\"start\":94727},{\"end\":94742,\"start\":94735},{\"end\":94748,\"start\":94742},{\"end\":94757,\"start\":94748},{\"end\":94764,\"start\":94757},{\"end\":94970,\"start\":94962},{\"end\":94976,\"start\":94970},{\"end\":94983,\"start\":94976},{\"end\":94990,\"start\":94983},{\"end\":95180,\"start\":95172},{\"end\":95186,\"start\":95180},{\"end\":95193,\"start\":95186},{\"end\":95201,\"start\":95193},{\"end\":95215,\"start\":95201},{\"end\":95223,\"start\":95215},{\"end\":95236,\"start\":95223},{\"end\":95479,\"start\":95471},{\"end\":95486,\"start\":95479},{\"end\":95494,\"start\":95486},{\"end\":95500,\"start\":95494},{\"end\":95508,\"start\":95500},{\"end\":95516,\"start\":95508},{\"end\":95524,\"start\":95516},{\"end\":95805,\"start\":95796},{\"end\":95812,\"start\":95805},{\"end\":95824,\"start\":95812},{\"end\":96075,\"start\":96067},{\"end\":96088,\"start\":96075},{\"end\":96099,\"start\":96088},{\"end\":96320,\"start\":96302},{\"end\":96331,\"start\":96320},{\"end\":96342,\"start\":96331},{\"end\":96625,\"start\":96614},{\"end\":96632,\"start\":96625},{\"end\":96646,\"start\":96632},{\"end\":96657,\"start\":96646},{\"end\":96665,\"start\":96657},{\"end\":96941,\"start\":96934},{\"end\":96950,\"start\":96941},{\"end\":96958,\"start\":96950},{\"end\":96966,\"start\":96958},{\"end\":97196,\"start\":97188},{\"end\":97203,\"start\":97196},{\"end\":97212,\"start\":97203},{\"end\":97221,\"start\":97212},{\"end\":97229,\"start\":97221},{\"end\":97237,\"start\":97229},{\"end\":97244,\"start\":97237},{\"end\":97250,\"start\":97244},{\"end\":97257,\"start\":97250},{\"end\":97265,\"start\":97257},{\"end\":97272,\"start\":97265},{\"end\":97280,\"start\":97272},{\"end\":97651,\"start\":97640},{\"end\":97665,\"start\":97651},{\"end\":97677,\"start\":97665},{\"end\":97687,\"start\":97677},{\"end\":97699,\"start\":97687},{\"end\":97977,\"start\":97969},{\"end\":97984,\"start\":97977},{\"end\":97990,\"start\":97984},{\"end\":97998,\"start\":97990},{\"end\":98005,\"start\":97998},{\"end\":98183,\"start\":98176},{\"end\":98192,\"start\":98183},{\"end\":98204,\"start\":98192},{\"end\":98212,\"start\":98204},{\"end\":98402,\"start\":98393},{\"end\":98412,\"start\":98402},{\"end\":98419,\"start\":98412},{\"end\":98428,\"start\":98419},{\"end\":98436,\"start\":98428},{\"end\":98445,\"start\":98436},{\"end\":98449,\"start\":98445},{\"end\":98642,\"start\":98636},{\"end\":98650,\"start\":98642},{\"end\":98657,\"start\":98650},{\"end\":98663,\"start\":98657},{\"end\":98671,\"start\":98663},{\"end\":98679,\"start\":98671},{\"end\":98877,\"start\":98870},{\"end\":98885,\"start\":98877},{\"end\":98891,\"start\":98885},{\"end\":98898,\"start\":98891},{\"end\":98906,\"start\":98898},{\"end\":98914,\"start\":98906},{\"end\":98922,\"start\":98914},{\"end\":99116,\"start\":99108},{\"end\":99128,\"start\":99116},{\"end\":99137,\"start\":99128},{\"end\":99143,\"start\":99137},{\"end\":99279,\"start\":99268},{\"end\":99290,\"start\":99279},{\"end\":99300,\"start\":99290},{\"end\":99313,\"start\":99300},{\"end\":99322,\"start\":99313},{\"end\":99333,\"start\":99322},{\"end\":99343,\"start\":99333},{\"end\":99357,\"start\":99343},{\"end\":99572,\"start\":99566},{\"end\":99579,\"start\":99572},{\"end\":99587,\"start\":99579},{\"end\":99593,\"start\":99587},{\"end\":99600,\"start\":99593},{\"end\":99608,\"start\":99600},{\"end\":99614,\"start\":99608},{\"end\":99824,\"start\":99815},{\"end\":99832,\"start\":99824},{\"end\":99841,\"start\":99832},{\"end\":99850,\"start\":99841},{\"end\":99857,\"start\":99850},{\"end\":99864,\"start\":99857},{\"end\":100062,\"start\":100054},{\"end\":100071,\"start\":100062},{\"end\":100078,\"start\":100071},{\"end\":100087,\"start\":100078},{\"end\":100095,\"start\":100087},{\"end\":100103,\"start\":100095},{\"end\":100325,\"start\":100318},{\"end\":100333,\"start\":100325},{\"end\":100343,\"start\":100333},{\"end\":100350,\"start\":100343},{\"end\":100566,\"start\":100560},{\"end\":100573,\"start\":100566},{\"end\":100582,\"start\":100573},{\"end\":100590,\"start\":100582},{\"end\":100844,\"start\":100829},{\"end\":100853,\"start\":100844},{\"end\":100867,\"start\":100853},{\"end\":100882,\"start\":100867},{\"end\":100890,\"start\":100882},{\"end\":100905,\"start\":100890},{\"end\":100917,\"start\":100905},{\"end\":100929,\"start\":100917},{\"end\":100940,\"start\":100929},{\"end\":100949,\"start\":100940},{\"end\":100962,\"start\":100949},{\"end\":100973,\"start\":100962},{\"end\":101323,\"start\":101312},{\"end\":101331,\"start\":101323},{\"end\":101340,\"start\":101331},{\"end\":101349,\"start\":101340},{\"end\":101365,\"start\":101349},{\"end\":101374,\"start\":101365},{\"end\":101636,\"start\":101629},{\"end\":101643,\"start\":101636},{\"end\":101650,\"start\":101643},{\"end\":101656,\"start\":101650},{\"end\":101663,\"start\":101656},{\"end\":101672,\"start\":101663},{\"end\":101679,\"start\":101672},{\"end\":101686,\"start\":101679},{\"end\":101948,\"start\":101940},{\"end\":101955,\"start\":101948},{\"end\":101963,\"start\":101955},{\"end\":101972,\"start\":101963},{\"end\":101978,\"start\":101972},{\"end\":101986,\"start\":101978},{\"end\":101994,\"start\":101986},{\"end\":102001,\"start\":101994},{\"end\":102250,\"start\":102244},{\"end\":102257,\"start\":102250},{\"end\":102264,\"start\":102257},{\"end\":102271,\"start\":102264},{\"end\":102488,\"start\":102479},{\"end\":102495,\"start\":102488},{\"end\":102503,\"start\":102495},{\"end\":102515,\"start\":102503},{\"end\":102710,\"start\":102699},{\"end\":102720,\"start\":102710},{\"end\":102730,\"start\":102720},{\"end\":102740,\"start\":102730},{\"end\":102965,\"start\":102958},{\"end\":102973,\"start\":102965},{\"end\":102979,\"start\":102973},{\"end\":102993,\"start\":102979},{\"end\":103006,\"start\":102993},{\"end\":103013,\"start\":103006},{\"end\":103314,\"start\":103305},{\"end\":103327,\"start\":103314},{\"end\":103339,\"start\":103327},{\"end\":103570,\"start\":103564},{\"end\":103578,\"start\":103570},{\"end\":103586,\"start\":103578},{\"end\":103592,\"start\":103586},{\"end\":103598,\"start\":103592},{\"end\":103609,\"start\":103598},{\"end\":103616,\"start\":103609},{\"end\":103627,\"start\":103616},{\"end\":103636,\"start\":103627},{\"end\":103889,\"start\":103873},{\"end\":103900,\"start\":103889},{\"end\":103914,\"start\":103900},{\"end\":103923,\"start\":103914},{\"end\":103931,\"start\":103923},{\"end\":103946,\"start\":103931},{\"end\":103954,\"start\":103946},{\"end\":103965,\"start\":103954},{\"end\":103976,\"start\":103965},{\"end\":103989,\"start\":103976},{\"end\":103998,\"start\":103989},{\"end\":104013,\"start\":103998},{\"end\":104341,\"start\":104334},{\"end\":104350,\"start\":104341},{\"end\":104358,\"start\":104350},{\"end\":104370,\"start\":104358},{\"end\":104377,\"start\":104370},{\"end\":104385,\"start\":104377},{\"end\":104693,\"start\":104685},{\"end\":104701,\"start\":104693},{\"end\":104707,\"start\":104701},{\"end\":104713,\"start\":104707},{\"end\":104719,\"start\":104713},{\"end\":104727,\"start\":104719},{\"end\":105039,\"start\":105025},{\"end\":105047,\"start\":105039},{\"end\":105057,\"start\":105047},{\"end\":105066,\"start\":105057},{\"end\":105077,\"start\":105066},{\"end\":105087,\"start\":105077},{\"end\":105100,\"start\":105087},{\"end\":105114,\"start\":105100},{\"end\":105123,\"start\":105114},{\"end\":105133,\"start\":105123},{\"end\":105143,\"start\":105133},{\"end\":105152,\"start\":105143},{\"end\":105166,\"start\":105152},{\"end\":105176,\"start\":105166},{\"end\":105184,\"start\":105176},{\"end\":105193,\"start\":105184},{\"end\":105203,\"start\":105193},{\"end\":105604,\"start\":105592},{\"end\":105617,\"start\":105604},{\"end\":105870,\"start\":105864},{\"end\":105878,\"start\":105870},{\"end\":105886,\"start\":105878},{\"end\":105893,\"start\":105886},{\"end\":105899,\"start\":105893},{\"end\":106098,\"start\":106089},{\"end\":106111,\"start\":106098},{\"end\":106363,\"start\":106357},{\"end\":106369,\"start\":106363},{\"end\":106377,\"start\":106369},{\"end\":106383,\"start\":106377},{\"end\":106698,\"start\":106690},{\"end\":106706,\"start\":106698},{\"end\":106722,\"start\":106706},{\"end\":106971,\"start\":106964},{\"end\":106980,\"start\":106971},{\"end\":106987,\"start\":106980},{\"end\":106994,\"start\":106987},{\"end\":107002,\"start\":106994},{\"end\":107009,\"start\":107002},{\"end\":107020,\"start\":107009},{\"end\":107035,\"start\":107020},{\"end\":107047,\"start\":107035},{\"end\":107365,\"start\":107357},{\"end\":107373,\"start\":107365},{\"end\":107389,\"start\":107373},{\"end\":107704,\"start\":107694},{\"end\":107713,\"start\":107704},{\"end\":107724,\"start\":107713},{\"end\":107917,\"start\":107906},{\"end\":107926,\"start\":107917},{\"end\":107939,\"start\":107926},{\"end\":107950,\"start\":107939},{\"end\":107960,\"start\":107950},{\"end\":107969,\"start\":107960},{\"end\":108207,\"start\":108200},{\"end\":108216,\"start\":108207},{\"end\":108223,\"start\":108216},{\"end\":108230,\"start\":108223},{\"end\":108241,\"start\":108230},{\"end\":108463,\"start\":108448},{\"end\":108478,\"start\":108463},{\"end\":108711,\"start\":108702},{\"end\":108718,\"start\":108711},{\"end\":108725,\"start\":108718},{\"end\":108733,\"start\":108725},{\"end\":108741,\"start\":108733},{\"end\":108749,\"start\":108741},{\"end\":109100,\"start\":109093},{\"end\":109108,\"start\":109100},{\"end\":109115,\"start\":109108},{\"end\":109121,\"start\":109115},{\"end\":109128,\"start\":109121},{\"end\":109442,\"start\":109433},{\"end\":109449,\"start\":109442},{\"end\":109457,\"start\":109449},{\"end\":109464,\"start\":109457},{\"end\":109472,\"start\":109464},{\"end\":109479,\"start\":109472},{\"end\":109488,\"start\":109479},{\"end\":109750,\"start\":109743},{\"end\":109757,\"start\":109750},{\"end\":109765,\"start\":109757},{\"end\":109773,\"start\":109765},{\"end\":109782,\"start\":109773},{\"end\":109960,\"start\":109953},{\"end\":109967,\"start\":109960},{\"end\":109976,\"start\":109967},{\"end\":109983,\"start\":109976},{\"end\":109995,\"start\":109983},{\"end\":110004,\"start\":109995},{\"end\":110011,\"start\":110004},{\"end\":110235,\"start\":110228},{\"end\":110241,\"start\":110235},{\"end\":110247,\"start\":110241},{\"end\":110253,\"start\":110247},{\"end\":110261,\"start\":110253},{\"end\":110268,\"start\":110261},{\"end\":110530,\"start\":110522},{\"end\":110539,\"start\":110530},{\"end\":110547,\"start\":110539},{\"end\":110556,\"start\":110547},{\"end\":110565,\"start\":110556},{\"end\":110831,\"start\":110824},{\"end\":110839,\"start\":110831},{\"end\":110846,\"start\":110839},{\"end\":110852,\"start\":110846},{\"end\":110860,\"start\":110852},{\"end\":110872,\"start\":110860},{\"end\":111104,\"start\":111097},{\"end\":111114,\"start\":111104},{\"end\":111127,\"start\":111114},{\"end\":111137,\"start\":111127},{\"end\":111146,\"start\":111137},{\"end\":111159,\"start\":111146},{\"end\":111392,\"start\":111386},{\"end\":111401,\"start\":111392},{\"end\":111410,\"start\":111401},{\"end\":111419,\"start\":111410},{\"end\":111425,\"start\":111419},{\"end\":111433,\"start\":111425},{\"end\":111442,\"start\":111433},{\"end\":111448,\"start\":111442},{\"end\":111455,\"start\":111448},{\"end\":111732,\"start\":111725},{\"end\":111738,\"start\":111732},{\"end\":111745,\"start\":111738},{\"end\":111752,\"start\":111745},{\"end\":112025,\"start\":112018},{\"end\":112036,\"start\":112025},{\"end\":112051,\"start\":112036},{\"end\":112062,\"start\":112051},{\"end\":112073,\"start\":112062},{\"end\":112332,\"start\":112319},{\"end\":112342,\"start\":112332},{\"end\":112350,\"start\":112342},{\"end\":112360,\"start\":112350},{\"end\":112569,\"start\":112560},{\"end\":112578,\"start\":112569},{\"end\":112586,\"start\":112578},{\"end\":112807,\"start\":112801},{\"end\":112813,\"start\":112807},{\"end\":112819,\"start\":112813},{\"end\":112828,\"start\":112819},{\"end\":112835,\"start\":112828},{\"end\":112844,\"start\":112835},{\"end\":113076,\"start\":113069},{\"end\":113083,\"start\":113076},{\"end\":113089,\"start\":113083},{\"end\":113097,\"start\":113089},{\"end\":113103,\"start\":113097},{\"end\":113111,\"start\":113103},{\"end\":113319,\"start\":113312},{\"end\":113328,\"start\":113319},{\"end\":113334,\"start\":113328},{\"end\":113343,\"start\":113334},{\"end\":113349,\"start\":113343},{\"end\":113358,\"start\":113349},{\"end\":113370,\"start\":113358},{\"end\":113376,\"start\":113370},{\"end\":113387,\"start\":113376},{\"end\":113644,\"start\":113637},{\"end\":113652,\"start\":113644},{\"end\":113658,\"start\":113652},{\"end\":113666,\"start\":113658},{\"end\":113673,\"start\":113666},{\"end\":113681,\"start\":113673},{\"end\":113689,\"start\":113681},{\"end\":113696,\"start\":113689},{\"end\":113960,\"start\":113953},{\"end\":113966,\"start\":113960},{\"end\":113972,\"start\":113966},{\"end\":113981,\"start\":113972},{\"end\":113990,\"start\":113981},{\"end\":113998,\"start\":113990},{\"end\":114264,\"start\":114253},{\"end\":114273,\"start\":114264},{\"end\":114281,\"start\":114273},{\"end\":114288,\"start\":114281},{\"end\":114297,\"start\":114288},{\"end\":114307,\"start\":114297},{\"end\":114318,\"start\":114307},{\"end\":114329,\"start\":114318},{\"end\":114584,\"start\":114573},{\"end\":114595,\"start\":114584},{\"end\":114607,\"start\":114595},{\"end\":114615,\"start\":114607},{\"end\":114626,\"start\":114615},{\"end\":114640,\"start\":114626},{\"end\":114932,\"start\":114920},{\"end\":114943,\"start\":114932},{\"end\":114954,\"start\":114943},{\"end\":114965,\"start\":114954},{\"end\":115271,\"start\":115263},{\"end\":115279,\"start\":115271},{\"end\":115285,\"start\":115279},{\"end\":115293,\"start\":115285},{\"end\":115519,\"start\":115503},{\"end\":115536,\"start\":115519},{\"end\":115545,\"start\":115536},{\"end\":115551,\"start\":115545},{\"end\":115567,\"start\":115551},{\"end\":115576,\"start\":115567},{\"end\":115591,\"start\":115576},{\"end\":115601,\"start\":115591},{\"end\":115852,\"start\":115846},{\"end\":115860,\"start\":115852},{\"end\":115875,\"start\":115860},{\"end\":116093,\"start\":116084},{\"end\":116099,\"start\":116093},{\"end\":116107,\"start\":116099},{\"end\":116116,\"start\":116107},{\"end\":116339,\"start\":116333},{\"end\":116347,\"start\":116339},{\"end\":116354,\"start\":116347},{\"end\":116361,\"start\":116354},{\"end\":116369,\"start\":116361},{\"end\":116627,\"start\":116618},{\"end\":116635,\"start\":116627},{\"end\":116904,\"start\":116888},{\"end\":116915,\"start\":116904},{\"end\":117116,\"start\":117108},{\"end\":117126,\"start\":117116},{\"end\":117316,\"start\":117308},{\"end\":117323,\"start\":117316},{\"end\":117330,\"start\":117323},{\"end\":117583,\"start\":117575},{\"end\":117589,\"start\":117583},{\"end\":117596,\"start\":117589},{\"end\":117605,\"start\":117596},{\"end\":117614,\"start\":117605},{\"end\":117621,\"start\":117614},{\"end\":117632,\"start\":117621},{\"end\":117639,\"start\":117632},{\"end\":117958,\"start\":117949},{\"end\":117964,\"start\":117958},{\"end\":117972,\"start\":117964},{\"end\":117979,\"start\":117972},{\"end\":117987,\"start\":117979},{\"end\":117994,\"start\":117987},{\"end\":118002,\"start\":117994},{\"end\":118272,\"start\":118263},{\"end\":118280,\"start\":118272},{\"end\":118290,\"start\":118280},{\"end\":118298,\"start\":118290},{\"end\":118307,\"start\":118298},{\"end\":118570,\"start\":118563},{\"end\":118578,\"start\":118570},{\"end\":118588,\"start\":118578},{\"end\":118595,\"start\":118588},{\"end\":118606,\"start\":118595},{\"end\":118854,\"start\":118848},{\"end\":118862,\"start\":118854},{\"end\":118868,\"start\":118862},{\"end\":118876,\"start\":118868},{\"end\":118885,\"start\":118876},{\"end\":118891,\"start\":118885},{\"end\":118898,\"start\":118891},{\"end\":118904,\"start\":118898},{\"end\":119168,\"start\":119161},{\"end\":119177,\"start\":119168},{\"end\":119186,\"start\":119177},{\"end\":119193,\"start\":119186},{\"end\":119204,\"start\":119193},{\"end\":119215,\"start\":119204},{\"end\":119244,\"start\":119215},{\"end\":119591,\"start\":119582},{\"end\":119600,\"start\":119591},{\"end\":119609,\"start\":119600},{\"end\":119617,\"start\":119609},{\"end\":119625,\"start\":119617},{\"end\":119632,\"start\":119625},{\"end\":119879,\"start\":119873},{\"end\":119888,\"start\":119879},{\"end\":119895,\"start\":119888},{\"end\":119902,\"start\":119895},{\"end\":120085,\"start\":120075},{\"end\":120094,\"start\":120085},{\"end\":120103,\"start\":120094},{\"end\":120114,\"start\":120103},{\"end\":120125,\"start\":120114},{\"end\":120135,\"start\":120125},{\"end\":120369,\"start\":120362},{\"end\":120375,\"start\":120369},{\"end\":120384,\"start\":120375},{\"end\":120390,\"start\":120384},{\"end\":120399,\"start\":120390},{\"end\":120405,\"start\":120399},{\"end\":120412,\"start\":120405},{\"end\":120581,\"start\":120575},{\"end\":120589,\"start\":120581},{\"end\":120596,\"start\":120589},{\"end\":120755,\"start\":120747},{\"end\":120768,\"start\":120755},{\"end\":120779,\"start\":120768},{\"end\":120790,\"start\":120779},{\"end\":120800,\"start\":120790},{\"end\":121053,\"start\":121045},{\"end\":121060,\"start\":121053},{\"end\":121070,\"start\":121060},{\"end\":121363,\"start\":121350},{\"end\":121374,\"start\":121363},{\"end\":121386,\"start\":121374},{\"end\":121398,\"start\":121386},{\"end\":121411,\"start\":121398},{\"end\":121420,\"start\":121411},{\"end\":121719,\"start\":121707},{\"end\":121729,\"start\":121719},{\"end\":121740,\"start\":121729},{\"end\":121750,\"start\":121740},{\"end\":121764,\"start\":121750},{\"end\":121775,\"start\":121764},{\"end\":121786,\"start\":121775},{\"end\":122054,\"start\":122042},{\"end\":122064,\"start\":122054},{\"end\":122075,\"start\":122064},{\"end\":122086,\"start\":122075},{\"end\":122250,\"start\":122235},{\"end\":122257,\"start\":122250},{\"end\":122270,\"start\":122257},{\"end\":122279,\"start\":122270},{\"end\":122289,\"start\":122279},{\"end\":122472,\"start\":122460},{\"end\":122478,\"start\":122472},{\"end\":122633,\"start\":122619},{\"end\":122644,\"start\":122633},{\"end\":122655,\"start\":122644},{\"end\":122895,\"start\":122886},{\"end\":122904,\"start\":122895},{\"end\":122916,\"start\":122904},{\"end\":122926,\"start\":122916},{\"end\":123210,\"start\":123200},{\"end\":123223,\"start\":123210},{\"end\":123236,\"start\":123223},{\"end\":123246,\"start\":123236},{\"end\":123509,\"start\":123503},{\"end\":123520,\"start\":123509},{\"end\":123534,\"start\":123520},{\"end\":123542,\"start\":123534},{\"end\":123549,\"start\":123542},{\"end\":123559,\"start\":123549},{\"end\":123571,\"start\":123559},{\"end\":123833,\"start\":123825},{\"end\":123841,\"start\":123833},{\"end\":123849,\"start\":123841},{\"end\":124018,\"start\":124011},{\"end\":124025,\"start\":124018},{\"end\":124032,\"start\":124025},{\"end\":124038,\"start\":124032},{\"end\":124047,\"start\":124038},{\"end\":124054,\"start\":124047},{\"end\":124060,\"start\":124054},{\"end\":124239,\"start\":124227},{\"end\":124251,\"start\":124239},{\"end\":124257,\"start\":124251},{\"end\":124267,\"start\":124257},{\"end\":124419,\"start\":124410},{\"end\":124425,\"start\":124419},{\"end\":124434,\"start\":124425},{\"end\":124441,\"start\":124434},{\"end\":124450,\"start\":124441},{\"end\":124457,\"start\":124450},{\"end\":124464,\"start\":124457},{\"end\":124470,\"start\":124464},{\"end\":124481,\"start\":124470},{\"end\":124493,\"start\":124481},{\"end\":124499,\"start\":124493},{\"end\":124510,\"start\":124499},{\"end\":124770,\"start\":124761},{\"end\":124779,\"start\":124770},{\"end\":124792,\"start\":124779},{\"end\":124804,\"start\":124792},{\"end\":124815,\"start\":124804},{\"end\":125118,\"start\":125109},{\"end\":125126,\"start\":125118},{\"end\":125144,\"start\":125126},{\"end\":125152,\"start\":125144},{\"end\":125162,\"start\":125152},{\"end\":125178,\"start\":125162},{\"end\":125494,\"start\":125485},{\"end\":125501,\"start\":125494},{\"end\":125509,\"start\":125501},{\"end\":125521,\"start\":125509},{\"end\":125753,\"start\":125744},{\"end\":125760,\"start\":125753},{\"end\":125772,\"start\":125760},{\"end\":125978,\"start\":125967},{\"end\":125987,\"start\":125978},{\"end\":126001,\"start\":125987},{\"end\":126014,\"start\":126001},{\"end\":126192,\"start\":126183},{\"end\":126202,\"start\":126192},{\"end\":126213,\"start\":126202},{\"end\":126229,\"start\":126213},{\"end\":126438,\"start\":126429},{\"end\":126446,\"start\":126438},{\"end\":126462,\"start\":126446},{\"end\":126693,\"start\":126684},{\"end\":126703,\"start\":126693},{\"end\":126717,\"start\":126703},{\"end\":126728,\"start\":126717},{\"end\":126956,\"start\":126947},{\"end\":126967,\"start\":126956},{\"end\":126976,\"start\":126967},{\"end\":126987,\"start\":126976},{\"end\":127194,\"start\":127186},{\"end\":127204,\"start\":127194},{\"end\":127211,\"start\":127204},{\"end\":127223,\"start\":127211},{\"end\":127434,\"start\":127428},{\"end\":127442,\"start\":127434},{\"end\":127450,\"start\":127442},{\"end\":127458,\"start\":127450},{\"end\":127466,\"start\":127458},{\"end\":127473,\"start\":127466},{\"end\":127485,\"start\":127473},{\"end\":127496,\"start\":127485},{\"end\":127746,\"start\":127738},{\"end\":127753,\"start\":127746},{\"end\":127759,\"start\":127753},{\"end\":127766,\"start\":127759},{\"end\":127774,\"start\":127766},{\"end\":127783,\"start\":127774},{\"end\":127789,\"start\":127783},{\"end\":127796,\"start\":127789},{\"end\":127804,\"start\":127796},{\"end\":128087,\"start\":128072},{\"end\":128098,\"start\":128087},{\"end\":128106,\"start\":128098}]", "bib_venue": "[{\"end\":88042,\"start\":88039},{\"end\":88389,\"start\":88385},{\"end\":88773,\"start\":88769},{\"end\":89116,\"start\":89113},{\"end\":89413,\"start\":89408},{\"end\":89702,\"start\":89697},{\"end\":89924,\"start\":89853},{\"end\":90274,\"start\":90270},{\"end\":90533,\"start\":90529},{\"end\":90784,\"start\":90779},{\"end\":91110,\"start\":91106},{\"end\":91461,\"start\":91457},{\"end\":91832,\"start\":91828},{\"end\":92218,\"start\":92214},{\"end\":92605,\"start\":92601},{\"end\":92883,\"start\":92879},{\"end\":93026,\"start\":93010},{\"end\":93451,\"start\":93395},{\"end\":93818,\"start\":93814},{\"end\":94159,\"start\":94154},{\"end\":94520,\"start\":94510},{\"end\":94768,\"start\":94764},{\"end\":94994,\"start\":94990},{\"end\":95246,\"start\":95236},{\"end\":95526,\"start\":95524},{\"end\":95828,\"start\":95824},{\"end\":96103,\"start\":96099},{\"end\":96347,\"start\":96342},{\"end\":96672,\"start\":96665},{\"end\":96970,\"start\":96966},{\"end\":97285,\"start\":97280},{\"end\":97704,\"start\":97699},{\"end\":98009,\"start\":98005},{\"end\":98216,\"start\":98212},{\"end\":98456,\"start\":98449},{\"end\":98683,\"start\":98679},{\"end\":98926,\"start\":98922},{\"end\":99147,\"start\":99143},{\"end\":99364,\"start\":99357},{\"end\":99618,\"start\":99614},{\"end\":99868,\"start\":99864},{\"end\":100107,\"start\":100103},{\"end\":100355,\"start\":100350},{\"end\":100595,\"start\":100590},{\"end\":100977,\"start\":100973},{\"end\":101385,\"start\":101381},{\"end\":101690,\"start\":101686},{\"end\":102005,\"start\":102001},{\"end\":102276,\"start\":102271},{\"end\":102527,\"start\":102522},{\"end\":102751,\"start\":102747},{\"end\":102956,\"start\":102874},{\"end\":103346,\"start\":103339},{\"end\":103640,\"start\":103636},{\"end\":104020,\"start\":104013},{\"end\":104390,\"start\":104385},{\"end\":104732,\"start\":104727},{\"end\":105207,\"start\":105203},{\"end\":105622,\"start\":105617},{\"end\":105903,\"start\":105899},{\"end\":106115,\"start\":106111},{\"end\":106386,\"start\":106383},{\"end\":106688,\"start\":106575},{\"end\":107051,\"start\":107047},{\"end\":107394,\"start\":107389},{\"end\":107728,\"start\":107724},{\"end\":107973,\"start\":107969},{\"end\":108245,\"start\":108241},{\"end\":108489,\"start\":108485},{\"end\":108700,\"start\":108592},{\"end\":109131,\"start\":109128},{\"end\":109492,\"start\":109488},{\"end\":109786,\"start\":109782},{\"end\":110015,\"start\":110011},{\"end\":110279,\"start\":110275},{\"end\":110572,\"start\":110565},{\"end\":110879,\"start\":110872},{\"end\":111163,\"start\":111159},{\"end\":111459,\"start\":111455},{\"end\":111757,\"start\":111752},{\"end\":112077,\"start\":112073},{\"end\":112364,\"start\":112360},{\"end\":112590,\"start\":112586},{\"end\":112848,\"start\":112844},{\"end\":113115,\"start\":113111},{\"end\":113392,\"start\":113387},{\"end\":113700,\"start\":113696},{\"end\":114003,\"start\":113998},{\"end\":114336,\"start\":114329},{\"end\":114647,\"start\":114640},{\"end\":114969,\"start\":114965},{\"end\":115297,\"start\":115293},{\"end\":115608,\"start\":115601},{\"end\":115879,\"start\":115875},{\"end\":116120,\"start\":116116},{\"end\":116373,\"start\":116369},{\"end\":116639,\"start\":116635},{\"end\":116926,\"start\":116922},{\"end\":117130,\"start\":117126},{\"end\":117334,\"start\":117330},{\"end\":117643,\"start\":117639},{\"end\":118006,\"start\":118002},{\"end\":118311,\"start\":118307},{\"end\":118610,\"start\":118606},{\"end\":118908,\"start\":118904},{\"end\":119248,\"start\":119244},{\"end\":119636,\"start\":119632},{\"end\":119906,\"start\":119902},{\"end\":120139,\"start\":120135},{\"end\":120416,\"start\":120412},{\"end\":120600,\"start\":120596},{\"end\":120807,\"start\":120800},{\"end\":121075,\"start\":121070},{\"end\":121348,\"start\":121253},{\"end\":121790,\"start\":121786},{\"end\":122097,\"start\":122093},{\"end\":122233,\"start\":122195},{\"end\":122482,\"start\":122478},{\"end\":122659,\"start\":122655},{\"end\":122930,\"start\":122926},{\"end\":123251,\"start\":123246},{\"end\":123575,\"start\":123571},{\"end\":123853,\"start\":123849},{\"end\":124064,\"start\":124060},{\"end\":124271,\"start\":124267},{\"end\":124408,\"start\":124376},{\"end\":124819,\"start\":124815},{\"end\":125107,\"start\":124977},{\"end\":125525,\"start\":125521},{\"end\":125776,\"start\":125772},{\"end\":126018,\"start\":126014},{\"end\":126233,\"start\":126229},{\"end\":126466,\"start\":126462},{\"end\":126732,\"start\":126728},{\"end\":126991,\"start\":126987},{\"end\":127235,\"start\":127231},{\"end\":127500,\"start\":127496},{\"end\":127807,\"start\":127804},{\"end\":128112,\"start\":128106}]"}}}, "year": 2023, "month": 12, "day": 17}