{"id": 235436036, "updated": "2023-10-06 02:25:44.259", "metadata": {"title": "Towards Total Recall in Industrial Anomaly Detection", "authors": "[{\"first\":\"Karsten\",\"last\":\"Roth\",\"middle\":[]},{\"first\":\"Latha\",\"last\":\"Pemula\",\"middle\":[]},{\"first\":\"Joaquin\",\"last\":\"Zepeda\",\"middle\":[]},{\"first\":\"Bernhard\",\"last\":\"Scholkopf\",\"middle\":[]},{\"first\":\"Thomas\",\"last\":\"Brox\",\"middle\":[]},{\"first\":\"Peter\",\"last\":\"Gehler\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Being able to spot defective parts is a critical component in large-scale industrial manufacturing. A particular challenge that we address in this work is the cold-start problem: fit a model using nominal (non-defective) example images only. While handcrafted solutions per class are possible, the goal is to build systems that work well simultaneously on many different tasks automatically. The best performing approaches combine embeddings from ImageNet models with an outlier detection model. In this paper, we extend on this line of work and propose \\textbf{PatchCore}, which uses a maximally representative memory bank of nominal patch-features. PatchCore offers competitive inference times while achieving state-of-the-art performance for both detection and localization. On the challenging, widely used MVTec AD benchmark PatchCore achieves an image-level anomaly detection AUROC score of up to $99.6\\%$, more than halving the error compared to the next best competitor. We further report competitive results on two additional datasets and also find competitive results in the few samples regime.\\freefootnote{$^*$ Work done during a research internship at Amazon AWS.} Code: github.com/amazon-research/patchcore-inspection.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2106.08265", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/RothPZSBG22", "doi": "10.1109/cvpr52688.2022.01392"}}, "content": {"source": {"pdf_hash": "23ad8fc48530ce366f8192dfb48d0f7df1dba277", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2106.08265v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "14b88a56efbe7ae3542640d3b74f6e7898d7b518", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/23ad8fc48530ce366f8192dfb48d0f7df1dba277.txt", "contents": "\nTowards Total Recall in Industrial Anomaly Detection\n\n\nKarsten Roth \nUniversity of T\u00fcbingen\n\n\nLatha Pemula \nAmazon AWS\n\n\nJoaquin Zepeda \nAmazon AWS\n\n\nBernhard Sch\u00f6lkopf \nAmazon AWS\n\n\nThomas Brox \nAmazon AWS\n\n\nPeter Gehler \nAmazon AWS\n\n\nTowards Total Recall in Industrial Anomaly Detection\n\nBeing able to spot defective parts is a critical component in large-scale industrial manufacturing. A particular challenge that we address in this work is the cold-start problem: fit a model using nominal (non-defective) example images only. While handcrafted solutions per class are possible, the goal is to build systems that work well simultaneously on many different tasks automatically. The best peforming approaches combine embeddings from ImageNet models with an outlier detection model. In this paper, we extend on this line of work and propose PatchCore, which uses a maximally representative memory bank of nominal patchfeatures. PatchCore offers competitive inference times while achieving state-of-the-art performance for both detection and localization. On the challenging, widely used MVTec AD benchmark PatchCore achieves an image-level anomaly detection AUROC score of up to 99.6%, more than halving the error compared to the next best competitor. We further report competitive results on two additional datasets and also find competitive results in the few samples regime. Code: github.com/amazon-research/patchcore-inspection. * Work done during a research internship at Amazon AWS.1 Commonly also dubbed one-class classification (OCC).\n\nIntroduction\n\nThe ability to detect unusual patterns in images is a feature deeply ingrained in human cognition. Humans can differentiate between expected variance in the data and outliers after having only seen a small number of normal instances. In this work we address the computational version of this problem, cold-start 1 anomaly detection for visual inspection of industrial image data. It arises in many industrial scenarios where it is easy to acquire imagery of normal examples but costly and complicated to specify the expected defect variations in full. This task is naturally cast as a outof-distribution detection problem where a model needs to distinguish between samples being drawn from the training data distribution and those outside its support. Industrial visual defect classification is especially hard, as errors can Figure 1. Examples from the MVTec benchmark datasets. Superimposed on the images are the segmentation results from Patch-Core. The orange boundary denotes anomaly contours of actual segmentation maps for anomalies such as broken glass, scratches, burns or structural changes in blue-orange color gradients.\n\nvary from subtle changes such as thin scratches to larger structural defects like missing components [5]. Some examples from the MVTec AD benchmark along with results from our proposed method are shown in Figure 1. Existing work on cold-start, industrial visual anomaly detection relies on learning a model of the nominal distribution via autoencoding methods [12,36,44], GANs [2,39,43], or other unsupervised adaptation methods [42,56]. Recently, [4,10] proposed to leverag common deep representations from Im-ageNet classification without adaptation to the target distribution. Despite the missing adaptation, these models offer strong anomaly detection performance and even solid spatial localization of the defects. The key principle behind these techniques is a feature matching between the test sample and the nominal samples while exploiting the multiscale nature of deep feature representations. Subtle, finegrained defect segmentation is covered by high-resolution features, whereas structural deviations and full image-level anomaly detection are supposed to be covered by features at much higher abstraction levels. The inherent downside of this approach, since it is non-adaptive, is the limited matching confidence at the higher abstraction levels: high-level abstract features from ImageNet training coincide little with the abstract features required in an industrial environment. In addition, nominal context usable by these methods at test time is effectively limited by the small number of extractable high-level feature representations.\n\nIn this paper, we present PatchCore as an effective remedy by (1) maximizing nominal information available at test time, (2) reducing biases towards ImageNet classes and (3) retaining high inference speeds. Relying on the fact that an image can be already classified as anomalous as soon as a single patch is anomalous [14,56], Patch-Core achieves this by utilizing locally aggregated, mid-level features patches. The usage of mid-level network patch features allows PatchCore to operate with minimal bias towards ImageNet classes on a high resolution, while a feature aggregation over a local neighbourhood ensures retention of sufficient spatial context. This results in an extensive memory bank allowing PatchCore to optimally leverage available nominal context at test time. Finally, for practical applicability, PatchCore additionally introduces greedy coreset subsampling [1] for nominal feature banks as a key element to both reduce redundancy in the extracted, patch-level memory bank as well as significantly bringing down storage memory and inference time, making Patch-Core very attractive for realistic industrial use cases.\n\nThorough experiments on the diverse MVTec AD [5] as well as the specialized Magnetic Tile Defects (MTD) [26] industrial anomaly detection benchmarks showcase the power of PatchCore for industrial anomaly detection. It achieves state-of-the-art image-level detection scores on MVTec AD and MTD, with nearly perfect scores on MVTec AD (up to AUROC 99.6%), reducing detection error of previous methods by more than half, as well as state-ofthe-art industrial anomaly localization performance. Patch-Core achieves this while retaining fast inference times without requiring training on the dataset at hand. This makes PatchCore very attractive for practical use in industrial anomaly detection. In addition, further experiments showcase the high sample efficiency of PatchCore, matching existing anomaly detection methods in performance while using only a fraction of the nominal training data.\n\n\nRelated Works\n\nMost anomaly detection models rely on the ability to learn representations inherent to the nominal data. This can be achieved for example through the usage of autoencoding models [44]. To encourage better estimation of the nominal feature distribution, extensions based on Gaussian mixture models [60], generative adversarial training objectives [2,39,43], invariance towards predefined physical augmentations [25], robustness of hidden features to reintroduction of reconstructions [29], prototypical memory banks [21], attention-guidance [52], structural objectives [7,59] or constrained representation spaces [38] have been pro-posed. Other unsupervised representation learning methods can similarly be utilised, such as via GANs [13], learning to predict predefined geometric transformations [20] or via normalizing flows [42]. Given respective nominal representations and novel test representations, anomaly detection can then be a simple matter of reconstruction errors [44], distances to k nearest neighbours [18] or finetuning of a one-class classification model such as OC-SVMs [46] or SVDD [50,56] on top of these features. For the majority of these approaches, anomaly localization comes naturally based on pixel-wise reconstruction errors, saliency-based approaches such as GradCAM [47] or XRAI [28] can be used for anomaly segmentation [42,45,52] as well.\n\nIndustrial Anomaly Detection. While literature on general anomaly detection through learned nominal representations is vast, industrial image data comes with its own challenges [5], for which recent works starting with [4] have shown state-of-the-art detection performance using models pretrained on large external natural image datasets such as ImageNet [16] without any adaptation to the data at hand. This has given rise to other industrial anomaly detection methods reliant on better reuse of pretrained features such as SPADE [10], which utilizes memory banks comprising various feature hierarchies for finegrained, kNN-based [18] anomaly segmentation and image-level anomaly detection. Similarly, [14] recently proposed PaDiM, which utilizes a locally constrained bag-of-features approach [8], estimating patch-level feature distribution moments (mean and covariance) for patch-level Mahalanobis distance measures [33]. This approach is similar to [40] studied on full images. To better account for the distribution shift between natural pretraining and industrial image data, subsequent adaptation can be done, e.g. via student-teacher knowledge distillation [24] such as in [6,45] or normalizing flows [17,30] trained on top of pretrained network features [42].\n\nThe specific components used in PatchCore are most related to SPADE and PaDiM. SPADE makes use of a memory-bank of nominal features extracted from a pretrained backbone network with separate approaches for image-and pixel-level anomaly detection. PatchCore similarly uses a memory bank, however with neighbourhoodaware patch-level features critical to achieve higher performance, as more nominal context is retained and a better fitting inductive bias is incorporated. In addition, the memory bank is coreset-subsampled to ensure low inference cost at higher performance. Coresets have seen longstanding usage in fundamental kNN and kMeans approaches [22] or mixture models [19] by finding subsets that best approximate the structure of some available set and allow for approximate solution finding with notably reduced cost [1,9]. More recently, coreset-based methods have also found their way into Deep Learning approaches, e.g for network pruning [34], active learning [48] and increasing effective data coverage of mini-batches for improved GAN training [49] or representation learning [41]. The latter three have found success utilizing a greedy coreset selection mechanism. As we aim to approximate memory bank feature space coverage, we similarly adapt a greedy coreset mechanism for PatchCore . Finally, our patch-level approach to both image-level anomaly detection and anomaly segmentation is related to PaDiM with the goal of encouraging higher anomaly detection sensitivity. We make use of an efficient patch-feature memory bank equally accessible to all patches evaluated at test time, whereas PaDiM limits patch-level anomaly detection to Mahalanobis distance measures specific to each patch. In doing so, PatchCore becomes less reliant on image alignment while also estimating anomalies using a much larger nominal context. Furthermore, unlike PaDiM, input images do not require the same shape during training and testing. Finally, PatchCore makes use of locally aware patch-feature scores to account for local spatial variance and to reduce bias towards ImageNet classes.\n\n\nMethod\n\nThe PatchCore method consists of several parts that we will describe in sequence: local patch features aggregated into a memory bank ( \u00a73.1), a coreset-reduction method to increase efficiency ( \u00a73.2) and finally the full algorithm that arrives at detection and localization decisions ( \u00a73.3).\n\n\nLocally aware patch features\n\nWe use X N to denote the set of all nominal images (\u2200x \u2208 X N : y x = 0) available at training time, with y x \u2208 {0, 1} denoting if an image x is nominal (0) or anomalous (1). Accordingly, we define X T to be the set of samples provided at test time, with \u2200x \u2208 X T : y x \u2208 {0, 1}. Following [4], [10] and [14], PatchCore uses a network \u03c6 pre-trained on ImageNet. As the features at specific network hierarchies plays an important role, we use \u03c6 i,j = \u03c6 j (x i ) to denote the features for image x i \u2208 X (with dataset X ) and hierarchylevel j of the pretrained network \u03c6. If not noted otherwise, in concordance with existing literature, j indexes feature maps from ResNet-like [23] architectures, such as ResNet-50 or WideResnet-50 [57], with j \u2208 {1, 2, 3, 4} indicating the final output of respective spatial resolution blocks.\n\nOne choice for a feature representation would be the last level in the feature hierarchy of the network. This is done in [4] or [10] but introduces the following two problems. Firstly, it loses more localized nominal information [14]. As the types of anomalies encountered at test time are not known a priori, this becomes detrimental to the downstream anomaly detection performance. Secondly, very deep and abstract features in ImageNet pretrained networks are biased towards the task of natural image classification, which has only little overlap with the cold-start industrial anomaly detection task and the evaluated data at hand.\n\nWe thus propose to use a memory bank M of patch-level features comprising intermediate or mid-level feature representations to make use of provided training context, avoiding features too generic or too heavily biased towards Im-ageNet classification. In the specific case of ResNet-like architectures, this would refer to e.g. j \u2208 [2,3]. To formalize the patch representation we extend the previously introduced notation. Assume the feature map \u03c6 i,j \u2208 R c * \u00d7h * \u00d7w * to be a three-dimensional tensor of depth c * , height h * and width w * . We then use \u03c6 i,j (h, w) = \u03c6 j (x i , h, w) \u2208 R c * to denote the c * -dimensional feature slice at positions h \u2208 {1, . . . , h * } and w \u2208 {1, . . . , w * }. Assuming the receptive field size of each \u03c6 i,j to be larger than one, this effectively relates to image-patch feature representations. Ideally, each patch-representation operates on a large enough receptive field size to account for meaningful anomalous context robust to local spatial variations. While this could be achieved by strided pooling and going further down the network hierarchy, the thereby created patch-features become more ImageNet-specific and thus less relevant for the anomaly detection task at hand, while training cost increases and effective feature map resolution drops.\n\nThis motivates a local neighbourhood aggregation when composing each patch-level feature representation to increase receptive field size and robustness to small spatial deviations without losing spatial resolution or usability of feature maps. For that, we extend above notation for \u03c6 i,j (h, w) to account for an uneven patchsizes p (corresponding to the neighbourhood size considered), incorporating feature vectors from the neighbourhood\nN (h,w) p = {(a, b)|a \u2208 [h \u2212 p/2 , ..., h + p/2 ], b \u2208 [w \u2212 p/2 , ..., w + p/2 ]},(1)\nand locally aware features at position (h, w) as\n\u03c6 i,j N (h,w) p = f agg {\u03c6 i,j (a, b)|(a, b) \u2208 N (h,w) p } ,(2)\nwith f agg some aggregation function of feature vectors in the neighbourhood N (h,w) p . For PatchCore, we use adaptive average pooling. This is similar to local smoothing over each individual feature map, and results in one single representation at (h, w) of predefined dimensionality d, which is performed for all pairs (h, w) with h \u2208 {1, ..., h * } and w \u2208 {1, ..., w * } and thus retains feature map resolution. For a feature map tensor \u03c6 i,j , its locally aware patch-feature collection P s,p (\u03c6 i,j ) is\nP s,p (\u03c6 i,j ) = {\u03c6 i,j (N (h,w) p )| h, w mod s = 0, h < h * , w < w * , h, w \u2208 N},(3)\nwith the optional use of a striding parameter s, which we set to 1 except for ablation experiments done in \u00a74.4.2. Empirically and similar to [10] and [14], we found aggregation of multiple feature hierarchies to offer some benefit. However, to retain the generality of used features as well as the spatial resolution, PatchCore uses only two intermediate feature hierarchies j and j + 1. This is achieved simply by computing P s,p (\u03c6 i,j+1 ) and aggregating each element with its corresponding patch feature at the lowest hierarchy level used (i.e., at the highest resolution), which we achieve by bilinearly rescaling P s,\np (\u03c6 i,j+1 ) such that |P s,p (\u03c6 i,j+1 )| and |P s,p (\u03c6 i,j )| match.\nFinally, for all nominal training samples x i \u2208 X N , the PatchCore memory bank M is then simply defined as\nM = xi\u2208X N P s,p (\u03c6 j (x i )).(4)\n\nCoreset-reduced patch-feature memory bank\n\nFor increasing sizes of X N , M becomes exceedingly large and with it both the inference time to evaluate novel test data and required storage. This issue has already been noted in SPADE [10] for anomaly segmentation, which makes use of both low-and high-level feature maps. Due to computational limitations, SPADE requires a preselec-tion stage of feature maps for pixel-level anomaly detection based on a weaker image-level anomaly detection mechanism reliant on full-image, deep feature representations, i.e., global averaging of the last feature map. This results in low-resolution, ImageNet-biased representations computed from full images which may negatively impact detection and localization performance.\n\nThese issues can be addressed by making M meaningfully searchable for larger image sizes and counts, allowing for patch-based comparison beneficial to both anomaly detection and segmentation. This requires that the nominal feature coverage encoded in M is retained. Unfortunately, random subsampling, especially by several magnitudes, will lose significant information available in M encoded in the coverage of nominal features (see also experiments done in \u00a74. 4.2). In this work we use a coreset subsampling mechanism to reduce M, which we find reduces inference time while retaining performance.\n\nConceptually, coreset selection aims to find a subset S \u2282 A such that problem solutions over A can be most closely and especially more quickly approximated by those computed over S [1]. Depending on the specific problem, the coreset of interest varies. Because PatchCore uses nearest neighbour computations (next Section), we use a minimax facility location coreset selection, see e.g., [48] and [49], to ensure approximately similar coverage of the M-coreset M C in patch-level feature space as compared to the original memory bank M\nM * C = arg min M C \u2282M max m\u2208M min n\u2208M C m \u2212 n 2 .(5)\nThe exact computation of M * C is NP-Hard [54], we use the iterative greedy approximation suggested in [48]. To further reduce coreset selection time, we follow [49], making use of the Johnson-Lindenstrauss theorem [11] to reduce dimensionalities of elements m \u2208 M through random linear projections \u03c8 :\nR d \u2192 R d * with d * < d.\nThe memory bank reduction is summarized in Algorithm 1. For notation, we use PatchCore\u2212n% to denote the percentage n to which the original memory bank has been subsampled to, e.g., Patch-Core\u22121% a 100x times reduction of M. Figure 3 gives a visual impression of the spatial coverage of greedy coreset subsampling compared to random selection.\n\nAlgorithm 1: PatchCore memory bank.\n\nInput: Pretrained \u03c6, hierarchies j, nominal data X N , stride s, patchsize p, coreset target l, random linear projection \u03c8. Output: Patch-level Memory bank M. Algorithm:\nM \u2190 {} for x i \u2208 X N do M \u2190 M \u222a P s,p (\u03c6 j (x i )) end / * Apply greedy coreset selection. * / M C \u2190 {} for i \u2208 [0, ..., l \u2212 1] do m i \u2190 arg max m\u2208M\u2212M C min n\u2208M C \u03c8(m) \u2212 \u03c8(n) 2 M C \u2190 M C \u222a {m i } end M \u2190 M C\n\nAnomaly Detection with PatchCore\n\nWith the nominal patch-feature memory bank M, we estimate the image-level anomaly score s \u2208 R for a test image x test by the maximum distance score s * between test patchfeatures in its patch collection P(x test ) = P s,p (\u03c6 j (x test )) to each respective nearest neighbour m * in M:\nm test, * , m * = arg max m test \u2208P(x test ) arg min m\u2208M m test \u2212 m 2 s * = m test, * \u2212 m * 2 .(6)\nTo obtain s, we use scaling w on s * to account for the behaviour of neighbour patches: If memory bank features closest to anomaly candidate m test, * , m * , are themselves far from neighbouring samples and thereby an already rare nominal occurrence, we increase the anomaly score\ns = 1 \u2212 exp m test, * \u2212 m * 2 m\u2208N b (m * ) exp m test, * \u2212 m 2 \u00b7 s * ,(7)\nwith N b (m * ) the b nearest patch-features in M for test patch-feature m * . We found this re-weighting to be more robust than just the maximum patch distance. Given s, segmentations follow directly. The image-level anomaly score in Eq. 7 (first line) requires the computation of the anomaly score for each patch through the arg max-operation. A segmentation map can be computed in the same step, similar to [14], by realigning computed patch anomaly scores based on their respective spatial location. To match the original input resolution, (we may want to use intermediate network features), we upscale the result by bi-linear interpolation. Additionally, we smoothed the result with a Gaussian of kernel width \u03c3 = 4, but did not optimize this parameter.\n\n\nExperiments\n\n\nExperimental Details\n\nDatasets. To study industrial anomaly detection performance, the majority of our experiments are performed on the MVTec Anomaly Detection benchmark [5]. MVTec AD contains 15 sub-datasets with a total of 5354 images, 1725 of which are in the test set. Each sub-dataset is divided into nominal-only training data and test sets containing both nominal and anomalous samples for a specific product with various defect types as well as respective anomaly ground truth masks. As in [10,14,56], images are resized and center cropped to 256 \u00d7 256 and 224 \u00d7 224, respectively. No data augmentation is applied, as this requires prior knowledge about class-retaining augmentations. We also study industrial anomaly detection on more specialized tasks. For that, we leverage the Magnetic Tile Defects (MTD) [26] dataset as used in [42], which contains 925 defect-free and 392 anomalous magnetic tile images with varied illumination levels and image sizes. Same as in [42], 20% of defect-free images are evaluated against at test time, with the rest used for cold-start training. Finally, we also highlight potential applicability of Patch-Core to non-industrial image data, benchmarking coldstart anomaly localization on Mini Shanghai Tech Campus (mSTC) as done in e.g. [52] and [14]. mSTC is a subsampled version of the original STC dataset [32], only using every fifth training and test video frame. It contains pedestrian videos from 12 different scenes. Training videos include normal pedestrian behaviour while test videos can contain different behaviours such as fighting or cycling. For comparability of our cold-start experiments, we follow established mSTC protocols [14,52], not making use of any anomaly supervision and images resized to 256 \u00d7 256. Evaluation Metrics. Image-level anomaly detection performance is measured via the area under the receiveroperator curve (AUROC) using produced anomaly scores. In accordance with prior work we compute on MVTec the class-average AUROC [2,10,14]. To measure segmentation performance, we use both pixel-wise AUROC and the PRO metric first, both following [6]. The PRO score takes into account the overlap and recovery of connected anomaly components to better account for varying anomaly sizes in MVTec AD, see [6] for details. Table 1. Anomaly Detection Performance (AUROC) on MVTec AD [5]. PaDiM * denotes a result from [14] with problem-specific backbone selection. The total count of misclassifications was determined as the sum of false-positive and false-negative predictions given a F1-optimal threshold. We did not have individual anomaly scores for competing methods so could compute this number only for PatchCore.  \n\n\nAnomaly Detection on MVTec AD\n\nThe results for image-level anomaly detection on MVTec are shown in Table 1. For PatchCore we report on various levels of memory bank subsampling (25%, 10% and 1%). For all cases, PatchCore achieves significantly higher mean image anomaly detection performance with consistently high performance on all sub-datasets (see supplementary B for detailed comparison). Please note, that a reduction from an error of 2.1% (PaDiM) to 0.9% for Patch-Core\u221225% means a reduction of the error by 57%. In industrial inspection settings this is a relevant and significant reduction. For MVTec at optimal F1 threshold, there are only 42 out of 1725 images classified incorrectly and a third of all classes are solved perfectly. In the supplementary material B we also show that both with F1-optimal working point and at full recall, classification errors are also lower when compared to both SPADE and PaDiM. With Patch-Core, less than 50 images remain misclassified. In addition, PatchCore achieves state-of-the-art anomaly segmentation, both measured by pixelwise AUROC (  Figure 1 offer qualitative impressions of the accurate anomaly localization.\n\nIn addition, due to the effectiveness of our coreset memory subsampling, we can apply PatchCore\u22121% on images of higher resolution (e.g. 280/320 instead of 224) and en-semble systems while retaining inferences times less than PatchCore\u221210% on the default resolution. This allows us to further push image-and pixel-level anomaly detection as highlighted in Tab. 4 (detailed results in supplementary), in parts more than halving the error again (e.g. 1% \u2192 0.4% for image-level AUROC).\n\n\nInference Time\n\nThe other dimension we are interested in is inference time. We report results in Table 5 (implementation details in supp. A) comparing to reimplementations of SPADE [10] and PaDiM [14] using WideResNet50 and operations on GPU where possible. These inference times include the forward pass through the backbone. As can be seen, inference time for joint image-and pixel-level anomaly detection of PatchCore\u2212100% (without subsampling) are lower than SPADE [10] but with higher performance. With coreset subsampling, Patchcore can be made even faster, with lower inference times than even PaDiM while retaining state-of-the-art image-level anomaly detection and segmentation performance. Finally, we examine PatchCore\u2212100% with approximate nearest neighbour search (IVFPQ [27]) as an orthogonal way of reducing inference time (which can also be applied to SPADE, however which already performs notably worse than even PatchCore\u22121%). We find a performance drop, especially for image-level anomaly detection, while inference times are still higher than Patch-Core\u22121%. Though even with performance reduction, approximate nearest neighbour search on PatchCore\u2212100% still outperforms other methods. A combination of coreset and approximate nearest neighbour would further reduce inference time, allowing scaling to much larger datasets.\n\n\nAblations Study\n\nWe report on ablations for the locally aware patchfeatures and the coreset reduction method. Supplementary experiments show consistency across different backbones ( \u00a7C.2), scalability with increased image resolution ( \u00a7C.3) and a qualitative analysis of remaining errors ( \u00a7C.4).   \n\n\nLocally aware patch-features and hierarchies\n\nWe investigate the importance of locally aware patchfeatures ( \u00a73.3) by evaluating changes in anomaly detection performance over different neighbourhood sizes in Eq. 1. Results in the top half of Figure 4 show a clear optimum between locality and global context for patch-based anomaly predictions, thus motivating the neighbourhood size p = 3.\n\nMore global context can also be achieved by moving down the network hierarchy (see e.g. [10,14]), however at the cost of reduced resolution and heavier ImageNet class bias ( \u00a73.1). Indexing the first three WideResNet50-blocks with 1 -3, Fig. 4 (bottom) again highlights an optimum between highly localized predictions, more global context and Ima-geNet bias. As can be seen, features from hierarchy level 2\n\ncan already achieve state-of-the-art performance, but benefit from additional feature maps taken from subsequent hierarchy levels (2+3, which is chosen as the default setting). Figure 5 compares different memory bank M subsampling methods: Greedy coreset selection, random subsampling and learning of a set of basis proxies corresponding to the subsampling target percentage p target . For the latter, we sample proxies p i \u2208 P \u2282 R d with |P| = p target \u00b7 |M|, which are then tasked to minimize a basis reconstruction objective\n\n\nImportance of Coreset subsampling\nL rec (m i ) = m i \u2212 p k \u2208P e mi\u2212p k 2 pj \u2208P e mi\u2212pj p k 2 2 ,(8)\nto find N proxies that best describe the memory bank data M. In Figure 5 we compare the three settings and find that coreset-based subsampling performs better than the other possible choices. The performance of no subsampling is comparable to a coreset-reduced memory bank that is two orders of magnitudes smaller in size. We also find subsampled memory banks to contain much less redundancy. We recorded the percentage of memory bank samples that are used at test time for non-subsampled and coreset-subsampled memory banks. While initially only less than 30% of memory bank samples are used, coreset subsampling (to 1%) increases this factor to nearly 95%. For certain subsampling intervals (between around 50% and 10%), we even find joint performance over anomaly detection and localization to partly increase as compared to nonsubsampled PatchCore . Finally, reducing the memory bank size M by means of increased striding (see Eq. 3) shows worse performance due to the decrease in resolution context, with stride s = 2 giving an image anomaly detection AUROC of 97.6%, and stride s = 3 an AUROC of 96.8%.\n\n\nLow-shot Anomaly Detection\n\nHaving access to limited nominal data is a relevant setting for real-world inspection. Therefore in addition to reporting results on the full MVTec AD, we also study the performance with fewer training examples. We vary the amount of training samples from 1 (corresponding to 0.4% of the total nominal training data) to 50 (21%), and compare to reimplementations of SPADE [10] and PaDiM [14] using the same backbone (WideResNet50). Results are summarized in Figure 6, with detailed results available in Supp. Figure 6. PatchCore shows notably higher sample-efficiency than competitors, matching the previous state-of-the-art with a fraction of nominal training data. Note that PaDiM and SPADE where reimplemented with WideResNet50 for comparability. Table 6. Anomaly Segmentation on mSTC [32,52] and anomaly detection on MTD [26] compared to results reported in [42].  [42], we find PatchCore to outperform their approach which adapts a normalizing flows model on top of already pretrained features. Compared to image-level memory approaches in [10], we find matching localization and detection performance with only 5/1 nominal shots.\n\n\nEvaluation on other benchmarks\n\nWe benchmark PatchCore on two additional anomaly detection performance benchmarks: The ShanghaiTech Campus dataset (STC) [32] and the Magnetic Tile Defects dataset (MTD) [26]. Evaluation for STC as described in \u00a74.1 follows [52], [14] and [10]. We report unsupervised anomaly localization performance on a subsampled version of the STC video data (mSTC), with images resized to 256 \u00d7 256 [14]. As the detection context is much closer to natural image data available in ImageNet, we make use of deeper network feature maps at hierarchy levels 3 and 4, but otherwise do not perform any hyperparameter tuning for PatchCore. The results in Table 6 (top) show state-ofthe-art anomaly localization performance which suggests good transferability of PatchCore to such domains. Finally, we examine MTD, containing magnetic tile defect images of varying sizes on which spatially rigid approaches like PaDiM cannot be applied directly. Here, nominal data already exhibits high variability similar to those encountered in anomalous samples [42]. We follow the protocol proposed in [42] to measure image-level anomaly detection performance and find performance to match (and even slightly outperform) that of [42] (Table 6, bottom).\n\n\nConclusion\n\nThis paper introduced the PatchCore algorithm for coldstart anomaly detection, in which knowledge of only nominal examples has to be leveraged to detect and segment anomalous data at test-time. PatchCore strikes a balance between retaining a maximum amount of nominal context at test-time through the usage of memory banks comprising locally aware, nominal patch-level feature representations extracted from ImageNet pretrained networks, and minimal runtime through coreset subsampling. The result is a state-of-the-art cold-start image anomaly detection and localization system with low computational cost on industrial anomaly detection benchmarks. On MVTec, we achieve an image anomaly detection AUROC over 99% with highest sample efficiency in relevant small training set regimes.\n\nBroader Impact. As automated industrial anomaly detection is one of the most successful applications of Computer Vision, the improvements gained through Patch-Core can be of notable interest for practitioners in this domain. As our work focuses specifically on industrial anomaly detection, negative societal impact is limited. And while the fundamental approach can potentially we leveraged for detection systems in more controversial domains, we don't believe that our improvements are significant enough to change societal application of such systems.\n\nLimitations. While PatchCore shows high effectiveness for industrial anomaly detection without the need to specifically adapt to the problem domain at hand, applicability is generally limited by the transferability of the pretrained features leveraged. This can be addressed by merging the effectiveness of PatchCore with adaptation of the utilized features. We leave this interesting extension to future work.\n\n\nSupplementary: Towards Total Recall in Industrial Anomaly Detection\n\n\nA. Implementation Details\n\nWe implemented our models in Python 3.7 [51] and PyTorch [37]. Experiments are run on Nvidia Tesla V4 GPUs. We used torchvision ImageNet-pretrained models from torchvision and the PyTorch Image Models repository [53]. By default, following [10] and [14], PatchCore uses a WideResNet50-backbone [57] for direct comparability. Patch-level features are taken from feature map aggregation of the final outputs in blocks 2 and 3. For all nearest neighbour retrieval and distance computations, we use faiss [27].\n\n\nB. Full MVTec AD comparison\n\nThis section contains a more detailed comparison on MVTec AD. We include more models and a more finegrained performance comparison on all MVTec AD sub-datasets where available. In the main part of the paper this has been referenced in \u00a74.2. The corresponding result tables are S1, S2 and S3. We observe that PatchCore\u221225% solves six of the 15 MVTec datasets and achieves highest AUROC performance on most datasets and in average. Figure S3 show Precision-Recall and ROC curves for PatchCore variants as well as reimplemented, comparable methods SPADE [10] and PaDiM [14] using a WideResNet50 backbone. We also plot classification error both at 100% recall and under a F1-optimal threshold to give a comparable working point. As can be seen, PatchCore achieves consistently low classification errors with defined working points as well, with near-optimal Precision-Recall and ROC curves across datasets, in contrast to SPADE and PaDiM.\n\nFinally, Table S4 showcases the detailed performance on all MVTec AD subdatasets for larger imagesizes (280 \u00d7 280) and a WideResNet-101 backbone for further performance boosts using PatchCore\u22121%, which allows for efficient anomaly detection at inference time even with larger images.\n\n\nC. Additional Ablations & Details\n\n\nC.1. Detailed Low-Shot experiments\n\nThis section offers detailed numerical values to the low-shot method study provided in the main part of this work ( \u00a74.5). The results are included in Table S5 and we find consistently higher numbers for detection and anomaly localization metrics.\n\n\nC.2. Dependency on pretrained networks\n\nWe tested PatchCore with different backbones, the results are shown in S6. We find that results are mostly stable over the choice of different backbones. The choice of WideResNet50 was made to be comparable with SPADE and PaDiM.\n\n\nC.3. Influence of image resolution\n\nNext we study the influence of image size on performance. In the main paper we have used 224 \u00d7 224 to be comparable with prior work. In Figure S4 we vary the image size from 288 \u00d7 288, 360 \u00d7 360 to 448 \u00d7 448 and the neighborhood sizes (P) within 3, 5, 7, and 9. We observe slightly increased detection performance and the performance saturates for PatchCore . For anomaly segmentation we observe a consistent increase, so if good localization is of importance, this is an ingredient to validate over.\n\n\nC.4. Remaining Misclassifications\n\nThe high image-level anomaly detection performance allows us to look into all remaining misclassifications in detail. We compute the working point (threshold above which scores are considered anomalous) using the F1-optimal point. With this threshold a total of 19 false-positive and 23 false-negative errors remain, all of which are visualized in Figures S1 and S2. Each segmentation map was normalized to the threshold value, so in some cases background scores are pronounced disproportionally.\n\nLooking at Figure S1, we find that the majority of false-positive errors either stem from a) (in blue) ambiguity in labelling , i.e., image changes that could also be potentially labelled as anomalous, and b) (in orange) very high nominal variance, Figure S1. Visualization of remaining false positive classifications (under F1-optimal thresholding). Colors denote different error sources. Orange denotes high degrees of nominal variance mistaken for anomalies, blue denotes misclassifications due to anomalies in the labelling context and olive denotes variance in the background mistaken for anomalous content. resembling potential anomalies . While the former can hardly be addressed by proposed methods, the latter could be addressed by offering some form of adaptation to the nominal data. However, as PatchCore outperforms adaptive methods, such adaptation would show most promise operating alongside pretraining-based methods such as PatchCore .\n\nTo understand false-negative errors made, we include in Figure S2 the generated segmentation maps and ground-truth masks. As can be seen, a large part of anomalies are localized well, however with insufficient weight placed on the anomalous regions, and could potentially be addressed by some means of postprocessing. Other misclassifications are caused mostly by either high degrees of nominal variance that gets mistaken for anomalous context, and finegrained anomalies that could be captured when moving to higher image resolutions. The amount of completely missed anomalies is small in comparison, and in one case caused by image preprocessing cropping out the actual anomalous region.\n\n\nC.5. Local Awareness and Subsampling\n\nFor completeness we repeat the Figures 4 and 5 from the main paper with included PRO score results in S5 and S6. Figure S2. Visualization of remaining false-negative classifications (under F1-optimal thresholding). Colors denote different error sources. Orange denotes high degrees of nominal variance mistaken for anomalies, green denotes actually localized anomalies, but too little weight placed on these anomalies, pink stands for anomalies that were not recovered, purple denotes anomalies missed due to cropping-based image-processing (one anomaly in total), and gray stands for finegrained anomalies that could be recovered when operating on higher image resolutions. Table S1. Anomaly Detection Performance (AUROC) on MVTec AD [5]. PaDiM * denotes a result from [14] with a backbone specifically selected for the task of image-level anomaly detection, which we could not reproduce.  Figure S3. Precision-Recall curves (left) and ROC curves (right) for PatchCore , variants and comparable methods SPADE [10] and PaDiM [14]. Different colors in the lines correspond to difference MVTec classes.  Figure S4. Influence of image size (S) and neighbourhood size (P) on PatchCore performance. The PatchCore baseline with default values is included for reference. Figure S5. Influence of local awareness and network feature depths on anomaly detection performance. Figure S6. Performance retention for different subsamplers.\n\nFigure 2 .Figure 3 .\n23Overview of PatchCore. Nominal samples are broken down into a memory bank of neighbourhood-aware patch-level features. For reduced redundancy and inference time, this memory bank is downsampled via greedy coreset subsampling. At test time, images are classified as anomalies if at least one patch is anomalous, and pixel-level anomaly segmentation is generated by scoring each patch-feature. Comparison: coreset (top) vs. random subsampling (bottom) (red) for 2D data (iblue) sampled from (a) multimodal and (b) uniform distributions. Visually, coreset subsampling better approximates the spatial support, random subsampling misses clusters in the multi-modal case and is less uniform in (b).\n\nFigure 4 .\n4Local awareness and network feature depths vs. detection performance. PRO score results in the supplementary.\n\nFigure 5 .\n5Performance retention for different subsamplers, results for PRO score in the supplementary.\n\nTable 2 ,\n298.1 versus 97.5 for PaDiM) and PRO metric (Table 3, 93.5 versus 92.1). Sample segmentations in\n\nTable 3 .\n3Anomaly Detection Performance on MVTec AD[5] as measured in PRO [%][5,10]. AE SSIM[5] Student[6] SPADE[10] PaDiM[14] PatchCore\u221225% PatchCore\u221210% PatchCore\u22121%Method PRO \u2191 \n69.4 \n85.7 \n91.7 \n92.1 \n93.4 \n93.5 \n93.1 \nError \u2193 \n30.6 \n14.3 \n8.3 \n7.9 \n6.6 \n6.5 \n6.9 \n\nTable 4. PatchCore-1% with higher resolution/larger back-\nbones/ensembles. The coreset subsampling allows for computa-\ntionally expensive setups while still retaining fast inference. \n\nMetric\u2192 AUROC pwAUROC \nPRO \n\nDenseN-201 & RNext-101 & WRN-101 (2+3), Imagesize 320 \n\nScore \u2191 \n99.6 \n98.2 \n94.9 \nError \u2193 \n0.4 \n1.8 \n5.6 \n\nWRN-101 (2+3), Imagesize 280 \n\nScore \u2191 \n99.4 \n98.2 \n94.4 \nError \u2193 \n0.6 \n1.8 \n5.6 \n\nWRN-101 (1+2+3), Imagesize 280 \n\nScore \u2191 \n99.2 \n98.4 \n95.0 \nError \u2193 \n0.8 \n1.6 \n5.0 \n\n\n\nTable 5 .\n5Mean inference time per image on MVTec AD. Scores are (image AUROC, pixel AUROC, PRO metric).Method \nPatchCore\u2212100% \nPatchCore\u221210% \nPatchCore\u22121% \nScores \n(99.1, 98.0, 93.3) \n(99.0, 98.1, 93.5) (99.0, 98.0, 93.1) \nTime (s) \n0.6 \n0.22 \n0.17 \n\nMethod PatchCore\u2212100% + IVFPQ \nSPADE \nPaDiM \nScores \n(98.0, 97.9, 93.0) \n(85.3, 96.6, 91.5) (95.4, 97.3, 91.8) \nTime (s) \n0.2 \n0.66 \n0.19 \n\n\n\n\n\u00a7C.1. As shown, using only one fifth of nominal training data, PatchCore can still match previous state-of-the-art performance. In addition, comparing to the 16-shot experiments performed inmSTC \nCAVGA-Ru [52] SPADE [10] \nPaDiM [14] \nPatchCore\u221210 \nPixelwise AUROC [%] \n85 \n89.9 \n91.2 \n91.8 \n\nMTD \nGANomaly [2] \n1-NN [35] \nDifferNet [42] PatchCore\u221210 \nAUROC [%] \n76.6 \n80.0 \n97.7 \n97.9 \n\n \n\n\n\u2193 Method \\Dataset \u2192 Avg Bottle Cable Capsule Carpet Grid Hazeln. Leather Metal Nut Pill Screw Tile Toothb. Trans. Wood Zipper Table S2. Anomaly Segmentation Performance on MVTec [5], as measured in pixelwise AUROC. Method \\Dataset \u2192 Avg Bottle Cable Capsule Carpet Grid Hazeln. Leather Metal Nut Pill Screw Tile Toothb. Trans. Wood Zipper Table S3. Anomaly Segmentation Performance on MVTec [5], as measured in PRO [%] [5, 10]. Method \\Dataset \u2192 Avg Bottle Cable Capsule Carpet Grid Hazeln. Leather Metal Nut Pill Screw Tile Toothb. Trans. Wood Zipper Table S4. Anomaly Detection and Localization Performance (AUROC) on MVTec AD [5] with PatchCore\u22121 using larger images (280 \u00d7 280) and a WideResNet101 backbone. Metric \\Dataset \u2192 Avg Bottle Cable Capsule Carpet Grid Hazeln. Leather Metal Nut Pill Screw Tile Toothb. Trans. Wood ZipperGeoTrans [20] \n67.2 \n74.4 \n78.3 \n67.0 \n43.7 \n61.9 \n35.9 \n84.1 \n81.3 \n63.0 \n50.0 \n41.7 \n97.2 \n86.9 \n61.1 \n82.0 \nGANomaly [2] \n76.2 \n89.2 \n75.7 \n73.2 \n69.9 \n70.8 \n78.5 \n84.2 \n70.0 \n74.3 \n74.6 \n79.4 \n65.3 \n79.2 \n83.4 \n74.5 \nDSEBM [58] \n70.9 \n81.8 \n68.5 \n59.4 \n41.3 \n71.7 \n76.2 \n41.6 \n67.9 \n80.6 \n99.9 \n69.0 \n78.1 \n74.1 \n95.2 \n58.4 \nOCSVM [3] \n71.9 \n99.0 \n80.3 \n54.4 \n62.7 \n41.0 \n91.1 \n88.0 \n61.1 \n72.9 \n74.7 \n87.6 \n61.9 \n56.7 \n95.3 \n51.7 \nITAE [25] \n83.9 \n94.1 \n83.2 \n68.1 \n70.6 \n88.3 \n85.5 \n86.2 \n66.7 \n78.6 \n100 \n73.5 \n100 \n84.3 \n92.3 \n87.6 \nSPADE [10] \n85.5 \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\nCAVGA-R w [52] \n90 \n96 \n92 \n93 \n88 \n84 \n97 \n89 \n82 \n86 \n81 \n97 \n89 \n99 \n79 \n96 \nPatchSVDD [56] \n92.1 \n98.6 \n90.3 \n76.7 \n92.9 \n94.6 \n92.0 \n90.9 \n94.0 \n86.1 \n81.3 \n97.8 \n100 \n91.5 \n96.5 \n97.9 \nDifferNet [42] \n94.9 \n99.0 \n95.9 \n86.9 \n92.9 \n84.0 \n99.3 \n97.1 \n96.1 \n88.8 \n96.3 \n99.4 \n98.6 \n91.1 \n99.8 \n95.1 \nPaDiM [14] \n95.3 \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\nMahalanobisAD [40] \n95.8 \n100 \n95.0 \n95.1 \n100 \n89.7 \n99.1 \n100 \n94.7 \n88.7 \n85.2 \n99.8 \n96.9 \n95.5 \n99.6 \n97.9 \nPaDiM  *  [14] \n97.9 \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n\nPatchCore\u221225 \n99.1 \n100 \n99.5 \n98.1 \n98.7 \n98.2 \n100 \n100 \n100 \n96.6 \n98.1 \n98.7 \n100 \n100 \n99.2 \n99.4 \nPatchCore\u221210 \n99.0 \n100 \n99.4 \n97.8 \n98.7 \n97.9 \n100 \n100 \n100 \n96.0 \n97.0 \n98.9 \n99.7 \n100 \n99.0 \n99.5 \nPatchCore\u22121 \n99.0 \n100 \n99.3 \n98.0 \n98.0 \n98.6 \n100 \n100 \n99.7 \n97.0 \n96.4 \n99.4 \n100 \n99.9 \n99.2 \n99.2 \n\n\u2193 vis. expl. VAE [31] \n86 \n87 \n90 \n74 \n78 \n73 \n98 \n95 \n94 \n83 \n97 \n80 \n94 \n93 \n77 \n78 \nAE SSIM [5] \n87 \n93 \n82 \n94 \n87 \n94 \n97 \n78 \n89 \n91 \n96 \n59 \n92 \n90 \n73 \n88 \n\u03b3-VAE + grad. [15] \n88.8 \n93.1 \n88.0 \n91.7 \n72.7 \n97.9 \n98.8 \n89.7 \n91.4 \n93.5 \n97.2 \n58.1 \n98.3 \n93.1 \n80.9 \n87.1 \nCAVGA-R w [52] \n89 \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\nPatchSVDD [56] \n95.7 \n98.1 \n96.8 \n95.8 \n92.6 \n96.2 \n97.5 \n97.4 \n98.0 \n95.1 \n95.7 \n91.4 \n98.1 \n97.0 \n90.8 \n95.1 \nSPADE [10] \n96.0 \n98.4 \n97.2 \n99.0 \n97.5 \n93.7 \n99.1 \n97.6 \n98.1 \n96.5 \n98.9 \n87.4 \n97.9 \n94.1 \n88.5 \n96.5 \nPaDiM [14] \n97.5 \n98.3 \n96.7 \n98.5 \n99.1 \n97.3 \n98.2 \n99.2 \n97.2 \n95.7 \n98.5 \n94.1 \n98.8 \n98.5 \n94.9 \n98.5 \n\nPatchCore\u221225 \n98.1 \n98.6 \n98.4 \n98.8 \n99.0 \n98.7 \n98.7 \n99.3 \n98.4 \n97.4 \n99.4 \n95.6 \n98.7 \n96.3 \n95.0 \n98.8 \nPatchCore\u221210 \n98.1 \n98.6 \n98.5 \n98.9 \n99.1 \n98.7 \n98.7 \n99.3 \n98.4 \n97.6 \n99.4 \n95.9 \n98.7 \n96.4 \n95.1 \n98.9 \nPatchCore\u22121 \n98.0 \n98.5 \n98.2 \n98.8 \n98.9 \n98.6 \n98.6 \n99.3 \n98.4 \n97.1 \n99.2 \n96.1 \n98.5 \n94.9 \n95.1 \n98.8 \n\n\u2193 AE SSIM [5] \n69.4 \n83.4 \n47.8 \n86.0 \n64.7 \n84.9 \n91.6 \n56.1 \n60.3 \n83.0 \n88.7 \n17.5 \n78.4 \n72.5 \n60.5 \n66.5 \nStudent [6] \n85.7 \n91.8 \n86.5 \n91.6 \n69.5 \n81.9 \n93.7 \n81.9 \n89.5 \n93.5 \n92.8 \n91.2 \n86.3 \n70.1 \n72.5 \n93.3 \nSPADE [10] \n91.7 \n95.5 \n90.9 \n93.7 \n94.7 \n86.7 \n95.4 \n97.2 \n94.4 \n94.6 \n96.0 \n75.6 \n93.5 \n87.4 \n87.4 \n92.6 \nPaDiM [14] \n92.1 \n94.8 \n88.8 \n93.5 \n96.2 \n94.6 \n92.6 \n97.8 \n85.6 \n92.7 \n94.4 \n86.0 \n93.1 \n84.5 \n91.1 \n95.9 \n\nPatchCore\u221225 \n93.4 \n96.2 \n92.5 \n95.5 \n96.6 \n96.0 \n93.8 \n98.9 \n91.4 \n93.2 \n97.9 \n87.3 \n91.5 \n83.7 \n89.4 \n97.1 \nPatchCore\u221210 \n93.5 \n96.1 \n92.6 \n95.5 \n96.6 \n95.9 \n93.9 \n98.9 \n91.3 \n94.1 \n97.9 \n87.4 \n91.4 \n83.5 \n89.6 \n97.1 \nPatchCore\u22121 \n93.1 \n95.9 \n91.6 \n95.5 \n96.5 \n96.1 \n93.8 \n98.9 \n91.2 \n92.9 \n97.1 \n88.3 \n90.2 \n81.2 \n89.5 \n97.0 \n\n\u2193 PatchCore\u22121, Hierarchies (2, 3), Imagesize 280 \n\nAUROC \n99.4 \n100 \n99.6 \n98.2 \n98.4 \n99.8 \n100 \n100 \n100 \n97.2 \n98.9 \n98.9 \n100 \n100 \n99.5 \n99.9 \npwAUROC \n98.2 \n98.6 \n98.4 \n99.1 \n98.7 \n98.7 \n98.8 \n99.3 \n98.8 \n97.8 \n99.3 \n96.1 \n98.8 \n96.4 \n95.1 \n98.9 \nPRO \n94.4 \n96.6 \n93.8 \n96.0 \n97.4 \n96.8 \n91.2 \n99.1 \n94.8 \n94.0 \n97.5 \n89.5 \n95.5 \n84.8 \n91.7 \n97.8 \n\nPatchCore\u22121, Hierarchies (1, 2, 3), Imagesize 280 \n\nAUROC \n99.2 \n100 \n99.7 \n98.1 \n98.2 \n98.3 \n100 \n100 \n100 \n97.1 \n99.0 \n98.9 \n98.9 \n99.7 \n99.9 \n99.7 \npwAUROC \n98.4 \n98.6 \n98.7 \n99.1 \n98.7 \n98.8 \n98.8 \n99.3 \n99.0 \n98.6 \n99.5 \n96.3 \n98.9 \n97.1 \n95.2 \n99.0 \nPRO \n95.0 \n96.6 \n94.6 \n96.3 \n97.5 \n97.0 \n91.5 \n99.1 \n95.4 \n96.0 \n98.1 \n90.0 \n95.8 \n85.9 \n92.0 \n98.0 \n\n\n\nTable S5 .\nS5Low-Shot Anomaly Detection Performance on MVTec [5], as measured on AUROC. IMAGE-LEVEL AUROC SPADE 71.6 \u00b1 0.7 73.4 \u00b1 1.3 75.2 \u00b1 1.5 77.5 \u00b1 1.1 78.9 \u00b1 0.9 79.6 \u00b1 0.8 81.1 \u00b1 0.4 PaDiM 76.1 \u00b1 0.4 78.9 \u00b1 0.6 81.0 \u00b1 0.2 83.2 \u00b1 0.7 85.5 \u00b1 0.6 86.5 \u00b1 0.3 90.1 \u00b1 0.Table S6. Anomaly Detection Performance on MVTec [5], as measured on AUROC. Backbone % of M Img. AUROC Pw. AUROC PRO\u2193 Method \\Shots \u2192 \n1 \n2 \n5 \n10 \n16 \n20 \n50 \n\nRetained % \n0.4 \n0.8 \n2.1 \n4.1 \n6.6 \n8.3 \n21 \n\n3 \nDifferNet \n-\n-\n-\n-\n87.3 \n-\n-\nPatchCore-10 \n83.4 \u00b1 0.6 86.4 \u00b1 0.9 90.8 \u00b1 0.8 93.6 \u00b1 0.6 95.4 \u00b1 0.7 95.8 \u00b1 0.6 97.5 \u00b1 0.3 \nPatchCore-25 \n84.1 \u00b1 0.7 87.2 \u00b1 1.0 91.0 \u00b1 0.9 93.8 \u00b1 0.5 95.5 \u00b1 0.6 95.9 \u00b1 0.6 97.7 \u00b1 0.4 \n\nPIXEL-LEVEL AUROC \n\nSPADE \n91.9 \u00b1 0.3 93.1 \u00b1 0.2 94.5 \u00b1 0.1 95.4 \u00b1 0.1 95.7 \u00b1 0.2 95.7 \u00b1 0.2 96.2 \u00b1 0.0 \nPaDiM \n88.2 \u00b1 0.3 90.5 \u00b1 0.2 92.5 \u00b1 0.1 93.9 \u00b1 0.1 94.8 \u00b1 0.1 95.1 \u00b1 0.1 96.3 \u00b1 0.0 \nPatchCore-10 \n92.0 \u00b1 0.2 93.1 \u00b1 0.2 94.8 \u00b1 0.1 96.2 \u00b1 0.1 96.8 \u00b1 0.3 96.9 \u00b1 0.3 97.8 \u00b1 0.0 \nPatchCore-25 \n92.4 \u00b1 0.3 93.3 \u00b1 0.2 94.8 \u00b1 0.1 96.1 \u00b1 0.1 96.8 \u00b1 0.3 96.9 \u00b1 0.3 97.7 \u00b1 0.0 \n\nPRO METRIC \n\nSPADE \n83.5 \u00b1 0.4 85.8 \u00b1 0.1 88.3 \u00b1 0.2 89.6 \u00b1 0.1 90.1 \u00b1 0.2 90.1 \u00b1 0.3 90.8 \u00b1 0.1 \nPaDiM \n72.4 \u00b1 1.2 77.8 \u00b1 0.7 82.7 \u00b1 0.2 85.9 \u00b1 0.2 87.5 \u00b1 0.2 88.2 \u00b1 0.2 90.4 \u00b1 0.1 \nPatchCore-10 \n82.4 \u00b1 0.3 85.1 \u00b1 0.3 88.7 \u00b1 0.2 90.9 \u00b1 0.1 91.8 \u00b1 0.2 92.0 \u00b1 0.2 93.0 \u00b1 0.1 \nPatchCore-25 \n83.7 \u00b1 0.5 86.0 \u00b1 0.3 88.8 \u00b1 0.2 90.9 \u00b1 0.1 91.7 \u00b1 0.1 91.9 \u00b1 0.2 92.8 \u00b1 0.0 \n\n\u2193 ResNet50 [23] \n10 \n99.0 \n98.1 \n93.3 \n1 \n98.7 \n97.8 \n93.3 \nWideResNet50 [57] \n10 \n98.9 \n98.1 \n93.5 \n1 \n99.0 \n98.0 \n93.1 \nResNet101 [23] \n10 \n98.6 \n97.9 \n92.5 \n1 \n98.7 \n97.8 \n92.2 \nWideResNet101 [57] \n10 \n99.1 \n98.2 \n93.4 \n1 \n99.0 \n98.1 \n93.0 \nResNeXt101 [55] \n10 \n98.9 \n98.0 \n92.8 \n1 \n98.7 \n97.8 \n92.6 \n\n\nAcknowledgementsWe thank Yasser Jadidi and Alex Smola for setup support of our compute infrastructure. K.R. thanks the International Max Planck Research School for Intelligent Systems (IMPRS-IS) and the European Laboratory for Learning and Intelligent Systems (ELLIS) PhD program for support.\nGeometric approximation via coresets. Pankaj Agarwal, Sariel Har, Peled Kasturi, R Varadarajan, Combinatorial and Computational Geometry. 524Pankaj Agarwal, Sariel Har, Peled Kasturi, and R Varadara- jan. Geometric approximation via coresets. Combinatorial and Computational Geometry, 52, 11 2004. 2, 4\n\nGanomaly: Semi-supervised anomaly detection via adversarial training. Samet Akcay, Amir Atapour-Abarghouei, Toby P Breckon, Asian Conference on Computer Vision. Springer84Samet Akcay, Amir Atapour-Abarghouei, and Toby P Breckon. Ganomaly: Semi-supervised anomaly detection via adversarial training. In Asian Conference on Computer Vision, pages 622-637. Springer, 2018. 1, 2, 5, 8, 4\n\nTransfer representation-learning for anomaly detection. Jerone Andrews, Thomas Tanay, Edward Morton, Lewis Griffin, . 07 2016. 4Jerone Andrews, Thomas Tanay, Edward Morton, and Lewis Griffin. Transfer representation-learning for anomaly detec- tion. 07 2016. 4\n\nDeep nearest neighbor anomaly detection. CoRR, abs. Liron Bergman, Niv Cohen, Yedid Hoshen, 23Liron Bergman, Niv Cohen, and Yedid Hoshen. Deep nearest neighbor anomaly detection. CoRR, abs/2002.10445, 2020. 1, 2, 3\n\nMvtec ad -a comprehensive real-world dataset for unsupervised anomaly detection. Paul Bergmann, Michael Fauser, David Sattlegger, Carsten Steger, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)74Paul Bergmann, Michael Fauser, David Sattlegger, and Carsten Steger. Mvtec ad -a comprehensive real-world dataset for unsupervised anomaly detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pat- tern Recognition (CVPR), June 2019. 1, 2, 5, 6, 7, 4\n\nUninformed students: Student-teacher anomaly detection with discriminative latent embeddings. Paul Bergmann, Michael Fauser, David Sattlegger, Carsten Steger, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)74Paul Bergmann, Michael Fauser, David Sattlegger, and Carsten Steger. Uninformed students: Student-teacher anomaly detection with discriminative latent embeddings. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), June 2020. 2, 5, 7, 4\n\nImproving unsupervised defect segmentation by applying structural similarity to autoencoders. Paul Bergmann, Sindy L\u00f6we, Michael Fauser, David Sattlegger, Carsten Steger, Proceedings of the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications. the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and ApplicationsPaul Bergmann, Sindy L\u00f6we, Michael Fauser, David Sattleg- ger, and Carsten Steger. Improving unsupervised defect seg- mentation by applying structural similarity to autoencoders. Proceedings of the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, 2019. 2\n\nApproximating CNNs with bag-of-local-features models works surprisingly well on imagenet. Wieland Brendel, Matthias Bethge, International Conference on Learning Representations. Wieland Brendel and Matthias Bethge. Approximating CNNs with bag-of-local-features models works surprisingly well on imagenet. In International Conference on Learning Representations, 2019. 2\n\nCoresets, sparse greedy approximation, and the frank-wolfe algorithm. Kenneth L Clarkson, ACM Trans. Algorithms. 64Kenneth L. Clarkson. Coresets, sparse greedy approxima- tion, and the frank-wolfe algorithm. ACM Trans. Algorithms, 6(4), Sept. 2010. 2\n\nSub-image anomaly detection with deep pyramid correspondences. CoRR, abs. Niv Cohen, Yedid Hoshen, 7Niv Cohen and Yedid Hoshen. Sub-image anomaly detection with deep pyramid correspondences. CoRR, abs/2005.02357, 2020. 1, 2, 3, 4, 5, 6, 7, 8\n\nAn elementary proof of a theorem of johnson and lindenstrauss. Random Structures & Algorithms. Sanjoy Dasgupta, Anupam Gupta, 22Sanjoy Dasgupta and Anupam Gupta. An elementary proof of a theorem of johnson and lindenstrauss. Random Struc- tures & Algorithms, 22(1):60-65, 2003. 4\n\nUnsupervised anomaly detection for x-ray images. Diana Davletshina, Valentyn Melnychuk, Viet Tran, Hitansh Singla, Max Berrendorf, Evgeniy Faerman, Michael Fromm, Matthias Schubert, 2020Diana Davletshina, Valentyn Melnychuk, Viet Tran, Hitansh Singla, Max Berrendorf, Evgeniy Faerman, Michael Fromm, and Matthias Schubert. Unsupervised anomaly detection for x-ray images, 2020. 1\n\nImage anomaly detection with generative adversarial networks. Lucas Deecke, Robert Vandermeulen, Lukas Ruff, Stephan Mandt, Marius Kloft, Machine Learning and Knowledge Discovery in Databases. Michele Berlingerio, Francesco Bonchi, Thomas G\u00e4rtner, Neil Hurley, and Georgiana IfrimChamSpringer International PublishingLucas Deecke, Robert Vandermeulen, Lukas Ruff, Stephan Mandt, and Marius Kloft. Image anomaly detection with generative adversarial networks. In Michele Berlingerio, Francesco Bonchi, Thomas G\u00e4rtner, Neil Hurley, and Geor- giana Ifrim, editors, Machine Learning and Knowledge Dis- covery in Databases, pages 3-17, Cham, 2019. Springer In- ternational Publishing. 2\n\nPadim: A patch distribution modeling framework for anomaly detection and localization. Thomas Defard, Aleksandr Setkov, Angelique Loesch, Romaric Audigier, Pattern Recognition. ICPR International Workshops and Challenges. Alberto Del Bimbo, Rita Cucchiara, Stan Sclaroff, Giovanni Maria Farinella, Tao Mei, Marco Bertini, Hugo Jair Escalante, and Roberto VezzaniChamSpringer International Publishing2Thomas Defard, Aleksandr Setkov, Angelique Loesch, and Romaric Audigier. Padim: A patch distribution model- ing framework for anomaly detection and localization. In Alberto Del Bimbo, Rita Cucchiara, Stan Sclaroff, Gio- vanni Maria Farinella, Tao Mei, Marco Bertini, Hugo Jair Escalante, and Roberto Vezzani, editors, Pattern Recogni- tion. ICPR International Workshops and Challenges, pages 475-489, Cham, 2021. Springer International Publishing. 2, 3, 5, 6, 7, 8, 1, 4\n\nIterative energy-based projection on a normal data manifold for anomaly localization. David Dehaene, Oriel Frigo, S\u00e9bastien Combrexelle, Pierre Eline, International Conference on Learning Representations. 64David Dehaene, Oriel Frigo, S\u00e9bastien Combrexelle, and Pierre Eline. Iterative energy-based projection on a nor- mal data manifold for anomaly localization. In International Conference on Learning Representations, 2020. 6, 4\n\nImagenet: A large-scale hierarchical image database. J Deng, W Dong, R Socher, L Li, Kai Li, Li Fei-Fei, 2009 IEEE Conference on Computer Vision and Pattern Recognition. J. Deng, W. Dong, R. Socher, L. Li, Kai Li, and Li Fei- Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 248-255, 2009. 2\n\nDensity estimation using real NVP. Laurent Dinh, Jascha Sohl-Dickstein, Samy Bengio, 5th International Conference on Learning Representations. Toulon, FranceConference Track Proceedings. OpenReview.netLaurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real NVP. In 5th Interna- tional Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Pro- ceedings. OpenReview.net, 2017. 2\n\nA Geometric Framework for Unsupervised Anomaly Detection. Eleazar Eskin, Andrew Arnold, Michael Prerau, Leonid Portnoy, Sal Stolfo, Springer USBoston, MAEleazar Eskin, Andrew Arnold, Michael Prerau, Leonid Portnoy, and Sal Stolfo. A Geometric Framework for Un- supervised Anomaly Detection, pages 77-101. Springer US, Boston, MA, 2002. 2\n\nScalable training of mixture models via coresets. Dan Feldman, Matthew Faulkner, Andreas Krause, Advances in Neural Information Processing Systems. J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Q. WeinbergerCurran Associates, Inc24Dan Feldman, Matthew Faulkner, and Andreas Krause. Scal- able training of mixture models via coresets. In J. Shawe- Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Q. Wein- berger, editors, Advances in Neural Information Processing Systems, volume 24, pages 2142-2150. Curran Associates, Inc., 2011. 2\n\nDeep anomaly detection using geometric transformations. Izhak Golan, Ran El-Yaniv, Advances in Neural Information Processing Systems. S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. GarnettCurran Associates, Inc314Izhak Golan and Ran El-Yaniv. Deep anomaly detection us- ing geometric transformations. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31, pages 9758-9769. Curran Associates, Inc., 2018. 2, 4\n\nMoussa Reda Mansour, Svetha Venkatesh, and Anton van den Hengel. Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection. Dong Gong, Lingqiao Liu, Vuong Le, Budhaditya Saha, Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). the IEEE/CVF International Conference on Computer Vision (ICCV)Dong Gong, Lingqiao Liu, Vuong Le, Budhaditya Saha, Moussa Reda Mansour, Svetha Venkatesh, and Anton van den Hengel. Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision (ICCV), October 2019. 2\n\nSmaller coresets for kmedian and k-means clustering. Sariel Har, -Peled , Akash Kushal, Discrete and Computational Geometry. 37Sariel Har-Peled and Akash Kushal. Smaller coresets for k- median and k-means clustering. Discrete and Computational Geometry, 37:3-19, 12 2007. 2\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)36Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016. 3, 6\n\nDistilling the knowledge in a neural network. Geoffrey Hinton, Oriol Vinyals, Jeffrey Dean, NIPS Deep Learning and Representation Learning Workshop. Geoffrey Hinton, Oriol Vinyals, and Jeffrey Dean. Distilling the knowledge in a neural network. In NIPS Deep Learning and Representation Learning Workshop, 2015. 2\n\nInverse-transform autoencoder for anomaly detection. CoRR, abs. Chaoqing Huang, Jinkun Cao, Fei Ye, Maosen Li, Ya Zhang, Cewu Lu, 24Chaoqing Huang, Jinkun Cao, Fei Ye, Maosen Li, Ya Zhang, and Cewu Lu. Inverse-transform autoencoder for anomaly detection. CoRR, abs/1911.10676, 2019. 2, 4\n\nSurface defect saliency of magnetic tile. The Visual Computer. Yibin Huang, C Qiu, K Yuan, 36Yibin Huang, C. Qiu, and K. Yuan. Surface defect saliency of magnetic tile. The Visual Computer, 36:85-96, 2018. 2, 5, 8\n\nBillionscale similarity search with gpus. Jeff Johnson, Matthijs Douze, Herv\u00e9 J\u00e9gou, IEEE Transactions on Big Data. 61Jeff Johnson, Matthijs Douze, and Herv\u00e9 J\u00e9gou. Billion- scale similarity search with gpus. IEEE Transactions on Big Data, pages 1-1, 2019. 6, 1\n\nXrai: Better attributions through regions. Andrei Kapishnikov, Tolga Bolukbasi, Fernanda Viegas, Michael Terry, Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). the IEEE/CVF International Conference on Computer Vision (ICCV)Andrei Kapishnikov, Tolga Bolukbasi, Fernanda Viegas, and Michael Terry. Xrai: Better attributions through regions. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), October 2019. 2\n\nRapp: Novelty detection with reconstruction along projection pathway. Ki Hyun Kim, Sangwoo Shim, Yongsub Lim, Jongseob Jeon, Jeongwoo Choi, Byungchan Kim, Andre S Yoon, International Conference on Learning Representations. Ki Hyun Kim, Sangwoo Shim, Yongsub Lim, Jongseob Jeon, Jeongwoo Choi, Byungchan Kim, and Andre S. Yoon. Rapp: Novelty detection with reconstruction along projection path- way. In International Conference on Learning Representa- tions, 2020. 2\n\nGlow: Generative flow with invertible 1x1 convolutions. P Durk, Prafulla Kingma, Dhariwal, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and RDurk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions. In S. Bengio, H. Wal- lach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R.\n\nGarnett, Advances in Neural Information Processing Systems. Curran Associates, Inc31Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018. 2\n\nTowards visually explaining variational autoencoders. Wenqian Liu, Runze Li, Meng Zheng, Srikrishna Karanam, Ziyan Wu, Bir Bhanu, Richard J Radke, Octavia Camps, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)Wenqian Liu, Runze Li, Meng Zheng, Srikrishna Karanam, Ziyan Wu, Bir Bhanu, Richard J. Radke, and Octavia Camps. Towards visually explaining variational autoencoders. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition (CVPR), June 2020. 4\n\nFuture frame prediction for anomaly detection -a new baseline. W Liu, D W Lian, S Luo, Gao, 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 5W. Liu, D. Lian W. Luo, and S. Gao. Future frame pre- diction for anomaly detection -a new baseline. In 2018 IEEE Conference on Computer Vision and Pattern Recog- nition (CVPR), 2018. 5, 8\n\nOn the generalized distance in statistics. Prasanta Chandra Mahalanobis, Proceedings of the National Institute of Sciences (Calcutta). the National Institute of Sciences (Calcutta)2Prasanta Chandra Mahalanobis. On the generalized distance in statistics. Proceedings of the National Institute of Sciences (Calcutta), 2:49-55, 1936. 2\n\nData-independent neural pruning via coresets. Ben Mussay, Margarita Osadchy, Vladimir Braverman, Samson Zhou, Dan Feldman, International Conference on Learning Representations. 2020Ben Mussay, Margarita Osadchy, Vladimir Braverman, Sam- son Zhou, and Dan Feldman. Data-independent neural prun- ing via coresets. In International Conference on Learning Representations, 2020. 2\n\nAre pre-trained cnns good feature extractors for anomaly detection in surveillance videos? CoRR. S Tiago, Rodrigo Nazar\u00e9, Moacir A Fernandes De Mello, Ponti, abs/1811.08495Tiago S. Nazar\u00e9, Rodrigo Fernandes de Mello, and Moacir A. Ponti. Are pre-trained cnns good feature extrac- tors for anomaly detection in surveillance videos? CoRR, abs/1811.08495, 2018. 8\n\nAnomaly detection with multiple-hypotheses predictions. Zhongyu Duc Tam Nguyen, Michael Lou, Thomas Klar, Brox, PMLR, 09-15Proceedings of the 36th International Conference on Machine Learning. Kamalika Chaudhuri and Ruslan Salakhutdinovthe 36th International Conference on Machine Learning97Duc Tam Nguyen, Zhongyu Lou, Michael Klar, and Thomas Brox. Anomaly detection with multiple-hypotheses predic- tions. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 4800-4809. PMLR, 09-15 Jun 2019. 1\n\nPytorch: An imperative style, high-performance deep learning library. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K\u00f6pf, Edward Yang, Zach Devito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, Soumith Chintala, Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K\u00f6pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An im- perative style, high-performance deep learning library, 2019. 1\n\nOcgan: One-class novelty detection using gans with constrained latent representations. Pramuditha Perera, Ramesh Nallapati, Bing Xiang, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)Pramuditha Perera, Ramesh Nallapati, and Bing Xiang. Oc- gan: One-class novelty detection using gans with constrained latent representations. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2019. 2\n\nGenerative probabilistic novelty detection with adversarial autoencoders. Stanislav Pidhorskyi, Ranya Almohsen, Donald A Adjeroh, Gianfranco Doretto, Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS'18. the 32nd International Conference on Neural Information Processing Systems, NIPS'18Red Hook, NY, USACurran Associates Inc1Stanislav Pidhorskyi, Ranya Almohsen, Donald A. Adjeroh, and Gianfranco Doretto. Generative probabilistic novelty de- tection with adversarial autoencoders. In Proceedings of the 32nd International Conference on Neural Information Pro- cessing Systems, NIPS'18, page 6823-6834, Red Hook, NY, USA, 2018. Curran Associates Inc. 1, 2\n\nModeling the distribution of normal data in pre-trained deep features for anomaly detection. Oliver Rippel, Patrick Mertens, Dorit Merhof, 2020 25th International Conference on Pattern Recognition (ICPR). 64Oliver Rippel, Patrick Mertens, and Dorit Merhof. Model- ing the distribution of normal data in pre-trained deep fea- tures for anomaly detection. In 2020 25th International Con- ference on Pattern Recognition (ICPR), pages 6726-6733, 2021. 2, 6, 4\n\nRevisiting training strategies and generalization performance in deep metric learning. Karsten Roth, Timo Milbich, Samarth Sinha, Prateek Gupta, Bjorn Ommer, Joseph Paul Cohen, PMLRProceedings of the 37th International Conference on Machine Learning. Hal Daum\u00e9 III and Aarti Singhthe 37th International Conference on Machine Learning119Karsten Roth, Timo Milbich, Samarth Sinha, Prateek Gupta, Bjorn Ommer, and Joseph Paul Cohen. Revisiting train- ing strategies and generalization performance in deep metric learning. In Hal Daum\u00e9 III and Aarti Singh, editors, Pro- ceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 8242-8252. PMLR, 13-18 Jul 2020. 3\n\nSame same but differnet: Semi-supervised defect detection with normalizing flows. Marco Rudolph, Bastian Wandt, Bodo Rosenhahn, Winter Conference on Applications of Computer Vision (WACV). 84Marco Rudolph, Bastian Wandt, and Bodo Rosenhahn. Same same but differnet: Semi-supervised defect detection with normalizing flows. In Winter Conference on Applications of Computer Vision (WACV), Jan. 2021. 1, 2, 5, 6, 8, 4\n\nAdversarially learned one-class classifier for novelty detection. Mohammad Sabokrou, Mohammad Khalooei, Mahmood Fathy, Ehsan Adeli, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Mohammad Sabokrou, Mohammad Khalooei, Mahmood Fathy, and Ehsan Adeli. Adversarially learned one-class classifier for novelty detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2018. 1, 2\n\nAnomaly detection using autoencoders with nonlinear dimensionality reduction. Mayu Sakurada, Takehisa Yairi, Proceedings of the MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, MLSDA'14. the MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, MLSDA'14New York, NY, USA1Association for Computing MachineryMayu Sakurada and Takehisa Yairi. Anomaly detection us- ing autoencoders with nonlinear dimensionality reduction. In Proceedings of the MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, MLSDA'14, page 4-11, New York, NY, USA, 2014. Association for Computing Ma- chinery. 1, 2\n\n. Mohammadreza Salehi, Niousha Sadjadi, Soroosh Baselizadeh, Mohammad Hossein Rohban, and Hamid RMohammadreza Salehi, Niousha Sadjadi, Soroosh Baselizadeh, Mohammad Hossein Rohban, and Hamid R.\n\nMultiresolution knowledge distillation for anomaly detection. Rabiee, Rabiee. Multiresolution knowledge distillation for anomaly detection, 2020. 2\n\nSupport vector method for novelty detection. Bernhard Sch\u00f6lkopf, Robert C Williamson, Alex J Smola, John Shawe-Taylor, John C Platt, Advances in Neural Information Processing Systems. Cambridge, MA, USAMIT Press12Max-Planck-GesellschaftBernhard Sch\u00f6lkopf, Robert C. Williamson, Alex J. Smola, John Shawe-Taylor, and John C. Platt. Support vector method for novelty detection. In Advances in Neural Infor- mation Processing Systems 12, pages 582-588, Cambridge, MA, USA, June 2000. Max-Planck-Gesellschaft, MIT Press. 2\n\nGrad-cam: Visual explanations from deep networks via gradient-based localization. R R Selvaraju, M Cogswell, A Das, R Vedantam, D Parikh, D Batra, 2017 IEEE International Conference on Computer Vision (ICCV). R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In 2017 IEEE International Conference on Computer Vision (ICCV), pages 618-626, 2017. 2\n\nActive learning for convolutional neural networks: A core-set approach. Ozan Sener, Silvio Savarese, International Conference on Learning Representations. 24Ozan Sener and Silvio Savarese. Active learning for convolu- tional neural networks: A core-set approach. In International Conference on Learning Representations, 2018. 2, 4\n\nSmall-GAN: Speeding up GAN training using core-sets. Samarth Sinha, Han Zhang, Anirudh Goyal, Yoshua Bengio, Hugo Larochelle, Augustus Odena, PMLRProceedings of the 37th International Conference on Machine Learning. Hal Daum\u00e9 III and Aarti Singhthe 37th International Conference on Machine Learning1194Samarth Sinha, Han Zhang, Anirudh Goyal, Yoshua Ben- gio, Hugo Larochelle, and Augustus Odena. Small-GAN: Speeding up GAN training using core-sets. In Hal Daum\u00e9 III and Aarti Singh, editors, Proceedings of the 37th Interna- tional Conference on Machine Learning, volume 119 of Pro- ceedings of Machine Learning Research, pages 9005-9015. PMLR, 13-18 Jul 2020. 3, 4\n\nSupport vector data description. M J David, Tax, P W Robert, Duin, Machine Learning. 54David M. J. Tax and Robert P. W. Duin. Support vector data description. Machine Learning, 54:45-66, 2004. 2\n\nPython 3 Reference Manual. CreateSpace. Guido Van Rossum, Fred L Drake, Scotts Valley, CAGuido Van Rossum and Fred L. Drake. Python 3 Reference Manual. CreateSpace, Scotts Valley, CA, 2009. 1\n\nAttention guided anomaly localization in images. Shashanka Venkataramanan, Kuan-Chuan, Rajat Vikram Peng, Abhijit Singh, Mahalanobis, Computer Vision -ECCV 2020. Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael FrahmChamSpringer International Publishing24Shashanka Venkataramanan, Kuan-Chuan Peng, Ra- jat Vikram Singh, and Abhijit Mahalanobis. Attention guided anomaly localization in images. In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm, editors, Computer Vision -ECCV 2020, pages 485-503, Cham, 2020. Springer International Publishing. 2, 5, 6, 8, 4\n\nPytorch image models. Ross Wightman, Ross Wightman. Pytorch image models. https : / / github . com / rwightman / pytorch -image - models, 2019. 1\n\nInteger and Combinatorial Optimization. A Laurence, George L Wolsey, Nemhauser, Wiley Series in Discrete Mathematics and Optimization. WileyLaurence A. Wolsey and George L. Nemhauser. Integer and Combinatorial Optimization. Wiley Series in Discrete Math- ematics and Optimization. Wiley, 2014. 4\n\nAggregated residual transformations for deep neural networks. Saining Xie, Ross Girshick, Piotr Dollar, Zhuowen Tu, Kaiming He, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Saining Xie, Ross Girshick, Piotr Dollar, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017. 6\n\nPatch svdd: Patch-level svdd for anomaly detection and segmentation. Jihun Yi, Sungroh Yoon, Proceedings of the Asian Conference on Computer Vision (ACCV). the Asian Conference on Computer Vision (ACCV)64Jihun Yi and Sungroh Yoon. Patch svdd: Patch-level svdd for anomaly detection and segmentation. In Proceedings of the Asian Conference on Computer Vision (ACCV), November 2020. 1, 2, 5, 6, 4\n\nWide residual networks. Sergey Zagoruyko, Nikos Komodakis, Proceedings of the British Machine Vision Conference (BMVC). Edwin R. Hancock Richard C. Wilson and William A. P. Smiththe British Machine Vision Conference (BMVC)BMVA Press126Sergey Zagoruyko and Nikos Komodakis. Wide residual net- works. In Edwin R. Hancock Richard C. Wilson and William A. P. Smith, editors, Proceedings of the British Machine Vi- sion Conference (BMVC), pages 87.1-87.12. BMVA Press, September 2016. 3, 1, 6\n\nDeep structured energy based models for anomaly detection. Shuangfei Zhai, Yu Cheng, Weining Lu, Zhongfei Zhang, PMLR. 4Proceedings of The 33rd International Conference on Machine Learning. Maria Florina Balcan and Kilian Q. WeinbergerThe 33rd International Conference on Machine LearningNew York, New York, USA48Shuangfei Zhai, Yu Cheng, Weining Lu, and Zhongfei Zhang. Deep structured energy based models for anomaly detection. In Maria Florina Balcan and Kilian Q. Weinberger, editors, Proceedings of The 33rd International Conference on Machine Learning, volume 48 of Proceedings of Machine Learning Research, pages 1100-1109, New York, New York, USA, 20-22 Jun 2016. PMLR. 4\n\nImage quality assessment: from error visibility to structural similarity. A C Zhou Wang, H R Bovik, E P Sheikh, Simoncelli, IEEE Transactions on Image Processing. 134Zhou Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simon- celli. Image quality assessment: from error visibility to struc- tural similarity. IEEE Transactions on Image Processing, 13(4):600-612, 2004. 2\n\nDeep autoencoding gaussian mixture model for unsupervised anomaly detection. Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, Haifeng Chen, International Conference on Learning Representations. Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cris- tian Lumezanu, Daeki Cho, and Haifeng Chen. Deep autoen- coding gaussian mixture model for unsupervised anomaly detection. In International Conference on Learning Repre- sentations, 2018. 2\n", "annotations": {"author": "[{\"end\":94,\"start\":56},{\"end\":121,\"start\":95},{\"end\":150,\"start\":122},{\"end\":183,\"start\":151},{\"end\":209,\"start\":184},{\"end\":236,\"start\":210}]", "publisher": null, "author_last_name": "[{\"end\":68,\"start\":64},{\"end\":107,\"start\":101},{\"end\":136,\"start\":130},{\"end\":169,\"start\":160},{\"end\":195,\"start\":191},{\"end\":222,\"start\":216}]", "author_first_name": "[{\"end\":63,\"start\":56},{\"end\":100,\"start\":95},{\"end\":129,\"start\":122},{\"end\":159,\"start\":151},{\"end\":190,\"start\":184},{\"end\":215,\"start\":210}]", "author_affiliation": "[{\"end\":93,\"start\":70},{\"end\":120,\"start\":109},{\"end\":149,\"start\":138},{\"end\":182,\"start\":171},{\"end\":208,\"start\":197},{\"end\":235,\"start\":224}]", "title": "[{\"end\":53,\"start\":1},{\"end\":289,\"start\":237}]", "venue": null, "abstract": "[{\"end\":1545,\"start\":291}]", "bib_ref": "[{\"end\":2395,\"start\":2387},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2799,\"start\":2796},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3059,\"start\":3055},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":3062,\"start\":3059},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":3065,\"start\":3062},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3075,\"start\":3072},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3078,\"start\":3075},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3081,\"start\":3078},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":3128,\"start\":3124},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":3131,\"start\":3128},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3146,\"start\":3143},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3149,\"start\":3146},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4376,\"start\":4373},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4575,\"start\":4571},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":4578,\"start\":4575},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5133,\"start\":5130},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5438,\"start\":5435},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5498,\"start\":5494},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":6481,\"start\":6477},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":6599,\"start\":6595},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6647,\"start\":6644},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":6650,\"start\":6647},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":6653,\"start\":6650},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6712,\"start\":6708},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":6785,\"start\":6781},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6817,\"start\":6813},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":6842,\"start\":6838},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6869,\"start\":6866},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":6872,\"start\":6869},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":6914,\"start\":6910},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7035,\"start\":7031},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7098,\"start\":7094},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7128,\"start\":7124},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":7278,\"start\":7274},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7318,\"start\":7314},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7389,\"start\":7385},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":7402,\"start\":7398},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":7405,\"start\":7402},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":7596,\"start\":7592},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7609,\"start\":7605},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7651,\"start\":7647},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":7654,\"start\":7651},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":7657,\"start\":7654},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7848,\"start\":7845},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7890,\"start\":7887},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8027,\"start\":8023},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8203,\"start\":8199},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8303,\"start\":8299},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8375,\"start\":8371},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8466,\"start\":8463},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8592,\"start\":8588},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":8626,\"start\":8622},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8838,\"start\":8834},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8853,\"start\":8850},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":8856,\"start\":8853},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8882,\"start\":8878},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8885,\"start\":8882},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8936,\"start\":8932},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9594,\"start\":9590},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9617,\"start\":9613},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9767,\"start\":9764},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9769,\"start\":9767},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9893,\"start\":9889},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":9915,\"start\":9911},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":10001,\"start\":9997},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":10033,\"start\":10029},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11654,\"start\":11651},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11660,\"start\":11656},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11669,\"start\":11665},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":12040,\"start\":12036},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":12095,\"start\":12091},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":12313,\"start\":12310},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12321,\"start\":12317},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12422,\"start\":12418},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13160,\"start\":13157},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13162,\"start\":13160},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15510,\"start\":15506},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":15519,\"start\":15515},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16436,\"start\":16432},{\"end\":17425,\"start\":17421},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17743,\"start\":17740},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":17950,\"start\":17946},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":17959,\"start\":17955},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":18194,\"start\":18190},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":18255,\"start\":18251},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":18313,\"start\":18309},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":18367,\"start\":18363},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20425,\"start\":20421},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":20959,\"start\":20956},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21288,\"start\":21284},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21291,\"start\":21288},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":21294,\"start\":21291},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":21607,\"start\":21603},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":21631,\"start\":21627},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":21767,\"start\":21763},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":22070,\"start\":22066},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22079,\"start\":22075},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22142,\"start\":22138},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22476,\"start\":22472},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":22479,\"start\":22476},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":22792,\"start\":22789},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":22795,\"start\":22792},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22798,\"start\":22795},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":22910,\"start\":22907},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":23066,\"start\":23063},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23142,\"start\":23139},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":23178,\"start\":23174},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25319,\"start\":25315},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":25334,\"start\":25330},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25607,\"start\":25603},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":25922,\"start\":25918},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27266,\"start\":27262},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":27269,\"start\":27266},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":29727,\"start\":29723},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":29742,\"start\":29738},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":30143,\"start\":30139},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":30146,\"start\":30143},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":30180,\"start\":30176},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":30217,\"start\":30213},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":30224,\"start\":30220},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":30400,\"start\":30396},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":30646,\"start\":30642},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":30695,\"start\":30691},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":30749,\"start\":30745},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":30755,\"start\":30751},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":30764,\"start\":30760},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":30913,\"start\":30909},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":31554,\"start\":31550},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":31595,\"start\":31591},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":31722,\"start\":31718},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":33652,\"start\":33648},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":33669,\"start\":33665},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":33824,\"start\":33820},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":33852,\"start\":33848},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":33861,\"start\":33857},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":33906,\"start\":33902},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":34113,\"start\":34109},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34701,\"start\":34697},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":34716,\"start\":34712},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":39455,\"start\":39452},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":39491,\"start\":39487},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":39731,\"start\":39727},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":39746,\"start\":39742},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":41252,\"start\":41249},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":41278,\"start\":41275},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":41281,\"start\":41278},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":41293,\"start\":41290},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":41304,\"start\":41301},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":41314,\"start\":41310},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":41324,\"start\":41320}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":40858,\"start\":40142},{\"attributes\":{\"id\":\"fig_1\"},\"end\":40981,\"start\":40859},{\"attributes\":{\"id\":\"fig_2\"},\"end\":41087,\"start\":40982},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":41195,\"start\":41088},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41958,\"start\":41196},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":42352,\"start\":41959},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":42743,\"start\":42353},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":47471,\"start\":42744},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":49216,\"start\":47472}]", "paragraph": "[{\"end\":2693,\"start\":1561},{\"end\":4250,\"start\":2695},{\"end\":5388,\"start\":4252},{\"end\":6280,\"start\":5390},{\"end\":7666,\"start\":6298},{\"end\":8937,\"start\":7668},{\"end\":11026,\"start\":8939},{\"end\":11329,\"start\":11037},{\"end\":12187,\"start\":11362},{\"end\":12823,\"start\":12189},{\"end\":14123,\"start\":12825},{\"end\":14565,\"start\":14125},{\"end\":14700,\"start\":14652},{\"end\":15275,\"start\":14765},{\"end\":15988,\"start\":15364},{\"end\":16166,\"start\":16059},{\"end\":16957,\"start\":16245},{\"end\":17557,\"start\":16959},{\"end\":18093,\"start\":17559},{\"end\":18450,\"start\":18148},{\"end\":18819,\"start\":18477},{\"end\":18856,\"start\":18821},{\"end\":19027,\"start\":18858},{\"end\":19555,\"start\":19271},{\"end\":19936,\"start\":19655},{\"end\":20769,\"start\":20011},{\"end\":23478,\"start\":20808},{\"end\":24648,\"start\":23512},{\"end\":25131,\"start\":24650},{\"end\":26477,\"start\":25150},{\"end\":26779,\"start\":26497},{\"end\":27172,\"start\":26828},{\"end\":27580,\"start\":27174},{\"end\":28109,\"start\":27582},{\"end\":29320,\"start\":28212},{\"end\":30486,\"start\":29351},{\"end\":31741,\"start\":30521},{\"end\":32540,\"start\":31756},{\"end\":33096,\"start\":32542},{\"end\":33508,\"start\":33098},{\"end\":34114,\"start\":33608},{\"end\":35080,\"start\":34146},{\"end\":35365,\"start\":35082},{\"end\":35687,\"start\":35440},{\"end\":35958,\"start\":35730},{\"end\":36497,\"start\":35997},{\"end\":37031,\"start\":36535},{\"end\":37985,\"start\":37033},{\"end\":38676,\"start\":37987},{\"end\":40141,\"start\":38717}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14651,\"start\":14566},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14764,\"start\":14701},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15363,\"start\":15276},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16058,\"start\":15989},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16200,\"start\":16167},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18147,\"start\":18094},{\"attributes\":{\"id\":\"formula_6\"},\"end\":18476,\"start\":18451},{\"attributes\":{\"id\":\"formula_7\"},\"end\":19235,\"start\":19028},{\"attributes\":{\"id\":\"formula_8\"},\"end\":19654,\"start\":19556},{\"attributes\":{\"id\":\"formula_9\"},\"end\":20010,\"start\":19937},{\"attributes\":{\"id\":\"formula_10\"},\"end\":28211,\"start\":28146}]", "table_ref": "[{\"end\":23087,\"start\":23080},{\"end\":23587,\"start\":23580},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":25238,\"start\":25231},{\"end\":30108,\"start\":30101},{\"end\":31164,\"start\":31157},{\"end\":31731,\"start\":31723},{\"end\":35099,\"start\":35091},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":35599,\"start\":35591},{\"end\":39400,\"start\":39392}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1559,\"start\":1547},{\"attributes\":{\"n\":\"2.\"},\"end\":6296,\"start\":6283},{\"attributes\":{\"n\":\"3.\"},\"end\":11035,\"start\":11029},{\"attributes\":{\"n\":\"3.1.\"},\"end\":11360,\"start\":11332},{\"attributes\":{\"n\":\"3.2.\"},\"end\":16243,\"start\":16202},{\"attributes\":{\"n\":\"3.3.\"},\"end\":19269,\"start\":19237},{\"attributes\":{\"n\":\"4.\"},\"end\":20783,\"start\":20772},{\"attributes\":{\"n\":\"4.1.\"},\"end\":20806,\"start\":20786},{\"attributes\":{\"n\":\"4.2.\"},\"end\":23510,\"start\":23481},{\"attributes\":{\"n\":\"4.3.\"},\"end\":25148,\"start\":25134},{\"attributes\":{\"n\":\"4.4.\"},\"end\":26495,\"start\":26480},{\"attributes\":{\"n\":\"4.4.1\"},\"end\":26826,\"start\":26782},{\"attributes\":{\"n\":\"4.4.2\"},\"end\":28145,\"start\":28112},{\"attributes\":{\"n\":\"4.5.\"},\"end\":29349,\"start\":29323},{\"attributes\":{\"n\":\"4.6.\"},\"end\":30519,\"start\":30489},{\"attributes\":{\"n\":\"5.\"},\"end\":31754,\"start\":31744},{\"end\":33578,\"start\":33511},{\"end\":33606,\"start\":33581},{\"end\":34144,\"start\":34117},{\"end\":35401,\"start\":35368},{\"end\":35438,\"start\":35404},{\"end\":35728,\"start\":35690},{\"end\":35995,\"start\":35961},{\"end\":36533,\"start\":36500},{\"end\":38715,\"start\":38679},{\"end\":40163,\"start\":40143},{\"end\":40870,\"start\":40860},{\"end\":40993,\"start\":40983},{\"end\":41098,\"start\":41089},{\"end\":41206,\"start\":41197},{\"end\":41969,\"start\":41960},{\"end\":47483,\"start\":47473}]", "table": "[{\"end\":41958,\"start\":41365},{\"end\":42352,\"start\":42064},{\"end\":42743,\"start\":42545},{\"end\":47471,\"start\":43581},{\"end\":49216,\"start\":47859}]", "figure_caption": "[{\"end\":40858,\"start\":40166},{\"end\":40981,\"start\":40872},{\"end\":41087,\"start\":40995},{\"end\":41195,\"start\":41100},{\"end\":41365,\"start\":41208},{\"end\":42064,\"start\":41971},{\"end\":42545,\"start\":42355},{\"end\":43581,\"start\":42746},{\"end\":47859,\"start\":47486}]", "figure_ref": "[{\"end\":2908,\"start\":2900},{\"end\":18709,\"start\":18701},{\"end\":24580,\"start\":24572},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27032,\"start\":27024},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27417,\"start\":27411},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":27767,\"start\":27759},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":28284,\"start\":28276},{\"end\":29817,\"start\":29809},{\"end\":29868,\"start\":29860},{\"end\":34585,\"start\":34576},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":36142,\"start\":36133},{\"end\":37053,\"start\":37044},{\"end\":37291,\"start\":37282},{\"end\":38052,\"start\":38043},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":38763,\"start\":38748},{\"end\":38839,\"start\":38830},{\"end\":39617,\"start\":39608},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":39828,\"start\":39819},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":39990,\"start\":39981},{\"end\":40091,\"start\":40082}]", "bib_author_first_name": "[{\"end\":49554,\"start\":49548},{\"end\":49570,\"start\":49564},{\"end\":49581,\"start\":49576},{\"end\":49592,\"start\":49591},{\"end\":49889,\"start\":49884},{\"end\":49901,\"start\":49897},{\"end\":49926,\"start\":49922},{\"end\":49928,\"start\":49927},{\"end\":50261,\"start\":50255},{\"end\":50277,\"start\":50271},{\"end\":50291,\"start\":50285},{\"end\":50305,\"start\":50300},{\"end\":50518,\"start\":50513},{\"end\":50531,\"start\":50528},{\"end\":50544,\"start\":50539},{\"end\":50762,\"start\":50758},{\"end\":50780,\"start\":50773},{\"end\":50794,\"start\":50789},{\"end\":50814,\"start\":50807},{\"end\":51360,\"start\":51356},{\"end\":51378,\"start\":51371},{\"end\":51392,\"start\":51387},{\"end\":51412,\"start\":51405},{\"end\":51965,\"start\":51961},{\"end\":51981,\"start\":51976},{\"end\":51995,\"start\":51988},{\"end\":52009,\"start\":52004},{\"end\":52029,\"start\":52022},{\"end\":52696,\"start\":52689},{\"end\":52714,\"start\":52706},{\"end\":53047,\"start\":53040},{\"end\":53049,\"start\":53048},{\"end\":53299,\"start\":53296},{\"end\":53312,\"start\":53307},{\"end\":53566,\"start\":53560},{\"end\":53583,\"start\":53577},{\"end\":53800,\"start\":53795},{\"end\":53822,\"start\":53814},{\"end\":53838,\"start\":53834},{\"end\":53852,\"start\":53845},{\"end\":53864,\"start\":53861},{\"end\":53884,\"start\":53877},{\"end\":53901,\"start\":53894},{\"end\":53917,\"start\":53909},{\"end\":54194,\"start\":54189},{\"end\":54209,\"start\":54203},{\"end\":54229,\"start\":54224},{\"end\":54243,\"start\":54236},{\"end\":54257,\"start\":54251},{\"end\":54903,\"start\":54897},{\"end\":54921,\"start\":54912},{\"end\":54939,\"start\":54930},{\"end\":54955,\"start\":54948},{\"end\":55773,\"start\":55768},{\"end\":55788,\"start\":55783},{\"end\":55805,\"start\":55796},{\"end\":55825,\"start\":55819},{\"end\":56169,\"start\":56168},{\"end\":56177,\"start\":56176},{\"end\":56185,\"start\":56184},{\"end\":56195,\"start\":56194},{\"end\":56203,\"start\":56200},{\"end\":56210,\"start\":56208},{\"end\":56533,\"start\":56526},{\"end\":56546,\"start\":56540},{\"end\":56567,\"start\":56563},{\"end\":57012,\"start\":57005},{\"end\":57026,\"start\":57020},{\"end\":57042,\"start\":57035},{\"end\":57057,\"start\":57051},{\"end\":57070,\"start\":57067},{\"end\":57339,\"start\":57336},{\"end\":57356,\"start\":57349},{\"end\":57374,\"start\":57367},{\"end\":57896,\"start\":57891},{\"end\":57907,\"start\":57904},{\"end\":58553,\"start\":58549},{\"end\":58568,\"start\":58560},{\"end\":58579,\"start\":58574},{\"end\":58594,\"start\":58584},{\"end\":59132,\"start\":59126},{\"end\":59144,\"start\":59138},{\"end\":59152,\"start\":59147},{\"end\":59401,\"start\":59394},{\"end\":59413,\"start\":59406},{\"end\":59429,\"start\":59421},{\"end\":59439,\"start\":59435},{\"end\":59865,\"start\":59857},{\"end\":59879,\"start\":59874},{\"end\":59896,\"start\":59889},{\"end\":60197,\"start\":60189},{\"end\":60211,\"start\":60205},{\"end\":60220,\"start\":60217},{\"end\":60231,\"start\":60225},{\"end\":60238,\"start\":60236},{\"end\":60250,\"start\":60246},{\"end\":60482,\"start\":60477},{\"end\":60491,\"start\":60490},{\"end\":60498,\"start\":60497},{\"end\":60675,\"start\":60671},{\"end\":60693,\"start\":60685},{\"end\":60706,\"start\":60701},{\"end\":60941,\"start\":60935},{\"end\":60960,\"start\":60955},{\"end\":60980,\"start\":60972},{\"end\":60996,\"start\":60989},{\"end\":61435,\"start\":61433},{\"end\":61440,\"start\":61436},{\"end\":61453,\"start\":61446},{\"end\":61467,\"start\":61460},{\"end\":61481,\"start\":61473},{\"end\":61496,\"start\":61488},{\"end\":61512,\"start\":61503},{\"end\":61523,\"start\":61518},{\"end\":61525,\"start\":61524},{\"end\":61887,\"start\":61886},{\"end\":61902,\"start\":61894},{\"end\":62425,\"start\":62418},{\"end\":62436,\"start\":62431},{\"end\":62445,\"start\":62441},{\"end\":62463,\"start\":62453},{\"end\":62478,\"start\":62473},{\"end\":62486,\"start\":62483},{\"end\":62501,\"start\":62494},{\"end\":62503,\"start\":62502},{\"end\":62518,\"start\":62511},{\"end\":63029,\"start\":63028},{\"end\":63036,\"start\":63035},{\"end\":63038,\"start\":63037},{\"end\":63046,\"start\":63045},{\"end\":63371,\"start\":63363},{\"end\":63703,\"start\":63700},{\"end\":63721,\"start\":63712},{\"end\":63739,\"start\":63731},{\"end\":63757,\"start\":63751},{\"end\":63767,\"start\":63764},{\"end\":64130,\"start\":64129},{\"end\":64145,\"start\":64138},{\"end\":64160,\"start\":64154},{\"end\":64162,\"start\":64161},{\"end\":64457,\"start\":64450},{\"end\":64481,\"start\":64474},{\"end\":64493,\"start\":64487},{\"end\":65101,\"start\":65097},{\"end\":65113,\"start\":65110},{\"end\":65130,\"start\":65121},{\"end\":65142,\"start\":65138},{\"end\":65155,\"start\":65150},{\"end\":65173,\"start\":65166},{\"end\":65188,\"start\":65182},{\"end\":65204,\"start\":65198},{\"end\":65217,\"start\":65210},{\"end\":65234,\"start\":65230},{\"end\":65248,\"start\":65243},{\"end\":65267,\"start\":65260},{\"end\":65280,\"start\":65274},{\"end\":65291,\"start\":65287},{\"end\":65306,\"start\":65300},{\"end\":65322,\"start\":65315},{\"end\":65337,\"start\":65331},{\"end\":65358,\"start\":65352},{\"end\":65370,\"start\":65368},{\"end\":65383,\"start\":65377},{\"end\":65396,\"start\":65389},{\"end\":65899,\"start\":65889},{\"end\":65914,\"start\":65908},{\"end\":65930,\"start\":65926},{\"end\":66433,\"start\":66424},{\"end\":66451,\"start\":66446},{\"end\":66468,\"start\":66462},{\"end\":66470,\"start\":66469},{\"end\":66490,\"start\":66480},{\"end\":67153,\"start\":67147},{\"end\":67169,\"start\":67162},{\"end\":67184,\"start\":67179},{\"end\":67605,\"start\":67598},{\"end\":67616,\"start\":67612},{\"end\":67633,\"start\":67626},{\"end\":67648,\"start\":67641},{\"end\":67661,\"start\":67656},{\"end\":67675,\"start\":67669},{\"end\":67680,\"start\":67676},{\"end\":68330,\"start\":68325},{\"end\":68347,\"start\":68340},{\"end\":68359,\"start\":68355},{\"end\":68733,\"start\":68725},{\"end\":68752,\"start\":68744},{\"end\":68770,\"start\":68763},{\"end\":68783,\"start\":68778},{\"end\":69270,\"start\":69266},{\"end\":69289,\"start\":69281},{\"end\":69845,\"start\":69833},{\"end\":69861,\"start\":69854},{\"end\":70228,\"start\":70220},{\"end\":70246,\"start\":70240},{\"end\":70248,\"start\":70247},{\"end\":70265,\"start\":70261},{\"end\":70267,\"start\":70266},{\"end\":70279,\"start\":70275},{\"end\":70298,\"start\":70294},{\"end\":70300,\"start\":70299},{\"end\":70778,\"start\":70777},{\"end\":70780,\"start\":70779},{\"end\":70793,\"start\":70792},{\"end\":70805,\"start\":70804},{\"end\":70812,\"start\":70811},{\"end\":70824,\"start\":70823},{\"end\":70834,\"start\":70833},{\"end\":71227,\"start\":71223},{\"end\":71241,\"start\":71235},{\"end\":71543,\"start\":71536},{\"end\":71554,\"start\":71551},{\"end\":71569,\"start\":71562},{\"end\":71583,\"start\":71577},{\"end\":71596,\"start\":71592},{\"end\":71617,\"start\":71609},{\"end\":72185,\"start\":72184},{\"end\":72187,\"start\":72186},{\"end\":72201,\"start\":72200},{\"end\":72203,\"start\":72202},{\"end\":72392,\"start\":72387},{\"end\":72409,\"start\":72405},{\"end\":72411,\"start\":72410},{\"end\":72598,\"start\":72589},{\"end\":72639,\"start\":72627},{\"end\":72653,\"start\":72646},{\"end\":73155,\"start\":73151},{\"end\":73317,\"start\":73316},{\"end\":73334,\"start\":73328},{\"end\":73336,\"start\":73335},{\"end\":73642,\"start\":73635},{\"end\":73652,\"start\":73648},{\"end\":73668,\"start\":73663},{\"end\":73684,\"start\":73677},{\"end\":73696,\"start\":73689},{\"end\":74165,\"start\":74160},{\"end\":74177,\"start\":74170},{\"end\":74517,\"start\":74511},{\"end\":74534,\"start\":74529},{\"end\":75044,\"start\":75035},{\"end\":75053,\"start\":75051},{\"end\":75068,\"start\":75061},{\"end\":75081,\"start\":75073},{\"end\":75732,\"start\":75731},{\"end\":75734,\"start\":75733},{\"end\":75747,\"start\":75746},{\"end\":75749,\"start\":75748},{\"end\":75758,\"start\":75757},{\"end\":75760,\"start\":75759},{\"end\":76103,\"start\":76101},{\"end\":76112,\"start\":76110},{\"end\":76125,\"start\":76119},{\"end\":76134,\"start\":76126},{\"end\":76143,\"start\":76140},{\"end\":76159,\"start\":76151},{\"end\":76175,\"start\":76170},{\"end\":76188,\"start\":76181}]", "bib_author_last_name": "[{\"end\":49562,\"start\":49555},{\"end\":49574,\"start\":49571},{\"end\":49589,\"start\":49582},{\"end\":49604,\"start\":49593},{\"end\":49895,\"start\":49890},{\"end\":49920,\"start\":49902},{\"end\":49936,\"start\":49929},{\"end\":50269,\"start\":50262},{\"end\":50283,\"start\":50278},{\"end\":50298,\"start\":50292},{\"end\":50313,\"start\":50306},{\"end\":50526,\"start\":50519},{\"end\":50537,\"start\":50532},{\"end\":50551,\"start\":50545},{\"end\":50771,\"start\":50763},{\"end\":50787,\"start\":50781},{\"end\":50805,\"start\":50795},{\"end\":50821,\"start\":50815},{\"end\":51369,\"start\":51361},{\"end\":51385,\"start\":51379},{\"end\":51403,\"start\":51393},{\"end\":51419,\"start\":51413},{\"end\":51974,\"start\":51966},{\"end\":51986,\"start\":51982},{\"end\":52002,\"start\":51996},{\"end\":52020,\"start\":52010},{\"end\":52036,\"start\":52030},{\"end\":52704,\"start\":52697},{\"end\":52721,\"start\":52715},{\"end\":53058,\"start\":53050},{\"end\":53305,\"start\":53300},{\"end\":53319,\"start\":53313},{\"end\":53575,\"start\":53567},{\"end\":53589,\"start\":53584},{\"end\":53812,\"start\":53801},{\"end\":53832,\"start\":53823},{\"end\":53843,\"start\":53839},{\"end\":53859,\"start\":53853},{\"end\":53875,\"start\":53865},{\"end\":53892,\"start\":53885},{\"end\":53907,\"start\":53902},{\"end\":53926,\"start\":53918},{\"end\":54201,\"start\":54195},{\"end\":54222,\"start\":54210},{\"end\":54234,\"start\":54230},{\"end\":54249,\"start\":54244},{\"end\":54263,\"start\":54258},{\"end\":54910,\"start\":54904},{\"end\":54928,\"start\":54922},{\"end\":54946,\"start\":54940},{\"end\":54964,\"start\":54956},{\"end\":55781,\"start\":55774},{\"end\":55794,\"start\":55789},{\"end\":55817,\"start\":55806},{\"end\":55831,\"start\":55826},{\"end\":56174,\"start\":56170},{\"end\":56182,\"start\":56178},{\"end\":56192,\"start\":56186},{\"end\":56198,\"start\":56196},{\"end\":56206,\"start\":56204},{\"end\":56218,\"start\":56211},{\"end\":56538,\"start\":56534},{\"end\":56561,\"start\":56547},{\"end\":56574,\"start\":56568},{\"end\":57018,\"start\":57013},{\"end\":57033,\"start\":57027},{\"end\":57049,\"start\":57043},{\"end\":57065,\"start\":57058},{\"end\":57077,\"start\":57071},{\"end\":57347,\"start\":57340},{\"end\":57365,\"start\":57357},{\"end\":57381,\"start\":57375},{\"end\":57902,\"start\":57897},{\"end\":57916,\"start\":57908},{\"end\":58558,\"start\":58554},{\"end\":58572,\"start\":58569},{\"end\":58582,\"start\":58580},{\"end\":58599,\"start\":58595},{\"end\":59136,\"start\":59133},{\"end\":59159,\"start\":59153},{\"end\":59404,\"start\":59402},{\"end\":59419,\"start\":59414},{\"end\":59433,\"start\":59430},{\"end\":59443,\"start\":59440},{\"end\":59872,\"start\":59866},{\"end\":59887,\"start\":59880},{\"end\":59901,\"start\":59897},{\"end\":60203,\"start\":60198},{\"end\":60215,\"start\":60212},{\"end\":60223,\"start\":60221},{\"end\":60234,\"start\":60232},{\"end\":60244,\"start\":60239},{\"end\":60253,\"start\":60251},{\"end\":60488,\"start\":60483},{\"end\":60495,\"start\":60492},{\"end\":60503,\"start\":60499},{\"end\":60683,\"start\":60676},{\"end\":60699,\"start\":60694},{\"end\":60712,\"start\":60707},{\"end\":60953,\"start\":60942},{\"end\":60970,\"start\":60961},{\"end\":60987,\"start\":60981},{\"end\":61002,\"start\":60997},{\"end\":61444,\"start\":61441},{\"end\":61458,\"start\":61454},{\"end\":61471,\"start\":61468},{\"end\":61486,\"start\":61482},{\"end\":61501,\"start\":61497},{\"end\":61516,\"start\":61513},{\"end\":61530,\"start\":61526},{\"end\":61892,\"start\":61888},{\"end\":61909,\"start\":61903},{\"end\":61919,\"start\":61911},{\"end\":62173,\"start\":62166},{\"end\":62429,\"start\":62426},{\"end\":62439,\"start\":62437},{\"end\":62451,\"start\":62446},{\"end\":62471,\"start\":62464},{\"end\":62481,\"start\":62479},{\"end\":62492,\"start\":62487},{\"end\":62509,\"start\":62504},{\"end\":62524,\"start\":62519},{\"end\":63033,\"start\":63030},{\"end\":63043,\"start\":63039},{\"end\":63050,\"start\":63047},{\"end\":63055,\"start\":63052},{\"end\":63391,\"start\":63372},{\"end\":63710,\"start\":63704},{\"end\":63729,\"start\":63722},{\"end\":63749,\"start\":63740},{\"end\":63762,\"start\":63758},{\"end\":63775,\"start\":63768},{\"end\":64136,\"start\":64131},{\"end\":64152,\"start\":64146},{\"end\":64181,\"start\":64163},{\"end\":64188,\"start\":64183},{\"end\":64472,\"start\":64458},{\"end\":64485,\"start\":64482},{\"end\":64498,\"start\":64494},{\"end\":64504,\"start\":64500},{\"end\":65108,\"start\":65102},{\"end\":65119,\"start\":65114},{\"end\":65136,\"start\":65131},{\"end\":65148,\"start\":65143},{\"end\":65164,\"start\":65156},{\"end\":65180,\"start\":65174},{\"end\":65196,\"start\":65189},{\"end\":65208,\"start\":65205},{\"end\":65228,\"start\":65218},{\"end\":65241,\"start\":65235},{\"end\":65258,\"start\":65249},{\"end\":65272,\"start\":65268},{\"end\":65285,\"start\":65281},{\"end\":65298,\"start\":65292},{\"end\":65313,\"start\":65307},{\"end\":65329,\"start\":65323},{\"end\":65350,\"start\":65338},{\"end\":65366,\"start\":65359},{\"end\":65375,\"start\":65371},{\"end\":65387,\"start\":65384},{\"end\":65405,\"start\":65397},{\"end\":65906,\"start\":65900},{\"end\":65924,\"start\":65915},{\"end\":65936,\"start\":65931},{\"end\":66444,\"start\":66434},{\"end\":66460,\"start\":66452},{\"end\":66478,\"start\":66471},{\"end\":66498,\"start\":66491},{\"end\":67160,\"start\":67154},{\"end\":67177,\"start\":67170},{\"end\":67191,\"start\":67185},{\"end\":67610,\"start\":67606},{\"end\":67624,\"start\":67617},{\"end\":67639,\"start\":67634},{\"end\":67654,\"start\":67649},{\"end\":67667,\"start\":67662},{\"end\":67686,\"start\":67681},{\"end\":68338,\"start\":68331},{\"end\":68353,\"start\":68348},{\"end\":68369,\"start\":68360},{\"end\":68742,\"start\":68734},{\"end\":68761,\"start\":68753},{\"end\":68776,\"start\":68771},{\"end\":68789,\"start\":68784},{\"end\":69279,\"start\":69271},{\"end\":69295,\"start\":69290},{\"end\":69852,\"start\":69846},{\"end\":69869,\"start\":69862},{\"end\":70094,\"start\":70088},{\"end\":70238,\"start\":70229},{\"end\":70259,\"start\":70249},{\"end\":70273,\"start\":70268},{\"end\":70292,\"start\":70280},{\"end\":70306,\"start\":70301},{\"end\":70790,\"start\":70781},{\"end\":70802,\"start\":70794},{\"end\":70809,\"start\":70806},{\"end\":70821,\"start\":70813},{\"end\":70831,\"start\":70825},{\"end\":70840,\"start\":70835},{\"end\":71233,\"start\":71228},{\"end\":71250,\"start\":71242},{\"end\":71549,\"start\":71544},{\"end\":71560,\"start\":71555},{\"end\":71575,\"start\":71570},{\"end\":71590,\"start\":71584},{\"end\":71607,\"start\":71597},{\"end\":71623,\"start\":71618},{\"end\":72193,\"start\":72188},{\"end\":72198,\"start\":72195},{\"end\":72210,\"start\":72204},{\"end\":72216,\"start\":72212},{\"end\":72403,\"start\":72393},{\"end\":72417,\"start\":72412},{\"end\":72613,\"start\":72599},{\"end\":72625,\"start\":72615},{\"end\":72644,\"start\":72640},{\"end\":72659,\"start\":72654},{\"end\":72672,\"start\":72661},{\"end\":73164,\"start\":73156},{\"end\":73326,\"start\":73318},{\"end\":73343,\"start\":73337},{\"end\":73354,\"start\":73345},{\"end\":73646,\"start\":73643},{\"end\":73661,\"start\":73653},{\"end\":73675,\"start\":73669},{\"end\":73687,\"start\":73685},{\"end\":73699,\"start\":73697},{\"end\":74168,\"start\":74166},{\"end\":74182,\"start\":74178},{\"end\":74527,\"start\":74518},{\"end\":74544,\"start\":74535},{\"end\":75049,\"start\":75045},{\"end\":75059,\"start\":75054},{\"end\":75071,\"start\":75069},{\"end\":75087,\"start\":75082},{\"end\":75744,\"start\":75735},{\"end\":75755,\"start\":75750},{\"end\":75767,\"start\":75761},{\"end\":75779,\"start\":75769},{\"end\":76108,\"start\":76104},{\"end\":76117,\"start\":76113},{\"end\":76138,\"start\":76135},{\"end\":76149,\"start\":76144},{\"end\":76168,\"start\":76160},{\"end\":76179,\"start\":76176},{\"end\":76193,\"start\":76189}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":13812735},\"end\":49812,\"start\":49510},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":21688963},\"end\":50197,\"start\":49814},{\"attributes\":{\"doi\":\". 07 2016. 4\",\"id\":\"b2\"},\"end\":50459,\"start\":50199},{\"attributes\":{\"id\":\"b3\"},\"end\":50675,\"start\":50461},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":189857704},\"end\":51260,\"start\":50677},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":207880670},\"end\":51865,\"start\":51262},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":49567058},\"end\":52597,\"start\":51867},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":68222714},\"end\":52968,\"start\":52599},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":5706462},\"end\":53220,\"start\":52970},{\"attributes\":{\"id\":\"b9\"},\"end\":53463,\"start\":53222},{\"attributes\":{\"id\":\"b10\"},\"end\":53744,\"start\":53465},{\"attributes\":{\"id\":\"b11\"},\"end\":54125,\"start\":53746},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":53694083},\"end\":54808,\"start\":54127},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":226976039},\"end\":55680,\"start\":54810},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":211068987},\"end\":56113,\"start\":55682},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":57246310},\"end\":56489,\"start\":56115},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":8768364},\"end\":56945,\"start\":56491},{\"attributes\":{\"id\":\"b17\"},\"end\":57284,\"start\":56947},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":7162940},\"end\":57833,\"start\":57286},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":44108048},\"end\":58372,\"start\":57835},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":102353587},\"end\":59071,\"start\":58374},{\"attributes\":{\"id\":\"b21\"},\"end\":59346,\"start\":59073},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":206594692},\"end\":59809,\"start\":59348},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":7200347},\"end\":60123,\"start\":59811},{\"attributes\":{\"id\":\"b24\"},\"end\":60412,\"start\":60125},{\"attributes\":{\"id\":\"b25\"},\"end\":60627,\"start\":60414},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":926364},\"end\":60890,\"start\":60629},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":201125339},\"end\":61361,\"start\":60892},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":213787017},\"end\":61828,\"start\":61363},{\"attributes\":{\"id\":\"b29\"},\"end\":62164,\"start\":61830},{\"attributes\":{\"id\":\"b30\"},\"end\":62362,\"start\":62166},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":208139191},\"end\":62963,\"start\":62364},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":3865699},\"end\":63318,\"start\":62965},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":117765088},\"end\":63652,\"start\":63320},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":203593945},\"end\":64030,\"start\":63654},{\"attributes\":{\"doi\":\"abs/1811.08495\",\"id\":\"b35\"},\"end\":64392,\"start\":64032},{\"attributes\":{\"doi\":\"PMLR, 09-15\",\"id\":\"b36\",\"matched_paper_id\":59316845},\"end\":65025,\"start\":64394},{\"attributes\":{\"id\":\"b37\"},\"end\":65800,\"start\":65027},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":84186723},\"end\":66348,\"start\":65802},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":49657108},\"end\":67052,\"start\":66350},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":218971560},\"end\":67509,\"start\":67054},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b41\",\"matched_paper_id\":211204852},\"end\":68241,\"start\":67511},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":221370646},\"end\":68657,\"start\":68243},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":3509717},\"end\":69186,\"start\":68659},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":14613395},\"end\":69829,\"start\":69188},{\"attributes\":{\"id\":\"b45\"},\"end\":70024,\"start\":69831},{\"attributes\":{\"id\":\"b46\"},\"end\":70173,\"start\":70026},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":2198181},\"end\":70693,\"start\":70175},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":15019293},\"end\":71149,\"start\":70695},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":3383786},\"end\":71481,\"start\":71151},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b50\",\"matched_paper_id\":204960694},\"end\":72149,\"start\":71483},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":114800582},\"end\":72345,\"start\":72151},{\"attributes\":{\"id\":\"b52\"},\"end\":72538,\"start\":72347},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":215870627},\"end\":73127,\"start\":72540},{\"attributes\":{\"id\":\"b54\"},\"end\":73274,\"start\":73129},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":8707032},\"end\":73571,\"start\":73276},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":8485068},\"end\":74089,\"start\":73573},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":220250825},\"end\":74485,\"start\":74091},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":15276198},\"end\":74974,\"start\":74487},{\"attributes\":{\"doi\":\"PMLR. 4\",\"id\":\"b59\",\"matched_paper_id\":173548},\"end\":75655,\"start\":74976},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":207761262},\"end\":76022,\"start\":75657},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":51805340},\"end\":76494,\"start\":76024}]", "bib_title": "[{\"end\":49546,\"start\":49510},{\"end\":49882,\"start\":49814},{\"end\":50756,\"start\":50677},{\"end\":51354,\"start\":51262},{\"end\":51959,\"start\":51867},{\"end\":52687,\"start\":52599},{\"end\":53038,\"start\":52970},{\"end\":54187,\"start\":54127},{\"end\":54895,\"start\":54810},{\"end\":55766,\"start\":55682},{\"end\":56166,\"start\":56115},{\"end\":56524,\"start\":56491},{\"end\":57334,\"start\":57286},{\"end\":57889,\"start\":57835},{\"end\":58547,\"start\":58374},{\"end\":59124,\"start\":59073},{\"end\":59392,\"start\":59348},{\"end\":59855,\"start\":59811},{\"end\":60669,\"start\":60629},{\"end\":60933,\"start\":60892},{\"end\":61431,\"start\":61363},{\"end\":62416,\"start\":62364},{\"end\":63026,\"start\":62965},{\"end\":63361,\"start\":63320},{\"end\":63698,\"start\":63654},{\"end\":64448,\"start\":64394},{\"end\":65887,\"start\":65802},{\"end\":66422,\"start\":66350},{\"end\":67145,\"start\":67054},{\"end\":67596,\"start\":67511},{\"end\":68323,\"start\":68243},{\"end\":68723,\"start\":68659},{\"end\":69264,\"start\":69188},{\"end\":70218,\"start\":70175},{\"end\":70775,\"start\":70695},{\"end\":71221,\"start\":71151},{\"end\":71534,\"start\":71483},{\"end\":72182,\"start\":72151},{\"end\":72587,\"start\":72540},{\"end\":73314,\"start\":73276},{\"end\":73633,\"start\":73573},{\"end\":74158,\"start\":74091},{\"end\":74509,\"start\":74487},{\"end\":75033,\"start\":74976},{\"end\":75729,\"start\":75657},{\"end\":76099,\"start\":76024}]", "bib_author": "[{\"end\":49564,\"start\":49548},{\"end\":49576,\"start\":49564},{\"end\":49591,\"start\":49576},{\"end\":49606,\"start\":49591},{\"end\":49897,\"start\":49884},{\"end\":49922,\"start\":49897},{\"end\":49938,\"start\":49922},{\"end\":50271,\"start\":50255},{\"end\":50285,\"start\":50271},{\"end\":50300,\"start\":50285},{\"end\":50315,\"start\":50300},{\"end\":50528,\"start\":50513},{\"end\":50539,\"start\":50528},{\"end\":50553,\"start\":50539},{\"end\":50773,\"start\":50758},{\"end\":50789,\"start\":50773},{\"end\":50807,\"start\":50789},{\"end\":50823,\"start\":50807},{\"end\":51371,\"start\":51356},{\"end\":51387,\"start\":51371},{\"end\":51405,\"start\":51387},{\"end\":51421,\"start\":51405},{\"end\":51976,\"start\":51961},{\"end\":51988,\"start\":51976},{\"end\":52004,\"start\":51988},{\"end\":52022,\"start\":52004},{\"end\":52038,\"start\":52022},{\"end\":52706,\"start\":52689},{\"end\":52723,\"start\":52706},{\"end\":53060,\"start\":53040},{\"end\":53307,\"start\":53296},{\"end\":53321,\"start\":53307},{\"end\":53577,\"start\":53560},{\"end\":53591,\"start\":53577},{\"end\":53814,\"start\":53795},{\"end\":53834,\"start\":53814},{\"end\":53845,\"start\":53834},{\"end\":53861,\"start\":53845},{\"end\":53877,\"start\":53861},{\"end\":53894,\"start\":53877},{\"end\":53909,\"start\":53894},{\"end\":53928,\"start\":53909},{\"end\":54203,\"start\":54189},{\"end\":54224,\"start\":54203},{\"end\":54236,\"start\":54224},{\"end\":54251,\"start\":54236},{\"end\":54265,\"start\":54251},{\"end\":54912,\"start\":54897},{\"end\":54930,\"start\":54912},{\"end\":54948,\"start\":54930},{\"end\":54966,\"start\":54948},{\"end\":55783,\"start\":55768},{\"end\":55796,\"start\":55783},{\"end\":55819,\"start\":55796},{\"end\":55833,\"start\":55819},{\"end\":56176,\"start\":56168},{\"end\":56184,\"start\":56176},{\"end\":56194,\"start\":56184},{\"end\":56200,\"start\":56194},{\"end\":56208,\"start\":56200},{\"end\":56220,\"start\":56208},{\"end\":56540,\"start\":56526},{\"end\":56563,\"start\":56540},{\"end\":56576,\"start\":56563},{\"end\":57020,\"start\":57005},{\"end\":57035,\"start\":57020},{\"end\":57051,\"start\":57035},{\"end\":57067,\"start\":57051},{\"end\":57079,\"start\":57067},{\"end\":57349,\"start\":57336},{\"end\":57367,\"start\":57349},{\"end\":57383,\"start\":57367},{\"end\":57904,\"start\":57891},{\"end\":57918,\"start\":57904},{\"end\":58560,\"start\":58549},{\"end\":58574,\"start\":58560},{\"end\":58584,\"start\":58574},{\"end\":58601,\"start\":58584},{\"end\":59138,\"start\":59126},{\"end\":59147,\"start\":59138},{\"end\":59161,\"start\":59147},{\"end\":59406,\"start\":59394},{\"end\":59421,\"start\":59406},{\"end\":59435,\"start\":59421},{\"end\":59445,\"start\":59435},{\"end\":59874,\"start\":59857},{\"end\":59889,\"start\":59874},{\"end\":59903,\"start\":59889},{\"end\":60205,\"start\":60189},{\"end\":60217,\"start\":60205},{\"end\":60225,\"start\":60217},{\"end\":60236,\"start\":60225},{\"end\":60246,\"start\":60236},{\"end\":60255,\"start\":60246},{\"end\":60490,\"start\":60477},{\"end\":60497,\"start\":60490},{\"end\":60505,\"start\":60497},{\"end\":60685,\"start\":60671},{\"end\":60701,\"start\":60685},{\"end\":60714,\"start\":60701},{\"end\":60955,\"start\":60935},{\"end\":60972,\"start\":60955},{\"end\":60989,\"start\":60972},{\"end\":61004,\"start\":60989},{\"end\":61446,\"start\":61433},{\"end\":61460,\"start\":61446},{\"end\":61473,\"start\":61460},{\"end\":61488,\"start\":61473},{\"end\":61503,\"start\":61488},{\"end\":61518,\"start\":61503},{\"end\":61532,\"start\":61518},{\"end\":61894,\"start\":61886},{\"end\":61911,\"start\":61894},{\"end\":61921,\"start\":61911},{\"end\":62175,\"start\":62166},{\"end\":62431,\"start\":62418},{\"end\":62441,\"start\":62431},{\"end\":62453,\"start\":62441},{\"end\":62473,\"start\":62453},{\"end\":62483,\"start\":62473},{\"end\":62494,\"start\":62483},{\"end\":62511,\"start\":62494},{\"end\":62526,\"start\":62511},{\"end\":63035,\"start\":63028},{\"end\":63045,\"start\":63035},{\"end\":63052,\"start\":63045},{\"end\":63057,\"start\":63052},{\"end\":63393,\"start\":63363},{\"end\":63712,\"start\":63700},{\"end\":63731,\"start\":63712},{\"end\":63751,\"start\":63731},{\"end\":63764,\"start\":63751},{\"end\":63777,\"start\":63764},{\"end\":64138,\"start\":64129},{\"end\":64154,\"start\":64138},{\"end\":64183,\"start\":64154},{\"end\":64190,\"start\":64183},{\"end\":64474,\"start\":64450},{\"end\":64487,\"start\":64474},{\"end\":64500,\"start\":64487},{\"end\":64506,\"start\":64500},{\"end\":65110,\"start\":65097},{\"end\":65121,\"start\":65110},{\"end\":65138,\"start\":65121},{\"end\":65150,\"start\":65138},{\"end\":65166,\"start\":65150},{\"end\":65182,\"start\":65166},{\"end\":65198,\"start\":65182},{\"end\":65210,\"start\":65198},{\"end\":65230,\"start\":65210},{\"end\":65243,\"start\":65230},{\"end\":65260,\"start\":65243},{\"end\":65274,\"start\":65260},{\"end\":65287,\"start\":65274},{\"end\":65300,\"start\":65287},{\"end\":65315,\"start\":65300},{\"end\":65331,\"start\":65315},{\"end\":65352,\"start\":65331},{\"end\":65368,\"start\":65352},{\"end\":65377,\"start\":65368},{\"end\":65389,\"start\":65377},{\"end\":65407,\"start\":65389},{\"end\":65908,\"start\":65889},{\"end\":65926,\"start\":65908},{\"end\":65938,\"start\":65926},{\"end\":66446,\"start\":66424},{\"end\":66462,\"start\":66446},{\"end\":66480,\"start\":66462},{\"end\":66500,\"start\":66480},{\"end\":67162,\"start\":67147},{\"end\":67179,\"start\":67162},{\"end\":67193,\"start\":67179},{\"end\":67612,\"start\":67598},{\"end\":67626,\"start\":67612},{\"end\":67641,\"start\":67626},{\"end\":67656,\"start\":67641},{\"end\":67669,\"start\":67656},{\"end\":67688,\"start\":67669},{\"end\":68340,\"start\":68325},{\"end\":68355,\"start\":68340},{\"end\":68371,\"start\":68355},{\"end\":68744,\"start\":68725},{\"end\":68763,\"start\":68744},{\"end\":68778,\"start\":68763},{\"end\":68791,\"start\":68778},{\"end\":69281,\"start\":69266},{\"end\":69297,\"start\":69281},{\"end\":69854,\"start\":69833},{\"end\":69871,\"start\":69854},{\"end\":70096,\"start\":70088},{\"end\":70240,\"start\":70220},{\"end\":70261,\"start\":70240},{\"end\":70275,\"start\":70261},{\"end\":70294,\"start\":70275},{\"end\":70308,\"start\":70294},{\"end\":70792,\"start\":70777},{\"end\":70804,\"start\":70792},{\"end\":70811,\"start\":70804},{\"end\":70823,\"start\":70811},{\"end\":70833,\"start\":70823},{\"end\":70842,\"start\":70833},{\"end\":71235,\"start\":71223},{\"end\":71252,\"start\":71235},{\"end\":71551,\"start\":71536},{\"end\":71562,\"start\":71551},{\"end\":71577,\"start\":71562},{\"end\":71592,\"start\":71577},{\"end\":71609,\"start\":71592},{\"end\":71625,\"start\":71609},{\"end\":72195,\"start\":72184},{\"end\":72200,\"start\":72195},{\"end\":72212,\"start\":72200},{\"end\":72218,\"start\":72212},{\"end\":72405,\"start\":72387},{\"end\":72419,\"start\":72405},{\"end\":72615,\"start\":72589},{\"end\":72627,\"start\":72615},{\"end\":72646,\"start\":72627},{\"end\":72661,\"start\":72646},{\"end\":72674,\"start\":72661},{\"end\":73166,\"start\":73151},{\"end\":73328,\"start\":73316},{\"end\":73345,\"start\":73328},{\"end\":73356,\"start\":73345},{\"end\":73648,\"start\":73635},{\"end\":73663,\"start\":73648},{\"end\":73677,\"start\":73663},{\"end\":73689,\"start\":73677},{\"end\":73701,\"start\":73689},{\"end\":74170,\"start\":74160},{\"end\":74184,\"start\":74170},{\"end\":74529,\"start\":74511},{\"end\":74546,\"start\":74529},{\"end\":75051,\"start\":75035},{\"end\":75061,\"start\":75051},{\"end\":75073,\"start\":75061},{\"end\":75089,\"start\":75073},{\"end\":75746,\"start\":75731},{\"end\":75757,\"start\":75746},{\"end\":75769,\"start\":75757},{\"end\":75781,\"start\":75769},{\"end\":76110,\"start\":76101},{\"end\":76119,\"start\":76110},{\"end\":76140,\"start\":76119},{\"end\":76151,\"start\":76140},{\"end\":76170,\"start\":76151},{\"end\":76181,\"start\":76170},{\"end\":76195,\"start\":76181}]", "bib_venue": "[{\"end\":50986,\"start\":50913},{\"end\":51584,\"start\":51511},{\"end\":52281,\"start\":52168},{\"end\":54411,\"start\":54407},{\"end\":55176,\"start\":55172},{\"end\":56648,\"start\":56634},{\"end\":58744,\"start\":58681},{\"end\":59600,\"start\":59531},{\"end\":61147,\"start\":61084},{\"end\":62689,\"start\":62616},{\"end\":63500,\"start\":63455},{\"end\":64683,\"start\":64630},{\"end\":66101,\"start\":66028},{\"end\":66700,\"start\":66600},{\"end\":67844,\"start\":67791},{\"end\":68946,\"start\":68877},{\"end\":69497,\"start\":69397},{\"end\":70377,\"start\":70359},{\"end\":71781,\"start\":71728},{\"end\":72771,\"start\":72767},{\"end\":73856,\"start\":73787},{\"end\":74293,\"start\":74247},{\"end\":74709,\"start\":74665},{\"end\":75287,\"start\":75211},{\"end\":49646,\"start\":49606},{\"end\":49973,\"start\":49938},{\"end\":50253,\"start\":50199},{\"end\":50511,\"start\":50461},{\"end\":50911,\"start\":50823},{\"end\":51509,\"start\":51421},{\"end\":52166,\"start\":52038},{\"end\":52775,\"start\":52723},{\"end\":53081,\"start\":53060},{\"end\":53294,\"start\":53222},{\"end\":53558,\"start\":53465},{\"end\":53793,\"start\":53746},{\"end\":54318,\"start\":54265},{\"end\":55030,\"start\":54966},{\"end\":55885,\"start\":55833},{\"end\":56283,\"start\":56220},{\"end\":56632,\"start\":56576},{\"end\":57003,\"start\":56947},{\"end\":57432,\"start\":57383},{\"end\":57967,\"start\":57918},{\"end\":58679,\"start\":58601},{\"end\":59196,\"start\":59161},{\"end\":59529,\"start\":59445},{\"end\":59958,\"start\":59903},{\"end\":60187,\"start\":60125},{\"end\":60475,\"start\":60414},{\"end\":60743,\"start\":60714},{\"end\":61082,\"start\":61004},{\"end\":61584,\"start\":61532},{\"end\":61884,\"start\":61830},{\"end\":62224,\"start\":62175},{\"end\":62614,\"start\":62526},{\"end\":63127,\"start\":63057},{\"end\":63453,\"start\":63393},{\"end\":63829,\"start\":63777},{\"end\":64127,\"start\":64032},{\"end\":64585,\"start\":64517},{\"end\":65095,\"start\":65027},{\"end\":66026,\"start\":65938},{\"end\":66598,\"start\":66500},{\"end\":67257,\"start\":67193},{\"end\":67760,\"start\":67692},{\"end\":68430,\"start\":68371},{\"end\":68875,\"start\":68791},{\"end\":69395,\"start\":69297},{\"end\":70086,\"start\":70026},{\"end\":70357,\"start\":70308},{\"end\":70902,\"start\":70842},{\"end\":71304,\"start\":71252},{\"end\":71697,\"start\":71629},{\"end\":72234,\"start\":72218},{\"end\":72385,\"start\":72347},{\"end\":72700,\"start\":72674},{\"end\":73149,\"start\":73129},{\"end\":73409,\"start\":73356},{\"end\":73785,\"start\":73701},{\"end\":74245,\"start\":74184},{\"end\":74605,\"start\":74546},{\"end\":75164,\"start\":75096},{\"end\":75818,\"start\":75781},{\"end\":76247,\"start\":76195}]"}}}, "year": 2023, "month": 12, "day": 17}