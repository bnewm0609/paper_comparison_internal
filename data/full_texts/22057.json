{"id": 22057, "updated": "2023-12-13 23:36:06.347", "metadata": {"title": "Anomaly Detection in Streams with Extreme Value Theory", "authors": "[{\"first\":\"Alban\",\"last\":\"Siffer\",\"middle\":[]},{\"first\":\"Pierre-Alain\",\"last\":\"Fouque\",\"middle\":[]},{\"first\":\"Alexandre\",\"last\":\"Termier\",\"middle\":[]},{\"first\":\"Christine\",\"last\":\"Largouet\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "publication_date": {"year": 2017, "month": null, "day": null}, "abstract": "Anomaly detection in time series has attracted considerable attention due to its importance in many real-world applications including intrusion detection, energy management and finance. Most approaches for detecting outliers rely on either manually set thresholds or assumptions on the distribution of data according to Chandola, Banerjee and Kumar. Here, we propose a new approach to detect outliers in streaming univariate time series based on Extreme Value Theory that does not require to hand-set thresholds and makes no assumption on the distribution: the main parameter is only the risk, controlling the number of false positives. Our approach can be used for outlier detection, but more generally for automatically setting thresholds, making it useful in wide number of situations. We also experiment our algorithms on various real-world datasets which confirm its soundness and efficiency.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2743617586", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/kdd/SifferFTL17", "doi": "10.1145/3097983.3098144"}}, "content": {"source": {"pdf_hash": "95e79c4e723d71228b018222f4019d2e179c9e16", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://hal.archives-ouvertes.fr/hal-01640325/file/siffer_kdd_17.pdf", "status": "GREEN"}}, "grobid": {"id": "847523d166eca4272d51f390ac0edf598d410420", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/95e79c4e723d71228b018222f4019d2e179c9e16.txt", "contents": "\nAnomaly Detection in Streams with Extreme Value Theory\n\n\nAlban Siffer alban.siffer@irisa.fr \nIRISA\nAmossysInria\n\nPierre-Alain Fouque pierre-alain.fouque@inria.fr \nUniv\nRennes 1IRISA\n\nAlexandre Termier alexandre.termier@irisa.fr \nUniv\nRennes 1, InriaIRISA\n\nChristine Largouet christine.largouet@irisa.fr \nInria\nIRISA\n\nAnomaly Detection in Streams with Extreme Value Theory\n10.1145/3097983.3098144CCS CONCEPTS \u2022 Computing methodologies \u2192 Anomaly detection\u2022 Math- ematics of computing \u2192 Time series analysis\u2022 Information systems \u2192 Data stream miningKEYWORDS Outliers in time series, Extreme Value Theory, Streaming\nAnomaly detection in time series has attracted considerable attention due to its importance in many real-world applications including intrusion detection, energy management and finance. Most approaches for detecting outliers rely on either manually set thresholds or assumptions on the distribution of data according to Chandola, Banerjee and Kumar.Here, we propose a new approach to detect outliers in streaming univariate time series based on Extreme Value Theory that does not require to hand-set thresholds and makes no assumption on the distribution: the main parameter is only the risk, controlling the number of false positives. Our approach can be used for outlier detection, but more generally for automatically setting thresholds, making it useful in wide number of situations. We also experiment our algorithms on various real-world datasets which confirm its soundness and efficiency.\n\nWhen the data is static, or is a stream coming from an extremely controlled environment, such assumptions can safely be made. But in the general case of streaming data from an open environment, these assumptions are no longer true. They may fail in unexpected cases.\n\nThe issue is that nowadays, more and more critical applications rely on high throughput streaming numerical data like energy management [30], cyber-security [32] or finance [26]. For example, in intrusion detection, some network attack techniques rely on intensive scans of the network, which are characterized by an unusually high number of SYN packets [32].\n\nThe main challenge is to learn \"normality\" in an ever changing environment and to automatically adapt the detection method accordingly.\n\nThe problem of detecting extreme values in streams can be expressed as follows: Let (X t ) t \u22650 be a streaming time series of iid observations. Can we set a threshold z q such that for any t \u2265 0, the probability to observe X t > z q is lower than q (for q as small as desired) ?\n\nTo solve this problem, we use the statistical powerful tool of Extreme Value Theory (EVT). This theory was developed to study the law of extreme values in a distribution function after the following dramatic event. In the night of January 31 to February 1 of the year 1953, a set of rare conditions occurred in the North Sea, leading to a \"perfect storm\" scenario. On the coast of Netherlands, the waves generated overwhelmed the dikes, causing extensive flooding. The flooding led to the death of 1800+ people in the Netherlands alone. In the dike case, X t is the height of the waves, and z q is the height of the dike.\n\nIn the aftermath of this disaster, scientists were tasked to determine a minimal dike height such that the probability for waves to exceed this height is extremely low. Statisticians devised an elegant theory for the study of such rare events [10]. One of the most elegant result of EVT is that the distribution of the extreme values is almost independent of the distribution of the data with a theorem similar to the central limit theorem, for min, max instead of the mean value.\n\nThe main contribution of this paper is to propose an approach for outlier detection in high throughput streaming univariate and unimodal time series. Thanks to EVT, our approach makes no distribution assumption on the data: it is thus a solution to \"Research Issue 6\" for outlier detection in data streams as stated by Sadik and Gruenwald [29] in SIGKDD Explorations 2014. We decline our approach into two algorithms: SPOT for streaming data having any stationary distribution, and DSPOT for streaming data that can be subject to concept drift. Through detailed experiments on synthetic and real data, we show that our approach is accurate for detecting outliers, is computationally efficient, and for DSPOT reacts quickly to any change in the stream. For instance, we decide to test our algorithm on incoming streams without knowledge on their distribution. We show that we detect very efficiently and accurately: (i) network SYN attacks on a labeled data stream and (ii) peaks that allows to take decision on stock market (quickly react for buying or selling shares). Our experiments also confirm the EVT theory with accuracy and fast convergence.\n\nAnalyzing streaming data require the computation of EVT to be fast and resilient: as a secondary contribution, we propose two improvements on the general method for solving the EVT problem, that improve both its speed and its robustness. They are used in our algorithms, but they are not specific to streaming data and can immediately be applied to most algorithms using EVT.\n\n\nRELATED WORK\n\nClassically, anomaly detectors have to highlight what will be considered as an anomaly, also called outlier. As we propose a statistical method to find anomalies, we rely on the assumption given by Chandola, Banerjee and Kumar in [13]: \"Normal data instances occur in high probability regions of a stochastic model, while anomalies occur in the low probability regions of the stochastic model\".\n\nA great deal of algorithms for static outlier detection are given in the literature. The main approaches are distance based [7], nearestneighbor based [11] or clustering based [14] and are very well detailed in [13]. Nonetheless, as mentioned in [31], most existing outlier detection methods need to scan several times the data and/or have high time complexity, thus they cannot be used in data streams.\n\nIn [28,29], Sadik details the specificities of the stream environment and the hardships of outlier detection in this context. The main constraints are the following: data cannot be scanned twice and new concepts may keep evolving.\n\nMany works which address the streaming case present distance based algorithms for outlier detection (STORM [8], CORM [15], DBOD-DS [28], attributes weighting [31]). These methods are able to work on multidimensional streams with categorical features but they need user defined thresholds which could be a real hindrance in practice.\n\nCurrent statistical approaches to perform outlier detection in data stream suffer from the inherent problem, namely the distribution assumption. In [6], Agarwal assumes a gaussian model to detect anomalies in multidimensional arrays and recommends a Box-Cox transformation if it is not the case. In [16], a more general mixture model is presented by Eskin, based on a majority distribution and an anomaly one. However both models need to be learned, so data of each distribution are required. In [24], the authors use a probabilist threshold \u03f5 to discriminate normal or abnormal data (observations with probability lower than \u03f5 are anomalies), but its possible values are lower-bounded by 1/(k + 1) where k is the number of training elements. Thus it needs a huge training sample if we want a very low false positive rate.\n\nIn our work, we do not assume the distribution of the value we monitor but we rely on powerful theoretical results to estimate accurately low probability areas and then discriminate outliers.\n\nWith our single parameter algorithms, we are able to detect outliers in both stationary and drifting contexts.\n\n\nBACKGROUND\n\nIn this section we describe the theoretical background of the Extreme Value Theory (EVT). We try to explain the main results and how they could be used to address our problem (the reader could refer to the rich reference of Beirlant et al. [10] for more details). This part is not a prerequisite to understand the purpose of our algorithm but it gathers some elements to precise its fundamental basis.\n\nMany techniques allow the scientist to find statistical thresholds (quantiles). For instance, we can compute them empirically or assume a distribution. However data do not necessarily follow well-known distributions (Gaussian, uniform, exponential etc.) so the model step (the choice of the distribution) could be hard, even inappropriate. Moreover, if we want to predict extreme events, like rare or unprecedented events (as tidal waves), the empirical method will not give accurate estimation (an unprecedented event would have a probability equal to zero). The extreme value theory addresses these problems by inferring the distribution of the extreme events we might monitor, without strong hypothesis on the original distribution.\n\nMathematically, X is a random variable and F its cumulative distribution function: F (x) = P(X \u2264 x). We denote byF the \"tail\" of the distribution:F (x) = 1 \u2212 F (x) = P(X > x). We use X i to denote both random variables and their outcomes, however the context will precise their meanings. For a random variable X and a given probability q we note z q its quantile at level 1 \u2212 q, i.e. z q is the smallest value s.t. P(X \u2264 z q ) \u2265 1 \u2212 q i.e. P(X > z q ) < q.\n\n\nExtreme value distributions\n\nThe goal of the extreme value theory is to find the law of extreme events (e.g. the law of the daily maximum of temperature, or the law of the monthly maximal tide height). A beautiful result from Fisher, Tippett [18] and later Gnedenko [20] states that, under a weak condition, these extreme events have the same kind of distribution, regardless of the original one. For instance the maximum of temperatures or tide heights have more or less the same distribution whereas the distributions of the temperatures and the tide heights are not likely to be the same. This extreme laws are called the Extreme Value Distributions (EVD) and they have the following form :\nG \u03b3 : x \u2192 exp \u2212 (1 + \u03b3 x) \u2212 1 \u03b3 , \u03b3 \u2208 R, 1 + \u03b3 x > 0.\nAll the extremes of common standard distributions follow such a distribution and the extreme value index \u03b3 depends on this original law. For example, if X 1 , . . . X n are n iid variables (e.g. gaussian N (0, 1)) then M n = max 1\u2264i \u2264n X i is likely to follow an EVD which extreme value index \u03b3 is given by the initial distribution (for the Gaussian distribution \u03b3 = 0). This result may seem very counterintuitive but we can give some elements to catch the idea. Indeed, we can easily imagine that for most distributions the probabilities decrease when events are extreme, ie P(X > x) \u2192 0 when x increases. The functionF (x) = P(X > x) represents the tail of the distribution of X . Actually, there are not many possible shapes for this tail and G \u03b3 tries to fit them. The table 1 presents the three possible shapes of the tail and the link with the extreme value index \u03b3 . It gives also an example of standard distribution which follows each tail behavior. The parameter \u03c4 represents the bound of the initial distribution, so it could be finite (ex: uniform cdf) or infinite (ex: normal cdf). The figure 1 depicts an example of the three behaviors.\n\nTail behavior (x \u2192 \u03c4 ) Domain Example  \nHeavy tail, P(X > x) \u2243 x \u2212 1 \u03b3 \u03b3 > 0 Frechet Exponential tail, P(X > x) \u2243 e \u2212x \u03b3 = 0 Gamma Bounded, P(X > x) = x \u2265\u03c4 0 \u03b3 < 0 Uniform\n\nPower of EVT\n\nThis phenomenon allows us to accurately compute probabilities without inferring the initial law that can be really complex. It \"regularizes\" the initial distribution. Indeed, the central limit theorem states that the mean of n iid random variables converges in distribution to a normal distribution. The EVT theorem states the same result for the maximum. By fitting an EVD to the unknown input distribution tail (see figure 2), it is then possible to evaluate the probability of potential extreme events. In particular, from a given probability q it is possible to calculate z q such that P(X > z q ) < q. To solve this problem, the natural way will be to estimate \u03b3 . Several estimates exist such as Hill's estimate [22] and Pickands' estimate [27] but they give good results only for certain tail behaviors. Its estimation is hard and nowadays we do not know a general and efficient method to compute it (i.e. for all \u03b3 \u2208 R).\n\nAnother way exists to fit the tail of the distribution: the Peaks-Over-Threshold (POT) approach.\n\n\nPeaks-Over-Threshold (POT) approach\n\nThe Peaks-Over-Threshold (POT) approach relies on the Pickands-Balkema-de Haan theorem [9,27] (also called second theorem in EVT in comparison to the initial result of Fisher, Tippett and Gnedenko) given below.\nTheorem 3.1 (Pickands-Balkema-de Haan). The cumulative distribution function F \u2208 D \u03b3 1 if and only if a function \u03c3 exists, for all x \u2208 R s.t . 1 + \u03b3 x > 0: F (t + \u03c3 (t)x) F (t) \u2212\u2192 t \u2192\u03c4 (1 + \u03b3 x) \u2212 1 \u03b3 .\nA clearer view of the theorem is the following:\nF t (x) = P (X \u2212 t > x | X > t) \u223c t \u2192\u03c4 1 + \u03b3 x \u03c3 (t) \u2212 1 \u03b3 .\nThis result shows that the excess over a threshold t, written X \u2212 t, are likely to follow a Generalized Pareto Distribution (GPD) with parameters \u03b3 , \u03c3 . In fact, the GPD needs a third parameter, the location \u00b5, but it is null in our case. Rather than fitting an EVD to the extreme values of X , the POT approach tries to fit a GPD to the excesses X \u2212 t.\n\nIn the case we get estimates\u03b3 and\u03c3 (our method will be described in 3.4), the quantile can be computed through :\nz q \u2243 t +\u03c3 \u03b3 qn N t \u2212\u03b3 \u2212 1 ,(1)\nwhere t is a \"high\" threshold (details will be given in 4.3.3), q the desired probability, n the total number of observations, N t the number of peaks i.e the number of X i s.t. X i > t. Some classical methods can be used to perform the estimation of \u03b3 and \u03c3 , as the Method of Moments (MOM) or the Probability Weigted Moments (PWM) but they are less efficient and robust than the maximum likelihood estimation [10] that we describe below.\n\n\nMaximum likelihood estimation\n\n3.4.1 Likelihood expression. The maximum likelihood estimation remains a natural way to evaluate the parameters through observations. If X 1 , . . . X n are n independent realizations of the random variable X which density (noted f \u03b8 ) is parametrized by \u03b8 (possibly a vector), the likelihood function is defined by:\nL (X 1 , . . . X n ; \u03b8 ) = n i=1 f \u03b8 (X i ).\nIt represents joint density of these n observations. As X 1 , . . . X n are fixed in our context, we try to find the parameter \u03b8 such that the likelihood is maximized. It means that we are looking for the value of \u03b8 which makes our observations the most probable. Practically, we work on the log-likelihood, so in our case (GPD fit) we have to maximize :\nlog L(\u03b3 , \u03c3 ) = \u2212N t log \u03c3 \u2212 1 + 1 \u03b3 N t i=1 log 1 + \u03b3 \u03c3 Y i , 1 It means that the extrema of the distribution of F converge in distribution to G \u03b3 . where Y i > 0 are the excesses of X i over t (Y i = X i \u2212 t for X i > t).\nUnfortunately, the optimization must be done numerically, implying the classical numerical issues. To perform it, the procedure of Grimshaw [21] can be used.\n\nIn a strict GPD case (if the Y i follow exactly a GPD), the Maximum Likelihood Estimate (MLE) has some good convergence properties in comparison to other estimates (MOM or PWM). It converges in distribution to a Gaussian distribution when the number of peaks N t \u2192 \u221e when \u03b3 > \u2212 1 2 (with a rate of consistency\n\u221a N t ) and is superefficient when \u22121 < \u03b3 < \u2212 1 2 with a rate of consistency N \u2212\u03b3 t .\n\nThe\n\nGrimshaw's trick. The trick of the Grimshaw's procedure is to reduce the two variables optimization problem to a single variable equation. Let us write \u2113(\u03b3 , \u03c3 ) = log L(\u03b3 , \u03c3 ). As we find an extremum of \u2113, we look for solutions of the system \u2207\u2113(\u03b3 , \u03c3 ) = 0. Grimshaw has shown that if we get a solution (\u03b3 * , \u03c3 * ) of this system then the variable x * = \u03b3 * /\u03c3 * is solution of the scalar equation\nu(x)v(x) = 1 where: u(x) = 1 N t N t i=1 1 1 + xY i v(x) = 1 + 1 N t N t i=1 log (1 + xY i ) .\nMoreover, by finding a solution x * of this equation, we can retrieve \u03b3 * = v (x * ) \u2212 1 and \u03c3 * = \u03b3 * /x * . Nevertheless, the solutions of this equation give only possible candidates for the maximum of \u2113, so we have to get all the roots, to calculate the corresponding likelihood and keep the best tuple (\u03b3 ,\u03c3 ) as our final estimates.\n\nWe have to pay attention to how this numerical root search is done. In fact, the values 1 + xY i must be strictly positives. As the Y i are positive, we must find\nx * on \u2212 1 Y M , +\u221e where Y M = max Y i .\nGrimshaw calculates also an upper-bound x * max for this root search:\nx * max = 2 Y \u2212 Y m (Y m ) 2 ,\nwhere Y m = min Y i and Y is the mean of the Y i . Finally, the number of roots is not known and 0 is always a solution so the implementation must find all the solutions and pick up those which maximizes the likelihood.\n\n\nOUR CONTRIBUTION\n\nThe extreme value theory, through the POT approach, gives us a way to estimate z q such that P(X > z q ) < q without any strong assumption on the distribution of X and without any clear knowledge about its distribution. In this section we use this result to build a streaming outlier detector. First we present the initialization step which computes an threshold z q from n observations X 1 , . . . X n . Then, we detail our two streaming algorithms which update z q with the incoming data and use it as a decision bound. We propose SPOT which works in stationary cases, and DSPOT which takes into account a drift component. Finally we give some theoretical and technical improvements making our bound update fast and sturdy.\n\n\nInitialization step\n\nLet us sum up the basic idea of our algorithm. We have n observations X 1 , . . . X n , and we have fixed a risk q. The goal is to compute a first threshold z q verifying P(X > z q ) < q. The figure 3 shows what we do on this initial batch (calibration). The idea is to set a high threshold t (e.g. a high empirical quantile practically), retrieve the peaks (the excesses over t) and fit a GPD (Generalized Pareto Distribution) to them. So that we infer the distribution of the extreme values and we can compute the threshold z q . This initialization step is summarized in the algorithm 1. The choice of t will be discussed in 4.3.3. The set Y t is the peaks set where we store the observed excesses over t. The GPD fit is performed with the Grimshaw trick (we detail our likelihood optimization in 4.3.2) and then we can compute z q with equation 1.\n\nAlgorithm 1 POT (Peaks-over-Threshold) 1: procedure POT(X 1 , . . . X n ,q) 2:\nt \u2190 SetInitialThreshold(X 1 , . . . X n ) 3: Y t \u2190 {X i \u2212 t | X i > t } 4:\u03b3 ,\u03c3 \u2190 Grimshaw(Y t ) 5: z q \u2190 CalcThreshold(q,\u03b3 ,\u03c3 , n, N t , t) 6:\nreturn z q , t 7: end procedure\n\n\nFinding anomalies in a stream\n\nThe POT primitive returns a threshold z q which we use to define a \"normality bound\" (figure 3).\n\nIn our streaming algorithms the POT primitive (algorithm 1) is used as an initialization step.\n\nThe POT primitive may be seen as a training step but this is partly wrong because the initial batch X 1 , . . . X n is not labeled and is not considered as a ground truth in our algorithm. The initialization is more a calibration step. Our streaming anomaly detector uses the next observations to both detect anomalies and refine the anomaly threshold z q .\n\n4.2.1 Stationary case. The way how the POT estimate is built is really stream-ready. As we do not have to store the whole time series (only the peaks), it requires low memory so we can use it in a stream. However, the stream must contain values from the same distribution, so this distribution cannot been time-dependent (what we call stationary). In case of time-dependency, we will show that our algorithm can be adapted to drifting cases (see 4.2.2).\n\nThe principle of the SPOT algorithm is the following : we want to detect abnormal events in a stream (X i ) i >0 in a blind way (without knowledge about the distribution). Firstly, we perform a POT estimate on the n first values (n \u223c 1000) and we get an initial threshold z q (initialization). Then for all the next observed values we can flag the events or update the threshold (see figure 3). If a value exceeds our threshold z q then we consider it as abnormal (we can retrieve this anomaly in a list A). The anomalies are not taken into account for the model update. In the other cases, either X i is greater than the initial threshold (peak case) either it is a \"common\" value (normal case). In the peak case, we add the excess to the peaks set and we update the threshold z q .\n\nIn this algorithm we perform the maximum number of threshold updates but it is possible to do it off-line at fixed time interval. Of course we illustrate the principle only with upper-bound thresholds Algorithm 2 SPOT (Streaming POT) 1: procedure SPOT((X i ) i >0 , n, q)\n\n\n2:\n\nA \u2190 \u2205 \u25b7 set of the anomalies 3: z q , t \u2190 POT(X 1 , . . . X n , q) 4: k \u2190 n 5:\n\nfor i > n do 6: if X i > z q then \u25b7 anomaly case 7:\nAdd (i, X i ) in A 8:\nelse if X i > t then \u25b7 real peak case 9:\nY i \u2190 X i \u2212 t 10: Add Y i in Y t 11:\nN t \u2190 N t + 1 12:  Figure 3: Anomaly detection overview but the method is the same for lower-bound ones and we can even combine both (performances will be presented in 5.4).\nk \u2190 k + 1 13:\u03b3 ,\u03c3 \u2190 Grimshaw(Y t ) 14: z q \u2190 CalcThreshold(q,\u03b3 ,\u03c3 , k, N t ,\n\nDrifting case.\n\nSPOT assumes that the distribution of the X i does not change over time but it might be restrictive. For instance, a mid-term seasonality cannot be taken into account, making local peaks undetectable. In this section we overcome this issue by modeling an average local behavior and applying SPOT on relative gaps.\n\nWe propose Drift SPOT (DSPOT) which makes SPOT run not on the absolute values X i but on the relative ones. We use the variable change X \u2032 i = X i \u2212 M i where M i models the local behavior at time i (see figure 4). In our implementation we used a moving average is a window parameter). In this new context we assume that the local variations X \u2032 i come from a same stationary distribution (the hypothesis assumed for X i in SPOT is now assumed for X \u2032 i ). This variant uses an additional parameter d, which can be viewed as a window size. The distinctive features of this window (noted W * ) are the following: it might be non continuous and it does not contain abnormal values. A \u2190 \u2205 \u25b7 set of the anomalies \nM i = (1/d) \u00b7 d k =1 X * i\u2212k with X * i\u22121 , . . . X * i\u2212d the last d \"normal\" observations (so dFLAG! z q t M time X i M i X j M jX \u2032 i = X i \u2212 M i 7: W * \u2190 [X i\u2212d+1 , . . . X i ] 8: M i+1 \u2190 W * 9:\nend for 10:\nz q , t \u2190 POT(X \u2032 d+1 , . . . X \u2032 d+n , q) 11:\nk \u2190 n 12:\n\nfor i > d + n do 13:\nX \u2032 i = X i \u2212 M i \u25b7 variable change 14:\nif X \u2032 i > z q then \u25b7 anomaly case 15:\nAdd (i, X i ) in A 16: M i+1 \u2190 M i \u25b7 no update 17:\nelse if X \u2032 i > t then \u25b7 real peak case 18:\nY i \u2190 X \u2032 i \u2212 t 19: Add Y i in Y t 20:\nN t \u2190 N t + 1 21: end for 32: end procedure\nk \u2190 k + 1 22:\u03b3 ,\u03c3 \u2190 Grimshaw(Y t ) 23: z q \u2190 CalcThreshold(q,\u03b3 ,\u03c3 , k, N t ,\nThe algorithm 3 shows our method to capture the local model and perform SPOT thresholding on local variations. It contains some additional steps so as to compute variable changes. For these stages, we principally use a sliding windows over normal observations W * (lines 3, 7, 24 and 28) in order to calculate a local normal behavior M i (lines 4, 8, 25 and 29) through averaging. We logically update the local behavior only in normal or peak cases (lines 25 and 29).\n\nWe can retrieve sequentially the \"real\" extreme quantiles by adding M i to the calculated z q . Such a choice to model the local behavior is a very efficient way to adapt SPOT to drifting contexts. As mentioned in the previous paragraph, DSPOT can be adapted to compute upper and lower bounds.\n\n\nNumerical optimization\n\nThe streaming context requests fast and resilient algorithms. In this part, we optimize the GPD fit by reducing the search of optimal parameters and making it more robust to common numerical stability problems (divergence, absurd values). The proposition 4.1 gives a general result for EVT, improving the Grimshaw's trick. In 4.3.2, we detail how we perform the likelihood optimization and finally we give some details about the initial threshold t.\n\n4.3.1 Reduction of the optimal parameters search. As we have seen in section 3.4.2, the Grimshaw's method for the maximum likelihood estimation requires a numerical root search in a bounded interval. In this paragraph we show that we can reduce this interval.\n\nGathering the following result and the previous bounds (section 3.4.2), the possible solutions of u(x)v(x) = 1 stand in the two intervals\n\u2212 1 Y M , 0 and 2 Y \u2212 Y m YY m , 2 Y \u2212 Y m (Y m ) 2 . Proposition 4.1. If x * is a solution of u(x)v(x) = 1, x * \u2264 0 or x * \u2265 2 Y \u2212 Y m YY m . Proof. Since \u2200x > \u22121, log(1 + x) \u2265 2x 2+x = 2 \u2212 4 2+x , v(x) \u2265 1 + 1 N t N t i=1 2 \u2212 4 2 + xY i \u2265 3 \u2212 4 2 + xY m .\nThen applying Jensen's inequality on the convex function x \u2192 1 1+x we get :\nu(x) \u2265 1 1 + xY , so that u(x)v(x) \u2265 3 \u2212 4 2 + xY m 1 1 + xY . If x * is a solution of the equation u(x)v(x) = 1, we must have 1 \u2265 3 \u2212 4 2 + x * Y m 1 1 + x * Y .\nSimplifying this inequality, we get\nx * x * Y m Y \u2212 2 Y \u2212 Y m \u2265 0.\nAnd a simple sign study gives the result. \u25a1\n\n\nHow can we maximize the likelihood function?\n\nFinding the maximum of the likelihood boils down to apply a root search. But this is not a trivial task: we do not know the number of roots and all the roots are potential candidates to maximize this function.\n\nIn [21], Grimshaw gives an analytic-based routine using rootfinding algorithm is given however the needed condition f (a)f (b) < 0 is not emphasized leading to uncertain results. For this reason we decide to use another method to find these roots.\n\nIn our implementation, we set a very small \u03f5 > 0 (\u223c 10 \u22128 ) and we look for the roots of the function w :\nx \u2192 u(x)v(x) \u2212 1 in both intervals \u2212 1 Y M + \u03f5, \u2212\u03f5 and 2 Y \u2212 Y m YY m , 2 Y \u2212 Y m (Y m ) 2 .\nThe real \u03f5 is used to avoid both cases x = 1 Y M (where w is not defined) and x = 0 (which is always a solution).\n\nMany methods exist to find multiple roots of polynomials (such as Sturm method) but not for the general case of scalar functions. Furthermore, finding a root needs a sign change which may be difficult to detect. Thus we have reduced our root search to a function minimization which requires less assumptions.\n\nTo find the zeros of w we solve numerically the following optimization problem in both intervals (that we note I ):\nmin x 1 , ..x k \u2208I k i=1 w(x k ) 2 .\nThe minimization can be done with a classical algorithm (e.g. L-BFGS-B [12]) starting with k points x 0 1 , ...x 0 k (k \u2243 10) distributed over I . We use this procedure for three reasons: the optimal configuration (x * 1 , ..x * k ) is likely to contain the zeros of w in I , we can retrieve several roots (according to k) and optimizing procedures do not require sign change between the bounds.\n\nWe perform this optimization in both intervals so we get a list of candidates to maximize the likelihood (the case x = 0 is also treated). We keep the best of them and we retrieve the best parameters for the GPD fit.\n\n\nInitial threshold.\n\nWe have detailed the Grimshaw procedure (3.4.2 and 4.3) and how the final threshold z q is calculated (equation 1) but we have not dealt with the initial threshold t. In practice, its value is not paramount except that it must be \"high\" enough. The higher is t, the more relevant will be the GPD fit (low bias). However, if t is too high, the peaks set Y t would be little filled in, so the model would be more variable (high variance). The only important condition is to ensure that t is lower than z q , meaning that the probability associated to t must be lower than 1 \u2212 q. In practice we set t to a high empirical quantile (98%).\n\nA method based on the mean excess plot [10] could be used to set t in a smarter way but it is less stable and likely to output absurd values.\n\n\nEXPERIMENTS\n\nIn this section we apply both our algorithms SPOT and DSPOT on several contexts. First, we compare the computed threshold z q with the theoretical ones through experiments on synthetic data. Then we use real world datasets from several fields (network, physics, finance) to highlight the properties of our algorithms.\n\nFinally we present the performance of our implementation. The real world datasets used in these experiments are all available on the Internet and we do our utmost to detail experimental protocols making them totally reproducible. Our python3 implementation is available at [1].\n\n\n(D)SPOT reliability\n\nIn this section, we compare our computed threshold z q to the theoretical one. In other words, we want to check if z q is the desired threshold (which verifies P(X > z q ) < q). In the same time we evaluate the impact of the number of observations n in the initial batch.\n\nIn the following experiments we set q = 10 \u22123 and we run SPOT on Gaussian white noises of 15000 values, i.e. 15000 independent values from a standard normal distribution (\u00b5 = 0, \u03c3 2 = 1). For different values of n (300, 500, 1000, 2000 and 5000), we run SPOT k = 100 times and we retrieve the averaged error made in comparison to the theoretical threshold:\nerror rate = z SPOT \u2212 z th z th .\nHere, z th is the quantile of the standard normal distribution at level 1 \u2212 q, so z th \u2243 3.09. The figure 5 presents the results. First of all the curves show that, for all initial batch sizes n, the error is low and decreases when the number of observations increases. It means that the computed threshold z SPOT is close to the theoretical one and tends to it.\n\nSecondly, we have to notice that the error curves all converge to the same value regardless of n. Therefore, n is not a paramount parameter. In our experiments, we just have to ensure that n is not too small, otherwise the initialization step is likely to fail because of a lack of peaks to perform the GPD fit. Generally, we use n \u2243 1000. SPOT computes a robust threshold estimation (z q ): the more data we monitor, the more accurate the estimation is. So having a lot of data from the same and unknown distribution, SPOT can gradually adapt this threshold in order to detect anomalies. Cyber-security is a typical field where such configurations appear.\n\nTo test our algorithm we use real data from the MAWI repository which contains daily network captures (15 minutes a day stored in a .pcap file). In these captures, MAWIlab [19] finds anomalies and labels them with the taxonomy proposed by Mazel et al. [25]. The anomalies are referred through detailed patterns. To be close to real monitoring systems we converted raw .pcap files into NetFlow format, which aggregates packets and retrieves meta-data only, and is commonly used to measure network activity. Then we labeled the flows according to the patterns given by the MAWIlab. In this experiment we use the two captures from the 17/08/2012 and the 18/08/2012.\n\nClassical attacks are network scans where many SYN packets are sent in order to find open and potentially vulnerable ports on several machines. A relevant feature to detect such attack is the ratio of SYN packets in a given time window [17]. From our NetFlow records we compute this feature on successive 50 ms time windows and we try to find extreme events. To initialize SPOT we use the last 1000 values of the 17/08 record and we let the algorithm working on the 18/08 capture.  The figure 6 shows the alerts triggered by SPOT (red circles). We recall that each point represents a 50 ms window gathering several flows (possibly benign and malicious). The computed threshold (dashed line) seems nearly constant but this behavior is due to the stability of the measure we monitor (SPOT has quickly inferred the behavior of the feature). By flagging all the flows in the triggered windows, we get a true positive rate equal to 86% with less than 4% of false positives.\n\n\n5.2.2\n\nThe parameter q as a false-positive regulator. In the previous section we noticed that the size of the initial batch n is not an important parameter insofar as it does not affect the overall behavior of SPOT. Here, we study the impact of the main parameter q on the MAWI dataset.\n\nOn the figure 7, the ROC curve shows the effect of q on the False Positive rate (FPr). Values of q between 10 \u22123 and 10 \u22125 allow to have a high TPr while keeping a low FPr: this leaves some room for error when setting q.\n\n\nFinding anomalies with DSPOT\n\n5.3.1 Measure of the magnetic field. To show the wide variety of fields on which we can use DSPOT, we apply our algorithm on astrophysics measures from the SPIDR (Space Physics Interactive Data Resource) [4]. SPIDR is an online platform which stores and manages historical space physics data for integration with environment models and space weather forecasts.\n\nParticularly we use a dataset available on Comp-Engine Time Series [3] which gathers some physical measures taken by the ACE satellite between 1/1/1995 and 1/6/1995. In the figure 8   At the first glance, the bounds are following the signal and some alarms are triggered by high peaks. After 9000 minutes, the upper bound seems higher than expected.\n\nTo understand why, let us divide the signal into two parts: before and after 8000 minutes. Before 8000, we can observe that \"peaks\" lean upwards the trend although the opposite phenomenon appears after 8000. During these 8000 first minutes, DSPOT learns that peaks may lean upwards the trend and it keeps this information in memory. Hence after 8000 minutes, the upper bound stays high in order to accommodate for possible peaks above the trend. DSPOT has this behavior because it keeps a global memory of all peaks encountered. If it was not desired, un easy modification is to keep only the last k peaks, for a fixed k.\n\n\nStock prices.\n\nOn Thursday the 9th of February 2017, an explosion happened at Flamanville nuclear plant, in northern France. This power plant is managed by EDF, a French electricity provider. The incident was not in the nuclear zone and did not hurt people [5]. This incident was officially declared at 11:00 a.m. making the EDF stock price fall down. This recent event encouraged us to test DSPOT on EDF stock prices.\n\nObviously, retrieving financial data with high resolution is not within ours grasp. However, some websites like Google Finance [2] propose intraday financial data with a record per minute. Google Finance keeps these records during 15 days, so we retrieve the records from the 6th to the 8th of February 2017 for calibration (1062 values) and ran DSPOT on the explosion day (379 values). .\n\nOn figure 9, we notice that DSPOT follows the average behavior and flags the drop around 11:00 a.m. This may help a trading system to quickly take actions or warn experts. \n\n\nPerformances\n\nHere we give some details about the time and memory performances of our python3 implementation. All these experiments have been made on a laptop with an Intel i5-5300U CPU @ 2.30GHz (4 cores) and 8 GB RAM. Both algorithms, SPOT and DSPOT require a fixed memory size for all the variables except for the peak set Y t which may grow with the number of observations. To measure the memory performance of our algorithm we report the number of peaks we stored.\n\nTo test the performances of our algorithms we run each of them on 100 Gaussian white noises of 15000 values (like the experiment in section 5.1). At every run we measure the averaged time to perform one iteration and the ratio of stored peaks, i.e. the number of peaks over the number of observations.\n\nFor these experiments we set q = 10 \u22123 and we use n = 1000 values for the initial batch. We record these measures in four contexts: SPOT, SPOT both sides (bi-SPOT), DSPOT and DSPOT both sides (bi-DSPOT). The \"both sides\" runs take into account upper and lower thresholds updates. In drifting cases, we add a drift to the Gaussian white noise and we use a depth d = 50.\n\nThe table 2 presents the averaged time to perform one iteration (denoted T, measured in \u00b5s) and the ratio number of peaks over number of observations at the end of the run (denoted M, in %) in mean, best and worst cases.  Our algorithm stores a little ratio of all the stream (few percents). Logically we store about twice more when we compute upper and lower thresholds. Even if the growth speed of the peaks sets size is low it could be an hindrance for a long term monitoring. However, the size of the peaks set could be upper-bounded (with a high bound) making it work like a wide sliding window (very old peaks would be dropped) without loss of accuracy.\n\n\nMethod\n\nFinally the time performances of our algorithms show that our implementation is able to work on streams with more than 1000 values a second.\n\n\nCONCLUSION\n\nThis paper has presented a novel approach to detect outliers in high throughput numerical time series. The key points of our approach is that it does not assume the data distribution, and it does not require manually set thresholds. It adapts on multiple and complex contexts, learning how the interest measure behaves. It achieves these results by using the Extreme Values Theory (EVT). To the best of our knowledge, it is the first time EVT has been used to detect outliers in streaming data.\n\nThere are two kinds of perspectives. From the theoretical side, in this paper we only exploited a small part of EVT, we would like to extend this work to the multivariate case and to non-iid observations.\n\nFrom the practical side, one of the immediate application of our approach is automatic thresholding: it can provide thresholds with strong statistical guarantees that can adapt to the evolution of a data stream. We would like to explore the use of our approach as a building block into more complex systems that require thresholding. Also the EVT on multivariate cases could address our problem in more general contexts without independence condition.\n\nFigure 1 :\n1Tail distribution\u1e20 \u03b3 according to \u03b3\n\nF = 1 Figure 2 :\n12EVD fit of an unknown cdf\n\nFigure 4 :\n4Anomaly detection with drift Algorithm 3 DSPOT (Streaming POT with drift) 1: procedure DSPOT((X i ) i >0 ,\n\nFigure 5 :\n5Error rate with the number of observations according to the batch size n 5.2 Finding anomalies with SPOT 5.2.1 Intrusion detection example.\n\n\nSYN packets in 50 ms time window\n\nFigure 6 :\n6SYN flood detection at level q = 10 \u22124\n\nFigure 7 :\n7ROC curves on MAWI dataset (the markers give the corresponding value of q)\n\n\nwe monitor a component of the magnetic field (in nT) during several minutes. This time series is very noisy and contains different complex behaviors. We calibrate DSPOT with the n = 2000 first values and we run on the 15801 others with q = 10 \u22123 and d = 450. The results are depicted on the figure 8.\n\nFigure 8 :\n8DSPOT run with q = 10 \u22123 , d = 450\n\nFigure 9 :\n9DSPOT run with q = 10 \u22123 , d = 10\n\nTable 1 :\n1Relation between F and \u03b3\n\nTable 2 :\n2Time (T, in \u00b5s) and Memory (M, in %) performances\n\nMagnetic field time series. Magnetic field time series. http://www.comp-engine.org/timeseries/time-series_ data/data-17481/. (????).\n\nSpace Physics Interactive Data Resource. Space Physics Interactive Data Resource. http://spidr.ionosonde.net/spidr/home. do. (????).\n\nAn empirical bayes approach to detect anomalies in dynamic multidimensional arrays. Deepak Agarwal, ICDM. Deepak Agarwal. 2005. An empirical bayes approach to detect anomalies in dynamic multidimensional arrays. In ICDM.\n\nDistance-based detection and prediction of outliers. Fabrizio Angiulli, Stefano Basta, Clara Pizzuti, IEEE transactions on knowledge and data engineering. Fabrizio Angiulli, Stefano Basta, and Clara Pizzuti. 2006. Distance-based detection and prediction of outliers. IEEE transactions on knowledge and data engineering (2006).\n\nDetecting distance-based outliers in streams of data. Fabrizio Angiulli, Fabio Fassetti, Proceedings of the 16th ACM conference on Conference on information and knowledge management. the 16th ACM conference on Conference on information and knowledge managementFabrizio Angiulli and Fabio Fassetti. 2007. Detecting distance-based outliers in streams of data. In Proceedings of the 16th ACM conference on Conference on information and knowledge management.\n\nResidual life time at great age. The Annals of probability. A August, Laurens Balkema, De Haan, August A Balkema and Laurens De Haan. 1974. Residual life time at great age. The Annals of probability (1974).\n\nStatistics of extremes: theory and applications. Jan Beirlant, Yuri Goegebeur, Johan Segers, Jozef Teugels, John Wiley & SonsJan Beirlant, Yuri Goegebeur, Johan Segers, and Jozef Teugels. 2006. Statistics of extremes: theory and applications. John Wiley & Sons.\n\nLOF: identifying density-based local outliers. M Markus, Hans-Peter Breunig, Raymond T Kriegel, J\u00f6rg Ng, Sander, ACM sigmod record. ACM29Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and J\u00f6rg Sander. 2000. LOF: identifying density-based local outliers. In ACM sigmod record, Vol. 29. ACM, 93-104.\n\nA limited memory algorithm for bound constrained optimization. H Richard, Peihuang Byrd, Jorge Lu, Ciyou Nocedal, Zhu, SIAM J. on Scientific Computing. Richard H Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou Zhu. 1995. A limited memory algorithm for bound constrained optimization. SIAM J. on Scientific Computing (1995).\n\nAnomaly detection: A survey. Varun Chandola, Arindam Banerjee, Vipin Kumar, ACM computing surveys. Varun Chandola, Arindam Banerjee, and Vipin Kumar. 2009. Anomaly detection: A survey. ACM computing surveys (2009).\n\nCluster-based outlier detection. Lian Duan, Lida Xu, Ying Liu, Annals of Operations Research. 168Lian Duan, Lida Xu, Ying Liu, and Jun Lee. 2009. Cluster-based outlier detection. Annals of Operations Research 168, 1 (2009), 151-168.\n\nEfficient clustering-based outlier detection algorithm for dynamic data stream. Manzoor Elahi, Kun Li, Wasif Nisar, Xinjie Lv, Hongan Wang, FSKD'08Manzoor Elahi, Kun Li, Wasif Nisar, Xinjie Lv, and Hongan Wang. 2008. Efficient clustering-based outlier detection algorithm for dynamic data stream. In FSKD'08.\n\nAnomaly detection over noisy data using learned probability distributions. Eleazar Eskin, ICML. Eleazar Eskin. 2000. Anomaly detection over noisy data using learned probability distributions. In ICML.\n\nAutomated classification of network traffic anomalies. Guilherme Fernandes, Philippe Owezarski, ICSPCS. Guilherme Fernandes and Philippe Owezarski. 2009. Automated classification of network traffic anomalies. In ICSPCS.\n\nLimiting forms of the frequency distribution of the largest or smallest member of a sample. Aylmer Ronald, Leonard Henry Caleb Fisher, Tippett, Mathematical Proceedings of the Cambridge Philosophical Society. Ronald Aylmer Fisher and Leonard Henry Caleb Tippett. 1928. Limiting forms of the frequency distribution of the largest or smallest member of a sample. In Mathematical Proceedings of the Cambridge Philosophical Society.\n\nMAWILab: Combining Diverse Anomaly Detectors for Automated Anomaly Labeling and Performance Benchmarking. Romain Fontugne, Pierre Borgnat, Patrice Abry, Kensuke Fukuda, ACM CoNEXT '10. Romain Fontugne, Pierre Borgnat, Patrice Abry, and Kensuke Fukuda. 2010. MAWILab: Combining Diverse Anomaly Detectors for Automated Anomaly Labeling and Performance Benchmarking. In ACM CoNEXT '10.\n\nSur la distribution limite du terme maximum d'une serie aleatoire. Boris Gnedenko, Annals of mathematics. Boris Gnedenko. 1943. Sur la distribution limite du terme maximum d'une serie aleatoire. Annals of mathematics (1943), 423-453.\n\nComputing Maximum Likelihood Estimates for the Generalized Pareto Distribution. D Scott, Grimshaw, http:/arxiv.org/abs/http:/amstat.tandfonline.com/doi/pdf/10.1080/00401706.1993.10485040Technometrics. 35Scott D. Grimshaw. 1993. Computing Maximum Likelihood Esti- mates for the Generalized Pareto Distribution. Technometrics 35, 2 (1993), 185-191. https://doi.org/10.1080/00401706.1993.10485040 arXiv:http://amstat.tandfonline.com/doi/pdf/10.1080/00401706.1993.10485040\n\nA simple general approach to inference about the tail of a distribution. M Bruce, Hill, The annals of statistics. 3Bruce M Hill. 1975. A simple general approach to inference about the tail of a distribution. The annals of statistics 3, 5 (1975), 1163-1174.\n\nClassifier ensembles for detecting concept change in streaming data: Overview and perspectives. I Ludmila, Kuncheva, 2nd Workshop SUEMA. Ludmila I Kuncheva. 2008. Classifier ensembles for detecting concept change in streaming data: Overview and perspectives. In 2nd Workshop SUEMA.\n\nOnline learning and sequential anomaly detection in trajectories. Rikard Laxhammar, G\u00f6ran Falkman, 36Rikard Laxhammar and G\u00f6ran Falkman. 2014. Online learning and sequential anomaly detection in trajectories. IEEE transactions on pattern analysis and machine intelligence 36, 6 (2014), 1158-1173.\n\nA taxonomy of anomalies in backbone network traffic. Johan Mazel, Romain Fontugne, Kensuke Fukuda, IWCMC. Johan Mazel, Romain Fontugne, and Kensuke Fukuda. 2014. A taxonomy of anomalies in backbone network traffic. In IWCMC.\n\nThe application of data mining techniques in financial fraud detection: A classification framework and an academic review of literature. Yong Ewt Ngai, Y H Hu, Yijun Wong, Xin Chen, Sun, Decision Support Systems. 50EWT Ngai, Yong Hu, YH Wong, Yijun Chen, and Xin Sun. 2011. The application of data mining techniques in financial fraud detection: A classification framework and an academic review of literature. Decision Support Systems 50, 3 (2011), 559-569.\n\nStatistical inference using extreme order statistics. the Annals of Statistics. James Pickands, Iii , James Pickands III. 1975. Statistical inference using extreme order statistics. the Annals of Statistics (1975).\n\nDBOD-DS: Distance based outlier detection for data streams. Shiblee Md, Le Sadik, Gruenwald, International Conference on Database and Expert Systems Applications. SpringerMd Shiblee Sadik and Le Gruenwald. 2010. DBOD-DS: Distance based outlier detection for data streams. In International Conference on Database and Expert Systems Applications. Springer, 122-136.\n\nResearch issues in outlier detection for data streams. Shiblee Sadik, Le Gruenwald, ACM SIGKDD Explorations Newsletter. 15Shiblee Sadik and Le Gruenwald. 2014. Research issues in outlier detection for data streams. ACM SIGKDD Explorations Newsletter 15, 1 (2014), 33-40.\n\nUsing intelligent data analysis to detect abnormal energy consumption in buildings. E John, Seem, Energy and buildings. 39John E Seem. 2007. Using intelligent data analysis to detect abnormal energy consumption in buildings. Energy and buildings 39, 1 (2007), 52-58.\n\nA framework for outlier detection in evolving data streams by weighting attributes in clustering. Durga Toshniwal, Procedia Technology. 6Durga Toshniwal. 2012. A framework for outlier detection in evolving data streams by weighting attributes in clustering. Procedia Technology 6 (2012), 214-222.\n\nDetecting SYN flooding attacks. Haining Wang, Danlu Zhang, Kang G Shin, INFOCOM. Haining Wang, Danlu Zhang, and Kang G Shin. 2002. Detecting SYN flooding attacks. In INFOCOM.\n", "annotations": {"author": "[{\"end\":113,\"start\":58},{\"end\":183,\"start\":114},{\"end\":256,\"start\":184},{\"end\":317,\"start\":257}]", "publisher": null, "author_last_name": "[{\"end\":70,\"start\":64},{\"end\":133,\"start\":127},{\"end\":201,\"start\":194},{\"end\":275,\"start\":267}]", "author_first_name": "[{\"end\":63,\"start\":58},{\"end\":126,\"start\":114},{\"end\":193,\"start\":184},{\"end\":266,\"start\":257}]", "author_affiliation": "[{\"end\":112,\"start\":94},{\"end\":182,\"start\":164},{\"end\":255,\"start\":230},{\"end\":316,\"start\":305}]", "title": "[{\"end\":55,\"start\":1},{\"end\":372,\"start\":318}]", "venue": null, "abstract": "[{\"end\":1509,\"start\":613}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b26\"},\"end\":1919,\"start\":1915},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":1940,\"start\":1936},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1956,\"start\":1952},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2137,\"start\":2133},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3427,\"start\":3423},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":4005,\"start\":4001},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5439,\"start\":5435},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5728,\"start\":5725},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5756,\"start\":5752},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5781,\"start\":5777},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5816,\"start\":5812},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":5851,\"start\":5847},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6013,\"start\":6009},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6016,\"start\":6013},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6348,\"start\":6345},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6359,\"start\":6355},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6373,\"start\":6369},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":6400,\"start\":6396},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6723,\"start\":6720},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6875,\"start\":6871},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7072,\"start\":7068},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7958,\"start\":7954},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9559,\"start\":9555},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9583,\"start\":9579},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12121,\"start\":12117},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":12149,\"start\":12145},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":12555,\"start\":12552},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":12558,\"start\":12555},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15047,\"start\":15043},{\"end\":20836,\"start\":20834},{\"end\":20874,\"start\":20872},{\"end\":20900,\"start\":20898},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":22696,\"start\":22694},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22791,\"start\":22789},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":25466,\"start\":25462},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":26560,\"start\":26556},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":27799,\"start\":27795},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":30395,\"start\":30391},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":30475,\"start\":30471},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":31123,\"start\":31119},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":32602,\"start\":32599},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":32827,\"start\":32824},{\"end\":33992,\"start\":33989},{\"end\":34282,\"start\":34279}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":37888,\"start\":37840},{\"attributes\":{\"id\":\"fig_1\"},\"end\":37934,\"start\":37889},{\"attributes\":{\"id\":\"fig_2\"},\"end\":38054,\"start\":37935},{\"attributes\":{\"id\":\"fig_3\"},\"end\":38207,\"start\":38055},{\"attributes\":{\"id\":\"fig_4\"},\"end\":38242,\"start\":38208},{\"attributes\":{\"id\":\"fig_5\"},\"end\":38294,\"start\":38243},{\"attributes\":{\"id\":\"fig_6\"},\"end\":38382,\"start\":38295},{\"attributes\":{\"id\":\"fig_7\"},\"end\":38685,\"start\":38383},{\"attributes\":{\"id\":\"fig_8\"},\"end\":38733,\"start\":38686},{\"attributes\":{\"id\":\"fig_9\"},\"end\":38780,\"start\":38734},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":38817,\"start\":38781},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":38879,\"start\":38818}]", "paragraph": "[{\"end\":1777,\"start\":1511},{\"end\":2138,\"start\":1779},{\"end\":2275,\"start\":2140},{\"end\":2555,\"start\":2277},{\"end\":3178,\"start\":2557},{\"end\":3660,\"start\":3180},{\"end\":4811,\"start\":3662},{\"end\":5188,\"start\":4813},{\"end\":5599,\"start\":5205},{\"end\":6004,\"start\":5601},{\"end\":6236,\"start\":6006},{\"end\":6570,\"start\":6238},{\"end\":7394,\"start\":6572},{\"end\":7587,\"start\":7396},{\"end\":7699,\"start\":7589},{\"end\":8115,\"start\":7714},{\"end\":8852,\"start\":8117},{\"end\":9310,\"start\":8854},{\"end\":10006,\"start\":9342},{\"end\":11210,\"start\":10061},{\"end\":11251,\"start\":11212},{\"end\":12327,\"start\":11399},{\"end\":12425,\"start\":12329},{\"end\":12675,\"start\":12465},{\"end\":12926,\"start\":12879},{\"end\":13342,\"start\":12988},{\"end\":13456,\"start\":13344},{\"end\":13928,\"start\":13489},{\"end\":14278,\"start\":13962},{\"end\":14678,\"start\":14324},{\"end\":15060,\"start\":14903},{\"end\":15371,\"start\":15062},{\"end\":15864,\"start\":15464},{\"end\":16297,\"start\":15960},{\"end\":16461,\"start\":16299},{\"end\":16573,\"start\":16504},{\"end\":16824,\"start\":16605},{\"end\":17570,\"start\":16845},{\"end\":18445,\"start\":17594},{\"end\":18525,\"start\":18447},{\"end\":18700,\"start\":18669},{\"end\":18830,\"start\":18734},{\"end\":18926,\"start\":18832},{\"end\":19285,\"start\":18928},{\"end\":19740,\"start\":19287},{\"end\":20525,\"start\":19742},{\"end\":20798,\"start\":20527},{\"end\":20883,\"start\":20805},{\"end\":20936,\"start\":20885},{\"end\":20999,\"start\":20959},{\"end\":21210,\"start\":21037},{\"end\":21618,\"start\":21305},{\"end\":22329,\"start\":21620},{\"end\":22539,\"start\":22528},{\"end\":22596,\"start\":22587},{\"end\":22618,\"start\":22598},{\"end\":22697,\"start\":22659},{\"end\":22792,\"start\":22749},{\"end\":22875,\"start\":22832},{\"end\":23420,\"start\":22953},{\"end\":23715,\"start\":23422},{\"end\":24191,\"start\":23742},{\"end\":24452,\"start\":24193},{\"end\":24591,\"start\":24454},{\"end\":24925,\"start\":24850},{\"end\":25124,\"start\":25089},{\"end\":25199,\"start\":25156},{\"end\":25457,\"start\":25248},{\"end\":25706,\"start\":25459},{\"end\":25813,\"start\":25708},{\"end\":26020,\"start\":25907},{\"end\":26330,\"start\":26022},{\"end\":26447,\"start\":26332},{\"end\":26880,\"start\":26485},{\"end\":27098,\"start\":26882},{\"end\":27754,\"start\":27121},{\"end\":27897,\"start\":27756},{\"end\":28230,\"start\":27913},{\"end\":28509,\"start\":28232},{\"end\":28804,\"start\":28533},{\"end\":29162,\"start\":28806},{\"end\":29559,\"start\":29197},{\"end\":30217,\"start\":29561},{\"end\":30881,\"start\":30219},{\"end\":31851,\"start\":30883},{\"end\":32140,\"start\":31861},{\"end\":32362,\"start\":32142},{\"end\":32755,\"start\":32395},{\"end\":33106,\"start\":32757},{\"end\":33729,\"start\":33108},{\"end\":34150,\"start\":33747},{\"end\":34540,\"start\":34152},{\"end\":34714,\"start\":34542},{\"end\":35186,\"start\":34731},{\"end\":35489,\"start\":35188},{\"end\":35859,\"start\":35491},{\"end\":36520,\"start\":35861},{\"end\":36671,\"start\":36531},{\"end\":37180,\"start\":36686},{\"end\":37386,\"start\":37182},{\"end\":37839,\"start\":37388}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10060,\"start\":10007},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11383,\"start\":11252},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12878,\"start\":12676},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12987,\"start\":12927},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13488,\"start\":13457},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14323,\"start\":14279},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14902,\"start\":14679},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15457,\"start\":15372},{\"attributes\":{\"id\":\"formula_8\"},\"end\":15959,\"start\":15865},{\"attributes\":{\"id\":\"formula_9\"},\"end\":16503,\"start\":16462},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16604,\"start\":16574},{\"attributes\":{\"id\":\"formula_11\"},\"end\":18668,\"start\":18526},{\"attributes\":{\"id\":\"formula_12\"},\"end\":20958,\"start\":20937},{\"attributes\":{\"id\":\"formula_13\"},\"end\":21036,\"start\":21000},{\"attributes\":{\"id\":\"formula_14\"},\"end\":21287,\"start\":21211},{\"attributes\":{\"id\":\"formula_15\"},\"end\":22426,\"start\":22330},{\"attributes\":{\"id\":\"formula_16\"},\"end\":22460,\"start\":22426},{\"attributes\":{\"id\":\"formula_17\"},\"end\":22527,\"start\":22460},{\"attributes\":{\"id\":\"formula_18\"},\"end\":22586,\"start\":22540},{\"attributes\":{\"id\":\"formula_19\"},\"end\":22658,\"start\":22619},{\"attributes\":{\"id\":\"formula_20\"},\"end\":22748,\"start\":22698},{\"attributes\":{\"id\":\"formula_21\"},\"end\":22831,\"start\":22793},{\"attributes\":{\"id\":\"formula_22\"},\"end\":22952,\"start\":22876},{\"attributes\":{\"id\":\"formula_23\"},\"end\":24849,\"start\":24592},{\"attributes\":{\"id\":\"formula_24\"},\"end\":25088,\"start\":24926},{\"attributes\":{\"id\":\"formula_25\"},\"end\":25155,\"start\":25125},{\"attributes\":{\"id\":\"formula_26\"},\"end\":25906,\"start\":25814},{\"attributes\":{\"id\":\"formula_27\"},\"end\":26484,\"start\":26448},{\"attributes\":{\"id\":\"formula_28\"},\"end\":29196,\"start\":29163}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"2\"},\"end\":5203,\"start\":5191},{\"attributes\":{\"n\":\"3\"},\"end\":7712,\"start\":7702},{\"attributes\":{\"n\":\"3.1\"},\"end\":9340,\"start\":9313},{\"attributes\":{\"n\":\"3.2\"},\"end\":11397,\"start\":11385},{\"attributes\":{\"n\":\"3.3\"},\"end\":12463,\"start\":12428},{\"attributes\":{\"n\":\"3.4\"},\"end\":13960,\"start\":13931},{\"attributes\":{\"n\":\"3.4.2\"},\"end\":15462,\"start\":15459},{\"attributes\":{\"n\":\"4\"},\"end\":16843,\"start\":16827},{\"attributes\":{\"n\":\"4.1\"},\"end\":17592,\"start\":17573},{\"attributes\":{\"n\":\"4.2\"},\"end\":18732,\"start\":18703},{\"end\":20803,\"start\":20801},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":21303,\"start\":21289},{\"attributes\":{\"n\":\"4.3\"},\"end\":23740,\"start\":23718},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":25246,\"start\":25202},{\"attributes\":{\"n\":\"4.3.3\"},\"end\":27119,\"start\":27101},{\"attributes\":{\"n\":\"5\"},\"end\":27911,\"start\":27900},{\"attributes\":{\"n\":\"5.1\"},\"end\":28531,\"start\":28512},{\"end\":31859,\"start\":31854},{\"attributes\":{\"n\":\"5.3\"},\"end\":32393,\"start\":32365},{\"attributes\":{\"n\":\"5.3.2\"},\"end\":33745,\"start\":33732},{\"attributes\":{\"n\":\"5.4\"},\"end\":34729,\"start\":34717},{\"end\":36529,\"start\":36523},{\"attributes\":{\"n\":\"6\"},\"end\":36684,\"start\":36674},{\"end\":37851,\"start\":37841},{\"end\":37906,\"start\":37890},{\"end\":37946,\"start\":37936},{\"end\":38066,\"start\":38056},{\"end\":38254,\"start\":38244},{\"end\":38306,\"start\":38296},{\"end\":38697,\"start\":38687},{\"end\":38745,\"start\":38735},{\"end\":38791,\"start\":38782},{\"end\":38828,\"start\":38819}]", "table": null, "figure_caption": "[{\"end\":37888,\"start\":37853},{\"end\":37934,\"start\":37909},{\"end\":38054,\"start\":37948},{\"end\":38207,\"start\":38068},{\"end\":38242,\"start\":38210},{\"end\":38294,\"start\":38256},{\"end\":38382,\"start\":38308},{\"end\":38685,\"start\":38385},{\"end\":38733,\"start\":38699},{\"end\":38780,\"start\":38747},{\"end\":38817,\"start\":38793},{\"end\":38879,\"start\":38830}]", "figure_ref": "[{\"end\":17794,\"start\":17786},{\"end\":20134,\"start\":20126},{\"end\":21064,\"start\":21056},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21832,\"start\":21824},{\"end\":21904,\"start\":21882},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":29051,\"start\":29020},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":29304,\"start\":29296},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":31377,\"start\":31369},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":32157,\"start\":32149},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":32938,\"start\":32930},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":34553,\"start\":34545}]", "bib_author_first_name": "[{\"end\":39239,\"start\":39233},{\"end\":39432,\"start\":39424},{\"end\":39450,\"start\":39443},{\"end\":39463,\"start\":39458},{\"end\":39761,\"start\":39753},{\"end\":39777,\"start\":39772},{\"end\":40216,\"start\":40215},{\"end\":40232,\"start\":40225},{\"end\":40415,\"start\":40412},{\"end\":40430,\"start\":40426},{\"end\":40447,\"start\":40442},{\"end\":40461,\"start\":40456},{\"end\":40674,\"start\":40673},{\"end\":40693,\"start\":40683},{\"end\":40710,\"start\":40703},{\"end\":40712,\"start\":40711},{\"end\":40726,\"start\":40722},{\"end\":40994,\"start\":40993},{\"end\":41012,\"start\":41004},{\"end\":41024,\"start\":41019},{\"end\":41034,\"start\":41029},{\"end\":41285,\"start\":41280},{\"end\":41303,\"start\":41296},{\"end\":41319,\"start\":41314},{\"end\":41504,\"start\":41500},{\"end\":41515,\"start\":41511},{\"end\":41524,\"start\":41520},{\"end\":41788,\"start\":41781},{\"end\":41799,\"start\":41796},{\"end\":41809,\"start\":41804},{\"end\":41823,\"start\":41817},{\"end\":41834,\"start\":41828},{\"end\":42277,\"start\":42268},{\"end\":42297,\"start\":42289},{\"end\":42532,\"start\":42526},{\"end\":42560,\"start\":42541},{\"end\":42976,\"start\":42970},{\"end\":42993,\"start\":42987},{\"end\":43010,\"start\":43003},{\"end\":43024,\"start\":43017},{\"end\":43320,\"start\":43315},{\"end\":43564,\"start\":43563},{\"end\":44027,\"start\":44026},{\"end\":44308,\"start\":44307},{\"end\":44566,\"start\":44560},{\"end\":44583,\"start\":44578},{\"end\":44850,\"start\":44845},{\"end\":44864,\"start\":44858},{\"end\":44882,\"start\":44875},{\"end\":45159,\"start\":45155},{\"end\":45171,\"start\":45170},{\"end\":45173,\"start\":45172},{\"end\":45183,\"start\":45178},{\"end\":45193,\"start\":45190},{\"end\":45563,\"start\":45558},{\"end\":45577,\"start\":45574},{\"end\":45761,\"start\":45754},{\"end\":45768,\"start\":45766},{\"end\":46121,\"start\":46114},{\"end\":46131,\"start\":46129},{\"end\":46416,\"start\":46415},{\"end\":46702,\"start\":46697},{\"end\":46936,\"start\":46929},{\"end\":46948,\"start\":46943},{\"end\":46962,\"start\":46956}]", "bib_author_last_name": "[{\"end\":39247,\"start\":39240},{\"end\":39441,\"start\":39433},{\"end\":39456,\"start\":39451},{\"end\":39471,\"start\":39464},{\"end\":39770,\"start\":39762},{\"end\":39786,\"start\":39778},{\"end\":40223,\"start\":40217},{\"end\":40240,\"start\":40233},{\"end\":40249,\"start\":40242},{\"end\":40424,\"start\":40416},{\"end\":40440,\"start\":40431},{\"end\":40454,\"start\":40448},{\"end\":40469,\"start\":40462},{\"end\":40681,\"start\":40675},{\"end\":40701,\"start\":40694},{\"end\":40720,\"start\":40713},{\"end\":40729,\"start\":40727},{\"end\":40737,\"start\":40731},{\"end\":41002,\"start\":40995},{\"end\":41017,\"start\":41013},{\"end\":41027,\"start\":41025},{\"end\":41042,\"start\":41035},{\"end\":41047,\"start\":41044},{\"end\":41294,\"start\":41286},{\"end\":41312,\"start\":41304},{\"end\":41325,\"start\":41320},{\"end\":41509,\"start\":41505},{\"end\":41518,\"start\":41516},{\"end\":41528,\"start\":41525},{\"end\":41794,\"start\":41789},{\"end\":41802,\"start\":41800},{\"end\":41815,\"start\":41810},{\"end\":41826,\"start\":41824},{\"end\":41839,\"start\":41835},{\"end\":42099,\"start\":42086},{\"end\":42287,\"start\":42278},{\"end\":42307,\"start\":42298},{\"end\":42539,\"start\":42533},{\"end\":42567,\"start\":42561},{\"end\":42576,\"start\":42569},{\"end\":42985,\"start\":42977},{\"end\":43001,\"start\":42994},{\"end\":43015,\"start\":43011},{\"end\":43031,\"start\":43025},{\"end\":43329,\"start\":43321},{\"end\":43570,\"start\":43565},{\"end\":43580,\"start\":43572},{\"end\":44033,\"start\":44028},{\"end\":44039,\"start\":44035},{\"end\":44316,\"start\":44309},{\"end\":44326,\"start\":44318},{\"end\":44576,\"start\":44567},{\"end\":44591,\"start\":44584},{\"end\":44856,\"start\":44851},{\"end\":44873,\"start\":44865},{\"end\":44889,\"start\":44883},{\"end\":45168,\"start\":45160},{\"end\":45176,\"start\":45174},{\"end\":45188,\"start\":45184},{\"end\":45198,\"start\":45194},{\"end\":45203,\"start\":45200},{\"end\":45572,\"start\":45564},{\"end\":45764,\"start\":45762},{\"end\":45774,\"start\":45769},{\"end\":45785,\"start\":45776},{\"end\":46127,\"start\":46122},{\"end\":46141,\"start\":46132},{\"end\":46421,\"start\":46417},{\"end\":46427,\"start\":46423},{\"end\":46712,\"start\":46703},{\"end\":46941,\"start\":46937},{\"end\":46954,\"start\":46949},{\"end\":46967,\"start\":46963}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":39013,\"start\":38881},{\"attributes\":{\"id\":\"b1\"},\"end\":39147,\"start\":39015},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":10094374},\"end\":39369,\"start\":39149},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":18595771},\"end\":39697,\"start\":39371},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":3244414},\"end\":40153,\"start\":39699},{\"attributes\":{\"id\":\"b5\"},\"end\":40361,\"start\":40155},{\"attributes\":{\"id\":\"b6\"},\"end\":40624,\"start\":40363},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":6787631},\"end\":40928,\"start\":40626},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":6398414},\"end\":41249,\"start\":40930},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":207172599},\"end\":41465,\"start\":41251},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":7042250},\"end\":41699,\"start\":41467},{\"attributes\":{\"doi\":\"FSKD'08\",\"id\":\"b11\"},\"end\":42009,\"start\":41701},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":38939287},\"end\":42211,\"start\":42011},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":15657892},\"end\":42432,\"start\":42213},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":123125823},\"end\":42862,\"start\":42434},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":7798047},\"end\":43246,\"start\":42864},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":123965626},\"end\":43481,\"start\":43248},{\"attributes\":{\"doi\":\"http:/arxiv.org/abs/http:/amstat.tandfonline.com/doi/pdf/10.1080/00401706.1993.10485040\",\"id\":\"b17\",\"matched_paper_id\":73555634},\"end\":43951,\"start\":43483},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":121963978},\"end\":44209,\"start\":43953},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":53605988},\"end\":44492,\"start\":44211},{\"attributes\":{\"id\":\"b20\"},\"end\":44790,\"start\":44494},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":3154024},\"end\":45016,\"start\":44792},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":27434345},\"end\":45476,\"start\":45018},{\"attributes\":{\"id\":\"b23\"},\"end\":45692,\"start\":45478},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":16435278},\"end\":46057,\"start\":45694},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":17203933},\"end\":46329,\"start\":46059},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":111043123},\"end\":46597,\"start\":46331},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":62609960},\"end\":46895,\"start\":46599},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":11960636},\"end\":47071,\"start\":46897}]", "bib_title": "[{\"end\":39231,\"start\":39149},{\"end\":39422,\"start\":39371},{\"end\":39751,\"start\":39699},{\"end\":40671,\"start\":40626},{\"end\":40991,\"start\":40930},{\"end\":41278,\"start\":41251},{\"end\":41498,\"start\":41467},{\"end\":42084,\"start\":42011},{\"end\":42266,\"start\":42213},{\"end\":42524,\"start\":42434},{\"end\":42968,\"start\":42864},{\"end\":43313,\"start\":43248},{\"end\":43561,\"start\":43483},{\"end\":44024,\"start\":43953},{\"end\":44305,\"start\":44211},{\"end\":44843,\"start\":44792},{\"end\":45153,\"start\":45018},{\"end\":45752,\"start\":45694},{\"end\":46112,\"start\":46059},{\"end\":46413,\"start\":46331},{\"end\":46695,\"start\":46599},{\"end\":46927,\"start\":46897}]", "bib_author": "[{\"end\":39249,\"start\":39233},{\"end\":39443,\"start\":39424},{\"end\":39458,\"start\":39443},{\"end\":39473,\"start\":39458},{\"end\":39772,\"start\":39753},{\"end\":39788,\"start\":39772},{\"end\":40225,\"start\":40215},{\"end\":40242,\"start\":40225},{\"end\":40251,\"start\":40242},{\"end\":40426,\"start\":40412},{\"end\":40442,\"start\":40426},{\"end\":40456,\"start\":40442},{\"end\":40471,\"start\":40456},{\"end\":40683,\"start\":40673},{\"end\":40703,\"start\":40683},{\"end\":40722,\"start\":40703},{\"end\":40731,\"start\":40722},{\"end\":40739,\"start\":40731},{\"end\":41004,\"start\":40993},{\"end\":41019,\"start\":41004},{\"end\":41029,\"start\":41019},{\"end\":41044,\"start\":41029},{\"end\":41049,\"start\":41044},{\"end\":41296,\"start\":41280},{\"end\":41314,\"start\":41296},{\"end\":41327,\"start\":41314},{\"end\":41511,\"start\":41500},{\"end\":41520,\"start\":41511},{\"end\":41530,\"start\":41520},{\"end\":41796,\"start\":41781},{\"end\":41804,\"start\":41796},{\"end\":41817,\"start\":41804},{\"end\":41828,\"start\":41817},{\"end\":41841,\"start\":41828},{\"end\":42101,\"start\":42086},{\"end\":42289,\"start\":42268},{\"end\":42309,\"start\":42289},{\"end\":42541,\"start\":42526},{\"end\":42569,\"start\":42541},{\"end\":42578,\"start\":42569},{\"end\":42987,\"start\":42970},{\"end\":43003,\"start\":42987},{\"end\":43017,\"start\":43003},{\"end\":43033,\"start\":43017},{\"end\":43331,\"start\":43315},{\"end\":43572,\"start\":43563},{\"end\":43582,\"start\":43572},{\"end\":44035,\"start\":44026},{\"end\":44041,\"start\":44035},{\"end\":44318,\"start\":44307},{\"end\":44328,\"start\":44318},{\"end\":44578,\"start\":44560},{\"end\":44593,\"start\":44578},{\"end\":44858,\"start\":44845},{\"end\":44875,\"start\":44858},{\"end\":44891,\"start\":44875},{\"end\":45170,\"start\":45155},{\"end\":45178,\"start\":45170},{\"end\":45190,\"start\":45178},{\"end\":45200,\"start\":45190},{\"end\":45205,\"start\":45200},{\"end\":45574,\"start\":45558},{\"end\":45580,\"start\":45574},{\"end\":45766,\"start\":45754},{\"end\":45776,\"start\":45766},{\"end\":45787,\"start\":45776},{\"end\":46129,\"start\":46114},{\"end\":46143,\"start\":46129},{\"end\":46423,\"start\":46415},{\"end\":46429,\"start\":46423},{\"end\":46714,\"start\":46697},{\"end\":46943,\"start\":46929},{\"end\":46956,\"start\":46943},{\"end\":46969,\"start\":46956}]", "bib_venue": "[{\"end\":38907,\"start\":38881},{\"end\":39054,\"start\":39015},{\"end\":39253,\"start\":39249},{\"end\":39524,\"start\":39473},{\"end\":39880,\"start\":39788},{\"end\":40213,\"start\":40155},{\"end\":40410,\"start\":40363},{\"end\":40756,\"start\":40739},{\"end\":41080,\"start\":41049},{\"end\":41348,\"start\":41327},{\"end\":41559,\"start\":41530},{\"end\":41779,\"start\":41701},{\"end\":42105,\"start\":42101},{\"end\":42315,\"start\":42309},{\"end\":42641,\"start\":42578},{\"end\":43047,\"start\":43033},{\"end\":43352,\"start\":43331},{\"end\":43682,\"start\":43669},{\"end\":44065,\"start\":44041},{\"end\":44346,\"start\":44328},{\"end\":44558,\"start\":44494},{\"end\":44896,\"start\":44891},{\"end\":45229,\"start\":45205},{\"end\":45556,\"start\":45478},{\"end\":45855,\"start\":45787},{\"end\":46177,\"start\":46143},{\"end\":46449,\"start\":46429},{\"end\":46733,\"start\":46714},{\"end\":46976,\"start\":46969},{\"end\":39959,\"start\":39882}]"}}}, "year": 2023, "month": 12, "day": 17}