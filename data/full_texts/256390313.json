{"id": 256390313, "updated": "2023-10-13 12:57:17.993", "metadata": {"title": "Pushing the Limits of Fewshot Anomaly Detection in Industry Vision: Graphcore", "authors": "[{\"first\":\"Guoyang\",\"last\":\"Xie\",\"middle\":[]},{\"first\":\"Jinbao\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Jiaqi\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Feng\",\"last\":\"Zheng\",\"middle\":[]},{\"first\":\"Yaochu\",\"last\":\"Jin\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "In the area of fewshot anomaly detection (FSAD), efficient visual feature plays an essential role in memory bank M-based methods. However, these methods do not account for the relationship between the visual feature and its rotated visual feature, drastically limiting the anomaly detection performance. To push the limits, we reveal that rotation-invariant feature property has a significant impact in industrial-based FSAD. Specifically, we utilize graph representation in FSAD and provide a novel visual isometric invariant feature (VIIF) as anomaly measurement feature. As a result, VIIF can robustly improve the anomaly discriminating ability and can further reduce the size of redundant features stored in M by a large amount. Besides, we provide a novel model GraphCore via VIIFs that can fast implement unsupervised FSAD training and can improve the performance of anomaly detection. A comprehensive evaluation is provided for comparing GraphCore and other SOTA anomaly detection models under our proposed fewshot anomaly detection setting, which shows GraphCore can increase average AUC by 5.8%, 4.1%, 3.4%, and 1.6% on MVTec AD and by 25.5%, 22.0%, 16.9%, and 14.1% on MPDD for 1, 2, 4, and 8-shot cases, respectively.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2301.12082", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iclr/XieWLJZ23", "doi": "10.48550/arxiv.2301.12082"}}, "content": {"source": {"pdf_hash": "8e37b3b30a1fce1a3f41374ceaf168d2e79bf53f", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2301.12082v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "af101089c3b835756b5577c7fffc8645ff48633a", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/8e37b3b30a1fce1a3f41374ceaf168d2e79bf53f.txt", "contents": "\nPUSHING THE LIMITS OF FEW-SHOT ANOMALY DE-TECTION IN INDUSTRY VISION: GRAPHCORE\n12 Oct 2023\n\nGuoyang Xie guoyang.xie@surrey.ac.uk \nResearch Institute of Trustworthy Autonomous Systems\n\n\nSouthern University of Science and Technology\n518055ShenzhenChina\n\nNICE Group\nUniversity of Surrey\nGU2 7YXGuildfordUnited Kingdom\n\nJinbao Wang \nResearch Institute of Trustworthy Autonomous Systems\n\n\nSouthern University of Science and Technology\n518055ShenzhenChina\n\nJiaqi Liu \nResearch Institute of Trustworthy Autonomous Systems\n\n\nSouthern University of Science and Technology\n518055ShenzhenChina\n\nFeng Zheng zhengf@sustech.edu.cn \nResearch Institute of Trustworthy Autonomous Systems\n\n\nSouthern University of Science and Technology\n518055ShenzhenChina\n\nYaochu Jin yaochu.jin@uni-bielefeld.de \nNICE Group\nUniversity of Surrey\nGU2 7YXGuildfordUnited Kingdom\n\nNICE Group\nBielefeld University\n33619BielefeldGermany\n\nPUSHING THE LIMITS OF FEW-SHOT ANOMALY DE-TECTION IN INDUSTRY VISION: GRAPHCORE\n12 Oct 2023933AB61829E4E2285BFEF4B41221199DarXiv:2301.12082v3[cs.CV]\nIn the area of few-shot anomaly detection (FSAD), efficient visual feature plays an essential role in the memory bank M-based methods.However, these methods do not account for the relationship between the visual feature and its rotated visual feature, drastically limiting the anomaly detection performance.To push the limits, we reveal that rotation-invariant feature property has a significant impact on industrial-based FSAD.Specifically, we utilize graph representation in FSAD and provide a novel visual isometric invariant feature (VIIF) as an anomaly measurement feature.As a result, VIIF can robustly improve the anomaly discriminating ability and can further reduce the size of redundant features stored in M by a large amount.Besides, we provide a novel model GraphCore via VIIFs that can fast implement unsupervised FSAD training and improve the performance of anomaly detection.A comprehensive evaluation is provided for comparing GraphCore and other SOTA anomaly detection models under our proposed few-shot anomaly detection setting, which shows GraphCore can increase average AUC by 5.8%, 4.1%, 3.4%, and 1.6% on MVTec AD and by 25.5%, 22.0%, 16.9%, and 14.1% on MPDD for 1, 2, 4, and 8-shot cases, respectively.\n\nINTRODUCTION\n\nWith the rapid development of deep vision detection technology in artificial intelligence, detecting anomalies/defects on the surface of industrial products has received unprecedented attention.Changeover in manufacturing refers to converting a line or machine from processing one product to another.Since the equipment has not been completely fine-tuned after the start of the production line, changeover frequently results in unsatisfactory anomaly detection (AD) performance.\n\nHow to achieve rapid training of industrial product models in the changeover scenario while assuring accurate anomaly detection is a critical issue in the actual production process.The current state of AD in the industry is as follows: (1) In terms of detection accuracy, the performance of state-ofthe-art (SOTA) AD models degrades dramatically during the changeover.Current mainstream work utilizes a considerable amount of training data as input to train the model, as shown in Fig. 1(a).However, this will make data collecting challenging, even for unsupervised learning.As a result, many approaches based on few-shot learning at the price of accuracy have been proposed.For instance, Huang et al. (2022) employ meta-learning, as shown in Fig. 1(b).While due to complicated settings, it is impossible to migrate to the new product during the changeover flexibly, and the detection accuracy cannot be guaranteed.(2) In terms of training speed, when a large amount of data is utilized for training, the training progress for new goods is slowed in the actual production line.As is well-known, vanilla unsupervised AD requires to collect a large amount of information.Even though meta-learning works in few-shot learning, as shown in Fig. 1(b), it is still necessary to train a massive portion of previously collected data.For our setting (c), there is no requirement to aggregate training categories in advance.The proposed model, vision isometric invariant GNN, can fast obtain the invariant feature within a few normal samples, and its accuracy outperforms models trained in a meta-learning context.\n\nWe state that AD of industrial products requires just a small quantity of data to achieve performance comparable to a large amount of data, i.e., a small quantity of image data can contain sufficient information to represent a large number of data.Due to the fact that industrial products are manufactured with high stability (no evident distortion of shape and color cast), the taken images lack the diversity of natural images, and there is a problem with the shooting angle or rotation.Therefore, it is essential to extract rotation-invariant structural features.As graph neural networks (GNNs) are capable of robustly extracting non-serialized structural features (Han et al. (2022), Bruna et al. (2013), Hamilton et al. (2017), Xu et al. (2018)), and they integrate global information better and faster Wang et al. (2020); Li et al. (2020).They are more suited than convolution neural networks (CNNs) to handle the problem of extracting rotation-invariant features.For this reason, the core idea of the proposed GraphCore method in this paper is to use the visual isometric invariant features (VIIFs) as the anomaly measurement features.In the method using memory bank (M) as the AD paradigm, PatchCore (Roth et al. (2022)) uses ResNet (He et al. ( 2016)) as the feature extractor.However, since their features obtained by CNNs do not have rotation invariance (Dieleman et al. ( 2016)), a large number of redundant features are stored in M. Note that these redundant features maybe come from multiple rotation features of the same patch structure.It will hence require a huge quantity of training data to ensure the high accuracy of the test set.To avoid these redundant features, we propose VIIFs, which not only produce more robust visual features but also dramatically lower the size of M and accelerate detection.\n\nBased on the previous considerations, the goal of our work is to handle the cold start of the production line during the changeover.As shown in Fig. 1(c), a new FSAD method, called GraphCore, is developed that employs a small number of normal samples to accomplish fast training and competitive AD accuracy performance of the new product.On the one hand, by utilizing a small amount of data, we would rapidly train and accelerate the speed of anomaly inference.On the other hand, because we directly train new product samples, adaptation and migration of anomalies from the old product to the new product do not occur.\n\n\u2022 The experimental results show that the proposed VIIFs are effective and can significantly enhance the FSAD performance on MVTec AD and MPDD.\n\nRelated Work.Few-shot anomaly detection (FSAD) is an attractive research topic.However, there are only a few papers devoted to the industrial image FSAD.Some works (Liznerski et al. (2020); Pang et al. (2021); Ding et al. (2022)) experiment with few-shot abnormal images in the test set, which contradicts our assumptions that no abnormal images existed.While others (Wu et al. (2021); Huang et al. (2022)) conduct experiments in a meta-learning setting.This configuration has the disadvantage of requiring a high number of base class images and being incapable of addressing the shortage of data under cold-start conditions in industrial applications.PatchCore (Roth et al. (2022)), SPADE (Cohen & Hoshen (2020)), and PaDiM (Defard et al. (2021)) investigated AD performance on MVTec AD in a few-shot setting.However, these approaches are not intended for changeover-based few-shot settings.Thus their performance cannot satisfy the requirements of manufacturing changeover.In this research, we propose a feature augmentation method for FSAD that can rapidly finish the training of anomaly detection models with a small quantity of data and meet manufacturing changeover requirements.\n\n\nAPPROACH\n\nProblem Setting.Motivation.In the realistic industrial image dataset (Bergmann et al. (2019); Jezek et al. (2021)), the images under certain categories are extremely similar.Most of them can be converted to one another with simple data augmentation, such as the meta nut (Fig. 2) and the screw (Fig. 6).For instance, rotation augmentation can effectively provide a new screw dataset.Consequently, when faced with the challenges stated in Section 2, our natural inclination is to acquire additional data through data augmentation.Then, the feature memory bank (Fig. 4) can store more useful features.\n\n\nAUGMENTATION+PATCHCORE\n\nTo validate our insight, we have adapted PatchCore (Roth et al. (2022)) to our model.We denote augmentation (rotation) with PatchCore as Aug.(R).The architecture is depicted in detail in Fig. 2. Before extracting features from the ImageNet pre-trained model, we augment the data (e.g., by rotating the data).\ni \u2208 [0, \u2022 \u2022 \u2022 , l \u2212 1] do mi \u2190 arg max m\u2208M\u2212M C min n\u2208M C \u2225\u03c8(m) \u2212 \u03c8(n)\u2225 2 ; MC \u2190 MC \u222a {mi}; end for M \u2190 MC.\nIn the training phase, the aim of the training phase is to build up a memory bank, which stores the neighborhood-aware features from all normal samples.At test time, the test image is predicted as anomalies if at least one patch is anomalous, and pixel-level anomaly segmentation is computed via the score of each patch feature.The feature memory construction method is shown in Algorithm 1.We default set ResNet18 (He et al. ( 2016)) as the feature extraction model.Conceptually, coreset sampling (Sener & Savarese (2018)) for memory bank aims to balance the size of the memory bank with the performance of anomaly detection.And the size of the memory bank has a considerable impact on the inference speed.In Section 3.3, we discuss the effect of the sampling rate in detail.\n\nIn testing phase, with the normal patches feature bank M, the image-level anomaly score s for the test image x test is computed by the maximum score s * between the test image's patch feature P(x test ) and its respective nearest neighbour m * in M.\n\nFrom Table 2 and Table 3, we can easily observe that the performance of Aug.(R) greatly outperforms the SOTA models under the proposed few-shot setting.\n\n\nVISION ISOMETRIC INVARIANT FEATURE\n\nIn Section 2.1, we heuristically demonstrate that Augmentation+PatchCore outperforms SOTA models in the few-shot anomaly detection context proposed.Essentially, the data augmentation method immediately incorporates the features of normal samples into the memory bank.In other words, Augmentation+PatchCore improves the probability of locating a subset feature, allowing the anomaly score of the test image to be calculated with greater precision.Therefore, we question whether it is possible to extract the invariant representational features from a small number of normal samples and add them to the feature memory bank.As demonstrated in Fig. 3, we propose a new model for feature extraction: vision isometric invariant graph neural network (VIIG).The proposed model is motivated by Section 2 and tries to extract the visual isometric invariant feature (VIIF) from each patch of the normal sample.As previously stated, the majority of industrial visual anomaly detection datasets are transformable via rotation, translation, and flipping.Thus, the isomorphism of GNN suited industrial visual anomaly detection excellently.\n\n\nGRAPH REPRESENTATION OF IMAGE\n\nFig. 4 shows the feature extraction process of GraphCore.Specifically, for a normal sample image with a size of H \u00d7W \u00d73, we evenly separate it as an N patch.In addition, each patch is transformed into a feature vector\nf i \u2208 R D . So we have the features F = [f 1 , f 2 , \u2022 \u2022 \u2022 , f N ],\nwhere D is the feature dimension and i = 1, 2, \u2022 \u2022 \u2022 , N .We view these features as unordered nodes\nV = {v 1 , v 2 , \u2022 \u2022 \u2022 , v N }.\nFor certain each node v i , we denote the K nearest neighbours N (v i ) and add an edge e ij directed from v j to v i for all v j \u2208 N (v i ).Hence, each patch of normal samples can be denoted as a graph G = (V, E).E refers all the edges of Graph G.\n\n\nGRAPH FEATURE PROCESSING\n\nFig. 4 shows the architecture of the proposed vision isometric invariant GNN.To be specific, we set the feature extraction as GCN (Kipf & Welling (2017)).We aggregate features for each node by exchanging information with its neighbour nodes.In specific, the feature extraction operates as follows:\nG \u2032 = F (G, W) = U pdate(Aggregate(G, W aggregate ), W update ),(1)\nwhere W aggregate and W update denote the weights of the aggregation and update operations.Both of them can be optimized in an end-to-end manner.Specifically, the aggregation operation for each node is calculated by aggregating neighbouring nodes' features:\nf \u2032 i = h(f i , g(f i , N (f i ), W aggregate ), W update ), (2)\nwhere h is the node feature update function and g is the node feature aggregate feature function.\n\nN (f l i ) denotes the set of neighbor nodes of f l i at the l-th layer.Specifically, we employ max-relative graph convolution (Li et al. (2019)) as our operator.So g and h are defined as:\ng(\u2022) = f \u2032\u2032 i = max({f i \u2212 f j |j \u2208 N (x i )}),(3)h(\u2022) = f \u2032 i = f \u2032\u2032 i W update .(4)\nIn Equations 3 and 4, g(\u2022) is a max-pooling vertex feature aggregator that aggregates the difference in features between node v i and all of its neighbours.h(\u2022) is an MLP layer with batch normalization and ReLU activation.2.5 GRAPHCORE ARCHITECTURE Fig. 5 shows the whole architecture of GraphCore.In the training phase, the most significant difference between GraphCore and Augmentation+PatchCore is the feature memory bank construction algorithm.The feature construction algorithm is the same as Aug.(R) memory bank in Algorithm 1.Note that we use vision isometric invariant GNN as feature extractor P without data augmentation.\n\nIn the testing phase, the computation of anomaly score s * for GraphCore is highly similar to the one in Augmentation+PatchCore.The only difference is the feature extraction method for each normal patch sample.The architecture details of the GraphCore are shown in the reference Table 21.\n\n\nA UNIFIED VIEW OF AUGMENTATION+PATCHCORE AND GRAPHCORE\n\nFig. 6 depicts a unified view of both Augmentation+PatchCore and GraphCore.Augmenta-tion+PatchCore prompts GraphCore to obtain the isometric invariant feature.Therefore, GraphCore can improve the probability of locating a feature subset, allowing the anomaly score of a test image to be calculated most precisely and rapidly.Table 1 shows the difference between PatchCore, Augmentation+PatchCore and GraphCore in terms of architectural details.\n\n\nAccuracy\n\nPixel AUROC @ GraphCore Image AUROC @ GraphCore Pixel AUROC @ Aug.(R) Image AUROC @ Aug.(R) Pixel AUROC @ RegAD Image AUROC @ RegAD (a) MPDD  2022)), using the official source code for comparison under our few-shot setting.PatchCore-1 is the result of our reimplementation with a 1% sampling rate, PatchCore-10 and PatchCore-25 are the results at 10% and 25% sampling rates, respectively, and RegAD-L is the RegAD experiment with our few-shot setting.\n\n\nCOMPARISON WITH THE SOTA METHODS\n\nThe comparative findings between MVTec and MPDD are shown in Table 2. Especially the performance of RegAD under the meta-learning setting is also listed in the table.In comparison to SOTA models, GraphCore improves average AUC by 5.8%, 4.1%, 3.4%, and 1.6% on MVTec and by 25.5%, 22.0%, 16.9%, and 14.1% on MPDD for 1, 2, 4, and 8-shot cases, respectively.From Fig. 7, it can be easily observed that GraphCore significantly outperforms the SOTA approach at the image and pixel level from 1-shot to 8-shot.As can be seen, the performance of GraphCore and Augmentation+PatchCore surpasses the other methods when using only a few samples for training.Considering that RegAD only shows detailed results of various categories above 2-shot, we only show the detailed results of 2-shot in the main text, and the results of 1-shot, 4-shot, and 8-shot are in the appendix.As shown in Table 3, GraphCore outperforms all other baseline methods in 12 out of the 15 categories at the image level and outperforms all other baselines in 11 out of the 15 categories at the pixel level on MVTec AD.Moreover, results in Table 4 show that GraphCore outperforms all other baselines in 5 out of the 6 categories at the image level and outperforms all other baselines in all categories at the pixel level on MPDD.\n\n\nABLATION STUDIES\n\nSampling Rate.When demonstrated in Fig. 8, our technique significantly improves as the sample rate increases from 0.0001 to 0.001, after which the increase in sampling rate has a flattening effect on the performance gain.In other words, as the sampling rate steadily increases, the performance of GraphCore is insensitive to the sampling rate.\n\nNearest Neighbour.In Fig. 8, the green colour represents the performance of GraphCore's 9 nearest neighbour search, and the blue colour represents the performance of GraphCore's 3 nearest neighbour search.As can be seen, increasing the number of neighbours from 3 to 9 greatly increases performance at the pixel level when the sampling rate is low, but does not enhance performance at the image level.As the sampling rate increases, the gain of the number of pixels' neighbours approaches zero.\n\nAugmentation Methods.Fig. 9 demonstrates that the performance of PatchCore on MVTec AD and MPDD is relatively weak, but Aug.(R) demonstrates higher performance.It demonstrates heuristically that our enhancement to feature rotation is significantly effective.Moreover, Graph-Core outperforms Aug.(R) by a large margin, confirming our assumption that GraphCore can extract the isometric invariant feature from industrial-based anomaly detection images.3.4 VISUALIZATION Fig. 10 shows the visualization results obtained by our method on MVTec AD and MPDD with sampling rates of 0.01 and 1 shot, respectively.Each column represents a different item type, and the four rows, from top to bottom, are the detection image, anomaly score map, anomaly map on detection image, and ground truth.According to the results, our method can produce a satisfactory impact of anomaly localization on various objects, indicating that it has a strong generalized ability even in the 1-shot case.\n\n\nCONCLUSION\n\nIn this study, we introduce a new approach, GraphCore, for industrial-based few-shot visual anomaly detection.Initially, by investigating the CNN-generated feature space, we present a simple pipeline -Augmentation+PatchCore -for obtaining rotation-invariant features.It turns out that this simple baseline can significantly improve anomaly detection performance.We further propose GraphCore to capture the isometric invariant features of normal industrial samples.It outperforms the SOTA models by a large margin using only a few normal samples (\u2264 8) for training.The majority of industrial datasets for anomaly detection possess isomorphism, which is a property ideally suited to GraphCore.We will continue to push the limits of industrial-based few-shot anomaly detection in the future.\n\n\nAPPENDIX\n\n\nDATASET\n\nMVTec AD is the most popular dataset for industrial image anomaly detection (Bergmann et al. (2019)), which consists of 15 categories of items, including a total of 3629 normal images as a training set, and a collection of 1725 normal images and abnormal images as a test set.All images have a resolution between 700\u00d7700 and 1024\u00d71024 pixels.\n\nMPDD is a more challenging AD dataset containing 6 classes of metal parts (Jezek et al. (2021)).\n\nThe images are taken in different spatial directions and distances and under the condition of nonuniform background, so it is more challenging.The statical result of Table 22 and Table 23 clearly demonstrate the effectiveness of GraphCore, especially for memory bank size and its inference speed.\n\nThe statistical results presented in Tables 24 and 25 demonstrate that the rotation method outperforms the other augmentation techniques.We believe this indicates that the majority of industrial anomaly image datasets can be augmented by rotation.In the future, we believe that there will a more complex and realistic industrial anomaly image dataset that cannot be overcome by rotation.\n\nFigure 1 :\n1\nFigure 1: Different from (a) vanilla unsupervised AD and (b) few-shot unsupervised AD in meta learning.As input training samples, our setting (c) only utilizes a small number of normal samples.For our setting (c), there is no requirement to aggregate training categories in advance.The proposed model, vision isometric invariant GNN, can fast obtain the invariant feature within a few normal samples, and its accuracy outperforms models trained in a meta-learning context.\n\n\n\n\nFig. 1(c) outlines the formal definition of the problem setting for the proposed FSAD.Given a training set of only n normal samples during training, where n \u2264 8, from a specific category.At test time, given a normal or abnormal sample from a target category, the anomaly detection model should predict whether or not the image is anomalous and localize the anomaly region if the prediction result is anomalous.Challenges.For the FSAD proposed in Fig. 1(c), we attempt to detect anomalies in the test sample using only a small number of normal images as the training dataset.The key challenges consist of: (1) Each category's training dataset contains only normal samples, i.e., no annotations at the image or pixel level.(2) There are few normal samples of the training set available.In our proposed setting, there are fewer than 8 training samples.\n\n\nFigure 2 :\n2\nFigure 2: Augmentation+PatchCore Architecture.\n\n\nFigure 3 :\n3\nFigure 3: Convolution feature VS vision isometric invariant feature.\n\n\nFigure 4 :\n4\nFigure 4: Vision isometric invariant GNN pipeline.\n\n\nFigure 5 :Figure 6 :\n56\nFigure 5: Vision isometric invariant GNN for FSAD.\n\n\nFigure 7 :\n7\nFigure 7: GraphCore VS Augmentation+PatchCore VS RegAD on various numbers of shot (K).\n\n\nFigure 8 :\n8\nFigure 8: Ablation results on sampling rates and the number of N nearest neighbors.\n\n\nFigure 9 :\n9\nFigure 9: GraphCore vs Augmentation+PatchCore vs PatchCore on various number of shot (K).\n\n\nFigure 10 :\n10\nFigure 10: Visualization results of the proposed method on MVTec AD and MPDD.The first row denotes the training example in the 1-shot setting.The second row is test samples (abnormal).The third row is the heatmap on test samples.The fourth row is the anomaly mask (ground truth).\n\n\n\n\nImageNet pre-trained \u03d5, all normal samples XN , data augmentation operator \u03b1, patch feature extractor P, memory size target l, random linear projection \u03c8.\nAlgorithm 1: Aug.(R) memory bankOutput: Patch-level augmented memory bank M.M \u2190 {};for xi \u2208 XN do x g i \u2190 \u03b1(xi);M \u2190 P(\u03d5(xi)); M \u2190 P(\u03d5(x g i ));end forMC \u2190 {} //Apply coreset sampling for memory bankfor\nInput :\n\n\nTable 1 :\n1\nUnified view for three methods.\nAugmentation NetworkModelNoImageNet Pre-trained Model PatchCoreRotationImageNet Pre-trained Model Aug.(R)NoGNNGraphCore3 EXPERIMENT3.1 EXPERIMENT SETTINGDatasets. To demonstrate the generalization of our proposed method, we conduct experimentson three datasets, namely MVTec AD (Bergmann et al. (2019)), MPDD (Jezek et al. (2021)) andMVTec LOCO AD (Bergmann et al. (2022)).\n(Wang et al. (2021a)0)D(Huang et al. (2022)) is the SOTA FSAD method.It works under a meta-learning setting: aggregated training on multiple categories and adapting to unseen categories, using few-shot unseen images as a support set.However, our proposed few-shot setting utilizes only a few images as a training set and not several categories.Taking into account the fairness of the experiments, we reimplement the classical and SOTA approaches in the field of unsupervised anomaly detection, such as SPADE(Cohen & Hoshen (2020)), STPM(Wang et al. (2021a)), RD4AD(Deng\n\n\nTable 2 :\n2DatesetK Aug.(R) GraphCoreCFASPADEPaDiMSTPMRD4AD PatchCore-1 PatchCore-10 PatchCore-25 RegAD-LRegAD1 87.4|94.589.9|95.678.8|90.7 69.8|79.1 76.1|88.2 69.7|58.2 74.4|69.078.5|90.183.4|92.084.1|92.4-82.4|-MVTec2 90.4|96.391.9|96.981.1|91.0 70.7|79.9 78.9|90.5 74.2|59.8 75.5|71.887.8|94.886.4|93.187.2|93.381.5|-85.7|94.6AD4 92.2|96.092.9|97.485.0|91.3-71.6|80.2 74.8|60.8 76.9|72.289.5|95.0--84.9|-88.2|95.88 95.4|96.495.9|97.890.9|91.6-75.3|80.5 77.6|61.6 78.5|73.094.3|95.6--87.4|-91.2|96.71 83.9|94.784.7|95.258.8|77.7-57.5|73.9 59.2|75.1 58.5|73.259.2|78.5---57.8|-MPDD2 84.6|94.9 4 84.9|95.285.4|95.4 85.7|95.758.6|78.2 59.3|78.7--58.0|75.4 62.4|75.8 61.8|74.5 58.3|75.9 62.6|76.2 62.1|75.559.6|79.2 59.8|79.8----50.8|-54.2|-63.4|93.2 68.8|93.98 85.1|95.586.0|95.960.9|79.0-58.5|76.2 63.1|76.6 62.4|75.760.0|80.3--61.1|-71.9|95.1\nHuang et al. (2022)s for all categories on MVTec AD and MPDD.The sampling ratio is 0.01, x|y represents image AUROC and pixel AUROC.The results for PaDiM, PatchCore-10 and PatchCore-25 are reported fromRoth et al. (2022).The results for RegAD-L and RegAD are reported fromHuang et al. (2022).The best-performing method is in bold.\n\n\nTable 3 :\n3\nHuang et al. (2022)ec AD.The number of shots K is 2, and the sampling ratio is 0.01, x|y represents image AUROC and pixel AUROC.The results for PaDiM, PatchCore-10 and PatchCore-25 are reported fromRoth et al. (2022).The results for RegAD are reported fromHuang et al. (2022).The best-performing method is in bold.\nCategoryAug.(R) GraphCoreCFASPADEPaDiMSTPMRD4AD PatchCore-1 PatchCore-10 PatchCore-25RegADBottle99.7|98.699.8|99.893.7|93.5 95.7|86.8-93.8|84.6 91.2|81.799.7|98.5--99.4|98.0Cable94.7|96.295.2|96.389.3|88.9 60.4|78.6-60.2|51.6 65.3|65.494.9|97.8--65.1|91.7Capsule66.5|97.773.2|97.853.4|85.9 48.7|79.8-45.2|59.2 50.5|78.267.2|97.7--67.5|97.3Carpet99.4|99.199.4|99.697.6|97.9 92.1|95.6-90.8|60.5 92.8|74.299.1|99.0--96.5|98.9Grid75.7|79.881.5|80.680.4|81.4 75.8|75.9-72.6|61.2 75.2|76.361.7|67.5--84.0|77.4Hazelnut99.7|97.999.5|98.299.4|98.2 95.2|88.9-90.3|74.5 93.4|64.893.5|96.4--96.0|98.1Leather100|99.3100|99.4100|99.3 97.9|89.2-95.8|75.2 96.7|86.5100|99.3--99.4|98.0Meta Nut95.0|96.896.3|98.168.6|89.7 61.3|59.5-59.4|51.1 63.4|68.992.0|97.1--91.4|96.9Pill87.8|93.988.6|94.167.4|91.5 60.2|57.2-58.7|49.9 62.8|70.287.4|96.8--81.3|93.6Screw63.6|96.065.7|96.558.2|96.7 51.3|70.2-51.9|51.8 54.3|60.848.3|90.8--52.5|94.4Tile100|99.3100|96.899.8|81.8 90.2|82.3-91.4|58.2 88.9|59.2100|96.0--94.3|94.3Toothbrush 83.6|98.287.3|98.686.9|93.9 80.2|76.8-76.5|66.3 77.1|78.383.9|98.2--86.6|98.2Transistor 96.3|94.197.1|99.272.5|80.3 51.6|73.6-82.4|47.5 78.1|67.896.9|95.0--86.0|93.4Wood97.1|98.497.5|99.598.2|92.4 50.3|89.7-95.8|48.4 93.7|93.897.2|93.0--99.2|93.5Zipper96.9|99.097.5|99.350.5|94.1 49.4|93.7-47.6|56.3 49.5|51.295.3|98.2--86.3|95.1Average90.4|96.391.9|96.981.1|91.0 70.7|79.9 78.9|90.5 74.2|59.8 75.5|71.887.8|94.886.4|93.187.2|93.385.7|94.6\n\nTable 4 :\n4\nHuang et al. (2022)D.The number of shots K is 2, and the sampling ratio is 0.01, x|y represents image AUROC and pixel AUROC.The results for PaDiM, PatchCore-10 and PatchCore-25 are reported fromRoth et al. (2022).The results for RegAD are reported fromHuang et al. (2022).The best-performing method is in bold.\nCategoryAug.(R) GraphCoreCFASPADESTPMRD4AD PatchCoreRegADBracket Black 66.8|92.167.0|92.554.3|75.8 62.4|72.8 94.5|75.1 91.7|75.458.6|78.963.3|-Bracket Brown 76.1|91.977.2|92.666.8|77.5 59.5|71.9 62.3|73.2 58.8|73.470.7|76.959.4|-Bracket White 87.2|97.189.4|97.568.7|70.8 67.2|72.4 53.8|64.2 55.6|62.470.4|68.155.6|-Connector98.6|97.298.9|97.758.5|88.2 59.2|82.8 51.6|83.4 53.7|82.359.2|85.273.0|-Metal Plate99.9|98.499.9|99.162.7|84.3 64.2|75.9 62.4|83.2 65.2|76.564.1|86.361.7|-Tubes79.2|92.679.8|93.140.7|72.8 35.6|76.8 49.6|75.6 45.9|77.134.3|79.567.1|-Average84.6|94.985.4|95.458.6|78.2 58.0|75.4 62.4|75.8 61.8|74.559.6|79.263.4|93.2\n\n\n\nThe training set contains 888 normal images, and the test set contains 176 normal images and 282 abnormal images.The resolution of all images is 1024\u00d71024 pixels.\nMVTEC LOCO AD adds logical abnormal images outside the structural class abnormal image(Bergmann et al. (2022)). The dataset contains 1,772 normal images as a training set, and 304normal images are used as a validation set. The test set contains 575 normal images, 432 structural\nabnormal images, and 561 logic abnormal images.Due to the different calculation methods of logic abnormal detection metric, we abandon the logical abnormal image of the test concentration, retaining the remaining 575 normal images and 432 structural abnormal images as a test set for experiments.Each image is 850 to 1600 pixels in height and 800 to 1700 pixels wide.6.2EXPERIMENT RESULTS\n\n\nTable 5 :\n5\nRoth et al. (2022) detection.Setting: New Few-shot Setting, K (number of shot)=1, Dataset: MVTec, Sampling Ratio: 0.01, Metrics: Image AUROC.The number of shot for RegAD is 2. The data for PaDiM and PatchCore-10, PatchCore-25 are fromRoth et al. (2022).\nCategoryAug.(R) GraphCore CFASPADE PaDiM STPM RD4AD PatchCore-1 PatchCore-10 PatchCore-25 RegADBottle99.799.896.7 95.2-93.291.296.5---Cable90.191.165.4 60.1-59.858.365.5---Capsule64.772.150.2 45.6-43.244.749.8---Carpet99.399.397.1 93.2-90.592.597.2---Grid70.880.979.2 75.1-71.274.378.9---Hazelnut97.498.598.1 95.0-90.393.298.0---Leather10010010097.2-95.196.5100---Meta Nut77.092.566.1 60.2-58.263.465.6---Pill81.081.266.3 59.7-57.362.465.1---Screw57.457.955.9 49.6-51.253.554.8---Tile99.999.299.8 89.5-90.288.799.5---Toothbrush 84.485.286.778.5-75.277.885.8---Transistor94.596.271.5 50.5-83.277.570.5---Wood97.097.398.1 49.5-95.493.598.9---Zipper97.497.550.3 48.5-45.248.651.2---Average87.489.978.75 69.83 76.169.70 74.478.583.4084.1082.4\n\nTable 6 :\n6\nRoth et al. (2022)hot Setting, K (number of shot)=1, Dataset: MVTec, Sampling Ratio: 0.01, Metrics: Pixel AUROC.The number of shot for RegAD is 2. The data for PaDiM and PatchCore-10, PatchCore-25 are fromRoth et al. (2022).\nCategoryAug.(R) GraphCore CFASPADE PaDiM STPM RD4AD PatchCore-1 PatchCore-10 PatchCore-25 RegADBottle98.599.893.2 85.2-84.381.793.0---Cable95.196.288.2 78.2-50.964.887.0---Capsule97.798.185.6 79.2-49.277.987.7---Carpet99.199.397.5 95.2-60.572.598.8---Grid70.576.981.3 75.6-61.274.384.1---Hazelnut97.198.598.1 88.2-73.363.297.5---Leather99.399.599.2 88.3-75.186.599.2---Meta Nut93.292.589.5 58.5-51.168.790.1---Pill95.796.291.2 54.2-49.365.690.4---Screw92.093.496.5 69.6-51.259.795.8---Tile95.896.881.5 81.5-57.288.782.7---Toothbrush 97.998.593.8 75.5-65.277.893.0---Transistor93.696.279.5 73.5-43.277.578.8---Wood93.194.391.8 89.5-45.493.590.7---Zipper98.597.593.2 93.5-55.248.694.0---Average94.4795.6090.67 79.07 88.20 58.15 69.0390.8592.0092.40\n-\n\n\nTable 7 :\n7\nSetting: Our Few-shot Setting, K (number of shot)=2, Dataset: MVTec, Sampling Ratio: 0.01, Metrics: Image AUROC.The data for PaDiM and PatchCore-10, PatchCore-25 are from Roth et al. (2022).\nCategoryAug.(R) GraphCore CFASPADE PaDiM STPM RD4AD PatchCore-1 PatchCore-10 PatchCore-25 RegADBottle99.799.893.7 95.7-93.891.299.7--99.4Cable94.795.289.3 60.4-60.265.394.9--65.1Capsule66.573.253.4 48.7-45.250.567.2--67.5Carpet99.499.497.6 92.1-90.892.899.1--96.5Grid75.781.580.4 75.8-72.675.261.7--84.0Hazelnut99.799.599.4 95.2-90.393.493.5--96.0Leather10010010097.9-95.896.7100--99.4Meta Nut95.096.368.6 61.3-59.463.492.0--91.4Pill87.888.667.4 60.2-58.762.887.4--81.3Screw63.665.758.2 51.3-51.954.348.3--52.5Tile10010099.8 90.2-91.488.9100--94.3Toothbrush 83.687.386.9 80.2-76.577.183.9--86.6Transistor96.397.172.5 51.6-82.478.196.9--86.0Wood97.197.598.2 50.3-95.893.797.2--99.2Zipper96.997.550.5 49.4-47.649.595.3--86.3Average90.4091.9181.06 70.69 78.90 74.16 75.5387.8186.4087.2085.70\n\nTable 8 :\n8\nSetting: Ours Few-shot Setting, K (number of shot)=2, Dataset: MVTec, Sampling Ratio: 0.01, Metrics: Pixel AUROC.The data for PaDiM and PatchCore-10, PatchCore-25 are from Roth et al. (2022).\nCategoryAug.(R) GraphCore CFASPADE PaDiM STPM RD4AD PatchCore-1 PatchCore-10 PatchCore-25 RegADBottle98.699.893.5 86.8-84.681.798.5--98.0Cable96.296.388.9 78.6-51.665.497.8--91.7Capsule97.797.885.9 79.8-59.278.297.7--97.3Carpet99.199.697.9 95.6-60.574.299.0--98.9Grid79.880.681.475.9-61.276.367.5--77.4Hazelnut97.998.298.2 88.9-74.564.896.4--98.1Leather99.399.499.3 89.2-75.286.599.3--98.0Meta Nut96.898.189.7 59.5-51.168.997.1--96.9Pill93.994.191.5 57.2-49.970.296.8--93.6Screw96.096.596.770.2-51.860.890.8--94.4Tile99.396.881.8 82.3-58.259.296.0--94.3Toothbrush 98.298.693.9 76.8-66.378.398.2--98.2Transistor94.199.280.3 73.6-47.567.895.0--93.4Wood98.499.592.4 89.7-48.493.893.0--93.5Zipper99.099.394.1 93.7-56.351.298.2--95.1Average96.2996.9291.03 79.85 90.5059.75 71.8294.7593.1093.3094.59Table 9: Setting: New Few-shot Setting, K (number of shot)=4, Dataset: MVTec, Sampling Ratio:0.01, Metrics: Image AUROCCategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBottle99.799.894.2 95.893.992.199.699.4Cable94.195.291.2 61.361.368.497.476.1Capsule66.274.556.2 48.747.451.766.372.4Carpet99.699.497.6 92.591.593.299.097.9Grid77.981.681.5 76.275.376.463.091.2Hazelnut99.999.599.4 95.691.493.892.895.8Leather10010010098.296.996.8100100Meta Nut95.996.291.3 62.560.865.394.794.6Pill89.388.285.6 61.861.362.889.080.8Screw63.968.949.2 52.952.855.754.156.6Tile10010099.8 91.390.490.810095.5Toothbrush 94.495.287.2 81.780.476.795.290.9Transistor98.599.295.8 52.582.479.398.485.2Wood97.497.998.651.495.894.297.498.6Zipper96.998.294.3 52.247.656.795.588.5Average92.2292.9284.97 71.64 74.77 76.9389.4988.23\n\nTable 10\n10: Setting: New Few-shot Setting, K (number of shot)=4, Dataset: MVTec, Sampling Ratio:0.01, Metrics: Pixel AUROCCategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBottle98.699.893.6 86.984.981.898.698.4Cable96.696.989.1 78.752.266.297.992.7Capsule97.797.986.2 80.159.378.497.797.6Carpet99.199.698.2 95.060.674.899.098.9Grid81.982.382.5 76.161.876.970.685.7Hazelnut98.399.198.5 89.174.965.297.098.0Leather99.399.699.3 89.375.386.796.999.1Meta Nut96.898.189.9 60.251.869.297.097.8Pill97.097.591.6 58.250.670.496.997.4Screw93.896.596.8 71.351.960.992.195.0Tile95.796.782.3 82.458.559.596.094.9Toothbrush 98.898.994.2 76.966.978.998.898.5Transistor94.199.380.5 74.257.567.995.093.8Wood93.299.592.6 90.448.994.293.194.7Zipper98.499.394.8 93.856.452.398.394.0Average95.9597.4091.34 80.17 60.77 72.2294.9995.77Table 11: Setting: New Few-shot Setting, K (number of shot)=8, Dataset: MVTec, Sampling Ratio:0.01, Metrics: Image AUROCCategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBottle10099.895.1 95.994.192.899.699.8Cable94.195.291.8 63.562.669.297.480.6Capsule89.790.569.5 58.957.858.585.376.3Carpet98.599.597.6 92.791.693.899.098.5Grid92.792.385.6 77.376.977.983.191.5Hazelnut10010099.4 96.591.894.299.896.5Leather10010010098.797.297.2100100Meta Nut96.897.992.3 68.961.365.695.198.3Pill90.191.188.9 63.964.263.689.680.6Screw79.480.165.4 56.455.959.374.163.4Tile99.310099.8 91.891.291.210097.4Toothbrush 94.695.188.9 82.982.377.996.898.5Transistor98.299.296.2 58.984.681.298.993.4Wood98.798.998.9 61.395.895.697.599.4Zipper99.099.294.5 62.557.258.998.494.0Average95.4195.9290.93 75.34 77.63 78.4694.3191.21\n\nTable 12 :\n12\nSetting: New Few-shot Setting, K (number of shot)=8, Dataset: MVTec, Sampling Ratio: 0.01, Metrics: Pixel AUROC\nCategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBottle98.699.893.6 87.185.282.198.797.5Cable97.097.289.2 78.953.368.298.394.9Capsule98.398.586.5 80.259.378.598.498.2Carpet99.199.798.4 95.160.779.299.298.9Grid82.583.782.8 77.261.876.971.588.7Hazelnut98.499.298.6 89.574.965.597.298.5Leather99.499.699.4 90.275.386.999.498.9Meta Nut97.398.989.9 60.554.669.597.596.9Pill98.198.491.7 58.255.770.598.197.8Screw94.296.696.9 71.452.361.992.597.1Tile96.897.483.4 82.558.960.896.395.2Toothbrush 99.299.294.5 77.266.979.199.298.7Transistor95.299.481.5 74.558.267.995.796.8Wood93.899.792.7 90.449.294.593.494.6Zipper98.699.794.9 94.257.852.898.697.4Average96.4397.8091.60 80.47 61.61 72.9595.6096.67CategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBracket Black 64.865.964.1 62.193.291.258.2-Bracket Brown 75.076.865.4 59.259.858.370.6-Bracket White 88.689.268.2 68.243.244.769.3-Connector98.398.758.5 58.590.592.559.0-Metal Plate99.999.962.1 63.271.274.364.1-Tubes76.677.834.2 33.865.144.234.1-Average83.8784.7258.75 57.50 59.20 67.5359.2257.8Table 14: Setting: New Few-shot Setting, K (number of shot)=1, Dataset: MPDD, Sampling Ratio:0.01, Metrics: Pixel AUROCCategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBracket Black 91.792.375.2 72.474.572.578.8-Bracket Brown 91.892.277.2 71.872.972.376.8-Bracket White 97.097.369.8 65.463.161.367.8-Connector97.097.588.9 82.482.181.785.0-Metal Plate98.198.983.1 75.283.275.484.1-Tubes92.492.871.7 76.274.576.178.2-Average94.6795.1777.65 73.90 75.05 73.2278.45-Table 15: Setting: New Few-shot Setting, K (number of shot)=2, Dataset: MPDD, Sampling Ratio:0.01, Metrics: Image AUROCCategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBracket Black 66.867.054.3 62.494.591.758.663.3Bracket Brown 76.177.266.8 59.562.358.870.759.4Bracket White 87.289.468.7 67.253.855.670.455.6Connector98.698.958.5 59.251.653.759.273.0Metal Plate99.999.962.7 64.262.465.264.161.7Tubes79.279.840.7 35.649.645.934.367.1Average84.6385.3758.62 58.02 62.37 61.8259.5563.35\nTable 13: Setting: New Few-shot Setting, K (number of shot)=1, Dataset: MPDD, Sampling Ratio: 0.01, Metrics: Image AUROC\n\n\nTable 16 :\n16\nSetting: New Few-shot Setting, K (number of shot)=2, Dataset: MPDD, Sampling Ratio: 0.01, Metrics: Pixel AUROC\nCategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBracket Black 92.192.575.8 72.875.175.478.9-Bracket Brown 91.992.677.5 71.973.273.476.9-Bracket White 97.197.570.8 72.464.262.468.1-Connector97.297.788.2 82.883.482.385.2-Metal Plate98.499.184.3 75.983.276.586.3-Tubes92.693.172.8 76.875.677.179.5-Average94.8895.4278.23 75.43 75.78 74.5279.1593.2Table 17: Setting: New Few-shot Setting, K (number of shot)=4, Dataset: MPDD, Sampling Ratio:0.01, Metrics: Image AUROCCategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBracket Black 66.967.854.9 62.494.591.958.963.8Bracket Brown 76.577.866.8 59.562.459.070.866.1Bracket White 87.589.671.1 67.554.255.770.759.3Connector98.998.958.7 59.552.154.459.477.2Metal Plate99.999.962.9 64.962.465.564.478.6Tubes79.680.041.1 35.950.246.234.567.5Average84.8885.6759.25 58.28 62.62 62.1259.7868.75CategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBracket Black 92.792.775.9 72.975.375.979.1-Bracket Brown 92.192.977.9 72.373.574.877.3-Bracket White 97.597.871.2 72.964.764.569.3-Connector97.598.188.8 82.984.282.486.4-Metal Plate98.599.284.8 76.983.577.286.7-Tubes92.793.573.5 77.275.878.180.1-Average95.1795.7078.68 75.85 76.17 75.4879.8293.9\nTable 18: Setting: New Few-shot Setting, K (number of shot)=4, Dataset: MPDD, Sampling Ratio: 0.01, Metrics: Pixel AUROC\n\n\nTable 19 :\n19\nSetting: New Few-shot Setting, K (number of shot)=8, Dataset: MPDD, Sampling Ratio: 0.01, Metrics: Image AUROC\nCategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBracket Black 67.168.255.2 62.494.692.259.267.3Bracket Brown 76.878.566.9 59.862.759.270.969.5Bracket White 87.989.979.4 67.654.755.970.561.4Connector98.999.158.9 59.952.754.659.684.9Metal Plate99.999.963.1 65.263.265.864.780.2Tubes79.880.341.7 36.250.846.734.867.9Average85.0785.9860.87 58.52 63.12 62.4059.9571.87\n\nTable 20 :\n20\nSetting: New Few-shot Setting, K (number of shot)=8, Dataset: MPDD, Sampling Ratio: 0.01, Metrics: Pixel AUROC\nCategoryAug.(R) GraphCore CFASPADE STPM RD4AD PatchCore RegADBracket Black 92.992.976.2 73.176.376.279.6-Bracket Brown 92.393.177.9 72.674.275.177.5-Bracket White 97.998.271.8 73.164.964.670.2-Connector98.198.389.1 83.184.582.687,1-Metal Plate98.799.385.2 77.283.777.586.9-Tubes92.993.473.9 78.176.178.380.5-Average95.4795.8779.02 76.20 76.62 75.7280.3095.10\n\nTable 21 :\n21\nWang et al. (2021b)tails of GraphCore Pooling and MLP In Table21, D represents the feature dimension, whereas K represents the number of neighbors in GraphCore.H \u00d7 W represents the size of the input image.We adapt GCN into the the pyramid architectureWang et al. (2021b).The training epochs is 300.The optimizer is AdamW Loshchilov & Hutter.The batch size is 128.The initial learning rate is 0.005.The learning rate schedule is Cosine.The warmup epochs is 50.The weight decay is 0.05.The loss function is the cross entropy loss function.\nStageOutput Size GraphCoreStemH 4 \u00d7 W 4Conv \u00d73Stage 1H 4 \u00d7 W 4D = 48 K = 9\u00d7 2Downsample H 8 \u00d7 W 8ConvStage 2H 8 \u00d7 W 8D = 96 K = 9\u00d7 2Downsample H 16 \u00d7 W 16ConvStage 3H 16 \u00d7 W 16D = 240 K = 9\u00d7 2Downsample H 32 \u00d7 W 32ConvStage 4H 32 \u00d7 W 32D = 384 K = 9\u00d7 2Head1 \u00d7 16.4 ABLATION STADIES\n\nTable 22 :\n22\nAblation study for memory bank size and inference speed with respect to 1 shot\nMethodMemory Bank Size (Average) Inference speed (Average)PatchCore1.6M0.0316sAug.(R) + PatchCore 1.8M0.0325sGraphCore1.2M0.0299s\n\nTable 23 :\n23\nAblation study for memory bank size and inference speed with respect to 2 shot\nMethodMemory Bank Size (Average) Inference speed (Average)PatchCore3.2M0.0327sAug.(R) + PatchCore 3.2M0.0327sGraphCore1.8M0.0287s\n\nTable 24 :\n24\nAblation study with respect to Dataset: MVTec 2D, sampling rate: 0.01, Metrics: imagelevel AUROC, number of shot is 1.\nAugmentation Type Aug + PatchCoreFlipping81.4Translation83.6Scaling82.3Rotation87.4\n\nTable 25 :\n25\nAblation study with respect to Dataset: MVTec 2D, sampling rate: 0.01, Metrics: imagelevel AUROC, number of shot is 2.\nAugmentation Type Aug + PatchCoreFlipping83.7Translation85.6Scaling90.2Rotation90.5\nACKNOWLEDGMENTSThis work is supported by the National Natural Science Foundation of China under Grant No. 62122035, 62206122, and 61972188.Y. Jin is supported by an Alexander von Humboldt Professorship for AI endowed by the German Federal Ministry of Education and Research.\nMvtec ad -a comprehensive real-world dataset for unsupervised anomaly detection. Paul Bergmann, Michael Fauser, David Sattlegger, Carsten Steger, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 2019. 2019\n\nBeyond dents and scratches: Logical constraints in unsupervised anomaly detection and localization. Paul Bergmann, Kilian Batzner, Michael Fauser, David Sattlegger, Carsten Steger, International Journal of Computer Vision. 13042022\n\nJoan Bruna, Wojciech Zaremba, Arthur Szlam, Yann Lecun, arXiv:1312.6203Spectral networks and locally connected networks on graphs. 2013arXiv preprint\n\nSub-image anomaly detection with deep pyramid correspondences. Niv Cohen, Yedid Hoshen, arXiv:2005.023572020arXiv preprint\n\nPadim: a patch distribution modeling framework for anomaly detection and localization. Thomas Defard, Aleksandr Setkov, Angelique Loesch, Romaric Audigier, International Conference on Pattern Recognition. Springer2021\n\nAnomaly detection via reverse distillation from one-class embedding. Hanqiu Deng, Xingyu Li, ArXiv, abs/2201.107032022\n\nExploiting cyclic symmetry in convolutional neural networks. Jeffrey Sander Dieleman, Koray De Fauw, Kavukcuoglu, International conference on machine learning. PMLR2016\n\nCatching both gray and black swans: Open-set supervised anomaly detection. Choubo Ding, Guansong Pang, Chunhua Shen, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022\n\nInductive representation learning on large graphs. Will Hamilton, Zhitao Ying, Jure Leskovec, Advances in neural information processing systems. 201730\n\nVision gnn: An image is worth graph of nodes. Kai Han, Yunhe Wang, Jianyuan Guo, Yehui Tang, Enhua Wu, arXiv:2206.002722022arXiv preprint\n\nIdentity mappings in deep residual networks. X Kaiming He, Shaoqing Zhang, Jian Ren, Sun, ArXiv, abs/1603.050272016\n\nRegistration based few-shot anomaly detection. Chaoqin Huang, Haoyan Guan, Aofan Jiang, Ya Zhang, Michael Spratling, Yan-Feng Wang, arXiv:2207.073612022arXiv preprint\n\nDeep learning-based defect detection of metal parts: evaluating current methods in complex conditions. Stepan Jezek, Martin Jonak, Radim Burget, Pavel Dvorak, Milos Skotak, 2021 13th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT). IEEE2021\n\nSemi-supervised classification with graph convolutional networks. Thomas Kipf, Max Welling, ArXiv, abs/1609.029072017\n\nCfa: Coupled-hypersphere-based feature adaptation for target-oriented anomaly localization. Sungwook Lee, Seunghyun Lee, Byung Cheol Song, IEEE Access. 102022\n\nCan gcns go as deep as cnns?. Guohao Li, Matthias M\u00fcller, Ali K Thabet, Bernard Ghanem, ArXiv, abs/1904.037512019\n\nFast haar transforms for graph neural networks. Ming Li, Zheng Ma, Yu Guang Wang, Xiaosheng Zhuang, Neural Networks. 1282020\n\nExplainable deep one-class classification. Philipp Liznerski, Lukas Ruff, Robert A Vandermeulen, Billy Joe Franks, Marius Kloft, Klaus Robert Muller, International Conference on Learning Representations. 2020\n\nDecoupled weight decay regularization. Ilya Loshchilov, Frank Hutter, International Conference on Learning Representations. \n\nExplainable deep fewshot anomaly detection with deviation networks. Guansong Pang, Choubo Ding, Chunhua Shen, Anton Van Den, Hengel, arXiv:2108.004622021arXiv preprint\n\nTowards total recall in industrial anomaly detection. Karsten Roth, Latha Pemula, Joaquin Zepeda, Bernhard Sch\u00f6lkopf, Thomas Brox, Peter Gehler, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022\n\nOzan Sener, Silvio Savarese, Active learning for convolutional neural networks: A core-set approach. arXiv: Machine Learning. 2018\n\nStudent-teacher feature pyramid matching for anomaly detection. Guodong Wang, Shumin Han, Errui Ding, Di Huang, BMVC. 2021a\n\nPyramid vision transformer: A versatile backbone for dense prediction without convolutions. Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, Ling Shao, Proceedings of the IEEE/CVF international conference on computer vision. the IEEE/CVF international conference on computer vision2021b\n\nHaar graph pooling. Yu Guang, Wang , Ming Li, Zheng Ma, Guido Montufar, Xiaosheng Zhuang, Yanan Fan, International conference on machine learning. PMLR2020\n\nLearning unsupervised metaformer for anomaly detection. Jhih-Ciang Wu, Ding-Jie Chen, Chiou-Shann, Tyng-Luh Fuh, Liu, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2021\n\nKeyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka, arXiv:1810.00826How powerful are graph neural networks?. 2018arXiv preprint\n", "annotations": {"author": "[{\"end\":317,\"start\":94},{\"end\":452,\"start\":318},{\"end\":585,\"start\":453},{\"end\":741,\"start\":586},{\"end\":900,\"start\":742}]", "publisher": null, "author_last_name": "[{\"end\":105,\"start\":102},{\"end\":329,\"start\":325},{\"end\":462,\"start\":459},{\"end\":596,\"start\":591},{\"end\":752,\"start\":749}]", "author_first_name": "[{\"end\":101,\"start\":94},{\"end\":324,\"start\":318},{\"end\":458,\"start\":453},{\"end\":590,\"start\":586},{\"end\":748,\"start\":742}]", "author_affiliation": "[{\"end\":185,\"start\":132},{\"end\":252,\"start\":187},{\"end\":316,\"start\":254},{\"end\":384,\"start\":331},{\"end\":451,\"start\":386},{\"end\":517,\"start\":464},{\"end\":584,\"start\":519},{\"end\":673,\"start\":620},{\"end\":740,\"start\":675},{\"end\":844,\"start\":782},{\"end\":899,\"start\":846}]", "title": "[{\"end\":80,\"start\":1},{\"end\":980,\"start\":901}]", "venue": null, "abstract": "[{\"end\":2277,\"start\":1050}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3481,\"start\":3462},{\"end\":3525,\"start\":3516},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5064,\"start\":5046},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5085,\"start\":5066},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5109,\"start\":5087},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5127,\"start\":5111},{\"end\":5204,\"start\":5186},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5222,\"start\":5206},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5605,\"start\":5586},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7154,\"start\":7130},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7174,\"start\":7156},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7194,\"start\":7176},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7350,\"start\":7333},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7371,\"start\":7352},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7647,\"start\":7628},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7678,\"start\":7656},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7712,\"start\":7691},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8256,\"start\":8233},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8277,\"start\":8258},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8860,\"start\":8841},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9728,\"start\":9704},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12431,\"start\":12409},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":13211,\"start\":13194},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":19318,\"start\":19295},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":19657,\"start\":19637}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":20834,\"start\":20347},{\"attributes\":{\"id\":\"fig_1\"},\"end\":21688,\"start\":20835},{\"attributes\":{\"id\":\"fig_2\"},\"end\":21750,\"start\":21689},{\"attributes\":{\"id\":\"fig_3\"},\"end\":21834,\"start\":21751},{\"attributes\":{\"id\":\"fig_4\"},\"end\":21900,\"start\":21835},{\"attributes\":{\"id\":\"fig_5\"},\"end\":21977,\"start\":21901},{\"attributes\":{\"id\":\"fig_6\"},\"end\":22079,\"start\":21978},{\"attributes\":{\"id\":\"fig_7\"},\"end\":22178,\"start\":22080},{\"attributes\":{\"id\":\"fig_8\"},\"end\":22283,\"start\":22179},{\"attributes\":{\"id\":\"fig_9\"},\"end\":22580,\"start\":22284},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":22949,\"start\":22581},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":23939,\"start\":22950},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":25116,\"start\":23940},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":26889,\"start\":25117},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":27852,\"start\":26890},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":28687,\"start\":27853},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":29693,\"start\":28688},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":30681,\"start\":29694},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":31674,\"start\":30682},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":33483,\"start\":31675},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":35119,\"start\":33484},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":37395,\"start\":35120},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":38853,\"start\":37396},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":39356,\"start\":38854},{\"attributes\":{\"id\":\"tab_17\",\"type\":\"table\"},\"end\":39841,\"start\":39357},{\"attributes\":{\"id\":\"tab_18\",\"type\":\"table\"},\"end\":40676,\"start\":39842},{\"attributes\":{\"id\":\"tab_19\",\"type\":\"table\"},\"end\":40900,\"start\":40677},{\"attributes\":{\"id\":\"tab_20\",\"type\":\"table\"},\"end\":41124,\"start\":40901},{\"attributes\":{\"id\":\"tab_21\",\"type\":\"table\"},\"end\":41342,\"start\":41125},{\"attributes\":{\"id\":\"tab_22\",\"type\":\"table\"},\"end\":41560,\"start\":41343}]", "paragraph": "[{\"end\":2771,\"start\":2293},{\"end\":4376,\"start\":2773},{\"end\":6200,\"start\":4378},{\"end\":6820,\"start\":6202},{\"end\":6964,\"start\":6822},{\"end\":8151,\"start\":6966},{\"end\":8763,\"start\":8164},{\"end\":9098,\"start\":8790},{\"end\":9982,\"start\":9206},{\"end\":10233,\"start\":9984},{\"end\":10387,\"start\":10235},{\"end\":11550,\"start\":10426},{\"end\":11801,\"start\":11584},{\"end\":11969,\"start\":11870},{\"end\":12250,\"start\":12002},{\"end\":12576,\"start\":12279},{\"end\":12902,\"start\":12645},{\"end\":13065,\"start\":12968},{\"end\":13255,\"start\":13067},{\"end\":13972,\"start\":13342},{\"end\":14262,\"start\":13974},{\"end\":14765,\"start\":14321},{\"end\":15229,\"start\":14778},{\"end\":16557,\"start\":15266},{\"end\":16921,\"start\":16578},{\"end\":17417,\"start\":16923},{\"end\":18393,\"start\":17419},{\"end\":19196,\"start\":18408},{\"end\":19561,\"start\":19219},{\"end\":19659,\"start\":19563},{\"end\":19957,\"start\":19661},{\"end\":20346,\"start\":19959},{\"end\":20833,\"start\":20361},{\"end\":21687,\"start\":20838},{\"end\":21749,\"start\":21703},{\"end\":21833,\"start\":21765},{\"end\":21899,\"start\":21849},{\"end\":21976,\"start\":21926},{\"end\":22078,\"start\":21992},{\"end\":22177,\"start\":22094},{\"end\":22282,\"start\":22193},{\"end\":22579,\"start\":22300},{\"end\":22738,\"start\":22584},{\"end\":22948,\"start\":22941},{\"end\":22994,\"start\":22963},{\"end\":23938,\"start\":23369},{\"end\":25115,\"start\":24785},{\"end\":25444,\"start\":25130},{\"end\":27213,\"start\":26903},{\"end\":28018,\"start\":27856},{\"end\":28686,\"start\":28298},{\"end\":28954,\"start\":28701},{\"end\":29931,\"start\":29707},{\"end\":30680,\"start\":30679},{\"end\":30885,\"start\":30695},{\"end\":31879,\"start\":31688},{\"end\":35246,\"start\":35135},{\"end\":37394,\"start\":37274},{\"end\":37521,\"start\":37411},{\"end\":38852,\"start\":38732},{\"end\":38979,\"start\":38869},{\"end\":39482,\"start\":39372},{\"end\":40394,\"start\":39857},{\"end\":40770,\"start\":40692},{\"end\":40994,\"start\":40916},{\"end\":41258,\"start\":41140},{\"end\":41476,\"start\":41358}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9205,\"start\":9099},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11869,\"start\":11802},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12001,\"start\":11970},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12644,\"start\":12577},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12966,\"start\":12903},{\"attributes\":{\"id\":\"formula_5\"},\"end\":12967,\"start\":12966},{\"attributes\":{\"id\":\"formula_6\"},\"end\":13306,\"start\":13256},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13341,\"start\":13306}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":10259,\"start\":10246},{\"attributes\":{\"ref_id\":\"tab_18\"},\"end\":14261,\"start\":14259},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":14653,\"start\":14652},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":15334,\"start\":15333},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":16148,\"start\":16147},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":16375,\"start\":16374},{\"attributes\":{\"ref_id\":\"tab_19\"},\"end\":19835,\"start\":19833},{\"attributes\":{\"ref_id\":\"tab_20\"},\"end\":19848,\"start\":19846},{\"attributes\":{\"ref_id\":\"tab_22\"},\"end\":20012,\"start\":20003}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2291,\"start\":2279},{\"attributes\":{\"n\":\"2\"},\"end\":8162,\"start\":8154},{\"attributes\":{\"n\":\"2.1\"},\"end\":8788,\"start\":8766},{\"attributes\":{\"n\":\"2.2\"},\"end\":10424,\"start\":10390},{\"attributes\":{\"n\":\"2.3\"},\"end\":11582,\"start\":11553},{\"attributes\":{\"n\":\"2.4\"},\"end\":12277,\"start\":12253},{\"attributes\":{\"n\":\"2.6\"},\"end\":14319,\"start\":14265},{\"end\":14776,\"start\":14768},{\"attributes\":{\"n\":\"3.2\"},\"end\":15264,\"start\":15232},{\"attributes\":{\"n\":\"3.3\"},\"end\":16576,\"start\":16560},{\"attributes\":{\"n\":\"4\"},\"end\":18406,\"start\":18396},{\"attributes\":{\"n\":\"6\"},\"end\":19207,\"start\":19199},{\"attributes\":{\"n\":\"6.1\"},\"end\":19217,\"start\":19210},{\"end\":20358,\"start\":20348},{\"end\":21700,\"start\":21690},{\"end\":21762,\"start\":21752},{\"end\":21846,\"start\":21836},{\"end\":21922,\"start\":21902},{\"end\":21989,\"start\":21979},{\"end\":22091,\"start\":22081},{\"end\":22190,\"start\":22180},{\"end\":22296,\"start\":22285},{\"end\":22960,\"start\":22951},{\"end\":23950,\"start\":23941},{\"end\":25127,\"start\":25118},{\"end\":26900,\"start\":26891},{\"end\":28698,\"start\":28689},{\"end\":29704,\"start\":29695},{\"end\":30692,\"start\":30683},{\"end\":31685,\"start\":31676},{\"end\":33493,\"start\":33485},{\"end\":35131,\"start\":35121},{\"end\":37407,\"start\":37397},{\"end\":38865,\"start\":38855},{\"end\":39368,\"start\":39358},{\"end\":39853,\"start\":39843},{\"end\":40688,\"start\":40678},{\"end\":40912,\"start\":40902},{\"end\":41136,\"start\":41126},{\"end\":41354,\"start\":41344}]", "table": "[{\"end\":22940,\"start\":22739},{\"end\":23368,\"start\":22995},{\"end\":24784,\"start\":23952},{\"end\":26889,\"start\":25445},{\"end\":27852,\"start\":27214},{\"end\":28297,\"start\":28019},{\"end\":29693,\"start\":28955},{\"end\":30678,\"start\":29932},{\"end\":31674,\"start\":30886},{\"end\":33483,\"start\":31880},{\"end\":35119,\"start\":33496},{\"end\":37273,\"start\":35247},{\"end\":38731,\"start\":37522},{\"end\":39356,\"start\":38980},{\"end\":39841,\"start\":39483},{\"end\":40676,\"start\":40395},{\"end\":40900,\"start\":40771},{\"end\":41124,\"start\":40995},{\"end\":41342,\"start\":41259},{\"end\":41560,\"start\":41477}]", "figure_caption": "[{\"end\":20834,\"start\":20360},{\"end\":21688,\"start\":20837},{\"end\":21750,\"start\":21702},{\"end\":21834,\"start\":21764},{\"end\":21900,\"start\":21848},{\"end\":21977,\"start\":21925},{\"end\":22079,\"start\":21991},{\"end\":22178,\"start\":22093},{\"end\":22283,\"start\":22192},{\"end\":22580,\"start\":22299},{\"end\":22739,\"start\":22583},{\"end\":22995,\"start\":22962},{\"end\":25445,\"start\":25129},{\"end\":27214,\"start\":26902},{\"end\":28019,\"start\":27855},{\"end\":28955,\"start\":28700},{\"end\":29932,\"start\":29706},{\"end\":30886,\"start\":30694},{\"end\":31880,\"start\":31687},{\"end\":35247,\"start\":35134},{\"end\":37522,\"start\":37410},{\"end\":38980,\"start\":38868},{\"end\":39483,\"start\":39371},{\"end\":40395,\"start\":39856},{\"end\":40771,\"start\":40691},{\"end\":40995,\"start\":40915},{\"end\":41259,\"start\":41139},{\"end\":41477,\"start\":41357}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3263,\"start\":3259},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4014,\"start\":4013},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6352,\"start\":6351},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":8442,\"start\":8441},{\"end\":8465,\"start\":8464},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":8730,\"start\":8729},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":8983,\"start\":8982},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":11072,\"start\":11071},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":11590,\"start\":11589},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":12285,\"start\":12284},{\"end\":13597,\"start\":13596},{\"end\":14327,\"start\":14326},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":15633,\"start\":15632},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":16619,\"start\":16618},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":16950,\"start\":16949},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":17446,\"start\":17445},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":17894,\"start\":17892}]", "bib_author_first_name": "[{\"end\":41921,\"start\":41917},{\"end\":41939,\"start\":41932},{\"end\":41953,\"start\":41948},{\"end\":41973,\"start\":41966},{\"end\":42169,\"start\":42165},{\"end\":42186,\"start\":42180},{\"end\":42203,\"start\":42196},{\"end\":42217,\"start\":42212},{\"end\":42237,\"start\":42230},{\"end\":42302,\"start\":42298},{\"end\":42318,\"start\":42310},{\"end\":42334,\"start\":42328},{\"end\":42346,\"start\":42342},{\"end\":42515,\"start\":42512},{\"end\":42528,\"start\":42523},{\"end\":42666,\"start\":42660},{\"end\":42684,\"start\":42675},{\"end\":42702,\"start\":42693},{\"end\":42718,\"start\":42711},{\"end\":42867,\"start\":42861},{\"end\":42880,\"start\":42874},{\"end\":42980,\"start\":42973},{\"end\":43003,\"start\":42998},{\"end\":43163,\"start\":43157},{\"end\":43178,\"start\":43170},{\"end\":43192,\"start\":43185},{\"end\":43409,\"start\":43405},{\"end\":43426,\"start\":43420},{\"end\":43437,\"start\":43433},{\"end\":43556,\"start\":43553},{\"end\":43567,\"start\":43562},{\"end\":43582,\"start\":43574},{\"end\":43593,\"start\":43588},{\"end\":43605,\"start\":43600},{\"end\":43692,\"start\":43691},{\"end\":43713,\"start\":43705},{\"end\":43725,\"start\":43721},{\"end\":43817,\"start\":43810},{\"end\":43831,\"start\":43825},{\"end\":43843,\"start\":43838},{\"end\":43853,\"start\":43851},{\"end\":43868,\"start\":43861},{\"end\":43888,\"start\":43880},{\"end\":44040,\"start\":44034},{\"end\":44054,\"start\":44048},{\"end\":44067,\"start\":44062},{\"end\":44081,\"start\":44076},{\"end\":44095,\"start\":44090},{\"end\":44297,\"start\":44291},{\"end\":44307,\"start\":44304},{\"end\":44444,\"start\":44436},{\"end\":44459,\"start\":44450},{\"end\":44476,\"start\":44465},{\"end\":44540,\"start\":44534},{\"end\":44553,\"start\":44545},{\"end\":44565,\"start\":44562},{\"end\":44567,\"start\":44566},{\"end\":44583,\"start\":44576},{\"end\":44671,\"start\":44667},{\"end\":44681,\"start\":44676},{\"end\":44688,\"start\":44686},{\"end\":44694,\"start\":44689},{\"end\":44710,\"start\":44701},{\"end\":44795,\"start\":44788},{\"end\":44812,\"start\":44807},{\"end\":44825,\"start\":44819},{\"end\":44827,\"start\":44826},{\"end\":44847,\"start\":44842},{\"end\":44851,\"start\":44848},{\"end\":44866,\"start\":44860},{\"end\":44879,\"start\":44874},{\"end\":44886,\"start\":44880},{\"end\":44998,\"start\":44994},{\"end\":45016,\"start\":45011},{\"end\":45157,\"start\":45149},{\"end\":45170,\"start\":45164},{\"end\":45184,\"start\":45177},{\"end\":45196,\"start\":45191},{\"end\":45311,\"start\":45304},{\"end\":45323,\"start\":45318},{\"end\":45339,\"start\":45332},{\"end\":45356,\"start\":45348},{\"end\":45374,\"start\":45368},{\"end\":45386,\"start\":45381},{\"end\":45554,\"start\":45550},{\"end\":45568,\"start\":45562},{\"end\":45753,\"start\":45746},{\"end\":45766,\"start\":45760},{\"end\":45777,\"start\":45772},{\"end\":45786,\"start\":45784},{\"end\":45905,\"start\":45899},{\"end\":45916,\"start\":45912},{\"end\":45927,\"start\":45922},{\"end\":45941,\"start\":45932},{\"end\":45953,\"start\":45947},{\"end\":45964,\"start\":45960},{\"end\":45976,\"start\":45972},{\"end\":45985,\"start\":45981},{\"end\":45995,\"start\":45991},{\"end\":46160,\"start\":46158},{\"end\":46172,\"start\":46168},{\"end\":46179,\"start\":46175},{\"end\":46189,\"start\":46184},{\"end\":46199,\"start\":46194},{\"end\":46219,\"start\":46210},{\"end\":46233,\"start\":46228},{\"end\":46361,\"start\":46351},{\"end\":46374,\"start\":46366},{\"end\":46402,\"start\":46394},{\"end\":46554,\"start\":46548},{\"end\":46565,\"start\":46559},{\"end\":46574,\"start\":46570},{\"end\":46593,\"start\":46585}]", "bib_author_last_name": "[{\"end\":41930,\"start\":41922},{\"end\":41946,\"start\":41940},{\"end\":41964,\"start\":41954},{\"end\":41980,\"start\":41974},{\"end\":42178,\"start\":42170},{\"end\":42194,\"start\":42187},{\"end\":42210,\"start\":42204},{\"end\":42228,\"start\":42218},{\"end\":42244,\"start\":42238},{\"end\":42308,\"start\":42303},{\"end\":42326,\"start\":42319},{\"end\":42340,\"start\":42335},{\"end\":42352,\"start\":42347},{\"end\":42521,\"start\":42516},{\"end\":42535,\"start\":42529},{\"end\":42673,\"start\":42667},{\"end\":42691,\"start\":42685},{\"end\":42709,\"start\":42703},{\"end\":42727,\"start\":42719},{\"end\":42872,\"start\":42868},{\"end\":42883,\"start\":42881},{\"end\":42996,\"start\":42981},{\"end\":43011,\"start\":43004},{\"end\":43024,\"start\":43013},{\"end\":43168,\"start\":43164},{\"end\":43183,\"start\":43179},{\"end\":43197,\"start\":43193},{\"end\":43418,\"start\":43410},{\"end\":43431,\"start\":43427},{\"end\":43446,\"start\":43438},{\"end\":43560,\"start\":43557},{\"end\":43572,\"start\":43568},{\"end\":43586,\"start\":43583},{\"end\":43598,\"start\":43594},{\"end\":43608,\"start\":43606},{\"end\":43703,\"start\":43693},{\"end\":43719,\"start\":43714},{\"end\":43729,\"start\":43726},{\"end\":43734,\"start\":43731},{\"end\":43823,\"start\":43818},{\"end\":43836,\"start\":43832},{\"end\":43849,\"start\":43844},{\"end\":43859,\"start\":43854},{\"end\":43878,\"start\":43869},{\"end\":43893,\"start\":43889},{\"end\":44046,\"start\":44041},{\"end\":44060,\"start\":44055},{\"end\":44074,\"start\":44068},{\"end\":44088,\"start\":44082},{\"end\":44102,\"start\":44096},{\"end\":44302,\"start\":44298},{\"end\":44315,\"start\":44308},{\"end\":44448,\"start\":44445},{\"end\":44463,\"start\":44460},{\"end\":44481,\"start\":44477},{\"end\":44543,\"start\":44541},{\"end\":44560,\"start\":44554},{\"end\":44574,\"start\":44568},{\"end\":44590,\"start\":44584},{\"end\":44674,\"start\":44672},{\"end\":44684,\"start\":44682},{\"end\":44699,\"start\":44695},{\"end\":44717,\"start\":44711},{\"end\":44805,\"start\":44796},{\"end\":44817,\"start\":44813},{\"end\":44840,\"start\":44828},{\"end\":44858,\"start\":44852},{\"end\":44872,\"start\":44867},{\"end\":44893,\"start\":44887},{\"end\":45009,\"start\":44999},{\"end\":45023,\"start\":45017},{\"end\":45162,\"start\":45158},{\"end\":45175,\"start\":45171},{\"end\":45189,\"start\":45185},{\"end\":45204,\"start\":45197},{\"end\":45212,\"start\":45206},{\"end\":45316,\"start\":45312},{\"end\":45330,\"start\":45324},{\"end\":45346,\"start\":45340},{\"end\":45366,\"start\":45357},{\"end\":45379,\"start\":45375},{\"end\":45393,\"start\":45387},{\"end\":45560,\"start\":45555},{\"end\":45577,\"start\":45569},{\"end\":45758,\"start\":45754},{\"end\":45770,\"start\":45767},{\"end\":45782,\"start\":45778},{\"end\":45792,\"start\":45787},{\"end\":45910,\"start\":45906},{\"end\":45920,\"start\":45917},{\"end\":45930,\"start\":45928},{\"end\":45945,\"start\":45942},{\"end\":45958,\"start\":45954},{\"end\":45970,\"start\":45965},{\"end\":45979,\"start\":45977},{\"end\":45989,\"start\":45986},{\"end\":46000,\"start\":45996},{\"end\":46166,\"start\":46161},{\"end\":46182,\"start\":46180},{\"end\":46192,\"start\":46190},{\"end\":46208,\"start\":46200},{\"end\":46226,\"start\":46220},{\"end\":46237,\"start\":46234},{\"end\":46364,\"start\":46362},{\"end\":46379,\"start\":46375},{\"end\":46392,\"start\":46381},{\"end\":46406,\"start\":46403},{\"end\":46411,\"start\":46408},{\"end\":46557,\"start\":46555},{\"end\":46568,\"start\":46566},{\"end\":46583,\"start\":46575},{\"end\":46601,\"start\":46594}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":189857704},\"end\":42063,\"start\":41836},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":247063535},\"end\":42296,\"start\":42065},{\"attributes\":{\"doi\":\"arXiv:1312.6203\",\"id\":\"b2\"},\"end\":42447,\"start\":42298},{\"attributes\":{\"doi\":\"arXiv:2005.02357\",\"id\":\"b3\"},\"end\":42571,\"start\":42449},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":226976039},\"end\":42790,\"start\":42573},{\"attributes\":{\"doi\":\"ArXiv, abs/2201.10703\",\"id\":\"b5\"},\"end\":42910,\"start\":42792},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":8569309},\"end\":43080,\"start\":42912},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":247763083},\"end\":43352,\"start\":43082},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":4755450},\"end\":43505,\"start\":43354},{\"attributes\":{\"doi\":\"arXiv:2206.00272\",\"id\":\"b9\"},\"end\":43644,\"start\":43507},{\"attributes\":{\"doi\":\"ArXiv, abs/1603.05027\",\"id\":\"b10\"},\"end\":43761,\"start\":43646},{\"attributes\":{\"doi\":\"arXiv:2207.07361\",\"id\":\"b11\"},\"end\":43929,\"start\":43763},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":245147304},\"end\":44223,\"start\":43931},{\"attributes\":{\"doi\":\"ArXiv, abs/1609.02907\",\"id\":\"b13\"},\"end\":44342,\"start\":44225},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":249538567},\"end\":44502,\"start\":44344},{\"attributes\":{\"doi\":\"ArXiv, abs/1904.03751\",\"id\":\"b15\"},\"end\":44617,\"start\":44504},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":198179822},\"end\":44743,\"start\":44619},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":220347587},\"end\":44953,\"start\":44745},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":53592270},\"end\":45079,\"start\":44955},{\"attributes\":{\"doi\":\"arXiv:2108.00462\",\"id\":\"b19\"},\"end\":45248,\"start\":45081},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":235436036},\"end\":45548,\"start\":45250},{\"attributes\":{\"id\":\"b21\"},\"end\":45680,\"start\":45550},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":240070818},\"end\":45805,\"start\":45682},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":232035922},\"end\":46136,\"start\":45807},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":211069077},\"end\":46293,\"start\":46138},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":244100442},\"end\":46546,\"start\":46295},{\"attributes\":{\"doi\":\"arXiv:1810.00826\",\"id\":\"b26\"},\"end\":46678,\"start\":46548}]", "bib_title": "[{\"end\":41915,\"start\":41836},{\"end\":42163,\"start\":42065},{\"end\":42658,\"start\":42573},{\"end\":42971,\"start\":42912},{\"end\":43155,\"start\":43082},{\"end\":43403,\"start\":43354},{\"end\":44032,\"start\":43931},{\"end\":44434,\"start\":44344},{\"end\":44665,\"start\":44619},{\"end\":44786,\"start\":44745},{\"end\":44992,\"start\":44955},{\"end\":45302,\"start\":45250},{\"end\":45744,\"start\":45682},{\"end\":45897,\"start\":45807},{\"end\":46156,\"start\":46138},{\"end\":46349,\"start\":46295}]", "bib_author": "[{\"end\":41932,\"start\":41917},{\"end\":41948,\"start\":41932},{\"end\":41966,\"start\":41948},{\"end\":41982,\"start\":41966},{\"end\":42180,\"start\":42165},{\"end\":42196,\"start\":42180},{\"end\":42212,\"start\":42196},{\"end\":42230,\"start\":42212},{\"end\":42246,\"start\":42230},{\"end\":42310,\"start\":42298},{\"end\":42328,\"start\":42310},{\"end\":42342,\"start\":42328},{\"end\":42354,\"start\":42342},{\"end\":42523,\"start\":42512},{\"end\":42537,\"start\":42523},{\"end\":42675,\"start\":42660},{\"end\":42693,\"start\":42675},{\"end\":42711,\"start\":42693},{\"end\":42729,\"start\":42711},{\"end\":42874,\"start\":42861},{\"end\":42885,\"start\":42874},{\"end\":42998,\"start\":42973},{\"end\":43013,\"start\":42998},{\"end\":43026,\"start\":43013},{\"end\":43170,\"start\":43157},{\"end\":43185,\"start\":43170},{\"end\":43199,\"start\":43185},{\"end\":43420,\"start\":43405},{\"end\":43433,\"start\":43420},{\"end\":43448,\"start\":43433},{\"end\":43562,\"start\":43553},{\"end\":43574,\"start\":43562},{\"end\":43588,\"start\":43574},{\"end\":43600,\"start\":43588},{\"end\":43610,\"start\":43600},{\"end\":43705,\"start\":43691},{\"end\":43721,\"start\":43705},{\"end\":43731,\"start\":43721},{\"end\":43736,\"start\":43731},{\"end\":43825,\"start\":43810},{\"end\":43838,\"start\":43825},{\"end\":43851,\"start\":43838},{\"end\":43861,\"start\":43851},{\"end\":43880,\"start\":43861},{\"end\":43895,\"start\":43880},{\"end\":44048,\"start\":44034},{\"end\":44062,\"start\":44048},{\"end\":44076,\"start\":44062},{\"end\":44090,\"start\":44076},{\"end\":44104,\"start\":44090},{\"end\":44304,\"start\":44291},{\"end\":44317,\"start\":44304},{\"end\":44450,\"start\":44436},{\"end\":44465,\"start\":44450},{\"end\":44483,\"start\":44465},{\"end\":44545,\"start\":44534},{\"end\":44562,\"start\":44545},{\"end\":44576,\"start\":44562},{\"end\":44592,\"start\":44576},{\"end\":44676,\"start\":44667},{\"end\":44686,\"start\":44676},{\"end\":44701,\"start\":44686},{\"end\":44719,\"start\":44701},{\"end\":44807,\"start\":44788},{\"end\":44819,\"start\":44807},{\"end\":44842,\"start\":44819},{\"end\":44860,\"start\":44842},{\"end\":44874,\"start\":44860},{\"end\":44895,\"start\":44874},{\"end\":45011,\"start\":44994},{\"end\":45025,\"start\":45011},{\"end\":45164,\"start\":45149},{\"end\":45177,\"start\":45164},{\"end\":45191,\"start\":45177},{\"end\":45206,\"start\":45191},{\"end\":45214,\"start\":45206},{\"end\":45318,\"start\":45304},{\"end\":45332,\"start\":45318},{\"end\":45348,\"start\":45332},{\"end\":45368,\"start\":45348},{\"end\":45381,\"start\":45368},{\"end\":45395,\"start\":45381},{\"end\":45562,\"start\":45550},{\"end\":45579,\"start\":45562},{\"end\":45760,\"start\":45746},{\"end\":45772,\"start\":45760},{\"end\":45784,\"start\":45772},{\"end\":45794,\"start\":45784},{\"end\":45912,\"start\":45899},{\"end\":45922,\"start\":45912},{\"end\":45932,\"start\":45922},{\"end\":45947,\"start\":45932},{\"end\":45960,\"start\":45947},{\"end\":45972,\"start\":45960},{\"end\":45981,\"start\":45972},{\"end\":45991,\"start\":45981},{\"end\":46002,\"start\":45991},{\"end\":46168,\"start\":46158},{\"end\":46175,\"start\":46168},{\"end\":46184,\"start\":46175},{\"end\":46194,\"start\":46184},{\"end\":46210,\"start\":46194},{\"end\":46228,\"start\":46210},{\"end\":46239,\"start\":46228},{\"end\":46366,\"start\":46351},{\"end\":46381,\"start\":46366},{\"end\":46394,\"start\":46381},{\"end\":46408,\"start\":46394},{\"end\":46413,\"start\":46408},{\"end\":46559,\"start\":46548},{\"end\":46570,\"start\":46559},{\"end\":46585,\"start\":46570},{\"end\":46603,\"start\":46585}]", "bib_venue": "[{\"end\":43348,\"start\":43282},{\"end\":45544,\"start\":45478},{\"end\":46131,\"start\":46075},{\"end\":46542,\"start\":46486},{\"end\":42051,\"start\":41982},{\"end\":42286,\"start\":42246},{\"end\":42427,\"start\":42369},{\"end\":42510,\"start\":42449},{\"end\":42776,\"start\":42729},{\"end\":42859,\"start\":42792},{\"end\":43070,\"start\":43026},{\"end\":43280,\"start\":43199},{\"end\":43497,\"start\":43448},{\"end\":43551,\"start\":43507},{\"end\":43689,\"start\":43646},{\"end\":43808,\"start\":43763},{\"end\":44213,\"start\":44104},{\"end\":44289,\"start\":44225},{\"end\":44494,\"start\":44483},{\"end\":44532,\"start\":44504},{\"end\":44734,\"start\":44719},{\"end\":44947,\"start\":44895},{\"end\":45077,\"start\":45025},{\"end\":45147,\"start\":45081},{\"end\":45476,\"start\":45395},{\"end\":45674,\"start\":45579},{\"end\":45798,\"start\":45794},{\"end\":46073,\"start\":46002},{\"end\":46283,\"start\":46239},{\"end\":46484,\"start\":46413},{\"end\":46658,\"start\":46619}]"}}}, "year": 2023, "month": 12, "day": 17}