{"id": 252316923, "updated": "2022-09-30 13:36:06.708", "metadata": {"title": "PU-DetNet: Deep Unfolding Aided Smart Sensing Framework for Cognitive Radio", "authors": "[{\"first\":\"Brijesh\",\"last\":\"Soni\",\"middle\":[]},{\"first\":\"Dhaval\",\"last\":\"Patel\",\"middle\":[\"K.\"]},{\"first\":\"Sanket\",\"last\":\"Shah\",\"middle\":[\"B.\"]},{\"first\":\"Miguel\",\"last\":\"L\u00f3pez-Ben\u00edtez\",\"middle\":[]},{\"first\":\"Siddhartan\",\"last\":\"Govindasamy\",\"middle\":[]}]", "venue": "IEEE Access", "journal": "IEEE Access", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Spectrum sensing in cognitive radio (CR) paradigm can be broadly categorized as analytical-based and data-driven approaches. The former is sensitive to model inaccuracies in evolving network environment, while the latter (machine learning (ML)/deep learning (DL) based approach) suffers from high computational cost. For devices with low computational abilities, such approaches could be rendered less useful. In this context, we propose a deep unfolding architecture namely the Primary User-Detection Network (PU-DetNet) that harvests the strength of both: analytical and data-driven approaches. In particular, a technique is described that reduces computation in terms of inference time and the number of floating point operations (FLOPs). It involves binding the loss function such that each layer of the proposed architecture possesses its own loss function whose aggregate is optimized during training. Compared to the state-of-the-art, experimental results demonstrate that at SNR $= -10$ dB, the probability of detection is significantly improved as compared to the long short term memory (LSTM) scheme (between 39% and 56%), convolutional neural network (CNN) scheme (between 45% and 84%), and artificial neural network (ANN) scheme (between 53% and 128%) over empirical, 5G new radio, DeepSig, satellite communications, and radar datasets. The accuracy of proposed scheme also outperforms other existing schemes in terms of the F1-score. Additionally, inference time reduces by 91.69%, 90.90%, and 93.15%, while FLOPs reduces by 62.50%, 56.25%, 64.70% w.r.t. LSTM, CNN and ANN schemes, respectively. Moreover, the proposed scheme also shows improvement in throughput by 56.39%, 51.23%, and 69.52% as compared to LSTM, CNN and ANN schemes respectively, at SNR $= -6$ dB.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/access/SoniPSLG22", "doi": "10.1109/access.2022.3206814"}}, "content": {"source": {"pdf_hash": "4938e9e68bccf5efeea2cf3ce52874bedaaed998", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/09893119.pdf", "status": "GOLD"}}, "grobid": {"id": "0205389a199aec1353197cb24ca4e78f46c8b9f5", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/4938e9e68bccf5efeea2cf3ce52874bedaaed998.txt", "contents": "\nPU-DetNet: Deep Unfolding Aided Smart Sensing Framework for Cognitive Radio\n\n\nBrijesh Soni \nDepartment of Engineering\nBoston College\n02467BostonMAUSA\n\nDhaval K Patel \nSchool of Engineering and Applied Science\nAhmedabad University\n380009AhmedabadIndia\n\nMember, IEEESanket B Shah \nDepartment of Computer Science\nSan Francisco State University\n94132San FranciscoCAUSA\n\nMiguel L\u00f3pez-Ben\u00edtez \nDepartment of Electrical Engineering and Electronics\nUniversity of Liverpool\nL69 3BXLiverpoolU.K\n\nARIES Research Centre\nAntonio de Nebrija University\n8015MadridSpain\n\nANDSiddhartan Govindasamy \nDepartment of Engineering\nBoston College\n02467BostonMAUSA\n\nPU-DetNet: Deep Unfolding Aided Smart Sensing Framework for Cognitive Radio\n10.1109/ACCESS.2022.3206814Received 24 August 2022, accepted 12 September 2022, date of publication 15 September 2022, date of current version 23 September 2022.Corresponding author: Brijesh Soni (sonib@bc.edu) The work of Dhaval K. Patel was supported in part by the Department of Science and Technology-Gujarat Council of Science and Technology (DST-GUJCOST) under Grant GUJCOST/STI/2021-22/3916.\n\n\ngenerally trained, tested and deployed on an environment 92 powered by a computationally equipped graphics processing 93 unit (GPU). The time taken to produce outputs completely 94 depends upon the specifications and robustness of the hard-95 ware. This implies that devices with lesser efficiency and 96 capacity are bound to face difficulties in deploying ML/DL 97 frameworks effectively. Especially for network architectures 98 where it is envisaged that there would be massive devices 99 with low computational abilities, for instance machine-type 100 communications, low cost sensors, and edge devices (also 101 included in the 3rd generation partnership project (3GPP) 102 release-14 and to its subsequent versions [32]), the implemen-103 tation and usage of a conventional ML/DL framework could 104 be rendered less useful [33]. 105 To overcome the aforementioned shortcomings of both: the 106 analytical and data-driven approaches, the concept of deep 107 unfolding was introduced in [34] which aims at simultane-108 ously harvesting the strength of both the approaches. Given 109 an analytical-based approach, one unfolds the iterations of 110 a derived algorithm into a layer-wise structure analogous to 111 an ML/DL architecture such that each iteration is consid-112 ered a layer and an algorithm is called a network [35]. This 113 approach combines the expressive power of a conventional 114 deep network with the explainability of an analytical-based 115 approach [36], [37]. There have been few recent works in the 116 literature which have utilized deep unfolding techniques. For 117 instance, the work in [38] proposed to compute the bit error 118 rate for MIMO systems using alternating direction method 119 of multipliers (ADMM) unfolding, while [33] attempted 120 via iterative algorithm induced deep unfolding. Moreover, 121 MIMO detection using deep unfolding technique was studied 122 in [39]. The work in [40] focused on the deep unfolding 123 for compressive sensing. A comprehensive survey of deep 124 unfolding for wireless communications can be found in [41]. 125 As far as spectrum sensing is concerned, the detection 126 performance needs to be accurate as well as computationally 127 efficient. Inspired by the fact that the future wireless networks 128 is envisaged to have massive machine-type communications, 129 as included in 3GPP release-14 and its subsequent versions; 130 the aforementioned shortcomings of the data-driven approach 131 would further add challenges in sensing for devices with low 132 computational abilities. In this context, the key objective of 133 this work is to design a deep unfolding aided smart sensing 134 framework, which to the best of the authors' knowledge is 135 yet to be reported in the literature. A deep unfolding scheme 136 alongside the architectural innovations presented performs 137 spectrum sensing in a computationally inexpensive manner 138 while also yielding promising results, especially in the low 139 SNR regime. The key contributions of this work can be summarized as: 142 \u2022 Firstly, we propose a novel architecture namely the pri-143 mary user detection network (PU-DetNet), where the 144 approach is to iteratively reduce the error between esti-145 mation (classification) and ground truth by unfolding 146 Section VI concludes this work.\n\n\n188\n\nNotations: Boldface uppercase letters represent matrices.\n\n\n189\n\nBoldface lowercase represent vectors. Raw outputs (pre-190 activation) are denoted as (\u00b7) . Transpose is denoted as (\u00b7) T .\n\n\n191\n\nThe i th data sample is denoted as (\u00b7) i and the truth label  The binary hypothesis can be written as:  Fig. 1 shows the generic deep unfolding framework and 212 the paper flow. Given an analytical-based approach, one 213 unfolds the iterations of a derived algorithm into a layer-wise 214 structure analogous to an ML/DL architecture such that each 215 iteration of an algorithm is computed by a different layer 216 in the unfolded architecture [35]. To form such a model, 217 an iterative algorithm is derived and trainable parameters are 218 identified which form the basis of the learning architecture. 219 Instead of optimizing a generic neural network, we untie 220 the trainable parameters of the model across layers to create 221 a more flexible network. The resulting architecture can be 222 trained discriminatively to obtain accurate inference within 223 a fixed network size. This approach combines the expressive 224 power of a conventional DL method with the explainability 225 of an analytical-based approach.\n202 H 0 : y(t) = w(t) 203 H 1 : y(t) = h(t)x(t) + w(t),(1)\n\n226\n\n\nB. ITERATIVE APPROACH TO PU DETECTION\n\n\n227\n\nThe variables used in this paper are listed in Table 1. The 228 objective is to derive an expression that aims at iteratively 229 VOLUME 10, 2022 reducing the error of estimation. 1 The error is estimated and 230 reduced in an iterative manner. Mathematically, it can be 231 expressed as:\n232 y k = [y k\u22121 \u2212 \u03b4 k e k ] ,(2)\n\n233\n\nwhere y k is the estimation in the k th iteration, y k\u22121 is the 234 estimation in the (k \u2212 1) th iteration with respect to the whole 235 signal dataset, \u03b4 k is a tunable scaling parameter, e k is the 236 error observed in the k th iteration, and [\u00b7] is a non linear 237 projection operator. To define the error e k in (2), we first 238 define the error for a single data sample:\n239 e ik = y t i \u2212 \u03b8 T k x i ,(3)\nwhere e ik is the error of k th iteration on i th data sample, y t i is 241 the i th true label, x i is i th the data sample and \u03b8 T k represents 242 the trainable parameters during the k th iteration. For the entire 243 dataset, the vectorized form can be expressed as:\n244 e k = y t \u2212 \u03b8 T k X,(4)\n\n245\n\nwhere e k , y t are the vector forms of their respective variables 246 and X represents the entire dataset. However, the estimated 247 error e k is imperfect as its value depends upon the size of the 248 dataset. Hence, the error is further normalized as:\n249 e k = y t \u2212 \u03b8 T k X n ,(5)\n\n250\n\nwhere n is the number of total samples in the dataset. On sub-251 stituting (5) in (2), we obtain:  given as: \n252 y k = y k\u22121 \u2212 \u03b4 k y t \u2212 \u03b8 T k X n .(6)271 z k = ReLU \uf8eb \uf8ed W 1k \uf8ee \uf8f0 x v k\u22121 y k\u22121 \uf8f9 \uf8fb + b 1k \uf8f6 \uf8f8 (7) 272 v = W 2k z k + b 2k (8) 273 y = W 3k z k + b 3k (9) 274 v k = \u03b1 \u00b7 v + (1 \u2212 \u03b1)v k\u22121 (10) 275 y k = \u03b1 \u00b7 ReLU(y) + (1 \u2212 \u03b1)y k\u22121 (11) 276\u03b8 k = {W 1k , b 1k , W 2k , b 2k , W 3k , b 3k , \u03b4 k } K k=1\n. 280 When such k iterations are unfolded, a DL architecture 281 with k layers analogous to conventional deep network is 282 formed, along with the explainability of an analytical based 283 approach. Moreover, every layer has a unique set of trainable 284 weights and biases. Fig. 3 describes the structural relation-285 ship between the input nodes, the hidden nodes, and the 286 output nodes of a single layer of PU-DetNet. In particular, 287 Fig. 3(a) describes the process of obtaining the propagation 288 vector v k of a given layer, while Fig. 3(b) describes how a 289 layer computes y k . As seen in both figures, the input sequence 290 of nodes receives as its input the spectrum dataset (x), the 291 predicted output provided by the previous layer (y k\u22121 ), and 292 the propagation vector of the previous layer (v k\u22121 ). The archi-293 tecture uses a sequence of hidden nodes z k with parameters 294 W 1k , b 1k to expand upon the knowledge provided by the input 295 nodes. Furthermore, the propagation vector v k is obtained 296 that passes on the inference obtained from layer k to layer 297 k + 1. After obtaining v k , the architecture obtains the layer's 298 estimated output y k . From Fig. 2 and Fig. 3, it can be noted 299 that the intermediate outputs of each layer v k and y k are 300 obtained via different sets of weights and biases: (W 2k , b 2k ) 301 and (W 3k , b 3k ), respectively. The output y k of the k th layer is 302 also used to calculate the loss value of layer k which further 303 contributes to the aggregate loss function as described in the 304 following subsection.  \nl nk = y t n \u00b7 log(P(y n ) k ) + (1 \u2212 y t n ) \u00b7 log(1 \u2212 P(y n ) k ), (12) 315\nwhere y t n is the ground truth of n th data sample and P(y n ) k is 316 the probability of y n being true, i.e., the estimated output of 317 the k th layer of architecture.\n\n\n318\n\nDuring the training part, learning architectures calculate 319 the loss function of a specific portion of the dataset at once.\n\n\n320\n\nIn case of batch gradient descent, the architecture calculates 321 the loss value for the entire dataset as follows:\n322 l k = 1 N \u00b7 N n=1 l nk = 1 N \u00b7 N n=1 [y t n \u00b7 log(P(y n ) k ) 323 + (1 \u2212 y t n ) \u00b7 log(1 \u2212 P(y n ) k )]. (13) 324\nUnlike neural networks where the loss function is calculated 325 using the output of just the final layer, PU-DetNet is designed 326 such that it accounts for the loss of every single layer during 327 the training process. Therefore, we use the following loss 328 function which combines the losses of all layers as follows: 329\nl = 1 K K k=1 l k = 1 K 1 N K k=1 N n=1 [y t n \u00b7 log(P(y n ) k ) 330 + (1 \u2212 y t n ) \u00b7 log(1 \u2212 P(y n ) k )]. (14) 331\nThe proposed PU-DetNet architecture aims to learn the 332 underlying structure of the PU detection problem in 333 VOLUME 10, 2022 for i \u2190 1 to data_size do 5: X Energies \u2190 Append(Energy(X Noisy , i, data_size)) 6: labels \u2190 Append (1) 7:\n\nX Energies \u2190 Append(Energy(AWGN, i, data_size)) 8:\n\nlabels \u2190 Append(0) 9: end for 10: end for 11: return X Energies , labels a computationally efficient manner, without compromising 334 the accuracy. Hence, the architecture is designed to be deep 335 in layers, such that it can capture the complicated patterns 336 of a highly noisy dataset, i.e., even at low SNR regimes. One conventional design of the loss function is described in (14). 350 The effect of binding the loss function of each layer is that 351 the every layer is constrained to be optimized and be equally   We divide the processed data into train (X train , y train ) and 379 test (X test , y test ) datasets. The parameters of the architecture 380 are randomly initialized and updated iteratively. The detailed 381 process of training the PU-DetNet architecture is described 382 in Algorithm 2. The function EstimateOutput() is based on 383 equations (7) -(11), while the function CalculateBinded-384 Loss() is based on (14). The function UpdateParameters() 385 is an optimization function and in the case of PU-DetNet, 386 it is chosen to be Adam Optimizer [44] due to its lower 387 computational cost and lower dependence on hyperparameter 388 tuning. 389 2) TESTING PHASE 390 The optimal parameters obtained after the process of training 391 the model collectively represent the final architecture which 392 is ready to be tested. While testing, the number of correct 393 and incorrect estimations (classifications) are recorded and 394 the performance metrics probability of detection (P d ) and 395 probability of false alarm (P f ) are calculated. The detailed 396 process of testing the PU-DetNet architecture is described 397 in Algorithm 3.\n\n\n398\n\nTo evaluate the ability of the proposed PU-DetNet archi-399 tecture to detect the PU signal correctly, we compute the 400 performance metrics P d and P f as:      Table 3. 425 This dataset contains more than 1,000,000 samples per band. 426 The detection of 5G signals is relevant in spectrum sharing 428 scenarios such as those enabled by the 5G NR -unlicensed 429 technology, where the presence of 5G NR waveforms in 430 unlicensed bands needs to be detected. We used MATLAB 431 5G toolbox in generating 5G waveforms which are compliant 432 with 3GPP Release 15 [46]. Test models from the waveform 433 generator were used to obtain signal data from four different 434 configurations, each having a different set of parameters as 435 shown in Table 4. This dataset contains 153,600 samples for 436 each configuration. The publicly available DeepSig dataset [47] (RADIOML 439 2016.10A) contains signal data consisting of 11 modulations 440 (8 digital, 3 analog). This dataset was first released at the 441 6th annual GNU radio conference and is useful in the con-442 text of this work to assess the performance of the proposed 443 PU-DetNet scheme with commonly used signal modulations. 444 While typically used for modulation classification, we utilize 445 VOLUME 10, 2022 To obtain the dataset, an end-to-end DVB-S2 simulation with 464 RF impairments and corrections was used. The parameters 465 of the configuration are described in Table 5. This dataset 466 contains 800,000 samples.  \n401 P d = No.Throughput = (T \u2212 T s ) T \u00d7 B \u00b7 log 2 (1 + SNR),(17)\n\nV. EXPERIMENTAL RESULTS\n\n\n483\n\nIn this section, we describe the experiments comparing the   \n\n\nA. MODEL EVALUATION\n\nIn learning architectures, performance is often evaluated  Table 7. 523 Table 7 shows the value of P d obtained from a model where   layers i.e., in the last layers. As the number of training layers 544 decrease, the overfitting decreases and the optimum shifts 545 towards higher number of testing layers. The training layers 546 that form a backward feedback system with the aid of loss 547 binding are not observed to be necessary in making a decision 548 regarding the presence of PU. Thus, the layers succeeding 549 the layer that was used while testing were discarded and a 550 computationally efficient system was formed. 551 Fig. 6 shows the plot of accuracy v/s epochs for the 552 PU-DetNet architecture in classifying correctly over the train 553 and test data. An observation from this figure can be made 554 that the accuracies remain at 50% till around 350 epochs. 555 It can be inferred that the model does not learn much about 556 the underlying structure of the data and hence displays a 557 random behaviour on these binary labelled data. However, 558 after around 350 epochs the accuracies spike and the model 559 starts learning the underlying structure of the dataset as the 560 training accuracy immediately rises up to 85% and the test 561 accuracy rises up to 65%. With increasing epochs, the gap 562 VOLUME 10, 2022   between train and test accuracy slowly decreases as they con-  followed by the fully connected (FC) layer. The number of 578 Kernels (n ker ) considered was 3 with shape (s ker ) of each 579 kernel as 4 (can also be viewed as 4 \u00d7 1 due to 1D CNN). For 580 fair evaluation and comparison, all the schemes were trained, 581 tested on same datasets (for various radio technologies as 582 discussed in Section-IV). Hyperparameters were tuned to 583 ensure optimum results as summarized in Table 8. 584 Fig. 8 shows the comparison of P d on the empirical testbed 585 dataset. An average gain of 42.04%, 57.42% and 78.03% 586 is observed at \u221210dB with respect to LSTM, CNN and 587 ANN schemes respectively on this dataset. Fig. 9 shows the 588 comparison with respect to the 5G simulated dataset and an 589 average gain of 47.43%, 63.74% and 86.11% is observed 590 at \u221210 dB with respect to LSTM, CNN and ANN schemes 591 respectively. Fig. 10 validates the PU-DetNet scheme on the 592 DeepSig dataset and an average gain of 56.03%, 84.66% and 593  128.32% is observed at -10 dB with respect to LSTM, CNN 594 and ANN schemes respectively. Fig. 11 shows the compari-   Table 9 shows the comparison of precision, recall and 616 F1 score [51] observed for the proposed scheme and the  benchmark schemes for data comprising of samples with 618 SNR = \u22125 dB. Values marked in boldface represent the opti-619 mal value for each set of comparison. In terms of precision 620 and recall, the proposed PU-DetNet scheme provides the best 621 accuracy in most cases; in those cases where it does not, the 622 achieved accuracy is very similar to the highest attained value. 623 F1 score is commonly used to evaluate the accuracy of an 624 algorithm and can be interpreted as a weighted average of 625 the precision and recall. It can be appreciated from the table 626 that the proposed PU-DetNet scheme outperforms the other 627 state-of-the-art sensing schemes in terms of F1 score, thus 628 highlighting its ability to provide more accurate results.\n\n\n629\n\n\nC. COMPUTATIONAL ANALYSIS\n\n\n630\n\nIn addition to the detection performance, we perform the 631 computational analysis of the proposed PU-DetNet scheme 632 and the baseline models. The number of FLOPs is one of 633 the measure of computation that describes the total number 634 of instructions a processor has to execute to perform the 635 specific operation. FLOPs calculation can be done by ana-636 lyzing the structure of a model and the final value depends 637 on the hyperparameters of the model. Table 10 analyzes the 638  TABLE 9. Precision, Recall and F1 score comparison of the proposed PU-DetNet scheme with the baseline models on considered datasets for SNR = \u22125 dB.   Table 10.    \n\n\nunprecedented empirical success, such techniques usually 87 suffer from the requirement of exhaustive training, computa-88 tionally large training data, explainability of trained ML/DL 89 model, numerous trainable parameters, and high computa-90 tional cost. Furthermore, such ML/DL aided frameworks are 91\n\n\n140B. CONTRIBUTIONS OF THIS WORK141\n\n201 FIGURE 1 .\n2011corresponding to the same is denoted as (\u00b7) t i . Variables cor-193 responding to the k th layer of the considered architecture are 194 referred to as (\u00b7) k . 195 II. SYSTEM MODEL AND PRELIMINARIES OF DEEP 196 UNFOLDING 197 A. CONSIDERED SYSTEM MODEL 198 The problem of PU detection can be formulated as a binary 199 classification problem. The secondary user (SU) detects the 200 presence of the PU from the signal it receives, defined as y(t). Generic deep unfolding framework and the paper flow.\n\nFig. 2\n2and expressions (7)-(11) describe a layer of the 277 proposed PU-DetNet architecture, where the dashed box 278 represents a single layer of the architecture with the train-279 able parameters\n\n305 FIGURE 2 .\n3052Architecture of a single layer of PU-DetNet.\n\nFIGURE 3 .\n3Nodal structure of a single layer PU-DetNet. B. DESCRIPTION OF THE LOSS FUNCTION 306 A loss function is typically used with gradient descent to 307 update trainable parameters of the model, such that the value 308 of the loss function reduces in successive epochs of the train-309 ing process. Since the problem under consideration is binary 310 classification (i.e., whether PU is present or not), the intuitive 311 choice of the loss function is binary cross-entropy (BCE). The 312 BCE between the ground truth and the architecture output for 313 one data sample is described as [42]:314\n\n\n337 common problem of deep architectures is increased computa-338 tional cost. To overcome the same, we incorporate the concept 339 of loss binding where layers of the architecture are bound 340 in a way such that their outputs and hence their losses are 341 tied together and thus behave similarly in terms of estimation. 342 In implementation, we add the losses of all layers to obtain an 343 aggregate loss of the whole architecture. This aggregate loss 344 is further used by gradient descent like optimization methods. 345 This idea was inspired by the concept of auxiliary classi-346 fiers presented in GoogleNet [43] that aimed to discriminate 347 the lower layers in the network such that intermediate lay-348 ers could be used directly as classifiers. Due to this, a non 349\n\n\n352 close to the ground truth. This effect further leads to infer that 353 even though the training is performed on a deep architecture, 354 one can use outputs from even the shallower layers of the 355 model. In implementing such idea where only shallower lay-356 ers are required while testing, we observe the need for a high 357 number of layers during training. Theoretically, the higher 358 number of training layers can help build a more descriptive 359 network as the number of trainable parameters increases. Due 360 to the loss binding, the layers succeeding any given layer 361 form a backward feedback system, as the optimization of the 362 deeper layers can affect the optimization of preceding layers 363 as well. This is analyzed and comprehensively described in 364 the numerical results section.\n\n\n365C. PROCESSING THE ARCHITECTURE366    In this subsection, we first describe the pre-processing of 367 the data in order to make it suitable for training and testing368 of the proposed PU-DetNet architecture. As described in 369 Algorithm 1, AWGN noise with power \u03c3 2 w = \u03c3 2 X Signal /SNR is 370 generated and added to the signal at each SNR, which forms 371 Algorithm\n\n\n416A. EMPIRICAL TEST-BED SETUP417    We deployed an empirical test-bed setup on the roof-top of418 the School of Engineering and Applied Science, Ahmedabad 419 University for spectrum data acquisition, the details of which 420 are reported in [17], [26], and [27], omitted here for the 421 sake of brevity. The empirical measurement setup is shown 422 in Fig. 4. The aforementioned setup was used to capture raw 423 signal data of four bands: FM, GSM, DCS, and UHF. The 424 specifications of signal data captured are described in\n\nFIGURE 4 .\n4Empirical measurement test-bed setup [26]. B. 5G NEW RADIO SIMULATED DATASET 427\n\n\nsoftware tool [49] provides a radio frequency (RF) 469 dataset generator for incumbent signals in the 3.5 GHz 470 citizens broadband radio service (CBRS) band, which is 471 another practical scenario where detection and sensing is 472 relevant. The pulse modulation types for the radar signals 473 and their parameters are selected based on national telecom-474 munications and information administration (NTIA) test-475 ing procedures for environmental sensing capability (ECS) 476 certification. Using the generator provided, two simulated 477 radar waveforms with varying parameters were obtained to 478 validate the PU-DetNet scheme. The parameters of the con-479 figurations set up to obtain these waveforms are described in480\n\n\nproposed PU-DetNet scheme and other state-of-the-art ML485 based sensing schemes. The training and testing of the pro-486 posed PU-DetNet architecture were performed with the aid 487 of the Tensorflow library [50]. For processing the proposed 488\n\n\nby the value of a loss function which describes the behaviour 501 of the model with respect to the ground truth. The loss func-502 tion of the PU-DetNet architecture is described in(14). This 503 loss is calculated and then plotted with respect to epochs,504 i.e., the number of times a dataset is passed through the 505 architecture during the training phase. 506 It can be observed in Fig. 5 (a) that the train and test loss 507 decrease with the number of epochs. An elbow-shaped curve 508 is obtained with a cut-off at around 100 epochs. This states 509 that the loss reduction slows down after 100 epochs. The 510 reduction in loss over epochs suggests that with increasing 511 training, the model performs better on data. It can also be 512 seen that the loss over test data remains slightly higher than 513 the loss over train data which is quite intuitive given the fact 514 that test data were unseen by the model when this result was 515 obtained. Fig. 5 (b) demonstrates the PU-DetNet's property 516 of loss binding as described in Section III. It can be observed 517 that the loss value quickly drops and almost becomes constant 518 after layer 2. Thus, we can infer that after the architecture 519 is completely trained on the dataset, the losses across the 520 layers are bound to have similar values. However, we would 521 like to highlight that all the layers are necessary for training, 522 as confirmed through\n\n\nfor a given value in the table, the column index represents the 525 number of layers present in the architecture while training, 526 and the row index represents the number of layers used 527 for testing. The value indicated in boldface represents the 528 optimum value of P d for a given number of training layers.\n\n529 543 FIGURE 6 .\n5436We can notice that for a model with 100 training layers, the 530 optimal output (P d = 0.9755) is obtained at shallower layer 531 (layer 5 in this case). The need for higher number of layers 532 while training is thus clearly observed inTable 7. When 50 or 533 100 layers are used, the optimum output is provided by the 534 5th layer, however, this does not mean that the network could535 achieve the same level of performance with a lower number 536 of layers for training, since in the case of a network with only 537 5 layers; the accuracy (P d = 0.7564) is significantly lower 538 than in the case of 100 layers (P d = 0.9755). This is because 539 feedback across all layers helps optimize the performance 540 of shallower layers. However, output from the deep layers 541 tends to get overfitted (due to more testing layers) and hence 542 high generalization error (or lower performance) at the deep Comparison of train and test accuracies with respect to epochs for (Empirical dataset, FM broadcasting band, SNR = -5 dB).\n\nFIGURE 7 .\n7P d v/s SNR for the proposed PU-DetNet scheme at various values of P f (Empirical testbed dataset, FM band).\n\nFIGURE 8 .\n8Comparison and validation of detection probability on the empirical test-bed data set for the considered spectrum sensing schemes: proposed PU-DetNet, LSTM-based sensing [26], CNN-based sensing [22], and ANN-based sensing [17] (P f \u2248 0.05).\n\nFIGURE 9 .\n9Comparison and validation of detection probability on 5G simulated Dataset for the considered spectrum sensing schemes: proposed PU-DetNet, LSTM-based sensing [26], CNN-based sensing [22], and ANN-based sensing [17] (P f \u2248 0.05).\n\nFIGURE 10 .\n10Comparison and validation of detection probability on DeepSig dataset for the considered spectrum sensing schemes: proposed PU-DetNet, LSTM-based sensing [26], CNN-based sensing [22], and ANN-based sensing [17] (P f \u2248 0.05).\n\n\n563verge. This indicates that with increasing epochs, the model's 564 ability to generalize improves on unseen data. Furthermore,565    we observe the probability of the model to detect the presence 566 of PU in spectrum with respect to the SNR value for varying567    values of P f inFig. 7.\n\n\nof PU-DetNet is compared with the state-571 of-the-art baseline models: The LSTM [26], CNN [22] and 572 the ANN [17]. For LSTM and ANN schemes, the models 573 mentioned in the base papers were implemented. For CNN 574 based scheme, we adopted the 1D-CNN model due to the 575 one dimensional structure of data. The model consist of 576 two convolutional layers (CL) with ReLu activation function 577\n\nFIGURE 11 .\n11Comparison and validation of detection probability on satellite communications dataset for the considered spectrum sensing schemes: proposed PU-DetNet, LSTM-based sensing [26], CNN-based sensing [22], and ANN-based sensing [17] (P f \u2248 0.05).\n\n\n595 son with respect to the satellite communications dataset and 596 an average gain of 39.21%, 45.38% and 53.37% is observed 597 at \u2212-10 dB with respect to LSTM, CNN and ANN schemes 598 respectively. Furthermore, Fig. 12 provides the comparison 599 with respect to the radar dataset and an average gain of 600 40.06%, 58.50% and 63.86% is observed at -10 dB with 601 respect to LSTM, CNN and ANN schemes respectively. 602 We can notice that the proposed scheme consistently out-603 performs the benchmarks scheme in terms of P d . Although 604 varying with different datasets, it can be said that the pro-605 posed PU-DetNet scheme can yield an acceptable value of 606 (P d = 0.9) at 2 dB to 6 dB of SNR lesser than the state-of-607 the-art schemes.\n\n608 Fig\n608. 13 shows the comparison of the receiver operating 609 characteristic (ROC) curves. It can be observed that for a 610 given P f , the PU-DetNet scheme yields a higher P d than 611 the other baseline schemes. It is also observed that for lower 612 values of SNR, all schemes yield a lower P d for a given P f 613 but the proposed method still outperforms the state-of-the-art 614 LSTM, CNN and ANN schemes.615\n\n617 FIGURE 12 .\n61712Comparison and validation of detection probability on radar dataset for the considered spectrum sensing schemes: proposed PU-DetNet, LSTM-based sensing [26], CNN-based sensing [22], and ANN-based sensing [17] (P f \u2248 0.05).\n\nFIGURE 13 .\n13ROC comparison of proposed scheme with LSTM-based sensing [26], CNN-based sensing [22], and ANN-based sensing [17] at SNR = \u221210 dB and SNR = \u2212 20 dB (DeepSig Dataset, BPSK Modulation).\n\nFIGURE 14 .\n14Throughput performance of the considered spectrum sensing methods: proposed PU-DetNet scheme, CNN [22], LSTM [26], and ANN-based sensing schemes [17] over various datasets. FLOPs calculation to compute the total number of FLOPs 639 for each scheme. In addition to the number of FLOPs, the 640 time each scheme consumed for training and testing were 641 also observed. As mentioned before, all the schemes were 642 processed on a 12GB NVIDIA Tesla K80 GPU offered by 643 Google Colab. Considering hyperparameters from Table 8, 644 it is intuitive that due to its deep nature the PU-DetNet 645 scheme takes more time than ANN and CNN in training. 646 However, PU-DetNet still manages to train completely in 647 less time than LSTM as observed in Table 10. It is worth 648 mentioning that training is often performed once before the 649 network is deployed in real system for operation. There-650 fore, a high training time is not necessarily inconvenient, 651 in particular if it allows a better performance/accuracy and 652 even shorter execution time as demonstrated by the inference 653 time. Moreover, it can be observed from Table 10 that the 654 number of FLOPs for proposed PU-DetNet scheme reduces 655 by 62.50%, 56.25%, 64.70% w.r.t. LSTM, CNN and ANN 656schemes, respectively. Although the FLOPs account for the 657 number of arithmetic operations undergone to perform a task, 658 the actual time consumed by a scheme may vary depending 659 upon biases, non linear activation functions and the complex-660 ity of the type of arithmetic/matrix operation. We can also 661 notice that the inference time (per single sample) reduces by 662 91.69%, 90.9% and 93.15% over the LSTM, CNN and ANN 663 schemes respectively. Hence PU-DetNet significantly outper-664 forms the baseline schemes not only in terms of detection 665 performance but also in terms of computation. The advan-666 tage is inevitably due to the combined analytical-based and 667 data-driven approach in the unfolded architecture. We would 668 like to highlight that although the simple ML analytical-based sensing approaches are also reported 675 to be outperformed by the data-driven approaches in[26]    676 and[27], and hence not shown in this work for the sake of subsection, we demonstrate the application of the 680 proposed scheme. It is intuitive to note that the sensing time681 (time employed to sense PU) is analogous to the inference 682 time of the ML architecture, as enlisted in the last column 683 of Table 10. Fig. 14 shows the plot of throughput v/s SNR 684 validated over various datasets for the proposed PU-DetNet, 685 LSTM and ANN based sensing schemes (with T = 0.1ms, 686 and B as per the considered dataset). We can notice that the 687 proposed PU-DetNet has an average gain of 56.39%, 51.23%, 688 and 69.52% as compared to LSTM, CNN and ANN scheme 689 respectively, at SNR = \u22126 dB. The gain in throughput is due 690 to the fact that the inference time for proposed PU-DetNet 691 scheme is much shorter (and hence quicker detection) as 692 compared to other schemes in\n\n\nwork, a deep unfolding approach is introduced for 695 spectrum sensing problem that harvests the strength of both: 696 analytical-based and data-driven approaches. The Primary 697 User-Detection Network (PU-DetNet) is proposed to over-698 come the shortcomings of ML/DL frameworks like high 699 computational cost. A unique technique is described which 700 involves binding the loss function across all layers that 701 helps in reducing the computational cost significantly. The 702 proposed scheme is thoroughly evaluated on five different 703 datasets. The proposed scheme outperforms state-of-the-704 art spectrum sensing schemes in all cases. Furthermore, 705 it was observed that at SNR = \u221210 dB, probability of 706\n\n802 [\n80223] J. Xie, C. Liu, Y.-C. Liang, and J. Fang, ''Activity pattern aware spectrum 803 sensing: A CNN-based deep learning approach,'' IEEE Commun. Lett., 804 vol. 23, no. 6, pp. 1025-1028, Jun. 2019. 805 [24] W. Lee, M. Kim, and D. Cho, ''Deep cooperative sensing: Cooperative 806 spectrum sensing based on convolutional neural networks,'' IEEE Trans. 807 Veh. Technol., vol. 68, no. 3, pp. 3005-3009, Mar. 2019. 808 [25] Q. Cheng, Z. Shi, D. N. Nguyen, and E. Dutkiewicz, ''Sensing OFDM 809 signal: A deep learning approach,'' IEEE Trans. Commun., vol. 67, no. 11, 810 pp. 7785-7798, Nov. 2019. 811 [26] B. Soni, D. K. Patel, and M. L\u00f3pez-Ben\u00edtez, ''Long short-term memory 812 based spectrum sensing scheme for cognitive radio using primary activity 813 statistics,'' IEEE Access, vol. 8, pp. Surrey, U.K. In 2013, he became a Lecturer (Assistant Profes-945 sor) at the Department of Electrical Engineering and Electronics, University 946 of Liverpool, U.K., and was promoted to a Senior Lecturer (Associate 947 Professor), since 2018. His research interests include wireless communi-948 cations and networking, with special emphasis on mobile communications 949 and dynamic spectrum access in cognitive radio systems. He is/has been the 950 Principal Investigator or a Co-Investigator of research projects funded by 951 the EPSRC, British Council and Royal Society, and has been involved in 952 the European-funded projects AROMA, NEWCOM++, FARAMIR, QoS-953 MOS, and CoRaSat. He has been a member of the Organising Committee 954 for the IEEE WCNC International Workshop on Smart Spectrum (IWSS 955 2015-2020). He is an Associate Editor of IEEE ACCESS, IET Communica-956 tions, and Wireless Communications and Mobile Computing. Please visit 957 http://www.lopezbenitez.es for details. 958 SIDDHARTAN GOVINDASAMY (Member, 959 IEEE) received the bachelor's, master's, and Ph.D. 960 degrees from the Massachusetts Institute of Tech-961 nology (MIT), in 1999, 2000, and 2008, respec-962 tively. At MIT, he worked on a master's thesis 963 on speech enhancement algorithms in partnership 964 with Qualcomm Inc.; and the Ph.D. thesis on ad-965 hoc wireless networks with multi-antenna devices. 966 From 2000 to 2003, he was a DSP Engineer and 967 later a Senior DSP Engineer at Aware Inc., where 968 he worked on developing broadband modem technology. From 2008 to 2020, 969 he was an Assistant Professor and later an Associate Professor of electrical 970 and computer engineering at the Olin College of Engineering, Needham, 971 MA, USA, where he conducted research on large multiple-input multiple-972 output (MIMO) systems and optical wireless communications. He joined the 973 Department of Engineering, Boston College, as a Founding Faculty Member, 974 in Fall 2020, where he is a Professor of engineering. He is the coauthor 975 of the textbook Adaptive Wireless Communications: MIMO Channels and 976 Networks (Cambridge University Press, 2013). His research interests include 977 in large MIMO systems and signal detection and processing.\n\n\nthe iterations of the algorithm. When such k iterations schemes in terms of the F1-score. Moreover, compared 173 to the baselines: LSTM, CNN, and ANN based sensing 69.52% as compared to LSTM, CNN and ANN scheme respectively, at SNR = -6 dB.The remainder of this paper is organized as follows.Section II describes the system model and preliminaries of the 183 deep unfolding framework. The architecture of the proposed PU-DetNet scheme is presented in Section III. Section IV147 \n\nare unfolded, a DL architecture with k layers analogous \n\n148 \n\nto conventional deep network is formed along with the \n\n149 \n\nexplainability of an analytical-based approach. \n\n150 \n\n\u2022 Secondly, a technique is described that involves bind-\n\n151 \n\ning the loss function such that each layer of the pro-\n\n152 \n\nposed architecture possesses its own loss function whose \n\n153 \n\naggregate is optimized. This technique leads to a state \n\n154 \n\nwhere after training, values of the loss functions from \n\n155 \n\nshallow to deep layers become nearly equal. The impli-\n\n156 \n\ncation of this property is that the shallow layers exhibit \n\n157 \n\noptimal performance than the deep layers, hence form-\n\n158 \n\ning the computationally efficient model as compared to \n\n159 \n\ndata-driven approaches. \n\n160 \n\n\u2022 Thirdly, the proposed PU-DetNet scheme is experi-\n\n161 \n\nmentally validated with spectrum data from five differ-\n\n162 \n\nent datasets corresponding to realistic scenarios which \n\n163 \n\nincludes: an empirical test-bed measurement setup, \n\n164 \n\na 5G new radio (NR) dataset, the DeepSig dataset, \n\n165 \n\na satellite communications dataset, and a radar dataset. \n\n166 \n\nThe obtained results show that at SNR = \u221210 dB, \n\n167 \n\nthe probability of detection is improved by a signifi-\n\n168 \n\ncant amount compared to the LSTM approach (between \n\n169 \n\n39% to 56%), CNN approach (45% to 84%) and the \n\n170 \n\nANN approach (between 53% and 128%). Also, the \n\n171 \n\naccuracy of proposed scheme outperforms other existing \n\n172 \n\n174 \n\nschemes, inference time reduces by 91.69%, 90.90%, \n\n175 \n\nand 93.15%, while the number of floating point oper-\n\n176 \n\nations (FLOPs) reduces by 62.50%, 56.25%, 64.70% \n\n177 \n\nrespectively. Furthermore, the proposed scheme shows \n\n178 \n\nan improvement in throughput by 56.39%, 51.23%, and \n\n179 \n\n180 \n\n181 \n\n182 \n\n184 \n\n185 \n\nprovides the description of the considered datasets. Section V \n\n186 \n\ncomprehensively describes the experimental results. Finally, \n\n187 \n\n\n\nTABLE 1 .\n1Variables and their description used in this paper.\n\n\nchannel coefficient. H 0 , the null hypothesis, describes the 208 scenario when only noise is present during the fixed time 209 sensing event, i.e., indicating the absence of PU, while H 1 , 210 the alternate hypothesis, describes the presence of PU.204 \n\nwhere y(t) is the received signal by the SU at a time t, x(t) is 205 \nthe transmitted signal, w(t) is additive white Gaussian noise 206 \nwith zero mean and variance \u03c3 2 \nw , and h(t) is the flat-fading 207 \n211 \n\n\n\nTABLE 2 .\n2Components of the architecture used in this paper.\n\n\n2 Training the Proposed PU-DetNet Scheme Input: X train , y train , epochs Output: Parameters 1: Parameters \u2190 RandomInitialization() 2: for i \u2190 1 to epochs do return Parameters the data for hypothesis (H 1 ). Similarly, for hypothesis (H 0 ), 372 only the AWGN noise is considered. Energy is computed for 373 both hypotheses and labelled accordingly. These processed 374 datasets are further used to compare the performance of the 375 proposed PU-DetNet scheme with the other state-of-the-art 376 schemes.3: \n\ny est \u2190 EstimateOutput(X train , Parameters) \n\n4: \n\nloss \u2190 CalculateBindedLoss(y est ,y train ) \n\n5: \n\nParameters \u2190 UpdateParameters(loss, Parameters) \n6: end for \n7: 377 \n\n1) TRAINING PHASE \n\n378 \n\n\n\n\nFurthermore, in DSA/CR systems, spectrum sensing has 405 direct impact on throughput[45]. The relation between sens-406 ing time (T s ) and the throughput for SU can be expressed as: 407of H 1 samples correctly classified as H 1 \nTotal no. of H 1 samples fed \n(15) 402 \n\nP f = \nNo. of H 0 samples incorrectly classified as H 1 \nTotal no. of H 0 samples fed \n\n403 \n\n(16) 404 \n\n\n\nTABLE 3 .\n3Channels measured in empirical setup and USRP configuration[26].\n\nTABLE 4 .\n4Parameters of the configurations of the 5G-NR test models for data simulation.IV. CONSIDERED DATASETSTo validate the proposed scheme, we have considered data from five different datasets corresponding to signal formats whose detection performance is relevant in several realistic spectrum sharing and coexistence scenarios.where T is the frame duration in DSA/CR networks, and B is \n\n409 \n\nthe bandwidth. These metrics are further used in Section V to \n\n410 \n\ndemonstrate experimental results. \n\n411 \n\nAlgorithm 3 Testing the Proposed PU-DetNet Scheme \n\nInput: X test , y test , Parameters * \nOutput: P d , P f \n1: N \u2190 length(X test ) \n2: Out incorr \u2190 0 \n3: Out corr \u2190 0 \n4: for i \u2190 1 to N do \n\n5: \n\ny est \u2190 EstimateOutput(X test (i),Parameters) \n\n6: \n\nif y est = 1 and y test (i) = 1 then \n\n7: \n\nOut corr \u2190 Out corr + 1 \n\n8: \n\nelse if y est = 1 and y test (i) = 0 then \n\n9: \n\nOut incorr \u2190 Out incorr + 1 \n\n10: \n\nend if \n11: end for \n12: P d \u2190 Out corr \n\nN \n\n13: P f \u2190 Out incorr \n\nN \n\n14: return P d , P f \n\n412 \n\n413 \n\n414 \n\n415 \n\n\n\nTABLE 5 .\n5Parameters of the DVB-S2 simulation.this dataset for PU-detection after processing it as described in Algorithm 1. It should be noted that unlike other mentioned datasets, no noise was added to the DeepSig dataset since it is considered that the AWGN noise is already present in the signal (i.e., for H 1 ) at different SNR. However for H 0 , CR has been proposed to enable spectrum sharing not only in terrestrial but also in satellite communication bands and therefore the performance of spectrum sensing methods with satellite communication signals is relevant as well. We uti-446 \n\n447 \n\n448 \n\n449 \n\n450 \n\nthe AWGN noise with power \u03c3 2 \nw = \u03c3 2 \nX Signal /SNR at each \n\n451 \n\nrespective SNR were generated. Out of the 11 modulations, \n\n452 \n\nsignal data of the modulations BPSK, QPSK, 64-QAM and \n\n453 \n\nGFSK were considered and processed. 128,000 samples per \n\n454 \n\nmodulation scheme were considered. \n\n455 \n\nD. SATELLITE COMMUNICATIONS DATASET \n\n456 \n\n457 \n\n458 \n\n459 \n\n460 \n\nlized MATLAB's satellite communications toolbox [48] that \n\n461 \n\nprovides standards-based tools for designing, simulating, \n\n462 \n\nand verifying satellite communications systems and links. \n\n463 \n\n\n\nTable 6 .\n6This dataset contains 800,000 samples per SNR for481 \n\neach configuration. \n\n482 \n\n\n\nTABLE 6 .\n6Parameters of the simulated radar waveform.FIGURE 5. Behaviour of loss function for FM band with SNR = -5 dB \n(similar trend was observed for other datasets). \n\narchitecture and benchmark architectures, we used a 12GB 489 \nNVIDIA Tesla K80 GPU offered by Google Colab. For train-490 \ning and testing, signal data with SNR values from \u221220 dB to 491 \n\n+4 dB were considered, unless otherwise mentioned. More-492 \nover, to ensure that the model is not biased, equal number 493 \nof data points in both hypotheses were generated. Training 494 \ndataset size was kept approximately 70%, while the remain-495 \ning 30% was used for testing. Moreover, all the results of 496 \nP d v/s SNR are plotted by training the model such that 497 \nP f \u2248 0.05. \n\n\nTABLE 7 .\n7Variation in P d with respect to number of layers used for training (columns) and number of layers used for testing (rows) at SNR = -4 dB, Empirical testbed setup.\n\nTABLE 8 .\n8Hyperparameters of the considered schemes.\n\nTABLE 10 .\n10Computational analysis.\n\n\ndetection is improved by a significant amount compared to the LSTM approach (between 39% to 56%), CNN approach 708 (45% to 84%) and the ANN approach (between 53% and 128%) using empirical, 5G new radio, DeepSig, satellite communications and radar datasets.The accuracy of proposed scheme outperforms other existing schemes in terms of the F1-score. Additionally, inference time reduces 713 by 91.69%, 90.90%, and 93.15%, while FLOPs reduces 714 by 62.50%, 56.25%, 64.70% w.r.t. LSTM, CNN and ANN schemes, respectively. Moreover, the proposed scheme also shows improvement in throughput by 56.39%, 51.23%, and 69.52% as compared to LSTM, CNN and ANN schemes respectively, at SNR = \u22126 dB. This work provides a comprehensive study and offers a computationally efficient detection framework suitable for devices with low computational abilities, as envisaged in the next generation of wireless networks. The authors thank the Department of Engineering-Boston 724 College, Machine Intelligence, Computing and xG Networks 725 (MICxN) Research Laboratory-Ahmedabad University, and 726 the University of Liverpool for providing the infrastructural 727 support. Finally, they also thank the Associate Editor for 728 handling the review of this paper, and anonymous reviewers 729 for their valuable suggestions in improving the quality of this 730 manuscript. cooperative spectrum sensing for non-orthogonal multiple access,'' IEEE Trans. Wireless Commun., vol. 19, no. 9, pp. 5692-5702, Sep. 2020. [21] C. Liu, J. Wang, X. Liu, and Y.-C. Liang, ''Deep CM-CNN for spectrum sensing in cognitive radio,'' IEEE J. Sel. Areas Commun., vol. 37, no. 10, pp. 2306-2321, Oct. 2019. [22] C. Liu, X. Liu, and Y. Liang, ''Deep CNN for spectrum sensing in cognitive radio,'' in Proc. IEEE Int. Conf. Commun. (ICC), May 2019,707 \n\n709 \n\n710 \n\n711 \n\n712 \n\n715 \n\n716 \n\n717 \n\n718 \n\n719 \n\n720 \n\n721 \n\n722 \n\nACKNOWLEDGMENT \n\n723 \n\n731 \n795 \n\n796 \n\n797 \n\n798 \n\n799 \n\n800 \n\n801 \n\npp. 1-6. \n\n\n98744VOLUME 10, 2022   \n\n. H Wymeersch, D Shrestha, C Morais De Lima, V Yajnanarayana, B Richerzhagen, M Furkan Keskin, K Schindhelm, A Ramirez, 734H. Wymeersch, D. Shrestha, C. Morais de Lima, V. Yajnanarayana, 733 B. Richerzhagen, M. Furkan Keskin, K. Schindhelm, A. Ramirez, 734\n\n. A Wolfgang, M Francis De Guzman, K Haneda, T Svensson, 735A. Wolfgang, M. Francis de Guzman, K. Haneda, T. Svensson, 735\n\nIntegration of communication and 736 sensing in 6G: A joint industrial and academic perspective. R Baldemair, S Parkvall, arXiv:2106.13023.738737R. Baldemair, and S. Parkvall, ''Integration of communication and 736 sensing in 6G: A joint industrial and academic perspective,'' 2021, 737 arXiv:2106.13023. 738\n\nSpectrum exploration and 739 exploitation for cognitive radio: Recent advances. J Lunden, V Koivunen, H V Poor, IEEE Signal Process740J. Lunden, V. Koivunen, and H. V. Poor, ''Spectrum exploration and 739 exploitation for cognitive radio: Recent advances,'' IEEE Signal Process. 740\n\n. Mag , 32Mag., vol. 32, no. 3, pp. 123-140, May 2015. 741\n\nBig-data-based intelligent 742 spectrum sensing for heterogeneous spectrum communications in 5G. X Liu, Q Sun, W Lu, C Wu, H Ding, IEEE Wireless Commun. 275X. Liu, Q. Sun, W. Lu, C. Wu, and H. Ding, ''Big-data-based intelligent 742 spectrum sensing for heterogeneous spectrum communications in 5G,'' 743 IEEE Wireless Commun., vol. 27, no. 5, pp. 67-73, Oct. 2020. 744\n\nCognitive radio: Brain-empowered wireless communica-745 tions. S Haykin, IEEE J. Sel. Areas Commun. 232S. Haykin, ''Cognitive radio: Brain-empowered wireless communica-745 tions,'' IEEE J. Sel. Areas Commun., vol. 23, no. 2, pp. 201-220, Feb. 2005. 746\n\nEnergy detection of unknown deterministic signals. H Urkowitz, Proc. 747 IEEE. 747 IEEE55H. Urkowitz, ''Energy detection of unknown deterministic signals,'' Proc. 747 IEEE, vol. 55, no. 4, pp. 523-531, Apr. 1967. 748\n\nOn the energy detection 749 of unknown signals over fading channels. F F Digham, M.-S Alouini, M K Simon, IEEE Trans. Commun. 551F. F. Digham, M.-S. Alouini, and M. K. Simon, ''On the energy detection 749 of unknown signals over fading channels,'' IEEE Trans. Commun., vol. 55, 750 no. 1, pp. 21-24, Jan. 2007. 751\n\nImproved energy detection 752 spectrum sensing for cognitive radio. M Lopez-Benitez, F Casadevall, IET Commun. 68M. Lopez-Benitez and F. Casadevall, ''Improved energy detection 752 spectrum sensing for cognitive radio,'' IET Commun., vol. 6, no. 8, 753 pp. 785-796, May 2012.\n\nImproved likelihood ratio 755 statistic-based cooperative spectrum sensing for cognitive radio. D K Patel, B Soni, M Lopez-Benitez, IET 756 Commun. 1411D. K. Patel, B. Soni, and M. Lopez-Benitez, ''Improved likelihood ratio 755 statistic-based cooperative spectrum sensing for cognitive radio,'' IET 756 Commun., vol. 14, no. 11, pp. 1675-1686, Jul. 2020. 757\n\nOn sensing per-758 formance of multi-antenna mobile cognitive radio conditioned on primary 759 user activity statistics. B Soni, D K Patel, Z Ding, Y L Guan, S Sun, IEEE Trans. Wireless Commun. 215761B. Soni, D. K. Patel, Z. Ding, Y. L. Guan, and S. Sun, ''On sensing per-758 formance of multi-antenna mobile cognitive radio conditioned on primary 759 user activity statistics,'' IEEE Trans. Wireless Commun., vol. 21, no. 5, 760 pp. 3381-3394, May 2022. 761\n\nModel-driven deep-learning. Z Xu, J Sun, Nat. Sci. Rev. 51763Z. Xu and J. Sun, ''Model-driven deep-learning,'' Nat. Sci. Rev., vol. 5, 762 no. 1, pp. 22-24, Jan. 2017. 763\n\nMachine 764 learning paradigms for next-generation wireless networks. C Jiang, H Zhang, Y Ren, Z Han, K.-C Chen, L Hanzo, IEEE Wireless 765 Commun. 242766C. Jiang, H. Zhang, Y. Ren, Z. Han, K.-C. Chen, and L. Hanzo, ''Machine 764 learning paradigms for next-generation wireless networks,'' IEEE Wireless 765 Commun., vol. 24, no. 2, pp. 98-105, Apr. 2017. 766\n\nAn introduction to deep learning for the phys-767 ical layer. T J O&apos;shea, J Hoydis, IEEE Trans. Cogn. Commun. Netw. 34768T. J. O'Shea and J. Hoydis, ''An introduction to deep learning for the phys-767 ical layer,'' IEEE Trans. Cogn. Commun. Netw., vol. 3, no. 4, pp. 563-575, 768\n\nDeep learning based 770 communication over the air. S D\u00f6rner, S Cammerer, J Hoydis, S Brink, IEEE J. Sel. Topics Signal Process. 121772S. D\u00f6rner, S. Cammerer, J. Hoydis, and S. ten Brink, ''Deep learning based 770 communication over the air,'' IEEE J. Sel. Topics Signal Process., vol. 12, 771 no. 1, pp. 132-143, Feb. 2018. 772\n\nThirty 773 years of machine learning: The road to Pareto-optimal wireless net-774 works. J Wang, C Jiang, H Zhang, Y Ren, K.-C Chen, L Hanzo, IEEE Commun. Surveys Tuts. 2237763rd Quart.J. Wang, C. Jiang, H. Zhang, Y. Ren, K.-C. Chen, and L. Hanzo, ''Thirty 773 years of machine learning: The road to Pareto-optimal wireless net-774 works,'' IEEE Commun. Surveys Tuts., vol. 22, no. 3, pp. 1472-1514, 775 3rd Quart., 2020. 776\n\nModulation-constrained 777 clustering approach to blind modulation classification for MIMO sys-778 tems. J Tian, Y Pei, Y D Huang, Y.-C Liang, IEEE Trans. Cogn. Commun. Netw. 44779J. Tian, Y. Pei, Y. D. Huang, and Y.-C. Liang, ''Modulation-constrained 777 clustering approach to blind modulation classification for MIMO sys-778 tems,'' IEEE Trans. Cogn. Commun. Netw., vol. 4, no. 4, pp. 894-907, 779\n\n. Dec, 780Dec. 2018. 780\n\nArtificial neural network based 781 spectrum sensing method for cognitive radio. Y.-J Tang, Q.-Y Zhang, W Lin, Proc. Int. Conf. Comput. Int. Conf. Comput782Y.-J. Tang, Q.-Y. Zhang, and W. Lin, ''Artificial neural network based 781 spectrum sensing method for cognitive radio,'' in Proc. Int. Conf. Comput. 782\n\n. Intell. Softw. Eng. Intell. Softw. Eng., Sep. 2010, pp. 1-4.\n\nArtificial neural network 784 based hybrid spectrum sensing scheme for cognitive radio,'' in Proc. M R Vyas, D K Patel, M Lopez-Benitez, Annu. Int. Symp. Pers., Indoor, Mobile Radio Commun. 785786PIMRCIEEEM. R. Vyas, D. K. Patel, and M. Lopez-Benitez, ''Artificial neural network 784 based hybrid spectrum sensing scheme for cognitive radio,'' in Proc. IEEE 785 28th Annu. Int. Symp. Pers., Indoor, Mobile Radio Commun. (PIMRC), 786\n\nArti-788 ficial neural network design for improved spectrum sensing in cognitive 789 radio. D K Patel, M L\u00f3pez-Ben\u00edtez, B Soni, \u00c1 F Garc\u00eda-Fern\u00e1ndez, Wireless Netw. 268D. K. Patel, M. L\u00f3pez-Ben\u00edtez, B. Soni, and \u00c1. F. Garc\u00eda-Fern\u00e1ndez, ''Arti-788 ficial neural network design for improved spectrum sensing in cognitive 789 radio,'' Wireless Netw., vol. 26, no. 8, pp. 6155-6174, Nov. 2020. 790\n\nA machine 791 learning-enabled spectrum sensing method for OFDM systems. J Tian, P Cheng, Z Chen, M Li, H Hu, Y Li, B Vucetic, IEEE 792J. Tian, P. Cheng, Z. Chen, M. Li, H. Hu, Y. Li, and B. Vucetic, ''A machine 791 learning-enabled spectrum sensing method for OFDM systems,'' IEEE 792\n\n. Trans. Veh. Technol. 6811Trans. Veh. Technol., vol. 68, no. 11, pp. 11374-11378, Nov. 2019.\n\nLong short-815 term memory based spectrum sensing scheme for cognitive radio. N Balwani, D K Patel, B Soni, M Lopez-Benitez, N. Balwani, D. K. Patel, B. Soni, and M. Lopez-Benitez, ''Long short- 815 term memory based spectrum sensing scheme for cognitive radio,'' in\n\nProc. IEEE 30th Annu. Int. Symp. Pers., Indoor Mobile Radio Commun. 817 (PIMRC). IEEE 30th Annu. Int. Symp. Pers., Indoor Mobile Radio Commun. 817 (PIMRC)Proc. IEEE 30th Annu. Int. Symp. Pers., Indoor Mobile Radio Commun. 817 (PIMRC), Sep. 2019, pp. 1-6.\n\nUnsupervised deep spectrum sensing: 819 A variational auto-encoder based approach. J Xie, J Fang, C Liu, L Yang, IEEE Trans. Veh. Technol. 8205J. Xie, J. Fang, C. Liu, and L. Yang, ''Unsupervised deep spectrum sensing: 819 A variational auto-encoder based approach,'' IEEE Trans. Veh. Technol., 820 vol. 69, no. 5, pp. 5307-5319, May 2020.\n\nSpectrum sensing based 822 on deep learning classification for cognitive radios. S Zheng, S Chen, P Qi, H Zhou, X Yang, China Commun. 8232S. Zheng, S. Chen, P. Qi, H. Zhou, and X. Yang, ''Spectrum sensing based 822 on deep learning classification for cognitive radios,'' China Commun., 823 vol. 17, no. 2, pp. 138-148, Feb. 2020.\n\nDeep learning-based spectrum sens-825 ing in cognitive radio: A CNN-LSTM approach. J Xie, J Fang, C Liu, X Li, IEEE Commun. Lett. 82610J. Xie, J. Fang, C. Liu, and X. Li, ''Deep learning-based spectrum sens- 825 ing in cognitive radio: A CNN-LSTM approach,'' IEEE Commun. Lett., 826 vol. 24, no. 10, pp. 2196-2200, Oct. 2020.\n\nSpectrum sensing 828 based on parallel CNN-LSTM network. M Xu, Z Yin, M Wu, Z Wu, Y Zhao, Z Gao, Proc. IEEE 91st Veh. IEEE 91st VehTechnolM. Xu, Z. Yin, M. Wu, Z. Wu, Y. Zhao, and Z. Gao, ''Spectrum sensing 828 based on parallel CNN-LSTM network,'' in Proc. IEEE 91st Veh. Technol.\n\nConf. (VTC-Spring). Conf. (VTC-Spring), May 2020, pp. 1-5.\n\n. A Hoglund, X Lin, O Liberg, A Behravan, E A Yavuz, 831A. Hoglund, X. Lin, O. Liberg, A. Behravan, E. A. Yavuz, 831\n\nOverview of 3GPP release 14 enhanced NB-IoT. M Van Der Zee, Y Sui, T Tirronen, A Ratilainen, D Eriksson, IEEE Netw. 8326M. Van Der Zee, Y. Sui, T. Tirronen, A. Ratilainen, and D. Eriksson, 832 ''Overview of 3GPP release 14 enhanced NB-IoT,'' IEEE Netw., vol. 31, 833 no. 6, pp. 16-22, Dec. 2017.\n\nIterative algo-835 rithm induced deep-unfolding neural networks: Precoding design for mul-836. Q Hu, Y Cai, Q Shi, K Xu, G Yu, Z Ding, Q. Hu, Y. Cai, Q. Shi, K. Xu, G. Yu, and Z. Ding, ''Iterative algo- 835 rithm induced deep-unfolding neural networks: Precoding design for mul- 836\n\n. Systems, IEEE Trans. Wireless Commun. 202tiuser MIMO systems,'' IEEE Trans. Wireless Commun., vol. 20, no. 2, 837 pp. 1394-1410, Feb. 2021.\n\nDeep unfolding: Model-based 839 inspiration of novel deep architectures. J R Hershey, J Le Roux, F Weninger, arXiv:1409.2574J. R. Hershey, J. Le Roux, and F. Weninger, ''Deep unfolding: Model-based 839 inspiration of novel deep architectures,'' 2014, arXiv:1409.2574.\n\nRedefining wireless com-841 munication for 6G: Signal processing meets deep learning with deep 842 unfolding. A Jagannath, J Jagannath, T Melodia, arXiv:2004.107152020A. Jagannath, J. Jagannath, and T. Melodia, ''Redefining wireless com- 841 munication for 6G: Signal processing meets deep learning with deep 842 unfolding,'' 2020, arXiv:2004.10715.\n\nWireless networks design in 844 the era of deep learning: Model-based, AI-based, or both?. A Zappone, M Di Renzo, M Debbah, IEEETransA. Zappone, M. Di Renzo, and M. Debbah, ''Wireless networks design in 844 the era of deep learning: Model-based, AI-based, or both?'' IEEE Trans.\n\n. Commun. 6710Commun., vol. 67, no. 10, pp. 7331-7376, Oct. 2019.\n\nAlgorithm unrolling: Interpretable, 847 efficient deep learning for signal and image processing. V Monga, Y Li, Y C Eldar, IEEE Signal. 848V. Monga, Y. Li, and Y. C. Eldar, ''Algorithm unrolling: Interpretable, 847 efficient deep learning for signal and image processing,'' IEEE Signal 848\n\n. Process. Mag. 382Process. Mag., vol. 38, no. 2, pp. 18-44, Mar. 2021.\n\nDeep MIMO detection 850 using ADMM unfolding,'' in Proc. M.-W Un, M Shao, W.-K Ma, P C Ching, IEEE Data Sci. Workshop. DSWM.-W. Un, M. Shao, W.-K. Ma, and P. C. Ching, ''Deep MIMO detection 850 using ADMM unfolding,'' in Proc. IEEE Data Sci. Workshop (DSW),\n\nLearning to detect. N Samuel, T Diskin, A Wiesel, IEEE Trans. 853 Signal Process. 6710N. Samuel, T. Diskin, and A. Wiesel, ''Learning to detect,'' IEEE Trans. 853 Signal Process., vol. 67, no. 10, pp. 2554-2564, May 2019.\n\nDeep unfolding 855 with weighted 2 minimization for compressive sensing. J Zhang, Y Li, Z L Yu, Z Gu, Y Cheng, H Gong, IEEE Internet. 856J. Zhang, Y. Li, Z. L. Yu, Z. Gu, Y. Cheng, and H. Gong, ''Deep unfolding 855 with weighted 2 minimization for compressive sensing,'' IEEE Internet 856\n\n. J Things, 8Things J., vol. 8, no. 4, pp. 3027-3041, Feb. 2021.\n\nDeep unfolding for communi-858 cations systems: A survey and some new directions,'' in Proc. A Balatsoukas-Stimming, C Studer, IEEE Int. A. Balatsoukas-Stimming and C. Studer, ''Deep unfolding for communi- 858 cations systems: A survey and some new directions,'' in Proc. IEEE Int.\n\n. Workshop Signal Process. Syst. (SiPS). Workshop Signal Process. Syst. (SiPS), Oct. 2019, pp. 266-271.\n\nI Goodfellow, Y Bengio, A Courville, Deep Learning. Cambridge861I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. Cambridge, 861\n\n. Usa Ma, MIT PressMA, USA: MIT Press, 2016.\n\n. C Szegedy, W Liu, Y Jia, P Sermanet, S Reed, D Anguelov, D Erhan, 863C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, 863\n\nGoing deeper with convolutions. V Vanhoucke, A Rabinovich, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)865V. Vanhoucke, and A. Rabinovich, ''Going deeper with convolutions,'' 864 in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2015, 865 pp. 1-9.\n\nAdam: A method for stochastic optimization. D P Kingma, J Ba, arXiv:1412.6980867D. P. Kingma and J. Ba, ''Adam: A method for stochastic optimization,'' 867 2014, arXiv:1412.6980.\n\nSensing-throughput 869 tradeoff for cognitive radio networks. Y.-C Liang, Y Zeng, E Peh, A T Hoang, IEEE Trans. Wireless Commun. 8704871Y.-C. Liang, Y. Zeng, E. Peh, and A. T. Hoang, ''Sensing-throughput 869 tradeoff for cognitive radio networks,'' IEEE Trans. Wireless Commun., 870 vol. 7, no. 4, pp. 1326-1337, Apr. 2018. 871\n\n. 5g Toolbox, 5G Toolbox. Accessed: Sep. 2021. [Online]. Available: https://www. 872 mathworks.com/products/5g.html 873\n\nRadio machine learning dataset generation with 874 GNU radio. T J O&apos;shea, N West, Proc. GNU Radio Conf. GNU Radio Conf1875T. J. O'shea and N. West, ''Radio machine learning dataset generation with 874 GNU radio,'' in Proc. GNU Radio Conf., 2016, vol. 1, no. 1. 875\n\n. Satellite Communications Toolbox. Accessed. Satellite Communications Toolbox. Accessed: Sep. 2021. [Online].\n\nSimulated Radar Waveform and RF 878 Dataset Generator for. M Caromi, M R Souryal, 879Incumbent Signals in the 3.5 GHz CBRSM. Caromi and M. R. Souryal. Simulated Radar Waveform and RF 878 Dataset Generator for Incumbent Signals in the 3.5 GHz CBRS 879\n\nTensorFlow: Large-Scale Machine Learning on Hetero-882 geneous Systems. M Abadi, M. Abadi. (2015). TensorFlow: Large-Scale Machine Learning on Hetero-882 geneous Systems. [Online]. Available: https://www.tensorflow.org/ 883\n\nEvaluation: From precision, recall and F-884 measure to ROC, informedness, markedness and correlation. D M W Powers, arXiv:2010.16061885D. M. W. Powers, ''Evaluation: From precision, recall and F-884 measure to ROC, informedness, markedness and correlation,'' 2020, 885 arXiv:2010.16061.\n\n890 respectively, and the Ph.D. degree from the School 891 of Engineering and Applied Science. Ahmedabad892Technological UniversityTechnological University, in 2014 and 2017, 890 respectively, and the Ph.D. degree from the School 891 of Engineering and Applied Science, Ahmedabad 892\n\nHe is currently a Post-893 doctoral Researcher with the. 894Boston College, MAUniversityUniversity, in July 2021. He is currently a Post-893 doctoral Researcher with the Boston College, MA, 894\n\nPrior to that, he was an Adjunct Faculty at 895. USAUSA. Prior to that, he was an Adjunct Faculty at 895\n\nHe was also associated as 896 a Junior Research Fellow at Ahmedabad University for the Department of 897 Science and Technology (DST)-U.K. India Education and Research Initia-898 tive (UKIERI) Research Project jointly funded by DST and British Coun-899. Ahmedabad UniversityAhmedabad University. He was also associated as 896 a Junior Research Fellow at Ahmedabad University for the Department of 897 Science and Technology (DST)-U.K. India Education and Research Initia-898 tive (UKIERI) Research Project jointly funded by DST and British Coun-899\n\nHis research interests include cognitive radio networks, applied 900 machine learning/deep learning for xG wireless networks, NOMA, and 901 physical layer security. U K Cil, cil, U.K. His research interests include cognitive radio networks, applied 900 machine learning/deep learning for xG wireless networks, NOMA, and 901 physical layer security.\n\n. Dhaval K Patel (member, 903DHAVAL K. PATEL (Member, IEEE) received the 903\n\nB E , M E , degrees (Hons.) in communica-904 tion systems engineering from Gujarat University. 905B.E. and M.E. degrees (Hons.) in communica-904 tion systems engineering from Gujarat University, 905\n\nHe was a Vis-909 iting Faculty at the Franklin W. Olin College of 910 Engineering-Massachusetts. India Ahmedabad, respectively, 906 and the Ph.D. degree in electronics and commu-907 nications from the Institute of Technology. Ahmedabad; Needham, MA, USA912Nirma 908 UniversityAhmedabad, India, in 2003 and 2010, respectively, 906 and the Ph.D. degree in electronics and commu-907 nications from the Institute of Technology, Nirma 908 University, Ahmedabad, in 2014. He was a Vis-909 iting Faculty at the Franklin W. Olin College of 910 Engineering-Massachusetts, Needham, MA, USA. 911 From 2011 to 2014, he was a Junior Research 912\n\nFellow at the Post Graduate Laboratory for Communication Systems. Nirma 913 University. Since. 914he has been with the School of EngineeringFellow at the Post Graduate Laboratory for Communication Systems, Nirma 913 University. Since 2014, he has been with the School of Engineering and 914\n\nHis research interests include vehicular cyber physical 916 systems, 5G wireless networks, non-parametric statistics, and physical layer 917 security. He is the Principal Investigator of Research Projects funded by the 918 Department of Science and Technology. 919U.KAssociate ProfessorAssociate Professor. His research interests include vehicular cyber physical 916 systems, 5G wireless networks, non-parametric statistics, and physical layer 917 security. He is the Principal Investigator of Research Projects funded by the 918 Department of Science and Technology, U.K. India Education and Research 919\n\nAssociation of Southeast Asian Nations. ASEAN920Initiative (UKIERI), Association of Southeast Asian Nations (ASEAN)-920\n\nIndia Collaborative Research and Development Project, and the Gujarat 921. India Collaborative Research and Development Project, and the Gujarat 921\n\nHe is a Reviewer of various confer-922 ences, including IEEE ICASSP. PIMRC. 923Council on Science and TechnologyCouncil on Science and Technology. He is a Reviewer of various confer-922 ences, including IEEE ICASSP, IEEE VTC, and IEEE PIMRC. 923\n", "annotations": {"author": "[{\"end\":151,\"start\":79},{\"end\":252,\"start\":152},{\"end\":366,\"start\":253},{\"end\":555,\"start\":367},{\"end\":641,\"start\":556}]", "publisher": null, "author_last_name": "[{\"end\":91,\"start\":87},{\"end\":166,\"start\":161},{\"end\":278,\"start\":274},{\"end\":387,\"start\":374},{\"end\":581,\"start\":570}]", "author_first_name": "[{\"end\":86,\"start\":79},{\"end\":158,\"start\":152},{\"end\":160,\"start\":159},{\"end\":271,\"start\":265},{\"end\":273,\"start\":272},{\"end\":373,\"start\":367},{\"end\":569,\"start\":559}]", "author_affiliation": "[{\"end\":150,\"start\":93},{\"end\":251,\"start\":168},{\"end\":365,\"start\":280},{\"end\":485,\"start\":389},{\"end\":554,\"start\":487},{\"end\":640,\"start\":583}]", "title": "[{\"end\":76,\"start\":1},{\"end\":717,\"start\":642}]", "venue": null, "abstract": null, "bib_ref": "[{\"end\":1549,\"start\":1547},{\"end\":1953,\"start\":1949},{\"end\":1958,\"start\":1955},{\"end\":2452,\"start\":2448},{\"end\":2607,\"start\":2603},{\"end\":2745,\"start\":2741},{\"end\":3034,\"start\":3030},{\"end\":3052,\"start\":3048},{\"end\":3205,\"start\":3201},{\"end\":3210,\"start\":3207},{\"end\":4179,\"start\":4176},{\"end\":4578,\"start\":4570},{\"end\":5101,\"start\":5097},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5968,\"start\":5967},{\"end\":10376,\"start\":10374},{\"end\":10431,\"start\":10429},{\"end\":10529,\"start\":10527},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10552,\"start\":10550},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10895,\"start\":10891},{\"end\":10900,\"start\":10897},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11449,\"start\":11445},{\"end\":11548,\"start\":11545},{\"end\":11682,\"start\":11679},{\"end\":11703,\"start\":11700},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":12749,\"start\":12745},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":13043,\"start\":13039},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":16428,\"start\":16424},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":23433,\"start\":23429},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":31680,\"start\":31676}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":18236,\"start\":17928},{\"attributes\":{\"id\":\"fig_1\"},\"end\":18274,\"start\":18237},{\"attributes\":{\"id\":\"fig_2\"},\"end\":18793,\"start\":18275},{\"attributes\":{\"id\":\"fig_3\"},\"end\":18994,\"start\":18794},{\"attributes\":{\"id\":\"fig_4\"},\"end\":19059,\"start\":18995},{\"attributes\":{\"id\":\"fig_5\"},\"end\":19662,\"start\":19060},{\"attributes\":{\"id\":\"fig_6\"},\"end\":20448,\"start\":19663},{\"attributes\":{\"id\":\"fig_7\"},\"end\":21262,\"start\":20449},{\"attributes\":{\"id\":\"fig_8\"},\"end\":21635,\"start\":21263},{\"attributes\":{\"id\":\"fig_9\"},\"end\":22167,\"start\":21636},{\"attributes\":{\"id\":\"fig_10\"},\"end\":22261,\"start\":22168},{\"attributes\":{\"id\":\"fig_12\"},\"end\":22996,\"start\":22262},{\"attributes\":{\"id\":\"fig_13\"},\"end\":23245,\"start\":22997},{\"attributes\":{\"id\":\"fig_14\"},\"end\":24676,\"start\":23246},{\"attributes\":{\"id\":\"fig_15\"},\"end\":24994,\"start\":24677},{\"attributes\":{\"id\":\"fig_16\"},\"end\":26045,\"start\":24995},{\"attributes\":{\"id\":\"fig_17\"},\"end\":26167,\"start\":26046},{\"attributes\":{\"id\":\"fig_18\"},\"end\":26421,\"start\":26168},{\"attributes\":{\"id\":\"fig_19\"},\"end\":26664,\"start\":26422},{\"attributes\":{\"id\":\"fig_20\"},\"end\":26904,\"start\":26665},{\"attributes\":{\"id\":\"fig_21\"},\"end\":27199,\"start\":26905},{\"attributes\":{\"id\":\"fig_22\"},\"end\":27600,\"start\":27200},{\"attributes\":{\"id\":\"fig_23\"},\"end\":27857,\"start\":27601},{\"attributes\":{\"id\":\"fig_24\"},\"end\":28610,\"start\":27858},{\"attributes\":{\"id\":\"fig_25\"},\"end\":29032,\"start\":28611},{\"attributes\":{\"id\":\"fig_26\"},\"end\":29277,\"start\":29033},{\"attributes\":{\"id\":\"fig_27\"},\"end\":29477,\"start\":29278},{\"attributes\":{\"id\":\"fig_28\"},\"end\":32556,\"start\":29478},{\"attributes\":{\"id\":\"fig_29\"},\"end\":33279,\"start\":32557},{\"attributes\":{\"id\":\"fig_30\"},\"end\":36326,\"start\":33280},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":38786,\"start\":36327},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":38850,\"start\":38787},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":39322,\"start\":38851},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":39385,\"start\":39323},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":40097,\"start\":39386},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":40476,\"start\":40098},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":40553,\"start\":40477},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":41599,\"start\":40554},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":42793,\"start\":41600},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":42889,\"start\":42794},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":43642,\"start\":42890},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":43818,\"start\":43643},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":43873,\"start\":43819},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":43911,\"start\":43874},{\"attributes\":{\"id\":\"tab_17\",\"type\":\"table\"},\"end\":45875,\"start\":43912}]", "paragraph": "[{\"end\":4447,\"start\":1119},{\"end\":4512,\"start\":4455},{\"end\":4643,\"start\":4520},{\"end\":5675,\"start\":4651},{\"end\":6075,\"start\":5787},{\"end\":6494,\"start\":6116},{\"end\":6799,\"start\":6529},{\"end\":7089,\"start\":6834},{\"end\":7237,\"start\":7127},{\"end\":9143,\"start\":7539},{\"end\":9395,\"start\":9222},{\"end\":9529,\"start\":9403},{\"end\":9653,\"start\":9537},{\"end\":10100,\"start\":9772},{\"end\":10454,\"start\":10218},{\"end\":10506,\"start\":10456},{\"end\":12174,\"start\":10508},{\"end\":13670,\"start\":12182},{\"end\":13830,\"start\":13769},{\"end\":17227,\"start\":13854},{\"end\":17927,\"start\":17269}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":5734,\"start\":5676},{\"attributes\":{\"id\":\"formula_1\"},\"end\":6109,\"start\":6076},{\"attributes\":{\"id\":\"formula_2\"},\"end\":6528,\"start\":6495},{\"attributes\":{\"id\":\"formula_3\"},\"end\":6827,\"start\":6800},{\"attributes\":{\"id\":\"formula_4\"},\"end\":7120,\"start\":7090},{\"attributes\":{\"id\":\"formula_5\"},\"end\":7280,\"start\":7238},{\"attributes\":{\"id\":\"formula_6\"},\"end\":7478,\"start\":7280},{\"attributes\":{\"id\":\"formula_7\"},\"end\":7538,\"start\":7478},{\"attributes\":{\"id\":\"formula_8\"},\"end\":9221,\"start\":9144},{\"attributes\":{\"id\":\"formula_9\"},\"end\":9771,\"start\":9654},{\"attributes\":{\"id\":\"formula_10\"},\"end\":10217,\"start\":10101},{\"attributes\":{\"id\":\"formula_11\"},\"end\":13684,\"start\":13671},{\"attributes\":{\"id\":\"formula_12\"},\"end\":13736,\"start\":13684}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":5841,\"start\":5834},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":12352,\"start\":12345},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":12932,\"start\":12925},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":13624,\"start\":13617},{\"attributes\":{\"ref_id\":\"tab_14\"},\"end\":13920,\"start\":13913},{\"attributes\":{\"ref_id\":\"tab_14\"},\"end\":13933,\"start\":13926},{\"attributes\":{\"ref_id\":\"tab_15\"},\"end\":15688,\"start\":15681},{\"end\":16364,\"start\":16357},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":17770,\"start\":17736},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":17922,\"start\":17914}]", "section_header": "[{\"end\":4453,\"start\":4450},{\"end\":4518,\"start\":4515},{\"end\":4649,\"start\":4646},{\"end\":5739,\"start\":5736},{\"end\":5779,\"start\":5742},{\"end\":5785,\"start\":5782},{\"end\":6114,\"start\":6111},{\"end\":6832,\"start\":6829},{\"end\":7125,\"start\":7122},{\"end\":9401,\"start\":9398},{\"end\":9535,\"start\":9532},{\"end\":12180,\"start\":12177},{\"end\":13761,\"start\":13738},{\"end\":13767,\"start\":13764},{\"end\":13852,\"start\":13833},{\"end\":17233,\"start\":17230},{\"end\":17261,\"start\":17236},{\"end\":17267,\"start\":17264},{\"end\":18290,\"start\":18276},{\"end\":18801,\"start\":18795},{\"end\":19010,\"start\":18996},{\"end\":19071,\"start\":19061},{\"end\":22179,\"start\":22169},{\"end\":25014,\"start\":24996},{\"end\":26057,\"start\":26047},{\"end\":26179,\"start\":26169},{\"end\":26433,\"start\":26423},{\"end\":26677,\"start\":26666},{\"end\":27613,\"start\":27602},{\"end\":28619,\"start\":28612},{\"end\":29049,\"start\":29034},{\"end\":29290,\"start\":29279},{\"end\":29490,\"start\":29479},{\"end\":33286,\"start\":33281},{\"end\":38797,\"start\":38788},{\"end\":39333,\"start\":39324},{\"end\":40487,\"start\":40478},{\"end\":40564,\"start\":40555},{\"end\":41610,\"start\":41601},{\"end\":42804,\"start\":42795},{\"end\":42900,\"start\":42891},{\"end\":43653,\"start\":43644},{\"end\":43829,\"start\":43820},{\"end\":43885,\"start\":43875}]", "table": "[{\"end\":38786,\"start\":36803},{\"end\":39322,\"start\":39103},{\"end\":40097,\"start\":39893},{\"end\":40476,\"start\":40286},{\"end\":41599,\"start\":40889},{\"end\":42793,\"start\":42192},{\"end\":42889,\"start\":42855},{\"end\":43642,\"start\":42945},{\"end\":45875,\"start\":45716}]", "figure_caption": "[{\"end\":18236,\"start\":17930},{\"end\":18274,\"start\":18239},{\"end\":18793,\"start\":18295},{\"end\":18994,\"start\":18803},{\"end\":19059,\"start\":19015},{\"end\":19662,\"start\":19073},{\"end\":20448,\"start\":19665},{\"end\":21262,\"start\":20451},{\"end\":21635,\"start\":21265},{\"end\":22167,\"start\":21638},{\"end\":22261,\"start\":22181},{\"end\":22996,\"start\":22264},{\"end\":23245,\"start\":22999},{\"end\":24676,\"start\":23248},{\"end\":24994,\"start\":24679},{\"end\":26045,\"start\":25019},{\"end\":26167,\"start\":26059},{\"end\":26421,\"start\":26181},{\"end\":26664,\"start\":26435},{\"end\":26904,\"start\":26680},{\"end\":27199,\"start\":26907},{\"end\":27600,\"start\":27202},{\"end\":27857,\"start\":27616},{\"end\":28610,\"start\":27860},{\"end\":29032,\"start\":28623},{\"end\":29277,\"start\":29055},{\"end\":29477,\"start\":29293},{\"end\":32556,\"start\":29493},{\"end\":33279,\"start\":32559},{\"end\":36326,\"start\":33290},{\"end\":36803,\"start\":36329},{\"end\":38850,\"start\":38799},{\"end\":39103,\"start\":38853},{\"end\":39385,\"start\":39335},{\"end\":39893,\"start\":39388},{\"end\":40286,\"start\":40100},{\"end\":40553,\"start\":40489},{\"end\":40889,\"start\":40566},{\"end\":42192,\"start\":41612},{\"end\":42855,\"start\":42806},{\"end\":42945,\"start\":42902},{\"end\":43818,\"start\":43655},{\"end\":43873,\"start\":43831},{\"end\":43911,\"start\":43888},{\"end\":45716,\"start\":43914}]", "figure_ref": "[{\"end\":4761,\"start\":4755},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":7821,\"start\":7815},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":7990,\"start\":7984},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":8090,\"start\":8084},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":8745,\"start\":8739},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":8756,\"start\":8750},{\"end\":14493,\"start\":14487},{\"attributes\":{\"ref_id\":\"fig_18\"},\"end\":15700,\"start\":15694},{\"attributes\":{\"ref_id\":\"fig_19\"},\"end\":15919,\"start\":15913},{\"attributes\":{\"ref_id\":\"fig_20\"},\"end\":16132,\"start\":16125},{\"attributes\":{\"ref_id\":\"fig_23\"},\"end\":16335,\"start\":16328}]", "bib_author_first_name": "[{\"end\":45904,\"start\":45903},{\"end\":45917,\"start\":45916},{\"end\":45929,\"start\":45928},{\"end\":45947,\"start\":45946},{\"end\":45964,\"start\":45963},{\"end\":45980,\"start\":45979},{\"end\":45997,\"start\":45996},{\"end\":46011,\"start\":46010},{\"end\":46162,\"start\":46161},{\"end\":46174,\"start\":46173},{\"end\":46195,\"start\":46194},{\"end\":46205,\"start\":46204},{\"end\":46381,\"start\":46380},{\"end\":46394,\"start\":46393},{\"end\":46674,\"start\":46673},{\"end\":46684,\"start\":46683},{\"end\":46696,\"start\":46695},{\"end\":46698,\"start\":46697},{\"end\":46882,\"start\":46879},{\"end\":47035,\"start\":47034},{\"end\":47042,\"start\":47041},{\"end\":47049,\"start\":47048},{\"end\":47055,\"start\":47054},{\"end\":47061,\"start\":47060},{\"end\":47371,\"start\":47370},{\"end\":47613,\"start\":47612},{\"end\":47849,\"start\":47848},{\"end\":47851,\"start\":47850},{\"end\":47864,\"start\":47860},{\"end\":47875,\"start\":47874},{\"end\":47877,\"start\":47876},{\"end\":48164,\"start\":48163},{\"end\":48181,\"start\":48180},{\"end\":48469,\"start\":48468},{\"end\":48471,\"start\":48470},{\"end\":48480,\"start\":48479},{\"end\":48488,\"start\":48487},{\"end\":48855,\"start\":48854},{\"end\":48863,\"start\":48862},{\"end\":48865,\"start\":48864},{\"end\":48874,\"start\":48873},{\"end\":48882,\"start\":48881},{\"end\":48884,\"start\":48883},{\"end\":48892,\"start\":48891},{\"end\":49222,\"start\":49221},{\"end\":49228,\"start\":49227},{\"end\":49437,\"start\":49436},{\"end\":49446,\"start\":49445},{\"end\":49455,\"start\":49454},{\"end\":49462,\"start\":49461},{\"end\":49472,\"start\":49468},{\"end\":49480,\"start\":49479},{\"end\":49790,\"start\":49789},{\"end\":49792,\"start\":49791},{\"end\":49807,\"start\":49806},{\"end\":50066,\"start\":50065},{\"end\":50076,\"start\":50075},{\"end\":50088,\"start\":50087},{\"end\":50098,\"start\":50097},{\"end\":50433,\"start\":50432},{\"end\":50441,\"start\":50440},{\"end\":50450,\"start\":50449},{\"end\":50459,\"start\":50458},{\"end\":50469,\"start\":50465},{\"end\":50477,\"start\":50476},{\"end\":50876,\"start\":50875},{\"end\":50884,\"start\":50883},{\"end\":50891,\"start\":50890},{\"end\":50893,\"start\":50892},{\"end\":50905,\"start\":50901},{\"end\":51283,\"start\":51279},{\"end\":51294,\"start\":51290},{\"end\":51303,\"start\":51302},{\"end\":51673,\"start\":51672},{\"end\":51675,\"start\":51674},{\"end\":51683,\"start\":51682},{\"end\":51685,\"start\":51684},{\"end\":51694,\"start\":51693},{\"end\":52100,\"start\":52099},{\"end\":52102,\"start\":52101},{\"end\":52111,\"start\":52110},{\"end\":52128,\"start\":52127},{\"end\":52136,\"start\":52135},{\"end\":52138,\"start\":52137},{\"end\":52476,\"start\":52475},{\"end\":52484,\"start\":52483},{\"end\":52493,\"start\":52492},{\"end\":52501,\"start\":52500},{\"end\":52507,\"start\":52506},{\"end\":52513,\"start\":52512},{\"end\":52519,\"start\":52518},{\"end\":52863,\"start\":52862},{\"end\":52874,\"start\":52873},{\"end\":52876,\"start\":52875},{\"end\":52885,\"start\":52884},{\"end\":52893,\"start\":52892},{\"end\":53392,\"start\":53391},{\"end\":53399,\"start\":53398},{\"end\":53407,\"start\":53406},{\"end\":53414,\"start\":53413},{\"end\":53731,\"start\":53730},{\"end\":53740,\"start\":53739},{\"end\":53748,\"start\":53747},{\"end\":53754,\"start\":53753},{\"end\":53762,\"start\":53761},{\"end\":54064,\"start\":54063},{\"end\":54071,\"start\":54070},{\"end\":54079,\"start\":54078},{\"end\":54086,\"start\":54085},{\"end\":54365,\"start\":54364},{\"end\":54371,\"start\":54370},{\"end\":54378,\"start\":54377},{\"end\":54384,\"start\":54383},{\"end\":54390,\"start\":54389},{\"end\":54398,\"start\":54397},{\"end\":54653,\"start\":54652},{\"end\":54664,\"start\":54663},{\"end\":54671,\"start\":54670},{\"end\":54681,\"start\":54680},{\"end\":54693,\"start\":54692},{\"end\":54695,\"start\":54694},{\"end\":54814,\"start\":54813},{\"end\":54829,\"start\":54828},{\"end\":54836,\"start\":54835},{\"end\":54848,\"start\":54847},{\"end\":54862,\"start\":54861},{\"end\":55161,\"start\":55160},{\"end\":55167,\"start\":55166},{\"end\":55174,\"start\":55173},{\"end\":55181,\"start\":55180},{\"end\":55187,\"start\":55186},{\"end\":55193,\"start\":55192},{\"end\":55566,\"start\":55565},{\"end\":55568,\"start\":55567},{\"end\":55579,\"start\":55578},{\"end\":55582,\"start\":55580},{\"end\":55590,\"start\":55589},{\"end\":55872,\"start\":55871},{\"end\":55885,\"start\":55884},{\"end\":55898,\"start\":55897},{\"end\":56204,\"start\":56203},{\"end\":56215,\"start\":56214},{\"end\":56218,\"start\":56216},{\"end\":56227,\"start\":56226},{\"end\":56557,\"start\":56556},{\"end\":56566,\"start\":56565},{\"end\":56572,\"start\":56571},{\"end\":56574,\"start\":56573},{\"end\":56884,\"start\":56880},{\"end\":56890,\"start\":56889},{\"end\":56901,\"start\":56897},{\"end\":56907,\"start\":56906},{\"end\":56909,\"start\":56908},{\"end\":57103,\"start\":57102},{\"end\":57113,\"start\":57112},{\"end\":57123,\"start\":57122},{\"end\":57379,\"start\":57378},{\"end\":57388,\"start\":57387},{\"end\":57394,\"start\":57393},{\"end\":57396,\"start\":57395},{\"end\":57402,\"start\":57401},{\"end\":57408,\"start\":57407},{\"end\":57417,\"start\":57416},{\"end\":57598,\"start\":57597},{\"end\":57755,\"start\":57754},{\"end\":57779,\"start\":57778},{\"end\":58050,\"start\":58049},{\"end\":58064,\"start\":58063},{\"end\":58074,\"start\":58073},{\"end\":58193,\"start\":58190},{\"end\":58237,\"start\":58236},{\"end\":58248,\"start\":58247},{\"end\":58255,\"start\":58254},{\"end\":58262,\"start\":58261},{\"end\":58274,\"start\":58273},{\"end\":58282,\"start\":58281},{\"end\":58294,\"start\":58293},{\"end\":58416,\"start\":58415},{\"end\":58429,\"start\":58428},{\"end\":58751,\"start\":58750},{\"end\":58753,\"start\":58752},{\"end\":58763,\"start\":58762},{\"end\":58952,\"start\":58948},{\"end\":58961,\"start\":58960},{\"end\":58969,\"start\":58968},{\"end\":58976,\"start\":58975},{\"end\":58978,\"start\":58977},{\"end\":59399,\"start\":59398},{\"end\":59401,\"start\":59400},{\"end\":59416,\"start\":59415},{\"end\":59779,\"start\":59778},{\"end\":59789,\"start\":59788},{\"end\":59791,\"start\":59790},{\"end\":60044,\"start\":60043},{\"end\":60300,\"start\":60299},{\"end\":60304,\"start\":60301},{\"end\":61787,\"start\":61786},{\"end\":61789,\"start\":61788},{\"end\":61979,\"start\":61973},{\"end\":61981,\"start\":61980},{\"end\":62050,\"start\":62049},{\"end\":62052,\"start\":62051},{\"end\":62056,\"start\":62055},{\"end\":62058,\"start\":62057},{\"end\":62351,\"start\":62346}]", "bib_author_last_name": "[{\"end\":45914,\"start\":45905},{\"end\":45926,\"start\":45918},{\"end\":45944,\"start\":45930},{\"end\":45961,\"start\":45948},{\"end\":45977,\"start\":45965},{\"end\":45994,\"start\":45981},{\"end\":46008,\"start\":45998},{\"end\":46019,\"start\":46012},{\"end\":46171,\"start\":46163},{\"end\":46192,\"start\":46175},{\"end\":46202,\"start\":46196},{\"end\":46214,\"start\":46206},{\"end\":46391,\"start\":46382},{\"end\":46403,\"start\":46395},{\"end\":46681,\"start\":46675},{\"end\":46693,\"start\":46685},{\"end\":46703,\"start\":46699},{\"end\":47039,\"start\":47036},{\"end\":47046,\"start\":47043},{\"end\":47052,\"start\":47050},{\"end\":47058,\"start\":47056},{\"end\":47066,\"start\":47062},{\"end\":47378,\"start\":47372},{\"end\":47622,\"start\":47614},{\"end\":47858,\"start\":47852},{\"end\":47872,\"start\":47865},{\"end\":47883,\"start\":47878},{\"end\":48178,\"start\":48165},{\"end\":48192,\"start\":48182},{\"end\":48477,\"start\":48472},{\"end\":48485,\"start\":48481},{\"end\":48502,\"start\":48489},{\"end\":48860,\"start\":48856},{\"end\":48871,\"start\":48866},{\"end\":48879,\"start\":48875},{\"end\":48889,\"start\":48885},{\"end\":48896,\"start\":48893},{\"end\":49225,\"start\":49223},{\"end\":49232,\"start\":49229},{\"end\":49443,\"start\":49438},{\"end\":49452,\"start\":49447},{\"end\":49459,\"start\":49456},{\"end\":49466,\"start\":49463},{\"end\":49477,\"start\":49473},{\"end\":49486,\"start\":49481},{\"end\":49804,\"start\":49793},{\"end\":49814,\"start\":49808},{\"end\":50073,\"start\":50067},{\"end\":50085,\"start\":50077},{\"end\":50095,\"start\":50089},{\"end\":50104,\"start\":50099},{\"end\":50438,\"start\":50434},{\"end\":50447,\"start\":50442},{\"end\":50456,\"start\":50451},{\"end\":50463,\"start\":50460},{\"end\":50474,\"start\":50470},{\"end\":50483,\"start\":50478},{\"end\":50881,\"start\":50877},{\"end\":50888,\"start\":50885},{\"end\":50899,\"start\":50894},{\"end\":50911,\"start\":50906},{\"end\":51177,\"start\":51174},{\"end\":51288,\"start\":51284},{\"end\":51300,\"start\":51295},{\"end\":51307,\"start\":51304},{\"end\":51680,\"start\":51676},{\"end\":51691,\"start\":51686},{\"end\":51708,\"start\":51695},{\"end\":52108,\"start\":52103},{\"end\":52125,\"start\":52112},{\"end\":52133,\"start\":52129},{\"end\":52155,\"start\":52139},{\"end\":52481,\"start\":52477},{\"end\":52490,\"start\":52485},{\"end\":52498,\"start\":52494},{\"end\":52504,\"start\":52502},{\"end\":52510,\"start\":52508},{\"end\":52516,\"start\":52514},{\"end\":52527,\"start\":52520},{\"end\":52871,\"start\":52864},{\"end\":52882,\"start\":52877},{\"end\":52890,\"start\":52886},{\"end\":52907,\"start\":52894},{\"end\":53396,\"start\":53393},{\"end\":53404,\"start\":53400},{\"end\":53411,\"start\":53408},{\"end\":53419,\"start\":53415},{\"end\":53737,\"start\":53732},{\"end\":53745,\"start\":53741},{\"end\":53751,\"start\":53749},{\"end\":53759,\"start\":53755},{\"end\":53767,\"start\":53763},{\"end\":54068,\"start\":54065},{\"end\":54076,\"start\":54072},{\"end\":54083,\"start\":54080},{\"end\":54089,\"start\":54087},{\"end\":54368,\"start\":54366},{\"end\":54375,\"start\":54372},{\"end\":54381,\"start\":54379},{\"end\":54387,\"start\":54385},{\"end\":54395,\"start\":54391},{\"end\":54402,\"start\":54399},{\"end\":54661,\"start\":54654},{\"end\":54668,\"start\":54665},{\"end\":54678,\"start\":54672},{\"end\":54690,\"start\":54682},{\"end\":54701,\"start\":54696},{\"end\":54826,\"start\":54815},{\"end\":54833,\"start\":54830},{\"end\":54845,\"start\":54837},{\"end\":54859,\"start\":54849},{\"end\":54871,\"start\":54863},{\"end\":55164,\"start\":55162},{\"end\":55171,\"start\":55168},{\"end\":55178,\"start\":55175},{\"end\":55184,\"start\":55182},{\"end\":55190,\"start\":55188},{\"end\":55198,\"start\":55194},{\"end\":55358,\"start\":55351},{\"end\":55576,\"start\":55569},{\"end\":55587,\"start\":55583},{\"end\":55599,\"start\":55591},{\"end\":55882,\"start\":55873},{\"end\":55895,\"start\":55886},{\"end\":55906,\"start\":55899},{\"end\":56212,\"start\":56205},{\"end\":56224,\"start\":56219},{\"end\":56234,\"start\":56228},{\"end\":56563,\"start\":56558},{\"end\":56569,\"start\":56567},{\"end\":56580,\"start\":56575},{\"end\":56887,\"start\":56885},{\"end\":56895,\"start\":56891},{\"end\":56904,\"start\":56902},{\"end\":56915,\"start\":56910},{\"end\":57110,\"start\":57104},{\"end\":57120,\"start\":57114},{\"end\":57130,\"start\":57124},{\"end\":57385,\"start\":57380},{\"end\":57391,\"start\":57389},{\"end\":57399,\"start\":57397},{\"end\":57405,\"start\":57403},{\"end\":57414,\"start\":57409},{\"end\":57422,\"start\":57418},{\"end\":57605,\"start\":57599},{\"end\":57776,\"start\":57756},{\"end\":57786,\"start\":57780},{\"end\":58061,\"start\":58051},{\"end\":58071,\"start\":58065},{\"end\":58084,\"start\":58075},{\"end\":58196,\"start\":58194},{\"end\":58245,\"start\":58238},{\"end\":58252,\"start\":58249},{\"end\":58259,\"start\":58256},{\"end\":58271,\"start\":58263},{\"end\":58279,\"start\":58275},{\"end\":58291,\"start\":58283},{\"end\":58300,\"start\":58295},{\"end\":58426,\"start\":58417},{\"end\":58440,\"start\":58430},{\"end\":58760,\"start\":58754},{\"end\":58766,\"start\":58764},{\"end\":58958,\"start\":58953},{\"end\":58966,\"start\":58962},{\"end\":58973,\"start\":58970},{\"end\":58984,\"start\":58979},{\"end\":59227,\"start\":59217},{\"end\":59413,\"start\":59402},{\"end\":59421,\"start\":59417},{\"end\":59786,\"start\":59780},{\"end\":59799,\"start\":59792},{\"end\":60050,\"start\":60045},{\"end\":60311,\"start\":60305},{\"end\":61793,\"start\":61790},{\"end\":61995,\"start\":61982},{\"end\":62361,\"start\":62352}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":46157,\"start\":45901},{\"attributes\":{\"id\":\"b1\"},\"end\":46281,\"start\":46159},{\"attributes\":{\"doi\":\"arXiv:2106.13023.738\",\"id\":\"b2\"},\"end\":46591,\"start\":46283},{\"attributes\":{\"id\":\"b3\"},\"end\":46875,\"start\":46593},{\"attributes\":{\"id\":\"b4\"},\"end\":46935,\"start\":46877},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":226230720},\"end\":47305,\"start\":46937},{\"attributes\":{\"id\":\"b6\"},\"end\":47559,\"start\":47307},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":17731209},\"end\":47777,\"start\":47561},{\"attributes\":{\"id\":\"b8\"},\"end\":48093,\"start\":47779},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":18078269},\"end\":48370,\"start\":48095},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":214054302},\"end\":48731,\"start\":48372},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":240032298},\"end\":49191,\"start\":48733},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":90099899},\"end\":49364,\"start\":49193},{\"attributes\":{\"id\":\"b13\"},\"end\":49725,\"start\":49366},{\"attributes\":{\"id\":\"b14\"},\"end\":50011,\"start\":49727},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":3499915},\"end\":50341,\"start\":50013},{\"attributes\":{\"id\":\"b16\"},\"end\":50768,\"start\":50343},{\"attributes\":{\"id\":\"b17\"},\"end\":51170,\"start\":50770},{\"attributes\":{\"id\":\"b18\"},\"end\":51196,\"start\":51172},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":7639899},\"end\":51507,\"start\":51198},{\"attributes\":{\"id\":\"b20\"},\"end\":51571,\"start\":51509},{\"attributes\":{\"id\":\"b21\"},\"end\":52005,\"start\":51573},{\"attributes\":{\"id\":\"b22\"},\"end\":52400,\"start\":52007},{\"attributes\":{\"doi\":\"IEEE 792\",\"id\":\"b23\"},\"end\":52687,\"start\":52402},{\"attributes\":{\"id\":\"b24\"},\"end\":52782,\"start\":52689},{\"attributes\":{\"id\":\"b25\"},\"end\":53050,\"start\":52784},{\"attributes\":{\"id\":\"b26\"},\"end\":53306,\"start\":53052},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":215846216},\"end\":53647,\"start\":53308},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":202572897},\"end\":53978,\"start\":53649},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":222297732},\"end\":54305,\"start\":53980},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":220314317},\"end\":54588,\"start\":54307},{\"attributes\":{\"id\":\"b31\"},\"end\":54648,\"start\":54590},{\"attributes\":{\"id\":\"b32\"},\"end\":54766,\"start\":54650},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":30172337},\"end\":55063,\"start\":54768},{\"attributes\":{\"id\":\"b34\"},\"end\":55347,\"start\":55065},{\"attributes\":{\"id\":\"b35\"},\"end\":55490,\"start\":55349},{\"attributes\":{\"doi\":\"arXiv:1409.2574\",\"id\":\"b36\"},\"end\":55759,\"start\":55492},{\"attributes\":{\"doi\":\"arXiv:2004.10715\",\"id\":\"b37\"},\"end\":56110,\"start\":55761},{\"attributes\":{\"id\":\"b38\"},\"end\":56390,\"start\":56112},{\"attributes\":{\"id\":\"b39\"},\"end\":56457,\"start\":56392},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":209444725},\"end\":56748,\"start\":56459},{\"attributes\":{\"id\":\"b41\"},\"end\":56821,\"start\":56750},{\"attributes\":{\"id\":\"b42\"},\"end\":57080,\"start\":56823},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":29157140},\"end\":57303,\"start\":57082},{\"attributes\":{\"id\":\"b44\"},\"end\":57593,\"start\":57305},{\"attributes\":{\"id\":\"b45\"},\"end\":57659,\"start\":57595},{\"attributes\":{\"id\":\"b46\"},\"end\":57942,\"start\":57661},{\"attributes\":{\"id\":\"b47\"},\"end\":58047,\"start\":57944},{\"attributes\":{\"id\":\"b48\"},\"end\":58186,\"start\":58049},{\"attributes\":{\"id\":\"b49\"},\"end\":58232,\"start\":58188},{\"attributes\":{\"id\":\"b50\"},\"end\":58381,\"start\":58234},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":206592484},\"end\":58704,\"start\":58383},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b52\"},\"end\":58884,\"start\":58706},{\"attributes\":{\"id\":\"b53\"},\"end\":59213,\"start\":58886},{\"attributes\":{\"id\":\"b54\"},\"end\":59334,\"start\":59215},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":114654356},\"end\":59605,\"start\":59336},{\"attributes\":{\"id\":\"b56\"},\"end\":59717,\"start\":59607},{\"attributes\":{\"id\":\"b57\"},\"end\":59969,\"start\":59719},{\"attributes\":{\"id\":\"b58\"},\"end\":60194,\"start\":59971},{\"attributes\":{\"doi\":\"arXiv:2010.16061\",\"id\":\"b59\"},\"end\":60483,\"start\":60196},{\"attributes\":{\"id\":\"b60\"},\"end\":60768,\"start\":60485},{\"attributes\":{\"id\":\"b61\"},\"end\":60963,\"start\":60770},{\"attributes\":{\"id\":\"b62\"},\"end\":61069,\"start\":60965},{\"attributes\":{\"id\":\"b63\"},\"end\":61619,\"start\":61071},{\"attributes\":{\"id\":\"b64\"},\"end\":61969,\"start\":61621},{\"attributes\":{\"id\":\"b65\"},\"end\":62047,\"start\":61971},{\"attributes\":{\"id\":\"b66\"},\"end\":62247,\"start\":62049},{\"attributes\":{\"id\":\"b67\"},\"end\":62881,\"start\":62249},{\"attributes\":{\"id\":\"b68\"},\"end\":63173,\"start\":62883},{\"attributes\":{\"id\":\"b69\"},\"end\":63780,\"start\":63175},{\"attributes\":{\"id\":\"b70\"},\"end\":63901,\"start\":63782},{\"attributes\":{\"id\":\"b71\"},\"end\":64051,\"start\":63903},{\"attributes\":{\"doi\":\"PIMRC. 923\",\"id\":\"b72\"},\"end\":64298,\"start\":64053}]", "bib_title": "[{\"end\":47032,\"start\":46937},{\"end\":47368,\"start\":47307},{\"end\":47610,\"start\":47561},{\"end\":47846,\"start\":47779},{\"end\":48161,\"start\":48095},{\"end\":48466,\"start\":48372},{\"end\":48852,\"start\":48733},{\"end\":49219,\"start\":49193},{\"end\":49434,\"start\":49366},{\"end\":49787,\"start\":49727},{\"end\":50063,\"start\":50013},{\"end\":50430,\"start\":50343},{\"end\":50873,\"start\":50770},{\"end\":51277,\"start\":51198},{\"end\":51670,\"start\":51573},{\"end\":52097,\"start\":52007},{\"end\":53389,\"start\":53308},{\"end\":53728,\"start\":53649},{\"end\":54061,\"start\":53980},{\"end\":54362,\"start\":54307},{\"end\":54811,\"start\":54768},{\"end\":56554,\"start\":56459},{\"end\":56878,\"start\":56823},{\"end\":57100,\"start\":57082},{\"end\":57376,\"start\":57305},{\"end\":57752,\"start\":57661},{\"end\":58413,\"start\":58383},{\"end\":58946,\"start\":58886},{\"end\":59396,\"start\":59336},{\"end\":62344,\"start\":62249},{\"end\":62947,\"start\":62883}]", "bib_author": "[{\"end\":45916,\"start\":45903},{\"end\":45928,\"start\":45916},{\"end\":45946,\"start\":45928},{\"end\":45963,\"start\":45946},{\"end\":45979,\"start\":45963},{\"end\":45996,\"start\":45979},{\"end\":46010,\"start\":45996},{\"end\":46021,\"start\":46010},{\"end\":46173,\"start\":46161},{\"end\":46194,\"start\":46173},{\"end\":46204,\"start\":46194},{\"end\":46216,\"start\":46204},{\"end\":46393,\"start\":46380},{\"end\":46405,\"start\":46393},{\"end\":46683,\"start\":46673},{\"end\":46695,\"start\":46683},{\"end\":46705,\"start\":46695},{\"end\":46885,\"start\":46879},{\"end\":47041,\"start\":47034},{\"end\":47048,\"start\":47041},{\"end\":47054,\"start\":47048},{\"end\":47060,\"start\":47054},{\"end\":47068,\"start\":47060},{\"end\":47380,\"start\":47370},{\"end\":47624,\"start\":47612},{\"end\":47860,\"start\":47848},{\"end\":47874,\"start\":47860},{\"end\":47885,\"start\":47874},{\"end\":48180,\"start\":48163},{\"end\":48194,\"start\":48180},{\"end\":48479,\"start\":48468},{\"end\":48487,\"start\":48479},{\"end\":48504,\"start\":48487},{\"end\":48862,\"start\":48854},{\"end\":48873,\"start\":48862},{\"end\":48881,\"start\":48873},{\"end\":48891,\"start\":48881},{\"end\":48898,\"start\":48891},{\"end\":49227,\"start\":49221},{\"end\":49234,\"start\":49227},{\"end\":49445,\"start\":49436},{\"end\":49454,\"start\":49445},{\"end\":49461,\"start\":49454},{\"end\":49468,\"start\":49461},{\"end\":49479,\"start\":49468},{\"end\":49488,\"start\":49479},{\"end\":49806,\"start\":49789},{\"end\":49816,\"start\":49806},{\"end\":50075,\"start\":50065},{\"end\":50087,\"start\":50075},{\"end\":50097,\"start\":50087},{\"end\":50106,\"start\":50097},{\"end\":50440,\"start\":50432},{\"end\":50449,\"start\":50440},{\"end\":50458,\"start\":50449},{\"end\":50465,\"start\":50458},{\"end\":50476,\"start\":50465},{\"end\":50485,\"start\":50476},{\"end\":50883,\"start\":50875},{\"end\":50890,\"start\":50883},{\"end\":50901,\"start\":50890},{\"end\":50913,\"start\":50901},{\"end\":51179,\"start\":51174},{\"end\":51290,\"start\":51279},{\"end\":51302,\"start\":51290},{\"end\":51309,\"start\":51302},{\"end\":51682,\"start\":51672},{\"end\":51693,\"start\":51682},{\"end\":51710,\"start\":51693},{\"end\":52110,\"start\":52099},{\"end\":52127,\"start\":52110},{\"end\":52135,\"start\":52127},{\"end\":52157,\"start\":52135},{\"end\":52483,\"start\":52475},{\"end\":52492,\"start\":52483},{\"end\":52500,\"start\":52492},{\"end\":52506,\"start\":52500},{\"end\":52512,\"start\":52506},{\"end\":52518,\"start\":52512},{\"end\":52529,\"start\":52518},{\"end\":52873,\"start\":52862},{\"end\":52884,\"start\":52873},{\"end\":52892,\"start\":52884},{\"end\":52909,\"start\":52892},{\"end\":53398,\"start\":53391},{\"end\":53406,\"start\":53398},{\"end\":53413,\"start\":53406},{\"end\":53421,\"start\":53413},{\"end\":53739,\"start\":53730},{\"end\":53747,\"start\":53739},{\"end\":53753,\"start\":53747},{\"end\":53761,\"start\":53753},{\"end\":53769,\"start\":53761},{\"end\":54070,\"start\":54063},{\"end\":54078,\"start\":54070},{\"end\":54085,\"start\":54078},{\"end\":54091,\"start\":54085},{\"end\":54370,\"start\":54364},{\"end\":54377,\"start\":54370},{\"end\":54383,\"start\":54377},{\"end\":54389,\"start\":54383},{\"end\":54397,\"start\":54389},{\"end\":54404,\"start\":54397},{\"end\":54663,\"start\":54652},{\"end\":54670,\"start\":54663},{\"end\":54680,\"start\":54670},{\"end\":54692,\"start\":54680},{\"end\":54703,\"start\":54692},{\"end\":54828,\"start\":54813},{\"end\":54835,\"start\":54828},{\"end\":54847,\"start\":54835},{\"end\":54861,\"start\":54847},{\"end\":54873,\"start\":54861},{\"end\":55166,\"start\":55160},{\"end\":55173,\"start\":55166},{\"end\":55180,\"start\":55173},{\"end\":55186,\"start\":55180},{\"end\":55192,\"start\":55186},{\"end\":55200,\"start\":55192},{\"end\":55360,\"start\":55351},{\"end\":55578,\"start\":55565},{\"end\":55589,\"start\":55578},{\"end\":55601,\"start\":55589},{\"end\":55884,\"start\":55871},{\"end\":55897,\"start\":55884},{\"end\":55908,\"start\":55897},{\"end\":56214,\"start\":56203},{\"end\":56226,\"start\":56214},{\"end\":56236,\"start\":56226},{\"end\":56565,\"start\":56556},{\"end\":56571,\"start\":56565},{\"end\":56582,\"start\":56571},{\"end\":56889,\"start\":56880},{\"end\":56897,\"start\":56889},{\"end\":56906,\"start\":56897},{\"end\":56917,\"start\":56906},{\"end\":57112,\"start\":57102},{\"end\":57122,\"start\":57112},{\"end\":57132,\"start\":57122},{\"end\":57387,\"start\":57378},{\"end\":57393,\"start\":57387},{\"end\":57401,\"start\":57393},{\"end\":57407,\"start\":57401},{\"end\":57416,\"start\":57407},{\"end\":57424,\"start\":57416},{\"end\":57607,\"start\":57597},{\"end\":57778,\"start\":57754},{\"end\":57788,\"start\":57778},{\"end\":58063,\"start\":58049},{\"end\":58073,\"start\":58063},{\"end\":58086,\"start\":58073},{\"end\":58198,\"start\":58190},{\"end\":58247,\"start\":58236},{\"end\":58254,\"start\":58247},{\"end\":58261,\"start\":58254},{\"end\":58273,\"start\":58261},{\"end\":58281,\"start\":58273},{\"end\":58293,\"start\":58281},{\"end\":58302,\"start\":58293},{\"end\":58428,\"start\":58415},{\"end\":58442,\"start\":58428},{\"end\":58762,\"start\":58750},{\"end\":58768,\"start\":58762},{\"end\":58960,\"start\":58948},{\"end\":58968,\"start\":58960},{\"end\":58975,\"start\":58968},{\"end\":58986,\"start\":58975},{\"end\":59229,\"start\":59217},{\"end\":59415,\"start\":59398},{\"end\":59423,\"start\":59415},{\"end\":59788,\"start\":59778},{\"end\":59801,\"start\":59788},{\"end\":60052,\"start\":60043},{\"end\":60313,\"start\":60299},{\"end\":61795,\"start\":61786},{\"end\":61997,\"start\":61973},{\"end\":62055,\"start\":62049},{\"end\":62061,\"start\":62055},{\"end\":62363,\"start\":62346}]", "bib_venue": "[{\"end\":46378,\"start\":46283},{\"end\":46671,\"start\":46593},{\"end\":47088,\"start\":47068},{\"end\":47405,\"start\":47380},{\"end\":47638,\"start\":47624},{\"end\":47903,\"start\":47885},{\"end\":48204,\"start\":48194},{\"end\":48518,\"start\":48504},{\"end\":48925,\"start\":48898},{\"end\":49247,\"start\":49234},{\"end\":49512,\"start\":49488},{\"end\":49846,\"start\":49816},{\"end\":50140,\"start\":50106},{\"end\":50510,\"start\":50485},{\"end\":50943,\"start\":50913},{\"end\":51332,\"start\":51309},{\"end\":51529,\"start\":51511},{\"end\":51761,\"start\":51710},{\"end\":52170,\"start\":52157},{\"end\":52473,\"start\":52402},{\"end\":52710,\"start\":52691},{\"end\":52860,\"start\":52784},{\"end\":53131,\"start\":53052},{\"end\":53445,\"start\":53421},{\"end\":53781,\"start\":53769},{\"end\":54108,\"start\":54091},{\"end\":54423,\"start\":54404},{\"end\":54608,\"start\":54590},{\"end\":54882,\"start\":54873},{\"end\":55158,\"start\":55065},{\"end\":55387,\"start\":55360},{\"end\":55563,\"start\":55492},{\"end\":55869,\"start\":55761},{\"end\":56201,\"start\":56112},{\"end\":56400,\"start\":56394},{\"end\":56593,\"start\":56582},{\"end\":56764,\"start\":56752},{\"end\":56940,\"start\":56917},{\"end\":57162,\"start\":57132},{\"end\":57437,\"start\":57424},{\"end\":57796,\"start\":57788},{\"end\":57983,\"start\":57946},{\"end\":58099,\"start\":58086},{\"end\":58496,\"start\":58442},{\"end\":58748,\"start\":58706},{\"end\":59013,\"start\":58986},{\"end\":59443,\"start\":59423},{\"end\":59651,\"start\":59609},{\"end\":59776,\"start\":59719},{\"end\":60041,\"start\":59971},{\"end\":60297,\"start\":60196},{\"end\":60578,\"start\":60485},{\"end\":60825,\"start\":60770},{\"end\":61012,\"start\":60965},{\"end\":61323,\"start\":61071},{\"end\":61784,\"start\":61621},{\"end\":62142,\"start\":62061},{\"end\":62473,\"start\":62363},{\"end\":62976,\"start\":62949},{\"end\":63434,\"start\":63175},{\"end\":63820,\"start\":63782},{\"end\":63976,\"start\":63903},{\"end\":64120,\"start\":64053},{\"end\":47648,\"start\":47640},{\"end\":51351,\"start\":51334},{\"end\":53206,\"start\":53133},{\"end\":54438,\"start\":54425},{\"end\":58110,\"start\":58101},{\"end\":58546,\"start\":58498},{\"end\":59459,\"start\":59445},{\"end\":60589,\"start\":60580},{\"end\":62502,\"start\":62475}]"}}}, "year": 2023, "month": 12, "day": 17}