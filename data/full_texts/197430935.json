{"id": 197430935, "updated": "2023-10-07 00:54:36.941", "metadata": {"title": "A Survey on Explainable Artificial Intelligence (XAI): Towards Medical XAI", "authors": "[{\"first\":\"Erico\",\"last\":\"Tjoa\",\"middle\":[]},{\"first\":\"Cuntai\",\"last\":\"Guan\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2019, "month": 7, "day": 17}, "abstract": "Recently, artificial intelligence, especially machine learning has demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning. Along with research progress, machine learning has encroached into many different fields and disciplines. Some of them, such as the medical field, require high level of accountability, and thus transparency, which means we need to be able to explain machine decisions, predictions and justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the black-box nature of the deep learning is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them, with the intention of providing alternative perspective that is hopefully more tractable for future adoption of interpretability standard. We explore further into interpretability in the medical field, illustrating the complexity of interpretability issue.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": "1907.07374", "mag": "3094189037", "acl": null, "pubmed": "33079674", "pubmedcentral": null, "dblp": "journals/tnn/TjoaG21", "doi": "10.1109/tnnls.2020.3027314"}}, "content": {"source": {"pdf_hash": "38f23fe236b152cd4983c8f30d305a568afd0d3e", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1907.07374v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://ieeexplore.ieee.org/ielx7/5962385/6104215/09233366.pdf", "status": "BRONZE"}}, "grobid": {"id": "c3e31d7081421f117f880d812dd8185816ad2b68", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/38f23fe236b152cd4983c8f30d305a568afd0d3e.txt", "contents": "\n\n\nIndex Terms-Explainable Artificial IntelligenceSurveyMachine LearningInterpretabilityMedical Information System\nRecently, artificial intelligence, especially machine learning has demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning. Along with research progress, machine learning has encroached into many different fields and disciplines. Some of them, such as the medical field, require high level of accountability, and thus transparency, which means we need to be able to explain machine decisions, predictions and justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the black-box nature of the deep learning is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them, with the intention of providing alternative perspective that is hopefully more tractable for future adoption of interpretability standard. We explore further into interpretability in the medical field, illustrating the complexity of interpretability issue.\n\nINTRODUCTION\n\nMachine learning (ML) has grown large in both research and industrial applications, especially with the success of deep learning (DL) and neural networks (NN), so large that its impact and possible after-effects can no longer be taken for granted. In some fields, failure is not an option: even a momentarily dysfunctional computer vision algorithm in autonomous vehicle easily leads to fatality. In the medical field, clearly human lives are on the line. Detection of a disease at its early phase is often critical to the recovery of patients or to prevent the disease from advancing to more severe stages. While machine learning methods, artificial neural networks, brain-machine interfaces and related subfields have recently demonstrated promising performance in performing medical tasks, they are hardly perfect [1] [2] [3] [4] [5] [6] [7] [8].\n\nInterpretability and explainability of a ML algorithm have thus become pressing issues: who is accountable if things go wrong? Can we explain why things go wrong? If things are working well, do we know why and how to leverage on them further? Many papers have suggested different measures and frameworks to capture interpretability, and the topic explainable artificial intelligence (XAI) has become a hotspot in ML research community. Furthermore, the proliferation of interpretability assessment criteria (such as reliability, causality and usability) helps ML community keep track of how algorithms are used and how their usage can be improved, providing guiding posts for further developments [9] [10] [11]. In particular, [12] shows how visualization is capable of helping researchers detect erroneous reasoning in classification problems that many previous researchers have missed,\n\nIn this work, we survey through research works related to the interpretability of ML or computer algorithms in general, categorize them, and then apply the same categories to the interpretability in the medical field. We will not attempt to cover all the related works many of which are already presented in the research and survey works we cite [1] [2] [9] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] [23]. This paper is arranged as the following. Section 2 explores the types of interpretability. Section 3 lists some concepts that frequently occur in interpretability studies. Section 4 examines a proposed category for interpretabilities. Section 5 extends the previous sections into the medical field. Lastly, it is also imperative to point out that the issue of accountability and interpretability has even entered the sphere of ethics and law enforcements [24], engendering movements to protect the society from possible misuses and harms in the wake of the increasing use of AI.\n\n\nTYPES OF INTERPRETABILITY\n\nThere has yet to be a widely-adopted standard to understand ML interpretability, though there have been works proposing frameworks for interpretability [9] [25] [12]. In fact, different works use different criteria, and they are justifiable in one way or another. [26] suggests network dissection for the interpretability of visual representations, and offers a way to quantify it as well. [27] [28] have suggested a unified framework to study interpretabilities that have thus-far been studied separately. [29] defines a unified measure of feature importance. Here, we categorize existing interpretabilities and present non-exhaustive list of works in each category.\n\n\nVisual and Textual Explanations as Interpretability\n\nThe paper [30] aptly summarizes interpretability issue within ML research with the phrase \"Why Should I Trust You?\". It introduces LIME algorithm (Local Interpretable Model-agnostic Explanations) that explains the output of other models visually or textually. In this vein, it suggests that an interpretable model is one that provides a humanly easyto-understand explanations. For example, an interpretable classifier will distinguish an elephant from a yellow-striped A Survey on Explainable Artificial Intelligence (XAI):\n\ntowards Medical XAI Erico Tjoa and Cuntai Guan Fellow, IEEE cat by explaining its choice with words such as \"grey\" and \"trunk\". In text classification problems, a model will distinguish a food-related article from a sports news by providing an importance chart highlighting words such as \"delicious\" and \"tasty\".\n\nIn image processing, saliency maps, heat maps and superpixels may be the natural way towards interpretability. For example, in an object detection problem, the detection of a dog in an image can be explained by providing an image obtained from element-wise multiplication of the image with its super-pixel map. The output, i.e. the explanation, is the same image with the dog left intact and greyed out region elsewhere. More generally, if \u2208 \u211d \u00d7 is the original representation having \u00d7 pixels, then the super-pixel map \u2032 \u2208 \u211d \u00d7 \u2208 {0,1} \u00d7 indicates the presence of some human-interpretable feature around some patches in the image, labeling the pixels in the patches with 1 (and labelling other patches with 0). The explanation is then the elementwise product * \u2032 . Recently developed Automatic Concept-based Explanations (ACE) algorithm [31] also uses superpixels as explanations.\n\nClass Activation Map (CAM) has been introduced as a kind of saliency-map that corresponds to discriminative features for classifications [32] [33] [34]. In an image of a person with a dog, to explain the detection the dog, localization is performed by computing a heatmap showing high intensity around the image patches where the dog is. This has been shown to correspond to a reasonably high accuracy of object classification. Note that, so far, there is neither explanation nor interpretation of the inner working of an ML algorithm. [ [40] use Layer-wise Relevance Propagation (LRP) to construct heat-maps/relevance-maps for interpretability. Saliency map can be in the form of \"heat\" scores over words in texts in natural language processing or sentiment analysis, as demonstrated by [41] using LRP and by [42]. Heat-map values correspond to the importance of the pixels in their contribution to the classification. According (B) A model that explicitly provides the logical statement leading to some conclusion is sometimes considered obviously interpretable. (C) A parametric model can be pre-specified. Variables are then interpreted with respect to the equation and how the output y might vary with them. (D) Features can be extracted in the form of multi-dimensional vectors with meaningful weightage of variables. For example, blue feature in the figure corresponds to the effect of healthy-lifestyle on the output variable. (E) Decisions can be interpreted as the amount of confidence a model groups an object into different categories. (F) Typically, large collection of data is fed into algorithm to minimize loss function. This example, however, shows tabulation of vast data collection across different dimensions and different models which has been suggested as a means to achieve interpretability.\n\nto [43], LRP is considered a decomposition. Indeed, the importance scores are decomposed such that the sum of the scores in each layer will be equal to the output. In short, ( ) = \u03a3 ( ) where is the relevance score of neuron and any layer whose relevance scores are considered. Other decomposition methods further developed include Deep Taylor Decomposition [44], DeepLIFT and gradient*input [45], Prediction Difference Analysis [46].\n\nA feature map is the output of the convolution of a filter with the output from a previous layer in a convolutional neural network (CNN). [47] demonstrates that feature maps in the deeper layer activate more strongly to complex features, such as human face, keyboard etc. Conversely, it is observed that earlier layers activate more strongly to simple features such as edges, vertical lines etc. Methods of interpretability that observe the stimulation of neuron layers like this are also called signal methods [48] (although this paper specifically refers to the observation of neuron layers at higher layers).\n\nA feature map often looks like a highly blurred image with most region showing zero (or low intensity), except for the patch that a human could roughly discern as a detected feature. Sometimes, these discernible features are considered interpretable, as in [47]. However, they might be too distorted to be acceptable. Then, how else can a feature map be related to a humanly visible feature? An inverse convolution map can be defined: for example, if feature map in layer 2 is computed in the network via 2 = 2 ( 1 ( )) where is the input, 1 (. ) consists of 7x7 convolutions of stride 2 followed by maxpooling and likewise 2 (. ). Then [47] reconstructs an image using a deconvolution network by approximately inversing the trained convolutional network \u0303= ( ) = 2 \u22121\u03031\u22121 ( ) which is an approximation, because layers such as max-pooling have no unique inverse. It is shown that \u0303 does appear like slightly blurred version of the original image, which is distinct to human eye. Inversion of image representations within the layers has been used to demonstrate that CNN layers do store important information of an input image accurately [49] [50]. Earlier works of visualization of neural network layers include [51] on MNIST dataset and [52] that shows more recognizable visual cues within deep layers.\n\nFeature visualization by optimization is described by [27] with an excellent interactive interface. In essence, choose a neuron (or a set of them) from a neural network (NN), then an input image is optimized so as to maximize or minimize the activation of the neuron. Starting with a noise as an input, the optimized input that maximizes the activation of a neuron can emerge as something visually interpretable. For example, the image could be a surreal fuzzy combination of swirling patterns and parts of dog faces. Earlier research is similar, \"synthesizing preferred input\" using deep generator networks [53].\n\nIn [27] , GoogLeNet [54] is used, which has the advantage of having deep layers. Images that optimize neuron activations at deeper layer turn out to be interesting as well, some being combinations of visibly distinct parts of cat faces with cars, suggesting that each neuron might not always correspond to concepts that are similar with respect to human understanding. Unfortunately, many high frequencies or intricate patterns are still hard to explain.\n\nTo bring this one step further, [28] introduces the \"semantic dictionary\". Given an image of a cat, pick a small patch, for example, corresponding to the paw of the cat. Observe the activation intensities 1 , 2 , \u2026 of several corresponding neurons 1 , 2 , \u2026 generally from different layers in decreasing intensity of activation. Using the feature visualization by optimization explained before, each neuron corresponds to an optimized input 1 , 2 , \u2026 and { , = 1, \u2026 , } forms the semantic dictionary. Then, we can say that the paw corresponds to 1 \u00d7 1 + 2 \u00d7 2 + \u22ef. The good news is, if 1 is a somewhat clear image, for example, a surreal combinations of paws and claws, then we can at least say the small patch we chose from the cat image has 1 degree of \"paw-ness\". The bad news is, say, if 2 is some undecipherable swirls of patterns, we have nothing much to interpret.\n\nIn the medical field (see later section), [34] [55] [56] [57] [58] have studied methods employing visual explanations.\n\n\nLogical Statements as Interpretability\n\nLogical statements can be formed from proper concatenation of predicates, connectives etc. An example of logical statement is the conditional statement. Conditional statements are statements of the form \u2192 , in another words \"if A then B\". An ML model from which logical statements can be extracted directly has been considered obviously interpretable. In [59], a rule-based system could provide the statement \"has asthma\u2192lower risk\", where risk here refers to death risk due to pneumonia. Likewise, [60] creates a model that provides such statements for stroke prediction.\n\nOne can indeed question the interpretability there. Just as many MLs are able to extract some humanly non-intuitive pattern, the rule-based system seems to have captured the strange link between asthma and pneumonia. The link becomes clear once the actual explanation based on real situation is provided: a pneumonia patient which also suffers from asthma is often sent directly to the Intensive Care Unit (ICU) rather than a standard ward. Obviously, if there is a variable ICU=0 or 1 that indicates admission to ICU, then a better model can provide \"asthma\u2192 ICU\u2192 lower risk\". In the paper, the model appears not to do so. We can see that interpretability issues are not always clear-cut.\n\nSimilarly, decision sets or rule sets have been studied for interpretability [61]. A single line in a rule set is for example \" rainy and gumpy or calm \u2192 dairy or vegetables \". Each line in a rule set contains a clause with an input in disjunctive normal form (DNF) mapped to an output in DNF as well. The example above is formally written (rainy \u2227 gumpy) \u2228 calm \u2192 dairy \u2227 veget . Comparing three different variables, [61] finds out that interpretability of explanations in the form of rule sets is most affected by cognitive chunks, explanation size and little effected by variable repetition. Here, a cognitive chunk is defined as a clause of inputs in DNF and the number of (repeated) cognitive chunks in a rule set is varied. The explanation size is self-explanatory (a longer/shorter line in a rule set, or more/less lines in a rule set).\n\n\nModel-based Interpretability\n\nA problem can be put into the framework of a model, and the explanation can then be extracted from the typically parametric model. In the medical field (see later section), kinetic modelling is a popular choice, and machine learning can be used to compute the parameters. Other methods exist, for example, [62] utilizes regression to create interpretable solution indirectly. A good regression model will provide a relation that reveals a trend. For example, = ( \u20d7) = ( 1 , \u2026 , , \u2026 ) can provide a trend like \" increases linearly with but does not depend on \". In other cases, the explanation can be in the form of more general logical statement \"if [ \u20d7] then [ ( \u20d7)]\", where , are the appropriate predicates. As in the previous section, such statements have sometimes been taken as obviously interpretable. Note that the dependence on the variables { } might be hard to interpret if (. ) turns out to be a very complex function.\n\nIn [59], a logistic regression model picked up a relation between asthma and lower risk of pneumonia death, i.e. asthma has a negative weight as a risk predictor in the regression model. This idea is represented by the Generalized Additive Model (GAM) [63] [64] with standard form ( [ ]) = 0 + \u03a3 ( ) where is the link function. The familiar General Linear Model (GLM) is GAM with linear . Besides, as a natural extension to the model, interaction terms like ( ) can be used as well [65]. [66] introduced atomistic neural network architecture, in which each atom is like a node in a graph with a set of feature vectors. The specifics depend on the neural network used, but this model is considered inherently interpretable.\n\n\nKernel function, Reduced Dimension and Features Extraction for Interpretability\n\nA kernel function transforms high-dimensional vectors such that the transformed vectors better distinguish different features in the data. For example, the Principal Component Analysis transforms vectors into the principal components (PC) that can be ordered by the eigenvalues of singular-valuedecomposed (SVD) covariance matrix. The PC with the highest eigenvalue is roughly the most informative feature. Many kernel functions have been introduced, including the Canonical Correlation Analysis (CCA) [67].\n\nHow does a kernel function help with interpretability? We give an intuitive explanation via a hypothetical example of a classifier for heart-attack prediction. Given, say, 100dimensional features including eating pattern, job and residential area of a subject. The kernel function of a model finds out that the strong predictor for heart attack is a 100dimensional vector which is significant in the following axes: eating pattern, exercise frequency and sleeping pattern. Then, this model is interpretable because we can link heart-attack risk with healthy habits rather than, say socio-geographical factors. More information can be drawn from the next most significant predictor and so on.\n\nRecently, Singular Vector Canonical Correlation Analysis (SVCCA) is suggested as a tool to analyze interpretability [68]. Given an input dataset = { 1 , \u2026 , } where each input is possibly multi-dimensional. Denote the activation of neuron at layer as = ( ( 1 ), \u2026 , ( )). Note that one such output is defined for the entire input dataset. SVCCA finds out the relation between 2 layers of a network = { | = 1, \u2026 , } for = 1, 2 by taking 1 and 2 as the input (generally, does not have to be the entire layer). SVCCA uses SVD to extract the most informative components \u2032 and uses CCA to transform 1 \u2032 and 2 \u2032 such that \u0305 1 \u2032 = 1 \u2032 and \u0305 2 \u2032 = 2 \u2032 have the maximum correlation = { 1 , \u2026 , min( 1 , 2 ) } . One of the SVCCA experiments on CIFAR-10 demonstrates that only 25 most-significant axes in \u2032 are needed to obtain nearly the full accuracy of a fullnetwork with 512 dimensions. Besides, the similarity between 2 compared layers is defined to be \u0305 = 1 min( 1 , 2 ) \u03a3 . Testing with Concept Activation Vectors (TCAV) has also been introduced as a technique to interpret the low-level representation of neural network layer [69]. Given input \u2208 \u211d and a feedforward layer having neurons, then the activation at that layer can be given by : \u211d \u2192 \u211d . If we are interested in the concept C, for example \"striped\" pattern, then, using TCAV, we supply a set of examples corresponding to \"striped\" pattern (zebra, clothing pattern etc) and the negative examples . This collection is used to train a binary classifier \u2208 \u211d for layer that partitions { ( ): \u2208 } and { ( ): \u2208 } . In another words, a kernel function maps out a set of activations that has relevant information about the \"stripe\"-ness. And then CAV is defined as the normal vector to the hyperplane that separates the positive examples from the negative ones. ACE algorithm [31] uses TCAV to compute saliency score and generate super-pixels as explanations.\n\nAlgorithm such as t-SNE has been used to cluster input images based on their activation of neurons in a network [70] [53]. In [70], the activations { 7 ( )} of 4096-dimensional layer fc7 in the CNN are collected over all input { }. Then { 7 ( )} is fed into t-SNE to be arranged and embedded into two-dimension for visualization (each point then is visually represented by the input image ). [71] introduces activation atlases, which is similarly using t-SNE to arrange some activations { ( )}, except that each point is represented by the average activations of feature visualization.\n\nIn the medical field (see later section), [72] uses Laplacian Eigenmap for interpretability; [73] introduces a low-rank representation method for Autistic Spectrum Diagnosis.\n\n\nLocality and Perturbation-based interpretability\n\nTo interpret a model, we can perform post-processing. For example, a customized probe can be designed specific to a model to observe activation of neurons in a trained layer. Perturbative methods include observation of output \u2032 for an input \u2032, where \u2032 is in the locality of some input with output . This abstraction may make sense in terms of interpretability if we imagine a trained model as a highly multi-dimensional space. The points in the space form a whole space (possibly a continuum) where each patch or locality corresponds to a notion, concept, or object as shown in figure 1(E). In this sense, an interpretable model groups together similar objects, or objects that are \"near\" with respect to some metric.\n\nThe difficulty yet to be resolved is how this space can be represented concisely and accurately. The interpretability of a model might suffer if \u2032 is similar to , but somehow \u2032 produces a radically different output. Such cases have been used by [74] to generate adversarial training data to further train the model.\n\nIn the section on locality later, we see that LIME from [30] is an optimization problem using [ + \u03a9] . The sampling method used to find an interpretable model, for example a linear \u2208 , is perturbative because given in input \u2032 to the model, its perturbed counterparts \u2032 which contains some of the non-zero elements of \u2032 are sampled (uniform randomly). See a section later on Locality, Sensitivity, Gradients for more elaboration of the model.\n\nTCAV is claimed to be a global-perturbation-based tool for interpretability [69]. It uses directional derivative , , ( ) = \u2207\u210e , ( ( )) \u22c5 where \u210e , is the logit function for class of C for layer , TCAV computes the score , , = |{ \u2208 : , , ( )>0}|\n| | \u2208 [0,1] . A two-sided t-test can be used\nwhere null hypothesis, TCAV=0.5, means there is no prediction related to the classification w.r.t concept C, i.e. not interpretable where concept C is concerned. From our understanding, it is a perturbation method by the virtue of stable continuity in the usual derivative and it is global because the whole subset of dataset with label of concept C has been shown to be well-distinguished by TCAV. However, we may want to point out that despite their claim to globality, it is possible to view the success of TCAV as local, since it is only \"global\" within each label k rather than within all dataset considered at once. Furthermore, perturbation is, by definition, local. More related works are explained in the section Locality, Sensitivity, Gradients.\n\n\nData-driven interpretability\n\nA large amount of data has been crucial to the functioning of many ML algorithms, mainly as the input data. In this section, we mention works that put a different emphasize on the treatment of these data. In essence, [9] suggests that we create a matrix whose rows are different real-world tasks (e.g. pneumonia detection), columns are different methods (e.g. decision tree with different depths) and the entries are the performance of the methods on some end-task. A row in the matrix can be, for example, identifying pneumonia patients and the columns can correspond to decision trees of increasing depths. How can we gather a large collection of entries in such a large matrix? Apart from competitions and challenges, crowd-sourcing efforts will aid the formation of such database [75] [76]. A clear problem is how multidimensional and gigantic such tabulation will become, not to mention that the collection of entries is very likely uncountably many.\n\nFormalizing interpretability here means we pick task-and method-related common criteria, the so-called latent dimensions, that human can evaluate e.g. time constraint or time-spent, cognitive chunks (defined as the basic unit of explanation, also see the definition in [61]) etc. These dimensions are to be refined along iterative processes as more user-inputs enter the repository.\n\nThe paper begins by posing the problem of incompleteness of problem formulation as an issue in interpretability.\n\nIncompleteness is present in many forms, from the impracticality to produce all test-cases to the difficulty in justifying why a choice of proxy is the best for some scenarios. At the end, it suggests that interpretability criteria are to be born out of collective agreements of the majority, through a cyclical process of discoveries, justifications and rebuttals. In our opinion, a disadvantage is that there is a possibility that no unique convergence will be born, and the situation may aggravate if, say, two different conflicting factions are born, each with enough advocate. The advantage lies in the existence of strong roots for the advocacy of certain choice of interpretability. This prevents malicious intent from tweaking interpretability criteria to suit ad hoc purposes.\n\n\nCONCEPTS ASSOCIATED WITH INTERPRETABILITY\n\n[9] points out that a major way to understand interpretability is through a proxy. Depending on the system, a metric measures some property such as sparsity, and an interpretable model will be one that attains some value assigned by the metric. We explore properties that might be quantified as proxies in this section.\n\n\nLocality, Sensitivity, Gradients\n\nThere is a concern of locality vs globality in a model. Let a model (. ) predicts ( ) accurately for some . Denote \u0303 as a slightly noisy version of . The model is a locally faithful (\u0303) produces correct prediction, otherwise, the model is unfaithful and clearly such instability reduces its reliability. In another words, the function is able to identify a locally important feature. There is no guarantee there exists globally important feature that is invariant in a machine learning task. [77] emphasizes the importance of the variation of input to neural network in explaining the network. They define explanation and local explanation in terms of the response of black box to some input Amongst many of the studies conducted, they provide experimental results on the effect of varying input such as via deletion of some regions.\n\n[78] defines gradient-based explanation vector If it is positive, the higher the value is, the less likely 0 contributes to decision ( 0 ) . The paper also suggests a different definition. [30] shows that at least locally, fidelity can be achieved. Suppose a binary problem is perfectly captured by : \u211d \u2192 \u211d with ( ) \u2208 [\u22121,1] and suppose there is a model \u2208 that is trained to estimate and contains explanations either textual or visual forms can be presented directly to user that. Some examples of possible include linear models and decision trees. Let ( ) be the \"distance\" between and , and ( , , ) be the measure of unfaithfulness. As an example, ( , , ) = \u03a3 , \u2032 \u2208 ( )[ ( ) \u2212 ( \u2032 )] 2 and ( ) = \u2212 ( , ) 2 / 2 where ( , ) can be Euclidean distance or similar variants, and some constant. It is clear that the closer is to at some locality of , the smaller is the contribution of to unfaithfulness. Furthermore, define \u03a9( ) as the complexity of the classifier. As a simple example, \u03a9 can quantify the depth of decision tree classifier; if can be computed at a shallow level of the tree, then there will be a few features that a human can easily extract. With fewer features, it is more humanly readable, hence more explainable. Then, an optimally interpretable model is 0 = [ ( , , ) + \u03a9( )] \u23df \u2208 If we denote LIME as the mapping from a locality around to a model \u2208 , then ( ) = 0 , i.e. LIME computes a model that tries to output value 0 ( ), where is near , that estimates the best possible ( ) while keeping the interpretability high by keeping the complexity low.\n\n[69] categorizes its TCAV (see the section on perturbation) as A global method, though it should be taken with a pinch of salt due to the computation of their metrics that strictly partition the labels beforehand. [29] identifies local accuracy as an important property for models that use additive feature attributions (see next section on linearity).\n\n\nLinearity\n\n\nThe simplest interpretable model is the linear combination of variables = \u03a3\n\nwhere is the degree of -ness of the prediction . If the model performs well, this can be considered highly interpretable. However, in other cases, while linearity might not be directly associated with interpretability, studying interpretability via linear properties are useful in several ways, including the ease of implementation. When non-linearity is required, it is typically not difficult to replace the linear function w \u20d7\u20d7\u20d7\u20d7 \u22c5 a \u20d7\u20d7 within the system with a non-linear version ( 1 1 , \u2026 , ) . [29] refers to a linear combination method with \u2208 {0,1} as the additive feature attribution method.\n\nA linear probe is used in [79] to extract information from each layer in a neural network. More technically, assume we have deep learning classifier ( ) \u2208 \u211d where F i (x) \u2208 [0,1] is the probability that input x is classified into class out of classes. Given a set of features at layer k of a neural network, then the linear probe at layer is defined as a linear classifier : \u2192 [0,1] i.e. (\u210e ) = ( \u210e + ). In another words, the probe tells us how well the information from only layer k can predict the output, and each of this predictive probe is a linear classifier by design. The paper then shows plots of the error rate of the prediction made by each against and demonstrates that these linear classifiers generally perform better at deeper layer, that is, at larger k.\n\nIn their words, linear separability is low at earlier layers (figure 2A) and improves deeper into layer (figure 2B). We can say that an ML model is interpretable because it learns to distinguish classes of objects more linearly deeper into the layers. Since any 2 straight-lines intersect at one point at most, the improvement in linear separability means that different classes are separated further in some D-dimensional space as shown by the + mark in figure 2B, while an object sharing the properties of some classes will turn out nearer the intersection points as shown by the x mark in figure 2B. This is visual enough to be easily understandable by a human (at least one with basic notion of linear algebra). The biggest problem we can procure on the fly is the possibility that the classes might not intersect around the same locality (figure 2C), which renders the interpretation of the probe possibly noisy.\n\nIn the medical field (see later section), [62] [80] suggest linear combination of variables as the means to interpretability (for example clinical variables, metabolites signals for MRS etc). [81] discusses the linearity in models used in the estimation of brain states, including how it is misinterpreted.\n\n\nInvariances\n\n\nImplementation\n\ninvariance. [82] suggests implementation invariance as an axiomatic requirement. In the paper, it is stated as the following. Define two functionally equivalent functions as 1 , 2 so that 1 ( ) = 2 ( ) for any regardless of their implementation details. Given any two such networks using attribution method, then the attribution functional will map the importance of each component of an input to 1 the same way it does to 2 . In another words, ( [ 1 ]( )) = ( [ 2 ]( )) for any\n= 1, \u2026 ,\nwhere is the dimension of the input. The statement can be easily extended to methods that do not use attribution as well. Input invariance. We use figure 1(A) as an illustration of input invariance: if we move the sleeping cat to the right, then the explanation provided by a model (in this case the blue super-pixels) will shift right correspondingly. Clearly, this property is desirable and has been proposed as an axiomatic invariance of a reliable saliency method. [48] studies the input invariance of some saliency methods with respect to translation of input \u2192 + for some . Of the methods studied, gradients/sensitivity-based methods [78] and signal methods [47] [83] are input invariant while some attribution methods, such as integrated gradient, do not [82].\n\n\nOthers\n\nThere are many other concepts that can be related to interpretability. [33] conducted tests on the improvements of human performance on a task after being given explanations (in the form of visualization) produced by machine learning algorithms. We believe this might be an exemplary form of Figure 2. Illustration of linear separability. (A) Not highly linearly separable (B) Good linear separability. + mark shows an input classified as B2 with high confidence, while x mark corresponds to an input classified to either B4 or B5 since it might share both properties (C) Potential problematic situation. interpretability evaluation. For example, we want to compare machine learning algorithms with . Say, human subjects are given difficult classfication tasks and attain a baseline 40% accuracies. Repeat the task with different set of human subjects, but they are given explanations churned out by and . If the accuracies attained are now 50% and 80% respectively, then is more interpretable. Even then, if human subjects cannot really explain why they can perform better with the given explanations, then the interpretability may be questionable. This brings us to the question of what kind of interpretability is necessary in different tasks and certainly points to the possibility that there is no need for a unified version of interpretability.\n\n\nBASES OF INTERPRETABILITY EVALUATION\n\nThis section explores how researchers classify different interpretability classes. This is relevant because not all scenarios require the same explanations. For example, it might not be useful to provide words searched from a common dictionary if a medical imaging diagnosis depends on the location and size of a lesion. [10] specifically studies \"What Clinicians Want\", providing what qualifies as explainable for clinicians. We group some works based on the recommendation by [9] which suggests three different bases for evaluation (though we do not include most works it already cited). Fitting them into one of the following categories may or may not enhance their usefulness and interpretability, but we attempt to do so as part of an overview.\n\n\nApplication-grounded\n\nFirst, an evaluation is application-grounded if human A gives explanation on a specific application, so-called the end-task (e.g. a doctor performs diagnosis) to human B, and B performs the same task. Then A has given B a useful explanation if B performs better in the task. Suppose A is now a machine learning model, then the model is highly interpretable if human B performs the same task with improved performance after given . Some medical segmentation works will fall into this category as well, since the segmentation will constitute a visual explanation for further diagnosis/prognosis [84] [85] (also see other categories of the grand challenge).\n\nSuch evaluation is performed, for example, by [33]. They proposed Grad-CAM applied on Guided Back-propagation (proposed by [83]) of AlexNet CNN and VGG, whose visualizations help human subjects in Amazon Mechanical Turks identify objects with higher accuracy in predicting VOC 2007 images. The human subjects achieved 61.23% accuracy, which is 16.79% higher than visualization provided by Guided Back-propagation.\n\n\nHuman-grounded\n\nSecond evaluation suggested by [9] is human-grounded. This evaluation involves real humans and simplified tasks. It can be used when, for some reasons or another, having human A gives a good explanation is challenging, possibly because the performance on the task cannot be evaluated easily or the explanation itself requires specialized knowledge. In this case, a simplified or partial problem may be posed and is still demanded. Unlike the applicationbased approach, it is now necessary to look at specifically for interpretability evaluation. Bigger pool of human subjects can then be hired to give a generic valuation to or create a model answer X A to compare X A with, and then a generic valuation is computed. Now, suppose A is a machine learning model, A is more interpretable compared to another ML model if it scores better in this generic valuation. In [86], a ML model is given a document containing the conversation of humans making a plan. The ML model produces a \"report\" containing relevant predicates (words) for the task of inferring what the final plan is. The metric used for interpretability evaluation is, for example, the percentage of the predicates that appear, compared to human-made report.\n\nWe believe the format of human-based evaluation needs not be strictly like the above. In [87], hybrid human and interactive ML classifiers require human users to nominate features for training. Two different standard MLs can be compared to the hybrid, and one can be said to be more interpretable than another if it picks up features similar to the hybrid, assuming they perform at similarly acceptable level.\n\n\nFunctionally-grounded\n\nThird, an evaluation is functionally-grounded evaluation if there exist proxies (which can be defined a priori) for evaluation, for example sparsity [9]. This evaluation is appropriate when specific requirements are met (e.g. there is already a strong justification to use a specific ML model, and the remaining concern is which relevant proxy is best) or impossible to meet (e.g. unethical to use human). Some papers [2] [85] use metrics that rely on this evaluation include many supervised learning models with clearly defined metrics such as 1. Dice coefficients: related to visual interpretability, 2. values from dimensionality reduction methods:\n\ninterpretability is related to the degree an object relates to a feature, for example, classification of a dog has high values related to four limbs, snout and paws and others.\n\n\nXAI IN MEDICAL FIELD\n\nML has also gained traction recently in the medical field, with large volume of works on automated diagnosis, prognosis [89]. From the grand-challenge.org, we can see many different challenges in the medical field have emerged and galvanized researches that use ML and AI methods. Amongst successful deep learning models are [2] [5], using U-Net for medical segmentation. However, being a deep learning neural network, U-Net is still a black-box; it is not very interpretable. Other domain specific methods and special functions (denoising etc) have been published as well ( [90] and many other works, for example in MICCAI publications).\n\nIn the medical field the question of interpretability is far from just intellectual curiosity. More specifically, it is pointed out that interpretabilities in the medical fields include factors other fields do not consider, including risk and responsibilities [15] [91] [92]. When medical responses are made, lives may be at stake. To leave such important decisions to machines that could not provide accountabilities would be akin to shirking the responsibilities altogether.\n\nApart from ethical issues, this is a serious loophole that could turn catastrophic when exploited with malicious intent.\n\nMany more works have thus been dedicated to exploring explainability in the medical fields [10] [14] [34], providing summaries of previous works [15] including subfield specific review [20] (for chest radiograph), or at least set aside a section to promote awareness for the importance of interpretability in the medical field [93].\n\n\nCategorizing interpretabilities in Medical Field\n\nHere, we consider the interpretabilities that have been discussed in the previous section but are also prevalent in the medical imaging field.\n\nVisual interpretability -Visual interpretability applies to the medical field as well. However, the images in medical field comes in many different formats such as NIFTI or DCOM. They could come in traditional 2D images, 3D images with multiple modalities and even 4D images which are time-evolving 3D volumes. The difficulties in using ML for these data include the following. Medical images are sometimes far less available in quantity than common images, such as photographs of animals. Obtaining these data certainly requires some level of consents from the patients and other administrative barriers. High dimensional data also add complexity to data processing and the large RAM space requirement might prevent data to be input without modification, random sampling or down-sizing, which may compromise analysis.\n\nWhen data is available, ground-truth images may not be \"correct\", in the sense that human can correctly identify different common animals relatively easily (see the risk of machine interpretation in a later section: noisy training data). Not only do these data require some specialized knowledge to understand, the lack of comprehensive understanding of how biological components such as the brain complicates the analysis. For example, many CT or MRI scans are presented with skull-stripping or other pre-processing. However, without a more complete knowledge of what fine details might have been accidentally removed, we cannot guarantee that an ML algorithm can capture the correct features, even if an ML can capture features in principle. All these considered, ML still holds great potentials for both reliability and interpretability.\n\n[34] develops Grad-CAM which is derived from [32] [33], and provides a saliency-map in the form of heat-map on 3D images obtained from Cellular Electron Cryo-Tomography. High intensity in the heatmap marks the region where macromolecular complexes are present. [56] uses multiinstance (MI) aggregation method during pre-processing for the training of CNNs to classify breast tumour tissue microarray (TMA) images for 5 different tasks, for example the classification of the histologic subtype. Super-pixel maps indicate the region in each TMA image where the tumour cells are; each label corresponds to a class of tumour. These maps are proposed as the means for visual interpretability. Likewise, see [57] [94].\n\nThe autofocus module from [58] promises improvements for CNN in terms of visual interpretability. It uses attention mechanism (proposed by [95]) and improves it with adaptive selection of scale with which the network \"sees\" an object within an image. With the correct scale adopted by the network while performing a single task, human observer analysing the network can understand that a neural network is properly identifying the object, rather than mistaking the combination of the object plus the surrounding as the object itself.\n\nCase-Based Reasoning (CBR) performs medical evaluation (classifications etc) by comparing a query case (new data) with similar existing data from a database. [96] combines CBR with an algorithm that presents the similarity between these cases by visually providing proxies and measures. By observing these proxies, the user can decide to take the decision suggested by the algorithm or not. The paper also asserts that medical experts appreciate such visual information with clear decision-support system.\n\nLogical statements as interpretability -as previously mentioned, such works include [59] [60] [61].\n\nKernel function, dimensionality reduction for interpretability -Kernel function and dimensionality reduction are also used in the medical field to provide interpretability. Dimensionality reduction methods in medical field might be important since they afford us analysis methods independent of pre-defined models since the complexity of biological models often render pre-defined models insufficient. Medical data can thus be treated similarly as common images, except that medical data are often higher dimensional in their raw form. However, interpretability problems for unclear features extracted might have just been delayed and remain unresolved. Eventually, human interpretation will be required in such situations. The following are some examples. [72] uses Variational Autoencoder (VAE) to obtain vectors in 64-dimensional latent dimension in order to predict whether samples suffer from hypertrophic cardiomyopathy (HCM). A non-linear transformation is used to create Laplacian Eigenmap (LE) with two dimensions, which is suggested as the means for interpretability. [62] proposes Generative Discriminative Machine (GDM) that combines ordinary least square regression and ridge regression to handle confounding variables in Alzheimer's disease dataset. GDM parameters are said to be interpretable, since they are linear combinations of the clinical variables. [97] introduces frame singular value decomposition (F-SVD) for classifications for electromyography (EMG) data. [98] uses DWT-based method (discrete wavelet transform) to perform feature extraction before eventually feeding the EEG data into a neural network for epilepsy classification. [99] developed a host of wavelet-based feature extraction methods as well applied on EEG data for epilepsy classification.\n\nModel-based interpretability -As previously mentioned, models help with interpretability by providing a generic sense of what a variable does to the output variable in question, whether in medical fields or not. A parametric model is usually designed with at least an estimate of the working mechanism of the system, with simplification and based on empirically observed patterns. For example, [90]  which depends on perfusion-weighted image \u0394 obtained from the signal difference between labelled image of arterial blood water treated with RF pulses and the control image. This function is incorporated in the loss function of a fully convolutional neural network. At least, an interpretation can be made partially: the neural network model is designed to denoise a perfusion-weighted image (and thus improve its quality) by considering CBF. How the network \"understands\" the CBF is again an interpretability problem of a neural network which has yet to be resolved. Deep learning method is also used to perform parameters fitting for Magnetic Resonance Spectroscopy [80]. The parametric model specified, ( ) = \u03a3a m ( ) \u0394 +2 \u0394 , consists of linear combination of metabolite signals ( ). In cases like this, clinicians may find the model interpretable as long as the parameters are well-fit, although the neural network itself may still not be interpretable. Likewise, deep learning has been used for PET pharmacokinetic (PK) modelling to quantify tracer target density [100]. CNN has helped PK modelling as a part of a sequence of processes to reduce PET acquisition time, and the output is interpreted with respect to the golden standard PK model, which is the linearized version of Simplified Reference Tissue Model (SRTM).\n\nOn a different note, reinforcement learning (RL) has been applied to personalized healthcare. In particular, [101] introduces group-driven RL in personalized healthcare, taking into considerations different groups, each having similar agents. As usual, Q-value is optimized w.r.t policy , which can be qualitatively interpreted as the maximization of rewards over time over the choices of action selected by many participating agents in the system.\n\n\nRisk of Machine Interpretation in Medical Field\n\n\u2022 Jumping conclusion. According to [59], logical statements such as \"has asthma \u2192 lower risk\" are considered interpretable. However, in the example, the statement indicates that a patient with asthma has lower risk of death from pneumonia, which might be strange without the intermediate thought process. While human can infer that the lowered risk is due to the fact that pneumonia patients with asthma history tend to be given more aggressive treatment, we cannot always assume there is a similar humanly inferable reason behind each decision. Furthermore, interpretability method such as LRP, deconvolution and guided backpropagation introduced earlier are shown to not work for simple model, such as linear model, bringing into question their reliability [102]. \u2022 Manipulation of explanations. [103] shows that an image can be generated that is perceptibly indistinguishable from the original but produces radically different interpretation. Furthermore, explanation can even be manipulated arbitrarily [104]. For example, an explanation for the classification of a cat image can be implanted into the prediction of the image of a dog. The risk in medical field is clear: even without malicious, intentional manipulation, noises can render \"explanations\" wrong. \u2022 Incomplete constraints. In [90], the loss function of a fully convolutional network includes CBF as a constraint.\n\nHowever, many other constraints may play important roles in the mechanism of a living organ or tissue, not to mention applying kinetic model is itself a simplification.\n\nGiving an interpretation within limited constraints may place undue emphasis on the constraint itself. Other works that use predefined models might suffer similar problems [62] [80] [100]. \u2022 Noisy training data. The so-called ground truths for medical tasks, provided by professionals, are not always absolutely correct. In fact, news regarding how AI beats human performance in medical imaging diagnosis [105] indicates that human judgment could be brittle. This is true even of trained medical personnel. This might give rise to the classic garbage-in-garbage-out situation.\n\nThe above risks are presented in large part as a reminder of the nature of automation. It is true that algorithms have been used to extract invisible patterns with some successes. However, one ought to view scientific problems with the correct order of priority. The society should not risk overallocating resources into building machine and deep learning models, especially since due improvements to understanding the underlying science might be the key to solving the root problem. For example, higher quality MRI scans might reveal key information not \"visible\" with current technology, and many models built for lesion segmentation nowadays might not be very successful because there is simply not enough useful information contained in the MRI scans fed into the models.\n\n\nCONCLUSION\n\nWe present a survey on interpretability and explainability of ML algorithms in general, and place different interpretations suggested by different research works into distinct categories. From general interpretabilities, we apply the categorization into the medical field. Some attempts are made to formalize interpretabilities mathematically, some provide visual explanations, while others might focus on the improvement in task performance after being given explanations produced by algorithms. Visual and textual explanation supplied by an algorithm might seem like the obvious choice; unfortunately, imagine an otherwise reliable deep learning model providing a strangely wrong visual or textual explanation. Before the black-box is unblack-boxed, machine decision always carries some exploitable risks. It is also clear that a unified notion of interpretability is elusive. An authoritative body setting up the standard of requirements for the deployment of model building might stifle the progress of the research itself, though it might be the most efficient way to reach an agreement. This might be necessary to prevent damages, seeing that even corporate companies and other bodies non-academic in the traditional sense have joined the fray (consider health-tech start-ups and the implications). Acknowledging that machine and deep learning might not be fully mature for large scale deployment, it might be wise to deploy the algorithms side by side and leave most decisions to the traditional methods. It might take a long time before humanity graduates from this stage, but it might be timely: we can collect more data to compare machine predictions with traditional predictions and sort out data ownership issues along the way.\n\nFigure 1 .\n1Types of interpretability and an example in each category. (A) A heatmap provides the intermediate \"thought processes\" of an algorithm that can be used to justify image classification.\n\n\n| = ) where , are d-dimensional. For any = 1, \u2026 , , high absolute value of [ ( 0 )] means that component contributes significantly to the decision of the classifier.\n\n\nuses kinetic model for the cerebral blood flow in /100 / with\nACKNOWLEDGMENT This research was supported by Alibaba Group Holding Limited, DAMO Academy, Health-AI division under Alibaba-NTU Talent Program. The program is the collaboration between Alibaba and Nanyang Technological university, Singapore.\nDeep into the Brain Artificial Intelligence in Stroke Imaging. Eun-Jae Lee, Yong-Hwan Kim, Namkug Kim, Dong-Wha Kang, Journal of Stroke. Eun-Jae Lee, Yong-Hwan Kim, Namkug Kim and Dong-Wha Kang, \"Deep into the Brain Artificial Intelligence in Stroke Imaging,\" Journal of Stroke, 2017.\n\nU-Net: Convolutional Networks for Biomedical Image Segmentation. Olaf Ronneberger, Philipp Fischer, Thomas Brox, MICCAIOlaf Ronneberger, Philipp Fischer and Thomas Brox, \"U-Net: Convolutional Networks for Biomedical Image Segmentation,\" Springer Link, MICCAI, 2015.\n\nThe role of trust in automation. M T Dzindolet, S A Peterson, R A Pomranky, L G Pierce, H P Beck, International Journal of Human-Computer Interaction. M. T. Dzindolet, S. A. Peterson, R. A. Pomranky, L. G. Pierce and H. P. Beck, \"The role of trust in automation,\" International Journal of Human-Computer Interaction, 2003.\n\nFully automatic acute ischemic lesion segmentation in DWI using convolutional neural networks. Liang Chen, Paul Bentley, Daniel Rueckert, Neuroimage. Liang Chen, Paul Bentley and Daniel Rueckert, \"Fully automatic acute ischemic lesion segmentation in DWI using convolutional neural networks,\" Neuroimage: Clinical, 2017.\n\n3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation. Ozgun Cicek, Ahmed Abdulkadir, S Soeren, Thomas Lienkamp, Olaf Brox, Ronneberger, Springer Link, MICCAIOzgun Cicek, Ahmed Abdulkadir, Soeren S. Lienkamp, Thomas Brox and Olaf Ronneberger, \"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation,\" Springer Link, MICCAI, 2016.\n\n. Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Silviana Ciurea-Ilcus, Chris Chute, Henrik Mark, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, Jayne Seekins, David A Mong, Yifan Yu, S Safwan, Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Silviana Ciurea-Ilcus, Chris Chute, Henrik Mark, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, Jayne Seekins, David A. Mong, Yifan Yu, Safwan S.\n\nCheXpert A large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison. Jesse K Halabi, Ricky Sandberg, David B Jones, Curtis P Larson, Langlotz, N Bhavik, Matthew P Patel, Andrew Y Lungren, Ng, Halabi, Jesse K. Sandberg, Ricky Jones, David B. Larson, Curtis P. Langlotz, Bhavik N. Patel, Matthew P. Lungren and Andrew Y. Ng, \"CheXpert A large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison,\" 2019. [Online]. Available: https://arxiv.org/pdf/1901.07031.pdf.\n\nV-Net: fully convolutional neural network for volumetric medical image segmentation. Fausto Milletari, Nassir Navab, Seyed-Ahmad Ahmadi, Fourth International Conference on 3D Vision (3DV). Fausto Milletari, Nassir Navab and Seyed-Ahmad Ahmadi, \"V-Net: fully convolutional neural network for volumetric medical image segmentation,\" in Fourth International Conference on 3D Vision (3DV), 2016.\n\nDeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs. Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L Yuille, Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy and Alan L. Yuille, \"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs,\" 2016. [Online]. Available: https://arxiv.org/abs/1606.00915.\n\nTowards A Rigorous Science of Interpretable Machine Learning. Finale Doshi, - Velez, Been Kim, Finale Doshi-Velez and Been Kim, \"Towards A Rigorous Science of Interpretable Machine Learning,\" 2017. [Online]. Available: https://arxiv.org/pdf/1702.08608.pdf.\n\nWhat Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use. Sana Tonekaboni, Shalmali Joshi, Melissa D Mccradden, Anna Goldenberg, Sana Tonekaboni, Shalmali Joshi, Melissa D. McCradden and Anna Goldenberg, \"What Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use,\" 2019. [Online]. Available: https://arxiv.org/abs/1905.05134.\n\nExplaining collaborative filtering recommendations. J L Herlocker, J A Konstan, J Riedl, Conference on Computer Supported Cooperative Work. J. L. Herlocker, J. A. Konstan and J. Riedl, \"Explaining collaborative filtering recommendations,\" Conference on Computer Supported Cooperative Work, 2000.\n\nUnmasking Clever Hans predictors and assessing what machines really learn. Sebastian Lapuschkin, Stephan W\u00e4ldchen, Alexander Binder, Gr\u00e9goire Montavon, Wojciech Samek, Klaus-Robert M\u00fcller, Nature Communications. Sebastian Lapuschkin, Stephan W\u00e4ldchen, Alexander Binder, Gr\u00e9goire Montavon, Wojciech Samek and Klaus-Robert M\u00fcller, \"Unmasking Clever Hans predictors and assessing what machines really learn,\" Nature Communications, 2019.\n\nBrain-machine interfaces in neurorehabilitation of stroke. R Surjo, Niels Soekadar, Marcw Birbaumer, Leonardo G Slutzky, Cohen, Neurobiology of Disease. Surjo R. Soekadar, Niels Birbaumer, MarcW. Slutzky and Leonardo G. Cohen, \"Brain-machine interfaces in neurorehabilitation of stroke,\" Neurobiology of Disease, 2015.\n\nCausability and explainabilty of artificial intelligence in medicine. Andreas Holzinger, Georg Langs, Helmut Denk, Kurt Zatloukal, Heimo M\u00fcller, Andreas Holzinger, Georg Langs, Helmut Denk, Kurt Zatloukal and Heimo M\u00fcller, \"Causability and explainabilty of artificial intelligence in medicine,\" 2019. [Online]. Available: https://onlinelibrary.wiley.com/journal/19424795.\n\nOutlining the Design Space of Explainable Intelligent Systems for Medical Diagnosis. Yao Xie, &apos; Xiang, &apos; Anthony, Ge Chen, Gao, IUI Workshops. Yao Xie, Xiang 'Anthony' Chen and Ge Gao, \"Outlining the Design Space of Explainable Intelligent Systems for Medical Diagnosis,\" in IUI Workshops, 2019.\n\nThe Mythos of Model Interpretability. Zachary C Lipton, Zachary C. Lipton, \"The Mythos of Model Interpretability,\" 2017. [Online]. Available: https://arxiv.org/pdf/1606.03490.pdf.\n\nThe importance of interpretability and visualization in machine learning for applications in medicine and health care. A Vellido, Neural Computing and Applications. A. Vellido, \"The importance of interpretability and visualization in machine learning for applications in medicine and health care,\" Neural Computing and Applications, 2019.\n\nHigh-performance medicine: the convergence of human and artificial intelligence. E J Topol, Nature Medicine. E. J. Topol, \"High-performance medicine: the convergence of human and artificial intelligence,\" Nature Medicine, 2019.\n\nEvolutionary Fuzzy Systems for Explainable Artificial Intelligence: Why, When, What for, and Where to?. Alberto Fernandez, Francisco Herrera, Oscar Cordon, Maria Jose Del, Jesus , Francesco Marcelloni, IEEE Computational intelligence magazine. Alberto Fernandez, Francisco Herrera, Oscar Cordon, Maria Jose del Jesus and Francesco Marcelloni, \"Evolutionary Fuzzy Systems for Explainable Artificial Intelligence: Why, When, What for, and Where to?,\" in IEEE Computational intelligence magazine, 2019.\n\nHow far have we come? Artificial intelligence for chest radiograph interpretation. K Kallianos, J Mongan, S Antani, T Henry, A Taylor, J Abuya, M Kohli, Clinical Radiology. K. Kallianos, J. Mongan, S. Antani, T. Henry, A. Taylor, J. Abuya and M. Kohli, \"How far have we come? Artificial intelligence for chest radiograph interpretation,\" Clinical Radiology, 2019.\n\nMethods for Interpreting and Understanding Deep Neural Networks. W S K M -R, Gr\u00e9goire Montavon, 25W. S. K.-R. M. Gr\u00e9goire Montavon, \"Methods for Interpreting and Understanding Deep Neural Networks,\" 2017. [Online]. Available: https://arxiv.org/abs/1706.07979. [Accessed 25 July 2019].\n\nExplainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models. W Samek, T Wiegand, K.-R M\u00fcller, W. Samek, T. Wiegand and K.-R. M\u00fcller, \"Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models,\" 2017. [Online].\n\nStructuring Neural Networks for More Explainable Predictions. L Rieger, P Chormai, G Montavon, L K Hansen, K.-R M\u00fcller, Explainable and Interpretable Models in Computer Vision and Machine Learning. L. Rieger, P. Chormai, G. Montavon, L. K. Hansen and K.-R. M\u00fcller, \"Structuring Neural Networks for More Explainable Predictions,\" in Explainable and Interpretable Models in Computer Vision and Machine Learning, 2018, pp. 115-131.\n\nEuropean Union. Europa &quot;ec, Eu, Accessed\"ec.europa.eu,\" European Union, April 2019. [Online]. Available: https://ec.europa.eu/digital-single-market/en/news/ethics- guidelines-trustworthy-ai. [Accessed June 2019].\n\nDesigning Theory-Driven User-Centric Explainable AI. Danding Wang, Qian Yang, Ashraf Abdul, Brian Y Lim, Conference on Human Factors in Computing Systems. Danding Wang, Qian Yang, Ashraf Abdul and Brian Y. Lim, \"Designing Theory-Driven User-Centric Explainable AI,\" in Conference on Human Factors in Computing Systems, 2019.\n\nD Bau, B Zhou, A Khosla, A Oliva, A Torralba, Network Dissection: Quantifying Interpretability of Deep Visual Representations. D. Bau, B. Zhou, A. Khosla, A. Oliva and A. Torralba, \"Network Dissection: Quantifying Interpretability of Deep Visual Representations,\" 2017. [Online].\n\n. Chris Olah, Alexander Mordvintsev, Ludwig Schubert, distill.pub,\" Google, 2017. [OnlineChris Olah, Alexander Mordvintsev and Ludwig Schubert, \"distill.pub,\" Google, 2017. [Online].\n\n. Chris Olah, Arvind Satyanarayan, Ian Johnson, Shan Carter, Ludwig Schubert, Katherine Ye, Alexander Mordvintsev, distill.pub,\" GoogleChris Olah, Arvind Satyanarayan, Ian Johnson, Shan Carter, Ludwig Schubert, Katherine Ye and Alexander Mordvintsev, \"distill.pub,\" Google, 2018. [Online]. Available: https://distill.pub/2018/building- blocks/.\n\nA Unified Approach to Interpreting Model Predictions. M Scott, Su-In Lundberg, Lee, Neural Information Processing Systems. Scott M. Lundberg and Su-In Lee, \"A Unified Approach to Interpreting Model Predictions,\" in Neural Information Processing Systems, 2017.\n\nExplaining the Predictions of Any Classifier. Sameer Marco Tulio Ribeiro, Carlos Singh, Guestrin, Why Should I Trust You?Marco Tulio Ribeiro, Sameer Singh and Carlos Guestrin, \"\"Why Should I Trust You?\" Explaining the Predictions of Any Classifier,\" 2016. [Online]. Available: https://arxiv.org/pdf/1602.04938.pdf.\n\nTowards Automatic Concept-based Explanations. Amirata Ghorbani, James Wexler, James Zou, Been Kim, Amirata Ghorbani, James Wexler, James Zou and Been Kim, \"Towards Automatic Concept-based Explanations,\" 2019. [Online].\n\nLearning Deep Features for Discriminative Localization. Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba, Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva and Antonio Torralba, \"Learning Deep Features for Discriminative Localization,\" 2015. [Online].\n\nGrad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization. R Ramprasaath, Michael Selvaraju, Abhishek Cogswell, Ramakrishna Das, Devi Vedantam, Dhruv Parikh, Batra, OnlineRamprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh and Dhruv Batra, \"Grad- CAM: Visual Explanations from Deep Networks via Gradient-based Localization,\" [Online].\n\nRespond-CAM: Analyzing Deep Models for 3D Imaging Data by Visualizations. Guannan Zhao, Bo Zhou, Kaiwen Wang, Rui Jiang, Min Xu, MICCAIGuannan Zhao, Bo Zhou, Kaiwen Wang, Rui Jiang and Min Xu, \"Respond-CAM: Analyzing Deep Models for 3D Imaging Data by Visualizations,\" in MICCAI, 2018.\n\nOn Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation. Sebastian Bach, Alexander Binder, Gr\u00e9goire Montavon, Frederick Klauschen, Klaus-Robert M\u00fcller, Wojciech Samek, PLOS ONE. Sebastian Bach, Alexander Binder, Gr\u00e9goire Montavon, Frederick Klauschen, Klaus-Robert M\u00fcller and Wojciech Samek, \"On Pixel- Wise Explanations for Non-Linear Classifier Decisions by Layer- Wise Relevance Propagation,\" PLOS ONE, 2015.\n\nInterpreting and Explaining Deep Neural Networks for Classification of Audio Signals. S Becker, M Ackermann, S Lapuschkin, K.-R M\u00fcller, W Samek, 25S. Becker, M. Ackermann, S. Lapuschkin, K.-R. M\u00fcller and W. Samek, \"Interpreting and Explaining Deep Neural Networks for Classification of Audio Signals,\" 2018. [Online]. Available: https://arxiv.org/abs/1807.03418. [Accessed 25 July 2019].\n\nAnalyzing Neuroimaging Data Through Recurrent Deep Learning Models. A W Thomas, H R Heekeren, K.-R M\u00fcller, W Samek, A. W. Thomas, H. R. Heekeren, K.-R. M\u00fcller and W. Samek, \"Analyzing Neuroimaging Data Through Recurrent Deep Learning Models,\" 2018. [Online].\n\nWhat is Relevant in a Text Document. L Arras, F Horn, G Montavon, K.-R M\u00fcller, W Samek, An Interpretable Machine Learning Approach. L. Arras, F. Horn, G. Montavon, K.-R. M\u00fcller and W. Samek, \"\"What is Relevant in a Text Document?\": An Interpretable Machine Learning Approach,\" 2016. [Online].\n\nInterpreting the Predictions of Complex ML Models by Layer-wise Relevance Propagation. W Samek, G Montavon, A Binder, S Lapuschkin, K.-R M\u00fcller, 25W. Samek, G. Montavon, A. Binder, S. Lapuschkin and K.-R. M\u00fcller, \"Interpreting the Predictions of Complex ML Models by Layer-wise Relevance Propagation,\" 2016. [Online]. Available: https://arxiv.org/abs/1611.08191. [Accessed 25 July 2019].\n\nInterpretable human action recognition in compressed domain. V Srinivasan, S Lapuschkin, C Hellge, K.-R M\u00fcller, W Samek, IEEE International Conference on Acoustics, Speech and Signal Processing. V. Srinivasan, S. Lapuschkin, C. Hellge, K.-R. M\u00fcller and W. Samek, \"Interpretable human action recognition in compressed domain,\" IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017.\n\nExplaining Recurrent Neural Network Predictions in Sentiment Analysis. G M K M W S -R, Leila Arras, G. M. K.-R. M. W. S. Leila Arras, \"Explaining Recurrent Neural Network Predictions in Sentiment Analysis,\" 2017. [Online].\n\nVisualizing and Understanding Recurrent Networks. J J L , F.-F. Andrej Karpathy, J. J. L. F.-F. Andrej Karpathy, \"Visualizing and Understanding Recurrent Networks,\" 2015. [Online].\n\nMachine Learning and AI for the Sciences -Towards Understanding. K.-R M\u00fcller, IEEE WCCI. 29K.-R. M\u00fcller, \"Machine Learning and AI for the Sciences -Towards Understanding,\" IEEE WCCI, 2018. [Online]. Available: http://heatmapping.org/slides/XAI18.pdf. [Accessed 29 July 2019].\n\nDeep Taylor Decomposition of Neural Networks. G Montavon, S Bach, A Binder, W Samek, K.-R Muller, 29G. Montavon, S. Bach, A. Binder, W. Samek and K.-R. Muller, \"Deep Taylor Decomposition of Neural Networks,\" 2017. [Online]. Available: http://iphome.hhi.de/samek/pdf/MonICML16.pdf. [Accessed 29 July 2019].\n\nLearning Important Features Through Propagating Activation Differences. A Shrikumar, P Greenside, A Y Shcherbina, A Kundaje, A. Shrikumar, P. Greenside, A. Y. Shcherbina and A. Kundaje, \"Learning Important Features Through Propagating Activation Differences,\" 2017. [Online].\n\nVisualizing Deep Neural Network Decisions Prediction Difference Analysis. T S C T A M W Luisa, Zintgraf, T. S. C. T. A. M. W. Luisa M Zintgraf, \"Visualizing Deep Neural Network Decisions Prediction Difference Analysis,\" 2017. [Online].\n\nVisualizing and Understanding Convolutional Networks. D Matthew, Rob Zeiler, Fergus, Computer Vision -ECCV. Matthew D. Zeiler and Rob Fergus, \"Visualizing and Understanding Convolutional Networks,\" in Computer Vision -ECCV, 2014.\n\nThe (Un)reliability of saliency methods. Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, T Kristof, Sven Sch\u00fctt, Dumitru D\u00e4hne, Been Erhan, Kim, Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof T. Sch\u00fctt, Sven D\u00e4hne, Dumitru Erhan and Been Kim, \"The (Un)reliability of saliency methods,\" 2017. [Online].\n\nUnderstanding Deep Image Representations by Inverting Them. A Mahendran, A Vedaldi, 29A. Mahendran and A. Vedaldi, \"Understanding Deep Image Representations by Inverting Them,\" 2014. [Online]. Available: https://arxiv.org/abs/1412.0035. [Accessed 29 July 2019].\n\nInverting Visual Representations with Convolutional Networks. A Dosovitskiy, T Brox, A. Dosovitskiy and T. Brox, \"Inverting Visual Representations with Convolutional Networks,\" 2016. [Online].\n\nVisualizing Higher-Layer Features of a Deep Network. D Erhan, Y Bengio, A Courville, P Vincent, 29D. Erhan, Y. Bengio, A. Courville and P. Vincent, \"Visualizing Higher-Layer Features of a Deep Network,\" 2009. [Online]. Available: https://pdfs.semanticscholar.org/65d9/94fb778a8d9e0f632659fb33a 082949a50d3.pdf. [Accessed 29 July 2019].\n\nUnderstanding Neural Networks Through Deep Visualization. J Yosinski, J Clune, A Nguyen, T Fuchs, H Lipson, 29J. Yosinski, J. Clune, A. Nguyen, T. Fuchs and H. Lipson, \"Understanding Neural Networks Through Deep Visualization,\" 2015. [Online]. Available: https://arxiv.org/abs/1506.06579. [Accessed 29 July 2019].\n\nMultifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks. Anh Nguyen, Jason Yosinski, Jeff Clune, Anh Nguyen, Jason Yosinski and Jeff Clune, \"Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks,\" 2016. [Online].\n\nGoing Deeper with Convolutions. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke and Andrew Rabinovich, \"Going Deeper with Convolutions,\" 2014. [Online]. Available: https://arxiv.org/abs/1409.4842.\n\nM Paschali, Sailesh Conjeti, Fernando Navarro, Nassir Navab, Generalizability vs. Robustness: Investigating Medical Imaging Networks Using Adversarial Examples. MICCAIM. Paschali, Sailesh Conjeti, Fernando Navarro and Nassir Navab, \"Generalizability vs. Robustness: Investigating Medical Imaging Networks Using Adversarial Examples,\" in MICCAI, 2018.\n\nMultiple Instance Learning for Heterogeneous Images: Training a CNN for Histopathology. Heather D Couture, J S Marron, Charles M Perou, Melissa A Troester, Marc Niethammer, Lecture Notes in Computer Science. Heather D. Couture, J. S. Marron, Charles M. Perou, Melissa A. Troester and Marc Niethammer, \"Multiple Instance Learning for Heterogeneous Images: Training a CNN for Histopathology,\" in MICCAI 2018. Lecture Notes in Computer Science.\n\nBrain Biomarker Interpretation in ASD Using Deep Learning and fMRI. Xiaoxiao Li, C Nicha, Juntang Dvornek, Pamela Zhuang, James S Ventola, Duncan, Lecture Notes in Computer Science. Xiaoxiao Li, Nicha C. Dvornek, Juntang Zhuang, Pamela Ventola and James S. Duncan, \"Brain Biomarker Interpretation in ASD Using Deep Learning and fMRI,\" in MICCAI 2018. Lecture Notes in Computer Science, 2018.\n\nAutofocus Layer for Semantic Segmentation. Yao Qin, Konstantinos Kamnitsas, Siddharth Ancha, Jay Nanavati, Garrison Cottrell, Antonio Criminisi, Aditya Nori, Yao Qin, Konstantinos Kamnitsas, Siddharth Ancha, Jay Nanavati, Garrison Cottrell, Antonio Criminisi and Aditya Nori, \"Autofocus Layer for Semantic Segmentation,\" 2018. [Online]. Available: https://arxiv.org/abs/1805.08403.\n\nIntelligible Models for HealthCare Predicting pneumonia risk and hospital 30-day readmission. Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, No\u00e9mie Elhadad, Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningRich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm and No\u00e9mie Elhadad, \"Intelligible Models for HealthCare Predicting pneumonia risk and hospital 30-day readmission,\" in Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2015.\n\nInterpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model. B Letham, C Rudin, T H Mccormick, D Madigan, The Annals of Applied Statistics. B. Letham, C. Rudin, T. H. McCormick and D. Madigan, \"Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model,\" The Annals of Applied Statistics, 2015.\n\nAn Evaluation of the Human-Interpretability of Explanation. Isaac Lage, Emily Chen, Jeffrey He, Menaka Narayanan, Been Kim, Sam Gershman, Finale Doshi-Velez, Google Brain. Isaac Lage, Emily Chen, Jeffrey He, Menaka Narayanan, Been Kim, Sam Gershman and Finale Doshi-Velez, \"An Evaluation of the Human-Interpretability of Explanation,\" Google Brain, 2019. [Online]. Available: https://arxiv.org/abs/1902.00006.\n\nGenerative Discriminative Models for Multivariate Inference and Statistical Mapping in Medical Imaging. Erdem Varol, Aristeidis Sotiras, Ke Zeng, Christos Davatzikos, Erdem Varol, Aristeidis Sotiras, Ke Zeng and Christos Davatzikos, \"Generative Discriminative Models for Multivariate Inference and Statistical Mapping in Medical Imaging,\" 2018. [Online]. Available: https://arxiv.org/abs/1807.00445.\n\nGeneralized additive models. T Hastie, R Tibshirani, Chapman & Hall, CRC PressT. Hastie and R. Tibshirani, Generalized additive models, Chapman & Hall, CRC Press, 1990.\n\nIntelligible models for classification and regression. Y Lou, R Caruana, J Gehrke, KDD. Y. Lou, R. Caruana and J. Gehrke, \"Intelligible models for classification and regression,\" in KDD, 2012.\n\nAccurate intelligible models with pairwise interactions. Y Lou, R Caruana, J Gehrke, G Hooker, KDD. Y. Lou, R. Caruana, J. Gehrke and G. Hooker, \"Accurate intelligible models with pairwise interactions,\" in KDD, 2013.\n\nQuantum-chemical insights from interpretable atomistic neural networks. K T Sch\u00fctt, M Gastegger, A Tkatchenko, K.-R M\u00fcller, 25K. T. Sch\u00fctt, M. Gastegger, A. Tkatchenko and K.-R. M\u00fcller, \"Quantum-chemical insights from interpretable atomistic neural networks,\" [Online]. Available: https://arxiv.org/abs/1806.10349. [Accessed 25 July 2019].\n\nCanonical Correlation Analysis: An Overview with Application to Learning Methods. David R Hardoon, Sandor Szedmak, John Shawe-Taylor, Neural Computation. David R. Hardoon, Sandor Szedmak and John Shawe-Taylor, \"Canonical Correlation Analysis: An Overview with Application to Learning Methods,\" Neural Computation, 2004.\n\nSVCCA Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability. Maithra Raghu, Justin Gilmer, Justin Gilmer, Jascha Sohl-Dickstein, Neural Information Processing Systems. Maithra Raghu, Justin Gilmer, Justin Gilmer and Jascha Sohl- Dickstein, \"SVCCA Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability,\" in Neural Information Processing Systems, 2017.\n\nBeen Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, Rory Sayres, Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV). Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas and Rory Sayres, \"Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV),\" 2018. [Online].\n\n. A K , A. K. account, 2014. [Online].\n\nExploring Neural Networks with Activation Atlases. Shan Carter, Zan Armstrong, Ludwig Schubert, Ian Johnson, Chris Olah, Shan Carter, Zan Armstrong, Ludwig Schubert, Ian Johnson and Chris Olah, \"Exploring Neural Networks with Activation Atlases,\" 2019. [Online]. Available: https://distill.pub/2019/activation-atlas/.\n\nLearning Interpretable Anatomical Features Through Deep Generative Models: Application to Cardiac Remodeling. Carlo Biffi, Ozan Oktay, Giacomo Tarroni, Wenjia Bai, Antonio De Marvao, Georgia Doumou, Martin Rajchl, Reem Bedair, Sanjay Prasad, Stuart Cook, O&apos; Declan, Daniel Regan, Rueckert, MICCAI. Carlo Biffi, Ozan Oktay, Giacomo Tarroni, Wenjia Bai, Antonio De Marvao, Georgia Doumou, Martin Rajchl, Reem Bedair, Sanjay Prasad, Stuart Cook, Declan O'Regan and Daniel Rueckert, \"Learning Interpretable Anatomical Features Through Deep Generative Models: Application to Cardiac Remodeling,\" in MICCAI, 2018.\n\nLow-Rank Representation for Multi-center Autism Spectrum Disorder Identification. Mingliang Wang, Daoqiang Zhang, Jiashuang Huang, Dinggang Shen, Mingxia Liu, MICCAIMingliang Wang, Daoqiang Zhang, Jiashuang Huang, Dinggang Shen and Mingxia Liu, \"Low-Rank Representation for Multi-center Autism Spectrum Disorder Identification,\" in MICCAI, 2018.\n\nUnderstanding Black-box Predictions via Influence Functions. Wei Pang, Percy Koh, Liang, Proceedings of the 34-th International Conference on Machine Learning. the 34-th International Conference on Machine LearningPang Wei Koh and Percy Liang, \"Understanding Black-box Predictions via Influence Functions,\" in Proceedings of the 34-th International Conference on Machine Learning, 2017.\n\nEpilepsyecosystem.org: crowd-sourcing reproducible seizure prediction with long-term human intracranial EEG. Levin Kuhlmann, Philippa Karoly, Dean R Freestone, H Benjamin, Andriy Brinkmann, Alexandre Temko, Feng Barachant, Gilberto Li, Jr Titericz, W Brian, Daniel Lang, Kelly Lavery, Derek Roman, Scott Broadhead, Gareth Dobson, Qingnan Jones, Irina Tang, Oleg Ivanenko, Panichev, Brain. 1419Levin Kuhlmann, Philippa Karoly, Dean R Freestone, Benjamin H Brinkmann, Andriy Temko, Alexandre Barachant, Feng Li, Gilberto Titericz, Jr. , Brian W Lang, Daniel Lavery, Kelly Roman, Derek Broadhead, Scott Dobson, Gareth Jones, Qingnan Tang, Irina Ivanenko, Oleg Panichev, Timoth\u00e9e Proix, Michal N\u00e1hl\u00edk, Daniel B Grunberg, Chip Reuben, Gregory Worrell, David B Grayden and Mark J Cook, \"Epilepsyecosystem.org: crowd-sourcing reproducible seizure prediction with long-term human intracranial EEG,\" Brain, vol. 141, no. 9, 2018.\n\nEnabling an Open Data Ecosystem for the Neurosciences. Martin Wiener, Friedrich T Sommer, Zachary G Ives, Russell A Poldrack, Brianlitt, Neuron. 924Martin Wiener, Friedrich T.Sommer, Zachary G.Ives, Russell A.Poldrack and BrianLitt, \"Enabling an Open Data Ecosystem for the Neurosciences,\" Neuron, vol. 92, no. 4, 2016.\n\nInterpretable Explanations of Black Boxes by Meaningful Perturbation. R Fong, A Vedaldi, 29R. Fong and A. Vedaldi, \"Interpretable Explanations of Black Boxes by Meaningful Perturbation,\" 2017. [Online]. Available: https://arxiv.org/abs/1704.03296. [Accessed 29 July 2019].\n\nHow to Explain Individual Classification Decisions. David Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja Hansen, Klaus-Robert Mueller, David Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja Hansen and Klaus-Robert Mueller, \"How to Explain Individual Classification Decisions,\" 2009. [Online].\n\nUnderstanding intermediate layers using linear classifier probes. Guillaume Alain, Yoshua Bengio, arxiv.org. Guillaume Alain and Yoshua Bengio, \"Understanding intermediate layers using linear classifier probes,\" arxiv.org, 2018.\n\nMagnetic Resonance Spectroscopy Quantification using Deep Learning. Nima Hatami, Michael Sdika, Helene Ratiney, MICCAI. Nima Hatami, Michael Sdika and Helene Ratiney, \"Magnetic Resonance Spectroscopy Quantification using Deep Learning,\" in MICCAI, 2018.\n\nOn the interpretation of weight vectors of linear models in multivariate neuroimaging. Stefan Haufe, Frank Meinecke, Kai G\u00f6rgen, Sven D\u00e4hne, John-Dylan Haynes, Benjamin Blankertz, Felix Bie\u00dfmann, NeuroImage. Stefan Haufe, Frank Meinecke, Kai G\u00f6rgen, Sven D\u00e4hne, John- Dylan Haynes, Benjamin Blankertz and Felix Bie\u00dfmann, \"On the interpretation of weight vectors of linear models in multivariate neuroimaging,\" NeuroImage, 2014.\n\nAxiomatic Attribution for Deep Networks. Mukund Sundararajan, Ankur Taly, Qiqi Yan, Mukund Sundararajan, Ankur Taly and Qiqi Yan, \"Axiomatic Attribution for Deep Networks,\" 2017. [Online]. Available: https://arxiv.org/abs/1703.01365.\n\nStriving for Simplicity. The All Convolutional Net. Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, Martin Riedmiller, Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox and Martin Riedmiller, \"Striving for Simplicity. The All Convolutional Net,\" 2015. [Online].\n\nEnsemble of Deep Convolutional Neural Networks for Prognosis of Ischemic Stroke. Youngwon Choi, Yongchan Kwon, Hanbyul Lee, Joon Beom, Myunghee Kim, Joong-Ho Cho Paik, Won, International Workshop on Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. Youngwon Choi, Yongchan Kwon, Hanbyul Lee, Beom Joon Kim, Myunghee Cho Paik and Joong-Ho Won, \"Ensemble of Deep Convolutional Neural Networks for Prognosis of Ischemic Stroke,\" in International Workshop on Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries, 2016.\n\nPredicting Stroke Lesion and Clinical Outcome with Random Forests. Oskar Maier, Heinz Handels, International Workshop on Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. Oskar Maier and Heinz Handels, \"Predicting Stroke Lesion and Clinical Outcome with Random Forests,\" in International Workshop on Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries, 2016.\n\nInferring Robot Task Plans from Human Team Meetings: A Generative Modeling Approach with Logic-Based. B Kim, C M Chacha, J Shah, B. Kim, C. M. Chacha and J. Shah, \"Inferring Robot Task Plans from Human Team Meetings: A Generative Modeling Approach with Logic-Based,\" 2013. [Online].\n\nFlock: Hybrid Crowd-Machine Learning Classifiers. J Cheng, Michael S Bernstein, ACM Conference on Computer Supported Cooperative Work & Social Computing. J. Cheng and Michael S. Bernstein, \"Flock: Hybrid Crowd-Machine Learning Classifiers,\" in ACM Conference on Computer Supported Cooperative Work & Social Computing, 2015.\n\nBeen Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, Rory Sayres, Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV). Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas and Rory Sayres, \"Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV),\" arxiv.org, 2018.\n\nArtificial intelligence in healthcare past, present and future. Fei Jiang, Yong Jiang, Hui Zhi, Yi Dong, Hao Li, Sufeng Ma, Yilong Wang, Qiang Dong, Haipeng Shen, Yongjun Wang, Stroke and Vascular Neurology. Fei Jiang, Yong Jiang, Hui Zhi, Yi Dong, Hao Li, Sufeng Ma, Yilong Wang, Qiang Dong, Haipeng Shen and Yongjun Wang, \"Artificial intelligence in healthcare past, present and future,\" Stroke and Vascular Neurology, 2017`.\n\nDeepASL: Kinetic Model Incorporated Loss for Denoising Arterial Spin Labeled MRI via Deep Residual Learning. Cagdas Ulas, Giles Tetteh, Stephan Kaczmarz, Christine Preibisch, H Bjoern, Menze, MICCAICagdas Ulas, Giles Tetteh, Stephan Kaczmarz, Christine Preibisch and Bjoern H. Menze, \"DeepASL: Kinetic Model Incorporated Loss for Denoising Arterial Spin Labeled MRI via Deep Residual Learning,\" in MICCAI, 2018.\n\nDementia in the elderly: an analysis of medical responsibility. C K Cassel, A L Jameton, Annals of Internal Medicine. Cassel CK and Jameton AL, \"Dementia in the elderly: an analysis of medical responsibility,\" Annals of Internal Medicine, 1981.\n\nPat Croskerry, Karen Cosby, Mark L Graber, Hardeep Singh, Diagnosis: Interpreting the Shadows. CRC PressPat Croskerry, Karen Cosby, Mark L. Graber and Hardeep Singh, Diagnosis: Interpreting the Shadows, CRC Press, 2017.\n\n. Curtis P Langlotz, Bibb Allen, Bradley J Erickson, Jayashree Kalpathy-Cramer, Keith Bigelow, Tessa S C , Adam E Flanders, Matthew P Lungren, David S Mendelson, Jeffrey D Rudie, Ge Wang, Krishna Kandarpa, A Roadmap for Foundational Research on Artificial Intelligence in Medical Imaging. RadiologyCurtis P. Langlotz, Bibb Allen, Bradley J. Erickson, Jayashree Kalpathy-Cramer, Keith Bigelow, Tessa S. C, Adam E. Flanders, Matthew P. Lungren, David S. Mendelson, Jeffrey D. Rudie, Ge Wang and Krishna Kandarpa, \"A Roadmap for Foundational Research on Artificial Intelligence in Medical Imaging,\" Radiology, 2019.\n\nWeakly-Supervised Learning-Based Feature Localization for Confocal Laser Endomicroscopy Glioma Images. Mohammadhassan Izadyyazdanabadi, Evgenii Belykh, Claudio Cavallo, Xiaochun Zhao, Sirin Gandhi, Leandro Borba Moreira, Jennifer Eschbacher, Peter Nakaji, C Mark, Yezhou Preul, Yang, MICCAIMohammadhassan Izadyyazdanabadi, Evgenii Belykh, Claudio Cavallo, Xiaochun Zhao, Sirin Gandhi, Leandro Borba Moreira, Jennifer Eschbacher, Peter Nakaji, Mark C. Preul and Yezhou Yang, \"Weakly-Supervised Learning-Based Feature Localization for Confocal Laser Endomicroscopy Glioma Images,\" in MICCAI, 2018.\n\nNeural Machine Translation by Jointly Learning to Align and Translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, Dzmitry Bahdanau, KyungHyun Cho and Yoshua Bengio, \"Neural Machine Translation by Jointly Learning to Align and Translate,\" 2016. [Online]. Available: https://arxiv.org/pdf/1409.0473.pdf.\n\nExplainable artificial intelligence for breast cancer: A visual Case-Based Reasoning Approach. Jean-Baptiste Lamy, Boomadevi Sekar, Gilles Guezennec, Jacques Bouaud, Brigitte S\u00e9roussi, Artificial Intelligence In Medicine. Jean-Baptiste Lamy, Boomadevi Sekar, Gilles Guezennec, Jacques Bouaud and Brigitte S\u00e9roussi, \"Explainable artificial intelligence for breast cancer: A visual Case-Based Reasoning Approach,\" Artificial Intelligence In Medicine, 2018.\n\nF-SVD based algorithm for variability and stability measurement of bio-signals, feature extraction and fusion for pattern recognition. Anil Hazarika, Mausumi Barthakur, Lachit Dutta, Manabendra Bhuyan, Biomedical Signal Processing and Control. Anil Hazarika, Mausumi Barthakur, Lachit Dutta and Manabendra Bhuyan, \"F-SVD based algorithm for variability and stability measurement of bio-signals, feature extraction and fusion for pattern recognition,\" Biomedical Signal Processing and Control, 2019.\n\nClassification of EEG signals for epileptic seizures using hybrid artificial neural networks based wavelet transforms and fuzzy relations. Ozan Kocadagli, Reza Langari, Expert Systems With Applications. Ozan Kocadagli and Reza Langari, \"Classification of EEG signals for epileptic seizures using hybrid artificial neural networks based wavelet transforms and fuzzy relations,\" Expert Systems With Applications, 2017.\n\nClassification of inter-ictal and ictal EEGs using multi-basis MODWPT dimensionality reduction algorithms and LS-SVM: A comparative study. Tao Zhang, Wanzhong Chen, Mingyang Li, Biomedical Signal Processing and Control. Tao Zhang, Wanzhong Chen and Mingyang Li, \"Classification of inter-ictal and ictal EEGs using multi-basis MODWPT dimensionality reduction algorithms and LS-SVM: A comparative study,\" Biomedical Signal Processing and Control, 2018.\n\nCatherine J Scott, Jieqing Jiao, M Jorge Cardoso, Kerstin Kl\u00a8aser, Andrew Melbourne, J Pawel, Jonathan M Markiewicz, Brian F Schott, Sebastien Hutton, Ourselin, Short Acquisition Time PET/MR Pharmacokinetic Modelling Using CNNs. MICCAICatherine J. Scott, Jieqing Jiao, M. Jorge Cardoso, Kerstin Kl\u00a8aser, Andrew Melbourne, Pawel J. Markiewicz, Jonathan M. Schott, Brian F. Hutton and Sebastien Ourselin, \"Short Acquisition Time PET/MR Pharmacokinetic Modelling Using CNNs,\" in MICCAI, 2018.\n\nGroup-Driven Reinforcement Learning for Personalized mHealth Intervention. Feiyun Zhu, Jun Guo, Zheng Xu, Peng Liao, Liu Yang, Junzhou Huang, MICCAIFeiyun Zhu, Jun Guo, Zheng Xu, Peng Liao, Liu Yang and Junzhou Huang, \"Group-Driven Reinforcement Learning for Personalized mHealth Intervention,\" in MICCAI, 2018.\n\nearning how to explain neural networks: PatternNet and PatternAttribution. P.-J Kindermans, K T Sch\u00fctt, M Alber, K.-R M\u00fcller, D Erhan, B Kim, S D\u00e4hne, 29P.-J. Kindermans, K. T. Sch\u00fctt, M. Alber, K.-R. M\u00fcller, D. Erhan, B. Kim and S. D\u00e4hne, \"earning how to explain neural networks: PatternNet and PatternAttribution,\" 2017. [Online]. Available: https://arxiv.org/abs/1705.05598. [Accessed 29 July 2019].\n\nInterpretation of Neural Networks is Fragile. Amirata Ghorbani, Abubakar Abid, James Zou, Amirata Ghorbani, Abubakar Abid and James Zou, \"Interpretation of Neural Networks is Fragile,\" 2017. [Online]. Available: https://arxiv.org/abs/1710.10547.\n\n. Ann-Kathrin Dombrowski, Maximilian Alber, Christopher J Anders, Marcel Ackermann, Klaus-Robert M\u00fcller, Pan Kessel, Ann-Kathrin Dombrowski, Maximilian Alber, Christopher J. Anders, Marcel Ackermann, Klaus-Robert M\u00fcller and Pan Kessel, 2019. [Online]. Available: https://arxiv.org/abs/1906.07983.\n\nDetecting Cancer Metastases on Gigapixel Pathology Images. Yun Liu, Krishna Gadepalli, Mohammad Norouzi, George E Dahl, Timo Kohlberger, Aleksey Boyko, Subhashini Venugopalan, Aleksei Timofeev, Philip Q Nelson, Greg S Corrado, Jason D Hipp, Lily Peng, Martin C Stumpe, Yun Liu, Krishna Gadepalli, Mohammad Norouzi, George E. Dahl, Timo Kohlberger, Aleksey Boyko, Subhashini Venugopalan, Aleksei Timofeev, Philip Q. Nelson, Greg S. Corrado, Jason D. Hipp, Lily Peng and Martin C. Stumpe, \"Detecting Cancer Metastases on Gigapixel Pathology Images,\" 2017. [Online].\n\n. Chris Olah, Alexander Mordvintsev, Ludwig Schubert, distill.pub,\" Google, 2017. [OnlineChris Olah, Alexander Mordvintsev and Ludwig Schubert, \"distill.pub,\" Google, 2017. [Online].\n\nSynthesizing the preferred inputs for neurons in neural networks via deep generator networks. A Nguyen, A Dosovitskiy, J Yosinski, T Brox, J Clune, 29A. Nguyen, A. Dosovitskiy, J. Yosinski, T. Brox and J. Clune, \"Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,\" 2016. [Online]. Available: https://arxiv.org/abs/1605.09304. [Accessed 29 July 2019].\n", "annotations": {"author": null, "publisher": null, "author_last_name": null, "author_first_name": null, "author_affiliation": null, "title": null, "venue": null, "abstract": "[{\"end\":1257,\"start\":115}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2093,\"start\":2090},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2097,\"start\":2094},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2105,\"start\":2102},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2113,\"start\":2110},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2121,\"start\":2118},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2824,\"start\":2821},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2834,\"start\":2830},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2855,\"start\":2851},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3362,\"start\":3359},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3370,\"start\":3367},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3380,\"start\":3376},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3390,\"start\":3386},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3395,\"start\":3391},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3400,\"start\":3396},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3405,\"start\":3401},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3410,\"start\":3406},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3420,\"start\":3416},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3425,\"start\":3421},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3886,\"start\":3882},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4190,\"start\":4187},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4200,\"start\":4196},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4303,\"start\":4299},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":4429,\"start\":4425},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4434,\"start\":4430},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":4546,\"start\":4542},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":4772,\"start\":4768},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6437,\"start\":6433},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":6619,\"start\":6615},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":6629,\"start\":6625},{\"end\":7015,\"start\":7014},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7020,\"start\":7016},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":7270,\"start\":7266},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7292,\"start\":7288},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":8301,\"start\":8297},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":8656,\"start\":8652},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":8690,\"start\":8686},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8727,\"start\":8723},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":8872,\"start\":8868},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":9245,\"start\":9241},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":9604,\"start\":9600},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":9984,\"start\":9980},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":10484,\"start\":10480},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":10489,\"start\":10485},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":10559,\"start\":10555},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":10585,\"start\":10581},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10706,\"start\":10702},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":11260,\"start\":11256},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11270,\"start\":11266},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":11287,\"start\":11283},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11755,\"start\":11751},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":12638,\"start\":12634},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":12648,\"start\":12644},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":12658,\"start\":12654},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":13112,\"start\":13108},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":13256,\"start\":13252},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":14099,\"start\":14095},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":14440,\"start\":14436},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":15204,\"start\":15200},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":15832,\"start\":15828},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":16081,\"start\":16077},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":16311,\"start\":16307},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":16317,\"start\":16313},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":17137,\"start\":17133},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":17953,\"start\":17949},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":18960,\"start\":18956},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":19661,\"start\":19657},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":19858,\"start\":19854},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":19872,\"start\":19868},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":20138,\"start\":20134},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":20375,\"start\":20371},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":20426,\"start\":20422},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":21524,\"start\":21520},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21652,\"start\":21648},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":22115,\"start\":22111},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":23333,\"start\":23330},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":23901,\"start\":23897},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":23906,\"start\":23902},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":24343,\"start\":24339},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":26251,\"start\":26247},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26783,\"start\":26779},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":28377,\"start\":28373},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":29107,\"start\":29103},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":29234,\"start\":29230},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":30941,\"start\":30937},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":31091,\"start\":31087},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":31250,\"start\":31246},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":32195,\"start\":32191},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":32366,\"start\":32362},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":32390,\"start\":32386},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":32395,\"start\":32391},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":32488,\"start\":32484},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":32575,\"start\":32571},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":34216,\"start\":34212},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34372,\"start\":34369},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":35262,\"start\":35258},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":35267,\"start\":35263},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":35371,\"start\":35367},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":35448,\"start\":35444},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":35787,\"start\":35784},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":36621,\"start\":36617},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":37065,\"start\":37061},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":37559,\"start\":37556},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":37828,\"start\":37825},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":37833,\"start\":37829},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":38385,\"start\":38381},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":38589,\"start\":38586},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":38840,\"start\":38836},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":39165,\"start\":39161},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":39175,\"start\":39171},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":39596,\"start\":39592},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":39606,\"start\":39602},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":39650,\"start\":39646},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":39690,\"start\":39686},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":39832,\"start\":39828},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":41741,\"start\":41737},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":41746,\"start\":41742},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":41957,\"start\":41953},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":42398,\"start\":42394},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":42403,\"start\":42399},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":42436,\"start\":42432},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":42549,\"start\":42545},{\"attributes\":{\"ref_id\":\"b96\"},\"end\":43103,\"start\":43099},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":43536,\"start\":43532},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":43546,\"start\":43542},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":44310,\"start\":44306},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":44631,\"start\":44627},{\"attributes\":{\"ref_id\":\"b97\"},\"end\":44924,\"start\":44920},{\"attributes\":{\"ref_id\":\"b98\"},\"end\":45036,\"start\":45032},{\"attributes\":{\"ref_id\":\"b99\"},\"end\":45212,\"start\":45208},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":45730,\"start\":45726},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":46403,\"start\":46399},{\"attributes\":{\"ref_id\":\"b100\"},\"end\":46806,\"start\":46801},{\"attributes\":{\"ref_id\":\"b101\"},\"end\":47173,\"start\":47168},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":47598,\"start\":47594},{\"attributes\":{\"ref_id\":\"b102\"},\"end\":48323,\"start\":48318},{\"attributes\":{\"ref_id\":\"b103\"},\"end\":48362,\"start\":48357},{\"attributes\":{\"ref_id\":\"b104\"},\"end\":48571,\"start\":48566},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":48858,\"start\":48854},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":49288,\"start\":49284},{\"attributes\":{\"ref_id\":\"b100\"},\"end\":49299,\"start\":49294},{\"attributes\":{\"ref_id\":\"b105\"},\"end\":49522,\"start\":49517}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":52417,\"start\":52220},{\"attributes\":{\"id\":\"fig_1\"},\"end\":52585,\"start\":52418},{\"attributes\":{\"id\":\"fig_2\"},\"end\":52649,\"start\":52586}]", "paragraph": "[{\"end\":2122,\"start\":1273},{\"end\":3011,\"start\":2124},{\"end\":4005,\"start\":3013},{\"end\":4702,\"start\":4035},{\"end\":5281,\"start\":4758},{\"end\":5595,\"start\":5283},{\"end\":6476,\"start\":5597},{\"end\":8292,\"start\":6478},{\"end\":8728,\"start\":8294},{\"end\":9341,\"start\":8730},{\"end\":10646,\"start\":9343},{\"end\":11261,\"start\":10648},{\"end\":11717,\"start\":11263},{\"end\":12590,\"start\":11719},{\"end\":12710,\"start\":12592},{\"end\":13325,\"start\":12753},{\"end\":14016,\"start\":13327},{\"end\":14861,\"start\":14018},{\"end\":15823,\"start\":14894},{\"end\":16547,\"start\":15825},{\"end\":17138,\"start\":16631},{\"end\":17831,\"start\":17140},{\"end\":19740,\"start\":17833},{\"end\":20327,\"start\":19742},{\"end\":20503,\"start\":20329},{\"end\":21273,\"start\":20556},{\"end\":21590,\"start\":21275},{\"end\":22033,\"start\":21592},{\"end\":22279,\"start\":22035},{\"end\":23080,\"start\":22325},{\"end\":24068,\"start\":23113},{\"end\":24452,\"start\":24070},{\"end\":24566,\"start\":24454},{\"end\":25353,\"start\":24568},{\"end\":25718,\"start\":25399},{\"end\":26588,\"start\":25755},{\"end\":28157,\"start\":26590},{\"end\":28511,\"start\":28159},{\"end\":29202,\"start\":28603},{\"end\":29974,\"start\":29204},{\"end\":30893,\"start\":29976},{\"end\":31201,\"start\":30895},{\"end\":31712,\"start\":31234},{\"end\":32489,\"start\":31722},{\"end\":33850,\"start\":32500},{\"end\":34640,\"start\":33891},{\"end\":35319,\"start\":34665},{\"end\":35734,\"start\":35321},{\"end\":36970,\"start\":35753},{\"end\":37381,\"start\":36972},{\"end\":38058,\"start\":37407},{\"end\":38236,\"start\":38060},{\"end\":38899,\"start\":38261},{\"end\":39377,\"start\":38901},{\"end\":39499,\"start\":39379},{\"end\":39833,\"start\":39501},{\"end\":40028,\"start\":39886},{\"end\":40848,\"start\":40030},{\"end\":41690,\"start\":40850},{\"end\":42404,\"start\":41692},{\"end\":42939,\"start\":42406},{\"end\":43446,\"start\":42941},{\"end\":43547,\"start\":43448},{\"end\":45330,\"start\":43549},{\"end\":47057,\"start\":45332},{\"end\":47507,\"start\":47059},{\"end\":48940,\"start\":47559},{\"end\":49110,\"start\":48942},{\"end\":49688,\"start\":49112},{\"end\":50465,\"start\":49690},{\"end\":52219,\"start\":50480}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":22324,\"start\":22280},{\"attributes\":{\"id\":\"formula_1\"},\"end\":31721,\"start\":31713}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1271,\"start\":1259},{\"attributes\":{\"n\":\"2.\"},\"end\":4033,\"start\":4008},{\"attributes\":{\"n\":\"2.1.\"},\"end\":4756,\"start\":4705},{\"attributes\":{\"n\":\"2.2.\"},\"end\":12751,\"start\":12713},{\"attributes\":{\"n\":\"2.3.\"},\"end\":14892,\"start\":14864},{\"attributes\":{\"n\":\"2.4.\"},\"end\":16629,\"start\":16550},{\"attributes\":{\"n\":\"2.5.\"},\"end\":20554,\"start\":20506},{\"attributes\":{\"n\":\"2.6.\"},\"end\":23111,\"start\":23083},{\"attributes\":{\"n\":\"3.\"},\"end\":25397,\"start\":25356},{\"attributes\":{\"n\":\"3.1.\"},\"end\":25753,\"start\":25721},{\"attributes\":{\"n\":\"3.2.\"},\"end\":28523,\"start\":28514},{\"end\":28601,\"start\":28526},{\"attributes\":{\"n\":\"3.3.\"},\"end\":31215,\"start\":31204},{\"end\":31232,\"start\":31218},{\"attributes\":{\"n\":\"3.4.\"},\"end\":32498,\"start\":32492},{\"attributes\":{\"n\":\"4.\"},\"end\":33889,\"start\":33853},{\"attributes\":{\"n\":\"4.1.\"},\"end\":34663,\"start\":34643},{\"attributes\":{\"n\":\"4.2.\"},\"end\":35751,\"start\":35737},{\"attributes\":{\"n\":\"4.3.\"},\"end\":37405,\"start\":37384},{\"attributes\":{\"n\":\"5.\"},\"end\":38259,\"start\":38239},{\"attributes\":{\"n\":\"5.1.\"},\"end\":39884,\"start\":39836},{\"attributes\":{\"n\":\"5.2.\"},\"end\":47557,\"start\":47510},{\"attributes\":{\"n\":\"6.\"},\"end\":50478,\"start\":50468},{\"end\":52231,\"start\":52221}]", "table": null, "figure_caption": "[{\"end\":52417,\"start\":52233},{\"end\":52585,\"start\":52420},{\"end\":52649,\"start\":52588}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":29098,\"start\":29087},{\"end\":30440,\"start\":30431},{\"end\":30577,\"start\":30568},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":31880,\"start\":31869},{\"end\":32800,\"start\":32792}]", "bib_author_first_name": "[{\"end\":52962,\"start\":52955},{\"end\":52977,\"start\":52968},{\"end\":52989,\"start\":52983},{\"end\":53003,\"start\":52995},{\"end\":53247,\"start\":53243},{\"end\":53268,\"start\":53261},{\"end\":53284,\"start\":53278},{\"end\":53479,\"start\":53478},{\"end\":53481,\"start\":53480},{\"end\":53494,\"start\":53493},{\"end\":53496,\"start\":53495},{\"end\":53508,\"start\":53507},{\"end\":53510,\"start\":53509},{\"end\":53522,\"start\":53521},{\"end\":53524,\"start\":53523},{\"end\":53534,\"start\":53533},{\"end\":53536,\"start\":53535},{\"end\":53869,\"start\":53864},{\"end\":53880,\"start\":53876},{\"end\":53896,\"start\":53890},{\"end\":54169,\"start\":54164},{\"end\":54182,\"start\":54177},{\"end\":54196,\"start\":54195},{\"end\":54211,\"start\":54205},{\"end\":54226,\"start\":54222},{\"end\":54465,\"start\":54459},{\"end\":54479,\"start\":54473},{\"end\":54498,\"start\":54491},{\"end\":54511,\"start\":54503},{\"end\":54531,\"start\":54526},{\"end\":54545,\"start\":54539},{\"end\":54558,\"start\":54552},{\"end\":54573,\"start\":54568},{\"end\":54585,\"start\":54580},{\"end\":54603,\"start\":54598},{\"end\":54618,\"start\":54613},{\"end\":54620,\"start\":54619},{\"end\":54632,\"start\":54627},{\"end\":54638,\"start\":54637},{\"end\":54931,\"start\":54926},{\"end\":54933,\"start\":54932},{\"end\":54947,\"start\":54942},{\"end\":54963,\"start\":54958},{\"end\":54965,\"start\":54964},{\"end\":54979,\"start\":54973},{\"end\":54981,\"start\":54980},{\"end\":55001,\"start\":55000},{\"end\":55017,\"start\":55010},{\"end\":55019,\"start\":55018},{\"end\":55033,\"start\":55027},{\"end\":55035,\"start\":55034},{\"end\":55428,\"start\":55422},{\"end\":55446,\"start\":55440},{\"end\":55465,\"start\":55454},{\"end\":55854,\"start\":55843},{\"end\":55867,\"start\":55861},{\"end\":55887,\"start\":55880},{\"end\":55903,\"start\":55898},{\"end\":55916,\"start\":55912},{\"end\":55918,\"start\":55917},{\"end\":56260,\"start\":56254},{\"end\":56269,\"start\":56268},{\"end\":56281,\"start\":56277},{\"end\":56543,\"start\":56539},{\"end\":56564,\"start\":56556},{\"end\":56579,\"start\":56572},{\"end\":56581,\"start\":56580},{\"end\":56597,\"start\":56593},{\"end\":56891,\"start\":56890},{\"end\":56893,\"start\":56892},{\"end\":56906,\"start\":56905},{\"end\":56908,\"start\":56907},{\"end\":56919,\"start\":56918},{\"end\":57219,\"start\":57210},{\"end\":57239,\"start\":57232},{\"end\":57259,\"start\":57250},{\"end\":57276,\"start\":57268},{\"end\":57295,\"start\":57287},{\"end\":57315,\"start\":57303},{\"end\":57631,\"start\":57630},{\"end\":57644,\"start\":57639},{\"end\":57660,\"start\":57655},{\"end\":57680,\"start\":57672},{\"end\":57682,\"start\":57681},{\"end\":57968,\"start\":57961},{\"end\":57985,\"start\":57980},{\"end\":57999,\"start\":57993},{\"end\":58010,\"start\":58006},{\"end\":58027,\"start\":58022},{\"end\":58352,\"start\":58349},{\"end\":58364,\"start\":58358},{\"end\":58378,\"start\":58372},{\"end\":58390,\"start\":58388},{\"end\":58616,\"start\":58609},{\"end\":58618,\"start\":58617},{\"end\":58872,\"start\":58871},{\"end\":59174,\"start\":59173},{\"end\":59176,\"start\":59175},{\"end\":59432,\"start\":59425},{\"end\":59453,\"start\":59444},{\"end\":59468,\"start\":59463},{\"end\":59482,\"start\":59477},{\"end\":59487,\"start\":59483},{\"end\":59498,\"start\":59493},{\"end\":59510,\"start\":59501},{\"end\":59906,\"start\":59905},{\"end\":59919,\"start\":59918},{\"end\":59929,\"start\":59928},{\"end\":59939,\"start\":59938},{\"end\":59948,\"start\":59947},{\"end\":59958,\"start\":59957},{\"end\":59967,\"start\":59966},{\"end\":60253,\"start\":60252},{\"end\":60259,\"start\":60254},{\"end\":60577,\"start\":60576},{\"end\":60586,\"start\":60585},{\"end\":60600,\"start\":60596},{\"end\":60833,\"start\":60832},{\"end\":60843,\"start\":60842},{\"end\":60854,\"start\":60853},{\"end\":60866,\"start\":60865},{\"end\":60868,\"start\":60867},{\"end\":60881,\"start\":60877},{\"end\":61222,\"start\":61216},{\"end\":61479,\"start\":61472},{\"end\":61490,\"start\":61486},{\"end\":61503,\"start\":61497},{\"end\":61516,\"start\":61511},{\"end\":61518,\"start\":61517},{\"end\":61746,\"start\":61745},{\"end\":61753,\"start\":61752},{\"end\":61761,\"start\":61760},{\"end\":61771,\"start\":61770},{\"end\":61780,\"start\":61779},{\"end\":62033,\"start\":62028},{\"end\":62049,\"start\":62040},{\"end\":62069,\"start\":62063},{\"end\":62217,\"start\":62212},{\"end\":62230,\"start\":62224},{\"end\":62248,\"start\":62245},{\"end\":62262,\"start\":62258},{\"end\":62277,\"start\":62271},{\"end\":62297,\"start\":62288},{\"end\":62311,\"start\":62302},{\"end\":62611,\"start\":62610},{\"end\":62624,\"start\":62619},{\"end\":62869,\"start\":62863},{\"end\":62897,\"start\":62891},{\"end\":63186,\"start\":63179},{\"end\":63202,\"start\":63197},{\"end\":63216,\"start\":63211},{\"end\":63226,\"start\":63222},{\"end\":63414,\"start\":63409},{\"end\":63427,\"start\":63421},{\"end\":63441,\"start\":63436},{\"end\":63457,\"start\":63453},{\"end\":63472,\"start\":63465},{\"end\":63718,\"start\":63717},{\"end\":63739,\"start\":63732},{\"end\":63759,\"start\":63751},{\"end\":63781,\"start\":63770},{\"end\":63791,\"start\":63787},{\"end\":63807,\"start\":63802},{\"end\":64115,\"start\":64108},{\"end\":64124,\"start\":64122},{\"end\":64137,\"start\":64131},{\"end\":64147,\"start\":64144},{\"end\":64158,\"start\":64155},{\"end\":64430,\"start\":64421},{\"end\":64446,\"start\":64437},{\"end\":64463,\"start\":64455},{\"end\":64483,\"start\":64474},{\"end\":64507,\"start\":64495},{\"end\":64524,\"start\":64516},{\"end\":64864,\"start\":64863},{\"end\":64874,\"start\":64873},{\"end\":64887,\"start\":64886},{\"end\":64904,\"start\":64900},{\"end\":64914,\"start\":64913},{\"end\":65235,\"start\":65234},{\"end\":65237,\"start\":65236},{\"end\":65247,\"start\":65246},{\"end\":65249,\"start\":65248},{\"end\":65264,\"start\":65260},{\"end\":65274,\"start\":65273},{\"end\":65464,\"start\":65463},{\"end\":65473,\"start\":65472},{\"end\":65481,\"start\":65480},{\"end\":65496,\"start\":65492},{\"end\":65506,\"start\":65505},{\"end\":65808,\"start\":65807},{\"end\":65817,\"start\":65816},{\"end\":65829,\"start\":65828},{\"end\":65839,\"start\":65838},{\"end\":65856,\"start\":65852},{\"end\":66171,\"start\":66170},{\"end\":66185,\"start\":66184},{\"end\":66199,\"start\":66198},{\"end\":66212,\"start\":66208},{\"end\":66222,\"start\":66221},{\"end\":66597,\"start\":66596},{\"end\":66607,\"start\":66598},{\"end\":66800,\"start\":66799},{\"end\":66804,\"start\":66801},{\"end\":66819,\"start\":66807},{\"end\":67000,\"start\":66996},{\"end\":67255,\"start\":67254},{\"end\":67267,\"start\":67266},{\"end\":67275,\"start\":67274},{\"end\":67285,\"start\":67284},{\"end\":67297,\"start\":67293},{\"end\":67588,\"start\":67587},{\"end\":67601,\"start\":67600},{\"end\":67614,\"start\":67613},{\"end\":67616,\"start\":67615},{\"end\":67630,\"start\":67629},{\"end\":67867,\"start\":67866},{\"end\":67879,\"start\":67868},{\"end\":68084,\"start\":68083},{\"end\":68097,\"start\":68094},{\"end\":68311,\"start\":68301},{\"end\":68328,\"start\":68324},{\"end\":68343,\"start\":68337},{\"end\":68363,\"start\":68353},{\"end\":68372,\"start\":68371},{\"end\":68386,\"start\":68382},{\"end\":68402,\"start\":68395},{\"end\":68414,\"start\":68410},{\"end\":68677,\"start\":68676},{\"end\":68690,\"start\":68689},{\"end\":68942,\"start\":68941},{\"end\":68957,\"start\":68956},{\"end\":69127,\"start\":69126},{\"end\":69136,\"start\":69135},{\"end\":69146,\"start\":69145},{\"end\":69159,\"start\":69158},{\"end\":69469,\"start\":69468},{\"end\":69481,\"start\":69480},{\"end\":69490,\"start\":69489},{\"end\":69500,\"start\":69499},{\"end\":69509,\"start\":69508},{\"end\":69855,\"start\":69852},{\"end\":69869,\"start\":69864},{\"end\":69884,\"start\":69880},{\"end\":70122,\"start\":70113},{\"end\":70135,\"start\":70132},{\"end\":70149,\"start\":70141},{\"end\":70161,\"start\":70155},{\"end\":70177,\"start\":70172},{\"end\":70192,\"start\":70184},{\"end\":70210,\"start\":70203},{\"end\":70225,\"start\":70218},{\"end\":70243,\"start\":70237},{\"end\":70498,\"start\":70497},{\"end\":70516,\"start\":70509},{\"end\":70534,\"start\":70526},{\"end\":70550,\"start\":70544},{\"end\":70944,\"start\":70937},{\"end\":70946,\"start\":70945},{\"end\":70957,\"start\":70956},{\"end\":70959,\"start\":70958},{\"end\":70975,\"start\":70968},{\"end\":70977,\"start\":70976},{\"end\":70992,\"start\":70985},{\"end\":70994,\"start\":70993},{\"end\":71009,\"start\":71005},{\"end\":71368,\"start\":71360},{\"end\":71374,\"start\":71373},{\"end\":71389,\"start\":71382},{\"end\":71405,\"start\":71399},{\"end\":71419,\"start\":71414},{\"end\":71421,\"start\":71420},{\"end\":71731,\"start\":71728},{\"end\":71749,\"start\":71737},{\"end\":71770,\"start\":71761},{\"end\":71781,\"start\":71778},{\"end\":71800,\"start\":71792},{\"end\":71818,\"start\":71811},{\"end\":71836,\"start\":71830},{\"end\":72166,\"start\":72162},{\"end\":72179,\"start\":72176},{\"end\":72193,\"start\":72185},{\"end\":72206,\"start\":72202},{\"end\":72217,\"start\":72213},{\"end\":72231,\"start\":72225},{\"end\":72817,\"start\":72816},{\"end\":72827,\"start\":72826},{\"end\":72836,\"start\":72835},{\"end\":72838,\"start\":72837},{\"end\":72851,\"start\":72850},{\"end\":73160,\"start\":73155},{\"end\":73172,\"start\":73167},{\"end\":73186,\"start\":73179},{\"end\":73197,\"start\":73191},{\"end\":73213,\"start\":73209},{\"end\":73222,\"start\":73219},{\"end\":73239,\"start\":73233},{\"end\":73615,\"start\":73610},{\"end\":73633,\"start\":73623},{\"end\":73645,\"start\":73643},{\"end\":73660,\"start\":73652},{\"end\":73937,\"start\":73936},{\"end\":73947,\"start\":73946},{\"end\":74133,\"start\":74132},{\"end\":74140,\"start\":74139},{\"end\":74151,\"start\":74150},{\"end\":74329,\"start\":74328},{\"end\":74336,\"start\":74335},{\"end\":74347,\"start\":74346},{\"end\":74357,\"start\":74356},{\"end\":74563,\"start\":74562},{\"end\":74565,\"start\":74564},{\"end\":74575,\"start\":74574},{\"end\":74588,\"start\":74587},{\"end\":74605,\"start\":74601},{\"end\":74918,\"start\":74913},{\"end\":74920,\"start\":74919},{\"end\":74936,\"start\":74930},{\"end\":74950,\"start\":74946},{\"end\":75261,\"start\":75254},{\"end\":75275,\"start\":75269},{\"end\":75290,\"start\":75284},{\"end\":75305,\"start\":75299},{\"end\":75590,\"start\":75586},{\"end\":75602,\"start\":75596},{\"end\":75621,\"start\":75615},{\"end\":75636,\"start\":75630},{\"end\":75647,\"start\":75642},{\"end\":75664,\"start\":75656},{\"end\":75677,\"start\":75673},{\"end\":76023,\"start\":76022},{\"end\":76025,\"start\":76024},{\"end\":76115,\"start\":76111},{\"end\":76127,\"start\":76124},{\"end\":76145,\"start\":76139},{\"end\":76159,\"start\":76156},{\"end\":76174,\"start\":76169},{\"end\":76494,\"start\":76489},{\"end\":76506,\"start\":76502},{\"end\":76521,\"start\":76514},{\"end\":76537,\"start\":76531},{\"end\":76550,\"start\":76543},{\"end\":76553,\"start\":76551},{\"end\":76569,\"start\":76562},{\"end\":76584,\"start\":76578},{\"end\":76597,\"start\":76593},{\"end\":76612,\"start\":76606},{\"end\":76627,\"start\":76621},{\"end\":76641,\"start\":76634},{\"end\":76656,\"start\":76650},{\"end\":77084,\"start\":77075},{\"end\":77099,\"start\":77091},{\"end\":77116,\"start\":77107},{\"end\":77132,\"start\":77124},{\"end\":77146,\"start\":77139},{\"end\":77404,\"start\":77401},{\"end\":77416,\"start\":77411},{\"end\":77842,\"start\":77837},{\"end\":77861,\"start\":77853},{\"end\":77889,\"start\":77888},{\"end\":77906,\"start\":77900},{\"end\":77927,\"start\":77918},{\"end\":77939,\"start\":77935},{\"end\":77959,\"start\":77951},{\"end\":77966,\"start\":77964},{\"end\":77978,\"start\":77977},{\"end\":77992,\"start\":77986},{\"end\":78004,\"start\":77999},{\"end\":78018,\"start\":78013},{\"end\":78031,\"start\":78026},{\"end\":78049,\"start\":78043},{\"end\":78065,\"start\":78058},{\"end\":78078,\"start\":78073},{\"end\":78089,\"start\":78085},{\"end\":78711,\"start\":78705},{\"end\":78729,\"start\":78720},{\"end\":78731,\"start\":78730},{\"end\":78747,\"start\":78740},{\"end\":78749,\"start\":78748},{\"end\":78763,\"start\":78756},{\"end\":78765,\"start\":78764},{\"end\":79042,\"start\":79041},{\"end\":79050,\"start\":79049},{\"end\":79302,\"start\":79297},{\"end\":79318,\"start\":79313},{\"end\":79336,\"start\":79330},{\"end\":79355,\"start\":79348},{\"end\":79371,\"start\":79366},{\"end\":79392,\"start\":79380},{\"end\":79656,\"start\":79647},{\"end\":79670,\"start\":79664},{\"end\":79883,\"start\":79879},{\"end\":79899,\"start\":79892},{\"end\":79913,\"start\":79907},{\"end\":80159,\"start\":80153},{\"end\":80172,\"start\":80167},{\"end\":80186,\"start\":80183},{\"end\":80199,\"start\":80195},{\"end\":80217,\"start\":80207},{\"end\":80234,\"start\":80226},{\"end\":80251,\"start\":80246},{\"end\":80542,\"start\":80536},{\"end\":80562,\"start\":80557},{\"end\":80573,\"start\":80569},{\"end\":80786,\"start\":80782},{\"end\":80814,\"start\":80808},{\"end\":80834,\"start\":80828},{\"end\":80847,\"start\":80841},{\"end\":81101,\"start\":81093},{\"end\":81116,\"start\":81108},{\"end\":81130,\"start\":81123},{\"end\":81140,\"start\":81136},{\"end\":81155,\"start\":81147},{\"end\":81169,\"start\":81161},{\"end\":81652,\"start\":81647},{\"end\":81665,\"start\":81660},{\"end\":82096,\"start\":82095},{\"end\":82103,\"start\":82102},{\"end\":82105,\"start\":82104},{\"end\":82115,\"start\":82114},{\"end\":82328,\"start\":82327},{\"end\":82343,\"start\":82336},{\"end\":82345,\"start\":82344},{\"end\":82606,\"start\":82602},{\"end\":82618,\"start\":82612},{\"end\":82637,\"start\":82631},{\"end\":82652,\"start\":82646},{\"end\":82663,\"start\":82658},{\"end\":82680,\"start\":82672},{\"end\":82693,\"start\":82689},{\"end\":83104,\"start\":83101},{\"end\":83116,\"start\":83112},{\"end\":83127,\"start\":83124},{\"end\":83135,\"start\":83133},{\"end\":83145,\"start\":83142},{\"end\":83156,\"start\":83150},{\"end\":83167,\"start\":83161},{\"end\":83179,\"start\":83174},{\"end\":83193,\"start\":83186},{\"end\":83207,\"start\":83200},{\"end\":83581,\"start\":83575},{\"end\":83593,\"start\":83588},{\"end\":83609,\"start\":83602},{\"end\":83629,\"start\":83620},{\"end\":83642,\"start\":83641},{\"end\":83944,\"start\":83943},{\"end\":83946,\"start\":83945},{\"end\":83956,\"start\":83955},{\"end\":83958,\"start\":83957},{\"end\":84128,\"start\":84125},{\"end\":84145,\"start\":84140},{\"end\":84157,\"start\":84153},{\"end\":84159,\"start\":84158},{\"end\":84175,\"start\":84168},{\"end\":84354,\"start\":84348},{\"end\":84356,\"start\":84355},{\"end\":84371,\"start\":84367},{\"end\":84386,\"start\":84379},{\"end\":84388,\"start\":84387},{\"end\":84408,\"start\":84399},{\"end\":84431,\"start\":84426},{\"end\":84446,\"start\":84441},{\"end\":84450,\"start\":84447},{\"end\":84457,\"start\":84453},{\"end\":84459,\"start\":84458},{\"end\":84477,\"start\":84470},{\"end\":84479,\"start\":84478},{\"end\":84494,\"start\":84489},{\"end\":84496,\"start\":84495},{\"end\":84515,\"start\":84508},{\"end\":84517,\"start\":84516},{\"end\":84527,\"start\":84525},{\"end\":84541,\"start\":84534},{\"end\":85077,\"start\":85063},{\"end\":85103,\"start\":85096},{\"end\":85119,\"start\":85112},{\"end\":85137,\"start\":85129},{\"end\":85149,\"start\":85144},{\"end\":85165,\"start\":85158},{\"end\":85171,\"start\":85166},{\"end\":85189,\"start\":85181},{\"end\":85207,\"start\":85202},{\"end\":85217,\"start\":85216},{\"end\":85230,\"start\":85224},{\"end\":85635,\"start\":85628},{\"end\":85655,\"start\":85646},{\"end\":85667,\"start\":85661},{\"end\":85973,\"start\":85960},{\"end\":85989,\"start\":85980},{\"end\":86003,\"start\":85997},{\"end\":86022,\"start\":86015},{\"end\":86039,\"start\":86031},{\"end\":86460,\"start\":86456},{\"end\":86478,\"start\":86471},{\"end\":86496,\"start\":86490},{\"end\":86514,\"start\":86504},{\"end\":86964,\"start\":86960},{\"end\":86980,\"start\":86976},{\"end\":87381,\"start\":87378},{\"end\":87397,\"start\":87389},{\"end\":87412,\"start\":87404},{\"end\":87700,\"start\":87691},{\"end\":87702,\"start\":87701},{\"end\":87717,\"start\":87710},{\"end\":87725,\"start\":87724},{\"end\":87731,\"start\":87726},{\"end\":87748,\"start\":87741},{\"end\":87764,\"start\":87758},{\"end\":87777,\"start\":87776},{\"end\":87793,\"start\":87785},{\"end\":87795,\"start\":87794},{\"end\":87813,\"start\":87808},{\"end\":87815,\"start\":87814},{\"end\":87833,\"start\":87824},{\"end\":88263,\"start\":88257},{\"end\":88272,\"start\":88269},{\"end\":88283,\"start\":88278},{\"end\":88292,\"start\":88288},{\"end\":88302,\"start\":88299},{\"end\":88316,\"start\":88309},{\"end\":88574,\"start\":88570},{\"end\":88588,\"start\":88587},{\"end\":88590,\"start\":88589},{\"end\":88600,\"start\":88599},{\"end\":88612,\"start\":88608},{\"end\":88622,\"start\":88621},{\"end\":88631,\"start\":88630},{\"end\":88638,\"start\":88637},{\"end\":88952,\"start\":88945},{\"end\":88971,\"start\":88963},{\"end\":88983,\"start\":88978},{\"end\":89159,\"start\":89148},{\"end\":89182,\"start\":89172},{\"end\":89201,\"start\":89190},{\"end\":89203,\"start\":89202},{\"end\":89218,\"start\":89212},{\"end\":89242,\"start\":89230},{\"end\":89254,\"start\":89251},{\"end\":89506,\"start\":89503},{\"end\":89519,\"start\":89512},{\"end\":89539,\"start\":89531},{\"end\":89555,\"start\":89549},{\"end\":89557,\"start\":89556},{\"end\":89568,\"start\":89564},{\"end\":89588,\"start\":89581},{\"end\":89606,\"start\":89596},{\"end\":89627,\"start\":89620},{\"end\":89644,\"start\":89638},{\"end\":89646,\"start\":89645},{\"end\":89659,\"start\":89655},{\"end\":89661,\"start\":89660},{\"end\":89676,\"start\":89671},{\"end\":89678,\"start\":89677},{\"end\":89689,\"start\":89685},{\"end\":89702,\"start\":89696},{\"end\":89704,\"start\":89703},{\"end\":90016,\"start\":90011},{\"end\":90032,\"start\":90023},{\"end\":90052,\"start\":90046},{\"end\":90288,\"start\":90287},{\"end\":90298,\"start\":90297},{\"end\":90313,\"start\":90312},{\"end\":90325,\"start\":90324},{\"end\":90333,\"start\":90332}]", "bib_author_last_name": "[{\"end\":52966,\"start\":52963},{\"end\":52981,\"start\":52978},{\"end\":52993,\"start\":52990},{\"end\":53008,\"start\":53004},{\"end\":53259,\"start\":53248},{\"end\":53276,\"start\":53269},{\"end\":53289,\"start\":53285},{\"end\":53491,\"start\":53482},{\"end\":53505,\"start\":53497},{\"end\":53519,\"start\":53511},{\"end\":53531,\"start\":53525},{\"end\":53541,\"start\":53537},{\"end\":53874,\"start\":53870},{\"end\":53888,\"start\":53881},{\"end\":53905,\"start\":53897},{\"end\":54175,\"start\":54170},{\"end\":54193,\"start\":54183},{\"end\":54203,\"start\":54197},{\"end\":54220,\"start\":54212},{\"end\":54231,\"start\":54227},{\"end\":54244,\"start\":54233},{\"end\":54471,\"start\":54466},{\"end\":54489,\"start\":54480},{\"end\":54501,\"start\":54499},{\"end\":54524,\"start\":54512},{\"end\":54537,\"start\":54532},{\"end\":54550,\"start\":54546},{\"end\":54566,\"start\":54559},{\"end\":54578,\"start\":54574},{\"end\":54596,\"start\":54586},{\"end\":54611,\"start\":54604},{\"end\":54625,\"start\":54621},{\"end\":54635,\"start\":54633},{\"end\":54645,\"start\":54639},{\"end\":54940,\"start\":54934},{\"end\":54956,\"start\":54948},{\"end\":54971,\"start\":54966},{\"end\":54988,\"start\":54982},{\"end\":54998,\"start\":54990},{\"end\":55008,\"start\":55002},{\"end\":55025,\"start\":55020},{\"end\":55043,\"start\":55036},{\"end\":55047,\"start\":55045},{\"end\":55438,\"start\":55429},{\"end\":55452,\"start\":55447},{\"end\":55472,\"start\":55466},{\"end\":55859,\"start\":55855},{\"end\":55878,\"start\":55868},{\"end\":55896,\"start\":55888},{\"end\":55910,\"start\":55904},{\"end\":55925,\"start\":55919},{\"end\":56266,\"start\":56261},{\"end\":56275,\"start\":56270},{\"end\":56285,\"start\":56282},{\"end\":56554,\"start\":56544},{\"end\":56570,\"start\":56565},{\"end\":56591,\"start\":56582},{\"end\":56608,\"start\":56598},{\"end\":56903,\"start\":56894},{\"end\":56916,\"start\":56909},{\"end\":56925,\"start\":56920},{\"end\":57230,\"start\":57220},{\"end\":57248,\"start\":57240},{\"end\":57266,\"start\":57260},{\"end\":57285,\"start\":57277},{\"end\":57301,\"start\":57296},{\"end\":57322,\"start\":57316},{\"end\":57637,\"start\":57632},{\"end\":57653,\"start\":57645},{\"end\":57670,\"start\":57661},{\"end\":57690,\"start\":57683},{\"end\":57697,\"start\":57692},{\"end\":57978,\"start\":57969},{\"end\":57991,\"start\":57986},{\"end\":58004,\"start\":58000},{\"end\":58020,\"start\":58011},{\"end\":58034,\"start\":58028},{\"end\":58356,\"start\":58353},{\"end\":58370,\"start\":58365},{\"end\":58386,\"start\":58379},{\"end\":58395,\"start\":58391},{\"end\":58400,\"start\":58397},{\"end\":58625,\"start\":58619},{\"end\":58880,\"start\":58873},{\"end\":59182,\"start\":59177},{\"end\":59442,\"start\":59433},{\"end\":59461,\"start\":59454},{\"end\":59475,\"start\":59469},{\"end\":59491,\"start\":59488},{\"end\":59521,\"start\":59511},{\"end\":59916,\"start\":59907},{\"end\":59926,\"start\":59920},{\"end\":59936,\"start\":59930},{\"end\":59945,\"start\":59940},{\"end\":59955,\"start\":59949},{\"end\":59964,\"start\":59959},{\"end\":59973,\"start\":59968},{\"end\":60262,\"start\":60260},{\"end\":60281,\"start\":60264},{\"end\":60583,\"start\":60578},{\"end\":60594,\"start\":60587},{\"end\":60607,\"start\":60601},{\"end\":60840,\"start\":60834},{\"end\":60851,\"start\":60844},{\"end\":60863,\"start\":60855},{\"end\":60875,\"start\":60869},{\"end\":60888,\"start\":60882},{\"end\":61231,\"start\":61223},{\"end\":61235,\"start\":61233},{\"end\":61484,\"start\":61480},{\"end\":61495,\"start\":61491},{\"end\":61509,\"start\":61504},{\"end\":61522,\"start\":61519},{\"end\":61750,\"start\":61747},{\"end\":61758,\"start\":61754},{\"end\":61768,\"start\":61762},{\"end\":61777,\"start\":61772},{\"end\":61789,\"start\":61781},{\"end\":62038,\"start\":62034},{\"end\":62061,\"start\":62050},{\"end\":62078,\"start\":62070},{\"end\":62222,\"start\":62218},{\"end\":62243,\"start\":62231},{\"end\":62256,\"start\":62249},{\"end\":62269,\"start\":62263},{\"end\":62286,\"start\":62278},{\"end\":62300,\"start\":62298},{\"end\":62323,\"start\":62312},{\"end\":62617,\"start\":62612},{\"end\":62633,\"start\":62625},{\"end\":62638,\"start\":62635},{\"end\":62889,\"start\":62870},{\"end\":62903,\"start\":62898},{\"end\":62913,\"start\":62905},{\"end\":63195,\"start\":63187},{\"end\":63209,\"start\":63203},{\"end\":63220,\"start\":63217},{\"end\":63230,\"start\":63227},{\"end\":63419,\"start\":63415},{\"end\":63434,\"start\":63428},{\"end\":63451,\"start\":63442},{\"end\":63463,\"start\":63458},{\"end\":63481,\"start\":63473},{\"end\":63730,\"start\":63719},{\"end\":63749,\"start\":63740},{\"end\":63768,\"start\":63760},{\"end\":63785,\"start\":63782},{\"end\":63800,\"start\":63792},{\"end\":63814,\"start\":63808},{\"end\":63821,\"start\":63816},{\"end\":64120,\"start\":64116},{\"end\":64129,\"start\":64125},{\"end\":64142,\"start\":64138},{\"end\":64153,\"start\":64148},{\"end\":64161,\"start\":64159},{\"end\":64435,\"start\":64431},{\"end\":64453,\"start\":64447},{\"end\":64472,\"start\":64464},{\"end\":64493,\"start\":64484},{\"end\":64514,\"start\":64508},{\"end\":64530,\"start\":64525},{\"end\":64871,\"start\":64865},{\"end\":64884,\"start\":64875},{\"end\":64898,\"start\":64888},{\"end\":64911,\"start\":64905},{\"end\":64920,\"start\":64915},{\"end\":65244,\"start\":65238},{\"end\":65258,\"start\":65250},{\"end\":65271,\"start\":65265},{\"end\":65280,\"start\":65275},{\"end\":65470,\"start\":65465},{\"end\":65478,\"start\":65474},{\"end\":65490,\"start\":65482},{\"end\":65503,\"start\":65497},{\"end\":65512,\"start\":65507},{\"end\":65814,\"start\":65809},{\"end\":65826,\"start\":65818},{\"end\":65836,\"start\":65830},{\"end\":65850,\"start\":65840},{\"end\":65863,\"start\":65857},{\"end\":66182,\"start\":66172},{\"end\":66196,\"start\":66186},{\"end\":66206,\"start\":66200},{\"end\":66219,\"start\":66213},{\"end\":66228,\"start\":66223},{\"end\":66610,\"start\":66608},{\"end\":66623,\"start\":66612},{\"end\":66828,\"start\":66820},{\"end\":67007,\"start\":67001},{\"end\":67264,\"start\":67256},{\"end\":67272,\"start\":67268},{\"end\":67282,\"start\":67276},{\"end\":67291,\"start\":67286},{\"end\":67304,\"start\":67298},{\"end\":67598,\"start\":67589},{\"end\":67611,\"start\":67602},{\"end\":67627,\"start\":67617},{\"end\":67638,\"start\":67631},{\"end\":67885,\"start\":67880},{\"end\":67895,\"start\":67887},{\"end\":68092,\"start\":68085},{\"end\":68104,\"start\":68098},{\"end\":68112,\"start\":68106},{\"end\":68322,\"start\":68312},{\"end\":68335,\"start\":68329},{\"end\":68351,\"start\":68344},{\"end\":68369,\"start\":68364},{\"end\":68380,\"start\":68373},{\"end\":68393,\"start\":68387},{\"end\":68408,\"start\":68403},{\"end\":68420,\"start\":68415},{\"end\":68425,\"start\":68422},{\"end\":68687,\"start\":68678},{\"end\":68698,\"start\":68691},{\"end\":68954,\"start\":68943},{\"end\":68962,\"start\":68958},{\"end\":69133,\"start\":69128},{\"end\":69143,\"start\":69137},{\"end\":69156,\"start\":69147},{\"end\":69167,\"start\":69160},{\"end\":69478,\"start\":69470},{\"end\":69487,\"start\":69482},{\"end\":69497,\"start\":69491},{\"end\":69506,\"start\":69501},{\"end\":69516,\"start\":69510},{\"end\":69862,\"start\":69856},{\"end\":69878,\"start\":69870},{\"end\":69890,\"start\":69885},{\"end\":70130,\"start\":70123},{\"end\":70139,\"start\":70136},{\"end\":70153,\"start\":70150},{\"end\":70170,\"start\":70162},{\"end\":70182,\"start\":70178},{\"end\":70201,\"start\":70193},{\"end\":70216,\"start\":70211},{\"end\":70235,\"start\":70226},{\"end\":70254,\"start\":70244},{\"end\":70507,\"start\":70499},{\"end\":70524,\"start\":70517},{\"end\":70542,\"start\":70535},{\"end\":70556,\"start\":70551},{\"end\":70954,\"start\":70947},{\"end\":70966,\"start\":70960},{\"end\":70983,\"start\":70978},{\"end\":71003,\"start\":70995},{\"end\":71020,\"start\":71010},{\"end\":71371,\"start\":71369},{\"end\":71380,\"start\":71375},{\"end\":71397,\"start\":71390},{\"end\":71412,\"start\":71406},{\"end\":71429,\"start\":71422},{\"end\":71437,\"start\":71431},{\"end\":71735,\"start\":71732},{\"end\":71759,\"start\":71750},{\"end\":71776,\"start\":71771},{\"end\":71790,\"start\":71782},{\"end\":71809,\"start\":71801},{\"end\":71828,\"start\":71819},{\"end\":71841,\"start\":71837},{\"end\":72174,\"start\":72167},{\"end\":72183,\"start\":72180},{\"end\":72200,\"start\":72194},{\"end\":72211,\"start\":72207},{\"end\":72223,\"start\":72218},{\"end\":72239,\"start\":72232},{\"end\":72824,\"start\":72818},{\"end\":72833,\"start\":72828},{\"end\":72848,\"start\":72839},{\"end\":72859,\"start\":72852},{\"end\":73165,\"start\":73161},{\"end\":73177,\"start\":73173},{\"end\":73189,\"start\":73187},{\"end\":73207,\"start\":73198},{\"end\":73217,\"start\":73214},{\"end\":73231,\"start\":73223},{\"end\":73251,\"start\":73240},{\"end\":73621,\"start\":73616},{\"end\":73641,\"start\":73634},{\"end\":73650,\"start\":73646},{\"end\":73671,\"start\":73661},{\"end\":73944,\"start\":73938},{\"end\":73958,\"start\":73948},{\"end\":74137,\"start\":74134},{\"end\":74148,\"start\":74141},{\"end\":74158,\"start\":74152},{\"end\":74333,\"start\":74330},{\"end\":74344,\"start\":74337},{\"end\":74354,\"start\":74348},{\"end\":74364,\"start\":74358},{\"end\":74572,\"start\":74566},{\"end\":74585,\"start\":74576},{\"end\":74599,\"start\":74589},{\"end\":74612,\"start\":74606},{\"end\":74928,\"start\":74921},{\"end\":74944,\"start\":74937},{\"end\":74963,\"start\":74951},{\"end\":75267,\"start\":75262},{\"end\":75282,\"start\":75276},{\"end\":75297,\"start\":75291},{\"end\":75320,\"start\":75306},{\"end\":75594,\"start\":75591},{\"end\":75613,\"start\":75603},{\"end\":75628,\"start\":75622},{\"end\":75640,\"start\":75637},{\"end\":75654,\"start\":75648},{\"end\":75671,\"start\":75665},{\"end\":75684,\"start\":75678},{\"end\":76122,\"start\":76116},{\"end\":76137,\"start\":76128},{\"end\":76154,\"start\":76146},{\"end\":76167,\"start\":76160},{\"end\":76179,\"start\":76175},{\"end\":76500,\"start\":76495},{\"end\":76512,\"start\":76507},{\"end\":76529,\"start\":76522},{\"end\":76541,\"start\":76538},{\"end\":76560,\"start\":76554},{\"end\":76576,\"start\":76570},{\"end\":76591,\"start\":76585},{\"end\":76604,\"start\":76598},{\"end\":76619,\"start\":76613},{\"end\":76632,\"start\":76628},{\"end\":76648,\"start\":76642},{\"end\":76662,\"start\":76657},{\"end\":76672,\"start\":76664},{\"end\":77089,\"start\":77085},{\"end\":77105,\"start\":77100},{\"end\":77122,\"start\":77117},{\"end\":77137,\"start\":77133},{\"end\":77150,\"start\":77147},{\"end\":77409,\"start\":77405},{\"end\":77420,\"start\":77417},{\"end\":77427,\"start\":77422},{\"end\":77851,\"start\":77843},{\"end\":77868,\"start\":77862},{\"end\":77886,\"start\":77870},{\"end\":77898,\"start\":77890},{\"end\":77916,\"start\":77907},{\"end\":77933,\"start\":77928},{\"end\":77949,\"start\":77940},{\"end\":77962,\"start\":77960},{\"end\":77975,\"start\":77967},{\"end\":77984,\"start\":77979},{\"end\":77997,\"start\":77993},{\"end\":78011,\"start\":78005},{\"end\":78024,\"start\":78019},{\"end\":78041,\"start\":78032},{\"end\":78056,\"start\":78050},{\"end\":78071,\"start\":78066},{\"end\":78083,\"start\":78079},{\"end\":78098,\"start\":78090},{\"end\":78108,\"start\":78100},{\"end\":78718,\"start\":78712},{\"end\":78738,\"start\":78732},{\"end\":78754,\"start\":78750},{\"end\":78774,\"start\":78766},{\"end\":78785,\"start\":78776},{\"end\":79047,\"start\":79043},{\"end\":79058,\"start\":79051},{\"end\":79311,\"start\":79303},{\"end\":79328,\"start\":79319},{\"end\":79346,\"start\":79337},{\"end\":79364,\"start\":79356},{\"end\":79378,\"start\":79372},{\"end\":79400,\"start\":79393},{\"end\":79662,\"start\":79657},{\"end\":79677,\"start\":79671},{\"end\":79890,\"start\":79884},{\"end\":79905,\"start\":79900},{\"end\":79921,\"start\":79914},{\"end\":80165,\"start\":80160},{\"end\":80181,\"start\":80173},{\"end\":80193,\"start\":80187},{\"end\":80205,\"start\":80200},{\"end\":80224,\"start\":80218},{\"end\":80244,\"start\":80235},{\"end\":80260,\"start\":80252},{\"end\":80555,\"start\":80543},{\"end\":80567,\"start\":80563},{\"end\":80577,\"start\":80574},{\"end\":80806,\"start\":80787},{\"end\":80826,\"start\":80815},{\"end\":80839,\"start\":80835},{\"end\":80858,\"start\":80848},{\"end\":81106,\"start\":81102},{\"end\":81121,\"start\":81117},{\"end\":81134,\"start\":81131},{\"end\":81145,\"start\":81141},{\"end\":81159,\"start\":81156},{\"end\":81178,\"start\":81170},{\"end\":81183,\"start\":81180},{\"end\":81658,\"start\":81653},{\"end\":81673,\"start\":81666},{\"end\":82100,\"start\":82097},{\"end\":82112,\"start\":82106},{\"end\":82120,\"start\":82116},{\"end\":82334,\"start\":82329},{\"end\":82355,\"start\":82346},{\"end\":82610,\"start\":82607},{\"end\":82629,\"start\":82619},{\"end\":82644,\"start\":82638},{\"end\":82656,\"start\":82653},{\"end\":82670,\"start\":82664},{\"end\":82687,\"start\":82681},{\"end\":82700,\"start\":82694},{\"end\":83110,\"start\":83105},{\"end\":83122,\"start\":83117},{\"end\":83131,\"start\":83128},{\"end\":83140,\"start\":83136},{\"end\":83148,\"start\":83146},{\"end\":83159,\"start\":83157},{\"end\":83172,\"start\":83168},{\"end\":83184,\"start\":83180},{\"end\":83198,\"start\":83194},{\"end\":83212,\"start\":83208},{\"end\":83586,\"start\":83582},{\"end\":83600,\"start\":83594},{\"end\":83618,\"start\":83610},{\"end\":83639,\"start\":83630},{\"end\":83649,\"start\":83643},{\"end\":83656,\"start\":83651},{\"end\":83953,\"start\":83947},{\"end\":83966,\"start\":83959},{\"end\":84138,\"start\":84129},{\"end\":84151,\"start\":84146},{\"end\":84166,\"start\":84160},{\"end\":84181,\"start\":84176},{\"end\":84365,\"start\":84357},{\"end\":84377,\"start\":84372},{\"end\":84397,\"start\":84389},{\"end\":84424,\"start\":84409},{\"end\":84439,\"start\":84432},{\"end\":84468,\"start\":84460},{\"end\":84487,\"start\":84480},{\"end\":84506,\"start\":84497},{\"end\":84523,\"start\":84518},{\"end\":84532,\"start\":84528},{\"end\":84550,\"start\":84542},{\"end\":85094,\"start\":85078},{\"end\":85110,\"start\":85104},{\"end\":85127,\"start\":85120},{\"end\":85142,\"start\":85138},{\"end\":85156,\"start\":85150},{\"end\":85179,\"start\":85172},{\"end\":85200,\"start\":85190},{\"end\":85214,\"start\":85208},{\"end\":85222,\"start\":85218},{\"end\":85236,\"start\":85231},{\"end\":85242,\"start\":85238},{\"end\":85644,\"start\":85636},{\"end\":85659,\"start\":85656},{\"end\":85674,\"start\":85668},{\"end\":85978,\"start\":85974},{\"end\":85995,\"start\":85990},{\"end\":86013,\"start\":86004},{\"end\":86029,\"start\":86023},{\"end\":86048,\"start\":86040},{\"end\":86469,\"start\":86461},{\"end\":86488,\"start\":86479},{\"end\":86502,\"start\":86497},{\"end\":86521,\"start\":86515},{\"end\":86974,\"start\":86965},{\"end\":86988,\"start\":86981},{\"end\":87387,\"start\":87382},{\"end\":87402,\"start\":87398},{\"end\":87415,\"start\":87413},{\"end\":87708,\"start\":87703},{\"end\":87722,\"start\":87718},{\"end\":87739,\"start\":87732},{\"end\":87756,\"start\":87749},{\"end\":87774,\"start\":87765},{\"end\":87783,\"start\":87778},{\"end\":87806,\"start\":87796},{\"end\":87822,\"start\":87816},{\"end\":87840,\"start\":87834},{\"end\":87850,\"start\":87842},{\"end\":88267,\"start\":88264},{\"end\":88276,\"start\":88273},{\"end\":88286,\"start\":88284},{\"end\":88297,\"start\":88293},{\"end\":88307,\"start\":88303},{\"end\":88322,\"start\":88317},{\"end\":88585,\"start\":88575},{\"end\":88597,\"start\":88591},{\"end\":88606,\"start\":88601},{\"end\":88619,\"start\":88613},{\"end\":88628,\"start\":88623},{\"end\":88635,\"start\":88632},{\"end\":88644,\"start\":88639},{\"end\":88961,\"start\":88953},{\"end\":88976,\"start\":88972},{\"end\":88987,\"start\":88984},{\"end\":89170,\"start\":89160},{\"end\":89188,\"start\":89183},{\"end\":89210,\"start\":89204},{\"end\":89228,\"start\":89219},{\"end\":89249,\"start\":89243},{\"end\":89261,\"start\":89255},{\"end\":89510,\"start\":89507},{\"end\":89529,\"start\":89520},{\"end\":89547,\"start\":89540},{\"end\":89562,\"start\":89558},{\"end\":89579,\"start\":89569},{\"end\":89594,\"start\":89589},{\"end\":89618,\"start\":89607},{\"end\":89636,\"start\":89628},{\"end\":89653,\"start\":89647},{\"end\":89669,\"start\":89662},{\"end\":89683,\"start\":89679},{\"end\":89694,\"start\":89690},{\"end\":89711,\"start\":89705},{\"end\":90021,\"start\":90017},{\"end\":90044,\"start\":90033},{\"end\":90061,\"start\":90053},{\"end\":90295,\"start\":90289},{\"end\":90310,\"start\":90299},{\"end\":90322,\"start\":90314},{\"end\":90330,\"start\":90326},{\"end\":90339,\"start\":90334}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":8861952},\"end\":53176,\"start\":52892},{\"attributes\":{\"id\":\"b1\"},\"end\":53443,\"start\":53178},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":29006669},\"end\":53767,\"start\":53445},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":4907362},\"end\":54089,\"start\":53769},{\"attributes\":{\"id\":\"b4\"},\"end\":54455,\"start\":54091},{\"attributes\":{\"id\":\"b5\"},\"end\":54835,\"start\":54457},{\"attributes\":{\"id\":\"b6\"},\"end\":55335,\"start\":54837},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":206429151},\"end\":55728,\"start\":55337},{\"attributes\":{\"id\":\"b8\"},\"end\":56190,\"start\":55730},{\"attributes\":{\"id\":\"b9\"},\"end\":56448,\"start\":56192},{\"attributes\":{\"id\":\"b10\"},\"end\":56836,\"start\":56450},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":2057093},\"end\":57133,\"start\":56838},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":67856367},\"end\":57569,\"start\":57135},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":15857872},\"end\":57889,\"start\":57571},{\"attributes\":{\"id\":\"b14\"},\"end\":58262,\"start\":57891},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":62841749},\"end\":58569,\"start\":58264},{\"attributes\":{\"id\":\"b16\"},\"end\":58750,\"start\":58571},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":59553332},\"end\":59090,\"start\":58752},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":57574615},\"end\":59319,\"start\":59092},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":52213238},\"end\":59820,\"start\":59321},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":73428468},\"end\":60185,\"start\":59822},{\"attributes\":{\"id\":\"b21\"},\"end\":60471,\"start\":60187},{\"attributes\":{\"id\":\"b22\"},\"end\":60768,\"start\":60473},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":69428199},\"end\":61198,\"start\":60770},{\"attributes\":{\"id\":\"b24\"},\"end\":61417,\"start\":61200},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":113404661},\"end\":61743,\"start\":61419},{\"attributes\":{\"id\":\"b26\"},\"end\":62024,\"start\":61745},{\"attributes\":{\"id\":\"b27\"},\"end\":62208,\"start\":62026},{\"attributes\":{\"id\":\"b28\"},\"end\":62554,\"start\":62210},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":21889700},\"end\":62815,\"start\":62556},{\"attributes\":{\"id\":\"b30\"},\"end\":63131,\"start\":62817},{\"attributes\":{\"id\":\"b31\"},\"end\":63351,\"start\":63133},{\"attributes\":{\"id\":\"b32\"},\"end\":63633,\"start\":63353},{\"attributes\":{\"id\":\"b33\"},\"end\":64032,\"start\":63635},{\"attributes\":{\"id\":\"b34\"},\"end\":64319,\"start\":64034},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":9327892},\"end\":64775,\"start\":64321},{\"attributes\":{\"id\":\"b36\"},\"end\":65164,\"start\":64777},{\"attributes\":{\"id\":\"b37\"},\"end\":65424,\"start\":65166},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":2479906},\"end\":65718,\"start\":65426},{\"attributes\":{\"id\":\"b39\"},\"end\":66107,\"start\":65720},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":12078410},\"end\":66523,\"start\":66109},{\"attributes\":{\"id\":\"b41\"},\"end\":66747,\"start\":66525},{\"attributes\":{\"id\":\"b42\"},\"end\":66929,\"start\":66749},{\"attributes\":{\"id\":\"b43\"},\"end\":67206,\"start\":66931},{\"attributes\":{\"id\":\"b44\"},\"end\":67513,\"start\":67208},{\"attributes\":{\"id\":\"b45\"},\"end\":67790,\"start\":67515},{\"attributes\":{\"id\":\"b46\"},\"end\":68027,\"start\":67792},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":3960646},\"end\":68258,\"start\":68029},{\"attributes\":{\"id\":\"b48\"},\"end\":68614,\"start\":68260},{\"attributes\":{\"id\":\"b49\"},\"end\":68877,\"start\":68616},{\"attributes\":{\"id\":\"b50\"},\"end\":69071,\"start\":68879},{\"attributes\":{\"id\":\"b51\"},\"end\":69408,\"start\":69073},{\"attributes\":{\"id\":\"b52\"},\"end\":69723,\"start\":69410},{\"attributes\":{\"id\":\"b53\"},\"end\":70079,\"start\":69725},{\"attributes\":{\"id\":\"b54\"},\"end\":70495,\"start\":70081},{\"attributes\":{\"id\":\"b55\"},\"end\":70847,\"start\":70497},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":49186719},\"end\":71290,\"start\":70849},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":52095861},\"end\":71683,\"start\":71292},{\"attributes\":{\"id\":\"b58\"},\"end\":72066,\"start\":71685},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":14190268},\"end\":72710,\"start\":72068},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":17699665},\"end\":73093,\"start\":72712},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":3652280},\"end\":73504,\"start\":73095},{\"attributes\":{\"id\":\"b62\"},\"end\":73905,\"start\":73506},{\"attributes\":{\"id\":\"b63\"},\"end\":74075,\"start\":73907},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":7715182},\"end\":74269,\"start\":74077},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":11246170},\"end\":74488,\"start\":74271},{\"attributes\":{\"id\":\"b66\"},\"end\":74829,\"start\":74490},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":202473},\"end\":75150,\"start\":74831},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":23890457},\"end\":75584,\"start\":75152},{\"attributes\":{\"id\":\"b69\"},\"end\":76018,\"start\":75586},{\"attributes\":{\"id\":\"b70\"},\"end\":76058,\"start\":76020},{\"attributes\":{\"id\":\"b71\"},\"end\":76377,\"start\":76060},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":49862143},\"end\":76991,\"start\":76379},{\"attributes\":{\"id\":\"b73\"},\"end\":77338,\"start\":76993},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":13193974},\"end\":77726,\"start\":77340},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":51966202},\"end\":78648,\"start\":77728},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":7891407},\"end\":78969,\"start\":78650},{\"attributes\":{\"id\":\"b77\"},\"end\":79243,\"start\":78971},{\"attributes\":{\"id\":\"b78\"},\"end\":79579,\"start\":79245},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":9794990},\"end\":79809,\"start\":79581},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":49313133},\"end\":80064,\"start\":79811},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":4512713},\"end\":80493,\"start\":80066},{\"attributes\":{\"id\":\"b82\"},\"end\":80728,\"start\":80495},{\"attributes\":{\"id\":\"b83\"},\"end\":81010,\"start\":80730},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":43006678},\"end\":81578,\"start\":81012},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":32615829},\"end\":81991,\"start\":81580},{\"attributes\":{\"id\":\"b86\"},\"end\":82275,\"start\":81993},{\"attributes\":{\"id\":\"b87\",\"matched_paper_id\":12429105},\"end\":82600,\"start\":82277},{\"attributes\":{\"id\":\"b88\"},\"end\":83035,\"start\":82602},{\"attributes\":{\"id\":\"b89\",\"matched_paper_id\":3779750},\"end\":83464,\"start\":83037},{\"attributes\":{\"id\":\"b90\"},\"end\":83877,\"start\":83466},{\"attributes\":{\"id\":\"b91\",\"matched_paper_id\":21037154},\"end\":84123,\"start\":83879},{\"attributes\":{\"id\":\"b92\"},\"end\":84344,\"start\":84125},{\"attributes\":{\"id\":\"b93\"},\"end\":84958,\"start\":84346},{\"attributes\":{\"id\":\"b94\"},\"end\":85555,\"start\":84960},{\"attributes\":{\"id\":\"b95\"},\"end\":85863,\"start\":85557},{\"attributes\":{\"id\":\"b96\",\"matched_paper_id\":67954510},\"end\":86319,\"start\":85865},{\"attributes\":{\"id\":\"b97\",\"matched_paper_id\":53013032},\"end\":86819,\"start\":86321},{\"attributes\":{\"id\":\"b98\",\"matched_paper_id\":30814610},\"end\":87237,\"start\":86821},{\"attributes\":{\"id\":\"b99\",\"matched_paper_id\":53014430},\"end\":87689,\"start\":87239},{\"attributes\":{\"id\":\"b100\"},\"end\":88180,\"start\":87691},{\"attributes\":{\"id\":\"b101\"},\"end\":88493,\"start\":88182},{\"attributes\":{\"id\":\"b102\"},\"end\":88897,\"start\":88495},{\"attributes\":{\"id\":\"b103\"},\"end\":89144,\"start\":88899},{\"attributes\":{\"id\":\"b104\"},\"end\":89442,\"start\":89146},{\"attributes\":{\"id\":\"b105\"},\"end\":90007,\"start\":89444},{\"attributes\":{\"id\":\"b106\"},\"end\":90191,\"start\":90009},{\"attributes\":{\"id\":\"b107\"},\"end\":90586,\"start\":90193}]", "bib_title": "[{\"end\":52953,\"start\":52892},{\"end\":53476,\"start\":53445},{\"end\":53862,\"start\":53769},{\"end\":55420,\"start\":55337},{\"end\":56888,\"start\":56838},{\"end\":57208,\"start\":57135},{\"end\":57628,\"start\":57571},{\"end\":58347,\"start\":58264},{\"end\":58869,\"start\":58752},{\"end\":59171,\"start\":59092},{\"end\":59423,\"start\":59321},{\"end\":59903,\"start\":59822},{\"end\":60830,\"start\":60770},{\"end\":61470,\"start\":61419},{\"end\":62608,\"start\":62556},{\"end\":64419,\"start\":64321},{\"end\":65461,\"start\":65426},{\"end\":66168,\"start\":66109},{\"end\":66994,\"start\":66931},{\"end\":68081,\"start\":68029},{\"end\":70935,\"start\":70849},{\"end\":71358,\"start\":71292},{\"end\":72160,\"start\":72068},{\"end\":72814,\"start\":72712},{\"end\":73153,\"start\":73095},{\"end\":74130,\"start\":74077},{\"end\":74326,\"start\":74271},{\"end\":74911,\"start\":74831},{\"end\":75252,\"start\":75152},{\"end\":76487,\"start\":76379},{\"end\":77399,\"start\":77340},{\"end\":77835,\"start\":77728},{\"end\":78703,\"start\":78650},{\"end\":79645,\"start\":79581},{\"end\":79877,\"start\":79811},{\"end\":80151,\"start\":80066},{\"end\":81091,\"start\":81012},{\"end\":81645,\"start\":81580},{\"end\":82325,\"start\":82277},{\"end\":83099,\"start\":83037},{\"end\":83941,\"start\":83879},{\"end\":85958,\"start\":85865},{\"end\":86454,\"start\":86321},{\"end\":86958,\"start\":86821},{\"end\":87376,\"start\":87239}]", "bib_author": "[{\"end\":52968,\"start\":52955},{\"end\":52983,\"start\":52968},{\"end\":52995,\"start\":52983},{\"end\":53010,\"start\":52995},{\"end\":53261,\"start\":53243},{\"end\":53278,\"start\":53261},{\"end\":53291,\"start\":53278},{\"end\":53493,\"start\":53478},{\"end\":53507,\"start\":53493},{\"end\":53521,\"start\":53507},{\"end\":53533,\"start\":53521},{\"end\":53543,\"start\":53533},{\"end\":53876,\"start\":53864},{\"end\":53890,\"start\":53876},{\"end\":53907,\"start\":53890},{\"end\":54177,\"start\":54164},{\"end\":54195,\"start\":54177},{\"end\":54205,\"start\":54195},{\"end\":54222,\"start\":54205},{\"end\":54233,\"start\":54222},{\"end\":54246,\"start\":54233},{\"end\":54473,\"start\":54459},{\"end\":54491,\"start\":54473},{\"end\":54503,\"start\":54491},{\"end\":54526,\"start\":54503},{\"end\":54539,\"start\":54526},{\"end\":54552,\"start\":54539},{\"end\":54568,\"start\":54552},{\"end\":54580,\"start\":54568},{\"end\":54598,\"start\":54580},{\"end\":54613,\"start\":54598},{\"end\":54627,\"start\":54613},{\"end\":54637,\"start\":54627},{\"end\":54647,\"start\":54637},{\"end\":54942,\"start\":54926},{\"end\":54958,\"start\":54942},{\"end\":54973,\"start\":54958},{\"end\":54990,\"start\":54973},{\"end\":55000,\"start\":54990},{\"end\":55010,\"start\":55000},{\"end\":55027,\"start\":55010},{\"end\":55045,\"start\":55027},{\"end\":55049,\"start\":55045},{\"end\":55440,\"start\":55422},{\"end\":55454,\"start\":55440},{\"end\":55474,\"start\":55454},{\"end\":55861,\"start\":55843},{\"end\":55880,\"start\":55861},{\"end\":55898,\"start\":55880},{\"end\":55912,\"start\":55898},{\"end\":55927,\"start\":55912},{\"end\":56268,\"start\":56254},{\"end\":56277,\"start\":56268},{\"end\":56287,\"start\":56277},{\"end\":56556,\"start\":56539},{\"end\":56572,\"start\":56556},{\"end\":56593,\"start\":56572},{\"end\":56610,\"start\":56593},{\"end\":56905,\"start\":56890},{\"end\":56918,\"start\":56905},{\"end\":56927,\"start\":56918},{\"end\":57232,\"start\":57210},{\"end\":57250,\"start\":57232},{\"end\":57268,\"start\":57250},{\"end\":57287,\"start\":57268},{\"end\":57303,\"start\":57287},{\"end\":57324,\"start\":57303},{\"end\":57639,\"start\":57630},{\"end\":57655,\"start\":57639},{\"end\":57672,\"start\":57655},{\"end\":57692,\"start\":57672},{\"end\":57699,\"start\":57692},{\"end\":57980,\"start\":57961},{\"end\":57993,\"start\":57980},{\"end\":58006,\"start\":57993},{\"end\":58022,\"start\":58006},{\"end\":58036,\"start\":58022},{\"end\":58358,\"start\":58349},{\"end\":58372,\"start\":58358},{\"end\":58388,\"start\":58372},{\"end\":58397,\"start\":58388},{\"end\":58402,\"start\":58397},{\"end\":58627,\"start\":58609},{\"end\":58882,\"start\":58871},{\"end\":59184,\"start\":59173},{\"end\":59444,\"start\":59425},{\"end\":59463,\"start\":59444},{\"end\":59477,\"start\":59463},{\"end\":59493,\"start\":59477},{\"end\":59501,\"start\":59493},{\"end\":59523,\"start\":59501},{\"end\":59918,\"start\":59905},{\"end\":59928,\"start\":59918},{\"end\":59938,\"start\":59928},{\"end\":59947,\"start\":59938},{\"end\":59957,\"start\":59947},{\"end\":59966,\"start\":59957},{\"end\":59975,\"start\":59966},{\"end\":60264,\"start\":60252},{\"end\":60283,\"start\":60264},{\"end\":60585,\"start\":60576},{\"end\":60596,\"start\":60585},{\"end\":60609,\"start\":60596},{\"end\":60842,\"start\":60832},{\"end\":60853,\"start\":60842},{\"end\":60865,\"start\":60853},{\"end\":60877,\"start\":60865},{\"end\":60890,\"start\":60877},{\"end\":61233,\"start\":61216},{\"end\":61237,\"start\":61233},{\"end\":61486,\"start\":61472},{\"end\":61497,\"start\":61486},{\"end\":61511,\"start\":61497},{\"end\":61524,\"start\":61511},{\"end\":61752,\"start\":61745},{\"end\":61760,\"start\":61752},{\"end\":61770,\"start\":61760},{\"end\":61779,\"start\":61770},{\"end\":61791,\"start\":61779},{\"end\":62040,\"start\":62028},{\"end\":62063,\"start\":62040},{\"end\":62080,\"start\":62063},{\"end\":62224,\"start\":62212},{\"end\":62245,\"start\":62224},{\"end\":62258,\"start\":62245},{\"end\":62271,\"start\":62258},{\"end\":62288,\"start\":62271},{\"end\":62302,\"start\":62288},{\"end\":62325,\"start\":62302},{\"end\":62619,\"start\":62610},{\"end\":62635,\"start\":62619},{\"end\":62640,\"start\":62635},{\"end\":62891,\"start\":62863},{\"end\":62905,\"start\":62891},{\"end\":62915,\"start\":62905},{\"end\":63197,\"start\":63179},{\"end\":63211,\"start\":63197},{\"end\":63222,\"start\":63211},{\"end\":63232,\"start\":63222},{\"end\":63421,\"start\":63409},{\"end\":63436,\"start\":63421},{\"end\":63453,\"start\":63436},{\"end\":63465,\"start\":63453},{\"end\":63483,\"start\":63465},{\"end\":63732,\"start\":63717},{\"end\":63751,\"start\":63732},{\"end\":63770,\"start\":63751},{\"end\":63787,\"start\":63770},{\"end\":63802,\"start\":63787},{\"end\":63816,\"start\":63802},{\"end\":63823,\"start\":63816},{\"end\":64122,\"start\":64108},{\"end\":64131,\"start\":64122},{\"end\":64144,\"start\":64131},{\"end\":64155,\"start\":64144},{\"end\":64163,\"start\":64155},{\"end\":64437,\"start\":64421},{\"end\":64455,\"start\":64437},{\"end\":64474,\"start\":64455},{\"end\":64495,\"start\":64474},{\"end\":64516,\"start\":64495},{\"end\":64532,\"start\":64516},{\"end\":64873,\"start\":64863},{\"end\":64886,\"start\":64873},{\"end\":64900,\"start\":64886},{\"end\":64913,\"start\":64900},{\"end\":64922,\"start\":64913},{\"end\":65246,\"start\":65234},{\"end\":65260,\"start\":65246},{\"end\":65273,\"start\":65260},{\"end\":65282,\"start\":65273},{\"end\":65472,\"start\":65463},{\"end\":65480,\"start\":65472},{\"end\":65492,\"start\":65480},{\"end\":65505,\"start\":65492},{\"end\":65514,\"start\":65505},{\"end\":65816,\"start\":65807},{\"end\":65828,\"start\":65816},{\"end\":65838,\"start\":65828},{\"end\":65852,\"start\":65838},{\"end\":65865,\"start\":65852},{\"end\":66184,\"start\":66170},{\"end\":66198,\"start\":66184},{\"end\":66208,\"start\":66198},{\"end\":66221,\"start\":66208},{\"end\":66230,\"start\":66221},{\"end\":66612,\"start\":66596},{\"end\":66625,\"start\":66612},{\"end\":66807,\"start\":66799},{\"end\":66830,\"start\":66807},{\"end\":67009,\"start\":66996},{\"end\":67266,\"start\":67254},{\"end\":67274,\"start\":67266},{\"end\":67284,\"start\":67274},{\"end\":67293,\"start\":67284},{\"end\":67306,\"start\":67293},{\"end\":67600,\"start\":67587},{\"end\":67613,\"start\":67600},{\"end\":67629,\"start\":67613},{\"end\":67640,\"start\":67629},{\"end\":67887,\"start\":67866},{\"end\":67897,\"start\":67887},{\"end\":68094,\"start\":68083},{\"end\":68106,\"start\":68094},{\"end\":68114,\"start\":68106},{\"end\":68324,\"start\":68301},{\"end\":68337,\"start\":68324},{\"end\":68353,\"start\":68337},{\"end\":68371,\"start\":68353},{\"end\":68382,\"start\":68371},{\"end\":68395,\"start\":68382},{\"end\":68410,\"start\":68395},{\"end\":68422,\"start\":68410},{\"end\":68427,\"start\":68422},{\"end\":68689,\"start\":68676},{\"end\":68700,\"start\":68689},{\"end\":68956,\"start\":68941},{\"end\":68964,\"start\":68956},{\"end\":69135,\"start\":69126},{\"end\":69145,\"start\":69135},{\"end\":69158,\"start\":69145},{\"end\":69169,\"start\":69158},{\"end\":69480,\"start\":69468},{\"end\":69489,\"start\":69480},{\"end\":69499,\"start\":69489},{\"end\":69508,\"start\":69499},{\"end\":69518,\"start\":69508},{\"end\":69864,\"start\":69852},{\"end\":69880,\"start\":69864},{\"end\":69892,\"start\":69880},{\"end\":70132,\"start\":70113},{\"end\":70141,\"start\":70132},{\"end\":70155,\"start\":70141},{\"end\":70172,\"start\":70155},{\"end\":70184,\"start\":70172},{\"end\":70203,\"start\":70184},{\"end\":70218,\"start\":70203},{\"end\":70237,\"start\":70218},{\"end\":70256,\"start\":70237},{\"end\":70509,\"start\":70497},{\"end\":70526,\"start\":70509},{\"end\":70544,\"start\":70526},{\"end\":70558,\"start\":70544},{\"end\":70956,\"start\":70937},{\"end\":70968,\"start\":70956},{\"end\":70985,\"start\":70968},{\"end\":71005,\"start\":70985},{\"end\":71022,\"start\":71005},{\"end\":71373,\"start\":71360},{\"end\":71382,\"start\":71373},{\"end\":71399,\"start\":71382},{\"end\":71414,\"start\":71399},{\"end\":71431,\"start\":71414},{\"end\":71439,\"start\":71431},{\"end\":71737,\"start\":71728},{\"end\":71761,\"start\":71737},{\"end\":71778,\"start\":71761},{\"end\":71792,\"start\":71778},{\"end\":71811,\"start\":71792},{\"end\":71830,\"start\":71811},{\"end\":71843,\"start\":71830},{\"end\":72176,\"start\":72162},{\"end\":72185,\"start\":72176},{\"end\":72202,\"start\":72185},{\"end\":72213,\"start\":72202},{\"end\":72225,\"start\":72213},{\"end\":72241,\"start\":72225},{\"end\":72826,\"start\":72816},{\"end\":72835,\"start\":72826},{\"end\":72850,\"start\":72835},{\"end\":72861,\"start\":72850},{\"end\":73167,\"start\":73155},{\"end\":73179,\"start\":73167},{\"end\":73191,\"start\":73179},{\"end\":73209,\"start\":73191},{\"end\":73219,\"start\":73209},{\"end\":73233,\"start\":73219},{\"end\":73253,\"start\":73233},{\"end\":73623,\"start\":73610},{\"end\":73643,\"start\":73623},{\"end\":73652,\"start\":73643},{\"end\":73673,\"start\":73652},{\"end\":73946,\"start\":73936},{\"end\":73960,\"start\":73946},{\"end\":74139,\"start\":74132},{\"end\":74150,\"start\":74139},{\"end\":74160,\"start\":74150},{\"end\":74335,\"start\":74328},{\"end\":74346,\"start\":74335},{\"end\":74356,\"start\":74346},{\"end\":74366,\"start\":74356},{\"end\":74574,\"start\":74562},{\"end\":74587,\"start\":74574},{\"end\":74601,\"start\":74587},{\"end\":74614,\"start\":74601},{\"end\":74930,\"start\":74913},{\"end\":74946,\"start\":74930},{\"end\":74965,\"start\":74946},{\"end\":75269,\"start\":75254},{\"end\":75284,\"start\":75269},{\"end\":75299,\"start\":75284},{\"end\":75322,\"start\":75299},{\"end\":75596,\"start\":75586},{\"end\":75615,\"start\":75596},{\"end\":75630,\"start\":75615},{\"end\":75642,\"start\":75630},{\"end\":75656,\"start\":75642},{\"end\":75673,\"start\":75656},{\"end\":75686,\"start\":75673},{\"end\":76028,\"start\":76022},{\"end\":76124,\"start\":76111},{\"end\":76139,\"start\":76124},{\"end\":76156,\"start\":76139},{\"end\":76169,\"start\":76156},{\"end\":76181,\"start\":76169},{\"end\":76502,\"start\":76489},{\"end\":76514,\"start\":76502},{\"end\":76531,\"start\":76514},{\"end\":76543,\"start\":76531},{\"end\":76562,\"start\":76543},{\"end\":76578,\"start\":76562},{\"end\":76593,\"start\":76578},{\"end\":76606,\"start\":76593},{\"end\":76621,\"start\":76606},{\"end\":76634,\"start\":76621},{\"end\":76650,\"start\":76634},{\"end\":76664,\"start\":76650},{\"end\":76674,\"start\":76664},{\"end\":77091,\"start\":77075},{\"end\":77107,\"start\":77091},{\"end\":77124,\"start\":77107},{\"end\":77139,\"start\":77124},{\"end\":77152,\"start\":77139},{\"end\":77411,\"start\":77401},{\"end\":77422,\"start\":77411},{\"end\":77429,\"start\":77422},{\"end\":77853,\"start\":77837},{\"end\":77870,\"start\":77853},{\"end\":77888,\"start\":77870},{\"end\":77900,\"start\":77888},{\"end\":77918,\"start\":77900},{\"end\":77935,\"start\":77918},{\"end\":77951,\"start\":77935},{\"end\":77964,\"start\":77951},{\"end\":77977,\"start\":77964},{\"end\":77986,\"start\":77977},{\"end\":77999,\"start\":77986},{\"end\":78013,\"start\":77999},{\"end\":78026,\"start\":78013},{\"end\":78043,\"start\":78026},{\"end\":78058,\"start\":78043},{\"end\":78073,\"start\":78058},{\"end\":78085,\"start\":78073},{\"end\":78100,\"start\":78085},{\"end\":78110,\"start\":78100},{\"end\":78720,\"start\":78705},{\"end\":78740,\"start\":78720},{\"end\":78756,\"start\":78740},{\"end\":78776,\"start\":78756},{\"end\":78787,\"start\":78776},{\"end\":79049,\"start\":79041},{\"end\":79060,\"start\":79049},{\"end\":79313,\"start\":79297},{\"end\":79330,\"start\":79313},{\"end\":79348,\"start\":79330},{\"end\":79366,\"start\":79348},{\"end\":79380,\"start\":79366},{\"end\":79402,\"start\":79380},{\"end\":79664,\"start\":79647},{\"end\":79679,\"start\":79664},{\"end\":79892,\"start\":79879},{\"end\":79907,\"start\":79892},{\"end\":79923,\"start\":79907},{\"end\":80167,\"start\":80153},{\"end\":80183,\"start\":80167},{\"end\":80195,\"start\":80183},{\"end\":80207,\"start\":80195},{\"end\":80226,\"start\":80207},{\"end\":80246,\"start\":80226},{\"end\":80262,\"start\":80246},{\"end\":80557,\"start\":80536},{\"end\":80569,\"start\":80557},{\"end\":80579,\"start\":80569},{\"end\":80808,\"start\":80782},{\"end\":80828,\"start\":80808},{\"end\":80841,\"start\":80828},{\"end\":80860,\"start\":80841},{\"end\":81108,\"start\":81093},{\"end\":81123,\"start\":81108},{\"end\":81136,\"start\":81123},{\"end\":81147,\"start\":81136},{\"end\":81161,\"start\":81147},{\"end\":81180,\"start\":81161},{\"end\":81185,\"start\":81180},{\"end\":81660,\"start\":81647},{\"end\":81675,\"start\":81660},{\"end\":82102,\"start\":82095},{\"end\":82114,\"start\":82102},{\"end\":82122,\"start\":82114},{\"end\":82336,\"start\":82327},{\"end\":82357,\"start\":82336},{\"end\":82612,\"start\":82602},{\"end\":82631,\"start\":82612},{\"end\":82646,\"start\":82631},{\"end\":82658,\"start\":82646},{\"end\":82672,\"start\":82658},{\"end\":82689,\"start\":82672},{\"end\":82702,\"start\":82689},{\"end\":83112,\"start\":83101},{\"end\":83124,\"start\":83112},{\"end\":83133,\"start\":83124},{\"end\":83142,\"start\":83133},{\"end\":83150,\"start\":83142},{\"end\":83161,\"start\":83150},{\"end\":83174,\"start\":83161},{\"end\":83186,\"start\":83174},{\"end\":83200,\"start\":83186},{\"end\":83214,\"start\":83200},{\"end\":83588,\"start\":83575},{\"end\":83602,\"start\":83588},{\"end\":83620,\"start\":83602},{\"end\":83641,\"start\":83620},{\"end\":83651,\"start\":83641},{\"end\":83658,\"start\":83651},{\"end\":83955,\"start\":83943},{\"end\":83968,\"start\":83955},{\"end\":84140,\"start\":84125},{\"end\":84153,\"start\":84140},{\"end\":84168,\"start\":84153},{\"end\":84183,\"start\":84168},{\"end\":84367,\"start\":84348},{\"end\":84379,\"start\":84367},{\"end\":84399,\"start\":84379},{\"end\":84426,\"start\":84399},{\"end\":84441,\"start\":84426},{\"end\":84453,\"start\":84441},{\"end\":84470,\"start\":84453},{\"end\":84489,\"start\":84470},{\"end\":84508,\"start\":84489},{\"end\":84525,\"start\":84508},{\"end\":84534,\"start\":84525},{\"end\":84552,\"start\":84534},{\"end\":85096,\"start\":85063},{\"end\":85112,\"start\":85096},{\"end\":85129,\"start\":85112},{\"end\":85144,\"start\":85129},{\"end\":85158,\"start\":85144},{\"end\":85181,\"start\":85158},{\"end\":85202,\"start\":85181},{\"end\":85216,\"start\":85202},{\"end\":85224,\"start\":85216},{\"end\":85238,\"start\":85224},{\"end\":85244,\"start\":85238},{\"end\":85646,\"start\":85628},{\"end\":85661,\"start\":85646},{\"end\":85676,\"start\":85661},{\"end\":85980,\"start\":85960},{\"end\":85997,\"start\":85980},{\"end\":86015,\"start\":85997},{\"end\":86031,\"start\":86015},{\"end\":86050,\"start\":86031},{\"end\":86471,\"start\":86456},{\"end\":86490,\"start\":86471},{\"end\":86504,\"start\":86490},{\"end\":86523,\"start\":86504},{\"end\":86976,\"start\":86960},{\"end\":86990,\"start\":86976},{\"end\":87389,\"start\":87378},{\"end\":87404,\"start\":87389},{\"end\":87417,\"start\":87404},{\"end\":87710,\"start\":87691},{\"end\":87724,\"start\":87710},{\"end\":87741,\"start\":87724},{\"end\":87758,\"start\":87741},{\"end\":87776,\"start\":87758},{\"end\":87785,\"start\":87776},{\"end\":87808,\"start\":87785},{\"end\":87824,\"start\":87808},{\"end\":87842,\"start\":87824},{\"end\":87852,\"start\":87842},{\"end\":88269,\"start\":88257},{\"end\":88278,\"start\":88269},{\"end\":88288,\"start\":88278},{\"end\":88299,\"start\":88288},{\"end\":88309,\"start\":88299},{\"end\":88324,\"start\":88309},{\"end\":88587,\"start\":88570},{\"end\":88599,\"start\":88587},{\"end\":88608,\"start\":88599},{\"end\":88621,\"start\":88608},{\"end\":88630,\"start\":88621},{\"end\":88637,\"start\":88630},{\"end\":88646,\"start\":88637},{\"end\":88963,\"start\":88945},{\"end\":88978,\"start\":88963},{\"end\":88989,\"start\":88978},{\"end\":89172,\"start\":89148},{\"end\":89190,\"start\":89172},{\"end\":89212,\"start\":89190},{\"end\":89230,\"start\":89212},{\"end\":89251,\"start\":89230},{\"end\":89263,\"start\":89251},{\"end\":89512,\"start\":89503},{\"end\":89531,\"start\":89512},{\"end\":89549,\"start\":89531},{\"end\":89564,\"start\":89549},{\"end\":89581,\"start\":89564},{\"end\":89596,\"start\":89581},{\"end\":89620,\"start\":89596},{\"end\":89638,\"start\":89620},{\"end\":89655,\"start\":89638},{\"end\":89671,\"start\":89655},{\"end\":89685,\"start\":89671},{\"end\":89696,\"start\":89685},{\"end\":89713,\"start\":89696},{\"end\":90023,\"start\":90011},{\"end\":90046,\"start\":90023},{\"end\":90063,\"start\":90046},{\"end\":90297,\"start\":90287},{\"end\":90312,\"start\":90297},{\"end\":90324,\"start\":90312},{\"end\":90332,\"start\":90324},{\"end\":90341,\"start\":90332}]", "bib_venue": "[{\"end\":72424,\"start\":72341},{\"end\":77554,\"start\":77500},{\"end\":53027,\"start\":53010},{\"end\":53241,\"start\":53178},{\"end\":53594,\"start\":53543},{\"end\":53917,\"start\":53907},{\"end\":54162,\"start\":54091},{\"end\":54924,\"start\":54837},{\"end\":55524,\"start\":55474},{\"end\":55841,\"start\":55730},{\"end\":56252,\"start\":56192},{\"end\":56537,\"start\":56450},{\"end\":56976,\"start\":56927},{\"end\":57345,\"start\":57324},{\"end\":57722,\"start\":57699},{\"end\":57959,\"start\":57891},{\"end\":58415,\"start\":58402},{\"end\":58607,\"start\":58571},{\"end\":58915,\"start\":58882},{\"end\":59199,\"start\":59184},{\"end\":59563,\"start\":59523},{\"end\":59993,\"start\":59975},{\"end\":60250,\"start\":60187},{\"end\":60574,\"start\":60473},{\"end\":60966,\"start\":60890},{\"end\":61214,\"start\":61200},{\"end\":61572,\"start\":61524},{\"end\":61870,\"start\":61791},{\"end\":62677,\"start\":62640},{\"end\":62861,\"start\":62817},{\"end\":63177,\"start\":63133},{\"end\":63407,\"start\":63353},{\"end\":63715,\"start\":63635},{\"end\":64106,\"start\":64034},{\"end\":64540,\"start\":64532},{\"end\":64861,\"start\":64777},{\"end\":65232,\"start\":65166},{\"end\":65556,\"start\":65514},{\"end\":65805,\"start\":65720},{\"end\":66302,\"start\":66230},{\"end\":66594,\"start\":66525},{\"end\":66797,\"start\":66749},{\"end\":67018,\"start\":67009},{\"end\":67252,\"start\":67208},{\"end\":67585,\"start\":67515},{\"end\":67864,\"start\":67792},{\"end\":68135,\"start\":68114},{\"end\":68299,\"start\":68260},{\"end\":68674,\"start\":68616},{\"end\":68939,\"start\":68879},{\"end\":69124,\"start\":69073},{\"end\":69466,\"start\":69410},{\"end\":69850,\"start\":69725},{\"end\":70111,\"start\":70081},{\"end\":70656,\"start\":70558},{\"end\":71055,\"start\":71022},{\"end\":71472,\"start\":71439},{\"end\":71726,\"start\":71685},{\"end\":72339,\"start\":72241},{\"end\":72893,\"start\":72861},{\"end\":73265,\"start\":73253},{\"end\":73608,\"start\":73506},{\"end\":73934,\"start\":73907},{\"end\":74163,\"start\":74160},{\"end\":74369,\"start\":74366},{\"end\":74560,\"start\":74490},{\"end\":74983,\"start\":74965},{\"end\":75359,\"start\":75322},{\"end\":75790,\"start\":75686},{\"end\":76109,\"start\":76060},{\"end\":76680,\"start\":76674},{\"end\":77073,\"start\":76993},{\"end\":77498,\"start\":77429},{\"end\":78115,\"start\":78110},{\"end\":78793,\"start\":78787},{\"end\":79039,\"start\":78971},{\"end\":79295,\"start\":79245},{\"end\":79688,\"start\":79679},{\"end\":79929,\"start\":79923},{\"end\":80272,\"start\":80262},{\"end\":80534,\"start\":80495},{\"end\":80780,\"start\":80730},{\"end\":81287,\"start\":81185},{\"end\":81777,\"start\":81675},{\"end\":82093,\"start\":81993},{\"end\":82429,\"start\":82357},{\"end\":82806,\"start\":82702},{\"end\":83243,\"start\":83214},{\"end\":83573,\"start\":83466},{\"end\":83995,\"start\":83968},{\"end\":84218,\"start\":84183},{\"end\":84633,\"start\":84552},{\"end\":85061,\"start\":84960},{\"end\":85626,\"start\":85557},{\"end\":86085,\"start\":86050},{\"end\":86563,\"start\":86523},{\"end\":87022,\"start\":86990},{\"end\":87457,\"start\":87417},{\"end\":87918,\"start\":87852},{\"end\":88255,\"start\":88182},{\"end\":88568,\"start\":88495},{\"end\":88943,\"start\":88899},{\"end\":89501,\"start\":89444},{\"end\":90285,\"start\":90193}]"}}}, "year": 2023, "month": 12, "day": 17}