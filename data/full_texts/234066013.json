{"id": 234066013, "updated": "2023-07-22 23:04:29.163", "metadata": {"title": "From TTP to IoC: Advanced Persistent Graphs for Threat Hunting", "authors": "[{\"first\":\"Aimad\",\"last\":\"Berady\",\"middle\":[]},{\"first\":\"Mathieu\",\"last\":\"Jaume\",\"middle\":[]},{\"first\":\"Val\u00e9rie\",\"last\":\"Tong\",\"middle\":[\"Viet\",\"Triem\"]},{\"first\":\"Gilles\",\"last\":\"Guette\",\"middle\":[]}]", "venue": "IEEE Transactions on Network and Service Management", "journal": "IEEE Transactions on Network and Service Management", "publication_date": {"year": 2021, "month": 6, "day": 1}, "abstract": "Defenders fighting against Advanced Persistent Threats need to discover the propagation area of an adversary as quickly as possible. This discovery takes place through a phase of an incident response operation called Threat Hunting, where defenders track down attackers within the compromised network. In this article, we propose a formal model that dissects and abstracts elements of an attack, from both attacker and defender perspectives. This model leads to the construction of two persistent graphs on a common set of objects and components allowing for (1) an omniscient actor to compare, for both defender and attacker, the gap in knowledge and perceptions; (2) the attacker to become aware of the traces left on the targeted network; (3) the defender to improve the quality of Threat Hunting by identifying false-positives and adapting logging policy to be oriented for investigations. In this article, we challenge this model using an attack campaign mimicking APT29, a real-world threat, in a scenario designed by the MITRE Corporation. We measure the quality of the defensive architecture experimentally and then determine the most effective strategy to exploit data collected by the defender in order to extract actionable Cyber Threat Intelligence, and finally unveil the attacker.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3128070938", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tnsm/BeradyJTG21", "doi": "10.1109/tnsm.2021.3056999"}}, "content": {"source": {"pdf_hash": "a101849c0300223aac63f06bac80792f34a4cade", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://hal.inria.fr/hal-03131262/file/Final%20version%20TNSM%20-%20From%20TTP%20to%20IoC%20-%20Advanced%20Persistent%20Graphs%20for%20Threat%20Hunting.pdf", "status": "GREEN"}}, "grobid": {"id": "6d27419ced79870fdaf12ff40db278fdf67ed9ca", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a101849c0300223aac63f06bac80792f34a4cade.txt", "contents": "\nFrom TTP to IoC: Advanced Persistent Graphs for Threat Hunting\nJUNE 2021\n\nAimad Berady \nMathieu Jaume \nVal\u00e9rie Viet \nTriem Tong \nGilles Guette \nFrom TTP to IoC: Advanced Persistent Graphs for Threat Hunting\n\nIEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT\n1821321JUNE 202110.1109/TNSM.2021.3056999Index Terms-Advanced persistent threattactics techniques proceduresthreat huntingIOCSIEM\nDefenders fighting against Advanced Persistent Threats need to discover the propagation area of an adversary as quickly as possible. This discovery takes place through a phase of an incident response operation called Threat Hunting, where defenders track down attackers within the compromised network. In this article, we propose a formal model that dissects and abstracts elements of an attack, from both attacker and defender perspectives. This model leads to the construction of two persistent graphs on a common set of objects and components allowing for (1) an omniscient actor to compare, for both defender and attacker, the gap in knowledge and perceptions;(2) the attacker to become aware of the traces left on the targeted network; (3) the defender to improve the quality of Threat Hunting by identifying false-positives and adapting logging policy to be oriented for investigations. In this article, we challenge this model using an attack campaign mimicking APT29, a real-world threat, in a scenario designed by the MITRE Corporation. We measure the quality of the defensive architecture experimentally and then determine the most effective strategy to exploit data collected by the defender in order to extract actionable Cyber Threat Intelligence, and finally unveil the attacker.\n\nmaneuvers whose objectives are to test the soldier readiness and attack effectiveness through simulations. In cybersecurity, these exercises help organizations keep their assets safe. The Red Team is composed of highly trained individuals playing the role of potential attackers motivated by a strategic objective (e.g., stealing sensitive information, using organizations' capabilities for malicious purposes, defeating the availability of victim's services). The Blue Team defends the company, and has to ensure that its assets are not compromised, in the event of the Red Team finding a vulnerability and exploiting it. The Blue Team thus needs to rapidly remediate the incident to control the Red Team's network propagation and contain the threat. To estimate the effectiveness of their respective games, we can naively measure the time it took the Red Team to dominate the target and the time it took the Blue Team to detect and respond to the attack. We believe that this measure would be greatly improved with knowledge of the compromised components, by the Red Team, from the victim's network (i.e., its propagation area) and how aware the Blue Team was of this.\n\nIn this article, we formalize both defensive processes and the attacker's offensive approaches, allowing for confronting their respective perceptions during the same attack campaign. The attacker's perception of the campaign is built from (1) the execution of his procedures chosen from among his Tactics, Techniques and Procedures (TTP) [2]; (2) his exposed resources during these executions; and (3) the victim's components he compromised. The defender's perception of the attack is built from (1) the collected traces on the targeted information system; and (2) the exploitation of these traces through his defensive procedures. The benefits of the proposed model are twofold. First of all, it provides a high-level representation of the attack campaign, allowing to quickly assess the attacker and defender progressions. This representation can also be used by an omniscient third party to measure the success of a Red versus Blue exercise. Second, the model highlights how the defender can improve the efficiency of his detection process by tweaking the input (configurations and rules) of some of his defensive procedures. Here, we conduct an experiment with our model, using an attack campaign issued from the public project Mordor [3]. This attack campaign mimics the real-world threat APT29 in a scenario designed by MITRE for the purposes of ATT&CK Evaluations [4]. The confrontation of these two perceptions allows us to define a metric to estimate the deployed detection chain efficiency.\n\nThis article is structured as follows. Section II provides an overview of the concepts manipulated in the model. Sections III and IV present respectively the attacker and the defender's perspectives. Section V details the experiment architecture and specifies requirements for integration in existing infrastructures. Section VI discusses how to evaluate the efficiency of the detection chain and how to enhance it.\n\n\nII. OVERVIEW\n\nThis article formalizes the Threat Hunting process conducted by an incident response team, towards ultimately evaluating the efficiency of a detection chain. We start our process with the attacker's point of view; the attacker has initiative and sets the tempo.\n\nWe begin by specifying the scope of this study and explaining the terms we will use in the rest of this article. Thus, this section successively details the infrastructure under consideration, the attacker's scope, and then the defender's scope before outlining how we will be able to compare their two points of view with the help of two graphs.\n\n\nA. The Infrastructure\n\nThe targeted network is the information system hosting the attacker's final objective. In this network, we distinguish the components from the objects. The components are assets (i.e., machines) with logging capabilities over which the defender has full control, such as computers, servers, or appliances. The objects are measurable events or stateful properties relative to malware characterization, intrusion detection, incident response or digital forensics. These objects correspond to the observable objects defined in the STIX standard [5]. Each object plays a precise role in the context of an event. This role specifies the function that the object holds in the event. The set of possible roles is here denoted by R. Each role r is associated with a unique type that specifies the nature of any object playing this role. By denoting T the set of possible types, the type associated with a role is defined through the function \u03c4 : R \u2192 T.\n\nFor our implementation, we used the MITRE Cyber Analytics Repository (CAR) [6] data model to name objects' roles. An object can play different roles associated with different types. For example, the object maliciousfile.com can hold the role destination hostname with the type domain, the role file name, or even the role executable with the type file. The three columns on the left of the Table I  Although the attacker also has his own machines, which could be components, in this model, we only consider the victim's components since those of the attacker cannot be reached by the defender, in a strictly defensive posture. Nevertheless, the defender may have an insight into some of the attacker's objects (e.g., a domain name, a hash value, an IP) because the attacker would have exposed them. The attacker will, however, be able to discover and gain access to part of the victim's components through objects. For these reasons, this article highlights only the set of components of the targeted network, refering to it as C. We denote by O D the set of objects relative to the victim (some of them related to components of C), by O A the set of objects relative to the attacker and by O the set\nO D \u222a O A .\n\nB. The Attacker Scope\n\nThe attacker can be an individual, a group, or a Red Team, but for the sake of clarity, we simply refer here to the attacker. In the same way, the presence of multiple attackers in the victim's network is not an obstacle because the ambition of this model is to provide a more exhaustive view of the compromised components. The attacker is at the initiative of the attack campaign and has his own components at his disposal, which is part of his infrastructure. He also owns a collection of attack procedures (denoted TTP A ) often related to techniques described in the MITRE ATT&CK matrix. These procedures may be parameterized by objects from O D as well as objects from O A . These procedures are executed on components in the targeted network (in C) only if the attacker has already discovered these components. The attacker scope is completely formalized in Section III.\n\n\nC. The Defender Scope\n\nThe defender can be the victim itself, the security team of a company, an external security team, or a Blue Team. For the same reasons, we simply refer here to the defender. The defender has defensive procedures to cope with an attack campaign. The defender only observes the events occurring on components in C that he has chosen to monitor. The relevant events to be monitored by sensors are specified in their configuration S. The defensive procedure p logs allows him to generate traces from events that occur on these components. The defensive procedure p hunting exploits these traces in an attempt to identify in C the components compromised by the attacker. The defender scope is formalized in Section IV.\n\n\nD. Confronting Perspectives\n\nWe propose here to represent the attacker network propagation during an attack campaign by a persistent graph G A between objects and components. This graph will be computed from the sequence of attack procedures and the involved objects. These objects represent characteristic information that the attacker cannot conceal and is aware of exposing.\n\nSimilarly, we represent the defender perception of the attacker's propagation by a second persistent graph G D . This graph computation relies on the defensive procedures executed by the defender. Figure 1 gives a global overview of this process, including the attacker and the defender scopes.\n\nThe knowledge of the attacker and the defender of the targeted network are enriched by their own directory. For both the attacker and the defender, their directory determines how an object with a given type is relative to a component from his own perspective. In the following, D A will be the attacker directory and D the defender directory. Both D A and D are possibly imperfect or incomplete; they are here represented by two functions from T \u00d7 O D to C \u222a{None}. When the attacker (resp. the defender) has no information concerning an object   For example, the defender may know that a machine has a given IP address, is a Web server, owns files, and has a name, while the attacker only knows the IP address of this machine. In the Table I example, the two right columns show if an object with a specific type is related to a component using the attacker and the defender directory.\n\nIn the following, Section V explains how the comparison of G A and G D allows confronting the perceptions of the attack campaign from both points of view: that of the attacker and that of the defender. We also show how the Threat Hunting operation can be greatly improved by increasing the quality of Indicators of Compromise (IoC) and Events of Interest (EoI) used by the defender.\n\n\nE. Experiment: APT29 Simulated Campaign\n\nIn the context of cybersecurity product evaluations, MITRE creates attack scenarios inspired by real-world threats. Two of them concern the so-called APT29, which is a statesponsored attackers group that has been active since 2008. During these attacks, the attacker used different procedures to collect and exfiltrate sensitive files from the targeted network after exploring it. These two scenarios detail the steps of an APT campaign using the threat actor's TTPs as they were observed by the infosec community. Subsequently, Roberto Rodriguez [3] was at the initiative of a dataset of logs recorded on an infrastructure allowing the procedure execution from scenarios. We decide to merge these two scenarios because of their similarities in targeting the same infrastructure and the fact that they mimic the same APT actor. Among the traces in the dataset, we focused on those coming from the Sysmon sensor, which is the one recommended according to state of the art [7]. Experimentation infrastructure is detailed in Section V, and the results of this experiment are discussed in Section VI.\n\n\nIII. ATTACKER'S PERSPECTIVE\n\nThe attacker is modeled through a graph of objects and components. The components belong to the targeted network, with which the attacker interacts while executing an offensive procedure. The objects represent the traces that the attacker is aware of leaving on the target infrastructure while executing these procedures. This section details the construction of this graph by taking into account both actions, which define the whole attack campaign, and progression of the attacker's knowledge about the targeted network.\n\n\nA. Actions of the Attacker\n\nAn attack campaign A is composed of a sequence e 1 , . . . , e N of executions of N attack procedures p 1 , . . . , p N on components in C of the targeted network. We assume here that the attacker knows at least one initial component of the targeted network. This component could have been discovered by the attacker through an external reconnaissance of the exposed services provided by the targeted network or even by a social engineering attack. When the attacker has compromised at least one component of the targeted network, he is able to apply attack procedures inside it. Here begins the Network Propagation phase [8].\n\nThe execution e of an attack procedure p \u2208 TTP A requires the knowledge of:\n\n\u2022 A Machine M(e): a component c \u2208 C named through a relative object o and a type t occurring in its directory D A where the procedure will be executed (thus c = D A (t, o)). This machine is typically the host where the procedure will be executed, satisfying a technical intention (also known as Tactic) such as Privilege Escalation, Discovery or even Persistence; Listing 1 gives the example of an attack procedure commonly used by the attacker. This procedure performs a lateral movement using psexec. It allows the attacker to execute a command-line process on a remote machine and redirect console applications output to its local system. In this example, the host component for the main procedure is SCRANTON.dmevals.local, the component for the sub-procedure is NASHUA.dmevals.local. The attacker launches the malware file named python.exe remotely, with the user's privileges of pbeesly on both sides.\n\n\nB. Attacker Propagation in the Targeted Network From the Attacker Point of View\n\nWe represent here the attacker propagation by a graph whose nodes are the objects involved in the attack campaign and their potential relative components from the attacker perspective. Each execution of an attack procedure requires the attacker to use objects and components either from his own resources or objects and components he has already discovered in the targeted network. In this model, we consider that the attacker's knowledge about the targeted network is frozen and already fully described through his directory D A . If we wanted to make this directory dynamic, it is necessary to formalize a Discovery procedure that allows the attacker to improve his knowledge of the targeted network infrastructure.\n\n\n1) Small\n\nStep Propagation: From each execution e of an attack procedure p, we build an oriented graph G(e), whose nodes are the objects and their relative components involved in this execution referenced by the attacker's directory. This graph represents one step of his attack campaign. Formally,\nG(e) is defined for e = (id e , p, (o, t), ((o 1 , r 1 ), . . . , (o n , r n )), (e 1 , . . . , e m )) by: G(e) = (V e , \u2192 e ) \u2295 m i=1 G(e i )\nand computed from:\n\n\u2022 the nodes V e , which are the host component, all the objects used in the procedure execution, and their potential relative components known by the attacker:\n{M(e), o 1 , . . . , o n } \u222a c = D A (\u03c4 (r i ), o i ) = None\n\u2022 the edges \u2192 e connecting the host component with parameters (objects) and the components linked to these objects according to the attacker's directory:\nn i=1 M(e) ide,r i \u2212 \u2212\u2212 \u2192 o i \u222a o i ref \u2212 \u2212 \u2192 c | c = D A (\u03c4 (r i ), o i ) = None\n\u2022 and the union of graphs m i=1 G(e i ) issued from subprocedures called during e. The operator \u2295 denotes here the classical union between two graphs. Figure 2 presents graph G(psexec) computed from the specific psexec attack procedure execution as previously described in Listing 1. In this graph, dark blue nodes are components and light blue nodes are objects. The labels on thin black edges define the object role in the procedure. The thick green edges define objects that are related to another component according to the attacker directory. Given that a Lateral Movement procedure, by definition, involves two components, both are represented on the graph, connected by \"ref\" edges.\n\n2) Big Step Propagation: Finally, an attack campaign A composed of executions e 1 , . . . , e N can be modeled by the  graph G A (A) resulting from the union of all the graphs associated with each execution:\nG A (A) = N i=1 G(e i ).\nThe computation of this graph allows the attacker to represent all the objects he exposes during his attack campaign. This graph can be seen as an attack footprint exposed to a defender. Moreover, in a Red versus Blue exercise, this graph allows an omniscient team (i.e., the White Team) to measure the distance between what the Blue Team has actually found and the attacker's actual footprint. Figure 3 presents the graph G A computed by the attacker during the APT29 simulated campaign in 49 steps corresponding to execution procedures, 4 compromised components SCRANTON, NASHUA, NEWYORK and UTICA, which are the four on which the attacker actually executed procedures during the attack campaign. Those 4 components are also defined in his directory.\n\n\nIV. DEFENDER'S PERSPECTIVE\n\nWe consider the same attack campaign but now from the defender's perspective. The defender is never considered to have initiative. The aim of the defender is to compute a representation of the attacker propagation in the targeted network from his (the defender's) point of view. In other words, his goal is to compute a graph of objects and components that are as similar as possible to the one produced by the attacker on his side. To this end, the defender uses his own defensive procedures. The semantic framework proposed in this article allows for generalizing offensive or defensive procedures. We specify that we have already identified several other tactics that would be generalizable. These include, for example, p discovery , which consists for the attacker to browse a namespace to discover new components.\n\nIn the following, we describe two main defensive procedures: p logs and p hunting , which must be implemented by the defender to conduct incident response operations. Attack campaigns against the targeted network generate events on its components. We represent an event ev by a tuple ( , c, O) where \u2208 E denotes the type of ev (with E the set of event types that can be observed), c \u2208 C is the component over which the event is observed,\nand O = {(o 1 , r 1 ), . . . , (o m , r m )} \u2286 O\u00d7R\ncontains all the objects involved in this event associated with their role from the defender's point of view.\n\nDepending on the configuration of sensors, events can gen-\nerate traces. A trace x is a tuple (id x , t, , c, O)\nwhere id x is the trace identifier, t is a timestamp, \u2208 E is the type of events causing this trace, c \u2208 C is the component where the event causing this trace has been observed and O are all the objects together with their roles involved in this trace. A single object can assume several roles in a single event and therefore appears several times in the O set. In contrast, each role is unique within the same trace.\n\nIn a Threat Hunting process, the defender can influence the quality of his results on three aspects: sensor configuration, detection rules, and his IoC database.\n\nFirst, the defender decides through his defensive procedure p logs which components on the targeted network are monitored by sensors and which events produce traces that will be forwarded to the Security Information Event Management (SIEM). This procedure, detailed in Section IV-A, will generate a huge number of traces allowing the defender to identify the traces relative to the attacker's activity.\n\nThe second defensive procedure called p hunting , detailed in Section IV-B, exploits those traces.\n\n\nA. Targeted Network Monitoring\n\nTechnically, the defender is able to monitor almost any event occurring on the targeted network's components. Nevertheless, many of these events tend to be irrelevant from a security point of view and may generate too many false-positives in a SIEM alerting system.\n\nAs the traces raised by the sensors are the only way for the defender to perceive a part of the attacker's activity, the defender has to pay very close attention to the configuration S of sensors. The more meaningful a trace is, the more valuable it is to the defender.\n\nWe assume here that all components can be observed, and their monitoring is configured by a sensor configuration S. In this configuration, the defender defines the relevant event types for each component c \u2208 C, which need to be traced and filtered on objects according to their roles. The configuration S(c) makes it possible to monitor the component c. The configuration is defined by a set of tuple ( , \u03c6, R ) where \u2208 E Listing 2. Sysmon Sensor Configuration Example, Part of a p logs Procedure. is the event type raised by the sensor when the condition \u03c6 holds true. \u03c6 expresses properties on the objects involved in the observed event ( , c, O) and their corresponding roles. We write O |= \u03c6 when objects in O satisfy condition \u03c6. The syntax of \u03c6 and satisfaction relation |= are defined in the Appendix.\n\nR \u2286 R contains the roles considered to be relevant to this type of event. Objects with one of these roles could be exploited in a Threat Hunting approach because of their searchability. For example, the string 10.0.1.4 (the object) with the role dest_ip and the observable type IP address can be searched in the logs.\n\nListing 2 presents the part of a Sysmon configuration. Sysmon is Windows service that monitors and logs system activity. In this example, the monitored component is the machine running on Windows; the condition \u03c6 expresses that Sysmon will generate ProcessCreate traces for all the Process creation events, except if the command line is exactly \\SystemRoot\\System32\\smss.exe (falsepositives are frequently generated, possibly due to legitimate command line). Moreover, this Sysmon instance will generate NetworkConnect traces for all images (i.e., PE binary files) stored in C:\\Windows\\Temp filesystem folder. Table II gives examples of relevant roles R for these two event types. As a model of system-level events, we use the MITRE Cyber Analytics Repository (CAR) [6].\n\nFinding an adapted sensor configuration is very tricky because the defender has to find an optimal position between logging every single observed event and defining highly restrictive conditions (including specific or excluding generic objects). The first option will generate too many traces and risks producing many false-positives. The second option will rarely be positively satisfied and thus will produce a very few numbers of traces, which will lead the defender to misjudge the threat.\n\nFinally, the defender's defensive procedure determines the monitored events and the reported traces in the procedure p logs . This procedure is parameterized by S that specifies the configurations associated with components and by E a set of events that occurred on the components. p logs generates a set of traces X c for each component c:\n\nListing 3 is an example of a trace raised by Sysmon sensor. It happens because the configuration in Listing 2 observed a Network Connection event for which the object with the role Image (i.e., executable file name) matched with an expected location in the filesystem (i.e., the Windows Temp folder). The sensor thus logged it. The produced trace indicates that this event has occurred on the component NASHUA.dmevals.local and has some objects to give more information to this event, such as DestinationIp, User, or the full path of the Image.\n\n\nB. Attacker Propagation From the Defender's Point of View\n\nWe assume here that all traces produced by the sensors are reported to a SIEM. The second defensive procedure used by the defender is the procedure p hunting . This procedure helps the defender to construct a graph G D from the observed traces. The graph G D is built on the same model as the graph G A constructed by the attacker: nodes are objects or components, edges between two nodes indicate that these objects or components are relative in this attack campaign from the defender point of view. The graph G D is not built directly from the raw set of traces reported to the SIEM because these traces cover a lot of objects and components irrelevant to the hunting process. It is for this reason that the defender has to filter the traces reported to the SIEM to focus only on traces dealing with an Event of Interest (EoI).\n\n\n1) Highlighting Events of Interest:\n\nThe defender relies on a database of Indicators of Compromise IoC and a set of detection rules R to define the traces that have to be considered as Events of Interest. An Indicator of Compromise (IoC) is an object o with a type t that indicates, with high confidence, malicious activity on a network. An IoC is similar to an artifact generated along with a malicious activity. Table III gives an extract of the IoC database used by the defender during the APT29 Threat Hunting process. In this example, objects like toby or m.exe with the observable types of user and file respectively, are searchable in a local scope. Those are local IoC. The defender decides this classification because the user has been created in the target information system, so it makes little sense to look for it globally, Listing 3. Extract of a \"Sysmon/Network Connection\" Trace.  1 , t 1 ), . . . , (o n , t n )} is maintained by the defender who can update it through sharing his knowledge with other security teams (global IoCs) or through his own investigations on his network (local IoCs). A detection rule r \u2208 R expresses a defender-specific condition specifying that a trace has to be considered as an Event of Interest. We write x |= r when the condition specified by r is satisfied by the trace x. The syntax of rules and satisfaction relation |= are inductively defined in the Appendix.\n\nFinally, the set of detection rules R and the IoC database allow the defender to specify the function EoI R,IoC , which filters the traces in order to highlight the traces that are Events of Interest exclusively. More precisely, EoI R,IoC (x) provides two sets: the subset R x of R containing rules satisfied by x, and the subset O x of IoC containing objects occurring in x. Hence, a given trace x is an Event of Interest if at least one of these subsets is not empty. Formally, given a trace\nx = (id x , t, , c, O) this function is defined by EoI R,IoC (x) = (R x , O x ) where: R x = {r \u2208 R | x |= r } and O x = (o, t) | (o, t) \u2208 IoC and (o, r) \u2208 O and \u03c4 (r) = t\nListing 4 details a rule commonly used by a defender to detect execution of psexec by analyzing process_creation event types observed by sensors such as Sysmon with an object matching * \\PsExec64.exe. The object has the role Image (i.e., executable file name). Following this detection, the EoI function returns, in particular, the trace (see Listing 3), which resulted in the verification of the condition set out in the rule.\n\n\n2) Small\n\nStep: Each observation of a trace x = (id x , t, , c, O) considered as an Event of Interest leads to  Figure 4 gives an example of graph computed by the defender from the trace described in Listing 3. This graph is thus the perception of the execution of the psexec attack procedure on the network. At the center of the graph in Figure 4 is the component on which the trace has been observed. Around this component are the relevant objects involved in the trace. This graph can contain objects similar to the small step attacker's graph, presented in Figure 2.  \n\n\n3) Big\n\nStep: Finally, an attack campaign A observed by a defender through a collection of traces X can be modeled by the graph G(X ) = x\u2208X G(x, R x , O x ) resulting from the union of all the graphs associated with each Event of Interest computed from a set of traces X. Figure 5 is the graph computed by the defender during the APT29 simulated campaign with rules from the public project Sigma. Section V gives all the details on its computation and discusses how to deal with the objects present.\n\nThe graph on the Figure 5 has to be compared with the graph representing this same attack campaign from the attacker's perspective on the Figure 3.\n\n\n4) Quality of the Defender Perspective:\n\nThe quality of the graph G(X) constructed by the defender is influenced by three parameters: the configuration of the sensors S, the set of detection rules R database, and the IoC database. In a Threat Hunting process, updating the sensor configuration or the set of detection rules is too long and too impactful to be done straightaway. On the other hand, the IoC database can and must be updated each time a trace is considered to be of interest by the function generate_IoC((R x , O x ), x, IoC). All objects that appear in a trace considered as an Event of Interest are candidates to become IoC and, in particular, objects with roles corresponding to types of observables such as IP address, hashes or domain. Although Kurogome et al. [9] have already proposed to automate this function generate_IoC, the intervention of an expert can be considered. The defender therefore has two main defensive procedures p logs , which he uses to designate the components to monitor and information to report. The p hunting procedure completes this first defensive procedure by computing the defender's graph and updating the IoC database for each trace considered as an Event of Interest. p hunting can be formalized as follows. Starting from scratch, G D = (\u2205, \u2205).\n\nDuring a Threat Hunting operation, the defender goes to build from G D , a restricted graph that highlights the objects shared between several components. This means that these objects with relevant roles and involved in Events of Interest have been observed on at least two components. This graph is useful for orientation during the hunt.\n\n\nV. MODEL EXPERIMENTATION\n\nIntegrating our approach in a production environment would allow both the attacker and the defender on either side to become aware of the traces left on the victim's network. The attacker could use this information to improve the stealthiness of his procedures, and the defender could use it to improve his Threat Hunting process. In practice, its deployment in existing architectures requires:\n\n\u2022 On the Attacker's Side: a logging system for executed procedures formatted according to Listing 1; a directory that corresponds to the attacker's current knowledge of the victim's network; \u2022 On the Defender's Side: sensors installed on defended components and configured as presented in Listing 2 and whose relevant roles are specified as presented in Table II; a directory that corresponds to the defender's current knowledge of the victim's network; an indexer enriched with a set of detection rules as in Listing 4; an IoC database, such as in Table III, an analyst for tasks that are not automatable to date, such as IoC generation. In this article, we take the point of view of an omniscient actor, which allows us to answer the following questions.\n\nHow to measure the quality of defensive architecture? The comparison of the graphs G A and G D allows calculating the coverage rate of objects coming from the attacker into the defender's graph. This allows estimating the relevance of the detection chain.\n\nHow to reduce the defender's graph to unveil the attacker? Too many objects in the defender's graph G D can make it unusable. We are therefore looking for ways to reduce the number of objects while maintaining a sufficient coverage rate to provide potential IoC to a Threat Hunting team.\n\nFor this, we exploited traces of a realistic attack scenario on defensive infrastructure representative of that which we find in modern companies.\n\n\nA. Attack Scenario\n\nWe choose to experiment our model with an independent and representative attack scenario. We rely on the cybersecurity project Mordor [3] maintained by Roberto Rodriguez. The Mordor project provides pre-recorded security events generated after simulating adversarial techniques. It was updated in 2020 with a new dataset called APT29. The dataset provides the logs built by replaying both parts of an attack scenario designed by MITRE in the context of their ATT&CK Evaluations [4]. The attack scenario emulates a 2-part attack led by the threat group APT29. The attack aims to collect and exfiltrate sensitive data. The first part is a rapid \"smash and grab\" collection and exfiltration of specific file types after an initial infection due to a widespread phishing campaign. Then the attacker drops a toolkit used to further explore and compromise the network. The second part is a targeted and methodical breach. It is a low and slow takeover of the target.\n\nA part of the attack procedures is described in the Listing 5. The complete list of attack procedures is described on the MITRE-Engenuity website. 2 Two videos were also recorded by the author which gives an informal understanding of the attacker's perspective during this attack and of the objects that he was aware of exposing to the defender. We wrote all the attack procedures of this campaign according to the format presented in Listing 1. This allows us to build the attacker graph G A . Thus for each procedure, a central node that corresponds to the component is created. It is then connected by edges to each of the objects, presumed to be the attacker's, to be exposed during the execution of the procedure. Each of these edges is tagged with the role of the object in the procedure and also with an identifier. Where an involved procedure exists, an object designating the third component is created. The object is linked to the appropriate node with an edge annotated \"Ref\".  \n\n\nB. Targeted Infrastructure and Defensive Architecture\n\nThe targeted infrastructure, on which the scenario that produced the Mordor APT29 dataset took place, has been reproduced according to the environment described by MITRE as part of their ATT&CK Evaluations as shown in Figure 6.\n\nThe victim's network consists of three workstations, one file server, and one domain controller. All ran Microsoft Windows operating systems. The targeted infrastructure's systems are monitored by Microsoft Windows Sysmon, which provides detailed information about processes, network connections, and file manipulations. Microsoft Windows Sysmon produces the traces used to compute the defender view. These traces form a dataset of 783367 log entries corresponding to two days of observation (attack duration).\n\nWe have injected all the traces from the Mordor dataset into a Splunk 4 indexer. In this raw dataset, we now have to reveal the Events of Interest (EoI). In this experiment, the set of rules R is formed by the 565 commonly used rules from the public detection project Sigma. 5 Sigma is an open community project which aims to capitalize on detection rules sharing the same formalism and which are thus convertible to a large number of SIEM or directly integrated into malware analysis platforms such as VirusTotal. 6 At the beginning of the experiment, our Indicators of Compromise IoC database is empty. The first pass made it possible to detect 6100 EoI, thanks to the matching of 22 detection rules among the 565 enabled rules. We can now build the defender's graph with these EoI. 7 The computed graph has 4 components and 1758 unique objects. Table IV presents this graph's specifications.\n\nThrough this experimentation, we evaluated the relevance of two rule-disabling strategies in order to determine the approach, which is the most efficient to reduce the number of false-positives and make the defender graph G D exploitable. \n\n\nVI. RESULTS\n\nAs we previously discussed, the attacker graph misses certain objects that the attacker is not aware of exposing. In our experiment, the components present in the attacker's graph are all present in the defender's graph, which is not surprising because they have proper monitoring, and all rules are enabled.\n\nHowever, the number of objects in the attacker's graph (180) is significantly inferior to the number of objects (1758) in the defender's graph. This suggests that the defender's graph contains many false-positives. In this context, false-positives are generally legitimate or native objects of the system and whose normal behavior triggers inappropriate or lax detection rules R, or even verbose sensor configuration S. In other words, a false-positive is an object that can never become an IoC since it would not make sense to look for it in a wider scope or because it is not directly related to the malicious event that occurs on the victim's system.\n\nIn order to reduce these false-positives, the intervention of a cognitive agent is often necessary. However, it would be possible to automatically mark objects which correspond to legitimate behaviors of the system while paying attention to malicious actions falling within the Living-off-the-Land [10] paradigm. These actions have the particularity of staying under the radar since they rely on native objects of the system in order to satisfy the attacker's technical intentions. The next step is to find a method to remove these false-positives. It has to be done because their preponderance on the graph may reduce the importance of interesting objects. The defender will, therefore, have to find a more efficient way to identify them instead of manually qualifying each of them.\n\n\nA. How to Measure the Quality of Defensive Architecture\n\nFrom an omniscient perspective, the model allows for comparing data from both sides, attacker and defender. The number of objects from G A , existing also in G D , allows for estimating the efficiency of the entire defender detection chain. We compute that 27.78% of all attacker objects are effectively considered by the defender as Events of Interest (EoI). If this percentage is high enough to allow the defender to initiate a Threat Hunting operation, the large number of objects present in the defender's graph may disturb him. Consequently, the defender may not pay attention to particular objects in G D that could become new IoCs. Some of them are objects that have very discriminating characteristics, like those presented in Table III, and it would be productive to search for them in Listing 6. Algorithm to Compute Coverage Rates. a wider scope. Those could be qualified by a cognitive agent as new IoC and be added in the IoC database.\n\n\nB. How to Reduce the Defender's Graph to Unveil the Attacker\n\nThreat Hunting is a cyclical discipline where the defender identifies new IoCs, modifies detection rules to search for them in a wider scope, analyzes the collected objects, and extracts new IoCs. In this process, not all objects can become IoCs.\n\nFor example, if an attacker uses the attack procedure psexec to perform lateral movements, and if the victim's administration team's performs remote tasks with this tool, then considering psexec.exe or one of its hashes as an IoC will cause a large number of false-positives. It is then necessary to write a detection rule which will allow us to specify the legitimate context of these administrative actions (e.g., by specifying the source IP addresses and user accounts involved). The disabling of too verbose rules can be done in post-processing to clean up G D and to make it more exploitable. We have experimented with two rule-disabling strategies called Top-objects and Top-events. The Top-objects strategy consists of a sequence of rounds of disabling the rule that created the largest number of new unique objects in the defender's graph. This stops upon reaching the highest coverage rate, without having too many objects in the graph and having the fewest rules disabled. The Top-events strategy is similar but first disables the rules, which are at the origin of the largest number of EoI.\n\nGiven a defender's graph G D = (V D , \u2192 D ), disabling a set of rules R D leads to a new defender's graph, written Update(G D , R D ), defined by removing from G D all the edges: \u2022 Update(G D , R D ) is a function that updates the graph G D view by excluding the events resulting from the rules R D . Implementing R D as a list allows us to keep the order in which the rules were disabled and therefore revert the graph G D to an earlier state. Figure 7 shows two 3D curves which correspond respectively to the deactivation of Top-objects and Top-events strategies. We can observe that the Top-objects strategy seems to be the most effective because it allows maintaining high coverage while considerably reducing the number of objects. So when there are only 63 objects left in the graph and only 4 rules have been deactivated, the coverage rate is 24.4%.\n\n\nC. Discussion\n\nBy applying a rule disabling strategy, the defender will thus considerably reduce the number of objects to be investigated while maintaining a sufficiently high coverage rate. However, it should be emphasized that, unlike a detection system which aims to automatically contain a technical threat (e.g., antimalware, Endpoint Detection and Response), the defensive infrastructure, as described in this article, aims to collect as much Cyber Threat Intelligence as possible related to the adversary in order to be able to better hunt it in the victim's network. Thus, an exhaustive detection is not necessary since the objective is not to block unknown threats but simply to ensure the sufficient number of IoC that will allow it to be tracked in the victim's network. This approach of measuring the coverage rate is possible only in the context of Red versus Blue exercises. However, the disabling of too verbose rules can be done in post-processing without observing the evolution of the coverage rate, but simply in order to clean up the graph generated by the defender and to make it more exploitable.\n\n\nVII. RELATED WORKS\n\nThreat Hunting is an agile and iterative process of searching, characterizing, and later identifying attackers who may have compromised the victim's network. In 2021, it is still a widespread focus of cyber defense research. We believe that this area still requires further formalization efforts in order to allow a good understanding of the different layers and their interactions. We observe two main lines of research that should converge: those that formalize the relationships between reallife components; and those focusing on the improvement of actors' strategies, for instance, based on Game Theory.\n\n\nA. Need for Unified Views\n\nGianvecchio et al. [11] point out the semantic gap between the defender and the attacker. Indeed, the attacker operates at the level of strategy and tactics; he focuses on target discovery, and can deploy various kill chains tactics [8], [12]. However, the defender spends significant time processing lowlevel, rule-generated alerts and single-log analysis can hardly reveal the complete attack story for complex, multi-stage attacks. Gianvecchio et al. reduce this gap by proposing an explicit model of the attacker strategy using machine-readable data structures and clustering of security events around TTP annotations from a well-known behavioral taxonomy. This model enables the defender to operate similarly to the attacker at the strategic level without sacrificing their ability to drill into evidential details. For their implementation, they used CALDERA, previously introduced by Applebaum et al. [13] in order to automate Red Teaming while retaining the concept of TTP.\n\n\nB. From Events of Interest to Objects\n\nIn [14], Najafi et al. are one of the first to introduce the intuition behind global features for threat detection. They define a SIEM-based knowledge graph allowing highlighting the most important entities (what we call objects) and relationships observed in Event Logs of Interest extracted from DNS and proxy logs. These relations are enriched with information gathered from publicly available sources of threat intelligence. Over this knowledge graph, Najafi et al. design MalRank, a graph-based inference algorithm designed to infer a node maliciousness score based on its associations to other entities presented in the graph. MalRank has successfully been helpful in identifying previously unknown malicious entities such as malicious domain names and IP addresses.\n\n\nC. From Traces to Indicator of Compromise\n\nIn [9], Kurogome et al. propose to enhance the Threat Hunting process by automatically generating accurate and interpretable IoCs from malware traces. They design EIGER that takes a dataset of traces computed from malware as input. EIGER then computes IoCs of different abstraction levels using an enumerate-then-optimize algorithm. Kurogome et al. demonstrate that their generated IoCs bear comparison with manually generated ones, which indicates that EIGER is an appealing complement to endpoint malware detection in realworld security operations. This is an example of a concrete implementation for the function generate_IoC formalized here.\n\n\nD. From Logs to Defender's Perspective\n\nPei et al. describe in [15] HERCULE a log-based intrusion analysis system. It models the relationship between multiple logs in the system and automatically generates a multidimensional weighted graph with potentially valuable information for the defender embedded within. Their proposed graph provides a panoramic view of the logs generated by different system components and help the defender to understand the whole attack trace. Recently, Burr et al. published a study [16] that focuses on community detection in graphs constructed from Intrusion Detection System (IDS) alerts.\n\nThis article is in line with these works and proposes a richer model that offers a dual view of the Threat Hunting process by also taking the perception into account, but also knowledge and actions of the campaign from the attacker perspective. We believe that in the near future, this work will allow us to join the research conducted in Game Theory and in Security Games [17], [18] where the Threat Hunting process requires more accurate models [19]. In these games, the defender, who is monitoring some collection of resources, has to decide how to deploy a certain number of sensors or honeypots [20] at some predetermined cost. His goal is to properly protect this network at a minimal cost. The attacker's goal is to cheat the defender in order to reach his objectives.\n\n\nVIII. CONCLUSION\n\nThreat Hunting is a fundamental step of an incident response operation that allows for spotting the components of an information system compromised by an attacker. In this process, the defender's ambition is to shed light on the attacker's propagation area in order to best prepare the operation for his eradication.\n\nIn this article, we have proposed a model to analyze both the attacker propagation and the defender knowledge of that propagation. All the steps involved in a Threat Hunting approach have been carefully formalized here. Our approach allows enhancing the knowledge base of the defender with new Indicators of Compromise, which can subsequently enable proactive threat detection. Furthermore, our model and its experimentation highlight the existence of false-positives in particular because of lax detection rules. This feature is valuable for the defender since it allows him to gain efficiency and to improve his detection tools. In particular, because the graph analysis subserves the attack correlations by identifying event patterns. During this study, we better understood the origin of objects which then become IoC. We also emphasize that some objects, which have a meaning only in the context of the information system where they were found, can be very interesting to exploit for Threat Hunting. Finally, our model explains the mutual inference necessary for attacker and defender to understand each other. The most valuable intelligence is the understanding of attacker's procedures.\n\nIn future work, we plan to focus on graph similarity computation in order to design metrics that could testify to the quality of attacker and defender points of view. Such experiments require implementing different comparison algorithms and benchmarking them. However, beyond a metric confrontation between two graphs, we hope the semantics introduced in this article allows for interpreting the differences between attacker and defender perceptions at a deeper level, towards designing other defensive procedures.\n\nIn the long run, our goal is to adjust defender levers defined in this article dynamically: sensor configuration, detection rules, and IoC database to better reveal the presence of an attacker. To achieve this goal, we might need to define a defensive strategy that takes deployment costs into account. Thus, a Red versus Blue exercise would have concrete and immediate technical repercussions on the company's cybersecurity to fight Advanced Persistent Threats. \nO |= true O |= (r i , c) iff c(o i ) O |= not \u03c6 iff O |= \u03c6 O |= \u03c6 1 and \u03c6 2 iff O |= \u03c6 1 and O |= \u03c6 2 O |= \u03c6 1 or \u03c6 2 iff O |= \u03c6 1 or O |= \u03c6 2\nWe assume here that for each role in \u03c6 there exists an object in O playing it and that a role occurs at most one time in O. b) Detection Rule: Detection rules r are built from logical constants true, false and operators and, or, not applied over pairs (\u03b1, c) where \u03b1 is a timestamp t, or an event type \u2208 E, or a component c \u2208 C, or a role r \u2208 R, and c is a property over \u03b1 (we write c(\u03b1) to express that \u03b1 satisfies the property c):\n\nr ::= true | false | (\u03b1, c) | not r | r and r | r or r Then, given a trace x = (id x , t, , c, O), the satisfaction relation |= of a detection rule r is inductively defined by: \n\nFig. 1 .\n1Model overview.\n\no\nwith a type t or if the object o in a type t does not correspond to a component, then D A (t, o) is equal to None (resp. D D (t, o) = None). The representation of a component c from the attacker's point of view may be different from the representation of the same component c from the defender's point of view.\n\n\u2022\nSome Parameters ((o 1 , r 1 ), . . . , (o n , r n )): objects o i in O with their roles r i that configure the procedure; \u2022 Some Sub-Executions (e 1 , . . . , e m ): corresponding to the invocation of sub-procedures orchestrated by p and such that for each e i , the host component M(e i ) is accessible through a relative object appearing in ((o 1 , r 1 ), . . . , (o n , r n )) the parameters of p. An execution e (designated by a unique identifier id e ) of an attack procedure p \u2208 TTP A on a component c = D A (t, o) = None can thus be formalized by: e = (id e , p, (o, t), ((o 1 , r 1 ), . . . , (o n , r n )), (e 1 , . . . , e m ))\n\nListing 1 .\n1Attack Procedure: Lateral Movement Using psexec.\n\nFig. 2 .\n2G(psexec).\n\nFig. 3 .\n3G A computed by the attacker during APT29 simulated campaign.\n\nListing 4 .\n4Extract of Sigma Detection Rule 1 for psexec. the creation of a graph G(x, R x , O x ) (where EoI R,IoC (x) = (R x , O x )) representing this trace. The nodes of this graph are: \u2022 the component c where the trace has been collected; \u2022 the objects o occurring in O; \u2022 the components referred by an object from the trace in the defender's directory {c = D D (\u03c4 (r), o) = None | (o, r) \u2208 O}. The edges in G(x, R x , O x ) permit to connect: \u2022 all the objects o \u2208 O to the component c: (o,r)\u2208O c r,R (o,r) ,is_ioc \u2212 \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212 \u2192 o Each edge is labeled by the role of o, the subset R (o,r) of R x defined by: R (o,r) = {r \u2208 R x | (id x , t, , c, O \\ {(o, r)}) |= r } and by a boolean is_ioc, which is true iff there exists (o, t) \u2208 IoC such that \u03c4 (r) = t. Hence, to remove the edge c r,R (o,r) ,is_ioc \u2212 \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212 \u2192 o from G(x, R x , O x ) it suffices to disable rules in R (o,r) and to remove (o, t) from IoC when is_ioc is true. \u2022 and all the components c referenced in the defender directory c = D D (\u03c4 (r), o) = None (such edges are just labeled by ref).\n\nFig. 4 .\n4Computed graph from a single trace which is considered by the defender as an EoI.\n\nFig. 5 .\n5G D computed by the defender during APT29 simulated campaign.\n\nListing 5 .\n5Part of All Procedures From the Mordor APT29 Attack Campaign.\n\n\nFigure 3presents this graph, characterized by 4 components, 180 unique objects, and 359 edges. 2 https://attackevals.mitre-engenuity.org/APT29/operational-flow.html\n\nFig. 6 .\n6APT29 Evaluation Environment (source: MITRE 3 ).\n\nFig. 7 .\n7c r,R (o,r) ,is_ioc \u2212 \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212 \u2192 o such that R (o,r) \\ R D = \u2205 and is_ioc = false and to remove (if it exists) the edge labeled by ref starting from o together with the component ending such edge. Starting from:\u2022 the attacker's graphG A = (V A , \u2192 A ) containing objects in O A = V A \u2229 O; \u2022 the defender's graph G D = (V D , \u2192 D )containing objects in O D = V D \u2229 O; \u2022 an empty set R D of disabled rules; \u2022 and an initial value coverage = v > 0 for coverage; Listing 6 defines an algorithm to compute R D according to the Top-events strategy, where: \u2022 most_used(\u2192 D ) is a function providing the rule appearing the most times in G D ; Evolutions of coverage rates and count of objects present in the graph G D according to the number of disabled rules.\n\n\nSensor Configuration: Expressions \u03c6 of sensor configurations are built from logical constants true, false and operators and, or, not applied over pairs (r, c) where r is a role and c is a property over the object playing this role (we write c(o) to express that an object o satisfies the property c): \u03c6 ::= true | false | (r, c) | not \u03c6 | \u03c6 and \u03c6 | \u03c6 or \u03c6 Then, given a set O = {(o 1 , r 1 ), . . . , (o n , r n )} \u2286 O \u00d7 R, the satisfaction relation |= of a condition is defined by:\n\nx\n|= true x |= t , c iff t = t and c(t)x |= , c iff = and c( )x |= c , c iff c = c and c(c) x |= (r i , c) iff (o, r i ) \u2208 O and c(o i ) x |= not r iff x |= r x |= r 1 and r 2 iff x |= r 1 and x |= r 2 x |= r 1 or r 2 iff x |= r 1 or x |= r 2 c) Main Notations: -C is a set of components of the targeted network; c is a component in C -O = O D \u222a O A where O D (resp. O A )is the set of objects relative to the victim (resp. to the attacker); o \u2208 O -R is a set of roles associated with objects -T is set of types associated with roles; t is a type in T \u03c4 : R \u2192 T is the function from roles to types-D A (resp. D) : (T \u00d7 O D ) \u2192 (C \u222a {None}) is the attacker (resp. defender) directory -E isa set of types of observable events (by the defender) on components; is an event in E ev = ( , c, O) is an observable event on a component -O \u2286 O \u00d7 R is a (sub)set of objects with their role x = (id x , t, , c, O) is a trace observed on c at date t -S is a set of sensor configurations -S(c) is a sensor configuration on the component c -TTP is a set of procedures; p is a procedure in TTP -A = e 1 , . . . , e N is an attack campaign -e is a procedure execution -M(e) is a machine (component) on which e is executed \u03c6 is a condition over some objects and their roles -R \u2286 R are relevant roles for an event type -( , \u03c6, R ) is an element of a sensor configuration -IoC \u2286 O \u00d7 T is an Indicators of Compromise database -R is a set of detection rules; r is a rule in R -EoI R,IoC (x) = (R x , O x ) is the function providing relevant rules (R x \u2286 R) and objects (O x \u2286 O) from a trace generated by an Event of Interest -G(e) = (V e , \u2192 e ) is an attacker's graph relating to an execution e -G A (A) = (V A , \u2192 A ) is the attacker's network propagation graph resulting from the A attack campaign -G(x, R x , O x ) is a defender's graph relating to a trace x -G D (X ) = (V D , \u2192 D ) is the defender's perception graph of the attacker's propagation associated with each Event of Interest computed from a set of traces X.\n\n\ndetail some examples of objects and their relative types and roles. IP addresses, domain names, or files are examples of frequently observed types.\n\nTABLE I EXAMPLES\nIOF OBJECTS, THEIR RELATIVE TYPES, POSSIBLE ROLES, AND EXISTENCE IN BOTH DIRECTORIES\n\nTABLE II RELEVANT\nIIROLES IN A SYSMON TRACE AND THEIR CAR NAME\n\nTABLE III EXTRACT\nIIIOF THE IOC DATABASE USED BY THE DEFENDER DURING APT29 THREAT HUNTING PROCESS in other victims' networks, due to the high risk of falsepositives caused by its detection. However, cod.3aka3.scr and 9d1c5ef38e6073661c74660b3a71a76e, with the observable types of file and hash respectively, are searchable in a larger scope and may make sense in other networks: those are global IoC. A database IoC = {(o\n\nTABLE IV DEFENDER\nIVPOINT OF VIEW: BIG GRAPH SPECIFICATIONS\nhttps://github.com/Neo23x0/sigma/blob/master/rules/windows/other/win_ tool_psexec.yml\nc 2018 -2020 The MITRE Corporation. This work is reproduced and distributed with the permission of The MITRE Corporation. 4 https://www.splunk.com 5 https://github.com/Neo23x0/sigma 6 https://developers.virustotal.com/v3.0/reference#sigma-analyses 7 Datasets, code, and full graphs are publicly available at https://gitlab.inria. fr/cidre-public/from-ttp-to-ioc-dataset.\n\nThreat hunting,\" in Designing a HIPAA-Compliant Security Operations Center. E C Thompson, ApressBerkeley, CA, USAE. C. Thompson, \"Threat hunting,\" in Designing a HIPAA-Compliant Security Operations Center. Berkeley, CA, USA: Apress, 2020.\n\nTowards a definition of cyberspace tactics, techniques and procedures. F Maymi, R Bixler, R M Jones, S D Lathrop, Proc. IEEE Int. Conf. Big Data. IEEE Int. Conf. Big DataF. Maymi, R. Bixler, R. M. Jones, and S. D. Lathrop, \"Towards a defi- nition of cyberspace tactics, techniques and procedures,\" in Proc. IEEE Int. Conf. Big Data, 2017, pp. 4674-4679.\n\nAPT29 Activity From the ATT&CK Evaluations. R Rodriguez, R. Rodriguez. (2020). APT29 Activity From the ATT&CK Evaluations. [Online].\n\nATT&CK Evaluation. Mitre Corporation, MITRE Corporation. (2019). ATT&CK Evaluation. [Online]. Available: https://attackevals.mitre-engenuity.org/\n\nSTIX a Structured Language for Cyber Threat Intelligence. OASIS Cyber Threat Intelligence. OASIS Cyber Threat Intelligence. (2017). STIX a Structured Language for Cyber Threat Intelligence. [Online]. Available: https://oasis-open. github.io/cti-documentation/stix/intro\n\nThe MITRE Cyber Analytics Repository (CAR). MITRE Corporation. MITRE Corporation. (2018). The MITRE Cyber Analytics Repository (CAR). [Online]. Available: https://car.mitre.org/\n\nData-driven threat hunting using Sysmon. V Mavroeidis, A J\u00f8sang, Proc. 2nd Int. Conf. Cryptogr. Security Privacy. 2nd Int. Conf. Cryptogr. Security PrivacyV. Mavroeidis and A. J\u00f8sang, \"Data-driven threat hunting using Sysmon,\" in Proc. 2nd Int. Conf. Cryptogr. Security Privacy, 2018, pp. 82-88.\n\nModeling the operational phases of APT campaigns. A Berady, V V T Tong, G Guette, C Bidan, G Carat, Proc. 6th Annu. 6th AnnuA. Berady, V. V. T. Tong, G. Guette, C. Bidan, and G. Carat, \"Modeling the operational phases of APT campaigns,\" in Proc. 6th Annu. Conf. Comput. Sci. Comput. Intell., 2019, pp. 96-101.\n\nEIGER: Automated IOC generation for accurate and interpretable endpoint malware detection. Y Kurogome, Proc. 35th Annu. 35th AnnuY. Kurogome et al., \"EIGER: Automated IOC generation for accu- rate and interpretable endpoint malware detection,\" in Proc. 35th Annu. Comput. Security Appl. Conf., 2019, pp. 687-701.\n\nAn emerging threat fileless malware: A survey and research challenges. S Sudhakar, Kumar, Cybersecurity. 321Sudhakar and S. Kumar, \"An emerging threat fileless malware: A survey and research challenges,\" Cybersecurity, vol. 32, p. 1, Jan. 2020.\n\nClosing the gap with APTs through semantic clusters and automated cybergames. S Gianvecchio, C Burkhalter, H Lan, A Sillers, K Smith, Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering. Cham, SwitzerlandSpringerS. Gianvecchio, C. Burkhalter, H. Lan, A. Sillers, and K. Smith, \"Closing the gap with APTs through semantic clusters and auto- mated cybergames,\" in Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering. Cham, Switzerland: Springer, 2019.\n\nCyber kill chain-based taxonomy of advanced persistent threat actors: Analogy of tactics, techniques, and procedures. P N Bahrami, A Dehghantanha, T Dargahi, R M Parizi, K.-K R Choo, H H S Javadi, J. Inf. Process. Syst. 154P. N. Bahrami, A. Dehghantanha, T. Dargahi, R. M. Parizi, K.-K. R. Choo, and H. H. S. Javadi, \"Cyber kill chain-based tax- onomy of advanced persistent threat actors: Analogy of tactics, techniques, and procedures,\" J. Inf. Process. Syst., vol. 15, no. 4, pp. 865-889, 2019.\n\nIntelligent, automated red team emulation. A Applebaum, D Miller, B Strom, C Korban, R Wolf, Proc. 32nd Annu. Conf. Comput. Security Appl. 32nd Annu. Conf. Comput. Security ApplA. Applebaum, D. Miller, B. Strom, C. Korban, and R. Wolf, \"Intelligent, automated red team emulation,\" in Proc. 32nd Annu. Conf. Comput. Security Appl., 2016, pp. 363-373.\n\nMalRank: A measure of maliciousness in SIEM-based knowledge graphs. P Najafi, A M\u00fchle, W P\u00fcnter, F Cheng, C Meinel, Proc. 35th Annu. 35th AnnuP. Najafi, A. M\u00fchle, W. P\u00fcnter, F. Cheng, and C. Meinel, \"MalRank: A measure of maliciousness in SIEM-based knowledge graphs,\" in Proc. 35th Annu. Comput. Security Appl. Conf., 2019, pp. 417-429.\n\nHERCULE: Attack story reconstruction via community discovery on correlated log graph. K Pei, Proc. 32nd Annu. Conf. Comput. Security Appl. 32nd Annu. Conf. Comput. Security ApplK. Pei et al., \"HERCULE: Attack story reconstruction via community discovery on correlated log graph,\" in Proc. 32nd Annu. Conf. Comput. Security Appl., 2016, pp. 583-595.\n\nOn the detection of persistent attacks using alert graphs and event feature embeddings. B Burr, S Wang, G Salmon, H Soliman, Proc. NOMS, 2020. NOMS, 2020B. Burr, S. Wang, G. Salmon, and H. Soliman, \"On the detection of persistent attacks using alert graphs and event feature embeddings,\" in Proc. NOMS, 2020, pp. 1-4.\n\nGame theory on attack graph for cyber deception,\" in Decision and Game Theory for Security. A H Anwar, C Kamhoua, SpringerCham, SwitzerlandA. H. Anwar and C. Kamhoua, \"Game theory on attack graph for cyber deception,\" in Decision and Game Theory for Security. Cham, Switzerland: Springer, 2020.\n\nA game theoretic investigation of deception in network security. T E Carroll, D Grosu, Proc. 18th Int. Conf. Comput. Commun. Netw. 18th Int. Conf. Comput. Commun. NetwT. E. Carroll and D. Grosu, \"A game theoretic investigation of deception in network security,\" in Proc. 18th Int. Conf. Comput. Commun. Netw., 2009, pp. 1-6.\n\nLie Another Day: Demonstrating Bias in a Multi-round Cyber Deception Game of Questionable Veracity. M Bilinski, SpringerCham, SwitzerlandM. Bilinski et al., Lie Another Day: Demonstrating Bias in a Multi-round Cyber Deception Game of Questionable Veracity. Cham, Switzerland: Springer, 2020.\n\nGame theoretic model of strategic honeypot selection in computer networks. R P\u00edbil, V Lis\u00fd, C Kiekintveld, B Bo\u0161ansk\u00fd, M P\u011bchou\u010dek, Decision and Game Theory for Security. Berlin, GermanySpringerR. P\u00edbil, V. Lis\u00fd, C. Kiekintveld, B. Bo\u0161ansk\u00fd, and M. P\u011bchou\u010dek, \"Game theoretic model of strategic honeypot selection in computer networks,\" in Decision and Game Theory for Security. Berlin, Germany: Springer, 2012.\n", "annotations": {"author": "[{\"end\":88,\"start\":75},{\"end\":103,\"start\":89},{\"end\":117,\"start\":104},{\"end\":129,\"start\":118},{\"end\":144,\"start\":130}]", "publisher": null, "author_last_name": "[{\"end\":87,\"start\":81},{\"end\":102,\"start\":97},{\"end\":116,\"start\":112},{\"end\":128,\"start\":124},{\"end\":143,\"start\":137}]", "author_first_name": "[{\"end\":80,\"start\":75},{\"end\":96,\"start\":89},{\"end\":111,\"start\":104},{\"end\":123,\"start\":118},{\"end\":136,\"start\":130}]", "author_affiliation": null, "title": "[{\"end\":63,\"start\":1},{\"end\":207,\"start\":145}]", "venue": "[{\"end\":260,\"start\":209}]", "abstract": "[{\"end\":1684,\"start\":391}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3199,\"start\":3196},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4100,\"start\":4097},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4232,\"start\":4229},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5972,\"start\":5969},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6451,\"start\":6448},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11766,\"start\":11763},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":12190,\"start\":12187},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13522,\"start\":13519},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":23026,\"start\":23023},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":29823,\"start\":29820},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":32714,\"start\":32711},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33058,\"start\":33055},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":33687,\"start\":33686},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":35603,\"start\":35602},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35843,\"start\":35842},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":36113,\"start\":36112},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":37745,\"start\":37741},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":43310,\"start\":43306},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":43523,\"start\":43520},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":43529,\"start\":43525},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":44199,\"start\":44195},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":44317,\"start\":44313},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":45134,\"start\":45131},{\"end\":45151,\"start\":45136},{\"end\":45476,\"start\":45461},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":45843,\"start\":45839},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":46292,\"start\":46288},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":46775,\"start\":46771},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":46781,\"start\":46777},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":46849,\"start\":46845},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":47002,\"start\":46998}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":50468,\"start\":50442},{\"attributes\":{\"id\":\"fig_1\"},\"end\":50782,\"start\":50469},{\"attributes\":{\"id\":\"fig_2\"},\"end\":51423,\"start\":50783},{\"attributes\":{\"id\":\"fig_3\"},\"end\":51486,\"start\":51424},{\"attributes\":{\"id\":\"fig_4\"},\"end\":51508,\"start\":51487},{\"attributes\":{\"id\":\"fig_5\"},\"end\":51581,\"start\":51509},{\"attributes\":{\"id\":\"fig_6\"},\"end\":52646,\"start\":51582},{\"attributes\":{\"id\":\"fig_7\"},\"end\":52739,\"start\":52647},{\"attributes\":{\"id\":\"fig_8\"},\"end\":52812,\"start\":52740},{\"attributes\":{\"id\":\"fig_9\"},\"end\":52888,\"start\":52813},{\"attributes\":{\"id\":\"fig_10\"},\"end\":53055,\"start\":52889},{\"attributes\":{\"id\":\"fig_11\"},\"end\":53115,\"start\":53056},{\"attributes\":{\"id\":\"fig_12\"},\"end\":53879,\"start\":53116},{\"attributes\":{\"id\":\"fig_13\"},\"end\":54364,\"start\":53880},{\"attributes\":{\"id\":\"fig_14\"},\"end\":56369,\"start\":54365},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":56519,\"start\":56370},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":56622,\"start\":56520},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":56686,\"start\":56623},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":57109,\"start\":56687},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":57170,\"start\":57110}]", "paragraph": "[{\"end\":2856,\"start\":1686},{\"end\":4358,\"start\":2858},{\"end\":4775,\"start\":4360},{\"end\":5053,\"start\":4792},{\"end\":5401,\"start\":5055},{\"end\":6371,\"start\":5427},{\"end\":7573,\"start\":6373},{\"end\":8486,\"start\":7610},{\"end\":9225,\"start\":8512},{\"end\":9605,\"start\":9257},{\"end\":9901,\"start\":9607},{\"end\":10788,\"start\":9903},{\"end\":11172,\"start\":10790},{\"end\":12312,\"start\":11216},{\"end\":12866,\"start\":12344},{\"end\":13523,\"start\":12897},{\"end\":13600,\"start\":13525},{\"end\":14509,\"start\":13602},{\"end\":15310,\"start\":14593},{\"end\":15611,\"start\":15323},{\"end\":15773,\"start\":15755},{\"end\":15934,\"start\":15775},{\"end\":16149,\"start\":15996},{\"end\":16921,\"start\":16232},{\"end\":17130,\"start\":16923},{\"end\":17908,\"start\":17156},{\"end\":18757,\"start\":17939},{\"end\":19196,\"start\":18759},{\"end\":19357,\"start\":19248},{\"end\":19417,\"start\":19359},{\"end\":19888,\"start\":19472},{\"end\":20051,\"start\":19890},{\"end\":20455,\"start\":20053},{\"end\":20555,\"start\":20457},{\"end\":20855,\"start\":20590},{\"end\":21126,\"start\":20857},{\"end\":21936,\"start\":21128},{\"end\":22255,\"start\":21938},{\"end\":23027,\"start\":22257},{\"end\":23522,\"start\":23029},{\"end\":23864,\"start\":23524},{\"end\":24410,\"start\":23866},{\"end\":25301,\"start\":24472},{\"end\":26716,\"start\":25341},{\"end\":27211,\"start\":26718},{\"end\":27811,\"start\":27384},{\"end\":28386,\"start\":27824},{\"end\":28888,\"start\":28397},{\"end\":29037,\"start\":28890},{\"end\":30337,\"start\":29081},{\"end\":30679,\"start\":30339},{\"end\":31102,\"start\":30708},{\"end\":31860,\"start\":31104},{\"end\":32117,\"start\":31862},{\"end\":32406,\"start\":32119},{\"end\":32554,\"start\":32408},{\"end\":33537,\"start\":32577},{\"end\":34528,\"start\":33539},{\"end\":34813,\"start\":34586},{\"end\":35325,\"start\":34815},{\"end\":36221,\"start\":35327},{\"end\":36462,\"start\":36223},{\"end\":36786,\"start\":36478},{\"end\":37441,\"start\":36788},{\"end\":38226,\"start\":37443},{\"end\":39234,\"start\":38286},{\"end\":39545,\"start\":39299},{\"end\":40648,\"start\":39547},{\"end\":41506,\"start\":40650},{\"end\":42627,\"start\":41524},{\"end\":43257,\"start\":42650},{\"end\":44268,\"start\":43287},{\"end\":45082,\"start\":44310},{\"end\":45773,\"start\":45128},{\"end\":46396,\"start\":45816},{\"end\":47173,\"start\":46398},{\"end\":47510,\"start\":47194},{\"end\":48705,\"start\":47512},{\"end\":49221,\"start\":48707},{\"end\":49686,\"start\":49223},{\"end\":50262,\"start\":49830},{\"end\":50441,\"start\":50264}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7585,\"start\":7574},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15754,\"start\":15612},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15995,\"start\":15935},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16231,\"start\":16150},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17155,\"start\":17131},{\"attributes\":{\"id\":\"formula_5\"},\"end\":19247,\"start\":19197},{\"attributes\":{\"id\":\"formula_6\"},\"end\":19471,\"start\":19418},{\"attributes\":{\"id\":\"formula_7\"},\"end\":27383,\"start\":27212},{\"attributes\":{\"id\":\"formula_8\"},\"end\":49829,\"start\":49687}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":6770,\"start\":6763},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":22875,\"start\":22867},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":25727,\"start\":25718},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":31466,\"start\":31458},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":31662,\"start\":31653},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":36183,\"start\":36175},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":39030,\"start\":39021}]", "section_header": "[{\"end\":4790,\"start\":4778},{\"end\":5425,\"start\":5404},{\"end\":7608,\"start\":7587},{\"end\":8510,\"start\":8489},{\"end\":9255,\"start\":9228},{\"end\":11214,\"start\":11175},{\"end\":12342,\"start\":12315},{\"end\":12895,\"start\":12869},{\"end\":14591,\"start\":14512},{\"end\":15321,\"start\":15313},{\"end\":17937,\"start\":17911},{\"end\":20588,\"start\":20558},{\"end\":24470,\"start\":24413},{\"end\":25339,\"start\":25304},{\"end\":27822,\"start\":27814},{\"end\":28395,\"start\":28389},{\"end\":29079,\"start\":29040},{\"end\":30706,\"start\":30682},{\"end\":32575,\"start\":32557},{\"end\":34584,\"start\":34531},{\"end\":36476,\"start\":36465},{\"end\":38284,\"start\":38229},{\"end\":39297,\"start\":39237},{\"end\":41522,\"start\":41509},{\"end\":42648,\"start\":42630},{\"end\":43285,\"start\":43260},{\"end\":44308,\"start\":44271},{\"end\":45126,\"start\":45085},{\"end\":45814,\"start\":45776},{\"end\":47192,\"start\":47176},{\"end\":50451,\"start\":50443},{\"end\":50471,\"start\":50470},{\"end\":50785,\"start\":50784},{\"end\":51436,\"start\":51425},{\"end\":51496,\"start\":51488},{\"end\":51518,\"start\":51510},{\"end\":51594,\"start\":51583},{\"end\":52656,\"start\":52648},{\"end\":52749,\"start\":52741},{\"end\":52825,\"start\":52814},{\"end\":53065,\"start\":53057},{\"end\":53125,\"start\":53117},{\"end\":54367,\"start\":54366},{\"end\":56537,\"start\":56521},{\"end\":56641,\"start\":56624},{\"end\":56705,\"start\":56688},{\"end\":57128,\"start\":57111}]", "table": null, "figure_caption": "[{\"end\":50468,\"start\":50453},{\"end\":50782,\"start\":50472},{\"end\":51423,\"start\":50786},{\"end\":51486,\"start\":51438},{\"end\":51508,\"start\":51498},{\"end\":51581,\"start\":51520},{\"end\":52646,\"start\":51596},{\"end\":52739,\"start\":52658},{\"end\":52812,\"start\":52751},{\"end\":52888,\"start\":52827},{\"end\":53055,\"start\":52891},{\"end\":53115,\"start\":53067},{\"end\":53879,\"start\":53127},{\"end\":54364,\"start\":53882},{\"end\":56369,\"start\":54368},{\"end\":56519,\"start\":56372},{\"end\":56622,\"start\":56539},{\"end\":56686,\"start\":56644},{\"end\":57109,\"start\":56709},{\"end\":57170,\"start\":57131}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9812,\"start\":9804},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":16391,\"start\":16383},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":17559,\"start\":17551},{\"end\":19052,\"start\":19043},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":26210,\"start\":26201},{\"end\":27880,\"start\":27866},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":27934,\"start\":27926},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":28161,\"start\":28153},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":28383,\"start\":28375},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":28669,\"start\":28661},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":28915,\"start\":28907},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":29036,\"start\":29028},{\"end\":29579,\"start\":29532},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":34812,\"start\":34804},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":41103,\"start\":41095},{\"end\":50361,\"start\":50339}]", "bib_author_first_name": "[{\"end\":57706,\"start\":57705},{\"end\":57708,\"start\":57707},{\"end\":57941,\"start\":57940},{\"end\":57950,\"start\":57949},{\"end\":57960,\"start\":57959},{\"end\":57962,\"start\":57961},{\"end\":57971,\"start\":57970},{\"end\":57973,\"start\":57972},{\"end\":58269,\"start\":58268},{\"end\":58997,\"start\":58996},{\"end\":59011,\"start\":59010},{\"end\":59303,\"start\":59302},{\"end\":59313,\"start\":59312},{\"end\":59317,\"start\":59314},{\"end\":59325,\"start\":59324},{\"end\":59335,\"start\":59334},{\"end\":59344,\"start\":59343},{\"end\":59655,\"start\":59654},{\"end\":59949,\"start\":59948},{\"end\":60202,\"start\":60201},{\"end\":60217,\"start\":60216},{\"end\":60231,\"start\":60230},{\"end\":60238,\"start\":60237},{\"end\":60249,\"start\":60248},{\"end\":60805,\"start\":60804},{\"end\":60807,\"start\":60806},{\"end\":60818,\"start\":60817},{\"end\":60834,\"start\":60833},{\"end\":60845,\"start\":60844},{\"end\":60847,\"start\":60846},{\"end\":60860,\"start\":60856},{\"end\":60862,\"start\":60861},{\"end\":60870,\"start\":60869},{\"end\":60874,\"start\":60871},{\"end\":61229,\"start\":61228},{\"end\":61242,\"start\":61241},{\"end\":61252,\"start\":61251},{\"end\":61261,\"start\":61260},{\"end\":61271,\"start\":61270},{\"end\":61605,\"start\":61604},{\"end\":61615,\"start\":61614},{\"end\":61624,\"start\":61623},{\"end\":61634,\"start\":61633},{\"end\":61643,\"start\":61642},{\"end\":61962,\"start\":61961},{\"end\":62314,\"start\":62313},{\"end\":62322,\"start\":62321},{\"end\":62330,\"start\":62329},{\"end\":62340,\"start\":62339},{\"end\":62637,\"start\":62636},{\"end\":62639,\"start\":62638},{\"end\":62648,\"start\":62647},{\"end\":62906,\"start\":62905},{\"end\":62908,\"start\":62907},{\"end\":62919,\"start\":62918},{\"end\":63267,\"start\":63266},{\"end\":63535,\"start\":63534},{\"end\":63544,\"start\":63543},{\"end\":63552,\"start\":63551},{\"end\":63567,\"start\":63566},{\"end\":63579,\"start\":63578}]", "bib_author_last_name": "[{\"end\":57717,\"start\":57709},{\"end\":57947,\"start\":57942},{\"end\":57957,\"start\":57951},{\"end\":57968,\"start\":57963},{\"end\":57981,\"start\":57974},{\"end\":58279,\"start\":58270},{\"end\":58394,\"start\":58377},{\"end\":59008,\"start\":58998},{\"end\":59018,\"start\":59012},{\"end\":59310,\"start\":59304},{\"end\":59322,\"start\":59318},{\"end\":59332,\"start\":59326},{\"end\":59341,\"start\":59336},{\"end\":59350,\"start\":59345},{\"end\":59664,\"start\":59656},{\"end\":59958,\"start\":59950},{\"end\":59965,\"start\":59960},{\"end\":60214,\"start\":60203},{\"end\":60228,\"start\":60218},{\"end\":60235,\"start\":60232},{\"end\":60246,\"start\":60239},{\"end\":60255,\"start\":60250},{\"end\":60815,\"start\":60808},{\"end\":60831,\"start\":60819},{\"end\":60842,\"start\":60835},{\"end\":60854,\"start\":60848},{\"end\":60867,\"start\":60863},{\"end\":60881,\"start\":60875},{\"end\":61239,\"start\":61230},{\"end\":61249,\"start\":61243},{\"end\":61258,\"start\":61253},{\"end\":61268,\"start\":61262},{\"end\":61276,\"start\":61272},{\"end\":61612,\"start\":61606},{\"end\":61621,\"start\":61616},{\"end\":61631,\"start\":61625},{\"end\":61640,\"start\":61635},{\"end\":61650,\"start\":61644},{\"end\":61966,\"start\":61963},{\"end\":62319,\"start\":62315},{\"end\":62327,\"start\":62323},{\"end\":62337,\"start\":62331},{\"end\":62348,\"start\":62341},{\"end\":62645,\"start\":62640},{\"end\":62656,\"start\":62649},{\"end\":62916,\"start\":62909},{\"end\":62925,\"start\":62920},{\"end\":63276,\"start\":63268},{\"end\":63541,\"start\":63536},{\"end\":63549,\"start\":63545},{\"end\":63564,\"start\":63553},{\"end\":63576,\"start\":63568},{\"end\":63589,\"start\":63580}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":57867,\"start\":57629},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":23248234},\"end\":58222,\"start\":57869},{\"attributes\":{\"id\":\"b2\"},\"end\":58356,\"start\":58224},{\"attributes\":{\"id\":\"b3\"},\"end\":58503,\"start\":58358},{\"attributes\":{\"id\":\"b4\"},\"end\":58774,\"start\":58505},{\"attributes\":{\"id\":\"b5\"},\"end\":58953,\"start\":58776},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":49864578},\"end\":59250,\"start\":58955},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":213232938},\"end\":59561,\"start\":59252},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":208278121},\"end\":59875,\"start\":59563},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":210166540},\"end\":60121,\"start\":59877},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":212620788},\"end\":60684,\"start\":60123},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":202745284},\"end\":61183,\"start\":60686},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":2138593},\"end\":61534,\"start\":61185},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":208277753},\"end\":61873,\"start\":61536},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":5196694},\"end\":62223,\"start\":61875},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":219591692},\"end\":62542,\"start\":62225},{\"attributes\":{\"id\":\"b16\"},\"end\":62838,\"start\":62544},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":34770},\"end\":63164,\"start\":62840},{\"attributes\":{\"id\":\"b18\"},\"end\":63457,\"start\":63166},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":10498709},\"end\":63870,\"start\":63459}]", "bib_title": "[{\"end\":57938,\"start\":57869},{\"end\":58561,\"start\":58505},{\"end\":58818,\"start\":58776},{\"end\":58994,\"start\":58955},{\"end\":59300,\"start\":59252},{\"end\":59652,\"start\":59563},{\"end\":59946,\"start\":59877},{\"end\":60199,\"start\":60123},{\"end\":60802,\"start\":60686},{\"end\":61226,\"start\":61185},{\"end\":61602,\"start\":61536},{\"end\":61959,\"start\":61875},{\"end\":62311,\"start\":62225},{\"end\":62903,\"start\":62840},{\"end\":63532,\"start\":63459}]", "bib_author": "[{\"end\":57719,\"start\":57705},{\"end\":57949,\"start\":57940},{\"end\":57959,\"start\":57949},{\"end\":57970,\"start\":57959},{\"end\":57983,\"start\":57970},{\"end\":58281,\"start\":58268},{\"end\":58396,\"start\":58377},{\"end\":59010,\"start\":58996},{\"end\":59020,\"start\":59010},{\"end\":59312,\"start\":59302},{\"end\":59324,\"start\":59312},{\"end\":59334,\"start\":59324},{\"end\":59343,\"start\":59334},{\"end\":59352,\"start\":59343},{\"end\":59666,\"start\":59654},{\"end\":59960,\"start\":59948},{\"end\":59967,\"start\":59960},{\"end\":60216,\"start\":60201},{\"end\":60230,\"start\":60216},{\"end\":60237,\"start\":60230},{\"end\":60248,\"start\":60237},{\"end\":60257,\"start\":60248},{\"end\":60817,\"start\":60804},{\"end\":60833,\"start\":60817},{\"end\":60844,\"start\":60833},{\"end\":60856,\"start\":60844},{\"end\":60869,\"start\":60856},{\"end\":60883,\"start\":60869},{\"end\":61241,\"start\":61228},{\"end\":61251,\"start\":61241},{\"end\":61260,\"start\":61251},{\"end\":61270,\"start\":61260},{\"end\":61278,\"start\":61270},{\"end\":61614,\"start\":61604},{\"end\":61623,\"start\":61614},{\"end\":61633,\"start\":61623},{\"end\":61642,\"start\":61633},{\"end\":61652,\"start\":61642},{\"end\":61968,\"start\":61961},{\"end\":62321,\"start\":62313},{\"end\":62329,\"start\":62321},{\"end\":62339,\"start\":62329},{\"end\":62350,\"start\":62339},{\"end\":62647,\"start\":62636},{\"end\":62658,\"start\":62647},{\"end\":62918,\"start\":62905},{\"end\":62927,\"start\":62918},{\"end\":63278,\"start\":63266},{\"end\":63543,\"start\":63534},{\"end\":63551,\"start\":63543},{\"end\":63566,\"start\":63551},{\"end\":63578,\"start\":63566},{\"end\":63591,\"start\":63578}]", "bib_venue": "[{\"end\":57703,\"start\":57629},{\"end\":58013,\"start\":57983},{\"end\":58266,\"start\":58224},{\"end\":58375,\"start\":58358},{\"end\":58594,\"start\":58563},{\"end\":58837,\"start\":58820},{\"end\":59067,\"start\":59020},{\"end\":59366,\"start\":59352},{\"end\":59681,\"start\":59666},{\"end\":59980,\"start\":59967},{\"end\":60364,\"start\":60257},{\"end\":60904,\"start\":60883},{\"end\":61322,\"start\":61278},{\"end\":61667,\"start\":61652},{\"end\":62012,\"start\":61968},{\"end\":62366,\"start\":62350},{\"end\":62634,\"start\":62544},{\"end\":62969,\"start\":62927},{\"end\":63264,\"start\":63166},{\"end\":63628,\"start\":63591},{\"end\":58039,\"start\":58015},{\"end\":59110,\"start\":59069},{\"end\":59376,\"start\":59368},{\"end\":59692,\"start\":59683},{\"end\":60383,\"start\":60366},{\"end\":61362,\"start\":61324},{\"end\":61678,\"start\":61669},{\"end\":62052,\"start\":62014},{\"end\":62378,\"start\":62368},{\"end\":63007,\"start\":62971},{\"end\":63645,\"start\":63630}]"}}}, "year": 2023, "month": 12, "day": 17}