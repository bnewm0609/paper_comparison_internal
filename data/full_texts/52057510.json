{"id": 52057510, "updated": "2023-09-30 18:20:14.327", "metadata": {"title": "QuAC : Question Answering in Context", "authors": "[{\"first\":\"Eunsol\",\"last\":\"Choi\",\"middle\":[]},{\"first\":\"He\",\"last\":\"He\",\"middle\":[]},{\"first\":\"Mohit\",\"last\":\"Iyyer\",\"middle\":[]},{\"first\":\"Mark\",\"last\":\"Yatskar\",\"middle\":[]},{\"first\":\"Wen-tau\",\"last\":\"Yih\",\"middle\":[]},{\"first\":\"Yejin\",\"last\":\"Choi\",\"middle\":[]},{\"first\":\"Percy\",\"last\":\"Liang\",\"middle\":[]},{\"first\":\"Luke\",\"last\":\"Zettlemoyer\",\"middle\":[]}]", "venue": "EMNLP", "journal": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing", "publication_date": {"year": 2018, "month": 8, "day": 21}, "abstract": "We present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total). The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts from the text. QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as we show in a detailed qualitative evaluation. We also report results for a number of reference models, including a recently state-of-the-art reading comprehension architecture extended to model dialog context. Our best model underperforms humans by 20 F1, suggesting that there is significant room for future work on this data. Dataset, baseline, and leaderboard available at http://quac.ai.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1808.07036", "mag": "2951831170", "acl": "D18-1241", "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/ChoiHIYYCLZ18", "doi": "10.18653/v1/d18-1241"}}, "content": {"source": {"pdf_hash": "3a20280c7f36ed8c615447b836cbc5112650eaa6", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/D18-1241.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/D18-1241.pdf", "status": "HYBRID"}}, "grobid": {"id": "3a03e6b4e43ccb0789da668697875131d8622301", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3a20280c7f36ed8c615447b836cbc5112650eaa6.txt", "contents": "\nQuAC : Question Answering in Context\nAssociation for Computational LinguisticsCopyright Association for Computational LinguisticsOctober 31 -November 4. 2018. 2018\n\nEunsol Choi eunsol@cs.washington.edu \nAllen Institute for Artificial Intelligence \u2020 University of Washington\nStanford University\nUMass Amherst \u2663\n\n\n\u2665 He \nAllen Institute for Artificial Intelligence \u2020 University of Washington\nStanford University\nUMass Amherst \u2663\n\n\nHe \u2666 Mohit mohiti@allenai.org \nAllen Institute for Artificial Intelligence \u2020 University of Washington\nStanford University\nUMass Amherst \u2663\n\n\nIyyer \u2663 \nAllen Institute for Artificial Intelligence \u2020 University of Washington\nStanford University\nUMass Amherst \u2663\n\n\nMark Yatskar marky@allenai.org \nAllen Institute for Artificial Intelligence \u2020 University of Washington\nStanford University\nUMass Amherst \u2663\n\n\nWen-Tau Yih \nAllen Institute for Artificial Intelligence \u2020 University of Washington\nStanford University\nUMass Amherst \u2663\n\n\nYejin Choi \nAllen Institute for Artificial Intelligence \u2020 University of Washington\nStanford University\nUMass Amherst \u2663\n\n\n\u2665 \nAllen Institute for Artificial Intelligence \u2020 University of Washington\nStanford University\nUMass Amherst \u2663\n\n\nPercy Liang pliang@cs.stanford.edu \nAllen Institute for Artificial Intelligence \u2020 University of Washington\nStanford University\nUMass Amherst \u2663\n\n\nLuke Zettlemoyer \nAllen Institute for Artificial Intelligence \u2020 University of Washington\nStanford University\nUMass Amherst \u2663\n\n\nQuAC : Question Answering in Context\n\nProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\nthe 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational LinguisticsOctober 31 -November 4. 2018. 20182174\nWe present QuAC, a dataset for Question Answering in Context that contains 14K information-seeking QA dialogs (100K questions in total). The dialogs involve two crowd workers: (1) a student who poses a sequence of freeform questions to learn as much as possible about a hidden Wikipedia text, and (2) a teacher who answers the questions by providing short excerpts from the text. QuAC introduces challenges not found in existing machine comprehension datasets: its questions are often more open-ended, unanswerable, or only meaningful within the dialog context, as we show in a detailed qualitative evaluation. We also report results for a number of reference models, including a recently state-ofthe-art reading comprehension architecture extended to model dialog context. Our best model underperforms humans by 20 F1, suggesting that there is significant room for future work on this data. Dataset, baseline, and leaderboard available at http://quac.ai.\n\nIntroduction\n\nIn information-seeking dialog, students repeatedly ask teachers questions to learn about a topic of interest (Stede and Schlangen, 2004). Modeling such conversations is challenging, as the questions can be highly context-dependent, elliptical, and even unanswerable. To enable learning from rich information-seeking dialog, we present QuAC (henceforth ), a large-scale dataset for Question Answering in Context that contains 14K crowdsourced QA dialogs (100K total QA pairs). 1 Figure 1 shows an example dialog. The interaction is student driven and centered around a short evidence text (a section from Daffy Duck's \u2192 Yes, the only aspects of the character that have remained consistent (...) are his voice characterization by Mel Blanc STUDENT: How has he changed? TEACHER: \u2192 Daffy was less anthropomorphic STUDENT: In what other ways did he change?\n\n\nTEACHER:\n\n\u2192 Daffy's slobbery, exaggerated lisp (...) is barely noticeable in the early cartoons. STUDENT: Why did they add the lisp? TEACHER:\n\n\u2192 One often-repeated \"official\" story is that it was modeled after producer Leon Schlesinger's tendency to lisp. STUDENT: Is there an \"unofficial\" story?  Wikipedia page), which only the teacher can access. Given just the section's heading, \"Origin & History\", the student aims to learn as much as possible about its contents by asking questions. The teacher answers these questions with spans from the evidence text, as in existing reading comprehension tasks (Rajpurkar et al., 2016). Additionally, the teacher uses dialog acts to provide the student with feedback (e.g., \"ask a follow up ques- CoQA (Reddy et al., 2018) CSQA (Saha et al., 2018) CQA (Talmor and Berant, 2018) SQA (Iyyer et al., 2017) NarrativeQA (Kocisk\u00fd et al., 2017) TriviaQA (Joshi et al., 2017) SQuAD 2.0 (Rajpurkar et al., 2018) MS Marco (Nguyen et al., 2016) NewsQA (Trischler et al., 2016)  tion\"), which makes the dialogs more productive.\n\nWe collect the dataset in an interactive setting where two crowd workers play the roles of teacher and student. To encourage natural and diverse questions, we do not follow previous dialogstyle QA datasets that semi-automatically generate questions (Talmor and Berant, 2018;Saha et al., 2018). Furthermore, unlike QA datasets such as SQuAD and CoQA (Reddy et al., 2018), students in do not know the answers to their questions prior to asking them, which lessens the role of string matching and simple paraphrasing in answering their questions. This property makes similar to datasets that contain real user queries on search engines (Nguyen et al., 2016). contains many challenging phenomena unique to dialog, such as coreference to previous questions and answers and open-ended questions that must be answered without repeating previous information (Section 3). Additionally, despite lacking access to the section text, we find that students start dialogs by asking questions about the beginning of the section before progressing to asking questions about the end. These observations imply that models built for must incorporate the dialog context to achieve good performance.\n\nWe present a strong neural baseline ) that considers both dialog context and section text. While this model achieves within 6 F1 of human performance on SQuAD, it performs 20 F1 points below the human upper bound on , indicating room for future improvement.\n\n\nDataset collection\n\nThis section describes our data collection process, which involves facilitating QA dialogs between crowd workers. Table 1 shows shares many of the same positive characteristics of existing QA datasets while expanding upon the dialog aspect.  \n\n\nInteractive Task\n\nOur task pairs up two workers, a teacher and a student, who discuss a section s (e.g., \"Origin & History\" in the example from Figure 1) from a Wikipedia article about an entity e (Daffy Duck). The student is permitted to see only the section's title t and the first paragraph of the main article b, while the teacher is additionally provided with full access to the section text. The task begins with the student formulating a free-text question q from the limited information they have been given. The teacher is not allowed to answer with free text; instead, they must select a contiguous span of text defined by indices (i, j) into the section text s. 2 While this decision limits the expressivity of answers, it makes evaluation simpler and more reliable; as such, it has been adopted in other reading comprehension datasets such as SQuAD, TriviaQA (Joshi et al., 2017), and NewsQA (Trischler et al., 2016).\n\nTo facilitate more natural interactions, teachers must also provide the student with a list of dialog acts v that indicates the presence of any of n discrete statements. We include three types of di-  alog acts: (1) continuation (follow up, maybe follow up, or don't follow up), (2) affirmation (yes, no, or neither) and (3) answerability (answerable or no answer). The continuation act is crucial for workers to have productive dialogs, as it allows teachers to guide the student's questioning towards aspects of the article that are especially important or interesting. Altogether, a teacher's complete answer to a question q includes a pair of indices and dialog indicators, a = (i, j, v). If a question is marked no answer, the indices are ignored.\n\nAfter receiving an answer from the teacher, the student asks another question. At every turn, the student has more information about the topic than they did previously, which encourages them to ask follow-up questions about what they have just learned. The dialog continues until (1) twelve questions are answered, (2) one of the partners decides to end the interaction, or (3) more than two unanswerable questions were asked.\n\n\nCollection Details\n\nWe used Amazon Mechanical Turk for collection, restricting the task to workers in English-speaking countries and with more than 1000 HITs with at least a 95% acceptance rate. We paid workers per the number of completed turns in the dialog, which encourages workers to have long dialogs with their partners, and discarded dialogs with less than three QA pairs. 3 To ensure quality, we created a qualification task and allowed workers to report their partner for various problems. More details on data collection can be found in our datasheet. 4\n\nArticle selection Our early pilot studies showed that articles about people generally require less background knowledge to write good questions than other categories. To find articles about people with varied backgrounds, we retrieved articles from a list of category keywords (culture, animal, people associated with event, geography, health, celebrity) using a web interface provided by the Wikimedia foundation. 5 We pruned by popularity by selecting articles with at least 100 incoming links, and we additionally removed non-person entities using YAGO (Suchanek et al., 2007). After article selection, we filtered sections from these articles based on the number of paragraphs, number of tokens, and average words per sentence. 6\n\nDataset validation To create our evaluation sets, we collected four additional annotations per question. Workers were presented with questions from a previously collected dialog and asked to provide answer spans. 7 Acquiring many annotations is important since many questions in have multiple valid answers. Table 2 shows small differences between training, development and testing splits. Sections in the training set are shorter than those in the evaluation folds because we permit multiple dialogs about the same section only in training; since workers preferred reading shorter sections, these were more likely to result in multiple dialogs. Variations in answer span length arise from two sources: (1) having multiple annotations in the validation task and (2) differing incentives between the data collection and validation procedures. 8 An analysis measuring the effect of these variations shows that they result in little difference in evaluation. 9\n\n\nTrain / Dev / Test Differences\n\n3 Dataset Analysis differs from other reading comprehension datasets due to our dialog-style collection process and the information asymmetry between teacher and student. In the following sections, we provide a qualitative analysis of the dataset in that highlights challenging question types as well as the impact of the dialog context. Table 2 shows dataset summary statistics.\n\n\nQuestion and answer types\n\nhas long answers of 15 tokens on average compared to 3 for SQuAD, which is unsurprising as most SQuAD answers are either entities or numerics (Jurczyk et al., 2018) while questions can be more open-ended. While the average question length (6.5 tokens) is shorter than that of SQuAD (11 tokens), this does not indicate reduced question complexity, as the student (1) cannot access the section to paraphrase it and (2) can be more concise by coreferencing previous interactions. Figure 2 visualizes the most frequent question types in based on \"Wh\" words. 10 For a more 7 After submitting an answer, they were shown the original teacher's answer so that they could understand the context of the subsequent questions. 8 Validation workers did not have to maintain the dialog and so did not include as much information in the response.\n\n9 More specifically, we analyze whether references from the initial data collection significantly differ from references collected during validation. We observe a difference of less than 1 F1 when using the original answer as system output versus using validation answers. 10 To more effectively visualize sub-boxes like \"what did\", we exclude questions from the tail of the distribution.  fine-grained analysis, we randomly sampled 100 questions (each from a different dialog) and manually labeled different phenomena in Table 3. Unlike most current QA datasets that focus on factoid questions, our task setup encourages more open-ended questions: about half of questions are non-factoid. Furthermore, 86% of questions are contextual, requiring reading the context to resolve coreference; of these, 44% refer to entities or events in the dialog history, while 61% refer to the subject of the article.\n\nThe role of context Dialog context is crucial to understanding and answering questions. Figure 5a shows that the location of the answer within the text is influenced by the number of questions asked previously. Early questions are mostly answered in the beginning of the section, while later questions tend to focus on the end of the section.\n\nInterestingly, text in the middle of the section is not asked about as frequently ( Figure 5c). As more questions get asked, the more likely a question is to be unanswerable. Figure 5b shows how the answers progress through different chunks of the evidence text (where each section is divided into 12 chunks of  . The student struggles to get information despite asking good questions. The teacher attempts to provide extra context to guide the student, but the dialog ultimately ends because of too many unanswerable questions. equal size). The answer to the next question is most frequently either in the same chunk as the previous question or an adjacent chunk, and most dialogs in the dataset cover three to six of the chunks (Figure 5d). These observations suggest that models for must take into account the dialog context. However, results in Section 5 show that solely relying on the location of previous answers is not sufficient.\n\nFinally, we examine properties of the questions as a function of the turn position in the dialog ( Figure 6). The frequency of yes/no questions increases significantly as the dialogs progress; again, at the beginning of the dialog, students have very little information, so it is harder to formulate a yes/no question. The percentage of questions that have multiple answers declines as the dialog progresses, implying students ask general questions first and specific ones later. Figures 3 and 4 contain two representative dialogs from . Longer dialogs sometimes switch topics (such as in Figure 3 about \"academic work\") and often go from general to specific questions. Students whose ques-  Table 3: An analysis of questions. Non-factoid questions do not ask about specific facts, while contextual questions require reading the history to resolve coreferences to the dialog history and/or article. tions go unanswered commonly resort to asking their teacher for any interesting content; even if this strategy fails to prolong the dialog as in Figure 4, models can still use the dialog to learn when to give no answer.\n\n\nQualitative examples\n\n\nExperimental Setup\n\nWe consider the following QA task: given the first k questions and k ground-truth answers in the dialog, all supporting material (entity e, topic t, background b, and section text s), and question q k+1 , we predict the answer span indices i, j in the section text s. Since affirmation questions are incomplete without a yes/no answer and the continuation feedback is important for information-seeking dialog, we predict the dialog acts v, which with the span form the final answer prediction a k+1 .\n\nAll of our experiments are carried out on a train/dev/test split of 83.5k/7.3k/7.3k questions/answer pairs, where no sections are shared between the different folds. Questions in the training set have one reference answer, while dev and test questions have five references each. For all experiments, we do not evaluate on questions with a human F1 lower than 40, which eliminates roughly 10% of our noisiest annotations. 11\n\n\nEvaluation Metrics\n\nOur core evaluation metric, word-level F1, is implemented similarly to SQuAD (Rajpurkar et al.,  (b) share the same color scale. The student's earlier questions are answered mostly by the first few chunks, while the end of the section is covered in later turns (a). The middle is the least covered portion (c), and dialogs cover around five unique chunks of the section on average (d). The transition matrix (b) shows that the answer to the next question is more likely to be located within a chunk adjacent to the current answer than in one farther away.\n\nOccurrence frequency Turn number Figure 6: The number of turns in the dialog influences the student's behavior: they start by asking general questions (i.e., easier to answer, with multiple possible answers) and progress to more specific ones. 2016): precision and recall are computed by considering the portion of words in the prediction and references that overlap after removing stopwords. 12 For no answer questions, we give the system an F1 of one if it correctly predicts no answer and zero otherwise. 13 Like SQuAD, we compute the maximum F1 among all references; however, since many questions have multiple valid answers, this metric varies significantly with 12 Since our answer spans have vaguer boundaries than the shorter ones in SQuAD, exact match is not a useful metric. 13 Because the validation task was more susceptible to spam by constant annotation of \"no-answer,\" we only allow \"no-answer\" if the majority of references marked \"noanswer\", removing other answers. If \"no-answer\" is not the majority answer, we remove all instances of \"no-answer\". the number of reference annotations. To make oracle human and system performance comparable, given n references, we report the average of the maximum F1 computed from each n \u2212 1 subset with respect to the heldout reference.\n\nAdditionally, since averaged F1 can be misleading for questions with multiple valid answers, we introduce the human equivalence score (HEQ), a performance measure for judging whether a system's output is as good as that of an average human. 14 HEQ measures the percentage of examples for which system F1 exceeds or matches human F1. We compute two variants: (1) the percentage of questions for which this is true (HEQ-Q), and (2) the percentage of dialogs for which this is true for every question in the dialog (HEQ-D). A system that achieves a value of 100 on HEQ-D can by definition maintain average human quality output over full dialogs.\n\nFor dialog acts, we report accuracy with respect to the majority annotation, breaking ties randomly.\n\n\nExperiments\n\n\nSanity checks\n\nRandom sentence This baseline selects a random sentence in the section text s as the answer (including no answer).\n\nMajority The majority answer outputs no answer and the majority class for all other dialog acts (neither for affirmation and don't follow up for continuation).\n\nTransition matrix We divide the supporting text into 12 chunks (with a special chunk for no answer) and use the transition matrix (computed from the training set) in Figure 5b to select an answer given the position of the previous answer. This baseline does not output other dialog acts.\n\n\nUpper bounds\n\nGold NA + TM This is the same transition matrix (TM) baseline as before, except that for questions whose gold annotations are no answer, we always output no answer.\n\nGold sentence + NA To see if can be treated as an answer sentence selection problem, we output the sentence from s with the maximal F1 with respect to references, or no answer for unanswerable questions.\n\nHuman performance We pick one reference as a system output and compute the F1 with respect to the remaining references using the method described in Section 4.1. By definition, all HEQ measures are 100, and we report agreement for the affirmation dialog act. 15\n\n\nBaselines\n\nPretrained InferSent To test the importance of lexical matching in our dataset, we output the sentence in s whose pretrained InferSent representation (Conneau et al., 2017) has the highest cosine similarity to that of the question.\n\nFeature-rich logistic regression We train a logistic regression using Vowpal Wabbit (Langford et al., 2007) to select answer sentences. We use simple matching features (e.g., n-gram overlap between questions and candidate answers), bias features (position and length of a candidate), and contextual features (e.g., matching features computed with previous questions / answers, turn number).\n\n\nBiDAF++\n\nWe use a re-implementation of a topperforming SQuAD model (Peters et al., 2018) that augments bidirectional attention flow (Seo et al., 2016, BiDAF) with self-attention  and contextualized embeddings. 16 A token for no answer is appended to s to enable its prediction following Levy et al. (2017). Additionally, we modify the model for our task to also predict dialog acts, placing a classifier over the same representation used to predict the end position of the predicted span.\n\nBiDAF++ w/ k-ctx As BiDAF++ does not model any dialog context, we modify the passage and question embedding processes to consider the dialog history. We consider context from the previous k QA pairs. 17\n\n\u2022 Passage embedding We explicitly identify the previous k answers within the section text by concatenating marker embeddings to the existing word embeddings.\n\n\u2022 Question embedding Naively prepending the previous k questions to the current question did not show gains in initial experiments. We opt instead to simply encode the dialog turn number within the question embedding. Sanity check Overall, the poor sanity check results imply that is very challenging. Of these, following the transition matrix (TM) gives the best performance, reinforcing the observation that the dialog context plays a significant role in the task.\n\n\nResults\n\n\nUpper bounds\n\nThe human upper bound (80.8 F1) demonstrates high agreement. While Gold sentence + NA does perform well, indicating that significant progress can be made by treating the problem as answer sentence selection, HEQ measures show that span-based approaches will be needed achieve average human equivalence. Finally, the Gold NA + TM shows that cannot be solved by ignoring question and answer text. 16 The AllenNLP (Gardner et al., 2017) implementation we use reaches 82.7 on the SQuAD development set, compared to the paper's reported 85.8 on SQuAD; regardless, this implementation would have been state-of-the-art less than a year ago, making it an extremely strong baseline. 17 Our implementation is available in AllenNLP.  Baselines Text similarity methods such as bagof-ngrams overlap and InferSent are largely ineffective on , which shows that questions have little direct overlap with their answers. On the other hand, BiDAF++ models make significant progress, demonstrating that existing models can already capture a significant portion of phenomena in . The addition of information from previous turns (w/ 1-ctx) helps significantly, indicating that integration of context is essential to solving the task. While increasing the context size in BiDAF++ continues to help, we observe saturation using contexts of length 3, suggesting that more sophisticated models are necessary to take full advantage of the context. Finally, even our best model underperforms humans: the system achieves human equivalence on only 60% of questions and 5% of full dialogs.\n\n\nError Analysis\n\nIn this section, we analyze the development set performance of our best context-aware model (BiDAF++ w/ 2-ctx), our best context-agnostic model (BiDAF++), and humans. Figure 7 contains three plots showing how F1 scores of baseline models and human agreement vary with (1) turn number, (2) distance from previous answer, 18 and (3) answer length in tokens. Taken as a whole, our analysis reveals significant qualitative differences between our context-aware and context-agnostic models beyond simply F1; additionally, human 18 We divide the text into 12 equally-sized chunks and compute the difference of the current and previous chunk indices.\n\nbehavior differs from that of both models.\n\nIn the first plot, human agreement is unchanged throughout the dialog while the performance of both models decreases as the number of turns increases, although the context-aware model degrades less. While continuing a dialog for more turns does not affect human agreement, the second plot shows that human disagreement increases as the distance between the current answer's location within the section text and that of the previous answer increases. Larger distances indicate shifts in the student's line of questioning (e.g., if the teacher told the student not to follow up on the previous question). The plot also shows that model performance suffers (significantly more than humans) as distance increases, although the contextaware model can tolerate smaller shifts better than the context-agnostic model. In the last plot, human agreement is higher when the answer span is short; in contrast, our model struggles to pin down short answers compared to longer ones.\n\nThe plots demonstrate the increased robustness of the context-aware model compared to BiDAF++. This finding is reinforced by examining the difference in model performance on questions where previously the teacher recommended the student to \"follow up\" vs. not to follow up. The context-aware baseline performs 6 HEQ-Q higher on the \"follow up\" questions; in contrast, the context-agnostic baseline shows no HEQ-Q difference between the two types of questions. This discrepancy stems from the context-agnostic Figure 7: The F1 scores of baseline models and human agreements based on dialog turn number, answer's distance from previous answer, and the answer span token length. model's inability to take advantage of the location of the previous answer.\n\n\nRelated Work\n\nReading Comprehension Our work builds on span based reading comprehension (Rajpurkar et al., 2016;Joshi et al., 2017;Trischler et al., 2016), while also incorporating innovations such as curating questions independently of supporting text to reduce trivial lexical overlap (Joshi et al., 2017;Kocisk\u00fd et al., 2017) and allowing for unanswerable questions (Trischler et al., 2016;Rajpurkar et al., 2018). We handle open-ended questions like in MSMARCO (Nguyen et al., 2016), with multiple references, but we are the first to incorporate these into information-seeking dialog.\n\nSequential QA Our work is similar to sequential question answering against knowledge bases (Iyyer et al., 2017) and the web (Talmor and Berant, 2018), but instead of decomposing a single question into smaller questions, we rely on the curiosity of the student to generate a sequence of questions. Such open information seeking was studied in semantic parsing on knowledge bases (Dahl et al., 1994) and more recently with modern approaches (Saha et al., 2018), but with questions paraphrased from templates. Concurrent to our work, Saeidi et al. (2018) proposed a task of generating and answering yes/no questions for rule focused text (such as traffic laws) by interacting with a user through dialog. Also concurrently, Reddy et al. (2018) propose conversational question answering (CoQA) from text but allow both students and questioners to see the evidence. As a result, a large percentage of CoQA answers are named entities or short noun phrases, much like those in SQuAD. In contrast, the asymmetric nature of forces students to ask more exploratory questions whose answers can be potentially be followed up on. 19\n\nDialog fits into an increasing interest in open domain dialog, mostly studied in the context of social chit-chat Ritter et al., 2011;Fang et al., 2017;Ghazvininejad et al., 2018). Most related to our effort is visual dialog (Das et al., 2017), which relies on images as evidence instead of text. More explicit goal driven scenarios, such as bargaining (Lewis et al., 2017) and item guessing (He et al., 2017) have also been explored, but the language is more constrained than in . Information-seeking dialog specifically was studied in Stede and Schlangen (2004).\n\n\nConclusion\n\nIn this paper, we introduce , a large scale dataset of information-seeking dialogs over sections from Wikipedia articles. Our data collection process, which takes the form of a teacher-student interaction between two crowd workers, encourages questions that are highly contextual, openended, and even unanswerable from the text. Our baselines, which include top performers on existing machine comprehension datasets, significantly underperform humans on . We hope this discrepancy will spur the development of machines that can more effectively participate in information seeking dialog.\n\n\u2192\nYes, Mel Blanc (...) contradicts that conventional belief . . .\n\nFigure 1 :\n1An example dialog about a Wikipedia section. The student, who does not see the section text, asks questions. The teacher provides a response in the form of a text span (or No answer ), optionally yes or no ( Yes / No ), and encouragement about continuing a line of questioning (should, \u2192 , could\u00af \u2192 , or should not \u2192 ask a follow-up question).\n\nFigure 2 :\n2A treemap visualization of the eight most frequent \"Wh\" words in , where box area is proportional to number of occurrences. Compared to other machine comprehension datasets, we observe increased contextuality and open-endedness, as well as a variety of both general and specific questions.\n\nFigure 3 :\n3An example successful dialog from . Questions build on each other and interesting aspects (e.g., plagiarism) are explored as they are discovered.\n\nFigure 4 :\n4A less successful dialog from\n\nFigure 5 :\n5) % dialogs that visit n th answer chunk (d) # unique answer chunks visited per dialog Heatmaps depicting the importance of context in dialogs, where (a) and\n\nTable 1 :\n1Comparison of the QUAC dataset to other question answering datasets.\n\nTable 2 :\n2Statistics summarizing the dataset.\n\n\nWhat other countries if any did he visit? What type of museum did Peggy plan to open? What were her troubles in 2016? What do critics say about them? What other movies did she do?why \n\nwho \n\nwhere \nwhen \ndid \nwhen \n\nwhat \nwas \n\nwhat \nis \n\nwhat \nhappened \nwhat \nelse \n\nwhat \ndid \nwhat \n\nwas \nPRN \n\nwas \nhow \ndid \nhow \n\ndid \nPRN \ndid \n\nwhat \n\ndid \n\nhow \nwas \n\nwhen \n\nwho \n\nwhere \n\nwhy \n\nwhat did \nwhat is \n\nwhat was \nwhat happened \nwhat else \n\nwhen did \n\nhow did \nwas PRN \n\ndid PRN \n\nWhat team was he with? \nWhat station did it air on? \n\nWhat was it about? \nWhat was the name of the single? \nWhat was Takemitsu's opinion of Debussy? \nWhat was their first album? \nWhat was one of his reforms? \nWhat was the driving force behind the name change? \n\nWhat is \nnotable about \nhis player \nprofile? \nWhat is \nRefused's \nmusical style? \n\nWhat did they try next? \nWhat did Doris \ncontribute to? \nWhat did they record? \nWhat did he do in there? \nWhat did she do after \ncollege? \n\nWhat happened \nafter that? \nWhat happened \nin 1983? \n\nWhat else must \none do? \nWhat else is \nnotable? \n\nDid the albums do well? \nDid Huxley teach his \nbeliefs? \nDid she rise in the \ncompany? \nDid Pamela cheat on \nChurchill? \n\nDid they have a lot of followers? \nDid she go on any tours after this? \nDid they win against Cuba? \nDid he marry? \nDid they serve any prison time? \nDid he have any conflicts with team mates? \nDid she win an award? \nDid he actually get a Muslim state started? \n\nHow was perversion handled? \nHow long was he there? \nHow popular did she become? \n\nHow did Mark Felt \ncontact Woodword? \nHow did the meeting go? \nHow did it do on the charts? \n\nWhen was she born? \nWhen was it founded? \nWhen was the \nbreakup? \n\nWhen did he \nget started \nin politics? \nWhen did he \ndie? \n\nWhere was the club \nbased? \nWhere was she from? \nWhere did Julianne \nHough tour? \n\nWhy did they meet at \nWoodside Hotel? \nWhy did he represent \nher? \n\nWhy did \nhe retire? \n\nWho promoted the film? \nWho was in The Go-Go's? \nWho was their father? \nWho acquired the rights to the \nband's back catalogs? \nWho was Emily influenced by? \n\nWas he very mean to these \nrelatives? \nWas she a happy child? \n\nWas it a \nsuccess? \n\nWas Villa ever the \ngovernor of Chihuahua? \nWas there another \nlawsuit? \n\nWas this report \nhelpful? \n\nHow does he try to \ntake over the world? \n\n\n\n\nSection: Augusto Pinochet : Intellectual life... STUDENT: Was he known for being intelligent? TEACHER: \u2192 No, Pinochet was publicly known as a man with a lack of culture. STUDENT: why did people feel that way? TEACHER: \u2192 reinforced by the fact that he also portrayed himself as a common man STUDENT: did he have any hobbies? TEACHER: \u2192 Yes, Before wresting power from Allende, Pinochet had written two books. STUDENT: what is the name of a book written by him? TEACHER: \u2192 Geopolitica (1968) and Campana de Tarapaca (1972). STUDENT: what were the books about? TEACHER: \u2192 Chile's military literature. STUDENT: was there anything noteworthy regarding his books?TEACHER: \n\n\u2192 Yes, In Geopolitica Pinochet pla-\ngiarized (...) Gregorio Rodriguez Tascon \nSTUDENT: did he deny those allegations? \n\nTEACHER: \n\n\u2192 No answer \nSTUDENT: what did he plagiarize in Geopolitica? \nTEACHER:\u00af \u2192 In Geopolitica Pinochet plagia-\nrized (...) paragraphs from a 1949 presentation \n. . . \n\n\n\n\nSection: Gaelic Ireland : Invasion STUDENT: What year did the invasion happen? TEACHER: \u2192 in 1169 the main body of Norman, Welsh and Flemish forces landed in Ireland and quickly retook Leinster and the cities of Waterford and Dublin on behalf of Diarmait. STUDENT: Who was Diarmait? TEACHER:\u00af \u2192 King Diarmait Mac Murchada of Leinster. STUDENT: Where is Leinster located? TEACHER: \u2192 landed in Ireland and quickly re-Who lead the invasion? TEACHER: \u2192 No answer STUDENT: Did England defeat the Irish armies? TEACHER: \u2192 No answertook Leinster. \nSTUDENT: Were invasions common? \nTEACHER: \u2192 No answer \nSTUDENT: Are there any other interesting as-\npects about this article? \nTEACHER:\u00af \u2192 Yes, IPope Adrian IV, the only \nEnglish pope, had already issued a Papal Bull \nin 1155 giving Henry II of England authority \nto invade Ireland. \nSTUDENT: \n\nTable 4\n4summarizes our results (each cell displays \ndev/test scores), where dialog acts are Yes/No (af-\nfirmation) and Follow up (continuation). For com-\nparison to other datasets, we report F1 without fil-\ntering low-agreement QA pairs (F1'). \n\n\n\nTable 4 :\n4baselines perform poorly, while models that incorporate the dialog context significantly outperform those that do not. Humans outperform our best model by a large margin, indicating room for future improvement.Experimental results of sanity checks (top), baselines (middle) and upper bounds (bottom) on \n. Simple \ntext matching \nWe use \"dialog\" to refer to a sequence of QA pairs. Authors contributed equally.\nWe set the maximum answer length to 30 tokens to prevent teachers from revealing the full article all at once.\nOn average, we paid $0.33 per question, increasing pay per question as dialogs got longer to encourage completion. 4 http://quac.ai/datasheet.pdf 5 https://petscan.wmflabs.org/ 6 These filtering steps bias our data towards entertainers; see datasheet for details.\nA manual inspection of annotations below this threshold revealed many lower quality questions; however, we also report unthresholded F1 in the final column ofTable 4.\nIn cases with lower human agreement on F1, if a system produces one reference exactly (F1 = 100), it will get points that it can use to offset poor performance on other examples.\nWe did not collect multiple annotations for the continuation dialog act and so omit it.\nOn average, CoQA answers are 2.7 tokens long, while SQuAD's are 3.2 tokens and 's are over 14 tokens.\nAcknowledgments was jointly funded by the Allen Institute for Artificial Intelligence and the DARPA CwC program through ARO (W911NF-15-1-0543). We would like to thank anonymous reviewers and Hsin-Yuan Huang who helped improve the draft.\nSimple and effective multi-paragraph reading comprehension. Christopher Clark, Matt Gardner, Proceedings of the Association for Computational Linguistics. the Association for Computational LinguisticsChristopher Clark and Matt Gardner. 2018. Simple and effective multi-paragraph reading comprehen- sion. Proceedings of the Association for Computa- tional Linguistics.\n\nSupervised learning of universal sentence representations from natural language inference data. Alexis Conneau, Douwe Kiela, Holger Schwenk, Loic Barrault, Antoine Bordes, Proceedings of Empirical Methods in Natural Language Processing. Empirical Methods in Natural Language ProcessingAlexis Conneau, Douwe Kiela, Holger Schwenk, Loic Barrault, and Antoine Bordes. 2017. Supervised learning of universal sentence representations from natural language inference data. In Proceedings of Empirical Methods in Natural Language Process- ing.\n\n. Deborah A Dahl, Madeleine Bates, Michael Brown, William M Fisher, Kate Hunicke-Smith, S David, Deborah A. Dahl, Madeleine Bates, Michael Brown, William M. Fisher, Kate Hunicke-Smith, David S.\n\nExpanding the scope of the atis task: The atis-3 corpus. Christine Pallett, Alexander I Pao, Elizabeth Rudnicky, Shriberg, Proceedings of the workshop on Human Language Technology. the workshop on Human Language TechnologyPallett, Christine Pao, Alexander I. Rudnicky, and Elizabeth Shriberg. 1994. Expanding the scope of the atis task: The atis-3 corpus. In Proceedings of the workshop on Human Language Technology.\n\nAbhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav, M F Jos\u00e9, Devi Moura, Dhruv Parikh, Batra, Computer Vision and Pattern Recognition. Visual dialogAbhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav, Jos\u00e9 MF Moura, Devi Parikh, and Dhruv Batra. 2017. Visual dialog. In Computer Vision and Pattern Recognition.\n\nSounding board-university of washingtons alexa prize submission. Hao Fang, Hao Cheng, Elizabeth Clark, Ariel Holtzman, Maarten Sap, Mari Ostendorf, Yejin Choi, Noah A Smith, Alexa Prize ProceedingsHao Fang, Hao Cheng, Elizabeth Clark, Ariel Holtz- man, Maarten Sap, Mari Ostendorf, Yejin Choi, and Noah A Smith. 2017. Sounding board-university of washingtons alexa prize submission. Alexa Prize Proceedings.\n\nAllennlp: A deep semantic natural language processing platform. Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson F Liu, Matthew Peters, Michael Schmitz, Luke S Zettlemoyer, Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson F. Liu, Matthew Peters, Michael Schmitz, and Luke S. Zettlemoyer. 2017. Allennlp: A deep semantic natural language processing platform.\n\nA knowledge-grounded neural conversation model. Association for the Advancement of Artificial Intelligence. Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wen-Tau Yih, Michel Galley, Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wen-tau Yih, and Michel Galley. 2018. A knowledge-grounded neural conversation model. Association for the Advance- ment of Artificial Intelligence.\n\nLearning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings. He He, Anusha Balakrishnan, Mihail Eric, Percy Liang, Proceedings of the Association for Computational Linguistics. the Association for Computational LinguisticsHe He, Anusha Balakrishnan, Mihail Eric, and Percy Liang. 2017. Learning symmetric collaborative di- alogue agents with dynamic knowledge graph em- beddings. Proceedings of the Association for Com- putational Linguistics.\n\nSearch-based neural structured learning for sequential question answering. Mohit Iyyer, Ming-Wei Wen Tau Yih, Chang, Proceedings of the Association for Computational Linguistics. the Association for Computational LinguisticsMohit Iyyer, Wen tau Yih, and Ming-Wei Chang. 2017. Search-based neural structured learning for sequen- tial question answering. In Proceedings of the Asso- ciation for Computational Linguistics.\n\nTriviaqa: A large scale distantly supervised challenge dataset for reading comprehension. Mandar Joshi, Eunsol Choi, Daniel S Weld, Luke Zettlemoyer, Proceedings of the Association for Computational Linguistics. the Association for Computational LinguisticsMandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehen- sion. In Proceedings of the Association for Compu- tational Linguistics.\n\nAnalysis of wikipedia-based corpora for question answering. Tomasz Jurczyk, Amit Deshmane, Jinho D Choi, arXiv:abs/1801.02073arXiv preprintTomasz Jurczyk, Amit Deshmane, and Jinho D. Choi. 2018. Analysis of wikipedia-based cor- pora for question answering. arXiv preprint arXiv:abs/1801.02073.\n\nThe narrativeqa reading comprehension challenge. Tom\u00e1s Kocisk\u00fd, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, G\u00e1bor Melis, Edward Grefenstette, abs/1712.07040Transactions of the Association for Computational Linguistics. Tom\u00e1s Kocisk\u00fd, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, G\u00e1bor Melis, and Edward Grefenstette. 2017. The narrativeqa reading comprehension challenge. Transactions of the Association for Computational Linguistics, abs/1712.07040.\n\nVowpal wabbit online learning project. John Langford, Lihong Li, Alex Strehl, John Langford, Lihong Li, and Alex Strehl. 2007. Vowpal wabbit online learning project.\n\nZero-shot relation extraction via reading comprehension. Omer Levy, Minjoon Seo, Eunsol Choi, Luke S Zettlemoyer, Conference on Computational Natural Language Learning. Omer Levy, Minjoon Seo, Eunsol Choi, and Luke S. Zettlemoyer. 2017. Zero-shot relation extraction via reading comprehension. In Conference on Compu- tational Natural Language Learning.\n\nDeal or no deal? end-to-end learning for negotiation dialogues. Proceedings of Empirical Methods in Natural Language Processing. Mike Lewis, Denis Yarats, Devi Yann N Dauphin, Dhruv Parikh, Batra, Mike Lewis, Denis Yarats, Yann N Dauphin, Devi Parikh, and Dhruv Batra. 2017. Deal or no deal? end-to-end learning for negotiation dialogues. Pro- ceedings of Empirical Methods in Natural Language Processing.\n\nDeep reinforcement learning for dialogue generation. Proceedings of Empirical Methods in Natural Language Processing. Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, Dan Jurafsky, Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, and Dan Jurafsky. 2016. Deep re- inforcement learning for dialogue generation. Pro- ceedings of Empirical Methods in Natural Language Processing.\n\nMs marco: A human generated machine read. Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, ing comprehension dataset. arXiv, abs/1611.09268Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng. 2016. Ms marco: A human generated machine read- ing comprehension dataset. arXiv, abs/1611.09268.\n\nE Matthew, Mark Peters, Mohit Neumann, Matt Iyyer, Christopher Gardner, Kenton Clark, Luke Lee, Zettlemoyer, Deep contextualized word representations. Conference of the North American Chapter of the Association for Computational Linguistics. Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word rep- resentations. Conference of the North American Chapter of the Association for Computational Lin- guistics.\n\nKnow what you don't know: Unanswerable questions for squad. Pranav Rajpurkar, Robin Jia, Percy Liang, Proceedings of the Association for Computational Linguistics. the Association for Computational LinguisticsPranav Rajpurkar, Robin Jia, and Percy Liang. 2018. Know what you don't know: Unanswerable ques- tions for squad. In Proceedings of the Association for Computational Linguistics.\n\nSquad: 100,000+ questions for machine comprehension of text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, Proceedings of Empirical Methods in Natural Language Processing. Empirical Methods in Natural Language ProcessingPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text. In Proceedings of Empirical Methods in Natural Language Process- ing.\n\nCoqa: A conversational question answering challenge. Siva Reddy, Danqi Chen, Christopher D Manning, ArXivSiva Reddy, Danqi Chen, and Christopher D. Manning. 2018. Coqa: A conversational question answering challenge. ArXiv.\n\nData-driven response generation in social media. Alan Ritter, Colin Cherry, William B Dolan, Proceedings of Empirical Methods in Natural Language Processing. Empirical Methods in Natural Language ProcessingAlan Ritter, Colin Cherry, and William B. Dolan. 2011. Data-driven response generation in social media. In Proceedings of Empirical Methods in Natural Lan- guage Processing.\n\nInterpretation of natural language rules in conversational machine reading. Marzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer Signh, Tim Rocktschel, Mike Sheldon, Guillaume Bouchard, Sebastian Riedel, Proceedings of Empirical Methods in Natural Language Processing. Empirical Methods in Natural Language ProcessingMarzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer Signh, Tim Rocktschel, Mike Sheldon, Guillaume Bouchard, and Sebastian Riedel. 2018. Interpreta- tion of natural language rules in conversational ma- chine reading. In Proceedings of Empirical Methods in Natural Language Processing.\n\nComplex sequential question answering: Towards learning to converse over linked question answer pairs with a knowledge graph. Amrita Saha, Vardaan Pahuja, M Mitesh, Karthik Khapra, Sarath Sankaranarayanan, Chandar, Association for the Advancement of Artificial Intelligence. Amrita Saha, Vardaan Pahuja, Mitesh M Khapra, Karthik Sankaranarayanan, and Sarath Chandar. 2018. Complex sequential question answering: To- wards learning to converse over linked question an- swer pairs with a knowledge graph. In Association for the Advancement of Artificial Intelligence.\n\nBidirectional attention flow for machine comprehension. Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi, Proceedings of the International Conference on Learning Representations. the International Conference on Learning RepresentationsMinjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and Hannaneh Hajishirzi. 2016. Bidirectional attention flow for machine comprehension. Proceedings of the International Conference on Learning Represen- tations.\n\nInformation-seeking chat: Dialogues driven by topic-structure. Manfred Stede, David Schlangen, Eighth workshop on the semantics and pragmatics of dialogue. SemDialManfred Stede and David Schlangen. 2004. Information-seeking chat: Dialogues driven by topic-structure. In Eighth workshop on the seman- tics and pragmatics of dialogue; SemDial.\n\nYago: a core of semantic knowledge. Fabian M Suchanek, Gjergji Kasneci, Gerhard Weikum, Proceedings of the World Wide Web Conference. the World Wide Web ConferenceFabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowl- edge. In Proceedings of the World Wide Web Con- ference.\n\nThe web as knowledgebase for answering complex questions. A Talmor, J Berant, Conference of the North American Chapter of the Association for Computational Linguistics. A. Talmor and J. Berant. 2018. The web as knowledge- base for answering complex questions. In Confer- ence of the North American Chapter of the Associa- tion for Computational Linguistics.\n\nAdam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, Kaheer Suleman, arXiv:1611.09830Newsqa: A machine comprehension dataset. arXiv preprintAdam Trischler, Tong Wang, Xingdi Yuan, Justin Har- ris, Alessandro Sordoni, Philip Bachman, and Ka- heer Suleman. 2016. Newsqa: A machine compre- hension dataset. arXiv preprint arXiv:1611.09830.\n", "annotations": {"author": "[{\"end\":312,\"start\":166},{\"end\":427,\"start\":313},{\"end\":567,\"start\":428},{\"end\":685,\"start\":568},{\"end\":826,\"start\":686},{\"end\":948,\"start\":827},{\"end\":1069,\"start\":949},{\"end\":1181,\"start\":1070},{\"end\":1326,\"start\":1182},{\"end\":1453,\"start\":1327}]", "publisher": "[{\"end\":79,\"start\":38},{\"end\":1708,\"start\":1667}]", "author_last_name": "[{\"end\":177,\"start\":173},{\"end\":317,\"start\":315},{\"end\":438,\"start\":433},{\"end\":698,\"start\":691},{\"end\":838,\"start\":835},{\"end\":959,\"start\":955},{\"end\":1193,\"start\":1188},{\"end\":1343,\"start\":1332}]", "author_first_name": "[{\"end\":172,\"start\":166},{\"end\":314,\"start\":313},{\"end\":430,\"start\":428},{\"end\":432,\"start\":431},{\"end\":573,\"start\":568},{\"end\":575,\"start\":574},{\"end\":690,\"start\":686},{\"end\":834,\"start\":827},{\"end\":954,\"start\":949},{\"end\":1071,\"start\":1070},{\"end\":1187,\"start\":1182},{\"end\":1331,\"start\":1327}]", "author_affiliation": "[{\"end\":311,\"start\":204},{\"end\":426,\"start\":319},{\"end\":566,\"start\":459},{\"end\":684,\"start\":577},{\"end\":825,\"start\":718},{\"end\":947,\"start\":840},{\"end\":1068,\"start\":961},{\"end\":1180,\"start\":1073},{\"end\":1325,\"start\":1218},{\"end\":1452,\"start\":1345}]", "title": "[{\"end\":37,\"start\":1},{\"end\":1490,\"start\":1454}]", "venue": "[{\"end\":1578,\"start\":1492}]", "abstract": "[{\"end\":2702,\"start\":1747}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b26\"},\"end\":2854,\"start\":2827},{\"end\":3493,\"start\":3485},{\"end\":3535,\"start\":3527},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4200,\"start\":4176},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":4337,\"start\":4317},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4362,\"start\":4343},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4392,\"start\":4367},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4416,\"start\":4397},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4452,\"start\":4430},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4481,\"start\":4462},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4517,\"start\":4493},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4548,\"start\":4527},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":4580,\"start\":4556},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4906,\"start\":4881},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4924,\"start\":4906},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5001,\"start\":4981},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5286,\"start\":5265},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7227,\"start\":7207},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7264,\"start\":7240},{\"end\":9431,\"start\":9430},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9594,\"start\":9571},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":11315,\"start\":11293},{\"end\":11720,\"start\":11719},{\"end\":11867,\"start\":11866},{\"end\":12259,\"start\":12257},{\"end\":16694,\"start\":16691},{\"end\":17627,\"start\":17625},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20306,\"start\":20284},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20473,\"start\":20451},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20848,\"start\":20827},{\"end\":20917,\"start\":20892},{\"end\":20972,\"start\":20970},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":21065,\"start\":21047},{\"end\":22503,\"start\":22501},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22539,\"start\":22517},{\"end\":22782,\"start\":22780},{\"end\":24208,\"start\":24206},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":26208,\"start\":26184},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":26227,\"start\":26208},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":26250,\"start\":26227},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":26403,\"start\":26383},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":26424,\"start\":26403},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":26489,\"start\":26465},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":26512,\"start\":26489},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":26582,\"start\":26561},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":26797,\"start\":26777},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":26835,\"start\":26810},{\"end\":27083,\"start\":27064},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":27144,\"start\":27125},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":27237,\"start\":27217},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":27425,\"start\":27406},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":27939,\"start\":27919},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":27957,\"start\":27939},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27984,\"start\":27957},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":28048,\"start\":28030},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":28178,\"start\":28158},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":28214,\"start\":28197},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":28368,\"start\":28342}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":29038,\"start\":28972},{\"attributes\":{\"id\":\"fig_1\"},\"end\":29395,\"start\":29039},{\"attributes\":{\"id\":\"fig_2\"},\"end\":29698,\"start\":29396},{\"attributes\":{\"id\":\"fig_3\"},\"end\":29857,\"start\":29699},{\"attributes\":{\"id\":\"fig_4\"},\"end\":29900,\"start\":29858},{\"attributes\":{\"id\":\"fig_5\"},\"end\":30071,\"start\":29901},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":30152,\"start\":30072},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":30200,\"start\":30153},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":32522,\"start\":30201},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":33487,\"start\":32523},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":34324,\"start\":33488},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":34573,\"start\":34325},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":34914,\"start\":34574}]", "paragraph": "[{\"end\":3569,\"start\":2718},{\"end\":3713,\"start\":3582},{\"end\":4630,\"start\":3715},{\"end\":5809,\"start\":4632},{\"end\":6068,\"start\":5811},{\"end\":6333,\"start\":6091},{\"end\":7265,\"start\":6354},{\"end\":8019,\"start\":7267},{\"end\":8447,\"start\":8021},{\"end\":9013,\"start\":8470},{\"end\":9748,\"start\":9015},{\"end\":10707,\"start\":9750},{\"end\":11121,\"start\":10742},{\"end\":11982,\"start\":11151},{\"end\":12885,\"start\":11984},{\"end\":13229,\"start\":12887},{\"end\":14169,\"start\":13231},{\"end\":15289,\"start\":14171},{\"end\":15835,\"start\":15335},{\"end\":16260,\"start\":15837},{\"end\":16838,\"start\":16283},{\"end\":18129,\"start\":16840},{\"end\":18773,\"start\":18131},{\"end\":18875,\"start\":18775},{\"end\":19021,\"start\":18907},{\"end\":19182,\"start\":19023},{\"end\":19471,\"start\":19184},{\"end\":19652,\"start\":19488},{\"end\":19857,\"start\":19654},{\"end\":20120,\"start\":19859},{\"end\":20365,\"start\":20134},{\"end\":20757,\"start\":20367},{\"end\":21248,\"start\":20769},{\"end\":21452,\"start\":21250},{\"end\":21611,\"start\":21454},{\"end\":22079,\"start\":21613},{\"end\":23664,\"start\":22106},{\"end\":24326,\"start\":23683},{\"end\":24370,\"start\":24328},{\"end\":25340,\"start\":24372},{\"end\":26093,\"start\":25342},{\"end\":26684,\"start\":26110},{\"end\":27804,\"start\":26686},{\"end\":28369,\"start\":27806},{\"end\":28971,\"start\":28384}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":6212,\"start\":6205},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":10065,\"start\":10058},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":11087,\"start\":11080},{\"end\":12513,\"start\":12506},{\"end\":14870,\"start\":14863}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2716,\"start\":2704},{\"end\":3580,\"start\":3572},{\"attributes\":{\"n\":\"2\"},\"end\":6089,\"start\":6071},{\"attributes\":{\"n\":\"2.1\"},\"end\":6352,\"start\":6336},{\"attributes\":{\"n\":\"2.2\"},\"end\":8468,\"start\":8450},{\"end\":10740,\"start\":10710},{\"end\":11149,\"start\":11124},{\"end\":15312,\"start\":15292},{\"attributes\":{\"n\":\"4\"},\"end\":15333,\"start\":15315},{\"attributes\":{\"n\":\"4.1\"},\"end\":16281,\"start\":16263},{\"attributes\":{\"n\":\"5\"},\"end\":18889,\"start\":18878},{\"attributes\":{\"n\":\"5.1\"},\"end\":18905,\"start\":18892},{\"attributes\":{\"n\":\"5.2\"},\"end\":19486,\"start\":19474},{\"attributes\":{\"n\":\"5.3\"},\"end\":20132,\"start\":20123},{\"end\":20767,\"start\":20760},{\"attributes\":{\"n\":\"5.4\"},\"end\":22089,\"start\":22082},{\"end\":22104,\"start\":22092},{\"attributes\":{\"n\":\"5.5\"},\"end\":23681,\"start\":23667},{\"attributes\":{\"n\":\"6\"},\"end\":26108,\"start\":26096},{\"attributes\":{\"n\":\"7\"},\"end\":28382,\"start\":28372},{\"end\":28974,\"start\":28973},{\"end\":29050,\"start\":29040},{\"end\":29407,\"start\":29397},{\"end\":29710,\"start\":29700},{\"end\":29869,\"start\":29859},{\"end\":29912,\"start\":29902},{\"end\":30082,\"start\":30073},{\"end\":30163,\"start\":30154},{\"end\":34333,\"start\":34326},{\"end\":34584,\"start\":34575}]", "table": "[{\"end\":32522,\"start\":30382},{\"end\":33487,\"start\":33182},{\"end\":34324,\"start\":34015},{\"end\":34573,\"start\":34335},{\"end\":34914,\"start\":34796}]", "figure_caption": "[{\"end\":29038,\"start\":28975},{\"end\":29395,\"start\":29052},{\"end\":29698,\"start\":29409},{\"end\":29857,\"start\":29712},{\"end\":29900,\"start\":29871},{\"end\":30071,\"start\":29914},{\"end\":30152,\"start\":30084},{\"end\":30200,\"start\":30165},{\"end\":30382,\"start\":30203},{\"end\":33182,\"start\":32525},{\"end\":34015,\"start\":33490},{\"end\":34796,\"start\":34586}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":3204,\"start\":3196},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":6488,\"start\":6480},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":11636,\"start\":11628},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":12984,\"start\":12975},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":13324,\"start\":13315},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":13415,\"start\":13406},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":13971,\"start\":13961},{\"end\":14278,\"start\":14270},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":14666,\"start\":14651},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":14768,\"start\":14760},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":15223,\"start\":15215},{\"end\":16881,\"start\":16873},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":19359,\"start\":19350},{\"end\":23858,\"start\":23850},{\"end\":25859,\"start\":25851}]", "bib_author_first_name": "[{\"end\":36215,\"start\":36204},{\"end\":36227,\"start\":36223},{\"end\":36615,\"start\":36609},{\"end\":36630,\"start\":36625},{\"end\":36644,\"start\":36638},{\"end\":36658,\"start\":36654},{\"end\":36676,\"start\":36669},{\"end\":37060,\"start\":37053},{\"end\":37062,\"start\":37061},{\"end\":37078,\"start\":37069},{\"end\":37093,\"start\":37086},{\"end\":37108,\"start\":37101},{\"end\":37110,\"start\":37109},{\"end\":37123,\"start\":37119},{\"end\":37140,\"start\":37139},{\"end\":37312,\"start\":37303},{\"end\":37331,\"start\":37322},{\"end\":37333,\"start\":37332},{\"end\":37348,\"start\":37339},{\"end\":37672,\"start\":37664},{\"end\":37684,\"start\":37678},{\"end\":37699,\"start\":37693},{\"end\":37710,\"start\":37707},{\"end\":37725,\"start\":37718},{\"end\":37734,\"start\":37733},{\"end\":37736,\"start\":37735},{\"end\":37747,\"start\":37743},{\"end\":37760,\"start\":37755},{\"end\":38078,\"start\":38075},{\"end\":38088,\"start\":38085},{\"end\":38105,\"start\":38096},{\"end\":38118,\"start\":38113},{\"end\":38136,\"start\":38129},{\"end\":38146,\"start\":38142},{\"end\":38163,\"start\":38158},{\"end\":38176,\"start\":38170},{\"end\":38487,\"start\":38483},{\"end\":38501,\"start\":38497},{\"end\":38512,\"start\":38508},{\"end\":38528,\"start\":38522},{\"end\":38545,\"start\":38538},{\"end\":38560,\"start\":38554},{\"end\":38562,\"start\":38561},{\"end\":38575,\"start\":38568},{\"end\":38591,\"start\":38584},{\"end\":38605,\"start\":38601},{\"end\":38607,\"start\":38606},{\"end\":38950,\"start\":38944},{\"end\":38971,\"start\":38966},{\"end\":38990,\"start\":38982},{\"end\":39002,\"start\":38998},{\"end\":39018,\"start\":39010},{\"end\":39031,\"start\":39024},{\"end\":39043,\"start\":39037},{\"end\":39373,\"start\":39371},{\"end\":39384,\"start\":39378},{\"end\":39405,\"start\":39399},{\"end\":39417,\"start\":39412},{\"end\":39835,\"start\":39830},{\"end\":39851,\"start\":39843},{\"end\":40272,\"start\":40266},{\"end\":40286,\"start\":40280},{\"end\":40299,\"start\":40293},{\"end\":40301,\"start\":40300},{\"end\":40312,\"start\":40308},{\"end\":40730,\"start\":40724},{\"end\":40744,\"start\":40740},{\"end\":40760,\"start\":40755},{\"end\":40762,\"start\":40761},{\"end\":41013,\"start\":41008},{\"end\":41031,\"start\":41023},{\"end\":41045,\"start\":41041},{\"end\":41060,\"start\":41055},{\"end\":41071,\"start\":41067},{\"end\":41078,\"start\":41072},{\"end\":41093,\"start\":41088},{\"end\":41107,\"start\":41101},{\"end\":41495,\"start\":41491},{\"end\":41512,\"start\":41506},{\"end\":41521,\"start\":41517},{\"end\":41680,\"start\":41676},{\"end\":41694,\"start\":41687},{\"end\":41706,\"start\":41700},{\"end\":41717,\"start\":41713},{\"end\":41719,\"start\":41718},{\"end\":42107,\"start\":42103},{\"end\":42120,\"start\":42115},{\"end\":42133,\"start\":42129},{\"end\":42155,\"start\":42150},{\"end\":42504,\"start\":42499},{\"end\":42513,\"start\":42509},{\"end\":42526,\"start\":42522},{\"end\":42541,\"start\":42535},{\"end\":42558,\"start\":42550},{\"end\":42567,\"start\":42564},{\"end\":42835,\"start\":42832},{\"end\":42847,\"start\":42844},{\"end\":42862,\"start\":42859},{\"end\":42877,\"start\":42869},{\"end\":42890,\"start\":42883},{\"end\":42905,\"start\":42899},{\"end\":42918,\"start\":42916},{\"end\":43170,\"start\":43169},{\"end\":43184,\"start\":43180},{\"end\":43198,\"start\":43193},{\"end\":43212,\"start\":43208},{\"end\":43231,\"start\":43220},{\"end\":43247,\"start\":43241},{\"end\":43259,\"start\":43255},{\"end\":43733,\"start\":43727},{\"end\":43750,\"start\":43745},{\"end\":43761,\"start\":43756},{\"end\":44123,\"start\":44117},{\"end\":44139,\"start\":44135},{\"end\":44157,\"start\":44147},{\"end\":44172,\"start\":44167},{\"end\":44555,\"start\":44551},{\"end\":44568,\"start\":44563},{\"end\":44586,\"start\":44575},{\"end\":44588,\"start\":44587},{\"end\":44775,\"start\":44771},{\"end\":44789,\"start\":44784},{\"end\":44805,\"start\":44798},{\"end\":44807,\"start\":44806},{\"end\":45186,\"start\":45179},{\"end\":45198,\"start\":45195},{\"end\":45215,\"start\":45208},{\"end\":45229,\"start\":45223},{\"end\":45240,\"start\":45237},{\"end\":45257,\"start\":45253},{\"end\":45276,\"start\":45267},{\"end\":45296,\"start\":45287},{\"end\":45835,\"start\":45829},{\"end\":45849,\"start\":45842},{\"end\":45859,\"start\":45858},{\"end\":45875,\"start\":45868},{\"end\":45890,\"start\":45884},{\"end\":46333,\"start\":46326},{\"end\":46348,\"start\":46339},{\"end\":46362,\"start\":46359},{\"end\":46380,\"start\":46372},{\"end\":46801,\"start\":46794},{\"end\":46814,\"start\":46809},{\"end\":47116,\"start\":47110},{\"end\":47118,\"start\":47117},{\"end\":47136,\"start\":47129},{\"end\":47153,\"start\":47146},{\"end\":47449,\"start\":47448},{\"end\":47459,\"start\":47458},{\"end\":47753,\"start\":47749},{\"end\":47769,\"start\":47765},{\"end\":47782,\"start\":47776},{\"end\":47795,\"start\":47789},{\"end\":47814,\"start\":47804},{\"end\":47830,\"start\":47824},{\"end\":47846,\"start\":47840}]", "bib_author_last_name": "[{\"end\":36221,\"start\":36216},{\"end\":36235,\"start\":36228},{\"end\":36623,\"start\":36616},{\"end\":36636,\"start\":36631},{\"end\":36652,\"start\":36645},{\"end\":36667,\"start\":36659},{\"end\":36683,\"start\":36677},{\"end\":37067,\"start\":37063},{\"end\":37084,\"start\":37079},{\"end\":37099,\"start\":37094},{\"end\":37117,\"start\":37111},{\"end\":37137,\"start\":37124},{\"end\":37146,\"start\":37141},{\"end\":37320,\"start\":37313},{\"end\":37337,\"start\":37334},{\"end\":37357,\"start\":37349},{\"end\":37367,\"start\":37359},{\"end\":37676,\"start\":37673},{\"end\":37691,\"start\":37685},{\"end\":37705,\"start\":37700},{\"end\":37716,\"start\":37711},{\"end\":37731,\"start\":37726},{\"end\":37741,\"start\":37737},{\"end\":37753,\"start\":37748},{\"end\":37767,\"start\":37761},{\"end\":37774,\"start\":37769},{\"end\":38083,\"start\":38079},{\"end\":38094,\"start\":38089},{\"end\":38111,\"start\":38106},{\"end\":38127,\"start\":38119},{\"end\":38140,\"start\":38137},{\"end\":38156,\"start\":38147},{\"end\":38168,\"start\":38164},{\"end\":38182,\"start\":38177},{\"end\":38495,\"start\":38488},{\"end\":38506,\"start\":38502},{\"end\":38520,\"start\":38513},{\"end\":38536,\"start\":38529},{\"end\":38552,\"start\":38546},{\"end\":38566,\"start\":38563},{\"end\":38582,\"start\":38576},{\"end\":38599,\"start\":38592},{\"end\":38619,\"start\":38608},{\"end\":38964,\"start\":38951},{\"end\":38980,\"start\":38972},{\"end\":38996,\"start\":38991},{\"end\":39008,\"start\":39003},{\"end\":39022,\"start\":39019},{\"end\":39035,\"start\":39032},{\"end\":39050,\"start\":39044},{\"end\":39376,\"start\":39374},{\"end\":39397,\"start\":39385},{\"end\":39410,\"start\":39406},{\"end\":39423,\"start\":39418},{\"end\":39841,\"start\":39836},{\"end\":39863,\"start\":39852},{\"end\":39870,\"start\":39865},{\"end\":40278,\"start\":40273},{\"end\":40291,\"start\":40287},{\"end\":40306,\"start\":40302},{\"end\":40324,\"start\":40313},{\"end\":40738,\"start\":40731},{\"end\":40753,\"start\":40745},{\"end\":40767,\"start\":40763},{\"end\":41021,\"start\":41014},{\"end\":41039,\"start\":41032},{\"end\":41053,\"start\":41046},{\"end\":41065,\"start\":41061},{\"end\":41086,\"start\":41079},{\"end\":41099,\"start\":41094},{\"end\":41120,\"start\":41108},{\"end\":41504,\"start\":41496},{\"end\":41515,\"start\":41513},{\"end\":41528,\"start\":41522},{\"end\":41685,\"start\":41681},{\"end\":41698,\"start\":41695},{\"end\":41711,\"start\":41707},{\"end\":41731,\"start\":41720},{\"end\":42113,\"start\":42108},{\"end\":42127,\"start\":42121},{\"end\":42148,\"start\":42134},{\"end\":42162,\"start\":42156},{\"end\":42169,\"start\":42164},{\"end\":42507,\"start\":42505},{\"end\":42520,\"start\":42514},{\"end\":42533,\"start\":42527},{\"end\":42548,\"start\":42542},{\"end\":42562,\"start\":42559},{\"end\":42576,\"start\":42568},{\"end\":42842,\"start\":42836},{\"end\":42857,\"start\":42848},{\"end\":42867,\"start\":42863},{\"end\":42881,\"start\":42878},{\"end\":42897,\"start\":42891},{\"end\":42914,\"start\":42906},{\"end\":42923,\"start\":42919},{\"end\":43178,\"start\":43171},{\"end\":43191,\"start\":43185},{\"end\":43206,\"start\":43199},{\"end\":43218,\"start\":43213},{\"end\":43239,\"start\":43232},{\"end\":43253,\"start\":43248},{\"end\":43263,\"start\":43260},{\"end\":43276,\"start\":43265},{\"end\":43743,\"start\":43734},{\"end\":43754,\"start\":43751},{\"end\":43767,\"start\":43762},{\"end\":44133,\"start\":44124},{\"end\":44145,\"start\":44140},{\"end\":44165,\"start\":44158},{\"end\":44178,\"start\":44173},{\"end\":44561,\"start\":44556},{\"end\":44573,\"start\":44569},{\"end\":44596,\"start\":44589},{\"end\":44782,\"start\":44776},{\"end\":44796,\"start\":44790},{\"end\":44813,\"start\":44808},{\"end\":45193,\"start\":45187},{\"end\":45206,\"start\":45199},{\"end\":45221,\"start\":45216},{\"end\":45235,\"start\":45230},{\"end\":45251,\"start\":45241},{\"end\":45265,\"start\":45258},{\"end\":45285,\"start\":45277},{\"end\":45303,\"start\":45297},{\"end\":45840,\"start\":45836},{\"end\":45856,\"start\":45850},{\"end\":45866,\"start\":45860},{\"end\":45882,\"start\":45876},{\"end\":45907,\"start\":45891},{\"end\":45916,\"start\":45909},{\"end\":46337,\"start\":46334},{\"end\":46357,\"start\":46349},{\"end\":46370,\"start\":46363},{\"end\":46391,\"start\":46381},{\"end\":46807,\"start\":46802},{\"end\":46824,\"start\":46815},{\"end\":47127,\"start\":47119},{\"end\":47144,\"start\":47137},{\"end\":47160,\"start\":47154},{\"end\":47456,\"start\":47450},{\"end\":47466,\"start\":47460},{\"end\":47763,\"start\":47754},{\"end\":47774,\"start\":47770},{\"end\":47787,\"start\":47783},{\"end\":47802,\"start\":47796},{\"end\":47822,\"start\":47815},{\"end\":47838,\"start\":47831},{\"end\":47854,\"start\":47847}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":223637},\"end\":36511,\"start\":36144},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":28971531},\"end\":37049,\"start\":36513},{\"attributes\":{\"id\":\"b2\"},\"end\":37244,\"start\":37051},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":8180378},\"end\":37662,\"start\":37246},{\"attributes\":{\"id\":\"b4\"},\"end\":38008,\"start\":37664},{\"attributes\":{\"id\":\"b5\"},\"end\":38417,\"start\":38010},{\"attributes\":{\"id\":\"b6\"},\"end\":38834,\"start\":38419},{\"attributes\":{\"id\":\"b7\"},\"end\":39279,\"start\":38836},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":3051772},\"end\":39753,\"start\":39281},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":2623009},\"end\":40174,\"start\":39755},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":26501419},\"end\":40662,\"start\":40176},{\"attributes\":{\"doi\":\"arXiv:abs/1801.02073\",\"id\":\"b11\"},\"end\":40957,\"start\":40664},{\"attributes\":{\"doi\":\"abs/1712.07040\",\"id\":\"b12\",\"matched_paper_id\":2593903},\"end\":41450,\"start\":40959},{\"attributes\":{\"id\":\"b13\"},\"end\":41617,\"start\":41452},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":793385},\"end\":41972,\"start\":41619},{\"attributes\":{\"id\":\"b15\"},\"end\":42379,\"start\":41974},{\"attributes\":{\"id\":\"b16\"},\"end\":42788,\"start\":42381},{\"attributes\":{\"id\":\"b17\"},\"end\":43167,\"start\":42790},{\"attributes\":{\"id\":\"b18\"},\"end\":43665,\"start\":43169},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":47018994},\"end\":44054,\"start\":43667},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":11816014},\"end\":44496,\"start\":44056},{\"attributes\":{\"id\":\"b21\"},\"end\":44720,\"start\":44498},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":780171},\"end\":45101,\"start\":44722},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":52165754},\"end\":45701,\"start\":45103},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":19240019},\"end\":46268,\"start\":45703},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":8535316},\"end\":46729,\"start\":46270},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":60671162},\"end\":47072,\"start\":46731},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":207163173},\"end\":47388,\"start\":47074},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":3986974},\"end\":47747,\"start\":47390},{\"attributes\":{\"doi\":\"arXiv:1611.09830\",\"id\":\"b29\"},\"end\":48123,\"start\":47749}]", "bib_title": "[{\"end\":36202,\"start\":36144},{\"end\":36607,\"start\":36513},{\"end\":37301,\"start\":37246},{\"end\":39369,\"start\":39281},{\"end\":39828,\"start\":39755},{\"end\":40264,\"start\":40176},{\"end\":41006,\"start\":40959},{\"end\":41674,\"start\":41619},{\"end\":43725,\"start\":43667},{\"end\":44115,\"start\":44056},{\"end\":44769,\"start\":44722},{\"end\":45177,\"start\":45103},{\"end\":45827,\"start\":45703},{\"end\":46324,\"start\":46270},{\"end\":46792,\"start\":46731},{\"end\":47108,\"start\":47074},{\"end\":47446,\"start\":47390}]", "bib_author": "[{\"end\":36223,\"start\":36204},{\"end\":36237,\"start\":36223},{\"end\":36625,\"start\":36609},{\"end\":36638,\"start\":36625},{\"end\":36654,\"start\":36638},{\"end\":36669,\"start\":36654},{\"end\":36685,\"start\":36669},{\"end\":37069,\"start\":37053},{\"end\":37086,\"start\":37069},{\"end\":37101,\"start\":37086},{\"end\":37119,\"start\":37101},{\"end\":37139,\"start\":37119},{\"end\":37148,\"start\":37139},{\"end\":37322,\"start\":37303},{\"end\":37339,\"start\":37322},{\"end\":37359,\"start\":37339},{\"end\":37369,\"start\":37359},{\"end\":37678,\"start\":37664},{\"end\":37693,\"start\":37678},{\"end\":37707,\"start\":37693},{\"end\":37718,\"start\":37707},{\"end\":37733,\"start\":37718},{\"end\":37743,\"start\":37733},{\"end\":37755,\"start\":37743},{\"end\":37769,\"start\":37755},{\"end\":37776,\"start\":37769},{\"end\":38085,\"start\":38075},{\"end\":38096,\"start\":38085},{\"end\":38113,\"start\":38096},{\"end\":38129,\"start\":38113},{\"end\":38142,\"start\":38129},{\"end\":38158,\"start\":38142},{\"end\":38170,\"start\":38158},{\"end\":38184,\"start\":38170},{\"end\":38497,\"start\":38483},{\"end\":38508,\"start\":38497},{\"end\":38522,\"start\":38508},{\"end\":38538,\"start\":38522},{\"end\":38554,\"start\":38538},{\"end\":38568,\"start\":38554},{\"end\":38584,\"start\":38568},{\"end\":38601,\"start\":38584},{\"end\":38621,\"start\":38601},{\"end\":38966,\"start\":38944},{\"end\":38982,\"start\":38966},{\"end\":38998,\"start\":38982},{\"end\":39010,\"start\":38998},{\"end\":39024,\"start\":39010},{\"end\":39037,\"start\":39024},{\"end\":39052,\"start\":39037},{\"end\":39378,\"start\":39371},{\"end\":39399,\"start\":39378},{\"end\":39412,\"start\":39399},{\"end\":39425,\"start\":39412},{\"end\":39843,\"start\":39830},{\"end\":39865,\"start\":39843},{\"end\":39872,\"start\":39865},{\"end\":40280,\"start\":40266},{\"end\":40293,\"start\":40280},{\"end\":40308,\"start\":40293},{\"end\":40326,\"start\":40308},{\"end\":40740,\"start\":40724},{\"end\":40755,\"start\":40740},{\"end\":40769,\"start\":40755},{\"end\":41023,\"start\":41008},{\"end\":41041,\"start\":41023},{\"end\":41055,\"start\":41041},{\"end\":41067,\"start\":41055},{\"end\":41088,\"start\":41067},{\"end\":41101,\"start\":41088},{\"end\":41122,\"start\":41101},{\"end\":41506,\"start\":41491},{\"end\":41517,\"start\":41506},{\"end\":41530,\"start\":41517},{\"end\":41687,\"start\":41676},{\"end\":41700,\"start\":41687},{\"end\":41713,\"start\":41700},{\"end\":41733,\"start\":41713},{\"end\":42115,\"start\":42103},{\"end\":42129,\"start\":42115},{\"end\":42150,\"start\":42129},{\"end\":42164,\"start\":42150},{\"end\":42171,\"start\":42164},{\"end\":42509,\"start\":42499},{\"end\":42522,\"start\":42509},{\"end\":42535,\"start\":42522},{\"end\":42550,\"start\":42535},{\"end\":42564,\"start\":42550},{\"end\":42578,\"start\":42564},{\"end\":42844,\"start\":42832},{\"end\":42859,\"start\":42844},{\"end\":42869,\"start\":42859},{\"end\":42883,\"start\":42869},{\"end\":42899,\"start\":42883},{\"end\":42916,\"start\":42899},{\"end\":42925,\"start\":42916},{\"end\":43180,\"start\":43169},{\"end\":43193,\"start\":43180},{\"end\":43208,\"start\":43193},{\"end\":43220,\"start\":43208},{\"end\":43241,\"start\":43220},{\"end\":43255,\"start\":43241},{\"end\":43265,\"start\":43255},{\"end\":43278,\"start\":43265},{\"end\":43745,\"start\":43727},{\"end\":43756,\"start\":43745},{\"end\":43769,\"start\":43756},{\"end\":44135,\"start\":44117},{\"end\":44147,\"start\":44135},{\"end\":44167,\"start\":44147},{\"end\":44180,\"start\":44167},{\"end\":44563,\"start\":44551},{\"end\":44575,\"start\":44563},{\"end\":44598,\"start\":44575},{\"end\":44784,\"start\":44771},{\"end\":44798,\"start\":44784},{\"end\":44815,\"start\":44798},{\"end\":45195,\"start\":45179},{\"end\":45208,\"start\":45195},{\"end\":45223,\"start\":45208},{\"end\":45237,\"start\":45223},{\"end\":45253,\"start\":45237},{\"end\":45267,\"start\":45253},{\"end\":45287,\"start\":45267},{\"end\":45305,\"start\":45287},{\"end\":45842,\"start\":45829},{\"end\":45858,\"start\":45842},{\"end\":45868,\"start\":45858},{\"end\":45884,\"start\":45868},{\"end\":45909,\"start\":45884},{\"end\":45918,\"start\":45909},{\"end\":46339,\"start\":46326},{\"end\":46359,\"start\":46339},{\"end\":46372,\"start\":46359},{\"end\":46393,\"start\":46372},{\"end\":46809,\"start\":46794},{\"end\":46826,\"start\":46809},{\"end\":47129,\"start\":47110},{\"end\":47146,\"start\":47129},{\"end\":47162,\"start\":47146},{\"end\":47458,\"start\":47448},{\"end\":47468,\"start\":47458},{\"end\":47765,\"start\":47749},{\"end\":47776,\"start\":47765},{\"end\":47789,\"start\":47776},{\"end\":47804,\"start\":47789},{\"end\":47824,\"start\":47804},{\"end\":47840,\"start\":47824},{\"end\":47856,\"start\":47840}]", "bib_venue": "[{\"end\":36297,\"start\":36237},{\"end\":36748,\"start\":36685},{\"end\":37425,\"start\":37369},{\"end\":37815,\"start\":37776},{\"end\":38073,\"start\":38010},{\"end\":38481,\"start\":38419},{\"end\":38942,\"start\":38836},{\"end\":39485,\"start\":39425},{\"end\":39932,\"start\":39872},{\"end\":40386,\"start\":40326},{\"end\":40722,\"start\":40664},{\"end\":41197,\"start\":41136},{\"end\":41489,\"start\":41452},{\"end\":41786,\"start\":41733},{\"end\":42101,\"start\":41974},{\"end\":42497,\"start\":42381},{\"end\":42830,\"start\":42790},{\"end\":43409,\"start\":43278},{\"end\":43829,\"start\":43769},{\"end\":44243,\"start\":44180},{\"end\":44549,\"start\":44498},{\"end\":44878,\"start\":44815},{\"end\":45368,\"start\":45305},{\"end\":45976,\"start\":45918},{\"end\":46464,\"start\":46393},{\"end\":46885,\"start\":46826},{\"end\":47206,\"start\":47162},{\"end\":47557,\"start\":47468},{\"end\":47911,\"start\":47872},{\"end\":36344,\"start\":36299},{\"end\":36798,\"start\":36750},{\"end\":37468,\"start\":37427},{\"end\":39532,\"start\":39487},{\"end\":39979,\"start\":39934},{\"end\":40433,\"start\":40388},{\"end\":43876,\"start\":43831},{\"end\":44293,\"start\":44245},{\"end\":44928,\"start\":44880},{\"end\":45418,\"start\":45370},{\"end\":46522,\"start\":46466},{\"end\":47237,\"start\":47208}]"}}}, "year": 2023, "month": 12, "day": 17}