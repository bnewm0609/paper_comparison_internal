{"id": 250242201, "updated": "2023-09-26 17:06:59.047", "metadata": {"title": "mmSpy: Spying Phone Calls using mmWave Radars", "authors": "[{\"first\":\"Suryoday\",\"last\":\"Basak\",\"middle\":[]},{\"first\":\"Mahanth\",\"last\":\"Gowda\",\"middle\":[]}]", "venue": "2022 IEEE Symposium on Security and Privacy (SP)", "journal": "2022 IEEE Symposium on Security and Privacy (SP)", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "\u2014This paper presents a system mmSpy that shows the feasibility of eavesdropping phone calls remotely. Towards this end, mmSpy performs sensing of earpiece vibrations using an off-the-shelf radar device that operates in the mmWave spectrum (77 GHz, and 60 GHz). Given that mmWave radars are becoming popular in a number of autonomous driving, remote sensing, and other IoT applications, we believe this is a critical privacy concern. In contrast to prior works that show the feasibility of detecting loudspeaker vibrations with larger amplitudes, mmSpy exploits smaller wavelengths of mmWave radar signals to detect subtle vibrations in the earpiece devices used in phonecalls. Towards designing this attack, mmSpy solves a number of challenges related to non-availability of large scale radar datasets, systematic correction of various sources of noises, as well as domain adaptation problems in harvesting training data. Extensive measurement-based validation achieves an end-to-end accuracy of 83 \u2212 44% in classifying digits and keywords over a range of 1-6 ft, thereby compromising the privacy in applications such as exchange of credit card information. In addition, mmSpy shows the feasibility of reconstruction of the audio signals from the radar data, using which more sensitive information can be potentially leaked.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sp/BasakG22", "doi": "10.1109/sp46214.2022.9833568"}}, "content": {"source": {"pdf_hash": "d979852ed79e55dac7609e3fa7897cdc9ba718ca", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "bf6e4883732620b978bf6d0f1c3b26794f06e40e", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d979852ed79e55dac7609e3fa7897cdc9ba718ca.txt", "contents": "\nmmSpy: Spying Phone Calls using mmWave Radars\n\n\nSuryoday Basak \nThe Pennsylvania State University\nUniversity ParkPA\n\nMahanth Gowda mahanth.gowda@psu.edu \nThe Pennsylvania State University\nUniversity ParkPA\n\nmmSpy: Spying Phone Calls using mmWave Radars\n1side channel attacksmmWave radarsspeech privacy\nThis paper presents a system mmSpy that shows the feasibility of eavesdropping phone calls remotely. Towards this end, mmSpy performs sensing of earpiece vibrations using an off-the-shelf radar device that operates in the mmWave spectrum (77 GHz, and 60 GHz). Given that mmWave radars are becoming popular in a number of autonomous driving, remote sensing, and other IoT applications, we believe this is a critical privacy concern. In contrast to prior works that show the feasibility of detecting loudspeaker vibrations with larger amplitudes, mmSpy exploits smaller wavelengths of mmWave radar signals to detect subtle vibrations in the earpiece devices used in phonecalls. Towards designing this attack, mmSpy solves a number of challenges related to non-availability of large scale radar datasets, systematic correction of various sources of noises, as well as domain adaptation problems in harvesting training data. Extensive measurement-based validation achieves an endto-end accuracy of 83 \u2212 44% in classifying digits and keywords over a range of 1-6 ft, thereby compromising the privacy in applications such as exchange of credit card information. In addition, mmSpy shows the feasibility of reconstruction of the audio signals from the radar data, using which more sensitive information can be potentially leaked.\n\nI. INTRODUCTION\n\nMillimeter wave (mmWave) communication technology is being increasingly adopted for next generation networking applications that require low latency and high throughput such as virtual/augmented reality [47], vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) networking [102] in autonomous driving, machine type communications in industrial IoT [9] etc. In addition to networking, mmWave technology is also becoming increasingly popular in a number of remote sensing applications in the areas of material detection, autonomous driving, precision agriculture, vibration sensing in industries, robotics, etc. [62], [45], [55], [53].\n\nMotivated by these applications, mmWave communication has been incorporated in 5G and other networking standards, thereby increasing the proliferation of mmWave sensing and networking devices in a number of IoT applications. The technology is readily available on newer smartphones, virtual/augmented reality (VR/AR) headsets, as well as several off-the-shelf radar devices for autonomous driving applications. While other exciting applications are around the corner, this paper takes a step back and exposes a critical capability in mmWave devices that can enable a malicious adversary to passively overhear phone calls. This paper proposes mmSpy, a system that uses off-the-shelf mmWave radar devices for eavesdropping the audio spoken by the remote caller during phone calls. The core intuition is that the earpiece 1 device that users listen to during phone calls generate minute vibrations in the order of 7 \u00b5m. mmSpy senses these vibrations by detecting the changes in phases of mmWave signals reflected from the body of the phone. This opens up the possibility of eavesdropping the audio content of the remote caller during a phone conversation. In particular, mmSpy can eavesdrop the contents of the audio even when the audio is completely inaudible to both humans and microphones nearby. In addition, since the audio is detected directly from the source of vibrations, mmSpy's spying capabilities are immune to ambient noise, which makes the attack suitable in noisy and crowded spaces where suspicion is low. This opens up an interesting attack scenario. An attacker can eavesdrop on nearby users on phone calls, especially in a social setting like conferences, or parties and spy on users who might be seated and engaged in a phone conversation. Credit card numbers, one-time passwords, SSN numbers, etc. can be stolen within the capabilities of mmSpy.\n\nSuch an attack is challenging for a number of reasons (i) The vibrations are extremely small (\u2248 7 um) in comparison to the hardware noise floor (ii) The ramping and settling time of the frequency oscillator used to generate frequency modulated carrier wave (FMCW) signals introduces a characteristic noise pattern into phase measurements. (iii) The vibration needs to be decoupled from other ambient multipath signals in the environment (iv) Because of the hardware limitations, the sampling rate of the sensed vibration tends to be non-uniform (v) Finally, while robustness of audio/speech processing algorithms depend on large high quality training data, such large datasets are not available for our problem domain.\n\nmmSpy exploits a number of opportunities to handle the above challenges. The opportunities listed below map to the above enumerated challenges in the same order. (i) The peaks corresponding to multipath components are tracked over time in order to identify stable reflections and ignore noisy peaks. (ii) We employ statistical error correction techniques to model the noise due to ramp/settle times in the oscillator and systematically subtract it from the phase data corresponding to vibrations (iii) The reflection from a static object such as a wall will have low variation in the phases. In contrast, the reflection from the phone will have higher variation in the phases because of high frequency audio vibrations. mmSpy isolates phone reflection from ambient multipath by exploiting this variation. (iv) The system parameters such as the chirp Fig. 1: Overall architecture of mmSpy for spying on phone calls. Synthetic training data generated from speech datasets is combined with small scale training data from real radars -this generates mmSpy's audio reconstruction and speech classification models. and frame rates of the FMCW signal, and the duty cycle etc., are carefully selected to balance the non-uniform radar sampling rate with a uniform phase sampling rate for audio.\n\n(v) We model the transformation between high quality audio to low quality vibration data. Such a modeling allows us to convert existing large-scale speech processing datasets into synthetic radar datasets. We use such synthetic datasets to train machine learning (ML) algorithms for classifying digits, keywords, as well as performing end-to-end reconstruction of audio samples. Finally, mmSpy performs fine-tuning of the models with small-datasets of sensor-data to enhance the accuracy of audio classification and reconstruction.\n\nPrior works in the area of speech analysis with radar signals include wireless vibrometry [92] that can detect audio from loudspeakers using WiFi signals. Similarly, WaveEar [95] can detect speech signals using mmWave hardware based on reflection from a human throat. UWHear [90] uses UWB radios for separating speech signals from multiple loudspeakers. In contrast to these works, mmSpy differs in the following ways: (i) mmSpy shows the feasibility of eavesdropping on earpieces used during phone calls -the first such attempt to our best knowledge. (ii) Prior works focus on detecting vibrations from a loudspeaker, humans, or other sound sources which can also be heard by a colocated microphone. In contrast, by exploiting shorter wavelengths of mmWave signals, mmSpy shows the feasibility of detecting minute vibrations of an earpiece that cannot be heard by a microphone co-located with the radar. mmSpy is implemented using off-the-shelf radar devices at two different frequencies -TI AWR1843 BOOST in 77 GHz, and IWR6843ISK in 60 GHz -which use FMCW signals. The attack is performed on two models of smartphones with contrasting material properties -Google Pixel 4a, and Samsing Galaxy S20. The radar sensor data is pre-processed offline with MATLAB/python modules, and fed to machine learning modules implemented in PyTorch for various applications of speech processing. The accuracy varies between 83\u221244% over a distance of 1-6 feet for applications in digit classification and keyword recognition. The spectrograms of reconstructed audio from the spying attack match closely with the ground truth which is of critical concern from a privacy perspective.\n\nIn achieving the above reported levels of attack accuracy on smartphones with off-the-shelf radar devices, we briefly enumerate our contributions below: (i) Identification of security threats related to eavesdropping of the earpiece devices used in phone-calls with mmWave radars; (ii) Systematic preprocessing techniques for subtraction of hardware related noise and artifacts; (iii) Synthetic training data generation for training high precision machine learning models for speech classification and audio reconstruction; (iv) Domain adaptation techniques for coping up with the domain shift between synthetic training data and real sensor data; (v) Implementation and evaluation under various attack scenarios related to word/digit classification. Fig. 1 depicts the overall architecture of mmSpy. A synthetic model in mmSpy is first created with large-scale synthetic training data generated using popular speech datasets. Towards handling the residual differences between synthetic and real radar data, the model is later adapted by using small-scale training datasets from real radar. The model thus generated is used for launching the eavesdropping attack. The rest of the paper will expand upon this idea.\n\n\nII. BACKGROUND\n\n\nA. Earpiece Vibrations\n\nFig. 2 depicts the locations of earpieces in popular phone models such as iPhone-12, Google Pixel 4a, and Samsung Galaxy S4. The vibrations of the earpiece are much smaller than that of loudspeakers. Therefore, the users need to place their ears in direct contact with the earpiece to be able to hear the sound clearly. Because of direct physical contact, the sound waves propagate directly from one solid surface (earpiece) to another solid surface (ears), thus providing a high quality sound reception within human ears in comparison to the case where there is no physical contact with the earpiece. As a result, the leakage of the earpiece vibrations over the air is also much weaker compared to that of a loudspeaker.\n\nHowever, mmSpy uses reflections of mmWave signals to directly track the vibrations produced by the earpiece. The The reflected FMCW signals from objects in the environment maintain a constant frequency difference with respect to the transmitted FMCW signal. The distance of the reflector can be measured from this frequency difference. earpiece vibrations will also induce vibrations in the body of the phone. mmSpy detects vibrations from the back of the phone which is not facing the user's ears. This enables eavesdropping of earpiece vibrations even if the leakage of sound over the air is significantly weaker. We next elaborate details on the mmWave hardware that enables this capability.\n\nB. Overview of FMCW mmSpy adopts an FMCW radar that works by emitting chirps 2 .\n\nThe chirp is reflected back by objects in the environment of the radar and based on the time differences between transmission and reception of chirps and the doppler shifts, the radar can estimate the range (distance) of these objects as well as their velocities.\n\nA chirp and the working principle of FMCW radars is visualized in Fig. 3. The signal visualized in Fig. 3(a) is a sinusoidal signal with a linearly increasing frequency which is a popular type of chirp. The radar modules used in this paper (TI AWR1843BOOST [8], TI IWR6843ISK [12]) employ such chirps with linearly increasing frequency. Since the transmitted 2 chirps are signals with varying frequency, usually increasing frequency or decreasing frequency signals are frequency-modulated signals, the reflected components will also be frequency modulated signals. However, because they are delayed, at any given point in time, there is a constant frequency difference between the transmitted and reflected chirp as depicted in Fig. 3(b). By computing the frequency difference \u2206F between the transmitted and received chirps, the distance of the reflecting object can be computed. The below equation precisely converts the frequency difference into the range (r) of the object from the radar.\nr = \u2206F Slope (1)\nwhere Slope refers to the rate at which the chirp frequency is linearly modulated.\n\nAs depicted in Fig. 3(b), multiple reflected chirps corresponding to different multipath components in the environment can be received at the transmitter. By performing an FFT operation at the receiver (called range FFT), different multipath components, as well as their ranges can be determined.\n\nThe resolution at which distances can be computed using such a method can be expressed as a function of the chirp sweeping bandwidth B as follows [83]:\n\u2206R = c 2B (2)\nwhere c is the speed of light. In the best case scenario where the entire working bandwidth of the radar is effectively swept by a chirp, the above equation predicts a range resolution of the radar of about 3.75cm. While this is good for a number of applications such as human activity recognition where the motion of objects are at larger scales, the resolution is not sufficient for tracking minute micrometer-level vibrations needed for capturing the earpiece vibrations during a phone call. Towards capturing a higher resolution range information, mmSpy exploits the phase of each reflected signal.\n\nThe phase variations can capture minute changes in motion of the reflector, as per the equation below.\n\u2206\u03d5 = 2\u03c0\u2206r \u03bb(3)\nGiven the wavelength is in the order of millimeters (\u2248 4mm), and a typical phase noise of 0.057 \u2022 , extremely small changes in range (\u2206r \u2248 0.63 um) can be tracked by exploiting the phase variations. mmSpy tracks such variations to eavesdrop on the contents of a phone call. Fig. 4 depicts extraction of continuous phase changes from the FMCW radar. A range-FFT operation will result in multiple peaks corresponding to reflections in the environment. Among these peaks, the peak corresponding to reflection from the phone is first isolated (Section IV-A). By measuring the phase of this FFT peak, and tracking its variations continuously over time will facilitate eavesdropping of earpiece vibrations.\n\nC. System Parameters mmSpy uses a commodity off-the shelf (COTS) radar to demonstrate radar-based cellphone eavesdropping. While the phase data can be noisy because of practical constraints, Fig. 4: A range-FFT will result in multiple peaks corresponding to objects in the environment. Tracking the phase of the peak due to phone's reflection will facilitate eavesdropping.\n\nmmSpy chooses an appropriate set of parameters in the design space so as to facilitate high quality measurements with a high sampling rate. We elaborate below on the deliberations. We begin by briefly explaining the cycle of operations in the radar for transmission of chirps. Illustrated in Fig. 5(a), The TI radar modules transmit a series of chirps continuously. Fig.  5(b) provides a zoomed-in view of a single chirp. Performing range FFT on each chirp, and isolating the reflection from the phone (discussed in Section IV-A), provides one phase sample per chirp -we call this the phase sampling rate. The chirps are grouped into frames as depicted in the figure. Each frame enforces a duty cycle of less than 100% so as to provide the radar enough time to settle down between frames. This leads to power fluctuations within the hardware due to discontinuous operation. While a higher duty cycle provides more samples, it comes with a tradeoff of noisier sensor data. Similarly, there is an inter-chirp separation time so as to let the hardware switch from the highest frequency at the end of a chirp back to the lowest frequency to begin a new chirp. The slope of the chirp also offers a tradeoff between sampling rate of sensor data and the hardware noise. While faster slope produces more chirps per second, the power fluctuations in the hardware can lead to low quality phase data. Keeping the above discussed tradeoffs in consideration, Appendix B expands on the details on the chosen system parameters in mmSpy.  A malicious adversary with an mmWave radar attempts to spy on the audio contents of a phone call made by a nearby victim. Towards this end, the attacker shines mmWave signals on the victim's phone and captures the reflections. We assume that the captured reflections come from the back of the phone opposite to the side of the earpiece that faces the user's ear. By analyzing the phases of the reflection, the vibration of the earpiece device of the phone can be detected. We do not assume that the attacker has training data for domain adaptation (Section IV) from the victim's phone. The attacker generates such training data from his own phone (which is assumed to be of the same make and model as the victim's phone) for developing the speech recognition ML models (alternatives such as training from a different phone model is evaluated in Section V). mmSpy's ML models are designed to perform audio reconstruction as well as speech recognition tasks from the noisy vibration data captured from reflection from the phone. Following is an example setting where such an attack is feasible. Consider a setting like a research conference or a social party. An attacker can eavesdrop on phone calls received by a nearby victim who might be seated on a chair. Given that mmWave radars can track vibrations directly from the earpiece, this is particularly effective in noisy and crowded spaces where the victim might be less suspicious of eavesdropping. Within the capabilities of mmSpy, the sensitive information that can be eavesdropped include credit card information, one time passwords, social security numbers, etc.\n\n\nIII. THREAT MODEL\n\n\nIV. TECHNICAL MODULES\n\nA. Isolation of phone reflection:\n\nAs discussed in Section II, a given range-FFT window will include reflection from the phone as well as multipath reflections from other objects in the environment. We face two main challenges in isolating the phone reflection: (i) Several noisy peaks show up in the range-bin which do not correspond to multipath reflections. (ii) In addition to the noisy peaks, there will be peaks corresponding to static reflectors in the environment such as walls and furniture. Towards better isolation of signal of interest from the above sources, mmSpy tracks consistent peaks across successive frames. Since the noisy peaks do not consistently appear at a given distance, they are eliminated. Fig. 7 shows an example where the phone reflection is consistently tracked over time. In addition Fig. 7: Tracking of FMCW peaks over time helps eliminate noisy peaks. The phase data corresponding to the peak from phone's reflection is used to eavesdrop the audio.\n\nto phone reflections, reflections from other objects in the environment can be seen in the figure. However, the phase of the reflection from the phone would oscillate (due to vibrations from the audio) whereas phase from other reflectors will not oscillate. By exploiting this property, mmSpy designs a shallow convolutional neural network based model to first classify reflections due to audio vibrations and reflections from static reflectors such as walls. The classifier provides a high accuracy of 99.4%, thus facilitating elimination of static reflectors like walls, furniture etc. Once the peak corresponding to the reflection from the phone has been identified, the phase of this peak is used for reconstruction of the earpiece audio as well as performing speech classification tasks (more details in Appendix B). Given that the receiver has four receiver antennas, the phase values are averaged across all four antennas to minimize the Gaussian noise in the extracted audio.\n\n\nB. Statistical error correction:\n\nThe vibrations induced on the body of the phone by the earpiece is, by nature, of a very low magnitude. As a consequence of this, the variation in the phase of the range-FFT peaks is also very low and noise can supersede the magnitude of the phase changes that are useful for vibration detection.\n\nThe mmWave radio transmits and receives chirps in a discontinuous manner in the form of frames. We observe that at the beginning of every frame, there is a spike in the magnitude of the phase values (as shown in Fig. 8 (a)). Additionally, there is also a continuous noise component that fluctuates more smoothly with time. In order to eliminate this, we assume that within each frame of chirps, a smooth enveloping component exists and we eliminate it. This is done by estimating the fluctuation within a frame using a polynomial of degree 2. To avoid the effect of the spikes at the beginning of each frame, we also eliminate the first two data points received in a frame. Since the frame size in mmSpy is 128, we effectively work with 126 points within each frame to offset the fluctuations.\n\nIf a frame is represented as (X, Y ), where X is the index of chirps and Y is the magnitude of the phase extracted from the chirps, then the smooth fluctuation is estimated using the following model:\u0176\n= a 0 X 2 + a 1 X + c(4)\nwhere X 2 refers to each element of X being raised to a power of 2. This is similar to a linear regression of order 2 on (X, Y ).\n\nHere, the parameters a 0 , a 1 and c are the estimated parameters in the polynomial fitting model. Once\u0176 has been estimated, the corrected frame is obtained by subtracting\u0176 from Y :\nY \u2032 = Y \u2212\u0176 (5)\nwhere Y \u2032 is the corrected frame.\n\nThe effect of the error correction is demonstrated in Fig. 8. The spikes are eliminated, and the signal is zero centered, as we expect audio signals to be, due to the elimination of the fluctuating components.\n\n\nC. Preprocessing and Signal Filtering\n\nWe perform a number of preprocessing and filtering techniques on the extracted raw audio from the radar as outlines below.\n\nBandpass Filtering: mmSpy tracks sound via material vibrations. It is known from literature that materials attenuate vibrations at higher frequencies [41], [86], [85]. Therefore, the spectrum measured at higher frequencies mostly consists of noise which can be eliminated by applying a low pass filter at 2000 Hz [73]. Also, the fundamental frequency of the voiced speech of a typical adult male will vary from 85 to 180 Hz, and that of an adult female from 165 to 255 Hz [87], [34]. Thus, we apply a high pass filter at 80 Hz to eliminate the DC offsets and low frequency noise without affecting speech recognition.\n\nSpectral Subtraction: We perform background noise elimination using spectral subtraction techniques popular in speech processing [38]. At a high level, the average signal spectrum and the average noise spectrum are first estimated and then subtracted from each other, which is shown to eliminate additive stationary noise [88], [85], [78]. Fig. 9 depicts an audio signal before and after preprocessing techniques. Evidently, the voice part of the signal has been enhanced in comparison to hardware noise. \n\n\nD. Synthetic training data generation:\n\nSpeech processing algorithms have to be robust to speaker patterns, dialects, gender, etc. However, developing robust models require large scale training data accumulated over years across diverse users. While large scale datasets are available for speech and vision domains, the unfortunate lack of availability of similar radar datasets makes it challenging to develop robust models. Towards minimizing the overhead of training data collection, mmSpy generates synthetic training data to bootstrap the training of ML models.\n\nThe synthetic data is created from the existing datasets (AudioMNIST [36] and Speech Commands [91]) using two main operations: scaling and noising. In order to scale the existing datasets, radar samples were collected and moments of speech were identified. Whenever words are being spoken, the phase magnitudes vary in the range of -0.024 and 0.024 (after statistical error correction). We assume that the noise in the sensor data is normally distributed and estimate the parameters of the noise distribution from samples where no sounds are played on the phone. The mean and the standard deviation of the noise distribution are 0 and 0.0035 respectively. Thus, the audio datasets were scaled in the range of [-0.024, 0.024] and random noise sequences with a normal distribution N (0, 0.0035) were added to create synthetic training data.\n\nAlthough the synthetic data attempts to match the distribution of real radar data well at a high level, there will still be residual differences in distribution. Towards eliminating such differences, mmSpy later performs domain adaptation based on a small set of real training data, thus achieving a sweet-spot in the trade-off between training data overhead and robustness of the ML model.\n\n\nE. Audio Reconstruction:\n\nTowards reconstruction of the original audio from the noisy radar data, we design a redundant convolutional encoder decoder (RCED) architecture [79] as illustrated in Fig. 10. The audio and radar samples are downsampled to a sampling rate of 8kHz -this sampling rate is adequate to capture audible frequencies from human speech. The input X i to the network are the mel-spectrograms of 1-second audio samples. The dimensions of the spectrograms are 128\u00d781. We refer to each column of this input matrix as a segment. Towards generating an enhanced segment at time t, the network accepts input segments from times t to t \u2212 7, thus accepting an input of size 128 \u00d7 8, and producing an output of size 128 \u00d7 1. This allows the network to exploit temporal locality in performing the enhancement. Also, the network consists of skip connections that help in training and convergence [46], [61], [29]. The network outputs one segment at a time, and after passing through the entire input, it produces an output matrix O of size 128 \u00d7 73 3 . After performing the enhancement, we exploit masking techniques [51] as an alternative enhancement option. While the enhanced output O eliminates noise, it may distort the voiced segments of the audio as well. The masking can potentially help eliminate such distortions. After performing the enhancement with RCED network, the output spectrogram O is divided into 8 evenly spaced frequency ranges in the mel scale. Within each frequency range, a threshold is decided adaptively based on Otsu's method [67].  Loss Functions and Optimization: The loss function used to train the audio reconstruction model is the mean-squared error (MSE) loss function. If X i and Z i are the i th input and output spectrograms respectively, the MSE is defined as:\nMSE = 1 n n i=1 ||X i \u2212 Z i || 2 2(6)\nSince the inputs and outputs are spectrograms, the MSE loss function is used to make the input and output spectrograms resemble each other as much as possible.\n\nThe Adam optimizer was used to minimize the loss function with a learning rate of 0.001 and L2 regularization loss with weight decay of 10 \u22125 .\n\nHyperparameter Selection: The hyperparameters were the number of skip connections between the encoder and the decoder sections, the learning rate, the L2 regularization factor. The optimal set of hyperparameters were selected using a grid search: all combinations of skip connections (that were dimensionally compatible) between the encoder and decoder were tried, the learning rate and L2 regularization rate were varied in the set {0.001, 0.005, 0.01, 0.05}.\n\nBootstrapping the Training: The synthetic data generated as described in Section IV-D and the true data samples corresponding to each synthetic sample were treated as the input-output pairs (X i , Z i ), to train a synthetic model. The goal of the audio reconstruction model is thus to denoise and appropriately scale the noisy inputs to resemble the true outputs.\n\nDomain Adaptation: The synthetic model is adapted using a small sensor data sample (5% of the size of the synthetic dataset for Audio MNIST, and speech commands). We perform fine-tuning of the model where we simply update the weights of all parameters with real sensor data. The amount of domain adaptation data was sufficient to achieve convergence even though none of the layers were frozen. Based on a crossvalidation approach, we verified that such a fine-tuning approach provided us best results for this architecture instead of performing domain adaptation only on a few layers and freezing the rest.\n\n\nF. Speech Recognition via Classification:\n\nTowards performing speech recognition, we develop models based on convolutional neural networks that take spectrograms as inputs and estimate class labels corresponding to digits and speech-commands as outputs. The high level architecture of the classification model is depicted in Fig. 11. Similar to the network for audio reconstruction, skip connections are exploited for benefits in training and convergence. Loss functions and optimizations: The model is trained using a cross-entropy loss function. The cross entropy loss function is commonly used in classification problems. It is given as:\nCE = \u2212 N i=1 M c=1 y i,c log(p i,c )(7)\nwhere N is the number of data samples, M is the number of classes, y i,c is 1 if sample i belongs to class c and 0 otherwise, and p is the predicted probability that sample i is of class c.\n\nBootstrapping the Training: The synthetic data that was generated as described in Section IV-D and the labels corresponding to each synthetic sample were treated as the inputoutput pairs (X i , y i ), to train a synthetic model. The goal of the classifier is to best estimate the word that is being spoken, given the spectrogram of the vibration (sensed using the mmWave radar) as the input.\n\nHyperparameter Selection: The hyperparameters include learning rate, L2 regularization factors, kernel sizes for convolutional layers, dropout rates, the number of resnet blocks, and the number of nodes per fully connected layer. Domain Adaptation: In order to adapt the synthetic model to the sensor data, the last layers (indicated in Fig. 11) are retrained using sensor data as inputs and the corresponding true data samples as outputs. All the layers excepting the last few layers are frozen so that their weights do not change when the model is adapted. This is done so that the model can learn the same representation as the synthetic model by relearning only the last layers. Such a strategy is popular in other domain adaptation and transfer-learning applications [60], [74], [44]. Approximately 5% of synthetic data is used for domain adaptation for both AudioMNIST and speech commands datasets.\n\n\nV. EVALUATION\n\n\nImplementation:\n\nThe experimental setup is depicted in Fig. 12  (0-9) of 60 different speakers consisting of 48 males and 12 females from all age groups. Each audio sample is less than one second long, captured in a controlled environment at a sampling rate of 8kHz. The AudioMNIST dataset is a popular benchmark for testing several techniques in the literature of speech recognition including an attack on the accelerometer sensor [33], [48]. (ii) Towards validating a task in recognition of words, we use the speech command dataset [91]. ]. This dataset is completely anonymous and does not come with any information about age groups, genders, etc. Additionally, this dataset was crowdsourced and prepared so it includes samples from phone, laptop and tablet microphones. Each sample is converted to a 16kHz WAV file and is 1-second long.\n\nTraining Data: About 90% of samples from the datasets described above were converted into synthetic radar data (as discussed in Section IV-D) to bootstrap the training process. This includes data from all speakers, regardless of gender, age, etc. A synthetic model is first created, which is later adapted with small sets of real sensor data as elaborated next.\n\nData for Domain Adaptation: The data used for domain adaptation is approximately 5% of the size of the synthetic training data. We play the audio samples corresponding to this data on the smartphone and record the radar measurements. This generates labelled training dataset with radar recordings and their respective audio classes. We used two phones of each of these models -Google Pixel 4a and Samsung S20 -a total of four smartphones. This allows us to perform the domain adaptation and testing on different phones. We use an app, Stealth Audio Player [18] that plays the audio contents of the domain adaptation data on the smartphone's earpiece. \n\n\nMetrics of Evaluation:\n\nWe consider the following two metrics of evaluation. (i) For the audio reconstruction model, we report the reconstruction loss between the recovered audio from the radar and the original audio played on the phone. A MSE error is used to quantify this. (ii) For speech recognition with digits and speech commands dataset, we report the classification accuracy (or simply the accuracy), which is the ratio of number of correct classifications over the total number of test cases. In addition to the above, we provide qualitative results such as spectrograms and an audio demo. We now present results from a systematic measurement study.\n\nTerminology: Since we consider multiple phones, multiple datasets, and multiple frequency bands in this paper, the number of different combinations can be exhaustive. Therefore, we choose the following subset of combinations that provide a good representation of the variation across different factors. Accordingly, we use the following terminology to represent these cases. Qualitative Reconstruction Results: Figures 13, 14 depict the spectrograms from a qualitative reconstruction of the audio. The y-axis of the spectrograms varies from 0 to 4KHz. Representative samples from each class are presented for both AudioMNIST and speech commands datasets. The raw capture from the sensor (top row), as well as mmSpy's reconstruction of the original audio from the raw sensor data is shown. Second row shows the output before masking whereas the third row shows the output after masking (discussed in Section IV-E). The bottom row shows the spectrograms of ground truth audio. Evidently, mmSpy's reconstruction agrees well visually with the ground truth. While the raw sensor data looks mostly noisy, mmSpy's audio reconstruction is able to highlight the key spectro-temporal trends in the audio resulting in a good recovery of the original audio.\n\nAudio Demo: Sample audio files from the raw sensor, mm-Spy's reconstruction from the raw sensor data, as well as the ground truth is included in the following anonymous url [5]. Headphones are recommended for listening. While the raw sensor data is incomprehensible, evidently, an adversary can roughly decipher the contents of the ground truth audio from mmSpy's reconstruction. mmSpy uses Griffin-Lim algorithm for reconstructing audio from spectrograms [52].\n\nQuantitative Reconstruction Results: Fig. 15 depicts the MSE error of audio reconstruction. The spectrograms are normalized within a range of [-1,1] for a uniform comparison. As depicted, the difference in MSE between the enhanced and the true audio is lower than the MSE between the raw sensor data and the true audio. Fig 15(b) shows the MSE averaged over 1-6 ft for various settings. This shows the effectiveness   Power vs Range: Fig. 16 depicts the power levels of sound vibrations as a function of the distance of the phone from the radar device. The power levels are measured in dB in reference to the noise power levels when there is no sound being played on the earpiece device. As expected, the power levels drops linearly as a function of distance. At a distance of 6f t ft, the power starts getting closer to noise levels. Beyond this, accurate detection of the phone reflection becomes hard. The variation is consistent for different phone models (Pixel vs. S20) as well as different frequencies (77 vs. 60 GHz). The power levels with speech commands is slightly lower than AudioMNIST mainly due to a corresponding lower quality (volume) of the data in comparison to AudioMNIST data. Speech Recognition Accuracy vs Range: Table. I depicts the accuracy of mmSpy as a function of range for different phone models and frequency range. Evidently, the accuracy only degrades gracefully over distances upto 6 ft which suggests the potential for a successful attack under conditions identified in the threat model in Section III. The performance is consistent across multiple phone models and frequency bands.\n\nThe performance with speech commands is slightly lower than  the performance with AudioMNIST data which follows the trend in power levels observed in Fig .16. The confusion matrices (Fig. 29), precision, and recall values (Table III) for a representative setting is depicted in the appendix.\n\nAccuracy vs Users: Fig. 17 shows distribution of users including males and females, the model is overall robust across a variety of users. We notice that the variation in accuracy across users is roughly correlated with the volume of their voice. The accuracy is also consistent across different genders with a 66.39% and 63.02% accuracy for male and female users respectively.\n\nPerformance in the 60 GHz spectrum: Table I also depicts the performance at 60 GHz frequencies in comparison with the 77 GHz spectrum. Evidently, the performance is consistent across both frequency spectrums. This is mainly because the propagation path loss does not change much between the two frequencies. Therefore, we observe a similar trend in SNR as well as the accuracies across both spectrums.\n\nThe Role of Domain Adaptation: Fig. 18 depicts the breakup of the gain in accuracy due to domain adaptation. The results are averaged over the entire range of 1 \u2212 6f t where the power level varies between 4.4\u22120.2dB. mmSpy trained with synthetic radar data helps bootstrap the process of training. While the average accuracies (\u2248 30%) with synthetic data is a modest start, mmSpy boosts the accuracy by adapting the model with small scale training data from real sensor. Evidently, with only 5% of real sensor data in comparison with original source of training dataset, the performance of mmSpy is substantially enhanced resulting in accuracy levels of 58 \u2212 69%.\n\nAll Data Pixel (77GHz) S20 (60GHz) S20 (77GHz) S20 (Sp, 77GHz) Earpiece Signal Levels and Performance under Noisy Setting: Fig. 19 depicts earpiece power levels measured by a high fidelity microphone under two settings: (i) Ambient noise in an indoor lab, approximately estimated at 32dB with respect to a complete silence. (ii) Loudspeaker playing white noise with approximately 58dB relative to silence, thus simulating a crowded setting. The measurements were conducted using a high fidelity microphone model Zoom H1 [27]. For each case, we report the overall power levels (earpiece audio + ambient/external noise) in comparison with ambient/external noise levels when the earpiece is silent. Evidently, the earpiece  whereas the detection from mmSpy matches closely with true audio. mmSpy detects vibrations from the source (earpiece), thus free of interference from ambient sound. (iii) Interference in the mmWave spectrum using network devices based on 802.11ad protocol with Netgear XR700 router [26] and a MG360 network adapter [14] that generate video traffic. (iv) Interference in the mmWave spectrum caused by other radar devices (IWR6843ISK). In all cases, the interferer was co-located with the radar so as to measure the performance under the most challenging case. Fig. 21 summarizes the results. The results are taken from IWR6843ISK radar placed at a distance of 3ft from the phone (\"S20 (60 GHz) setting\"). As expected, the microwave spectrum effectively does not have any influence on the mmWave radars since they operate in different frequency bands. On the other hand, even though the mmWave interference can happen in the same frequency band as the radar, our experiments reveal that this does not affect the accuracy in any significant way. This is because of the following reasons (i) The networking protocols use traditional modulation schemes such as OFDM [65], whereas radar uses FMCW. Because of the difference in modulation, the OFDM or other non-FMCW signals will have less interference on a FMCW radar that primarily latches onto chirps. (ii) Another FMCW radar ceases to have any interference. The lack of clock synchronization will create an interference peak at the radar at a different position than the reflection from phone. This is automatically eliminated by the static multipath elimination algorithms in mmSpy. Moreover, automatic filtering at the hardware level can typically happen even for a small clock offset. This observation is consistent with the documentation by Texas Instruments [13]. Effect of Hand Coverage of Phone: We have been able to extend the evaluation to include humans holding the phone in the hand (as if engaged in a casual conversation) as depicted in Figure 22. The distance between the phone and the radar is approximately 3ft. Our results indicate that a sufficient amount of information still exists despite two interfering factors: (i) Partial coverage of the body of the phone by the human hand.\n\n(ii) Any micro-motion (due to breathing, heartbeats, muscular twitches, etc.) in the human body which interferes with the audio sensing. Figure 23a shows the raw audio captured when the phone is held in the hand, with the audio content on the phone being \"four\". The artifacts due to body motion and vibrations are evident from the figure. Figure 23b shows the zoomed-in version of Figure 23a where the audio contents are now visible. We apply a simple threshold to eliminate the body motion artifact (caused due to micro-motions), as well as interpolation to fill out the gap after eliminating the body motion artifacts. The recovered audio is depicted in Figure  23c. We process the recovered audio with the classification model presented in Figure 11 (from the paper submission). The accuracy under \"S20 (77 GHz)\" setting (the dataset being AudioMNIST) is 58.8%. In contrast, when the phone was held on a tripod, the corresponding accuracy at the same distance was 65.09%. Similarly, for the case of \"S20 (Sp, 77GHz)\" (the dataset being Speech Commands), the accuracy with hand coverage is \"52.74%\", whereas when the phone was held on a tripod, the corresponding accuracy was \"60.74%\".\n\nExperiments on Longer Speech Sentences including Songs and Music: We have been able to capture multi-word sentences, and even music, in order to demonstrate the capabilities of mmSpy. The performance of the audio reconstruction model in Fig. 10 is independent of the length of the audio. Therefore, we can readily use the model to extract audio even if the audio includes multiple words or sentences. We have used the network to extract audio from actual sentences including speech, music, and song. A few examples of spectrograms as well as the corresponding sound recordings (headphones are recommended to listen to the recordings) are included in this document, for three categories: (i) Speech -\"I have a dream .. \" speech by Dr. Martin Luther King Jr. in Figure 26 (ii) Song with background music -\"Twinkle Twinkle little star .. \" in Figure 27, and (iii) Music (Turkish March) in Figure 28. We believe the speech content is evident from the recordings.  The recording is here [7] (c) The recovered audio after body motion filtering. The recording is here: [6].\n\nAfter the network is adapted, the inference per sample takes 15.3ms on average. Training the enhancer took longer since each sample is converted into multiple inputs -the training time using synthetic data on an average is 17.2 minutes. The adaptation of the enhancer took longer as well -2.17 minutes on average, and finally, the inference per spectrogram takes 54.7ms. All evaluation was done on the desktop whose configuration is specified in the implementation subsection.\n\n\nVI. RELATED WORK\n\nSensing Applications with RF: There is a lot of recent interest in using WiFi-like communication devices for RADARlike sensing applications in addition to more conventional applications in communication and networking. LiquID [45] identifies permittivties of liquid materials by measuring the slow-down and attenuation of UWB RF signals. RF-EATS [55] can sense food materials in containers by measuring reflection of backscattered RFID stickers attached on the container. RFavatar [101] shows capabilities of beyond-the-wall 3D imaging using RF signals. While the above works use microwave frequencies, with the proliferation of 5G, there has been a lot of recent interest in using mmWave frequencies for sensing applications. mSense [93] can classify upto 21 liquids by measuring reflection of mmWave signals. mmVib can detect vibrations for classifying machines as well as monitoring their health in a number of industrial IoT applications [62]. Pointillism [35] can detect objects such as cars for applications in autonomous driving. Osprey [81] uses mmWave technologies for geometry sensing. Osprey estimates the depth of tire by utilizing concepts of synthetic aperture radars to create an image of the tire thread being placed over tires of cars. By identifying anomalies in the tire image, debris, and the wear and tear is detected. In contrast to the above applications mmSpy exploits the high precision sensing capabilities of the small wavelength of mmWave spectrum for exposing a security vulnerability. WaveSpy [66] spies apps running on a system by analyzing reflections from its screen. Material properties such as permittivity change with on-screen color patterns used by apps. This manifests as SNR/phase changes in reflected mmWave signals. In contrast to detecting material properties, mmSpy analyzes vibrations of a known material.\n\nSpeech Sensing with RF: Acoustic eavesdropping of loudspeakers have been shown in [92], where phase variations of radio frequency (RF) reflections in the microwave frequencies collected from a large antenna array are exploited to detect digits. In a similar spirit, UWHear [90] uses high resolution UltraWideBand (UWB) RF reflections for detecting multiple speakers in the environment, and shows the feasibility on a problem on digit classification. WaveEar [95] can detect speech signals using custom mmWave hardware based on reflection from a human throat. More recently, RadioMic [77] uses mmWave to detect speech signals from loudspeakers, humans, and objects. In contrast to these works, mmSpy shows the feasibility of eavesdropping earpiece devices used in phone calls. While loudspeaker or human throat vibrations can be stronger, thus can also be eavesdropped by a co-located microphone, the earpiece vibrations are very minute and inaudible to a microphone co-located with the attacking radar device. Nevertheless, mmSpy exploits small wavelength of mmWave signals to show the capability of audio reconstruction as well as speech classification.\n\nEavesdropping with cameras and lasers: Works in [41], [42] detect sounds played in a room using camera. In particular, sound waves induce vibration in objects (paper bags, bottles etc). By capturing such vibration patterns using a high speed camera, feasibility of recovering sound is shown even from the outside of a sound-proof room. In contrast to the above works, which detect stronger vibrations from loudspeakers, mmSpy detects minute vibrations from an earpiece device. Similarly, laser microphones have been popularly used for eavesdropping in a passive manner. However mmWave antennas are much smaller in size in comparison to laser microphones thus making them easier to conceal. Additionally, the presence of laser microphones is detectable [4], while mmWave signals can conceal themselves within ambient mmWave signals. Given that mmWave based 5G is a popular communication technology, this allows the adversary to conceal themselves among ambient mmWave signals. Lamphone [73] can eavesdrop acoustic vibrations that are are already in the air by analyzing vibrations of a light bulb. However, the sound is also audible to a colocated microphone near the bulb. In contrast, mmSpy detects weaker sound sources by picking up vibrations directly from the source, even if it us inaudible to a colocated microphone near the mmWave hardware.\n\nMotion Sensor based Attacks: Gyrophone [69] detects the speech content from an external loudspeaker (subwoofer) using smartphone gyroscope sensors placed on the same surface (for example, shared table). Classification of 11 digits (0-9 and \"oh\") is shown feasible. Speechless [30] shows the sensitivity of smartphone accelerometers to eavesdrop on speech content from a loudspeaker source sharing the same surface as the phone (subwoofers, laptops etc). Spearphone [31] performs gender and speaker classification, and detection of keywords by spying on smartphone speech content with builtin accelerometers. AccelEve [33] proposes an attack in a similar setting to Spearphone. Apart from gender and speaker classification, they perform digit and alphabet classification. AccelWord [100] shows the feasibility of detecting the wakeup keywords of voice commands such as \"Okay Google\", and \"Hi Galaxy\" using accelerometers. PitchIn [59] shows the feasibility of eavesdropping ambient speech by fusing data from multiple non-acoustic sensors (accelerometers, gyroscope, geophone etc) with low sampling rate. In contrast to such works that exploit motion sensors, mmSpy launches a remote attack with mmWave devices.\n\nAttacks on mobile sensors: Ghosttalk [64] shows the capability of injecting fake data into analog sensors by directly inducing voltages into the circuitry by an external RF excitation, thus critically compromising IoT systems including heart monitors. DolphinAttack [98] shows the feasibility of injecting inaudible voice commands to attack voice assistants. Mole [89] uses a smartwatch accelerometer to spy on the contents of a user's typing. S3 [49] detects drawings on a tablet using an apple pencil by exploiting variations in magnetic fields sensed by the magnetometer. Accelerometer sensors are also known to reveal passwords as entered on the touchscreen of a phone [76]. The smartphone magnetometers are even shown to be capable of identifying the operating systems and the pattern of applications in a nearby desktop by monitoring the spinning of hard-drives which are made of magnetic materials [37]. In contrast, mmSpy performs an attack on spying speech contents based on radar reflections.\n\nDomain adaptation: Transfer-learning based domain adaptation is popular in vision and speech processing. For example, AlexNet model [63] pretrained on ImageNet database [43] was fine-tuned for classifying images in the medical domain [103], remote-sensing [60] and breast-cancer [74]. Similarly, a pretrained BERT language model [44] was fine-tuned for tasks such as text-summarizing [99], question answering [82] etc. This significantly reduces the burden of training for a new task.\n\nIn a similar spirit, we use pre-trained model from synthetic radar data. While this provides a good enough synthetic model to begin with, we adapt the model with real radar data. Noted in Section IV, our domain adaptation trains only a few layers such that it significantly decreases the overhead of training.\n\nVII. DISCUSSION, LIMITATIONS, AND FUTURE WORK Eavesdropping a User under Mobility: Results in Fig. 23 show that enough information for the attack exists despite partial coverage of the phone by the human hand. However, not being able to attack a user who is in motion (such as walking) is a limitation of the current work. While sufficient vibration information still exists, the motion of the user might create interference which needs to be eliminated. We have some preliminary ideas for canceling body motion based on emerging recent works. Wistress [56] uses self-similarity matrices to identify and cancel out artefacts that are caused by small muscular movements to extract heartbeat signals. We will explore such opportunities in the future.\n\nRelevance of the Attack in Context of 5G Applications:  Defense: The vibration sensor on the phone can be used to produce noisy vibrations [84] such that the accuracy of vibration detection in mmSpy using the phases of the reflections is reduced. Similar to white box adversarial attacks on machine learning models [39], we can generate minimal noise using vibrations that is enough to confuse mmSpy's models, while still having negligible impact on user experience. Another possible defense against mmSpy is to surround the end of the earpiece that is not facing the ears with a vibration dampening material. For example, materials such as q-pads, or borosilicate paints are commonly used in the music industry to eliminate unwanted vibrations [25]. Evaluation of the above ideas for defense would be a part of our future work.\n\nAutomatic Speech Recognition: While mmSpy demonstrates the feasibility of the attack on isolated speech recognition, we plan to extend to recognition of continuous speech. Automatic speech recognition (ASR) models based on LSTM, attentions, and language modeling [40] are popular in continuous speech recognition where the boundaries between successive words can be blurred. While training such deep learning based models requires an extensive amount of datasets, we plan to adopt a procedure similar to synthetic training data proposed here to bootstrap the training process.\n\n\nVIII. CONCLUSION\n\nThis paper shows the feasibility of eavesdropping phone calls by detecting minute vibrations produced by the earpiece device used in phone calls using mmWave radars. While the sensor data is very noisy, mmSpy proposes a range of techniques from statistical noise correction, machine learning based modeling, as well as domain adaptation to develop robust models for speech recognition with low overhead of training. Extensive measurements demonstrate the feasibility of the attack. The proliferation of off-the-shelf mmWave devices both for 5G networking as well as in sensing applications makes this attack of critical concern in the context of speech privacy.\n\n\nIX. ACKNOWLEDGEMENT\n\nWe are grateful to the reviewers and the anonymous shepherd for feedback. This research was partially supported by NSF grants CNS-2008384, and CNS-1956276. We also thank Ankush Mishra for help with some of the experiments, and Trent Jaeger for feedback on the paper draft. APPENDIX A. Train/Test split across Phone Models and Frequency Bands Fig. 24 depicts the accuracy in mmSpy across several combination of train/test split were explored where training and test data come from different phone models. The y-labels indicate the source of training data whereas the labels on each bar indicate the source of test data. The results include data averaged from 1-6 ft for AudioMNIST dataset. Note that we do not assume access to training data from the victim's phone in any of the above cases. For cases where training and testing data is coming from the same phone model, they are generated from two different phones of the same model. Evidently the accuracy levels with train/test data split across different phone models are lower than the overall accuracy levels where training data incorporates data from the same phone model. We hypothesize the difference comes because of the difference in material properties among smartphones which affect the properties of acoustic vibrations. Nevertheless the accuracy levels are still substantially higher than random guessing (10%) which can result in leakage of information. Training and test split across 60 and 77 GHz spectrum also shows a similar trend because the phase variations are a function of the wavelength. Fig. 25 further depicts cases where training data is derived from two settings and tested on a third different setting. These accuracies are higher in comparison to cases where training data is derived from only a single setting. This indicates that accumulating more training data from diverse phone models can improve the robustness when testing is conducted on a new phone model not included in the training dataset. 20 \n\n\nB. System Parameters\n\nExpanding on the high level overview in Section II-C, we provide a detailed description of the system parameters  in this section. From each chirp, we select the FFT-peak corresponding to the reflection from a phone and extract the phase. Thus, every chirp results in a single sample that can be converted to audio. To be more specific, the variation in phase of the FFT-peak from the reflection of the phone is the raw audio signal extracted from the radar. We term the frequency of chirp transmission as the phase sampling frequency since the phase of the FFT peak is selected and converted to audio. The necessary chirp parameters that determine the phase sampling frequency are:\n\n1 Start Frequency: The starting frequency is the initial frequency at which the radar starts emitting a signal. In our system, the starting frequency is set as 77GHz. 2 Frequency Slope (MHz/\u00b5s): The TI AWR1843BOOST can modulate the chirp frequency linearly. The frequency slope determines the rate at which the frequency changes. In mmSpy, we set the frequency slope as 30MHz/\u00b5s. There are  practical limitations with setting a slope higher than this. For chirps with a small cycle time, if the slope is really high, the received signals become noisy as the system requires some time to cool down when transitioning quickly from the highest to the lowest frequency. 3 Idle Time: At the end of each chirp, the system is required to stay idle for sometime in order to avoid noise due to heat. The idle time in mmSpy is a low 20\u00b5s. 4 TX Start Time: The TX start time determines the time the transmitter takes to begin transmitting with respect to the start of a cycle. In our system, this is set as a low 10\u00b5s. 5 ADC Start Time: The ADC start time determines the time the ADC (at the RX) takes to begin converting received chirps. Note that the TX and ADC begin at the same instance of time but the TX start time can be earlier than the ADC start time. However, in mmSpy, the TX start time and the ADC start time are both set to 10\u00b5s in order to avoid further overhead and time delays and maximize the resolution of sensing.\n\n6 ADC Samples: The number of ADC samples collected at the receiver is determined by this parameter. The ADC begins sampling at the the ADC start time and ends when this fixed number of samples have been collected. In mmSpy, the number of ADC samples is set to 256. 7 Sample Rate: The sample rate determines the rate at which discrete ADC samples are collected at the receiver. The TI AWR1843BOOST has an upper limit of 25Msps for realvalued data, and 12.5Msps for complex in-phase/quadrature (IQ) data. mmSpy collects IQ data and the sample rate is set as 10Msps. 8 Ramp End Time: The ramp end time determines the duration for which a chirp is emitted. It also determines the bandwidth of the transmitted signal, and consequently, the maximum range that can be detected. The ramp end time was set as 60\u00b5s. 9 Chirp Cycle Time: This is the sum of the idle time and the ramp up time. One value of phase is extracted per cycle. The important parameters for the frames are:\n\n\u2022 No. of Chirp Loops: The number of chirp loops determines the number of chirps within a frame. It is set as 128 in our system. \u2022 No. of Frames: The number of frames that are transmitted and received is set as 800. \u2022 Periodicity (ms): The periodicity of a frame is the total duration over which a frame is transmitted and received.\n\nIn mmSpy, this is set as 10.64 milliseconds. \u2022 Duty Cycle (%): The duty cycle of a frame is the amount of time for which frames are actively transmitted and received. The TI AWR1843BOOSTe requires that the device not be used on a 100% duty cycle, so as to allow it to cool down between frames. We use a duty cycle of 96.2%.\n\nA few key considerations are made in setting the periodicity. First, the lower the periodicity, the better, as that allows us to capture more chirps within a given time period. Second, since there is a discontinuity between frames in order to allow the device to settle down (duty cycle is < 100). We decide to pad phase values due to such discontinuity between two frames with zeros. So the periodicity should be set such that the device is able to function at the assigned periodicity and that the number of zeros padded between frames is a discrete number. Additionally, we decided to use the same radar parameters for both the AWR1843 and IWR6843ISK, and we find that the settings we have mentioned work for both. We set the periodicity to 10.64ms as it is the smallest periodicity for which a discrete number of zeros can be padded between frames captured from both radars. The below equations further elaborate on the interrelationships between various system parameters as well as the computation of the final sampling rate based on the chosen parameter setting.\n\nt ramp = t adc-start + t adc-sampling + t misc (8) where t misc is the time spent transmitting at the end of a chirp cycle that is not sampled by the receiver.\nt cycle = t idle + t ramp(9)\nIn mmWave studio, we can specify the values of t ramp and t idle . Let the number of chirps be given by n chirps and the number of zero skips between two frames be given by n skips . Thus, the frame periodicity (p) is given by: p = (n chirps + n skips ) \u00d7 t cycle (10) In mmSpy, we set n chirps = 128 and n skips = 5. This implies, p = (128 + 5) \u00d7 t cycle = 133 \u00b7 t cycle (11) Since one phase value is extracted from each chirp cycle, the sampling rate F s is given as:\nF s = 1 t cycle(12)\nWe need to set t ramp and t idle such that the radar can successfully transmit and receive. In mmSpy, we set the values as t ramp = 60\u00b5s and t idle = 20\u00b5s. Thus, t cycle = 80\u00b5s. This implies, F s = 1 t cycle = 12500Hz = 12.5kHz (13) and p = 133 \u00b7 80\u00b5s = 10.64ms (14) Thus, the values of frame periodicity is set as 10.64ms in mmSpy, ramp end time is set as 60\u00b5s and idle time is set as 20\u00b5s. This results in a total bandwidth of 1798.92MHz. For mmSpy, we downsample the audio from 12.5kHz to 8kHz. Based on the Nyquist sampling theorem, the highest frequency audio signal that can thus be captured is 4kHz, which is adequate for speech recognition tasks.\n\n\nC. Size of Attack Equipment\n\nThe current experimental setup is bulky. However, we note that the actual mmWave chip as highlighted in Figure 31 is only 2cm\u00d72cm in size, and the dimensions of the antenna is 2.5cm\u00d73cm. This can be integrated into a concealed PCB to enforce wireless wiretapping [57] and the raw data can be streamed to a smartphone with powerful GPU via 5G communication which can support Gbps data rates [28] sufficient for streaming the raw data at 25 MHz sampling rate (same as the sampling rate of our data acquisition device DCA1000). The development board shown in the figure is only used in the 'prototypying phase' as this is the standard procedure in many IoT applications to extensively test the prototype before rolling out on a compact PCB [32]. Our future work will include testing the feasibility of such a fabrication to create a smaller attack device.  \n\n\nD. Attack with 5G routers\n\nAt a high level, if an adversary gains access to the physical layer of a 5G router, or use a software-defined 5G radios which are becoming popular [70], [71], then they can modulate emitted radio waves. In such a scenario, it might be possible to modulate and mix sent and received signals to replicate an attack like mmSpy. At this point in time, this is a preemptive estimate of the possibility of such an attack; one of the reasons is that 5G has not yet fully proliferated as a popular technology. One of the key aspects of mmSpy is the short wavelength of the carrier wave used (which is of the order of millimeters), which makes tiny phase changes easy to detect: and this is a commonality that automotive radars share with commercial 5G appliances. We already have various hardware and open source software tools that can allow end users to build custom WiFi hardware [58]. We believe that with time, it will be possible to build adversarially-capable 5G hardware based on the same prototyping tools that enable their usual functionality.\n\nFig. 2 :Fig. 3 :\n23Earpiece locations in popular phone models (a) iPhone 12 ((a) An FMCW signal with linearly increasing frequency (b)\n\nFig. 5 :\n5(a) A series of FMCW chirps are grouped into frames (b) Key parameters involved in the cycle of a single chirp.Fig. from[16].\n\nFig. 6 :\n6Threat model of mmSpy. The attacker transmits mmWave signals towards a victim's phone and measures reflections. By analyzing the phases of reflections, the earpiece vibrations can be detected leading to reconstruction of the audio as well as speech classification.\n\nFig. 6\n6depicts the threat model in mmSpy.\n\nFig. 8 :\n8Statistical error correction: (a) Noisy phase data (b) Phase data after elimination of noise.\n\nFig. 9 :\n9Preprocessing and noise subtraction (the word spoken is \"two\") -(a) Raw signal (b) After bandpass filtering (c) After spectral subtraction.\n\n\nBased on the thresholding, a 0/1 binary mask is computed from spectrogram O. The 0/1 masked values are further smoothed based on Gaussian blurring [72] with a kernel of size 3 \u00d7 3 resulting in a masking matrix M with values between 0 and 1. The enhanced output O \u2032 is then calculated as O \u2032 = I \u2299 M . We compare the performance of both O, and O \u2032 in Section V.\n\nFig. 10 :\n10Architecture of audio reconstruction network.\n\nFig. 11 :\n11Architecture of speech classification network.\n\nFig. 12 :\n12Experimental setup in mmSpy. Off the shelf mmWave radar device is used to detect earpiece vibrations from a smartphone.\n\n\nThe dataset consists of 38546 samples of the following speech commands: ['down', 'go', 'left', 'no', 'off', 'on', 'right', 'stop', 'up', 'yes'\n\n\n(a) \"S20 (77 GHz)\" -results from Samsung S20 at 77 GHz with AudioMNIST. (b) \"S20 (60 GHz)\" -results from Samsung S20 at 60 GHz with AudioMNIST. (c) \"Pixel (77 GHz)\" -results from Google Pixel 4a at 77 GHz with AudioMNIST. (d) S20 (Sp, 77 GHz)\" -results from Samsung S20 at 77 GHz with Speech commands dataset.\n\nFig. 13 :\n13Qualitative Results (at 3ft range): Speech commands. While the raw sensor data (top row) is noisy, mmSpy's reconstruction (second row) is able to extract the key spectro-temporal trends in the noisy sensor data. The masking ideas (third row) allows focusing on distortion free voiced components from the input. The enhanced outputs looks visually similar to the true audio spectrograms (bottom row).\n\nFig. 14 :\n14Qualitative Results (at 3ft range): Audio MNIST. Similar to speech commands, the audio reconstruction model is able to extract the key spectro-temporal trends from noisy sensor data. of the ML algorithms in mmSpy in reducing the MSE.\n\nFig. 15 :\n15Reconstruction error (a) MSE vs Range (S20, 77 GHz) (b) Average MSE across settings.\n\nFig. 16 :\n16Power Levels vs Range\n\nFig. 17 :\n17the accuracy as a function of different users. The results are averaged over the entire range of 1 \u2212 6f t where the power level related to noise varies between 4.4 \u2212 0.2dB. These results are only based on AudioMNIST dataset since the speech command dataset is a crowd-sourced dataset that does not have classes organized by users. Given that the model has been trained from Accuracy vs Users\n\nFig. 18 :\n18While synthetic data bootstraps the training, domain adaptation substantially boosts the accuracy with small real training data.\n\nFig. 19 :\n19w. ambient noise) Earpiece (w. noise jam) Radar Data (w. ambient noise) Radar Data (w. noise jam) Earpiece vs radar power levels in normal and noisy setting audio is feeble and becomes easily buried under the noise floor. The power levels when the earpiece is playing is close to 0dB relative to ambient power levels, thus it is hard to distinguish whether the earpiece is playing sound or silent. The figure also depicts the performance of radar under both conditions. Evidently, the existence of external noise does not interfere with the signal strength of detection by the radar since the radar picks up the vibrations directly from the source of the vibration. In addition,Fig 20 showssamples of spectrograms from testing in the noisy environment with the loudspeaker. The microphone spectrum mainly consists of white noise\n\nFig. 20 :\n20Audio spectrograms (range = 3ft) from (a) Raw radar data (b) Reconstructed audio by mmSpy before masking (b) Reconstructed audio by mmSpy after masking (c) Ground truth (d) Microphone colocated with the radar. mmSpy's spectra closely match the ground truth whereas a co-located microphone only detects noise.\n\nFig. 21 :\n21Accuracy under various interference settings (range = 3ft) Train/Test split across Phone Models and Frequency Bands: We discuss the feasibility of training and testing on different brands of phones in Appendix A.\n\nFig. 22 :\n22A test subject holding the phone at a distance of 3 ft from the radar device.\n\n\nCost of Model Training: Training the classifier using synthetic data takes 10.29 minutes on average. Since the domain adaptation is done on a smaller set of real examples, the adaptation for the classifier takes 43.8 seconds on average.\n\nFig. 23 :\n23Hand Coverage Experiments (a) Body motion artifacts can be seen in the raw audio (b) Zoomed in version of the raw audio.\n\n( a )\naRaw audio spectrogram (distance = 3ft, Recording [23]) (b) Enhanced audio spectrogram (distance = 3ft, Recording [22] )Fig. 27: \"Twinkle Twinkle Little Star\" -sung by a child, with light music in the background.\n\n( a )\naRaw audio spectrogram (distance = 3ft, Recording [21]) (b) Enhanced audio spectrogram (distance = 3ft, Recording [20]) Fig. 28: \"Rondo Alla Turca\" (\"Turkish March\") -composition by Mozart.\n\nFig. 29 :\n29Confusion Matrices for S-20 at 77 GHz with data from 1-6 ft combined.\n\nFig. 30 :\n30Scale of development arrangement.\n\nFig. 31 :\n31Scale of chip and antenna.\n\n\nThe above parameters were varied using a grid search as follows: learning rate in the set of {0.001, 0.005, 0.01, 0.05}, square kernel sizes {3, 5, 7}, number of resnet blocks 1 \u2212 3, number of filters per convolutional layer in the resent blocks as {64, 128, 256}, number of convolutional filters in the deep convolutional layers as {64, 128, 256, 512}, the number of nodes per fully connected top layer as {128, 256, 512}. We use randomized cross-validation to tune the hyperparameters for the model, and run multiple cross-validation programs on a campus GPU cluster concurrently.\n\nTABLE I :\nIAccuracy vs distance under different settings\n\nTable\nII outlines applications (both current and future) that reply on 5G technology. We believe the attack is relevant in the context of applications outlined in the table.Application \nFrequency Band \nAutonomous Driving \n77-81GHz [50], [68], 76GHz [102], [15] \nIndustrial IoT \n77-81GHz [62] \nHealthcare \n76GHz [96], 77-81GHz [56] \n5G Communication \n60GHz [75], [19], [2] \nAugmented and Virtual Reality \n77-81GHz [97], [54], 60GHz ([47], Google Soli) \nRemote Sensing \n60GHz [94] \nSmart Cities \n[2], [3], [1] \n\n\n\nTABLE II :\nIIUse of mmWave bands in various applications.\n\n\nFig. 24: Train/Test split across different phones and spectrum.Fig. 25: Train/Test split across different phones and spectrum.(a) Raw audio spectrogram (distance = 3ft, Recording [11]) (b) Enhanced audio spectrogram (distance = 3ft, Recording [10]) Fig. 26: \"I Have A Dream\" -speech by Dr. Martin Luther King Jr.30 \n40 \n50 \n60 \n70 \n80 \n\nAccuracy (%) \n\nPixel (77GHz) \n\nS20 (60GHz) \n\nS20 (77GHz) \n\nS20 (77GHz) \n\nS20 (77GHz) \n\nS20 (77GHz) \n\nS20 (60GHz) \n\nS20 (60GHz) \n\nS20 (60GHz) \n\nPixel (77GHz) \n\nPixel (77GHz) \n\nPixel (77GHz) \n\n20 \n30 \n40 \n50 \n60 \n70 \n\nAccuracy (%) \n\nS20 (60GHz), Pixel (77GHz) \n\nS20 (77GHz), Pixel (77GHz) \n\nS20 (77GHz), S20 (60GHz) \nPixel (77GHz) \n\nS20 (60GHz) \n\nS20 (77GHz) \n\n(a) AudioMNIST \n\nClass \nPrecision \nRecall \nF1-Score \n0 \n0.79 \n0.83 \n0.83 \n1 \n0.65 \n0.66 \n0.66 \n2 \n0.6 \n0.51 \n0.51 \n3 \n0.49 \n0.55 \n0.55 \n4 \n0.72 \n0.71 \n0.71 \n5 \n0.76 \n0.68 \n0.68 \n6 \n0.82 \n0.78 \n0.78 \n7 \n0.75 \n0.88 \n0.88 \n8 \n0.66 \n0.72 \n0.72 \n9 \n0.69 \n0.61 \n0.61 \n\n(b) Speech Commands \n\nClass \nPrecision \nRecall \nF1-Score \nyes \n0.67 \n0.68 \n0.68 \nno \n0.52 \n0.66 \n0.66 \ngo \n0.74 \n0.63 \n0.63 \nstop \n0.47 \n0.46 \n0.46 \non \n0.64 \n0.62 \n0.62 \noff \n0.51 \n0.47 \n0.47 \nleft \n0.44 \n0.54 \n0.54 \nright \n0.53 \n0.56 \n0.56 \nup \n0.51 \n0.45 \n0.45 \ndown \n0.51 \n0.48 \n0.48 \n\n\n\nTABLE III :\nIIIDescriptive statistics for S20 at 77 GHz with data from 1-6 ft distance combined.\nEarpiece speaker is used to listen to incoming calls, which is different from inbuilt loudspeakers. This paper focuses on eavesdropping earpiece devices whose vibrations are much smaller than loudspeakers\nDue to the overlapping windows used in creating spectrograms, this creates a truncation of approximately 5.48% of the final time domain output with respect to the size of the input, which we ignore in this paper.\n\n5g use cases: 31 examples that showcase what 5g is capable of. 5g use cases: 31 examples that showcase what 5g is capable of. https: //www.5gradar.com/features/what-is-5g-these-use-cases-reveal-all.\n\nAlba iulia smart city pilot project. Alba iulia smart city pilot project. https://sustainablecities.eu/ transformative-actions-database/?c=search&action id=ixgrulm3.\n\nAn/avr-2 laser warning system. An/avr-2 laser warning system. https://fas.org/man/dod-101/sys/ac/ equip/an-avr-2.htm.\n\nAudio demo of mmspy. Audio demo of mmspy. https://www.dropbox.com/sh/ jppc7pg1881y51a/AAD9cHvCRWtXt MFCko96eha?dl=0.\n\nAudio recording after compensation of body signals. Audio recording after compensation of body signals. https:// www.dropbox.com/s/3m9xop64ja59jz0/4 23 43.wav?dl=0.\n\nAudio recording polluted by body signals. Audio recording polluted by body signals. https://www.dropbox.com/ s/hyc4xr62e4av5uy/main body vib.wav?dl=0.\n\nAwr1843 single-chip 76-ghz to 81-ghz automotive radar sensor evaluation module. Awr1843 single-chip 76-ghz to 81-ghz automotive radar sen- sor evaluation module. https://www.ti.com/store/ti/en/p/product/?p= AWR1843BOOST.\n\nBoosting smart manufacturing with 5g wireless connectivity. Boosting smart manufacturing with 5g wireless connectivity. https:// www.ericsson.com/en/reports-and-papers/ericsson-technology-review/ articles/boosting-smart-manufacturing-with-5g-wireless-connectivity.\n\nI have a dream speech, enhanced recording. I have a dream speech, enhanced recording. https://www.dropbox.com/ s/ndwff7slqwx55ig/i have a dream.wav?dl=0.\n\nI have a dream speech, raw recording. I have a dream speech, raw recording. https://www.dropbox.com/s/ oyiuv4ne4jzp6fv/i have a dream.wav?dl=0.\n\nManaging interference in fmcw radar systems. Managing interference in fmcw radar systems. https://training.ti.com/ managing-interference-fmcw-radar-systems.\n\nMg360 millitronic. Mg360 millitronic. https://millitronic.com.tw/mg360/.\n\nO2 partners with trl testbed to bring 5g-powered driverless cars to london. O2 partners with trl testbed to bring 5g-powered driverless cars to london. https://www.5gradar.com/news/o2-partners-with-trl-testbed- to-bring-5g-powered-driverless-cars-to-london.\n\nProgramming chirp parameters in ti radar devices. Programming chirp parameters in ti radar devices. https:\n\nReal-time data-capture adapter for radar sensing evaluation module. Real-time data-capture adapter for radar sensing evaluation module. https://www.ti.com/tool/DCA1000EVM.\n\nTop use cases for 5g technology. Top use cases for 5g technology. https://www.intel.com/content/www/ us/en/wireless-network/5g-use-cases-applications.html.\n\nTurkish march, enhanced recording. Turkish march, enhanced recording. https://www.dropbox.com/s/ x63by49yfxoys1h/turkish march.wav?dl=0.\n\nTurkish march, raw recording. Turkish march, raw recording. https://www.dropbox.com/s/ zv0phre4fn3pr62/turkish march.wav?dl=0.\n\nTwinkle twinkle little star, enhanced recording. Twinkle twinkle little star, enhanced recording. https: //www.dropbox.com/s/o375a03z31eimwb/twinkle twinkle little star.wav?dl=0.\n\nTwinkle twinkle little star, raw recording. Twinkle twinkle little star, raw recording. https://www.dropbox.com/ s/4i1wtkdyg8kl42k/twinkle twinkle little star.wav?dl=0.\n\nUsrp n210 software defined radio (sdr. Usrp n210 software defined radio (sdr). https://www.ettus.com/all- products/un210-kit/.\n\nVibration: Origins, effects, solutions. Vibration: Origins, effects, solutions. https://www.gcaudio.com/tips- tricks/vibration-origins-effects-solutions/.\n\nXr700 -nighthawk pro gaming router. Xr700 -nighthawk pro gaming router. https://www.netgear.com/ support/product/XR700.aspx.\n\nZoom zh1 h1 handy portable digital recorder. Zoom zh1 h1 handy portable digital recorder. https: //www.amazon.com/Zoom-ZH1-Portable-Digital-Recorder/dp/ B003QKBVYK.\n\nWhat is 5g: Everything you need to know about 5g: 5g faq. What is 5g: Everything you need to know about 5g: 5g faq, May 2021. https://www.qualcomm.com/5g/what-is-5g.\n\nIntuitive explanation of skip connections in deep learning. N Adaloglou, ADALOGLOU, N. Intuitive explanation of skip connections in deep learning. https://theaisummer.com/ (2020).\n\nSpeechless: Analyzing the threat to speech privacy from smartphone motion sensors. S A Anand, Al, 2018 IEEE Symposium on Security and Privacy. IEEEANAND, S. A., ET AL. Speechless: Analyzing the threat to speech privacy from smartphone motion sensors. In 2018 IEEE Symposium on Security and Privacy (SP) (2018), IEEE, pp. 1000-1017.\n\nSpearphone: a lightweight speech privacy exploit via accelerometer-sensed reverberations from smartphone loudspeakers. S A Anand, Al, Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks. the 14th ACM Conference on Security and Privacy in Wireless and Mobile NetworksANAND, S. A., ET AL. Spearphone: a lightweight speech privacy exploit via accelerometer-sensed reverberations from smartphone loud- speakers. In Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks (2021), pp. 288-299.\n\nEverything you need to know about iot prototyping. A Ashwini, ASHWINI, A. Everything you need to know about iot prototyping, Mar 2020. https://medium.com/swlh/everything-you-need-to-know-about- iot-prototyping-e4ad2739bc6a.\n\nLearning-based practical smartphone eavesdropping with built-in accelerometer. Z Ba, Et Al, Proceedings of the Network and Distributed Systems Security (NDSS) Symposium (2020). the Network and Distributed Systems Security (NDSS) Symposium (2020)BA, Z., ET AL. Learning-based practical smartphone eavesdropping with built-in accelerometer. In Proceedings of the Network and Distributed Systems Security (NDSS) Symposium (2020), pp. 23-26.\n\nClinical measurement of speech and voice. R J Baken, Al, Cengage LearningBAKEN, R. J., ET AL. Clinical measurement of speech and voice. Cengage Learning, 2000.\n\nPointillism: accurate 3d bounding box estimation with multi-radars. K Bansal, Et Al, Proceedings of the 18th Conference on Embedded Networked Sensor Systems (2020). the 18th Conference on Embedded Networked Sensor Systems (2020)BANSAL, K., ET AL. Pointillism: accurate 3d bounding box estimation with multi-radars. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems (2020), pp. 340-353.\n\nInterpreting and explaining deep neural networks for classification of audio signals. S Becker, Et Al, CoRR abs/1807.03418BECKER, S., ET AL. Interpreting and explaining deep neural networks for classification of audio signals. CoRR abs/1807.03418 (2018).\n\nHard drive side-channel attacks using smartphone magnetic field sensors. S Biedermann, Et Al, International Conference on Financial Cryptography and Data Security. SpringerBIEDERMANN, S., ET AL. Hard drive side-channel attacks using smartphone magnetic field sensors. In International Conference on Financial Cryptography and Data Security (2015), Springer, pp. 489- 496.\n\nSuppression of acoustic noise in speech using spectral subtraction. S Boll, IEEE Transactions on acoustics, speech, and signal processing. 27BOLL, S. Suppression of acoustic noise in speech using spectral subtraction. IEEE Transactions on acoustics, speech, and signal processing 27, 2 (1979), 113-120.\n\nAudio adversarial examples: Targeted attacks on speech-to-text. N Carlini, Et Al, IEEE Security and Privacy Workshops (SPW). IEEECARLINI, N., ET AL. Audio adversarial examples: Targeted attacks on speech-to-text. In 2018 IEEE Security and Privacy Workshops (SPW) (2018), IEEE, pp. 1-7.\n\nListen, attend and spell: A neural network for large vocabulary conversational speech recognition. W Chan, Et Al, 2016 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEECHAN, W., ET AL. Listen, attend and spell: A neural network for large vocabulary conversational speech recognition. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2016), IEEE, pp. 4960-4964.\n\nThe visual microphone: Passive recovery of sound from video. A Davis, Et Al, DAVIS, A., ET AL. The visual microphone: Passive recovery of sound from video.\n\nVisual vibrometry: Estimating material properties from small motion in video. A Davis, Et Al, Proceedings of the ieee conference on computer vision and pattern recognition. the ieee conference on computer vision and pattern recognitionDAVIS, A., ET AL. Visual vibrometry: Estimating material properties from small motion in video. In Proceedings of the ieee conference on computer vision and pattern recognition (2015), pp. 5335-5343.\n\nImagenet: A large-scale hierarchical image database. J Deng, Et Al, IEEE CVPR. DENG, J., ET AL. Imagenet: A large-scale hierarchical image database. In IEEE CVPR (2009).\n\nJ Devlin, A L Et, Bert, arXiv:1810.04805Pre-training of deep bidirectional transformers for language understanding. arXiv preprintDEVLIN, J., ET AL. Bert: Pre-training of deep bidirectional trans- formers for language understanding. arXiv preprint arXiv:1810.04805 (2018).\n\nLiquid: A wireless liquid identifier. A Dhekne, Et Al, Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services. the 16th Annual International Conference on Mobile Systems, Applications, and ServicesDHEKNE, A., ET AL. Liquid: A wireless liquid identifier. In Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services (2018), pp. 442-454.\n\nThe importance of skip connections in biomedical image segmentation. M Drozdzal, Et Al, Deep learning and data labeling for medical applications. SpringerDROZDZAL, M., ET AL. The importance of skip connections in biomedical image segmentation. In Deep learning and data labeling for medical applications. Springer, 2016, pp. 179-187.\n\nEdge computing meets millimeter-wave enabled vr: Paving the way to cutting the cord. M S Elbamby, Al, 2018 IEEE Wireless Communications and Networking Conference. IEEEELBAMBY, M. S., ET AL. Edge computing meets millimeter-wave enabled vr: Paving the way to cutting the cord. In 2018 IEEE Wireless Communications and Networking Conference (WCNC) (2018), IEEE, pp. 1-6.\n\nAdversarial representation learning for private speech generation. D Ericsson, Et Al, arXiv:2006.09114arXiv preprintERICSSON, D., ET AL. Adversarial representation learning for private speech generation. arXiv preprint arXiv:2006.09114 (2020).\n\nH Farrukh, Et Al, arXiv:2103.05840Side-channel attack on stylus pencil through sensors. 3arXiv preprintFARRUKH, H., ET AL. S3: Side-channel attack on stylus pencil through sensors. arXiv preprint arXiv:2103.05840 (2021).\n\nRobust traffic and intersection monitoring using millimeter wave sensors. K Garcia, Et Al, GARCIA, K., ET AL. Robust traffic and intersection monitoring using millimeter wave sensors.\n\nSpectral masking and filtering. T Gerkmann, Et Al, GERKMANN, T., ET AL. Spectral masking and filtering, 2018.\n\nSignal estimation from modified short-time fourier transform. D Griffin, Et Al, IEEE Transactions on Acoustics, Speech, and Signal Processing. 32GRIFFIN, D., ET AL. Signal estimation from modified short-time fourier transform. IEEE Transactions on Acoustics, Speech, and Signal Processing 32, 2 (1984), 236-243.\n\nHigh resolution millimeter wave imaging for selfdriving cars. J Guan, Et Al, arXiv:1912.09579arXiv preprintGUAN, J., ET AL. High resolution millimeter wave imaging for self- driving cars. arXiv preprint arXiv:1912.09579 (2019).\n\nThrough fog high-resolution imaging using millimeter wave radar. J Guan, Et Al, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2020). GUAN, J., ET AL. Through fog high-resolution imaging using millime- ter wave radar. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2020), pp. 11461-11470.\n\nFood and liquid sensing in practical environments using rfids. U Ha, Et Al, 17th {USENIX} Symposium on Networked Systems Design and Implementation. 20HA, U., ET AL. Food and liquid sensing in practical environments using rfids. In 17th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 20) (2020), pp. 1083-1100.\n\nU Ha, A L Et, Wistress, Contactless stress monitoring using wireless signals. HA, U., ET AL. Wistress: Contactless stress monitoring using wireless signals.\n\nThe wiretapping of things. E Haber, UC Davis L. Rev. 53733HABER, E. The wiretapping of things. UC Davis L. Rev. 53 (2019), 733.\n\n. T M Hackett, Al, Procedia Engineering. 159HACKETT, T. M., ET AL. Procedia Engineering 159 (2016), 158-166.\n\nPitchln: eavesdropping via intelligible speech reconstruction using non-acoustic sensor fusion. J Han, Et Al, Proceedings of the 16th ACM/IEEE International Conference on Information Processing in Sensor Networks. the 16th ACM/IEEE International Conference on Information Processing in Sensor NetworksHAN, J., ET AL. Pitchln: eavesdropping via intelligible speech re- construction using non-acoustic sensor fusion. In Proceedings of the 16th ACM/IEEE International Conference on Information Processing in Sensor Networks (2017), pp. 181-192.\n\nPre-trained alexnet architecture with pyramid pooling and supervision for high spatial resolution remote sensing image scene classification. X Han, Et Al, Remote SensingHAN, X., ET AL. Pre-trained alexnet architecture with pyramid pooling and supervision for high spatial resolution remote sensing image scene classification. Remote Sensing (2017).\n\nDeep residual learning for image recognition. K He, Et Al, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionHE, K., ET AL. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (2016), pp. 770-778.\n\nmmvib: micrometer-level vibration measurement with mmwave radar. C Jiang, Et Al, Proceedings of the 26th Annual International Conference on Mobile Computing and Networking. the 26th Annual International Conference on Mobile Computing and NetworkingJIANG, C., ET AL. mmvib: micrometer-level vibration measurement with mmwave radar. In Proceedings of the 26th Annual International Conference on Mobile Computing and Networking (2020), pp. 1-13.\n\nImagenet classification with deep convolutional neural networks. A Krizhevsky, Et Al, NIPS. KRIZHEVSKY, A., ET AL. Imagenet classification with deep convolu- tional neural networks. In NIPS (2012).\n\nGhost talk: Mitigating emi signal injection attacks against analog sensors. D F Kune, Al, 2013 IEEE Symposium on Security and Privacy. IEEEKUNE, D. F., ET AL. Ghost talk: Mitigating emi signal injection attacks against analog sensors. In 2013 IEEE Symposium on Security and Privacy (2013), IEEE, pp. 145-159.\n\nOrthogonal frequency division multiplexing for wireless communications. Y G Li, Al, Springer Science & Business MediaLI, Y. G., ET AL. Orthogonal frequency division multiplexing for wireless communications. Springer Science & Business Media, 2006.\n\nWaveSpy: Remote and through-wall screen attack via mmWave sensing. Z Li, Et Al, 2020 IEEE Symposium on Security and Privacy (SP). IEEELI, Z., ET AL. WaveSpy: Remote and through-wall screen attack via mmWave sensing. In 2020 IEEE Symposium on Security and Privacy (SP) (May 2020), IEEE.\n\nOtsu method and k-means. D Liu, Et Al, Ninth International Conference on Hybrid Intelligent Systems. IEEE1LIU, D., ET AL. Otsu method and k-means. In 2009 Ninth Interna- tional Conference on Hybrid Intelligent Systems (2009), vol. 1, IEEE, pp. 344-349.\n\nSingle-chip mmwave radar aided egomotion estimation via deep sensor fusion. C X Lu, A L Et, Milliego, Proceedings of the 18th Conference on Embedded Networked Sensor Systems. the 18th Conference on Embedded Networked Sensor SystemsNew York, NY, USAAssociation for Computing MachinerySenSys '20LU, C. X., ET AL. Milliego: Single-chip mmwave radar aided egomotion estimation via deep sensor fusion. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems (New York, NY, USA, 2020), SenSys '20, Association for Computing Machinery, p. 109-122.\n\nGyrophone: Recognizing speech from gyroscope signals. Y Michalevsky, Et Al, 23rd {USENIX} Security Symposium. {USENIX} Security 14MICHALEVSKY, Y., ET AL. Gyrophone: Recognizing speech from gyroscope signals. In 23rd {USENIX} Security Symposium ({USENIX} Security 14) (2014), pp. 1053-1067.\n\nThe future of 5g with sdr. R Mohammadi, MOHAMMADI, R. The future of 5g with sdr, Mar 2021.\n\nThese cots sdr system solutions focus on 5g. B Muro, MURO, B. These cots sdr system solutions focus on 5g, Aug 2019.\n\nMathematical morphology: from theory to applications. L Najman, Et Al, John Wiley & SonsNAJMAN, L., ET AL. Mathematical morphology: from theory to applications. John Wiley & Sons, 2013.\n\nLamphone: Real-time passive sound recovery from light bulb vibrations. Cryptology ePrint Archive. B Nassi, Et Al, ReportNASSI, B., ET AL. Lamphone: Real-time passive sound recovery from light bulb vibrations. Cryptology ePrint Archive, Report 2020/708, 2020. https://eprint.iacr.org/2020/708.\n\nClassification of breast cancer histology images using alexnet. W Nawaz, Et Al, International conference image analysis and recognition. SpringerNAWAZ, W., ET AL. Classification of breast cancer histology images using alexnet. In International conference image analysis and recog- nition (2018), Springer.\n\nIeee 802.11ad: directional 60 ghz communication for multi-gigabit-per-second wi-fi. T Nitsche, Et Al, invited paperNITSCHE, T., ET AL. Ieee 802.11ad: directional 60 ghz communication for multi-gigabit-per-second wi-fi [invited paper].\n\n. IEEE Communications Magazine. 52IEEE Communica- tions Magazine 52, 12 (2014), 132-141.\n\nAccessory: password inference using accelerometers on smartphones. E Owusu, Et Al, proceedings of the twelfth workshop on mobile computing systems & applications (2012). the twelfth workshop on mobile computing systems & applications (2012)OWUSU, E., ET AL. Accessory: password inference using accelerome- ters on smartphones. In proceedings of the twelfth workshop on mobile computing systems & applications (2012), pp. 1-6.\n\nM Z Ozturk, A L Et, Radiomic, arXiv:2108.03164Sound sensing via mmwave signals. arXiv preprintOZTURK, M. Z., ET AL. Radiomic: Sound sensing via mmwave signals. arXiv preprint arXiv:2108.03164 (2021).\n\nSingle-channel speech enhancement using spectral subtraction in the short-time modulation domain. K Paliwal, Et Al, Speech communication. 52PALIWAL, K., ET AL. Single-channel speech enhancement using spectral subtraction in the short-time modulation domain. Speech communication 52, 5 (2010), 450-475.\n\nA fully convolutional neural network for speech enhancement. S R Park, Al, Proc. Interspeech 2017. Interspeech 2017PARK, S. R., ET AL. A fully convolutional neural network for speech enhancement. In Proc. Interspeech 2017 (2017), pp. 1993-1997.\n\nAutomatic differentiation in pytorch. A Paszke, Et Al, PASZKE, A., ET AL. Automatic differentiation in pytorch.\n\nA Prabhakara, A L Et, Osprey, Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services. the 18th International Conference on Mobile Systems, Applications, and ServicesACMPRABHAKARA, A., ET AL. Osprey. In Proceedings of the 18th In- ternational Conference on Mobile Systems, Applications, and Services (June 2020), ACM.\n\nBert with history answer embedding for conversational question answering. C Qu, Et Al, ACM SIGIR Conference on Research and Development in Information Retrieval. QU, C., ET AL. Bert with history answer embedding for conversational question answering. In ACM SIGIR Conference on Research and Development in Information Retrieval (2019).\n\nIntroduction to mmwave sensing: Fmcw radars. S Rao, Texas Instruments (TI) mmWave Training Series. RAO, S. Introduction to mmwave sensing: Fmcw radars. Texas Instruments (TI) mmWave Training Series (2017).\n\nRipple: Communicating through physical vibration. N Roy, Et Al, 12th {USENIX} Symposium on Networked Systems Design and Implementation. ROY, N., ET AL. Ripple: Communicating through physical vibration. In 12th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 15) (2015), pp. 265-278.\n\nSpying with your robot vacuum cleaner: eavesdropping via lidar sensors. S Sami, Et Al, Proceedings of the 18th Conference on Embedded Networked Sensor Systems (2020). the 18th Conference on Embedded Networked Sensor Systems (2020)SAMI, S., ET AL. Spying with your robot vacuum cleaner: eaves- dropping via lidar sensors. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems (2020), pp. 354-367.\n\nSeanet: A multi-modal speech enhancement network. M Tagliasacchi, Et Al, arXiv:2009.02095arXiv preprintTAGLIASACCHI, M., ET AL. Seanet: A multi-modal speech enhance- ment network. arXiv preprint arXiv:2009.02095 (2020).\n\nPrinciples of voice production. I R Titze, Al, TITZE, I. R., ET AL. Principles of voice production, 1998.\n\nSpeech enhancement using spectral subtraction-type algorithms: A comparison and simulation study. N Upadhyay, Et Al, Procedia Computer Science. 54UPADHYAY, N., ET AL. Speech enhancement using spectral subtraction-type algorithms: A comparison and simulation study. Pro- cedia Computer Science 54 (2015), 574-584.\n\nMole: Motion leaks through smartwatch sensors. H Wang, Et Al, Proceedings of the 21st Annual International Conference on Mobile Computing and Networking. the 21st Annual International Conference on Mobile Computing and NetworkingWANG, H., ET AL. Mole: Motion leaks through smartwatch sensors. In Proceedings of the 21st Annual International Conference on Mobile Computing and Networking (2015), pp. 155-166.\n\nUwhear: through-wall extraction and separation of audio vibrations using wireless signals. Z Wang, Et Al, Proceedings of the 18th Conference on Embedded Networked Sensor Systems (2020). the 18th Conference on Embedded Networked Sensor Systems (2020)WANG, Z., ET AL. Uwhear: through-wall extraction and separation of audio vibrations using wireless signals. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems (2020), pp. 1-14.\n\nSpeech Commands: A Dataset for Limited-Vocabulary Speech Recognition. P Warden, ArXiv e-printsWARDEN, P. Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition. ArXiv e-prints (Apr. 2018).\n\nAcoustic eavesdropping through wireless vibrometry. T Wei, Et Al, Proceedings of the 21st Annual International Conference on Mobile Computing and Networking. the 21st Annual International Conference on Mobile Computing and NetworkingWEI, T., ET AL. Acoustic eavesdropping through wireless vibrometry. In Proceedings of the 21st Annual International Conference on Mobile Computing and Networking (2015), pp. 130-141.\n\nmsense: Towards mobile material sensing with a single millimeter-wave radio. C Wu, Et Al, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies4WU, C., ET AL. msense: Towards mobile material sensing with a single millimeter-wave radio. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 4, 3 (2020), 1-20.\n\nMsense: Towards mobile material sensing with a single millimeter-wave radio. C Wu, Et Al, Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4WU, C., ET AL. Msense: Towards mobile material sensing with a single millimeter-wave radio. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 3 (Sept. 2020).\n\nWaveear: Exploring a mmwave-based noise-resistant speech sensing for voice-user interface. C Xu, Et Al, Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services. the 17th Annual International Conference on Mobile Systems, Applications, and ServicesXU, C., ET AL. Waveear: Exploring a mmwave-based noise-resistant speech sensing for voice-user interface. In Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services (2019), pp. 14-26.\n\nCardiacwave: A mmwave-based scheme of non-contact and high-definition heart activity computing. C Xu, Et Al, Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5XU, C., ET AL. Cardiacwave: A mmwave-based scheme of non-contact and high-definition heart activity computing. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 5, 3 (Sept. 2021).\n\nTowards 3d real-time dynamic human mesh construction using millimeter-wave. H Xue, A L Et, Mmmesh, Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services. the 19th Annual International Conference on Mobile Systems, Applications, and ServicesNew York, NY, USAAssociation for Computing MachineryMobiSys '21XUE, H., ET AL. Mmmesh: Towards 3d real-time dynamic human mesh construction using millimeter-wave. In Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services (New York, NY, USA, 2021), MobiSys '21, Association for Computing Machinery, p. 269-282.\n\nDolphinattack: Inaudible voice commands. G Zhang, Et Al, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. the 2017 ACM SIGSAC Conference on Computer and Communications SecurityZHANG, G., ET AL. Dolphinattack: Inaudible voice commands. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security (2017), pp. 103-117.\n\nPretraining-based natural language generation for text summarization. H Zhang, Et Al, arXiv:1902.09243arXiv preprintZHANG, H., ET AL. Pretraining-based natural language generation for text summarization. arXiv preprint arXiv:1902.09243 (2019).\n\nAccelword: Energy efficient hotword detection through accelerometer. L Zhang, Et Al, Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services. the 13th Annual International Conference on Mobile Systems, Applications, and ServicesZHANG, L., ET AL. Accelword: Energy efficient hotword detection through accelerometer. In Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services (2015), pp. 301-315.\n\nThrough-wall human mesh recovery using radio signals. M Zhao, Et Al, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer VisionZHAO, M., ET AL. Through-wall human mesh recovery using radio signals. In Proceedings of the IEEE/CVF International Conference on Computer Vision (2019), pp. 10113-10122.\n\n5g v2x communication at millimeter wave: rate maps and use cases. W Zheng, Et Al, 2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring). IEEEZHENG, W., ET AL. 5g v2x communication at millimeter wave: rate maps and use cases. In 2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring) (2020), IEEE, pp. 1-5.\n\nFine-tuning convolutional neural networks for biomedical image analysis: actively and incrementally. Z Zhou, Et Al, IEEE CVPR. ZHOU, Z., ET AL. Fine-tuning convolutional neural networks for biomedical image analysis: actively and incrementally. In IEEE CVPR (2017).\n", "annotations": {"author": "[{\"end\":117,\"start\":49},{\"end\":207,\"start\":118}]", "publisher": null, "author_last_name": "[{\"end\":63,\"start\":58},{\"end\":131,\"start\":126}]", "author_first_name": "[{\"end\":57,\"start\":49},{\"end\":125,\"start\":118}]", "author_affiliation": "[{\"end\":116,\"start\":65},{\"end\":206,\"start\":155}]", "title": "[{\"end\":46,\"start\":1},{\"end\":253,\"start\":208}]", "venue": null, "abstract": "[{\"end\":1625,\"start\":303}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b43\"},\"end\":1851,\"start\":1847},{\"attributes\":{\"ref_id\":\"b99\"},\"end\":1930,\"start\":1925},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2003,\"start\":2000},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":2266,\"start\":2262},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2272,\"start\":2268},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":2278,\"start\":2274},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":2284,\"start\":2280},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":6786,\"start\":6782},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":6870,\"start\":6866},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":6971,\"start\":6967},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11642,\"start\":11639},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":12923,\"start\":12919},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":22142,\"start\":22138},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":22148,\"start\":22144},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":22154,\"start\":22150},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":22305,\"start\":22301},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":22464,\"start\":22460},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":22470,\"start\":22466},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":22739,\"start\":22735},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":22932,\"start\":22928},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":22938,\"start\":22934},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":22944,\"start\":22940},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":23755,\"start\":23751},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":23780,\"start\":23776},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":25089,\"start\":25085},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":25820,\"start\":25816},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":25826,\"start\":25822},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":25832,\"start\":25828},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":26041,\"start\":26037},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":26478,\"start\":26474},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":30541,\"start\":30537},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":30547,\"start\":30543},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":30553,\"start\":30549},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31124,\"start\":31120},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":31130,\"start\":31126},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":31226,\"start\":31222},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":34630,\"start\":34627},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":34914,\"start\":34910},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":38797,\"start\":38793},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":39280,\"start\":39276},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":39313,\"start\":39309},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":40159,\"start\":40155},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":40808,\"start\":40804},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":43417,\"start\":43414},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":43497,\"start\":43494},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":44227,\"start\":44223},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":44347,\"start\":44343},{\"attributes\":{\"ref_id\":\"b98\"},\"end\":44483,\"start\":44478},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":44735,\"start\":44731},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":44943,\"start\":44939},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":44961,\"start\":44957},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":45045,\"start\":45041},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":45524,\"start\":45520},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":45935,\"start\":45931},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":46126,\"start\":46122},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":46311,\"start\":46307},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":46436,\"start\":46432},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":47057,\"start\":47053},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":47063,\"start\":47059},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":47760,\"start\":47757},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":47994,\"start\":47990},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":48397,\"start\":48393},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":48634,\"start\":48630},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":48823,\"start\":48819},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":48975,\"start\":48971},{\"attributes\":{\"ref_id\":\"b97\"},\"end\":49140,\"start\":49135},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":49287,\"start\":49283},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":49607,\"start\":49603},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":49836,\"start\":49832},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":49934,\"start\":49930},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":50017,\"start\":50013},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":50243,\"start\":50239},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":50475,\"start\":50471},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":50706,\"start\":50702},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":50743,\"start\":50739},{\"attributes\":{\"ref_id\":\"b100\"},\"end\":50809,\"start\":50804},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":50830,\"start\":50826},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":50853,\"start\":50849},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":50903,\"start\":50899},{\"attributes\":{\"ref_id\":\"b96\"},\"end\":50958,\"start\":50954},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":50983,\"start\":50979},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":51924,\"start\":51920},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":52260,\"start\":52256},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":52436,\"start\":52432},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":52866,\"start\":52862},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":53214,\"start\":53210},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":56214,\"start\":56212},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":61096,\"start\":61093},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":61503,\"start\":61499},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":61611,\"start\":61607},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":61957,\"start\":61953},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":61991,\"start\":61987},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":62678,\"start\":62674},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":62805,\"start\":62801},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":63152,\"start\":63148},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":63446,\"start\":63442},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":63452,\"start\":63448},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":64174,\"start\":64170},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":64612,\"start\":64608}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":64476,\"start\":64341},{\"attributes\":{\"id\":\"fig_1\"},\"end\":64613,\"start\":64477},{\"attributes\":{\"id\":\"fig_2\"},\"end\":64889,\"start\":64614},{\"attributes\":{\"id\":\"fig_3\"},\"end\":64933,\"start\":64890},{\"attributes\":{\"id\":\"fig_4\"},\"end\":65038,\"start\":64934},{\"attributes\":{\"id\":\"fig_5\"},\"end\":65189,\"start\":65039},{\"attributes\":{\"id\":\"fig_6\"},\"end\":65552,\"start\":65190},{\"attributes\":{\"id\":\"fig_7\"},\"end\":65611,\"start\":65553},{\"attributes\":{\"id\":\"fig_8\"},\"end\":65671,\"start\":65612},{\"attributes\":{\"id\":\"fig_9\"},\"end\":65804,\"start\":65672},{\"attributes\":{\"id\":\"fig_10\"},\"end\":65949,\"start\":65805},{\"attributes\":{\"id\":\"fig_11\"},\"end\":66261,\"start\":65950},{\"attributes\":{\"id\":\"fig_12\"},\"end\":66674,\"start\":66262},{\"attributes\":{\"id\":\"fig_13\"},\"end\":66921,\"start\":66675},{\"attributes\":{\"id\":\"fig_14\"},\"end\":67019,\"start\":66922},{\"attributes\":{\"id\":\"fig_15\"},\"end\":67054,\"start\":67020},{\"attributes\":{\"id\":\"fig_16\"},\"end\":67459,\"start\":67055},{\"attributes\":{\"id\":\"fig_17\"},\"end\":67601,\"start\":67460},{\"attributes\":{\"id\":\"fig_18\"},\"end\":68443,\"start\":67602},{\"attributes\":{\"id\":\"fig_19\"},\"end\":68765,\"start\":68444},{\"attributes\":{\"id\":\"fig_20\"},\"end\":68991,\"start\":68766},{\"attributes\":{\"id\":\"fig_21\"},\"end\":69082,\"start\":68992},{\"attributes\":{\"id\":\"fig_22\"},\"end\":69321,\"start\":69083},{\"attributes\":{\"id\":\"fig_23\"},\"end\":69455,\"start\":69322},{\"attributes\":{\"id\":\"fig_24\"},\"end\":69675,\"start\":69456},{\"attributes\":{\"id\":\"fig_25\"},\"end\":69872,\"start\":69676},{\"attributes\":{\"id\":\"fig_27\"},\"end\":69955,\"start\":69873},{\"attributes\":{\"id\":\"fig_28\"},\"end\":70002,\"start\":69956},{\"attributes\":{\"id\":\"fig_29\"},\"end\":70042,\"start\":70003},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":70627,\"start\":70043},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":70685,\"start\":70628},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":71197,\"start\":70686},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":71256,\"start\":71198},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":72508,\"start\":71257},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":72606,\"start\":72509}]", "paragraph": "[{\"end\":2285,\"start\":1644},{\"end\":4150,\"start\":2287},{\"end\":4870,\"start\":4152},{\"end\":6157,\"start\":4872},{\"end\":6690,\"start\":6159},{\"end\":8357,\"start\":6692},{\"end\":9572,\"start\":8359},{\"end\":10337,\"start\":9616},{\"end\":11033,\"start\":10339},{\"end\":11115,\"start\":11035},{\"end\":11380,\"start\":11117},{\"end\":12373,\"start\":11382},{\"end\":12473,\"start\":12391},{\"end\":12771,\"start\":12475},{\"end\":12924,\"start\":12773},{\"end\":13541,\"start\":12939},{\"end\":13645,\"start\":13543},{\"end\":14361,\"start\":13661},{\"end\":14736,\"start\":14363},{\"end\":17880,\"start\":14738},{\"end\":17959,\"start\":17926},{\"end\":18909,\"start\":17961},{\"end\":19894,\"start\":18911},{\"end\":20227,\"start\":19931},{\"end\":21022,\"start\":20229},{\"end\":21224,\"start\":21024},{\"end\":21379,\"start\":21250},{\"end\":21562,\"start\":21381},{\"end\":21611,\"start\":21578},{\"end\":21822,\"start\":21613},{\"end\":21986,\"start\":21864},{\"end\":22604,\"start\":21988},{\"end\":23111,\"start\":22606},{\"end\":23680,\"start\":23154},{\"end\":24520,\"start\":23682},{\"end\":24912,\"start\":24522},{\"end\":26718,\"start\":24941},{\"end\":26916,\"start\":26757},{\"end\":27061,\"start\":26918},{\"end\":27523,\"start\":27063},{\"end\":27889,\"start\":27525},{\"end\":28497,\"start\":27891},{\"end\":29140,\"start\":28543},{\"end\":29370,\"start\":29181},{\"end\":29763,\"start\":29372},{\"end\":30669,\"start\":29765},{\"end\":31528,\"start\":30705},{\"end\":31891,\"start\":31530},{\"end\":32544,\"start\":31893},{\"end\":33205,\"start\":32571},{\"end\":34452,\"start\":33207},{\"end\":34915,\"start\":34454},{\"end\":36532,\"start\":34917},{\"end\":36825,\"start\":36534},{\"end\":37204,\"start\":36827},{\"end\":37607,\"start\":37206},{\"end\":38271,\"start\":37609},{\"end\":41240,\"start\":38273},{\"end\":42430,\"start\":41242},{\"end\":43498,\"start\":42432},{\"end\":43976,\"start\":43500},{\"end\":45847,\"start\":43997},{\"end\":47003,\"start\":45849},{\"end\":48352,\"start\":47005},{\"end\":49564,\"start\":48354},{\"end\":50568,\"start\":49566},{\"end\":51054,\"start\":50570},{\"end\":51365,\"start\":51056},{\"end\":52115,\"start\":51367},{\"end\":52945,\"start\":52117},{\"end\":53523,\"start\":52947},{\"end\":54205,\"start\":53544},{\"end\":56215,\"start\":54229},{\"end\":56922,\"start\":56240},{\"end\":58345,\"start\":56924},{\"end\":59315,\"start\":58347},{\"end\":59648,\"start\":59317},{\"end\":59973,\"start\":59650},{\"end\":61044,\"start\":59975},{\"end\":61205,\"start\":61046},{\"end\":61704,\"start\":61235},{\"end\":62379,\"start\":61725},{\"end\":63265,\"start\":62411},{\"end\":64340,\"start\":63295}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12390,\"start\":12374},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12938,\"start\":12925},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13660,\"start\":13646},{\"attributes\":{\"id\":\"formula_3\"},\"end\":21249,\"start\":21225},{\"attributes\":{\"id\":\"formula_4\"},\"end\":21577,\"start\":21563},{\"attributes\":{\"id\":\"formula_5\"},\"end\":26756,\"start\":26719},{\"attributes\":{\"id\":\"formula_6\"},\"end\":29180,\"start\":29141},{\"attributes\":{\"id\":\"formula_7\"},\"end\":61234,\"start\":61206},{\"attributes\":{\"id\":\"formula_8\"},\"end\":61724,\"start\":61705}]", "table_ref": "[{\"end\":36158,\"start\":36152},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":36767,\"start\":36756},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":37249,\"start\":37242}]", "section_header": "[{\"end\":1642,\"start\":1627},{\"end\":9589,\"start\":9575},{\"end\":9614,\"start\":9592},{\"end\":17900,\"start\":17883},{\"end\":17924,\"start\":17903},{\"end\":19929,\"start\":19897},{\"end\":21862,\"start\":21825},{\"end\":23152,\"start\":23114},{\"end\":24939,\"start\":24915},{\"end\":28541,\"start\":28500},{\"end\":30685,\"start\":30672},{\"end\":30703,\"start\":30688},{\"end\":32569,\"start\":32547},{\"end\":43995,\"start\":43979},{\"end\":53542,\"start\":53526},{\"end\":54227,\"start\":54208},{\"end\":56238,\"start\":56218},{\"end\":62409,\"start\":62382},{\"end\":63293,\"start\":63268},{\"end\":64358,\"start\":64342},{\"end\":64486,\"start\":64478},{\"end\":64623,\"start\":64615},{\"end\":64897,\"start\":64891},{\"end\":64943,\"start\":64935},{\"end\":65048,\"start\":65040},{\"end\":65563,\"start\":65554},{\"end\":65622,\"start\":65613},{\"end\":65682,\"start\":65673},{\"end\":66272,\"start\":66263},{\"end\":66685,\"start\":66676},{\"end\":66932,\"start\":66923},{\"end\":67030,\"start\":67021},{\"end\":67065,\"start\":67056},{\"end\":67470,\"start\":67461},{\"end\":67612,\"start\":67603},{\"end\":68454,\"start\":68445},{\"end\":68776,\"start\":68767},{\"end\":69002,\"start\":68993},{\"end\":69332,\"start\":69323},{\"end\":69462,\"start\":69457},{\"end\":69682,\"start\":69677},{\"end\":69883,\"start\":69874},{\"end\":69966,\"start\":69957},{\"end\":70013,\"start\":70004},{\"end\":70638,\"start\":70629},{\"end\":70692,\"start\":70687},{\"end\":71209,\"start\":71199},{\"end\":72521,\"start\":72510}]", "table": "[{\"end\":71197,\"start\":70860},{\"end\":72508,\"start\":71571}]", "figure_caption": "[{\"end\":64476,\"start\":64361},{\"end\":64613,\"start\":64488},{\"end\":64889,\"start\":64625},{\"end\":64933,\"start\":64899},{\"end\":65038,\"start\":64945},{\"end\":65189,\"start\":65050},{\"end\":65552,\"start\":65192},{\"end\":65611,\"start\":65566},{\"end\":65671,\"start\":65625},{\"end\":65804,\"start\":65685},{\"end\":65949,\"start\":65807},{\"end\":66261,\"start\":65952},{\"end\":66674,\"start\":66275},{\"end\":66921,\"start\":66688},{\"end\":67019,\"start\":66935},{\"end\":67054,\"start\":67033},{\"end\":67459,\"start\":67068},{\"end\":67601,\"start\":67473},{\"end\":68443,\"start\":67615},{\"end\":68765,\"start\":68457},{\"end\":68991,\"start\":68779},{\"end\":69082,\"start\":69005},{\"end\":69321,\"start\":69085},{\"end\":69455,\"start\":69335},{\"end\":69675,\"start\":69464},{\"end\":69872,\"start\":69684},{\"end\":69955,\"start\":69886},{\"end\":70002,\"start\":69969},{\"end\":70042,\"start\":70016},{\"end\":70627,\"start\":70045},{\"end\":70685,\"start\":70640},{\"end\":70860,\"start\":70693},{\"end\":71256,\"start\":71212},{\"end\":71571,\"start\":71259},{\"end\":72606,\"start\":72525}]", "figure_ref": "[{\"end\":5728,\"start\":5722},{\"end\":9116,\"start\":9110},{\"end\":11454,\"start\":11448},{\"end\":11487,\"start\":11481},{\"end\":12119,\"start\":12110},{\"end\":12499,\"start\":12490},{\"end\":13941,\"start\":13935},{\"end\":14560,\"start\":14554},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15036,\"start\":15030},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15111,\"start\":15104},{\"end\":18651,\"start\":18645},{\"end\":18749,\"start\":18743},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20451,\"start\":20441},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":21673,\"start\":21667},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":22952,\"start\":22946},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":25115,\"start\":25108},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":28832,\"start\":28825},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":30109,\"start\":30102},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":30750,\"start\":30743},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":33632,\"start\":33618},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":34961,\"start\":34954},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":35246,\"start\":35237},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":35358,\"start\":35351},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":36691,\"start\":36684},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":36725,\"start\":36716},{\"attributes\":{\"ref_id\":\"fig_16\"},\"end\":36853,\"start\":36846},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":37647,\"start\":37640},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":38403,\"start\":38396},{\"attributes\":{\"ref_id\":\"fig_20\"},\"end\":39560,\"start\":39553},{\"attributes\":{\"ref_id\":\"fig_21\"},\"end\":41000,\"start\":40991},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":41389,\"start\":41379},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":41592,\"start\":41582},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":41634,\"start\":41624},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":41910,\"start\":41899},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":41995,\"start\":41986},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":42676,\"start\":42669},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":43201,\"start\":43192},{\"end\":43281,\"start\":43272},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":43327,\"start\":43318},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":51468,\"start\":51461},{\"end\":54578,\"start\":54571},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":55799,\"start\":55792},{\"attributes\":{\"ref_id\":\"fig_29\"},\"end\":62524,\"start\":62515}]", "bib_author_first_name": "[{\"end\":77085,\"start\":77084},{\"end\":77289,\"start\":77288},{\"end\":77291,\"start\":77290},{\"end\":77658,\"start\":77657},{\"end\":77660,\"start\":77659},{\"end\":78161,\"start\":78160},{\"end\":78414,\"start\":78413},{\"end\":78816,\"start\":78815},{\"end\":78818,\"start\":78817},{\"end\":79003,\"start\":79002},{\"end\":79433,\"start\":79432},{\"end\":79676,\"start\":79675},{\"end\":80044,\"start\":80043},{\"end\":80344,\"start\":80343},{\"end\":80666,\"start\":80665},{\"end\":81061,\"start\":81060},{\"end\":81235,\"start\":81234},{\"end\":81646,\"start\":81645},{\"end\":81764,\"start\":81763},{\"end\":81774,\"start\":81773},{\"end\":81776,\"start\":81775},{\"end\":82076,\"start\":82075},{\"end\":82535,\"start\":82534},{\"end\":82886,\"start\":82885},{\"end\":82888,\"start\":82887},{\"end\":83237,\"start\":83236},{\"end\":83415,\"start\":83414},{\"end\":83711,\"start\":83710},{\"end\":83854,\"start\":83853},{\"end\":83995,\"start\":83994},{\"end\":84308,\"start\":84307},{\"end\":84540,\"start\":84539},{\"end\":84889,\"start\":84888},{\"end\":85164,\"start\":85163},{\"end\":85170,\"start\":85169},{\"end\":85172,\"start\":85171},{\"end\":85349,\"start\":85348},{\"end\":85453,\"start\":85452},{\"end\":85455,\"start\":85454},{\"end\":85657,\"start\":85656},{\"end\":86245,\"start\":86244},{\"end\":86500,\"start\":86499},{\"end\":86883,\"start\":86882},{\"end\":87327,\"start\":87326},{\"end\":87537,\"start\":87536},{\"end\":87539,\"start\":87538},{\"end\":87843,\"start\":87842},{\"end\":87845,\"start\":87844},{\"end\":88087,\"start\":88086},{\"end\":88332,\"start\":88331},{\"end\":88637,\"start\":88636},{\"end\":88639,\"start\":88638},{\"end\":88645,\"start\":88644},{\"end\":88647,\"start\":88646},{\"end\":89176,\"start\":89175},{\"end\":89440,\"start\":89439},{\"end\":89550,\"start\":89549},{\"end\":89677,\"start\":89676},{\"end\":89908,\"start\":89907},{\"end\":90168,\"start\":90167},{\"end\":90495,\"start\":90494},{\"end\":90804,\"start\":90803},{\"end\":91164,\"start\":91163},{\"end\":91166,\"start\":91165},{\"end\":91176,\"start\":91175},{\"end\":91178,\"start\":91177},{\"end\":91463,\"start\":91462},{\"end\":91729,\"start\":91728},{\"end\":91731,\"start\":91730},{\"end\":91952,\"start\":91951},{\"end\":92027,\"start\":92026},{\"end\":92041,\"start\":92040},{\"end\":92043,\"start\":92042},{\"end\":92459,\"start\":92458},{\"end\":92767,\"start\":92766},{\"end\":92979,\"start\":92978},{\"end\":93311,\"start\":93310},{\"end\":93707,\"start\":93706},{\"end\":93910,\"start\":93909},{\"end\":93912,\"start\":93911},{\"end\":94083,\"start\":94082},{\"end\":94346,\"start\":94345},{\"end\":94799,\"start\":94798},{\"end\":95229,\"start\":95228},{\"end\":95415,\"start\":95414},{\"end\":95857,\"start\":95856},{\"end\":96297,\"start\":96296},{\"end\":96622,\"start\":96621},{\"end\":97151,\"start\":97150},{\"end\":97480,\"start\":97479},{\"end\":97487,\"start\":97486},{\"end\":97489,\"start\":97488},{\"end\":98091,\"start\":98090},{\"end\":98504,\"start\":98503},{\"end\":98748,\"start\":98747},{\"end\":99221,\"start\":99220},{\"end\":99603,\"start\":99602},{\"end\":99964,\"start\":99963}]", "bib_author_last_name": "[{\"end\":77095,\"start\":77086},{\"end\":77297,\"start\":77292},{\"end\":77301,\"start\":77299},{\"end\":77666,\"start\":77661},{\"end\":77670,\"start\":77668},{\"end\":78169,\"start\":78162},{\"end\":78417,\"start\":78415},{\"end\":78424,\"start\":78419},{\"end\":78824,\"start\":78819},{\"end\":78828,\"start\":78826},{\"end\":79010,\"start\":79004},{\"end\":79017,\"start\":79012},{\"end\":79440,\"start\":79434},{\"end\":79447,\"start\":79442},{\"end\":79687,\"start\":79677},{\"end\":79694,\"start\":79689},{\"end\":80049,\"start\":80045},{\"end\":80352,\"start\":80345},{\"end\":80359,\"start\":80354},{\"end\":80671,\"start\":80667},{\"end\":80678,\"start\":80673},{\"end\":81067,\"start\":81062},{\"end\":81074,\"start\":81069},{\"end\":81241,\"start\":81236},{\"end\":81248,\"start\":81243},{\"end\":81651,\"start\":81647},{\"end\":81658,\"start\":81653},{\"end\":81771,\"start\":81765},{\"end\":81779,\"start\":81777},{\"end\":81785,\"start\":81781},{\"end\":82083,\"start\":82077},{\"end\":82090,\"start\":82085},{\"end\":82544,\"start\":82536},{\"end\":82551,\"start\":82546},{\"end\":82896,\"start\":82889},{\"end\":82900,\"start\":82898},{\"end\":83246,\"start\":83238},{\"end\":83253,\"start\":83248},{\"end\":83423,\"start\":83416},{\"end\":83430,\"start\":83425},{\"end\":83718,\"start\":83712},{\"end\":83725,\"start\":83720},{\"end\":83863,\"start\":83855},{\"end\":83870,\"start\":83865},{\"end\":84003,\"start\":83996},{\"end\":84010,\"start\":84005},{\"end\":84313,\"start\":84309},{\"end\":84320,\"start\":84315},{\"end\":84545,\"start\":84541},{\"end\":84552,\"start\":84547},{\"end\":84892,\"start\":84890},{\"end\":84899,\"start\":84894},{\"end\":85167,\"start\":85165},{\"end\":85175,\"start\":85173},{\"end\":85185,\"start\":85177},{\"end\":85355,\"start\":85350},{\"end\":85463,\"start\":85456},{\"end\":85467,\"start\":85465},{\"end\":85661,\"start\":85658},{\"end\":85668,\"start\":85663},{\"end\":86249,\"start\":86246},{\"end\":86256,\"start\":86251},{\"end\":86503,\"start\":86501},{\"end\":86510,\"start\":86505},{\"end\":86889,\"start\":86884},{\"end\":86896,\"start\":86891},{\"end\":87338,\"start\":87328},{\"end\":87345,\"start\":87340},{\"end\":87544,\"start\":87540},{\"end\":87548,\"start\":87546},{\"end\":87848,\"start\":87846},{\"end\":87852,\"start\":87850},{\"end\":88090,\"start\":88088},{\"end\":88097,\"start\":88092},{\"end\":88336,\"start\":88333},{\"end\":88343,\"start\":88338},{\"end\":88642,\"start\":88640},{\"end\":88650,\"start\":88648},{\"end\":88660,\"start\":88652},{\"end\":89188,\"start\":89177},{\"end\":89195,\"start\":89190},{\"end\":89450,\"start\":89441},{\"end\":89555,\"start\":89551},{\"end\":89684,\"start\":89678},{\"end\":89691,\"start\":89686},{\"end\":89914,\"start\":89909},{\"end\":89921,\"start\":89916},{\"end\":90174,\"start\":90169},{\"end\":90181,\"start\":90176},{\"end\":90503,\"start\":90496},{\"end\":90510,\"start\":90505},{\"end\":90810,\"start\":90805},{\"end\":90817,\"start\":90812},{\"end\":91173,\"start\":91167},{\"end\":91181,\"start\":91179},{\"end\":91191,\"start\":91183},{\"end\":91471,\"start\":91464},{\"end\":91478,\"start\":91473},{\"end\":91736,\"start\":91732},{\"end\":91740,\"start\":91738},{\"end\":91959,\"start\":91953},{\"end\":91966,\"start\":91961},{\"end\":92038,\"start\":92028},{\"end\":92046,\"start\":92044},{\"end\":92054,\"start\":92048},{\"end\":92462,\"start\":92460},{\"end\":92469,\"start\":92464},{\"end\":92771,\"start\":92768},{\"end\":92983,\"start\":92980},{\"end\":92990,\"start\":92985},{\"end\":93316,\"start\":93312},{\"end\":93323,\"start\":93318},{\"end\":93720,\"start\":93708},{\"end\":93727,\"start\":93722},{\"end\":93918,\"start\":93913},{\"end\":93922,\"start\":93920},{\"end\":94092,\"start\":94084},{\"end\":94099,\"start\":94094},{\"end\":94351,\"start\":94347},{\"end\":94358,\"start\":94353},{\"end\":94804,\"start\":94800},{\"end\":94811,\"start\":94806},{\"end\":95236,\"start\":95230},{\"end\":95419,\"start\":95416},{\"end\":95426,\"start\":95421},{\"end\":95860,\"start\":95858},{\"end\":95867,\"start\":95862},{\"end\":96300,\"start\":96298},{\"end\":96307,\"start\":96302},{\"end\":96625,\"start\":96623},{\"end\":96632,\"start\":96627},{\"end\":97154,\"start\":97152},{\"end\":97161,\"start\":97156},{\"end\":97484,\"start\":97481},{\"end\":97492,\"start\":97490},{\"end\":97500,\"start\":97494},{\"end\":98097,\"start\":98092},{\"end\":98104,\"start\":98099},{\"end\":98510,\"start\":98505},{\"end\":98517,\"start\":98512},{\"end\":98754,\"start\":98749},{\"end\":98761,\"start\":98756},{\"end\":99226,\"start\":99222},{\"end\":99233,\"start\":99228},{\"end\":99609,\"start\":99604},{\"end\":99616,\"start\":99611},{\"end\":99969,\"start\":99965},{\"end\":99976,\"start\":99971}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":73224,\"start\":73026},{\"attributes\":{\"id\":\"b1\"},\"end\":73391,\"start\":73226},{\"attributes\":{\"id\":\"b2\"},\"end\":73510,\"start\":73393},{\"attributes\":{\"id\":\"b3\"},\"end\":73628,\"start\":73512},{\"attributes\":{\"id\":\"b4\"},\"end\":73794,\"start\":73630},{\"attributes\":{\"id\":\"b5\"},\"end\":73946,\"start\":73796},{\"attributes\":{\"id\":\"b6\"},\"end\":74168,\"start\":73948},{\"attributes\":{\"id\":\"b7\"},\"end\":74434,\"start\":74170},{\"attributes\":{\"id\":\"b8\"},\"end\":74589,\"start\":74436},{\"attributes\":{\"id\":\"b9\"},\"end\":74734,\"start\":74591},{\"attributes\":{\"id\":\"b10\"},\"end\":74892,\"start\":74736},{\"attributes\":{\"id\":\"b11\"},\"end\":74966,\"start\":74894},{\"attributes\":{\"id\":\"b12\"},\"end\":75225,\"start\":74968},{\"attributes\":{\"id\":\"b13\"},\"end\":75333,\"start\":75227},{\"attributes\":{\"id\":\"b14\"},\"end\":75506,\"start\":75335},{\"attributes\":{\"id\":\"b15\"},\"end\":75663,\"start\":75508},{\"attributes\":{\"id\":\"b16\"},\"end\":75801,\"start\":75665},{\"attributes\":{\"id\":\"b17\"},\"end\":75929,\"start\":75803},{\"attributes\":{\"id\":\"b18\"},\"end\":76109,\"start\":75931},{\"attributes\":{\"id\":\"b19\"},\"end\":76279,\"start\":76111},{\"attributes\":{\"id\":\"b20\"},\"end\":76407,\"start\":76281},{\"attributes\":{\"id\":\"b21\"},\"end\":76563,\"start\":76409},{\"attributes\":{\"id\":\"b22\"},\"end\":76689,\"start\":76565},{\"attributes\":{\"id\":\"b23\"},\"end\":76855,\"start\":76691},{\"attributes\":{\"id\":\"b24\"},\"end\":77022,\"start\":76857},{\"attributes\":{\"id\":\"b25\"},\"end\":77203,\"start\":77024},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":49230159},\"end\":77536,\"start\":77205},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":235628558},\"end\":78107,\"start\":77538},{\"attributes\":{\"id\":\"b28\"},\"end\":78332,\"start\":78109},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":211268160},\"end\":78771,\"start\":78334},{\"attributes\":{\"id\":\"b30\"},\"end\":78932,\"start\":78773},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":227154816},\"end\":79344,\"start\":78934},{\"attributes\":{\"doi\":\"CoRR abs/1807.03418\",\"id\":\"b32\"},\"end\":79600,\"start\":79346},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":13594261},\"end\":79973,\"start\":79602},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":9052322},\"end\":80277,\"start\":79975},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":4475201},\"end\":80564,\"start\":80279},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":18165915},\"end\":80997,\"start\":80566},{\"attributes\":{\"id\":\"b37\"},\"end\":81154,\"start\":80999},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":7409091},\"end\":81590,\"start\":81156},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":57246310},\"end\":81761,\"start\":81592},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b40\"},\"end\":82035,\"start\":81763},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":13661051},\"end\":82463,\"start\":82037},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":14754931},\"end\":82798,\"start\":82465},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":44657737},\"end\":83167,\"start\":82800},{\"attributes\":{\"doi\":\"arXiv:2006.09114\",\"id\":\"b44\"},\"end\":83412,\"start\":83169},{\"attributes\":{\"doi\":\"arXiv:2103.05840\",\"id\":\"b45\"},\"end\":83634,\"start\":83414},{\"attributes\":{\"id\":\"b46\"},\"end\":83819,\"start\":83636},{\"attributes\":{\"id\":\"b47\"},\"end\":83930,\"start\":83821},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":53067},\"end\":84243,\"start\":83932},{\"attributes\":{\"doi\":\"arXiv:1912.09579\",\"id\":\"b49\"},\"end\":84472,\"start\":84245},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":215762013},\"end\":84823,\"start\":84474},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":215540880},\"end\":85161,\"start\":84825},{\"attributes\":{\"id\":\"b52\"},\"end\":85319,\"start\":85163},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":214283901},\"end\":85448,\"start\":85321},{\"attributes\":{\"id\":\"b54\"},\"end\":85558,\"start\":85450},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":12208452},\"end\":86101,\"start\":85560},{\"attributes\":{\"id\":\"b56\"},\"end\":86451,\"start\":86103},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":206594692},\"end\":86815,\"start\":86453},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":221785132},\"end\":87259,\"start\":86817},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":195908774},\"end\":87458,\"start\":87261},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":6521359},\"end\":87768,\"start\":87460},{\"attributes\":{\"id\":\"b61\"},\"end\":88017,\"start\":87770},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":216228013},\"end\":88304,\"start\":88019},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":17245563},\"end\":88558,\"start\":88306},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":224815220},\"end\":89119,\"start\":88560},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":942903},\"end\":89410,\"start\":89121},{\"attributes\":{\"id\":\"b66\"},\"end\":89502,\"start\":89412},{\"attributes\":{\"id\":\"b67\"},\"end\":89620,\"start\":89504},{\"attributes\":{\"id\":\"b68\"},\"end\":89807,\"start\":89622},{\"attributes\":{\"id\":\"b69\"},\"end\":90101,\"start\":89809},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":49312241},\"end\":90408,\"start\":90103},{\"attributes\":{\"id\":\"b71\"},\"end\":90644,\"start\":90410},{\"attributes\":{\"id\":\"b72\"},\"end\":90734,\"start\":90646},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":12130011},\"end\":91161,\"start\":90736},{\"attributes\":{\"doi\":\"arXiv:2108.03164\",\"id\":\"b74\"},\"end\":91362,\"start\":91163},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":2358161},\"end\":91665,\"start\":91364},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":18708216},\"end\":91911,\"start\":91667},{\"attributes\":{\"id\":\"b77\"},\"end\":92024,\"start\":91913},{\"attributes\":{\"id\":\"b78\"},\"end\":92382,\"start\":92026},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":153312701},\"end\":92719,\"start\":92384},{\"attributes\":{\"id\":\"b80\"},\"end\":92926,\"start\":92721},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":13943806},\"end\":93236,\"start\":92928},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":227154660},\"end\":93654,\"start\":93238},{\"attributes\":{\"doi\":\"arXiv:2009.02095\",\"id\":\"b83\"},\"end\":93875,\"start\":93656},{\"attributes\":{\"id\":\"b84\"},\"end\":93982,\"start\":93877},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":53834121},\"end\":94296,\"start\":93984},{\"attributes\":{\"id\":\"b86\",\"matched_paper_id\":2983351},\"end\":94705,\"start\":94298},{\"attributes\":{\"id\":\"b87\",\"matched_paper_id\":227154904},\"end\":95156,\"start\":94707},{\"attributes\":{\"id\":\"b88\"},\"end\":95360,\"start\":95158},{\"attributes\":{\"id\":\"b89\",\"matched_paper_id\":1875264},\"end\":95777,\"start\":95362},{\"attributes\":{\"id\":\"b90\",\"matched_paper_id\":221651925},\"end\":96217,\"start\":95779},{\"attributes\":{\"id\":\"b91\",\"matched_paper_id\":221651925},\"end\":96528,\"start\":96219},{\"attributes\":{\"id\":\"b92\",\"matched_paper_id\":189926717},\"end\":97052,\"start\":96530},{\"attributes\":{\"id\":\"b93\",\"matched_paper_id\":237508108},\"end\":97401,\"start\":97054},{\"attributes\":{\"id\":\"b94\",\"matched_paper_id\":235599497},\"end\":98047,\"start\":97403},{\"attributes\":{\"id\":\"b95\",\"matched_paper_id\":2419970},\"end\":98431,\"start\":98049},{\"attributes\":{\"doi\":\"arXiv:1902.09243\",\"id\":\"b96\"},\"end\":98676,\"start\":98433},{\"attributes\":{\"id\":\"b97\",\"matched_paper_id\":207224888},\"end\":99164,\"start\":98678},{\"attributes\":{\"id\":\"b98\",\"matched_paper_id\":207993979},\"end\":99534,\"start\":99166},{\"attributes\":{\"id\":\"b99\",\"matched_paper_id\":220314297},\"end\":99860,\"start\":99536},{\"attributes\":{\"id\":\"b100\",\"matched_paper_id\":7284862},\"end\":100127,\"start\":99862}]", "bib_title": "[{\"end\":77286,\"start\":77205},{\"end\":77655,\"start\":77538},{\"end\":78411,\"start\":78334},{\"end\":79000,\"start\":78934},{\"end\":79673,\"start\":79602},{\"end\":80041,\"start\":79975},{\"end\":80341,\"start\":80279},{\"end\":80663,\"start\":80566},{\"end\":81232,\"start\":81156},{\"end\":81643,\"start\":81592},{\"end\":82073,\"start\":82037},{\"end\":82532,\"start\":82465},{\"end\":82883,\"start\":82800},{\"end\":83992,\"start\":83932},{\"end\":84537,\"start\":84474},{\"end\":84886,\"start\":84825},{\"end\":85346,\"start\":85321},{\"end\":85654,\"start\":85560},{\"end\":86497,\"start\":86453},{\"end\":86880,\"start\":86817},{\"end\":87324,\"start\":87261},{\"end\":87534,\"start\":87460},{\"end\":88084,\"start\":88019},{\"end\":88329,\"start\":88306},{\"end\":88634,\"start\":88560},{\"end\":89173,\"start\":89121},{\"end\":90165,\"start\":90103},{\"end\":90801,\"start\":90736},{\"end\":91460,\"start\":91364},{\"end\":91726,\"start\":91667},{\"end\":92456,\"start\":92384},{\"end\":92764,\"start\":92721},{\"end\":92976,\"start\":92928},{\"end\":93308,\"start\":93238},{\"end\":94080,\"start\":93984},{\"end\":94343,\"start\":94298},{\"end\":94796,\"start\":94707},{\"end\":95412,\"start\":95362},{\"end\":95854,\"start\":95779},{\"end\":96294,\"start\":96219},{\"end\":96619,\"start\":96530},{\"end\":97148,\"start\":97054},{\"end\":97477,\"start\":97403},{\"end\":98088,\"start\":98049},{\"end\":98745,\"start\":98678},{\"end\":99218,\"start\":99166},{\"end\":99600,\"start\":99536},{\"end\":99961,\"start\":99862}]", "bib_author": "[{\"end\":77097,\"start\":77084},{\"end\":77299,\"start\":77288},{\"end\":77303,\"start\":77299},{\"end\":77668,\"start\":77657},{\"end\":77672,\"start\":77668},{\"end\":78171,\"start\":78160},{\"end\":78419,\"start\":78413},{\"end\":78426,\"start\":78419},{\"end\":78826,\"start\":78815},{\"end\":78830,\"start\":78826},{\"end\":79012,\"start\":79002},{\"end\":79019,\"start\":79012},{\"end\":79442,\"start\":79432},{\"end\":79449,\"start\":79442},{\"end\":79689,\"start\":79675},{\"end\":79696,\"start\":79689},{\"end\":80051,\"start\":80043},{\"end\":80354,\"start\":80343},{\"end\":80361,\"start\":80354},{\"end\":80673,\"start\":80665},{\"end\":80680,\"start\":80673},{\"end\":81069,\"start\":81060},{\"end\":81076,\"start\":81069},{\"end\":81243,\"start\":81234},{\"end\":81250,\"start\":81243},{\"end\":81653,\"start\":81645},{\"end\":81660,\"start\":81653},{\"end\":81773,\"start\":81763},{\"end\":81781,\"start\":81773},{\"end\":81787,\"start\":81781},{\"end\":82085,\"start\":82075},{\"end\":82092,\"start\":82085},{\"end\":82546,\"start\":82534},{\"end\":82553,\"start\":82546},{\"end\":82898,\"start\":82885},{\"end\":82902,\"start\":82898},{\"end\":83248,\"start\":83236},{\"end\":83255,\"start\":83248},{\"end\":83425,\"start\":83414},{\"end\":83432,\"start\":83425},{\"end\":83720,\"start\":83710},{\"end\":83727,\"start\":83720},{\"end\":83865,\"start\":83853},{\"end\":83872,\"start\":83865},{\"end\":84005,\"start\":83994},{\"end\":84012,\"start\":84005},{\"end\":84315,\"start\":84307},{\"end\":84322,\"start\":84315},{\"end\":84547,\"start\":84539},{\"end\":84554,\"start\":84547},{\"end\":84894,\"start\":84888},{\"end\":84901,\"start\":84894},{\"end\":85169,\"start\":85163},{\"end\":85177,\"start\":85169},{\"end\":85187,\"start\":85177},{\"end\":85357,\"start\":85348},{\"end\":85465,\"start\":85452},{\"end\":85469,\"start\":85465},{\"end\":85663,\"start\":85656},{\"end\":85670,\"start\":85663},{\"end\":86251,\"start\":86244},{\"end\":86258,\"start\":86251},{\"end\":86505,\"start\":86499},{\"end\":86512,\"start\":86505},{\"end\":86891,\"start\":86882},{\"end\":86898,\"start\":86891},{\"end\":87340,\"start\":87326},{\"end\":87347,\"start\":87340},{\"end\":87546,\"start\":87536},{\"end\":87550,\"start\":87546},{\"end\":87850,\"start\":87842},{\"end\":87854,\"start\":87850},{\"end\":88092,\"start\":88086},{\"end\":88099,\"start\":88092},{\"end\":88338,\"start\":88331},{\"end\":88345,\"start\":88338},{\"end\":88644,\"start\":88636},{\"end\":88652,\"start\":88644},{\"end\":88662,\"start\":88652},{\"end\":89190,\"start\":89175},{\"end\":89197,\"start\":89190},{\"end\":89452,\"start\":89439},{\"end\":89557,\"start\":89549},{\"end\":89686,\"start\":89676},{\"end\":89693,\"start\":89686},{\"end\":89916,\"start\":89907},{\"end\":89923,\"start\":89916},{\"end\":90176,\"start\":90167},{\"end\":90183,\"start\":90176},{\"end\":90505,\"start\":90494},{\"end\":90512,\"start\":90505},{\"end\":90812,\"start\":90803},{\"end\":90819,\"start\":90812},{\"end\":91175,\"start\":91163},{\"end\":91183,\"start\":91175},{\"end\":91193,\"start\":91183},{\"end\":91473,\"start\":91462},{\"end\":91480,\"start\":91473},{\"end\":91738,\"start\":91728},{\"end\":91742,\"start\":91738},{\"end\":91961,\"start\":91951},{\"end\":91968,\"start\":91961},{\"end\":92040,\"start\":92026},{\"end\":92048,\"start\":92040},{\"end\":92056,\"start\":92048},{\"end\":92464,\"start\":92458},{\"end\":92471,\"start\":92464},{\"end\":92773,\"start\":92766},{\"end\":92985,\"start\":92978},{\"end\":92992,\"start\":92985},{\"end\":93318,\"start\":93310},{\"end\":93325,\"start\":93318},{\"end\":93722,\"start\":93706},{\"end\":93729,\"start\":93722},{\"end\":93920,\"start\":93909},{\"end\":93924,\"start\":93920},{\"end\":94094,\"start\":94082},{\"end\":94101,\"start\":94094},{\"end\":94353,\"start\":94345},{\"end\":94360,\"start\":94353},{\"end\":94806,\"start\":94798},{\"end\":94813,\"start\":94806},{\"end\":95238,\"start\":95228},{\"end\":95421,\"start\":95414},{\"end\":95428,\"start\":95421},{\"end\":95862,\"start\":95856},{\"end\":95869,\"start\":95862},{\"end\":96302,\"start\":96296},{\"end\":96309,\"start\":96302},{\"end\":96627,\"start\":96621},{\"end\":96634,\"start\":96627},{\"end\":97156,\"start\":97150},{\"end\":97163,\"start\":97156},{\"end\":97486,\"start\":97479},{\"end\":97494,\"start\":97486},{\"end\":97502,\"start\":97494},{\"end\":98099,\"start\":98090},{\"end\":98106,\"start\":98099},{\"end\":98512,\"start\":98503},{\"end\":98519,\"start\":98512},{\"end\":98756,\"start\":98747},{\"end\":98763,\"start\":98756},{\"end\":99228,\"start\":99220},{\"end\":99235,\"start\":99228},{\"end\":99611,\"start\":99602},{\"end\":99618,\"start\":99611},{\"end\":99971,\"start\":99963},{\"end\":99978,\"start\":99971}]", "bib_venue": "[{\"end\":77847,\"start\":77768},{\"end\":78579,\"start\":78511},{\"end\":79162,\"start\":79099},{\"end\":81391,\"start\":81329},{\"end\":82281,\"start\":82195},{\"end\":85861,\"start\":85774},{\"end\":86653,\"start\":86591},{\"end\":87065,\"start\":86990},{\"end\":88808,\"start\":88735},{\"end\":90976,\"start\":90906},{\"end\":91782,\"start\":91766},{\"end\":92231,\"start\":92152},{\"end\":93468,\"start\":93405},{\"end\":94527,\"start\":94452},{\"end\":94956,\"start\":94893},{\"end\":95595,\"start\":95520},{\"end\":96022,\"start\":95954},{\"end\":96823,\"start\":96737},{\"end\":97708,\"start\":97605},{\"end\":98263,\"start\":98193},{\"end\":98952,\"start\":98866},{\"end\":99364,\"start\":99308},{\"end\":73087,\"start\":73026},{\"end\":73261,\"start\":73226},{\"end\":73422,\"start\":73393},{\"end\":73531,\"start\":73512},{\"end\":73680,\"start\":73630},{\"end\":73836,\"start\":73796},{\"end\":74026,\"start\":73948},{\"end\":74228,\"start\":74170},{\"end\":74477,\"start\":74436},{\"end\":74627,\"start\":74591},{\"end\":74779,\"start\":74736},{\"end\":74911,\"start\":74894},{\"end\":75042,\"start\":74968},{\"end\":75275,\"start\":75227},{\"end\":75401,\"start\":75335},{\"end\":75539,\"start\":75508},{\"end\":75698,\"start\":75665},{\"end\":75831,\"start\":75803},{\"end\":75978,\"start\":75931},{\"end\":76153,\"start\":76111},{\"end\":76318,\"start\":76281},{\"end\":76447,\"start\":76409},{\"end\":76599,\"start\":76565},{\"end\":76734,\"start\":76691},{\"end\":76913,\"start\":76857},{\"end\":77082,\"start\":77024},{\"end\":77346,\"start\":77303},{\"end\":77766,\"start\":77672},{\"end\":78158,\"start\":78109},{\"end\":78509,\"start\":78426},{\"end\":78813,\"start\":78773},{\"end\":79097,\"start\":79019},{\"end\":79430,\"start\":79346},{\"end\":79764,\"start\":79696},{\"end\":80112,\"start\":80051},{\"end\":80402,\"start\":80361},{\"end\":80757,\"start\":80680},{\"end\":81058,\"start\":80999},{\"end\":81327,\"start\":81250},{\"end\":81669,\"start\":81660},{\"end\":81877,\"start\":81803},{\"end\":82193,\"start\":82092},{\"end\":82609,\"start\":82553},{\"end\":82961,\"start\":82902},{\"end\":83234,\"start\":83169},{\"end\":83500,\"start\":83448},{\"end\":83708,\"start\":83636},{\"end\":83851,\"start\":83821},{\"end\":84073,\"start\":84012},{\"end\":84305,\"start\":84245},{\"end\":84635,\"start\":84554},{\"end\":84971,\"start\":84901},{\"end\":85239,\"start\":85187},{\"end\":85372,\"start\":85357},{\"end\":85489,\"start\":85469},{\"end\":85772,\"start\":85670},{\"end\":86242,\"start\":86103},{\"end\":86589,\"start\":86512},{\"end\":86988,\"start\":86898},{\"end\":87351,\"start\":87347},{\"end\":87593,\"start\":87550},{\"end\":87840,\"start\":87770},{\"end\":88147,\"start\":88099},{\"end\":88405,\"start\":88345},{\"end\":88733,\"start\":88662},{\"end\":89229,\"start\":89197},{\"end\":89437,\"start\":89412},{\"end\":89547,\"start\":89504},{\"end\":89674,\"start\":89622},{\"end\":89905,\"start\":89809},{\"end\":90238,\"start\":90183},{\"end\":90492,\"start\":90410},{\"end\":90676,\"start\":90648},{\"end\":90904,\"start\":90819},{\"end\":91241,\"start\":91209},{\"end\":91500,\"start\":91480},{\"end\":91764,\"start\":91742},{\"end\":91949,\"start\":91913},{\"end\":92150,\"start\":92056},{\"end\":92544,\"start\":92471},{\"end\":92818,\"start\":92773},{\"end\":93062,\"start\":92992},{\"end\":93403,\"start\":93325},{\"end\":93704,\"start\":93656},{\"end\":93907,\"start\":93877},{\"end\":94126,\"start\":94101},{\"end\":94450,\"start\":94360},{\"end\":94891,\"start\":94813},{\"end\":95226,\"start\":95158},{\"end\":95518,\"start\":95428},{\"end\":95952,\"start\":95869},{\"end\":96361,\"start\":96309},{\"end\":96735,\"start\":96634},{\"end\":97215,\"start\":97163},{\"end\":97603,\"start\":97502},{\"end\":98191,\"start\":98106},{\"end\":98501,\"start\":98433},{\"end\":98864,\"start\":98763},{\"end\":99306,\"start\":99235},{\"end\":99681,\"start\":99618},{\"end\":99987,\"start\":99978}]"}}}, "year": 2023, "month": 12, "day": 17}