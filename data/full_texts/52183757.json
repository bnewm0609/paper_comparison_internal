{"id": 52183757, "updated": "2023-09-30 01:00:32.274", "metadata": {"title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering", "authors": "[{\"first\":\"Todor\",\"last\":\"Mihaylov\",\"middle\":[]},{\"first\":\"Peter\",\"last\":\"Clark\",\"middle\":[]},{\"first\":\"Tushar\",\"last\":\"Khot\",\"middle\":[]},{\"first\":\"Ashish\",\"last\":\"Sabharwal\",\"middle\":[]}]", "venue": "EMNLP", "journal": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing", "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "We present a new kind of question answering dataset, OpenBookQA, modeled after open book exams for assessing human understanding of a subject. The open book that comes with our questions is a set of 1326 elementary level science facts. Roughly 6000 questions probe an understanding of these facts and their application to novel situations. This requires combining an open book fact (e.g., metals conduct electricity) with broad common knowledge (e.g., a suit of armor is made of metal) obtained from other sources. While existing QA datasets over documents or knowledge bases, being generally self-contained, focus on linguistic understanding, OpenBookQA probes a deeper understanding of both the topic\u2014in the context of common knowledge\u2014and the language it is expressed in. Human performance on OpenBookQA is close to 92%, but many state-of-the-art pre-trained QA methods perform surprisingly poorly, worse than several simple neural baselines we develop. Our oracle experiments designed to circumvent the knowledge retrieval bottleneck demonstrate the value of both the open book and additional facts. We leave it as a challenge to solve the retrieval problem in this multi-hop setting and to close the large gap to human performance.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1809.02789", "mag": "2952396187", "acl": "D18-1260", "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/MihaylovCKS18", "doi": "10.18653/v1/d18-1260"}}, "content": {"source": {"pdf_hash": "1536e8958697c5364f68b2e2448905dbbeb3a0ca", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/D18-1260.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/D18-1260.pdf", "status": "HYBRID"}}, "grobid": {"id": "98dea5f0418da349f18263f72a3b597ac4985558", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1536e8958697c5364f68b2e2448905dbbeb3a0ca.txt", "contents": "\nCan a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering\nAssociation for Computational LinguisticsCopyright Association for Computational LinguisticsOctober 31 -November 4. 2018. 2018\n\nTodor Mihaylov mihaylov@cl.uni-heidelberg.de \nInstitute for Artificial Intelligence\nU.S.A. \u2021 Research Training Group AIPHES & Heidelberg University\nSeattle, HeidelbergWAGermany\n\nPeter Clark \nInstitute for Artificial Intelligence\nU.S.A. \u2021 Research Training Group AIPHES & Heidelberg University\nSeattle, HeidelbergWAGermany\n\nTushar Khot \nInstitute for Artificial Intelligence\nU.S.A. \u2021 Research Training Group AIPHES & Heidelberg University\nSeattle, HeidelbergWAGermany\n\nAshish Sabharwal ashishs@allenai.org \nInstitute for Artificial Intelligence\nU.S.A. \u2021 Research Training Group AIPHES & Heidelberg University\nSeattle, HeidelbergWAGermany\n\n\u2020 Allen \nInstitute for Artificial Intelligence\nU.S.A. \u2021 Research Training Group AIPHES & Heidelberg University\nSeattle, HeidelbergWAGermany\n\nCan a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering\n\nProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\nthe 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational LinguisticsOctober 31 -November 4. 2018. 20182381\nWe present a new kind of question answering dataset, OpenBookQA, modeled after open book exams for assessing human understanding of a subject. The open book that comes with our questions is a set of 1326 elementary level science facts. Roughly 6000 questions probe an understanding of these facts and their application to novel situations. This requires combining an open book fact (e.g., metals conduct electricity) with broad common knowledge (e.g., a suit of armor is made of metal) obtained from other sources. While existing QA datasets over documents or knowledge bases, being generally self-contained, focus on linguistic understanding, OpenBookQA probes a deeper understanding of both the topic-in the context of common knowledge-and the language it is expressed in. Human performance on OpenBookQA is close to 92%, but many state-of-the-art pre-trained QA methods perform surprisingly poorly, worse than several simple neural baselines we develop. Our oracle experiments designed to circumvent the knowledge retrieval bottleneck demonstrate the value of both the open book and additional facts. We leave it as a challenge to solve the retrieval problem in this multi-hop setting and to close the large gap to human performance. 1  The dataset and the code for the models are available at http://data.allenai.org/OpenBookQA.\n\nIntroduction\n\nOpen book exams are a common mechanism for assessing human understanding of a subject, where test takers are allowed free access to a relevant book, study guide, or class notes when answering questions. In this context, the goal is not to evaluate memorization but a deeper understanding of the material and its application to new situations (Jenkins, 1995;Landsberger, 1996). The application, in turn, often requires combining a fact in the book (e.g., metals conduct electricity) with additional common knowledge the test taker is ex-Question: Which of these would let the most heat travel through? A) a new pair of jeans. B) a steel spoon in a cafeteria. C) a cotton candy at a store. D) a calvin klein cotton hat.\n\n\nScience Fact:\n\nMetal is a thermal conductor.  pected to have acquired by this stage (e.g., a suit of armor is made of metal).\n\nMotivated by this setting, we present a new kind of question answering dataset, OpenBookQA, 1 that consists of two parts: Q, a set of 5957 multiple-choice questions, and F, a set of 1326 diverse facts about elementary level science. F has three key characteristics of an 'open book': (a) it forms the basis for generating Q; (b) it has been deemed central to scientific explanations (Jansen et al., 2018); and (c) by itself, F is generally insufficient to answer questions in Q. Faced with a question q \u2208 Q, a student or system S is expected retrieve a relevant fact f \u2208 F, and appeal to their own common knowledge, K S , when applying f to answer q. Figure 1 provides an example. Here, metals are thermal conductors is a core scientific fact available in F. One way to apply this fact to decide whether a steel spoon would let the most heat travel through is to appeal to common knowledge that steel is metallic and heat travels through thermal conductors. In general, the expected common knowledge is relatively simple (taxonomic facts, definitions, object properties, etc.); the difficulty lies in identifying it and meaningfully combining it with a core fact from F to answer the question.\n\nOpenBookQA questions are challenging as they require multi-hop reasoning with partial context provided by F. Specifically, unlike existing datasets for reading comprehension (RC), answering questions on the back of a textbook (TQA), 2 as well as question answering over structured knowledge-bases (KBQA), the open book F that comes with OpenBookQA is not self-contained. A successful system must therefore go beyond the typical challenges such as paraphrase matching and coreference resolution, without benefiting from the canonicalized and complete information in KBQA. Generating interesting open book questions is a difficult task. We used a multi-stage process starting with F, using crowd-sourcing to generate (noisy) questions based on F that probe novel situations, using an automatic filter to ensure hardness for retrieval and association based systems, using a crowd filter to ensure answerability by a lay person, and further using an expert filter to ensure higher quality in Dev and Test sets.\n\nWe evaluate a number of existing QA systems for science (without retraining) on OpenBookQA, finding that they perform surprisingly close to the random guessing baseline of 25%. Human performance, on the other hand, is close to 92%. 3 Motivated by recent findings of gameability of NLP datasets (Gururangan et al., 2018), we also develop and evaluate simple, attention-based, neural baselines including a plausible answer detector (which ignores the question text completely) and an odd-one-out solver. These highlight inevitable human bias in any crowdsourced dataset, increasing performance on OpenBookQA to 48%.\n\nBuilding upon a recent neural model for incorporating external knowledge in the story cloze setting (Mihaylov and Frank, 2018), we propose a knowledge-aware neural baseline that can utilize both the open book F and common knowledge retrieved from sources such as ConceptNet (Speer et al., 2017). While retrieving the most useful pieces of knowledge remains an open challenge, our 'oracle' experiments with the fact f used while generating a question q and an interpretation (by 2 Only \u223c5% of the TQA questions of Kembhavi et al. (2017) require additional common knowledge. 3 To avoid ambiguity in the term 'human performance', Section 3.2 describes the specific randomized model we use. the question author) of the additional knowledge k needed for q, provides valuable insight into the nature of this dataset: Facts from the open book F are valuable (5% improvement) but not sufficient. Using both f and k increases the accuracy to 76%, but is still far from human level performance, suggesting the need for non-trivial reasoning to combine these facts.\n\nTo encourage further research on this new task, for each Train and Dev question q, OpenBookQA also includes f as intermediate supervision signal, which may be viewed as a partial explanation for q. We leave closing the large gap to human performance as a challenge for the NLP community.\n\n\nRelated Work\n\nBy construction, answering OpenBookQA questions requires (i) some base science facts from a provided 'open book', (ii) broader understanding about the world (common or commonsense knowledge), and (iii) an ability to combine these facts (reasoning). This setup differs from several existing QA tasks, as summarized below.\n\nReading Comprehension (RC) datasets have been proposed as benchmarks to evaluate the ability of systems to understand a document by answering factoid-style questions over this document. These datasets have taken various forms: multiple-choice (Richardson et al., 2013), clozestyle (Hermann et al., 2015;Onishi et al., 2016;Hill et al., 2016), and span prediction (Rajpurkar et al., 2016;Trischler et al., 2017;Joshi et al., 2017) However, analysis (Chen et al., 2016;Sugawara et al., 2017) of these datasets has shown that many of the questions can be solved with context token matching (Chen et al., 2017a;Weissenborn et al., 2017) or relatively simple paraphrasing.\n\nTo focus on the more challenging problem of reasoning across sentences, new datasets have been proposed for multi-step RC. QAngaroo (Welbl et al., 2018) have used a knowledgebase to identify entity pairs (s, o) with a known relation, r, which is also supported by a multihop path in a set of documents. They use structured tuple queries (s, r, ?) and use all the documents along the path as the input passage. Nar-rativeQA (Kocisk\u00fd et al., 2017) is an RC dataset that has been shown to require an iterative reasoning about the narrative of a story. Similar to Open-BookQA, the questions were generated to ensure that the answer is not a direct match or paraphrase that can be retrieved with an IR approach. Most recently, Khashabi et al. (2018) proposed Mul-tiRC, a multiple-choice RC dataset that is designed to require multi-sentence reasoning and can have multiple correct answers. Again, like most RC datasets, it is self-contained.\n\nTasks with external knowledge. While many of the RC datasets could benefit from commonsense or background knowledge, they are designed to be self-contained, i.e., solvable by the document context alone. Datasets such as the Story Cloze Test (Mostafazadeh et al., 2016), MCScript, 4 and ProPara (Mishra et al., 2018) do require additional domain knowledge about everyday events, scripts, and processes, respectively. However, these datasets need domain-specific modeling of events, whereas OpenBookQA appeals to broad common knowledge cutting across a variety of types and topics. Stasaski and Hearst (2017) explore the creation of multi-hop questions and propose generating stronger distractors for the multiple-choice setting. Their work, however, starts with structured knowledge, specifically a Biology ontology.\n\nLastly, many Science Question Answering datasets (e.g.  have been released that need broad external knowledge to answer the questions. However, these questions are not associated with a core set of facts, i.e., an \"open book\" used to define these questions. As a result, the questions vary widely in style and complexity . In contrast, Open-BookQA focuses on a more well-defined subset of science QA, appealing to one core fact from the open book and one (or few) relatively simple commonly known supporting facts.\n\n\nOpenBookQA Dataset\n\nThe OpenBookQA dataset consists of about 6,000 4-way multiple-choice questions, each associated with one core fact from a \"book\" F of 1326 such facts, and an auxiliary set K of about 6000 additional facts. The questions were created via a multi-stage crowdsourcing and partial expert filtering process, discussed in Section 3.1.\n\nThe small \"book\" F consists of recurring science themes and principles, each of which can be (and here is) instantiated into multiple questions.\n\nFor F, we use a subset of the WorldTree corpus which Jansen et al. (2018) have analyzed for sufficiency for elementary level science. The subset we use is taken from the 2287 WorldTree facts that were marked as \"central\" by the original authors in at least one explanation. We further filter them down to 1326 that appear general enough to be applicable to multiple situations.\n\nOpenBookQA additionally requires broad common knowledge, which is expected to come from large corpora, such as ConceptNet, Wikipedia, or a corpus with 14M science-related sentences used by some existing baselines. The crowdsourcing process below also asks workers to mark a second fact, k, needed for each question q, in addition to f . These second facts, unfortunately, were often incomplete, over-complete, or only distantly related to q. We thus include in OpenBookQA the set K of such second facts only as auxiliary data for optional use. We emphasize that K should not be viewed as 'gold' additional facts, or as a substitute for broad common knowledge.\n\n\nCrowdsourcing Process\n\nThe overall question generation and filtering pipeline is summarized in Figure 2. Given the \"book\" F of core facts, the process proceeds as follows, starting with an empty question set Qs and an empty 'second facts' set K:\n\n1. A crowd-worker 5 w is shown a random science fact f from the set F.\n\n2. w is asked to think of a second common fact, k, that may be combined with f to derive a new, valid assertion s.\n\n3. w then converts s into a question-answer pair and extends this into a 4-way multiple choice question by adding 3 incorrect answer choices, q mc = (q, {c 1 , c 2 , c 3 , c 4 }), where one of the c i 's is the unique correct answer. 4. The system verifies q mc passes basic checks such as uniformity of answer choices. 6 5. w then feeds the multiple-choice question q mc to an information retrieval solver (Clark et   6. Question q mc is then shown to 5 new crowdworkers, who are asked to answer it.\n\n7. If at least 4 out of 5 workers answer q mc correctly, it is deemed answerable and the process continues. If not, q mc is discarded.\n\n8. The answer choices of q mc are randomly shuffled to avoid unintended bias. 7 9. q mc is associated with f as the core science fact and added to the question set Q. k is added to the set K of additional (noisy) facts.\n\nThe Dev and Test splits were further filtered by an in-house expert to ensure higher quality.\n\n\nHuman Performance\n\nTo assess human accuracy on this dataset, we consider the following model: Each question q \u2208 Q has some (unknown) human accuracy p q , defined as the probability that a random human subject, chosen uniformly from a large pool H, would answer q correctly. Thus, we can think of this as defining a Bernoulli random variable, X q \u223c B(p q ), whose mean is (unknown) p q . The average human accuracy on Q under this model is:\nH(Q) = 1 |Q| q\u2208Q p q where {p q | q \u2208 Q} are unknown.\nWith H as the set of crowd-workers (cf. Footnote 5), step 6 of the above question generation process is equivalent to obtaining 5 independent samples, X q,i , i \u2208 I, |I| = 5, from B(p q ). We must, however, be careful when using this data to estimate p q , as the same 5 samples were used to decide whether q makes it into the question set Q or not. For instance, if we had kept only those questions that all 5 workers answered correctly, it would clearly be inaccurate to claim that the human accuracy on Q is 100%. Nevertheless, it is possible to re-use the judgments from Step 6 to approximate H(Q) with high confidence, without posing the questions to new workers.\n\nIntuitively, if all questions in Q were difficult to answer (i.e., all p q were small), it would be unlikely that all |Q| questions would pass the test in\n\nStep 6. We can use the contrapositive of this observation to conclude that p q , on average, must have been high for q \u2208 Q.\n\nFormally, aggregating across all questions gives the following empirical estimate of H(Q):\nH(Q) = 1 |Q| q\u2208Q 1 |I| i\u2208I X q,i = 1 |Q||I| q\u2208Q,i\u2208|I| X q,i\nFor analysis, we assume all samples X q,i are independent, i.e., every answer is obtained independently. 8 An application of Hoeffding's Inequality (Hoeffding, 1963) shows thatH(Q) converges to H(Q) very rapidly as n = |Q||I| grows; specifically,H(Q) \u2264 H(Q) + t with probability at least 1\u2212exp(\u22122nt 2 ); similarly forH(Q) \u2265 H(Q)\u2212t. In our Dev and Test sets, where |Q| = 500 and |I| = 5, this translates into H(Q) being at least H(Q) \u2212 3% with probability over 98.8% and at leastH(Q) \u2212 2.5% with prob 95.6%; we report the former as our conservative estimate on human performance.\n\n\nQuestion Set Analysis\n\nOpenBookQA consists of 5957 questions, with 4957/500/500 in the Train/Dev/Test splits. 9 Table 1 summarizes some statistics about the full dataset. Each question has exactly four answer choices and one associated fact used in the creation process. We report the average length of questions, candidate choices, and associated facts, as well as how often is the longest/shortest choice the correct one. We analyzed 100 questions in the Train set to capture the kind of common knowledge and reasoning needed. For each, we wrote down the additional common knowledge needed to answer this question in addition to the original science fact. In 21% of the cases, the crowdsourced question actually tests for a fact that doesn't necessarily need the original science fact. For example, the question: \"On a rainy day the clouds are (A) low (B) white (C) small (D) gray\" was written based on the science fact \"clouds produce rain\" but doesn't need this fact to answer it. We ignore such questions in our analysis. For the remaining questions, we categorized the additional facts into five high-level categories (and collapsed the remaining facts into a catch-all OTHERS category) based on previous approaches on similar science questions Jansen et al., 2016  living thing), isa(granite, rock). 2. PROPERTY: Properties of objects such as madeof(belt buckle, metal), has(mammals, four legs), contains(lemon juice, citric acid). 3. DEFINITION: Definitions of objects that may be based on their appearance (tape is a plastic with markings), working mechanism (telescope is a device that uses mirrors to view objects), etc. 4. CAUSAL: Causal facts such as causes(adding lemon juice to milk, milk to break down). 5. BASIC: General scientific fact that did not fit above, e.g. squirrels eat nuts for food. Table 2 presents the proportions of these facts in our analyzed question set. For each type of fact, we calculate the percentage of questions that need at least one such fact (shown as % Questions). We also calculate the overall percentage of each fact type across all the common knowledge facts (shown as % Facts). Most of our questions need simple facts such as isa knowledge and properties of objects, further confirming the need for simple reasoning with common knowledge. Apart from these five major categories of facts, the catch-all OTHERS category contains commonsense facts (e.g., it is dark at night), world knowledge (e.g., Japan is often hit by earthquakes) and lexical rewrites 10 (e.g., ad infinitum means over and over).\n\nMost of our questions need simple facts that should be easily retrievable from any knowledgebase/textual corpora. On an average, each question needed 1.16 additional facts ignoring any linguistic variations. Despite the simplicity of the knowledge needed for these questions, as we show empirically, most baseline approaches achieve a relatively low score on this dataset (even when the core fact is provided). We claim that this is due to the fact that the reasoning needed to answer these questions is non-trivial. Table 3 shows few questions with the associated facts and high-level reasoning needed to answer these questions. Assuming a model can extract the described relations (e.g. defn, contains), the QA system still needs to be able to chain these facts together, identify the resulting relation and verify its expression for each choice. In the extreme case (as shown in the last example), even though only one additional fact is needed to answer the question, it needs a system to apply the core \"general\" science fact to a \"specific\" situation.\n\n\nBaseline Models\n\nWe evaluate the performance of several baselines systems on the Dev and Test subsets of Open-BookQA. For each question, a solver receives 1 point towards this score if it chooses the correct answer, and 1/k if it reports a k-way tie that includes the correct answer. The \"Guess All\" baseline, which always outputs a 4-way tie, thus achieves a score of 25%, same as the expected performance of a uniform random baseline.\n\n\nNo Training, External Knowledge Only\n\nSince OpenBookQA is a set of elementary level science questions, one natural baseline category is existing systems that have proven to be effective on elementary-and middle-school level science exams. These pre-trained systems, however, rely only on their background knowledge and do not take the set F of core facts into account. Further, their knowledge sources and retrieval mechanism are close to those used by the IR solver that, by design, is guaranteed to fail on OpenBookQA. These two aspects place a natural limit on the effectiveness of these solvers on OpenBookQA, despite their excellent fit for the domain of multiplechoice science questions. We consider four such solvers.\n\nPMI  uses pointwise mutual information (PMI) to score each answer choice using statistics based on a corpus of 280 GB of plain text. It extracts unigrams, bigrams, trigrams, and skip-bigrams from the question q and each answer choice c i . Each answer choice is scored based on the average PMI across all pairs of question and answer n-grams.\n\nTableILP  is an Integer Linear Programming (ILP) based reasoning system designed for science questions. It operates over semi-structured relational tables of knowledge. It scores each answer choice based on the optimal (as defined by the ILP objective) \"support graph\" connecting the question to that answer through table rows. The small set of these knowledge tables, however, often results in missing knowledge, making TableILP not answer 24% of the OpenBookQA questions at all.\n\nTupleInference (Khot et al., 2017), also an ILP-based QA system, uses Open IE tuples (Banko et al., 2007) as its semi-structured representation. It builds these subject-verb-object tuples on-the-fly by retrieving text for each question from a large corpus. It then defines an ILP program to combine evidence from multiple tuples.\n\nDGEM ) is a neural entailment model that also uses Open IE to produce a semi-structured representation. We use the adaptation of this model to multiple-choice question answering proposed by , which works as follows: (1) convert q and each c i into a hypothesis, h i , and each retrieved fact into a premise p j ; and (2) return the answer choice with the highest entailment score, arg max i e(p j , h i ).\n\n\nNo Training; F and Extr. Knowledge\n\nWe also consider providing the set F of core facts to two existing solvers: the IR solver of  (to assess how far simple wordoverlap can get), and the TupleInference solver.\n\n\nTrained Models, No Knowledge\n\nWe consider several neural baseline models that are trained using Train set of OpenBookQA. For ease of explanation, we first define the notation used in our models. For a given question q mc = (q, {c 1 , c 2 , c 3 , c 4 }), we define the set of token sequences , S = {q, c 1 , c 2 , c 3 , c 4 }. For each token sequence s \u2208 S, w s j is the j th and e s j = Emb(w s j ) is the embedding for this token. We use n s to indicate the number of tokens in s and d for the dimensionality of the embeddings. 11 We model multiple-choice QA as multi-class classification: Given q mc , predict one of four class labels L =  Table 3: Example training questions (with their correct choices marked) along with the facts and reasoning needed. In the last example, the science fact states that lhs=\"source of light becomes closer\" implies rhs=\"source will appear brighter\". Grounding this rule based on the common-knowledge fact, produces a new rule: \"As headlights of the car come closer, headlights will appear brighter\"\n\n{1, 2, 3, 4}, where the true label is the correct answer index.\n\nEmbeddings + Similarities as Features. We first experiment with a simple logistic regression model (Mihaylov and Nakov, 2016;Frank, 2016, 2017) that uses centroid vectors r emb s of the word embeddings of tokens in s, and then computes the cosine similarities between the question and each answer choice, r cos q,c i :\nr emb s = 1 n s ns j=1 e s j \u2208 R d r cos q,c i = cos(r emb q , r emb c i ) \u2208 R 1\nFor each training instance, we build a feature representations f by concatenating these vectors and train an L2 logistic regression classifier:\nf = [r emb q\n; r emb c 1..4 ; r cos q,c 1..4 ] \u2208 R 5d+4 BiLSTM Max-Out Baselines. As a simple neural baseline, we adapt BiLSTM max-out model (Conneau et al., 2017) to our QA task. That is, we first encode the question tokens and choice tokens w s 1...ns , independently with a bi-directional context encoder (LSTM) to obtain a context (ctx) representation h ctx s 1...ns = BiLSTM(e s 1...ns ) \u2208 R ns\u00d72h Next, we perform an element-wise aggregation operation max on the encoded representations h ctx s 1..ns to construct a single vector:\nr ctx s = max(h ctx s 1..ns ) \u2208 R 2h .(1)\nGiven the contextual representations for each token sequence, we experiment with three configurations for using these representations for QA:\n\n(a) Plausible Answer Detector. This baseline goes to the extreme of completely ignoring q and trying to learn how plausible it is for c i to be the correct answer to some question in this domain. This captures the fact that certain choices like 'a magical place' or 'flying cats' are highly unlikely to be the correct answer to a science question without negation (which is the case for OpenBookQA).\n\nWe implement a plausible answer detector using a choice-only model for predicting the answer by obtaining a score \u03b1 c i as:\n\u03b1 c i = W T c r ctx c i \u2208 R 1 , where W T c \u2208 R 2h\nis a weights vector optimized during training, i = {1..4} is the index of the choice.\n\nTo obtain the answer choice from the set of choice scores \u03b1 c 1..4 using arg max(softmax(\u03b1 c 1..4 )), where softmax(\u03b1 c i ) = exp(\u03b1c i ) 4 j=1 exp(\u03b1c j ) as usual.\n\n(b) Odd-One-Out Solver. It considers all 4 answer options jointly and selects the one that is least similar to the others. This captures bias in human authored questions arising from the fact that creating good quality incorrect answers is difficult. Workers generally start with the correct answer, and then come up with three incorrect ones. The latter often tend to be homogeneous or share other common properties (e.g., non-scientific terms) uncharacteristic of the correct answer.\n\nWe implement this using a choice-to-choices attention model. For each choice c i , we calculate the attention to the other choices as \u03b1 c i ,c j . We then sum these attention values to compute the attention for c i to the rest of the choices, \u03b1 c i 2c r(est) , and return the choice with the lowest sum. The atten-tion is computed as \u03b1 c i ,c j = Att(r ctx\nc i , r ctx c j ) where Att(u, v) = W T ([u; v; u \u00b7 v; |u \u2212 v|]) \u2208 R 1\nis a linear attention function and W \u2208 R 8h is a weight vector. We then compute \u03b1 c i 2c r(est) = 4 j=1 \u03b1 c i ,c j (j = i) and select the answer with the index a c2cr = arg min(softmax(\u03b1 c 1..4 2cr )).\n\n(c) Question Match. This solver tries to predict which choice best matches the question (Nakov et al., 2016), without relying on external knowledge. To achieve that, we compute an attention score \u03b1 q,c i between q and each of the choices q i as \u03b1 q,c i = Att(r ctx q , r ctx c i ), and select the one with the highest score. We also experiment with a model where r ctx q and r ctx c i are obtained using token-wise interaction proposed in ESIM (Chen et al., 2017b).\n\n\nTrained Model with External Knowledge\n\nLastly, we implement a two stage model for incorporating external common knowledge, K. The first module performs information retrieval on K to select a fixed size subset of potentially relevant facts K Q,C for each instance in the dataset (see Appendix A). The second module is a neural network that takes (Q, C, K Q,C ) as input to predict the answer a q,c to a question Q from the set of choices C.\n\nKnowledge-Enhanced Reader. As a base knowledge-aware model, we use a variant of the model of Mihaylov and Frank (2018), implemented by extending our BiLSTM max-out question-match baseline (c). For each instance the model reads the question q and answers c 1..4 independently and attends to the set of retrieved external knowledge facts K Q,C . We encode each fact k j from K Q,C = k 1..N k (N k is the number of facts) with same BiLSTM as used for q and c 1..4 and construct a single vector r ctx k j \u2208 R 2h using Eq. 1. Having such representations for each k j results in knowledge memory matrix M k = r ctx k 1..N k \u2208 R N k \u00d72h . Note that M k is dynamic memory, specific for each instance in the batch and is encoded in each step during training. This memory is used to calculate a knowledge-aware representation, r kn s = ((M T k r ctx s ).M k ) \u2208 R 2h . Each context (ctx) representation r ctx s (s \u2208 S) is combined with r kn s to obtain a knowledge-enhanced representation r ctx+kn s = (r ctx s + r kn s )/2. We then model the knowledge-enhanced attention \u03b1 kn q,c i between   where W \u2208 R 9 is a weight vector initialized with the ones vector and optimized during training. We then select the answer c i with the highest score.\n\n\nBaseline Performance\n\nThe results for various baseline models are summarized in Table 4, grouped by method category.\n\nWe make a few observations: First, the task is largely solvable by a layperson, as evidenced by the 92% score of crowdworkers. This is measured as described in Sec-tion 3.2. We use annotations from Step 6 of the question generation process and reportH(Q)\u22123% as a conservative lower estimate. As an additional assessment, we also obtained 5 new annotations for 100 randomly chosen questions from each of Train, Dev, and Test sets. The performance remained similar at 88.6%, 90.2%, and 91.6%, resp.\n\nThe second group shows that pre-trained state-of-the-art solvers for multiple-choice science questions perform poorly. One explanation is their correlation with the the IR method used for question filtering, as mentioned in Section 4.1.\n\nThe third group of results suggests that adding F to pre-trained models has a mixed effect, improving TupleInference by 8.7% but not changing DGEM. 12 Unlike DGEM, TupleInference relies on brittle word-overlap similarity measures very similar to the ones used by IR. Since IR (KB) gets 0% by design, TupleInference (KB) also has poor performance and adding F helps it find better support despite the brittle measures.\n\nThe fourth group demonstrates that carefully designed trainable neural models-even if simplistic and knowledge-free-can be surprisingly powerful. For example, the \"plausible answer detector\" can predict the correct answer with 49.6% accuracy without even looking at the question. The \"odd-one-out\" solver, by considering other answer choices, raises this to 50.2%. The \"question match\" solver, which simply compares the BiLSTM max-out encoding of the question with that of various answer choices, also achieves 50.2%. 13 Similar findings have been reported for several recent datasets (Gururangan et al., 2018), making it imperative to perform such tests early.\n\nInterestingly, all of these neural knowledge-free baselines simultaneously succeed on 34.4% of the Dev questions, and simultaneously fail on 23.6%. For Question Match and ESIM we also experiment with ElMo (Peters et al., 2018) which improved their score on Test with 0.4% and 1.8%.\n\nThe final group demonstrates the need for external knowledge and deeper reasoning. When the \"oracle\" science fact f used by the question author is provided to the knowledge-enhanced reader, it improves over the knowledge-less models by about 5%. However, there is still a large gap, showing that the core fact is insufficient to answer the question. When we also include facts retrieved from WordNet (Miller et al., 1990), the score improves by about 0.5%. Unlike the WordNet gain, adding ConceptNet (Speer et al., 2017) introduces a distraction and reduces the score. This suggests that ConceptNet is either not a good source of knowledge for our task, or only a subset of its relations should be considered. Overall, external knowledge helps, although retrieving the right bits of knowledge remains difficult. In the last row of Table 4, we use the oracle core fact along with question author's interpretation of the additional fact k. This increases the scores substantially, to about 76%. This big jump shows that improved knowledge retrieval should help on this task. At the same time, we are still not close to the human performance level of 92% due to various reasons: (a) the additional fact needed can be subjective, as hinted at by our earlier analysis; (b) the authored facts K tend to be noisy (incomplete, over-complete, or only distantly related), also as mentioned earlier; and (b) even given the true gold facts, performing reliable \"reasoning\" to link them properly remains a challenge.\n\nSample predictions and analysis of questions from Dev are provided in Appendix D.\n\n\nConclusion\n\nWe present a new dataset, OpenBookQA, of about 6000 questions for open book question answering. The task focuses on the challenge of combining a corpus of provided science facts (open book) with external broad common knowledge. We show that this dataset requires simple common knowledge beyond the provided core facts, as well as multihop reasoning combining the two. While simple neural methods are able to achieve an accuracy of about 50%, this is still far from the human performance of 92% on this task. We leave closing this gap for future research, and illustrate, via oraclestyle experiments, the potential of better retrieval and reasoning on this task.\n\nFigure 1 :\n1An example for a question with a given set of choices and supporting facts.\n\nFigure 2 :\n2OpenBookQA question generation pipeline 2016) and a word association based solver (Turney, 2017), and verifies that (a) neither of them answers q mc correctly and (b) the top 3 IR retrieved sentences are insufficient to answer q mc ; if not, the question is edited and re-tried.\n\nq\nand c i as a linear combination of the ctx, kn and ctx + kn representations as \u03b1 q,c i = W T [Att(r ctx s , r ctx c i ); Att(r kn s , r kn c i ); Att(r ctx+kn s , r ctx c i ); Att(r ctx s\n\n\nCommon Knowledge:Steel is made of metal. Heat travels through a thermal conductor.\n\n\nal.,Fact, f \nFact, f \n\nCore \nFacts \n\nWrite question, q \n\nVerify hardness \n\nFact, f \n\nNo \n\nYes \n\nHard \nQuestions \n\nVerify \nanswerability \n\nOpenBookQA \n\nHard \nAnswerable \nQuestions \n\nDe-bias \nchoices \n\nHard for IR \n\nHard for ACME \nUniform Choice \nLength \n\n\n\n\nTable 1: Statistics for full OpenBookQA dataset. Parenthetical numbers next to each average are the max.OpenBookQA Statistics \n# of questions \n5957 \n# of choices per question \n4 \nAvg. question sentences \n1.08 (6) \nAvg. question tokens \n11.46 (76) \nAvg. choice tokens \n2.89 (23) \nAvg. science fact tokens \n9.38 (28) \nVocabulary size (q+c) \n11855 \nVocabulary size (q+c+f) \n12839 \nAnswer is the longest choice 1108 (18.6%) \nAnswer is the shortest choice \n216 (3.6%) \n\n\n\n\n):1. ISA: Basic taxonomic facts such as isa(tree,9 Overall, 8140 questions were collected, of which 2183 \nwere discarded in crowdsourcing Step 7. \n\nFact Type \n% Questions % Facts \nPROPERTY \n29.11% 25.81% \nISA \n20.25% 17.20% \nBASIC \n17.72% 19.35% \nDEFINITION \n17.72% 15.05% \nCAUSAL \n11.39% \n9.68% \nOTHERS \n13.92% 12.90% \n\n\n\nTable 2 :\n2Percentage of questions and facts for the five \nmost common type of additional facts. Note that % \nQuestions does not add up to 100% since we count the \npercentage of questions where at least one such fact is \nneeded. \n\n\n\nTable 4 :\n4Scores obtained by various solvers on Open-BookQA, reported as a percentage \u00b1 the standard deviation across 5 runs with different random seeds. Other baselines are described in the corresponding referenced section. For oracle evaluation, we use the gold science fact f associated with each question, and optionally the additional fact k provided by the question author. Bold denotes the best Test score in each category.\nSemEval-2018 Task 11: Machine Comprehension using Commonsense Knowledge https://competitions. codalab.org/competitions/17184\nWe used Amazon Mechnical Turk, with workers from North America and with a 'masters' level qualification.6  Specifically, it looks for: 1) exactly 4 answer choices; 2) no negation words to trivially fool baselines (no, none, not, isn't, doesn't, aren't, don't, won't, except, can't, shouldn't,  wouldn't, couldn't, mustn't); 3) uniform answer choice length: all with at most 3 or at least 4 words.\nChoice 'A' was the correct answer in 69% of the questions at the end of Step 4.\nRealistically, there is some dependence across questions as a single worker may answer multiple questions. We leave a formal analysis of this setting as future work.\nOf course, every question had lexical variations. We marked it when this was the only change to the core fact.\nFor all experiments we use d = 300 GloVe(Pennington et al., 2014) embeddings pre-trained on 840B tokens from Common Crawl (https://nlp.stanford.edu/projects/glove/).\nBy design, IR with its default corpus gets 0% on Open-BookQA. Hence we don't consider the effect of adding F, which appears artificially magnified.13  This model also achieves the current best score, 33.87%, on the ARC Reasoning Challenge. When adapted for the textual entailment task by comparing BiLSTM max-out encodings of premise and hypothesis, it achieves 85% on the SciTail dataset.\nAcknowledgmentsThe authors would like to thank Lane Aasen for helping develop the infrastructure for the crowdsourcing task, and Madeleine van Zuylen for providing expert annotation for the Dev and Test questions.\nOpen information extraction from the web. M Banko, M J Cafarella, S Soderland, M Broadhead, O Etzioni, IJCAI. M. Banko, M. J. Cafarella, S. Soderland, M. Broad- head, and O. Etzioni. 2007. Open information ex- traction from the web. In IJCAI.\n\nA thorough examination of the cnn/daily mail reading comprehension task. D Chen, J Bolton, C D Manning, ACL. D. Chen, J. Bolton, and C. D. Manning. 2016. A thorough examination of the cnn/daily mail reading comprehension task. In ACL, pages 2358-2367.\n\nReading wikipedia to answer open-domain questions. D Chen, A Fisch, J Weston, A Bordes, ACL. D. Chen, A. Fisch, J. Weston, and A. Bordes. 2017a. Reading wikipedia to answer open-domain ques- tions. In ACL.\n\nEnhanced lstm for natural language inference. Q Chen, X Zhu, Z.-H Ling, S Wei, H Jiang, D Inkpen, ACL. Q. Chen, X. Zhu, Z.-H. Ling, S. Wei, H. Jiang, and D. Inkpen. 2017b. Enhanced lstm for natural lan- guage inference. In ACL, pages 1657-1668.\n\nThink you have solved question answering? Try ARC, the AI2 reasoning challenge. P Clark, I Cowhey, O Etzioni, T Khot, A Sabharwal, C Schoenick, O Tafjord, abs/1803.05457CoRRP. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabhar- wal, C. Schoenick, and O. Tafjord. 2018. Think you have solved question answering? Try ARC, the AI2 reasoning challenge. CoRR, abs/1803.05457.\n\nCombining retrieval, statistics, and inference to answer elementary science questions. P Clark, O Etzioni, T Khot, A Sabharwal, O Tafjord, P D Turney, D Khashabi, AAAI. P. Clark, O. Etzioni, T. Khot, A. Sabharwal, O. Tafjord, P. D. Turney, and D. Khashabi. 2016. Combining retrieval, statistics, and inference to answer elemen- tary science questions. In AAAI, pages 2580-2586.\n\nSupervised learning of universal sentence representations from natural language inference data. A Conneau, D Kiela, H Schwenk, L Barrault, A Bordes, EMNLP. A. Conneau, D. Kiela, H. Schwenk, L. Barrault, and A. Bordes. 2017. Supervised learning of universal sentence representations from natural language in- ference data. In EMNLP, pages 670-680.\n\nAllenNLP: A deep semantic natural language processing platform. M Gardner, J Grus, M Neumann, O Tafjord, P Dasigi, N F Liu, M Peters, M Schmitz, L S Zettlemoyer, abs/1803.07640CoRRM. Gardner, J. Grus, M. Neumann, O. Tafjord, P. Dasigi, N. F. Liu, M. Peters, M. Schmitz, and L. S. Zettlemoyer. 2017. AllenNLP: A deep seman- tic natural language processing platform. CoRR, abs/1803.07640.\n\nAnnotation artifacts in natural language inference data. S Gururangan, S Swayamdipta, O Levy, R Schwartz, S R Bowman, N A Smith, NAACL. S. Gururangan, S. Swayamdipta, O. Levy, R. Schwartz, S. R. Bowman, and N. A. Smith. 2018. Annota- tion artifacts in natural language inference data. In NAACL.\n\nTeaching machines to read and comprehend. K M Hermann, T Kocisky, E Grefenstette, L Espeholt, W Kay, M Suleyman, P Blunsom, NIPS. K. M. Hermann, T. Kocisky, E. Grefenstette, L. Espe- holt, W. Kay, M. Suleyman, and P. Blunsom. 2015. Teaching machines to read and comprehend. In NIPS, pages 1693-1701.\n\nThe goldilocks principle: Reading children's books with explicit memory representations. F Hill, A Bordes, S Chopra, J Weston, ICLR. F. Hill, A. Bordes, S. Chopra, and J. Weston. 2016. The goldilocks principle: Reading children's books with explicit memory representations. In ICLR.\n\nProbability inequalities for sums of bounded random variables. W Hoeffding, Journal of the American Statistical Association. 58301W. Hoeffding. 1963. Probability inequalities for sums of bounded random variables. Journal of the Amer- ican Statistical Association, 58(301):13-30.\n\nWhat's in an explanation? characterizing knowledge and inference requirements for elementary science exams. P Jansen, N Balasubramanian, M Surdeanu, P Clark, COLING. P. Jansen, N. Balasubramanian, M. Surdeanu, and P. Clark. 2016. What's in an explanation? charac- terizing knowledge and inference requirements for elementary science exams. In COLING.\n\nWorldTree: A corpus of explanation graphs for elementary science questions supporting multi-hop inference. P A Jansen, E Wainwright, S Marmorstein, C T Morrison, LREC. P. A. Jansen, E. Wainwright, S. Marmorstein, and C. T. Morrison. 2018. WorldTree: A corpus of explana- tion graphs for elementary science questions sup- porting multi-hop inference. In LREC.\n\nOpen book assessment in computing degree programmes 1. T Jenkins, 95.28University of LeedsTechnical ReportT. Jenkins. 1995. Open book assessment in comput- ing degree programmes 1. Technical Report 95.28, University of Leeds.\n\nTriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. M Joshi, E Choi, D Weld, L Zettlemoyer, ACL. M. Joshi, E. Choi, D. Weld, and L. Zettlemoyer. 2017. TriviaQA: A large scale distantly supervised chal- lenge dataset for reading comprehension. In ACL, pages 1601-1611.\n\nAre you smarter than a sixth grader? textbook question answering for multimodal machine comprehension. A Kembhavi, M J Seo, D Schwenk, J Choi, A Farhadi, H Hajishirzi, CVPR. A. Kembhavi, M. J. Seo, D. Schwenk, J. Choi, A. Farhadi, and H. Hajishirzi. 2017. Are you smarter than a sixth grader? textbook question an- swering for multimodal machine comprehension. In CVPR, pages 5376-5384.\n\nLooking beyond the surface: A challenge set for reading comprehension over multiple sentences. D Khashabi, S Chaturvedi, M Roth, S Upadhyay, D Roth, NAACL. D. Khashabi, S. Chaturvedi, M. Roth, S. Upadhyay, and D. Roth. 2018. Looking beyond the surface: A challenge set for reading comprehension over multi- ple sentences. In NAACL.\n\nQuestion answering via integer programming over semi-structured knowledge. D Khashabi, T Khot, A Sabharwal, P Clark, O Etzioni, D Roth, IJCAI. D. Khashabi, T. Khot, A. Sabharwal, P. Clark, O. Et- zioni, and D. Roth. 2016. Question answering via integer programming over semi-structured knowl- edge. In IJCAI.\n\nAnswering complex questions using open information extraction. T Khot, A Sabharwal, P Clark, ACL. T. Khot, A. Sabharwal, and P. Clark. 2017. Answer- ing complex questions using open information ex- traction. In ACL.\n\nSciTail: A textual entailment dataset from science question answering. T Khot, A Sabharwal, P Clark, AAAI. T. Khot, A. Sabharwal, and P. Clark. 2018. SciTail: A textual entailment dataset from science question answering. In AAAI.\n\nAdam: a Method for Stochastic Optimization. D P Kingma, J L Ba, International Conference on Learning Representations. D. P. Kingma and J. L. Ba. 2015. Adam: a Method for Stochastic Optimization. International Conference on Learning Representations 2015, pages 1-15.\n\nThe NarrativeQA reading comprehension challenge. T Kocisk\u00fd, J Schwarz, P Blunsom, C Dyer, K M Hermann, G Melis, E Grefenstette, abs/1712.07040CoRRT. Kocisk\u00fd, J. Schwarz, P. Blunsom, C. Dyer, K. M. Hermann, G. Melis, and E. Grefenstette. 2017. The NarrativeQA reading comprehension challenge. CoRR, abs/1712.07040.\n\nJ Landsberger, Study guides and strategies. J. Landsberger. 1996. Study guides and strategies. Http://www.studygs.net/tsttak7.htm.\n\nDiscourse relation sense classification using cross-argument semantic similarity based on word embeddings. T Mihaylov, A Frank, CoNLL-16 shared task. T. Mihaylov and A. Frank. 2016. Discourse relation sense classification using cross-argument semantic similarity based on word embeddings. In CoNLL- 16 shared task, pages 100-107.\n\nStory Cloze Ending Selection Baselines and Data Examination. T Mihaylov, A Frank, LSD-Sem Shared Task. T. Mihaylov and A. Frank. 2017. Story Cloze Ending Selection Baselines and Data Examination. In LSD- Sem Shared Task.\n\nKnowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge. T Mihaylov, A Frank, ACL. T. Mihaylov and A. Frank. 2018. Knowledgeable Reader: Enhancing Cloze-Style Reading Compre- hension with External Commonsense Knowledge. In ACL, pages 821-832.\n\nSemanticZ at SemEval-2016 Task 3: Ranking relevant answers in community question answering using semantic similarity based on fine-tuned word embeddings. T Mihaylov, P Nakov, Se-mEval '16. T. Mihaylov and P. Nakov. 2016. SemanticZ at SemEval-2016 Task 3: Ranking relevant answers in community question answering using semantic sim- ilarity based on fine-tuned word embeddings. In Se- mEval '16.\n\nWordnet: a lexical database for english. G A Miller, Communications of the ACM. 3811G. A. Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39- 41.\n\nIntroduction to WordNet: An online lexical database. G A Miller, R Beckwith, C Fellbaum, D Gross, K J Miller, International Journal of Lexicography. 34G. A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. J. Miller. 1990. Introduction to WordNet: An on- line lexical database. International Journal of Lexi- cography, 3(4):235-244.\n\nTracking state changes in procedural text: A challenge dataset and models for process paragraph comprehension. B D Mishra, L Huang, N Tandon, W Tau Yih, P Clark, NAACL. B. D. Mishra, L. Huang, N. Tandon, W. tau Yih, and P. Clark. 2018. Tracking state changes in procedu- ral text: A challenge dataset and models for process paragraph comprehension. In NAACL.\n\nA Corpus and Evaluation Framework for Deeper Understanding of Commonsense Stories. N Mostafazadeh, N Chambers, X He, D Parikh, D Batra, L Vanderwende, P Kohli, J Allen, NAACL. N. Mostafazadeh, N. Chambers, X. He, D. Parikh, D. Batra, L. Vanderwende, P. Kohli, and J. Allen. 2016. A Corpus and Evaluation Framework for Deeper Understanding of Commonsense Stories. In NAACL.\n\ntask 3: Community question answering. P Nakov, L M\u00e0rquez, A Moschitti, W Magdy, H Mubarak, . A Freihat, J Glass, B , SemEval '16. Randeree. 2016. Semeval-2016P. Nakov, L. M\u00e0rquez, A. Moschitti, W. Magdy, H. Mubarak, a. A. Freihat, J. Glass, and B. Ran- deree. 2016. Semeval-2016 task 3: Community question answering. In SemEval '16, pages 525- 545.\n\nWho did what: A large-scale person-centered cloze dataset. T Onishi, H Wang, M Bansal, K Gimpel, D Mcallester, EMNLP. Austin, TexasT. Onishi, H. Wang, M. Bansal, K. Gimpel, and D. McAllester. 2016. Who did what: A large-scale person-centered cloze dataset. In EMNLP, pages 2230-2235, Austin, Texas.\n\nAutomatic differentiation in pytorch. A Paszke, S Gross, S Chintala, G Chanan, E Yang, Z Devito, Z Lin, A Desmaison, L Antiga, A Lerer, NIPS-W. A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, and A. Lerer. 2017. Automatic differentiation in py- torch. In NIPS-W.\n\nScikit-learn: Machine learning in Python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, J Vanderplas, A Passos, D Cournapeau, M Brucher, M Perrot, E Duchesnay, Journal of Machine Learning Research. 12F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Pretten- hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas- sos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825-2830.\n\nGloVe: Global vectors for word representation. J Pennington, R Socher, C Manning, EMNLP. J. Pennington, R. Socher, and C. Manning. 2014. GloVe: Global vectors for word representation. In EMNLP, pages 1532-1543.\n\nDeep contextualized word representations. M E Peters, M Neumann, M Iyyer, M Gardner, C Clark, K Lee, L Zettlemoyer, NAACL. M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer. 2018. Deep contextualized word representations. In NAACL.\n\nSQuAD: 100,000+ questions for machine comprehension of text. P Rajpurkar, J Zhang, K Lopyrev, P Liang, EMNLP. P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang. 2016. SQuAD: 100,000+ questions for machine compre- hension of text. In EMNLP, pages 2383-2392.\n\nMCTest: A challenge dataset for the open-domain machine comprehension of text. M Richardson, C J Burges, E Renshaw, EMNLP. M. Richardson, C. J. Burges, and E. Renshaw. 2013. MCTest: A challenge dataset for the open-domain machine comprehension of text. In EMNLP, pages 193-203.\n\nOpen mind common sense: Knowledge acquisition from the general public. P Singh, T Lin, E Mueller, G Lim, T Perkins, W Zhu, Lecture Notes in Computer Science. 2519P. Singh, T. Lin, E. Mueller, G. Lim, T. Perkins, and W. Zhu. 2002. Open mind common sense: Knowl- edge acquisition from the general public. In Lec- ture Notes in Computer Science, volume 2519, pages 1223-1237.\n\nConceptNet 5.5: An open multilingual graph of general knowledge. R Speer, J Chin, C Havasi, AAAI. R. Speer, J. Chin, and C. Havasi. 2017. ConceptNet 5.5: An open multilingual graph of general knowl- edge. In AAAI.\n\nMultiple choice question generation utilizing an ontology. K Stasaski, M A Hearst, BEA@EMNLP, 12th Workshop on Innovative Use of NLP for Building Educational Applications. K. Stasaski and M. A. Hearst. 2017. Multiple choice question generation utilizing an ontology. In BEA@EMNLP, 12th Workshop on Innovative Use of NLP for Building Educational Applications.\n\nPrerequisite skills for reading comprehension: Multiperspective analysis of mctest datasets and systems. S Sugawara, H Yokono, A Aizawa, AAAI. S. Sugawara, H. Yokono, and A. Aizawa. 2017. Pre- requisite skills for reading comprehension: Multi- perspective analysis of mctest datasets and systems. In AAAI, pages 3089-3096.\n\nNewsQA: A machine comprehension dataset. A Trischler, T Wang, X Yuan, J Harris, A Sordoni, P Bachman, K Suleman, Proceedings of the 2nd Workshop on Representation Learning for NLP. the 2nd Workshop on Representation Learning for NLPA. Trischler, T. Wang, X. Yuan, J. Harris, A. Sordoni, P. Bachman, and K. Suleman. 2017. NewsQA: A machine comprehension dataset. In Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 191-200.\n\nLeveraging term banks for answering complex questions: A case for sparse vectors. P D Turney, abs/1704.03543CoRRP. D. Turney. 2017. Leveraging term banks for answer- ing complex questions: A case for sparse vectors. CoRR, abs/1704.03543.\n\nMaking neural qa as simple as possible but not simpler. D Weissenborn, G Wiese, L Seiffe, CoNLL. D. Weissenborn, G. Wiese, and L. Seiffe. 2017. Mak- ing neural qa as simple as possible but not simpler. In CoNLL, pages 271-280.\n\nConstructing datasets for multi-hop reading comprehension across documents. J Welbl, P Stenetorp, S Riedel, TACLJ. Welbl, P. Stenetorp, and S. Riedel. 2018. Construct- ing datasets for multi-hop reading comprehension across documents. TACL.\n\nKG\u02c62: Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings. Y Zhang, H Dai, K Toraman, L Song, In arXivY. Zhang, H. Dai, K. Toraman, and L. Song. 2018. KG\u02c62: Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings. In arXiv.\n", "annotations": {"author": "[{\"end\":394,\"start\":217},{\"end\":539,\"start\":395},{\"end\":684,\"start\":540},{\"end\":854,\"start\":685},{\"end\":995,\"start\":855}]", "publisher": "[{\"end\":130,\"start\":89},{\"end\":1301,\"start\":1260}]", "author_last_name": "[{\"end\":231,\"start\":223},{\"end\":406,\"start\":401},{\"end\":551,\"start\":547},{\"end\":701,\"start\":692},{\"end\":862,\"start\":857}]", "author_first_name": "[{\"end\":222,\"start\":217},{\"end\":400,\"start\":395},{\"end\":546,\"start\":540},{\"end\":691,\"start\":685},{\"end\":856,\"start\":855}]", "author_affiliation": "[{\"end\":393,\"start\":263},{\"end\":538,\"start\":408},{\"end\":683,\"start\":553},{\"end\":853,\"start\":723},{\"end\":994,\"start\":864}]", "title": "[{\"end\":88,\"start\":1},{\"end\":1083,\"start\":996}]", "venue": "[{\"end\":1171,\"start\":1085}]", "abstract": "[{\"end\":2672,\"start\":1340}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3045,\"start\":3030},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3063,\"start\":3045},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3939,\"start\":3918},{\"end\":5300,\"start\":5295},{\"end\":5971,\"start\":5970},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6057,\"start\":6032},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":6479,\"start\":6453},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":6647,\"start\":6627},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6888,\"start\":6866},{\"end\":6927,\"start\":6926},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":8303,\"start\":8278},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8338,\"start\":8316},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8358,\"start\":8338},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8376,\"start\":8358},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8422,\"start\":8398},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":8445,\"start\":8422},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8464,\"start\":8445},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8502,\"start\":8483},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":8524,\"start\":8502},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8642,\"start\":8622},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8667,\"start\":8642},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":8856,\"start\":8836},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9149,\"start\":9127},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9448,\"start\":9426},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9910,\"start\":9883},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9957,\"start\":9936},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":10248,\"start\":10222},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11545,\"start\":11525},{\"end\":13364,\"start\":13355},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":15664,\"start\":15647},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":17350,\"start\":17331},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":21714,\"start\":21695},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21785,\"start\":21765},{\"end\":23161,\"start\":23159},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":23857,\"start\":23831},{\"end\":23874,\"start\":23857},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":24439,\"start\":24417},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":27052,\"start\":27032},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":27408,\"start\":27388},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":27971,\"start\":27946},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30972,\"start\":30947},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":31251,\"start\":31230},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31729,\"start\":31708},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":31828,\"start\":31808},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":36887,\"start\":36862}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33659,\"start\":33571},{\"attributes\":{\"id\":\"fig_1\"},\"end\":33951,\"start\":33660},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34142,\"start\":33952},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":34227,\"start\":34143},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":34484,\"start\":34228},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":34952,\"start\":34485},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":35276,\"start\":34953},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":35509,\"start\":35277},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":35942,\"start\":35510}]", "paragraph": "[{\"end\":3405,\"start\":2688},{\"end\":3533,\"start\":3423},{\"end\":4728,\"start\":3535},{\"end\":5736,\"start\":4730},{\"end\":6351,\"start\":5738},{\"end\":7407,\"start\":6353},{\"end\":7696,\"start\":7409},{\"end\":8033,\"start\":7713},{\"end\":8702,\"start\":8035},{\"end\":9640,\"start\":8704},{\"end\":10457,\"start\":9642},{\"end\":10973,\"start\":10459},{\"end\":11324,\"start\":10996},{\"end\":11470,\"start\":11326},{\"end\":11849,\"start\":11472},{\"end\":12510,\"start\":11851},{\"end\":12758,\"start\":12536},{\"end\":12830,\"start\":12760},{\"end\":12946,\"start\":12832},{\"end\":13448,\"start\":12948},{\"end\":13584,\"start\":13450},{\"end\":13805,\"start\":13586},{\"end\":13900,\"start\":13807},{\"end\":14342,\"start\":13922},{\"end\":15065,\"start\":14397},{\"end\":15221,\"start\":15067},{\"end\":15346,\"start\":15223},{\"end\":15438,\"start\":15348},{\"end\":16077,\"start\":15499},{\"end\":18627,\"start\":16103},{\"end\":19686,\"start\":18629},{\"end\":20125,\"start\":19706},{\"end\":20852,\"start\":20166},{\"end\":21196,\"start\":20854},{\"end\":21678,\"start\":21198},{\"end\":22009,\"start\":21680},{\"end\":22416,\"start\":22011},{\"end\":22627,\"start\":22455},{\"end\":23665,\"start\":22660},{\"end\":23730,\"start\":23667},{\"end\":24050,\"start\":23732},{\"end\":24275,\"start\":24132},{\"end\":24812,\"start\":24289},{\"end\":24996,\"start\":24855},{\"end\":25397,\"start\":24998},{\"end\":25522,\"start\":25399},{\"end\":25659,\"start\":25574},{\"end\":25824,\"start\":25661},{\"end\":26311,\"start\":25826},{\"end\":26669,\"start\":26313},{\"end\":26942,\"start\":26741},{\"end\":27409,\"start\":26944},{\"end\":27851,\"start\":27451},{\"end\":29086,\"start\":27853},{\"end\":29205,\"start\":29111},{\"end\":29703,\"start\":29207},{\"end\":29941,\"start\":29705},{\"end\":30360,\"start\":29943},{\"end\":31023,\"start\":30362},{\"end\":31306,\"start\":31025},{\"end\":32811,\"start\":31308},{\"end\":32894,\"start\":32813},{\"end\":33570,\"start\":32909}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14396,\"start\":14343},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15498,\"start\":15439},{\"attributes\":{\"id\":\"formula_2\"},\"end\":24131,\"start\":24051},{\"attributes\":{\"id\":\"formula_3\"},\"end\":24288,\"start\":24276},{\"attributes\":{\"id\":\"formula_4\"},\"end\":24854,\"start\":24813},{\"attributes\":{\"id\":\"formula_5\"},\"end\":25573,\"start\":25523},{\"attributes\":{\"id\":\"formula_6\"},\"end\":26740,\"start\":26670}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":17899,\"start\":17892},{\"end\":19153,\"start\":19146},{\"end\":23279,\"start\":23272},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":29176,\"start\":29169},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":32146,\"start\":32139}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2686,\"start\":2674},{\"end\":3421,\"start\":3408},{\"attributes\":{\"n\":\"2\"},\"end\":7711,\"start\":7699},{\"attributes\":{\"n\":\"3\"},\"end\":10994,\"start\":10976},{\"attributes\":{\"n\":\"3.1\"},\"end\":12534,\"start\":12513},{\"attributes\":{\"n\":\"3.2\"},\"end\":13920,\"start\":13903},{\"attributes\":{\"n\":\"3.3\"},\"end\":16101,\"start\":16080},{\"attributes\":{\"n\":\"4\"},\"end\":19704,\"start\":19689},{\"attributes\":{\"n\":\"4.1\"},\"end\":20164,\"start\":20128},{\"attributes\":{\"n\":\"4.2\"},\"end\":22453,\"start\":22419},{\"attributes\":{\"n\":\"4.3\"},\"end\":22658,\"start\":22630},{\"attributes\":{\"n\":\"4.4\"},\"end\":27449,\"start\":27412},{\"attributes\":{\"n\":\"5\"},\"end\":29109,\"start\":29089},{\"attributes\":{\"n\":\"6\"},\"end\":32907,\"start\":32897},{\"end\":33582,\"start\":33572},{\"end\":33671,\"start\":33661},{\"end\":33954,\"start\":33953},{\"end\":35287,\"start\":35278},{\"end\":35520,\"start\":35511}]", "table": "[{\"end\":34484,\"start\":34234},{\"end\":34952,\"start\":34591},{\"end\":35276,\"start\":35004},{\"end\":35509,\"start\":35289}]", "figure_caption": "[{\"end\":33659,\"start\":33584},{\"end\":33951,\"start\":33673},{\"end\":34142,\"start\":33955},{\"end\":34227,\"start\":34145},{\"end\":34234,\"start\":34230},{\"end\":34591,\"start\":34487},{\"end\":35004,\"start\":34955},{\"end\":35942,\"start\":35522}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4194,\"start\":4186},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12616,\"start\":12608}]", "bib_author_first_name": "[{\"end\":37635,\"start\":37634},{\"end\":37644,\"start\":37643},{\"end\":37646,\"start\":37645},{\"end\":37659,\"start\":37658},{\"end\":37672,\"start\":37671},{\"end\":37685,\"start\":37684},{\"end\":37910,\"start\":37909},{\"end\":37918,\"start\":37917},{\"end\":37928,\"start\":37927},{\"end\":37930,\"start\":37929},{\"end\":38141,\"start\":38140},{\"end\":38149,\"start\":38148},{\"end\":38158,\"start\":38157},{\"end\":38168,\"start\":38167},{\"end\":38343,\"start\":38342},{\"end\":38351,\"start\":38350},{\"end\":38361,\"start\":38357},{\"end\":38369,\"start\":38368},{\"end\":38376,\"start\":38375},{\"end\":38385,\"start\":38384},{\"end\":38623,\"start\":38622},{\"end\":38632,\"start\":38631},{\"end\":38642,\"start\":38641},{\"end\":38653,\"start\":38652},{\"end\":38661,\"start\":38660},{\"end\":38674,\"start\":38673},{\"end\":38687,\"start\":38686},{\"end\":39000,\"start\":38999},{\"end\":39009,\"start\":39008},{\"end\":39020,\"start\":39019},{\"end\":39028,\"start\":39027},{\"end\":39041,\"start\":39040},{\"end\":39052,\"start\":39051},{\"end\":39054,\"start\":39053},{\"end\":39064,\"start\":39063},{\"end\":39388,\"start\":39387},{\"end\":39399,\"start\":39398},{\"end\":39408,\"start\":39407},{\"end\":39419,\"start\":39418},{\"end\":39431,\"start\":39430},{\"end\":39704,\"start\":39703},{\"end\":39715,\"start\":39714},{\"end\":39723,\"start\":39722},{\"end\":39734,\"start\":39733},{\"end\":39745,\"start\":39744},{\"end\":39755,\"start\":39754},{\"end\":39757,\"start\":39756},{\"end\":39764,\"start\":39763},{\"end\":39774,\"start\":39773},{\"end\":39785,\"start\":39784},{\"end\":39787,\"start\":39786},{\"end\":40085,\"start\":40084},{\"end\":40099,\"start\":40098},{\"end\":40114,\"start\":40113},{\"end\":40122,\"start\":40121},{\"end\":40134,\"start\":40133},{\"end\":40136,\"start\":40135},{\"end\":40146,\"start\":40145},{\"end\":40148,\"start\":40147},{\"end\":40366,\"start\":40365},{\"end\":40368,\"start\":40367},{\"end\":40379,\"start\":40378},{\"end\":40390,\"start\":40389},{\"end\":40406,\"start\":40405},{\"end\":40418,\"start\":40417},{\"end\":40425,\"start\":40424},{\"end\":40437,\"start\":40436},{\"end\":40714,\"start\":40713},{\"end\":40722,\"start\":40721},{\"end\":40732,\"start\":40731},{\"end\":40742,\"start\":40741},{\"end\":40972,\"start\":40971},{\"end\":41297,\"start\":41296},{\"end\":41307,\"start\":41306},{\"end\":41326,\"start\":41325},{\"end\":41338,\"start\":41337},{\"end\":41648,\"start\":41647},{\"end\":41650,\"start\":41649},{\"end\":41660,\"start\":41659},{\"end\":41674,\"start\":41673},{\"end\":41689,\"start\":41688},{\"end\":41691,\"start\":41690},{\"end\":41956,\"start\":41955},{\"end\":42218,\"start\":42217},{\"end\":42227,\"start\":42226},{\"end\":42235,\"start\":42234},{\"end\":42243,\"start\":42242},{\"end\":42538,\"start\":42537},{\"end\":42550,\"start\":42549},{\"end\":42552,\"start\":42551},{\"end\":42559,\"start\":42558},{\"end\":42570,\"start\":42569},{\"end\":42578,\"start\":42577},{\"end\":42589,\"start\":42588},{\"end\":42918,\"start\":42917},{\"end\":42930,\"start\":42929},{\"end\":42944,\"start\":42943},{\"end\":42952,\"start\":42951},{\"end\":42964,\"start\":42963},{\"end\":43231,\"start\":43230},{\"end\":43243,\"start\":43242},{\"end\":43251,\"start\":43250},{\"end\":43264,\"start\":43263},{\"end\":43273,\"start\":43272},{\"end\":43284,\"start\":43283},{\"end\":43529,\"start\":43528},{\"end\":43537,\"start\":43536},{\"end\":43550,\"start\":43549},{\"end\":43754,\"start\":43753},{\"end\":43762,\"start\":43761},{\"end\":43775,\"start\":43774},{\"end\":43958,\"start\":43957},{\"end\":43960,\"start\":43959},{\"end\":43970,\"start\":43969},{\"end\":43972,\"start\":43971},{\"end\":44230,\"start\":44229},{\"end\":44241,\"start\":44240},{\"end\":44252,\"start\":44251},{\"end\":44263,\"start\":44262},{\"end\":44271,\"start\":44270},{\"end\":44273,\"start\":44272},{\"end\":44284,\"start\":44283},{\"end\":44293,\"start\":44292},{\"end\":44496,\"start\":44495},{\"end\":44735,\"start\":44734},{\"end\":44747,\"start\":44746},{\"end\":45020,\"start\":45019},{\"end\":45032,\"start\":45031},{\"end\":45284,\"start\":45283},{\"end\":45296,\"start\":45295},{\"end\":45625,\"start\":45624},{\"end\":45637,\"start\":45636},{\"end\":45908,\"start\":45907},{\"end\":45910,\"start\":45909},{\"end\":46108,\"start\":46107},{\"end\":46110,\"start\":46109},{\"end\":46120,\"start\":46119},{\"end\":46132,\"start\":46131},{\"end\":46144,\"start\":46143},{\"end\":46153,\"start\":46152},{\"end\":46155,\"start\":46154},{\"end\":46502,\"start\":46501},{\"end\":46504,\"start\":46503},{\"end\":46514,\"start\":46513},{\"end\":46523,\"start\":46522},{\"end\":46533,\"start\":46532},{\"end\":46544,\"start\":46543},{\"end\":46834,\"start\":46833},{\"end\":46850,\"start\":46849},{\"end\":46862,\"start\":46861},{\"end\":46868,\"start\":46867},{\"end\":46878,\"start\":46877},{\"end\":46887,\"start\":46886},{\"end\":46902,\"start\":46901},{\"end\":46911,\"start\":46910},{\"end\":47163,\"start\":47162},{\"end\":47172,\"start\":47171},{\"end\":47183,\"start\":47182},{\"end\":47196,\"start\":47195},{\"end\":47205,\"start\":47204},{\"end\":47216,\"start\":47215},{\"end\":47218,\"start\":47217},{\"end\":47229,\"start\":47228},{\"end\":47238,\"start\":47237},{\"end\":47534,\"start\":47533},{\"end\":47544,\"start\":47543},{\"end\":47552,\"start\":47551},{\"end\":47562,\"start\":47561},{\"end\":47572,\"start\":47571},{\"end\":47813,\"start\":47812},{\"end\":47823,\"start\":47822},{\"end\":47832,\"start\":47831},{\"end\":47844,\"start\":47843},{\"end\":47854,\"start\":47853},{\"end\":47862,\"start\":47861},{\"end\":47872,\"start\":47871},{\"end\":47879,\"start\":47878},{\"end\":47892,\"start\":47891},{\"end\":47902,\"start\":47901},{\"end\":48131,\"start\":48130},{\"end\":48144,\"start\":48143},{\"end\":48157,\"start\":48156},{\"end\":48169,\"start\":48168},{\"end\":48179,\"start\":48178},{\"end\":48190,\"start\":48189},{\"end\":48200,\"start\":48199},{\"end\":48211,\"start\":48210},{\"end\":48227,\"start\":48226},{\"end\":48236,\"start\":48235},{\"end\":48247,\"start\":48246},{\"end\":48261,\"start\":48260},{\"end\":48271,\"start\":48270},{\"end\":48285,\"start\":48284},{\"end\":48296,\"start\":48295},{\"end\":48306,\"start\":48305},{\"end\":48719,\"start\":48718},{\"end\":48733,\"start\":48732},{\"end\":48743,\"start\":48742},{\"end\":48926,\"start\":48925},{\"end\":48928,\"start\":48927},{\"end\":48938,\"start\":48937},{\"end\":48949,\"start\":48948},{\"end\":48958,\"start\":48957},{\"end\":48969,\"start\":48968},{\"end\":48978,\"start\":48977},{\"end\":48985,\"start\":48984},{\"end\":49213,\"start\":49212},{\"end\":49226,\"start\":49225},{\"end\":49235,\"start\":49234},{\"end\":49246,\"start\":49245},{\"end\":49488,\"start\":49487},{\"end\":49502,\"start\":49501},{\"end\":49504,\"start\":49503},{\"end\":49514,\"start\":49513},{\"end\":49759,\"start\":49758},{\"end\":49768,\"start\":49767},{\"end\":49775,\"start\":49774},{\"end\":49786,\"start\":49785},{\"end\":49793,\"start\":49792},{\"end\":49804,\"start\":49803},{\"end\":50127,\"start\":50126},{\"end\":50136,\"start\":50135},{\"end\":50144,\"start\":50143},{\"end\":50336,\"start\":50335},{\"end\":50348,\"start\":50347},{\"end\":50350,\"start\":50349},{\"end\":50742,\"start\":50741},{\"end\":50754,\"start\":50753},{\"end\":50764,\"start\":50763},{\"end\":51002,\"start\":51001},{\"end\":51015,\"start\":51014},{\"end\":51023,\"start\":51022},{\"end\":51031,\"start\":51030},{\"end\":51041,\"start\":51040},{\"end\":51052,\"start\":51051},{\"end\":51063,\"start\":51062},{\"end\":51492,\"start\":51491},{\"end\":51494,\"start\":51493},{\"end\":51705,\"start\":51704},{\"end\":51720,\"start\":51719},{\"end\":51729,\"start\":51728},{\"end\":51953,\"start\":51952},{\"end\":51962,\"start\":51961},{\"end\":51975,\"start\":51974},{\"end\":52211,\"start\":52210},{\"end\":52220,\"start\":52219},{\"end\":52227,\"start\":52226},{\"end\":52238,\"start\":52237}]", "bib_author_last_name": "[{\"end\":37641,\"start\":37636},{\"end\":37656,\"start\":37647},{\"end\":37669,\"start\":37660},{\"end\":37682,\"start\":37673},{\"end\":37693,\"start\":37686},{\"end\":37915,\"start\":37911},{\"end\":37925,\"start\":37919},{\"end\":37938,\"start\":37931},{\"end\":38146,\"start\":38142},{\"end\":38155,\"start\":38150},{\"end\":38165,\"start\":38159},{\"end\":38175,\"start\":38169},{\"end\":38348,\"start\":38344},{\"end\":38355,\"start\":38352},{\"end\":38366,\"start\":38362},{\"end\":38373,\"start\":38370},{\"end\":38382,\"start\":38377},{\"end\":38392,\"start\":38386},{\"end\":38629,\"start\":38624},{\"end\":38639,\"start\":38633},{\"end\":38650,\"start\":38643},{\"end\":38658,\"start\":38654},{\"end\":38671,\"start\":38662},{\"end\":38684,\"start\":38675},{\"end\":38695,\"start\":38688},{\"end\":39006,\"start\":39001},{\"end\":39017,\"start\":39010},{\"end\":39025,\"start\":39021},{\"end\":39038,\"start\":39029},{\"end\":39049,\"start\":39042},{\"end\":39061,\"start\":39055},{\"end\":39073,\"start\":39065},{\"end\":39396,\"start\":39389},{\"end\":39405,\"start\":39400},{\"end\":39416,\"start\":39409},{\"end\":39428,\"start\":39420},{\"end\":39438,\"start\":39432},{\"end\":39712,\"start\":39705},{\"end\":39720,\"start\":39716},{\"end\":39731,\"start\":39724},{\"end\":39742,\"start\":39735},{\"end\":39752,\"start\":39746},{\"end\":39761,\"start\":39758},{\"end\":39771,\"start\":39765},{\"end\":39782,\"start\":39775},{\"end\":39799,\"start\":39788},{\"end\":40096,\"start\":40086},{\"end\":40111,\"start\":40100},{\"end\":40119,\"start\":40115},{\"end\":40131,\"start\":40123},{\"end\":40143,\"start\":40137},{\"end\":40154,\"start\":40149},{\"end\":40376,\"start\":40369},{\"end\":40387,\"start\":40380},{\"end\":40403,\"start\":40391},{\"end\":40415,\"start\":40407},{\"end\":40422,\"start\":40419},{\"end\":40434,\"start\":40426},{\"end\":40445,\"start\":40438},{\"end\":40719,\"start\":40715},{\"end\":40729,\"start\":40723},{\"end\":40739,\"start\":40733},{\"end\":40749,\"start\":40743},{\"end\":40982,\"start\":40973},{\"end\":41304,\"start\":41298},{\"end\":41323,\"start\":41308},{\"end\":41335,\"start\":41327},{\"end\":41344,\"start\":41339},{\"end\":41657,\"start\":41651},{\"end\":41671,\"start\":41661},{\"end\":41686,\"start\":41675},{\"end\":41700,\"start\":41692},{\"end\":41964,\"start\":41957},{\"end\":42224,\"start\":42219},{\"end\":42232,\"start\":42228},{\"end\":42240,\"start\":42236},{\"end\":42255,\"start\":42244},{\"end\":42547,\"start\":42539},{\"end\":42556,\"start\":42553},{\"end\":42567,\"start\":42560},{\"end\":42575,\"start\":42571},{\"end\":42586,\"start\":42579},{\"end\":42600,\"start\":42590},{\"end\":42927,\"start\":42919},{\"end\":42941,\"start\":42931},{\"end\":42949,\"start\":42945},{\"end\":42961,\"start\":42953},{\"end\":42969,\"start\":42965},{\"end\":43240,\"start\":43232},{\"end\":43248,\"start\":43244},{\"end\":43261,\"start\":43252},{\"end\":43270,\"start\":43265},{\"end\":43281,\"start\":43274},{\"end\":43289,\"start\":43285},{\"end\":43534,\"start\":43530},{\"end\":43547,\"start\":43538},{\"end\":43556,\"start\":43551},{\"end\":43759,\"start\":43755},{\"end\":43772,\"start\":43763},{\"end\":43781,\"start\":43776},{\"end\":43967,\"start\":43961},{\"end\":43975,\"start\":43973},{\"end\":44238,\"start\":44231},{\"end\":44249,\"start\":44242},{\"end\":44260,\"start\":44253},{\"end\":44268,\"start\":44264},{\"end\":44281,\"start\":44274},{\"end\":44290,\"start\":44285},{\"end\":44306,\"start\":44294},{\"end\":44508,\"start\":44497},{\"end\":44744,\"start\":44736},{\"end\":44753,\"start\":44748},{\"end\":45029,\"start\":45021},{\"end\":45038,\"start\":45033},{\"end\":45293,\"start\":45285},{\"end\":45302,\"start\":45297},{\"end\":45634,\"start\":45626},{\"end\":45643,\"start\":45638},{\"end\":45917,\"start\":45911},{\"end\":46117,\"start\":46111},{\"end\":46129,\"start\":46121},{\"end\":46141,\"start\":46133},{\"end\":46150,\"start\":46145},{\"end\":46162,\"start\":46156},{\"end\":46511,\"start\":46505},{\"end\":46520,\"start\":46515},{\"end\":46530,\"start\":46524},{\"end\":46541,\"start\":46534},{\"end\":46550,\"start\":46545},{\"end\":46847,\"start\":46835},{\"end\":46859,\"start\":46851},{\"end\":46865,\"start\":46863},{\"end\":46875,\"start\":46869},{\"end\":46884,\"start\":46879},{\"end\":46899,\"start\":46888},{\"end\":46908,\"start\":46903},{\"end\":46917,\"start\":46912},{\"end\":47169,\"start\":47164},{\"end\":47180,\"start\":47173},{\"end\":47193,\"start\":47184},{\"end\":47202,\"start\":47197},{\"end\":47213,\"start\":47206},{\"end\":47226,\"start\":47219},{\"end\":47235,\"start\":47230},{\"end\":47541,\"start\":47535},{\"end\":47549,\"start\":47545},{\"end\":47559,\"start\":47553},{\"end\":47569,\"start\":47563},{\"end\":47583,\"start\":47573},{\"end\":47820,\"start\":47814},{\"end\":47829,\"start\":47824},{\"end\":47841,\"start\":47833},{\"end\":47851,\"start\":47845},{\"end\":47859,\"start\":47855},{\"end\":47869,\"start\":47863},{\"end\":47876,\"start\":47873},{\"end\":47889,\"start\":47880},{\"end\":47899,\"start\":47893},{\"end\":47908,\"start\":47903},{\"end\":48141,\"start\":48132},{\"end\":48154,\"start\":48145},{\"end\":48166,\"start\":48158},{\"end\":48176,\"start\":48170},{\"end\":48187,\"start\":48180},{\"end\":48197,\"start\":48191},{\"end\":48208,\"start\":48201},{\"end\":48224,\"start\":48212},{\"end\":48233,\"start\":48228},{\"end\":48244,\"start\":48237},{\"end\":48258,\"start\":48248},{\"end\":48268,\"start\":48262},{\"end\":48282,\"start\":48272},{\"end\":48293,\"start\":48286},{\"end\":48303,\"start\":48297},{\"end\":48316,\"start\":48307},{\"end\":48730,\"start\":48720},{\"end\":48740,\"start\":48734},{\"end\":48751,\"start\":48744},{\"end\":48935,\"start\":48929},{\"end\":48946,\"start\":48939},{\"end\":48955,\"start\":48950},{\"end\":48966,\"start\":48959},{\"end\":48975,\"start\":48970},{\"end\":48982,\"start\":48979},{\"end\":48997,\"start\":48986},{\"end\":49223,\"start\":49214},{\"end\":49232,\"start\":49227},{\"end\":49243,\"start\":49236},{\"end\":49252,\"start\":49247},{\"end\":49499,\"start\":49489},{\"end\":49511,\"start\":49505},{\"end\":49522,\"start\":49515},{\"end\":49765,\"start\":49760},{\"end\":49772,\"start\":49769},{\"end\":49783,\"start\":49776},{\"end\":49790,\"start\":49787},{\"end\":49801,\"start\":49794},{\"end\":49808,\"start\":49805},{\"end\":50133,\"start\":50128},{\"end\":50141,\"start\":50137},{\"end\":50151,\"start\":50145},{\"end\":50345,\"start\":50337},{\"end\":50357,\"start\":50351},{\"end\":50751,\"start\":50743},{\"end\":50761,\"start\":50755},{\"end\":50771,\"start\":50765},{\"end\":51012,\"start\":51003},{\"end\":51020,\"start\":51016},{\"end\":51028,\"start\":51024},{\"end\":51038,\"start\":51032},{\"end\":51049,\"start\":51042},{\"end\":51060,\"start\":51053},{\"end\":51071,\"start\":51064},{\"end\":51501,\"start\":51495},{\"end\":51717,\"start\":51706},{\"end\":51726,\"start\":51721},{\"end\":51736,\"start\":51730},{\"end\":51959,\"start\":51954},{\"end\":51972,\"start\":51963},{\"end\":51982,\"start\":51976},{\"end\":52217,\"start\":52212},{\"end\":52224,\"start\":52221},{\"end\":52235,\"start\":52228},{\"end\":52243,\"start\":52239}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":207169186},\"end\":37834,\"start\":37592},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":6360322},\"end\":38087,\"start\":37836},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":3618568},\"end\":38294,\"start\":38089},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":34032948},\"end\":38540,\"start\":38296},{\"attributes\":{\"doi\":\"abs/1803.05457\",\"id\":\"b4\"},\"end\":38910,\"start\":38542},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":1255845},\"end\":39289,\"start\":38912},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":28971531},\"end\":39637,\"start\":39291},{\"attributes\":{\"doi\":\"abs/1803.07640\",\"id\":\"b7\"},\"end\":40025,\"start\":39639},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":4537113},\"end\":40321,\"start\":40027},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":6203757},\"end\":40622,\"start\":40323},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":14915449},\"end\":40906,\"start\":40624},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":121341745},\"end\":41186,\"start\":40908},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":2498076},\"end\":41538,\"start\":41188},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":3623373},\"end\":41898,\"start\":41540},{\"attributes\":{\"doi\":\"95.28\",\"id\":\"b14\"},\"end\":42125,\"start\":41900},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":26501419},\"end\":42432,\"start\":42127},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":1310550},\"end\":42820,\"start\":42434},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":5112038},\"end\":43153,\"start\":42822},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":7145148},\"end\":43463,\"start\":43155},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":957320},\"end\":43680,\"start\":43465},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":24462950},\"end\":43911,\"start\":43682},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":6628106},\"end\":44178,\"start\":43913},{\"attributes\":{\"doi\":\"abs/1712.07040\",\"id\":\"b22\"},\"end\":44493,\"start\":44180},{\"attributes\":{\"id\":\"b23\"},\"end\":44625,\"start\":44495},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":16692427},\"end\":44956,\"start\":44627},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":7173982},\"end\":45178,\"start\":44958},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":29151507},\"end\":45468,\"start\":45180},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":8078497},\"end\":45864,\"start\":45470},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1671874},\"end\":46052,\"start\":45866},{\"attributes\":{\"id\":\"b29\"},\"end\":46388,\"start\":46054},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":5019682},\"end\":46748,\"start\":46390},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":15337246},\"end\":47122,\"start\":46750},{\"attributes\":{\"id\":\"b32\"},\"end\":47472,\"start\":47124},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":5761781},\"end\":47772,\"start\":47474},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":40027675},\"end\":48086,\"start\":47774},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":10659969},\"end\":48669,\"start\":48088},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":1957433},\"end\":48881,\"start\":48671},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":3626819},\"end\":49149,\"start\":48883},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":11816014},\"end\":49406,\"start\":49151},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":2100831},\"end\":49685,\"start\":49408},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":7190428},\"end\":50059,\"start\":49687},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":15206880},\"end\":50274,\"start\":50061},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":21067620},\"end\":50634,\"start\":50276},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":29159687},\"end\":50958,\"start\":50636},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":1167588},\"end\":51407,\"start\":50960},{\"attributes\":{\"doi\":\"abs/1704.03543\",\"id\":\"b45\"},\"end\":51646,\"start\":51409},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":2592133},\"end\":51874,\"start\":51648},{\"attributes\":{\"id\":\"b47\"},\"end\":52116,\"start\":51876},{\"attributes\":{\"id\":\"b48\"},\"end\":52403,\"start\":52118}]", "bib_title": "[{\"end\":37632,\"start\":37592},{\"end\":37907,\"start\":37836},{\"end\":38138,\"start\":38089},{\"end\":38340,\"start\":38296},{\"end\":38997,\"start\":38912},{\"end\":39385,\"start\":39291},{\"end\":40082,\"start\":40027},{\"end\":40363,\"start\":40323},{\"end\":40711,\"start\":40624},{\"end\":40969,\"start\":40908},{\"end\":41294,\"start\":41188},{\"end\":41645,\"start\":41540},{\"end\":42215,\"start\":42127},{\"end\":42535,\"start\":42434},{\"end\":42915,\"start\":42822},{\"end\":43228,\"start\":43155},{\"end\":43526,\"start\":43465},{\"end\":43751,\"start\":43682},{\"end\":43955,\"start\":43913},{\"end\":44732,\"start\":44627},{\"end\":45017,\"start\":44958},{\"end\":45281,\"start\":45180},{\"end\":45622,\"start\":45470},{\"end\":45905,\"start\":45866},{\"end\":46105,\"start\":46054},{\"end\":46499,\"start\":46390},{\"end\":46831,\"start\":46750},{\"end\":47160,\"start\":47124},{\"end\":47531,\"start\":47474},{\"end\":47810,\"start\":47774},{\"end\":48128,\"start\":48088},{\"end\":48716,\"start\":48671},{\"end\":48923,\"start\":48883},{\"end\":49210,\"start\":49151},{\"end\":49485,\"start\":49408},{\"end\":49756,\"start\":49687},{\"end\":50124,\"start\":50061},{\"end\":50333,\"start\":50276},{\"end\":50739,\"start\":50636},{\"end\":50999,\"start\":50960},{\"end\":51702,\"start\":51648}]", "bib_author": "[{\"end\":37643,\"start\":37634},{\"end\":37658,\"start\":37643},{\"end\":37671,\"start\":37658},{\"end\":37684,\"start\":37671},{\"end\":37695,\"start\":37684},{\"end\":37917,\"start\":37909},{\"end\":37927,\"start\":37917},{\"end\":37940,\"start\":37927},{\"end\":38148,\"start\":38140},{\"end\":38157,\"start\":38148},{\"end\":38167,\"start\":38157},{\"end\":38177,\"start\":38167},{\"end\":38350,\"start\":38342},{\"end\":38357,\"start\":38350},{\"end\":38368,\"start\":38357},{\"end\":38375,\"start\":38368},{\"end\":38384,\"start\":38375},{\"end\":38394,\"start\":38384},{\"end\":38631,\"start\":38622},{\"end\":38641,\"start\":38631},{\"end\":38652,\"start\":38641},{\"end\":38660,\"start\":38652},{\"end\":38673,\"start\":38660},{\"end\":38686,\"start\":38673},{\"end\":38697,\"start\":38686},{\"end\":39008,\"start\":38999},{\"end\":39019,\"start\":39008},{\"end\":39027,\"start\":39019},{\"end\":39040,\"start\":39027},{\"end\":39051,\"start\":39040},{\"end\":39063,\"start\":39051},{\"end\":39075,\"start\":39063},{\"end\":39398,\"start\":39387},{\"end\":39407,\"start\":39398},{\"end\":39418,\"start\":39407},{\"end\":39430,\"start\":39418},{\"end\":39440,\"start\":39430},{\"end\":39714,\"start\":39703},{\"end\":39722,\"start\":39714},{\"end\":39733,\"start\":39722},{\"end\":39744,\"start\":39733},{\"end\":39754,\"start\":39744},{\"end\":39763,\"start\":39754},{\"end\":39773,\"start\":39763},{\"end\":39784,\"start\":39773},{\"end\":39801,\"start\":39784},{\"end\":40098,\"start\":40084},{\"end\":40113,\"start\":40098},{\"end\":40121,\"start\":40113},{\"end\":40133,\"start\":40121},{\"end\":40145,\"start\":40133},{\"end\":40156,\"start\":40145},{\"end\":40378,\"start\":40365},{\"end\":40389,\"start\":40378},{\"end\":40405,\"start\":40389},{\"end\":40417,\"start\":40405},{\"end\":40424,\"start\":40417},{\"end\":40436,\"start\":40424},{\"end\":40447,\"start\":40436},{\"end\":40721,\"start\":40713},{\"end\":40731,\"start\":40721},{\"end\":40741,\"start\":40731},{\"end\":40751,\"start\":40741},{\"end\":40984,\"start\":40971},{\"end\":41306,\"start\":41296},{\"end\":41325,\"start\":41306},{\"end\":41337,\"start\":41325},{\"end\":41346,\"start\":41337},{\"end\":41659,\"start\":41647},{\"end\":41673,\"start\":41659},{\"end\":41688,\"start\":41673},{\"end\":41702,\"start\":41688},{\"end\":41966,\"start\":41955},{\"end\":42226,\"start\":42217},{\"end\":42234,\"start\":42226},{\"end\":42242,\"start\":42234},{\"end\":42257,\"start\":42242},{\"end\":42549,\"start\":42537},{\"end\":42558,\"start\":42549},{\"end\":42569,\"start\":42558},{\"end\":42577,\"start\":42569},{\"end\":42588,\"start\":42577},{\"end\":42602,\"start\":42588},{\"end\":42929,\"start\":42917},{\"end\":42943,\"start\":42929},{\"end\":42951,\"start\":42943},{\"end\":42963,\"start\":42951},{\"end\":42971,\"start\":42963},{\"end\":43242,\"start\":43230},{\"end\":43250,\"start\":43242},{\"end\":43263,\"start\":43250},{\"end\":43272,\"start\":43263},{\"end\":43283,\"start\":43272},{\"end\":43291,\"start\":43283},{\"end\":43536,\"start\":43528},{\"end\":43549,\"start\":43536},{\"end\":43558,\"start\":43549},{\"end\":43761,\"start\":43753},{\"end\":43774,\"start\":43761},{\"end\":43783,\"start\":43774},{\"end\":43969,\"start\":43957},{\"end\":43977,\"start\":43969},{\"end\":44240,\"start\":44229},{\"end\":44251,\"start\":44240},{\"end\":44262,\"start\":44251},{\"end\":44270,\"start\":44262},{\"end\":44283,\"start\":44270},{\"end\":44292,\"start\":44283},{\"end\":44308,\"start\":44292},{\"end\":44510,\"start\":44495},{\"end\":44746,\"start\":44734},{\"end\":44755,\"start\":44746},{\"end\":45031,\"start\":45019},{\"end\":45040,\"start\":45031},{\"end\":45295,\"start\":45283},{\"end\":45304,\"start\":45295},{\"end\":45636,\"start\":45624},{\"end\":45645,\"start\":45636},{\"end\":45919,\"start\":45907},{\"end\":46119,\"start\":46107},{\"end\":46131,\"start\":46119},{\"end\":46143,\"start\":46131},{\"end\":46152,\"start\":46143},{\"end\":46164,\"start\":46152},{\"end\":46513,\"start\":46501},{\"end\":46522,\"start\":46513},{\"end\":46532,\"start\":46522},{\"end\":46543,\"start\":46532},{\"end\":46552,\"start\":46543},{\"end\":46849,\"start\":46833},{\"end\":46861,\"start\":46849},{\"end\":46867,\"start\":46861},{\"end\":46877,\"start\":46867},{\"end\":46886,\"start\":46877},{\"end\":46901,\"start\":46886},{\"end\":46910,\"start\":46901},{\"end\":46919,\"start\":46910},{\"end\":47171,\"start\":47162},{\"end\":47182,\"start\":47171},{\"end\":47195,\"start\":47182},{\"end\":47204,\"start\":47195},{\"end\":47215,\"start\":47204},{\"end\":47228,\"start\":47215},{\"end\":47237,\"start\":47228},{\"end\":47241,\"start\":47237},{\"end\":47543,\"start\":47533},{\"end\":47551,\"start\":47543},{\"end\":47561,\"start\":47551},{\"end\":47571,\"start\":47561},{\"end\":47585,\"start\":47571},{\"end\":47822,\"start\":47812},{\"end\":47831,\"start\":47822},{\"end\":47843,\"start\":47831},{\"end\":47853,\"start\":47843},{\"end\":47861,\"start\":47853},{\"end\":47871,\"start\":47861},{\"end\":47878,\"start\":47871},{\"end\":47891,\"start\":47878},{\"end\":47901,\"start\":47891},{\"end\":47910,\"start\":47901},{\"end\":48143,\"start\":48130},{\"end\":48156,\"start\":48143},{\"end\":48168,\"start\":48156},{\"end\":48178,\"start\":48168},{\"end\":48189,\"start\":48178},{\"end\":48199,\"start\":48189},{\"end\":48210,\"start\":48199},{\"end\":48226,\"start\":48210},{\"end\":48235,\"start\":48226},{\"end\":48246,\"start\":48235},{\"end\":48260,\"start\":48246},{\"end\":48270,\"start\":48260},{\"end\":48284,\"start\":48270},{\"end\":48295,\"start\":48284},{\"end\":48305,\"start\":48295},{\"end\":48318,\"start\":48305},{\"end\":48732,\"start\":48718},{\"end\":48742,\"start\":48732},{\"end\":48753,\"start\":48742},{\"end\":48937,\"start\":48925},{\"end\":48948,\"start\":48937},{\"end\":48957,\"start\":48948},{\"end\":48968,\"start\":48957},{\"end\":48977,\"start\":48968},{\"end\":48984,\"start\":48977},{\"end\":48999,\"start\":48984},{\"end\":49225,\"start\":49212},{\"end\":49234,\"start\":49225},{\"end\":49245,\"start\":49234},{\"end\":49254,\"start\":49245},{\"end\":49501,\"start\":49487},{\"end\":49513,\"start\":49501},{\"end\":49524,\"start\":49513},{\"end\":49767,\"start\":49758},{\"end\":49774,\"start\":49767},{\"end\":49785,\"start\":49774},{\"end\":49792,\"start\":49785},{\"end\":49803,\"start\":49792},{\"end\":49810,\"start\":49803},{\"end\":50135,\"start\":50126},{\"end\":50143,\"start\":50135},{\"end\":50153,\"start\":50143},{\"end\":50347,\"start\":50335},{\"end\":50359,\"start\":50347},{\"end\":50753,\"start\":50741},{\"end\":50763,\"start\":50753},{\"end\":50773,\"start\":50763},{\"end\":51014,\"start\":51001},{\"end\":51022,\"start\":51014},{\"end\":51030,\"start\":51022},{\"end\":51040,\"start\":51030},{\"end\":51051,\"start\":51040},{\"end\":51062,\"start\":51051},{\"end\":51073,\"start\":51062},{\"end\":51503,\"start\":51491},{\"end\":51719,\"start\":51704},{\"end\":51728,\"start\":51719},{\"end\":51738,\"start\":51728},{\"end\":51961,\"start\":51952},{\"end\":51974,\"start\":51961},{\"end\":51984,\"start\":51974},{\"end\":52219,\"start\":52210},{\"end\":52226,\"start\":52219},{\"end\":52237,\"start\":52226},{\"end\":52245,\"start\":52237}]", "bib_venue": "[{\"end\":47605,\"start\":47592},{\"end\":51192,\"start\":51141},{\"end\":37700,\"start\":37695},{\"end\":37943,\"start\":37940},{\"end\":38180,\"start\":38177},{\"end\":38397,\"start\":38394},{\"end\":38620,\"start\":38542},{\"end\":39079,\"start\":39075},{\"end\":39445,\"start\":39440},{\"end\":39701,\"start\":39639},{\"end\":40161,\"start\":40156},{\"end\":40451,\"start\":40447},{\"end\":40755,\"start\":40751},{\"end\":41031,\"start\":40984},{\"end\":41352,\"start\":41346},{\"end\":41706,\"start\":41702},{\"end\":41953,\"start\":41900},{\"end\":42260,\"start\":42257},{\"end\":42606,\"start\":42602},{\"end\":42976,\"start\":42971},{\"end\":43296,\"start\":43291},{\"end\":43561,\"start\":43558},{\"end\":43787,\"start\":43783},{\"end\":44029,\"start\":43977},{\"end\":44227,\"start\":44180},{\"end\":44537,\"start\":44510},{\"end\":44775,\"start\":44755},{\"end\":45059,\"start\":45040},{\"end\":45307,\"start\":45304},{\"end\":45657,\"start\":45645},{\"end\":45944,\"start\":45919},{\"end\":46201,\"start\":46164},{\"end\":46557,\"start\":46552},{\"end\":46924,\"start\":46919},{\"end\":47252,\"start\":47241},{\"end\":47590,\"start\":47585},{\"end\":47916,\"start\":47910},{\"end\":48354,\"start\":48318},{\"end\":48758,\"start\":48753},{\"end\":49004,\"start\":48999},{\"end\":49259,\"start\":49254},{\"end\":49529,\"start\":49524},{\"end\":49843,\"start\":49810},{\"end\":50157,\"start\":50153},{\"end\":50446,\"start\":50359},{\"end\":50777,\"start\":50773},{\"end\":51139,\"start\":51073},{\"end\":51489,\"start\":51409},{\"end\":51743,\"start\":51738},{\"end\":51950,\"start\":51876},{\"end\":52208,\"start\":52118}]"}}}, "year": 2023, "month": 12, "day": 17}