{"id": 211171550, "updated": "2023-10-06 18:43:44.513", "metadata": {"title": "Beyond Clicks: Modeling Multi-Relational Item Graph for Session-Based Target Behavior Prediction", "authors": "[{\"first\":\"Wen\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Wei\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Shukai\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Qi\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Bo\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Leyu\",\"last\":\"Lin\",\"middle\":[]},{\"first\":\"Hongyuan\",\"last\":\"Zha\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of The Web Conference 2020", "publication_date": {"year": 2020, "month": 2, "day": 19}, "abstract": "Session-based target behavior prediction aims to predict the next item to be interacted with specific behavior types (e.g., clicking). Although existing methods for session-based behavior prediction leverage powerful representation learning approaches to encode items' sequential relevance in a low-dimensional space, they suffer from several limitations. Firstly, they focus on only utilizing the same type of user behavior for prediction, but ignore the potential of taking other behavior data as auxiliary information. This is particularly crucial when the target behavior is sparse but important (e.g., buying or sharing an item). Secondly, item-to-item relations are modeled separately and locally in one behavior sequence, and they lack a principled way to globally encode these relations more effectively. To overcome these limitations, we propose a novel Multi-relational Graph Neural Network model for Session-based target behavior Prediction, namely MGNN-SPred for short. Specifically, we build a Multi-Relational Item Graph (MRIG) based on all behavior sequences from all sessions, involving target and auxiliary behavior types. Based on MRIG, MGNN-SPred learns global item-to-item relations and further obtains user preferences w.r.t. current target and auxiliary behavior sequences, respectively. In the end, MGNN-SPred leverages a gating mechanism to adaptively fuse user representations for predicting next item interacted with target behavior. The extensive experiments on two real-world datasets demonstrate the superiority of MGNN-SPred by comparing with state-of-the-art session-based prediction methods, validating the benefits of leveraging auxiliary behavior and learning item-to-item relations over MRIG.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2002.07993", "mag": "3012705926", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/www/WangZLLZLZ20", "doi": "10.1145/3366423.3380077"}}, "content": {"source": {"pdf_hash": "8b716b3723b78f5ceaedcd656041e9f679dfc5b6", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2002.07993v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2002.07993", "status": "GREEN"}}, "grobid": {"id": "e9621d500df789347614a80cd463e6ce70f518a0", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/8b716b3723b78f5ceaedcd656041e9f679dfc5b6.txt", "contents": "\nBeyond Clicks: Modeling Multi-Relational Item Graph for Session-Based Target Behavior Prediction\n\n\nWen Wang \nWei Zhang nevinzhang@tencent.com \nShukai Liu shukailiu@tencent.com \nQi Liu Tencent \nBo Zhang Tencent \nLeyu Lin Tencent \nHongyuan Zha zha@cc.gatech.edu \n\nSchool of Computer Science and Technology\nSchool of Computer Science and Technology\nEast China Normal University\nEast China\n\n\nNormal University\nGeorgia Institute of Technology\n\n\nBeyond Clicks: Modeling Multi-Relational Item Graph for Session-Based Target Behavior Prediction\n10.1145/3366423.3380077\nSession-based target behavior prediction aims to predict the next item to be interacted with specific behavior types (e.g., clicking). Although existing methods for session-based behavior prediction leverage powerful representation learning approaches to encode items' sequential relevance in a low-dimensional space, they suffer from several limitations. Firstly, they focus on only utilizing the same type of user behavior for prediction, but ignore the potential of taking other behavior data as auxiliary information. This is particularly crucial when the target behavior is sparse but important (e.g., buying or sharing an item). Secondly, item-to-item relations are modeled separately and locally in one behavior sequence, and they lack a principled way to globally encode these relations more effectively. To overcome these limitations, we propose a novel Multirelational Graph Neural Network model for Session-based target behavior Prediction, namely MGNN-SPred for short. Specifically, we build a Multi-Relational Item Graph (MRIG) based on all behavior sequences from all sessions, involving target and auxiliary behavior types. Based on MRIG, MGNN-SPred learns global itemto-item relations and further obtains user preferences w.r.t. current target and auxiliary behavior sequences, respectively. In the end, MGNN-SPred leverages a gating mechanism to adaptively fuse user representations for predicting next item interacted with target behavior. The extensive experiments on two real-world datasets demonstrate the superiority of MGNN-SPred by comparing with state-of-the-art session-based prediction methods, validating the benefits of leveraging auxiliary behavior and learning item-to-item relations over MRIG.\n\nINTRODUCTION\n\nUnlike conventional recommendation algorithms which get accustomed to modeling each user-item interaction separately [11], recent sequential recommendation approaches meet more realistic requirements for its ability of modeling user dynamic interest. Session-based target behavior prediction [8] is the one of the main studied problem in this regard, aiming to predict the next item to be interacted with a user under a specific type of behavior (e.g., clicking an item). Based on the predictions, information providers can effectively deliver items to appropriate users and at the same time, and users can quickly find the items what they actually want. Note that we use session-based prediction and session-based recommendation interchangeably throughout this paper.\n\nEarly studies for this problem assume that the appearance of the next item depends only on its previous item [23,33] in the same sequence. With such a strong assumption, they could only model the last item in each sequence and ignore other information from the sequence. To relieve this assumption, various methods adopt sequential models for session-based recommendation system to learn behavior sequences. Recurrent Neural Networks (RNN) [9] is commonly leveraged to obtain promising performance. The relevant methods could roughly be attributed into two categories: singlesession based recommendation models [8,30] and multi-session based recommendation models [21,31]. As the latter category requires the user ID of each behavior sequence should be known in advance to link multiple sequences of the same user together, it is not so universal than the first category due to privacy issues and user scalability problem (e.g., a billion of active users each day in WeChat). As such, we study session-based target behavior prediction from the perspective of single-session based modeling.\n\nIn the domain of single-session based behavior prediction, some studies [14,22,25] adopt attention mechanism [1,28] and outperform the pioneering RNN based methods [8]. Recent advances in graph neural networks (GNN) [3,7] further boost the performance of session-based behavior prediction by modeling each sessionbased behavior sequence as a graph to achieve the state-of-the-art performance [29,30]. However, existing studies in this regard still suffer from several limitations. Firstly, they focus on only using the same type of user behavior as input for the next item prediction, but ignore the potential of leveraging other type of behavior as auxiliary information. This is particularly crucial when the target behavior is sparse but important (e.g., buying or sharing an item). Secondly, item-to-item relations are modeled separately and locally, since both RNN based and GNN based recommendation models only utilize one behavior sequence each time. It is intuitive that abundant item-to-item relations are hidden in various behavior sequences. For example, if many other users who have bought item B after buying item A, the relation between item A and B is especially vital if a target user just bought item A.\n\nTo overcome these limitations, we propose a novel Multi-relational Graph Neural Network model for Session-based target behavior Prediction, namely MGNN-SPred for short. The target behavior we focused on is the aforementioned sparse behavior beyond the dense click behavior. MGNN-SPred jointly considers target behavior and auxiliary behavior sequences and explores global item-toitem relations for accurate prediction. Specifically, for the purpose of considering the global item-to-item relations, we build a Multi-Relational Item Graph (MRIG) based on the past behavior sequences of all sessions. There might exist multiple relations between two graph nodes, denoting target and auxiliary behavior types. Based on MRIG, MGNN-SPred encodes global item-to-item relations into node representations and further obtains local representations for current target and auxiliary behavior sequences, respectively. In the end, MGNN-SPred leverages a gating mechanism to adaptively fuse the representations from target behavior sequence and auxiliary behavior sequence to produce current user interest representation.\n\nThe main contributions of this work is summarized as follows: 1. We address the two limitations of existing methods by breaking the restriction of only using one type of behavior sequence in session-based recommendation and exploring another type of behavior as auxiliary information. We further construct the multirelational item graph for learning global item-to-item relations.\n\n2. To effectively model MRIG w.r.t. target and auxiliary behavior sequences, we develop the novel graph model MGNN-SPred which learns global item-to-item relations through graph neural network and integrates representations of target and auxiliary of current sequences by the gating mechanism.\n\n3. We carry out extensive experiments and demonstrate MGNN-SPred achieves the best performance among strong competitors, showing the benefits of overcoming the two limitations.\n\n\nRELATED WORK\n\nSession-Based Behavior Prediction. In the literature, the pioneering study [8] in the direction of single-session based recommendation first adopts a recurrent neural network based approach with past interacted items as the input of different time steps for session-based recommendation. Following that, [26] improves the model with data augmentation and the consideration of temporal user behavior shift. In addition to using RNN, [13] also adopts attention mechanism to capture a user's sequential behavior and its main purpose in a current session. Similarly, [14] proposes a novel attention mechanism to capture both the users' long-term interests in general and their short-term attention. More recently, with the flourish Graph Neural Networks (GNN) methodologies, [29] first separates each session sequence into different graphs and uses graph neural networks to capture complex item transitions in a specific graph. Afterwards, each session is represented as the combination of the global preference and current interests of this session using an attention network. [30] is similar to [29], which uses a multi-layered self-attention network as an alternative to capture long-range dependencies between items within a session. As discussed in the introduction, these existing relevant methods suffer from two limitations which motivate the proposal of our model in this paper. Multi-Behavior Modeling. Multi-behavior modeling for recommender system aims to leverage other types of user behavior to boost the recommendation performance on the target behavior. A few studies have already investigated this scenario from different perspectives. [12] considers to leverage users' social interactions as auxiliary behavior for target behavior prediction by collective matrix factorization (CMF) techniques. In a similar fashion, [34] builds multiple matrices from user different behaviors which cover user resharing behavior, user commenting behavior, user posting behavior, etc. CMF is adopted to learn shared user representation for recommendation as well. [15] proposes multi-feedback Bayesian personalized ranking (BPR), an extension of the classical Bayesian personalized ranking approach and tailored for different user behaviors. It differentiates different preference levels between different user behaviors in the sampling stage for ranking. [4] also considers the assignment different preference levels of various user behaviors. Instead of BPR, it incorporates this useful information into element-wise alternating least squares learner. More recently, a neural network approach is proposed by [6] to learn representations for user-item interactions with different behaviors. Multi-task learning is conducted to predict multi-behaviors with respect to a certain item in a cascading way. Our work fundamentally differs from the above studies since all of them assume the independence of different user-item interactions while our study is more realistic by considering to model user behaviors in a sequential setting. Graph Neural Networks. Graph neural networks are the methods used to generate representation of graph structured data, such as social network and knowledge graph. [20] extends Word2vec [17] by proposing a model, DeepWalk, to learn node representations based on sequences sampled from graphs. LINE [27] encodes firstorder and second-order proximity of nodes into a low-dimensional space. Recently, a surge of methods related on graph convolutional networks (GCN) have been raised. [2] presents a method with a graph-based analogue of convolutional architectures, which is the original version of GCN. Later, a number of improvements, extensions, and approximations of these spectral convolutions be proposed [5,7,10,18]. These approaches outperform other methods based on random walks (e.g., DeepWalk and node2vec). With the success in mind, an amount of GCN based methods are widely applied in various domains such as recommendation systems [18]. But most GCN based methods require that all nodes in the graph are present in each propagation step of GNN. Different from GCN, GraphSAGE [7] can train GNN with a minibatch setting. Inspired by this, we design our GNN to learn from the constructed multirelational item graph for session-based behavior prediction.\n\n\nTECHNOLOGIES 3.1 Problem Definition\n\nFor a session s in the session set S, let P s = [p s 1 , p s 2 , p s 3 , ..., p s |P s | ] denote the target behavior sequence and Q s = [q s 1 , q s 2 , q s 3 , ..., q s |Q s | ] represent the auxiliary behavior sequence. Moreover, we construct a Multi-Relational Item Graph G = (V, E) based on all behavior sequences from all sessions, where V is the set of nodes in the graph containing all available items and E is the edge sets involving multiple types of directed edges. Each edge is a triple consisting of the head item, the tail item, and the type of this edge. For instance, if we construct the graph based on behaviors of sharing and clicking, then an edge (a, b, share) \u2208 E means that a user shared item a and subsequently shared item b, and an edge (a, b, click) \u2208 E means that a user clicked item b after clicking item b. Given the above notations, we formulate the problem as follows:\n\nProblem 1 (session-based target behavior prediction). Given a session s \u2208 S and its target and auxiliary behavior sequences P s and Q s , along with MRIG G, the target of this problem is to learn a model that can generate K items which are most likely to be interacted with the user of the session in the next.\n\n\nOverview\n\nThe overall architecture of the proposed MGNN-SPred is depicted in Figure 1. The input to MGNN-SPred contains a Multi-Relational Item Graph (MRIG) and the two types of behavior sequences. SR-MRIG first learns item correlations from MRIG by graph neural networks and encode them into item representations. Afterwards, a user's two behavior sequences are regarded as two sub-graphs in the MRIG where the items in each sub-graph are connected Algorithm 1 Multi-relational item graph construction Input: Session set S, both target and auxiliary behavior sequences P s and Q s , \u2200s \u2208 S Output:\nMRIG G = (V, E) 1: V \u2190 , E \u2190 2: for s \u2208 S do 3: V \u2190 V \u222a {P s [1]} 4: for i = 2 to |P s | do 5: V \u2190 V \u222a {P s [i]}, E \u2190 E \u222a {(P s [i \u2212 1], P s [i], target)} 6: end for 7: V \u2190 V \u222a {Q s [1]} 8: for i = 2 to |Q s | do 9: V \u2190 V \u222a {Q s [i]}, E \u2190 E \u222a {(Q s [i \u22121], Q s [i]\n, auxiliary)} 10:\n\nend for 11: end for with a virtual node (\"T\" or \"A\" in Figure 1), respectively. Subsequently, SR-MRIG aggregates the nodes of each sub-graph to the corresponding virtual node, thus getting the representation of each behavior sequence. Finally, to fuse the two behavior representations and obtain user preference representations, a gating mechanism is adopted to adaptively decide the importance of different behaviors and perform weighted summation over them. For the purpose of recommendation, SR-MRIG calculates each item's score by user and item representations via a bi-linear product and use the scores to rank them for recommendation.\n\n\nGraph Construction\n\nThere are abundant relationships between items lying in users' historical behaviors. If a user buys item a, and subsequently buys item b in the same session, it indicates that item a and item b probably have some dependency, but does not reflect similarity too much since a user less likely buys two very similar items within a short duration. In comparison, if a user clicks item a, and subsequently clicks item b, it indicates that item a and item b are probably with large similarity. This is intuitive because a user usually browses a number of similar items, and picks the most suitable one to buy.\n\nWe construct the multi-relational item graph by taking all items as nodes and each type of behavior corresponds as one directed edge, denoting different relationships between items. The process of constructing MRIG is shown in Algorithm 1. The both target and auxiliary behavior sequences from all sessions P s and Q s (\u2200s \u2208 S) are provided as input. The algorithm browses all behavior sequences, and collects all items in the sequences as nodes of graph and constructs edges between two consequent items in the same sequence with their behavior types as the edge types. After constructing the graph with target and auxiliary behaviors, there are two types of directional edges in the graph.\n\n\nItem Representation Learning\n\nFor each node v \u2208 V, we use\u0113 v \u2208 R |V | denotes its one-hot representation. Before we feed the one-hot representations of nodes into GNN, we first convert each of them into a low-dimensional dense vector e v \u2208 R d by a learnable embedding matrix E \u2208 R |V |\u00d7d :\ne v = E \u22a4\u0113 v .\nAfter collecting the vectors e v (\u2200v \u2208 V), we feed them with MRIG G into GNN to generate global representation of nodes g v . The representations are expected to encode multiple item-to-item relations. We take node v as an example for illustration. First of all, we collect neighbors of the node v. Each node in the graph has four types of neighboring node sets. According to the type and direction, we name the four sets as \"target-forward\", \"targetbackward\", \"auxiliary-forward\", and \"auxiliary-backward\". Take the type of \"target\" as an example, we obtain neighbor groups corresponding to forward and backward direction as below:\nN t+ (v) = {v \u2032 |(v \u2032 , v, target) \u2208 E}, N t\u2212 (v) = {v \u2032 |(v, v \u2032 , target) \u2208 E}.\n(1) For the type of \"auxiliary\", its neighbor groups, i.e., N a+ (v) and N a\u2212 (v), are acquired by the same way.\n\nAt each step of representation propagation in GNN, we first aggregate each group of neighbors by the mean-pooling defined as follows: The representation of this group is defined below:\nh k t+,v = v \u2032 \u2208N t+ (v) h k \u22121 v \u2032 |N t+ (v)| .(2)\nThe representations of the three remaining groups are calculated in a similar fashion. Consequently, for the propose of joint considering different relations between items, we combine these four representations of different neighbor groups by sum-pooling:\nh k v = h k t+,v + h k t\u2212,v + h k a+,v + h k a\u2212,v .(3)\nFinally, we update the representation of the center node v by:\nh k v = h k \u22121 v +h k v .(4)\nAfter performing K iterations, we take the node representation of the last step as the representation of the corresponding item:\ng v = h K v .\nIn practice, we implement the GNN in a minibatch setting which is inspired by [7] to ensure scalability.\n\n\nSequence Representation Learning\n\nWe have tried different ways to compute the representation of the virtual node for the target and auxiliary behavior sequences, including using attention mechanism to assign different importance weights to the nodes and performing sub-graph propagating for several times. Empirically, we have found that simple mean-pooling could already achieve comparable performance while retaining low complexity. We denote the summarized representations of target behavior sequence P and auxiliary behavior sequence Q as p and q, respectively, which are given as:\np = |P | i=1 g p i |P | , q = |Q | i=1 g q i |Q | .(5)\nWe argue that two different types of behavior sequence representations might contribute differently when building an integrated representation. This is because the auxiliary behavior is not exactly the same with the target behavior to be predicted, and different users might have different concentration on different behaviors. For instances, some users might browse the item pages frequently and click various items arbitrarily, and another users might only click the items they want to buy. It is self-evident that the contributions of auxiliary behavior sequence for the next item prediction are different in these situations. We define the following gating mechanism to calculate the relative importance weight \u03b1:\n\u03b1 = \u03c3 (W \u0434 [p; q]),(6)\nwhere [p; q] denotes the concatenation of the two representations, \u03c3 is the sigmoid function, and W \u0434 \u2208 R 1\u00d72d is a trainable parameter of our model. Finally, we obtain the user preference representation o for the current session by the weighted summation of p and q:\no = \u03b1 \u00b7 p + (1 \u2212 \u03b1) \u00b7 q.(7)\n\nModel Prediction and Training\n\nWe further calculate the recommendation score s v of each items v \u2208 V using the item embedding e v . A bi-linear matching scheme is employed by:\ns v = o \u22a4 We v ,(8)\nwhere W \u2208 R d \u00d7d is a trainable parameter matrix of our model. To learn the parameters of our model, we apply a softmax function to normalize the scores s \u2208 R |V | over all items to get the probability distribution\u0177:\u0177 = softmax(s).\n\nBackpropagation for neural networks is adopted to optimize the model by minimizing the cross-entropy loss of the predicted probability distribution\u0177 w.r.t. the ground truth. The loss function is defined as follows:\nL = \u2212 m i=1 y i log(\u0177 i ) + (1 \u2212 y i ) log(1 \u2212\u0177 i ),(10)\nwhere y denotes the one-hot representation of the ground truth. randomly select one hundred thousand active users and collect their behavior records for a duration of one week. Since the duration is relatively short, we retain an entire behavior sequence of each user by taking the sequence as a single session. We treat behavior of purchase in Yoochoose and behavior of sharing in WeChat as the target behavior, and regard clicking behavior in both datasets as the auxiliary behavior. Given a session with the target behavior sequence P = [p 1 , p 2 , ..., p |P | ] and the auxiliary behavior sequence Q = [q 1 , q 2 , ..., q |Q | ], we adopt a similar way to construct training example as [13,29]. That is, we treat each item p i , (i \u2265 2) as the label and use [p 1 , p 2 , ...p i\u22121 ] as input of target behavior. The treatment for the auxiliary behavior is a little different, because a user is very likely to click an item before buying or sharing it. To avoid the auxiliary input already sees the labels, we only keep the clicked items before the target item that is also bought or shared by the user. We set a maximum length L for both types of sequences and only keep the last L items longer than the maximum length. Considering the fact that two datasets have different average sequence length (see details in Table 1), we set the maximum length L to 10 for WeChat and 3 for Yoochoose. We discuss the impact of different maximum length in Section 4.4.3.\n\n\nEXPERIMENT\n\nWe split the datasets in a chronological order for evaluation, consistent with real situations. We take the first 6/7 of datasets as the training data, and use 1/3 of the remaining data as the validation data to determine optimal hyper-parameter settings. MRIG used throughout the experiments are constructed only based on training data. The basic statistics of two datasets are summarized in Table 1.\n\n\nBaselines.\n\nWe compare the proposed model with several strong competitors, including state-of-the-art graph neural network based model for session-based recommendation.\n\n\u2022 POP. It just recommends the top-n frequent items in the training set regardless of behaviors in current sessions. \u2022 Item-KNN [24]. It recommends items most similar to the previously interacted items belonging to the same sessions. \u2022 GRU4Rec [8]. GRU4Rec is the pioneering RNN-based deep sequential model for session-based recommendation. \u2022 NARM [13]. It employs attention mechanism to capture different importance of each item according to their hidden states obtained by RNN. A weighted integration of different item representations is performed to obtain final representation. \u2022 STAMP [14]. This model learns users' general interest from the long-term memory of session context and current interest from the short-term memory of their last behaviors. \u2022 SR-GNN [29] and GC-SAN [30]. Both of the graph-based models only use a current session to construct graph for applying GNN to learn item representations. The difference is SR-GNN represents each session by a traditional attention network while GC-SAN is based on a multi-layered self-attention mechanism. \u2022 R-DAN. Reasoning-DAN (R-DAN) [19] is used to model both behavior sequences simultaneously. \u2022 CoAtt. Co-Attention (CoAtt) [16] with alternative calculation for interactive attention is adopted for comparison. \u2022 HetGNN. Heterogeneous graph neural network [32] is applied for recommendation, with two edge types and one node type. It is worth noting only target behavior is considered by the above baselines originally developed for session-based recommendation, i.e., GRU4Rec, NARM, STAMP, SR-GNN, and GC-SAN. To make the comparison more fairable, we revise these methods through the following manner. We use their original forms to model the target behavior sequence and auxiliary behavior sequence respectively, And afterwards, we utilize the proposed gating mechanism  to fuse the two types of representations as ours. In addition, we also compare our model with the baselines in the situation of only considering target behavior (see Table 3 for details).\n\n\nImplementation Details.\n\nWe implement our proposed model based on Tensorflow. The dimension of item embedding is set to 64. Adam with default parameter setting is adopted to optimize the model, with the mini-batch size of 64. GNN is ensured to run in a minibatch setting and the depth K is set to 2. We terminate the learning process with an early stopping strategy. We test different forms of attention computation formulas for the baselines based on attention mechanism and report their best results. The hyperparameters of baselines are turned on validation datasets as well.\n\n\nModel Comparison\n\nWe consider the top-100 ranked predictions as recommended items. Following [29,30], we adopt HR@100 (H@100), MRR@100 (M@100), and NDCG@100 (N@100) to evaluate the recommendation performance of all models after obtaining their recommendation lists. Table 2 shows the performance comparison between our model and the adopted baselines. (1) The first part of the table corresponds to the simple baselines. We observe their results are significantly worse than other methods. (2) The second part involves standard sequential based methods for session-based recommendation. We observe that their results keep at the same level, except for STAMP on WeChat. It shows that: 1) taking session-based recommendation as a sequential modeling task can improve performance; 2) although NARM and STAMP are more advanced approaches which use attention mechanism to combine hidden representations of different time steps, they do not show advantages on the sparse behavior prediction problem we studied (not the same as previous studies focusing on click prediction). (3) The third part is GNN based models. SR-GNN and GC-SAN seem to be better than the sequential methods, and HetGNN further boost the performance. (4) The second-to-last part involves approaches of learning two sequences in other research domains. Their best results are worse than the best performance of the above recommendation methods, which suggests that considering the interaction of items in two sequences might have no benefit for the studied problem. Finally, we can see that our method outperforms all the other methods, demonstrating the superiority of our model for session-based recommendation.\n\n\nImpact of Auxiliary Behavior Sequence\n\nWe choose several representative methods in Table 3 to test whether considering the auxiliary behavior sequence indeed boosts the performance of session-based recommendation. The methods with \"(w/o a)\" mean removing the auxiliary behavior sequence from their full version. Firstly, we observe that our proposed model still consistently achieves better performance in this situation. Moreover, by comparing each method in Table 2 with its \"(w/o a)\" version, we can find every method beats the one of \"(w/o a)\" with significant margins. Based on the above illustrations, we demonstrate that considering the auxiliary behavior sequence is indeed meaningful.\n\n\nModel Analysis\n\n\nAblation Study.\n\nWe conduct ablation studies of our model, using \"w/o ae\" to denote removing the edges related to the auxiliary behavior, using \"w/o asg\" to denote that not modeling the subgraph of the auxiliary behavior sequence in getting user preference representation, and using \"w/o g\" to indicate merging the two representations of the target and auxiliary behavior sequences by simple summation instead of the gating mechanism. Table 4 shows the corresponding results. We observe that the incorporation of the auxiliary edge into the built graph is beneficial for the problem by seeing \"w/o ae\". The integration of the auxiliary behavior with target behavior sequence have a notable contribution by seeing \"w/o asg\". Besides, we find that the performance becomes worse if we do not use the gating mechanism to merge the two representations of the target and auxiliary behavior sequences by investigating \"w/o g\". Through the above comparison, we conclude the main components in our model are effective.\n\n\nImpact of Depth of GNN.\n\nWe test different depth settings (from 0 to 3) about graph representation propagation. The depth setting with value 0 means the our model does not use GNN and could not learn any information from MRIG. Figure 2 shows the corresponding results. We can see that the performance of depth 0 is without doubt much worse than the results with depths from 1 to 3. This comparison clarifies the significance of considering MRIG for our model. Moreover, the performance becomes significantly better when the depth grows from 1 to 2, showing modeling high-order relation between items through GNN is indispensable. When the number of graph representation propagation is larger than 3, the representations of nodes might become less distinguishable, which is not ideal for further improving the performance.    \n\n\nImpact of Sequence\n\nLength. We visualize the performance variation with the change of the maximum behavior sequence length L in Figure 3, where we set L in the range from 1 to 20. As expected, with larger maximum sequence length at the beginning, the performance of both our model and SR-GNN grows to be better. After reaching the peaks, the results slightly become worse, and finally the variation trends turn to be stable. Overall, our model outperforms SR-GNN consistently. Besides, we find the lengths with the best performance are not the same in the two datasets. This is due to the fact the average length of Yoochoose is much smaller than that of WeChat, as shown in Table 1.\n\n\nCONCLUSION\n\nIn this paper, we study session-based target behavior prediction. Two limitations of existing relevant models are addressed: using only target behavior for next item prediction and lacking a principled way encode global item-to-item relations. To alleviate the issues, MGNN-SPred is proposed, with the major novelties of building and modeling of the multi-relational item graph. In addition, a gating mechanism is adopted to adaptively fuse target behavior sequences and auxiliary behavior sequences into the user preference representations for the next item prediction. Comprehensive experiments on two real-world datasets demonstrate MGNN-SPred achieves the best performance and its design is rational.\n\nFigure 1 :\n1The architecture of our model. We use a toy MRIG and two current behavior sequences as input. The number of recommended items is set to 2.\n\nFigure 2 :\n2Results of our model with different depths of GNN.\n\nFigure 3 :\n3Results for different maximum lengths.\n\nTable 1 :\n1Basic statistics of the datasets.Data \nWeChat \nYoochoose \n#items \n56,561 \n52,740 \n#sessions \n100,000 \n9,249,729 \nTime duration \n2019/09/17~23 2014/04/01~09/30 \n#edge of target \n217,774 \n225,879 \n#edge of auxiliary \n1,546,220 \n3,277,411 \nAverage length of target \n9.76 \n3.31 \nAverage length of auxiliary \n33.49 \n8.56 \n#training data \n167,931 \n163,005 \n#validation data \n12,333 \n12,985 \n#test data \n24,667 \n25,971 \n\n4.1 Experimental Setup \n\n4.1.1 Dataset. We evaluate our model on two real-world datasets \nnamed WeChat and Yoochoose. The Yoochoose dataset is obtained \nfrom the RecSys Challenge 2015. The user behavior sequences in \nthe dataset are already segmented into sessions and all the users are \nanonymized. The WeChat dataset is collected from Top Stories (\u770b\u4e00 \n\u770b) of WeChat, where we choose videos are regarded as items. We \n\n\n\nTable 2 :\n2Evaluation results of all methods.Methods \n\nWeChat \nYoochoose \nH@100 M@100 N@100 \nH@100 M@100 N@100 \nPOP \n13.565 \n1.1247 \n3.2621 \n6.095 \n0.2529 \n1.2231 \nItem-KNN 15.770 \n1.1624 \n3.7222 \n15.286 \n1.9415 \n4.4040 \nGRU4Rec \n18.831 \n1.3956 \n4.3966 \n19.114 \n2.5292 \n5.5830 \nNARM \n19.131 \n1.4034 \n4.4416 \n18.775 \n2.5819 \n5.5813 \nSTAMP \n17.757 \n1.3083 \n4.1078 \n20.361 \n2.3487 \n5.6879 \nSR-GNN \n18.940 \n1.3827 \n4.3967 \n21.262 \n2.6892 \n6.1232 \nGC-SAN \n19.034 \n1.2090 \n4.2490 \n19.718 \n2.5218 \n5.6861 \nHetGNN \n20.290 \n1.4171 \n4.6504 \n24.031 \n2.9546 \n6.8732 \nR-DAN \n18.952 \n1.3879 \n4.3980 \n15.956 \n2.3107 \n4.8608 \nCoAtt \n17.700 \n1.1931 \n4.0137 \n20.080 \n2.5742 \n5.8206 \nOurs \n21.271 1.4797 4.8529 \n28.632 3.6564 8.2722 \n\n\n\nTable 3 :\n3Results of not using auxiliary behavior sequences.Methods \n\nWeChat \nYoochoose \nH@100 M@100 N@100 \nH@100 M@100 N@100 \nGRU4Rec (w/o a) 16.889 \n1.2346 \n3.9128 \n14.817 \n1.6032 \n4.0012 \nNARM (w/o a) \n17.773 \n1.3123 \n4.1298 \n14.443 \n1.5540 \n3.8900 \nSR-GNN (w/o a) \n18.093 \n1.2621 \n4.1368 \n15.302 \n1.5782 \n4.0852 \nOurs (w/o a) \n19.252 \n1.3933 \n4.4473 \n21.089 \n2.3798 \n5.8221 \n\n\n\nTable 4 :\n4Ablation study of MGNN-SPredl.Methods \n\nWeChat \nYoochoose \nH@100 M@100 N@100 \nH@100 M@100 N@100 \nOurs (w/o ae) \n20.923 \n1.4665 \n4.7945 \n25.463 \n2.7678 \n6.8907 \nOurs (w/o asg) 19.742 \n1.3949 \n4.5167 \n22.517 \n2.6025 \n6.2631 \nOurs (w/o g) \n20.363 \n1.3707 \n4.6154 \n27.577 \n3.3531 \n7.7896 \nOurs \n21.271 1.4797 4.8529 \n28.632 3.6564 8.2722 \n\n\n\nDzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, Neural Machine Translation by Jointly Learning to Align and Translate. ICLR. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate. ICLR (2015).\n\n. Joan Bruna, Wojciech Zaremba, Arthur Szlam, Yann Lecun, Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral networks and locally connected networks on graphs. ICLR (2014).\n\nConvolutional Neural Networks on Graphs with Fast Localized Spectral Filtering. Micha\u00ebl Defferrard, Xavier Bresson, Pierre Vandergheynst, NIPS. Micha\u00ebl Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolu- tional Neural Networks on Graphs with Fast Localized Spectral Filtering. In NIPS. 3837-3845.\n\nImproving Implicit Recommender Systems with View Data. Jingtao Ding, Guanghui Yu, Xiangnan He, Yuhan Quan, Yong Li, Tat-Seng Chua, Depeng Jin, Jiajie Yu, Jingtao Ding, Guanghui Yu, Xiangnan He, Yuhan Quan, Yong Li, Tat-Seng Chua, Depeng Jin, and Jiajie Yu. 2018. Improving Implicit Recommender Systems with View Data. In IJCAI. 3343-3349.\n\nConvolutional networks on graphs for learning molecular fingerprints. Dougal David K Duvenaud, Jorge Maclaurin, Rafael Iparraguirre, Timothy Bombarell, Al\u00e1n Hirzel, Ryan P Aspuru-Guzik, Adams, David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Al\u00e1n Aspuru-Guzik, and Ryan P Adams. 2015. Convolutional networks on graphs for learning molecular fingerprints. In NIPS. 2224-2232.\n\nChen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, Fuli Feng, Yong Li, Tat-Seng Chua, and Depeng Jin. 2019. Neural Multi-task Recommendation from Multi-behavior Data. In ICDE. Chen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, Fuli Feng, Yong Li, Tat- Seng Chua, and Depeng Jin. 2019. Neural Multi-task Recommendation from Multi-behavior Data. In ICDE. 1554-1557.\n\nInductive representation learning on large graphs. Will Hamilton, Zhitao Ying, Jure Leskovec, NIPS. Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NIPS. 1024-1034.\n\nSession-based recommendations with recurrent neural networks. Bal\u00e1zs Hidasi, Alexandros Karatzoglou, ICLR. Linas Baltrunas, and Domonkos TikkBal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based recommendations with recurrent neural networks. ICLR (2016).\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural computation. 9Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735-1780.\n\nSemi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. ICLR (2017).\n\nMatrix Factorization Techniques for Recommender Systems. Yehuda Koren, Robert M Bell, Chris Volinsky, IEEE Computer. 42Yehuda Koren, Robert M. Bell, and Chris Volinsky. 2009. Matrix Factorization Techniques for Recommender Systems. IEEE Computer 42, 8 (2009), 30-37.\n\nMulti-relational matrix factorization using bayesian personalized ranking for social network data. Artus Krohn-Grimberghe, Lucas Drumond, Christoph Freudenthaler, Lars Schmidt-Thieme, WSDM. Artus Krohn-Grimberghe, Lucas Drumond, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2012. Multi-relational matrix factorization using bayesian personalized ranking for social network data. In WSDM. 173-182.\n\nNeural attentive session-based recommendation. Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, Jun Ma, CIKM. Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural attentive session-based recommendation. In CIKM. 1419-1428.\n\nSTAMP: shortterm attention/memory priority model for session-based recommendation. Qiao Liu, Yifu Zeng, Refuoe Mokhosi, Haibin Zhang, Qiao Liu, Yifu Zeng, Refuoe Mokhosi, and Haibin Zhang. 2018. STAMP: short- term attention/memory priority model for session-based recommendation. In KDD. 1831-1839.\n\nBayesian Personalized Ranking with Multi-Channel User Feedback. Babak Loni, Roberto Pagano, Martha Larson, Alan Hanjalic, RecSys. Babak Loni, Roberto Pagano, Martha Larson, and Alan Hanjalic. 2016. Bayesian Personalized Ranking with Multi-Channel User Feedback. In RecSys. 361-364.\n\nHierarchical question-image co-attention for visual question answering. Jiasen Lu, Jianwei Yang, Dhruv Batra, Devi Parikh, NIPS. Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. 2016. Hierarchical question-image co-attention for visual question answering. In NIPS. 289-297.\n\nDistributed representations of words and phrases and their compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, Jeff Dean, NIPS. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In NIPS. 3111-3119.\n\nGeometric matrix completion with recurrent multi-graph neural networks. Federico Monti, Michael Bronstein, Xavier Bresson, NIPS. Federico Monti, Michael Bronstein, and Xavier Bresson. 2017. Geometric matrix completion with recurrent multi-graph neural networks. In NIPS. 3697-3707.\n\nDual attention networks for multimodal reasoning and matching. Hyeonseob Nam, Jung-Woo Ha, Jeonghee Kim, CVPR. Hyeonseob Nam, Jung-Woo Ha, and Jeonghee Kim. 2017. Dual attention networks for multimodal reasoning and matching. In CVPR. 299-307.\n\nDeepwalk: Online learning of social representations. Bryan Perozzi, Rami Al-Rfou, Steven Skiena, KDD. Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In KDD. 701-710.\n\nPersonalizing session-based recommendations with hierarchical recurrent neural networks. Massimo Quadrana, Alexandros Karatzoglou, Bal\u00e1zs Hidasi, Paolo Cremonesi, In RecSysMassimo Quadrana, Alexandros Karatzoglou, Bal\u00e1zs Hidasi, and Paolo Cremonesi. 2017. Personalizing session-based recommendations with hierarchical recurrent neural networks. In RecSys. 130-137.\n\nRepeatNet: A Repeat Aware Neural Recommendation Machine for Session-Based Recommendation. Pengjie Ren, Zhumin Chen, Jing Li, Zhaochun Ren, Jun Ma, Maarten De Rijke, AAAI. Pengjie Ren, Zhumin Chen, Jing Li, Zhaochun Ren, Jun Ma, and Maarten de Rijke. 2019. RepeatNet: A Repeat Aware Neural Recommendation Machine for Session-Based Recommendation. In AAAI. 4806-4813.\n\nFactorizing personalized markov chains for next-basket recommendation. Steffen Rendle, Christoph Freudenthaler, Lars Schmidt-Thieme, WWW. Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factor- izing personalized markov chains for next-basket recommendation. In WWW. 811-820.\n\nItem-based collaborative filtering recommendation algorithms. George Badrul Munir Sarwar, Karypis, A Joseph, John Konstan, Riedl, Www. 1Badrul Munir Sarwar, George Karypis, Joseph A Konstan, John Riedl, et al. 2001. Item-based collaborative filtering recommendation algorithms. Www 1 (2001), 285-295.\n\nBERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, Peng Jiang, CIKM. Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Repre- sentations from Transformer. In CIKM.\n\nImproved recurrent neural networks for session-based recommendations. Xinxing Yong Kiam Tan, Yong Xu, Liu, Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. the 1st Workshop on Deep Learning for Recommender SystemsACMYong Kiam Tan, Xinxing Xu, and Yong Liu. 2016. Improved recurrent neural networks for session-based recommendations. In Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. ACM, 17-22.\n\nLine: Large-scale information network embedding. Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, Qiaozhu Mei, Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW. 1067-1077.\n\n. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, Attention is All you Need. In NIPS. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In NIPS. 6000-6010.\n\nSession-based recommendation with graph neural networks. Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, Tieniu Tan, AAAI. Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In AAAI. 346-353.\n\nGraph Contextualized Self-Attention Network for Session-based Recommendation. Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, S Victor, Jiajie Sheng, Xu, Fuzhen Zhuang, Junhua Fang, and Xiaofang Zhou. Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, Victor S Sheng, Jiajie Xu, Fuzhen Zhuang, Junhua Fang, and Xiaofang Zhou. 2019. Graph Contextualized Self- Attention Network for Session-based Recommendation. In IJCAI. 3940-3946.\n\nHierarchical Temporal Convolutional Networks for Dynamic Recommender Systems. Jiaxuan You, Yichen Wang, Aditya Pal, Pong Eksombatchai, Chuck Rosenberg, Jure Leskovec, Jiaxuan You, Yichen Wang, Aditya Pal, Pong Eksombatchai, Chuck Rosenberg, and Jure Leskovec. 2019. Hierarchical Temporal Convolutional Networks for Dynamic Recommender Systems. In WWW. 2236-2246.\n\nHeterogeneous Graph Neural Network. Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, Nitesh V Chawla, KDD. Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V. Chawla. 2019. Heterogeneous Graph Neural Network. In KDD. 793-803.\n\nLocation and Time Aware Social Collaborative Retrieval for New Successive Point-of-Interest Recommendation. Wei Zhang, Jianyong Wang, CIKM. Wei Zhang and Jianyong Wang. 2015. Location and Time Aware Social Collabo- rative Retrieval for New Successive Point-of-Interest Recommendation. In CIKM. 1221-1230.\n\nImproving User Topic Interest Profiles by Behavior Factorization. Zhe Zhao, Zhiyuan Cheng, Lichan Hong, and Ed Huai-hsin ChiZhe Zhao, Zhiyuan Cheng, Lichan Hong, and Ed Huai-hsin Chi. 2015. Improving User Topic Interest Profiles by Behavior Factorization. In WWW. 1406-1416.\n", "annotations": {"author": "[{\"end\":109,\"start\":100},{\"end\":143,\"start\":110},{\"end\":177,\"start\":144},{\"end\":193,\"start\":178},{\"end\":211,\"start\":194},{\"end\":229,\"start\":212},{\"end\":261,\"start\":230},{\"end\":387,\"start\":262},{\"end\":440,\"start\":388}]", "publisher": null, "author_last_name": "[{\"end\":108,\"start\":104},{\"end\":119,\"start\":114},{\"end\":154,\"start\":151},{\"end\":192,\"start\":185},{\"end\":210,\"start\":203},{\"end\":228,\"start\":217},{\"end\":242,\"start\":239}]", "author_first_name": "[{\"end\":103,\"start\":100},{\"end\":113,\"start\":110},{\"end\":150,\"start\":144},{\"end\":180,\"start\":178},{\"end\":184,\"start\":181},{\"end\":196,\"start\":194},{\"end\":202,\"start\":197},{\"end\":216,\"start\":212},{\"end\":238,\"start\":230}]", "author_affiliation": "[{\"end\":386,\"start\":263},{\"end\":439,\"start\":389}]", "title": "[{\"end\":97,\"start\":1},{\"end\":537,\"start\":441}]", "venue": null, "abstract": "[{\"end\":2287,\"start\":562}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2424,\"start\":2420},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2598,\"start\":2595},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3186,\"start\":3182},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3189,\"start\":3186},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3516,\"start\":3513},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3687,\"start\":3684},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3690,\"start\":3687},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3741,\"start\":3737},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3744,\"start\":3741},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4240,\"start\":4236},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":4243,\"start\":4240},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4246,\"start\":4243},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4276,\"start\":4273},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":4279,\"start\":4276},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4331,\"start\":4328},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4383,\"start\":4380},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4385,\"start\":4383},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4560,\"start\":4556},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":4563,\"start\":4560},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7443,\"start\":7440},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7673,\"start\":7669},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7801,\"start\":7797},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7932,\"start\":7928},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8140,\"start\":8136},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8443,\"start\":8439},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8462,\"start\":8458},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9018,\"start\":9014},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9200,\"start\":9196},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9430,\"start\":9426},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9721,\"start\":9718},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9975,\"start\":9972},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10562,\"start\":10558},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10584,\"start\":10580},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":10696,\"start\":10692},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":10878,\"start\":10875},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11105,\"start\":11102},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11107,\"start\":11105},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11110,\"start\":11107},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11113,\"start\":11110},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11340,\"start\":11336},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11483,\"start\":11480},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17752,\"start\":17749},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":20853,\"start\":20849},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":20856,\"start\":20853},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22339,\"start\":22335},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":22454,\"start\":22451},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22559,\"start\":22555},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22801,\"start\":22797},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":22976,\"start\":22972},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":22992,\"start\":22988},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23305,\"start\":23301},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":23397,\"start\":23393},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":23529,\"start\":23525},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":24910,\"start\":24906},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":24913,\"start\":24910}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":30600,\"start\":30449},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30664,\"start\":30601},{\"attributes\":{\"id\":\"fig_4\"},\"end\":30716,\"start\":30665},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":31562,\"start\":30717},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":32280,\"start\":31563},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":32663,\"start\":32281},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":33012,\"start\":32664}]", "paragraph": "[{\"end\":3071,\"start\":2303},{\"end\":4162,\"start\":3073},{\"end\":5384,\"start\":4164},{\"end\":6493,\"start\":5386},{\"end\":6875,\"start\":6495},{\"end\":7170,\"start\":6877},{\"end\":7348,\"start\":7172},{\"end\":11655,\"start\":7365},{\"end\":12593,\"start\":11695},{\"end\":12905,\"start\":12595},{\"end\":13506,\"start\":12918},{\"end\":13789,\"start\":13772},{\"end\":14431,\"start\":13791},{\"end\":15057,\"start\":14454},{\"end\":15750,\"start\":15059},{\"end\":16043,\"start\":15783},{\"end\":16691,\"start\":16059},{\"end\":16886,\"start\":16774},{\"end\":17072,\"start\":16888},{\"end\":17380,\"start\":17125},{\"end\":17498,\"start\":17436},{\"end\":17656,\"start\":17528},{\"end\":17775,\"start\":17671},{\"end\":18363,\"start\":17812},{\"end\":19136,\"start\":18419},{\"end\":19427,\"start\":19160},{\"end\":19632,\"start\":19488},{\"end\":19884,\"start\":19653},{\"end\":20100,\"start\":19886},{\"end\":21619,\"start\":20158},{\"end\":22035,\"start\":21634},{\"end\":22206,\"start\":22050},{\"end\":24229,\"start\":22208},{\"end\":24810,\"start\":24257},{\"end\":26490,\"start\":24831},{\"end\":27186,\"start\":26532},{\"end\":28215,\"start\":27223},{\"end\":29043,\"start\":28243},{\"end\":29729,\"start\":29066},{\"end\":30448,\"start\":29744}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13771,\"start\":13507},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16058,\"start\":16044},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16773,\"start\":16692},{\"attributes\":{\"id\":\"formula_3\"},\"end\":17124,\"start\":17073},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17435,\"start\":17381},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17527,\"start\":17499},{\"attributes\":{\"id\":\"formula_6\"},\"end\":17670,\"start\":17657},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18418,\"start\":18364},{\"attributes\":{\"id\":\"formula_8\"},\"end\":19159,\"start\":19137},{\"attributes\":{\"id\":\"formula_9\"},\"end\":19455,\"start\":19428},{\"attributes\":{\"id\":\"formula_10\"},\"end\":19652,\"start\":19633},{\"attributes\":{\"id\":\"formula_12\"},\"end\":20157,\"start\":20101}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21483,\"start\":21476},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22034,\"start\":22027},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24215,\"start\":24208},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":25086,\"start\":25079},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":26583,\"start\":26576},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":26960,\"start\":26953},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":27648,\"start\":27641},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":29728,\"start\":29721}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2301,\"start\":2289},{\"attributes\":{\"n\":\"2\"},\"end\":7363,\"start\":7351},{\"attributes\":{\"n\":\"3\"},\"end\":11693,\"start\":11658},{\"attributes\":{\"n\":\"3.2\"},\"end\":12916,\"start\":12908},{\"attributes\":{\"n\":\"3.3\"},\"end\":14452,\"start\":14434},{\"attributes\":{\"n\":\"3.4\"},\"end\":15781,\"start\":15753},{\"attributes\":{\"n\":\"3.5\"},\"end\":17810,\"start\":17778},{\"attributes\":{\"n\":\"3.6\"},\"end\":19486,\"start\":19457},{\"attributes\":{\"n\":\"4\"},\"end\":21632,\"start\":21622},{\"attributes\":{\"n\":\"4.1.2\"},\"end\":22048,\"start\":22038},{\"attributes\":{\"n\":\"4.1.3\"},\"end\":24255,\"start\":24232},{\"attributes\":{\"n\":\"4.2\"},\"end\":24829,\"start\":24813},{\"attributes\":{\"n\":\"4.3\"},\"end\":26530,\"start\":26493},{\"attributes\":{\"n\":\"4.4\"},\"end\":27203,\"start\":27189},{\"attributes\":{\"n\":\"4.4.1\"},\"end\":27221,\"start\":27206},{\"attributes\":{\"n\":\"4.4.2\"},\"end\":28241,\"start\":28218},{\"attributes\":{\"n\":\"4.4.3\"},\"end\":29064,\"start\":29046},{\"attributes\":{\"n\":\"5\"},\"end\":29742,\"start\":29732},{\"end\":30460,\"start\":30450},{\"end\":30612,\"start\":30602},{\"end\":30676,\"start\":30666},{\"end\":30727,\"start\":30718},{\"end\":31573,\"start\":31564},{\"end\":32291,\"start\":32282},{\"end\":32674,\"start\":32665}]", "table": "[{\"end\":31562,\"start\":30762},{\"end\":32280,\"start\":31609},{\"end\":32663,\"start\":32343},{\"end\":33012,\"start\":32706}]", "figure_caption": "[{\"end\":30600,\"start\":30462},{\"end\":30664,\"start\":30614},{\"end\":30716,\"start\":30678},{\"end\":30762,\"start\":30729},{\"end\":31609,\"start\":31575},{\"end\":32343,\"start\":32293},{\"end\":32706,\"start\":32676}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12993,\"start\":12985},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13854,\"start\":13846},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":28453,\"start\":28445},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":29182,\"start\":29174}]", "bib_author_first_name": "[{\"end\":33021,\"start\":33014},{\"end\":33041,\"start\":33032},{\"end\":33053,\"start\":33047},{\"end\":33288,\"start\":33284},{\"end\":33304,\"start\":33296},{\"end\":33320,\"start\":33314},{\"end\":33332,\"start\":33328},{\"end\":33567,\"start\":33560},{\"end\":33586,\"start\":33580},{\"end\":33602,\"start\":33596},{\"end\":33857,\"start\":33850},{\"end\":33872,\"start\":33864},{\"end\":33885,\"start\":33877},{\"end\":33895,\"start\":33890},{\"end\":33906,\"start\":33902},{\"end\":33919,\"start\":33911},{\"end\":33932,\"start\":33926},{\"end\":33944,\"start\":33938},{\"end\":34211,\"start\":34205},{\"end\":34235,\"start\":34230},{\"end\":34253,\"start\":34247},{\"end\":34275,\"start\":34268},{\"end\":34291,\"start\":34287},{\"end\":34306,\"start\":34300},{\"end\":34556,\"start\":34552},{\"end\":34570,\"start\":34562},{\"end\":34580,\"start\":34575},{\"end\":34595,\"start\":34586},{\"end\":34606,\"start\":34602},{\"end\":34617,\"start\":34613},{\"end\":34970,\"start\":34966},{\"end\":34987,\"start\":34981},{\"end\":34998,\"start\":34994},{\"end\":35208,\"start\":35202},{\"end\":35227,\"start\":35217},{\"end\":35466,\"start\":35462},{\"end\":35485,\"start\":35479},{\"end\":35701,\"start\":35700},{\"end\":35713,\"start\":35710},{\"end\":35909,\"start\":35903},{\"end\":35923,\"start\":35917},{\"end\":35925,\"start\":35924},{\"end\":35937,\"start\":35932},{\"end\":36218,\"start\":36213},{\"end\":36242,\"start\":36237},{\"end\":36261,\"start\":36252},{\"end\":36281,\"start\":36277},{\"end\":36568,\"start\":36564},{\"end\":36580,\"start\":36573},{\"end\":36592,\"start\":36586},{\"end\":36607,\"start\":36599},{\"end\":36616,\"start\":36613},{\"end\":36626,\"start\":36623},{\"end\":36869,\"start\":36865},{\"end\":36879,\"start\":36875},{\"end\":36892,\"start\":36886},{\"end\":36908,\"start\":36902},{\"end\":37151,\"start\":37146},{\"end\":37165,\"start\":37158},{\"end\":37180,\"start\":37174},{\"end\":37193,\"start\":37189},{\"end\":37443,\"start\":37437},{\"end\":37455,\"start\":37448},{\"end\":37467,\"start\":37462},{\"end\":37479,\"start\":37475},{\"end\":37728,\"start\":37723},{\"end\":37742,\"start\":37738},{\"end\":37757,\"start\":37754},{\"end\":37768,\"start\":37764},{\"end\":37770,\"start\":37769},{\"end\":37784,\"start\":37780},{\"end\":38053,\"start\":38045},{\"end\":38068,\"start\":38061},{\"end\":38086,\"start\":38080},{\"end\":38328,\"start\":38319},{\"end\":38342,\"start\":38334},{\"end\":38355,\"start\":38347},{\"end\":38559,\"start\":38554},{\"end\":38573,\"start\":38569},{\"end\":38589,\"start\":38583},{\"end\":38824,\"start\":38817},{\"end\":38845,\"start\":38835},{\"end\":38865,\"start\":38859},{\"end\":38879,\"start\":38874},{\"end\":39191,\"start\":39184},{\"end\":39203,\"start\":39197},{\"end\":39214,\"start\":39210},{\"end\":39227,\"start\":39219},{\"end\":39236,\"start\":39233},{\"end\":39248,\"start\":39241},{\"end\":39539,\"start\":39532},{\"end\":39557,\"start\":39548},{\"end\":39577,\"start\":39573},{\"end\":39830,\"start\":39824},{\"end\":39862,\"start\":39861},{\"end\":39875,\"start\":39871},{\"end\":40164,\"start\":40161},{\"end\":40173,\"start\":40170},{\"end\":40183,\"start\":40179},{\"end\":40196,\"start\":40188},{\"end\":40206,\"start\":40202},{\"end\":40217,\"start\":40212},{\"end\":40226,\"start\":40222},{\"end\":40509,\"start\":40502},{\"end\":40529,\"start\":40525},{\"end\":40933,\"start\":40929},{\"end\":40944,\"start\":40940},{\"end\":40956,\"start\":40949},{\"end\":40967,\"start\":40963},{\"end\":40978,\"start\":40975},{\"end\":40991,\"start\":40984},{\"end\":41152,\"start\":41146},{\"end\":41166,\"start\":41162},{\"end\":41180,\"start\":41176},{\"end\":41194,\"start\":41189},{\"end\":41211,\"start\":41206},{\"end\":41224,\"start\":41219},{\"end\":41226,\"start\":41225},{\"end\":41240,\"start\":41234},{\"end\":41254,\"start\":41249},{\"end\":41543,\"start\":41540},{\"end\":41554,\"start\":41548},{\"end\":41568,\"start\":41561},{\"end\":41579,\"start\":41574},{\"end\":41590,\"start\":41586},{\"end\":41602,\"start\":41596},{\"end\":41855,\"start\":41846},{\"end\":41868,\"start\":41860},{\"end\":41881,\"start\":41875},{\"end\":41888,\"start\":41887},{\"end\":41903,\"start\":41897},{\"end\":42269,\"start\":42262},{\"end\":42281,\"start\":42275},{\"end\":42294,\"start\":42288},{\"end\":42304,\"start\":42300},{\"end\":42324,\"start\":42319},{\"end\":42340,\"start\":42336},{\"end\":42589,\"start\":42584},{\"end\":42604,\"start\":42597},{\"end\":42615,\"start\":42611},{\"end\":42632,\"start\":42623},{\"end\":42646,\"start\":42640},{\"end\":42648,\"start\":42647},{\"end\":42911,\"start\":42908},{\"end\":42927,\"start\":42919},{\"end\":43175,\"start\":43172},{\"end\":43189,\"start\":43182}]", "bib_author_last_name": "[{\"end\":33030,\"start\":33022},{\"end\":33045,\"start\":33042},{\"end\":33060,\"start\":33054},{\"end\":33294,\"start\":33289},{\"end\":33312,\"start\":33305},{\"end\":33326,\"start\":33321},{\"end\":33338,\"start\":33333},{\"end\":33578,\"start\":33568},{\"end\":33594,\"start\":33587},{\"end\":33616,\"start\":33603},{\"end\":33862,\"start\":33858},{\"end\":33875,\"start\":33873},{\"end\":33888,\"start\":33886},{\"end\":33900,\"start\":33896},{\"end\":33909,\"start\":33907},{\"end\":33924,\"start\":33920},{\"end\":33936,\"start\":33933},{\"end\":33947,\"start\":33945},{\"end\":34228,\"start\":34212},{\"end\":34245,\"start\":34236},{\"end\":34266,\"start\":34254},{\"end\":34285,\"start\":34276},{\"end\":34298,\"start\":34292},{\"end\":34319,\"start\":34307},{\"end\":34326,\"start\":34321},{\"end\":34560,\"start\":34557},{\"end\":34573,\"start\":34571},{\"end\":34584,\"start\":34581},{\"end\":34600,\"start\":34596},{\"end\":34611,\"start\":34607},{\"end\":34620,\"start\":34618},{\"end\":34979,\"start\":34971},{\"end\":34992,\"start\":34988},{\"end\":35007,\"start\":34999},{\"end\":35215,\"start\":35209},{\"end\":35239,\"start\":35228},{\"end\":35477,\"start\":35467},{\"end\":35497,\"start\":35486},{\"end\":35708,\"start\":35702},{\"end\":35718,\"start\":35714},{\"end\":35727,\"start\":35720},{\"end\":35915,\"start\":35910},{\"end\":35930,\"start\":35926},{\"end\":35946,\"start\":35938},{\"end\":36235,\"start\":36219},{\"end\":36250,\"start\":36243},{\"end\":36275,\"start\":36262},{\"end\":36296,\"start\":36282},{\"end\":36571,\"start\":36569},{\"end\":36584,\"start\":36581},{\"end\":36597,\"start\":36593},{\"end\":36611,\"start\":36608},{\"end\":36621,\"start\":36617},{\"end\":36629,\"start\":36627},{\"end\":36873,\"start\":36870},{\"end\":36884,\"start\":36880},{\"end\":36900,\"start\":36893},{\"end\":36914,\"start\":36909},{\"end\":37156,\"start\":37152},{\"end\":37172,\"start\":37166},{\"end\":37187,\"start\":37181},{\"end\":37202,\"start\":37194},{\"end\":37446,\"start\":37444},{\"end\":37460,\"start\":37456},{\"end\":37473,\"start\":37468},{\"end\":37486,\"start\":37480},{\"end\":37736,\"start\":37729},{\"end\":37752,\"start\":37743},{\"end\":37762,\"start\":37758},{\"end\":37778,\"start\":37771},{\"end\":37789,\"start\":37785},{\"end\":38059,\"start\":38054},{\"end\":38078,\"start\":38069},{\"end\":38094,\"start\":38087},{\"end\":38332,\"start\":38329},{\"end\":38345,\"start\":38343},{\"end\":38359,\"start\":38356},{\"end\":38567,\"start\":38560},{\"end\":38581,\"start\":38574},{\"end\":38596,\"start\":38590},{\"end\":38833,\"start\":38825},{\"end\":38857,\"start\":38846},{\"end\":38872,\"start\":38866},{\"end\":38889,\"start\":38880},{\"end\":39195,\"start\":39192},{\"end\":39208,\"start\":39204},{\"end\":39217,\"start\":39215},{\"end\":39231,\"start\":39228},{\"end\":39239,\"start\":39237},{\"end\":39257,\"start\":39249},{\"end\":39546,\"start\":39540},{\"end\":39571,\"start\":39558},{\"end\":39592,\"start\":39578},{\"end\":39850,\"start\":39831},{\"end\":39859,\"start\":39852},{\"end\":39869,\"start\":39863},{\"end\":39883,\"start\":39876},{\"end\":39890,\"start\":39885},{\"end\":40168,\"start\":40165},{\"end\":40177,\"start\":40174},{\"end\":40186,\"start\":40184},{\"end\":40200,\"start\":40197},{\"end\":40210,\"start\":40207},{\"end\":40220,\"start\":40218},{\"end\":40232,\"start\":40227},{\"end\":40523,\"start\":40510},{\"end\":40532,\"start\":40530},{\"end\":40537,\"start\":40534},{\"end\":40938,\"start\":40934},{\"end\":40947,\"start\":40945},{\"end\":40961,\"start\":40957},{\"end\":40973,\"start\":40968},{\"end\":40982,\"start\":40979},{\"end\":40995,\"start\":40992},{\"end\":41160,\"start\":41153},{\"end\":41174,\"start\":41167},{\"end\":41187,\"start\":41181},{\"end\":41204,\"start\":41195},{\"end\":41217,\"start\":41212},{\"end\":41232,\"start\":41227},{\"end\":41247,\"start\":41241},{\"end\":41265,\"start\":41255},{\"end\":41546,\"start\":41544},{\"end\":41559,\"start\":41555},{\"end\":41572,\"start\":41569},{\"end\":41584,\"start\":41580},{\"end\":41594,\"start\":41591},{\"end\":41606,\"start\":41603},{\"end\":41858,\"start\":41856},{\"end\":41873,\"start\":41869},{\"end\":41885,\"start\":41882},{\"end\":41895,\"start\":41889},{\"end\":41909,\"start\":41904},{\"end\":41913,\"start\":41911},{\"end\":42273,\"start\":42270},{\"end\":42286,\"start\":42282},{\"end\":42298,\"start\":42295},{\"end\":42317,\"start\":42305},{\"end\":42334,\"start\":42325},{\"end\":42349,\"start\":42341},{\"end\":42595,\"start\":42590},{\"end\":42609,\"start\":42605},{\"end\":42621,\"start\":42616},{\"end\":42638,\"start\":42633},{\"end\":42655,\"start\":42649},{\"end\":42917,\"start\":42912},{\"end\":42932,\"start\":42928},{\"end\":43180,\"start\":43176},{\"end\":43195,\"start\":43190}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":33280,\"start\":33014},{\"attributes\":{\"id\":\"b1\"},\"end\":33478,\"start\":33282},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":3016223},\"end\":33793,\"start\":33480},{\"attributes\":{\"id\":\"b3\"},\"end\":34133,\"start\":33795},{\"attributes\":{\"id\":\"b4\"},\"end\":34550,\"start\":34135},{\"attributes\":{\"id\":\"b5\"},\"end\":34913,\"start\":34552},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":4755450},\"end\":35138,\"start\":34915},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":11810482},\"end\":35436,\"start\":35140},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1915014},\"end\":35632,\"start\":35438},{\"attributes\":{\"id\":\"b9\"},\"end\":35844,\"start\":35634},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":58370896},\"end\":36112,\"start\":35846},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":5569779},\"end\":36515,\"start\":36114},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":21066930},\"end\":36780,\"start\":36517},{\"attributes\":{\"id\":\"b13\"},\"end\":37080,\"start\":36782},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":757461},\"end\":37363,\"start\":37082},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":868693},\"end\":37644,\"start\":37365},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":16447573},\"end\":37971,\"start\":37646},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":18052422},\"end\":38254,\"start\":37973},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":945386},\"end\":38499,\"start\":38256},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":3051291},\"end\":38726,\"start\":38501},{\"attributes\":{\"id\":\"b20\"},\"end\":39092,\"start\":38728},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":54447414},\"end\":39459,\"start\":39094},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":207178809},\"end\":39760,\"start\":39461},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":8047550},\"end\":40062,\"start\":39762},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":119181611},\"end\":40430,\"start\":40064},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":2552056},\"end\":40878,\"start\":40432},{\"attributes\":{\"id\":\"b26\"},\"end\":41142,\"start\":40880},{\"attributes\":{\"id\":\"b27\"},\"end\":41481,\"start\":41144},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":53219431},\"end\":41766,\"start\":41483},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":199465865},\"end\":42182,\"start\":41768},{\"attributes\":{\"id\":\"b30\"},\"end\":42546,\"start\":42184},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":198952485},\"end\":42798,\"start\":42548},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":2157551},\"end\":43104,\"start\":42800},{\"attributes\":{\"id\":\"b33\"},\"end\":43380,\"start\":43106}]", "bib_title": "[{\"end\":33558,\"start\":33480},{\"end\":34964,\"start\":34915},{\"end\":35200,\"start\":35140},{\"end\":35460,\"start\":35438},{\"end\":35901,\"start\":35846},{\"end\":36211,\"start\":36114},{\"end\":36562,\"start\":36517},{\"end\":37144,\"start\":37082},{\"end\":37435,\"start\":37365},{\"end\":37721,\"start\":37646},{\"end\":38043,\"start\":37973},{\"end\":38317,\"start\":38256},{\"end\":38552,\"start\":38501},{\"end\":39182,\"start\":39094},{\"end\":39530,\"start\":39461},{\"end\":39822,\"start\":39762},{\"end\":40159,\"start\":40064},{\"end\":40500,\"start\":40432},{\"end\":41538,\"start\":41483},{\"end\":41844,\"start\":41768},{\"end\":42582,\"start\":42548},{\"end\":42906,\"start\":42800}]", "bib_author": "[{\"end\":33032,\"start\":33014},{\"end\":33047,\"start\":33032},{\"end\":33062,\"start\":33047},{\"end\":33296,\"start\":33284},{\"end\":33314,\"start\":33296},{\"end\":33328,\"start\":33314},{\"end\":33340,\"start\":33328},{\"end\":33580,\"start\":33560},{\"end\":33596,\"start\":33580},{\"end\":33618,\"start\":33596},{\"end\":33864,\"start\":33850},{\"end\":33877,\"start\":33864},{\"end\":33890,\"start\":33877},{\"end\":33902,\"start\":33890},{\"end\":33911,\"start\":33902},{\"end\":33926,\"start\":33911},{\"end\":33938,\"start\":33926},{\"end\":33949,\"start\":33938},{\"end\":34230,\"start\":34205},{\"end\":34247,\"start\":34230},{\"end\":34268,\"start\":34247},{\"end\":34287,\"start\":34268},{\"end\":34300,\"start\":34287},{\"end\":34321,\"start\":34300},{\"end\":34328,\"start\":34321},{\"end\":34562,\"start\":34552},{\"end\":34575,\"start\":34562},{\"end\":34586,\"start\":34575},{\"end\":34602,\"start\":34586},{\"end\":34613,\"start\":34602},{\"end\":34622,\"start\":34613},{\"end\":34981,\"start\":34966},{\"end\":34994,\"start\":34981},{\"end\":35009,\"start\":34994},{\"end\":35217,\"start\":35202},{\"end\":35241,\"start\":35217},{\"end\":35479,\"start\":35462},{\"end\":35499,\"start\":35479},{\"end\":35710,\"start\":35700},{\"end\":35720,\"start\":35710},{\"end\":35729,\"start\":35720},{\"end\":35917,\"start\":35903},{\"end\":35932,\"start\":35917},{\"end\":35948,\"start\":35932},{\"end\":36237,\"start\":36213},{\"end\":36252,\"start\":36237},{\"end\":36277,\"start\":36252},{\"end\":36298,\"start\":36277},{\"end\":36573,\"start\":36564},{\"end\":36586,\"start\":36573},{\"end\":36599,\"start\":36586},{\"end\":36613,\"start\":36599},{\"end\":36623,\"start\":36613},{\"end\":36631,\"start\":36623},{\"end\":36875,\"start\":36865},{\"end\":36886,\"start\":36875},{\"end\":36902,\"start\":36886},{\"end\":36916,\"start\":36902},{\"end\":37158,\"start\":37146},{\"end\":37174,\"start\":37158},{\"end\":37189,\"start\":37174},{\"end\":37204,\"start\":37189},{\"end\":37448,\"start\":37437},{\"end\":37462,\"start\":37448},{\"end\":37475,\"start\":37462},{\"end\":37488,\"start\":37475},{\"end\":37738,\"start\":37723},{\"end\":37754,\"start\":37738},{\"end\":37764,\"start\":37754},{\"end\":37780,\"start\":37764},{\"end\":37791,\"start\":37780},{\"end\":38061,\"start\":38045},{\"end\":38080,\"start\":38061},{\"end\":38096,\"start\":38080},{\"end\":38334,\"start\":38319},{\"end\":38347,\"start\":38334},{\"end\":38361,\"start\":38347},{\"end\":38569,\"start\":38554},{\"end\":38583,\"start\":38569},{\"end\":38598,\"start\":38583},{\"end\":38835,\"start\":38817},{\"end\":38859,\"start\":38835},{\"end\":38874,\"start\":38859},{\"end\":38891,\"start\":38874},{\"end\":39197,\"start\":39184},{\"end\":39210,\"start\":39197},{\"end\":39219,\"start\":39210},{\"end\":39233,\"start\":39219},{\"end\":39241,\"start\":39233},{\"end\":39259,\"start\":39241},{\"end\":39548,\"start\":39532},{\"end\":39573,\"start\":39548},{\"end\":39594,\"start\":39573},{\"end\":39852,\"start\":39824},{\"end\":39861,\"start\":39852},{\"end\":39871,\"start\":39861},{\"end\":39885,\"start\":39871},{\"end\":39892,\"start\":39885},{\"end\":40170,\"start\":40161},{\"end\":40179,\"start\":40170},{\"end\":40188,\"start\":40179},{\"end\":40202,\"start\":40188},{\"end\":40212,\"start\":40202},{\"end\":40222,\"start\":40212},{\"end\":40234,\"start\":40222},{\"end\":40525,\"start\":40502},{\"end\":40534,\"start\":40525},{\"end\":40539,\"start\":40534},{\"end\":40940,\"start\":40929},{\"end\":40949,\"start\":40940},{\"end\":40963,\"start\":40949},{\"end\":40975,\"start\":40963},{\"end\":40984,\"start\":40975},{\"end\":40997,\"start\":40984},{\"end\":41162,\"start\":41146},{\"end\":41176,\"start\":41162},{\"end\":41189,\"start\":41176},{\"end\":41206,\"start\":41189},{\"end\":41219,\"start\":41206},{\"end\":41234,\"start\":41219},{\"end\":41249,\"start\":41234},{\"end\":41267,\"start\":41249},{\"end\":41548,\"start\":41540},{\"end\":41561,\"start\":41548},{\"end\":41574,\"start\":41561},{\"end\":41586,\"start\":41574},{\"end\":41596,\"start\":41586},{\"end\":41608,\"start\":41596},{\"end\":41860,\"start\":41846},{\"end\":41875,\"start\":41860},{\"end\":41887,\"start\":41875},{\"end\":41897,\"start\":41887},{\"end\":41911,\"start\":41897},{\"end\":41915,\"start\":41911},{\"end\":42275,\"start\":42262},{\"end\":42288,\"start\":42275},{\"end\":42300,\"start\":42288},{\"end\":42319,\"start\":42300},{\"end\":42336,\"start\":42319},{\"end\":42351,\"start\":42336},{\"end\":42597,\"start\":42584},{\"end\":42611,\"start\":42597},{\"end\":42623,\"start\":42611},{\"end\":42640,\"start\":42623},{\"end\":42657,\"start\":42640},{\"end\":42919,\"start\":42908},{\"end\":42934,\"start\":42919},{\"end\":43182,\"start\":43172},{\"end\":43197,\"start\":43182}]", "bib_venue": "[{\"end\":40670,\"start\":40613},{\"end\":33137,\"start\":33062},{\"end\":33622,\"start\":33618},{\"end\":33848,\"start\":33795},{\"end\":34203,\"start\":34135},{\"end\":34725,\"start\":34622},{\"end\":35013,\"start\":35009},{\"end\":35245,\"start\":35241},{\"end\":35517,\"start\":35499},{\"end\":35698,\"start\":35634},{\"end\":35961,\"start\":35948},{\"end\":36302,\"start\":36298},{\"end\":36635,\"start\":36631},{\"end\":36863,\"start\":36782},{\"end\":37210,\"start\":37204},{\"end\":37492,\"start\":37488},{\"end\":37795,\"start\":37791},{\"end\":38100,\"start\":38096},{\"end\":38365,\"start\":38361},{\"end\":38601,\"start\":38598},{\"end\":38815,\"start\":38728},{\"end\":39263,\"start\":39259},{\"end\":39597,\"start\":39594},{\"end\":39895,\"start\":39892},{\"end\":40238,\"start\":40234},{\"end\":40611,\"start\":40539},{\"end\":40927,\"start\":40880},{\"end\":41301,\"start\":41267},{\"end\":41612,\"start\":41608},{\"end\":41960,\"start\":41915},{\"end\":42260,\"start\":42184},{\"end\":42660,\"start\":42657},{\"end\":42938,\"start\":42934},{\"end\":43170,\"start\":43106}]"}}}, "year": 2023, "month": 12, "day": 17}