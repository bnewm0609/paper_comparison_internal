{"id": 237589917, "updated": "2022-02-24 05:07:59.329", "metadata": {"title": "Towards High Generalization Performance on Electrocardiogram Classification", "authors": "[{\"first\":\"Hyeongrok\",\"last\":\"Han\",\"middle\":[]},{\"first\":\"Seongjae\",\"last\":\"Park\",\"middle\":[]},{\"first\":\"Seonwoo\",\"last\":\"Min\",\"middle\":[]},{\"first\":\"Hyun-Soo\",\"last\":\"Choi\",\"middle\":[]},{\"first\":\"Eunji\",\"last\":\"Kim\",\"middle\":[]},{\"first\":\"Hyunki\",\"last\":\"Kim\",\"middle\":[]},{\"first\":\"Sangha\",\"last\":\"Park\",\"middle\":[]},{\"first\":\"Jinkook\",\"last\":\"Kim\",\"middle\":[]},{\"first\":\"Junsang\",\"last\":\"Park\",\"middle\":[]},{\"first\":\"Junho\",\"last\":\"An\",\"middle\":[]},{\"first\":\"Kwanglo\",\"last\":\"Lee\",\"middle\":[]},{\"first\":\"Wonsun\",\"last\":\"Jeong\",\"middle\":[]},{\"first\":\"\",\"last\":\"Sangil\",\"middle\":[]},{\"first\":\"\",\"last\":\"Chon\",\"middle\":[]},{\"first\":\"Kwonwoo\",\"last\":\"Ha\",\"middle\":[]},{\"first\":\"Myungkyu\",\"last\":\"Han\",\"middle\":[]},{\"first\":\"Sungroh\",\"last\":\"Yoon\",\"middle\":[]}]", "venue": "2021 Computing in Cardiology (CinC)", "journal": "2021 Computing in Cardiology (CinC)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Recently, many electrocardiogram (ECG) classification algorithms using deep learning have been proposed. The characteristics of ECG vary from dataset to dataset for various reasons (i.e., hospital, race, etc). Therefore, it is important that models have high dataset-wise generalization performance. In this paper, as part of the PhysioNet / Computing in Cardiology Challenge 2021, we developed a model to classify cardiac abnormalities from 12 lead and reduced-lead ECGs. In particular, to select a model with high generalization performance, we applied constant-weighted cross-entropy loss, and evaluated the performance using a leave-one-dataset-out crossvalidation setting. Our DSAIL SNU team got challenge scores of 0.61, 0.58, 0.60, 0.59, and 0.59 on 12, 6, 4, 3, 2-lead ECGs respectively. Our model obtained higher dataset-wise generalization performance than the model we submitted last year.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cinc/HanPMCKKPKPALJC21", "doi": "10.23919/cinc53138.2021.9662737"}}, "content": {"source": {"pdf_hash": "6e5f42f8b216d8286f178460a05a84159db253a8", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4ba38bd7d94501b55a38f18b3bac6045166c8341", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/6e5f42f8b216d8286f178460a05a84159db253a8.txt", "contents": "\nTowards High Generalization Performance on Electrocardiogram Classification\n\n\nHyeongrok Han \nDepartment of Electrical and Computer engineering\nSeoul National University\nSeoulSouth Korea\n\nSeongjae Park \nHUINNO Co., Ltd,. Seoul\nSouth Korea\n\nSeonwoo Min \nDepartment of Electrical and Computer engineering\nSeoul National University\nSeoulSouth Korea\n\nLG AI Research\nSeoulSouth Korea\n\nHyun-Soo Choi \nDepartment of Computer Science and Engineering\nKangwon National University\nChuncheonSouth Korea\n\nEunji Kim \nDepartment of Electrical and Computer engineering\nSeoul National University\nSeoulSouth Korea\n\nHyunki Kim \nSangha Park \nDepartment of Electrical and Computer engineering\nSeoul National University\nSeoulSouth Korea\n\nJinkook Kim \nHUINNO Co., Ltd,. Seoul\nSouth Korea\n\nJunsang Park \nDepartment of Electrical and Computer engineering\nSeoul National University\nSeoulSouth Korea\n\nHUINNO Co., Ltd,. Seoul\nSouth Korea\n\nJunho An \nKwanglo Lee \nHUINNO Co., Ltd,. Seoul\nSouth Korea\n\nWonsun Jeong \nHUINNO Co., Ltd,. Seoul\nSouth Korea\n\nSangil Chon \nHUINNO Co., Ltd,. Seoul\nSouth Korea\n\nKwonwoo Ha \nHUINNO Co., Ltd,. Seoul\nSouth Korea\n\nMyungkyu Han \nHUINNO Co., Ltd,. Seoul\nSouth Korea\n\nSungroh Yoon \nDepartment of Electrical and Computer engineering\nSeoul National University\nSeoulSouth Korea\n\nHUINNO Co., Ltd,. Seoul\nSouth Korea\n\nDepartment of Biological Sciences\nInterdisciplinary Program in Bioinformatics\nInterdisciplinary Program in Artificial Intelligence\nASRI\nINMC, and Institute of Engineering Research\nSeoul National University\nSeoulSouth Korea\n\nTowards High Generalization Performance on Electrocardiogram Classification\n\nRecently, many electrocardiogram (ECG) classification algorithms using deep learning have been proposed. The characteristics of ECG vary from dataset to dataset for various reasons (i.e., hospital, race, etc). Therefore, it is important that models have high dataset-wise generalization performance. In this paper, as part of the Phys-ioNet / Computing in Cardiology Challenge 2021, we developed a model to classify cardiac abnormalities from 12 lead and reduced-lead ECGs. In particular, to select a model with high generalization performance, we applied constant-weighted cross-entropy loss, and evaluated the performance using a leave-one-dataset-out crossvalidation setting. Our DSAIL SNU team got challenge scores of 0.61, 0.58, 0.60, 0.59, and 0.59 on 12, 6, 4, 3, 2-lead ECGs respectively. Our model obtained higher dataset-wise generalization performance than the model we submitted last year.\n\nIntroduction\n\nElectrocardiogram (ECG) is an important tool for diagnosing cardiac abnormalities, and more than 300 million ECGs are obtained worldwide each year [1]. Standard ECGs, which are used to diagnose heart diseases, consist of 12 leads. However, it is not always possible to obtain all 12 leads due to the cost and limitations of measurement devices. Recently, it has been demonstrated that a subset of \u2020: equal contribution (Hyeongrok Han and Seongjae Park) *: corresponding author (Sungroh Yoon) 12 leads also contains sufficiently meaningful information [2]. According to the rapid growth of deep learning, there have been proposed ECG classification methods based on deep neural networks (DNNs). These approaches can automatically learn feature representations and have shown superior performance to traditional methods using handcrafted features [3,4]. The characteristics of ECG vary from dataset to dataset for various reasons, i.e., hospital, race, etc. It is important to consider that model has generalization performance on dataset which was not seen during training. Therefore, it is necessary to check whether the proposed model shows high dataset-wise performance.\n\nIn this paper, as part of the PhysioNet / Computing in Cardiology Challenge 2021, we developed a model to classify cardiac abnormalities from 12 and reduced-lead ECGs [5][6][7]. In order for the model to have high dataset-wise generalization performance, we applied various methods. In addition, we evaluated the model using the leave-onedataset-out cross-validation for model selection. Our proposed model achieved a 0.1 higher dataset-wise challenge score than the model we submitted last year [4]. Table 1 shows the statistics of the data provided by the challenge with 26 scored SNOMED-CT labels [14] from 8 datasets [7]. Among them, PTB and INCART data are not used for training because of the long lengths and relatively small number of samples. We also do not use those without any positive scored labels for training. When training the Number of w/ Scored Average Dataset recordings Labels Length (second) Ningbo [8] 34,905 34,485 10 PTB-XL [9] 21,837 21,604 10 Chapman [10] 10,247 9,710 10 G12EC [6] 10,344 9,458 9 CPSC [11] 6,877 5,279 15 CPSC-Extra [11] 3,453 1,278 15 PTB [12] 516 97 110 INCART [13] 74 33 1,800 Table 1. Data statistics model, the ratio of train and validation datasets is 9:1. In the leave-one-dataset-out cross-validation setting, one of the six datasets is used as the test dataset, and the remaining five datasets are used to train and validation datasets. We apply the following data pre-processing procedures. First, we upsample or downsample ECGs into 500Hz. Then, we apply a Finite Impulse Response (FIR) bandpass filter with a bandwidth of 3 to 45Hz. Normalization is applied using the minimum and maximum values of each sample. Finally, for any recording with a data length longer than 7,500, we randomly use a segment with a length of 7,500 as input. If the length is shorter than 7,500, we use zero-padding to 7,500. For reduced-lead model training, pre-defined leads are extracted from the 12-lead sample [7].\n\n\nMethods\n\n\nData\n\n\nModel Architecture\n\nFor the baseline model, we use our previous work [4]. We use the WRN model architecture with 14 convolution/dense layers and widening factor 1 [15]. The overall structure of the model is shown in Figure 1. The additional parts from the baseline are depicted in purple. The baseline model consists of the basic residual block, but we use the Squeeze and Excitation (SE) block to let the model learn interdependency between channels [16]. For the model to consider the demographic information, we add the additional features to the dense layer of the output stem.\n\n\nTraining\n\nFirst, we describe the experiment settings. Each model is trained for 100 epochs using Pytorch with an NVIDIA GeForce RTX 3080 [17]. We use Adam optimizer, L2 weight decay of 0.0005, a dropout rate of 0.3, a batch size of 128, and a learning rate of 0.001 through hyperparameter search. In the next part, we explain the training refinements to improve dataset-wise generalization.\n\n\nConstant-weighted binary cross-entropy loss\n\nIn last year, we proposed confusion-weighted binarycross-entropy (CoW-BCE) [4] loss designed to resemble an evaluation metric called challenge score [7]. Although the model trained via CoW-BCE loss showed a high challenge score on the validation dataset, it showed a much lower score on the hidden test dataset.\n\nIn this work, we use constant-weighted binary-cross entropy inspired via asymmetric loss (ASL) [18]. The ASL uses asymmetric focusing and asymmetric probability shifting to overcome the inherent positive-negative imbalance in typical multi-label classification problems as follows:\nASL = \u2212(1 \u2212 p) \u03b3 + log (p), if y is 1 \u2212(p m ) \u03b3 \u2212 log (1 \u2212 p m ), otherwise(1)\nwhere p is the output probability of the model, p m is the shifted probability, and \u03b3 + , \u03b3 \u2212 are positive and negative focusing parameters, respectively. For ease of implementation, we assume the positive focusing parameter \u03b3 + to be 0. We investigate the constant value of the negative coefficient, which depends on the optimal negative focusing parameters \u03b3 \u2212 and shifted probability p m . Experimentally, we set the negative coefficient to be 0.1, which is approximately the ratio of positive to negative classes in the whole dataset.\n\n\nDemographic features\n\nFor the model to learn demographic information, we ad-  Figure 1, the feature vector is concatenated with the feature extracted by DNN before the last dense layer.\n\n\nMixup\n\nMixup is one of the data augmentation techniques for better generalization [19]. It makes the decision boundary smoother by regularizing the model. Assuming that two arbitrary input signals in the batch are x 1 , x 2 , the features of the samples are f 1 , f 2 , and the labels are l 1 , l 2 , the mixup samples x , f , l are created as follows.\nx = \u03bbx 1 + (1 \u2212 \u03bb)x 2\n(2)\nf = \u03bbf 1 + (1 \u2212 \u03bb)f 2 (3) l = \u03bbl 1 + (1 \u2212 \u03bb)l 2(4)\nAs used in the original mixup paper, mixing coefficient \u03bb is sampled from a Beta(0.2, 0.2) distribution. The model is trained using the generated x , f , and l .\n\n\nLearning rate scheduler\n\nWe use the OneCycle learning rate scheduler [20]. It is known as a method for effective training by \"superconvergence\" of residual blocks. At the beginning of training, the learning rate is set to a small value, and it is gradually increased and then decreased again after reaching the pre-defined maximum value. The learning rate values per epoch are shown in Figure 2. The maximum learning rate value is set to 0.001, and the model is trained for a total of 100 epochs using a cosine annealing strategy.  Table 3. Challenge score of the baseline and our model using whole six datasets.\n\n\nExperiments results\n\nThe experiment results of the model trained using the whole six datasets are shown in Table 2. We report the training and validation challenge score, and team ranking for our proposed 12, 6, 4, 3, and 2-lead models. The average validation challenge score was 0.594. In Table 3, we compare the validation challenge scores of the baseline and our 12-lead model. The challenge score obtained by our model is 0.654, which is 0.08 lower than the baseline. Table 4 shows the results of the 12-lead models from the leave-one-dataset-out cross-validation setting. This is an important setting to check the dataset-wise generalization performance. We report the challenge scores when the dataset in the first row is used as a test dataset. Our proposed model show higher dataset-wise generalization performance than the baseline, and the average challenge score is 0.483. Although our model obtain a lower challenge score when trained using the whole six datasets, the dataset-wise generalization performance is better compared to the baseline. The usage of a constant-weighted binary cross-entropy loss instead of CoW-BCE loss function makes the most of the improvement in the dataset-wise generalization performance. In particular, the changed loss function improve the generalization performance for the PTB-XL dataset.\n\n\nConcluding Remarks\n\nIn this paper, as a participating team in the PhysioNet Challenge 2021, we proposed 12 and reduced-lead models for automatically classifying cardiac abnormalities from ECGs. We focused on building the classification model that high dataset-wise generalization performance. We used the SE WRN-14-1 network, constant binary crossentropy loss, feature extraction, mixup, and OneCycle learning rate scheduler.  Table 4. Results of leave-one-dataset-out cross-validation setting (12-lead model)\n\nFor better model selection, we compared the challenge score with the leave-one-dataset-out cross-validation setting in Table 4. The average challenge score of our proposed model was 0.483, confirming that the dataset-wise generalization performance was higher than that of the baseline which was 0.384.\n\nFigure 1 .\n1Model overview.\n\nFigure 2 .\n2OneCycle Learning rate Scheduler. ditionally use two kinds of features, i.e., age and sex. The demographic feature vector consists of 5 values for age, one-hot encoded sex, and two flags for missing values. If there are age and gender values in the header, the values are used directly, and missing flags are set to 0. Otherwise, pre-defined default values are used, and the missing flags are set to 1. The default age value is 60.37, and the default sex value (female/male ratio) is 0.471/0.519. As shown in the purple path in\n\n\nModelNingbo PTB-XL Chapman G12EC CPSC CPSC-ExtraAvg \nBaseline \n0.545 \n-0.101 \n0.659 \n0.428 \n0.463 \n0.310 \n0.384 \nOur model \n0.626 \n0.200 \n0.723 \n0.519 \n0.506 \n0.424 \n0.483 \n\n\n\nA confident decision support system for interpreting electrocardiograms. H Holst, M Ohlsson, C Peterson, L Edenbrandt, Clinical Physiology. 195Holst H, Ohlsson M, Peterson C, Edenbrandt L. A confi- dent decision support system for interpreting electrocardio- grams. Clinical Physiology 1999;19(5):410-418.\n\nComparison of a new reduced lead set ecg with the standard ecg for diagnosing cardiac arrhythmias and myocardial ischemia. B J Drew, M M Pelter, D E Brodnick, A V Yadav, D Dempel, M G Adams, Journal of electrocardiology. 354Drew BJ, Pelter MM, Brodnick DE, Yadav AV, Dempel D, Adams MG. Comparison of a new reduced lead set ecg with the standard ecg for diagnosing cardiac arrhythmias and myocardial ischemia. Journal of electrocardiology 2002; 35(4):13-21.\n\nAn automated ecg beat classification system using convolutional neural networks. M Zubair, J Kim, C Yoon, 2016 6th international conference on IT convergence and security (ICITCS). Zubair M, Kim J, Yoon C. An automated ecg beat classifi- cation system using convolutional neural networks. In 2016 6th international conference on IT convergence and security (ICITCS). IEEE, 2016; 1-5.\n\nBag of tricks for electrocardiogram classification with deep neural networks. S Min, H S Choi, H Han, M Seo, J K Kim, J Park, Computing in Cardiology. IEEE. Min S, Choi HS, Han H, Seo M, Kim JK, Park J, et al. Bag of tricks for electrocardiogram classification with deep neural networks. In 2020 Computing in Cardiology. IEEE, 2020; 1-4.\n\nA L Goldberger, L A Amaral, L Glass, J M Hausdorff, P C Ivanov, R G Mark, PhysioToolkit, and Phys-ioNet: Components of a New Research Resource for Complex Physiologic Signals. 101Goldberger AL, Amaral LA, Glass L, Hausdorff JM, Ivanov PC, Mark RG, et al. PhysioBank, PhysioToolkit, and Phys- ioNet: Components of a New Research Resource for Com- plex Physiologic Signals. Circulation 2000;101(23):e215- e220.\n\nClassification of 12-lead ECGs: the Phys-ioNet/Computing in Cardiology Challenge 2020. E A Perez Alday, A Gu, A Shah, C Robichaux, Aki Wong, C Liu, Physiological Measurement. 41Perez Alday EA, Gu A, Shah A, Robichaux C, Wong AKI, Liu C, et al. Classification of 12-lead ECGs: the Phys- ioNet/Computing in Cardiology Challenge 2020. Physio- logical Measurement 2020;41.\n\nWill Two Do? Varying Dimensions in Electrocardiography: the PhysioNet/Computing in Cardiology Challenge 2021. M A Reyna, N Sadr, E A Perez Alday, A Gu, A Shah, C Robichaux, Computing in Cardiology. 48Reyna MA, Sadr N, Perez Alday EA, Gu A, Shah A, Ro- bichaux C, et al. Will Two Do? Varying Dimensions in Electrocardiography: the PhysioNet/Computing in Cardiol- ogy Challenge 2021. Computing in Cardiology 2021;48:1- 4.\n\n. J Zheng, H Cui, D Struppa, J Zhang, S M Yacoub, H El-Askary, Optimal Multi-Stage Arrhythmia Classification Approach. Scientific Data. 10Zheng J, Cui H, Struppa D, Zhang J, Yacoub SM, El-Askary H, et al. Optimal Multi-Stage Arrhythmia Classification Approach. Scientific Data 2020;10(2898):1-17.\n\n. P Wagner, N Strodthoff, R D Bousseljot, D Kreiseler, F I Lunze, W Samek, Large Publicly Available Electrocardiography Dataset. Scientific Data. 71Wagner P, Strodthoff N, Bousseljot RD, Kreiseler D, Lunze FI, Samek W, et al. PTB-XL, a Large Publicly Available Electrocardiography Dataset. Scientific Data 2020;7(1):1- 15.\n\nA 12-lead Electrocardiogram Database for Arrhythmia Research Covering More Than 10,000 Patients. J Zheng, J Zhang, S Danioko, H Yao, H Guo, C Rakovski, Scientific Data. 748Zheng J, Zhang J, Danioko S, Yao H, Guo H, Rakovski C. A 12-lead Electrocardiogram Database for Arrhythmia Re- search Covering More Than 10,000 Patients. Scientific Data 2020;7(48):1-8.\n\nAn Open Access Database for Evaluating the Algorithms of Electrocardiogram Rhythm and Morphology Abnormality Detection. F Liu, C Liu, L Zhao, X Zhang, X Wu, X Xu, Journal of Medical Imaging and Health Informatics. 87Liu F, Liu C, Zhao L, Zhang X, Wu X, Xu X, et al. An Open Access Database for Evaluating the Algorithms of Electro- cardiogram Rhythm and Morphology Abnormality Detec- tion. Journal of Medical Imaging and Health Informatics 2018;8(7):1368--1373.\n\nNutzung der EKG-Signaldatenbank CARDIODAT der PTB\u00fcber das Internet. R Bousseljot, D Kreiseler, A Schnabel, Biomedizinische Technik. 40S1Bousseljot R, Kreiseler D, Schnabel A. Nutzung der EKG- Signaldatenbank CARDIODAT der PTB\u00fcber das Internet. Biomedizinische Technik 1995;40(S1):317-318.\n\nSt Petersburg INCART 12-lead Arrhythmia Database. V Tihonenko, A Khaustov, S Ivanov, A Rivin, E Yakushenko, file:/localhost/opt/grobid/grobid-home/tmp/10.13026/C2V88NDoi: 10.1 3026/C2V88NPhysioBank PhysioToolkit and PhysioNet. Tihonenko V, Khaustov A, Ivanov S, Rivin A, Yakushenko E. St Petersburg INCART 12-lead Arrhythmia Database. PhysioBank PhysioToolkit and PhysioNet 2008;Doi: 10.1 3026/C2V88N.\n\nSystematized nomenclature of medicine-clinical terms direction and its implications on critical care. R Shahpori, C Doig, Journal of critical care. 252Shahpori R, Doig C. Systematized nomenclature of medicine-clinical terms direction and its implications on critical care. Journal of critical care 2010;25(2):364-e1.\n\nWide residual networks. S Zagoruyko, N Komodakis, arXiv preprint arXiv160507146Zagoruyko S, Komodakis N. Wide residual networks. arXiv preprint arXiv160507146 2016;.\n\nSqueeze-and-excitation networks. J Hu, L Shen, G Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionHu J, Shen L, Sun G. Squeeze-and-excitation networks. In Proceedings of the IEEE conference on computer vision and pattern recognition. 2018; 7132-7141.\n\nAutomatic differentiation in PyTorch. A Paszke, S Gross, S Chintala, NIPS Autodiff Workshop. Paszke A, Gross S, Chintala S, et al. Automatic differentia- tion in PyTorch. NIPS Autodiff Workshop 2017;.\n\nAsymmetric loss for multi-label classification. E Ben-Baruch, T Ridnik, N Zamir, A Noy, I Friedman, M Protter, Ben-Baruch E, Ridnik T, Zamir N, Noy A, Friedman I, Prot- ter M, et al. Asymmetric loss for multi-label classification, 2020.\n\nH Zhang, M Cisse, Y N Dauphin, D Lopez-Paz, mixup: Beyond empirical risk minimization. arXiv preprint arXiv171009412. Zhang H, Cisse M, Dauphin YN, Lopez-Paz D. mixup: Beyond empirical risk minimization. arXiv preprint arXiv171009412 2017;.\n\nSuper-convergence: Very fast training of neural networks using large learning rates. L N Smith, N Topin, Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications. 110061100612Smith LN, Topin N. Super-convergence: Very fast training of neural networks using large learning rates. In Artificial Intelligence and Machine Learning for Multi-Domain Op- erations Applications, volume 11006. International Society for Optics and Photonics, 2019; 1100612.\n", "annotations": {"author": "[{\"end\":187,\"start\":79},{\"end\":239,\"start\":188},{\"end\":379,\"start\":240},{\"end\":491,\"start\":380},{\"end\":596,\"start\":492},{\"end\":608,\"start\":597},{\"end\":715,\"start\":609},{\"end\":765,\"start\":716},{\"end\":910,\"start\":766},{\"end\":920,\"start\":911},{\"end\":970,\"start\":921},{\"end\":1021,\"start\":971},{\"end\":1071,\"start\":1022},{\"end\":1120,\"start\":1072},{\"end\":1171,\"start\":1121},{\"end\":1540,\"start\":1172}]", "publisher": null, "author_last_name": "[{\"end\":92,\"start\":89},{\"end\":201,\"start\":197},{\"end\":251,\"start\":248},{\"end\":393,\"start\":389},{\"end\":501,\"start\":498},{\"end\":607,\"start\":604},{\"end\":620,\"start\":616},{\"end\":727,\"start\":724},{\"end\":778,\"start\":774},{\"end\":919,\"start\":917},{\"end\":932,\"start\":929},{\"end\":983,\"start\":978},{\"end\":1033,\"start\":1029},{\"end\":1082,\"start\":1080},{\"end\":1133,\"start\":1130},{\"end\":1184,\"start\":1180}]", "author_first_name": "[{\"end\":88,\"start\":79},{\"end\":196,\"start\":188},{\"end\":247,\"start\":240},{\"end\":388,\"start\":380},{\"end\":497,\"start\":492},{\"end\":603,\"start\":597},{\"end\":615,\"start\":609},{\"end\":723,\"start\":716},{\"end\":773,\"start\":766},{\"end\":916,\"start\":911},{\"end\":928,\"start\":921},{\"end\":977,\"start\":971},{\"end\":1028,\"start\":1022},{\"end\":1079,\"start\":1072},{\"end\":1129,\"start\":1121},{\"end\":1179,\"start\":1172}]", "author_affiliation": "[{\"end\":186,\"start\":94},{\"end\":238,\"start\":203},{\"end\":345,\"start\":253},{\"end\":378,\"start\":347},{\"end\":490,\"start\":395},{\"end\":595,\"start\":503},{\"end\":714,\"start\":622},{\"end\":764,\"start\":729},{\"end\":872,\"start\":780},{\"end\":909,\"start\":874},{\"end\":969,\"start\":934},{\"end\":1020,\"start\":985},{\"end\":1070,\"start\":1035},{\"end\":1119,\"start\":1084},{\"end\":1170,\"start\":1135},{\"end\":1278,\"start\":1186},{\"end\":1315,\"start\":1280},{\"end\":1539,\"start\":1317}]", "title": "[{\"end\":76,\"start\":1},{\"end\":1616,\"start\":1541}]", "venue": null, "abstract": "[{\"end\":2519,\"start\":1618}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2685,\"start\":2682},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3029,\"start\":3027},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3089,\"start\":3086},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3383,\"start\":3380},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3385,\"start\":3383},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3879,\"start\":3876},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3882,\"start\":3879},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3885,\"start\":3882},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4208,\"start\":4205},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4313,\"start\":4309},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4333,\"start\":4330},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4633,\"start\":4630},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4661,\"start\":4658},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4691,\"start\":4687},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4717,\"start\":4714},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4742,\"start\":4738},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4773,\"start\":4769},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4797,\"start\":4793},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4820,\"start\":4816},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5659,\"start\":5656},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5752,\"start\":5749},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5847,\"start\":5843},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6135,\"start\":6131},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6405,\"start\":6401},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6780,\"start\":6777},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6854,\"start\":6851},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7114,\"start\":7110},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8191,\"start\":8187},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8772,\"start\":8768}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":11493,\"start\":11465},{\"attributes\":{\"id\":\"fig_1\"},\"end\":12034,\"start\":11494},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":12211,\"start\":12035}]", "paragraph": "[{\"end\":3707,\"start\":2535},{\"end\":5660,\"start\":3709},{\"end\":6261,\"start\":5700},{\"end\":6654,\"start\":6274},{\"end\":7013,\"start\":6702},{\"end\":7296,\"start\":7015},{\"end\":7914,\"start\":7376},{\"end\":8102,\"start\":7939},{\"end\":8457,\"start\":8112},{\"end\":8483,\"start\":8480},{\"end\":8696,\"start\":8535},{\"end\":9311,\"start\":8724},{\"end\":10648,\"start\":9335},{\"end\":11160,\"start\":10671},{\"end\":11464,\"start\":11162}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7375,\"start\":7297},{\"attributes\":{\"id\":\"formula_1\"},\"end\":8479,\"start\":8458},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8534,\"start\":8484}]", "table_ref": "[{\"end\":4217,\"start\":4210},{\"end\":4840,\"start\":4833},{\"end\":9238,\"start\":9231},{\"end\":9428,\"start\":9421},{\"end\":9611,\"start\":9604},{\"end\":9793,\"start\":9786},{\"end\":11085,\"start\":11078},{\"end\":11288,\"start\":11281}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2533,\"start\":2521},{\"attributes\":{\"n\":\"2.\"},\"end\":5670,\"start\":5663},{\"attributes\":{\"n\":\"2.1.\"},\"end\":5677,\"start\":5673},{\"attributes\":{\"n\":\"2.2.\"},\"end\":5698,\"start\":5680},{\"attributes\":{\"n\":\"2.3.\"},\"end\":6272,\"start\":6264},{\"end\":6700,\"start\":6657},{\"end\":7937,\"start\":7917},{\"end\":8110,\"start\":8105},{\"end\":8722,\"start\":8699},{\"attributes\":{\"n\":\"3.\"},\"end\":9333,\"start\":9314},{\"attributes\":{\"n\":\"4.\"},\"end\":10669,\"start\":10651},{\"end\":11476,\"start\":11466},{\"end\":11505,\"start\":11495}]", "table": "[{\"end\":12211,\"start\":12085}]", "figure_caption": "[{\"end\":11493,\"start\":11478},{\"end\":12034,\"start\":11507},{\"end\":12085,\"start\":12037}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5904,\"start\":5896},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8003,\"start\":7995},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9093,\"start\":9085}]", "bib_author_first_name": "[{\"end\":12287,\"start\":12286},{\"end\":12296,\"start\":12295},{\"end\":12307,\"start\":12306},{\"end\":12319,\"start\":12318},{\"end\":12644,\"start\":12643},{\"end\":12646,\"start\":12645},{\"end\":12654,\"start\":12653},{\"end\":12656,\"start\":12655},{\"end\":12666,\"start\":12665},{\"end\":12668,\"start\":12667},{\"end\":12680,\"start\":12679},{\"end\":12682,\"start\":12681},{\"end\":12691,\"start\":12690},{\"end\":12701,\"start\":12700},{\"end\":12703,\"start\":12702},{\"end\":13061,\"start\":13060},{\"end\":13071,\"start\":13070},{\"end\":13078,\"start\":13077},{\"end\":13443,\"start\":13442},{\"end\":13450,\"start\":13449},{\"end\":13452,\"start\":13451},{\"end\":13460,\"start\":13459},{\"end\":13467,\"start\":13466},{\"end\":13474,\"start\":13473},{\"end\":13476,\"start\":13475},{\"end\":13483,\"start\":13482},{\"end\":13704,\"start\":13703},{\"end\":13706,\"start\":13705},{\"end\":13720,\"start\":13719},{\"end\":13722,\"start\":13721},{\"end\":13732,\"start\":13731},{\"end\":13741,\"start\":13740},{\"end\":13743,\"start\":13742},{\"end\":13756,\"start\":13755},{\"end\":13758,\"start\":13757},{\"end\":13768,\"start\":13767},{\"end\":13770,\"start\":13769},{\"end\":14201,\"start\":14200},{\"end\":14203,\"start\":14202},{\"end\":14218,\"start\":14217},{\"end\":14224,\"start\":14223},{\"end\":14232,\"start\":14231},{\"end\":14247,\"start\":14244},{\"end\":14255,\"start\":14254},{\"end\":14594,\"start\":14593},{\"end\":14596,\"start\":14595},{\"end\":14605,\"start\":14604},{\"end\":14613,\"start\":14612},{\"end\":14615,\"start\":14614},{\"end\":14630,\"start\":14629},{\"end\":14636,\"start\":14635},{\"end\":14644,\"start\":14643},{\"end\":14907,\"start\":14906},{\"end\":14916,\"start\":14915},{\"end\":14923,\"start\":14922},{\"end\":14934,\"start\":14933},{\"end\":14943,\"start\":14942},{\"end\":14945,\"start\":14944},{\"end\":14955,\"start\":14954},{\"end\":15205,\"start\":15204},{\"end\":15215,\"start\":15214},{\"end\":15229,\"start\":15228},{\"end\":15231,\"start\":15230},{\"end\":15245,\"start\":15244},{\"end\":15258,\"start\":15257},{\"end\":15260,\"start\":15259},{\"end\":15269,\"start\":15268},{\"end\":15624,\"start\":15623},{\"end\":15633,\"start\":15632},{\"end\":15642,\"start\":15641},{\"end\":15653,\"start\":15652},{\"end\":15660,\"start\":15659},{\"end\":15667,\"start\":15666},{\"end\":16006,\"start\":16005},{\"end\":16013,\"start\":16012},{\"end\":16020,\"start\":16019},{\"end\":16028,\"start\":16027},{\"end\":16037,\"start\":16036},{\"end\":16043,\"start\":16042},{\"end\":16417,\"start\":16416},{\"end\":16431,\"start\":16430},{\"end\":16444,\"start\":16443},{\"end\":16689,\"start\":16688},{\"end\":16702,\"start\":16701},{\"end\":16714,\"start\":16713},{\"end\":16724,\"start\":16723},{\"end\":16733,\"start\":16732},{\"end\":17144,\"start\":17143},{\"end\":17156,\"start\":17155},{\"end\":17384,\"start\":17383},{\"end\":17397,\"start\":17396},{\"end\":17560,\"start\":17559},{\"end\":17566,\"start\":17565},{\"end\":17574,\"start\":17573},{\"end\":17914,\"start\":17913},{\"end\":17924,\"start\":17923},{\"end\":17933,\"start\":17932},{\"end\":18126,\"start\":18125},{\"end\":18140,\"start\":18139},{\"end\":18150,\"start\":18149},{\"end\":18159,\"start\":18158},{\"end\":18166,\"start\":18165},{\"end\":18178,\"start\":18177},{\"end\":18316,\"start\":18315},{\"end\":18325,\"start\":18324},{\"end\":18334,\"start\":18333},{\"end\":18336,\"start\":18335},{\"end\":18347,\"start\":18346},{\"end\":18643,\"start\":18642},{\"end\":18645,\"start\":18644},{\"end\":18654,\"start\":18653}]", "bib_author_last_name": "[{\"end\":12293,\"start\":12288},{\"end\":12304,\"start\":12297},{\"end\":12316,\"start\":12308},{\"end\":12330,\"start\":12320},{\"end\":12651,\"start\":12647},{\"end\":12663,\"start\":12657},{\"end\":12677,\"start\":12669},{\"end\":12688,\"start\":12683},{\"end\":12698,\"start\":12692},{\"end\":12709,\"start\":12704},{\"end\":13068,\"start\":13062},{\"end\":13075,\"start\":13072},{\"end\":13083,\"start\":13079},{\"end\":13447,\"start\":13444},{\"end\":13457,\"start\":13453},{\"end\":13464,\"start\":13461},{\"end\":13471,\"start\":13468},{\"end\":13480,\"start\":13477},{\"end\":13488,\"start\":13484},{\"end\":13717,\"start\":13707},{\"end\":13729,\"start\":13723},{\"end\":13738,\"start\":13733},{\"end\":13753,\"start\":13744},{\"end\":13765,\"start\":13759},{\"end\":13775,\"start\":13771},{\"end\":14215,\"start\":14204},{\"end\":14221,\"start\":14219},{\"end\":14229,\"start\":14225},{\"end\":14242,\"start\":14233},{\"end\":14252,\"start\":14248},{\"end\":14259,\"start\":14256},{\"end\":14602,\"start\":14597},{\"end\":14610,\"start\":14606},{\"end\":14627,\"start\":14616},{\"end\":14633,\"start\":14631},{\"end\":14641,\"start\":14637},{\"end\":14654,\"start\":14645},{\"end\":14913,\"start\":14908},{\"end\":14920,\"start\":14917},{\"end\":14931,\"start\":14924},{\"end\":14940,\"start\":14935},{\"end\":14952,\"start\":14946},{\"end\":14965,\"start\":14956},{\"end\":15212,\"start\":15206},{\"end\":15226,\"start\":15216},{\"end\":15242,\"start\":15232},{\"end\":15255,\"start\":15246},{\"end\":15266,\"start\":15261},{\"end\":15275,\"start\":15270},{\"end\":15630,\"start\":15625},{\"end\":15639,\"start\":15634},{\"end\":15650,\"start\":15643},{\"end\":15657,\"start\":15654},{\"end\":15664,\"start\":15661},{\"end\":15676,\"start\":15668},{\"end\":16010,\"start\":16007},{\"end\":16017,\"start\":16014},{\"end\":16025,\"start\":16021},{\"end\":16034,\"start\":16029},{\"end\":16040,\"start\":16038},{\"end\":16046,\"start\":16044},{\"end\":16428,\"start\":16418},{\"end\":16441,\"start\":16432},{\"end\":16453,\"start\":16445},{\"end\":16699,\"start\":16690},{\"end\":16711,\"start\":16703},{\"end\":16721,\"start\":16715},{\"end\":16730,\"start\":16725},{\"end\":16744,\"start\":16734},{\"end\":17153,\"start\":17145},{\"end\":17161,\"start\":17157},{\"end\":17394,\"start\":17385},{\"end\":17407,\"start\":17398},{\"end\":17563,\"start\":17561},{\"end\":17571,\"start\":17567},{\"end\":17578,\"start\":17575},{\"end\":17921,\"start\":17915},{\"end\":17930,\"start\":17925},{\"end\":17942,\"start\":17934},{\"end\":18137,\"start\":18127},{\"end\":18147,\"start\":18141},{\"end\":18156,\"start\":18151},{\"end\":18163,\"start\":18160},{\"end\":18175,\"start\":18167},{\"end\":18186,\"start\":18179},{\"end\":18322,\"start\":18317},{\"end\":18331,\"start\":18326},{\"end\":18344,\"start\":18337},{\"end\":18357,\"start\":18348},{\"end\":18651,\"start\":18646},{\"end\":18660,\"start\":18655}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":16095200},\"end\":12518,\"start\":12213},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":22297170},\"end\":12977,\"start\":12520},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":10054302},\"end\":13362,\"start\":12979},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":227956224},\"end\":13701,\"start\":13364},{\"attributes\":{\"id\":\"b4\"},\"end\":14111,\"start\":13703},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":231915966},\"end\":14481,\"start\":14113},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":237624113},\"end\":14902,\"start\":14483},{\"attributes\":{\"id\":\"b7\"},\"end\":15200,\"start\":14904},{\"attributes\":{\"id\":\"b8\"},\"end\":15524,\"start\":15202},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":211080866},\"end\":15883,\"start\":15526},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":70024401},\"end\":16346,\"start\":15885},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":111121953},\"end\":16636,\"start\":16348},{\"attributes\":{\"doi\":\"file:/localhost/opt/grobid/grobid-home/tmp/10.13026/C2V88N\",\"id\":\"b12\"},\"end\":17039,\"start\":16638},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":24996581},\"end\":17357,\"start\":17041},{\"attributes\":{\"id\":\"b14\"},\"end\":17524,\"start\":17359},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":140309863},\"end\":17873,\"start\":17526},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":40027675},\"end\":18075,\"start\":17875},{\"attributes\":{\"id\":\"b17\"},\"end\":18313,\"start\":18077},{\"attributes\":{\"id\":\"b18\"},\"end\":18555,\"start\":18315},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":23376859},\"end\":19033,\"start\":18557}]", "bib_title": "[{\"end\":12284,\"start\":12213},{\"end\":12641,\"start\":12520},{\"end\":13058,\"start\":12979},{\"end\":13440,\"start\":13364},{\"end\":14198,\"start\":14113},{\"end\":14591,\"start\":14483},{\"end\":15621,\"start\":15526},{\"end\":16003,\"start\":15885},{\"end\":16414,\"start\":16348},{\"end\":16686,\"start\":16638},{\"end\":17141,\"start\":17041},{\"end\":17557,\"start\":17526},{\"end\":17911,\"start\":17875},{\"end\":18640,\"start\":18557}]", "bib_author": "[{\"end\":12295,\"start\":12286},{\"end\":12306,\"start\":12295},{\"end\":12318,\"start\":12306},{\"end\":12332,\"start\":12318},{\"end\":12653,\"start\":12643},{\"end\":12665,\"start\":12653},{\"end\":12679,\"start\":12665},{\"end\":12690,\"start\":12679},{\"end\":12700,\"start\":12690},{\"end\":12711,\"start\":12700},{\"end\":13070,\"start\":13060},{\"end\":13077,\"start\":13070},{\"end\":13085,\"start\":13077},{\"end\":13449,\"start\":13442},{\"end\":13459,\"start\":13449},{\"end\":13466,\"start\":13459},{\"end\":13473,\"start\":13466},{\"end\":13482,\"start\":13473},{\"end\":13490,\"start\":13482},{\"end\":13719,\"start\":13703},{\"end\":13731,\"start\":13719},{\"end\":13740,\"start\":13731},{\"end\":13755,\"start\":13740},{\"end\":13767,\"start\":13755},{\"end\":13777,\"start\":13767},{\"end\":14217,\"start\":14200},{\"end\":14223,\"start\":14217},{\"end\":14231,\"start\":14223},{\"end\":14244,\"start\":14231},{\"end\":14254,\"start\":14244},{\"end\":14261,\"start\":14254},{\"end\":14604,\"start\":14593},{\"end\":14612,\"start\":14604},{\"end\":14629,\"start\":14612},{\"end\":14635,\"start\":14629},{\"end\":14643,\"start\":14635},{\"end\":14656,\"start\":14643},{\"end\":14915,\"start\":14906},{\"end\":14922,\"start\":14915},{\"end\":14933,\"start\":14922},{\"end\":14942,\"start\":14933},{\"end\":14954,\"start\":14942},{\"end\":14967,\"start\":14954},{\"end\":15214,\"start\":15204},{\"end\":15228,\"start\":15214},{\"end\":15244,\"start\":15228},{\"end\":15257,\"start\":15244},{\"end\":15268,\"start\":15257},{\"end\":15277,\"start\":15268},{\"end\":15632,\"start\":15623},{\"end\":15641,\"start\":15632},{\"end\":15652,\"start\":15641},{\"end\":15659,\"start\":15652},{\"end\":15666,\"start\":15659},{\"end\":15678,\"start\":15666},{\"end\":16012,\"start\":16005},{\"end\":16019,\"start\":16012},{\"end\":16027,\"start\":16019},{\"end\":16036,\"start\":16027},{\"end\":16042,\"start\":16036},{\"end\":16048,\"start\":16042},{\"end\":16430,\"start\":16416},{\"end\":16443,\"start\":16430},{\"end\":16455,\"start\":16443},{\"end\":16701,\"start\":16688},{\"end\":16713,\"start\":16701},{\"end\":16723,\"start\":16713},{\"end\":16732,\"start\":16723},{\"end\":16746,\"start\":16732},{\"end\":17155,\"start\":17143},{\"end\":17163,\"start\":17155},{\"end\":17396,\"start\":17383},{\"end\":17409,\"start\":17396},{\"end\":17565,\"start\":17559},{\"end\":17573,\"start\":17565},{\"end\":17580,\"start\":17573},{\"end\":17923,\"start\":17913},{\"end\":17932,\"start\":17923},{\"end\":17944,\"start\":17932},{\"end\":18139,\"start\":18125},{\"end\":18149,\"start\":18139},{\"end\":18158,\"start\":18149},{\"end\":18165,\"start\":18158},{\"end\":18177,\"start\":18165},{\"end\":18188,\"start\":18177},{\"end\":18324,\"start\":18315},{\"end\":18333,\"start\":18324},{\"end\":18346,\"start\":18333},{\"end\":18359,\"start\":18346},{\"end\":18653,\"start\":18642},{\"end\":18662,\"start\":18653}]", "bib_venue": "[{\"end\":12351,\"start\":12332},{\"end\":12739,\"start\":12711},{\"end\":13158,\"start\":13085},{\"end\":13519,\"start\":13490},{\"end\":13877,\"start\":13777},{\"end\":14286,\"start\":14261},{\"end\":14679,\"start\":14656},{\"end\":15038,\"start\":14967},{\"end\":15346,\"start\":15277},{\"end\":15693,\"start\":15678},{\"end\":16097,\"start\":16048},{\"end\":16478,\"start\":16455},{\"end\":16863,\"start\":16825},{\"end\":17187,\"start\":17163},{\"end\":17381,\"start\":17359},{\"end\":17657,\"start\":17580},{\"end\":17966,\"start\":17944},{\"end\":18123,\"start\":18077},{\"end\":18431,\"start\":18359},{\"end\":18747,\"start\":18662},{\"end\":17721,\"start\":17659}]"}}}, "year": 2023, "month": 12, "day": 17}