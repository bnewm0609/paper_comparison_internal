{"id": 250462711, "updated": "2023-01-04 14:19:59.676", "metadata": {"title": "Flexible Job-Shop Scheduling via Graph Neural Network and Deep Reinforcement Learning", "authors": "[{\"first\":\"Wen\",\"last\":\"Song\",\"middle\":[]},{\"first\":\"Xinyang\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Qiqiang\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Zhiguang\",\"last\":\"Cao\",\"middle\":[]}]", "venue": "IEEE Transactions on Industrial Informatics", "journal": "IEEE Transactions on Industrial Informatics", "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Recently, deep reinforcement learning (DRL) has been applied to learn priority dispatching rules (PDRs) for solving complex scheduling problems. However, the existing works face challenges in dealing with flexibility, which allows an operation to be scheduled on one out of multiple machines and is often required in practice. Such one-to-many relationship brings additional complexity in both decision making and state representation. This article considers the well-known flexible job-shop scheduling problem and addresses these issues by proposing a novel DRL method to learn high-quality PDRs end to end. The operation selection and the machine assignment are combined as a composite decision. Moreover, based on a novel heterogeneous graph representation of scheduling states, a heterogeneous-graph-neural-network-based architecture is proposed to capture complex relationships among operations and machines. Experiments show that the proposed method outperforms traditional PDRs and is computationally efficient, even on instances of larger scales and different properties unseen in training.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tii/SongCLC23", "doi": "10.1109/tii.2022.3189725"}}, "content": {"source": {"pdf_hash": "aa5fb1ead01c83773a7cd6e20d581578f0c413d6", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "381e75adef4ba79958046770b95d860dd157188f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/aa5fb1ead01c83773a7cd6e20d581578f0c413d6.txt", "contents": "\nFlexible Job-Shop Scheduling via Graph Neural Network and Deep Reinforcement Learning\nFEBRUARY 2023\n\nWen Song \nXinyang Chen \nQiqiang Li \nZhiguang Cao \nFlexible Job-Shop Scheduling via Graph Neural Network and Deep Reinforcement Learning\n\nIEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS\n192FEBRUARY 202310.1109/TII.2022.31897251600\nRecently, deep reinforcement learning (DRL) has been applied to learn priority dispatching rules (PDRs) for solving complex scheduling problems. However, the existing works face challenges in dealing with flexibility, which allows an operation to be scheduled on one out of multiple machines and is often required in practice. Such one-to-many relationship brings additional complexity in both decision making and state representation. This article considers the well-known flexible job-shop scheduling problem and addresses these issues by proposing a novel DRL method to learn high-quality PDRs end to end. The operation selection and the machine assignment are combined as a composite decision. Moreover, based on a novel heterogeneous graph representation of scheduling states, a heterogeneous-graph-neural-network-based architecture is proposed to capture complex relationships among operations and machines. Experiments show that the proposed method outperforms traditional PDRs and is computationally efficient, even on instances of larger scales and different properties unseen in training.Index Terms-Deep reinforcement learning (DRL), flexible job-shop scheduling, graph neural network (GNN).1551-3203\n\nI. INTRODUCTION\n\nC LOUD manufacturing, as an emerging paradigm of nextgeneration manufacturing systems in the age of Industry 4.0, has received much attention in the past decade [1]. It virtualizes and integrates distributed manufacturing resources into a common cloud platform, so as to provide flexible, high-quality, and on-demand manufacturing services, supported by advanced technologies, such as cyber-physical systems, logistic Internet of Things [2], and artificial intelligence (AI). To unleash its full potential, effective resource scheduling is a critical factor for cloud manufacturing systems [3]. Its main task is to schedule the manufacturing demands (jobs) onto the manufacturing resources (machines), so as to achieve the optimal system performance. However, different from traditional production, resource scheduling for cloud manufacturing is much more complicated. Its cloudbased open environment makes manufacturing scheduling much more diverse, flexible, and dynamic. Moreover, the scale of the scheduling problem required to be solved is often large due to the large volume of involved demands and resources. Therefore, scheduling algorithms and systems for cloud manufacturing should be fast and adaptive in responding to the scheduling requests and must be able to cope with manufacturing flexibility and large-scale problems, which is challenging to design and develop. This article focuses on the flexible job-shop scheduling problem (FJSP), a well-known generalization of the job-shop scheduling problem (JSP) with wide applications in cloud manufacturing [4], [5]. Different from the JSP, the FJSP allows operations to be processed on any machine from a set of alternative ones and, hence, is more suitable in handling the flexibility and diversity of the task-resource relations in new manufacturing paradigms, such as cloud manufacturing [6]. Owing to its important application value, the FJSP receives much attention in the literature [6], [7].\n\nThe FJSP is well known to be NP-hard since it is harder than the JSP, which is already strongly NP-hard, due to the requirement of machine assignment decisions [6]- [8]. Therefore, exact methods, such as mathematical programming and constraint programming, often suffer from prohibitively long computational time, especially in solving large-sized problems. In practice, heuristics methods are often employed, which sacrifice optimality for efficiency. A priority dispatching rule (PDR) is a well-known and practical heuristic scheduling method. It solves the scheduling problem in a constructive fashion, which iteratively dispatches jobs to machines based on some priority rules [e.g., first in first out (FIFO)] [9]. Metaheuristics, such as evolutionary algorithms, form another popular paradigm of heuristics, which have also received much attention. They employ complicated search procedures to explore the solution space to find high-quality solutions [6]. Compared to metaheuristics, PDRs are intuitive, easy to implementation, and very fast in computation, making it more preferable in dealing with problems in cloud manufacturing, which are often large scale and even dynamic [10]. While PDRs have been widely applied in practice, their scheduling quality is still quite far from optimality. This could result from the following reasons. First, the construction process is greedy based on the priority measure, which could be myopic. Second, the decisions are based mostly on information from the eligible jobs and machines at each step, while the global information is largely ignored. Finally, current PDRs are mainly designed based on human experience, which usually have no guarantee on the optimality and lack the ability of adapting to specific problems and situations. In the age of Industry 4.0, however, the development of new technologies provides new impetus to overcome these limitations. In particular, large amounts of historical/simulation data about the frequently solved scheduling problem are much easier to obtain, from which advanced AI algorithms, such as deep reinforcement learning (DRL), can be utilized to discover better patterns for solving the scheduling problem (conceptual architecture is shown in Fig. 1). In this direction, a number of recent works attempt to automatically generate PDRs for scheduling problems using DRL in an end-toend fashion [11]- [16]. By viewing the decision making of PDRs as a Markov decision process (MDP), they train scheduling policies that take the future into account, so as to alleviate the myopic nature of PDRs. They employ deep neural networks to capture the global scheduling status instead of only local information. Furthermore, the reinforcement training process is guided by the cumulative reward toward the direction of optimizing performance, which is fully automatic without the need of human intervention [17].\n\nDespite the promising results, most of the existing DRL methods only focus on nonflexible problems, such as the JSP. The existence of flexibility imposes two major challenges on the design of effective learning mechanism. First, decisions in the FJSP are more complicated with not only operation selection but also machine assignment. Second, the scheduling status could be much harder to encode using the neural network due to the complex one-to-many relationships between operations and machines. Consequently, a more complex decision-making framework and more informative representation techniques are necessary. The key research questions are: 1) how to formulate the scheduling process so as to incorporate the machine assignment and 2) how to design the representation scheme and the neural architecture to extract useful information from raw scheduling states.\n\nTo address the above challenges, this article proposes a novel end-to-end DRL method to learn high-quality PDRs for solving the FJSP. For research question 1), this article proposes an MDP formulation for PDR-based FJSP scheduling, where an action is to select an eligible operation-machine (O-M) pair, such that both the operation selection and machine assignment decisions can be made at the same time. For research question 2), by extending the disjunctive graph of the FJSP with machine nodes, this article proposes a novel heterogeneous graph structure to represent the MDP states, such that the complicated relationships among operations and machines can be captured. Moreover, a two-stage graph neural network (GNN) is proposed to obtain the feature embeddings of the nodes in the heterogeneous graph, based on which a policy network is designed and trained using proximal policy optimization (PPO). Different from the GNNs used in the existing DRL-based scheduling methods (see, e.g., [13], [14], and [18]), the GNN proposed in this article works on heterogeneous graphs specialized for the FJSP, which captures the status for not only operations but also machines and O-M relationships. Extensive experiments are conducted on synthetic instances and public benchmarks. Results show that while maintaining high computational efficiency, the proposed method can outperform traditional handcrafted PDRs and effectively generalize to larger sized problems and public benchmarks unseen in training.\n\nBesides the methodological novelty, the proposed method also has good practical value. Its neural architecture is size agnostic; hence, the trained policy can be applied to solve the instances of varying sizes, not only the training size. More importantly, the trained policy can rapidly solve large-scale FJSP instances and deliver reasonably good schedules better than traditional PDRs, making it a good choice for the management staff to optimize the production resource usage.\n\nTo summarize, this article makes the following contributions: 1) an end-to-end DRL method to solve the FJSP, which can train size-agnostic policies that outperform traditional handcrafted PDRs while maintaining high efficiency; 2) an MDP formulation with an integrated decision-making approach, which combines the operation selection and machine assignment decisions as one decision; 3) a heterogeneous graph structure for state representation, which effectively integrates operation and machine information with relatively low graph density; 4) a heterogeneous graph neural network (HGNN)-based neural architecture, which extracts rich information from the heterogeneous state graph for high-quality scheduling decision making. The rest of this article is organized as follows. Section II reviews recent DRL-based scheduling methods. Section III describes the FJSP and its graph representation. Section IV introduces the proposed method in detail. Section V provides experimental results and analysis. Finally, Section VI concludes this article.\n\n\nII. RELATED WORKS\n\nIn this section, we briefly review conventional FJSP methods and the recent DRL-based scheduling methods.\n\n\nA. Conventional FJSP Methods\n\nConventional methods for solving the FJSP can be classified into exact methods, heuristics, and metaheuristics [7]. Typical exact methods are mixed-integer linear programming [19] and constraint programming [20]. They have theoretical guarantee of finding the optimal schedule but requires exponentially long computational time. Heuristics are developed based on expert knowledge, which do not possess optimality guarantee but are considerably faster than exact methods. Typical FJSP heuristics include PDR [21], A* [22], local search [23], etc. Metaheuristics can be further classified into single-solution-based (e.g., simulated annealing [24] and tabu search [25]) and population-based (e.g., genetic algorithm [26], [27]) methods, which works on a single solution and a pool of solutions, respectively. Complete reviews of FJSP methods can be found in [6] and [7]. This article focuses on PDRs, which are widely used in practical production systems due to its easy implementation and fast computation. The aim is to discover high-quality PDRs using DRL, and the relevant works are discussed in the following.\n\n\nB. DRL-Based Scheduling Methods\n\nRecently, quite a few works have employed DRL to solve complex scheduling problems. A key issue in DRL-based scheduling is state representation. For the JSP, some researchers use vectors or matrices to represent states and use a multilayer perceptron (MLP) [10], [12], [28], [29] or a convolutional neural network [11] to extract state features. A major limitation of such representation is that it is hard bounded by fixed matrix dimensions and cannot solve problems of different sizes. A recent work [15] partially resolves this issue for the hybrid flow-shop scheduling problem (HFSP), by viewing matrices as relationship between two item groups (jobs and machines), and uses self-attention [30], a size-agnostic structure, to process each item. However, this model is still limited to the fixed number of HFSP stages. For the permutation flow-shop scheduling problem (PFSP), a recurrent-neural-network-based architecture is designed in [31] to handle the varying number of jobs and machines. However, it is specific to the PFSP and not applicable to the FJSP.\n\nAn arguably better representation technique for scheduling problems is the GNN [32], which can process graphs of varying sizes and, thus, overcomes the limitation of matrix representation. Zhang et al. [13] combine DRL and the GNN to learn high-quality PDRs for the JSP. They model states as disjunctive graphs with different connections and use the GNN to encode the state graphs. Park et al. [14] adopt a similar scheme using richer node (i.e., operation) features and, at the same time, considering the different relationships between nodes in the GNN message passing process. Ni et al. [18] employ DRL to learn a local search heuristic for solving the HFSP. They represent the solution at each search step as a multigraph structure and overcome the scale limitation in [15] by an attention-based pooling across different stages.\n\nTill now, most related works focus on solving the JSP using DRL and cannot be applied to the FJSP due to its additional complexity in decision making and representation. For the FJSP, the decision framework should be able to handle two types of decisions, i.e., operation selection and machine assignment, and the representation scheme should be able to extract more informative state features, especially for the flexible machines. While the HFSP is flexible due to the parallel machines at each stage, its problem structure is significantly different from that of the FJSP. The application of DRL in the FJSP is rather sparse. Luo et al. [33] employ a deep Q-network to solve a dynamic FJSP. However, the action is to select from a pool of handcrafted PDRs, which heavily relies on human experience. Han and Yang [34] propose an end-to-end DRL method for the FJSP based on a 3-D disjunctive graph. However, the attention-based policy network they designed only processes raw features without considering the graph structure and, hence, is limited in extracting useful information for high-quality decision making.\n\n\nIII. PRELIMINARIES\n\nAn FJSP instance of size n \u00d7 m includes n jobs and m machines, forming two sets J and M. Each job J i \u2208 J has an operation set O i , which contains n i operations O ij that must be processed in a specific order (i.e., precedence constraints). Each operation O ij can be processed on any machine M k from its compatible set M ij \u2286 M for a processing time p ijk without preemption. Each machine can only process one operation at a time. To solve the FJSP, one needs to assign each operation O ij to a compatible machine and determine its start time S ij , such that the makespan\nC max = max i,j {C ij } is minimized, where C ij is the completion time of O ij .\nA disjunctive graph for the FJSP [35] can be written as\nG = (O, C, D). Specifically, O = {O ij |\u2200i, j} \u222a {Start, End}\nis the node set, which includes all the operations and two dummy ones (with zero processing time) representing the start and end of production. C is the set of conjunctive arcs, which are directed arcs that form n paths from Start to End representing the respective processing sequence of J i . D = k D k is the set of disjunctive arcs, which are undirected, and D k is a clique that connects the operations that can be processed on machine M k . Note that unlike the JSP, an operation in the FJSP could be connected to multiple disjunctive arcs due to the flexibility. Solving the FJSP is equivalent to selecting for each node a disjunctive arc and fixing its direction. An illustration of the disjunctive graph for the FJSP is given in Fig. 2.\n\n\nIV. METHOD\n\nThis section introduces the proposed method in detail. In this article, solving the FJSP is considered as a sequential decision-making process, which iteratively takes a scheduling action to assign an operation to a compatible machine at each state, until all the operations are scheduled. The workflow of the proposed method is shown in Fig. 3. In each iteration, the scheduling state is first transformed into a heterogeneous graph structure (see Section IV-B). Then, an HGNN with a two-stage embedding process is applied to the heterogeneous graph to extract the feature embeddings of the operations and machines (see Section IV-C), which are consumed by the decision-making network to generate the action probability distribution, from which a scheduling action is sampled (see Section IV-D). In the following subsection, the MDP formulation of the above process is first presented.\n\n\nA. MDP Formulation\n\nThe scheduling process considered here works as follows. At each decision step t (time 0 or when an operation is completed), the agent observes the current system state s t and makes a decision a t , which is to allocate an unscheduled operation to an idle machine and start it from the current time, denoted as T (t). Then, the environment transits to the next decision step t + 1. The process iterates until all the operations are scheduled. The corresponding MDP is defined as follows.\n\nState: The conditions of all the operations and the machines at step t constitute state s t . The initial state s 0 is an FJSP instance drawn from a distribution. Note that for each s t , a partial schedule S(t) is maintained, which is computed as follows.\nIf O ij is scheduled, its start time S ij (t) is the actual value S ij . Otherwise, S ij (t) is an estimate computed with only prece- dence constraints. If its immediate predecessor O il is scheduled on machine M k , then S ij (t) = S il + p ilk ; otherwise, S ij (t) = S il (t) +p il , wherep ij = M k \u2208M ij p ijk /|M ij | is an estimated processing time of O ij . S ij (t)\ncan be computed recursively for all the unscheduled operations in the direction from Start to End.\n\nAction: This article uses an integrated approach to solve the FJSP, which combines the operation selection and the machine assignment as a composite decision. Specifically, an action\na t \u2208 A t is defined as a feasible O-M pair (O ij , M k ) at step t, where O ij is eligible (i.e., its immediate predecessor is completed) and M k \u2208 M ij is idle. O ij starts on M k imme- diately, i.e., S ij = T (t).\nThe action set A t is step dependent, which collects all the feasible pairs. Since each job can have at most one operation ready at a time and |M ij | \u2264 m, therefore |A t | \u2264 n\u00d7m.\n\nTransition: Based on s t and a t , the environment deterministically transits to a new state s t+1 , which is the time when an operation is completed. In this article, two difference states are distinguished by the topology and features of the corresponding heterogeneous graph structure.\n\nReward: The reward is defined as the difference between the makespan of the partial schedule at s t and s t+1 , i.e., r(s t , a t , s t+1 ) = C max (s t ) \u2212 C max (s t+1 ). When the discount factor \u03b3 = 1, the cumulative reward in an solving episode is\nG = |O| t=0 r(s t , a t , s t+1 ) = C max (s 0 ) \u2212 C max .\nFor a specific problem instance, C max (s 0 ) is a constant, which means that minimizing C max and maximizing G are equivalent.\n\nPolicy: A policy \u03c0(a t |s t ) defines for each state s t a probability distribution over the action set A t . Later in this section, a DRL algorithm will be designed that parameterizes \u03c0 as a neural network and optimizes it toward the direction of maximizing the expected cumulative reward.\n\n\nB. Heterogeneous Graph\n\nPrevious works have employed the disjunctive graph to represent JSP scheduling states and achieved good results. However, the disjunctive graph of the FJSP is more complicated. First, the disjunctive arc set D could be much larger since operations can be processed by multiple machines. Such dense graph is hard to be efficiently processed [13]. Second, the processing times of an operation on different compatible machines are different, making it difficult to represent. To resolve the above issue, this article defines a novel heterogeneous graph structure H = (O, M, C, E) by modifying the disjunctive graph. As shown in Fig. 4, the operation node set O and the conjunctive arcs set C are kept, and a set of machine nodes M is added, each for one machine M k . The disjunctive arc set D is replaced with an O-M arc set E, where each element E ijk \u2208 E is an undirected arc connects an operation node O ij with a compatible machine node M k .\n\nThe above heterogeneous graph representation has several advantages over the original FJSP disjunctive graph. First, the graph density is significantly reduced. Suppose that for each machine M k , there are n k processable operations; then, |D| = k n k 2 , while |E| = k n k . It is easy to prove that when n k > 3 holds for all M k , |D| > |E|, and the difference between |D| and |E| grows quadratically with the increase of n k . For large-sized problems, the heterogeneous graph H requires much less O-M arcs than the disjunctive arcs in G. Second, the machine nodes in H provide a convenient way to inject machine information and extract useful features to distinguish different machines in a state. Such information is very important to solve the FJSP since operations need to be allocated to a suitable machine and is difficult to obtain in G. Finally, the processing time p ijk is easily represented by simply attaching as a feature to the O-M arc E ijk .\n\nBased on the above definition of H, this article represents each state s t as a heterogeneous graph H t = (O, M, C, E t ), where E t dynamically changes during a solving episode. Specifically, after an action (O ij , M k ) is taken at step t, only E ijk is kept and other O-M arcs of O ij are removed to obtain H t+1 . Hence, the neighboring relationship among nodes also dynamically changes. For each step t, let N t (O ij ) be the neighboring machines of operation O ij , and N t (M k ) be the neighboring operations of machine M k . For each operation, machine, and O-M arc, raw feature vectors \u03bc ij \u2208 R 6 , \u03bd ij \u2208 R 3 , and \u03bb ij \u2208 R are defined to reflect their states at step t. Detailed definition can be found in the Appendix.\n\n\nC. Heterogeneous Graph Neural Network\n\nAs typical in combinatorial problems, FJSP instances have varying sizes. To learn practical scheduling policy using DRL, the neural architecture must be able to operate on state graphs of different sizes. Previous works [13], [14], [18] have shown that the GNN can achieve this size-agnostic property. However, they all deal with homogeneous graphs and, hence, are not applicable here. In the general GNN literature, research on the heterogeneous graph is rather sparse [32]. While some HGNNs have been proposed recently [36]- [38], they do not consider the unique properties of the FJSP heterogeneous graph H t . First, different node types in H t have strong connection patterns. The To exploit the properties and advantages of the heterogeneous graph structure, this article proposes a novel HGNN architecture customized for the FJSP to effectively encode H t . As shown in Fig. 5, the proposed method is featured with a two-stage embedding process, so as to take graph topological and numerical information (raw features) into account and map the nodes in H t into d-dimensional embeddings. In the first stage, machine embeddings \u03bd k \u2208 R d are updated by aggregating relevant information, while operation embeddings \u03bc ij \u2208 R d are updated in the second stage. Details are given as follows.\n\n1) Machine Node Embedding: In H t , the neighbors of a machine M k are a set of operations N t (M k ), which may have different meanings to M k . For example, operations that are expected to start sooner might be more important than those which start later. This motivates us to consider graph attention networks (GATs) [39], which automatically learn the importance of different nodes by applying the attention mechanism [30]. For a homogeneous graph, given a node i with feature x i , the GAT first computes the attention coefficient e ij (a scalar) between i and each j in its first-order neighborhood N (i) (including i itself) as\ne ij = LeakyReLU a [Wx i ||Wx j ] .(1)\nIn other words, x i and x j are processed by a shared linear transformation W first and then concatenated (||) and fed into a single-layer feedforward neural network with weights a and LeakyReLU activation. Then, the coefficients are normalized across the neighborhood using softmax function\n\u03b1 ij = exp(e ij ) q\u2208N (i) exp(e iq ) \u2200j \u2208 N (i).(2)\nFinally, the GAT aggregates (linearly transformed) features over N (i) and applies a nonlinearity \u03c3 to get the embedding of i\nx i = \u03c3 j\u2208N (i) \u03b1 ij Wx j .(3)\nHowever, the original GAT is for homogeneous graphs only and does not consider arc features. Therefore, it is modified, here, to satisfy the need of this article, which is to calculate the importance of a neighboring operation to a machine. First, it can be observed that for each machine M k , there is only one O-M arc connects it with a neighboring operation. Therefore, the raw feature vector of each O ij \u2208 N t (M k ) is extended by concatenating its original raw features with that of the corresponding O-M arc as \u03bc ijk = [\u03bc ij ||\u03bb ijk ] \u2208 R 7 . Next, instead of using a shared one, here, two linear transformations W M \u2208 R d\u00d73 and W O \u2208 R d\u00d77 are used for the machine and operation nodes, respectively. Then, for a machine M k , the attention coefficients e ijk , i.e., the importance of each neighboring operation O ij \u2208 N t (M k ), can be calculated as\ne ijk = LeakyReLU a W M \u03bd k ||W O \u03bc ijk(4)\nwhere a \u2208 R 2 d . In this way, information from heterogeneous nodes and O-M arcs can be effectively incorporated in the attention computation. One thing not considered in (4) is the attention coefficient of machine M k to itself, which is involved in the original GAT [see (1)]. Here, e kk is computed using the machine specific weights W M as follows:\ne kk = LeakyReLU a W M \u03bd k ||W M \u03bd k .(5)\nThen, all e ijk \u2200O ij \u2208 N t (M k ) are normalized together with e kk using a softmax function to obtain the normalized attention coefficients \u03b1 ijk and \u03b1 kk . Finally, the machine embedding \u03bd k is computed by fusing features from neighboring operations and itself. Owing to the importance of processing time, the extended raw feature vector \u03bc ijk is used for each neighboring O ij . The aggregation function for calculating \u03bd k is as follows: \n\u03bd k = \u03c3 \u03b1 kk W M \u03bd k + O ij \u2208N t (M k ) \u03b1 ijk W O \u03bc ijk . (6) 2) Operation\u03bc ij = MLP \u03b8 0 (ELU [MLP \u03b8 1 (\u03bc i,j\u22121 ) ||MLP \u03b8 2 (\u03bc i,j+1 ) ||MLP \u03b8 3 \u03bd ij ||MLP \u03b8 4 (\u03bc ij ) .(7)\nNote that there is no need to compute the embeddings of the two dummy operations Start and End.\n\n3) Stacking and Pooling: The above embedding process can be considered as an HGNN layer, which transforms raw features \u03bc ij and \u03bd k of each operation and machine into embeddings \u03bc ij and \u03bd k . To enhance feature extraction ability, here, L HGNN layers with identical structure but independent trainable parameters are stacked to obtain the final embeddings \u03bc After the L layers of the HGNN, mean pooling is applied to the obtained operation embedding set and machine embedding set separately. The resulting two d-dimensional vectors are, then, concatenated as the embedding h t \u2208 R 2 d of the heterogeneous graph state H t as follows:\nh t = 1 |O| O ij \u2208O \u03bc (L) ij 1 |M| M k \u2208M \u03bd (L) k .(8)\nThrough the above process, a varying-size heterogeneous graph can be transformed into a fixed-dimensional embedding. Let \u03b8 be the collection of all the HGNN parameters.\n\n\nD. Decision Making\n\nAs the last part of the proposed neural architecture, in the following, a policy network is designed. Remind that an action is a feasible O-M pair. Thanks to the above heterogeneous graph structure and the HGNN, the policy \u03c0(a t |s t ) is easy and convenient to represent using the extracted embeddings. Specifically, for each feasible action a t = (O ij , M k ) \u2208 A t at step t, the corresponding operation, machine, and state embedding are concatenated and fed into an MLP to get its priority index of being selected at state s t as follows:\nP (a t , s t ) = MLP \u03c9 \u03bc (L) ij ||\u03bd (L) k ||h t(9)\nwhere MLP \u03c9 has two d \u03c0 -dimensional hidden layers and tanh activation. Then, the probability of selecting each a t is calculated by applying softmax over all P (a t , s t )\n\u03c0 \u03c9 (a t |s t ) = exp (P (a t , s t )) a t \u2208A t exp (P (a t , s t )) \u2200a t \u2208 A t .(10)\nDuring training, actions are sampled according to the policy \u03c0 \u03c9 , so as to enable exploration. For testing, there could be two strategies of utilizing a trained policy \u03c0 \u03c9 to solve a given instance, including 1) greedily picking actions with the maximum probability and 2) sampling actions following \u03c0 \u03c9 at each state, same as in training. Different from the greedy one, the solutions delivered by the sampling strategy could be different each run due to the stochasticity. This provides additional possibilities of finding better solutions since, in general, current DRL algorithms can only converge to suboptimal policies. In particular, the sampling strategy solves N s copies of a given instance to obtain N s solutions, from which it picks the best one as in [40]. Note that for neural policies, the additional overhead of sampling is often small since graphical processing unit (GPU) is able to sample solutions in parallel. \n\n\nE. Training\n\nThis article uses PPO [41] for training, which employs an actor-critic structure. Actor is the policy network \u03c0 \u03c9 , and critic v \u03c6 is another network that predicts the value v(s t ) of a state s t . Here, the critic is designed as an MLP, which takes input the state embedding h t computed by the HGNN to get v \u03c6 (s t ). MLP \u03c6 has the same structure as MLP \u03c0 , i.e., two hidden layers with d \u03c6 dimension and tanh activation, but with different parameters \u03c6 and different input dimension (2d instead of 4d). The overall network architecture is shown in Fig. 6. As shown in Algorithm 1, the training is performed for I iterations, during which a batch of B instances (replaced every 20 iterations) is solved by the DRL agent in parallel (Lines 3-10). During training, the policy is validated on a set of independent validation instances every ten iterations.\n\n\nV. EXPERIMENTS\n\nThis section shows experimental results on synthetic and public FJSP instances to validate the proposed method.\n\nA. Experimental Settings 1) Evaluation Instances: As in most related works, this article generates synthetic FJSP instances for training and testing. The generation method is similar to the well-known procedure in [35]. As listed in Table I, six problem sizes are considered. For each size, an instance is sampled by drawing from the corresponding uniform distribution in Table I (p ijk is sampled from U(0.8p ij , 1.2p ij )). This article performs training on the four smaller sizes and uses the largest two (30 \u00d7 10 and 40 \u00d7 10) to test the generalization capability of the trained policies. The training instances are generated on the fly (with 100 validation instances), while, for testing, 100 instances are sampled for each size. Besides the synthetic instances, two well-known FJSP benchmarks are used for generalization analysis, including the ten mk instances (mk01-mk10) in [35] and the three groups of la instances (rdata, edata, and vdata, each with 40 instances) in [42]. These instances are of various sizes (ranging from 10 \u00d7 6 to 30 \u00d7 10), drawing from distributions significantly different from those in Table I. Hence, testing on these benchmarks can further verify the proposed method in generalizing to out-ofdistribution instances. More details about these instances can be found in [43].\n\n2) Configuration: This article sets the number of HGNN iterations as L = 2 and dimensions of machine and operation embeddings as d = 8. For the MLPs, the hidden dimensions are set as d h = 128, and d \u03c0 = d \u03c6 = 64. For training, the number of training iterations and instance batch size is set to I = 1000 and B = 20. For the PPO loss function, the coefficients of the policy loss (with 0.2 clip ratio), value loss, and entropy term are set as 1, 0.5, and 0.01, respectively. The PPO optimization epochs are set to R = 3, and the discount factor is set to \u03b3 = 1.0. The network is updated using the Adam optimizer, with learning rate lr = 2 \u00d7 10 \u22124 . For testing, the trained policies are tested using both the greedy and sampling strategies (with N s = 100 solutions) mentioned in Section IV-D, named DRL-G and DRL-S, respectively. These hyperparameters are empirically tuned on the smallest problem size 10 \u00d7 5 and fixed on the remaining sizes. The hardware is a machine with Intel Xeon Gold 6152 CPU, one Nvidia Titan V GPU, and Ubuntu 16.04 64-bit OS. The code in Pytorch is publicly available. 1 3) Baselines: The learned FJSP scheduling policies are compared to four well-known PDRs that work well in practice, including FIFO, most operations remaining (MOR), shortest processing time (SPT), and most work remaining (MWKR) [35], [44]. For MWKR, average processing timep ij is used to compute the priority, just as [35] did. For fair comparison, the baseline PDRs are implemented in the same environment as the proposed method, so as to verify that a learned policy is indeed better than a handcrafted one. At each decision point, after an operation is selected by a PDR, it is assigned to the corresponding idle machine immediately. This article also compares to Google OR-Tools, 2 a powerful constraint programming solver showing strong performance in solving industrial scheduling problems [45]. Since OR-Tools is an exact solver, a time limit of 1800 s is set, and the obtained optimal or best solutions are used to evaluate the solution quality of the learned or handcrafted PDRs. For the public benchmarks, this article also compares to the results of the DRL method [34] and two recent genetic algorithms (GAs) in [26] and [27], as well as the best known solutions collected in [43]. For each solution with makespan C max , its relative gap to the makespan C BS max of the best solution (not necessarily optimal) is calculated as follows:\n= C max /C BS max \u2212 1 \u00d7 100%.(11)\n\nB. Performance on Synthetic Instances\n\nThe training process of the proposed DRL method is fairly stable and converged on all the four training sizes. Here, for brevity, the training curve on 10 \u00d7 5 is in Fig. 7, which is plotted based on the average makespan on the 100 validation instances. It can be observed that without human intervention, the DRL agent can indeed learn the high-quality scheduling policy from scratch, based on its own solving experiences. Next, the trained policies will be evaluated on the synthetic instances of the same size as in training and larger sizes unseen in training. Run time analysis will also be provided.\n\n\n1) Evaluation on Instances of Training Sizes:\n\nFor each of the training size, Table II reports the average makespan and gap to the OR-Tools solutions on the 100 testing instances drawn from the same distribution as in training. As can be seen, even for small-sized problems, OR-Tools can only solve a small portion of instances optimally within the time limit, showing the complexity of the FJSP. For the PDR-based methods, the proposed method (in both the strategies) consistently outperforms all the baseline PDRs in the four training sizes. The average gap of the proposed method to the OR-Tools solutions ranges from 9% to 16% using the greedy strategy, which is similar to the results 2 [Online]. Available: https://developers.google.com/optimization    [13] and [14] in JSP study. Meanwhile, the sampling strategy can further boost the performance and reduce the gap to be within 11%. To have a more detailed comparison, the proposed method is used as reference to compute the gap of each baseline PDRs, and the boxplots are shown in Fig. 8. It can be observed that the proposed method performs better than baseline PDRs on more than 75% of the instances, except on 15 \u00d7 10 where it manages to surpass MWKR on nearly 75% of the instances. The improvement of the proposed method against baseline PDRs on 20 \u00d7 5 is relatively small than on other sizes. This may be caused by the graph structure of the 20 \u00d7 5 instances. For this distribution, each job tends to have fewer operations and fewer compatible machines, which may affect the effectiveness of the HGNN.\n\n\n2) Generalization Performance on Large-Sized Instances:\n\nThis article further examines the capability of the proposed sizeagnostic policy in generalizing to unseen large-sized instances. To this end, the policy trained on 20 \u00d7 10 instances is directly run on 30 \u00d7 10 and 40 \u00d7 10 instances, and the results are summarized in Table III. It can be observed that the advantage of the proposed method still maintains on these large instances, showing that the patterns learned on small-and medium-sized instances are still effective in solving large-sized ones.\n\n3) Run Time Analysis: Table IV lists the average run time of the proposed method and PDR baselines. It can be seen that the   1 The gaps of the RegGA and the 2SGA are computed on 30 out of 40 la vdata instances (la01-la30), on which Rooyani and Defersha [27] reported results. 2 For the two rows of each DRL policy, the above and below rows are the result of the greedy and sampling strategies, respectively. 3 Bold means the best performance among the PDR-based methods.\n\nproposed method maintains the high efficiency of PDR-based methods, and the run time increases mildly with the increase in the problem size. For a given size, the run time of the proposed method is longer than those of the other PDRs. This is because neural network inference is more costly than the simple rules employed by handcrafted PDRs, which is consistent with other works (see, e.g., [13] and [14]) and is reasonable considering the performance boost. For training, the proposed method takes about 0.36, 0.69, 1.18, and 1.64 h on the four training sizes 10 \u00d7 5, 20 \u00d7 5, 15 \u00d7 10, and 20 \u00d7 10, respectively. It can be concluded that the training time increases relatively mildly with the increase in the problem size. Considering that training is offline, such time efficiency is acceptable.\n\n\nC. Performance on Public Benchmarks\n\nThis subsection further evaluates the generalization performance of the trained policies on the two public benchmarks that are often used in traditional research, by directly running the four policies trained in Section V-B (named DRL n \u00d7 m) on the benchmark instances. Results are summarized in Table V (gaps are computed with respect to the best solutions in [43]), which also includes results from the recent DRL [34] and GA [26], [27] baselines. In particular, Chen et al. [26] propose a self-learning genetic algorithm (SLGA) that uses reinforcement learning to adjust the GA parameters during solving FJSP instances. Rooyani and Defersha [27] propose a two-stage genetic algorithm (2SGA) for the FJSP, which improves the regular genetic algorithm (RegGA) by a first stage that generates high-quality initial population. Results of both the 2SGA and the RegGA in [27] are included here.\n\nThe upper part of Table V shows that OR-Tools obtain very good solutions, though it only solves half instances optimally. The GA methods also find high-quality solutions. However, the run time of these search-based methods is much longer than that of the PDR-based ones in the lower part of Table V. It can be seen that the proposed method with the greedy strategy generally performs better than other baseline PDRs on both the benchmarks, and the sampling strategy further reduces the gaps. This shows that the learned policies generalize well to these out-of-distribution instances. The four learned policies have almost the same run time, since they have the same neural structure with only different parameters. Compared with the recent method [34] that reported results on the mk benchmark, the proposed method significantly outperforms it by a large margin (except the policy trained on 20 \u00d7 5 instances), showing the advantage of the HGNN in extracting rich state information for better decision making. An interesting observation is that among the four of our policies, the one trained on the smallest size 10 \u00d7 5 performs the best in general. With sampling, it even achieves the optimal solutions on two mk instances (mk03 and mk08) and finds solutions within 5% gap to the best solutions in [43] for more than 50% (69 out of 120) of the la instances. This might be because for the simpler learning task, the training of the DRL agent could be more sufficient so that it can discover better patterns. We will investigate this in the future. As another interesting direction, the fast and high-quality solving performance of the proposed method provides additional possibilities of being integrated with the search-based methods, for example generating initial populations in the 2SGA.\n\n\nVI. CONCLUSION\n\nSolving flexible scheduling problems efficiently is of great importance to the next-generation manufacturing paradigms, such as cloud manufacturing. This article proposed a novel end-to-end DRL method to learn high-quality PDRs for the FJSP, which is widely used in practice but rarely studied by the existing DRL-based methods. The underlying MDP was formulated using an integrated approach, which combined operation selection and machine assignment as one decision. Then, a heterogeneous graph structure was proposed to represent scheduling states, which was processed by a novel HGNN architecture so as to convert the numerical and topological information in the graph into feature embeddings. Based on the HGNN, an actor-critic architecture was designed and trained with PPO. Results showed that the proposed method outperforms baseline PDRs with reasonable efficiency and generalizes well to the unseen instances of larger sizes and from public benchmarks. For future work, the method will be extended to handle more challenging factors in practical production, such as batching, due dates, and uncertainties. In addition, the multioptima property [46] of the FJSP (i.e., an instance could have multiple optimal solutions) will be exploited to enhance the training performance. The possibilities of combining with advanced search mechanisms, such as the GA, will also be investigated.\n\n\nAPPENDIX DEFINITION OF RAW FEATURE VECTORS\n\nFor each state S t , the raw features of each operation, machine, and O-M arcs are defined as follows (dependence on t is ignored for clearance).\n\nRaw features of operation nodes: For each O ij \u2208 O \\ {Start, End}, the raw feature vector \u03bc ij \u2208 R 6 has six elements: 1) status: a binary value indicates whether O ij has been scheduled (1) or not (0) till step t; 2) number of neighboring machines: |N t (O ij )|; 3) processing time: p ijk if O ij is scheduled, otherwisep ij ; 4) start time: the estimated or actual start time of O ij in the corresponding partial schedule S(t); 5) number of unscheduled operations in the job: the number of operations in O i that have not been scheduled; 6) job completion time: C i in the partial schedule S(t). Note that for the two dummy operations Start and End, zero vectors are used when necessary.\n\nRaw features of machine nodes: For each M k \u2208 M, three features are used to form its raw feature vector \u03bd k \u2208 R 3 : 1) available time: the time when M k completes all its assigned operations and can process new operations; 2) number of neighboring operations: |N t (M k )|; 3) utilization: ratio of the nonidle time to the total production time of M k till T (t) and is within the range [0,1]. Raw feature of O-M arcs: For each E ijk \u2208 E, its raw feature vector \u03bb ijk \u2208 R contains only one element, i.e., the corresponding processing time p ijk .\n\n\nManuscript received 30 December 2021; revised 19 April 2022 and 26 June 2022; accepted 29 June 2022. Date of publication 11 July 2022; date of current version 13 December 2022. This work was supported in part by the National Natural Science Foundation of China under Grant 62102228 and in part by the Shandong Provincial Natural Science Foundation under Grant ZR2021QF063. Paper no. TII-21-5892. (Wen Song and Xinyang Chen contributed equally to this work.) (Corresponding author: Qiqiang Li.) Wen Song is with the Institute of Marine Science and Technology, Shandong University, Qingdao 266237, China (e-mail: wen-song@email.sdu.edu.cn). Xinyang Chen and Qiqiang Li are with the School of Control Science and Engineering, Shandong University, Jinan 250061, China (e-mail: chenxy19@mail.sdu.edu.cn; qqli@sdu.edu.cn). Zhiguang Cao is with the Singapore Institute of Manufacturing Technology, Singapore 138634 (e-mail: zhiguangcao@outlook.com). Color versions of one or more figures in this article are available at https://doi.org/10.1109/TII.2022.3189725. Digital Object Identifier 10.1109/TII.2022.3189725\n\nFig. 1 .\n1Conceptual architecture of the DRL-based method.\n\nFig. 2 .\n2Disjunctive graph of the FJSP. Dotted line means processable, while solid line means scheduled. (a) Instance. (b) Solution.\n\nFig. 3 .\n3Workflow of the proposed method.\n\nFig. 4 .\n4Heterogeneous graph of the FJSP. Dotted line means processable, while solid line means scheduled. (a) Instance. (b) Solution.\n\nFig. 5 .\n5Two-stage embedding scheme. Update of machine embedding \u03bd 2 and operation embedding \u03bc 12 are highlighted for illustration.neighbors of any machine can only be operations connected by undirected arcs, while an operation could be connected to both the operations and the machines by directed or undirected arcs. Second, features on O-M arcs (i.e., processing times) are of great importance for solving the FJSP. However, the existing HGNNs usually focus on node features only and do not consider arc features.\n\n\nfeatures \u03bc ij and \u03bd k of operation and machine nodes are only used in the first layer, while raw features \u03bb ijk of O-M arcs are used in all the L layers.\n\nFig. 6 .\n6Network architecture.\n\nFig. 7 .\n7Training curve on 10 \u00d7 5 instances.\n\nFig. 8 .\n8Relative gaps of the handcrafted PDRs to the DRL policy. (a) 10 \u00d7 05. (b) 20 \u00d7 05. (c) 15 \u00d7 10. (d) 20 \u00d7 10.\n\n\nNode Embedding: Different from machines, the neighbors of an operation O ij in H t are of several types, including an immediate predecessor O i,j\u22121 , an immediate successor O i,j+1 , and the machines in N t (O ij ). Moreover, O i,j\u22121 and O i,j+1 are connected to O ij by directed arcs from the opposite direction, while M k \u2208 N t (O ij ) are connected by undirected arcs. Owing to the heterogeneity of information sources and arc types, it is not very helpful and convenient to apply attentionbased mechanisms. Instead, this article directly uses multiple MLPs to process information from each source (including the features of O ij itself), concatenates the results, and projects it back to the d-dimensional space as the embedding of O ij . Specifically, five MLPs (denoted as MLP \u03b8 0 ,..., MLP \u03b8 4 ) are defined, each with d-dimensional output, two d h -dimensional hidden layers, and ELU activation. They are responsible for the final projection and processing information from O i,j\u22121 , O i,j+1 M k \u2208 N t (O ij ), and O ij . Since N t (O ij ) may have multiple machines, elementwise sum is applied to obtain\u03bd ij = k\u2208N t (O ij ) \u03bd k as the input to MLP \u03b8 3 . The computation of embedding for O ij is as follows:\n\nTABLE I INSTANCE\nIGENERATION DISTRIBUTIONS 1 Number of operations in Job J i . 2 Number of compatible machines for operation O ij . 3 Average processing time of operation O ij .\n\nTABLE II RESULTS\nIION SYNTHETIC INSTANCES OF TRAINING SIZE 1 (.%): percentage of instances solved optimally within 1800 s.\n\nTABLE III RESULTS\nIIION THE LARGE-SIZED SYNTHETIC INSTANCES 1 (.%): percentage of instances solved optimally within 1800 s.\n\nTABLE IV RUN\nIVTIME (IN SECONDS) COMPARISONof \n\nTABLE V RESULTS\nVON THE PUBLIC BENCHMARKS\n[Online]. Available: https://github.com/songwenas12/fjsp-drl\n\nSoftware-defined cloud manufacturing for Industry 4.0. L Thames, D Schaefer, Procedia CIRP. 52L. Thames and D. Schaefer, \"Software-defined cloud manufacturing for Industry 4.0,\" Procedia CIRP, vol. 52, pp. 12-17, 2016.\n\nA review of logistics Internet-of-Things: Current trends and scope for future research. H Golp\u00eera, S A R Khan, S Safaeipour, J. Ind. Inf. Integr. 22Art. no. 100194H. Golp\u00eera, S. A. R. Khan, and S. Safaeipour, \"A review of logistics Internet-of-Things: Current trends and scope for future research,\" J. Ind. Inf. Integr., vol. 22, 2021, Art. no. 100194.\n\nScheduling in cloud manufacturing: State-of-the-art and research challenges. Y Liu, L Wang, X V Wang, X Xu, L Zhang, Int. J. Prod. Res. 57Y. Liu, L. Wang, X. V. Wang, X. Xu, and L. Zhang, \"Scheduling in cloud manufacturing: State-of-the-art and research challenges,\" Int. J. Prod. Res., vol. 57, no. 15-16, pp. 4854-4879, 2019.\n\nDigital-twin-based job shop scheduling toward smart manufacturing. Y Fang, C Peng, P Lou, Z Zhou, J Hu, J Yan, IEEE Trans. Ind. Informat. 1512Y. Fang, C. Peng, P. Lou, Z. Zhou, J. Hu, and J. Yan, \"Digital-twin-based job shop scheduling toward smart manufacturing,\" IEEE Trans. Ind. In- format., vol. 15, no. 12, pp. 6425-6435, Dec. 2019.\n\nGame theory based real-time shop floor scheduling strategy and method for cloud manufacturing. Y Zhang, J Wang, S Liu, C Qian, Int. J. Intell. Syst. 324Y. Zhang, J. Wang, S. Liu, and C. Qian, \"Game theory based real-time shop floor scheduling strategy and method for cloud manufacturing,\" Int. J. Intell. Syst., vol. 32, no. 4, pp. 437-463, 2017.\n\nA review on swarm intelligence and evolutionary algorithms for solving flexible job shop scheduling problems. K Gao, Z Cao, L Zhang, Z Chen, Y Han, Q Pan, IEEE/CAA J. Autom. Sinica. 64K. Gao, Z. Cao, L. Zhang, Z. Chen, Y. Han, and Q. Pan, \"A review on swarm intelligence and evolutionary algorithms for solving flexible job shop scheduling problems,\" IEEE/CAA J. Autom. Sinica, vol. 6, no. 4, pp. 904-916, Jul. 2019.\n\nReview on flexible job shop scheduling. J Xie, L Gao, K Peng, X Li, H Li, IET Collab. Intell. Manuf. 13J. Xie, L. Gao, K. Peng, X. Li, and H. Li, \"Review on flexible job shop scheduling,\" IET Collab. Intell. Manuf., vol. 1, no. 3, pp. 67-77, 2019.\n\nReview of job shop scheduling research and its new perspectives under Industry 4.0. J Zhang, G Ding, Y Zou, S Qin, J Fu, J. Intell. Manuf. 304J. Zhang, G. Ding, Y. Zou, S. Qin, and J. Fu, \"Review of job shop scheduling research and its new perspectives under Industry 4.0,\" J. Intell. Manuf., vol. 30, no. 4, pp. 1809-1830, 2019.\n\nA flexible dispatching rule for minimizing tardiness in job shop scheduling. B Chen, T I Matis, Int. J. Prod. Econ. 1411B. Chen and T. I. Matis, \"A flexible dispatching rule for minimizing tardiness in job shop scheduling,\" Int. J. Prod. Econ., vol. 141, no. 1, pp. 360-365, 2013.\n\nSmart manufacturing scheduling with edge computing using multiclass deep Q network. C.-C Lin, D.-J Deng, Y.-L Chih, H.-T Chiu, IEEE Trans. Ind. Informat. 157C.-C. Lin, D.-J. Deng, Y.-L. Chih, and H.-T. Chiu, \"Smart manufacturing scheduling with edge computing using multiclass deep Q network,\" IEEE Trans. Ind. Informat., vol. 15, no. 7, pp. 4276-4284, Jul. 2019.\n\nActor-critic deep reinforcement learning for solving job shop scheduling problems. C.-L Liu, C.-C Chang, C.-J Tseng, IEEE Access. 8C.-L. Liu, C.-C. Chang, and C.-J. Tseng, \"Actor-critic deep reinforcement learning for solving job shop scheduling problems,\" IEEE Access, vol. 8, pp. 71752-71762, 2020.\n\nDynamic job-shop scheduling in smart manufacturing using deep reinforcement learning. L Wang, Comput. Netw. 190Art. no. 107969L. Wang et al., \"Dynamic job-shop scheduling in smart manufactur- ing using deep reinforcement learning,\" Comput. Netw., vol. 190, 2021, Art. no. 107969.\n\nLearning to dispatch for job shop scheduling via deep reinforcement learning. C Zhang, W Song, Z Cao, J Zhang, P S Tan, X Chi, Proc. Int. Conf. Neural Inf. Process. Syst. Int. Conf. Neural Inf. ess. SystC. Zhang, W. Song, Z. Cao, J. Zhang, P. S. Tan, and X. Chi, \"Learning to dispatch for job shop scheduling via deep reinforcement learning,\" in Proc. Int. Conf. Neural Inf. Process. Syst., 2020, pp. 1621-1632.\n\nLearning to schedule job-shop problems: Representation and policy learning using graph neural network and reinforcement learning. J Park, J Chun, S Kim, Y Kim, J Park, Int. J. Prod. Res. 5911J. Park, J. Chun, S. Kim, Y. Kim, and J. Park, \"Learning to schedule job-shop problems: Representation and policy learning using graph neural network and reinforcement learning,\" Int. J. Prod. Res., vol. 59, no. 11, pp. 3360-3377, 2021.\n\nMatrix encoding networks for neural combinatorial optimization. Y.-D Kwon, J Choo, I Yoon, M Park, D Park, Y Gwon, Proc. Int. Conf. Neural Inf. Process. Syst. Int. Conf. Neural Inf. ess. SystY.-D. Kwon, J. Choo, I. Yoon, M. Park, D. Park, and Y. Gwon, \"Matrix encoding networks for neural combinatorial optimization,\" in Proc. Int. Conf. Neural Inf. Process. Syst., 2021, pp. 5138-5149.\n\nHeterogeneous graph attention networks for scalable multi-robot scheduling with temporospatial constraints. Z Wang, C Liu, M Gombolay, Auton. Robots. 461Z. Wang, C. Liu, and M. Gombolay, \"Heterogeneous graph attention networks for scalable multi-robot scheduling with temporospatial con- straints,\" Auton. Robots, vol. 46, no. 1, pp. 249-268, 2022.\n\nStep-wise deep learning models for solving routing problems. L Xin, W Song, Z Cao, J Zhang, IEEE Trans. Ind. Informat. 177L. Xin, W. Song, Z. Cao, and J. Zhang, \"Step-wise deep learning models for solving routing problems,\" IEEE Trans. Ind. Informat., vol. 17, no. 7, pp. 4861-4871, Jul. 2021.\n\nA multi-graph attributed reinforcement learning based optimization algorithm for large-scale hybrid flow shop scheduling problem. F Ni, Proc. 27th ACM SIGKDD Conf. Knowl. Discov. Data Mining. 27th ACM SIGKDD Conf. Knowl. Discov. Data MiningF. Ni et al., \"A multi-graph attributed reinforcement learning based opti- mization algorithm for large-scale hybrid flow shop scheduling problem,\" in Proc. 27th ACM SIGKDD Conf. Knowl. Discov. Data Mining, 2021, pp. 3441-3451.\n\nMathematical models for job-shop scheduling problems with routing and process plan flexibility. C \u00d6zgven, L \u00d6zbak\u0131r, Y Yavuz, Appl. Math. Model. 346C. \u00d6zgven, L. \u00d6zbak\u0131r, and Y. Yavuz, \"Mathematical models for job-shop scheduling problems with routing and process plan flexibility,\" Appl. Math. Model., vol. 34, no. 6, pp. 1539-1548, 2010.\n\nAn algorithm selection approach for the flexible job shop scheduling problem: Choosing constraint programming solvers through machine learning. D M\u00fcller, M G M\u00fcller, D Kress, E Pesch, Eur. J. Oper. Res. 302D. M\u00fcller, M. G. M\u00fcller, D. Kress, and E. Pesch, \"An algorithm selec- tion approach for the flexible job shop scheduling problem: Choosing constraint programming solvers through machine learning,\" Eur. J. Oper. Res., vol. 302, pp. 874-891, 2022.\n\nDispatching algorithm for production programming of flexible job-shop systems in the smart factory industry. M A Ort\u00edz, L E Betancourt, K P Negrete, F De Felice, A Petrillo, Ann. Oper. Res. 2641M. A. Ort\u00edz, L. E. Betancourt, K. P. Negrete, F. De Felice, and A. Petrillo, \"Dispatching algorithm for production programming of flexible job-shop systems in the smart factory industry,\" Ann. Oper. Res., vol. 264, no. 1, pp. 409-433, 2018.\n\nScheduling of flexible manufacturing systems based on petri nets and hybrid heuristic search. B Huang, Y Sun, Y Sun, Int. J. Prod. Res. 4616B. Huang, Y. Sun, and Y. Sun, \"Scheduling of flexible manufacturing systems based on petri nets and hybrid heuristic search,\" Int. J. Prod. Res., vol. 46, no. 16, pp. 4553-4565, 2008.\n\nHeuristic approaches for scheduling jobs in large-scale flexible job shops. O Sobeyko, L M\u00f6nch, Comput. Oper. Res. 68O. Sobeyko and L. M\u00d6nch, \"Heuristic approaches for scheduling jobs in large-scale flexible job shops,\" Comput. Oper. Res., vol. 68, pp. 97-109, 2016.\n\nAn object-oriented approach for multi-objective flexible job-shop scheduling problem. V Kaplanoglu, Expert Syst. Appl. 45V. Kaplanoglu, \"An object-oriented approach for multi-objective flexible job-shop scheduling problem,\" Expert Syst. Appl., vol. 45, pp. 71-84, 2016.\n\nPath-relinking tabu search for the multi-objective flexible job shop scheduling problem. S Jia, Z.-H Hu, Comput. Oper. Res. 47S. Jia and Z.-H. Hu, \"Path-relinking tabu search for the multi-objective flexible job shop scheduling problem,\" Comput. Oper. Res., vol. 47, pp. 11- 26, 2014.\n\nA self-learning genetic algorithm based on reinforcement learning for flexible job-shop scheduling problem. R Chen, B Yang, S Li, S Wang, Comput. Ind. Eng. 149Art. no. 106778R. Chen, B. Yang, S. Li, and S. Wang, \"A self-learning genetic algorithm based on reinforcement learning for flexible job-shop scheduling prob- lem,\" Comput. Ind. Eng., vol. 149, 2020, Art. no. 106778.\n\nAn efficient two-stage genetic algorithm for flexible job-shop scheduling. D Rooyani, F M Defersha, IFAC-PapersOnLine. 5213D. Rooyani and F. M. Defersha, \"An efficient two-stage genetic algorithm for flexible job-shop scheduling,\" IFAC-PapersOnLine, vol. 52, no. 13, pp. 2519-2524, 2019.\n\nDeep reinforcement learning for semiconductor production scheduling. B Waschneck, Proc. IEEE 29th Annu. IEEE 29th AnnuB. Waschneck et al., \"Deep reinforcement learning for semiconductor production scheduling,\" in Proc. IEEE 29th Annu. SEMI Adv. Semicond. Manuf. Conf., 2018, pp. 301-306.\n\nIntelligent scheduling of discrete automated production line via deep reinforcement learning. D Shi, W Fan, Y Xiao, T Lin, C Xing, Int. J. Prod. Res. 5811D. Shi, W. Fan, Y. Xiao, T. Lin, and C. Xing, \"Intelligent scheduling of discrete automated production line via deep reinforcement learning,\" Int. J. Prod. Res., vol. 58, no. 11, pp. 3362-3380, 2020.\n\nAttention is all you need. A Vaswani, Proc. Int. Conf. Neural Inf. Process. Syst. Int. Conf. Neural Inf. ess. SystA. Vaswani et al., \"Attention is all you need,\" in Proc. Int. Conf. Neural Inf. Process. Syst., 2017, pp. 5998-6008.\n\nDeep reinforcement learning based optimization algorithm for permutation flow-shop scheduling. Z Pan, L Wang, J Wang, J Lu, 10.1109/TETCI.2021.3098354IEEE Trans. Emerg. Topics Comput. Intell. to be publishedZ. Pan, L. Wang, J. Wang, and J. Lu, \"Deep reinforcement learn- ing based optimization algorithm for permutation flow-shop schedul- ing,\" IEEE Trans. Emerg. Topics Comput. Intell., to be published, doi: 10.1109/TETCI.2021.3098354.\n\nA comprehensive survey on graph neural networks. Z Wu, S Pan, F Chen, G Long, C Zhang, S Y Philip, IEEE Trans. Neural Netw. Learn. Syst. 321Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip, \"A com- prehensive survey on graph neural networks,\" IEEE Trans. Neural Netw. Learn. Syst., vol. 32, no. 1, pp. 4-24, Jan. 2021.\n\nDynamic multi-objective scheduling for flexible job shop by deep reinforcement learning. S Luo, L Zhang, Y Fan, Comput. Ind. Eng. 159Art. no. 107489S. Luo, L. Zhang, and Y. Fan, \"Dynamic multi-objective scheduling for flexible job shop by deep reinforcement learning,\" Comput. Ind. Eng., vol. 159, 2021, Art. no. 107489.\n\nA deep reinforcement learning based solution for flexible job shop scheduling problem. B Han, J Yang, Int. J. Simul. Model. 202B. Han and J. Yang, \"A deep reinforcement learning based solution for flexible job shop scheduling problem,\" Int. J. Simul. Model., vol. 20, no. 2, pp. 375-386, 2021.\n\nRouting and scheduling in a flexible job shop by tabu search. P Brandimarte, Ann. Oper. Res. 413P. Brandimarte, \"Routing and scheduling in a flexible job shop by tabu search,\" Ann. Oper. Res., vol. 41, no. 3, pp. 157-183, 1993.\n\nGraph transformer networks. S Yun, M Jeong, R Kim, J Kang, H J Kim, Proc. Int. Conf. Neural Inf. Process. Syst. Int. Conf. Neural Inf. ess. Syst32S. Yun, M. Jeong, R. Kim, J. Kang, and H. J. Kim, \"Graph transformer networks,\" in Proc. Int. Conf. Neural Inf. Process. Syst., 2019, vol. 32, pp. 11983-11993.\n\nMAGNN: Metapath aggregated graph neural network for heterogeneous graph embedding. X Fu, J Zhang, Z Meng, I King, Proc. Web Conf., 2020. Web Conf., 2020X. Fu, J. Zhang, Z. Meng, and I. King, \"MAGNN: Metapath aggregated graph neural network for heterogeneous graph embedding,\" in Proc. Web Conf., 2020, pp. 2331-2341.\n\nHeterogeneous graph neural network via attribute completion. D Jin, C Huo, C Liang, L Yang, Proc. Web Conf., 2021. Web Conf., 2021D. Jin, C. Huo, C. Liang, and L. Yang, \"Heterogeneous graph neural network via attribute completion,\" in Proc. Web Conf., 2021, pp. 391-400.\n\nGraph attention networks. P Veli\u010dkovi\u0107, G Cucurull, A Casanova, A Romero, P Li\u00f3, Y Bengio, Proc. Int. Conf. Learn. Representations. Int. Conf. Learn. RepresentationsP. Veli\u010dkovi\u0107, G. Cucurull, A. Casanova, A. Romero, P. Li\u00f3, and Y. Bengio, \"Graph attention networks,\" in Proc. Int. Conf. Learn. Representations, 2018.\n\nAttention, learn to solve routing problems!. W Kool, H Van Hoof, M Welling, Proc. Int. Conf. Learn. Representations. Int. Conf. Learn. RepresentationsW. Kool, H. Van Hoof, and M. Welling, \"Attention, learn to solve routing problems!,\" in Proc. Int. Conf. Learn. Representations, 2019.\n\nProximal policy optimization algorithms. J Schulman, F Wolski, P Dhariwal, A Radford, O Klimov, arXiv:1707.06347J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, \"Proximal policy optimization algorithms,\" 2017, arXiv:1707.06347.\n\nTabu search for the job-shop scheduling problem with multi-purpose machines. J Hurink, B Jurisch, M Thole, OR Spektrum. 154J. Hurink, B. Jurisch, and M. Thole, \"Tabu search for the job-shop schedul- ing problem with multi-purpose machines,\" OR Spektrum, vol. 15, no. 4, pp. 205-215, 1994.\n\nTest instances for the flexible job shop scheduling problem with work centers. D Behnke, M J Geiger, RR-12-01-01Helmut Schmidt Univ. Tech. Rep.D. Behnke and M. J. Geiger, \"Test instances for the flexible job shop scheduling problem with work centers,\" Helmut Schmidt Univ., Hamburg, Germany, Tech. Rep. RR-12-01-01, 2012.\n\nAnalysis of scheduling rules for an FMS. M Montazeri, L Van Wassenhove, Int. J. Prod. Res. 284M. Montazeri and L. Van Wassenhove, \"Analysis of scheduling rules for an FMS,\" Int. J. Prod. Res., vol. 28, no. 4, pp. 785-802, 1990.\n\nIndustrial size job shop scheduling tackled by present day CP solvers. G Da Col, E C Teppan, Proc. Int. Conf. Princ. Pract. Constraint Program. Int. Conf. Princ. Pract. Constraint ProgramG. Da Col and E. C. Teppan, \"Industrial size job shop scheduling tackled by present day CP solvers,\" in Proc. Int. Conf. Princ. Pract. Constraint Program., 2019, pp. 144-160.\n\nPOMO: Policy optimization with multiple optima for reinforcement learning. Y.-D Kwon, J Choo, B Kim, I Yoon, Y Gwon, S Min, Proc. Int. Conf. Neural Inf. Process. Syst. Int. Conf. Neural Inf. ess. SystY.-D. Kwon, J. Choo, B. Kim, I. Yoon, Y. Gwon, and S. Min, \"POMO: Policy optimization with multiple optima for reinforcement learning,\" in Proc. Int. Conf. Neural Inf. Process. Syst., 2020, pp. 21188-21198.\n", "annotations": {"author": "[{\"end\":111,\"start\":102},{\"end\":125,\"start\":112},{\"end\":137,\"start\":126},{\"end\":151,\"start\":138}]", "publisher": null, "author_last_name": "[{\"end\":110,\"start\":106},{\"end\":124,\"start\":120},{\"end\":136,\"start\":134},{\"end\":150,\"start\":147}]", "author_first_name": "[{\"end\":105,\"start\":102},{\"end\":119,\"start\":112},{\"end\":133,\"start\":126},{\"end\":146,\"start\":138}]", "author_affiliation": null, "title": "[{\"end\":86,\"start\":1},{\"end\":237,\"start\":152}]", "venue": "[{\"end\":282,\"start\":239}]", "abstract": "[{\"end\":1539,\"start\":328}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1722,\"start\":1719},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1998,\"start\":1995},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2151,\"start\":2148},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3129,\"start\":3126},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3134,\"start\":3131},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3414,\"start\":3411},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3512,\"start\":3509},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3517,\"start\":3514},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3683,\"start\":3680},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3688,\"start\":3685},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4238,\"start\":4235},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4481,\"start\":4478},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4709,\"start\":4705},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5911,\"start\":5907},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":5917,\"start\":5913},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6413,\"start\":6409},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8282,\"start\":8278},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8288,\"start\":8284},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8298,\"start\":8294},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10591,\"start\":10588},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10656,\"start\":10652},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10688,\"start\":10684},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10988,\"start\":10984},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10997,\"start\":10993},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":11016,\"start\":11012},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11122,\"start\":11118},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11143,\"start\":11139},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":11195,\"start\":11191},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11201,\"start\":11197},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11336,\"start\":11333},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11344,\"start\":11341},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11886,\"start\":11882},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":11892,\"start\":11888},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11898,\"start\":11894},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11904,\"start\":11900},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":11943,\"start\":11939},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12131,\"start\":12127},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12323,\"start\":12319},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12569,\"start\":12565},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":12773,\"start\":12769},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12896,\"start\":12892},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":13088,\"start\":13084},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13284,\"start\":13280},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13467,\"start\":13463},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14168,\"start\":14164},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14343,\"start\":14339},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":15358,\"start\":15354},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":20302,\"start\":20298},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22867,\"start\":22863},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22873,\"start\":22869},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22879,\"start\":22875},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":23117,\"start\":23113},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":23168,\"start\":23164},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":23174,\"start\":23170},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":24262,\"start\":24258},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":24364,\"start\":24360},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":26294,\"start\":26291},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":29632,\"start\":29628},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":29837,\"start\":29833},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":31017,\"start\":31013},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":31687,\"start\":31683},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":31782,\"start\":31778},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":32107,\"start\":32103},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":33208,\"start\":33207},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":33441,\"start\":33437},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":33447,\"start\":33443},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":33532,\"start\":33528},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":34010,\"start\":34006},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":34290,\"start\":34286},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":34338,\"start\":34334},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":34347,\"start\":34343},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":34402,\"start\":34398},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":35931,\"start\":35930},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":36003,\"start\":35999},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":36012,\"start\":36008},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":37493,\"start\":37492},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":37624,\"start\":37620},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":37644,\"start\":37643},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":38235,\"start\":38231},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":38244,\"start\":38240},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":39041,\"start\":39037},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":39096,\"start\":39092},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":39108,\"start\":39104},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":39114,\"start\":39110},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":39157,\"start\":39153},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":39324,\"start\":39320},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":39548,\"start\":39544},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":40321,\"start\":40317},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":40874,\"start\":40870},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":42538,\"start\":42534}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":45311,\"start\":44203},{\"attributes\":{\"id\":\"fig_1\"},\"end\":45371,\"start\":45312},{\"attributes\":{\"id\":\"fig_2\"},\"end\":45506,\"start\":45372},{\"attributes\":{\"id\":\"fig_3\"},\"end\":45550,\"start\":45507},{\"attributes\":{\"id\":\"fig_4\"},\"end\":45687,\"start\":45551},{\"attributes\":{\"id\":\"fig_5\"},\"end\":46206,\"start\":45688},{\"attributes\":{\"id\":\"fig_6\"},\"end\":46362,\"start\":46207},{\"attributes\":{\"id\":\"fig_7\"},\"end\":46395,\"start\":46363},{\"attributes\":{\"id\":\"fig_8\"},\"end\":46442,\"start\":46396},{\"attributes\":{\"id\":\"fig_9\"},\"end\":46562,\"start\":46443},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":47780,\"start\":46563},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":47959,\"start\":47781},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":48083,\"start\":47960},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":48208,\"start\":48084},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":48256,\"start\":48209},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":48299,\"start\":48257}]", "paragraph": "[{\"end\":3518,\"start\":1558},{\"end\":6414,\"start\":3520},{\"end\":7283,\"start\":6416},{\"end\":8787,\"start\":7285},{\"end\":9269,\"start\":8789},{\"end\":10317,\"start\":9271},{\"end\":10444,\"start\":10339},{\"end\":11589,\"start\":10477},{\"end\":12688,\"start\":11625},{\"end\":13522,\"start\":12690},{\"end\":14639,\"start\":13524},{\"end\":15238,\"start\":14662},{\"end\":15376,\"start\":15321},{\"end\":16184,\"start\":15439},{\"end\":17085,\"start\":16199},{\"end\":17596,\"start\":17108},{\"end\":17854,\"start\":17598},{\"end\":18328,\"start\":18230},{\"end\":18512,\"start\":18330},{\"end\":18909,\"start\":18730},{\"end\":19199,\"start\":18911},{\"end\":19452,\"start\":19201},{\"end\":19639,\"start\":19512},{\"end\":19931,\"start\":19641},{\"end\":20902,\"start\":19958},{\"end\":21866,\"start\":20904},{\"end\":22601,\"start\":21868},{\"end\":23936,\"start\":22643},{\"end\":24572,\"start\":23938},{\"end\":24903,\"start\":24612},{\"end\":25081,\"start\":24956},{\"end\":25974,\"start\":25113},{\"end\":26370,\"start\":26018},{\"end\":26856,\"start\":26413},{\"end\":27125,\"start\":27030},{\"end\":27761,\"start\":27127},{\"end\":27985,\"start\":27817},{\"end\":28551,\"start\":28008},{\"end\":28776,\"start\":28603},{\"end\":29795,\"start\":28863},{\"end\":30667,\"start\":29811},{\"end\":30797,\"start\":30686},{\"end\":32108,\"start\":30799},{\"end\":34558,\"start\":32110},{\"end\":35237,\"start\":34633},{\"end\":36805,\"start\":35287},{\"end\":37364,\"start\":36865},{\"end\":37837,\"start\":37366},{\"end\":38636,\"start\":37839},{\"end\":39567,\"start\":38676},{\"end\":41362,\"start\":39569},{\"end\":42770,\"start\":41381},{\"end\":42962,\"start\":42817},{\"end\":43654,\"start\":42964},{\"end\":44202,\"start\":43656}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15320,\"start\":15239},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15438,\"start\":15377},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18229,\"start\":17855},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18729,\"start\":18513},{\"attributes\":{\"id\":\"formula_4\"},\"end\":19511,\"start\":19453},{\"attributes\":{\"id\":\"formula_5\"},\"end\":24611,\"start\":24573},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24955,\"start\":24904},{\"attributes\":{\"id\":\"formula_7\"},\"end\":25112,\"start\":25082},{\"attributes\":{\"id\":\"formula_8\"},\"end\":26017,\"start\":25975},{\"attributes\":{\"id\":\"formula_9\"},\"end\":26412,\"start\":26371},{\"attributes\":{\"id\":\"formula_10\"},\"end\":26931,\"start\":26857},{\"attributes\":{\"id\":\"formula_11\"},\"end\":27029,\"start\":26931},{\"attributes\":{\"id\":\"formula_12\"},\"end\":27816,\"start\":27762},{\"attributes\":{\"id\":\"formula_13\"},\"end\":28602,\"start\":28552},{\"attributes\":{\"id\":\"formula_14\"},\"end\":28862,\"start\":28777},{\"attributes\":{\"id\":\"formula_15\"},\"end\":34592,\"start\":34559}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":31039,\"start\":31032},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":31178,\"start\":31171},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":31927,\"start\":31920},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":35326,\"start\":35318},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":37141,\"start\":37132},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":37396,\"start\":37388},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":38979,\"start\":38972},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":39594,\"start\":39587},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":39867,\"start\":39860}]", "section_header": "[{\"end\":1556,\"start\":1541},{\"end\":10337,\"start\":10320},{\"end\":10475,\"start\":10447},{\"end\":11623,\"start\":11592},{\"end\":14660,\"start\":14642},{\"end\":16197,\"start\":16187},{\"end\":17106,\"start\":17088},{\"end\":19956,\"start\":19934},{\"end\":22641,\"start\":22604},{\"end\":28006,\"start\":27988},{\"end\":29809,\"start\":29798},{\"end\":30684,\"start\":30670},{\"end\":34631,\"start\":34594},{\"end\":35285,\"start\":35240},{\"end\":36863,\"start\":36808},{\"end\":38674,\"start\":38639},{\"end\":41379,\"start\":41365},{\"end\":42815,\"start\":42773},{\"end\":45321,\"start\":45313},{\"end\":45381,\"start\":45373},{\"end\":45516,\"start\":45508},{\"end\":45560,\"start\":45552},{\"end\":45697,\"start\":45689},{\"end\":46372,\"start\":46364},{\"end\":46405,\"start\":46397},{\"end\":46452,\"start\":46444},{\"end\":47798,\"start\":47782},{\"end\":47977,\"start\":47961},{\"end\":48102,\"start\":48085},{\"end\":48222,\"start\":48210},{\"end\":48273,\"start\":48258}]", "table": "[{\"end\":48256,\"start\":48253}]", "figure_caption": "[{\"end\":45311,\"start\":44205},{\"end\":45371,\"start\":45323},{\"end\":45506,\"start\":45383},{\"end\":45550,\"start\":45518},{\"end\":45687,\"start\":45562},{\"end\":46206,\"start\":45699},{\"end\":46362,\"start\":46209},{\"end\":46395,\"start\":46374},{\"end\":46442,\"start\":46407},{\"end\":46562,\"start\":46454},{\"end\":47780,\"start\":46565},{\"end\":47959,\"start\":47800},{\"end\":48083,\"start\":47980},{\"end\":48208,\"start\":48106},{\"end\":48253,\"start\":48225},{\"end\":48299,\"start\":48275}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":5763,\"start\":5757},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16183,\"start\":16177},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16543,\"start\":16537},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20589,\"start\":20583},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":23526,\"start\":23520},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":30369,\"start\":30363},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":34804,\"start\":34798},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":36286,\"start\":36280}]", "bib_author_first_name": "[{\"end\":48418,\"start\":48417},{\"end\":48428,\"start\":48427},{\"end\":48671,\"start\":48670},{\"end\":48682,\"start\":48681},{\"end\":48686,\"start\":48683},{\"end\":48694,\"start\":48693},{\"end\":49014,\"start\":49013},{\"end\":49021,\"start\":49020},{\"end\":49029,\"start\":49028},{\"end\":49031,\"start\":49030},{\"end\":49039,\"start\":49038},{\"end\":49045,\"start\":49044},{\"end\":49333,\"start\":49332},{\"end\":49341,\"start\":49340},{\"end\":49349,\"start\":49348},{\"end\":49356,\"start\":49355},{\"end\":49364,\"start\":49363},{\"end\":49370,\"start\":49369},{\"end\":49700,\"start\":49699},{\"end\":49709,\"start\":49708},{\"end\":49717,\"start\":49716},{\"end\":49724,\"start\":49723},{\"end\":50063,\"start\":50062},{\"end\":50070,\"start\":50069},{\"end\":50077,\"start\":50076},{\"end\":50086,\"start\":50085},{\"end\":50094,\"start\":50093},{\"end\":50101,\"start\":50100},{\"end\":50411,\"start\":50410},{\"end\":50418,\"start\":50417},{\"end\":50425,\"start\":50424},{\"end\":50433,\"start\":50432},{\"end\":50439,\"start\":50438},{\"end\":50704,\"start\":50703},{\"end\":50713,\"start\":50712},{\"end\":50721,\"start\":50720},{\"end\":50728,\"start\":50727},{\"end\":50735,\"start\":50734},{\"end\":51028,\"start\":51027},{\"end\":51036,\"start\":51035},{\"end\":51038,\"start\":51037},{\"end\":51320,\"start\":51316},{\"end\":51330,\"start\":51326},{\"end\":51341,\"start\":51337},{\"end\":51352,\"start\":51348},{\"end\":51684,\"start\":51680},{\"end\":51694,\"start\":51690},{\"end\":51706,\"start\":51702},{\"end\":51986,\"start\":51985},{\"end\":52259,\"start\":52258},{\"end\":52268,\"start\":52267},{\"end\":52276,\"start\":52275},{\"end\":52283,\"start\":52282},{\"end\":52292,\"start\":52291},{\"end\":52294,\"start\":52293},{\"end\":52301,\"start\":52300},{\"end\":52724,\"start\":52723},{\"end\":52732,\"start\":52731},{\"end\":52740,\"start\":52739},{\"end\":52747,\"start\":52746},{\"end\":52754,\"start\":52753},{\"end\":53090,\"start\":53086},{\"end\":53098,\"start\":53097},{\"end\":53106,\"start\":53105},{\"end\":53114,\"start\":53113},{\"end\":53122,\"start\":53121},{\"end\":53130,\"start\":53129},{\"end\":53519,\"start\":53518},{\"end\":53527,\"start\":53526},{\"end\":53534,\"start\":53533},{\"end\":53822,\"start\":53821},{\"end\":53829,\"start\":53828},{\"end\":53837,\"start\":53836},{\"end\":53844,\"start\":53843},{\"end\":54186,\"start\":54185},{\"end\":54621,\"start\":54620},{\"end\":54631,\"start\":54630},{\"end\":54642,\"start\":54641},{\"end\":55010,\"start\":55009},{\"end\":55020,\"start\":55019},{\"end\":55022,\"start\":55021},{\"end\":55032,\"start\":55031},{\"end\":55041,\"start\":55040},{\"end\":55428,\"start\":55427},{\"end\":55430,\"start\":55429},{\"end\":55439,\"start\":55438},{\"end\":55441,\"start\":55440},{\"end\":55455,\"start\":55454},{\"end\":55457,\"start\":55456},{\"end\":55468,\"start\":55467},{\"end\":55481,\"start\":55480},{\"end\":55849,\"start\":55848},{\"end\":55858,\"start\":55857},{\"end\":55865,\"start\":55864},{\"end\":56156,\"start\":56155},{\"end\":56167,\"start\":56166},{\"end\":56434,\"start\":56433},{\"end\":56708,\"start\":56707},{\"end\":56718,\"start\":56714},{\"end\":57013,\"start\":57012},{\"end\":57021,\"start\":57020},{\"end\":57029,\"start\":57028},{\"end\":57035,\"start\":57034},{\"end\":57357,\"start\":57356},{\"end\":57368,\"start\":57367},{\"end\":57370,\"start\":57369},{\"end\":57640,\"start\":57639},{\"end\":57954,\"start\":57953},{\"end\":57961,\"start\":57960},{\"end\":57968,\"start\":57967},{\"end\":57976,\"start\":57975},{\"end\":57983,\"start\":57982},{\"end\":58242,\"start\":58241},{\"end\":58542,\"start\":58541},{\"end\":58549,\"start\":58548},{\"end\":58557,\"start\":58556},{\"end\":58565,\"start\":58564},{\"end\":58935,\"start\":58934},{\"end\":58941,\"start\":58940},{\"end\":58948,\"start\":58947},{\"end\":58956,\"start\":58955},{\"end\":58964,\"start\":58963},{\"end\":58973,\"start\":58972},{\"end\":58975,\"start\":58974},{\"end\":59306,\"start\":59305},{\"end\":59313,\"start\":59312},{\"end\":59322,\"start\":59321},{\"end\":59626,\"start\":59625},{\"end\":59633,\"start\":59632},{\"end\":59896,\"start\":59895},{\"end\":60091,\"start\":60090},{\"end\":60098,\"start\":60097},{\"end\":60107,\"start\":60106},{\"end\":60114,\"start\":60113},{\"end\":60122,\"start\":60121},{\"end\":60124,\"start\":60123},{\"end\":60453,\"start\":60452},{\"end\":60459,\"start\":60458},{\"end\":60468,\"start\":60467},{\"end\":60476,\"start\":60475},{\"end\":60749,\"start\":60748},{\"end\":60756,\"start\":60755},{\"end\":60763,\"start\":60762},{\"end\":60772,\"start\":60771},{\"end\":60986,\"start\":60985},{\"end\":61000,\"start\":60999},{\"end\":61012,\"start\":61011},{\"end\":61024,\"start\":61023},{\"end\":61034,\"start\":61033},{\"end\":61041,\"start\":61040},{\"end\":61324,\"start\":61323},{\"end\":61332,\"start\":61331},{\"end\":61344,\"start\":61343},{\"end\":61606,\"start\":61605},{\"end\":61618,\"start\":61617},{\"end\":61628,\"start\":61627},{\"end\":61640,\"start\":61639},{\"end\":61651,\"start\":61650},{\"end\":61886,\"start\":61885},{\"end\":61896,\"start\":61895},{\"end\":61907,\"start\":61906},{\"end\":62178,\"start\":62177},{\"end\":62188,\"start\":62187},{\"end\":62190,\"start\":62189},{\"end\":62463,\"start\":62462},{\"end\":62476,\"start\":62475},{\"end\":62722,\"start\":62721},{\"end\":62732,\"start\":62731},{\"end\":62734,\"start\":62733},{\"end\":63092,\"start\":63088},{\"end\":63100,\"start\":63099},{\"end\":63108,\"start\":63107},{\"end\":63115,\"start\":63114},{\"end\":63123,\"start\":63122},{\"end\":63131,\"start\":63130}]", "bib_author_last_name": "[{\"end\":48425,\"start\":48419},{\"end\":48437,\"start\":48429},{\"end\":48679,\"start\":48672},{\"end\":48691,\"start\":48687},{\"end\":48705,\"start\":48695},{\"end\":49018,\"start\":49015},{\"end\":49026,\"start\":49022},{\"end\":49036,\"start\":49032},{\"end\":49042,\"start\":49040},{\"end\":49051,\"start\":49046},{\"end\":49338,\"start\":49334},{\"end\":49346,\"start\":49342},{\"end\":49353,\"start\":49350},{\"end\":49361,\"start\":49357},{\"end\":49367,\"start\":49365},{\"end\":49374,\"start\":49371},{\"end\":49706,\"start\":49701},{\"end\":49714,\"start\":49710},{\"end\":49721,\"start\":49718},{\"end\":49729,\"start\":49725},{\"end\":50067,\"start\":50064},{\"end\":50074,\"start\":50071},{\"end\":50083,\"start\":50078},{\"end\":50091,\"start\":50087},{\"end\":50098,\"start\":50095},{\"end\":50105,\"start\":50102},{\"end\":50415,\"start\":50412},{\"end\":50422,\"start\":50419},{\"end\":50430,\"start\":50426},{\"end\":50436,\"start\":50434},{\"end\":50442,\"start\":50440},{\"end\":50710,\"start\":50705},{\"end\":50718,\"start\":50714},{\"end\":50725,\"start\":50722},{\"end\":50732,\"start\":50729},{\"end\":50738,\"start\":50736},{\"end\":51033,\"start\":51029},{\"end\":51044,\"start\":51039},{\"end\":51324,\"start\":51321},{\"end\":51335,\"start\":51331},{\"end\":51346,\"start\":51342},{\"end\":51357,\"start\":51353},{\"end\":51688,\"start\":51685},{\"end\":51700,\"start\":51695},{\"end\":51712,\"start\":51707},{\"end\":51991,\"start\":51987},{\"end\":52265,\"start\":52260},{\"end\":52273,\"start\":52269},{\"end\":52280,\"start\":52277},{\"end\":52289,\"start\":52284},{\"end\":52298,\"start\":52295},{\"end\":52305,\"start\":52302},{\"end\":52729,\"start\":52725},{\"end\":52737,\"start\":52733},{\"end\":52744,\"start\":52741},{\"end\":52751,\"start\":52748},{\"end\":52759,\"start\":52755},{\"end\":53095,\"start\":53091},{\"end\":53103,\"start\":53099},{\"end\":53111,\"start\":53107},{\"end\":53119,\"start\":53115},{\"end\":53127,\"start\":53123},{\"end\":53135,\"start\":53131},{\"end\":53524,\"start\":53520},{\"end\":53531,\"start\":53528},{\"end\":53543,\"start\":53535},{\"end\":53826,\"start\":53823},{\"end\":53834,\"start\":53830},{\"end\":53841,\"start\":53838},{\"end\":53850,\"start\":53845},{\"end\":54189,\"start\":54187},{\"end\":54628,\"start\":54622},{\"end\":54639,\"start\":54632},{\"end\":54648,\"start\":54643},{\"end\":55017,\"start\":55011},{\"end\":55029,\"start\":55023},{\"end\":55038,\"start\":55033},{\"end\":55047,\"start\":55042},{\"end\":55436,\"start\":55431},{\"end\":55452,\"start\":55442},{\"end\":55465,\"start\":55458},{\"end\":55478,\"start\":55469},{\"end\":55490,\"start\":55482},{\"end\":55855,\"start\":55850},{\"end\":55862,\"start\":55859},{\"end\":55869,\"start\":55866},{\"end\":56164,\"start\":56157},{\"end\":56173,\"start\":56168},{\"end\":56445,\"start\":56435},{\"end\":56712,\"start\":56709},{\"end\":56721,\"start\":56719},{\"end\":57018,\"start\":57014},{\"end\":57026,\"start\":57022},{\"end\":57032,\"start\":57030},{\"end\":57040,\"start\":57036},{\"end\":57365,\"start\":57358},{\"end\":57379,\"start\":57371},{\"end\":57650,\"start\":57641},{\"end\":57958,\"start\":57955},{\"end\":57965,\"start\":57962},{\"end\":57973,\"start\":57969},{\"end\":57980,\"start\":57977},{\"end\":57988,\"start\":57984},{\"end\":58250,\"start\":58243},{\"end\":58546,\"start\":58543},{\"end\":58554,\"start\":58550},{\"end\":58562,\"start\":58558},{\"end\":58568,\"start\":58566},{\"end\":58938,\"start\":58936},{\"end\":58945,\"start\":58942},{\"end\":58953,\"start\":58949},{\"end\":58961,\"start\":58957},{\"end\":58970,\"start\":58965},{\"end\":58982,\"start\":58976},{\"end\":59310,\"start\":59307},{\"end\":59319,\"start\":59314},{\"end\":59326,\"start\":59323},{\"end\":59630,\"start\":59627},{\"end\":59638,\"start\":59634},{\"end\":59908,\"start\":59897},{\"end\":60095,\"start\":60092},{\"end\":60104,\"start\":60099},{\"end\":60111,\"start\":60108},{\"end\":60119,\"start\":60115},{\"end\":60128,\"start\":60125},{\"end\":60456,\"start\":60454},{\"end\":60465,\"start\":60460},{\"end\":60473,\"start\":60469},{\"end\":60481,\"start\":60477},{\"end\":60753,\"start\":60750},{\"end\":60760,\"start\":60757},{\"end\":60769,\"start\":60764},{\"end\":60777,\"start\":60773},{\"end\":60997,\"start\":60987},{\"end\":61009,\"start\":61001},{\"end\":61021,\"start\":61013},{\"end\":61031,\"start\":61025},{\"end\":61038,\"start\":61035},{\"end\":61048,\"start\":61042},{\"end\":61329,\"start\":61325},{\"end\":61341,\"start\":61333},{\"end\":61352,\"start\":61345},{\"end\":61615,\"start\":61607},{\"end\":61625,\"start\":61619},{\"end\":61637,\"start\":61629},{\"end\":61648,\"start\":61641},{\"end\":61658,\"start\":61652},{\"end\":61893,\"start\":61887},{\"end\":61904,\"start\":61897},{\"end\":61913,\"start\":61908},{\"end\":62185,\"start\":62179},{\"end\":62197,\"start\":62191},{\"end\":62473,\"start\":62464},{\"end\":62491,\"start\":62477},{\"end\":62729,\"start\":62723},{\"end\":62741,\"start\":62735},{\"end\":63097,\"start\":63093},{\"end\":63105,\"start\":63101},{\"end\":63112,\"start\":63109},{\"end\":63120,\"start\":63116},{\"end\":63128,\"start\":63124},{\"end\":63135,\"start\":63132}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":54950058},\"end\":48580,\"start\":48362},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":233585545},\"end\":48934,\"start\":48582},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":115506718},\"end\":49263,\"start\":48936},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":202773771},\"end\":49602,\"start\":49265},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":37749060},\"end\":49950,\"start\":49604},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":195831298},\"end\":50368,\"start\":49952},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":196179021},\"end\":50617,\"start\":50370},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":117274376},\"end\":50948,\"start\":50619},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":62771404},\"end\":51230,\"start\":50950},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":132741897},\"end\":51595,\"start\":51232},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":216588142},\"end\":51897,\"start\":51597},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":233354780},\"end\":52178,\"start\":51899},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":225062395},\"end\":52591,\"start\":52180},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":234053468},\"end\":53020,\"start\":52593},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":235490054},\"end\":53408,\"start\":53022},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":220069856},\"end\":53758,\"start\":53410},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":229516324},\"end\":54053,\"start\":53760},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":236980306},\"end\":54522,\"start\":54055},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":10523876},\"end\":54863,\"start\":54524},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":246459769},\"end\":55316,\"start\":54865},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":4706913},\"end\":55752,\"start\":55318},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":112331935},\"end\":56077,\"start\":55754},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":28562567},\"end\":56345,\"start\":56079},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":7257020},\"end\":56616,\"start\":56347},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":13166600},\"end\":56902,\"start\":56618},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":225212609},\"end\":57279,\"start\":56904},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":214137660},\"end\":57568,\"start\":57281},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":46968780},\"end\":57857,\"start\":57570},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":213912555},\"end\":58212,\"start\":57859},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":13756489},\"end\":58444,\"start\":58214},{\"attributes\":{\"doi\":\"10.1109/TETCI.2021.3098354\",\"id\":\"b30\",\"matched_paper_id\":240480973},\"end\":58883,\"start\":58446},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":57375753},\"end\":59214,\"start\":58885},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":237284264},\"end\":59536,\"start\":59216},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":236299290},\"end\":59831,\"start\":59538},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":33443952},\"end\":60060,\"start\":59833},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":202763464},\"end\":60367,\"start\":60062},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":211031947},\"end\":60685,\"start\":60369},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":235324868},\"end\":60957,\"start\":60687},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":3292002},\"end\":61276,\"start\":60959},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":59608816},\"end\":61562,\"start\":61278},{\"attributes\":{\"doi\":\"arXiv:1707.06347\",\"id\":\"b40\"},\"end\":61806,\"start\":61564},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":15310204},\"end\":62096,\"start\":61808},{\"attributes\":{\"doi\":\"RR-12-01-01\",\"id\":\"b42\",\"matched_paper_id\":54531116},\"end\":62419,\"start\":62098},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":109281248},\"end\":62648,\"start\":62421},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":202728762},\"end\":63011,\"start\":62650},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":226222332},\"end\":63419,\"start\":63013}]", "bib_title": "[{\"end\":48415,\"start\":48362},{\"end\":48668,\"start\":48582},{\"end\":49011,\"start\":48936},{\"end\":49330,\"start\":49265},{\"end\":49697,\"start\":49604},{\"end\":50060,\"start\":49952},{\"end\":50408,\"start\":50370},{\"end\":50701,\"start\":50619},{\"end\":51025,\"start\":50950},{\"end\":51314,\"start\":51232},{\"end\":51678,\"start\":51597},{\"end\":51983,\"start\":51899},{\"end\":52256,\"start\":52180},{\"end\":52721,\"start\":52593},{\"end\":53084,\"start\":53022},{\"end\":53516,\"start\":53410},{\"end\":53819,\"start\":53760},{\"end\":54183,\"start\":54055},{\"end\":54618,\"start\":54524},{\"end\":55007,\"start\":54865},{\"end\":55425,\"start\":55318},{\"end\":55846,\"start\":55754},{\"end\":56153,\"start\":56079},{\"end\":56431,\"start\":56347},{\"end\":56705,\"start\":56618},{\"end\":57010,\"start\":56904},{\"end\":57354,\"start\":57281},{\"end\":57637,\"start\":57570},{\"end\":57951,\"start\":57859},{\"end\":58239,\"start\":58214},{\"end\":58539,\"start\":58446},{\"end\":58932,\"start\":58885},{\"end\":59303,\"start\":59216},{\"end\":59623,\"start\":59538},{\"end\":59893,\"start\":59833},{\"end\":60088,\"start\":60062},{\"end\":60450,\"start\":60369},{\"end\":60746,\"start\":60687},{\"end\":60983,\"start\":60959},{\"end\":61321,\"start\":61278},{\"end\":61883,\"start\":61808},{\"end\":62175,\"start\":62098},{\"end\":62460,\"start\":62421},{\"end\":62719,\"start\":62650},{\"end\":63086,\"start\":63013}]", "bib_author": "[{\"end\":48427,\"start\":48417},{\"end\":48439,\"start\":48427},{\"end\":48681,\"start\":48670},{\"end\":48693,\"start\":48681},{\"end\":48707,\"start\":48693},{\"end\":49020,\"start\":49013},{\"end\":49028,\"start\":49020},{\"end\":49038,\"start\":49028},{\"end\":49044,\"start\":49038},{\"end\":49053,\"start\":49044},{\"end\":49340,\"start\":49332},{\"end\":49348,\"start\":49340},{\"end\":49355,\"start\":49348},{\"end\":49363,\"start\":49355},{\"end\":49369,\"start\":49363},{\"end\":49376,\"start\":49369},{\"end\":49708,\"start\":49699},{\"end\":49716,\"start\":49708},{\"end\":49723,\"start\":49716},{\"end\":49731,\"start\":49723},{\"end\":50069,\"start\":50062},{\"end\":50076,\"start\":50069},{\"end\":50085,\"start\":50076},{\"end\":50093,\"start\":50085},{\"end\":50100,\"start\":50093},{\"end\":50107,\"start\":50100},{\"end\":50417,\"start\":50410},{\"end\":50424,\"start\":50417},{\"end\":50432,\"start\":50424},{\"end\":50438,\"start\":50432},{\"end\":50444,\"start\":50438},{\"end\":50712,\"start\":50703},{\"end\":50720,\"start\":50712},{\"end\":50727,\"start\":50720},{\"end\":50734,\"start\":50727},{\"end\":50740,\"start\":50734},{\"end\":51035,\"start\":51027},{\"end\":51046,\"start\":51035},{\"end\":51326,\"start\":51316},{\"end\":51337,\"start\":51326},{\"end\":51348,\"start\":51337},{\"end\":51359,\"start\":51348},{\"end\":51690,\"start\":51680},{\"end\":51702,\"start\":51690},{\"end\":51714,\"start\":51702},{\"end\":51993,\"start\":51985},{\"end\":52267,\"start\":52258},{\"end\":52275,\"start\":52267},{\"end\":52282,\"start\":52275},{\"end\":52291,\"start\":52282},{\"end\":52300,\"start\":52291},{\"end\":52307,\"start\":52300},{\"end\":52731,\"start\":52723},{\"end\":52739,\"start\":52731},{\"end\":52746,\"start\":52739},{\"end\":52753,\"start\":52746},{\"end\":52761,\"start\":52753},{\"end\":53097,\"start\":53086},{\"end\":53105,\"start\":53097},{\"end\":53113,\"start\":53105},{\"end\":53121,\"start\":53113},{\"end\":53129,\"start\":53121},{\"end\":53137,\"start\":53129},{\"end\":53526,\"start\":53518},{\"end\":53533,\"start\":53526},{\"end\":53545,\"start\":53533},{\"end\":53828,\"start\":53821},{\"end\":53836,\"start\":53828},{\"end\":53843,\"start\":53836},{\"end\":53852,\"start\":53843},{\"end\":54191,\"start\":54185},{\"end\":54630,\"start\":54620},{\"end\":54641,\"start\":54630},{\"end\":54650,\"start\":54641},{\"end\":55019,\"start\":55009},{\"end\":55031,\"start\":55019},{\"end\":55040,\"start\":55031},{\"end\":55049,\"start\":55040},{\"end\":55438,\"start\":55427},{\"end\":55454,\"start\":55438},{\"end\":55467,\"start\":55454},{\"end\":55480,\"start\":55467},{\"end\":55492,\"start\":55480},{\"end\":55857,\"start\":55848},{\"end\":55864,\"start\":55857},{\"end\":55871,\"start\":55864},{\"end\":56166,\"start\":56155},{\"end\":56175,\"start\":56166},{\"end\":56447,\"start\":56433},{\"end\":56714,\"start\":56707},{\"end\":56723,\"start\":56714},{\"end\":57020,\"start\":57012},{\"end\":57028,\"start\":57020},{\"end\":57034,\"start\":57028},{\"end\":57042,\"start\":57034},{\"end\":57367,\"start\":57356},{\"end\":57381,\"start\":57367},{\"end\":57652,\"start\":57639},{\"end\":57960,\"start\":57953},{\"end\":57967,\"start\":57960},{\"end\":57975,\"start\":57967},{\"end\":57982,\"start\":57975},{\"end\":57990,\"start\":57982},{\"end\":58252,\"start\":58241},{\"end\":58548,\"start\":58541},{\"end\":58556,\"start\":58548},{\"end\":58564,\"start\":58556},{\"end\":58570,\"start\":58564},{\"end\":58940,\"start\":58934},{\"end\":58947,\"start\":58940},{\"end\":58955,\"start\":58947},{\"end\":58963,\"start\":58955},{\"end\":58972,\"start\":58963},{\"end\":58984,\"start\":58972},{\"end\":59312,\"start\":59305},{\"end\":59321,\"start\":59312},{\"end\":59328,\"start\":59321},{\"end\":59632,\"start\":59625},{\"end\":59640,\"start\":59632},{\"end\":59910,\"start\":59895},{\"end\":60097,\"start\":60090},{\"end\":60106,\"start\":60097},{\"end\":60113,\"start\":60106},{\"end\":60121,\"start\":60113},{\"end\":60130,\"start\":60121},{\"end\":60458,\"start\":60452},{\"end\":60467,\"start\":60458},{\"end\":60475,\"start\":60467},{\"end\":60483,\"start\":60475},{\"end\":60755,\"start\":60748},{\"end\":60762,\"start\":60755},{\"end\":60771,\"start\":60762},{\"end\":60779,\"start\":60771},{\"end\":60999,\"start\":60985},{\"end\":61011,\"start\":60999},{\"end\":61023,\"start\":61011},{\"end\":61033,\"start\":61023},{\"end\":61040,\"start\":61033},{\"end\":61050,\"start\":61040},{\"end\":61331,\"start\":61323},{\"end\":61343,\"start\":61331},{\"end\":61354,\"start\":61343},{\"end\":61617,\"start\":61605},{\"end\":61627,\"start\":61617},{\"end\":61639,\"start\":61627},{\"end\":61650,\"start\":61639},{\"end\":61660,\"start\":61650},{\"end\":61895,\"start\":61885},{\"end\":61906,\"start\":61895},{\"end\":61915,\"start\":61906},{\"end\":62187,\"start\":62177},{\"end\":62199,\"start\":62187},{\"end\":62475,\"start\":62462},{\"end\":62493,\"start\":62475},{\"end\":62731,\"start\":62721},{\"end\":62743,\"start\":62731},{\"end\":63099,\"start\":63088},{\"end\":63107,\"start\":63099},{\"end\":63114,\"start\":63107},{\"end\":63122,\"start\":63114},{\"end\":63130,\"start\":63122},{\"end\":63137,\"start\":63130}]", "bib_venue": "[{\"end\":48452,\"start\":48439},{\"end\":48726,\"start\":48707},{\"end\":49070,\"start\":49053},{\"end\":49401,\"start\":49376},{\"end\":49751,\"start\":49731},{\"end\":50132,\"start\":50107},{\"end\":50469,\"start\":50444},{\"end\":50756,\"start\":50740},{\"end\":51064,\"start\":51046},{\"end\":51384,\"start\":51359},{\"end\":51725,\"start\":51714},{\"end\":52005,\"start\":51993},{\"end\":52349,\"start\":52307},{\"end\":52778,\"start\":52761},{\"end\":53179,\"start\":53137},{\"end\":53558,\"start\":53545},{\"end\":53877,\"start\":53852},{\"end\":54245,\"start\":54191},{\"end\":54667,\"start\":54650},{\"end\":55066,\"start\":55049},{\"end\":55506,\"start\":55492},{\"end\":55888,\"start\":55871},{\"end\":56192,\"start\":56175},{\"end\":56464,\"start\":56447},{\"end\":56740,\"start\":56723},{\"end\":57058,\"start\":57042},{\"end\":57398,\"start\":57381},{\"end\":57672,\"start\":57652},{\"end\":58007,\"start\":57990},{\"end\":58294,\"start\":58252},{\"end\":58636,\"start\":58596},{\"end\":59020,\"start\":58984},{\"end\":59344,\"start\":59328},{\"end\":59660,\"start\":59640},{\"end\":59924,\"start\":59910},{\"end\":60172,\"start\":60130},{\"end\":60504,\"start\":60483},{\"end\":60800,\"start\":60779},{\"end\":61089,\"start\":61050},{\"end\":61393,\"start\":61354},{\"end\":61603,\"start\":61564},{\"end\":61926,\"start\":61915},{\"end\":62229,\"start\":62210},{\"end\":62510,\"start\":62493},{\"end\":62792,\"start\":62743},{\"end\":63179,\"start\":63137},{\"end\":52383,\"start\":52351},{\"end\":53213,\"start\":53181},{\"end\":54295,\"start\":54247},{\"end\":57688,\"start\":57674},{\"end\":58328,\"start\":58296},{\"end\":60206,\"start\":60174},{\"end\":60521,\"start\":60506},{\"end\":60817,\"start\":60802},{\"end\":61124,\"start\":61091},{\"end\":61428,\"start\":61395},{\"end\":62837,\"start\":62794},{\"end\":63213,\"start\":63181}]"}}}, "year": 2023, "month": 12, "day": 17}