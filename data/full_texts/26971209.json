{"id": 26971209, "updated": "2023-03-25 19:14:09.344", "metadata": {"title": "Detecting User Story Information in Developer-Client Conversations to Generate Extractive Summaries", "authors": "[{\"first\":\"Paige\",\"last\":\"Rodeghero\",\"middle\":[]},{\"first\":\"Siyuan\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Ameer\",\"last\":\"Armaly\",\"middle\":[]},{\"first\":\"Collin\",\"last\":\"McMillan\",\"middle\":[]}]", "venue": "2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)", "journal": "2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)", "publication_date": {"year": 2017, "month": null, "day": null}, "abstract": "User stories are descriptions of functionality that a software user needs. They play an important role in determining which software requirements and bug fixes should be handled and in what order. Developers elicit user stories through meetings with customers. But user story elicitation is complex, and involves many passes to accommodate shifting and unclear customer needs. The result is that developers must take detailed notes during meetings or risk missing important information. Ideally, developers would be freed of the need to take notes themselves, and instead speak naturally with their customers. This paper is a step towards that ideal. We present a technique for automatically extracting information relevant to user stories from recorded conversations between customers and developers. We perform a qualitative study to demonstrate that user story information exists in these conversations in a sufficient quantity to extract automatically. From this, we found that roughly 10.2% of these conversations contained user story information. Then, we test our technique in a quantitative study to determine the degree to which our technique can extract user story information. In our experiment, our process obtained about 70.8% precision and 18.3% recall on the information.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2619636279", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icse/RodegheroJAM17", "doi": "10.1109/icse.2017.13"}}, "content": {"source": {"pdf_hash": "e15730a8bf68afaabbc4773f680a20a17acf0363", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "f5c1a609b6d69c084f3a9ee4da81be2331994147", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/e15730a8bf68afaabbc4773f680a20a17acf0363.txt", "contents": "\nDetecting User Story Information in Developer-Client Conversations to Generate Extractive Summaries\n\n\nPaige Rodeghero prodeghe@nd.edu \nDepartment of Computer Science and Engineering\nUniversity of Notre Dame Notre Dame\nINUSA\n\nSiyuan Jiang sjiang1@nd.edu \nDepartment of Computer Science and Engineering\nUniversity of Notre Dame Notre Dame\nINUSA\n\nAmeer Armaly aarmaly@nd.edu \nDepartment of Computer Science and Engineering\nUniversity of Notre Dame Notre Dame\nINUSA\n\nCollin Mcmillan \nDepartment of Computer Science and Engineering\nUniversity of Notre Dame Notre Dame\nINUSA\n\nDetecting User Story Information in Developer-Client Conversations to Generate Extractive Summaries\n10.1109/ICSE.2017.13\nUser stories are descriptions of functionality that a software user needs. They play an important role in determining which software requirements and bug fixes should be handled and in what order. Developers elicit user stories through meetings with customers. But user story elicitation is complex, and involves many passes to accommodate shifting and unclear customer needs. The result is that developers must take detailed notes during meetings or risk missing important information. Ideally, developers would be freed of the need to take notes themselves, and instead speak naturally with their customers. This paper is a step towards that ideal. We present a technique for automatically extracting information relevant to user stories from recorded conversations between customers and developers. We perform a qualitative study to demonstrate that user story information exists in these conversations in a sufficient quantity to extract automatically. From this, we found that roughly 10.2% of these conversations contained user story information. Then, we test our technique in a quantitative study to determine the degree to which our technique can extract user story information. In our experiment, our process obtained about 70.8% precision and 18.3% recall on the information.\n\nI. INTRODUCTION\n\nA user story is a description of software functionality from the perspective of the software's user [1]. User story management is under the umbrella of requirements engineering, but a user story is different from a requirement in the traditional sense, because a story usually contains no information about how the software should be implemented. Instead, the story focuses on user experience, including the role, function, and rationale behind the user's objective in the format \"as a \u00a1role\u00bf, I want to \u00a1function\u00bf, so that I can \u00a1rationale\u00bf.\" For example, instead of a requirement \"the system shall use a SQL database to store recently sold home prices\", a user story might say \"as a homebuyer, I want to search for recently sold homes, so I can estimate prices in my area. \" Cohn [1] points out that the typical source of user stories is careful analysis of the conversations between programmers and customers. Since user stories do not contain implementation details, conversations with customers are an effective place to search for user stories. Developers are advised to take notes during conversations and reread these notes to write user stories by hand. This process is important because stories play a crucial role in Agile development, where release cycles are often short to accomodate the constantly-evolving needs of customers. The result is that developers are in a constant process of user story elicitation, as stories appear, mature, and are removed [2].\n\nWhile there is an emphasis on by-hand effort for writing user stories in practice, software engineering literature describes automated summarization techniques for knowledge extraction from software artifacts. Notably, Rastkar et al. [3], [4] (ICSE 2010) built an algorithm for summarizing software artifacts, and tested the algorithm on a corpus of bug reports. That approach was based on earlier work by Murray and Carenini [5] designed to summarize emails and conversations. In a nutshell, these approaches are machine learning classifiers that are trained to recognize sentences in documents that are likely to contain certain types of information important to the summary. The performance was considered reasonable by human evaluators, at approximately 50% precision and 30% recall (see Section II-D for a more detailed discussion).\n\nIn this paper, we automatically extract data for writing user stories from records of conversations between developers and customers. Specifically, we 1) perform a qualitative study to test the hypothesis that conversations between developers and customers contain role, function, and rationale information for user stories, and 2) perform a quantitative study to determine the degree to which an existing classification algorithm can be trained to recognize this information in the conversations.\n\nFor the qualitative study (Section III), we recorded approximately 24 hours of spoken conversation (27 conversations total) between developers and customers over a period of three weeks at a software development company in the United States with between 30 and 50 employees. We then transcribed the recorded conversations to text, and manually annotated sections of the conversations as containing role, function, and/or rationale information pertaining to user stories. To ensure we could compare our results with earlier work, we also annotated \"extractive summaries\" for each conversation (see Section II-C for details on these summaries). We found that about 5.5% of the conversations included function information, 2.9% discussed rationale, but only 0.5% discussed role. About 10.2% were part of the extractive summaries, which was slightly less than the 13% and 19% reported by Murray and Carenini [5] for the meeting and email corpora, respectively, and 28% reported by Rastkar et al. [3] for the bug reports. It is important to note that the Murray and Carenini meeting study, which is the most similar to our study since it also used annotated meeting transcripts, has the most similar extractive percentage. Put briefly, we found that the conversations included significant function and rationale information, but very limited data about the roles.\n\nIn the quantitative study (Section VI), we trained a classifier to recognize the function and rationale information, as well as the extractive summaries for comparision. We made numerous modifications from the technique described by Rastkar et al. and Murray and Carenini to adapt the technique to detect function and rationale data for user stories. We describe our procedure in detail in Section V. We obtained approximately 54.5% precision 24.0% recall for detecting sections of conversations containing function data, and 25.0% precision 26.9% recall for rationale data. For comparison purposes, we obtained about 70.8% precision 18.3% recall for extractive summaries.\n\nOur long range vision for this research is to design an algorithm that generates user stories by listening to the conversations between developers and customers. The algorithm could, for example, be installed into teleconferencing software to automatically create notes about user stories for developers after a meeting. The technique we present in this paper is a research prototype in that direction; to be usable, it would need an automated transcriptionist and a natural language generation system to create \"abstractive\" user stories from the extractive data we currently can provide. Still, it is our view that this paper is a vital early step.\n\nTo facilitate reproducibility and assist other researchers, we have made our implementation available via an online appendix 1 , including a virtual machine image with all dependencies installed. While we cannot release the recordings of the meetings for ethical and privacy reasons, we do provide our trained classifier so that it can be tested on other datasets. To our knowledge, no public records of meetings with user story information are available, but for comparision purposes, we duplicate our quantitative experiments for extractive summaries on the public AMI meeting corpus [6].\n\n\nII. BACKGROUND AND RELATED WORK\n\nThis section describes supporting technologies for this research, as well as related literature. Note that these technologies have been proposed and evaluated in previous work. We include them here because our work is based on these earlier techniques.\n\n\nA. User Story Elicitation\n\nUser stories play a crucial role in Agile development, where programming activities are centered around the needs of customers. In a \"textbook\" Agile environment, developers 1 http://www3.nd.edu/ \u223c prodeghe/projects/userstories/ elicit user stories through contact with customers, prioritize these stories, and schedule tasks in release cycles based on the stories. One characteristic of Agile development is a relatively short release cycle that is responsive to changing requirements [7]. The result is that developers are in a constant process of user story elicitation, as stories appear, mature, and are removed.\n\nThis process of elicitation is often messy: customers may have difficulty articulating their own needs, and developers may miss opportunities to ask clarifying questions or highlight important problems. Cohn [1] reinforces an opinion by Robertson and Robertson [2] that elicitation is akin to trawling for fish, as numerous passes are needed with different tools and techniques in order to catch as many user stories as possible. Nevertheless, Cohn [1] points out that a key component of user story elicitation is careful analysis of the conversations between programmers and customers. Developers are advised to take notes during conversations and reread these notes to write user stories by hand. Some researchers, such as Berenbach et al. [8], are even trying to introduce unique frameworks to better capture and analyze these elicitations.\n\n\nB. Turn-based Conversation Analysis\n\nIn this paper, we use turns instead of sentences as the unit of analysis. This section defines these terms and outlines our motivation for using turns.\n\nOne important characteristic of the work by Rastkar et al. is that it is based on the sentences in the bug reports. The extractive summaries are a subset of the sentences in the bug reports. Likewise, the work by Murray and Carenini creates summaries from the sentences in emails and transcripts. For written text and some types of spoken text, sentence-based analysis is ideal because the boundaries between sentences are clear, and written sentences tend to contain cohesive information [9].\n\nIn contrast, the preferred unit of analysis for most types of spoken language is the turn, as noted by numerous authors in the field of conversation analysis in sociology [9], [10], [11], [12], [13]. A turn is the unit of speech that occurs when a person speaks in a conversation, between other speakers. In ordinary conversation, people take turns speaking and listening to others speak. Turns are different than sentences in that turns are dependent on the context in which the speaker takes a turn, and the speaker's own immediate thoughts and reactions. Human factors are present in spoken turns to a higher level than written sentences; social rank, confusion, number of listeners, etc., affect the length, order, and content of turns.\n\nTranscriptionists are tasked with creating written sentences from spoken language. They will typically divide each turn into multiple sentences, marking punctuation including periods and commas. But this is a highly subjective process, since speakers may repeat or rephrase information, or fill gaps while thinking with \"hmms\" and \"uhhs.\" The listeners in a conversation will typically defer to a speaker to finish a turn, even if the turn contains unfinished or run-on sentences.\n\nOur view is that role, function, and rationale information are much more likely to be detectable in turn-based analysis than sentence-based. The reason is that in a conversation, a customer may struggle to describe, for example, the function that he or she needs. The customer may describe a situation in many ways, splitting important information over several sentences or partial sentences. The developers will listen carefully during the customer's turn, to allow the customer to finish his or her thought. In these situations, it is far more useful to have the entire turn, rather than try to detect a single sentence which contains all the necessary information -such a sentence may not exist.\n\n\nC. Summarization and Knowledge Extraction\n\nSummarization is the process of creating a short description of a longer artifact [14], [15]. There are two types of summaries: extractive and abstractive. An extractive summary is a summary created out of pieces of the larger artifact. Sentence selection is a form of extractive summary generation, because it picks one sentence out of a document that describes the main points of the document [16]. A commonly-used extractive technique in software engineering research is a TF/IDF vector space model, in which the top n words are selected from a software artifact to describe that artifact [17]. In contrast, abstractive summaries are synthesized from information inside the artifact, without copying that information. Abstractive summarization is typically what humans do, as it often involves contextual information or \"in your own words\" interpretation. Nevertheless, abstractive summarization techniques do exist in the software engineering literature, such as work by McBurney et al. [18], Sridhara et al. [19], [20], [21], Moreno et al [22], [23], [24], and Buse and Weimer [25], [26]. These techniques are related to our work in that they use summarization techniques to extract knowledge from software artifacts, but differ widely in their approach, the type of data they are summarizing, and the type of artifacts they analyze. To our knowledge, we describe the first technique to automatically extract user story information from developer/customer meeting transcripts.\n\nIn this paper, we treat summarization as a form of knowledge extraction, in that a summarizer is attempting to extract and highlight a specific type of information from the larger artifact [27], [28]. We believe this is similar to, but unique from, the work done in Requirements Engineering by Cleland-Huang et al. [29] and others. In a nutshell, instead of summarizing a whole document, we aim to extract the parts of the document pertaining to the role, function, and rationale behind user stories. We apply summarization to the problem of knowledge extraction about user stories.\n\n\nD. Summarizing Software Artifacts\n\nThree key publications behind this research are by Murray and Carenini [5] in 2008, and a related advancement on that work by Rastkar et al. [3], [4] published in ICSE 2010 and TSE in 2014.\n\nMurray and Carenini describe a technique to produce extractive summaries of email threads and meeting transcripts. The technique is essentially a machine learning classification problem, in which one class of sentences includes the sentences in the extractive summaries, and another class includes all other sentences. Generally speaking, their approach occurs over three steps: 1) compute quantifiable attributes for each sentence in the emails and meetings, 2) train a logistic regression classifier to detect sentences that are in manually-annotated extractive summaries, and 3) conduct a cross-validation experiment and compute performance metrics. The experiment they conducted was a \"leave one conversation out\" format, in which they trained on all conversations except one, and then tested on the remaining conversation. One major research contribution of their work is that the attributes they computed were generic in the sense that they did not depend on domain-specific terminology. The attributes can be calculated on multi-modal conversations instead of a specific type of conversation.\n\nRastkar et al. demonstrated how to apply Murray and Carenini's multi-modal conversation summarization to software artifacts. Using the same set of attributes, Rastkar automatically generated extractive summaries for bug reports. They manually annotated 36 bug reports by marking sentences in the bug reports that belonged to extractive summaries. They recruited three programmers to annotate each bug report, and then used a voting procedure to choose a \"gold set\" of annotations for each bug report. The performance of the classification was 57% precision and 35% recall. A user study with human experts found that this performance level was acceptable, with the experts rating 3.54/5.00 that the summaries represented the important points of the bug report.\n\n\nIII. FIELD OBSERVATIONS\n\nWe conducted a series of field observations to create a corpus of meeting records between developers and customers. This section describes our methodology for collecting these observations. This section also describes our qualitative analysis of the observations, including our research questions for the qualitative study and our annotation procedure.\n\n\nA. Research Questions\n\nOur research objective in this qualitative evaluation is to test the hypothesis that conversations between developers and customers contain role, function, and rationale information. This hypothesis stems from existing literature that emphasizes the importance of customer-developer conversations in user story elicitation [1], [2]. Specifically, it is important that we know whether our dataset contains this information to prepare for our quantitative analysis in Section VI. Therefore, we ask the following Research Questions (RQs): RQ 1 What percent of the turns in the conversations contain role information, function information, and rationale information related to user stories? RQ 2 What percent of the turns in the conversations belong to extractive summaries of those conversations?  [5] Enron Emails [30] n/a 39 351 4600 Murray and Carenini [5] AMI Meetings [6] 100 hours 138 64419 89302** Rastkar et al. [3], [4] Bug Reports The purpose of RQ 1 is twofold. First, while it is widely accepted that the elicitation of user stories should result from these conversations [1], it is possible that not all of the information necessary to write a user story is contained in these conversations. If the information is not in the conversations, then it is not possible to automatically extract it, and there is no reason to study it in our quantitative analysis in Section VI. Second, that quantitative study depends on the turns being annotated as having role, function, and/or rationale information. Answering RQ 1 provides the opportunity to complete this annotation.\n\nWe ask RQ 2 in order to provide a mechanism for comparing the performance of our classifier (Section V) to previous work. It is not possible for us to release the records of conversations we collect, which means that we will need to use a public dataset to compare our classifier to earlier ones. However, our technique is designed for user story information, while the available public datasets have only extractive summaries annotated. Therefore, we annotate our dataset with extractive summaries to maintain a consistent baseline.\n\n\nB. Methodology\n\nThis section describes our methodology for answering our research questions. We first describe how we created the corpus of meeting records. Second, we describe how we annotated that corpus with role, function, and rationale data, as well as extractive summaries.\n\n\nC. Data Collection\n\nThe data that we collect includes recordings of meetings between developers and customers. To collect this data, the first author spent two months working as a software engineering intern at a software development company in the United States with between 30 and 50 employees (for privacy purposes, the company is anonymous). During this time, she was invited to regular stand up meetings and teleconferences with the client. These meetings consisted of discussions about progress on current tasks and plans for future tasks. After obtaining appropriate permission, the author observed, took notes, and recorded audio during each meeting. In total, nine meetings between developers and customers were recorded. We then hired a professional transcriptionist to create written transcripts of the audio for each meeting.\n\nThe transcripts contained an entire meeting's dialogue. However, each meeting contained several conversations, each of which had a separate topic with separate people (for instance, people joining or leaving a conference call as they are needed for each topic). Therefore, we manually separated each transcript into a set conversations. We understand that this is a subjective process, so we used the following criteria to minimize any bias during conversation separation: 1) a current speaker(s) leaves the conversation, 2) a new speaker(s) joins the conversation, or 3) a noticeable shift in topic, such as switching to a new bug. After this process was complete, we had 27 conversations total over the nine meetings. Our dataset is comparable in size to datasets for related experiments, as shown in Table I.\n\n\nD. Annotation Process\n\nAll of the authors annotated the conversations. Each conversation was manually annotated by at least 3 authors. We restricted annotation to authors-only in order to maintain privacy of the speakers. The assignment of conversations to annotators was random, to ensure an unbiased assignment. The authors then annotated each of their conversations, but were careful not to discuss any annotations with each other to avoid introducing a bias. Every annotation used the following format:\n\nFile: the file name of the transcript Conversation: an ID number for the conversation Abstractive: an \"in your own words\" summary Extractive: a list of turns summarizing the transcript Role: a list of turns summarizing the role Function: a list of turns summarizing the function Rationale: a list of turns summarizing the rationale Note that the annotations include an abstractive summary. We included this summary as an exercise to help the annotators understand the content of the conversation, but otherwise the abstractive summary was not used in our experiments.\n\nOnce annotations were complete, we combined them using a voting process to create a final goldset annotation for each conversation. The voting process was a simple majority: we selected turns for the goldset if those turns were selected by at least two of the three annotators for that conversation.\n\n\nE. Threats to Validity\n\nOne threat to the validity of these observations is that much of the conversation was over the phone. This caused some of the conversation to be slightly garbled, meaning the transcriber to may have misheard some of the conversation. Although possibly causing some turns to be slightly wrong, in our view this threat is minimal, since we did not encounter evidence that the errors would significantly change the meaning or context of the conversation. To minimize this threat, we hired a professional transcriptionist with experience handling difficult audio.\n\nAnother threat with these observations is the subjective nature of manual annotations. We attempt to mitigate this threat with the voting process of a majority consensus among the set of authors who annotated each conversation. With this consensus check, the final combined annotation is less likely to be biased. In addition, we compute the metric Pyramid Precision (see Section VI-C), which computes precision weighted for the number of votes for each turn.\n\nFinally, one threat to validity is the source of the data we collected. It is possible that our dataset is not representative of \"typical\" meetings between developers and customers. We aim to mitigate this threat by recording actual meetings at an active software development company (unlike the AMI meeting corpus, which is simulated). Still, it is possible that our partner company is different from other companies in a way that would affect our results.\n\n\nIV. FIELD OBSERVATIONS RESULTS\n\nIn this section, we present our answer to each research question, as well as our rationale, and interpretation of the answers. These answers are the basis for the quantitative study discussed later in the paper.\n\n\nA. RQ 1 : Turn Information\n\nWe found that out of the 3176 total turns, 5.5% of turns contained function information, 2.9% of turns contained rationale information, and only 0.5% of turns contained role information (see Figure 1). Our perception of why role information was missing from conversations is that during these regular meetings, the employees already had a understanding of their roles within these projects. Therefore, there was no need to identify each participant's role during the meeting in order for the speakers to complete their assigned tasks. In contrast, function and rationale information is present since it is usually unknown before the task is discussed in the meeting. Therefore, we only used function and rationale information during the quantitative study.\n\n\nB. RQ 2 : Extractive Summaries\n\nFor extractive summaries produced from our annotations, we found that 10.2% of turns belong to extractive summaries of their respective conversations (see Figure 1). For comparison, Murray and Carenini found 13.0% of their turns to be included within the extractive summaries for the AMI meetings and 19.0% of their sentences included in the Enron email summaries [5]. Also, Rastkar et al. found 28.3% of the bug report turns were included in the extractive summaries [3], [4]. In our view, our findings are consistent with the findings from the AMI meeting conversations. V. OUR APPROACH Our approach, is essentially a machine learning classifier, in which we classify turns in speech as either having user story information, or not. We build two classifiers for each type of data that we extract: two for function information, and two for rationale information. The two classifiers are based on two different algorithms. We also build two classifiers to create extractive summaries of the conversations, for purposes of comparison to related work. Note that because of the very small amount of role information in our dataset (see Section IV-A), we do not attempt to extract that type of information. Our approach is inspired by previous work (see Section II-D), but has numerous differences that we describe in this section.\n\n\nA. Data Preparation\n\nAny technique using supervised machine learning will depend on prepared data in the form of labels for the items to be classified. In our case, we labeled every turn in every conversation as containing role, function, and/or rationale data, as well as whether the turn belongs to an extractive summary. We completed this annotation process as part of our Field Observations in Section III. We use the same annotations in this section. This annotation process is depicted in Figure 2: we describe our process of obtaining the transcripts in area 1 in Section III-C, and the annotations in area 2 in Section III-D.\n\n\nB. Attributes\n\nWe use a set of 25 attributes in each of classifier that we build (Figure 2, area 3). Table II provides a brief description of each attribute. These attributes are in general similar to the attributes proposed by Murray and Carenini [5] and later used by Rastkar et al. [3], [4], and due to space limitations we refer readers to those publications for complete details. However, a key distinction is that the unit of analysis in our work is a turn, not a sentence, as described in Section II-B. A few of the attributes are identical, such as spau, which is the time between the current turn and the following turn. Also, a few attributes, such as tloc (the position of a sentence in its turn) are nonsensical when calculated on turns instead of sentences. But most attributes could be modified slightly, for example thisent. In Murray and Carenini's paper, thisent is the entropy of the current sentence. In our work, it is the entropy of the current turn.\n\nFrom [5], these classification attributes fall into four categories: length, structural, participants, and lexical. Our attributes still fit into these categories. Slen and wc are in the length category; cloc, ppau, spau, tpos1, and tpos2 are in the structural category; and begauth and dom are in the participant category. The remaining attributes, which are based on probability and entropy of textual data, are contained within the lexical category.\n\nWe have added two new attributes: pent_empt and sent_empt. These are when two of the entropy-based attributes, pent and sent, equal zero. This means that either all previous turns or all subsequent turns, respectively, have  no entropy at all. These attributes are simpler descriptors of the turns than their numeric counterparts, which may provide better classifications for sparser data. These new attributes still fall under the lexical category. Prior to training with each algorithm, we scaled the attribute values to ensure they would be between 0 and 1 to avoid some attributes from dominating the others [31].\n\n\nC. Adaption for Low Incidence Data\n\nOne challenge with our dataset is that the incidence of function and rationale information is relatively low. In Section IV-A, we found that function data was present in 5.5% of turns and rationale data in 2.9% -the turns in the groups labeled as having function and/or rationale data are a small minority class. A common problem in supervised machine learning of low incidence data is that the algorithm may predict that everything is in the large class, while ignoring the minority class [32].\n\nWe used the SMOTE [33] algorithm to address this problem ( Figure 2, area 4). SMOTE works by oversampling the minority class by creating synthetic examples of the minority class, and adding those examples to the dataset until the minority class is equal in size to the larger class. SMOTE has been shown to have generally good performance, outperforming duplicative oversampling as well as undersampling of the majority class for many datasets [33], [32].\n\n\nD. Creating the Prediction Models\n\nWe built two prediction models for each of the types of information we extract: two for function data, two for rationale data, and two for extractive summaries. One model is based on the algorithm Support Vector Machines (with an RBF kernel) [34], and the other model is based on the algorithm Logistic Regression [35] (Figure 2, area 5). We used Logistic Regression for two reasons: first, it is the algorithm that Murray and Carenini [5] and Rastkar et al. [3], [4] used to obtain reasonable performance. Second, Logistic Regression is a probabilistic classifier, which means that it returns a probability that each turn belongs to a class. The advantage to these probabilities is that the size of the predicted class can be set with a cutpoint; the top n turns can be selected. As a contrast, we also used the SVM-RBF algorithm, which is a prominent binary classifier. In Section VI, we compare the performance of these algorithms on our dataset.\n\n\nE. Reproducibility and Implementation\n\nTo facilitate reproducibility and to assist other researchers, we release our prediction models as well as our complete implementation via an online appendix 2 . Our implementation is built using Scikit-learn [36], as well as custom scripts to parse the transcripts and calculate the attributes. These are all available online, along with a virtual machine image with all dependencies installed to demonstrate how it is used.\n\nWe also release the prediction models that we created as part of the procedure depicted in Figure 2 (area 6). Note that these are models trained on the entire corpus of conversations in our dataset -they are not the models we use for testing in the cross-validation experiments in the next section. We release these models in lieu of the transcripts, since we cannot release the transcripts for privacy reasons. Future researchers can use these models on their own datasets, similar to how Rastkar et al. tested a model on their own dataset that was created by Murray and Carenini [3].\n\n\nVI. CROSS-VALIDATION EXPERIMENT\n\nThis section describes our quantitative study, which is a cross-validation experiment to evaluate our approach. We cover our research questions, our methodology and metrics for answering those questions, and threats to validity.\n\n\nA. Research Questions\n\nOur objective with this quantitative study is to determine the degree to which the classifiers we train are able to extract function and rationale information, as well as extractive summaries. As in Section V, we do not include role information because our dataset contains so little of it (see Section IV-A). We pose the following two questions: RQ 3 What is the performance of the best-performing configuration of our approach, in terms of the metrics in Section VI-C? RQ 4 Which attributes are the most informative for the classification task?\n\nWe ask RQ 3 because there are several potential configurations of our approach, and we seek the highest performing configuration. The configuration is the algorithm (SVM-RBF vs Logistic Regression) and the classification threshold for Logistic Regression. We ask RQ 4 for a similar reason. We 2 http://www3.nd.edu/ \u223c prodeghe/projects/userstories/ use 25 attributes in our approach, and several of these we adapted for turn-based analysis instead of sentence-based. Some attributes may be more useful for classification than others. It is beneficial for us to report the usefulness of each attribute because it may be possible for future researchers to simplify the approach by removing some less useful attributes, without significantly harming performance.\n\n\nB. Methodology\n\nThe methodology we follow is depicted in Figure 3. Generally speaking, we follow a \"leave one conversation out\" procedure. The typical cross-validation process is either a leave-one-out or an n-fold validation. Leave-one-out usually means train all items in the dataset, then test on one. In an n-fold validation, 1/n items are randomly selected as the testing set. In our case, the items in the dataset are turns. In our view, the typical leave-one-out and n-fold validation do not reflect realistic scenarios, since the turns in one conversation almost never have any direct affect on the turns in another conversation. The realistic scenario is that a researcher has m conversations, and trains a classifier on those conversations. Then the researcher receives a \"new\" conversation, and classifies that conversation. Fig. 3: Outline of our cross-validation experiment procedure. Note that the procedure is slightly different than the creation of the prediction models shown in Figure 2. In the experiment, we create a new model for each cross validation fold. In each fold, we train on all conversations except one, and then test on the one remaining conversation. With 27 conversations, our experiment has 27 folds.\n\nTo emulate that realistic scenario, we use a leave one conversation out process in which we set aside one conversation as the test set, and create a training set using the remaining conversations ( Figure 3, area 1). Note that we use the SMOTE procedure (Section V-C) on the training set only (area 2) to avoid biasing the experiment -SMOTE changes the dataset, and a bias could occur if we modify testing data.\n\nNext, we train both SVM-RBF and Logistic Regression algorithms (area 3). We list them together in Figure 3 to emphasize that we train both, but the algorithms are independent. They do not share data, and we do not attempt to combine the models that they create (area 4). We use each model to test the conversation that we left out of the training set, and compute our performance metrics during that test (area 5). We repeat this process for every conversation.\n\n\nC. Metrics\n\nFor RQ 3 , we calculate the standard machine learning performance metrics Precision, Recall, True Positive Rate (TPR), and False Positive Rate (FPR) [37], [32]. We also compute Pyramid Precision, which is similar to precision, except that it considers the number of human annotators who marked each turn. In Pyramid Precision, a prediction model is rewarded for predicting turns that have been annotated by more people as belonging to a class. Pyramid Precision is useful in cases where a goldset is created by multiple people who may disagree [38], and was used by Murray and Carenini [5] and Rastkar et al. [3].\n\nNote that Logistic Regression generates predictions based on a probability threshold: turns with probabilities above the threshold are predicted as part of the class. That is in contrast to SVM-RBF, which provides binary predictions (see Section V-D). Therefore, for SVM-RBF, we report the average of the performance metrics over all folds of the cross validation. But for Logistic Regression, we report the optimal probability threshold.\n\nFor RQ 4 , we calculate the standard metric F-score [39] for each attribute. F-score is commonly used in feature selection to determine which attributes are the most informative for a classification task. We report F-score for both SVM-RBF and Logistic Regression.\n\n\nD. Threats to Validity\n\nOne threat to validity to this study is our data source, as mentioned in Section III-E. There is a possibility that the data set we use is not representative of \"typical\" developercustomer meetings. However, this threat was mitigated by recording several real meetings taking place at an active software development company.\n\nAnother threat to validity exists in the selection of attributes. Although it is a relatively large set and most were used in previous studies, they may not represent all usable attributes for classification tasks. In addition, the conversion of certain attributes from sentence-based to turn-based may have affected the usefulness of those attributes. This is handled, however, by the modeling itself and the analysis performed in Section VII-B.\n\n\nVII. CROSS-VALIDATION RESULTS\n\nIn this section, we present our answer to each research question, as well as our rationale, and interpretation of the answers.\n\n\nA. RQ 3 : Best Configuration\n\nWe found the best configuration for classification is Logistic Regression (92% threshold) (see Table II  With the extractive summary (E) information, the Logistic Regression model performed the best using traditional metrics, as mentioned above, with a Precision of 70.8%, a Recall of 18.3%, and a AUROC score of 0.587. In terms of Pyramid Precision, the SVM model with RBF kernel outperformed Logistic Regression with a PP of 64.9%. Although the PP was higher for SVM-RBF, it still did not overcome the Logistic Regression's Precision, which we believe means that Logistic Regression outperformed SVM-RBF overall.\n\nWe observe a similar pattern with function (F) information. The Logistic Regression model performed the best using traditional metrics with a Precision of 54.5%, a Recall of 24.0%, and a AUROC score of 0.614. In terms of Pyramid Precision, the SVM model with RBF kernel outperformed Logistic Regression with a PP of 49.1%, though the results are extremely close. Logistic Regression outperforms SVM-RBF overall, though the margin is not large enough to justify a strong recommendation either way.\n\nWith the rationale (A) information as the type, the Logistic Regression model outperforms the SVM model for all metrics. This configuration had a Precision of 25.0%, a Recall of 26.9%, a PP of 36.4%, and a AUROC of 0.622. With this configuration, there are a couple differences to note other than Logistic Regression having a better PP than SVM-RBF. One observation is that this is the only configuration where the PP measures higher than the Precision. Another observation is that the ROC score is highest with this A information than with the E and F information. We believe all three of these observations are due to the lower incidence of rationale information compared to extractive summary and function information. With less data to use, the traditional prediction becomes more difficult, but the metrics that make use of other data that balances them become more useful.\n\nFrom all these configurations, the best overall configuration for the classification task is the Logistic Regression model, especially for the extractive summary information. As mentioned in Section VI-C, Logistic Regression uses a probability threshold to determine classification. This configuration uses a probability threshold of about 0.92, which produces a lower FPR at the cost of a lower TPR.\n\nIn terms of the most-closely related work (Section II-D), we caution that our data is different (transcripts vs. bug reports and emails), and that our analysis is turn-based rather than sentence-based. Still, the previous results provide a rough basis for comparision (a \"sanity check\"). The Murray and Carenini AMI meeting experiments produced a best case Pyramid Precision of 23.0% and AUROC score of 0.850 [5]. The Murray and Carenini Email experiments produced a best case Pyramid Precision of 47.0% and AUROC score of 0.740 [5]. The Murray and Carenini studies did not report Precision and Recall, but they did mention that they recorded high Precision and low Recall values. The Rastkar Bug Report experiments produced a best case Pyramid Precision of 63.0%, an AUROC score of 0.722, a Precision of 57.0%, and a Recall of 35.0% [3], [4]. While these numbers are not directly comparable, we do note that high precision and low recall is a common feature of the approaches, and that Rastkar et al. reported that this was acceptable during a study with human experts [4].\n\n\nB. RQ 4 : Best Attributes\n\nWe found 7 of the 25 attributes to consistently be the most informative for this classification task across both models and all three types of turn information. As shown in Figure 4, these attributes tended towards higher F-scores (see Section VI-C) compared to other attributes. These attributes are cent1, cent2, slen, sms, smt, spau, and wc and are briefly described in Table II. As explained in Section V-B, these attributes can be separated into four distinct categories: length, structural, participants, and lexical. Of these 7 most informative attributes, 2 are in length, 1 is in structural, 0 are in participants, and 4 are in lexical. It is important to note that attributes within the lexical category perform the best in this classification task, which we believe is because they are created using the most information. Another important observation is that the attributes representing participant specifics have little to no effect on the classification with our data. We believe that is because the speech in each conversation is so broken between speakers that it is difficult for the algorithm to use it effectively. We also found 4 somewhat informative attributes: cloc (structural), cos1 (lexical), cos2 (lexical), and cws (lexical). As can be seen in Figure 4, these 4 attributes do not get as high F-scores as often as the other 7, but they do occasionally score higher than the strictly non-informative attributes.\n\nAmong all the configurations, the one containing the highest F-scores for the informative attributes is the Logistic Regression model with the extractive summary information. This is the same configuration shown in Section VII-A.\n\nIt is our view that our most informative set is comparable to the sets produced by the previous studies mentioned in Section II-D. All three experiments agree that cent1, cent2, cws, slen, sms, and smt are informative for classifica-tion. The Murray and Carenini AMI experiments and Email experiments additionally have the mxs and mxt attributes included. Also, the Murray and Carenini AMI experiments and the Rastkar Bug Report experiments list the slen2 attribute as informative. Compared to our set, almost everyting is in agreement. We do not include cws, slen2, mxs, or mxt. However, cws was somewhat informative with our approach, and slen2 was not included in our usable attributes to begin with because of our use of the turn/conversation system.\n\n\nVIII. AMI EXPERIMENTS\n\nAs mentioned in Section I, we duplicated our quantitative experiments (Section VI) for extractive summaries on the public AMI meeting corpus [6]. Since we cannot ethically release any of our meeting recordings from the active software company, these experiments on the AMI corpus serve as a reproducible example of our work. Although the AMI dataset uses artificially created meetings and conversations, it is a popular dataset due to its size and depth of information. For these experiments, we followed the same approach as outlined in Figure 3, except that there were many more folds since the API corpus contains more conversations. However, since the AMI dataset only includes extractive summaries, we do not use function and rationale information for these experiments. We have made our implementation and this example available via an online appendix (see Section V-E).\n\nUsing the same metrics we used in our quantitative study (see Section VI-C), we found the metric values to be more split between the two models, as can be seen in Table IV. For two of the metrics, Logistic Regression outperforms SVM-RBF with a Recall of 24.9% and an AUROC score of 0.619. The Receiver Operating Characteristic Area Under the Curve (AUROC) score is a combined representation of the True Positive Rate (TPR) and the False Positive Rate (FPR). For the other two metrics, the SVM model with the RBF kernel outperforms the Logistic Regression model with a Precision of 78.2% and a Pyramid Precision of 82.6%. In general, both algorithms had generally similar performance, so from our view, future researchers may choose either algorithm depending on other factors affecting their experiments. Also, we observed that the same 7 attributes that were found to be most informative in our study were most informative in terms of F-score: cent1, cent2, slen, sms, smt, spau, and wc.\n\nOne may observe that our AMI experiments produced a best case Pyramid Precision of 82.6% and AUROC score of 0.619, and the Murray and Carenini AMI experiments produced a best case Pyramid Precision of 23.0% and AUROC score of 0.850. As in Section VII, we caution that these numbers are not comparable since the unit of analysis is different (turns vs. sentences). We reiterate that we include this section only to observe trends and to provide a reproducible baseline for our approach. Our intent is that future researchers in the area of summarization and user story generation can build and test their approach on this reproducible baseline of public data, to verify that their approach functions similarly to ours.\n\n\nIX. DISCUSSION AND CONCLUSION\n\nIn this paper, we advance the state of the art in two key directions. First, we contribute the analysis of actual user story conversations to the software engineering literature. Although we cannot publish the conversations themselves due to privacy concerns, previous work in user story analysis used the AMI meeting corpus, which was artificially created. In our qualitative study (Section IV), we found that about 5.5% of the turns included function information, 2.9% discussed rationale, but only 0.5% discussed role. About 10.2% were part of the extractive summaries. From these results, we have two key findings: 1) while function and rationale information are available for analysis in real conversations, role information is not; and 2) in terms of extractive summary information, the artificial AMI dataset is a comparably useful source of information as an active meeting dataset.\n\nSecond, we create a novel approach that extracts user story information from transcripts of spoken conversations. In our quantitative study (Section VII), we obtained approximately 54.5% precision and 24.0% recall for detecting sections of conversations containing function data, and 25.0% precision and 26.9% recall for rationale data. For comparison purposes, we obtained about 70.8% precision and 18.3% recall for extractive summaries. Compared to similar previous studies, we found our results to be comparable in most cases and better in others, most notably with the Pyramid Precision metric. With these results, this new approach provides an extra option for researchers if they feel their data is either more appropriately broken into turns or simply cannot be represented as full sentences.\n\n\nACKNOWLEDGMENT\n\nWe strongly thank Karen Hooge Michalka and Dr. Lyn Spillman from the University of Notre Dame Department of Sociology for their advice in preparing the qualitative study in this paper. We also thank teacher Michael Dimino of the Concord Public School district for participating in portions of this research. We hugely appreciate the active software company for allowing the recording of several of their customer meetings, as well as the many employees who allowed the collection of their data. This work was partially supported by the NSF grants CCF-1452959 and DGE-1313583, and the Office of Naval Research grant N000141410037. Any opinions, findings, and conclusions expressed herein are the authors' and do not necessarily reflect those of the sponsors.\n\nFig. 1 :\n1Venn diagram of the percentages of turns that are included in each category. The categories are function (F), rationale (A), and extractive Summary (E). For example, 0.2% of turns were marked as including function information only, while 3.8% of turns had both function and extractive summary information only.\n\nFig. 2 :\n2Overview of our approach. We completed steps 1 and 2 while answering RQ 1 and RQ 2 ins Section III. Steps 3, 4, 5, and 6 are described in Section V.\n\n\n), though the performance of the algorithms is similar. Logistic Regression outperforms SVM-RBF with the more traditional metrics of Precision, Recall, True Positive Rate (TPR), and False Positive Rate (FPR). The TPR and FPR are represented together as the Receiver Operating Characteristic Area Under the Curve (AUROC) score. However, with the Pyramid Precision (PP) metric, which takes the number of annotators into account, SVM-RBF performs better with two of the three types of information.\n\nFig. 4 :\n4F-scores of the 25 attributes after running both models on our corpus. (a) includes the Logistic Regression model using extractive summary (E), function (F), or rationale (A) information. (b) is the same for the SVM model using the RBF kernel.\n\nTABLE I :\nIA comparison of the size of our corpus to related work.Related Experiment \nCorpus \nSpeech \n# of Conversations \n# of Turns \n# of Sentences \nMurray and Carenini \n\nTABLE II :\nIIList of attributes we calculate.Attribute \nDescription \nbegauth \nfirst participant in convo \ncent1 \ncos. of turn and convo., w/ Sprob \ncent2 \ncos. of turn and convo., w/ Tprob \ncloc \nposition in convo. \ncos1 \ncos. of convo. splits, w/ Sprob \ncos2 \ncos. of convo. splits, w/ Tprob \ncws \nrough ClueWordScore \ndom \nparticipiant dominance in words \nmns \nmean Sprob score \nmnt \nmean Tprob score \nmxs \nmax Sprob score \nmxt \nmax Tprob score \npent \nentropy of convo. before the turn \npent empt \nno entropy in convo. before the turn \nppau \ntime btwn. current and prior turn \nsent \nentropy of convo. after the turn \nsent empt \nno entropy in convo. after the turn \nslen \nword count in turn, globally normalized \nsms \nsum of Sprob scores \nsmt \nsum of Tprob scores \nspau \ntime btwn. current and next turn \nthisent \nentropy of current turn \ntpos1 \ntime from beg. of convo. to turn \ntpos2 \ntime from turn to end of convo. \nwc \nword count in turn, not normalized \n\n\n\nTABLE III :\nIIIMetric results using our corpus.Details shown \nare Type, Classifier & Threshold where applicable (Class.), \nPrecision (Prec.), Recall(Rec.), Pyramid Precision (PP), and \nAUROC score. \nType \nClass. \nPrec. Rec. \nPP \nAUROC \nE \nLR(92%) 0.708 0.183 0.597 \n0.587 \nE \nSVM \n0.684 0.140 0.649 \n0.566 \nF \nLR(94%) 0.545 0.240 0.472 \n0.614 \nF \nSVM \n0.522 0.240 0.491 \n0.613 \nA \nLR(81%) 0.250 0.269 0.364 \n0.622 \nA \nSVM \n0.182 0.154 0.204 \n0.566 \n\n\n\nTABLE IV :\nIVMetric results using the AMI meetings corpus. Details shown are Type, Classifier (Class.), Precision (Prec.), Recall(Rec.), Pyramid Precision (PP), and AUROC score.Type \nClass. \nPrec. \nRec. \nPP \nAUROC \nE \nLR(97%) \n0.758 \n0.249 \n0.791 \n0.619 \nE \nSVM \n0.782 \n0.158 \n0.826 \n0.576 \n\n\n\nUser stories applied: For agile software development. M Cohn, Addison-Wesley ProfessionalM. Cohn, User stories applied: For agile software development. Addison-Wesley Professional, 2004.\n\nMastering the requirements process: Getting requirements right. S Robertson, J Robertson, Addison-wesleyS. Robertson and J. Robertson, Mastering the requirements process: Getting requirements right. Addison-wesley, 2012.\n\nSummarizing software artifacts: a case study of bug reports. S Rastkar, G C Murphy, G Murray, Proceedings of the 32nd. the 32ndS. Rastkar, G. C. Murphy, and G. Murray, \"Summarizing software artifacts: a case study of bug reports,\" in Proceedings of the 32nd\n\nACM/IEEE International Conference on Software Engineering. ACM1ACM/IEEE International Conference on Software Engineering-Volume 1. ACM, 2010, pp. 505-514.\n\nAutomatic summarization of bug reports. IEEE Transactions on Software Engineering. 404--, \"Automatic summarization of bug reports,\" IEEE Transactions on Software Engineering, vol. 40, no. 4, pp. 366-380, 2014.\n\nSummarizing spoken and written conversations. G Murray, G Carenini, Proceedings of the Conference on Empirical Methods in Natural Language Processing. the Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational LinguisticsG. Murray and G. Carenini, \"Summarizing spoken and written con- versations,\" in Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2008, pp. 773-782.\n\nThe ami meeting corpus. I Mccowan, J Carletta, W Kraaij, S Ashby, S Bourban, M Flynn, M Guillemot, T Hain, J Kadlec, V Karaiskos, Proceedings of the 5th International Conference on Methods and Techniques in Behavioral Research. the 5th International Conference on Methods and Techniques in Behavioral Research88I. McCowan, J. Carletta, W. Kraaij, S. Ashby, S. Bourban, M. Flynn, M. Guillemot, T. Hain, J. Kadlec, V. Karaiskos et al., \"The ami meeting corpus,\" in Proceedings of the 5th International Conference on Methods and Techniques in Behavioral Research, vol. 88, 2005.\n\nManifesto for agile software development. K Beck, M Beedle, A Van Bennekum, A Cockburn, W Cunningham, M Fowler, J Grenning, J Highsmith, A Hunt, R Jeffries, K. Beck, M. Beedle, A. Van Bennekum, A. Cockburn, W. Cunningham, M. Fowler, J. Grenning, J. Highsmith, A. Hunt, R. Jeffries et al., \"Manifesto for agile software development,\" 2001.\n\nTowards a framework for real time requirements elicitation. M Gall, B Berenbach, 2006 First International Workshop on Multimedia Requirements Engineering (MERE'06 -RE'06 Workshop). M. Gall and B. Berenbach, \"Towards a framework for real time require- ments elicitation,\" in 2006 First International Workshop on Multimedia Requirements Engineering (MERE'06 -RE'06 Workshop), Sept 2006, pp. 4-4.\n\nDoing conversation analysis. Sage. P Ten Have, P. Ten Have, Doing conversation analysis. Sage, 2007.\n\nThe language of turn and sequence. C E Ford, B A Fox, S A Thompson, Oxford University Press on DemandC. E. Ford, B. A. Fox, and S. A. Thompson, The language of turn and sequence. Oxford University Press on Demand, 2002.\n\nI Hutchby, R Wooffitt, Conversation analysis. Polity. I. Hutchby and R. Wooffitt, Conversation analysis. Polity, 2008.\n\nT Nishida, Conversational Informatics: An Engineering Approach. WileyT. Nishida, Conversational Informatics: An Engineering Approach. Wiley, 2007.\n\nSequence Organization in Interaction: A Primer in Conversation Analysis I. E A Schegloff, Cambridge University PressE. A. Schegloff, Sequence Organization in Interaction: A Primer in Conversation Analysis I. Cambridge University Press, 2007.\n\nInformation fusion in the context of multi-document summarization. R Barzilay, K R Mckeown, M Elhadad, 10.3115/1034678.1034760Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics, ser. ACL '99. the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics, ser. ACL '99Stroudsburg, PA, USAAssociation for Computational LinguisticsR. Barzilay, K. R. McKeown, and M. Elhadad, \"Information fusion in the context of multi-document summarization,\" in Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics, ser. ACL '99. Stroudsburg, PA, USA: Association for Computational Linguistics, 1999, pp. 550-557. [Online]. Available: http://dx.doi.org/10.3115/1034678.1034760\n\nA survey of text summarization extractive techniques. V Gupta, G S , Journal of emerging technologies in web intelligence. 23V. Gupta and G. S. Lehal, \"A survey of text summarization extractive techniques,\" Journal of emerging technologies in web intelligence, vol. 2, no. 3, pp. 258-268, 2010.\n\nSummarizing text documents: sentence selection and evaluation metrics. J Goldstein, M Kantrowitz, V Mittal, J Carbonell, Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval. the 22nd annual international ACM SIGIR conference on Research and development in information retrievalACMJ. Goldstein, M. Kantrowitz, V. Mittal, and J. Carbonell, \"Summa- rizing text documents: sentence selection and evaluation metrics,\" in Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 1999, pp. 121-128.\n\nOn the use of automated text summarization techniques for summarizing source code. S Haiduc, J Aponte, L Moreno, A Marcus, 2010 17th Working Conference on Reverse Engineering. IEEES. Haiduc, J. Aponte, L. Moreno, and A. Marcus, \"On the use of automated text summarization techniques for summarizing source code,\" in 2010 17th Working Conference on Reverse Engineering. IEEE, 2010, pp. 35-44.\n\nAutomatic source code summarization of context for java methods. P W Mcburney, C Mcmillan, IEEE Transactions on Software Engineering. 422P. W. McBurney and C. McMillan, \"Automatic source code summa- rization of context for java methods,\" IEEE Transactions on Software Engineering, vol. 42, no. 2, pp. 103-119, 2016.\n\nTowards automatically generating summary comments for java methods. G Sridhara, E Hill, D Muppaneni, L Pollock, K Vijay-Shanker, 10.1145/1858996.1859006Proceedings of the IEEE/ACM international conference on Automated software engineering, ser. ASE '10. the IEEE/ACM international conference on Automated software engineering, ser. ASE '10New York, NY, USAACMG. Sridhara, E. Hill, D. Muppaneni, L. Pollock, and K. Vijay- Shanker, \"Towards automatically generating summary comments for java methods,\" in Proceedings of the IEEE/ACM international conference on Automated software engineering, ser. ASE '10. New York, NY, USA: ACM, 2010, pp. 43-52. [Online]. Available: http://doi.acm.org/10.1145/1858996.1859006\n\nAutomatically detecting and describing high level actions within methods. G Sridhara, L Pollock, K Vijay-Shanker, Proceedings of the 33rd International Conference on Software Engineering, ser. ICSE '11. the 33rd International Conference on Software Engineering, ser. ICSE '11New York, NY, USAACMG. Sridhara, L. Pollock, and K. Vijay-Shanker, \"Automatically detecting and describing high level actions within methods,\" in Proceedings of the 33rd International Conference on Software Engineering, ser. ICSE '11. New York, NY, USA: ACM, 2011, pp. 101-110. [Online].\n\n. 10.1145/1985793.1985808Available: http://doi.acm.org/10.1145/1985793.1985808\n\nGenerating parameter comments and integrating with method summaries. 10.1109/ICPC.2011.28Proceedings of the 2011 IEEE 19th International Conference on Program Comprehension, ser. ICPC '11. the 2011 IEEE 19th International Conference on Program Comprehension, ser. ICPC '11--, \"Generating parameter comments and integrating with method summaries,\" in Proceedings of the 2011 IEEE 19th International Conference on Program Comprehension, ser. ICPC '11, 2011, pp. 71-80. [Online]. Available: http://dx.doi.org/10.1109/ICPC.2011.28\n\nSummarization of complex software artifacts. L Moreno, 10.1145/2591062.2591096Companion Proceedings of the 36th International Conference on Software Engineering, ser. ICSE Companion. New York, NY, USAACML. Moreno, \"Summarization of complex software artifacts,\" in Companion Proceedings of the 36th International Conference on Software Engineering, ser. ICSE Companion 2014. New York, NY, USA: ACM, 2014, pp. 654-657. [Online]. Available: http: //doi.acm.org/10.1145/2591062.2591096\n\nOn the analysis of human and automatic summaries of source code. L Moreno, J Aponte, CLEI Electronic Journal. 152L. Moreno and J. Aponte, \"On the analysis of human and automatic summaries of source code,\" CLEI Electronic Journal, vol. 15, no. 2, pp. 2-2, 2012.\n\nAutomatic generation of natural language summaries for java classes. L Moreno, J Aponte, S Giriprasad, A Marcus, L Pollock, K Vijay-Shanker, Proceedings of the 21st International Conference on Program Comprehension, ser. ICPC '13. the 21st International Conference on Program Comprehension, ser. ICPC '13L. Moreno, J. Aponte, S. Giriprasad, A. Marcus, L. Pollock, and K. Vijay-Shanker, \"Automatic generation of natural language summaries for java classes,\" in Proceedings of the 21st International Conference on Program Comprehension, ser. ICPC '13, 2013.\n\nAutomatic documentation inference for exceptions. R P Buse, W R Weimer, 10.1145/1390630.1390664Proceedings of the 2008 international symposium on Software testing and analysis, ser. ISSTA '08. the 2008 international symposium on Software testing and analysis, ser. ISSTA '08New York, NY, USAACMR. P. Buse and W. R. Weimer, \"Automatic documentation inference for exceptions,\" in Proceedings of the 2008 international symposium on Software testing and analysis, ser. ISSTA '08. New York, NY, USA: ACM, 2008, pp. 273-282. [Online]. Available: http: //doi.acm.org/10.1145/1390630.1390664\n\nA metric for software readability. Proceedings of the 2008 International Symposium on Software Testing and Analysis, ser. ISSTA '08. the 2008 International Symposium on Software Testing and Analysis, ser. ISSTA '08New York, NY, USAACM--, \"A metric for software readability,\" in Proceedings of the 2008 International Symposium on Software Testing and Analysis, ser. ISSTA '08. New York, NY, USA: ACM, 2008, pp. 121-130. [Online].\n\n. 10.1145/1390630.1390647Available: http://doi.acm.org/10.1145/1390630.1390647\n\nIntroduction to the special issue on summarization. D R Radev, E Hovy, K Mckeown, Computational linguistics. 284D. R. Radev, E. Hovy, and K. McKeown, \"Introduction to the special issue on summarization,\" Computational linguistics, vol. 28, no. 4, pp. 399-408, 2002.\n\nInformation extraction and text summarization using linguistic knowledge acquisition. L F Rau, P S Jacobs, U Zernik, Information Processing & Management. 254L. F. Rau, P. S. Jacobs, and U. Zernik, \"Information extraction and text summarization using linguistic knowledge acquisition,\" Information Processing & Management, vol. 25, no. 4, pp. 419-428, 1989.\n\nThe detection and classification of non-functional requirements with application to early aspects. J Cleland-Huang, R Settimi, X Zou, P Solc, 10.1109/RE.2006.65Proceedings of the 14th IEEE International Requirements Engineering Conference, ser. RE '06. the 14th IEEE International Requirements Engineering Conference, ser. RE '06Washington, DC, USAIEEE Computer SocietyJ. Cleland-Huang, R. Settimi, X. Zou, and P. Solc, \"The detection and classification of non-functional requirements with application to early aspects,\" in Proceedings of the 14th IEEE International Requirements Engineering Conference, ser. RE '06. Washington, DC, USA: IEEE Computer Society, 2006, pp. 36-45. [Online]. Available: http://dx.doi.org/10.1109/RE.2006.65\n\nThe enron corpus: A new dataset for email classification research. B Klimt, Y Yang, European Conference on Machine Learning. SpringerB. Klimt and Y. Yang, \"The enron corpus: A new dataset for email classification research,\" in European Conference on Machine Learning. Springer, 2004, pp. 217-226.\n\nA practical guide to support vector classification. C.-W Hsu, C.-C Chang, C.-J Lin, C.-W. Hsu, C.-C. Chang, C.-J. Lin et al., \"A practical guide to support vector classification,\" 2003.\n\nA study of the behavior of several methods for balancing machine learning training data. G E Batista, R C Prati, M C Monard, ACM Sigkdd Explorations Newsletter. 61G. E. Batista, R. C. Prati, and M. C. Monard, \"A study of the behavior of several methods for balancing machine learning training data,\" ACM Sigkdd Explorations Newsletter, vol. 6, no. 1, pp. 20-29, 2004.\n\nSmote: synthetic minority over-sampling technique. N V Chawla, K W Bowyer, L O Hall, W P Kegelmeyer, Journal of artificial intelligence research. 16N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, \"Smote: synthetic minority over-sampling technique,\" Journal of artificial intel- ligence research, vol. 16, pp. 321-357, 2002.\n\nSupport vector machines. M A Hearst, S T Dumais, E Osman, J Platt, B Scholkopf, IEEE Intelligent Systems and their Applications. 134M. A. Hearst, S. T. Dumais, E. Osman, J. Platt, and B. Scholkopf, \"Sup- port vector machines,\" IEEE Intelligent Systems and their Applications, vol. 13, no. 4, pp. 18-28, 1998.\n\nApplied logistic regression. D W HosmerJr, S Lemeshow, John Wiley & SonsD. W. Hosmer Jr and S. Lemeshow, Applied logistic regression. John Wiley & Sons, 2004.\n\nScikit-learn: Machine learning in python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, Journal of Machine Learning Research. 12F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg et al., \"Scikit-learn: Machine learning in python,\" Journal of Machine Learning Research, vol. 12, no. Oct, pp. 2825-2830, 2011.\n\nAn empirical comparison of supervised learning algorithms. R Caruana, A Niculescu-Mizil, 10.1145/1143844.1143865Proceedings of the 23rd International Conference on Machine Learning, ser. ICML '06. the 23rd International Conference on Machine Learning, ser. ICML '06New York, NY, USAACMR. Caruana and A. Niculescu-Mizil, \"An empirical comparison of supervised learning algorithms,\" in Proceedings of the 23rd International Conference on Machine Learning, ser. ICML '06. New York, NY, USA: ACM, 2006, pp. 161-168. [Online]. Available: http://doi.acm.org/10.1145/1143844.1143865\n\nSummarizing emails with conversational cohesion and subjectivity. G Carenini, R T Ng, X Zhou, G. Carenini, R. T. Ng, and X. Zhou, \"Summarizing emails with conversational cohesion and subjectivity.\" 2008.\n\nC J V Rijsbergen, Information Retrieval. Newton, MA, USAButterworth-Heinemann2nd ed.C. J. V. Rijsbergen, Information Retrieval, 2nd ed. Newton, MA, USA: Butterworth-Heinemann, 1979.\n", "annotations": {"author": "[{\"end\":225,\"start\":103},{\"end\":344,\"start\":226},{\"end\":463,\"start\":345},{\"end\":570,\"start\":464}]", "publisher": null, "author_last_name": "[{\"end\":118,\"start\":109},{\"end\":238,\"start\":233},{\"end\":357,\"start\":351},{\"end\":479,\"start\":471}]", "author_first_name": "[{\"end\":108,\"start\":103},{\"end\":232,\"start\":226},{\"end\":350,\"start\":345},{\"end\":470,\"start\":464}]", "author_affiliation": "[{\"end\":224,\"start\":136},{\"end\":343,\"start\":255},{\"end\":462,\"start\":374},{\"end\":569,\"start\":481}]", "title": "[{\"end\":100,\"start\":1},{\"end\":670,\"start\":571}]", "venue": null, "abstract": "[{\"end\":1978,\"start\":692}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2100,\"start\":2097},{\"end\":2773,\"start\":2772},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2782,\"start\":2779},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3468,\"start\":3465},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3708,\"start\":3705},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3713,\"start\":3710},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3900,\"start\":3897},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5716,\"start\":5713},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5804,\"start\":5801},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8084,\"start\":8081},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8892,\"start\":8889},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9233,\"start\":9230},{\"end\":9286,\"start\":9259},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9474,\"start\":9471},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9767,\"start\":9764},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10550,\"start\":10547},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10727,\"start\":10724},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10733,\"start\":10729},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10739,\"start\":10735},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10745,\"start\":10741},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10751,\"start\":10747},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12607,\"start\":12603},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12613,\"start\":12609},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12920,\"start\":12916},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13117,\"start\":13113},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13516,\"start\":13512},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13538,\"start\":13534},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13544,\"start\":13540},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":13550,\"start\":13546},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13569,\"start\":13565},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":13575,\"start\":13571},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":13581,\"start\":13577},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":13607,\"start\":13603},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":13613,\"start\":13609},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14197,\"start\":14193},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":14203,\"start\":14199},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14323,\"start\":14319},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":14698,\"start\":14695},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14768,\"start\":14765},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":14773,\"start\":14770},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17407,\"start\":17404},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":17412,\"start\":17409},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":17879,\"start\":17876},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":17897,\"start\":17893},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":17937,\"start\":17934},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17954,\"start\":17951},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":18001,\"start\":17998},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":18006,\"start\":18003},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":18165,\"start\":18162},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":25446,\"start\":25443},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25550,\"start\":25547},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25555,\"start\":25552},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":27296,\"start\":27293},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":27333,\"start\":27330},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27338,\"start\":27335},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":28026,\"start\":28023},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":29088,\"start\":29084},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":29622,\"start\":29618},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":29647,\"start\":29643},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":30073,\"start\":30069},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":30079,\"start\":30075},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":30364,\"start\":30360},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":30436,\"start\":30432},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":30557,\"start\":30554},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":30580,\"start\":30577},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":30585,\"start\":30582},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":31322,\"start\":31318},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":32120,\"start\":32117},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":35999,\"start\":35995},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":36005,\"start\":36001},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":36394,\"start\":36390},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36435,\"start\":36432},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":36458,\"start\":36455},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":36957,\"start\":36953},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":40965,\"start\":40962},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":41085,\"start\":41082},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":41390,\"start\":41387},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":41395,\"start\":41392},{\"end\":41554,\"start\":41540},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":41626,\"start\":41623},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":44250,\"start\":44247}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":49514,\"start\":49193},{\"attributes\":{\"id\":\"fig_1\"},\"end\":49674,\"start\":49515},{\"attributes\":{\"id\":\"fig_2\"},\"end\":50171,\"start\":49675},{\"attributes\":{\"id\":\"fig_3\"},\"end\":50426,\"start\":50172},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":50598,\"start\":50427},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":51562,\"start\":50599},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":52014,\"start\":51563},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":52308,\"start\":52015}]", "paragraph": "[{\"end\":3469,\"start\":1997},{\"end\":4308,\"start\":3471},{\"end\":4807,\"start\":4310},{\"end\":6167,\"start\":4809},{\"end\":6841,\"start\":6169},{\"end\":7493,\"start\":6843},{\"end\":8085,\"start\":7495},{\"end\":8373,\"start\":8121},{\"end\":9020,\"start\":8403},{\"end\":9865,\"start\":9022},{\"end\":10056,\"start\":9905},{\"end\":10551,\"start\":10058},{\"end\":11293,\"start\":10553},{\"end\":11775,\"start\":11295},{\"end\":12475,\"start\":11777},{\"end\":14002,\"start\":12521},{\"end\":14586,\"start\":14004},{\"end\":14813,\"start\":14624},{\"end\":15914,\"start\":14815},{\"end\":16675,\"start\":15916},{\"end\":17055,\"start\":16703},{\"end\":18656,\"start\":17081},{\"end\":19191,\"start\":18658},{\"end\":19473,\"start\":19210},{\"end\":20313,\"start\":19496},{\"end\":21126,\"start\":20315},{\"end\":21635,\"start\":21152},{\"end\":22204,\"start\":21637},{\"end\":22505,\"start\":22206},{\"end\":23091,\"start\":22532},{\"end\":23552,\"start\":23093},{\"end\":24011,\"start\":23554},{\"end\":24257,\"start\":24046},{\"end\":25044,\"start\":24288},{\"end\":26406,\"start\":25079},{\"end\":27042,\"start\":26430},{\"end\":28016,\"start\":27060},{\"end\":28470,\"start\":28018},{\"end\":29089,\"start\":28472},{\"end\":29623,\"start\":29128},{\"end\":30080,\"start\":29625},{\"end\":31067,\"start\":30118},{\"end\":31534,\"start\":31109},{\"end\":32121,\"start\":31536},{\"end\":32385,\"start\":32157},{\"end\":32957,\"start\":32411},{\"end\":33717,\"start\":32959},{\"end\":34955,\"start\":33736},{\"end\":35368,\"start\":34957},{\"end\":35831,\"start\":35370},{\"end\":36459,\"start\":35846},{\"end\":36899,\"start\":36461},{\"end\":37165,\"start\":36901},{\"end\":37516,\"start\":37192},{\"end\":37964,\"start\":37518},{\"end\":38124,\"start\":37998},{\"end\":38771,\"start\":38157},{\"end\":39269,\"start\":38773},{\"end\":40149,\"start\":39271},{\"end\":40551,\"start\":40151},{\"end\":41627,\"start\":40553},{\"end\":43093,\"start\":41657},{\"end\":43324,\"start\":43095},{\"end\":44080,\"start\":43326},{\"end\":44982,\"start\":44106},{\"end\":45972,\"start\":44984},{\"end\":46691,\"start\":45974},{\"end\":47615,\"start\":46725},{\"end\":48416,\"start\":47617},{\"end\":49192,\"start\":48435}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21125,\"start\":21118},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":27154,\"start\":27146},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":38260,\"start\":38252},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":42038,\"start\":42030},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":45155,\"start\":45147}]", "section_header": "[{\"end\":1995,\"start\":1980},{\"end\":8119,\"start\":8088},{\"end\":8401,\"start\":8376},{\"end\":9903,\"start\":9868},{\"end\":12519,\"start\":12478},{\"end\":14622,\"start\":14589},{\"end\":16701,\"start\":16678},{\"end\":17079,\"start\":17058},{\"end\":19208,\"start\":19194},{\"end\":19494,\"start\":19476},{\"end\":21150,\"start\":21129},{\"end\":22530,\"start\":22508},{\"end\":24044,\"start\":24014},{\"end\":24286,\"start\":24260},{\"end\":25077,\"start\":25047},{\"end\":26428,\"start\":26409},{\"end\":27058,\"start\":27045},{\"end\":29126,\"start\":29092},{\"end\":30116,\"start\":30083},{\"end\":31107,\"start\":31070},{\"end\":32155,\"start\":32124},{\"end\":32409,\"start\":32388},{\"end\":33734,\"start\":33720},{\"end\":35844,\"start\":35834},{\"end\":37190,\"start\":37168},{\"end\":37996,\"start\":37967},{\"end\":38155,\"start\":38127},{\"end\":41655,\"start\":41630},{\"end\":44104,\"start\":44083},{\"end\":46723,\"start\":46694},{\"end\":48433,\"start\":48419},{\"end\":49202,\"start\":49194},{\"end\":49524,\"start\":49516},{\"end\":50181,\"start\":50173},{\"end\":50437,\"start\":50428},{\"end\":50610,\"start\":50600},{\"end\":51575,\"start\":51564},{\"end\":52026,\"start\":52016}]", "table": "[{\"end\":50598,\"start\":50494},{\"end\":51562,\"start\":50645},{\"end\":52014,\"start\":51611},{\"end\":52308,\"start\":52193}]", "figure_caption": "[{\"end\":49514,\"start\":49204},{\"end\":49674,\"start\":49526},{\"end\":50171,\"start\":49677},{\"end\":50426,\"start\":50183},{\"end\":50494,\"start\":50439},{\"end\":50645,\"start\":50613},{\"end\":51611,\"start\":51579},{\"end\":52193,\"start\":52029}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":24487,\"start\":24479},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":25242,\"start\":25234},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":26912,\"start\":26904},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27144,\"start\":27126},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":29701,\"start\":29684},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":30455,\"start\":30437},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":31635,\"start\":31627},{\"end\":33785,\"start\":33777},{\"end\":34562,\"start\":34556},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":34724,\"start\":34716},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35171,\"start\":35155},{\"end\":35476,\"start\":35468},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":41838,\"start\":41830},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":42936,\"start\":42928},{\"end\":44652,\"start\":44644}]", "bib_author_first_name": "[{\"end\":52365,\"start\":52364},{\"end\":52563,\"start\":52562},{\"end\":52576,\"start\":52575},{\"end\":52782,\"start\":52781},{\"end\":52793,\"start\":52792},{\"end\":52795,\"start\":52794},{\"end\":52805,\"start\":52804},{\"end\":53393,\"start\":53392},{\"end\":53403,\"start\":53402},{\"end\":53855,\"start\":53854},{\"end\":53866,\"start\":53865},{\"end\":53878,\"start\":53877},{\"end\":53888,\"start\":53887},{\"end\":53897,\"start\":53896},{\"end\":53908,\"start\":53907},{\"end\":53917,\"start\":53916},{\"end\":53930,\"start\":53929},{\"end\":53938,\"start\":53937},{\"end\":53948,\"start\":53947},{\"end\":54450,\"start\":54449},{\"end\":54458,\"start\":54457},{\"end\":54468,\"start\":54467},{\"end\":54484,\"start\":54483},{\"end\":54496,\"start\":54495},{\"end\":54510,\"start\":54509},{\"end\":54520,\"start\":54519},{\"end\":54532,\"start\":54531},{\"end\":54545,\"start\":54544},{\"end\":54553,\"start\":54552},{\"end\":54808,\"start\":54807},{\"end\":54816,\"start\":54815},{\"end\":55178,\"start\":55177},{\"end\":55182,\"start\":55179},{\"end\":55280,\"start\":55279},{\"end\":55282,\"start\":55281},{\"end\":55290,\"start\":55289},{\"end\":55292,\"start\":55291},{\"end\":55299,\"start\":55298},{\"end\":55301,\"start\":55300},{\"end\":55466,\"start\":55465},{\"end\":55477,\"start\":55476},{\"end\":55586,\"start\":55585},{\"end\":55809,\"start\":55808},{\"end\":55811,\"start\":55810},{\"end\":56044,\"start\":56043},{\"end\":56056,\"start\":56055},{\"end\":56058,\"start\":56057},{\"end\":56069,\"start\":56068},{\"end\":56861,\"start\":56860},{\"end\":56870,\"start\":56869},{\"end\":56872,\"start\":56871},{\"end\":57174,\"start\":57173},{\"end\":57187,\"start\":57186},{\"end\":57201,\"start\":57200},{\"end\":57211,\"start\":57210},{\"end\":57814,\"start\":57813},{\"end\":57824,\"start\":57823},{\"end\":57834,\"start\":57833},{\"end\":57844,\"start\":57843},{\"end\":58189,\"start\":58188},{\"end\":58191,\"start\":58190},{\"end\":58203,\"start\":58202},{\"end\":58509,\"start\":58508},{\"end\":58521,\"start\":58520},{\"end\":58529,\"start\":58528},{\"end\":58542,\"start\":58541},{\"end\":58553,\"start\":58552},{\"end\":59226,\"start\":59225},{\"end\":59238,\"start\":59237},{\"end\":59249,\"start\":59248},{\"end\":60369,\"start\":60368},{\"end\":60872,\"start\":60871},{\"end\":60882,\"start\":60881},{\"end\":61138,\"start\":61137},{\"end\":61148,\"start\":61147},{\"end\":61158,\"start\":61157},{\"end\":61172,\"start\":61171},{\"end\":61182,\"start\":61181},{\"end\":61193,\"start\":61192},{\"end\":61676,\"start\":61675},{\"end\":61678,\"start\":61677},{\"end\":61686,\"start\":61685},{\"end\":61688,\"start\":61687},{\"end\":62773,\"start\":62772},{\"end\":62775,\"start\":62774},{\"end\":62784,\"start\":62783},{\"end\":62792,\"start\":62791},{\"end\":63074,\"start\":63073},{\"end\":63076,\"start\":63075},{\"end\":63083,\"start\":63082},{\"end\":63085,\"start\":63084},{\"end\":63095,\"start\":63094},{\"end\":63445,\"start\":63444},{\"end\":63462,\"start\":63461},{\"end\":63473,\"start\":63472},{\"end\":63480,\"start\":63479},{\"end\":64150,\"start\":64149},{\"end\":64159,\"start\":64158},{\"end\":64436,\"start\":64432},{\"end\":64446,\"start\":64442},{\"end\":64458,\"start\":64454},{\"end\":64657,\"start\":64656},{\"end\":64659,\"start\":64658},{\"end\":64670,\"start\":64669},{\"end\":64672,\"start\":64671},{\"end\":64681,\"start\":64680},{\"end\":64683,\"start\":64682},{\"end\":64988,\"start\":64987},{\"end\":64990,\"start\":64989},{\"end\":65000,\"start\":64999},{\"end\":65002,\"start\":65001},{\"end\":65012,\"start\":65011},{\"end\":65014,\"start\":65013},{\"end\":65022,\"start\":65021},{\"end\":65024,\"start\":65023},{\"end\":65301,\"start\":65300},{\"end\":65303,\"start\":65302},{\"end\":65313,\"start\":65312},{\"end\":65315,\"start\":65314},{\"end\":65325,\"start\":65324},{\"end\":65334,\"start\":65333},{\"end\":65343,\"start\":65342},{\"end\":65615,\"start\":65614},{\"end\":65617,\"start\":65616},{\"end\":65629,\"start\":65628},{\"end\":65788,\"start\":65787},{\"end\":65801,\"start\":65800},{\"end\":65814,\"start\":65813},{\"end\":65826,\"start\":65825},{\"end\":65836,\"start\":65835},{\"end\":65847,\"start\":65846},{\"end\":65857,\"start\":65856},{\"end\":65868,\"start\":65867},{\"end\":65884,\"start\":65883},{\"end\":65893,\"start\":65892},{\"end\":66258,\"start\":66257},{\"end\":66269,\"start\":66268},{\"end\":66842,\"start\":66841},{\"end\":66854,\"start\":66853},{\"end\":66856,\"start\":66855},{\"end\":66862,\"start\":66861},{\"end\":66981,\"start\":66980},{\"end\":66985,\"start\":66982}]", "bib_author_last_name": "[{\"end\":52370,\"start\":52366},{\"end\":52573,\"start\":52564},{\"end\":52586,\"start\":52577},{\"end\":52790,\"start\":52783},{\"end\":52802,\"start\":52796},{\"end\":52812,\"start\":52806},{\"end\":53400,\"start\":53394},{\"end\":53412,\"start\":53404},{\"end\":53863,\"start\":53856},{\"end\":53875,\"start\":53867},{\"end\":53885,\"start\":53879},{\"end\":53894,\"start\":53889},{\"end\":53905,\"start\":53898},{\"end\":53914,\"start\":53909},{\"end\":53927,\"start\":53918},{\"end\":53935,\"start\":53931},{\"end\":53945,\"start\":53939},{\"end\":53958,\"start\":53949},{\"end\":54455,\"start\":54451},{\"end\":54465,\"start\":54459},{\"end\":54481,\"start\":54469},{\"end\":54493,\"start\":54485},{\"end\":54507,\"start\":54497},{\"end\":54517,\"start\":54511},{\"end\":54529,\"start\":54521},{\"end\":54542,\"start\":54533},{\"end\":54550,\"start\":54546},{\"end\":54562,\"start\":54554},{\"end\":54813,\"start\":54809},{\"end\":54826,\"start\":54817},{\"end\":55187,\"start\":55183},{\"end\":55287,\"start\":55283},{\"end\":55296,\"start\":55293},{\"end\":55310,\"start\":55302},{\"end\":55474,\"start\":55467},{\"end\":55486,\"start\":55478},{\"end\":55594,\"start\":55587},{\"end\":55821,\"start\":55812},{\"end\":56053,\"start\":56045},{\"end\":56066,\"start\":56059},{\"end\":56077,\"start\":56070},{\"end\":56867,\"start\":56862},{\"end\":57184,\"start\":57175},{\"end\":57198,\"start\":57188},{\"end\":57208,\"start\":57202},{\"end\":57221,\"start\":57212},{\"end\":57821,\"start\":57815},{\"end\":57831,\"start\":57825},{\"end\":57841,\"start\":57835},{\"end\":57851,\"start\":57845},{\"end\":58200,\"start\":58192},{\"end\":58212,\"start\":58204},{\"end\":58518,\"start\":58510},{\"end\":58526,\"start\":58522},{\"end\":58539,\"start\":58530},{\"end\":58550,\"start\":58543},{\"end\":58567,\"start\":58554},{\"end\":59235,\"start\":59227},{\"end\":59246,\"start\":59239},{\"end\":59263,\"start\":59250},{\"end\":60376,\"start\":60370},{\"end\":60879,\"start\":60873},{\"end\":60889,\"start\":60883},{\"end\":61145,\"start\":61139},{\"end\":61155,\"start\":61149},{\"end\":61169,\"start\":61159},{\"end\":61179,\"start\":61173},{\"end\":61190,\"start\":61183},{\"end\":61207,\"start\":61194},{\"end\":61683,\"start\":61679},{\"end\":61695,\"start\":61689},{\"end\":62781,\"start\":62776},{\"end\":62789,\"start\":62785},{\"end\":62800,\"start\":62793},{\"end\":63080,\"start\":63077},{\"end\":63092,\"start\":63086},{\"end\":63102,\"start\":63096},{\"end\":63459,\"start\":63446},{\"end\":63470,\"start\":63463},{\"end\":63477,\"start\":63474},{\"end\":63485,\"start\":63481},{\"end\":64156,\"start\":64151},{\"end\":64164,\"start\":64160},{\"end\":64440,\"start\":64437},{\"end\":64452,\"start\":64447},{\"end\":64462,\"start\":64459},{\"end\":64667,\"start\":64660},{\"end\":64678,\"start\":64673},{\"end\":64690,\"start\":64684},{\"end\":64997,\"start\":64991},{\"end\":65009,\"start\":65003},{\"end\":65019,\"start\":65015},{\"end\":65035,\"start\":65025},{\"end\":65310,\"start\":65304},{\"end\":65322,\"start\":65316},{\"end\":65331,\"start\":65326},{\"end\":65340,\"start\":65335},{\"end\":65353,\"start\":65344},{\"end\":65624,\"start\":65618},{\"end\":65638,\"start\":65630},{\"end\":65798,\"start\":65789},{\"end\":65811,\"start\":65802},{\"end\":65823,\"start\":65815},{\"end\":65833,\"start\":65827},{\"end\":65844,\"start\":65837},{\"end\":65854,\"start\":65848},{\"end\":65865,\"start\":65858},{\"end\":65881,\"start\":65869},{\"end\":65890,\"start\":65885},{\"end\":65901,\"start\":65894},{\"end\":66266,\"start\":66259},{\"end\":66285,\"start\":66270},{\"end\":66851,\"start\":66843},{\"end\":66859,\"start\":66857},{\"end\":66867,\"start\":66863},{\"end\":66996,\"start\":66986}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":52496,\"start\":52310},{\"attributes\":{\"id\":\"b1\"},\"end\":52718,\"start\":52498},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":11703129},\"end\":52977,\"start\":52720},{\"attributes\":{\"id\":\"b3\"},\"end\":53133,\"start\":52979},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":14398817},\"end\":53344,\"start\":53135},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15440612},\"end\":53828,\"start\":53346},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":8156476},\"end\":54405,\"start\":53830},{\"attributes\":{\"id\":\"b7\"},\"end\":54745,\"start\":54407},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":39486239},\"end\":55140,\"start\":54747},{\"attributes\":{\"id\":\"b9\"},\"end\":55242,\"start\":55142},{\"attributes\":{\"id\":\"b10\"},\"end\":55463,\"start\":55244},{\"attributes\":{\"id\":\"b11\"},\"end\":55583,\"start\":55465},{\"attributes\":{\"id\":\"b12\"},\"end\":55731,\"start\":55585},{\"attributes\":{\"id\":\"b13\"},\"end\":55974,\"start\":55733},{\"attributes\":{\"doi\":\"10.3115/1034678.1034760\",\"id\":\"b14\",\"matched_paper_id\":7031344},\"end\":56804,\"start\":55976},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":10157083},\"end\":57100,\"start\":56806},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":11218013},\"end\":57728,\"start\":57102},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":7843537},\"end\":58121,\"start\":57730},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":17406565},\"end\":58438,\"start\":58123},{\"attributes\":{\"doi\":\"10.1145/1858996.1859006\",\"id\":\"b19\",\"matched_paper_id\":9790585},\"end\":59149,\"start\":58440},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":11106352},\"end\":59713,\"start\":59151},{\"attributes\":{\"doi\":\"10.1145/1985793.1985808\",\"id\":\"b21\"},\"end\":59793,\"start\":59715},{\"attributes\":{\"doi\":\"10.1109/ICPC.2011.28\",\"id\":\"b22\",\"matched_paper_id\":2992151},\"end\":60321,\"start\":59795},{\"attributes\":{\"doi\":\"10.1145/2591062.2591096\",\"id\":\"b23\",\"matched_paper_id\":18946755},\"end\":60804,\"start\":60323},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":4861489},\"end\":61066,\"start\":60806},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":1129667},\"end\":61623,\"start\":61068},{\"attributes\":{\"doi\":\"10.1145/1390630.1390664\",\"id\":\"b26\",\"matched_paper_id\":919701},\"end\":62208,\"start\":61625},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":207168405},\"end\":62638,\"start\":62210},{\"attributes\":{\"doi\":\"10.1145/1390630.1390647\",\"id\":\"b28\"},\"end\":62718,\"start\":62640},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":94818},\"end\":62985,\"start\":62720},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":22321032},\"end\":63343,\"start\":62987},{\"attributes\":{\"doi\":\"10.1109/RE.2006.65\",\"id\":\"b31\",\"matched_paper_id\":18511667},\"end\":64080,\"start\":63345},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":13451873},\"end\":64378,\"start\":64082},{\"attributes\":{\"id\":\"b33\"},\"end\":64565,\"start\":64380},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":207155015},\"end\":64934,\"start\":64567},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":1554582},\"end\":65273,\"start\":64936},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":661123},\"end\":65583,\"start\":65275},{\"attributes\":{\"id\":\"b37\"},\"end\":65743,\"start\":65585},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":10659969},\"end\":66196,\"start\":65745},{\"attributes\":{\"doi\":\"10.1145/1143844.1143865\",\"id\":\"b39\",\"matched_paper_id\":15619865},\"end\":66773,\"start\":66198},{\"attributes\":{\"id\":\"b40\"},\"end\":66978,\"start\":66775},{\"attributes\":{\"id\":\"b41\"},\"end\":67161,\"start\":66980}]", "bib_title": "[{\"end\":52779,\"start\":52720},{\"end\":53173,\"start\":53135},{\"end\":53390,\"start\":53346},{\"end\":53852,\"start\":53830},{\"end\":54805,\"start\":54747},{\"end\":56041,\"start\":55976},{\"end\":56858,\"start\":56806},{\"end\":57171,\"start\":57102},{\"end\":57811,\"start\":57730},{\"end\":58186,\"start\":58123},{\"end\":58506,\"start\":58440},{\"end\":59223,\"start\":59151},{\"end\":59862,\"start\":59795},{\"end\":60366,\"start\":60323},{\"end\":60869,\"start\":60806},{\"end\":61135,\"start\":61068},{\"end\":61673,\"start\":61625},{\"end\":62243,\"start\":62210},{\"end\":62770,\"start\":62720},{\"end\":63071,\"start\":62987},{\"end\":63442,\"start\":63345},{\"end\":64147,\"start\":64082},{\"end\":64654,\"start\":64567},{\"end\":64985,\"start\":64936},{\"end\":65298,\"start\":65275},{\"end\":65785,\"start\":65745},{\"end\":66255,\"start\":66198}]", "bib_author": "[{\"end\":52372,\"start\":52364},{\"end\":52575,\"start\":52562},{\"end\":52588,\"start\":52575},{\"end\":52792,\"start\":52781},{\"end\":52804,\"start\":52792},{\"end\":52814,\"start\":52804},{\"end\":53402,\"start\":53392},{\"end\":53414,\"start\":53402},{\"end\":53865,\"start\":53854},{\"end\":53877,\"start\":53865},{\"end\":53887,\"start\":53877},{\"end\":53896,\"start\":53887},{\"end\":53907,\"start\":53896},{\"end\":53916,\"start\":53907},{\"end\":53929,\"start\":53916},{\"end\":53937,\"start\":53929},{\"end\":53947,\"start\":53937},{\"end\":53960,\"start\":53947},{\"end\":54457,\"start\":54449},{\"end\":54467,\"start\":54457},{\"end\":54483,\"start\":54467},{\"end\":54495,\"start\":54483},{\"end\":54509,\"start\":54495},{\"end\":54519,\"start\":54509},{\"end\":54531,\"start\":54519},{\"end\":54544,\"start\":54531},{\"end\":54552,\"start\":54544},{\"end\":54564,\"start\":54552},{\"end\":54815,\"start\":54807},{\"end\":54828,\"start\":54815},{\"end\":55189,\"start\":55177},{\"end\":55289,\"start\":55279},{\"end\":55298,\"start\":55289},{\"end\":55312,\"start\":55298},{\"end\":55476,\"start\":55465},{\"end\":55488,\"start\":55476},{\"end\":55596,\"start\":55585},{\"end\":55823,\"start\":55808},{\"end\":56055,\"start\":56043},{\"end\":56068,\"start\":56055},{\"end\":56079,\"start\":56068},{\"end\":56869,\"start\":56860},{\"end\":56875,\"start\":56869},{\"end\":57186,\"start\":57173},{\"end\":57200,\"start\":57186},{\"end\":57210,\"start\":57200},{\"end\":57223,\"start\":57210},{\"end\":57823,\"start\":57813},{\"end\":57833,\"start\":57823},{\"end\":57843,\"start\":57833},{\"end\":57853,\"start\":57843},{\"end\":58202,\"start\":58188},{\"end\":58214,\"start\":58202},{\"end\":58520,\"start\":58508},{\"end\":58528,\"start\":58520},{\"end\":58541,\"start\":58528},{\"end\":58552,\"start\":58541},{\"end\":58569,\"start\":58552},{\"end\":59237,\"start\":59225},{\"end\":59248,\"start\":59237},{\"end\":59265,\"start\":59248},{\"end\":60378,\"start\":60368},{\"end\":60881,\"start\":60871},{\"end\":60891,\"start\":60881},{\"end\":61147,\"start\":61137},{\"end\":61157,\"start\":61147},{\"end\":61171,\"start\":61157},{\"end\":61181,\"start\":61171},{\"end\":61192,\"start\":61181},{\"end\":61209,\"start\":61192},{\"end\":61685,\"start\":61675},{\"end\":61697,\"start\":61685},{\"end\":62783,\"start\":62772},{\"end\":62791,\"start\":62783},{\"end\":62802,\"start\":62791},{\"end\":63082,\"start\":63073},{\"end\":63094,\"start\":63082},{\"end\":63104,\"start\":63094},{\"end\":63461,\"start\":63444},{\"end\":63472,\"start\":63461},{\"end\":63479,\"start\":63472},{\"end\":63487,\"start\":63479},{\"end\":64158,\"start\":64149},{\"end\":64166,\"start\":64158},{\"end\":64442,\"start\":64432},{\"end\":64454,\"start\":64442},{\"end\":64464,\"start\":64454},{\"end\":64669,\"start\":64656},{\"end\":64680,\"start\":64669},{\"end\":64692,\"start\":64680},{\"end\":64999,\"start\":64987},{\"end\":65011,\"start\":64999},{\"end\":65021,\"start\":65011},{\"end\":65037,\"start\":65021},{\"end\":65312,\"start\":65300},{\"end\":65324,\"start\":65312},{\"end\":65333,\"start\":65324},{\"end\":65342,\"start\":65333},{\"end\":65355,\"start\":65342},{\"end\":65628,\"start\":65614},{\"end\":65640,\"start\":65628},{\"end\":65800,\"start\":65787},{\"end\":65813,\"start\":65800},{\"end\":65825,\"start\":65813},{\"end\":65835,\"start\":65825},{\"end\":65846,\"start\":65835},{\"end\":65856,\"start\":65846},{\"end\":65867,\"start\":65856},{\"end\":65883,\"start\":65867},{\"end\":65892,\"start\":65883},{\"end\":65903,\"start\":65892},{\"end\":66268,\"start\":66257},{\"end\":66287,\"start\":66268},{\"end\":66853,\"start\":66841},{\"end\":66861,\"start\":66853},{\"end\":66869,\"start\":66861},{\"end\":66998,\"start\":66980}]", "bib_venue": "[{\"end\":52847,\"start\":52839},{\"end\":53563,\"start\":53497},{\"end\":54139,\"start\":54058},{\"end\":56369,\"start\":56234},{\"end\":57446,\"start\":57343},{\"end\":58796,\"start\":58694},{\"end\":59443,\"start\":59354},{\"end\":60067,\"start\":59984},{\"end\":60523,\"start\":60506},{\"end\":61372,\"start\":61299},{\"end\":61916,\"start\":61818},{\"end\":62441,\"start\":62343},{\"end\":63693,\"start\":63598},{\"end\":66480,\"start\":66395},{\"end\":67036,\"start\":67021},{\"end\":52362,\"start\":52310},{\"end\":52560,\"start\":52498},{\"end\":52837,\"start\":52814},{\"end\":53036,\"start\":52979},{\"end\":53216,\"start\":53175},{\"end\":53495,\"start\":53414},{\"end\":54056,\"start\":53960},{\"end\":54447,\"start\":54407},{\"end\":54926,\"start\":54828},{\"end\":55175,\"start\":55142},{\"end\":55277,\"start\":55244},{\"end\":55517,\"start\":55488},{\"end\":55647,\"start\":55596},{\"end\":55806,\"start\":55733},{\"end\":56232,\"start\":56102},{\"end\":56927,\"start\":56875},{\"end\":57341,\"start\":57223},{\"end\":57904,\"start\":57853},{\"end\":58255,\"start\":58214},{\"end\":58692,\"start\":58592},{\"end\":59352,\"start\":59265},{\"end\":59982,\"start\":59884},{\"end\":60504,\"start\":60401},{\"end\":60914,\"start\":60891},{\"end\":61297,\"start\":61209},{\"end\":61816,\"start\":61720},{\"end\":62341,\"start\":62245},{\"end\":62827,\"start\":62802},{\"end\":63139,\"start\":63104},{\"end\":63596,\"start\":63505},{\"end\":64205,\"start\":64166},{\"end\":64430,\"start\":64380},{\"end\":64726,\"start\":64692},{\"end\":65080,\"start\":65037},{\"end\":65402,\"start\":65355},{\"end\":65612,\"start\":65585},{\"end\":65939,\"start\":65903},{\"end\":66393,\"start\":66310},{\"end\":66839,\"start\":66775},{\"end\":67019,\"start\":66998}]"}}}, "year": 2023, "month": 12, "day": 17}