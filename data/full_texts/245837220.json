{"id": 245837220, "updated": "2023-10-05 17:59:40.196", "metadata": {"title": "Adaptive Performance Anomaly Detection for Online Service Systems via Pattern Sketching", "authors": "[{\"first\":\"Zhuangbin\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Jinyang\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Yuxin\",\"last\":\"Su\",\"middle\":[]},{\"first\":\"Hongyu\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Xiao\",\"last\":\"Ling\",\"middle\":[]},{\"first\":\"Yongqiang\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Michael\",\"last\":\"Lyu\",\"middle\":[\"R.\"]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "To ensure the performance of online service systems, their status is closely monitored with various software and system metrics. Performance anomalies represent the performance degradation issues (e.g., slow response) of the service systems. When performing anomaly detection over the metrics, existing methods often lack the merit of interpretability, which is vital for engineers and analysts to take remediation actions. Moreover, they are unable to effectively accommodate the ever-changing services in an online fashion. To address these limitations, in this paper, we propose ADSketch, an interpretable and adaptive performance anomaly detection approach based on pattern sketching. ADSketch achieves interpretability by identifying groups of anomalous metric patterns, which represent particular types of performance issues. The underlying issues can then be immediately recognized if similar patterns emerge again. In addition, an adaptive learning algorithm is designed to embrace unprecedented patterns induced by service updates or user behavior changes. The proposed approach is evaluated with public data as well as industrial data collected from a representative online service system in Huawei Cloud. The experimental results show that ADSketch outperforms state-of-the-art approaches by a significant margin, and demonstrate the effectiveness of the online algorithm in new pattern discovery. Furthermore, our approach has been successfully deployed in industrial practice.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2201.02944", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icse/ChenL00LL22", "doi": "10.1145/3510003.3510085"}}, "content": {"source": {"pdf_hash": "57d284a57ada4700b19b4faaea571cb6427f3849", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2201.02944v4.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "2310ffbf033d4a1f8d85c4bf7d41b2d26f6d071b", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/57d284a57ada4700b19b4faaea571cb6427f3849.txt", "contents": "\nAdaptive Performance Anomaly Detection for Online Service Systems via Pattern Sketching\nMay 21-29, 2022. 2022. May 21-29, 2022\n\nZhuangbin Chen \nJinyang Liu \nYuxin Su \nHongyu Zhang \nXiao Ling \nYongqiang Yang \nMichael R Lyu \nZhuangbin Chen \nJinyang Liu \nYuxin Su \nHongyu Zhang \nXiao Ling \nYongqiang Yang \nMichael R Lyu \n\nThe Chinese University of Hong Kong Hong Kong\nChina\n\n\nSchool of Software Engineering Sun Yat-sen University Zhuhai\nThe Chinese University of Hong Kong Hong Kong\nChina, China\n\n\nThe University of Newcastle NSW\nAustralia\n\n\nHuawei Cloud BU\nBeijingChina\n\n\nThe Chinese University of Hong Kong Hong Kong\nChina\n\nAdaptive Performance Anomaly Detection for Online Service Systems via Pattern Sketching\n\n44th International Con-ference on Software Engineering (ICSE '22)\nPittsburgh, PA, USA; Pittsburgh, PAMay 21-29, 2022. 2022. May 21-29, 2022ACM ISBN 978-1-4503-9221-1/22/05. . . $15.00 USA. ACM, New York, NY, USA, 12 pages. https://CCS CONCEPTS \u2022 Computer systems organization \u2192 Cloud computingReli- abilityMaintainability and maintenance KEYWORDS Cloud computing, performance anomaly detection, online learning * Corresponding author (\nTo ensure the performance of online service systems, their status is closely monitored with various software and system metrics. Performance anomalies represent the performance degradation issues (e.g., slow response) of the service systems. When performing anomaly detection over the metrics, existing methods often lack the merit of interpretability, which is vital for engineers and analysts to take remediation actions. Moreover, they are unable to effectively accommodate the ever-changing services in an online fashion. To address these limitations, in this paper, we propose ADSketch, an interpretable and adaptive performance anomaly detection approach based on pattern sketching. ADSketch achieves interpretability by identifying groups of anomalous metric patterns, which represent particular types of performance issues. The underlying issues can then be immediately recognized if similar patterns emerge again. In addition, an adaptive learning algorithm is designed to embrace unprecedented patterns induced by service updates or user behavior changes. The proposed approach is evaluated with public data as well as industrial data collected from a representative online service system in Huawei Cloud. The experimental results show that ADSketch outperforms state-of-the-art approaches by a significant margin, and demonstrate the effectiveness of the online algorithm in new pattern discovery. Furthermore, our approach has been successfully deployed in industrial practice.\n\nINTRODUCTION\n\nWith the emergence of cloud computing, many traditional software systems have been migrated to cloud computing platforms as online services. Similar to conventional shrink-wrapped software, the performance of online service systems is an important quality attribute. As online services need to serve millions of customers worldwide, a short period of performance degradation could lead to economic loss and user dissatisfaction. Therefore, proactive and even adaptive system troubleshooting has become the core competence of online service providers. Enterprises that have promoted the automation of system troubleshooting have already received real gains in reliability, efficiency, and agility [6,7,21].\n\nIn industrial scenarios, online service systems are closely monitored with various metrics (e.g., the CPU usage of an application, service response delay) on a 24\u00d77 basis. This is because the monitoring metrics often serve as the most direct and fine-grained signals that flag the occurrence of service performance issues. In addition, they provide informative clues for engineers to pinpoint the root causes. However, due to the large scale and complexity of online service systems, the number of metrics is overwhelming the existing troubleshooting systems [6]. Automated anomaly detection over the metrics, which aims to discover the unexpected or rare behaviors of the metric time series, is therefore an important means to ensure the reliability and availability of service systems.\n\nAlthough many efforts, e.g., [13,32,37], have been devoted to performance anomaly detection, most of the existing work does not possess the merit of interpretability. Specifically, at each timestamp, they calculate a probability indicating the likelihood of performance anomalies. A threshold is then chosen to convert the probability into a binary label -normal vs. anomaly. However, in reality, a simple recommendation of the suspicious anomalies might not be of much interest to engineers. This is because they need to manually investigate the problematic metrics (recommended by the model) for fault localization. For large-scale online services, this process is like finding a needle in a haystack. The problem is compounded by the fact that false alerts are not rare. Moreover, many stateof-the-art methods train models with historical metric data in an offline setting. As online services continuously undergo feature upgrades and system renewal, the patterns of metrics may evolve accordingly, i.e., concept drift [11,12]. Without adaptability, these models are unable to accommodate the ever-changing services and user behaviors.\n\nIn this paper, we propose ADSketch, a performance anomaly detection approach for online service systems based on pattern sketching, which is interpretable and adaptive. The main idea is to identify discriminative subsequences from metric time series that can represent classes of service performance issues. This is similar to the problem of shapelet discovery in time series data [28,36]. Particularly, for multiple subsequences that describe the same type of performance issue, we take the average of them and regard the result as a metric pattern for the issue. For example, services may be experiencing performance degradation when we observe a level shift down on Service Throughput or a level shift up on CPU Utilization. The advantages of such metric patterns are twofold. First, the normality of the incoming metric subsequences can be quickly determined through a comparison with the metric patterns. Second, by associating the patterns with typical anomaly symptoms, we can immediately understand the ongoing performance issues when the metric subsequences exhibit known patterns. This is similar to failure/issue profiling [18,22,27]. In this way, ADSketch provides a novel mechanism to characterize service performance issues with metric time series. Previous work on failure/issue profiling often requires handcrafted features, which suffers from limited generalization. For example, Brandon et al. [4] manually defined a set of features collected from metrics, logs, and anomalies to characterize failures. Pattern sketching with metrics enjoys the advantages of automation and accuracy. Moreover, ADSketch is able to adaptively embrace new anomalous patterns when detecting anomalies on the fly. Experimental results demonstrate the superiority of our design over the existing state-of-the-art time series anomaly detectors on both public and industrial data. In particular, we have achieved an average F1 score of over 0.8 in production systems.\n\nTo sum up, this work makes the following major contributions:\n\n\u2022 We propose ADSketch, an interpretable and adaptive approach for service performance anomaly detection. ADSketch offers a way to characterize service performance issues with monitoring metrics. Different from the existing work, ADSketch is able to provide explanations (e.g., the type of the underlying performance issues) for its prediction results and accept new patterns on the fly. The implementation of ADSketch and datasets are publicly available on GitHub 1 . \u2022 We conduct experiments with public data as well as industrial service metric data collected from Huawei Cloud. The experimental results demonstrate the effectiveness of ADSketch in terms of both anomaly detection and adaptive metric pattern learning. Furthermore, our framework has been successfully incorporated into the service performance monitoring system of Huawei Cloud. Our industrial practice confirms its practical usefulness. In online service systems, a large number of metrics are configured to monitor various aspects of both logical resources (e.g., a virtual machine) and physical resources (e.g., a computing server). Cloud systems often possess an abundance of redundant components, providing the ability of fault tolerance and self-healing (e.g., load balancing, availability zones). Consequently, the majority of service breakdowns tend to manifest themselves as performance anomalies first instead of fail-stop failures [14,20]. We observe when performance anomalies of similar types happen, their impacts tend to trigger similar reactions/symptoms on the metric time series, which we refer to as metric patterns. For example, a level shift up on Interface Throughput may indicate slow service response, which could be caused by a load balancing failure; a level shift down on it may suggest service unavailability, and the culprit could be performance bugs (e.g., memory leak bugs). Similar observations have been made in [8,22]. The rationale behind such a phenomenon is twofold. First, the design of the metrics is sophisticated and fine-grained, each of which is dedicated to monitoring a specific problem, e.g., request timeout, high API error rate. Second, cloud systems widely employ the microservices architecture, where cloud applications employ lightweight container deployment, e.g., cloud-native applications, serverless computing. With this architecture, each microservice is designated for well-defined and modularized jobs, e.g., user login, location service. Thus, they tend to develop individual and stable patterns, which can manifest through their monitoring metrics.\n\n\nMetric Pattern Mining\n\nMetric patterns (i.e., time-series subsequences describing the misbehaving moments of metrics) can be leveraged to sketch the performance issues for anomaly detection. This is essentially profiling the mode of recurrent anomalies.  In online scenarios, if a metric encounters any known anomalous patterns, the underlying performance issues can be recommended. Pattern sketching therefore provides a means to accumulate and utilize engineers' knowledge.\n\nIn real-world scenarios, the patterns exhibited in metrics are extremely complicated and can have numerous variants in terms of scale, length, and combination. Particularly, we have identified the following challenges for metric pattern discovery, which are illustrated in Fig. 1. Each metric time series records around one week of monitoring data, whose anomalies are shown in red.\n\nBackground noise. Although a large amount of metric time series is generated, a significant portion of them is trivial, which only records plain system runtime behaviors. Moreover, due to the dynamics of online services, some metrics may experience concept drift [11]. For example, the Application CPU Usage in Fig. 1 drops abruptly, which could be caused by a role switch (e.g., from a primary node to a backup node) or user behavior change. How to distinguish anomalous patterns from normal ones is non-trivial.\n\nPattern variety. A metric curve can possess multiple distinct patterns simultaneously. For example, in Fig. 1, the Interface Throughput has two anomaly patterns, i.e., spike up and spike down. Also, the patterns can have different scales, as indicated by the two spikes in the Request Timeout Number. We need to consider the context of each metric for pattern extraction.\n\nVarying anomaly duration. Different performance issues may vary in duration. The first two anomalies in the Interface Throughput constitute such an example. Particularly, how long an anomaly lasts is also an important factor that engineers rely on to understand a service's health state. When characterizing the issues, such a fact should be properly considered.\n\n\nProblem Statement\n\nThe goal of this work is to detect performance anomalies for modern software systems, especially online service systems, based on monitoring metrics. To facilitate issue understanding and problem mitigation, we intend to improve the interpretability of the detection results. To this end, we propose to sketch performance issues with metrics based on our observation that similar issues often exhibit alike patterns. By extracting such anomalous metric An anomaly-free metric time series T An input metric time series for anomaly detection A subsequence of metric time series The length of the metric subsequence The percentile threshold to find deviated subseqs P\n\nThe index set of normal metric patterns P\n\nThe index set of anomalous metric patterns The vector of cluster mean vectors S\n\nThe vector of cluster sizes R\n\nThe vector of cluster radii patterns, we can conduct performance anomaly detection by examining whether the incoming metric subsequences match the known patterns. Moreover, by associating the extracted metric patterns to specific performance issues, we can obtain a quick understanding of the ongoing issues in online scenarios. Additionally, as online services are continuously evolving, unprecedented metric patterns may emerge. Thus, our algorithm should be adaptive to the new patterns. The problem can be formally defined as follows. The input of a metric time series can be represented as T \u2208 R = [ 1 , 2 , ..., ], where is the number of observations. = [ , ..., + \u22121 ] is a consecutive subsequence of T starting from with length , where \u2208 [0, \u2212 ]. The objective of performance anomaly detection is to determine whether or not a given is anomalous, i.e., whether there are performance issues happening from timestamp to + \u2212 1. Particularly, we also try to explain the type of performance issues associated with . The anomalous subsequences will be used to construct abnormal metric patterns, while the benign ones will be regarded as normal patterns. Both the normal and abnormal metric patterns will be updated as the anomaly detection proceeds.\n\n\nMETHODOLOGY 3.1 Overview\n\nIn online service systems, performance anomalies often serve as the (early) signals for critical failures, which should be detected effectively. However, accuracy alone is far from satisfactory, as it will be labor-intensive to manually investigate the problematic metrics for issue understanding. ADSketch facilitates this process by providing prompt anomaly alerts with explanations.\n\nThe overall framework of ADSketch is shown in Fig. 2, which consists of two phases, namely, offline anomaly detection and online anomaly detection. In the offline phase, ADSketch takes as input a pair of metric time series. One metric time series is anomaly-free, which serves as the basis to detect anomalies in the other metric (if any). In this process, a set of metric patterns will be automatically learned. A metric pattern is essentially the mean of a set of similar metric subsequences representing similar service behaviors. The identified metric patterns are divided into two types, i.e., normal and abnormal. The abnormal patterns often characterize some particular types of performance issues, as discussed in Sec. 2  by investing manual efforts to link them to the corresponding issues, a clearer picture of the underlying problems can be easily obtained if similar patterns are encountered again. In the online phase, we leverage the metric patterns built in the offline phase to conduct anomaly detection in online scenarios, where metrics arrive in streams. Particularly, in production environments, unprecedented patterns could appear. Thus, we design an adaptive learning algorithm to capture the new patterns continuously. Before formally introducing our algorithms, we have summarized the variables involved in Table 1.\n\n\nOffline Anomaly Detection\n\n\nMetric Pattern Discovery.\n\nThe idea for discovering the abnormal patterns follows the basic definition of an anomaly: if a metric subsequence deviates significantly from those collected during a service's normal executions, it is likely that the subsequence captures some misbehaving moments of the service. To measure how deviated a metric subsequence is, we calculate its distance to other subsequences and search for the smallest distance score. Intuitively, metric subsequences which have large scores to others tend to be anomalous. The function for distance measure is customizable, and we adopt Euclidean distance in this paper.\n\nGiven a metric time series with observations, the number of all possible subsequences is \u2212 + 1, where is the length of its subsequences. A na\u00efve solution for calculating the smallest pair-wise distance (which we refer to as SPW distance hereafter) would be brute force searching. However, this algorithm owns a quadratic time complexity, which is practically infeasible for large time series. Fortunately, some novel scalable algorithms [35,36,38] have been proposed in the literature to attack such all-pairs-similaritysearch problems for time series subsequences. Particularly, Yeh et al. [36] proposed STAMP, which has achieved orders of magnitude faster compared to state-of-the-art methods. For exceptionally large datasets, an ultra-fast approximate solution is also provided. An illustrating example is provided in Fig. 4, where we can see the misbehaving metric subsequences have larger SPW distances. In particular, the original STAMP algorithm adopts z-normalization for data preprocessing. However, we found min-max normalization yields more meaningful results in our scenario. For a subsequence in a metric time series T , we record the index and distance score of another subsequence having the SPW distance to it. Such index and score of all subsequences, i.e., ( \u2208 [0, \u2212 ]), constitute two vectors I and S. In particular, for , its closest subsequence can either come from the same time series (i.e., self-union) or another time series (i.e., cross-union). In the first case, a trivial match region around will be excluded to avoid self matches [36]. The proposed algorithm for metric pattern discovery is presented in Algorithm 1, which is illustrated in Fig. 3. Algorithm 1 takes as input two metric time series, i.e., T and T (T is anomaly-free and T may contain anomalies to be detected), and two hyperparameters, i.e., and ( is the length of subsequences and is the percentile threshold to find the deviated subsequences). As production service systems are mostly running in normal status [6], the anomaly-free input is easily obtainable (we discuss how we address the violating cases in Sec. 5.3). In line 1 of Algorithm 1, we apply STAMP to T with self-union (i.e., similar subsequences come from T ), and obtain the index and score vectors I and S . In line 2, we search similar subsequences for T from T , i.e., cross-union, and get I and S . Intuitively, given the fact that T is anomaly-free, subsequences in T having large SPW distances to their closest peers in T are suspected to be anomalous. Interestingly, we later learn that Mercer et al. [23] proposed a similar idea concurrently. We introduce a percentile threshold (i.e., ) on S to find such deviated subsequences. In particular, is loosely set to avoid missing anomalies, i.e., false negatives. Such a setting will inevitably produce false positives. We next discuss how we alleviate this issue.\n\n\nAlgorithm 1: Performance Anomaly Pattern Discovery\n\nInput: T , T , , and Output: Two disjoint sets of P and A metric pattern is defined as the mean of a group of similar subsequences, which represents some typical behaviors of the metric time series. To mine similar subsequences, we propose to leverage their similarity connections. Specifically, in line 3, we construct a graph whose nodes correspond to the subsequences. Two nodes will be linked if any one of them is deemed as the most similar subsequence to the other, as indicated by I and I . Note such a relationship is not mutual, i.e., is the most similar to does not necessarily imply the opposite case. We break the edges whose distance score fails to meet the threshold requirement . The above operations are depicted in the first part of Fig. 3. Next, we find the connected subgraphs of , each of which is composed of subsequences resembling each other. Particularly, there will be some isolated nodes, i.e., subgraphs with a single node, which are collected at line 4. Such deviated subsequences constitute a set of anomaly candidates, i.e., . The second part of Fig. 3 illustrates this process.\nP 1 I , S \u2190 STAMP(T , T , ) 2 I , S \u2190 STAMP(T , T , ) 3 \u2190 ConnectedSubgraphs(I + I , S , ) 4 \u2190 IsolatedNodes( ) 5 \u2190 GraphWiseMean( ) 6 \u2190 AffinityPropagation( G ) 7 \u2190 ClusterWiseMean( ) 8 P \u2190 EmptyArray, P \u2190 EmptyArray\nUp to this point, we have divided the subsequences of T and T into different parts, each of which is represented as a subgraph. However, each subgraph cannot be directly regarded as a metric pattern because: 1) the graph construction criteria can be too strict (i.e., only the most similar pairs are connected), so some subgraphs might still be similar; 2) the loosely set percentile threshold may flag some normal subsequences as abnormal (i.e., false positives). To further combine the similar subsequences, we apply the Affinity Propagation algorithm [10] to cluster the mean vector of each subgroup (line 5-6). We choose this algorithm because of its superior performance and efficiency, and it requires no pre-defined cluster number. As a result, similar normal subgraphs can be merged together, and abnormal subgraphs have a chance to embrace their normal communities. Thus, each cluster will contain all similar subsequences across the two time-series inputs and different clusters represent distinct patterns. The mean of clusters (i.e., ) will form the set of metric patterns (line 7). For each cluster, we check whether or not all its members come from the set of anomaly candidates (line 9-15). If yes, the mean of the cluster will be regarded as an abnormal metric pattern and otherwise normal, indexed by P and P , respectively. The third part of Fig. 3 presents the above operations. Finally, all subsequences in the anomalous clusters will be predicted as an anomaly to be the output of this phase.\n\n\nMetric Pattern Interpretability.\n\nIn this section, we expound on how to label the performance issues that each metric pattern represents. By allowing metric patterns to have semantics, the understanding and mitigation of service problems can be greatly accelerated. Given the fact that the duration of different performance issues may vary, our fixed-length metric patterns may over-represent (i.e., the metric pattern is much larger than the issue's duration) or under-represent (i.e., the metric pattern is only an excerpt of the issue) the corresponding issues. To alleviate the first problem, we select a relatively small , which turns out to be aligned with the goal of better performance. For the second problem, we adopt the following strategy to group clusters which are actually describing a common issue. For each pair of clusters, we check whether they have some subsequences that share some parts in common. All clusters sharing such overlaps together can recover the complete picture of the issue. Thus, we regard them as describing an identical issue. Finally, for each metric pattern, domain engineers will label the type of performance issue that triggers it. Particularly, one pattern can have multiple labels simultaneously. The metric patterns with overlaps will share the same set of performance issue labels.\n\n\nOnline Anomaly Detection\n\n3.3.1 Anomaly Detection on the Fly. Based on the metric patterns identified in Algorithm 1, we now describe our algorithm (Algorithm 2) for anomaly detection in online scenarios. The idea is straightforward: given a new metric subsequence with length , we search for its most similar metric pattern (line 1-2) and check which pattern pool it comes from. If is more similar to an abnormal pattern, it will be predicted as anomalous; otherwise, normal (line 3-7). In real-world systems where monitoring metrics are generated in a stream manner, this process is continuously running for all coming subsequences. When an anomaly is identified, we would like to provide more interpretation about it, e.g., what kinds of performance issues have happened. This is done by simply recommending the issues associated with the most similar metric pattern for all involved metrics. Particularly, in Algorithm 1, each cluster (i.e., at line 6) contains all subsequences that are deemed as similar. The design of our online anomaly detection only requires the mean vector of each cluster, i.e., . Thus, instead of keeping all its members (which is storage-intensive), the clusters can be simply represented by their mean vectors. Note that the offline and online anomaly detection can work collaboratively as a performance anomaly detector without the interpretability component, which requires human intervention.\n\nSo far the metric patterns for anomaly detection are discovered based on historical data. However, due to the dynamics of online service systems (e.g., software upgrade, customer behavior change), the metrics may experience concept drift [11,12], which produces brand-new patterns. Thus, an adaptive learning mechanism is desirable to help adapt to such unprecedented patterns and update the metric patterns accordingly. In the next section, we will introduce the algorithm to this end called adaptive pattern learning.\n\n\nAdaptive Pattern\n\nLearning. The algorithm of adaptive pattern learning is presented in Algorithm 3, which automatically updates metric patterns during streaming anomaly detection. To start with, for each cluster, we calculate its size and the maximum distance between its mean vector and all members (which we refer to as radius), denoted as S and R , respectively. In particular, the size and radius of clusters with only a single member are one and zero. For adaptive pattern learning, all clusters can be sufficiently\n! ! ! ! [#$%] \" # \" # # \u211b ! [#$%] metric subsequence mean vector ! ! ! ! [#$%] \" # \" # # \u211b ! [#$%] tangent normal tangent ! ! ! ! [#$%] \" # \" # # \u211b ! [#$%]\nnormal \" $ \" $ Figure 5: The update of the radius of a cluster\n\nrepresented with the following properties: , S , and R . All subsequences can be discarded.\n\nThe main idea is that given a new subsequence , we determine whether it possesses a known metric pattern carried by an existing cluster. If yes, the cluster will absorb as a new member and update its properties; otherwise, a brand-new anomalous cluster with only itself will be created, representing an unseen metric pattern. Specifically, we first search for the closest pattern of (line 1-2). Then, we determine whether should become a new member to the corresponding cluster by checking if the distance To address this problem, we employ the worst-case distance for approximation. As shown in Fig. 5, the new radius reaches its maximum value when lies in the (inward-pointing) normal of the tangent space at the member yielding the radius (denoted as ) [3], which can be calculated by the equation at line 4. We omit the proof, which is standard. Two cases are possible. The first (the left subfigure) is that continues to be the farthest member from the new mean \u2032 . The second (the right subfigure) is that takes the place of and becomes the farthest one. Therefore, besides , we also compute the distance between and \u2032 , i.e., , and compare them (line 4-6). The bigger one will be the new radius (line 10). Recall we need to check if D [ ] \u2264 Max(R ) to decide whether or not should be taken as a new member. Considering the high imbalance between normal and abnormal clusters, we maintain two maximum radii for them, denoted as and , respectively (line 7). Once a cluster alters its radius, we reset the maximum radius of its kind ( or as determined by line 8) if it is exceeded by \u2032 (line 15). On the other hand, if the cluster rejects , we form a new anomalous cluster containing only by properly setting its properties (line [18][19][20][21].\n\nAn issue with this strategy is that false positives will accumulate in P as the unseen patterns can also be normal. We alleviate it by setting a threshold to the size of the newly-formed anomalous clusters (line 11). The role of the cluster will be switched from abnormal to normal if its size exceeds the threshold (line 12-13). The rationale is that performance anomalies are generally rare events. A large anomalous cluster would mean the particular type of issue it represents occurs too often. However, a pattern with a large frequency tends to be the metric's normal behavior. In this paper, we simply set the default threshold as the largest size of the anomalous clusters identified in the offline stage, i.e., Max(S [P ]). Nevertheless, more sophisticated strategies can be applied by, for example, considering the distribution of clusters' sizes. Other operations are of trivial linear time complexity, which is also the case for Algorithm 2 and Algorithm 3. Overall, ADSketch owns a time complexity of O ( 2 ) (O ( 2 + 2 + | | 2 )). Fortunately, unlike other models such as deep neural networks, STAMP can be embarrassingly parallelized by distributing its unit operation (SPW distance calculation) to multi-core processors [36]. Moreover, STAMP has an ultra-fast approximation to generate results in an anytime fashion.\n\n\nTime and Space Complexity\n\n3.4.2 Space Complexity. As described in Sec. 3.3.2, pattern clusters have a lightweight representation, i.e., , S , and R . We also need P and P to distinguish anomalous patterns from the normal ones. Besides whose space complexity is O ( \u00d7 | |), other vectors are of O (| |). Therefore, the dominant term of space complexity is O ( \u00d7 | |). Since both and | | are usually small, the space overhead of ADSketch can be considered trivial.\n\n\nEXPERIMENTS\n\nIn this section, we evaluate ADSketch using both public data and real-world metric data collected from the industry. Particularly, we aim at answering the following research questions.\n\nRQ1: How effective is ADSketch's offline anomaly detection? RQ2: How effective is ADSketch's online anomaly detection? RQ3: How effective is ADSketch's adaptive pattern learning?\n\nThe evaluation process of much existing work, e.g., [29,32], essentially corresponds to the process adopted in RQ1 (i.e., the offline anomaly detection phase), because the threshold they select for anomaly alerting is determined by iterating the full range of its possible values. The best results achieved during the iteration process are reported. To fully examine the performance of different methods in online scenarios, we fix models' data and parameters (including the threshold learned in offline mode) as if they are deployed in production systems, i.e., RQ2. The online adaptability of ADSketch will be evaluated in RQ3.\n\n\nExperiment Setting\n\n\nDataset.\n\nTo evaluate the effectiveness of ADSketch in performance anomaly detection, we conduct experiments on two publicly available datasets. Moreover, to confirm its practical significance, we collect a production dataset from a large-scale online service of Huawei Cloud. Table 2 summarizes the statistics of the datasets. Public dataset. The public datasets for experiments are Yahoo [30] and AIOps18 [2,29]. Particularly, we do not conduct online anomaly detection on Yahoo due to its limited number of anomalies.\n\n\u2022 Yahoo. Yahoo released by Yahoo! Research [30] is a benchmark dataset for time series anomaly detection. Part of the dataset is synthetic (which is simulated by algorithmically injecting anomalies), and part of the dataset is collected from the real traffic of Yahoo services. The anomalies in the real dataset are manually labeled. All time series are sampled every hour. In particular, as our goal is detecting performance anomalies for online services, we only use the real dataset, which reflects the real-world service performance issues. For each time series, we select the first 300 data points as the anomaly-free input (any anomalies are ignored), while the remaining part as the input for offline anomaly detection. \u2022 AIOps18. AIOps18 dataset was released by an international AIOps competition held in 2018 [1]. The dataset is composed of multiple metric time series collected from the web services of large-scale IT companies. Particularly, the dataset contains two types of metrics, i.e., service metrics and machine metrics. The service metrics record the scale and performance of the web services, including response time, traffic, connection errors; while the machine metrics reflect the health states of physical machines, including CPU usage, network throughput. Some metric time series has a sampling interval of one minute, while that of others is five minutes. Each metric has a training and a testing time series. Thanks to its large quantity, we follow the following procedure to separate the data for ADSketch offline and online anomaly detection. First, we extract a small part of the training time series that is anomaly-free, which often contains thousands of data points. Then, we use the remainder of the training time series for offline anomaly detection. Finally, the whole testing time series will be employed for online anomaly detection. We also compare the performance of online anomaly detection with and without the adaptive learning component.\n\nIndustrial dataset. To evaluate ADSketch in production scenarios, we collect various metrics (e.g., Application CPU Usage, Interface Throughput, Request Timeout Number, Round-trip Delay) from a large-scale online service (we conceal the name for privacy concern) of Huawei Cloud. The system under study produces millions of metric time series, which contain an abundance of different metric patterns. The number of metric curves collected is 436, which come from multiple instances of virtual machines, containers, and applications of the selected service system. For each metric, we collect one week of data with a sampling interval of one minute, resulting in more than four million data points in total. The anomalies representing the performance issues of the service are labeled by experienced domain engineers. From Table 2, we can see that the anomaly ratio is very low. Particularly, we use the first day as the anomaly-free input, whose anomalies (if any) are simply ignored. The next three days are used for offline anomaly detection. Finally, we conduct online anomaly detection on the remaining three days, where we also evaluate the adaptability of different approaches to unseen anomaly patterns.\n\n\nEvaluation Metrics.\n\nAs anomaly detection is essentially a binary classification problem, i.e., normal and abnormal, we employ precision, recall, and F1 score for evaluation. They can gauge the performance of an anomaly detection algorithm at a fine-grained level. A satisfactory algorithm should be able to quickly and precisely detect both the occurrence and duration of performance anomalies. Specifically, precision measures the percentage of anomalous metric points that are successfully identified as anomalies over all the metric points that are predicted as anomalous:\n\n= + . Recall calculates the portion of anomalous metric points that are successfully identified by ADSketch over all the actual anomalous points:\n\n= + . Finally, the F1 score is the harmonic mean of precision and recall:\n1 = 2\u00d7 \u00d7 + .\nis the number of anomalous metric points that are correctly discovered by ADSketch;\n\nis the number of normal metric points that are wrongly predicted as an anomaly by ADSketch;\n\nis the number of anomalous metric points that ADSketch fails to notice. Since there are multiple metrics in each dataset, we report their average weighted by the size of each metric time series. \u2022 LSTM [15,37]. This method employs Long Short-Term Memory (LSTM) network to capture the normal behaviors of metrics in a forecasting-based manner. Specifically, it predicts the next values of a metric based on its past observations. The predicted values are then compared with the actual values. Anomaly warnings will be raised if the differences exceed the pre-defined thresholds. \u2022 Donut [34]. Donut adopts the Variational Autoencoder (VAE) framework to properly reconstruct the normal metric subsequences. The trained model will have a large reconstruction loss when it meets anomalous instances, which serves as the signal to alert anomalies. \u2022 LSTM-VAE [25]. Similar to Donut, this work detects anomalies based on metric subsequence reconstruction. It combines LSTM and VAE in the model design. \u2022 LODA [26]. LODA is an online anomaly detector based on the ensemble of a series of one-dimensional histograms. Each histogram approximates the probability density of input data projected onto a single projection vector. LODA calculates the likelihood of an anomaly based on the joint probability of the projections. \u2022 iForest [19]. Isolation Forest (iForest) is composed of a collection of isolation trees, which isolates anomalies based on random subsets of the input features. The height of an input sample, averaged over the trees, is a measure of its normality. Samples with noticeably shorter heights are likely to be anomalies. We use metric subsequences as the input samples. \u2022 DAGMM [39]. DAGMM utilizes a deep autoencoder to generate a low-dimensional representation for each input data point, which is further fed into a Gaussian Mixture Model to estimate the anomaly score. \u2022 SR-CNN [29]. SR-CNN first applies Spectral Residual to highlight the most important regions for seasonal metric data where anomalies often reside. It then trains a Convolutional Neural Network (CNN) through synthetic anomalies to detect the real anomalies.\n\n\nExperimental Results\n\n\nRQ1\n\nThe Effectiveness of ADSketch's Offline Anomaly Detection. To answer this research question, we compare ADSketch with the baselines in the offline setting. The results are shown in Table 3, where we can see the average F1 score of ADSketch outperforms all baseline methods in all datasets. In AIOps18 and Industry, the improvement achieved by ADSketch is more significant. In particular, the patterns of anomalies in Yahoo are relatively simple. By iterating over all possible values of the anomaly threshold, the baselines can find the best setting for the dataset under study. Among them, LSTM [15,37] and Donut [34] achieve comparable performance compared to that of ADSketch (i.e., 0.541), whose average F1 scores are 0.53 and 0.524, respectively. Moreover, LSTM [15,37] has the best recall (i.e., 0.706), while the best precision (i.e., 0.754) goes to LODA [26]. DAGMM and SR-CNN turn out to be the worst methods in this dataset. In terms of AIOps18 and Industry datasets, we can see ADSketch surpasses the baselines by a larger margin. Specifically, the average F1 score of ADSketch in AIOps18 is 0.677, while that of the second-best method (i.e., LSTM-VAE) is 0.537. ADSketch also attains the best precision and recall. In AIOps18, the anomaly patterns are much more complicated. Baselines tend to predict more data points as anomalous, leading to a lower precision. Different from them, ADSketch is able to precisely capture them and outperforms other methods. The situation is similar in Industry. Particularly, this dataset is collected from online services, and many of its metric curves possess more perceivable and regular patterns. Thus, all methods perform better in this dataset than in the other two. The average F1 scores of ADSketch and the second-best method (i.e., LSTM) are 0.740 and 0.632, respectively. In Table 3, we can see among all comparative methods, LSTM and LSTM-VAE have better overall performance, which are forecastingbased and reconstruction-based methods, respectively. They both try to model the normal patterns of a metric time series and alert anomalies once the metric significantly deviates from the learned patterns. The difference is that a forecasting-based method aims to predict the next metric values and a reconstruction-based method tries to encode and regenerate metric subsequences. We can see    except for LSTM-VAE in Yahoo, these two methods attain the best results compared to other baseline counterparts in the other two datasets. However, LSTM lacks the ability to explicitly detect anomalies in the level of subsequence. Many anomalies are composed of a collection of anomalous points corresponding to the period of performance issues. LSTM-VAE does not take into account the relationship among subsequences. Many suspicious subsequences are not necessarily anomalies if they often occur in the history of the service systems. Compared to them, ADSketch is able to simultaneously learn the subsequence-level features and consider the context of metric time series.\n\n\nRQ2\n\nThe Effectiveness of ADSketch's Online Anomaly Detection. We also compare ADSketch against the selected methods for online anomaly detection. Table 4 presents the experimental results. Except for Donut in AIOps18, all models and algorithms encounter an obvious performance degradation in both datasets. Nevertheless, ADSketch manages to maintain the best ranking (0.507 in AIOps18 and 0.606 in Industry), which is followed by LSTM (0.408 in AIOps18) and LSTM-VAE (0.601 in Industry). Particularly, in AIOps18, the average F1 score of different methods drops by 11%-27%. This observation demonstrates the existence of unprecedented metric patterns in online scenarios. By relying on the \"outdated\" data and parameters (e.g., ADSketch's metric patterns and baselines' anomaly thresholds) learned from the offline stage, the methods cannot accommodate them. In addition, by plotting the metric time series, we observe the emergence of concept drift on metrics. This can be caused by software upgrades or the integration of new service components (e.g., virtual machines, containers). In the industrial dataset, the evaluation results of the baselines are more promising (i.e., the average F1 score drops by less than 10%). This is because the anomalies are triggered by real-world performance issues. The issues have a more natural distribution, and the collected metrics exhibit relatively stable patterns. ADSketch presents a significant performance degradation. We found it is because in some cases, the two metric time series fed to the offline stage are often both anomaly-free. Consequently, no abnormal patterns will be learned, disabling ADSketch to detect anomalies in the online stage. Therefore, when designing an anomaly detection algorithm, adaptability is indispensable.\n\n\nRQ3\n\nThe Effectiveness of ADSketch's Adaptive Pattern Learning. This research question looks into the issue of online adaptability. Particularly, we only compare ADSketch with LODA, which is the only baseline method with the design of online learning. Similar to RQ2, we only conduct experiments with AIOps18 and Industry datasets. Table 5 shows the experimental results, where we can see ADSketch's adaptive pattern learning indeed brings performance gains. With more anomalous patterns identified, ADSketch is able to detect anomalies more accurately, i.e., a better precision (0.594 in AIOps18 and 0.882 in Industry). The average F1 score also enjoys some improvements, i.e., 0.548 in AIOps18 and 0.832 in Industry. Particularly, in the industrial case, adaptive ADSketch achieves a performance of over 0.8 in all evaluation metrics (even in some cases without any abnormal patterns learned from the offline stage). Such an achievement indicates its potential to meet the industrial requirements of performance anomaly detection. On the other hand, the online version of LODA does not show much performance improvement (i.e., an average F1 score of 0.387 in AIOps18 and 0.548 \n\n\nParameter Sensitivity.\n\nIn ADSketch, there are only two parameters to tune (both in Algorithm 1), i.e., the pattern length and the percentile threshold for identifying deviated metric subsequences. We evaluate the sensitivity of ADSketch to these two parameters by conducting experiments with different settings. Due to space limitations, we only show the results of the Industry dataset. The default value of and for the dataset is 15 and 99.5th, respectively. We fix one parameter and employ a different setting for the other one. Specifically, ranges from 9 to 21, and varies from 97th to 99.8th. Fig. 6 presents the results. Performance degradation is observed in both offline and online stages when the two parameters deviate from their default setting. The offline stage exhibits a greater sensitivity, and thus, less anomalous metric patterns are captured. Nevertheless, both the online anomaly detection and adaptive pattern learning algorithms achieve stable performance with a smaller set of abnormal patterns. This further confirms ADSketch's capability of new pattern discovery.\n\n\nINDUSTRIAL PRACTICE 5.1 Online Deployment\n\nSince October 2020, ADSketch has been successfully incorporated into the performance anomaly detection system of a large-scale online service system in Huawei Cloud. The deployment process can be easily done by leveraging the existing data analytics pipeline, for example, data consumption by Apache Kafka [16], and online parallel execution by Apache Flink [9]. After months of usage, ADSketch has demonstrated its effectiveness on metric-based system troubleshooting. A lot of positive feedback has been received from on-site engineers. Particularly, engineers confirmed its superiority in anomaly detection over the current algorithms (e.g., fixed thresholding, moving average) in operation. One typical case is multiple benign spikes arriving suddenly and consecutively. ADSketch is able to quickly figure out that such recurrent spikes have happened before, which reduces the number of false alerts. In terms of issue understanding, engineers benefited from ADSketch by having readily-available descriptions about the anomaly symptoms. Therefore, we have initialized a project of metric pattern database construction. ADSketch is continuously accumulating anomalous patterns in the database. Moreover, engineers also expressed the need for metric pattern auto-correlation across different metrics. This is because multiple anomalies collectively could constitute a \n\n\nCase Study\n\nWe provide some case studies of ADSketch collected from production systems in Fig. 7, where anomalies are indicated by the red lines. Due to space limitations, we only showcase three metric time series. Clearly, all anomalous metric patterns have been successfully located regardless of shape, scale, and length. Each metric time series possesses at least two types of anomalous patterns, e.g., level shifts and spikes. Interestingly, we found the depression in the second metric can help catch a similar pattern in the third metric, demonstrating the feasibility of cross-metric pattern sharing. Moreover, engineers confirmed that these patterns are typical, based on which they can make a good guess about the ongoing issues. For example, the spikes often come from user request surge or network attack; the depressions in the second and third metrics often indicate service restart or link flap. To quantify the interpretability of ADSketch, we label the recurrent performance issues and employ the learned metric patterns to identify them. As performance issues may contain uncertainty [33], we allow one pattern to be associated with multiple labels simultaneously (Sec. 3.2.2). During the evaluation, an anomaly interpretation is considered correct if the predicted performance issue appears in the label set. In our experiments, ADSketch attains a promising F1 score of 0.825. This demonstrates the potentials of ADSketch in providing interpretable results to engineers, which can greatly accelerate the investigation of service performance issues.\n\n\nThreats to Validity\n\nWe have identified the following major threats to validity. Internal threats. The implementation and parameter selection are two critical internal threats to the validity. To reduce the implementation threat, we directly borrow the codes released by the baseline approaches. For the proposed approach, we employ peer code review, i.e., the authors are invited to carefully check the implementation for mistakes. In terms of parameter selection, we conduct multiple comparative experiments with different parameters for all methods. We choose the parameter settings empirically based on the best results.\n\nExternal threats. The selection of the service system and the baselines are two main external threats to validity. We choose a large-scale online service of Huawei Cloud, which produces millions of metrics with diverse patterns. Moreover, we detect anomalies by following the basic definition of an anomaly, i.e., the data point that deviates from the majority in a dataset. Thus, ADSketch is generalizable to other systems. For baselines, we select the representative ones in the literature, covering a wide spectrum of techniques.\n\nConstruct threats. The main construct threat to validity is that the anomaly-free input (i.e., T ) to Algorithm 1 actually contains anomalies. Although anomaly-free data are easily obtainable in reality, false negatives could happen if the data are contaminated. We alleviate this issue by applying percentile thresholding to T . Specifically, after obtaining the closest subsequence pairs in T , we break the connection between those having a distance above the percentile threshold. Thus, the set of anomaly candidates, i.e., , becomes larger. If T is indeed clean, this operation is harmless as the (isolated) normal metric subsequences can be grouped with other similar ones again; if not, they will stay isolated and eventually be recognized as anomalies. We have also conducted experiments on some cases where T contains anomalies, and the results show its effectiveness.\n\n\nRELATED WORK\n\nPerformance anomaly detection on time series has been a hot topic. Monitoring metrics used to profile the runtime status of a system are usually denoted as multiple univariate time series. In the literature, anomaly detection methods on time series can be categorized into statistical, traditional machine learning, and deep learning approaches. In industry, Autoregressive Moving Average Model (ARMA) [5] remains the most popular statistical method to detect obvious anomalous data points from univariate time series. To capture complex anomalous patterns, Ma et al. [22] summarized several type-oriented patterns from the metrics of cloud databases to diagnose the performance degradation in associated online services.\n\nMore complex pattern recognition methods utilize machine learning based models. For example, unsupervised clustering methods can be used to detect anomalous points in time-series data. Similar to our work, Pang et al. [24] proposed a clustering-based statistical model called LeSiNN to detect anomaly patterns from history. However, it is not robust in real industry practices due to complicated parameter tuning. With the assumption that anomalous data should be in smaller numbers and isolated from a large number of normal observations, Isolation Forest (iForest) [19] employs multiple binary trees to distinguish anomalies in non-linear space. Extreme Value Theory (EVT) [31] learns the hidden state of a random variable around the tails of its distribution to adaptively enhance the performance of many statistical and machine learning methods. However, EVT heavily relies on hyperparameter tuning.\n\nIn recent years, there has been an explosion of interest in applying neural networks to conduct anomaly detection on time-series data. For example, Zong et al. [39] proposed a deep autoencoding Gaussian mixture model (DAGMM) to detect anomalous data points from each observed data without considering the temporal dependencies in time series. To detect complex anomalies in spacecraft monitoring systems, LSTM-NDT [15] leverages Long Short-Term Memory (LSTM) networks with nonparametric dynamic thresholding to pursue interpretability throughout the systems. Zhao et al. [37] and Lin et al. [17] also employed LSTM to predict performance anomalies in software systems. Inspired by the Spectral Residual algorithm in other domains, Ren et al. [29] proposed SR-CNN to detect anomalies from seasonal metric data for large-scale cloud services, which contain the periodic recurrence of fluctuations. DONUT [34] designs an unsupervised anomaly detection method based on the Variational Auto-Encoder (VAE) framework to detect anomalies from low-qualified seasonal metric time series with various patterns. DONUT provides a theoretical explanation compared to other deep learning methods. LSTM-VAE [25] combines LSTM networks and the VAE framework to reconstruct the probability distribution of observed data in time series. However, LSTM-VAE ignores the temporal dependencies in time series. Omni-Anomaly [32] learns the normal patterns using a large collection of historical data. The anomalous patterns are located from the large margin of reconstruction loss to the normal patterns. However, the aforementioned deep learning-based methods usually follow an end-to-end style and play as a black box inside. Due to poor interpretability, the detection results cannot provide engineers with actionable suggestions for fault diagnosis. Furthermore, all these methods have difficulties handling unseen metric patterns brought by the frequent updates of online services.\n\n\nCONCLUSION\n\nIn this paper, we propose ADSketch, a performance anomaly detection approach based on pattern sketching. By extracting normal and abnormal patterns from metric time series, anomalies can be quickly detected through a comparison with the identified patterns. By associating metric patterns with typical performance issues, ADSketch can provide interpretable results when any known patterns appear again. Moreover, we design an adaptive learning algorithm to help ADSketch embrace unprecedented metric patterns during online anomaly detection. We have conducted experiments on two public datasets and one production dataset collected from a representative online service system of Huawei Cloud. For offline anomaly detection where models' parameters are still being tuned, ADSketch has achieved the highest F1 score, outperforming the existing methods by a significant margin. For online anomaly detection where models are fixed, ADSketch safeguards its best rankings. Finally, the adaptive pattern learning brings noticeable performance gains, especially in the industrial dataset. From our industrial practice, we have witnessed it shedding light on accurate and interpretable performance anomaly detection, which confirms its practical benefits conveyed to Huawei Cloud. We believe ADSketch is able to assist engineers in service failure understanding and diagnosis.\n\nFor future work, we will extend our algorithms to multivariate metric time series. We will also try to provide more detailed information about failures by exploring the correlations among the metric patterns.\n\nFigure 1 :\n1Examples\n\nFigure 2 :\n2The Overall Framework of ADSketch time series has experienced. For each identified pattern, engineers can label the typical performance issues it often associates with.\n\nFigure 3 :Figure 4 :\n34The The SPW distance of different metric subsequences\n\n: 2 \u2190\n2Performance Anomaly Detection Input: , P , and Output: Anomaly detection result for 1 D \u2190 PairWiseDistance( , ) MinIndex\n\nAlgorithm 3 :,\n3Adaptive Pattern Learning Input: , P , P , , S , and R Output: Updated variables: P , P , , S , and R 1 D \u2190 PairWiseDistance( \u2190 Max(R [P ]), Max(R [P ]) 8 if \u2208 P then \u2190 else \u2190 end 9 if D [ ] < then // add to the most similar cluster\n\n\nD [ ] is smaller than the largest radius recorded in all clusters, i.e., D [ ] \u2264 Max(R ). If it is the case, should be considered as an old pattern; otherwise, it should be expressing a new pattern. When a cluster accepts a new member (line 9-16), we need to update its mean vector [ ] (i.e., the metric pattern), size S [ ], and radius R [ ]. For [ ], it can be precisely updated by the equation at line 3 (i.e., \u2032 ). S [ ] can be trivially updated by increasing itself by one. The update of the radius R [ ] is a bit problematic. We cannot directly calculate the new radius as the original subsequences are not available.\n\n\nComplexity. For Algorithm 1, the theoretical time complexity of operation STAMP is O ( 2 ). Thus, line 1-2 require O ( 2 ) and O ( 2 ), respectively, where and are the length of T and T . Another operation with an interesting time complexity is the affinity propagation algorithm (line 7), whose complexity is quadratic in the number of clusters (which is often small), i.e., O (| | 2 ).\n\n\nMethods. The following methods are selected for comparative evaluation of ADSketch. As all baselines have open-sourced their code, we directly borrow the implementations and follow the procedure of model training and parameter tuning introduced in each method.\n\nFigure 6 :\n6Parameter Sensitivity in Industry), which even falls behind some methods without the capability of online learning.\n\nFigure 7 :\n7Case Study of ADSketch stronger performance issue indicator. We leave the identification of such correlations to our future work.\n\nTable 1 :\n1Summary of VariablesVariable Meaning \n\nT \n\n\n\n.1. Thus, Anomaly-free metric time series ! ! Metric time series for anomaly detection ! \"Break due to percentile \nthreshold unfulfillment \n\nApply self-union and cross-union STAMP \nto get the most similar subsequences \n\nApply Affinity \nPropagation to \nthe mean of each \nsubgraph \n\nThe mean of each cluster \n\nMetric patterns, and \nis the only abnormal pattern \n\nApply Affinity Propagation to get globally similar \nsubsequences and calculate the metric patterns \n\nConstruct a graph G based on subsequences' \nsimilarity and find the connected subgraphs \n\nIsolated subgraphs, \nalso the anomaly \ncandidates \n\nMetric subsequences \nThe most similar subsequence \nA group of similar subsequences \nSubsequence graph link \n\n\" # \n\n# $ \n\n# % \n\n\n\nTable 2 :\n2Dataset StatisticsDataset #Curves #Points Anomaly RatioYahoo \n67 \n94,866 \n1.8% \nAIOps18 \n58 \n5,922,913 \n2.26% \nIndustry \n436 \n4,394,880 \n1.07% \n\n\n\nTable 3 :\n3Experimental Results of Offline Anomaly DetectionYahoo \nAIOps18 \nIndustry \nMethod \nprecision recall F1 score precision recall F1 score precision recall F1 score \n\nLSTM \n0.598 \n0.706 \n0.530 \n0.499 \n0.531 \n0.518 \n0.704 \n0.656 \n0.632 \nLSTM-VAE \n0.622 \n0.634 \n0.484 \n0.510 \n0.625 \n0.537 \n0.717 \n0.639 \n0.622 \nDonut \n0.530 \n0.658 \n0.524 \n0.405 \n0.527 \n0.382 \n0.693 \n0.628 \n0.604 \nLODA \n0.754 \n0.583 \n0.428 \n0.553 \n0.429 \n0.401 \n0.583 \n0.498 \n0.529 \niForest \n0.713 \n0.597 \n0.437 \n0.555 \n0.439 \n0.413 \n0.616 \n0.567 \n0.538 \nDAGMM \n0.643 \n0.517 \n0.401 \n0.590 \n0.477 \n0.461 \n0.597 \n0.542 \n0.530 \nSR-CNN \n0.433 \n0.618 \n0.307 \n0.424 \n0.387 \n0.363 \n0.519 \n0.471 \n0.434 \nADSketch \n0.511 \n0.673 \n0.541 \n0.744 \n0.670 \n0.677 \n0.811 \n0.813 \n0.740 \n\n\n\nTable 4 :\n4Experimental Results of Online Anomaly DetectionAIOps18 \nIndustry \nMethod \nprec. \nrec. \nF1 \nprec. \nrec. \nF1 \n\n\n\nTable 5 :\n5Experimental Results of Adaptive Pattern LearningAIOps18 \nIndustry \nMethod prec. \nrec. \nF1 \nprec. \nrec. \nF1 \n\nLODA \n0.424 0.405 0.387 0.623 0.512 0.548 \nADSketch 0.594 0.557 0.548 0.882 0.856 0.832 \n\n\nACKNOWLEDGMENTS\n. KPI Anomaly Detection Competition. 2018. KPI Anomaly Detection Competition. Retrieved April, 2021 from http: //iops.ai/competition_detail/?competition_id=5&flag=1\n\n. KPI Anomaly Detection Dataset. 2018. KPI Anomaly Detection Dataset. Retrieved April, 2021 from http://iops.ai/ dataset_detail/?id=10\n\nConvex optimization. Stephen Boyd, P Stephen, Lieven Boyd, Vandenberghe, Cambridge university pressStephen Boyd, Stephen P Boyd, and Lieven Vandenberghe. 2004. Convex opti- mization. Cambridge university press.\n\nGraph-based root cause analysis for serviceoriented and microservice architectures. \u00c1lvaro Brand\u00f3n, Marc Sol\u00e9, Alberto Hu\u00e9lamo, David Solans, S Mar\u00eda, Victor P\u00e9rez, Munt\u00e9s-Mulero, Journal of Systems and Software. 159110432\u00c1lvaro Brand\u00f3n, Marc Sol\u00e9, Alberto Hu\u00e9lamo, David Solans, Mar\u00eda S P\u00e9rez, and Victor Munt\u00e9s-Mulero. 2020. Graph-based root cause analysis for service- oriented and microservice architectures. Journal of Systems and Software 159 (2020), 110432.\n\nDiscrete time representation of continuous time ARMA processes. J Marcus, Michael A Chambers, Thornton, Econometric Theory. Marcus J Chambers and Michael A Thornton. 2012. Discrete time representation of continuous time ARMA processes. Econometric Theory (2012), 219-238.\n\nTowards intelligent incident management: why we need it and how we make it. Zhuangbin Chen, Yu Kang, Liqun Li, Xu Zhang, Hongyu Zhang, Hui Xu, Yangfan Zhou, Li Yang, Jeffrey Sun, Zhangwei Xu, Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software EngineeringZhuangbin Chen, Yu Kang, Liqun Li, Xu Zhang, Hongyu Zhang, Hui Xu, Yangfan Zhou, Li Yang, Jeffrey Sun, Zhangwei Xu, et al. 2020. Towards intelligent incident management: why we need it and how we make it. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1487-1497.\n\nAIOps: real-world challenges and research innovations. Yingnong Dang, Qingwei Lin, Peng Huang, 2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion). IEEEYingnong Dang, Qingwei Lin, and Peng Huang. 2019. AIOps: real-world chal- lenges and research innovations. In 2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion). IEEE, 4-5.\n\nExperience report: Anomaly detection of cloud application operations using log and cloud metric correlation analysis. Mostafa Farshchi, Jean-Guy Schneider, Ingo Weber, John Grundy, IEEE 26th international symposium on software reliability engineering (ISSRE). IEEEMostafa Farshchi, Jean-Guy Schneider, Ingo Weber, and John Grundy. 2015. Experience report: Anomaly detection of cloud application operations using log and cloud metric correlation analysis. In 2015 IEEE 26th international symposium on software reliability engineering (ISSRE). IEEE, 24-34.\n\n. Apache Flink, Apache Flink. 2011. [Online].\n\nClustering by passing messages between data points. J Brendan, Delbert Frey, Dueck, science. 315Brendan J Frey and Delbert Dueck. 2007. Clustering by passing messages between data points. science 315, 5814 (2007), 972-976.\n\nA survey on concept drift adaptation. Jo\u00e3o Gama, Indr\u0117 \u017dliobait\u0117, Albert Bifet, Mykola Pechenizkiy, Abdelhamid Bouchachia, ACM computing surveys (CSUR). 46Jo\u00e3o Gama, Indr\u0117 \u017dliobait\u0117, Albert Bifet, Mykola Pechenizkiy, and Abdelhamid Bouchachia. 2014. A survey on concept drift adaptation. ACM computing surveys (CSUR) 46, 4 (2014), 1-37.\n\nToward adaptive disk failure prediction via stream mining. Shujie Han, P C Patrick, Zhirong Lee, Cheng Shen, Yi He, Tao Liu, Huang, Proceedings of IEEE ICDCS. IEEE ICDCSShujie Han, Patrick PC Lee, Zhirong Shen, Cheng He, Yi Liu, and Tao Huang. 2020. Toward adaptive disk failure prediction via stream mining. In Proceedings of IEEE ICDCS.\n\nIdentifying impactful service system problems via log analysis. Shilin He, Qingwei Lin, Jian-Guang Lou, Hongyu Zhang, Dongmei Michael R Lyu, Zhang, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software EngineeringShilin He, Qingwei Lin, Jian-Guang Lou, Hongyu Zhang, Michael R Lyu, and Dongmei Zhang. 2018. Identifying impactful service system problems via log analysis. In Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 60-70.\n\nGray failure: The achilles' heel of cloud-scale systems. Peng Huang, Chuanxiong Guo, Lidong Zhou, Yingnong Jacob R Lorch, Murali Dang, Randolph Chintalapati, Yao, Proceedings of the 16th Workshop on Hot Topics in Operating Systems. the 16th Workshop on Hot Topics in Operating SystemsPeng Huang, Chuanxiong Guo, Lidong Zhou, Jacob R Lorch, Yingnong Dang, Murali Chintalapati, and Randolph Yao. 2017. Gray failure: The achilles' heel of cloud-scale systems. In Proceedings of the 16th Workshop on Hot Topics in Operating Systems. 150-155.\n\nDetecting spacecraft anomalies using lstms and nonparametric dynamic thresholding. Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, Tom Soderstrom, Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining. the 24th ACM SIGKDD international conference on knowledge discovery & data miningKyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and Tom Soderstrom. 2018. Detecting spacecraft anomalies using lstms and nonpara- metric dynamic thresholding. In Proceedings of the 24th ACM SIGKDD interna- tional conference on knowledge discovery & data mining. 387-395.\n\n. Apache Kafka, Apache Kafka. 2011. [Online].\n\nPredicting node failure in cloud service systems. Qingwei Lin, Ken Hsieh, Yingnong Dang, Hongyu Zhang, Kaixin Sui, Yong Xu, Jian-Guang Lou, Chenggang Li, Youjiang Wu, Randolph Yao, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software EngineeringQingwei Lin, Ken Hsieh, Yingnong Dang, Hongyu Zhang, Kaixin Sui, Yong Xu, Jian-Guang Lou, Chenggang Li, Youjiang Wu, Randolph Yao, et al. 2018. Predicting node failure in cloud service systems. In Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 480-490.\n\nLog clustering based problem identification for online service systems. Qingwei Lin, Hongyu Zhang, Jian-Guang Lou, Yu Zhang, Xuewei Chen, 2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C). IEEEQingwei Lin, Hongyu Zhang, Jian-Guang Lou, Yu Zhang, and Xuewei Chen. 2016. Log clustering based problem identification for online service systems. In 2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C). IEEE, 102-111.\n\nIsolation forest. Tony Fei, Kai Ming Liu, Zhi-Hua Ting, Zhou, eighth ieee international conference on data mining. IEEEFei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation forest. In 2008 eighth ieee international conference on data mining. IEEE, 413-422.\n\nUnderstanding, detecting and localizing partial failures in large system software. Chang Lou, Peng Huang, Scott Smith, 17th USENIX Symposium on Networked Systems Design and Implementation. 20Chang Lou, Peng Huang, and Scott Smith. 2020. Understanding, detecting and localizing partial failures in large system software. In 17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20). 559-574.\n\nSoftware analytics for incident management of online services: An experience report. Jian-Guang Lou, Qingwei Lin, Rui Ding, Qiang Fu, Dongmei Zhang, Tao Xie, 28th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEEJian-Guang Lou, Qingwei Lin, Rui Ding, Qiang Fu, Dongmei Zhang, and Tao Xie. 2013. Software analytics for incident management of online services: An experience report. In 2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 475-485.\n\nDiagnosing root causes of intermittent slow queries in cloud databases. Minghua Ma, Zheng Yin, Shenglin Zhang, Sheng Wang, Christopher Zheng, Xinhao Jiang, Hanwen Hu, Cheng Luo, Yilin Li, Nengjun Qiu, Proceedings of the VLDB Endowment. 13Minghua Ma, Zheng Yin, Shenglin Zhang, Sheng Wang, Christopher Zheng, Xin- hao Jiang, Hanwen Hu, Cheng Luo, Yilin Li, Nengjun Qiu, et al. 2020. Diagnosing root causes of intermittent slow queries in cloud databases. Proceedings of the VLDB Endowment 13, 10 (2020), 1176-1189.\n\nMatrix Profile XXIII: Contrast Profile: A Novel Time Series Primitive that Allows Real World Classification. Ryan Mercer, Sara Alaee, Alireza Abdoli, Shailendra Singh, Amy Murillo, Eamonn Keogh, The IEEE International Conference on Data Mining. Ryan Mercer, Sara Alaee, Alireza Abdoli, Shailendra Singh, Amy Murillo, and Eamonn Keogh. 2021. Matrix Profile XXIII: Contrast Profile: A Novel Time Series Primitive that Allows Real World Classification. In The IEEE International Conference on Data Mining.\n\nLeSiNN: Detecting Anomalies by Identifying Least Similar Nearest Neighbours. Guansong Pang, Kai Ming Ting, David W Albrecht, IEEE International Conference on Data Mining Workshop, ICDMW 2015. Atlantic City, NJ, USAIEEE Computer SocietyGuansong Pang, Kai Ming Ting, and David W. Albrecht. 2015. LeSiNN: Detecting Anomalies by Identifying Least Similar Nearest Neighbours. In IEEE Interna- tional Conference on Data Mining Workshop, ICDMW 2015, Atlantic City, NJ, USA, November 14-17, 2015. IEEE Computer Society, 623-630.\n\nA multimodal anomaly detector for robot-assisted feeding using an lstm-based variational autoencoder. Daehyung Park, Yuuna Hoshi, Charles C Kemp, IEEE Robotics and Automation Letters. 3Daehyung Park, Yuuna Hoshi, and Charles C Kemp. 2018. A multimodal anomaly detector for robot-assisted feeding using an lstm-based variational autoencoder. IEEE Robotics and Automation Letters 3, 3 (2018), 1544-1551.\n\nLoda: Lightweight on-line detector of anomalies. Tom\u00e1\u0161 Pevn\u1ef3, Machine Learning. 102Tom\u00e1\u0161 Pevn\u1ef3. 2016. Loda: Lightweight on-line detector of anomalies. Machine Learning 102, 2 (2016), 275-304.\n\nAutomated support for classifying software failure reports. Andy Podgurski, David Leon, Patrick Francis, Wes Masri, Melinda Minch, Jiayang Sun, Bin Wang, 25th International Conference on Software Engineering. Andy Podgurski, David Leon, Patrick Francis, Wes Masri, Melinda Minch, Jiayang Sun, and Bin Wang. 2003. Automated support for classifying software failure reports. In 25th International Conference on Software Engineering, 2003. Proceedings. IEEE, 465-475.\n\nFast shapelets: A scalable algorithm for discovering time series shapelets. Thanawin Rakthanmanon, Eamonn Keogh, proceedings of the 2013 SIAM International Conference on Data Mining. SIAM. the 2013 SIAM International Conference on Data Mining. SIAMThanawin Rakthanmanon and Eamonn Keogh. 2013. Fast shapelets: A scalable algorithm for discovering time series shapelets. In proceedings of the 2013 SIAM International Conference on Data Mining. SIAM, 668-676.\n\nTime-series anomaly detection service at microsoft. Bixiong Hansheng Ren, Yujing Xu, Chao Wang, Congrui Yi, Xiaoyu Huang, Tony Kou, Mao Xing, Jie Yang, Qi Tong, Zhang, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningHansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang, Xiaoyu Kou, Tony Xing, Mao Yang, Jie Tong, and Qi Zhang. 2019. Time-series anomaly detec- tion service at microsoft. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 3009-3017.\n\nA Benchmark Dataset for Time Series Anomaly Detection. ! Yahoo, Research, Yahoo! Research. 2015. A Benchmark Dataset for Time Series Anomaly De- tection. Retrieved August, 2021 from https://yahooresearch.tumblr.com/post/ 114590420346/a-benchmark-dataset-for-time-series-anomaly\n\nAnomaly Detection in Streams with Extreme Value Theory. Alban Siffer, Pierre-Alain Fouque, Alexandre Termier, Christine Largou\u00ebt, Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data MiningHalifax, NS, CanadaACMAlban Siffer, Pierre-Alain Fouque, Alexandre Termier, and Christine Largou\u00ebt. 2017. Anomaly Detection in Streams with Extreme Value Theory. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, NS, Canada, August 13 -17, 2017. ACM, 1067-1075.\n\nRobust anomaly detection for multivariate time series through stochastic recurrent neural network. Ya Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, Dan Pei, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningYa Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei. 2019. Robust anomaly detection for multivariate time series through stochastic recurrent neural network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2828-2837.\n\nPerformance issues? Hey DevOps, mind the uncertainty. Catia Trubiani, Pooyan Jamshidi, Jurgen Cito, Weiyi Shang, Ming Zhen, Markus Jiang, Borg, IEEE Software. 36Catia Trubiani, Pooyan Jamshidi, Jurgen Cito, Weiyi Shang, Zhen Ming Jiang, and Markus Borg. 2018. Performance issues? Hey DevOps, mind the uncertainty. IEEE Software 36, 2 (2018), 110-117.\n\nUnsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications. Haowen Xu, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu, Youjian Zhao, Dan Pei, Yang Feng, Proceedings of the 2018 World Wide Web Conference. the 2018 World Wide Web ConferenceHaowen Xu, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu, Youjian Zhao, Dan Pei, Yang Feng, et al. 2018. Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications. In Proceedings of the 2018 World Wide Web Conference. 187-196.\n\nDisk aware discord discovery: Finding unusual time series in terabyte sized datasets. Dragomir Yankov, Eamonn Keogh, Umaa Rebbapragada, Knowledge and Information Systems. 17Dragomir Yankov, Eamonn Keogh, and Umaa Rebbapragada. 2008. Disk aware dis- cord discovery: Finding unusual time series in terabyte sized datasets. Knowledge and Information Systems 17, 2 (2008), 241-262.\n\nMatrix profile I: all pairs similarity joins for time series: a unifying view that includes motifs, discords and shapelets. Chin-Chia Michael Yeh, Yan Zhu, Liudmila Ulanova, Nurjahan Begum, Yifei Ding, Anh Hoang, Diego Furtado Dau, Abdullah Silva, Eamonn Mueen, Keogh, IEEE 16th international conference on data mining (ICDM). IEEEChin-Chia Michael Yeh, Yan Zhu, Liudmila Ulanova, Nurjahan Begum, Yifei Ding, Hoang Anh Dau, Diego Furtado Silva, Abdullah Mueen, and Eamonn Keogh. 2016. Matrix profile I: all pairs similarity joins for time series: a unifying view that includes motifs, discords and shapelets. In 2016 IEEE 16th international conference on data mining (ICDM). IEEE, 1317-1322.\n\nPredicting Performance Anomalies in Software Systems at Run-time. Guoliang Zhao, Safwat Hassan, Ying Zou, Derek Truong, Toby Corbin, ACM Transactions on Software Engineering and Methodology (TOSEM). 30Guoliang Zhao, Safwat Hassan, Ying Zou, Derek Truong, and Toby Corbin. 2021. Predicting Performance Anomalies in Software Systems at Run-time. ACM Transactions on Software Engineering and Methodology (TOSEM) 30, 3 (2021), 1-33.\n\nMatrix profile XI: SCRIMP++: time series motif discovery at interactive speeds. Yan Zhu, Chin-Chia Michael Yeh, Zachary Zimmerman, Kaveh Kamgar, Eamonn Keogh, 2018 IEEE International Conference on Data Mining (ICDM). IEEEYan Zhu, Chin-Chia Michael Yeh, Zachary Zimmerman, Kaveh Kamgar, and Eamonn Keogh. 2018. Matrix profile XI: SCRIMP++: time series motif discovery at interactive speeds. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 837-846.\n\nDeep autoencoding gaussian mixture model for unsupervised anomaly detection. Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, Haifeng Chen, International Conference on Learning Representations. Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, and Haifeng Chen. 2018. Deep autoencoding gaussian mixture model for unsupervised anomaly detection. In International Conference on Learning Representations.\n", "annotations": {"author": "[{\"end\":144,\"start\":129},{\"end\":157,\"start\":145},{\"end\":167,\"start\":158},{\"end\":181,\"start\":168},{\"end\":192,\"start\":182},{\"end\":208,\"start\":193},{\"end\":223,\"start\":209},{\"end\":239,\"start\":224},{\"end\":252,\"start\":240},{\"end\":262,\"start\":253},{\"end\":276,\"start\":263},{\"end\":287,\"start\":277},{\"end\":303,\"start\":288},{\"end\":318,\"start\":304},{\"end\":372,\"start\":319},{\"end\":494,\"start\":373},{\"end\":538,\"start\":495},{\"end\":569,\"start\":539},{\"end\":623,\"start\":570}]", "publisher": null, "author_last_name": "[{\"end\":143,\"start\":139},{\"end\":156,\"start\":153},{\"end\":166,\"start\":164},{\"end\":180,\"start\":175},{\"end\":191,\"start\":187},{\"end\":207,\"start\":203},{\"end\":222,\"start\":219},{\"end\":238,\"start\":234},{\"end\":251,\"start\":248},{\"end\":261,\"start\":259},{\"end\":275,\"start\":270},{\"end\":286,\"start\":282},{\"end\":302,\"start\":298},{\"end\":317,\"start\":314}]", "author_first_name": "[{\"end\":138,\"start\":129},{\"end\":152,\"start\":145},{\"end\":163,\"start\":158},{\"end\":174,\"start\":168},{\"end\":186,\"start\":182},{\"end\":202,\"start\":193},{\"end\":216,\"start\":209},{\"end\":218,\"start\":217},{\"end\":233,\"start\":224},{\"end\":247,\"start\":240},{\"end\":258,\"start\":253},{\"end\":269,\"start\":263},{\"end\":281,\"start\":277},{\"end\":297,\"start\":288},{\"end\":311,\"start\":304},{\"end\":313,\"start\":312}]", "author_affiliation": "[{\"end\":371,\"start\":320},{\"end\":493,\"start\":374},{\"end\":537,\"start\":496},{\"end\":568,\"start\":540},{\"end\":622,\"start\":571}]", "title": "[{\"end\":88,\"start\":1},{\"end\":711,\"start\":624}]", "venue": "[{\"end\":778,\"start\":713}]", "abstract": "[{\"end\":2638,\"start\":1149}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3353,\"start\":3350},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3355,\"start\":3353},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3358,\"start\":3355},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3923,\"start\":3920},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4183,\"start\":4179},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":4186,\"start\":4183},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":4189,\"start\":4186},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5176,\"start\":5172},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5179,\"start\":5176},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":5675,\"start\":5671},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":5678,\"start\":5675},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6428,\"start\":6424},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6431,\"start\":6428},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":6434,\"start\":6431},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6705,\"start\":6702},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8730,\"start\":8726},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8733,\"start\":8730},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9232,\"start\":9229},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9235,\"start\":9232},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":11023,\"start\":11019},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":15245,\"start\":15244},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":16965,\"start\":16961},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":16968,\"start\":16965},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":16971,\"start\":16968},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":17119,\"start\":17115},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":18088,\"start\":18084},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18536,\"start\":18533},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":19100,\"start\":19096},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21346,\"start\":21342},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":25306,\"start\":25302},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":25309,\"start\":25306},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":27179,\"start\":27176},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":28158,\"start\":28154},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":28162,\"start\":28158},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":28166,\"start\":28162},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":28170,\"start\":28166},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":29412,\"start\":29408},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30408,\"start\":30404},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":30411,\"start\":30408},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31399,\"start\":31395},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":31415,\"start\":31412},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":31418,\"start\":31415},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31574,\"start\":31570},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":32348,\"start\":32345},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":35919,\"start\":35915},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":35922,\"start\":35919},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":36303,\"start\":36299},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":36571,\"start\":36567},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":36720,\"start\":36716},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":37041,\"start\":37037},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":37406,\"start\":37402},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":37609,\"start\":37605},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":38485,\"start\":38481},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":38488,\"start\":38485},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":38503,\"start\":38499},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":38656,\"start\":38652},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":38659,\"start\":38656},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":38751,\"start\":38747},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":45328,\"start\":45324},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":45379,\"start\":45376},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":47497,\"start\":47493},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":50420,\"start\":50417},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":50587,\"start\":50583},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":50960,\"start\":50956},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":51309,\"start\":51305},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":51417,\"start\":51413},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":51807,\"start\":51803},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":52061,\"start\":52057},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":52218,\"start\":52214},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":52238,\"start\":52234},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":52389,\"start\":52385},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":52549,\"start\":52545},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":52838,\"start\":52834},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":53046,\"start\":53042}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":55218,\"start\":55197},{\"attributes\":{\"id\":\"fig_1\"},\"end\":55400,\"start\":55219},{\"attributes\":{\"id\":\"fig_2\"},\"end\":55478,\"start\":55401},{\"attributes\":{\"id\":\"fig_3\"},\"end\":55607,\"start\":55479},{\"attributes\":{\"id\":\"fig_4\"},\"end\":55857,\"start\":55608},{\"attributes\":{\"id\":\"fig_5\"},\"end\":56483,\"start\":55858},{\"attributes\":{\"id\":\"fig_6\"},\"end\":56873,\"start\":56484},{\"attributes\":{\"id\":\"fig_7\"},\"end\":57136,\"start\":56874},{\"attributes\":{\"id\":\"fig_9\"},\"end\":57265,\"start\":57137},{\"attributes\":{\"id\":\"fig_10\"},\"end\":57408,\"start\":57266},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":57463,\"start\":57409},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":58197,\"start\":57464},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":58355,\"start\":58198},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":59099,\"start\":58356},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":59222,\"start\":59100},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":59435,\"start\":59223}]", "paragraph": "[{\"end\":3359,\"start\":2654},{\"end\":4148,\"start\":3361},{\"end\":5288,\"start\":4150},{\"end\":7251,\"start\":5290},{\"end\":7314,\"start\":7253},{\"end\":9892,\"start\":7316},{\"end\":10370,\"start\":9918},{\"end\":10754,\"start\":10372},{\"end\":11269,\"start\":10756},{\"end\":11642,\"start\":11271},{\"end\":12006,\"start\":11644},{\"end\":12692,\"start\":12028},{\"end\":12735,\"start\":12694},{\"end\":12816,\"start\":12737},{\"end\":12847,\"start\":12818},{\"end\":14101,\"start\":12849},{\"end\":14515,\"start\":14130},{\"end\":15856,\"start\":14517},{\"end\":16522,\"start\":15914},{\"end\":19406,\"start\":16524},{\"end\":20569,\"start\":19461},{\"end\":22301,\"start\":20788},{\"end\":23633,\"start\":22338},{\"end\":25062,\"start\":23662},{\"end\":25583,\"start\":25064},{\"end\":26106,\"start\":25604},{\"end\":26325,\"start\":26263},{\"end\":26418,\"start\":26327},{\"end\":28171,\"start\":26420},{\"end\":29504,\"start\":28173},{\"end\":29970,\"start\":29534},{\"end\":30170,\"start\":29986},{\"end\":30350,\"start\":30172},{\"end\":30981,\"start\":30352},{\"end\":31525,\"start\":31015},{\"end\":33508,\"start\":31527},{\"end\":34720,\"start\":33510},{\"end\":35299,\"start\":34744},{\"end\":35446,\"start\":35301},{\"end\":35521,\"start\":35448},{\"end\":35618,\"start\":35535},{\"end\":35711,\"start\":35620},{\"end\":37854,\"start\":35713},{\"end\":40908,\"start\":37885},{\"end\":42697,\"start\":40916},{\"end\":43879,\"start\":42705},{\"end\":44972,\"start\":43906},{\"end\":46388,\"start\":45018},{\"end\":47958,\"start\":46403},{\"end\":48585,\"start\":47982},{\"end\":49119,\"start\":48587},{\"end\":49998,\"start\":49121},{\"end\":50736,\"start\":50015},{\"end\":51641,\"start\":50738},{\"end\":53604,\"start\":51643},{\"end\":54986,\"start\":53619},{\"end\":55196,\"start\":54988}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":20787,\"start\":20570},{\"attributes\":{\"id\":\"formula_1\"},\"end\":26262,\"start\":26107},{\"attributes\":{\"id\":\"formula_2\"},\"end\":35534,\"start\":35522}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":15855,\"start\":15848},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":31289,\"start\":31282},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":34339,\"start\":34332},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":38073,\"start\":38066},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":39722,\"start\":39715},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":41065,\"start\":41058},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":43039,\"start\":43032}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2652,\"start\":2640},{\"attributes\":{\"n\":\"2.2\"},\"end\":9916,\"start\":9895},{\"attributes\":{\"n\":\"2.3\"},\"end\":12026,\"start\":12009},{\"attributes\":{\"n\":\"3\"},\"end\":14128,\"start\":14104},{\"attributes\":{\"n\":\"3.2\"},\"end\":15884,\"start\":15859},{\"attributes\":{\"n\":\"3.2.1\"},\"end\":15912,\"start\":15887},{\"end\":19459,\"start\":19409},{\"attributes\":{\"n\":\"3.2.2\"},\"end\":22336,\"start\":22304},{\"attributes\":{\"n\":\"3.3\"},\"end\":23660,\"start\":23636},{\"attributes\":{\"n\":\"3.3.2\"},\"end\":25602,\"start\":25586},{\"attributes\":{\"n\":\"3.4\"},\"end\":29532,\"start\":29507},{\"attributes\":{\"n\":\"4\"},\"end\":29984,\"start\":29973},{\"attributes\":{\"n\":\"4.1\"},\"end\":31002,\"start\":30984},{\"attributes\":{\"n\":\"4.1.1\"},\"end\":31013,\"start\":31005},{\"attributes\":{\"n\":\"4.1.2\"},\"end\":34742,\"start\":34723},{\"attributes\":{\"n\":\"4.2\"},\"end\":37877,\"start\":37857},{\"attributes\":{\"n\":\"4.2.1\"},\"end\":37883,\"start\":37880},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":40914,\"start\":40911},{\"attributes\":{\"n\":\"4.2.3\"},\"end\":42703,\"start\":42700},{\"attributes\":{\"n\":\"4.2.4\"},\"end\":43904,\"start\":43882},{\"attributes\":{\"n\":\"5\"},\"end\":45016,\"start\":44975},{\"attributes\":{\"n\":\"5.2\"},\"end\":46401,\"start\":46391},{\"attributes\":{\"n\":\"5.3\"},\"end\":47980,\"start\":47961},{\"attributes\":{\"n\":\"6\"},\"end\":50013,\"start\":50001},{\"attributes\":{\"n\":\"7\"},\"end\":53617,\"start\":53607},{\"end\":55208,\"start\":55198},{\"end\":55230,\"start\":55220},{\"end\":55422,\"start\":55402},{\"end\":55485,\"start\":55480},{\"end\":55623,\"start\":55609},{\"end\":57148,\"start\":57138},{\"end\":57277,\"start\":57267},{\"end\":57419,\"start\":57410},{\"end\":58208,\"start\":58199},{\"end\":58366,\"start\":58357},{\"end\":59110,\"start\":59101},{\"end\":59233,\"start\":59224}]", "table": "[{\"end\":57463,\"start\":57441},{\"end\":58197,\"start\":57556},{\"end\":58355,\"start\":58265},{\"end\":59099,\"start\":58417},{\"end\":59222,\"start\":59160},{\"end\":59435,\"start\":59284}]", "figure_caption": "[{\"end\":55218,\"start\":55210},{\"end\":55400,\"start\":55232},{\"end\":55478,\"start\":55425},{\"end\":55607,\"start\":55487},{\"end\":55857,\"start\":55625},{\"end\":56483,\"start\":55860},{\"end\":56873,\"start\":56486},{\"end\":57136,\"start\":56876},{\"end\":57265,\"start\":57150},{\"end\":57408,\"start\":57279},{\"end\":57441,\"start\":57421},{\"end\":57556,\"start\":57466},{\"end\":58265,\"start\":58210},{\"end\":58417,\"start\":58368},{\"end\":59160,\"start\":59112},{\"end\":59284,\"start\":59235}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10651,\"start\":10645},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11073,\"start\":11067},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11380,\"start\":11374},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14569,\"start\":14563},{\"end\":17352,\"start\":17346},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18201,\"start\":18195},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20217,\"start\":20211},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20543,\"start\":20537},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22154,\"start\":22148},{\"end\":26286,\"start\":26278},{\"end\":27022,\"start\":27016},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":44488,\"start\":44482},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":46487,\"start\":46481}]", "bib_author_first_name": "[{\"end\":59782,\"start\":59775},{\"end\":59790,\"start\":59789},{\"end\":59806,\"start\":59800},{\"end\":60056,\"start\":60050},{\"end\":60070,\"start\":60066},{\"end\":60084,\"start\":60077},{\"end\":60099,\"start\":60094},{\"end\":60109,\"start\":60108},{\"end\":60123,\"start\":60117},{\"end\":60497,\"start\":60496},{\"end\":60515,\"start\":60506},{\"end\":60790,\"start\":60781},{\"end\":60799,\"start\":60797},{\"end\":60811,\"start\":60806},{\"end\":60818,\"start\":60816},{\"end\":60832,\"start\":60826},{\"end\":60843,\"start\":60840},{\"end\":60855,\"start\":60848},{\"end\":60864,\"start\":60862},{\"end\":60878,\"start\":60871},{\"end\":60892,\"start\":60884},{\"end\":61595,\"start\":61587},{\"end\":61609,\"start\":61602},{\"end\":61619,\"start\":61615},{\"end\":62096,\"start\":62089},{\"end\":62115,\"start\":62107},{\"end\":62131,\"start\":62127},{\"end\":62143,\"start\":62139},{\"end\":62535,\"start\":62529},{\"end\":62627,\"start\":62626},{\"end\":62644,\"start\":62637},{\"end\":62840,\"start\":62836},{\"end\":62852,\"start\":62847},{\"end\":62870,\"start\":62864},{\"end\":62884,\"start\":62878},{\"end\":62908,\"start\":62898},{\"end\":63201,\"start\":63195},{\"end\":63208,\"start\":63207},{\"end\":63210,\"start\":63209},{\"end\":63227,\"start\":63220},{\"end\":63238,\"start\":63233},{\"end\":63247,\"start\":63245},{\"end\":63255,\"start\":63252},{\"end\":63546,\"start\":63540},{\"end\":63558,\"start\":63551},{\"end\":63574,\"start\":63564},{\"end\":63586,\"start\":63580},{\"end\":63601,\"start\":63594},{\"end\":64284,\"start\":64280},{\"end\":64302,\"start\":64292},{\"end\":64314,\"start\":64308},{\"end\":64329,\"start\":64321},{\"end\":64351,\"start\":64345},{\"end\":64366,\"start\":64358},{\"end\":64849,\"start\":64845},{\"end\":64868,\"start\":64859},{\"end\":64894,\"start\":64883},{\"end\":64907,\"start\":64904},{\"end\":64920,\"start\":64917},{\"end\":65416,\"start\":65410},{\"end\":65512,\"start\":65505},{\"end\":65521,\"start\":65518},{\"end\":65537,\"start\":65529},{\"end\":65550,\"start\":65544},{\"end\":65564,\"start\":65558},{\"end\":65574,\"start\":65570},{\"end\":65589,\"start\":65579},{\"end\":65604,\"start\":65595},{\"end\":65617,\"start\":65609},{\"end\":65630,\"start\":65622},{\"end\":66352,\"start\":66345},{\"end\":66364,\"start\":66358},{\"end\":66382,\"start\":66372},{\"end\":66390,\"start\":66388},{\"end\":66404,\"start\":66398},{\"end\":66780,\"start\":66776},{\"end\":66789,\"start\":66786},{\"end\":66794,\"start\":66790},{\"end\":66807,\"start\":66800},{\"end\":67113,\"start\":67108},{\"end\":67123,\"start\":67119},{\"end\":67136,\"start\":67131},{\"end\":67533,\"start\":67523},{\"end\":67546,\"start\":67539},{\"end\":67555,\"start\":67552},{\"end\":67567,\"start\":67562},{\"end\":67579,\"start\":67572},{\"end\":67590,\"start\":67587},{\"end\":68031,\"start\":68024},{\"end\":68041,\"start\":68036},{\"end\":68055,\"start\":68047},{\"end\":68068,\"start\":68063},{\"end\":68086,\"start\":68075},{\"end\":68100,\"start\":68094},{\"end\":68114,\"start\":68108},{\"end\":68124,\"start\":68119},{\"end\":68135,\"start\":68130},{\"end\":68147,\"start\":68140},{\"end\":68580,\"start\":68576},{\"end\":68593,\"start\":68589},{\"end\":68608,\"start\":68601},{\"end\":68627,\"start\":68617},{\"end\":68638,\"start\":68635},{\"end\":68654,\"start\":68648},{\"end\":69056,\"start\":69048},{\"end\":69066,\"start\":69063},{\"end\":69071,\"start\":69067},{\"end\":69083,\"start\":69078},{\"end\":69085,\"start\":69084},{\"end\":69603,\"start\":69595},{\"end\":69615,\"start\":69610},{\"end\":69632,\"start\":69623},{\"end\":69950,\"start\":69945},{\"end\":70153,\"start\":70149},{\"end\":70170,\"start\":70165},{\"end\":70184,\"start\":70177},{\"end\":70197,\"start\":70194},{\"end\":70212,\"start\":70205},{\"end\":70227,\"start\":70220},{\"end\":70236,\"start\":70233},{\"end\":70639,\"start\":70631},{\"end\":70660,\"start\":70654},{\"end\":71073,\"start\":71066},{\"end\":71094,\"start\":71088},{\"end\":71103,\"start\":71099},{\"end\":71117,\"start\":71110},{\"end\":71128,\"start\":71122},{\"end\":71140,\"start\":71136},{\"end\":71149,\"start\":71146},{\"end\":71159,\"start\":71156},{\"end\":71168,\"start\":71166},{\"end\":71710,\"start\":71709},{\"end\":71994,\"start\":71989},{\"end\":72015,\"start\":72003},{\"end\":72033,\"start\":72024},{\"end\":72052,\"start\":72043},{\"end\":72671,\"start\":72669},{\"end\":72683,\"start\":72676},{\"end\":72697,\"start\":72690},{\"end\":72707,\"start\":72703},{\"end\":72716,\"start\":72713},{\"end\":72725,\"start\":72722},{\"end\":73253,\"start\":73248},{\"end\":73270,\"start\":73264},{\"end\":73287,\"start\":73281},{\"end\":73299,\"start\":73294},{\"end\":73311,\"start\":73307},{\"end\":73324,\"start\":73318},{\"end\":73651,\"start\":73645},{\"end\":73663,\"start\":73656},{\"end\":73677,\"start\":73670},{\"end\":73689,\"start\":73684},{\"end\":73700,\"start\":73694},{\"end\":73711,\"start\":73705},{\"end\":73720,\"start\":73716},{\"end\":73733,\"start\":73726},{\"end\":73743,\"start\":73740},{\"end\":73753,\"start\":73749},{\"end\":74230,\"start\":74222},{\"end\":74245,\"start\":74239},{\"end\":74257,\"start\":74253},{\"end\":74656,\"start\":74639},{\"end\":74665,\"start\":74662},{\"end\":74679,\"start\":74671},{\"end\":74697,\"start\":74689},{\"end\":74710,\"start\":74705},{\"end\":74720,\"start\":74717},{\"end\":74733,\"start\":74728},{\"end\":74741,\"start\":74734},{\"end\":74755,\"start\":74747},{\"end\":74769,\"start\":74763},{\"end\":75282,\"start\":75274},{\"end\":75295,\"start\":75289},{\"end\":75308,\"start\":75304},{\"end\":75319,\"start\":75314},{\"end\":75332,\"start\":75328},{\"end\":75721,\"start\":75718},{\"end\":75744,\"start\":75727},{\"end\":75757,\"start\":75750},{\"end\":75774,\"start\":75769},{\"end\":75789,\"start\":75783},{\"end\":76184,\"start\":76182},{\"end\":76193,\"start\":76191},{\"end\":76206,\"start\":76200},{\"end\":76215,\"start\":76207},{\"end\":76224,\"start\":76221},{\"end\":76240,\"start\":76232},{\"end\":76256,\"start\":76251},{\"end\":76269,\"start\":76262}]", "bib_author_last_name": "[{\"end\":59787,\"start\":59783},{\"end\":59798,\"start\":59791},{\"end\":59811,\"start\":59807},{\"end\":59825,\"start\":59813},{\"end\":60064,\"start\":60057},{\"end\":60075,\"start\":60071},{\"end\":60092,\"start\":60085},{\"end\":60106,\"start\":60100},{\"end\":60115,\"start\":60110},{\"end\":60129,\"start\":60124},{\"end\":60144,\"start\":60131},{\"end\":60504,\"start\":60498},{\"end\":60524,\"start\":60516},{\"end\":60534,\"start\":60526},{\"end\":60795,\"start\":60791},{\"end\":60804,\"start\":60800},{\"end\":60814,\"start\":60812},{\"end\":60824,\"start\":60819},{\"end\":60838,\"start\":60833},{\"end\":60846,\"start\":60844},{\"end\":60860,\"start\":60856},{\"end\":60869,\"start\":60865},{\"end\":60882,\"start\":60879},{\"end\":60895,\"start\":60893},{\"end\":61600,\"start\":61596},{\"end\":61613,\"start\":61610},{\"end\":61625,\"start\":61620},{\"end\":62105,\"start\":62097},{\"end\":62125,\"start\":62116},{\"end\":62137,\"start\":62132},{\"end\":62150,\"start\":62144},{\"end\":62541,\"start\":62536},{\"end\":62635,\"start\":62628},{\"end\":62649,\"start\":62645},{\"end\":62656,\"start\":62651},{\"end\":62845,\"start\":62841},{\"end\":62862,\"start\":62853},{\"end\":62876,\"start\":62871},{\"end\":62896,\"start\":62885},{\"end\":62919,\"start\":62909},{\"end\":63205,\"start\":63202},{\"end\":63218,\"start\":63211},{\"end\":63231,\"start\":63228},{\"end\":63243,\"start\":63239},{\"end\":63250,\"start\":63248},{\"end\":63259,\"start\":63256},{\"end\":63266,\"start\":63261},{\"end\":63549,\"start\":63547},{\"end\":63562,\"start\":63559},{\"end\":63578,\"start\":63575},{\"end\":63592,\"start\":63587},{\"end\":63615,\"start\":63602},{\"end\":63622,\"start\":63617},{\"end\":64290,\"start\":64285},{\"end\":64306,\"start\":64303},{\"end\":64319,\"start\":64315},{\"end\":64343,\"start\":64330},{\"end\":64356,\"start\":64352},{\"end\":64379,\"start\":64367},{\"end\":64384,\"start\":64381},{\"end\":64857,\"start\":64850},{\"end\":64881,\"start\":64869},{\"end\":64902,\"start\":64895},{\"end\":64915,\"start\":64908},{\"end\":64931,\"start\":64921},{\"end\":65422,\"start\":65417},{\"end\":65516,\"start\":65513},{\"end\":65527,\"start\":65522},{\"end\":65542,\"start\":65538},{\"end\":65556,\"start\":65551},{\"end\":65568,\"start\":65565},{\"end\":65577,\"start\":65575},{\"end\":65593,\"start\":65590},{\"end\":65607,\"start\":65605},{\"end\":65620,\"start\":65618},{\"end\":65634,\"start\":65631},{\"end\":66356,\"start\":66353},{\"end\":66370,\"start\":66365},{\"end\":66386,\"start\":66383},{\"end\":66396,\"start\":66391},{\"end\":66409,\"start\":66405},{\"end\":66784,\"start\":66781},{\"end\":66798,\"start\":66795},{\"end\":66812,\"start\":66808},{\"end\":66818,\"start\":66814},{\"end\":67117,\"start\":67114},{\"end\":67129,\"start\":67124},{\"end\":67142,\"start\":67137},{\"end\":67537,\"start\":67534},{\"end\":67550,\"start\":67547},{\"end\":67560,\"start\":67556},{\"end\":67570,\"start\":67568},{\"end\":67585,\"start\":67580},{\"end\":67594,\"start\":67591},{\"end\":68034,\"start\":68032},{\"end\":68045,\"start\":68042},{\"end\":68061,\"start\":68056},{\"end\":68073,\"start\":68069},{\"end\":68092,\"start\":68087},{\"end\":68106,\"start\":68101},{\"end\":68117,\"start\":68115},{\"end\":68128,\"start\":68125},{\"end\":68138,\"start\":68136},{\"end\":68151,\"start\":68148},{\"end\":68587,\"start\":68581},{\"end\":68599,\"start\":68594},{\"end\":68615,\"start\":68609},{\"end\":68633,\"start\":68628},{\"end\":68646,\"start\":68639},{\"end\":68660,\"start\":68655},{\"end\":69061,\"start\":69057},{\"end\":69076,\"start\":69072},{\"end\":69094,\"start\":69086},{\"end\":69608,\"start\":69604},{\"end\":69621,\"start\":69616},{\"end\":69637,\"start\":69633},{\"end\":69956,\"start\":69951},{\"end\":70163,\"start\":70154},{\"end\":70175,\"start\":70171},{\"end\":70192,\"start\":70185},{\"end\":70203,\"start\":70198},{\"end\":70218,\"start\":70213},{\"end\":70231,\"start\":70228},{\"end\":70241,\"start\":70237},{\"end\":70652,\"start\":70640},{\"end\":70666,\"start\":70661},{\"end\":71086,\"start\":71074},{\"end\":71097,\"start\":71095},{\"end\":71108,\"start\":71104},{\"end\":71120,\"start\":71118},{\"end\":71134,\"start\":71129},{\"end\":71144,\"start\":71141},{\"end\":71154,\"start\":71150},{\"end\":71164,\"start\":71160},{\"end\":71173,\"start\":71169},{\"end\":71180,\"start\":71175},{\"end\":71716,\"start\":71711},{\"end\":71726,\"start\":71718},{\"end\":72001,\"start\":71995},{\"end\":72022,\"start\":72016},{\"end\":72041,\"start\":72034},{\"end\":72061,\"start\":72053},{\"end\":72674,\"start\":72672},{\"end\":72688,\"start\":72684},{\"end\":72701,\"start\":72698},{\"end\":72711,\"start\":72708},{\"end\":72720,\"start\":72717},{\"end\":72729,\"start\":72726},{\"end\":73262,\"start\":73254},{\"end\":73279,\"start\":73271},{\"end\":73292,\"start\":73288},{\"end\":73305,\"start\":73300},{\"end\":73316,\"start\":73312},{\"end\":73330,\"start\":73325},{\"end\":73336,\"start\":73332},{\"end\":73654,\"start\":73652},{\"end\":73668,\"start\":73664},{\"end\":73682,\"start\":73678},{\"end\":73692,\"start\":73690},{\"end\":73703,\"start\":73701},{\"end\":73714,\"start\":73712},{\"end\":73724,\"start\":73721},{\"end\":73738,\"start\":73734},{\"end\":73747,\"start\":73744},{\"end\":73758,\"start\":73754},{\"end\":74237,\"start\":74231},{\"end\":74251,\"start\":74246},{\"end\":74270,\"start\":74258},{\"end\":74660,\"start\":74657},{\"end\":74669,\"start\":74666},{\"end\":74687,\"start\":74680},{\"end\":74703,\"start\":74698},{\"end\":74715,\"start\":74711},{\"end\":74726,\"start\":74721},{\"end\":74745,\"start\":74742},{\"end\":74761,\"start\":74756},{\"end\":74775,\"start\":74770},{\"end\":74782,\"start\":74777},{\"end\":75287,\"start\":75283},{\"end\":75302,\"start\":75296},{\"end\":75312,\"start\":75309},{\"end\":75326,\"start\":75320},{\"end\":75339,\"start\":75333},{\"end\":75725,\"start\":75722},{\"end\":75748,\"start\":75745},{\"end\":75767,\"start\":75758},{\"end\":75781,\"start\":75775},{\"end\":75795,\"start\":75790},{\"end\":76189,\"start\":76185},{\"end\":76198,\"start\":76194},{\"end\":76219,\"start\":76216},{\"end\":76230,\"start\":76225},{\"end\":76249,\"start\":76241},{\"end\":76260,\"start\":76257},{\"end\":76274,\"start\":76270}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":59616,\"start\":59452},{\"attributes\":{\"id\":\"b1\"},\"end\":59752,\"start\":59618},{\"attributes\":{\"id\":\"b2\"},\"end\":59964,\"start\":59754},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":208128313},\"end\":60430,\"start\":59966},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":45358376},\"end\":60703,\"start\":60432},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":221792244},\"end\":61530,\"start\":60705},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":174800922},\"end\":61969,\"start\":61532},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":17488311},\"end\":62525,\"start\":61971},{\"attributes\":{\"id\":\"b8\"},\"end\":62572,\"start\":62527},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":6502291},\"end\":62796,\"start\":62574},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":207208264},\"end\":63134,\"start\":62798},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":232061789},\"end\":63474,\"start\":63136},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":49573393},\"end\":64221,\"start\":63476},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":8781910},\"end\":64760,\"start\":64223},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3625298},\"end\":65406,\"start\":64762},{\"attributes\":{\"id\":\"b15\"},\"end\":65453,\"start\":65408},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":53082265},\"end\":66271,\"start\":65455},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":10476185},\"end\":66756,\"start\":66273},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":6505449},\"end\":67023,\"start\":66758},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":211566520},\"end\":67436,\"start\":67025},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":16843343},\"end\":67950,\"start\":67438},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":216561890},\"end\":68465,\"start\":67952},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":237489754},\"end\":68969,\"start\":68467},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":18178448},\"end\":69491,\"start\":68971},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":3561975},\"end\":69894,\"start\":69493},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":17445696},\"end\":70087,\"start\":69896},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":452842},\"end\":70553,\"start\":70089},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":11759273},\"end\":71012,\"start\":70555},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":182952311},\"end\":71652,\"start\":71014},{\"attributes\":{\"id\":\"b29\"},\"end\":71931,\"start\":71654},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":22057},\"end\":72568,\"start\":71933},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":196175745},\"end\":73192,\"start\":72570},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":67869537},\"end\":73544,\"start\":73194},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":3636669},\"end\":74134,\"start\":73546},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":10524988},\"end\":74513,\"start\":74136},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":16475819},\"end\":75206,\"start\":74515},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":233987722},\"end\":75636,\"start\":75208},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":52834234},\"end\":76103,\"start\":75638},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":51805340},\"end\":76567,\"start\":76105}]", "bib_title": "[{\"end\":60048,\"start\":59966},{\"end\":60494,\"start\":60432},{\"end\":60779,\"start\":60705},{\"end\":61585,\"start\":61532},{\"end\":62087,\"start\":61971},{\"end\":62624,\"start\":62574},{\"end\":62834,\"start\":62798},{\"end\":63193,\"start\":63136},{\"end\":63538,\"start\":63476},{\"end\":64278,\"start\":64223},{\"end\":64843,\"start\":64762},{\"end\":65503,\"start\":65455},{\"end\":66343,\"start\":66273},{\"end\":66774,\"start\":66758},{\"end\":67106,\"start\":67025},{\"end\":67521,\"start\":67438},{\"end\":68022,\"start\":67952},{\"end\":68574,\"start\":68467},{\"end\":69046,\"start\":68971},{\"end\":69593,\"start\":69493},{\"end\":69943,\"start\":69896},{\"end\":70147,\"start\":70089},{\"end\":70629,\"start\":70555},{\"end\":71064,\"start\":71014},{\"end\":71987,\"start\":71933},{\"end\":72667,\"start\":72570},{\"end\":73246,\"start\":73194},{\"end\":73643,\"start\":73546},{\"end\":74220,\"start\":74136},{\"end\":74637,\"start\":74515},{\"end\":75272,\"start\":75208},{\"end\":75716,\"start\":75638},{\"end\":76180,\"start\":76105}]", "bib_author": "[{\"end\":59789,\"start\":59775},{\"end\":59800,\"start\":59789},{\"end\":59813,\"start\":59800},{\"end\":59827,\"start\":59813},{\"end\":60066,\"start\":60050},{\"end\":60077,\"start\":60066},{\"end\":60094,\"start\":60077},{\"end\":60108,\"start\":60094},{\"end\":60117,\"start\":60108},{\"end\":60131,\"start\":60117},{\"end\":60146,\"start\":60131},{\"end\":60506,\"start\":60496},{\"end\":60526,\"start\":60506},{\"end\":60536,\"start\":60526},{\"end\":60797,\"start\":60781},{\"end\":60806,\"start\":60797},{\"end\":60816,\"start\":60806},{\"end\":60826,\"start\":60816},{\"end\":60840,\"start\":60826},{\"end\":60848,\"start\":60840},{\"end\":60862,\"start\":60848},{\"end\":60871,\"start\":60862},{\"end\":60884,\"start\":60871},{\"end\":60897,\"start\":60884},{\"end\":61602,\"start\":61587},{\"end\":61615,\"start\":61602},{\"end\":61627,\"start\":61615},{\"end\":62107,\"start\":62089},{\"end\":62127,\"start\":62107},{\"end\":62139,\"start\":62127},{\"end\":62152,\"start\":62139},{\"end\":62543,\"start\":62529},{\"end\":62637,\"start\":62626},{\"end\":62651,\"start\":62637},{\"end\":62658,\"start\":62651},{\"end\":62847,\"start\":62836},{\"end\":62864,\"start\":62847},{\"end\":62878,\"start\":62864},{\"end\":62898,\"start\":62878},{\"end\":62921,\"start\":62898},{\"end\":63207,\"start\":63195},{\"end\":63220,\"start\":63207},{\"end\":63233,\"start\":63220},{\"end\":63245,\"start\":63233},{\"end\":63252,\"start\":63245},{\"end\":63261,\"start\":63252},{\"end\":63268,\"start\":63261},{\"end\":63551,\"start\":63540},{\"end\":63564,\"start\":63551},{\"end\":63580,\"start\":63564},{\"end\":63594,\"start\":63580},{\"end\":63617,\"start\":63594},{\"end\":63624,\"start\":63617},{\"end\":64292,\"start\":64280},{\"end\":64308,\"start\":64292},{\"end\":64321,\"start\":64308},{\"end\":64345,\"start\":64321},{\"end\":64358,\"start\":64345},{\"end\":64381,\"start\":64358},{\"end\":64386,\"start\":64381},{\"end\":64859,\"start\":64845},{\"end\":64883,\"start\":64859},{\"end\":64904,\"start\":64883},{\"end\":64917,\"start\":64904},{\"end\":64933,\"start\":64917},{\"end\":65424,\"start\":65410},{\"end\":65518,\"start\":65505},{\"end\":65529,\"start\":65518},{\"end\":65544,\"start\":65529},{\"end\":65558,\"start\":65544},{\"end\":65570,\"start\":65558},{\"end\":65579,\"start\":65570},{\"end\":65595,\"start\":65579},{\"end\":65609,\"start\":65595},{\"end\":65622,\"start\":65609},{\"end\":65636,\"start\":65622},{\"end\":66358,\"start\":66345},{\"end\":66372,\"start\":66358},{\"end\":66388,\"start\":66372},{\"end\":66398,\"start\":66388},{\"end\":66411,\"start\":66398},{\"end\":66786,\"start\":66776},{\"end\":66800,\"start\":66786},{\"end\":66814,\"start\":66800},{\"end\":66820,\"start\":66814},{\"end\":67119,\"start\":67108},{\"end\":67131,\"start\":67119},{\"end\":67144,\"start\":67131},{\"end\":67539,\"start\":67523},{\"end\":67552,\"start\":67539},{\"end\":67562,\"start\":67552},{\"end\":67572,\"start\":67562},{\"end\":67587,\"start\":67572},{\"end\":67596,\"start\":67587},{\"end\":68036,\"start\":68024},{\"end\":68047,\"start\":68036},{\"end\":68063,\"start\":68047},{\"end\":68075,\"start\":68063},{\"end\":68094,\"start\":68075},{\"end\":68108,\"start\":68094},{\"end\":68119,\"start\":68108},{\"end\":68130,\"start\":68119},{\"end\":68140,\"start\":68130},{\"end\":68153,\"start\":68140},{\"end\":68589,\"start\":68576},{\"end\":68601,\"start\":68589},{\"end\":68617,\"start\":68601},{\"end\":68635,\"start\":68617},{\"end\":68648,\"start\":68635},{\"end\":68662,\"start\":68648},{\"end\":69063,\"start\":69048},{\"end\":69078,\"start\":69063},{\"end\":69096,\"start\":69078},{\"end\":69610,\"start\":69595},{\"end\":69623,\"start\":69610},{\"end\":69639,\"start\":69623},{\"end\":69958,\"start\":69945},{\"end\":70165,\"start\":70149},{\"end\":70177,\"start\":70165},{\"end\":70194,\"start\":70177},{\"end\":70205,\"start\":70194},{\"end\":70220,\"start\":70205},{\"end\":70233,\"start\":70220},{\"end\":70243,\"start\":70233},{\"end\":70654,\"start\":70631},{\"end\":70668,\"start\":70654},{\"end\":71088,\"start\":71066},{\"end\":71099,\"start\":71088},{\"end\":71110,\"start\":71099},{\"end\":71122,\"start\":71110},{\"end\":71136,\"start\":71122},{\"end\":71146,\"start\":71136},{\"end\":71156,\"start\":71146},{\"end\":71166,\"start\":71156},{\"end\":71175,\"start\":71166},{\"end\":71182,\"start\":71175},{\"end\":71718,\"start\":71709},{\"end\":71728,\"start\":71718},{\"end\":72003,\"start\":71989},{\"end\":72024,\"start\":72003},{\"end\":72043,\"start\":72024},{\"end\":72063,\"start\":72043},{\"end\":72676,\"start\":72669},{\"end\":72690,\"start\":72676},{\"end\":72703,\"start\":72690},{\"end\":72713,\"start\":72703},{\"end\":72722,\"start\":72713},{\"end\":72731,\"start\":72722},{\"end\":73264,\"start\":73248},{\"end\":73281,\"start\":73264},{\"end\":73294,\"start\":73281},{\"end\":73307,\"start\":73294},{\"end\":73318,\"start\":73307},{\"end\":73332,\"start\":73318},{\"end\":73338,\"start\":73332},{\"end\":73656,\"start\":73645},{\"end\":73670,\"start\":73656},{\"end\":73684,\"start\":73670},{\"end\":73694,\"start\":73684},{\"end\":73705,\"start\":73694},{\"end\":73716,\"start\":73705},{\"end\":73726,\"start\":73716},{\"end\":73740,\"start\":73726},{\"end\":73749,\"start\":73740},{\"end\":73760,\"start\":73749},{\"end\":74239,\"start\":74222},{\"end\":74253,\"start\":74239},{\"end\":74272,\"start\":74253},{\"end\":74662,\"start\":74639},{\"end\":74671,\"start\":74662},{\"end\":74689,\"start\":74671},{\"end\":74705,\"start\":74689},{\"end\":74717,\"start\":74705},{\"end\":74728,\"start\":74717},{\"end\":74747,\"start\":74728},{\"end\":74763,\"start\":74747},{\"end\":74777,\"start\":74763},{\"end\":74784,\"start\":74777},{\"end\":75289,\"start\":75274},{\"end\":75304,\"start\":75289},{\"end\":75314,\"start\":75304},{\"end\":75328,\"start\":75314},{\"end\":75341,\"start\":75328},{\"end\":75727,\"start\":75718},{\"end\":75750,\"start\":75727},{\"end\":75769,\"start\":75750},{\"end\":75783,\"start\":75769},{\"end\":75797,\"start\":75783},{\"end\":76191,\"start\":76182},{\"end\":76200,\"start\":76191},{\"end\":76221,\"start\":76200},{\"end\":76232,\"start\":76221},{\"end\":76251,\"start\":76232},{\"end\":76262,\"start\":76251},{\"end\":76276,\"start\":76262}]", "bib_venue": "[{\"end\":59487,\"start\":59454},{\"end\":59649,\"start\":59620},{\"end\":59773,\"start\":59754},{\"end\":60177,\"start\":60146},{\"end\":60554,\"start\":60536},{\"end\":61039,\"start\":60897},{\"end\":61734,\"start\":61627},{\"end\":62229,\"start\":62152},{\"end\":62665,\"start\":62658},{\"end\":62949,\"start\":62921},{\"end\":63293,\"start\":63268},{\"end\":63771,\"start\":63624},{\"end\":64453,\"start\":64386},{\"end\":65029,\"start\":64933},{\"end\":65783,\"start\":65636},{\"end\":66497,\"start\":66411},{\"end\":66871,\"start\":66820},{\"end\":67212,\"start\":67144},{\"end\":67674,\"start\":67596},{\"end\":68186,\"start\":68153},{\"end\":68710,\"start\":68662},{\"end\":69161,\"start\":69096},{\"end\":69675,\"start\":69639},{\"end\":69974,\"start\":69958},{\"end\":70296,\"start\":70243},{\"end\":70742,\"start\":70668},{\"end\":71278,\"start\":71182},{\"end\":71707,\"start\":71654},{\"end\":72161,\"start\":72063},{\"end\":72827,\"start\":72731},{\"end\":73351,\"start\":73338},{\"end\":73809,\"start\":73760},{\"end\":74305,\"start\":74272},{\"end\":74840,\"start\":74784},{\"end\":75405,\"start\":75341},{\"end\":75853,\"start\":75797},{\"end\":76328,\"start\":76276},{\"end\":61168,\"start\":61041},{\"end\":63305,\"start\":63295},{\"end\":63905,\"start\":63773},{\"end\":64507,\"start\":64455},{\"end\":65112,\"start\":65031},{\"end\":65917,\"start\":65785},{\"end\":69185,\"start\":69163},{\"end\":70803,\"start\":70744},{\"end\":71361,\"start\":71280},{\"end\":72265,\"start\":72163},{\"end\":72910,\"start\":72829},{\"end\":73845,\"start\":73811}]"}}}, "year": 2023, "month": 12, "day": 17}