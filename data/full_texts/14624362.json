{"id": 14624362, "updated": "2023-10-01 10:08:32.997", "metadata": {"title": "Annotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems", "authors": "[{\"first\":\"Shyam\",\"last\":\"Upadhyay\",\"middle\":[]},{\"first\":\"Ming-Wei\",\"last\":\"Chang\",\"middle\":[]}]", "venue": "EACL", "journal": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers", "publication_date": {"year": 2017, "month": null, "day": null}, "abstract": "We propose a new evaluation for automatic solvers for algebra word problems, which can identify mistakes that existing evaluations overlook. Our proposal is to evaluate such solvers using derivations, which reflect how an equation system was constructed from the word problem. To accomplish this, we develop an algorithm for checking the equivalence between two derivations, and show how derivation annotations can be semi-automatically added to existing datasets. To make our experiments more comprehensive, we include the derivation annotation for DRAW-1K, a new dataset containing 1000 general algebra word problems. In our experiments, we found that the annotated derivations enable a more accurate evaluation of automatic solvers than previously used metrics. We release derivation annotations for over 2300 algebra word problems for future evaluations.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1609.07197", "mag": "2963199195", "acl": "E17-1047", "pubmed": null, "pubmedcentral": null, "dblp": "conf/eacl/UpadhyayC17", "doi": "10.18653/v1/e17-1047"}}, "content": {"source": {"pdf_hash": "ce587cc01ba9b122c4798e66f0d7baa94c966b7a", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/E17-1047.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/E17-1047.pdf", "status": "HYBRID"}}, "grobid": {"id": "1d5206c852d73f90638400fbc408309cb17331e8", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/ce587cc01ba9b122c4798e66f0d7baa94c966b7a.txt", "contents": "\nAnnotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems\nAssociation for Computational LinguisticsCopyright Association for Computational LinguisticsApril 3-7, 2017. 2017\n\nShyam Upadhyay upadhya3@illinois.edu \nUniversity of Illinois at Urbana-Champaign\nILUSA\n\nMing-Wei Chang minchang@microsoft.com \nMicrosoft Research\nRedmondWAUSA\n\nAnnotating Derivations: A New Evaluation Strategy and Dataset for Algebra Word Problems\n\nthe Association for Computational Linguistics\nthe 15th Conference of the European ChapterValencia, SpainAssociation for Computational Linguistics1April 3-7, 2017. 2017\nWe propose a new evaluation for automatic solvers for algebra word problems, which can identify mistakes that existing evaluations overlook. Our proposal is to evaluate such solvers using derivations, which reflect how an equation system was constructed from the word problem. To accomplish this, we develop an algorithm for checking the equivalence between two derivations, and show how derivation annotations can be semi-automatically added to existing datasets. To make our experiments more comprehensive, we include the derivation annotation for DRAW-1K, a new dataset containing 1000 general algebra word problems. In our experiments, we found that the annotated derivations enable a more accurate evaluation of automatic solvers than previously used metrics. We release derivation annotations for over 2300 algebra word problems for future evaluations.\n\nIntroduction\n\nAutomatically solving math reasoning problems is a long-pursued goal of AI (Newell et al., 1959;Bobrow, 1964). Recent work Shi et al., 2015;Koncel-Kedziorski et al., 2015) has focused on developing solvers for algebra word problems, such as the one shown in Figure 1. Developing a solver for word problems can open several new avenues, especially for online education and intelligent tutoring systems (Kang et al., 2016). In addition, as solving word problems requires the ability to understand and analyze natural language, it serves as a good test-bed for evaluating progress towards goals of artificial intelligence (Clark and Etzioni, 2016).\n\n\nAm=Bn\n\nCm + Dn = E Costs of apple and orange are in ratio 5 : 15 at the Acme Market. Mark wanted some fruits so he buys 5 apples and 5 oranges for 100 dollars. Find cost of each.\n\n5m=15n,5m+5n=100 (m=15,n=5)\n\n\nSolution Equation System Derivation\n\nFigure 1: An algebra word problem with its solution, equation system and derivation. Evaluating solvers on derivation is more reliable than evaluating on solution or equation system, as it reveals errors that other metric overlook.\n\nAn automatic solver finds the solution of a given word problem by constructing a derivation, consisting of an un-grounded equation system 1 ({Am = Bn, Cm + Dn = E} in Figure 1) and alignments of numbers in the text to its coefficients (blue edges).\n\nThe derivation identifies a grounded equation system {5m = 15n, 5m + 5n = 100}, whose solution can then be generated to answer the problem. A derivation precisely describes how the grounded equation system was constructed from the word problem by the automatic solver. On the other hand, the grounded equation systems and the solutions are less informative, as they do not explain which span of text aligns to the coefficients in the equations.\n\nWhile the derivation is clearly the most informative structure, surprisingly, no prior work evaluates automatic solvers using derivations directly. To the best of our knowledge, none of the current datasets contain human-annotated derivations, possibly due to the belief that the current evaluation metrics are sufficient and the benefit of evaluating on derivations is minor. Currently, the most popular evaluation strategy is to use solution accuracy Hosseini et al., 2014;Shi et al., 2015;Koncel-Kedziorski et al., 2015;Zhou et al., 2015;Huang et al., 2016), which computes whether the solution was correct or not, as this is an easy-to-implement metric. Another evaluation strategy was proposed in , which finds an approximate derivation from the gold equation system and uses it to compare against a predicted derivation. We follow  and call this evaluation strategy the equation accuracy. 2 In this work, we argue that evaluating solvers against human labeled derivation is important. Existing evaluation metrics, like solution accuracy are often quite generous -for example, an incorrect equation system, such as, {m + 5 = n + 15, m + n = 15 + 5}, (1) can generate the correct solution of the word problem in Figure 1. While equation accuracy appears to be a stricter metric than solution accuracy, our experiments show that the approximation can mislead evaluation, by assigning higher scores to an inferior solver. Indeed, a correct equation system, (5m = 15n, 5m+5n = 100), can be generated by using a wrong template, Am = Bn, Am + An = C, and aligning numbers in the text to coefficients incorrectly. We show that without knowing the correct derivation at evaluation time, a solver can be awarded for the wrong reasons.\n\nThe lack of annotated derivations for word problems and no clear definition for comparing derivations present technical difficulties in using derivation for evaluation. In this paper, we address these difficulties and for the first time propose to evaluate the solvers using derivation accuracy. To summarize, the contributions of this paper are:\n\n\u2022 We point out that evaluating using derivations is more precise compared to existing metrics. Moreover, contrary to popular belief, there is a meaningful gap between the derivation accuracy and existing metrics, as it can discover crucial errors not captured previously.\n\n\u2022 We formally define when two derivations are equivalent, and develop an algorithm that can determine the same. The algorithm is simple 2 Note that an approximation of the derivation is necessary, as there is no annotated derivation. From the brief description in their paper and the code released by , we found that their implementation assumes that the first derivation that matches the equations and generates the correct solution is the correct reference derivation against which predicted derivations are then evaluated.  to implement, and can accurately detect the equivalence even if two derivations have very different syntactic forms.\nTemplate T Am + Bn = C * D, m + n = C Coefficients C(T ) A, B, C, D Alignments A {321 \u2192 A, 121 \u2192 B, 50 \u2192 C, 20 \u2192 D} EquivTNum {[321, 322], [121, 122]} Derivation z (T, A)\n\u2022 We annotated over 2300 word algebra problems 3 with detailed derivation annotations, providing high quality labeled semantic parses for evaluating word problems.\n\n\nEvaluating Derivations\n\nWe describe our notation and revisit the notion of derivation introduced in . We then formalize the notion of derivation equivalence and provide an algorithm to determine it.\n\n\nStructure of Derivation\n\nThe word problem in Table 1 shows our notation, where our proposed annotations are shown in bold. We denote a word problem by x and an equation system by y. An un-grounded equation system (or template) T is a family of equation systems parameterized by a set of coefficients C(T ) = {c i } k i=1 , where each coefficient c i aligns to a textual number (e.g., four) in the word problem. We also refer to the coefficients as slots of the template. We use (A, B, C, . . .) to represents coefficients and (m, n, . . .) to represent the unknown variables in the templates.\n\nLet Q(x) be the set of all the textual numbers in the problem x, and C(T ) be the coefficients to be determined in the template T . An alignment is a set of tuples A = {(q, c) | q \u2208 Q(x), c \u2208 C(T ) \u222a { }} aligning textual numbers to coefficient slots, where a tuple (q, ) indicates that the number q is not relevant to the final equation system.\n\nNote that there may be multiple semantically equivalent textual numbers. e.g., in Figure 1, either of the 32 can be aligned to coefficient slot A in the template. These equivalent textual numbers are marked in the EquivTNum field in the annotation. If two textual numbers q, q \u2208 EquivTNum, then we can align a coefficient slot to either q or q , and generate a equivalent alignment.\n\nAn alignment A and a template T together identify a derivation z = (T, A) of an equation system. Note that there may be multiple valid derivations, using one of the equivalent alignments. We assume there exists a routine Solve(y) that find the solution of an equation system. We use a Gaussian elimination solver for our Solve routine. We use hand-written rules and the quantity normalizer in Stanford CoreNLP (Manning et al., 2014) to identify textual numbers.\n\n\nDerivation Equivalence\n\nWe define two derivations (T 1 , A 1 ) and (T 2 , A 2 ) to be equivalent iff the corresponding templates T 1 , T 2 and alignments A 1 , A 2 are equivalent.\n\nIntuitively, two templates T 1 , T 2 are equivalent if they can generate the same space of equation systems -i.e., for every assignment of values to slots of T 1 , there exists an assignment of values to slots of T 2 such that they generate the same equation systems. For instance, template (2) and (3) below are equivalent\nm = A + Bn m = C \u2212 n (2) m + n = A m \u2212 Cn = B.(3)\nbecause after renaming (A, B, C) to (B, C, A) respectively in template (2), and algebraic manipulations, it is identical to template (3). We can see that any assignment of values to corresponding slots will result in the same equation system. Similarly, two alignments A 1 and A 2 are equivalent if corresponding slots from each template align to the same textual number. For the above example, the alignment {1 \u2192 A, 3 \u2192 B, 4 \u2192 C} in template (2), and alignment {1 \u2192 B, 3 \u2192 C, 4 \u2192 A} in template (3) are equivalent. Note that the alignment {1 \u2192 A, 3 \u2192 B, 4 \u2192 C} for (2) is not equivalent to {1 \u2192 A, 3 \u2192 B, 4 \u2192 C} in (3), because it does not respect variable renaming. Our definition also allows two alignments to be return 1 10: end if 11: return 0 12: 13: procedure TEMPLEQUIV(T1, T2) 14:\n\nNote that here |C(T1)| = |C(T2)| holds 15:\n\n\u0393 \u2190 \u2205 16:\n\nfor each 1-to-1 mapping \u03b3 : C(T1) \u2192 C(T2) do 17: match \u2190 True 18:\n\nfor t = 1 \u00b7 \u00b7 \u00b7 R do R : Rounds 19:\n\nGenerate random vector v 20: return \u0393 \u0393 = \u2205 iff the templates are equivalent 28: end procedure 29: 30: procedure ALIGNEQUIV(\u0393, A1, A2) 31:\nA1 \u2190 {(vi \u2192 ci)},A2 \u2190 {(vi \u2192 \u03b3(ci))} 21: if Solve(T1, A1) = Solve(T2,\nfor mapping \u03b3 \u2208 \u0393 do 32:\n\nif following holds true,\n(q, c) \u2208 A1 \u21d0\u21d2 {(q, \u03b3(c)) or (q , \u03b3(c))} \u2208 A2\n\n33:\n\nwhere (q , q) \u2208 EquivTNum 34: then return 1 35: end if 36: end for 37: return 0 38: end procedure equivalent, if they use textual numbers in equivalent positions for corresponding slots (as described by EquivTNum field).\n\nIn the following, we carefully explain how template and alignment equivalence are determined algorithmically. Algorithm 1 shows the complete algorithm for comparing two derivations.\n\n\nTemplate Equivalence\n\nWe propose an approximate procedure TEMPLEQUIV (line 13) that detects equivalence between two templates. The procedure relies on the fact that under appropriate renaming of coefficients, two equivalent templates will generate equations which have the same solutions, for all possible coefficient assignments.\n\nFor two templates T 1 and T 2 , with the same number of coefficients |C(T 1 )| = |C(T 2 )|, we represent a choice of renaming coefficients by \u03b3, a 1-to-1 mapping from C(T 1 ) to C(T 2 ). The two templates are equivalent if there exists a \u03b3 such that solutions of the equations identified by T 1 and T 2 are same, for all possible coefficient assignments. The TEMPLEQUIV procedure exhaustively tries all possible renaming of coefficients (line 16), checking if the solutions of the equation systems generated from a random assignment (line 19) match exactly. It declares equivalence if for a renaming \u03b3, the solutions match for R = 10 such random assignments. 4 The procedure returns all renamings \u0393 of coefficients between two templates under which they are equivalent (line 27). We discuss its effectiveness in \u00a73.\n\n\nAlignment Equivalence\n\nThe TEMPLEQUIV procedure returns every mapping \u03b3 in \u0393 under which the templates were equivalent (line 4). Recall that \u03b3 identifies corresponding slots, c and \u03b3(c), in T 1 and T 2 respectively. We describe alignment equivalence using these mappings.\n\nTwo alignments A 1 and A 2 are equivalent if corresponding slots (according to \u03b3) align to the same textual number. More formally, if we find a mapping \u03b3 such that for each tuple (q, c) in A 1 there is (q, \u03b3(c)) in A 2 , then the alignments are equivalent (line 33). We allow for equivalent textual numbers (as identified by EquivTNum field) to match when comparing tuples in alignments.\n\nThe proof of correctness of Algorithm 1 is sketched in the appendix. Using Algorithm 1, we can define derivation accuracy, to be 1 if the predicted derivation (T p , A p ) and the reference derivation (T g , A g ) are equivalent, and 0 otherwise.\n\nProperties of Derivation Accuracy By comparing derivations, we can ensure that the following errors are detected by the evaluation.\n\nFirstly, correct solutions found using incorrect equations will be penalized, as the template used will not be equivalent to reference template. Secondly, correct equation system obtained by an incorrect template will also be penalized for the same reason. Lastly, if the solver uses the correct template to get the correct equation system, but aligns the wrong number to a slot, the alignment will not be equivalent to the reference alignment, and the solver will be penalized too.\n\nWe will see some illustrative examples of above errors in \u00a75.3. Note that the currently popular evaluation metric of solution accuracy will not detect any of these error types.\n\n\nAnnotating Derivations\n\nAs none of the existing benchmarks contain derivation annotations, we decided to augment existing datasets with these annotations. We also annotated DRAW-1K, a new dataset of 1000 general algebra word problems to make our study more comprehensive. Below, we describe how we reduced annotation effort by semi-automatic generated some annotations.\n\nAnnotating gold derivations from scratch for all problems is time consuming. However, not all word problems require manual annotation -sometimes all numbers appearing in the equation system can be uniquely aligned to a textual number without ambiguity. For such problems, the annotations are generated automatically. 5 We identify word problems which have at least one alignment ambiguity -multiple textual numbers with the same value, which appears in the equation system. A example of such a problem is shown in Figure 1, where there are three textual numbers with value 5, which appears in the equation system. Statistics for the number of word problems with such ambiguity is shown in Table 2.\n\nWe only ask annotators to resolve such alignment ambiguities, instead of annotating the entire derivation. If more than one alignments are genuinely correct (as in word problem of Table 1), we ask the annotators to mark both (using the Equiv-TNum field). This ensures our derivation annotations are exhaustive -all correct derivations are marked. With the correct alignment annotations, templates for all problems can be easily induced.\n\nAnnotation Effort To estimate the effort required to annotate derivations, we timed our annotators when annotating 50 word problems (all involved alignment ambiguities). As a control, we also asked annotators to annotate the entire derivation from scratch (i.e., only provided with the word problem and equations), instead of only fixing alignment ambiguities. When annotating from scratch, annotators took an average of 4 minute per word problem, while when fixing alignment ambiguities this time dropped to average of 1 minute  per word problem. We attained a inter-annotator agreement of 92% (raw percentage agreement), with most disagreements arising on EquivTNum field. 6\n\nReconciling Equivalent Templates The number of templates has been used as a measure of dataset diversity (Shi et al., 2015;Huang et al., 2016), however prior work did not reconcile the equivalent templates in the dataset. Indeed, if two templates are equivalent, we can replace one with the other and still generate the correct equations. Therefore, after getting human judgements on alignments, we reconcile all the templates using TEMPLEQUIV as the final step of annotation. TEMPLEQUIV is quite effective (despite being approximate), reducing the number of templates by at least 20% for all datasets (Table 2). We did not find any false positives generated by the TEMPLEQUIV in our manual examination. The reduction in Table 2 clearly indicates that equivalent templates are quite common in all datasets, and number of templates (and hence, dataset diversity) can be significantly overestimated without proper reconciliation.\n\n\nExperimental Setup\n\nWe describe the three datasets used in our experiments. Statistics comparing the datasets is shown in Table 2. In total, our experiments involve over 2300 word problems.\n\n\nAlg-514\n\nThe dataset ALG-514 was introduced in . It consists of 514 general algebra word problems ranging over a variety of narrative scenarios (distance-speed, object counting, simple interest, etc.).\n\nDolphin-L DOLPHIN-L is the linear-T2 subset of the DOLPHIN dataset (Shi et al., 2015), which focuses on number word problems -algebra word problems which describe mathematical relationships directly in the text. All word problems in the linear-T2 subset of the DOLPHIN dataset can be solved using linear equations.\n\nDRAW-1K Diverse Algebra Word (DRAW-1K), consists of 1000 word problems crawled from algebra.com. Details on the dataset creation can be found in the appendix. As ALG-514 was also crawled from algebra.com, we ensured that there is little overlap between the datasets.\n\nWe randomly split DRAW-1K into train, development and test splits with 600, 200, 200 problems respectively. We use 5-fold cross validation splits provided by the authors for DOLPHIN-L and ALG-514.\n\n\nEvaluation\n\nWe compare derivation accuracy against the following evaluation metrics.\n\n\nSolution Accuracy\n\nWe compute solution accuracy by checking if each number in the reference solution appears in the generated solution (disregarding order), following previous work Shi et al., 2015).\n\n\nEquation Accuracy\n\nAn approximation of derivation accuracy that is similar to the one used in . We approximate the reference derivationz by randomly chosen from the (several possible) derivations which lead to the gold y from x. Derivation accuracy is computed against this (possibly incorrect) reference derivation. Note that in equation accuracy, the approximation is used instead of annotated derivation. We include the metric of equation accuracy in our evaluations to show that human annotated derivation is necessary, as approximation made by equation accuracy might be problematic.\n\n\nOur Solver\n\nWe train a solver using a simple modeling approach inspired by  and Zhou et al. (2015). The solver operates as follows. Given a word problem, the solver ranks all templates seen during training, \u0393 train , and selects the set of the top-k (we use k = 10) templates \u03a0 \u2282 \u0393 train . Next, all possible derivations D(\u03a0) that use a template from \u03a0 are generated  Table 3: TE and TD compared using different evaluation metrics. Note that while TD is clearly superior to TE due to extra supervision using the annotations, only derivation accuracy is able to correctly reflect the differences. and scored. The equation system\u0177 identified by highest scoring derivation\u1e91 is output as the prediction. Following (Zhou et al., 2015), we do not model the alignment of nouns phrases to variables, allowing for tractable inference when scoring the generated derivations. The solver is trained using a structured perceptron (Collins, 2002). We extract the following features for a (x, z) pair, Template Features. Unigrams and bigrams of lemmas and POS tags from the word problem x, conjoined with |Q(x)| and |C(T )|.\n\n\nAlignment Tuple Features.\n\nFor two alignment tuples, (q 1 , c 1 ), (q 2 , c 2 ), we add features indicating whether c 1 and c 2 belong to the same equation in the template or share the same variable. If they belong to the same sentence, we also add lemmas of the nouns and verbs between q 1 and q 2 in x.\n\n\nSolution Features.\n\nFeatures indicating if the solution of the system identified by the derivation are integer, negative, non-negative or fractional.\n\n\nExperiments\n\nAre solution and equation accuracy equally capable as derivation accuracy at distinguishing between good and bad models? To answer this question, we train the solver under two settings such that one of the settings has clear advantage over the other, and see if the evaluation metrics reflect this advantage. The two settings are,   Zhou et al., 2015), the solver finds a derivation which agrees with the equation system and the solution, and trains on it.\n\nNote that the derivation found by the solver may be incorrect.\n\nTD (TRAIN ON DERIVATION) (x, z) pairs obtained by the derivation annotation are used as supervision. This setting trains the solver on humanlabeled derivations. Clearly, the TD setting is a more informative supervision strategy than the TE setting. TD provides the correct template and correct alignment (i.e. labeled derivation) as supervision and is expected to perform better than TE, which only provides the question-equation pair. We first present the main results comparing different evaluation metrics on solvers trained using the two settings.\n\n\nMain Results\n\nWe compare the evaluation metrics in Table 3. We want to determine to what degree each evaluation metric reflects the superiority of TD over TE.\n\nWe note that solution accuracy always exceeds derivation accuracy, as a solver can sometimes get the right solutions even with the wrong derivation. Also, solution accuracy is not as sensitive as derivation accuracy to improvements in the solver. For instance, solution accuracy only changes by 2.4 on Dolphin-L when comparing TE and TD, whereas derivation accuracy changes by 10.7 points. We found that the large gap on Dolphin-L was due to several alignment errors in the predicted derivations, which were detected by derivation accuracy. Recall that over 35% of the problems in Dolphin-L have alignment ambiguities (Table 2). In the TD setting, many of these errors made by our solver were corrected as the gold alignment was part of supervision.\n\nEquation accuracy too has several limitations. For DRAW-1K, it cannot determine which solver is better and assigns them the same score. Furthermore, it often (incorrectly) considers TD to be a worse setting than TE, as evident from decrease in the scores (for instance, on DOLPHIN-L). Recall that equation accuracy attempts to approximate derivation accuracy by choosing a random derivation agreeing with the equations, which might be incorrect.\n\n\nStudy with Combining Datasets\n\nWith several ongoing annotation efforts, it is a natural question to ask is whether we can leverage multiple datasets in training to generalize better. In Table 4, we combine DRAW-1K's train split with other datasets, and test on DRAW-1K's test split. DRAW-1K's test split was chosen as it is the largest test split with general algebra problems (recall Dolphin-L contains only number word problems).\n\nWe found that in this setting, it was important to reconcile the templates across datasets. Indeed, when we simply combine the two datasets in the TE setting, we notice a sharp drop in performance (compared to Table 3). However, if we reconciled all templates and then used the new equations for training (called TE * setting in Table 4), we were able to see improvements from training on more data. We suspect difference in annotation style led to several equivalent templates in the combined dataset, which got resolved in TE * . Therefore, in Table 4, we compare TE * and TD settings. 7 In Table 4, a trend similar to Table 3 can be observed -solution accuracy assigns a small improvement to TD over TE * . Derivation accuracy clearly reflects the fact that TD is superior to TE * , with a larger improvement compared to solution accuracy (eg., 5.5 vs 1.5). Equation accuracy, as before, considers TD to be worse than TE * .\n\nNote that this experiment also shows that differences in annotation styles across different algebra problem datasets can lead to poor performance 7 In TE * , the model still trains only using equations, without access to derivations. So TD is still better than TE * .\n\n\nDataset\n\nOurs  when combining these datasets naively. Our findings suggest that derivation annotation and template reconciliation are crucial for such multi-data supervision scenarios.\nKAZB Best Result ALG\n\nComparing Solvers\n\nTo ensure that the results in the previous section were not an artifact of any limitations of our solver, we show here that our solver is competitive to other state-of-the-art solvers, and therefore it is reasonable to assume that similar results can be obtained with other automatic solvers.\n\nIn Table 5, we compare our solver to KAZB, the system of , when trained under the existing supervision paradigm, TE (i.e., training on equations) and evaluated using solution accuracy. We also report the best scores on each dataset, using ZDC and SWLLR to denote the systems of Zhou et al. (2015) and Shi et al. (2015) respectively. Note that our system and KAZB are the only systems that can process all three datasets without significant modification, with our solver being clearly superior to KAZB.\n\n\nCase Study\n\nWe discuss some interesting examples from the datasets, to show the limitations of existing metrics, which derivation accuracy overcomes.\n\nCorrect Solution, Incorrect Equation In the following example from the DOLPHIN-L dataset, by choosing the correct template and the wrong alignments, the solver arrived at the correct solutions, and gets rewarded by solution accuracy.\n\nThe sum of 2(q1) numbers is 25(q2). 12(q3) less than 4(q4) times one(q5) of the numbers is 16(q6) more than twice(q7) the other number.\n\nFind the numbers. \u2021 SWLLR also had a solver which achieves 68.0, using over 9000 semi-automatically generated rules tailored to number word problems. We compare to their similarity based solver instead, which does not use any such rules, given that the rulebased system cannot be applied to general word problems.\n\nNote that there are seven textual numbers (q 1 , . . . , q 7 ) in the word problem. We can arrive at the correct equations ({m + n = 25, 4m \u2212 2n = 16 + 12}), by the correct derivation, m + n = q 2 q 4 m \u2212 q 7 n = q 6 + q 3 .\n\nHowever, the solver found the following derivation, which produces the incorrect equations ({m + n = 25, 2m \u2212 n = 2 + 12}), m + n = q 2 q 1 m \u2212 q 5 n = q 7 + q 3 .\n\nBoth the equations have the same solutions (m = 13, n = 12), but the second derivation is clearly using incorrect reasoning.\n\n\nCorrect Equation, Incorrect Alignment\n\nIn such cases, the solver gets the right equation system, but derived it using wrong alignment. Solution accuracy still rewards the solver. Consider the problem from the DOLPHIN-L dataset,\n\nThe larger of two(q1) numbers is 2(q2) more than 4(q3) times the smaller. Their sum is 67(q4).\n\nFind the numbers.\n\nThe correct derivation for this problem is, m \u2212 q 3 n = q 2 m + n = q 4 . However, our system generated the following derivation, which although results in the exact same equation system (and thus same solutions), is clearly incorrect due incorrect choice of \"two\", m \u2212 q 3 n = q 1 m + n = q 4 .\n\nNote that derivation accuracy will penalize the solver, as the alignment is not equivalent to the reference alignment (q 1 and q 2 are not semantically equivalent textual numbers).\n\n\nBad Approx. in Equation Accuracy\n\nThe following word problem is from the ALG-514 dataset:\n\nMrs.\n\nMartin bought 3(q1) cups of coffee and 2(q2) bagels and spent 12.75(q3) dollars.\n\nMr. Martin bought 2(q4) cups of coffee and 5(q5) bagels and spent 14.00(q6) dollars. Find the cost of one(q7) cup of coffee and that of one(q8) bagel.\n\nThe correct derivation is, q 1 m + q 2 n = q 3 q 4 m + q 5 n = q 6 .\n\nHowever, we found that equation accuracy used the following incorrect derivation for evaluation, q 1 m + q 2 n = q 3 q 2 m + q 5 n = q 6 .\n\nNote while this derivation does generate the correct equation system and solutions, the derivation utilizes the wrong numbers and misunderstood the word problem. This example demonstrates the needs to evaluate the quality of the word problem solvers using the annotated derivations.\n\n\nRelated Work\n\nWe discuss several aspects of previous work in the literature, and how it relates to our study.\n\nExisting Solvers Current solvers for this task can be divided into two broad categories based on their inference approach -template-first and bottom-up. Template-first approaches like Zhou et al., 2015) infer the derivation z = (T, A) sequentially. They first predict the template T and then predict alignments A from textual numbers to coefficients. In contrast, bottom-up approaches (Hosseini et al., 2014;Shi et al., 2015;Koncel-Kedziorski et al., 2015) jointly infer the derivation z = (T, A). Inference proceeds by identifying parts of the template (eg. Am + Bn) and aligning numbers to it ({2 \u2192 A, 3 \u2192 B}). At any intermediate state during inference, we have a partial derivation, describing a fragment of the final equation system (2m + 3n).\n\nWhile our experiments used a solver employing the template-first approach, it is evident that performing inference in all such solvers requires constructing a derivation z = (T, A). Therefore, annotated derivations will be useful for evaluating all such solvers, and may also aid in debugging errors.\n\nOther reconciliation procedures are also discussed (though briefly) in earlier work.  reconciled templates by using a symbolic solver and removing pairs with the same canonicalized form. Zhou et al. (2015) also reconciled templates, but do not describe how it was performed. We showed that reconciliation is important for correct evaluation, for reporting dataset complexity, and also when combining multiple datasets.\n\nLabeling Semantic Parses Similar to our work, efforts have been made to annotate semantic parses for other tasks, although primarily for providing supervision. Prior to the works of Liang et al. (2009) and Clarke et al. (2010), semantic parsers were trained using annotated logical forms (Zelle and Mooney, 1996;Zettlemoyer and Collins, 2005;Wong and Mooney, 2007, inter alia), which were expensive to annotate. Recently, Yih et al. (2016) showed that labeled semantic parses for the knowledge based question answering task can be obtained at a cost comparable to obtaining answers. They showed significant improvements in performance of a questionanswering system using the labeled parses instead of answers for training. More recently, by treating word problems as a semantic parsing task, Upadhyay et al. (2016) found that joint learning using both explicit (derivation as labeled semantic parses) and implicit supervision signals (solution as responses) can significantly outperform models trained using only one type of supervision signal.\n\nOther Semantic Parsing Tasks We demonstrated that response-based evaluation, which is quite popular for most semantic parsing problems (Zelle and Mooney, 1996;Berant et al., 2013;Liang et al., 2011, inter alia) can overlook reasoning errors for algebra problems. A reason for this is that in algebra word problems there can be several semantic parses (i.e., derivations, both correct and incorrect) that can lead to the correct solution using the input (i.e., textual number in word problem). This is not the case for semantic parsing problems like knowledge based question answering, as correct semantic parse can often be identified given the question and the answer. For instance, paths in the knowledge base (KB), that connect the answer and the entities in the question can be interpreted as legitimate semantic parses. The KB therefore acts as a constraint which helps prune out possible semantic parses, given only the problem and the answer. However, such KB-based constraints are unavailable for algebra word problems.\n\n\nConclusion and Discussion\n\nWe proposed an algorithm for evaluating derivations for word problems. We also showed how derivation annotations can be easily obtained by only involving annotators for ambiguous cases. We augmented several existing benchmarks with derivation annotations to facilitate future comparisons. Our experiments with multiple datasets also provided insights into the right approach to combine datasets -a natural step in future work. Our main finding indicates that derivation accuracy leads to a more accurate assessment of algebra word problem solvers, finding errors which other metrics overlook. While we should strive to build such solvers using as little supervision as possible for training, having high quality annotated data is essential for correct evaluation.\n\nThe value of such annotations for evaluation becomes more immediate for online education scenarios, where such word solvers are likely to be used. Indeed, in these cases, merely arriving at the correct solution, by using incorrect reasoning may prove detrimental for teaching purposes. We believe derivation based evaluation closely mirrors how humans are evaluated in schools (by forcing solvers to show \"their work\").\n\nOur datasets with the derivation annotations have applications beyond accurate evaluation. For instance, certain solvers, like the one in (Roy and Roth, 2015), train a relevance classifier to identify which textual numbers are relevant to solving the word problem. As we only annotate relevant numbers in our annotations, our datasets can provide high quality supervision for such classifiers. The datasets can also be used in evaluation test-beds, like the one proposed in (Koncel-Kedziorski et al., 2016).\n\nWe hope our datasets will open new possibilities for the community to simulate new ideas and applications for automatic problem solvers.\n\nLemma 1. The procedure TEMPLEQUIV returns \u0393 = \u2205 iff templates T 1 , T 2 are equivalent (w.h.p.).\n\nProof First we prove that with high probability we are correct in claiming that a \u03b3 found by the algorithm leads to equivalence. Let probability of getting the same solution even when the template are not equivalent be (T 1 , T 2 , \u03b3) < 1. The probability that solution is same for R rounds for T 1 , T 2 which are not equivalent is \u2264 R , which can be made arbitrarily small by choosing large R. Therefore, with a large enough R, obtaining \u0393 = \u2205 from TEMPLEQUIV implies there is a \u03b3 under which templates generate equations with the same solution, and by definition, are equivalent.\n\nConversely, if templates are equivalent, it implies \u2203\u03b3 * such that under that mapping for any assignment, the generated equations have the same solution. As we iterate over all possible 1-1 mappings \u03b3 between the two templates, we will find \u03b3 * eventually.\n\nProposition Algorithm 1 returning 1 implies derivations (T p , A p ) and (T g , A g ) are equivalent.\n\nProof Algorithm returns 1 only if TEMPLEQUIV found a \u0393 = \u2205, and \u2203\u03b3 \u2208 \u0393, following holds (q, c) \u2208 A g \u21d0\u21d2 (q, \u03b3(c)) \u2208 A p i.e., the corresponding slots aligned to the same textual number. TEMPLEQUIV found a \u0393 = \u2205 implies templates are equivalent (w.h.p). Therefore, \u2203\u03b3 \u2208 \u0393 such that the corresponding slots aligned to the same textual number implies the alignments are equivalent under mapping \u03b3. Together they imply that the derivation was equivalent (w.h.p.).\n\nTable 1 :\n1The symbols we used in the paper. Our proposed annotations are shown in bold. Equivalent textual numbers, described in EquivTNum, are distinguished with subscripts.\n\n\nAlgorithm 1 Evaluating DerivationInput: Predicted (Tp, Ap) and gold (Tg, Ag) derivationOutput: 1 if predicted derivation is correct, 0 otherwise \n1: if |C(Tp)| = |C(Tg)| then \ndifferent # of coeff. slots \n2: \nreturn 0 \n3: end if \n4: \u0393 \u2190 TEMPLEQUIV(Tp,Tg) \n5: if \u0393 = \u2205 then \nnot equivalent templates \n6: \nreturn 0 \n7: end if \n8: if ALIGNEQUIV(\u0393, Ap, Ag) then \nCheck alignments \n9: \n\n\nTable 2 :\n2Statistics of the datasets. At least 20% of problems \nin each dataset had alignment ambiguities that required hu-\nman annotations. The number of templates before and after \nannotation is also shown (reduction > 20%). \n\n\n\n\nSettingSoln. Acc. Eqn. Acc. Deriv. Acc.ALG-514 \n\nTE \n76.2 \n72.7 \n75.5 \nTD \n78.4 \n73.9 \n77.8 \nTD -TE \n2.2 \n1.2 \n2.3 \n\nDRAW-1K \n\nTE \n52.0 \n48.0 \n48.0 \nTD \n55.0 \n48.0 \n53.0 \nTD -TE \n3.0 \n0 \n5.0 \n\nDOLPHIN \n\nTE \n55.1 \n50.1 \n44.2 \nTD \n57.5 \n36.8 \n54.9 \nTD -TE \n2.4 \n-13.3 \n10.7 \n\n\n\nTable 4 :\n4When combining two datasets, it is essential to reconcile templates across datasets. Here TE * denotes training on equations after reconciling the templates, while TE simply combines datasets naively. As TE * represents a more appropriate setting, we compare TE * and TD in this experiment.TE (TRAIN ON EQUATION) Only the (x, y) \npairs are provided as supervision. Similar to \n\n\nTable 5 :\n5Comparison of our solver and other state-of-the-art \nsystems, when trained under TE setting. All numbers are \nsolution accuracy. See footnote for details on the comparison \nto SWLLR. \n\n\nAlso referred to as a template. We use these two terms interchangeably.\navailable at https://aka.ms/datadraw\nNote that this procedure is a Monte-Carlo algorithm, and can be made more precise by increasing R. We found making R larger than 10 did not have an impact on the empirical results.\nAnnotations for all problems are manually verified later.\nThese were adjudicated on by the first author.\nIn some cases, some of the numbers in the text are rephrased (\"10ml\" to \"10 ml\") in order to allow NLP pipeline work properly.\nAcknowledgmentsThe first author was supported on a grant sponsored by DARPA under agreement number FA8750-13-2-0008. We would also like to thank Subhro Roy, Stephen Mayhew and Christos Christodoulopoulos for useful discussions and comments on earlier versions of the paper.A Creating DRAW-1KWe crawl over 100k problems from http:// algebra.com. The 100k word problems include some problems which require solving nonlinear equations (e.g. finding roots of quadratic equations). We filter out these problems using keyword matching. We also filter problems whose explanation do not contain a variable named \"x\". This leaves us with 12k word problems.Extracting Equations A word problem on algebra.com is accompanied by a detailed explanation provided by instructors. In our crawler, we use simple pattern matching rules to extract all the equations in the explanation. The problems often have sentences which are irrelevant to solving the word problem (e.g. \"Please help me, I am stuck.\"). During cleaning, the annotator removes such sentences from the final word problem and performs some minor editing if necessary. 8 1000 problems were randomly chosen from these pool of 12k problems, which were then shown to annotators as described earlier to get the derivation annotations.B Proof of Correctness (Sketch)For simplicity, we will assume that EquivTNum is empty. The proof can easily be extended to handle the more general situation.\nSemantic parsing on Freebase from question-answer pairs. Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. the 2013 Conference on Empirical Methods in Natural Language ProcessingSeattle, Washington, USA, October. Association for Computational LinguisticsJonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on Freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Lan- guage Processing, pages 1533-1544, Seattle, Wash- ington, USA, October. Association for Computa- tional Linguistics.\n\nA question-answering system for high school algebra word problems. G Daniel, Bobrow, Proceedings of the. theACMfall joint computer conference, part IDaniel G. Bobrow. 1964. A question-answering sys- tem for high school algebra word problems. In Pro- ceedings of the October 27-29, 1964, fall joint com- puter conference, part I, pages 591-614. ACM.\n\nMy computer is an honor student but how intelligent is it? standardized tests as a measure of ai. Peter Clark, Oren Etzioni, 37AI MagazinePeter Clark and Oren Etzioni. 2016. My computer is an honor student but how intelligent is it? standard- ized tests as a measure of ai. AI Magazine, 37(1):5- 12.\n\nDriving semantic parsing from the world's response. James Clarke, Dan Goldwasser, Ming-Wei Chang, Dan Roth , Proceedings of the Fourteenth Conference on Computational Natural Language Learning. the Fourteenth Conference on Computational Natural Language LearningUppsala, SwedenAssociation for Computational LinguisticsJames Clarke, Dan Goldwasser, Ming-Wei Chang, and Dan Roth. 2010. Driving semantic parsing from the world's response. In Proceedings of the Four- teenth Conference on Computational Natural Lan- guage Learning, pages 18-27, Uppsala, Sweden, July. Association for Computational Linguistics.\n\nDiscriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. Michael Collins, Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing. the 2002 Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational LinguisticsMichael Collins. 2002. Discriminative training meth- ods for hidden markov models: Theory and experi- ments with perceptron algorithms. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 1-8. Associ- ation for Computational Linguistics, July.\n\nLearning to solve arithmetic word problems with verb categorization. Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, Nate Kushman, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)Doha, Qatar, OctoberAssociation for Computational LinguisticsMohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning to solve arithmetic word problems with verb catego- rization. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Process- ing (EMNLP), pages 523-533, Doha, Qatar, Octo- ber. Association for Computational Linguistics.\n\nHow well do computers solve math word problems? large-scale dataset construction and evaluation. Danqing Huang, Shuming Shi, Chin-Yew Lin, Jian Yin, Wei-Ying Ma, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyAssociation for Computational Linguistics1Danqing Huang, Shuming Shi, Chin-Yew Lin, Jian Yin, and Wei-Ying Ma. 2016. How well do comput- ers solve math word problems? large-scale dataset construction and evaluation. In Proceedings of the 54th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 887-896, Berlin, Germany, August. Association for Computational Linguistics.\n\nAnalyticalink: An interactive learning environment for math word problem solving. Bo Kang, Arun Kulshreshth, Joseph J LaviolaJr, Proceedings of the 21st International Conference on Intelligent User Interfaces. the 21st International Conference on Intelligent User InterfacesACMBo Kang, Arun Kulshreshth, and Joseph J. LaViola Jr. 2016. Analyticalink: An interactive learning envi- ronment for math word problem solving. In Pro- ceedings of the 21st International Conference on In- telligent User Interfaces, pages 419-430. ACM.\n\nParsing algebraic word problems into equations. Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, Siena Ang, Transactions of the Association for Computational Linguistics. 3Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and Siena Ang. 2015. Parsing algebraic word problems into equations. Transactions of the Association for Computational Linguistics, 3:585-597.\n\nMawps: A math word problem repository. Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, Hannaneh Hajishirzi, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSan Diego, CaliforniaAssociation for Computational LinguisticsRik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, and Hannaneh Hajishirzi. 2016. Mawps: A math word problem repository. In Proceedings of the 2016 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies, pages 1152-1157, San Diego, California, June. Association for Com- putational Linguistics.\n\nLearning to automatically solve algebra word problems. Nate Kushman, Yoav Artzi, Luke Zettlemoyer, Regina Barzilay, Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. the 52nd Annual Meeting of the Association for Computational LinguisticsBaltimore, MarylandAssociation for Computational Linguistics1Nate Kushman, Yoav Artzi, Luke Zettlemoyer, and Regina Barzilay. 2014. Learning to automatically solve algebra word problems. In Proceedings of the 52nd Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 271-281, Baltimore, Maryland, June. Association for Computational Linguistics.\n\nLearning semantic correspondences with less supervision. Percy Liang, Michael Jordan, Dan Klein, Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLPSuntec, Singapore, August. Association for Computational LinguisticsPercy Liang, Michael Jordan, and Dan Klein. 2009. Learning semantic correspondences with less super- vision. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th In- ternational Joint Conference on Natural Language Processing of the AFNLP, pages 91-99, Suntec, Sin- gapore, August. Association for Computational Lin- guistics.\n\nLearning dependency-based compositional semantics. Percy Liang, Michael Jordan, Dan Klein, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesOregon, USAPortland. Association for Computational LinguisticsPercy Liang, Michael Jordan, and Dan Klein. 2011. Learning dependency-based compositional seman- tics. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Hu- man Language Technologies, pages 590-599, Port- land, Oregon, USA, June. Association for Computa- tional Linguistics.\n\nThe Stanford CoreNLP natural language processing toolkit. Christopher D Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J Bethard, David Mc-Closky, Proc. of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations. of 52nd Annual Meeting of the Association for Computational Linguistics: System DemonstrationsChristopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David Mc- Closky. 2014. The Stanford CoreNLP natural lan- guage processing toolkit. In Proc. of 52nd Annual Meeting of the Association for Computational Lin- guistics: System Demonstrations.\n\nReport on a general problem-solving program. Allen Newell, John C Shaw, Herbert A Simon, IFIP Congress. 25664Allen Newell, John C. Shaw, and Herbert A. Simon. 1959. Report on a general problem-solving pro- gram. In IFIP Congress, volume 256, page 64.\n\nSolving general arithmetic word problems. Subhro Roy, Dan Roth, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational LinguisticsSubhro Roy and Dan Roth. 2015. Solving general arithmetic word problems. In Proceedings of the 2015 Conference on Empirical Methods in Natu- ral Language Processing, pages 1743-1752, Lisbon, Portugal, September. Association for Computational Linguistics.\n\nAutomatically solving number word problems by semantic parsing and reasoning. Shuming Shi, Yuehui Wang, Chin-Yew Lin, Xiaojiang Liu, Yong Rui, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational LinguisticsShuming Shi, Yuehui Wang, Chin-Yew Lin, Xiaojiang Liu, and Yong Rui. 2015. Automatically solving number word problems by semantic parsing and rea- soning. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Process- ing, pages 1132-1142, Lisbon, Portugal, September. Association for Computational Linguistics.\n\nLearning from Explicit and Implicit Supervision Jointly For Algebra Word Problems. Shyam Upadhyay, Ming-Wei Chang, Kai-Wei Chang, Wen-Tau Yih, Proceedings of EMNLP. EMNLPShyam Upadhyay, Ming-Wei Chang, Kai-Wei Chang, and Wen-tau Yih. 2016. Learning from Explicit and Implicit Supervision Jointly For Algebra Word Problems. In Proceedings of EMNLP, pages 297- 306.\n\nLearning synchronous grammars for semantic parsing with lambda calculus. Yuk Wah Wong, Raymond Mooney, Proceedings of the 45th. the 45thYuk Wah Wong and Raymond Mooney. 2007. Learn- ing synchronous grammars for semantic parsing with lambda calculus. In Proceedings of the 45th\n\nAnnual Meeting of the Association of Computational Linguistics. Prague, Czech RepublicAssociation for Computational LinguisticsAnnual Meeting of the Association of Computational Linguistics, pages 960-967, Prague, Czech Repub- lic, June. Association for Computational Linguis- tics.\n\nThe value of semantic parse labeling for knowledge base question answering. Matthew Wen-Tau Yih, Chris Richardson, Ming-Wei Meek, Jina Chang, Suh, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyShort Papers2Association for Computational LinguisticsWen-tau Yih, Matthew Richardson, Chris Meek, Ming- Wei Chang, and Jina Suh. 2016. The value of semantic parse labeling for knowledge base ques- tion answering. In Proceedings of the 54th Annual Meeting of the Association for Computational Lin- guistics (Volume 2: Short Papers), pages 201-206, Berlin, Germany, August. Association for Computa- tional Linguistics.\n\nLearning to Parse Database Queries using Inductive Logic Proramming. J M Zelle, R J Mooney, AAAI. J. M. Zelle and R. J. Mooney. 1996. Learning to Parse Database Queries using Inductive Logic Pro- ramming. In AAAI.\n\nLearning to map sentences to logical form: Structured classification with probabilistic categorial grammars. Luke S Zettlemoyer, Michael Collins, UAI '05, Proceedings of the 21st Conference in Uncertainty in Artificial Intelligence. ScotlandLuke S. Zettlemoyer and Michael Collins. 2005. Learning to map sentences to logical form: Struc- tured classification with probabilistic categorial grammars. In UAI '05, Proceedings of the 21st Con- ference in Uncertainty in Artificial Intelligence, Ed- inburgh, Scotland, July 26-29, 2005, pages 658-666.\n\nLearn to solve algebra word problems using quadratic programming. Lipu Zhou, Shuaixiang Dai, Liwei Chen, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational LinguisticsLipu Zhou, Shuaixiang Dai, and Liwei Chen. 2015. Learn to solve algebra word problems using quadratic programming. In Proceedings of the 2015 Conference on Empirical Methods in Natural Lan- guage Processing, pages 817-822, Lisbon, Portugal, September. Association for Computational Linguis- tics.\n", "annotations": {"author": "[{\"end\":291,\"start\":204},{\"end\":363,\"start\":292}]", "publisher": "[{\"end\":130,\"start\":89},{\"end\":598,\"start\":557}]", "author_last_name": "[{\"end\":218,\"start\":210},{\"end\":306,\"start\":301}]", "author_first_name": "[{\"end\":209,\"start\":204},{\"end\":300,\"start\":292}]", "author_affiliation": "[{\"end\":290,\"start\":242},{\"end\":362,\"start\":331}]", "title": "[{\"end\":88,\"start\":1},{\"end\":451,\"start\":364}]", "venue": "[{\"end\":498,\"start\":453}]", "abstract": "[{\"end\":1479,\"start\":621}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b14\"},\"end\":1591,\"start\":1570},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1604,\"start\":1591},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":1635,\"start\":1618},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":1666,\"start\":1635},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":1915,\"start\":1896},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2139,\"start\":2114},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3794,\"start\":3772},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3811,\"start\":3794},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3842,\"start\":3811},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3860,\"start\":3842},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3879,\"start\":3860},{\"end\":4215,\"start\":4214},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8611,\"start\":8589},{\"end\":11858,\"start\":11857},{\"end\":14411,\"start\":14410},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":16031,\"start\":16013},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16050,\"start\":16031},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":17318,\"start\":17300},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18301,\"start\":18284},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":18994,\"start\":18976},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":19625,\"start\":19606},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":19828,\"start\":19813},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":20831,\"start\":20813},{\"end\":23937,\"start\":23936},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":25363,\"start\":25345},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":25385,\"start\":25368},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":28890,\"start\":28872},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":29096,\"start\":29073},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29113,\"start\":29096},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":29144,\"start\":29113},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":29945,\"start\":29927},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":30361,\"start\":30342},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":30386,\"start\":30366},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":30472,\"start\":30448},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":30502,\"start\":30472},{\"end\":30536,\"start\":30502},{\"end\":30599,\"start\":30572},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":30974,\"start\":30952},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":31365,\"start\":31341},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":31385,\"start\":31365},{\"end\":31416,\"start\":31385},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":33607,\"start\":33587},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":33955,\"start\":33923}]", "figure": "[{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":35775,\"start\":35599},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":36159,\"start\":35776},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":36391,\"start\":36160},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":36668,\"start\":36392},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":37058,\"start\":36669},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":37256,\"start\":37059}]", "paragraph": "[{\"end\":2140,\"start\":1495},{\"end\":2321,\"start\":2150},{\"end\":2350,\"start\":2323},{\"end\":2621,\"start\":2390},{\"end\":2871,\"start\":2623},{\"end\":3317,\"start\":2873},{\"end\":5049,\"start\":3319},{\"end\":5397,\"start\":5051},{\"end\":5670,\"start\":5399},{\"end\":6315,\"start\":5672},{\"end\":6650,\"start\":6487},{\"end\":6851,\"start\":6677},{\"end\":7446,\"start\":6879},{\"end\":7793,\"start\":7448},{\"end\":8177,\"start\":7795},{\"end\":8640,\"start\":8179},{\"end\":8822,\"start\":8667},{\"end\":9147,\"start\":8824},{\"end\":9987,\"start\":9198},{\"end\":10031,\"start\":9989},{\"end\":10042,\"start\":10033},{\"end\":10109,\"start\":10044},{\"end\":10146,\"start\":10111},{\"end\":10286,\"start\":10148},{\"end\":10381,\"start\":10357},{\"end\":10407,\"start\":10383},{\"end\":10680,\"start\":10460},{\"end\":10863,\"start\":10682},{\"end\":11196,\"start\":10888},{\"end\":12013,\"start\":11198},{\"end\":12287,\"start\":12039},{\"end\":12676,\"start\":12289},{\"end\":12924,\"start\":12678},{\"end\":13057,\"start\":12926},{\"end\":13541,\"start\":13059},{\"end\":13719,\"start\":13543},{\"end\":14091,\"start\":13746},{\"end\":14790,\"start\":14093},{\"end\":15228,\"start\":14792},{\"end\":15906,\"start\":15230},{\"end\":16835,\"start\":15908},{\"end\":17027,\"start\":16858},{\"end\":17231,\"start\":17039},{\"end\":17547,\"start\":17233},{\"end\":17815,\"start\":17549},{\"end\":18013,\"start\":17817},{\"end\":18100,\"start\":18028},{\"end\":18302,\"start\":18122},{\"end\":18893,\"start\":18324},{\"end\":20005,\"start\":18908},{\"end\":20312,\"start\":20035},{\"end\":20464,\"start\":20335},{\"end\":20936,\"start\":20480},{\"end\":21000,\"start\":20938},{\"end\":21553,\"start\":21002},{\"end\":21714,\"start\":21570},{\"end\":22465,\"start\":21716},{\"end\":22912,\"start\":22467},{\"end\":23346,\"start\":22946},{\"end\":24275,\"start\":23348},{\"end\":24544,\"start\":24277},{\"end\":24731,\"start\":24556},{\"end\":25065,\"start\":24773},{\"end\":25568,\"start\":25067},{\"end\":25720,\"start\":25583},{\"end\":25955,\"start\":25722},{\"end\":26092,\"start\":25957},{\"end\":26407,\"start\":26094},{\"end\":26633,\"start\":26409},{\"end\":26798,\"start\":26635},{\"end\":26924,\"start\":26800},{\"end\":27154,\"start\":26966},{\"end\":27250,\"start\":27156},{\"end\":27269,\"start\":27252},{\"end\":27566,\"start\":27271},{\"end\":27748,\"start\":27568},{\"end\":27840,\"start\":27785},{\"end\":27846,\"start\":27842},{\"end\":27928,\"start\":27848},{\"end\":28080,\"start\":27930},{\"end\":28150,\"start\":28082},{\"end\":28290,\"start\":28152},{\"end\":28574,\"start\":28292},{\"end\":28686,\"start\":28591},{\"end\":29436,\"start\":28688},{\"end\":29738,\"start\":29438},{\"end\":30158,\"start\":29740},{\"end\":31204,\"start\":30160},{\"end\":32233,\"start\":31206},{\"end\":33026,\"start\":32263},{\"end\":33447,\"start\":33028},{\"end\":33956,\"start\":33449},{\"end\":34094,\"start\":33958},{\"end\":34192,\"start\":34096},{\"end\":34776,\"start\":34194},{\"end\":35034,\"start\":34778},{\"end\":35137,\"start\":35036},{\"end\":35598,\"start\":35139}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":6486,\"start\":6316},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9197,\"start\":9148},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10356,\"start\":10287},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10453,\"start\":10408}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":6906,\"start\":6899},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":14789,\"start\":14782},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":14979,\"start\":14972},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":16519,\"start\":16510},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":16636,\"start\":16629},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":16967,\"start\":16960},{\"end\":19271,\"start\":19264},{\"end\":21614,\"start\":21607},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":22342,\"start\":22334},{\"end\":23565,\"start\":23555},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":23684,\"start\":23677},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":23901,\"start\":23894},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":23948,\"start\":23941},{\"end\":23976,\"start\":23969},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":25077,\"start\":25070}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1493,\"start\":1481},{\"end\":2148,\"start\":2143},{\"end\":2388,\"start\":2353},{\"attributes\":{\"n\":\"2\"},\"end\":6675,\"start\":6653},{\"end\":6877,\"start\":6854},{\"end\":8665,\"start\":8643},{\"end\":10458,\"start\":10455},{\"end\":10886,\"start\":10866},{\"end\":12037,\"start\":12016},{\"attributes\":{\"n\":\"3\"},\"end\":13744,\"start\":13722},{\"attributes\":{\"n\":\"4\"},\"end\":16856,\"start\":16838},{\"end\":17037,\"start\":17030},{\"attributes\":{\"n\":\"4.1\"},\"end\":18026,\"start\":18016},{\"end\":18120,\"start\":18103},{\"end\":18322,\"start\":18305},{\"attributes\":{\"n\":\"4.2\"},\"end\":18906,\"start\":18896},{\"end\":20033,\"start\":20008},{\"end\":20333,\"start\":20315},{\"attributes\":{\"n\":\"5\"},\"end\":20478,\"start\":20467},{\"attributes\":{\"n\":\"5.1\"},\"end\":21568,\"start\":21556},{\"end\":22944,\"start\":22915},{\"end\":24554,\"start\":24547},{\"attributes\":{\"n\":\"5.2\"},\"end\":24771,\"start\":24754},{\"attributes\":{\"n\":\"5.3\"},\"end\":25581,\"start\":25571},{\"end\":26964,\"start\":26927},{\"end\":27783,\"start\":27751},{\"attributes\":{\"n\":\"6\"},\"end\":28589,\"start\":28577},{\"attributes\":{\"n\":\"7\"},\"end\":32261,\"start\":32236},{\"end\":35609,\"start\":35600},{\"end\":36170,\"start\":36161},{\"end\":36679,\"start\":36670},{\"end\":37069,\"start\":37060}]", "table": "[{\"end\":36159,\"start\":35865},{\"end\":36391,\"start\":36172},{\"end\":36668,\"start\":36433},{\"end\":37058,\"start\":36971},{\"end\":37256,\"start\":37071}]", "figure_caption": "[{\"end\":35775,\"start\":35611},{\"end\":35865,\"start\":35778},{\"end\":36433,\"start\":36394},{\"end\":36971,\"start\":36681}]", "figure_ref": "[{\"end\":1761,\"start\":1753},{\"end\":2798,\"start\":2790},{\"end\":4543,\"start\":4535},{\"end\":7885,\"start\":7877},{\"end\":14615,\"start\":14607}]", "bib_author_first_name": "[{\"end\":39278,\"start\":39270},{\"end\":39293,\"start\":39287},{\"end\":39303,\"start\":39300},{\"end\":39318,\"start\":39313},{\"end\":39945,\"start\":39944},{\"end\":40330,\"start\":40325},{\"end\":40342,\"start\":40338},{\"end\":40585,\"start\":40580},{\"end\":40597,\"start\":40594},{\"end\":40618,\"start\":40610},{\"end\":40629,\"start\":40626},{\"end\":40634,\"start\":40630},{\"end\":41252,\"start\":41245},{\"end\":41835,\"start\":41821},{\"end\":41854,\"start\":41846},{\"end\":41871,\"start\":41867},{\"end\":41885,\"start\":41881},{\"end\":42574,\"start\":42567},{\"end\":42589,\"start\":42582},{\"end\":42603,\"start\":42595},{\"end\":42613,\"start\":42609},{\"end\":42627,\"start\":42619},{\"end\":43310,\"start\":43308},{\"end\":43321,\"start\":43317},{\"end\":43341,\"start\":43335},{\"end\":43343,\"start\":43342},{\"end\":43806,\"start\":43803},{\"end\":43834,\"start\":43826},{\"end\":43853,\"start\":43847},{\"end\":43869,\"start\":43865},{\"end\":43884,\"start\":43879},{\"end\":44216,\"start\":44213},{\"end\":44242,\"start\":44236},{\"end\":44252,\"start\":44248},{\"end\":44264,\"start\":44260},{\"end\":44282,\"start\":44274},{\"end\":45059,\"start\":45055},{\"end\":45073,\"start\":45069},{\"end\":45085,\"start\":45081},{\"end\":45105,\"start\":45099},{\"end\":45730,\"start\":45725},{\"end\":45745,\"start\":45738},{\"end\":45757,\"start\":45754},{\"end\":46560,\"start\":46555},{\"end\":46575,\"start\":46568},{\"end\":46587,\"start\":46584},{\"end\":47263,\"start\":47252},{\"end\":47265,\"start\":47264},{\"end\":47280,\"start\":47275},{\"end\":47295,\"start\":47291},{\"end\":47308,\"start\":47303},{\"end\":47323,\"start\":47317},{\"end\":47325,\"start\":47324},{\"end\":47340,\"start\":47335},{\"end\":47879,\"start\":47874},{\"end\":47892,\"start\":47888},{\"end\":47894,\"start\":47893},{\"end\":47908,\"start\":47901},{\"end\":47910,\"start\":47909},{\"end\":48129,\"start\":48123},{\"end\":48138,\"start\":48135},{\"end\":48702,\"start\":48695},{\"end\":48714,\"start\":48708},{\"end\":48729,\"start\":48721},{\"end\":48744,\"start\":48735},{\"end\":48754,\"start\":48750},{\"end\":49402,\"start\":49397},{\"end\":49421,\"start\":49413},{\"end\":49436,\"start\":49429},{\"end\":49451,\"start\":49444},{\"end\":49755,\"start\":49752},{\"end\":49759,\"start\":49756},{\"end\":49773,\"start\":49766},{\"end\":50324,\"start\":50317},{\"end\":50343,\"start\":50338},{\"end\":50364,\"start\":50356},{\"end\":50375,\"start\":50371},{\"end\":51053,\"start\":51052},{\"end\":51055,\"start\":51054},{\"end\":51064,\"start\":51063},{\"end\":51066,\"start\":51065},{\"end\":51311,\"start\":51307},{\"end\":51313,\"start\":51312},{\"end\":51334,\"start\":51327},{\"end\":51816,\"start\":51812},{\"end\":51833,\"start\":51823},{\"end\":51844,\"start\":51839}]", "bib_author_last_name": "[{\"end\":39285,\"start\":39279},{\"end\":39298,\"start\":39294},{\"end\":39311,\"start\":39304},{\"end\":39324,\"start\":39319},{\"end\":39952,\"start\":39946},{\"end\":39960,\"start\":39954},{\"end\":40336,\"start\":40331},{\"end\":40350,\"start\":40343},{\"end\":40592,\"start\":40586},{\"end\":40608,\"start\":40598},{\"end\":40624,\"start\":40619},{\"end\":41260,\"start\":41253},{\"end\":41844,\"start\":41836},{\"end\":41865,\"start\":41855},{\"end\":41879,\"start\":41872},{\"end\":41893,\"start\":41886},{\"end\":42580,\"start\":42575},{\"end\":42593,\"start\":42590},{\"end\":42607,\"start\":42604},{\"end\":42617,\"start\":42614},{\"end\":42630,\"start\":42628},{\"end\":43315,\"start\":43311},{\"end\":43333,\"start\":43322},{\"end\":43351,\"start\":43344},{\"end\":43824,\"start\":43807},{\"end\":43845,\"start\":43835},{\"end\":43863,\"start\":43854},{\"end\":43877,\"start\":43870},{\"end\":43888,\"start\":43885},{\"end\":44234,\"start\":44217},{\"end\":44246,\"start\":44243},{\"end\":44258,\"start\":44253},{\"end\":44272,\"start\":44265},{\"end\":44293,\"start\":44283},{\"end\":45067,\"start\":45060},{\"end\":45079,\"start\":45074},{\"end\":45097,\"start\":45086},{\"end\":45114,\"start\":45106},{\"end\":45736,\"start\":45731},{\"end\":45752,\"start\":45746},{\"end\":45763,\"start\":45758},{\"end\":46566,\"start\":46561},{\"end\":46582,\"start\":46576},{\"end\":46593,\"start\":46588},{\"end\":47273,\"start\":47266},{\"end\":47289,\"start\":47281},{\"end\":47301,\"start\":47296},{\"end\":47315,\"start\":47309},{\"end\":47333,\"start\":47326},{\"end\":47350,\"start\":47341},{\"end\":47886,\"start\":47880},{\"end\":47899,\"start\":47895},{\"end\":47916,\"start\":47911},{\"end\":48133,\"start\":48130},{\"end\":48143,\"start\":48139},{\"end\":48706,\"start\":48703},{\"end\":48719,\"start\":48715},{\"end\":48733,\"start\":48730},{\"end\":48748,\"start\":48745},{\"end\":48758,\"start\":48755},{\"end\":49411,\"start\":49403},{\"end\":49427,\"start\":49422},{\"end\":49442,\"start\":49437},{\"end\":49455,\"start\":49452},{\"end\":49764,\"start\":49760},{\"end\":49780,\"start\":49774},{\"end\":50336,\"start\":50325},{\"end\":50354,\"start\":50344},{\"end\":50369,\"start\":50365},{\"end\":50381,\"start\":50376},{\"end\":50386,\"start\":50383},{\"end\":51061,\"start\":51056},{\"end\":51073,\"start\":51067},{\"end\":51325,\"start\":51314},{\"end\":51342,\"start\":51335},{\"end\":51821,\"start\":51817},{\"end\":51837,\"start\":51834},{\"end\":51849,\"start\":51845}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":6401679},\"end\":39875,\"start\":39213},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":14485675},\"end\":40225,\"start\":39877},{\"attributes\":{\"id\":\"b2\"},\"end\":40526,\"start\":40227},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":5667590},\"end\":41134,\"start\":40528},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":10888973},\"end\":41750,\"start\":41136},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":428579},\"end\":42468,\"start\":41752},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":524450},\"end\":43224,\"start\":42470},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":1845555},\"end\":43753,\"start\":43226},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":4894130},\"end\":44172,\"start\":43755},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":2228719},\"end\":44998,\"start\":44174},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":12451537},\"end\":45666,\"start\":45000},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":238873},\"end\":46502,\"start\":45668},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":340852},\"end\":47192,\"start\":46504},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":14068874},\"end\":47827,\"start\":47194},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":35199622},\"end\":48079,\"start\":47829},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":560565},\"end\":48615,\"start\":48081},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":15717845},\"end\":49312,\"start\":48617},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":18796557},\"end\":49677,\"start\":49314},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":9337134},\"end\":49955,\"start\":49679},{\"attributes\":{\"id\":\"b19\"},\"end\":50239,\"start\":49957},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":13905064},\"end\":50981,\"start\":50241},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":263135},\"end\":51196,\"start\":50983},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":449252},\"end\":51744,\"start\":51198},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":14407737},\"end\":52363,\"start\":51746}]", "bib_title": "[{\"end\":39268,\"start\":39213},{\"end\":39942,\"start\":39877},{\"end\":40578,\"start\":40528},{\"end\":41243,\"start\":41136},{\"end\":41819,\"start\":41752},{\"end\":42565,\"start\":42470},{\"end\":43306,\"start\":43226},{\"end\":43801,\"start\":43755},{\"end\":44211,\"start\":44174},{\"end\":45053,\"start\":45000},{\"end\":45723,\"start\":45668},{\"end\":46553,\"start\":46504},{\"end\":47250,\"start\":47194},{\"end\":47872,\"start\":47829},{\"end\":48121,\"start\":48081},{\"end\":48693,\"start\":48617},{\"end\":49395,\"start\":49314},{\"end\":49750,\"start\":49679},{\"end\":50315,\"start\":50241},{\"end\":51050,\"start\":50983},{\"end\":51305,\"start\":51198},{\"end\":51810,\"start\":51746}]", "bib_author": "[{\"end\":39287,\"start\":39270},{\"end\":39300,\"start\":39287},{\"end\":39313,\"start\":39300},{\"end\":39326,\"start\":39313},{\"end\":39954,\"start\":39944},{\"end\":39962,\"start\":39954},{\"end\":40338,\"start\":40325},{\"end\":40352,\"start\":40338},{\"end\":40594,\"start\":40580},{\"end\":40610,\"start\":40594},{\"end\":40626,\"start\":40610},{\"end\":40637,\"start\":40626},{\"end\":41262,\"start\":41245},{\"end\":41846,\"start\":41821},{\"end\":41867,\"start\":41846},{\"end\":41881,\"start\":41867},{\"end\":41895,\"start\":41881},{\"end\":42582,\"start\":42567},{\"end\":42595,\"start\":42582},{\"end\":42609,\"start\":42595},{\"end\":42619,\"start\":42609},{\"end\":42632,\"start\":42619},{\"end\":43317,\"start\":43308},{\"end\":43335,\"start\":43317},{\"end\":43355,\"start\":43335},{\"end\":43826,\"start\":43803},{\"end\":43847,\"start\":43826},{\"end\":43865,\"start\":43847},{\"end\":43879,\"start\":43865},{\"end\":43890,\"start\":43879},{\"end\":44236,\"start\":44213},{\"end\":44248,\"start\":44236},{\"end\":44260,\"start\":44248},{\"end\":44274,\"start\":44260},{\"end\":44295,\"start\":44274},{\"end\":45069,\"start\":45055},{\"end\":45081,\"start\":45069},{\"end\":45099,\"start\":45081},{\"end\":45116,\"start\":45099},{\"end\":45738,\"start\":45725},{\"end\":45754,\"start\":45738},{\"end\":45765,\"start\":45754},{\"end\":46568,\"start\":46555},{\"end\":46584,\"start\":46568},{\"end\":46595,\"start\":46584},{\"end\":47275,\"start\":47252},{\"end\":47291,\"start\":47275},{\"end\":47303,\"start\":47291},{\"end\":47317,\"start\":47303},{\"end\":47335,\"start\":47317},{\"end\":47352,\"start\":47335},{\"end\":47888,\"start\":47874},{\"end\":47901,\"start\":47888},{\"end\":47918,\"start\":47901},{\"end\":48135,\"start\":48123},{\"end\":48145,\"start\":48135},{\"end\":48708,\"start\":48695},{\"end\":48721,\"start\":48708},{\"end\":48735,\"start\":48721},{\"end\":48750,\"start\":48735},{\"end\":48760,\"start\":48750},{\"end\":49413,\"start\":49397},{\"end\":49429,\"start\":49413},{\"end\":49444,\"start\":49429},{\"end\":49457,\"start\":49444},{\"end\":49766,\"start\":49752},{\"end\":49782,\"start\":49766},{\"end\":50338,\"start\":50317},{\"end\":50356,\"start\":50338},{\"end\":50371,\"start\":50356},{\"end\":50383,\"start\":50371},{\"end\":50388,\"start\":50383},{\"end\":51063,\"start\":51052},{\"end\":51075,\"start\":51063},{\"end\":51327,\"start\":51307},{\"end\":51344,\"start\":51327},{\"end\":51823,\"start\":51812},{\"end\":51839,\"start\":51823},{\"end\":51851,\"start\":51839}]", "bib_venue": "[{\"end\":39509,\"start\":39414},{\"end\":39985,\"start\":39982},{\"end\":40805,\"start\":40722},{\"end\":41421,\"start\":41350},{\"end\":42090,\"start\":41991},{\"end\":42808,\"start\":42721},{\"end\":43500,\"start\":43436},{\"end\":44587,\"start\":44439},{\"end\":45296,\"start\":45205},{\"end\":46072,\"start\":45927},{\"end\":46825,\"start\":46713},{\"end\":47548,\"start\":47454},{\"end\":48320,\"start\":48233},{\"end\":48935,\"start\":48848},{\"end\":49484,\"start\":49479},{\"end\":49815,\"start\":49807},{\"end\":50043,\"start\":50021},{\"end\":50564,\"start\":50477},{\"end\":51439,\"start\":51431},{\"end\":52026,\"start\":51939},{\"end\":39412,\"start\":39326},{\"end\":39980,\"start\":39962},{\"end\":40323,\"start\":40227},{\"end\":40720,\"start\":40637},{\"end\":41348,\"start\":41262},{\"end\":41989,\"start\":41895},{\"end\":42719,\"start\":42632},{\"end\":43434,\"start\":43355},{\"end\":43951,\"start\":43890},{\"end\":44437,\"start\":44295},{\"end\":45203,\"start\":45116},{\"end\":45925,\"start\":45765},{\"end\":46711,\"start\":46595},{\"end\":47452,\"start\":47352},{\"end\":47931,\"start\":47918},{\"end\":48231,\"start\":48145},{\"end\":48846,\"start\":48760},{\"end\":49477,\"start\":49457},{\"end\":49805,\"start\":49782},{\"end\":50019,\"start\":49957},{\"end\":50475,\"start\":50388},{\"end\":51079,\"start\":51075},{\"end\":51429,\"start\":51344},{\"end\":51937,\"start\":51851}]"}}}, "year": 2023, "month": 12, "day": 17}