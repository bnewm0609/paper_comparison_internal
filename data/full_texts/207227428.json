{"id": 207227428, "updated": "2022-02-02 21:11:40.942", "metadata": {"title": "Generic and Scalable Framework for Automated Time-series Anomaly Detection", "authors": "[{\"middle\":[],\"last\":\"Laptev\",\"first\":\"Nikolay\"},{\"middle\":[],\"last\":\"Amizadeh\",\"first\":\"Saeed\"},{\"middle\":[],\"last\":\"Flint\",\"first\":\"Ian\"}]", "venue": null, "journal": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "publication_date": {"year": 2015, "month": null, "day": null}, "abstract": "This paper introduces a generic and scalable framework for automated anomaly detection on large scale time-series data. Early detection of anomalies plays a key role in maintaining consistency of person's data and protects corporations against malicious attackers. Current state of the art anomaly detection approaches suffer from scalability, use-case restrictions, difficulty of use and a large number of false positives. Our system at Yahoo, EGADS, uses a collection of anomaly detection and forecasting models with an anomaly filtering layer for accurate and scalable anomaly detection on time-series. We compare our approach against other anomaly detection systems on real and synthetic data with varying time-series characteristics. We found that our framework allows for 50-60% improvement in precision and recall for a variety of use-cases. Both the data and the framework are being open-sourced. The open-sourcing of the data, in particular, represents the first of its kind effort to establish the standard benchmark for anomaly detection.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2093606067", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/kdd/LaptevAF15", "doi": "10.1145/2783258.2788611"}}, "content": {"source": {"pdf_hash": "c66689fafa0ce5d6d85ac8b361068de31c623516", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "68e5bd8decc501fd28fa84df3ba9fa42dbc3d680", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c66689fafa0ce5d6d85ac8b361068de31c623516.txt", "contents": "\nGeneric and Scalable Framework for Automated Time-series Anomaly Detection\n\n\nNikolay Laptev nlaptev@yahoo-inc.com \nSaeed Amizadeh amizadeh@yahoo-inc.com \nIan Flint Yahoo \n\nYahoo Labs Sunnyvale\nCAUSA\n\n\nYahoo Labs Sunnyvale\nSunnyvaleCA, CAUSA, USA\n\nGeneric and Scalable Framework for Automated Time-series Anomaly Detection\n10.1145/2783258.2788611\nThis paper introduces a generic and scalable framework for automated anomaly detection on large scale time-series data. Early detection of anomalies plays a key role in maintaining consistency of person's data and protects corporations against malicious attackers. Current state of the art anomaly detection approaches suffer from scalability, use-case restrictions, difficulty of use and a large number of false positives. Our system at Yahoo, EGADS, uses a collection of anomaly detection and forecasting models with an anomaly filtering layer for accurate and scalable anomaly detection on timeseries. We compare our approach against other anomaly detection systems on real and synthetic data with varying time-series characteristics. We found that our framework allows for 50-60% improvement in precision and recall for a variety of use-cases. Both the data and the framework are being open-sourced. The open-sourcing of the data, in particular, represents the first of its kind effort to establish the standard benchmark for anomaly detection.\n\nINTRODUCTION\n\nWhile rapid advances in computing hardware and software have led to powerful applications, still hundreds of software bugs and hardware failures continue to happen in a large cluster compromising user experience and subsequently revenue. Non-stop systems have a strict uptime requirement and continuous monitoring of these systems is critical. From the data analysis point of view, this means non-stop monitoring of large volume of time-series data in order to detect potential faults or anomalies. Due to the large scale of the problem, human monitoring of this data is practically infeasible which leads us to automated anomaly detection using Machine Learning and Data Mining techniques.\n\nAn anomaly, or an outlier, is a data point which is significantly different from the rest of the data. Generally, the data in most applications is created by one or more generating processes that reflect the functionality of a system. When the underlying generating process behaves in an un-Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Permissions@acm.org.  usual way, it creates outliers. Fast and efficient identification of these outliers is useful for many applications including: intrusion detection, credit card fraud, sensor events, medical diagnoses, law enforcement and others [1].\n\nCurrent approaches in automated anomaly detection suffer from a large number of false positives which prohibit the usefulness of these systems in practice. Use-case, or category specific, anomaly detection models [4] may enjoy a low false positive rate for a specific application, but when the characteristics of the time-series change, these techniques perform poorly without proper retraining. Section 6.3 demonstrates the shortcoming of 'one size fits all' principle in practice.\n\nOur system at Yahoo is called EGADS (Extensible Generic Anomaly Detection System) and it enables the accurate and scalable detection of time-series anomalies. EGADS separates forecasting, anomaly detection and alerting into three separate components which allows the person to add her own models into any of the components. Note that this paper focuses on the latter two components.\n\nEGADS uses a set of default models that are tuned to reduce the number of false positives, which by itself suffices for the average user. More advanced use-cases, however, will require the system to capture some types of anomalies while ignoring others. The anomalies of interest may vary in magnitude, severity or other parameters which are unknown apriori and depend on the use-case. For this reason the alerting component of EGADS uses machine learning to select the most relevant anomalies for the consumer.\n\nTo the best of our knowledge EGADS is the first comprehensive system for anomaly detection that is flexible, accurate, scalable and extensible. EGADS is being open-sourced [19] along with the anomaly detection benchmarking data [18]. The open-sourcing of the data and the system will provide the first of its kind benchmarking data and the framework to help the academics and the industry collaborate and develop novel anomaly detection models. At Yahoo, EGADS is used on millions of time-series by many teams daily.\n\nIn Section 2 we describe the EGADS architecture. The algorithms and the alerting module are described in Sections 3 and 4 respectively. Previous work is described in Section 5. Experiments are discussed in Section 6 followed by the real-world use-cases and conclusion in Sections 7 and 8 respectively.\n\n\nARCHITECTURE\n\nThe EGADS framework consists of three main components: the time-series modeling module (TMM), the anomaly detection module (ADM) and the alerting module (AM).\n\nGiven a time-series the TMM component models the timeseries producing an expected value later consumed by the ADM and AM components that, respectively, compute the error and filter uninteresting anomalies. These components are described in detail in Sections 3 and 4.\n\nEGADS was built as a framework to be easily integrated into an existing monitoring infrastructure. At Yahoo, our internal Yahoo Monitoring Service (YMS) processes millions of data-points every second. Therefore, having a scalable, accurate and automated anomaly detection for YMS is critical. We describe the integration details into YMS next.\n\n\nSystem Integration\n\nEGADS operates as a stand-alone platform that can be used as a library in larger systems. Therefore, designing an interface between EGADS and an internal Yahoo monitoring service (YMS) is critical. A key constraint of YMS is scale; the platform needs to evaluate millions of data points per second. As a result, many of the integration architecture decisions are focused on optimizing real-time processing. The integration with YMS is shown in Figure 1. Several support components are required to drive action based on detected anomalies. First of all, all anomaly detection models are generated in batch and applied in real time. The batch flow is comprised of three steps:\n\n1. Telemetry (i.e. the monitored time-series) data are stored in bulk on a Hadoop cluster.\n\n2. A batch model generator runs against these data and builds models for targeted time-series.\n\n3. The models are stored in a model database.\n\nThe online flow then utilizes the stored models.\n\n1. Data flows into a Storm [25] stream-processing topology.\n\n2. One of the bolts (modules) in the topology calls the EGADS ADM to evaluate incoming data points based on models stored in the model database.\n\n3. If an anomaly is present, this is fed to a secondary rule flow, consisting of combinatorial rules and other use-case specific logic (see Section 4).\n\n4. Based on the rules, if the anomaly is an alert event, the event is generated, stored in a status database, and forwarded to an alert routing system. 5. The alert routing system applies routing configuration rules to send the alert to the appropriate support staff.\n\n\nScalability\n\nThe monitoring use case for EGADS requires the evaluation of millions of data-points per second, across over one hundred million time-series. This has scalability implications in terms of CPU load, I/O, and memory footprint. The evaluation of a datapoint needs to be as efficient as possible. This means that as much of the model as possible should be precomputed. It is not practical to read a model from disk each time a datapoint arrives because of the rate of inbound traffic. This suggests that the models should be stored in memory. In order to contain costs, the models should be as small as possible.\n\nOne optimization is to share models across multiple similar time-series. This is practical in the context of a large web serving environment, since applications are broken into horizontal tiers of similar servers. This optimization will reduce the memory footprint, the batch workload, and I/O against the model database.\n\nAnother possible optimization is to investigate self-tuning models; models that update themselves based on a stream of inbound data via online learning rather than requiring periodic batch generation. Models of this type may need to be initialized in batch, but overall they will reduce the batch workload. Depending on implementation, however, they may increase writes against the model database since they are being constantly refined.\n\nYet another optimization involves a trade-off between model size, training speed and accuracy. Depending on the characteristics of the time-series a light and fast forecasting model can provide similar accuracy as a more sophisticated one. We evaluate some of these optimization approaches in Section 6.2.2.\n\n\nANOMALY DETECTION ALGORITHMS\n\nIn this section, we give a big picture overview of the anomaly detection algorithms supported by EGADS. Currently, EGADS is capable of detecting three classes of anomalies:\n\n(a) Outliers: given an input time-series x, an outlier is a timestamp-value pair t, xt where the observed value xt is significantly different from the expected value of the time-series at that time, i.e. E(xt).\n\n(b) Change points: given an input time-series x, a change point is a timestamp t such that the behavior of the time-series is significantly different before and after t.\n\n(c) Anomalous time-series: given a set of time-series X = {x (i) }, an anomalous time-series x (j) \u2208 X is a time-series whose behavior is significantly different from the majority of the time-series in X.\n\nIn the following sections, we give the general sketch of the methods that are currently used in EGADS for detecting the aforementioned anomaly types.\n\n\nOutlier Detection\n\nDetecting outliers is the most important functionality in many monitoring applications. For this reason the main focus of this paper is on outlier detection and unless it is explicitly specified, by anomalies, we refer to outliers by default.\n\nEGADS offers two classes of algorithms for detecting outliers, which are described in this section.\n\n\nPlug-in methods\n\nThe first class of methods for time-series outlier detection in EGADS are called plug-in methods. These methods explicitly model the normal behavior of the time-series such that a significant deviation from this model is considered an outlier. To model the normal behavior of the input time-series we can plug-in a wide range of time-series modeling and forecasting models (e.g. ARIMA [30], Exponential Smoothing [11], Kalman Filter [9], State Space Models [6], etc.) depending on the application and the nature of timeseries. That is why we refer to this general strategy as the plug-in methods. It should be noted that all these models are used in EGADS for time-series forecasting which is another feature of our framework; however, since the focus of this paper is on anomaly detection, we do not give more details on modeling and forecasting features of EGADS.\n\nOur proposed Plug-in framework consists of two main components: the time-series modeling module (TMM) and the anomaly detection module (ADM). Given a time-series X = {xt \u2208 R : \u2200t \u2265 0}, the TMM provides the predicted value of xt at time t, denoted by ut. We also refer to this quantity as the expected value of xt (not to be confused with the mathematical notion of expectation). The TMM can be a machine learned model which makes predictions based on some training data or a rule-based system which encodes expert's knowledge about how xt behaves at time t. In this paper, we do not make any assumption regarding the TMM; that is, the TMM is just a black box module in our proposed method that generates predictions ut. In this sense, our proposed framework is generic and does not depend on any specific time-series modeling framework.\n\nGiven the predicted value ut and the actual observed value xt, the ADM computes some notion of deviation which we refer to as the deviation metric (DM). The simplest measure of deviation is the prediction error, P Et = xt \u2212 ut. If the error falls outside some fixed thresholds, an alert is issued. This simple method may work in some cases, but it will not be a good strategy for most because it does not capture the relative error. The relative error, REt is defined as a factor of ut:\nREt = xt \u2212 ut ut = xt ut \u2212 1(1)\nBy thresholding the relative error, one can detect anomalies while normalizing out the dependence on the magnitude of the expected value. The values of these thresholds, indeed, determine how sensitive the anomaly detection module is. Various thresholding techniques are described in Section 4. Despite its common usage and effectiveness, however, there is no reason to believe the relative error is always the optimal metric for anomaly detection on a given time-series. In fact, the choice of the optimal metric for a given timeseries highly depends on the nature of the time-series as well as the TMM performance. For instance, if we are dealing with a very regular time-series for which we have an accu-rate model, using the prediction error for anomaly detection might be sufficient as it is expected to be Normally distributed. In other cases, the optimal metric might be something between the prediction error and the relative error. For this reason, EGADS tracks a set of deviation metrics by default and the person using the system can create her own error metrics. These error metrics, together with other features, such as the time series characteristics, are used in the alerting module (AM), described in Section 4, to learn consumer's preferences and filter unimportant anomalies.\n\n\nDecomposition-based methods\n\nThe second class of outlier detection methods in EGADS is based on the idea of time-series decomposition. In particular, in the time-series analysis literature, it is a common practice to decompose a time-series into three components: trend, seasonality and noise. By monitoring the noise component, one can capture the outliers. More precisely, if the absolute value of the noise component of point xt is greater than a certain threshold, one can announce xt as an outlier.\n\nThe decomposition of time-series can be done both in the time-domain via smoothing or in the frequency-domain via spectral decomposition. STL (Seasonal-Trend Decomposition based on Loess) [5] is a famous technique that uses Loess smoothing for decomposition. The frequency-domain methods can be further divided into parameteric and nonparametric methods. For the parametric methods, the basis used for spectral decomposition has a known parametric form (such as Fourier transform [2] or wavelet transform [22]) whereas, for non-parametric methods, the basis is datadriven [21].\n\n\nChange Point Detection\n\nChange points are those points in time where the behavior of the time-series starts to deviate from what is expected. The big difference between change points and outliers is that change points correspond to more sustained, long-term changes compared to volatile outliers. A common strategy for detecting change points in the literature is to move two side-by-side windows on the time-series and compute the difference between the behavior of the time-series in the two windows as a measure of the deviation metric [12,31,20,23]. The behavior of the time-series in each window is typically modeled by the distribution of the values, motifs, frequencies, etc. that are present in the time-series. We refer to these techniques as the absolute techniques because they do not make explicit assumptions regarding the expected behavior of the time-series.\n\nIn EGADS, currently we have taken a different approach which we refer to as the relative or model-based methods. In these methods, the expected behavior of the time-series is explicitly modeled through one of the modeling techniques mentioned in Section 3.1.1. In particular, we incorporate the plug-in approach described in Section 3.1.1 to compute the sequence of residuals (or deviations from the model expectation) for an input time-series. Then we apply the absolute change point detection methods on the series of residuals to detect a change in the distribution of the residuals. We have used Kernel Density Estimation [7] to non-parametrically estimate the distribution of the residuals and the Kullback-Leibler divergence [16] to measure the change in the distribution. We believe the model-based change point detection methods are more useful than the absolute methods in the practical applications. This is because the change points are meaningful as much as our models cannot explain the behavior of the time-series after a certain time point. However, if the model can explain the time-series behavior even after an absolute change point, from the practical point of view, there is no reason for us to consider that time point as a change point. In other words, the change points are relative to the underlying model used to explain the behavior of the time-series, which in turn gives rise to the relative change-point detection techniques.\n\n\nDetecting Anomalous Time-series\n\nAnother class of anomaly detection techniques supported by EGADS involves detecting anomalous time-series. An anomalous time-series T is defined as a time-series whose average deviation from the other time-series is significant. Assuming all time-series are homogeneous and come from the same source (i.e. are part of the same cluster) one can simply compute the average deviation for time-series (i) relative to other time-series. In EGADS our current approach involves clustering the time-series into a set of clusters C based on various time-series features including trend & seasonality, spectral entropy, autocorrelation, average Euclidean distance etc. After clustering we perform intra or inter-cluster time-series anomaly detection by measuring the deviation within or among the cluster centroids and the time-series (i). A common use-case for this EGADS anomaly detection type involves triaging. For example if a network engineer wants to find an anomalous server amongst millions of time-series, it can be impractical with the previous approaches because the modeling is done on the per time-series basis without taking into account the behavior of other metrics. Another application of this anomaly detection type is in finding similar anomalies, which is the inverse of the previous use-case.\n\n\nALERTING\n\nThe end-goal of anomaly detection is to produce accurate and timely alerts. EGADS achieves this via a two stage process by first generating a set of candidate anomalies by threshold selection and then filtering the irrelevant anomalies for a given use-case.\n\n\nThreshold Selection\n\nThe job of threshold selection is to select appropriate thresholds on the deviation metrics produced by the anomaly detection module (ADM). Currently EGADS implements two algorithms for threshold selection based on (a) K\u03c3 deviation and (b) density distribution.\n\nThe first approach is parametric and assumes that the data is normally distributed with a well-defined mean and standard deviation. Relying on the Gaussian distribution we can apply a well known statistical tool called the 'threesigma rule' which states that 99.73% of all samples lie within three standard deviations of the mean. Therefore, depending on the value of K in K\u03c3, one can be confident as to the probability of observing a sample at time t. Depending on the desired level of sensitivity, one can measure if a given sample lies within the 95.45% or 68.27% of all the samples for K = 2 or 1 respectively. Note that the assumption here was that our deviation metrics are normally distributed.  The second approach is non-parametric and is useful for the cases when the deviation metric is not normally distributed. The basic idea is to to find low density regions of the deviation metric distribution. One approach is to use an algorithm such as Local Outlier Factor (LOF) [3] which is based on a concept of a local density, where locality is given by nearest neighbors, whose distance is used to estimate the density. By comparing the local density of an object to the local densities of its neighbors, one can identify regions of similar density, and points that have a substantially lower density than their neighbors. These are considered to be outliers.\n\n\nFiltering\n\nFiltering performs the last stage post-processing on the anomalies which are then delivered to the consumer. While the candidate anomalies, which are the input to the filtering stage, are statistically significant, not all of them will be relevant for a particular use-case. For example some consumers are interested in spikes in the time-series, while others are interested in dips, yet others are interested in change points. EGADS provides a simple and intuitive interface which allows users to mark the regions of the time-series that are anomalous. This feedback is then used by EGADS together with time-series and model features to train a classifier that predicts if an anomaly ai is relevant to user uj. The timeseries features tracked by EGADS are shown in Table 1 and are described in more detail in [29]. Section 6.4 explores the performance of a filtering module for a specific use-case. Like other components of EGADS, the filtering component is extensible in terms of models and features. Figure 2 shows the feature profile of a sample time-series. Note that the metrics beginning with dc are obtained on the adjusted time-series (i.e. after removing trend and seasonality). In Section 6.2 we look at how these time-series characteristics impact the model performance. \n\n\nRELATED WORK\n\nThere are a number of anomaly detection techniques in the literature. The techniques range from point anomaly detection algorithms to change-point detection algorithms. In [24] authors propose an outlier detection technique based on hypothesis testing, which is very accurate at detecting extreme outliers. In fact Twitter, [26], uses [24] in conjunction with piecewise approximation of the underlying long-term trends to remove many of the false positives. Twitter's approach is fast and enjoys an impressive precision and recall, however it is specific to the use-case of Twitter. There are also a number of open-source point anomaly detection techniques available including [27,15].\n\nAuthors in [13] provide an anomaly detection technique that finds 'Change Points' or 'Level Shifts'. Change Points (CP) are different form point anomalies or point outliers in that CP reflect a change in underlying statistic of the timeseries (e.g., Mean shift). CP typically occurs in a time-series with a launch of a new product feature or a new platform. There are a number of open-source change point detection algorithms available including [14].\n\nIn our experience, a particular anomaly detection algorithm is usually applicable to only a specific use-case. As authors in [1] mention the anomalies will have typically a high anomaly score, but the high score alone is not a distinguishing factor for an anomaly. Rather, it is the analyst, who regulates the distinction between noise and anomaly. Similarly, authors in [4] provide a concise overview of the anomaly detection technique per category, citing the fact that only a set of anomaly models are most appropriate for a given anomaly category of interest. Therefore, based on the observation that 'One Size Fits All' is a myth in the anomaly detection world, EGADS uses a strategy where a collection of well trained anomaly detection models with a post-processing use-case-specific anomaly filtering stage is used. Nevertheless, EGADS is not the only generic anomaly detection framework out there. Venkataraman et. al [28] proposed a 'Black Box Anomaly Detection' framework that can be applied to a variety of data sources. Although the proposed framework is generic, it is not fully automated because it still needs a significant degree of user involvement in setting the appropriate models and metrics for a given application. Besides, this framework assumes the input training data to the system is anomaly-free, which is an unrealistic assumption in many real-world use-cases. On the other hand, Lan et. al. [17] proposed a framework for anomaly detection in large-scale systems which is automated but not generic enough to be applied to a general time-series anomaly detection problem. EGADS, however, provides flexible and effective mechanisms which make it both generic, automated and scalable. Furthermore, from the industrial point of view, EGADS has been incorporated in large-scale monitoring systems across Yahoo.\n\n\nEXPERIMENTAL STUDY\n\nWe present the experiments for the modeling, anomaly detection and alerting components of EGADS next.\n\n\nData\n\nThe dataset used for the experiments is comprised of a mixture (50/50) of synthetic and real data. We have created a synthetic time-series generation tool that is being open-sourced along with the framework [19] and the benchmarking data [18]. Using the tool, each synthetic time-series is generated by specifying the length, magnitude, number of anomalies, anomaly type, anomaly magnitude, noise level,  trend and seasonality. These parameters are picked from a fixed distribution. The real dataset is comprised of Yahoo Membership Login (YML) data. The YML data tracks the aggregate status of user logins to the Yahoo network. Both the synthetic and real time-series contain 1400 data-points each, which for the YML data represent 3 months worth of data-points. Unless otherwise stated, all experiments were run on 1000 randomly picked time-series and the results were averaged. Also note that both the synthetic and real-time data have anomaly labels, that are either synthetically or editorially generated, allowing us to measure precision and recall.\n\n\nModeling Experiments\n\nTime-series modeling (captured by the TMM component in EGADS) is a fundamental part of anomaly detection. It is often the case that the anomaly detection is as good as the underlying time-series model. Due to a large number of candidate models, model-selection becomes critical and depends upon time-series characteristics and available resources. In the experiments that follow, we demonstrate the impact of time-series features on the model performance and show the trade-off between accuracy, memory usage and training time. The models and the error metrics used in the experiments are described in Tables 2 and 3 respectively. More details about the models and the metrics can be found in [10] and [29].\n\n\nTime-series Characteristics and Model Performance\n\nTo demonstrate the impact of time-series features on model performance we compare the error metrics of different models when fitting time-series with different features (see Section 4.2). Figure 3 shows that time-series characteristics play an important role in model behavior. For example the Seasonal Naive Model, performs poorly on a dataset with no seasonality and a strong trend. EGADS keeps track of the historic time-series characteristics and model performance. Using this historical information, EGADS selects the best model (given the time-series features) judged by the error metrics described in Table 3. In practice, performing model selection based on the data features is much faster than performing cross-validation for every model. An in-house algorithm that implements a fast multi-variate spectral learning method for learning Kalman Filter parameters. As discussed in Section 2 it is often prohibitive to build models for every time-series and optimization techniques are required to support real-time performance over massive (e.g., millions of points every second) data-streams. A fundamental optimization performs a trade-off between model size, training time and accuracy. Such a trade-off is shown in Figures 4(a) and 4(b). From the figure, for example, it is clear that the Seasonal Naive model is quick to train but has a relatively large memory requirement and a high average error. At Yahoo, a target in terms of resources and training The arithmetic mean of the errors.\n\n\nTime-series Model Scalability\n\n\nMAD\n\nThe mean absolute deviation. Also known as MAE.\n\n\nMAPE\n\nThe mean absolute percentage error.\n\n\nMSE\n\nThe mean square of the errors.\n\n\nSAE\n\nThe Sum of Absolute Errors. ME Mean Error.\n\n\nMASE\n\nMean absolute scaled error. MPE Mean percentage error.  \n\n\nAnomaly Detection Experiments\n\nIn this section we compare open source system against EGADS. The open source systems considered are shown in Table 4. The results on the data described in Section 6.1 are shown in Figure 5. The results are compared in terms of the standard F1-Score = 2 \u00d7 precision\u00d7recall precision+recall . The results indicate that there is no best anomaly detection model for all use-cases. In particular different algorithms are best at detection different types of anomalies. For example Twitter [13] performs best on the time-series labeled TS-2 while ExtremeLowDensity model is best on TS-3. These datasets contain a mixture of anomaly types (e.g., outliers, changepoints), and one might argue that comparing an algorithm that is only meant for change-point detection is not fair. Recall, however, that the motivation for EGADS was that the user should be agnostic to the type of time-series and the type of anomalies that are in the data. The system must be able to gracefully and robustly deal with a wide variety of anomalies present in the data. For this reason, EGADS is built as a library that combines a set of anomaly detection models into a single framework. The anomalies from these models are forwarded to the filtering component for accurate anomaly detection.  \n\n\nAnomaly Filtering Experiments\n\nThe importance of an anomaly often depends on the usecase. Specifically, some users may be interested in the timeseries behavior that exhibits a malicious attack, while others may be interested in revenue drops. Yahoo Membership (YM) use-case refers to the former set of users. Specifically for the YM use-case, editors supplied feedback to EGADS of instances that exhibited abnormal spikes and level shifts. Abnormal in the case of YM meant seasonal followed by non-seasonal behavior which characterizes most of the attacks. Also the YM editors did not care about traffic-shift behavior, where a large drop in traffic was observed in a time-series due to router table being updated.\n\nTo address this requirement the filtering stage scanned all anomalies ai from all models and using a model classified if ai was a true positive. The model used in the filtering stage for the YM use-case is a boosted tree model based on Ad-aBoost [8]. The features used in the model are described in Table 1. The core principle of AdaBoost is to fit a sequence of weak learners (e.g., small decision trees) on repeatedly modified version of the data. The final result is then produced via a combined weighted majority vote. On each iteration, the examples that are difficult to predict receive a higher importance in the next iteration and therefore each subsequent weak learner focuses on the examples that are missed by the previous learners in the sequence. Besides the time-series features described in Table 1 we use the model features described in Section 6.2. The experiments in Figure 6 indicate an impressive precision/recall even with just the time-series features compared to just using the model alone without the filtering stage. This experiment underlines an important principle and a critical component of any anomaly detection framework: an anomaly is use-case specific and must be learned automatically for a fully scalable and automated solution.\n\n\nPRACTICAL USE-CASES AT YAHOO\n\nA major use case for anomaly detection at Yahoo is the monitoring of system and business metrics in order to detect infrastructure and product issues. Yahoo currently tracks over one hundred million distinct timeseries emitted by its production systems. In monitoring these timeseries, three broad use categories emerge; system metrics, business KPIs, and groups of like metrics.\n\n\nSystem Metrics\n\nSystem metrics are broadly defined as measurements of the health of a hardware component in a serving system. Examples include CPU utilization, free disk space, network interface traffic stats, and memory utilization. Some of these metrics, such as CPU utilization, track the overall traffic to a component, and some, like free disk space, are independent of the current traffic levels. What sets system metrics apart from other types of metrics is that due to the redundant nature of Yahoo's serving system, a threshold violation is typically a leading indicator of serving problems. Because of this, alerting against these types of metrics is often not treated as an outage, but instead used to trigger longer term remediations such as adding capacity or clearing disk space.\n\n\nBusiness KPIs\n\nBusiness KPIs are metrics that directly reflect customers' experiences with Yahoo sites. Examples include things such as page views, serving latency, serving errors, click-through rate, and revenue received. Business KPIs are almost always trailing indicators of site issues, and by definition reflect impact to Yahoo's ability to serve. As a result, anomalies in business KPIs are normally treated with a high degree of urgency. The nature of business KPIs at large scale is that they tend to be highly predictable, so they lend themselves well to automated anomaly detection. Yahoo has had tremendous success in instrumenting business KPIs to discover serving and revenue issues using automated anomaly detection.\n\n\nGroups of similar metrics\n\nMost of Yahoo's infrastructure follows a horizontal scaling model, with dozens to hundreds of individual servers making up each serving tier. When triaging and isolating the cause of a suspected incident, it can be difficult to survey an infrastructure of thousands of machines to find the fault. Automated anomaly detection can be used to rank the relative anomalousness, or \"interestingness\", of each component of the infrastructure, and these characteristics can be ranked in descending order to enable operators to quickly see patterns and isolate issues.\n\n\nCONCLUSION\n\nAnomaly detection is a critical component at the heart of many real-time monitoring systems with applications in fault detection, fraud detection, network intrusion detection and many others. Despite its crucial importance, implementing a fully-automatic anomaly detection system in practice is a challenging task due to the large problem scale and the diverse use-cases residing in the real-world setting. These challenges typically result in solutions that are either not scalable or highly specialized, which would in turn result in a high rate of false positives when applied to other use-cases.\n\nIn this paper, we introduced EGADS, the generic anomaly detection system implemented at Yahoo to automatically monitor and alert on millions of time-series on different Yahoo properties for different use-cases ranging from fault detection to intrusion detection. As we described in the paper, the parallel architecture of EGADS on Hadoop as well as its stream processing mechanism through Storm enable it to perform real-time anomaly detection on millions of timeseries at Yahoo. Furthermore, EGADS employs different time-series modeling, and anomaly detection algorithms to handle different monitoring use-cases. By incorporating this array of algorithms combined with a machine-learned mechanism in the alerting module, EGADS automatically adapts itself to the anomaly detection use-case that is important to the user. All of these features effectively create a powerful anomaly detection framework which is both generic and scalable. Our showcase experiments on real and synthetic datasets have shown the superior applicability of our framework compared to its rival solutions.\n\nLast but not least, EGADS by its very nature is extendable, providing an easy mechanism to plugin new models and algorithms into the system. This feature specifically creates an oppurtunity for the community to contribute to EGADS. Finally, to further engage with the anomaly detection and monitoring community, our framework together with all its datasets are contributed to the open source repository.\n\n\nKDD'15, August 10-13, 2015, Sydney, NSW, Australia.\n\n\nc 2015 ACM. ISBN 978-1-4503-3664-2/15/08 ...$15.00. DOI: http://dx.doi.org/10.1145/2783258.2788611.\n\nFigure 1 :\n1EGADS-YMS Architecture\n\nFigure 2 :\n2An example of the time-series and its characteristics extracted by EGADS. These characteristics are used by EGADS for filtering and model selection.\n\n\nperformance on TimeSeries with seasonality.\n\nFigure 3 :\n3Model performance on time-series with varying characteristics.\n\n\nseasonal model where the prediction for next point is a smoothed average over previous n periods. Exponential Smoothing Model A popular model used to produce smoothed time-series. Double and Triple exponential smoothing variants add trend and seasonality into the model. The ETS model used for the experiments automatically picks the best 'fit' exponential smoothing model. Moving Average Model In this mode, the forecast is based on an artificially constructed time series in which the value for a given time period is replaced by the mean of that value and the values for some number of preceding and succeeding time periods. The Weighted Moving Average and Naive Forecasting Model are special cases of the moving average model. Regression Models Models the relationship between x & y using one or more variable. ARIMA Autoregressive integrated moving average.\n\n\nFigure 4: Model trade-offs\n\nFigure 5 :\n5Anomaly model performance on different datasets. Observe that there is no single model that is best on all datasets.\n\nFigure 6 :\n6Accuracy of the filtering stage using different types of features.\n\nTable 1 :\n1Time-series features used by EGADS\n\nTable 2 :\n2Models Used for Modeling Experiments\n\nTable 3 :\n3Metrics Used for Modeling ExperimentsModel \nDescription \nEGADS \nExtremeLow-\nDensityModel \nOutlier \n\nEGADS density-based anomaly detection. \n\nEGADS CP \nEGADS kernel-based change-point detec-\ntion. \nEGADS \nKSig-\nmaModel \nOutlier \n\nEGADS re-implementation of the classic k-\nsigma model. \n\nTwitter Out-\nlier \n\nThe Open-Source Twitter-R anomaly de-\ntection library based on the Generalized \nESD method. \nExtremeI & II \nR Outlier \n\nOpen source univariate outlier detection \nthat threshold the absolute value and the \nresidual to detect anomalies. \nBreakOut \nTwitter CP \n\nA package from Twitter that uses an ESD \nstatistics test to detect change points. \nChangePt1 R \nCP \n\nAn R library that implements various \nmainstream and specialized change-point \nmethods for finding single and multiple \nchange-points within data. Method I uses \na change in variance. \nChangePt2 & \n3 R CP \n\nDetects a change in the mean and the vari-\nance. \n\n\n\nTable 4 :\n4Open Source systems used for evaluation time is first set and then the models are picked accordingly. In other words, the objective is to minimize the errors inTable 3subject to the resource and model building time constrains. Other optimization techniques including timeseries sampling and model sharing are being investigated.\n\nOutlier Analysis. C , SpringerNew YorkC. Aggarwal. Outlier Analysis. Springer New York, 2013.\n\nFourier analysis of time series: an introduction. P Bloomfield, John Wiley & SonsP. Bloomfield. Fourier analysis of time series: an introduction. John Wiley & Sons, 2004.\n\nLof: Identifying density-based local outliers. M M Breunig, H.-P Kriegel, R T Ng, J Sander, SIGMOD Rec. 292M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander. Lof: Identifying density-based local outliers. SIGMOD Rec., 29(2):93-104, May 2000.\n\nAnomaly detection: A survey. V Chandola, A Banerjee, V Kumar, 15:1-15:58ACM Comput. Surv. 413V. Chandola, A. Banerjee, and V. Kumar. Anomaly detection: A survey. ACM Comput. Surv., 41(3):15:1-15:58, July 2009.\n\nStl: A seasonal-trend decomposition procedure based on loess. R B Cleveland, W S Cleveland, J E Mcrae, I Terpenning, Journal of Official Statistics. 61R. B. Cleveland, W. S. Cleveland, J. E. McRae, and I. Terpenning. Stl: A seasonal-trend decomposition procedure based on loess. Journal of Official Statistics, 6(1):3-73, 1990.\n\nTime series analysis by state space methods. J Durbin, S J Koopman, Number. 38Oxford University PressJ. Durbin and S. J. Koopman. Time series analysis by state space methods. Number 38. Oxford University Press, 2012.\n\nNon-parametric estimation of a multivariate probability density. V A Epanechnikov, Theory of Probability & Its Applications. 14V. A. Epanechnikov. Non-parametric estimation of a multivariate probability density. Theory of Probability & Its Applications, 14(1):153-158, 1969.\n\nA decision-theoretic generalization of on-line learning and an application to boosting. Y Freund, R E Schapire, Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting, 1996.\n\nKalman filtering and neural networks. S S Haykin, S S Haykin, S S Haykin, Wiley Online LibraryS. S. Haykin, S. S. Haykin, and S. S. Haykin. Kalman filtering and neural networks. Wiley Online Library, 2001.\n\nAnother look at measures of forecast accuracy. R J Hyndman, A B Koehler, International Journal of Forecasting. R. J. Hyndman and A. B. Koehler. Another look at measures of forecast accuracy. International Journal of Forecasting, pages 679-688, 2006.\n\nExponential smoothing for multivariate time series. R H Jones, Journal of the Royal Statistical Society. Series B (Methodological). R. H. Jones. Exponential smoothing for multivariate time series. Journal of the Royal Statistical Society. Series B (Methodological), pages 241-251, 1966.\n\nChange-point detection in time-series data based on subspace identification. Y Kawahara, T Yairi, K Machida, ICDM. IEEEY. Kawahara, T. Yairi, and K. Machida. Change-point detection in time-series data based on subspace identification. In ICDM, pages 559-564. IEEE, 2007.\n\nMitigating user experience from 'breaking bad': The twitter approach. A Kejariwal, P Kumar, Velocity. New York, NYA. Kejariwal and P. Kumar. Mitigating user experience from 'breaking bad': The twitter approach. In Velocity, New York, NY, Sept. 2014.\n\nchangepoint, an R package that implements various mainstream and specialised changepoint methods. R Killick, R. Killick. changepoint, an R package that implements various mainstream and specialised changepoint methods., 2014.\n\noutliers, an R package of some tests commonly used outlier detection techniques. L Komsta, L. Komsta. outliers, an R package of some tests commonly used outlier detection techniques., 2011.\n\nInformation theory and statistics. Courier Corporation. S Kullback, S. Kullback. Information theory and statistics. Courier Corporation, 1997.\n\nToward automated anomaly identification in large-scale systems. Parallel and Distributed Systems. Z Lan, Z Zheng, Y Li, IEEE Transactions on. 212Z. Lan, Z. Zheng, and Y. Li. Toward automated anomaly identification in large-scale systems. Parallel and Distributed Systems, IEEE Transactions on, 21(2):174-187, 2010.\n\nOnline dataset for anomaly detection. N Laptev, S Amizadeh, N. Laptev and S. Amizadeh. Online dataset for anomaly detection. http://webscope.sandbox.yahoo.com/ catalog.php?datatype=s&did=70, April 2015.\n\nEgads source code. N Laptev, S Amizadeh, N. Laptev and S. Amizadeh. Egads source code. https://github.com/yahoo/egads, June 2015.\n\nChange-point detection in time-series data by relative density-ratio estimation. S Liu, M Yamada, N Collier, M Sugiyama, Neural Networks. 43S. Liu, M. Yamada, N. Collier, and M. Sugiyama. Change-point detection in time-series data by relative density-ratio estimation. Neural Networks, 43:72-83, 2013.\n\nAn algorithm based on singular spectrum analysis for change-point detection. V Moskvina, A Zhigljavsky, Communications in Statistics-Simulation and Computation. 322V. Moskvina and A. Zhigljavsky. An algorithm based on singular spectrum analysis for change-point detection. Communications in Statistics-Simulation and Computation, 32(2):319-352, 2003.\n\nWavelet methods for time series analysis. D B Percival, A T Walden, Cambridge University Press4D. B. Percival and A. T. Walden. Wavelet methods for time series analysis, volume 4. Cambridge University Press, 2006.\n\nBayesian methods for change-point detection in long-range dependent processes. B K Ray, R S Tsay, Journal of Time Series Analysis. 236B. K. Ray and R. S. Tsay. Bayesian methods for change-point detection in long-range dependent processes. Journal of Time Series Analysis, 23(6):687-705, 2002.\n\nPercentage points for a generalized esd many-outlier procedure. B Rosner, Technometrics. 252B. Rosner. Percentage points for a generalized esd many-outlier procedure. Technometrics, 25(2):165-172, 1983.\n\nA Toshniwal, S Taneja, A Shukla, K Ramasamy, J M Patel, S Kulkarni, J Jackson, K Gade, M Fu, J Donham, N Bhagat, S Mittal, D Ryaboy, Storm@twitter, SIGMOD. New York, NY, USAACMA. Toshniwal, S. Taneja, A. Shukla, K. Ramasamy, J. M. Patel, S. Kulkarni, J. Jackson, K. Gade, M. Fu, J. Donham, N. Bhagat, S. Mittal, and D. Ryaboy. Storm@twitter. In SIGMOD, pages 147-156, New York, NY, USA, 2014. ACM.\n\nA novel technique for long-term anomaly detection in the cloud. O Vallis, J Hochenbaum, A Kejariwal, USENIX. Philadelphia, PAUSENIX AssociationO. Vallis, J. Hochenbaum, and A. Kejariwal. A novel technique for long-term anomaly detection in the cloud. In USENIX, Philadelphia, PA, June 2014. USENIX Association.\n\nextremevalues, an R package for outlier detection in univariate data. M Van Der Loo, R package version 2.0M. van der Loo. extremevalues, an R package for outlier detection in univariate data, 2010. R package version 2.0.\n\nBlack box anomaly detection: is it utopian?. S Venkataraman, J Caballero, D Song, A Blum, J Yates, S. Venkataraman, J. Caballero, D. Song, A. Blum, and J. Yates. Black box anomaly detection: is it utopian? 2006.\n\nRule induction for forecasting method selection: Meta-learning the characteristics of univariate time series. X Wang, K Smith-Miles, R Hyndman, Neurocomput. 72X. Wang, K. Smith-Miles, and R. Hyndman. Rule induction for forecasting method selection: Meta-learning the characteristics of univariate time series. Neurocomput., 72(10-12):2581-2594, June 2009.\n\nTime series analysis. W W , - S Wei, Addison-Wesley publW. W.-S. Wei. Time series analysis. Addison-Wesley publ, 1994.\n\nChange-point detection for high-dimensional time series with missing data. Selected Topics in Signal Processing. Y Xie, J Huang, R Willett, IEEE Journal. 71Y. Xie, J. Huang, and R. Willett. Change-point detection for high-dimensional time series with missing data. Selected Topics in Signal Processing, IEEE Journal of, 7(1):12-27, 2013.\n", "annotations": {"author": "[{\"start\":\"78\",\"end\":\"115\"},{\"start\":\"116\",\"end\":\"154\"},{\"start\":\"155\",\"end\":\"171\"},{\"start\":\"172\",\"end\":\"200\"},{\"start\":\"201\",\"end\":\"247\"}]", "publisher": null, "author_last_name": "[{\"start\":\"86\",\"end\":\"92\"},{\"start\":\"122\",\"end\":\"130\"},{\"start\":\"165\",\"end\":\"170\"}]", "author_first_name": "[{\"start\":\"78\",\"end\":\"85\"},{\"start\":\"116\",\"end\":\"121\"},{\"start\":\"155\",\"end\":\"158\"},{\"start\":\"159\",\"end\":\"164\"}]", "author_affiliation": "[{\"start\":\"173\",\"end\":\"199\"},{\"start\":\"202\",\"end\":\"246\"}]", "title": "[{\"start\":\"1\",\"end\":\"75\"},{\"start\":\"248\",\"end\":\"322\"}]", "venue": null, "abstract": "[{\"start\":\"347\",\"end\":\"1395\"}]", "bib_ref": "[{\"start\":\"3199\",\"end\":\"3202\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"3418\",\"end\":\"3421\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"4758\",\"end\":\"4762\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"4814\",\"end\":\"4818\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"7205\",\"end\":\"7209\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"7690\",\"end\":\"7691\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"11215\",\"end\":\"11219\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"11243\",\"end\":\"11247\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"11263\",\"end\":\"11266\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"11287\",\"end\":\"11290\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"15044\",\"end\":\"15047\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"15336\",\"end\":\"15339\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"15361\",\"end\":\"15365\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"15428\",\"end\":\"15432\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"15975\",\"end\":\"15979\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"15979\",\"end\":\"15982\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"15982\",\"end\":\"15985\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"15985\",\"end\":\"15988\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"16937\",\"end\":\"16940\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"17042\",\"end\":\"17046\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"20644\",\"end\":\"20647\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"21853\",\"end\":\"21857\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"22515\",\"end\":\"22519\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"22667\",\"end\":\"22671\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"22678\",\"end\":\"22682\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"23020\",\"end\":\"23024\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"23024\",\"end\":\"23027\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"23041\",\"end\":\"23045\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"23476\",\"end\":\"23480\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"23608\",\"end\":\"23611\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"23854\",\"end\":\"23857\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"24409\",\"end\":\"24413\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"24903\",\"end\":\"24907\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"25656\",\"end\":\"25660\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"25687\",\"end\":\"25691\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"27222\",\"end\":\"27226\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"27231\",\"end\":\"27235\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"29591\",\"end\":\"29595\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"31336\",\"end\":\"31339\",\"attributes\":{\"ref_id\":\"b7\"}}]", "figure": "[{\"start\":\"36985\",\"end\":\"37038\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"37039\",\"end\":\"37140\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"37141\",\"end\":\"37176\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"37177\",\"end\":\"37338\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"37339\",\"end\":\"37384\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"37385\",\"end\":\"37460\",\"attributes\":{\"id\":\"fig_5\"}},{\"start\":\"37461\",\"end\":\"38325\",\"attributes\":{\"id\":\"fig_6\"}},{\"start\":\"38326\",\"end\":\"38354\",\"attributes\":{\"id\":\"fig_7\"}},{\"start\":\"38355\",\"end\":\"38484\",\"attributes\":{\"id\":\"fig_8\"}},{\"start\":\"38485\",\"end\":\"38564\",\"attributes\":{\"id\":\"fig_9\"}},{\"start\":\"38565\",\"end\":\"38611\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"38612\",\"end\":\"38660\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}},{\"start\":\"38661\",\"end\":\"39597\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}},{\"start\":\"39598\",\"end\":\"39938\",\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"1411\",\"end\":\"2101\"},{\"start\":\"2103\",\"end\":\"3203\"},{\"start\":\"3205\",\"end\":\"3687\"},{\"start\":\"3689\",\"end\":\"4071\"},{\"start\":\"4073\",\"end\":\"4584\"},{\"start\":\"4586\",\"end\":\"5102\"},{\"start\":\"5104\",\"end\":\"5405\"},{\"start\":\"5422\",\"end\":\"5580\"},{\"start\":\"5582\",\"end\":\"5849\"},{\"start\":\"5851\",\"end\":\"6194\"},{\"start\":\"6217\",\"end\":\"6891\"},{\"start\":\"6893\",\"end\":\"6983\"},{\"start\":\"6985\",\"end\":\"7079\"},{\"start\":\"7081\",\"end\":\"7126\"},{\"start\":\"7128\",\"end\":\"7176\"},{\"start\":\"7178\",\"end\":\"7237\"},{\"start\":\"7239\",\"end\":\"7383\"},{\"start\":\"7385\",\"end\":\"7536\"},{\"start\":\"7538\",\"end\":\"7805\"},{\"start\":\"7821\",\"end\":\"8429\"},{\"start\":\"8431\",\"end\":\"8752\"},{\"start\":\"8754\",\"end\":\"9191\"},{\"start\":\"9193\",\"end\":\"9500\"},{\"start\":\"9533\",\"end\":\"9705\"},{\"start\":\"9707\",\"end\":\"9917\"},{\"start\":\"9919\",\"end\":\"10088\"},{\"start\":\"10090\",\"end\":\"10294\"},{\"start\":\"10296\",\"end\":\"10445\"},{\"start\":\"10467\",\"end\":\"10709\"},{\"start\":\"10711\",\"end\":\"10810\"},{\"start\":\"10830\",\"end\":\"11695\"},{\"start\":\"11697\",\"end\":\"12533\"},{\"start\":\"12535\",\"end\":\"13021\"},{\"start\":\"13054\",\"end\":\"14348\"},{\"start\":\"14380\",\"end\":\"14854\"},{\"start\":\"14856\",\"end\":\"15433\"},{\"start\":\"15460\",\"end\":\"16309\"},{\"start\":\"16311\",\"end\":\"17765\"},{\"start\":\"17801\",\"end\":\"19105\"},{\"start\":\"19118\",\"end\":\"19375\"},{\"start\":\"19399\",\"end\":\"19660\"},{\"start\":\"19662\",\"end\":\"21029\"},{\"start\":\"21043\",\"end\":\"22326\"},{\"start\":\"22343\",\"end\":\"23028\"},{\"start\":\"23030\",\"end\":\"23481\"},{\"start\":\"23483\",\"end\":\"25316\"},{\"start\":\"25339\",\"end\":\"25440\"},{\"start\":\"25449\",\"end\":\"26504\"},{\"start\":\"26529\",\"end\":\"27236\"},{\"start\":\"27290\",\"end\":\"28789\"},{\"start\":\"28829\",\"end\":\"28876\"},{\"start\":\"28885\",\"end\":\"28920\"},{\"start\":\"28928\",\"end\":\"28958\"},{\"start\":\"28966\",\"end\":\"29008\"},{\"start\":\"29017\",\"end\":\"29073\"},{\"start\":\"29107\",\"end\":\"30371\"},{\"start\":\"30405\",\"end\":\"31088\"},{\"start\":\"31090\",\"end\":\"32353\"},{\"start\":\"32386\",\"end\":\"32765\"},{\"start\":\"32784\",\"end\":\"33561\"},{\"start\":\"33579\",\"end\":\"34294\"},{\"start\":\"34324\",\"end\":\"34883\"},{\"start\":\"34898\",\"end\":\"35497\"},{\"start\":\"35499\",\"end\":\"36579\"},{\"start\":\"36581\",\"end\":\"36984\"}]", "formula": "[{\"start\":\"13022\",\"end\":\"13053\",\"attributes\":{\"id\":\"formula_0\"}}]", "table_ref": "[{\"start\":\"21809\",\"end\":\"21816\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"27131\",\"end\":\"27145\",\"attributes\":{\"ref_id\":\"tab_2\"}},{\"start\":\"27898\",\"end\":\"27905\",\"attributes\":{\"ref_id\":\"tab_3\"}},{\"start\":\"29216\",\"end\":\"29223\",\"attributes\":{\"ref_id\":\"tab_4\"}},{\"start\":\"31389\",\"end\":\"31396\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"31896\",\"end\":\"31903\",\"attributes\":{\"ref_id\":\"tab_1\"}}]", "section_header": "[{\"start\":\"1397\",\"end\":\"1409\",\"attributes\":{\"n\":\"1.\"}},{\"start\":\"5408\",\"end\":\"5420\",\"attributes\":{\"n\":\"2.\"}},{\"start\":\"6197\",\"end\":\"6215\",\"attributes\":{\"n\":\"2.1\"}},{\"start\":\"7808\",\"end\":\"7819\",\"attributes\":{\"n\":\"2.2\"}},{\"start\":\"9503\",\"end\":\"9531\",\"attributes\":{\"n\":\"3.\"}},{\"start\":\"10448\",\"end\":\"10465\",\"attributes\":{\"n\":\"3.1\"}},{\"start\":\"10813\",\"end\":\"10828\",\"attributes\":{\"n\":\"3.1.1\"}},{\"start\":\"14351\",\"end\":\"14378\",\"attributes\":{\"n\":\"3.1.2\"}},{\"start\":\"15436\",\"end\":\"15458\",\"attributes\":{\"n\":\"3.2\"}},{\"start\":\"17768\",\"end\":\"17799\",\"attributes\":{\"n\":\"3.3\"}},{\"start\":\"19108\",\"end\":\"19116\",\"attributes\":{\"n\":\"4.\"}},{\"start\":\"19378\",\"end\":\"19397\",\"attributes\":{\"n\":\"4.1\"}},{\"start\":\"21032\",\"end\":\"21041\",\"attributes\":{\"n\":\"4.2\"}},{\"start\":\"22329\",\"end\":\"22341\",\"attributes\":{\"n\":\"5.\"}},{\"start\":\"25319\",\"end\":\"25337\",\"attributes\":{\"n\":\"6.\"}},{\"start\":\"25443\",\"end\":\"25447\",\"attributes\":{\"n\":\"6.1\"}},{\"start\":\"26507\",\"end\":\"26527\",\"attributes\":{\"n\":\"6.2\"}},{\"start\":\"27239\",\"end\":\"27288\",\"attributes\":{\"n\":\"6.2.1\"}},{\"start\":\"28792\",\"end\":\"28821\",\"attributes\":{\"n\":\"6.2.2\"}},{\"start\":\"28824\",\"end\":\"28827\"},{\"start\":\"28879\",\"end\":\"28883\"},{\"start\":\"28923\",\"end\":\"28926\"},{\"start\":\"28961\",\"end\":\"28964\"},{\"start\":\"29011\",\"end\":\"29015\"},{\"start\":\"29076\",\"end\":\"29105\",\"attributes\":{\"n\":\"6.3\"}},{\"start\":\"30374\",\"end\":\"30403\",\"attributes\":{\"n\":\"6.4\"}},{\"start\":\"32356\",\"end\":\"32384\",\"attributes\":{\"n\":\"7.\"}},{\"start\":\"32768\",\"end\":\"32782\",\"attributes\":{\"n\":\"7.1\"}},{\"start\":\"33564\",\"end\":\"33577\",\"attributes\":{\"n\":\"7.2\"}},{\"start\":\"34297\",\"end\":\"34322\",\"attributes\":{\"n\":\"7.3\"}},{\"start\":\"34886\",\"end\":\"34896\",\"attributes\":{\"n\":\"8.\"}},{\"start\":\"37142\",\"end\":\"37152\"},{\"start\":\"37178\",\"end\":\"37188\"},{\"start\":\"37386\",\"end\":\"37396\"},{\"start\":\"38356\",\"end\":\"38366\"},{\"start\":\"38486\",\"end\":\"38496\"},{\"start\":\"38566\",\"end\":\"38575\"},{\"start\":\"38613\",\"end\":\"38622\"},{\"start\":\"38662\",\"end\":\"38671\"},{\"start\":\"39599\",\"end\":\"39608\"}]", "table": "[{\"start\":\"38710\",\"end\":\"39597\"}]", "figure_caption": "[{\"start\":\"36987\",\"end\":\"37038\"},{\"start\":\"37041\",\"end\":\"37140\"},{\"start\":\"37154\",\"end\":\"37176\"},{\"start\":\"37190\",\"end\":\"37338\"},{\"start\":\"37341\",\"end\":\"37384\"},{\"start\":\"37398\",\"end\":\"37460\"},{\"start\":\"37463\",\"end\":\"38325\"},{\"start\":\"38328\",\"end\":\"38354\"},{\"start\":\"38368\",\"end\":\"38484\"},{\"start\":\"38498\",\"end\":\"38564\"},{\"start\":\"38577\",\"end\":\"38611\"},{\"start\":\"38624\",\"end\":\"38660\"},{\"start\":\"38673\",\"end\":\"38710\"},{\"start\":\"39610\",\"end\":\"39938\"}]", "figure_ref": "[{\"start\":\"6661\",\"end\":\"6669\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"22046\",\"end\":\"22054\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"27478\",\"end\":\"27486\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"28516\",\"end\":\"28537\"},{\"start\":\"29287\",\"end\":\"29295\",\"attributes\":{\"ref_id\":\"fig_8\"}},{\"start\":\"31975\",\"end\":\"31983\",\"attributes\":{\"ref_id\":\"fig_9\"}}]", "bib_author_first_name": "[{\"start\":\"39958\",\"end\":\"39959\"},{\"start\":\"40085\",\"end\":\"40086\"},{\"start\":\"40254\",\"end\":\"40255\"},{\"start\":\"40256\",\"end\":\"40257\"},{\"start\":\"40267\",\"end\":\"40271\"},{\"start\":\"40281\",\"end\":\"40282\"},{\"start\":\"40283\",\"end\":\"40284\"},{\"start\":\"40289\",\"end\":\"40290\"},{\"start\":\"40483\",\"end\":\"40484\"},{\"start\":\"40495\",\"end\":\"40496\"},{\"start\":\"40507\",\"end\":\"40508\"},{\"start\":\"40727\",\"end\":\"40728\"},{\"start\":\"40729\",\"end\":\"40730\"},{\"start\":\"40742\",\"end\":\"40743\"},{\"start\":\"40744\",\"end\":\"40745\"},{\"start\":\"40757\",\"end\":\"40758\"},{\"start\":\"40759\",\"end\":\"40760\"},{\"start\":\"40768\",\"end\":\"40769\"},{\"start\":\"41039\",\"end\":\"41040\"},{\"start\":\"41049\",\"end\":\"41050\"},{\"start\":\"41051\",\"end\":\"41052\"},{\"start\":\"41277\",\"end\":\"41278\"},{\"start\":\"41279\",\"end\":\"41280\"},{\"start\":\"41576\",\"end\":\"41577\"},{\"start\":\"41586\",\"end\":\"41587\"},{\"start\":\"41588\",\"end\":\"41589\"},{\"start\":\"41763\",\"end\":\"41764\"},{\"start\":\"41765\",\"end\":\"41766\"},{\"start\":\"41775\",\"end\":\"41776\"},{\"start\":\"41777\",\"end\":\"41778\"},{\"start\":\"41787\",\"end\":\"41788\"},{\"start\":\"41789\",\"end\":\"41790\"},{\"start\":\"41979\",\"end\":\"41980\"},{\"start\":\"41981\",\"end\":\"41982\"},{\"start\":\"41992\",\"end\":\"41993\"},{\"start\":\"41994\",\"end\":\"41995\"},{\"start\":\"42235\",\"end\":\"42236\"},{\"start\":\"42237\",\"end\":\"42238\"},{\"start\":\"42548\",\"end\":\"42549\"},{\"start\":\"42560\",\"end\":\"42561\"},{\"start\":\"42569\",\"end\":\"42570\"},{\"start\":\"42813\",\"end\":\"42814\"},{\"start\":\"42826\",\"end\":\"42827\"},{\"start\":\"43092\",\"end\":\"43093\"},{\"start\":\"43302\",\"end\":\"43303\"},{\"start\":\"43468\",\"end\":\"43469\"},{\"start\":\"43654\",\"end\":\"43655\"},{\"start\":\"43661\",\"end\":\"43662\"},{\"start\":\"43670\",\"end\":\"43671\"},{\"start\":\"43910\",\"end\":\"43911\"},{\"start\":\"43920\",\"end\":\"43921\"},{\"start\":\"44095\",\"end\":\"44096\"},{\"start\":\"44105\",\"end\":\"44106\"},{\"start\":\"44288\",\"end\":\"44289\"},{\"start\":\"44295\",\"end\":\"44296\"},{\"start\":\"44305\",\"end\":\"44306\"},{\"start\":\"44316\",\"end\":\"44317\"},{\"start\":\"44587\",\"end\":\"44588\"},{\"start\":\"44599\",\"end\":\"44600\"},{\"start\":\"44904\",\"end\":\"44905\"},{\"start\":\"44906\",\"end\":\"44907\"},{\"start\":\"44918\",\"end\":\"44919\"},{\"start\":\"44920\",\"end\":\"44921\"},{\"start\":\"45156\",\"end\":\"45157\"},{\"start\":\"45158\",\"end\":\"45159\"},{\"start\":\"45165\",\"end\":\"45166\"},{\"start\":\"45167\",\"end\":\"45168\"},{\"start\":\"45435\",\"end\":\"45436\"},{\"start\":\"45575\",\"end\":\"45576\"},{\"start\":\"45588\",\"end\":\"45589\"},{\"start\":\"45598\",\"end\":\"45599\"},{\"start\":\"45608\",\"end\":\"45609\"},{\"start\":\"45620\",\"end\":\"45621\"},{\"start\":\"45622\",\"end\":\"45623\"},{\"start\":\"45631\",\"end\":\"45632\"},{\"start\":\"45643\",\"end\":\"45644\"},{\"start\":\"45654\",\"end\":\"45655\"},{\"start\":\"45662\",\"end\":\"45663\"},{\"start\":\"45668\",\"end\":\"45669\"},{\"start\":\"45678\",\"end\":\"45679\"},{\"start\":\"45688\",\"end\":\"45689\"},{\"start\":\"45698\",\"end\":\"45699\"},{\"start\":\"46038\",\"end\":\"46039\"},{\"start\":\"46048\",\"end\":\"46049\"},{\"start\":\"46062\",\"end\":\"46063\"},{\"start\":\"46356\",\"end\":\"46357\"},{\"start\":\"46553\",\"end\":\"46554\"},{\"start\":\"46569\",\"end\":\"46570\"},{\"start\":\"46582\",\"end\":\"46583\"},{\"start\":\"46590\",\"end\":\"46591\"},{\"start\":\"46598\",\"end\":\"46599\"},{\"start\":\"46831\",\"end\":\"46832\"},{\"start\":\"46839\",\"end\":\"46840\"},{\"start\":\"46854\",\"end\":\"46855\"},{\"start\":\"47100\",\"end\":\"47101\"},{\"start\":\"47102\",\"end\":\"47103\"},{\"start\":\"47106\",\"end\":\"47107\"},{\"start\":\"47108\",\"end\":\"47109\"},{\"start\":\"47311\",\"end\":\"47312\"},{\"start\":\"47318\",\"end\":\"47319\"},{\"start\":\"47327\",\"end\":\"47328\"}]", "bib_author_last_name": "[{\"start\":\"40087\",\"end\":\"40097\"},{\"start\":\"40258\",\"end\":\"40265\"},{\"start\":\"40272\",\"end\":\"40279\"},{\"start\":\"40285\",\"end\":\"40287\"},{\"start\":\"40291\",\"end\":\"40297\"},{\"start\":\"40485\",\"end\":\"40493\"},{\"start\":\"40497\",\"end\":\"40505\"},{\"start\":\"40509\",\"end\":\"40514\"},{\"start\":\"40731\",\"end\":\"40740\"},{\"start\":\"40746\",\"end\":\"40755\"},{\"start\":\"40761\",\"end\":\"40766\"},{\"start\":\"40770\",\"end\":\"40780\"},{\"start\":\"41041\",\"end\":\"41047\"},{\"start\":\"41053\",\"end\":\"41060\"},{\"start\":\"41281\",\"end\":\"41293\"},{\"start\":\"41578\",\"end\":\"41584\"},{\"start\":\"41590\",\"end\":\"41598\"},{\"start\":\"41767\",\"end\":\"41773\"},{\"start\":\"41779\",\"end\":\"41785\"},{\"start\":\"41791\",\"end\":\"41797\"},{\"start\":\"41983\",\"end\":\"41990\"},{\"start\":\"41996\",\"end\":\"42003\"},{\"start\":\"42239\",\"end\":\"42244\"},{\"start\":\"42550\",\"end\":\"42558\"},{\"start\":\"42562\",\"end\":\"42567\"},{\"start\":\"42571\",\"end\":\"42578\"},{\"start\":\"42815\",\"end\":\"42824\"},{\"start\":\"42828\",\"end\":\"42833\"},{\"start\":\"43094\",\"end\":\"43101\"},{\"start\":\"43304\",\"end\":\"43310\"},{\"start\":\"43470\",\"end\":\"43478\"},{\"start\":\"43656\",\"end\":\"43659\"},{\"start\":\"43663\",\"end\":\"43668\"},{\"start\":\"43672\",\"end\":\"43674\"},{\"start\":\"43912\",\"end\":\"43918\"},{\"start\":\"43922\",\"end\":\"43930\"},{\"start\":\"44097\",\"end\":\"44103\"},{\"start\":\"44107\",\"end\":\"44115\"},{\"start\":\"44290\",\"end\":\"44293\"},{\"start\":\"44297\",\"end\":\"44303\"},{\"start\":\"44307\",\"end\":\"44314\"},{\"start\":\"44318\",\"end\":\"44326\"},{\"start\":\"44589\",\"end\":\"44597\"},{\"start\":\"44601\",\"end\":\"44612\"},{\"start\":\"44908\",\"end\":\"44916\"},{\"start\":\"44922\",\"end\":\"44928\"},{\"start\":\"45160\",\"end\":\"45163\"},{\"start\":\"45169\",\"end\":\"45173\"},{\"start\":\"45437\",\"end\":\"45443\"},{\"start\":\"45577\",\"end\":\"45586\"},{\"start\":\"45590\",\"end\":\"45596\"},{\"start\":\"45600\",\"end\":\"45606\"},{\"start\":\"45610\",\"end\":\"45618\"},{\"start\":\"45624\",\"end\":\"45629\"},{\"start\":\"45633\",\"end\":\"45641\"},{\"start\":\"45645\",\"end\":\"45652\"},{\"start\":\"45656\",\"end\":\"45660\"},{\"start\":\"45664\",\"end\":\"45666\"},{\"start\":\"45670\",\"end\":\"45676\"},{\"start\":\"45680\",\"end\":\"45686\"},{\"start\":\"45690\",\"end\":\"45696\"},{\"start\":\"45700\",\"end\":\"45706\"},{\"start\":\"45708\",\"end\":\"45721\"},{\"start\":\"46040\",\"end\":\"46046\"},{\"start\":\"46050\",\"end\":\"46060\"},{\"start\":\"46064\",\"end\":\"46073\"},{\"start\":\"46358\",\"end\":\"46369\"},{\"start\":\"46555\",\"end\":\"46567\"},{\"start\":\"46571\",\"end\":\"46580\"},{\"start\":\"46584\",\"end\":\"46588\"},{\"start\":\"46592\",\"end\":\"46596\"},{\"start\":\"46600\",\"end\":\"46605\"},{\"start\":\"46833\",\"end\":\"46837\"},{\"start\":\"46841\",\"end\":\"46852\"},{\"start\":\"46856\",\"end\":\"46863\"},{\"start\":\"47110\",\"end\":\"47113\"},{\"start\":\"47313\",\"end\":\"47316\"},{\"start\":\"47320\",\"end\":\"47325\"},{\"start\":\"47329\",\"end\":\"47336\"}]", "bib_entry": "[{\"start\":\"39940\",\"end\":\"40033\",\"attributes\":{\"id\":\"b0\"}},{\"start\":\"40035\",\"end\":\"40205\",\"attributes\":{\"id\":\"b1\"}},{\"start\":\"40207\",\"end\":\"40452\",\"attributes\":{\"matched_paper_id\":\"6787631\",\"id\":\"b2\"}},{\"start\":\"40454\",\"end\":\"40663\",\"attributes\":{\"matched_paper_id\":\"207172599\",\"id\":\"b3\",\"doi\":\"15:1-15:58\"}},{\"start\":\"40665\",\"end\":\"40992\",\"attributes\":{\"matched_paper_id\":\"64570714\",\"id\":\"b4\"}},{\"start\":\"40994\",\"end\":\"41210\",\"attributes\":{\"matched_paper_id\":\"40484227\",\"id\":\"b5\"}},{\"start\":\"41212\",\"end\":\"41486\",\"attributes\":{\"matched_paper_id\":\"122653538\",\"id\":\"b6\"}},{\"start\":\"41488\",\"end\":\"41723\",\"attributes\":{\"id\":\"b7\"}},{\"start\":\"41725\",\"end\":\"41930\",\"attributes\":{\"id\":\"b8\"}},{\"start\":\"41932\",\"end\":\"42181\",\"attributes\":{\"matched_paper_id\":\"15947215\",\"id\":\"b9\"}},{\"start\":\"42183\",\"end\":\"42469\",\"attributes\":{\"matched_paper_id\":\"125796618\",\"id\":\"b10\"}},{\"start\":\"42471\",\"end\":\"42741\",\"attributes\":{\"matched_paper_id\":\"10006725\",\"id\":\"b11\"}},{\"start\":\"42743\",\"end\":\"42992\",\"attributes\":{\"id\":\"b12\"}},{\"start\":\"42994\",\"end\":\"43219\",\"attributes\":{\"id\":\"b13\"}},{\"start\":\"43221\",\"end\":\"43410\",\"attributes\":{\"id\":\"b14\"}},{\"start\":\"43412\",\"end\":\"43554\",\"attributes\":{\"id\":\"b15\"}},{\"start\":\"43556\",\"end\":\"43870\",\"attributes\":{\"matched_paper_id\":\"7760930\",\"id\":\"b16\"}},{\"start\":\"43872\",\"end\":\"44074\",\"attributes\":{\"id\":\"b17\"}},{\"start\":\"44076\",\"end\":\"44205\",\"attributes\":{\"id\":\"b18\"}},{\"start\":\"44207\",\"end\":\"44508\",\"attributes\":{\"matched_paper_id\":\"12679112\",\"id\":\"b19\"}},{\"start\":\"44510\",\"end\":\"44860\",\"attributes\":{\"matched_paper_id\":\"59041988\",\"id\":\"b20\"}},{\"start\":\"44862\",\"end\":\"45075\",\"attributes\":{\"id\":\"b21\"}},{\"start\":\"45077\",\"end\":\"45369\",\"attributes\":{\"matched_paper_id\":\"15157524\",\"id\":\"b22\"}},{\"start\":\"45371\",\"end\":\"45573\",\"attributes\":{\"matched_paper_id\":\"120153383\",\"id\":\"b23\"}},{\"start\":\"45575\",\"end\":\"45972\",\"attributes\":{\"id\":\"b24\"}},{\"start\":\"45974\",\"end\":\"46284\",\"attributes\":{\"matched_paper_id\":\"2107118\",\"id\":\"b25\"}},{\"start\":\"46286\",\"end\":\"46506\",\"attributes\":{\"id\":\"b26\"}},{\"start\":\"46508\",\"end\":\"46719\",\"attributes\":{\"id\":\"b27\"}},{\"start\":\"46721\",\"end\":\"47076\",\"attributes\":{\"matched_paper_id\":\"207100900\",\"id\":\"b28\"}},{\"start\":\"47078\",\"end\":\"47196\",\"attributes\":{\"id\":\"b29\"}},{\"start\":\"47198\",\"end\":\"47535\",\"attributes\":{\"id\":\"b30\"}}]", "bib_title": "[{\"start\":\"40207\",\"end\":\"40252\"},{\"start\":\"40454\",\"end\":\"40481\"},{\"start\":\"40665\",\"end\":\"40725\"},{\"start\":\"40994\",\"end\":\"41037\"},{\"start\":\"41212\",\"end\":\"41275\"},{\"start\":\"41932\",\"end\":\"41977\"},{\"start\":\"42183\",\"end\":\"42233\"},{\"start\":\"42471\",\"end\":\"42546\"},{\"start\":\"42743\",\"end\":\"42811\"},{\"start\":\"43556\",\"end\":\"43652\"},{\"start\":\"44207\",\"end\":\"44286\"},{\"start\":\"44510\",\"end\":\"44585\"},{\"start\":\"45077\",\"end\":\"45154\"},{\"start\":\"45371\",\"end\":\"45433\"},{\"start\":\"45974\",\"end\":\"46036\"},{\"start\":\"46721\",\"end\":\"46829\"},{\"start\":\"47198\",\"end\":\"47309\"}]", "bib_author": "[{\"start\":\"39958\",\"end\":\"39962\"},{\"start\":\"40085\",\"end\":\"40099\"},{\"start\":\"40254\",\"end\":\"40267\"},{\"start\":\"40267\",\"end\":\"40281\"},{\"start\":\"40281\",\"end\":\"40289\"},{\"start\":\"40289\",\"end\":\"40299\"},{\"start\":\"40483\",\"end\":\"40495\"},{\"start\":\"40495\",\"end\":\"40507\"},{\"start\":\"40507\",\"end\":\"40516\"},{\"start\":\"40727\",\"end\":\"40742\"},{\"start\":\"40742\",\"end\":\"40757\"},{\"start\":\"40757\",\"end\":\"40768\"},{\"start\":\"40768\",\"end\":\"40782\"},{\"start\":\"41039\",\"end\":\"41049\"},{\"start\":\"41049\",\"end\":\"41062\"},{\"start\":\"41277\",\"end\":\"41295\"},{\"start\":\"41576\",\"end\":\"41586\"},{\"start\":\"41586\",\"end\":\"41600\"},{\"start\":\"41763\",\"end\":\"41775\"},{\"start\":\"41775\",\"end\":\"41787\"},{\"start\":\"41787\",\"end\":\"41799\"},{\"start\":\"41979\",\"end\":\"41992\"},{\"start\":\"41992\",\"end\":\"42005\"},{\"start\":\"42235\",\"end\":\"42246\"},{\"start\":\"42548\",\"end\":\"42560\"},{\"start\":\"42560\",\"end\":\"42569\"},{\"start\":\"42569\",\"end\":\"42580\"},{\"start\":\"42813\",\"end\":\"42826\"},{\"start\":\"42826\",\"end\":\"42835\"},{\"start\":\"43092\",\"end\":\"43103\"},{\"start\":\"43302\",\"end\":\"43312\"},{\"start\":\"43468\",\"end\":\"43480\"},{\"start\":\"43654\",\"end\":\"43661\"},{\"start\":\"43661\",\"end\":\"43670\"},{\"start\":\"43670\",\"end\":\"43676\"},{\"start\":\"43910\",\"end\":\"43920\"},{\"start\":\"43920\",\"end\":\"43932\"},{\"start\":\"44095\",\"end\":\"44105\"},{\"start\":\"44105\",\"end\":\"44117\"},{\"start\":\"44288\",\"end\":\"44295\"},{\"start\":\"44295\",\"end\":\"44305\"},{\"start\":\"44305\",\"end\":\"44316\"},{\"start\":\"44316\",\"end\":\"44328\"},{\"start\":\"44587\",\"end\":\"44599\"},{\"start\":\"44599\",\"end\":\"44614\"},{\"start\":\"44904\",\"end\":\"44918\"},{\"start\":\"44918\",\"end\":\"44930\"},{\"start\":\"45156\",\"end\":\"45165\"},{\"start\":\"45165\",\"end\":\"45175\"},{\"start\":\"45435\",\"end\":\"45445\"},{\"start\":\"45575\",\"end\":\"45588\"},{\"start\":\"45588\",\"end\":\"45598\"},{\"start\":\"45598\",\"end\":\"45608\"},{\"start\":\"45608\",\"end\":\"45620\"},{\"start\":\"45620\",\"end\":\"45631\"},{\"start\":\"45631\",\"end\":\"45643\"},{\"start\":\"45643\",\"end\":\"45654\"},{\"start\":\"45654\",\"end\":\"45662\"},{\"start\":\"45662\",\"end\":\"45668\"},{\"start\":\"45668\",\"end\":\"45678\"},{\"start\":\"45678\",\"end\":\"45688\"},{\"start\":\"45688\",\"end\":\"45698\"},{\"start\":\"45698\",\"end\":\"45708\"},{\"start\":\"45708\",\"end\":\"45723\"},{\"start\":\"46038\",\"end\":\"46048\"},{\"start\":\"46048\",\"end\":\"46062\"},{\"start\":\"46062\",\"end\":\"46075\"},{\"start\":\"46356\",\"end\":\"46371\"},{\"start\":\"46553\",\"end\":\"46569\"},{\"start\":\"46569\",\"end\":\"46582\"},{\"start\":\"46582\",\"end\":\"46590\"},{\"start\":\"46590\",\"end\":\"46598\"},{\"start\":\"46598\",\"end\":\"46607\"},{\"start\":\"46831\",\"end\":\"46839\"},{\"start\":\"46839\",\"end\":\"46854\"},{\"start\":\"46854\",\"end\":\"46865\"},{\"start\":\"47100\",\"end\":\"47106\"},{\"start\":\"47106\",\"end\":\"47115\"},{\"start\":\"47311\",\"end\":\"47318\"},{\"start\":\"47318\",\"end\":\"47327\"},{\"start\":\"47327\",\"end\":\"47338\"}]", "bib_venue": "[{\"start\":\"39940\",\"end\":\"39956\"},{\"start\":\"40035\",\"end\":\"40083\"},{\"start\":\"40299\",\"end\":\"40309\"},{\"start\":\"40526\",\"end\":\"40542\"},{\"start\":\"40782\",\"end\":\"40812\"},{\"start\":\"41062\",\"end\":\"41068\"},{\"start\":\"41295\",\"end\":\"41335\"},{\"start\":\"41488\",\"end\":\"41574\"},{\"start\":\"41725\",\"end\":\"41761\"},{\"start\":\"42005\",\"end\":\"42041\"},{\"start\":\"42246\",\"end\":\"42313\"},{\"start\":\"42580\",\"end\":\"42584\"},{\"start\":\"42835\",\"end\":\"42843\"},{\"start\":\"42994\",\"end\":\"43090\"},{\"start\":\"43221\",\"end\":\"43300\"},{\"start\":\"43412\",\"end\":\"43466\"},{\"start\":\"43676\",\"end\":\"43696\"},{\"start\":\"43872\",\"end\":\"43908\"},{\"start\":\"44076\",\"end\":\"44093\"},{\"start\":\"44328\",\"end\":\"44343\"},{\"start\":\"44614\",\"end\":\"44669\"},{\"start\":\"44862\",\"end\":\"44902\"},{\"start\":\"45175\",\"end\":\"45206\"},{\"start\":\"45445\",\"end\":\"45458\"},{\"start\":\"45723\",\"end\":\"45729\"},{\"start\":\"46075\",\"end\":\"46081\"},{\"start\":\"46286\",\"end\":\"46354\"},{\"start\":\"46508\",\"end\":\"46551\"},{\"start\":\"46865\",\"end\":\"46876\"},{\"start\":\"47078\",\"end\":\"47098\"},{\"start\":\"47338\",\"end\":\"47350\"},{\"start\":\"42845\",\"end\":\"42857\"},{\"start\":\"45731\",\"end\":\"45748\"},{\"start\":\"46083\",\"end\":\"46099\"}]"}}}, "year": 2023, "month": 12, "day": 17}