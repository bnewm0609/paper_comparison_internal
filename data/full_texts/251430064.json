{"id": 251430064, "updated": "2022-12-16 15:46:29.459", "metadata": {"title": "Hybrid Machine-Learning-Based Spectrum Sensing and Allocation With Adaptive Congestion-Aware Modeling in CR-Assisted IoV Networks", "authors": "[{\"first\":\"Ramsha\",\"last\":\"Ahmed\",\"middle\":[]},{\"first\":\"Yueyun\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Bilal\",\"last\":\"Hassan\",\"middle\":[]},{\"first\":\"Liping\",\"last\":\"Du\",\"middle\":[]},{\"first\":\"Taimur\",\"last\":\"Hassan\",\"middle\":[]},{\"first\":\"Jorge\",\"last\":\"Dias\",\"middle\":[]}]", "venue": "IEEE Internet of Things Journal", "journal": "IEEE Internet of Things Journal", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Unlicensed cognitive-radio (CR)-assisted Internet of Vehicles (IoV) users can access licensed providers\u2019 radio spectrum and concurrently utilize the dedicated channel for data transmission in vehicular communication. Optimizing channel access in cognitive IoV networks can help maximize available spectrum resources. This article proposes a novel sensing and communication integrated framework, dubbed as the CR-assisted IoV network (CRAV-Net), using a cluster-based hybrid optimization approach with adaptive congestion-aware modeling for dynamic high-mobility vehicular networks in an urban city context. In CRAV-Net, intelligent hybrid learning spectrum agents are introduced, which perform spectrum sensing (SS) using a deep learning (DL) model. It dynamically learns the multilevel spatial and temporal graphical features from input spectrograms through layer-by-layer propagation. It efficiently predicts the spectrum occupancy in the primary spectrum, without a priori knowledge of the radio environment. Then, to assign the vacant channels to the secondary vehicles, a support vector machine classifier is trained based on several learning features, including the vehicle stay time, vehicle density, and network capacity, to select the optimal resource route. The proposed framework achieves an overall accuracy of 99.74% in SS using the custom data set, outperforming state of the art by 12.60% at \u221225-dB signal-to-noise ratio. In addition, it brings a performance gain of 0.81% in SS accuracy when evaluated on real-world signals. Furthermore, in optimal network node allocation, the proposed framework achieves a mean accuracy of 98.45%, outperforming the existing methods by 0.63% and 18.32% in terms of accuracy and allocation time, respectively.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/iotj/AhmedCHDH022", "doi": "10.1109/jiot.2022.3195425"}}, "content": {"source": {"pdf_hash": "e80b0c2779ecd2e8cfe448e8627dc223dc220a00", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "034d1bf2d6b11b4c9f2e796e27c50941b06399cc", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/e80b0c2779ecd2e8cfe448e8627dc223dc220a00.txt", "contents": "\nHybrid Machine-Learning-Based Spectrum Sensing and Allocation With Adaptive Congestion-Aware Modeling in CR-Assisted IoV Networks\n15 DECEMBER 2022\n\nRamsha Ahmed ramsha.ahmed46@hotmail.com. \nMember, IEEEYueyun Chen chenyy@ustb.edu.cn \nBilal Hassan bilal.hassan@ku.ac.ae \nLiping Du \nMember, IEEETaimur Hassan taimur.hassan@ku.ac.ae. \nSenior Member, IEEEJorge Dias jorge.dias@ku.ac.ae. \nYueyun Chen \nLiping \nBilal Hassan \nJorge Dias \n\nDepartment of Biomedical Engineering\nSchool of Computer and Communication Engineering\nKhalifa University of Science and Technology\nAbu DhabiUAE\n\n\nSchool of Computer and Communication Engineering\nUniversity of Science and Technology\n100083Beijing, BeijingChina\n\n\nDepartment of Electrical Engineering and Computer Science\nare with the Khalifa University Center for Autonomous Robotic Systems\nUniversity of Science and Technology\n100083Beijing, BeijingChina\n\n\nDepartment of Electrical Engineering and Computer Science\nTaimur Hassan is with the Center for Cyber-Physical Systems\nKhalifa University of Science and Technology\nAbu DhabiUAE\n\n\nKhalifa University of Science and Technology\nAbu DhabiUAE\n\nHybrid Machine-Learning-Based Spectrum Sensing and Allocation With Adaptive Congestion-Aware Modeling in CR-Assisted IoV Networks\n\nIEEE INTERNET OF THINGS JOURNAL\n92415 DECEMBER 202210.1109/JIOT.2022.3195425Manuscript received 28 June 2022; accepted 25 July 2022. Date of publi-cation 1 August 2022; date of current version 7 December 2022.25100 (Corresponding author: Yueyun Chen.) Ramsha Ahmed is with the Healthcare Engineering Innovation Center, This article has supplementary downloadable material available at https://doi.org/10.1109/JIOT.2022.3195425, provided by the authors.\nUnlicensed cognitive-radio (CR)-assisted Internet of Vehicles (IoV) users can access licensed providers' radio spectrum and concurrently utilize the dedicated channel for data transmission in vehicular communication. Optimizing channel access in cognitive IoV networks can help maximize available spectrum resources. This article proposes a novel sensing and communication integrated framework, dubbed as the CR-assisted IoV network (CRAV-Net), using a cluster-based hybrid optimization approach with adaptive congestion-aware modeling for dynamic high-mobility vehicular networks in an urban city context. In CRAV-Net, intelligent hybrid learning spectrum agents are introduced, which perform spectrum sensing (SS) using a deep learning (DL) model. It dynamically learns the multilevel spatial and temporal graphical features from input spectrograms through layer-by-layer propagation. It efficiently predicts the spectrum occupancy in the primary spectrum, without a priori knowledge of the radio environment. Then, to assign the vacant channels to the secondary vehicles, a support vector machine classifier is trained based on several learning features, including the vehicle stay time, vehicle density, and network capacity, to select the optimal resource route. The proposed framework achieves an overall accuracy of 99.74% in SS using the custom data set, outperforming state of the art by 12.60% at \u221225-dB signal-to-noise ratio. In addition, it brings a performance gain of 0.81% in SS accuracy when evaluated on real-world signals. Furthermore, in optimal network node allocation, the proposed framework achieves a mean accuracy of 98.45%, outperforming the existing methods by 0.63% and 18.32% in terms of accuracy and allocation time, respectively.\n\nI. INTRODUCTION\n\nT HE TECHNOLOGICAL revolution of the nextgeneration wireless network (beyond 5G (B5G) and 6G) impacts all industries, resulting in emerging applications, such as smart cities and industries, remote healthcare, connected intelligence, and connected vehicles. For these applications to succeed, high-precision sensing and reliable wireless connectivity are required. Many futuristic assumptions, especially for context-aware scenarios, assume that sensing will play a significant role in B5G/6G networks [1], [2]. Future smart cities will rely on sensing, and the network's ability to collect ambient sensory input to learn and gain intelligence. As a result, integrated sensing and communications (ISAC) in B5G/6G networks is regarded as a paradigm shift in wireless network design [3].\n\nISAC aims to combine sensing and communication processes to investigate direct tradeoffs and mutual performance improvements. Besides, ISAC is expected to improve energy and spectral efficiency while lowering signaling and hardware costs. However, ISAC strives for greater integration, where the two operations are no longer considered separate end-goals but are co-designed for mutual benefit [2]. Due to these characteristics, ISAC is now being used in a wide range of applications, including unmanned aerial vehicle (UAV) networks [4], Wi-Fi networks [5], and the Internet of Vehicles (IoV) [6], [7]. Generally, sensing is frequently used in communication systems, despite being rarely acknowledged [2]. For instance, spectrum sensing (SS) in cognitive radio (CR) is a classic example of sensingassisted communication. If the primary user (PU) is not using a specific frequency band, the secondary user (SU) can use it to send data using spectrum sharing [2].\n\nIn IoV, vehicular communication is considered the backbone of intelligent transportation system (ITS) [8]. Vehicular communication helps prevent traffic jams and accidents, reduce fuel consumption, and improve overall traffic management [8]. An IoV network typically includes roadside units (RSUs) for Internet connectivity and multiple vehicles with onboard units (OBUs) for processing [9]. These vehicles communicate with other vehicles or with RSUs using the dedicated short-range communication (DSRC) protocol. The DSRC has six service channels and a common control channel allocated to vehicular communication at 5.9 GHz [9]. However, these channels are inadequate and easily overburdened, especially in congested areas with high vehicle density. Consequently, the delivery of safety control messages may be delayed [9]. Therefore, to alleviate the issue of restricted channel availability, the concept of CR has been proposed and studied in IoV context [10].\n\nThe demand for wireless radio spectrum has grown exponentially over the last few decades. This led to increase in end-users in various fields, such as industry [11], [12], [13], healthcare [14], [15], [16], security [17], [18], and ITS, resulting in shortage of available spectrum. Therefore, effective implementation of IoV in the near future will necessitate vast additional spectrum resources to enable a large number of vehicles to communicate with each other, or the Internet [8].\n\nAccording to the recent research, most networks do not fully utilize their licensed spectrum [8]. Opportunistic spectrum access (OSA) allows nonlicensed SUs to find spectrum holes and communicate without interfering with licensed PUs following the CR networks (CRNs) principle. To leverage opportunistic communication in CR-based IoV, nonlicensed vehicles (SUs) employ SS to locate unoccupied channels for efficient data dissemination when the DSRC is completely occupied [9].\n\n\nA. Related Works\n\nIoV is important in many applications. The connected vehicles gather information from the environment and share it with other entities in the network to take and control actions based on the underlying applications, such as traffic control and management, emergency, and infotainment services [9]. Wireless access in vehicular environments (WAVE) is introduced as an efficient and cost-effective wireless technology for smooth connectivity in IoV [19]. However, WAVE technology relies on DSRC channels, which are insufficient, especially as the number of vehicles increases, causing network congestion [20]. As a result, alternate ways for enhancing channel capacity in IoV must be investigated, and CR-based networks are one such solution [9].\n\nIn the past, researchers have focused on the CRN architecture, SS and sharing, channel modeling, and spectrum management [21], [22]. These works include the Markov chain, cooperative SS (CSS), generalized likelihood ratio test [23], and machine-intelligence-based algorithms [24]. Moreover, CSS, mainly using a decision fusion center, has been employed to improve the SS capability and address major challenges of spectrum exploration and allocation in CRNs, such as intercarrier interference, frequency-selective fading, and correlated shadowing [25], [26], [27]. Such models forecast the free channels within the licensed spectral band, and vehicles in CR-based IoV can use them for communication. For instance, Eze et al. [28] proposed a CSS method to sense unoccupied spectrum holes to transmit data in CR-assisted IoV. Similarly, in [29], a cluster-based CSS scheme is proposed with a multiuser multiple-input and multiple-output antennas system to detect the PU signals. In another approach [30], Zhang and Guo proposed a beam-alignment-based vehicular mmWave SS model using the temporal correlation of sensing data induced by vehicular activity and derived the detection probability.\n\nFurthermore, merging the IoV paradigm with new artificial intelligence (AI) technologies may open up new possibilities and opportunities. Traditional centralized systems face serious computational and resource utilization challenges when dealing with large numbers of smart vehicles and IoV connections [31]. Hence, combining AI and decentralized edge computing may be a viable solution to ameliorate these challenges [31], [32]. Besides, the conventional sensing-assisted communication schemes rely on a priori statistics about the primary network (such as signal-noise distribution or prior probabilities) or some predetermined conditions [23]. However, an SS or resource allocation method that uses estimated results may not be suitable for dynamic IoV networks [31]. Instead, by sensing and learning the radio environment, AI can intelligently manage and control vehicle network resources [31]. As a result, AI algorithms can help with efficient SS and resource allocation in high-mobility CR-based IoV networks [31], [32].\n\nMuch recently, researchers have started to apply AI-based algorithms in different CRN scenarios to perform the SS tasks [33], [34]. Ahmed et al. [35] considered a B5G CRN of UAVs and Internet of Things (IoT) and developed a deep learning (DL)-based approach to sense the spectrum holes. Ahmed et al. [36] proposed a convolutional neural network (CNN) model for OSA. Moreover, Xie et al. [37] proposed an SS technique in CRNs by combining CNN with a long shortterm memory (LSTM) network. It initially captures the energy correlation features using the CNN, which are afterward used to train the LSTM for learning the PU activity pattern.\n\nApart from this, many deep neural network (DNN) solutions have been proposed to perform the resource allocation task [38]. Ye and Li [39] proposed a decentralized resource allocation method for vehicular communication based on deep Q-networks (DQN). Lei et al. [40] proposed a deep reinforcement learning (DRL) framework to investigate the spectrum allocation (SA) in large-scale and dynamic integrated access and backhaul (IAB) networks. Similarly, Zhao et al. [41] proposed a DRL algorithm for energy-efficient and optimal channel allocation in Satellite IoT (SIoT). Besides, in [42], a recurrent-neural-network-based approach is proposed to allocate resources in the unlicensed band with fairness constraints between WiFi and other licensed assisted access long-term evolution (LTE-LAA) operators. Table I summarizes AI-based SS and allocation works for a qualitative comparison in terms of distinctive characteristics, objectives, CRN environment considered, and the algorithms adopted for the training and validation purposes.\n\nHowever, while investigating SS and resource allocation problems in CR-based IoV networks, there has been little research done in the literature to study the combined impact of various challenges, such as vehicle speed, the direction of travel, PU activity status (active/idle), network capacity to determine currently allocated resources, and vehicle density Considering these challenges, we present a hybrid optimization scheme with adaptive congestion-aware modeling to perform intelligent SS and resource allocation in a 5G-based IoV network.\n\n\nB. Key Contributions\n\nWe investigate the joint SS and resource allocation problem in the dynamic high-mobility environment of 5G-based IoV networks for improving spectrum efficiency while intelligently managing and controlling vehicular network resources. To achieve this, we propose a cluster-based CR-assisted IoV network called CRAV-Net. We devised a novel congestionaware hybrid learning solution for SS and optimal resource routing. The notable contributions of this article are fourfold.\n\n1) The CRAV-Net framework is designed for an urban city environment, comprising four main network components: a) PU base station (PBS); b) hybrid learning spectrum agents (HLSAs); c) RSUs; and d) SU vehicles. The HLSA acts as the intelligent cluster head, leveraging DL and machine learning (ML) techniques for spectrum resource optimization in CRAV-Net. Hence, the name \"hybrid learning\" is coined for the proposed scheme. 2) Unlike traditional schemes, we propose a novel DLbased SS model that leverages residual learning with integrated atrous spatial pyramid pooling (ASPP) module to learn the dynamic signal environment by detecting and classifying the PU activity patterns in CRAV-Net (active or idle) using spectrograms. 3) Next, an ML-based effective resource allocation mechanism, driven via support vector machines (SVM), is proposed for the SU vehicles in the CRAV-Net, which considers the high mobility and randomness of the IoV networks to allocate the optimal RSU nodes. 4) The CRAV-Net is capable of adapting to the changing IoV network dynamics (such as signal environment, vehicle speed, and congestion) by regularly updating the learning features, allowing it to forecast the availability of vacant channels more accurately, as well as to determine the best route through the network for resource allocation in order to maintain a traffic load balance in the overall network environment. The remainder of this article is organized as follows: Section II elaborates the CRAV-Net system model and the proposed hybrid learning scheme, involving DL-based SS and ML-based resource allocation mechanisms. Section III presents the details on the experimental setup, containing system specifications and key evaluation metrics used in this study. Next, simulation results are discussed in Section IV, explaining the training performances of the proposed DL and ML models along with the various conducted experimental results. Section V discusses the proposed research and sheds light on the future scope of this work. Finally, Section VI concludes this article. In addition, the important acronyms of this research are listed in Table II. II. HYBRID LEARNING-BASED SPECTRUM SENSING AND RESOURCE ALLOCATION\n\n\nA. System Model\n\nThis article investigates a joint SS and resource allocation problem in a 5G-based IoV network. To address these issues, we propose a cluster-based CR-assisted IoV network (CRAV-Net), where a novel congestion-aware hybrid learning solution is devised for SS and optimal resource routing. Fig. 1 shows the proposed CRAV-Net system model. It is designed for an urban city environment and comprises four main network components: 1) PBS; 2) HLSAs; 3) RSUs; and 4) SU vehicles.\n\nThe CRAV-Net has A number of HLSAs serving under a PBS, macrocell of radius r PU (i.e., a = 1, 2, 3, . . . , a, . . . , A). Furthermore, each HLSA cluster consists of U number of RSUs, microcells of radius r RSU (i.e., u  network. In order to define the mobility of SU vehicles in the proposed scheme, two parameters are used [43]: 1) the SU velocity \u03b2 SU and 2) the SU direction of travel \u03b1 SU . Both of these parameters follow the Gaussian distribution, as expressed in the following:\n\u03b2 v SU = N \u03b2 v \u03bc , \u03b2 v \u03c3 (1) \u03b1 v SU = N \u03b1 v \u03bc , 2\u03c0 \u2212 \u03b1 v \u03bc tan \u03b2 v SU 2 t (2)\nwhere the term N(\u03bc, \u03c3 ) shows the Gaussian distribution with \u03bc mean and \u03c3 standard deviation. For the vth SU vehicle, \u03b2 v \u03bc denotes the mean velocity and \u03b2 v \u03c3 denotes its standard deviation. Similarly, \u03b1 v \u03bc denotes the previous direction of the vth SU vehicle and t denotes the time period to update the SU vehicle's mobility model in the proposed scheme. Next, the description of each network entity and its responsibilities are presented as follows.\n\n1) PBS: In the proposed study, the PBS is stationary and assumed to be located at a fixed position within the CRAV-Net system model. It provides backhaul connectivity to the HLSAs, which administer the RSUs along the city roads, and coordinates spectrum access services within its coverage area. 2) HLSA: The HLSA acts as the intelligent cluster head in the CRAV-Net system model and is responsible for various decision-making tasks in response to the SU vehicles' requests. First, it is responsible for periodically observing the PU spectrum occupancy using a DL-based SS algorithm and maintaining the spectrum hole table (SHT) to accommodate the SU requests within its cluster. Second, when a request is received for spectrum access for opportunistic communication at any given RSU in the cluster, it analyzes serving RSUs through a trained ML classifier (SVM) to determine the most optimal node for channel allocation. In HLSA, the optimal RSU allocation for resource routing is based on a 3-D feature vector, encompassing the following aspects. a) Learn Signal Environment: First, to learn the signal environment in CRAV-Net, SS is performed, in which the PU presence or absence is identified in the network, and as a result, an SHT is generated.\n\nIn the SS process, if a PU signal is detected, it is marked as \"no spectrum hole\" (no SH) entry in the table, and if the PU signal is not detected, it is labeled as \"spectrum hole\" (SH) entry (i.e., vacant frequency bands of PU spectrum) in the SHT. Thus, the PU detection problem is formulated as expressed in the following:\ns i PU\u2192HLSA a = h i PU\u2192HLSA a s i PU + \u03c9 i , (no SH) \u03c9 i , ( SH)(3)\nwhere s i PU is the PU signal,\u015d i PU\u2192HLSA a denotes the ith received PU signal sample at the ath HLSA in the network. h i PU\u2192HLSA a denotes the Rayleigh multipath fading channel between the ath HLSA and PBS. \u03c9 i denotes the additive white Gaussian noise (AWGN), with \u03c3 2 \u03c9 noise power and zero mean. b) Learn Vehicle Behavior: Second, to learn the vehicle behavior in CRAV-Net, the vehicle stay time in the target RSU cell is computed based on vehicle mobility (speed) and angle of movement. Since vehicles (i.e., SUs) are mobile and RSUs are stationed along the highway, therefore, the vehicle speed is the relative velocity between the SU and RSU. Other vehicle behavioral aspects include its direction of travel on the two-lane highway (i.e., left moving vehicles or right moving vehicles) and vehicle density, which indicates the number of active vehicles in a single RSU coverage area above a specified range to identify congestion or traffic-jam on the road. c) Learn Network Environment: Finally, to learn the network environment in CRAV-Net, network capacity is computed based on the resources allocated to all active SU vehicles associated with the network in contrast to the total network resources. The details on the learning features will be described later. 3) RSUs: The PBS coverage is extended through RSUs in the CRAV-Net system model. They serve the secondary IoV users within their coverage area and route the channels assigned to vehicles upon request. 4) SU Vehicle: In CRAV-Net, the IoV users are highly mobile, designated as unlicensed SUs without a dedicated spectrum. They perform opportunistic data transmission based on the licensed spectrum holes in the PU spectrum routed via RSUs.\n\n\nB. Spectrum Sensing via Deep Learning\n\n1) Data Generation: The training and validation data in this research consist of spectrograms (which is a visual depiction of the frequency spectrum of a signal as it changes over time) of complex synthetic waveforms belonging to two classes: 1) spectrum hole and 2) no spectrum hole. We created 40 000 spectrum hole class spectrograms, representing the PU idle transmission status (i.e., noise). Similarly, we generated 40 000 no spectrum hole class spectrograms, representing the PU active transmission status (i.e., PU signal) relevant to the PU activity in the network. Refer to the supplementary material for more details regarding the different parameters and data generation methodology adopted in this research.\n\n2) DL Network Architecture: The proposed DL-based model for SS consists of 53 layers, as illustrated in Fig. 2. The network architecture is finalized through extensive ablation experiments to analyze the effectiveness of each functional component (Refer to the supplementary material for more details). It is a lightweight network that uses around 0.3 million parameters, with a network depth of 14 convolutional layers. While existing DL models are completely feedforward and employ standard convolutions, the proposed model is a directed acyclic graph network with integrated residual connections and ASPP module, designed to gradually improve the features learning capabilities of the network toward spectrum hole detection.\n\nThe model is fed a complex spectrogram of dimensions 224 \u00d7 224 \u00d7 3 as input. The first five modules of the model (M1, M2, M3, ASPP, and M4) serve as the contracting path, where it learns the differences between the classes of spectrum hole and no spectrum hole, as well as the characteristics of each class. The last block (M5) produces the classification outcome based on softmax confidence. To generate the feature maps, the proposed model begins with a stem-like structure in which a kernel of size 3 \u00d7 3 and 2 \u00d7 2 is utilized to execute the convolution (C) and max-pooling (MP) operations, respectively.\n\nEach convolution in the network is followed by a batch normalization (BN) and rectified linear activation (R) layer to reduce nonlinearity and truncate the negative pixels, which further enhance the network's ability to identify variations in the spatial-temporal features. Furthermore, we used residual connections to enable explicit multiscale feature learning as well as model generalization. Moreover, these connections prevent the gradient from disappearing, allowing for rapid convergence of the network. Another critical component of our model is the ASPP module, which leverages high-level features in the signal and noise spectrograms while also retaining more spatial information [16]. It is composed of four 3 \u00d7 3 atrous C with increasing dilation rates (1, 3, 6, and 9), expressed as given in\nO(\u03b6, \u03d5) = \u03b6 x=1 \u03d5 y=1 I(\u03b6 +d \u00d7 x, \u03d5 +d \u00d7 y)g(x, y)(4)\nwhere I(\u03b6, \u03d5) are the input and O(\u03b6, \u03d5) are the output features maps, with width \u03d5 and length \u03b6 .d is the dilation rate and g(x, y) is the convolutional kernel. The advantage of atrous convolution over conventional convolution is that it can aggregate multiscale contextual information more flexibly and adaptively. Besides, it adaptively enlarges the small-sized kernel (g\u00d7g) to a new receptive field of size g+(g\u22121)(d \u22121) by varying the value of the dilation rate (see the supplementary material for atrous convolution mechanism). Accordingly, it enables broader and context-aware filtering while retaining the exact spatial resolution, that is, without increasing the computation cost involved or the number of network parameters [44]. As a result, combining atrous convolutions and ASPP into the proposed model allows the network to outperform the existing methods in terms of SS accuracy. Furthermore, as illustrated in Fig. 2, the atrous convolutions are followed by BN and R layers. These four convolutional branches are then concatenated using the depthwise concatenation (DC) layer, restoring the original feature size as seen at the ASPP input. At M5, the final module in the network, which contains global average pooling (GAP), fully connected (FC), softmax, and classification layers, the input spectrogram is classified as either spectrum hole or no spectrum hole, corresponding to the absence or presence of PUs, respectively. Fundamentally, the classification mechanism (C) of the proposed model is based on the softmax activation, expressed as C = M5 M4 . . . M1 I spec (5) M5 I spec = l 4 arg max l 3 l 2 l 1 I spec (6) where I spec is the input spectrogram. M1-M5 including ASPP are the six modules of the proposed model, with their respective activation functions and weights. l \u03b8 , \u03b8 = {1, . . . , 4}, are the four layers of the M5 module, where l 3 represents the softmax activation layer and l 4 represents the classification layer that returns the input spectrogram with the label having the highest score based on the arg max operator.\n\n\nC. Resource Allocation via Machine Learning Classifier\n\nNext, we used the ML technique to build an effective resource allocation mechanism for SU vehicles in CRAV-Net, which considers the highly mobile and dynamic character of IoV networks. The HLSA determines the merit of the RSUs within the cluster through a trained SVM classifier, considering different learning features as decision-making attributes for the selection and allocation of optimal network resources.\n\n\n1) Extraction of Learning Features:\n\nIn the proposed research, we initially considered six different features to validate the performances of ML classifiers (see the supplementary material for more details). Afterward, we empirically selected the three most relevant learning features in order to maximize spectrum efficiency and resource allocation for secondary IoV users in CRAV-Net. Furthermore, these characteristic features enable the proposed scheme to accommodate the shifting network dynamics, allowing it to accurately and reliably estimate the availability of vacant channels and determine the best route through the network for resource allocation. The description of these three learning features used is as follows.\n\nf 1 (Vehicle Stay Time): The predicted stay time of the vth SU vehicle in the target RSU cell (let us say in the uth RSU cell) as illustrated in Fig. 3, can be computed as [43] \u03c4\nv SU = \u2212 \u2212\u2212\u2212\u2212\u2212\u2212\u2212 \u2192 SU v IN SU v OUT \u03b2 v SU = 2r u RSU cos(\u03b3 ) \u03b2 v SU(7)\nwhere SU v IN is the location at which the SU vehicle arrives in the RSU cell and SU v OUT denotes the location where the SU vehicle departs the RSU cell's coverage area. \u03b2 v SU symbolizes the SU velocity and r u RSU represents the coverage radius of the uth RSU. Furthermore, using the sine rule in Fig. 3, we get\n\u2212 \u2212\u2212\u2212\u2212\u2212 \u2192 SU v 1 RSU u 0 sin(180 \u2212 \u03b3 ) = r u RSU sin(\u03b1)(8)\nwhere RSU u 0 denotes the fixed location of the RSU and SU v 1 shows the previous location of the SU vehicle. Simplifying the above expression, we get\nsin(\u03b3 ) = sin(\u03b1) \u2212 \u2212\u2212\u2212\u2212\u2212 \u2192 SU v 1 RSU u 0 r u RSU .(9)\nThus\ncos(\u03b3 ) = 1 \u2212 sin(\u03b1) \u2212 \u2212\u2212\u2212\u2212\u2212 \u2192 SU v 1 RSU u 0 2 r u RSU 2 .(10)\nFurthermore, the angle between the trajectory path of the SU vehicle and the position of the RSU can be computed as\n\u03b1 = arccos \u239b \u239d \u2212 \u2212\u2212\u2212\u2212\u2212 \u2192 SU v 1 RSU u 0 \u00b7 \u2212 \u2212\u2212\u2212\u2212 \u2192 SU v 1 SU v 2 \u2212 \u2212\u2212\u2212\u2212\u2212 \u2192 SU v 1 RSU u 0 \u00d7 \u2212 \u2212\u2212\u2212\u2212 \u2192 SU v 1 SU v 2 \u239e \u23a0 .(11)\nHere, SU v 2 shows the current location of the SU vehicle. Next, putting (11) in (10), we get\ncos(\u03b3 ) = 1 \u2212 sin arccos \u2212 \u2212\u2212\u2212\u2212\u2212 \u2192 SU v 1 RSU u 0 \u00b7 \u2212 \u2212\u2212\u2212\u2212 \u2192 SU v 1 SU v 2 \u2212 \u2212\u2212\u2212\u2212\u2212 \u2192 SU v 1 RSU u 0 \u00d7 \u2212 \u2212\u2212\u2212\u2212 \u2192 SU v 1 SU v 2 \u2212 \u2212\u2212\u2212\u2212\u2212 \u2192 SU v 1 RSU u 0 2 r u RSU 2 .(12)\nFinally, substituting the expression of cos(\u03b3 ) in (7) yields the expression for the predicted stay time of the vth SU vehicle as\nf 1 = \u03c4 v SU (13) = 2r u RSU 1 \u2212 sin arccos \u2212\u2212\u2212\u2212\u2212\u2212\u2192 SU v 1 RSU u 0 \u00b7 \u2212 \u2212\u2212\u2212\u2212\u2192 SU v 1 SU v 2 \u2212\u2212\u2212\u2212\u2212\u2212\u2192 SU v 1 RSU u 0 \u00d7 \u2212 \u2212\u2212\u2212\u2212\u2192 SU v 1 SU v 2 \u2212 \u2212\u2212\u2212\u2212\u2212 \u2192 SU v 1 RSU u 0 2 r u RSU 2 \u03b2 v SU .(14)\nf 2 (Vehicle Density): Vehicle density is defined as the number of active secondary IoV users in the RSU cell. Hence, the vehicle density in the coverage area of the uth RSU, with v number of active SU vehicles, can be expressed as\nf 2 = \u03b4 u RSU = \u2200v SU v ACTIVE .(15)\nIn addition, to express the vehicle density within the jurisdiction of an HLSA cluster, we determine the number of active SU vehicles connected to all RSUs in the cluster, such as, for the ath HLSA cluster consisting of u number of RSUs, the vehicle density can be stated as\n\u03b4 a HLSA = \u2200u \u03b4 u RSU .(16)\nThe preceding expression can be further simplified as\n\u03b4 a HLSA = \u2200u \u2200v SU uv ACTIVE .(17)\nf 3 (Network Capacity): The network capacity of the uth RSU existing in the ath HLSA cluster can be expressed as\nf 3 = \u03b7 u RSU = BW \u00b7 \u03c6 u ALLOTTED \u00b7 log 2 1 +\u03c8 RSU u \u2192SU v . (18)\nwhere BW denotes the bandwidth, \u03c6 u ALLOTTED shows the proportion of allotted resources to all active SU vehicles affiliated with the uth RSU, in contrast to its total resources \u03c6 u TOTAL . Then, \u03c6 u ALLOTTED can be expressed as [43] \n\u03c6 u ALLOTTED = \u2200v SU v ACTIVE \u03c6 u TOTAL .(19)\nFurthermore,\u03c8 RSU u \u2192SU v in (18) represents the signal-tointerference-plus-noise ratio (SINR) received at the vth SU vehicle from the uth RSU in the ath HLSA cluster. To integrate the impact of interference in the decision-making process, the downlink SINR must be treated as a critical parameter, expressed a\u015d\n\u03c8 RSU u \u2192SU v =\u03c1 RSU u \u2192SU v RSU\u2208HLSA a ,RSU =RSU u h RSU u \u2192SU v \u03c1 RSU u + \u03c9 2(20)\nwhere\u03c1 RSU u \u2192SU v is the downlink signal power received at the vth SU vehicle from the uth RSU computed a\u015d\n\u03c1 RSU u \u2192SU v = h RSU u \u2192SU v \u03c1 RSU u(21)\nhere, \u03c1 RSU u denotes the transmission power of the uth RSU and h RSU u \u2192SU v represents the Rayleigh multipath fading channel between the RSU and SU vehicle, existing in the same HLSA cluster. Because of the high-speed mobility inherent with IoV, a vehicle can travel very fast from one radio environment to another, causing it to experience the Doppler shift effects. Therefore, the Rayleigh channel comprises the Doppler shift effects due to the relative motion of SU vehicles in the network. We assume that the maximum speed of a mobile IoV user in an urban city environment, as depicted in Fig. 1, is 80 km/h. So, the maximum Doppler shift is calculated to be 70 Hz. Furthermore, in (20),\nRSU\u2208HLSA a ,RSU =RSU u h RSU u \u2192SU v \u03c1 RSU u\nshows the sum of the interfering downlink signal powers from all the other RSUs in the ath HLSA cluster, except RSU u , and \u03c9 2 denotes the noise power.\n\n2) Feature Set Formulation: In the following step, a (U \u00d7 3)-D feature set FS(v) is formed by concatenating the three computed feature vectors (f 1 , f 2 , and f 3 ) against U RSUs in the network as described above. Here, U is the total number of RSUs in the relevant ath HLSA cluster, where the vth SU vehicle has submitted the request for channel allocation. The ML classifier in CRAV-Net is trained based on this feature set to determine the optimal spectrum access node (RSU in the cluster) against each SU vehicle request (w.r.t. the availability of spectrum holes, and the best route for resource allocation at HLSA). The (U \u00d73)-D FS(v) of an SU v vehicle for U number of RSUs (i.e., u = 1, 2, 3, . . . , u, . . . , U) in the HLSA a cluster can be expressed as (1, v) . . . . . . . . .\nFS(v) = \u23a1 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a3 f 1 (1, v) f 2 (1, v) f 3f 1 (u, v) f 2 (u, v) f 3 (u, v) . . . . . . . . . f 1 (U, v) f 2 (U, v) f 3 (U, v) \u23a4 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a6(22)\nwhere feature f 1 (u, v) represents the predicted stay time of the requesting SU v vehicle against RSU u . Similarly, feature f 2 (u, v) represents the vehicle density, and feature f 3 (u, v) represents the network capacity in the target RSU u cell belonging to the HLSA a cluster of the network.\n\n\n3) SVM Training Process and Data Generation:\n\nWe considered a single cluster of HLSA under the PBS, with three RSUs and 300 SU vehicles deployed for the training the ML classifier. Moreover, it is essential to note that an SU vehicle sends a request for resource allocation after a random time delay. It is assumed that the HLSA decides on the optimal RSU allocation after collecting the decision results corresponding to the requested SU vehicle's recent location reported in the network to avoid multiple node conflicts. Consequently, for every SU request, the three distant features are computed against all RSUs to formulate a (3 \u00d7 3)-D feature set, as explained earlier. The corresponding training labels are generated by ranking the feature sets based on their optimality using the gray relational analysis (GRA) technique [43].\n\nFurthermore, because each feature value is distinct and has its own unit and range, we cannot just add all of the features together or compute their average to figure out which network node is the best. Instead, we use the GRA technique (explained in the next section) to process all features independently (while assigning equal value to each one). We compute the gray relational coefficients (GRC) [43] for each class and rank the classes according to their GRC scores. The best RSU node for resource allocation in CRAV-Net is the class with the highest GRC score. It allows us to determine the optimality, i.e., the optimal network node for resource routing in the system based on the relative importance of each independent feature. In the proposed study, we apply this heuristic to create true labels for all of the training data.\n\nUsing the labeled data produced by the aforementioned heuristics, we developed the ML technique such that the CRAV-Net framework could automatically determine and allocate the best RSU node (in real time) to handle requests from SU vehicles. In contrast, the heuristics approach [45] is: 1) less viable and computationally costly for time-critical applications, for instance, SS and resource allocation issues, as studied in this article; 2) it is highly responsive to variations in the network's environment, such as CRAV-Net constitutes a dynamic network environment, where there are enormous variations in terms of the signal environment, vehicle behavior, and network environment, as well as the presence of multiple RSUs and SU vehicles in the network may result in inadequate system performance; and 3) it is sensitive to complex problems, in particular with high-dimensional feature space. Thus, ML classifiers are exemplified as a superior strategy in dealing with dynamic problems involving multidimensional domains [45].\n\nWe employed an SVM classifier in CRAV-Net since it was the most flexible with respect to the heuristics. Moreover, compared to other classifiers, SVM yielded the highest performance results [24], [46] (see the supplementary material for more details).   Fig. 4 depicts the block diagram of the SVM classifier utilized in our proposed study during its training and testing phases to determine optimal RSU allocation for resource routing. Next, we will walk through the process of labeling the training data using the GRA-based heuristic method.\n\n\n4) Training Label Generation Using GRA Technique:\n\nIn CRAV-Net, we assume that the requesting SU v vehicle in an HLSA a cluster has p number of learning features and U number of target RSUs (i.e., u = 1, 2, 3, . . . , u, . . . , U), respectively. In order to identify the best RSU node (groundtruth label) for transmission, the GRA technique involves the following steps [43].\n\nStep 1: The target RSUs are mapped across the learning features (in our case, p = 3) to formulate the decision matrix D given as \nD = \u23a1 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a3d\u23a4 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a6(23)\nwhere the rows correlate to the target RSUs in the cluster and columns correlate to the learning features. Each matrix entry d rc relates to measuring the cth learning feature corresponding to the rth target RSU.\n\nStep 2: The decision matrix is normalized using the enhanced max-min process, which involves both cost (lowest is better) and benefit (highest is better) attributes of the features. After the normalization process, the learning features appear dimensionless and unitless, and their value lies in the [0, 1] interval. In the proposed scheme, benefit features include network capacity, stay time, and costly feature involves vehicle density. The normalization of the cth learning feature corresponding to the rth target RSU for benefit features is obtained as follows:\nd p rc = d rc \u2212 min \u2200r {d rc } max \u2200r {d rc } \u2212 min \u2200r {d rc } .(24)\nSimilarly, the normalization of the cth learning feature corresponding to the rth target RSU for cost feature is obtained as follows:\nd p rc = max \u2200r {d rc } \u2212 d rc max \u2200r {d rc } \u2212 min \u2200r {d rc } .(25)\nStep 3: The optimal RSU node is obtained by comparing it with the ideal reference sequence. Generally, if the value of d p rc is equal or nearby 1, the rth target RSU for the cth learning feature is said to be the best among others. Consequently, for the rth target RSU and cth feature, the favored value is 1. Hence, (d * c = 1 for \u2200c = 1, 2, 3) and [111] represent the ideal reference sequence and ideal RSU decision vector, respectively.\n\nStep 4: GRC is used to assess the degree of similarity between d p rc and the ideal reference sequence d * c . GRC can be mathematically stated as follows:\nGRC d p rc , d * c = min \u2200r\u2200c {\u03bb rc } + max \u2200r\u2200c {\u03bb rc } \u03bb rc + max \u2200r\u2200c {\u03bb rc }(26)\nwhere \u03bb rc = |d * c \u2212 d p rc | and \u2208 [0, 1] is the distinguishing coefficient.\n\nStep 5: The GRC ranking is computed as\nGRA u = \u2200c GRC d p rc , d * c .(27)\nStep 6: The highest GRC score represents the optimal RSU node (ground-truth label) in the cluster for resource allocation in CRAV-Net\nRSU u OPTIMAL = arg max u\u2208U {GRA u }.(28)\nIn addition, the DL-based SS model presented in Section II-B is trained using a spectrograms data set to be employed in HLSA to predict the spectrum occupancy in the network. Contrary to this, when the HLSA fails to discover any vacant channels in the PBS within the CRAV-Net framework, the entire spectrum is assumed to be in use, i.e., no spectrum hole is observed for any frequency bands within the PU spectrum throughout the sensing time. In such cases, the HLSA continues to look for spectrum gaps in order to fulfill the incoming demands for service.\n\n\nD. CRAV-Net Execution Complexity\n\nThe proposed system employs two key algorithms (DLbased SS and ML-based resource allocation). The execution complexity of the CRAV-Net at the inference phase (test time) depends jointly on these two algorithms. \n\n\nIII. EXPERIMENTAL SETUP\n\n\nA. System Specifications\n\nThe CRAV-Net is implemented using MATLAB R2021a software installed on a system with 64-bit Windows OS, 16-GB memory, Intel Core i7-7500U@2.90-GHz processor, and an NVIDIA GeForce 940MX graphics processor.\n\n\nB. Key Evaluation Metrics\n\nThe performance of the proposed CRAV-Net for both DL-based SS and ML-based optimal RSU allocation is evaluated using various metrics, including accuracy\n(A = ([T P + T N ]/[T P + T N + F P + F N ])), recall (R = ([T P ]/[T P + F N ])), specificity (S = ([T N ]/[T N + F P ])), precision (P = ([T P ]/[T P + F P ])\n), fall-out (FO = 1 \u2212 S), and miss rate (MR = 1 \u2212 R). Here, T P , T N , F P , and F N represent true positives, true negatives, false positives, and false negatives. For spectrum hole detection, we consider T P as correctly predicted instances of spectrum holes. T N represents the instances when the DL-based model correctly identifies the no spectrum hole spectrograms. Similarly, F P and F N show the incorrectly predicted labels by the model, where F P depicts the false alarm cases when the model wrongly identifies no spectrum hole spectrograms as spectrum hole class. On the other hand, F N are the miss instances when the model falsely rejects the spectrum holes in the network. Moreover, for the RSU allocation task, T P denotes the optimal RSU allocation instances against the SU vehicle request. T N shows the cases when the model correctly denies the nonoptimal RSUs. On the contrary, F P and F N are the false classification labels, where F P marks the cases when nonoptimal RSUs are assigned to serve the requesting SU vehicles, and F N represents the instances when optimal RSU is inaccurately rejected. Fig. 5 depicts the approach we use to compute these four labels against each RSU in a single cluster. Here, the yellow communication links represent the ground truth, while the dotted-colored lines show the SVM-based RSU allocations at HLSA. Furthermore, for any SU vehicle SU v moving across the CRAV-Net, the ground truth and the SVM verdict are dynamic entities and may change over time (t), as shown in Fig. 5. The SU vehicle's location at the time of spectrum request and the corresponding computed features at each RSU in the HLSA are crucial factors in making these determinations. In addition, to analyze the performance of the proposed DL-based SS model in the CRAVNet framework, we use the standard P D versus P FA and P D versus SNR receiver operating characteristic (ROC) performance curves.\n\n\nIV. SIMULATION RESULTS AND DISCUSSION\n\n\nA. Training DL-Based Spectrum Sensing Model\n\nWe used a total of 80 000 spectrograms (40 000 spectrograms each class) for training (60%), validation (20%), and testing (20%) the proposed CRAV-Net framework. Furthermore, in the proposed scheme, we employed the binary cross-entropy loss function (L CE ) to train the DL-based SS model as both the classes spectrum hole and no spectrum hole investigated in this study are mutually exclusive. L CE is measured as expressed in the following: (32) where N is the total observations, \u03c7 is the vector with groundtruth labels, and is the prediction score by the DL-based model. The first component in the summation is zero when the sensed spectrogram is from the spectrum hole class, and the second is zero for the no spectrum hole class. Hence, the loss (L CE ) is calculated solely in relation to the appropriate ground-truth class in each instance, using the model predicted score to balance the impact of the other class. Moreover, we used various augmentation techniques to perturb the spectrograms data at each epoch. The goal of data augmentation is to prevent overfitting and augment data in such a manner that best improves the classifier in terms of domain adaptation against the unseen real-world data. We used four types of transformations for augmenting data (reflection, rotation, scaling, and translation) to enable better generalization characteristics in the model. These transformations introduce geometrical and spatial nonlinearities in the spectrograms. In other words, the adopted data augmentation techniques lead to structural changes and transform the orientation of the original spectrogram by scaling and/or shifting the original pixel's location, depending on the transformation type and parameters used.\nL CE = \u2212 1 N N n=1 \u03c7 n log( n ) + (1 \u2212 \u03c7 n ) log(1 \u2212 n )\nIn addition, we specified the transformation parameters in a small range (as indicated in Table IV), and did not use the coarse parameters for augmenting data, as it can result in the loss of useful information such as high power per frequency components and power spectral density patterns at the central frequency in case of a signal class spectrogram. Fig. 6 shows the four transformations applied to the signal class spectrogram in the proposed research.\n\nFurthermore, a stochastic gradient descent with momentum (SGDM) optimizer is used to update the training parameters of the DL-based SS model. Besides, a minibatch size of 128 is specified to train the network over 7500 iterations in 20 epochs using a 0.001 learning rate. It is pertinent to mention here that the training hyperparameters are adjusted using Bayesian optimization ran over 30 objective function evaluations so as to minimize the classification error on the validation set. Table IV presents the details on hyperparameters used for training and the corresponding ranges to search these through the Bayesian optimization. Refer to the supplementary material for the training performance curves, along with the visualization of the strongest activation channels at various modules of the proposed DL model.  \n\n\nB. Spectrum Sensing Performance of the DL-Based Model\n\nThe trained DL-model for sensing the spectrum holes in CRAV-Net correctly classified 15 959 spectrograms out of 16 000 with 7977 T P (spectrum holes), and 7982 T N (no spectrum holes). On the other hand, the false classification results by the proposed model are only 41, with 23 F N (missed spectrum holes) and 18 F P (falsely classified spectrum holes). Table V shows the classification performance of the proposed DL-based SS model using various evaluation metrics. Here, it can be observed that the proposed model achieved an overall accuracy of 99.74% in accurately classifying the spectrograms of both classes (spectrum hole and no spectrum hole). As observed, the high values for all metrics validate the superior sensing and classification performance of the proposed DL-based SS model in CRAV-Net.\n\n\nC. Spectrum Sensing Performance on Over-the-Air Signals\n\nIn this experiment, the sensing performance of the DL-based model is assessed using the real-world over-the-air (OTA) data. For this purpose, the public RadioML data set [47] is considered, which contains a wide range of real-world modulated signals. Further details and relevant technical specifications about the RadioML data acquisition process, such as frequency range, channel impairments, and the equipment utilized, can be referred from the paper [47]. Besides, it contains 4096 signal frames per modulation type (each frame with 1024 samples length), and the SNR values range from \u221220 to +30 dB.\n\nSpecifically, we created a customized data set for testing and evaluating the proposed DL-based model by considering the signal frames of only five relevant modulations schemes from the RadioML data set (BPSK, QPSK, 8-PSK, 16-QAM, and 64-QAM) as investigated in this study. The constructed custom data set comprises 16 500 OTA signals with 300 randomly chosen frames for each modulation type, covering the whole SNR range from \u221220 down to 0 dB (in 2-dB increment). Furthermore, since the RadioML data set contains time-domain signal frames, we first converted all the frames to spectrograms to test the DL-based SS model.\n\nTo compare the results, we considered four minimalistic DL architectures [35], [48], [49], [50]. The PU-Net [35] is a residual learning-based DL model developed to classify the transmitted signal patterns. It has a network depth of 14 (convolution layers) and contains 52 layers in total. The remaining three models are state-of-the-art pretrained networks, which we have retrained in the proposed research using a transfer learning approach to compare the results. ShuffleNet [48] is a 172-layer network architecture that uses pointwise group convolution and channel shuffling to retain accuracy while reducing computational costs. SqueezeNet [49] is a 26-layer deep network architecture that notably employs 1 \u00d7 1 convolutions in fire modules to \"squeeze\" the number of parameters. MobileNet-v2 [50] is a 53-layer deep network built on an inverted residual structure between bottleneck levels. As a source of nonlinearity, the intermediate expansion layer in the MobileNet-v2 model filters features using lightweight depthwise convolutions [50]. Fig. 7 depicts the proposed DL-based model's SS results compared to the existing methods using the real-world OTA data. It can be observed from Fig. 7 that the proposed DLbased model performed consistently well in terms of SS accuracy for the entire SNR range (\u221220 dB to 0 dB), achieving 0.81% performance gain over the second-best results (PU-Net [35]). Furthermore, considering specifically the low SNR levels of \u221220, \u221218, and \u221216 dB, the proposed model exceeds the second-best results [35] by 1.22%, 0.94%, and 0.93%, respectively. It shows the efficacy and robustness of the proposed model against the real-world data in terms of accurately sensing the PU signals for locating the spectral holes even at low SNR levels.\n\n\nD. Comparison of Communication Performance With State-of-the-Art Detectors\n\nThe detection probability P D (the probability of recognizing the PU as being there while the PU is present) and the false alarm probability P FA (the probability of recognizing the PU as being there while the PU is actually absent) are two important performance metrics that characterize the communication performance of CR users (SUs) in CRNs. An SU's SS performance is quantified by its ability to reach a target P D and P FA at a particular SNR [24]. The simulation results in Fig. 8 correspond to the ROC performance curves, where the comparative analysis of the proposed DL-based SS model is presented with traditional and existing DL-based methods. First, the performance is evaluated in terms of P D versus P FA . We generated a separate data set for this purpose. It contains 8000 signal spectrograms at \u221215-dB SNR, where 1000 spectrograms belong to each of the eight modulation types investigated in this study. Furthermore, to cater to the effect of P FA , we modified the default classification threshold (T C = 0.5) of the proposed DL-based model as T C = 1\u2212P FA . In other words, the confidence score (C S ) for the PU signal spectrograms (i.e., no spectrum hole class) at the softmax layer is challenged, such that the condition C S \u2265 T C needs to be satisfied to obtain correct detection of the PU signals.\n\nMoreover, we varied P FA between 0 and 1 with 0.01 step size and calculated the average detection probability over the complete data set (8000 spectrograms) at each P FA level to plot the ROC curves, as shown in Fig. 8(a) and (b). First, we present the comparison of the proposed model with traditional schemes (MED [51], SSE [52], and AGM [52]) in terms of PU signal detection, as shown in Fig. 8(a). Here, we can observe the superior performance of the proposed DL-based method for all P FA levels. Furthermore, considering detection probability at the low P FA level of 0.1, the proposed model exceeds the second-best results (SSE [52]) by a neat margin of 66.67%. The higher performance, in this case, is because the proposed DL-based model does not require any prior information about the radio environment, such as signal-noise distribution and their prior probabilities, which is essential to traditional schemes. Next, we compared the proposed model performance with other state-of-the-art DL methods (CNN-LSTM [37], APASS [33], and PU-Net [35]), as shown in Fig. 8(b). Here, it can be observed that the proposed DL-based SS model's detection probability converges quickly compared to the other methods, and it outperforms the second-best results (PU-Net) by 0.22% in terms of the AUC metric.\n\nIn another experiment, the SS performance of the proposed DL-based model is compared using P D versus SNR ROC curves. We generated another local data set for this experiment. It consists of 20 800 signal spectrograms, where 2600 spectrograms belong to each of the eight modulation types investigated in this study. Furthermore, these 2600 spectrograms for each modulation category are generated using 26 different SNR levels between \u221225 and 0 dB, with 1-dB increment (100 spectrograms per SNR level). Moreover, P FA in this experiment is specified as 0.1. We measured the average detection probability over the complete data set for each SNR level to plot the ROC curves, as shown in Fig. 8(c) and (d). The comparison of the proposed DL-based model with traditional schemes (MED [51], SSE [52], AGM [52], Max-min [53], and Entropy [54]) is presented in Fig. 8(c). Here, it can be observed that the proposed method achieves considerable gain over the other methods and exceeds the second-best method (SSE [52]) by a neat gap of 58.53% in terms of the AUC metric. Furthermore, Fig. 8(d) shows the detection performance of the proposed model with its DL competitors (CNN-LSTM [37], APASS [33], DetectNet [34], [55], and PU-Net [35]). From the results in Fig 8(d), it can be observed that the proposed model achieved superior results, especially in the low SNR regimes. Besides, it brings a performance gain of 12.60% compared to the second-best detector (PU-Net [35]) and 118.75% over the third-best results (CNN-LSTM [37]) at as low as \u221225-dB SNR.\n\n\nE. Performance Evaluation of ML-Based Optimal Allocation of RSUs\n\nThis section evaluates the trained SVM classifier for the optimal allocation of RSUs against the spectrum access requests received from the SU vehicles in the CRAV-Net framework. For this experiment, we consider a single cluster administered by its cluster head HLSA a | a=1 , which manages and routes the spectrum access requests of SU vehicles in the network to three RSUs RSU u | 3 u\u21921 within its jurisdiction. Besides, HLSA a is directly connected to the serving PBS and periodically senses the PU spectrum using the proposed DLbased SS model to locate and maintain the SHT of vacant frequency bands. Furthermore, each RSU u in HLSA a has a coverage area of 500 m. Moreover, we randomly distributed 500 moving vehicles SU v | 500 v\u21921 within the geographical area of HLSA a , where each SU v is enabled to raise a spectrum access request at any point in time. These spectrum access requests are received by the nearest RSU u , which are then forwarded to the cluster head HLSA a for optimal allocation of the node. For each request received, the HLSA a first checks for the available spectrum hole in the SHT, and then performs the SVM-based optimal RSU u allocation using a formulated (3 \u00d7 3)-D feature set FS(v). The corresponding ground-truth data against all the spectrum access requests are generated using the heuristics scheme explained earlier in Sections II-C3 and II-C4.\n\nThe HLSA a performance in terms of RSU u allocation is evaluated using the predictive labels (T P , T N , F P , and F N ), as shown in Table VI. Furthermore, Table VI displays the groundtruth information about the number of spectrum requests the HLSA a should ideally assign to the corresponding RSU u in the cluster. In other words, for any given RSU u , the ground-truth values would be the total number of T P . Ideally, the SVMbased allocations at HLSA a for each RSU u should match the associated ground-truth data. First, from Table VI, the overall ground-truth value of 472 suggests that the proposed DLbased model in the HLSA can successfully detect the spectrum holes against 472 requests out of the 500 requests received. It shows the higher spectrum availability of around 94.40%, which, in turn, demonstrates the superior SS performance of the proposed DL-based model in the cluster head HLSA a for the identification and utilization of vacant frequency bands. Furthermore, HLSA a formulates (3 \u00d7 3)-D FS(v) against these 472 requests for optimal allocation of RSU u using the SVM classifier. Table VI shows that the correct classification labels (T P and T N ) for the optimal allocations of each RSU u are considerably more significant than the false classification labels (F P and F N ). It verifies that in the proposed CRAV-Net framework, the SVM classifier in the cluster head HLSA a is adequately trained using the three distinctive features. It correctly allocates the optimal RSUs against most of the spectrum access requests raised by the SU vehicles in the network. Apart from this, the higher values of other metrics, such as accuracy, recall, and specificity also demonstrate the effectiveness of the proposed SS and allocation scheme in the CRAV-Net framework. Furthermore, the low miss and fallout rates (less than 0.02%) show that only a small fraction of RSU u instances are allocated incorrectly in the proposed scheme.  [23], ML [56], [57], and DL [34], [37], [48], [49], [50], [55], [58] frameworks, considering network size and computing complexity. As indicated in Table VII, we first report on the performance comparison between conventional and ML methods based on different metrics. Here, we see that other methods require less training and inference time than the proposed DL-based model. Nevertheless, there is a tradeoff between time and accuracy. As observed, the GLRT [23] and SVM [56] methods have the fastest inference times, needing just 0.01 ms for SS. However, when accuracy is taken into consideration, the proposed DL-based model outperforms the second-best results (GLRT [23]) by 3.59%, indicating a significant increase in classification performance over the GLRT [23] method. Therefore, in contrast to the conventional and ML methods described in Table VII, the proposed approach exhibits a superior sensing performance at the cost of higher computing complexity and processing time.\n\nMoreover, Table VIII presents a comparison between the proposed and other DL methods. Here, we present the differences and similarities in training and inference time, network depth, number of layers and parameters, and classification accuracy. As observed, the proposed DL-based model requires 1087 s for training. A further characteristic of the proposed model is that it needs an average time of just 0.09 ms to classify a single spectrogram once trained. 2) ML-Based Resource Allocation: In this experiment, we compared the performance of the trained SVM classifier with other state-of-the-art methods in terms of accuracy and allocation time, as shown in Table IX. Here, it can be observed that the proposed model outperformed the second-best results by 0.63% and 18.32% in terms of accuracy and allocation time, respectively.\n\n\nV. DISCUSSION\n\nEfficient communication or routing protocols are essential for IoV networks to function properly, which account for the unique features of vehicular networks (such as mobility, congestion, scarcity, or asymmetry in the distribution of vehicles, and disruptions in communication caused by frequent topological changes). Besides, many safety applications in IoV networks are delay sensitive, in which even a microsecond of delay might have catastrophic results. Edge clouds, on the other hand, have storage and computing resource constraints; as a result, many delay-tolerant processes and applications, such as nonsafety applications delivering value-added services ranging from information to entertainment, must be processed in a centralized cloud environment. In order to meet the challenges that arise in a highly dynamic IoV environment, complete vehicular connectivity must be established. In this context, cluster-based communication and routing protocols are considered the best solution for addressing these issues in vehicular networks and the expectations for stable, dependable, scalable, and bandwidth-optimized networks while minimizing the hidden node problem [59].\n\nGiven the above, this research presents a novel sensing and communication integrated framework (CRAV-Net) using a cluster-based hybrid optimization approach with adaptive congestion-aware modeling for dynamic high-mobility vehicular networks. The target of the proposed research is to allocate the idle channel or spectrum resource to the SU via the optimal node in the network. The objective is to facilitate the requesting user to opportunistically establish a communication link (when PU is idle) for data transmission. In this work, we opted for a hybrid learning (combined DL and SVM) solution to determine the optimal spectrum access node (RSU in the cluster) against each SU vehicle request (w.r.t. the availability of spectrum holes, and the best route for resource allocation at HLSA) to maintain a traffic load balance in the overall network environment. We employed the DL technique for SS as we used the visual data (spectrograms) for this purpose, and the proposed DL model performed exceptionally well in automatically learning the distinguishable features from the input data without the need for manual feature extraction from the complex spectrograms.\n\nHowever, the resource allocation task is somewhat different from the SS in the proposed research scenario. For this purpose and to determine the optimal RSU node, we considered three different features (vehicle stay time, vehicle density, and network capacity), considering the dynamic IoV network. These features are computed using mathematical expressions to formulate a 3-D feature set. Also, we found it simpler to develop the heuristic approach for labeling the optimal node from the limited samples (feature sets) and train the supervised SVM classifier based on it. The trained SVM in this way also achieved excellent performance in accurately identifying the optimal node. Moreover, compared to the DL method for resource allocation, the proposed SVM-based approach is more computationally efficient and requires far less training and inference time as well as training data.\n\nFurthermore, the HLSA in the proposed research acts as a centric entity and intelligent cluster head responsible for decision-making tasks and on which the performance of the CRAV-Net model largely depends. In the current scenario, we assumed a single PBS and multiple HLSAs are serving under a single PBS while the coverage is extended through RSUs. In addition, to avoid communication bottlenecks, HLSA can exchange its resources and operational information (such as signal environment, vehicle failure, congestion, and road conditions) with other nodes in its local zone via infrastructure-to-infrastructure (I2I) connectivity in an emergency state [59].\n\nThe optimality of the HLSA cluster is based on both the DL-based SS and ML-based resource allocation performances. In other words, both the classifiers in HLSA must be adequately trained and achieve maximum training accuracy for the ideal functioning of the HLSA. If any of the algorithms in HLSA gives a suboptimal performance, it will affect the overall performance of the CRAV-Net framework. For instance, an inadequately trained DL model will lead to interferences and communication disruptions between the PU and SU despite allocating the optimal RSU node for resource routing through a properly trained ML classifier. Similarly, the poorly trained ML model will lead to improper RSU node allocation, resulting in delays and communication cutoffs. Moreover, a worst case scenario when both the ML and DL classifiers of HLSA are not sufficiently trained will severely affect the network performance, such as joint interference and communication delays. Therefore, adequate training of both the classifiers of HLSA is essential to achieving optimal SS and allocation performance. Nevertheless, Tables V and VI show that both the DL-based model and SVM-based classifier in the proposed research showcased superior performances with 99.74% and 98.45% accuracy in terms of SS and RSU allocation tasks, respectively.\n\nIn addition to that, we evaluated the SS performance of the proposed DL model using the real-world OTA signals, as shown in Fig. 7. Here, the performance comparison is presented with existing DL-based methods regarding PU detection accuracy over a range of SNR. As observed, the proposed model performs better than the existing schemes. Similarly, in another experiment, we evaluated the communication performance of the proposed DL-based detector in terms of P D versus P FA and P D versus SNR ROC curves. It can be observed from Fig. 8 that the proposed model converges quickly [ Fig. 8(a) and (b)] and performs consistently well with high PU detection probability even at low SNR levels [ Fig. 8(c) and (d)] when compared to the other schemes.\n\nHowever, some issues must also be addressed before AIbased solutions such as CRAV-Net can be easily adopted and deployed. From a deployment perspective, the major practical challenges include the planning network topology to install a minimum number of nodes (HLSAs and RSUs) and ensure maximum coverage in an urban city environment. Besides, power management is another issue as these network nodes require a power supply to operate. Although wired nodes are quite simple, these are confined to the hardline that connects them to the network and supplies power. In CRAV-Net, wireless and battery-powered nodes are a far more versatile option. However, such network nodes also introduce a new set of issues, such as power consumption and network connection. Another critical challenge in deploying the CRAV-Net is to provide and maintain solid and secure connectivity solutions with minimum interferences, which can arise due to different interconnected network entities.\n\nMoreover, implementing adequate protocols is critical for the CRAV-Net paradigm to govern the communication between the central entity (HLSA) and the nodes (RSU, PBS). It involves requesting nodes to sense an allocated spectrum channel and notifying the concerned nodes in case of any changes. Furthermore, there are additional issues with interoperability and compatibility of numerous communication standards. It is essential to provide multitechnological support to ensure the seamless functioning of different nodes in the CRAV-Net framework. Besides, obtaining precise knowledge is unachievable in a dynamic wireless environment, particularly in intelligent communication networks, where various factors are fully considered to optimize performance. Furthermore, proper transfer of information incurs unacceptably high costs. As a result, the latest research should be conducted to dynamically allocate resources while considering weak PU signals, the uncertainty of channel state information, imperfect SS, or a noisy sensing environment with considerable variations that might impair the sensing performance in CRNs.\n\nIn the future scope of this work, we can expand the CRAV-Net framework to more complicated and dynamic vehicular network deployment scenarios, such as those involving multiple HLSAs, PUs, and an increase in the number of RSUs and SU vehicles in the network. Another object of future research in CR-based IoV networks is to find ways to alleviate interference problems, which are one of the most severe limits on the temporal and spectral reuse of limited resources in the high-mobility radio environment that IoV networks operate in. For example, by utilizing beamforming antennas and cooperative relays, the performance of CRAV-Net can be explored. Furthermore, we can investigate the effectiveness of CRAV-Net by utilizing reinforcement learning [31] for resource allocation or by employing multitask learning-driven DNNs [60] for SS and resource allocation tasks in CRAV-Net.\n\n\nVI. CONCLUSION\n\nTo achieve the goals of enhanced spectrum efficiency and intelligent management and control of vehicular network resources, a novel congestion-aware hybrid learning solution in a cluster-based CRAV-Net was described and evaluated. The CRAV-Net framework comprised intelligent HLSAs that initially perform SS based on DL to detect spectrum holes (vacant frequency bands in the PU spectrum). Next, using a trained SVM classifier, it designated those frequency bands to the requesting SU vehicles via the best possible route in the network. Furthermore, the SS and resource allocation performance of CRAV-Net was evaluated across a number of critical parameters, with simulation results demonstrating the efficacy of the proposed scheme in terms of detection probability, sensing and allocation accuracy, and ROC performance curves when compared to the existing state-of-the-art methods.\n\n\n), installed within the coverage area of the PBS and follow a uniform distribution. Also, there are V number of SU vehicles (i.e.,v = 1, 2, 3, . . . , v, . . . , V)deployed in the\n\nFig. 1 .\n1CRAV-Net system model for 5G-based IoV networks in an urban city scenario.\n\nFig. 2 .\n2DL-based SS model architecture. M = Module, ASPP = Atrous spatial pyramid pooling.\n\nFig. 3 .\n3SU vehicles stay time calculation in the CRAV-Net framework.\n\n\nFor DL-based methods, each layer performs the matrix multiplications and activations, resulting in execution complexity of N M (number of multiplications) + N A (number of activations). Here, N M has an asymptotic runtime of O(n 3 ) because the matrices are quadratic and have equal rows and columns. Besides, N A is an elementwise activation function with O(n) runtime. Moreover, these operations are performed at each layer, where the total layers are equal to the number of neurons in a single layer. Therefore, the N M runtime becomes equal to O(n * n 3 ) = O(n 4 ), and, similarly, N A has a runtime of O(n * n) = O(n 2 ). Hence, the total execution complexity of the proposed DL-based model becomes O(n 4 + n 2 ). On the other hand, we employed radial basis function (RBF) kernel SVM to perform the allocation of RSU nodes. It has a linear complexity O(n) on the number of support vectors and linear on the number of features O(n). Therefore, the inference phase execution complexity of the proposed SVM turns out to be O(n * n) = O(n 2 ). Moreover, the total execution complexity of the proposed CRAV-Net framework can be expressed as EC = DL + SVM (29) EC = O(n 4 + n 2 ) + O(n 2 ) (30) EC = O(n 4 + n 2 + n 2 ).\n\nFig. 5 .\n5Representation of true positives (T P ), true negatives (T N ), false positives (F P ), and false negatives (F N ) in the CRAV-Net framework.\n\nFig. 6 .\n6Augmentation techniques: (a) original spectrogram, (b) reflection, (c) rotation, (d) scaling, (e) translation, and (f) multiple transformations.\n\nFig. 7 .\n7Performance comparison of the DL-based SS model on OTA signals.\n\nFig. 8 .\n8P D versus P FA performance comparison of the DL-based SS model: (a) traditional methods and (b) DL-based methods. P D versus SNR performance comparison of the DL-based SS model: (c) traditional methods and (d) DL-based methods.\n\nTABLE I SUMMARY\nIOF EXISTING AI-BASED WORKS ON SS AND SA to identify vehicular congestion or traffic jams on highways.\n\nTABLE II LIST\nIIOF ABBREVIATIONS\n\n\nTable III details the simulation setup used during SVM training and provides parameter values for calculating the proposed scheme's learning features. Furthermore,\n\nTABLE III SIMULATION\nIIIENVIRONMENT FOR SVM TRAINING Fig. 4. Block diagram of the SVM classifier's training and testing phases.\n\nTABLE IV DETAILS\nIVOF DATA AUGMENTATIONS AND HYPERPARAMETERS SELECTION FOR THE DL-BASED SS MODEL TRAINING\n\nTABLE V VALIDATION\nVOF DL-BASED SS MODEL OVER THE COMPLETE TESTING DATA SET USING VARIOUS EVALUATION METRICS\n\nTABLE VI VALIDATION\nVIOF ML-BASED OPTIMAL ALLOCATION OF RSUS USING VARIOUS EVALUATION METRICS\n\nTABLE VII PERFORMANCE\nVIICOMPARISON IN TERMS OF COMPUTATIONAL COMPLEXITY WITH STATE-OF-THE-ART TRADITIONAL AND ML METHODS. THE BEST AND SECOND-BEST RESULTS ARE SHOWN IN BOLD AND UNDERLINE, RESPECTIVELYTABLE VIII \nPERFORMANCE COMPARISON IN TERMS OF COMPUTATIONAL \nCOMPLEXITY WITH STATE-OF-THE-ART DL METHODS. THE BEST AND \nSECOND-BEST RESULTS ARE SHOWN IN BOLD \nAND UNDERLINE, RESPECTIVELY \n\nF. Comparison of Model Complexity and Accuracy \n\n1) DL-Based Spectrum Sensing: In this experiment, we \nfirst compare the proposed DL-based SS model performance \nwith various conventional \n\nTABLE IX PERFORMANCE\nIXCOMPARISON IN TERMS OF ACCURACY AND ALLOCATION TIME WITH STATE-OF-THE-ART METHODS. THE BEST AND SECOND-BEST RESULTS ARE SHOWN IN BOLD AND UNDERLINE, RESPECTIVELYSimilarly, among other DL methods shown inTable VIII, the proposed model obtained the highest accuracy of 99.74%, representing a 0.46% increase over the second-best results (ShuffleNet[48]). Furthermore, with only 0.3 million parameters, the proposed DL-based model also has a comparatively minimalistic design that enables an efficient training and processing of new spectrograms. Besides, it can be observed fromTable VIIIthat the proposed method reduces the training time by 6.72% (CNN-LSTM[37]) and the inference time by 33.33% (SqueezeNet[49]) compared to the second-best results.\n\nA vision of 6G wireless systems: Applications, trends, technologies, and open research problems. W Saad, M Bennis, M Chen, IEEE Netw. 343W. Saad, M. Bennis, and M. Chen, \"A vision of 6G wireless systems: Applications, trends, technologies, and open research problems,\" IEEE Netw., vol. 34, no. 3, pp. 134-142, May/Jun. 2020.\n\nIntegrated sensing and communications: Towards dualfunctional wireless networks for 6G and beyond. F Liu, IEEE J. Sel. Areas Commun. 406F. Liu et al., \"Integrated sensing and communications: Towards dual- functional wireless networks for 6G and beyond,\" IEEE J. Sel. Areas Commun., vol. 40, no. 6, pp. 1728-1767, Jun. 2022.\n\nIntegrating sensing and communications for ubiquitous IoT: Applications, trends, and challenges. Y Cui, F Liu, X Jing, J Mu, IEEE Netw. 355Y. Cui, F. Liu, X. Jing, and J. Mu, \"Integrating sensing and communi- cations for ubiquitous IoT: Applications, trends, and challenges,\" IEEE Netw., vol. 35, no. 5, pp. 158-167, Sep./Oct. 2022.\n\nConstrained utility maximization in dual-functional radar-communication multi-UAV networks. X Wang, Z Fei, J A Zhang, J Huang, J Yuan, IEEE Trans. Commun. 694X. Wang, Z. Fei, J. A. Zhang, J. Huang, and J. Yuan, \"Constrained utility maximization in dual-functional radar-communication multi-UAV networks,\" IEEE Trans. Commun., vol. 69, no. 4, pp. 2660-2672, Apr. 2021.\n\nWiFi sensing with channel state information: A survey. Y Ma, G Zhou, S Wang, ACM Comput. Surveys. 523Y. Ma, G. Zhou, and S. Wang, \"WiFi sensing with channel state information: A survey,\" ACM Comput. Surveys, vol. 52, no. 3, pp. 1-36, 2019.\n\nIntegrated sensing and communication-enabled predictive beamforming with deep learning in vehicular networks. J Mu, Y Gong, F Zhang, Y Cui, F Zheng, X Jing, IEEE Commun. Lett. 2510J. Mu, Y. Gong, F. Zhang, Y. Cui, F. Zheng, and X. Jing, \"Integrated sensing and communication-enabled predictive beamforming with deep learning in vehicular networks,\" IEEE Commun. Lett., vol. 25, no. 10, pp. 3301-3304, Oct. 2021.\n\nDesign and performance evaluation of joint sensing and communication integrated system for 5G mmWave enabled CAVs. Q Zhang, X Wang, Z Li, Z Wei, IEEE J. Sel. Topics Signal Process. 156Q. Zhang, X. Wang, Z. Li, and Z. Wei, \"Design and performance eval- uation of joint sensing and communication integrated system for 5G mmWave enabled CAVs,\" IEEE J. Sel. Topics Signal Process., vol. 15, no. 6, pp. 1500-1514, Nov. 2021.\n\nOn the performance of cognitive Internet-of-Vehicles with unlicensed user-mobility and licensed user-activity. D B Rawat, R Alsabet, C Bajracharya, M Song, Comput. Netw. 137D. B. Rawat, R. Alsabet, C. Bajracharya, and M. Song, \"On the performance of cognitive Internet-of-Vehicles with unlicensed user-mobility and licensed user-activity,\" Comput. Netw., vol. 137, pp. 98-106, Jun. 2018.\n\nA secured and efficient communication scheme for decentralized cognitive radio-based Internet of vehicles. W Yao, IEEE Access. 7W. Yao et al., \"A secured and efficient communication scheme for decen- tralized cognitive radio-based Internet of vehicles,\" IEEE Access, vol. 7, pp. 160889-160900, 2019.\n\nSecure enforcement in cognitive Internet of Vehicles. Y Qian, M Chen, J Chen, M S Hossain, A Alamri, IEEE Internet Things J. 52Y. Qian, M. Chen, J. Chen, M. S. Hossain, and A. Alamri, \"Secure enforcement in cognitive Internet of Vehicles,\" IEEE Internet Things J., vol. 5, no. 2, pp. 1242-1250, Apr. 2018.\n\nChallenges to IoT-enabled predictive maintenance for industry 4.0. M Compare, P Baraldi, E Zio, IEEE Internet Things J. 75M. Compare, P. Baraldi, and E. Zio, \"Challenges to IoT-enabled predictive maintenance for industry 4.0,\" IEEE Internet Things J., vol. 7, no. 5, pp. 4585-4597, May 2020.\n\nSEADNet: Deep learning driven segmentation and extraction of macular fluids in 3D retinal OCT scans. B Hassan, S Qin, R Ahmed, Proc. IEEE Int. Symp. Signal Process. Inf. Technol. (ISSPIT). IEEE Int. Symp. Signal ess. Inf. Technol. (ISSPIT)B. Hassan, S. Qin, and R. Ahmed, \"SEADNet: Deep learning driven segmentation and extraction of macular fluids in 3D retinal OCT scans,\" in Proc. IEEE Int. Symp. Signal Process. Inf. Technol. (ISSPIT), 2020, pp. 1-6.\n\nRRI-Net: Classification of multiclass retinal diseases with deep recurrent residual inception network using OCT scans. B Hassan, S Qin, R Ahmed, Proc. IEEE Int. Symp. Signal Process. Inf. Technol. (ISSPIT). IEEE Int. Symp. Signal ess. Inf. Technol. (ISSPIT)B. Hassan, S. Qin, and R. Ahmed, \"RRI-Net: Classification of multi- class retinal diseases with deep recurrent residual inception network using OCT scans,\" in Proc. IEEE Int. Symp. Signal Process. Inf. Technol. (ISSPIT), 2020, pp. 1-6.\n\nCDC-Net: Cascaded decoupled convolutional network for lesionassisted detection and grading of retinopathy using optical coherence tomography (OCT) scans. B Hassan, S Qin, T Hassan, M U Akram, R Ahmed, N Werghi, Biomed. Signal Process. Control. 70Art. no. 103030B. Hassan, S. Qin, T. Hassan, M. U. Akram, R. Ahmed, and N. Werghi, \"CDC-Net: Cascaded decoupled convolutional network for lesion- assisted detection and grading of retinopathy using optical coherence tomography (OCT) scans,\" Biomed. Signal Process. Control, vol. 70, Sep. 2021, Art. no. 103030.\n\nDeep learning based joint segmentation and characterization of multi-class retinal fluid lesions on OCT scans for clinical use in anti-VEGF therapy. B Hassan, Comput. Biol. Med. 136Art. no. 104727B. Hassan et al., \"Deep learning based joint segmentation and charac- terization of multi-class retinal fluid lesions on OCT scans for clinical use in anti-VEGF therapy,\" Comput. Biol. Med., vol. 136, Sep. 2021, Art. no. 104727.\n\nJoint segmentation and quantification of chorioretinal biomarkers in optical coherence tomography scans: A deep learning approach. B Hassan, S Qin, T Hassan, R Ahmed, N Werghi, IEEE Trans. Instrum. Meas. 70B. Hassan, S. Qin, T. Hassan, R. Ahmed, and N. Werghi, \"Joint segmen- tation and quantification of chorioretinal biomarkers in optical coherence tomography scans: A deep learning approach,\" IEEE Trans. Instrum. Meas., vol. 70, pp. 1-17, May 2021.\n\nAn imperceptible medical image watermarking framework for automated diagnosis of retinal pathologies in an eHealth arrangement. B Hassan, R Ahmed, B Li, O Hassan, IEEE Access. 7B. Hassan, R. Ahmed, B. Li, and O. Hassan, \"An imperceptible medical image watermarking framework for automated diagnosis of retinal pathologies in an eHealth arrangement,\" IEEE Access, vol. 7, pp. 69758-69775, 2019.\n\nRobust hybrid watermarking for security of medical images in computer-aided diagnosis based telemedicine applications. R Ahmed, B Hassan, B Li, Proc. IEEE Int. Symp. Signal Process. IEEE Int. Symp. Signal essR. Ahmed, B. Hassan, and B. Li, \"Robust hybrid watermarking for secu- rity of medical images in computer-aided diagnosis based telemedicine applications,\" in Proc. IEEE Int. Symp. Signal Process. Inf. Technol. (ISSPIT), 2018, pp. 1-5.\n\nVehicle communications via wireless access vehicular environment. M D Nathanson, N Fairbanks, U.S. Patent. 9M. D. Nathanson and N. Fairbanks, \"Vehicle communications via wire- less access vehicular environment,\" U.S. Patent 9 503 968, Nov. 22, 2016.\n\nChannel access optimization with adaptive congestion pricing for cognitive vehicular networks: An evolutionary game approach. D Tian, J Zhou, Y Wang, Z Sheng, X Duan, V C M Leung, IEEE Trans. Mobile Comput. 194D. Tian, J. Zhou, Y. Wang, Z. Sheng, X. Duan, and V. C. M. Leung, \"Channel access optimization with adaptive congestion pricing for cog- nitive vehicular networks: An evolutionary game approach,\" IEEE Trans. Mobile Comput., vol. 19, no. 4, pp. 803-820, Apr. 2020.\n\nSpectrum assignment in cognitive radio networks for Internet-of-Things delaysensitive applications under jamming attacks. H A B Salameh, S Almajali, M Ayyash, H Elgala, IEEE Internet Things J. 53H. A. B. Salameh, S. Almajali, M. Ayyash, and H. Elgala, \"Spectrum assignment in cognitive radio networks for Internet-of-Things delay- sensitive applications under jamming attacks,\" IEEE Internet Things J., vol. 5, no. 3, pp. 1904-1913, Jun. 2018.\n\nA reliable energy efficient dynamic spectrum sensing for cognitive radio IoT networks. J A Ansere, G Han, H Wang, C Choi, C Wu, IEEE Internet Things J. 64J. A. Ansere, G. Han, H. Wang, C. Choi, and C. Wu, \"A reliable energy efficient dynamic spectrum sensing for cognitive radio IoT networks,\" IEEE Internet Things J., vol. 6, no. 4, pp. 6748-6759, Aug. 2019.\n\nOptimal spectrum sensing in MIMO-based cognitive radio wireless sensor network (CR-WSN) using GLRT with noise uncertainty at low SNR. R Ahmed, Y Chen, B Hassan, AEU-Int. J. Electron. Commun. 136Art. no. 153741R. Ahmed, Y. Chen, and B. Hassan, \"Optimal spectrum sensing in MIMO-based cognitive radio wireless sensor network (CR-WSN) using GLRT with noise uncertainty at low SNR,\" AEU-Int. J. Electron. Commun., vol. 136, Jul. 2021, Art. no. 153741.\n\nCR-IoTNet: Machine learning based joint spectrum sensing and allocation for cognitive radio enabled IoT cellular networks. R Ahmed, Y Chen, B Hassan, L Du, Ad Hoc Netw. 112Art. no. 102390R. Ahmed, Y. Chen, B. Hassan, and L. Du, \"CR-IoTNet: Machine learning based joint spectrum sensing and allocation for cognitive radio enabled IoT cellular networks,\" Ad Hoc Netw., vol. 112, Mar. 2021, Art. no. 102390.\n\nWideband collaborative spectrum sensing using massive MIMO decision fusion. I Dey, D Ciuonzo, P S Rossi, IEEE Trans. Wireless Commun. 198I. Dey, D. Ciuonzo, and P. S. Rossi, \"Wideband collaborative spectrum sensing using massive MIMO decision fusion,\" IEEE Trans. Wireless Commun., vol. 19, no. 8, pp. 5246-5260, Aug. 2020.\n\nOrthogonality and cooperation in collaborative spectrum sensing through MIMO decision fusion. P S Rossi, D Ciuonzo, G Romano, IEEE Trans. Wireless Commun. 1211P. S. Rossi, D. Ciuonzo, and G. Romano, \"Orthogonality and cooperation in collaborative spectrum sensing through MIMO decision fusion,\" IEEE Trans. Wireless Commun., vol. 12, no. 11, pp. 5826-5836, Nov. 2013.\n\nAsymptotic performance of collaborative spectrum sensing under correlated log-normal shadowing. A Ghasemi, E S Sousa, IEEE Commun. Lett. 111A. Ghasemi and E. S. Sousa, \"Asymptotic performance of collabora- tive spectrum sensing under correlated log-normal shadowing,\" IEEE Commun. Lett., vol. 11, no. 1, pp. 34-36, Jan. 2007.\n\nCognitive radio-enabled Internet of Vehicles: A cooperative spectrum sensing and allocation for vehicular communication. J Eze, S Zhang, E Liu, E Eze, IET Netw. 74J. Eze, S. Zhang, E. Liu, and E. Eze, \"Cognitive radio-enabled Internet of Vehicles: A cooperative spectrum sensing and allocation for vehicular communication,\" IET Netw., vol. 7, no. 4, pp. 190-199, 2018.\n\nMU-MIMO based cognitive radio in Internet of Vehicles (IoV) for enhanced spectrum sensing accuracy and sum rate. M A Hossain, M Schukat, E Barrett, Proc. IEEE 93rd Veh. Technol. Conf. (VTC2021-Spring). IEEE 93rd Veh. Technol. Conf. (VTC2021-Spring)M. A. Hossain, M. Schukat, and E. Barrett, \"MU-MIMO based cogni- tive radio in Internet of Vehicles (IoV) for enhanced spectrum sensing accuracy and sum rate,\" in Proc. IEEE 93rd Veh. Technol. Conf. (VTC2021-Spring), 2021, pp. 1-7.\n\nBeam alignment-based mmwave spectrum sensing in cognitive vehicular networks. H Zhang, C Guo, Proc. IEEE Glob. Conf. Signal Inf. Process. (GlobalSIP). IEEE Glob. Conf. Signal Inf. ess. (GlobalSIP)H. Zhang and C. Guo, \"Beam alignment-based mmwave spectrum sens- ing in cognitive vehicular networks,\" in Proc. IEEE Glob. Conf. Signal Inf. Process. (GlobalSIP), 2019, pp. 1-5.\n\nReinforcement learning enabled dynamic resource allocation in the Internet of Vehicles. H Liang, IEEE Trans. Ind. Informat. 177H. Liang et al., \"Reinforcement learning enabled dynamic resource allo- cation in the Internet of Vehicles,\" IEEE Trans. Ind. Informat., vol. 17, no. 7, pp. 4957-4967, Jul. 2021.\n\nConnected vehicles: Solutions and challenges. N Lu, N Cheng, N Zhang, X Shen, J W Mark, IEEE Internet Things J. 14N. Lu, N. Cheng, N. Zhang, X. Shen, and J. W. Mark, \"Connected vehicles: Solutions and challenges,\" IEEE Internet Things J., vol. 1, no. 4, pp. 289-299, Aug. 2014.\n\nActivity pattern aware spectrum sensing: A CNN-based deep learning approach. J Xie, C Liu, Y.-C Liang, J Fang, IEEE Commun. Lett. 236J. Xie, C. Liu, Y.-C. Liang, and J. Fang, \"Activity pattern aware spectrum sensing: A CNN-based deep learning approach,\" IEEE Commun. Lett., vol. 23, no. 6, pp. 1025-1028, Jun. 2019.\n\nDeep learning for spectrum sensing. J Gao, X Yi, C Zhong, X Chen, Z Zhang, IEEE Wireless Commun. Lett. 86J. Gao, X. Yi, C. Zhong, X. Chen, and Z. Zhang, \"Deep learning for spectrum sensing,\" IEEE Wireless Commun. Lett., vol. 8, no. 6, pp. 1727-1730, Dec. 2019.\n\nDeep residual learning-based cognitive model for detection and classification of transmitted signal patterns in 5G smart city networks. R Ahmed, Y Chen, B Hassan, Digit. Signal Process. 120Art. no. 103290R. Ahmed, Y. Chen, and B. Hassan, \"Deep residual learning-based cog- nitive model for detection and classification of transmitted signal patterns in 5G smart city networks,\" Digit. Signal Process., vol. 120, Jan. 2022, Art. no. 103290.\n\nDeep learning-driven opportunistic spectrum access (OSA) framework for cognitive 5G and beyond 5G (B5G) networks. R Ahmed, Y Chen, B Hassan, Ad Hoc Netw. 123Art. no. 102632R. Ahmed, Y. Chen, and B. Hassan, \"Deep learning-driven opportunistic spectrum access (OSA) framework for cognitive 5G and beyond 5G (B5G) networks,\" Ad Hoc Netw., vol. 123, Dec. 2021, Art. no. 102632.\n\nDeep learning-based spectrum sensing in cognitive radio: A CNN-LSTM approach. J Xie, J Fang, C Liu, X Li, IEEE Commun. Lett. 2410J. Xie, J. Fang, C. Liu, and X. Li, \"Deep learning-based spectrum sens- ing in cognitive radio: A CNN-LSTM approach,\" IEEE Commun. Lett., vol. 24, no. 10, pp. 2196-2200, Oct. 2020.\n\nResource allocation based on deep neural networks for cognitive radio networks. F Zhou, X Zhang, R Q Hu, A Papathanassiou, W Meng, Proc. IEEE/CIC Int. Conf. Commun. China (ICCC). IEEE/CIC Int. Conf. Commun. China (ICCC)F. Zhou, X. Zhang, R. Q. Hu, A. Papathanassiou, and W. Meng, \"Resource allocation based on deep neural networks for cognitive radio networks,\" in Proc. IEEE/CIC Int. Conf. Commun. China (ICCC), 2018, pp. 40-45.\n\nDeep reinforcement learning for resource allocation in V2V communications. H Ye, G Y Li, Proc. IEEE Int. Conf. Commun. (ICC). IEEE Int. Conf. Commun. (ICC)H. Ye and G. Y. Li, \"Deep reinforcement learning for resource allocation in V2V communications,\" in Proc. IEEE Int. Conf. Commun. (ICC), 2018, pp. 1-6.\n\nDeep reinforcement learning-based spectrum allocation in integrated access and backhaul networks. W Lei, Y Ye, M Xiao, IEEE Trans. Cogn. Commun. Netw. 63W. Lei, Y. Ye, and M. Xiao, \"Deep reinforcement learning-based spec- trum allocation in integrated access and backhaul networks,\" IEEE Trans. Cogn. Commun. Netw., vol. 6, no. 3, pp. 970-979, Sep. 2020.\n\nA deep reinforcement learning based approach for energy-efficient channel allocation in satellite Internet of Things. B Zhao, J Liu, Z Wei, I You, IEEE Access. 8B. Zhao, J. Liu, Z. Wei, and I. You, \"A deep reinforcement learn- ing based approach for energy-efficient channel allocation in satellite Internet of Things,\" IEEE Access, vol. 8, pp. 62197-62206, 2020.\n\nProactive resource management for LTE in unlicensed spectrum: A deep learning perspective. U Challita, L Dong, W Saad, IEEE Trans. Wireless Commun. 177U. Challita, L. Dong, and W. Saad, \"Proactive resource management for LTE in unlicensed spectrum: A deep learning perspective,\" IEEE Trans. Wireless Commun., vol. 17, no. 7, pp. 4674-4689, Jul. 2018.\n\nApplication aware networks' resource selection decision making technique using group mobility in vehicular cognitive radio networks. M S Gupta, K Kumar, Veh. Commun. 26Art. no. 100263M. S. Gupta and K. Kumar, \"Application aware networks' resource selection decision making technique using group mobility in vehic- ular cognitive radio networks,\" Veh. Commun., vol. 26, Dec. 2020, Art. no. 100263.\n\nMulti-column Atrous convolutional neural network for counting metro passengers. J Zhang, G Zhu, Z Wang, Symmetry. 124682J. Zhang, G. Zhu, and Z. Wang, \"Multi-column Atrous convolutional neural network for counting metro passengers,\" Symmetry, vol. 12, no. 4, p. 682, 2020.\n\nIntegrating heuristic and machine-learning methods for efficient virtual machine allocation in data centers. A Pahlevan, X Qu, M Zapater, D Atienza, IEEE Trans. Comput.-Aided Design Integr. Circuits Syst. 378A. Pahlevan, X. Qu, M. Zapater, and D. Atienza, \"Integrating heuristic and machine-learning methods for efficient virtual machine allocation in data centers,\" IEEE Trans. Comput.-Aided Design Integr. Circuits Syst., vol. 37, no. 8, pp. 1667-1680, Aug. 2018.\n\nA survey on feature selection methods. G Chandrashekar, F Sahin, Comput. Elect. Eng. 401G. Chandrashekar and F. Sahin, \"A survey on feature selection methods,\" Comput. Elect. Eng., vol. 40, no. 1, pp. 16-28, 2014.\n\nOver-the-air deep learning based radio signal classification. T J Shea, T Roy, T C Clancy, IEEE J. Sel. Topics Signal Process. 121T. J. O'Shea, T. Roy, and T. C. Clancy, \"Over-the-air deep learning based radio signal classification,\" IEEE J. Sel. Topics Signal Process., vol. 12, no. 1, pp. 168-179, Feb. 2018.\n\nShufflenet: An extremely efficient convolutional neural network for mobile devices. X Zhang, X Zhou, M Lin, J Sun, Proc. IEEE Conf. Comput. Vis. IEEE Conf. Comput. VisX. Zhang, X. Zhou, M. Lin, and J. Sun, \"Shufflenet: An extremely efficient convolutional neural network for mobile devices,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2018, pp. 6848-6856.\n\nSqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size. F N Iandola, S Han, M W Moskewicz, K Ashraf, W J Dally, K Keutzer, arXiv:1602.07360F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and K. Keutzer, \"SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size,\" 2016, arXiv:1602.07360.\n\nMobileNetV2: Inverted residuals and linear bottlenecks. M Sandler, A Howard, M Zhu, A Zhmoginov, L.-C Chen, Proc. IEEE Conf. Comput. Vis Pattern Recognit. IEEE Conf. Comput. Vis Pattern RecognitM. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, \"MobileNetV2: Inverted residuals and linear bottlenecks,\" in Proc. IEEE Conf. Comput. Vis Pattern Recognit., 2018, pp. 4510-4520.\n\nMaximum eigenvalue detection: Theory and application. Y Zeng, C L Koh, Y.-C Liang, Proc. IEEE Int. Conf. Commun. IEEE Int. Conf. CommunY. Zeng, C. L. Koh, and Y.-C. Liang, \"Maximum eigenvalue detec- tion: Theory and application,\" in Proc. IEEE Int. Conf. Commun., 2008, pp. 4160-4164.\n\nMulti-antenna based spectrum sensing for cognitive radios: A GLRT approach. R Zhang, T J Lim, Y.-C Liang, Y Zeng, IEEE Trans. Commun. 581R. Zhang, T. J. Lim, Y.-C. Liang, and Y. Zeng, \"Multi-antenna based spectrum sensing for cognitive radios: A GLRT approach,\" IEEE Trans. Commun., vol. 58, no. 1, pp. 84-88, Jan. 2010.\n\nEigenvalue-based spectrum sensing algorithms for cognitive radio. Y Zeng, Y.-C Liang, IEEE Trans. Commun. 576Y. Zeng and Y.-C. Liang, \"Eigenvalue-based spectrum sensing algo- rithms for cognitive radio,\" IEEE Trans. Commun., vol. 57, no. 6, pp. 1784-1793, Jun. 2009.\n\nEntropy-based robust spectrum sensing in cognitive radio. Y Zhang, Q Zhang, S Wu, IET Commun. 44Y. Zhang, Q. Zhang, and S. Wu, \"Entropy-based robust spectrum sensing in cognitive radio,\" IET Commun., vol. 4, no. 4, pp. 428-436, 2010.\n\nSpectrum sensing based on deep learning classification for cognitive radios. S Zheng, S Chen, P Qi, H Zhou, X Yang, China Commun. 172S. Zheng, S. Chen, P. Qi, H. Zhou, and X. Yang, \"Spectrum sens- ing based on deep learning classification for cognitive radios,\" China Commun., vol. 17, no. 2, pp. 138-148, 2020.\n\nEnsemble classifier based spectrum sensing in cognitive radio networks. H B Ahmad, Wireless Commun. Mobile Comput. 2019Art. no. 9250562H. B. Ahmad, \"Ensemble classifier based spectrum sensing in cogni- tive radio networks,\" Wireless Commun. Mobile Comput., vol. 2019, Jan. 2019, Art. no. 9250562.\n\nImproving energy detection in cognitive radio systems using machine learning. T O Fajemilehin, A Yahya, K Langat, J. Commun. 151T. O. Fajemilehin, A. Yahya, and K. Langat, \"Improving energy detec- tion in cognitive radio systems using machine learning,\" J. Commun., vol. 15, no. 1, pp. 74-80, 2020.\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitK. He, X. Zhang, S. Ren, and J. Sun, \"Deep residual learning for image recognition,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016, pp. 770-778.\n\nA comprehensive survey on clustering in vehicular networks: Current solutions and future challenges. M Ayyub, A Oracevic, R Hussain, A A Khan, Z Zhang, Ad Hoc Netw. 124Art. no. 102729M. Ayyub, A. Oracevic, R. Hussain, A. A. Khan, and Z. Zhang, \"A comprehensive survey on clustering in vehicular networks: Current solutions and future challenges,\" Ad Hoc Netw., vol. 124, Jan. 2022, Art. no. 102729.\n\nMultitask-learningbased deep neural network for automatic modulation classification. S Chang, S Huang, R Zhang, Z Feng, L Liu, IEEE Internet Things J. 93S. Chang, S. Huang, R. Zhang, Z. Feng, and L. Liu, \"Multitask-learning- based deep neural network for automatic modulation classification,\" IEEE Internet Things J., vol. 9, no. 3, pp. 2192-2206, Feb. 2022.\n", "annotations": {"author": "[{\"end\":190,\"start\":149},{\"end\":234,\"start\":191},{\"end\":270,\"start\":235},{\"end\":281,\"start\":271},{\"end\":332,\"start\":282},{\"end\":384,\"start\":333},{\"end\":397,\"start\":385},{\"end\":405,\"start\":398},{\"end\":419,\"start\":406},{\"end\":431,\"start\":420},{\"end\":577,\"start\":432},{\"end\":693,\"start\":578},{\"end\":888,\"start\":694},{\"end\":1066,\"start\":889},{\"end\":1126,\"start\":1067}]", "publisher": null, "author_last_name": "[{\"end\":161,\"start\":156},{\"end\":214,\"start\":210},{\"end\":247,\"start\":241},{\"end\":280,\"start\":278},{\"end\":307,\"start\":301},{\"end\":362,\"start\":358},{\"end\":396,\"start\":392},{\"end\":418,\"start\":412},{\"end\":430,\"start\":426}]", "author_first_name": "[{\"end\":155,\"start\":149},{\"end\":209,\"start\":203},{\"end\":240,\"start\":235},{\"end\":277,\"start\":271},{\"end\":300,\"start\":294},{\"end\":357,\"start\":352},{\"end\":391,\"start\":385},{\"end\":404,\"start\":398},{\"end\":411,\"start\":406},{\"end\":425,\"start\":420}]", "author_affiliation": "[{\"end\":576,\"start\":433},{\"end\":692,\"start\":579},{\"end\":887,\"start\":695},{\"end\":1065,\"start\":890},{\"end\":1125,\"start\":1068}]", "title": "[{\"end\":130,\"start\":1},{\"end\":1256,\"start\":1127}]", "venue": "[{\"end\":1289,\"start\":1258}]", "abstract": "[{\"end\":3470,\"start\":1711}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3994,\"start\":3991},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3999,\"start\":3996},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4273,\"start\":4270},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4673,\"start\":4670},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4813,\"start\":4810},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4833,\"start\":4830},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4873,\"start\":4870},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4878,\"start\":4875},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4981,\"start\":4978},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5237,\"start\":5234},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5345,\"start\":5342},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5480,\"start\":5477},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5630,\"start\":5627},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5869,\"start\":5866},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6064,\"start\":6061},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6203,\"start\":6199},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6370,\"start\":6366},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6376,\"start\":6372},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6382,\"start\":6378},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6399,\"start\":6395},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6405,\"start\":6401},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6411,\"start\":6407},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6426,\"start\":6422},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6432,\"start\":6428},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6690,\"start\":6687},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6789,\"start\":6786},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7168,\"start\":7165},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7486,\"start\":7483},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7641,\"start\":7637},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7796,\"start\":7792},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7933,\"start\":7930},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8061,\"start\":8057},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8067,\"start\":8063},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8167,\"start\":8163},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8215,\"start\":8211},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8487,\"start\":8483},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8493,\"start\":8489},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8499,\"start\":8495},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8665,\"start\":8661},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8778,\"start\":8774},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8937,\"start\":8933},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9435,\"start\":9431},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9550,\"start\":9546},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9556,\"start\":9552},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9773,\"start\":9769},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9897,\"start\":9893},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10025,\"start\":10021},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10148,\"start\":10144},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10154,\"start\":10150},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":10281,\"start\":10277},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10287,\"start\":10283},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":10306,\"start\":10302},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10461,\"start\":10457},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":10548,\"start\":10544},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":10916,\"start\":10912},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10932,\"start\":10928},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":11060,\"start\":11056},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":11261,\"start\":11257},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":11380,\"start\":11376},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":15911,\"start\":15907},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":22752,\"start\":22748},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":23654,\"start\":23650},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":24554,\"start\":24551},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":26358,\"start\":26354},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":27400,\"start\":27396},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":28977,\"start\":28973},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":32541,\"start\":32537},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":32948,\"start\":32944},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":33664,\"start\":33660},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":34410,\"start\":34406},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":34607,\"start\":34603},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":34613,\"start\":34609},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":35334,\"start\":35330},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":41437,\"start\":41433},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":45155,\"start\":45151},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":45439,\"start\":45435},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":46286,\"start\":46282},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":46292,\"start\":46288},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":46298,\"start\":46294},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":46304,\"start\":46300},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":46321,\"start\":46317},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":46690,\"start\":46686},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":46857,\"start\":46853},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":47010,\"start\":47006},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":47255,\"start\":47251},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":47609,\"start\":47605},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":47749,\"start\":47745},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":48512,\"start\":48508},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":49703,\"start\":49699},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":49713,\"start\":49709},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":49727,\"start\":49723},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":50021,\"start\":50017},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":50406,\"start\":50402},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":50418,\"start\":50414},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":50435,\"start\":50431},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":51468,\"start\":51464},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":51478,\"start\":51474},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":51488,\"start\":51484},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":51502,\"start\":51498},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":51520,\"start\":51516},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":51693,\"start\":51689},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":51862,\"start\":51858},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":51874,\"start\":51870},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":51890,\"start\":51886},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":51896,\"start\":51892},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":51913,\"start\":51909},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":52148,\"start\":52144},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":52204,\"start\":52200},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":55639,\"start\":55635},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":55648,\"start\":55644},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":55654,\"start\":55650},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":55667,\"start\":55663},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":55673,\"start\":55669},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":55679,\"start\":55675},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":55685,\"start\":55681},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":55691,\"start\":55687},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":55697,\"start\":55693},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":55703,\"start\":55699},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":56098,\"start\":56094},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":56111,\"start\":56107},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":56309,\"start\":56305},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":56403,\"start\":56399},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":58648,\"start\":58644},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":61362,\"start\":61358},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":66280,\"start\":66276},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":66356,\"start\":66352},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":71305,\"start\":71301},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":71614,\"start\":71610},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":71664,\"start\":71660}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":67491,\"start\":67310},{\"attributes\":{\"id\":\"fig_1\"},\"end\":67577,\"start\":67492},{\"attributes\":{\"id\":\"fig_2\"},\"end\":67671,\"start\":67578},{\"attributes\":{\"id\":\"fig_3\"},\"end\":67743,\"start\":67672},{\"attributes\":{\"id\":\"fig_4\"},\"end\":68966,\"start\":67744},{\"attributes\":{\"id\":\"fig_5\"},\"end\":69119,\"start\":68967},{\"attributes\":{\"id\":\"fig_6\"},\"end\":69275,\"start\":69120},{\"attributes\":{\"id\":\"fig_7\"},\"end\":69350,\"start\":69276},{\"attributes\":{\"id\":\"fig_8\"},\"end\":69590,\"start\":69351},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":69710,\"start\":69591},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":69744,\"start\":69711},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":69910,\"start\":69745},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":70039,\"start\":69911},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":70146,\"start\":70040},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":70256,\"start\":70147},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":70351,\"start\":70257},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":70931,\"start\":70352},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":71702,\"start\":70932}]", "paragraph": "[{\"end\":4274,\"start\":3489},{\"end\":5238,\"start\":4276},{\"end\":6204,\"start\":5240},{\"end\":6691,\"start\":6206},{\"end\":7169,\"start\":6693},{\"end\":7934,\"start\":7190},{\"end\":9126,\"start\":7936},{\"end\":10155,\"start\":9128},{\"end\":10793,\"start\":10157},{\"end\":11826,\"start\":10795},{\"end\":12374,\"start\":11828},{\"end\":12870,\"start\":12399},{\"end\":15087,\"start\":12872},{\"end\":15579,\"start\":15107},{\"end\":16067,\"start\":15581},{\"end\":16599,\"start\":16146},{\"end\":17851,\"start\":16601},{\"end\":18178,\"start\":17853},{\"end\":19957,\"start\":18247},{\"end\":20718,\"start\":19999},{\"end\":21447,\"start\":20720},{\"end\":22056,\"start\":21449},{\"end\":22862,\"start\":22058},{\"end\":24977,\"start\":22917},{\"end\":25448,\"start\":25036},{\"end\":26180,\"start\":25488},{\"end\":26360,\"start\":26182},{\"end\":26747,\"start\":26433},{\"end\":26957,\"start\":26807},{\"end\":27017,\"start\":27013},{\"end\":27197,\"start\":27082},{\"end\":27416,\"start\":27323},{\"end\":27714,\"start\":27585},{\"end\":28134,\"start\":27903},{\"end\":28446,\"start\":28172},{\"end\":28528,\"start\":28475},{\"end\":28677,\"start\":28565},{\"end\":28978,\"start\":28744},{\"end\":29336,\"start\":29025},{\"end\":29528,\"start\":29421},{\"end\":30264,\"start\":29571},{\"end\":30462,\"start\":30310},{\"end\":31255,\"start\":30464},{\"end\":31705,\"start\":31409},{\"end\":32542,\"start\":31754},{\"end\":33379,\"start\":32544},{\"end\":34411,\"start\":33381},{\"end\":34956,\"start\":34413},{\"end\":35335,\"start\":35010},{\"end\":35466,\"start\":35337},{\"end\":35719,\"start\":35507},{\"end\":36287,\"start\":35721},{\"end\":36490,\"start\":36357},{\"end\":37000,\"start\":36560},{\"end\":37157,\"start\":37002},{\"end\":37321,\"start\":37243},{\"end\":37361,\"start\":37323},{\"end\":37531,\"start\":37398},{\"end\":38130,\"start\":37574},{\"end\":38378,\"start\":38167},{\"end\":38637,\"start\":38433},{\"end\":38819,\"start\":38667},{\"end\":40903,\"start\":38981},{\"end\":42719,\"start\":40991},{\"end\":43235,\"start\":42777},{\"end\":44057,\"start\":43237},{\"end\":44921,\"start\":44115},{\"end\":45584,\"start\":44981},{\"end\":46207,\"start\":45586},{\"end\":47980,\"start\":46209},{\"end\":49381,\"start\":48059},{\"end\":50683,\"start\":49383},{\"end\":52230,\"start\":50685},{\"end\":53682,\"start\":52299},{\"end\":56619,\"start\":53684},{\"end\":57452,\"start\":56621},{\"end\":58649,\"start\":57470},{\"end\":59819,\"start\":58651},{\"end\":60704,\"start\":59821},{\"end\":61363,\"start\":60706},{\"end\":62680,\"start\":61365},{\"end\":63428,\"start\":62682},{\"end\":64401,\"start\":63430},{\"end\":65526,\"start\":64403},{\"end\":66406,\"start\":65528},{\"end\":67309,\"start\":66425}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":16145,\"start\":16068},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18246,\"start\":18179},{\"attributes\":{\"id\":\"formula_2\"},\"end\":22916,\"start\":22863},{\"attributes\":{\"id\":\"formula_3\"},\"end\":26432,\"start\":26361},{\"attributes\":{\"id\":\"formula_4\"},\"end\":26806,\"start\":26748},{\"attributes\":{\"id\":\"formula_5\"},\"end\":27012,\"start\":26958},{\"attributes\":{\"id\":\"formula_6\"},\"end\":27081,\"start\":27018},{\"attributes\":{\"id\":\"formula_7\"},\"end\":27322,\"start\":27198},{\"attributes\":{\"id\":\"formula_8\"},\"end\":27584,\"start\":27417},{\"attributes\":{\"id\":\"formula_9\"},\"end\":27902,\"start\":27715},{\"attributes\":{\"id\":\"formula_10\"},\"end\":28171,\"start\":28135},{\"attributes\":{\"id\":\"formula_11\"},\"end\":28474,\"start\":28447},{\"attributes\":{\"id\":\"formula_12\"},\"end\":28564,\"start\":28529},{\"attributes\":{\"id\":\"formula_13\"},\"end\":28743,\"start\":28678},{\"attributes\":{\"id\":\"formula_14\"},\"end\":29024,\"start\":28979},{\"attributes\":{\"id\":\"formula_15\"},\"end\":29420,\"start\":29337},{\"attributes\":{\"id\":\"formula_16\"},\"end\":29570,\"start\":29529},{\"attributes\":{\"id\":\"formula_17\"},\"end\":30309,\"start\":30265},{\"attributes\":{\"id\":\"formula_18\"},\"end\":31305,\"start\":31256},{\"attributes\":{\"id\":\"formula_19\"},\"end\":31408,\"start\":31305},{\"attributes\":{\"id\":\"formula_20\"},\"end\":35487,\"start\":35467},{\"attributes\":{\"id\":\"formula_21\"},\"end\":35506,\"start\":35487},{\"attributes\":{\"id\":\"formula_22\"},\"end\":36356,\"start\":36288},{\"attributes\":{\"id\":\"formula_23\"},\"end\":36559,\"start\":36491},{\"attributes\":{\"id\":\"formula_24\"},\"end\":37242,\"start\":37158},{\"attributes\":{\"id\":\"formula_25\"},\"end\":37397,\"start\":37362},{\"attributes\":{\"id\":\"formula_26\"},\"end\":37573,\"start\":37532},{\"attributes\":{\"id\":\"formula_28\"},\"end\":38980,\"start\":38820},{\"attributes\":{\"id\":\"formula_29\"},\"end\":42776,\"start\":42720}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":11603,\"start\":11596},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":15020,\"start\":15011},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":42876,\"start\":42867},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":43733,\"start\":43725},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":44478,\"start\":44471},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":53827,\"start\":53819},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":53850,\"start\":53842},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":54225,\"start\":54217},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":54797,\"start\":54789},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":55792,\"start\":55783},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":56492,\"start\":56483},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":56641,\"start\":56631},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":57289,\"start\":57281}]", "section_header": "[{\"end\":3487,\"start\":3472},{\"end\":7188,\"start\":7172},{\"end\":12397,\"start\":12377},{\"end\":15105,\"start\":15090},{\"end\":19997,\"start\":19960},{\"end\":25034,\"start\":24980},{\"end\":25486,\"start\":25451},{\"end\":31752,\"start\":31708},{\"end\":35008,\"start\":34959},{\"end\":38165,\"start\":38133},{\"end\":38404,\"start\":38381},{\"end\":38431,\"start\":38407},{\"end\":38665,\"start\":38640},{\"end\":40943,\"start\":40906},{\"end\":40989,\"start\":40946},{\"end\":44113,\"start\":44060},{\"end\":44979,\"start\":44924},{\"end\":48057,\"start\":47983},{\"end\":52297,\"start\":52233},{\"end\":57468,\"start\":57455},{\"end\":66423,\"start\":66409},{\"end\":67501,\"start\":67493},{\"end\":67587,\"start\":67579},{\"end\":67681,\"start\":67673},{\"end\":68976,\"start\":68968},{\"end\":69129,\"start\":69121},{\"end\":69285,\"start\":69277},{\"end\":69360,\"start\":69352},{\"end\":69607,\"start\":69592},{\"end\":69725,\"start\":69712},{\"end\":69932,\"start\":69912},{\"end\":70057,\"start\":70041},{\"end\":70166,\"start\":70148},{\"end\":70277,\"start\":70258},{\"end\":70374,\"start\":70353},{\"end\":70953,\"start\":70933}]", "table": "[{\"end\":70931,\"start\":70554}]", "figure_caption": "[{\"end\":67491,\"start\":67312},{\"end\":67577,\"start\":67503},{\"end\":67671,\"start\":67589},{\"end\":67743,\"start\":67683},{\"end\":68966,\"start\":67746},{\"end\":69119,\"start\":68978},{\"end\":69275,\"start\":69131},{\"end\":69350,\"start\":69287},{\"end\":69590,\"start\":69362},{\"end\":69710,\"start\":69609},{\"end\":69744,\"start\":69728},{\"end\":69910,\"start\":69747},{\"end\":70039,\"start\":69936},{\"end\":70146,\"start\":70060},{\"end\":70256,\"start\":70168},{\"end\":70351,\"start\":70280},{\"end\":70554,\"start\":70378},{\"end\":71702,\"start\":70956}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15401,\"start\":15395},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20830,\"start\":20824},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":23848,\"start\":23842},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26333,\"start\":26327},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26739,\"start\":26733},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":30172,\"start\":30166},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":31237,\"start\":31231},{\"end\":34673,\"start\":34667},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":35190,\"start\":35156},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":40106,\"start\":40100},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":40513,\"start\":40507},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":43138,\"start\":43132},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":47263,\"start\":47257},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":47407,\"start\":47401},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":48546,\"start\":48540},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":49612,\"start\":49595},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":49783,\"start\":49774},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":50459,\"start\":50450},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":51386,\"start\":51369},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":51547,\"start\":51538},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":51769,\"start\":51760},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":51944,\"start\":51936},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":62812,\"start\":62806},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":63219,\"start\":63213},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":63281,\"start\":63264},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":63380,\"start\":63374}]", "bib_author_first_name": "[{\"end\":71802,\"start\":71801},{\"end\":71810,\"start\":71809},{\"end\":71820,\"start\":71819},{\"end\":72130,\"start\":72129},{\"end\":72453,\"start\":72452},{\"end\":72460,\"start\":72459},{\"end\":72467,\"start\":72466},{\"end\":72475,\"start\":72474},{\"end\":72782,\"start\":72781},{\"end\":72790,\"start\":72789},{\"end\":72797,\"start\":72796},{\"end\":72799,\"start\":72798},{\"end\":72808,\"start\":72807},{\"end\":72817,\"start\":72816},{\"end\":73114,\"start\":73113},{\"end\":73120,\"start\":73119},{\"end\":73128,\"start\":73127},{\"end\":73410,\"start\":73409},{\"end\":73416,\"start\":73415},{\"end\":73424,\"start\":73423},{\"end\":73433,\"start\":73432},{\"end\":73440,\"start\":73439},{\"end\":73449,\"start\":73448},{\"end\":73828,\"start\":73827},{\"end\":73837,\"start\":73836},{\"end\":73845,\"start\":73844},{\"end\":73851,\"start\":73850},{\"end\":74245,\"start\":74244},{\"end\":74247,\"start\":74246},{\"end\":74256,\"start\":74255},{\"end\":74267,\"start\":74266},{\"end\":74282,\"start\":74281},{\"end\":74630,\"start\":74629},{\"end\":74878,\"start\":74877},{\"end\":74886,\"start\":74885},{\"end\":74894,\"start\":74893},{\"end\":74902,\"start\":74901},{\"end\":74904,\"start\":74903},{\"end\":74915,\"start\":74914},{\"end\":75198,\"start\":75197},{\"end\":75209,\"start\":75208},{\"end\":75220,\"start\":75219},{\"end\":75525,\"start\":75524},{\"end\":75535,\"start\":75534},{\"end\":75542,\"start\":75541},{\"end\":75999,\"start\":75998},{\"end\":76009,\"start\":76008},{\"end\":76016,\"start\":76015},{\"end\":76528,\"start\":76527},{\"end\":76538,\"start\":76537},{\"end\":76545,\"start\":76544},{\"end\":76555,\"start\":76554},{\"end\":76557,\"start\":76556},{\"end\":76566,\"start\":76565},{\"end\":76575,\"start\":76574},{\"end\":77081,\"start\":77080},{\"end\":77489,\"start\":77488},{\"end\":77499,\"start\":77498},{\"end\":77506,\"start\":77505},{\"end\":77516,\"start\":77515},{\"end\":77525,\"start\":77524},{\"end\":77940,\"start\":77939},{\"end\":77950,\"start\":77949},{\"end\":77959,\"start\":77958},{\"end\":77965,\"start\":77964},{\"end\":78326,\"start\":78325},{\"end\":78335,\"start\":78334},{\"end\":78345,\"start\":78344},{\"end\":78717,\"start\":78716},{\"end\":78719,\"start\":78718},{\"end\":78732,\"start\":78731},{\"end\":79028,\"start\":79027},{\"end\":79036,\"start\":79035},{\"end\":79044,\"start\":79043},{\"end\":79052,\"start\":79051},{\"end\":79061,\"start\":79060},{\"end\":79069,\"start\":79068},{\"end\":79073,\"start\":79070},{\"end\":79499,\"start\":79498},{\"end\":79503,\"start\":79500},{\"end\":79514,\"start\":79513},{\"end\":79526,\"start\":79525},{\"end\":79536,\"start\":79535},{\"end\":79909,\"start\":79908},{\"end\":79911,\"start\":79910},{\"end\":79921,\"start\":79920},{\"end\":79928,\"start\":79927},{\"end\":79936,\"start\":79935},{\"end\":79944,\"start\":79943},{\"end\":80317,\"start\":80316},{\"end\":80326,\"start\":80325},{\"end\":80334,\"start\":80333},{\"end\":80755,\"start\":80754},{\"end\":80764,\"start\":80763},{\"end\":80772,\"start\":80771},{\"end\":80782,\"start\":80781},{\"end\":81114,\"start\":81113},{\"end\":81121,\"start\":81120},{\"end\":81132,\"start\":81131},{\"end\":81134,\"start\":81133},{\"end\":81457,\"start\":81456},{\"end\":81459,\"start\":81458},{\"end\":81468,\"start\":81467},{\"end\":81479,\"start\":81478},{\"end\":81828,\"start\":81827},{\"end\":81839,\"start\":81838},{\"end\":81841,\"start\":81840},{\"end\":82180,\"start\":82179},{\"end\":82187,\"start\":82186},{\"end\":82196,\"start\":82195},{\"end\":82203,\"start\":82202},{\"end\":82542,\"start\":82541},{\"end\":82544,\"start\":82543},{\"end\":82555,\"start\":82554},{\"end\":82566,\"start\":82565},{\"end\":82988,\"start\":82987},{\"end\":82997,\"start\":82996},{\"end\":83373,\"start\":83372},{\"end\":83638,\"start\":83637},{\"end\":83644,\"start\":83643},{\"end\":83653,\"start\":83652},{\"end\":83662,\"start\":83661},{\"end\":83670,\"start\":83669},{\"end\":83672,\"start\":83671},{\"end\":83948,\"start\":83947},{\"end\":83955,\"start\":83954},{\"end\":83965,\"start\":83961},{\"end\":83974,\"start\":83973},{\"end\":84224,\"start\":84223},{\"end\":84231,\"start\":84230},{\"end\":84237,\"start\":84236},{\"end\":84246,\"start\":84245},{\"end\":84254,\"start\":84253},{\"end\":84586,\"start\":84585},{\"end\":84595,\"start\":84594},{\"end\":84603,\"start\":84602},{\"end\":85005,\"start\":85004},{\"end\":85014,\"start\":85013},{\"end\":85022,\"start\":85021},{\"end\":85344,\"start\":85343},{\"end\":85351,\"start\":85350},{\"end\":85359,\"start\":85358},{\"end\":85366,\"start\":85365},{\"end\":85657,\"start\":85656},{\"end\":85665,\"start\":85664},{\"end\":85674,\"start\":85673},{\"end\":85676,\"start\":85675},{\"end\":85682,\"start\":85681},{\"end\":85700,\"start\":85699},{\"end\":86083,\"start\":86082},{\"end\":86089,\"start\":86088},{\"end\":86091,\"start\":86090},{\"end\":86414,\"start\":86413},{\"end\":86421,\"start\":86420},{\"end\":86427,\"start\":86426},{\"end\":86790,\"start\":86789},{\"end\":86798,\"start\":86797},{\"end\":86805,\"start\":86804},{\"end\":86812,\"start\":86811},{\"end\":87128,\"start\":87127},{\"end\":87140,\"start\":87139},{\"end\":87148,\"start\":87147},{\"end\":87522,\"start\":87521},{\"end\":87524,\"start\":87523},{\"end\":87533,\"start\":87532},{\"end\":87867,\"start\":87866},{\"end\":87876,\"start\":87875},{\"end\":87883,\"start\":87882},{\"end\":88170,\"start\":88169},{\"end\":88182,\"start\":88181},{\"end\":88188,\"start\":88187},{\"end\":88199,\"start\":88198},{\"end\":88567,\"start\":88566},{\"end\":88584,\"start\":88583},{\"end\":88805,\"start\":88804},{\"end\":88807,\"start\":88806},{\"end\":88815,\"start\":88814},{\"end\":88822,\"start\":88821},{\"end\":88824,\"start\":88823},{\"end\":89139,\"start\":89138},{\"end\":89148,\"start\":89147},{\"end\":89156,\"start\":89155},{\"end\":89163,\"start\":89162},{\"end\":89506,\"start\":89505},{\"end\":89508,\"start\":89507},{\"end\":89519,\"start\":89518},{\"end\":89526,\"start\":89525},{\"end\":89528,\"start\":89527},{\"end\":89541,\"start\":89540},{\"end\":89551,\"start\":89550},{\"end\":89553,\"start\":89552},{\"end\":89562,\"start\":89561},{\"end\":89837,\"start\":89836},{\"end\":89848,\"start\":89847},{\"end\":89858,\"start\":89857},{\"end\":89865,\"start\":89864},{\"end\":89881,\"start\":89877},{\"end\":90221,\"start\":90220},{\"end\":90229,\"start\":90228},{\"end\":90231,\"start\":90230},{\"end\":90241,\"start\":90237},{\"end\":90529,\"start\":90528},{\"end\":90538,\"start\":90537},{\"end\":90540,\"start\":90539},{\"end\":90550,\"start\":90546},{\"end\":90559,\"start\":90558},{\"end\":90841,\"start\":90840},{\"end\":90852,\"start\":90848},{\"end\":91101,\"start\":91100},{\"end\":91110,\"start\":91109},{\"end\":91119,\"start\":91118},{\"end\":91355,\"start\":91354},{\"end\":91364,\"start\":91363},{\"end\":91372,\"start\":91371},{\"end\":91378,\"start\":91377},{\"end\":91386,\"start\":91385},{\"end\":91663,\"start\":91662},{\"end\":91665,\"start\":91664},{\"end\":91967,\"start\":91966},{\"end\":91969,\"start\":91968},{\"end\":91984,\"start\":91983},{\"end\":91993,\"start\":91992},{\"end\":92235,\"start\":92234},{\"end\":92241,\"start\":92240},{\"end\":92250,\"start\":92249},{\"end\":92257,\"start\":92256},{\"end\":92610,\"start\":92609},{\"end\":92619,\"start\":92618},{\"end\":92631,\"start\":92630},{\"end\":92642,\"start\":92641},{\"end\":92644,\"start\":92643},{\"end\":92652,\"start\":92651},{\"end\":92994,\"start\":92993},{\"end\":93003,\"start\":93002},{\"end\":93012,\"start\":93011},{\"end\":93021,\"start\":93020},{\"end\":93029,\"start\":93028}]", "bib_author_last_name": "[{\"end\":71807,\"start\":71803},{\"end\":71817,\"start\":71811},{\"end\":71825,\"start\":71821},{\"end\":72134,\"start\":72131},{\"end\":72457,\"start\":72454},{\"end\":72464,\"start\":72461},{\"end\":72472,\"start\":72468},{\"end\":72478,\"start\":72476},{\"end\":72787,\"start\":72783},{\"end\":72794,\"start\":72791},{\"end\":72805,\"start\":72800},{\"end\":72814,\"start\":72809},{\"end\":72822,\"start\":72818},{\"end\":73117,\"start\":73115},{\"end\":73125,\"start\":73121},{\"end\":73133,\"start\":73129},{\"end\":73413,\"start\":73411},{\"end\":73421,\"start\":73417},{\"end\":73430,\"start\":73425},{\"end\":73437,\"start\":73434},{\"end\":73446,\"start\":73441},{\"end\":73454,\"start\":73450},{\"end\":73834,\"start\":73829},{\"end\":73842,\"start\":73838},{\"end\":73848,\"start\":73846},{\"end\":73855,\"start\":73852},{\"end\":74253,\"start\":74248},{\"end\":74264,\"start\":74257},{\"end\":74279,\"start\":74268},{\"end\":74287,\"start\":74283},{\"end\":74634,\"start\":74631},{\"end\":74883,\"start\":74879},{\"end\":74891,\"start\":74887},{\"end\":74899,\"start\":74895},{\"end\":74912,\"start\":74905},{\"end\":74922,\"start\":74916},{\"end\":75206,\"start\":75199},{\"end\":75217,\"start\":75210},{\"end\":75224,\"start\":75221},{\"end\":75532,\"start\":75526},{\"end\":75539,\"start\":75536},{\"end\":75548,\"start\":75543},{\"end\":76006,\"start\":76000},{\"end\":76013,\"start\":76010},{\"end\":76022,\"start\":76017},{\"end\":76535,\"start\":76529},{\"end\":76542,\"start\":76539},{\"end\":76552,\"start\":76546},{\"end\":76563,\"start\":76558},{\"end\":76572,\"start\":76567},{\"end\":76582,\"start\":76576},{\"end\":77088,\"start\":77082},{\"end\":77496,\"start\":77490},{\"end\":77503,\"start\":77500},{\"end\":77513,\"start\":77507},{\"end\":77522,\"start\":77517},{\"end\":77532,\"start\":77526},{\"end\":77947,\"start\":77941},{\"end\":77956,\"start\":77951},{\"end\":77962,\"start\":77960},{\"end\":77972,\"start\":77966},{\"end\":78332,\"start\":78327},{\"end\":78342,\"start\":78336},{\"end\":78348,\"start\":78346},{\"end\":78729,\"start\":78720},{\"end\":78742,\"start\":78733},{\"end\":79033,\"start\":79029},{\"end\":79041,\"start\":79037},{\"end\":79049,\"start\":79045},{\"end\":79058,\"start\":79053},{\"end\":79066,\"start\":79062},{\"end\":79079,\"start\":79074},{\"end\":79511,\"start\":79504},{\"end\":79523,\"start\":79515},{\"end\":79533,\"start\":79527},{\"end\":79543,\"start\":79537},{\"end\":79918,\"start\":79912},{\"end\":79925,\"start\":79922},{\"end\":79933,\"start\":79929},{\"end\":79941,\"start\":79937},{\"end\":79947,\"start\":79945},{\"end\":80323,\"start\":80318},{\"end\":80331,\"start\":80327},{\"end\":80341,\"start\":80335},{\"end\":80761,\"start\":80756},{\"end\":80769,\"start\":80765},{\"end\":80779,\"start\":80773},{\"end\":80785,\"start\":80783},{\"end\":81118,\"start\":81115},{\"end\":81129,\"start\":81122},{\"end\":81140,\"start\":81135},{\"end\":81465,\"start\":81460},{\"end\":81476,\"start\":81469},{\"end\":81486,\"start\":81480},{\"end\":81836,\"start\":81829},{\"end\":81847,\"start\":81842},{\"end\":82184,\"start\":82181},{\"end\":82193,\"start\":82188},{\"end\":82200,\"start\":82197},{\"end\":82207,\"start\":82204},{\"end\":82552,\"start\":82545},{\"end\":82563,\"start\":82556},{\"end\":82574,\"start\":82567},{\"end\":82994,\"start\":82989},{\"end\":83001,\"start\":82998},{\"end\":83379,\"start\":83374},{\"end\":83641,\"start\":83639},{\"end\":83650,\"start\":83645},{\"end\":83659,\"start\":83654},{\"end\":83667,\"start\":83663},{\"end\":83677,\"start\":83673},{\"end\":83952,\"start\":83949},{\"end\":83959,\"start\":83956},{\"end\":83971,\"start\":83966},{\"end\":83979,\"start\":83975},{\"end\":84228,\"start\":84225},{\"end\":84234,\"start\":84232},{\"end\":84243,\"start\":84238},{\"end\":84251,\"start\":84247},{\"end\":84260,\"start\":84255},{\"end\":84592,\"start\":84587},{\"end\":84600,\"start\":84596},{\"end\":84610,\"start\":84604},{\"end\":85011,\"start\":85006},{\"end\":85019,\"start\":85015},{\"end\":85029,\"start\":85023},{\"end\":85348,\"start\":85345},{\"end\":85356,\"start\":85352},{\"end\":85363,\"start\":85360},{\"end\":85369,\"start\":85367},{\"end\":85662,\"start\":85658},{\"end\":85671,\"start\":85666},{\"end\":85679,\"start\":85677},{\"end\":85697,\"start\":85683},{\"end\":85705,\"start\":85701},{\"end\":86086,\"start\":86084},{\"end\":86094,\"start\":86092},{\"end\":86418,\"start\":86415},{\"end\":86424,\"start\":86422},{\"end\":86432,\"start\":86428},{\"end\":86795,\"start\":86791},{\"end\":86802,\"start\":86799},{\"end\":86809,\"start\":86806},{\"end\":86816,\"start\":86813},{\"end\":87137,\"start\":87129},{\"end\":87145,\"start\":87141},{\"end\":87153,\"start\":87149},{\"end\":87530,\"start\":87525},{\"end\":87539,\"start\":87534},{\"end\":87873,\"start\":87868},{\"end\":87880,\"start\":87877},{\"end\":87888,\"start\":87884},{\"end\":88179,\"start\":88171},{\"end\":88185,\"start\":88183},{\"end\":88196,\"start\":88189},{\"end\":88207,\"start\":88200},{\"end\":88581,\"start\":88568},{\"end\":88590,\"start\":88585},{\"end\":88812,\"start\":88808},{\"end\":88819,\"start\":88816},{\"end\":88831,\"start\":88825},{\"end\":89145,\"start\":89140},{\"end\":89153,\"start\":89149},{\"end\":89160,\"start\":89157},{\"end\":89167,\"start\":89164},{\"end\":89516,\"start\":89509},{\"end\":89523,\"start\":89520},{\"end\":89538,\"start\":89529},{\"end\":89548,\"start\":89542},{\"end\":89559,\"start\":89554},{\"end\":89570,\"start\":89563},{\"end\":89845,\"start\":89838},{\"end\":89855,\"start\":89849},{\"end\":89862,\"start\":89859},{\"end\":89875,\"start\":89866},{\"end\":89886,\"start\":89882},{\"end\":90226,\"start\":90222},{\"end\":90235,\"start\":90232},{\"end\":90247,\"start\":90242},{\"end\":90535,\"start\":90530},{\"end\":90544,\"start\":90541},{\"end\":90556,\"start\":90551},{\"end\":90564,\"start\":90560},{\"end\":90846,\"start\":90842},{\"end\":90858,\"start\":90853},{\"end\":91107,\"start\":91102},{\"end\":91116,\"start\":91111},{\"end\":91122,\"start\":91120},{\"end\":91361,\"start\":91356},{\"end\":91369,\"start\":91365},{\"end\":91375,\"start\":91373},{\"end\":91383,\"start\":91379},{\"end\":91391,\"start\":91387},{\"end\":91671,\"start\":91666},{\"end\":91981,\"start\":91970},{\"end\":91990,\"start\":91985},{\"end\":92000,\"start\":91994},{\"end\":92238,\"start\":92236},{\"end\":92247,\"start\":92242},{\"end\":92254,\"start\":92251},{\"end\":92261,\"start\":92258},{\"end\":92616,\"start\":92611},{\"end\":92628,\"start\":92620},{\"end\":92639,\"start\":92632},{\"end\":92649,\"start\":92645},{\"end\":92658,\"start\":92653},{\"end\":93000,\"start\":92995},{\"end\":93009,\"start\":93004},{\"end\":93018,\"start\":93013},{\"end\":93026,\"start\":93022},{\"end\":93033,\"start\":93030}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":67856161},\"end\":72028,\"start\":71704},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":237091687},\"end\":72353,\"start\":72030},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":233388137},\"end\":72687,\"start\":72355},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":233331178},\"end\":73056,\"start\":72689},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":253247250},\"end\":73297,\"start\":73058},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":237717285},\"end\":73710,\"start\":73299},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":237278177},\"end\":74131,\"start\":73712},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":5040280},\"end\":74520,\"start\":74133},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":204846466},\"end\":74821,\"start\":74522},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":4878926},\"end\":75128,\"start\":74823},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":213704372},\"end\":75421,\"start\":75130},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":233376110},\"end\":75877,\"start\":75423},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":233377141},\"end\":76371,\"start\":75879},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":237577287},\"end\":76929,\"start\":76373},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":236998636},\"end\":77355,\"start\":76931},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":234788173},\"end\":77809,\"start\":77357},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":183603957},\"end\":78204,\"start\":77811},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":146119085},\"end\":78648,\"start\":78206},{\"attributes\":{\"id\":\"b18\"},\"end\":78899,\"start\":78650},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":86748019},\"end\":79374,\"start\":78901},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":49192773},\"end\":79819,\"start\":79376},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":181924939},\"end\":80180,\"start\":79821},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":234806605},\"end\":80629,\"start\":80182},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":230552163},\"end\":81035,\"start\":80631},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":218958193},\"end\":81360,\"start\":81037},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":5926991},\"end\":81729,\"start\":81362},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":31741252},\"end\":82056,\"start\":81731},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":51612775},\"end\":82426,\"start\":82058},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":235455684},\"end\":82907,\"start\":82428},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":209063869},\"end\":83282,\"start\":82909},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":226465108},\"end\":83589,\"start\":83284},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":6176661},\"end\":83868,\"start\":83591},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":164309790},\"end\":84185,\"start\":83870},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":202538530},\"end\":84447,\"start\":84187},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":240267869},\"end\":84888,\"start\":84449},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":238780679},\"end\":85263,\"start\":84890},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":222297732},\"end\":85574,\"start\":85265},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":49657173},\"end\":86005,\"start\":85576},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":29873442},\"end\":86313,\"start\":86007},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":216562458},\"end\":86669,\"start\":86315},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":215800129},\"end\":87034,\"start\":86671},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":49728640},\"end\":87386,\"start\":87036},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":219759284},\"end\":87784,\"start\":87388},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":219029994},\"end\":88058,\"start\":87786},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":12399628},\"end\":88525,\"start\":88060},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":38916788},\"end\":88740,\"start\":88527},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":3449450},\"end\":89052,\"start\":88742},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":24982157},\"end\":89418,\"start\":89054},{\"attributes\":{\"doi\":\"arXiv:1602.07360\",\"id\":\"b48\"},\"end\":89778,\"start\":89420},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":4555207},\"end\":90164,\"start\":89780},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":17773526},\"end\":90450,\"start\":90166},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":8457857},\"end\":90772,\"start\":90452},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":113695},\"end\":91040,\"start\":90774},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":20498107},\"end\":91275,\"start\":91042},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":202572897},\"end\":91588,\"start\":91277},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":57760300},\"end\":91886,\"start\":91590},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":209387588},\"end\":92186,\"start\":91888},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":206594692},\"end\":92506,\"start\":92188},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":240323815},\"end\":92906,\"start\":92508},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":237904219},\"end\":93266,\"start\":92908}]", "bib_title": "[{\"end\":71799,\"start\":71704},{\"end\":72127,\"start\":72030},{\"end\":72450,\"start\":72355},{\"end\":72779,\"start\":72689},{\"end\":73111,\"start\":73058},{\"end\":73407,\"start\":73299},{\"end\":73825,\"start\":73712},{\"end\":74242,\"start\":74133},{\"end\":74627,\"start\":74522},{\"end\":74875,\"start\":74823},{\"end\":75195,\"start\":75130},{\"end\":75522,\"start\":75423},{\"end\":75996,\"start\":75879},{\"end\":76525,\"start\":76373},{\"end\":77078,\"start\":76931},{\"end\":77486,\"start\":77357},{\"end\":77937,\"start\":77811},{\"end\":78323,\"start\":78206},{\"end\":78714,\"start\":78650},{\"end\":79025,\"start\":78901},{\"end\":79496,\"start\":79376},{\"end\":79906,\"start\":79821},{\"end\":80314,\"start\":80182},{\"end\":80752,\"start\":80631},{\"end\":81111,\"start\":81037},{\"end\":81454,\"start\":81362},{\"end\":81825,\"start\":81731},{\"end\":82177,\"start\":82058},{\"end\":82539,\"start\":82428},{\"end\":82985,\"start\":82909},{\"end\":83370,\"start\":83284},{\"end\":83635,\"start\":83591},{\"end\":83945,\"start\":83870},{\"end\":84221,\"start\":84187},{\"end\":84583,\"start\":84449},{\"end\":85002,\"start\":84890},{\"end\":85341,\"start\":85265},{\"end\":85654,\"start\":85576},{\"end\":86080,\"start\":86007},{\"end\":86411,\"start\":86315},{\"end\":86787,\"start\":86671},{\"end\":87125,\"start\":87036},{\"end\":87519,\"start\":87388},{\"end\":87864,\"start\":87786},{\"end\":88167,\"start\":88060},{\"end\":88564,\"start\":88527},{\"end\":88802,\"start\":88742},{\"end\":89136,\"start\":89054},{\"end\":89834,\"start\":89780},{\"end\":90218,\"start\":90166},{\"end\":90526,\"start\":90452},{\"end\":90838,\"start\":90774},{\"end\":91098,\"start\":91042},{\"end\":91352,\"start\":91277},{\"end\":91660,\"start\":91590},{\"end\":91964,\"start\":91888},{\"end\":92232,\"start\":92188},{\"end\":92607,\"start\":92508},{\"end\":92991,\"start\":92908}]", "bib_author": "[{\"end\":71809,\"start\":71801},{\"end\":71819,\"start\":71809},{\"end\":71827,\"start\":71819},{\"end\":72136,\"start\":72129},{\"end\":72459,\"start\":72452},{\"end\":72466,\"start\":72459},{\"end\":72474,\"start\":72466},{\"end\":72480,\"start\":72474},{\"end\":72789,\"start\":72781},{\"end\":72796,\"start\":72789},{\"end\":72807,\"start\":72796},{\"end\":72816,\"start\":72807},{\"end\":72824,\"start\":72816},{\"end\":73119,\"start\":73113},{\"end\":73127,\"start\":73119},{\"end\":73135,\"start\":73127},{\"end\":73415,\"start\":73409},{\"end\":73423,\"start\":73415},{\"end\":73432,\"start\":73423},{\"end\":73439,\"start\":73432},{\"end\":73448,\"start\":73439},{\"end\":73456,\"start\":73448},{\"end\":73836,\"start\":73827},{\"end\":73844,\"start\":73836},{\"end\":73850,\"start\":73844},{\"end\":73857,\"start\":73850},{\"end\":74255,\"start\":74244},{\"end\":74266,\"start\":74255},{\"end\":74281,\"start\":74266},{\"end\":74289,\"start\":74281},{\"end\":74636,\"start\":74629},{\"end\":74885,\"start\":74877},{\"end\":74893,\"start\":74885},{\"end\":74901,\"start\":74893},{\"end\":74914,\"start\":74901},{\"end\":74924,\"start\":74914},{\"end\":75208,\"start\":75197},{\"end\":75219,\"start\":75208},{\"end\":75226,\"start\":75219},{\"end\":75534,\"start\":75524},{\"end\":75541,\"start\":75534},{\"end\":75550,\"start\":75541},{\"end\":76008,\"start\":75998},{\"end\":76015,\"start\":76008},{\"end\":76024,\"start\":76015},{\"end\":76537,\"start\":76527},{\"end\":76544,\"start\":76537},{\"end\":76554,\"start\":76544},{\"end\":76565,\"start\":76554},{\"end\":76574,\"start\":76565},{\"end\":76584,\"start\":76574},{\"end\":77090,\"start\":77080},{\"end\":77498,\"start\":77488},{\"end\":77505,\"start\":77498},{\"end\":77515,\"start\":77505},{\"end\":77524,\"start\":77515},{\"end\":77534,\"start\":77524},{\"end\":77949,\"start\":77939},{\"end\":77958,\"start\":77949},{\"end\":77964,\"start\":77958},{\"end\":77974,\"start\":77964},{\"end\":78334,\"start\":78325},{\"end\":78344,\"start\":78334},{\"end\":78350,\"start\":78344},{\"end\":78731,\"start\":78716},{\"end\":78744,\"start\":78731},{\"end\":79035,\"start\":79027},{\"end\":79043,\"start\":79035},{\"end\":79051,\"start\":79043},{\"end\":79060,\"start\":79051},{\"end\":79068,\"start\":79060},{\"end\":79081,\"start\":79068},{\"end\":79513,\"start\":79498},{\"end\":79525,\"start\":79513},{\"end\":79535,\"start\":79525},{\"end\":79545,\"start\":79535},{\"end\":79920,\"start\":79908},{\"end\":79927,\"start\":79920},{\"end\":79935,\"start\":79927},{\"end\":79943,\"start\":79935},{\"end\":79949,\"start\":79943},{\"end\":80325,\"start\":80316},{\"end\":80333,\"start\":80325},{\"end\":80343,\"start\":80333},{\"end\":80763,\"start\":80754},{\"end\":80771,\"start\":80763},{\"end\":80781,\"start\":80771},{\"end\":80787,\"start\":80781},{\"end\":81120,\"start\":81113},{\"end\":81131,\"start\":81120},{\"end\":81142,\"start\":81131},{\"end\":81467,\"start\":81456},{\"end\":81478,\"start\":81467},{\"end\":81488,\"start\":81478},{\"end\":81838,\"start\":81827},{\"end\":81849,\"start\":81838},{\"end\":82186,\"start\":82179},{\"end\":82195,\"start\":82186},{\"end\":82202,\"start\":82195},{\"end\":82209,\"start\":82202},{\"end\":82554,\"start\":82541},{\"end\":82565,\"start\":82554},{\"end\":82576,\"start\":82565},{\"end\":82996,\"start\":82987},{\"end\":83003,\"start\":82996},{\"end\":83381,\"start\":83372},{\"end\":83643,\"start\":83637},{\"end\":83652,\"start\":83643},{\"end\":83661,\"start\":83652},{\"end\":83669,\"start\":83661},{\"end\":83679,\"start\":83669},{\"end\":83954,\"start\":83947},{\"end\":83961,\"start\":83954},{\"end\":83973,\"start\":83961},{\"end\":83981,\"start\":83973},{\"end\":84230,\"start\":84223},{\"end\":84236,\"start\":84230},{\"end\":84245,\"start\":84236},{\"end\":84253,\"start\":84245},{\"end\":84262,\"start\":84253},{\"end\":84594,\"start\":84585},{\"end\":84602,\"start\":84594},{\"end\":84612,\"start\":84602},{\"end\":85013,\"start\":85004},{\"end\":85021,\"start\":85013},{\"end\":85031,\"start\":85021},{\"end\":85350,\"start\":85343},{\"end\":85358,\"start\":85350},{\"end\":85365,\"start\":85358},{\"end\":85371,\"start\":85365},{\"end\":85664,\"start\":85656},{\"end\":85673,\"start\":85664},{\"end\":85681,\"start\":85673},{\"end\":85699,\"start\":85681},{\"end\":85707,\"start\":85699},{\"end\":86088,\"start\":86082},{\"end\":86096,\"start\":86088},{\"end\":86420,\"start\":86413},{\"end\":86426,\"start\":86420},{\"end\":86434,\"start\":86426},{\"end\":86797,\"start\":86789},{\"end\":86804,\"start\":86797},{\"end\":86811,\"start\":86804},{\"end\":86818,\"start\":86811},{\"end\":87139,\"start\":87127},{\"end\":87147,\"start\":87139},{\"end\":87155,\"start\":87147},{\"end\":87532,\"start\":87521},{\"end\":87541,\"start\":87532},{\"end\":87875,\"start\":87866},{\"end\":87882,\"start\":87875},{\"end\":87890,\"start\":87882},{\"end\":88181,\"start\":88169},{\"end\":88187,\"start\":88181},{\"end\":88198,\"start\":88187},{\"end\":88209,\"start\":88198},{\"end\":88583,\"start\":88566},{\"end\":88592,\"start\":88583},{\"end\":88814,\"start\":88804},{\"end\":88821,\"start\":88814},{\"end\":88833,\"start\":88821},{\"end\":89147,\"start\":89138},{\"end\":89155,\"start\":89147},{\"end\":89162,\"start\":89155},{\"end\":89169,\"start\":89162},{\"end\":89518,\"start\":89505},{\"end\":89525,\"start\":89518},{\"end\":89540,\"start\":89525},{\"end\":89550,\"start\":89540},{\"end\":89561,\"start\":89550},{\"end\":89572,\"start\":89561},{\"end\":89847,\"start\":89836},{\"end\":89857,\"start\":89847},{\"end\":89864,\"start\":89857},{\"end\":89877,\"start\":89864},{\"end\":89888,\"start\":89877},{\"end\":90228,\"start\":90220},{\"end\":90237,\"start\":90228},{\"end\":90249,\"start\":90237},{\"end\":90537,\"start\":90528},{\"end\":90546,\"start\":90537},{\"end\":90558,\"start\":90546},{\"end\":90566,\"start\":90558},{\"end\":90848,\"start\":90840},{\"end\":90860,\"start\":90848},{\"end\":91109,\"start\":91100},{\"end\":91118,\"start\":91109},{\"end\":91124,\"start\":91118},{\"end\":91363,\"start\":91354},{\"end\":91371,\"start\":91363},{\"end\":91377,\"start\":91371},{\"end\":91385,\"start\":91377},{\"end\":91393,\"start\":91385},{\"end\":91673,\"start\":91662},{\"end\":91983,\"start\":91966},{\"end\":91992,\"start\":91983},{\"end\":92002,\"start\":91992},{\"end\":92240,\"start\":92234},{\"end\":92249,\"start\":92240},{\"end\":92256,\"start\":92249},{\"end\":92263,\"start\":92256},{\"end\":92618,\"start\":92609},{\"end\":92630,\"start\":92618},{\"end\":92641,\"start\":92630},{\"end\":92651,\"start\":92641},{\"end\":92660,\"start\":92651},{\"end\":93002,\"start\":92993},{\"end\":93011,\"start\":93002},{\"end\":93020,\"start\":93011},{\"end\":93028,\"start\":93020},{\"end\":93035,\"start\":93028}]", "bib_venue": "[{\"end\":75662,\"start\":75612},{\"end\":76136,\"start\":76086},{\"end\":78414,\"start\":78388},{\"end\":82676,\"start\":82630},{\"end\":83105,\"start\":83060},{\"end\":85795,\"start\":85755},{\"end\":86162,\"start\":86133},{\"end\":89221,\"start\":89199},{\"end\":89974,\"start\":89935},{\"end\":90301,\"start\":90279},{\"end\":92351,\"start\":92311},{\"end\":71836,\"start\":71827},{\"end\":72161,\"start\":72136},{\"end\":72489,\"start\":72480},{\"end\":72842,\"start\":72824},{\"end\":73154,\"start\":73135},{\"end\":73473,\"start\":73456},{\"end\":73891,\"start\":73857},{\"end\":74301,\"start\":74289},{\"end\":74647,\"start\":74636},{\"end\":74946,\"start\":74924},{\"end\":75248,\"start\":75226},{\"end\":75610,\"start\":75550},{\"end\":76084,\"start\":76024},{\"end\":76615,\"start\":76584},{\"end\":77107,\"start\":77090},{\"end\":77559,\"start\":77534},{\"end\":77985,\"start\":77974},{\"end\":78386,\"start\":78350},{\"end\":78755,\"start\":78744},{\"end\":79106,\"start\":79081},{\"end\":79567,\"start\":79545},{\"end\":79971,\"start\":79949},{\"end\":80371,\"start\":80343},{\"end\":80798,\"start\":80787},{\"end\":81169,\"start\":81142},{\"end\":81515,\"start\":81488},{\"end\":81866,\"start\":81849},{\"end\":82217,\"start\":82209},{\"end\":82628,\"start\":82576},{\"end\":83058,\"start\":83003},{\"end\":83406,\"start\":83381},{\"end\":83701,\"start\":83679},{\"end\":83998,\"start\":83981},{\"end\":84288,\"start\":84262},{\"end\":84633,\"start\":84612},{\"end\":85042,\"start\":85031},{\"end\":85388,\"start\":85371},{\"end\":85753,\"start\":85707},{\"end\":86131,\"start\":86096},{\"end\":86464,\"start\":86434},{\"end\":86829,\"start\":86818},{\"end\":87182,\"start\":87155},{\"end\":87552,\"start\":87541},{\"end\":87898,\"start\":87890},{\"end\":88263,\"start\":88209},{\"end\":88610,\"start\":88592},{\"end\":88867,\"start\":88833},{\"end\":89197,\"start\":89169},{\"end\":89503,\"start\":89420},{\"end\":89933,\"start\":89888},{\"end\":90277,\"start\":90249},{\"end\":90584,\"start\":90566},{\"end\":90878,\"start\":90860},{\"end\":91134,\"start\":91124},{\"end\":91405,\"start\":91393},{\"end\":91703,\"start\":91673},{\"end\":92011,\"start\":92002},{\"end\":92309,\"start\":92263},{\"end\":92671,\"start\":92660},{\"end\":93057,\"start\":93035}]"}}}, "year": 2023, "month": 12, "day": 17}