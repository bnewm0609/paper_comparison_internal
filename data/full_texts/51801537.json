{"id": 51801537, "updated": "2023-10-07 19:17:27.321", "metadata": {"title": "Selfie Video Stabilization", "authors": "[{\"first\":\"Jiyang\",\"last\":\"Yu\",\"middle\":[]},{\"first\":\"Ravi\",\"last\":\"Ramamoorthi\",\"middle\":[]}]", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "publication_date": {"year": 2021, "month": 2, "day": 1}, "abstract": "We propose a novel algorithm for stabilizing selfie videos. Our goal is to automatically generate stabilized video that has optimal smooth motion in the sense of both foreground and background. The key insight is that non-rigid foreground motion in selfie videos can be analyzed using a 3D face model, and background motion can be analyzed using optical flow. We use second derivative of temporal trajectory of selected pixels as the measure of smoothness. Our algorithm stabilizes selfie videos by minimizing the smoothness measure of the background, regularized by the motion of the foreground. Experiments show that our method outperforms state-of-the-art general video stabilization techniques in selfie videos.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": "2965649664", "acl": null, "pubmed": "31380744", "pubmedcentral": null, "dblp": "journals/pami/YuR21", "doi": "10.1109/tpami.2019.2931897"}}, "content": {"source": {"pdf_hash": "d0ef52bde45ff92047a70e482eb8afaddcae5be8", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "767d10db3add71a24da82eadcbd2da51011c08a1", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d0ef52bde45ff92047a70e482eb8afaddcae5be8.txt", "contents": "\nSelfie Video Stabilization\n\n\nJiyang Yu \nFellow, IEEERavi Ramamoorthi \nSelfie Video Stabilization\n10.1109/TPAMI.2019.2931897Index Terms-Video stabilization, face modeling\nWe propose a novel algorithm for stabilizing selfie videos. Our goal is to automatically generate stabilized video that has optimal smooth motion in the sense of both foreground and background. The key insight is that non-rigid foreground motion in selfie videos can be analyzed using a 3D face model, and background motion can be analyzed using optical flow. We use second derivative of temporal trajectory of selected pixels as the measure of smoothness. Our algorithm stabilizes selfie videos by minimizing the smoothness measure of the background, regularized by the motion of the foreground. Experiments show that our method outperforms state-of-the-art general video stabilization techniques in selfie videos.Index Terms-Video stabilization, face modeling \u00c7 J. Yu is with the\n\nINTRODUCTION\n\nS ELFIE video has become one of the major video types thanks to the recent development of social media. However, selfie videos taken by amateurs are usually shaky due to the lack of stabilizing equipment. Recent state-of-the-art works have been developed for general video stabilization tasks and integrated into commercial tools such as Adobe Warp Stabilizer [1] and the YouTube video stabilizer [2]. However, selfie videos usually have properties that create difficulties for existing methods. We show several example frames from typical selfie videos in Fig. 1, in which these properties are demonstrated:\n\n(a) Large non-rigid occlusion from face and body close to the camera; (b) Selfie videos usually come with strong motion blur/ out-of-focus background; (c) Foreground motion does not coincide with background motion. General video stabilization methods fail in selfie videos for several reasons. First, most of these works depend on tracking 2D feature points. Existing 3D stabilization approaches require Structure from Motion (SfM) to estimate an initial camera path and build a sparse 3D scene. 2D methods also need to find frame motion using features. Therefore these methods are sensitive to inaccurate tracking of feature points. In Fig. 1b, we show the example frames with blurred background and lack of sharp corners. In these videos, feature point detection is less reliable and the subsequent feature tracking is error-prone.\n\nSecond, it is also difficult to obtain long and error-free feature tracks in selfie videos with strong shake. The feature tracking becomes brittle due to the significant occlusion imposed by human face and body. Having noticed feature tracking as a general shortcoming in video stabilization, some methods tried to avoid using features by analyzing the pixel profiles using optical flow [3]. However, optical flow based algorithms still have failure cases when the occluding object dominates the foreground, which is likely to happen in selfie videos (Fig. 1a). Our algorithm takes advantage of optical flow to track the background pixels. Unlike Liu et al. [3] which uses optical flow to synthesize new frames, we only warp the frame with 2D projective transformations and a grid-based warp field. This guarantees the rigidity over the entire frame. To avoid tracking points and generating long trajectories, we only use small segments of these trajectories so that the foreground occlusion has minimal impact on the stabilization. We further discuss the advantages of the strategy in Section 7.\n\nThird, general video stabilization only stabilizes with respect to part of the scene. This is not always desired in selfie videos. Both foreground (face and body) and background are important regions that need to be stabilized. To our knowledge, ours is the first method that utilizes the face geometry information in the video stabilization task (Fig. 1d). Our algorithm can automatically plan the optimal motion so that both the foreground and background motion are smoothed (Figs. 1d and 1e). In summary, our contributions include:\n\nForeground motion from 3D face model: We utilize 3D human face information to gain knowledge about foreground motion in selfie videos (Section 4). Novel background motion tracking: Our method uses optical flow to find dense correspondences on the background, and therefore does not require good feature detection and tracking. We only use temporal motion information and are robust to occlusions in the scene (Section 5).\n\nOptimal foreground/background stabilization: By considering foreground motion, our method can stabilize selfie videos with respect to foreground and background simultaneously (Section 6). Labeled selfie video dataset: We provide a selfie video dataset ( Fig. 7) of 33 videos, labeled with properties such as dynamic occlusion and lack of background features ( Fig. 9) that significantly affect the video stabilization task. The dataset can be used to compare different methods, and will be a useful resource for the field. We make the dataset, code and benchmark per Fig. 9 publicly available online at http://cseweb.ucsd.edu/$viscomp/ projects/ECCV18VideoStab. This paper is an extension to Yu and Ramamoorthi [4]. We provide new comparisons with Grundmann et al. [2] and Liu et al. [5] results, evaluated by the metric used in Liu et al. [6] ( Fig. 10). We also provide a comparison of the results using different head tracking information (Fig. 11), showing the benefit of utilizing the 3D head model in our method. Besides the 6 general videos presented in Yu and Ramamoorthi [4], we also provide results of 10 general videos used in Liu et al. [5] and Grundmann et al. [2] and Liu et al. [6] (Fig. 12). We also evaluated our method over the entire general video dataset from Liu et al. [6] (Fig. 13).\n\n\nRELATED WORK\n\nGeneral video stabilization can be broadly categorized into 2D methods and 3D methods, according to their proposed camera motion models.\n\n2D Stabilization. General 2D video stabilization techniques compute 2D motion and generate stabilized video by applying the smoothed motion to original video frames. Some approaches use simple camera motion models. Grundmann et al. [2] proposed a constrainable L1-optimization framework which solves the smoothed camera path composed of constant, linear and parabolic motion. Gleicher and Liu [7] assume the scene is largely planar and use homography to synthesize new frames. Liu et al. [6] divide the frame space into a grid mesh and allow spatially-variant motion. Some methods smooth the motion by imposing non-trivial constraints. Liu et al. [1] smooth 2D feature tracks by enforcing low-dimensional subspace constraints. Wang et al. [8] smoothes feature tracks while maintaining the spatial relations among them. Goldstein and Fattal [9] uses epipolar constraints when warping the video frames into synthesized frames. There are also explorations of non feature-point based approaches: Liu et al. [3] solves for a smooth per-frame optical flow field and stabilizes the video by smoothing pixel profiles instead of smoothing feature tracks.\n\n3D Stabilization. Some methods sparsely reconstruct the 3D scene. The sparse 3D information is used to guide the synthesis of new frames. These methods generate better results than 2D methods by modeling physically accurate 3D camera motions but are less robust under non-ideal conditions, e.g., large occlusion, motion blur, and rolling shutter. Liu et al. [5] first uses structure from motion to find feature points' 3D positions, reprojects them onto the smoothed camera path and warps the original frames according to reprojected feature points. There are also methods that render new frames using 3D information: Buehler et al. [10] uses image-based rendering to synthesize new views; Smith et al. [11] utilize the light field camera to stabilize video; Sun [12] uses depth information. Due to the non-rigid occlusion in selfie videos (Fig. 1a), 3D methods that are based on structure from motion can be error-prone. 3D methods that use depth information are also not directly applicable to selfie videos, since depth is not available in most cases.\n\nFace Modeling. Human face modeling has been intensely studied. We will only summarize works that are closely related to our work. A widely used early work (Blanz and Vetter [13]) models face shape across people as a parametric PCA space learned from a database of laser scans. Cao et al. [14] models faces by assembling Kinect face scans as a tensor with identity and expression dimensions. Many follow-up works apply these models in image manipulation (Cao et al. [14], Fried et al. [15]), image/video re-animation (Blanz et al. [16], Thies et al. [17]), face tracking (Cao et al. [18]), facial performance capture (Cao et al. [19], Shi and Tomasi [20]), face reconstruction and rigging (Garrido et al. [21], Ichim et al. [22]). However, these works mainly focus on images/videos captured under ideal conditions (still or stable camera). Our work explores the possibility of utilizing 3D face models in the analysis of selfie videos captured with camera shake. We blend the models in Blanz and Vetter [13] and Cao et al. [14], to use as the reference model for the face fitting process, which will be discussed in Section 4. \n\n\nOVERVIEW\n\nIn this section, we provide an overview of our approach for stabilizing selfie videos (Fig. 2). We seek to stabilize the selfie video with respect to both foreground and background. We analyze the foreground motion by modeling the face using a 3D face model, and analyze the background motion by optical flow. Fitting the 3D face model to selfie videos provides the head trajectory. We transform each frame according to the head positions so that the foreground regions are roughly aligned across the entire video. Since the foreground regions are aligned, the accumulated motion in this region will be smaller than background regions. Therefore the foreground and background regions can be separated. Details regarding this process will be discussed in Section 4. The background is defined as the white region in the foreground mask shown in Fig. 2. We randomly select pixels in the background that satisfy certain conditions, and use the optical flow to track their motion. Because of occlusion, our method only tracks pixels for 3 neighboring frames. We discuss details of pixel selection and tracking in Section 5.\n\nThe goal of video stabilization is to warp the original video frame so that the undesired frame motions are cancelled. We model the frame motion as a combination of global motion and local motion. The global motion refers to the 2D projective transformation of a frame. Since the frame content is the result of multiple factors, e.g., camera projection, camera distortion, rolling shutter and the 3D structure of the scene, simple 2D projective transformation cannot represent the camera motion accurately. Therefore, we use local motion to refer to any residual motion. Motivated by this analysis, we design our stabilization algorithm as a single joint optimization that simultaneously stabilizes foreground head motion and the background's global and local motion. We will describe details of our joint optimization algorithm in Section 6.\n\n\nFOREGROUND TRACKING\n\nSince the head and body are attached, we believe that the head motion can well represent the entire foreground motion. We don't explicitly track the body in this work, but implicitly separate the foreground and background by accumulating the optical flow. Details will be discussed in Section 5. Here we seek to find the position of the head in each frame. Since multiple faces could exist in the selfie video, we only track the dominant face in the video. A regular 2D face detector can provide the face bounding box for each frame, but is not accurate enough for tracking the exact head position. A 2D facial landmark detector provides more accurate detection of the face, but is easily affected by head rotation and facial expression. To find the actual head position invariant to head rotation and facial expression, we use the 3D position of the head and reproject it to the image space as the head position. This requires modeling the face and gaining knowledge about the shape of the face in the selfie video.\n\n3D Face Model. We utilize the linear face model proposed by Blanz and Vetter [13] and the bilinear face model proposed by Cao et al. [14]. Note that although the bilinear face model is more widely used in recent researches, their model was built based on a head mesh with relatively sparse vertices compared to Blanz and Vetter [13]. Our facial landmark based algorithm, which we will discuss later in this section, needs a dense face mesh in the face fitting algorithm. Therefore, we extend the linear face model of Blanz and Vetter [13] by transferring the expressions from Cao et al. [14]. Our extended linear face model is parameterized as follows:\nF F \u00bc m m \u00fe U U s S S s c c s \u00fe U U e S S e c c e ;(1)\nwhere m m encodes the vertex position of the mean face, U U s are the principal components of face shape, diagonal matrix S S s contains standard deviations of principal components and c c s is the weight vector that combines principal components. In (1), the third term U U e represents the expression principal components. It is generated as follows: we average the shape dimension of the bilinear face model [14] and use deformation transfer [23] to deform the mean linear face model with the bilinear face model's expressions. We extract principal components U U e of these expression deformed face meshes using regular PCA. Face Fitting Algorithm. Our face model fitting algorithm is a purely landmark based algorithm. For a video with T frames, we detect facial landmarks L t in each frame using Bulat and Tzimiropoulos [24]. The unknown parameters include the 3D rotation R R t 2 SO\u00f03\u00de, the 3D translation T T t 2 R 3 , per-frame facial expression coefficient c c e;t and the shape parameter c c s . We also assume a simple perspective camera projection:\nP P \u00bc f 0 w=2 0 f h=2 0 0 1 2 4 3 5 ;\n(2) Fig. 2. Pipeline of our method. A: By fitting a 3D face model, we find the head trajectory in the selfie video (Section 4); B: Optical flow is used to track background pixels for 3 neighboring frames; C: The foreground mask is computed from the head trajectory and is used to find the background pixels (Section 5). The 2D projective transformation and a grid-based warp field is estimated to remove the undesired motion of both foreground and background (Section 6).\n\nwhere we assume same unknown focal length in horizontal and vertical direction, known fixed optical center at the center of the frame (w and h represents frame width and height respectively), and zero skew. Denoting the 3D transformation matrix as\nK K t \u00bc \u00bdR R t T T t where R R t 2 R 3\u00c23 and T T t 2 R 3 , the 3D face model is fitted by solving: min P P;R R t ;T T t ; c cs;c c e;t X T \u00c01 t\u00bc0 L t \u00c0 P P K K t b F b F t 2 \u00fe 1 c c e;t 2 \u00fe 2 T c c s k k 2 ;(3)\nwhere b F b F t represents the landmark vertices controlled by c c s and c c e;t as in (1), and 1 and 2 are regularization values that prevent the optimization from getting in local minima. The optimization can be easily solved as an unconstrained nonlinear least squares problem. We use all the 199 shape principal components and 46 expression principal components in the fitting process. We use 1 \u00bc 5 and 2 \u00bc 5 in our experiment. The centroids of fitted face meshes are projected using the solved projection matrix P P , resulting in the head trajectory.\n\nFacial Landmark Update. In Bulat and Tzimiropoulos [24], the contour 2D landmarks are defined by the face silhouette. The face silhouette depends on the pose of the head; therefore the corresponding contour landmark vertices need to be updated during optimization (3). However, this requires computing and rendering the whole mesh for facial landmark detection. To avoid this cost, we only update the contour landmark vertices between two iterations of optimization: we first fix the landmark vertices and use them in the face model fitting, then fix the estimated parameters and update the contour landmark vertices. The update of landmark vertices is demonstrated in Fig. 3. We first render the current face mesh, and detect 2D landmarks using the rendered image. We update the landmark vertices' indices by projecting all the visible vertices to the image plane and find the closest ones to the detected 2D landmarks. These closest vertices are used as contour landmark vertices in the next iteration. Note that the 2D-3D correspondence is established by finding vertices closest to landmarks. Therefore, a denser mesh will result in more accurate correspondence. This explains why we extend the denser linear face model (Blanz and Vetter [13]) instead of using the sparse bilinear face model (Cao et al. [14]) directly.\n\nDiscussion. General video stabilization methods have difficulties when occlusion occurs in the video. Some methods either try to exclude the occlusion region by detecting discontinuity in motions (Liu et al. [3]) or let users remove features belonging to the foreground (Bai et al. [25]). The novelty of our method is that it also considers the motion in the foreground. Due to the dynamics of faces, feature based analysis is easily affected by head poses and facial expressions. We use the 3D face model to track the foreground face, so that the foreground can be analyzed even with large non-rigidity. Our method only uses the centroid of the face model to represent the foreground motion. Therefore, the goal of our face fitting algorithm is to provide reliable foreground tracking with minimal computational overhead, but not high geometry fidelity. In Fig. 4 we show that by implementing the contour landmark update scheme, our face fitting algorithm achieves sufficiently good results for video stabilization purposes. Our method uses only 2D landmarks and thus is simpler than state-of-the-art methods that use 3D facial landmarks estimated using non-rigid structure-from-motion (Shi et al. [20]) or 2D facial landmarks with additional light and shading constraints (Thies et al. [17]). In Fig. 11 we further show that the head trajectory estimated by our algorithm is reliable and greatly improves the final video stabilization results.\n\n\nBACKGROUND TRACKING\n\nWhile we can track the foreground motion using a 3D face model, we also need to analyze the background motion so that both these regions can be considered in the stabilization process. We use the optical flow proposed by Kroeger et al. [26] to track a group of background pixels in each frame. The optical flow can be inaccurate in specific regions due to motion blur/out-of-focus and occlusion. However, minor   [20] and Thies et al. [17]. Our method achieves sufficiently good results without using complex structure-from-motion and shading constraints.\n\ninaccuracies in small regions can be ignored since our goal is to analyze the global camera motion. In addition, to minimize the impact of occlusion in the scene, we only track each pixel for 3 neighboring frames. We will discuss how this temporal motion information is used in our stabilization process in Section 6.\n\nNot all pixels can be used to track the background motion. Obviously, pixels falling in the foreground region should not be selected. Face fitting described in Section 4 provides the head positions in each frame. We first translate all the frames so that the head positions in each frame are aligned to the same point, which leads to a head-aligned video. We perform optical flow between each frame of the head-aligned video. The accumulated optical flow forms a map that encodes the accumulated motion magnitude of each pixel. Since the video is aligned with respect to head position, the accumulated magnitude of optical flow will be smaller in the face and body region, but larger in the background region.\n\nWe show an example of a motion map in Fig. 5 A. After computing the motion map, we use K-means to divide the pixels into two clusters. The cluster with smaller values is considered as foreground. The randomly selected pixels in this cluster will not be used in the stabilization.\n\nMoreover, pixels near the occluding boundary should not be selected. Although our method does not require long feature tracks, we still need to track pixels using optical flow. The downside of tracking with optical flow is that tracking loss caused by occlusion is not easily detectable. To tackle this problem, we want to remove the pixels that are near the occluding boundary.\n\nThe objects in the scene can be distinguished by the direction of their motions. We use the standard deviation of the optical flow s F in a 21 \u00c2 21 neighborhood to measure the local variation in the optical flow. An example of standard deviation of the optical flow is shown in Fig. 5 B. The foreground boundary has a larger variation in terms of the optical flow direction. In the stabilization, we only use the pixels with s F smaller than a threshold value. We use 0.3 as the threshold in all of our tests.\n\n\nSTABILIZATION\n\nThe goal of video stabilization is to warp the original video frame so that the undesired frame motions are cancelled. We model the frame motion as a combination of global motion and local motion. The global motion refers to the 2D projective transformation of a frame. Since the frame content is the result of multiple factors, e.g., camera projection, camera distortion, rolling shutter and the 3D structure of the scene, a simple 2D projective transformation cannot represent the camera motion accurately. Therefore, we use local motion to refer to any residual motion.\n\nMotivated by this analysis, we design our algorithm to stabilize the global motion using the whole frame 2D projective transformation and stabilize the local motion using the per-frame grid warping.\n\nSmoothness Measure. In selfie videos, the human appears as a large occlusion near the camera, making the trajectory of a pixel fragile. As a consequence, obtaining long feature tracks is difficult. Instead of tracking a pixel over multiple frames, we only track a pixel for 3 frames that are necessary for estimating the second derivative at time t. To demonstrate our idea, we use a single pixel in the scene as an example. Assume a pixel p is tracked over a time period. The trajectory it forms is denoted by p\u00f0t\u00de. To evaluate the smoothness of this trajectory, we use the integral of squared second derivative or acceleration over the time period. This metric is commonly used in cubic spline fitting algorithms for optimal smoothness. By using this metric, we allow the frames to move to some extent but not try to completely eliminate the low frequency shake. This also helps in generating a larger output frame size when the camera motion is large, which is very common in selfie videos. Details of this effect will be discussed in Section 7. For a set of selected background pixels (which pixels we choose for this purpose is discussed in Section 5), the smoothness of the background motion can be written as:\nE s \u00f0t\u00de \u00bc X N t i\u00bc1 b p t;i \u00f0t \u00fe 1\u00de \u00c0 2b p t;i \u00f0t\u00de \u00fe b p t;i \u00f0t \u00c0 1\u00de 2 ;(4)\nwhere p t;i is the ith pixel tracked from t \u00c0 1 to t \u00fe 1, and b p is the new trajectory formed by transforming the original trajectory p. To guarantee the robustness, we track N t pixels that are randomly selected in the frame at time t \u00c0 1. We illustrate the tracking of background pixels in Fig. 6.\n\nFrame Transformation. We seek to find a per-frame 2D projective transformation along with a per-frame grid warp field to transform p t;i to b p t;i so that the objective (4) is minimized. For the grid warping, we use the same bilinear interpolation representation as Liu et al. [5]. Each point is represented by a combination of four vertices of its enclosing grid cell:\np t;i \u00bc w T t;i V t ;(5)\nwhere V t is a vector of the four vertices of the original grid cell that p\u00f0t\u00de is in; and w t is the weight which sums to 1. Denote the output grid as b V and the 2D projective transformation as  H. The warped scene point b p can be calculated using the same weights:\nb p t;i \u00bc w T t;i H t b V t :(6)\nRegularization. In selfie videos, the foreground that contains face and body should also be stabilized. The motion of the foreground is not always consistent with the motion of the background. To account for the foreground motion, we also consider the head trajectory:\nE h \u00f0t\u00de \u00bc N t b h\u00f0t \u00fe 1\u00de \u00c0 b h\u00f0t\u00de 2 ;(7)\nwhere h\u00f0t\u00de is the head trajectory and b h\u00f0t\u00de is the transformed head trajectory at time t. The head trajectory was obtained via fitting a 3D face model to the video as described in Section 4.\n\nMoreover, to avoid undesired deformation caused by grid warping, we use the Laplacian of the grid to measure the rigidity of the warping:\nE V \u00f0t\u00de \u00bc D\u00f0 b V t \u00de 2 ;(8)\nwhere D is an operator that takes the difference between a grid vertex b v x;y and the average of its four neighbors:\nD\u00f0 b V t \u00de \u00bc X x;y b v x;y \u00c0 \u00f0b v x\u00fe1;y \u00fe b v x\u00c01;y \u00fe b v x;y\u00fe1 \u00fe b v x;y\u00c01 \u00de=4 2 :(9)\nOptimization. Our final objective function is a combination of the smoothness measure and the regularization term:\nmin H t ; b V t X T \u00c02 t\u00bc1 E s \u00f0t\u00de \u00fe a E h \u00f0t\u00de \u00fe b E V \u00f0t\u00de:(10)\nDue to the high degree of freedom of the unknowns, the objective function has a complex landscape. Therefore, we first fix the grid b V t and solve for 2D projective transformation H t , then use the result as an initialization and refine by running the full optimization (10).\n\nWe use Matlab's nonlinear least-squares solver to solve this optimization problem. For each frame at time t, the error terms E s , E h and E V are only affected by 3 frames at t \u00c0 1, t and t \u00fe 1. This leads to a sparse jacobian matrix. Therefore this problem can be efficiently solved.\n\n\nRESULTS\n\nIn this section, we show example frames of selfie video stabilization, along with the visual comparison of the input video, our result, Liu et al. [5] and Grundmann et al. [2]. We also show that our method achieves better quantitative results than the comparison methods in both selfie video cases and general video cases. Finally we discuss the advantages of our method over general video stabilization methods. Our results are generated with fixed parameters a \u00bc 1 and b \u00bc 5. On average, our Matlab code takes 15 min in all: 3 min for head fitting, 1 min for optical flow, 8 min for optimization and 3 min for warping and rendering the video on a desktop computer with an Intel i7-5930K CPU@ 3.5GHz. We did not focus on speed in this work and we believe that our optimization can be implemented on the GPU in future.\n\nTest Set. We collected 33 selfie video clips from the Internet, which is the first such dataset of selfie videos. A subset of our example clips are shown in Fig. 7. We label each video with properties that affect video stabilization: dynamic occlusion, multiple faces, large foreground motion, lack of background features, dynamic background and motion/ defocus blur (Fig. 9). Our test set is available at http:// cseweb.ucsd.edu/$viscomp/projects/ECCV18VideoStab for comparison of different methods, and we believe it will be a useful resource for the community.\n\nVisual Comparison. In Fig. 8, the video stills are scaled by the same factor so that their sizes can be compared. Our results have a larger field of view compared to Liu et al. [5] and Grundmann et al. [2], which is often desired in stabilizing selfie videos. This is because the movement of the camera is large in these examples. The methods proposed by Liu et al. [5] and Grundmann et al. [2] over-stabilize the background, resulting in a small overlap region among frames.  [2] result and Liu et al. [5] result. The video stills are scaled by the same factor. Our method generates results with larger field of view and does not introduce visible distortion. We recommend readers to watch the accompanying video for more visual comparison. Labels represent example indices in Fig. 9. Fig. 7. Example video stills from our dataset. The labels represent the example indices in Fig. 9.\n\nTo obtain a rectangular video, most of the regions have to be cropped. Our method considers the foreground and background motion together and allows the frame to move in a low frequency sense. Therefore we avoid over-stabilization with respect to either foreground or background. Also note that our result preserves the original shape of the face and body, while the Liu et al. [5] result contains large distortions on the face. This is because we excluded the pixels in the foreground, so the face and body region is not affected by the grid warping. Since the dynamics are hard to show with images, we recommend readers to watch the accompanying video for the visual comparison of the results.\n\nOur method is not sensitive to b , but by changing the head regularization value a in (10), we can control the algorithm to mainly stabilize the foreground or the background. We also included an example stabilized with different a values in the accompanying video.\n\nQuantitative Comparision. To evaluate the level of smoothness of the videos, we compute the average squared magnitude of second derivative of tracks of all pixels in each frame. The smoothness measure is defined as:\nS \u00bc 1 V j j X T \u00c02 t\u00bc1 X i v t;i \u00f0t \u00fe 1\u00de \u00c0 2v t;i \u00f0t\u00de \u00fe v t;i \u00f0t \u00c0 1\u00de 2 ;(11)\nwhere we track all the pixels v v t \u00bc v t;1 ; v t;2 ::: \u00c8 \u00c9 in the frame at time t, and V is the set of all the pixels v v 1 ; v v 2 :::v v T \u00c01 f g . Since we sum the second derivatives of all the pixel tracks, a smaller smoothness measure indicates that the frames are changing in a more stabilized way. In (11), we use the optical flow to track the pixels. To eliminate the effect of different video sizes, we normalize the optical flow with the frame size on horizontal and vertical directions respectively. We show smoothness comparison for these examples in Fig. 9. Note that a lower bar indicates a better result. For better comparison, we sorted the examples by their original smoothness value. Our final results achieve better smoothness compared to the results of Liu et al. [5] and Grundmann et al. [2] in all of the examples.\n\nFor more comprehensive comparison, we also provide quantative comparison with Liu et al. [5] and Grundmann et al. [2] using the three metrics in Liu et al. [6]. The result is shown in Fig. 10. Note that in these metrics, a higher bar indicates a better result. The colored horizontal lines indicate the average metric values of the corresponding methods over the entire dataset. These results clearly show that our method still performs better under these metrics in the sense of the amount of cropping, distortion and stability. This indicates the effectiveness of our methods in stabilizing selfie videos.\n\nAdvantages. Our method has some advantages over other general video stabilization methods in the selfie video case. Traditional 2D and 3D methods usually rely on feature tracks [1], [2], [5], [11], making them vulnerable to insufficient feature counts in selfie videos. Since our method uses optical flow to track the motion, we achieve significantly better result in videos with few background features (examples 3, 5, 10, 11, 12, 21, 24, 26 and 29 in Fig. 9). Note that the feature point based general video stabilization methods fail in some of the low feature count cases (examples 5, 21 and 29 in Fig. 9), resulting in an even higher smoothness value than the input video. Our method is also robust to videos with motion blur and defocus blur, which are very common properties in selfie videos.\n\nIt is hard to obtain long feature tracks in selfie videos with large foreground motion. Note that 3D methods like Liu et al. [5] cannot perform accurate structure from motion when there is dynamic occlusion. Therefore Liu et al. [5] in general does not perform well in large foreground motion cases (examples 2, 4, 6, 8, 9, 11, 13, 14, 15, 16 and 27 in Fig. 9). Using only fragments of pixel trajectories over 3 frames, our method is robust to large occlusions near the camera. This strategy also helps handle dynamic background (examples 8,14,15,18,20,27,28,30 and 31 in which multiple non-dominant faces or moving objects exist).\n\nTo stabilize the foreground, we need to find the component of head motion that can represent the entire foreground's motion. Our method benefits from a 3D head model since we effectively rule out the head motion purely from rotation and expression. To show this benefit, we compare smoothness measures of example 1, 2, 3, 4, 6, 11 using the 3D head model, the 2D facial landmarks/3D facial landmarks from Bulat and Tzimiropoulos [24] and the face bounding box from Viola et al. [27] in Fig. 11.\n\nIn these experiments, we use the centroid of landmarks or the center of the face bounding box as the head position.\n\nNote that examples 1, 2, 3 are chosen as general representative examples while 4, 6, 11 are videos with relatively large foreground area or large face rotation/expression. As shown in Fig. 11, using 3D head model fitting in general performs better than using just the 2D/3D landmarks or the bounding boxes. In examples 4, 6 and 11, the benefit becomes larger since the 2D/3D landmarks or the bounding boxes are sensitive to head rotation and facial expression change. Note that the 3D head model fitting can be replaced with a more complex algorithm like Shi et al. [20] and Thies et al. [17] in Fig. 4. Fig. 11 only shows the benefit of using a 3D head model in general.\n\nFinally, our method provides a novel application of 3D face modeling: track the foreground motion in selfie videos. Current 2D video stabilization methods focus on detecting nonrigid regions and do not consider the motion in these regions. In selfie videos, the foreground occupies a large portion of the frames and cannot be ignored. Our method automatically plans the motion so that both foreground and background motion are smoothed. The foreground motion also helps regularize the video stabilization process. In all of the examples, our method avoids over stabilizing the background and produces results with significantly larger field of view.\n\nGeneralization. Our method also applies to stabilizing general videos. We can simply ignore the E h term in (10) and perform the optimization for the entire background region. We also collect 6 general videos along with 10 videos from Liu et al. [5], Grundmann et al. [2] and Liu et al. [6] shown in Fig. 12 and compare the smoothness of our result against the comparison methods. Note that we only use 3 neighboring frames to track the frame motion and only local motion information is available. Therefore, our method faces a harder problem in general video stabilization. However, Fig. 12 shows that our method achieves much better results to Grundmann et al. [2], Liu et al. [5] and Liu et al. [6] in most of the general video cases. Our results also perform better on average under the three metrics in Liu et al. [6]. This indicates that our optical flow based pixel tracking is generally more robust than feature based tracking. Moreover, our method performs significantly better in the blurred video case (example 13) also thanks to the optical flow as the pixel tracking method.  We also evaluate our method over the widely used general video stabilization dataset (NUS dataset [6]) in Fig. 13. The comparison to Liu et al. [6], Grundmann et al. [2] and Liu et al. [5] is based on both our metric and the 3 metrics proposed in Liu et al. [6]. In this figure, we average the metric values for each category summarized in the NUS dataset [6]. Overall, our method shows competitive performance in the most important smoothness metric and stability metric, with less cropping and distortion. Note that our method is robust in the quick rotation category, in which 3D methods fail to generate satisfactory results.\n\nFailure Cases. Our frame motion model does not apply to videos with complex motions, e.g., strong rolling shutter effect and fisheye effect. We also include a selfie video taken with a fisheye camera in the accompanying video, in which our method does not perform well. Our method does not  explicitly correct motion blur. Therefore our results on videos with strong motion blur (mostly because of low illumination) will have unsatisfactory appearance. Our result of example 4 in the selfie video dataset belongs to this category. Note that Fig. 9 shows that we still generate better results for example 4 compared to Liu et al. [5] and Grundmann et al. [2].\n\n\nCONCLUSION, LIMITATIONS AND FUTURE WORK\n\nWe proposed a novel video stabilization technique for selfie videos. Our method analyzes the motion of foreground (face and body) using a 3D face model and the motion of background by temporally tracking the pixels using optical flow. We achieve visually and quantatively better results than the state-of-the-art general video stabilization methods. Our method also exhibits robustness under different situations (e.g., large foreground occlusion, blur due to motion or out-of-focus and foreground/background motion mismatch).\n\nOur method requires optical flow to track pixels in the video, and therefore suffers from the overhead of computing optical flow for neighboring frames. Another limitation of our method is that we require that facial landmarks can be detected in most of the frames. In our experiments, we linearly interpolate the head position for frames in which no face was detected. If the faces are undetectable in many consecutive frames, simply interpolating head positions will yield inaccurate estimation of the foreground motion. These limitations can be resolved by applying a more efficient optical flow technique and a more robust facial landmark detector. Our frame motion model does not apply to videos with complex motion. Our method also does not correct motion blur. Therefore for night-time videos or videos taken under dark lighting conditions, our method does not produce satisfactory results.\n\nSince our method utilizes the 3D face model in selfie videos, one future work would be using 3D information to estimate 3D camera motion, so that the 3D video stabilization can be applied to selfie videos with large dynamic occlusions. The 3D face model also enables other future works, including manipulating the shape and expression of the face in selfie videos or high quality 3D reconstruction of face and body from selfie videos. Jiyang Yu received the BS degree in electrical engineering from Southeast University, China in 2011, and the MS degree in electrical engineering from Washington State University, in 2013. He is currently working toward the PhD degree in electrical and computer engineering at the University of California, San Diego. His research interests are computer vision and graphics.\n\nRavi Ramamoorthi received the BS degree in engineering and applied science and MS degrees in computer science and physics from the California Institute of Technology, in 1998, and the PhD degree in computer science from the Stanford University Computer Graphics Laboratory, in 2002, upon which he joined the Columbia University Computer Science Department. He was on the UC Berkeley EECS faculty from 2009-2014. Since July 2014, he is a professor of Computer Science and Engineering at the University of California, San Diego, where he holds the Ronald L. Graham Chair of Computer Science. He is also the founding director of the UC San Diego Center for Visual Computing. His research interests cover many areas of computer vision and graphics, with more than 150 publications. His research has been recognized with a number of awards, including the 2007 ACM SIGGRAPH Significant New Researcher Award in computer graphics, and by the white house with a Presidential Early Career Award for Scientists and Engineers in 2008 for his work on physics-based computer vision. Most recently, he was named an IEEE and ACM Fellow in 2017, and inducted into the SIGGRAPH Academy in 2019. He has advised more than 20 Postdoctoral, PhD and MS students, many of whom have gone on to leading positions in industry and academia; and he has taught the first open online course in computer graphics on the edX platform in fall 2012, with more than 100,000 students enrolled in that and subsequent iterations. He was a finalist for the inaugural 2016 edX Prize for exceptional contributions in online teaching and learning, and again in 2017.\n\nFig. 1 .\n1Selfie videos have several properties that cause difficulties for traditional video stabilization methods: (a) Face and body significantly occludes the background; (b) bad feature detection caused by motion blur/out of focus, insets show areas where feature points are hard to track accurately; (c) foreground and background motion mismatch, the foreground motion (red) can be different from background motion (blue) due to the dynamics of face and body; Our method uses (d) a 3D face model to analyze the motion in the foreground and (e) optical flow to analyze the motion in the background. The video is stabilized with respect to both foreground and background.\n\nFig. 3 .\n3The vertices used as contour 3D landmarks are fixed in the fitting process. The fitted face is rendered and new contour 2D landmarks are detected. The projected vertices closest to the detected 2D contour landmarks are selected as 3D contour landmarks for the next iteration.\n\nFig. 4 .\n4Comparison of our 3D face fitting result to Shi et al.\n\nFig. 5 .\n5A: Accumulated optical flow. A large value indicates the background area. B: Example moving standard deviation of optical flow. Large values indicate the edges of objects in the scene.\n\nFig. 6 .\n6Our method tracks background pixels for 3 neighboring frames.\n\nFig. 8 .\n8Visual comparison of input video, our result, Grundmann et al.\n\nFig. 9 .\n9Smoothness comparison of input video, our result, Liu et al. result [5] and Grundmann et al. result [2]. The horizontal axis represents the examples, and the height of the bar represents the smoothness value. Colored arrows are added where the bars overlap. The labeled properties are visualized as colored dots below each example.\n\nFig. 11 .\n11Smoothness comparison using 3D head model, 2D/3D landmarks[23] and face bounding box from Viola et al.[27] A lower bar indicates a better result.\n\nFig. 10 .\n10Comparison using 3 metrics suggested in Liu et al.[6]. Horizontal lines represent the average metric values of the corresponding methods. Note that a higher bar indicates a better result in these metrics.\n\nFig. 12 .\n12Example video stills from our test set, and smoothness comparison on general videos, showing our result, Liu et al. [5] result, Grundmann et al. [2] result and Liu et al. [6] result. For our metric (the upper left figure) a lower bar indicates a better result. For the other 3 metrics, a higher bar indicates a better result. Numbers on video stills indicate the example indices on the bar graph. Horizontal lines represent the average values of the corresponding methods.\n\nFig. 13 .\n13Comparison with Liu et al.[6], Grundmann et al.[2] and Liu et al.[5] and over the NUS dataset[6] using our metric and the 3 metrics proposed in Liu et al.[6]. The results are averaged over each category. For our metric, a lower bar indicates a better result. For the other 3 metrics, a higher bar indicates a better result.\n\" For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/csdl.\nACKNOWLEDGMENTSWe thank Nima Khademi Kalantari for the supplementary video voice over. This work was supported in part by Sony, the Ronald L. Graham endowed Chair, and the UC San Diego Center for Visual Computing.\nSubspace video stabilization. F Liu, M Gleicher, J Wang, H Jin, A Agarwala, ACM Trans. Graph. 301F. Liu, M. Gleicher, J. Wang, H. Jin, and A. Agarwala, \"Subspace video stabilization,\" ACM Trans. Graph., vol. 30, no. 1, Feb. 2011, Art. no. 4.\n\nAuto-directed video stabilization with robust L1 optimal camera paths. M Grundmann, V Kwatra, I Essa, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitM. Grundmann, V. Kwatra, and I. Essa, \"Auto-directed video sta- bilization with robust L1 optimal camera paths,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2011, pp. 225-232.\n\nSteadyflow: Spatially smooth optical flow for video stabilization. S Liu, L Yuan, P Tan, J Sum, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitS. Liu, L. Yuan, P. Tan, and J. Sum, \"Steadyflow: Spatially smooth optical flow for video stabilization,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2014, pp. 4209-4216.\n\nSelfie video stabilization. J Yu, R Ramamoorthi, Proc. Eur. Conf. Comput. Vis. Eur. Conf. Comput. VisJ. Yu and R. Ramamoorthi, \"Selfie video stabilization,\" in Proc. Eur. Conf. Comput. Vis., 2018, pp. 569-584.\n\nContent-preserving warps for 3D video stabilization. F Liu, M Gleicher, H Jin, A Agarwala, ACM Trans. Graph. 283F. Liu, M. Gleicher, H. Jin, and A. Agarwala, \"Content-preserving warps for 3D video stabilization,\" ACM Trans. Graph., vol. 28, no. 3, Jul. 2009, Art. no. 44.\n\nBundled camera paths for video stabilization. S Liu, L Yuan, P Tan, J Sun, ACM Trans. Graph. 324S. Liu, L. Yuan, P. Tan, and J. Sun, \"Bundled camera paths for video stabilization,\" ACM Trans. Graph., vol. 32, no. 4, Jul. 2013, Art. no. 78.\n\nRe-cinematography: Improving the camerawork of casual video. M L Gleicher, F Liu, ACM Trans. Multimedia Comput. Commun. Appl. 51M. L. Gleicher and F. Liu, \"Re-cinematography: Improving the camerawork of casual video,\" ACM Trans. Multimedia Comput. Commun. Appl., vol. 5, no. 1, Oct. 2008, Art. no. 2.\n\nSpatially and temporally optimized video stabilization. Y S Wang, F Liu, P S Hsu, T Y Lee, IEEE Trans. Visual. Comput. Graph. 198Y. S. Wang, F. Liu, P. S. Hsu, and T. Y. Lee, \"Spatially and tempo- rally optimized video stabilization,\" IEEE Trans. Visual. Comput. Graph., vol. 19, no. 8, pp. 1354-1361, Aug 2013.\n\nVideo stabilization using epipolar geometry. A Goldstein, R , ACM Trans. Graph. 315A. Goldstein and R. Fattal, \"Video stabilization using epipolar geometry,\" ACM Trans. Graph., vol. 31, no. 5, Sep. 2012.\n\nNon-metric image-based rendering for video stabilization. C Buehler, M Bosse, L Mcmillan, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitC. Buehler, M. Bosse, and L. McMillan, \"Non-metric image-based rendering for video stabilization,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2001, pp. II-II.\n\nLight field video stabilization. B M Smith, L Zhang, H Jin, A Agarwala, Proc. IEEE Int. Conf. Comput. Vis. IEEE Int. Conf. Comput. VisB. M. Smith, L. Zhang, H. Jin, and A. Agarwala, \"Light field video stabilization,\" in Proc. IEEE Int. Conf. Comput. Vis., 2009, pp. 341-348.\n\nVideo stabilization with a depth camera. J Sun, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitJ. Sun, \"Video stabilization with a depth camera,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2012, pp. 89-95.\n\nA morphable model for the synthesis of 3D faces. V Blanz, T Vetter, Proc. 26th Annu. Conf. Comput. Graphics interactive Techn. 26th Annu. Conf. Comput. Graphics interactive TechnV. Blanz and T. Vetter, \"A morphable model for the synthesis of 3D faces,\" in Proc. 26th Annu. Conf. Comput. Graphics interactive Techn., 1999, pp. 187-194.\n\nFacewarehouse: A 3D facial expression database for visual computing. C Cao, Y Weng, S Zhou, Y Tong, K Zhou, IEEE Trans. Visual. Comput. Graph. 203C. Cao, Y. Weng, S. Zhou, Y. Tong, and K. Zhou, \"Facewarehouse: A 3D facial expression database for visual computing,\" IEEE Trans. Visual. Comput. Graph., vol. 20, no. 3, pp. 413-425, Mar. 2014.\n\nPerspective-aware manipulation of portrait photos. O Fried, E Shechtman, D B Goldman, A Finkelstein, ACM Trans. Graph. 354O. Fried, E. Shechtman, D. B. Goldman, and A. Finkelstein, \"Perspective-aware manipulation of portrait photos,\" ACM Trans. Graph., vol. 35, no. 4, 2016, Art. no. 128.\n\nReanimating faces in images and video. V Blanz, C Basso, T Poggio, T Vetter, Comput. Graph. Forum. 223V. Blanz, C. Basso, T. Poggio, and T. Vetter, \"Reanimating faces in images and video,\" Comput. Graph. Forum, vol. 22, no. 3, pp. 554-561, 2003.\n\nFace2Face: Real-time face capture and reenactment of RGB videos. J Thies, M Zollh\u20ac Ofer, M Stamminger, C Theobalt, M Nie\u00dfner, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitJ. Thies, M. Zollh\u20ac ofer, M. Stamminger, C. Theobalt, and M. Nie\u00dfner, \"Face2Face: Real-time face capture and reenactment of RGB vid- eos,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016, pp. 2387-2395.\n\nDisplaced dynamic expression regression for real-time facial tracking and animation. C Cao, Q Hou, K Zhou, ACM Trans. Graph. 334C. Cao, Q. Hou, and K. Zhou, \"Displaced dynamic expression regression for real-time facial tracking and animation,\" ACM Trans. Graph., vol. 33, no. 4, Jul. 2014, Art. no. 43.\n\nReal-time high-fidelity facial performance capture. C Cao, D Bradley, K Zhou, T Beeler, ACM Trans. Graph. 344C. Cao, D. Bradley, K. Zhou, and T. Beeler, \"Real-time high-fidelity facial performance capture,\" ACM Trans. Graph., vol. 34, no. 4, Jul. 2015, Art. no. 46.\n\nAutomatic acquisition of high-fidelity facial performances using monocular videos. F Shi, H.-T Wu, X Tong, J Chai, ACM Trans. Graph. 336Art. no. 222F. Shi, H.-T. Wu, X. Tong, and J. Chai, \"Automatic acquisition of high-fidelity facial performances using monocular videos,\" ACM Trans. Graph., vol. 33, no. 6, 2014, Art. no. 222.\n\nReconstruction of personalized 3D face rigs from monocular video. P Garrido, M Zollh\u20ac Ofer, D Casas, L Valgaerts, K Varanasi, P , C Theobalt, ACM Trans. Graph. 353P. Garrido, M. Zollh\u20ac ofer, D. Casas, L. Valgaerts, K. Varanasi, P. P erez, and C. Theobalt, \"Reconstruction of personalized 3D face rigs from monocular video,\" ACM Trans. Graph., vol. 35, no. 3, May 2016, Art. no. 28.\n\nDynamic 3D avatar creation from hand-held video input. A E Ichim, S Bouaziz, M Pauly, ACM Trans. Graph. 344A. E. Ichim, S. Bouaziz, and M. Pauly, \"Dynamic 3D avatar crea- tion from hand-held video input,\" ACM Trans. Graph., vol. 34, no. 4, Jul. 2015, Art. no. 45.\n\nDeformation transfer for triangle meshes. R W Sumner, J Popovi, Proc. ACM SIGGRAPH Papers. ACM SIGGRAPH PapersR. W. Sumner and J. Popovi c, \"Deformation transfer for triangle meshes,\" in Proc. ACM SIGGRAPH Papers, 2004, pp. 399-405.\n\nHow far are we from solving the 2D & 3D face alignment problem? (and a dataset of 230,000 3D facial landmarks). A Bulat, G Tzimiropoulos, Proc. IEEE Int. Conf. Comput. Vis. IEEE Int. Conf. Comput. VisA. Bulat and G. Tzimiropoulos, \"How far are we from solving the 2D & 3D face alignment problem? (and a dataset of 230,000 3D facial landmarks),\" in Proc. IEEE Int. Conf. Comput. Vis., 2017, pp. 1021-1030.\n\nUserassisted video stabilization. J Bai, A Agarwala, M Agrawala, R Ramamoorthi, Proc. 25th Eur. Symp. Rendering. 25th Eur. Symp. RenderingJ. Bai, A. Agarwala, M. Agrawala, and R. Ramamoorthi, \"User- assisted video stabilization,\" in Proc. 25th Eur. Symp. Rendering, 2014, pp. 61-70.\n\nFast optical flow using dense inverse search. T Kroeger, R Timofte, D Dai, L V Gool, Proc. Eur. Conf. Comput. Vis., Part IV. Eur. Conf. Comput. Vis., Part IVT. Kroeger, R. Timofte, D. Dai, and L. V. Gool, \"Fast optical flow using dense inverse search,\" in Proc. Eur. Conf. Comput. Vis., Part IV, 2016, pp. 471-488.\n\nRapid object detection using a boosted cascade of simple features. P A Viola, M J Jones, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitP. A. Viola and M. J. Jones, \"Rapid object detection using a boosted cascade of simple features,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2001, pp. I-I.\n", "annotations": {"author": "[{\"end\":40,\"start\":30},{\"end\":70,\"start\":41},{\"end\":40,\"start\":30},{\"end\":70,\"start\":41}]", "publisher": null, "author_last_name": "[{\"end\":39,\"start\":37},{\"end\":69,\"start\":58},{\"end\":39,\"start\":37},{\"end\":69,\"start\":58}]", "author_first_name": "[{\"end\":36,\"start\":30},{\"end\":57,\"start\":53},{\"end\":36,\"start\":30},{\"end\":57,\"start\":53}]", "author_affiliation": null, "title": "[{\"end\":27,\"start\":1},{\"end\":97,\"start\":71},{\"end\":27,\"start\":1},{\"end\":97,\"start\":71}]", "venue": null, "abstract": "[{\"end\":952,\"start\":171},{\"end\":952,\"start\":171}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1331,\"start\":1328},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1368,\"start\":1365},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2803,\"start\":2800},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3074,\"start\":3071},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5184,\"start\":5181},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5238,\"start\":5235},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5257,\"start\":5254},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5313,\"start\":5310},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5553,\"start\":5550},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5622,\"start\":5619},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5647,\"start\":5644},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5666,\"start\":5663},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5764,\"start\":5761},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6165,\"start\":6162},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6326,\"start\":6323},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6421,\"start\":6418},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6580,\"start\":6577},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6672,\"start\":6669},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6773,\"start\":6770},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6936,\"start\":6933},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7438,\"start\":7435},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7714,\"start\":7710},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7784,\"start\":7780},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7844,\"start\":7840},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8310,\"start\":8306},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8425,\"start\":8421},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8602,\"start\":8598},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8621,\"start\":8617},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8667,\"start\":8663},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8686,\"start\":8682},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8719,\"start\":8715},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8765,\"start\":8761},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8786,\"start\":8782},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8841,\"start\":8837},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8860,\"start\":8856},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9139,\"start\":9135},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9159,\"start\":9155},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12357,\"start\":12353},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12413,\"start\":12409},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12608,\"start\":12604},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12814,\"start\":12810},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12867,\"start\":12863},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":13399,\"start\":13395},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":13433,\"start\":13429},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13814,\"start\":13810},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":15629,\"start\":15625},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":16820,\"start\":16816},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16886,\"start\":16882},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17110,\"start\":17107},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":17185,\"start\":17181},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18102,\"start\":18098},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18191,\"start\":18187},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":18608,\"start\":18604},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18785,\"start\":18781},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18807,\"start\":18803},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23793,\"start\":23790},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25538,\"start\":25534},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25988,\"start\":25985},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":26013,\"start\":26010},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27403,\"start\":27400},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":27428,\"start\":27425},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27592,\"start\":27589},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":27617,\"start\":27614},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":27703,\"start\":27700},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27729,\"start\":27726},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":28490,\"start\":28487},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":30154,\"start\":30151},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":30179,\"start\":30176},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":30297,\"start\":30294},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":30322,\"start\":30319},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":30364,\"start\":30361},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30994,\"start\":30991},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":30999,\"start\":30996},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":31004,\"start\":31001},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":31010,\"start\":31006},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":31743,\"start\":31740},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":31847,\"start\":31844},{\"end\":31967,\"start\":31924},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":32156,\"start\":32154},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":32159,\"start\":32156},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":32162,\"start\":32159},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32165,\"start\":32162},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":32168,\"start\":32165},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":32171,\"start\":32168},{\"end\":32174,\"start\":32171},{\"end\":32176,\"start\":32174},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":32681,\"start\":32677},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":32730,\"start\":32726},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":33431,\"start\":33427},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":33453,\"start\":33449},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34297,\"start\":34293},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":34434,\"start\":34431},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":34456,\"start\":34453},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":34475,\"start\":34472},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":34851,\"start\":34848},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":34867,\"start\":34864},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":34886,\"start\":34883},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35007,\"start\":35004},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35375,\"start\":35372},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35421,\"start\":35418},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":35443,\"start\":35440},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":35462,\"start\":35459},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35535,\"start\":35532},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35633,\"start\":35630},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":36537,\"start\":36534},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":36562,\"start\":36559},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":42258,\"start\":42254},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":42302,\"start\":42298},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":42408,\"start\":42405},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":43088,\"start\":43085},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":43109,\"start\":43106},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":43127,\"start\":43124},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":43155,\"start\":43152},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":43216,\"start\":43213},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1331,\"start\":1328},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1368,\"start\":1365},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2803,\"start\":2800},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3074,\"start\":3071},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5184,\"start\":5181},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5238,\"start\":5235},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5257,\"start\":5254},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5313,\"start\":5310},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5553,\"start\":5550},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5622,\"start\":5619},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5647,\"start\":5644},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5666,\"start\":5663},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5764,\"start\":5761},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6165,\"start\":6162},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6326,\"start\":6323},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6421,\"start\":6418},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6580,\"start\":6577},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6672,\"start\":6669},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6773,\"start\":6770},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6936,\"start\":6933},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7438,\"start\":7435},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7714,\"start\":7710},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7784,\"start\":7780},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7844,\"start\":7840},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8310,\"start\":8306},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8425,\"start\":8421},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8602,\"start\":8598},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8621,\"start\":8617},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8667,\"start\":8663},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8686,\"start\":8682},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8719,\"start\":8715},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8765,\"start\":8761},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8786,\"start\":8782},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8841,\"start\":8837},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8860,\"start\":8856},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9139,\"start\":9135},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9159,\"start\":9155},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12357,\"start\":12353},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12413,\"start\":12409},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12608,\"start\":12604},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12814,\"start\":12810},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12867,\"start\":12863},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":13399,\"start\":13395},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":13433,\"start\":13429},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13814,\"start\":13810},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":15629,\"start\":15625},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":16820,\"start\":16816},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16886,\"start\":16882},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17110,\"start\":17107},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":17185,\"start\":17181},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18102,\"start\":18098},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18191,\"start\":18187},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":18608,\"start\":18604},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18785,\"start\":18781},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18807,\"start\":18803},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23793,\"start\":23790},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25538,\"start\":25534},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25988,\"start\":25985},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":26013,\"start\":26010},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27403,\"start\":27400},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":27428,\"start\":27425},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27592,\"start\":27589},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":27617,\"start\":27614},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":27703,\"start\":27700},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27729,\"start\":27726},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":28490,\"start\":28487},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":30154,\"start\":30151},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":30179,\"start\":30176},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":30297,\"start\":30294},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":30322,\"start\":30319},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":30364,\"start\":30361},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30994,\"start\":30991},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":30999,\"start\":30996},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":31004,\"start\":31001},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":31010,\"start\":31006},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":31743,\"start\":31740},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":31847,\"start\":31844},{\"end\":31967,\"start\":31924},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":32156,\"start\":32154},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":32159,\"start\":32156},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":32162,\"start\":32159},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32165,\"start\":32162},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":32168,\"start\":32165},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":32171,\"start\":32168},{\"end\":32174,\"start\":32171},{\"end\":32176,\"start\":32174},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":32681,\"start\":32677},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":32730,\"start\":32726},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":33431,\"start\":33427},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":33453,\"start\":33449},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34297,\"start\":34293},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":34434,\"start\":34431},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":34456,\"start\":34453},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":34475,\"start\":34472},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":34851,\"start\":34848},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":34867,\"start\":34864},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":34886,\"start\":34883},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35007,\"start\":35004},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35375,\"start\":35372},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35421,\"start\":35418},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":35443,\"start\":35440},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":35462,\"start\":35459},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35535,\"start\":35532},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35633,\"start\":35630},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":36537,\"start\":36534},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":36562,\"start\":36559},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":42258,\"start\":42254},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":42302,\"start\":42298},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":42408,\"start\":42405},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":43088,\"start\":43085},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":43109,\"start\":43106},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":43127,\"start\":43124},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":43155,\"start\":43152},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":43216,\"start\":43213}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":41143,\"start\":40468},{\"attributes\":{\"id\":\"fig_1\"},\"end\":41430,\"start\":41144},{\"attributes\":{\"id\":\"fig_2\"},\"end\":41496,\"start\":41431},{\"attributes\":{\"id\":\"fig_3\"},\"end\":41692,\"start\":41497},{\"attributes\":{\"id\":\"fig_4\"},\"end\":41765,\"start\":41693},{\"attributes\":{\"id\":\"fig_5\"},\"end\":41839,\"start\":41766},{\"attributes\":{\"id\":\"fig_6\"},\"end\":42182,\"start\":41840},{\"attributes\":{\"id\":\"fig_7\"},\"end\":42341,\"start\":42183},{\"attributes\":{\"id\":\"fig_8\"},\"end\":42559,\"start\":42342},{\"attributes\":{\"id\":\"fig_9\"},\"end\":43045,\"start\":42560},{\"attributes\":{\"id\":\"fig_10\"},\"end\":43382,\"start\":43046},{\"attributes\":{\"id\":\"fig_0\"},\"end\":41143,\"start\":40468},{\"attributes\":{\"id\":\"fig_1\"},\"end\":41430,\"start\":41144},{\"attributes\":{\"id\":\"fig_2\"},\"end\":41496,\"start\":41431},{\"attributes\":{\"id\":\"fig_3\"},\"end\":41692,\"start\":41497},{\"attributes\":{\"id\":\"fig_4\"},\"end\":41765,\"start\":41693},{\"attributes\":{\"id\":\"fig_5\"},\"end\":41839,\"start\":41766},{\"attributes\":{\"id\":\"fig_6\"},\"end\":42182,\"start\":41840},{\"attributes\":{\"id\":\"fig_7\"},\"end\":42341,\"start\":42183},{\"attributes\":{\"id\":\"fig_8\"},\"end\":42559,\"start\":42342},{\"attributes\":{\"id\":\"fig_9\"},\"end\":43045,\"start\":42560},{\"attributes\":{\"id\":\"fig_10\"},\"end\":43382,\"start\":43046}]", "paragraph": "[{\"end\":1576,\"start\":968},{\"end\":2411,\"start\":1578},{\"end\":3509,\"start\":2413},{\"end\":4045,\"start\":3511},{\"end\":4468,\"start\":4047},{\"end\":5775,\"start\":4470},{\"end\":5928,\"start\":5792},{\"end\":7075,\"start\":5930},{\"end\":8131,\"start\":7077},{\"end\":9259,\"start\":8133},{\"end\":10390,\"start\":9272},{\"end\":11234,\"start\":10392},{\"end\":12274,\"start\":11258},{\"end\":12928,\"start\":12276},{\"end\":14045,\"start\":12984},{\"end\":14555,\"start\":14084},{\"end\":14804,\"start\":14557},{\"end\":15572,\"start\":15016},{\"end\":16897,\"start\":15574},{\"end\":18344,\"start\":16899},{\"end\":18923,\"start\":18368},{\"end\":19242,\"start\":18925},{\"end\":19953,\"start\":19244},{\"end\":20234,\"start\":19955},{\"end\":20614,\"start\":20236},{\"end\":21125,\"start\":20616},{\"end\":21715,\"start\":21143},{\"end\":21915,\"start\":21717},{\"end\":23133,\"start\":21917},{\"end\":23510,\"start\":23210},{\"end\":23882,\"start\":23512},{\"end\":24175,\"start\":23908},{\"end\":24477,\"start\":24209},{\"end\":24710,\"start\":24519},{\"end\":24849,\"start\":24712},{\"end\":24995,\"start\":24878},{\"end\":25197,\"start\":25083},{\"end\":25539,\"start\":25262},{\"end\":25826,\"start\":25541},{\"end\":26656,\"start\":25838},{\"end\":27221,\"start\":26658},{\"end\":28107,\"start\":27223},{\"end\":28804,\"start\":28109},{\"end\":29070,\"start\":28806},{\"end\":29287,\"start\":29072},{\"end\":30203,\"start\":29366},{\"end\":30812,\"start\":30205},{\"end\":31613,\"start\":30814},{\"end\":32246,\"start\":31615},{\"end\":32742,\"start\":32248},{\"end\":32859,\"start\":32744},{\"end\":33532,\"start\":32861},{\"end\":34183,\"start\":33534},{\"end\":35903,\"start\":34185},{\"end\":36563,\"start\":35905},{\"end\":37133,\"start\":36607},{\"end\":38032,\"start\":37135},{\"end\":38842,\"start\":38034},{\"end\":40467,\"start\":38844},{\"end\":1576,\"start\":968},{\"end\":2411,\"start\":1578},{\"end\":3509,\"start\":2413},{\"end\":4045,\"start\":3511},{\"end\":4468,\"start\":4047},{\"end\":5775,\"start\":4470},{\"end\":5928,\"start\":5792},{\"end\":7075,\"start\":5930},{\"end\":8131,\"start\":7077},{\"end\":9259,\"start\":8133},{\"end\":10390,\"start\":9272},{\"end\":11234,\"start\":10392},{\"end\":12274,\"start\":11258},{\"end\":12928,\"start\":12276},{\"end\":14045,\"start\":12984},{\"end\":14555,\"start\":14084},{\"end\":14804,\"start\":14557},{\"end\":15572,\"start\":15016},{\"end\":16897,\"start\":15574},{\"end\":18344,\"start\":16899},{\"end\":18923,\"start\":18368},{\"end\":19242,\"start\":18925},{\"end\":19953,\"start\":19244},{\"end\":20234,\"start\":19955},{\"end\":20614,\"start\":20236},{\"end\":21125,\"start\":20616},{\"end\":21715,\"start\":21143},{\"end\":21915,\"start\":21717},{\"end\":23133,\"start\":21917},{\"end\":23510,\"start\":23210},{\"end\":23882,\"start\":23512},{\"end\":24175,\"start\":23908},{\"end\":24477,\"start\":24209},{\"end\":24710,\"start\":24519},{\"end\":24849,\"start\":24712},{\"end\":24995,\"start\":24878},{\"end\":25197,\"start\":25083},{\"end\":25539,\"start\":25262},{\"end\":25826,\"start\":25541},{\"end\":26656,\"start\":25838},{\"end\":27221,\"start\":26658},{\"end\":28107,\"start\":27223},{\"end\":28804,\"start\":28109},{\"end\":29070,\"start\":28806},{\"end\":29287,\"start\":29072},{\"end\":30203,\"start\":29366},{\"end\":30812,\"start\":30205},{\"end\":31613,\"start\":30814},{\"end\":32246,\"start\":31615},{\"end\":32742,\"start\":32248},{\"end\":32859,\"start\":32744},{\"end\":33532,\"start\":32861},{\"end\":34183,\"start\":33534},{\"end\":35903,\"start\":34185},{\"end\":36563,\"start\":35905},{\"end\":37133,\"start\":36607},{\"end\":38032,\"start\":37135},{\"end\":38842,\"start\":38034},{\"end\":40467,\"start\":38844}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12983,\"start\":12929},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14083,\"start\":14046},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15015,\"start\":14805},{\"attributes\":{\"id\":\"formula_3\"},\"end\":23209,\"start\":23134},{\"attributes\":{\"id\":\"formula_4\"},\"end\":23907,\"start\":23883},{\"attributes\":{\"id\":\"formula_5\"},\"end\":24208,\"start\":24176},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24518,\"start\":24478},{\"attributes\":{\"id\":\"formula_7\"},\"end\":24877,\"start\":24850},{\"attributes\":{\"id\":\"formula_8\"},\"end\":25082,\"start\":24996},{\"attributes\":{\"id\":\"formula_9\"},\"end\":25261,\"start\":25198},{\"attributes\":{\"id\":\"formula_10\"},\"end\":29365,\"start\":29288},{\"attributes\":{\"id\":\"formula_0\"},\"end\":12983,\"start\":12929},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14083,\"start\":14046},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15015,\"start\":14805},{\"attributes\":{\"id\":\"formula_3\"},\"end\":23209,\"start\":23134},{\"attributes\":{\"id\":\"formula_4\"},\"end\":23907,\"start\":23883},{\"attributes\":{\"id\":\"formula_5\"},\"end\":24208,\"start\":24176},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24518,\"start\":24478},{\"attributes\":{\"id\":\"formula_7\"},\"end\":24877,\"start\":24850},{\"attributes\":{\"id\":\"formula_8\"},\"end\":25082,\"start\":24996},{\"attributes\":{\"id\":\"formula_9\"},\"end\":25261,\"start\":25198},{\"attributes\":{\"id\":\"formula_10\"},\"end\":29365,\"start\":29288}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":966,\"start\":954},{\"attributes\":{\"n\":\"2\"},\"end\":5790,\"start\":5778},{\"attributes\":{\"n\":\"3\"},\"end\":9270,\"start\":9262},{\"attributes\":{\"n\":\"4\"},\"end\":11256,\"start\":11237},{\"attributes\":{\"n\":\"5\"},\"end\":18366,\"start\":18347},{\"attributes\":{\"n\":\"6\"},\"end\":21141,\"start\":21128},{\"attributes\":{\"n\":\"7\"},\"end\":25836,\"start\":25829},{\"attributes\":{\"n\":\"8\"},\"end\":36605,\"start\":36566},{\"end\":40477,\"start\":40469},{\"end\":41153,\"start\":41145},{\"end\":41440,\"start\":41432},{\"end\":41506,\"start\":41498},{\"end\":41702,\"start\":41694},{\"end\":41775,\"start\":41767},{\"end\":41849,\"start\":41841},{\"end\":42193,\"start\":42184},{\"end\":42352,\"start\":42343},{\"end\":42570,\"start\":42561},{\"end\":43056,\"start\":43047},{\"attributes\":{\"n\":\"1\"},\"end\":966,\"start\":954},{\"attributes\":{\"n\":\"2\"},\"end\":5790,\"start\":5778},{\"attributes\":{\"n\":\"3\"},\"end\":9270,\"start\":9262},{\"attributes\":{\"n\":\"4\"},\"end\":11256,\"start\":11237},{\"attributes\":{\"n\":\"5\"},\"end\":18366,\"start\":18347},{\"attributes\":{\"n\":\"6\"},\"end\":21141,\"start\":21128},{\"attributes\":{\"n\":\"7\"},\"end\":25836,\"start\":25829},{\"attributes\":{\"n\":\"8\"},\"end\":36605,\"start\":36566},{\"end\":40477,\"start\":40469},{\"end\":41153,\"start\":41145},{\"end\":41440,\"start\":41432},{\"end\":41506,\"start\":41498},{\"end\":41702,\"start\":41694},{\"end\":41775,\"start\":41767},{\"end\":41849,\"start\":41841},{\"end\":42193,\"start\":42184},{\"end\":42352,\"start\":42343},{\"end\":42570,\"start\":42561},{\"end\":43056,\"start\":43047}]", "table": null, "figure_caption": "[{\"end\":41143,\"start\":40479},{\"end\":41430,\"start\":41155},{\"end\":41496,\"start\":41442},{\"end\":41692,\"start\":41508},{\"end\":41765,\"start\":41704},{\"end\":41839,\"start\":41777},{\"end\":42182,\"start\":41851},{\"end\":42341,\"start\":42196},{\"end\":42559,\"start\":42355},{\"end\":43045,\"start\":42573},{\"end\":43382,\"start\":43059},{\"end\":41143,\"start\":40479},{\"end\":41430,\"start\":41155},{\"end\":41496,\"start\":41442},{\"end\":41692,\"start\":41508},{\"end\":41765,\"start\":41704},{\"end\":41839,\"start\":41777},{\"end\":42182,\"start\":41851},{\"end\":42341,\"start\":42196},{\"end\":42559,\"start\":42355},{\"end\":43045,\"start\":42573},{\"end\":43382,\"start\":43059}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":1531,\"start\":1525},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2222,\"start\":2215},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2973,\"start\":2964},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3866,\"start\":3858},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4004,\"start\":3988},{\"end\":4730,\"start\":4724},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":4836,\"start\":4830},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":5043,\"start\":5037},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5324,\"start\":5316},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5421,\"start\":5412},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5676,\"start\":5667},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5773,\"start\":5765},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7926,\"start\":7917},{\"end\":9366,\"start\":9358},{\"end\":10121,\"start\":10115},{\"end\":14094,\"start\":14088},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16249,\"start\":16243},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17763,\"start\":17757},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18204,\"start\":18197},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19999,\"start\":19993},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20903,\"start\":20894},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":23509,\"start\":23503},{\"end\":26821,\"start\":26815},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":27032,\"start\":27025},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27251,\"start\":27245},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":28007,\"start\":28001},{\"end\":28015,\"start\":28009},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":28106,\"start\":28100},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29936,\"start\":29930},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":30396,\"start\":30389},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":31273,\"start\":31267},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":31422,\"start\":31416},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":31974,\"start\":31968},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32741,\"start\":32734},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":33052,\"start\":33045},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":33463,\"start\":33457},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":33472,\"start\":33465},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34492,\"start\":34485},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34776,\"start\":34769},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35387,\"start\":35380},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":36452,\"start\":36446},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":1531,\"start\":1525},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2222,\"start\":2215},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2973,\"start\":2964},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3866,\"start\":3858},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4004,\"start\":3988},{\"end\":4730,\"start\":4724},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":4836,\"start\":4830},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":5043,\"start\":5037},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5324,\"start\":5316},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5421,\"start\":5412},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5676,\"start\":5667},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5773,\"start\":5765},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7926,\"start\":7917},{\"end\":9366,\"start\":9358},{\"end\":10121,\"start\":10115},{\"end\":14094,\"start\":14088},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16249,\"start\":16243},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17763,\"start\":17757},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18204,\"start\":18197},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19999,\"start\":19993},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20903,\"start\":20894},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":23509,\"start\":23503},{\"end\":26821,\"start\":26815},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":27032,\"start\":27025},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27251,\"start\":27245},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":28007,\"start\":28001},{\"end\":28015,\"start\":28009},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":28106,\"start\":28100},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29936,\"start\":29930},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":30396,\"start\":30389},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":31273,\"start\":31267},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":31422,\"start\":31416},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":31974,\"start\":31968},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32741,\"start\":32734},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":33052,\"start\":33045},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":33463,\"start\":33457},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":33472,\"start\":33465},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34492,\"start\":34485},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34776,\"start\":34769},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35387,\"start\":35380},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":36452,\"start\":36446}]", "bib_author_first_name": "[{\"end\":43748,\"start\":43747},{\"end\":43755,\"start\":43754},{\"end\":43767,\"start\":43766},{\"end\":43775,\"start\":43774},{\"end\":43782,\"start\":43781},{\"end\":44032,\"start\":44031},{\"end\":44045,\"start\":44044},{\"end\":44055,\"start\":44054},{\"end\":44403,\"start\":44402},{\"end\":44410,\"start\":44409},{\"end\":44418,\"start\":44417},{\"end\":44425,\"start\":44424},{\"end\":44728,\"start\":44727},{\"end\":44734,\"start\":44733},{\"end\":44964,\"start\":44963},{\"end\":44971,\"start\":44970},{\"end\":44983,\"start\":44982},{\"end\":44990,\"start\":44989},{\"end\":45230,\"start\":45229},{\"end\":45237,\"start\":45236},{\"end\":45245,\"start\":45244},{\"end\":45252,\"start\":45251},{\"end\":45486,\"start\":45485},{\"end\":45488,\"start\":45487},{\"end\":45500,\"start\":45499},{\"end\":45783,\"start\":45782},{\"end\":45785,\"start\":45784},{\"end\":45793,\"start\":45792},{\"end\":45800,\"start\":45799},{\"end\":45802,\"start\":45801},{\"end\":45809,\"start\":45808},{\"end\":45811,\"start\":45810},{\"end\":46085,\"start\":46084},{\"end\":46098,\"start\":46097},{\"end\":46303,\"start\":46302},{\"end\":46314,\"start\":46313},{\"end\":46323,\"start\":46322},{\"end\":46625,\"start\":46624},{\"end\":46627,\"start\":46626},{\"end\":46636,\"start\":46635},{\"end\":46645,\"start\":46644},{\"end\":46652,\"start\":46651},{\"end\":46909,\"start\":46908},{\"end\":47174,\"start\":47173},{\"end\":47183,\"start\":47182},{\"end\":47530,\"start\":47529},{\"end\":47537,\"start\":47536},{\"end\":47545,\"start\":47544},{\"end\":47553,\"start\":47552},{\"end\":47561,\"start\":47560},{\"end\":47854,\"start\":47853},{\"end\":47863,\"start\":47862},{\"end\":47876,\"start\":47875},{\"end\":47878,\"start\":47877},{\"end\":47889,\"start\":47888},{\"end\":48132,\"start\":48131},{\"end\":48141,\"start\":48140},{\"end\":48150,\"start\":48149},{\"end\":48160,\"start\":48159},{\"end\":48405,\"start\":48404},{\"end\":48414,\"start\":48413},{\"end\":48429,\"start\":48428},{\"end\":48443,\"start\":48442},{\"end\":48455,\"start\":48454},{\"end\":48852,\"start\":48851},{\"end\":48859,\"start\":48858},{\"end\":48866,\"start\":48865},{\"end\":49123,\"start\":49122},{\"end\":49130,\"start\":49129},{\"end\":49141,\"start\":49140},{\"end\":49149,\"start\":49148},{\"end\":49421,\"start\":49420},{\"end\":49431,\"start\":49427},{\"end\":49437,\"start\":49436},{\"end\":49445,\"start\":49444},{\"end\":49733,\"start\":49732},{\"end\":49744,\"start\":49743},{\"end\":49759,\"start\":49758},{\"end\":49768,\"start\":49767},{\"end\":49781,\"start\":49780},{\"end\":49793,\"start\":49792},{\"end\":49797,\"start\":49796},{\"end\":50105,\"start\":50104},{\"end\":50107,\"start\":50106},{\"end\":50116,\"start\":50115},{\"end\":50127,\"start\":50126},{\"end\":50357,\"start\":50356},{\"end\":50359,\"start\":50358},{\"end\":50369,\"start\":50368},{\"end\":50661,\"start\":50660},{\"end\":50670,\"start\":50669},{\"end\":50989,\"start\":50988},{\"end\":50996,\"start\":50995},{\"end\":51008,\"start\":51007},{\"end\":51020,\"start\":51019},{\"end\":51285,\"start\":51284},{\"end\":51296,\"start\":51295},{\"end\":51307,\"start\":51306},{\"end\":51314,\"start\":51313},{\"end\":51316,\"start\":51315},{\"end\":51622,\"start\":51621},{\"end\":51624,\"start\":51623},{\"end\":51633,\"start\":51632},{\"end\":51635,\"start\":51634},{\"end\":43748,\"start\":43747},{\"end\":43755,\"start\":43754},{\"end\":43767,\"start\":43766},{\"end\":43775,\"start\":43774},{\"end\":43782,\"start\":43781},{\"end\":44032,\"start\":44031},{\"end\":44045,\"start\":44044},{\"end\":44055,\"start\":44054},{\"end\":44403,\"start\":44402},{\"end\":44410,\"start\":44409},{\"end\":44418,\"start\":44417},{\"end\":44425,\"start\":44424},{\"end\":44728,\"start\":44727},{\"end\":44734,\"start\":44733},{\"end\":44964,\"start\":44963},{\"end\":44971,\"start\":44970},{\"end\":44983,\"start\":44982},{\"end\":44990,\"start\":44989},{\"end\":45230,\"start\":45229},{\"end\":45237,\"start\":45236},{\"end\":45245,\"start\":45244},{\"end\":45252,\"start\":45251},{\"end\":45486,\"start\":45485},{\"end\":45488,\"start\":45487},{\"end\":45500,\"start\":45499},{\"end\":45783,\"start\":45782},{\"end\":45785,\"start\":45784},{\"end\":45793,\"start\":45792},{\"end\":45800,\"start\":45799},{\"end\":45802,\"start\":45801},{\"end\":45809,\"start\":45808},{\"end\":45811,\"start\":45810},{\"end\":46085,\"start\":46084},{\"end\":46098,\"start\":46097},{\"end\":46303,\"start\":46302},{\"end\":46314,\"start\":46313},{\"end\":46323,\"start\":46322},{\"end\":46625,\"start\":46624},{\"end\":46627,\"start\":46626},{\"end\":46636,\"start\":46635},{\"end\":46645,\"start\":46644},{\"end\":46652,\"start\":46651},{\"end\":46909,\"start\":46908},{\"end\":47174,\"start\":47173},{\"end\":47183,\"start\":47182},{\"end\":47530,\"start\":47529},{\"end\":47537,\"start\":47536},{\"end\":47545,\"start\":47544},{\"end\":47553,\"start\":47552},{\"end\":47561,\"start\":47560},{\"end\":47854,\"start\":47853},{\"end\":47863,\"start\":47862},{\"end\":47876,\"start\":47875},{\"end\":47878,\"start\":47877},{\"end\":47889,\"start\":47888},{\"end\":48132,\"start\":48131},{\"end\":48141,\"start\":48140},{\"end\":48150,\"start\":48149},{\"end\":48160,\"start\":48159},{\"end\":48405,\"start\":48404},{\"end\":48414,\"start\":48413},{\"end\":48429,\"start\":48428},{\"end\":48443,\"start\":48442},{\"end\":48455,\"start\":48454},{\"end\":48852,\"start\":48851},{\"end\":48859,\"start\":48858},{\"end\":48866,\"start\":48865},{\"end\":49123,\"start\":49122},{\"end\":49130,\"start\":49129},{\"end\":49141,\"start\":49140},{\"end\":49149,\"start\":49148},{\"end\":49421,\"start\":49420},{\"end\":49431,\"start\":49427},{\"end\":49437,\"start\":49436},{\"end\":49445,\"start\":49444},{\"end\":49733,\"start\":49732},{\"end\":49744,\"start\":49743},{\"end\":49759,\"start\":49758},{\"end\":49768,\"start\":49767},{\"end\":49781,\"start\":49780},{\"end\":49793,\"start\":49792},{\"end\":49797,\"start\":49796},{\"end\":50105,\"start\":50104},{\"end\":50107,\"start\":50106},{\"end\":50116,\"start\":50115},{\"end\":50127,\"start\":50126},{\"end\":50357,\"start\":50356},{\"end\":50359,\"start\":50358},{\"end\":50369,\"start\":50368},{\"end\":50661,\"start\":50660},{\"end\":50670,\"start\":50669},{\"end\":50989,\"start\":50988},{\"end\":50996,\"start\":50995},{\"end\":51008,\"start\":51007},{\"end\":51020,\"start\":51019},{\"end\":51285,\"start\":51284},{\"end\":51296,\"start\":51295},{\"end\":51307,\"start\":51306},{\"end\":51314,\"start\":51313},{\"end\":51316,\"start\":51315},{\"end\":51622,\"start\":51621},{\"end\":51624,\"start\":51623},{\"end\":51633,\"start\":51632},{\"end\":51635,\"start\":51634}]", "bib_author_last_name": "[{\"end\":43752,\"start\":43749},{\"end\":43764,\"start\":43756},{\"end\":43772,\"start\":43768},{\"end\":43779,\"start\":43776},{\"end\":43791,\"start\":43783},{\"end\":44042,\"start\":44033},{\"end\":44052,\"start\":44046},{\"end\":44060,\"start\":44056},{\"end\":44407,\"start\":44404},{\"end\":44415,\"start\":44411},{\"end\":44422,\"start\":44419},{\"end\":44429,\"start\":44426},{\"end\":44731,\"start\":44729},{\"end\":44746,\"start\":44735},{\"end\":44968,\"start\":44965},{\"end\":44980,\"start\":44972},{\"end\":44987,\"start\":44984},{\"end\":44999,\"start\":44991},{\"end\":45234,\"start\":45231},{\"end\":45242,\"start\":45238},{\"end\":45249,\"start\":45246},{\"end\":45256,\"start\":45253},{\"end\":45497,\"start\":45489},{\"end\":45504,\"start\":45501},{\"end\":45790,\"start\":45786},{\"end\":45797,\"start\":45794},{\"end\":45806,\"start\":45803},{\"end\":45815,\"start\":45812},{\"end\":46095,\"start\":46086},{\"end\":46311,\"start\":46304},{\"end\":46320,\"start\":46315},{\"end\":46332,\"start\":46324},{\"end\":46633,\"start\":46628},{\"end\":46642,\"start\":46637},{\"end\":46649,\"start\":46646},{\"end\":46661,\"start\":46653},{\"end\":46913,\"start\":46910},{\"end\":47180,\"start\":47175},{\"end\":47190,\"start\":47184},{\"end\":47534,\"start\":47531},{\"end\":47542,\"start\":47538},{\"end\":47550,\"start\":47546},{\"end\":47558,\"start\":47554},{\"end\":47566,\"start\":47562},{\"end\":47860,\"start\":47855},{\"end\":47873,\"start\":47864},{\"end\":47886,\"start\":47879},{\"end\":47901,\"start\":47890},{\"end\":48138,\"start\":48133},{\"end\":48147,\"start\":48142},{\"end\":48157,\"start\":48151},{\"end\":48167,\"start\":48161},{\"end\":48411,\"start\":48406},{\"end\":48426,\"start\":48415},{\"end\":48440,\"start\":48430},{\"end\":48452,\"start\":48444},{\"end\":48463,\"start\":48456},{\"end\":48856,\"start\":48853},{\"end\":48863,\"start\":48860},{\"end\":48871,\"start\":48867},{\"end\":49127,\"start\":49124},{\"end\":49138,\"start\":49131},{\"end\":49146,\"start\":49142},{\"end\":49156,\"start\":49150},{\"end\":49425,\"start\":49422},{\"end\":49434,\"start\":49432},{\"end\":49442,\"start\":49438},{\"end\":49450,\"start\":49446},{\"end\":49741,\"start\":49734},{\"end\":49756,\"start\":49745},{\"end\":49765,\"start\":49760},{\"end\":49778,\"start\":49769},{\"end\":49790,\"start\":49782},{\"end\":49806,\"start\":49798},{\"end\":50113,\"start\":50108},{\"end\":50124,\"start\":50117},{\"end\":50133,\"start\":50128},{\"end\":50366,\"start\":50360},{\"end\":50376,\"start\":50370},{\"end\":50667,\"start\":50662},{\"end\":50684,\"start\":50671},{\"end\":50993,\"start\":50990},{\"end\":51005,\"start\":50997},{\"end\":51017,\"start\":51009},{\"end\":51032,\"start\":51021},{\"end\":51293,\"start\":51286},{\"end\":51304,\"start\":51297},{\"end\":51311,\"start\":51308},{\"end\":51321,\"start\":51317},{\"end\":51630,\"start\":51625},{\"end\":51641,\"start\":51636},{\"end\":43752,\"start\":43749},{\"end\":43764,\"start\":43756},{\"end\":43772,\"start\":43768},{\"end\":43779,\"start\":43776},{\"end\":43791,\"start\":43783},{\"end\":44042,\"start\":44033},{\"end\":44052,\"start\":44046},{\"end\":44060,\"start\":44056},{\"end\":44407,\"start\":44404},{\"end\":44415,\"start\":44411},{\"end\":44422,\"start\":44419},{\"end\":44429,\"start\":44426},{\"end\":44731,\"start\":44729},{\"end\":44746,\"start\":44735},{\"end\":44968,\"start\":44965},{\"end\":44980,\"start\":44972},{\"end\":44987,\"start\":44984},{\"end\":44999,\"start\":44991},{\"end\":45234,\"start\":45231},{\"end\":45242,\"start\":45238},{\"end\":45249,\"start\":45246},{\"end\":45256,\"start\":45253},{\"end\":45497,\"start\":45489},{\"end\":45504,\"start\":45501},{\"end\":45790,\"start\":45786},{\"end\":45797,\"start\":45794},{\"end\":45806,\"start\":45803},{\"end\":45815,\"start\":45812},{\"end\":46095,\"start\":46086},{\"end\":46311,\"start\":46304},{\"end\":46320,\"start\":46315},{\"end\":46332,\"start\":46324},{\"end\":46633,\"start\":46628},{\"end\":46642,\"start\":46637},{\"end\":46649,\"start\":46646},{\"end\":46661,\"start\":46653},{\"end\":46913,\"start\":46910},{\"end\":47180,\"start\":47175},{\"end\":47190,\"start\":47184},{\"end\":47534,\"start\":47531},{\"end\":47542,\"start\":47538},{\"end\":47550,\"start\":47546},{\"end\":47558,\"start\":47554},{\"end\":47566,\"start\":47562},{\"end\":47860,\"start\":47855},{\"end\":47873,\"start\":47864},{\"end\":47886,\"start\":47879},{\"end\":47901,\"start\":47890},{\"end\":48138,\"start\":48133},{\"end\":48147,\"start\":48142},{\"end\":48157,\"start\":48151},{\"end\":48167,\"start\":48161},{\"end\":48411,\"start\":48406},{\"end\":48426,\"start\":48415},{\"end\":48440,\"start\":48430},{\"end\":48452,\"start\":48444},{\"end\":48463,\"start\":48456},{\"end\":48856,\"start\":48853},{\"end\":48863,\"start\":48860},{\"end\":48871,\"start\":48867},{\"end\":49127,\"start\":49124},{\"end\":49138,\"start\":49131},{\"end\":49146,\"start\":49142},{\"end\":49156,\"start\":49150},{\"end\":49425,\"start\":49422},{\"end\":49434,\"start\":49432},{\"end\":49442,\"start\":49438},{\"end\":49450,\"start\":49446},{\"end\":49741,\"start\":49734},{\"end\":49756,\"start\":49745},{\"end\":49765,\"start\":49760},{\"end\":49778,\"start\":49769},{\"end\":49790,\"start\":49782},{\"end\":49806,\"start\":49798},{\"end\":50113,\"start\":50108},{\"end\":50124,\"start\":50117},{\"end\":50133,\"start\":50128},{\"end\":50366,\"start\":50360},{\"end\":50376,\"start\":50370},{\"end\":50667,\"start\":50662},{\"end\":50684,\"start\":50671},{\"end\":50993,\"start\":50990},{\"end\":51005,\"start\":50997},{\"end\":51017,\"start\":51009},{\"end\":51032,\"start\":51021},{\"end\":51293,\"start\":51286},{\"end\":51304,\"start\":51297},{\"end\":51311,\"start\":51308},{\"end\":51321,\"start\":51317},{\"end\":51630,\"start\":51625},{\"end\":51641,\"start\":51636}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":1305354},\"end\":43958,\"start\":43717},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":17707171},\"end\":44333,\"start\":43960},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":15857498},\"end\":44697,\"start\":44335},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":51801537},\"end\":44908,\"start\":44699},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":8264664},\"end\":45181,\"start\":44910},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":207202654},\"end\":45422,\"start\":45183},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":6505111},\"end\":45724,\"start\":45424},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":10580690},\"end\":46037,\"start\":45726},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":17754191},\"end\":46242,\"start\":46039},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":7854090},\"end\":46589,\"start\":46244},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":137341},\"end\":46865,\"start\":46591},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":14783851},\"end\":47122,\"start\":46867},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":203705211},\"end\":47458,\"start\":47124},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":206804955},\"end\":47800,\"start\":47460},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":585068},\"end\":48090,\"start\":47802},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":491418},\"end\":48337,\"start\":48092},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":56894332},\"end\":48764,\"start\":48339},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":698664},\"end\":49068,\"start\":48766},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":207226489},\"end\":49335,\"start\":49070},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":13913625},\"end\":49664,\"start\":49337},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":10355485},\"end\":50047,\"start\":49666},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":1135252},\"end\":50312,\"start\":50049},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":10701255},\"end\":50546,\"start\":50314},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":14911023},\"end\":50952,\"start\":50548},{\"attributes\":{\"id\":\"b24\"},\"end\":51236,\"start\":50954},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":14824916},\"end\":51552,\"start\":51238},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":2715202},\"end\":51895,\"start\":51554},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":1305354},\"end\":43958,\"start\":43717},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":17707171},\"end\":44333,\"start\":43960},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":15857498},\"end\":44697,\"start\":44335},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":51801537},\"end\":44908,\"start\":44699},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":8264664},\"end\":45181,\"start\":44910},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":207202654},\"end\":45422,\"start\":45183},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":6505111},\"end\":45724,\"start\":45424},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":10580690},\"end\":46037,\"start\":45726},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":17754191},\"end\":46242,\"start\":46039},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":7854090},\"end\":46589,\"start\":46244},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":137341},\"end\":46865,\"start\":46591},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":14783851},\"end\":47122,\"start\":46867},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":203705211},\"end\":47458,\"start\":47124},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":206804955},\"end\":47800,\"start\":47460},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":585068},\"end\":48090,\"start\":47802},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":491418},\"end\":48337,\"start\":48092},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":56894332},\"end\":48764,\"start\":48339},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":698664},\"end\":49068,\"start\":48766},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":207226489},\"end\":49335,\"start\":49070},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":13913625},\"end\":49664,\"start\":49337},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":10355485},\"end\":50047,\"start\":49666},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":1135252},\"end\":50312,\"start\":50049},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":10701255},\"end\":50546,\"start\":50314},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":14911023},\"end\":50952,\"start\":50548},{\"attributes\":{\"id\":\"b24\"},\"end\":51236,\"start\":50954},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":14824916},\"end\":51552,\"start\":51238},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":2715202},\"end\":51895,\"start\":51554}]", "bib_title": "[{\"end\":43745,\"start\":43717},{\"end\":44029,\"start\":43960},{\"end\":44400,\"start\":44335},{\"end\":44725,\"start\":44699},{\"end\":44961,\"start\":44910},{\"end\":45227,\"start\":45183},{\"end\":45483,\"start\":45424},{\"end\":45780,\"start\":45726},{\"end\":46082,\"start\":46039},{\"end\":46300,\"start\":46244},{\"end\":46622,\"start\":46591},{\"end\":46906,\"start\":46867},{\"end\":47171,\"start\":47124},{\"end\":47527,\"start\":47460},{\"end\":47851,\"start\":47802},{\"end\":48129,\"start\":48092},{\"end\":48402,\"start\":48339},{\"end\":48849,\"start\":48766},{\"end\":49120,\"start\":49070},{\"end\":49418,\"start\":49337},{\"end\":49730,\"start\":49666},{\"end\":50102,\"start\":50049},{\"end\":50354,\"start\":50314},{\"end\":50658,\"start\":50548},{\"end\":50986,\"start\":50954},{\"end\":51282,\"start\":51238},{\"end\":51619,\"start\":51554},{\"end\":43745,\"start\":43717},{\"end\":44029,\"start\":43960},{\"end\":44400,\"start\":44335},{\"end\":44725,\"start\":44699},{\"end\":44961,\"start\":44910},{\"end\":45227,\"start\":45183},{\"end\":45483,\"start\":45424},{\"end\":45780,\"start\":45726},{\"end\":46082,\"start\":46039},{\"end\":46300,\"start\":46244},{\"end\":46622,\"start\":46591},{\"end\":46906,\"start\":46867},{\"end\":47171,\"start\":47124},{\"end\":47527,\"start\":47460},{\"end\":47851,\"start\":47802},{\"end\":48129,\"start\":48092},{\"end\":48402,\"start\":48339},{\"end\":48849,\"start\":48766},{\"end\":49120,\"start\":49070},{\"end\":49418,\"start\":49337},{\"end\":49730,\"start\":49666},{\"end\":50102,\"start\":50049},{\"end\":50354,\"start\":50314},{\"end\":50658,\"start\":50548},{\"end\":50986,\"start\":50954},{\"end\":51282,\"start\":51238},{\"end\":51619,\"start\":51554}]", "bib_author": "[{\"end\":43754,\"start\":43747},{\"end\":43766,\"start\":43754},{\"end\":43774,\"start\":43766},{\"end\":43781,\"start\":43774},{\"end\":43793,\"start\":43781},{\"end\":44044,\"start\":44031},{\"end\":44054,\"start\":44044},{\"end\":44062,\"start\":44054},{\"end\":44409,\"start\":44402},{\"end\":44417,\"start\":44409},{\"end\":44424,\"start\":44417},{\"end\":44431,\"start\":44424},{\"end\":44733,\"start\":44727},{\"end\":44748,\"start\":44733},{\"end\":44970,\"start\":44963},{\"end\":44982,\"start\":44970},{\"end\":44989,\"start\":44982},{\"end\":45001,\"start\":44989},{\"end\":45236,\"start\":45229},{\"end\":45244,\"start\":45236},{\"end\":45251,\"start\":45244},{\"end\":45258,\"start\":45251},{\"end\":45499,\"start\":45485},{\"end\":45506,\"start\":45499},{\"end\":45792,\"start\":45782},{\"end\":45799,\"start\":45792},{\"end\":45808,\"start\":45799},{\"end\":45817,\"start\":45808},{\"end\":46097,\"start\":46084},{\"end\":46101,\"start\":46097},{\"end\":46313,\"start\":46302},{\"end\":46322,\"start\":46313},{\"end\":46334,\"start\":46322},{\"end\":46635,\"start\":46624},{\"end\":46644,\"start\":46635},{\"end\":46651,\"start\":46644},{\"end\":46663,\"start\":46651},{\"end\":46915,\"start\":46908},{\"end\":47182,\"start\":47173},{\"end\":47192,\"start\":47182},{\"end\":47536,\"start\":47529},{\"end\":47544,\"start\":47536},{\"end\":47552,\"start\":47544},{\"end\":47560,\"start\":47552},{\"end\":47568,\"start\":47560},{\"end\":47862,\"start\":47853},{\"end\":47875,\"start\":47862},{\"end\":47888,\"start\":47875},{\"end\":47903,\"start\":47888},{\"end\":48140,\"start\":48131},{\"end\":48149,\"start\":48140},{\"end\":48159,\"start\":48149},{\"end\":48169,\"start\":48159},{\"end\":48413,\"start\":48404},{\"end\":48428,\"start\":48413},{\"end\":48442,\"start\":48428},{\"end\":48454,\"start\":48442},{\"end\":48465,\"start\":48454},{\"end\":48858,\"start\":48851},{\"end\":48865,\"start\":48858},{\"end\":48873,\"start\":48865},{\"end\":49129,\"start\":49122},{\"end\":49140,\"start\":49129},{\"end\":49148,\"start\":49140},{\"end\":49158,\"start\":49148},{\"end\":49427,\"start\":49420},{\"end\":49436,\"start\":49427},{\"end\":49444,\"start\":49436},{\"end\":49452,\"start\":49444},{\"end\":49743,\"start\":49732},{\"end\":49758,\"start\":49743},{\"end\":49767,\"start\":49758},{\"end\":49780,\"start\":49767},{\"end\":49792,\"start\":49780},{\"end\":49796,\"start\":49792},{\"end\":49808,\"start\":49796},{\"end\":50115,\"start\":50104},{\"end\":50126,\"start\":50115},{\"end\":50135,\"start\":50126},{\"end\":50368,\"start\":50356},{\"end\":50378,\"start\":50368},{\"end\":50669,\"start\":50660},{\"end\":50686,\"start\":50669},{\"end\":50995,\"start\":50988},{\"end\":51007,\"start\":50995},{\"end\":51019,\"start\":51007},{\"end\":51034,\"start\":51019},{\"end\":51295,\"start\":51284},{\"end\":51306,\"start\":51295},{\"end\":51313,\"start\":51306},{\"end\":51323,\"start\":51313},{\"end\":51632,\"start\":51621},{\"end\":51643,\"start\":51632},{\"end\":43754,\"start\":43747},{\"end\":43766,\"start\":43754},{\"end\":43774,\"start\":43766},{\"end\":43781,\"start\":43774},{\"end\":43793,\"start\":43781},{\"end\":44044,\"start\":44031},{\"end\":44054,\"start\":44044},{\"end\":44062,\"start\":44054},{\"end\":44409,\"start\":44402},{\"end\":44417,\"start\":44409},{\"end\":44424,\"start\":44417},{\"end\":44431,\"start\":44424},{\"end\":44733,\"start\":44727},{\"end\":44748,\"start\":44733},{\"end\":44970,\"start\":44963},{\"end\":44982,\"start\":44970},{\"end\":44989,\"start\":44982},{\"end\":45001,\"start\":44989},{\"end\":45236,\"start\":45229},{\"end\":45244,\"start\":45236},{\"end\":45251,\"start\":45244},{\"end\":45258,\"start\":45251},{\"end\":45499,\"start\":45485},{\"end\":45506,\"start\":45499},{\"end\":45792,\"start\":45782},{\"end\":45799,\"start\":45792},{\"end\":45808,\"start\":45799},{\"end\":45817,\"start\":45808},{\"end\":46097,\"start\":46084},{\"end\":46101,\"start\":46097},{\"end\":46313,\"start\":46302},{\"end\":46322,\"start\":46313},{\"end\":46334,\"start\":46322},{\"end\":46635,\"start\":46624},{\"end\":46644,\"start\":46635},{\"end\":46651,\"start\":46644},{\"end\":46663,\"start\":46651},{\"end\":46915,\"start\":46908},{\"end\":47182,\"start\":47173},{\"end\":47192,\"start\":47182},{\"end\":47536,\"start\":47529},{\"end\":47544,\"start\":47536},{\"end\":47552,\"start\":47544},{\"end\":47560,\"start\":47552},{\"end\":47568,\"start\":47560},{\"end\":47862,\"start\":47853},{\"end\":47875,\"start\":47862},{\"end\":47888,\"start\":47875},{\"end\":47903,\"start\":47888},{\"end\":48140,\"start\":48131},{\"end\":48149,\"start\":48140},{\"end\":48159,\"start\":48149},{\"end\":48169,\"start\":48159},{\"end\":48413,\"start\":48404},{\"end\":48428,\"start\":48413},{\"end\":48442,\"start\":48428},{\"end\":48454,\"start\":48442},{\"end\":48465,\"start\":48454},{\"end\":48858,\"start\":48851},{\"end\":48865,\"start\":48858},{\"end\":48873,\"start\":48865},{\"end\":49129,\"start\":49122},{\"end\":49140,\"start\":49129},{\"end\":49148,\"start\":49140},{\"end\":49158,\"start\":49148},{\"end\":49427,\"start\":49420},{\"end\":49436,\"start\":49427},{\"end\":49444,\"start\":49436},{\"end\":49452,\"start\":49444},{\"end\":49743,\"start\":49732},{\"end\":49758,\"start\":49743},{\"end\":49767,\"start\":49758},{\"end\":49780,\"start\":49767},{\"end\":49792,\"start\":49780},{\"end\":49796,\"start\":49792},{\"end\":49808,\"start\":49796},{\"end\":50115,\"start\":50104},{\"end\":50126,\"start\":50115},{\"end\":50135,\"start\":50126},{\"end\":50368,\"start\":50356},{\"end\":50378,\"start\":50368},{\"end\":50669,\"start\":50660},{\"end\":50686,\"start\":50669},{\"end\":50995,\"start\":50988},{\"end\":51007,\"start\":50995},{\"end\":51019,\"start\":51007},{\"end\":51034,\"start\":51019},{\"end\":51295,\"start\":51284},{\"end\":51306,\"start\":51295},{\"end\":51313,\"start\":51306},{\"end\":51323,\"start\":51313},{\"end\":51632,\"start\":51621},{\"end\":51643,\"start\":51632}]", "bib_venue": "[{\"end\":43809,\"start\":43793},{\"end\":44108,\"start\":44062},{\"end\":44477,\"start\":44431},{\"end\":44776,\"start\":44748},{\"end\":45017,\"start\":45001},{\"end\":45274,\"start\":45258},{\"end\":45548,\"start\":45506},{\"end\":45850,\"start\":45817},{\"end\":46117,\"start\":46101},{\"end\":46380,\"start\":46334},{\"end\":46696,\"start\":46663},{\"end\":46961,\"start\":46915},{\"end\":47249,\"start\":47192},{\"end\":47601,\"start\":47568},{\"end\":47919,\"start\":47903},{\"end\":48189,\"start\":48169},{\"end\":48511,\"start\":48465},{\"end\":48889,\"start\":48873},{\"end\":49174,\"start\":49158},{\"end\":49468,\"start\":49452},{\"end\":49824,\"start\":49808},{\"end\":50151,\"start\":50135},{\"end\":50403,\"start\":50378},{\"end\":50719,\"start\":50686},{\"end\":51065,\"start\":51034},{\"end\":51361,\"start\":51323},{\"end\":51689,\"start\":51643},{\"end\":43809,\"start\":43793},{\"end\":44108,\"start\":44062},{\"end\":44477,\"start\":44431},{\"end\":44776,\"start\":44748},{\"end\":45017,\"start\":45001},{\"end\":45274,\"start\":45258},{\"end\":45548,\"start\":45506},{\"end\":45850,\"start\":45817},{\"end\":46117,\"start\":46101},{\"end\":46380,\"start\":46334},{\"end\":46696,\"start\":46663},{\"end\":46961,\"start\":46915},{\"end\":47249,\"start\":47192},{\"end\":47601,\"start\":47568},{\"end\":47919,\"start\":47903},{\"end\":48189,\"start\":48169},{\"end\":48511,\"start\":48465},{\"end\":48889,\"start\":48873},{\"end\":49174,\"start\":49158},{\"end\":49468,\"start\":49452},{\"end\":49824,\"start\":49808},{\"end\":50151,\"start\":50135},{\"end\":50403,\"start\":50378},{\"end\":50719,\"start\":50686},{\"end\":51065,\"start\":51034},{\"end\":51361,\"start\":51323},{\"end\":51689,\"start\":51643},{\"end\":44150,\"start\":44110},{\"end\":44519,\"start\":44479},{\"end\":44800,\"start\":44778},{\"end\":46422,\"start\":46382},{\"end\":46725,\"start\":46698},{\"end\":47003,\"start\":46963},{\"end\":47302,\"start\":47251},{\"end\":48553,\"start\":48513},{\"end\":50424,\"start\":50405},{\"end\":50748,\"start\":50721},{\"end\":51092,\"start\":51067},{\"end\":51395,\"start\":51363},{\"end\":51731,\"start\":51691},{\"end\":44150,\"start\":44110},{\"end\":44519,\"start\":44479},{\"end\":44800,\"start\":44778},{\"end\":46422,\"start\":46382},{\"end\":46725,\"start\":46698},{\"end\":47003,\"start\":46963},{\"end\":47302,\"start\":47251},{\"end\":48553,\"start\":48513},{\"end\":50424,\"start\":50405},{\"end\":50748,\"start\":50721},{\"end\":51092,\"start\":51067},{\"end\":51395,\"start\":51363},{\"end\":51731,\"start\":51691}]"}}}, "year": 2023, "month": 12, "day": 17}