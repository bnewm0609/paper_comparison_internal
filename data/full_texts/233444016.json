{"id": 233444016, "updated": "2023-12-14 07:53:39.935", "metadata": {"title": "WGCN: Graph Convolutional Networks with Weighted Structural Features", "authors": "[{\"first\":\"Yunxiang\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Jianzhong\",\"last\":\"Qi\",\"middle\":[]},{\"first\":\"Qingwei\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Rui\",\"last\":\"Zhang\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Graph structural information such as topologies or connectivities provides valuable guidance for graph convolutional networks (GCNs) to learn nodes' representations. Existing GCN models that capture nodes' structural information weight in- and out-neighbors equally or differentiate in- and out-neighbors globally without considering nodes' local topologies. We observe that in- and out-neighbors contribute differently for nodes with different local topologies. To explore the directional structural information for different nodes, we propose a GCN model with weighted structural features, named WGCN. WGCN first captures nodes' structural fingerprints via a direction and degree aware Random Walk with Restart algorithm, where the walk is guided by both edge direction and nodes' in- and out-degrees. Then, the interactions between nodes' structural fingerprints are used as the weighted node structural features. To further capture nodes' high-order dependencies and graph geometry, WGCN embeds graphs into a latent space to obtain nodes' latent neighbors and geometrical relationships. Based on nodes' geometrical relationships in the latent space, WGCN differentiates latent, in-, and out-neighbors with an attention-based geometrical aggregation. Experiments on transductive node classification tasks show that WGCN outperforms the baseline models consistently by up to 17.07% in terms of accuracy on five benchmark datasets.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigir/Zhao0L021", "doi": "10.1145/3404835.3462834"}}, "content": {"source": {"pdf_hash": "5ece0a0a8d8b0c55a96d2b2908037c79c58b411f", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2104.14060v3.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "http://minerva-access.unimelb.edu.au/bitstream/11343/281919/2/SIGIR%202021%20WGCN%20-%20Graph%20Convolutional%20Networks%20with%20Weighted%20Structural%20Features.pdf", "status": "GREEN"}}, "grobid": {"id": "3141092760110d6d1bad84412292927b0363d529", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/5ece0a0a8d8b0c55a96d2b2908037c79c58b411f.txt", "contents": "\nVirtual Event, Canada\nCanadaCopyright CanadaJuly 11-15, 2021. July 11-15, 2021\n\nYunxiang Zhao \nJianzhong Qi jianzhong.qi@unimelb.edu.au \nQingwei Liu qingweil@student.unimelb.edu.au \nRui Zhang \nACM Reference Format\n\n\nYunxiang Zhao \nJianzhong Qi \nQingwei Liu \nRui Zhang \nACM Reference Format\n\n\n... ... ... ... ...P \n\nThe University of Melbourne\n1 , www.ruizhang\n\nVirtual Event, Canada\n\n44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '21)\nNew York, NY, USA, 10CanadaJuly 11-15, 2021. July 11-15, 202110.1145/3404835.34628342021. WGCN: Graph Convolutional Networks with Weighted Structural Features. In Pro- *Corresponding author. ACM ISBN 978-1-4503-8037-9/21/07. . . $15.00 NP Figure 1: Citation networks for popular (P) and non-popular (NP) papers. Ellipses cover papers with the same class as the target paper. Different node colors denote different classes, such as DM, CV, and NLP (best view in color).CCS CONCEPTS \u2022 Computing methodologies \u2192 Neural networks; KEYWORDS Directional Graph Convolutional NetworksStructural InformationRandom Walk with Restart\nGraph structural information such as topologies or connectivities provides valuable guidance for graph convolutional networks (GCNs) to learn nodes' representations. Existing GCN models that capture nodes' structural information weight in-and out-neighbors equally or differentiate in-and out-neighbors globally without considering nodes' local topologies. We observe that in-and outneighbors contribute differently for nodes with different local topologies. To explore the directional structural information for different nodes, we propose a GCN model with weighted structural features, named WGCN. WGCN first captures nodes' structural fingerprints via a direction and degree aware Random Walk with Restart algorithm, where the walk is guided by both edge direction and nodes' in-and out-degrees. Then, the interactions between nodes' structural fingerprints are used as the weighted node structural features. To further capture nodes' high-order dependencies and graph geometry, WGCN embeds graphs into a latent space to obtain nodes' latent neighbors and geometrical relationships. Based on nodes' geometrical relationships in the latent space, WGCN differentiates latent, in-, and out-neighbors with an attention-based geometrical aggregation. Experiments on transductive node classification tasks show that WGCN outperforms the baseline models consistently by up to 17.07% in terms of accuracy on five benchmark datasets.\n\nINTRODUCTION\n\nGraphs are essential representations of many real-world data such as social networks, transportation networks, and e-commerce useritem graphs [19,33,37,45,50,54]. Graph convolutional networks (GCNs), graph attention networks (GATs), and their variants have shown promising results in applications on graph datasets [2, 4-6, 20, 21, 29, 36, 47, 49]. However, most GCN and GAT based models focus on how to aggregate neighboring nodes' content features (e.g., keywords of a document in a document network) and take graph structures (edges/topology) for checking neighboring relationships only. For example, GATs learn the similarities between two nodes' content features as the attention coefficients while overlooking the relationship between nodes' local topologies (e.g., similarities).\n\nRecent studies show that explicitly adding node structural information before the aggregation procedure of GCNs substantially improves models' performance [14,46]. However, existing approaches treat directed edges as bi-directional, i.e., neighbors connecting to a node have the same weight irrespective of the direction when capturing node structural information [31,48,53]. Such approaches ignore directional structures such as irreversible time-series relationships, which may mislead the node structural information learning [40,44]. A few studies [17,22,40,41] differentiate in-and out-neighbors when capturing node's structural information, but they give the same weight to the in-neighbors of all nodes and another the same weight to the out-neighbors of all nodes.\n\nWe believe that the weight difference between in-and out-neighbors when capturing nodes' structural information is highly related to nodes' local topologies. Without loss of generality, we illustrate our insight via node classification tasks for directed graphs, as shown in Figure 1. Consider the difference between popular and non-popular nodes. A node is popular if it has much more in-neighbors than out-neighbors, e.g., a paper with many citations but cites few other papers or a celebrity social network user with many followers but follows few other users. A non-popular node, on the other hand, has more out-neighbors than in-neighbors, e.g., a not-so-popular paper or an average social network user. In node classification, neighbors similar to the target node play an essential role, e.g., papers within the same class in citation networks and people with the same profession in social networks. In general, the more neighbors a node has in one direction (in or out), the higher proportion of dissimilar neighbors the node has in that direction. As shown in Figure 1, most citations of a not-so-popular paper (denoted as NP) are from the same class because, typically, only people studying in its area cite the paper. On the other hand, a popular paper (denoted as P) obtains many citations, which may come from other classes instead of the class to which the paper belongs. In summary, compared to the in-neighbors, the out-neighbors of a popular paper have a higher possibility of being similar neighbors. In this case, out-neighbors should carry higher weights when capturing node structural information. For non-popular papers, on the other hand, in-neighbors have a higher possibility of being similar neighbors, compared to the out-neighbors. In this case, in-neighbors should carry higher weights when capturing node structural information.\n\nTo confirm this intuition, we analyze five real datasets and compute the possibility of a node reaching a neighbor of the same class via inor out-edges. We find that up to 21% more nodes reach a neighbor of the same class via the direction with a smaller degree than the direction with a larger degree. This observation conforms to our intuition, which will be detailed in Section 3.1.\n\nA straightforward strategy to differentiate the directional structural information for different nodes is to learn a parameter that weights one-hop in-and out-neighbors for each node according to its in-and out-degrees [9]. However, such a strategy cannot capture the nodes' density or differentiate nodes' geometrical relationships, and hence will lose structural information such as communities [48]. Besides, unlike continuous space such as images or videos, GCNs cannot differentiate non-isomorphic graphs due to their permutation-invariant aggregation and cannot capture longrange dependencies [18,31]. Such information is critical in node representation learning. For example, capturing communities can help learn node structural information because nodes within the same community have closer relationships than those not within the same community [48]; capturing latent neighbors and hierarchical relationships [25,28] in the latent space can further improve the performance of node representation learning [7,24].\n\nTo address the above limitations, we propose a novel GCN variant named WGCN. It models nodes' directional structural information, where the weights of in-and out-neighbors are determined by nodes' local topologies. WGCN contains two components. (i) the first component is a direction and degree aware Random Walk with Restart algorithm (DDRWR), where the walk is guided by both edge direction and node in-and out-degrees. We take the proximity of reaching -hop neighbors from a given node as the structural fingerprint of the node. The procedure of computing the proximity quantitatively weights in-and out-neighbors for different nodes and captures communities simultaneously. Based on the structural fingerprint of each node, we define the node level interactions between node structural fingerprints to obtain an N -dimensional vector for each node as its structural features (N is the number of nodes in the graph). (ii) the second component embeds node topology into a latent space, and nodes far away from each other in the graph may become neighbors in the latent space. Moreover, the positions of different nodes in the latent space capture their latent geometrical relationships. Based on nodes' geometrical relationships in the latent space, in message passing, WGCN performs an attention-based geometrical aggregation with learnable parameters for latent, in-, and out-neighbors, respectively. We summarize our contributions as follows:\n\n\u2022 We propose a novel GCN model named WGCN to capture nodes' structural information, which differentiates the weights of node in-neighbors from those of node out-neighbors according to nodes' local topologies. \u2022 We propose to embed node topology into a latent space to obtain nodes' high-order dependencies and latent geometrical relationships. We then aggregate latent, in-, and out-neighbors separately with a geometrical attention-based message passing for node representation learning. \u2022 We evaluate the proposed WGCN model with transductive node classification tasks on five public benchmark datasets, and WGCN achieves state-of-the-art performance consistently. We have made the implementation of WGCN public available 1 .\n\n\nRELATED WORK\n\nGCNs apply a message-passing strategy where each node aggregates messages/features from its neighboring nodes and updates its feature vector until an equilibrium state is reached [11]. Instead of aggregating all neighboring nodes equally, Velickovic et al. [42] propose a graph attention model (GAT) with a trainable attention function, which learns implicit information to distinguish different neighbors during the aggregation. Based on GAT, various approaches have been proposed for aggregating neighbors' information based on neighbors' content features and structural information [16,43]. For example, Wang et al. [43] propose to differentiate the weights of different neighbors for heterogeneous graphs and then aggregate content features from meta-path-based neighbors hierarchically. Recently, researchers found that omitting the edge direction information will lead to information loss for node representation learning [41], and explicitly adding rich structural features such as the topology or \"shapes\" of local edge connections can further boost the performance of GCNs [48]. Therefore, various GCN models have been proposed for directed graphs, and some also explicitly capture directional structural features. They are divided into spectral and spatial approaches.\n\nTo capture the edge direction information in the spectral domain. Ma et al. [22] propose a directed Laplacian matrix for directed graphs. However, they only consider the nodes' out-neighbors (outdegree matrix) and overlook the information from in-neighbors, which may cause information loss. To cope with the high computation cost of spectral-GCNs for directed graphs, Li et al. [17] propose a scalable graph convolutional neural network with fast localized convolution operators derived from directed graph Laplacian. To capture both edge direction information and nodes' local structural information, Tong et al. [40,41] propose to learn first-and secondorder proximities, which are combined via a signal fusion function. However, they apply the same weight for in-neighbors of all nodes and another the same weight for out-neighbors of all nodes when computing the first-and second-order proximity.\n\nSpatial GCN models mainly focus on undirected graphs when learning nodes' representations and can be applied to directed graphs by following the edge directions during the message passing. For example, Hamilton et al. [6] propose a general inductive framework that can efficiently generate node embeddings for previously unseen data. Zhu et al. [52] propose a neighborhood-aware GCN model, which considers both neighbor-level and relation-level information. Mostafa et al. [23] propose a global attention mechanism where a node can selectively attend to and aggregate content features from any other node in the graph. To capture both edge direction information and nodes' local structural information, Zhang et al. [48] propose to use Random Walk with Restart to obtain node structural information according to node's local topology, and then train a GAT model that considers both the node content features and node structural features. Spatial GCN models can be applied to directed graphs by aggregating in-or out-neighbors only during the message passing. However, considering in-or out-neighbors only may lead to information loss because neighbors in the other direction are overlooked [41].\n\n\nMETHODS\n\nWe start by analyzing real data to show that in-and out-neighbors have different probabilities of being similar neighbors for nodes with different local topologies (Section 3.1). We then present an overview of our WGCN model that captures such data characteristics in embedding learning (Section 3.2). After that, we discuss how to adapt a classic algorithm -the Random Walk -to capture a neighbor's weight in representing a node's directional local structure information (Section 3.3), detail how to compute a node's structural features based on such an algorithm (Section 3.4), present an attention-based geometrical message passing to support our embedding leaning (Section 3.5), and show the time complexity of our model (Section 3.6).\n\n\nMotivation and Insight\n\nOur model is based on the insight that neighbors at the direction with a smaller degree have a higher possibility of being similar neighbors (e.g., being in the same class). We analyze five datasets (details in Section 4.1) and report the percentage of nodes that conform to our insight. In Figure 2a, the nodes in each dataset are divided into three categories: (i) nodes with in-or out-degree being zero (gray bars), i.e., nodes with only in-or out-neighbors. (ii) nodes with the same in-and out-degrees (yellow bars). (iii) nodes with different and non-zero in-and out-degrees (blue bars). Our model benefits the representation learning of the nodes of Category (iii), while it does not has a negative impact on nodes of the other categories. We see that the five datasets have between 52.7% and 61.5% of nodes of Category (iii). Improving the representations learned for such nodes is expected to bring substantial performance gains for downstream applications (e.g., node classifications, detailed in Section 4.2). Within the nodes in Category (iii), we further show the percentage of nodes that conform to our insight in Figure 2b. The y-axis denotes the percentage of nodes where neighbors at the direction with a smaller degree have a higher possibility of sharing the same class with these nodes. We observe that over 50% of the nodes in Category (iii) of each dataset tested conform to our insight, confirming the necessity of weighing the in-and out-neighbors differently for the nodes. For the rest nodes in Category (iii), our model has a negative impact on their representation learning, but the overall performance of all nodes is increased since they are the minority. The theoretical analysis in Section 3.3 and the experimental results in Section 4.2 conform to this claim. Next, we present our WGCN model to learn such different weights.\n\n\nModel Overview\n\nThe overall structure of WGCN is shown in Figure 3, which contains two components. Given a directed graph and node content features (e.g., keywords of a document in a document network, denoted as the vector next to each node), (i) we obtain nodes' structural fingerprints via a direction and degree aware Random Walk with Restart algorithm (DDRWR), where the walk is guided by edge direction and node in-and out-degrees. The interactions between nodes' structural fingerprints are taken as the nodes' structural features. We then concatenate structural features with node content features as the input to be passed to the message passing phase. (ii) meanwhile, we embed nodes into a latent space via existing embedding approaches that capture nodes' latent neighbors and the graph topology, i.e., the nodes' geometrical relationships. For each node, we differentiate its neighbors into different classes (folds) according to neighbors' geometrical relationships in the latent space. During the message passing, we first aggregate (e.g., sum or mean) latent, in-and out-neighbors separately in each sub-space to obtain virtual nodes denoted as v \u25cb in Figure 3, and an attention mechanism is applied to enable nodes to discriminately attend to neighbors with different weights. We then update node representation by aggregating (e.g., concatenate) those virtual nodes to obtain the final representation of each node. The \"concatenate\" aggregation can retain the order of different virtual nodes and hence can differentiate neighbors with different geometrical relationships.\n\n\nNeighbor Weight Modeling\n\nIn GCN models, Random Walk has been widely used to capture structural information in node representation learning [3,13,48], We take 1-hop in-neighbors (blue) and out-neighbors (yellow) of node 1 \u25cb in a four-fold attention-based geometrical message passing as an example. Nodes with high-order dependencies to node 1 \u25cb in the latent space are red colored such as node 7 \u25cb (best view in color).\n\nwhere the possibility of reaching each neighbor during the exploring process denotes the weight of the neighbor in representing a node's structural information. In this subsection, we first show that traditional Random Walk algorithms do not serve our purpose on directed graphs. We then present our adapted Markov process and show its advantages. Random Walk algorithms can be seen as time-homogeneous Markov processes. Let\n{ [ ] ,\n\u2265 0} be a time-homogeneous Markov process with state/node space and transition matrix = ( ) , \u2208 . For any nodes , \u2208 :\n:= P( [ +1] = | [ ] = ), \u2200 \u2265 0 (1)\nwhere [ +1] denotes the next state generated from the current state [ ] . Random Walk with Restart (RWR) further captures the intuitively decaying weight of neighbors of different hops, while maintaining the community information [48]. The RWR procedure forces the walk on a graph to always restart from the same node (or group of nodes). It can quantify the structural proximity between a given node and all other nodes in the graph [39,51], which has been widely used for graph embedding [3,12,13,30,32]. Without loss of generality, we take graphs without self-loop and mutual connections as an example for illustration. For each node \u2208 , we denote \u2286 as the \"neighbors\" of node , and as the in-neighbors and out-neighbors of node , respectively, and = \u222a . Let be the degree of node (here and below degree means in-degree plus out-degree), i.e., := + , where := | | and := | | are the in-degree and out-degree of node , respectively. In the traditional RWR, the possibility of any node \u2208 reaching next node during the exploring procedure is:\n:= \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f3 , if = 1\u2212 , if \u2208 0, else(2)\nwhere node is the starting node, i.e., P( [0] = ) = 1, and \u2208 (0, 1) is a fixed constant, which indicates the possibility of restart.\n\nExisting studies on RWR do not consider the asymmetric roles of vertices and are not robust for directed graphs [9]. Based on our insight in Section 3.1, for a node , if there is a difference between its in-degree and out-degree, its neighbors in the direction with the smaller degree are more likely to be similar to node . More precisely, given node , if | \u2212 | exceeds a threshold \u210e \u2208 N, for any node \u2208 , and node \u2208 , we have:\nP( \u2208 I ) > P( \u2208 I ), if \u2212 > \u210e P( \u2208 I ) < P( \u2208 I ), if \u2212 > \u210e(3)\nwhere I denotes all neighbors similar to node , which is a random subset of . In practice, we set the threshold \u210e as 0.\n\nBased on this insight, we propose a Markov process {\u02dc[ ] : \u2265 0} with transition matrix\u02dc= (\u02dc) , \u2208 , where\u02dcfor each node \u2208 is computed as follows:\n= \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 , if = , if \u2208 , if \u2208 0, else , \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f3 > , if \u2212 > \u210e < , if \u2212 > \u210e = , else(4)\nHere, + + = 1. For each node , the possibility of the Markov process reaching the set of similar neighbors I is \u22651P (\u02dc[ ] \u2208 I ). Throughout this paper, we only consider such a set of neighbors w.r.t. the starting node . Thus, for simplification, we use I instead of I . Assume that the distribution of I is independent of the distribution of {\u02dc[ ] : \u2265 0}. Then the possibility of reaching set I in the typical RWR and the proposed Markov process in the 1-hop neighbors are:   \nP( [ +1] \u2208 I) = \u2211\ufe01 \u2208 \u2211\ufe01 \u2208 P( \u2208 I) 1 \u2212 P( [ ] = ) + O (a) A simple graph.P(\u02dc[ +1] \u2208I) = \u2211\ufe01 \u2208 1 \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 \u2211\ufe01 \u2208 P( \u2208 I) + \u2211\ufe01 \u2208 P( \u2208 I) \uf8fc \uf8f4 \uf8f4 \uf8fd \uf8f4 \uf8f4 \uf8feP (\u02dc[ ] = ) + \u2211\ufe01 \u2208 2 \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 \u2211\ufe01 \u2208 P( \u2208 I) + \u2211\ufe01 \u2208 P( \u2208 I) \uf8fc \uf8f4 \uf8f4 \uf8fd \uf8f4 \uf8f4 \uf8feP (\u02dc[ ] = ) + \u2211\ufe01 \u2208 3 \u2211\ufe01 \u2208 P( \u2208 I) 1 \u2212P (\u02dc[ ] = ) +\nwhere \u2265 0, 1 , 2 , and 3 are defined as: 1 \n:= { \u2208 : \u2212 > \u210e }, 2 := { \u2208 : \u2212 > \u210e }, 3 := { \u2208 : | \u2212 | \u2264 \u210e }. When = 0, it is clear that P( [1] \u2208 I) \u2264P(\u02dc[ 1] \u2208 I).\nMore precisely, given the initial distribution P( [0] = ) =P(\u02dc[ 0] = ) = 1, node must fall in one of , since { 1 , 2 , 3 } is a partition of . If \u2208 1 , we have < 1\u2212 < and P( \u2208 I) < P ( \u2208 I) for any \u2208 , \u2208 from Equations 3 and 4. Therefore:\n\u2211\ufe01 \u2208 P( \u2208 I) + \u2211\ufe01 \u2208 P( \u2208 I) > \u2211\ufe01 \u2208 P( \u2208 I) 1 \u2212 (5)\nSimilarly, the inequality (5) holds for \u2208 2 . Because our model has the same possibility of reaching I as typical RWR for \u2208 3 , then:\nP( [1] \u2208 I) \u2264P(\u02dc[ 1] \u2208 I)(6)\nCompared with the neighbors of a dissimilar neighbor, those of a similar neighbor have a higher possibility to be similar high-order neighbors. Therefore, with the increased possibility of reaching I for node , the possibility of reaching I in high-order neighbors will also become higher in our model. Figure 4 shows an example of using typical RWR and our Markov process to capture the node structural information. In Figure 4a, circles denote nodes, and directed edges between nodes are the topology. Node has 4 in-neighbors and 20 out-neighbors in the graph. According to our insight, the in-neighbors should have a higher possibility to be similar neighbors. In this graph, three out of four (i.e., a probability of 75%) in-neighbors are in the same class as node . On the other hand, the out-neighbors of node have a smaller possibility to contain similar neighbors of node . In Figure 4a, there are four out of 20 (i.e., only a probability of 20%) out-neighbors in the same class as node .\n\nIf we run the typical RWR algorithm with a restart rate of 0.2 to capture the node structural information of node , the weight distribution will be like Figure 4b Figure 5: Neighbor weighting and node-level structural interactions in WGCN. The in-neighbors of node have higher weights due to the smaller in-degree compared to the outdegree. Node has a higher interaction weight with node because their interacted nodes have higher weights.\n\nnode have the same weight. On the other hand, if we take that \"inneighbors have a higher possibility to contain similar neighbors\" as pre-knowledge, and assign the in-neighbors with a higher weight, then the weight distribution will be like Figure 4c, where the inneighbors have a higher weight. Note that the similar neighbors of node in the out-direction have lower weights, and the dissimilar inneighbors of node have higher weights in our method. However, the overall possibility of reaching similar nodes has been increased.\n\n\nDirectional Node Structural Features\n\nIn GCN models, node structural features can be represented as the similarities between the local topologies of pairwise nodes. To embed the directional information into node structural features, we first present our DDRWR module for learning nodes' local topologies (fingerprints), which is based on the proposed Markov process in Section 3.3. We then present the method for computing the node structural features.\n\nWhen computing the structural fingerprint for each node, it is desirable to assign weights to neighbors adaptively based on nodes' local structures (e.g., communities). Figure 5a shows a spanning process on node 's -hop ( =2 in this example) local subgraph , and each neighbor in contributes a weight, which denotes the importance of the neighbor when capturing the structural fingerprint of node . Based on discussions above, in-neighbors are more likely to be similar neighbors because the in-degree of node is smaller than its out-degree , and hence they should have higher weights when capturing the node structural fingerprint. Besides, even though neighbors far away from node should have smaller weights, mapping the node distance levels [1, 2, ..., k] to non-negative, monotonically decreasing weight levels = [ 1 , 2 , ..., ] will overlook the importance of communities in evaluating node similarities.\n\nTo achieve the above objectives, we combine RWR with our proposed Markov process in Section 3.3, which yields an algorithm named DDRWR. DDRWR adjusts the walk according to the edge direction and the in/out-degrees of different nodes. Without abuse of notations, we define the transition matrix\u02dc= (\u02dc) , \u2208 as:\n= 1 + \u00b7 ( \u2212 + )(7)\nwhere controls the maximum weight difference between in-and out-neighbors, indicates the relationship between nodes and node in the graph. equals \u22121 if node reaches node via the in-edges of node following the BFS, equals 1 if node reaches node via the out-edges of node following the breadth first search (BFS), and is 0 if node is out of reach from node . Recall that and are the in-and out-degrees of node , respectively. is zero or a positive odd number that controls the in-and out-neighbor weight variation trend regarding the in-and out-degrees ratio. For example, = 0 denotes that in-and out-neighbors have the same weight, = 1 denotes that the weight of in-and out-neighbors has a linear relationship to the in-and out-degrees' difference, and = 3 denotes a cubic relationship. Accordingly, we formulate the iterations of DDRWR taking node as the origin as:\nw [ +1] = (1 \u2212 ) \u00b7\u02dc\u2032w [ ] + \u00b7 e(8)\nwhere \u2208 [0, 1] determines the ratio of the restart, e is a vector with all components equal to 0, except the entry corresponding to node , which is 1, and\u02dc\u2032 is the normalized version of the transition matrix\u02dcrestricted on . In general, if and are close to each other,\u02dcapproaches to the in typical RWR, which means that in-and out-neighbors obtain similar weights and closer neighbors obtain a higher weight. If is larger than , then is negative when node reaches node via its in-edges. Therefore, the weight\u02dcis larger for nodes reached via out-edges and smaller for nodes reached via in-edges. On the contrary, if is smaller than , weight\u02dcis smaller for nodes reached via out-edges and larger for nodes reached via inedges. For mutually connected neighbors of node , we set their probabilities as the sum of being both in-and out-neighbor. The converged solution of Equation 8 is:\nw = ( \u2212 (1 \u2212 ) \u00b7\u02dc\u2032) \u22121 e(9)\nwhere w quantifies the proximity of node reaching its -hop neighbors , and we take w as the structural fingerprint of node , controls the decay rate of the fingerprint. w is zeros except for position if is 1, and w has the same distribution as that produced by a Random Walk without restart if is 0.\n\nAfter computing the structural fingerprint w of each node , we only keep those values of neighbors within (neighbors within -hops) and normalize w to compute the node level structural interactions. We use weighted Jaccard similarity to evaluate the structural interactions = ( ) , \u2208 as follows:\n= \u2208 ( \u222a ) ( , ) \u2208 ( \u222a ) ( , )(10)\nwhere and are the th values of the normalized w and w , respectively. Each in is a value denoting the structural interaction between node and . Figure 5b illustrates Equation 10. For node , out-neighbors have a higher weight because the outdegree is smaller than the in-degree. Nodes and each has two intersected neighbors with node , but node has a higher structural interaction with node because of the higher weights of their intersected neighbors.\n\n\nGeometrical Message Passing\n\nTo explore node latent geometrical relationships, we embed each node in the graph by : \u2192 z , where z denotes the position of node in the latent space, function is an embedding function that preserves node latent geometrical relationships. We apply Isomap embedding later in the experiments, which can be replaced by other approaches that preserve node latent geometrical relationships. In the latent space, complex topology patterns can be preserved and presented as intuitive geometry, such as subgraph, community, and hierarchy [25][26][27]31]. We apply a distance threshold to determine the latent neighbors of each node, as the dashed circle shown in Figure 3. The way to obtain the threshold is the same as that in Geom-GCN [31]. To capture nodes' geometric relationships, for node 's neighbors in the latent space ( \u2286 because may contain latent neighbors), WGCN computes their relative positions:\n(z , z ) \u2192 \u2208 , \u2208(11)\nwhere is a function defined in the latent space, and is a set of relationships. For example, in 2D embedding space, a four-fold relationship set includes 13 relationships as shown in Figure 6: upper-left, upper-right, lower-left, lower-right for latent, in-and out-neighbors, respectively, and one last relationship is self-loop. Given the positions of two nodes in 2D embedding space, the function in Equation 11 will return one of the 13 relationships. After obtaining the geometrical relationships for all neighbors of a given node , WGCN either performs attention-based or pure sub-aggregation. For attention-based sub-aggregation, WGCN first concatenates node structural features to content features as the new features of each node via h = (x ||s ) \u2208 R , wherex ands are two vectors denoting the row-normalized (described in GCN) content features x and structural features s of node , || denotes the concatenate operator. For neighbors with each type of relationship , WGCN learns a projection matrix \u2208 R \u00d7 parameterizing a particular attention function A \u2208 A to enable the sub-aggregation to discriminate the neighbors with relationship to node . The unnormalized attention coefficient between node and its neighbors in one of the sub-aggregation spaces is:\n= A( h , h ), \u2208 ,(12)\nwhere denotes the importance of node to node , , denotes the set of neighbors with relationship to node only, i.e.,\n, := { \u2208 : \u2192 }.\nWe then apply a Softmax function to , and the attention coefficient between each pair of nodes and its neighbor is:\n= ( ( )) \u2208 , ( ( ))(13)\nwhere denotes the coefficient between node and node . With the attention coefficients , we summarize the sub-aggregation of node under relationship in WGCN as:\nv , = || A\u2208A \u2211\ufe01 \u2208 , h(14)\nwhere h denotes the features of node . The sum operator can be replaced by other permutation-invariant operators such as the mean operator. The attention function A (with and ) is learned for each relationship . || A\u2208A concatenates the output from all attention heads A to obtain the features of virtual node v , . The corresponding equation to obtain features of virtual node v , in pure sub-aggregation can be easily inferred from Equation 14. Based on the virtual nodes from neighbors with different relationships, WGCN aggregates the features of all virtual nodes as follows:\nh \u2032 = (\u02c6([v , 1 , ...v , ]))(15)\nwhere\u02c6denotes a learnable weight matrix for the overall aggregation, denotes a non-linear activation function, function is a permutation-variant function (e.g., concatenate) that summarizes the features from all virtual nodes, so as to explore the neighbors' geometry relationships. Equations 14 and 15 work together as one message passing layer in WGCN, and multi-layer message passing can be implemented by aggregating Equations 14 and 15 iteratively.\n\n\nComplexity Analysis\n\nWe analyze the complexity of WGCN as follows. To compute the structural fingerprint of each node, we reach -hop neighbors via BFS, where is two for assortative datasets and one for disassortative datasets in our experiments. The complexity is (N \u00b7 K), where N denotes the number of nodes in the graph, and K denotes the average number of -hop neighbors. For each node, we compute the interactions with its 2 -hop neighbors via Jaccard similarity, and the complexity is (K). Therefore, the overall complexity for learning node structural features is still (N \u00b7 K). The computation of node structural features is a one-off pre-processing step before the training process. During the message passing, WGCN combines node structural features with node content features and then performs an attention-based geometrical aggregation. Take WGCN without attention mechanism as an example (adding attention mechanism does not change the time complexity [42]), the time complexity is ((N +F ) \u00b7 E), where F denotes the dimensionality of the original node content features, and E denotes the number of edges in the graph. An important future work is to develop accelerating technology for improving the scalability of WGCN.\n\n\nEXPERIMENTS\n\nWe compare WGCN with state-of-the-art models on graph datasets for transductive node classification tasks.\n\n\nDatasets and Experimental Setup\n\nDatasets: We use both assortative and disassortative graph datasets. Assortative graphs [18] refer to those with high node homophily, and we use two directed citation graphs, Cora-ML [1] and Citeseer [1]. The graph nodes represent articles, while the edges represent citations between articles. Both datasets also include bag-ofwords feature vectors for each article. Disassortative graphs [18] contain more nodes that share the same class labels but are distant from each other. We use three directed Wikipedia page link graphs Chameleon, Squirrel, and Crocodile. These are page-to-page link networks on three different topics. In these datasets, the nodes represent web pages, and the edges are directed links from one page  [35]. Table 1 summarizes these datasets. Experimental setup: We implement a two-layer WGCN. For each layer, we first apply a four-fold geometrical aggregation to obtain virtual nodes that capture the latent geometry relationships. To capture node latent geometrical relationships, we apply the Isomap embedding [38], where the distance patterns (lengths of shortest paths) and geometrical information are preserved in the latent space. We then concatenate the output of different virtual nodes as the output. During the structural fingerprint generation, we set the hops of neighbors to consider as two during the DDRWR exploring for assortative graphs and one for disassortative graphs, and as three. Parameter and are dataset and embedding algorithm related. We use the grid search to find optimal values for them in the range of [0,1] with a step length of 0.1. In general, setting \u2208 [0.2, 0.4] and \u2208 [0.4, 0.6] yields a satisfactory performance. We set the parameter as 0.3 and as 0.5 for all datasets. We use Adam optimizer [10], and ReLU as the activation function for the overall aggregation. We run our model for 500 epochs, use a dropout ratio of 0.5, a learning rate of 0.05, and a weight decay of 5e-6. We set the number of attention head as one, and the number of hidden units as 48 for both layers.\n\nBaselines: We compare our model with nine state-of-the-art models divided into three groups: 1) spectral-based GNNs including GCN [11], DGCN [53], and H-GCN [8]; 2) spatial-based GNNs containing GAT [42], ADSF [48], Geom-GCN [31] (Geom-GCN I , Geom-GCN S , and Geom-GCN P are its variants with different embedding methods), and PH-GCN [23] (PH-GCN_ea replaces the original GAT attention mechanism in PH-GCN by Euclidean attention mechanism); 3) DiGCN [40], which is the SOTA GNN model for directed graphs. The source codes of other GNN models for directed graphs [17,22,41] are not publicly available. For GCN and GAT, we follow their implementations in the Geom-GCN paper. For all other baselines, we set their parameters the same as those in the original paper. We randomly split the datasets and perform 10 experiments for each model to obtain more reliable results. For all baselines and our WGCN model, we randomly split nodes of each class into 60%, 20%, and 20% for training, validation, and testing, respectively. This data splitting has been used in existing works such as Geom-GCN and PH-GCN. We run experiments with NVIDIA Tesla P100 [15].\n\n\nResults\n\nThe experimental results are summarized in Table 2, where the reported values denote the mean classification accuracy in percentage. WGCN achieves state-of-the-art performance on both assortative and disassortative datasets. Specifically, (i) on assortative datasets, To analyze the importance of the embedding methods for capturing nodes' latent neighbors, we implement two more variants of WGCN with Struc2vec [34] (WGCN S ) and Poincare [27] (WGCN P ) embedding methods, respectively. Struc2vec embedding that capturing node structure (k-hop neighbors' degree) similarities has a competitive performance on all datasets except the Squirrel dataset, where the accuracy is 2.3% lower than that of WGCN with Isomap embedding [38]. Its inferior performance may be due to the lack of capturing nodes' geometrical relationships, which does not suit our WGCN model. The performance of Poincare embedding achieves competitive performance on citation datasets. However, it achieves less satisfactory results on Wikipedia page link datasets with up to 7.24% drops in the accuracy. This is because Poincare embedding assumes that nodes have latent hierarchical relationships (e.g., mammal and rodent), which may not hold on the Wikipedia page link datasets on a specific topic. Therefore, we recommend using Isomap embedding (or other embedding methods) that can capture the nodes' geometrical relationships for our WGCN model.\n\n\nEfficiency\n\nTo evaluate the time costs of WGCN, we run each model with 100 epochs on different datasets and summarize the running times in Figure 7. On assortative datasets, the running time of WGCN is on par with 5 out of 8 baselines, except for the GCN, DGCN, and H-GCN models. For disassortative graphs, WGCN still achieves comparable running times with DiGCN_ib, GAT, ADSF, and Geom-GCN. Considering the performance gain of WGCN, we argue that its extra time costs are worthwhile. \n\n\nAblation Study\n\nWGCN contains two main components. The first component DDRWR applies a direction and degree aware RWR to capture the rich directional structural information. To study its impact, we implement a variant of WGCN named WGCN/E that takes all neighbors with the same weights when capturing the node structural information. In other words, we replace our proposed DDRWR with typical RWR to capture the node structural information. We skip variants using vanilla Random Walk [32] as RWR has been shown to capture node structural features better [48]. The second component of WGCN captures nodes' geometrical relationships and latent neighbors for node structural information learning. To study its impact, we implement two variants of WGCN named WGCN/G and WGCN/L. WGCN/G does not differentiate the geometrical relationships of different neighbors. In WGCN/L, the latent neighbors are removed during the geometrical aggregation (e.g., node 7 \u25cb in Figure 3). The results of different variants are summarized in Table 3. In general, WGCN and WGCN/G achieve similar accuracy with at most 0.18% difference. Meanwhile, WGCN achieves lower variances on the disassortative datasets, and WGCN/G achieves lower variances on the assortative datasets. Therefore, we recommend using WGCN for disassortative datasets and WGCN/G for assortative datasets. The geometrical relationships among assortative datasets are less important than that of disassortative datasets. For WGCN/E and WGCN/L, we see that they are consistently worse than or equal to WGCN and WGCN/G. This confirms that differentiating the inand out-neighbors and capturing the long-range dependencies are important when capturing node structural information.\n\n\nParameter Study\n\nWe examine the hyper-parameters , the number of hops of neighbors during the DDRWR process, and the number of network layers of WGCN. We set the default values of as 3, as 2 for assortative datasets and 1 for disassortative datasets, and the number of network layers as two.\n\nImpact of : Parameter determines the weight variation trend of in-and out-neighbors under a given ratio between the in-and out-degrees. A smaller value of denotes that the weight is more sensitive to the ratio (e.g., linear relationship to the ratio when is 1). A larger value of denotes that the weight is less sensitive to the ratio but changes sharply if neighbors are mostly in-or out-neighbors (e.g., the variation trend of quintic function). We report the performance of WGCN with \u2208 [1, 9] and a step length of 2. The results in Table 4 show that WGCN performs the best when the value of is 3 for all datasets. When > 3, the model's performance decreases on all datasets slightly. Therefore, we take = 3 as a choice for yielding a good performance. Impact of : The neighbors' range determines the neighbors that WGCN considers when generating node structural fingerprint. We report the performance of WGCN with -hop neighbors, where \u2208 [1,3]. The results in Table 5 show that WGCN achieves the highest accuracy using 2-hop local neighbors for assortative graphs and 1-hop local neighbors only for disassortative graphs. This possibly is because, in assortative graphs, similar nodes tend to be close to each other, where 2-hop neighbors still maintain a strong relationship with the target node, while this relationship is weaker on disassortative graphs. Notice that the determines the hops of graph neighbors to consider during the message passing, our model will also involve neighbors that close in the latent space but beyond -hop in the graph topology. Impact of the number of network layers: As shown in Section 3.5, our model first aggregates the nodes with different relationships to the target node into different virtual nodes and then aggregates all the virtual nodes to obtain the final representation of the target nodes. We add multiple layers (each layer contains a local and then a global aggregation) to evaluate the impact of the number of network layers on the model performance. As summarized in Table 6, when there are more layers, our model's performance decreases in general. We see that using two layers yields the best performance on both assortative and disassortative graphs. More specifically, on the assortative graphs, the performance of a 3-layer WGCN yields good performance, but the performance drops when the number of the network layers increases to four. On disassortative graphs, the performance of a 3-layer WGCN decreases a lot compared with a 2-layer WGCN, and the performance is even worse when the number of network layers increases to four. \n\n\nCONCLUSION\n\nWe proposed a graph convolutional network model named WGCN that captures structural features according to nodes' local topologies. WGCN first obtains nodes' structural fingerprints via a direction and degree aware Random Walk with Restart algorithm, where the walk is guided by both edge direction and in-and out-degrees of nodes. WGCN then takes the interactions between nodes' structural fingerprints as nodes' structural features. WGCN also embeds nodes into a latent space to capture nodes' high-order dependencies and latent geometrical relationships. During the message passing, WGCN contextualizes the content and structural features of each node with learnable parameters to navigate the attention-based geometrical aggregation. Experiments show that WGCN outperforms the baselines by up to 17.07% in terms of accuracy in transductive node classification on five benchmark datasets.\n\n\nACKNOWLEDGMENTS\n\nThis work is partially supported by Australian Research Council (ARC) Discovery Projects DP180102050. Yunxiang Zhao is supported by the Chinese Scholarship Council (CSC).\n\nFigure 2 :\n2(a) The percentage of nodes with different and nonzero in-and out-degrees (blue bars), the same in-and outdegrees (yellow bars), and only in-or out-neighbors (gray bars). (b) Among nodes with different and non-zero in-and out-degrees, the percentage of nodes where neighbors at the direction with a smaller degree have a higher possibility of sharing the same class with the nodes.\n\nFigure 3 :\n3Overall structure of WGCN.\n\nFigure 4 :\n4Neighbor weighing via typical RWR and the proposed Markov process for node structural information learning on a simple graph.\n\nFigure 6 :\n6An example of four-fold sub-aggregation.\n\nFigure 7 :\n7The time costs of different models on different datasets in 100 epochs. The y axis is the running time in the Log scale, and the labels are the running times in seconds.\n\nTable 1 :\n1Datasets statistics.Dataset \nCora-ML Citeseer Chameleon Squirrel Crocodile \n\nNodes \n2,995 \n4,320 \n2,277 \n5,201 \n11,631 \nEdges \n8,416 \n5,358 \n36,101 \n217,073 180,021 \nfeatures \n2,879 \n602 \n2,325 \n2,089 \n13,183 \nClasses \n7 \n6 \n5 \n5 \n5 \nAssortative \nYes \nYes \nNo \nNo \nNo \n\nto another. The nodes' content features correspond to informative \nnouns in the Wikipedia pages. The nodes are evenly divided into \nfive classes according to their average monthly traffic (number of \nvisits) \n\nTable 2 :\n2Mean Classification Accuracy (Percent) and Training Time for 100 Epochs (Second).Models \n\nAssortative \nDisassortative \nCora-ML \nCiteseer \nChameleon \nSquirrel \nCrocodile \n\nAcc \nTime \nAcc \nTime \nAcc \nTime \nAcc \nTime \nAcc \nTime \n\nGCN [11] \n76.23\u00b11.3 4.69 84.40\u00b10.9 4.00 32.21\u00b12.1 13.51 25.69\u00b11.6 46.27 55.87\u00b10.8 41.15 \nDGCN [53] \n30.07\u00b15.4 15.80 95.22\u00b10.8 5.60 61.84\u00b11.4 11.26 20.27\u00b10.7 40.65 19.82\u00b10.9 135.99 \nH-GCN [8] \n72.60\u00b14.4 9.97 91.59\u00b11.2 8.32 42.32\u00b10.1 8.12 23.54\u00b10.1 38.47 44.01\u00b10.1 46.52 \nPH-GCN [23] \n59.25\u00b13.4 2.56 80.47\u00b12.4 2.05 30.70\u00b13.6 3.94 21.13\u00b10.9 17.70 55.09\u00b10.9 42.96 \nPH-GCN_ea [23] 64.95\u00b12.5 51.70 83.65\u00b12.1 87.17 35.53\u00b13.4 44.42 24.11\u00b11.1 58.06 57.41\u00b11.1 115.68 \nDiGCN [40] \n81.22\u00b10.5 13.14 85.14\u00b10.5 12.04 51.92\u00b11.5 14.71 34.32\u00b11.1 38.23 65.47\u00b10.3 75.77 \nDiGCN_ib [40] \n83.55\u00b10.2 22.28 89.33\u00b10.5 21.60 50.59\u00b11.9 25.86 33.67\u00b10.6 92.57 63.91\u00b10.3 170.59 \nGAT [42] \n69.87\u00b12.2 30.25 79.90\u00b11.3 25.03 38.09\u00b11.5 96.35 27.89\u00b11.4 358.00 56.67\u00b11.3 315.84 \nADSF-RWR [48] 70.92\u00b12.6 30.02 80.06\u00b11.2 25.11 40.65\u00b11.8 95.71 29.01\u00b11.2 357.53 57.37\u00b11.3 304.64 \nGeom-GCN I [31] 80.94\u00b11.4 28.23 92.77\u00b10.8 22.08 60.41\u00b13.0 133.79 32.23\u00b12.2 793.29 62.37\u00b10.8 441.84 \nGeom-GCN S [31] 78.59\u00b11.2 37.84 91.50\u00b10.8 31.37 59.54\u00b13.1 138.17 34.45\u00b11.3 482.75 57.63\u00b10.4 427.52 \nGeom-GCN P [31] 82.06\u00b11.3 31.30 94.96\u00b10.7 27.27 53.46\u00b12.0 202.74 35.98\u00b11.3 428.69 47.47\u00b11.1 419.32 \n\nWGCN \n87.31\u00b12.1 27.42 96.45\u00b10.8 22.45 67.25\u00b12.9 74.97 53.05\u00b13.8 425.56 75.57\u00b10.6 580.13 \nWGCN S \n86.83\u00b12.0 29.88 95.75\u00b11.0 22.25 66.38\u00b17.9 76.40 50.75\u00b12.6 419.82 75.49\u00b10.5 578.45 \nWGCN P \n86.99\u00b11.2 27.04 95.84\u00b11.1 22.50 62.59\u00b13.3 74.94 45.81\u00b12.2 425.96 73.12\u00b10.9 594.12 \n\nWGCN achieves state-of-the-art performance on the Cora-ML and \nCiteseer datasets with 3.76% and 1.22% accuracy improvements, \nrespectively; (ii) on disassortative datasets, WGCN outperforms \nbaselines by up to 5.41% on the Chameleon dataset, 17.07% on the \nSquirrel dataset, and 10.10% on the Crocodile dataset. \n\n\nTable 3 :\n3Mean Classification Accuracy (Percent). 31\u00b12.09 96.45\u00b10.8 67.25\u00b12.98 53.05\u00b13.83 WGCN/G 87.49\u00b10.86 96.41\u00b10.3 67.43\u00b15.42 52.95\u00b14.26 WGCN/L 87.01\u00b11.56 96.41\u00b10.6 67.19\u00b13.70 52.63\u00b11.28 WGCN/E 86.78\u00b10.92 96.22\u00b10.8 66.71\u00b15.48 51.97\u00b11.76Models \nAssortative \nDisassortative \nCora-ML \nCiteseer Chameleon \nSquirrel \n\nWGCN \n87.\n\nTable 4 :\n4Accuracy with different . 49\u00b11.63 96.22\u00b10.33 67.14\u00b15.20 51.89\u00b12.26 3 87.31\u00b12.09 96.45\u00b10.80 67.25\u00b12.98 53.05\u00b13.83 5 85.60\u00b14.29 96.18\u00b10.40 66.78\u00b12.78 52.21\u00b11.25 7 86.41\u00b11.13 96.16\u00b10.49 66.03\u00b14.09 52.93\u00b11.43 9 86.46\u00b13.05 96.16\u00b10.45 66.97\u00b14.49 51.49\u00b12.23Assortative \nDisassortative \nCora-ML \nCiteseer \nChameleon \nSquirrel \n\n1 86.\n\nTable 5 :\n5Accuracy with different . 85\u00b11.96 95.90\u00b10.78 67.25\u00b12.98 53.05\u00b13.83 2 87.31\u00b12.09 96.45\u00b10.80 66.07\u00b13.47 48.99\u00b11.56 3 86.03\u00b10.63 95.86\u00b10.55 65.15\u00b11.89 47.98\u00b15.44-hops \nAssortative \nDisassortative \nCora-ML \nCiteseer \nChameleon \nSquirrel \n\n1 \n85.\n\nTable 6 :\n6Accuracy with different network layers.Layers \nAssortative \nDisassortative \nCora-ML \nCiteseer Chameleon \nSquirrel \n\n2 \n87.31\u00b12.09 96.45\u00b10.8 67.25\u00b12.98 53.05\u00b13.83 \n3 \n83.79\u00b13.56 95.84\u00b10.45 58.53\u00b13.95 33.79\u00b12.86 \n4 \n47.81\u00b16.44 90.32\u00b11.63 41.62\u00b110.05 20.91\u00b14.26 \n\n\nThe source code is public available at: https://github.com/ruizhang-ai/WGCN_Graph-Convolutional-Networks-with-Weighted-Structural-Features.\n\nDeep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking. Aleksandar Bojchevski, Stephan G\u00fcnnemann, Aleksandar Bojchevski and Stephan G\u00fcnnemann. 2018. Deep Gaussian Embed- ding of Graphs: Unsupervised Inductive Learning via Ranking. In ICLR. 1-13.\n\nJoan Bruna, Wojciech Zaremba, Arthur Szlam, Yann Lecun, arXiv:1312.6203Spectral networks and locally connected networks on graphs. arXiv preprintJoan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2013. Spectral net- works and locally connected networks on graphs. arXiv preprint arXiv:1312.6203 (2013).\n\nSimple and deep graph convolutional networks. Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, Yaliang Li, ICML. Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, and Yaliang Li. 2020. Simple and deep graph convolutional networks. In ICML. 1725-1735.\n\nConvolutional neural networks on graphs with fast localized spectral filtering. Micha\u00ebl Defferrard, Xavier Bresson, Pierre Vandergheynst, NIPS. Micha\u00ebl Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolu- tional neural networks on graphs with fast localized spectral filtering. In NIPS. 3844-3852.\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL. 4171-4186.\n\nInductive representation learning on large graphs. Will Hamilton, Zhitao Ying, Jure Leskovec, NIPS. Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NIPS. 1024-1034.\n\nLatent space approaches to social network analysis. D Peter, Adrian E Hoff, Mark S Raftery, Handcock, J. Amer. Statist. Assoc. 97Peter D Hoff, Adrian E Raftery, and Mark S Handcock. 2002. Latent space approaches to social network analysis. J. Amer. Statist. Assoc. 97, 460 (2002), 1090-1098.\n\nHierarchical Graph Convolutional Networks for Semi-supervised Node Classification. Fenyu Hu, Yanqiao Zhu, Shu Wu, Liang Wang, Tieniu Tan, IJCAI. Fenyu Hu, Yanqiao Zhu, Shu Wu, Liang Wang, and Tieniu Tan. 2019. Hierarchical Graph Convolutional Networks for Semi-supervised Node Classification. In IJCAI. 4532-4539.\n\nNode representation learning for directed graphs. Megha Khosla, Jurek Leonhardt, Wolfgang Nejdl, Avishek Anand, ECML&PKDD. Megha Khosla, Jurek Leonhardt, Wolfgang Nejdl, and Avishek Anand. 2019. Node representation learning for directed graphs. In ECML&PKDD. 395-411.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, ICLR. Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic opti- mization. In ICLR.\n\nSemi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, ICLR. Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In ICLR.\n\nPredict then propagate: Graph neural networks meet personalized pagerank. Johannes Klicpera, Aleksandar Bojchevski, Stephan G\u00fcnnemann, ICLR. Johannes Klicpera, Aleksandar Bojchevski, and Stephan G\u00fcnnemann. 2018. Pre- dict then propagate: Graph neural networks meet personalized pagerank. In ICLR.\n\nDiffusion improves graph learning. Johannes Klicpera, Stefan Wei\u00dfenberger, Stephan G\u00fcnnemann, NIPS. Johannes Klicpera, Stefan Wei\u00dfenberger, and Stephan G\u00fcnnemann. 2019. Diffu- sion improves graph learning. In NIPS. 13354-13366.\n\nCovariant compositional networks for learning graphs. Risi Kondor, Hy Truong Son, Horace Pan, Brandon Anderson, Shubhendu Trivedi, ICLR (Workshop). Risi Kondor, Hy Truong Son, Horace Pan, Brandon Anderson, and Shubhendu Trivedi. 2018. Covariant compositional networks for learning graphs. In ICLR (Workshop).\n\nSpartan performance and flexibility: An hpc-cloud chimera. Lev Lafayette, Greg Sauter, Linh Vu, Bernard Meade, OpenStack Summit. Lev Lafayette, Greg Sauter, Linh Vu, and Bernard Meade. 2016. Spartan perfor- mance and flexibility: An hpc-cloud chimera. OpenStack Summit (2016).\n\nAttention models in graphs: A survey. John Boaz Lee, A Ryan, Sungchul Rossi, Kim, K Nesreen, Eunyee Ahmed, Koh, ACM Transactions on Knowledge Discovery from Data. 13John Boaz Lee, Ryan A Rossi, Sungchul Kim, Nesreen K Ahmed, and Eunyee Koh. 2019. Attention models in graphs: A survey. ACM Transactions on Knowledge Discovery from Data 13, 6 (2019), 1-25.\n\nScalable Graph Convolutional Networks With Fast Localized Spectral Filter for Directed Graphs. Chensheng Li, Xiaowei Qin, Xiaodong Xu, Dujia Yang, Guo Wei, IEEE Access. 8Chensheng Li, Xiaowei Qin, Xiaodong Xu, Dujia Yang, and Guo Wei. 2020. Scal- able Graph Convolutional Networks With Fast Localized Spectral Filter for Di- rected Graphs. IEEE Access 8 (2020), 105634-105644.\n\nMeng Liu, Zhengyang Wang, Shuiwang Ji, arXiv:2005.14612Non-Local Graph Neural Networks. arXiv preprintMeng Liu, Zhengyang Wang, and Shuiwang Ji. 2020. Non-Local Graph Neural Networks. arXiv preprint arXiv:2005.14612 (2020).\n\nEfficient Bayesian methods for graph-based recommendation. Ramon Lopes, Renato Assun\u00e7\u00e3o, Rodrygo Lt Santos, RecSys. Ramon Lopes, Renato Assun\u00e7\u00e3o, and Rodrygo LT Santos. 2016. Efficient Bayesian methods for graph-based recommendation. In RecSys. 333-340.\n\nVGCN-BERT: augmenting BERT with graph embedding for text classification. Zhibin Lu, Pan Du, Jian-Yun Nie, Zhibin Lu, Pan Du, and Jian-Yun Nie. 2020. VGCN-BERT: augmenting BERT with graph embedding for text classification. In ECIR. 369-382.\n\nYao Ma, Ziyi Guo, Zhaocun Ren, Jiliang Tang, and Dawei Yin. 2020. Streaming graph neural networks. In SIGIR. Yao Ma, Ziyi Guo, Zhaocun Ren, Jiliang Tang, and Dawei Yin. 2020. Streaming graph neural networks. In SIGIR. 719-728.\n\nYi Ma, Jianye Hao, Yaodong Yang, Han Li, Junqi Jin, Guangyong Chen, arXiv:1907.08990Spectral-based graph convolutional network for directed graphs. arXiv preprintYi Ma, Jianye Hao, Yaodong Yang, Han Li, Junqi Jin, and Guangyong Chen. 2019. Spectral-based graph convolutional network for directed graphs. arXiv preprint arXiv:1907.08990 (2019).\n\nHesham Mostafa, Marcel Nassar, arXiv:2003.00635Permutohedral-GCN: Graph Convolutional Networks with Global Attention. arXiv preprintHesham Mostafa and Marcel Nassar. 2020. Permutohedral-GCN: Graph Con- volutional Networks with Global Attention. arXiv preprint arXiv:2003.00635 (2020).\n\nMachine learning meets complex networks via coalescent embedding in the hyperbolic space. Alessandro Muscoloni, Josephine Maria Thomas, Sara Ciucci, Ginestra Bianconi, Carlo Vittorio Cannistraci, Nature Communications. 8Alessandro Muscoloni, Josephine Maria Thomas, Sara Ciucci, Ginestra Bianconi, and Carlo Vittorio Cannistraci. 2017. Machine learning meets complex networks via coalescent embedding in the hyperbolic space. Nature Communications 8, 1 (2017), 1-19.\n\nSubgraph2vec: Learning distributed representations of rooted sub-graphs from large graphs. Annamalai Narayanan, Mahinthan Chandramohan, Lihui Chen, Yang Liu, Santhoshkumar Saminathan, arXiv:1606.08928arXiv preprintAnnamalai Narayanan, Mahinthan Chandramohan, Lihui Chen, Yang Liu, and Santhoshkumar Saminathan. 2016. Subgraph2vec: Learning distributed represen- tations of rooted sub-graphs from large graphs. arXiv preprint arXiv:1606.08928 (2016).\n\nCommunity detection on networks with ricci flow. Yu-Yao Chien-Chun Ni, Feng Lin, Jie Luo, Gao, Scientific Reports. 9Chien-Chun Ni, Yu-Yao Lin, Feng Luo, and Jie Gao. 2019. Community detection on networks with ricci flow. Scientific Reports 9, 1 (2019), 1-12.\n\nPoincar\u00e9 embeddings for learning hierarchical representations. Maximillian Nickel, Douwe Kiela, NIPS. Maximillian Nickel and Douwe Kiela. 2017. Poincar\u00e9 embeddings for learning hierarchical representations. In NIPS. 6338-6347.\n\nLearning continuous hierarchies in the lorentz model of hyperbolic geometry. Maximilian Nickel, Douwe Kiela, ICML. Maximilian Nickel and Douwe Kiela. 2018. Learning continuous hierarchies in the lorentz model of hyperbolic geometry. In ICML. 3776-3785.\n\nLearning convolutional neural networks for graphs. Mathias Niepert, Mohamed Ahmed, Konstantin Kutzkov, ICML. Mathias Niepert, Mohamed Ahmed, and Konstantin Kutzkov. 2016. Learning convolutional neural networks for graphs. In ICML. 2014-2023.\n\nAsymmetric transitivity preserving graph embedding. Mingdong Ou, Peng Cui, Jian Pei, Ziwei Zhang, Wenwu Zhu, KDD. Mingdong Ou, Peng Cui, Jian Pei, Ziwei Zhang, and Wenwu Zhu. 2016. Asym- metric transitivity preserving graph embedding. In KDD. 1105-1114.\n\nGeom-GCN: Geometric Graph Convolutional Networks. Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan, Yu Chang, Bo Lei, Yang, ICLR. Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, and Bo Yang. 2020. Geom-GCN: Geometric Graph Convolutional Networks. In ICLR.\n\nDeepwalk: Online learning of social representations. Bryan Perozzi, Rami Al-Rfou, Steven Skiena, KDD. Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In KDD. 701-710.\n\nA location-query-browse graph for contextual recommendation. Yongli Ren, Martin Tomko, Flora Dilys Salim, Jeffrey Chan, L A Charles, Mark Clarke, Sanderson, IEEE Transactions on Knowledge and Data Engineering. 30Yongli Ren, Martin Tomko, Flora Dilys Salim, Jeffrey Chan, Charles LA Clarke, and Mark Sanderson. 2017. A location-query-browse graph for contextual rec- ommendation. IEEE Transactions on Knowledge and Data Engineering 30, 2 (2017), 204-218.\n\nLeonardo Fr Ribeiro, H P Pedro, Daniel R Saverese, Figueiredo, struc2vec: Learning node representations from structural identity. In KDD. Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. 2017. struc2vec: Learning node representations from structural identity. In KDD. 385-394.\n\nCarl Benedek Rozemberczki, Rik Allen, Sarkar, arXiv:1909.13021Multi-scale Attributed Node Embedding. arXiv preprintBenedek Rozemberczki, Carl Allen, and Rik Sarkar. 2019. Multi-scale Attributed Node Embedding. arXiv preprint arXiv:1909.13021 (2019).\n\nThe emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains. David I Shuman, K Sunil, Pascal Narang, Antonio Frossard, Pierre Ortega, Vandergheynst, IEEE Signal Processing Magazine. 30David I Shuman, Sunil K Narang, Pascal Frossard, Antonio Ortega, and Pierre Vandergheynst. 2013. The emerging field of signal processing on graphs: Ex- tending high-dimensional data analysis to networks and other irregular domains. IEEE Signal Processing Magazine 30, 3 (2013), 83-98.\n\nDetecting Beneficial Feature Interactions for Recommender Systems. Yixin Su, Rui Zhang, Sarah Erfani, Zhenghua Xu, AAAI. Yixin Su, Rui Zhang, Sarah Erfani, and Zhenghua Xu. 2021. Detecting Beneficial Feature Interactions for Recommender Systems. In AAAI.\n\nA global geometric framework for nonlinear dimensionality reduction. Vin De Joshua B Tenenbaum, John C Silva, Langford, Science. 290Joshua B Tenenbaum, Vin De Silva, and John C Langford. 2000. A global geometric framework for nonlinear dimensionality reduction. Science 290, 5500 (2000), 2319- 2323.\n\nFast random walk with restart and its applications. Hanghang Tong, Christos Faloutsos, Jia-Yu Pan, ICDM. Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan. 2006. Fast random walk with restart and its applications. In ICDM. 613-622.\n\nDigraph Inception Convolutional Networks. Zekun Tong, Yuxuan Liang, Changsheng Sun, Xinke Li, David Rosenblum, Andrew Lim, NIPS. Zekun Tong, Yuxuan Liang, Changsheng Sun, Xinke Li, David Rosenblum, and Andrew Lim. 2020. Digraph Inception Convolutional Networks. In NIPS.\n\nZekun Tong, Yuxuan Liang, Changsheng Sun, S David, Andrew Rosenblum, Lim, arXiv:2004.13970Directed Graph Convolutional Network. arXiv preprintZekun Tong, Yuxuan Liang, Changsheng Sun, David S Rosenblum, and An- drew Lim. 2020. Directed Graph Convolutional Network. arXiv preprint arXiv:2004.13970 (2020).\n\nGraph attention networks. Petar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, ICLR. Petar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. In ICLR.\n\nHeterogeneous graph attention network. Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, Philip S Yu, Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019. Heterogeneous graph attention network. In WWW. 2022-2032.\n\nNodeaug: Semi-supervised node classification with data augmentation. Yiwei Wang, Wei Wang, Yuxuan Liang, Yujun Cai, Juncheng Liu, Bryan Hooi, Yiwei Wang, Wei Wang, Yuxuan Liang, Yujun Cai, Juncheng Liu, and Bryan Hooi. 2020. Nodeaug: Semi-supervised node classification with data augmentation. In KDD. 207-217.\n\nGraph-based semi-supervised learning for text classification. Natalie Widmann, Suzan Verberne, SIGIR. Natalie Widmann and Suzan Verberne. 2017. Graph-based semi-supervised learning for text classification. In SIGIR. 59-66.\n\nHow powerful are graph neural networks?. Keyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka, In ICLRKeyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerful are graph neural networks?. In ICLR.\n\nIncorporating graph attention and recurrent architectures for city-wide taxi demand prediction. Ying Xu, Dongsheng Li, ISPRS International Journal of Geo-Information. 8414Ying Xu and Dongsheng Li. 2019. Incorporating graph attention and recurrent architectures for city-wide taxi demand prediction. ISPRS International Journal of Geo-Information 8, 9 (2019), 414.\n\nAdaptive structural fingerprints for graph attention networks. Kai Zhang, Yaokang Zhu, Jun Wang, Jie Zhang, ICLR. Kai Zhang, Yaokang Zhu, Jun Wang, and Jie Zhang. 2020. Adaptive structural fingerprints for graph attention networks. In ICLR.\n\nYunxiang Zhao, Qiuhong Ke, Flip Korn, Jianzhong Qi, and Rui Zhang. 2020. HexCNN: A Framework for Native Hexagonal Convolutional Neural Networks. In ICDM. Yunxiang Zhao, Qiuhong Ke, Flip Korn, Jianzhong Qi, and Rui Zhang. 2020. HexCNN: A Framework for Native Hexagonal Convolutional Neural Networks. In ICDM. 1424-1429.\n\nCbhe: Corner-based building height estimation for complex street scene images. Yunxiang Zhao, Jianzhong Qi, Rui Zhang, Yunxiang Zhao, Jianzhong Qi, and Rui Zhang. 2019. Cbhe: Corner-based building height estimation for complex street scene images. In WWW. 2436-2447.\n\nScalable graph embedding for asymmetric proximity. Chang Zhou, Yuqiong Liu, Xiaofei Liu, Zhongyi Liu, Jun Gao, AAAI. Chang Zhou, Yuqiong Liu, Xiaofei Liu, Zhongyi Liu, and Jun Gao. 2017. Scalable graph embedding for asymmetric proximity. In AAAI. 2942-2948.\n\nNeighborhood-aware attentional representation for multilingual knowledge graphs. Qiannan Zhu, Xiaofei Zhou, Jia Wu, Jianlong Tan, Li Guo, IJCAI. Qiannan Zhu, Xiaofei Zhou, Jia Wu, Jianlong Tan, and Li Guo. 2019. Neighborhood-aware attentional representation for multilingual knowledge graphs. In IJCAI. 10-16.\n\nDual graph convolutional networks for graph-based semi-supervised classification. Chenyi Zhuang, Qiang Ma, WWW. Chenyi Zhuang and Qiang Ma. 2018. Dual graph convolutional networks for graph-based semi-supervised classification. In WWW. 499-508.\n\nUnderstanding People Lifestyles: Construction of Urban Movement Knowledge Graph from GPS Trajectory. Chenyi Zhuang, Nicholas Jing Yuan, Ruihua Song, Xing Xie, Qiang Ma, IJCAI. Chenyi Zhuang, Nicholas Jing Yuan, Ruihua Song, Xing Xie, and Qiang Ma. 2017. Understanding People Lifestyles: Construction of Urban Movement Knowledge Graph from GPS Trajectory.. In IJCAI. 3616-3623.\n", "annotations": {"author": "[{\"end\":95,\"start\":81},{\"end\":137,\"start\":96},{\"end\":182,\"start\":138},{\"end\":216,\"start\":183},{\"end\":231,\"start\":217},{\"end\":245,\"start\":232},{\"end\":258,\"start\":246},{\"end\":292,\"start\":259},{\"end\":314,\"start\":293},{\"end\":361,\"start\":315}]", "publisher": "[{\"end\":29,\"start\":23},{\"end\":517,\"start\":511}]", "author_last_name": "[{\"end\":94,\"start\":90},{\"end\":108,\"start\":106},{\"end\":149,\"start\":146},{\"end\":192,\"start\":187},{\"end\":230,\"start\":226},{\"end\":244,\"start\":242},{\"end\":257,\"start\":254},{\"end\":268,\"start\":263}]", "author_first_name": "[{\"end\":89,\"start\":81},{\"end\":105,\"start\":96},{\"end\":145,\"start\":138},{\"end\":186,\"start\":183},{\"end\":225,\"start\":217},{\"end\":241,\"start\":232},{\"end\":253,\"start\":246},{\"end\":262,\"start\":259},{\"end\":313,\"start\":312}]", "author_affiliation": "[{\"end\":215,\"start\":194},{\"end\":291,\"start\":270},{\"end\":360,\"start\":316}]", "title": "[{\"end\":22,\"start\":1},{\"end\":383,\"start\":362}]", "venue": "[{\"end\":489,\"start\":385}]", "abstract": "[{\"end\":2539,\"start\":1112}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2701,\"start\":2697},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2704,\"start\":2701},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":2707,\"start\":2704},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":2710,\"start\":2707},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":2713,\"start\":2710},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":2716,\"start\":2713},{\"end\":2902,\"start\":2870},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3502,\"start\":3498},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3505,\"start\":3502},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3711,\"start\":3707},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":3714,\"start\":3711},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":3717,\"start\":3714},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3876,\"start\":3872},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3879,\"start\":3876},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3899,\"start\":3895},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3902,\"start\":3899},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3905,\"start\":3902},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":3908,\"start\":3905},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6585,\"start\":6582},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":6764,\"start\":6760},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6966,\"start\":6962},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6969,\"start\":6966},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7222,\"start\":7218},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7286,\"start\":7282},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7289,\"start\":7286},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7381,\"start\":7378},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7384,\"start\":7381},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9763,\"start\":9759},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":9841,\"start\":9837},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10169,\"start\":10165},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":10172,\"start\":10169},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":10203,\"start\":10199},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10512,\"start\":10508},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":10666,\"start\":10662},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10940,\"start\":10936},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11243,\"start\":11239},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":11479,\"start\":11475},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":11482,\"start\":11479},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11984,\"start\":11981},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":12112,\"start\":12108},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":12240,\"start\":12236},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":12483,\"start\":12479},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":12957,\"start\":12953},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17329,\"start\":17326},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":17332,\"start\":17329},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":17335,\"start\":17332},{\"end\":18204,\"start\":18199},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":18427,\"start\":18423},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":18631,\"start\":18627},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":18634,\"start\":18631},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":18686,\"start\":18683},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":18689,\"start\":18686},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":18692,\"start\":18689},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":18695,\"start\":18692},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":18698,\"start\":18695},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19534,\"start\":19531},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21087,\"start\":21086},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27940,\"start\":27938},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":28780,\"start\":28776},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":28784,\"start\":28780},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":28788,\"start\":28784},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":28791,\"start\":28788},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":28979,\"start\":28975},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":29583,\"start\":29581},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":31359,\"start\":31357},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":32951,\"start\":32947},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":33465,\"start\":33461},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":33559,\"start\":33556},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":33576,\"start\":33573},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":33767,\"start\":33763},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":34104,\"start\":34100},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":34415,\"start\":34411},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":35133,\"start\":35129},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":35547,\"start\":35543},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":35558,\"start\":35554},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":35573,\"start\":35570},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":35616,\"start\":35612},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":35627,\"start\":35623},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":35642,\"start\":35638},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":35752,\"start\":35748},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":35868,\"start\":35864},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":35980,\"start\":35976},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":35983,\"start\":35980},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":35986,\"start\":35983},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":36562,\"start\":36558},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":36991,\"start\":36987},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":37019,\"start\":37015},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":37304,\"start\":37300},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":38973,\"start\":38969},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":39043,\"start\":39039},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":41444,\"start\":41441},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":41446,\"start\":41444}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":44580,\"start\":44186},{\"attributes\":{\"id\":\"fig_1\"},\"end\":44620,\"start\":44581},{\"attributes\":{\"id\":\"fig_4\"},\"end\":44759,\"start\":44621},{\"attributes\":{\"id\":\"fig_6\"},\"end\":44813,\"start\":44760},{\"attributes\":{\"id\":\"fig_7\"},\"end\":44996,\"start\":44814},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":45487,\"start\":44997},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":47451,\"start\":45488},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":47779,\"start\":47452},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":48117,\"start\":47780},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":48371,\"start\":48118},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":48645,\"start\":48372}]", "paragraph": "[{\"end\":3341,\"start\":2555},{\"end\":4115,\"start\":3343},{\"end\":5974,\"start\":4117},{\"end\":6361,\"start\":5976},{\"end\":7385,\"start\":6363},{\"end\":8834,\"start\":7387},{\"end\":9563,\"start\":8836},{\"end\":10858,\"start\":9580},{\"end\":11761,\"start\":10860},{\"end\":12958,\"start\":11763},{\"end\":13709,\"start\":12970},{\"end\":15592,\"start\":13736},{\"end\":17183,\"start\":15611},{\"end\":17605,\"start\":17212},{\"end\":18031,\"start\":17607},{\"end\":18157,\"start\":18040},{\"end\":19235,\"start\":18193},{\"end\":19417,\"start\":19285},{\"end\":19847,\"start\":19419},{\"end\":20030,\"start\":19911},{\"end\":20176,\"start\":20032},{\"end\":20768,\"start\":20292},{\"end\":21088,\"start\":21045},{\"end\":21443,\"start\":21205},{\"end\":21628,\"start\":21495},{\"end\":22654,\"start\":21658},{\"end\":23095,\"start\":22656},{\"end\":23626,\"start\":23097},{\"end\":24081,\"start\":23667},{\"end\":24994,\"start\":24083},{\"end\":25303,\"start\":24996},{\"end\":26188,\"start\":25323},{\"end\":27104,\"start\":26224},{\"end\":27432,\"start\":27133},{\"end\":27728,\"start\":27434},{\"end\":28214,\"start\":27763},{\"end\":29148,\"start\":28246},{\"end\":30434,\"start\":29170},{\"end\":30572,\"start\":30457},{\"end\":30704,\"start\":30589},{\"end\":30888,\"start\":30729},{\"end\":31494,\"start\":30915},{\"end\":31981,\"start\":31528},{\"end\":33215,\"start\":32005},{\"end\":33337,\"start\":33231},{\"end\":35411,\"start\":33373},{\"end\":36563,\"start\":35413},{\"end\":37994,\"start\":36575},{\"end\":38482,\"start\":38009},{\"end\":40204,\"start\":38501},{\"end\":40498,\"start\":40224},{\"end\":43090,\"start\":40500},{\"end\":43995,\"start\":43105},{\"end\":44185,\"start\":44015}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":18039,\"start\":18032},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18192,\"start\":18158},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19284,\"start\":19236},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19910,\"start\":19848},{\"attributes\":{\"id\":\"formula_4\"},\"end\":20291,\"start\":20177},{\"attributes\":{\"id\":\"formula_5\"},\"end\":20841,\"start\":20769},{\"attributes\":{\"id\":\"formula_6\"},\"end\":21044,\"start\":20841},{\"attributes\":{\"id\":\"formula_7\"},\"end\":21204,\"start\":21089},{\"attributes\":{\"id\":\"formula_8\"},\"end\":21494,\"start\":21444},{\"attributes\":{\"id\":\"formula_9\"},\"end\":21657,\"start\":21629},{\"attributes\":{\"id\":\"formula_10\"},\"end\":25322,\"start\":25304},{\"attributes\":{\"id\":\"formula_11\"},\"end\":26223,\"start\":26189},{\"attributes\":{\"id\":\"formula_12\"},\"end\":27132,\"start\":27105},{\"attributes\":{\"id\":\"formula_13\"},\"end\":27762,\"start\":27729},{\"attributes\":{\"id\":\"formula_14\"},\"end\":29169,\"start\":29149},{\"attributes\":{\"id\":\"formula_15\"},\"end\":30456,\"start\":30435},{\"attributes\":{\"id\":\"formula_16\"},\"end\":30588,\"start\":30573},{\"attributes\":{\"id\":\"formula_17\"},\"end\":30728,\"start\":30705},{\"attributes\":{\"id\":\"formula_18\"},\"end\":30914,\"start\":30889},{\"attributes\":{\"id\":\"formula_19\"},\"end\":31527,\"start\":31495}]", "table_ref": "[{\"end\":21394,\"start\":21388},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":34113,\"start\":34106},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":36625,\"start\":36618},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":39511,\"start\":39504},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":41042,\"start\":41035},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":41470,\"start\":41463},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":42529,\"start\":42522}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2553,\"start\":2541},{\"attributes\":{\"n\":\"2\"},\"end\":9578,\"start\":9566},{\"attributes\":{\"n\":\"3\"},\"end\":12968,\"start\":12961},{\"attributes\":{\"n\":\"3.1\"},\"end\":13734,\"start\":13712},{\"attributes\":{\"n\":\"3.2\"},\"end\":15609,\"start\":15595},{\"attributes\":{\"n\":\"3.3\"},\"end\":17210,\"start\":17186},{\"attributes\":{\"n\":\"3.4\"},\"end\":23665,\"start\":23629},{\"attributes\":{\"n\":\"3.5\"},\"end\":28244,\"start\":28217},{\"attributes\":{\"n\":\"3.6\"},\"end\":32003,\"start\":31984},{\"attributes\":{\"n\":\"4\"},\"end\":33229,\"start\":33218},{\"attributes\":{\"n\":\"4.1\"},\"end\":33371,\"start\":33340},{\"attributes\":{\"n\":\"4.2\"},\"end\":36573,\"start\":36566},{\"attributes\":{\"n\":\"4.3\"},\"end\":38007,\"start\":37997},{\"attributes\":{\"n\":\"4.4\"},\"end\":38499,\"start\":38485},{\"attributes\":{\"n\":\"4.5\"},\"end\":40222,\"start\":40207},{\"attributes\":{\"n\":\"5\"},\"end\":43103,\"start\":43093},{\"attributes\":{\"n\":\"6\"},\"end\":44013,\"start\":43998},{\"end\":44197,\"start\":44187},{\"end\":44592,\"start\":44582},{\"end\":44632,\"start\":44622},{\"end\":44771,\"start\":44761},{\"end\":44825,\"start\":44815},{\"end\":45007,\"start\":44998},{\"end\":45498,\"start\":45489},{\"end\":47462,\"start\":47453},{\"end\":47790,\"start\":47781},{\"end\":48128,\"start\":48119},{\"end\":48382,\"start\":48373}]", "table": "[{\"end\":45487,\"start\":45029},{\"end\":47451,\"start\":45581},{\"end\":47779,\"start\":47693},{\"end\":48117,\"start\":48042},{\"end\":48371,\"start\":48288},{\"end\":48645,\"start\":48423}]", "figure_caption": "[{\"end\":44580,\"start\":44199},{\"end\":44620,\"start\":44594},{\"end\":44759,\"start\":44634},{\"end\":44813,\"start\":44773},{\"end\":44996,\"start\":44827},{\"end\":45029,\"start\":45009},{\"end\":45581,\"start\":45500},{\"end\":47693,\"start\":47464},{\"end\":48042,\"start\":47792},{\"end\":48288,\"start\":48130},{\"end\":48423,\"start\":48384}]", "figure_ref": "[{\"end\":4400,\"start\":4392},{\"end\":5193,\"start\":5185},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14036,\"start\":14027},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14872,\"start\":14863},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15661,\"start\":15653},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16769,\"start\":16761},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":21969,\"start\":21961},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22087,\"start\":22078},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22552,\"start\":22543},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22818,\"start\":22809},{\"end\":22827,\"start\":22819},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":23347,\"start\":23338},{\"end\":24261,\"start\":24252},{\"end\":27916,\"start\":27907},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":28909,\"start\":28901},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29361,\"start\":29353},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":38144,\"start\":38136},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":39449,\"start\":39441}]", "bib_author_first_name": "[{\"end\":48877,\"start\":48867},{\"end\":48897,\"start\":48890},{\"end\":49062,\"start\":49058},{\"end\":49078,\"start\":49070},{\"end\":49094,\"start\":49088},{\"end\":49106,\"start\":49102},{\"end\":49421,\"start\":49417},{\"end\":49434,\"start\":49428},{\"end\":49448,\"start\":49440},{\"end\":49461,\"start\":49456},{\"end\":49475,\"start\":49468},{\"end\":49713,\"start\":49706},{\"end\":49732,\"start\":49726},{\"end\":49748,\"start\":49742},{\"end\":50028,\"start\":50023},{\"end\":50045,\"start\":50037},{\"end\":50059,\"start\":50053},{\"end\":50073,\"start\":50065},{\"end\":50316,\"start\":50312},{\"end\":50333,\"start\":50327},{\"end\":50344,\"start\":50340},{\"end\":50539,\"start\":50538},{\"end\":50553,\"start\":50547},{\"end\":50555,\"start\":50554},{\"end\":50566,\"start\":50562},{\"end\":50568,\"start\":50567},{\"end\":50867,\"start\":50862},{\"end\":50879,\"start\":50872},{\"end\":50888,\"start\":50885},{\"end\":50898,\"start\":50893},{\"end\":50911,\"start\":50905},{\"end\":51149,\"start\":51144},{\"end\":51163,\"start\":51158},{\"end\":51183,\"start\":51175},{\"end\":51198,\"start\":51191},{\"end\":51408,\"start\":51407},{\"end\":51424,\"start\":51419},{\"end\":51604,\"start\":51603},{\"end\":51616,\"start\":51613},{\"end\":51833,\"start\":51825},{\"end\":51854,\"start\":51844},{\"end\":51874,\"start\":51867},{\"end\":52092,\"start\":52084},{\"end\":52109,\"start\":52103},{\"end\":52131,\"start\":52124},{\"end\":52336,\"start\":52332},{\"end\":52347,\"start\":52345},{\"end\":52366,\"start\":52360},{\"end\":52379,\"start\":52372},{\"end\":52399,\"start\":52390},{\"end\":52650,\"start\":52647},{\"end\":52666,\"start\":52662},{\"end\":52679,\"start\":52675},{\"end\":52691,\"start\":52684},{\"end\":52913,\"start\":52904},{\"end\":52920,\"start\":52919},{\"end\":52935,\"start\":52927},{\"end\":52949,\"start\":52948},{\"end\":52965,\"start\":52959},{\"end\":53326,\"start\":53317},{\"end\":53338,\"start\":53331},{\"end\":53352,\"start\":53344},{\"end\":53362,\"start\":53357},{\"end\":53372,\"start\":53369},{\"end\":53604,\"start\":53600},{\"end\":53619,\"start\":53610},{\"end\":53634,\"start\":53626},{\"end\":53889,\"start\":53884},{\"end\":53903,\"start\":53897},{\"end\":53924,\"start\":53914},{\"end\":54159,\"start\":54153},{\"end\":54167,\"start\":54164},{\"end\":54180,\"start\":54172},{\"end\":54324,\"start\":54321},{\"end\":54333,\"start\":54329},{\"end\":54346,\"start\":54339},{\"end\":54551,\"start\":54549},{\"end\":54562,\"start\":54556},{\"end\":54575,\"start\":54568},{\"end\":54585,\"start\":54582},{\"end\":54595,\"start\":54590},{\"end\":54610,\"start\":54601},{\"end\":54900,\"start\":54894},{\"end\":54916,\"start\":54910},{\"end\":55280,\"start\":55270},{\"end\":55301,\"start\":55292},{\"end\":55307,\"start\":55302},{\"end\":55320,\"start\":55316},{\"end\":55337,\"start\":55329},{\"end\":55353,\"start\":55348},{\"end\":55362,\"start\":55354},{\"end\":55748,\"start\":55739},{\"end\":55769,\"start\":55760},{\"end\":55789,\"start\":55784},{\"end\":55800,\"start\":55796},{\"end\":55819,\"start\":55806},{\"end\":56154,\"start\":56148},{\"end\":56174,\"start\":56170},{\"end\":56183,\"start\":56180},{\"end\":56433,\"start\":56422},{\"end\":56447,\"start\":56442},{\"end\":56674,\"start\":56664},{\"end\":56688,\"start\":56683},{\"end\":56899,\"start\":56892},{\"end\":56916,\"start\":56909},{\"end\":56934,\"start\":56924},{\"end\":57144,\"start\":57136},{\"end\":57153,\"start\":57149},{\"end\":57163,\"start\":57159},{\"end\":57174,\"start\":57169},{\"end\":57187,\"start\":57182},{\"end\":57396,\"start\":57389},{\"end\":57409,\"start\":57402},{\"end\":57420,\"start\":57415},{\"end\":57435,\"start\":57433},{\"end\":57445,\"start\":57443},{\"end\":57658,\"start\":57653},{\"end\":57672,\"start\":57668},{\"end\":57688,\"start\":57682},{\"end\":57894,\"start\":57888},{\"end\":57906,\"start\":57900},{\"end\":57919,\"start\":57914},{\"end\":57925,\"start\":57920},{\"end\":57940,\"start\":57933},{\"end\":57948,\"start\":57947},{\"end\":57950,\"start\":57949},{\"end\":57964,\"start\":57960},{\"end\":58304,\"start\":58303},{\"end\":58306,\"start\":58305},{\"end\":58320,\"start\":58314},{\"end\":58322,\"start\":58321},{\"end\":58580,\"start\":58576},{\"end\":58606,\"start\":58603},{\"end\":58977,\"start\":58976},{\"end\":58991,\"start\":58985},{\"end\":59007,\"start\":59000},{\"end\":59024,\"start\":59018},{\"end\":59441,\"start\":59436},{\"end\":59449,\"start\":59446},{\"end\":59462,\"start\":59457},{\"end\":59479,\"start\":59471},{\"end\":59697,\"start\":59694},{\"end\":59700,\"start\":59698},{\"end\":59727,\"start\":59721},{\"end\":59986,\"start\":59978},{\"end\":60001,\"start\":59993},{\"end\":60019,\"start\":60013},{\"end\":60206,\"start\":60201},{\"end\":60219,\"start\":60213},{\"end\":60237,\"start\":60227},{\"end\":60248,\"start\":60243},{\"end\":60258,\"start\":60253},{\"end\":60276,\"start\":60270},{\"end\":60436,\"start\":60431},{\"end\":60449,\"start\":60443},{\"end\":60467,\"start\":60457},{\"end\":60474,\"start\":60473},{\"end\":60488,\"start\":60482},{\"end\":60768,\"start\":60763},{\"end\":60788,\"start\":60781},{\"end\":60806,\"start\":60799},{\"end\":60824,\"start\":60817},{\"end\":60839,\"start\":60833},{\"end\":60851,\"start\":60845},{\"end\":61052,\"start\":61048},{\"end\":61064,\"start\":61059},{\"end\":61074,\"start\":61069},{\"end\":61083,\"start\":61080},{\"end\":61097,\"start\":61090},{\"end\":61106,\"start\":61102},{\"end\":61120,\"start\":61112},{\"end\":61345,\"start\":61340},{\"end\":61355,\"start\":61352},{\"end\":61368,\"start\":61362},{\"end\":61381,\"start\":61376},{\"end\":61395,\"start\":61387},{\"end\":61406,\"start\":61401},{\"end\":61652,\"start\":61645},{\"end\":61667,\"start\":61662},{\"end\":61854,\"start\":61848},{\"end\":61865,\"start\":61859},{\"end\":61874,\"start\":61870},{\"end\":61893,\"start\":61885},{\"end\":62126,\"start\":62122},{\"end\":62140,\"start\":62131},{\"end\":62457,\"start\":62454},{\"end\":62472,\"start\":62465},{\"end\":62481,\"start\":62478},{\"end\":62491,\"start\":62488},{\"end\":62641,\"start\":62633},{\"end\":62655,\"start\":62648},{\"end\":63040,\"start\":63032},{\"end\":63056,\"start\":63047},{\"end\":63064,\"start\":63061},{\"end\":63277,\"start\":63272},{\"end\":63291,\"start\":63284},{\"end\":63304,\"start\":63297},{\"end\":63317,\"start\":63310},{\"end\":63326,\"start\":63323},{\"end\":63568,\"start\":63561},{\"end\":63581,\"start\":63574},{\"end\":63591,\"start\":63588},{\"end\":63604,\"start\":63596},{\"end\":63612,\"start\":63610},{\"end\":63879,\"start\":63873},{\"end\":63893,\"start\":63888},{\"end\":64144,\"start\":64138},{\"end\":64161,\"start\":64153},{\"end\":64166,\"start\":64162},{\"end\":64179,\"start\":64173},{\"end\":64190,\"start\":64186},{\"end\":64201,\"start\":64196}]", "bib_author_last_name": "[{\"end\":48888,\"start\":48878},{\"end\":48907,\"start\":48898},{\"end\":49068,\"start\":49063},{\"end\":49086,\"start\":49079},{\"end\":49100,\"start\":49095},{\"end\":49112,\"start\":49107},{\"end\":49426,\"start\":49422},{\"end\":49438,\"start\":49435},{\"end\":49454,\"start\":49449},{\"end\":49466,\"start\":49462},{\"end\":49478,\"start\":49476},{\"end\":49724,\"start\":49714},{\"end\":49740,\"start\":49733},{\"end\":49762,\"start\":49749},{\"end\":50035,\"start\":50029},{\"end\":50051,\"start\":50046},{\"end\":50063,\"start\":50060},{\"end\":50083,\"start\":50074},{\"end\":50325,\"start\":50317},{\"end\":50338,\"start\":50334},{\"end\":50353,\"start\":50345},{\"end\":50545,\"start\":50540},{\"end\":50560,\"start\":50556},{\"end\":50576,\"start\":50569},{\"end\":50586,\"start\":50578},{\"end\":50870,\"start\":50868},{\"end\":50883,\"start\":50880},{\"end\":50891,\"start\":50889},{\"end\":50903,\"start\":50899},{\"end\":50915,\"start\":50912},{\"end\":51156,\"start\":51150},{\"end\":51173,\"start\":51164},{\"end\":51189,\"start\":51184},{\"end\":51204,\"start\":51199},{\"end\":51417,\"start\":51409},{\"end\":51431,\"start\":51425},{\"end\":51435,\"start\":51433},{\"end\":51611,\"start\":51605},{\"end\":51621,\"start\":51617},{\"end\":51630,\"start\":51623},{\"end\":51842,\"start\":51834},{\"end\":51865,\"start\":51855},{\"end\":51884,\"start\":51875},{\"end\":52101,\"start\":52093},{\"end\":52122,\"start\":52110},{\"end\":52141,\"start\":52132},{\"end\":52343,\"start\":52337},{\"end\":52358,\"start\":52348},{\"end\":52370,\"start\":52367},{\"end\":52388,\"start\":52380},{\"end\":52407,\"start\":52400},{\"end\":52660,\"start\":52651},{\"end\":52673,\"start\":52667},{\"end\":52682,\"start\":52680},{\"end\":52697,\"start\":52692},{\"end\":52917,\"start\":52914},{\"end\":52925,\"start\":52921},{\"end\":52941,\"start\":52936},{\"end\":52946,\"start\":52943},{\"end\":52957,\"start\":52950},{\"end\":52971,\"start\":52966},{\"end\":52976,\"start\":52973},{\"end\":53329,\"start\":53327},{\"end\":53342,\"start\":53339},{\"end\":53355,\"start\":53353},{\"end\":53367,\"start\":53363},{\"end\":53376,\"start\":53373},{\"end\":53608,\"start\":53605},{\"end\":53624,\"start\":53620},{\"end\":53637,\"start\":53635},{\"end\":53895,\"start\":53890},{\"end\":53912,\"start\":53904},{\"end\":53931,\"start\":53925},{\"end\":54162,\"start\":54160},{\"end\":54170,\"start\":54168},{\"end\":54184,\"start\":54181},{\"end\":54327,\"start\":54325},{\"end\":54337,\"start\":54334},{\"end\":54350,\"start\":54347},{\"end\":54554,\"start\":54552},{\"end\":54566,\"start\":54563},{\"end\":54580,\"start\":54576},{\"end\":54588,\"start\":54586},{\"end\":54599,\"start\":54596},{\"end\":54615,\"start\":54611},{\"end\":54908,\"start\":54901},{\"end\":54923,\"start\":54917},{\"end\":55290,\"start\":55281},{\"end\":55314,\"start\":55308},{\"end\":55327,\"start\":55321},{\"end\":55346,\"start\":55338},{\"end\":55374,\"start\":55363},{\"end\":55758,\"start\":55749},{\"end\":55782,\"start\":55770},{\"end\":55794,\"start\":55790},{\"end\":55804,\"start\":55801},{\"end\":55830,\"start\":55820},{\"end\":56168,\"start\":56155},{\"end\":56178,\"start\":56175},{\"end\":56187,\"start\":56184},{\"end\":56192,\"start\":56189},{\"end\":56440,\"start\":56434},{\"end\":56453,\"start\":56448},{\"end\":56681,\"start\":56675},{\"end\":56694,\"start\":56689},{\"end\":56907,\"start\":56900},{\"end\":56922,\"start\":56917},{\"end\":56942,\"start\":56935},{\"end\":57147,\"start\":57145},{\"end\":57157,\"start\":57154},{\"end\":57167,\"start\":57164},{\"end\":57180,\"start\":57175},{\"end\":57191,\"start\":57188},{\"end\":57400,\"start\":57397},{\"end\":57413,\"start\":57410},{\"end\":57431,\"start\":57421},{\"end\":57441,\"start\":57436},{\"end\":57449,\"start\":57446},{\"end\":57455,\"start\":57451},{\"end\":57666,\"start\":57659},{\"end\":57680,\"start\":57673},{\"end\":57695,\"start\":57689},{\"end\":57898,\"start\":57895},{\"end\":57912,\"start\":57907},{\"end\":57931,\"start\":57926},{\"end\":57945,\"start\":57941},{\"end\":57958,\"start\":57951},{\"end\":57971,\"start\":57965},{\"end\":57982,\"start\":57973},{\"end\":58301,\"start\":58282},{\"end\":58312,\"start\":58307},{\"end\":58331,\"start\":58323},{\"end\":58343,\"start\":58333},{\"end\":58601,\"start\":58581},{\"end\":58612,\"start\":58607},{\"end\":58620,\"start\":58614},{\"end\":58974,\"start\":58960},{\"end\":58983,\"start\":58978},{\"end\":58998,\"start\":58992},{\"end\":59016,\"start\":59008},{\"end\":59031,\"start\":59025},{\"end\":59046,\"start\":59033},{\"end\":59444,\"start\":59442},{\"end\":59455,\"start\":59450},{\"end\":59469,\"start\":59463},{\"end\":59482,\"start\":59480},{\"end\":59719,\"start\":59701},{\"end\":59733,\"start\":59728},{\"end\":59743,\"start\":59735},{\"end\":59991,\"start\":59987},{\"end\":60011,\"start\":60002},{\"end\":60023,\"start\":60020},{\"end\":60211,\"start\":60207},{\"end\":60225,\"start\":60220},{\"end\":60241,\"start\":60238},{\"end\":60251,\"start\":60249},{\"end\":60268,\"start\":60259},{\"end\":60280,\"start\":60277},{\"end\":60441,\"start\":60437},{\"end\":60455,\"start\":60450},{\"end\":60471,\"start\":60468},{\"end\":60480,\"start\":60475},{\"end\":60498,\"start\":60489},{\"end\":60503,\"start\":60500},{\"end\":60779,\"start\":60769},{\"end\":60797,\"start\":60789},{\"end\":60815,\"start\":60807},{\"end\":60831,\"start\":60825},{\"end\":60843,\"start\":60840},{\"end\":60858,\"start\":60852},{\"end\":61057,\"start\":61053},{\"end\":61067,\"start\":61065},{\"end\":61078,\"start\":61075},{\"end\":61088,\"start\":61084},{\"end\":61100,\"start\":61098},{\"end\":61110,\"start\":61107},{\"end\":61123,\"start\":61121},{\"end\":61350,\"start\":61346},{\"end\":61360,\"start\":61356},{\"end\":61374,\"start\":61369},{\"end\":61385,\"start\":61382},{\"end\":61399,\"start\":61396},{\"end\":61411,\"start\":61407},{\"end\":61660,\"start\":61653},{\"end\":61676,\"start\":61668},{\"end\":61857,\"start\":61855},{\"end\":61868,\"start\":61866},{\"end\":61883,\"start\":61875},{\"end\":61901,\"start\":61894},{\"end\":62129,\"start\":62127},{\"end\":62143,\"start\":62141},{\"end\":62463,\"start\":62458},{\"end\":62476,\"start\":62473},{\"end\":62486,\"start\":62482},{\"end\":62497,\"start\":62492},{\"end\":62646,\"start\":62642},{\"end\":62658,\"start\":62656},{\"end\":63045,\"start\":63041},{\"end\":63059,\"start\":63057},{\"end\":63070,\"start\":63065},{\"end\":63282,\"start\":63278},{\"end\":63295,\"start\":63292},{\"end\":63308,\"start\":63305},{\"end\":63321,\"start\":63318},{\"end\":63330,\"start\":63327},{\"end\":63572,\"start\":63569},{\"end\":63586,\"start\":63582},{\"end\":63594,\"start\":63592},{\"end\":63608,\"start\":63605},{\"end\":63616,\"start\":63613},{\"end\":63886,\"start\":63880},{\"end\":63896,\"start\":63894},{\"end\":64151,\"start\":64145},{\"end\":64171,\"start\":64167},{\"end\":64184,\"start\":64180},{\"end\":64194,\"start\":64191},{\"end\":64204,\"start\":64202}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":49056,\"start\":48787},{\"attributes\":{\"doi\":\"arXiv:1312.6203\",\"id\":\"b1\"},\"end\":49369,\"start\":49058},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":220363476},\"end\":49624,\"start\":49371},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3016223},\"end\":49939,\"start\":49626},{\"attributes\":{\"id\":\"b4\"},\"end\":50259,\"start\":49941},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":4755450},\"end\":50484,\"start\":50261},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":15173994},\"end\":50777,\"start\":50486},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":173188231},\"end\":51092,\"start\":50779},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":53046770},\"end\":51361,\"start\":51094},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":6628106},\"end\":51535,\"start\":51363},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":3144218},\"end\":51749,\"start\":51537},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":67855539},\"end\":52047,\"start\":51751},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":202783932},\"end\":52276,\"start\":52049},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":2703040},\"end\":52586,\"start\":52278},{\"attributes\":{\"id\":\"b14\"},\"end\":52864,\"start\":52588},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":219890523},\"end\":53220,\"start\":52866},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":219689836},\"end\":53598,\"start\":53222},{\"attributes\":{\"doi\":\"arXiv:2005.14612\",\"id\":\"b17\"},\"end\":53823,\"start\":53600},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":8947749},\"end\":54078,\"start\":53825},{\"attributes\":{\"id\":\"b19\"},\"end\":54319,\"start\":54080},{\"attributes\":{\"id\":\"b20\"},\"end\":54547,\"start\":54321},{\"attributes\":{\"doi\":\"arXiv:1907.08990\",\"id\":\"b21\"},\"end\":54892,\"start\":54549},{\"attributes\":{\"doi\":\"arXiv:2003.00635\",\"id\":\"b22\"},\"end\":55178,\"start\":54894},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":17123412},\"end\":55646,\"start\":55180},{\"attributes\":{\"doi\":\"arXiv:1606.08928\",\"id\":\"b24\"},\"end\":56097,\"start\":55648},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":195848169},\"end\":56357,\"start\":56099},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":25418227},\"end\":56585,\"start\":56359},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":47016889},\"end\":56839,\"start\":56587},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1430801},\"end\":57082,\"start\":56841},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":4957091},\"end\":57337,\"start\":57084},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":210843644},\"end\":57598,\"start\":57339},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":3051291},\"end\":57825,\"start\":57600},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":6784014},\"end\":58280,\"start\":57827},{\"attributes\":{\"id\":\"b33\"},\"end\":58574,\"start\":58282},{\"attributes\":{\"doi\":\"arXiv:1909.13021\",\"id\":\"b34\"},\"end\":58825,\"start\":58576},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":1594725},\"end\":59367,\"start\":58827},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":234771712},\"end\":59623,\"start\":59369},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":221338160},\"end\":59924,\"start\":59625},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":3926195},\"end\":60157,\"start\":59926},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":227275072},\"end\":60429,\"start\":60159},{\"attributes\":{\"doi\":\"arXiv:2004.13970\",\"id\":\"b40\"},\"end\":60735,\"start\":60431},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":3292002},\"end\":61007,\"start\":60737},{\"attributes\":{\"id\":\"b42\"},\"end\":61269,\"start\":61009},{\"attributes\":{\"id\":\"b43\"},\"end\":61581,\"start\":61271},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":28426544},\"end\":61805,\"start\":61583},{\"attributes\":{\"id\":\"b45\"},\"end\":62024,\"start\":61807},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":203142296},\"end\":62389,\"start\":62026},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":212901464},\"end\":62631,\"start\":62391},{\"attributes\":{\"id\":\"b48\"},\"end\":62951,\"start\":62633},{\"attributes\":{\"id\":\"b49\"},\"end\":63219,\"start\":62953},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":29152633},\"end\":63478,\"start\":63221},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":199465777},\"end\":63789,\"start\":63480},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":4899764},\"end\":64035,\"start\":63791},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":6095069},\"end\":64413,\"start\":64037}]", "bib_title": "[{\"end\":49415,\"start\":49371},{\"end\":49704,\"start\":49626},{\"end\":50310,\"start\":50261},{\"end\":50536,\"start\":50486},{\"end\":50860,\"start\":50779},{\"end\":51142,\"start\":51094},{\"end\":51405,\"start\":51363},{\"end\":51601,\"start\":51537},{\"end\":51823,\"start\":51751},{\"end\":52082,\"start\":52049},{\"end\":52330,\"start\":52278},{\"end\":52645,\"start\":52588},{\"end\":52902,\"start\":52866},{\"end\":53315,\"start\":53222},{\"end\":53882,\"start\":53825},{\"end\":55268,\"start\":55180},{\"end\":56146,\"start\":56099},{\"end\":56420,\"start\":56359},{\"end\":56662,\"start\":56587},{\"end\":56890,\"start\":56841},{\"end\":57134,\"start\":57084},{\"end\":57387,\"start\":57339},{\"end\":57651,\"start\":57600},{\"end\":57886,\"start\":57827},{\"end\":58958,\"start\":58827},{\"end\":59434,\"start\":59369},{\"end\":59692,\"start\":59625},{\"end\":59976,\"start\":59926},{\"end\":60199,\"start\":60159},{\"end\":60761,\"start\":60737},{\"end\":61643,\"start\":61583},{\"end\":62120,\"start\":62026},{\"end\":62452,\"start\":62391},{\"end\":63270,\"start\":63221},{\"end\":63559,\"start\":63480},{\"end\":63871,\"start\":63791},{\"end\":64136,\"start\":64037}]", "bib_author": "[{\"end\":48890,\"start\":48867},{\"end\":48909,\"start\":48890},{\"end\":49070,\"start\":49058},{\"end\":49088,\"start\":49070},{\"end\":49102,\"start\":49088},{\"end\":49114,\"start\":49102},{\"end\":49428,\"start\":49417},{\"end\":49440,\"start\":49428},{\"end\":49456,\"start\":49440},{\"end\":49468,\"start\":49456},{\"end\":49480,\"start\":49468},{\"end\":49726,\"start\":49706},{\"end\":49742,\"start\":49726},{\"end\":49764,\"start\":49742},{\"end\":50037,\"start\":50023},{\"end\":50053,\"start\":50037},{\"end\":50065,\"start\":50053},{\"end\":50085,\"start\":50065},{\"end\":50327,\"start\":50312},{\"end\":50340,\"start\":50327},{\"end\":50355,\"start\":50340},{\"end\":50547,\"start\":50538},{\"end\":50562,\"start\":50547},{\"end\":50578,\"start\":50562},{\"end\":50588,\"start\":50578},{\"end\":50872,\"start\":50862},{\"end\":50885,\"start\":50872},{\"end\":50893,\"start\":50885},{\"end\":50905,\"start\":50893},{\"end\":50917,\"start\":50905},{\"end\":51158,\"start\":51144},{\"end\":51175,\"start\":51158},{\"end\":51191,\"start\":51175},{\"end\":51206,\"start\":51191},{\"end\":51419,\"start\":51407},{\"end\":51433,\"start\":51419},{\"end\":51437,\"start\":51433},{\"end\":51613,\"start\":51603},{\"end\":51623,\"start\":51613},{\"end\":51632,\"start\":51623},{\"end\":51844,\"start\":51825},{\"end\":51867,\"start\":51844},{\"end\":51886,\"start\":51867},{\"end\":52103,\"start\":52084},{\"end\":52124,\"start\":52103},{\"end\":52143,\"start\":52124},{\"end\":52345,\"start\":52332},{\"end\":52360,\"start\":52345},{\"end\":52372,\"start\":52360},{\"end\":52390,\"start\":52372},{\"end\":52409,\"start\":52390},{\"end\":52662,\"start\":52647},{\"end\":52675,\"start\":52662},{\"end\":52684,\"start\":52675},{\"end\":52699,\"start\":52684},{\"end\":52919,\"start\":52904},{\"end\":52927,\"start\":52919},{\"end\":52943,\"start\":52927},{\"end\":52948,\"start\":52943},{\"end\":52959,\"start\":52948},{\"end\":52973,\"start\":52959},{\"end\":52978,\"start\":52973},{\"end\":53331,\"start\":53317},{\"end\":53344,\"start\":53331},{\"end\":53357,\"start\":53344},{\"end\":53369,\"start\":53357},{\"end\":53378,\"start\":53369},{\"end\":53610,\"start\":53600},{\"end\":53626,\"start\":53610},{\"end\":53639,\"start\":53626},{\"end\":53897,\"start\":53884},{\"end\":53914,\"start\":53897},{\"end\":53933,\"start\":53914},{\"end\":54164,\"start\":54153},{\"end\":54172,\"start\":54164},{\"end\":54186,\"start\":54172},{\"end\":54329,\"start\":54321},{\"end\":54339,\"start\":54329},{\"end\":54352,\"start\":54339},{\"end\":54556,\"start\":54549},{\"end\":54568,\"start\":54556},{\"end\":54582,\"start\":54568},{\"end\":54590,\"start\":54582},{\"end\":54601,\"start\":54590},{\"end\":54617,\"start\":54601},{\"end\":54910,\"start\":54894},{\"end\":54925,\"start\":54910},{\"end\":55292,\"start\":55270},{\"end\":55316,\"start\":55292},{\"end\":55329,\"start\":55316},{\"end\":55348,\"start\":55329},{\"end\":55376,\"start\":55348},{\"end\":55760,\"start\":55739},{\"end\":55784,\"start\":55760},{\"end\":55796,\"start\":55784},{\"end\":55806,\"start\":55796},{\"end\":55832,\"start\":55806},{\"end\":56170,\"start\":56148},{\"end\":56180,\"start\":56170},{\"end\":56189,\"start\":56180},{\"end\":56194,\"start\":56189},{\"end\":56442,\"start\":56422},{\"end\":56455,\"start\":56442},{\"end\":56683,\"start\":56664},{\"end\":56696,\"start\":56683},{\"end\":56909,\"start\":56892},{\"end\":56924,\"start\":56909},{\"end\":56944,\"start\":56924},{\"end\":57149,\"start\":57136},{\"end\":57159,\"start\":57149},{\"end\":57169,\"start\":57159},{\"end\":57182,\"start\":57169},{\"end\":57193,\"start\":57182},{\"end\":57402,\"start\":57389},{\"end\":57415,\"start\":57402},{\"end\":57433,\"start\":57415},{\"end\":57443,\"start\":57433},{\"end\":57451,\"start\":57443},{\"end\":57457,\"start\":57451},{\"end\":57668,\"start\":57653},{\"end\":57682,\"start\":57668},{\"end\":57697,\"start\":57682},{\"end\":57900,\"start\":57888},{\"end\":57914,\"start\":57900},{\"end\":57933,\"start\":57914},{\"end\":57947,\"start\":57933},{\"end\":57960,\"start\":57947},{\"end\":57973,\"start\":57960},{\"end\":57984,\"start\":57973},{\"end\":58303,\"start\":58282},{\"end\":58314,\"start\":58303},{\"end\":58333,\"start\":58314},{\"end\":58345,\"start\":58333},{\"end\":58603,\"start\":58576},{\"end\":58614,\"start\":58603},{\"end\":58622,\"start\":58614},{\"end\":58976,\"start\":58960},{\"end\":58985,\"start\":58976},{\"end\":59000,\"start\":58985},{\"end\":59018,\"start\":59000},{\"end\":59033,\"start\":59018},{\"end\":59048,\"start\":59033},{\"end\":59446,\"start\":59436},{\"end\":59457,\"start\":59446},{\"end\":59471,\"start\":59457},{\"end\":59484,\"start\":59471},{\"end\":59721,\"start\":59694},{\"end\":59735,\"start\":59721},{\"end\":59745,\"start\":59735},{\"end\":59993,\"start\":59978},{\"end\":60013,\"start\":59993},{\"end\":60025,\"start\":60013},{\"end\":60213,\"start\":60201},{\"end\":60227,\"start\":60213},{\"end\":60243,\"start\":60227},{\"end\":60253,\"start\":60243},{\"end\":60270,\"start\":60253},{\"end\":60282,\"start\":60270},{\"end\":60443,\"start\":60431},{\"end\":60457,\"start\":60443},{\"end\":60473,\"start\":60457},{\"end\":60482,\"start\":60473},{\"end\":60500,\"start\":60482},{\"end\":60505,\"start\":60500},{\"end\":60781,\"start\":60763},{\"end\":60799,\"start\":60781},{\"end\":60817,\"start\":60799},{\"end\":60833,\"start\":60817},{\"end\":60845,\"start\":60833},{\"end\":60860,\"start\":60845},{\"end\":61059,\"start\":61048},{\"end\":61069,\"start\":61059},{\"end\":61080,\"start\":61069},{\"end\":61090,\"start\":61080},{\"end\":61102,\"start\":61090},{\"end\":61112,\"start\":61102},{\"end\":61125,\"start\":61112},{\"end\":61352,\"start\":61340},{\"end\":61362,\"start\":61352},{\"end\":61376,\"start\":61362},{\"end\":61387,\"start\":61376},{\"end\":61401,\"start\":61387},{\"end\":61413,\"start\":61401},{\"end\":61662,\"start\":61645},{\"end\":61678,\"start\":61662},{\"end\":61859,\"start\":61848},{\"end\":61870,\"start\":61859},{\"end\":61885,\"start\":61870},{\"end\":61903,\"start\":61885},{\"end\":62131,\"start\":62122},{\"end\":62145,\"start\":62131},{\"end\":62465,\"start\":62454},{\"end\":62478,\"start\":62465},{\"end\":62488,\"start\":62478},{\"end\":62499,\"start\":62488},{\"end\":62648,\"start\":62633},{\"end\":62660,\"start\":62648},{\"end\":63047,\"start\":63032},{\"end\":63061,\"start\":63047},{\"end\":63072,\"start\":63061},{\"end\":63284,\"start\":63272},{\"end\":63297,\"start\":63284},{\"end\":63310,\"start\":63297},{\"end\":63323,\"start\":63310},{\"end\":63332,\"start\":63323},{\"end\":63574,\"start\":63561},{\"end\":63588,\"start\":63574},{\"end\":63596,\"start\":63588},{\"end\":63610,\"start\":63596},{\"end\":63618,\"start\":63610},{\"end\":63888,\"start\":63873},{\"end\":63898,\"start\":63888},{\"end\":64153,\"start\":64138},{\"end\":64173,\"start\":64153},{\"end\":64186,\"start\":64173},{\"end\":64196,\"start\":64186},{\"end\":64206,\"start\":64196}]", "bib_venue": "[{\"end\":48865,\"start\":48787},{\"end\":49187,\"start\":49129},{\"end\":49484,\"start\":49480},{\"end\":49768,\"start\":49764},{\"end\":50021,\"start\":49941},{\"end\":50359,\"start\":50355},{\"end\":50611,\"start\":50588},{\"end\":50922,\"start\":50917},{\"end\":51215,\"start\":51206},{\"end\":51441,\"start\":51437},{\"end\":51636,\"start\":51632},{\"end\":51890,\"start\":51886},{\"end\":52147,\"start\":52143},{\"end\":52424,\"start\":52409},{\"end\":52715,\"start\":52699},{\"end\":53027,\"start\":52978},{\"end\":53389,\"start\":53378},{\"end\":53686,\"start\":53655},{\"end\":53939,\"start\":53933},{\"end\":54151,\"start\":54080},{\"end\":54428,\"start\":54352},{\"end\":54695,\"start\":54633},{\"end\":55010,\"start\":54941},{\"end\":55397,\"start\":55376},{\"end\":55737,\"start\":55648},{\"end\":56212,\"start\":56194},{\"end\":56459,\"start\":56455},{\"end\":56700,\"start\":56696},{\"end\":56948,\"start\":56944},{\"end\":57196,\"start\":57193},{\"end\":57461,\"start\":57457},{\"end\":57700,\"start\":57697},{\"end\":58035,\"start\":57984},{\"end\":58418,\"start\":58345},{\"end\":58675,\"start\":58638},{\"end\":59079,\"start\":59048},{\"end\":59488,\"start\":59484},{\"end\":59752,\"start\":59745},{\"end\":60029,\"start\":60025},{\"end\":60286,\"start\":60282},{\"end\":60557,\"start\":60521},{\"end\":60864,\"start\":60860},{\"end\":61046,\"start\":61009},{\"end\":61338,\"start\":61271},{\"end\":61683,\"start\":61678},{\"end\":61846,\"start\":61807},{\"end\":62191,\"start\":62145},{\"end\":62503,\"start\":62499},{\"end\":62785,\"start\":62660},{\"end\":63030,\"start\":62953},{\"end\":63336,\"start\":63332},{\"end\":63623,\"start\":63618},{\"end\":63901,\"start\":63898},{\"end\":64211,\"start\":64206}]"}}}, "year": 2023, "month": 12, "day": 17}