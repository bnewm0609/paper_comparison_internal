{"id": 250340430, "updated": "2022-07-09 16:14:28.454", "metadata": {"title": "An MLP-based Algorithm for Efficient Contrastive Graph Recommendations", "authors": "[{\"first\":\"Siwei\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Iadh\",\"last\":\"Ounis\",\"middle\":[]},{\"first\":\"Craig\",\"last\":\"Macdonald\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Graph-based recommender systems (GBRSs) have achieved promising performance by incorporating the user-item bipartite graph using the Graph Neural Network (GNN). Among GBRSs, the information from each user and item's multi-hop neighbours is effectively conveyed between nodes through neighbourhood aggregation and message passing. Although effective, existing neighbourhood information aggregation and passing functions are usually computationally expensive. Motivated by the emerging contrastive learning technique, we design a simple neighbourhood construction method in conjunction with the contrastive objective function to simulate the neighbourhood information processing of GNN. In addition, we propose a simple algorithm based on Multilayer Perceptron (MLP) for learning users and items' representations with extra non-linearity while lowering computational burden compared with multi-layers GNNs. Our extensive empirical experiments on three public datasets demonstrate that our proposed model, i.e. MLP-CGRec, can reduce the GPU memory consumption and training time by up to 24.0% and 33.1%, respectively, without significantly degenerating the recommendation accuracy in comparison with competitive baselines.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigir/0001OM22", "doi": "10.1145/3477495.3531874"}}, "content": {"source": {"pdf_hash": "46bd3d5fdfb5f8550bc3750cb3b6362fd29e425a", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "9f105e62d1fedea85cda8ea54dde3771aa92a6ef", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/46bd3d5fdfb5f8550bc3750cb3b6362fd29e425a.txt", "contents": "\nAn MLP-based Algorithm for Efficient Contrastive Graph Recommendations\nACMCopyright ACM2022. July 11-15, 2022\n\nSiwei Liu \nUniversity of Glasgow Glasgow\nScotland Iadh Ounis\n\nCraig Macdonald craig.macdonald@glasgow.ac.uk \nUniversity of Glasgow Glasgow\nScotland, United Kingdom\n\nSiwei Liu \nUniversity of Glasgow Glasgow\nScotland, United Kingdom\n\nIadh Ounis iadh.ounis@glasgow.ac.uk \nUniversity of Glasgow Glasgow\nScotland, United Kingdom\n\nCraig Macdonald \nUniversity of Glasgow Glasgow\nScotland, United Kingdom\n\nAn MLP-based Algorithm for Efficient Contrastive Graph Recommendations\n\nProceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22)\nthe 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22)Madrid, Spain; New York, NY, USAACM62022. July 11-15, 202210.1145/3477495.3531874KEYWORDS\nGraph-based recommender systems (GBRSs) have achieved promising performance by incorporating the user-item bipartite graph using the Graph Neural Network (GNN). Among GBRSs, the information from each user and item's multi-hop neighbours is effectively conveyed between nodes through neighbourhood aggregation and message passing. Although effective, existing neighbourhood information aggregation and passing functions are usually computationally expensive. Motivated by the emerging contrastive learning technique, we design a simple neighbourhood construction method in conjunction with the contrastive objective function to simulate the neighbourhood information processing of GNN. In addition, we propose a simple algorithm based on Multilayer Perceptron (MLP) for learning users and items' representations with extra non-linearity while lowering computational burden compared with multi-layers GNNs. Our extensive empirical experiments on three public datasets demonstrate that our proposed model, i.e. MLP-CGRec, can reduce the GPU memory consumption and training time by up to 24.0% and 33.1%, respectively, without significantly degenerating the recommendation accuracy in comparison with competitive baselines.CCS CONCEPTS\u2022 Information systems \u2192 Collaborative filtering.\n\nINTRODUCTION\n\nRecommender systems are designed to efficiently and effectively serve items of interest to users from a large amount of available options. Recently, recommender systems based on graph neural Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR '22, July 11-15, 2022 networks have attracted increasing attention in the community, and state-of-the-art recommendation performance has been achieved by such models including LightGCN [8] and UltraGCN [22]. The advantages of applying a GNN, especially multi-layer or heterogeneous GNNs, for the recommendation task lie in two pivotal functions, namely neighbourhood aggregation and message passing. By applying a neighbourhood aggregation function, the interactive information between users and items can be captured in their representations through message passing over the edges of a user-item bipartite graph. Besides, stacking multiple layers of GNNs can help recommender systems pass message over multi-hop neighbours.\n\nHowever, the neighbourhood aggregation and message passing of the existing graph-based recommender systems (GBRSs) heavily rely on the pre-computed adjacency matrix A of the user-item bipartite graph, which is time-and memory-consuming to compute. Although A is normally sparse, many epochs of iterative matrix multiplications and gradient updates over the concatenation of users and items' embeddings is still less efficient, especially when multiple stacked layers of GNNs are applied [8,38]. We argue that the inefficiency of the existing GBRSs is mainly caused by the matrix multiplications over unnecessary neighbours. Indeed, some frequently interacted items would be aggregated to most users, causing more time-and memory-consumption with trivial improvements. Given that the performance gained by the GBRSs is attributed to neighbourhood aggregation and message passing [6], the challenge here is to exploit a more efficient manner to perform similar functionalities without using the full neighbourhood graph convolution. In this paper, we propose a Multilayer Perceptron (MLP) based Contrastive Graph Recommender, abbreviated as MLP-CGRec, that uses an MLP-Mixer [31] to encode users and items' representations and conducts efficient contrastive learning.\n\nThe key idea of our approach is that, instead of aggregating and passing message over all the neighbours, we sample each user and item's neighbours to form each positive pair. To conduct the message passing function efficiently, we propose to sample multi-hop neighbours by raising the adjacency matrix A to the power of n, which is more efficient than the iterative matrix multiplications. In particular, the used MLP-Mixer in our MLP-CGRec (motivated by of MLP-Mixer in computer vision), is able to model complex user-item interactions and enhance our model's expressive power, ensuring the effectiveness.\n\nOur proposed MLP-CGRec offers multiple positive samples, which will lead to an unbalanced number of positive and negative items. Instead of sampling more random negative items, we use an approximate nearest neighbour search method to efficiently sample an equal amount of contrastive negative items to rebalance learning. To summarise, our contributions are threefold: (1) We incorporate a contrastive loss and a novel graph sampling method to simplify the neighbourhood aggregation and message passing of GBRSs; (2) We employ an efficient MLP-based learning algorithm to enhance the expressive power and recommendation accuracy; (3) We conduct extensive experiments on three public datasets, and show that our proposed MLP-CGRec can achieve high efficiency regarding both the memory and time consumption compared with state-of-the-art GBRSs without a significant loss of effectiveness.\n\n\nRELATED WORK\n\nRecently, GBRSs have achieved promising performance in not only the general recommendation [8,26,38,40] but also the sequential [24,36,42,44], social [18,34,41,45] and knowledgebased [7,35,37] recommendations. The most crucial functionalities of GBRSs are neighbourhood aggregation and message passing functions. Specifically, by aggregating information from graph neighbours, recommenders can learn more representative embeddings because neighbouring users are likely to share similar interests, and neighbouring items might share the same properties. Although effective, we notice that GBRSs have higher model complexity than traditional embedding-based recommenders, leading to higher training time and memory consumption. Therefore, building on NGCF [38], LightGCN [8] is proposed as a lightweight variant by dropping the redundant neural operations. Afterwards, GF-CF [30] is proposed by leveraging the low-pass graph filtering theorem to avoid the training process with back-propagation, which requires a large embedding dimension for competitive performance. Ultra-GCN [22] was proposed to speed up the training by avoiding the message passing function. However, it requires the graph representation learning on dual graphs, i.e. the user-item graph and item-item graph, which even aggravates the memory consumption. Another line of research focuses on graph contrastive learning, where graph augmentation techniques are used to create different views of nodes for the following contrastive objective function [19,19,24,25,39,40]. However, graph augmentations based on stochastic perturbations, including random walk and random node/edge dropout [19,40,47], are usually performed for every training epoch, which will increase the training time and memory consumption. Different from existing GBRSs, our MLP-CGRec uses a simple neighbourhood construction method and a contrastive objective function to learn information from neighbours. Furthermore, we use a straightforward MLP-Mixer [31] to encapsulate more non-linearity for learnt users and items' embeddings. Therefore, compared with existing GBRSs, our proposed MLP-CGRec is highly efficient and effective.\n\n\nMETHODOLOGY 3.1 Preliminaries\n\nWe consider a recommender system with a set of users U (| | = ) and a set of items I (| | = ). Let R \u2208 R \u00d7 be the useritem interaction matrix, where the content of the matrix R \u00d7 corresponds to implicit feedback [11,27]. We consider implicit feedback here because it is more abundant, therefore, R = 1 if the user u has interacted with the item i, otherwise R = 0. Following the BPR [27] framework for training, each triplet ( , + , \u2212 ) contains a user, a positive item and a randomly selected negative item.\n\n\nGraph Neighbourhood Construction\n\nFrom the user-item interaction matrix R, we can obtain its corresponding adjacency matrix A ( + )\u00d7( + ) . The elements of A indicate whether the pairs of users and items are adjacent or not in the interaction graph. In existing GBRSs, the multi-hop graph embeddings of users and items are usually computed by:\nE ( +1) = (D \u2212 1 2 AD \u2212 1 2 )E ( )(1)\nwhere E ( ) containing embeddings of all users and items at l-th layer of the GNN, and D is the diagonal degree matrix of A.\n\nStarting from the initial embeddings E (0) , we follow Equation (1) to compute \u22121 times to obtain the -hop embeddings. Although the adjacency matrix and the diagonal degree matrix are both sparse, the users and items' embeddings are however dense and the whole process not only involves the matrix multiplication but also the iterative gradient update for the GNNs at each training epoch. This is why existing GBRSs have a relatively unsatisfactory training efficiency. To avoid this costly operation, we derive how to use the adjacency matrix to explore the -hop neighbours by raising A to the power of below with an induction process:\nLemma 3.1. The ( , ) \u210e entry ( ) of A ,\nwhere A is the adjacency matrix of R, counts the number of walks of length having start and end nodes i and j respectively.\n\nProof. Base case: When = 1, A = A, and there is walk between node and if and only if =1, thus the result holds. Induction step: Assume the proposition holds for = and consider the case when = + 1, i.e. the matrix A +1 = A A. From the induction hypothesis, the value of ( , ) of the matrix A is the count of walks of length n from to . Now, the number of walks of length + 1 between node and node equals the number of walks of length from node to each node , which is adjacent to node . Therefore, the number of walks of length + 1 from node to node , i.e. the ( , ) \u210e entry A +1 is the non-zero entries of the column of A, which corresponds exactly to the first neighbours of . Thus the result holds for = + 1 as well. Conclusion: By the principle of induction, Lemma 3.1 is true for all \u2208 Z + . \u25a1 From the induction above, we can draw the conclusion that the -hop neighbours of R can be obtained by raising A to the power of . For example, we can refer to the -th row of the matrix A 2 to find user 's 2-hop neighbours. Therefore, by pre-defining how many neighbourhoods we aim to incorporate, we can pre-compute the corresponding graph neighbourhood matrices. For the most commonly adopted case in GBRSs, where 3-hop neighbours are included, we can pre-compute A 2 and A 3 of R for the subsequent sampling. With the graph neighbourhood construction, we obtain additional positive samples but without a balanced number of negative samples, which might lead to the over-repelling of some negative samples from other data points [2]. Therefore, in the next section, we describe how to use the contrastive negative sampling approach to select negative samples to balance the number of positive and negative samples.\n\n\nContrastive Negative Sampling\n\nGiven that each training triplet ( , + , \u2212 ) is extended to a training instance with multiple positive samples, we need to obtain more negative samples to reach a balance. Similar to how we get \u2212 , the most straightforward way is to randomly sample more negative items. However, inspired by the recent work of contrastive negative sampling [29,43], we propose to sample negative items based on a similarity function instead of sampling from random ones.\n\nIn the existing work, contrastive negative items are usually defined as those generated negative items obtained from the positive items using the data augmentation method [13,40]. The motivation of this sampling method is to obtain hard negative items which can be used to enhance the model's discriminative power. Although effective, generating contrastive negative items can pose challenges regarding the training and memory efficiencies. Since both the augmented and original graphs are created, stored and processed at every epoch, the time consumption will increase and the memory consumption will experience a surge. Besides, there is no theoretical analysis of why those data augmentation techniques, including the random edge/node dropouts, can enhance the overall accuracy [46]. Therefore, we propose to re-sample negative items from existing items, which avoids the redundant data augmentation step.\n\nWe use the cosine similarity [3,29] as the distance metric to search for contrastive negative items from each user's pool of uninteracted items. Specifically, we select those negative items \u2212 \u2032 that have lower cosine similarity towards the target user .\n\u2212 \u2032 \u2208 top-k \u2212 cos(e , E \u2212 )(2)\nwhere e is the embedding of the target user and E \u2212 represents all embeddings of this user's negative item.\n\nTo further increase the training efficiency, we adopt the fast neighbour search library, Faiss [14], to reduce the search time. Given the number of users and items in used datasets, we follow the advice in [14] to use the flat indexes and the brute-force search 1 to avoid accuracy loss. In particular, we select those negative items with lower similarity scores to avoid the false-negative items. As the recommendation accuracy increases along the model training, we can become more confident that target users are unlikely to prefer items with lower similarity scores, which will benefit the subsequent contrastive training.\n\n\nMLP-Mixer\n\nAlthough the graph neighbourhood construction and contrastive negative sampling are efficient, the model's expressive power is limited without a nonlinear activation. Recently, some advanced variants of Multilayer Perceptron (MLP) [17,31,32] have been proposed for more efficient deep model training. Inspired by their high efficiency and competitive accuracy on the image classification and NLP tasks, we propose to adopt MLP-Mixer to enhance our model's expressive power without a high computational cost. Our MLP module is defined as:\nE +1 = E + W 2 W 1 LayerNorm(E )(3)\nwhere E +1 contains embeddings for all users and items at the + 1 epoch; (\u00b7) is the GELU [10] activation; W 1 and W 2 are trainable weight matrices; and LayerNorm(\u00b7) denotes the layer normalisation [1], which is used to enhance the training stability.  (3), we use a self-addition loop i.e. adding the original E to E +1 , which is inspired by the tying parameter technique in MLP-Mixer [31]. The self-addition loop can help the model preserve the information from the previous epoch and avoid overfitting. To justify our choice, we also implement a variant without the selfaddition loop, which is identical to the MLP architecture used by the Graph-MLP model. We term this variant as plain MLP and we will compare our model to it in an ablation study.\n\n\nContrastive Training\n\nContrastive learning aims to encourage similar pairs to stay close to each other while dissimilar ones are far apart in the latent space [4,5]. In the contrastive recommendation scenario [39,47], we target learning representations for users and items, where interacted users and items stay closer in the learnt space. Inspired by the performance of InfoNCE loss, we construct our objective function as follows:\nL = \u2211\ufe01 \u2212log s (e , e + ) + 2 s (e , e + ) s (e , e + ) + s (e , e \u2212 ) + 2 s (e , e \u2212 )(4)\nwhere s (\u00b7) = cos(\u00b7) ; + , + , \u2212 and \u2212 denote a positive item, a -hop neighbour, a random negative item and a contrastive negative item of user , respectively; determines how many hops of neighbours to incorporate.\n\nWith Equation (4), we aim to encourage users to stay closer with their positive items and multi-hop neighbours while maximising the distance between users with their random and contrastive negative items. To predict each user's preferred items, we use the dot product between the embedding of each user and embeddings of all items, where more preferable items will receive higher scores.\n\n\nDATASETS AND EXPERIMENTAL SETUP\n\nThree public datasets, i.e. MovieLens-1M 2 , Yelp 3 and Amazonelectronics 4 , are used to evaluate our proposed MLP-CGRec model. In particular, MovieLens-1M is a dataset containing interactions between users and movies; Yelp is a venue check-ins dataset; and Amazon-electronics is a subset of the Amazon review dataset. For the rest of the paper, we respectively denote 'MovieLens' and 'Amazon' as 'MovieLens-1M' and 'Amazon-electronics'. Table 1 provides the statistics of the three used datasets. In the following, we aim to answer the following research questions: RQ1. Can MLP-CGRec achieve higher efficiency compared with the existing GBRS without significantly degrading its recommendation effectiveness? RQ2. What is the impact of these additional samples? RQ3. What is the impact of the MLP-based learning method? To answer RQ1, we compare our MLP-CGRec model with the following baselines: BPRMF [27], NeuMF [9], NGCF [38], Light-GCN [8], UltraGCN [22], MixGCF [13] and SGL [40]. Since efficiency and effectiveness are both critical in our study, we compare our MLP-CGRec with all baselines in terms of Normalised Discounted Cumulative Gain@10 (NDCG), Hit Ratio@10 (HR), max memory consumption, average epoch time and total training time, where the max memory consumption is monitored by Tensorboard. Following a common setup, we use a leave-one-out evaluation strategy to split the interactions of each dataset into training, validation and testing sets. However, different from prior works [9,28] that only use one oracle testing set per dataset with the sampled negative items, we construct 10 different testing sets with different sampled negative items for each dataset using different random seeds, in order to reduce the evaluation bias on some specific testing negatives [15]. Hence, the reported performance of each run is based on the average of the 10 testing sets. For a fair comparison, we conduct all experiments on the same machine with a GeForce RTX 2080Ti GPU. For significant testing, we apply a two one-sided of equivalence test (TOST), with \u0394AP=0.05 [16,20,21,23]. The purpose of the TOST test is to examine if MLP-CGRec is significantly equivalent to a baseline with the acceptable range of inequality being \u00b15%. We define success as outperforming a baseline regarding accuracy and efficiency or outperforming a baseline regarding efficiency but significantly equivalent to it regarding accuracy.\n\nTo answer RQ2, we compare the following variants of MLP-CGRec: (i) 2-hop neighbours with contrastive negative items and (ii) 3-hop neighbours with contrastive negative items. Hence, we can clearly examine the effect of each type of neighbours. Recall that contrastive negative items are sampled as complements only when multi-hop neighbours are incorporated so we can neglect the condition when only contrastive negative items are sampled. To answer RQ3, we use an ablation study to examine the effectiveness of the proposed method when: (i) the MLP module is not applied; (ii) a plain MLP is applied; (iii) MLP-mixer is applied.\n\nThe latent dimension and batch size are fixed to 64 and 1000, respectively, for all models. For each dataset, we use 20% of the interactions as a test set; of the remaining, we use 10% as a validation set, and the remainder for training. For the trainable matrices W 1 and W 2 used in MLP-CGRec, we closely follow the implementation details in [31] and set W 1 and W 2 to 32, which is half of the input latent dimension. For the top\u2212k function, we empirically set k to 100 according to our early stage experiments. To tune all hyper-parameters, we apply a grid search, where the learning rate is tuned in 10 \u22122 , 10 \u22123 , 10 \u22124 ; and the 2 normalisation in 10 \u22121 , 10 \u22122 , ..., 10 \u22125 . The node dropout technique is adopted in the NGCF, SGL and LightGCN models, and the ratios vary amongst {0.3, 0.4, ..., 0.8} as suggested in [33]. We use 3-hop neighbours in MLP-CGRec following other GBRSs. Table 2 reports the overall performances of our MLP-CGRec model and all other baselines. The results show that MLP-CGRec achieves competitive performance on all used datasets. On MovieLens, although LightGCN and SGL slightly outperform our MLP-CGRec, both models do not surpass MLP-CGRec by a significant difference according to a TOST test. More importantly, our model generally performs better on larger datasets than on smaller datasets. For example, MLP-CGRec achieves the second-best and the best on the larger Yelp and Amazon datasets regarding NDCG@10, respectively. This observation is consistent with the findings in [12,31], where both Graph-MLP and MLP-Mixer models only outperform state-of-the-art models on larger datasets for both node and image classification tasks. We notice that SGL and UltraGCN do not always outperform LightGCN as reported in [22] and [40]. This is due to the difference in experimental setup where we additionally use 10 different testing sets to reduce the evaluation bias. Therefore, our results further demonstrate the promising generalisability of a simple MLP-based learning architecture, whose scalability is better than complicated networks. Furthermore, our proposed MLP-CGRec model consistently achieves the best efficiency among all neural recommenders regarding GPU memory consumption and training time. We owe this high efficiency of MLP-CGRec to the simple design of the MLP module and the neighbourhood construction, which can be accomplished quickly using the sparse matrix multiplication. Therefore, we conclude that our MLP-CGRec can achieve competitive recommendation effectiveness with a higher efficiency compared with existing GBRSs. Figure 1 plots the NDCG@10 performances of all different variants of MLP-CGRec on all used datasets. In order to answer RQ2, we compare the variants of MLP-CGRec without using encoders over different hops of neighbours (green bars). Recall that a user's 1-hop, 2-hop and 3-hop neighbours are items, users, and items, respectively. Here, 1-hop neighbours are neglected because they are already included in the interaction graph neglected. By comparing the performances of variants with 2-hop and 3-hop neighbours, we find that the 3-hop neighbours bring more gains over the 2-hop neighbours, which means that users sharing one interacted item may not necessarily share the same overall interests. This explains why the 3-hop neighbourhood aggregation becomes the most common setup of the GBRSs. In answer to RQ3, the variant using Mixer constantly outperforms the one with a plain MLP and the plain MLP surpasses the one with no MLP on all datasets. This observation justifies our choice of incorporating the MLP architecture inspired by the MLP-Mixer as our representation learning module. Lastly, none of the variants can outperform MLP-CGRec, which means the integration of all proposed modules can achieve the best performance.\n\n\nRESULTS\n\n\nCONCLUSIONS\n\nWe propose MLP-CGRec, an MLP-based recommender that uses a neighbourhood construction method and a contrastive objective to replace the classic neighbourhood aggregation and message passing to achieve a competitive recommendation accuracy with an up to 33.7% running time reduction. Our proposed MLP-CGRec model has been demonstrated to achieve the best efficiency and comparable effectiveness compared with state-of-the-art graph-based and contrastive baselines on three public datasets. Furthermore, our ablation study reveals the effects of different proposed modules.\n\nFigure 1 :\n1Comparison between different variants of MLP-CGRec, where the green bars are variants with multiple neighbours, orange bars are variants with different MLPs and red bar is the final MLP-CGRec model.\n\n\n, Madrid, Spain \u00a9 2022 Association for Computing Machinery. ACM ISBN 978-1-4503-8732-3/22/07. . . $15.00 https://doi.org/10.1145/3477495.3531874\n\nTable 1 :\n1Statistics of the datasets.MovieLens Yelp \nAmazon \n\nUsers \n6,038 \n19,539 \n65,387 \nItems \n3,533 \n21,266 \n38,776 \nInteractions 575,281 \n450,884 \n739,380 \nDensity(%) \n2.697 \n0.108 \n0.029 \n\nIn Equation \n\nTable 2 :\n2Experimental results of MLP-CGRec and other baselines on the three used datasets w.r.t. HR@10, NDCG@10, max memory consumption (gigabytes), average epoch time (seconds) and total training time (minutes). The best accuracy is highlighted in bold and the second best result is highlighted with underline. * denotes a significant difference compared to the result of MLP-CGRec using the two one-sided test with p<0.05.MovieLens \nYelp \nAmazon \nNDCG HR \nMem Epoch Total NDCG HR \nMem Epoch Total NDCG HR \nMem Epoch Total \n\nBPRMF \n0.2031  *  0.1274  *  2.91 \n45.8 \n61.2 \n0.1221  *  0.1520  *  5.42 \n84.5 \n96.7 \n0.0745  *  0.1138  *  5.78 \n95.1 \n147.6 \nNeuMF \n0.2114  *  0.1398  *  3.88 \n58.7 \n100.5 0.1330  *  0.1598  *  6.07 \n98.9 \n123.3 0.1093  *  0.1678  *  6.31 \n132.2 188.5 \nNGCF \n0.2517  *  0.1665  *  4.13 \n65.7 \n161.0 0.1420  *  0.1736  *  7.64 \n112.4 168.6 0.1297  *  0.1927  *  7.91 \n168.9 241.4 \nLightGCN \n0.3303 0.2329 3.96 \n59.8 \n118.5 0.2233 0.2597 6.43 \n102.3 136.6 0.1519 0.2177 7.01 \n149.2 206.0 \nUltraGCN \n0.2646  *  0.1862  *  3.98 \n61.3 \n147.5 0.2111 0.2619 6.70 \n108.9 166.8 0.1302  *  0.2021  *  7.11 \n145.2 208.2 \nMixGCF \n0.2737  *  0.1989  *  4.38 \n60.3 \n132.2 0.2003  *  0.2378  *  6.91 \n107.8 158.4 0.1403  *  0.2107 \n8.03 \n143.9 211.4 \nSGL \n0.3116 0.2260 4.08 \n69.3 \n135.6 0.1673  *  0.2098  *  6.61 \n101.9 145.8 0.1581 0.2201 6.58 \n151.5 184.8 \nMLP-CGRec \n0.3004 0.2176 3.01 \n48.2 \n78.5 \n0.2164 0.2501 5.71 \n91.3 \n121.2 0.1593 0.2190 5.90 \n101.3 152.2 \nDiff (%) \n-6.02 \n-6.57 \n-24.0 -19.4 -33.7 -3.09 \n-4.51 \n-11.2 -10.1 -12.7 +4.87 \n-0.50 \n-10.3 -33.1 -17.6 \n\n\nUsing flat indexes and the brute-force search is mathematically the same with the commonly used exact search. However, the overall search process is accelerated by optimising the General Matrix Multiply (GEMM) routines in the cuBLAS library for the GPU acceleration.\nhttps://grouplens.org/datasets/movielens/ 3 https://www.yelp.com/dataset 4 https://jmcauley.ucsd.edu/data/amazon/\n\nLayer normalization. Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E Hinton, Proc. of Deep Learning Symposium. of Deep Learning SymposiumJimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normaliza- tion. In Proc. of Deep Learning Symposium.\n\nLarge-margin contrastive learning with distance polarization regularizer. Shuo Chen, Gang Niu, Chen Gong, Jun Li, Jian Yang, Masashi Sugiyama, Proc. of ICML. of ICMLShuo Chen, Gang Niu, Chen Gong, Jun Li, Jian Yang, and Masashi Sugiyama. 2021. Large-margin contrastive learning with distance polarization regularizer. In Proc. of ICML.\n\nA simple framework for contrastive learning of visual representations. Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, Proc. of ICML. of ICMLTing Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A simple framework for contrastive learning of visual representations. In Proc. of ICML.\n\nBig self-supervised models are strong semi-supervised learners. Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, Geoffrey Hinton, Proc. of NeurIPS. of NeurIPSTing Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey Hinton. 2020. Big self-supervised models are strong semi-supervised learners. In Proc. of NeurIPS.\n\nLearning a similarity metric discriminatively, with application to face verification. Sumit Chopra, Raia Hadsell, Yann Lecun, Proc. of CVPR. of CVPRSumit Chopra, Raia Hadsell, and Yann LeCun. 2005. Learning a similarity metric discriminatively, with application to face verification. In Proc. of CVPR.\n\nGraph neural networks for recommender systems: Challenges, methods, and directions. Chen Gao, Yu Zheng, Nian Li, Yinfeng Li, Yingrong Qin, Jinghua Piao, Yuhan Quan, Jianxin Chang, Depeng Jin, Xiangnan He, ACM Transactions on Information Systems. 1Chen Gao, Yu Zheng, Nian Li, Yinfeng Li, Yingrong Qin, Jinghua Piao, Yuhan Quan, Jianxin Chang, Depeng Jin, Xiangnan He, et al. 2021. Graph neural net- works for recommender systems: Challenges, methods, and directions. ACM Transactions on Information Systems 1 (2021).\n\nStructured multi-modal feature embedding and alignment for image-sentence retrieval. Xuri Ge, Fuhai Chen, M Joemon, Zhilong Jose, Zhongqin Ji, Xiao Wu, Liu, Proc. of SIGMM. of SIGMMXuri Ge, Fuhai Chen, Joemon M Jose, Zhilong Ji, Zhongqin Wu, and Xiao Liu. 2021. Structured multi-modal feature embedding and alignment for image-sentence retrieval. In Proc. of SIGMM.\n\nLightGCN: Simplifying and powering graph convolution network for recommendation. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, Meng Wang, Proc. of SIGIR. of SIGIRXiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020. LightGCN: Simplifying and powering graph convolution network for recommendation. In Proc. of SIGIR.\n\nNeural collaborative filtering. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Proc. of WWW. of WWWXiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proc. of WWW.\n\nDan Hendrycks, Kevin Gimpel, arXiv:1606.08415Gaussian error linear units (gelus). arXiv preprintDan Hendrycks and Kevin Gimpel. 2016. Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415 (2016).\n\nCollaborative filtering for implicit feedback datasets. Y Hu, Y Koren, C Volinsky, Proc. of ICDM. of ICDMY. Hu, Y. Koren, and C. Volinsky. 2008. Collaborative filtering for implicit feedback datasets. In Proc. of ICDM.\n\nGraph-MLP: node classification without message passing in graph. Yang Hu, Haoxuan You, Zhecan Wang, Zhicheng Wang, Erjin Zhou, Yue Gao, arXiv:2106.04051arXiv preprintYang Hu, Haoxuan You, Zhecan Wang, Zhicheng Wang, Erjin Zhou, and Yue Gao. 2021. Graph-MLP: node classification without message passing in graph. arXiv preprint arXiv:2106.04051 (2021).\n\nMixGCF: An improved training method for graph neural network-based recommender systems. Tinglin Huang, Yuxiao Dong, Ming Ding, Zhen Yang, Wenzheng Feng, Xinyu Wang, Jie Tang, Proc. of SIGKDD. of SIGKDDTinglin Huang, Yuxiao Dong, Ming Ding, Zhen Yang, Wenzheng Feng, Xinyu Wang, and Jie Tang. 2021. MixGCF: An improved training method for graph neural network-based recommender systems. In Proc. of SIGKDD.\n\nBillion-scale similarity search with gpus. Jeff Johnson, Matthijs Douze, Herv\u00e9 J\u00e9gou, IEEE Transactions on Big Data. 7Jeff Johnson, Matthijs Douze, and Herv\u00e9 J\u00e9gou. 2019. Billion-scale similarity search with gpus. IEEE Transactions on Big Data 7 (2019).\n\nOn sampled metrics for item recommendation. Walid Krichene, Steffen Rendle, Proc. of SIGKDD. of SIGKDDWalid Krichene and Steffen Rendle. 2020. On sampled metrics for item recom- mendation. In Proc. of SIGKDD.\n\nA comparative analysis of human and automatic query variants. Binsheng Liu, Nick Craswell, Xiaolu Lu, Oren Kurland, J Shane Culpepper, Proc. of SIGIR. of SIGIRBinsheng Liu, Nick Craswell, Xiaolu Lu, Oren Kurland, and J Shane Culpepper. 2019. A comparative analysis of human and automatic query variants. In Proc. of SIGIR.\n\nPay attention to MLPs. Hanxiao Liu, Zihang Dai, R David, Quoc V So, Le, Proc. of NeurIPS. of NeurIPSHanxiao Liu, Zihang Dai, David R So, and Quoc V Le. 2021. Pay attention to MLPs. In Proc. of NeurIPS.\n\nA heterogeneous graph neural model for cold-start recommendation. Siwei Liu, Iadh Ounis, Craig Macdonald, Zaiqiao Meng, Proc. of SIGIR. of SIGIRSiwei Liu, Iadh Ounis, Craig Macdonald, and Zaiqiao Meng. 2020. A heteroge- neous graph neural model for cold-start recommendation. In Proc. of SIGIR.\n\nZhuang Liu, Yunpu Ma, arXiv:2101.01317Yuanxin Ouyang, and Zhang Xiong. 2021. Contrastive learning for recommender system. arXiv preprintZhuang Liu, Yunpu Ma, Yuanxin Ouyang, and Zhang Xiong. 2021. Contrastive learning for recommender system. arXiv preprint arXiv:2101.01317 (2021).\n\nEfficient document re-ranking for transformers by precomputing term representations. Sean Macavaney, Maria Franco, Raffaele Nardini, Nicola Perego, Nazli Tonellotto, Ophir Goharian, Frieder, Proc. of SIGIR. of SIGIRSean MacAvaney, Franco Maria Nardini, Raffaele Perego, Nicola Tonellotto, Nazli Goharian, and Ophir Frieder. 2020. Efficient document re-ranking for transform- ers by precomputing term representations. In Proc. of SIGIR.\n\nQuery driven algorithm selection in early stage retrieval. Joel Mackenzie, Shane Culpepper, Roi Blanco, Matt Crane, L A Charles, Jimmy Clarke, Lin, Proc. of WSDM. of WSDMJoel Mackenzie, J Shane Culpepper, Roi Blanco, Matt Crane, Charles LA Clarke, and Jimmy Lin. 2018. Query driven algorithm selection in early stage retrieval. In Proc. of WSDM.\n\nUltraGCN: Ultra simplification of graph convolutional networks for recommendation. Kelong Mao, Jieming Zhu, Xi Xiao, Biao Lu, Zhaowei Wang, Xiuqiang He, Proc. of CIKM. of CIKMKelong Mao, Jieming Zhu, Xi Xiao, Biao Lu, Zhaowei Wang, and Xiuqiang He. 2021. UltraGCN: Ultra simplification of graph convolutional networks for recom- mendation. In Proc. of CIKM.\n\nDynamic shard cutoff prediction for selective search. Keyang Hafeezul Rahman Mohammad, Jamie Xu, J Shane Callan, Culpepper, Proc. of SIGIR. of SIGIRHafeezul Rahman Mohammad, Keyang Xu, Jamie Callan, and J Shane Culpepper. 2018. Dynamic shard cutoff prediction for selective search. In Proc. of SIGIR.\n\nMax-Utility based arm selection strategy for sequential query recommendations. Christos Shameem Puthiya Parambath, Roderick Anagnostopoulos, Sean Murray-Smith, Macavaney, Proc. of ACML. of ACMLShameem Puthiya Parambath, Christos Anagnostopoulos, Roderick Murray- Smith, Sean MacAvaney, et al. 2021. Max-Utility based arm selection strategy for sequential query recommendations. In Proc. of ACML.\n\nSimple and effective neural-free soft-cluster embeddings for item cold-start recommendations. Puthiya Shameem, Sanjay Parambath, Chawla, Data Mining and Knowledge Discovery. 345Shameem A Puthiya Parambath and Sanjay Chawla. 2020. Simple and effective neural-free soft-cluster embeddings for item cold-start recommendations. Data Mining and Knowledge Discovery 34, 5 (2020).\n\nA coverage-based approach to recommendation diversity on similarity graph. Nicolas Shameem A Puthiya Parambath, Yves Usunier, Grandvalet, Proc. of RecSys. of RecSysShameem A Puthiya Parambath, Nicolas Usunier, and Yves Grandvalet. 2016. A coverage-based approach to recommendation diversity on similarity graph. In Proc. of RecSys. 15-22.\n\nBPR: Bayesian personalized ranking from implicit feedback. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, Proc. of UAI. of UAISteffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In Proc. of UAI.\n\nNeural collaborative filtering vs. matrix factorization revisited. Walid Steffen Rendle, Li Krichene, John Zhang, Anderson, Proc. of RecSys. of RecSysSteffen Rendle, Walid Krichene, Li Zhang, and John Anderson. 2020. Neural collaborative filtering vs. matrix factorization revisited. In Proc. of RecSys.\n\nContrastive learning with hard negative samples. Joshua Robinson, Ching-Yao Chuang, Suvrit Sra, Stefanie Jegelka, Proc. of ICLR. of ICLRJoshua Robinson, Ching-Yao Chuang, Suvrit Sra, and Stefanie Jegelka. 2020. Contrastive learning with hard negative samples. In Proc. of ICLR.\n\nHow powerful is graph convolution for recommendation. Yifei Shen, Yongji Wu, Yao Zhang, Caihua Shan, Proc. of CIKM. Zhang, B Khaled Letaief, and Dongsheng Li. 2021of CIKMYifei Shen, Yongji Wu, Yao Zhang, Caihua Shan, Jun Zhang, B Khaled Letaief, and Dongsheng Li. 2021. How powerful is graph convolution for recommendation?. In Proc. of CIKM.\n\nMlp-mixer: An all-mlp architecture for vision. Ilya Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Thomas Unterthiner, Jessica Yung, Daniel Keysers, Jakob Uszkoreit, Mario Lucic, Proc. of NeurIPS. of NeurIPSIlya Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Thomas Unterthiner, Jessica Yung, Daniel Keysers, Jakob Uszkoreit, Mario Lucic, et al. 2021. Mlp-mixer: An all-mlp architecture for vision. In Proc. of NeurIPS.\n\nHugo Touvron, Piotr Bojanowski, Mathilde Caron, Matthieu Cord, Alaaeldin El-Nouby, Edouard Grave, Gautier Izacard, Armand Joulin, Gabriel Synnaeve, Jakob Verbeek, arXiv:2105.03404Resmlp: Feedforward networks for image classification with data-efficient training. arXiv preprintHugo Touvron, Piotr Bojanowski, Mathilde Caron, Matthieu Cord, Alaaeldin El-Nouby, Edouard Grave, Gautier Izacard, Armand Joulin, Gabriel Synnaeve, Jakob Verbeek, et al. 2021. Resmlp: Feedforward networks for image classification with data-efficient training. arXiv preprint arXiv:2105.03404 (2021).\n\nGraph convolutional matrix completion. Rianne Van Den, Thomas N Berg, Max Kipf, Welling, Proc. of KDD. of KDDRianne van den Berg, Thomas N Kipf, and Max Welling. 2018. Graph convolu- tional matrix completion. In Proc. of KDD.\n\nHeterogeneous edge embedding for friend recommendation. Janu Verma, Srishti Gupta, Debdoot Mukherjee, Tanmoy Chakraborty, Proc. of ECIR. of ECIRJanu Verma, Srishti Gupta, Debdoot Mukherjee, and Tanmoy Chakraborty. 2019. Heterogeneous edge embedding for friend recommendation. In Proc. of ECIR.\n\nRipplenet: Propagating user preferences on the knowledge graph for recommender systems. Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, Minyi Guo, Proc. of CIKM. of CIKMHongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, and Minyi Guo. 2018. Ripplenet: Propagating user preferences on the knowledge graph for recommender systems. In Proc. of CIKM.\n\nBeyond clicks: Modeling multi-relational item graph for session-based target behavior prediction. Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, Hongyuan Zha, Proc. of WWW. of WWWWen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, and Hongyuan Zha. 2020. Beyond clicks: Modeling multi-relational item graph for session-based target behavior prediction. In Proc. of WWW.\n\nKgat: Knowledge graph attention network for recommendation. Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, Tat-Seng Chua, Proc. of SIGKDD. of SIGKDDXiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng Chua. 2019. Kgat: Knowledge graph attention network for recommendation. In Proc. of SIGKDD.\n\nXiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural graph collaborative filtering. SIGIRXiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural graph collaborative filtering. In SIGIR.\n\nNoise contrastive estimation for one-class collaborative filtering. Ga Wu, Maksims Volkovs, Chee Loong Soon, Scott Sanner, Himanshu Rai, Proc. of SIGIR. of SIGIRGa Wu, Maksims Volkovs, Chee Loong Soon, Scott Sanner, and Himanshu Rai. 2019. Noise contrastive estimation for one-class collaborative filtering. In Proc. of SIGIR.\n\nSelf-supervised graph learning for recommendation. Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, Xing Xie, Proc. of SIGIR. of SIGIRJiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, and Xing Xie. 2021. Self-supervised graph learning for recommendation. In Proc. of SIGIR.\n\nDiffnet++: A neural influence and interest diffusion network for social recommendation. Le Wu, Junwei Li, Peijie Sun, Richang Hong, Yong Ge, Meng Wang, IEEE Transactions on Knowledge and Data Engineering. Le Wu, Junwei Li, Peijie Sun, Richang Hong, Yong Ge, and Meng Wang. 2020. Diffnet++: A neural influence and interest diffusion network for social recom- mendation. IEEE Transactions on Knowledge and Data Engineering (2020).\n\nSession-based recommendation with graph neural networks. Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, Tieniu Tan, Proc. of AAAI. of AAAIShu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In Proc. of AAAI.\n\nApproximate nearest neighbor negative contrastive learning for dense text retrieval. Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, Arnold Overwijk, Proc. of ICLR. of ICLRLee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed, and Arnold Overwijk. 2021. Approximate nearest neighbor negative contrastive learning for dense text retrieval. In Proc. of ICLR.\n\nGraph contextualized selfattention network for session-based recommendation. Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, S Victor, Jiajie Sheng, Xu, Fuzhen Zhuang, Junhua Fang, and Xiaofang Zhou. Proc. of IJCAIChengfeng Xu, Pengpeng Zhao, Yanchi Liu, Victor S Sheng, Jiajie Xu, Fuzhen Zhuang, Junhua Fang, and Xiaofang Zhou. 2019. Graph contextualized self- attention network for session-based recommendation.. In Proc. of IJCAI.\n\nXin Xia, Xiangliang Zhang, and Nguyen Quoc Viet Hung. 2021. Socially-aware self-supervised tri-training for recommendation. Junliang Yu, Hongzhi Yin, Min Gao, Proc. of SIGKDD. of SIGKDDJunliang Yu, Hongzhi Yin, Min Gao, Xin Xia, Xiangliang Zhang, and Nguyen Quoc Viet Hung. 2021. Socially-aware self-supervised tri-training for recommendation. In Proc. of SIGKDD.\n\nLizhen Cui, and Nguyen Quoc Viet Hung. 2022. Are graph augmentations necessary? simple graph contrastive learning for recommendation. Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Proc. of SIGIR. of SIGIRJunliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Nguyen Quoc Viet Hung. 2022. Are graph augmentations necessary? simple graph contrastive learning for recommendation. In Proc. of SIGIR.\n\nContrastive learning for debiased candidate generation in large-scale recommender systems. Chang Zhou, Jianxin Ma, Jianwei Zhang, Jingren Zhou, Hongxia Yang, Proc. of SIGKDD. of SIGKDDChang Zhou, Jianxin Ma, Jianwei Zhang, Jingren Zhou, and Hongxia Yang. 2021. Contrastive learning for debiased candidate generation in large-scale recom- mender systems. In Proc. of SIGKDD.\n", "annotations": {"author": "[{\"end\":173,\"start\":112},{\"end\":276,\"start\":174},{\"end\":343,\"start\":277},{\"end\":436,\"start\":344},{\"end\":509,\"start\":437}]", "publisher": "[{\"end\":75,\"start\":72},{\"end\":849,\"start\":846}]", "author_last_name": "[{\"end\":121,\"start\":118},{\"end\":189,\"start\":180},{\"end\":286,\"start\":283},{\"end\":354,\"start\":349},{\"end\":452,\"start\":443}]", "author_first_name": "[{\"end\":117,\"start\":112},{\"end\":179,\"start\":174},{\"end\":282,\"start\":277},{\"end\":348,\"start\":344},{\"end\":442,\"start\":437}]", "author_affiliation": "[{\"end\":172,\"start\":123},{\"end\":275,\"start\":221},{\"end\":342,\"start\":288},{\"end\":435,\"start\":381},{\"end\":508,\"start\":454}]", "title": "[{\"end\":71,\"start\":1},{\"end\":580,\"start\":510}]", "venue": "[{\"end\":705,\"start\":582}]", "abstract": "[{\"end\":2183,\"start\":904}]", "bib_ref": "[{\"end\":2993,\"start\":2972},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3160,\"start\":3157},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3178,\"start\":3174},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4188,\"start\":4185},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":4191,\"start\":4188},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4579,\"start\":4576},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":4875,\"start\":4871},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6571,\"start\":6568},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6574,\"start\":6571},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":6577,\"start\":6574},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":6580,\"start\":6577},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6609,\"start\":6605},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":6612,\"start\":6609},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":6615,\"start\":6612},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":6618,\"start\":6615},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6631,\"start\":6627},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":6634,\"start\":6631},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":6637,\"start\":6634},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":6640,\"start\":6637},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6663,\"start\":6660},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":6666,\"start\":6663},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":6669,\"start\":6666},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":7235,\"start\":7231},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7249,\"start\":7246},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7354,\"start\":7350},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7557,\"start\":7553},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7998,\"start\":7994},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8001,\"start\":7998},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8004,\"start\":8001},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8007,\"start\":8004},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8010,\"start\":8007},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":8013,\"start\":8010},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8134,\"start\":8130},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":8137,\"start\":8134},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8140,\"start\":8137},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8472,\"start\":8468},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8895,\"start\":8891},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8898,\"start\":8895},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9066,\"start\":9062},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12031,\"start\":12028},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":12591,\"start\":12587},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":12594,\"start\":12591},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12877,\"start\":12873},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":12880,\"start\":12877},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":13488,\"start\":13484},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13645,\"start\":13642},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":13648,\"start\":13645},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":14106,\"start\":14102},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":14217,\"start\":14213},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":14882,\"start\":14878},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":14885,\"start\":14882},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14888,\"start\":14885},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15314,\"start\":15310},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":15422,\"start\":15419},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":15612,\"start\":15608},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":16138,\"start\":16135},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16140,\"start\":16138},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":16189,\"start\":16185},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":16192,\"start\":16189},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":18046,\"start\":18042},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18057,\"start\":18054},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":18068,\"start\":18064},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":18083,\"start\":18080},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":18098,\"start\":18094},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":18111,\"start\":18107},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":18124,\"start\":18120},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18641,\"start\":18638},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":18644,\"start\":18641},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":18929,\"start\":18925},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":19220,\"start\":19216},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":19223,\"start\":19220},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":19226,\"start\":19223},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":19229,\"start\":19226},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":20544,\"start\":20540},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":21026,\"start\":21022},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":21718,\"start\":21714},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21721,\"start\":21718},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21955,\"start\":21951},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":21964,\"start\":21960}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":24820,\"start\":24609},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":24967,\"start\":24821},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":25178,\"start\":24968},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":26773,\"start\":25179}]", "paragraph": "[{\"end\":3696,\"start\":2199},{\"end\":4963,\"start\":3698},{\"end\":5572,\"start\":4965},{\"end\":6460,\"start\":5574},{\"end\":8645,\"start\":6477},{\"end\":9187,\"start\":8679},{\"end\":9533,\"start\":9224},{\"end\":9696,\"start\":9572},{\"end\":10334,\"start\":9698},{\"end\":10498,\"start\":10375},{\"end\":12213,\"start\":10500},{\"end\":12700,\"start\":12247},{\"end\":13611,\"start\":12702},{\"end\":13866,\"start\":13613},{\"end\":14005,\"start\":13898},{\"end\":14633,\"start\":14007},{\"end\":15184,\"start\":14647},{\"end\":15973,\"start\":15221},{\"end\":16408,\"start\":15998},{\"end\":16713,\"start\":16499},{\"end\":17102,\"start\":16715},{\"end\":19563,\"start\":17138},{\"end\":20194,\"start\":19565},{\"end\":24011,\"start\":20196},{\"end\":24608,\"start\":24037}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9571,\"start\":9534},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10374,\"start\":10335},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13897,\"start\":13867},{\"attributes\":{\"id\":\"formula_3\"},\"end\":15220,\"start\":15185},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16498,\"start\":16409}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":17584,\"start\":17577},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":21095,\"start\":21088}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2197,\"start\":2185},{\"attributes\":{\"n\":\"2\"},\"end\":6475,\"start\":6463},{\"attributes\":{\"n\":\"3\"},\"end\":8677,\"start\":8648},{\"attributes\":{\"n\":\"3.2\"},\"end\":9222,\"start\":9190},{\"attributes\":{\"n\":\"3.3\"},\"end\":12245,\"start\":12216},{\"attributes\":{\"n\":\"3.4\"},\"end\":14645,\"start\":14636},{\"attributes\":{\"n\":\"3.5\"},\"end\":15996,\"start\":15976},{\"attributes\":{\"n\":\"4\"},\"end\":17136,\"start\":17105},{\"attributes\":{\"n\":\"5\"},\"end\":24021,\"start\":24014},{\"attributes\":{\"n\":\"6\"},\"end\":24035,\"start\":24024},{\"end\":24620,\"start\":24610},{\"end\":24978,\"start\":24969},{\"end\":25189,\"start\":25180}]", "table": "[{\"end\":25178,\"start\":25007},{\"end\":26773,\"start\":25606}]", "figure_caption": "[{\"end\":24820,\"start\":24622},{\"end\":24967,\"start\":24823},{\"end\":25007,\"start\":24980},{\"end\":25606,\"start\":25191}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22789,\"start\":22781}]", "bib_author_first_name": "[{\"end\":27182,\"start\":27177},{\"end\":27186,\"start\":27183},{\"end\":27196,\"start\":27191},{\"end\":27201,\"start\":27197},{\"end\":27217,\"start\":27209},{\"end\":27219,\"start\":27218},{\"end\":27488,\"start\":27484},{\"end\":27499,\"start\":27495},{\"end\":27509,\"start\":27505},{\"end\":27519,\"start\":27516},{\"end\":27528,\"start\":27524},{\"end\":27542,\"start\":27535},{\"end\":27822,\"start\":27818},{\"end\":27834,\"start\":27829},{\"end\":27854,\"start\":27846},{\"end\":27872,\"start\":27864},{\"end\":28134,\"start\":28130},{\"end\":28146,\"start\":28141},{\"end\":28163,\"start\":28158},{\"end\":28181,\"start\":28173},{\"end\":28199,\"start\":28191},{\"end\":28501,\"start\":28496},{\"end\":28514,\"start\":28510},{\"end\":28528,\"start\":28524},{\"end\":28801,\"start\":28797},{\"end\":28809,\"start\":28807},{\"end\":28821,\"start\":28817},{\"end\":28833,\"start\":28826},{\"end\":28846,\"start\":28838},{\"end\":28859,\"start\":28852},{\"end\":28871,\"start\":28866},{\"end\":28885,\"start\":28878},{\"end\":28899,\"start\":28893},{\"end\":28913,\"start\":28905},{\"end\":29320,\"start\":29316},{\"end\":29330,\"start\":29325},{\"end\":29338,\"start\":29337},{\"end\":29354,\"start\":29347},{\"end\":29369,\"start\":29361},{\"end\":29378,\"start\":29374},{\"end\":29687,\"start\":29679},{\"end\":29696,\"start\":29692},{\"end\":29708,\"start\":29703},{\"end\":29718,\"start\":29715},{\"end\":29731,\"start\":29723},{\"end\":29743,\"start\":29739},{\"end\":29996,\"start\":29988},{\"end\":30005,\"start\":30001},{\"end\":30019,\"start\":30012},{\"end\":30034,\"start\":30027},{\"end\":30043,\"start\":30040},{\"end\":30056,\"start\":30048},{\"end\":30221,\"start\":30218},{\"end\":30238,\"start\":30233},{\"end\":30487,\"start\":30486},{\"end\":30493,\"start\":30492},{\"end\":30502,\"start\":30501},{\"end\":30719,\"start\":30715},{\"end\":30731,\"start\":30724},{\"end\":30743,\"start\":30737},{\"end\":30758,\"start\":30750},{\"end\":30770,\"start\":30765},{\"end\":30780,\"start\":30777},{\"end\":31098,\"start\":31091},{\"end\":31112,\"start\":31106},{\"end\":31123,\"start\":31119},{\"end\":31134,\"start\":31130},{\"end\":31149,\"start\":31141},{\"end\":31161,\"start\":31156},{\"end\":31171,\"start\":31168},{\"end\":31457,\"start\":31453},{\"end\":31475,\"start\":31467},{\"end\":31488,\"start\":31483},{\"end\":31714,\"start\":31709},{\"end\":31732,\"start\":31725},{\"end\":31945,\"start\":31937},{\"end\":31955,\"start\":31951},{\"end\":31972,\"start\":31966},{\"end\":31981,\"start\":31977},{\"end\":31998,\"start\":31991},{\"end\":32229,\"start\":32222},{\"end\":32241,\"start\":32235},{\"end\":32248,\"start\":32247},{\"end\":32262,\"start\":32256},{\"end\":32473,\"start\":32468},{\"end\":32483,\"start\":32479},{\"end\":32496,\"start\":32491},{\"end\":32515,\"start\":32508},{\"end\":32704,\"start\":32698},{\"end\":32715,\"start\":32710},{\"end\":33070,\"start\":33066},{\"end\":33087,\"start\":33082},{\"end\":33104,\"start\":33096},{\"end\":33120,\"start\":33114},{\"end\":33134,\"start\":33129},{\"end\":33152,\"start\":33147},{\"end\":33481,\"start\":33477},{\"end\":33498,\"start\":33493},{\"end\":33513,\"start\":33510},{\"end\":33526,\"start\":33522},{\"end\":33535,\"start\":33534},{\"end\":33537,\"start\":33536},{\"end\":33552,\"start\":33547},{\"end\":33854,\"start\":33848},{\"end\":33867,\"start\":33860},{\"end\":33875,\"start\":33873},{\"end\":33886,\"start\":33882},{\"end\":33898,\"start\":33891},{\"end\":33913,\"start\":33905},{\"end\":34184,\"start\":34178},{\"end\":34216,\"start\":34211},{\"end\":34228,\"start\":34221},{\"end\":34513,\"start\":34505},{\"end\":34549,\"start\":34541},{\"end\":34571,\"start\":34567},{\"end\":34924,\"start\":34917},{\"end\":34940,\"start\":34934},{\"end\":35280,\"start\":35273},{\"end\":35314,\"start\":35310},{\"end\":35604,\"start\":35597},{\"end\":35622,\"start\":35613},{\"end\":35642,\"start\":35638},{\"end\":35656,\"start\":35652},{\"end\":35928,\"start\":35923},{\"end\":35947,\"start\":35945},{\"end\":35962,\"start\":35958},{\"end\":36216,\"start\":36210},{\"end\":36236,\"start\":36227},{\"end\":36251,\"start\":36245},{\"end\":36265,\"start\":36257},{\"end\":36499,\"start\":36494},{\"end\":36512,\"start\":36506},{\"end\":36520,\"start\":36517},{\"end\":36534,\"start\":36528},{\"end\":36835,\"start\":36831},{\"end\":36852,\"start\":36848},{\"end\":36871,\"start\":36862},{\"end\":36889,\"start\":36884},{\"end\":36904,\"start\":36897},{\"end\":36917,\"start\":36911},{\"end\":36938,\"start\":36931},{\"end\":36951,\"start\":36945},{\"end\":36966,\"start\":36961},{\"end\":36983,\"start\":36978},{\"end\":37265,\"start\":37261},{\"end\":37280,\"start\":37275},{\"end\":37301,\"start\":37293},{\"end\":37317,\"start\":37309},{\"end\":37333,\"start\":37324},{\"end\":37351,\"start\":37344},{\"end\":37366,\"start\":37359},{\"end\":37382,\"start\":37376},{\"end\":37398,\"start\":37391},{\"end\":37414,\"start\":37409},{\"end\":37884,\"start\":37878},{\"end\":37900,\"start\":37894},{\"end\":37902,\"start\":37901},{\"end\":37912,\"start\":37909},{\"end\":38126,\"start\":38122},{\"end\":38141,\"start\":38134},{\"end\":38156,\"start\":38149},{\"end\":38174,\"start\":38168},{\"end\":38456,\"start\":38449},{\"end\":38470,\"start\":38463},{\"end\":38484,\"start\":38478},{\"end\":38495,\"start\":38491},{\"end\":38508,\"start\":38502},{\"end\":38517,\"start\":38513},{\"end\":38528,\"start\":38523},{\"end\":38859,\"start\":38856},{\"end\":38869,\"start\":38866},{\"end\":38883,\"start\":38877},{\"end\":38891,\"start\":38889},{\"end\":38899,\"start\":38897},{\"end\":38911,\"start\":38907},{\"end\":38925,\"start\":38917},{\"end\":39217,\"start\":39212},{\"end\":39232,\"start\":39224},{\"end\":39242,\"start\":39237},{\"end\":39252,\"start\":39248},{\"end\":39266,\"start\":39258},{\"end\":39456,\"start\":39451},{\"end\":39471,\"start\":39463},{\"end\":39480,\"start\":39476},{\"end\":39757,\"start\":39755},{\"end\":39769,\"start\":39762},{\"end\":39783,\"start\":39779},{\"end\":39801,\"start\":39796},{\"end\":39818,\"start\":39810},{\"end\":40073,\"start\":40066},{\"end\":40083,\"start\":40078},{\"end\":40094,\"start\":40090},{\"end\":40109,\"start\":40101},{\"end\":40119,\"start\":40114},{\"end\":40133,\"start\":40126},{\"end\":40144,\"start\":40140},{\"end\":40429,\"start\":40427},{\"end\":40440,\"start\":40434},{\"end\":40451,\"start\":40445},{\"end\":40464,\"start\":40457},{\"end\":40475,\"start\":40471},{\"end\":40484,\"start\":40480},{\"end\":40829,\"start\":40826},{\"end\":40840,\"start\":40834},{\"end\":40854,\"start\":40847},{\"end\":40865,\"start\":40860},{\"end\":40876,\"start\":40872},{\"end\":40888,\"start\":40882},{\"end\":41158,\"start\":41155},{\"end\":41173,\"start\":41166},{\"end\":41183,\"start\":41181},{\"end\":41197,\"start\":41188},{\"end\":41210,\"start\":41204},{\"end\":41220,\"start\":41216},{\"end\":41236,\"start\":41230},{\"end\":41250,\"start\":41244},{\"end\":41589,\"start\":41580},{\"end\":41602,\"start\":41594},{\"end\":41615,\"start\":41609},{\"end\":41622,\"start\":41621},{\"end\":41637,\"start\":41631},{\"end\":42063,\"start\":42055},{\"end\":42075,\"start\":42068},{\"end\":42084,\"start\":42081},{\"end\":42438,\"start\":42430},{\"end\":42450,\"start\":42443},{\"end\":42459,\"start\":42456},{\"end\":42469,\"start\":42465},{\"end\":42796,\"start\":42791},{\"end\":42810,\"start\":42803},{\"end\":42822,\"start\":42815},{\"end\":42837,\"start\":42830},{\"end\":42851,\"start\":42844}]", "bib_author_last_name": "[{\"end\":27189,\"start\":27187},{\"end\":27207,\"start\":27202},{\"end\":27226,\"start\":27220},{\"end\":27493,\"start\":27489},{\"end\":27503,\"start\":27500},{\"end\":27514,\"start\":27510},{\"end\":27522,\"start\":27520},{\"end\":27533,\"start\":27529},{\"end\":27551,\"start\":27543},{\"end\":27827,\"start\":27823},{\"end\":27844,\"start\":27835},{\"end\":27862,\"start\":27855},{\"end\":27879,\"start\":27873},{\"end\":28139,\"start\":28135},{\"end\":28156,\"start\":28147},{\"end\":28171,\"start\":28164},{\"end\":28189,\"start\":28182},{\"end\":28206,\"start\":28200},{\"end\":28508,\"start\":28502},{\"end\":28522,\"start\":28515},{\"end\":28534,\"start\":28529},{\"end\":28805,\"start\":28802},{\"end\":28815,\"start\":28810},{\"end\":28824,\"start\":28822},{\"end\":28836,\"start\":28834},{\"end\":28850,\"start\":28847},{\"end\":28864,\"start\":28860},{\"end\":28876,\"start\":28872},{\"end\":28891,\"start\":28886},{\"end\":28903,\"start\":28900},{\"end\":28916,\"start\":28914},{\"end\":29323,\"start\":29321},{\"end\":29335,\"start\":29331},{\"end\":29345,\"start\":29339},{\"end\":29359,\"start\":29355},{\"end\":29372,\"start\":29370},{\"end\":29381,\"start\":29379},{\"end\":29386,\"start\":29383},{\"end\":29690,\"start\":29688},{\"end\":29701,\"start\":29697},{\"end\":29713,\"start\":29709},{\"end\":29721,\"start\":29719},{\"end\":29737,\"start\":29732},{\"end\":29748,\"start\":29744},{\"end\":29999,\"start\":29997},{\"end\":30010,\"start\":30006},{\"end\":30025,\"start\":30020},{\"end\":30038,\"start\":30035},{\"end\":30046,\"start\":30044},{\"end\":30061,\"start\":30057},{\"end\":30231,\"start\":30222},{\"end\":30245,\"start\":30239},{\"end\":30490,\"start\":30488},{\"end\":30499,\"start\":30494},{\"end\":30511,\"start\":30503},{\"end\":30722,\"start\":30720},{\"end\":30735,\"start\":30732},{\"end\":30748,\"start\":30744},{\"end\":30763,\"start\":30759},{\"end\":30775,\"start\":30771},{\"end\":30784,\"start\":30781},{\"end\":31104,\"start\":31099},{\"end\":31117,\"start\":31113},{\"end\":31128,\"start\":31124},{\"end\":31139,\"start\":31135},{\"end\":31154,\"start\":31150},{\"end\":31166,\"start\":31162},{\"end\":31176,\"start\":31172},{\"end\":31465,\"start\":31458},{\"end\":31481,\"start\":31476},{\"end\":31494,\"start\":31489},{\"end\":31723,\"start\":31715},{\"end\":31739,\"start\":31733},{\"end\":31949,\"start\":31946},{\"end\":31964,\"start\":31956},{\"end\":31975,\"start\":31973},{\"end\":31989,\"start\":31982},{\"end\":32008,\"start\":31999},{\"end\":32233,\"start\":32230},{\"end\":32245,\"start\":32242},{\"end\":32254,\"start\":32249},{\"end\":32265,\"start\":32263},{\"end\":32269,\"start\":32267},{\"end\":32477,\"start\":32474},{\"end\":32489,\"start\":32484},{\"end\":32506,\"start\":32497},{\"end\":32520,\"start\":32516},{\"end\":32708,\"start\":32705},{\"end\":32718,\"start\":32716},{\"end\":33080,\"start\":33071},{\"end\":33094,\"start\":33088},{\"end\":33112,\"start\":33105},{\"end\":33127,\"start\":33121},{\"end\":33145,\"start\":33135},{\"end\":33161,\"start\":33153},{\"end\":33170,\"start\":33163},{\"end\":33491,\"start\":33482},{\"end\":33508,\"start\":33499},{\"end\":33520,\"start\":33514},{\"end\":33532,\"start\":33527},{\"end\":33545,\"start\":33538},{\"end\":33559,\"start\":33553},{\"end\":33564,\"start\":33561},{\"end\":33858,\"start\":33855},{\"end\":33871,\"start\":33868},{\"end\":33880,\"start\":33876},{\"end\":33889,\"start\":33887},{\"end\":33903,\"start\":33899},{\"end\":33916,\"start\":33914},{\"end\":34209,\"start\":34185},{\"end\":34219,\"start\":34217},{\"end\":34235,\"start\":34229},{\"end\":34246,\"start\":34237},{\"end\":34539,\"start\":34514},{\"end\":34565,\"start\":34550},{\"end\":34584,\"start\":34572},{\"end\":34595,\"start\":34586},{\"end\":34932,\"start\":34925},{\"end\":34950,\"start\":34941},{\"end\":34958,\"start\":34952},{\"end\":35308,\"start\":35281},{\"end\":35322,\"start\":35315},{\"end\":35334,\"start\":35324},{\"end\":35611,\"start\":35605},{\"end\":35636,\"start\":35623},{\"end\":35650,\"start\":35643},{\"end\":35671,\"start\":35657},{\"end\":35943,\"start\":35929},{\"end\":35956,\"start\":35948},{\"end\":35968,\"start\":35963},{\"end\":35978,\"start\":35970},{\"end\":36225,\"start\":36217},{\"end\":36243,\"start\":36237},{\"end\":36255,\"start\":36252},{\"end\":36273,\"start\":36266},{\"end\":36504,\"start\":36500},{\"end\":36515,\"start\":36513},{\"end\":36526,\"start\":36521},{\"end\":36539,\"start\":36535},{\"end\":36846,\"start\":36836},{\"end\":36860,\"start\":36853},{\"end\":36882,\"start\":36872},{\"end\":36895,\"start\":36890},{\"end\":36909,\"start\":36905},{\"end\":36929,\"start\":36918},{\"end\":36943,\"start\":36939},{\"end\":36959,\"start\":36952},{\"end\":36976,\"start\":36967},{\"end\":36989,\"start\":36984},{\"end\":37273,\"start\":37266},{\"end\":37291,\"start\":37281},{\"end\":37307,\"start\":37302},{\"end\":37322,\"start\":37318},{\"end\":37342,\"start\":37334},{\"end\":37357,\"start\":37352},{\"end\":37374,\"start\":37367},{\"end\":37389,\"start\":37383},{\"end\":37407,\"start\":37399},{\"end\":37422,\"start\":37415},{\"end\":37892,\"start\":37885},{\"end\":37907,\"start\":37903},{\"end\":37917,\"start\":37913},{\"end\":37926,\"start\":37919},{\"end\":38132,\"start\":38127},{\"end\":38147,\"start\":38142},{\"end\":38166,\"start\":38157},{\"end\":38186,\"start\":38175},{\"end\":38461,\"start\":38457},{\"end\":38476,\"start\":38471},{\"end\":38489,\"start\":38485},{\"end\":38500,\"start\":38496},{\"end\":38511,\"start\":38509},{\"end\":38521,\"start\":38518},{\"end\":38532,\"start\":38529},{\"end\":38864,\"start\":38860},{\"end\":38875,\"start\":38870},{\"end\":38887,\"start\":38884},{\"end\":38895,\"start\":38892},{\"end\":38905,\"start\":38900},{\"end\":38915,\"start\":38912},{\"end\":38929,\"start\":38926},{\"end\":39222,\"start\":39218},{\"end\":39235,\"start\":39233},{\"end\":39246,\"start\":39243},{\"end\":39256,\"start\":39253},{\"end\":39271,\"start\":39267},{\"end\":39461,\"start\":39457},{\"end\":39474,\"start\":39472},{\"end\":39485,\"start\":39481},{\"end\":39760,\"start\":39758},{\"end\":39777,\"start\":39770},{\"end\":39794,\"start\":39784},{\"end\":39808,\"start\":39802},{\"end\":39822,\"start\":39819},{\"end\":40076,\"start\":40074},{\"end\":40088,\"start\":40084},{\"end\":40099,\"start\":40095},{\"end\":40112,\"start\":40110},{\"end\":40124,\"start\":40120},{\"end\":40138,\"start\":40134},{\"end\":40148,\"start\":40145},{\"end\":40432,\"start\":40430},{\"end\":40443,\"start\":40441},{\"end\":40455,\"start\":40452},{\"end\":40469,\"start\":40465},{\"end\":40478,\"start\":40476},{\"end\":40489,\"start\":40485},{\"end\":40832,\"start\":40830},{\"end\":40845,\"start\":40841},{\"end\":40858,\"start\":40855},{\"end\":40870,\"start\":40866},{\"end\":40880,\"start\":40877},{\"end\":40892,\"start\":40889},{\"end\":41164,\"start\":41159},{\"end\":41179,\"start\":41174},{\"end\":41186,\"start\":41184},{\"end\":41202,\"start\":41198},{\"end\":41214,\"start\":41211},{\"end\":41228,\"start\":41221},{\"end\":41242,\"start\":41237},{\"end\":41259,\"start\":41251},{\"end\":41592,\"start\":41590},{\"end\":41607,\"start\":41603},{\"end\":41619,\"start\":41616},{\"end\":41629,\"start\":41623},{\"end\":41643,\"start\":41638},{\"end\":41647,\"start\":41645},{\"end\":42066,\"start\":42064},{\"end\":42079,\"start\":42076},{\"end\":42088,\"start\":42085},{\"end\":42441,\"start\":42439},{\"end\":42454,\"start\":42451},{\"end\":42463,\"start\":42460},{\"end\":42474,\"start\":42470},{\"end\":42801,\"start\":42797},{\"end\":42813,\"start\":42811},{\"end\":42828,\"start\":42823},{\"end\":42842,\"start\":42838},{\"end\":42856,\"start\":42852}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":8236317},\"end\":27408,\"start\":27156},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":235741950},\"end\":27745,\"start\":27410},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":211096730},\"end\":28064,\"start\":27747},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":219721239},\"end\":28408,\"start\":28066},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":5555257},\"end\":28711,\"start\":28410},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":237940542},\"end\":29229,\"start\":28713},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":236924453},\"end\":29596,\"start\":29231},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":211043589},\"end\":29954,\"start\":29598},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":13907106},\"end\":30216,\"start\":29956},{\"attributes\":{\"doi\":\"arXiv:1606.08415\",\"id\":\"b9\"},\"end\":30428,\"start\":30218},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":10537313},\"end\":30648,\"start\":30430},{\"attributes\":{\"doi\":\"arXiv:2106.04051\",\"id\":\"b11\"},\"end\":31001,\"start\":30650},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":236980247},\"end\":31408,\"start\":31003},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":926364},\"end\":31663,\"start\":31410},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":221191136},\"end\":31873,\"start\":31665},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":203592185},\"end\":32197,\"start\":31875},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":234742218},\"end\":32400,\"start\":32199},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":219660161},\"end\":32696,\"start\":32402},{\"attributes\":{\"doi\":\"arXiv:2101.01317\",\"id\":\"b18\"},\"end\":32979,\"start\":32698},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":216641996},\"end\":33416,\"start\":32981},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":3290478},\"end\":33763,\"start\":33418},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":240070722},\"end\":34122,\"start\":33765},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":26070552},\"end\":34424,\"start\":34124},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":237363429},\"end\":34821,\"start\":34426},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":220931841},\"end\":35196,\"start\":34823},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":14483341},\"end\":35536,\"start\":35198},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":10795036},\"end\":35854,\"start\":35538},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":218719424},\"end\":36159,\"start\":35856},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":222272463},\"end\":36438,\"start\":36161},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":237142347},\"end\":36782,\"start\":36440},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":233714958},\"end\":37259,\"start\":36784},{\"attributes\":{\"doi\":\"arXiv:2105.03404\",\"id\":\"b31\"},\"end\":37837,\"start\":37261},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":36809545},\"end\":38064,\"start\":37839},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":104292636},\"end\":38359,\"start\":38066},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3766110},\"end\":38756,\"start\":38361},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":211171550},\"end\":39150,\"start\":38758},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":159042183},\"end\":39449,\"start\":39152},{\"attributes\":{\"id\":\"b37\"},\"end\":39685,\"start\":39451},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":197928456},\"end\":40013,\"start\":39687},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":224814335},\"end\":40337,\"start\":40015},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":211010740},\"end\":40767,\"start\":40339},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":53219431},\"end\":41068,\"start\":40769},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":220302524},\"end\":41501,\"start\":41070},{\"attributes\":{\"id\":\"b43\"},\"end\":41929,\"start\":41503},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":235358394},\"end\":42294,\"start\":41931},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":247940233},\"end\":42698,\"start\":42296},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":219434009},\"end\":43073,\"start\":42700}]", "bib_title": "[{\"end\":27175,\"start\":27156},{\"end\":27482,\"start\":27410},{\"end\":27816,\"start\":27747},{\"end\":28128,\"start\":28066},{\"end\":28494,\"start\":28410},{\"end\":28795,\"start\":28713},{\"end\":29314,\"start\":29231},{\"end\":29677,\"start\":29598},{\"end\":29986,\"start\":29956},{\"end\":30484,\"start\":30430},{\"end\":31089,\"start\":31003},{\"end\":31451,\"start\":31410},{\"end\":31707,\"start\":31665},{\"end\":31935,\"start\":31875},{\"end\":32220,\"start\":32199},{\"end\":32466,\"start\":32402},{\"end\":33064,\"start\":32981},{\"end\":33475,\"start\":33418},{\"end\":33846,\"start\":33765},{\"end\":34176,\"start\":34124},{\"end\":34503,\"start\":34426},{\"end\":34915,\"start\":34823},{\"end\":35271,\"start\":35198},{\"end\":35595,\"start\":35538},{\"end\":35921,\"start\":35856},{\"end\":36208,\"start\":36161},{\"end\":36492,\"start\":36440},{\"end\":36829,\"start\":36784},{\"end\":37876,\"start\":37839},{\"end\":38120,\"start\":38066},{\"end\":38447,\"start\":38361},{\"end\":38854,\"start\":38758},{\"end\":39210,\"start\":39152},{\"end\":39753,\"start\":39687},{\"end\":40064,\"start\":40015},{\"end\":40425,\"start\":40339},{\"end\":40824,\"start\":40769},{\"end\":41153,\"start\":41070},{\"end\":41578,\"start\":41503},{\"end\":42053,\"start\":41931},{\"end\":42428,\"start\":42296},{\"end\":42789,\"start\":42700}]", "bib_author": "[{\"end\":27191,\"start\":27177},{\"end\":27209,\"start\":27191},{\"end\":27228,\"start\":27209},{\"end\":27495,\"start\":27484},{\"end\":27505,\"start\":27495},{\"end\":27516,\"start\":27505},{\"end\":27524,\"start\":27516},{\"end\":27535,\"start\":27524},{\"end\":27553,\"start\":27535},{\"end\":27829,\"start\":27818},{\"end\":27846,\"start\":27829},{\"end\":27864,\"start\":27846},{\"end\":27881,\"start\":27864},{\"end\":28141,\"start\":28130},{\"end\":28158,\"start\":28141},{\"end\":28173,\"start\":28158},{\"end\":28191,\"start\":28173},{\"end\":28208,\"start\":28191},{\"end\":28510,\"start\":28496},{\"end\":28524,\"start\":28510},{\"end\":28536,\"start\":28524},{\"end\":28807,\"start\":28797},{\"end\":28817,\"start\":28807},{\"end\":28826,\"start\":28817},{\"end\":28838,\"start\":28826},{\"end\":28852,\"start\":28838},{\"end\":28866,\"start\":28852},{\"end\":28878,\"start\":28866},{\"end\":28893,\"start\":28878},{\"end\":28905,\"start\":28893},{\"end\":28918,\"start\":28905},{\"end\":29325,\"start\":29316},{\"end\":29337,\"start\":29325},{\"end\":29347,\"start\":29337},{\"end\":29361,\"start\":29347},{\"end\":29374,\"start\":29361},{\"end\":29383,\"start\":29374},{\"end\":29388,\"start\":29383},{\"end\":29692,\"start\":29679},{\"end\":29703,\"start\":29692},{\"end\":29715,\"start\":29703},{\"end\":29723,\"start\":29715},{\"end\":29739,\"start\":29723},{\"end\":29750,\"start\":29739},{\"end\":30001,\"start\":29988},{\"end\":30012,\"start\":30001},{\"end\":30027,\"start\":30012},{\"end\":30040,\"start\":30027},{\"end\":30048,\"start\":30040},{\"end\":30063,\"start\":30048},{\"end\":30233,\"start\":30218},{\"end\":30247,\"start\":30233},{\"end\":30492,\"start\":30486},{\"end\":30501,\"start\":30492},{\"end\":30513,\"start\":30501},{\"end\":30724,\"start\":30715},{\"end\":30737,\"start\":30724},{\"end\":30750,\"start\":30737},{\"end\":30765,\"start\":30750},{\"end\":30777,\"start\":30765},{\"end\":30786,\"start\":30777},{\"end\":31106,\"start\":31091},{\"end\":31119,\"start\":31106},{\"end\":31130,\"start\":31119},{\"end\":31141,\"start\":31130},{\"end\":31156,\"start\":31141},{\"end\":31168,\"start\":31156},{\"end\":31178,\"start\":31168},{\"end\":31467,\"start\":31453},{\"end\":31483,\"start\":31467},{\"end\":31496,\"start\":31483},{\"end\":31725,\"start\":31709},{\"end\":31741,\"start\":31725},{\"end\":31951,\"start\":31937},{\"end\":31966,\"start\":31951},{\"end\":31977,\"start\":31966},{\"end\":31991,\"start\":31977},{\"end\":32010,\"start\":31991},{\"end\":32235,\"start\":32222},{\"end\":32247,\"start\":32235},{\"end\":32256,\"start\":32247},{\"end\":32267,\"start\":32256},{\"end\":32271,\"start\":32267},{\"end\":32479,\"start\":32468},{\"end\":32491,\"start\":32479},{\"end\":32508,\"start\":32491},{\"end\":32522,\"start\":32508},{\"end\":32710,\"start\":32698},{\"end\":32720,\"start\":32710},{\"end\":33082,\"start\":33066},{\"end\":33096,\"start\":33082},{\"end\":33114,\"start\":33096},{\"end\":33129,\"start\":33114},{\"end\":33147,\"start\":33129},{\"end\":33163,\"start\":33147},{\"end\":33172,\"start\":33163},{\"end\":33493,\"start\":33477},{\"end\":33510,\"start\":33493},{\"end\":33522,\"start\":33510},{\"end\":33534,\"start\":33522},{\"end\":33547,\"start\":33534},{\"end\":33561,\"start\":33547},{\"end\":33566,\"start\":33561},{\"end\":33860,\"start\":33848},{\"end\":33873,\"start\":33860},{\"end\":33882,\"start\":33873},{\"end\":33891,\"start\":33882},{\"end\":33905,\"start\":33891},{\"end\":33918,\"start\":33905},{\"end\":34211,\"start\":34178},{\"end\":34221,\"start\":34211},{\"end\":34237,\"start\":34221},{\"end\":34248,\"start\":34237},{\"end\":34541,\"start\":34505},{\"end\":34567,\"start\":34541},{\"end\":34586,\"start\":34567},{\"end\":34597,\"start\":34586},{\"end\":34934,\"start\":34917},{\"end\":34952,\"start\":34934},{\"end\":34960,\"start\":34952},{\"end\":35310,\"start\":35273},{\"end\":35324,\"start\":35310},{\"end\":35336,\"start\":35324},{\"end\":35613,\"start\":35597},{\"end\":35638,\"start\":35613},{\"end\":35652,\"start\":35638},{\"end\":35673,\"start\":35652},{\"end\":35945,\"start\":35923},{\"end\":35958,\"start\":35945},{\"end\":35970,\"start\":35958},{\"end\":35980,\"start\":35970},{\"end\":36227,\"start\":36210},{\"end\":36245,\"start\":36227},{\"end\":36257,\"start\":36245},{\"end\":36275,\"start\":36257},{\"end\":36506,\"start\":36494},{\"end\":36517,\"start\":36506},{\"end\":36528,\"start\":36517},{\"end\":36541,\"start\":36528},{\"end\":36848,\"start\":36831},{\"end\":36862,\"start\":36848},{\"end\":36884,\"start\":36862},{\"end\":36897,\"start\":36884},{\"end\":36911,\"start\":36897},{\"end\":36931,\"start\":36911},{\"end\":36945,\"start\":36931},{\"end\":36961,\"start\":36945},{\"end\":36978,\"start\":36961},{\"end\":36991,\"start\":36978},{\"end\":37275,\"start\":37261},{\"end\":37293,\"start\":37275},{\"end\":37309,\"start\":37293},{\"end\":37324,\"start\":37309},{\"end\":37344,\"start\":37324},{\"end\":37359,\"start\":37344},{\"end\":37376,\"start\":37359},{\"end\":37391,\"start\":37376},{\"end\":37409,\"start\":37391},{\"end\":37424,\"start\":37409},{\"end\":37894,\"start\":37878},{\"end\":37909,\"start\":37894},{\"end\":37919,\"start\":37909},{\"end\":37928,\"start\":37919},{\"end\":38134,\"start\":38122},{\"end\":38149,\"start\":38134},{\"end\":38168,\"start\":38149},{\"end\":38188,\"start\":38168},{\"end\":38463,\"start\":38449},{\"end\":38478,\"start\":38463},{\"end\":38491,\"start\":38478},{\"end\":38502,\"start\":38491},{\"end\":38513,\"start\":38502},{\"end\":38523,\"start\":38513},{\"end\":38534,\"start\":38523},{\"end\":38866,\"start\":38856},{\"end\":38877,\"start\":38866},{\"end\":38889,\"start\":38877},{\"end\":38897,\"start\":38889},{\"end\":38907,\"start\":38897},{\"end\":38917,\"start\":38907},{\"end\":38931,\"start\":38917},{\"end\":39224,\"start\":39212},{\"end\":39237,\"start\":39224},{\"end\":39248,\"start\":39237},{\"end\":39258,\"start\":39248},{\"end\":39273,\"start\":39258},{\"end\":39463,\"start\":39451},{\"end\":39476,\"start\":39463},{\"end\":39487,\"start\":39476},{\"end\":39762,\"start\":39755},{\"end\":39779,\"start\":39762},{\"end\":39796,\"start\":39779},{\"end\":39810,\"start\":39796},{\"end\":39824,\"start\":39810},{\"end\":40078,\"start\":40066},{\"end\":40090,\"start\":40078},{\"end\":40101,\"start\":40090},{\"end\":40114,\"start\":40101},{\"end\":40126,\"start\":40114},{\"end\":40140,\"start\":40126},{\"end\":40150,\"start\":40140},{\"end\":40434,\"start\":40427},{\"end\":40445,\"start\":40434},{\"end\":40457,\"start\":40445},{\"end\":40471,\"start\":40457},{\"end\":40480,\"start\":40471},{\"end\":40491,\"start\":40480},{\"end\":40834,\"start\":40826},{\"end\":40847,\"start\":40834},{\"end\":40860,\"start\":40847},{\"end\":40872,\"start\":40860},{\"end\":40882,\"start\":40872},{\"end\":40894,\"start\":40882},{\"end\":41166,\"start\":41155},{\"end\":41181,\"start\":41166},{\"end\":41188,\"start\":41181},{\"end\":41204,\"start\":41188},{\"end\":41216,\"start\":41204},{\"end\":41230,\"start\":41216},{\"end\":41244,\"start\":41230},{\"end\":41261,\"start\":41244},{\"end\":41594,\"start\":41580},{\"end\":41609,\"start\":41594},{\"end\":41621,\"start\":41609},{\"end\":41631,\"start\":41621},{\"end\":41645,\"start\":41631},{\"end\":41649,\"start\":41645},{\"end\":42068,\"start\":42055},{\"end\":42081,\"start\":42068},{\"end\":42090,\"start\":42081},{\"end\":42443,\"start\":42430},{\"end\":42456,\"start\":42443},{\"end\":42465,\"start\":42456},{\"end\":42476,\"start\":42465},{\"end\":42803,\"start\":42791},{\"end\":42815,\"start\":42803},{\"end\":42830,\"start\":42815},{\"end\":42844,\"start\":42830},{\"end\":42858,\"start\":42844}]", "bib_venue": "[{\"end\":27288,\"start\":27262},{\"end\":27575,\"start\":27568},{\"end\":27903,\"start\":27896},{\"end\":28236,\"start\":28226},{\"end\":28558,\"start\":28551},{\"end\":29412,\"start\":29404},{\"end\":29774,\"start\":29766},{\"end\":30083,\"start\":30077},{\"end\":30535,\"start\":30528},{\"end\":31204,\"start\":31195},{\"end\":31767,\"start\":31758},{\"end\":32034,\"start\":32026},{\"end\":32299,\"start\":32289},{\"end\":32546,\"start\":32538},{\"end\":33196,\"start\":33188},{\"end\":33588,\"start\":33581},{\"end\":33940,\"start\":33933},{\"end\":34272,\"start\":34264},{\"end\":34619,\"start\":34612},{\"end\":35362,\"start\":35353},{\"end\":35693,\"start\":35687},{\"end\":36006,\"start\":35997},{\"end\":36297,\"start\":36290},{\"end\":36610,\"start\":36603},{\"end\":37019,\"start\":37009},{\"end\":37948,\"start\":37942},{\"end\":38210,\"start\":38203},{\"end\":38556,\"start\":38549},{\"end\":38951,\"start\":38945},{\"end\":39299,\"start\":39290},{\"end\":39848,\"start\":39840},{\"end\":40174,\"start\":40166},{\"end\":40916,\"start\":40909},{\"end\":41283,\"start\":41276},{\"end\":42116,\"start\":42107},{\"end\":42500,\"start\":42492},{\"end\":42884,\"start\":42875},{\"end\":27260,\"start\":27228},{\"end\":27566,\"start\":27553},{\"end\":27894,\"start\":27881},{\"end\":28224,\"start\":28208},{\"end\":28549,\"start\":28536},{\"end\":28957,\"start\":28918},{\"end\":29402,\"start\":29388},{\"end\":29764,\"start\":29750},{\"end\":30075,\"start\":30063},{\"end\":30298,\"start\":30263},{\"end\":30526,\"start\":30513},{\"end\":30713,\"start\":30650},{\"end\":31193,\"start\":31178},{\"end\":31525,\"start\":31496},{\"end\":31756,\"start\":31741},{\"end\":32024,\"start\":32010},{\"end\":32287,\"start\":32271},{\"end\":32536,\"start\":32522},{\"end\":32818,\"start\":32736},{\"end\":33186,\"start\":33172},{\"end\":33579,\"start\":33566},{\"end\":33931,\"start\":33918},{\"end\":34262,\"start\":34248},{\"end\":34610,\"start\":34597},{\"end\":34995,\"start\":34960},{\"end\":35351,\"start\":35336},{\"end\":35685,\"start\":35673},{\"end\":35995,\"start\":35980},{\"end\":36288,\"start\":36275},{\"end\":36554,\"start\":36541},{\"end\":37007,\"start\":36991},{\"end\":37522,\"start\":37440},{\"end\":37940,\"start\":37928},{\"end\":38201,\"start\":38188},{\"end\":38547,\"start\":38534},{\"end\":38943,\"start\":38931},{\"end\":39288,\"start\":39273},{\"end\":39559,\"start\":39487},{\"end\":39838,\"start\":39824},{\"end\":40164,\"start\":40150},{\"end\":40542,\"start\":40491},{\"end\":40907,\"start\":40894},{\"end\":41274,\"start\":41261},{\"end\":41694,\"start\":41649},{\"end\":42105,\"start\":42090},{\"end\":42490,\"start\":42476},{\"end\":42873,\"start\":42858}]"}}}, "year": 2023, "month": 12, "day": 17}