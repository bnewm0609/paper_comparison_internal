{"id": 173991158, "updated": "2023-09-28 10:02:34.004", "metadata": {"title": "HopSkipJumpAttack: A Query-Efficient Decision-Based Attack", "authors": "[{\"first\":\"Jianbo\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Michael\",\"last\":\"Jordan\",\"middle\":[\"I.\"]},{\"first\":\"Martin\",\"last\":\"Wainwright\",\"middle\":[\"J.\"]}]", "venue": "ArXiv", "journal": "2020 IEEE Symposium on Security and Privacy (SP)", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "The goal of a decision-based adversarial attack on a trained model is to generate adversarial examples based solely on observing output labels returned by the targeted model. We develop HopSkipJumpAttack, a family of algorithms based on a novel estimate of the gradient direction using binary information at the decision boundary. The proposed family includes both untargeted and targeted attacks optimized for $\\ell_2$ and $\\ell_\\infty$ similarity metrics respectively. Theoretical analysis is provided for the proposed algorithms and the gradient direction estimate. Experiments show HopSkipJumpAttack requires significantly fewer model queries than Boundary Attack. It also achieves competitive performance in attacking several widely-used defense mechanisms. (HopSkipJumpAttack was named Boundary Attack++ in a previous version of the preprint.)", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1904.02144", "mag": "3015625436", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sp/ChenJW20", "doi": "10.1109/sp40000.2020.00045"}}, "content": {"source": {"pdf_hash": "f0a4e8674bfd3a0d3f6a9e228c20743a931b8b2a", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1904.02144v5.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://ieeexplore.ieee.org/ielx7/9144328/9152199/09152788.pdf", "status": "BRONZE"}}, "grobid": {"id": "bbbf4b21b12ce2332f1d48408d3a49ecac6759b7", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f0a4e8674bfd3a0d3f6a9e228c20743a931b8b2a.txt", "contents": "\nHopSkipJumpAttack: A Query-Efficient Decision-Based Attack\n\n\nJianbo Chen jianbochen@ \nVoleon Group \u2020\n\n\nMichael I Jordan jordan@cs. \nVoleon Group \u2020\n\n\nMartin J Wainwright wainwrig@berkeley.edu \nVoleon Group \u2020\n\n\n\nUniversity of California\nBerkeley\n\nHopSkipJumpAttack: A Query-Efficient Decision-Based Attack\n\nThe goal of a decision-based adversarial attack on a trained model is to generate adversarial examples based solely on observing output labels returned by the targeted model. We develop HopSkipJumpAttack, a family of algorithms based on a novel estimate of the gradient direction using binary information at the decision boundary. The proposed family includes both untargeted and targeted attacks optimized for 2 and \u221e similarity metrics respectively. Theoretical analysis is provided for the proposed algorithms and the gradient direction estimate. Experiments show HopSkipJumpAttack requires significantly fewer model queries than several state-of-the-art decision-based adversarial attacks. It also achieves competitive performance in attacking several widely-used defense mechanisms.\n\nI. INTRODUCTION\n\nAlthough deep neural networks have achieved state-of-the-art performance on a variety of tasks, they have been shown to be vulnerable to adversarial examples-that is, maliciously perturbed examples that are almost identical to original samples in human perception, but cause models to make incorrect decisions [1]. The vulnerability of neural networks to adversarial examples implies a security risk in applications with real-world consequences, such as self-driving cars, robotics, financial services, and criminal justice; in addition, it highlights fundamental differences between human learning and existing machine-based systems. The study of adversarial examples is thus necessary to identify the limitation of current machine learning algorithms, provide a metric for robustness, investigate the potential risk, and suggest ways to improve the robustness of models.\n\nRecent years have witnessed a flurry of research on the design of new algorithms for generating adversarial examples [1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][16]. Adversarial examples can be categorized according to at least three different criteria: the similarity metric, the attack goal, and the threat model. Commonly used similarity metrics are p -distances between adversarial and original examples with p \u2208 {0, 2, \u221e}. The goal of attack is either untargeted or targeted. The goal of an untargeted attack is to perturb the input so as to cause any type of misclassification, whereas the goal of a targeted attack is to alter the decision of the model to a pre-specific target class. Changing the loss function allows for switching between two types of attacks [3,5,6].\n\nPerhaps the most important criterion in practice is the threat Figure 1: An illustration of accessible components of the target model for each of the three threat models. A white-box threat model assumes access to the whole model; a score-based threat model assumes access to the output layer; a decision-based threat model assumes access to the predicted label alone. model, of which there are two primary types: white-box and black-box. In the white-box setting, an attacker has complete access to the model, including its structure and weights. Under this setting, the generation of adversarial examples is often formulated as an optimization problem, which is solved either via treating misclassification loss as a regularization [1,6] or via tackling the dual as a constrained optimization problem [2,3,7]. In the black-box setting, an attacker can only access outputs of the target model. Based on whether one has access to the full probability or the label of a given input, black-box attacks are further divided into score-based and decision-based. See Figure 1 for an illustration of accessible components of the target model for each of the three threat models. Chen et al. [8] and Ilyas et al. [9,10] introduced score-based methods using zeroth-order gradient estimation to craft adversarial examples.\n\nThe most practical threat model is that in which an attacker has access to decisions alone. A widely studied type of the decision-based attack is transfer-based attack. Liu et al. [11] showed that adversarial examples generated on an ensemble of deep neural networks from a white-box attack can be transferred to an unseen neural network. Papernot et al. [12,13] proposed to train a substitute model by querying the target model. However, transfer-based attack often requires a carefully-designed substitute model, or even access to part of the training data. Moreover, they can be defended against via training on a data set augmented by adversarial examples from multiple static pre-trained models [17]. In recent work, Brendel et al. [14] proposed Boundary Attack, which generates adversarial examples via rejection sampling. While relying neither on training data nor on the assumption of transferability, this attack method achieves comparable performance with state-of-the-art white-box attacks such as C&W attack [6]. One limitation of Boundary Attack, however, is that it was formulated only for 2 -distance. Moreover, it requires a relatively large number of model queries, rendering it impractical for real-world applications.\n\nIt is more realistic to evaluate the vulnerability of a machine learning system under the decision-based attack with a limited budget of model queries. Online image classification platforms often set a limit on the allowed number of queries within a certain time period. For example, the cloud vision API from Google currently allow 1,800 requests per minute. Query inefficiency thus leads to clock-time inefficiency and prevents an attacker from carrying out large-scale attacks. A system may also be set to recognize the behavior of feeding a large number of similar queries within a small amount of time as a fraud, which will automatically filter out query-inefficient decision-based attacks. Last but not least, a smaller query budget directly implies less cost in evaluation and research. Query-efficient algorithms help save the cost of evaluating the robustness of public platforms, which incur a cost for each query made by the attacker. It also helps facilitate research in adversarial vulnerability, as such a decision-based attack which does not require access to model details may be used as a simple and efficient first step in evaluating new defense mechanisms, as we will see in Section V-B and Appendix C.\n\nIn this paper, we study decision-based attacks under an optimization framework, and propose a novel family of algorithms for generating both targeted and untargeted adversarial examples that are optimized for minimum distance with respect to either the 2 -distance or \u221e distance. The family of algorithms is iterative in nature, with each iteration involving three steps: estimation of the gradient direction, step-size search via geometric progression, and Boundary search via a binary search. Theoretical analysis has been carried out for the optimization framework and the gradient direction estimate, which not only provides insights for choosing hyperparamters, but also motivating essential steps in the proposed algorithms. We refer to the algorithm as HopSkipJumpAttack 1 . In summary, our contributions are the following:\n\n\u2022 We propose a novel unbiased estimate of gradient direction at the decision boundary based solely on access to model decisions, and propose ways to control the error from deviation from the boundary. \u2022 We design a family of algorithms, HopSkipJumpAttack, based on the proposed estimate and our analysis, which is hyperparameter-free, query-efficient and equipped with a convergence analysis. \u2022 We demonstrate the superior efficiency of our algorithm over several state-of-the-art decision-based attacks through extensive experiments. \u2022 Through the evaluation of several defense mechanisms such as defensive distillation, region-based classification, adversarial training and input binarization, we suggest our attack can be used as a simple and efficient first step for researchers to evaluate new defense mechanisms.\n\nRoadmap. In Section II, we describe previous work on decision-based adversarial attacks and their relationship to our algorithm. We also discuss the connection of our algorithm to zeroth-order optimization. In Section III, we propose and analyze a novel iterative algorithm which requires access to the gradient information. Each step carries out a gradient update from the boundary, and then projects back to the boundary again. In Section IV, we introduce a novel asymptotically unbiased gradient-direction estimate at the boundary, and a binary-search procedure to approach the boundary. We also discuss how to control errors with deviation from the boundary. The analysis motivates a decision-based algorithm, HopSkipJumpAttack (Algorithm 2). Experimental results are provided in Section V. We conclude in Section VI with a discussion of future work.\n\n\nII. RELATED WORK\n\n\nA. Decision-based attacks\n\nMost related to our work is the Boundary Attack method introduced by Brendel et al. [14]. Boundary Attack is an iterative algorithm based on rejective sampling, initialized at an image that lies in the target class. At each step, a perturbation is sampled from a proposal distribution, which reduces the distance of the perturbed image towards the original input. If the perturbed image still lies in the target class, the perturbation is kept. Otherwise, the perturbation is dropped. Boundary Attack achieves performance comparable to state-of-the-art white-box attacks on deep neural networks for image classification. The key obstacle to its practical application is, however, the demand for a large number of model queries. In practice, the required number of model queries for crafting an adversarial example directly determines the level of the threat imposed by a decision-based attack. One source of inefficiency in Boundary Attack is the rejection of perturbations which deviate from the target class. In our algorithm, the perturbations are used for estimation of a gradient direction.\n\nSeveral other decision-based attacks have been proposed to improve efficiency. Brunner et al. [15] introduced Biased Boundary Attack, which biases the sampling procedure by combining low-frequency random noise with the gradient from a substitute model. Biased Boundary Attack is able to significantly reduce the number of model queries. However, it relies on the transferability between the substitute model and the target model, as with other transfer-based attacks.\n\nOur algorithm does not rely on the additional assumption of transferability. Instead, it achieves a significant improvement over Boundary Attack through the exploitation of discarded information into the gradient-direction estimation. Ilyas et al. [9] proposed Limited attack in the label-only setting, which directly performs projected gradient descent by estimating gradients based on novel proxy scores. Cheng et al. [16] introduced Opt attack, which transforms the original problem to a continuous version, and solves the new problem via randomized zeroth-order gradient update. Our algorithm approaches the original problem directly via a novel gradientdirection estimate, leading to improved query efficiency over both Limited Attack and Opt Attack. The majority of model queries in HopSkipJumpAttack come in mini-batches, which also leads to improved clock-time efficiency over Boundary Attack.\n\n\nB. Zeroth-order optimization\n\nZeroth-order optimization refers to the problem of optimizing a function f based only on access to function values f (x), as opposed to gradient values \u2207f (x). Such problems have been extensively studied in the convex optimization and bandit literatures. Flaxman et al. [18] studied one-point randomized estimate of gradient for bandit convex optimization. Agarwal et al. [19] and Nesterov and Spokoiny [20] demonstrated that faster convergence can be achieved by using two function evaluations for estimating the gradient. Duchi et al. [21] established optimal rates of convex zeroth-order optimization via mirror descent with two-point gradient estimates. Zerothorder algorithms have been applied to the generation of adversarial examples under the score-based threat model [8][9][10]. Subsequent work [22] proposed and analyzed an algorithm based on variance-reduced stochastic gradient estimates.\n\nWe formulate decision-based attack as an optimization problem. A core component of our proposed algorithm is a gradient-direction estimate, the design of which is motivated by zeroth-order optimization. However, the problem of decision-based attack is more challenging than zerothorder optimization, essentially because we only have binary information from output labels of the target model, rather than function values.\n\n\nIII. AN OPTIMIZATION FRAMEWORK\n\nIn this section, we describe an optimization framework for finding adversarial instances for an m-ary classification model of the following type. The first component is a discriminant function F : R d \u2192 R m that accepts an input x \u2208 [0, 1] d and produces an output y \u2208 \u2206 m := {y \u2208 [0, 1] m | m c=1 y c = 1}. The output vector y = (F 1 (x), . . . , F m (x)) can be viewed as a probability distribution over the label set [m] = {1, . . . , m}. Based on the function F , the classifier C : R d \u2192 [m] assigns input x to the class with maximum probability-that is,\nC(x) := arg max c\u2208[m] F c (x).\nWe study adversaries of both the untargeted and targeted varieties. Given some input x , the goal of an untargeted attack is to change the original classifier decision c := C(x ) to any c \u2208 [m]\\{c }, whereas the goal of a targeted attack is to change the decision to some pre-specified c \u2020 \u2208 [m]\\{c }. Formally, if we define the function S x :\nR d \u2192 R via S x (x ) := \uf8f1 \uf8f2 \uf8f3 max c =c F c (x ) \u2212 F c (x ) (Untargeted) F c \u2020 (x ) \u2212 max c =c \u2020 F c (x ) (Targeted)(1)\nthen a perturbed image x is a successful attack if and only if S x (x ) > 0. The boundary between successful and unsuccessful perturbed images is\nbd(S x ) := z \u2208 [0, 1] d | S x (z) = 0 .\nAs an indicator of successful perturbation, we introduce the\nBoolean-valued function \u03c6 x : [0, 1] d \u2192 {\u22121, 1} via \u03c6 x (x ) := sign (S x (x )) = 1 if S x (x ) > 0, \u22121 otherwise.\nThis function is accessible in the decision-based setting, as it can be computed by querying the classifier C alone. The goal of an adversarial attack is to generate a perturbed sample x such that \u03c6 x (x ) = 1, while keeping x close to the original sample x . This can be formulated as the optimization problem\nmin x d(x , x ) such that \u03c6 x (x ) = 1,(2)\nwhere d is a distance function that quantifies similarity. Standard choices of d studied in past work [2,5,6] include the usual p -norms, for p \u2208 {0, 2, \u221e}.\n\nA. An iterative algorithm for 2 distance\n\nConsider the case of the optimization problem (2) with the\n2 -norm d(x, x ) = x \u2212 x 2 .\nWe first specify an iterative algorithm that is given access to the gradient \u2207S x . Given an initial vector x 0 such that S x (x 0 ) > 0 and a stepsize sequence {\u03be t } t\u22650 , it performs the update\nx t+1 = \u03b1 t x + (1 \u2212 \u03b1 t ) x t + \u03be t \u2207S x (x t ) \u2207S x (x t ) 2 ,(3)\nwhere \u03be t is a positive step size. Here the line search parameter \u03b1 t \u2208 [0, 1] is chosen such that S x (x t+1 ) = 0-that is, so that the next iterate x t+1 lies on the boundary. The motivation for this choice is that our gradient-direction estimate in Section IV is only valid near the boundary.\n\nWe now analyze this algorithm with the assumption that we have access to the gradient of S x in the setting of binary classification. Assume that the function S x is twice differentiable with a locally Lipschitz gradient, meaning that there exists L > 0 such that for all x, y \u2208 {z :\nz \u2212 x 2 \u2264 x 0 \u2212 x 2 }, we have \u2207S x (x) \u2212 \u2207S x (y) 2 \u2264 L x \u2212 y 2 ,(4)\nIn addition, we assume the gradient is bounded away from zero on the boundary: there exists a positiveC > 0 such that \u2207S x (z) >C for any z \u2208 bd(S x ).\n\nWe analyze the behavior of the updates (3) in terms of the angular measure\nr(x t , x ) := cos \u2220 (x t \u2212 x , \u2207S x (x t )) = x t \u2212 x , \u2207S x (x t ) x t \u2212 x 2 \u2207S x (x t ) 2 ,\ncorresponding to the cosine of the angle between x t \u2212 x and the gradient \u2207S x (x t ). Note that the condition r(x, x ) = 1 holds if and only if x is a stationary point of the optimization (2). The following theorem guarantees that, with a suitable step size, the updates converge to such a stationary point:\nTheorem 1.\nUnder the previously stated conditions on S x , suppose that we compute the updates (3) with step size \u03be t = x t \u2212 x 2 t \u2212q for some q \u2208 1 2 , 1 . Then there is a universal constant c such that\n0 \u2264 1 \u2212 r(x t , x ) \u2264 c t q\u22121 for t = 1, 2, . . ..(5)\nIn particular, the algorithm converges to a stationary point of problem (2).\n\nTheorem 1 suggests a scheme for choosing the step size in the algorithm that we present in the next section. An experimental evaluation of the proposed scheme is carried out in Appendix B. The proof of the theorem is constructed by establishing the relationship between the objective value d(x t , x ) and r(x t , x ), with a second-order Taylor approximation to the boundary. See Appendix A-A for details.\n\n\nB. Extension to \u221e -distance\n\nWe now describe how to extend these updates so as to minimize the \u221e -distance. Consider the 2 -projection of a point x onto the sphere of radius \u03b1 t centered at x :\n\u03a0 2 x ,\u03b1t (x) := arg min y\u2212x 2\u2264\u03b1t y \u2212 x 2 = \u03b1 t x + (1 \u2212 \u03b1 t )x.(6)\nIn terms of this operator, our 2 -based update (3) can be rewritten in the equivalent form\nx t+1 = \u03a0 2 x ,\u03b1t x t + \u03be t \u2207S x (x t ) \u2207S x (x t ) 2 .(7)\nThis perspective allows us to extend the algorithm to other p -norms for p = 2. For instance, in the case p = \u221e, we can define the \u221e -projection operator \u03a0 \u221e x ,\u03b1 . It performs a perpixel clip within a neighborhood of x , such that the ith entry\nof \u03a0 \u221e x ,\u03b1 (x) is \u03a0 \u221e x ,\u03b1 (x) i := max {min{x i , x i + c} , x i \u2212 c}, where c := \u03b1 x \u2212 x \u221e .\nWe propose the \u221e -version of our algorithm by carrying out the following update iteratively:\nx t+1 = \u03a0 \u221e x ,\u03b1t x t + \u03be t sign(\u2207S x (x t )) ,(8)\nwhere \u03b1 t is chosen such that S x (x t+1 ) = 0, and \"sign\" returns the element-wise sign of a vector. We use the sign of the gradient for faster convergence in practice, similar to previous work [2,3,7].\n\n\nIV. A DECISION-BASED ALGORITHM BASED ON A NOVEL\n\n\nGRADIENT ESTIMATE\n\nWe now extend our procedures to the decision-based setting, in which we have access only to the Boolean-valued function \u03c6 x (x) = sign(S x (x))-that is, the method cannot observe the underlying discriminant function F or its gradient. In this section, we introduce a gradient-direction estimate based on \u03c6 x when x t \u2208 bd(S x ) (so that S x (x t ) = 0 by definition). We proceed to discuss how to approach the boundary. Then we discuss how to control the error of our estimate with a deviation from the boundary. We will summarize the analysis with a decision-based algorithm.\n\n\nA. At the boundary\n\nGiven an iterate x t \u2208 bd(S x ) we propose to approximate the direction of the gradient \u2207S x (x t ) via the Monte Carlo estimate\n\u2207S(x t , \u03b4) := 1 B B b=1 \u03c6 x (x t + \u03b4u b )u b ,(9)\nwhere {u b } B b=1 are i.i.d. draws from the uniform distribution over the d-dimensional sphere, and \u03b4 is small positive parameter. (The dependence of this estimator on the fixed centering point x is omitted for notational simplicity.)\n\nThe perturbation parameter \u03b4 is necessary, but introduces a form of bias in the estimate. Our first result controls this bias, and shows that \u2207S(x t , \u03b4) is asymptotically unbiased as \u03b4 \u2192 0 + . Theorem 2. For a boundary point x t , suppose that S x has L-Lipschitz gradients in a neighborhood of x t . Then the cosine of the angle between \u2207S(x t , \u03b4) and \u2207S x (x t ) is bounded as\ncos \u2220 E[ \u2207S(x t , \u03b4)], \u2207S x (x t ) \u2265 1 \u2212 9L 2 \u03b4 2 d 2 8 \u2207S(x t ) 2 2 . (10)\nIn particular, we have\nlim \u03b4\u21920 cos \u2220 E[ \u2207S(x t , \u03b4)], \u2207S x (x t ) = 1,(11)\nshowing that the estimate is asymptotically unbiased as an estimate of direction.\n\nWe remark that Theorem 2 only establishes the asymptotic behavior of the proposed estiamte at the boundary. This also motivates the boundary search step in our algorithm to be discussed in Seciton IV-B. The proof of Theorem 2 starts from dividing the unit sphere into three components: the upper cap along the direction of gradient, the lower cap opposite to the direction of gradient, and the annulus in between. The error from the annulus can be bounded when \u03b4 is small. See Appendix A-B for the proof of this theorem. As will be seen in the sequel, the size of perturbation \u03b4 should be chosen proportionally to d \u22121 ; see Section IV-C for details.\n\n\nB. Approaching the boundary\n\nThe proposed estimate (9) is only valid at the boundary. We now describe how we approach the boundary via a binary search. Letx t denote the updated sample before the operator \u03a0 p x,\u03b1t is applied:\nx t := x t + \u03be t v t (x t , \u03b4 t ), such that (12) v t (x t , \u03b4 t ) = \u2207S(x t , \u03b4 t )/ \u2207S(x t , \u03b4 t ) 2 , if p = 2, sign( \u2207S(x t , \u03b4 t )), if p = \u221e,\nwhere \u2207S will be introduced later in equation (16), as a variance-reduced version of \u2207S, and \u03b4 t is the size of perturbation at the t-th step.\n\nWe hopex t is at the opposite side of the boundary to x so that the binary search can be carried out. Therefore, we initialize atx 0 at the target side with \u03c6 x (x 0 ) = 1, and set\nx 0 := \u03a0 p x,\u03b10 (x 0 ),\nwhere \u03b1 0 is chosen via a binary search between 0 and 1 to approach the boundary, stopped at x 0 lying on the target side with \u03c6 x (x 0 ) = 1. At the t-th iteration, we start at x t lying at the target side \u03c6 x (x t ) = 1. The step size is initialized as\n\u03be t := x t \u2212 x p / \u221a t,(13)\nas suggested by Theorem 1 in the 2 case, and is decreased by half until \u03c6 x (x t ) = 1, which we call geometric progression of \u03be t . Having found an appropriatex t , we choose the projection radius \u03b1 t via a binary search between 0 and 1 to approach the boundary, which stops at x t+1 with \u03c6 x (x t+1 ) = 1. See Algorithm 1 for the complete binary search, where the binary search threshold \u03b8 is set to be some small constant. \n\n\nAlgorithm 1 Bin-Search\n\nRequire: Samples x , x, with a binary function \u03c6, such that\n\u03c6(x ) = 1, \u03c6(x) = 0, threshold \u03b8, constraint p . Ensure: A sample x near the boundary. Set \u03b1 l = 0 and \u03b1 u = 1. while |\u03b1 l \u2212 \u03b1 u | > \u03b8 do Set \u03b1 m \u2190 \u03b1 l +\u03b1u 2 . if \u03c6(\u03a0 x,\u03b1m (x )) = 1 then Set \u03b1 u \u2190 \u03b1 m . else Set \u03b1 l \u2190 \u03b1 m . end if end while Output x = \u03a0 x,\u03b1u (x ).\n\nC. Controlling errors of deviations from the boundary\n\nBinary search never places x t+1 exactly onto the boundary. We analyze the error of the gradient-direction estimate, and propose two approaches for reducing the error. a) Appropriate choice of the size of random perturbation: First, the size of random perturbation \u03b4 t for estimating the gradient direction is chosen as a function of image size d and the binary search threshold \u03b8. This is different from numerical differentiation, where the optimal choice of \u03b4 t is at the scale of round-off errors (e.g., [23]). Below we characterize the error incurred by a large \u03b4 t as a function of distance betweenx t and the boundary, and derive the appropriate choice of \u03be t and \u03b4 t . In fact, with a Taylor approximation of S x at x t , we have\nS x (x t + \u03b4 t u) = S x (x t ) + \u03b4 t \u2207S x (x t ), u + O(\u03b4 2 t )\n. At the boundary S x (x t ) = 0, the error of gradient approximation scales at O(\u03b4 2 t ), which is minimized by reducing \u03b4 t to the scale of rooted round-off error. However, the outcome x t of a finite-step binary search lies close to, but not exactly on the boundary.\n\nWhen \u03b4 t is small enough such that second-order terms can be omitted, the first-order Taylor approximation implies that \u03c6 x (x t +\u03b4 t u) = \u22121 if and only if x t +\u03b4 t u lies on the spherical cap C, with\nC := u | \u2207S x (x t ) \u2207S x (x t ) 2 , u < \u2212\u03b4 \u22121 t S x (x t ) \u2207S x (x t ) 2 .\nOn the other hand, the probability mass of u concentrates on the equator in a high-dimensional sphere, which is characterized by the following inequality [24]:\nP(u \u2208 C) \u2264 2 c exp{\u2212 c 2 2 }, where c = \u221a d \u2212 2S x (x t ) \u03b4 t \u2207S x (x t ) 2 . (14) A Taylor expansion of x t at x t := \u03a0 2 \u2202 (x t ) yields S x (x t ) = \u2207S x (x t ) T (x t \u2212 x t ) + O( x t \u2212 x t 2 2 ) = \u2207S x (x t ) T (x t \u2212 x t ) + O( x t \u2212 x t 2 2 ).\nBy the Cauchy-Schwarz inequality and the definition of 2projection, we have\n|\u2207S x (x t ) T (x t \u2212 x t )| \u2264 \u2207S x (x t ) 2 x t \u2212 \u03a0 2 \u2202 (x t ) 2 \u2264 \u2207S x (x t ) 2 \u03b8 x t\u22121 \u2212 x p , if p = 2, \u2207S x (x t ) 2 \u03b8 x t\u22121 \u2212 x p \u221a d, if p = \u221e.\nThis yields\nc = O( d q \u03b8 x t\u22121 \u2212 x p \u03b4 t ),\nwhere q = 1 \u2212 (1/p) is the dual exponent. In order to avoid a loss of accuracy from concentration of measure, we let\n\u03b4 t = d q \u03b8 x t\u22121 \u2212 x 2 .\nTo make the approximation error independent of dimension d, we set \u03b8 at the scale of d \u2212q\u22121 , so that \u03b4 t is proportional to d \u22121 , as suggested by Theorem 2. This leads to a logarithmic dependence on dimension for the number of model queries. In practice, we set\n\u03b8 = d \u2212q\u22121 ; \u03b4 t = d \u22121 x t\u22121 \u2212 x p .(15)\nb) A baseline for variance reduction in gradient-direction estimation: Another source of error comes from the variance of the estimate, where we characterize variance of a random vector v \u2208 R d by the trace of its covariance operator:\nVar(v) := d i=1 Var(v i )\n. When x t deviates from the boundary and \u03b4 t is not exactly zero, there is an uneven distribution of perturbed samples at the two sides of the boundary:\n|E[\u03c6 x (x t + \u03b4 t u)]| > 0,\nas we can see from Equation (14). To attempt to control the variance, we introduce a baseline \u03c6 x into the estimate:\n\u03c6 x := 1 B B b=1 \u03c6 x (x t + \u03b4u b ),\nwhich yields the following estimate:\n\u2207S(x t , \u03b4) := 1 B \u2212 1 B b=1 (\u03c6 x (x t + \u03b4u b ) \u2212 \u03c6 x )u b . (16)\n\nAlgorithm 2 HopSkipJumpAttack\n\nRequire: Classifier C, a sample x, constraint p , initial batch\nsize B 0 , iterations T . Ensure: Perturbed image x t .\nSet \u03b8 (Equation (15)). (15)).\nInitialize atx 0 with \u03c6 x (x 0 ) = 1. Compute d 0 = x 0 \u2212 x p . for t in 1, 2, . . . , T \u2212 1 do (Boundary search) x t = BIN-SEARCH(x t\u22121 , x, \u03b8, \u03c6 x , p) (Gradient-direction estimation) Sample B t = B 0 \u221a t unit vectors u 1 , . . . , u Bt . Set \u03b4 t (Equation\nCompute v t (x t , \u03b4 t ) (Equation (12)).\n(Step size search) Initialize step size \u03be t = x t \u2212 x p / \u221a t. while \u03c6 x (x t + \u03b5 t v t ) = 0 do \u03be t \u2190 \u03be t /2. end while Setx t = x t + \u03be t v t . Compute d t = x t \u2212 x p . end for Output x t = BIN-SEARCH(x t\u22121 , x, \u03b8, \u03c6 x , p).\nIt can be easily observed that this estimate is equal to the previous estimate in expectation, and thus still asymptotically unbiased at the boundary: When x t \u2208 bd(S x ), we have\ncos \u2220 E[ \u2207S(x t , \u03b4)], \u2207S x (x t ) \u2265 1 \u2212 9L 2 \u03b4 2 d 2 8 \u2207S(x t ) 2 2 , lim \u03b4\u21920 cos \u2220 E[ \u2207S(x t , \u03b4)], \u2207S x (x t ) = 1.\nMoreover, the introduction of the baseline reduces the variance when E[\u03c6 x (x t + \u03b4u)] deviates from zero. In particular, the following theorem shows that whenever |E[\u03c6 x (x t + \u03b4u)]| = \u2126(B \u2212 1 2 ), the introduction of a baseline reduces the variance.\n\nTheorem 3. Defining \u03c3 2 := Var(\u03c6 x (x t + \u03b4u)u) as the variance of one-point estimate, we have\nVar( \u2207S(x t , \u03b4)) < Var( \u2207S(x t , \u03b4))(1 \u2212 \u03c8), where \u03c8 = 2 \u03c3 2 (B \u2212 1) 2BE[\u03c6 x (x t + \u03b4u)] 2 \u2212 1 \u2212 2B \u2212 1 (B \u2212 1) 2 .\nSee Appendix A-C for the proof. We also present an experimental evaluation of our gradient-direction estimate when the sample deviates from the boundary in Appendix B, where we show our proposed choice of \u03b4 t and the introduction of baseline yield a performance gain in estimating gradient.\n\n\nD. HopSkipJumpAttack\n\nWe now combine the above analysis into an iterative algorithm, HopSkipJumpAttack. It is initialized with a sample in the target class for untargeted attack, and with a sample blended with uniform noise that is misclassified for targeted attack. Each iteration of the algorithm has three components. First, the iterate from the last iteration is pushed towards the boundary via a binary search (Algorithm 1). Second, the gradient direction is estimated via Equation (16). Third, the updating step size along the gradient direction is initialized as Equation (13) based on Theorem 1, and is decreased via geometric progression until perturbation becomes successful. The next iteration starts with projecting the perturbed sample back to the boundary again. The complete procedure is summarized in Algorithm 2. Figure 2 provides an intuitive visualization of the three steps in 2 . For all experiments, we initialize the batch size at 100 and increase it with \u221a t linearly, so that the variance of the estimate reduces with t. When the input domain is bounded in practice, a clip is performed at each step by default.\n\n\nV. EXPERIMENTS\n\nIn this section, we carry out experimental analysis of HopSkipJumpAttack. We compare the efficiency of Hop-SkipJumpAttack with several previously proposed decisionbased attacks on image classification tasks. In addition, we evaluate the robustness of three defense mechanisms under our attack method. All experiments were carried out on a Tesla K80 GPU, with code available online. 2 Our algorithm is also 2 See https://github.com/Jianbo-Lab/HSJA/. available on CleverHans [25] and Foolbox [26], which are two popular Python packages to craft adversarial examples for machine learning models.\n\nA. Efficiency evaluation a) Baselines: We compare HopSkipJumpAttack with three state-of-the-art decision-based attacks: Boundary Attack [14], Limited Attack [9] and Opt Attack [16]. We use the implementation of the three algorithms with the suggested hyperparameters from the publicly available source code online. Limited Attack is only included under the targeted \u221e setting, as in Ilyas et al. [9]. b) Data and models: For a comprehensive evaluation of HopSkipJumpAttack, we use a wide range of data and models, with varied image dimensions, data set sizes, complexity levels of task and model structures.\n\nThe experiments are carried out over four image data sets: MNIST, CIFAR-10 [27], CIFAR-100 [27], and ImageNet [28] with the standard train/test split [29]. The four data sets have varied image dimensions and class numbers. MNIST contains 70K 28 \u00d7 28 gray-scale images of handwritten digits in the range 0-9. CIFAR-10 and CIFAR-100 are both composed of 32\u00d732\u00d73 images. CIFAR-10 has 10 classes, with 6K images per class, while CIFAR-100 has 100 classes, with 600 images per class. ImageNet has 1, 000 classes. Images in ImageNet are rescaled to 224 \u00d7 224 \u00d7 3. For MNIST, CIFAR-10 and  CIFAR-100, 1, 000 correctly classified test images are used, which are randomly drawn from the test data set, and evenly distributed across classes. For ImageNet, we use 100 correctly classified test images, evenly distributed among 10 randomly selected classes. The selection scheme follows Metzen et al. [30] for reproducibility.\n\nWe also use models of varied structure, from simple to complex. For MNIST, we use a simple convolutional network composed of two convolutional layers followed by a hidden dense layer with 1024 units. Two convolutional layers have 32, 64 filters respectively, each of which is followed by a max-pooling layer. For both CIFAR-10 and CIFAR-100, we train a 20-layer ResNet [31] and 121-layer DenseNet [32] respectively, with the canonical network structure [29]. For ImageNet, we use a pre-trained 50-layer ResNet [31]. All models achieve close to state-of-the-art accuracy on the respective data set. All pixels are scaled to be in the range For targeted attack, the target class is sampled uniformly among the incorrect labels. An image belonging to the target class is randomly sampled from the test set as the initialization. The same target class and a common initialization image are used for all attacks.\n\n\nd) Metrics:\n\nThe first metric is the median p distance between perturbed and original samples over a subset of test images, which was commonly used in previous work, such as Carlini and Wagner [6]. A version normalized by image dimension was employed by Brendel et al. [14] for evaluating Boundary Attack. The 2 distance can be interpreted in the following way: Given a byte image of size h\u00d7w\u00d73, perturbation of size d in 2 distance on the rescaled input image amounts to perturbation on the original image of d/ \u221a h \u00d7 w \u00d7 3 * 255 bits per pixel on average, in the range [0, 255]. The perturbation of size d in \u221e distance amounts to a maximum perturbation of 255 \u00b7 d bits across all pixels on the raw image.\n\nAs an alternative metric, we also plot the success rate at various distance thresholds for both algorithms given a limited budget of model queries. An adversarial example is defined a success if the size of perturbation does not exceed a given distance threshold. The success rate can be directly related to the accuracy of a model on perturbed data under a given    Table I summarizes the median distance when the number of queries is fixed at 1,000, 5,000, and 20,000 across all distance types, data, models and objectives. Figure 5 and 6 show the success rate against the distance threshold. Figure 3 and 5 contain results on MNIST with CNN, and CIFAR-10 with ResNet, Denset, subsequently from the top row to the bottom row. Figure 4  By comparing the odd and even columns of Figure 3-6, we can find that targeted HopSkipJumpAttack takes more queries than the untargeted one to achieve a comparable distance. This phenomenon becomes more explicit on CIFAR-100 and ImageNet, which have more classes. With the same number of queries, there is an order-of-magnitude difference in median distance between untargeted and targeted attacks (Figure 3 and 4). For 2 -optimized HopSkipJumpAttack, while the untargeted version is able to craft adversarial images by perturbing 4 bits per pixel on average within 1,000 queries for 70% \u2212 90% of images in CIFAR-10 and CIFAR-100, the targeted counterpart takes 2,000-5,000 queries. The other attacks fail to achieve a comparable performance even with 25,000 queries. On ImageNet, untargeted 2 -optimized Hop-SkipJumpAttack is able to fool the model with a perturbation of size 6 bits per pixel on average for close to 50% of images with 1, 000 queries; untargeted \u221e -optimized Hop-SkipJumpAttack controls the maximum perturbation across all pixels within 16 bits for 50% images within 1, 000 queries. The targeted Boundary Attack is not able to control the perturbation size to such a small scale until after around 25, 000 queries. On the one hand, the larger query budget requirement results from a strictly more powerful formulation of targeted attack than untargeted attack. On the other hand, this is also because we initialize targeted HopSkipJumpAttack from an arbitrary image in the target class. The algorithm may be trapped in a bad local minimum with such an initialization. Future work can address systematic approaches to better initialization.\n\nAs a comparison between data sets and models, we see that adversarial images often have a larger distance to their corresponding original images on MNIST than on CIFAR-10 and CIFAR-100, which has also been observed in previous work (e.g., [6]). This might be because it is more difficult to fool a model on simpler tasks. On the other hand, Hop-SkipJumpAttack also converges in a fewer number of queries on MNIST, as is shown in Figure 3. It does not converge even after 25, 000 queries on ImageNet. We conjecture the query budget is related to the input dimension, and the smoothness of decision boundary. We also observe the difference in model structure does not have a large influence on decision-based algorithms, if the training algorithm and the data set keep the same. For ResNet and DenseNet trained on a common data set, a decision-based algorithm achieves comparable performance in crafting adversarial examples, although DenseNet has a more complex structure than ResNet.\n\nAs a comparison with state-of-the-art white-box targeted attacks, C&W attack [6] achieves an average 2 -distance of 0.33 on CIFAR-10, and BIM [3] achieves an average \u221edistance of 0.014 on CIFAR-10. Targeted HopSkipJumpAttack achieves a comparable distance with 5K-10K model queries on CIFAR-10, without access to model details. On ImageNet, targeted C&W attack and BIM achieve an 2 -distance of 0.96 and an \u221e -distance of 0.01 respectively. Untargeted HopSkipJumpAttack achieves a comparable performance with 10, 000 \u2212 15, 000 queries. The targeted version is not able to perform comparably as targeted white-box attacks when the budget of queries is limited within 25, 000.  \n\n\nB. Defense mechanisms under decision-based attacks\n\nWe investigate the robustness of various defense mechanisms under decision-based attacks.\n\na) Defense mechanisms: Three defense mechanisms are evaluated: defensive distillation, region-based classification, and adversarial training. Defensive distillation [33], a form of gradient masking [13], trains a second model to predict the output probabilities of an existing model of the same structure. We use the implementaion provided by Carlini and Wagner [6] for defensive distillation. The second defense, region-based classification, belongs to a wide family of mechanisms which add test-time randomness to the inputs or the model, causing the gradients to be randomized [34]. Multiple variants have been proposed to randomize the gradients [35][36][37][38][39]. We adopt the implementation in Cao and Gong [35] with suggested noise levels. Given a trained base model, region-based classification samples points from the hypercube centered at the input image, predicts the label for each sampled point with the base model, and then takes a majority vote to output the label. Adversarial training [2,3,7,17] is known to be one of the most effective defense mechanisms against adversarial perturbation [34,40]. We evaluate a publicly available model trained through a robust optimization method proposed by Madry et al. [7]. We further evaluate our attack method by constructing a non-differentiable model via input binarization followed by a random forest in Appendix C. The evaluation is carried out on MNIST, where defense mechanisms such as adversarial training work most effectively.\n\nb) Baselines: We compare our algorithm with state-of-the-art attack algorithms that require access to gradients, including C&W Attack [6], DeepFool [4] for minimizing 2 -distance, and FGSM [2], and BIM [7,41] for minimizing \u221e -distance. For region-based classification, the gradient of the base classifier is taken with respect to the original input.\n\nWe further include methods designed specifically for the defense mechanisms under threat. For defensive distillation, we include the \u221e -optimized C&W Attack [6]. For regionbased classification, we include backward pass differentiable approximation (BPDA) [34], which calculates the gradient of the model at a randomized input to replace the gradient at the original input in C&W Attack and BIM. All of these methods assume access to model details or even defense mechanisms, which is a stronger threat model than the one required for decision-based attacks. We also include Boundary Attack as a decision-based baseline.\n\nFor HopSkipJumpAttack and Boundary Attack, we include the success rate at three different scales of query budget: 2K, 10K and 50K, so as to evaluate our method both with limited queries and a sufficient number of queries. We find the convergence of HopSkipJumpAttack becomes unstable on region-based classification, resulting from the difficulty of locating the boundary in the binary search step when uncertainty is increased near the boundary. Thus, we increase the binary search threshold to 0.01 to resolve this issue. c) Results: Figure 8 shows the success rate of various attacks at different distance thresholds for the three defense mechanisms. On all of the three defenses, HopSkipJumpAttack demonstrates similar or superior performance compared to state-of-the-art white-box attacks with sufficient model queries. Even with only 1K-2K model queries, it also achieves acceptable performance, although worse than the best whitebox attacks. With sufficient queries, Boundary Attack achieves a comparable performance under the 2 -distance metric. But it is not able to generate any adversarial examples when the number of queries is limited to 1, 000. We think this is because the strength of our batch gradient direction estimate over the random walk step in Boundary Attack becomes more explicit when there is uncertainty or non-smoothness near the decision boundary. We also observe that Boundary Attack does not work in optimizing the \u221e -distance metric for adversarial examples, making it difficult to evaluate defenses designed for \u221e distance, such as adversarial training proposed by Madry et al. [7]. On a distilled model, when the \u221e -distance is thresholded at 0.3, a perturbation size proposed by Madry et al. [7] to measure adversarial robustness, HopSkipJumpAttack achieves success rates of 86% and 99% with 1K and 50K queries respectively. At an 2 -distance of 3.0, the success rate is 91% with 2K queries. HopSkipJumpAttack achieves a comparable performance with C&W attack under both distance metrics with 10K-50K queries. Also, gradient masking [13] by defensive distillation does not have a large influence on the query efficiency of HopSkipJumpAttack, indicating that the gradient direction estimate is robust under the setting where the model does not have useful gradients for certain white-box attacks.\n\nOn region-based classification, with 2K queries, Hop-SkipJumpAttack achieves success rates of 82% and 93% at the same \u221e -and 2 -distance thresholds respectively. With 10K-50K queries, it is able to achieve a comparable performance to BPDA, a white-box attack tailored to such defense mechanisms. On the other hand, we observe that Hop-SkipJumpAttack converges slightly slower on region-based classification than itself on ordinary models, which is because stochasticity near the boundary may prevent binary search in HopSkipJumpAttack from locating the boundary accurately.\n\nOn an adversarially trained model, HopSkipJumpAttack achieves a success rate of 11.0% with 50K queries when the \u221e -distance is thresholded at 0.3. As a comparison, BIM   has a success rate of 7.4% at the given distance threshold. The success rate of \u221e -HopSkipJumpAttack transfers to an accuracy of 87.58% on adversarially perturbed data, close to the state-of-the-art performance achieved by white-box attacks. 3 With 1K queries, HopSkipJumpAttack also achieves comparable performance to BIM and C&W attack.\n\n\nVI. DISCUSSION\n\nWe have proposed a family of query-efficient algorithms based on a novel gradient-direction estimate, HopSkipJumpAttack, for decision-based generation of adversarial examples, which is capable of optimizing 2 and \u221e -distances for both targeted and untargeted attacks. Convergence analysis has been carried out given access to the gradient. We have also provided analysis for the error of our Monte Carlo estimate of gradient direction, which comes from three sources: bias at the boundary for a nonzero perturbation size, bias of deviation from the boundary, and variance. Theoretical analysis has provided insights for selecting the step size and the perturbation size, which leads to a hyperparameter-free algorithm. We have also carried out extensive experiments, showing HopSkipJumpAttack compares favorably to Boundary Attack in query efficiency, and achieves competitive performance on several defense mechanisms. 3 See https://github.com/MadryLab/mnist challenge.\n\nGiven the fact that HopSkipJumpAttack is able to craft a human-indistinguishable adversarial example within a realistic budget of queries, it becomes important for the community to consider the real-world impact of decision-based threat models. We have also demonstrated that HopSkipJumpAttack is able to achieve comparable or even superior performance to state-of-the-art white-box attacks on several defense mechanisms, under a much weaker threat model. In particular, masked gradients, stochastic gradients, and nondifferentiability are not barriers to our algorithm. Because of its effectiveness, efficiency, and applicability to nondifferentiable models, we suggest future research on adversarial defenses may evaluate the designed mechanism against HopSkipJumpAttack as a first step.\n\nOne limitation of all existing decision-based algorithms, including HopSkipJumpAttack, is that they require evaluation of the target model near the boundary. They may not work effectively by limiting the queries near the boundary, or by widening the decision boundary through insertion of an additional \"unknown\" class for inputs with low confidence. We have also observed that it still takes tens of thousands of model queries for HopSkipJumpAttack to craft imperceptible adversarial examples with a target class on ImageNet, which has a relatively large image size. Future work may seek the combination of HopSkipJumpAttack with transfer-based attack to resolve these issues.\n\n\nVII. ACKNOWLEDGEMENT\n\nWe would like to thank Nicolas Papernot and anonymous reviewers for providing their helpful feedback.\n\n\nAPPENDIX A PROOFS\n\nFor notational simplicity, we use the shorthand S \u2261 S x throughout the proofs.\n\n\nA. Proof of Theorem 1\n\nWe denote \u03c4 t := \u03be t / \u2207S(x t ) 2 , so that the update (3) at iterate t can be rewritten as\nx t+1 = \u03b1 t x + (1 \u2212 \u03b1 t )(x t + \u03c4 t \u2207S(x t )).(18)\nLet the step size choice \u03be t = \u03b7 t x t \u2212 x with \u03b7 t := t \u2212q , we have \u03c4 t = \u03b7 t xt\u2212x \u2207S(xt) .\n\nThe squared distance ratio is\nx t+1 \u2212 x 2 2 x t \u2212 x 2 2 = (1 \u2212 \u03b1)(\u03c4 t \u2207S(x t ) + x t \u2212 x ) 2 2 x t \u2212 x 2 2 .(19)\nBy a second-order Taylor series, we have\n0 = \u2207S(x t ), x t+1 \u2212 x t + 1 2 (x t+1 \u2212 x t ) T H t (x t+1 \u2212 x t ),(20)\nwhere\nH t = \u2207 2 S(\u03b2x t+1 + (1 \u2212 \u03b2)x t ) for some \u03b2 \u2208 [0, 1].\nPlugging equation (18) into equation (20) yields\n\u2207S(x t ), \u2212\u03b1v t + \u03c4 t \u2207S(x t ) + 1 2 (\u2212\u03b1v t + \u03c4 t \u2207S(x t )) T H t (\u2212\u03b1v t + \u03c4 t \u2207S(x t )) = 0,(21)\nwhere we define v t := x t \u2212 x + \u03c4 t \u2207S(x t ). This can be rewritten as a quadratic equation with respect to \u03b1:\nv T t H t v t \u03b1 2 \u2212 2\u2207S(x t ) T (I + \u03c4 t H t )v t \u03b1 + \u2207S(x t ) T (\u03c4 2 t H t + 2\u03c4 t I)\u2207S(x t ) = 0.(22)\nSolving for \u03b1 yields\n\u03b1 \u2265 \u2207S(x t ) T (\u03c4 2 t H t + 2\u03c4 t I)\u2207S(x t ) 2\u2207S(x t ) T (I + \u03c4 t H t )v t .(23)\nIn order to simplify the notation, define \u2207 t := \u2207S(x t ) and d t := x t \u2212 x . Hence, we have\n(1 \u2212 \u03b1) 2 \u2264 r t + \u03b7 t \u00b7 3 2 L dt 2 \u2207t 2 r t + \u03b7 t \u00b7 (1 + 3 2 L dt 2 \u2207t 2 ) 2 , where r t = x t \u2212 x , \u2207S(x t ) x t \u2212 x 2 \u2207S(x t ) 2 = d t , \u2207 t d t 2 \u2207 t 2 .(24)\nLet \u03ba t := 3 2 L dt 2 \u2207t 2 . Then \u03ba t is bounded when \u2207 t 2 \u2265C and q > 1 2 . Equation (19) and the bound on\n(1 \u2212 \u03b1) 2 yield x t+1 \u2212 x 2 2 x t \u2212 x 2 2 \u2264 r t + \u03b7 t \u03ba t r t + \u03b7 t (1 + \u03ba t ) 2 \u00b7 (\u03b7 2 t + 2\u03b7 t r t + 1).(25)\nDefine \u03b8 t := rt+\u03b7t\u03bat rt+\u03b7t(1+\u03bat) 2 \u00b7 (\u03b7 2 t + 2\u03b7 t r t + 1). We analyze \u03b8 t in the following two different cases: r t < \u03b7 t and r t \u2265 \u03b7 t . In the first case, we have\n\u03b8 t \u2264 1 + \u03ba t 1 + (1 + \u03ba t ) 2 \u00b7 (\u03b7 2 t + 2\u03b7 2 t + 1).(26)\nAs long as \u03b7 t \u2192 0 as t \u2192 \u221e, there exists a positive constant c 2 > 0 such that \u03b8 t < 1 \u2212 c 2 for t large enough.\n\nIn the second case, we have r t \u2265 \u03b7 t . Define \u03bb t := \u03b7t rt \u2264 1. We bound \u03b8 t by\n\u03b8 t = (1 + 2\u03bb t \u03ba t + \u03bb 2 t \u03ba 2 t )(\u03b7 2 t + 2\u03b7 t r t + 1) 1 + 2\u03bb t (1 + \u03ba t ) + \u03bb 2 t (1 + \u03ba t ) 2 \u2264 1 + 2\u03bb t \u03ba t + \u03bb 2 t \u03ba 2 t + 2\u03bb t r 2 t 1 + 2\u03bb t \u03ba t + \u03bb 2 t \u03ba 2 t + 2\u03bb t + \u03b7 2 t (4\u03ba t + (1 + \u03bb t \u03ba t ) 2 + 2\u03bb t \u03ba 2 t ) \u2264 1 \u2212 2\u03bb t (1 \u2212 r 2 t ) 1 + 2\u03bb t \u03ba t + \u03bb 2 t \u03ba 2 t + 2\u03bb t + c\u03b7 2 t \u2264 1 \u2212 c 1 \u03bb t (1 \u2212 r 2 t ) + c 2 \u03b7 2 t ,\nwhere c 1 , c 2 are fixed constants. As the product of \u03b8 t over t is positive, we have\n\u221e t=1 log \u03b8 t = log \u03a0 \u221e t=1 \u03b8 t > \u2212\u221e.(27)\nThen we have that there are at most a finite number of t that falls in the first case, r t < \u03b7 t . In the second case, Equation (27) is equivalent to\n\u221e t=1 c 1 \u03b7 t 1 \u2212 r 2 t r t \u2212 c 2 \u03b7 2 t < \u221e, which implies c 1 \u03b7 t 1\u2212r 2 t rt \u2212 c 2 \u03b7 2 t = o(t \u22121 ). When \u03b7 t = t \u2212q for some constant 1 2 < q < 1, we have 1 \u2212 r 2 t r t = o(t q\u22121 ).\nHence we have 1 \u2212 r t = o(t q\u22121 ).\n\n\nB. Proof of Theorem 2\n\nLet u be a random vector uniformly distributed on the sphere. By Taylor's theorem, for any \u03b4 \u2208 (0, 1), we have\nS(x t + \u03b4u) = \u03b4\u2207S(x t ) T u + 1 2 \u03b4 2 u T \u2207 2 S(x )u.(28)\nfor some x on the line between x t and x t + \u03b4u, where we have made use of the fact that S(x t ) = 0. As the function S has Lipschitz gradients, we can bound the second-order term as\n| 1 2 \u03b4 2 u T \u2207 2 S(x )u| \u2264 1 2 L\u03b4 2 .(29)\nLet w := 1 2 L\u03b4. By the Taylor expansion and the bound on the second-order term by eigenvalues, when \u2207S(x t ) T u > w, we have\nS(x t + \u03b4u) \u2265 \u03b4\u2207S(x t ) T u + 1 2 \u03b4 2 u T \u2207 2 S(x )u \u2265 \u03b4(\u2207S(x t ) T u \u2212 1 2 L\u03b4) > 0.\nSimilarly, we have S(x t + \u03b4u) < 0 when \u2207S(x t ) T u < \u2212w. Therefore, we have\n\u03c6 x (x t + \u03b4u) = 1 if \u2207S(x t ) T u > w, \u22121 if \u2207S(x t ) T u < \u2212w.\nWe expand the vector \u2207S(x t ) to an orthogonal bases in R d : \nE[\u03b2 i | E 1 ] = E[\u03b2 i | E 3 ] = 0.\nTherefore, the expected value of the estimator is\nE[\u03c6 x (x t + \u03b4u)u] = p \u00b7 E[\u03c6 x (x t + \u03b4u)u | E 2 ] \u2212 1 2 E[\u03b2 1 v 1 | E 1 ] \u2212 1 2 E[\u2212\u03b2 1 v 1 | E 3 ] + E[\u03b2 1 v 1 | E 1 ] + E[\u2212\u03b2 1 v 1 | E 3 ]\nExploiting the above derivation, we can bound the difference between E[|\u03b2\n1 |v 1 ] = E|\u03b21| \u2207S(xt) 2 \u2207S(x t ) and E[\u03c6 x (x t + \u03b4u)u]: E[\u03c6 x (x t + \u03b4u)u] \u2212 E[|\u03b2 1 |v 1 ] 2 \u2264 2p + p = 3p, which yields cos \u2220 (E[\u03c6 x (x t + \u03b4u)u], \u2207S(x t )) \u2265 1 \u2212 1 2 3p E|\u03b2 1 | 2 .(30)\nWe can bound p by observing that \u2207S(xt)\n\u2207S(xt) 2 , u 2 is a Beta distribution B( 1 2 , d\u22121 2 ): p = P \u2207S(x t ) \u2207S(x t ) 2 , u 2 \u2264 w 2 \u2207S(x t ) 2 2 \u2264 2w B( 1 2 , d\u22121 2 ) \u2207S(x t ) 2 .\nPlugging into Equation (30), we get\ncos \u2220 (E[\u03c6 x (x t + \u03b4u)u], \u2207S(x t )) \u2265 1 \u2212 18w 2 (E|\u03b2 1 |) 2 B( 1 2 , d\u22121 2 ) 2 \u2207S(x t ) 2 2 = 1 \u2212 9L 2 \u03b4 2 (d \u2212 1) 2 8 \u2207S(x t ) 2 2 .\nWe also observe that\nE \u2207S(x t , \u03b4) = E[\u03c6 x (x t + \u03b4u)u].\nAs a consequence, we have established\ncos \u2220 E[ \u2207S(x t , \u03b4)], \u2207S(x t ) \u2265 1 \u2212 9L 2 \u03b4 2 (d \u2212 1) 2 8 \u2207S(x t ) 2 2 .\nTaking \u03b4 \u2192 0, we get lim \u03b4\u21920 cos\u2220 E[ \u2207S(x t , \u03b4)], \u2207S(x t ) = 1.\n\n\nC. Proof of Theorem 3\n\nProof. For notational simplicity, we denote\n\u03be b := \u03c6 x (x t + \u03b4u b ), and\u03be = 1 B B b=1 \u03be b = \u03c6 x .\nWe use \u03be, u to denote i.i.d. copies of \u03be b and u b respectively. By exploiting independence of u a , u b and independence of \u03be a u a , \u03be b u b , the variance of the estimate with the baseline can be expressed as\nVar( \u2207S(x t , \u03b4)) = 1 (B \u2212 1) 2 B a=1 E \u03be a u a \u2212 E[\u03beu] 2 2 \u2212 2E[\u03be\u03be a ]+ E\u03be 2 + ( 2 B \u2212 1 B 2 ) E[\u03beu] 2 + E\u03beu 2 2 B(B \u2212 1) = B 2 Var( \u2207S(x t , \u03b4)) (B \u2212 1) 2 \u2212 BE[\u03be 2 ] (B \u2212 1) 2 + (3B \u2212 2) E[\u03beu] 2 2 B(B \u2212 1) 2 \u2264 B 2 Var( \u2207S(x t , \u03b4)) (B \u2212 1) 2 \u2212 BE[\u03be 2 ] (B \u2212 1) 2 + 3B \u2212 2 B(B \u2212 1) 2 .(31)\nThe middle term can be expanded as\n\u2212 B (B \u2212 1) 2 E[\u03be 2 ] = \u2212 1 (B \u2212 1) 2 \u2212 4 B \u2212 1 (E\u03be \u2212 1 2 ) 2 .\nPlugging into Equation (31), we get\nVar( \u2207S(x t , \u03b4)) = Var( \u2207S(x t , \u03b4)) 1 + 2B \u2212 1 (B \u2212 1) 2 \u2212 2 \u03c3 2 (B \u2212 1) 2B(E[\u03be] \u2212 1 2 ) 2 \u2212 1 . When E[\u03be] satisfies (E[\u03be] \u2212 1 2 ) 2 > 1 2B (1 + 2B\u22121 2B\u22122 \u03c3 2 ), we have 2B \u2212 1 (B \u2212 1) 2 < 2 \u03c3 2 (B \u2212 1) (2B(E[\u03be] \u2212 1 2 ) 2 \u2212 1),\nwhich implies Var( \u2207S(x t , \u03b4)) < Var( \u2207S(x t , \u03b4)).\n\n\nAPPENDIX B SENSITIVITY ANALYSIS\n\nIn this section, we carry out experiments to evaluate the hyperparameters suggested by our theoretical analysis. We use a 20-layer ResNet [31] trained over CIFAR-10 [27]. We run the a) Choice of step size: We compare several schemes of choosing step size at each step. The first scheme is suggested by Theorem 1: at the t-th step, we set \u03be t = x t \u2212 x 2 / \u221a t, which we call \"Scale with Distance (Sqrt. Decay).\" We include the other two scales which scale with distance, \"Scale with Distance (Linear Decay)\" with \u03be t = x t \u2212 x 2 /t and \"Scale with Distance (No Decay)\" with \u03be t = x t \u2212 x 2 . We then include \"Grid Search,\" which searchs step sizes over a logscale grid, and chooses the step size that best controls the distance with the original sample after projecting the updated sample back to the boundary via binary search. Finally, we include constant stepsizes at \u03be t = 0.01, 0.1, 1.0. For all schemes, we always use geometric progression to decrease the step size by half until \u03c6 x (x t ) = 1 before the next binary search step.  Figure 9 plots the median distance against the number of queries for all schemes. We observe that the scheme suggested by Theorem 1 achieves the best performance in this experiment. Grid search costs extra query budget initially but eventually achieves a comparable convergence rate. When the step size scales with the distance but with inappropriately chosen decay, the algorithm converges slightly slower. The performance of the algorithm suffers from a constant step size.\n\n\nb) Choice of perturbation size and introduction of baseline:\n\nWe now study the effectiveness of the proposed perturbation size and baseline for estimating gradient direction when the sample deviates from the boundary. In particular, we focus on the choice of \u03b4 t and the introduction of baseline analyzed in Section IV. Gradient direction estimation is carried out at perturbed images at the ith iteration, for i = 10, 20, 30, 40, 50, 60.\n\nWe use the cosine of the angle between the gradient-direction estimate and the truth gradient of the model as a metric. Figure 10 shows the box plots of two gradient-direction estimates as \u03b4 t varies among 0.01\u03b4 * t , 0.1\u03b4 * t , \u03b4 * t , 10\u03b4 * t , 100\u03b4 * t , where \u03b4 * t = 10 \u221a d\u03b8 x t\u22121 \u2212 x 2 is our proposed choice. We observe that our proposed choice of \u03b4 t yields the highest cosine of the angle on average. Also, the baseline in \u2207S further improves the performance, in particular when \u03b4 t is not chosen optimally so that there is severe unevenness in the distribution of perturbed images. \n\n\nAPPENDIX C MODEL WITHOUT GRADIENTS\n\nIn this section, we evaluate HopSkipJumpAttack on a model without gradients. We aim to show HopSkipJumpAttack is able to craft adversarial examples under weaker conditions, such as non-differentiable models, or even discontinuous input transform.\n\nConcretely, we implement input binarization followed by a random forest on MNIST. Binarization transforms an input image to an array of {0, 1}, but transforming all pixels larger than a given threshold to 1, and all pixels smaller than the threshold to 0. The algorithm for training random forests applies bootstrap aggregating to tree learners. We implement the random forest with default parameters in scikit-learn [42], using the Gini impurity as split criterion. For each split, \u221a d randomly selected features are used, where d = 28 \u00d7 28 is the number of pixels. We evaluate two random forests with different thresholds for binarization: 0.1 and 0.5. With the first threshold, the model achieves the highest accuracy, 96%, on natural test data. The second threshold yields the most robust performance under adversarial perturbation, with accuracy 94.5% on natural test data.\n\nFor both Boundary Attack and HopSkipJumpAttack, we adopt the same initialization and hyper-parameters as in Section V-A. The original image (with real values) is used as input to both attacks for model queries. When an image is fed into the model by the attacker, the model processes the image with binarization first, followed by the random forest. Such a design preserves the black-box assumption for decision-based attacks. We only focus on untargeted 2 attack here. Note that over 91% of the pixels on MNIST are either greater than 0.9 or less than 0.1, and thus require a perturbation of size at least 0.4 to change their outputs after being thresholded by 0.5. This fact makes \u221e perturbation inappropriate for crafting adversarial examples.  Figure 12: Success rate versus distance threshold on MNIST with binarization + random forest. The threshold of binarization is set to be 0.1 and 0.5 respectively. Figure 11 shows the median distance (on a log scale) against the queries, with the first and third quartiles used as lower and upper error bars. Figure 12 shows the success rate against the distance threshold.\n\nWhen the threshold is set to be 0. When the threshold is set to be 0.5, we have a more robust model. A median 2 distance of 3 is achieved by HopSkipJumpAttack through 3K model queries. It takes 25K queries to achieve 99% success rate at an 2 distance of 3 for HopSkipJumpAttack. On the other hand, we observe that Boundary Attack only achieves a median distance of 5 even with 25K model queries. This might result from the inefficiency in spending queries on random walk instead of \"gradient direction\" estimation step in HopSkipJumpAttack. We remark that the concept of \"gradient direction\" requires an alternative definition in the current setting, such as a formulation via subgradients.\n\nFigure 2 :\n2Intuitive explanation of HopSkipJumpAttack. (a) Perform a binary search to find the boundary, and then updat\u1ebd x t \u2192 x t . (b) Estimate the gradient at the boundary point x t . (c) Geometric progression and then update x t \u2192x t+1 . (d) Perform a binary search, and then updatex t+1 \u2192 x t+1 .\n\nFigure 3 :\n3Median distance versus number of model queries on MNIST with CNN, and CIFAR-10 with ResNet and DenseNet from top to bottom rows. 1st column: untargeted 2 . 2nd col.: targeted 2 . 3rd col.: untargeted \u221e . 4th col.: targeted \u221e .\n\nFigure 4 :\n4Median distance versus number of model queries on CIFAR-100 with ResNet, DenseNet, and ImageNet with ResNet from top to bottom rows. 1st column: untargeted 2 . 2nd col.: targeted 2 . 3rd col.: untargeted \u221e . 4th col.: targeted \u221e . distance threshold: perturbed acc. = original acc. \u00d7 (1 \u2212 success rate). (17) Throughout the experiments, we limit the maximum budget of queries per image to 25,000, the setting of practical interest, due to limited computational resources. e) Results: Figure 3 and 4 show the median distance (on a log scale) against the queries, with the first and third quartiles used as lower and upper error bars. For Boundary, Opt and HopSkipJumpAttack,\n\nFigure 5 :\n5Success rate versus distance threshold for MNIST with CNN, and CIFAR-10 with ResNet, DenseNet from top to bottom rows. 1st column: untargeted 2 . 2nd column: targeted 2 . 3rd column: untargeted \u221e . 4th column: targeted \u221e .\n\n\nVisualized trajectories of HopSkipJumpAttack optimized for 2 distances along varied queries on CIFAR10 and ImageNet can be found inFigure 7. On CIFAR-10, we observe untargeted adversarial examples can be crafted within around 500\n\nFigure 7 :\n7Visualized trajectories of HopSkipJumpAttack for optimizing 2 distance on randomly selected images in CIFAR-10 and ImageNet. 1st column: initialization (after blended with original images). 2nd-9th columns: images at 100, 200, 500, 1K, 2K, 5K, 10K, 25K model queries. 10th column: original images.\n\nFigure 8 :\n8Success rate versus distance threshold for a distilled model, a region-based classifier and an adversarially trained model on MNIST. Blue, magenta, cyan and orange lines are used for HopSkipJumpAttack and Boundary Attack at the budget of 1K, 2K, 10K and 50K respectively. Different attacks are plotted with different line styles. An amplified figure is included near the critical \u221e -distance of 0.3 for adversarial training.\n\nv 1 =\n1\u2207S(x t )/ \u2207S(x t ) 2 , v 2 , . . . , v d . The random vector u can be expressed as u = d i=1 \u03b2 i v i , where \u03b2 is uniformly distributed on the sphere. Denote the upper cap as E 1 := {\u2207S(x t ) T u > w}, the annulus as E 2 := {|\u2207S(x t ) T u| < w}, and the lower cap as E 3 := {\u2207S(x t ) T u < \u2212w}. Let p := P(E 2 ) be the probability of event E 2 . Thus we have P(E 1 ) = P(E 3 ) = (1 \u2212 p)/2. By symmetry, for any i = 1, we have\n\nFigure 9 :\n9Comparison of various choices of step size.\n\nFigure 10 :\n10Box plots of the cosine of the angle between the proposed estimates and the true gradient.\n\nFigure 11 :\n11Median 2 distance versus number of model queries on MNIST with binarization + random forest. The threshold of binarization is set to be 0.1 and 0.5 respectively.\n\nTable I :\nIMedian distance at various model queries. The smaller median distance at a given model query is bold-faced. BA and HSJA stand for Boundary Attack and HopSkipJumpAttack respectively.Distance \nData \nModel \nObjective \n\nModel Queries \n1K \n5K \n20K \nBA \nOpt \nHSJA \nBA \nOpt \nHSJA \nBA \nOpt \nHSJA \n\n2 \n\nMNIST \nCNN \nUntargeted \n6.14 \n6.79 \n2.46 \n5.45 \n3.76 \n1.67 \n1.50 \n2.07 \n1.48 \nTargeted \n5.41 \n4.84 \n3.26 \n5.38 \n3.90 \n2.24 \n1.98 \n2.49 \n1.96 \n\nCIFAR10 \n\nResNet \nUntargeted \n2.78 \n2.07 \n0.56 \n2.34 \n0.77 \n0.21 \n0.27 \n0.29 \n0.13 \nTargeted \n7.83 \n8.21 \n2.53 \n5.91 \n4.76 \n0.41 \n0.59 \n1.06 \n0.21 \n\nDenseNet \nUntargeted \n2.57 \n1.78 \n0.48 \n2.12 \n0.67 \n0.18 \n0.21 \n0.28 \n0.12 \nTargeted \n7.70 \n7.65 \n1.75 \n5.33 \n3.47 \n0.34 \n0.35 \n0.78 \n0.19 \n\nCIFAR100 \n\nResNet \nUntargeted \n1.34 \n1.20 \n0.20 \n1.12 \n0.41 \n0.08 \n0.10 \n0.14 \n0.06 \nTargeted \n9.30 \n12.43 \n6.12 \n7.40 \n8.34 \n0.92 \n1.61 \n4.06 \n0.29 \n\nDenseNet \nUntargeted \n1.47 \n1.22 \n0.25 \n1.23 \n0.34 \n0.11 \n0.12 \n0.13 \n0.08 \nTargeted \n8.83 \n11.72 \n5.10 \n6.76 \n8.22 \n0.75 \n0.91 \n2.89 \n0.26 \n\nImageNet \nResNet \nUntargeted \n36.86 \n33.60 \n9.75 \n31.95 \n13.91 \n2.30 \n2.71 \n5.26 \n0.84 \nTargeted \n87.49 \n84.38 \n71.99 \n82.91 \n71.83 \n38.79 \n40.92 \n53.78 \n10.95 \n\n\u221e \n\nMNIST \nCNN \nUntargeted \n0.788 \n0.641 \n0.235 \n0.700 \n0.587 \n0.167 \n0.243 \n0.545 \n0.136 \nTargeted \n0.567 \n0.630 \n0.298 \n0.564 \n0.514 \n0.211 \n0.347 \n0.325 \n0.175 \n\nCIFAR10 \n\nResNet \nUntargeted \n0.127 \n0.128 \n0.023 \n0.105 \n0.096 \n0.008 \n0.019 \n0.073 \n0.005 \nTargeted \n0.379 \n0.613 \n0.134 \n0.289 \n0.353 \n0.028 \n0.038 \n0.339 \n0.010 \n\nDenseNet \nUntargeted \n0.114 \n0.119 \n0.017 \n0.095 \n0.078 \n0.007 \n0.017 \n0.063 \n0.004 \nTargeted \n0.365 \n0.629 \n0.130 \n0.249 \n0.359 \n0.022 \n0.025 \n0.338 \n0.008 \n\nCIFAR100 \n\nResNet \nUntargeted \n0.061 \n0.077 \n0.009 \n0.051 \n0.055 \n0.004 \n0.008 \n0.040 \n0.002 \nTargeted \n0.409 \n0.773 \n0.242 \n0.371 \n0.472 \n0.124 \n0.079 \n0.415 \n0.019 \n\nDenseNet \nUntargeted \n0.065 \n0.076 \n0.010 \n0.055 \n0.038 \n0.005 \n0.010 \n0.030 \n0.003 \nTargeted \n0.388 \n0.750 \n0.248 \n0.314 \n0.521 \n0.096 \n0.051 \n0.474 \n0.017 \n\nImageNet \nResNet \nUntargeted \n0.262 \n0.287 \n0.057 \n0.234 \n0.271 \n0.017 \n0.030 \n0.248 \n0.007 \nTargeted \n0.615 \n0.872 \n0.329 \n0.596 \n0.615 \n0.219 \n0.326 \n0.486 \n0.091 \n\n\n\n\nFigure 6: Success rate versus distance threshold for CIFAR-100 with ResNet, DenseNet, and ImageNet with ResNet from top to bottom rows. 1st column: untargeted 2 . 2nd column: targeted 2 . 3rd column: untargeted \u221e . 4th column: targeted \u221e .Success Rate \n\n1K \n\n1K \n\n1 K \n\n5K \n\n5 K \n\n5K \n\n25K 25K 25K \n\nUntargeted 2 (CIFAR100, ResNet) \n\n0.0 \n0.5 \n1.0 \n1.5 \n2.0 \n\n2 Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K 1K 1K \n\n5K \n\n5K 5K \n\n25K \n\n25 K \n\n25 K \n\nTargeted 2 (CIFAR100, ResNet) \n\n0.00 \n0.05 \n0.10 \n0.15 \n0.20 \n\n\u221e Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K \n\n1K \n1 K \n\n5K \n\n5 K 5K \n\n25K 25K 25K \n\nUntargeted \u221e (CIFAR100, ResNet) \n\n0.00 \n0.05 \n0.10 \n0.15 \n0.20 \n\n\u221e Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K 1K 1K 1K \n\n5 K \n\n5K 5K 5K \n\n25K \n25K \n\n25K \n25K \n\nTargeted \u221e (CIFAR100, ResNet) \n\n0.0 \n0.5 \n1.0 \n1.5 \n2.0 \n\n2 Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K \n\n1K \n\n1K \n\n5K \n\n5 K \n\n5K \n\n25K 25K 25K \n\nUntargeted 2 (CIFAR100, DenseNet) \n\n0.0 \n0.5 \n1.0 \n1.5 \n2.0 \n\n2 Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K 1K 1K \n\n5 K \n\n5K 5K \n\n25K \n\n25K \n\n25 K \n\nTargeted 2 (CIFAR100, DenseNet) \n\n0.00 \n0.05 \n0.10 \n0.15 \n0.20 \n\n\u221e Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K \n\n1 K \n\n1 K \n\n5K \n\n5 K 5K \n\n25K 25K 25K \n\nUntargeted \u221e (CIFAR100, DenseNet) \n\n0.00 \n0.05 \n0.10 \n0.15 \n0.20 \n\n\u221e Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K 1K 1K 1K \n\n5K \n\n5K 5K 5K \n\n25K 25K \n\n25K 25K \n\nTargeted \u221e (CIFAR100, DenseNet) \n\n0 \n10 \n20 \n30 \n\n2 Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K \n1K \n\n1K \n\n5K \n\n5K \n\n5 K \n\n25K 25K 25K \n\nUntargeted 2 (ImageNet, ResNet) \n\n0 \n10 \n20 \n30 \n\n2 Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K 1K 1K 5K 5K 5K \n\n25K \n\n25 K \n25K \n\nTargeted 2 (ImageNet, ResNet) \n\n0.0 \n0.1 \n0.2 \n0.3 \n0.4 \n\n\u221e Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K \n\n1K 1K \n\n5K \n\n5 K 5 K \n\n25K 25K \n\n25 K \n\nUntargeted \u221e (ImageNet, ResNet) \n\n0.0 \n0.1 \n0.2 \n0.3 \n0.4 \n\n\u221e Distance \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n0.8 \n\n1.0 \n\nSuccess Rate \n\n1K 1K 1K 1K \n\n5 K \n\n5K 5K 5K \n\n25K \n\n2 5 K \n\n2 5 K \n25 K \n\nTargeted \u221e (ImageNet, ResNet) \n\nqueries; targeted HopSkipJumpAttack is capable of crafting \nhuman indistinguishable targeted adversarial examples within \naround 1, 000 \u2212 2, 000 queries. On ImageNet, untargeted \nHopSkipJumpAttack is able to craft good adversarial examples \nwith 1, 000 queries, while targeted HopSkipJumpAttack takes \n10, 000 \u2212 20, 000 queries. \n\n\n\n\n1, the random forest with binarization becomes extremely vulnerable to adversarial examples. Around 96% adversarial examples fall into the size-3 2 -neighborhood of the respective original examples with 1K model queries of HopSkipJumpAttack. The vulnerability is caused by the ease of activating pixels through increasing the strength by 0.1. It also indicates HopSkipJumpAttack and Boundary Attack are able to craft adversarial examples without smooth decision boundaries.\nA hop, skip, and a jump originally referred to an exercise or game involving these movements dating from the early 1700s, but by the mid-1800s it was also being used figuratively for the short distance so covered.\n-optimized HopSkipJumpAttack over a subset of randomly sampled images.\n\nIntriguing properties of neural networks. Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus, In International Conference on Learning Representations. Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. In- triguing properties of neural networks. In International Confer- ence on Learning Representations, 2014.\n\nExplaining and harnessing adversarial examples. J Ian, Jonathon Goodfellow, Christian Shlens, Szegedy, Proceedings of the International Conference on Learning Representations. the International Conference on Learning RepresentationsIan J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. In Proceedings of the International Conference on Learning Representations, 2015.\n\nAdversarial machine learning at scale. Alexey Kurakin, Ian Goodfellow, Samy Bengio, International Conference on Learning Representations. Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial machine learning at scale. In International Conference on Learning Representations, 2017.\n\nDeepfool: a simple and accurate method to fool deep neural networks. Alhussein Seyed-Mohsen Moosavi-Dezfooli, Pascal Fawzi, Frossard, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionSeyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. Deepfool: a simple and accurate method to fool deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2574-2582, 2016.\n\nMatt Fredrikson, Z Berkay Celik, and Ananthram Swami. The limitations of deep learning in adversarial settings. Nicolas Papernot, Patrick Mcdaniel, Somesh Jha, 2016 IEEE European Symposium on Security and Privacy. IEEENicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrik- son, Z Berkay Celik, and Ananthram Swami. The limitations of deep learning in adversarial settings. In 2016 IEEE European Symposium on Security and Privacy, pages 372-387. IEEE, 2016.\n\nTowards evaluating the robustness of neural networks. Nicholas Carlini, David Wagner, 2017 IEEE Symposium on Security and Privacy. IEEENicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017 IEEE Symposium on Security and Privacy, pages 39-57. IEEE, 2017.\n\nTowards deep learning models resistant to adversarial attacks. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu, International Conference on Learning Representations. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. In International Confer- ence on Learning Representations, 2018.\n\nZoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models. Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, Cho-Jui Hsieh, Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. the 10th ACM Workshop on Artificial Intelligence and SecurityACMPin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho- Jui Hsieh. Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models. In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pages 15-26. ACM, 2017.\n\nBlack-box adversarial attacks with limited queries and information. Andrew Ilyas, Logan Engstrom, Anish Athalye, Jessy Lin, International Conference on Machine Learning. Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin. Black-box adversarial attacks with limited queries and information. In International Conference on Machine Learning, pages 2142-2151, 2018.\n\nPrior convictions: Black-box adversarial attacks with bandits and priors. Andrew Ilyas, Logan Engstrom, Aleksander Madry, International Conference on Learning Representations. Andrew Ilyas, Logan Engstrom, and Aleksander Madry. Prior convictions: Black-box adversarial attacks with bandits and pri- ors. In International Conference on Learning Representations, 2019.\n\nDelving into transferable adversarial examples and black-box attacks. Yanpei Liu, Xinyun Chen, Chang Liu, Dawn Song, Proceedings of the International Conference on Learning Representations. the International Conference on Learning RepresentationsYanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song. Delving into transferable adversarial examples and black-box attacks. In Proceedings of the International Conference on Learning Representations, 2017.\n\nTransferability in machine learning: from phenomena to black-box attacks using adversarial samples. Nicolas Papernot, Patrick Mcdaniel, Ian Goodfellow, arXiv:1605.07277arXiv preprintNicolas Papernot, Patrick McDaniel, and Ian Goodfellow. Transferability in machine learning: from phenomena to black-box attacks using adversarial samples. arXiv preprint arXiv:1605.07277, 2016.\n\nPractical blackbox attacks against machine learning. Nicolas Papernot, Patrick Mcdaniel, Ian Goodfellow, Somesh Jha, Ananthram Berkay Celik, Swami, Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. the 2017 ACM on Asia Conference on Computer and Communications SecurityACMNicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami. Practical black- box attacks against machine learning. In Proceedings of the 2017 ACM on Asia Conference on Computer and Communica- tions Security, pages 506-519. ACM, 2017.\n\nDecisionbased adversarial attacks: Reliable attacks against black-box machine learning models. Wieland Brendel, Jonas Rauber, Matthias Bethge, International Conference on Learning Representations. Wieland Brendel, Jonas Rauber, and Matthias Bethge. Decision- based adversarial attacks: Reliable attacks against black-box machine learning models. In International Conference on Learning Representations, 2018.\n\nGuessing smart: Biased sampling for efficient black-box adversarial attacks. Thomas Brunner, Frederik Diehl, Michael Truong Le, Alois Knoll, arXiv:1812.09803arXiv preprintThomas Brunner, Frederik Diehl, Michael Truong Le, and Alois Knoll. Guessing smart: Biased sampling for efficient black-box adversarial attacks. arXiv preprint arXiv:1812.09803, 2018.\n\nQuery-efficient hard-label black-box attack: An optimization-based approach. Minhao Cheng, Thong Le, Pin-Yu Chen, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, International Conference on Learning Representations. Minhao Cheng, Thong Le, Pin-Yu Chen, Huan Zhang, JinFeng Yi, and Cho-Jui Hsieh. Query-efficient hard-label black-box attack: An optimization-based approach. In International Con- ference on Learning Representations, 2019.\n\nEnsemble adversarial training: Attacks and defenses. Florian Tramr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick Mcdaniel, International Conference on Learning Representations. Florian Tramr, Alexey Kurakin, Nicolas Papernot, Ian Goodfel- low, Dan Boneh, and Patrick McDaniel. Ensemble adversarial training: Attacks and defenses. In International Conference on Learning Representations, 2018.\n\nOnline convex optimization in the bandit setting: gradient descent without a gradient. Adam Tauman Abraham D Flaxman, H Brendan Kalai, Mcmahan, Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms. the Sixteenth Annual ACM-SIAM Symposium on Discrete AlgorithmsSIAMAbraham D Flaxman, Adam Tauman Kalai, and H Brendan McMahan. Online convex optimization in the bandit setting: gradient descent without a gradient. In Proceedings of the Six- teenth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 385-394. SIAM, 2005.\n\nStochastic convex optimization with bandit feedback. Alekh Agarwal, P Dean, Foster, J Daniel, Hsu, M Sham, Alexander Kakade, Rakhlin, Advances in Neural Information Processing Systems. Alekh Agarwal, Dean P Foster, Daniel J Hsu, Sham M Kakade, and Alexander Rakhlin. Stochastic convex optimization with bandit feedback. In Advances in Neural Information Processing Systems, pages 1035-1043, 2011.\n\nRandom gradient-free minimization of convex functions. Yurii Nesterov, Vladimir Spokoiny, Foundations of Computational Mathematics. 172Yurii Nesterov and Vladimir Spokoiny. Random gradient-free minimization of convex functions. Foundations of Computa- tional Mathematics, 17(2):527-566, 2017.\n\nOptimal rates for zero-order convex optimization: The power of two function evaluations. C John, Michael I Duchi, Jordan, J Martin, Andre Wainwright, Wibisono, IEEE Transactions on Information Theory. 615John C Duchi, Michael I Jordan, Martin J Wainwright, and An- dre Wibisono. Optimal rates for zero-order convex optimization: The power of two function evaluations. IEEE Transactions on Information Theory, 61(5):2788-2806, 2015.\n\nZeroth-order stochastic variance reduction for nonconvex optimization. Sijia Liu, Bhavya Kailkhura, Pin-Yu Chen, Paishun Ting, Shiyu Chang, Lisa Amini, Advances in Neural Information Processing Systems. Sijia Liu, Bhavya Kailkhura, Pin-Yu Chen, Paishun Ting, Shiyu Chang, and Lisa Amini. Zeroth-order stochastic variance reduction for nonconvex optimization. In Advances in Neural Information Processing Systems, pages 3731-3741, 2018.\n\n. David Kincaid, David Ronald Kincaid, Elliott Ward Cheney, Numerical Analysis: Mathematics of Scientific Computing. 2American Mathematical SocDavid Kincaid, David Ronald Kincaid, and Elliott Ward Cheney. Numerical Analysis: Mathematics of Scientific Computing, vol- ume 2. American Mathematical Soc., 2009.\n\nThe Concentration of Measure Phenomenon. Number 89. Michel Ledoux, American Mathematical SocMichel Ledoux. The Concentration of Measure Phenomenon. Number 89. American Mathematical Soc., 2001.\n\nNicolas Papernot, Fartash Faghri, Nicholas Carlini, Ian Goodfellow, Reuben Feinman, Alexey Kurakin, Cihang Xie, Yash Sharma, Tom Brown, Aurko Roy, Alexander Matyasko, Vahid Behzadan, Karen Hambardzumyan, Zhishuai Zhang, Yi-Lin Juang, Zhi Li, Ryan Sheatsley, Abhibhav Garg, Jonathan Uesato, Willi Gierke, Yinpeng Dong, David Berthelot, arXiv:1610.00768Paul Hendricks, Jonas Rauber, and Rujun Long. Technical report on the cleverhans v2.1.0 adversarial examples library. arXiv preprintNicolas Papernot, Fartash Faghri, Nicholas Carlini, Ian Good- fellow, Reuben Feinman, Alexey Kurakin, Cihang Xie, Yash Sharma, Tom Brown, Aurko Roy, Alexander Matyasko, Vahid Behzadan, Karen Hambardzumyan, Zhishuai Zhang, Yi-Lin Juang, Zhi Li, Ryan Sheatsley, Abhibhav Garg, Jonathan Ue- sato, Willi Gierke, Yinpeng Dong, David Berthelot, Paul Hen- dricks, Jonas Rauber, and Rujun Long. Technical report on the cleverhans v2.1.0 adversarial examples library. arXiv preprint arXiv:1610.00768, 2018.\n\nFoolbox: A python toolbox to benchmark the robustness of machine learning models. Jonas Rauber, Wieland Brendel, Matthias Bethge, arXiv:1707.04131arXiv preprintJonas Rauber, Wieland Brendel, and Matthias Bethge. Foolbox: A python toolbox to benchmark the robustness of machine learning models. arXiv preprint arXiv:1707.04131, 2017.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, CiteseerTechnical reportAlex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009.\n\nImageNet: A Large-Scale Hierarchical Image Database. J Deng, W Dong, R Socher, L.-J Li, K Li, L Fei-Fei, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionJ. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei- Fei. ImageNet: A Large-Scale Hierarchical Image Database. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2009.\n\n. Fran\u00e7ois Chollet, Fran\u00e7ois Chollet et al. Keras. https://keras.io, 2015.\n\nOn detecting adversarial perturbations. Jan Hendrik Metzen, Tim Genewein, Volker Fischer, Bastian Bischoff, International Conference on Learning Representations. Jan Hendrik Metzen, Tim Genewein, Volker Fischer, and Bas- tian Bischoff. On detecting adversarial perturbations. In International Conference on Learning Representations, 2017.\n\nIdentity mappings in deep residual networks. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, European Conference on Computer Vision. SpringerKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In European Conference on Computer Vision, pages 630-645. Springer, 2016.\n\nDensely connected convolutional networks. Gao Huang, Zhuang Liu, Laurens Van Der Maaten, Kilian Q Weinberger, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionGao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4700-4708, 2017.\n\n. Nicolas Papernot, Patrick Mcdaniel, Xi Wu, Somesh Jha,Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and\n\nDistillation as a defense to adversarial perturbations against deep neural networks. Ananthram Swami, 2016 IEEE Symposium on Security and Privacy. IEEEAnanthram Swami. Distillation as a defense to adversarial perturbations against deep neural networks. In 2016 IEEE Symposium on Security and Privacy, pages 582-597. IEEE, 2016.\n\nObfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples. Anish Athalye, Nicholas Carlini, David Wagner, International Conference on Machine Learning. Anish Athalye, Nicholas Carlini, and David Wagner. Obfus- cated gradients give a false sense of security: Circumventing defenses to adversarial examples. In International Conference on Machine Learning, pages 274-283, 2018.\n\nMitigating evasion attacks to deep neural networks via region-based classification. Xiaoyu Cao, Neil Zhenqiang Gong, Proceedings of the 33rd Annual Computer Security Applications Conference. the 33rd Annual Computer Security Applications ConferenceACMXiaoyu Cao and Neil Zhenqiang Gong. Mitigating evasion at- tacks to deep neural networks via region-based classification. In Proceedings of the 33rd Annual Computer Security Applications Conference, pages 278-287. ACM, 2017.\n\nTowards robust neural networks via random self-ensemble. Xuanqing Liu, Minhao Cheng, Huan Zhang, Cho-Jui Hsieh, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)Xuanqing Liu, Minhao Cheng, Huan Zhang, and Cho-Jui Hsieh. Towards robust neural networks via random self-ensemble. In Proceedings of the European Conference on Computer Vision (ECCV), pages 369-385, 2018.\n\nStochastic activation pruning for robust adversarial defense. S Guneet, Kamyar Dhillon, Jeremy D Azizzadenesheli, Jean Bernstein, Aran Kossaifi, Zachary C Khanna, Animashree Lipton, Anandkumar, International Conference on Learning Representations. Guneet S. Dhillon, Kamyar Azizzadenesheli, Jeremy D. Bern- stein, Jean Kossaifi, Aran Khanna, Zachary C. Lipton, and Animashree Anandkumar. Stochastic activation pruning for robust adversarial defense. In International Conference on Learning Representations, 2018.\n\nCertified adversarial robustness via randomized smoothing. Jeremy Cohen, Elan Rosenfeld, Zico Kolter, International Conference on Machine Learning. Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified ad- versarial robustness via randomized smoothing. In International Conference on Machine Learning, pages 1310-1320, 2019.\n\nMitigating adversarial effects through randomization. Cihang Xie, Jianyu Wang, Zhishuai Zhang, Alan Zhou Ren, Yuille, International Conference on Learning Representations. Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille. Mitigating adversarial effects through randomization. In International Conference on Learning Representations, 2018.\n\nAdversarial examples are not easily detected: Bypassing ten detection methods. Nicholas Carlini, David Wagner, Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. the 10th ACM Workshop on Artificial Intelligence and SecurityACMNicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten detection methods. In Pro- ceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pages 3-14. ACM, 2017.\n\nAdversarial examples in the physical world. Alexey Kurakin, J Ian, Samy Goodfellow, Bengio, Artificial Intelligence Safety and Security. Chapman and Hall/CRCAlexey Kurakin, Ian J Goodfellow, and Samy Bengio. Adver- sarial examples in the physical world. In Artificial Intelligence Safety and Security, pages 99-112. Chapman and Hall/CRC, 2018.\n\nScikit-learn: Machine learning in Python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, J Vanderplas, A Passos, D Cournapeau, M Brucher, M Perrot, E Duchesnay, Journal of Machine Learning Research. 12F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825-2830, 2011.\n", "annotations": {"author": "[{\"end\":103,\"start\":62},{\"end\":149,\"start\":104},{\"end\":209,\"start\":150},{\"end\":245,\"start\":210}]", "publisher": null, "author_last_name": "[{\"end\":73,\"start\":69},{\"end\":120,\"start\":114},{\"end\":169,\"start\":159}]", "author_first_name": "[{\"end\":68,\"start\":62},{\"end\":111,\"start\":104},{\"end\":113,\"start\":112},{\"end\":156,\"start\":150},{\"end\":158,\"start\":157}]", "author_affiliation": "[{\"end\":102,\"start\":87},{\"end\":148,\"start\":133},{\"end\":208,\"start\":193},{\"end\":244,\"start\":211}]", "title": "[{\"end\":59,\"start\":1},{\"end\":304,\"start\":246}]", "venue": null, "abstract": "[{\"end\":1093,\"start\":306}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1425,\"start\":1422},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2106,\"start\":2103},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2109,\"start\":2106},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2112,\"start\":2109},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2115,\"start\":2112},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2118,\"start\":2115},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2121,\"start\":2118},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2124,\"start\":2121},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2127,\"start\":2124},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2130,\"start\":2127},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2134,\"start\":2130},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2138,\"start\":2134},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2142,\"start\":2138},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2146,\"start\":2142},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2150,\"start\":2146},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2154,\"start\":2150},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2158,\"start\":2154},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2766,\"start\":2763},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2768,\"start\":2766},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2770,\"start\":2768},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3510,\"start\":3507},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3512,\"start\":3510},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3579,\"start\":3576},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3581,\"start\":3579},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3583,\"start\":3581},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3960,\"start\":3957},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3981,\"start\":3978},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3984,\"start\":3981},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4271,\"start\":4267},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4446,\"start\":4442},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4449,\"start\":4446},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4791,\"start\":4787},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4828,\"start\":4824},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5110,\"start\":5107},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9192,\"start\":9188},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10299,\"start\":10295},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10921,\"start\":10918},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11094,\"start\":11090},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11878,\"start\":11874},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11980,\"start\":11976},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12011,\"start\":12007},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12145,\"start\":12141},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12383,\"start\":12380},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12386,\"start\":12383},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12390,\"start\":12386},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12412,\"start\":12408},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":14838,\"start\":14835},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":14840,\"start\":14838},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":14842,\"start\":14840},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":18411,\"start\":18408},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":18413,\"start\":18411},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":18415,\"start\":18413},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":23122,\"start\":23118},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":24119,\"start\":24115},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":25567,\"start\":25563},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":28050,\"start\":28046},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":29097,\"start\":29096},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":29121,\"start\":29120},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":29191,\"start\":29187},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":29208,\"start\":29204},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":29448,\"start\":29444},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":29468,\"start\":29465},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":29488,\"start\":29484},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":29707,\"start\":29704},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":29996,\"start\":29992},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":30012,\"start\":30008},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":30031,\"start\":30027},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30071,\"start\":30067},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":30810,\"start\":30806},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":31206,\"start\":31202},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":31234,\"start\":31230},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":31290,\"start\":31286},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":31347,\"start\":31343},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":31939,\"start\":31936},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":32016,\"start\":32012},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35092,\"start\":35089},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35915,\"start\":35912},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":35980,\"start\":35977},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":36826,\"start\":36822},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":36859,\"start\":36855},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":37022,\"start\":37019},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":37241,\"start\":37237},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":37311,\"start\":37307},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":37315,\"start\":37311},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":37319,\"start\":37315},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":37323,\"start\":37319},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":37327,\"start\":37323},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":37377,\"start\":37373},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":37665,\"start\":37662},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":37667,\"start\":37665},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":37669,\"start\":37667},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":37672,\"start\":37669},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":37770,\"start\":37766},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":37773,\"start\":37770},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":37887,\"start\":37884},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":38291,\"start\":38288},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":38305,\"start\":38302},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":38346,\"start\":38343},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":38359,\"start\":38356},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":38362,\"start\":38359},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":38666,\"start\":38663},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":38765,\"start\":38761},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":40740,\"start\":40737},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":40856,\"start\":40853},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":41198,\"start\":41194},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":42446,\"start\":42445},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":43481,\"start\":43480},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":45801,\"start\":45797},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":45820,\"start\":45816},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":46587,\"start\":46583},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":51105,\"start\":51101},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":51132,\"start\":51128},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":54219,\"start\":54215}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":56794,\"start\":56491},{\"attributes\":{\"id\":\"fig_1\"},\"end\":57034,\"start\":56795},{\"attributes\":{\"id\":\"fig_3\"},\"end\":57721,\"start\":57035},{\"attributes\":{\"id\":\"fig_4\"},\"end\":57957,\"start\":57722},{\"attributes\":{\"id\":\"fig_5\"},\"end\":58189,\"start\":57958},{\"attributes\":{\"id\":\"fig_6\"},\"end\":58500,\"start\":58190},{\"attributes\":{\"id\":\"fig_8\"},\"end\":58938,\"start\":58501},{\"attributes\":{\"id\":\"fig_9\"},\"end\":59372,\"start\":58939},{\"attributes\":{\"id\":\"fig_10\"},\"end\":59429,\"start\":59373},{\"attributes\":{\"id\":\"fig_11\"},\"end\":59535,\"start\":59430},{\"attributes\":{\"id\":\"fig_12\"},\"end\":59712,\"start\":59536},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":61892,\"start\":59713},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":64430,\"start\":61893},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":64906,\"start\":64431}]", "paragraph": "[{\"end\":1984,\"start\":1112},{\"end\":2771,\"start\":1986},{\"end\":4085,\"start\":2773},{\"end\":5323,\"start\":4087},{\"end\":6547,\"start\":5325},{\"end\":7379,\"start\":6549},{\"end\":8199,\"start\":7381},{\"end\":9055,\"start\":8201},{\"end\":10199,\"start\":9104},{\"end\":10668,\"start\":10201},{\"end\":11571,\"start\":10670},{\"end\":12504,\"start\":11604},{\"end\":12926,\"start\":12506},{\"end\":13520,\"start\":12961},{\"end\":13895,\"start\":13552},{\"end\":14160,\"start\":14015},{\"end\":14262,\"start\":14202},{\"end\":14689,\"start\":14379},{\"end\":14889,\"start\":14733},{\"end\":14931,\"start\":14891},{\"end\":14991,\"start\":14933},{\"end\":15217,\"start\":15021},{\"end\":15581,\"start\":15286},{\"end\":15866,\"start\":15583},{\"end\":16088,\"start\":15937},{\"end\":16164,\"start\":16090},{\"end\":16568,\"start\":16260},{\"end\":16773,\"start\":16580},{\"end\":16904,\"start\":16828},{\"end\":17312,\"start\":16906},{\"end\":17508,\"start\":17344},{\"end\":17667,\"start\":17577},{\"end\":17972,\"start\":17727},{\"end\":18161,\"start\":18069},{\"end\":18416,\"start\":18213},{\"end\":19064,\"start\":18488},{\"end\":19215,\"start\":19087},{\"end\":19502,\"start\":19267},{\"end\":19884,\"start\":19504},{\"end\":19983,\"start\":19961},{\"end\":20117,\"start\":20036},{\"end\":20769,\"start\":20119},{\"end\":20997,\"start\":20801},{\"end\":21287,\"start\":21145},{\"end\":21469,\"start\":21289},{\"end\":21748,\"start\":21494},{\"end\":22203,\"start\":21777},{\"end\":22289,\"start\":22230},{\"end\":23347,\"start\":22611},{\"end\":23681,\"start\":23412},{\"end\":23884,\"start\":23683},{\"end\":24120,\"start\":23961},{\"end\":24447,\"start\":24372},{\"end\":24610,\"start\":24599},{\"end\":24759,\"start\":24643},{\"end\":25049,\"start\":24786},{\"end\":25326,\"start\":25092},{\"end\":25506,\"start\":25353},{\"end\":25651,\"start\":25535},{\"end\":25724,\"start\":25688},{\"end\":25886,\"start\":25823},{\"end\":25972,\"start\":25943},{\"end\":26273,\"start\":26232},{\"end\":26681,\"start\":26502},{\"end\":27052,\"start\":26801},{\"end\":27148,\"start\":27054},{\"end\":27556,\"start\":27266},{\"end\":28695,\"start\":27581},{\"end\":29306,\"start\":28714},{\"end\":29915,\"start\":29308},{\"end\":30831,\"start\":29917},{\"end\":31740,\"start\":30833},{\"end\":32450,\"start\":31756},{\"end\":34848,\"start\":32452},{\"end\":35833,\"start\":34850},{\"end\":36511,\"start\":35835},{\"end\":36655,\"start\":36566},{\"end\":38152,\"start\":36657},{\"end\":38504,\"start\":38154},{\"end\":39125,\"start\":38506},{\"end\":41456,\"start\":39127},{\"end\":42031,\"start\":41458},{\"end\":42541,\"start\":42033},{\"end\":43530,\"start\":42560},{\"end\":44321,\"start\":43532},{\"end\":45000,\"start\":44323},{\"end\":45126,\"start\":45025},{\"end\":45226,\"start\":45148},{\"end\":45343,\"start\":45252},{\"end\":45489,\"start\":45396},{\"end\":45520,\"start\":45491},{\"end\":45644,\"start\":45604},{\"end\":45723,\"start\":45718},{\"end\":45827,\"start\":45779},{\"end\":46037,\"start\":45926},{\"end\":46161,\"start\":46141},{\"end\":46335,\"start\":46242},{\"end\":46604,\"start\":46497},{\"end\":46883,\"start\":46716},{\"end\":47056,\"start\":46943},{\"end\":47138,\"start\":47058},{\"end\":47556,\"start\":47470},{\"end\":47748,\"start\":47599},{\"end\":47967,\"start\":47933},{\"end\":48103,\"start\":47993},{\"end\":48344,\"start\":48162},{\"end\":48514,\"start\":48388},{\"end\":48677,\"start\":48600},{\"end\":48805,\"start\":48743},{\"end\":48890,\"start\":48841},{\"end\":49105,\"start\":49032},{\"end\":49335,\"start\":49296},{\"end\":49513,\"start\":49478},{\"end\":49669,\"start\":49649},{\"end\":49743,\"start\":49706},{\"end\":49882,\"start\":49818},{\"end\":49951,\"start\":49908},{\"end\":50218,\"start\":50007},{\"end\":50544,\"start\":50510},{\"end\":50644,\"start\":50609},{\"end\":50927,\"start\":50875},{\"end\":52476,\"start\":50963},{\"end\":52917,\"start\":52541},{\"end\":53511,\"start\":52919},{\"end\":53796,\"start\":53550},{\"end\":54676,\"start\":53798},{\"end\":55798,\"start\":54678},{\"end\":56490,\"start\":55800}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13551,\"start\":13521},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14014,\"start\":13896},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14201,\"start\":14161},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14378,\"start\":14263},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14732,\"start\":14690},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15020,\"start\":14992},{\"attributes\":{\"id\":\"formula_6\"},\"end\":15285,\"start\":15218},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15936,\"start\":15867},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16259,\"start\":16165},{\"attributes\":{\"id\":\"formula_9\"},\"end\":16579,\"start\":16569},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16827,\"start\":16774},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17576,\"start\":17509},{\"attributes\":{\"id\":\"formula_12\"},\"end\":17726,\"start\":17668},{\"attributes\":{\"id\":\"formula_13\"},\"end\":18068,\"start\":17973},{\"attributes\":{\"id\":\"formula_14\"},\"end\":18212,\"start\":18162},{\"attributes\":{\"id\":\"formula_15\"},\"end\":19266,\"start\":19216},{\"attributes\":{\"id\":\"formula_16\"},\"end\":19960,\"start\":19885},{\"attributes\":{\"id\":\"formula_17\"},\"end\":20035,\"start\":19984},{\"attributes\":{\"id\":\"formula_18\"},\"end\":21144,\"start\":20998},{\"attributes\":{\"id\":\"formula_19\"},\"end\":21493,\"start\":21470},{\"attributes\":{\"id\":\"formula_20\"},\"end\":21776,\"start\":21749},{\"attributes\":{\"id\":\"formula_21\"},\"end\":22554,\"start\":22290},{\"attributes\":{\"id\":\"formula_22\"},\"end\":23411,\"start\":23348},{\"attributes\":{\"id\":\"formula_23\"},\"end\":23960,\"start\":23885},{\"attributes\":{\"id\":\"formula_24\"},\"end\":24371,\"start\":24121},{\"attributes\":{\"id\":\"formula_25\"},\"end\":24598,\"start\":24448},{\"attributes\":{\"id\":\"formula_26\"},\"end\":24642,\"start\":24611},{\"attributes\":{\"id\":\"formula_27\"},\"end\":24785,\"start\":24760},{\"attributes\":{\"id\":\"formula_28\"},\"end\":25091,\"start\":25050},{\"attributes\":{\"id\":\"formula_29\"},\"end\":25352,\"start\":25327},{\"attributes\":{\"id\":\"formula_30\"},\"end\":25534,\"start\":25507},{\"attributes\":{\"id\":\"formula_31\"},\"end\":25687,\"start\":25652},{\"attributes\":{\"id\":\"formula_32\"},\"end\":25790,\"start\":25725},{\"attributes\":{\"id\":\"formula_33\"},\"end\":25942,\"start\":25887},{\"attributes\":{\"id\":\"formula_34\"},\"end\":26231,\"start\":25973},{\"attributes\":{\"id\":\"formula_35\"},\"end\":26501,\"start\":26274},{\"attributes\":{\"id\":\"formula_36\"},\"end\":26800,\"start\":26682},{\"attributes\":{\"id\":\"formula_37\"},\"end\":27265,\"start\":27149},{\"attributes\":{\"id\":\"formula_38\"},\"end\":45395,\"start\":45344},{\"attributes\":{\"id\":\"formula_39\"},\"end\":45603,\"start\":45521},{\"attributes\":{\"id\":\"formula_40\"},\"end\":45717,\"start\":45645},{\"attributes\":{\"id\":\"formula_41\"},\"end\":45778,\"start\":45724},{\"attributes\":{\"id\":\"formula_42\"},\"end\":45925,\"start\":45828},{\"attributes\":{\"id\":\"formula_43\"},\"end\":46140,\"start\":46038},{\"attributes\":{\"id\":\"formula_44\"},\"end\":46241,\"start\":46162},{\"attributes\":{\"id\":\"formula_45\"},\"end\":46496,\"start\":46336},{\"attributes\":{\"id\":\"formula_46\"},\"end\":46715,\"start\":46605},{\"attributes\":{\"id\":\"formula_47\"},\"end\":46942,\"start\":46884},{\"attributes\":{\"id\":\"formula_48\"},\"end\":47469,\"start\":47139},{\"attributes\":{\"id\":\"formula_49\"},\"end\":47598,\"start\":47557},{\"attributes\":{\"id\":\"formula_50\"},\"end\":47932,\"start\":47749},{\"attributes\":{\"id\":\"formula_51\"},\"end\":48161,\"start\":48104},{\"attributes\":{\"id\":\"formula_52\"},\"end\":48387,\"start\":48345},{\"attributes\":{\"id\":\"formula_53\"},\"end\":48599,\"start\":48515},{\"attributes\":{\"id\":\"formula_54\"},\"end\":48742,\"start\":48678},{\"attributes\":{\"id\":\"formula_55\"},\"end\":48840,\"start\":48806},{\"attributes\":{\"id\":\"formula_56\"},\"end\":49031,\"start\":48891},{\"attributes\":{\"id\":\"formula_57\"},\"end\":49295,\"start\":49106},{\"attributes\":{\"id\":\"formula_58\"},\"end\":49477,\"start\":49336},{\"attributes\":{\"id\":\"formula_59\"},\"end\":49648,\"start\":49514},{\"attributes\":{\"id\":\"formula_60\"},\"end\":49705,\"start\":49670},{\"attributes\":{\"id\":\"formula_61\"},\"end\":49817,\"start\":49744},{\"attributes\":{\"id\":\"formula_62\"},\"end\":50006,\"start\":49952},{\"attributes\":{\"id\":\"formula_63\"},\"end\":50509,\"start\":50219},{\"attributes\":{\"id\":\"formula_64\"},\"end\":50608,\"start\":50545},{\"attributes\":{\"id\":\"formula_65\"},\"end\":50874,\"start\":50645}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":32826,\"start\":32819}]", "section_header": "[{\"end\":1110,\"start\":1095},{\"end\":9074,\"start\":9058},{\"end\":9102,\"start\":9077},{\"end\":11602,\"start\":11574},{\"end\":12959,\"start\":12929},{\"end\":17342,\"start\":17315},{\"end\":18466,\"start\":18419},{\"end\":18486,\"start\":18469},{\"end\":19085,\"start\":19067},{\"end\":20799,\"start\":20772},{\"end\":22228,\"start\":22206},{\"end\":22609,\"start\":22556},{\"end\":25821,\"start\":25792},{\"end\":27579,\"start\":27559},{\"end\":28712,\"start\":28698},{\"end\":31754,\"start\":31743},{\"end\":36564,\"start\":36514},{\"end\":42558,\"start\":42544},{\"end\":45023,\"start\":45003},{\"end\":45146,\"start\":45129},{\"end\":45250,\"start\":45229},{\"end\":47991,\"start\":47970},{\"end\":49906,\"start\":49885},{\"end\":50961,\"start\":50930},{\"end\":52539,\"start\":52479},{\"end\":53548,\"start\":53514},{\"end\":56502,\"start\":56492},{\"end\":56806,\"start\":56796},{\"end\":57046,\"start\":57036},{\"end\":57733,\"start\":57723},{\"end\":58201,\"start\":58191},{\"end\":58512,\"start\":58502},{\"end\":58945,\"start\":58940},{\"end\":59384,\"start\":59374},{\"end\":59442,\"start\":59431},{\"end\":59548,\"start\":59537},{\"end\":59723,\"start\":59714}]", "table": "[{\"end\":61892,\"start\":59906},{\"end\":64430,\"start\":62134}]", "figure_caption": "[{\"end\":56794,\"start\":56504},{\"end\":57034,\"start\":56808},{\"end\":57721,\"start\":57048},{\"end\":57957,\"start\":57735},{\"end\":58189,\"start\":57960},{\"end\":58500,\"start\":58203},{\"end\":58938,\"start\":58514},{\"end\":59372,\"start\":58947},{\"end\":59429,\"start\":59386},{\"end\":59535,\"start\":59445},{\"end\":59712,\"start\":59551},{\"end\":59906,\"start\":59725},{\"end\":62134,\"start\":61895},{\"end\":64906,\"start\":64433}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":2844,\"start\":2836},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":3842,\"start\":3834},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":28397,\"start\":28389},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":32992,\"start\":32978},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":33055,\"start\":33047},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":33188,\"start\":33180},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":33239,\"start\":33231},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":33604,\"start\":33588},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":35287,\"start\":35279},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":39670,\"start\":39662},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":52009,\"start\":52001},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":53048,\"start\":53039},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":55435,\"start\":55426},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":55598,\"start\":55589},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":55743,\"start\":55734}]", "bib_author_first_name": "[{\"end\":65244,\"start\":65235},{\"end\":65262,\"start\":65254},{\"end\":65276,\"start\":65272},{\"end\":65292,\"start\":65288},{\"end\":65307,\"start\":65300},{\"end\":65318,\"start\":65315},{\"end\":65334,\"start\":65331},{\"end\":65671,\"start\":65670},{\"end\":65685,\"start\":65677},{\"end\":65707,\"start\":65698},{\"end\":66088,\"start\":66082},{\"end\":66101,\"start\":66098},{\"end\":66118,\"start\":66114},{\"end\":66411,\"start\":66402},{\"end\":66449,\"start\":66443},{\"end\":66971,\"start\":66964},{\"end\":66989,\"start\":66982},{\"end\":67006,\"start\":67000},{\"end\":67379,\"start\":67371},{\"end\":67394,\"start\":67389},{\"end\":67688,\"start\":67678},{\"end\":67706,\"start\":67696},{\"end\":67722,\"start\":67716},{\"end\":67740,\"start\":67732},{\"end\":67756,\"start\":67750},{\"end\":68158,\"start\":68152},{\"end\":68169,\"start\":68165},{\"end\":68181,\"start\":68177},{\"end\":68197,\"start\":68190},{\"end\":68209,\"start\":68202},{\"end\":68724,\"start\":68718},{\"end\":68737,\"start\":68732},{\"end\":68753,\"start\":68748},{\"end\":68768,\"start\":68763},{\"end\":69101,\"start\":69095},{\"end\":69114,\"start\":69109},{\"end\":69135,\"start\":69125},{\"end\":69465,\"start\":69459},{\"end\":69477,\"start\":69471},{\"end\":69489,\"start\":69484},{\"end\":69499,\"start\":69495},{\"end\":69946,\"start\":69939},{\"end\":69964,\"start\":69957},{\"end\":69978,\"start\":69975},{\"end\":70277,\"start\":70270},{\"end\":70295,\"start\":70288},{\"end\":70309,\"start\":70306},{\"end\":70328,\"start\":70322},{\"end\":70343,\"start\":70334},{\"end\":70905,\"start\":70898},{\"end\":70920,\"start\":70915},{\"end\":70937,\"start\":70929},{\"end\":71296,\"start\":71290},{\"end\":71314,\"start\":71306},{\"end\":71329,\"start\":71322},{\"end\":71346,\"start\":71341},{\"end\":71652,\"start\":71646},{\"end\":71665,\"start\":71660},{\"end\":71676,\"start\":71670},{\"end\":71687,\"start\":71683},{\"end\":71702,\"start\":71695},{\"end\":71714,\"start\":71707},{\"end\":72059,\"start\":72052},{\"end\":72073,\"start\":72067},{\"end\":72090,\"start\":72083},{\"end\":72104,\"start\":72101},{\"end\":72120,\"start\":72117},{\"end\":72135,\"start\":72128},{\"end\":72508,\"start\":72504},{\"end\":72515,\"start\":72509},{\"end\":72544,\"start\":72535},{\"end\":73024,\"start\":73019},{\"end\":73035,\"start\":73034},{\"end\":73051,\"start\":73050},{\"end\":73066,\"start\":73065},{\"end\":73082,\"start\":73073},{\"end\":73424,\"start\":73419},{\"end\":73443,\"start\":73435},{\"end\":73748,\"start\":73747},{\"end\":73762,\"start\":73755},{\"end\":73764,\"start\":73763},{\"end\":73781,\"start\":73780},{\"end\":73795,\"start\":73790},{\"end\":74167,\"start\":74162},{\"end\":74179,\"start\":74173},{\"end\":74197,\"start\":74191},{\"end\":74211,\"start\":74204},{\"end\":74223,\"start\":74218},{\"end\":74235,\"start\":74231},{\"end\":74535,\"start\":74530},{\"end\":74550,\"start\":74545},{\"end\":74557,\"start\":74551},{\"end\":74574,\"start\":74567},{\"end\":74579,\"start\":74575},{\"end\":74895,\"start\":74889},{\"end\":75038,\"start\":75031},{\"end\":75056,\"start\":75049},{\"end\":75073,\"start\":75065},{\"end\":75086,\"start\":75083},{\"end\":75105,\"start\":75099},{\"end\":75121,\"start\":75115},{\"end\":75137,\"start\":75131},{\"end\":75147,\"start\":75143},{\"end\":75159,\"start\":75156},{\"end\":75172,\"start\":75167},{\"end\":75187,\"start\":75178},{\"end\":75203,\"start\":75198},{\"end\":75219,\"start\":75214},{\"end\":75243,\"start\":75235},{\"end\":75257,\"start\":75251},{\"end\":75268,\"start\":75265},{\"end\":75277,\"start\":75273},{\"end\":75297,\"start\":75289},{\"end\":75312,\"start\":75304},{\"end\":75326,\"start\":75321},{\"end\":75342,\"start\":75335},{\"end\":75354,\"start\":75349},{\"end\":76100,\"start\":76095},{\"end\":76116,\"start\":76109},{\"end\":76134,\"start\":76126},{\"end\":76406,\"start\":76402},{\"end\":76604,\"start\":76603},{\"end\":76612,\"start\":76611},{\"end\":76620,\"start\":76619},{\"end\":76633,\"start\":76629},{\"end\":76639,\"start\":76638},{\"end\":76645,\"start\":76644},{\"end\":77011,\"start\":77003},{\"end\":77120,\"start\":77117},{\"end\":77140,\"start\":77137},{\"end\":77157,\"start\":77151},{\"end\":77174,\"start\":77167},{\"end\":77469,\"start\":77462},{\"end\":77481,\"start\":77474},{\"end\":77497,\"start\":77489},{\"end\":77507,\"start\":77503},{\"end\":77781,\"start\":77778},{\"end\":77795,\"start\":77789},{\"end\":77808,\"start\":77801},{\"end\":77833,\"start\":77825},{\"end\":78216,\"start\":78209},{\"end\":78234,\"start\":78227},{\"end\":78247,\"start\":78245},{\"end\":78417,\"start\":78408},{\"end\":78758,\"start\":78753},{\"end\":78776,\"start\":78768},{\"end\":78791,\"start\":78786},{\"end\":79161,\"start\":79155},{\"end\":79181,\"start\":79167},{\"end\":79613,\"start\":79605},{\"end\":79625,\"start\":79619},{\"end\":79637,\"start\":79633},{\"end\":79652,\"start\":79645},{\"end\":80045,\"start\":80044},{\"end\":80060,\"start\":80054},{\"end\":80076,\"start\":80070},{\"end\":80078,\"start\":80077},{\"end\":80100,\"start\":80096},{\"end\":80116,\"start\":80112},{\"end\":80134,\"start\":80127},{\"end\":80136,\"start\":80135},{\"end\":80155,\"start\":80145},{\"end\":80561,\"start\":80555},{\"end\":80573,\"start\":80569},{\"end\":80589,\"start\":80585},{\"end\":80885,\"start\":80879},{\"end\":80897,\"start\":80891},{\"end\":80912,\"start\":80904},{\"end\":80924,\"start\":80920},{\"end\":81270,\"start\":81262},{\"end\":81285,\"start\":81280},{\"end\":81707,\"start\":81701},{\"end\":81718,\"start\":81717},{\"end\":81728,\"start\":81724},{\"end\":82045,\"start\":82044},{\"end\":82058,\"start\":82057},{\"end\":82071,\"start\":82070},{\"end\":82083,\"start\":82082},{\"end\":82093,\"start\":82092},{\"end\":82104,\"start\":82103},{\"end\":82114,\"start\":82113},{\"end\":82125,\"start\":82124},{\"end\":82141,\"start\":82140},{\"end\":82150,\"start\":82149},{\"end\":82161,\"start\":82160},{\"end\":82175,\"start\":82174},{\"end\":82185,\"start\":82184},{\"end\":82199,\"start\":82198},{\"end\":82210,\"start\":82209},{\"end\":82220,\"start\":82219}]", "bib_author_last_name": "[{\"end\":65252,\"start\":65245},{\"end\":65270,\"start\":65263},{\"end\":65286,\"start\":65277},{\"end\":65298,\"start\":65293},{\"end\":65313,\"start\":65308},{\"end\":65329,\"start\":65319},{\"end\":65341,\"start\":65335},{\"end\":65675,\"start\":65672},{\"end\":65696,\"start\":65686},{\"end\":65714,\"start\":65708},{\"end\":65723,\"start\":65716},{\"end\":66096,\"start\":66089},{\"end\":66112,\"start\":66102},{\"end\":66125,\"start\":66119},{\"end\":66441,\"start\":66412},{\"end\":66455,\"start\":66450},{\"end\":66465,\"start\":66457},{\"end\":66980,\"start\":66972},{\"end\":66998,\"start\":66990},{\"end\":67010,\"start\":67007},{\"end\":67387,\"start\":67380},{\"end\":67401,\"start\":67395},{\"end\":67694,\"start\":67689},{\"end\":67714,\"start\":67707},{\"end\":67730,\"start\":67723},{\"end\":67748,\"start\":67741},{\"end\":67762,\"start\":67757},{\"end\":68163,\"start\":68159},{\"end\":68175,\"start\":68170},{\"end\":68188,\"start\":68182},{\"end\":68200,\"start\":68198},{\"end\":68215,\"start\":68210},{\"end\":68730,\"start\":68725},{\"end\":68746,\"start\":68738},{\"end\":68761,\"start\":68754},{\"end\":68772,\"start\":68769},{\"end\":69107,\"start\":69102},{\"end\":69123,\"start\":69115},{\"end\":69141,\"start\":69136},{\"end\":69469,\"start\":69466},{\"end\":69482,\"start\":69478},{\"end\":69493,\"start\":69490},{\"end\":69504,\"start\":69500},{\"end\":69955,\"start\":69947},{\"end\":69973,\"start\":69965},{\"end\":69989,\"start\":69979},{\"end\":70286,\"start\":70278},{\"end\":70304,\"start\":70296},{\"end\":70320,\"start\":70310},{\"end\":70332,\"start\":70329},{\"end\":70356,\"start\":70344},{\"end\":70363,\"start\":70358},{\"end\":70913,\"start\":70906},{\"end\":70927,\"start\":70921},{\"end\":70944,\"start\":70938},{\"end\":71304,\"start\":71297},{\"end\":71320,\"start\":71315},{\"end\":71339,\"start\":71330},{\"end\":71352,\"start\":71347},{\"end\":71658,\"start\":71653},{\"end\":71668,\"start\":71666},{\"end\":71681,\"start\":71677},{\"end\":71693,\"start\":71688},{\"end\":71705,\"start\":71703},{\"end\":71720,\"start\":71715},{\"end\":72065,\"start\":72060},{\"end\":72081,\"start\":72074},{\"end\":72099,\"start\":72091},{\"end\":72115,\"start\":72105},{\"end\":72126,\"start\":72121},{\"end\":72144,\"start\":72136},{\"end\":72533,\"start\":72516},{\"end\":72550,\"start\":72545},{\"end\":72559,\"start\":72552},{\"end\":73032,\"start\":73025},{\"end\":73040,\"start\":73036},{\"end\":73048,\"start\":73042},{\"end\":73058,\"start\":73052},{\"end\":73063,\"start\":73060},{\"end\":73071,\"start\":73067},{\"end\":73089,\"start\":73083},{\"end\":73098,\"start\":73091},{\"end\":73433,\"start\":73425},{\"end\":73452,\"start\":73444},{\"end\":73753,\"start\":73749},{\"end\":73770,\"start\":73765},{\"end\":73778,\"start\":73772},{\"end\":73788,\"start\":73782},{\"end\":73806,\"start\":73796},{\"end\":73816,\"start\":73808},{\"end\":74171,\"start\":74168},{\"end\":74189,\"start\":74180},{\"end\":74202,\"start\":74198},{\"end\":74216,\"start\":74212},{\"end\":74229,\"start\":74224},{\"end\":74241,\"start\":74236},{\"end\":74543,\"start\":74536},{\"end\":74565,\"start\":74558},{\"end\":74586,\"start\":74580},{\"end\":74902,\"start\":74896},{\"end\":75047,\"start\":75039},{\"end\":75063,\"start\":75057},{\"end\":75081,\"start\":75074},{\"end\":75097,\"start\":75087},{\"end\":75113,\"start\":75106},{\"end\":75129,\"start\":75122},{\"end\":75141,\"start\":75138},{\"end\":75154,\"start\":75148},{\"end\":75165,\"start\":75160},{\"end\":75176,\"start\":75173},{\"end\":75196,\"start\":75188},{\"end\":75212,\"start\":75204},{\"end\":75233,\"start\":75220},{\"end\":75249,\"start\":75244},{\"end\":75263,\"start\":75258},{\"end\":75271,\"start\":75269},{\"end\":75287,\"start\":75278},{\"end\":75302,\"start\":75298},{\"end\":75319,\"start\":75313},{\"end\":75333,\"start\":75327},{\"end\":75347,\"start\":75343},{\"end\":75364,\"start\":75355},{\"end\":76107,\"start\":76101},{\"end\":76124,\"start\":76117},{\"end\":76141,\"start\":76135},{\"end\":76417,\"start\":76407},{\"end\":76609,\"start\":76605},{\"end\":76617,\"start\":76613},{\"end\":76627,\"start\":76621},{\"end\":76636,\"start\":76634},{\"end\":76642,\"start\":76640},{\"end\":76653,\"start\":76646},{\"end\":77019,\"start\":77012},{\"end\":77135,\"start\":77121},{\"end\":77149,\"start\":77141},{\"end\":77165,\"start\":77158},{\"end\":77183,\"start\":77175},{\"end\":77472,\"start\":77470},{\"end\":77487,\"start\":77482},{\"end\":77501,\"start\":77498},{\"end\":77511,\"start\":77508},{\"end\":77787,\"start\":77782},{\"end\":77799,\"start\":77796},{\"end\":77823,\"start\":77809},{\"end\":77844,\"start\":77834},{\"end\":78225,\"start\":78217},{\"end\":78243,\"start\":78235},{\"end\":78250,\"start\":78248},{\"end\":78423,\"start\":78418},{\"end\":78766,\"start\":78759},{\"end\":78784,\"start\":78777},{\"end\":78798,\"start\":78792},{\"end\":79165,\"start\":79162},{\"end\":79186,\"start\":79182},{\"end\":79617,\"start\":79614},{\"end\":79631,\"start\":79626},{\"end\":79643,\"start\":79638},{\"end\":79658,\"start\":79653},{\"end\":80052,\"start\":80046},{\"end\":80068,\"start\":80061},{\"end\":80094,\"start\":80079},{\"end\":80110,\"start\":80101},{\"end\":80125,\"start\":80117},{\"end\":80143,\"start\":80137},{\"end\":80162,\"start\":80156},{\"end\":80174,\"start\":80164},{\"end\":80567,\"start\":80562},{\"end\":80583,\"start\":80574},{\"end\":80596,\"start\":80590},{\"end\":80889,\"start\":80886},{\"end\":80902,\"start\":80898},{\"end\":80918,\"start\":80913},{\"end\":80933,\"start\":80925},{\"end\":80941,\"start\":80935},{\"end\":81278,\"start\":81271},{\"end\":81292,\"start\":81286},{\"end\":81715,\"start\":81708},{\"end\":81722,\"start\":81719},{\"end\":81739,\"start\":81729},{\"end\":81747,\"start\":81741},{\"end\":82055,\"start\":82046},{\"end\":82068,\"start\":82059},{\"end\":82080,\"start\":82072},{\"end\":82090,\"start\":82084},{\"end\":82101,\"start\":82094},{\"end\":82111,\"start\":82105},{\"end\":82122,\"start\":82115},{\"end\":82138,\"start\":82126},{\"end\":82147,\"start\":82142},{\"end\":82158,\"start\":82151},{\"end\":82172,\"start\":82162},{\"end\":82182,\"start\":82176},{\"end\":82196,\"start\":82186},{\"end\":82207,\"start\":82200},{\"end\":82217,\"start\":82211},{\"end\":82230,\"start\":82221}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":604334},\"end\":65620,\"start\":65193},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":6706414},\"end\":66041,\"start\":65622},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":9059612},\"end\":66331,\"start\":66043},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":12387176},\"end\":66850,\"start\":66333},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":7004303},\"end\":67315,\"start\":66852},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2893830},\"end\":67613,\"start\":67317},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3488815},\"end\":68035,\"start\":67615},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":2179389},\"end\":68648,\"start\":68037},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":5046541},\"end\":69019,\"start\":68650},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":49907212},\"end\":69387,\"start\":69021},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":17707860},\"end\":69837,\"start\":69389},{\"attributes\":{\"doi\":\"arXiv:1605.07277\",\"id\":\"b11\"},\"end\":70215,\"start\":69839},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":1090603},\"end\":70801,\"start\":70217},{\"attributes\":{\"id\":\"b13\"},\"end\":71211,\"start\":70803},{\"attributes\":{\"doi\":\"arXiv:1812.09803\",\"id\":\"b14\"},\"end\":71567,\"start\":71213},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":49672236},\"end\":71997,\"start\":71569},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":21946795},\"end\":72415,\"start\":71999},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3264230},\"end\":72964,\"start\":72417},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":6383922},\"end\":73362,\"start\":72966},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":2147817},\"end\":73656,\"start\":73364},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":552111},\"end\":74089,\"start\":73658},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":44080680},\"end\":74526,\"start\":74091},{\"attributes\":{\"id\":\"b22\"},\"end\":74835,\"start\":74528},{\"attributes\":{\"id\":\"b23\"},\"end\":75029,\"start\":74837},{\"attributes\":{\"doi\":\"arXiv:1610.00768\",\"id\":\"b24\"},\"end\":76011,\"start\":75031},{\"attributes\":{\"doi\":\"arXiv:1707.04131\",\"id\":\"b25\"},\"end\":76345,\"start\":76013},{\"attributes\":{\"id\":\"b26\"},\"end\":76548,\"start\":76347},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":57246310},\"end\":76999,\"start\":76550},{\"attributes\":{\"id\":\"b28\"},\"end\":77075,\"start\":77001},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":7071211},\"end\":77415,\"start\":77077},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":6447277},\"end\":77734,\"start\":77417},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":9433631},\"end\":78205,\"start\":77736},{\"attributes\":{\"id\":\"b32\"},\"end\":78321,\"start\":78207},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":2672720},\"end\":78650,\"start\":78323},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3310672},\"end\":79069,\"start\":78652},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":1213397},\"end\":79546,\"start\":79071},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":12455403},\"end\":79980,\"start\":79548},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":3604396},\"end\":80494,\"start\":79982},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":59842968},\"end\":80823,\"start\":80496},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":3526769},\"end\":81181,\"start\":80825},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":207599948},\"end\":81655,\"start\":81183},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":1257772},\"end\":82000,\"start\":81657},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":10659969},\"end\":82579,\"start\":82002}]", "bib_title": "[{\"end\":65233,\"start\":65193},{\"end\":65668,\"start\":65622},{\"end\":66080,\"start\":66043},{\"end\":66400,\"start\":66333},{\"end\":66962,\"start\":66852},{\"end\":67369,\"start\":67317},{\"end\":67676,\"start\":67615},{\"end\":68150,\"start\":68037},{\"end\":68716,\"start\":68650},{\"end\":69093,\"start\":69021},{\"end\":69457,\"start\":69389},{\"end\":70268,\"start\":70217},{\"end\":70896,\"start\":70803},{\"end\":71644,\"start\":71569},{\"end\":72050,\"start\":71999},{\"end\":72502,\"start\":72417},{\"end\":73017,\"start\":72966},{\"end\":73417,\"start\":73364},{\"end\":73745,\"start\":73658},{\"end\":74160,\"start\":74091},{\"end\":76601,\"start\":76550},{\"end\":77115,\"start\":77077},{\"end\":77460,\"start\":77417},{\"end\":77776,\"start\":77736},{\"end\":78406,\"start\":78323},{\"end\":78751,\"start\":78652},{\"end\":79153,\"start\":79071},{\"end\":79603,\"start\":79548},{\"end\":80042,\"start\":79982},{\"end\":80553,\"start\":80496},{\"end\":80877,\"start\":80825},{\"end\":81260,\"start\":81183},{\"end\":81699,\"start\":81657},{\"end\":82042,\"start\":82002}]", "bib_author": "[{\"end\":65254,\"start\":65235},{\"end\":65272,\"start\":65254},{\"end\":65288,\"start\":65272},{\"end\":65300,\"start\":65288},{\"end\":65315,\"start\":65300},{\"end\":65331,\"start\":65315},{\"end\":65343,\"start\":65331},{\"end\":65677,\"start\":65670},{\"end\":65698,\"start\":65677},{\"end\":65716,\"start\":65698},{\"end\":65725,\"start\":65716},{\"end\":66098,\"start\":66082},{\"end\":66114,\"start\":66098},{\"end\":66127,\"start\":66114},{\"end\":66443,\"start\":66402},{\"end\":66457,\"start\":66443},{\"end\":66467,\"start\":66457},{\"end\":66982,\"start\":66964},{\"end\":67000,\"start\":66982},{\"end\":67012,\"start\":67000},{\"end\":67389,\"start\":67371},{\"end\":67403,\"start\":67389},{\"end\":67696,\"start\":67678},{\"end\":67716,\"start\":67696},{\"end\":67732,\"start\":67716},{\"end\":67750,\"start\":67732},{\"end\":67764,\"start\":67750},{\"end\":68165,\"start\":68152},{\"end\":68177,\"start\":68165},{\"end\":68190,\"start\":68177},{\"end\":68202,\"start\":68190},{\"end\":68217,\"start\":68202},{\"end\":68732,\"start\":68718},{\"end\":68748,\"start\":68732},{\"end\":68763,\"start\":68748},{\"end\":68774,\"start\":68763},{\"end\":69109,\"start\":69095},{\"end\":69125,\"start\":69109},{\"end\":69143,\"start\":69125},{\"end\":69471,\"start\":69459},{\"end\":69484,\"start\":69471},{\"end\":69495,\"start\":69484},{\"end\":69506,\"start\":69495},{\"end\":69957,\"start\":69939},{\"end\":69975,\"start\":69957},{\"end\":69991,\"start\":69975},{\"end\":70288,\"start\":70270},{\"end\":70306,\"start\":70288},{\"end\":70322,\"start\":70306},{\"end\":70334,\"start\":70322},{\"end\":70358,\"start\":70334},{\"end\":70365,\"start\":70358},{\"end\":70915,\"start\":70898},{\"end\":70929,\"start\":70915},{\"end\":70946,\"start\":70929},{\"end\":71306,\"start\":71290},{\"end\":71322,\"start\":71306},{\"end\":71341,\"start\":71322},{\"end\":71354,\"start\":71341},{\"end\":71660,\"start\":71646},{\"end\":71670,\"start\":71660},{\"end\":71683,\"start\":71670},{\"end\":71695,\"start\":71683},{\"end\":71707,\"start\":71695},{\"end\":71722,\"start\":71707},{\"end\":72067,\"start\":72052},{\"end\":72083,\"start\":72067},{\"end\":72101,\"start\":72083},{\"end\":72117,\"start\":72101},{\"end\":72128,\"start\":72117},{\"end\":72146,\"start\":72128},{\"end\":72535,\"start\":72504},{\"end\":72552,\"start\":72535},{\"end\":72561,\"start\":72552},{\"end\":73034,\"start\":73019},{\"end\":73042,\"start\":73034},{\"end\":73050,\"start\":73042},{\"end\":73060,\"start\":73050},{\"end\":73065,\"start\":73060},{\"end\":73073,\"start\":73065},{\"end\":73091,\"start\":73073},{\"end\":73100,\"start\":73091},{\"end\":73435,\"start\":73419},{\"end\":73454,\"start\":73435},{\"end\":73755,\"start\":73747},{\"end\":73772,\"start\":73755},{\"end\":73780,\"start\":73772},{\"end\":73790,\"start\":73780},{\"end\":73808,\"start\":73790},{\"end\":73818,\"start\":73808},{\"end\":74173,\"start\":74162},{\"end\":74191,\"start\":74173},{\"end\":74204,\"start\":74191},{\"end\":74218,\"start\":74204},{\"end\":74231,\"start\":74218},{\"end\":74243,\"start\":74231},{\"end\":74545,\"start\":74530},{\"end\":74567,\"start\":74545},{\"end\":74588,\"start\":74567},{\"end\":74904,\"start\":74889},{\"end\":75049,\"start\":75031},{\"end\":75065,\"start\":75049},{\"end\":75083,\"start\":75065},{\"end\":75099,\"start\":75083},{\"end\":75115,\"start\":75099},{\"end\":75131,\"start\":75115},{\"end\":75143,\"start\":75131},{\"end\":75156,\"start\":75143},{\"end\":75167,\"start\":75156},{\"end\":75178,\"start\":75167},{\"end\":75198,\"start\":75178},{\"end\":75214,\"start\":75198},{\"end\":75235,\"start\":75214},{\"end\":75251,\"start\":75235},{\"end\":75265,\"start\":75251},{\"end\":75273,\"start\":75265},{\"end\":75289,\"start\":75273},{\"end\":75304,\"start\":75289},{\"end\":75321,\"start\":75304},{\"end\":75335,\"start\":75321},{\"end\":75349,\"start\":75335},{\"end\":75366,\"start\":75349},{\"end\":76109,\"start\":76095},{\"end\":76126,\"start\":76109},{\"end\":76143,\"start\":76126},{\"end\":76419,\"start\":76402},{\"end\":76611,\"start\":76603},{\"end\":76619,\"start\":76611},{\"end\":76629,\"start\":76619},{\"end\":76638,\"start\":76629},{\"end\":76644,\"start\":76638},{\"end\":76655,\"start\":76644},{\"end\":77021,\"start\":77003},{\"end\":77137,\"start\":77117},{\"end\":77151,\"start\":77137},{\"end\":77167,\"start\":77151},{\"end\":77185,\"start\":77167},{\"end\":77474,\"start\":77462},{\"end\":77489,\"start\":77474},{\"end\":77503,\"start\":77489},{\"end\":77513,\"start\":77503},{\"end\":77789,\"start\":77778},{\"end\":77801,\"start\":77789},{\"end\":77825,\"start\":77801},{\"end\":77846,\"start\":77825},{\"end\":78227,\"start\":78209},{\"end\":78245,\"start\":78227},{\"end\":78252,\"start\":78245},{\"end\":78425,\"start\":78408},{\"end\":78768,\"start\":78753},{\"end\":78786,\"start\":78768},{\"end\":78800,\"start\":78786},{\"end\":79167,\"start\":79155},{\"end\":79188,\"start\":79167},{\"end\":79619,\"start\":79605},{\"end\":79633,\"start\":79619},{\"end\":79645,\"start\":79633},{\"end\":79660,\"start\":79645},{\"end\":80054,\"start\":80044},{\"end\":80070,\"start\":80054},{\"end\":80096,\"start\":80070},{\"end\":80112,\"start\":80096},{\"end\":80127,\"start\":80112},{\"end\":80145,\"start\":80127},{\"end\":80164,\"start\":80145},{\"end\":80176,\"start\":80164},{\"end\":80569,\"start\":80555},{\"end\":80585,\"start\":80569},{\"end\":80598,\"start\":80585},{\"end\":80891,\"start\":80879},{\"end\":80904,\"start\":80891},{\"end\":80920,\"start\":80904},{\"end\":80935,\"start\":80920},{\"end\":80943,\"start\":80935},{\"end\":81280,\"start\":81262},{\"end\":81294,\"start\":81280},{\"end\":81717,\"start\":81701},{\"end\":81724,\"start\":81717},{\"end\":81741,\"start\":81724},{\"end\":81749,\"start\":81741},{\"end\":82057,\"start\":82044},{\"end\":82070,\"start\":82057},{\"end\":82082,\"start\":82070},{\"end\":82092,\"start\":82082},{\"end\":82103,\"start\":82092},{\"end\":82113,\"start\":82103},{\"end\":82124,\"start\":82113},{\"end\":82140,\"start\":82124},{\"end\":82149,\"start\":82140},{\"end\":82160,\"start\":82149},{\"end\":82174,\"start\":82160},{\"end\":82184,\"start\":82174},{\"end\":82198,\"start\":82184},{\"end\":82209,\"start\":82198},{\"end\":82219,\"start\":82209},{\"end\":82232,\"start\":82219}]", "bib_venue": "[{\"end\":65398,\"start\":65343},{\"end\":65796,\"start\":65725},{\"end\":66179,\"start\":66127},{\"end\":66544,\"start\":66467},{\"end\":67064,\"start\":67012},{\"end\":67446,\"start\":67403},{\"end\":67816,\"start\":67764},{\"end\":68293,\"start\":68217},{\"end\":68818,\"start\":68774},{\"end\":69195,\"start\":69143},{\"end\":69577,\"start\":69506},{\"end\":69937,\"start\":69839},{\"end\":70451,\"start\":70365},{\"end\":70998,\"start\":70946},{\"end\":71288,\"start\":71213},{\"end\":71774,\"start\":71722},{\"end\":72198,\"start\":72146},{\"end\":72638,\"start\":72561},{\"end\":73149,\"start\":73100},{\"end\":73494,\"start\":73454},{\"end\":73857,\"start\":73818},{\"end\":74292,\"start\":74243},{\"end\":74643,\"start\":74588},{\"end\":74887,\"start\":74837},{\"end\":75498,\"start\":75382},{\"end\":76093,\"start\":76013},{\"end\":76400,\"start\":76347},{\"end\":76732,\"start\":76655},{\"end\":77237,\"start\":77185},{\"end\":77551,\"start\":77513},{\"end\":77923,\"start\":77846},{\"end\":78468,\"start\":78425},{\"end\":78844,\"start\":78800},{\"end\":79260,\"start\":79188},{\"end\":79724,\"start\":79660},{\"end\":80228,\"start\":80176},{\"end\":80642,\"start\":80598},{\"end\":80995,\"start\":80943},{\"end\":81370,\"start\":81294},{\"end\":81792,\"start\":81749},{\"end\":82268,\"start\":82232},{\"end\":65854,\"start\":65798},{\"end\":66608,\"start\":66546},{\"end\":68356,\"start\":68295},{\"end\":69635,\"start\":69579},{\"end\":70524,\"start\":70453},{\"end\":72702,\"start\":72640},{\"end\":76796,\"start\":76734},{\"end\":77987,\"start\":77925},{\"end\":79319,\"start\":79262},{\"end\":79775,\"start\":79726},{\"end\":81433,\"start\":81372}]"}}}, "year": 2023, "month": 12, "day": 17}