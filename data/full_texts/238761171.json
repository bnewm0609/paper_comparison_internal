{"id": 238761171, "updated": "2023-10-05 21:55:12.692", "metadata": {"title": "Journal of Humanistic Mathematics of Humanistic Mathematics Markov Chains for Computer Music Generation Markov Chains for Computer Music Generation", "authors": "[{\"first\":\"Ilana\",\"last\":\"Shapiro\",\"middle\":[]},{\"first\":\"Mark\",\"last\":\"Huber\",\"middle\":[]}]", "venue": "Journal of Humanistic Mathematics", "journal": "Journal of Humanistic Mathematics", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Random generation of music goes back at least to the 1700s with the introduction of Musical Dice Games. More recently, Markov chain models have been used as a way of extracting information from a piece of music and generating new music. We explain this approach and give Python code for using it to \ufb01rst draw out a model of the music and then create new music with that model.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": null, "doi": "10.5642/jhummath.202102.08"}}, "content": {"source": {"pdf_hash": "01fd08e04017a93d9733bc31de87041ef1ea669a", "pdf_src": "Adhoc", "pdf_uri": "[\"https://web.archive.org/web/20210830084240/https:/scholarship.claremont.edu/cgi/viewcontent.cgi?article=1848&context=jhm\"]", "oa_url_match": false, "oa_info": {"license": "CCBYNCND", "open_access_url": "https://scholarship.claremont.edu/cgi/viewcontent.cgi?article=1848&context=jhm", "status": "GOLD"}}, "grobid": {"id": "a0aebb642c31d374bc7b8f205d360ffd33bda839", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/01fd08e04017a93d9733bc31de87041ef1ea669a.txt", "contents": "\nChains for Computer Music Generation\nJuly 2021. July 2021\n\nIlana Shapiro \nMark Huber mhuber@cmc.edu \nI Shapiro \nM &quot; Huber \nMarkov \nIlana Shapiro \nMark Huber \n\nDepartment of Mathematical Sciences\nPomona College\nPomona College\nCaliforniaUSA\n\n\nClaremont McKenna College\nCaliforniaUSA\n\nChains for Computer Music Generation\n\nJournal of Humanistic Mathematics Journal of Humanistic Mathematics\n112July 2021. July 202110.5642/jhummath.202102.08Claremont McKenna College Follow this and additional works at: https://scholarship.claremont.edu/jhmrandomized algorithmsmusical dice gamesmusic compositionMarkov chains\nThe editorial staff of JHM works hard to make sure the scholarship disseminated in JHM is accurate and upholds professional ethical guidelines. However the views and opinions expressed in each published manuscript belong exclusively to the individual contributor(s). The publisher and the editors do not endorse or accept responsibility for them.AbstractRandom generation of music goes back at least to the 1700s with the introduction of Musical Dice Games. More recently, Markov chain models have been used as a way of extracting information from a piece of music and generating new music. We explain this approach and give Python code for using it to first draw out a model of the music and then create new music with that model.\n\nIntroduction\n\nRandomness has long been used in the generation of music. One of the first methods for randomized music composition, called Musikalisches W\u00fcrfelspiel (Musical Dice Games), arose in the 18 th century. These games were based off the observation that in any piece of music, individual notes of music are combined into measures (or bars), each of which has a fixed length. They work by deciding what an entire bar will sound like at once.\n\nThe initial musical dice game was created in 1757 by Johann Philipp Kirnberger, who published a method [2] for composing a polonaise in minuet and trio form. This is an example of a musical form called ternary because it consists of three parts. The first and third parts are the same eight bars, called the minuet. The middle part is called the trio. A simple way to represent this structure is to write ABA, where section A is the minuet and section B is the trio. Each section is eight bars long.\n\nSo to create such a musical piece, it was necessary to write down the minuet part (section A) and the trio part (section B). Rather than generate one section at a time, in Kirnberger's game the first measures of both section A and B were generated, then the second measures, and so on until all eight measures were complete.\n\nFor a particular measure, the procedure for generating the corresponding minuet measure and the trio measure worked as follows. One would roll two fair six-sided dice, and label the results X 1 and X 2 . X 1 was then used in a look-up table to determine the content of that measure of the minuet, and X 2 was used in a different look-up table to determine the content of that measure of the trio. Figure 1 shows a table from a 1767 edition [3] of Kirnberger's work. \"Premiere partie\" indicates the minuet, and \"seconde partie\" indicates the trio.  Each roll of the dice for each bar of the result determines a different piece. There are sixteen distinct bars in total in sections A and B, and each bar has six possibilities (since one die is rolled per bar); hence, this game can theoretically produce 6 16 = 2.82110991\u00d710 12 different musical compositions.\n\nHowever, these dice games are greatly restricted in that they rely on a composer that has already created the possible bars to be put together. In other words, the player is merely piecing together already composed music in new ways.\n\nThat leaves open the following question: how does one randomly create the individual notes that comprise the bars?\n\nOne such approach is to model music using Markov chains, which opens doors to computationally composing arbitrarily long and fully-fledged compositions.\n\n\nUsing Markov chains\n\nIn the musical dice game, the bar choices were independent. However, this is a bad idea for note generation. If the notes are changing too rapidly, and each note is independent of the preceding note, the result is more likely to be cacophony than music.\n\nA solution comes with the use of Markov chains. A Markov chain is a sequence of random variables X 1 , X 2 , X 3 , . . . such that the distribution of X t+1 conditioned on X 1 , . . . , X t only depends on X t , and not on the values of X 1 , . . . , X t\u22121 . Markov chains were introduced in 1906 by Andrey Markov [5] as a way of understanding which letters follow others in a typical text.\n\nIn this paper, Markov chains are used to determine the sequence of notes (both in pitch and duration). The distribution of the type of the next note will only depend on the current note, and not on any of the notes that came before.\n\nThe first use of Markov chains to compose music came in 1957, when the ILLIAC I computer was used to compose the Illiac Suite by Hiller and Isaacson [7]. Since then, Markov chains have been a simple tool for automatically generating a new piece of music. The Markov chains employed by Hiller and Isaacson dealt purely with horizontal melody; in this paper, we endeavor to incorporate harmony and rhythm as well.\n\nIn the past sixty years since Hiller and Isaacson, Markov chains have become increasingly popular as a means of music generation. Ramanto and Maulidevi (2017) [6] employed Markov chains for procedural content generation of music, in which music is randomly generated in response to a user-inputted mood. Rather than generating music in the style of an existing piece as this paper seeks to, they sought to generate music in the style of a certain mood. Linskens (2014) [4] also employed Markov chains for algorithmic music improvisation, rather than composition. The Markov chains were trained on an existing piece, like they are in this paper, but then the algorithm was given a certain amount of freedom to vary between the notes of a designated chord or even an unspecified pitch lying somewhere in the bounds of a chord in order to achieve the improvisation quality. This paper does not explore improvisation, though this is certainly an interesting avenue.\n\nOthers, such as Yanchenko and Mukherjee (2018) [8] have used more complex statistical models such as time series models, which are variations on Hidden Markov Models (HMMs). With the Hidden Markov Model, instead of generating a sequence of states, each state omits an observable, and the states themselves are hidden. The idea here is to use techniques such as dynamic programming to backtrack from the generated observables in order to determine the optimal sequence of hidden states that generated these observables. Kathiresan (2015) [1] also employs HMMs to generate music against a variety of constraints with the goal of making it sound as subjectively \"musical\" as possible. This paper does not delve into HMMs, as the aim is to experiment with the musical capabilities of simple Markov chains, but this may certainly be an interesting avenue for future exploration.\n\nThe rest of the paper is organized as follows. In the next section ( \u00a72), we describe the terminology of Markov chains in more detail. The subsequent sections show how to estimate the parameters of the chain ( \u00a73- \u00a74), and then finally a new piece of music is built from an existing piece using these estimates ( \u00a75). \u00a76 contains the results of our work and \u00a77 concludes this paper.\n\n\nTheoretical Foundations of Markov Chains\n\nConsider a sequence of random variables X 1 , X 2 , X 3 , . . .. Such a set of random variables {X i } forms a stochastic process. The index i in X i is often called the time. For a fixed time i, X i is called the state of the chain.\n\nA Markov chain is a stochastic process such that for all i, it holds that\n[X i | X 1 , . . . , X i\u22121 ] \u223c [X i | X i\u22121 ].\nHere the \u223c symbol means that the left hand side and the right hand side have the same distribution. In words, this says that the distribution of the i th state in the sequence, given the values of all the states that came before, will depend purely on the previous state. The most common type of Markov chain is also time homogeneous, which means that for all i it holds that\n[X i | X i\u22121 ] \u223c [X 2 | X 1 ].\nIn other words, the random way in which the state evolves does not change as the time changes.\n\nA Markov chain is also called a memoryless process, since the next state depends purely on the current state, and not on the memory of the notes that came before. In order to describe a time homegeneous Markov chain, it is necessary to know what values the random variables X i can take on, and what the probabilities are for moving to the next state.\n\n\nRepresenting Markov chains\n\nMarkov chains can be represented in a variety of ways. One helpful way is to represent them graphically with a directed graph. This is a collection of nodes and edges, in which each edge has a direction from one node to another. Each node represents a state in the Markov chain, and each edge has a probability associated with it that represents the probability the source node will transition to the destination node (the source and destination node can be the same, which means the process remains in the same state). All the probabilities associated with the edges extending from a node must sum to one (if any edges are omitted, it is assumed that they represent a transition with probability zero).\n\nAn example of a graphical representation of a simple Markov chain is shown in Figure 2. The states {Sunny, Windy, Rainy} represent weather, and the probabilities of moving between the three states are above the arrows.\n\nAn alternate way of encoding the Markov chain is with the transition matrix, where the (a, b) th entry of the matrix is the probability of moving from state a to state b. Note that all rows in the transition matrix (or equivalently the probabilities on all outgoing edges) must sum to 1.\n\n\nUsing Markov Chains to Generate Music\n\nNow consider a given piece of music, which we will call the training data. This data will be used to estimate the probabilities for our Markov chain. This chain can then be used to generate music in the same style as the original piece.\n\nIn order to generate music, we want the nodes in the Markov chain, or the set of states, to represent sound objects. These are entities that represent a single note or chord and contain information about its pitch(es), octave(s), and duration. Thus, each node will contain data about the single note name or collection of notes in the chord, using note names A through G; the accidental (sharp, flat, or natural) for each note, represented by #, b, or no symbol, respectively; the octave for each note, represented by an integer from 0-8; and the duration of the sound object, denoted by a whole note, half note, quarter note, or some shorter value.\n\nOne additional special case will be accounted for: the rest, where no sound is played. A rest will be indicated by R. Rests also have a duration.\n\nThe set of states will be determined by parsing the piece of music. This process will be discussed shortly, in \u00a74.\n\nWe can define our transition matrix by determining the probability for each pair of sound objects s 1 and s 2 , i.e., the chance of moving from s 1 to s 2 in the chain. In addition, we would also like to define an initial probability vector I. This vector gives us the probability that for each state s i , the initial state in the chain X 1 will be equal to s i .\n\nFor example, consider the Markov chain represented graphically in Figure 3 that consists of only three sound objects. Note that represents a quarter note, and represents an eighth note.  The set of states in the example is S = {(C#4, E4, A4) , F4 , R }. The first state is a chord that consists of three notes -C#, E4, and A4 -and lasts for a duration of one quarter note. The second state is a single note -F4 -with a duration of one eighth note, and the final state is a rest with a duration of one quarter note.\n\nThe transition matrix M representation of this chain is shown in Figure 4. In order to generate a new piece of music, it is necessary to choose a sound object to start with in our generation. We could simply pick the first sound object in the training data, or we could create an initial probability vector that tells us the probability that each sound object is encountered. We will choose to do the latter and determine our initial probability vector by finding how many total sound objects there are in the piece (including repetitions) and the number of times each individual sound object appears.\n\nTo see how this works, suppose that in the training data, (C#4, E4, A4) appears twice, F4 appears three times, and R appears once. Then the resulting initial probability vector I is shown in Figure 5. We now have the tools to generate music from the Markov chain in the same style as the training data.\n\n\nParsing the Training Data\n\nNow we move from theory to practice: using a computer, how can we find the probabilities for our Markov chain, and then simulate a musical score using this chain? The Python language will be used for this exploration.\n\nThroughout this section, please refer to the file parse_musicxml.py in Appendix A.1 for the full Python code. Alternatively, the code as well as the examples are available at the following link:\nhttps://github.com/ilanashapiro/Markov-Model-Music-Generation\nThere are additional examples included in the GitHub repository; the ones discussed in this paper are in the files named \"Cantabile flute excerpt\" and \"Cantabile piano excerpt\" (.musicxml extension for the original version and .mid extension for the generated version).\n\nThe training data (the input musical piece) is given in a symbolic form called MusicXML. It is a file format that encodes musical notation based on extensible markup language (hence the xml ending of MusicXML).\n\nWe will use Python's ElementTree library to parse the MusicXML file and the NumPy library to build and manipulate matrices in a class called Parser. This class will be used later in the runner file generate.py to parse the input MusicXML files. Parser's constructor initializes some important information, such as filename, transition matrix, initial probability vector, and states (the sound objects we will obtain from the input piece).\n\nWe initially obtain the data that allows us to build our transition matrix. All sound objects (whether they are chords or individual notes) are extracted sequentially from the MusicXML file and stored in an ordered dictionary alongside the number of times each one appears in the piece. A sound object is uniquely identified by its note(s), accidental, octave, and duration. At this time, we also simultaneously save each sound object in an ordered list (the set of states) in the order it appears. Note that this ordered list, as it represents a set, does not contain repetitions. This process ensures that the sound object dictionary and the list of states contain the same data in the same order, which will allow us to successfully create our transition matrix.\n\nFrom the dictionary, the transition matrix is created using NumPy. If the length of the list of states (i.e. the number of sound objects) is n, then the transition matrix has dimensions n \u00d7 n. Both the row and column order correspond to the order of the state dictionary and the list of states. The transition matrix is built as follows:\n\n1. Using NumPy, the matrix is initialized to the known dimensions n \u00d7 n.\n\nNext, the matrix is built row by row.\n\n2. Each entry i, j in the matrix is initialized to represent the number of times the i th sound object transitions to the j th sound object in the list of states. At this point, the matrix is symmetric. 3. Once all n 2 entries have been initialized, NumPy is used to divide all the elements in each row by the row sum. 4. Finally, for each row, each entry is replaced with the sum of all the previous entries using NumPy's cumsum function. This means that the first element in each row will retain the value from the previous step, and all subsequent values will be sequentially greater. Note that because of what we did in the previous step, by applying cumsum we ensure that the final value in each row is now 1.\n\nImagine the i th row representing a line, and each i, j entry representing a segment on that line. The i, j entry that corresponds to the longest line segment is the entry corresponding to some sound object (i.e. state) j that sound object i has the highest probability of transitioning to. This process to transform the data into the line analogy is also known as inverse transform sampling.\n\nThe initial probability vector is built in a similar way. This vector has dimensions 1 \u00d7 n, since we simply want to know the probability that each of n sound objects is chosen at random. We therefore build the initial probability vector as follows:\n\n1. Using NumPy, a matrix is initialized to the known size of 1 \u00d7 n (i.e. one row of length n). 2. The i th entry in the matrix (i.e. the initial probability vector) is initialized to represent the number of times the i th note in the list of states appears in the piece. 3. Once all n entries have been initialized, NumPy is used to divide all the elements in each row by the row sum. 4. Finally, NumPy's cumsum function is used to replace each entry in the single row of this matrix with the sum of all the previous entries. This means that the first element will retain the value from the previous step, and all subsequent values will be sequentially greater. Note that because of what we did in the previous step, by applying cumsum we ensure that the final (i.e. n th ) value is now 1.\n\nThe line segment analogy applies here exactly the same way as before.\n\nA final thing to note is that the last note in the piece is assigned a transition to a quarter rest, and a transition is then added from the quarter rest to the first note in the piece. This ensures that the Markov model contains no absorbing states, or states that once entered, cannot be exited.\n\n\nGenerating New Music\n\n[Throughout this section, please refer to the file generate.py in Appendix A.\n\n2.]\n\nNow that we have a working parser that initializes all the elements we need for our Markov chain, we are ready to generate new music in the style of the training data.\n\nWe now a create file called generate.py and import our parser file (parse_musicxml.py). We can instantiate the Parser class to create Parser objects (i.e., create Markov chains) for however many songs we want, so long as we have the corresponding MusicXML files. In the code attached here, four parsers are created in a list. This allows us to loop through the Parser objects in the list and generate music for the Markov chain that each represents.\n\nIn order to generate music from a Markov chain, we start by using NumPy to generate a random number from 0 to 1 inclusive. This is known as a standard uniform random variable. Now consider the initial probability vector. To use our generated standard uniform to draw from this vector, think of the generated random number as being a point on the line segment that is the result of inverse transform sampling having been applied to this vector. This can be visualized in Figure 6.  We will choose the next highest state (i.e., sound object) compared to the randomly chosen point we generated. In this example, our randomly generated point would give us the sound object C3 . This allows us to choose the initial state of the Markov model. We then generate a sequence of states (i.e., our generated music) from the model starting at this initial state. We follow the same method as above for choosing the next state to transition to, except we now use the transition matrix instead of the initial probability vector. The length of the sequence is determined by the user's input. In the code in the Appendix, the length chosen is 100 notes.\n\nAfter generating the sequence of sound objects, the sequence is written out to a MIDI file, which is then loaded into the symbolic music software MuseScore for viewing and playing.\n\n\nResults of the Music Generation\n\nThe generated music in this paper results from Markov chains trained on excerpts from Shapiro's composition Cantabile for flute and piano. In order to obtain these excerpts, the flute and piano parts were separated, and a short passage was taken from each in order to demonstrate a monophonic example (i.e., the solo flute part), and an example with harmony/chords (i.e., the piano part). The results of the music generated from these parts using their respective Markov chains are as follows:  Notice that the generated flute part does not have the same number of measures as the original flute part. When running the program, the user must specify how many measures the generated part will be. This number does not have to match that of the training data, since the training data is only used to create the Markov chain. Once this is complete, arbitrarily long pieces can be generated from the chain.\n\nThe generated flute part in Figure 8 contains marked similarities to the original. The rhythm in measure 1 of the generated part is quite similar to the rhythm in measure 4 of the original, and the harmony throughout centers around the key of A major, just like the original, even though the key signature indicates D minor. Additionally, notice the behavior of the C in measures 3-4: it is sometimes flat and sometimes sharp, a behavior picked up from measures 6-7 of the original score. Some notes, such as the first two eighth notes of measure 6 in the generated score, are a direct quote (in this case, of measure 1) from the original. The last beat of measure 2 in the generated score also appears to be an incomplete F# minor scale inspired by measure 4 of the original. Figure 9 below contains the original piano part (i.e., the training data for piano) and Figure 10 on the next page contains the generated piano part. They also do not have the same number of measures, as was specified by the user before running the program. (Note that because of the way the MIDI file was generated, the generated piano part gets compressed into a single staff. This is not a result of the Markov chain, it is simply due to the MIDI formatting).\n\nThe generated piano part in Figure 10 demonstrates melodic, harmonic, and rhythmic qualities from the training piece. The parallel octaves from the original score are frequent throughout the generated part, and harmonic structures (like the augmented C chord (C-E-G#) in the final measure and the A major scale in measure 9) have made their way through as well.\n\nIn addition, notice the rhythmic similarity of the scores, particularly the common patterns of sixteenth notes tied over into the next beat and the pattern of four sixteenths, one eighth and two sixteenths, and two eighths that appears in both measure 3 of the original and measure 1 of the generated score.\n\n\nConclusions\n\nUsing a simple Markov chain, music can be successfully generated in the style of the training piece. Rhythm, octave, pitch, and accidentals are accounted for. However, there are limitations to the current setup as well as many other avenues to be explored. Currently, the parser does not handle pieces with multiple voices within a single part, or a piece with multiple instruments considered simultaneously, due to difficulty parsing the data from the current musicXML format. In addition, dynamics are not taken into account. Other statistical models, such as the Hidden Markov Model (HMM) mentioned earlier in the paper, may provide interesting avenues of exploration. Using HMMs and dynamic programming, we could, for instance, generate observable notes/chords, and use dynamic programming to uncover the optimal sequence of rhythms, or perhaps dynamics (whatever we choose to be the hidden states) based on the observables. It may also be an interesting avenue to explore the power of simple as well as hidden Markov models in creating less tonal music, and even jazz. It is evident that statistical modeling opens a multitude of creative avenues for computer music generation.      \n\nFor\ninstance, if bar 4 of the minuet were under construction, and the first roll were a 4, then based on Kirnberger's encoding, bar 4 of the minuet (section A) would use piece 74. Similarly, if the second roll were a 2, then bar 4 of the trio (i.e., section B) would use piece 39.\n\nFigure 1 :\n1Table forusing die rolls to construct bars of a minuet and trio. Scan from https: //imslp.org/wiki/File:PMLP243537-kirnberger_allezeit_fertiger_usw.pdf.\n\nFigure 2 :\n2Markov Chain graph example.The transition matrix for the Markov chain fromFigure 2is as follows.\n\nFigure 3 :\n3Musical Markov Chain example using graphical representation.\n\nFigure 4 :\n4Musical Markov Chain example using a transition matrix.\n\nFigure 5 :\n5Musical Markov Chain Example\n\nFigure 6 :\n6Inverse Transform Sampling example: the blue dot is a uniform draw from 0 to 1, the value of 0.3443 indicates that the draw is F4 since that is the next label to the right of the dot.\n\nFigure 7\n7below contains the original flute part (that is, the training data), andFigure 8on the next page contains the generated flute part.\n\nFigure 7 :Figure 8 :\n78Original flute part [excerpt from Cantabile by Ilana Shapiro] Generated flute part\n\nFigure 9 :Figure 10 :\n910Original Piano Part [excerpt from Cantabile by Ilana Shapiro] Generated Piano Part\n\n\nNone # the prev note ( it may be part of a chord ). but this variable itself NEVER stores\n\n\n. bu il d _n or ma l iz ed _i n it ia l_ p ro ba bi li t y_ ve ct o r () 142 143 def bu il d_ n or ma li z ed _i ni ti a l_ pr ob a bi li ty _ ve ct or ( self ) : 144 self . n ormal ized_ initi al_pr obabi lity_ vector = np . array ( list ( init_prob for init_prob in self . initial_transition_dict . values () ) ) 145 # convert to probabilities 146 self . n ormal ized_ initi al_pr obabi lity_ vector = self . n ormal ized_ initi al_pr obabi lity_ vecto r / self . n ormal ized_ initi al_pr obabi lity_ vecto r . sum ( keepdims = True ) 147 # multinomial dist 148 self . n ormal ized_ initi al_pr obabi lity_ vector = np . cumsum ( self . nor maliz ed_in itial _prob abili ty_ve ctor ) 149 150 def bu i l d_ n or m a li z ed _ t ra n si t i on _ pr o b ab i l it y _m a t ri x ( self ) : 151 # initialize matrix to known size 152 list_dimension = len ( self . states ) 153 self . nor ma liz ed _tr an sit io n_p rob ab ili ty _ma tr ix = np . zeros (( list_dimension , list_dimension ) , dtype = float )\n\n154 155\n154for i , sound_object in enumerate ( self . states ) : self . nor ma liz ed _tr an sit io n_p ro bab ili ty _ma tr ix = self . nor ma liz ed _tr an sit ion _p rob ab ili ty _ma tr ix / self . no rm ali ze d_t ra nsi tio n_ pro ba bil it y_m at rix . sum ( axis =1 , keepdims = True ) self . nor ma liz ed _tr an sit io n_p ro bab ili ty _ma tr ix = np . cumsum ( self . 166 if sound_object_to_insert not in self . states : def print_dict ( self , dict ) : for key in dict : print ( key , \" : \" , dict [ key ]) # I did not write this function . Credit : Akavall on StackOverflow 10 # https :// stackoverflow . com / questions /17118350/ howto -find -nearest -value -that -is -greater -in -numpyarray 11 def find_nearest_above ( my_array , target ) : diff = my_array -target 13 mask = np . ma . less ( diff , 0) 14 # We need to mask the negative differences and zero 15 # since we are looking for values above 16 if np . all ( mask ) : return None # returns None if target is greater than any value 18 masked_diff = np . ma . masked_array ( diff , mask ) # comment in for same start note as training data note_index = find_nearest_above ( parser . no rm ali ze d_t r an si tio n_ pro ba bil it y_m at rix [ note_index ] , note_prob ) sequence [ curr_index ] = parser . states [ note_index ]156 \n\nfor j , transition_sound_object in enumerate ( \nself . states ) : \n157 \n\nif transition_sound_object in self . \ntransition_probability_dict [ sound_object \n]: \n\n158 \n\nself . \nno rm ali ze d_t ra nsi ti on_ pro ba bil it y_m at rix \n[ i ][ j ] = self . \ntransition_probability_dict [ \nsound_object ][ transition_sound_object ] \n\n159 \n\n160 \n\nnormalized_transition_probability_matrix , axis \n=1) \n\n161 \n162 \n\ndef handle_insertion ( self , prev_sound_object , \nsound_object_to_insert ) : \n\n163 \n\nif sound_object_to_insert is not None and \nsound_object_to_insert [0] is not None : \n\n164 \n\nif prev_sound_object is not None and \nprev_sound_object [0] is not None : \n\n165 \n\nself . insert ( self . transition_probability_dict \n, prev_sound_object , \nsound_object_to_insert ) \n\n167 \n\nself . states . append ( sound_object_to_insert ) \n\n168 \n169 \n\nif sound_object_to_insert in self . \ninitial_transition_dict : \n\n170 \n\nself . initial_transition_dict [ \nsound_object_to_insert ] = self . \ninitial_transition_dict [ \nsound_object_to_insert ] + 1 \n\n171 \n\nelse : \n172 \n\nself . initial_transition_dict [ \nsound_object_to_insert ] = 1 \n\n173 \n174 \n\ndef insert ( self , dict , value1 , value2 ) : \n\n175 \n\nif value1 in dict : \n\n176 \n\nif value2 in dict [ value1 ]: \n\n177 \n\ndict [ value1 ][ value2 ] = dict [ value1 ][ value2 ] \n+ 1 \n\n178 \n\nelse : \n\n179 \n\ndict [ value1 ][ value2 ] = 1 \n\n180 \n\nelse : \n\n181 \n\ndict [ value1 ] = {} \n\n182 \n\ndict [ value1 ][ value2 ] = 1 \n\n183 \n184 \n\n185 \n\n186 \n\n187 \n188 \n\ndef rhythm_to_float ( self , duration ) : \n\n189 \n\nswitcher = { \n\n190 \n\n\" whole \" : 4 , \n\n191 \n\n\" half \" : 2 , \n\n192 \n\n\" quarter \" : 1 , \n\n193 \n\n\" eighth \" : 1/2 , \n\n194 \n\n\" 16 th \" : 1/4 , \n\n195 \n\n\" 32 nd \" : 1/8 , \n\n196 \n\n\" 64 th \" : 1/16 , \n\n197 \n\n\" 128 th \" : 1/32 \n\n198 \n\n} \n\n199 \n\nreturn switcher . get ( duration , None ) \n\nA.2. generate.py \n\n1 import parse_MusicXML \n2 import random \n3 import numpy as np \n4 import midi_numbers \n5 from midiutil import MIDIFile \n6 import sys \n7 import re \n\n8 \n\n9 12 \n\n17 \n\n19 \n\nreturn masked_diff . argmin () \n\n20 \n\n21 def generate ( seq_len , parser ) : \n\n22 \n\nsequence = [ None ] * seq_len \n\n23 \n24 \n\n25 \n\nnote_prob = random . uniform (0 , 1) \n\n26 \n\nrhythm_prob = random . uniform (0 , 1) \n\n27 \n\nnote_index = find_nearest_above ( parser . \nnormalized_initial_probability_vector , \nnote_prob ) \n\n28 \n\ncheck_null_index ( note_index , \" ERROR getting note \nindex in initial probability vector \" ) \n\n29 \n\ncurr_index = 0 \n\n30 \n31 \n\n# comment in for seed \n\n32 \n\n# sequence [0] = parser . states [0] \n\n33 \n\n# note_index = 0 \n\n34 \n\n# curr_index = 1 \n35 \n36 \n\nwhile ( curr_index < seq_len ) : \n\n37 \n\nnote_prob = random . uniform (0 , 1) \n\n38 \n\nrhythm_prob = random . uniform (0 , 1) \n\n39 \n40 \n\n41 \n\ncheck_null_index ( note_index , \" ERROR getting note \nindex in probability transition matrix \" ) \n\n42 \n43 \n\n44 \n\ncurr_index += 1 \n\n45 \n46 \n\nreturn sequence \n\n47 \n\n48 def check_null_index ( index , error_message ) : \n\n49 \n\nif ( index == None ) : \n\n50 \n\nprint ( error_message ) \n\n51 \n\nsys . exit (1) \n\n\noutput_midi . writeFile ( output_file )\nA. AppendixThe following code can also be accessed at https://github.com/ilanashapiro/Markov-Model-Music-Generation A.1. parse MusicXML.py 1 import xml . etree . ElementTree as ET 2 import collections 3 import numpy as np4 5with open ( parser . filename + \" . mid \" , \" wb \" ) as output_file :\nAutomatic Melody Generation. Thayabaran Kathiresan, KTH Royal Institute of Technology School of Electrical EngineeringPhD thesisThayabaran Kathiresan, Automatic Melody Generation, PhD thesis, KTH Royal Institute of Technology School of Electrical Engineering, June 2015.\n\nJohann Philipp Kirnberger, Der allezeit fertige Polonaisen-und Menuettencomponist. Werner Icking1757Johann Philipp Kirnberger, Der allezeit fertige Polonaisen-und Menuet- tencomponist, Werner Icking, 1757.\n\nJohann Philipp Kirnberger, Der allezeit fertige Polonaisen-und Menuettencomponist. George Ludewig Winter1767Johann Philipp Kirnberger, Der allezeit fertige Polonaisen-und Menuet- tencomponist, George Ludewig Winter, 1767.\n\nMusic Improvisation using Markov Chains. J Erlijn, Linskens, Maastricht UniversityPhD thesisErlijn J Linskens, Music Improvisation using Markov Chains, PhD thesis, Maastricht University, June 2014.\n\nAndrey Andreevich Markov, Classics of Science, Academy of Sciences of the USSR. Yu. V. LinnikAndrey Andreevich Markov, In Yu. V. Linnik, editor, Selected Works, Classics of Science, Academy of Sciences of the USSR, 1951.\n\nMarkov chain based procedural music generator with user chosen mood compatibility. Adhika Sigit Ramanto, Nur Ulfa Maulidevi, International Journal of Asia Digital Art & Design. 211Adhika Sigit Ramanto and Nur Ulfa Maulidevi, \"Markov chain based procedural music generator with user chosen mood compatibility\", Inter- national Journal of Asia Digital Art & Design, Volume 21 Issue 1 (March 2017), pages 19-24.\n\nRevisiting the illiac suite-a rule based approach to stochastic processes. \u00d6rjan Sandred, Mikael Laurson, Mika Kuuskankare, Sonic Ideas/Ideas Sonicas. 2\u00d6rjan Sandred, Mikael Laurson, and Mika Kuuskankare, \"Revisiting the illiac suite-a rule based approach to stochastic processes\", Sonic Ideas/Ideas Sonicas, Volume 2 (2009), pages 42-46.\n\nClassical Music Composition Using State Space Model. K Anna, Sayan Yanchenko, Mukherjee, Duke UniversityPhD thesisD # \" : 3 , 60 \" Eb \" : 3 , 61 \" E \" : 4 , 62 \" Fb \" : 4 , 63 \" E # \" : 5 , 64 \" F \" : 5 , 65 \" F # \" : 6 , 66 \" Gb \" : 6 , 67 \" G \" : 7 , 68 \" G # \" : 8 , 69 \" Ab \" : 8Anna K Yanchenko and Sayan Mukherjee, Classical Music Composition Using State Space Model, PhD thesis, Duke University, September 2018. \" D # \" : 3 , 60 \" Eb \" : 3 , 61 \" E \" : 4 , 62 \" Fb \" : 4 , 63 \" E # \" : 5 , 64 \" F \" : 5 , 65 \" F # \" : 6 , 66 \" Gb \" : 6 , 67 \" G \" : 7 , 68 \" G # \" : 8 , 69 \" Ab \" : 8 ,\n", "annotations": {"author": "[{\"end\":74,\"start\":60},{\"end\":101,\"start\":75},{\"end\":112,\"start\":102},{\"end\":128,\"start\":113},{\"end\":136,\"start\":129},{\"end\":151,\"start\":137},{\"end\":163,\"start\":152},{\"end\":245,\"start\":164},{\"end\":287,\"start\":246}]", "publisher": null, "author_last_name": "[{\"end\":73,\"start\":66},{\"end\":85,\"start\":80},{\"end\":111,\"start\":104},{\"end\":127,\"start\":122},{\"end\":135,\"start\":129},{\"end\":150,\"start\":143},{\"end\":162,\"start\":157}]", "author_first_name": "[{\"end\":65,\"start\":60},{\"end\":79,\"start\":75},{\"end\":103,\"start\":102},{\"end\":114,\"start\":113},{\"end\":121,\"start\":115},{\"end\":142,\"start\":137},{\"end\":156,\"start\":152}]", "author_affiliation": "[{\"end\":244,\"start\":165},{\"end\":286,\"start\":247}]", "title": "[{\"end\":37,\"start\":1},{\"end\":324,\"start\":288}]", "venue": "[{\"end\":393,\"start\":326}]", "abstract": "[{\"end\":1344,\"start\":613}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1902,\"start\":1899},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3066,\"start\":3063},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4581,\"start\":4578},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5042,\"start\":5039},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5465,\"start\":5462},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5775,\"start\":5772},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6316,\"start\":6313},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6802,\"start\":6785},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6806,\"start\":6803}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":24554,\"start\":24273},{\"attributes\":{\"id\":\"fig_1\"},\"end\":24720,\"start\":24555},{\"attributes\":{\"id\":\"fig_2\"},\"end\":24830,\"start\":24721},{\"attributes\":{\"id\":\"fig_4\"},\"end\":24904,\"start\":24831},{\"attributes\":{\"id\":\"fig_5\"},\"end\":24973,\"start\":24905},{\"attributes\":{\"id\":\"fig_6\"},\"end\":25015,\"start\":24974},{\"attributes\":{\"id\":\"fig_8\"},\"end\":25212,\"start\":25016},{\"attributes\":{\"id\":\"fig_9\"},\"end\":25355,\"start\":25213},{\"attributes\":{\"id\":\"fig_10\"},\"end\":25462,\"start\":25356},{\"attributes\":{\"id\":\"fig_11\"},\"end\":25571,\"start\":25463},{\"attributes\":{\"id\":\"fig_12\"},\"end\":25663,\"start\":25572},{\"attributes\":{\"id\":\"fig_13\"},\"end\":26670,\"start\":25664},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":30989,\"start\":26671}]", "paragraph": "[{\"end\":1794,\"start\":1360},{\"end\":2295,\"start\":1796},{\"end\":2621,\"start\":2297},{\"end\":3480,\"start\":2623},{\"end\":3715,\"start\":3482},{\"end\":3831,\"start\":3717},{\"end\":3985,\"start\":3833},{\"end\":4262,\"start\":4009},{\"end\":4654,\"start\":4264},{\"end\":4888,\"start\":4656},{\"end\":5301,\"start\":4890},{\"end\":6264,\"start\":5303},{\"end\":7139,\"start\":6266},{\"end\":7523,\"start\":7141},{\"end\":7801,\"start\":7568},{\"end\":7876,\"start\":7803},{\"end\":8299,\"start\":7924},{\"end\":8425,\"start\":8331},{\"end\":8778,\"start\":8427},{\"end\":9512,\"start\":8809},{\"end\":9732,\"start\":9514},{\"end\":10021,\"start\":9734},{\"end\":10299,\"start\":10063},{\"end\":10950,\"start\":10301},{\"end\":11097,\"start\":10952},{\"end\":11213,\"start\":11099},{\"end\":11579,\"start\":11215},{\"end\":12095,\"start\":11581},{\"end\":12698,\"start\":12097},{\"end\":13002,\"start\":12700},{\"end\":13249,\"start\":13032},{\"end\":13445,\"start\":13251},{\"end\":13777,\"start\":13508},{\"end\":13989,\"start\":13779},{\"end\":14429,\"start\":13991},{\"end\":15196,\"start\":14431},{\"end\":15535,\"start\":15198},{\"end\":15609,\"start\":15537},{\"end\":15648,\"start\":15611},{\"end\":16364,\"start\":15650},{\"end\":16758,\"start\":16366},{\"end\":17008,\"start\":16760},{\"end\":17799,\"start\":17010},{\"end\":17870,\"start\":17801},{\"end\":18169,\"start\":17872},{\"end\":18271,\"start\":18194},{\"end\":18276,\"start\":18273},{\"end\":18445,\"start\":18278},{\"end\":18896,\"start\":18447},{\"end\":20035,\"start\":18898},{\"end\":20217,\"start\":20037},{\"end\":21155,\"start\":20253},{\"end\":22396,\"start\":21157},{\"end\":22759,\"start\":22398},{\"end\":23068,\"start\":22761},{\"end\":24272,\"start\":23084}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7923,\"start\":7877},{\"attributes\":{\"id\":\"formula_1\"},\"end\":8330,\"start\":8300},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13507,\"start\":13446}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1358,\"start\":1346},{\"attributes\":{\"n\":\"1.1.\"},\"end\":4007,\"start\":3988},{\"attributes\":{\"n\":\"2.\"},\"end\":7566,\"start\":7526},{\"attributes\":{\"n\":\"2.1.\"},\"end\":8807,\"start\":8781},{\"attributes\":{\"n\":\"3.\"},\"end\":10061,\"start\":10024},{\"attributes\":{\"n\":\"4.\"},\"end\":13030,\"start\":13005},{\"attributes\":{\"n\":\"5.\"},\"end\":18192,\"start\":18172},{\"attributes\":{\"n\":\"6.\"},\"end\":20251,\"start\":20220},{\"attributes\":{\"n\":\"7.\"},\"end\":23082,\"start\":23071},{\"end\":24277,\"start\":24274},{\"end\":24566,\"start\":24556},{\"end\":24732,\"start\":24722},{\"end\":24842,\"start\":24832},{\"end\":24916,\"start\":24906},{\"end\":24985,\"start\":24975},{\"end\":25027,\"start\":25017},{\"end\":25222,\"start\":25214},{\"end\":25377,\"start\":25357},{\"end\":25485,\"start\":25464},{\"end\":26679,\"start\":26672}]", "table": "[{\"end\":30989,\"start\":27970}]", "figure_caption": "[{\"end\":24554,\"start\":24278},{\"end\":24720,\"start\":24568},{\"end\":24830,\"start\":24734},{\"end\":24904,\"start\":24844},{\"end\":24973,\"start\":24918},{\"end\":25015,\"start\":24987},{\"end\":25212,\"start\":25029},{\"end\":25355,\"start\":25224},{\"end\":25462,\"start\":25380},{\"end\":25571,\"start\":25489},{\"end\":25663,\"start\":25574},{\"end\":26670,\"start\":25666},{\"end\":27970,\"start\":26683}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":3028,\"start\":3020},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":9600,\"start\":9592},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":11655,\"start\":11647},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":12170,\"start\":12162},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":12899,\"start\":12891},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":19376,\"start\":19368},{\"end\":21193,\"start\":21185},{\"end\":21942,\"start\":21934},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":22031,\"start\":22022},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":22435,\"start\":22426}]", "bib_author_first_name": "[{\"end\":31363,\"start\":31353},{\"end\":31610,\"start\":31596},{\"end\":31817,\"start\":31803},{\"end\":32068,\"start\":32067},{\"end\":32242,\"start\":32225},{\"end\":32536,\"start\":32530},{\"end\":32560,\"start\":32552},{\"end\":32937,\"start\":32932},{\"end\":32953,\"start\":32947},{\"end\":32967,\"start\":32963},{\"end\":33251,\"start\":33250},{\"end\":33263,\"start\":33258}]", "bib_author_last_name": "[{\"end\":31374,\"start\":31364},{\"end\":31621,\"start\":31611},{\"end\":31828,\"start\":31818},{\"end\":32075,\"start\":32069},{\"end\":32085,\"start\":32077},{\"end\":32249,\"start\":32243},{\"end\":32550,\"start\":32537},{\"end\":32570,\"start\":32561},{\"end\":32945,\"start\":32938},{\"end\":32961,\"start\":32954},{\"end\":32979,\"start\":32968},{\"end\":33256,\"start\":33252},{\"end\":33273,\"start\":33264},{\"end\":33284,\"start\":33275}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":31594,\"start\":31324},{\"attributes\":{\"id\":\"b1\"},\"end\":31801,\"start\":31596},{\"attributes\":{\"id\":\"b2\"},\"end\":32024,\"start\":31803},{\"attributes\":{\"id\":\"b3\"},\"end\":32223,\"start\":32026},{\"attributes\":{\"id\":\"b4\"},\"end\":32445,\"start\":32225},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":69489806},\"end\":32855,\"start\":32447},{\"attributes\":{\"id\":\"b6\"},\"end\":33195,\"start\":32857},{\"attributes\":{\"id\":\"b7\"},\"end\":33789,\"start\":33197}]", "bib_title": "[{\"end\":32528,\"start\":32447},{\"end\":32930,\"start\":32857}]", "bib_author": "[{\"end\":31376,\"start\":31353},{\"end\":31623,\"start\":31596},{\"end\":31830,\"start\":31803},{\"end\":32077,\"start\":32067},{\"end\":32087,\"start\":32077},{\"end\":32251,\"start\":32225},{\"end\":32552,\"start\":32530},{\"end\":32572,\"start\":32552},{\"end\":32947,\"start\":32932},{\"end\":32963,\"start\":32947},{\"end\":32981,\"start\":32963},{\"end\":33258,\"start\":33250},{\"end\":33275,\"start\":33258},{\"end\":33286,\"start\":33275}]", "bib_venue": "[{\"end\":31351,\"start\":31324},{\"end\":31677,\"start\":31623},{\"end\":31884,\"start\":31830},{\"end\":32065,\"start\":32026},{\"end\":32303,\"start\":32251},{\"end\":32622,\"start\":32572},{\"end\":33006,\"start\":32981},{\"end\":33248,\"start\":33197},{\"end\":31692,\"start\":31679}]"}}}, "year": 2023, "month": 12, "day": 17}