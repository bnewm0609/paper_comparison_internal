{"id": 125954654, "updated": "2022-07-27 23:50:15.683", "metadata": {"title": "Industrial condition monitoring with smart sensors using automated feature extraction and selection", "authors": "[{\"first\":\"Tizian\",\"last\":\"Schneider\",\"middle\":[]},{\"first\":\"Nikolai\",\"last\":\"Helwig\",\"middle\":[]},{\"first\":\"Andreas\",\"last\":\"Sch\u00fctze\",\"middle\":[]}]", "venue": null, "journal": "Measurement Science and Technology", "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "Smart sensors with internal signal processing and machine learning capabilities are a current trend in sensor development. This paper suggests a set of complementary and automated algorithms for feature extraction and selection to be used with smart sensors. The suggested methods for feature extraction can be applied on smart sensors and are capable of extracting signal characteristics from signal shape, time domain, time-frequency domain, frequency domain and signal distribution. Feature selection subsequently is capable of selecting the most important features for linear and nonlinear fault classification. The paper also highlights the potential of smart sensors in combination with the suggested algorithms that provide both data and further functionality from self-monitoring to condition monitoring in industrial applications. The first example applications are condition monitoring of a complex hydraulic machine where smart signal processing allows classification and quantification of four different fault scenarios. Additionally redundancies in the systems were used for self-monitoring and allowed to detect simulated sensor faults before they become critical for fault classification. The second example application is remaining lifetime prediction of electromechanical cylinders that shows applicability to big data and transparency of the solution by providing detailed information about sensor significance.", "fields_of_study": "[\"Physics\"]", "external_ids": {"arxiv": null, "mag": "2844117170", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": null, "doi": "10.1088/1361-6501/aad1d4"}}, "content": {"source": {"pdf_hash": "ea18f2445bbd59387134f7beaa9e2968394f8ad4", "pdf_src": "IOP", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "3def6c81b9015725690b819c03d074f3642c8897", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/ea18f2445bbd59387134f7beaa9e2968394f8ad4.txt", "contents": "\n\n2018\n\nTizian Schneider t.schneider@zema.de \nCenter for Mechatronics and Automation Technology gGmbH\nZeMA\nSaarbrueckenGermany\n\nNikolai Helwig \nCenter for Mechatronics and Automation Technology gGmbH\nZeMA\nSaarbrueckenGermany\n\nAndreas Sch\u00fctze \nDepartment of Mechatronics\nLab for Measurement Technology\nSaarland University\nSaarbrueckenGermany\n\nMeas. Sci. Technol\n2915201810.1088/1361-6501/aad1d4Received 15 February 2018, revised 28 May 2018 Accepted for publication 6 July 2018(Some figures may appear in colour only in the online journal)feature extractionfeature selectioncondition monitoringsmart sensors\nSmart sensors with internal signal processing and machine learning capabilities are a current trend in sensor development. This paper suggests a set of complementary and automated algorithms for feature extraction and selection to be used with smart sensors. The suggested methods for feature extraction can be applied on smart sensors and are capable of extracting signal characteristics from signal shape, time domain, time-frequency domain, frequency domain and signal distribution. Feature selection subsequently is capable of selecting the most important features for linear and nonlinear fault classification. The paper also highlights the potential of smart sensors in combination with the suggested algorithms that provide both data and further functionality from self-monitoring to condition monitoring in industrial applications. The first example applications are condition monitoring of a complex hydraulic machine where smart signal processing allows classification and quantification of four different fault scenarios. Additionally redundancies in the systems were used for self-monitoring and allowed to detect simulated sensor faults before they become critical for fault classification. The second example application is remaining lifetime prediction of electromechanical cylinders that shows applicability to big data and transparency of the solution by providing detailed information about sensor significance.\n\nIntroduction: state of the art and current trends\n\nA current trend in sensor technologies is the integration of additional functionality by use of active measurement principles as seen in various sensor elements and systems. Examples include \u2022 Magnetic sensors like Hall sensors that use spinningcurrent, internal calibration and even correction of offset temperature coefficients though integration of internal chip heaters [1] or magnetoresistive (MR) sensors using the compensation principle to suppress temperature cross sensitivity [2];\n\n\u2022 Micromechanical accelerometers (also using compensation or internal calibration methods) [3] and gyroscopes (using the Coriolis effect with active vibration excitation) [4]; \u2022 Coriolis-based flow sensors also using active excitation and determination of the resonance frequency to measure the density of gases or fluids [5]; \u2022 Chemical sensors using temperature or gate bias modulation for improved selectivity, sensitivity and stability [6].\n\nActive modes of operation also offer additional potential for self-diagnosis, which is already extensively being used in automotive applications [7]. This does not only apply to inertial sensors, where the correct function is checked with Measurement Science and Technology Industrial condition monitoring with smart sensors using automated feature extraction and selection internal excitation, but also for e.g. the lambda probe: here the time constant for heating to the desired operating temper ature is used to detect faults, such as cracks of the ceramic. Selfdiagnosis is especially important for applications in safety and security. Fire detection and explosion protection could not be addressed with low-cost gas sensors, which are prone to poisoning. Here, dynamic operation also allows detection of sensor faults, e.g. poisoning of the sensor material [6].\n\nThus, smart sensors with additional functionality provide a significant added value for higher-level functions, e.g. in production systems. The correct sensor function is also required for condition monitoring of complex systems (see section 2 below). In this case, the correlation of sensor data within the system can also be used to verify the correct sensor function; however, in this case, the sensor fault diagnosis has to be performed at a higher level within the system. Hydraulic system for collection of training data: (top) working circuit with main pump MP1 (orange) with switchable orifice V9, switchable accumulators A1-A4 with different precharge pressures (blue) and variable load V10 (green); (bottom) cooling and filtration circuit with cooler C1 (red) [12]. All marked components can simulate faults with different steps of severity: the pump, for example, can simulate internal leakage by a switchable bypass. Additional trends that will be initiated or at least pushed further by the Industry 4.0 paradigm are \u2022 Measurement as a service: this could be a trend similar to the service provided by Uber in public transport, i.e. measurement values are sold instead of instruments [8].\n\nNote that the measurement uncertainty-determined online by self-calibration-will then influence the price. \u2022 Traceability of individual components down to screws, individual gears and even gaskets: this additional knowledge will allow tolerance measurement in the assembly of (sub-)systems and is also required for a comprehensive condition monitoring to assess the influence of individual processing steps and machines on the final result. \u2022 Self-learning systems: the correlation between sensor data as well as other process and ambient parameters can be evaluated to ensure the correct function of the system in the sense of a system self-diagnosis by making use of machine learning [9]. So far it is unclear if unsupervised methods are sufficient or if supervised learning is required, i.e. knowledge of the current system status for training the evaluation. \u2022 Semantic technologies for analysis of complex systems:\n\ninterpretation of measurement values beyond the purely data-based approaches could offer further opportunities, e.g. for plausibility checks of sensor data and for providing confidence values for (fault) causes. Note that the World Wide Web consortium (W3C) has started working on a semantic sensor network ontology as early as 2005 which allows representation of measurement values and their significance [10].\n\nThe last example shows that the importance of sensors and measurement technology was recognized also by other parties, which leads to some parallel and independent developments. Interestingly, however, aspects like measurement uncertainty and sensor self-monitoring are not addressed in the context of semantic technologies even though semantic representation would be highly valuable especially for these aspects [11].\n\n\nCondition monitoring using data-based modeling\n\nThe potential of data-based sensor signal evaluation is demonstrated by the projects intelligent condition monitoring (iCM) Hydraulics and MoSeS-Pro (modular sensor systems for real time process control and smart condition monitoring). In iCM Hydraulics a hydraulic model system combining a primary circuit with variable load and a secondary circuit for cooling and filtration was used to study the identification of typical system faults (internal pump leakage, delayed valve switching, pressure leakage in the accumulator, reduced cooling efficiency) only based on an evaluation of the typical process sensors (pressure flow rate, temperature, electrical power). The schematic of the test system is shown in figure 1. Figure 2 provides an overview of the approach: the hydraulic system is equipped with a total of 18 physical and virtual (e.g. efficiency calculated from electrical power input and hydraulic power output) sensors, which are read-out with up to 100 Hz.\n\nThe system was used to simulate a periodic industrial process with a working cycle of 1 min duration that is shown in figure 3. In each cycle a total of approx. 50.000 raw sensor values is recorded, which are interpreted as a high-dimensional measurement vector. A multi-step dimensionality reduction covering feature extraction and selection yields a projection obtained by linear discriminant analysis (LDA) [13], which allows classification of the system status, i.e. identification and quantification of the fault. Classification is performed based on the Mahalanobis distance of measured vectors to training group centers. Note that feature extraction is realized with unsupervised methods, i.e. without making use of the system status, while feature selection-here based primarily on support vector machines-and LDA projection are supervised methods, i.e. require the knowledge of the system status [14]. The evaluation is based on a comprehensive training phase in which all combinations of all fault states are tested. The complete training is based on several 1000 working cycles and requires approx. 3 d, primarily due to the relatively slow equilibration of the temperature after changing the cooling efficiency. The complete training data set contains almost 120 Mio raw data points. A systematic validation, e.g. based on k-fold cross-validation and projected faults, completes the development of the statistical model and ensures that no overfitting occurs in spite of the high-dimensional input data set and the supervised training methods [14].\n\nIn this example features were extracted from time domain using adaptive linear approximation (for accumulator pres sure loss, internal pump leakage and valve faults) and from timefrequency domain using Best Daubechies Wavelets (for cooler  figure 2) is switched off and the system runs into the maximum pressure limitation. During the following 50 s the system simulates a hydraulic press application by setting different pressure levels using valve V10. faults). The methods are explained in detail in section 3. Both methods can be implemented very efficiently on low cost hardware. They require less than 1 min on a standard PC for the complete data set with several 1000 cycles. The resulting maximum of 500 features result in a feature space that still has too many dimensions for efficient classification. Therefore, feature selection based on recursive feature elimination support vector machines (for details see section 3.2) for each target, i.e. fault type, is used which is the computationally most expensive step and takes several minutes on a standard PC. Note that these algorithms are chosen automatically as described in section 3.3. The pressure loss of the accumulator was detected using 21 features, 30 for cooler degradation, 10 for internal pump leakage and two for valve operation deterioration. The subsequent calculation of the LDA projection to obtain the 2D plots, see figure 4, or ideally only one discriminant function per system fault only takes a fraction of a second on the same hardware. Even faster is the classification of a new working cycle, i.e. extraction of the selected features, projection in the LDA space for each system fault and classification based on a Mahalanobis classifier, which can thus be performed in realtime even on a low-cost microcontroller-based system.\n\nThe performance of the approach is demonstrated in figure 4 for the four studied system faults: each fault state can be identified independently and its severity or level can be estimated with surprisingly high accuracy. The cooler efficiency, for example, can be estimated with an accuracy of better than 10% (the reduced cooler efficiency was simulated with pulse width modulation of the power supply, the percentage gives the duty cycle used); the accumulator pressure can be determined with an uncertainty of approx. 10 bar. Projected test data which were not used to build the model (open symbols) show that the model allows correct classification of unknown states and even an extrapolation of data outside the training range is possible within limits.  [14], as unknown data are always projected in between the correct adjacent training data of the corresponding fault, i.e. they prove the correct interpolation achieved with the data-processing. data not used in the training to prove that unknown data are interpolated and, in this case, even extrapolated correctly [17]. \u00a9 2015 IEEE. Reprinted, with permission, from [12].\n\nIn further experiments we could show that the training can be transferred from one system to a second, identical system after some calibration, i.e. shift of the LDA projections for the correct system state [15]. Because of the high performance, which was not expected when designing the experiments, we also studied how sensor faults would influence the classification results. Typical sensor faults, namely offset, drift, noise and signal drop-outs were simulated in the recorded data for all sensor channels and the resulting data were used to classify the system state. Not surprisingly, the classification rate is drastically reduced, especially for monitoring of pump leakage and hydraulic accumulator. The sensor faults were defined as new targets for the classification algorithm to allow automatic recognition and train using the same completely automated approach. Again, the simulated sensor faults could be recognized with high reliability independent of the system state as shown in figure 5 for the simulated drift of a pressure sensor. In fact, sensor faults can be diagnosed before they lead to false classification of the system state [16]. Correct classification of the overall system state is still possible by excluding the defective sensor(s) from the evaluation and evaluating the remaining sensors. In fact, up to five of the most important sensors can be excluded from the evaluation and still a correct classification rate of more than 80% is achieved for the various system faults [16].\n\nAnother example for data-driven modeling is shown in figures 6 and 7. A miniaturized sensor system prototype was designed for integration in an electromechanical cylinder (EMCs). These are increasingly applied as feed drives in machine tools, due to their unique combination of high loads, precision, and flexibility. The sensor system combines various (partially redundant) sensors: linear and rotary encoders, 3D accelerometers, microphone, temperature and IR radiation sensors. Currently, the sensor prototype consists of two separate subsystems: First, two stacked sensor PCBs mounted on the front surface of the ball screw inside the EMC housing (Festo ESBF-BS-63-400-5P, \u2300 63 mm, 400 mm stroke, 5 mm spindle pitch, axial load max. 7 kN) carrying a total of nine MEMS sensors. Furthermore, the rotary position of the spindle shaft is measured by an AMR Wheatstone bridge sensor [17] with an external bias magnet generating the support field which interacts with the ferromagnetic teeth of the spindle shaft. This sensor is positioned at a fixed position in the cylinder housing close to the ball bearing pointing to the thread with a working distance of 1 mm. During rotation, the relative position of sensor and teeth changes periodically resulting in sine and cosine sensor signals. Note that despite the fact that condition monitoring of EMCs and hydraulic machines are very different the data structure of time series that can be treated as working cycles (actual working cycle for the hydraulic machine; sliding windows in case of EMCs) are identical and therefore can be treated using the same data processing approach. The diversity of the datasets thereby shows the versatility of the approach.\n\nTo evaluate the sensor system in a condition-monitoring scenario, we induced a local abrasion of the spindle at stroke position 185 mm and recorded several stroke movements with varying velocity and three repetitions. Short-time Fourier transform (STFT) was applied (length 10 000/overlap 2000 samples) for signal processing with subsequent feature extraction and selection as previously demonstrated [18]. Feature extraction captures a total of 210 statistical parameters such as median, variance, skewness, and kurtosis in different intervals of the amplitude spectra of three acceleration axes (FXLN sensor). The features are selected by F-value ranking of univariate ANOVA and dimensionally reduced to three discriminant functions (DFs) using linear discriminant analysis (LDA) to obtain the maximum class separation. The latter algorithms are supervised learning methods, i.e. require class-annotated data which were given as velocity information and local spindle condition traversed by the spindle nut. Figure 6 shows the resulting 3D-projection of sensor data with the planes DF1-DF2 and DF1-DF3 separating the different velocity levels and spindle conditions, respectively. Here, the velocity classes with 10,  Deliberate abrasion as local defect on the spindle and corresponding signal of DF3 versus stroke position (moving average over 10 data points) [16]. A simple threshold for the value of DF3 is sufficient to locate the defect position during the stroke. The identification becomes more obvious as the velocity is increased. 20, and 50 mm s \u22121 , respectively, were used for training and the class with 30 mm s \u22121 velocity was used for evaluation. The intermediate velocity class fits well into the data-based model and the fault identification rate improves with increasing velocity. Figure 7 shows the plot of DF3 over the stroke position clearly indicating the defect. The maximum is blurred, first, due to the interaction of balls and spindle defect over a distance of 30 mm and, second, also results from the STFT temporal blur. Furthermore, especially at low speeds with accordingly higher local resolution, two local maxima can be seen indicating the entry and exit points of the spindle nut passing over the defect. This example shows that the stroke position dependent analysis of signals can be used for fault diagnosis differentiating between local anomalies such as defects of the spindle and global disturbances, e.g. of the bearings in the ball screw or of the ambient. Further details can be found in [18].\n\nAs shown in figure 8 the vibration sensors ADXL335 and FXLN measure sharp axial acceleration peaks when balls traverse the local flank defect that can be seen in time domain signal. The peaks are only visible in the signal recorded during the forward stroke, which can easily be explained by different contact angles on forward and back stroke. On the other hand, the observed effect, that only a few balls in the ball screw nut interact noticeably with the thread defect, makes prediction based on a physical model complicated. The pattern observed in figure 8, right, fits the expected ball pass frequency of 142 Hz but is not deterministic, i.e. not every ball passing over the defect leads to an acceleration peak. Nevertheless, the automated pattern recognition approach is able to identify this pattern and therefore can discriminate between good and defective axes (see figure 6).\n\n\nFully automated modular algorithm toolbox\n\nThe successful preliminary work in iCM Hydraulics resulted in the establishment of the successor project MoSeS-Pro [19], in which the developed methods are transferred to an open sensor system toolbox. In this project magnetoresistive sensors (anisotropic magnetoresistive (AMR), giant magnetoresistive (GMR) and especially tunneling magnetoresistive (TMR)) are primarily used as they are versatile tools for measuring current, position and angle yielding periodic sine-cosine-signals. In addition, other MEMS (micro-electro mechanical system) sensors, e.g. for noise, vibration, pressure or thermal radiation, are used to extend the measurement spectrum. All sensor principles are also integrated into components and subsystems [20] to allow improved performance and condition monitoring of mechatronic components, both as end-of-line test in their production and during their operation in manufacturing systems. In MoSeS-Pro, modular electronics and software algorithms are developed allowing the required signal pre-processing and feature extraction directly in the smart sensor system. Otherwise, signals recorded at high frequencies above several 100 MHz would result in data rates which would overload the higher-level systems in a typical production environment. In addition, novel self-X methods, wireless sensor interfaces and energy harvesting are developed for easy integration and initialization of system operation.\n\nTo make statistical data analysis a powerful tool for condition and process assessment without firm and detailed expert T ball is the inverse theoretical ball pass frequency. Only few balls seem to interact with the thread defect [16]. Furthermore the fault, i.e. the interaction of balls and thread defect, is only observed during the forward stroke due to different contact angles. knowledge, the underlying algorithms need to be self-optimizing and combined in automated signal processing chains. Since no machine learning algorithm can guarantee optimal results on all datasets a toolbox of automated algorithms is used that was designed to solve typical problems faced when applying machine learning for condition monitoring. However, this approach, especially in the case of supervised learning, requires a sufficient quality of training data, i.e. typically process-synchronized time series sensor data which are annotated with corresponding classes, i.e. the target vector for which the statistical model is to be trained. The typical steps for offline analysis are signal pre-processing, feature extraction (FE) and feature selection (FS) as well as classification with subsequent evaluation and can be interpreted as a gradual dimensionality reduction. Feature extraction and selection can be fully automated using the developed modular approach based on complementary algorithms to extract information that is usually used for remaining useful lifetime estimation and fault classification. Such information is typically extracted using PCA [21,22], Fourier transformation [23] or wavelet transformation [24]. Similarly, complementary techniques are also used to select suitable features and feature combinations, i.e. by a simple analysis of the signal correlation with the target condition or by recursive feature elimination support vector machines (RFESVM) for linear or RELIEFF for nonlinear class separability [25]. In this way, the signal processing software as part of the sensor kit is realized in a highly modular design since heterogeneous sensors differ significantly regarding signal shape, time and spatial resolution, as well as target information to be extracted. Most important, however, all of these algorithms are simple enough to be integrated directly in the smart sensor using either a microprocessor or, for signals with higher data rates, an FPGA board. The individual algorithms are introduced in the following section.\n\n\nAutomated feature extraction\n\nAll FE methods introduced here are unsupervised and aim to reconstruct the original raw data with as few features as possible. Simultaneously each method has to preserve similarities within classes, i.e. machine conditions, and differences between classes to find good representations for machine learning. Of course, there is a trade-off between low approximation error and low number of features. Furthermore, the method that extracts the features that provide highest contrast between different classes cannot be determined beforehand. Therefore multiple simple but complementary methods are tested and evaluated to identify the best one. The following methods are used for FE: Figure 9. Approximation X\u2032 using ALA with features x\u20321-x\u203216 compared to the original sensor signal X (here a pressure sensor over a complete working cycle, shifted for better clarity). The eight segments shown below are represented by mean values (uneven indices) and slopes (even indices). Adaptive linear approximation (ALA): ALA splits the measurement time segment or working cycle into variable length, approximately linear segments and extracts slope and mean value of each segment, as shown in figure 9. Start and end of each segment are chosen to minimize the overall reconstruction error over all training cycles and all cycle segments for a given number of splits performed on the data. Thereby the number of splits that controls the trade-off between low approximation error and low number of features is chosen automatically by monitoring the decrease of approximation error when performing one additional split. If the error does not decrease significantly with additional splits the major characteristics of the cycle shape are represented by the features and the algorithm stops. A detailed description of the algorithm can be found in [26]. This algorithm has been chosen over multiple other variants [27][28][29], because it guarantees to perform splits with lowest approximation error. The disadvantage of this method is the high computational complexity of O(n 2 ) with the number of data points n per time segment. In practice, this requires the maximum signal length to be limited to 500 values, e.g. by resampling, in order to achieve reasonable computing times. The maximum cycle length has been determined empirically to match the requirements for low computational cost in MoSeS-Pro and the Big-Data application shown in section 4 and at same time not to be restrictive in one of the applications mentioned in this paper. Nevertheless the advantages of a low number of extracted features and good representation of local information make ALA an excellent algorithm for Feature Extraction in time domain. See table 1 for a comparison of advantages and disadvantages of ALA.\n\nThe n first principal components (PCs) found by principal component analysis (PCA) are the optimum linear transformation of the signal in terms of minimal approximation error for a given number of features [30]. This is equivalent to PCA disassembling the signal into multiple linear driving forces ordered by descending significance [30]. As well as for ALA the maximum signal length is limited to 500 due to computational complexity O(n 2 ). Again this limitation is an empirically found trade-off between necessary accuracy and computational cost following the same ideas discussed for ALA [31]. Overall, PCA is optimal for representing the overall signal shape. Nevertheless, local details like sudden changes and edges (see figure 10) might be neglected in the first principal components in case they are not traceable to linear driving forces or do not significantly affect the global approximation error. For a list of advantages and disavantages see table 2. The number of principal components to extract is determined by dividing the maximum number of features FS can efficiently deal with (in our case approx. 500, for explanation see section 3.2) by the number of sensors in the dataset to capture as much information of each sensor as possible.  \n\n\nAdvantages\n\nDisadvantages/assumptions\n\n\n\u2022Extracts information from local details in the frequency domain \u2022Assumes information to be located in frequency domain \u2022Takes into account phase shifts\n\n\u2022Fixed data reduction factor \u2022Low computational complexity (nlogn)\n\n\u2022Prone to frequency shifts \u2022 FFT performed on complete signal length blurs frequencies from individual segments Best Fourier coefficients (BFC) extract amplitude and phase of the Fourier coefficients with highest mean absolute value over all cycles (see figure 11). These Fourier coefficients are the ones that contain the most signal energy and therefore contribute most to low approximation error [32]. This algorithm is therefore especially suitable for information that is well localized in the frequency domain, e.g. for vibration signals or motor cur rent analysis. The data reduction factor of this method is fixed to ten, as this was shown to be a reasonable tradeoff between low number of features and low approximation error (see section 3.4). If, after omitting the smaller 90% of the Fourier coefficients, the number of features is still too high for efficient multivariate FS the best 500 features are selected based on the highest absolute Pearson correlation to the target value (see section 3.2). A summarized list of advantages and disadvantages can be found in table 3.\n\nBest Daubechies wavelet coefficients (BDW) extracts the coefficients with highest mean absolute value of a multilevel wavelet transformation into the time-frequency domain using Daubechies-4 wavelets (see figure 12). As for BFC these coefficients contribute most to achieving a low approx imation error [32] and the best 10% of the coefficients are extracted. The Daubechies-4 wavelet was chosen because of its widespread use in signal processing and data compression. The fixed data reduction factor is again a trade-off between low number of features and low approximation error that was shown to be reasonable (see section 3.4). Advantages and disadvantages can be found in table 4. If necessary, preselection with Pearson correlation is applied to reduce the number of extracted features to 500 (see section 3.3). BDW captures information in time-frequency domain and provides a multiresolutional view to the data because it is applied multiple times for multi-level wavelet transformation.\n\nFor information that is contained in the statistical distribution of the measurement values signals are split into a fixed number of equally sized segments and the first four statistical moments of the data distribution-mean, standard deviation, skewness and kurtosis-are extracted for each segment. For advantages and disadvantages see table 5.\n\n\nAutomated feature selection\n\nAfter each of the feature extraction methods is applied to each available (sensor) signal, the features derived with each method are pooled and FS is applied to each of the five resulting feature pools to select a feature subset suitable for the desired classification task. Both this step (including preselection) and the classification step are based on supervised learning and therefore rely on the target value being known for each training signal. The pooling step is also called data fusion since features from multiple sensors are combined. Due to multiple problems that arise for feature selection there is no FS algorithm that will guarantee an optimal feature subset for every classification task other than exhaustive search [33], which is of course computationally prohibitive in most cases. Therefore, the following complementary feature ranking algorithms are used on every feature pool. The optimal size of the feature set to be used is estimated by computing the 10-fold cross-validation classification error (see section 3.3) while Figure 11. Approximation X\u2032 using BFC with features x\u20321-x\u203216 compared to the original signal X (shifted for better clarity). The approximation is the superposition of multiple sine waves represented by amplitude (uneven indices) and phase shifts (even indices). As shown in comparison to figures 9 and 10, in this case approximation in time-domain is more accurate and will be selected automatically (see section 3.3). adding features according to their relevance ranking until 500 features are selected. The set with minimal cross-validation error is chosen for classification. This method guarantees optimal feature subset size and is possible due to the low computational cost of LDA and Mahalanobis distance used for the classification (see section 3.3). The maximum number of 500 features was chosen to be as small as possible to allow fast evaluation of the feature sets and as big as possible to include sufficient information for the classification algorithm. In most applications the training set is too small (usually <1000 cycles) to justify more than 500 features and the minimal classification error is achieved with less than 100 features [34].\n\nRecursive feature elimination support vector machines (REFSVM) is a multivariate technique for FS based on training a linear SVM in each recursion. The normal vector of the found optimal separating hyperplane represents the direction of optimal class separation. The feature that contributes least to this vector, i.e. has lowest absolute value, is eliminated and the algorithm is repeated for the remaining feature set. Details of the algorithm can be found in [35]. Multiclass problems are resolved using one versus one multiclass encoding and computing the mean of all absolute feature weights. The SVM parameter C is set to 1000 and features are standardized to have a mean value of 0 and a standard deviation of 1 before the algorithm is applied. The value of the parameter C defines the penalization of missclassifications and is usually a good tradeoff between generalization and adaptation to the training data. The standardization is necessary to account for different feature scales [36]. RFESVM was shown to be very effective and reliable in a comparison of 66 FS algorithms for gas sensor and condition monitoring data [31]. Nevertheless it relies on the classes being linearly separable. A list of advantages and disadvantages is given in table 6.\n\nIf the classes are not linearly separable RFESVM is complemented by RELIEFF (fixed name), a multivariate FS algorithm that is based on K-nearest-neighbors and therefore a nonlinear radial classification. RELIEFF finds the k-nearest neighbors for each point of the same group and the k-nearest neighbors of different groups and updates the ranking vector according to the contrast between nearest hits and misses provided by the features. Usually the L1 norm is used as distance metric [37]. In our case k is set to 3 to prevent a highly fractural decision border in case of overlapping groups and low computational cost. A comparison of advantages and disadvantages can be found in table 7. RFESVM and RELIEFF are extremely powerful methods for feature selection taking feature interaction into account. Nevertheless they internally rely on machine learning and can therefore suffer from overfitting, the 'curse of dimensionality' and nonlinear algorithmic complexity if the number of features in the original feature pool is high. When more than 500 features are in the pool, feature interaction is neglected and features are ranked by their individual Pearson correlation to the target value to select the 500 most relevant individual features for RFESVM and RELIEFF. Pearson correlation is thus used both for preselection and for feature selection itself. Preliminary work showed that 500 features are sufficient to solve all feature selection tasks the methods have been applied to and at the Approximation X\u2032 of X using BDW (shifted for better clarity). Extracted features are wavelet coefficients x\u20321-x\u20328. The reconstruction is achieved by the superposition of the wavelets shown below weighted with the corresponding wavelet coefficients (features). As shown in comparison to figures 9 and 10, in this case approximation in time-domain is more accurate and will be selected automatically (see section 3.3). \n\n\nAdvantages\n\nDisadvantages/assumptions\n\n\n\u2022 Extracts information from statistical distribution of data values\n\n\u2022 Equally sized segmentation might be meaningless \u2022Low computational complexity (n) \u2022 Meaning of features is hard to interpret same time allow reasonable computing times for training (~1 h for RFESVM, training-time depends on FS-problem to solve) [34]. Advantages and disadvantages are summarized in table 8.\n\n\nLDA and Mahalanobis classification\n\nThe classification algorithm used to evaluate the 15 feature subsets generated by all combinations of five feature extraction and three feature selection algorithms is linear discriminant analysis (LDA) followed by Mahalanobis distance classification. In case of g groups LDA performs the linear projection of the feature space into a g \u2212 1 dimensional discriminating space that minimizes within group scattering and maximizes between group scattering [40]. In this discriminating space points are classified into that group to which their Mahalanobis distance is minimal [31]. The scheme of the full data evaluation is shown in figure 13. First each unsupervised feature extraction method is applied to each (sensor) signal available generating five feature pools, one for each method. From each feature pool the best feature subset is selected using the three supervised feature selection methods. Finally, the best combination of the 15 combinations of feature extraction and feature selection is chosen based on the lowest cross-validation error of the final classification to solve the problem at hand, i.e. condition monitoring with different fault states as target classes. Note that this cross-validation loop has to include not only the classification itself but also feature selection and even extraction to account for possible overfitting in supervised feature selection and to ensure statistical stability in feature extraction. Keep in mind that a second, nested cross-validation loop is employed for feature subset size determination. The computational cost of this nested cross-validation is not prohibitive because the LDA projection can be computed analytically and is therefore very efficient. Additionally, LDA provides two further advantages over more complex classifiers like artificial neural networks or (nonlinear) support vector machines. First, the low dimensional representation achieved by LDA is easily visualized by 2D scatter plots that provide additional insight \u2022 Needs to be limited to 500 features due to high computational cost \u2022Selects features for radial classification \u2022Fixed parameter k might be suboptimal for some applications \u2022Broadly used [38,39] \u2022Ignores nesting effects \u2022Takes feature interaction into account  Table 9. Advantages and disadvantages of LDA and Mahalanobis classification.\n\n\nAdvantages\n\nDisadvantages/assumptions\n\n\u2022 Allows determination of optimal feature subset size by brute force due to low computational cost.\n\n\u2022 Optimal performance only if groups form equal Gauss-distributed clusters \u2022Offers 2D visualizations\n\n\u2022 Linear projection can only solve simple classification tasks. \u2022Applicable for regression (with quantification) as long as system response is monotonous \u2022 Interpretable decision making due to linear projection and additional insights into feature relevance into the data allowing intuitive understanding why a certain prediction is obtained for a given signal. Second, the linear nature of LDA allows analyzing the contribution of individual sensors, time segments or frequencies to the overall classification result. This information can be used to optimize the overall system, i.e. number and types of sensors used, sample rate and measurement time. Table 9 contains a summary of advantages and disadvantages.\n\n\nEvaluation on multiple diverse datasets\n\nTo show the versatility of the explained approach and therefore its applicability in different classification scenarios it was tested on multiple datasets from very different domains. The evaluation datasets were intentionally chosen to be more diverse than the primary intended application condition monitoring. All applications have in common, that data can be treated as equal sized cycles that need to be classified. In [34] the approach was tested on eight different datasets and 17 different target values. Comparisons with the results previously achieved on these datasets show that on five out of eight tested datasets better results have been achieved compared to previously used approaches which were often specifically developed for the respective datasets. In the three other cases at least comparable results have been achieved and the approach failed on none of the tested datasets. These results were achieved without any manual parameter tuning and although a simple, linear classification algorithm was used. Furthermore, this set of algorithms is applicable both for smart sensors and   Features are added incrementally according to their ranking and for each feature subset the error is evaluated using ten-fold crossvalidation. Small feature subsets contain insufficient information to predict the ECMs remaining lifetime, thus additional features greatly improve the classification performance up to 25% error for 20 features. Adding further features leads to only a small decrease in the prediction error. By adding even more features the classification error would rise again due to overfitting (not shown here).\n\nbig data, since all FE algorithms and feature preselection can easily be implemented on an FPGA and with the use of Map-Reduce allowing distributed and parallel computing.\n\nTo make full use of this modular and automated approach, data pre-processing and feature extraction need to be integrated in the sensor system to reduce the data load in the network and the cloud. However, this modular approach can also be used to design cost efficient sensor systems for smart monitoring applications. In this case, a complete 'over-instrumented' sensor set is used and the full sensor data are evaluated with the automated approach described above. The fairly simple and transparent algorithms allow identification of relevant sensors and features and, thus, the necessary acquisition bandwidth using an offline analysis. On this basis a greatly simplified sensor system can be defined for practical application. This approach would also allow choosing an application specific balance between sensor redundancy, i.e. to achieve robust operation, and cost efficiency.\n\n\nLifetime prediction of EMCs\n\nTo evaluate the fully automated approach in a big data condition monitoring scenario for predictive maintenance a test bench for lifetime tests of an EMC (Festo ESBF-BS-63-400-5P, \u2300 63 mm, 400 mm stroke, 5 mm spindle pitch, max. axial load 7 kN) was set up to create a corresponding dataset. The EMC was operated at maximum velocity, repeatedly pushing and pulling against a load applied by a pneumatic cylinder, until failure of the EMC. This operation simulates quick weardown of the EMC to record data over its complete lifetime. Data was recorded by three 1D vibration sensors sampled at 100 kHz (mounted on the engine side ball bearing, the end of the piston rod and the friction bearing), eight process sensors sampled at 10 kHz (axial force, torque, pneumatic pressure, velocity, piston position, electrical current, lateral force and vibration) and three motor current sensors sampled at 1 MHz. With this setup a total of 347.198 cycles (i.e. single push and pull) were recorded over a period of 21 d at a raw data rate of approx. 650 GB d \u22121 . Note that although condition monitoring of EMCs and the hydraulic application previously discussed are very different, the data structure of time series data can always be treated as working cycles (sliding windows in case of EMCs compared to actual working cycles for the hydraulic machine). Thus the basic data structure is identical and can therefore be treated using the same automated data processing approach. The diversity of the tested datasets thereby proves the versatility and flexibility of the chosen approach.\n\nFor machine learning the complete lifetime was split into 50 equally sized groups, i.e. representing 2% of the total lifetime each, and the automated approach described above was applied to identify differences between these groups. The validation error determined by ten-fold cross-validation shows that the most suitable combination of feature extraction and feature selection is the combination of statistical moments extracted on five equally sized cycle segments and their selection according to the largest absolute Pearson correlation to the target, i.e. the relative axis lifetime. As shown in figure 14 a minimum error of 9% is achieved when all 300 features are evaluated (15 sensors * 5 segments * 4 statistical moments). Note that the information about the EMC lifetime state is thereby determined for every single cycle, i.e. every 4.8 s.\n\nSince the system monitors the degradation of the EMC which is very slow compared to the cycle time this high information rate is unnecessary or even unwanted. Thus, further improvement is possible by averaging over multiple cycles. Figure 15 shows the results achieved by taking into account the predictions over the last 15 minutes. As shown the prediction follows the target vector very well. There is only one outlier (more than one class difference to target) at 96% lifetime and all other misclassifications occur at class boundaries where they are neither unexpected nor prohibitive to the application.\n\nIn addition, the approach allows to analyze which sensors are the most important for lifetime prediction. Figure 16 shows the sensors from which the top 50 features are extracted. This information can be used to further improve the sensor system and give further insight into the degeneration and decision making process.\n\n\nConclusion and outlook\n\nThis paper has shown for two relevant applications, a complex hydraulic machine and an EMC, how smart sensors combined with a well-chosen set of algorithms for machine learning can be used for condition monitoring to implement predictive maintenance. The suggested approach using complementary algorithms for feature extraction and selection automatically builds a validated data-based model to predict the learned typical component faults as well as remaining lifetime. Thereby the algorithms are also applicable to big data as shown in the EMC example. Additionally the linear character of the classifier allows further insight into the decision-making process, e.g. importance of different sensors that can be used to optim ize the overall system, so as to minimize the number of sensors used. The smart sensor is not only capable of monitoring the system condition but also the condition of the sensor network itself. This self-monitoring allows quantitative evaluation of simulated sensor faults. If a faulty sensor is detected the fault can be compensated by removing the affected sensor from the database and automatic re-training. As the suggested methods are complementary and were tested on several different datasets from different fields of application it should achieve comparable results in other condition monitoring scenarios.\n\nThe current (r)evolution of Industry 4.0 and industrial Internet of Things continues and is pushed-among other drivers-by the development of smart sensors. Note that only some of the capabilities of smart sensors have been addressed in this paper. One of the intended extensions is the use of unsupervised novelty detection to warn if the current sensor signal pattern is generated by an unknown fault scenario that does not fit any of the previously learned faults. In this way the new fault can be indicated early, although it cannot be identified yet. This is important since not all possible faults can be simulated during training. Another desired extension is online learning. Using online learning a previously unknown fault indicated by novelty detection and subsequently identified during maintenance can be included in the list of known faults to correctly identify the fault the next time it occurs.\n\n\nORCID iDs\n\nTizian Schneider https://orcid.org/0000-0003-3488-8944\n\nFigure 1 .\n1Figure 1. Hydraulic system for collection of training data: (top) working circuit with main pump MP1 (orange) with switchable orifice V9, switchable accumulators A1-A4 with different precharge pressures (blue) and variable load V10 (green); (bottom) cooling and filtration circuit with cooler C1 (red) [12]. All marked components can simulate faults with different steps of severity: the pump, for example, can simulate internal leakage by a switchable bypass.\n\nFigure 2 .\n2iCM-hydraulic experimental and MoSeS-Pro data analysis approach. (top) Experimental setup with multiple simulated faults and process sensors to read sensor responses under different fault conditions. (bottom) Data analysis with gradual dimensionality reduction (feature extraction, selection and LDA), machine learning (classification) and cross-validation. Reproduced with permission from[16].\n\nFigure 3 .\n3Fixed working cycle (measured by PS1) with pre-defined load steps with static and transient sections. During the first 10 s V10 (see\n\nFigure 4 .\n4Results for determination of the four system faults studied: accumulator pressure (a), internal pump leakage (b), valve operation (c) and cooler degradation (d). Full symbols show data used for determining the statistical model, open symbols show additional test data not used in the training which prove that unknown data are interpreted correctly\n\nFigure 5 .\n5Results for identification of sensor drift. Full symbols show data used in determining the model for the sensor fault diagnosis, open symbols show additional\n\nFigure 6 .\n6LDA projection of 30 automatically selected vibration features, with training based on velocity classes 10, 20 and 50 mm s \u22121 ; classification rate determined for Mahalanobis distance classifier with 10-fold cross-validation. The velocity class 30 mm s \u22121 projected with the model again proves the shows correct interpolation achieved with the model.\n\nFigure 7 .\n7Figure 7. Deliberate abrasion as local defect on the spindle and corresponding signal of DF3 versus stroke position (moving average over 10 data points) [16]. A simple threshold for the value of DF3 is sufficient to locate the defect position during the stroke. The identification becomes more obvious as the velocity is increased.\n\nFigure 8 .\n8(left) Acceleration signal of forward stroke and backstroke in time domain traversing the prepared thread defect at 200 mm (total stroke is 400 mm). (right) Zoom in on defect.\n\nFigure 10 .\n10Approximation X\u2032 of X using PCA (shifted for better clarity). The extracted features x\u20321-x\u20328 are projections onto the first eight principal components that are shown below. The reconstruction is achieved by the sum of the PCs weighted with the corresponding coefficient (feature).\n\nFigure 12 .\n12Figure 12. Approximation X\u2032 of X using BDW (shifted for better clarity). Extracted features are wavelet coefficients x\u20321-x\u20328. The reconstruction is achieved by the superposition of the wavelets shown below weighted with the corresponding wavelet coefficients (features). As shown in comparison to figures 9 and 10, in this case approximation in time-domain is more accurate and will be selected automatically (see section 3.3).\n\nFigure 15 .\n15Ten-fold cross-validated lifetime prediction of an EMC averaged over 15 min. The prediction follows the actual lifetime of the EMC (blue) almost perfectly. Most prediction errors occur due to quantization at the class borders and are therefore negligible. Only a small section near the end of lifetime is severely misclassified.\n\nFigure 13 .\n13Schematic of the suggested algorithms for feature extraction (left), feature selection (center) and classification (right) and their combination for automated dimensionality reduction and classification. The performance of all 15 combinations of FE and FS methods are evaluated using LDA combined with Mahalanobis classification. The best combination based on the ten-fold cross-validation error is then chosen for the condition monitoring task at hand. \u00a9 2018 IEEE. Reprinted, with permission, from[25].\n\nFigure 14 .\n14Ten-fold cross-validation error plotted over the number of features selected by their absolute Pearson correlation to the remaining lifetime.\n\nFigure 16 .\n16Best 50 features extracted by BFC and selected by Pearson correlation attributed to the underlying sensor. These features are selected first to predict the EMCs lifetime and therefore capture the most important information concerning the wear process. In fact, 28 of the best 30 features can be linked to physically relevant frequencies like harmonics of the motor speed. This information can be used to further optimize the measurement setup or to reduce the number of sensors used by eliminating the least relevant sensors.\n\nTable 1 .\n1Advantages and disadvantages of ALA. Advantages Disadvantages/assumptions \u2022 Extracts information from local details in time domain \u2022 Assumes multiple linear signal segments within the cycle \u2022 Linear function provides first order approximations \u2022 Assumes the same splits can be performed on all cycles \u2022Noise suppression \u2022 Signal length has to be limited due to computational complexity \u2022 Does not create new clusters within the data\n\nTable 2 .\n2Advantages and disadvantages of PCA. Does not create new clusters within the data \u2022Signal length has to be limited due to computational complexityAdvantages \n\n\nTable 3 .\n3Advantages and disadvantages of BFC.\n\nTable 4 .\n4Advantages and disadvantages of BDW.Advantages \n\nDisadvantages/ \nassumptions \n\n\u2022 Extracts information from \ntime-frequency domain \n\n\u2022 Daubechies-4 wavelet \nmight not fit every data \n\u2022 Provides multi-resolutional view for \nboth overall shape and local details \n\n\u2022 Fixed data reduction \nfactor \n\u2022Low computational complexity (n) \n\n\nTable 5 .\n5Advantages and disadvantages of statistical moments.\n\nTable 6 .\n6Advantages and disadvantages of RFESVM.Advantages \n\n\nTable 8 .\n8Advantages and disadvantages of Pearson correlation.Advantages \n\nMeas. Sci. Technol. 29 (2018) 094002\n\nRobuste dreidimensionale Hall-Sensoren f\u00fcr mehrachsige Positionsmesssysteme Aktuelle Berichte aus der Mikrosystemtechnik-Recent Developments in MEMS. M Stahl-Offergeld, Band. 20Shaker-VerlagStahl-Offergeld M 2011 Robuste dreidimensionale Hall- Sensoren f\u00fcr mehrachsige Positionsmesssysteme Aktuelle Berichte aus der Mikrosystemtechnik-Recent Developments in MEMS, Band 20 (Aachen: Shaker-Verlag)\n\nMagnetic microsensors: Quo Vadis?. J Marien, A Sch\u00fctze, 10.5162/sensor09/v2/a6.1Proc. Sensor. SensorIIMarien J and Sch\u00fctze A 2009 Magnetic microsensors: Quo Vadis? Proc. Sensor 2009 vol II pp 17-22\n\nNumerical calibration for 3-axis accelerometers and magnetometers Proc. F Camps, S Harasse, A Monin, 10.1109/EIT.2009.5189614IEEE. Camps F, Harasse S and Monin A 2009 Numerical calibration for 3-axis accelerometers and magnetometers Proc. 2009 IEEE Int. Conf. Electro/Information Technology, EIT 2009 pp 217-21\n\nFabrication, characterization, and analysis of a DRIE CMOS-MEMS gyroscope. H Xie, G K Fedder, 10.1109/JSEN.2003.817901IEEE Sens. J. 3Xie H and Fedder G K 2003 Fabrication, characterization, and analysis of a DRIE CMOS-MEMS gyroscope IEEE Sens. J. 3 622-31\n\nA silicon resonant sensor structure for Coriolis mass-flow measurements. P Enoksson, G Stemme, E Stemme, 10.1109/84.585789J. Microelectromech. Syst. 6Enoksson P, Stemme G and Stemme E 1997 A silicon resonant sensor structure for Coriolis mass-flow measurements J. Microelectromech. Syst. 6 119-25\n\nSelectivity enhancement of SiC-FET gas sensors by combiningtemperature and gate bias cycled operation using multivariatestatistics. C Bur, M Bastuck, A L Spetz, Andersson , M Sch\u00fctze, A , 10.1016/j.snb.2013.12.030Sens. Actuators B. 193Bur C, Bastuck M, Spetz A L, Andersson M and Sch\u00fctze A 2014 Selectivity enhancement of SiC-FET gas sensors by combiningtemperature and gate bias cycled operation using multivariatestatistics Sens. Actuators B 193 931-40\n\nSelbst\u00fcberwachung und online Verifizierung von Sensordaten im Kraftfahrzeug 11. Dresdner Sensor-Symp. T Ochs, L Diehl, W Lehle, C Kern, F Stanglmeier, T Handler, 10.5162/11dss2013/1.1Ochs T, Diehl L, Lehle W, Kern C, Stanglmeier F and Handler T 2013 Selbst\u00fcberwachung und online Verifizierung von Sensordaten im Kraftfahrzeug 11. Dresdner Sensor-Symp. 2013 pp 14-6\n\nSensor information as a service-component of networked production. R H Schmitt, C Voigtmann, 10.5194/jsss-7-389-2018J. Sens. Sens. Syst. 7Schmitt R H and Voigtmann C 2018 Sensor information as a service-component of networked production J. Sens. Sens. Syst. 7 389-402\n\nDeveloping competencies for continuous improvement processes on the shop floor through learning factories-conceptual design and empirical validation Proc. J Cachay, E Abele, 10.1016/j.procir.2012.07.109CIRP. 3Cachay J and Abele E 2012 Developing competencies for continuous improvement processes on the shop floor through learning factories-conceptual design and empirical validation Proc. CIRP 3 638-43\n\nW3C Semantic Sensor Network Incubator Group 2005 Semantic Sensor Network Ontology. 28W3C Semantic Sensor Network Incubator Group 2005 Semantic Sensor Network Ontology www.w3.org/2005/ Incubator/ssn/ssnx/ssn (Accessed: 28 January 2018)\n\nSensors 4.0-smart sensors and measurement technology enable Industry 4.0. A Sch\u00fctze, N Helwig, Schneider, 10.5194/jsss-7-359-2018J. Sens. Sens. Syst. 7Sch\u00fctze A, Helwig N and Schneider T 2018 Sensors 4.0- smart sensors and measurement technology enable Industry 4.0 J. Sens. Sens. Syst. 7 359-71\n\nCondition monitoring of a complex hydraulic system using multivariate statistics 2015 IEEE. N Helwig, Pignanelli E Schutze, A , 10.1109/I2MTC.2015.7151267Measurement Technology Conf. (I2MTC) Proc. pp. Helwig N, Pignanelli E and Schutze A 2015 Condition monitoring of a complex hydraulic system using multivariate statistics 2015 IEEE Int. Instrumentation and Measurement Technology Conf. (I2MTC) Proc. pp 210-5\n\n. R O Duda, P E Hart, D G Stork, WileyNew YorkPattern Classiflcation 2nd ednDuda R O, Hart P E and Stork D G 2000 Pattern Classiflcation 2nd edn (New York: Wiley)\n\nN Helwig, 10.5162/AHMT2014/P1Intelligentes condition monitoring von hydraulischen Anlagen AHMT 2014-Symp. des Arbeitskreises der Hochschullehrer f\u00fcr Messtechnik pp. Helwig N 2014 Intelligentes condition monitoring von hydraulischen Anlagen AHMT 2014-Symp. des Arbeitskreises der Hochschullehrer f\u00fcr Messtechnik pp 121-8\n\nIdentification and quantification of hydraulic system faults based on multivariate statistics using spectral vibration features. N Helwig, S Klein, A Sch\u00fctze, 10.1016/j.proeng.2015.08.835Proc. Eng. 120Helwig N, Klein S and Sch\u00fctze A 2015 Identification and quantification of hydraulic system faults based on multivariate statistics using spectral vibration features Proc. Eng. 120 1225-8\n\nDetecting and compensating sensor faults in a hydraulic condition monitoring system. N Helwig, Pignanelli E Sch\u00fctze, A , 10.5162/sensor2015/D8.1Proc. Sensor pp. Sensor ppHelwig N, Pignanelli E and Sch\u00fctze A 2015 Detecting and compensating sensor faults in a hydraulic condition monitoring system Proc. Sensor pp 641-6\n\nMagnetoresistive sensors for angle, position, and electrical current measurement in demanding environments Proc. M Doms, R Slatter, 10.1117/12.2049886SPIE. 911391130Doms M and Slatter R 2014 Magnetoresistive sensors for angle, position, and electrical current measurement in demanding environments Proc. SPIE 9113 91130M\n\nIntegrated sensor system for condition monitoring of electromechanical cylinders. N Helwig, P Merten, T Schneider, A Sch\u00fctze, 10.3390/proceedings1040626Proceedings. 1626Helwig N, Merten P, Schneider T and Sch\u00fctze A 2017 Integrated sensor system for condition monitoring of electromechanical cylinders Proceedings 1 626\n\nA Sch\u00fctze, MoSeS-Pro: Modulare Sensorsysteme f\u00fcr Echtzeit-Prozesssteuerung und smarte Zustandsbewertung f\u00fcr die. Industrie 4.0, BMBF project funded in the funding area 'Sensorbasierte Elektroniksysteme f\u00fcr Anwendungen f\u00fcr Industrie 4.0 (SElekt I4.0)Sch\u00fctze A 2015 MoSeS-Pro: Modulare Sensorsysteme f\u00fcr Echtzeit-Prozesssteuerung und smarte Zustandsbewertung f\u00fcr die Industrie 4.0, BMBF project funded in the funding area 'Sensorbasierte Elektroniksysteme f\u00fcr Anwendungen f\u00fcr Industrie 4.0 (SElekt I4.0)\n\nMoSeS-Pro: modular sensor systems for real time process control and smart condition monitoring using XMR-technology Proc. N Helwig, T Schneider, A Sch\u00fctze, Helwig N, Schneider T and Sch\u00fctze A 2017 MoSeS-Pro: modular sensor systems for real time process control and smart condition monitoring using XMR-technology Proc.\n\nSymp. Magnetoresistive Sensors and Magnetic Systems pp. Symp. Magnetoresistive Sensors and Magnetic Systems pp 15-22\n\nSVM and PCA based fault classification approaches for complicated industrial process. C Jing, J Hou, 10.1016/j.neucom.2015.03.082Neurocomputing. 167Jing C and Hou J 2015 SVM and PCA based fault classification approaches for complicated industrial process Neurocomputing 167 636-42\n\nThe fault feature extraction and classification of gear using principal component analysis and kernel principal component analysis based on the wavelet packet transform Measurement. R Shao, W Hu, Wang Y Qi, X , 10.1016/j.measurement.2014.04.01654Shao R, Hu W, Wang Y and Qi X 2014 The fault feature extraction and classification of gear using principal component analysis and kernel principal component analysis based on the wavelet packet transform Measurement 54 118-32\n\nNeuralnetwork-based motor rolling bearing fault diagnosis. B Li, M-Y Chow, Tipsuwan Y Hung, J C , 10.1109/41.873214IEEE Trans. Ind. Electron. 47Li B, Chow M-Y, Tipsuwan Y and Hung J C 2000 Neural- network-based motor rolling bearing fault diagnosis IEEE Trans. Ind. Electron. 47 1060-9\n\nArtificial neural network based fault diagnostics of rotating machinery using wavelet transforms as a preprocessor. B A Paya, I Esat, M N M Badi, 10.1006/mssp.1997.0090Mech. Syst. Signal Process. 11Paya B A, Esat I I and Badi M N M 1997 Artificial neural network based fault diagnostics of rotating machinery using wavelet transforms as a preprocessor Mech. Syst. Signal Process. 11 751-65\n\nAutomatic feature extraction and selection for condition monitoring and related datasets. T Schneider, N Helwig, A Sch\u00fctze, Proc. 2Schneider T, Helwig N and Sch\u00fctze A 2018 Automatic feature extraction and selection for condition monitoring and related datasets Proc. I2MTC 2018 (Houston, TX, USA)\n\nGeneralized feature extraction for structural pattern recognition in time-series data. R Olszewski, Carnegie Mellon UniversityPhD ThesisOlszewski R T 2001 Generalized feature extraction for structural pattern recognition in time-series data PhD Thesis Carnegie Mellon University\n\nAn improved feature extraction technique for high volume time series data. J Anstey, D Peters, C Dawson, Proc. of the 4th Conf. on IASTED pp. of the 4th Conf. on IASTED ppAnstey J, Peters D and Dawson C 2007 An improved feature extraction technique for high volume time series data Proc. of the 4th Conf. on IASTED pp 74-81\n\nLocally adaptive dimensionality reduction for indexing large time series databases. K Chakrabarti, E Keogh, S Mehrotra, M Pazzani, 10.1145/568518.568520ACM Trans. Database Syst. 27Chakrabarti K, Keogh E, Mehrotra S and Pazzani M 2002 Locally adaptive dimensionality reduction for indexing large time series databases ACM Trans. Database Syst. 27 188-228\n\nAn enhanced representation of time series which allows fast and accurate classification. E J Keogh, M J Pazzani, clustering and relevance feedback KDD'98 Proc. 4th Int. Conf. on Knowledge Discovery and Data Mining. 98Keogh E J and Pazzani M J 1998 An enhanced representation of time series which allows fast and accurate classification, clustering and relevance feedback KDD'98 Proc. 4th Int. Conf. on Knowledge Discovery and Data Mining vol 98 pp 239-43\n\n. S Wold, K Esbensen, P Geladi, 10.1016/0169-7439(87)80084-9Principal component analysis Chemometr. Intell. Lab. Syst. 2Wold S, Esbensen K H and Geladi P 1987 Principal component analysis Chemometr. Intell. Lab. Syst. 2 37-52\n\nMethoden der automatisierten Merkmalextraktion und -selektion von. T Schneider, Sensorsignalen Master Thesis Saarland UniversitySchneider T 2015 Methoden der automatisierten Merkmalextraktion und -selektion von Sensorsignalen Master Thesis Saarland University\n\nTime series feature extraction for data mining using DWT and DFT. F Morchen, No.33Dep. Mathematics Comput. Sci. Philipps-University Marburg. Technical ReportMorchen F 2003 Time series feature extraction for data mining using DWT and DFT Technical Report No.33 (Dep. Mathematics Comput. Sci. Philipps-University Marburg) pp 1-31\n\nAn introduction to variable and feature selection. I Guyon, J. Mach. Learn. Res. 3Guyon I 2003 An introduction to variable and feature selection J. Mach. Learn. Res. 3 1157-82\n\nAutomatic feature extraction and selection for condition monitoring and related datasers IEEE. T Schneider, N Helwig, A Sch\u00fctze, Measurement Technology Conf. (I2MTC). Schneider T, Helwig N and Sch\u00fctze A 2018 Automatic feature extraction and selection for condition monitoring and related datasers IEEE Int. Instrumentation & Measurement Technology Conf. (I2MTC)\n\n. I Guyon, S Gunn, M Nikravesh, L A Zadeh, 10.1007/978-3-540-35488-8Feature Extraction-Foundations and Applications. SpringerGuyon I, Gunn S, Nikravesh M and Zadeh L A 2006 Feature Extraction-Foundations and Applications (Berlin: Springer) (https://doi.org/10.1007/978-3-540-35488-8)\n\nSupport Vector Machines for Pattern Classification 2nd edn. S Abe, 10.1007/978-1-84996-098-4SpringerLondonAbe S 2010 Support Vector Machines for Pattern Classification 2nd edn (London: Springer) (https://doi. org/10.1007/978-1-84996-098-4)\n\nAttribute selection for modelling Future Gener. I Kononenko, S J Hong, 10.1016/S0167-739X(97)81974-7Comput. Syst. 13Kononenko I and Hong S J 1997 Attribute selection for modelling Future Gener. Comput. Syst. 13 181-95\n\nWrappers for feature subset selection. R Kohavi, G H John, 10.1016/S0004-3702(97)00043-XArtif. Intell. 97Kohavi R and John G H 1997 Wrappers for feature subset selection Artif. Intell. 97 273-324\n\nA review and empirical evaluation of feature weighting methods for a class of lazy learning algorithms Lazy Learning. D Wettschereck, D Aha, T Mohri, 10.1007/978-94-017-2053-3_11SpringerDordrechtWettschereck D, Aha D W and Mohri T 1997 A review and empirical evaluation of feature weighting methods for a class of lazy learning algorithms Lazy Learning (Dordrecht: Springer) pp 273-314\n\n. R O Duda, P E Hart, D G Stork, WileyNew YorkPattern Classification 2nd ednDuda R O, Hart P E and Stork D G 2001 Pattern Classification 2nd edn (New York: Wiley)\n", "annotations": {"author": "[{\"end\":127,\"start\":8},{\"end\":225,\"start\":128},{\"end\":341,\"start\":226}]", "publisher": null, "author_last_name": "[{\"end\":24,\"start\":15},{\"end\":142,\"start\":136},{\"end\":241,\"start\":234}]", "author_first_name": "[{\"end\":14,\"start\":8},{\"end\":135,\"start\":128},{\"end\":233,\"start\":226}]", "author_affiliation": "[{\"end\":126,\"start\":46},{\"end\":224,\"start\":144},{\"end\":340,\"start\":243}]", "title": null, "venue": "[{\"end\":360,\"start\":342}]", "abstract": "[{\"end\":2036,\"start\":607}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2466,\"start\":2463},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2578,\"start\":2575},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2675,\"start\":2672},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2755,\"start\":2752},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2906,\"start\":2903},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3024,\"start\":3021},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3175,\"start\":3172},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3892,\"start\":3889},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4669,\"start\":4665},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5095,\"start\":5092},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5787,\"start\":5784},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6429,\"start\":6425},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6850,\"start\":6846},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8288,\"start\":8284},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8783,\"start\":8779},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9433,\"start\":9429},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12014,\"start\":12010},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12329,\"start\":12325},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12381,\"start\":12377},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12595,\"start\":12591},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":13540,\"start\":13536},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":13895,\"start\":13891},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":14785,\"start\":14781},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":16012,\"start\":16008},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":16974,\"start\":16970},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":17151,\"start\":17149},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":18143,\"start\":18139},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":19198,\"start\":19194},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":19812,\"start\":19808},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":20743,\"start\":20739},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":22064,\"start\":22060},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":22067,\"start\":22064},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22096,\"start\":22092},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":22127,\"start\":22123},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":22439,\"start\":22435},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24831,\"start\":24827},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":24897,\"start\":24893},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":24901,\"start\":24897},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":24905,\"start\":24901},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":25985,\"start\":25981},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26113,\"start\":26109},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":26372,\"start\":26368},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":27701,\"start\":27697},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":28694,\"start\":28690},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":30500,\"start\":30496},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":31966,\"start\":31962},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":32435,\"start\":32431},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":32966,\"start\":32962},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":33104,\"start\":33100},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":33720,\"start\":33716},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":35508,\"start\":35504},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":36060,\"start\":36056},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":36180,\"start\":36176},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":37792,\"start\":37788},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":37795,\"start\":37792},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":39367,\"start\":39363},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":48258,\"start\":48254},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":51438,\"start\":51434}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":47851,\"start\":47378},{\"attributes\":{\"id\":\"fig_1\"},\"end\":48259,\"start\":47852},{\"attributes\":{\"id\":\"fig_2\"},\"end\":48405,\"start\":48260},{\"attributes\":{\"id\":\"fig_3\"},\"end\":48767,\"start\":48406},{\"attributes\":{\"id\":\"fig_4\"},\"end\":48938,\"start\":48768},{\"attributes\":{\"id\":\"fig_5\"},\"end\":49302,\"start\":48939},{\"attributes\":{\"id\":\"fig_6\"},\"end\":49647,\"start\":49303},{\"attributes\":{\"id\":\"fig_7\"},\"end\":49836,\"start\":49648},{\"attributes\":{\"id\":\"fig_8\"},\"end\":50132,\"start\":49837},{\"attributes\":{\"id\":\"fig_9\"},\"end\":50575,\"start\":50133},{\"attributes\":{\"id\":\"fig_10\"},\"end\":50919,\"start\":50576},{\"attributes\":{\"id\":\"fig_11\"},\"end\":51439,\"start\":50920},{\"attributes\":{\"id\":\"fig_12\"},\"end\":51596,\"start\":51440},{\"attributes\":{\"id\":\"fig_13\"},\"end\":52137,\"start\":51597},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":52582,\"start\":52138},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":52753,\"start\":52583},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":52802,\"start\":52754},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":53143,\"start\":52803},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":53208,\"start\":53144},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":53272,\"start\":53209},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":53349,\"start\":53273}]", "paragraph": "[{\"end\":2579,\"start\":2089},{\"end\":3025,\"start\":2581},{\"end\":3893,\"start\":3027},{\"end\":5096,\"start\":3895},{\"end\":6017,\"start\":5098},{\"end\":6430,\"start\":6019},{\"end\":6851,\"start\":6432},{\"end\":7872,\"start\":6902},{\"end\":9434,\"start\":7874},{\"end\":11248,\"start\":9436},{\"end\":12382,\"start\":11250},{\"end\":13896,\"start\":12384},{\"end\":15605,\"start\":13898},{\"end\":18144,\"start\":15607},{\"end\":19033,\"start\":18146},{\"end\":20507,\"start\":19079},{\"end\":22963,\"start\":20509},{\"end\":25773,\"start\":22996},{\"end\":27033,\"start\":25775},{\"end\":27073,\"start\":27048},{\"end\":27296,\"start\":27230},{\"end\":28385,\"start\":27298},{\"end\":29381,\"start\":28387},{\"end\":29728,\"start\":29383},{\"end\":31967,\"start\":29760},{\"end\":33229,\"start\":31969},{\"end\":35145,\"start\":33231},{\"end\":35185,\"start\":35160},{\"end\":35565,\"start\":35257},{\"end\":37938,\"start\":35604},{\"end\":37978,\"start\":37953},{\"end\":38079,\"start\":37980},{\"end\":38181,\"start\":38081},{\"end\":38895,\"start\":38183},{\"end\":40574,\"start\":38939},{\"end\":40747,\"start\":40576},{\"end\":41634,\"start\":40749},{\"end\":43242,\"start\":41666},{\"end\":44095,\"start\":43244},{\"end\":44705,\"start\":44097},{\"end\":45028,\"start\":44707},{\"end\":46397,\"start\":45055},{\"end\":47309,\"start\":46399},{\"end\":47377,\"start\":47323}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":25716,\"start\":25709},{\"end\":33921,\"start\":33913},{\"end\":37869,\"start\":37862},{\"end\":38843,\"start\":38836}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2087,\"start\":2038},{\"attributes\":{\"n\":\"2.\"},\"end\":6900,\"start\":6854},{\"attributes\":{\"n\":\"3.\"},\"end\":19077,\"start\":19036},{\"attributes\":{\"n\":\"3.1.\"},\"end\":22994,\"start\":22966},{\"end\":27046,\"start\":27036},{\"end\":27228,\"start\":27076},{\"attributes\":{\"n\":\"3.2.\"},\"end\":29758,\"start\":29731},{\"end\":35158,\"start\":35148},{\"end\":35255,\"start\":35188},{\"attributes\":{\"n\":\"3.3.\"},\"end\":35602,\"start\":35568},{\"end\":37951,\"start\":37941},{\"attributes\":{\"n\":\"3.4.\"},\"end\":38937,\"start\":38898},{\"attributes\":{\"n\":\"4.\"},\"end\":41664,\"start\":41637},{\"attributes\":{\"n\":\"5.\"},\"end\":45053,\"start\":45031},{\"end\":47321,\"start\":47312},{\"end\":47389,\"start\":47379},{\"end\":47863,\"start\":47853},{\"end\":48271,\"start\":48261},{\"end\":48417,\"start\":48407},{\"end\":48779,\"start\":48769},{\"end\":48950,\"start\":48940},{\"end\":49314,\"start\":49304},{\"end\":49659,\"start\":49649},{\"end\":49849,\"start\":49838},{\"end\":50145,\"start\":50134},{\"end\":50588,\"start\":50577},{\"end\":50932,\"start\":50921},{\"end\":51452,\"start\":51441},{\"end\":51609,\"start\":51598},{\"end\":52148,\"start\":52139},{\"end\":52593,\"start\":52584},{\"end\":52764,\"start\":52755},{\"end\":52813,\"start\":52804},{\"end\":53154,\"start\":53145},{\"end\":53219,\"start\":53210},{\"end\":53283,\"start\":53274}]", "table": "[{\"end\":52753,\"start\":52741},{\"end\":53143,\"start\":52851},{\"end\":53272,\"start\":53260},{\"end\":53349,\"start\":53337}]", "figure_caption": "[{\"end\":47851,\"start\":47391},{\"end\":48259,\"start\":47865},{\"end\":48405,\"start\":48273},{\"end\":48767,\"start\":48419},{\"end\":48938,\"start\":48781},{\"end\":49302,\"start\":48952},{\"end\":49647,\"start\":49316},{\"end\":49836,\"start\":49661},{\"end\":50132,\"start\":49852},{\"end\":50575,\"start\":50148},{\"end\":50919,\"start\":50591},{\"end\":51439,\"start\":50935},{\"end\":51596,\"start\":51455},{\"end\":52137,\"start\":51612},{\"end\":52582,\"start\":52150},{\"end\":52741,\"start\":52595},{\"end\":52802,\"start\":52766},{\"end\":52851,\"start\":52815},{\"end\":53208,\"start\":53156},{\"end\":53260,\"start\":53221},{\"end\":53337,\"start\":53285}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":7630,\"start\":7622},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":8000,\"start\":7992},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9684,\"start\":9676},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":10839,\"start\":10831},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":11309,\"start\":11301},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":13388,\"start\":13380},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":16625,\"start\":16617},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":17416,\"start\":17408},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":18707,\"start\":18699},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":19031,\"start\":19023},{\"end\":23685,\"start\":23677},{\"end\":24185,\"start\":24177},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":26513,\"start\":26504},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":27561,\"start\":27552},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":28601,\"start\":28592},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":30818,\"start\":30809},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36242,\"start\":36233},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":43855,\"start\":43846},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":44338,\"start\":44329},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":44822,\"start\":44813}]", "bib_author_first_name": "[{\"end\":53539,\"start\":53538},{\"end\":53821,\"start\":53820},{\"end\":53831,\"start\":53830},{\"end\":54057,\"start\":54056},{\"end\":54066,\"start\":54065},{\"end\":54077,\"start\":54076},{\"end\":54372,\"start\":54371},{\"end\":54381,\"start\":54378},{\"end\":54627,\"start\":54626},{\"end\":54639,\"start\":54638},{\"end\":54649,\"start\":54648},{\"end\":54984,\"start\":54983},{\"end\":54991,\"start\":54990},{\"end\":55004,\"start\":55001},{\"end\":55021,\"start\":55012},{\"end\":55025,\"start\":55024},{\"end\":55036,\"start\":55035},{\"end\":55410,\"start\":55409},{\"end\":55418,\"start\":55417},{\"end\":55427,\"start\":55426},{\"end\":55436,\"start\":55435},{\"end\":55444,\"start\":55443},{\"end\":55459,\"start\":55458},{\"end\":55743,\"start\":55740},{\"end\":55754,\"start\":55753},{\"end\":56098,\"start\":56097},{\"end\":56108,\"start\":56107},{\"end\":56658,\"start\":56657},{\"end\":56669,\"start\":56668},{\"end\":56973,\"start\":56972},{\"end\":56992,\"start\":56982},{\"end\":56994,\"start\":56993},{\"end\":57005,\"start\":57004},{\"end\":57297,\"start\":57294},{\"end\":57307,\"start\":57304},{\"end\":57317,\"start\":57314},{\"end\":57457,\"start\":57456},{\"end\":57907,\"start\":57906},{\"end\":57917,\"start\":57916},{\"end\":57926,\"start\":57925},{\"end\":58252,\"start\":58251},{\"end\":58271,\"start\":58261},{\"end\":58273,\"start\":58272},{\"end\":58284,\"start\":58283},{\"end\":58599,\"start\":58598},{\"end\":58607,\"start\":58606},{\"end\":58890,\"start\":58889},{\"end\":58900,\"start\":58899},{\"end\":58910,\"start\":58909},{\"end\":58923,\"start\":58922},{\"end\":59128,\"start\":59127},{\"end\":59753,\"start\":59752},{\"end\":59763,\"start\":59762},{\"end\":59776,\"start\":59775},{\"end\":60155,\"start\":60154},{\"end\":60163,\"start\":60162},{\"end\":60533,\"start\":60532},{\"end\":60541,\"start\":60540},{\"end\":60550,\"start\":60546},{\"end\":60552,\"start\":60551},{\"end\":60558,\"start\":60557},{\"end\":60883,\"start\":60882},{\"end\":60891,\"start\":60888},{\"end\":60906,\"start\":60898},{\"end\":60908,\"start\":60907},{\"end\":60918,\"start\":60915},{\"end\":61229,\"start\":61226},{\"end\":61237,\"start\":61236},{\"end\":61249,\"start\":61244},{\"end\":61592,\"start\":61591},{\"end\":61605,\"start\":61604},{\"end\":61615,\"start\":61614},{\"end\":61887,\"start\":61886},{\"end\":62155,\"start\":62154},{\"end\":62165,\"start\":62164},{\"end\":62175,\"start\":62174},{\"end\":62489,\"start\":62488},{\"end\":62504,\"start\":62503},{\"end\":62513,\"start\":62512},{\"end\":62525,\"start\":62524},{\"end\":62851,\"start\":62848},{\"end\":62862,\"start\":62859},{\"end\":63218,\"start\":63217},{\"end\":63226,\"start\":63225},{\"end\":63238,\"start\":63237},{\"end\":63510,\"start\":63509},{\"end\":63770,\"start\":63769},{\"end\":64084,\"start\":64083},{\"end\":64305,\"start\":64304},{\"end\":64318,\"start\":64317},{\"end\":64328,\"start\":64327},{\"end\":64575,\"start\":64574},{\"end\":64584,\"start\":64583},{\"end\":64592,\"start\":64591},{\"end\":64607,\"start\":64604},{\"end\":64918,\"start\":64917},{\"end\":65147,\"start\":65146},{\"end\":65162,\"start\":65159},{\"end\":65357,\"start\":65356},{\"end\":65369,\"start\":65366},{\"end\":65633,\"start\":65632},{\"end\":65649,\"start\":65648},{\"end\":65656,\"start\":65655},{\"end\":65906,\"start\":65903},{\"end\":65916,\"start\":65913},{\"end\":65926,\"start\":65923}]", "bib_author_last_name": "[{\"end\":53555,\"start\":53540},{\"end\":53828,\"start\":53822},{\"end\":53839,\"start\":53832},{\"end\":54063,\"start\":54058},{\"end\":54074,\"start\":54067},{\"end\":54083,\"start\":54078},{\"end\":54376,\"start\":54373},{\"end\":54388,\"start\":54382},{\"end\":54636,\"start\":54628},{\"end\":54646,\"start\":54640},{\"end\":54656,\"start\":54650},{\"end\":54988,\"start\":54985},{\"end\":54999,\"start\":54992},{\"end\":55010,\"start\":55005},{\"end\":55033,\"start\":55026},{\"end\":55415,\"start\":55411},{\"end\":55424,\"start\":55419},{\"end\":55433,\"start\":55428},{\"end\":55441,\"start\":55437},{\"end\":55456,\"start\":55445},{\"end\":55467,\"start\":55460},{\"end\":55751,\"start\":55744},{\"end\":55764,\"start\":55755},{\"end\":56105,\"start\":56099},{\"end\":56114,\"start\":56109},{\"end\":56666,\"start\":56659},{\"end\":56676,\"start\":56670},{\"end\":56687,\"start\":56678},{\"end\":56980,\"start\":56974},{\"end\":57002,\"start\":56995},{\"end\":57302,\"start\":57298},{\"end\":57312,\"start\":57308},{\"end\":57323,\"start\":57318},{\"end\":57464,\"start\":57458},{\"end\":57914,\"start\":57908},{\"end\":57923,\"start\":57918},{\"end\":57934,\"start\":57927},{\"end\":58259,\"start\":58253},{\"end\":58281,\"start\":58274},{\"end\":58604,\"start\":58600},{\"end\":58615,\"start\":58608},{\"end\":58897,\"start\":58891},{\"end\":58907,\"start\":58901},{\"end\":58920,\"start\":58911},{\"end\":58931,\"start\":58924},{\"end\":59136,\"start\":59129},{\"end\":59760,\"start\":59754},{\"end\":59773,\"start\":59764},{\"end\":59784,\"start\":59777},{\"end\":60160,\"start\":60156},{\"end\":60167,\"start\":60164},{\"end\":60538,\"start\":60534},{\"end\":60544,\"start\":60542},{\"end\":60555,\"start\":60553},{\"end\":60886,\"start\":60884},{\"end\":60896,\"start\":60892},{\"end\":60913,\"start\":60909},{\"end\":61234,\"start\":61230},{\"end\":61242,\"start\":61238},{\"end\":61254,\"start\":61250},{\"end\":61602,\"start\":61593},{\"end\":61612,\"start\":61606},{\"end\":61623,\"start\":61616},{\"end\":61897,\"start\":61888},{\"end\":62162,\"start\":62156},{\"end\":62172,\"start\":62166},{\"end\":62182,\"start\":62176},{\"end\":62501,\"start\":62490},{\"end\":62510,\"start\":62505},{\"end\":62522,\"start\":62514},{\"end\":62533,\"start\":62526},{\"end\":62857,\"start\":62852},{\"end\":62870,\"start\":62863},{\"end\":63223,\"start\":63219},{\"end\":63235,\"start\":63227},{\"end\":63245,\"start\":63239},{\"end\":63520,\"start\":63511},{\"end\":63778,\"start\":63771},{\"end\":64090,\"start\":64085},{\"end\":64315,\"start\":64306},{\"end\":64325,\"start\":64319},{\"end\":64336,\"start\":64329},{\"end\":64581,\"start\":64576},{\"end\":64589,\"start\":64585},{\"end\":64602,\"start\":64593},{\"end\":64613,\"start\":64608},{\"end\":64922,\"start\":64919},{\"end\":65157,\"start\":65148},{\"end\":65167,\"start\":65163},{\"end\":65364,\"start\":65358},{\"end\":65374,\"start\":65370},{\"end\":65646,\"start\":65634},{\"end\":65653,\"start\":65650},{\"end\":65662,\"start\":65657},{\"end\":65911,\"start\":65907},{\"end\":65921,\"start\":65917},{\"end\":65932,\"start\":65927}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":53783,\"start\":53388},{\"attributes\":{\"doi\":\"10.5162/sensor09/v2/a6.1\",\"id\":\"b1\",\"matched_paper_id\":56324492},\"end\":53982,\"start\":53785},{\"attributes\":{\"doi\":\"10.1109/EIT.2009.5189614\",\"id\":\"b2\",\"matched_paper_id\":12350337},\"end\":54294,\"start\":53984},{\"attributes\":{\"doi\":\"10.1109/JSEN.2003.817901\",\"id\":\"b3\",\"matched_paper_id\":102322694},\"end\":54551,\"start\":54296},{\"attributes\":{\"doi\":\"10.1109/84.585789\",\"id\":\"b4\",\"matched_paper_id\":97993153},\"end\":54849,\"start\":54553},{\"attributes\":{\"doi\":\"10.1016/j.snb.2013.12.030\",\"id\":\"b5\",\"matched_paper_id\":47635},\"end\":55305,\"start\":54851},{\"attributes\":{\"doi\":\"10.5162/11dss2013/1.1\",\"id\":\"b6\"},\"end\":55671,\"start\":55307},{\"attributes\":{\"doi\":\"10.5194/jsss-7-389-2018\",\"id\":\"b7\",\"matched_paper_id\":54212890},\"end\":55940,\"start\":55673},{\"attributes\":{\"doi\":\"10.1016/j.procir.2012.07.109\",\"id\":\"b8\",\"matched_paper_id\":111058803},\"end\":56345,\"start\":55942},{\"attributes\":{\"id\":\"b9\"},\"end\":56581,\"start\":56347},{\"attributes\":{\"doi\":\"10.5194/jsss-7-359-2018\",\"id\":\"b10\",\"matched_paper_id\":58915667},\"end\":56878,\"start\":56583},{\"attributes\":{\"doi\":\"10.1109/I2MTC.2015.7151267\",\"id\":\"b11\",\"matched_paper_id\":34539062},\"end\":57290,\"start\":56880},{\"attributes\":{\"id\":\"b12\"},\"end\":57454,\"start\":57292},{\"attributes\":{\"doi\":\"10.5162/AHMT2014/P1\",\"id\":\"b13\"},\"end\":57775,\"start\":57456},{\"attributes\":{\"doi\":\"10.1016/j.proeng.2015.08.835\",\"id\":\"b14\",\"matched_paper_id\":113428650},\"end\":58164,\"start\":57777},{\"attributes\":{\"doi\":\"10.5162/sensor2015/D8.1\",\"id\":\"b15\"},\"end\":58483,\"start\":58166},{\"attributes\":{\"doi\":\"10.1117/12.2049886\",\"id\":\"b16\",\"matched_paper_id\":110388247},\"end\":58805,\"start\":58485},{\"attributes\":{\"doi\":\"10.3390/proceedings1040626\",\"id\":\"b17\",\"matched_paper_id\":3686940},\"end\":59125,\"start\":58807},{\"attributes\":{\"id\":\"b18\"},\"end\":59628,\"start\":59127},{\"attributes\":{\"id\":\"b19\"},\"end\":59948,\"start\":59630},{\"attributes\":{\"id\":\"b20\"},\"end\":60066,\"start\":59950},{\"attributes\":{\"doi\":\"10.1016/j.neucom.2015.03.082\",\"id\":\"b21\",\"matched_paper_id\":32220955},\"end\":60348,\"start\":60068},{\"attributes\":{\"doi\":\"10.1016/j.measurement.2014.04.016\",\"id\":\"b22\"},\"end\":60821,\"start\":60350},{\"attributes\":{\"doi\":\"10.1109/41.873214\",\"id\":\"b23\"},\"end\":61108,\"start\":60823},{\"attributes\":{\"doi\":\"10.1006/mssp.1997.0090\",\"id\":\"b24\",\"matched_paper_id\":122755859},\"end\":61499,\"start\":61110},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":49722418},\"end\":61797,\"start\":61501},{\"attributes\":{\"id\":\"b26\"},\"end\":62077,\"start\":61799},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":13621392},\"end\":62402,\"start\":62079},{\"attributes\":{\"doi\":\"10.1145/568518.568520\",\"id\":\"b28\",\"matched_paper_id\":15192608},\"end\":62757,\"start\":62404},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":382840},\"end\":63213,\"start\":62759},{\"attributes\":{\"doi\":\"10.1016/0169-7439(87)80084-9\",\"id\":\"b30\"},\"end\":63440,\"start\":63215},{\"attributes\":{\"id\":\"b31\"},\"end\":63701,\"start\":63442},{\"attributes\":{\"doi\":\"No.33\",\"id\":\"b32\",\"matched_paper_id\":15641166},\"end\":64030,\"start\":63703},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":379259},\"end\":64207,\"start\":64032},{\"attributes\":{\"id\":\"b34\"},\"end\":64570,\"start\":64209},{\"attributes\":{\"doi\":\"10.1007/978-3-540-35488-8\",\"id\":\"b35\"},\"end\":64855,\"start\":64572},{\"attributes\":{\"doi\":\"10.1007/978-1-84996-098-4\",\"id\":\"b36\"},\"end\":65096,\"start\":64857},{\"attributes\":{\"doi\":\"10.1016/S0167-739X(97)81974-7\",\"id\":\"b37\"},\"end\":65315,\"start\":65098},{\"attributes\":{\"doi\":\"10.1016/S0004-3702(97)00043-X\",\"id\":\"b38\",\"matched_paper_id\":15943670},\"end\":65512,\"start\":65317},{\"attributes\":{\"doi\":\"10.1007/978-94-017-2053-3_11\",\"id\":\"b39\"},\"end\":65899,\"start\":65514},{\"attributes\":{\"id\":\"b40\"},\"end\":66063,\"start\":65901}]", "bib_title": "[{\"end\":53536,\"start\":53388},{\"end\":53818,\"start\":53785},{\"end\":54054,\"start\":53984},{\"end\":54369,\"start\":54296},{\"end\":54624,\"start\":54553},{\"end\":54981,\"start\":54851},{\"end\":55738,\"start\":55673},{\"end\":56095,\"start\":55942},{\"end\":56655,\"start\":56583},{\"end\":56970,\"start\":56880},{\"end\":57904,\"start\":57777},{\"end\":58249,\"start\":58166},{\"end\":58596,\"start\":58485},{\"end\":58887,\"start\":58807},{\"end\":60152,\"start\":60068},{\"end\":60880,\"start\":60823},{\"end\":61224,\"start\":61110},{\"end\":61589,\"start\":61501},{\"end\":62152,\"start\":62079},{\"end\":62486,\"start\":62404},{\"end\":62846,\"start\":62759},{\"end\":63767,\"start\":63703},{\"end\":64081,\"start\":64032},{\"end\":64302,\"start\":64209},{\"end\":65144,\"start\":65098},{\"end\":65354,\"start\":65317}]", "bib_author": "[{\"end\":53557,\"start\":53538},{\"end\":53830,\"start\":53820},{\"end\":53841,\"start\":53830},{\"end\":54065,\"start\":54056},{\"end\":54076,\"start\":54065},{\"end\":54085,\"start\":54076},{\"end\":54378,\"start\":54371},{\"end\":54390,\"start\":54378},{\"end\":54638,\"start\":54626},{\"end\":54648,\"start\":54638},{\"end\":54658,\"start\":54648},{\"end\":54990,\"start\":54983},{\"end\":55001,\"start\":54990},{\"end\":55012,\"start\":55001},{\"end\":55024,\"start\":55012},{\"end\":55035,\"start\":55024},{\"end\":55039,\"start\":55035},{\"end\":55417,\"start\":55409},{\"end\":55426,\"start\":55417},{\"end\":55435,\"start\":55426},{\"end\":55443,\"start\":55435},{\"end\":55458,\"start\":55443},{\"end\":55469,\"start\":55458},{\"end\":55753,\"start\":55740},{\"end\":55766,\"start\":55753},{\"end\":56107,\"start\":56097},{\"end\":56116,\"start\":56107},{\"end\":56668,\"start\":56657},{\"end\":56678,\"start\":56668},{\"end\":56689,\"start\":56678},{\"end\":56982,\"start\":56972},{\"end\":57004,\"start\":56982},{\"end\":57008,\"start\":57004},{\"end\":57304,\"start\":57294},{\"end\":57314,\"start\":57304},{\"end\":57325,\"start\":57314},{\"end\":57466,\"start\":57456},{\"end\":57916,\"start\":57906},{\"end\":57925,\"start\":57916},{\"end\":57936,\"start\":57925},{\"end\":58261,\"start\":58251},{\"end\":58283,\"start\":58261},{\"end\":58287,\"start\":58283},{\"end\":58606,\"start\":58598},{\"end\":58617,\"start\":58606},{\"end\":58899,\"start\":58889},{\"end\":58909,\"start\":58899},{\"end\":58922,\"start\":58909},{\"end\":58933,\"start\":58922},{\"end\":59138,\"start\":59127},{\"end\":59762,\"start\":59752},{\"end\":59775,\"start\":59762},{\"end\":59786,\"start\":59775},{\"end\":60162,\"start\":60154},{\"end\":60169,\"start\":60162},{\"end\":60540,\"start\":60532},{\"end\":60546,\"start\":60540},{\"end\":60557,\"start\":60546},{\"end\":60561,\"start\":60557},{\"end\":60888,\"start\":60882},{\"end\":60898,\"start\":60888},{\"end\":60915,\"start\":60898},{\"end\":60921,\"start\":60915},{\"end\":61236,\"start\":61226},{\"end\":61244,\"start\":61236},{\"end\":61256,\"start\":61244},{\"end\":61604,\"start\":61591},{\"end\":61614,\"start\":61604},{\"end\":61625,\"start\":61614},{\"end\":61899,\"start\":61886},{\"end\":62164,\"start\":62154},{\"end\":62174,\"start\":62164},{\"end\":62184,\"start\":62174},{\"end\":62503,\"start\":62488},{\"end\":62512,\"start\":62503},{\"end\":62524,\"start\":62512},{\"end\":62535,\"start\":62524},{\"end\":62859,\"start\":62848},{\"end\":62872,\"start\":62859},{\"end\":63225,\"start\":63217},{\"end\":63237,\"start\":63225},{\"end\":63247,\"start\":63237},{\"end\":63522,\"start\":63509},{\"end\":63780,\"start\":63769},{\"end\":64092,\"start\":64083},{\"end\":64317,\"start\":64304},{\"end\":64327,\"start\":64317},{\"end\":64338,\"start\":64327},{\"end\":64583,\"start\":64574},{\"end\":64591,\"start\":64583},{\"end\":64604,\"start\":64591},{\"end\":64615,\"start\":64604},{\"end\":64924,\"start\":64917},{\"end\":65159,\"start\":65146},{\"end\":65169,\"start\":65159},{\"end\":65366,\"start\":65356},{\"end\":65376,\"start\":65366},{\"end\":65648,\"start\":65632},{\"end\":65655,\"start\":65648},{\"end\":65664,\"start\":65655},{\"end\":65913,\"start\":65903},{\"end\":65923,\"start\":65913},{\"end\":65934,\"start\":65923}]", "bib_venue": "[{\"end\":53561,\"start\":53557},{\"end\":53877,\"start\":53865},{\"end\":54113,\"start\":54109},{\"end\":54426,\"start\":54414},{\"end\":54700,\"start\":54675},{\"end\":55081,\"start\":55064},{\"end\":55407,\"start\":55307},{\"end\":55808,\"start\":55789},{\"end\":56148,\"start\":56144},{\"end\":56428,\"start\":56347},{\"end\":56731,\"start\":56712},{\"end\":57079,\"start\":57034},{\"end\":57619,\"start\":57485},{\"end\":57973,\"start\":57964},{\"end\":58325,\"start\":58310},{\"end\":58639,\"start\":58635},{\"end\":58970,\"start\":58959},{\"end\":59238,\"start\":59138},{\"end\":59750,\"start\":59630},{\"end\":60004,\"start\":59950},{\"end\":60211,\"start\":60197},{\"end\":60530,\"start\":60350},{\"end\":60963,\"start\":60938},{\"end\":61304,\"start\":61278},{\"end\":61629,\"start\":61625},{\"end\":61884,\"start\":61799},{\"end\":62219,\"start\":62184},{\"end\":62580,\"start\":62556},{\"end\":62972,\"start\":62872},{\"end\":63332,\"start\":63275},{\"end\":63507,\"start\":63442},{\"end\":63842,\"start\":63785},{\"end\":64111,\"start\":64092},{\"end\":64374,\"start\":64338},{\"end\":64687,\"start\":64640},{\"end\":64915,\"start\":64857},{\"end\":65210,\"start\":65198},{\"end\":65418,\"start\":65405},{\"end\":65630,\"start\":65514},{\"end\":53885,\"start\":53879},{\"end\":58336,\"start\":58327},{\"end\":62250,\"start\":62221}]"}}}, "year": 2023, "month": 12, "day": 17}