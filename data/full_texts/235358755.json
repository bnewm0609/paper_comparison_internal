{"id": 235358755, "updated": "2023-10-06 02:08:53.91", "metadata": {"title": "DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction", "authors": "[{\"first\":\"Fengtong\",\"last\":\"Xiao\",\"middle\":[]},{\"first\":\"Lin\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Weinan\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Jingyu\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Xiaofeng\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Jun\",\"last\":\"Lang\",\"middle\":[]},{\"first\":\"Hao\",\"last\":\"Wang\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining", "publication_date": {"year": 2021, "month": 6, "day": 7}, "abstract": "In E-commerce, vouchers are important marketing tools to enhance users' engagement and boost sales and revenue. The likelihood that a user redeems a voucher is a key factor in voucher distribution decision. User-item Click-Through-Rate (CTR) models are often applied to predict the user-voucher redemption rate. However, the voucher scenario involves more complicated relations among users, items and vouchers. The users' historical behavior in a voucher collection activity reflects users' voucher usage patterns, which is nevertheless overlooked by the CTR-based solutions. In this paper, we propose a Deep Multi-behavior Graph Networks (DMBGN) to shed light on this field for the voucher redemption rate prediction. The complex structural user-voucher-item relationships are captured by a User-Behavior Voucher Graph (UVG). User behavior happening both before and after voucher collection is taken into consideration, and a high-level representation is extracted by Higher-order Graph Neural Networks. On top of a sequence of UVGs, an attention network is built which can help to learn users' long-term voucher redemption preference. Extensive experiments on three large-scale production datasets demonstrate the proposed DMBGN model is effective, with 10% to 16% relative AUC improvement over Deep Neural Networks (DNN), and 2% to 4% AUC improvement over Deep Interest Network (DIN). Source code and a sample dataset are made publicly available to facilitate future research.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2106.03356", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/kdd/XiaoLX0YLW21", "doi": "10.1145/3447548.3467191"}}, "content": {"source": {"pdf_hash": "7171d359a97a9808043a594cec58f432b6e155bb", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2106.03356v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2106.03356", "status": "GREEN"}}, "grobid": {"id": "d5ae7ebf0fab1e3a393e4ebf9d1326afd4d07cb7", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/7171d359a97a9808043a594cec58f432b6e155bb.txt", "contents": "\nDMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction\nVirtual EventCopyright Virtual EventAugust 14-18, 2021\n\nFengtong Xiao fengtong.xiao@lazada.com \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nLin Li \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nWeinan Xu \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nJingyu Zhao jingyu.zhao@lazada.com \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nXiaofeng Yang xiaofeng.yang@lazada.com \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nJun Lang \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nHao Wang \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nFengtong Xiao \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nLin Li \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nWeinan Xu \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nJingyu Zhao \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nXiaofeng Yang \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nJun Lang \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nHao Wang \nAlibaba Group\nAlibaba Group\nSingapore, Singapore, Singapore, Singapore, Singapore, Singapore\n\nDMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction\n\nKDD\nSingaporeVirtual Event21August 14-18, 202110.1145/3447548.3467191ACM ISBN 978-1-4503-8332-5/21/08. . . $15.00 ACM Reference Format: 2021. DMBGN: Deep Multi-Behavior Graph Networks for Voucher Redemption Rate Prediction. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '21), August 14-18, 2021, Virtual Event, Singapore. ACM, New York, NY, USA, 9 pages. https://CCS CONCEPTS \u2022 Information systems \u2192 PersonalizationRecommender sys- tems\u2022 Applied computing \u2192 Electronic commerce * Both authors contributed equally to this work 1 https://githubcom/fengtong-xiao/DMBGN KEYWORDS VoucherRedemption Rate PredictionDeep LearningGraph Neural NetworksAttention MechanismMulti-Behavior\nIn E-commerce, vouchers are important marketing tools to enhance users' engagement and boost sales and revenue. The likelihood that a user redeems a voucher is a key factor in voucher distribution decision. User-item Click-Through-Rate (CTR) models are often applied to predict the user-voucher redemption rate. However, the voucher scenario involves more complicated relations among users, items and vouchers. The users' historical behavior in a voucher collection activity reflects users' voucher usage patterns, which is nevertheless overlooked by the CTR-based solutions. In this paper, we propose a Deep Multi-behavior Graph Networks (DMBGN) to shed light on this field for the voucher redemption rate prediction. The complex structural user-voucher-item relationships are captured by a User-Behavior Voucher Graph (UVG). User behavior happening both before and after voucher collection is taken into consideration, and a high-level representation is extracted by Higher-order Graph Neural Networks. On top of a sequence of UVGs, an attention network is built which can help to learn users' long-term voucher redemption preference. Extensive experiments on three large-scale production datasets demonstrate the proposed DMBGN model is effective, with 10% to 16% relative AUC improvement over Deep Neural Networks (DNN), and 2% to 4% AUC improvement over Deep Interest Network (DIN). Source code and a sample dataset are made publicly available to facilitate future research 1 .\n\nINTRODUCTION\n\nIn E-commerce, vouchers have already become significant tools which not only drive sales, but also help user growth and enhances customer loyalty. An online voucher (or coupon in some literature) is a digital ticket that can be redeemed with discount or rebate when a product is purchased 2 . A typical voucher is characterized by two components: condition and discount. The former specifies requirements of a voucher to be applicable, e.g, the minimum number of items purchased or the minimum amount of money spent in an order, and the latter refers to the amount or percentage deductible when the voucher is applied. This work focuses on minimum-spend and discount-amount based vouchers. Fig. 1 shows a typical user-voucher interaction scenario on an E-commerce platform: a user may do some online shopping before being assigned a voucher (i.e., pre-collection phase). After collecting the voucher (either manually or automatically), the user may continue to search, click or add-to-cart the items that he/she wants to buy with the voucher (i.e., post-collection phase). Finally, the user may redeem the voucher by purchasing some items (i.e., redemption phase), or simply leave the voucher expired without redemption. The capability of predicting the user-voucher redemption rate (VRR henceforth in this paper), the likelihood that a user may redeem a voucher, would contribute to a successful voucher marketing in multiple ways:\n\n\u2022 Performance Forecasting: Retailers are able to estimate the returns of a voucher (e.g. overall redemption rate, redeemed voucher count) before a campaign starts. \u2022 Budget Control: Retailers are able to know when to stop distributing vouchers so that the marketing budget would not be over-utilized or under-utilized. \u2022 Personalized Distribution: Retailers are able to distribute different voucher schema (e.g. condition and discount) to different customers to maximize the overall returns, by applying an optimization algorithm to the VRR results.\n\nThere are some preliminary studies [15,20,28] focusing on VRR prediction. Those studies solve voucher redemption rate prediction tasks by directly borrowing the ideas from user-item Click-Through-Rate (CTR) prediction models [6,38]. A common practice is to treat a given voucher in the same way as treating an item, simply replacing item features by voucher features in model training and prediction. Nonetheless, the VRR task is more challenging in several ways. Firstly, in item-wise CTR models, items in historical behavior and the item to be evaluated are homogeneous, while in VRR, the behavior involves heterogeneous relations between vouchers and items. Secondly, in CTR models, users' behavior on items has no obvious inter-dependent relationships. In voucher scenarios, by contrast, the user behavior is often triggered by the collected voucher and is strongly affected by the voucher condition and discount. As shown in Table 1, the behavior sequence in the post-collection phase becomes relatively longer than in pre-collection. Lastly, a user may have a multiple voucher redemption history, the long-term and short-term voucher usage preferences of the user need to be considered and balanced to better predict the VRR of the current voucher to be distributed (namely target voucher).\n\nTo tackle the above issues and shed light on the VRR prediction task, we propose a graph-based model Deep Multi-Behavior Graph Networks (DMBGN). To evaluate a user's VRR of the target voucher, DMBGN takes into consideration the user's historical interactions with vouchers. To model the structural user-voucher-item relationships, a User-Behavior Voucher Graph (UVG) is constructed for each user-voucher interaction activity. A UVG is a satellite-like heterogeneous graph containing nodes for both voucher and items in user behavior happening before and after the voucher collection. The techniques of Higher-order Graph Neural Networks are adopted to extract the high-level structural representation of a voucher activity, so that relationships like user-item preference, voucher-item dependency and user-voucher preference can be better distilled. To learn the user's long-term interests in voucher redemption, an attention network is applied on top of the historical UVG sequence. Finally, all the implicit representations of user, item, voucher and other side information are forwarded to a DNN network for the VRR prediction.\n\nThe main contributions of this paper are as follows:\n\n\u2022 To our best knowledge, this is the first work to propose a model specialized for the VRR prediction task. The model, DMBGN, follows the user's mindset in a real voucher activity \n\n\nRELATED WORK 2.1 Voucher-related Works\n\nThere are some preliminary studies in the literature addressing voucher-related problems. Those works can be divided into two types: i) the VRR prediction and ii) voucher distribution decisionmaking. For the first type, most of the studies adopt the CTR models widely utilized in item-wise recommendation. In [28], XGBoost model is used to solve the Online-to-Offline coupon redemption rate prediction, based on both user profile and coupon characteristic features. In [20], a sequence-based structure with attention-based mechanism is deployed, which considers long-term and short-term user behavior in addition to the voucher information. As discussed in introduction, our proposed model can better capture the more complex user-voucher-item relations with graph techniques, which is not presented in the previous works. For the second type, the task is to assign appropriate vouchers to different users based on the VRR prediction results and the total budget constraints. The most conventional optimization method for this task is the Multiple-Choice Knapsack Problem (MCKP) algorithm [18]. Some online learning algorithms can also be applied, such as online-MCKP [3], linear contextual bandits with knapsacks [1] and reinforcement learning based algorithms [9]. In this work, we focus on the first type of the problem on VRR prediction.\n\n\nCTR and CVR Prediction Models\n\nUser-item Click-Through-Rate (CTR) prediction, which is to predict the probability of a user clicking an item, is the key task in the itemwise recommendation domain. The widely utilized models include Wide-and-Deep (WDL) [6] and Deep Factorization Machine (DFM) [13]. In recent years, attention-based structures to capture user's historical interest representation become a hot topic. Among them, Deep Interest Network (DIN) [38], Deep Evolution Interest Network (DIEN) [37], Deep Hierarchical Attention Network (DHAN) [35], Deep Cross Networks (DCN) [32] and Behavior-sequence Transformer (BST) [5] are the representatives. There, the target and the attended objects are all items, and the behavior usually has no strong dependent relations. However, the VRR task needs to consider heterogeneous and inter-dependent relationships among users, items and vouchers. Conversion rate (CVR), the possibility that a user will finally convert (e.g. purchase the item), is another important task in item-wise recommendation. The multi-task learning framework is a popular solution in this area. In [2,22], MMoE and GMCM models utilize the shared bottom structure and task-specific upper structures to optimize CTR and CVR together. In [33], ESMM2 follows a similar strategy but instead optimizes CTR and Click-Through-Conversion Rate (CTCVR). Although multi-task learning can help to estimate the conversion before the target is exposed, it is not appropriate for the VRR task. Users usually have no objection to collect an assigned voucher, and under some circumstances, the voucher is auto-collected according to the platform's strategies. Therefore, it is difficult or even impossible to co-train the collection rate and the redemption rate in the multi-task manner.\n\nThere are also some works which take multiple user behaviors into account for more accurate CTR and CVR prediction. In these works, various behaviors such as clicks, favorites, add-to-cart, purchases, etc are considered and specific techniques are applied to model user-item relationships for better inference, such as hetergeneous graph convolution network [2,16], cascading ordinal behavior structure [4,10] and transformer architecture [34]. However, our work for VRR aims to model user-voucher-item relationships through a graph network, which focuses more on capturing different user behavior patterns happening before and after voucher collection.\n\n\nGraph Embedding and Related Models\n\nRecent years have seen the surge of research interests in deep graphnetwork techniques. A series of graph embedding techniques such as DeepWalk [26], Node2Vec [12] and MetaPath2Vec [7] have been widely utilized in various applications. More recently, convolutional network structures become popular which can dig deeper structural relationships from the graph. A number of models such as WL GNN [24], GraphSage [14], Graph-Attention Networks (GAT) [31], Graph Convolutional Networks (GCN) [19] and Gated Graph Neural Networks (GGNN) [21] have been successfully deployed in the fields of social networking, advertising, risk assessment and recommendation systems. For the CTR tasks, DHGAT [25] employs a heterogeneous graph structure to model the relationships among users, queries, shops and items. ATBRG [8] utilizes graph pruning techniques to get more effective recommendations. GMCM [2] adopts GCN to generate the hidden representations of various types of behavior such as click, review and add-to-cart.\n\n\nMETHODOLOGY\n\nThis section introduces the DMBGN model for VRR prediction. It starts with the problem definition, followed by the illustration of User-Behavior Voucher Graph (UVG) and the overview of the model architecture. Next, details about the graph neural networks on UVG are given. Then, the attention mechanism which aggregates the UVG sequences is explained. Finally, the loss function used for model training is presented.\n\n\nProblem Setup\n\nGiven a set < U, O, I, C >, U = { 1 , 2 , 3 , \u00b7 \u00b7 \u00b7 , } denotes the set of users, O = { 1 , 2 , 3 , \u00b7 \u00b7 \u00b7 , } denotes the set of vouchers, I = { 1 , 2 , 3 , \u00b7 \u00b7 \u00b7 , } denotes the set of items, C , = { , 1 , , 2 , , 3 , \u00b7 \u00b7 \u00b7 , , } denotes types of behavior happening before and after user collects voucher . A behavior is an item from I, associated with an action type (e.g, click, add-to-cart, order). Further, C , is divided into two subsets C , and C , , representing the behavior happening before ( ) and after ( ) voucher collection, respectively. In C , , all the behaviors after the voucher collection and before the voucher redemption (or expiration) are included. In C , , the nearest behavior items before voucher collection, up to a specified number, are included. A voucher session describes a voucher collected by the user and the associated behavior, which can be defined as a tuple of ( , , C , ).\n\nThe problem of VRR predication is to calculate the probability of a user to redeem a voucher, given the behaviors before user collects the voucher. Formally, the voucher redemption rate is defined as  \n\n\nUser-Behavior Voucher Graph (UVG)\n\nTo model the user-voucher-item relationships, a User-Behavior Voucher Graph (UVG) is constructed for each voucher session ( , , C , ). The graph is defined as G = (V, E) where V represents the node set and E represents the edge set. V contains a node for the voucher, denoted as V and the nodes for items in C , , denoted as V . Item nodes V can be further distinguished according to action timestamps as the pre-collection ( ) and post-collection ( ) phases, and according to the action types, i.e., add-to-cart ( ) and order ( ) 3 . Thus, V is divided into four sub-groups V , , V , , V , and V , along the two dimensions. Edges in E have two types. The first type connects the item nodes within the above four sub-groups of V , while the other type connects the item nodes to the voucher node. As shown in Fig. 2, a UVG is a satellite-like structure where the center is the voucher node surrounded by four zones. These four zones represent four types of relations, corresponding to the four sub-groups of V , respectively. The central voucher node is only connected to the closest (in event timestamp) item nodes in every zone, while in each particular zone, an item node is connected to its closest node. UVG is a directed graph, and the direction of each edge follows the corresponding chronological order.\n\n\nModel Architecture\n\nThe overall framework of DMBGN is presented in Fig. 3. The model takes user's profile information, historical voucher sessions information, and the current voucher session information as inputs. The left bottom part is for the user profiles features handled by an embedding layer. The central bottom is for the user's historical redeemed voucher sessions, while the right bottom is for the session of the target voucher to be predicted. The information and relationships about the voucher and its surrounding behavior are represented by UVG. Graph Neural Networks (GNN) are applied on the UVG to generate the embedding, as well as a score reflecting the quality of the embedding. On top of a user's historical UVG sequence, an attention network is introduced to obtain the aggregated embedding, which represents the user's voucher usage interest with respect to the target voucher. An addition output of the UVG sequence is also created by concatenating and pooling all the UVG scores in the sequence.\n\nThe outputs of the user profiles, historical voucher sessions and target voucher session are concatenated together and forwarded to an MLP layer for final redemption rate prediction. The result is a 0-to-1 value indicating the probability that a user would redeem a voucher. The parameters of DMBGN are learned on labelled training samples and can be applied for the later VRR prediction.\n\n\nGraph Embedding for UVG\n\n3.4.1 Higher-order Graph Neural Networks. When each UVG is constructed, graph neural networks are applied to extract the high-level representations. Higher-order Graph Neural Networks with Weisfeiler-Leman Algorithm [24] have the advantage of fast computation, easy tuning and robustness, and have been widely used in production pipelines. Hence Higher-order GNN is adopted here to conduct the convolution operations which update each node \u2208 V in UVG as follows:\n( ) ( ) = ( \u22121) ( ) \u00b7 ( ) 1 + \u2211\ufe01 \u2208 ( ) ( \u22121) ( ) \u00b7 ( ) 2(1)\nwhere represents \u210e layer, and ( ) represents the neighbors of . The first layer node embedding (0) ( ) is obtained by separate embedding layers for the input item and voucher features. For an item, the input features include item id, category id and item price level; for a voucher, the input features include the corresponding marketing activity id and schema values (i.e., minimum-spend and discount-amount).\n\nThe node embeddings generated by Equation (1) are further aggregated into the user-behavior embedding , , the voucher embedding , , and the final UVG embedding . Recall the item nodes in UVG can be divided into four sub-groups. We calculate the embedding for a sub-group as follows:\n= , || ,(2)\nwhere , and , represent the average and the maximization of all the node embeddings in the sub-group . These two results are concatenated to form the sub-group's final embedding . Next, the embeddings of four sub-groups, denoted as _ , _ , _ and _ are concatenated and forwarded to an MLP to derive , , that is:\n, = MLP( _ || _ || _ || _ )(3)\nThe voucher embedding , is simply the embedding from the voucher node.\n\n, and , are concatenated to obtain the final UVG embedding as in Equation (4). In addition, a score for a historical UVG is generated from the dot-product between , and , as in Equation (5). The score, namely , represents how well the voucher embedding alone can reflect the related behavior associated with this voucher.\n= , || ,(4)= ( , \u00b7 , )(5)\nwhere the (\u00b7) represents the sigmoid function. The first-layer node embeddings (0) ( ) for items and vouchers can either be learned from scratch with the main task, or be trained independently in advance. In this work, we pre-train these initial item node embeddings and voucher embeddings separately.\n\n\n3.4.2\n\nPre-training of Item Embedding. Following the previous works in [26,27,30], a meta-path type graph embedding algorithm is applied to generate the item embeddings. In order to avoid overfitting, the algorithm is run on all the logged user behavior data from our platform. To enrich the expression of users' item sequences, sideinformation features such as _ , _ , and \u210e _ are added for training. The pre-training is conducted separately for add-to-cart and order behavior in this paper, so that the same item of different behavior types has different embeddings. The learned embeddings are used to initialize the item nodes in both historical and target UVGs.\n\n\n3.4.3\n\nPre-training of Voucher Embedding. The historical UVGs in DMBGN represent the voucher-redeemed sessions. However, there may exist an overwhelming number of non-redeemed voucher sessions in the voucher usage data set. In this work, we utilize all the redeemed and non-redeemed voucher sessions from the platform to pre-train the voucher embeddings. A learned voucher embedding is expected to be capable of representing its related usage behavior, so it should be close to its corresponding behavior embedding in a semantic space if the voucher is redeemed, and far away otherwise.\n\nFor each user voucher session, a UVG is constructed as described in Section 3.2. The item embeddings input to UVG are implemented as in Section 3.4.2, while the voucher embedding is randomly initialized. Recall that , the score of the UVG represents the similarity between , and , . Loss function for voucher embedding training is defined as:\n\u2212 \u210e = 1 \u2211\ufe01 =1 ( , )(6)\nwhere represents the total size of the UVG pre-trained samples, and represents the \u210e sample. is a 1-or-0 label of UVG indicating the ground-truth whether the user redeems this voucher or not. (\u00b7) represents the binary cross-entropy loss function.\n\nAfter training, the initial embeddings of the voucher nodes are learned. Note that the above pre-training involves the ground-truth label whether a user redeems a voucher. Therefore, it is only conducted in the historical UVGs, but not in the target UVG. For all the target UVGs, the voucher embeddings are randomly initialized and learned from scratch with the main task.\n\nIn addition to the voucher embeddings, the weight parameters of the Higher-order Graph Neural Networks are learned during the pre-training of UVGs. These weights are used for DMBGN network initialization and to be further fine-tuned with the main task.\n\n\nAttention Networks on UVG sequences\n\nA user may have multiple previous voucher redemption sessions and thus may have a sequence of historical UVGs. To discover the user's long-term voucher usage preference (e.g. \"What kind of voucher the user will be interested in?\" and \"What kinds of items will the user purchases with the voucher?\"), an attention layer is added on top of the historical and the target UVGs. The AttentionNet proposed in the work of DIN [38] is adopted as follows:\n= ( , , ), = 1, 2, \u00b7 \u00b7 \u00b7 , \u210e = \u2211\ufe01 =1 \u00b7(7)\nhere, and are the embeddings of the \u210e historical UVG and the target UVG, respectively, and \u210e is the high-level representation of historical UVG sequences with respect to the target voucher . The AttentionUnit in Fig. 3 is a feed-forward neural network with scalar output as the attention weight, and the network parameters are represented as . Apart from the two input embedding vectors, AttentionUnit adds their outer-product and difference as well, which helps model the interactions between an input pair as mentioned in the original DIN model.\n\nThe learned attention network gives higher weights to the historical voucher sessions that are semantically closer to the target session. These historical sessions include the complete behavior information, and thus could better reflect the user's long-term voucher usage preference with respect to the target voucher. Referring to such sessions gives valuable clues whether a voucher will be redeemed in the end.\n\n\nLoss Function\n\nTo train the DMBGN model, two loss functions are considered. The first one, , evaluates the loss based on the difference between the predicted voucher redemption result\u02c6and the ground-truth label , where represents the \u210e training sample. The loss function is formulated as:\n= 1 \u2211\ufe01 =1 \u2212( log\u02c6+ (1 \u2212 ) log(1 \u2212\u02c6)) (8)\nwhere is the total number of training samples. Another loss function is introduced for regularization. Recall in DMBGN, each historical UVG session outputs a score indicating whether the voucher and the behavior embeddings are semantically close. It is expected that the voucher embedding can reflect the related behavior, the score should be as close to 1 as possible because each historical UVG corresponds to a redeemed session. Inspired by the work in [37], for better supervision of the UVG graph network training during the main task, the auxiliary loss function is defined as:\n= 1 \u2211\ufe01 =1 1 \u2211\ufe01 =1 \u2212 ( )(9)\nwhere denotes the history UVG sequence length from the \u210e sample, and represents the \u210e UVG in a user's history UVG sequence. Therefore, the final loss is the weighted sum of and , represented as follows:\n= + \u00b7 (10)\nwhere is the trade-off coefficient.\n\n\nEXPERIMENTS 4.1 Dataset\n\nFor the VRR prediction task, there is no public dataset so far. In this work, we use the large-scale dataset from the real voucher log data from Lazada, a leading South-East Asia (SEA) E-commerce platform of Alibaba Group. The data covers Lazada's voucher marketing activities during campaign periods such as Double 11 and Double 12 from 2019 to 2020. We select the data from three countries in SEA, named as Region-A, Region-B and Region-C, respectively. The three datasets contain users' platform voucher collection and redemption logs as well as users' behavior occurring both before and after voucher collection. To preserve adequate amount of user behavior without introducing too much noise, the 95% percentile of users' behavior length is retained. For each user, at most 45 addto-cart and 20 order items before or after voucher collection are reserved. The three datasets are of different sizes, and reflect various user-voucher engagement degrees. Overall, 44.2% (Region-A), 11.6% (Region-B) and 31.2% (Region-C) of the samples have at least one previous voucher redemption record. Each sample in the dataset is represented as a unique < _ , \u210e _ > pair, with a label 1 or 0 indicating if the user redeemed the voucher or not. A \u210e _ represents an individual voucher marketing activity. Each sample is associated with the user profile features (predicted age level, predicted gender, predicted purchase level, and user's order statistics), voucher features (minimumspend, discount-amount, collection and redemption timestamps) and item features (pre-trained embeddings, brand_id, category_id, price level). All numerical features used in the following experiments are normalized through z-normalization and all sparse id features are encoded using LabelEncoder. We have published a desensitized subset of original dataset Region-C for public use. Table 2 summarizes the statistics of three datasets, a full description of the dataset is also available on GitHub.\n\n\nCompared Models\n\nTo evaluate the performance of proposed method, we compare DMBGN with the following models which are commonly adopted in item CTR prediction tasks.\n\n\u2022  [38] is an attention-based model in recommendation systems that has been proven successful in Alibaba. We use this as our second baseline, replacing the user's historical item sequences with user's historical voucher sequences to adapt to the VRR prediction task. All dense and sparse features are used in the model along with the attention part.\n\n\nEvaluation Metrics\n\nTwo widely used metrics for binary classification tasks are adopted in our experiments: AUC and Logloss. Area under receiver operator curve (AUC) measures the probability of ranking a random positive sample higher than a negative one. Logloss is also utilized which reflects the prediction inaccuracy of voucher redemption rate. Each experiment is repeated 5 times. Mean and standard deviation of AUC and mean of Logloss are reported.\n\nIn addition, to measure the relative AUC improvement over models, RelaImpr [36,38] is also used which is defined as:\n= ( ) \u2212 0.5 ( ) \u2212 0.5 \u2212 1 \u00d7 100% (11)\n\nHyper-parameter Settings\n\nAll experiments in this paper use Adam optimizer with 1 = 0.9, 2 = 0.999 and learning rate = 0.001. 8 GPUs are used in the experiment with batch size of 1024. In the MLP layer across different deep models, the hidden units are (128, 64); dropout rate is set as 0.5; 2 regularization is applied to avoid over-fitting with  [38] is selected as the activation function with one layer of 64 hidden units. The embedding dimension of sparse id features is 16. The Graph Neural Networks for UVGs adopt a graph convolution layer and a top-K pooling layer [11] with ratio = 0.9. The loss trade-off coefficient is set as = 1.0. Besides, as 99.10% of users have not more than 6 historical redeemed vouchers, the maximal length of historical UVG sequence is set as = 6. The number of nodes connected to the voucher node in UVG mentioned in Section 3.2 is set as = 6.\n\n\nRESULTS AND DISCUSSIONS\n\nIn this section, we analyze the overall performance of DMBGN and other compared models. The following four questions are also proposed to be answered:\n\n\u2022 Q1: Are graph neural networks in DMBGN helpful in improving the overall performance? \u2022 Q2: How does the user behavior happening before and after voucher collection help improve the overall performance of DMBGN? \u2022 Q3: How does user activeness in terms of historical UVG sequence length affect the DMBGN performance? \u2022 Q4: How are the user-voucher-item structural relationships distilled by Higher-order Graph Neural Networks? The experimental results of DMBGN and the other compared models are summarized in Table 3. Besides, we also list the results of two variants of DMBGN, which use the same network structure but different embedding generation methods:\n\n\u2022 AvgPooling: Instead of using Higher-order Graph Neural Networks to model user-voucher-item relationships, it directly takes an average of pre-trained item embeddings from user behavior happening both before and after voucher collection. For target UVG, it only takes an average of precollection item embeddings. \n\n\nOverall Performance\n\nBased on the results in Table 3, we have the following observations:\n\n\u2022 DMBGN consistently outperforms other baseline models across all three datasets in terms of AUC and Logloss, the standard deviation of AUC is smaller than 0. \n\n\nAblation Study (Q1)\n\nTo further demonstrate the effectiveness by introducing the graph structure, we compare the performance of DMBGN with its two variants. The results are shown in the last three rows in Table 3:\n\n\u2022 Taking AvgPooling as baseline, Pre-trained achieves the relative AUC improvement of 1.7%, 0.4%, 0.9% as calculated in Equation (11) \n\n\nPost-collection User Behavior Study (Q2)\n\nUnlike item-wise recommendation, the user behavior related to voucher collection plays an important role in final redemption decisions. Hence, we conduct experiment to compare the influence from behavior in different phases (i.e., pre-collection and post-collection) on the overall performance of DMBGN. The results are summarized in Table 4. Based on the results shown in Table 4, we see that DBMGN using pre-collection behavior alone could achieve relative AUC improvement of 3.5%, 1.8%, 2.1% across three datasets compared to DIN, which uses \u210e _ but without related user behavior. Moreover, adding the post-collection behavior could further improve the overall performance by 0.7%, 0.2%, 0.9% compared to using the pre-collection only. Those pre-collection user behavior usually reflects a user's specific interest during a voucher campaign, and the post-collection could further reflect the interest stimulated by the current collected voucher. The results indicate that DBMGN is able to capture user's interest in both before and after voucher collection for better VRR prediction.\n\n\nAnalysis of User Activeness (Q3)\n\nExperiments are performed to see how DMBGN is affected by users' activeness in terms of the historical UVG sequence length. Region-A which is the most active region is taken for analysis. Fig. 4 visualizes the test AUC with respect to various historical UVG sequence lengths from 0 to 6 (the max historical UVG sequence length in our system setting). Note that the test data size under each sequence length group is more than 10k, which is statistically adequate for this analysis. In Fig. 4, as the historical UVG sequence length increases, the corresponding AUC increases from 0.7930 to 0.8335. This observation indicates that the attention structure in DMBGN can effectively capture users' long-term interest in voucher usage. For the groups with historical sequence length larger than 1, where the attention mechanism actually matters, the performance is better than those with smaller historical length. It is interesting to observe that the AUC of the group with length 1 is slightly lower than that of the group with sequence 0. A possible explanation is that the users from the former group are also inactive in voucher usage, and only one single redeemed session might not be sufficient to reflect the user's voucher preference, but nevertheless introduces noise.\n\n\nUser-behavior Embedding Visualization (Q4)\n\nTo show the effectiveness of knowledge distilling by the Higherorder Graph Neural Networks, we randomly sample the sessions of five \u210e _ from dataset Region-B, and visualize the corresponding learned user-behavior embedding vectors , from UVG in 2 dimension using t-SNE [29] algorithm in Fig. 5. All nonredeemed sessions from those \u210e _ are marked in red color, while the redeemed sessions with the same \u210e _ are marked with an individual color. It shows that the learned embeddings can well discriminate redeemed and non-redeemed sessions. It also illustrates that sessions with the same color are mostly located in the same cluster. One exception is Voucher 4 cluster, which is divided into two sub-clusters. A further analysis shows that the split clusters correspond to users of different activeness levels. Specifically, in the purple sub-cluster, 93.3% users have greater than or equal to 19 total items related to user behavior while in the green sub-cluster, 83.1% users have less than 19 items. Overall, Fig. 5 indicates that the learned embeddings from DMBGN can well represent the users' voucher-related behavior. \n\n\nCONCLUSION AND FUTURE WORK\n\nIn this paper, we propose a voucher redemption prediction (VRR) model: Deep Multi-Behavior Graph Networks (DMBGN). It considers the historical user behavior happening both before and after voucher collection to make better inference. To capture the uservoucher-item structural relationships, a User-Behavior Voucher Graph (UVG) is constructed, and Higher-order Graph Neural Networks are applied to extract the structural features reflecting interactions between voucher and user behavior. An attention network is built on top of the UVG sequences to mine user's longterm voucher usage preference. Extensive experiments in three large-scale datasets are conducted. The results show that DMBGN achieves 10% to 16% relative uplift in AUC compared to DNN, as well as 2% to 4% relative uplift in AUC compared to DIN. This demonstrates that DMBGN is effective for the VRR prediction task.\n\nThere are several potential future works for exploration. In a voucher campaign, there may exist multiple vouchers to be distributed simultaneously or within a short time interval. The influence of different vouchers on user behavior are intertwined. More sophisticated graph structures are needed to capture vouchervoucher cooperative or conflicting relationships. Besides, the applicable condition of a voucher may have restrictions over specific shops, brands or categories. The influence of the voucher usage scopes on the user behavior is also worthwhile to be explored.\n\nFigure 1 :\n1Illustration of interactions between users and vouchers in different phases.\n\nFigure 2 :\n2Illustration of User-Behavior Voucher Graph (UVG). The voucher node in the center represents the collected voucher. Item nodes from user behavior are subgrouped by action types ( and ) and phases (precollection and post-collection).\n\n\n( = 1| \u2208 U, \u2208 O, C , ), where = 1 if and only if user redeems the voucher .\n\nFigure 3 :\n3The architecture of DMBGN. The input consists of user profile features, UVG sequences representing user historical redeemed voucher sessions, and target voucher session. For each UVG, an embedding and its score are obtained. An attention layer is built on top of the UVG sequences to obtain the aggregated embeddings. The outputs from the three parts are concatenated and forwarded to the MLP for the VRR prediction of the target voucher .\n\n\nthe GNN weight parameters for \u210e convolution layer. (\u00b7) represents the sigmoid activation function.\n\n\nLR: Logistic Regression [23] is a shallow model. Only dense features from user profiles and voucher information are used in the model. \u2022 GBDT: Gradient Boosting Decision Tree [17] is used to assess the performance of non deep-learning algorithms. Similarly, only dense features are used. \u2022 DNN: The Deep Neural Network is used as the first baseline taking both dense features and embedding of sparse id features into the model. \u2022 WDL: Wide and Deep model [6] is widely accepted in real industrial applications. Compared with DNN, it has an additional linear model besides the deep model. All dense and sparse features are used in both wide and deep side. \u2022 DIN: Deep Interest Network\n\n\u2022\nPretrained: It uses the same weight parameters of Higherorder GNN learned during the voucher embedding pre-training as mentioned in Section 3.3. But the values of weight parameters are not further updated during the main task training. \u2022 DMBGN: The proposed model in this work, which loads the pre-trained GNN network including the item and voucher node embeddings. The GNN network parameters are further fine-tuned according to the final training loss.\n\nFigure 4 :\n4AUC performance on different historical UVG sequence length.\n\nFigure 5 :\n5Visualization of learned user-behavior embedding vectors , from UVG. Red color represents nonredeemed sessions, and the rest colors represent redeemed sessions with respect to different voucher ids.\n\nTable 1 :\n1The average sequence lengths and the percentage difference of items from user behavior (click, add-to-cart and order) happening before and after voucher collection.User Behavior \nAvg. Sequence \nAvg. Sequence \nAvg. Sequence Length \nLength (before) \nLength (after) \nDiff % = (after)/(before)-1 \n\nClicked Items \n79.8 \n92.2 \n15.5% \nAdd-to-cart Items \n10.9 \n13.7 \n25.2% \nOrdered Items \n1.8 \n3.6 \n105.7% \n\nand represents the historical behavior happening both before \nand after voucher collection with a User-Behavior Voucher \nGraph (UVG). \n\u2022 DMBGN is also the first work to utilize techniques of graph \nneural networks to learn the complex user-voucher-item re-\nlationships, and exploits an attention network to mine users' \nlong-term voucher redemption preference with respect to \nthe target voucher. \n\u2022 Extensive experimental results conducted on three large-\nscale production datasets collected from E-commerce plat-\nform Lazada indicate promising performance of DMBGN. \nCompared with Deep Neural Networks (DNN), DMBGN \nachieves 10% to 16% relative AUC improvement. Compared \nwith Deep Interest Network (DIN), DMBGN achieves 2% to \n4% uplift in AUC as well. \n\n\n\nTable 2 :\n2Statistics of three datasets from different regions.Dataset \nSessions Users \nItems \nVouchers \nTraining \nTesting \nSamples \nSamples \n\nRegion-A \n3.4M \n730K \n7.2M \n1k \n2.7M \n687K \nRegion-B \n14M \n6.5M \n19M \n0.5k \n11M \n2.8M \nRegion-C \n24M \n7.0M \n15.5M \n1k \n19.4M \n4.9M \n\n\n\nTable 3 :\n3Model performance evaluated by AUC on three production datasets. The Relative Improvement (RelaImpr) takes DNN and DIN as baseline models. Best results of all methods are highlighted in boldface.Model \n\nRegion-A \nRegion-B \nRegion-C \nAUC \nRelaImpr RelaImpr Logloss \nAUC \nRelaImpr RelaImpr Logloss \nAUC \nRelaImpr RelaImpr Logloss \nmean \u00b1 std \n(DNN) \n(DIN) \nmean \nmean \u00b1 std \n(DNN) \n(DIN) \nmean \nmean \u00b1 std \n(DNN) \n(DIN) \nmean \n\nLR \n0.7491 \u00b1 0.00005 \n-9.04% \n-14.43% \n0.4385 \n0.7805 \u00b1 0.00009 \n-10.74% \n-17.93% \n0.3712 \n0.7565 \u00b1 0.00011 \n-16.66% \n-26.39% \n0.3202 \nGBDT \n0.7538 \u00b1 0.00004 \n-7.34% \n-12.83% \n0.4215 \n0.7924 \u00b1 0.00004 \n-6.94% \n-14.44% \n0.3610 \n0.7982 \u00b1 0.00005 \n-3.12% \n-14.43% \n0.2933 \nDNN \n0.7739 \u00b1 0.00000 \n0.00% \n-5.93% \n0.4156 \n0.8142 \u00b1 0.00000 \n0.00% \n-8.06% \n0.3478 \n0.8078 \u00b1 0.00000 \n0.00% \n-11.67% \n0.2966 \nWDL \n0.7752 \u00b1 0.00004 \n0.47% \n-5.49% \n0.4145 \n0.8188 \u00b1 0.00004 \n1.46% \n-6.72% \n0.3452 \n0.8110 \u00b1 0.00009 \n1.05% \n-10.74% \n0.2948 \nDIN \n0.7912 \u00b1 0.00029 \n6.30% \n0.00% \n0.4021 \n0.8417 \u00b1 0.00017 \n8.77% \n0.00% \n0.3248 \n0.8485 \u00b1 0.00022 \n13.22% \n0.00% \n0.2692 \nDMBGN-AvgPooling 0.7961 \u00b1 0.00017 \n8.09% \n1.68% \n0.3975 \n0.8430 \u00b1 0.00015 \n9.15% \n0.36% \n0.3238 \n0.8497 \u00b1 0.00026 \n13.60% \n0.34% \n0.2681 \nDMBGN-Pretrained \n0.8012 \u00b1 0.00014 \n9.97% \n3.45% \n0.3954 \n0.8444 \u00b1 0.00011 \n9.62% \n0.78% \n0.3217 \n0.8530 \u00b1 0.00023 \n14.67% \n1.29% \n0.2658 \nDMBGN \n0.8034 \u00b1 0.00023 \n10.76% \n4.20% \n0.3921 \n0.8486 \u00b1 0.00021 \n10.94% \n2.00% \n0.3184 \n0.8591 \u00b1 0.00015 \n16.65% \n3.04% \n0.2614 \n\ncoefficient as 0.1. In Attention Net, PReLU \n\n\non dataset Region-A, B, C respectively. Recall that AvgPooling and Pre-trained take different strategies to generate the user behavior embedding , , by simple mean pooling and by graph techniques, respectively. The out-performance of Pre-trained over AvgPooling supports that the construction of and Higher-order GNN could better capture user-voucher-item relationships.\u2022 After fine-tuning of Higher-order GNN network parameters, DMBGN further improves the AUC over Pre-trained version by 0.7%, 1.2%, 1.7% on dataset Region-A, B, C, respectively. This improvement indicates that the graph network can adaptively learn from the final loss.\n\nTable 4 :\n4Experiment results of DMBGN for including and excluding post-collection user behavior on three datasets.Model \nRegion-A \nRegion-B \nRegion-C \nAUC Logloss AUC Logloss AUC Logloss \nDMBGN w/ pre-collection 0.8014 0.3937 0.8479 0.3191 0.8557 0.2639 \nbehavior only \nDMBGN w/ pre-and post-0.8034 0.3921 0.8486 0.3184 0.8591 0.2614 \ncollection behavior \n\n\nRetailers may limit the scope of a voucher to a specific pool of promoted items. This paper focuses on those voucher applicable to all the products in the platform.\nWe also conducted experiments considering nodes related to action type, but the results do not show any further improvement. This may attribute to the noises in the large amount of clicked items, and the weak correlations between clicked items and collected vouchers.\n\nShipra Agrawal, Nikhil R Devanur, arXiv:1507.06738Linear contextual bandits with knapsacks. arXiv preprintShipra Agrawal and Nikhil R Devanur. 2015. Linear contextual bandits with knapsacks. arXiv preprint arXiv:1507.06738 (2015).\n\nGmcm: Graph-based micro-behavior conversion model for post-click conversion rate estimation. Wentian Bao, Hong Wen, Sha Li, Xiao-Yang Liu, Quan Lin, Keping Yang, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 43rd International ACM SIGIR Conference on Research and Development in Information RetrievalWentian Bao, Hong Wen, Sha Li, Xiao-Yang Liu, Quan Lin, and Keping Yang. 2020. Gmcm: Graph-based micro-behavior conversion model for post-click conversion rate estimation. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2201-2210.\n\nOnline knapsack problems. Deeparnab Chakrabarty, Yunhong Zhou, Rajan Lukose, Workshop on internet and network economics (WINE). Deeparnab Chakrabarty, Yunhong Zhou, and Rajan Lukose. 2008. Online knap- sack problems. In Workshop on internet and network economics (WINE).\n\nEfficient Heterogeneous Collaborative Filtering without Negative Sampling for Recommendation. C Chen, Min Zhang, Yongfeng Zhang, W Ma, Yiqun Liu, Shaoping Ma, AAAI. C. Chen, Min Zhang, Yongfeng Zhang, W. Ma, Yiqun Liu, and Shaoping Ma. 2020. Efficient Heterogeneous Collaborative Filtering without Negative Sampling for Recommendation. In AAAI.\n\nBehavior sequence transformer for e-commerce recommendation in alibaba. Qiwei Chen, Huan Zhao, Wei Li, Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data. the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse DataQiwei Chen, Huan Zhao, Wei Li, et al. 2019. Behavior sequence transformer for e-commerce recommendation in alibaba. In Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data. 1-4.\n\n. Heng-Tze, Levent Cheng, Jeremiah Koc, Tal Harmsen, Tushar Shaked, Hrishi Chandra, Glen Aradhye, Greg Anderson, Wei Corrado, Mustafa Chai, Ispir, Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al.\n\nWide & deep learning for recommender systems. Proceedings of the 1st workshop on deep learning for recommender systems. the 1st workshop on deep learning for recommender systemsWide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. 7-10.\n\n2017. metapath2vec: Scalable representation learning for heterogeneous networks. Yuxiao Dong, V Nitesh, Ananthram Chawla, Swami, Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. the 23rd ACM SIGKDD international conference on knowledge discovery and data miningYuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable representation learning for heterogeneous networks. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 135-144.\n\nATBRG: Adaptive Target-Behavior Relational Graph Network for Effective Recommendation. Yufei Feng, Binbin Hu, Fuyu Lv, Qingwen Liu, Zhiqiang Zhang, Wenwu Ou, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 43rd International ACM SIGIR Conference on Research and Development in Information RetrievalYufei Feng, Binbin Hu, Fuyu Lv, Qingwen Liu, Zhiqiang Zhang, and Wenwu Ou. 2020. ATBRG: Adaptive Target-Behavior Relational Graph Network for Effective Recommendation. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2231-2240.\n\nOptimal resource allocation using reinforcement learning for IoT content-centric services. Keke Gai, Meikang Qiu, Applied Soft Computing. 70Keke Gai and Meikang Qiu. 2018. Optimal resource allocation using reinforcement learning for IoT content-centric services. Applied Soft Computing 70 (2018), 12- 21.\n\nChen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, Fuli Feng, Yong Li, 10.1109/ICDE.2019.00140Tat-Seng Chua, and Depeng Jin. 2019. Neural Multi-task Recommendation from Multibehavior Data. 2019 IEEE 35th International Conference on Data Engineering (ICDEChen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, Fuli Feng, Yong Li, Tat- Seng Chua, and Depeng Jin. 2019. Neural Multi-task Recommendation from Multi- behavior Data. In 2019 IEEE 35th International Conference on Data Engineering (ICDE). 1554-1557. https://doi.org/10.1109/ICDE.2019.00140\n\nGraph u-nets. Hongyang Gao, Shuiwang Ji, PMLRinternational conference on machine learning. Hongyang Gao and Shuiwang Ji. 2019. Graph u-nets. In international conference on machine learning. PMLR, 2083-2092.\n\nnode2vec: Scalable feature learning for networks. Aditya Grover, Jure Leskovec, Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on Knowledge discovery and data miningAditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 855-864.\n\nDeepFM: A Factorization-Machine Based Neural Network for CTR Prediction. Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, Xiuqiang He, Proceedings of the 26th International Joint Conference on Artificial Intelligence. the 26th International Joint Conference on Artificial IntelligenceMelbourne, AustraliaAAAI PressHuifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine Based Neural Network for CTR Prediction. In Proceedings of the 26th International Joint Conference on Artificial Intelligence (Melbourne, Australia) (IJCAI'17). AAAI Press, 1725-1731.\n\nRex William L Hamilton, Jure Ying, Leskovec, arXiv:1706.02216Inductive representation learning on large graphs. arXiv preprintWilliam L Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. arXiv preprint arXiv:1706.02216 (2017).\n\nPromotion recommendation method and system based on random forest. Wan-Hsun Hu, Shih-Hsien Tang, Yin-Che Chen, Proceedings of the 5th Multidisciplinary International Social Networks Conference. the 5th Multidisciplinary International Social Networks ConferenceWan-Hsun Hu, Shih-Hsien Tang, Yin-Che Chen, et al. 2018. Promotion recom- mendation method and system based on random forest. In Proceedings of the 5th Multidisciplinary International Social Networks Conference. 1-5.\n\nMultibehavior recommendation with graph convolutional networks. Chen Bowen Jin, Xiangnan Gao, Depeng He, Yong Jin, Li, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 43rd International ACM SIGIR Conference on Research and Development in Information RetrievalBowen Jin, Chen Gao, Xiangnan He, Depeng Jin, and Yong Li. 2020. Multi- behavior recommendation with graph convolutional networks. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 659-668.\n\nLightgbm: A highly efficient gradient boosting decision tree. Advances in neural information processing systems. Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, 30Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, et al. 2017. Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural information processing systems 30 (2017), 3146-3154.\n\nThe multiple-choice knapsack problem. Hans Kellerer, Ulrich Pferschy, David Pisinger, Knapsack Problems. SpringerHans Kellerer, Ulrich Pferschy, and David Pisinger. 2004. The multiple-choice knapsack problem. In Knapsack Problems. Springer, 317-347.\n\nSemi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, arXiv:1609.02907arXiv preprintThomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).\n\nSpending Money Wisely: Online Electronic Coupon Allocation based on Real-Time User Intent Detection. Liangwei Li, Liucheng Sun, Chenwei Weng, Chengfu Huo, Weijun Ren, Proceedings of the 29th ACM International Conference on Information & Knowledge Management. the 29th ACM International Conference on Information & Knowledge ManagementLiangwei Li, Liucheng Sun, Chenwei Weng, Chengfu Huo, and Weijun Ren. 2020. Spending Money Wisely: Online Electronic Coupon Allocation based on Real-Time User Intent Detection. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2597-2604.\n\nYujia Li, Daniel Tarlow, Marc Brockschmidt, Richard Zemel, arXiv:1511.05493Gated graph sequence neural networks. arXiv preprintYujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2015. Gated graph sequence neural networks. arXiv preprint arXiv:1511.05493 (2015).\n\nModeling task relationships in multi-task learning with multi-gate mixture-ofexperts. Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, Ed H Chi, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningJiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. 2018. Modeling task relationships in multi-task learning with multi-gate mixture-of- experts. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 1930-1939.\n\nAd Click Prediction: A View from the Trenches. H , Brendan Mcmahan, Gary Holt, D Sculley, Michael Young, Dietmar Ebner, 10.1145/2487575.2488200Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningChicago, Illinois, USA; New York, NY, USAAssociation for Computing MachineryKDD '13)H. Brendan McMahan, Gary Holt, D. Sculley, Michael Young, Dietmar Ebner, et al. 2013. Ad Click Prediction: A View from the Trenches. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Chicago, Illinois, USA) (KDD '13). Association for Computing Machinery, New York, NY, USA, 1222-1230. https://doi.org/10.1145/2487575.2488200\n\nWeisfeiler and leman go neural: Higher-order graph neural networks. Christopher Morris, Martin Ritzert, Matthias Fey, L William, Jan Eric Hamilton, Gaurav Lenssen, Martin Rattan, Grohe, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence33Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan Eric Lenssen, Gaurav Rattan, and Martin Grohe. 2019. Weisfeiler and leman go neural: Higher-order graph neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 4602-4609.\n\nA Dual Heterogeneous Graph Attention Network to Improve Long-Tail Performance for Shop Search in E-Commerce. Xichuan Niu, Bofang Li, Chenliang Li, Rong Xiao, Haochuan Sun, Hongbo Deng, Zhenzhong Chen, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningXichuan Niu, Bofang Li, Chenliang Li, Rong Xiao, Haochuan Sun, Hongbo Deng, and Zhenzhong Chen. 2020. A Dual Heterogeneous Graph Attention Network to Improve Long-Tail Performance for Shop Search in E-Commerce. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 3405-3415.\n\nDeepwalk: Online learning of social representations. Bryan Perozzi, Rami Al-Rfou, Steven Skiena, Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. the 20th ACM SIGKDD international conference on Knowledge discovery and data miningBryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 701-710.\n\nBillion-scale Recommendation with Heterogeneous Side Information at Taobao. Andreas Pfadler, Huan Zhao, Jizhe Wang, Lifeng Wang, Pipei Huang, Dik Lun Lee, 2020 IEEE 36th International Conference on Data Engineering (ICDE). IEEEAndreas Pfadler, Huan Zhao, Jizhe Wang, Lifeng Wang, Pipei Huang, and Dik Lun Lee. 2020. Billion-scale Recommendation with Heterogeneous Side Information at Taobao. In 2020 IEEE 36th International Conference on Data Engineering (ICDE). IEEE, 1667-1676.\n\nPrediction of O2O Coupon Usage Based on XGBoost Model. Shi Qiongyu, 2020 The 11th International Conference on E-business, Management and Economics. Shi Qiongyu. 2020. Prediction of O2O Coupon Usage Based on XGBoost Model. In 2020 The 11th International Conference on E-business, Management and Economics. 33-36.\n\nVisualizing Data using t-SNE. Laurens Van Der Maaten, Geoffrey Hinton, Journal of Machine Learning Research. 9Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing Data using t-SNE. Journal of Machine Learning Research 9 (2008), 2579-2605. http://www. jmlr.org/papers/v9/vandermaaten08a.html\n\nMeta-prod2vec: Product embeddings using side-information for recommendation. Flavian Vasile, Elena Smirnova, Alexis Conneau, Proceedings of the 10th ACM Conference on Recommender Systems. the 10th ACM Conference on Recommender SystemsFlavian Vasile, Elena Smirnova, and Alexis Conneau. 2016. Meta-prod2vec: Product embeddings using side-information for recommendation. In Proceedings of the 10th ACM Conference on Recommender Systems. 225-232.\n\nPetar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, arXiv:1710.10903Graph Attention Networks. stat.MLPetar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, et al. 2018. Graph Attention Networks. arXiv:1710.10903 [stat.ML]\n\nDeep & cross network for ad click predictions. Ruoxi Wang, Bin Fu, Gang Fu, Mingliang Wang, Proceedings of the ADKDD'17. the ADKDD'17Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & cross network for ad click predictions. In Proceedings of the ADKDD'17. 1-7.\n\nEntire space multi-task modeling via post-click behavior decomposition for conversion rate prediction. Hong Wen, Jing Zhang, Yuan Wang, Fuyu Lv, Wentian Bao, Quan Lin, Keping Yang, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 43rd International ACM SIGIR Conference on Research and Development in Information RetrievalHong Wen, Jing Zhang, Yuan Wang, Fuyu Lv, Wentian Bao, Quan Lin, and Keping Yang. 2020. Entire space multi-task modeling via post-click behavior decom- position for conversion rate prediction. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2377-2386.\n\nMultiplex Behavioral Relation Learning for Recommendation via Memory Augmented Transformer Network. Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Bo Zhang, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 43rd International ACM SIGIR Conference on Research and Development in Information RetrievalLianghao Xia, Chao Huang, Yong Xu, Peng Dai, Bo Zhang, et al. 2020. Multi- plex Behavioral Relation Learning for Recommendation via Memory Augmented Transformer Network. In Proceedings of the 43rd International ACM SIGIR Confer- ence on Research and Development in Information Retrieval. 2397-2406.\n\nDeep Interest with Hierarchical Attention Network for Click-Through Rate Prediction. Weinan Xu, Hengxu He, Minshi Tan, Yunming Li, Jun Lang, Dongbai Guo, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 43rd International ACM SIGIR Conference on Research and Development in Information RetrievalWeinan Xu, Hengxu He, Minshi Tan, Yunming Li, Jun Lang, and Dongbai Guo. 2020. Deep Interest with Hierarchical Attention Network for Click-Through Rate Prediction. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 1905-1908.\n\nCoupled group lasso for web-scale ctr prediction in display advertising. Ling Yan, Gui-Rong Wu-Jun Li, Dingyi Xue, Han, PMLRInternational Conference on Machine Learning. Ling Yan, Wu-jun Li, Gui-Rong Xue, and Dingyi Han. 2014. Coupled group lasso for web-scale ctr prediction in display advertising. In International Conference on Machine Learning. PMLR, 802-810.\n\nDeep interest evolution network for click-through rate prediction. Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence33Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, et al. 2019. Deep interest evolution network for click-through rate prediction. In Proceedings of the AAAI conference on artificial intelligence, Vol. 33. 5941-5948.\n\nDeep interest network for click-through rate prediction. Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, Kun Gai, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningGuorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 1059-1068.\n", "annotations": {"author": "[{\"end\":271,\"start\":138},{\"end\":373,\"start\":272},{\"end\":478,\"start\":374},{\"end\":608,\"start\":479},{\"end\":742,\"start\":609},{\"end\":846,\"start\":743},{\"end\":950,\"start\":847},{\"end\":1059,\"start\":951},{\"end\":1161,\"start\":1060},{\"end\":1266,\"start\":1162},{\"end\":1373,\"start\":1267},{\"end\":1482,\"start\":1374},{\"end\":1586,\"start\":1483},{\"end\":1690,\"start\":1587}]", "publisher": "[{\"end\":95,\"start\":82},{\"end\":1799,\"start\":1786}]", "author_last_name": "[{\"end\":151,\"start\":147},{\"end\":278,\"start\":276},{\"end\":383,\"start\":381},{\"end\":490,\"start\":486},{\"end\":622,\"start\":618},{\"end\":751,\"start\":747},{\"end\":855,\"start\":851},{\"end\":964,\"start\":960},{\"end\":1066,\"start\":1064},{\"end\":1171,\"start\":1169},{\"end\":1278,\"start\":1274},{\"end\":1387,\"start\":1383},{\"end\":1491,\"start\":1487},{\"end\":1595,\"start\":1591}]", "author_first_name": "[{\"end\":146,\"start\":138},{\"end\":275,\"start\":272},{\"end\":380,\"start\":374},{\"end\":485,\"start\":479},{\"end\":617,\"start\":609},{\"end\":746,\"start\":743},{\"end\":850,\"start\":847},{\"end\":959,\"start\":951},{\"end\":1063,\"start\":1060},{\"end\":1168,\"start\":1162},{\"end\":1273,\"start\":1267},{\"end\":1382,\"start\":1374},{\"end\":1486,\"start\":1483},{\"end\":1590,\"start\":1587}]", "author_affiliation": "[{\"end\":270,\"start\":178},{\"end\":372,\"start\":280},{\"end\":477,\"start\":385},{\"end\":607,\"start\":515},{\"end\":741,\"start\":649},{\"end\":845,\"start\":753},{\"end\":949,\"start\":857},{\"end\":1058,\"start\":966},{\"end\":1160,\"start\":1068},{\"end\":1265,\"start\":1173},{\"end\":1372,\"start\":1280},{\"end\":1481,\"start\":1389},{\"end\":1585,\"start\":1493},{\"end\":1689,\"start\":1597}]", "title": "[{\"end\":81,\"start\":1},{\"end\":1771,\"start\":1691}]", "venue": "[{\"end\":1776,\"start\":1773}]", "abstract": "[{\"end\":3978,\"start\":2496}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6018,\"start\":6014},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6021,\"start\":6018},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":6024,\"start\":6021},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6207,\"start\":6204},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":6210,\"start\":6207},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8999,\"start\":8995},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9159,\"start\":9155},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9779,\"start\":9775},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9857,\"start\":9854},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9903,\"start\":9900},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9951,\"start\":9948},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10285,\"start\":10282},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10327,\"start\":10323},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10490,\"start\":10486},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":10535,\"start\":10531},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10584,\"start\":10580},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":10616,\"start\":10612},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":10660,\"start\":10657},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11154,\"start\":11151},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":11157,\"start\":11154},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11292,\"start\":11288},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12185,\"start\":12182},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12188,\"start\":12185},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":12230,\"start\":12227},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":12233,\"start\":12230},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":12267,\"start\":12263},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12664,\"start\":12660},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12679,\"start\":12675},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12700,\"start\":12697},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12915,\"start\":12911},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12931,\"start\":12927},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":12968,\"start\":12964},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13009,\"start\":13005},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":13053,\"start\":13049},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":13208,\"start\":13204},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13324,\"start\":13321},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13406,\"start\":13403},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15659,\"start\":15658},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":18100,\"start\":18096},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20252,\"start\":20248},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":20255,\"start\":20252},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":20258,\"start\":20255},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":23136,\"start\":23132},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":24957,\"start\":24953},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":27530,\"start\":27526},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":28410,\"start\":28406},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":28413,\"start\":28410},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":28839,\"start\":28835},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":29064,\"start\":29060},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":33886,\"start\":33882}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36315,\"start\":36226},{\"attributes\":{\"id\":\"fig_1\"},\"end\":36561,\"start\":36316},{\"attributes\":{\"id\":\"fig_2\"},\"end\":36639,\"start\":36562},{\"attributes\":{\"id\":\"fig_3\"},\"end\":37092,\"start\":36640},{\"attributes\":{\"id\":\"fig_4\"},\"end\":37193,\"start\":37093},{\"attributes\":{\"id\":\"fig_5\"},\"end\":37879,\"start\":37194},{\"attributes\":{\"id\":\"fig_6\"},\"end\":38336,\"start\":37880},{\"attributes\":{\"id\":\"fig_7\"},\"end\":38410,\"start\":38337},{\"attributes\":{\"id\":\"fig_8\"},\"end\":38622,\"start\":38411},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":39793,\"start\":38623},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40071,\"start\":39794},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41616,\"start\":40072},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":42257,\"start\":41617},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42617,\"start\":42258}]", "paragraph": "[{\"end\":5426,\"start\":3994},{\"end\":5977,\"start\":5428},{\"end\":7275,\"start\":5979},{\"end\":8407,\"start\":7277},{\"end\":8461,\"start\":8409},{\"end\":8643,\"start\":8463},{\"end\":10027,\"start\":8686},{\"end\":11822,\"start\":10061},{\"end\":12477,\"start\":11824},{\"end\":13524,\"start\":12516},{\"end\":13956,\"start\":13540},{\"end\":14886,\"start\":13974},{\"end\":15089,\"start\":14888},{\"end\":16438,\"start\":15127},{\"end\":17462,\"start\":16461},{\"end\":17852,\"start\":17464},{\"end\":18342,\"start\":17880},{\"end\":18813,\"start\":18403},{\"end\":19097,\"start\":18815},{\"end\":19421,\"start\":19110},{\"end\":19523,\"start\":19453},{\"end\":19846,\"start\":19525},{\"end\":20174,\"start\":19873},{\"end\":20842,\"start\":20184},{\"end\":21431,\"start\":20852},{\"end\":21775,\"start\":21433},{\"end\":22045,\"start\":21799},{\"end\":22419,\"start\":22047},{\"end\":22673,\"start\":22421},{\"end\":23159,\"start\":22713},{\"end\":23749,\"start\":23202},{\"end\":24164,\"start\":23751},{\"end\":24455,\"start\":24182},{\"end\":25080,\"start\":24497},{\"end\":25310,\"start\":25108},{\"end\":25357,\"start\":25322},{\"end\":27354,\"start\":25385},{\"end\":27521,\"start\":27374},{\"end\":27872,\"start\":27523},{\"end\":28329,\"start\":27895},{\"end\":28447,\"start\":28331},{\"end\":29367,\"start\":28513},{\"end\":29545,\"start\":29395},{\"end\":30205,\"start\":29547},{\"end\":30521,\"start\":30207},{\"end\":30613,\"start\":30545},{\"end\":30774,\"start\":30615},{\"end\":30990,\"start\":30798},{\"end\":31126,\"start\":30992},{\"end\":32257,\"start\":31171},{\"end\":33566,\"start\":32294},{\"end\":34735,\"start\":33613},{\"end\":35648,\"start\":34766},{\"end\":36225,\"start\":35650}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":18402,\"start\":18343},{\"attributes\":{\"id\":\"formula_1\"},\"end\":19109,\"start\":19098},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19452,\"start\":19422},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19858,\"start\":19847},{\"attributes\":{\"id\":\"formula_4\"},\"end\":19872,\"start\":19858},{\"attributes\":{\"id\":\"formula_5\"},\"end\":21798,\"start\":21776},{\"attributes\":{\"id\":\"formula_6\"},\"end\":23201,\"start\":23160},{\"attributes\":{\"id\":\"formula_7\"},\"end\":24496,\"start\":24456},{\"attributes\":{\"id\":\"formula_8\"},\"end\":25107,\"start\":25081},{\"attributes\":{\"id\":\"formula_9\"},\"end\":25321,\"start\":25311},{\"attributes\":{\"id\":\"formula_10\"},\"end\":28485,\"start\":28448}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":6916,\"start\":6909},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":27246,\"start\":27239},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30063,\"start\":30056},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30576,\"start\":30569},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30989,\"start\":30982},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":31512,\"start\":31505},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":31551,\"start\":31544}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":3992,\"start\":3980},{\"attributes\":{\"n\":\"2\"},\"end\":8684,\"start\":8646},{\"attributes\":{\"n\":\"2.2\"},\"end\":10059,\"start\":10030},{\"attributes\":{\"n\":\"2.3\"},\"end\":12514,\"start\":12480},{\"attributes\":{\"n\":\"3\"},\"end\":13538,\"start\":13527},{\"attributes\":{\"n\":\"3.1\"},\"end\":13972,\"start\":13959},{\"attributes\":{\"n\":\"3.2\"},\"end\":15125,\"start\":15092},{\"attributes\":{\"n\":\"3.3\"},\"end\":16459,\"start\":16441},{\"attributes\":{\"n\":\"3.4\"},\"end\":17878,\"start\":17855},{\"end\":20182,\"start\":20177},{\"end\":20850,\"start\":20845},{\"attributes\":{\"n\":\"3.5\"},\"end\":22711,\"start\":22676},{\"attributes\":{\"n\":\"3.6\"},\"end\":24180,\"start\":24167},{\"attributes\":{\"n\":\"4\"},\"end\":25383,\"start\":25360},{\"attributes\":{\"n\":\"4.2\"},\"end\":27372,\"start\":27357},{\"attributes\":{\"n\":\"4.3\"},\"end\":27893,\"start\":27875},{\"attributes\":{\"n\":\"4.4\"},\"end\":28511,\"start\":28487},{\"attributes\":{\"n\":\"5\"},\"end\":29393,\"start\":29370},{\"attributes\":{\"n\":\"5.1\"},\"end\":30543,\"start\":30524},{\"attributes\":{\"n\":\"5.2\"},\"end\":30796,\"start\":30777},{\"attributes\":{\"n\":\"5.3\"},\"end\":31169,\"start\":31129},{\"attributes\":{\"n\":\"5.4\"},\"end\":32292,\"start\":32260},{\"attributes\":{\"n\":\"5.5\"},\"end\":33611,\"start\":33569},{\"attributes\":{\"n\":\"6\"},\"end\":34764,\"start\":34738},{\"end\":36237,\"start\":36227},{\"end\":36327,\"start\":36317},{\"end\":36651,\"start\":36641},{\"end\":37882,\"start\":37881},{\"end\":38348,\"start\":38338},{\"end\":38422,\"start\":38412},{\"end\":38633,\"start\":38624},{\"end\":39804,\"start\":39795},{\"end\":40082,\"start\":40073},{\"end\":42268,\"start\":42259}]", "table": "[{\"end\":39793,\"start\":38799},{\"end\":40071,\"start\":39858},{\"end\":41616,\"start\":40279},{\"end\":42617,\"start\":42374}]", "figure_caption": "[{\"end\":36315,\"start\":36239},{\"end\":36561,\"start\":36329},{\"end\":36639,\"start\":36564},{\"end\":37092,\"start\":36653},{\"end\":37193,\"start\":37095},{\"end\":37879,\"start\":37196},{\"end\":38336,\"start\":37883},{\"end\":38410,\"start\":38350},{\"end\":38622,\"start\":38424},{\"end\":38799,\"start\":38635},{\"end\":39858,\"start\":39806},{\"end\":40279,\"start\":40084},{\"end\":42257,\"start\":41619},{\"end\":42374,\"start\":42270}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4690,\"start\":4684},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15942,\"start\":15936},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16514,\"start\":16508},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23420,\"start\":23414},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":32488,\"start\":32482},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":32785,\"start\":32779},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":33906,\"start\":33900},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":34629,\"start\":34623}]", "bib_author_first_name": "[{\"end\":43058,\"start\":43052},{\"end\":43384,\"start\":43377},{\"end\":43394,\"start\":43390},{\"end\":43403,\"start\":43400},{\"end\":43417,\"start\":43408},{\"end\":43427,\"start\":43423},{\"end\":43439,\"start\":43433},{\"end\":43990,\"start\":43981},{\"end\":44011,\"start\":44004},{\"end\":44023,\"start\":44018},{\"end\":44322,\"start\":44321},{\"end\":44332,\"start\":44329},{\"end\":44348,\"start\":44340},{\"end\":44357,\"start\":44356},{\"end\":44367,\"start\":44362},{\"end\":44381,\"start\":44373},{\"end\":44650,\"start\":44645},{\"end\":44661,\"start\":44657},{\"end\":44671,\"start\":44668},{\"end\":45120,\"start\":45114},{\"end\":45136,\"start\":45128},{\"end\":45145,\"start\":45142},{\"end\":45161,\"start\":45155},{\"end\":45176,\"start\":45170},{\"end\":45190,\"start\":45186},{\"end\":45204,\"start\":45200},{\"end\":45218,\"start\":45215},{\"end\":45235,\"start\":45228},{\"end\":45795,\"start\":45789},{\"end\":45803,\"start\":45802},{\"end\":45821,\"start\":45812},{\"end\":46357,\"start\":46352},{\"end\":46370,\"start\":46364},{\"end\":46379,\"start\":46375},{\"end\":46391,\"start\":46384},{\"end\":46405,\"start\":46397},{\"end\":46418,\"start\":46413},{\"end\":47023,\"start\":47019},{\"end\":47036,\"start\":47029},{\"end\":47238,\"start\":47234},{\"end\":47252,\"start\":47244},{\"end\":47262,\"start\":47257},{\"end\":47277,\"start\":47268},{\"end\":47288,\"start\":47284},{\"end\":47299,\"start\":47295},{\"end\":47800,\"start\":47792},{\"end\":47814,\"start\":47806},{\"end\":48042,\"start\":48036},{\"end\":48055,\"start\":48051},{\"end\":48531,\"start\":48524},{\"end\":48544,\"start\":48537},{\"end\":48558,\"start\":48551},{\"end\":48570,\"start\":48563},{\"end\":48583,\"start\":48575},{\"end\":49061,\"start\":49058},{\"end\":49086,\"start\":49082},{\"end\":49406,\"start\":49398},{\"end\":49421,\"start\":49411},{\"end\":49435,\"start\":49428},{\"end\":49877,\"start\":49873},{\"end\":49897,\"start\":49889},{\"end\":49909,\"start\":49903},{\"end\":49918,\"start\":49914},{\"end\":50513,\"start\":50507},{\"end\":50520,\"start\":50518},{\"end\":50533,\"start\":50527},{\"end\":50549,\"start\":50542},{\"end\":50559,\"start\":50556},{\"end\":50573,\"start\":50566},{\"end\":50841,\"start\":50837},{\"end\":50858,\"start\":50852},{\"end\":50874,\"start\":50869},{\"end\":51117,\"start\":51116},{\"end\":51129,\"start\":51126},{\"end\":51428,\"start\":51420},{\"end\":51441,\"start\":51433},{\"end\":51454,\"start\":51447},{\"end\":51468,\"start\":51461},{\"end\":51480,\"start\":51474},{\"end\":51942,\"start\":51937},{\"end\":51953,\"start\":51947},{\"end\":51966,\"start\":51962},{\"end\":51988,\"start\":51981},{\"end\":52303,\"start\":52298},{\"end\":52311,\"start\":52308},{\"end\":52325,\"start\":52318},{\"end\":52335,\"start\":52330},{\"end\":52348,\"start\":52342},{\"end\":52357,\"start\":52355},{\"end\":52359,\"start\":52358},{\"end\":52870,\"start\":52869},{\"end\":52880,\"start\":52873},{\"end\":52894,\"start\":52890},{\"end\":52902,\"start\":52901},{\"end\":52919,\"start\":52912},{\"end\":52934,\"start\":52927},{\"end\":53690,\"start\":53679},{\"end\":53705,\"start\":53699},{\"end\":53723,\"start\":53715},{\"end\":53730,\"start\":53729},{\"end\":53743,\"start\":53740},{\"end\":53748,\"start\":53744},{\"end\":53765,\"start\":53759},{\"end\":53781,\"start\":53775},{\"end\":54306,\"start\":54299},{\"end\":54318,\"start\":54312},{\"end\":54332,\"start\":54323},{\"end\":54341,\"start\":54337},{\"end\":54356,\"start\":54348},{\"end\":54368,\"start\":54362},{\"end\":54384,\"start\":54375},{\"end\":54952,\"start\":54947},{\"end\":54966,\"start\":54962},{\"end\":54982,\"start\":54976},{\"end\":55477,\"start\":55470},{\"end\":55491,\"start\":55487},{\"end\":55503,\"start\":55498},{\"end\":55516,\"start\":55510},{\"end\":55528,\"start\":55523},{\"end\":55543,\"start\":55536},{\"end\":56225,\"start\":56218},{\"end\":56250,\"start\":56242},{\"end\":56573,\"start\":56566},{\"end\":56587,\"start\":56582},{\"end\":56604,\"start\":56598},{\"end\":56939,\"start\":56934},{\"end\":56959,\"start\":56952},{\"end\":56977,\"start\":56970},{\"end\":56995,\"start\":56988},{\"end\":57242,\"start\":57237},{\"end\":57252,\"start\":57249},{\"end\":57261,\"start\":57257},{\"end\":57275,\"start\":57266},{\"end\":57570,\"start\":57566},{\"end\":57580,\"start\":57576},{\"end\":57592,\"start\":57588},{\"end\":57603,\"start\":57599},{\"end\":57615,\"start\":57608},{\"end\":57625,\"start\":57621},{\"end\":57637,\"start\":57631},{\"end\":58282,\"start\":58274},{\"end\":58292,\"start\":58288},{\"end\":58304,\"start\":58300},{\"end\":58313,\"start\":58309},{\"end\":58321,\"start\":58319},{\"end\":58929,\"start\":58923},{\"end\":58940,\"start\":58934},{\"end\":58951,\"start\":58945},{\"end\":58964,\"start\":58957},{\"end\":58972,\"start\":58969},{\"end\":58986,\"start\":58979},{\"end\":59570,\"start\":59566},{\"end\":59584,\"start\":59576},{\"end\":59602,\"start\":59596},{\"end\":59931,\"start\":59925},{\"end\":59940,\"start\":59938},{\"end\":59950,\"start\":59946},{\"end\":59958,\"start\":59956},{\"end\":59969,\"start\":59963},{\"end\":59981,\"start\":59976},{\"end\":60392,\"start\":60386},{\"end\":60408,\"start\":60399},{\"end\":60420,\"start\":60414},{\"end\":60431,\"start\":60427},{\"end\":60440,\"start\":60437},{\"end\":60450,\"start\":60446},{\"end\":60462,\"start\":60455},{\"end\":60473,\"start\":60468},{\"end\":60482,\"start\":60479},{\"end\":60490,\"start\":60487}]", "bib_author_last_name": "[{\"end\":43066,\"start\":43059},{\"end\":43084,\"start\":43068},{\"end\":43388,\"start\":43385},{\"end\":43398,\"start\":43395},{\"end\":43406,\"start\":43404},{\"end\":43421,\"start\":43418},{\"end\":43431,\"start\":43428},{\"end\":43444,\"start\":43440},{\"end\":44002,\"start\":43991},{\"end\":44016,\"start\":44012},{\"end\":44030,\"start\":44024},{\"end\":44327,\"start\":44323},{\"end\":44338,\"start\":44333},{\"end\":44354,\"start\":44349},{\"end\":44360,\"start\":44358},{\"end\":44371,\"start\":44368},{\"end\":44384,\"start\":44382},{\"end\":44655,\"start\":44651},{\"end\":44666,\"start\":44662},{\"end\":44674,\"start\":44672},{\"end\":45112,\"start\":45104},{\"end\":45126,\"start\":45121},{\"end\":45140,\"start\":45137},{\"end\":45153,\"start\":45146},{\"end\":45168,\"start\":45162},{\"end\":45184,\"start\":45177},{\"end\":45198,\"start\":45191},{\"end\":45213,\"start\":45205},{\"end\":45226,\"start\":45219},{\"end\":45240,\"start\":45236},{\"end\":45247,\"start\":45242},{\"end\":45800,\"start\":45796},{\"end\":45810,\"start\":45804},{\"end\":45828,\"start\":45822},{\"end\":45835,\"start\":45830},{\"end\":46362,\"start\":46358},{\"end\":46373,\"start\":46371},{\"end\":46382,\"start\":46380},{\"end\":46395,\"start\":46392},{\"end\":46411,\"start\":46406},{\"end\":46421,\"start\":46419},{\"end\":47027,\"start\":47024},{\"end\":47040,\"start\":47037},{\"end\":47242,\"start\":47239},{\"end\":47255,\"start\":47253},{\"end\":47266,\"start\":47263},{\"end\":47282,\"start\":47278},{\"end\":47293,\"start\":47289},{\"end\":47302,\"start\":47300},{\"end\":47804,\"start\":47801},{\"end\":47817,\"start\":47815},{\"end\":48049,\"start\":48043},{\"end\":48064,\"start\":48056},{\"end\":48535,\"start\":48532},{\"end\":48549,\"start\":48545},{\"end\":48561,\"start\":48559},{\"end\":48573,\"start\":48571},{\"end\":48586,\"start\":48584},{\"end\":49080,\"start\":49062},{\"end\":49091,\"start\":49087},{\"end\":49101,\"start\":49093},{\"end\":49409,\"start\":49407},{\"end\":49426,\"start\":49422},{\"end\":49440,\"start\":49436},{\"end\":49887,\"start\":49878},{\"end\":49901,\"start\":49898},{\"end\":49912,\"start\":49910},{\"end\":49922,\"start\":49919},{\"end\":49926,\"start\":49924},{\"end\":50516,\"start\":50514},{\"end\":50525,\"start\":50521},{\"end\":50540,\"start\":50534},{\"end\":50554,\"start\":50550},{\"end\":50564,\"start\":50560},{\"end\":50576,\"start\":50574},{\"end\":50850,\"start\":50842},{\"end\":50867,\"start\":50859},{\"end\":50883,\"start\":50875},{\"end\":51124,\"start\":51118},{\"end\":51134,\"start\":51130},{\"end\":51143,\"start\":51136},{\"end\":51431,\"start\":51429},{\"end\":51445,\"start\":51442},{\"end\":51459,\"start\":51455},{\"end\":51472,\"start\":51469},{\"end\":51484,\"start\":51481},{\"end\":51945,\"start\":51943},{\"end\":51960,\"start\":51954},{\"end\":51979,\"start\":51967},{\"end\":51994,\"start\":51989},{\"end\":52306,\"start\":52304},{\"end\":52316,\"start\":52312},{\"end\":52328,\"start\":52326},{\"end\":52340,\"start\":52336},{\"end\":52353,\"start\":52349},{\"end\":52363,\"start\":52360},{\"end\":52888,\"start\":52881},{\"end\":52899,\"start\":52895},{\"end\":52910,\"start\":52903},{\"end\":52925,\"start\":52920},{\"end\":52940,\"start\":52935},{\"end\":53697,\"start\":53691},{\"end\":53713,\"start\":53706},{\"end\":53727,\"start\":53724},{\"end\":53738,\"start\":53731},{\"end\":53757,\"start\":53749},{\"end\":53773,\"start\":53766},{\"end\":53788,\"start\":53782},{\"end\":53795,\"start\":53790},{\"end\":54310,\"start\":54307},{\"end\":54321,\"start\":54319},{\"end\":54335,\"start\":54333},{\"end\":54346,\"start\":54342},{\"end\":54360,\"start\":54357},{\"end\":54373,\"start\":54369},{\"end\":54389,\"start\":54385},{\"end\":54960,\"start\":54953},{\"end\":54974,\"start\":54967},{\"end\":54989,\"start\":54983},{\"end\":55485,\"start\":55478},{\"end\":55496,\"start\":55492},{\"end\":55508,\"start\":55504},{\"end\":55521,\"start\":55517},{\"end\":55534,\"start\":55529},{\"end\":55547,\"start\":55544},{\"end\":55941,\"start\":55930},{\"end\":56240,\"start\":56226},{\"end\":56257,\"start\":56251},{\"end\":56580,\"start\":56574},{\"end\":56596,\"start\":56588},{\"end\":56612,\"start\":56605},{\"end\":56950,\"start\":56940},{\"end\":56968,\"start\":56960},{\"end\":56986,\"start\":56978},{\"end\":57002,\"start\":56996},{\"end\":57247,\"start\":57243},{\"end\":57255,\"start\":57253},{\"end\":57264,\"start\":57262},{\"end\":57280,\"start\":57276},{\"end\":57574,\"start\":57571},{\"end\":57586,\"start\":57581},{\"end\":57597,\"start\":57593},{\"end\":57606,\"start\":57604},{\"end\":57619,\"start\":57616},{\"end\":57629,\"start\":57626},{\"end\":57642,\"start\":57638},{\"end\":58286,\"start\":58283},{\"end\":58298,\"start\":58293},{\"end\":58307,\"start\":58305},{\"end\":58317,\"start\":58314},{\"end\":58327,\"start\":58322},{\"end\":58932,\"start\":58930},{\"end\":58943,\"start\":58941},{\"end\":58955,\"start\":58952},{\"end\":58967,\"start\":58965},{\"end\":58977,\"start\":58973},{\"end\":58990,\"start\":58987},{\"end\":59574,\"start\":59571},{\"end\":59594,\"start\":59585},{\"end\":59606,\"start\":59603},{\"end\":59611,\"start\":59608},{\"end\":59936,\"start\":59932},{\"end\":59944,\"start\":59941},{\"end\":59954,\"start\":59951},{\"end\":59961,\"start\":59959},{\"end\":59974,\"start\":59970},{\"end\":59986,\"start\":59982},{\"end\":60397,\"start\":60393},{\"end\":60412,\"start\":60409},{\"end\":60425,\"start\":60421},{\"end\":60435,\"start\":60432},{\"end\":60444,\"start\":60441},{\"end\":60453,\"start\":60451},{\"end\":60466,\"start\":60463},{\"end\":60477,\"start\":60474},{\"end\":60485,\"start\":60483},{\"end\":60494,\"start\":60491}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1507.06738\",\"id\":\"b0\"},\"end\":43282,\"start\":43052},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":220730039},\"end\":43953,\"start\":43284},{\"attributes\":{\"id\":\"b2\"},\"end\":44225,\"start\":43955},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":208284469},\"end\":44571,\"start\":44227},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":155099871},\"end\":45100,\"start\":44573},{\"attributes\":{\"id\":\"b5\"},\"end\":45399,\"start\":45102},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3352400},\"end\":45706,\"start\":45401},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":3919301},\"end\":46263,\"start\":45708},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":218870350},\"end\":46926,\"start\":46265},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":52815979},\"end\":47232,\"start\":46928},{\"attributes\":{\"doi\":\"10.1109/ICDE.2019.00140\",\"id\":\"b10\"},\"end\":47776,\"start\":47234},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b11\",\"matched_paper_id\":153311899},\"end\":47984,\"start\":47778},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":207238980},\"end\":48449,\"start\":47986},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":970388},\"end\":49056,\"start\":48451},{\"attributes\":{\"doi\":\"arXiv:1706.02216\",\"id\":\"b14\"},\"end\":49329,\"start\":49058},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":51868185},\"end\":49807,\"start\":49331},{\"attributes\":{\"id\":\"b16\"},\"end\":50392,\"start\":49809},{\"attributes\":{\"id\":\"b17\"},\"end\":50797,\"start\":50394},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":15330118},\"end\":51048,\"start\":50799},{\"attributes\":{\"doi\":\"arXiv:1609.02907\",\"id\":\"b19\"},\"end\":51317,\"start\":51050},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":221266474},\"end\":51935,\"start\":51319},{\"attributes\":{\"doi\":\"arXiv:1511.05493\",\"id\":\"b21\"},\"end\":52210,\"start\":51937},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":50770252},\"end\":52820,\"start\":52212},{\"attributes\":{\"doi\":\"10.1145/2487575.2488200\",\"id\":\"b23\",\"matched_paper_id\":5961991},\"end\":53609,\"start\":52822},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":52919090},\"end\":54188,\"start\":53611},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":221191392},\"end\":54892,\"start\":54190},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":3051291},\"end\":55392,\"start\":54894},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":218907540},\"end\":55873,\"start\":55394},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":227154822},\"end\":56186,\"start\":55875},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":5855042},\"end\":56487,\"start\":56188},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":9120907},\"end\":56932,\"start\":56489},{\"attributes\":{\"doi\":\"arXiv:1710.10903\",\"id\":\"b31\"},\"end\":57188,\"start\":56934},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":6011288},\"end\":57461,\"start\":57190},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":219559208},\"end\":58172,\"start\":57463},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":220730199},\"end\":58836,\"start\":58174},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":218900505},\"end\":59491,\"start\":58838},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b36\",\"matched_paper_id\":12400267},\"end\":59856,\"start\":59493},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":52188056},\"end\":60327,\"start\":59858},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":1637394},\"end\":60963,\"start\":60329}]", "bib_title": "[{\"end\":43375,\"start\":43284},{\"end\":43979,\"start\":43955},{\"end\":44319,\"start\":44227},{\"end\":44643,\"start\":44573},{\"end\":45445,\"start\":45401},{\"end\":45787,\"start\":45708},{\"end\":46350,\"start\":46265},{\"end\":47017,\"start\":46928},{\"end\":47790,\"start\":47778},{\"end\":48034,\"start\":47986},{\"end\":48522,\"start\":48451},{\"end\":49396,\"start\":49331},{\"end\":49871,\"start\":49809},{\"end\":50835,\"start\":50799},{\"end\":51418,\"start\":51319},{\"end\":52296,\"start\":52212},{\"end\":52867,\"start\":52822},{\"end\":53677,\"start\":53611},{\"end\":54297,\"start\":54190},{\"end\":54945,\"start\":54894},{\"end\":55468,\"start\":55394},{\"end\":55928,\"start\":55875},{\"end\":56216,\"start\":56188},{\"end\":56564,\"start\":56489},{\"end\":57235,\"start\":57190},{\"end\":57564,\"start\":57463},{\"end\":58272,\"start\":58174},{\"end\":58921,\"start\":58838},{\"end\":59564,\"start\":59493},{\"end\":59923,\"start\":59858},{\"end\":60384,\"start\":60329}]", "bib_author": "[{\"end\":43068,\"start\":43052},{\"end\":43086,\"start\":43068},{\"end\":43390,\"start\":43377},{\"end\":43400,\"start\":43390},{\"end\":43408,\"start\":43400},{\"end\":43423,\"start\":43408},{\"end\":43433,\"start\":43423},{\"end\":43446,\"start\":43433},{\"end\":44004,\"start\":43981},{\"end\":44018,\"start\":44004},{\"end\":44032,\"start\":44018},{\"end\":44329,\"start\":44321},{\"end\":44340,\"start\":44329},{\"end\":44356,\"start\":44340},{\"end\":44362,\"start\":44356},{\"end\":44373,\"start\":44362},{\"end\":44386,\"start\":44373},{\"end\":44657,\"start\":44645},{\"end\":44668,\"start\":44657},{\"end\":44676,\"start\":44668},{\"end\":45114,\"start\":45104},{\"end\":45128,\"start\":45114},{\"end\":45142,\"start\":45128},{\"end\":45155,\"start\":45142},{\"end\":45170,\"start\":45155},{\"end\":45186,\"start\":45170},{\"end\":45200,\"start\":45186},{\"end\":45215,\"start\":45200},{\"end\":45228,\"start\":45215},{\"end\":45242,\"start\":45228},{\"end\":45249,\"start\":45242},{\"end\":45802,\"start\":45789},{\"end\":45812,\"start\":45802},{\"end\":45830,\"start\":45812},{\"end\":45837,\"start\":45830},{\"end\":46364,\"start\":46352},{\"end\":46375,\"start\":46364},{\"end\":46384,\"start\":46375},{\"end\":46397,\"start\":46384},{\"end\":46413,\"start\":46397},{\"end\":46423,\"start\":46413},{\"end\":47029,\"start\":47019},{\"end\":47042,\"start\":47029},{\"end\":47244,\"start\":47234},{\"end\":47257,\"start\":47244},{\"end\":47268,\"start\":47257},{\"end\":47284,\"start\":47268},{\"end\":47295,\"start\":47284},{\"end\":47304,\"start\":47295},{\"end\":47806,\"start\":47792},{\"end\":47819,\"start\":47806},{\"end\":48051,\"start\":48036},{\"end\":48066,\"start\":48051},{\"end\":48537,\"start\":48524},{\"end\":48551,\"start\":48537},{\"end\":48563,\"start\":48551},{\"end\":48575,\"start\":48563},{\"end\":48588,\"start\":48575},{\"end\":49082,\"start\":49058},{\"end\":49093,\"start\":49082},{\"end\":49103,\"start\":49093},{\"end\":49411,\"start\":49398},{\"end\":49428,\"start\":49411},{\"end\":49442,\"start\":49428},{\"end\":49889,\"start\":49873},{\"end\":49903,\"start\":49889},{\"end\":49914,\"start\":49903},{\"end\":49924,\"start\":49914},{\"end\":49928,\"start\":49924},{\"end\":50518,\"start\":50507},{\"end\":50527,\"start\":50518},{\"end\":50542,\"start\":50527},{\"end\":50556,\"start\":50542},{\"end\":50566,\"start\":50556},{\"end\":50578,\"start\":50566},{\"end\":50852,\"start\":50837},{\"end\":50869,\"start\":50852},{\"end\":50885,\"start\":50869},{\"end\":51126,\"start\":51116},{\"end\":51136,\"start\":51126},{\"end\":51145,\"start\":51136},{\"end\":51433,\"start\":51420},{\"end\":51447,\"start\":51433},{\"end\":51461,\"start\":51447},{\"end\":51474,\"start\":51461},{\"end\":51486,\"start\":51474},{\"end\":51947,\"start\":51937},{\"end\":51962,\"start\":51947},{\"end\":51981,\"start\":51962},{\"end\":51996,\"start\":51981},{\"end\":52308,\"start\":52298},{\"end\":52318,\"start\":52308},{\"end\":52330,\"start\":52318},{\"end\":52342,\"start\":52330},{\"end\":52355,\"start\":52342},{\"end\":52365,\"start\":52355},{\"end\":52873,\"start\":52869},{\"end\":52890,\"start\":52873},{\"end\":52901,\"start\":52890},{\"end\":52912,\"start\":52901},{\"end\":52927,\"start\":52912},{\"end\":52942,\"start\":52927},{\"end\":53699,\"start\":53679},{\"end\":53715,\"start\":53699},{\"end\":53729,\"start\":53715},{\"end\":53740,\"start\":53729},{\"end\":53759,\"start\":53740},{\"end\":53775,\"start\":53759},{\"end\":53790,\"start\":53775},{\"end\":53797,\"start\":53790},{\"end\":54312,\"start\":54299},{\"end\":54323,\"start\":54312},{\"end\":54337,\"start\":54323},{\"end\":54348,\"start\":54337},{\"end\":54362,\"start\":54348},{\"end\":54375,\"start\":54362},{\"end\":54391,\"start\":54375},{\"end\":54962,\"start\":54947},{\"end\":54976,\"start\":54962},{\"end\":54991,\"start\":54976},{\"end\":55487,\"start\":55470},{\"end\":55498,\"start\":55487},{\"end\":55510,\"start\":55498},{\"end\":55523,\"start\":55510},{\"end\":55536,\"start\":55523},{\"end\":55549,\"start\":55536},{\"end\":55943,\"start\":55930},{\"end\":56242,\"start\":56218},{\"end\":56259,\"start\":56242},{\"end\":56582,\"start\":56566},{\"end\":56598,\"start\":56582},{\"end\":56614,\"start\":56598},{\"end\":56952,\"start\":56934},{\"end\":56970,\"start\":56952},{\"end\":56988,\"start\":56970},{\"end\":57004,\"start\":56988},{\"end\":57249,\"start\":57237},{\"end\":57257,\"start\":57249},{\"end\":57266,\"start\":57257},{\"end\":57282,\"start\":57266},{\"end\":57576,\"start\":57566},{\"end\":57588,\"start\":57576},{\"end\":57599,\"start\":57588},{\"end\":57608,\"start\":57599},{\"end\":57621,\"start\":57608},{\"end\":57631,\"start\":57621},{\"end\":57644,\"start\":57631},{\"end\":58288,\"start\":58274},{\"end\":58300,\"start\":58288},{\"end\":58309,\"start\":58300},{\"end\":58319,\"start\":58309},{\"end\":58329,\"start\":58319},{\"end\":58934,\"start\":58923},{\"end\":58945,\"start\":58934},{\"end\":58957,\"start\":58945},{\"end\":58969,\"start\":58957},{\"end\":58979,\"start\":58969},{\"end\":58992,\"start\":58979},{\"end\":59576,\"start\":59566},{\"end\":59596,\"start\":59576},{\"end\":59608,\"start\":59596},{\"end\":59613,\"start\":59608},{\"end\":59938,\"start\":59925},{\"end\":59946,\"start\":59938},{\"end\":59956,\"start\":59946},{\"end\":59963,\"start\":59956},{\"end\":59976,\"start\":59963},{\"end\":59988,\"start\":59976},{\"end\":60399,\"start\":60386},{\"end\":60414,\"start\":60399},{\"end\":60427,\"start\":60414},{\"end\":60437,\"start\":60427},{\"end\":60446,\"start\":60437},{\"end\":60455,\"start\":60446},{\"end\":60468,\"start\":60455},{\"end\":60479,\"start\":60468},{\"end\":60487,\"start\":60479},{\"end\":60496,\"start\":60487}]", "bib_venue": "[{\"end\":43655,\"start\":43559},{\"end\":44871,\"start\":44782},{\"end\":45578,\"start\":45521},{\"end\":46020,\"start\":45937},{\"end\":46632,\"start\":46536},{\"end\":48249,\"start\":48166},{\"end\":48757,\"start\":48671},{\"end\":49591,\"start\":49525},{\"end\":50137,\"start\":50041},{\"end\":51653,\"start\":51578},{\"end\":52544,\"start\":52463},{\"end\":53189,\"start\":53065},{\"end\":53906,\"start\":53860},{\"end\":54570,\"start\":54489},{\"end\":55174,\"start\":55091},{\"end\":56723,\"start\":56677},{\"end\":57323,\"start\":57311},{\"end\":57853,\"start\":57757},{\"end\":58538,\"start\":58442},{\"end\":59201,\"start\":59105},{\"end\":60097,\"start\":60051},{\"end\":60675,\"start\":60594},{\"end\":43142,\"start\":43102},{\"end\":43557,\"start\":43446},{\"end\":44081,\"start\":44032},{\"end\":44390,\"start\":44386},{\"end\":44780,\"start\":44676},{\"end\":45519,\"start\":45447},{\"end\":45935,\"start\":45837},{\"end\":46534,\"start\":46423},{\"end\":47064,\"start\":47042},{\"end\":47420,\"start\":47327},{\"end\":47867,\"start\":47823},{\"end\":48164,\"start\":48066},{\"end\":48669,\"start\":48588},{\"end\":49168,\"start\":49119},{\"end\":49523,\"start\":49442},{\"end\":50039,\"start\":49928},{\"end\":50505,\"start\":50394},{\"end\":50902,\"start\":50885},{\"end\":51114,\"start\":51050},{\"end\":51576,\"start\":51486},{\"end\":52048,\"start\":52012},{\"end\":52461,\"start\":52365},{\"end\":53063,\"start\":52965},{\"end\":53858,\"start\":53797},{\"end\":54487,\"start\":54391},{\"end\":55089,\"start\":54991},{\"end\":55615,\"start\":55549},{\"end\":56021,\"start\":55943},{\"end\":56295,\"start\":56259},{\"end\":56675,\"start\":56614},{\"end\":57044,\"start\":57020},{\"end\":57309,\"start\":57282},{\"end\":57755,\"start\":57644},{\"end\":58440,\"start\":58329},{\"end\":59103,\"start\":58992},{\"end\":59661,\"start\":59617},{\"end\":60049,\"start\":59988},{\"end\":60592,\"start\":60496}]"}}}, "year": 2023, "month": 12, "day": 17}