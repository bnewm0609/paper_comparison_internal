{"id": 3510042, "updated": "2023-09-29 01:59:44.979", "metadata": {"title": "Ranking Sentences for Extractive Summarization with Reinforcement Learning", "authors": "[{\"first\":\"Shashi\",\"last\":\"Narayan\",\"middle\":[]},{\"first\":\"Shay B.\",\"last\":\"Cohen\",\"middle\":[]},{\"first\":\"Mirella\",\"last\":\"Lapata\",\"middle\":[]}]", "venue": "NAACL", "journal": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)", "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "Single document summarization is the task of producing a shorter version of a document while preserving its principal information content. In this paper we conceptualize extractive summarization as a sentence ranking task and propose a novel training algorithm which globally optimizes the ROUGE evaluation metric through a reinforcement learning objective. We use our algorithm to train a neural summarization model on the CNN and DailyMail datasets and demonstrate experimentally that it outperforms state-of-the-art extractive and abstractive systems when evaluated automatically and by humans.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1802.08636", "mag": "2962972512", "acl": "N18-1158", "pubmed": null, "pubmedcentral": null, "dblp": "conf/naacl/NarayanCL18", "doi": "10.18653/v1/n18-1158"}}, "content": {"source": {"pdf_hash": "b2f9f332ee50bf67cebf126806510b9b6a65674e", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1802.08636v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/N18-1158.pdf", "status": "HYBRID"}}, "grobid": {"id": "ecfd33561d1771e44c263fb46449c9e1259fa11c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/b2f9f332ee50bf67cebf126806510b9b6a65674e.txt", "contents": "\nRanking Sentences for Extractive Summarization with Reinforcement Learning\n16 Apr 2018\n\nShashi Narayan shashi.narayan@ed.ac.uk \nInstitute for Language, Cognition and Computation School of Informatics\nUniversity of Edinburgh\n10 Crichton StreetEH8 9ABEdinburgh\n\nShay B Cohen \nInstitute for Language, Cognition and Computation School of Informatics\nUniversity of Edinburgh\n10 Crichton StreetEH8 9ABEdinburgh\n\nMirella Lapata \nInstitute for Language, Cognition and Computation School of Informatics\nUniversity of Edinburgh\n10 Crichton StreetEH8 9ABEdinburgh\n\nRanking Sentences for Extractive Summarization with Reinforcement Learning\n16 Apr 2018\nSingle document summarization is the task of producing a shorter version of a document while preserving its principal information content. In this paper we conceptualize extractive summarization as a sentence ranking task and propose a novel training algorithm which globally optimizes the ROUGE evaluation metric through a reinforcement learning objective. We use our algorithm to train a neural summarization model on the CNN and Dai-lyMail datasets and demonstrate experimentally that it outperforms state-of-the-art extractive and abstractive systems when evaluated automatically and by humans. . 2015. TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org.\n\nIntroduction\n\nAutomatic summarization has enjoyed wide popularity in natural language processing due to its potential for various information access applications. Examples include tools which aid users navigate and digest web content (e.g., news, social media, product reviews), question answering, and personalized recommendation engines. Single document summarization -the task of producing a shorter version of a document while preserving its information content -is perhaps the most basic of summarization tasks that have been identified over the years (see Nenkova and McKeown, 2011 for a comprehensive overview).\n\nModern approaches to single document summarization are data-driven, taking advantage of the success of neural network architectures and their ability to learn continuous features without recourse to preprocessing tools or linguistic annotations. Abstractive summarization involves various text rewriting operations (e.g., substitution, deletion, reordering) and has been recently framed as a sequence-to-sequence problem (Sutskever et al., 2014). Central in most approaches (Rush et al., 2015;Nallapati et al., 2016;See et al., 2017;Tan and Wan, 2017;Paulus et al., 1 Our code and data are available here: https://github.com/shashiongithub/Refresh. 2017) is an encoder-decoder architecture modeled by recurrent neural networks. The encoder reads the source sequence into a list of continuousspace representations from which the decoder generates the target sequence. An attention mechanism (Bahdanau et al., 2015) is often used to locate the region of focus during decoding.\n\nExtractive systems create a summary by identifying (and subsequently concatenating) the most important sentences in a document. A few recent approaches (Cheng and Lapata, 2016;Nallapati et al., 2017;Narayan et al., 2017;Yasunaga et al., 2017) conceptualize extractive summarization as a sequence labeling task in which each label specifies whether each document sentence should be included in the summary. Existing models rely on recurrent neural networks to derive a meaning representation of the document which is then used to label each sentence, taking the previously labeled sentences into account. These models are typically trained using crossentropy loss in order to maximize the likelihood of the ground-truth labels and do not necessarily learn to rank sentences based on their importance due to the absence of a ranking-based objective. Another discrepancy comes from the mismatch between the learning objective and the evaluation criterion, namely ROUGE (Lin and Hovy, 2003), which takes the entire summary into account.\n\nIn this paper we argue that cross-entropy training is not optimal for extractive summarization. Models trained this way are prone to generating verbose summaries with unnecessarily long sentences and redundant information. We propose to overcome these difficulties by globally optimizing the ROUGE evaluation metric and learning to rank sentences for summary generation through a reinforcement learning objective. Similar to previous work (Cheng and Lapata, 2016;Narayan et al., 2017;Nallapati et al., 2017), our neural summarization model consists of a hierarchical document encoder and a hierarchical sentence extractor. During training, it combines the maximum-likelihood cross-entropy loss with rewards from policy gradient reinforcement learning to directly optimize the evaluation metric relevant for the summarization task. We show that this global optimization framework renders extractive models better at discriminating among sentences for the final summary; a sentence is ranked high for selection if it often occurs in high scoring summaries.\n\nWe report results on the CNN and DailyMail news highlights datasets (Hermann et al., 2015) which have been recently used as testbeds for the evaluation of neural summarization systems. Experimental results show that when evaluated automatically (in terms of ROUGE), our model outperforms state-of-the-art extractive and abstractive systems. We also conduct two human evaluations in order to assess (a) which type of summary participants prefer (we compare extractive and abstractive systems) and (b) how much key information from the document is preserved in the summary (we ask participants to answer questions pertaining to the content in the document by reading system summaries). Both evaluations overwhelmingly show that human subjects find our summaries more informative and complete.\n\nOur contributions in this work are three-fold: a novel application of reinforcement learning to sentence ranking for extractive summarization; corroborated by analysis and empirical results showing that cross-entropy training is not well-suited to the summarization task; and large scale user studies following two evaluation paradigms which demonstrate that state-of-the-art abstractive systems lag behind extractive ones when the latter are globally trained.\n\n\nSummarization as Sentence Ranking\n\nGiven a document D consisting of a sequence of sentences (s 1 , s 2 , ..., s n ) , an extractive summarizer aims to produce a summary S by selecting m sentences from D (where m < n). For each sentence s i \u2208 D, we predict a label y i \u2208 {0, 1} (where 1 means that s i should be included in the summary) and assign a score p(y i |s i , D, \u03b8) quantifying s i 's relevance to the summary. The model learns to assign p(1|s i , D, \u03b8) > p(1|s j , D, \u03b8) when sentence s i is more relevant than s j . Model parameters are denoted by \u03b8. We estimate p(y i |s i , D, \u03b8) using a neural network model and assemble a summary S by selecting m sentences with top p(1|s i , D, \u03b8) scores.\n\nOur architecture resembles those previously proposed in the literature (Cheng and Lapata, 2016;Nallapati et al., 2017;Narayan et al., 2017).\n\nThe main components include a sentence encoder, a document encoder, and a sentence extractor (see the left block of Figure 1) which we describe in more detail below.\n\nSentence Encoder A core component of our model is a convolutional sentence encoder which encodes sentences into continuous representations.\n\nIn recent years, CNNs have proven useful for various NLP tasks (Collobert et al., 2011;Kim, 2014;Kalchbrenner et al., 2014;Zhang et al., 2015;Kim et al., 2016;Cheng and Lapata, 2016) because of their effectiveness in identifying salient patterns in the input (Xu et al., 2015). In the case of summarization, CNNs can identify named-entities and events that correlate with the gold summary.\n\nWe use temporal narrow convolution by applying a kernel filter K of width h to a window of h words in sentence s to produce a new feature. This filter is applied to each possible window of words in s to produce a feature map f \u2208 R k\u2212h+1 where k is the sentence length. We then apply max-pooling over time over the feature map f and take the maximum value as the feature corresponding to this particular filter K. We use multiple kernels of various sizes and each kernel multiple times to construct the representation of a sentence. In Figure 1, kernels of size 2 (red) and 4 (blue) are applied three times each. Max-pooling over time yields two feature lists f K 2 and f K 4 \u2208 R 3 . The final sentence embeddings have six dimensions.\n\n\nDocument Encoder\n\nThe document encoder composes a sequence of sentences to obtain a document representation. We use a recurrent neural network with Long Short-Term Memory (LSTM) cells to avoid the vanishing gradient problem when training long sequences (Hochreiter and Schmidhuber, 1997). Given a document D consisting of a sequence of sentences (s 1 , s 2 , . . . , s n ), we follow common practice and feed sentences in reverse order (Sutskever et al., 2014;Li et al., 2015;Filippova et al., 2015;Narayan et al., 2017). This way we make sure that the network also considers the top sentences of the document which are particularly important for summarization (Rush et al., 2015;Nallapati et al., 2016).\n\nSentence Extractor Our sentence extractor sequentially labels each sentence in a document with 1 (relevant for the summary) or 0 (otherwise). It is implemented with another RNN with LSTM cells and a softmax layer. At time t i , it reads Sentence extractor s 5 s 4 s 3 s 2 s 1 y 5 y 4 y 3 y 2 y 1 Figure 1: Extractive summarization model with reinforcement learning: a hierarchical encoder-decoder model ranks sentences for their extract-worthiness and a candidate summary is assembled from the top ranked sentences; the REWARD generator compares the candidate against the gold summary to give a reward which is used in the REINFORCE algorithm (Williams, 1992) to update the model. sentence s i and makes a binary prediction, conditioned on the document representation (obtained from the document encoder) and the previously labeled sentences. This way, the sentence extractor is able to identify locally and globally important sentences within the document. We rank the sentences in a document D by p(y i = 1|s i , D, \u03b8), the confidence scores assigned by the softmax layer of the sentence extractor.\n\nWe learn to rank sentences by training our network in a reinforcement learning framework, directly optimizing the final evaluation metric, namely ROUGE (Lin and Hovy, 2003). Before we describe our training algorithm, we elaborate on why the maximum-likelihood cross-entropy objective could be deficient for ranking sentences for summarization (Section 3). Then, we define our reinforcement learning objective in Section 4 and show that our new way of training allows the model to better discriminate amongst sentences, i.e., a sentence is ranked higher for selection if it often occurs in high scoring summaries.\n\n\nThe Pitfalls of Cross-Entropy Loss\n\nPrevious work optimizes summarization models by maximizing p(y|D, \u03b8) = \u220f n i=1 p(y i |s i , D, \u03b8), the likelihood of the ground-truth labels y = (y 1 , y 2 , ..., y n ) for sentences (s 1 , s 2 , . . . , s n ), given document D and model parameters \u03b8. This objective can be achieved by minimizing the cross-entropy loss at each decoding step:\nL(\u03b8) = \u2212 n \u2211 i=1 log p(y i |s i , D, \u03b8).\n(1)\n\nCross-entropy training leads to two kinds of discrepancies in the model. The first discrepancy comes from the disconnect between the task definition and the training objective. While MLE in Equation (1) aims to maximize the likelihood of the ground-truth labels, the model is (a) expected to rank sentences to generate a summary and (b) evaluated using ROUGE at test time. The second discrepancy comes from the reliance on ground-truth labels. Document collections for training summarization systems do not naturally contain labels indicating which sentences should be extracted. Instead, they are typically accompanied by abstractive summaries from which sentence-level labels are extrapolated. Cheng and Lapata (2016) follow Woodsend and Lapata (2010) in adopting a rulebased method which assigns labels to each sentence in the document individually based on their semantic correspondence with the gold summary (see the fourth column in Table 1). An alternative method (Svore et al., 2007;Cao et al., 2016;Nallapati et al., 2017) identifies the set of sentences which collectively gives the highest ROUGE with respect to the gold summary. Sentences in this set are labeled with 1 and 0 otherwise (see the column 5 in Table 1 Table 1: An abridged CNN article (only first 15 out of 31 sentences are shown) and its \"story highlights\". The latter are typically written by journalists to allow readers to quickly gather information on stories.\n\nHighlights are often used as gold standard abstractive summaries in the summarization literature.\n\nLabeling sentences individually often generates too many positive labels causing the model to overfit the data. For example, the document in Table 1 has 12 positively labeled sentences out of 31 in total (only first 10 are shown). Collective labels present a better alternative since they only pertain to the few sentences deemed most suitable to form the summary. However, a model trained with cross-entropy loss on collective labels will underfit the data as it will only maximize probabilities p(1|s i , D, \u03b8) for sentences in this set (e.g., sentences {0, 11, 13} in Table 1) and ignore all other sentences. We found that there are many candidate summaries with high ROUGE scores which could be considered during training.\n\nTable 1 (last column) shows candidate summaries ranked according to the mean of ROUGE-1, ROUGE-2, and ROUGE-L F 1 scores. Interestingly, multiple top ranked summaries have reasonably high ROUGE scores. For example, the average ROUGE for the summaries ranked second (0,13), third (11,13), and fourth (0,1,13) is 57.5%, 57.2%, and 57.1%, and all top 16 summaries have ROUGE scores more or equal to 50%. A few sentences are indicative of important content and appear frequently in the summaries: sentence 13 occurs in all summaries except one, while sentence 0 appears in several summaries too. Also note that summaries (11,13) and (1,13) yield better ROUGE scores compared to longer summaries, and may be as informative, yet more concise, alternatives.\n\nThese discrepancies render the model less efficient at ranking sentences for the summarization task. Instead of maximizing the likelihood of the ground-truth labels, we could train the model to predict the individual ROUGE score for each sentence in the document and then select the top m sentences with highest scores. But sentences with individual ROUGE scores do not necessarily lead to a high scoring summary, e.g., they may convey overlapping content and form verbose and redundant summaries. For example, sentence 3, despite having a high individual ROUGE score (35.6%), does not occur in any of the top 5 summaries. We next explain how we address these issues using reinforcement learning.\n\n\nSentence Ranking with Reinforcement Learning\n\nReinforcement learning (Sutton and Barto, 1998) has been proposed as a way of training sequenceto-sequence generation models in order to directly optimize the metric used at test time, e.g., BLEU or ROUGE (Ranzato et al., 2015). We adapt reinforcement learning to our formulation of extractive summarization to rank sentences for summary generation. We propose an objective function that combines the maximum-likelihood cross-entropy loss with rewards from policy gradient reinforcement learning to globally optimize ROUGE. Our training algorithm allows to explore the space of possible summaries, making our model more robust to unseen data. As a result, reinforcement learning helps extractive summarization in two ways: (a) it directly optimizes the evaluation metric instead of maximizing the likelihood of the ground-truth labels and (b) it makes our model better at discriminating among sentences; a sentence is ranked high for selection if it often occurs in high scoring summaries.\n\n\nPolicy Learning\n\nWe cast the neural summarization model introduced in Figure 1 in the Reinforcement Learning paradigm (Sutton and Barto, 1998). Accordingly, the model can be viewed as an \"agent\" which interacts with an \"environment\" consisting of documents. At first, the agent is initialized randomly, it reads document D and predicts a relevance score for each sentence s i \u2208 D using \"policy\" p(y i |s i , D, \u03b8), where \u03b8 are model parameters. Once the agent is done reading the document, a summary with labels\u0177 is sampled out of the ranked sentences. The agent is then given a \"reward\" r commensurate with how well the extract resembles the gold-standard summary. Specifically, as reward function we use mean F 1 of ROUGE-1, ROUGE-2, and ROUGE-L. Unigram and bigram overlap (ROUGE-1 and ROUGE-2) are meant to assess informativeness, whereas the longest common subsequence (ROUGE-L) is meant to assess fluency. We update the agent using the REIN-FORCE algorithm (Williams, 1992) which aims to minimize the negative expected reward:\nL(\u03b8) = \u2212E\u0177 \u223c p \u03b8 [r(\u0177)](2)\nwhere, p \u03b8 stands for p(y|D, \u03b8). REINFORCE is based on the observation that the expected gradient of a non-differentiable reward function (ROUGE, in our case) can be computed as follows:\n\u2207L(\u03b8) = \u2212E\u0177 \u223c p \u03b8 [r(\u0177)\u2207 log p(\u0177|D, \u03b8)] (3)\nWhile MLE in Equation (1) aims to maximize the likelihood of the training data, the objective in Equation (2) learns to discriminate among sentences with respect to how often they occur in high scoring summaries.\n\n\nTraining with High Probability Samples\n\nComputing the expectation term in Equation (3) is prohibitive, since there is a large number of possible extracts. In practice, we approximate the expected gradient using a single sample\u0177 from p \u03b8 for each training example in a batch:\n\u2207L(\u03b8) \u2248 \u2212r(\u0177)\u2207 log p(\u0177|D, \u03b8) \u2248 \u2212r(\u0177) n \u2211 i=1 \u2207 log p(\u0177 i |s i , D, \u03b8) (4)\nPresented in its original form, the REINFORCE algorithm starts learning with a random policy which can make model training challenging for complex tasks like ours where a single document can give rise to a very large number of candidate summaries. We therefore limit the search space of\u0177 in Equation (4) to the set of largest probability samples\u0176. We approximate\u0176 by the k extracts which receive highest ROUGE scores. More concretely, we assemble candidate summaries efficiently by first selecting p sentences from the document which on their own have high ROUGE scores. We then generate all possible combinations of p sentences subject to maximum length m and evaluate them against the gold summary. Summaries are ranked according to F 1 by taking the mean of ROUGE-1, ROUGE-2, and ROUGE-L.\u0176 contains these top k candidate summaries. During training, we sample\u0177 from\u0176 instead of p(\u0177|D, \u03b8).\n\nRanzato et al. (2015) proposed an alternative to REINFORCE called MIXER (Mixed Incremental Cross-Entropy Reinforce) which first pretrains the model with the cross-entropy loss using ground truth labels and then follows a curriculum learning strategy  to gradually teach the model to produce stable predictions on its own. In our experiments MIXER performed worse than the model of Nallapati et al. (2017) just trained on collective labels. We conjecture that this is due to the unbounded nature of our ranking problem. Recall that our model assigns relevance scores to sentences rather than words. The space of sentential representations is vast and fairly unconstrained compared to other prediction tasks operating with fixed vocabularies Paulus et al., 2017;Zhang and Lapata, 2017). Moreover, our approximation of the gradient allows the model to converge much faster to an optimal policy. Advantageously, we do not require an online reward estimator, we pre-compute\u0176, which leads to a significant speedup during training compared to MIXER (Ranzato et al., 2015) and related training schemes (Shen et al., 2016).\n\n\nExperimental Setup\n\nIn this section we present our experimental setup for assessing the performance of our model which we call REFRESH as a shorthand for REinFoRcement Learning-based Extractive Summarization. We describe our datasets, discuss implementation details, our evaluation protocol, and the systems used for comparison.\n\n\nSummarization Datasets\n\nWe evaluated our models on the CNN and DailyMail news highlights datasets (Hermann et al., 2015).\n\nWe used the standard splits of Hermann et al. (2015) for training, validation, and testing (90,266/1,220/1,093 documents for CNN and 196,961/12,148/10,397 for DailyMail). We did not anonymize entities or lower case tokens. We followed previous studies (Cheng and Lapata, 2016;Nallapati et al., 2016Nallapati et al., , 2017See et al., 2017;Tan and Wan, 2017) in assuming that the \"story highlights\" associated with each article are gold-standard abstractive summaries. During training we use these to generate high scoring extracts and to estimate rewards for them, but during testing, they are used as reference summaries to evaluate our models. Implementation Details We generated extracts by selecting three sentences (m = 3) for CNN articles and four sentences (m = 4) for DailyMail articles. These decisions were informed by the fact that gold highlights in the CNN/DailyMail validation sets are 2.6/4.2 sentences long. For both datasets, we estimated high-scoring extracts using 10 document sentences (p = 10) with highest ROUGE scores. We tuned the initialization parameter k for\u0176 on the validation set: we found that our model performs best with k = 5 for the CNN dataset and k = 15 for the DailyMail dataset.\n\nWe used the One Billion Word Benchmark corpus (Chelba et al., 2013) to train word embeddings with the skip-gram model  using context window size 6, negative sampling LEAD \u2022 A SkyWest Airlines flight made an emergency landing in Buffalo, New York, on Wednesday after a passenger lost consciousness, officials said.\n\n\u2022 The passenger received medical attention before being released, according to Marissa Snow, spokeswoman for SkyWest.\n\n\u2022 She said the airliner expects to accommodate the 75 passengers on another aircraft to their original destination -Hartford, Connecticut -later Wednesday afternoon.\n\n\nSee et al.\n\n\u2022 Skywest Airlines flight made an emergency landing in Buffalo, New York, on Wednesday after a passenger lost consciousness.\n\n\u2022 She said the airliner expects to accommodate the 75 passengers on another aircraft to their original destination -Hartford, Connecticut.\n\n\nREFRESH\n\n\u2022 A SkyWest Airlines flight made an emergency landing in Buffalo, New York, on Wednesday after a passenger lost consciousness, officials said.\n\n\u2022 The passenger received medical attention before being released, according to Marissa Snow, spokeswoman for SkyWest.\n\n\u2022 The Federal Aviation Administration initially reported a pressurization problem and said it would investigate. GOLD\n\n\u2022 FAA backtracks on saying crew reported a pressurization problem \u2022 One passenger lost consciousness \u2022 The plane descended 28,000 feet in three minutes Q 1 Who backtracked on saying crew reported a pressurization problem? (FAA) Q 2 How many passengers lost consciousness in the incident?\n\n(One) Q 3 How far did the plane descend in three minutes? (28,000 feet) Figure 2: Summaries produced by the LEAD baseline, the abstractive system of See et al. (2017) and REFRESH for a CNN (test) article. GOLD presents the human-authored summary; the bottom block shows manually written questions using the gold summary and their answers in parentheses.\n\nsize 10, and hierarchical softmax 1. Known words were initialized with pre-trained embeddings of size 200. Embeddings for unknown words were initialized to zero, but estimated during training. Sentences were padded with zeros to a length of 100. For the sentence encoder, we used a list of kernels of widths 1 to 7, each with output channel size of 50 (Kim et al., 2016). The sentence embedding size in our model was 350.\n\nFor the recurrent neural network component in the document encoder and sentence extractor, we used a single-layered LSTM network with size 600. All input documents were padded with zeros to a maximum document length of 120. We performed minibatch cross-entropy training with a batch size of 20 documents for 20 training epochs. It took around 12 hrs on a single GPU to train. After each epoch, we evaluated our model on the validation set and chose the best performing model for the test set. During training we used the Adam optimizer (Kingma and Ba, 2015) with initial learning rate 0.001. Our system is implemented in TensorFlow (Abadi et al., 2015).\n\nEvaluation We evaluated summarization quality using F 1 ROUGE (Lin and Hovy, 2003). We report unigram and bigram overlap (ROUGE-1 and ROUGE-2) as a means of assessing informativeness and the longest common subsequence (ROUGE-L) as a means of assessing fluency. 2 We compared REFRESH against a baseline which simply selects the first m leading sentences from each document (LEAD) and two neural models similar to ours (see left block in Figure 1), both trained with cross-entropy loss. Cheng and Lapata (2016) train on individual labels, while Nallapati et al. (2017) use collective labels. We also compared our model against the abstractive systems of , Nallapati et al. (2016), See et al. (2017), and Tan and Wan (2017). 3 In addition to ROUGE which can be misleading when used as the only means to assess the informativeness of summaries (Schluter, 2017), we also evaluated system output by eliciting human judgments in two ways. In our first experiment, participants were presented with a news article and summaries generated by three systems: the LEAD baseline, abstracts from See et al. (2017), and extracts from REFRESH. We also included the human-authored highlights. 4 Participants read the articles and were asked to rank the summaries from best (1) to worst (4) in order of informativeness (does the summary capture important information in the article?) and fluency (is the summary written in well-formed English?). We did not allow any ties. We randomly selected 10 articles from the CNN test set and 10 from the Dai-lyMail test set. The study was completed by five participants, all native or proficient English speakers. Each participant was presented with the 20 articles. The order of summaries to rank was randomized per article and the order of articles per participant. Examples of summaries our subjects ranked are shown in Figure 2. 2 We used pyrouge, a Python package, to compute all ROUGE scores with parameters \"-a -c 95 -m -n 4 -w 1.2.\" 3 Cheng and Lapata (2016) report ROUGE recall scores on the DailyMail dataset only.\n\nWe used their code (https://github.com/cheng6076/NeuralSum) to produce ROUGE F 1 scores on both CNN and DailyMail datasets. For other systems, all results are taken from their papers. 4 We are grateful to Abigail See for providing us with the output of her system. We did not include output from Nallapati et al. (2017), , Nallapati et al. (2016), or Tan and Wan (2017) in our human evaluation study, as these models are trained on a named-entity anonymized version of the CNN and DailyMail datasets, and as result produce summaries which are not comparable to ours. We did not include extracts from Cheng and Lapata (2016) either as they were significantly inferior to LEAD (see Table 2).\n\nOur second experiment assessed the degree to which our model retains key information from the document following a question-answering (QA) paradigm which has been previously used to evaluate summary quality and text compression (Morris et al., 1992;Mani et al., 2002;Clarke and Lapata, 2010). We created a set of questions based on the gold summary under the assumption that it highlights the most important document content. We then examined whether participants were able to answer these questions by reading system summaries alone without access to the article. The more questions a system can answer, the better it is at summarizing the document as a whole.\n\nWe worked on the same 20 documents used in our first elicitation study. We wrote multiple factbased question-answer pairs for each gold summary without looking at the document. Questions were formulated so as to not reveal answers to subsequent questions. We created 71 questions in total varying from two to six questions per gold summary. Example questions are given in Figure 2. Participants read the summary and answered all associated questions as best they could without access to the original document or the gold summary. Subjects were shown summaries from three systems: the LEAD baseline, the abstractive system of See et al. (2017), and RE-FRESH. Five participants answered questions for each summary. We used the same scoring mechanism from Clarke and Lapata (2010), i.e., a correct answer was marked with a score of one, partially correct answers with a score of 0.5, and zero otherwise. The final score for a system is the average of all its question scores. Answers were elicited using Amazon's Mechanical Turk crowdsourcing platform. We uploaded data in batches (one system at a time) on Mechanical Turk to ensure that same participant does not evaluate summaries from different systems on the same set of questions.\n\n\nResults\n\nWe report results using automatic metrics in Table 2. The top part of the table compares RE-FRESH against related extractive systems. The bottom part reports the performance of abstractive systems. We present three variants of LEAD, one is computed by ourselves and the other two are reported in Nallapati et al. (2017) and See et al. (2017). Note that they vary slightly due to differences in the preprocessing of the data. We report results on the CNN and DailyMail datasets  and their combination (CNN+DailyMail).\n\n\nCross-Entropy vs Reinforcement Learning\n\nThe results in Table 2 show that REFRESH is superior to our LEAD baseline and extractive systems across datasets and metrics. It outperforms the extractive system of Cheng and Lapata (2016) which is trained on individual labels. REFRESH is not directly comparable with Nallapati et al. (2017) as they generate anonymized summaries.\n\nTheir system lags behind their LEAD baseline on ROUGE-L on the CNN+DailyMail dataset (35.5% vs 35.3%). Also note that their model is trained on collective labels and has a significant lead over Cheng and Lapata (2016). As discussed in Section 3 cross-entropy training on individual labels tends to overgenerate positive labels leading to less informative and verbose summaries.\n\nExtractive vs Abstractive Systems Our automatic evaluation results further demonstrate that REFRESH is superior to abstractive systems Nallapati et al., 2016;See et al., 2017;Tan and Wan, 2017) which are all variants of an encoder-decoder architecture (Sutskever et al., 2014). Despite being more faithful to the actual summarization task (hand-written summaries combine several pieces of information from the original document), abstractive systems lag behind the LEAD baseline. Tan and Wan (2017) present a graph-based neural model, which manages to outperform LEAD on ROUGE-1 but falters when higher order ROUGE scores are used. Amongst abstractive systems See et al. (2017) perform best. Interestingly, their system is mostly extractive, exhibiting a small degree of rewriting; it copies more than 35% of the sentences in the source document, 85% of 4-grams, 90% of 3grams, 95% of bigrams, and 99% of unigrams.  Human Evaluation: System Ranking Table 3 shows, proportionally, how often participants ranked each system, 1st, 2nd, and so on. Perhaps unsurprisingly human-authored summaries are considered best (and ranked 1st 39% of the time). REFRESH is ranked 2nd best followed by LEAD and See et al. (2017) which are mostly ranked in 3rd and 4th places. We carried out pairwise comparisons between all models in Table 3 to assess whether system differences are statistically significant. There is no significant difference between LEAD and See et al. (2017), and REFRESH and GOLD (using a one-way ANOVA with posthoc Tukey HSD tests; p < 0.01). All other differences are statistically significant.\n\nHuman Evaluation: Question Answering The results of our QA evaluation are shown in the last column of Table 3. Based on summaries generated by REFRESH, participants can answer 66.34% of questions correctly. Summaries produced by LEAD and the abstractive system of See et al. (2017) provide answers for 36.33% and 28.73% of the questions, respectively. Differences between systems are all statistically significant (p < 0.01) with the exception of LEAD and See et al. (2017).\n\nAlthough the QA results in Table 3 follow the same pattern as ROUGE in Table 2, differences among systems are now greatly amplified. QAbased evaluation is more focused and a closer reflection of users' information need (i.e., to find out what the article is about), whereas ROUGE simply captures surface similarity (i.e., n-gram overlap) between output summaries and their references. Interestingly, LEAD is considered better than See et al. (2017) in the QA evaluation, whereas we find the opposite when participants are asked to rank systems. We hypothesize that LEAD is indeed more informative than See et al. (2017) but humans prefer shorter summaries. The average length of LEAD summaries is 105.7 words compared to 61.6 for See et al. (2017).\n\n\nRelated Work\n\nTraditional summarization methods manually define features to rank sentences for their salience in order to identify the most important sentences in a document or set of documents (Kupiec et al., 1995;Mani, 2001;Filatova and Hatzivassiloglou, 2004;Nenkova et al., 2006;Sp\u00e4rck Jones, 2007). A vast majority of these methods learn to score each sentence independently (Barzilay and Elhadad, 1997;Teufel and Moens, 1997;Erkan and Radev, 2004;Mihalcea and Tarau, 2004;Shen et al., 2007;Schilder and Kondadadi, 2008;Wan, 2010) and a summary is generated by selecting topscored sentences in a way that is not incorporated into the learning process. Summary quality can be improved heuristically, (Yih et al., 2007), via max-margin methods (Carbonell and Goldstein, 1998;Li et al., 2009), or integer-linear programming (Woodsend and Lapata, 2010;Berg-Kirkpatrick et al., 2011;Woodsend and Lapata, 2012;Almeida and Martins, 2013;Parveen et al., 2015).\n\nRecent deep learning methods (K\u00e5geb\u00e4ck et al., 2014;Yin and Pei, 2015;Cheng and Lapata, 2016;Nallapati et al., 2017) learn continuous features without any linguistic preprocessing (e.g., named entities). Like traditional methods, these approaches also suffer from the mismatch between the learning objective and the evaluation criterion (e.g., ROUGE) used at the test time. In comparison, our neural model globally optimizes the ROUGE evaluation metric through a reinforcement learning objective: sentences are highly ranked if they occur in highly scoring summaries.\n\nReinforcement learning has been previously used in the context of traditional multi-document summarization as a means of selecting a sentence or a subset of sentences from a document cluster. Ryang and Abekawa (2012) cast the sentence selection task as a search problem. Their agent observes a state (e.g., a candidate summary), executes an action (a transition operation that produces a new state selecting a not-yet-selected sentence), and then receives a delayed reward based on tf * idf. Follow-on work (Rioux et al., 2014) extends this approach by employing ROUGE as part of the reward function, while Hen\u00df et al. (2015) further experiment with Q-learning. Moll\u00e1-Aliod (2017) has adapt this approach to query-focused summarization. Our model differs from these approaches both in application and formulation. We focus solely on extractive summarization, in our case states are documents (not summaries) and actions are relevance scores which lead to sentence ranking (not sentence-to-sentence transitions). Rather than employing reinforcement learning for sentence selection, our algorithm performs sentence ranking using ROUGE as the reward function. The REINFORCE algorithm (Williams, 1992) has been shown to improve encoder-decoder textrewriting systems by allowing to directly optimize a non-differentiable objective (Ranzato et al., 2015;Paulus et al., 2017) or to inject task-specific constraints (Zhang and Lapata, 2017;Nogueira and Cho, 2017). However, we are not aware of any attempts to use reinforcement learning for training a sentence ranker in the context of extractive summarization.\n\n\nConclusions\n\nIn this work we developed an extractive summarization model which is globally trained by optimizing the ROUGE evaluation metric. Our training algorithm explores the space of candidate summaries while learning to optimize a reward function which is relevant for the task at hand. Experimental results show that reinforcement learning offers a great means to steer our model towards generating informative, fluent, and concise summaries outperforming state-of-the-art extractive and abstractive systems on the CNN and Daily-Mail datasets. In the future we would like to focus on smaller discourse units (Mann and Thompson, 1988) rather than individual sentences, modeling compression and extraction jointly.\n\n\n).10 \"So far this year we've recorded eight travel-associated cases, and seven of them have come from countries in the Caribbean where we know the virus is being transmitted,\" Nasci said. The Tennessee Department of Health said the state has had multiple cases of the virus in people who have traveled to the Caribbean. Those with weak immune systems, such as the elderly, are more likely to suffer from the virus' side effects than those who are healthier.Story Highlights\u2022 North Carolina reports first case of mosquito-borne virus called Chikungunya \u2022 Chikungunya is primarily found in Africa, East Asia and the Caribbean islands \u2022 Virus is not deadly, but it can be painful, with symptoms lasting for weekssent. pos. \n\nCNN article \nSent-level \n\nROUGE \n\nIndividual \nOracle \nCollective \nOracle \nMultiple \nCollective \nOracle \nSentences \n\n0 \nA debilitating, mosquito-borne virus called Chikungunya has made its way to \nNorth Carolina, health officials say. \n\n21.2 \n1 \n1 \n(0,11,13) : 59.3 \n(0,13) : 57.5 \n(11,13) : 57.2 \n(0,1,13) : 57.1 \n(1,13) : 56.6 \n(3,11,13) : 55.0 \n(13) : 54.5 \n(0,3,13) : 54.2 \n(3,13) : 53.4 \n(1,3,13) : 52.9 \n(1,11,13) : 52.0 \n(0,9,13) : 51.3 \n(0,7,13) : 51.3 \n(0,12,13) : 51.0 \n(9,11,13) : 50.4 \n(1,9,13) : 50.1 \n(12,13) : 49.3 \n(7,11,13) : 47.8 \n(0,10,13) : 47.8 \n(11,12,13):47.7 \n(7,13) : 47.6 \n(9,13) : 47.5 \n(1,7,13) : 46.9 \n(3,7,13) : 46.0 \n(3,12,13) : 46.0 \n(3,9,13) : 45.9 \n(10,13) : 45.5 \n(4,11,13) : 45.3 \n... \n\n1 \nIt's the state's first reported case of the virus. \n18.1 \n1 \n0 \n2 \nThe patient was likely infected in the Caribbean, according to the Forsyth County \nDepartment of Public Health. \n\n11.2 \n1 \n0 \n\n3 \nChikungunya is primarily found in Africa, East Asia and the Caribbean islands, \nbut the Centers for Disease Control and Prevention has been watching the virus,+ \nfor fear that it could take hold in the United States -much like West Nile did more \nthan a decade ago. \n\n35.6 \n1 \n0 \n\n4 \nThe virus, which can cause joint pain and arthritis-like symptoms, has been on \nthe U.S. public health radar for some time. \n\n16.7 \n1 \n0 \n\n5 \nAbout 25 to 28 infected travelers bring it to the United States each year, said \nRoger Nasci, chief of the CDC's Arboviral Disease Branch in the Division of \nVector-Borne Diseases. \n\n9.7 \n0 \n0 \n\n6 \n\"We haven't had any locally transmitted cases in the U.S. thus far,\" Nasci said. \n7.4 \n0 \n0 \n7 \nBut a major outbreak in the Caribbean this year -with more than 100,000 cases \nreported -has health officials concerned. \n\n16.4 \n1 \n0 \n\n8 \nExperts say American tourists are bringing Chikungunya back home, and it's just \na matter of time before it starts to spread within the United States. \n\n10.6 \n0 \n0 \n\n9 \nAfter all, the Caribbean is a popular one with American tourists, and summer is \nfast approaching. \n\n13.9 \n1 \n0 \n\n18.4 \n1 \n0 \n\n11 Other states have also reported cases of Chikungunya. \n13.4 \n0 \n1 \n12 15.6 \n1 \n0 \n\n13 The virus is not deadly, but it can be painful, with symptoms lasting for weeks. \n54.5 \n1 \n1 \n14 5.5 \n0 \n0 \n\n\n\nTable 2 :\n2Results on the CNN and DailyMail test sets.We report ROUGE-1 (R1), ROUGE-2 (R2), and \n\n\nTable 3 :\n3System ranking and QA-based evaluations. Rankings (1st, 2nd, 3rd and 4th) are shown as proportions. Rank 1 is the best and Rank 4, the worst. The column QA shows the percentage of questions that participants answered correctly by reading system summaries.\nAcknowledgments We gratefully acknowledge the support of the European Research Council (Lapata; award number 681760), the European Union under the Horizon\nFast and robust compressive summarization with dual decomposition and multi-task learning. Miguel B Almeida, F T Andr\u00e9, Martins, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. the 51st Annual Meeting of the Association for Computational LinguisticsSofia, BulgariaMiguel B. Almeida and Andr\u00e9 F. T. Martins. 2013. Fast and robust compressive summarization with dual de- composition and multi-task learning. In Proceed- ings of the 51st Annual Meeting of the Associa- tion for Computational Linguistics. Sofia, Bulgaria, pages 196-206.\n\nNeural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, Proceedings of the 3rd International Conference on Learning Representations. the 3rd International Conference on Learning RepresentationsSan Diego, California, USADzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2015. Neural machine translation by jointly learning to align and translate. In Proceedings of the 3rd International Conference on Learning Rep- resentations. San Diego, California, USA.\n\nUsing lexical chains for text summarization. Regina Barzilay, Michael Elhadad, Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization. the ACL Workshop on Intelligent Scalable Text SummarizationMadrid, SpainRegina Barzilay and Michael Elhadad. 1997. Using lexical chains for text summarization. In Proceed- ings of the ACL Workshop on Intelligent Scalable Text Summarization. Madrid, Spain, pages 10-17.\n\nScheduled sampling for sequence prediction with recurrent neural networks. Samy Bengio, Oriol Vinyals, Navdeep Jaitly, Noam Shazeer, Advances in Neural Information Processing Systems 28. Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. 2015. Scheduled sampling for se- quence prediction with recurrent neural networks. In Advances in Neural Information Processing Sys- tems 28. pages 1171-1179.\n\nJointly learning to extract and compress. Taylor Berg-Kirkpatrick, Dan Gillick, Dan Klein, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesPortland, Oregon, USATaylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein. 2011. Jointly learning to extract and compress. In Proceedings of the 49th Annual Meeting of the Asso- ciation for Computational Linguistics: Human Lan- guage Technologies. Portland, Oregon, USA, pages 481-490.\n\nTGSum: Build tweet guided multi-document summarization dataset. Ziqiang Cao, Chengyao Chen, Wenjie Li, Sujian Li, Furu Wei, Ming Zhou, Proceedings of the 30th AAAI Conference on Artificial Intelligence. the 30th AAAI Conference on Artificial IntelligencePhoenix, Arizona USAZiqiang Cao, Chengyao Chen, Wenjie Li, Sujian Li, Furu Wei, and Ming Zhou. 2016. TGSum: Build tweet guided multi-document summarization dataset. In Proceedings of the 30th AAAI Con- ference on Artificial Intelligence. Phoenix, Arizona USA, pages 2906-2912.\n\nThe use of MMR, diversity-based reranking for reordering documents and producing summaries. Jaime Carbonell, Jade Goldstein, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. the 21st Annual International ACM SIGIR Conference on Research and Development in Information RetrievalMelbourne, AustraliaJaime Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proceed- ings of the 21st Annual International ACM SIGIR Conference on Research and Development in Infor- mation Retrieval. Melbourne, Australia, pages 335- 336.\n\nOne billion word benchmark for measuring progress in statistical language modeling. Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, GoogleTechnical reportThorsten Brants, Phillipp Koehn, and Tony RobinsonCiprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, Thorsten Brants, Phillipp Koehn, and Tony Robin- son. 2013. One billion word benchmark for measur- ing progress in statistical language modeling. Tech- nical report, Google.\n\nDistraction-based neural networks for modeling documents. Qian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, Hui Jiang, Proceedings of the 25th International Joint Conference on Artificial Intelligence. the 25th International Joint Conference on Artificial IntelligenceNew York, USAQian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, and Hui Jiang. 2016. Distraction-based neural networks for modeling documents. In Proceedings of the 25th International Joint Conference on Artificial Intelli- gence. New York, USA, pages 2754-2760.\n\nNeural summarization by extracting sentences and words. Jianpeng Cheng, Mirella Lapata, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyJianpeng Cheng and Mirella Lapata. 2016. Neural summarization by extracting sentences and words. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Berlin, Germany, pages 484-494.\n\nDiscourse constraints for document compression. James Clarke, Mirella Lapata, Computational Linguistics. 363James Clarke and Mirella Lapata. 2010. Discourse constraints for document compression. Computa- tional Linguistics 36(3):411-441.\n\nNatural language processing (almost) from scratch. Ronan Collobert, Jason Weston, L\u00e9on Bottou, Michael Karlen, Koray Kavukcuoglu, Pavel Kuksa, Journal of Machine Learning Research. 12Ronan Collobert, Jason Weston, L\u00e9on Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research 12:2493-2537.\n\nLexRank: Graph-based lexical centrality as salience in text summarization. G\u00fcnes Erkan, Dragomir R Radev, Journal of Artificial Intelligence Research. 221G\u00fcnes Erkan and Dragomir R. Radev. 2004. LexRank: Graph-based lexical centrality as salience in text summarization. Journal of Artificial Intelligence Research 22(1):457-479.\n\nEvent-based extractive summarization. Elena Filatova, Vasileios Hatzivassiloglou, Proceedings of ACL Workshop on Text Summarization Branches Out. ACL Workshop on Text Summarization Branches OutBarcelona, SpainElena Filatova and Vasileios Hatzivassiloglou. 2004. Event-based extractive summarization. In Pro- ceedings of ACL Workshop on Text Summarization Branches Out. Barcelona, Spain, pages 104-111.\n\nSentence compression by deletion with LSTMs. Katja Filippova, Enrique Alfonseca, Carlos A Colmenares, Lukasz Kaiser, Oriol Vinyals, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalKatja Filippova, Enrique Alfonseca, Carlos A. Col- menares, Lukasz Kaiser, and Oriol Vinyals. 2015. Sentence compression by deletion with LSTMs. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Lisbon, Portugal, pages 360-368.\n\nA reinforcement learning approach for adaptive single-and multi-document summarization. Sebastian Hen\u00df, Margot Mieskes, Iryna Gurevych, Proceedings of International Conference of the German Society for Computational Linguistics and Language Technology. International Conference of the German Society for Computational Linguistics and Language TechnologyDuisburg-Essen, GermanySebastian Hen\u00df, Margot Mieskes, and Iryna Gurevych. 2015. A reinforcement learning approach for adap- tive single-and multi-document summarization. In Proceedings of International Conference of the Ger- man Society for Computational Linguistics and Lan- guage Technology. Duisburg-Essen, Germany, pages 3-12.\n\nTeaching machines to read and comprehend. Karl Moritz Hermann, Tom\u00e1\u0161 Ko\u010disk\u00fd, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, Phil Blunsom, Advances in Neural Information Processing Systems 28. Karl Moritz Hermann, Tom\u00e1\u0161 Ko\u010disk\u00fd, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Su- leyman, and Phil Blunsom. 2015. Teaching ma- chines to read and comprehend. In Advances in Neu- ral Information Processing Systems 28. pages 1693- 1701.\n\nLong Short-Term Memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural Computation. 98Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation 9(8):1735-1780.\n\nA convolutional neural network for modelling sentences. Nal Kalchbrenner, Edward Grefenstette, Phil Blunsom, Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. the 52nd Annual Meeting of the Association for Computational LinguisticsBaltimore, MarylandNal Kalchbrenner, Edward Grefenstette, and Phil Blun- som. 2014. A convolutional neural network for modelling sentences. In Proceedings of the 52nd Annual Meeting of the Association for Computa- tional Linguistics. Baltimore, Maryland, pages 655- 665.\n\nConvolutional neural networks for sentence classification. Yoon Kim, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. the 2014 Conference on Empirical Methods in Natural Language ProcessingDoha, QatarYoon Kim. 2014. Convolutional neural networks for sentence classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Lan- guage Processing. Doha, Qatar, pages 1746-1751.\n\nCharacter-aware neural language models. Yoon Kim, Yacine Jernite, David Sontag, Alexander M Rush, Proceedings of the 30th AAAI Conference on Artificial Intelligence. the 30th AAAI Conference on Artificial IntelligencePhoenix, Arizona USAYoon Kim, Yacine Jernite, David Sontag, and Alexan- der M. Rush. 2016. Character-aware neural lan- guage models. In Proceedings of the 30th AAAI Conference on Artificial Intelligence. Phoenix, Ari- zona USA, pages 2741-2749.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, Proceedings of the 3rd International Conference on Learning Representations. the 3rd International Conference on Learning RepresentationsSan Diego, California, USADiederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In Proceed- ings of the 3rd International Conference on Learn- ing Representations. San Diego, California, USA.\n\nExtractive summarization using continuous vector space models. Mikael K\u00e5geb\u00e4ck, Olof Mogren, Nina Tahmasebi, Devdatt Dubhashi, Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality. Gothenburg. the Workshop on Continuous Vector Space Models and their Compositionality. GothenburgSwedenMikael K\u00e5geb\u00e4ck, Olof Mogren, Nina Tahmasebi, and Devdatt Dubhashi. 2014. Extractive summariza- tion using continuous vector space models. In Pro- ceedings of the Workshop on Continuous Vector Space Models and their Compositionality. Gothen- burg, Sweden, pages 31-39.\n\nA trainable document summarizer. Julian Kupiec, Jan Pedersen, Francine Chen, Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. the 18th Annual International ACM SIGIR Conference on Research and Development in Information RetrievalSeattle, Washington, USAJulian Kupiec, Jan Pedersen, and Francine Chen. 1995. A trainable document summarizer. In Proceed- ings of the 18th Annual International ACM SIGIR Conference on Research and Development in Infor- mation Retrieval. Seattle, Washington, USA, pages 406-407.\n\nMolding CNNs for text: Non-linear, nonconsecutive convolutions. Tao Lei, Regina Barzilay, Tommi Jaakkola, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalTao Lei, Regina Barzilay, and Tommi Jaakkola. 2015. Molding CNNs for text: Non-linear, non- consecutive convolutions. In Proceedings of the 2015 Conference on Empirical Methods in Natu- ral Language Processing. Lisbon, Portugal, pages 1565-1575.\n\nA hierarchical neural autoencoder for paragraphs and documents. Jiwei Li, Thang Luong, Dan Jurafsky, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing. the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language ProcessingBeijing, ChinaJiwei Li, Thang Luong, and Dan Jurafsky. 2015. A hierarchical neural autoencoder for paragraphs and documents. In Proceedings of the 53rd Annual Meeting of the Association for Computational Lin- guistics and the 7th International Joint Conference on Natural Language Processing. Beijing, China, pages 1106-1115.\n\nDeep reinforcement learning for dialogue generation. Jiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, Jianfeng Gao, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingAustin, TexasJiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, and Jianfeng Gao. 2016. Deep rein- forcement learning for dialogue generation. In Pro- ceedings of the 2016 Conference on Empirical Meth- ods in Natural Language Processing. Austin, Texas, pages 1192-1202.\n\nEnhancing diversity, coverage and balance for summarization through structure learning. Liangda Li, Ke Zhou, Gui-Rong Xue, Hongyuan Zha, Yong Yu, Proceedings of the 18th international Conference on World Wide Web. the 18th international Conference on World Wide WebMadrid, SpainLiangda Li, Ke Zhou, Gui-Rong Xue, Hongyuan Zha, and Yong Yu. 2009. Enhancing diversity, cover- age and balance for summarization through struc- ture learning. In Proceedings of the 18th inter- national Conference on World Wide Web. Madrid, Spain, pages 71-80.\n\nAutomatic evaluation of summaries using n-gram cooccurrence statistics. Chin-Yew Lin, Eduard Hovy, Proceedings of the. theChin-Yew Lin and Eduard Hovy. 2003. Auto- matic evaluation of summaries using n-gram co- occurrence statistics. In Proceedings of the\n\nHuman Language Technology Conference of the North American Chapter of the Association for Computational Linguistics. Edmonton, CanadaHuman Language Technology Conference of the North American Chapter of the Association for Computational Linguistics. Edmonton, Canada, pages 71-78.\n\nAutomatic Summarization. Natural language processing. Inderjeet Mani, John Benjamins Publishing CompanyInderjeet Mani. 2001. Automatic Summarization. Nat- ural language processing. John Benjamins Publish- ing Company.\n\nSUMMAC: A text summarization evaluation. Inderjeet Mani, Gary Klein, David House, Lynette Hirschman, Therese Firmin, Beth Sundheim, Natural Language Engineering. 814368Inderjeet Mani, Gary Klein, David House, Lynette Hirschman, Therese Firmin, and Beth Sundheim. 2002. SUMMAC: A text summarization evaluation. Natural Language Engineering 8(1):4368.\n\nRhetorical Structure Theory: Toward a functional theory of text organization. C William, Sandra A Mann, Thompson, Text. 83William C. Mann and Sandra A. Thompson. 1988. Rhetorical Structure Theory: Toward a functional theory of text organization. Text 8(3):243-281.\n\nTextRank: Bringing order into texts. Rada Mihalcea, Paul Tarau, Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing. the 2004 Conference on Empirical Methods in Natural Language ProcessingBarcelona, SpainRada Mihalcea and Paul Tarau. 2004. TextRank: Bringing order into texts. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing. Barcelona, Spain, pages 404- 411.\n\nDistributed representations of words and phrases and their compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean, Advances in Neural Information Processing Systems 26. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor- rado, and Jeffrey Dean. 2013. Distributed represen- tations of words and phrases and their composition- ality. In Advances in Neural Information Processing Systems 26. pages 3111-3119.\n\nTowards the use of deep reinforcement learning with global policy for querybased extractive summarisation. Proceedings of the Australasian Language Technology Association Workshop. the Australasian Language Technology Association WorkshopBrisbane, AustraliaDiego Moll\u00e1-Aliod. 2017. Towards the use of deep re- inforcement learning with global policy for query- based extractive summarisation. In Proceedings of the Australasian Language Technology Association Workshop 2017. Brisbane, Australia, pages 103- 107.\n\nThe effects and limitations of automated text condensing on reading comprehension performance. Andrew H Morris, George M Kasper, Dennis A Adams, Information Systems Research. 31Andrew H. Morris, George M. Kasper, and Dennis A. Adams. 1992. The effects and limitations of au- tomated text condensing on reading comprehen- sion performance. Information Systems Research 3(1):17-35.\n\nSummaRuNNer: A recurrent neural network based sequence model for extractive summarization of documents. Ramesh Nallapati, Feifei Zhai, Bowen Zhou, Proceedings of the 31st AAAI Conference on Artificial Intelligence. the 31st AAAI Conference on Artificial IntelligenceSan Francisco, California USARamesh Nallapati, Feifei Zhai, and Bowen Zhou. 2017. SummaRuNNer: A recurrent neural network based sequence model for extractive summarization of documents. In Proceedings of the 31st AAAI Confer- ence on Artificial Intelligence. San Francisco, Cali- fornia USA, pages 3075-3081.\n\nAbstractive text summarization using sequence-tosequence RNNs and beyond. Ramesh Nallapati, Bowen Zhou, C\u00edcero Nogueira, Santos, Bing Aglar G\u00fcl\u00e7ehre, Xiang, Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning. the 20th SIGNLL Conference on Computational Natural Language LearningBerlin, GermanyRamesh Nallapati, Bowen Zhou, C\u00edcero Nogueira dos Santos, \u00c7 aglar G\u00fcl\u00e7ehre, and Bing Xiang. 2016. Abstractive text summarization using sequence-to- sequence RNNs and beyond. In Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning. Berlin, Germany, pages 280- 290.\n\nNeural extractive summarization with side information. Shashi Narayan, Nikos Papasarantopoulos, Shay B Cohen, Mirella Lapata, CoRR abs/1704.04530Shashi Narayan, Nikos Papasarantopoulos, Shay B. Cohen, and Mirella Lapata. 2017. Neural extrac- tive summarization with side information. CoRR abs/1704.04530.\n\nAutomatic summarization. Ani Nenkova, Kathleen Mckeown, Foundations and Trends in Information Retrieval. 52-3Ani Nenkova and Kathleen McKeown. 2011. Auto- matic summarization. Foundations and Trends in Information Retrieval 5(2-3):103-233.\n\nA compositional context sensitive multi-document summarizer: Exploring the factors that influence summarization. Ani Nenkova, Lucy Vanderwende, Kathleen Mckeown, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. the 29th Annual International ACM SIGIR Conference on Research and Development in Information RetrievalAni Nenkova, Lucy Vanderwende, and Kathleen McK- eown. 2006. A compositional context sensitive multi-document summarizer: Exploring the factors that influence summarization. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Re- trieval. pages 573-580.\n\nTaskoriented query reformulation with reinforcement learning. Rodrigo Nogueira, Kyunghyun Cho, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkRodrigo Nogueira and Kyunghyun Cho. 2017. Task- oriented query reformulation with reinforcement learning. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Process- ing. Copenhagen, Denmark, pages 585-594.\n\nTopical coherence for graph-based extractive summarization. Daraksha Parveen, Michael Hans-Martin Ramsl, Strube, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalDaraksha Parveen, Hans-Martin Ramsl, and Michael Strube. 2015. Topical coherence for graph-based ex- tractive summarization. In Proceedings of the 2015 Conference on Empirical Methods in Natural Lan- guage Processing. Lisbon, Portugal, pages 1949- 1954.\n\nA deep reinforced model for abstractive summarization. Romain Paulus, Caiming Xiong, Richard Socher, CoRR abs/1705.04304Romain Paulus, Caiming Xiong, and Richard Socher. 2017. A deep reinforced model for abstractive sum- marization. CoRR abs/1705.04304.\n\nMEAD -A platform for multidocument multilingual text summarization. Dragomir Radev, Timothy Allison, Sasha Blair-Goldensohn, John Blitzer, Arda \u00c7 Elebi, Stanko Dimitrov, Elliott Drabek, Ali Hakim, Wai Lam, Danyu Liu, Jahna Otterbacher, Hong Qi, Horacio Saggion, Simone Teufel, Michael Topper, Adam Winkel, Zhu Zhang, Proceedings of the 4th International Conference on Language Resources and Evaluation. the 4th International Conference on Language Resources and EvaluationLisbon, PortugalDragomir Radev, Timothy Allison, Sasha Blair- Goldensohn, John Blitzer, Arda \u00c7 elebi, Stanko Dimitrov, Elliott Drabek, Ali Hakim, Wai Lam, Danyu Liu, Jahna Otterbacher, Hong Qi, Horacio Saggion, Simone Teufel, Michael Topper, Adam Winkel, and Zhu Zhang. 2004. MEAD -A plat- form for multidocument multilingual text summa- rization. In Proceedings of the 4th International Conference on Language Resources and Evaluation. Lisbon, Portugal, pages 699-702.\n\nSequence level training with recurrent neural networks. Aurelio Marc, Sumit Ranzato, Michael Chopra, Wojciech Auli, Zaremba, CoRR abs/1511.06732Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2015. Sequence level training with recurrent neural networks. CoRR abs/1511.06732.\n\nFear the REAPER: A system for automatic multidocument summarization with reinforcement learning. Cody Rioux, A Sadid, Yllias Hasan, Chali, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. the 2014 Conference on Empirical Methods in Natural Language ProcessingDoha, QatarCody Rioux, Sadid A. Hasan, and Yllias Chali. 2014. Fear the REAPER: A system for automatic multi- document summarization with reinforcement learn- ing. In Proceedings of the 2014 Conference on Em- pirical Methods in Natural Language Processing. Doha, Qatar, pages 681-690.\n\nA neural attention model for abstractive sentence summarization. Alexander M Rush, Sumit Chopra, Jason Weston, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAlexander M. Rush, Sumit Chopra, and Jason Weston. 2015. A neural attention model for abstractive sen- tence summarization. In Proceedings of the 2015 Conference on Empirical Methods in Natural Lan- guage Processing. Lisbon, Portugal, pages 379-389.\n\nFramework of automatic text summarization using reinforcement learning. Seonggi Ryang, Takeshi Abekawa, Proceedings of the 2012. the 2012Seonggi Ryang and Takeshi Abekawa. 2012. Frame- work of automatic text summarization using rein- forcement learning. In Proceedings of the 2012\n\nJoint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. KoreaJoint Conference on Empirical Methods in Natu- ral Language Processing and Computational Nat- ural Language Learning. Jeju Island, Korea, pages 256-265.\n\nFastSum: Fast and accurate query-based multidocument summarization. Frank Schilder, Ravikumar Kondadadi, Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics and HLT: Short Papers. Columbus. the 45th Annual Meeting of the Association of Computational Linguistics and HLT: Short Papers. ColumbusOhio, USAFrank Schilder and Ravikumar Kondadadi. 2008. FastSum: Fast and accurate query-based multi- document summarization. In Proceedings of the 45th Annual Meeting of the Association of Compu- tational Linguistics and HLT: Short Papers. Colum- bus, Ohio, USA, pages 205-208.\n\nThe limits of automatic summarisation according to rouge. Natalie Schluter, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Short Papers. the 15th Conference of the European Chapter of the Association for Computational Linguistics: Short PapersValencia, SpainNatalie Schluter. 2017. The limits of automatic sum- marisation according to rouge. In Proceedings of the 15th Conference of the European Chapter of the As- sociation for Computational Linguistics: Short Pa- pers. Valencia, Spain, pages 41-45.\n\nGet to the point: Summarization with pointergenerator networks. Abigail See, J Peter, Christopher D Liu, Manning, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAbigail See, Peter J. Liu, and Christopher D. Manning. 2017. Get to the point: Summarization with pointer- generator networks. In Proceedings of the 55th An- nual Meeting of the Association for Computational Linguistics. Vancouver, Canada, pages 1073-1083.\n\nDocument summarization using conditional random fields. Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang, Zheng Chen, Proceedings of the 20th International Joint Conference on Artifical intelligence. the 20th International Joint Conference on Artifical intelligenceHyderabad, IndiaDou Shen, Jian-Tao Sun, Hua Li, Qiang Yang, and Zheng Chen. 2007. Document summarization us- ing conditional random fields. In Proceedings of the 20th International Joint Conference on Artifical in- telligence. Hyderabad, India, pages 2862-2867.\n\nMinimum risk training for neural machine translation. Shiqi Shen, Yong Cheng, Zhongjun He, Wei He, Hua Wu, Maosong Sun, Yang Liu, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Berlin, Germany. the 54th Annual Meeting of the Association for Computational Linguistics. Berlin, GermanyShiqi Shen, Yong Cheng, Zhongjun He, Wei He, Hua Wu, Maosong Sun, and Yang Liu. 2016. Minimum risk training for neural machine translation. In Pro- ceedings of the 54th Annual Meeting of the Asso- ciation for Computational Linguistics. Berlin, Ger- many, pages 1683-1692.\n\nAutomatic summarising: The state of the art. Karen Sp\u00e4rck, Jones , Information Processing and Management. 436Karen Sp\u00e4rck Jones. 2007. Automatic summarising: The state of the art. Information Processing and Management 43(6):1449-1481.\n\nSequence to sequence learning with neural networks. Ilya Sutskever, Oriol Vinyals, V Quoc, Le, Advances in Neural Information Processing Systems 27. Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural net- works. In Advances in Neural Information Process- ing Systems 27. pages 3104-3112.\n\nReinforcement Learning : An Introduction. Richard S Sutton, Andrew G Barto, MIT PressRichard S. Sutton and Andrew G. Barto. 1998. Rein- forcement Learning : An Introduction. MIT Press.\n\nEnhancing singledocument summarization by combining ranknet and third-party sources. Krysta Marie Svore, Lucy Vanderwende, Christopher J C Burges, Proceedings of the. theKrysta Marie Svore, Lucy Vanderwende, and Christo- pher J. C. Burges. 2007. Enhancing single- document summarization by combining ranknet and third-party sources. In Proceedings of the 2007\n\nNatural Language Processing and Computational Natural Language Learning. Prague, Czech RepublicJoint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Prague, Czech Republic, pages 448-457.\n\nAbstractive document summarization with a graph-based attentional neural model. Jiwei Tan, Xiaojun Wan, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaJiwei Tan and Xiaojun Wan. 2017. Abstractive docu- ment summarization with a graph-based attentional neural model. In Proceedings of the 55th Annual Meeting of the Association for Computational Lin- guistics. Vancouver, Canada, pages 1171-1181.\n\nSentence extraction as a classification task. Simone Teufel, Marc Moens, Proceedings of ACL Workshop on Intelligent and Scalable Text Summarization. ACL Workshop on Intelligent and Scalable Text SummarizationMadrid, SpainSimone Teufel and Marc Moens. 1997. Sentence ex- traction as a classification task. In Proceedings of ACL Workshop on Intelligent and Scalable Text Sum- marization. Madrid, Spain, pages 58-65.\n\nTowards a unified approach to simultaneous single-document and multi-document summarizations. Xiaojun Wan, Proceedings of the 23rd International Conference on Computational Linguistics. the 23rd International Conference on Computational LinguisticsBeijing, ChinaXiaojun Wan. 2010. Towards a unified approach to simultaneous single-document and multi-document summarizations. In Proceedings of the 23rd Inter- national Conference on Computational Linguistics. Beijing, China, pages 1137-1145.\n\nSimple statistical gradientfollowing algorithms for connectionist reinforcement learning. Ronald J Williams, Machine Learning. 83-4Ronald J. Williams. 1992. Simple statistical gradient- following algorithms for connectionist reinforce- ment learning. Machine Learning 8(3-4):229-256.\n\nAutomatic generation of story highlights. Kristian Woodsend, Mirella Lapata, Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. the 48th Annual Meeting of the Association for Computational LinguisticsUppsala, SwedenKristian Woodsend and Mirella Lapata. 2010. Auto- matic generation of story highlights. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Uppsala, Sweden, pages 565-574.\n\nMultiple aspect summarization using integer linear programming. Kristian Woodsend, Mirella Lapata, Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language LearningKoreaKristian Woodsend and Mirella Lapata. 2012. Multi- ple aspect summarization using integer linear pro- gramming. In Proceedings of the 2012 Joint Con- ference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Jeju Island, Korea, pages 233-243.\n\nShow, attend and tell: Neural image caption generation with visual attention. Kelvin Xu, Jimmy Lei Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard S Zemel, Yoshua Bengio, Proceedings of the 32nd International Conference on Machine Learning. the 32nd International Conference on Machine LearningLille, FranceKelvin Xu, Jimmy Lei Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard S. Zemel, and Yoshua Bengio. 2015. Show, attend and tell: Neural image caption generation with visual attention. In Proceedings of the 32nd In- ternational Conference on Machine Learning. Lille, France, pages 2048-2057.\n\nGraph-based neural multi-document summarization. Michihiro Yasunaga, Rui Zhang, Kshitijh Meelu, Ayush Pareek, Krishnan Srinivasan, Dragomir Radev, Proceedings of the 21st Conference on Computational Natural Language Learning. the 21st Conference on Computational Natural Language LearningVancouver, CanadaMichihiro Yasunaga, Rui Zhang, Kshitijh Meelu, Ayush Pareek, Krishnan Srinivasan, and Dragomir Radev. 2017. Graph-based neural multi-document summarization. In Proceedings of the 21st Confer- ence on Computational Natural Language Learning. Vancouver, Canada, pages 452-462.\n\nMulti-document summarization by maximizing informative content-words. Joshua Wen-Tau Yih, Lucy Goodman, Hisami Vanderwende, Suzuki, Proceedings of the 20th International Joint Conference on Artifical intelligence. the 20th International Joint Conference on Artifical intelligenceHyderabad, IndiaWen-tau Yih, Joshua Goodman, Lucy Vanderwende, and Hisami Suzuki. 2007. Multi-document summa- rization by maximizing informative content-words. In Proceedings of the 20th International Joint Con- ference on Artifical intelligence. Hyderabad, India, pages 1776-1782.\n\nOptimizing sentence modeling and selection for document summarization. Wenpeng Yin, Yulong Pei, Proceedings of the 24th International Joint Conference on Artificial Intelligence. the 24th International Joint Conference on Artificial IntelligenceBuenos Aires, ArgentinaWenpeng Yin and Yulong Pei. 2015. Optimizing sen- tence modeling and selection for document summa- rization. In Proceedings of the 24th International Joint Conference on Artificial Intelligence. Buenos Aires, Argentina, pages 1383-1389.\n\nCharacter-level convolutional networks for text classification. Xiang Zhang, Junbo Zhao, Yann Lecun, Advances in Neural Information Processing Systems 28. Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level convolutional networks for text clas- sification. In Advances in Neural Information Pro- cessing Systems 28. pages 649-657.\n\nSentence simplification with deep reinforcement learning. Xingxing Zhang, Mirella Lapata, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkXingxing Zhang and Mirella Lapata. 2017. Sentence simplification with deep reinforcement learning. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Copen- hagen, Denmark, pages 595-605.\n", "annotations": {"author": "[{\"end\":260,\"start\":89},{\"end\":406,\"start\":261},{\"end\":554,\"start\":407}]", "publisher": null, "author_last_name": "[{\"end\":103,\"start\":96},{\"end\":273,\"start\":268},{\"end\":421,\"start\":415}]", "author_first_name": "[{\"end\":95,\"start\":89},{\"end\":265,\"start\":261},{\"end\":267,\"start\":266},{\"end\":414,\"start\":407}]", "author_affiliation": "[{\"end\":259,\"start\":129},{\"end\":405,\"start\":275},{\"end\":553,\"start\":423}]", "title": "[{\"end\":75,\"start\":1},{\"end\":629,\"start\":555}]", "venue": null, "abstract": "[{\"end\":1355,\"start\":642}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b40\"},\"end\":1944,\"start\":1919},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":2422,\"start\":2398},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":2470,\"start\":2451},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":2493,\"start\":2470},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":2510,\"start\":2493},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":2528,\"start\":2510},{\"end\":2544,\"start\":2528},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2890,\"start\":2867},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3129,\"start\":3105},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3152,\"start\":3129},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3173,\"start\":3152},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":3195,\"start\":3173},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3939,\"start\":3919},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4450,\"start\":4426},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":4471,\"start\":4450},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":4494,\"start\":4471},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5133,\"start\":5111},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7098,\"start\":7074},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":7121,\"start\":7098},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":7142,\"start\":7121},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7540,\"start\":7516},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7550,\"start\":7540},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7576,\"start\":7550},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":7595,\"start\":7576},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7612,\"start\":7595},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7635,\"start\":7612},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":7729,\"start\":7712},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8867,\"start\":8833},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":9040,\"start\":9016},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9056,\"start\":9040},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9079,\"start\":9056},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":9100,\"start\":9079},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":9260,\"start\":9241},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":9283,\"start\":9260},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":9945,\"start\":9929},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10560,\"start\":10540},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12147,\"start\":12124},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":12181,\"start\":12155},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":12419,\"start\":12399},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":12436,\"start\":12419},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":12459,\"start\":12436},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":15241,\"start\":15217},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":15421,\"start\":15399},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":16328,\"start\":16304},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":17165,\"start\":17149},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":19337,\"start\":19314},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":19693,\"start\":19673},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":19716,\"start\":19693},{\"end\":19997,\"start\":19969},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":20046,\"start\":20027},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20501,\"start\":20479},{\"end\":20556,\"start\":20550},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":20780,\"start\":20756},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":20802,\"start\":20780},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":20826,\"start\":20802},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":20843,\"start\":20826},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":20861,\"start\":20843},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21789,\"start\":21768},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":23449,\"start\":23432},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":24008,\"start\":23990},{\"end\":24713,\"start\":24682},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":24798,\"start\":24778},{\"end\":24978,\"start\":24977},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25224,\"start\":25201},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":25282,\"start\":25259},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":25393,\"start\":25370},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":25412,\"start\":25395},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":25436,\"start\":25418},{\"end\":25439,\"start\":25438},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":25572,\"start\":25556},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":25814,\"start\":25797},{\"end\":26571,\"start\":26570},{\"end\":26948,\"start\":26947},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":27082,\"start\":27059},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":27109,\"start\":27086},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":27132,\"start\":27114},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":27703,\"start\":27682},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":27721,\"start\":27703},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":27745,\"start\":27721},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":28759,\"start\":28742},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":28894,\"start\":28870},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":29680,\"start\":29657},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":29702,\"start\":29685},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":30110,\"start\":30087},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":30213,\"start\":30190},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":30471,\"start\":30448},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":30791,\"start\":30768},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":30808,\"start\":30791},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":30826,\"start\":30808},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":30909,\"start\":30885},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":31310,\"start\":31293},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":31844,\"start\":31827},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":32095,\"start\":32078},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":32517,\"start\":32500},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":32709,\"start\":32692},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":33160,\"start\":33143},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":33331,\"start\":33314},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":33459,\"start\":33442},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":33678,\"start\":33657},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":33689,\"start\":33678},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":33725,\"start\":33689},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":33746,\"start\":33725},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":33765,\"start\":33746},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":33871,\"start\":33843},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":33894,\"start\":33871},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":33916,\"start\":33894},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":33941,\"start\":33916},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":33959,\"start\":33941},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":33988,\"start\":33959},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":33998,\"start\":33988},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":34185,\"start\":34167},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":34241,\"start\":34210},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":34258,\"start\":34241},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":34316,\"start\":34289},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":34346,\"start\":34316},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":34372,\"start\":34346},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":34398,\"start\":34372},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":34419,\"start\":34398},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":34474,\"start\":34451},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":34492,\"start\":34474},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34515,\"start\":34492},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":34538,\"start\":34515},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":35207,\"start\":35183},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":35518,\"start\":35498},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":35616,\"start\":35598},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":36188,\"start\":36172},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":36339,\"start\":36317},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":36359,\"start\":36339},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":36423,\"start\":36399},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":36446,\"start\":36423},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":37236,\"start\":37211}]", "figure": "[{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40315,\"start\":37316},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":40414,\"start\":40316},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":40682,\"start\":40415}]", "paragraph": "[{\"end\":1975,\"start\":1371},{\"end\":2951,\"start\":1977},{\"end\":3985,\"start\":2953},{\"end\":5041,\"start\":3987},{\"end\":5833,\"start\":5043},{\"end\":6295,\"start\":5835},{\"end\":7001,\"start\":6333},{\"end\":7143,\"start\":7003},{\"end\":7310,\"start\":7145},{\"end\":7451,\"start\":7312},{\"end\":7842,\"start\":7453},{\"end\":8577,\"start\":7844},{\"end\":9284,\"start\":8598},{\"end\":10386,\"start\":9286},{\"end\":11000,\"start\":10388},{\"end\":11381,\"start\":11039},{\"end\":11426,\"start\":11423},{\"end\":12868,\"start\":11428},{\"end\":12967,\"start\":12870},{\"end\":13695,\"start\":12969},{\"end\":14447,\"start\":13697},{\"end\":15145,\"start\":14449},{\"end\":16183,\"start\":15194},{\"end\":17218,\"start\":16203},{\"end\":17432,\"start\":17246},{\"end\":17689,\"start\":17477},{\"end\":17966,\"start\":17732},{\"end\":18931,\"start\":18041},{\"end\":20047,\"start\":18933},{\"end\":20378,\"start\":20070},{\"end\":20502,\"start\":20405},{\"end\":21720,\"start\":20504},{\"end\":22035,\"start\":21722},{\"end\":22154,\"start\":22037},{\"end\":22321,\"start\":22156},{\"end\":22460,\"start\":22336},{\"end\":22600,\"start\":22462},{\"end\":22754,\"start\":22612},{\"end\":22873,\"start\":22756},{\"end\":22992,\"start\":22875},{\"end\":23281,\"start\":22994},{\"end\":23636,\"start\":23283},{\"end\":24059,\"start\":23638},{\"end\":24714,\"start\":24061},{\"end\":26761,\"start\":24716},{\"end\":27452,\"start\":26763},{\"end\":28115,\"start\":27454},{\"end\":29349,\"start\":28117},{\"end\":29877,\"start\":29361},{\"end\":30252,\"start\":29921},{\"end\":30631,\"start\":30254},{\"end\":32234,\"start\":30633},{\"end\":32710,\"start\":32236},{\"end\":33460,\"start\":32712},{\"end\":34420,\"start\":33477},{\"end\":34989,\"start\":34422},{\"end\":36594,\"start\":34991},{\"end\":37315,\"start\":36610}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11422,\"start\":11382},{\"attributes\":{\"id\":\"formula_1\"},\"end\":17245,\"start\":17219},{\"attributes\":{\"id\":\"formula_2\"},\"end\":17476,\"start\":17433},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18040,\"start\":17967}]", "table_ref": "[{\"end\":12374,\"start\":12367},{\"end\":12654,\"start\":12647},{\"end\":12662,\"start\":12655},{\"end\":13547,\"start\":13540},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":27450,\"start\":27443},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":29943,\"start\":29936},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":31589,\"start\":31574},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":31957,\"start\":31950},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":32345,\"start\":32338},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":32746,\"start\":32739},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":32790,\"start\":32783}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1369,\"start\":1357},{\"attributes\":{\"n\":\"2\"},\"end\":6331,\"start\":6298},{\"end\":8596,\"start\":8580},{\"attributes\":{\"n\":\"3\"},\"end\":11037,\"start\":11003},{\"attributes\":{\"n\":\"4\"},\"end\":15192,\"start\":15148},{\"attributes\":{\"n\":\"4.1\"},\"end\":16201,\"start\":16186},{\"attributes\":{\"n\":\"4.2\"},\"end\":17730,\"start\":17692},{\"attributes\":{\"n\":\"5\"},\"end\":20068,\"start\":20050},{\"end\":20403,\"start\":20381},{\"end\":22334,\"start\":22324},{\"end\":22610,\"start\":22603},{\"attributes\":{\"n\":\"6\"},\"end\":29359,\"start\":29352},{\"end\":29919,\"start\":29880},{\"attributes\":{\"n\":\"7\"},\"end\":33475,\"start\":33463},{\"attributes\":{\"n\":\"8\"},\"end\":36608,\"start\":36597},{\"end\":40326,\"start\":40317},{\"end\":40425,\"start\":40416}]", "table": "[{\"end\":40315,\"start\":38027},{\"end\":40414,\"start\":40371}]", "figure_caption": "[{\"end\":38027,\"start\":37318},{\"end\":40371,\"start\":40328},{\"end\":40682,\"start\":40427}]", "figure_ref": "[{\"end\":7269,\"start\":7261},{\"end\":8387,\"start\":8379},{\"end\":9590,\"start\":9582},{\"end\":16264,\"start\":16256},{\"end\":23363,\"start\":23355},{\"end\":25160,\"start\":25152},{\"end\":26568,\"start\":26560},{\"end\":28497,\"start\":28489}]", "bib_author_first_name": "[{\"end\":40935,\"start\":40929},{\"end\":40937,\"start\":40936},{\"end\":40948,\"start\":40947},{\"end\":40950,\"start\":40949},{\"end\":41492,\"start\":41485},{\"end\":41512,\"start\":41503},{\"end\":41524,\"start\":41518},{\"end\":41989,\"start\":41983},{\"end\":42007,\"start\":42000},{\"end\":42442,\"start\":42438},{\"end\":42456,\"start\":42451},{\"end\":42473,\"start\":42466},{\"end\":42486,\"start\":42482},{\"end\":42820,\"start\":42814},{\"end\":42842,\"start\":42839},{\"end\":42855,\"start\":42852},{\"end\":43439,\"start\":43432},{\"end\":43453,\"start\":43445},{\"end\":43466,\"start\":43460},{\"end\":43477,\"start\":43471},{\"end\":43486,\"start\":43482},{\"end\":43496,\"start\":43492},{\"end\":43997,\"start\":43992},{\"end\":44013,\"start\":44009},{\"end\":44659,\"start\":44652},{\"end\":44673,\"start\":44668},{\"end\":44687,\"start\":44683},{\"end\":44700,\"start\":44698},{\"end\":45067,\"start\":45063},{\"end\":45081,\"start\":45074},{\"end\":45094,\"start\":45087},{\"end\":45103,\"start\":45101},{\"end\":45112,\"start\":45109},{\"end\":45592,\"start\":45584},{\"end\":45607,\"start\":45600},{\"end\":46067,\"start\":46062},{\"end\":46083,\"start\":46076},{\"end\":46309,\"start\":46304},{\"end\":46326,\"start\":46321},{\"end\":46339,\"start\":46335},{\"end\":46355,\"start\":46348},{\"end\":46369,\"start\":46364},{\"end\":46388,\"start\":46383},{\"end\":46721,\"start\":46716},{\"end\":46737,\"start\":46729},{\"end\":46739,\"start\":46738},{\"end\":47014,\"start\":47009},{\"end\":47034,\"start\":47025},{\"end\":47424,\"start\":47419},{\"end\":47443,\"start\":47436},{\"end\":47461,\"start\":47455},{\"end\":47463,\"start\":47462},{\"end\":47482,\"start\":47476},{\"end\":47496,\"start\":47491},{\"end\":48048,\"start\":48039},{\"end\":48061,\"start\":48055},{\"end\":48076,\"start\":48071},{\"end\":48683,\"start\":48679},{\"end\":48705,\"start\":48700},{\"end\":48721,\"start\":48715},{\"end\":48741,\"start\":48736},{\"end\":48756,\"start\":48752},{\"end\":48769,\"start\":48762},{\"end\":48784,\"start\":48780},{\"end\":49125,\"start\":49121},{\"end\":49144,\"start\":49138},{\"end\":49345,\"start\":49342},{\"end\":49366,\"start\":49360},{\"end\":49385,\"start\":49381},{\"end\":49891,\"start\":49887},{\"end\":50310,\"start\":50306},{\"end\":50322,\"start\":50316},{\"end\":50337,\"start\":50332},{\"end\":50355,\"start\":50346},{\"end\":50357,\"start\":50356},{\"end\":50774,\"start\":50773},{\"end\":50790,\"start\":50785},{\"end\":51231,\"start\":51225},{\"end\":51246,\"start\":51242},{\"end\":51259,\"start\":51255},{\"end\":51278,\"start\":51271},{\"end\":51791,\"start\":51785},{\"end\":51803,\"start\":51800},{\"end\":51822,\"start\":51814},{\"end\":52399,\"start\":52396},{\"end\":52411,\"start\":52405},{\"end\":52427,\"start\":52422},{\"end\":52929,\"start\":52924},{\"end\":52939,\"start\":52934},{\"end\":52950,\"start\":52947},{\"end\":53655,\"start\":53650},{\"end\":53664,\"start\":53660},{\"end\":53677,\"start\":53673},{\"end\":53689,\"start\":53686},{\"end\":53706,\"start\":53700},{\"end\":53723,\"start\":53715},{\"end\":54268,\"start\":54261},{\"end\":54275,\"start\":54273},{\"end\":54290,\"start\":54282},{\"end\":54304,\"start\":54296},{\"end\":54314,\"start\":54310},{\"end\":54793,\"start\":54785},{\"end\":54805,\"start\":54799},{\"end\":55315,\"start\":55306},{\"end\":55521,\"start\":55512},{\"end\":55532,\"start\":55528},{\"end\":55545,\"start\":55540},{\"end\":55560,\"start\":55553},{\"end\":55579,\"start\":55572},{\"end\":55592,\"start\":55588},{\"end\":55901,\"start\":55900},{\"end\":55917,\"start\":55911},{\"end\":55919,\"start\":55918},{\"end\":56129,\"start\":56125},{\"end\":56144,\"start\":56140},{\"end\":56608,\"start\":56603},{\"end\":56622,\"start\":56618},{\"end\":56637,\"start\":56634},{\"end\":56648,\"start\":56644},{\"end\":56665,\"start\":56658},{\"end\":57577,\"start\":57571},{\"end\":57579,\"start\":57578},{\"end\":57594,\"start\":57588},{\"end\":57596,\"start\":57595},{\"end\":57611,\"start\":57605},{\"end\":57613,\"start\":57612},{\"end\":57967,\"start\":57961},{\"end\":57985,\"start\":57979},{\"end\":57997,\"start\":57992},{\"end\":58513,\"start\":58507},{\"end\":58530,\"start\":58525},{\"end\":58543,\"start\":58537},{\"end\":58566,\"start\":58562},{\"end\":59118,\"start\":59112},{\"end\":59133,\"start\":59128},{\"end\":59157,\"start\":59153},{\"end\":59159,\"start\":59158},{\"end\":59174,\"start\":59167},{\"end\":59391,\"start\":59388},{\"end\":59409,\"start\":59401},{\"end\":59720,\"start\":59717},{\"end\":59734,\"start\":59730},{\"end\":59756,\"start\":59748},{\"end\":60373,\"start\":60366},{\"end\":60393,\"start\":60384},{\"end\":60881,\"start\":60873},{\"end\":60898,\"start\":60891},{\"end\":61417,\"start\":61411},{\"end\":61433,\"start\":61426},{\"end\":61448,\"start\":61441},{\"end\":61687,\"start\":61679},{\"end\":61702,\"start\":61695},{\"end\":61717,\"start\":61712},{\"end\":61740,\"start\":61736},{\"end\":61754,\"start\":61750},{\"end\":61756,\"start\":61755},{\"end\":61770,\"start\":61764},{\"end\":61788,\"start\":61781},{\"end\":61800,\"start\":61797},{\"end\":61811,\"start\":61808},{\"end\":61822,\"start\":61817},{\"end\":61833,\"start\":61828},{\"end\":61851,\"start\":61847},{\"end\":61863,\"start\":61856},{\"end\":61879,\"start\":61873},{\"end\":61895,\"start\":61888},{\"end\":61908,\"start\":61904},{\"end\":61920,\"start\":61917},{\"end\":62617,\"start\":62610},{\"end\":62629,\"start\":62624},{\"end\":62646,\"start\":62639},{\"end\":62663,\"start\":62655},{\"end\":62955,\"start\":62951},{\"end\":62964,\"start\":62963},{\"end\":62978,\"start\":62972},{\"end\":63512,\"start\":63503},{\"end\":63514,\"start\":63513},{\"end\":63526,\"start\":63521},{\"end\":63540,\"start\":63535},{\"end\":64054,\"start\":64047},{\"end\":64069,\"start\":64062},{\"end\":64603,\"start\":64598},{\"end\":64623,\"start\":64614},{\"end\":65202,\"start\":65195},{\"end\":65773,\"start\":65766},{\"end\":65780,\"start\":65779},{\"end\":65799,\"start\":65788},{\"end\":65801,\"start\":65800},{\"end\":66311,\"start\":66308},{\"end\":66326,\"start\":66318},{\"end\":66335,\"start\":66332},{\"end\":66345,\"start\":66340},{\"end\":66357,\"start\":66352},{\"end\":66833,\"start\":66828},{\"end\":66844,\"start\":66840},{\"end\":66860,\"start\":66852},{\"end\":66868,\"start\":66865},{\"end\":66876,\"start\":66873},{\"end\":66888,\"start\":66881},{\"end\":66898,\"start\":66894},{\"end\":67422,\"start\":67417},{\"end\":67436,\"start\":67431},{\"end\":67664,\"start\":67660},{\"end\":67681,\"start\":67676},{\"end\":67692,\"start\":67691},{\"end\":67990,\"start\":67983},{\"end\":67992,\"start\":67991},{\"end\":68007,\"start\":68001},{\"end\":68009,\"start\":68008},{\"end\":68218,\"start\":68212},{\"end\":68224,\"start\":68219},{\"end\":68236,\"start\":68232},{\"end\":68261,\"start\":68250},{\"end\":68265,\"start\":68262},{\"end\":68822,\"start\":68817},{\"end\":68835,\"start\":68828},{\"end\":69317,\"start\":69311},{\"end\":69330,\"start\":69326},{\"end\":69781,\"start\":69774},{\"end\":70269,\"start\":70263},{\"end\":70271,\"start\":70270},{\"end\":70508,\"start\":70500},{\"end\":70526,\"start\":70519},{\"end\":70996,\"start\":70988},{\"end\":71014,\"start\":71007},{\"end\":71662,\"start\":71656},{\"end\":71672,\"start\":71667},{\"end\":71676,\"start\":71673},{\"end\":71685,\"start\":71681},{\"end\":71702,\"start\":71693},{\"end\":71713,\"start\":71708},{\"end\":71731,\"start\":71725},{\"end\":71754,\"start\":71747},{\"end\":71756,\"start\":71755},{\"end\":71770,\"start\":71764},{\"end\":72293,\"start\":72284},{\"end\":72307,\"start\":72304},{\"end\":72323,\"start\":72315},{\"end\":72336,\"start\":72331},{\"end\":72353,\"start\":72345},{\"end\":72374,\"start\":72366},{\"end\":72892,\"start\":72886},{\"end\":72910,\"start\":72906},{\"end\":72926,\"start\":72920},{\"end\":73456,\"start\":73449},{\"end\":73468,\"start\":73462},{\"end\":73953,\"start\":73948},{\"end\":73966,\"start\":73961},{\"end\":73977,\"start\":73973},{\"end\":74293,\"start\":74285},{\"end\":74308,\"start\":74301}]", "bib_author_last_name": "[{\"end\":40945,\"start\":40938},{\"end\":40956,\"start\":40951},{\"end\":40965,\"start\":40958},{\"end\":41501,\"start\":41493},{\"end\":41516,\"start\":41513},{\"end\":41531,\"start\":41525},{\"end\":41998,\"start\":41990},{\"end\":42015,\"start\":42008},{\"end\":42449,\"start\":42443},{\"end\":42464,\"start\":42457},{\"end\":42480,\"start\":42474},{\"end\":42494,\"start\":42487},{\"end\":42837,\"start\":42821},{\"end\":42850,\"start\":42843},{\"end\":42861,\"start\":42856},{\"end\":43443,\"start\":43440},{\"end\":43458,\"start\":43454},{\"end\":43469,\"start\":43467},{\"end\":43480,\"start\":43478},{\"end\":43490,\"start\":43487},{\"end\":43501,\"start\":43497},{\"end\":44007,\"start\":43998},{\"end\":44023,\"start\":44014},{\"end\":44666,\"start\":44660},{\"end\":44681,\"start\":44674},{\"end\":44696,\"start\":44688},{\"end\":44703,\"start\":44701},{\"end\":45072,\"start\":45068},{\"end\":45085,\"start\":45082},{\"end\":45099,\"start\":45095},{\"end\":45107,\"start\":45104},{\"end\":45118,\"start\":45113},{\"end\":45598,\"start\":45593},{\"end\":45614,\"start\":45608},{\"end\":46074,\"start\":46068},{\"end\":46090,\"start\":46084},{\"end\":46319,\"start\":46310},{\"end\":46333,\"start\":46327},{\"end\":46346,\"start\":46340},{\"end\":46362,\"start\":46356},{\"end\":46381,\"start\":46370},{\"end\":46394,\"start\":46389},{\"end\":46727,\"start\":46722},{\"end\":46745,\"start\":46740},{\"end\":47023,\"start\":47015},{\"end\":47051,\"start\":47035},{\"end\":47434,\"start\":47425},{\"end\":47453,\"start\":47444},{\"end\":47474,\"start\":47464},{\"end\":47489,\"start\":47483},{\"end\":47504,\"start\":47497},{\"end\":48053,\"start\":48049},{\"end\":48069,\"start\":48062},{\"end\":48085,\"start\":48077},{\"end\":48698,\"start\":48684},{\"end\":48713,\"start\":48706},{\"end\":48734,\"start\":48722},{\"end\":48750,\"start\":48742},{\"end\":48760,\"start\":48757},{\"end\":48778,\"start\":48770},{\"end\":48792,\"start\":48785},{\"end\":49136,\"start\":49126},{\"end\":49156,\"start\":49145},{\"end\":49358,\"start\":49346},{\"end\":49379,\"start\":49367},{\"end\":49393,\"start\":49386},{\"end\":49895,\"start\":49892},{\"end\":50314,\"start\":50311},{\"end\":50330,\"start\":50323},{\"end\":50344,\"start\":50338},{\"end\":50362,\"start\":50358},{\"end\":50783,\"start\":50775},{\"end\":50797,\"start\":50791},{\"end\":50801,\"start\":50799},{\"end\":51240,\"start\":51232},{\"end\":51253,\"start\":51247},{\"end\":51269,\"start\":51260},{\"end\":51287,\"start\":51279},{\"end\":51798,\"start\":51792},{\"end\":51812,\"start\":51804},{\"end\":51827,\"start\":51823},{\"end\":52403,\"start\":52400},{\"end\":52420,\"start\":52412},{\"end\":52436,\"start\":52428},{\"end\":52932,\"start\":52930},{\"end\":52945,\"start\":52940},{\"end\":52959,\"start\":52951},{\"end\":53658,\"start\":53656},{\"end\":53671,\"start\":53665},{\"end\":53684,\"start\":53678},{\"end\":53698,\"start\":53690},{\"end\":53713,\"start\":53707},{\"end\":53727,\"start\":53724},{\"end\":54271,\"start\":54269},{\"end\":54280,\"start\":54276},{\"end\":54294,\"start\":54291},{\"end\":54308,\"start\":54305},{\"end\":54317,\"start\":54315},{\"end\":54797,\"start\":54794},{\"end\":54810,\"start\":54806},{\"end\":55320,\"start\":55316},{\"end\":55526,\"start\":55522},{\"end\":55538,\"start\":55533},{\"end\":55551,\"start\":55546},{\"end\":55570,\"start\":55561},{\"end\":55586,\"start\":55580},{\"end\":55601,\"start\":55593},{\"end\":55909,\"start\":55902},{\"end\":55924,\"start\":55920},{\"end\":55934,\"start\":55926},{\"end\":56138,\"start\":56130},{\"end\":56150,\"start\":56145},{\"end\":56616,\"start\":56609},{\"end\":56632,\"start\":56623},{\"end\":56642,\"start\":56638},{\"end\":56656,\"start\":56649},{\"end\":56670,\"start\":56666},{\"end\":57586,\"start\":57580},{\"end\":57603,\"start\":57597},{\"end\":57619,\"start\":57614},{\"end\":57977,\"start\":57968},{\"end\":57990,\"start\":57986},{\"end\":58002,\"start\":57998},{\"end\":58523,\"start\":58514},{\"end\":58535,\"start\":58531},{\"end\":58552,\"start\":58544},{\"end\":58560,\"start\":58554},{\"end\":58581,\"start\":58567},{\"end\":58588,\"start\":58583},{\"end\":59126,\"start\":59119},{\"end\":59151,\"start\":59134},{\"end\":59165,\"start\":59160},{\"end\":59181,\"start\":59175},{\"end\":59399,\"start\":59392},{\"end\":59417,\"start\":59410},{\"end\":59728,\"start\":59721},{\"end\":59746,\"start\":59735},{\"end\":59764,\"start\":59757},{\"end\":60382,\"start\":60374},{\"end\":60397,\"start\":60394},{\"end\":60889,\"start\":60882},{\"end\":60916,\"start\":60899},{\"end\":60924,\"start\":60918},{\"end\":61424,\"start\":61418},{\"end\":61439,\"start\":61434},{\"end\":61455,\"start\":61449},{\"end\":61693,\"start\":61688},{\"end\":61710,\"start\":61703},{\"end\":61734,\"start\":61718},{\"end\":61748,\"start\":61741},{\"end\":61762,\"start\":61757},{\"end\":61779,\"start\":61771},{\"end\":61795,\"start\":61789},{\"end\":61806,\"start\":61801},{\"end\":61815,\"start\":61812},{\"end\":61826,\"start\":61823},{\"end\":61845,\"start\":61834},{\"end\":61854,\"start\":61852},{\"end\":61871,\"start\":61864},{\"end\":61886,\"start\":61880},{\"end\":61902,\"start\":61896},{\"end\":61915,\"start\":61909},{\"end\":61926,\"start\":61921},{\"end\":62622,\"start\":62618},{\"end\":62637,\"start\":62630},{\"end\":62653,\"start\":62647},{\"end\":62668,\"start\":62664},{\"end\":62677,\"start\":62670},{\"end\":62961,\"start\":62956},{\"end\":62970,\"start\":62965},{\"end\":62984,\"start\":62979},{\"end\":62991,\"start\":62986},{\"end\":63519,\"start\":63515},{\"end\":63533,\"start\":63527},{\"end\":63547,\"start\":63541},{\"end\":64060,\"start\":64055},{\"end\":64077,\"start\":64070},{\"end\":64612,\"start\":64604},{\"end\":64633,\"start\":64624},{\"end\":65211,\"start\":65203},{\"end\":65777,\"start\":65774},{\"end\":65786,\"start\":65781},{\"end\":65805,\"start\":65802},{\"end\":65814,\"start\":65807},{\"end\":66316,\"start\":66312},{\"end\":66330,\"start\":66327},{\"end\":66338,\"start\":66336},{\"end\":66350,\"start\":66346},{\"end\":66362,\"start\":66358},{\"end\":66838,\"start\":66834},{\"end\":66850,\"start\":66845},{\"end\":66863,\"start\":66861},{\"end\":66871,\"start\":66869},{\"end\":66879,\"start\":66877},{\"end\":66892,\"start\":66889},{\"end\":66902,\"start\":66899},{\"end\":67429,\"start\":67423},{\"end\":67674,\"start\":67665},{\"end\":67689,\"start\":67682},{\"end\":67697,\"start\":67693},{\"end\":67701,\"start\":67699},{\"end\":67999,\"start\":67993},{\"end\":68015,\"start\":68010},{\"end\":68230,\"start\":68225},{\"end\":68248,\"start\":68237},{\"end\":68272,\"start\":68266},{\"end\":68826,\"start\":68823},{\"end\":68839,\"start\":68836},{\"end\":69324,\"start\":69318},{\"end\":69336,\"start\":69331},{\"end\":69785,\"start\":69782},{\"end\":70280,\"start\":70272},{\"end\":70517,\"start\":70509},{\"end\":70533,\"start\":70527},{\"end\":71005,\"start\":70997},{\"end\":71021,\"start\":71015},{\"end\":71665,\"start\":71663},{\"end\":71679,\"start\":71677},{\"end\":71691,\"start\":71686},{\"end\":71706,\"start\":71703},{\"end\":71723,\"start\":71714},{\"end\":71745,\"start\":71732},{\"end\":71762,\"start\":71757},{\"end\":71777,\"start\":71771},{\"end\":72302,\"start\":72294},{\"end\":72313,\"start\":72308},{\"end\":72329,\"start\":72324},{\"end\":72343,\"start\":72337},{\"end\":72364,\"start\":72354},{\"end\":72380,\"start\":72375},{\"end\":72904,\"start\":72893},{\"end\":72918,\"start\":72911},{\"end\":72938,\"start\":72927},{\"end\":72946,\"start\":72940},{\"end\":73460,\"start\":73457},{\"end\":73472,\"start\":73469},{\"end\":73959,\"start\":73954},{\"end\":73971,\"start\":73967},{\"end\":73983,\"start\":73978},{\"end\":74299,\"start\":74294},{\"end\":74315,\"start\":74309}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":5060178},\"end\":41412,\"start\":40838},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":11212020},\"end\":41936,\"start\":41414},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":1584325},\"end\":42361,\"start\":41938},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":1820089},\"end\":42770,\"start\":42363},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":15467396},\"end\":43366,\"start\":42772},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15912169},\"end\":43898,\"start\":43368},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":6334682},\"end\":44566,\"start\":43900},{\"attributes\":{\"id\":\"b7\"},\"end\":45003,\"start\":44568},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":14288483},\"end\":45526,\"start\":45005},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":1499080},\"end\":46012,\"start\":45528},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":16531053},\"end\":46251,\"start\":46014},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":351666},\"end\":46639,\"start\":46253},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":506350},\"end\":46969,\"start\":46641},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":10827006},\"end\":47372,\"start\":46971},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":1992250},\"end\":47949,\"start\":47374},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":12341014},\"end\":48635,\"start\":47951},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":6203757},\"end\":49095,\"start\":48637},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":1915014},\"end\":49284,\"start\":49097},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":1306065},\"end\":49826,\"start\":49286},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":9672033},\"end\":50264,\"start\":49828},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":686481},\"end\":50727,\"start\":50266},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":6628106},\"end\":51160,\"start\":50729},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":17394382},\"end\":51750,\"start\":51162},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":5775833},\"end\":52330,\"start\":51752},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":2146847},\"end\":52858,\"start\":52332},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":207468},\"end\":53595,\"start\":52860},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":3147007},\"end\":54171,\"start\":53597},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":1792271},\"end\":54711,\"start\":54173},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":16292125},\"end\":54968,\"start\":54713},{\"attributes\":{\"id\":\"b29\"},\"end\":55250,\"start\":54970},{\"attributes\":{\"id\":\"b30\"},\"end\":55469,\"start\":55252},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":17214063},\"end\":55820,\"start\":55471},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":60514661},\"end\":56086,\"start\":55822},{\"attributes\":{\"id\":\"b33\"},\"end\":56524,\"start\":56088},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":16447573},\"end\":56961,\"start\":56526},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":23962793},\"end\":57474,\"start\":56963},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":207228587},\"end\":57855,\"start\":57476},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":6405271},\"end\":58431,\"start\":57857},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":8928715},\"end\":59055,\"start\":58433},{\"attributes\":{\"doi\":\"CoRR abs/1704.04530\",\"id\":\"b39\"},\"end\":59361,\"start\":59057},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":5393989},\"end\":59602,\"start\":59363},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":86903},\"end\":60302,\"start\":59604},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":125545},\"end\":60811,\"start\":60304},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":269225},\"end\":61354,\"start\":60813},{\"attributes\":{\"doi\":\"CoRR abs/1705.04304\",\"id\":\"b44\"},\"end\":61609,\"start\":61356},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":10151424},\"end\":62552,\"start\":61611},{\"attributes\":{\"doi\":\"CoRR abs/1511.06732\",\"id\":\"b46\"},\"end\":62852,\"start\":62554},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":10221032},\"end\":63436,\"start\":62854},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":1918428},\"end\":63973,\"start\":63438},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":14666654},\"end\":64255,\"start\":63975},{\"attributes\":{\"id\":\"b50\"},\"end\":64528,\"start\":64257},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":22109805},\"end\":65135,\"start\":64530},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":9403493},\"end\":65700,\"start\":65137},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":8314118},\"end\":66250,\"start\":65702},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":126818},\"end\":66772,\"start\":66252},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":3913537},\"end\":67370,\"start\":66774},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":12824751},\"end\":67606,\"start\":67372},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":7961699},\"end\":67939,\"start\":67608},{\"attributes\":{\"id\":\"b58\"},\"end\":68125,\"start\":67941},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":7290594},\"end\":68486,\"start\":68127},{\"attributes\":{\"id\":\"b60\"},\"end\":68735,\"start\":68488},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":26698484},\"end\":69263,\"start\":68737},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":11846745},\"end\":69678,\"start\":69265},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":17224077},\"end\":70171,\"start\":69680},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":2332513},\"end\":70456,\"start\":70173},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":8015669},\"end\":70922,\"start\":70458},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":17497992},\"end\":71576,\"start\":70924},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":1055111},\"end\":72233,\"start\":71578},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":6532096},\"end\":72814,\"start\":72235},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":7176707},\"end\":73376,\"start\":72816},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":6026194},\"end\":73882,\"start\":73378},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":368182},\"end\":74225,\"start\":73884},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":7473831},\"end\":74722,\"start\":74227}]", "bib_title": "[{\"end\":40927,\"start\":40838},{\"end\":41483,\"start\":41414},{\"end\":41981,\"start\":41938},{\"end\":42436,\"start\":42363},{\"end\":42812,\"start\":42772},{\"end\":43430,\"start\":43368},{\"end\":43990,\"start\":43900},{\"end\":45061,\"start\":45005},{\"end\":45582,\"start\":45528},{\"end\":46060,\"start\":46014},{\"end\":46302,\"start\":46253},{\"end\":46714,\"start\":46641},{\"end\":47007,\"start\":46971},{\"end\":47417,\"start\":47374},{\"end\":48037,\"start\":47951},{\"end\":48677,\"start\":48637},{\"end\":49119,\"start\":49097},{\"end\":49340,\"start\":49286},{\"end\":49885,\"start\":49828},{\"end\":50304,\"start\":50266},{\"end\":50771,\"start\":50729},{\"end\":51223,\"start\":51162},{\"end\":51783,\"start\":51752},{\"end\":52394,\"start\":52332},{\"end\":52922,\"start\":52860},{\"end\":53648,\"start\":53597},{\"end\":54259,\"start\":54173},{\"end\":54783,\"start\":54713},{\"end\":55510,\"start\":55471},{\"end\":55898,\"start\":55822},{\"end\":56123,\"start\":56088},{\"end\":56601,\"start\":56526},{\"end\":57068,\"start\":56963},{\"end\":57569,\"start\":57476},{\"end\":57959,\"start\":57857},{\"end\":58505,\"start\":58433},{\"end\":59386,\"start\":59363},{\"end\":59715,\"start\":59604},{\"end\":60364,\"start\":60304},{\"end\":60871,\"start\":60813},{\"end\":61677,\"start\":61611},{\"end\":62949,\"start\":62854},{\"end\":63501,\"start\":63438},{\"end\":64045,\"start\":63975},{\"end\":64596,\"start\":64530},{\"end\":65193,\"start\":65137},{\"end\":65764,\"start\":65702},{\"end\":66306,\"start\":66252},{\"end\":66826,\"start\":66774},{\"end\":67415,\"start\":67372},{\"end\":67658,\"start\":67608},{\"end\":68210,\"start\":68127},{\"end\":68815,\"start\":68737},{\"end\":69309,\"start\":69265},{\"end\":69772,\"start\":69680},{\"end\":70261,\"start\":70173},{\"end\":70498,\"start\":70458},{\"end\":70986,\"start\":70924},{\"end\":71654,\"start\":71578},{\"end\":72282,\"start\":72235},{\"end\":72884,\"start\":72816},{\"end\":73447,\"start\":73378},{\"end\":73946,\"start\":73884},{\"end\":74283,\"start\":74227}]", "bib_author": "[{\"end\":40947,\"start\":40929},{\"end\":40958,\"start\":40947},{\"end\":40967,\"start\":40958},{\"end\":41503,\"start\":41485},{\"end\":41518,\"start\":41503},{\"end\":41533,\"start\":41518},{\"end\":42000,\"start\":41983},{\"end\":42017,\"start\":42000},{\"end\":42451,\"start\":42438},{\"end\":42466,\"start\":42451},{\"end\":42482,\"start\":42466},{\"end\":42496,\"start\":42482},{\"end\":42839,\"start\":42814},{\"end\":42852,\"start\":42839},{\"end\":42863,\"start\":42852},{\"end\":43445,\"start\":43432},{\"end\":43460,\"start\":43445},{\"end\":43471,\"start\":43460},{\"end\":43482,\"start\":43471},{\"end\":43492,\"start\":43482},{\"end\":43503,\"start\":43492},{\"end\":44009,\"start\":43992},{\"end\":44025,\"start\":44009},{\"end\":44668,\"start\":44652},{\"end\":44683,\"start\":44668},{\"end\":44698,\"start\":44683},{\"end\":44705,\"start\":44698},{\"end\":45074,\"start\":45063},{\"end\":45087,\"start\":45074},{\"end\":45101,\"start\":45087},{\"end\":45109,\"start\":45101},{\"end\":45120,\"start\":45109},{\"end\":45600,\"start\":45584},{\"end\":45616,\"start\":45600},{\"end\":46076,\"start\":46062},{\"end\":46092,\"start\":46076},{\"end\":46321,\"start\":46304},{\"end\":46335,\"start\":46321},{\"end\":46348,\"start\":46335},{\"end\":46364,\"start\":46348},{\"end\":46383,\"start\":46364},{\"end\":46396,\"start\":46383},{\"end\":46729,\"start\":46716},{\"end\":46747,\"start\":46729},{\"end\":47025,\"start\":47009},{\"end\":47053,\"start\":47025},{\"end\":47436,\"start\":47419},{\"end\":47455,\"start\":47436},{\"end\":47476,\"start\":47455},{\"end\":47491,\"start\":47476},{\"end\":47506,\"start\":47491},{\"end\":48055,\"start\":48039},{\"end\":48071,\"start\":48055},{\"end\":48087,\"start\":48071},{\"end\":48700,\"start\":48679},{\"end\":48715,\"start\":48700},{\"end\":48736,\"start\":48715},{\"end\":48752,\"start\":48736},{\"end\":48762,\"start\":48752},{\"end\":48780,\"start\":48762},{\"end\":48794,\"start\":48780},{\"end\":49138,\"start\":49121},{\"end\":49158,\"start\":49138},{\"end\":49360,\"start\":49342},{\"end\":49381,\"start\":49360},{\"end\":49395,\"start\":49381},{\"end\":49897,\"start\":49887},{\"end\":50316,\"start\":50306},{\"end\":50332,\"start\":50316},{\"end\":50346,\"start\":50332},{\"end\":50364,\"start\":50346},{\"end\":50785,\"start\":50773},{\"end\":50799,\"start\":50785},{\"end\":50803,\"start\":50799},{\"end\":51242,\"start\":51225},{\"end\":51255,\"start\":51242},{\"end\":51271,\"start\":51255},{\"end\":51289,\"start\":51271},{\"end\":51800,\"start\":51785},{\"end\":51814,\"start\":51800},{\"end\":51829,\"start\":51814},{\"end\":52405,\"start\":52396},{\"end\":52422,\"start\":52405},{\"end\":52438,\"start\":52422},{\"end\":52934,\"start\":52924},{\"end\":52947,\"start\":52934},{\"end\":52961,\"start\":52947},{\"end\":53660,\"start\":53650},{\"end\":53673,\"start\":53660},{\"end\":53686,\"start\":53673},{\"end\":53700,\"start\":53686},{\"end\":53715,\"start\":53700},{\"end\":53729,\"start\":53715},{\"end\":54273,\"start\":54261},{\"end\":54282,\"start\":54273},{\"end\":54296,\"start\":54282},{\"end\":54310,\"start\":54296},{\"end\":54319,\"start\":54310},{\"end\":54799,\"start\":54785},{\"end\":54812,\"start\":54799},{\"end\":55322,\"start\":55306},{\"end\":55528,\"start\":55512},{\"end\":55540,\"start\":55528},{\"end\":55553,\"start\":55540},{\"end\":55572,\"start\":55553},{\"end\":55588,\"start\":55572},{\"end\":55603,\"start\":55588},{\"end\":55911,\"start\":55900},{\"end\":55926,\"start\":55911},{\"end\":55936,\"start\":55926},{\"end\":56140,\"start\":56125},{\"end\":56152,\"start\":56140},{\"end\":56618,\"start\":56603},{\"end\":56634,\"start\":56618},{\"end\":56644,\"start\":56634},{\"end\":56658,\"start\":56644},{\"end\":56672,\"start\":56658},{\"end\":57588,\"start\":57571},{\"end\":57605,\"start\":57588},{\"end\":57621,\"start\":57605},{\"end\":57979,\"start\":57961},{\"end\":57992,\"start\":57979},{\"end\":58004,\"start\":57992},{\"end\":58525,\"start\":58507},{\"end\":58537,\"start\":58525},{\"end\":58554,\"start\":58537},{\"end\":58562,\"start\":58554},{\"end\":58583,\"start\":58562},{\"end\":58590,\"start\":58583},{\"end\":59128,\"start\":59112},{\"end\":59153,\"start\":59128},{\"end\":59167,\"start\":59153},{\"end\":59183,\"start\":59167},{\"end\":59401,\"start\":59388},{\"end\":59419,\"start\":59401},{\"end\":59730,\"start\":59717},{\"end\":59748,\"start\":59730},{\"end\":59766,\"start\":59748},{\"end\":60384,\"start\":60366},{\"end\":60399,\"start\":60384},{\"end\":60891,\"start\":60873},{\"end\":60918,\"start\":60891},{\"end\":60926,\"start\":60918},{\"end\":61426,\"start\":61411},{\"end\":61441,\"start\":61426},{\"end\":61457,\"start\":61441},{\"end\":61695,\"start\":61679},{\"end\":61712,\"start\":61695},{\"end\":61736,\"start\":61712},{\"end\":61750,\"start\":61736},{\"end\":61764,\"start\":61750},{\"end\":61781,\"start\":61764},{\"end\":61797,\"start\":61781},{\"end\":61808,\"start\":61797},{\"end\":61817,\"start\":61808},{\"end\":61828,\"start\":61817},{\"end\":61847,\"start\":61828},{\"end\":61856,\"start\":61847},{\"end\":61873,\"start\":61856},{\"end\":61888,\"start\":61873},{\"end\":61904,\"start\":61888},{\"end\":61917,\"start\":61904},{\"end\":61928,\"start\":61917},{\"end\":62624,\"start\":62610},{\"end\":62639,\"start\":62624},{\"end\":62655,\"start\":62639},{\"end\":62670,\"start\":62655},{\"end\":62679,\"start\":62670},{\"end\":62963,\"start\":62951},{\"end\":62972,\"start\":62963},{\"end\":62986,\"start\":62972},{\"end\":62993,\"start\":62986},{\"end\":63521,\"start\":63503},{\"end\":63535,\"start\":63521},{\"end\":63549,\"start\":63535},{\"end\":64062,\"start\":64047},{\"end\":64079,\"start\":64062},{\"end\":64614,\"start\":64598},{\"end\":64635,\"start\":64614},{\"end\":65213,\"start\":65195},{\"end\":65779,\"start\":65766},{\"end\":65788,\"start\":65779},{\"end\":65807,\"start\":65788},{\"end\":65816,\"start\":65807},{\"end\":66318,\"start\":66308},{\"end\":66332,\"start\":66318},{\"end\":66340,\"start\":66332},{\"end\":66352,\"start\":66340},{\"end\":66364,\"start\":66352},{\"end\":66840,\"start\":66828},{\"end\":66852,\"start\":66840},{\"end\":66865,\"start\":66852},{\"end\":66873,\"start\":66865},{\"end\":66881,\"start\":66873},{\"end\":66894,\"start\":66881},{\"end\":66904,\"start\":66894},{\"end\":67431,\"start\":67417},{\"end\":67439,\"start\":67431},{\"end\":67676,\"start\":67660},{\"end\":67691,\"start\":67676},{\"end\":67699,\"start\":67691},{\"end\":67703,\"start\":67699},{\"end\":68001,\"start\":67983},{\"end\":68017,\"start\":68001},{\"end\":68232,\"start\":68212},{\"end\":68250,\"start\":68232},{\"end\":68274,\"start\":68250},{\"end\":68828,\"start\":68817},{\"end\":68841,\"start\":68828},{\"end\":69326,\"start\":69311},{\"end\":69338,\"start\":69326},{\"end\":69787,\"start\":69774},{\"end\":70282,\"start\":70263},{\"end\":70519,\"start\":70500},{\"end\":70535,\"start\":70519},{\"end\":71007,\"start\":70988},{\"end\":71023,\"start\":71007},{\"end\":71667,\"start\":71656},{\"end\":71681,\"start\":71667},{\"end\":71693,\"start\":71681},{\"end\":71708,\"start\":71693},{\"end\":71725,\"start\":71708},{\"end\":71747,\"start\":71725},{\"end\":71764,\"start\":71747},{\"end\":71779,\"start\":71764},{\"end\":72304,\"start\":72284},{\"end\":72315,\"start\":72304},{\"end\":72331,\"start\":72315},{\"end\":72345,\"start\":72331},{\"end\":72366,\"start\":72345},{\"end\":72382,\"start\":72366},{\"end\":72906,\"start\":72886},{\"end\":72920,\"start\":72906},{\"end\":72940,\"start\":72920},{\"end\":72948,\"start\":72940},{\"end\":73462,\"start\":73449},{\"end\":73474,\"start\":73462},{\"end\":73961,\"start\":73948},{\"end\":73973,\"start\":73961},{\"end\":73985,\"start\":73973},{\"end\":74301,\"start\":74285},{\"end\":74317,\"start\":74301}]", "bib_venue": "[{\"end\":41143,\"start\":41056},{\"end\":41696,\"start\":41610},{\"end\":42165,\"start\":42093},{\"end\":43103,\"start\":42981},{\"end\":43642,\"start\":43571},{\"end\":44268,\"start\":44145},{\"end\":45282,\"start\":45203},{\"end\":45792,\"start\":45705},{\"end\":47180,\"start\":47117},{\"end\":47681,\"start\":47594},{\"end\":48327,\"start\":48204},{\"end\":49575,\"start\":49484},{\"end\":50067,\"start\":49985},{\"end\":50503,\"start\":50432},{\"end\":50966,\"start\":50880},{\"end\":51482,\"start\":51391},{\"end\":52076,\"start\":51949},{\"end\":52613,\"start\":52526},{\"end\":53284,\"start\":53124},{\"end\":53901,\"start\":53817},{\"end\":54451,\"start\":54387},{\"end\":54835,\"start\":54832},{\"end\":55103,\"start\":55087},{\"end\":56327,\"start\":56240},{\"end\":57220,\"start\":57144},{\"end\":58152,\"start\":58072},{\"end\":58760,\"start\":58676},{\"end\":59989,\"start\":59886},{\"end\":60577,\"start\":60487},{\"end\":61101,\"start\":61014},{\"end\":62099,\"start\":62014},{\"end\":63163,\"start\":63081},{\"end\":63724,\"start\":63637},{\"end\":64112,\"start\":64104},{\"end\":64376,\"start\":64371},{\"end\":64867,\"start\":64755},{\"end\":65457,\"start\":65336},{\"end\":65994,\"start\":65905},{\"end\":66527,\"start\":66446},{\"end\":67099,\"start\":67010},{\"end\":68297,\"start\":68294},{\"end\":68583,\"start\":68561},{\"end\":69019,\"start\":68930},{\"end\":69486,\"start\":69414},{\"end\":69942,\"start\":69866},{\"end\":70711,\"start\":70624},{\"end\":71287,\"start\":71161},{\"end\":71915,\"start\":71849},{\"end\":72540,\"start\":72461},{\"end\":73111,\"start\":73030},{\"end\":73646,\"start\":73557},{\"end\":74495,\"start\":74405},{\"end\":41054,\"start\":40967},{\"end\":41608,\"start\":41533},{\"end\":42091,\"start\":42017},{\"end\":42548,\"start\":42496},{\"end\":42979,\"start\":42863},{\"end\":43569,\"start\":43503},{\"end\":44143,\"start\":44025},{\"end\":44650,\"start\":44568},{\"end\":45201,\"start\":45120},{\"end\":45703,\"start\":45616},{\"end\":46117,\"start\":46092},{\"end\":46432,\"start\":46396},{\"end\":46790,\"start\":46747},{\"end\":47115,\"start\":47053},{\"end\":47592,\"start\":47506},{\"end\":48202,\"start\":48087},{\"end\":48846,\"start\":48794},{\"end\":49176,\"start\":49158},{\"end\":49482,\"start\":49395},{\"end\":49983,\"start\":49897},{\"end\":50430,\"start\":50364},{\"end\":50878,\"start\":50803},{\"end\":51389,\"start\":51289},{\"end\":51947,\"start\":51829},{\"end\":52524,\"start\":52438},{\"end\":53122,\"start\":52961},{\"end\":53815,\"start\":53729},{\"end\":54385,\"start\":54319},{\"end\":54830,\"start\":54812},{\"end\":55085,\"start\":54970},{\"end\":55304,\"start\":55252},{\"end\":55631,\"start\":55603},{\"end\":55940,\"start\":55936},{\"end\":56238,\"start\":56152},{\"end\":56724,\"start\":56672},{\"end\":57142,\"start\":57070},{\"end\":57649,\"start\":57621},{\"end\":58070,\"start\":58004},{\"end\":58674,\"start\":58590},{\"end\":59110,\"start\":59057},{\"end\":59466,\"start\":59419},{\"end\":59884,\"start\":59766},{\"end\":60485,\"start\":60399},{\"end\":61012,\"start\":60926},{\"end\":61409,\"start\":61356},{\"end\":62012,\"start\":61928},{\"end\":62608,\"start\":62554},{\"end\":63079,\"start\":62993},{\"end\":63635,\"start\":63549},{\"end\":64102,\"start\":64079},{\"end\":64369,\"start\":64257},{\"end\":64753,\"start\":64635},{\"end\":65334,\"start\":65213},{\"end\":65903,\"start\":65816},{\"end\":66444,\"start\":66364},{\"end\":67008,\"start\":66904},{\"end\":67476,\"start\":67439},{\"end\":67755,\"start\":67703},{\"end\":67981,\"start\":67941},{\"end\":68292,\"start\":68274},{\"end\":68559,\"start\":68488},{\"end\":68928,\"start\":68841},{\"end\":69412,\"start\":69338},{\"end\":69864,\"start\":69787},{\"end\":70298,\"start\":70282},{\"end\":70622,\"start\":70535},{\"end\":71159,\"start\":71023},{\"end\":71847,\"start\":71779},{\"end\":72459,\"start\":72382},{\"end\":73028,\"start\":72948},{\"end\":73555,\"start\":73474},{\"end\":74037,\"start\":73985},{\"end\":74403,\"start\":74317}]"}}}, "year": 2023, "month": 12, "day": 17}