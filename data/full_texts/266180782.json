{"id": 266180782, "updated": "2023-12-14 09:50:32.654", "metadata": {"title": "K NOWLEDGE R EFINEMENT VIA I NTERACTION B E - TWEEN S EARCH E NGINES AND L ARGE L ANGUAGE M ODELS", "authors": "[{\"first\":\"Jiazhan\",\"last\":\"Feng\",\"middle\":[]},{\"first\":\"Chongyang\",\"last\":\"Tao\",\"middle\":[]},{\"first\":\"Xiubo\",\"last\":\"Geng\",\"middle\":[]},{\"first\":\"Tao\",\"last\":\"Shen\",\"middle\":[]},{\"first\":\"Can\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Guodong\",\"last\":\"Long\",\"middle\":[]},{\"first\":\"Dongyan\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Daxin\",\"last\":\"Jiang\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern search engines (SEs). The emergence of large language models (LLMs) has further revolutionized the IR field by enabling users to interact with search systems in natural language. In this paper, we explore the advantages and disadvantages of LLMs and SEs, highlighting their respective strengths in understanding user-issued queries and retrieving up-to-date information. To leverage the benefits of both paradigms while circumventing their limitations, we propose InteR, a novel framework that facilitates knowledge refinement through interaction between SEs and LLMs. InteR allows SEs to expand knowledge in queries using LLM-generated knowledge collections and enables LLMs to enhance prompt formulation using SE-retrieved documents. This iterative refinement process augments the inputs of SEs and LLMs, leading to more accurate retrieval. Experiments on large-scale retrieval benchmarks involving web search and low-resource retrieval tasks demonstrate that InteR achieves overall superior zero-shot retrieval performance compared to state-of-the-art methods, even those using relevance judgment. Source code is available at https://github.com/Cyril-JZ/InteR.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2305-07402", "doi": "10.48550/arxiv.2305.07402"}}, "content": {"source": {"pdf_hash": "91f95445eb503b6d710ef4c924e17df70beb19af", "pdf_src": "ScienceParsePlus", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2305.07402", "status": "GREEN"}}, "grobid": {"id": "a0bf334c6d1b932817d47cd3858a0054b49c1e55", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/91f95445eb503b6d710ef4c924e17df70beb19af.txt", "contents": "\nKNOWLEDGE REFINEMENT VIA INTERACTION BE-TWEEN SEARCH ENGINES AND LARGE LANGUAGE MODELS\n21 May 2023\n\nJiazhan Feng fengjiazhan@pku.edu.cn \nWICT\nPeking University\n\n\nChongyang Tao chotao@microsoft.com \nMicrosoft Cooperation\n\n\nXiubo Geng xigeng@microsoft.com \nMicrosoft Cooperation\n\n\nTao Shen tao.shen@uts.edu.au \nSchool of CS\nAAII\nFEIT, UTS\n\n\nCan Xu caxu@microsoft.com \nMicrosoft Cooperation\n\n\nGuodong Long guodong.long@uts.edu.au \nSchool of CS\nAAII\nFEIT, UTS\n\n\nDongyan Zhao zhaody@pku.edu.cn \nWICT\nPeking University\n\n\nDaxin Jiang djiang@microsoft.com \nMicrosoft Cooperation\n\n\nKNOWLEDGE REFINEMENT VIA INTERACTION BE-TWEEN SEARCH ENGINES AND LARGE LANGUAGE MODELS\n21 May 2023ABAB2F5A77C14202E1EFC317DB1A91F4arXiv:2305.07402v2[cs.CL]\nInformation retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern search engines (SEs).The emergence of large language models (LLMs) has further revolutionized the IR field by enabling users to interact with search systems in natural language.In this paper, we explore the advantages and disadvantages of LLMs and SEs, highlighting their respective strengths in understanding user-issued queries and retrieving up-to-date information.To leverage the benefits of both paradigms while circumventing their limitations, we propose InteR, a novel framework that facilitates knowledge refinement through interaction between SEs and LLMs.InteR allows SEs to expand knowledge in queries using LLM-generated knowledge collections and enables LLMs to enhance prompt formulation using SE-retrieved documents.This iterative refinement process augments the inputs of SEs and LLMs, leading to more accurate retrieval.Experiments on large-scale retrieval benchmarks involving web search and low-resource retrieval tasks demonstrate that InteR achieves overall superior zero-shot retrieval performance compared to state-of-the-art methods, even those using relevance judgment.Source code is available at https://github.com/Cyril-JZ/InteR.\n\nINTRODUCTION\n\nInformation retrieval (IR) is an indispensable technique for locating relevant resources in a vast sea of data given ad-hoc queries (Mogotsi, 2010).It is a core component in knowledge-intensive tasks such as question answering (Karpukhin et al., 2020), entity linking (Gillick et al., 2019) and fact verification (Thorne et al., 2018).Over the years, the techniques of information retrieval have evolved significantly: from the traditional knowledge base (KB) (Lan et al., 2021;Gaur et al., 2022) to modern search engines (SEs) based on neural representation learning (Karpukhin et al., 2020;Yates et al., 2021), information retrieval has become increasingly important in our digital world.More recently, the emergence of cutting-edge large language models (LLMs; e.g., ChatGPT (OpenAI, 2022), GPT-4 (OpenAI, 2023), Bard (Google, 2023), LLaMA (Touvron et al., 2023)) has further revolutionized the NLP community and given intriguing insights into IR applications as users can now interact with search systems in natural languages.\n\nOver the decades, search engines like Google or Bing have become a staple for people looking to retrieve information on a variety of topics, allowing users to quickly sift through millions of documents to find the information they need by providing keywords or a query.Spurred by advancements in scale, LLMs have now exhibited the ability to undertake a variety of NLP tasks in a zero-shot scenario (Qin et al., 2023) by following instructions (Ouyang et al., 2022;Sanh et al., 2022;Min et al., 2022;Wei et al., 2022).Therefore, they could serve as an alternative option for people to obtain information directly by posing a question or query in natural language (OpenAI, 2022), instead of relying on specific keywords.For example, suppose a student is looking to write a research paper on the history of jazz music.They could type in keywords such as \"history of jazz\" or \"jazz pioneers\" to retrieve relevant articles and sources.However, with LLMs, this student could pose a question like \"Who were the key pioneers of jazz music, and how did they influence the genre?\"The LLMs could then generate a summary of the relevant information and sources, potentially saving time and effort in sifting through search results.\n\nAs with most things in life, there are two sides to every coin.Both IR technologies come with their own unique set of advantages and disadvantages.LLMs excel in understanding the context and meaning behind user-issued textual queries (Mao et al., 2023), allowing for more precise retrieval of information, while SEs expect well-designed precise keywords to deliver relevant results.Moreover, LLMs have the capacity to generate specific answers to questions (Ouyang et al., 2022), rather than merely present a list of relevant documents, setting them apart from SEs.However, it is important to note that SEs still have significant advantages over LLMs.For instance, SEs can index a vast number of up-to-date documents (Nakano et al., 2021), whereas LLMs can only generate information that falls within the time-scope of the data they were trained on, potentially leading to hallucinated results (Shuster et al., 2021;Ji et al., 2023).Additionally, SEs can conduct quick and efficient searches through a vast amount of information on the internet, making them an ideal choice for finding a wide range of data.Ultimately, both paradigms have their own unique set of irreplaceable advantages, making them useful in their respective areas of application.\n\nTo enhance IR by leveraging the benefits of SEs and LLMs while circumventing their limitations, we consider bridging these two domains.Fortunately, we observe that textual knowledge transfer can be performed between two counterparts and boost each other.On the one hand, SEs can gather potential documents with valuable information, serving as demonstrations for LLMs.On the other hand, LLMs generate concise summaries using well-crafted prompts, expanding the initial query and improving search accuracy.To this end, we introduce InteR, a novel framework that conducts knowledge refinement via interaction between SEs and LLMs.Precisely, we initially employ a Retrieval Model (RM) to concretize the search engine.1Then, the RM part of InteR receives the knowledge collection from the LLM part to refine and expand the knowledge in the query.While the LLM part involves the retrieved documents from the RM part as demonstrations to enrich the knowledge in prompt formulation.This two-step refinement procedure can be seamlessly repeated to augment the inputs of RM and LLM.Implicitly, we assume that the outputs of both components supplement each other, leading to more accurate retrieval.\n\nWe evaluate InteR on public large-scale retrieval benchmarks involving web search and low-resource retrieval tasks following prior work (Gao et al., 2022).The experimental results show that InteR can conduct zero-shot retrieval with overall better performance than state-of-the-art methods, even those using relevance judgment2 , and achieves new state-of-the-art zero-shot retrieval performance.\n\nOverall, our main contributions can be summarized as follows:\n\n\u2022 We introduce InteR, a novel IR framework bridging two cutting-edge IR products, search engines and large language models, while enjoying their strengths and circumventing their limitations.\n\n\u2022 We propose iterative knowledge refinement via interaction between retrieval models (of search engines) and large language models, resulting in improved retrieval quality.\n\n\u2022 Evaluation results on zero-shot retrieval demonstrate that InteR can overall conduct more accurate retrieval than state-of-the-art approaches and even outperform baselines that leverage relevance judgment for supervised learning.\n\n\nRELATED WORK\n\nDense Retrieval Document retrieval has been an important component for several knowledgeintensive tasks (Voorhees et al., 1999;Karpukhin et al., 2020).Traditional techniques such as TF-IDF and BM25 depend on term matching and create sparse vectors (Robertson, 2009;Yang et al., 2017;Chen et al., 2017) to ensure efficient retrieval.After the emergence of pre-trained language models (Devlin et al., 2019;Liu et al., 2019), dense retrieval which encodes both queries and documents into low-dimension vectors and then calculates their relevance scores (Lee et al., 2019;Karpukhin et al., 2020), has recently undergone substantial research.Relevant studies include improving training approach (Karpukhin et al., 2020;Xiong et al., 2021;Qu et al., 2021), distillation (Lin et al., 2021;Hofst\u00e4tter et al., 2021) and task-specific pre-training (Izacard et al., 2022;Gao & Callan, 2021;Lu et al., 2021;Gao & Callan, 2022;Xiao et al., 2022) of dense retrieval models which significantly outperform sparse approaches.\n\nZero-shot Dense Retrieval Many prior works consider training dense retrieval models on highresource passage retrieval datasets like Natural Questions (NQ) (Kwiatkowski et al., 2019) (Wang et al., 2022;Yu et al., 2022) are utilized in a transfer learning configuration (Thakur et al., 2021).However, on the one hand, it is time-consuming and expensive to collect such a vast training corpus.On the other hand, even MS-MARCO has limitations on commercial use and cannot be used in a wide range of real-world applications.To this end, recent work (Gao et al., 2022) proposes building zero-shot dense retrieval systems that require no relevance supervision (i.e., relevance label between a pair of query and document), which is considered \"unsupervised\" as the only supervision resides in the LLM where learning to follow instructions is conducted in earlier times (Sachan et al., 2022).In this work, we follow this zero-shot unsupervised setting and conduct knowledge refinement via interaction between SEs and LLMs without any relevance supervision to handle the aforementioned issues.\n\nEnhance Retrieval Through LMs Recent works have investigated using auto-regressive language models to generate intermediate targets for better retrieval (Cao et al., 2021;Bevilacqua et al., 2022) while identifier strings still need to be created.Other works consider \"retrieving\" the knowledge stored in the parameters of pre-trained language models by directly generating text (Petroni et al., 2019;Roberts et al., 2020).Some researchers (Mao et al., 2021;Wang et al., 2023) utilize LM to expand the query and incorporate these pseudo-queries for enhanced retrieval while others choose to expand the document (Nogueira et al., 2019).Besides, LMs can also be exploited to provide references for retrieval targets.For instance, GENREAD (Yu et al., 2023) directly generates contextual documents for given questions.\n\nEnhance LMs Through Retrieval On the contrary, retrieval-enhanced LMs have also received significant attention.Some approaches enhance the accuracy of predicting the distribution of the next word during training (Borgeaud et al., 2022) or inference (Khandelwal et al., 2020) through retrieving the k-most similar training contexts.Alternative methods utilize retrieved documents to provide supplementary context in generation tasks (Joshi et al., 2020;Guu et al., 2020;Lewis et al., 2020).WebGPT (Nakano et al., 2021) further adopts imitation learning and uses human feedback in a text-based web-browsing environment to enhance the LMs.LLM-Augmentor (Peng et al., 2023) improves large language models with external knowledge and automated feedback.REPLUG (Shi et al., 2023) prepends retrieved documents to the input for the frozen LM and treats the LM as a black box.Demonstrate-Search-Predict (DSP) framework (Khattab et al., 2022) obtains performance gains by relying on passing natural language texts in sophisticated pipelines between a language model and a retrieval model, which is most closely related to our approach.However, they rely on composing two parts with in-context learning and target on multi-hop question answering.While we aim at conducting knowledge refinement via multiple interactions between search engines and large language models for large-scale retrieval.\n\n\nPRELIMINARY\n\nDocument Retrieval: the RM Part Zero-shot document retrieval is a crucial component of modern search engines.Given the user query q and the document set D = {d 1 , d 2 , ..., d n } where n is the number of document candidates, the goal of a retrieval model (RM) from SE is to retrieve documents that are relevant to satisfy the user's real search intent of the current query q.To accomplish such document retrieval, prior works can be categorized into two groups: sparse retrieval and dense retrieval.\n\nBoth lines of research elaborate on devising the similarity function \u03c6(q, d) for each query-document pair.The sparse retrieval, e.g., TF-IDF and BM25, depends on lexicon overlap between query q and document d.This line of RMs (Zhou et al., 2022;Thakur et al., 2021) ranks documents D based on their relevance to a given query q by integrating term frequency and inverse document frequency.\n\nAnother works (Qu et al., 2021;Ni et al., 2022;Karpukhin et al., 2020) focus on dense retrieval that uses two encoding modules to map an input query q and a document d into a pair of vectors v q , v d , whose inner product is leveraged as a similarity function \u03c6:\n\u03c6(q, d) = E Q (q), E D (d) = v q , v d(1)\nThen the top-k documents, denoted as D that have the highest similarity scores when compared with the query q, are retrieved efficiently by RMs regardless of whether the retrieval is sparse or dense.\n\nNoting that as for dense retrieval, following existing methods (Gao et al., 2022), we pre-compute each document's vector v d for efficient retrieval and build the FAISS index (Johnson et al., 2019) over these vectors, and use Contriever (Izacard et al., 2022) as the backbone of query encoder E Q and document encoder E D .\n\nGenerative Retrieval: the LLM Part Generative search is a new paradigm of IR that employs neural generative models as search indices (Tay et al., 2022;Bevilacqua et al., 2022;Lee et al., 2022).\n\nRecent studies propose that LLMs further trained to follow instructions could zero-shot generalize to diverse unseen instructions (Ouyang et al., 2022;Sanh et al., 2022;Min et al., 2022;Wei et al., 2022).Therefore, we prepare textual prompts p that include instructions for the desired behavior to q and obtain a refined query q .Then the LLMs G such as ChatGPT (OpenAI, 2022) take in q and generate related knowledge s.This process can be illustrated as follows:\ns = G(q ) = G(q \u2295 p) (2)\nwhere \u2295 is the prompt formulation operation for q and p.For each q , if we sample h examples via LLM G, we will obtain a knowledge collection S = {s 1 , s 2 , ..., s h }.\n\n\nINTER\n\nOn top of the preliminaries, we introduce InteR, a novel IR framework that iteratively performs knowledge refinement via interaction between RMs and LLMs.The overview is shown in Figure 1.\n\nDuring each iteration, the RM part and LLM part refine their knowledge in the query through interaction with knowledge collection (via LLMs) or retrieved documents (via RMs) from previous iteration.Specifically, in RM part, InteR refines the knowledge stored in query q with knowledge collection S generated by LLM for better document retrieval.While in LLM part, InteR refines the knowledge in original query q with retrieved document D from RM for better invoking LLM to generate most relevant information.This two-step procedure can be repeated multiple times in an iterative refinement style.\n\nWe first elaborate on how RMs and LLMs refine the knowledge in queries detailedly in Section 4.1 and Section 4.2 respectively.Then, we describe the whole procedure of multiple knowledge refinement iterations in which RMs and LLMs can come together to perform IR effectively in Section 4.3.\n\n4.1 RM STEP: REFINING KNOWLEDGE IN RM VIA LLM When people use search engines, the natural way is to first type in a search query q whose genre can be a question, a keyword, or a combination of both.The RMs in search engines then process the search query q and retrieve several documents D based on their relevance \u03c6(q, d) to the search query q.Ideally, D contains the necessary information related to the user-issued query q.However, it may include irrelevant information to query as the candidate documents for retrieval are chunked and fixed (Yu et al., 2023).Moreover, it may also miss some required knowledge since the query is often fairly condensed and short (e.g., \"best sushi in San Francisco\").\n\nTo this end, we additionally involve the generated knowledge collection S from LLM in previous iteration and enrich the knowledge included in q with S. Specifically, we consider expanding the query q by concatenating each s i \u2208 S multiple times to q and obtaining the similarity of document d with: \u03c6(q, d; S) = \u03c6([q; s 1 ; q; s 2 ; ..., q; s h ], d) = E Q ([q; s 1 ; q; s 2 ; ..., q; s h ]),\nE D (d)(3)\nwhere [\u2022; \u2022] is a concatenating operation for query expansion.Now the query is knowledge-intensive equipping with S from LLM part that may be supplement to q.We hope the knowledge collection S can provide directly relevant information to the input query q and help the RMs focus on the domain or topic in user query q.\n\n\nLLM STEP: REFINING KNOWLEDGE IN LLM VIA RM\n\nAs aforementioned, we can invoke LLMs to conditionally generate knowledge collection S by preparing a prompt p that adapts the LLM to a specific function (Eq.2).Despite the remarkable text generation capabilities, they are also prone to hallucination and still struggle to represent the complete long tail of knowledge contained within their training corpus (Shi et al., 2023).To circumvent the aforementioned problems, we argue that D, the documents retrieved by RMs, may provide rich information about the original query q and can potentially help the LLMs make a better prediction.\n\nSpecifically, we include the knowledge in D into p by designing a new prompt as:\n\nGive a question {query} and its possible answering passages {passages} please write a correct answering passage.\n\nwhere \"{query}\" and \"{passages}\" are the placeholders for q and D respectively from previous RM step:\ns = G(q ) = G(q \u2295 p \u2295 D)(4)\nNow the query q is refined and contains more plentiful information about q through retrieved documents D as demonstrations.Here we simply concatenate D for placeholder \"{passages}\", which contains k retrieved documents from RM part for input of LLM G.\n\n\nITERATIVE INTERACTION BETWEEN RM AND LLM\n\nIn this section, we explain how iterative refinement can be used to improve both RM and LLM parts.This iterative procedure can be interpreted as exploiting the current query q and previous-generated knowledge collection S to retrieve another document set D with RM part for the subsequent stage of LLM step.Then, the LLM part leverages the retrieved documents D from previous stage of RM and synthesizes the knowledge collection S for next RM step.A critical point is that we take LLM as the starting point and use only q and let D be empty as the initial RM input.Therefore, the prompt of first LLM step is formulated as:\n\nPlease write a passage to answer the question.Question: {query} Passage:\n\nWe propose using an iterative IR pipeline, with each iteration consisting of the four steps listed below:\n\n1. Invoke LLM to conditionally generate knowledge collection S with prompt q on Eq. 4.\n\nThe retrieved document set D is derived from previous RM step and set as empty in the beginning.\n\n2. Construct the updated input for RM with knowledge collection S and query q to compute the similarity of each document d.\n\n3. Invoke RM to retrieve the top-k most \"relevant\" documents as D on Eq. 3.\n\n4. Formulate a new prompt q by combining the retrieved document set D with query q.\n\nThe iterative nature of this multi-step process enables the refinement of knowledge through the interaction between the Retrieval Models (RMs) of Search Engines (SEs) and the Large Language Models (LLMs), which can be executed repeatedly M times to further enhance the quality of results.\n\n\nEXPERIMENTS\n\nIn this section, we conduct extensive experimental evaluations of the proposed retrieval framework InteR and comprehensively compare it with competitive baselines.\n\n\nDATASETS AND METRICS\n\nFollowing (Gao et al., 2022), we adopt widely-used web search query sets TREC Deep Learning 2019 (DL'19) (Craswell et al., 2020) and TREC Deep Learning 2020 (DL'20) (Craswell et al., 2021) which are based on the MS-MARCO (Bajaj et al., 2016).Besides, we also use six diverse low-resource retrieval datasets from the BEIR benchmark (Thakur et al., 2021) consistent with (Gao et al., 2022) including SciFact (fact-checking), ArguAna (argument retrieval), TREC-COVID (bio-medical IR), FiQA (financial question-answering), DBPedia (entity retrieval), and TREC-NEWS (news retrieval).\n\nIt is worth pointing out that we do not employ any training query-document pairs, as we conduct retrieval in a zero-shot setting and directly evaluate our proposed method on these test sets.Consistent with prior works, we report MAP, nDCG@10, and Recall@1000 (R@1k) for TREC DL'19 and DL'20 data, and nDCG@10 is employed for all datasets in the BEIR benchmark.\n\n\nBASELINES\n\nMethods without relevance judgment We consider several zero-shot retrieval models as our main baselines, because we do not involve any query-document relevance scores (denoted as w/o relevance judgment) in our setting.Particularly, we choose heuristic-based lexical retriever BM25 (Robertson & Zaragoza, 2009), BERT-based term weighting framework DeepCT (Dai & Callan, 2019), and Contriever (Izacard et al., 2022) that is trained using unsupervised contrastive learning.We also compare our model with the state-of-the-art LLM-based retrieval model HyDE (Gao et al., 2022) which shares the exact same embedding spaces with Contriever but builds query vectors with LLMs.\n\nMethods with relevance judgment Moreover, we also incorporate several systems that utilize fine-tuning on extensive query-document relevance data, such as MS-MARCO, as references (denoted as w/ relevance judgment).This group encompasses some commonly used fully-supervised retrieval methods, including DPR (Karpukhin et al., 2020), ANCE (Xiong et al., 2021), and the fine-tuned Contriever (Izacard et al., 2022) (denoted as Contriever FT ).\n\n\nIMPLEMENTATION DETAILS\n\nAs for the LLM part, we utilize the March 1, 2023 version of the gpt-3.5-turbo,specifically gpt-3.5-turbo-0301 to avoid any interference caused by upgrading.As for the RM part, we MAP nDCG@10 R@1k MAP nDCG@10 R@1k w/o relevance judgment BM25 (Robertson & Zaragoza, 2009) (Izacard et al., 2022) 64.9 37.9 27.3 24.5 29.2 34.8 HyDE (Gao et al., 2022) 69 consider BM25 for document retrieval.For each q , we sample h = 10 knowledge examples via LLM.\n\nAfter hyper-parameter search, we set k and M as 15 and 2 by default. 3We use a temperature of 1 for LLM part to generate examples and a frequency penalty of zero.We also truncate each RM-retrieved passage/document to 256 tokens and set the maximum number of tokens for each LLM-generated knowledge example to 256 for efficiency.\n\n\nMAIN RESULTS\n\n\nWeb Search\n\nIn Table 1, we show zero-shot retrieval results on TREC DL'19 and TREC DL'20 with baselines.We can find that InteR can outperform state-of-the-art zero-shot model HyDE with significant improvement (> 8% absolute MAP gain and > 5% absolute nDCG@10 gain on both web search benchmarks).Moreover, InteR is also superior to models with relevance judgment on most metrics, which verifies the generalization ability of InteR on large-scale retrieval.Note that our approach does not involve any training process and merely leverages off-the-shelf RMs and LLMs, which is simpler in practice but shown to be more effective.\n\n\nLow Resource Retrieval\n\nIn Table 2, we also present the zero-shot retrieval results on six diverse low-resource retrieval tasks from BEIR benchmarks.Firstly, we find that InteR is especially competent on TREC-COVID and TREC-NEWS and even significantly outperforms baselines with relevance judgment.Secondly, our model also brings considerable improvements to baselines on SciFact and DBPedia, which shows our performance advantages on fact-checking and entity retrieval.Finally, it can be observed that the performance of FiQA and ArguAna falls short when compared to the baseline models.This could potentially be attributed to the LLM's limited financial knowledge of FiQA and    (Thakur et al., 2021).\n\n\nDISCUSSIONS\n\nThe impact of the size of knowledge collection (h) We conducted additional research to examine the impact of the size of knowledge collection (i.e., h) on the performance of InteR. Figure 2 illustrates the changes in MAP and nDCG@10 curves of InteR on TREC DL'19 and DL'20, with respect to varying numbers of knowledge examples.Our observations reveal a consistent pattern in both benchmarks: as the number of generated knowledge increases, the performance metrics demonstrate a gradual improvement until reaching 10 knowledge examples.Subsequently, the performance metrics stabilize, indicating that additional knowledge examples do not significantly enhance the results.This phenomenon could be attributed to the presence of redundant knowledge within the surplus examples generated by LLMs.\n\nThe impact of the number of knowledge refinement iterations (M ) We also investigated the effect of different numbers of knowledge refinement iterations (M ) on the performance of InteR.\n\nThe results presented in Table 3 indicate a notable enhancement in retrieval capacity as M increases from 0 to 2, which verifies the effectiveness of multiple iterative knowledge refinement between RMs and LLMs.However, if we further increase M , the performance may not improve, possibly due to a decrease in the diversity of retrieved documents from RMs.Here if we set M to 0, InteR will degenerate into BM25.\n\nDense retrieval v.s.sparse retrieval Finally, we delve into the impact of the retrieval strategy for constructing D on Eq. 4 on the performance of InteR.Table 4 shows the experimental results, where we initiate the RM with an unsupervised sparse retrieval model (i.e., BM25) or an unsupervised dense retrieval model (i.e., Contriever).Additionally, we introduce a hybrid retrieval paradigm that combines half of the documents from the sparse retrieval model with the other half from the dense retrieval model.These components are then merged to generate the output of the hybrid retrieval model, namely InteR (Hybrid).We can observe that the dense model is the best strategy for InteR and even outperforms the hybrid counterpart, which is consistent with the observations from prior works (Karpukhin et al., 2020).Therefore, we use a dense retrieval model to construct D as default.\n\nIt is noteworthy that we only use a dense retrieval model for constructing D during knowledge refinement and leave the final retrieval model as a sparse BM25 for efficiency.\n\n\nCONCLUSION AND FUTURE WORKS\n\nIn this work, we present InteR, a novel framework that harnesses the strengths of both large language models (LLMs) and search engines (SEs) to enhance information retrieval.By facilitating knowledge refinement through interaction between LLMs and Retrieval Models (RMs) of SEs, InteR achieves overall superior zero-shot retrieval performance compared to state-of-the-art methods, and even those using relevance judgment, on large-scale retrieval benchmarks involving web search and low-resource retrieval tasks.With its ability to leverage the benefits of both paradigms, InteR may present a potential direction for advancing information retrieval systems.\n\nFigure 1 :\n1\nFigure 1: Overall architecture of InteR.\n\n\nFigure 2 :\n2\nFigure 2: Performance of InteR across different size of knowledge collection (h) on TREC DL'19 and DL'20.\n\n\nTable 1 :\n1\nExperimental results on TREC Deep Learning 2019 (DL'19)and TREC Deep Learning 2020 (DL'20) datasets (%).The best results are marked in bold and the best performing w/ relevance judgment are marked with \u00b6 .The improvement is statistically significant compared with the baselines w/o relevance judgment (t-test with p-value < 0.05).\nMethodsDL'19DL'20\n\nTable 2 :\n2\nExperimental results (nDCG@10) on low resource tasks from BEIR (%).The best results are marked in bold and the best performing w/ relevance judgment are marked with \u00b6 .\n30.150.675.028.648.078.6DeepCT (Dai & Callan, 2019)-55.1--55.6-Contriever (Izacard et al., 2022)24.044.574.624.042.175.4HyDE (Gao et al., 2022)41.861.388.038.257.984.4InteR50.068.389.346.863.588.8w/ relevance judgmentDPR (Karpukhin et al., 2020)36.562.276.941.865.3  \u00b681.4ANCE (Xiong et al., 2021)37.164.5  \u00b675.540.864.677.6Contriever FT (Izacard et al., 2022)41.7  \u00b662.183.6  \u00b6 43.6  \u00b663.285.8  \u00b6MethodsSciFact ArguAna TREC-COVID FiQA DBPedia TREC-NEWSw/o relevance judgmentBM25 (Robertson & Zaragoza, 2009)67.939.759.523.631.839.5Contriever\n\nTable 3 :\n3\nPerformance of InteR across different number of knowledge refinement iterations (M ) on TREC DL'19 and DL'20.The default setting is marked with * and the best results are marked in bold.\nMethodsDL'19DL'20MAP nDCG@10 R@1k MAP nDCG@10 R@1kInteR (M = 0)30.150.675.028.648.078.6InteR (M = 1)45.865.389.342.661.088.7InteR (M = 2)  *  50.068.389.346.863.588.8InteR (M = 3)49.168.288.042.859.385.6the RM's marginal qualification to effectively handle relatively longer queries for ArguAna\n\nTable 4 :\n4\nPerformance of InteR across different retrieval strategies for constructing D on Eq. 4 on TREC DL'19 and DL'20.The default setting is marked with * and the best results are marked in bold.\nMethodsDL'19DL'20MAP nDCG@10 R@1k MAP nDCG@10 R@1kInteR (Sparse)46.966.689.442.360.485.4InteR (Dense)  *  50.068.389.346.863.588.8InteR (Hybrid)48.367.689.145.162.585.2\nUsually, the backbone of a modern search engine is a retrieval model. In this paper, we initialize the search engine as a retrieval model (RM) that functions as an SE instance.\nIn IR tasks, the relevance judgment illustrates the label of relevance between each pair of query and document, which is mainly used for supervised learning of an IR model.\nFor ArguAna data in BEIR benchmark, we set M to 1 as it achieves the best performance.\n\nMs marco: A human generated machine reading comprehension dataset. Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew Mcnamara, Bhaskar Mitra, Tri Nguyen, arXiv:1611.092682016arXiv preprint\n\nAutoregressive search engines: Generating substrings as document identifiers. Michele Bevilacqua, Giuseppe Ottaviano, Patrick Lewis, Scott Yih, Sebastian Riedel, Fabio Petroni, Advances in Neural Information Processing Systems. 202235\n\nImproving language models by retrieving from trillions of tokens. Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, International conference on machine learning. PMLR2022\n\nAutoregressive entity retrieval. Nicola De Cao, Gautier Izacard, Sebastian Riedel, Fabio Petroni, International Conference on Learning Representations. 2021\n\nReading Wikipedia to answer open-domain questions. Danqi Chen, Adam Fisch, Jason Weston, Antoine Bordes, 10.18653/v1/P17-1171Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational LinguisticsJuly 20171\n\nOverview of the trec 2019 deep learning track. Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, Ellen M Voorhees, arXiv:2003.078202020arXiv preprint\n\nOverview of the trec 2020 deep learning track. Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, arXiv:2102.076622021arXiv preprint\n\nContext-aware sentence/passage term importance estimation for first stage retrieval. Zhuyun Dai, Jamie Callan, arXiv:1910.106872019arXiv preprint\n\nBERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational LinguisticsJune 20191\n\nCondenser: a pre-training architecture for dense retrieval. Luyu Gao, Jamie Callan, 10.18653/v1/2021.emnlp-main.75Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicAssociation for Computational LinguisticsNovember 2021Online and Punta Cana\n\nUnsupervised corpus aware language model pre-training for dense passage retrieval. Luyu Gao, Jamie Callan, 10.18653/v1/2022.acl-long.203Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational LinguisticsMay 20221\n\nPrecise zero-shot dense retrieval without relevance labels. Luyu Gao, Xueguang Ma, Jimmy Lin, Jamie Callan, arXiv:2212.104962022arXiv preprint\n\nIseeq: Information seeking question generation using dynamic meta-information retrieval and knowledge graphs. Manas Gaur, Kalpa Gunaratna, Vijay Srinivasan, Hongxia Jin, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202236\n\nLearning dense representations for entity retrieval. Daniel Gillick, Sayali Kulkarni, Larry Lansing, Alessandro Presta, Jason Baldridge, Eugene Ie, Diego Garcia-Olano, 10.18653/v1/K19-1049Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL). the 23rd Conference on Computational Natural Language Learning (CoNLL)Hong Kong, ChinaAssociation for Computational LinguisticsNovember 2019\n\n. Google, Google, 2023\n\nRetrieval augmented language model pre-training. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Mingwei Chang, International conference on machine learning. PMLR2020\n\nEfficiently teaching an effective dense retriever with balanced topic aware sampling. Sebastian Hofst\u00e4tter, Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin, Allan Hanbury, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval2021\n\nUnsupervised dense information retrieval with contrastive learning. Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, Edouard Grave, Transactions on Machine Learning Research. 2835-88562022\n\nSurvey of hallucination in natural language generation. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye , Jin Bang, Andrea Madotto, Pascale Fung, ACM Computing Surveys. 55122023\n\nBillion-scale similarity search with gpus. Jeff Johnson, Matthijs Douze, Herv\u00e9 J\u00e9gou, IEEE Transactions on Big Data. 732019\n\nMandar Joshi, Kenton Lee, Yi Luan, Kristina Toutanova, arXiv:2004.12006Contextualized representations using textual encyclopedic knowledge. 2020arXiv preprint\n\nDense passage retrieval for open-domain question answering. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, 10.18653/v1/2020.emnlp-main.550Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. the 2020 Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational LinguisticsNovember 2020\n\nGeneralization through memorization: Nearest neighbor language models. Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, Mike Lewis, International Conference on Learning Representations. 2020\n\nDemonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp. Omar Khattab, Keshav Santhanam, Lisa Xiang, David Li, Percy Hall, Christopher Liang, Matei Potts, Zaharia, arXiv:2212.140242022arXiv preprint\n\nNatural questions: A benchmark for question answering research. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M Dai, Jakob Uszkoreit, Quoc Le, Slav Petrov, 10.1162/tacl_a_00276Transactions of the Association for Computational Linguistics. 72019\n\nA survey on complex knowledge base question answering: Methods, challenges and solutions. Yunshi Lan, Gaole He, Jinhao Jiang, Jing Jiang, Wayne Xin Zhao, Ji-Rong Wen, 10.24963/ijcai.2021/611Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21. Zhi-Hua Zhou, the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-2182021\n\nGenerative multi-hop retrieval. Hyunji Lee, Sohee Yang, Hanseok Oh, Minjoon Seo, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022\n\nLatent retrieval for weakly supervised open domain question answering. Kenton Lee, Ming-Wei Chang, Kristina Toutanova, 10.18653/v1/P19-1612Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational LinguisticsJuly 2019\n\nRetrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-Tau Yih, Tim Rockt\u00e4schel, Advances in Neural Information Processing Systems. 202033\n\nIn-batch negatives for knowledge distillation with tightly-coupled teachers for dense retrieval. Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin, 10.18653/v1/2021.repl4nlp-1.17Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021). the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)Association for Computational LinguisticsAugust 2021\n\nRoberta: A robustly optimized BERT pretraining approach. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, CoRR, abs/1907.116922019\n\nLess is more: Pretrain a strong Siamese encoder for dense text retrieval using a weak decoder. Shuqi Lu, Di He, Chenyan Xiong, Guolin Ke, Waleed Malik, Zhicheng Dou, Paul Bennett, Tie-Yan Liu, Arnold Overwijk, 10.18653/v1/2021.emnlp-main.220Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicAssociation for Computational LinguisticsNovember 2021Online and Punta Cana\n\nLarge language models know your contextual search intent: A prompting framework for conversational search. Kelong Mao, Zhicheng Dou, Haonan Chen, Fengran Mo, Hongjin Qian, arXiv:2303.065732023arXiv preprint\n\nGeneration-augmented retrieval for open-domain question answering. Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao, Jiawei Han, Weizhu Chen, doi: 10.18653Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. Long Papers. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingAssociation for Computational LinguisticsAugust 20211\n\nURL. \n\nMetaICL: Learning to learn in context. Sewon Min, Mike Lewis, Luke Zettlemoyer, Hannaneh Hajishirzi, doi: 10.18653Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSeattle, United StatesAssociation for Computational LinguisticsJuly 2022\n\nURL. \n\nChristopher d. manning, prabhakar raghavan, and hinrich sch\u00fctze: Introduction to information retrieval. Ic Mogotsi, Information Retrieval. 1322010\n\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, arXiv:2112.09332Browser-assisted question-answering with human feedback. 2021arXiv preprint\n\nLarge dual encoders are generalizable retrievers. Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hernandez Abrego, Ji Ma, Vincent Zhao, Yi Luan, Keith Hall, Ming-Wei Chang, Yinfei Yang, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022\n\nDocument expansion by query prediction. Rodrigo Nogueira, Wei Yang, Jimmy Lin, Kyunghyun Cho, arXiv:1904.083752019arXiv preprint\n\nOptimizing language models for dialogue. Openai, Chatgpt, \n\n. ArXiv, abs/2303.08774OpenAI. Gpt-4 technical report. 2023\n\nTraining language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, Advances in Neural Information Processing Systems. 202235\n\nCheck your facts and try again: Improving large language models with external knowledge and automated feedback. Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, arXiv:2302.128132023arXiv preprint\n\nLanguage models as knowledge bases?. Fabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander Miller, 10.18653/v1/D19-1250Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational LinguisticsNovember 2019\n\nIs chatgpt a general-purpose natural language processing task solver?. Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, Diyi Yang, arXiv:2302.064762023arXiv preprint\n\nRocketQA: An optimized training approach to dense passage retrieval for open-domain question answering. Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, 10.18653/v1/2021.naacl-main.466Proceedings of the 2021 Conference of the North American Chapter. the 2021 Conference of the North American ChapterAssociation for Computational LinguisticsJune 2021\n\nHow much knowledge can you pack into the parameters of a language model?. Adam Roberts, Colin Raffel, Noam Shazeer, 10.18653/v1/2020.emnlp-main.437Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational LinguisticsNovember 2020\n\nThe probabilistic relevance framework: BM25 and beyond. Stephen E Robertson, Hugo Zaragoza, 10.1561/1500000019Found. Trends Inf. Retr. 342009\n\nThe probabilistic relevance framework: Bm25 and beyond. Zaragoza Robertson. Robertson S, Found. Trends Inf. Retr. 342009\n\nImproving passage retrieval with zero-shot question generation. Devendra Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-Tau Yih, Joelle Pineau, Luke Zettlemoyer, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022\n\nMultitask prompted training enables zero-shot task generalization. Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, International Conference on Learning Representations. 2022\n\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, Wen-Tau Yih, arXiv:2301.12652Replug: Retrieval-augmented black-box language models. 2023arXiv preprint\n\nRetrieval augmentation reduces hallucination in conversation. Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, Jason Weston, 10.18653/v1/2021.findings-emnlp.320Findings of the Association for Computational Linguistics: EMNLP 2021. Punta Cana, Dominican RepublicAssociation for Computational LinguisticsNovember 2021\n\nTransformer memory as a differentiable search index. Yi Tay, Vinh Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao, Jai Gupta, Advances in Neural Information Processing Systems. 202235\n\nBEIR: A heterogenous benchmark for zero-shot evaluation of information retrieval models. Nandan Thakur, Nils Reimers, Andreas R\u00fcckl\u00e9, Abhishek Srivastava, Iryna Gurevych, CoRR, abs/2104.086632021\n\nChristos Christodoulopoulos, and Arpit Mittal. The fact extraction and VERification (FEVER) shared task. James Thorne, Andreas Vlachos, Oana Cocarascu, 10.18653/v1/W18-5501Proceedings of the First Workshop on Fact Extraction and VERification (FEVER). the First Workshop on Fact Extraction and VERification (FEVER)Brussels, BelgiumAssociation for Computational Linguistics2018\n\nThibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timoth\u00e9e Lachaux, Baptiste Lacroix, Naman Rozi\u00e8re, Eric Goyal, Hambro, arXiv:2302.13971Faisal Azhar, et al. Llama: Open and efficient foundation language models. 2023arXiv preprint\n\nThe trec-8 question answering track report. Ellen M Voorhees, Trec. 199999\n\nGPL: Generative pseudo labeling for unsupervised domain adaptation of dense retrieval. Kexin Wang, Nandan Thakur, Nils Reimers, Iryna Gurevych, 10.18653/v1/2022.naacl-main.168Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSeattle, United StatesAssociation for Computational LinguisticsJuly 2022\n\nQuery2doc: Query expansion with large language models. Liang Wang, Nan Yang, Furu Wei, arXiv:2303.076782023arXiv preprint\n\nFinetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, Quoc V Le, International Conference on Learning Representations. 2022\n\nRetroMAE: Pre-training retrieval-oriented language models via masked auto-encoder. Shitao Xiao, Zheng Liu, Yingxia Shao, Zhao Cao, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022\n\nApproximate nearest neighbor negative contrastive learning for dense text retrieval. Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N Bennett, Junaid Ahmed, Arnold Overwijk, International Conference on Learning Representations. 2021\n\nEnabling the use of lucene for information retrieval research. Peilin Yang, Hui Fang, Jimmy Lin, Anserini, 10.1145/3077136.3080721Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval. Noriko Kando, Tetsuya Sakai, Hideo Joho, Hang Li, Arjen P De Vries, Ryen W White, the 40th International ACM SIGIR Conference on Research and Development in Information RetrievalShinjuku, Tokyo, JapanACMAugust 7-11, 2017. 2017\n\nPretrained transformers for text ranking: BERT and beyond. Andrew Yates, Rodrigo Nogueira, Jimmy Lin, 10.18653/v1/2021.naacl-tutorials.1Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Tutorials. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: TutorialsAssociation for Computational LinguisticsJune 2021\n\nGenerate rather than retrieve: Large language models are strong context generators. Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, Michael Zeng, Meng Jiang, The Eleventh International Conference on Learning Representations. 2023\n\nCOCO-DR: Combating the distribution shift in zero-shot dense retrieval with contrastive and distributionally robust learning. Yue Yu, Chenyan Xiong, Si Sun, Chao Zhang, Arnold Overwijk, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022\n\nHyperlink-induced pre-training for passage retrieval in open-domain question answering. Jiawei Zhou, Xiaoguang Li, Lifeng Shang, Lan Luo, Ke Zhan, Enrui Hu, Xinyu Zhang, Hao Jiang, Zhao Cao, Fan Yu, Xin Jiang, Qun Liu, Lei Chen, doi: 10.18653Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational LinguisticsMay 20221\n\nURL. \n", "annotations": {"author": "[{\"end\":162,\"start\":101},{\"end\":222,\"start\":163},{\"end\":279,\"start\":223},{\"end\":339,\"start\":280},{\"end\":390,\"start\":340},{\"end\":458,\"start\":391},{\"end\":515,\"start\":459},{\"end\":573,\"start\":516}]", "publisher": null, "author_last_name": "[{\"end\":113,\"start\":109},{\"end\":176,\"start\":173},{\"end\":233,\"start\":229},{\"end\":288,\"start\":284},{\"end\":346,\"start\":344},{\"end\":403,\"start\":399},{\"end\":471,\"start\":467},{\"end\":527,\"start\":522}]", "author_first_name": "[{\"end\":108,\"start\":101},{\"end\":172,\"start\":163},{\"end\":228,\"start\":223},{\"end\":283,\"start\":280},{\"end\":343,\"start\":340},{\"end\":398,\"start\":391},{\"end\":466,\"start\":459},{\"end\":521,\"start\":516}]", "author_affiliation": "[{\"end\":161,\"start\":138},{\"end\":221,\"start\":199},{\"end\":278,\"start\":256},{\"end\":338,\"start\":310},{\"end\":389,\"start\":367},{\"end\":457,\"start\":429},{\"end\":514,\"start\":491},{\"end\":572,\"start\":550}]", "title": "[{\"end\":87,\"start\":1},{\"end\":660,\"start\":574}]", "venue": null, "abstract": "[{\"end\":2069,\"start\":730}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b37\"},\"end\":2232,\"start\":2217},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2336,\"start\":2312},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2375,\"start\":2353},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":2419,\"start\":2398},{\"end\":2563,\"start\":2545},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2581,\"start\":2563},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2677,\"start\":2653},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":2696,\"start\":2677},{\"end\":2877,\"start\":2855},{\"end\":2899,\"start\":2879},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2920,\"start\":2906},{\"end\":2950,\"start\":2922},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3534,\"start\":3516},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3582,\"start\":3561},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":3600,\"start\":3582},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3617,\"start\":3600},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":3634,\"start\":3617},{\"end\":3794,\"start\":3780},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":4591,\"start\":4573},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":4817,\"start\":4796},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":5077,\"start\":5056},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":5255,\"start\":5233},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5271,\"start\":5255},{\"end\":6935,\"start\":6917},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":7984,\"start\":7961},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8007,\"start\":7984},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":8122,\"start\":8105},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":8140,\"start\":8122},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8158,\"start\":8140},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8261,\"start\":8240},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8278,\"start\":8261},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8425,\"start\":8407},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8448,\"start\":8425},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8571,\"start\":8547},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":8590,\"start\":8571},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":8606,\"start\":8590},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8639,\"start\":8621},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8663,\"start\":8639},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8717,\"start\":8695},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8736,\"start\":8717},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8752,\"start\":8736},{\"end\":8771,\"start\":8752},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":8789,\"start\":8771},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9048,\"start\":9022},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":9068,\"start\":9049},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":9084,\"start\":9068},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":9156,\"start\":9135},{\"end\":9429,\"start\":9411},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":9749,\"start\":9728},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":10123,\"start\":10105},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":10147,\"start\":10123},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":10352,\"start\":10330},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":10373,\"start\":10352},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10409,\"start\":10391},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":10427,\"start\":10409},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10585,\"start\":10562},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":10704,\"start\":10687},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11002,\"start\":10979},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":11041,\"start\":11016},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11219,\"start\":11199},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11236,\"start\":11219},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11255,\"start\":11236},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":11284,\"start\":11263},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":11436,\"start\":11417},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":11540,\"start\":11522},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11699,\"start\":11677},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":12915,\"start\":12896},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":12935,\"start\":12915},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":13092,\"start\":13075},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":13108,\"start\":13092},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":13131,\"start\":13108},{\"end\":13649,\"start\":13631},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13765,\"start\":13743},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13827,\"start\":13805},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":14044,\"start\":14026},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":14068,\"start\":14044},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":14085,\"start\":14068},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":14239,\"start\":14218},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":14257,\"start\":14239},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":14274,\"start\":14257},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":14291,\"start\":14274},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":16397,\"start\":16380},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":17686,\"start\":17668},{\"end\":20316,\"start\":20298},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":20416,\"start\":20393},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":20476,\"start\":20453},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":20529,\"start\":20509},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":20640,\"start\":20619},{\"end\":20675,\"start\":20657},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":21551,\"start\":21523},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21616,\"start\":21596},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":21654,\"start\":21633},{\"end\":21813,\"start\":21795},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":22242,\"start\":22218},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":22269,\"start\":22249},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22323,\"start\":22301},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":22649,\"start\":22621},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22672,\"start\":22650},{\"end\":22726,\"start\":22708},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":24502,\"start\":24481},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":26728,\"start\":26704}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":27717,\"start\":27662},{\"attributes\":{\"id\":\"fig_1\"},\"end\":27838,\"start\":27718},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":28200,\"start\":27839},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":28925,\"start\":28201},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":29420,\"start\":28926},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":29791,\"start\":29421}]", "paragraph": "[{\"end\":3115,\"start\":2085},{\"end\":4337,\"start\":3117},{\"end\":5588,\"start\":4339},{\"end\":6779,\"start\":5590},{\"end\":7177,\"start\":6781},{\"end\":7240,\"start\":7179},{\"end\":7433,\"start\":7242},{\"end\":7607,\"start\":7435},{\"end\":7840,\"start\":7609},{\"end\":8865,\"start\":7857},{\"end\":9950,\"start\":8867},{\"end\":10765,\"start\":9952},{\"end\":12151,\"start\":10767},{\"end\":12668,\"start\":12167},{\"end\":13059,\"start\":12670},{\"end\":13324,\"start\":13061},{\"end\":13566,\"start\":13367},{\"end\":13891,\"start\":13568},{\"end\":14086,\"start\":13893},{\"end\":14551,\"start\":14088},{\"end\":14747,\"start\":14577},{\"end\":14945,\"start\":14757},{\"end\":15543,\"start\":14947},{\"end\":15834,\"start\":15545},{\"end\":16539,\"start\":15836},{\"end\":16933,\"start\":16541},{\"end\":17263,\"start\":16945},{\"end\":17894,\"start\":17310},{\"end\":17976,\"start\":17896},{\"end\":18090,\"start\":17978},{\"end\":18193,\"start\":18092},{\"end\":18473,\"start\":18222},{\"end\":19140,\"start\":18518},{\"end\":19214,\"start\":19142},{\"end\":19321,\"start\":19216},{\"end\":19409,\"start\":19323},{\"end\":19507,\"start\":19411},{\"end\":19632,\"start\":19509},{\"end\":19709,\"start\":19634},{\"end\":19794,\"start\":19711},{\"end\":20084,\"start\":19796},{\"end\":20263,\"start\":20100},{\"end\":20866,\"start\":20288},{\"end\":21228,\"start\":20868},{\"end\":21910,\"start\":21242},{\"end\":22352,\"start\":21912},{\"end\":22824,\"start\":22379},{\"end\":23154,\"start\":22826},{\"end\":23797,\"start\":23184},{\"end\":24503,\"start\":23824},{\"end\":25312,\"start\":24519},{\"end\":25500,\"start\":25314},{\"end\":25913,\"start\":25502},{\"end\":26797,\"start\":25915},{\"end\":26972,\"start\":26799},{\"end\":27661,\"start\":27004},{\"end\":27716,\"start\":27676},{\"end\":27837,\"start\":27732},{\"end\":28182,\"start\":27852},{\"end\":28382,\"start\":28214},{\"end\":29125,\"start\":28939},{\"end\":29622,\"start\":29434}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13366,\"start\":13325},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14575,\"start\":14552},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14576,\"start\":14575},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16944,\"start\":16934},{\"attributes\":{\"id\":\"formula_4\"},\"end\":18221,\"start\":18194}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23194,\"start\":23193},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":23834,\"start\":23833},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":25534,\"start\":25533},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":26075,\"start\":26074}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2083,\"start\":2071},{\"attributes\":{\"n\":\"2\"},\"end\":7855,\"start\":7843},{\"attributes\":{\"n\":\"3\"},\"end\":12165,\"start\":12154},{\"attributes\":{\"n\":\"4\"},\"end\":14755,\"start\":14750},{\"attributes\":{\"n\":\"4.2\"},\"end\":17308,\"start\":17266},{\"attributes\":{\"n\":\"4.3\"},\"end\":18516,\"start\":18476},{\"attributes\":{\"n\":\"5\"},\"end\":20098,\"start\":20087},{\"attributes\":{\"n\":\"5.1\"},\"end\":20286,\"start\":20266},{\"attributes\":{\"n\":\"5.2\"},\"end\":21240,\"start\":21231},{\"attributes\":{\"n\":\"5.3\"},\"end\":22377,\"start\":22355},{\"attributes\":{\"n\":\"5.4\"},\"end\":23169,\"start\":23157},{\"end\":23182,\"start\":23172},{\"end\":23822,\"start\":23800},{\"attributes\":{\"n\":\"5.5\"},\"end\":24517,\"start\":24506},{\"attributes\":{\"n\":\"6\"},\"end\":27002,\"start\":26975},{\"end\":27673,\"start\":27663},{\"end\":27729,\"start\":27719},{\"end\":27849,\"start\":27840},{\"end\":28211,\"start\":28202},{\"end\":28936,\"start\":28927},{\"end\":29431,\"start\":29422}]", "table": "[{\"end\":28200,\"start\":28183},{\"end\":28925,\"start\":28383},{\"end\":29420,\"start\":29126},{\"end\":29791,\"start\":29623}]", "figure_caption": "[{\"end\":27717,\"start\":27675},{\"end\":27838,\"start\":27731},{\"end\":28183,\"start\":27851},{\"end\":28383,\"start\":28213},{\"end\":29126,\"start\":28938},{\"end\":29623,\"start\":29433}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14944,\"start\":14943},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":24708,\"start\":24707}]", "bib_author_first_name": "[{\"end\":30302,\"start\":30297},{\"end\":30316,\"start\":30310},{\"end\":30329,\"start\":30325},{\"end\":30342,\"start\":30340},{\"end\":30357,\"start\":30349},{\"end\":30371,\"start\":30363},{\"end\":30383,\"start\":30377},{\"end\":30400,\"start\":30394},{\"end\":30418,\"start\":30411},{\"end\":30429,\"start\":30426},{\"end\":30559,\"start\":30552},{\"end\":30580,\"start\":30572},{\"end\":30599,\"start\":30592},{\"end\":30612,\"start\":30607},{\"end\":30627,\"start\":30618},{\"end\":30641,\"start\":30636},{\"end\":30785,\"start\":30776},{\"end\":30802,\"start\":30796},{\"end\":30817,\"start\":30811},{\"end\":30834,\"start\":30828},{\"end\":30845,\"start\":30840},{\"end\":30863,\"start\":30858},{\"end\":30880,\"start\":30874},{\"end\":30883,\"start\":30881},{\"end\":30916,\"start\":30903},{\"end\":30932,\"start\":30926},{\"end\":30945,\"start\":30940},{\"end\":31048,\"start\":31042},{\"end\":31064,\"start\":31057},{\"end\":31083,\"start\":31074},{\"end\":31097,\"start\":31092},{\"end\":31223,\"start\":31218},{\"end\":31234,\"start\":31230},{\"end\":31247,\"start\":31242},{\"end\":31263,\"start\":31256},{\"end\":31587,\"start\":31583},{\"end\":31605,\"start\":31598},{\"end\":31618,\"start\":31613},{\"end\":31633,\"start\":31627},{\"end\":31647,\"start\":31642},{\"end\":31649,\"start\":31648},{\"end\":31747,\"start\":31743},{\"end\":31765,\"start\":31758},{\"end\":31778,\"start\":31773},{\"end\":31793,\"start\":31787},{\"end\":31929,\"start\":31923},{\"end\":31940,\"start\":31935},{\"end\":32072,\"start\":32067},{\"end\":32089,\"start\":32081},{\"end\":32103,\"start\":32097},{\"end\":32117,\"start\":32109},{\"end\":32582,\"start\":32578},{\"end\":32593,\"start\":32588},{\"end\":32973,\"start\":32969},{\"end\":32984,\"start\":32979},{\"end\":33314,\"start\":33310},{\"end\":33328,\"start\":33320},{\"end\":33338,\"start\":33333},{\"end\":33349,\"start\":33344},{\"end\":33509,\"start\":33504},{\"end\":33521,\"start\":33516},{\"end\":33538,\"start\":33533},{\"end\":33558,\"start\":33551},{\"end\":33740,\"start\":33734},{\"end\":33756,\"start\":33750},{\"end\":33772,\"start\":33767},{\"end\":33792,\"start\":33782},{\"end\":33806,\"start\":33801},{\"end\":33824,\"start\":33818},{\"end\":33834,\"start\":33829},{\"end\":34177,\"start\":34171},{\"end\":34189,\"start\":34183},{\"end\":34199,\"start\":34195},{\"end\":34214,\"start\":34206},{\"end\":34231,\"start\":34224},{\"end\":34390,\"start\":34381},{\"end\":34414,\"start\":34403},{\"end\":34430,\"start\":34420},{\"end\":34442,\"start\":34437},{\"end\":34453,\"start\":34448},{\"end\":34753,\"start\":34746},{\"end\":34771,\"start\":34763},{\"end\":34784,\"start\":34779},{\"end\":34804,\"start\":34795},{\"end\":34818,\"start\":34813},{\"end\":34837,\"start\":34831},{\"end\":34853,\"start\":34846},{\"end\":34980,\"start\":34975},{\"end\":34991,\"start\":34985},{\"end\":35001,\"start\":34997},{\"end\":35019,\"start\":35011},{\"end\":35027,\"start\":35024},{\"end\":35035,\"start\":35032},{\"end\":35046,\"start\":35040},{\"end\":35056,\"start\":35054},{\"end\":35062,\"start\":35059},{\"end\":35075,\"start\":35069},{\"end\":35092,\"start\":35085},{\"end\":35179,\"start\":35175},{\"end\":35197,\"start\":35189},{\"end\":35210,\"start\":35205},{\"end\":35263,\"start\":35257},{\"end\":35277,\"start\":35271},{\"end\":35285,\"start\":35283},{\"end\":35300,\"start\":35292},{\"end\":35485,\"start\":35477},{\"end\":35503,\"start\":35497},{\"end\":35515,\"start\":35510},{\"end\":35528,\"start\":35521},{\"end\":35542,\"start\":35536},{\"end\":35553,\"start\":35547},{\"end\":35567,\"start\":35562},{\"end\":35581,\"start\":35574},{\"end\":35911,\"start\":35904},{\"end\":35928,\"start\":35924},{\"end\":35938,\"start\":35935},{\"end\":35953,\"start\":35949},{\"end\":35971,\"start\":35967},{\"end\":36140,\"start\":36136},{\"end\":36156,\"start\":36150},{\"end\":36172,\"start\":36168},{\"end\":36185,\"start\":36180},{\"end\":36195,\"start\":36190},{\"end\":36213,\"start\":36202},{\"end\":36226,\"start\":36221},{\"end\":36346,\"start\":36343},{\"end\":36370,\"start\":36360},{\"end\":36387,\"start\":36381},{\"end\":36405,\"start\":36398},{\"end\":36420,\"start\":36415},{\"end\":36434,\"start\":36429},{\"end\":36452,\"start\":36444},{\"end\":36467,\"start\":36462},{\"end\":36485,\"start\":36480},{\"end\":36500,\"start\":36494},{\"end\":36514,\"start\":36506},{\"end\":36531,\"start\":36526},{\"end\":36546,\"start\":36539},{\"end\":36563,\"start\":36555},{\"end\":36577,\"start\":36571},{\"end\":36579,\"start\":36578},{\"end\":36590,\"start\":36585},{\"end\":36606,\"start\":36602},{\"end\":36615,\"start\":36611},{\"end\":36810,\"start\":36804},{\"end\":36821,\"start\":36816},{\"end\":36832,\"start\":36826},{\"end\":36844,\"start\":36840},{\"end\":36857,\"start\":36852},{\"end\":36861,\"start\":36858},{\"end\":36875,\"start\":36868},{\"end\":37009,\"start\":37002},{\"end\":37142,\"start\":37136},{\"end\":37153,\"start\":37148},{\"end\":37167,\"start\":37160},{\"end\":37179,\"start\":37172},{\"end\":37508,\"start\":37502},{\"end\":37522,\"start\":37514},{\"end\":37538,\"start\":37530},{\"end\":37871,\"start\":37864},{\"end\":37884,\"start\":37879},{\"end\":37902,\"start\":37892},{\"end\":37916,\"start\":37911},{\"end\":37934,\"start\":37926},{\"end\":37951,\"start\":37946},{\"end\":37967,\"start\":37959},{\"end\":37981,\"start\":37977},{\"end\":37996,\"start\":37989},{\"end\":38005,\"start\":38002},{\"end\":38186,\"start\":38175},{\"end\":38202,\"start\":38192},{\"end\":38214,\"start\":38209},{\"end\":38518,\"start\":38512},{\"end\":38528,\"start\":38524},{\"end\":38539,\"start\":38534},{\"end\":38554,\"start\":38547},{\"end\":38565,\"start\":38559},{\"end\":38578,\"start\":38573},{\"end\":38589,\"start\":38585},{\"end\":38600,\"start\":38596},{\"end\":38612,\"start\":38608},{\"end\":38633,\"start\":38626},{\"end\":38770,\"start\":38765},{\"end\":38777,\"start\":38775},{\"end\":38789,\"start\":38782},{\"end\":38803,\"start\":38797},{\"end\":38814,\"start\":38808},{\"end\":38830,\"start\":38822},{\"end\":38840,\"start\":38836},{\"end\":38857,\"start\":38850},{\"end\":38869,\"start\":38863},{\"end\":39278,\"start\":39272},{\"end\":39292,\"start\":39284},{\"end\":39304,\"start\":39298},{\"end\":39318,\"start\":39311},{\"end\":39330,\"start\":39323},{\"end\":39446,\"start\":39440},{\"end\":39461,\"start\":39452},{\"end\":39474,\"start\":39466},{\"end\":39486,\"start\":39480},{\"end\":39501,\"start\":39493},{\"end\":39513,\"start\":39507},{\"end\":39525,\"start\":39519},{\"end\":39975,\"start\":39970},{\"end\":39985,\"start\":39981},{\"end\":39997,\"start\":39993},{\"end\":40019,\"start\":40011},{\"end\":40554,\"start\":40545},{\"end\":40568,\"start\":40563},{\"end\":40583,\"start\":40577},{\"end\":40596,\"start\":40592},{\"end\":40605,\"start\":40601},{\"end\":40623,\"start\":40614},{\"end\":40640,\"start\":40629},{\"end\":40656,\"start\":40648},{\"end\":40669,\"start\":40663},{\"end\":40687,\"start\":40680},{\"end\":40847,\"start\":40841},{\"end\":40856,\"start\":40852},{\"end\":40865,\"start\":40861},{\"end\":40876,\"start\":40870},{\"end\":40889,\"start\":40882},{\"end\":40910,\"start\":40908},{\"end\":40922,\"start\":40915},{\"end\":40931,\"start\":40929},{\"end\":40943,\"start\":40938},{\"end\":40958,\"start\":40950},{\"end\":40972,\"start\":40966},{\"end\":41272,\"start\":41265},{\"end\":41286,\"start\":41283},{\"end\":41298,\"start\":41293},{\"end\":41313,\"start\":41304},{\"end\":41549,\"start\":41545},{\"end\":41565,\"start\":41558},{\"end\":41572,\"start\":41570},{\"end\":41585,\"start\":41580},{\"end\":41602,\"start\":41595},{\"end\":41621,\"start\":41615},{\"end\":41636,\"start\":41631},{\"end\":41652,\"start\":41644},{\"end\":41670,\"start\":41662},{\"end\":41682,\"start\":41678},{\"end\":41865,\"start\":41859},{\"end\":41878,\"start\":41872},{\"end\":41896,\"start\":41887},{\"end\":41904,\"start\":41901},{\"end\":41917,\"start\":41912},{\"end\":41925,\"start\":41923},{\"end\":41937,\"start\":41930},{\"end\":41949,\"start\":41945},{\"end\":41961,\"start\":41957},{\"end\":41972,\"start\":41966},{\"end\":42057,\"start\":42052},{\"end\":42070,\"start\":42067},{\"end\":42093,\"start\":42084},{\"end\":42109,\"start\":42102},{\"end\":42122,\"start\":42117},{\"end\":42139,\"start\":42132},{\"end\":42153,\"start\":42144},{\"end\":42670,\"start\":42662},{\"end\":42681,\"start\":42676},{\"end\":42698,\"start\":42689},{\"end\":42711,\"start\":42706},{\"end\":42727,\"start\":42718},{\"end\":42742,\"start\":42738},{\"end\":42895,\"start\":42889},{\"end\":42906,\"start\":42900},{\"end\":42917,\"start\":42913},{\"end\":42926,\"start\":42923},{\"end\":42939,\"start\":42932},{\"end\":42950,\"start\":42945},{\"end\":42954,\"start\":42951},{\"end\":42968,\"start\":42961},{\"end\":42978,\"start\":42975},{\"end\":42990,\"start\":42983},{\"end\":43273,\"start\":43269},{\"end\":43288,\"start\":43283},{\"end\":43301,\"start\":43297},{\"end\":43636,\"start\":43629},{\"end\":43638,\"start\":43637},{\"end\":43654,\"start\":43650},{\"end\":43910,\"start\":43902},{\"end\":43923,\"start\":43919},{\"end\":43937,\"start\":43931},{\"end\":43950,\"start\":43945},{\"end\":43970,\"start\":43963},{\"end\":43982,\"start\":43976},{\"end\":43995,\"start\":43991},{\"end\":44328,\"start\":44322},{\"end\":44341,\"start\":44335},{\"end\":44355,\"start\":44350},{\"end\":44371,\"start\":44364},{\"end\":44385,\"start\":44378},{\"end\":44400,\"start\":44396},{\"end\":44418,\"start\":44411},{\"end\":44434,\"start\":44428},{\"end\":44449,\"start\":44445},{\"end\":44461,\"start\":44456},{\"end\":44533,\"start\":44527},{\"end\":44544,\"start\":44539},{\"end\":44559,\"start\":44550},{\"end\":44577,\"start\":44570},{\"end\":44587,\"start\":44583},{\"end\":44599,\"start\":44595},{\"end\":44611,\"start\":44607},{\"end\":44632,\"start\":44625},{\"end\":44795,\"start\":44791},{\"end\":44812,\"start\":44805},{\"end\":44823,\"start\":44819},{\"end\":44835,\"start\":44830},{\"end\":44848,\"start\":44843},{\"end\":45104,\"start\":45102},{\"end\":45114,\"start\":45110},{\"end\":45128,\"start\":45121},{\"end\":45145,\"start\":45139},{\"end\":45154,\"start\":45150},{\"end\":45167,\"start\":45162},{\"end\":45179,\"start\":45175},{\"end\":45188,\"start\":45185},{\"end\":45197,\"start\":45194},{\"end\":45207,\"start\":45204},{\"end\":45369,\"start\":45363},{\"end\":45382,\"start\":45378},{\"end\":45399,\"start\":45392},{\"end\":45416,\"start\":45408},{\"end\":45434,\"start\":45429},{\"end\":45581,\"start\":45576},{\"end\":45597,\"start\":45590},{\"end\":45611,\"start\":45607},{\"end\":45855,\"start\":45848},{\"end\":45877,\"start\":45870},{\"end\":45892,\"start\":45886},{\"end\":45912,\"start\":45902},{\"end\":45931,\"start\":45923},{\"end\":45949,\"start\":45941},{\"end\":45964,\"start\":45959},{\"end\":45978,\"start\":45974},{\"end\":46154,\"start\":46149},{\"end\":46156,\"start\":46155},{\"end\":46273,\"start\":46268},{\"end\":46286,\"start\":46280},{\"end\":46299,\"start\":46295},{\"end\":46314,\"start\":46309},{\"end\":46761,\"start\":46756},{\"end\":46771,\"start\":46768},{\"end\":46782,\"start\":46778},{\"end\":46879,\"start\":46874},{\"end\":46892,\"start\":46885},{\"end\":46907,\"start\":46900},{\"end\":46920,\"start\":46914},{\"end\":46931,\"start\":46926},{\"end\":46935,\"start\":46932},{\"end\":46945,\"start\":46940},{\"end\":46957,\"start\":46954},{\"end\":46968,\"start\":46962},{\"end\":46970,\"start\":46969},{\"end\":46982,\"start\":46976},{\"end\":47136,\"start\":47130},{\"end\":47148,\"start\":47143},{\"end\":47161,\"start\":47154},{\"end\":47172,\"start\":47168},{\"end\":47512,\"start\":47509},{\"end\":47527,\"start\":47520},{\"end\":47537,\"start\":47535},{\"end\":47551,\"start\":47542},{\"end\":47564,\"start\":47558},{\"end\":47574,\"start\":47570},{\"end\":47576,\"start\":47575},{\"end\":47592,\"start\":47586},{\"end\":47606,\"start\":47600},{\"end\":47746,\"start\":47740},{\"end\":47756,\"start\":47753},{\"end\":47768,\"start\":47763},{\"end\":47926,\"start\":47920},{\"end\":47941,\"start\":47934},{\"end\":47954,\"start\":47949},{\"end\":47965,\"start\":47961},{\"end\":47975,\"start\":47970},{\"end\":47977,\"start\":47976},{\"end\":47992,\"start\":47988},{\"end\":47994,\"start\":47993},{\"end\":48213,\"start\":48207},{\"end\":48228,\"start\":48221},{\"end\":48244,\"start\":48239},{\"end\":48719,\"start\":48713},{\"end\":48727,\"start\":48724},{\"end\":48742,\"start\":48734},{\"end\":48756,\"start\":48749},{\"end\":48769,\"start\":48761},{\"end\":48780,\"start\":48774},{\"end\":48798,\"start\":48789},{\"end\":48811,\"start\":48804},{\"end\":48822,\"start\":48818},{\"end\":49032,\"start\":49029},{\"end\":49044,\"start\":49037},{\"end\":49054,\"start\":49052},{\"end\":49064,\"start\":49060},{\"end\":49078,\"start\":49072},{\"end\":49429,\"start\":49423},{\"end\":49445,\"start\":49436},{\"end\":49456,\"start\":49450},{\"end\":49467,\"start\":49464},{\"end\":49475,\"start\":49473},{\"end\":49487,\"start\":49482},{\"end\":49497,\"start\":49492},{\"end\":49508,\"start\":49505},{\"end\":49520,\"start\":49516},{\"end\":49529,\"start\":49526},{\"end\":49537,\"start\":49534},{\"end\":49548,\"start\":49545},{\"end\":49557,\"start\":49554}]", "bib_author_last_name": "[{\"end\":30308,\"start\":30303},{\"end\":30323,\"start\":30317},{\"end\":30338,\"start\":30330},{\"end\":30347,\"start\":30343},{\"end\":30361,\"start\":30358},{\"end\":30375,\"start\":30372},{\"end\":30392,\"start\":30384},{\"end\":30409,\"start\":30401},{\"end\":30424,\"start\":30419},{\"end\":30436,\"start\":30430},{\"end\":30570,\"start\":30560},{\"end\":30590,\"start\":30581},{\"end\":30605,\"start\":30600},{\"end\":30616,\"start\":30613},{\"end\":30634,\"start\":30628},{\"end\":30649,\"start\":30642},{\"end\":30794,\"start\":30786},{\"end\":30809,\"start\":30803},{\"end\":30826,\"start\":30818},{\"end\":30838,\"start\":30835},{\"end\":30856,\"start\":30846},{\"end\":30872,\"start\":30864},{\"end\":30901,\"start\":30884},{\"end\":30924,\"start\":30917},{\"end\":30938,\"start\":30933},{\"end\":30951,\"start\":30946},{\"end\":31055,\"start\":31049},{\"end\":31072,\"start\":31065},{\"end\":31090,\"start\":31084},{\"end\":31105,\"start\":31098},{\"end\":31228,\"start\":31224},{\"end\":31240,\"start\":31235},{\"end\":31254,\"start\":31248},{\"end\":31270,\"start\":31264},{\"end\":31596,\"start\":31588},{\"end\":31611,\"start\":31606},{\"end\":31625,\"start\":31619},{\"end\":31640,\"start\":31634},{\"end\":31658,\"start\":31650},{\"end\":31756,\"start\":31748},{\"end\":31771,\"start\":31766},{\"end\":31785,\"start\":31779},{\"end\":31800,\"start\":31794},{\"end\":31933,\"start\":31930},{\"end\":31947,\"start\":31941},{\"end\":32079,\"start\":32073},{\"end\":32095,\"start\":32090},{\"end\":32107,\"start\":32104},{\"end\":32127,\"start\":32118},{\"end\":32586,\"start\":32583},{\"end\":32600,\"start\":32594},{\"end\":32977,\"start\":32974},{\"end\":32991,\"start\":32985},{\"end\":33318,\"start\":33315},{\"end\":33331,\"start\":33329},{\"end\":33342,\"start\":33339},{\"end\":33356,\"start\":33350},{\"end\":33514,\"start\":33510},{\"end\":33531,\"start\":33522},{\"end\":33549,\"start\":33539},{\"end\":33562,\"start\":33559},{\"end\":33748,\"start\":33741},{\"end\":33765,\"start\":33757},{\"end\":33780,\"start\":33773},{\"end\":33799,\"start\":33793},{\"end\":33816,\"start\":33807},{\"end\":33827,\"start\":33825},{\"end\":33847,\"start\":33835},{\"end\":34106,\"start\":34100},{\"end\":34114,\"start\":34108},{\"end\":34181,\"start\":34178},{\"end\":34193,\"start\":34190},{\"end\":34204,\"start\":34200},{\"end\":34222,\"start\":34215},{\"end\":34237,\"start\":34232},{\"end\":34401,\"start\":34391},{\"end\":34418,\"start\":34415},{\"end\":34435,\"start\":34431},{\"end\":34446,\"start\":34443},{\"end\":34461,\"start\":34454},{\"end\":34761,\"start\":34754},{\"end\":34777,\"start\":34772},{\"end\":34793,\"start\":34785},{\"end\":34811,\"start\":34805},{\"end\":34829,\"start\":34819},{\"end\":34844,\"start\":34838},{\"end\":34859,\"start\":34854},{\"end\":34983,\"start\":34981},{\"end\":34995,\"start\":34992},{\"end\":35009,\"start\":35002},{\"end\":35022,\"start\":35020},{\"end\":35030,\"start\":35028},{\"end\":35038,\"start\":35036},{\"end\":35052,\"start\":35047},{\"end\":35067,\"start\":35063},{\"end\":35083,\"start\":35076},{\"end\":35097,\"start\":35093},{\"end\":35187,\"start\":35180},{\"end\":35203,\"start\":35198},{\"end\":35216,\"start\":35211},{\"end\":35269,\"start\":35264},{\"end\":35281,\"start\":35278},{\"end\":35290,\"start\":35286},{\"end\":35310,\"start\":35301},{\"end\":35495,\"start\":35486},{\"end\":35508,\"start\":35504},{\"end\":35519,\"start\":35516},{\"end\":35534,\"start\":35529},{\"end\":35545,\"start\":35543},{\"end\":35560,\"start\":35554},{\"end\":35572,\"start\":35568},{\"end\":35585,\"start\":35582},{\"end\":35922,\"start\":35912},{\"end\":35933,\"start\":35929},{\"end\":35947,\"start\":35939},{\"end\":35965,\"start\":35954},{\"end\":35977,\"start\":35972},{\"end\":36148,\"start\":36141},{\"end\":36166,\"start\":36157},{\"end\":36178,\"start\":36173},{\"end\":36188,\"start\":36186},{\"end\":36200,\"start\":36196},{\"end\":36219,\"start\":36214},{\"end\":36232,\"start\":36227},{\"end\":36241,\"start\":36234},{\"end\":36358,\"start\":36347},{\"end\":36379,\"start\":36371},{\"end\":36396,\"start\":36388},{\"end\":36413,\"start\":36406},{\"end\":36427,\"start\":36421},{\"end\":36442,\"start\":36435},{\"end\":36460,\"start\":36453},{\"end\":36478,\"start\":36468},{\"end\":36492,\"start\":36486},{\"end\":36504,\"start\":36501},{\"end\":36524,\"start\":36515},{\"end\":36537,\"start\":36532},{\"end\":36553,\"start\":36547},{\"end\":36569,\"start\":36564},{\"end\":36583,\"start\":36580},{\"end\":36600,\"start\":36591},{\"end\":36609,\"start\":36607},{\"end\":36622,\"start\":36616},{\"end\":36814,\"start\":36811},{\"end\":36824,\"start\":36822},{\"end\":36838,\"start\":36833},{\"end\":36850,\"start\":36845},{\"end\":36866,\"start\":36862},{\"end\":36879,\"start\":36876},{\"end\":37014,\"start\":37010},{\"end\":37146,\"start\":37143},{\"end\":37158,\"start\":37154},{\"end\":37170,\"start\":37168},{\"end\":37183,\"start\":37180},{\"end\":37512,\"start\":37509},{\"end\":37528,\"start\":37523},{\"end\":37548,\"start\":37539},{\"end\":37877,\"start\":37872},{\"end\":37890,\"start\":37885},{\"end\":37909,\"start\":37903},{\"end\":37924,\"start\":37917},{\"end\":37944,\"start\":37935},{\"end\":37957,\"start\":37952},{\"end\":37975,\"start\":37968},{\"end\":37987,\"start\":37982},{\"end\":38000,\"start\":37997},{\"end\":38017,\"start\":38006},{\"end\":38190,\"start\":38187},{\"end\":38207,\"start\":38203},{\"end\":38218,\"start\":38215},{\"end\":38522,\"start\":38519},{\"end\":38532,\"start\":38529},{\"end\":38545,\"start\":38540},{\"end\":38557,\"start\":38555},{\"end\":38571,\"start\":38566},{\"end\":38583,\"start\":38579},{\"end\":38594,\"start\":38590},{\"end\":38606,\"start\":38601},{\"end\":38624,\"start\":38613},{\"end\":38642,\"start\":38634},{\"end\":38773,\"start\":38771},{\"end\":38780,\"start\":38778},{\"end\":38795,\"start\":38790},{\"end\":38806,\"start\":38804},{\"end\":38820,\"start\":38815},{\"end\":38834,\"start\":38831},{\"end\":38848,\"start\":38841},{\"end\":38861,\"start\":38858},{\"end\":38878,\"start\":38870},{\"end\":39282,\"start\":39279},{\"end\":39296,\"start\":39293},{\"end\":39309,\"start\":39305},{\"end\":39321,\"start\":39319},{\"end\":39335,\"start\":39331},{\"end\":39450,\"start\":39447},{\"end\":39464,\"start\":39462},{\"end\":39478,\"start\":39475},{\"end\":39491,\"start\":39487},{\"end\":39505,\"start\":39502},{\"end\":39517,\"start\":39514},{\"end\":39530,\"start\":39526},{\"end\":39979,\"start\":39976},{\"end\":39991,\"start\":39986},{\"end\":40009,\"start\":39998},{\"end\":40030,\"start\":40020},{\"end\":40511,\"start\":40501},{\"end\":40561,\"start\":40555},{\"end\":40575,\"start\":40569},{\"end\":40590,\"start\":40584},{\"end\":40599,\"start\":40597},{\"end\":40612,\"start\":40606},{\"end\":40627,\"start\":40624},{\"end\":40646,\"start\":40641},{\"end\":40661,\"start\":40657},{\"end\":40678,\"start\":40670},{\"end\":40696,\"start\":40688},{\"end\":40850,\"start\":40848},{\"end\":40859,\"start\":40857},{\"end\":40868,\"start\":40866},{\"end\":40880,\"start\":40877},{\"end\":40906,\"start\":40890},{\"end\":40913,\"start\":40911},{\"end\":40927,\"start\":40923},{\"end\":40936,\"start\":40932},{\"end\":40948,\"start\":40944},{\"end\":40964,\"start\":40959},{\"end\":40977,\"start\":40973},{\"end\":41281,\"start\":41273},{\"end\":41291,\"start\":41287},{\"end\":41302,\"start\":41299},{\"end\":41317,\"start\":41314},{\"end\":41402,\"start\":41396},{\"end\":41411,\"start\":41404},{\"end\":41556,\"start\":41550},{\"end\":41568,\"start\":41566},{\"end\":41578,\"start\":41573},{\"end\":41593,\"start\":41586},{\"end\":41613,\"start\":41603},{\"end\":41629,\"start\":41622},{\"end\":41642,\"start\":41637},{\"end\":41660,\"start\":41653},{\"end\":41676,\"start\":41671},{\"end\":41686,\"start\":41683},{\"end\":41870,\"start\":41866},{\"end\":41885,\"start\":41879},{\"end\":41899,\"start\":41897},{\"end\":41910,\"start\":41905},{\"end\":41921,\"start\":41918},{\"end\":41928,\"start\":41926},{\"end\":41943,\"start\":41938},{\"end\":41955,\"start\":41950},{\"end\":41964,\"start\":41962},{\"end\":41977,\"start\":41973},{\"end\":42065,\"start\":42058},{\"end\":42082,\"start\":42071},{\"end\":42100,\"start\":42094},{\"end\":42115,\"start\":42110},{\"end\":42130,\"start\":42123},{\"end\":42142,\"start\":42140},{\"end\":42160,\"start\":42154},{\"end\":42674,\"start\":42671},{\"end\":42687,\"start\":42682},{\"end\":42704,\"start\":42699},{\"end\":42716,\"start\":42712},{\"end\":42736,\"start\":42728},{\"end\":42747,\"start\":42743},{\"end\":42898,\"start\":42896},{\"end\":42911,\"start\":42907},{\"end\":42921,\"start\":42918},{\"end\":42930,\"start\":42927},{\"end\":42943,\"start\":42940},{\"end\":42959,\"start\":42955},{\"end\":42973,\"start\":42969},{\"end\":42981,\"start\":42979},{\"end\":42995,\"start\":42991},{\"end\":43281,\"start\":43274},{\"end\":43295,\"start\":43289},{\"end\":43309,\"start\":43302},{\"end\":43648,\"start\":43639},{\"end\":43663,\"start\":43655},{\"end\":43803,\"start\":43772},{\"end\":43917,\"start\":43911},{\"end\":43929,\"start\":43924},{\"end\":43943,\"start\":43938},{\"end\":43961,\"start\":43951},{\"end\":43974,\"start\":43971},{\"end\":43989,\"start\":43983},{\"end\":44007,\"start\":43996},{\"end\":44333,\"start\":44329},{\"end\":44348,\"start\":44342},{\"end\":44362,\"start\":44356},{\"end\":44376,\"start\":44372},{\"end\":44394,\"start\":44386},{\"end\":44409,\"start\":44401},{\"end\":44426,\"start\":44419},{\"end\":44443,\"start\":44435},{\"end\":44454,\"start\":44450},{\"end\":44465,\"start\":44462},{\"end\":44537,\"start\":44534},{\"end\":44548,\"start\":44545},{\"end\":44568,\"start\":44560},{\"end\":44581,\"start\":44578},{\"end\":44593,\"start\":44588},{\"end\":44605,\"start\":44600},{\"end\":44623,\"start\":44612},{\"end\":44636,\"start\":44633},{\"end\":44803,\"start\":44796},{\"end\":44817,\"start\":44813},{\"end\":44828,\"start\":44824},{\"end\":44841,\"start\":44836},{\"end\":44855,\"start\":44849},{\"end\":45108,\"start\":45105},{\"end\":45119,\"start\":45115},{\"end\":45137,\"start\":45129},{\"end\":45148,\"start\":45146},{\"end\":45160,\"start\":45155},{\"end\":45173,\"start\":45168},{\"end\":45183,\"start\":45180},{\"end\":45192,\"start\":45189},{\"end\":45202,\"start\":45198},{\"end\":45213,\"start\":45208},{\"end\":45376,\"start\":45370},{\"end\":45390,\"start\":45383},{\"end\":45406,\"start\":45400},{\"end\":45427,\"start\":45417},{\"end\":45443,\"start\":45435},{\"end\":45588,\"start\":45582},{\"end\":45605,\"start\":45598},{\"end\":45621,\"start\":45612},{\"end\":45868,\"start\":45856},{\"end\":45884,\"start\":45878},{\"end\":45900,\"start\":45893},{\"end\":45921,\"start\":45913},{\"end\":45939,\"start\":45932},{\"end\":45957,\"start\":45950},{\"end\":45972,\"start\":45965},{\"end\":45984,\"start\":45979},{\"end\":45992,\"start\":45986},{\"end\":46165,\"start\":46157},{\"end\":46278,\"start\":46274},{\"end\":46293,\"start\":46287},{\"end\":46307,\"start\":46300},{\"end\":46323,\"start\":46315},{\"end\":46766,\"start\":46762},{\"end\":46776,\"start\":46772},{\"end\":46786,\"start\":46783},{\"end\":46883,\"start\":46880},{\"end\":46898,\"start\":46893},{\"end\":46912,\"start\":46908},{\"end\":46924,\"start\":46921},{\"end\":46938,\"start\":46936},{\"end\":46952,\"start\":46946},{\"end\":46960,\"start\":46958},{\"end\":46974,\"start\":46971},{\"end\":46985,\"start\":46983},{\"end\":47141,\"start\":47137},{\"end\":47152,\"start\":47149},{\"end\":47166,\"start\":47162},{\"end\":47176,\"start\":47173},{\"end\":47518,\"start\":47513},{\"end\":47533,\"start\":47528},{\"end\":47540,\"start\":47538},{\"end\":47556,\"start\":47552},{\"end\":47568,\"start\":47565},{\"end\":47584,\"start\":47577},{\"end\":47598,\"start\":47593},{\"end\":47615,\"start\":47607},{\"end\":47751,\"start\":47747},{\"end\":47761,\"start\":47757},{\"end\":47772,\"start\":47769},{\"end\":47782,\"start\":47774},{\"end\":47932,\"start\":47927},{\"end\":47947,\"start\":47942},{\"end\":47959,\"start\":47955},{\"end\":47968,\"start\":47966},{\"end\":47986,\"start\":47978},{\"end\":48000,\"start\":47995},{\"end\":48219,\"start\":48214},{\"end\":48237,\"start\":48229},{\"end\":48248,\"start\":48245},{\"end\":48722,\"start\":48720},{\"end\":48732,\"start\":48728},{\"end\":48747,\"start\":48743},{\"end\":48759,\"start\":48757},{\"end\":48772,\"start\":48770},{\"end\":48787,\"start\":48781},{\"end\":48802,\"start\":48799},{\"end\":48816,\"start\":48812},{\"end\":48828,\"start\":48823},{\"end\":49035,\"start\":49033},{\"end\":49050,\"start\":49045},{\"end\":49058,\"start\":49055},{\"end\":49070,\"start\":49065},{\"end\":49087,\"start\":49079},{\"end\":49434,\"start\":49430},{\"end\":49448,\"start\":49446},{\"end\":49462,\"start\":49457},{\"end\":49471,\"start\":49468},{\"end\":49480,\"start\":49476},{\"end\":49490,\"start\":49488},{\"end\":49503,\"start\":49498},{\"end\":49514,\"start\":49509},{\"end\":49524,\"start\":49521},{\"end\":49532,\"start\":49530},{\"end\":49543,\"start\":49538},{\"end\":49552,\"start\":49549},{\"end\":49562,\"start\":49558}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1611.09268\",\"id\":\"b0\"},\"end\":30472,\"start\":30230},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":248366293},\"end\":30708,\"start\":30474},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":244954723},\"end\":31007,\"start\":30710},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":222125277},\"end\":31165,\"start\":31009},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1171\",\"id\":\"b4\",\"matched_paper_id\":3618568},\"end\":31534,\"start\":31167},{\"attributes\":{\"doi\":\"arXiv:2003.07820\",\"id\":\"b5\"},\"end\":31694,\"start\":31536},{\"attributes\":{\"doi\":\"arXiv:2102.07662\",\"id\":\"b6\"},\"end\":31836,\"start\":31696},{\"attributes\":{\"doi\":\"arXiv:1910.10687\",\"id\":\"b7\"},\"end\":31983,\"start\":31838},{\"attributes\":{\"doi\":\"10.18653/v1/N19-1423\",\"id\":\"b8\",\"matched_paper_id\":52967399},\"end\":32516,\"start\":31985},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.75\",\"id\":\"b9\",\"matched_paper_id\":237581068},\"end\":32884,\"start\":32518},{\"attributes\":{\"doi\":\"10.18653/v1/2022.acl-long.203\",\"id\":\"b10\",\"matched_paper_id\":236987190},\"end\":33248,\"start\":32886},{\"attributes\":{\"doi\":\"arXiv:2212.10496\",\"id\":\"b11\"},\"end\":33392,\"start\":33250},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":245131215},\"end\":33679,\"start\":33394},{\"attributes\":{\"doi\":\"10.18653/v1/K19-1049\",\"id\":\"b13\",\"matched_paper_id\":202718954},\"end\":34096,\"start\":33681},{\"attributes\":{\"id\":\"b14\"},\"end\":34120,\"start\":34098},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":211204736},\"end\":34293,\"start\":34122},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":233231706},\"end\":34676,\"start\":34295},{\"attributes\":{\"doi\":\"2835-8856\",\"id\":\"b17\",\"matched_paper_id\":249097975},\"end\":34917,\"start\":34678},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":246652372},\"end\":35130,\"start\":34919},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":926364},\"end\":35255,\"start\":35132},{\"attributes\":{\"doi\":\"arXiv:2004.12006\",\"id\":\"b20\"},\"end\":35415,\"start\":35257},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.550\",\"id\":\"b21\",\"matched_paper_id\":215737187},\"end\":35831,\"start\":35417},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":207870430},\"end\":36037,\"start\":35833},{\"attributes\":{\"doi\":\"arXiv:2212.14024\",\"id\":\"b23\"},\"end\":36277,\"start\":36039},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00276\",\"id\":\"b24\",\"matched_paper_id\":86611921},\"end\":36712,\"start\":36279},{\"attributes\":{\"doi\":\"10.24963/ijcai.2021/611\",\"id\":\"b25\",\"matched_paper_id\":235187102},\"end\":37102,\"start\":36714},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":249049410},\"end\":37429,\"start\":37104},{\"attributes\":{\"doi\":\"10.18653/v1/P19-1612\",\"id\":\"b27\",\"matched_paper_id\":173990818},\"end\":37796,\"start\":37431},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":218869575},\"end\":38076,\"start\":37798},{\"attributes\":{\"doi\":\"10.18653/v1/2021.repl4nlp-1.17\",\"id\":\"b29\",\"matched_paper_id\":235720578},\"end\":38453,\"start\":38078},{\"attributes\":{\"doi\":\"CoRR, abs/1907.11692\",\"id\":\"b30\"},\"end\":38668,\"start\":38455},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.220\",\"id\":\"b31\",\"matched_paper_id\":243865399},\"end\":39163,\"start\":38670},{\"attributes\":{\"doi\":\"arXiv:2303.06573\",\"id\":\"b32\"},\"end\":39371,\"start\":39165},{\"attributes\":{\"doi\":\"doi: 10.18653\",\"id\":\"b33\",\"matched_paper_id\":221802772},\"end\":39922,\"start\":39373},{\"attributes\":{\"id\":\"b34\"},\"end\":39929,\"start\":39924},{\"attributes\":{\"doi\":\"doi: 10.18653\",\"id\":\"b35\",\"matched_paper_id\":240288835},\"end\":40388,\"start\":39931},{\"attributes\":{\"id\":\"b36\"},\"end\":40395,\"start\":40390},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":31674042},\"end\":40543,\"start\":40397},{\"attributes\":{\"doi\":\"arXiv:2112.09332\",\"id\":\"b38\"},\"end\":40789,\"start\":40545},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":245144556},\"end\":41223,\"start\":40791},{\"attributes\":{\"doi\":\"arXiv:1904.08375\",\"id\":\"b40\"},\"end\":41353,\"start\":41225},{\"attributes\":{\"id\":\"b41\"},\"end\":41413,\"start\":41355},{\"attributes\":{\"doi\":\"ArXiv, abs/2303.08774\",\"id\":\"b42\"},\"end\":41474,\"start\":41415},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":246426909},\"end\":41745,\"start\":41476},{\"attributes\":{\"doi\":\"arXiv:2302.12813\",\"id\":\"b44\"},\"end\":42013,\"start\":41747},{\"attributes\":{\"doi\":\"10.18653/v1/D19-1250\",\"id\":\"b45\",\"matched_paper_id\":202539551},\"end\":42589,\"start\":42015},{\"attributes\":{\"doi\":\"arXiv:2302.06476\",\"id\":\"b46\"},\"end\":42783,\"start\":42591},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.466\",\"id\":\"b47\",\"matched_paper_id\":231815627},\"end\":43193,\"start\":42785},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.437\",\"id\":\"b48\",\"matched_paper_id\":211205183},\"end\":43571,\"start\":43195},{\"attributes\":{\"doi\":\"10.1561/1500000019\",\"id\":\"b49\",\"matched_paper_id\":207178704},\"end\":43714,\"start\":43573},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":207178704},\"end\":43836,\"start\":43716},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":248218489},\"end\":44253,\"start\":43838},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":239009562},\"end\":44525,\"start\":44255},{\"attributes\":{\"doi\":\"arXiv:2301.12652\",\"id\":\"b53\"},\"end\":44727,\"start\":44527},{\"attributes\":{\"doi\":\"10.18653/v1/2021.findings-emnlp.320\",\"id\":\"b54\",\"matched_paper_id\":233240939},\"end\":45047,\"start\":44729},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":246863488},\"end\":45272,\"start\":45049},{\"attributes\":{\"doi\":\"CoRR, abs/2104.08663\",\"id\":\"b56\"},\"end\":45469,\"start\":45274},{\"attributes\":{\"doi\":\"10.18653/v1/W18-5501\",\"id\":\"b57\",\"matched_paper_id\":53645946},\"end\":45846,\"start\":45471},{\"attributes\":{\"doi\":\"arXiv:2302.13971\",\"id\":\"b58\"},\"end\":46103,\"start\":45848},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":16944215},\"end\":46179,\"start\":46105},{\"attributes\":{\"doi\":\"10.18653/v1/2022.naacl-main.168\",\"id\":\"b60\",\"matched_paper_id\":245131402},\"end\":46699,\"start\":46181},{\"attributes\":{\"doi\":\"arXiv:2303.07678\",\"id\":\"b61\"},\"end\":46822,\"start\":46701},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":237416585},\"end\":47045,\"start\":46824},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":252917569},\"end\":47422,\"start\":47047},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":220302524},\"end\":47675,\"start\":47424},{\"attributes\":{\"doi\":\"10.1145/3077136.3080721\",\"id\":\"b65\",\"matched_paper_id\":1340183},\"end\":48146,\"start\":47677},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-tutorials.1\",\"id\":\"b66\",\"matched_paper_id\":222310837},\"end\":48627,\"start\":48148},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":252408513},\"end\":48901,\"start\":48629},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":253157773},\"end\":49333,\"start\":48903},{\"attributes\":{\"doi\":\"doi: 10.18653\",\"id\":\"b69\",\"matched_paper_id\":247447562},\"end\":49816,\"start\":49335},{\"attributes\":{\"id\":\"b70\"},\"end\":49823,\"start\":49818}]", "bib_title": "[{\"end\":30550,\"start\":30474},{\"end\":30774,\"start\":30710},{\"end\":31040,\"start\":31009},{\"end\":31216,\"start\":31167},{\"end\":32065,\"start\":31985},{\"end\":32576,\"start\":32518},{\"end\":32967,\"start\":32886},{\"end\":33502,\"start\":33394},{\"end\":33732,\"start\":33681},{\"end\":34169,\"start\":34122},{\"end\":34379,\"start\":34295},{\"end\":34744,\"start\":34678},{\"end\":34973,\"start\":34919},{\"end\":35173,\"start\":35132},{\"end\":35475,\"start\":35417},{\"end\":35902,\"start\":35833},{\"end\":36341,\"start\":36279},{\"end\":36802,\"start\":36714},{\"end\":37134,\"start\":37104},{\"end\":37500,\"start\":37431},{\"end\":37862,\"start\":37798},{\"end\":38173,\"start\":38078},{\"end\":38763,\"start\":38670},{\"end\":39438,\"start\":39373},{\"end\":39968,\"start\":39931},{\"end\":40499,\"start\":40397},{\"end\":40839,\"start\":40791},{\"end\":41543,\"start\":41476},{\"end\":42050,\"start\":42015},{\"end\":42887,\"start\":42785},{\"end\":43267,\"start\":43195},{\"end\":43627,\"start\":43573},{\"end\":43770,\"start\":43716},{\"end\":43900,\"start\":43838},{\"end\":44320,\"start\":44255},{\"end\":44789,\"start\":44729},{\"end\":45100,\"start\":45049},{\"end\":45574,\"start\":45471},{\"end\":46147,\"start\":46105},{\"end\":46266,\"start\":46181},{\"end\":46872,\"start\":46824},{\"end\":47128,\"start\":47047},{\"end\":47507,\"start\":47424},{\"end\":47738,\"start\":47677},{\"end\":48205,\"start\":48148},{\"end\":48711,\"start\":48629},{\"end\":49027,\"start\":48903},{\"end\":49421,\"start\":49335}]", "bib_author": "[{\"end\":30310,\"start\":30297},{\"end\":30325,\"start\":30310},{\"end\":30340,\"start\":30325},{\"end\":30349,\"start\":30340},{\"end\":30363,\"start\":30349},{\"end\":30377,\"start\":30363},{\"end\":30394,\"start\":30377},{\"end\":30411,\"start\":30394},{\"end\":30426,\"start\":30411},{\"end\":30438,\"start\":30426},{\"end\":30572,\"start\":30552},{\"end\":30592,\"start\":30572},{\"end\":30607,\"start\":30592},{\"end\":30618,\"start\":30607},{\"end\":30636,\"start\":30618},{\"end\":30651,\"start\":30636},{\"end\":30796,\"start\":30776},{\"end\":30811,\"start\":30796},{\"end\":30828,\"start\":30811},{\"end\":30840,\"start\":30828},{\"end\":30858,\"start\":30840},{\"end\":30874,\"start\":30858},{\"end\":30903,\"start\":30874},{\"end\":30926,\"start\":30903},{\"end\":30940,\"start\":30926},{\"end\":30953,\"start\":30940},{\"end\":31057,\"start\":31042},{\"end\":31074,\"start\":31057},{\"end\":31092,\"start\":31074},{\"end\":31107,\"start\":31092},{\"end\":31230,\"start\":31218},{\"end\":31242,\"start\":31230},{\"end\":31256,\"start\":31242},{\"end\":31272,\"start\":31256},{\"end\":31598,\"start\":31583},{\"end\":31613,\"start\":31598},{\"end\":31627,\"start\":31613},{\"end\":31642,\"start\":31627},{\"end\":31660,\"start\":31642},{\"end\":31758,\"start\":31743},{\"end\":31773,\"start\":31758},{\"end\":31787,\"start\":31773},{\"end\":31802,\"start\":31787},{\"end\":31935,\"start\":31923},{\"end\":31949,\"start\":31935},{\"end\":32081,\"start\":32067},{\"end\":32097,\"start\":32081},{\"end\":32109,\"start\":32097},{\"end\":32129,\"start\":32109},{\"end\":32588,\"start\":32578},{\"end\":32602,\"start\":32588},{\"end\":32979,\"start\":32969},{\"end\":32993,\"start\":32979},{\"end\":33320,\"start\":33310},{\"end\":33333,\"start\":33320},{\"end\":33344,\"start\":33333},{\"end\":33358,\"start\":33344},{\"end\":33516,\"start\":33504},{\"end\":33533,\"start\":33516},{\"end\":33551,\"start\":33533},{\"end\":33564,\"start\":33551},{\"end\":33750,\"start\":33734},{\"end\":33767,\"start\":33750},{\"end\":33782,\"start\":33767},{\"end\":33801,\"start\":33782},{\"end\":33818,\"start\":33801},{\"end\":33829,\"start\":33818},{\"end\":33849,\"start\":33829},{\"end\":34108,\"start\":34100},{\"end\":34116,\"start\":34108},{\"end\":34183,\"start\":34171},{\"end\":34195,\"start\":34183},{\"end\":34206,\"start\":34195},{\"end\":34224,\"start\":34206},{\"end\":34239,\"start\":34224},{\"end\":34403,\"start\":34381},{\"end\":34420,\"start\":34403},{\"end\":34437,\"start\":34420},{\"end\":34448,\"start\":34437},{\"end\":34463,\"start\":34448},{\"end\":34763,\"start\":34746},{\"end\":34779,\"start\":34763},{\"end\":34795,\"start\":34779},{\"end\":34813,\"start\":34795},{\"end\":34831,\"start\":34813},{\"end\":34846,\"start\":34831},{\"end\":34861,\"start\":34846},{\"end\":34985,\"start\":34975},{\"end\":34997,\"start\":34985},{\"end\":35011,\"start\":34997},{\"end\":35024,\"start\":35011},{\"end\":35032,\"start\":35024},{\"end\":35040,\"start\":35032},{\"end\":35054,\"start\":35040},{\"end\":35059,\"start\":35054},{\"end\":35069,\"start\":35059},{\"end\":35085,\"start\":35069},{\"end\":35099,\"start\":35085},{\"end\":35189,\"start\":35175},{\"end\":35205,\"start\":35189},{\"end\":35218,\"start\":35205},{\"end\":35271,\"start\":35257},{\"end\":35283,\"start\":35271},{\"end\":35292,\"start\":35283},{\"end\":35312,\"start\":35292},{\"end\":35497,\"start\":35477},{\"end\":35510,\"start\":35497},{\"end\":35521,\"start\":35510},{\"end\":35536,\"start\":35521},{\"end\":35547,\"start\":35536},{\"end\":35562,\"start\":35547},{\"end\":35574,\"start\":35562},{\"end\":35587,\"start\":35574},{\"end\":35924,\"start\":35904},{\"end\":35935,\"start\":35924},{\"end\":35949,\"start\":35935},{\"end\":35967,\"start\":35949},{\"end\":35979,\"start\":35967},{\"end\":36150,\"start\":36136},{\"end\":36168,\"start\":36150},{\"end\":36180,\"start\":36168},{\"end\":36190,\"start\":36180},{\"end\":36202,\"start\":36190},{\"end\":36221,\"start\":36202},{\"end\":36234,\"start\":36221},{\"end\":36243,\"start\":36234},{\"end\":36360,\"start\":36343},{\"end\":36381,\"start\":36360},{\"end\":36398,\"start\":36381},{\"end\":36415,\"start\":36398},{\"end\":36429,\"start\":36415},{\"end\":36444,\"start\":36429},{\"end\":36462,\"start\":36444},{\"end\":36480,\"start\":36462},{\"end\":36494,\"start\":36480},{\"end\":36506,\"start\":36494},{\"end\":36526,\"start\":36506},{\"end\":36539,\"start\":36526},{\"end\":36555,\"start\":36539},{\"end\":36571,\"start\":36555},{\"end\":36585,\"start\":36571},{\"end\":36602,\"start\":36585},{\"end\":36611,\"start\":36602},{\"end\":36624,\"start\":36611},{\"end\":36816,\"start\":36804},{\"end\":36826,\"start\":36816},{\"end\":36840,\"start\":36826},{\"end\":36852,\"start\":36840},{\"end\":36868,\"start\":36852},{\"end\":36881,\"start\":36868},{\"end\":37148,\"start\":37136},{\"end\":37160,\"start\":37148},{\"end\":37172,\"start\":37160},{\"end\":37185,\"start\":37172},{\"end\":37514,\"start\":37502},{\"end\":37530,\"start\":37514},{\"end\":37550,\"start\":37530},{\"end\":37879,\"start\":37864},{\"end\":37892,\"start\":37879},{\"end\":37911,\"start\":37892},{\"end\":37926,\"start\":37911},{\"end\":37946,\"start\":37926},{\"end\":37959,\"start\":37946},{\"end\":37977,\"start\":37959},{\"end\":37989,\"start\":37977},{\"end\":38002,\"start\":37989},{\"end\":38019,\"start\":38002},{\"end\":38192,\"start\":38175},{\"end\":38209,\"start\":38192},{\"end\":38220,\"start\":38209},{\"end\":38524,\"start\":38512},{\"end\":38534,\"start\":38524},{\"end\":38547,\"start\":38534},{\"end\":38559,\"start\":38547},{\"end\":38573,\"start\":38559},{\"end\":38585,\"start\":38573},{\"end\":38596,\"start\":38585},{\"end\":38608,\"start\":38596},{\"end\":38626,\"start\":38608},{\"end\":38644,\"start\":38626},{\"end\":38775,\"start\":38765},{\"end\":38782,\"start\":38775},{\"end\":38797,\"start\":38782},{\"end\":38808,\"start\":38797},{\"end\":38822,\"start\":38808},{\"end\":38836,\"start\":38822},{\"end\":38850,\"start\":38836},{\"end\":38863,\"start\":38850},{\"end\":38880,\"start\":38863},{\"end\":39284,\"start\":39272},{\"end\":39298,\"start\":39284},{\"end\":39311,\"start\":39298},{\"end\":39323,\"start\":39311},{\"end\":39337,\"start\":39323},{\"end\":39452,\"start\":39440},{\"end\":39466,\"start\":39452},{\"end\":39480,\"start\":39466},{\"end\":39493,\"start\":39480},{\"end\":39507,\"start\":39493},{\"end\":39519,\"start\":39507},{\"end\":39532,\"start\":39519},{\"end\":39981,\"start\":39970},{\"end\":39993,\"start\":39981},{\"end\":40011,\"start\":39993},{\"end\":40032,\"start\":40011},{\"end\":40513,\"start\":40501},{\"end\":40563,\"start\":40545},{\"end\":40577,\"start\":40563},{\"end\":40592,\"start\":40577},{\"end\":40601,\"start\":40592},{\"end\":40614,\"start\":40601},{\"end\":40629,\"start\":40614},{\"end\":40648,\"start\":40629},{\"end\":40663,\"start\":40648},{\"end\":40680,\"start\":40663},{\"end\":40698,\"start\":40680},{\"end\":40852,\"start\":40841},{\"end\":40861,\"start\":40852},{\"end\":40870,\"start\":40861},{\"end\":40882,\"start\":40870},{\"end\":40908,\"start\":40882},{\"end\":40915,\"start\":40908},{\"end\":40929,\"start\":40915},{\"end\":40938,\"start\":40929},{\"end\":40950,\"start\":40938},{\"end\":40966,\"start\":40950},{\"end\":40979,\"start\":40966},{\"end\":41283,\"start\":41265},{\"end\":41293,\"start\":41283},{\"end\":41304,\"start\":41293},{\"end\":41319,\"start\":41304},{\"end\":41404,\"start\":41396},{\"end\":41413,\"start\":41404},{\"end\":41558,\"start\":41545},{\"end\":41570,\"start\":41558},{\"end\":41580,\"start\":41570},{\"end\":41595,\"start\":41580},{\"end\":41615,\"start\":41595},{\"end\":41631,\"start\":41615},{\"end\":41644,\"start\":41631},{\"end\":41662,\"start\":41644},{\"end\":41678,\"start\":41662},{\"end\":41688,\"start\":41678},{\"end\":41872,\"start\":41859},{\"end\":41887,\"start\":41872},{\"end\":41901,\"start\":41887},{\"end\":41912,\"start\":41901},{\"end\":41923,\"start\":41912},{\"end\":41930,\"start\":41923},{\"end\":41945,\"start\":41930},{\"end\":41957,\"start\":41945},{\"end\":41966,\"start\":41957},{\"end\":41979,\"start\":41966},{\"end\":42067,\"start\":42052},{\"end\":42084,\"start\":42067},{\"end\":42102,\"start\":42084},{\"end\":42117,\"start\":42102},{\"end\":42132,\"start\":42117},{\"end\":42144,\"start\":42132},{\"end\":42162,\"start\":42144},{\"end\":42676,\"start\":42662},{\"end\":42689,\"start\":42676},{\"end\":42706,\"start\":42689},{\"end\":42718,\"start\":42706},{\"end\":42738,\"start\":42718},{\"end\":42749,\"start\":42738},{\"end\":42900,\"start\":42889},{\"end\":42913,\"start\":42900},{\"end\":42923,\"start\":42913},{\"end\":42932,\"start\":42923},{\"end\":42945,\"start\":42932},{\"end\":42961,\"start\":42945},{\"end\":42975,\"start\":42961},{\"end\":42983,\"start\":42975},{\"end\":42997,\"start\":42983},{\"end\":43283,\"start\":43269},{\"end\":43297,\"start\":43283},{\"end\":43311,\"start\":43297},{\"end\":43650,\"start\":43629},{\"end\":43665,\"start\":43650},{\"end\":43805,\"start\":43772},{\"end\":43919,\"start\":43902},{\"end\":43931,\"start\":43919},{\"end\":43945,\"start\":43931},{\"end\":43963,\"start\":43945},{\"end\":43976,\"start\":43963},{\"end\":43991,\"start\":43976},{\"end\":44009,\"start\":43991},{\"end\":44335,\"start\":44322},{\"end\":44350,\"start\":44335},{\"end\":44364,\"start\":44350},{\"end\":44378,\"start\":44364},{\"end\":44396,\"start\":44378},{\"end\":44411,\"start\":44396},{\"end\":44428,\"start\":44411},{\"end\":44445,\"start\":44428},{\"end\":44456,\"start\":44445},{\"end\":44467,\"start\":44456},{\"end\":44539,\"start\":44527},{\"end\":44550,\"start\":44539},{\"end\":44570,\"start\":44550},{\"end\":44583,\"start\":44570},{\"end\":44595,\"start\":44583},{\"end\":44607,\"start\":44595},{\"end\":44625,\"start\":44607},{\"end\":44638,\"start\":44625},{\"end\":44805,\"start\":44791},{\"end\":44819,\"start\":44805},{\"end\":44830,\"start\":44819},{\"end\":44843,\"start\":44830},{\"end\":44857,\"start\":44843},{\"end\":45110,\"start\":45102},{\"end\":45121,\"start\":45110},{\"end\":45139,\"start\":45121},{\"end\":45150,\"start\":45139},{\"end\":45162,\"start\":45150},{\"end\":45175,\"start\":45162},{\"end\":45185,\"start\":45175},{\"end\":45194,\"start\":45185},{\"end\":45204,\"start\":45194},{\"end\":45215,\"start\":45204},{\"end\":45378,\"start\":45363},{\"end\":45392,\"start\":45378},{\"end\":45408,\"start\":45392},{\"end\":45429,\"start\":45408},{\"end\":45445,\"start\":45429},{\"end\":45590,\"start\":45576},{\"end\":45607,\"start\":45590},{\"end\":45623,\"start\":45607},{\"end\":45870,\"start\":45848},{\"end\":45886,\"start\":45870},{\"end\":45902,\"start\":45886},{\"end\":45923,\"start\":45902},{\"end\":45941,\"start\":45923},{\"end\":45959,\"start\":45941},{\"end\":45974,\"start\":45959},{\"end\":45986,\"start\":45974},{\"end\":45994,\"start\":45986},{\"end\":46167,\"start\":46149},{\"end\":46280,\"start\":46268},{\"end\":46295,\"start\":46280},{\"end\":46309,\"start\":46295},{\"end\":46325,\"start\":46309},{\"end\":46768,\"start\":46756},{\"end\":46778,\"start\":46768},{\"end\":46788,\"start\":46778},{\"end\":46885,\"start\":46874},{\"end\":46900,\"start\":46885},{\"end\":46914,\"start\":46900},{\"end\":46926,\"start\":46914},{\"end\":46940,\"start\":46926},{\"end\":46954,\"start\":46940},{\"end\":46962,\"start\":46954},{\"end\":46976,\"start\":46962},{\"end\":46987,\"start\":46976},{\"end\":47143,\"start\":47130},{\"end\":47154,\"start\":47143},{\"end\":47168,\"start\":47154},{\"end\":47178,\"start\":47168},{\"end\":47520,\"start\":47509},{\"end\":47535,\"start\":47520},{\"end\":47542,\"start\":47535},{\"end\":47558,\"start\":47542},{\"end\":47570,\"start\":47558},{\"end\":47586,\"start\":47570},{\"end\":47600,\"start\":47586},{\"end\":47617,\"start\":47600},{\"end\":47753,\"start\":47740},{\"end\":47763,\"start\":47753},{\"end\":47774,\"start\":47763},{\"end\":47784,\"start\":47774},{\"end\":48221,\"start\":48207},{\"end\":48239,\"start\":48221},{\"end\":48250,\"start\":48239},{\"end\":48724,\"start\":48713},{\"end\":48734,\"start\":48724},{\"end\":48749,\"start\":48734},{\"end\":48761,\"start\":48749},{\"end\":48774,\"start\":48761},{\"end\":48789,\"start\":48774},{\"end\":48804,\"start\":48789},{\"end\":48818,\"start\":48804},{\"end\":48830,\"start\":48818},{\"end\":49037,\"start\":49029},{\"end\":49052,\"start\":49037},{\"end\":49060,\"start\":49052},{\"end\":49072,\"start\":49060},{\"end\":49089,\"start\":49072},{\"end\":49436,\"start\":49423},{\"end\":49450,\"start\":49436},{\"end\":49464,\"start\":49450},{\"end\":49473,\"start\":49464},{\"end\":49482,\"start\":49473},{\"end\":49492,\"start\":49482},{\"end\":49505,\"start\":49492},{\"end\":49516,\"start\":49505},{\"end\":49526,\"start\":49516},{\"end\":49534,\"start\":49526},{\"end\":49545,\"start\":49534},{\"end\":49554,\"start\":49545},{\"end\":49564,\"start\":49554}]", "bib_venue": "[{\"end\":31483,\"start\":31394},{\"end\":32465,\"start\":32316},{\"end\":32809,\"start\":32720},{\"end\":33198,\"start\":33111},{\"end\":33673,\"start\":33627},{\"end\":34042,\"start\":33956},{\"end\":34672,\"start\":34576},{\"end\":35777,\"start\":35706},{\"end\":37097,\"start\":37016},{\"end\":37375,\"start\":37273},{\"end\":37746,\"start\":37659},{\"end\":38401,\"start\":38334},{\"end\":39088,\"start\":38999},{\"end\":39869,\"start\":39722},{\"end\":40338,\"start\":40189},{\"end\":41169,\"start\":41067},{\"end\":42535,\"start\":42359},{\"end\":43143,\"start\":43094},{\"end\":43517,\"start\":43438},{\"end\":44199,\"start\":44097},{\"end\":44993,\"start\":44963},{\"end\":45801,\"start\":45722},{\"end\":46649,\"start\":46500},{\"end\":47368,\"start\":47266},{\"end\":48120,\"start\":48002},{\"end\":48577,\"start\":48439},{\"end\":49279,\"start\":49177},{\"end\":49766,\"start\":49679},{\"end\":30295,\"start\":30230},{\"end\":30700,\"start\":30651},{\"end\":30997,\"start\":30953},{\"end\":31159,\"start\":31107},{\"end\":31379,\"start\":31292},{\"end\":31392,\"start\":31381},{\"end\":31581,\"start\":31536},{\"end\":31741,\"start\":31696},{\"end\":31921,\"start\":31838},{\"end\":32291,\"start\":32149},{\"end\":32314,\"start\":32293},{\"end\":32718,\"start\":32632},{\"end\":33109,\"start\":33022},{\"end\":33308,\"start\":33250},{\"end\":33625,\"start\":33564},{\"end\":33954,\"start\":33869},{\"end\":34283,\"start\":34239},{\"end\":34574,\"start\":34463},{\"end\":34902,\"start\":34861},{\"end\":35120,\"start\":35099},{\"end\":35247,\"start\":35218},{\"end\":35395,\"start\":35328},{\"end\":35704,\"start\":35618},{\"end\":36031,\"start\":35979},{\"end\":36134,\"start\":36039},{\"end\":36705,\"start\":36644},{\"end\":37000,\"start\":36904},{\"end\":37271,\"start\":37185},{\"end\":37657,\"start\":37570},{\"end\":38068,\"start\":38019},{\"end\":38332,\"start\":38250},{\"end\":38510,\"start\":38455},{\"end\":38997,\"start\":38911},{\"end\":39270,\"start\":39165},{\"end\":39707,\"start\":39545},{\"end\":39720,\"start\":39709},{\"end\":39927,\"start\":39924},{\"end\":40187,\"start\":40045},{\"end\":40393,\"start\":40390},{\"end\":40534,\"start\":40513},{\"end\":40769,\"start\":40714},{\"end\":41065,\"start\":40979},{\"end\":41263,\"start\":41225},{\"end\":41394,\"start\":41355},{\"end\":41468,\"start\":41438},{\"end\":41737,\"start\":41688},{\"end\":41857,\"start\":41747},{\"end\":42357,\"start\":42182},{\"end\":42660,\"start\":42591},{\"end\":43092,\"start\":43028},{\"end\":43436,\"start\":43342},{\"end\":43706,\"start\":43683},{\"end\":43828,\"start\":43805},{\"end\":44095,\"start\":44009},{\"end\":44519,\"start\":44467},{\"end\":44707,\"start\":44654},{\"end\":44961,\"start\":44892},{\"end\":45264,\"start\":45215},{\"end\":45361,\"start\":45274},{\"end\":45720,\"start\":45643},{\"end\":46083,\"start\":46010},{\"end\":46171,\"start\":46167},{\"end\":46498,\"start\":46356},{\"end\":46754,\"start\":46701},{\"end\":47039,\"start\":46987},{\"end\":47264,\"start\":47178},{\"end\":47669,\"start\":47617},{\"end\":47918,\"start\":47807},{\"end\":48437,\"start\":48284},{\"end\":48895,\"start\":48830},{\"end\":49175,\"start\":49089},{\"end\":49664,\"start\":49577},{\"end\":49677,\"start\":49666},{\"end\":49821,\"start\":49818}]"}}}, "year": 2023, "month": 12, "day": 17}