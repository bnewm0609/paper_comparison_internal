{"id": 249901105, "updated": "2022-10-28 17:59:18.031", "metadata": {"title": "mmPhone: Acoustic Eavesdropping on Loudspeakers via mmWave-characterized Piezoelectric Effect", "authors": "[{\"first\":\"Chao\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Feng\",\"last\":\"Lin\",\"middle\":[]},{\"first\":\"Tiantian\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Ziwei\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Yijie\",\"last\":\"Shen\",\"middle\":[]},{\"first\":\"Zhongjie\",\"last\":\"Ba\",\"middle\":[]},{\"first\":\"Li\",\"last\":\"Lu\",\"middle\":[]},{\"first\":\"Wenyao\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Kui\",\"last\":\"Ren\",\"middle\":[]}]", "venue": "IEEE INFOCOM 2022 - IEEE Conference on Computer Communications", "journal": "IEEE INFOCOM 2022 - IEEE Conference on Computer Communications", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "More and more people turn to online voice communication with loudspeaker-equipped devices due to its convenience. To prevent speech leakage, soundproof rooms are often adopted. This paper presents mmPhone, a novel acoustic eavesdropping system that recovers loudspeaker speech protected by soundproof environments. The key idea is that properties of piezoelectric films in mmWave band can change with sound pressure due to the piezoelectric effect. If the property changes are acquired by an adversary (i.e., characterizing the piezoelectric effect with mmWaves), speech leakage can happen. More importantly, the piezoelectric film can work without a power supply. Base on this, we proposed a methodology using mmWaves to sense the film and decoding the speech from mmWaves, which turns the film into a passive \"microphone\". To recover intelligible speech, we further develop an enhancement scheme based on a denoising neural network, multi-channel augmentation, and speech synthesis, to compensate for the propagation and penetration loss of mmWaves. We perform extensive experiments to evaluate mmPhone and conduct digit recognition with over 93% accuracy. The results indicate mmPhone can recover high-quality and intelligible speech from a distance over 5m and is resilient to incident angles of sound waves (within 55 degrees) and different types of loudspeakers.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/infocom/WangLLLSBLXR22", "doi": "10.1109/infocom48880.2022.9796806"}}, "content": {"source": {"pdf_hash": "c3df7280386ebe2b9a5f0798019be1aa82b1e71b", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "48218ab0f365159f146dd9bc762a943f3513d7da", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c3df7280386ebe2b9a5f0798019be1aa82b1e71b.txt", "contents": "\nmmPhone: Acoustic Eavesdropping on Loudspeakers via mmWave-characterized Piezoelectric Effect\n\n\nChao Wang \nZhejiang University\nHangzhouChina\n\nFeng Lin \nZhejiang University\nHangzhouChina\n\nTiantian Liu \nZhejiang University\nHangzhouChina\n\nZiwei Liu \nYijie Shen \nZhejiang University\nHangzhouChina\n\nZhongjie Ba \nZhejiang University\nHangzhouChina\n\nLi Lu \nZhejiang University\nHangzhouChina\n\nWenyao Xu wenyaoxu@buffalo.edu \nZhejiang University\nHangzhouChina\n\nUniversity at Buffalo\nSUNY\nUSA\n\nKui Ren kuiren@zju.edu.cn \nZhejiang University\nHangzhouChina\n\nmmPhone: Acoustic Eavesdropping on Loudspeakers via mmWave-characterized Piezoelectric Effect\n10.1109/INFOCOM48880.2022.9796806Index Terms-EavesdroppingmmWave sensingloudspeakers\nMore and more people turn to online voice communication with loudspeaker-equipped devices due to its convenience. To prevent speech leakage, soundproof rooms are often adopted. This paper presents mmPhone, a novel acoustic eavesdropping system that recovers loudspeaker speech protected by soundproof environments. The key idea is that properties of piezoelectric films in mmWave band can change with sound pressure due to the piezoelectric effect. If the property changes are acquired by an adversary (i.e., characterizing the piezoelectric effect with mmWaves), speech leakage can happen. More importantly, the piezoelectric film can work without a power supply. Base on this, we proposed a methodology using mmWaves to sense the film and decoding the speech from mmWaves, which turns the film into a passive \"microphone\". To recover intelligible speech, we further develop an enhancement scheme based on a denoising neural network, multi-channel augmentation, and speech synthesis, to compensate for the propagation and penetration loss of mmWaves. We perform extensive experiments to evaluate mmPhone and conduct digit recognition with over 93% accuracy. The results indicate mmPhone can recover high-quality and intelligible speech from a distance over 5m and is resilient to incident angles of sound waves (within 55 degrees) and different types of loudspeakers.\n\nI. INTRODUCTION\n\nVoice telecommunication plays an important role in our daily life. Voice and video calls are becoming more and more popular for social and business communications [1], such as web conferences. Especially due to the COVID-19 pandemic, online voice communication has shown increasing uptake on a global scale [2]. More and more people choose to have online conversations leveraging their electronic communication equipment, such as smartphones, personal computers, and intercom screens in meeting rooms. These devices play the machine-rendered speech on loudspeakers during conversations. Because the speech can be related to personal privacy (e.g., social passwords) and business secrets (e.g., enterprise conferences), soundproof obstacles are often deployed around a room to prevent speech leakage. * Feng Lin is the corresponding author. Nonetheless, researchers reveal that such machine-rendered speech can be compromised by leveraging sound-related vibration. When a loudspeaker generates sound waves, speech leakage can happen via the physical vibration of objects, including the loudspeaker itself or nearby objects. For the former, speech information can be retrieved by the motion sensors [3]- [6] and RF signals [7]. For the latter, adversaries can use nonacoustic sensors to sense the vibration of objects induced by propagating sound waves for sound recovery, such as lidars [8], high-speed cameras [9], vibration motor [10], and hard drives [11]. However, the physical properties of objects (e.g., materials, stiffness, and structures) can affect the vibration, which further influences the eavesdropping performance.\n\nConsidering the pervasiveness of sound waves in the air, we wonder if there exists a methodology to eavesdrop on the propagating sound waves directly instead of targeting particular vibrating objects. Can we use the methodology to recover high-quality and intelligible speech even though the speech is protected by a soundproof environment? Based on our preliminary study, we find that the electromagnetic property (e.g., reflection coefficients) of piezoelectric materials in the millimeter-wave band can change with sound pressure due to the piezoelectric effect [12], [13]. If an adversary leverages a mmWave sensor to sense such changes remotely, the adversary can acquire sound-related information, which may cause threats to the speech contents. Specifically, as shown in Figure 1, the propagating sound waves hit the surface of a piezoelectric film and change the film's reflection coefficient by the applied sound pressure. An attacker uses a mmWave probe to interrogate the reflection coefficient changes of the film penetrating the soundproof wall and analyzes the reflected mmWaves to recover the speech remotely.\n\nTo realize the speech eavesdropping, there are some challenges to be addressed. First, the sound pressure level (SPL) of propagating sound waves in a normal conversation is limited (60 \u223c 70dB). Building a remote sensing methodology based on the sound-sensitive material to recover the lowenergy soundwaves is vital to the eavesdropping. Second, the mmWave signal can decay with the sensing distance, causing a decreasing signal-to-noise ratio (SNR), especially when penetrating obstacles (e.g., soundproof walls). This poses a great challenge for a remote attacker to recover high-quality speech. Third, considering the spectral complexity of human speech, higher frequency components of sound waves suffer more attenuation during the propagation [14] and are easier to be flooded by noise, which results in poor speech intelligibility. An intelligible voice recovery is required to cause practical threats to the speech contents.\n\nIn this paper, we propose mmPhone, an eavesdropping system that can recover the speech protected by a soundproof room. Our work focuses on speech threats exposed by loudspeakers. We first theoretically model the piezoelectric film in the sound fields, transforming the speech from sound fields to electromagnetic fields. Then we build a mmWave-based methodology to interrogate the film and decode the speech from reflected mmWave signals. To fight against attenuation and noise interference, we design a speech enhancement scheme containing a denoising neural network and a multichannel augmentation to improve recovered speech quality (i.e., how comfortable the speech sounds, such as clean or noisy). To increase the intelligibility (i.e., how comprehensible the speech is) of recovered speech, we further develop a training-free method based on pitch estimation and harmonic extension to recover harmonics of the human voice and reconstruct intelligible speech. Overall, we make the following contributions in this work:\n\n\u2022 We build a methodology to sense acoustic waves directly leveraging the piezoelectric effect and mmWave signals. We theoretically model the sound-mmWave transforma-tion and reveal a novel attack that can eavesdrop on the speech protected by soundproof obstacles. \u2022 We propose an eavesdropping system mmPhone based on a COTS mmWave probe. To increase speech quality, we design an enhancement scheme containing a denoising neural network and a phase-alignment-based multichannel augmentation. To improve speech intelligibility, we develop a training-free method based on speech synthesis which leverages recovered audio from the four receiving antennas for accurate speech reconstruction. \u2022 We evaluate mmPhone with extensive experiments. The results indicate that mmPhone can recover high-quality and intelligible speech remotely (5m) with digit recognition accuracy of over 93%. We quantitatively evaluate robustness of mmPhone which shows resilience to incident angles of soundwaves (< 55 \u2022 ) and different loudspeakers.\n\n\nII. BACKGROUND AND THREAT MODEL\n\n\nA. Piezoelectric Film\n\nPolyvinylidene fluoride (PVDF) [15] is a specialty plastic ubiquitous in daily life, such as folder covers and piping products. After polarization, a PVDF film can become piezoelectric without appearance changes. We use a PVDF piezoelectric film in this paper. Due to the piezoelectric effect, the film can work as a passive transducer to transform sound pressure into electromagnetic signals [16]. As shown in Figure 2(a), the film charges when a force is applied to the film surface. A changing force, such as the force induced by the changing sound pressure, can cause the film to charge and discharge alternatively. We theoretically model the piezoelectric effect when sound waves hit the film surface in Section III.\n\n\nB. mmWave Sensing\n\nThe frequency-modulated continuous-wave (FMCW) radar system transmits FMCW (also called chirp) and captures reflected signals from objects. The received signal is demodulated by a mixer, passed to a low-pass filter LP F (\u00b7), and then sampled by the analog-to-digit converter (ADC) to produce an intermediate frequency (IF) signal. For two sinusoidal inputs x 1 (transmitted signal) and x 2 (received signal) of the mixer x i = A i sin(\u03c9 i t + \u03c6 i ) (i = 1, 2), the output IF signal x o can be calculated as\nx o = LP F (x 1 \u00b7 x 2 ) = A 3 cos((\u03c9 1 \u2212 \u03c9 2 )t + \u03c6 1 \u2212 \u03c6 2 ), (1)\nwhere A 3 is the amplitude of x o , \u03c9 1 \u2212 \u03c9 2 = 2\u03c0f c , and f c is the frequency of x 0 . The reflected signal x 2 from an object can be taken as the replicate of the transmitted signal x 1 . The time delay \u03c4 of the two signals can be calculated by \u03c4 = 2d c , where d is the distance to the object and c is the speed of light. Then the initial phase of x o can be written as\n\u03c6 0 = 2\u03c0f c \u03c4 + \u03c6 1 \u2212 \u03c6 2 = 4\u03c0d \u03bb + \u03c6 1 \u2212 \u03c6 2 ,(2)\nwhere f c is the frequency of x 1 and \u03bb is the wavelength of x 1 . For a static object at distance d 0 , we denote the reflection coefficient of the object as \u0393 = |\u0393 |e j\u03c6r . Given that x 2 is the echo of x 1 reflected by the object, i.e., \u03c6 1 \u2212 \u03c6 2 = \u03c6 r , we have\n\u03c6 0 = 4\u03c0d 0 \u03bb + \u03c6 r ,(3)\nwhere 4\u03c0d0 \u03bb is a constant. According to Eq. 3, the phase of the IF signal x 0 and the phase of the reflection coefficient \u0393 has the following relationship: 1) If the \u0393 of the object is constant, i.e., \u03c6 r = \u03c6 a , then \u03c6 0 is also a constant. 2) If the \u0393 of the object varies with external stimulation like soundwaves, then \u03c6 0 can also change with the stimulation.\n\n\nC. Threat Model\n\nWe consider a scenario where a victim uses loudspeakers in a soundproof room, e.g., attending an online conference in a conference room at the company. To ensure speech confidentiality, the victim is vigilant to the in-room eavesdropping devices and thus forbids any active electronic devices into the room, such as microphones or smartphones. This can be achieved by electronic device detectors which rely on the detection of emitted electromagnetic signals or wireless signals from malicious devices. In such a scenario, the piezoelectric film, a passive element free of any electronic components like butteries or ADCs, can be disguised as the cover of a book or papers and token by an executor into the room. The executor can be a hired person by the adversary. The attacker can also be an inner adversary of the company and thus he/she can pre-install the film in the room. We have the following assumptions: 1) The victim uses a loudspeaker to emit the participants' speech in the online communication.\n\n2) The piezoelectric film is pre-placed in the room, which can be achieved by social engineering [17]. 3) The adversary knows the film's location to transmit directional mmWaves.\n\n\nIII. MODELING SOUND-MMWAVE TRANSFORMATION\n\n\nA. Sound Propagation Model\n\nSound waves propagating through the air can be formulated by a function of position and time P (x, t) which is also known as sound fields [18]. The sound pressure at position x 0 can be taken as the superposition of a series of single-frequency waves varying with time t:\nP (t) = i P i cos (\u03c9 i t + \u03c6 i ),(4)\nwhere the P i , \u03c9 i , \u03c6 i are the pressure amplitude, radian frequency and initial phase of i th wave component at position x 0 . When soundwaves hit a piezoelectric film, the induced force on the film can be calculated by F = P \u00b7 S, where S is the size of the film and P is the sound pressure. Due to the piezoelectric effect of the film, the quantity of electric charges induced by the applied force F can be calculated as Q = D 33 \u00b7 F , where D 33 is the piezoelectric constant of the piezoelectric film. Then we get the relationship between sound waves and induced charges on the film\nQ = i D 33 SP i cos (\u03c9 i t + \u03c6 i ).(5)\n\nB. mmWave Reflected from A Piezoelectric Film\n\nWhen propagating mmWaves in the air impinges upon a piezoelectric film, the mmWave can be partially reflected. The initial phase of reflected waves (i.e., the phase of reflected mmWaves on the boundary between the air and the film) is determined by electric properties of the two mediums. According to the Transmission Line model [19], the reflection of mmWaves at the boundary can be formulated by the reflection coefficient\n\u0393 = Z 2 \u2212 Z 1 Z 2 + Z 1 .(6)\nZ 1 and Z 2 are the intrinsic impedance of the air and the film,\nwhere Z i = \u03c9\u00b5i kz i , k i = \u03c9 \u221a \u00b5 i \u03b5 i (i = 1, 2)\n, \u03c9 is the radian frequency of the mmWave, \u00b5 i , \u03b5 i are the magnetic permittivity and medium permittivity. For a given incident angle \u03b8 of the mmWave, the propagation coefficients k z1 , k z2 in the direction of propagation can be calculated by\nk z1 = k 1 cos \u03b8, k z2 = k 2 2 \u2212 k 2 x , where k x = k 1 sin \u03b8.\nThen we can derive the reflection coefficient\n\u0393 = cos \u03b8 \u2212 \u03b5 r \u2212 sin 2 \u03b8 cos \u03b8 + \u03b5 r \u2212 sin 2 \u03b8 ,(7)\nWe consider vertically incident mmWaves towards the film without loss of generality, i.e., \u03b8 = 0. The relative permittivity of the film \u03b5 r = 1 \u2212 [19]. Now we can derive the relationship between the phase of \u0393 and the quantity of sound-induced charges Q:\n\u03c9 2 p \u03c9 2 , where \u03c9 p = N e 2 m\u03b50 , N = Q Sd\u03a6(\u0393 ) = \u03a6( 1 \u2212 \u221a a 1 Q \u2212 1j 1 + \u221a a 1 Q \u2212 1j ) = \u22122 arctan a 1 Q \u2212 1,(8)\nwhere a 1 = e 2 \u03c9 2 m\u03b50Sd . We further apply Taylor expansion on Eq.8 at Q = Q 0 :\n\u03a6(\u0393 ) = \u2212 1 Q 0 \u221a a 1 Q 0 \u2212 1 Q + C 0 + o(Q \u2212 Q 0 ) 2 = k 0 Q + C 0 , |Q \u2212 Q 0 | < ,(9)\nwhere k 0 and C 0 are determined by a 1 and Q 0 , Q 0 is the average quantity of induced charges by the incident sound waves. is the quantity changes determined by the changes of sound waves, which is a small value. According to Eq. 5 and Eq. 9, the phase of \u0393\n\u03c6 r = k 0 D 33 S i P i cos (\u03c9 i t + \u03c6 i ) + C 0 .(10)\n\nC. Decoding Sound Waves from Reflected mmWaves\n\nAs introduced in Section II-B, an object with varying reflection coefficient \u0393 = |\u0393 |e j\u03c6r can change the \u03c6 0 of the IF signal. According to Eq. 3 and Eq. 10, we can easily derive\n\u03c6 0 = \u03a6 1 ( i P i cos (\u03c9 i t + \u03c6 i )),(11)\nwhere \u03a6 1 (\u00b7) is a linear function. For successively reflected chirps x 1 , x 2 , ..., x n , we denote the phase of the IF signal demodulated from i th chirp as \u03c6 i 0 . Then the phases of successively demodulated chirps can be written as \u03c6 1 0 , \u03c6 2 0 , ..., \u03c6 n 0 . According to Eq. 11, the phase \u03c6 i 0 is determined by the soundwave state at a specific time. In other words, we can take each demodulation of a mmWave chirp as a sampling of the sound waves where the sampling rate f s = 1 T chirp .\n\n\nD. Verification Experiment\n\nExperimental Setting: As shown in Figure 3, we conducted experiments in an anechoic chamber. We placed a loudspeaker playing audio chirps (50 \u2212 2k Hz, 65 dBSPL) with a period of 2s towards the piezoelectric film and used a mmWave probe (AWR1843) to interrogate the film from a distance of 0.8m. The whole film was stuck on an acrylic board with glue to avoid physical vibration caused by sound waves. To avoid vibration interference from the loudspeaker, we placed the loudspeaker side by side with the probe without any physical contact between the two. Note that the loudspeaker was beyond the field-of-view (\u00b128 \u2022 horizontally) of the probe. The chirp rate of transmitted mmWave is 10.2k per second (f s = 10.2kHz). We also used a microphone to record the played audio as the reference.\n\nDecoding Audio from mmWave: For each period of demodulated mmWave signals (IF signals), we derived the phase\nspectrum \u03a6 i = {\u03c6 i 1 , \u03c6 i 2 , .\n.., \u03c6 i 512 } by a 512-point fast Fourier transform (FFT). For M successively demodulated mmWave signals, we got a set of phase spectrums {\u03a6 1 , \u03a6 2 , ..., \u03a6 M }. Then we derived the phase value across different periods {\u03c6 1 j , \u03c6 2 j , ..., \u03c6 M j } for the j th frequency point of the phase spectrum, where j = 1, 2, ..., 512. According to Eq.11, the sequence {\u03c6 1 j , \u03c6 2 j , ..., \u03c6 M j } has a linear relationship with the sound waves. So we searched for all the 512 derived sequences and chose the one that has the largest correlation value [20] with the audio chirp (recorded by the mic) as the decoded result. The spectrograms of the mic-recorded audio and mmWave-decoded audio are shown in Figure 4(a) and (b), respectively. We observe that the audio can be successfully decoded from the phase sequences which is consistent with our theoretical model. However, we also find that:\n\n\u2022 The power density of recovered audio in Figure 4(b) is weaker than the mic's in the unobstructed case. For a remote through-wall eavesdropping, the attenuation of mmWave would be larger and worsen recovered speech quality. \u2022 The weak response in the high-frequency band of mmWavedecoded audio (indicated by the red circle in Figure 4(b)) can cause loss of speech formants which play a vital role in the intelligibility of speech [21]. \n\n\nE. Observations and Potential Solution\n\nAudio Decoded from Multiple Channels: Hereafter, we denote each frequency point in the FFT result of IF signals as a channel, which can modulate the audio information.\n\nDuring the experiments, we found that there was more than one channel from which we could successfully decode the played audio. A premier observation is that these frequency points are successive. This is probably because the A4-size (21.0cm \u00d7 29.7cm) film can induce multiple frequency points in the FFT results considering that the range resolution of the mmWave probe is only 3.75cm for a 4GHz bandwidth. Figure  5 shows the decoded audio from another two channels adjacent to the one of Figure 4(b). We can observe that the audio can be decoded from multiple channels but with different SNR. Based on this observation, we proposed a phase-alignmentbased method to merge audio traces decoded from multiple channels to improve speech quality (Section IV-D).\n\nAudio Recovered from Multiple Receiving Antennas: The COTS mmWave probe we used has an antenna array with three transmitting antennas (Tx) and four receiving antennas (Rx). The four receiving antennas can act as four separate microphones with different SNR considering that they have respective mixers and analog-to-digital converters (ADCs). Thus, we can leverage the \"microphone array\" for further speech enhancement as introduced in Section IV-E.\n\nAcoustic Nonlinearity of Loudspeakers: Due to the acoustic nonlinearity of loudspeakers [22], there are chirp harmonics in both mic-recorded and mmWave-decoded audio, as dotted circles in Figure 4(a)(b) show. However, the harmonics in Figure 4(b) disappear when the chirp frequency is above 250 Hz, which cause little interference to the intelligibility of  recovered speech (only two vowels, i.e., i and y, have formants below 250 Hz that may be interfered with [23]). So we do not take further exploration about this in the following pages.\n\n\nIV. SYSTEM DESIGN\n\n\nA. System Overview\n\nThe framework of mmPhone is shown in Figure 6. The mmWave probe transmits FMCW to interrogate the piezoelectric film through the soundproof wall and demodulate reflected mmWave signals. The audio is decoded from multiple channels respectively according to the sound-mmWave transformation model (Section III). Then a preprocessing is applied to the decoded audio traces to eliminate clutters preliminarily. To recover high-quality speech, we merge the multiple audio traces by a speech enhancement scheme which consists of a denoising neural network and a multi-channel augmentation. Finally, the enhanced audio is fed into a training-free speech reconstruction module to improve the speech intelligibility. Channel Filtration: After the phase unwrapping, we get the decoded audio of each channel, i.e., the unwrapped phase sequence. However, not all channels convey the speech information as analyzed in Section III-E. To localize the channels that contain speech information, an intuitive but time-consuming way is listening to the decoded audio one by one to judge if it contains speech. Here we propose a more efficient method called channel filtration to localize the desired channels automatically. The core idea is that the human voice has a higher power density than background noise in the frequency band of 85 \u223c 255 Hz. Thus, we can use this feature of the human voice to identify if a decoded trace contains speech. Specifically, we first apply a band-pass filter with cutoff frequencies of 80 Hz and 260 Hz to all the decoded traces and then calculate power spectral density for each trace. The top k traces with the highest density values are chosen (k=3).\n\n\nC. Speech Preprocessing\n\nDC Removal and Filtering: After decoding the audio from the mmWave, we subtract the mean from the decoded audio trace to correct DC offset raised by the film (Eq. 11) and the probe. Then we design a fourth-order highpass Butterworth filter with a cut-off frequency of 80 Hz to eliminate clutters, such as human wiggles and wind blowing.\n\nNormalization: We apply an amplitude normalization to the decoded audio traces considering that the amplitude of the audio signal is within [-1,1]. The normalization can partly suppress the amplitude fluctuation due to different sensing distances and played volumes. After the normalization, we acquire multiple noisy audio traces whose quality and intelligibility need to be improved.\n\n\nD. Speech Enhancement\n\nDenoising Neural Network: The propagation and penetration loss of mmWave can result in a low SNR of reflected signals and thus cause a poor-quality speech that requires denoising. Traditional denoising methods, such as Wiener filter and spectral subtraction, will introduce broadband residual noise and musical noise, damaging speech quality. In this part, we use a deep neural network (DNN) based denoising method. One of the advantages of such methods is that non-linear structures of DNN contribute to learning the more complex mapping between noisy and clean speech. This allows the network to handle non-stationary noise in real-world scenarios. Specifically, the denoising approach leverages spectral masking [24] to map noisy speech into clean ones. The noisy speech segment is first transformed into a spectrogram and multiplied with the spectral mask to generate a new spectrogram. Then the generated spectrogram is resynthesized into a clean speech with the phase information derived from the noisy speech. The spectral mask is estimated by a DNN, as shown in Figure 7. The input is the magnitude spectrum of a speech segment after a short-time Fourier transform (STFT) with a size of 240 \u00d7 513. The first two 3 \u00d7 3 convolution layers consist of 1024 and 512 filters with a stride of 1. The eight encoder layers adopt a multi-head self-attention mechanism [25] which allows the model to jointly attend to information from different subspaces at different positions. The output layer applies a linear transformation to the incoming vector, and a following ReLU layer is used as the activation function. The denoising neural network takes the MimicLoss [24] as the loss function which achieves better enhancement using the information derived from a speech recognizer. We trained the network with public datasets [26] and deployed the model on a laptop for signal denoising. After denoising, the audio traces decoded from multiple channels are fed into a phase-alignment module to further improve the speech quality.\n\nPhase-alignment-based Enhancement: As demonstrated in Section III-E, we can decode the played audio from multiple channels respectively. The decoded audio traces contain the same speech contents but have different SNR. A simple method to merge the multiple traces for enhancement is aligning the signals in the time domain and adding up their amplitudes directly. However, this method has poor performance when the phases of signals are not aligned. Thus, we propose a phase-alignment-based enhancement as shown in Algorithm 1. We first choose the one with the highest SNR from multiple decoded traces of each Rx (note that the probe has four Rx) as the baseline. Then we apply FFT to all the traces with a window size of 512 to get the spectrums. We set the phases of the other traces to the baseline's and add up all the spectrums (complex values). Then we perform the inverse FFT (iFFT) to get time-domain signals. The time-domain segments are overlap-added when the window slides with a step of 128 until all the segments are phase-aligned.\n\n\nE. Speech Reconstruction\n\nAs aforementioned in Section III-D, the decoded audio traces suffer weak response in the high-frequency band due to the attenuation of mmWave, which damages speech intelligibility. This can be mitigated by speech synthesis to recover the harmonic bandwidth from the distorted audio traces. Trainingbased methods [27], [28] require a large amount of training data to achieve a satisfying performance which costs a lot. Based on this consideration, we turn to a training-free speech reconstruction scheme to improve the speech intelligibility.\n\nPitch Estimation: This step aims to estimate the fundamental frequency (i.e., the pitch, which has the strongest power in the spectrum) of the human voice. This is the basic step for speech reconstruction. As analyzed in Section III-E, the four receiving antennas can act as a \"microphone\" array. However, different SNR of the four antennas can cause varying estimation errors. To improve the estimation accuracy, we first estimate the pitch f i 0 for the audio trace of Antenna #i, where i = 1, 2, 3, 4. Then a calibrated f 0 is calculated based on the four estimated pitches. Specifically, we first segment the audio of each antenna into 50-ms segments considering the short-time stability of the human voice and then apply the f 0 estimation on the segments. We use a band-pass filter to get the fundamental frequency of each segment coarsely. Considering \nf 0 = 4 i=1 (snr i * f i 0 )/ 4 i=1 snr i . Harmonic Extension:\nThe formants, which refer to local maximums in the spectral envelope of human voice [23], play a vital role in speech intelligibility. We adopt a spectral envelope estimation algorithm [29] which applies harmonic extension to recover the distorted spectral envelope. Instead of feeding the estimated pitch of each audio trace respectively, we use the calibrated f 0 for better spectral envelope estimation. After the harmonic extension, the formants in the spectral envelope are recovered, which helps improve speech intelligibility.\n\nSynthesis: After harmonic extension, we use D4C algorithm [30] to recover aperiodic components of the speech and combine it with the calibrated pitch f 0 and extended harmonics for intelligible speech synthesis. The synthesis is achieved by the convolution of minimum phase response and excitation signals. The synthesized speech has a bandwidth of up to 2.3 kHz, intelligible for human hearing [31]. After speech synthesis for all the antennas, we apply the phase-alignment method in Section IV-D to the four reconstructed audio for further enhancement. Finally, we get an enhanced speech with high quality and intelligibility. The spectrograms of the played audio, decoded (unprocessed) audio from a single channel, and processed audio by the scheme are shown in Figure 8(a)(b)(c).\n\n\nV. EVALUATION\n\n\nA. System Setup\n\nThe system setup is shown in Figure 9. The COTS mmWave probe AWR1843Boost has a transmitting power of 12dBm with a portable size of 6.5cm \u00d7 8.5cm \u00d7 2.0cm to interrogate the piezoelectric film. The transmitted chirp has a frequency range of 77-81 GHz. We set the chirp rate to 10,200 chirps/sec. The IF signal is collected by a DCA1000EVM and sent to a laptop (Thinkpad T490) for processing. The film has a size of 21cm \u00d7 29.7cm \u00d7 28\u00b5m and a piezo constant d 33 of 3.3 \u00d7 10 \u221211 C/N. It is stuck to an acrylic board with glue to avoid physical vibration. The denoising network is trained on a Linux server with a GeForce RTX 2060 GPU. We adopted Adam as the optimizer (Lr=0.001,epoch=500).\n\n\nB. Datasets and Data Collection\n\nWe used three public datasets that are widely adopted for speech testing to evaluate our system, i.e., Harvard Speech Corpus (HSC) [32], AudioMNIST [33], and Open Speech Repository (OSR) [34]. The HSC consists of 720 sentences (known as Harvard Sentences) designed to feature phonemes at the same frequency they appear in spoken English. The AudioMNIST contains 30,000 samples of spoken digits from 60 speakers. The OSR includes Harvard Sentences from different speakers, from which we chose 100 samples. We evaluated mmPhone robustness in V-E, V-F, and V-H with two speakers' samples in AudioMNIST. All experiments were ensured to follow the institutional review board (IRB) protocol.\n\nWe asked a volunteer to play audio samples of the three datasets via a loudspeaker (Hp) in a soundproof room ( Figure  11). The SPL (measured by a sound level meter placed nearby the piezoelectric film) was around 67dB within the range of normal conversations [35]. When the loudspeaker played audio, the volunteer and two other volunteers typed randomly on their laptops. We deployed the mmWave probe outside the room with a sensing distance of 5m. The distance between the loudspeaker and piezoelectric film is 2m. For comparison, we also deployed two microphones to record the played audio, one (Mic1) inside and the other (Mic2) outside the room.\n\nInterrogated Source Validation: We performed a controlled experiment to ensure the recovered speech was from the PVDF film rather than the vibrating loudspeaker. We respectively placed (i.e., w/ PVDF) and removed (i.e., w/o PVDF) the film for speech recovery with exactly the same processing steps (e.g., the same decoding channel). The results are shown in Figure 8. Comparing (c) and (f), we observe that mmPhone failed to recover the played audio when we removed the film, indicating the recovered speech by mmPhone was from the PVDF film rather than the vibrating loudspeaker. Fig. 9. System setup (mmPhone). Fig. 10. Tested loudspeakers.\n\n\nC. Metrics\n\nPeak-signal-to-noise ratio (PSNR): The PSNR is a commonly used metric to quantify speech quality [7], [9]. The empirical boundary of PSNR for human-audible speech is 0dB [7]. A higher PSNR indicates a better speech quality.\n\nShort-Time Objective Intelligibility (STOI): The STOI has a monotonic relationship with the subjective speechintelligibility [36]. The STOI varies within [0,1], of which a higher value indicates better speech intelligibility.\n\n\nD. Overall Performance\n\nIn this part, we evaluate the system performance by calculating the PSNR and STOI of the speech recovered by mmPhone. Given that the digits (i.e., 0 \u223c 9) are often related to secret information, such as passwords and security numbers, we also apply automatic speech recognition (ASR) and manual speech recognition (MSR) to the recovered digit speech.\n\n1) Sound Recovery: The results of PSNR and STOI are shown in Figure 12 and Figure 13, respectively. From Figure  12, we can observe that mmPhone outperforms the out-room microphone (Mic2, yellow bars) with high PSNR above 14dB on the three datasets. We find that the PSNR of recovered speech by mmPhone can even be higher than the in-room microphone's (blue bars) on the OSR datasets. The reasons are two folds. First, the DNN-based denoising and phasealignment-based enhancement can significantly improve the SNR of recovered speech. Second, compared with the single in-room microphone, mmPhone also enhances the recovered speech leveraging the four receiving antennas, each of which acts as a separate microphone. Thus, the \"microphone array\" of mmPhone can outperform the single acoustic microphone by leveraging the proposed scheme in Section IV. Fig. 11. Experimental scenario of a conference room with a soundproof glass wall (two layers of glass and 1cm-thick for each).  Figure 13 indicates that the STOI of speech recovered by mmPhone is lower than the in-room acoustic microphone's (Mic1) but far larger than the out-room microphone's (Mic2). The lower STOI of mmPhone compared with the in-room microphone results from the limited sampling rate of mm-Phone, which cause loss of high frequency (above 5.1kHz according to Nyquist theorem) of human voice. Figure 14 shows the performance gain of system modules. The Enhancement (Section IV-D) and Reconstruction (Section IV-E) modules aim to improve speech quality and intelligibility, respectively. For each module, we calculated the metrics of the input (i.e., Unprocessed) and output (i.e., Processed) audio for comparison. We find that the PSNR increases by 8.2dB after the Enhancement. The STOI increases by 53.6% after the Reconstruction. The results validate the effectiveness of the proposed scheme in Section IV.\n\n2) Digit Recognition: We define a true positive as a correctly predicted digit and a false negative as a digit wrongly classified into other classes. For the ASR, we trained a digit recognition model based on ResNet-50. Specifically, we got the spectrograms of the recovered speech from the AudioM-NIST (30,000 traces in total) corresponding to each digit by applying the STFT. We randomly separated the spectrograms (3 \u00d7 224 \u00d7 224) into 80% training data and 20% testing data for model training and testing, respectively. For the MSR, we randomly chose 10 recovered audio traces from each digit class and invited 15 volunteers (Chinese) to listen to the 100 audio traces. We asked the volunteers to pick up the most likely one from the ten digits (0 \u223c 9). The recognition results are shown in Figure 15. The accuracy, precision, and recall of ASR are 97.0%, 97.3%, and 97.1%, and MSR achieves 93.5%, 94.1%, and 92.9%, respectively. We find that the digits \"four\" and \"five\" are more likely to be misclassified by the volunteers due to distorted phonemes. Besides, the diverse accents and tones can also pose challenges for the MSR. Overall, mmPhone can achieve over 93% accuracy for both ASR and MSR.\n\n\nE. Sensing Distance\n\nConsidering that mmWave signals can decay with distance, we evaluated mmPhone with different sensing (probe-film) distances from 2m to 7m in the through-wall scenario ( Figure  11). Other settings are the same as in V-B. As shown in Figure 16, the PSNR of raw decoded speech (Unprocessed, blue dashed line) is steady above 10dB when the distance is within 5m but reduces to 3.9dB when the distance is 7m. This results from the declining power density of mmWave when the distance increases. With our proposed enhancement scheme, the PSNR has a gain of 9 \u223c 11dB. We also observe that the STOI reduces to 0.53 when the distance is 6m. The possible reason is that mmWaves suffer larger attenuation as the distance increases, resulting in a lower SNR at the receiver.\n\nWith the enhancement scheme, the STOI of reconstructed audio increases to 0.61 when the distance is less than 6m.\n\n\nF. Incident Angle of Propagating Sound Waves\n\nThe pressure amplitude P i (in Eq. 4) applied to the film can be different with respect to different incident angles of sound saves, which can influence the reflection coefficient \u0393 of the film according to Eq. 10. Here we define the incident angle of sound waves as the angle between the wavepropagating direction and the normal of the film surface. We changed the incident angle of sound waves and kept other settings the same as in V-B. We deployed the probe outside the soundproof room for through-wall eavesdropping. The results are shown in Figure 17. We can observe that mmPhone is resilient to the incident angles of sound waves within 55 \u2022 , but the performance declines significantly when the incident angle is above 65 \u2022 . The recovered speech is still audible (5.8dB) but with poor intelligibility. We also find that the gain of intelligibility (i.e., the difference between orange lines) goes down as the angle increases. Considering that the spectral envelope (Section IV-E) plays an important role in the speech intelligibility, the possible reason is that the low PSNR at large incident angles makes high-frequency components of decoded speech ambiguous in the spectrum. Thus, the estimated spectral envelope can be partly distorted, resulting in the limited performance gain.\n\n\nG. Incident Angle of the mmWave\n\nWe quantitatively study the impact of the incident angle of mmWave in the soundproof scene ( Figure 11). We define the incident angle of mmWave as the angle between the mmWavepropagating direction (main lobe) and the normal of the film surface. Other settings are the same as in V-B. The results are shown in Figure 18. We observe that the PSNR varies from 21.5dB to 23.1dB and the STOI varies from 0.61 to 0.63. Both are steady with little fluctuation under different incident angles of mmWave (15 \u2022 /30 \u2022 /45 \u2022 ). The results indicate that mmPhone has a certain tolerance for different incident angles of mmWave to recover high-quality and intelligible speech.  \n\n\nH. Different Loudspeakers\n\nTo investigate the impact of loudspeaker structures, we chose five different types of commodity loudspeakers shown in Figure 10. We played speech samples in the AudioMNIST dataset with the same experimental setting as in Section V-B. The PSNR and STOI of recovered speech are shown in Figure  19. We find that the PSNR of recovered speech (blue bars) varies from 19.1dB to 23.5dB with a fluctuation of 4.4dB, and the STOI (red bars) varies from 0.59 to 0.70. We observe that Hivi M200 has higher STOI than other loudspeakers because the speaker (costs more than $430) has a more flat frequency-response curve than others [37]. The results indicate that mmPhone can recover intelligible speech with a slight intelligibility fluctuation among different loudspeakers.\n\n\nVI. RELATED WORK\n\n\nA. Vibrometry-based Speech Eavesdropping\n\nNon-acoustic sensors, such as motion sensors [3]- [6], [38], wireless signals [7], [39], [40], lidars [8], [41], high-speed cameras [9], vibration motors [10], and hard drives [11] can measure the physical vibration to recover sound information. When targeting surrounding objects, the sound-induced vibration on objects in normal conversations (60-70dB) can be extremely delicate, requiring \u00b5m-level resolution sensors for vibration measurement, such as a laser. However, the rigidness and transparency of vibrating objects can significantly impact the performance of laser-based methods [8]. Soundproof materials, such as wool board and glossy plywood, can degrade the performance but cannot prevent mmPhone due to mmWave's penetrating property. Wei et al. [7] proposed a radio-based vibrometry leveraging the multipath effect in the WiFi band to measure the loudspeaker vibration for sound retrieval. Our work relies on different principles and eavesdrops on the propagating sound waves rather than the vibration of the loudspeaker. Wei's work leveraged wireless traffic in 2.4GHz band, which is prone to be detected and raise the awareness of the user. Our used attack device transmits fast chirps and operate in the band of 77-81GHz. To detect malicious signals, the user requires a strict synchronization with the adversarial device and pre-knowledge about the operating frequency of the malicious device, which is unlikely to happen in real world.\n\n\nB. mmWave-based Speech Recovery\n\nmmWave is raising more and more attention in both security areas and noise-resistent speech applications [42]- [48]. Xu et Fig. 18. Incident angle of mmWave. Fig. 19. Impact of loudspeaker type.\n\nal. [45] proposed a noise-resistent speech recovery scheme based on mmWave sensing. Liu et al. [46] proposed a multimodal speech recognition system with a high recognition accuracy and robustness in real world by fusing mmWave and audio signals. Li et al. [47] developed a noise-resilient user authentication system based on interrogating users' vocal vibration. Hu et al. [48] proposed a mmWave-based speech eavesdropping scheme which could reconstruct the original audio. Our work focus on a new acoustic side-channel, leveraging the mmWave-characterized piezoelectric effect for eavesdropping.\n\n\nVII. COUNTERMEASURES\n\nThe defense methods can be two folds. First, blocking or interfering with the mmWave can defend against mmPhone, such as deploying electromagnetic shielding materials around the room and jamming with mmWave signals. However, the jamming method requires the user to know the operating frequency of malicious devices. Second, considering that mm-Phone eavesdrops on the propagating sound waves for speech recovery, it is an efficient countermeasure to prevent the sound waves from propagating through the air, such as wearing a headset or earphone when people are involved in an online conversation rather than playing the audio on loudspeakers.\n\n\nVIII. CONCLUSION\n\nThis paper presents mmPhone, a novel eavesdropping system recovering speech emitted by loudspeakers in a soundproof room. We built a methodology to decode the speech via reflected mmWaves from a piezoelectric film and proposed an enhancement scheme to improve the speech quality and intelligibility. The results of extensive experiments indicate that mmPhone can recover high-quality and intelligible speech with digit recognition above 93%.\n\nFig. 1 .\n1mmPhone can recover speech emitted by loudspeakers in a soundproof room via interrogating an in-room piezoelectric film with mmWaves.\n\nFig. 2 .\n2Piezoelectric effect of the piezo (piezoelectric) film. (a) The piezo film charges when a force is applied to its surface. (b) The changing sound pressure of sound waves can cause the film charging/discharging, influencing the phase of reflected mmWave signals.\n\nFig. 3 .\n3Verification experiment setting in an anechoic chamber. The A4-size piezoelectric film is stuck to an acrylic board with glue to avoid vibration.\n\nFig. 4 .\n4We compare (a) the audio recorded by a microphone and (b) the audio decoded by the proposed sound-mmWave transformation model.\n\nFig. 5 .\n5(a) and (b) show decoded results of two channels adjacent to the one inFigure 4(b), which can be leveraged for enhancement (detailed in IV-D).\n\nFig. 6 .\n6System overview of the proposed system mmPhone.\n\n\nB. Decoding Audio from mmWaveDemodulation: The mmWave probe transmits mmWave signals periodically and demodulates the reflected mmWaves to generate IF signals. We apply 512-point FFT to each period of the IF signal. For M successive periods, we get an FFT matrix S = [S i j ], i = 1, ..., M, j = 1, ..., 512 and the phase matrix \u03a6 = {\u03c6 i j }, i = 1, ..., M, j = 1, ..., 512 from S. We further extract the phase sequence {\u03c6 1 j , \u03c6 2 j , ..., \u03c6 M j } for each of the 512 channels, where j = 1, ..., 512. Then we perform phase unwrapping to all the derived phase sequences to eliminate the impact of integer ambiguity.\n\nFig. 7 .\n7The structure of the denoising neural network.\n\nAlgorithm 1 : 7 S\n17Speech Enhancement for A Single Rx Input: Preprocessed audio {s i }, i = 1, ..., I, where I is the number of channels. Output: Enhanced audio s en 1 Initialize N = 512, hop = N 4 , win = hanning(N ); 2{s i } \u2190 DN N ({s i }), slen = length(s i ) 3 for i \u2190 1 : I do 4 s en \u2190 zeros(slen), s ref \u2190 arg max s SN R(s) 5 for k \u2190 0 : f loor( slen\u2212N hop ) do 6 S i \u2190 F F T N (s i (1+k * hop : N +k * hop) * win) \u2190 i |Si| |S ref | * S ref 8 s en (1 + k * hop : N + k * hop)+ = iF F T (S)9 return s en that the fundamental frequency of the human voice is within 85-255 Hz, we set the cut-off frequency of the band-pass filter to 80 Hz and 260 Hz. After the filtering, we apply FFT to the segments and take the frequency with the highest magnitude as the estimated f 0 . We denote SN R i as the SNR of the segment from Antenna #i, then the calibrated f 0 is calculated by\n\nFig. 8 .\n8(a), (b), and (c) show the played audio, raw decoded audio, and processed audio by mmPhone when we deployed the PVDF film. (d), (e), and (f) show the results when we removed the film.\n\nFig. 12 .\n12Overall performance(PSNR).Fig. 13. Overall performance(STOI).\n\nFig. 14 .\n14Module performance.Fig. 15. Digit recognition.\n\nFig. 16 .\n16Impact of distance.\n\nFig. 17 .\n17Soundwave incident angle.\n\nVideo calls fast becoming as popular as voice calls, reaching almost universal adoption for social use, according to vonage study. Businesswire, 17Businesswire, \"Video calls fast becoming as popular as voice calls, reaching almost universal adoption for social use, according to vonage study,\" https://www.businesswire.com/news/home/20190117005173/en, 2019, [Online; accessed 17-July-2021].\n\nVoice and video calls more than trapled during covid-19 pandemic. Parks Associates, 17Parks Associates, \"Voice and video calls more than trapled dur- ing covid-19 pandemic,\" https://www.parksassociates.com/blog/article/ pr-08262020, 2020, [Online; accessed 17-July-2021].\n\nGyrophone: Recognizing speech from gyroscope signals. Y Michalevsky, D Boneh, G Nakibly, 23rd {USENIX} Security Symposium. {USENIX} Security 14Y. Michalevsky, D. Boneh, and G. Nakibly, \"Gyrophone: Recognizing speech from gyroscope signals,\" in 23rd {USENIX} Security Symposium ({USENIX} Security 14), 2014, pp. 1053-1067.\n\nLearningbased practical smartphone eavesdropping with built-in accelerometer. Z Ba, T Zheng, X Zhang, Z Qin, B Li, X Liu, K Ren, Proceedings of the Network and Distributed Systems Security (NDSS) Symposium, 2020. the Network and Distributed Systems Security (NDSS) Symposium, 2020Z. Ba, T. Zheng, X. Zhang, Z. Qin, B. Li, X. Liu, and K. Ren, \"Learning- based practical smartphone eavesdropping with built-in accelerometer,\" in Proceedings of the Network and Distributed Systems Security (NDSS) Symposium, 2020, pp. 23-26.\n\nSpeechless: Analyzing the threat to speech privacy from smartphone motion sensors. S A Anand, N Saxena, 2018 IEEE Symposium on Security and Privacy (SP). IEEES. A. Anand and N. Saxena, \"Speechless: Analyzing the threat to speech privacy from smartphone motion sensors,\" in 2018 IEEE Symposium on Security and Privacy (SP). IEEE, 2018, pp. 1000-1017.\n\nSpearphone: a lightweight speech privacy exploit via accelerometer-sensed reverberations from smartphone loudspeakers. S A Anand, C Wang, J Liu, N Saxena, Y Chen, Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks. the 14th ACM Conference on Security and Privacy in Wireless and Mobile NetworksS. A. Anand, C. Wang, J. Liu, N. Saxena, and Y. Chen, \"Spearphone: a lightweight speech privacy exploit via accelerometer-sensed reverbera- tions from smartphone loudspeakers,\" in Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks, 2021, pp. 288-299.\n\nAcoustic eavesdropping through wireless vibrometry. T Wei, S Wang, A Zhou, X Zhang, Proceedings of the 21st Annual International Conference on Mobile Computing and Networking. the 21st Annual International Conference on Mobile Computing and NetworkingT. Wei, S. Wang, A. Zhou, and X. Zhang, \"Acoustic eavesdropping through wireless vibrometry,\" in Proceedings of the 21st Annual Inter- national Conference on Mobile Computing and Networking, 2015, pp. 130-141.\n\nSpying with your robot vacuum cleaner: eavesdropping via lidar sensors. S Sami, Y Dai, S R X Tan, N Roy, J Han, Proceedings of the 18th Conference on Embedded Networked Sensor Systems. the 18th Conference on Embedded Networked Sensor SystemsS. Sami, Y. Dai, S. R. X. Tan, N. Roy, and J. Han, \"Spying with your robot vacuum cleaner: eavesdropping via lidar sensors,\" in Proceedings of the 18th Conference on Embedded Networked Sensor Systems, 2020, pp. 354-367.\n\nThe visual microphone: Passive recovery of sound from video. A Davis, M Rubinstein, N Wadhwa, G J Mysore, F Durand, W T Freeman, A. Davis, M. Rubinstein, N. Wadhwa, G. J. Mysore, F. Durand, and W. T. Freeman, \"The visual microphone: Passive recovery of sound from video,\" 2014.\n\nListening through a vibration motor. N Roy, R Roy Choudhury, Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services. the 14th Annual International Conference on Mobile Systems, Applications, and ServicesN. Roy and R. Roy Choudhury, \"Listening through a vibration motor,\" in Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services, 2016, pp. 57-69.\n\nHard drive of hearing: Disks that eavesdrop with a synthesized microphone. A Kwong, W Xu, K Fu, 2019 IEEE Symposium on Security and Privacy (SP). A. Kwong, W. Xu, and K. Fu, \"Hard drive of hearing: Disks that eavesdrop with a synthesized microphone,\" in 2019 IEEE Symposium on Security and Privacy (SP), 2019, pp. 905-919.\n\nDielectric tunability of ferroelectric barium titanate at millimeter-wave frequencies. C Cochard, T Spielmann, T Granzow, Physical Review B. 10018184104C. Cochard, T. Spielmann, and T. Granzow, \"Dielectric tunability of ferroelectric barium titanate at millimeter-wave frequencies,\" Physical Review B, vol. 100, no. 18, p. 184104, 2019.\n\nMicrowave and mm-wave magnetoelectric interactions in ferrite-ferroelectric bilayers. G Srinivasan, A Tatarenko, The European Physical Journal B. 713G. Srinivasan, A. Tatarenko, and etc., \"Microwave and mm-wave mag- netoelectric interactions in ferrite-ferroelectric bilayers,\" The European Physical Journal B, vol. 71, no. 3, pp. 371-375, 2009.\n\nP M Morse, K U Ingard, Theoretical acoustics. Princeton university pressP. M. Morse and K. U. Ingard, Theoretical acoustics. Princeton university press, 1986.\n\nPoly (vinylidene fluoride)(pvdf) and its copolymers. Q Zhang, V Bharti, G Kavarnos, Encyclopedia of Smart Materials. Q. Zhang, V. Bharti, and G. Kavarnos, \"Poly (vinylidene fluoride)(pvdf) and its copolymers,\" Encyclopedia of Smart Materials, 2002.\n\nMolecular modeling of the piezoelectric effect in the ferroelectric polymer poly (vinylidene fluoride)(pvdf). V S Bystrov, Journal of molecular modeling. 199V. S. Bystrov and etc., \"Molecular modeling of the piezoelectric effect in the ferroelectric polymer poly (vinylidene fluoride)(pvdf),\" Journal of molecular modeling, vol. 19, no. 9, pp. 3591-3602, 2013.\n\nSocial engineering: The art of human hacking. C Hadnagy, John Wiley & SonsC. Hadnagy, Social engineering: The art of human hacking. John Wiley & Sons, 2010.\n\nAnalytic methods of sound field synthesis. J Ahrens, Springer Science & Business MediaJ. Ahrens, Analytic methods of sound field synthesis. Springer Science & Business Media, 2012.\n\nD K Cheng, Field and wave electromagnetics. Pearson Education IndiaD. K. Cheng et al., Field and wave electromagnetics. Pearson Education India, 1989.\n\nPearson correlation coefficient,\" in Noise reduction in speech processing. J Benesty, J Chen, SpringerJ. Benesty, J. Chen, and etc., \"Pearson correlation coefficient,\" in Noise reduction in speech processing. Springer, 2009, pp. 1-4.\n\nSpeaker Perception and Recognition. An Integrative Framework for Computational Speech Processing. O Lapteva, O. Lapteva, Speaker Perception and Recognition. An Integrative Frame- work for Computational Speech Processing, 2011.\n\nLoudspeaker nonlinearities -causes, parameters, symptoms. W Klippel, Journal of The Audio Engineering Society. W. Klippel, \"Loudspeaker nonlinearities -causes, parameters, symp- toms,\" Journal of The Audio Engineering Society, october 2005.\n\nFormant. Online; accessed 14\"Formant,\" https://en.wikipedia.org/w/index.php?title=Formant&oldid= 1031036735, 2021, [Online; accessed 14-July-2021].\n\nSpectral feature mapping with mimic loss for robust speech recognition. D Bagchi, P Plantinga, A Stiff, E Fosler-Lussier, IEEE ICASSP. IEEE. D. Bagchi, P. Plantinga, A. Stiff, and E. Fosler-Lussier, \"Spectral feature mapping with mimic loss for robust speech recognition,\" in 2018 IEEE ICASSP. IEEE, 2018, pp. 5609-5613.\n\nAttention is all you need. A Vaswani, N Shazeer, Advances in neural information processing systems. A. Vaswani, N. Shazeer, and etc., \"Attention is all you need,\" in Advances in neural information processing systems, 2017, pp. 5998- 6008.\n\nThe voice bank corpus: Design, collection and data analysis of a large regional accent speech database. C Veaux, J Yamagishi, S King, C. Veaux, J. Yamagishi, and S. King, \"The voice bank corpus: Design, collection and data analysis of a large regional accent speech database,\" 2013, pp. 1-4.\n\nEfficient super-wide bandwidth extension using linear prediction based analysis-synthesis. P Bachhav, M Todisco, N Evans, 2018 IEEE International Conference on Acoustics, Speech and Signal Processing. P. Bachhav, M. Todisco, and N. Evans, \"Efficient super-wide band- width extension using linear prediction based analysis-synthesis,\" in 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018, pp. 5429-5433.\n\nExploiting explicit memory inclusion for artificial bandwidth extension. P Bachhav, M Todisco, N Evans, 2018 IEEE International Conference on Acoustics, Speech and Signal Processing. ICASSPP. Bachhav, M. Todisco, and N. Evans, \"Exploiting explicit memory inclusion for artificial bandwidth extension,\" in 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).\n\n. IEEE. IEEE, 2018, pp. 5459-5463.\n\nCheaptrick, a spectral envelope estimator for high-quality speech synthesis. M Morise, Speech Communication. 67M. Morise, \"Cheaptrick, a spectral envelope estimator for high-quality speech synthesis,\" Speech Communication, vol. 67, pp. 1-7, 2015.\n\nD4c, a band-aperiodicity estimator for high-quality speech synthesis. M Morise, Speech Communication. 84M. Morise, \"D4c, a band-aperiodicity estimator for high-quality speech synthesis,\" Speech Communication, vol. 84, pp. 57-65, 2016.\n\nSound sampling. P Pearson, P. Pearson, \"Sound sampling,\" 1993.\n\nHarvard speech corpus-audio recording 2019. P Demonte, University of Salford CollectionP. Demonte, \"Harvard speech corpus-audio recording 2019,\" University of Salford Collection, 2019.\n\nInterpreting and explaining deep neural networks for classification of audio signals. S Becker, M Ackermann, S Lapuschkin, K.-R M\u00fcller, W Samek, arXiv:1807.03418arXiv preprintS. Becker, M. Ackermann, S. Lapuschkin, K.-R. M\u00fcller, and W. Samek, \"Interpreting and explaining deep neural networks for classification of audio signals,\" arXiv preprint arXiv:1807.03418, 2018.\n\nThe open speech repository. V Troubleshooter, V. Troubleshooter, \"The open speech repository,\" 2010.\n\nAccelword: Energy efficient hotword detection through accelerometer. L Zhang, P H Pathak, M Wu, Y Zhao, P Mohapatra, Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services. the 13th Annual International Conference on Mobile Systems, Applications, and ServicesL. Zhang, P. H. Pathak, M. Wu, Y. Zhao, and P. Mohapatra, \"Accelword: Energy efficient hotword detection through accelerometer,\" in Proceed- ings of the 13th Annual International Conference on Mobile Systems, Applications, and Services, 2015, pp. 301-315.\n\nAn algorithm for intelligibility prediction of time-frequency weighted noisy speech. C Taal, R Hendriks, IEEE Transactions on Audio, Speech, and Language Processing. 197C. Taal, R. Hendriks, and etc., \"An algorithm for intelligibility prediction of time-frequency weighted noisy speech,\" IEEE Transactions on Audio, Speech, and Language Processing, vol. 19, no. 7, pp. 2125-2136, 2011.\n\nHivi m200mkiii. Swans, Accessed 10-Swans, \"Hivi m200mkiii,\" [Accessed 10-July-2021]. [Online]. Available: https://swanspeakers.com/product/m200mkiii/\n\nPitchln: eavesdropping via intelligible speech reconstruction using non-acoustic sensor fusion. J Han, A J Chung, P Tague, Proceedings of the 16th ACM/IEEE International Conference on Information Processing in Sensor Networks. the 16th ACM/IEEE International Conference on Information Processing in Sensor NetworksJ. Han, A. J. Chung, and P. Tague, \"Pitchln: eavesdropping via intelligi- ble speech reconstruction using non-acoustic sensor fusion,\" in Proceed- ings of the 16th ACM/IEEE International Conference on Information Processing in Sensor Networks, 2017, pp. 181-192.\n\nUwhear: through-wall extraction and separation of audio vibrations using wireless signals. Z Wang, Z Chen, A D Singh, L Garcia, J Luo, M B Srivastava, in SenSys'20, 2020Z. Wang, Z. Chen, A. D. Singh, L. Garcia, J. Luo, and M. B. Srivastava, \"Uwhear: through-wall extraction and separation of audio vibrations using wireless signals,\" in SenSys'20, 2020, pp. 1-14.\n\nTechnique and device for through-the-wall audio surveillance. W Mcgrath, App. 11/095122US PatentW. McGrath, \"Technique and device for through-the-wall audio surveil- lance,\" Oct. 6 2005, US Patent App. 11/095,122.\n\nLaser microphone. R P Muscatell, The Journal of the Acoustical Society of America. 764R. P. Muscatell, \"Laser microphone,\" The Journal of the Acoustical Society of America, vol. 76, no. 4, pp. 1284-1284, 1984.\n\nCardiac scan: A non-contact and continuous heart-based user authentication system. F Lin, C Song, Y Zhuang, W Xu, C Li, K Ren, Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking. the 23rd Annual International Conference on Mobile Computing and NetworkingF. Lin, C. Song, Y. Zhuang, W. Xu, C. Li, and K. Ren, \"Cardiac scan: A non-contact and continuous heart-based user authentication system,\" in Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking, 2017, pp. 315-328.\n\nWavespy: Remote and through-wall screen attack via mmwave sensing. Z Li, F Ma, A S Rathore, Z Yang, B Chen, L Su, W Xu, 2020 IEEE Symposium on Security and Privacy (SP). Z. Li, F. Ma, A. S. Rathore, Z. Yang, B. Chen, L. Su, and W. Xu, \"Wavespy: Remote and through-wall screen attack via mmwave sens- ing,\" in 2020 IEEE Symposium on Security and Privacy (SP), 2020, pp. 217-232.\n\nWho is in control? practical physical layer attack and defense for mmwave-based sensing in autonomous vehicles. Z Sun, S Balakrishnan, L Su, A Bhuyan, P Wang, C Qiao, IEEE Transactions on Information Forensics and Security. 16Z. Sun, S. Balakrishnan, L. Su, A. Bhuyan, P. Wang, and C. Qiao, \"Who is in control? practical physical layer attack and defense for mmwave-based sensing in autonomous vehicles,\" IEEE Transactions on Information Forensics and Security, vol. 16, pp. 3199-3214, 2021.\n\nWaveear: Exploring a mmwave-based noise-resistant speech sensing for voice-user interface. C Xu, Z Li, H Zhang, A S Rathore, H Li, C Song, K Wang, W Xu, Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services. the 17th Annual International Conference on Mobile Systems, Applications, and ServicesC. Xu, Z. Li, H. Zhang, A. S. Rathore, H. Li, C. Song, K. Wang, and W. Xu, \"Waveear: Exploring a mmwave-based noise-resistant speech sensing for voice-user interface,\" in Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services, 2019, pp. 14-26.\n\nWavoice: A noise-resistant multi-modal speech recognition system fusing mmwave and audio signals. T Liu, M Gao, F Lin, C Wang, Z Ba, J Han, W Xu, K Ren, Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems. the 19th ACM Conference on Embedded Networked Sensor SystemsT. Liu, M. Gao, F. Lin, C. Wang, Z. Ba, J. Han, W. Xu, and K. Ren, \"Wavoice: A noise-resistant multi-modal speech recognition system fusing mmwave and audio signals,\" in Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems, 2021, pp. 97-110.\n\nVocalprint: exploring a resilient and secure voice authentication via mmwave biometric interrogation. H Li, C Xu, A S Rathore, Z Li, H Zhang, C Song, K Wang, L Su, F Lin, K Ren, Proceedings of the 18th Conference on Embedded Networked Sensor Systems. the 18th Conference on Embedded Networked Sensor SystemsH. Li, C. Xu, A. S. Rathore, Z. Li, H. Zhang, C. Song, K. Wang, L. Su, F. Lin, K. Ren et al., \"Vocalprint: exploring a resilient and secure voice authentication via mmwave biometric interrogation,\" in Proceedings of the 18th Conference on Embedded Networked Sensor Systems, 2020, pp. 312-325.\n\nMilliear: Millimeter-wave acoustic eavesdropping with unconstrained vocabulary. P Hu, Y Ma, S S Panneer, P H Pathak, X Cheng, IEEE INFOCOM 2022 -IEEE Conference on Computer Communications. 52022P. Hu, Y. Ma, S. S. Panneer, P. H. Pathak, and X. Cheng, \"Milliear: Millimeter-wave acoustic eavesdropping with unconstrained vocabu- lary,\" in IEEE INFOCOM 2022 -IEEE Conference on Computer Communications, 5 2022.\n", "annotations": {"author": "[{\"end\":142,\"start\":97},{\"end\":187,\"start\":143},{\"end\":236,\"start\":188},{\"end\":247,\"start\":237},{\"end\":294,\"start\":248},{\"end\":342,\"start\":295},{\"end\":384,\"start\":343},{\"end\":483,\"start\":385},{\"end\":545,\"start\":484}]", "publisher": null, "author_last_name": "[{\"end\":106,\"start\":102},{\"end\":151,\"start\":148},{\"end\":200,\"start\":197},{\"end\":246,\"start\":243},{\"end\":258,\"start\":254},{\"end\":306,\"start\":304},{\"end\":348,\"start\":346},{\"end\":394,\"start\":392},{\"end\":491,\"start\":488}]", "author_first_name": "[{\"end\":101,\"start\":97},{\"end\":147,\"start\":143},{\"end\":196,\"start\":188},{\"end\":242,\"start\":237},{\"end\":253,\"start\":248},{\"end\":303,\"start\":295},{\"end\":345,\"start\":343},{\"end\":391,\"start\":385},{\"end\":487,\"start\":484}]", "author_affiliation": "[{\"end\":141,\"start\":108},{\"end\":186,\"start\":153},{\"end\":235,\"start\":202},{\"end\":293,\"start\":260},{\"end\":341,\"start\":308},{\"end\":383,\"start\":350},{\"end\":450,\"start\":417},{\"end\":482,\"start\":452},{\"end\":544,\"start\":511}]", "title": "[{\"end\":94,\"start\":1},{\"end\":639,\"start\":546}]", "venue": null, "abstract": "[{\"end\":2093,\"start\":725}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2278,\"start\":2275},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2422,\"start\":2419},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3312,\"start\":3309},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3317,\"start\":3314},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3336,\"start\":3333},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3501,\"start\":3498},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3525,\"start\":3522},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3547,\"start\":3543},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3569,\"start\":3565},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4312,\"start\":4308},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4318,\"start\":4314},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5620,\"start\":5616},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7943,\"start\":7939},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8305,\"start\":8301},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11438,\"start\":11434},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11732,\"start\":11728},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12909,\"start\":12905},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13706,\"start\":13702},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":16699,\"start\":16695},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":17473,\"start\":17469},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":18991,\"start\":18987},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":19366,\"start\":19362},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22648,\"start\":22644},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":23299,\"start\":23295},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":23594,\"start\":23590},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23754,\"start\":23750},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":25344,\"start\":25340},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":25350,\"start\":25346},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":26583,\"start\":26579},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":26684,\"start\":26680},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":27092,\"start\":27088},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":27429,\"start\":27425},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":28707,\"start\":28703},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":28724,\"start\":28720},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":28763,\"start\":28759},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":29523,\"start\":29519},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":30668,\"start\":30665},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30673,\"start\":30670},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":30741,\"start\":30738},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":30922,\"start\":30918},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":38075,\"start\":38071},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":38326,\"start\":38323},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":38331,\"start\":38328},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":38337,\"start\":38333},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":38359,\"start\":38356},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":38365,\"start\":38361},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":38371,\"start\":38367},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":38383,\"start\":38380},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":38389,\"start\":38385},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":38413,\"start\":38410},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":38436,\"start\":38432},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":38458,\"start\":38454},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":38870,\"start\":38867},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":39040,\"start\":39037},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":39877,\"start\":39873},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":39883,\"start\":39879},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":39972,\"start\":39968},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":40063,\"start\":40059},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":40224,\"start\":40220},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":40341,\"start\":40337},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":43793,\"start\":43792}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":41835,\"start\":41691},{\"attributes\":{\"id\":\"fig_1\"},\"end\":42108,\"start\":41836},{\"attributes\":{\"id\":\"fig_2\"},\"end\":42265,\"start\":42109},{\"attributes\":{\"id\":\"fig_3\"},\"end\":42403,\"start\":42266},{\"attributes\":{\"id\":\"fig_4\"},\"end\":42557,\"start\":42404},{\"attributes\":{\"id\":\"fig_5\"},\"end\":42616,\"start\":42558},{\"attributes\":{\"id\":\"fig_6\"},\"end\":43235,\"start\":42617},{\"attributes\":{\"id\":\"fig_7\"},\"end\":43293,\"start\":43236},{\"attributes\":{\"id\":\"fig_8\"},\"end\":44174,\"start\":43294},{\"attributes\":{\"id\":\"fig_9\"},\"end\":44369,\"start\":44175},{\"attributes\":{\"id\":\"fig_10\"},\"end\":44444,\"start\":44370},{\"attributes\":{\"id\":\"fig_11\"},\"end\":44504,\"start\":44445},{\"attributes\":{\"id\":\"fig_12\"},\"end\":44537,\"start\":44505},{\"attributes\":{\"id\":\"fig_13\"},\"end\":44576,\"start\":44538}]", "paragraph": "[{\"end\":3741,\"start\":2112},{\"end\":4867,\"start\":3743},{\"end\":5799,\"start\":4869},{\"end\":6824,\"start\":5801},{\"end\":7848,\"start\":6826},{\"end\":8629,\"start\":7908},{\"end\":9157,\"start\":8651},{\"end\":9599,\"start\":9225},{\"end\":9916,\"start\":9651},{\"end\":10307,\"start\":9942},{\"end\":11335,\"start\":10327},{\"end\":11515,\"start\":11337},{\"end\":11861,\"start\":11590},{\"end\":12487,\"start\":11899},{\"end\":13000,\"start\":12575},{\"end\":13094,\"start\":13030},{\"end\":13392,\"start\":13147},{\"end\":13502,\"start\":13457},{\"end\":13810,\"start\":13556},{\"end\":14010,\"start\":13928},{\"end\":14359,\"start\":14099},{\"end\":14642,\"start\":14463},{\"end\":15185,\"start\":14686},{\"end\":16005,\"start\":15216},{\"end\":16115,\"start\":16007},{\"end\":17036,\"start\":16150},{\"end\":17475,\"start\":17038},{\"end\":17685,\"start\":17518},{\"end\":18446,\"start\":17687},{\"end\":18897,\"start\":18448},{\"end\":19441,\"start\":18899},{\"end\":21152,\"start\":19484},{\"end\":21516,\"start\":21180},{\"end\":21903,\"start\":21518},{\"end\":23953,\"start\":21929},{\"end\":24999,\"start\":23955},{\"end\":25569,\"start\":25028},{\"end\":26430,\"start\":25571},{\"end\":27028,\"start\":26495},{\"end\":27813,\"start\":27030},{\"end\":28536,\"start\":27849},{\"end\":29257,\"start\":28572},{\"end\":29909,\"start\":29259},{\"end\":30553,\"start\":29911},{\"end\":30791,\"start\":30568},{\"end\":31018,\"start\":30793},{\"end\":31395,\"start\":31045},{\"end\":33275,\"start\":31397},{\"end\":34478,\"start\":33277},{\"end\":35264,\"start\":34502},{\"end\":35379,\"start\":35266},{\"end\":36720,\"start\":35428},{\"end\":37420,\"start\":36756},{\"end\":38214,\"start\":37450},{\"end\":39732,\"start\":38278},{\"end\":39962,\"start\":39768},{\"end\":40560,\"start\":39964},{\"end\":41228,\"start\":40585},{\"end\":41690,\"start\":41249}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9224,\"start\":9158},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9650,\"start\":9600},{\"attributes\":{\"id\":\"formula_2\"},\"end\":9941,\"start\":9917},{\"attributes\":{\"id\":\"formula_3\"},\"end\":11898,\"start\":11862},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12526,\"start\":12488},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13029,\"start\":13001},{\"attributes\":{\"id\":\"formula_6\"},\"end\":13146,\"start\":13095},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13456,\"start\":13393},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13555,\"start\":13503},{\"attributes\":{\"id\":\"formula_9\"},\"end\":13855,\"start\":13811},{\"attributes\":{\"id\":\"formula_10\"},\"end\":13927,\"start\":13855},{\"attributes\":{\"id\":\"formula_11\"},\"end\":14098,\"start\":14011},{\"attributes\":{\"id\":\"formula_12\"},\"end\":14413,\"start\":14360},{\"attributes\":{\"id\":\"formula_13\"},\"end\":14685,\"start\":14643},{\"attributes\":{\"id\":\"formula_14\"},\"end\":16149,\"start\":16116},{\"attributes\":{\"id\":\"formula_15\"},\"end\":26494,\"start\":26431}]", "table_ref": null, "section_header": "[{\"end\":2110,\"start\":2095},{\"end\":7882,\"start\":7851},{\"end\":7906,\"start\":7885},{\"end\":8649,\"start\":8632},{\"end\":10325,\"start\":10310},{\"end\":11559,\"start\":11518},{\"end\":11588,\"start\":11562},{\"end\":12573,\"start\":12528},{\"end\":14461,\"start\":14415},{\"end\":15214,\"start\":15188},{\"end\":17516,\"start\":17478},{\"end\":19461,\"start\":19444},{\"end\":19482,\"start\":19464},{\"end\":21178,\"start\":21155},{\"end\":21927,\"start\":21906},{\"end\":25026,\"start\":25002},{\"end\":27829,\"start\":27816},{\"end\":27847,\"start\":27832},{\"end\":28570,\"start\":28539},{\"end\":30566,\"start\":30556},{\"end\":31043,\"start\":31021},{\"end\":34500,\"start\":34481},{\"end\":35426,\"start\":35382},{\"end\":36754,\"start\":36723},{\"end\":37448,\"start\":37423},{\"end\":38233,\"start\":38217},{\"end\":38276,\"start\":38236},{\"end\":39766,\"start\":39735},{\"end\":40583,\"start\":40563},{\"end\":41247,\"start\":41231},{\"end\":41700,\"start\":41692},{\"end\":41845,\"start\":41837},{\"end\":42118,\"start\":42110},{\"end\":42275,\"start\":42267},{\"end\":42413,\"start\":42405},{\"end\":42567,\"start\":42559},{\"end\":43245,\"start\":43237},{\"end\":43312,\"start\":43295},{\"end\":44184,\"start\":44176},{\"end\":44380,\"start\":44371},{\"end\":44455,\"start\":44446},{\"end\":44515,\"start\":44506},{\"end\":44548,\"start\":44539}]", "table": null, "figure_caption": "[{\"end\":41835,\"start\":41702},{\"end\":42108,\"start\":41847},{\"end\":42265,\"start\":42120},{\"end\":42403,\"start\":42277},{\"end\":42557,\"start\":42415},{\"end\":42616,\"start\":42569},{\"end\":43235,\"start\":42619},{\"end\":43293,\"start\":43247},{\"end\":44174,\"start\":43315},{\"end\":44369,\"start\":44186},{\"end\":44444,\"start\":44383},{\"end\":44504,\"start\":44458},{\"end\":44537,\"start\":44518},{\"end\":44576,\"start\":44551}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4529,\"start\":4521},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":8327,\"start\":8319},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":15258,\"start\":15250},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16855,\"start\":16847},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":17088,\"start\":17080},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":17373,\"start\":17365},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18104,\"start\":18095},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18186,\"start\":18178},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19101,\"start\":19087},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19142,\"start\":19134},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":19529,\"start\":19521},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":23007,\"start\":22999},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":27812,\"start\":27795},{\"end\":27886,\"start\":27878},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":29380,\"start\":29370},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":30277,\"start\":30269},{\"end\":30498,\"start\":30492},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":30531,\"start\":30524},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":31467,\"start\":31458},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":31481,\"start\":31472},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":31512,\"start\":31502},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32255,\"start\":32248},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32385,\"start\":32376},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32769,\"start\":32760},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34080,\"start\":34071},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34681,\"start\":34671},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34744,\"start\":34735},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35984,\"start\":35975},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36858,\"start\":36849},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":37074,\"start\":37065},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":37577,\"start\":37568},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":37745,\"start\":37735},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39898,\"start\":39891},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39933,\"start\":39926}]", "bib_author_first_name": "[{\"end\":45041,\"start\":45036},{\"end\":45298,\"start\":45297},{\"end\":45313,\"start\":45312},{\"end\":45322,\"start\":45321},{\"end\":45645,\"start\":45644},{\"end\":45651,\"start\":45650},{\"end\":45660,\"start\":45659},{\"end\":45669,\"start\":45668},{\"end\":45676,\"start\":45675},{\"end\":45682,\"start\":45681},{\"end\":45689,\"start\":45688},{\"end\":46173,\"start\":46172},{\"end\":46175,\"start\":46174},{\"end\":46184,\"start\":46183},{\"end\":46560,\"start\":46559},{\"end\":46562,\"start\":46561},{\"end\":46571,\"start\":46570},{\"end\":46579,\"start\":46578},{\"end\":46586,\"start\":46585},{\"end\":46596,\"start\":46595},{\"end\":47127,\"start\":47126},{\"end\":47134,\"start\":47133},{\"end\":47142,\"start\":47141},{\"end\":47150,\"start\":47149},{\"end\":47609,\"start\":47608},{\"end\":47617,\"start\":47616},{\"end\":47624,\"start\":47623},{\"end\":47628,\"start\":47625},{\"end\":47635,\"start\":47634},{\"end\":47642,\"start\":47641},{\"end\":48060,\"start\":48059},{\"end\":48069,\"start\":48068},{\"end\":48083,\"start\":48082},{\"end\":48093,\"start\":48092},{\"end\":48095,\"start\":48094},{\"end\":48105,\"start\":48104},{\"end\":48115,\"start\":48114},{\"end\":48117,\"start\":48116},{\"end\":48315,\"start\":48314},{\"end\":48322,\"start\":48321},{\"end\":48326,\"start\":48323},{\"end\":48795,\"start\":48794},{\"end\":48804,\"start\":48803},{\"end\":48810,\"start\":48809},{\"end\":49131,\"start\":49130},{\"end\":49142,\"start\":49141},{\"end\":49155,\"start\":49154},{\"end\":49468,\"start\":49467},{\"end\":49482,\"start\":49481},{\"end\":49729,\"start\":49728},{\"end\":49731,\"start\":49730},{\"end\":49740,\"start\":49739},{\"end\":49742,\"start\":49741},{\"end\":49942,\"start\":49941},{\"end\":49951,\"start\":49950},{\"end\":49961,\"start\":49960},{\"end\":50249,\"start\":50248},{\"end\":50251,\"start\":50250},{\"end\":50547,\"start\":50546},{\"end\":50702,\"start\":50701},{\"end\":50841,\"start\":50840},{\"end\":50843,\"start\":50842},{\"end\":51068,\"start\":51067},{\"end\":51079,\"start\":51078},{\"end\":51326,\"start\":51325},{\"end\":51514,\"start\":51513},{\"end\":51919,\"start\":51918},{\"end\":51929,\"start\":51928},{\"end\":51942,\"start\":51941},{\"end\":51951,\"start\":51950},{\"end\":52196,\"start\":52195},{\"end\":52207,\"start\":52206},{\"end\":52513,\"start\":52512},{\"end\":52522,\"start\":52521},{\"end\":52535,\"start\":52534},{\"end\":52793,\"start\":52792},{\"end\":52804,\"start\":52803},{\"end\":52815,\"start\":52814},{\"end\":53228,\"start\":53227},{\"end\":53239,\"start\":53238},{\"end\":53250,\"start\":53249},{\"end\":53662,\"start\":53661},{\"end\":53903,\"start\":53902},{\"end\":54085,\"start\":54084},{\"end\":54177,\"start\":54176},{\"end\":54405,\"start\":54404},{\"end\":54415,\"start\":54414},{\"end\":54428,\"start\":54427},{\"end\":54445,\"start\":54441},{\"end\":54455,\"start\":54454},{\"end\":54718,\"start\":54717},{\"end\":54861,\"start\":54860},{\"end\":54870,\"start\":54869},{\"end\":54872,\"start\":54871},{\"end\":54882,\"start\":54881},{\"end\":54888,\"start\":54887},{\"end\":54896,\"start\":54895},{\"end\":55440,\"start\":55439},{\"end\":55448,\"start\":55447},{\"end\":55989,\"start\":55988},{\"end\":55996,\"start\":55995},{\"end\":55998,\"start\":55997},{\"end\":56007,\"start\":56006},{\"end\":56562,\"start\":56561},{\"end\":56570,\"start\":56569},{\"end\":56578,\"start\":56577},{\"end\":56580,\"start\":56579},{\"end\":56589,\"start\":56588},{\"end\":56599,\"start\":56598},{\"end\":56606,\"start\":56605},{\"end\":56608,\"start\":56607},{\"end\":56898,\"start\":56897},{\"end\":57069,\"start\":57068},{\"end\":57071,\"start\":57070},{\"end\":57345,\"start\":57344},{\"end\":57352,\"start\":57351},{\"end\":57360,\"start\":57359},{\"end\":57370,\"start\":57369},{\"end\":57376,\"start\":57375},{\"end\":57382,\"start\":57381},{\"end\":57877,\"start\":57876},{\"end\":57883,\"start\":57882},{\"end\":57889,\"start\":57888},{\"end\":57891,\"start\":57890},{\"end\":57902,\"start\":57901},{\"end\":57910,\"start\":57909},{\"end\":57918,\"start\":57917},{\"end\":57924,\"start\":57923},{\"end\":58301,\"start\":58300},{\"end\":58308,\"start\":58307},{\"end\":58324,\"start\":58323},{\"end\":58330,\"start\":58329},{\"end\":58340,\"start\":58339},{\"end\":58348,\"start\":58347},{\"end\":58773,\"start\":58772},{\"end\":58779,\"start\":58778},{\"end\":58785,\"start\":58784},{\"end\":58794,\"start\":58793},{\"end\":58796,\"start\":58795},{\"end\":58807,\"start\":58806},{\"end\":58813,\"start\":58812},{\"end\":58821,\"start\":58820},{\"end\":58829,\"start\":58828},{\"end\":59414,\"start\":59413},{\"end\":59421,\"start\":59420},{\"end\":59428,\"start\":59427},{\"end\":59435,\"start\":59434},{\"end\":59443,\"start\":59442},{\"end\":59449,\"start\":59448},{\"end\":59456,\"start\":59455},{\"end\":59462,\"start\":59461},{\"end\":59974,\"start\":59973},{\"end\":59980,\"start\":59979},{\"end\":59986,\"start\":59985},{\"end\":59988,\"start\":59987},{\"end\":59999,\"start\":59998},{\"end\":60005,\"start\":60004},{\"end\":60014,\"start\":60013},{\"end\":60022,\"start\":60021},{\"end\":60030,\"start\":60029},{\"end\":60036,\"start\":60035},{\"end\":60043,\"start\":60042},{\"end\":60553,\"start\":60552},{\"end\":60559,\"start\":60558},{\"end\":60565,\"start\":60564},{\"end\":60567,\"start\":60566},{\"end\":60578,\"start\":60577},{\"end\":60580,\"start\":60579},{\"end\":60590,\"start\":60589}]", "bib_author_last_name": "[{\"end\":44721,\"start\":44709},{\"end\":45052,\"start\":45042},{\"end\":45310,\"start\":45299},{\"end\":45319,\"start\":45314},{\"end\":45330,\"start\":45323},{\"end\":45648,\"start\":45646},{\"end\":45657,\"start\":45652},{\"end\":45666,\"start\":45661},{\"end\":45673,\"start\":45670},{\"end\":45679,\"start\":45677},{\"end\":45686,\"start\":45683},{\"end\":45693,\"start\":45690},{\"end\":46181,\"start\":46176},{\"end\":46191,\"start\":46185},{\"end\":46568,\"start\":46563},{\"end\":46576,\"start\":46572},{\"end\":46583,\"start\":46580},{\"end\":46593,\"start\":46587},{\"end\":46601,\"start\":46597},{\"end\":47131,\"start\":47128},{\"end\":47139,\"start\":47135},{\"end\":47147,\"start\":47143},{\"end\":47156,\"start\":47151},{\"end\":47614,\"start\":47610},{\"end\":47621,\"start\":47618},{\"end\":47632,\"start\":47629},{\"end\":47639,\"start\":47636},{\"end\":47646,\"start\":47643},{\"end\":48066,\"start\":48061},{\"end\":48080,\"start\":48070},{\"end\":48090,\"start\":48084},{\"end\":48102,\"start\":48096},{\"end\":48112,\"start\":48106},{\"end\":48125,\"start\":48118},{\"end\":48319,\"start\":48316},{\"end\":48336,\"start\":48327},{\"end\":48801,\"start\":48796},{\"end\":48807,\"start\":48805},{\"end\":48813,\"start\":48811},{\"end\":49139,\"start\":49132},{\"end\":49152,\"start\":49143},{\"end\":49163,\"start\":49156},{\"end\":49479,\"start\":49469},{\"end\":49492,\"start\":49483},{\"end\":49737,\"start\":49732},{\"end\":49749,\"start\":49743},{\"end\":49948,\"start\":49943},{\"end\":49958,\"start\":49952},{\"end\":49970,\"start\":49962},{\"end\":50259,\"start\":50252},{\"end\":50555,\"start\":50548},{\"end\":50709,\"start\":50703},{\"end\":50849,\"start\":50844},{\"end\":51076,\"start\":51069},{\"end\":51084,\"start\":51080},{\"end\":51334,\"start\":51327},{\"end\":51522,\"start\":51515},{\"end\":51926,\"start\":51920},{\"end\":51939,\"start\":51930},{\"end\":51948,\"start\":51943},{\"end\":51966,\"start\":51952},{\"end\":52204,\"start\":52197},{\"end\":52215,\"start\":52208},{\"end\":52519,\"start\":52514},{\"end\":52532,\"start\":52523},{\"end\":52540,\"start\":52536},{\"end\":52801,\"start\":52794},{\"end\":52812,\"start\":52805},{\"end\":52821,\"start\":52816},{\"end\":53236,\"start\":53229},{\"end\":53247,\"start\":53240},{\"end\":53256,\"start\":53251},{\"end\":53669,\"start\":53663},{\"end\":53910,\"start\":53904},{\"end\":54093,\"start\":54086},{\"end\":54185,\"start\":54178},{\"end\":54412,\"start\":54406},{\"end\":54425,\"start\":54416},{\"end\":54439,\"start\":54429},{\"end\":54452,\"start\":54446},{\"end\":54461,\"start\":54456},{\"end\":54733,\"start\":54719},{\"end\":54867,\"start\":54862},{\"end\":54879,\"start\":54873},{\"end\":54885,\"start\":54883},{\"end\":54893,\"start\":54889},{\"end\":54906,\"start\":54897},{\"end\":55445,\"start\":55441},{\"end\":55457,\"start\":55449},{\"end\":55762,\"start\":55757},{\"end\":55993,\"start\":55990},{\"end\":56004,\"start\":55999},{\"end\":56013,\"start\":56008},{\"end\":56567,\"start\":56563},{\"end\":56575,\"start\":56571},{\"end\":56586,\"start\":56581},{\"end\":56596,\"start\":56590},{\"end\":56603,\"start\":56600},{\"end\":56619,\"start\":56609},{\"end\":56906,\"start\":56899},{\"end\":57081,\"start\":57072},{\"end\":57349,\"start\":57346},{\"end\":57357,\"start\":57353},{\"end\":57367,\"start\":57361},{\"end\":57373,\"start\":57371},{\"end\":57379,\"start\":57377},{\"end\":57386,\"start\":57383},{\"end\":57880,\"start\":57878},{\"end\":57886,\"start\":57884},{\"end\":57899,\"start\":57892},{\"end\":57907,\"start\":57903},{\"end\":57915,\"start\":57911},{\"end\":57921,\"start\":57919},{\"end\":57927,\"start\":57925},{\"end\":58305,\"start\":58302},{\"end\":58321,\"start\":58309},{\"end\":58327,\"start\":58325},{\"end\":58337,\"start\":58331},{\"end\":58345,\"start\":58341},{\"end\":58353,\"start\":58349},{\"end\":58776,\"start\":58774},{\"end\":58782,\"start\":58780},{\"end\":58791,\"start\":58786},{\"end\":58804,\"start\":58797},{\"end\":58810,\"start\":58808},{\"end\":58818,\"start\":58814},{\"end\":58826,\"start\":58822},{\"end\":58832,\"start\":58830},{\"end\":59418,\"start\":59415},{\"end\":59425,\"start\":59422},{\"end\":59432,\"start\":59429},{\"end\":59440,\"start\":59436},{\"end\":59446,\"start\":59444},{\"end\":59453,\"start\":59450},{\"end\":59459,\"start\":59457},{\"end\":59466,\"start\":59463},{\"end\":59977,\"start\":59975},{\"end\":59983,\"start\":59981},{\"end\":59996,\"start\":59989},{\"end\":60002,\"start\":60000},{\"end\":60011,\"start\":60006},{\"end\":60019,\"start\":60015},{\"end\":60027,\"start\":60023},{\"end\":60033,\"start\":60031},{\"end\":60040,\"start\":60037},{\"end\":60047,\"start\":60044},{\"end\":60556,\"start\":60554},{\"end\":60562,\"start\":60560},{\"end\":60575,\"start\":60568},{\"end\":60587,\"start\":60581},{\"end\":60596,\"start\":60591}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":44968,\"start\":44578},{\"attributes\":{\"id\":\"b1\"},\"end\":45241,\"start\":44970},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":942903},\"end\":45564,\"start\":45243},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":211268160},\"end\":46087,\"start\":45566},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":49230159},\"end\":46438,\"start\":46089},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":235628558},\"end\":47072,\"start\":46440},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":1875264},\"end\":47534,\"start\":47074},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":227154660},\"end\":47996,\"start\":47536},{\"attributes\":{\"id\":\"b8\"},\"end\":48275,\"start\":47998},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":6252639},\"end\":48717,\"start\":48277},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":132878678},\"end\":49041,\"start\":48719},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":209923274},\"end\":49379,\"start\":49043},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":30459051},\"end\":49726,\"start\":49381},{\"attributes\":{\"id\":\"b13\"},\"end\":49886,\"start\":49728},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":137182310},\"end\":50136,\"start\":49888},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":24646441},\"end\":50498,\"start\":50138},{\"attributes\":{\"id\":\"b16\"},\"end\":50656,\"start\":50500},{\"attributes\":{\"id\":\"b17\"},\"end\":50838,\"start\":50658},{\"attributes\":{\"id\":\"b18\"},\"end\":50990,\"start\":50840},{\"attributes\":{\"id\":\"b19\"},\"end\":51225,\"start\":50992},{\"attributes\":{\"id\":\"b20\"},\"end\":51453,\"start\":51227},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":107078764},\"end\":51695,\"start\":51455},{\"attributes\":{\"id\":\"b22\"},\"end\":51844,\"start\":51697},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":4395438},\"end\":52166,\"start\":51846},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":13756489},\"end\":52406,\"start\":52168},{\"attributes\":{\"id\":\"b25\"},\"end\":52699,\"start\":52408},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":52287794},\"end\":53152,\"start\":52701},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":52290478},\"end\":53546,\"start\":53154},{\"attributes\":{\"id\":\"b28\"},\"end\":53582,\"start\":53548},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":205223113},\"end\":53830,\"start\":53584},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":30848183},\"end\":54066,\"start\":53832},{\"attributes\":{\"id\":\"b31\"},\"end\":54130,\"start\":54068},{\"attributes\":{\"id\":\"b32\"},\"end\":54316,\"start\":54132},{\"attributes\":{\"doi\":\"arXiv:1807.03418\",\"id\":\"b33\"},\"end\":54687,\"start\":54318},{\"attributes\":{\"id\":\"b34\"},\"end\":54789,\"start\":54689},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":207224888},\"end\":55352,\"start\":54791},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":13972181},\"end\":55739,\"start\":55354},{\"attributes\":{\"id\":\"b37\"},\"end\":55890,\"start\":55741},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":12208452},\"end\":56468,\"start\":55892},{\"attributes\":{\"id\":\"b39\"},\"end\":56833,\"start\":56470},{\"attributes\":{\"doi\":\"App. 11/095\",\"id\":\"b40\"},\"end\":57048,\"start\":56835},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":106403756},\"end\":57259,\"start\":57050},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":29565200},\"end\":57807,\"start\":57261},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":216228013},\"end\":58186,\"start\":57809},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":227127580},\"end\":58679,\"start\":58188},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":189926717},\"end\":59313,\"start\":58681},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":243942547},\"end\":59869,\"start\":59315},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":227154551},\"end\":60470,\"start\":59871},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":245019338},\"end\":60880,\"start\":60472}]", "bib_title": "[{\"end\":45295,\"start\":45243},{\"end\":45642,\"start\":45566},{\"end\":46170,\"start\":46089},{\"end\":46557,\"start\":46440},{\"end\":47124,\"start\":47074},{\"end\":47606,\"start\":47536},{\"end\":48312,\"start\":48277},{\"end\":48792,\"start\":48719},{\"end\":49128,\"start\":49043},{\"end\":49465,\"start\":49381},{\"end\":49939,\"start\":49888},{\"end\":50246,\"start\":50138},{\"end\":51511,\"start\":51455},{\"end\":51916,\"start\":51846},{\"end\":52193,\"start\":52168},{\"end\":52790,\"start\":52701},{\"end\":53225,\"start\":53154},{\"end\":53659,\"start\":53584},{\"end\":53900,\"start\":53832},{\"end\":54858,\"start\":54791},{\"end\":55437,\"start\":55354},{\"end\":55986,\"start\":55892},{\"end\":57066,\"start\":57050},{\"end\":57342,\"start\":57261},{\"end\":57874,\"start\":57809},{\"end\":58298,\"start\":58188},{\"end\":58770,\"start\":58681},{\"end\":59411,\"start\":59315},{\"end\":59971,\"start\":59871},{\"end\":60550,\"start\":60472}]", "bib_author": "[{\"end\":44723,\"start\":44709},{\"end\":45054,\"start\":45036},{\"end\":45312,\"start\":45297},{\"end\":45321,\"start\":45312},{\"end\":45332,\"start\":45321},{\"end\":45650,\"start\":45644},{\"end\":45659,\"start\":45650},{\"end\":45668,\"start\":45659},{\"end\":45675,\"start\":45668},{\"end\":45681,\"start\":45675},{\"end\":45688,\"start\":45681},{\"end\":45695,\"start\":45688},{\"end\":46183,\"start\":46172},{\"end\":46193,\"start\":46183},{\"end\":46570,\"start\":46559},{\"end\":46578,\"start\":46570},{\"end\":46585,\"start\":46578},{\"end\":46595,\"start\":46585},{\"end\":46603,\"start\":46595},{\"end\":47133,\"start\":47126},{\"end\":47141,\"start\":47133},{\"end\":47149,\"start\":47141},{\"end\":47158,\"start\":47149},{\"end\":47616,\"start\":47608},{\"end\":47623,\"start\":47616},{\"end\":47634,\"start\":47623},{\"end\":47641,\"start\":47634},{\"end\":47648,\"start\":47641},{\"end\":48068,\"start\":48059},{\"end\":48082,\"start\":48068},{\"end\":48092,\"start\":48082},{\"end\":48104,\"start\":48092},{\"end\":48114,\"start\":48104},{\"end\":48127,\"start\":48114},{\"end\":48321,\"start\":48314},{\"end\":48338,\"start\":48321},{\"end\":48803,\"start\":48794},{\"end\":48809,\"start\":48803},{\"end\":48815,\"start\":48809},{\"end\":49141,\"start\":49130},{\"end\":49154,\"start\":49141},{\"end\":49165,\"start\":49154},{\"end\":49481,\"start\":49467},{\"end\":49494,\"start\":49481},{\"end\":49739,\"start\":49728},{\"end\":49751,\"start\":49739},{\"end\":49950,\"start\":49941},{\"end\":49960,\"start\":49950},{\"end\":49972,\"start\":49960},{\"end\":50261,\"start\":50248},{\"end\":50557,\"start\":50546},{\"end\":50711,\"start\":50701},{\"end\":50851,\"start\":50840},{\"end\":51078,\"start\":51067},{\"end\":51086,\"start\":51078},{\"end\":51336,\"start\":51325},{\"end\":51524,\"start\":51513},{\"end\":51928,\"start\":51918},{\"end\":51941,\"start\":51928},{\"end\":51950,\"start\":51941},{\"end\":51968,\"start\":51950},{\"end\":52206,\"start\":52195},{\"end\":52217,\"start\":52206},{\"end\":52521,\"start\":52512},{\"end\":52534,\"start\":52521},{\"end\":52542,\"start\":52534},{\"end\":52803,\"start\":52792},{\"end\":52814,\"start\":52803},{\"end\":52823,\"start\":52814},{\"end\":53238,\"start\":53227},{\"end\":53249,\"start\":53238},{\"end\":53258,\"start\":53249},{\"end\":53671,\"start\":53661},{\"end\":53912,\"start\":53902},{\"end\":54095,\"start\":54084},{\"end\":54187,\"start\":54176},{\"end\":54414,\"start\":54404},{\"end\":54427,\"start\":54414},{\"end\":54441,\"start\":54427},{\"end\":54454,\"start\":54441},{\"end\":54463,\"start\":54454},{\"end\":54735,\"start\":54717},{\"end\":54869,\"start\":54860},{\"end\":54881,\"start\":54869},{\"end\":54887,\"start\":54881},{\"end\":54895,\"start\":54887},{\"end\":54908,\"start\":54895},{\"end\":55447,\"start\":55439},{\"end\":55459,\"start\":55447},{\"end\":55764,\"start\":55757},{\"end\":55995,\"start\":55988},{\"end\":56006,\"start\":55995},{\"end\":56015,\"start\":56006},{\"end\":56569,\"start\":56561},{\"end\":56577,\"start\":56569},{\"end\":56588,\"start\":56577},{\"end\":56598,\"start\":56588},{\"end\":56605,\"start\":56598},{\"end\":56621,\"start\":56605},{\"end\":56908,\"start\":56897},{\"end\":57083,\"start\":57068},{\"end\":57351,\"start\":57344},{\"end\":57359,\"start\":57351},{\"end\":57369,\"start\":57359},{\"end\":57375,\"start\":57369},{\"end\":57381,\"start\":57375},{\"end\":57388,\"start\":57381},{\"end\":57882,\"start\":57876},{\"end\":57888,\"start\":57882},{\"end\":57901,\"start\":57888},{\"end\":57909,\"start\":57901},{\"end\":57917,\"start\":57909},{\"end\":57923,\"start\":57917},{\"end\":57929,\"start\":57923},{\"end\":58307,\"start\":58300},{\"end\":58323,\"start\":58307},{\"end\":58329,\"start\":58323},{\"end\":58339,\"start\":58329},{\"end\":58347,\"start\":58339},{\"end\":58355,\"start\":58347},{\"end\":58778,\"start\":58772},{\"end\":58784,\"start\":58778},{\"end\":58793,\"start\":58784},{\"end\":58806,\"start\":58793},{\"end\":58812,\"start\":58806},{\"end\":58820,\"start\":58812},{\"end\":58828,\"start\":58820},{\"end\":58834,\"start\":58828},{\"end\":59420,\"start\":59413},{\"end\":59427,\"start\":59420},{\"end\":59434,\"start\":59427},{\"end\":59442,\"start\":59434},{\"end\":59448,\"start\":59442},{\"end\":59455,\"start\":59448},{\"end\":59461,\"start\":59455},{\"end\":59468,\"start\":59461},{\"end\":59979,\"start\":59973},{\"end\":59985,\"start\":59979},{\"end\":59998,\"start\":59985},{\"end\":60004,\"start\":59998},{\"end\":60013,\"start\":60004},{\"end\":60021,\"start\":60013},{\"end\":60029,\"start\":60021},{\"end\":60035,\"start\":60029},{\"end\":60042,\"start\":60035},{\"end\":60049,\"start\":60042},{\"end\":60558,\"start\":60552},{\"end\":60564,\"start\":60558},{\"end\":60577,\"start\":60564},{\"end\":60589,\"start\":60577},{\"end\":60598,\"start\":60589}]", "bib_venue": "[{\"end\":45846,\"start\":45779},{\"end\":46778,\"start\":46699},{\"end\":47325,\"start\":47250},{\"end\":47777,\"start\":47721},{\"end\":48527,\"start\":48441},{\"end\":55097,\"start\":55011},{\"end\":56206,\"start\":56119},{\"end\":57555,\"start\":57480},{\"end\":59023,\"start\":58937},{\"end\":59605,\"start\":59545},{\"end\":60178,\"start\":60122},{\"end\":44707,\"start\":44578},{\"end\":45034,\"start\":44970},{\"end\":45364,\"start\":45332},{\"end\":45777,\"start\":45695},{\"end\":46241,\"start\":46193},{\"end\":46697,\"start\":46603},{\"end\":47248,\"start\":47158},{\"end\":47719,\"start\":47648},{\"end\":48057,\"start\":47998},{\"end\":48439,\"start\":48338},{\"end\":48863,\"start\":48815},{\"end\":49182,\"start\":49165},{\"end\":49525,\"start\":49494},{\"end\":49772,\"start\":49751},{\"end\":50003,\"start\":49972},{\"end\":50290,\"start\":50261},{\"end\":50544,\"start\":50500},{\"end\":50699,\"start\":50658},{\"end\":50882,\"start\":50851},{\"end\":51065,\"start\":50992},{\"end\":51323,\"start\":51227},{\"end\":51564,\"start\":51524},{\"end\":51704,\"start\":51697},{\"end\":51985,\"start\":51968},{\"end\":52266,\"start\":52217},{\"end\":52510,\"start\":52408},{\"end\":52900,\"start\":52823},{\"end\":53335,\"start\":53258},{\"end\":53554,\"start\":53550},{\"end\":53691,\"start\":53671},{\"end\":53932,\"start\":53912},{\"end\":54082,\"start\":54068},{\"end\":54174,\"start\":54132},{\"end\":54402,\"start\":54318},{\"end\":54715,\"start\":54689},{\"end\":55009,\"start\":54908},{\"end\":55518,\"start\":55459},{\"end\":55755,\"start\":55741},{\"end\":56117,\"start\":56015},{\"end\":56559,\"start\":56470},{\"end\":56895,\"start\":56835},{\"end\":57131,\"start\":57083},{\"end\":57478,\"start\":57388},{\"end\":57977,\"start\":57929},{\"end\":58410,\"start\":58355},{\"end\":58935,\"start\":58834},{\"end\":59543,\"start\":59468},{\"end\":60120,\"start\":60049},{\"end\":60659,\"start\":60598}]"}}}, "year": 2023, "month": 12, "day": 17}