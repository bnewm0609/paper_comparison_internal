{"id": 2023817, "updated": "2023-04-05 09:15:38.22", "metadata": {"title": "A Dynamic Recurrent Model for Next Basket Recommendation", "authors": "[{\"first\":\"Feng\",\"last\":\"Yu\",\"middle\":[]},{\"first\":\"Qiang\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Shu\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Liang\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Tieniu\",\"last\":\"Tan\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "publication_date": {"year": 2016, "month": null, "day": null}, "abstract": "Next basket recommendation becomes an increasing concern. Most conventional models explore either sequential transaction features or general interests of users. Further, some works treat users' general interests and sequential behaviors as two totally divided matters, and then combine them in some way for next basket recommendation. Moreover, the state-of-the-art models are based on the assumption of Markov Chains (MC), which only capture local sequential features between two adjacent baskets. In this work, we propose a novel model, Dynamic REcurrent bAsket Model (DREAM), based on Recurrent Neural Network (RNN). DREAM not only learns a dynamic representation of a user but also captures global sequential features among baskets. The dynamic representation of a specific user can reveal user's dynamic interests at different time, and the global sequential features reflect interactions of all baskets of the user over time. Experiment results on two public datasets indicate that DREAM is more effective than the state-of-the-art models for next basket recommendation.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2474909202", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigir/YuLWWT16", "doi": "10.1145/2911451.2914683"}}, "content": {"source": {"pdf_hash": "043ae0ffa13c3b6b356a1d2a9859dcf2876388b3", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "f01e0511b80e268b4273b2d2221613e3b820e48f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/043ae0ffa13c3b6b356a1d2a9859dcf2876388b3.txt", "contents": "\nA Dynamic Recurrent Model for Next Basket Recommendation\n\n\nFeng Yu feng.yu@nlpr.ia.ac.cn \nCenter for Research on Intelligent Perception and Computing National Laboratory of Pattern Recognition Institute of Automation\nChinese Academy of Sciences\n\n\nQiang Liu qiang.liu@nlpr.ia.ac.cn \nCenter for Research on Intelligent Perception and Computing National Laboratory of Pattern Recognition Institute of Automation\nChinese Academy of Sciences\n\n\nShu Wu shu.wu@nlpr.ia.ac.cn \nCenter for Research on Intelligent Perception and Computing National Laboratory of Pattern Recognition Institute of Automation\nChinese Academy of Sciences\n\n\nLiang Wang wangliang@nlpr.ia.ac.cn \nCenter for Research on Intelligent Perception and Computing National Laboratory of Pattern Recognition Institute of Automation\nChinese Academy of Sciences\n\n\nTieniu Tan \nCenter for Research on Intelligent Perception and Computing National Laboratory of Pattern Recognition Institute of Automation\nChinese Academy of Sciences\n\n\nA Dynamic Recurrent Model for Next Basket Recommendation\n10.1145/2911451.2914683Next basket recommendation; recurrent neural network\nNext basket recommendation becomes an increasing concern. Most conventional models explore either sequential transaction features or general interests of users. Further, some works treat users' general interests and sequential behaviors as two totally divided matters, and then combine them in some way for next basket recommendation. Moreover, the state-of-the-art models are based on the assumption of Markov Chains (MC), which only capture local sequential features between two adjacent baskets. In this work, we propose a novel model, Dynamic REcurrent bAsket Model (DREAM), based on Recurrent Neural Network (RNN). DREAM not only learns a dynamic representation of a user but also captures global sequential features among baskets. The dynamic representation of a specific user can reveal user's dynamic interests at different time, and the global sequential features reflect interactions of all baskets of the user over time. Experiment results on two public datasets indicate that DREAM is more effective than the state-of-the-art models for next basket recommendation.\n\nINTRODUCTION\n\nIn real-world scenarios, a customer always purchases a series of baskets of items at different time. This recommendation task in e-commerce sites is formulated as the next basket recommendation, which has received much attention recently [1,3].\n\nIn general, there are two distinct approaches for next basket recommendation. One perspective is the collaborative filtering (CF) models, which capture users' general interests but have difficulty in considering sequential features of * The first two authors contributed equally to this paper.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. historical transactions. Matrix factorization (MF) is a successful CF model [4]. Through factorizing a user-item matrix constructed by the whole historical transaction data, users' general interests can be represented by latent vectors. For instance, a sportsman always buy various athletic equipment, the latent vector may tell that he is interested in sport and we can recommend sports items. Moreover, some sequential recommendation models mainly based on MC [2], which extract sequential features from historical transactions and then predict next purchase based on these sequential behaviors.\n\nAs a consequence, a more appropriate way to next basket recommendation is to capture above sequential behaviors and user general interests in a hybrid model. Factorizing Personalized Markov Chains (FPMC) can model sequential behaviors between every two adjacent baskets, and user general interests is shaped by items in baskets [7]. Actually there are multiple interacting factors influencing users' next purchase in real commercial scenarios. FPMC just utilizes a linear operation on multiple factors, and cannot depict the interactions among multiple factors. Hierarchical Representation Model (HRM) seems to partially solve the problem of how to summarize multiple interacting factors through a nonlinear max pooling operation [9]. Nevertheless, all the MC based methods (including above FPMC and HRM) have the same deficiency that these recommenders can only model local sequential behaviors between every two adjacent baskets, and some of which may be irrelevant sometimes. For instance, a user u bought a ultrabook in basket B u t 1 (a basket of user u at time t1, similarly hereinafter), some food in B u t 2 and accessories of the ultrabook in B u t 3 , there does not exist any relevance between every two adjacent baskets. Hence, we need to model global sequential behaviors to make the best of all relations among sequential baskets like the above B u t 1 and B u t 3 . For this reason, we plan to model global sequential features among all sequential baskets of a user.\n\nIn order to mine global sequential features in complex commercial scenarios and reveal dynamic representations of users' interests, deep neural network is employed in this work. As stated above, local sequential features extracted by HRM is not capable enough to model relations among apart baskets, while a recurrent operation of a deep RNN architecture can capture global sequential features from all baskets of a user. Recently, RNN approaches to word embedding for sentence modeling [5], sequential click prediction [10] have achieved much success in respective fields. We propose a dynamic recurrent model, i.e., DREAM, for next bas-  ket recommendation. An input instance of DREAM model consists a series of baskets of items, which are sequential transactions of a specific user. Pooling and matrix operations can offer each user a dynamic representation with different baskets over time. Moreover, the recurrent structure can obtain some global sequential features for all users from overall historical transaction data. Our experiment results on two real-world datasets reveal that the DREAM model achieves great improvement for next basket recommendation comparing with the state-of-the-art models such as FPMC, HRM.\n\nIn this work, we take advantage of the whole historical sequential transaction data to gain comprehensive understanding of users' purchase interests and consequently recommend items that each user most probably purchase in the next visit. The main contributions of this work are as follows. We investigate the dynamic representation of each user and the global sequential behaviors of item-purchase history. Experiments on two datasets are conducted to validate the effectiveness of DREAM model. To the best of our knowledge, DREAM is the first approach that attempts to incorporate dynamic representation and global sequential behaviors for enhancing the performance of next basket recommendation.\n\n\nTHE PROPOSED APPROACH\n\nIn this section, we formulate the task of next basket recommendation and then introduce the proposed DREAM model in detail.\n\n\nProblem Formulation\n\nIn the scenario of next basket recommendation, there are a mass of users, and each user purchases a series of baskets of items. Let N be the representations of items, and nv \u2208 R d indicates the latent representations of item v. For a user u, the historical transactions B u are composed of a collection of baskets\n{B u t 1 , B u t 2 , ...} in time order, where B u t i\nis a basket of items purchased by user u at time ti. For next basket recommendation with historical transaction data, we formalize the problem as predicting a ranking list of items for each user at a specific time ti.\n\n\nDREAM\n\nThe general framework of DREAM is illustrated in Figure  1. An input instance of the proposed model are a sequence of baskets. For one basket B u t i of the user u, there are a variety of items,\nB u t i = n u t i ,j \u2208 R d |j = 1, 2, ..., B u t i . n u t i ,j is the latent representation of the j-th item in basket B u t i and B u t i means the number of items in basket B u t i . Now, we can generate the latent vector representation b u t i for a basket B u t i\nby aggregating representation vectors of these items. In this work, we adopt two kinds of aggregation operation, i.e., max pooling and average pooling.\n\nFor the max pooling operation, we aggregate a group of vectors through taking the maximum value of every dimension among all those vectors. Then each dimension of b u t i is formulated as\nb u t i ,k = max n u t i ,1,k , n u t i ,2,k , ... ,(1)\nwhere b u t i ,k is the k-th dimension of a basket-representing vector b u t i , n u t i ,j,k means the value of k-th dimension of the vector representation of the j-th item (n u t i ,j ) in basket B u t i . The average pooling is a similar operation but replaces maximum with average. In other words, the average pooling is to aggregate a group of vectors through taking the average value of every dimension of all those vectors, which can be formulated in a similar way as\nb u t i = 1 B u t i B u t i j=1 n u t i ,j .(2)\nThese above representations of baskets can form the input layer of a recurrent architecture. As is shown in Figure 1, the vector representation of a hidden layer h u t i is the dynamic representation of user u at time ti. The recurrent connection weight matrix R helps to propagate sequential signals between every two adjacent hidden state h u t i\u22121 and h u t i [10]. X is a transition matrix between latent vector representations of baskets and a user's interests. Then, the vector representation of the hidden layer can be computed as:\nh u t i = f Xb u t i + Rh u t i\u22121 ,(3)\nwhere b u t i is a latent vector representation of the user's basket at time ti, and h u t i\u22121 is the dynamic representation of the previous time ti\u22121. f (x) is a activation function, here we choose a sigmoid function f (x) = 1 1+e \u2212x . Finally the model can output a user's scores ou,t i towards all items at time ti. The output ou,t i can be calculated through multiplication of item matrix N and a user's dynamic representation h u t i , which is formulated as follows:\nou,t i = N T h u t i .(4)\nTherefore ou,t i ,v , i.e., an element of ou,t i , represents the score of a transaction between a user u and an item v at time ti. A higher score indicates that the user is more likely to purchase the corresponding item.\n\n\nObjective Function\n\nIn the learning process of DREAM, we adopt Bayesian Personalized Ranking (BPR) [6]. BPR is a state-of-the-art pairwise ranking framework for the implicit feedback data. The basic assumption is that a user prefers an item in basket at a specific time than a negative item sample. The negative items can be any other items apart from those in the basket. In this way, we need to maximize the following probability:\np u, t, v v = \u03c3 (ou,t,v \u2212 o u,t,v ) ,(5)\nwhere v denotes a negative item sample, and \u03c3 (x) is a nonlinear function which is chosen as \u03c3 (x) = 1 1+e \u2212x . Adding up all the log likelihood and the regularization term, the objective function can be written as follows:\nJ = ln 1 + e \u2212(o u,t,v \u2212o u,t,v ) + \u03bb 2 \u0398 2 ,(6)\nwhere \u0398 = {N , R, X} denotes all the parameters to be learnt, \u03bb is a parameter to control the power of regularization. Furthermore, the objective function can be optimized by Back Propagation Through Time (BPTT) [8]. BPTT is to iteratively repeat the calculation of derivations of J with respect to different parameters and obtain these gradients of all the parameters in the end. Then we update parameters utilizing Stochastic Gradient Descent (SGD) until converge.\n\nNotice that the DREAM model utilize an iterative method in learning users' representation vectors. That is to say, for any new transactions, we can update users' representation vectors based current ones. Some state-of-the-art models, such as HRM, need to factorize a new built user-item matrix to get users' representation vectors. Therefore this iterative learning method may be more practical in real-world applications.\n\n\nEXPERIMENTS\n\n\nDatasets and Baselines\n\nTo evaluate the performance of our method on the task of next basket recommendation, we perform experiments on two real-world datasets, i.e., Ta-Feng 1 and T-mall 2 . The Ta-Feng dataset contains numerous baskets of purchased items from a grocery store, where each basket encapsulates the items purchased by one user in a period of time. This dataset is a public dataset which contains 817,741 transactions belonging to 32,266 users and 23,812 items. The Tmall dataset is a public online e-commerce dataset released 1 http://recsyswiki.com/wiki/Grocery shopping datasets 2 http://102.alibaba.com/competition/addDiscovery/index.htm by Alibaba group 3 , which contains 4,298 transactions of 884 users and 9,531 brands. The slight difference between these two datasets is that the T-mall dataset records the transactions based on brands and each brand may covers a series of items. The above datasets are preprocessed to obtain kcore subsets [7], i.e. each user u purchased in total at least k items t i B u t i k and vice versa each item was purchased by at least k users. We set k = 10 for the Ta-Feng dataset, and k = 3 for the relatively smaller T-Mall dataset.\n\nSeveral baseline and state-of-the-art methods on nextbasket recommendation are used for empirical comparison.\n\n(1) TOP recommends the top popular items to each user.\n\n(2) MC is a Markov chain model based on sequential transaction information of a user. The prediction function is as follows:    \np i \u2208 B u t i |B u t i\u22121 := 1 B u t i\u22121 j\u2208B u t i\u22121 p i \u2208 B u t i |j \u2208 B u t i\u22121 (3) NMF\n\nMetrics and Setup\n\nFor recommendation, we generate a ranking list of K items (K = 5) for each user u. In order to measure the performance of next basket recommendation, we adopt two evaluation metrics, i.e., F 1-score and Normalized Discounted Cumulative Gain (N DCG). F 1-score calculates the harmonic mean of the precision and recall measurements. N DCG is a cumulative measure of ranking quality, which is more sensitive to the relevance of higher ranked items. For both metrics, the larger the value, the better the performance.\n\nOn both datasets, we use the last transaction of each user as the testing data and all the rest transactions as the training data. The vector representations of items are randomly initialized. Moreover, performance results of different methods are compared along with varying dimensions d of the representation. We illustrate the results with dimensions {50, 100, 150} for the Ta-Feng dataset, and {10, 15, 20} for the relatively smaller T-Mall dataset.\n\n\nResults and Analyses\n\nFirst, the performance of DREAM model are compared with the state-of-the-art methods. As illustrated in Figure  2, in general, the performance ranking of next basket recommendation methods is as follows, DREAM, HRM, FPMC, NMF, MC and TOP. Since the baseline TOP just list the popular items and does not utilize the features of separate baskets, this method is the weakest one among all methods. Despite the fact that NMF and MC leverage only one kind of feature, either sequential behaviors or users' general interests, we can observe that the NMF model achieve better performance than that of the MC model, especially on the sparse T-mall data. It may be because that MC cannot reveal the collaborative information among users. On the sparse user-item matrix of T-mall, collaborative information is more important to generate the accurate interests of users than the sparse sequential behaviors. On both datasets, the HRM model outperforms the FPMC model. Though FPMC and HRM both utilize sequential behaviors, the nonlinear operations among multiple factors of HRM earn it a better performance, while the FPMC model's linear independence assumption of interaction relationship of items in a basket makes it inapplicable in complex commercial scenarios. The proposed DREAM model can consistently outperform all comparing models in terms of both metrics on two datasets. These results show that the dynamic representation of user with a recurrent architecture is effective in capturing sequential features and dynamic interests of users. Besides, richer nonlinear operations such as pooling and activation functions contribute to a better representations of baskets.\n\nThen, we assess performances of the DREAM model with max pooling and average pooling. As illustrated in Table 1, DREAM with max pooling can outperform DREAM with average pooling on both datasets with F 1-score@5 and N DCG@5. It demonstrates that max pooling gains advantage over average pooling in modeling interactions among multiple factors. Obviously, as a linear operation, average pooling takes an average representation of a basket, indicating that each item in a basket measures the basket representation in an independent way. In real-world scenario, many items we purchase are interactive, that is to say, one item influences whether we purchase another item, then the whole items we purchase can help shape our interests. Consequently a better solution is to learn the elaborate interaction relationship of a basket of items through a nonlinear operation. M ax pooling is a nonlinear operation, which takes a key representation of a basket and is more capable to learn those complicated interactions than a linear operation.\n\n\nCONCLUSIONS\n\nIn this paper, we have proposed a dynamic recurrent basket model based on RNN for next basket recommendation. Our model can merge users' current interests and global sequential features into users' recurrent and dynamic representation. Moreover, it shows that the nonlinear operation on learning the representation of a basket does well in capturing elaborate interactions among multiple factors of items. Extensive experiments on two public datasets demonstrated the effectiveness of the proposed model.\n\n\nACKNOWLEDGMENTS\n\nThis work is jointly supported by National Basic Research Program of China (2012CB316300), and National Natural Science Foundation of China (61403390, U1435221, 61525306).\n\nSIGIR ' 16 ,\n16July 17-21, 2016, Pisa, Italy \u00a9 2016 ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00 DOI: http://dx.doi.org/10.1145/2911451.2914683\n\nFigure 1 :\n1The framework of DREAM. Pooling operation on the items in a basket to get the representation of the basket. The input layer comprises a series of basket representations of a user. Dynamic representation of the user can be obtained in the hidden layer. Finally the output layer shows scores of this user towards all items.\n\nFigure 2 :\n2Experiment Results of different methods on two datasets.\n\nTable 1 :\n1Performance comparison of two pooling operations on two datasetsMethods \n\nTa-Feng \n\nhttp://www.alibabagroup.com/cn/global/home 4 http://cogsys.imm.dtu.dk/toolbox/nmf/\n\nToward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. G Adomavicius, A Tuzhilin, TKDE. 176G. Adomavicius and A. Tuzhilin. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. TKDE, 17(6):734-749, 2005.\n\nPlaylist prediction via metric embedding. S Chen, J L Moore, D Turnbull, T Joachims, SIGKDD. S. Chen, J. L. Moore, D. Turnbull, and T. Joachims. Playlist prediction via metric embedding. In SIGKDD, pages 714-722, 2012.\n\nA case-based recommendation approach for market basket data. A Gatzioura, M Sanchez-Marre, IEEE Intelligent Systems. 301A. Gatzioura and M. Sanchez-Marre. A case-based recommendation approach for market basket data. IEEE Intelligent Systems, 30(1):20-27, 2015.\n\nMatrix factorization techniques for recommender systems. Y Koren, R Bell, C Volinsky, IEEE Computer. 8Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. IEEE Computer, (8):30-37, 2009.\n\nExtensions of recurrent neural network language model. T Mikolov, S Kombrink, L Burget, J H \u010cernock\u1ef3, S Khudanpur, ICASSP. T. Mikolov, S. Kombrink, L. Burget, J. H.\u010cernock\u1ef3, and S. Khudanpur. Extensions of recurrent neural network language model. In ICASSP, pages 5528-5531, 2011.\n\nBpr: Bayesian personalized ranking from implicit feedback. S Rendle, C Freudenthaler, Z Gantner, L Schmidt-Thieme, UAI. S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme. Bpr: Bayesian personalized ranking from implicit feedback. In UAI, pages 452-461, 2009.\n\nFactorizing personalized markov chains for next-basket recommendation. S Rendle, C Freudenthaler, L Schmidt-Thieme, WWW. S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. Factorizing personalized markov chains for next-basket recommendation. In WWW, pages 811-820, 2010.\n\nLearning representations by back-propagating errors. D E Rumelhart, G E Hinton, R J Williams, Cognitive modeling. 53D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning representations by back-propagating errors. Cognitive modeling, 5:3, 1988.\n\nLearning hierarchical representation model for nextbasket recommendation. P Wang, J Guo, Y Lan, J Xu, S Wan, X Cheng, SIGIR. P. Wang, J. Guo, Y. Lan, J. Xu, S. Wan, and X. Cheng. Learning hierarchical representation model for nextbasket recommendation. In SIGIR, pages 403-412, 2015.\n\nSequential click prediction for sponsored search with recurrent neural networks. Y Zhang, H Dai, C Xu, J Feng, T Wang, J Bian, B Wang, T.-Y Liu, In AAAI. Y. Zhang, H. Dai, C. Xu, J. Feng, T. Wang, J. Bian, B. Wang, and T.-Y. Liu. Sequential click prediction for sponsored search with recurrent neural networks. In AAAI, pages 1369-1376, 2014.\n", "annotations": {"author": "[{\"end\":247,\"start\":60},{\"end\":439,\"start\":248},{\"end\":625,\"start\":440},{\"end\":818,\"start\":626},{\"end\":987,\"start\":819}]", "publisher": null, "author_last_name": "[{\"end\":67,\"start\":65},{\"end\":257,\"start\":254},{\"end\":446,\"start\":444},{\"end\":636,\"start\":632},{\"end\":829,\"start\":826}]", "author_first_name": "[{\"end\":64,\"start\":60},{\"end\":253,\"start\":248},{\"end\":443,\"start\":440},{\"end\":631,\"start\":626},{\"end\":825,\"start\":819}]", "author_affiliation": "[{\"end\":246,\"start\":91},{\"end\":438,\"start\":283},{\"end\":624,\"start\":469},{\"end\":817,\"start\":662},{\"end\":986,\"start\":831}]", "title": "[{\"end\":57,\"start\":1},{\"end\":1044,\"start\":988}]", "venue": null, "abstract": "[{\"end\":2197,\"start\":1121}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2454,\"start\":2451},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2456,\"start\":2454},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3409,\"start\":3406},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3795,\"start\":3792},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4260,\"start\":4257},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4662,\"start\":4659},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5902,\"start\":5899},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5936,\"start\":5932},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9857,\"start\":9853},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10893,\"start\":10890},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":11753,\"start\":11750},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13412,\"start\":13409}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":18591,\"start\":18446},{\"attributes\":{\"id\":\"fig_2\"},\"end\":18926,\"start\":18592},{\"attributes\":{\"id\":\"fig_4\"},\"end\":18996,\"start\":18927},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":19092,\"start\":18997}]", "paragraph": "[{\"end\":2457,\"start\":2213},{\"end\":2752,\"start\":2459},{\"end\":3927,\"start\":2754},{\"end\":5410,\"start\":3929},{\"end\":6637,\"start\":5412},{\"end\":7337,\"start\":6639},{\"end\":7486,\"start\":7363},{\"end\":7823,\"start\":7510},{\"end\":8096,\"start\":7879},{\"end\":8300,\"start\":8106},{\"end\":8721,\"start\":8570},{\"end\":8910,\"start\":8723},{\"end\":9441,\"start\":8967},{\"end\":10028,\"start\":9490},{\"end\":10540,\"start\":10068},{\"end\":10788,\"start\":10567},{\"end\":11223,\"start\":10811},{\"end\":11488,\"start\":11265},{\"end\":12004,\"start\":11538},{\"end\":12429,\"start\":12006},{\"end\":13632,\"start\":12470},{\"end\":13743,\"start\":13634},{\"end\":13799,\"start\":13745},{\"end\":13929,\"start\":13801},{\"end\":14552,\"start\":14039},{\"end\":15007,\"start\":14554},{\"end\":16698,\"start\":15032},{\"end\":17734,\"start\":16700},{\"end\":18254,\"start\":17750},{\"end\":18445,\"start\":18274}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7878,\"start\":7824},{\"attributes\":{\"id\":\"formula_1\"},\"end\":8569,\"start\":8301},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8966,\"start\":8911},{\"attributes\":{\"id\":\"formula_3\"},\"end\":9489,\"start\":9442},{\"attributes\":{\"id\":\"formula_4\"},\"end\":10067,\"start\":10029},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10566,\"start\":10541},{\"attributes\":{\"id\":\"formula_6\"},\"end\":11264,\"start\":11224},{\"attributes\":{\"id\":\"formula_7\"},\"end\":11537,\"start\":11489},{\"attributes\":{\"id\":\"formula_8\"},\"end\":14018,\"start\":13930}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":16811,\"start\":16804}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2211,\"start\":2199},{\"attributes\":{\"n\":\"2.\"},\"end\":7361,\"start\":7340},{\"attributes\":{\"n\":\"2.1\"},\"end\":7508,\"start\":7489},{\"attributes\":{\"n\":\"2.2\"},\"end\":8104,\"start\":8099},{\"attributes\":{\"n\":\"2.3\"},\"end\":10809,\"start\":10791},{\"attributes\":{\"n\":\"3.\"},\"end\":12443,\"start\":12432},{\"attributes\":{\"n\":\"3.1\"},\"end\":12468,\"start\":12446},{\"attributes\":{\"n\":\"3.2\"},\"end\":14037,\"start\":14020},{\"attributes\":{\"n\":\"3.3\"},\"end\":15030,\"start\":15010},{\"attributes\":{\"n\":\"4.\"},\"end\":17748,\"start\":17737},{\"attributes\":{\"n\":\"5.\"},\"end\":18272,\"start\":18257},{\"end\":18459,\"start\":18447},{\"end\":18603,\"start\":18593},{\"end\":18938,\"start\":18928},{\"end\":19007,\"start\":18998}]", "table": "[{\"end\":19092,\"start\":19073}]", "figure_caption": "[{\"end\":18591,\"start\":18462},{\"end\":18926,\"start\":18605},{\"end\":18996,\"start\":18940},{\"end\":19073,\"start\":19009}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":8164,\"start\":8155},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":9606,\"start\":9598},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":15145,\"start\":15136}]", "bib_author_first_name": "[{\"end\":19287,\"start\":19286},{\"end\":19302,\"start\":19301},{\"end\":19534,\"start\":19533},{\"end\":19542,\"start\":19541},{\"end\":19544,\"start\":19543},{\"end\":19553,\"start\":19552},{\"end\":19565,\"start\":19564},{\"end\":19773,\"start\":19772},{\"end\":19786,\"start\":19785},{\"end\":20031,\"start\":20030},{\"end\":20040,\"start\":20039},{\"end\":20048,\"start\":20047},{\"end\":20257,\"start\":20256},{\"end\":20268,\"start\":20267},{\"end\":20280,\"start\":20279},{\"end\":20290,\"start\":20289},{\"end\":20292,\"start\":20291},{\"end\":20304,\"start\":20303},{\"end\":20543,\"start\":20542},{\"end\":20553,\"start\":20552},{\"end\":20570,\"start\":20569},{\"end\":20581,\"start\":20580},{\"end\":20828,\"start\":20827},{\"end\":20838,\"start\":20837},{\"end\":20855,\"start\":20854},{\"end\":21084,\"start\":21083},{\"end\":21086,\"start\":21085},{\"end\":21099,\"start\":21098},{\"end\":21101,\"start\":21100},{\"end\":21111,\"start\":21110},{\"end\":21113,\"start\":21112},{\"end\":21357,\"start\":21356},{\"end\":21365,\"start\":21364},{\"end\":21372,\"start\":21371},{\"end\":21379,\"start\":21378},{\"end\":21385,\"start\":21384},{\"end\":21392,\"start\":21391},{\"end\":21649,\"start\":21648},{\"end\":21658,\"start\":21657},{\"end\":21665,\"start\":21664},{\"end\":21671,\"start\":21670},{\"end\":21679,\"start\":21678},{\"end\":21687,\"start\":21686},{\"end\":21695,\"start\":21694},{\"end\":21706,\"start\":21702}]", "bib_author_last_name": "[{\"end\":19299,\"start\":19288},{\"end\":19311,\"start\":19303},{\"end\":19539,\"start\":19535},{\"end\":19550,\"start\":19545},{\"end\":19562,\"start\":19554},{\"end\":19574,\"start\":19566},{\"end\":19783,\"start\":19774},{\"end\":19800,\"start\":19787},{\"end\":20037,\"start\":20032},{\"end\":20045,\"start\":20041},{\"end\":20057,\"start\":20049},{\"end\":20265,\"start\":20258},{\"end\":20277,\"start\":20269},{\"end\":20287,\"start\":20281},{\"end\":20301,\"start\":20293},{\"end\":20314,\"start\":20305},{\"end\":20550,\"start\":20544},{\"end\":20567,\"start\":20554},{\"end\":20578,\"start\":20571},{\"end\":20596,\"start\":20582},{\"end\":20835,\"start\":20829},{\"end\":20852,\"start\":20839},{\"end\":20870,\"start\":20856},{\"end\":21096,\"start\":21087},{\"end\":21108,\"start\":21102},{\"end\":21122,\"start\":21114},{\"end\":21362,\"start\":21358},{\"end\":21369,\"start\":21366},{\"end\":21376,\"start\":21373},{\"end\":21382,\"start\":21380},{\"end\":21389,\"start\":21386},{\"end\":21398,\"start\":21393},{\"end\":21655,\"start\":21650},{\"end\":21662,\"start\":21659},{\"end\":21668,\"start\":21666},{\"end\":21676,\"start\":21672},{\"end\":21684,\"start\":21680},{\"end\":21692,\"start\":21688},{\"end\":21700,\"start\":21696},{\"end\":21710,\"start\":21707}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":206742345},\"end\":19489,\"start\":19177},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":9956461},\"end\":19709,\"start\":19491},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":2807840},\"end\":19971,\"start\":19711},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":58370896},\"end\":20199,\"start\":19973},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":14850173},\"end\":20481,\"start\":20201},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":10795036},\"end\":20754,\"start\":20483},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":207178809},\"end\":21028,\"start\":20756},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":205001834},\"end\":21280,\"start\":21030},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":4002880},\"end\":21565,\"start\":21282},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":9655225},\"end\":21909,\"start\":21567}]", "bib_title": "[{\"end\":19284,\"start\":19177},{\"end\":19531,\"start\":19491},{\"end\":19770,\"start\":19711},{\"end\":20028,\"start\":19973},{\"end\":20254,\"start\":20201},{\"end\":20540,\"start\":20483},{\"end\":20825,\"start\":20756},{\"end\":21081,\"start\":21030},{\"end\":21354,\"start\":21282},{\"end\":21646,\"start\":21567}]", "bib_author": "[{\"end\":19301,\"start\":19286},{\"end\":19313,\"start\":19301},{\"end\":19541,\"start\":19533},{\"end\":19552,\"start\":19541},{\"end\":19564,\"start\":19552},{\"end\":19576,\"start\":19564},{\"end\":19785,\"start\":19772},{\"end\":19802,\"start\":19785},{\"end\":20039,\"start\":20030},{\"end\":20047,\"start\":20039},{\"end\":20059,\"start\":20047},{\"end\":20267,\"start\":20256},{\"end\":20279,\"start\":20267},{\"end\":20289,\"start\":20279},{\"end\":20303,\"start\":20289},{\"end\":20316,\"start\":20303},{\"end\":20552,\"start\":20542},{\"end\":20569,\"start\":20552},{\"end\":20580,\"start\":20569},{\"end\":20598,\"start\":20580},{\"end\":20837,\"start\":20827},{\"end\":20854,\"start\":20837},{\"end\":20872,\"start\":20854},{\"end\":21098,\"start\":21083},{\"end\":21110,\"start\":21098},{\"end\":21124,\"start\":21110},{\"end\":21364,\"start\":21356},{\"end\":21371,\"start\":21364},{\"end\":21378,\"start\":21371},{\"end\":21384,\"start\":21378},{\"end\":21391,\"start\":21384},{\"end\":21400,\"start\":21391},{\"end\":21657,\"start\":21648},{\"end\":21664,\"start\":21657},{\"end\":21670,\"start\":21664},{\"end\":21678,\"start\":21670},{\"end\":21686,\"start\":21678},{\"end\":21694,\"start\":21686},{\"end\":21702,\"start\":21694},{\"end\":21712,\"start\":21702}]", "bib_venue": "[{\"end\":19317,\"start\":19313},{\"end\":19582,\"start\":19576},{\"end\":19826,\"start\":19802},{\"end\":20072,\"start\":20059},{\"end\":20322,\"start\":20316},{\"end\":20601,\"start\":20598},{\"end\":20875,\"start\":20872},{\"end\":21142,\"start\":21124},{\"end\":21405,\"start\":21400},{\"end\":21719,\"start\":21712}]"}}}, "year": 2023, "month": 12, "day": 17}